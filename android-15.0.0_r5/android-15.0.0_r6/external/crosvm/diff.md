```diff
diff --git a/.cargo/config.toml b/.cargo/config.toml
index 1f84c3bbf..455cc2d71 100644
--- a/.cargo/config.toml
+++ b/.cargo/config.toml
@@ -16,6 +16,7 @@ rustflags = [
     "-Aclippy::needless_bool",
     "-Aclippy::new-ret-no-self",
     "-Aclippy::or_fun_call",
+    "-Aclippy::result_large_err",
     "-Aclippy::result-unit-err",
     "-Aclippy::should_implement_trait",
     "-Aclippy::single_char_pattern",
diff --git a/Android.bp b/Android.bp
index 8ee30fcc9..8cb75873f 100644
--- a/Android.bp
+++ b/Android.bp
@@ -42,7 +42,7 @@ rust_binary {
     crate_name: "crosvm",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/main.rs"],
+    crate_root: "src/main.rs",
     edition: "2021",
     features: [
         "android-sparse",
@@ -82,6 +82,7 @@ rust_binary {
         "libcrosvm_cli",
         "libdevices",
         "libdisk",
+        "libext2",
         "libgdbstub",
         "libgdbstub_arch",
         "libhypervisor",
@@ -93,6 +94,7 @@ rust_binary {
         "liblog_rust",
         "libmerge",
         "libmetrics",
+        "libmetrics_events",
         "libminijail_rust",
         "libnet_util",
         "libonce_cell",
@@ -106,12 +108,12 @@ rust_binary {
         "libstatic_assertions",
         "libswap",
         "libsync_rust",
-        "libtempfile",
         "libthiserror",
         "libuuid",
         "libvhost",
         "libvm_control",
         "libvm_memory",
+        "libvmm_vhost",
         "libzerocopy",
     ],
     proc_macros: [
@@ -178,7 +180,7 @@ rust_test {
     crate_name: "crosvm",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/main.rs"],
+    crate_root: "src/main.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -223,6 +225,7 @@ rust_test {
         "libcrosvm_cli",
         "libdevices",
         "libdisk",
+        "libext2",
         "libgdbstub",
         "libgdbstub_arch",
         "libhypervisor",
@@ -234,6 +237,7 @@ rust_test {
         "liblog_rust",
         "libmerge",
         "libmetrics",
+        "libmetrics_events",
         "libminijail_rust",
         "libnet_util",
         "libonce_cell",
@@ -254,6 +258,7 @@ rust_test {
         "libvhost",
         "libvm_control",
         "libvm_memory",
+        "libvmm_vhost",
         "libzerocopy",
     ],
     proc_macros: [
@@ -326,7 +331,8 @@ rust_defaults {
     ],
     defaults_visibility: [
         "//external/crosvm:__subpackages__",
-        "//packages/modules/Virtualization/authfs",
+        "//packages/modules/Virtualization/guest/authfs",
+        "//packages/modules/Virtualization/tests/authfs",
         // For QCOM's crosvm fork.
         "//vendor:__subpackages__",
     ],
diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
index 8463fe481..07f5175ce 100644
--- a/CONTRIBUTING.md
+++ b/CONTRIBUTING.md
@@ -106,10 +106,54 @@ pointing to the tip of the branch.
 ### Getting Reviews
 
 All submissions needs to be reviewed by one of the [crosvm owners]. Use the gerrit UI to request a
-review. If you are uncertain about the correct person to review, reach out to the team via
+review and add crosvm-reviews@google.com to assign to a random owner.
+
+If you run into issues with reviews, reach out to the team via
 [chat](https://matrix.to/#/#crosvm:matrix.org) or
 [email list](https://groups.google.com/a/chromium.org/g/crosvm-dev).
 
+**For Googlers**: see [go/crosvm-chat](https://goto.google.com/crosvm-chat).
+
+#### Any change to Cargo.lock
+
+When adding a new crate from crates.io, additional review is required to ensure that the crate meets
+the crosvm project standards. This review is provided by the members of `OWNERS_COUNCIL`.
+
+Unfortunately, our tooling cannot tell the difference between adding an external crate and changing
+dependencies within crosvm (e.g. `devices` depending on a new internal crosvm utility crate). For
+those cases, a rubberstamp is still needed from `OWNERS_COUNCIL`.
+
+**For Googlers**: see [go/crosvm/3p_crates](https://goto.google.com/crosvm/3p_crates).
+
+### Reviewing code (for OWNERS)
+
+We have two major types of reviewers on the project:
+
+1. Global OWNERS: these folks are broadly responsible for the health of the crosvm project, and have
+   expertise in multiple project subdomains. While they can technically approve any change, they
+   will often delegate to area OWNERS when a change is outside their expertise.
+1. Area OWNERS: experts in a particular subdomain of the project (e.g. graphics, USB, etc). Major
+   changes in an area SHOULD be reviewed by an area OWNER, if one exists (not all subdomains have
+   OWNERS).
+
+All owners are expected to review code in their areas, and to aim for the following goals in
+reviews:
+
+- Reply to reviews within 1 working day. If this is infeasible (especially if overloaded), reassign
+  to crosvm-reviews@ to pick another OWNER at random.
+- Defer to the [styleguide](./coding_style.md) where it makes sense to do so. Update the styleguide
+  when it does not.
+- Strive to avoid reviews getting stuck in endless back & forth. If you see this happening, you can:
+  - Schedule a meeting to discuss it online. Consider inviting another OWNER to help brainstorm
+    solutions.
+  - Bring the review discussion to the hallway chat to let the group weigh in.
+- Follow generally accepted practices for good code review
+  - Technically: We insist on good documentation, clean APIs especially when broadly consumed, and
+    generally keep code health in mind.
+  - Socially: Our goal, above all else, is to be good peers to each other. So we review *code*, not
+    *authors*. We remember to disagree respectfully, and that a code review is a team effort (author
+    and reviewer) against a hard technical problem.
+
 ### Submitting code
 
 Crosvm uses a Commit Queue, which will run pre-submit testing on all changes before merging them
diff --git a/Cargo.lock b/Cargo.lock
index 698ded8b7..a4889c642 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -6,6 +6,7 @@ version = 3
 name = "aarch64"
 version = "0.1.0"
 dependencies = [
+ "anyhow",
  "arch",
  "base",
  "cros_fdt",
@@ -17,7 +18,6 @@ dependencies = [
  "kernel_cmdline",
  "kernel_loader",
  "libc",
- "memoffset 0.6.5",
  "minijail",
  "rand",
  "remain",
@@ -71,6 +71,12 @@ dependencies = [
  "thiserror",
 ]
 
+[[package]]
+name = "android_log-sys"
+version = "0.3.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5ecc8056bf6ab9892dcd53216c83d1597487d7dacac16c8df6b877d127df9937"
+
 [[package]]
 name = "anti_tamper"
 version = "0.1.0"
@@ -117,6 +123,7 @@ dependencies = [
  "serde_keyvalue",
  "swap",
  "sync",
+ "tempfile",
  "thiserror",
  "uuid",
  "vm_control",
@@ -218,7 +225,6 @@ dependencies = [
  "cfg-if",
  "cros_async",
  "libcras",
- "minijail",
  "remain",
  "serde",
  "serde_json",
@@ -267,15 +273,15 @@ dependencies = [
 name = "base"
 version = "0.1.0"
 dependencies = [
+ "android_log-sys",
  "audio_streams",
  "base_event_token_derive",
  "cfg-if",
  "chrono",
  "env_logger",
+ "futures",
  "libc",
- "libtest-mimic",
  "log",
- "minijail",
  "once_cell",
  "protobuf",
  "protos",
@@ -302,6 +308,21 @@ dependencies = [
  "syn 2.0.37",
 ]
 
+[[package]]
+name = "base_tokio"
+version = "0.1.0"
+dependencies = [
+ "anyhow",
+ "base",
+ "cfg-if",
+ "futures",
+ "libc",
+ "serde",
+ "sync",
+ "tokio",
+ "winapi",
+]
+
 [[package]]
 name = "bindgen"
 version = "0.63.0"
@@ -791,6 +812,7 @@ dependencies = [
  "disk",
  "document-features",
  "enumn",
+ "ext2",
  "futures",
  "gdbstub",
  "gdbstub_arch",
@@ -806,6 +828,7 @@ dependencies = [
  "log",
  "merge",
  "metrics",
+ "metrics_events",
  "minijail",
  "net_util",
  "once_cell",
@@ -833,6 +856,7 @@ dependencies = [
  "vhost",
  "vm_control",
  "vm_memory",
+ "vmm_vhost",
  "win_audio",
  "win_util",
  "winapi",
@@ -876,6 +900,7 @@ name = "crosvm_control"
 version = "0.1.0"
 dependencies = [
  "anyhow",
+ "balloon_control",
  "base",
  "cbindgen",
  "cc",
@@ -996,13 +1021,13 @@ dependencies = [
  "futures",
  "gpu_display",
  "hypervisor",
+ "jail",
  "kvm_sys",
  "libc",
  "libcras",
  "libtest-mimic",
  "libvda",
  "linux_input_sys",
- "memoffset 0.6.5",
  "metrics",
  "minijail",
  "named-lock",
@@ -1062,6 +1087,7 @@ dependencies = [
  "thiserror",
  "uuid",
  "vm_memory",
+ "winapi",
  "zerocopy",
 ]
 
@@ -1076,9 +1102,9 @@ dependencies = [
 
 [[package]]
 name = "downcast-rs"
-version = "1.2.0"
+version = "1.2.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9ea835d29036a4087793836fa931b08837ad5e957da9e23886b29586fb9b6650"
+checksum = "75b325c5dbd37f80359721ad39aca5a29fb04c89279657cffdda8736d0c0b9d2"
 
 [[package]]
 name = "e2e_tests"
@@ -1154,6 +1180,22 @@ dependencies = [
  "num-traits",
 ]
 
+[[package]]
+name = "ext2"
+version = "0.1.0"
+dependencies = [
+ "anyhow",
+ "argh",
+ "base",
+ "enumn",
+ "libc",
+ "tempfile",
+ "uuid",
+ "walkdir",
+ "zerocopy",
+ "zerocopy-derive",
+]
+
 [[package]]
 name = "fastrand"
 version = "1.8.0"
@@ -1459,12 +1501,9 @@ dependencies = [
  "downcast-rs",
  "enumn",
  "fnv",
- "gdbstub",
- "gdbstub_arch",
- "kvm",
+ "hypervisor_test_macro",
  "kvm_sys",
  "libc",
- "memoffset 0.6.5",
  "once_cell",
  "serde",
  "serde_json",
@@ -1475,6 +1514,17 @@ dependencies = [
  "win_util",
  "winapi",
  "windows",
+ "zerocopy",
+]
+
+[[package]]
+name = "hypervisor_test_macro"
+version = "0.1.0"
+dependencies = [
+ "proc-macro2",
+ "quote 1.0.33",
+ "rand",
+ "syn 2.0.37",
 ]
 
 [[package]]
@@ -1508,11 +1558,11 @@ dependencies = [
 
 [[package]]
 name = "intrusive-collections"
-version = "0.9.4"
+version = "0.9.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bfe531a7789d7120f3e17d4f3f2cd95f54418ba7354f60b7b622b6644a07888a"
+checksum = "b694dc9f70c3bda874626d2aed13b780f137aab435f4e9814121955cf706122e"
 dependencies = [
- "memoffset 0.5.6",
+ "memoffset 0.9.0",
 ]
 
 [[package]]
@@ -1563,6 +1613,8 @@ dependencies = [
  "base",
  "cfg-if",
  "libc",
+ "libtest-mimic",
+ "log",
  "minijail",
  "once_cell",
  "rayon",
@@ -1785,24 +1837,6 @@ version = "2.5.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "2dffe52ecf27772e601905b7522cb4ef790d2cc203488bbd0e2fe85fcb74566d"
 
-[[package]]
-name = "memoffset"
-version = "0.5.6"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "043175f069eda7b85febe4a74abbaeff828d9f8b448515d3151a14a3542811aa"
-dependencies = [
- "autocfg",
-]
-
-[[package]]
-name = "memoffset"
-version = "0.6.5"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5aa361d4faea93603064a027415f07bd8e1d5c88c9fbf68bf56a285428fd79ce"
-dependencies = [
- "autocfg",
-]
-
 [[package]]
 name = "memoffset"
 version = "0.8.0"
@@ -2489,8 +2523,6 @@ dependencies = [
  "gdbstub_arch",
  "hypervisor",
  "kernel_cmdline",
- "kvm",
- "kvm_sys",
  "libc",
  "minijail",
  "rand",
@@ -2550,6 +2582,15 @@ version = "1.0.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "f3f6f92acf49d1b98f7a81226834412ada05458b7364277387724a237f062695"
 
+[[package]]
+name = "same-file"
+version = "1.0.6"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "93fc1dc3aaa9bfed95e02e6eadabb4baf7e3078b0bd1b4d7b6b0b68378900502"
+dependencies = [
+ "winapi-util",
+]
+
 [[package]]
 name = "sandbox"
 version = "0.1.0"
@@ -2861,9 +2902,21 @@ dependencies = [
  "num_cpus",
  "pin-project-lite",
  "socket2",
+ "tokio-macros",
  "windows-sys 0.48.0",
 ]
 
+[[package]]
+name = "tokio-macros"
+version = "2.1.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "630bdcf245f78637c13ec01ffae6187cca34625e8c63150d424b59e55af2675e"
+dependencies = [
+ "proc-macro2",
+ "quote 1.0.33",
+ "syn 2.0.37",
+]
+
 [[package]]
 name = "toml"
 version = "0.5.9"
@@ -2983,9 +3036,9 @@ dependencies = [
 
 [[package]]
 name = "uuid"
-version = "1.3.0"
+version = "1.8.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1674845326ee10d37ca60470760d4288a6f80f304007d92e5c53bab78c9cfd79"
+checksum = "a183cf7feeba97b4dd1c0d46788634f6221d87fa961b305bed08c851829efcc0"
 dependencies = [
  "getrandom",
  "serde",
@@ -3144,6 +3197,16 @@ dependencies = [
  "vk-parse",
 ]
 
+[[package]]
+name = "walkdir"
+version = "2.5.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "29790946404f91d9c5d06f9874efddea1dc06c5efe94541a7d6863108e3a5e4b"
+dependencies = [
+ "same-file",
+ "winapi-util",
+]
+
 [[package]]
 name = "wasi"
 version = "0.11.0+wasi-snapshot-preview1"
@@ -3450,7 +3513,6 @@ dependencies = [
  "kernel_cmdline",
  "kernel_loader",
  "libc",
- "memoffset 0.6.5",
  "minijail",
  "once_cell",
  "rand",
@@ -3473,9 +3535,9 @@ checksum = "0fcb9cbac069e033553e8bb871be2fbdffcab578eb25bd0f7c508cedc6dcd75a"
 
 [[package]]
 name = "zerocopy"
-version = "0.7.5"
+version = "0.7.32"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "870cdd4b8b867698aea998d95bcc06c1d75fe566267781ee6f5ae8c9c45a3930"
+checksum = "74d4d3961e53fa4c9a25a8637fc2bfaf2595b3d3ae34875568a5cf64787716be"
 dependencies = [
  "byteorder",
  "zerocopy-derive",
@@ -3483,9 +3545,9 @@ dependencies = [
 
 [[package]]
 name = "zerocopy-derive"
-version = "0.7.5"
+version = "0.7.32"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e9c6f95fa5657518b36c6784ba7cdd89e8bdf9a16e58266085248bfb950860c5"
+checksum = "9ce1b18ccd8e73a9321186f97e46f9f04b778851177567b1975109d26a08d2a6"
 dependencies = [
  "proc-macro2",
  "quote 1.0.33",
diff --git a/Cargo.toml b/Cargo.toml
index c71b03948..d4a3eefdf 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -45,6 +45,7 @@ members = [
     "audio_util",
     "audio_streams_conformance_test",
     "base",
+    "base_tokio",
     "bit_field",
     "broker_ipc",
     "common/audio_streams",
@@ -60,10 +61,12 @@ members = [
     "devices",
     "disk",
     "e2e_tests",
+    "ext2",
     "fuse",
     "fuzz",
     "gpu_display",
     "hypervisor",
+    "hypervisor/hypervisor_test_macro",
     "io_uring",
     "kernel_cmdline",
     "kernel_loader",
@@ -112,6 +115,9 @@ exclude = [
     "media/libvda",
 ]
 
+[workspace.dependencies]
+tokio = { version = "1.29.1", features = ["net", "rt-multi-thread", "time", "sync", "macros"] }
+
 [features]
 ## Default features of crosvm. This selection is somewhat arbitrary for historical reasons.
 default = ["audio", "balloon", "config-file", "document-features", "gpu", "qcow", "usb", "libvda-stub", "net", "slirp"]
@@ -157,7 +163,7 @@ net = ["devices/net"]
 ## Enables PCI hotplug. Only available on Linux, and currently only for x86/x86-64.
 pci-hotplug = ["devices/pci-hotplug", "vm_control/pci-hotplug"]
 
-## Enables virtio-pvclock. Only available on Linux, and currently only for x86/x86-64.
+## Enables virtio-pvclock. Currently only available for x86-64 and aarch64.
 pvclock = ["devices/pvclock"]
 
 ## Enables the use of the qcow format for block devices.
@@ -291,8 +297,11 @@ default-no-sandbox = []
 #!
 #! These features will only be functional in ChromeOS builds running on ChromeOS.
 
-## Enables virtio-fs quota reporting for ARCVM. Requires access to the
-## org.chromium.ArcQuota dbus service.
+## Enables ARCVM specified virtio-fs feature including:
+## - Support quota reporting for ARCVM
+##   Requires access to the org.chromium.ArcQuota dbus service.
+## - Support for FS_IOC_SETPERMISSION ioctl
+## - Support for FS_IOC_SETPATHXATTR ioctl
 arc_quota = ["devices/arc_quota"]
 
 ## Enables use of Android AAudio virtio-snd backend.
@@ -356,6 +365,7 @@ all-default = [
     "noncoherent-dma",
     "pci-hotplug",
     "power-monitor-powerd",
+    "pvclock",
     "registered_events",
     "slirp",
     "swap",
@@ -393,7 +403,6 @@ all-x86_64 = [
     "android_display_stub",
     "libaaudio_stub",
     "plugin",
-    "pvclock",
     "scudo"
 ]
 
@@ -420,18 +429,38 @@ all-mingw64 = [
     "slirp",
     "stats",
     "vulkan_display",
+    "pvclock",
 ]
 
 ## All features that are compiled and tested for msvc64
 all-msvc64 = [ "all-mingw64" ]
 
+## All features that are compiled and tested for android builds
+all-android = [
+        "android-sparse",
+        "audio",
+        "audio_aaudio",
+        "balloon",
+        "config-file",
+        "gdb",
+        "gdbstub",
+        "gdbstub_arch",
+        "geniezone",
+        "gunyah",
+        "libaaudio_stub",
+        "net",
+        "qcow",
+        "usb",
+        "composite-disk",
+]
+
 [dependencies]
 anyhow = "1.0.32"
 arch = { path = "arch" }
 argh = "0.1.10"
 argh_helpers = { path = "argh_helpers" }
 audio_streams = "*"
-base = "*"
+base = { path = "base" }
 bit_field = { path = "bit_field" }
 broker_ipc = { path = "broker_ipc" }
 cfg-if = "1.0.0"
@@ -444,6 +473,7 @@ devices = { path = "devices" }
 disk = { path = "disk" }
 document-features = { version = "0.2", optional = true }
 enumn = "0.1.0"
+ext2 = { path = "ext2" }
 gdbstub = { version = "0.7.0", optional = true }
 gdbstub_arch = { version = "0.3.0", optional = true }
 rutabaga_gfx = { path = "rutabaga_gfx"}
@@ -453,31 +483,32 @@ kernel_cmdline = { path = "kernel_cmdline" }
 kernel_loader = { path = "kernel_loader" }
 kvm = { path = "kvm", optional = true }
 kvm_sys = { path = "kvm_sys", optional = true }
-libc = "0.2.93"
+libc = "0.2.153"
 libcras = "*"
 # Compile out trace statements in release builds
 log = { version = "0", features = ["release_max_level_debug"]}
 merge = "0.1.0"
 metrics = { path = "metrics" }
+metrics_events = { path = "metrics_events" }
 net_util = { path = "net_util" }
 once_cell = "1.7"
 protobuf = { version = "3.2", optional = true }
 protos = { path = "protos", optional = true }
-remain = "*"
+remain = "0.2"
 resources = { path = "resources" }
 scudo = { version = "0.1", optional = true }
-serde = { version = "*", features = ["rc"] }
-serde_json = "*"
+serde = { version = "1", features = ["rc"] }
+serde_json = "1"
 serde_keyvalue = { path = "serde_keyvalue", features = ["argh_derive"] }
 smallvec = "1.6.1"
 static_assertions = "1.1"
 swap = { path = "swap" }
 sync = { path = "common/sync" }
-tempfile = "3"
 thiserror = { version = "1.0.20" }
 vm_control = { path = "vm_control" }
 acpi_tables = { path = "acpi_tables" }
 vm_memory = { path = "vm_memory" }
+vmm_vhost = { path = "third_party/vmm_vhost" }
 uuid = { version = "1", features = ["v4"] }
 zerocopy = { version = "0.7", features = ["derive"] }
 
@@ -499,24 +530,23 @@ android_audio = { path = "android_audio"}
 [target.'cfg(windows)'.dependencies]
 anti_tamper = { path = "vendor/generic/anti_tamper" }
 cros_async = { path = "cros_async" }
-ctrlc = "*"
+ctrlc = "3"
 futures = "0.3"
 gpu_display = { path = "gpu_display", optional = true }
 rand = "0.8"
 sandbox = { path = "sandbox" }
 cros_tracing = { path = "cros_tracing" }
 tube_transporter = { path = "tube_transporter" }
-winapi = "*"
+winapi = "0.3"
 win_audio = { path = "win_audio" }
 win_util = { path = "win_util" }
 
 [dev-dependencies]
-base = "*"
 rand = "0.8"
+tempfile = "3"
 
 [patch.crates-io]
 audio_streams = { path = "common/audio_streams" }
-base = { path = "base" }
 cros_async = { path = "cros_async" }
 data_model = { path = "common/data_model" }
 libcras = { path = "libcras_stub" } # ignored by ebuild
diff --git a/DIR_METADATA b/DIR_METADATA
index e67980b06..4d6367555 100644
--- a/DIR_METADATA
+++ b/DIR_METADATA
@@ -49,6 +49,11 @@ chromeos {
         project: "chromeos/config-internal"
         path: "test/plans/v2/ctpv1_compatible/parallels_cq.star"
       }
+      test_plan_starlark_files {
+        host: "chrome-internal.googlesource.com"
+        project: "chromeos/config-internal"
+        path: "test/plans/v2/ctpv1_compatible/arcvm_gki_cq.star"
+      }
     }
   }
 }
diff --git a/OWNERS b/OWNERS
index 6d92e4909..9b0ab4a53 100644
--- a/OWNERS
+++ b/OWNERS
@@ -11,7 +11,6 @@ denniskempin@google.com #{LAST_RESORT_SUGGESTION}
 dtor@chromium.org #{LAST_RESORT_SUGGESTION}
 dverkamp@chromium.org #{LAST_RESORT_SUGGESTION}
 keiichiw@chromium.org #{LAST_RESORT_SUGGESTION}
-paulhsia@chromium.org #{LAST_RESORT_SUGGESTION}
 stevensd@chromium.org #{LAST_RESORT_SUGGESTION}
 takayas@chromium.org #{LAST_RESORT_SUGGESTION}
 uekawa@chromium.org #{LAST_RESORT_SUGGESTION}
@@ -23,6 +22,7 @@ fmayle@google.com #{LAST_RESORT_SUGGESTION}
 auradkar@google.com #{LAST_RESORT_SUGGESTION}
 nkgold@google.com #{LAST_RESORT_SUGGESTION}
 rizhang@google.com #{LAST_RESORT_SUGGESTION}
+idanr@google.com #{LAST_RESORT_SUGGESTION}
 
 # Bots
 crosvm-bot@crosvm-packages.iam.gserviceaccount.com #{LAST_RESORT_SUGGESTION}
diff --git a/OWNERS_COUNCIL b/OWNERS_COUNCIL
index 52e50e302..e4ae61066 100644
--- a/OWNERS_COUNCIL
+++ b/OWNERS_COUNCIL
@@ -1,9 +1,9 @@
 # Crosvm Council Members
-auradkar@google.com
-cblichmann@google.com
 denniskempin@google.com
+dverkamp@chromium.org
 fmayle@google.com
-smoreland@google.com
+khei@google.com
+nkgold@google.com
 
 # Bots
 crosvm-bot@crosvm-packages.iam.gserviceaccount.com
diff --git a/aarch64/Android.bp b/aarch64/Android.bp
index e51fc5cc0..1d3dd0076 100644
--- a/aarch64/Android.bp
+++ b/aarch64/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "aarch64",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "gdb",
@@ -27,6 +27,7 @@ rust_library {
         "gdbstub_arch",
     ],
     rustlibs: [
+        "libanyhow",
         "libarch",
         "libbase_rust",
         "libcros_fdt",
@@ -38,7 +39,6 @@ rust_library {
         "libkernel_cmdline",
         "libkernel_loader",
         "liblibc",
-        "libmemoffset",
         "libminijail_rust",
         "librand",
         "libresources",
diff --git a/aarch64/Cargo.toml b/aarch64/Cargo.toml
index 3ffcb0512..074cda6ab 100644
--- a/aarch64/Cargo.toml
+++ b/aarch64/Cargo.toml
@@ -5,10 +5,11 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [features]
-gdb = ["gdbstub", "gdbstub_arch", "arch/gdb", "hypervisor/gdb"]
+gdb = ["gdbstub", "gdbstub_arch", "arch/gdb"]
 swap = ["swap/enable"]
 
 [dependencies]
+anyhow = "1"
 arch = { path = "../arch" }
 cros_fdt = { path = "../cros_fdt" }
 devices = { path = "../devices" }
@@ -18,15 +19,14 @@ hypervisor = { path = "../hypervisor" }
 jail = { path = "../jail" }
 kernel_cmdline = { path = "../kernel_cmdline" }
 kernel_loader = { path = "../kernel_loader" }
-libc = "*"
-memoffset = "0.6"
+libc = "0.2"
 rand = "0.8"
-remain = "*"
+remain = "0.2"
 resources = { path = "../resources" }
 swap = { path = "../swap" }
 sync = { path = "../common/sync" }
 base = { path = "../base" }
-thiserror = "*"
+thiserror = "1"
 vm_control = { path = "../vm_control" }
 vm_memory = { path = "../vm_memory" }
 
diff --git a/aarch64/src/fdt.rs b/aarch64/src/fdt.rs
index b01ffa186..60e60b39f 100644
--- a/aarch64/src/fdt.rs
+++ b/aarch64/src/fdt.rs
@@ -5,6 +5,8 @@
 use std::collections::BTreeMap;
 use std::collections::HashSet;
 use std::fs::File;
+use std::fs::OpenOptions;
+use std::io::Write;
 use std::path::PathBuf;
 
 use arch::apply_device_tree_overlays;
@@ -13,6 +15,7 @@ use arch::CpuSet;
 use arch::DtbOverlay;
 #[cfg(any(target_os = "android", target_os = "linux"))]
 use arch::PlatformBusResources;
+use base::open_file_or_duplicate;
 use cros_fdt::Error;
 use cros_fdt::Fdt;
 use cros_fdt::Result;
@@ -47,6 +50,7 @@ use crate::AARCH64_RTC_SIZE;
 use crate::AARCH64_SERIAL_SPEED;
 use crate::AARCH64_VIRTFREQ_BASE;
 use crate::AARCH64_VIRTFREQ_SIZE;
+use crate::AARCH64_VMWDT_IRQ;
 
 // This is an arbitrary number to specify the node for the GIC.
 // If we had a more complex interrupt architecture, then we'd need an enum for
@@ -573,14 +577,23 @@ fn create_battery_node(fdt: &mut Fdt, mmio_base: u64, irq: u32) -> Result<()> {
     Ok(())
 }
 
-fn create_vmwdt_node(fdt: &mut Fdt, vmwdt_cfg: VmWdtConfig) -> Result<()> {
+fn create_vmwdt_node(fdt: &mut Fdt, vmwdt_cfg: VmWdtConfig, num_cpus: u32) -> Result<()> {
     let vmwdt_name = format!("vmwdt@{:x}", vmwdt_cfg.base);
     let reg = [vmwdt_cfg.base, vmwdt_cfg.size];
+    let cpu_mask: u32 =
+        (((1 << num_cpus) - 1) << GIC_FDT_IRQ_PPI_CPU_SHIFT) & GIC_FDT_IRQ_PPI_CPU_MASK;
+    let irq = [
+        GIC_FDT_IRQ_TYPE_PPI,
+        AARCH64_VMWDT_IRQ,
+        cpu_mask | IRQ_TYPE_EDGE_RISING,
+    ];
+
     let vmwdt_node = fdt.root_mut().subnode_mut(&vmwdt_name)?;
     vmwdt_node.set_prop("compatible", "qemu,vcpu-stall-detector")?;
     vmwdt_node.set_prop("reg", &reg)?;
     vmwdt_node.set_prop("clock-frequency", vmwdt_cfg.clock_hz)?;
     vmwdt_node.set_prop("timeout-sec", vmwdt_cfg.timeout_sec)?;
+    vmwdt_node.set_prop("interrupts", &irq)?;
     Ok(())
 }
 
@@ -702,7 +715,7 @@ pub fn create_fdt(
     if let Some((bat_mmio_base, bat_irq)) = bat_mmio_base_and_irq {
         create_battery_node(&mut fdt, bat_mmio_base, bat_irq)?;
     }
-    create_vmwdt_node(&mut fdt, vmwdt_cfg)?;
+    create_vmwdt_node(&mut fdt, vmwdt_cfg, num_cpus)?;
     create_kvm_cpufreq_node(&mut fdt)?;
     vm_generator(&mut fdt, &phandles)?;
     if !cpu_frequencies.is_empty() {
@@ -734,7 +747,16 @@ pub fn create_fdt(
     let fdt_final = fdt.finish()?;
 
     if let Some(file_path) = dump_device_tree_blob {
-        std::fs::write(&file_path, &fdt_final)
+        let mut fd = open_file_or_duplicate(
+            &file_path,
+            OpenOptions::new()
+                .read(true)
+                .create(true)
+                .truncate(true)
+                .write(true),
+        )
+        .map_err(|e| Error::FdtIoError(e.into()))?;
+        fd.write_all(&fdt_final)
             .map_err(|e| Error::FdtDumpIoError(e, file_path.clone()))?;
     }
 
diff --git a/aarch64/src/lib.rs b/aarch64/src/lib.rs
index f7de776be..da1090921 100644
--- a/aarch64/src/lib.rs
+++ b/aarch64/src/lib.rs
@@ -16,14 +16,15 @@ use std::sync::Arc;
 use arch::get_serial_cmdline;
 use arch::CpuSet;
 use arch::DtbOverlay;
+use arch::FdtPosition;
 use arch::GetSerialCmdlineError;
 use arch::RunnableLinuxVm;
 use arch::VcpuAffinity;
 use arch::VmComponents;
 use arch::VmImage;
-use base::Event;
 use base::MemoryMappingBuilder;
 use base::SendTube;
+use base::Tube;
 use devices::serial_device::SerialHardware;
 use devices::serial_device::SerialParameters;
 use devices::vmwdt::VMWDT_DEFAULT_CLOCK_HZ;
@@ -45,7 +46,11 @@ use devices::VirtCpufreq;
 #[cfg(feature = "gdb")]
 use gdbstub::arch::Arch;
 #[cfg(feature = "gdb")]
+use gdbstub_arch::aarch64::reg::id::AArch64RegId;
+#[cfg(feature = "gdb")]
 use gdbstub_arch::aarch64::AArch64 as GdbArch;
+#[cfg(feature = "gdb")]
+use hypervisor::AArch64SysRegId;
 use hypervisor::CpuConfigAArch64;
 use hypervisor::DeviceKind;
 use hypervisor::Hypervisor;
@@ -64,10 +69,11 @@ use kernel_loader::LoadedKernel;
 #[cfg(any(target_os = "android", target_os = "linux"))]
 use minijail::Minijail;
 use remain::sorted;
+use resources::address_allocator::AddressAllocator;
 use resources::AddressRange;
+use resources::MmioType;
 use resources::SystemAllocator;
 use resources::SystemAllocatorConfig;
-#[cfg(any(target_os = "android", target_os = "linux"))]
 use sync::Condvar;
 use sync::Mutex;
 use thiserror::Error;
@@ -81,11 +87,13 @@ use vm_memory::MemoryRegionPurpose;
 
 mod fdt;
 
-// We place the kernel at the very beginning of physical memory.
-const AARCH64_KERNEL_OFFSET: u64 = 0;
 const AARCH64_FDT_MAX_SIZE: u64 = 0x200000;
+const AARCH64_FDT_ALIGN: u64 = 0x200000;
 const AARCH64_INITRD_ALIGN: u64 = 0x1000000;
 
+// Maximum Linux arm64 kernel command line size (arch/arm64/include/uapi/asm/setup.h).
+const AARCH64_CMDLINE_MAX_SIZE: usize = 2048;
+
 // These constants indicate the address space used by the ARM vGIC.
 const AARCH64_GIC_DIST_SIZE: u64 = 0x10000;
 const AARCH64_GIC_CPUI_SIZE: u64 = 0x20000;
@@ -95,12 +103,6 @@ const AARCH64_PHYS_MEM_START: u64 = 0x80000000;
 const AARCH64_AXI_BASE: u64 = 0x40000000;
 const AARCH64_PLATFORM_MMIO_SIZE: u64 = 0x800000;
 
-// FDT is placed at the front of RAM when booting in BIOS mode.
-const AARCH64_FDT_OFFSET_IN_BIOS_MODE: u64 = 0x0;
-// Therefore, the BIOS is placed after the FDT in memory.
-const AARCH64_BIOS_OFFSET: u64 = AARCH64_FDT_MAX_SIZE;
-const AARCH64_BIOS_MAX_LEN: u64 = 1 << 20;
-
 const AARCH64_PROTECTED_VM_FW_MAX_SIZE: u64 = 0x400000;
 const AARCH64_PROTECTED_VM_FW_START: u64 =
     AARCH64_PHYS_MEM_START - AARCH64_PROTECTED_VM_FW_MAX_SIZE;
@@ -152,22 +154,17 @@ impl PayloadType {
     }
 }
 
-fn get_kernel_addr() -> GuestAddress {
-    GuestAddress(AARCH64_PHYS_MEM_START + AARCH64_KERNEL_OFFSET)
-}
-
-fn get_bios_addr() -> GuestAddress {
-    GuestAddress(AARCH64_PHYS_MEM_START + AARCH64_BIOS_OFFSET)
-}
-
 // When static swiotlb allocation is required, returns the address it should be allocated at.
 // Otherwise, returns None.
 fn get_swiotlb_addr(
     memory_size: u64,
+    swiotlb_size: u64,
     hypervisor: &(impl Hypervisor + ?Sized),
 ) -> Option<GuestAddress> {
     if hypervisor.check_capability(HypervisorCap::StaticSwiotlbAllocationRequired) {
-        Some(GuestAddress(AARCH64_PHYS_MEM_START + memory_size))
+        Some(GuestAddress(
+            AARCH64_PHYS_MEM_START + memory_size - swiotlb_size,
+        ))
     } else {
         None
     }
@@ -214,6 +211,9 @@ const AARCH64_VIRTFREQ_MAXSIZE: u64 = 0x10000;
 // PMU PPI interrupt, same as qemu
 const AARCH64_PMU_IRQ: u32 = 7;
 
+// VCPU stall detector interrupt
+const AARCH64_VMWDT_IRQ: u32 = 15;
+
 #[sorted]
 #[derive(Error, Debug)]
 pub enum Error {
@@ -249,8 +249,12 @@ pub enum Error {
     CreateSerialDevices(arch::DeviceRegistrationError),
     #[error("failed to create socket: {0}")]
     CreateSocket(io::Error),
+    #[error("failed to create tube: {0}")]
+    CreateTube(base::TubeError),
     #[error("failed to create VCPU: {0}")]
     CreateVcpu(base::Error),
+    #[error("unable to create vm watchdog timer device: {0}")]
+    CreateVmwdtDevice(anyhow::Error),
     #[error("custom pVM firmware could not be loaded: {0}")]
     CustomPvmFwLoadFailure(arch::LoadImageError),
     #[error("vm created wrong kind of vcpu")]
@@ -317,25 +321,6 @@ pub enum Error {
 
 pub type Result<T> = std::result::Result<T, Error>;
 
-/// Returns the address in guest memory at which the FDT should be located.
-fn fdt_address(memory_end: GuestAddress, has_bios: bool) -> GuestAddress {
-    // TODO(rammuthiah) make kernel and BIOS startup use FDT from the same location. ARCVM startup
-    // currently expects the kernel at 0x80080000 and the FDT at the end of RAM for unknown reasons.
-    // Root cause and figure out how to fold these code paths together.
-    if has_bios {
-        GuestAddress(AARCH64_PHYS_MEM_START + AARCH64_FDT_OFFSET_IN_BIOS_MODE)
-    } else {
-        // Put fdt up near the top of memory
-        // TODO(sonnyrao): will have to handle this differently if there's
-        // > 4GB memory
-        memory_end
-            .checked_sub(AARCH64_FDT_MAX_SIZE)
-            .expect("Not enough memory for FDT")
-            .checked_sub(0x10000)
-            .expect("Not enough memory for FDT")
-    }
-}
-
 fn load_kernel(
     guest_mem: &GuestMemory,
     kernel_start: GuestAddress,
@@ -387,9 +372,18 @@ impl arch::LinuxArch for AArch64 {
         components: &VmComponents,
         hypervisor: &impl Hypervisor,
     ) -> std::result::Result<Vec<(GuestAddress, u64, MemoryRegionOptions)>, Self::Error> {
+        // Static swiotlb is allocated from the end of RAM as a separate memory region, so, if
+        // enabled, make the RAM memory region smaller to leave room for it.
+        let mut main_memory_size = components.memory_size;
+        if let Some(size) = components.swiotlb {
+            if hypervisor.check_capability(HypervisorCap::StaticSwiotlbAllocationRequired) {
+                main_memory_size -= size;
+            }
+        }
+
         let mut memory_regions = vec![(
             GuestAddress(AARCH64_PHYS_MEM_START),
-            components.memory_size,
+            main_memory_size,
             MemoryRegionOptions::new().align(get_block_size()),
         )];
 
@@ -403,7 +397,7 @@ impl arch::LinuxArch for AArch64 {
         }
 
         if let Some(size) = components.swiotlb {
-            if let Some(addr) = get_swiotlb_addr(components.memory_size, hypervisor) {
+            if let Some(addr) = get_swiotlb_addr(components.memory_size, size, hypervisor) {
                 memory_regions.push((
                     addr,
                     size,
@@ -437,10 +431,9 @@ impl arch::LinuxArch for AArch64 {
         dump_device_tree_blob: Option<PathBuf>,
         _debugcon_jail: Option<Minijail>,
         #[cfg(feature = "swap")] swap_controller: &mut Option<swap::SwapController>,
-        #[cfg(any(target_os = "android", target_os = "linux"))] _guest_suspended_cvar: Option<
-            Arc<(Mutex<bool>, Condvar)>,
-        >,
+        _guest_suspended_cvar: Option<Arc<(Mutex<bool>, Condvar)>>,
         device_tree_overlays: Vec<DtbOverlay>,
+        fdt_position: Option<FdtPosition>,
     ) -> std::result::Result<RunnableLinuxVm<V, Vcpu>, Self::Error>
     where
         V: VmAArch64,
@@ -449,22 +442,39 @@ impl arch::LinuxArch for AArch64 {
         let has_bios = matches!(components.vm_image, VmImage::Bios(_));
         let mem = vm.get_memory().clone();
 
+        let fdt_position = fdt_position.unwrap_or(if has_bios {
+            FdtPosition::Start
+        } else {
+            FdtPosition::End
+        });
+        let payload_address = match fdt_position {
+            // If FDT is at the start RAM, the payload needs to go somewhere after it.
+            FdtPosition::Start => GuestAddress(AARCH64_PHYS_MEM_START + AARCH64_FDT_MAX_SIZE),
+            // Otherwise, put the payload at the start of RAM.
+            FdtPosition::End | FdtPosition::AfterPayload => GuestAddress(AARCH64_PHYS_MEM_START),
+        };
+
         // separate out image loading from other setup to get a specific error for
         // image loading
         let mut initrd = None;
-        let payload = match components.vm_image {
+        let (payload, payload_end_address) = match components.vm_image {
             VmImage::Bios(ref mut bios) => {
-                let image_size =
-                    arch::load_image(&mem, bios, get_bios_addr(), AARCH64_BIOS_MAX_LEN)
-                        .map_err(Error::BiosLoadFailure)?;
-                PayloadType::Bios {
-                    entry: get_bios_addr(),
-                    image_size: image_size as u64,
-                }
+                let image_size = arch::load_image(&mem, bios, payload_address, u64::MAX)
+                    .map_err(Error::BiosLoadFailure)?;
+                (
+                    PayloadType::Bios {
+                        entry: payload_address,
+                        image_size: image_size as u64,
+                    },
+                    payload_address
+                        .checked_add(image_size.try_into().unwrap())
+                        .unwrap(),
+                )
             }
             VmImage::Kernel(ref mut kernel_image) => {
-                let loaded_kernel = load_kernel(&mem, get_kernel_addr(), kernel_image)?;
+                let loaded_kernel = load_kernel(&mem, payload_address, kernel_image)?;
                 let kernel_end = loaded_kernel.address_range.end;
+                let mut payload_end = GuestAddress(kernel_end);
                 initrd = match components.initrd_image {
                     Some(initrd_file) => {
                         let mut initrd_file = initrd_file;
@@ -476,16 +486,33 @@ impl arch::LinuxArch for AArch64 {
                         let initrd_size =
                             arch::load_image(&mem, &mut initrd_file, initrd_addr, initrd_max_size)
                                 .map_err(Error::InitrdLoadFailure)?;
+                        payload_end = initrd_addr
+                            .checked_add(initrd_size.try_into().unwrap())
+                            .unwrap();
                         Some((initrd_addr, initrd_size))
                     }
                     None => None,
                 };
-                PayloadType::Kernel(loaded_kernel)
+                (PayloadType::Kernel(loaded_kernel), payload_end)
             }
         };
 
         let memory_end = GuestAddress(AARCH64_PHYS_MEM_START + components.memory_size);
-        let fdt_offset = fdt_address(memory_end, has_bios);
+
+        let fdt_address = match fdt_position {
+            FdtPosition::Start => GuestAddress(AARCH64_PHYS_MEM_START),
+            FdtPosition::End => {
+                let addr = memory_end
+                    .checked_sub(AARCH64_FDT_MAX_SIZE)
+                    .expect("Not enough memory for FDT")
+                    .align_down(AARCH64_FDT_ALIGN);
+                assert!(addr >= payload_end_address, "Not enough memory for FDT");
+                addr
+            }
+            FdtPosition::AfterPayload => payload_end_address
+                .align(AARCH64_FDT_ALIGN)
+                .expect("Not enough memory for FDT"),
+        };
 
         let mut use_pmu = vm
             .get_hypervisor()
@@ -510,7 +537,7 @@ impl arch::LinuxArch for AArch64 {
                 Self::vcpu_init(
                     vcpu_id,
                     &payload,
-                    fdt_offset,
+                    fdt_address,
                     components.hv_cfg.protection_type,
                     components.boot_cpu,
                 )
@@ -543,7 +570,7 @@ impl arch::LinuxArch for AArch64 {
             .map_err(Error::MapPvtimeError)?;
         }
 
-        if components.hv_cfg.protection_type.loads_firmware() {
+        if components.hv_cfg.protection_type.needs_firmware_loaded() {
             arch::load_image(
                 &mem,
                 &mut components
@@ -577,7 +604,9 @@ impl arch::LinuxArch for AArch64 {
 
         // Event used by PMDevice to notify crosvm that
         // guest OS is trying to suspend.
-        let suspend_evt = Event::new().map_err(Error::CreateEvent)?;
+        let (suspend_tube_send, suspend_tube_recv) =
+            Tube::directional_pair().map_err(Error::CreateTube)?;
+        let suspend_tube_send = Arc::new(Mutex::new(suspend_tube_send));
 
         let (pci_devices, others): (Vec<_>, Vec<_>) = devs
             .into_iter()
@@ -628,11 +657,13 @@ impl arch::LinuxArch for AArch64 {
             .map_err(Error::CreatePlatformBus)?;
         pid_debug_label_map.append(&mut platform_pid_debug_label_map);
 
+        let (vmwdt_host_tube, vmwdt_control_tube) = Tube::pair().map_err(Error::CreateTube)?;
         Self::add_arch_devs(
             irq_chip.as_irq_chip_mut(),
             &mmio_bus,
             vcpu_count,
             _vm_evt_wrtube,
+            vmwdt_control_tube,
         )?;
 
         let com_evt_1_3 = devices::IrqEdgeEvent::new().map_err(Error::CreateEvent)?;
@@ -667,10 +698,6 @@ impl arch::LinuxArch for AArch64 {
 
         #[cfg(any(target_os = "android", target_os = "linux"))]
         if !components.cpu_frequencies.is_empty() {
-            // TODO: Revisit and optimization after benchmarking
-            let socket = components
-                .virt_cpufreq_socket
-                .map(|s| Arc::new(Mutex::new(s)));
             for vcpu in 0..vcpu_count {
                 let vcpu_affinity = match components.vcpu_affinity.clone() {
                     Some(VcpuAffinity::Global(v)) => v,
@@ -680,7 +707,14 @@ impl arch::LinuxArch for AArch64 {
 
                 let virt_cpufreq = Arc::new(Mutex::new(VirtCpufreq::new(
                     vcpu_affinity[0].try_into().unwrap(),
-                    socket.clone(),
+                    *components.normalized_cpu_capacities.get(&vcpu).unwrap(),
+                    *components
+                        .cpu_frequencies
+                        .get(&vcpu)
+                        .unwrap()
+                        .iter()
+                        .max()
+                        .unwrap(),
                 )));
 
                 if vcpu as u64 * AARCH64_VIRTFREQ_SIZE + AARCH64_VIRTFREQ_SIZE
@@ -718,17 +752,20 @@ impl arch::LinuxArch for AArch64 {
             size: AARCH64_PCI_CFG_SIZE,
         };
 
-        let pci_ranges: Vec<fdt::PciRange> = system_allocator
-            .mmio_pools()
-            .iter()
-            .map(|range| fdt::PciRange {
+        let mut pci_ranges: Vec<fdt::PciRange> = Vec::new();
+
+        let mut add_pci_ranges = |alloc: &AddressAllocator, prefetchable: bool| {
+            pci_ranges.extend(alloc.pools().iter().map(|range| fdt::PciRange {
                 space: fdt::PciAddressSpace::Memory64,
                 bus_address: range.start,
                 cpu_physical_address: range.start,
                 size: range.len().unwrap(),
-                prefetchable: false,
-            })
-            .collect();
+                prefetchable,
+            }));
+        };
+
+        add_pci_ranges(system_allocator.mmio_allocator(MmioType::Low), false);
+        add_pci_ranges(system_allocator.mmio_allocator(MmioType::High), true);
 
         let (bat_control, bat_mmio_base_and_irq) = match bat_type {
             Some(BatteryType::Goldfish) => {
@@ -777,8 +814,10 @@ impl arch::LinuxArch for AArch64 {
             components.cpu_clusters,
             components.cpu_capacity,
             components.cpu_frequencies,
-            fdt_offset,
-            cmdline.as_str(),
+            fdt_address,
+            cmdline
+                .as_str_with_max_len(AARCH64_CMDLINE_MAX_SIZE - 1)
+                .map_err(Error::Cmdline)?,
             (payload.entry(), payload.size() as usize),
             initrd,
             components.android_fstab,
@@ -787,7 +826,7 @@ impl arch::LinuxArch for AArch64 {
             psci_version,
             components.swiotlb.map(|size| {
                 (
-                    get_swiotlb_addr(components.memory_size, vm.get_hypervisor()),
+                    get_swiotlb_addr(components.memory_size, size, vm.get_hypervisor()),
                     size,
                 )
             }),
@@ -803,11 +842,13 @@ impl arch::LinuxArch for AArch64 {
 
         vm.init_arch(
             payload.entry(),
-            fdt_offset,
+            fdt_address,
             AARCH64_FDT_MAX_SIZE.try_into().unwrap(),
         )
         .map_err(Error::InitVmError)?;
 
+        let vm_request_tubes = vec![vmwdt_host_tube];
+
         Ok(RunnableLinuxVm {
             vm,
             vcpu_count,
@@ -819,7 +860,7 @@ impl arch::LinuxArch for AArch64 {
             io_bus,
             mmio_bus,
             pid_debug_label_map,
-            suspend_evt,
+            suspend_tube: (suspend_tube_send, suspend_tube_recv),
             rt_cpus: components.rt_cpus,
             delay_rt: components.delay_rt,
             bat_control,
@@ -831,7 +872,7 @@ impl arch::LinuxArch for AArch64 {
             platform_devices,
             hotplug_bus: BTreeMap::new(),
             devices_thread: None,
-            vm_request_tube: None,
+            vm_request_tubes,
         })
     }
 
@@ -863,6 +904,14 @@ impl arch::LinuxArch for AArch64 {
         Err(Error::Unsupported)
     }
 
+    fn get_host_cpu_max_freq_khz() -> std::result::Result<BTreeMap<usize, u32>, Self::Error> {
+        Ok(Self::collect_for_each_cpu(base::logical_core_max_freq_khz)
+            .map_err(Error::CpuFrequencies)?
+            .into_iter()
+            .enumerate()
+            .collect())
+    }
+
     fn get_host_cpu_frequencies_khz() -> std::result::Result<BTreeMap<usize, Vec<u32>>, Self::Error>
     {
         Ok(
@@ -937,27 +986,160 @@ impl<T: VcpuAArch64> arch::GdbOps<T> for AArch64 {
 
     fn read_registers(vcpu: &T) -> Result<<GdbArch as Arch>::Registers> {
         let mut regs: <GdbArch as Arch>::Registers = Default::default();
-
-        vcpu.get_gdb_registers(&mut regs).map_err(Error::ReadRegs)?;
+        assert!(
+            regs.x.len() == 31,
+            "unexpected number of Xn general purpose registers"
+        );
+        for (i, reg) in regs.x.iter_mut().enumerate() {
+            let n = u8::try_from(i).expect("invalid Xn general purpose register index");
+            *reg = vcpu
+                .get_one_reg(VcpuRegAArch64::X(n))
+                .map_err(Error::ReadReg)?;
+        }
+        regs.sp = vcpu
+            .get_one_reg(VcpuRegAArch64::Sp)
+            .map_err(Error::ReadReg)?;
+        regs.pc = vcpu
+            .get_one_reg(VcpuRegAArch64::Pc)
+            .map_err(Error::ReadReg)?;
+        // hypervisor API gives a 64-bit value for Pstate, but GDB wants a 32-bit "CPSR".
+        regs.cpsr = vcpu
+            .get_one_reg(VcpuRegAArch64::Pstate)
+            .map_err(Error::ReadReg)? as u32;
+        for (i, reg) in regs.v.iter_mut().enumerate() {
+            let n = u8::try_from(i).expect("invalid Vn general purpose register index");
+            *reg = vcpu.get_vector_reg(n).map_err(Error::ReadReg)?;
+        }
+        regs.fpcr = vcpu
+            .get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::FPCR))
+            .map_err(Error::ReadReg)? as u32;
+        regs.fpsr = vcpu
+            .get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::FPSR))
+            .map_err(Error::ReadReg)? as u32;
 
         Ok(regs)
     }
 
     fn write_registers(vcpu: &T, regs: &<GdbArch as Arch>::Registers) -> Result<()> {
-        vcpu.set_gdb_registers(regs).map_err(Error::WriteRegs)
+        assert!(
+            regs.x.len() == 31,
+            "unexpected number of Xn general purpose registers"
+        );
+        for (i, reg) in regs.x.iter().enumerate() {
+            let n = u8::try_from(i).expect("invalid Xn general purpose register index");
+            vcpu.set_one_reg(VcpuRegAArch64::X(n), *reg)
+                .map_err(Error::WriteReg)?;
+        }
+        vcpu.set_one_reg(VcpuRegAArch64::Sp, regs.sp)
+            .map_err(Error::WriteReg)?;
+        vcpu.set_one_reg(VcpuRegAArch64::Pc, regs.pc)
+            .map_err(Error::WriteReg)?;
+        // GDB gives a 32-bit value for "CPSR", but hypervisor API wants a 64-bit Pstate.
+        let pstate = vcpu
+            .get_one_reg(VcpuRegAArch64::Pstate)
+            .map_err(Error::ReadReg)?;
+        let pstate = (pstate & 0xffff_ffff_0000_0000) | (regs.cpsr as u64);
+        vcpu.set_one_reg(VcpuRegAArch64::Pstate, pstate)
+            .map_err(Error::WriteReg)?;
+        for (i, reg) in regs.v.iter().enumerate() {
+            let n = u8::try_from(i).expect("invalid Vn general purpose register index");
+            vcpu.set_vector_reg(n, *reg).map_err(Error::WriteReg)?;
+        }
+        vcpu.set_one_reg(
+            VcpuRegAArch64::System(AArch64SysRegId::FPCR),
+            u64::from(regs.fpcr),
+        )
+        .map_err(Error::WriteReg)?;
+        vcpu.set_one_reg(
+            VcpuRegAArch64::System(AArch64SysRegId::FPSR),
+            u64::from(regs.fpsr),
+        )
+        .map_err(Error::WriteReg)?;
+
+        Ok(())
     }
 
     fn read_register(vcpu: &T, reg_id: <GdbArch as Arch>::RegId) -> Result<Vec<u8>> {
-        let mut reg = vec![0; std::mem::size_of::<u128>()];
-        let size = vcpu
-            .get_gdb_register(reg_id, reg.as_mut_slice())
-            .map_err(Error::ReadReg)?;
-        reg.truncate(size);
-        Ok(reg)
+        let result = match reg_id {
+            AArch64RegId::X(n) => vcpu
+                .get_one_reg(VcpuRegAArch64::X(n))
+                .map(|v| v.to_ne_bytes().to_vec()),
+            AArch64RegId::Sp => vcpu
+                .get_one_reg(VcpuRegAArch64::Sp)
+                .map(|v| v.to_ne_bytes().to_vec()),
+            AArch64RegId::Pc => vcpu
+                .get_one_reg(VcpuRegAArch64::Pc)
+                .map(|v| v.to_ne_bytes().to_vec()),
+            AArch64RegId::Pstate => vcpu
+                .get_one_reg(VcpuRegAArch64::Pstate)
+                .map(|v| (v as u32).to_ne_bytes().to_vec()),
+            AArch64RegId::V(n) => vcpu.get_vector_reg(n).map(|v| v.to_ne_bytes().to_vec()),
+            AArch64RegId::System(op) => vcpu
+                .get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::from_encoded(op)))
+                .map(|v| v.to_ne_bytes().to_vec()),
+            _ => {
+                base::error!("Unexpected AArch64RegId: {:?}", reg_id);
+                Err(base::Error::new(libc::EINVAL))
+            }
+        };
+
+        match result {
+            Ok(bytes) => Ok(bytes),
+            // ENOENT is returned when KVM is aware of the register but it is unavailable
+            Err(e) if e.errno() == libc::ENOENT => Ok(Vec::new()),
+            Err(e) => Err(Error::ReadReg(e)),
+        }
     }
 
     fn write_register(vcpu: &T, reg_id: <GdbArch as Arch>::RegId, data: &[u8]) -> Result<()> {
-        vcpu.set_gdb_register(reg_id, data).map_err(Error::WriteReg)
+        fn try_into_u32(data: &[u8]) -> Result<u32> {
+            let s = data
+                .get(..4)
+                .ok_or(Error::WriteReg(base::Error::new(libc::EINVAL)))?;
+            let a = s
+                .try_into()
+                .map_err(|_| Error::WriteReg(base::Error::new(libc::EINVAL)))?;
+            Ok(u32::from_ne_bytes(a))
+        }
+
+        fn try_into_u64(data: &[u8]) -> Result<u64> {
+            let s = data
+                .get(..8)
+                .ok_or(Error::WriteReg(base::Error::new(libc::EINVAL)))?;
+            let a = s
+                .try_into()
+                .map_err(|_| Error::WriteReg(base::Error::new(libc::EINVAL)))?;
+            Ok(u64::from_ne_bytes(a))
+        }
+
+        fn try_into_u128(data: &[u8]) -> Result<u128> {
+            let s = data
+                .get(..16)
+                .ok_or(Error::WriteReg(base::Error::new(libc::EINVAL)))?;
+            let a = s
+                .try_into()
+                .map_err(|_| Error::WriteReg(base::Error::new(libc::EINVAL)))?;
+            Ok(u128::from_ne_bytes(a))
+        }
+
+        match reg_id {
+            AArch64RegId::X(n) => vcpu.set_one_reg(VcpuRegAArch64::X(n), try_into_u64(data)?),
+            AArch64RegId::Sp => vcpu.set_one_reg(VcpuRegAArch64::Sp, try_into_u64(data)?),
+            AArch64RegId::Pc => vcpu.set_one_reg(VcpuRegAArch64::Pc, try_into_u64(data)?),
+            AArch64RegId::Pstate => {
+                vcpu.set_one_reg(VcpuRegAArch64::Pstate, u64::from(try_into_u32(data)?))
+            }
+            AArch64RegId::V(n) => vcpu.set_vector_reg(n, try_into_u128(data)?),
+            AArch64RegId::System(op) => vcpu.set_one_reg(
+                VcpuRegAArch64::System(AArch64SysRegId::from_encoded(op)),
+                try_into_u64(data)?,
+            ),
+            _ => {
+                base::error!("Unexpected AArch64RegId: {:?}", reg_id);
+                Err(base::Error::new(libc::EINVAL))
+            }
+        }
+        .map_err(Error::WriteReg)
     }
 
     fn enable_singlestep(vcpu: &T) -> Result<()> {
@@ -980,7 +1162,7 @@ impl<T: VcpuAArch64> arch::GdbOps<T> for AArch64 {
 impl AArch64 {
     /// This returns a base part of the kernel command for this architecture
     fn get_base_linux_cmdline() -> kernel_cmdline::Cmdline {
-        let mut cmdline = kernel_cmdline::Cmdline::new(base::pagesize());
+        let mut cmdline = kernel_cmdline::Cmdline::new();
         cmdline.insert_str("panic=-1").unwrap();
         cmdline
     }
@@ -1036,6 +1218,7 @@ impl AArch64 {
         bus: &Bus,
         vcpu_count: usize,
         vm_evt_wrtube: &SendTube,
+        vmwdt_request_tube: Tube,
     ) -> Result<()> {
         let rtc_evt = devices::IrqEdgeEvent::new().map_err(Error::CreateEvent)?;
         let rtc = devices::pl030::Pl030::new(rtc_evt.try_clone().map_err(Error::CloneEvent)?);
@@ -1050,11 +1233,28 @@ impl AArch64 {
         )
         .expect("failed to add rtc device");
 
-        let vm_wdt = Arc::new(Mutex::new(
-            devices::vmwdt::Vmwdt::new(vcpu_count, vm_evt_wrtube.try_clone().unwrap()).unwrap(),
-        ));
-        bus.insert(vm_wdt, AARCH64_VMWDT_ADDR, AARCH64_VMWDT_SIZE)
-            .expect("failed to add vmwdt device");
+        let vmwdt_evt = devices::IrqEdgeEvent::new().map_err(Error::CreateEvent)?;
+        let vm_wdt = devices::vmwdt::Vmwdt::new(
+            vcpu_count,
+            vm_evt_wrtube.try_clone().unwrap(),
+            vmwdt_evt.try_clone().map_err(Error::CloneEvent)?,
+            vmwdt_request_tube,
+        )
+        .map_err(Error::CreateVmwdtDevice)?;
+        irq_chip
+            .register_edge_irq_event(
+                AARCH64_VMWDT_IRQ,
+                &vmwdt_evt,
+                IrqEventSource::from_device(&vm_wdt),
+            )
+            .map_err(Error::RegisterIrqfd)?;
+
+        bus.insert(
+            Arc::new(Mutex::new(vm_wdt)),
+            AARCH64_VMWDT_ADDR,
+            AARCH64_VMWDT_SIZE,
+        )
+        .expect("failed to add vmwdt device");
 
         Ok(())
     }
@@ -1098,7 +1298,7 @@ impl AArch64 {
 
         // Other cpus are powered off initially
         if vcpu_id == boot_cpu {
-            let entry_addr = if protection_type.loads_firmware() {
+            let entry_addr = if protection_type.needs_firmware_loaded() {
                 Some(AARCH64_PROTECTED_VM_FW_START)
             } else if protection_type.runs_firmware() {
                 None // Initial PC value is set by the hypervisor
diff --git a/acpi_tables/Android.bp b/acpi_tables/Android.bp
index f39bca670..db1cd3f95 100644
--- a/acpi_tables/Android.bp
+++ b/acpi_tables/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "acpi_tables",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -39,10 +39,7 @@ rust_library {
     crate_name: "acpi_tables",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
-    rustlibs: [
-        "libtempfile",
-        "libzerocopy",
-    ],
+    rustlibs: ["libzerocopy"],
 }
diff --git a/acpi_tables/Cargo.toml b/acpi_tables/Cargo.toml
index 04ea9af4d..1aac94f16 100644
--- a/acpi_tables/Cargo.toml
+++ b/acpi_tables/Cargo.toml
@@ -5,5 +5,7 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dependencies]
-tempfile = "3"
 zerocopy = { version = "0.7", features = ["derive"] }
+
+[dev-dependencies]
+tempfile = "3"
diff --git a/acpi_tables/src/aml.rs b/acpi_tables/src/aml.rs
index 7e3706b72..c9f95edb3 100644
--- a/acpi_tables/src/aml.rs
+++ b/acpi_tables/src/aml.rs
@@ -92,7 +92,7 @@ pub struct Zero {}
 
 impl Aml for Zero {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        bytes.append(&mut vec![ZEROOP]);
+        bytes.push(ZEROOP);
     }
 }
 
@@ -102,7 +102,7 @@ pub struct One {}
 
 impl Aml for One {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        bytes.append(&mut vec![ONEOP]);
+        bytes.push(ONEOP);
     }
 }
 
@@ -112,7 +112,7 @@ pub struct Ones {}
 
 impl Aml for Ones {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        bytes.append(&mut vec![ONESOP]);
+        bytes.push(ONESOP);
     }
 }
 
@@ -141,8 +141,8 @@ impl Aml for Path {
             }
         };
 
-        for part in self.name_parts.clone().iter_mut() {
-            bytes.append(&mut part.to_vec());
+        for part in &self.name_parts {
+            bytes.extend_from_slice(part);
         }
     }
 }
@@ -190,11 +190,11 @@ pub type Word = u16;
 
 impl Aml for Word {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        if *self <= Byte::max_value().into() {
+        if *self <= Byte::MAX.into() {
             (*self as Byte).to_aml_bytes(bytes);
         } else {
             bytes.push(WORDPREFIX);
-            bytes.append(&mut self.to_le_bytes().to_vec());
+            bytes.extend_from_slice(&self.to_le_bytes());
         }
     }
 }
@@ -203,11 +203,11 @@ pub type DWord = u32;
 
 impl Aml for DWord {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        if *self <= Word::max_value().into() {
+        if *self <= Word::MAX.into() {
             (*self as Word).to_aml_bytes(bytes);
         } else {
             bytes.push(DWORDPREFIX);
-            bytes.append(&mut self.to_le_bytes().to_vec());
+            bytes.extend_from_slice(&self.to_le_bytes());
         }
     }
 }
@@ -216,11 +216,11 @@ pub type QWord = u64;
 
 impl Aml for QWord {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        if *self <= DWord::max_value().into() {
+        if *self <= DWord::MAX.into() {
             (*self as DWord).to_aml_bytes(bytes);
         } else {
             bytes.push(QWORDPREFIX);
-            bytes.append(&mut self.to_le_bytes().to_vec());
+            bytes.extend_from_slice(&self.to_le_bytes());
         }
     }
 }
@@ -232,7 +232,7 @@ pub struct Name {
 
 impl Aml for Name {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        bytes.append(&mut self.bytes.clone());
+        bytes.extend_from_slice(&self.bytes);
     }
 }
 
@@ -252,8 +252,7 @@ impl Name {
     ///
     /// * 'field_name' - name string
     pub fn new_field_name(field_name: &str) -> Self {
-        let mut bytes: Vec<u8> = Vec::new();
-        bytes.extend_from_slice(field_name.as_bytes());
+        let bytes = field_name.as_bytes().to_vec();
         Name { bytes }
     }
 }
@@ -265,15 +264,9 @@ pub struct Package {
 
 impl Aml for Package {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let pkg_length = create_pkg_length(&self.children_bytes, true);
-        aml.append(
-            &mut [
-                &[PACKAGEOP],
-                pkg_length.as_slice(),
-                self.children_bytes.as_slice(),
-            ]
-            .concat(),
-        );
+        aml.push(PACKAGEOP);
+        append_pkg_length(aml, self.children_bytes.len());
+        aml.extend_from_slice(&self.children_bytes);
     }
 }
 
@@ -297,18 +290,13 @@ pub struct VarPackageTerm<'a> {
 
 impl<'a> Aml for VarPackageTerm<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.data.to_aml_bytes(&mut bytes);
-
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
-        }
+        aml.push(VARPACKAGEOP);
 
-        bytes.insert(0, VARPACKAGEOP);
+        let start = aml.len();
+        self.data.to_aml_bytes(aml);
+        let data_len = aml.len() - start;
 
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, data_len);
     }
 }
 
@@ -335,42 +323,63 @@ package length is 2**28."
 */
 
 /* Also used for NamedField but in that case the length is not included in itself */
-fn create_pkg_length(data: &[u8], include_self: bool) -> Vec<u8> {
-    let mut result = Vec::new();
-
+fn insert_length(aml: &mut Vec<u8>, position: usize, len: usize, include_self: bool) {
     /* PkgLength is inclusive and includes the length bytes */
-    let length_length = if data.len() < (2usize.pow(6) - 1) {
+    let length_length = if len < (2usize.pow(6) - 1) {
         1
-    } else if data.len() < (2usize.pow(12) - 2) {
+    } else if len < (2usize.pow(12) - 2) {
         2
-    } else if data.len() < (2usize.pow(20) - 3) {
+    } else if len < (2usize.pow(20) - 3) {
         3
     } else {
         4
     };
 
-    let length = data.len() + if include_self { length_length } else { 0 };
+    let length = len + if include_self { length_length } else { 0 };
 
     match length_length {
-        1 => result.push(length as u8),
+        1 => aml.insert(position, length as u8),
         2 => {
-            result.push((1u8 << 6) | (length & 0xf) as u8);
-            result.push((length >> 4) as u8)
+            aml.splice(
+                position..position,
+                [(1u8 << 6) | (length & 0xf) as u8, (length >> 4) as u8],
+            );
         }
         3 => {
-            result.push((2u8 << 6) | (length & 0xf) as u8);
-            result.push((length >> 4) as u8);
-            result.push((length >> 12) as u8);
+            aml.splice(
+                position..position,
+                [
+                    (2u8 << 6) | (length & 0xf) as u8,
+                    (length >> 4) as u8,
+                    (length >> 12) as u8,
+                ],
+            );
         }
         _ => {
-            result.push((3u8 << 6) | (length & 0xf) as u8);
-            result.push((length >> 4) as u8);
-            result.push((length >> 12) as u8);
-            result.push((length >> 20) as u8);
+            aml.splice(
+                position..position,
+                [
+                    (3u8 << 6) | (length & 0xf) as u8,
+                    (length >> 4) as u8,
+                    (length >> 12) as u8,
+                    (length >> 20) as u8,
+                ],
+            );
         }
     }
+}
+
+fn insert_pkg_length(aml: &mut Vec<u8>, position: usize, len: usize) {
+    insert_length(aml, position, len, true);
+}
+
+fn append_pkg_length(aml: &mut Vec<u8>, len: usize) {
+    insert_length(aml, aml.len(), len, true);
+}
 
-    result
+// Append a NamedField length, which does not count the size of the encoded length itself.
+fn append_named_field_length(aml: &mut Vec<u8>, len: usize) {
+    insert_length(aml, aml.len(), len, false);
 }
 
 /// EISAName object. 'value' means the encoded u32 EisaIdString.
@@ -420,11 +429,10 @@ impl Aml for Usize {
     }
 }
 
-fn create_aml_string(v: &str) -> Vec<u8> {
-    let mut data = vec![STRINGOP];
+fn append_aml_string(data: &mut Vec<u8>, v: &str) {
+    data.push(STRINGOP);
     data.extend_from_slice(v.as_bytes());
     data.push(0x0); /* NullChar */
-    data
 }
 
 /// implement Aml trait for 'str' so that 'str' can be directly append to the aml vector
@@ -432,7 +440,7 @@ pub type AmlStr = &'static str;
 
 impl Aml for AmlStr {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        bytes.append(&mut create_aml_string(self));
+        append_aml_string(bytes, self);
     }
 }
 
@@ -441,7 +449,7 @@ pub type AmlString = String;
 
 impl Aml for AmlString {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
-        bytes.append(&mut create_aml_string(self));
+        append_aml_string(bytes, self);
     }
 }
 
@@ -452,36 +460,29 @@ pub struct ResourceTemplate<'a> {
 
 impl<'a> Aml for ResourceTemplate<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
+        aml.push(BUFFEROP);
+
+        let pos = aml.len();
 
         // Add buffer data
         for child in &self.children {
-            child.to_aml_bytes(&mut bytes);
+            child.to_aml_bytes(aml);
         }
 
         // Mark with end and mark checksum as as always valid
-        bytes.push(ENDTAG);
-        bytes.push(0); /* zero checksum byte */
+        aml.push(ENDTAG);
+        aml.push(0); /* zero checksum byte */
 
         // Buffer length is an encoded integer including buffer data
         // and EndTag and checksum byte
-        let mut buffer_length = Vec::new();
-        bytes.len().to_aml_bytes(&mut buffer_length);
-        buffer_length.reverse();
-        for byte in buffer_length {
-            bytes.insert(0, byte);
-        }
+        let buffer_length = aml.len() - pos;
+        let mut buffer_length_bytes = Vec::new();
+        buffer_length.to_aml_bytes(&mut buffer_length_bytes);
+        aml.splice(pos..pos, buffer_length_bytes);
 
         // PkgLength is everything else
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
-        }
-
-        bytes.insert(0, BUFFEROP);
-
-        aml.append(&mut bytes);
+        let len = aml.len() - pos;
+        insert_pkg_length(aml, pos, len);
     }
 }
 
@@ -513,12 +514,12 @@ impl Memory32Fixed {
 impl Aml for Memory32Fixed {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
         bytes.push(MEMORY32FIXEDDESC); /* 32bit Fixed Memory Range Descriptor */
-        bytes.append(&mut 9u16.to_le_bytes().to_vec());
+        bytes.extend_from_slice(&9u16.to_le_bytes());
 
         // 9 bytes of payload
         bytes.push(self.read_write as u8);
-        bytes.append(&mut self.base.to_le_bytes().to_vec());
-        bytes.append(&mut self.length.to_le_bytes().to_vec());
+        bytes.extend_from_slice(&self.base.to_le_bytes());
+        bytes.extend_from_slice(&self.length.to_le_bytes());
     }
 }
 
@@ -580,7 +581,7 @@ impl<T> AddressSpace<T> {
 
     fn push_header(&self, bytes: &mut Vec<u8>, descriptor: u8, length: usize) {
         bytes.push(descriptor); /* Word Address Space Descriptor */
-        bytes.append(&mut (length as u16).to_le_bytes().to_vec());
+        bytes.extend_from_slice(&(length as u16).to_le_bytes());
         bytes.push(self.type_ as u8); /* type */
         let generic_flags = 1 << 2 /* Min Fixed */ | 1 << 3; /* Max Fixed */
         bytes.push(generic_flags);
@@ -596,12 +597,12 @@ impl Aml for AddressSpace<u16> {
             3 + 5 * std::mem::size_of::<u16>(), /* 3 bytes of header + 5 u16 fields */
         );
 
-        bytes.append(&mut 0u16.to_le_bytes().to_vec()); /* Granularity */
-        bytes.append(&mut self.min.to_le_bytes().to_vec()); /* Min */
-        bytes.append(&mut self.max.to_le_bytes().to_vec()); /* Max */
-        bytes.append(&mut 0u16.to_le_bytes().to_vec()); /* Translation */
+        bytes.extend_from_slice(&0u16.to_le_bytes()); /* Granularity */
+        bytes.extend_from_slice(&self.min.to_le_bytes()); /* Min */
+        bytes.extend_from_slice(&self.max.to_le_bytes()); /* Max */
+        bytes.extend_from_slice(&0u16.to_le_bytes()); /* Translation */
         let len = self.max - self.min + 1;
-        bytes.append(&mut len.to_le_bytes().to_vec()); /* Length */
+        bytes.extend_from_slice(&len.to_le_bytes()); /* Length */
     }
 }
 
@@ -613,12 +614,12 @@ impl Aml for AddressSpace<u32> {
             3 + 5 * std::mem::size_of::<u32>(), /* 3 bytes of header + 5 u32 fields */
         );
 
-        bytes.append(&mut 0u32.to_le_bytes().to_vec()); /* Granularity */
-        bytes.append(&mut self.min.to_le_bytes().to_vec()); /* Min */
-        bytes.append(&mut self.max.to_le_bytes().to_vec()); /* Max */
-        bytes.append(&mut 0u32.to_le_bytes().to_vec()); /* Translation */
+        bytes.extend_from_slice(&0u32.to_le_bytes()); /* Granularity */
+        bytes.extend_from_slice(&self.min.to_le_bytes()); /* Min */
+        bytes.extend_from_slice(&self.max.to_le_bytes()); /* Max */
+        bytes.extend_from_slice(&0u32.to_le_bytes()); /* Translation */
         let len = self.max - self.min + 1;
-        bytes.append(&mut len.to_le_bytes().to_vec()); /* Length */
+        bytes.extend_from_slice(&len.to_le_bytes()); /* Length */
     }
 }
 
@@ -630,12 +631,12 @@ impl Aml for AddressSpace<u64> {
             3 + 5 * std::mem::size_of::<u64>(), /* 3 bytes of header + 5 u64 fields */
         );
 
-        bytes.append(&mut 0u64.to_le_bytes().to_vec()); /* Granularity */
-        bytes.append(&mut self.min.to_le_bytes().to_vec()); /* Min */
-        bytes.append(&mut self.max.to_le_bytes().to_vec()); /* Max */
-        bytes.append(&mut 0u64.to_le_bytes().to_vec()); /* Translation */
+        bytes.extend_from_slice(&0u64.to_le_bytes()); /* Granularity */
+        bytes.extend_from_slice(&self.min.to_le_bytes()); /* Min */
+        bytes.extend_from_slice(&self.max.to_le_bytes()); /* Max */
+        bytes.extend_from_slice(&0u64.to_le_bytes()); /* Translation */
         let len = self.max - self.min + 1;
-        bytes.append(&mut len.to_le_bytes().to_vec()); /* Length */
+        bytes.extend_from_slice(&len.to_le_bytes()); /* Length */
     }
 }
 
@@ -663,8 +664,8 @@ impl Aml for IO {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
         bytes.push(IOPORTDESC); /* IO Port Descriptor */
         bytes.push(1); /* IODecode16 */
-        bytes.append(&mut self.min.to_le_bytes().to_vec());
-        bytes.append(&mut self.max.to_le_bytes().to_vec());
+        bytes.extend_from_slice(&self.min.to_le_bytes());
+        bytes.extend_from_slice(&self.max.to_le_bytes());
         bytes.push(self.alignment);
         bytes.push(self.length);
     }
@@ -701,14 +702,14 @@ impl Interrupt {
 impl Aml for Interrupt {
     fn to_aml_bytes(&self, bytes: &mut Vec<u8>) {
         bytes.push(EXTIRQDESC); /* Extended IRQ Descriptor */
-        bytes.append(&mut 6u16.to_le_bytes().to_vec());
+        bytes.extend_from_slice(&6u16.to_le_bytes());
         let flags = (self.shared as u8) << 3
             | (self.active_low as u8) << 2
             | (self.edge_triggered as u8) << 1
             | self.consumer as u8;
         bytes.push(flags);
         bytes.push(1u8); /* count */
-        bytes.append(&mut self.number.to_le_bytes().to_vec());
+        bytes.extend_from_slice(&self.number.to_le_bytes());
     }
 }
 
@@ -720,21 +721,17 @@ pub struct Device<'a> {
 
 impl<'a> Aml for Device<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.path.to_aml_bytes(&mut bytes);
-        for child in &self.children {
-            child.to_aml_bytes(&mut bytes);
-        }
+        aml.push(EXTOPPREFIX); /* ExtOpPrefix */
+        aml.push(DEVICEOP); /* DeviceOp */
 
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
+        let start = aml.len();
+        self.path.to_aml_bytes(aml);
+        for child in &self.children {
+            child.to_aml_bytes(aml);
         }
+        let len = aml.len() - start;
 
-        bytes.insert(0, DEVICEOP); /* DeviceOp */
-        bytes.insert(0, EXTOPPREFIX); /* ExtOpPrefix */
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -753,20 +750,16 @@ pub struct Scope<'a> {
 
 impl<'a> Aml for Scope<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.path.to_aml_bytes(&mut bytes);
-        for child in &self.children {
-            child.to_aml_bytes(&mut bytes);
-        }
+        aml.push(SCOPEOP);
 
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
+        let start = aml.len();
+        self.path.to_aml_bytes(aml);
+        for child in &self.children {
+            child.to_aml_bytes(aml);
         }
+        let len = aml.len() - start;
 
-        bytes.insert(0, SCOPEOP);
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -779,14 +772,15 @@ impl<'a> Scope<'a> {
     /// Create raw bytes representing a Scope from its children in raw bytes
     pub fn raw(path: Path, mut children: Vec<u8>) -> Vec<u8> {
         let mut bytes = Vec::new();
+        bytes.push(SCOPEOP);
+
+        let start = bytes.len();
         path.to_aml_bytes(&mut bytes);
         bytes.append(&mut children);
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
-        }
-        bytes.insert(0, SCOPEOP);
+        let len = bytes.len() - start;
+
+        insert_pkg_length(&mut bytes, start, len);
+
         bytes
     }
 }
@@ -813,22 +807,18 @@ impl<'a> Method<'a> {
 
 impl<'a> Aml for Method<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.path.to_aml_bytes(&mut bytes);
+        aml.push(METHODOP);
+
+        let start = aml.len();
+        self.path.to_aml_bytes(aml);
         let flags: u8 = (self.args & 0x7) | (self.serialized as u8) << 3;
-        bytes.push(flags);
+        aml.push(flags);
         for child in &self.children {
-            child.to_aml_bytes(&mut bytes);
-        }
-
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
+            child.to_aml_bytes(aml);
         }
+        let len = aml.len() - start;
 
-        bytes.insert(0, METHODOP);
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -895,35 +885,31 @@ impl Field {
 
 impl Aml for Field {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.path.to_aml_bytes(&mut bytes);
+        aml.push(EXTOPPREFIX);
+        aml.push(FIELDOP);
+
+        let start = aml.len();
+        self.path.to_aml_bytes(aml);
 
         let flags: u8 =
             self.access_type as u8 | (self.lock_rule as u8) << 4 | (self.update_rule as u8) << 5;
-        bytes.push(flags);
+        aml.push(flags);
 
         for field in self.fields.iter() {
             match field {
                 FieldEntry::Named(name, length) => {
-                    bytes.extend_from_slice(name);
-                    bytes.append(&mut create_pkg_length(&vec![0; *length], false));
+                    aml.extend_from_slice(name);
+                    append_named_field_length(aml, *length);
                 }
                 FieldEntry::Reserved(length) => {
-                    bytes.push(0x0);
-                    bytes.append(&mut create_pkg_length(&vec![0; *length], false));
+                    aml.push(0x0);
+                    append_named_field_length(aml, *length);
                 }
             }
         }
 
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
-        }
-
-        bytes.insert(0, FIELDOP);
-        bytes.insert(0, EXTOPPREFIX);
-        aml.append(&mut bytes)
+        let len = aml.len() - start;
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -964,14 +950,13 @@ impl<'a> OpRegion<'a> {
 
 impl<'a> Aml for OpRegion<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.path.to_aml_bytes(&mut bytes);
-        bytes.push(self.space as u8);
-        self.offset.to_aml_bytes(&mut bytes); /* RegionOffset */
-        self.length.to_aml_bytes(&mut bytes); /* RegionLen */
-        bytes.insert(0, OPREGIONOP);
-        bytes.insert(0, EXTOPPREFIX);
-        aml.append(&mut bytes)
+        aml.push(EXTOPPREFIX);
+        aml.push(OPREGIONOP);
+
+        self.path.to_aml_bytes(aml);
+        aml.push(self.space as u8);
+        self.offset.to_aml_bytes(aml); /* RegionOffset */
+        self.length.to_aml_bytes(aml); /* RegionLen */
     }
 }
 
@@ -993,20 +978,16 @@ impl<'a> If<'a> {
 
 impl<'a> Aml for If<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.predicate.to_aml_bytes(&mut bytes);
-        for child in self.if_children.iter() {
-            child.to_aml_bytes(&mut bytes);
-        }
+        aml.push(IFOP);
 
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
+        let start = aml.len();
+        self.predicate.to_aml_bytes(aml);
+        for child in self.if_children.iter() {
+            child.to_aml_bytes(aml);
         }
+        let len = aml.len() - start;
 
-        bytes.insert(0, IFOP);
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -1024,19 +1005,15 @@ impl<'a> Else<'a> {
 
 impl<'a> Aml for Else<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        for child in self.body.iter() {
-            child.to_aml_bytes(&mut bytes);
-        }
+        aml.push(ELSEOP);
 
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
+        let start = aml.len();
+        for child in self.body.iter() {
+            child.to_aml_bytes(aml);
         }
+        let len = aml.len() - start;
 
-        bytes.insert(0, ELSEOP);
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -1225,20 +1202,16 @@ impl<'a> While<'a> {
 
 impl<'a> Aml for While<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.predicate.to_aml_bytes(&mut bytes);
-        for child in self.while_children.iter() {
-            child.to_aml_bytes(&mut bytes);
-        }
+        aml.push(WHILEOP);
 
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
+        let start = aml.len();
+        self.predicate.to_aml_bytes(aml);
+        for child in self.while_children.iter() {
+            child.to_aml_bytes(aml);
         }
+        let len = aml.len() - start;
 
-        bytes.insert(0, WHILEOP);
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -1448,18 +1421,13 @@ impl<'a> BufferTerm<'a> {
 
 impl<'a> Aml for BufferTerm<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.data.to_aml_bytes(&mut bytes);
-
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
-        }
+        aml.push(BUFFEROP);
 
-        bytes.insert(0, BUFFEROP);
+        let start = aml.len();
+        self.data.to_aml_bytes(aml);
+        let len = aml.len() - start;
 
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -1477,19 +1445,14 @@ impl BufferData {
 
 impl Aml for BufferData {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
-        self.data.len().to_aml_bytes(&mut bytes);
-        bytes.extend_from_slice(&self.data);
-
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
-        }
+        aml.push(BUFFEROP);
 
-        bytes.insert(0, BUFFEROP);
+        let start = aml.len();
+        self.data.len().to_aml_bytes(aml);
+        aml.extend_from_slice(&self.data);
+        let len = aml.len() - start;
 
-        aml.append(&mut bytes)
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -1590,32 +1553,27 @@ impl<'a> PowerResource<'a> {
 
 impl<'a> Aml for PowerResource<'a> {
     fn to_aml_bytes(&self, aml: &mut Vec<u8>) {
-        let mut bytes = Vec::new();
+        aml.push(EXTOPPREFIX);
+        aml.push(POWERRESOURCEOP);
+
+        let start = aml.len();
 
         // Add name string
-        self.name.to_aml_bytes(&mut bytes);
+        self.name.to_aml_bytes(aml);
         // Add system level
-        bytes.push(self.level);
+        aml.push(self.level);
         // Add Resource Order
         let orders = self.order.to_le_bytes();
-        bytes.push(orders[0]);
-        bytes.push(orders[1]);
+        aml.push(orders[0]);
+        aml.push(orders[1]);
         // Add child data
         for child in &self.children {
-            child.to_aml_bytes(&mut bytes);
-        }
-
-        // PkgLength
-        let mut pkg_length = create_pkg_length(&bytes, true);
-        pkg_length.reverse();
-        for byte in pkg_length {
-            bytes.insert(0, byte);
+            child.to_aml_bytes(aml);
         }
 
-        bytes.insert(0, POWERRESOURCEOP);
-        bytes.insert(0, EXTOPPREFIX);
+        let len = aml.len() - start;
 
-        aml.append(&mut bytes);
+        insert_pkg_length(aml, start, len);
     }
 }
 
@@ -1894,14 +1852,19 @@ mod tests {
 
     #[test]
     fn test_pkg_length() {
-        assert_eq!(create_pkg_length(&[0u8; 62], true), vec![63]);
-        assert_eq!(
-            create_pkg_length(&[0u8; 64], true),
-            vec![1 << 6 | (66 & 0xf), 66 >> 4]
-        );
+        let mut pkg_len_62 = Vec::new();
+        insert_pkg_length(&mut pkg_len_62, 0, 62);
+        assert_eq!(pkg_len_62, [63]);
+
+        let mut pkg_len_64 = Vec::new();
+        insert_pkg_length(&mut pkg_len_64, 0, 64);
+        assert_eq!(pkg_len_64, [1 << 6 | (66 & 0xf), 66 >> 4]);
+
+        let mut pkg_len_4096 = Vec::new();
+        insert_pkg_length(&mut pkg_len_4096, 0, 4096);
         assert_eq!(
-            create_pkg_length(&[0u8; 4096], true),
-            vec![
+            pkg_len_4096,
+            [
                 2 << 6 | (4099 & 0xf) as u8,
                 (4099 >> 4) as u8,
                 (4099 >> 12) as u8
diff --git a/android-merge-1-setup.sh b/android-merge-1-setup.sh
index a1c4f7475..b97f29669 100755
--- a/android-merge-1-setup.sh
+++ b/android-merge-1-setup.sh
@@ -60,3 +60,4 @@ fi
 
 git merge --log aosp/upstream-main
 $ANDROID_BUILD_TOP/external/crosvm/tools/install-deps
+$ANDROID_BUILD_TOP/external/crosvm/android-fork-stats.sh
diff --git a/android-merge-2-cargo-embargo.sh b/android-merge-2-cargo-embargo.sh
index ceaaa1ded..bd2819fc5 100755
--- a/android-merge-2-cargo-embargo.sh
+++ b/android-merge-2-cargo-embargo.sh
@@ -5,12 +5,12 @@
 set -e -u
 
 function usage() { echo "$0 [-r]" && exit 1; }
-
+CROSVM_DIR="$ANDROID_BUILD_TOP/external/crosvm"
 REUSE=""
 while getopts 'r' FLAG; do
   case ${FLAG} in
     r)
-      REUSE="--reuse-cargo-out"
+      REUSE="--reuse-cargo-out --cargo-out-dir $CROSVM_DIR"
       ;;
     ?)
       echo "unknown flag."
@@ -25,9 +25,18 @@ if ! [ -x "$(command -v bpfmt)" ]; then
 fi
 
 # If there is need to verify installation of some packages, add them here in pkges.
-pkges='meson protobuf-compiler'
+pkges='
+libdrm-dev
+libcap-dev
+libepoxy-dev
+libwayland-dev
+meson
+pkg-config
+protobuf-compiler
+wayland-protocols
+'
 for pkg in $pkges; do
-  result="$(dpkg-query -W --showformat='${db:Status-Status}' "$pkg" 2>&1)"
+  set +e; result="$(dpkg-query -W --showformat='${db:Status-Status}' "$pkg" 2>&1)"; set -e
   if [ ! $? = 0 ] || [ ! "$result" = installed ]; then
     echo $pkg' not found. Please install.' >&2
     exit 1
@@ -40,12 +49,12 @@ done
 #
 # TODO: Consider using android's prebuilt rust binaries. Currently doesn't work
 # because they try to incorrectly use system clang and llvm.
-RUST_TOOLCHAIN="1.73.0"
+RUST_TOOLCHAIN="1.77.2"
 rustup which --toolchain $RUST_TOOLCHAIN cargo || \
   rustup toolchain install $RUST_TOOLCHAIN
 CARGO_BIN="$(dirname $(rustup which --toolchain $RUST_TOOLCHAIN cargo))"
 
-cd $ANDROID_BUILD_TOP/external/crosvm
+cd "$CROSVM_DIR"
 
 if [ ! "$REUSE" ]; then
   rm -f cargo.out cargo.metadata
diff --git a/android_audio/Android.bp b/android_audio/Android.bp
index dfe0ccb15..9b1eb6158 100644
--- a/android_audio/Android.bp
+++ b/android_audio/Android.bp
@@ -20,7 +20,7 @@ rust_library {
     crate_name: "android_audio",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libaudio_streams",
diff --git a/android_audio/src/lib.rs b/android_audio/src/lib.rs
index 4b5d542a0..e1449e5b3 100644
--- a/android_audio/src/lib.rs
+++ b/android_audio/src/lib.rs
@@ -6,11 +6,14 @@
 mod libaaudio_stub;
 
 use std::os::raw::c_void;
-use std::thread;
 use std::time::Duration;
 use std::time::Instant;
 
 use async_trait::async_trait;
+use audio_streams::capture::AsyncCaptureBuffer;
+use audio_streams::capture::AsyncCaptureBufferStream;
+use audio_streams::capture::CaptureBuffer;
+use audio_streams::capture::CaptureBufferStream;
 use audio_streams::AsyncBufferCommit;
 use audio_streams::AsyncPlaybackBuffer;
 use audio_streams::AsyncPlaybackBufferStream;
@@ -22,11 +25,18 @@ use audio_streams::PlaybackBuffer;
 use audio_streams::PlaybackBufferStream;
 use audio_streams::SampleFormat;
 use audio_streams::StreamControl;
+use audio_streams::StreamEffect;
 use audio_streams::StreamSource;
 use audio_streams::StreamSourceGenerator;
 use base::warn;
 use thiserror::Error;
 
+#[derive(Clone, Copy)]
+enum AndroidAudioStreamDirection {
+    Input = 1,
+    Output = 0,
+}
+
 #[derive(Error, Debug)]
 pub enum AAudioError {
     #[error("Failed to create stream builder")]
@@ -64,6 +74,7 @@ extern "C" {
         builder: *mut AAudioStreamBuilder,
         num_frames: i32,
     );
+    fn AAudioStreamBuilder_setDirection(builder: *mut AAudioStreamBuilder, direction: u32);
     fn AAudioStreamBuilder_setFormat(builder: *mut AAudioStreamBuilder, format: AaudioFormatT);
     fn AAudioStreamBuilder_setSampleRate(builder: *mut AAudioStreamBuilder, sample_rate: i32);
     fn AAudioStreamBuilder_setChannelCount(builder: *mut AAudioStreamBuilder, channel_count: i32);
@@ -71,7 +82,14 @@ extern "C" {
         builder: *mut AAudioStreamBuilder,
         stream: *mut *mut AAudioStream,
     ) -> AaudioResultT;
+    fn AAudioStream_getBufferSizeInFrames(stream: *mut AAudioStream) -> i32;
     fn AAudioStream_requestStart(stream: *mut AAudioStream) -> AaudioResultT;
+    fn AAudioStream_read(
+        stream: *mut AAudioStream,
+        buffer: *mut c_void,
+        num_frames: i32,
+        timeout_nanoseconds: i64,
+    ) -> AaudioResultT;
     fn AAudioStream_write(
         stream: *mut AAudioStream,
         buffer: *const c_void,
@@ -95,64 +113,56 @@ unsafe impl Send for AndroidAudioStreamCommit {}
 struct AudioStream {
     buffer: Box<[u8]>,
     frame_size: usize,
-    interval: Duration,
-    next_frame: Duration,
+    frame_rate: u32,
+    next_frame: Instant,
     start_time: Option<Instant>,
+    total_frames: i32,
     buffer_drop: AndroidAudioStreamCommit,
+    read_count: i32,
+    aaudio_buffer_size: usize,
 }
 
 struct AndroidAudioStreamCommit {
     buffer_ptr: *const u8,
     stream: AAudioStreamPtr,
+    direction: AndroidAudioStreamDirection,
 }
 
 impl BufferCommit for AndroidAudioStreamCommit {
-    fn commit(&mut self, nwritten: usize) {
-        // SAFETY:
-        // The AAudioStream_write reads buffer for nwritten * frame_size bytes
-        // It is safe since nwritten < buffer_size and the buffer.len() == buffer_size * frame_size
-        let frames_written: i32 = unsafe {
-            AAudioStream_write(
-                self.stream.stream_ptr,
-                self.buffer_ptr as *const c_void,
-                nwritten as i32,
-                0, // this call will not wait.
-            )
-        };
-        if frames_written < 0 {
-            warn!("AAudio stream write failed.");
-        } else if (frames_written as usize) < nwritten {
-            // Currently, the frames unable to write by the AAudio API are dropped.
-            warn!(
-                "Android Audio Stream:  Drop {} frames",
-                nwritten - (frames_written as usize)
-            );
-        }
+    fn commit(&mut self, _nwritten: usize) {
+        // This traits function is never called.
+        unimplemented!();
     }
 }
 
 #[async_trait(?Send)]
 impl AsyncBufferCommit for AndroidAudioStreamCommit {
     async fn commit(&mut self, nwritten: usize) {
-        // SAFETY:
-        // The AAudioStream_write reads buffer for nwritten * frame_size bytes
-        // It is safe since nwritten < buffer_size and the buffer.len() == buffer_size * frame_size
-        let frames_written: i32 = unsafe {
-            AAudioStream_write(
-                self.stream.stream_ptr,
-                self.buffer_ptr as *const c_void,
-                nwritten as i32,
-                0, // this call will not wait.
-            )
-        };
-        if frames_written < 0 {
-            warn!("AAudio stream write failed.");
-        } else if (frames_written as usize) < nwritten {
-            // Currently, the frames unable to write by the AAudio API are dropped.
-            warn!(
-                "Android Audio Stream:  Drop {} frames",
-                nwritten - (frames_written as usize)
-            );
+        match self.direction {
+            AndroidAudioStreamDirection::Input => {}
+            AndroidAudioStreamDirection::Output => {
+                // SAFETY:
+                // The AAudioStream_write reads buffer for nwritten * frame_size bytes
+                // It is safe since nwritten < buffer_size and the buffer.len() == buffer_size *
+                // frame_size
+                let frames_written: i32 = unsafe {
+                    AAudioStream_write(
+                        self.stream.stream_ptr,
+                        self.buffer_ptr as *const c_void,
+                        nwritten as i32,
+                        0, // this call will not wait.
+                    )
+                };
+                if frames_written < 0 {
+                    warn!("AAudio stream write failed.");
+                } else if (frames_written as usize) < nwritten {
+                    // Currently, the frames unable to write by the AAudio API are dropped.
+                    warn!(
+                        "Android Audio Stream:  Drop {} frames",
+                        nwritten - (frames_written as usize)
+                    );
+                }
+            }
         }
     }
 }
@@ -163,9 +173,9 @@ impl AudioStream {
         format: SampleFormat,
         frame_rate: u32,
         buffer_size: usize,
+        direction: AndroidAudioStreamDirection,
     ) -> Result<Self, BoxError> {
         let frame_size = format.sample_bytes() * num_channels;
-        let interval = Duration::from_millis(buffer_size as u64 * 1000 / frame_rate as u64);
 
         let mut stream_ptr: *mut AAudioStream = std::ptr::null_mut();
         let mut builder: *mut AAudioStreamBuilder = std::ptr::null_mut();
@@ -176,6 +186,7 @@ impl AudioStream {
             if AAudio_createStreamBuilder(&mut builder) != AAUDIO_OK {
                 return Err(Box::new(AAudioError::StreamBuilderCreation));
             }
+            AAudioStreamBuilder_setDirection(builder, direction as u32);
             AAudioStreamBuilder_setBufferCapacityInFrames(builder, buffer_size as i32 * 2);
             AAudioStreamBuilder_setFormat(builder, format as AaudioFormatT);
             AAudioStreamBuilder_setSampleRate(builder, frame_rate as i32);
@@ -190,60 +201,133 @@ impl AudioStream {
                 return Err(Box::new(AAudioError::StreamStart));
             }
         }
+        // SAFETY:
+        // Interfacing with the AAudio C API. Assumes correct linking
+        // and `stream_ptr` pointers are valid and properly initialized.
+        let aaudio_buffer_size = unsafe { AAudioStream_getBufferSizeInFrames(stream_ptr) } as usize;
         let buffer = vec![0; buffer_size * frame_size].into_boxed_slice();
         let stream = AAudioStreamPtr { stream_ptr };
         let buffer_drop = AndroidAudioStreamCommit {
             stream,
             buffer_ptr: buffer.as_ptr(),
+            direction,
         };
         Ok(AudioStream {
             buffer,
             frame_size,
-            interval,
-            next_frame: interval,
+            frame_rate,
+            next_frame: Instant::now(),
             start_time: None,
+            total_frames: 0,
             buffer_drop,
+            read_count: 0,
+            aaudio_buffer_size,
         })
     }
 }
 
 impl PlaybackBufferStream for AudioStream {
     fn next_playback_buffer<'b, 's: 'b>(&'s mut self) -> Result<PlaybackBuffer<'b>, BoxError> {
-        if let Some(start_time) = self.start_time {
-            let elapsed = start_time.elapsed();
-            if elapsed < self.next_frame {
-                thread::sleep(self.next_frame - elapsed);
+        // This traits function is never called.
+        unimplemented!();
+    }
+}
+
+#[async_trait(?Send)]
+impl AsyncPlaybackBufferStream for AudioStream {
+    async fn next_playback_buffer<'a>(
+        &'a mut self,
+        ex: &dyn AudioStreamsExecutor,
+    ) -> Result<AsyncPlaybackBuffer<'a>, BoxError> {
+        self.total_frames += (self.buffer.len() / self.frame_size) as i32;
+        let start_time = match self.start_time {
+            Some(time) => {
+                ex.delay(self.next_frame.saturating_duration_since(Instant::now()))
+                    .await?;
+                time
             }
-            self.next_frame += self.interval;
-        } else {
-            self.start_time = Some(Instant::now());
-            self.next_frame = self.interval;
-        }
+            None => {
+                let now = Instant::now();
+                self.start_time = Some(now);
+                now
+            }
+        };
+        self.next_frame = start_time
+            + Duration::from_millis(self.total_frames as u64 * 1000 / self.frame_rate as u64);
         Ok(
-            PlaybackBuffer::new(self.frame_size, self.buffer.as_mut(), &mut self.buffer_drop)
+            AsyncPlaybackBuffer::new(self.frame_size, self.buffer.as_mut(), &mut self.buffer_drop)
                 .map_err(Box::new)?,
         )
     }
 }
 
 #[async_trait(?Send)]
-impl AsyncPlaybackBufferStream for AudioStream {
-    async fn next_playback_buffer<'a>(
+impl CaptureBufferStream for AudioStream {
+    fn next_capture_buffer<'b, 's: 'b>(&'s mut self) -> Result<CaptureBuffer<'b>, BoxError> {
+        // This traits function is never called.
+        unimplemented!()
+    }
+}
+
+#[async_trait(?Send)]
+impl AsyncCaptureBufferStream for AudioStream {
+    async fn next_capture_buffer<'a>(
         &'a mut self,
         ex: &dyn AudioStreamsExecutor,
-    ) -> Result<AsyncPlaybackBuffer<'a>, BoxError> {
-        if let Some(start_time) = self.start_time {
-            let elapsed = start_time.elapsed();
-            if elapsed < self.next_frame {
-                ex.delay(self.next_frame - elapsed).await?;
+    ) -> Result<AsyncCaptureBuffer<'a>, BoxError> {
+        let buffer_size = self.buffer.len() / self.frame_size;
+        self.read_count += 1;
+        self.total_frames += buffer_size as i32;
+        let start_time = match self.start_time {
+            Some(time) => {
+                ex.delay(self.next_frame.saturating_duration_since(Instant::now()))
+                    .await?;
+                time
+            }
+            None => {
+                let now = Instant::now();
+                self.start_time = Some(now);
+                now
             }
-            self.next_frame += self.interval;
-        } else {
-            self.start_time = Some(Instant::now());
-            self.next_frame = self.interval;
+        };
+        self.next_frame = start_time
+            + Duration::from_millis(self.total_frames as u64 * 1000 / self.frame_rate as u64);
+
+        // Skip for at least (1.5x aaudio buffer size - buffer_size) to ensure there is always a
+        // aaudio buffer available for read.
+        if self.read_count < (self.aaudio_buffer_size * 3 / 2 / buffer_size) as i32 + 1 {
+            self.buffer.fill(0);
+            return Ok(AsyncCaptureBuffer::new(
+                buffer_size,
+                self.buffer.as_mut(),
+                &mut self.buffer_drop,
+            )
+            .map_err(Box::new)?);
+        }
+
+        // SAFETY:
+        // The AAudioStream_read writes buffer for buffer.len() / frame_size * frame_size bytes
+        let frames_read = unsafe {
+            AAudioStream_read(
+                self.buffer_drop.stream.stream_ptr,
+                self.buffer.as_mut_ptr() as *mut c_void,
+                (buffer_size) as i32,
+                0,
+            )
+        };
+
+        if frames_read < 0 {
+            warn!("AAudio stream read failed: {frames_read}");
+            self.buffer.fill(0);
+        } else if (frames_read as usize) < buffer_size {
+            warn!(
+                "AAudio stream read data not enough. frames read: {frames_read}, buffer size: {buffer_size}",
+            );
+            self.buffer[frames_read as usize * self.frame_size..].fill(0);
         }
+
         Ok(
-            AsyncPlaybackBuffer::new(self.frame_size, self.buffer.as_mut(), &mut self.buffer_drop)
+            AsyncCaptureBuffer::new(buffer_size, self.buffer.as_mut(), &mut self.buffer_drop)
                 .map_err(Box::new)?,
         )
     }
@@ -266,31 +350,67 @@ struct AndroidAudioStreamSource;
 impl StreamSource for AndroidAudioStreamSource {
     #[allow(clippy::type_complexity)]
     fn new_playback_stream(
+        &mut self,
+        _num_channels: usize,
+        _format: SampleFormat,
+        _frame_rate: u32,
+        _buffer_size: usize,
+    ) -> Result<(Box<dyn StreamControl>, Box<dyn PlaybackBufferStream>), BoxError> {
+        // This traits function is never called.
+        unimplemented!();
+    }
+
+    #[allow(clippy::type_complexity)]
+    fn new_async_playback_stream(
         &mut self,
         num_channels: usize,
         format: SampleFormat,
         frame_rate: u32,
         buffer_size: usize,
-    ) -> Result<(Box<dyn StreamControl>, Box<dyn PlaybackBufferStream>), BoxError> {
-        match AudioStream::new(num_channels, format, frame_rate, buffer_size) {
-            Ok(audio_stream) => Ok((Box::new(NoopStreamControl::new()), Box::new(audio_stream))),
-            Err(err) => Err(err),
-        }
+        _ex: &dyn AudioStreamsExecutor,
+    ) -> Result<(Box<dyn StreamControl>, Box<dyn AsyncPlaybackBufferStream>), BoxError> {
+        let audio_stream = AudioStream::new(
+            num_channels,
+            format,
+            frame_rate,
+            buffer_size,
+            AndroidAudioStreamDirection::Output,
+        )?;
+        Ok((Box::new(NoopStreamControl::new()), Box::new(audio_stream)))
     }
 
     #[allow(clippy::type_complexity)]
-    fn new_async_playback_stream(
+    fn new_capture_stream(
+        &mut self,
+        _num_channels: usize,
+        _format: SampleFormat,
+        _frame_rate: u32,
+        _buffer_size: usize,
+        _effects: &[StreamEffect],
+    ) -> std::result::Result<(Box<dyn StreamControl>, Box<dyn CaptureBufferStream>), BoxError> {
+        // This traits function is never called.
+        unimplemented!();
+    }
+
+    #[allow(clippy::type_complexity)]
+    fn new_async_capture_stream(
         &mut self,
         num_channels: usize,
         format: SampleFormat,
         frame_rate: u32,
         buffer_size: usize,
+        _effects: &[StreamEffect],
         _ex: &dyn AudioStreamsExecutor,
-    ) -> Result<(Box<dyn StreamControl>, Box<dyn AsyncPlaybackBufferStream>), BoxError> {
-        match AudioStream::new(num_channels, format, frame_rate, buffer_size) {
-            Ok(audio_stream) => Ok((Box::new(NoopStreamControl::new()), Box::new(audio_stream))),
-            Err(err) => Err(err),
-        }
+    ) -> std::result::Result<(Box<dyn StreamControl>, Box<dyn AsyncCaptureBufferStream>), BoxError>
+    {
+        let audio_stream = AudioStream::new(
+            num_channels,
+            format,
+            frame_rate,
+            buffer_size,
+            AndroidAudioStreamDirection::Input,
+        )?;
+        Ok((Box::new(NoopStreamControl::new()), Box::new(audio_stream)))
     }
 }
 
diff --git a/android_audio/src/libaaudio_stub.rs b/android_audio/src/libaaudio_stub.rs
index b7bf17f69..db74f656f 100644
--- a/android_audio/src/libaaudio_stub.rs
+++ b/android_audio/src/libaaudio_stub.rs
@@ -33,6 +33,14 @@ extern "C" fn AAudioStreamBuilder_setBufferCapacityInFrames(
     unimplemented!();
 }
 
+#[no_mangle]
+extern "C" fn AAudioStreamBuilder_setDirection(
+    _builder: *mut AAudioStreamBuilder,
+    _direction: u32,
+) {
+    unimplemented!();
+}
+
 #[no_mangle]
 extern "C" fn AAudioStreamBuilder_setFormat(
     _builder: *mut AAudioStreamBuilder,
@@ -65,11 +73,26 @@ extern "C" fn AAudioStreamBuilder_openStream(
     unimplemented!();
 }
 
+#[no_mangle]
+extern "C" fn AAudioStream_getBufferSizeInFrames(_stream: *mut AAudioStream) -> i32 {
+    unimplemented!();
+}
+
 #[no_mangle]
 extern "C" fn AAudioStream_requestStart(_stream: *mut AAudioStream) -> AaudioResultT {
     unimplemented!();
 }
 
+#[no_mangle]
+extern "C" fn AAudioStream_read(
+    _stream: *mut AAudioStream,
+    _buffer: *mut c_void,
+    _num_frames: i32,
+    _timeout_nanoseconds: i64,
+) -> AaudioResultT {
+    unimplemented!();
+}
+
 #[no_mangle]
 extern "C" fn AAudioStream_write(
     _stream: *mut AAudioStream,
diff --git a/arch/Android.bp b/arch/Android.bp
index 738e27584..4f1dbcd5e 100644
--- a/arch/Android.bp
+++ b/arch/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "arch",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -54,6 +54,7 @@ rust_test {
         "libserde_keyvalue",
         "libswap",
         "libsync_rust",
+        "libtempfile",
         "libthiserror",
         "libuuid",
         "libvm_control",
@@ -69,7 +70,7 @@ rust_library {
     crate_name: "arch",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "gdb",
diff --git a/arch/Cargo.toml b/arch/Cargo.toml
index 8fb29995d..376093990 100644
--- a/arch/Cargo.toml
+++ b/arch/Cargo.toml
@@ -13,7 +13,7 @@ swap = ["swap/enable"]
 
 [dependencies]
 acpi_tables = { path = "../acpi_tables" }
-anyhow = "*"
+anyhow = "1"
 base = { path = "../base" }
 cfg-if = "1.0.0"
 cros_fdt = { path = "../cros_fdt" }
@@ -24,11 +24,11 @@ gdbstub_arch = { version = "0.3.0", optional = true }
 hypervisor = { path = "../hypervisor" }
 jail = { path = "../jail" }
 kernel_cmdline = { path = "../kernel_cmdline" }
-libc = "*"
+libc = "0.2"
 metrics = { path = "../metrics" }
 resources = { path = "../resources" }
-remain = "*"
-serde = { version = "*", features = [ "derive"] }
+remain = "0.2"
+serde = { version = "1", features = [ "derive"] }
 serde_json = { version = "1" }
 serde_keyvalue = { path = "../serde_keyvalue", features = ["argh_derive"] }
 swap = { path = "../swap" }
@@ -43,7 +43,8 @@ minijail = "*" # provided by ebuild
 power_monitor = { path = "../power_monitor" }
 
 [target.'cfg(windows)'.dependencies]
-winapi = "*"
+winapi = "0.3"
 
 [dev-dependencies]
-serde_json = "*"
+serde_json = "1"
+tempfile = "3"
diff --git a/arch/src/lib.rs b/arch/src/lib.rs
index de7a19320..f351c3f13 100644
--- a/arch/src/lib.rs
+++ b/arch/src/lib.rs
@@ -26,9 +26,9 @@ use acpi_tables::sdt::SDT;
 use base::syslog;
 use base::AsRawDescriptor;
 use base::AsRawDescriptors;
-use base::Event;
 use base::FileGetLen;
 use base::FileReadWriteAtVolatile;
+use base::RecvTube;
 use base::SendTube;
 use base::Tube;
 use devices::virtio::VirtioDevice;
@@ -81,7 +81,6 @@ pub use serial::get_serial_cmdline;
 pub use serial::set_default_serial_parameters;
 pub use serial::GetSerialCmdlineError;
 pub use serial::SERIAL_ADDR;
-#[cfg(any(target_os = "android", target_os = "linux"))]
 use sync::Condvar;
 use sync::Mutex;
 #[cfg(any(target_os = "android", target_os = "linux"))]
@@ -94,6 +93,7 @@ use vm_control::PmResource;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 use vm_memory::GuestMemoryError;
+use vm_memory::MemoryRegionInformation;
 use vm_memory::MemoryRegionOptions;
 
 cfg_if::cfg_if! {
@@ -139,6 +139,17 @@ pub struct Pstore {
     pub size: u32,
 }
 
+#[derive(Clone, Copy, Debug, Serialize, Deserialize, FromKeyValues)]
+#[serde(deny_unknown_fields, rename_all = "kebab-case")]
+pub enum FdtPosition {
+    /// At the start of RAM.
+    Start,
+    /// Near the end of RAM.
+    End,
+    /// After the payload, with some padding for alignment.
+    AfterPayload,
+}
+
 /// Set of CPU cores.
 #[derive(Clone, Debug, Default, PartialEq, Eq, PartialOrd, Ord)]
 pub struct CpuSet(Vec<usize>);
@@ -360,6 +371,11 @@ pub struct VmComponents {
     pub no_i8042: bool,
     pub no_rtc: bool,
     pub no_smt: bool,
+    #[cfg(all(
+        any(target_arch = "arm", target_arch = "aarch64"),
+        any(target_os = "android", target_os = "linux")
+    ))]
+    pub normalized_cpu_capacities: BTreeMap<usize, u32>,
     #[cfg(target_arch = "x86_64")]
     pub pci_low_start: Option<u64>,
     #[cfg(target_arch = "x86_64")]
@@ -376,11 +392,6 @@ pub struct VmComponents {
     pub swiotlb: Option<u64>,
     pub vcpu_affinity: Option<VcpuAffinity>,
     pub vcpu_count: usize,
-    #[cfg(all(
-        any(target_arch = "arm", target_arch = "aarch64"),
-        any(target_os = "android", target_os = "linux")
-    ))]
-    pub virt_cpufreq_socket: Option<std::os::unix::net::UnixStream>,
     pub vm_image: VmImage,
 }
 
@@ -405,7 +416,7 @@ pub struct RunnableLinuxVm<V: VmArch, Vcpu: VcpuArch> {
     pub resume_notify_devices: Vec<Arc<Mutex<dyn BusResumeDevice>>>,
     pub root_config: Arc<Mutex<PciRoot>>,
     pub rt_cpus: CpuSet,
-    pub suspend_evt: Event,
+    pub suspend_tube: (Arc<Mutex<SendTube>>, RecvTube),
     pub vcpu_affinity: Option<VcpuAffinity>,
     pub vcpu_count: usize,
     pub vcpu_init: Vec<VcpuInitArch>,
@@ -413,7 +424,7 @@ pub struct RunnableLinuxVm<V: VmArch, Vcpu: VcpuArch> {
     /// If it's Some, then `build_vm` already created the vcpus.
     pub vcpus: Option<Vec<Vcpu>>,
     pub vm: V,
-    pub vm_request_tube: Option<Tube>,
+    pub vm_request_tubes: Vec<Tube>,
 }
 
 /// The device and optional jail.
@@ -486,10 +497,9 @@ pub trait LinuxArch {
         #[cfg(target_arch = "x86_64")] pflash_jail: Option<Minijail>,
         #[cfg(target_arch = "x86_64")] fw_cfg_jail: Option<Minijail>,
         #[cfg(feature = "swap")] swap_controller: &mut Option<swap::SwapController>,
-        #[cfg(any(target_os = "android", target_os = "linux"))] guest_suspended_cvar: Option<
-            Arc<(Mutex<bool>, Condvar)>,
-        >,
+        guest_suspended_cvar: Option<Arc<(Mutex<bool>, Condvar)>>,
         device_tree_overlays: Vec<DtbOverlay>,
+        fdt_position: Option<FdtPosition>,
     ) -> std::result::Result<RunnableLinuxVm<V, Vcpu>, Self::Error>
     where
         V: VmArch,
@@ -531,6 +541,9 @@ pub trait LinuxArch {
     /// Returns frequency map for each of the host's logical cores.
     fn get_host_cpu_frequencies_khz() -> Result<BTreeMap<usize, Vec<u32>>, Self::Error>;
 
+    /// Returns max-freq map of the host's logical cores.
+    fn get_host_cpu_max_freq_khz() -> Result<BTreeMap<usize, u32>, Self::Error>;
+
     /// Returns capacity map of the host's logical cores.
     fn get_host_cpu_capacity() -> Result<BTreeMap<usize, u32>, Self::Error>;
 
@@ -1242,8 +1255,12 @@ pub enum LoadImageError {
     GuestMemorySlice(GuestMemoryError),
     #[error("Image size too large: {0}")]
     ImageSizeTooLarge(u64),
+    #[error("No suitable memory region found")]
+    NoSuitableMemoryRegion,
     #[error("Reading image into memory failed: {0}")]
     ReadToMemory(io::Error),
+    #[error("Cannot load zero-sized image")]
+    ZeroSizedImage,
 }
 
 /// Load an image from a file into guest memory.
@@ -1267,7 +1284,7 @@ where
 {
     let size = image.get_len().map_err(LoadImageError::GetLen)?;
 
-    if size > usize::max_value() as u64 || size > max_size {
+    if size > usize::MAX as u64 || size > max_size {
         return Err(LoadImageError::ImageSizeTooLarge(size));
     }
 
@@ -1292,6 +1309,8 @@ where
 /// * `image` - The file containing the image to be loaded.
 /// * `min_guest_addr` - The minimum address of the start of the image.
 /// * `max_guest_addr` - The address to load the last byte of the image.
+/// * `region_filter` - The optional filter function for determining if the given guest memory
+///   region is suitable for loading the image into it.
 /// * `align` - The minimum alignment of the start address of the image in bytes (must be a power of
 ///   two).
 ///
@@ -1301,6 +1320,7 @@ pub fn load_image_high<F>(
     image: &mut F,
     min_guest_addr: GuestAddress,
     max_guest_addr: GuestAddress,
+    region_filter: Option<fn(&MemoryRegionInformation) -> bool>,
     align: u64,
 ) -> Result<(GuestAddress, usize), LoadImageError>
 where
@@ -1313,13 +1333,47 @@ where
     let max_size = max_guest_addr.offset_from(min_guest_addr) & !(align - 1);
     let size = image.get_len().map_err(LoadImageError::GetLen)?;
 
-    if size > usize::max_value() as u64 || size > max_size {
+    if size == 0 {
+        return Err(LoadImageError::ZeroSizedImage);
+    }
+
+    if size > usize::MAX as u64 || size > max_size {
         return Err(LoadImageError::ImageSizeTooLarge(size));
     }
 
-    // Load image at the maximum aligned address allowed.
-    // The subtraction cannot underflow because of the size checks above.
-    let guest_addr = GuestAddress((max_guest_addr.offset() - size) & !(align - 1));
+    // Sort the list of guest memory regions by address so we can iterate over them in reverse order
+    // (high to low).
+    let mut regions: Vec<_> = guest_mem
+        .regions()
+        .filter(region_filter.unwrap_or(|_| true))
+        .collect();
+    regions.sort_unstable_by(|a, b| a.guest_addr.cmp(&b.guest_addr));
+
+    // Find the highest valid address inside a guest memory region that satisfies the requested
+    // alignment and min/max address requirements while having enough space for the image.
+    let guest_addr = regions
+        .into_iter()
+        .rev()
+        .filter_map(|r| {
+            // Highest address within this region.
+            let rgn_max_addr = r
+                .guest_addr
+                .checked_add((r.size as u64).checked_sub(1)?)?
+                .min(max_guest_addr);
+            // Lowest aligned address within this region.
+            let rgn_start_aligned = r.guest_addr.align(align)?;
+            // Hypothetical address of the image if loaded at the end of the region.
+            let image_addr = rgn_max_addr.checked_sub(size - 1)? & !(align - 1);
+
+            // Would the image fit within the region?
+            if image_addr >= rgn_start_aligned {
+                Some(image_addr)
+            } else {
+                None
+            }
+        })
+        .find(|&addr| addr >= min_guest_addr)
+        .ok_or(LoadImageError::NoSuitableMemoryRegion)?;
 
     // This is safe due to the bounds check above.
     let size = size as usize;
@@ -1364,6 +1418,7 @@ pub struct SmbiosOptions {
 #[cfg(test)]
 mod tests {
     use serde_keyvalue::from_key_values;
+    use tempfile::tempfile;
 
     use super::*;
 
@@ -1420,4 +1475,32 @@ mod tests {
         assert_eq!(res, cpuset);
         assert_eq!(serde_json::to_string(&cpuset).unwrap(), json_str);
     }
+
+    #[test]
+    fn load_image_high_max_4g() {
+        let mem = GuestMemory::new(&[
+            (GuestAddress(0x0000_0000), 0x4000_0000), // 0x00000000..0x40000000
+            (GuestAddress(0x8000_0000), 0x4000_0000), // 0x80000000..0xC0000000
+        ])
+        .unwrap();
+
+        const TEST_IMAGE_SIZE: u64 = 1234;
+        let mut test_image = tempfile().unwrap();
+        test_image.set_len(TEST_IMAGE_SIZE).unwrap();
+
+        const TEST_ALIGN: u64 = 0x8000;
+        let (addr, size) = load_image_high(
+            &mem,
+            &mut test_image,
+            GuestAddress(0x8000),
+            GuestAddress(0xFFFF_FFFF), // max_guest_addr beyond highest guest memory region
+            None,
+            TEST_ALIGN,
+        )
+        .unwrap();
+
+        assert_eq!(addr, GuestAddress(0xBFFF_8000));
+        assert_eq!(addr.offset() % TEST_ALIGN, 0);
+        assert_eq!(size, TEST_IMAGE_SIZE as usize);
+    }
 }
diff --git a/arch/src/serial.rs b/arch/src/serial.rs
index 0040f22a2..18455dc45 100644
--- a/arch/src/serial.rs
+++ b/arch/src/serial.rs
@@ -252,7 +252,7 @@ mod tests {
 
     #[test]
     fn get_serial_cmdline_default() {
-        let mut cmdline = Cmdline::new(4096);
+        let mut cmdline = Cmdline::new();
         let mut serial_parameters = BTreeMap::new();
         let io_bus = Bus::new(BusType::Io);
         let evt1_3 = Event::new().unwrap();
@@ -279,7 +279,7 @@ mod tests {
 
     #[test]
     fn get_serial_cmdline_virtio_console() {
-        let mut cmdline = Cmdline::new(4096);
+        let mut cmdline = Cmdline::new();
         let mut serial_parameters = BTreeMap::new();
         let io_bus = Bus::new(BusType::Io);
         let evt1_3 = Event::new().unwrap();
@@ -325,7 +325,7 @@ mod tests {
 
     #[test]
     fn get_serial_cmdline_virtio_console_serial_earlycon() {
-        let mut cmdline = Cmdline::new(4096);
+        let mut cmdline = Cmdline::new();
         let mut serial_parameters = BTreeMap::new();
         let io_bus = Bus::new(BusType::Io);
         let evt1_3 = Event::new().unwrap();
@@ -391,7 +391,7 @@ mod tests {
 
     #[test]
     fn get_serial_cmdline_virtio_console_invalid_earlycon() {
-        let mut cmdline = Cmdline::new(4096);
+        let mut cmdline = Cmdline::new();
         let mut serial_parameters = BTreeMap::new();
         let io_bus = Bus::new(BusType::Io);
         let evt1_3 = Event::new().unwrap();
diff --git a/argh_helpers/Android.bp b/argh_helpers/Android.bp
index 33024d115..20c8d16b9 100644
--- a/argh_helpers/Android.bp
+++ b/argh_helpers/Android.bp
@@ -18,7 +18,7 @@ rust_proc_macro {
     crate_name: "argh_helpers",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libproc_macro2",
diff --git a/audio_streams_conformance_test/Cargo.toml b/audio_streams_conformance_test/Cargo.toml
index e3ea89bce..d8d067d7f 100644
--- a/audio_streams_conformance_test/Cargo.toml
+++ b/audio_streams_conformance_test/Cargo.toml
@@ -9,15 +9,12 @@ audio_cras = ["dep:libcras"]
 chromeos = ["audio_cras"]
 
 [dependencies]
-argh = "*"
+argh = "0.1"
 audio_streams = { path = "../common/audio_streams" }
 cfg-if = "1.0.0"
 cros_async = { path = "../cros_async" }
 libcras = { version = "*", optional = true }
 remain = "0.2"
 serde = { version = "1.0", features = ["derive"] }
-serde_json = "*"
+serde_json = "1"
 thiserror = "1.0.20"
-
-[target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
-minijail = "*"
diff --git a/audio_util/Android.bp b/audio_util/Android.bp
index 4000343d6..3c0dd95c0 100644
--- a/audio_util/Android.bp
+++ b/audio_util/Android.bp
@@ -14,7 +14,7 @@ rust_library {
     crate_name: "audio_util",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libaudio_streams",
diff --git a/base/Android.bp b/base/Android.bp
index 4a871fb0e..8b18b4b65 100644
--- a/base/Android.bp
+++ b/base/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "base",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -33,7 +33,6 @@ rust_test {
         "libenv_logger",
         "liblibc",
         "liblog_rust",
-        "libminijail_rust",
         "libonce_cell",
         "libserde",
         "libserde_json",
@@ -76,7 +75,7 @@ rust_test {
     crate_name: "linux",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/linux/main.rs"],
+    crate_root: "tests/linux/main.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -91,7 +90,6 @@ rust_test {
         "libenv_logger",
         "liblibc",
         "liblog_rust",
-        "libminijail_rust",
         "libonce_cell",
         "libserde",
         "libserde_json",
@@ -115,7 +113,7 @@ rust_test {
     crate_name: "syslog",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/syslog.rs"],
+    crate_root: "tests/syslog.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -130,7 +128,6 @@ rust_test {
         "libenv_logger",
         "liblibc",
         "liblog_rust",
-        "libminijail_rust",
         "libonce_cell",
         "libserde",
         "libserde_json",
@@ -154,7 +151,7 @@ rust_test {
     crate_name: "tube",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/tube.rs"],
+    crate_root: "tests/tube.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -169,7 +166,6 @@ rust_test {
         "libenv_logger",
         "liblibc",
         "liblog_rust",
-        "libminijail_rust",
         "libonce_cell",
         "libserde",
         "libserde_json",
@@ -212,7 +208,7 @@ rust_library {
     crate_name: "base",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libaudio_streams",
@@ -221,13 +217,11 @@ rust_library {
         "libenv_logger",
         "liblibc",
         "liblog_rust",
-        "libminijail_rust",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsmallvec",
         "libsync_rust",
-        "libtempfile",
         "libthiserror",
         "libuuid",
         "libzerocopy",
@@ -255,8 +249,5 @@ rust_library {
         },
     },
     shared_libs: ["libcap"], // specified in src/linux/capabilities.rs
-    visibility: [
-        "//packages/modules/Virtualization/virtualizationmanager",
-        "//vendor:__subpackages__",
-    ],
+    visibility: ["//vendor:__subpackages__"],
 }
diff --git a/base/Cargo.toml b/base/Cargo.toml
index 81056883d..cf82426eb 100644
--- a/base/Cargo.toml
+++ b/base/Cargo.toml
@@ -4,48 +4,41 @@ version = "0.1.0"
 authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
-# The process tests will use fork, which requires a custom test harness to enforce single threaded
-# execution.
-[[test]]
-name = "process"
-path = "tests/process.rs"
-harness = false
-
 [features]
 proto_tube = ["protobuf"]
 seccomp_trace = []
 
 [dependencies]
 audio_streams = { path = "../common/audio_streams" } # provided by ebuild
-base_event_token_derive = { path = "base_event_token_derive", version = "*" }
+base_event_token_derive = { path = "base_event_token_derive" }
 sync = { path = "../common/sync" } # provided by ebuild
 
-cfg-if = "*"
+cfg-if = "1"
 chrono = { version = "0.4.34", features = ["now"], default-features = false }
 env_logger = { version = "0.9.0", default-features = false }
-libc = "*"
+libc = "0.2"
 log = "0.4"
 once_cell = "1.7"
 protobuf = { version = "3.2", optional = true }
 remain = "0.2"
 serde = { version = "1", features = [ "derive" ] }
-serde_json = "*"
+serde_json = "1"
 smallvec = "1.6.1"
-tempfile = "3"
 thiserror = "1.0.20"
 uuid = { version = "1", features = ["v4"] }
 zerocopy = { version = "0.7", features = ["derive"] }
 
 [dev-dependencies]
-libtest-mimic = "0.6"
 # ANDROID: uncomment when protos is fixed to work with cargo.
 # protos = { path = "../protos", features = ["composite-disk"] }
-
-[target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
-minijail = "*"
+tempfile = "3"
 
 [target.'cfg(windows)'.dependencies]
+futures = { version = "0.3" }
 protobuf = "3.2"
 rand = "0.8"
-winapi = "*"
+winapi = "0.3"
 win_util = { path = "../win_util"}
+
+[target.'cfg(target_os = "android")'.dependencies]
+android_log-sys = "0.3.1"
diff --git a/base/base_event_token_derive/Android.bp b/base/base_event_token_derive/Android.bp
index 7f9b0862d..eb45b90d8 100644
--- a/base/base_event_token_derive/Android.bp
+++ b/base/base_event_token_derive/Android.bp
@@ -15,10 +15,11 @@ package {
 rust_test_host {
     name: "base_event_token_derive_test_src_lib",
     defaults: ["crosvm_inner_defaults"],
+    host_cross_supported: false,
     crate_name: "base_event_token_derive",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -38,7 +39,7 @@ rust_proc_macro {
     crate_name: "base_event_token_derive",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libproc_macro2",
diff --git a/base/patches/Android.bp.patch b/base/patches/Android.bp.patch
index 8116f7d5d..016f9b2ba 100644
--- a/base/patches/Android.bp.patch
+++ b/base/patches/Android.bp.patch
@@ -95,8 +95,5 @@ index 734ab7c1..20f48f53 100644
 +        },
 +    },
 +    shared_libs: ["libcap"], // specified in src/linux/capabilities.rs
-     visibility: [
-         "//packages/modules/Virtualization/virtualizationmanager",
-         "//vendor:__subpackages__",
-     ],
+     visibility: ["//vendor:__subpackages__"],
  }
diff --git a/base/src/custom_serde.rs b/base/src/custom_serde.rs
index c2391f044..94965486e 100644
--- a/base/src/custom_serde.rs
+++ b/base/src/custom_serde.rs
@@ -19,14 +19,10 @@ use sync::Mutex;
 /// NOTE: This does not validate already serialized Mutexes and data. If multiple structs contain a
 /// clone of the Arc, and they are all being serialized, this will result in the same data being
 /// serialized, once per clone.
-pub fn serialize_arc_mutex<S, T: ?Sized>(
+pub fn serialize_arc_mutex<S: Serializer, T: Serialize + ?Sized>(
     item: &Arc<Mutex<T>>,
     serializer: S,
-) -> Result<S::Ok, S::Error>
-where
-    S: Serializer,
-    T: Serialize,
-{
+) -> Result<S::Ok, S::Error> {
     let lock = item.lock();
     serde::Serialize::serialize(&*lock, serializer)
 }
diff --git a/base/src/descriptor.rs b/base/src/descriptor.rs
index 222aa2dc6..9bb9d3e00 100644
--- a/base/src/descriptor.rs
+++ b/base/src/descriptor.rs
@@ -9,6 +9,7 @@ use std::sync::Arc;
 
 use serde::Deserialize;
 use serde::Serialize;
+use serde::Serializer;
 
 use crate::EventToken;
 use crate::RawDescriptor;
@@ -156,7 +157,7 @@ impl From<File> for SafeDescriptor {
 ///
 /// Note that with the exception of the last use-case (which requires proper error checking against
 /// the descriptor being closed), the `Descriptor` instance would be very short-lived.
-#[derive(Copy, Clone, Hash, PartialEq, Eq, PartialOrd, Ord)]
+#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, PartialOrd, Ord)]
 #[repr(transparent)]
 pub struct Descriptor(pub RawDescriptor);
 impl AsRawDescriptor for Descriptor {
@@ -180,3 +181,21 @@ impl EventToken for Descriptor {
         Descriptor(data as RawDescriptor)
     }
 }
+
+impl Serialize for Descriptor {
+    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
+    where
+        S: Serializer,
+    {
+        serializer.serialize_u64(self.0 as u64)
+    }
+}
+
+impl<'de> Deserialize<'de> for Descriptor {
+    fn deserialize<D>(deserializer: D) -> Result<Descriptor, D::Error>
+    where
+        D: serde::Deserializer<'de>,
+    {
+        u64::deserialize(deserializer).map(|data| Descriptor(data as RawDescriptor))
+    }
+}
diff --git a/base/src/file_traits.rs b/base/src/file_traits.rs
index 41d684234..48d370a21 100644
--- a/base/src/file_traits.rs
+++ b/base/src/file_traits.rs
@@ -14,19 +14,19 @@ use crate::VolatileSlice;
 /// it can be implemented for other types.
 pub trait FileSync {
     // Flush buffers related to this file to disk.
-    fn fsync(&mut self) -> Result<()>;
+    fn fsync(&self) -> Result<()>;
 
     // Flush buffers related to this file's data to disk, avoiding updating extra metadata. Note
     // that an implementation may simply implement fsync for fdatasync.
-    fn fdatasync(&mut self) -> Result<()>;
+    fn fdatasync(&self) -> Result<()>;
 }
 
 impl FileSync for File {
-    fn fsync(&mut self) -> Result<()> {
+    fn fsync(&self) -> Result<()> {
         self.sync_all()
     }
 
-    fn fdatasync(&mut self) -> Result<()> {
+    fn fdatasync(&self) -> Result<()> {
         self.sync_data()
     }
 }
@@ -51,7 +51,7 @@ impl FileSetLen for File {
 /// This is equivalent to fallocate() with no special flags.
 pub trait FileAllocate {
     /// Allocate storage for the region of the file starting at `offset` and extending `len` bytes.
-    fn allocate(&mut self, offset: u64, len: u64) -> Result<()>;
+    fn allocate(&self, offset: u64, len: u64) -> Result<()>;
 }
 
 /// A trait for getting the size of a file.
@@ -165,7 +165,7 @@ pub trait FileReadWriteAtVolatile {
     /// Reads bytes from this file at `offset` into the given slice, returning the number of bytes
     /// read on success. On Windows file pointer will update with the read, but on Linux the
     /// file pointer will not change.
-    fn read_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<usize>;
+    fn read_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize>;
 
     /// Like `read_at_volatile`, except it reads to a slice of buffers. Data is copied to fill each
     /// buffer in order, with the final buffer written to possibly being only partially filled. This
@@ -174,7 +174,7 @@ pub trait FileReadWriteAtVolatile {
     /// buffer provided, or returns `Ok(0)` if none exists.
     /// On Windows file pointer will update with the read, but on Linux the file pointer will not
     /// change.
-    fn read_vectored_at_volatile(&mut self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+    fn read_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
         if let Some(&slice) = bufs.first() {
             self.read_at_volatile(slice, offset)
         } else {
@@ -185,7 +185,7 @@ pub trait FileReadWriteAtVolatile {
     /// Reads bytes from this file at `offset` into the given slice until all bytes in the slice are
     /// read, or an error is returned. On Windows file pointer will update with the read, but on
     /// Linux the file pointer will not change.
-    fn read_exact_at_volatile(&mut self, mut slice: VolatileSlice, mut offset: u64) -> Result<()> {
+    fn read_exact_at_volatile(&self, mut slice: VolatileSlice, mut offset: u64) -> Result<()> {
         while slice.size() > 0 {
             match self.read_at_volatile(slice, offset) {
                 Ok(0) => return Err(Error::from(ErrorKind::UnexpectedEof)),
@@ -203,7 +203,7 @@ pub trait FileReadWriteAtVolatile {
     /// Writes bytes to this file at `offset` from the given slice, returning the number of bytes
     /// written on success. On Windows file pointer will update with the write, but on Linux the
     /// file pointer will not change.
-    fn write_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<usize>;
+    fn write_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize>;
 
     /// Like `write_at_volatile`, except that it writes from a slice of buffers. Data is copied
     /// from each buffer in order, with the final buffer read from possibly being only partially
@@ -212,7 +212,7 @@ pub trait FileReadWriteAtVolatile {
     /// first nonempty buffer provided, or returns `Ok(0)` if none exists.
     /// On Windows file pointer will update with the write, but on Linux the file pointer will not
     /// change.
-    fn write_vectored_at_volatile(&mut self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+    fn write_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
         if let Some(&slice) = bufs.first() {
             self.write_at_volatile(slice, offset)
         } else {
@@ -223,7 +223,7 @@ pub trait FileReadWriteAtVolatile {
     /// Writes bytes to this file at `offset` from the given slice until all bytes in the slice
     /// are written, or an error is returned. On Windows file pointer will update with the write,
     /// but on Linux the file pointer will not change.
-    fn write_all_at_volatile(&mut self, mut slice: VolatileSlice, mut offset: u64) -> Result<()> {
+    fn write_all_at_volatile(&self, mut slice: VolatileSlice, mut offset: u64) -> Result<()> {
         while slice.size() > 0 {
             match self.write_at_volatile(slice, offset) {
                 Ok(0) => return Err(Error::from(ErrorKind::WriteZero)),
@@ -240,27 +240,53 @@ pub trait FileReadWriteAtVolatile {
 }
 
 impl<'a, T: FileReadWriteAtVolatile + ?Sized> FileReadWriteAtVolatile for &'a mut T {
-    fn read_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<usize> {
+    fn read_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize> {
         (**self).read_at_volatile(slice, offset)
     }
 
-    fn read_vectored_at_volatile(&mut self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+    fn read_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
         (**self).read_vectored_at_volatile(bufs, offset)
     }
 
-    fn read_exact_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<()> {
+    fn read_exact_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<()> {
         (**self).read_exact_at_volatile(slice, offset)
     }
 
-    fn write_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<usize> {
+    fn write_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize> {
         (**self).write_at_volatile(slice, offset)
     }
 
-    fn write_vectored_at_volatile(&mut self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+    fn write_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
         (**self).write_vectored_at_volatile(bufs, offset)
     }
 
-    fn write_all_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<()> {
+    fn write_all_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<()> {
+        (**self).write_all_at_volatile(slice, offset)
+    }
+}
+
+impl<'a, T: FileReadWriteAtVolatile + ?Sized> FileReadWriteAtVolatile for &'a T {
+    fn read_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize> {
+        (**self).read_at_volatile(slice, offset)
+    }
+
+    fn read_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+        (**self).read_vectored_at_volatile(bufs, offset)
+    }
+
+    fn read_exact_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<()> {
+        (**self).read_exact_at_volatile(slice, offset)
+    }
+
+    fn write_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize> {
+        (**self).write_at_volatile(slice, offset)
+    }
+
+    fn write_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+        (**self).write_vectored_at_volatile(bufs, offset)
+    }
+
+    fn write_all_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<()> {
         (**self).write_all_at_volatile(slice, offset)
     }
 }
diff --git a/base/src/lib.rs b/base/src/lib.rs
index 2b2151477..2232bfdae 100644
--- a/base/src/lib.rs
+++ b/base/src/lib.rs
@@ -80,7 +80,6 @@ pub use wait_context::TriggeredEvent;
 pub use wait_context::WaitContext;
 pub use worker_thread::WorkerThread;
 pub use write_zeroes::PunchHole;
-pub use write_zeroes::PunchHoleMut;
 pub use write_zeroes::WriteZeroesAt;
 
 // TODO(b/233233301): reorganize platform specific exports under platform
@@ -93,6 +92,7 @@ cfg_if::cfg_if! {
         pub use linux::{
             clone_descriptor, safe_descriptor_from_path,
             validate_raw_descriptor, clear_descriptor_cloexec,
+            safe_descriptor_from_cmdline_fd,
         };
 
         // Event/signal related exports.
@@ -112,6 +112,7 @@ cfg_if::cfg_if! {
         pub use linux::logical_core_capacity;
         pub use linux::logical_core_cluster_id;
         pub use linux::logical_core_frequencies_khz;
+        pub use linux::logical_core_max_freq_khz;
         pub use linux::sched_attr;
         pub use linux::sched_setattr;
         pub use linux::UnlinkUnixListener;
@@ -181,7 +182,6 @@ pub use log::trace;
 pub use log::warn;
 pub use mmap::Protection;
 pub use platform::get_cpu_affinity;
-pub use platform::get_filesystem_type;
 pub use platform::getpid;
 pub use platform::open_file_or_duplicate;
 pub use platform::platform_timer_resolution::enable_high_res_timers;
diff --git a/base/src/mmap.rs b/base/src/mmap.rs
index 8095135eb..89598d592 100644
--- a/base/src/mmap.rs
+++ b/base/src/mmap.rs
@@ -37,9 +37,15 @@ fn get_cacheline_size_once() -> usize {
     let mut assume_reason: &str = "unknown";
     cfg_if::cfg_if! {
         if #[cfg(all(any(target_os = "android", target_os = "linux"), not(target_env = "musl")))] {
+            // TODO: Remove once available in libc bindings
+            #[cfg(target_os = "android")]
+            const _SC_LEVEL1_DCACHE_LINESIZE: i32 = 0x0094;
+            #[cfg(target_os = "linux")]
+            use libc::_SC_LEVEL1_DCACHE_LINESIZE;
+
             // SAFETY:
             // Safe because we check the return value for errors or unsupported requests
-            let linesize = unsafe { libc::sysconf(libc::_SC_LEVEL1_DCACHE_LINESIZE) };
+            let linesize = unsafe { libc::sysconf(_SC_LEVEL1_DCACHE_LINESIZE) };
             if linesize > 0 {
                 return linesize as usize;
             } else {
diff --git a/base/src/periodic_logger.rs b/base/src/periodic_logger.rs
index 7fd1a045d..332729ee9 100644
--- a/base/src/periodic_logger.rs
+++ b/base/src/periodic_logger.rs
@@ -95,7 +95,7 @@ impl PeriodicLogger {
             move |kill_evt| {
                 let mut timer = Timer::new().map_err(PeriodicLoggerError::TimerNewError)?;
                 timer
-                    .reset(interval_copy, Some(interval_copy))
+                    .reset_repeating(interval_copy)
                     .map_err(PeriodicLoggerError::TimerResetError)?;
 
                 let wait_ctx = WaitContext::build_with(&[
@@ -112,6 +112,8 @@ impl PeriodicLogger {
                                 break 'outer;
                             }
                             Token::PeriodicLog => {
+                                timer.mark_waited().unwrap();
+
                                 let counter_map = cloned_counter.read().map_err(|e| {
                                     PeriodicLoggerError::ReadLockError(e.to_string())
                                 })?;
diff --git a/base/src/shm.rs b/base/src/shm.rs
index 96284f37c..a5df874ef 100644
--- a/base/src/shm.rs
+++ b/base/src/shm.rs
@@ -10,7 +10,6 @@ use serde::Deserialize;
 use serde::Serialize;
 
 use crate::descriptor::AsRawDescriptor;
-use crate::descriptor::IntoRawDescriptor;
 use crate::descriptor::SafeDescriptor;
 use crate::Error;
 use crate::RawDescriptor;
@@ -57,8 +56,10 @@ impl SharedMemory {
     /// Clones the SharedMemory. The new SharedMemory will refer to the same
     /// underlying object as the original.
     pub fn try_clone(&self) -> Result<SharedMemory> {
-        let shmem_descriptor = SafeDescriptor::try_from(self as &dyn AsRawDescriptor)?;
-        SharedMemory::from_safe_descriptor(shmem_descriptor, self.size())
+        Ok(SharedMemory {
+            descriptor: self.descriptor.try_clone()?,
+            size: self.size,
+        })
     }
 }
 
@@ -71,12 +72,6 @@ impl AsRawDescriptor for SharedMemory {
     }
 }
 
-impl IntoRawDescriptor for SharedMemory {
-    fn into_raw_descriptor(self) -> RawDescriptor {
-        self.descriptor.into_raw_descriptor()
-    }
-}
-
 impl From<SharedMemory> for SafeDescriptor {
     fn from(sm: SharedMemory) -> SafeDescriptor {
         sm.descriptor
diff --git a/base/src/sys/linux/android/syslog.rs b/base/src/sys/linux/android/syslog.rs
index eddc8a26c..6db5e7923 100644
--- a/base/src/sys/linux/android/syslog.rs
+++ b/base/src/sys/linux/android/syslog.rs
@@ -4,8 +4,6 @@
 
 //! Implementation of the Syslog trait as a wrapper around Android's logging library, liblog.
 
-extern crate android_log_sys;
-
 use std::ffi::CString;
 use std::ffi::NulError;
 use std::mem::size_of;
@@ -30,7 +28,7 @@ pub struct PlatformSyslog {
 impl Syslog for PlatformSyslog {
     fn new(
         proc_name: String,
-        facility: Facility,
+        _facility: Facility,
     ) -> Result<(Option<Box<dyn Log + Send>>, Option<RawDescriptor>), Error> {
         Ok((Some(Box::new(Self { proc_name })), None))
     }
@@ -56,7 +54,7 @@ impl Log for PlatformSyslog {
         );
     }
 
-    fn enabled(&self, metadata: &log::Metadata) -> bool {
+    fn enabled(&self, _metadata: &log::Metadata) -> bool {
         true
     }
 
@@ -82,6 +80,7 @@ fn android_log(
 ) -> Result<(), NulError> {
     let tag = CString::new(tag)?;
     let default_pri = LogPriority::VERBOSE;
+    // SAFETY: `tag` is guaranteed to be valid for duration of the call
     if unsafe { __android_log_is_loggable(priority as i32, tag.as_ptr(), default_pri as i32) } != 0
     {
         let c_file_name = match file {
@@ -99,6 +98,7 @@ fn android_log(
             line,
             message: message.as_ptr(),
         };
+        // SAFETY: `log_message` is guaranteed to be valid for duration of the call
         unsafe { __android_log_write_log_message(&mut log_message) };
     }
     Ok(())
diff --git a/base/src/sys/linux/event.rs b/base/src/sys/linux/event.rs
index 4d174a2e6..108eb91ab 100644
--- a/base/src/sys/linux/event.rs
+++ b/base/src/sys/linux/event.rs
@@ -15,12 +15,14 @@ use serde::Deserialize;
 use serde::Serialize;
 
 use super::errno_result;
+use super::Error;
 use super::RawDescriptor;
 use super::Result;
 use crate::descriptor::AsRawDescriptor;
 use crate::descriptor::FromRawDescriptor;
 use crate::descriptor::IntoRawDescriptor;
 use crate::descriptor::SafeDescriptor;
+use crate::handle_eintr_errno;
 use crate::unix::duration_to_timespec;
 use crate::EventWaitResult;
 
@@ -75,16 +77,19 @@ impl PlatformEvent {
         // SAFETY:
         // This is safe because we made this fd and the pointer we pass can not overflow because we
         // give the syscall's size parameter properly.
-        let ret = unsafe {
+        let ret = handle_eintr_errno!(unsafe {
             write(
                 self.as_raw_descriptor(),
                 &v as *const u64 as *const c_void,
                 mem::size_of::<u64>(),
             )
-        };
-        if ret <= 0 {
+        });
+        if ret < 0 {
             return errno_result();
         }
+        if ret as usize != mem::size_of::<u64>() {
+            return Err(Error::new(libc::EIO));
+        }
         Ok(())
     }
 
@@ -94,16 +99,19 @@ impl PlatformEvent {
         // SAFETY:
         // This is safe because we made this fd and the pointer we pass can not overflow because
         // we give the syscall's size parameter properly.
-        let ret = unsafe {
+        let ret = handle_eintr_errno!(unsafe {
             read(
                 self.as_raw_descriptor(),
                 &mut buf as *mut u64 as *mut c_void,
                 mem::size_of::<u64>(),
             )
-        };
-        if ret <= 0 {
+        });
+        if ret < 0 {
             return errno_result();
         }
+        if ret as usize != mem::size_of::<u64>() {
+            return Err(Error::new(libc::EIO));
+        }
         Ok(buf)
     }
 
diff --git a/base/src/sys/linux/file_traits.rs b/base/src/sys/linux/file_traits.rs
index 0321e5502..aff0ba7ab 100644
--- a/base/src/sys/linux/file_traits.rs
+++ b/base/src/sys/linux/file_traits.rs
@@ -14,7 +14,7 @@ use super::FallocateMode;
 use crate::FileAllocate;
 
 impl FileAllocate for File {
-    fn allocate(&mut self, offset: u64, len: u64) -> Result<()> {
+    fn allocate(&self, offset: u64, len: u64) -> Result<()> {
         fallocate(self, FallocateMode::Allocate, offset, len)
             .map_err(|e| Error::from_raw_os_error(e.errno()))
     }
diff --git a/base/src/sys/linux/get_filesystem_type.rs b/base/src/sys/linux/get_filesystem_type.rs
deleted file mode 100644
index 09bc2910e..000000000
--- a/base/src/sys/linux/get_filesystem_type.rs
+++ /dev/null
@@ -1,36 +0,0 @@
-// Copyright 2021 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-use std::fs::File;
-use std::mem::MaybeUninit;
-use std::os::unix::io::AsRawFd;
-
-use libc::fstatfs64;
-
-use super::Result;
-use crate::syscall;
-
-/// Obtain file system type of the file system that the file is served from.
-#[allow(clippy::unnecessary_cast)]
-pub fn get_filesystem_type(file: &File) -> Result<i64> {
-    let mut statfs_buf = MaybeUninit::<libc::statfs64>::uninit();
-    // SAFETY:
-    // Safe because we just got the memory space with exact required amount and
-    // passing that on.
-    syscall!(unsafe { fstatfs64(file.as_raw_fd(), statfs_buf.as_mut_ptr()) })?;
-    // SAFETY:
-    // Safe because the kernel guarantees the struct is initialized.
-    let statfs_buf = unsafe { statfs_buf.assume_init() };
-    Ok(statfs_buf.f_type as i64)
-}
-
-#[cfg(test)]
-mod tests {
-    use super::*;
-    #[test]
-    fn simple_test() {
-        let file = File::open("/dev/null").unwrap();
-        let _fstype = get_filesystem_type(&file).unwrap();
-    }
-}
diff --git a/base/src/sys/linux/ioctl.rs b/base/src/sys/linux/ioctl.rs
index 0d83f4e70..bacf3abd9 100644
--- a/base/src/sys/linux/ioctl.rs
+++ b/base/src/sys/linux/ioctl.rs
@@ -26,15 +26,13 @@ macro_rules! ioctl_expr {
     };
 }
 
-/// Raw macro to declare a function that returns an ioctl number.
+/// Raw macro to declare a constant or a function that returns an ioctl number.
 #[macro_export]
 macro_rules! ioctl_ioc_nr {
     ($name:ident, $dir:expr, $ty:expr, $nr:expr, $size:expr) => {
         #[allow(non_snake_case)]
-        /// Generates ioctl request number.
-        pub const fn $name() -> $crate::linux::IoctlNr {
-            $crate::ioctl_expr!($dir, $ty, $nr, $size)
-        }
+        /// Constant ioctl request number.
+        pub const $name: $crate::linux::IoctlNr = $crate::ioctl_expr!($dir, $ty, $nr, $size);
     };
     ($name:ident, $dir:expr, $ty:expr, $nr:expr, $size:expr, $($v:ident),+) => {
         #[allow(non_snake_case)]
@@ -233,10 +231,10 @@ mod tests {
 
     #[test]
     fn ioctl_macros() {
-        assert_eq!(0x0000af01, VHOST_SET_OWNER());
-        assert_eq!(0x800454cf, TUNGETFEATURES());
-        assert_eq!(0x400454d9, TUNSETQUEUE());
-        assert_eq!(0xc004af12, VHOST_GET_VRING_BASE());
+        assert_eq!(0x0000af01, VHOST_SET_OWNER);
+        assert_eq!(0x800454cf, TUNGETFEATURES);
+        assert_eq!(0x400454d9, TUNSETQUEUE);
+        assert_eq!(0xc004af12, VHOST_GET_VRING_BASE);
 
         assert_eq!(0x80804522, EVIOCGBIT(2));
         assert_eq!(0x00004509, FAKE_IOCTL_2_ARG(3, 5));
diff --git a/base/src/sys/linux/mmap.rs b/base/src/sys/linux/mmap.rs
index d7767625b..d27545279 100644
--- a/base/src/sys/linux/mmap.rs
+++ b/base/src/sys/linux/mmap.rs
@@ -77,6 +77,29 @@ impl dyn MappedRegion {
             Err(Error::SystemCallFailed(ErrnoError::last()))
         }
     }
+
+    /// Calls madvise on a mapping of `size` bytes starting at `offset` from the start of
+    /// the region.  `offset`..`offset+size` must be contained within the `MappedRegion`.
+    pub fn madvise(&self, offset: usize, size: usize, advice: libc::c_int) -> Result<()> {
+        validate_includes_range(self.size(), offset, size)?;
+
+        // SAFETY:
+        // Safe because the MemoryMapping/MemoryMappingArena interface ensures our pointer and size
+        // are correct, and we've validated that `offset`..`offset+size` is in the range owned by
+        // this `MappedRegion`.
+        let ret = unsafe {
+            libc::madvise(
+                (self.as_ptr() as usize + offset) as *mut libc::c_void,
+                size,
+                advice,
+            )
+        };
+        if ret != -1 {
+            Ok(())
+        } else {
+            Err(Error::SystemCallFailed(ErrnoError::last()))
+        }
+    }
 }
 
 /// Wraps an anonymous shared memory mapping in the current process. Provides
@@ -311,7 +334,7 @@ impl MemoryMapping {
         // and set the (ANONYMOUS | NORESERVE) flag.
         let (fd, offset) = match fd {
             Some((fd, offset)) => {
-                if offset > libc::off64_t::max_value() as u64 {
+                if offset > libc::off64_t::MAX as u64 {
                     return Err(Error::InvalidOffset);
                 }
                 // Map private for read-only seal. See below for upstream relax of the restriction.
@@ -1018,11 +1041,11 @@ mod tests {
     #[test]
     fn slice_overflow_error() {
         let m = MemoryMappingBuilder::new(5).build().unwrap();
-        let res = m.get_slice(std::usize::MAX, 3).unwrap_err();
+        let res = m.get_slice(usize::MAX, 3).unwrap_err();
         assert_eq!(
             res,
             VolatileMemoryError::Overflow {
-                base: std::usize::MAX,
+                base: usize::MAX,
                 offset: 3,
             }
         );
@@ -1037,8 +1060,8 @@ mod tests {
     #[test]
     fn from_fd_offset_invalid() {
         let fd = tempfile().unwrap();
-        let res = MemoryMapping::from_fd_offset(&fd, 4096, (libc::off64_t::max_value() as u64) + 1)
-            .unwrap_err();
+        let res =
+            MemoryMapping::from_fd_offset(&fd, 4096, (libc::off64_t::MAX as u64) + 1).unwrap_err();
         match res {
             Error::InvalidOffset => {}
             e => panic!("unexpected error: {}", e),
@@ -1158,4 +1181,21 @@ mod tests {
             e => panic!("unexpected error: {}", e),
         }
     }
+
+    #[test]
+    fn arena_madvise() {
+        let size = 0x40000;
+        let mut m = MemoryMappingArena::new(size).unwrap();
+        m.add_anon_protection(0, size, Protection::read_write())
+            .expect("failed to add writable protection for madvise MADV_REMOVE");
+        let ps = pagesize();
+        <dyn MappedRegion>::madvise(&m, 0, ps, libc::MADV_PAGEOUT).unwrap();
+        <dyn MappedRegion>::madvise(&m, 0, size, libc::MADV_PAGEOUT).unwrap();
+        <dyn MappedRegion>::madvise(&m, ps, size - ps, libc::MADV_REMOVE).unwrap();
+        let res = <dyn MappedRegion>::madvise(&m, ps, size, libc::MADV_PAGEOUT).unwrap_err();
+        match res {
+            Error::InvalidAddress => {}
+            e => panic!("unexpected error: {}", e),
+        }
+    }
 }
diff --git a/base/src/sys/linux/mod.rs b/base/src/sys/linux/mod.rs
index aa91e6086..ea185c816 100644
--- a/base/src/sys/linux/mod.rs
+++ b/base/src/sys/linux/mod.rs
@@ -24,7 +24,6 @@ mod descriptor;
 mod event;
 mod file;
 mod file_traits;
-mod get_filesystem_type;
 mod mmap;
 mod net;
 mod netlink;
@@ -32,7 +31,6 @@ mod notifiers;
 pub mod platform_timer_resolution;
 mod poll;
 mod priority;
-pub mod process;
 mod sched;
 mod shm;
 pub mod signal;
@@ -61,13 +59,11 @@ use std::time::Duration;
 
 pub use acpi_event::*;
 pub use capabilities::drop_capabilities;
-pub use descriptor::*;
 pub use event::EventExt;
 pub(crate) use event::PlatformEvent;
 pub use file::find_next_data;
 pub use file::FileDataIterator;
 pub(crate) use file_traits::lib::*;
-pub use get_filesystem_type::*;
 pub use ioctl::*;
 use libc::c_int;
 use libc::c_long;
@@ -98,7 +94,6 @@ pub use signal::*;
 pub use signalfd::Error as SignalFdError;
 pub use signalfd::*;
 pub use terminal::*;
-pub use timer::*;
 pub(crate) use write_zeroes::file_punch_hole;
 pub(crate) use write_zeroes::file_write_zeroes_at;
 
@@ -215,13 +210,13 @@ pub fn fallocate<F: AsRawDescriptor>(
     offset: u64,
     len: u64,
 ) -> Result<()> {
-    let offset = if offset > libc::off64_t::max_value() as u64 {
+    let offset = if offset > libc::off64_t::MAX as u64 {
         return Err(Error::new(libc::EINVAL));
     } else {
         offset as libc::off64_t
     };
 
-    let len = if len > libc::off64_t::max_value() as u64 {
+    let len = if len > libc::off64_t::MAX as u64 {
         return Err(Error::new(libc::EINVAL));
     } else {
         len as libc::off64_t
@@ -266,7 +261,7 @@ pub fn discard_block<F: AsRawDescriptor>(file: &F, offset: u64, len: u64) -> Res
     // - ioctl(BLKDISCARD) does not hold the descriptor after the call.
     // - ioctl(BLKDISCARD) does not break the file descriptor.
     // - ioctl(BLKDISCARD) does not modify the given range.
-    syscall!(unsafe { libc::ioctl(file.as_raw_descriptor(), BLKDISCARD(), &range) }).map(|_| ())
+    syscall!(unsafe { libc::ioctl(file.as_raw_descriptor(), BLKDISCARD, &range) }).map(|_| ())
 }
 
 /// A trait used to abstract types that provide a process id that can be operated on.
@@ -455,17 +450,17 @@ impl Drop for UnlinkUnixListener {
 /// Verifies that |raw_descriptor| is actually owned by this process and duplicates it
 /// to ensure that we have a unique handle to it.
 pub fn validate_raw_descriptor(raw_descriptor: RawDescriptor) -> Result<RawDescriptor> {
-    validate_raw_fd(raw_descriptor)
+    validate_raw_fd(&raw_descriptor)
 }
 
 /// Verifies that |raw_fd| is actually owned by this process and duplicates it to ensure that
 /// we have a unique handle to it.
-pub fn validate_raw_fd(raw_fd: RawFd) -> Result<RawFd> {
+pub fn validate_raw_fd(raw_fd: &RawFd) -> Result<RawFd> {
     // Checking that close-on-exec isn't set helps filter out FDs that were opened by
     // crosvm as all crosvm FDs are close on exec.
     // SAFETY:
     // Safe because this doesn't modify any memory and we check the return value.
-    let flags = unsafe { libc::fcntl(raw_fd, libc::F_GETFD) };
+    let flags = unsafe { libc::fcntl(*raw_fd, libc::F_GETFD) };
     if flags < 0 || (flags & libc::FD_CLOEXEC) != 0 {
         return Err(Error::new(libc::EBADF));
     }
@@ -474,7 +469,7 @@ pub fn validate_raw_fd(raw_fd: RawFd) -> Result<RawFd> {
     // Duplicate the fd to ensure that we don't accidentally close an fd previously
     // opened by another subsystem.  Safe because this doesn't modify any memory and
     // we check the return value.
-    let dup_fd = unsafe { libc::fcntl(raw_fd, libc::F_DUPFD_CLOEXEC, 0) };
+    let dup_fd = unsafe { libc::fcntl(*raw_fd, libc::F_DUPFD_CLOEXEC, 0) };
     if dup_fd < 0 {
         return Err(Error::last());
     }
@@ -505,7 +500,7 @@ pub fn poll_in<F: AsRawDescriptor>(fd: &F) -> bool {
 
 /// Return the maximum Duration that can be used with libc::timespec.
 pub fn max_timeout() -> Duration {
-    Duration::new(libc::time_t::max_value() as u64, 999999999)
+    Duration::new(libc::time_t::MAX as u64, 999999999)
 }
 
 /// If the given path is of the form /proc/self/fd/N for some N, returns `Ok(Some(N))`. Otherwise
@@ -518,7 +513,7 @@ pub fn safe_descriptor_from_path<P: AsRef<Path>>(path: P) -> Result<Option<SafeD
             .and_then(|fd_osstr| fd_osstr.to_str())
             .and_then(|fd_str| fd_str.parse::<RawFd>().ok())
             .ok_or_else(|| Error::new(EINVAL))?;
-        let validated_fd = validate_raw_fd(raw_descriptor)?;
+        let validated_fd = validate_raw_fd(&raw_descriptor)?;
         Ok(Some(
             // SAFETY:
             // Safe because nothing else has access to validated_fd after this call.
@@ -529,6 +524,18 @@ pub fn safe_descriptor_from_path<P: AsRef<Path>>(path: P) -> Result<Option<SafeD
     }
 }
 
+/// Check FD is not opened by crosvm and returns a FD that is freshly DUPFD_CLOEXEC's.
+/// A SafeDescriptor is created from the duplicated fd. It does not take ownership of
+/// fd passed by argument.
+pub fn safe_descriptor_from_cmdline_fd(fd: &RawFd) -> Result<SafeDescriptor> {
+    let validated_fd = validate_raw_fd(fd)?;
+    Ok(
+        // SAFETY:
+        // Safe because nothing else has access to validated_fd after this call.
+        unsafe { SafeDescriptor::from_raw_descriptor(validated_fd) },
+    )
+}
+
 /// Open the file with the given path, or if it is of the form `/proc/self/fd/N` then just use the
 /// file descriptor.
 ///
@@ -545,8 +552,8 @@ pub fn open_file_or_duplicate<P: AsRef<Path>>(path: P, options: &OpenOptions) ->
     })
 }
 
-/// Get the max number of open files allowed by the environment.
-pub fn max_open_files() -> Result<u64> {
+/// Get the soft and hard limits of max number of open files allowed by the environment.
+pub fn max_open_files() -> Result<libc::rlimit64> {
     let mut buf = mem::MaybeUninit::<libc::rlimit64>::zeroed();
 
     // SAFETY:
@@ -556,7 +563,44 @@ pub fn max_open_files() -> Result<u64> {
         // SAFETY:
         // Safe because the kernel guarantees that the struct is fully initialized.
         let limit = unsafe { buf.assume_init() };
-        Ok(limit.rlim_max)
+        Ok(limit)
+    } else {
+        errno_result()
+    }
+}
+
+/// Executes the given callback with extended soft limit of max number of open files. After the
+/// callback executed, restore the limit.
+pub fn call_with_extended_max_files<T, E>(
+    callback: impl FnOnce() -> std::result::Result<T, E>,
+) -> Result<std::result::Result<T, E>> {
+    let cur_limit = max_open_files()?;
+    let new_limit = libc::rlimit64 {
+        rlim_cur: cur_limit.rlim_max,
+        ..cur_limit
+    };
+    let needs_extension = cur_limit.rlim_cur < new_limit.rlim_cur;
+    if needs_extension {
+        set_max_open_files(new_limit)?;
+    }
+
+    let r = callback();
+
+    // Restore the soft limit.
+    if needs_extension {
+        set_max_open_files(cur_limit)?;
+    }
+
+    Ok(r)
+}
+
+/// Set the soft and hard limits of max number of open files to the given value.
+fn set_max_open_files(limit: libc::rlimit64) -> Result<()> {
+    // SAFETY: RLIMIT_NOFILE is known only to read a buffer of size rlimit64, and we have always
+    // rlimit64 allocated.
+    let res = unsafe { libc::setrlimit64(libc::RLIMIT_NOFILE, &limit) };
+    if res == 0 {
+        Ok(())
     } else {
         errno_result()
     }
@@ -619,11 +663,14 @@ pub fn logical_core_capacity(cpu_id: usize) -> Result<u32> {
     });
 
     if let Ok(cpu_max_freqs) = cpu_max_freqs {
-        let largest_max_freq = cpu_max_freqs.iter().max().ok_or(Error::new(EINVAL))?;
-        let cpu_max_freq = cpu_max_freqs.get(cpu_id).ok_or(Error::new(EINVAL))?;
-        (cpu_capacity * largest_max_freq)
-            .checked_div(*cpu_max_freq)
-            .ok_or(Error::new(EINVAL))
+        let largest_max_freq = *cpu_max_freqs.iter().max().ok_or(Error::new(EINVAL))?;
+        let cpu_max_freq = *cpu_max_freqs.get(cpu_id).ok_or(Error::new(EINVAL))?;
+        let normalized_cpu_capacity = (u64::from(cpu_capacity) * u64::from(largest_max_freq))
+            .checked_div(u64::from(cpu_max_freq))
+            .ok_or(Error::new(EINVAL))?;
+        normalized_cpu_capacity
+            .try_into()
+            .map_err(|_| Error::new(EINVAL))
     } else {
         // cpu-freq is not enabled. Fall back to using the normalized capacity.
         Ok(cpu_capacity)
@@ -636,7 +683,7 @@ pub fn logical_core_cluster_id(cpu_id: usize) -> Result<u32> {
 }
 
 /// Returns the maximum frequency (in kHz) of a given logical core.
-fn logical_core_max_freq_khz(cpu_id: usize) -> Result<u32> {
+pub fn logical_core_max_freq_khz(cpu_id: usize) -> Result<u32> {
     parse_sysfs_cpu_info(cpu_id, "cpufreq/cpuinfo_max_freq")
 }
 
diff --git a/base/src/sys/linux/poll.rs b/base/src/sys/linux/poll.rs
index 41011f262..45edf9f8c 100644
--- a/base/src/sys/linux/poll.rs
+++ b/base/src/sys/linux/poll.rs
@@ -217,7 +217,7 @@ impl<T: EventToken> EventContext<T> {
             // into `epoll_event` structures after the call.
             unsafe { MaybeUninit::uninit().assume_init() };
 
-        let timeout_millis = if timeout.as_secs() as i64 == i64::max_value() {
+        let timeout_millis = if timeout.as_secs() as i64 == i64::MAX {
             // We make the convenient assumption that 2^63 seconds is an effectively unbounded time
             // frame. This is meant to mesh with `wait` calling us with no timeout.
             -1
@@ -228,8 +228,8 @@ impl<T: EventToken> EventContext<T> {
                 .as_secs()
                 .checked_mul(1_000)
                 .and_then(|ms| ms.checked_add(u64::from(timeout.subsec_nanos()) / 1_000_000))
-                .unwrap_or(i32::max_value() as u64);
-            min(i32::max_value() as u64, millis) as i32
+                .unwrap_or(i32::MAX as u64);
+            min(i32::MAX as u64, millis) as i32
         };
         let ret = {
             let max_events = epoll_events.len() as c_int;
diff --git a/base/src/sys/linux/sched.rs b/base/src/sys/linux/sched.rs
index 054faf6b8..9f0e45932 100644
--- a/base/src/sys/linux/sched.rs
+++ b/base/src/sys/linux/sched.rs
@@ -35,6 +35,7 @@ impl CpuSet {
         CpuSet(cpuset)
     }
 
+    #[allow(clippy::unnecessary_cast)]
     pub fn to_cpus(&self) -> Vec<usize> {
         let mut cpus = Vec::new();
         for i in 0..(CPU_SETSIZE as usize) {
@@ -70,6 +71,7 @@ impl FromIterator<usize> for CpuSet {
 /// # use base::linux::set_cpu_affinity;
 ///   set_cpu_affinity(vec![0, 1, 5, 6]).unwrap();
 /// ```
+#[allow(clippy::unnecessary_cast)]
 pub fn set_cpu_affinity<I: IntoIterator<Item = usize>>(cpus: I) -> Result<()> {
     let CpuSet(cpuset) = cpus
         .into_iter()
diff --git a/base/src/sys/linux/timer.rs b/base/src/sys/linux/timer.rs
index 765218394..f9010dd47 100644
--- a/base/src/sys/linux/timer.rs
+++ b/base/src/sys/linux/timer.rs
@@ -15,6 +15,7 @@ use libc::CLOCK_MONOTONIC;
 use libc::EAGAIN;
 use libc::POLLIN;
 use libc::TFD_CLOEXEC;
+use libc::TFD_NONBLOCK;
 
 use super::super::errno_result;
 use super::super::Error;
@@ -39,7 +40,7 @@ impl Timer {
     pub fn new() -> Result<Timer> {
         // SAFETY:
         // Safe because this doesn't modify any memory and we check the return value.
-        let ret = unsafe { timerfd_create(CLOCK_MONOTONIC, TFD_CLOEXEC) };
+        let ret = unsafe { timerfd_create(CLOCK_MONOTONIC, TFD_CLOEXEC | TFD_NONBLOCK) };
         if ret < 0 {
             return errno_result();
         }
@@ -75,8 +76,12 @@ impl Timer {
 }
 
 impl TimerTrait for Timer {
-    fn reset(&mut self, dur: Duration, interval: Option<Duration>) -> Result<()> {
-        self.set_time(Some(dur), interval)
+    fn reset_oneshot(&mut self, dur: Duration) -> Result<()> {
+        self.set_time(Some(dur), None)
+    }
+
+    fn reset_repeating(&mut self, dur: Duration) -> Result<()> {
+        self.set_time(Some(dur), Some(dur))
     }
 
     fn clear(&mut self) -> Result<()> {
@@ -117,8 +122,8 @@ impl TimerTrait for Timer {
     fn mark_waited(&mut self) -> Result<bool> {
         let mut count = 0u64;
 
-        // SAFETY:
         // The timerfd is in non-blocking mode, so this should return immediately.
+        // SAFETY: We own the FD and provide a valid buffer we have exclusive access to.
         let ret = unsafe {
             libc::read(
                 self.as_raw_descriptor(),
diff --git a/base/src/sys/linux/vsock.rs b/base/src/sys/linux/vsock.rs
index 6a6b5d11c..aeda95c9c 100644
--- a/base/src/sys/linux/vsock.rs
+++ b/base/src/sys/linux/vsock.rs
@@ -37,7 +37,7 @@ const AF_VSOCK: sa_family_t = 40;
 const VMADDR_CID_LOCAL: c_uint = 1;
 
 /// Vsock equivalent of binding on port 0. Binds to a random port.
-pub const VMADDR_PORT_ANY: c_uint = c_uint::max_value();
+pub const VMADDR_PORT_ANY: c_uint = c_uint::MAX;
 
 // The number of bytes of padding to be added to the sockaddr_vm struct.  Taken directly
 // from linux/vm_sockets.h.
diff --git a/base/src/sys/macos/event.rs b/base/src/sys/macos/event.rs
index 90d63309f..9fb0d407a 100644
--- a/base/src/sys/macos/event.rs
+++ b/base/src/sys/macos/event.rs
@@ -2,100 +2,49 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-use std::ptr;
 use std::time::Duration;
 
-use crate::descriptor::AsRawDescriptor;
-use crate::descriptor::FromRawDescriptor;
-use crate::errno::errno_result;
 use crate::errno::Result;
 use crate::event::EventWaitResult;
+use crate::sys::macos::kqueue::make_kevent;
+use crate::sys::macos::kqueue::Kqueue;
 use crate::sys::unix::RawDescriptor;
-use crate::unix::duration_to_timespec;
 use crate::SafeDescriptor;
 
 #[derive(Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
 pub struct PlatformEvent {
-    // TODO(schuffelen): Implement a more complete kqueue abstraction?
-    queue: SafeDescriptor,
-}
-
-// Only accepts the subset of parameters we actually use
-fn make_kevent(filter: i16, flags: u16, fflags: u32) -> libc::kevent {
-    libc::kevent {
-        ident: 0, /* hopefully not global? */
-        filter,
-        flags,
-        fflags,
-        data: 0,
-        udata: ptr::null_mut(),
-    }
+    queue: Kqueue,
 }
 
 impl PlatformEvent {
     pub fn new() -> Result<PlatformEvent> {
-        // SAFETY: Trivially safe
-        let raw_queue = unsafe { libc::kqueue() };
-        if raw_queue < 0 {
-            return crate::errno::errno_result();
-        }
-        // SAFETY: Tested whether it was a valid file descriptor
-        let queue = unsafe { SafeDescriptor::from_raw_descriptor(raw_queue) };
-        let event = PlatformEvent { queue };
+        let event = PlatformEvent {
+            queue: Kqueue::new()?,
+        };
         let reg = make_kevent(
             libc::EVFILT_USER,
             libc::EV_ADD | libc::EV_CLEAR,
             libc::NOTE_FFNOP,
         );
-        event.kevent(&[reg], &mut [], None)?;
+        event.queue.kevent(&[reg], &mut [], None)?;
         Ok(event)
     }
 
-    fn kevent(
-        &self,
-        changelist: &[libc::kevent],
-        eventlist: &mut [libc::kevent],
-        timeout: Option<Duration>,
-    ) -> Result<libc::c_int> {
-        let timespec = timeout.map(duration_to_timespec);
-        // SAFETY: `queue` is a valid kqueue, `changelist` and `eventlist` are supplied with lengths
-        // based on valid slices
-        let res = unsafe {
-            libc::kevent(
-                self.queue.as_raw_descriptor(),
-                changelist.as_ptr(),
-                changelist.len() as i32,
-                eventlist.as_mut_ptr(),
-                eventlist.len() as i32,
-                if let Some(timeout) = timespec {
-                    &timeout
-                } else {
-                    ptr::null()
-                },
-            )
-        };
-        if res < 0 {
-            errno_result()
-        } else {
-            Ok(res)
-        }
-    }
-
     pub fn signal(&self) -> Result<()> {
         let event = make_kevent(libc::EVFILT_USER, 0, libc::NOTE_TRIGGER);
-        self.kevent(&[event], &mut [], None)?;
+        self.queue.kevent(&[event], &mut [], None)?;
         Ok(())
     }
 
     pub fn wait(&self) -> Result<()> {
         let mut event = [make_kevent(0, 0, 0)];
-        self.kevent(&[], &mut event[..], None)?;
+        self.queue.kevent(&[], &mut event[..], None)?;
         Ok(())
     }
 
     pub fn wait_timeout(&self, timeout: Duration) -> Result<EventWaitResult> {
         let mut event = [make_kevent(0, 0, 0)];
-        if self.kevent(&[], &mut event[..], Some(timeout))? == 0 {
+        if self.queue.kevent(&[], &mut event[..], Some(timeout))?.len() == 0 {
             Ok(EventWaitResult::TimedOut)
         } else {
             Ok(EventWaitResult::Signaled)
@@ -121,7 +70,7 @@ impl crate::AsRawDescriptor for PlatformEvent {
 impl crate::FromRawDescriptor for PlatformEvent {
     unsafe fn from_raw_descriptor(descriptor: RawDescriptor) -> Self {
         PlatformEvent {
-            queue: SafeDescriptor::from_raw_descriptor(descriptor),
+            queue: Kqueue::from_raw_descriptor(descriptor),
         }
     }
 }
@@ -132,14 +81,16 @@ impl crate::IntoRawDescriptor for PlatformEvent {
     }
 }
 
-impl From<PlatformEvent> for crate::SafeDescriptor {
+impl From<PlatformEvent> for SafeDescriptor {
     fn from(evt: PlatformEvent) -> Self {
-        evt.queue
+        SafeDescriptor::from(evt.queue)
     }
 }
 
 impl From<SafeDescriptor> for PlatformEvent {
     fn from(queue: SafeDescriptor) -> Self {
-        PlatformEvent { queue }
+        PlatformEvent {
+            queue: Kqueue::from(queue),
+        }
     }
 }
diff --git a/base/src/sys/macos/kqueue.rs b/base/src/sys/macos/kqueue.rs
new file mode 100644
index 000000000..ca5c86d69
--- /dev/null
+++ b/base/src/sys/macos/kqueue.rs
@@ -0,0 +1,120 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::ptr;
+use std::time::Duration;
+
+use crate::descriptor::AsRawDescriptor;
+use crate::descriptor::FromRawDescriptor;
+use crate::errno::errno_result;
+use crate::errno::Error;
+use crate::errno::Result;
+use crate::sys::unix::RawDescriptor;
+use crate::unix::duration_to_timespec;
+use crate::unix::set_descriptor_cloexec;
+use crate::SafeDescriptor;
+
+#[derive(Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
+pub(in crate::sys::macos) struct Kqueue {
+    queue: SafeDescriptor,
+}
+
+// Only accepts the subset of parameters we actually use
+pub(in crate::sys::macos) fn make_kevent(filter: i16, flags: u16, fflags: u32) -> libc::kevent64_s {
+    libc::kevent64_s {
+        ident: 0, /* hopefully not global? */
+        filter,
+        flags,
+        fflags,
+        data: 0,
+        udata: 0,
+        ext: [0, 0],
+    }
+}
+
+impl Kqueue {
+    pub(in crate::sys::macos) fn new() -> Result<Kqueue> {
+        // SAFETY: Trivially safe
+        let raw_queue = unsafe { libc::kqueue() };
+        if raw_queue < 0 {
+            return crate::errno::errno_result();
+        }
+        // SAFETY: Tested whether it was a valid file descriptor
+        let queue = unsafe { SafeDescriptor::from_raw_descriptor(raw_queue) };
+        set_descriptor_cloexec(&queue)?;
+        Ok(Kqueue { queue })
+    }
+
+    pub(in crate::sys::macos) fn kevent<'a>(
+        &self,
+        changelist: &[libc::kevent64_s],
+        eventlist: &'a mut [libc::kevent64_s],
+        timeout: Option<Duration>,
+    ) -> Result<&'a mut [libc::kevent64_s]> {
+        let timespec = timeout.map(duration_to_timespec);
+        // SAFETY: `queue` is a valid kqueue, `changelist` and `eventlist` are supplied with lengths
+        // based on valid slices
+        let res = unsafe {
+            libc::kevent64(
+                self.queue.as_raw_descriptor(),
+                changelist.as_ptr(),
+                changelist.len() as i32,
+                eventlist.as_mut_ptr(),
+                eventlist.len() as i32,
+                0,
+                if let Some(timeout) = timespec {
+                    &timeout
+                } else {
+                    ptr::null()
+                },
+            )
+        };
+        if res < 0 {
+            return errno_result();
+        }
+        let returned_events = eventlist.split_at_mut(res as usize).0;
+        for event in returned_events.iter() {
+            if event.flags & libc::EV_ERROR != 0 {
+                return Err(Error::new(event.data));
+            }
+        }
+        Ok(returned_events)
+    }
+
+    pub(in crate::sys::macos) fn try_clone(&self) -> Result<Kqueue> {
+        self.queue.try_clone().map(|queue| Kqueue { queue })
+    }
+}
+
+impl crate::AsRawDescriptor for Kqueue {
+    fn as_raw_descriptor(&self) -> RawDescriptor {
+        self.queue.as_raw_descriptor()
+    }
+}
+
+impl crate::FromRawDescriptor for Kqueue {
+    unsafe fn from_raw_descriptor(descriptor: RawDescriptor) -> Self {
+        Kqueue {
+            queue: SafeDescriptor::from_raw_descriptor(descriptor),
+        }
+    }
+}
+
+impl crate::IntoRawDescriptor for Kqueue {
+    fn into_raw_descriptor(self) -> RawDescriptor {
+        self.queue.into_raw_descriptor()
+    }
+}
+
+impl From<Kqueue> for crate::SafeDescriptor {
+    fn from(queue: Kqueue) -> Self {
+        queue.queue
+    }
+}
+
+impl From<SafeDescriptor> for Kqueue {
+    fn from(queue: SafeDescriptor) -> Self {
+        Kqueue { queue }
+    }
+}
diff --git a/base/src/sys/macos/mod.rs b/base/src/sys/macos/mod.rs
index 254cc30ed..db16a1e39 100644
--- a/base/src/sys/macos/mod.rs
+++ b/base/src/sys/macos/mod.rs
@@ -11,7 +11,9 @@ use crate::unix::Pid;
 use crate::MmapError;
 
 mod event;
+pub(in crate::sys::macos) mod kqueue;
 mod net;
+mod timer;
 
 pub(crate) use event::PlatformEvent;
 pub(in crate::sys) use libc::sendmsg;
@@ -23,10 +25,6 @@ pub fn get_cpu_affinity() -> crate::errno::Result<Vec<usize>> {
     todo!();
 }
 
-pub fn get_filesystem_type(_file: &std::fs::File) -> crate::errno::Result<i64> {
-    todo!();
-}
-
 pub fn getpid() -> Pid {
     todo!();
 }
@@ -258,34 +256,6 @@ impl crate::shm::PlatformSharedMemory for crate::SharedMemory {
     }
 }
 
-impl crate::Timer {
-    pub fn new() -> crate::errno::Result<crate::Timer> {
-        todo!();
-    }
-}
-
-impl crate::TimerTrait for crate::Timer {
-    fn reset(
-        &mut self,
-        _dur: std::time::Duration,
-        mut _interval: Option<std::time::Duration>,
-    ) -> crate::errno::Result<()> {
-        todo!();
-    }
-    fn wait(&mut self) -> crate::errno::Result<()> {
-        todo!();
-    }
-    fn mark_waited(&mut self) -> crate::errno::Result<bool> {
-        todo!();
-    }
-    fn clear(&mut self) -> crate::errno::Result<()> {
-        todo!();
-    }
-    fn resolution(&self) -> crate::errno::Result<std::time::Duration> {
-        todo!();
-    }
-}
-
 pub(crate) use libc::off_t;
 pub(crate) use libc::pread;
 pub(crate) use libc::preadv;
diff --git a/base/src/sys/macos/timer.rs b/base/src/sys/macos/timer.rs
new file mode 100644
index 000000000..6c46fcc31
--- /dev/null
+++ b/base/src/sys/macos/timer.rs
@@ -0,0 +1,89 @@
+// Copyright 2023 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::mem;
+use std::time::Duration;
+
+use crate::errno::errno_result;
+use crate::errno::Error;
+use crate::errno::Result;
+use crate::sys::macos::kqueue::make_kevent;
+use crate::sys::macos::kqueue::Kqueue;
+use crate::sys::unix::clone_descriptor;
+use crate::SafeDescriptor;
+use crate::Timer;
+
+impl Timer {
+    pub fn new() -> Result<Timer> {
+        Ok(Timer {
+            handle: SafeDescriptor::from(Kqueue::new()?),
+            interval: None,
+        })
+    }
+
+    fn queue(&self) -> Result<Kqueue> {
+        Ok(Kqueue::from(clone_descriptor(&self.handle)?))
+    }
+}
+
+impl crate::TimerTrait for Timer {
+    fn reset_oneshot(&mut self, delay: Duration) -> Result<()> {
+        self.interval = None;
+        let mut event = make_kevent(
+            libc::EVFILT_TIMER,
+            libc::EV_ADD | libc::EV_ONESHOT,
+            libc::NOTE_NSECONDS,
+        );
+        event.data = delay
+            .as_nanos()
+            .try_into()
+            .map_err(|_| Error::new(libc::EINVAL))?;
+        self.queue()?.kevent(&[event], &mut [], None)?;
+        Ok(())
+    }
+
+    fn reset_repeating(&mut self, interval: Duration) -> Result<()> {
+        self.interval = Some(interval);
+        let mut event = make_kevent(libc::EVFILT_TIMER, libc::EV_ADD, libc::NOTE_NSECONDS);
+        event.data = interval
+            .as_nanos()
+            .try_into()
+            .map_err(|_| Error::new(libc::EINVAL))?;
+        self.queue()?.kevent(&[event], &mut [], None)?;
+        Ok(())
+    }
+
+    fn wait(&mut self) -> Result<()> {
+        let mut event = [make_kevent(0, 0, 0)];
+        self.queue()?.kevent(&[], &mut event[..], None)?;
+        Ok(())
+    }
+
+    fn mark_waited(&mut self) -> Result<bool> {
+        // Timers cannot be tested without consuming the event
+        Ok(false)
+    }
+
+    fn clear(&mut self) -> Result<()> {
+        let delete = make_kevent(libc::EVFILT_TIMER, libc::EV_DELETE, 0);
+        self.queue()?.kevent(&[delete], &mut [], None)?;
+        Ok(())
+    }
+
+    fn resolution(&self) -> Result<Duration> {
+        // SAFETY:
+        // Safe because we are zero-initializing a struct with only primitive member fields.
+        let mut res: libc::timespec = unsafe { mem::zeroed() };
+
+        // SAFETY:
+        // Safe because it only modifies a local struct and we check the return value.
+        let ret = unsafe { libc::clock_getres(libc::CLOCK_MONOTONIC, &mut res) };
+
+        if ret != 0 {
+            return errno_result();
+        }
+
+        Ok(Duration::new(res.tv_sec as u64, res.tv_nsec as u32))
+    }
+}
diff --git a/base/src/sys/unix/file_traits.rs b/base/src/sys/unix/file_traits.rs
index f250805f4..608bf64de 100644
--- a/base/src/sys/unix/file_traits.rs
+++ b/base/src/sys/unix/file_traits.rs
@@ -130,7 +130,7 @@ macro_rules! volatile_at_impl {
     ($ty:ty) => {
         impl FileReadWriteAtVolatile for $ty {
             fn read_at_volatile(
-                &mut self,
+                &self,
                 slice: $crate::VolatileSlice,
                 offset: u64,
             ) -> std::io::Result<usize> {
@@ -154,7 +154,7 @@ macro_rules! volatile_at_impl {
             }
 
             fn read_vectored_at_volatile(
-                &mut self,
+                &self,
                 bufs: &[$crate::VolatileSlice],
                 offset: u64,
             ) -> std::io::Result<usize> {
@@ -184,7 +184,7 @@ macro_rules! volatile_at_impl {
             }
 
             fn write_at_volatile(
-                &mut self,
+                &self,
                 slice: $crate::VolatileSlice,
                 offset: u64,
             ) -> std::io::Result<usize> {
@@ -208,7 +208,7 @@ macro_rules! volatile_at_impl {
             }
 
             fn write_vectored_at_volatile(
-                &mut self,
+                &self,
                 bufs: &[$crate::VolatileSlice],
                 offset: u64,
             ) -> std::io::Result<usize> {
diff --git a/base/src/sys/unix/net.rs b/base/src/sys/unix/net.rs
index 1afa36649..0f0f1e93a 100644
--- a/base/src/sys/unix/net.rs
+++ b/base/src/sys/unix/net.rs
@@ -18,6 +18,7 @@ use std::net::TcpListener;
 use std::net::TcpStream;
 use std::net::ToSocketAddrs;
 use std::ops::Deref;
+use std::os::fd::OwnedFd;
 use std::os::unix::ffi::OsStringExt;
 use std::path::Path;
 use std::path::PathBuf;
@@ -744,6 +745,12 @@ impl AsRawDescriptor for UnixSeqpacketListener {
     }
 }
 
+impl From<UnixSeqpacketListener> for OwnedFd {
+    fn from(val: UnixSeqpacketListener) -> Self {
+        val.descriptor.into()
+    }
+}
+
 /// Used to attempt to clean up a `UnixSeqpacketListener` after it is dropped.
 pub struct UnlinkUnixSeqpacketListener(pub UnixSeqpacketListener);
 
diff --git a/base/src/sys/unix/sock_ctrl_msg.rs b/base/src/sys/unix/sock_ctrl_msg.rs
index ce2630b8c..1586ab2c1 100644
--- a/base/src/sys/unix/sock_ctrl_msg.rs
+++ b/base/src/sys/unix/sock_ctrl_msg.rs
@@ -29,6 +29,7 @@ use libc::SOL_SOCKET;
 use serde::Deserialize;
 use serde::Serialize;
 
+use crate::error;
 use crate::sys::sendmsg;
 use crate::AsRawDescriptor;
 use crate::FromRawDescriptor;
@@ -37,6 +38,9 @@ use crate::RawDescriptor;
 use crate::SafeDescriptor;
 use crate::VolatileSlice;
 
+// Linux kernel limits the max number of file descriptors to be sent at once.
+pub const SCM_MAX_FD: usize = 253;
+
 // Each of the following functions performs the same function as their C counterparts. They are
 // reimplemented as const fns here because they are used to size statically allocated arrays.
 
@@ -123,6 +127,14 @@ impl CmsgBuffer {
 // that is unnecessary when compiling for glibc.
 #[allow(clippy::useless_conversion)]
 fn raw_sendmsg(fd: RawFd, iovec: &[iovec], out_fds: &[RawFd]) -> io::Result<usize> {
+    if out_fds.len() > SCM_MAX_FD {
+        error!(
+            "too many fds to send: {} > SCM_MAX_FD (SCM_MAX_FD)",
+            out_fds.len()
+        );
+        return Err(io::Error::from(io::ErrorKind::InvalidInput));
+    }
+
     let cmsg_capacity = CMSG_SPACE(size_of_val(out_fds));
     let mut cmsg_buffer = CmsgBuffer::with_capacity(cmsg_capacity);
 
@@ -182,6 +194,11 @@ fn raw_recvmsg(
     iovs: &mut [iovec],
     max_fds: usize,
 ) -> io::Result<(usize, Vec<SafeDescriptor>)> {
+    if max_fds > SCM_MAX_FD {
+        error!("too many fds to recieve: {max_fds} > SCM_MAX_FD (SCM_MAX_FD)");
+        return Err(io::Error::from(io::ErrorKind::InvalidInput));
+    }
+
     let cmsg_capacity = CMSG_SPACE(max_fds * size_of::<RawFd>());
     let mut cmsg_buffer = CmsgBuffer::with_capacity(cmsg_capacity);
 
diff --git a/base/src/sys/unix/tube.rs b/base/src/sys/unix/tube.rs
index ce7deb253..6c8e655c3 100644
--- a/base/src/sys/unix/tube.rs
+++ b/base/src/sys/unix/tube.rs
@@ -25,6 +25,7 @@ use crate::ReadNotifier;
 use crate::ScmSocket;
 use crate::StreamChannel;
 use crate::UnixSeqpacket;
+use crate::SCM_SOCKET_MAX_FD_COUNT;
 
 // This size matches the inline buffer size of CmsgBuffer.
 const TUBE_MAX_FDS: usize = 32;
@@ -79,12 +80,24 @@ impl Tube {
             .map_err(Error::Clone)?
     }
 
+    /// Sends a message via a Tube.
+    /// The number of file descriptors that this method can send is limited to `TUBE_MAX_FDS`.
+    /// If you want to send more descriptors, use `send_with_max_fds` instead.
     pub fn send<T: Serialize>(&self, msg: &T) -> Result<()> {
+        self.send_with_max_fds(msg, TUBE_MAX_FDS)
+    }
+
+    /// Sends a message with at most `max_fds` file descriptors via a Tube.
+    /// Note that `max_fds` must not exceed `SCM_SOCKET_MAX_FD_COUNT` (= 253).
+    pub fn send_with_max_fds<T: Serialize>(&self, msg: &T, max_fds: usize) -> Result<()> {
+        if max_fds > SCM_SOCKET_MAX_FD_COUNT {
+            return Err(Error::SendTooManyFds);
+        }
         let msg_serialize = SerializeDescriptors::new(&msg);
         let msg_json = serde_json::to_vec(&msg_serialize).map_err(Error::Json)?;
         let msg_descriptors = msg_serialize.into_descriptors();
 
-        if msg_descriptors.len() > TUBE_MAX_FDS {
+        if msg_descriptors.len() > max_fds {
             return Err(Error::SendTooManyFds);
         }
 
@@ -93,7 +106,23 @@ impl Tube {
         Ok(())
     }
 
+    /// Recieves a message from a Tube.
+    /// If the sender sent file descriptors more than TUBE_MAX_FDS with `send_with_max_fds`, use
+    /// `recv_with_max_fds` instead.
     pub fn recv<T: DeserializeOwned>(&self) -> Result<T> {
+        self.recv_with_max_fds(TUBE_MAX_FDS)
+    }
+
+    /// Recieves a message with at most `max_fds` file descriptors from a Tube.
+    pub fn recv_with_max_fds<T: DeserializeOwned>(&self, max_fds: usize) -> Result<T> {
+        if max_fds > SCM_SOCKET_MAX_FD_COUNT {
+            return Err(Error::RecvTooManyFds);
+        }
+
+        // WARNING: The `cros_async` and `base_tokio` tube wrappers both assume that, if the tube
+        // is readable, then a call to `Tube::recv` will not block (which ought to be true since we
+        // use SOCK_SEQPACKET and a single recvmsg call currently).
+
         let msg_size = handle_eintr!(self.socket.inner().peek_size()).map_err(Error::Recv)?;
         // This buffer is the right size, as the size received in peek_size() represents the size
         // of only the message itself and not the file descriptors. The descriptors are stored
@@ -101,7 +130,7 @@ impl Tube {
         let mut msg_json = vec![0u8; msg_size];
 
         let (msg_json_size, msg_descriptors) =
-            handle_eintr!(self.socket.recv_with_fds(&mut msg_json, TUBE_MAX_FDS))
+            handle_eintr!(self.socket.recv_with_fds(&mut msg_json, max_fds))
                 .map_err(Error::Recv)?;
 
         if msg_json_size == 0 {
diff --git a/cros_async/src/sys/windows/wait_for_handle.rs b/base/src/sys/windows/async_wait_for_single_object.rs
similarity index 73%
rename from cros_async/src/sys/windows/wait_for_handle.rs
rename to base/src/sys/windows/async_wait_for_single_object.rs
index e0afa642d..c4ea3d242 100644
--- a/cros_async/src/sys/windows/wait_for_handle.rs
+++ b/base/src/sys/windows/async_wait_for_single_object.rs
@@ -1,9 +1,12 @@
-// Copyright 2021 The ChromiumOS Authors
+// Copyright 2024 The ChromiumOS Authors
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
 use std::ffi::c_void;
 use std::future::Future;
+use std::io::Error;
+use std::io::ErrorKind;
+use std::io::Result;
 use std::marker::PhantomData;
 use std::marker::PhantomPinned;
 use std::pin::Pin;
@@ -13,10 +16,6 @@ use std::task::Context;
 use std::task::Poll;
 use std::task::Waker;
 
-use base::error;
-use base::warn;
-use base::AsRawDescriptor;
-use base::Descriptor;
 use sync::Mutex;
 use winapi::shared::ntdef::FALSE;
 use winapi::um::handleapi::INVALID_HANDLE_VALUE;
@@ -27,8 +26,19 @@ use winapi::um::winnt::BOOLEAN;
 use winapi::um::winnt::PVOID;
 use winapi::um::winnt::WT_EXECUTEONLYONCE;
 
-use crate::sys::windows::handle_source::Error;
-use crate::sys::windows::handle_source::Result;
+use crate::error;
+use crate::warn;
+use crate::AsRawDescriptor;
+use crate::Descriptor;
+
+/// Async wrapper around `RegisterWaitForSingleObject`. See the official documentation of that
+/// function for a list of supported object types.
+///
+/// The implementation is not tied to any specific async runtime. `Waker::wake` gets invoked from
+/// an OS maintained thread pool when the object becomes readable.
+pub async fn async_wait_for_single_object(source: &impl AsRawDescriptor) -> Result<()> {
+    WaitForHandle::new(source).await
+}
 
 /// Inner state shared between the future struct & the kernel invoked waiter callback.
 struct WaitForHandleInner {
@@ -57,8 +67,7 @@ enum WaitState {
     Failed,
 }
 
-/// Waits for an object with a handle to be readable.
-pub struct WaitForHandle<'a, T: AsRawDescriptor> {
+struct WaitForHandle<'a, T: AsRawDescriptor> {
     handle: Descriptor,
     inner: Mutex<WaitForHandleInner>,
     _marker: PhantomData<&'a T>,
@@ -69,7 +78,7 @@ impl<'a, T> WaitForHandle<'a, T>
 where
     T: AsRawDescriptor,
 {
-    pub fn new(source: &'a T) -> WaitForHandle<'a, T> {
+    fn new(source: &'a T) -> WaitForHandle<'a, T> {
         WaitForHandle {
             handle: Descriptor(source.as_raw_descriptor()),
             inner: Mutex::new(WaitForHandleInner::new()),
@@ -106,7 +115,7 @@ where
                     )
                 };
                 if err == 0 {
-                    return Poll::Ready(Err(Error::HandleWaitFailed(base::Error::last())));
+                    return Poll::Ready(Err(Error::last_os_error()));
                 }
 
                 inner.wait_state = WaitState::Sleeping;
@@ -138,7 +147,9 @@ where
 
                 Poll::Ready(Ok(()))
             }
-            WaitState::Aborted => Poll::Ready(Err(Error::OperationAborted)),
+            WaitState::Aborted => {
+                Poll::Ready(Err(Error::new(ErrorKind::Other, "operation aborted")))
+            }
             WaitState::Finished => panic!("polled an already completed WaitForHandle future."),
             WaitState::Failed => {
                 panic!("WaitForHandle future's waiter callback hit unexpected behavior.")
@@ -237,77 +248,79 @@ unsafe fn unregister_wait(desc: Descriptor) {
     if UnregisterWaitEx(desc.0, INVALID_HANDLE_VALUE) == 0 {
         warn!(
             "WaitForHandle: failed to clean up RegisterWaitForSingleObject wait handle: {}",
-            base::Error::last()
+            Error::last_os_error()
         )
     }
 }
 
 #[cfg(test)]
 mod tests {
+    use std::sync::mpsc;
     use std::sync::Arc;
-    use std::sync::Weak;
     use std::time::Duration;
 
-    use base::thread::spawn_with_timeout;
-    use base::Event;
-    use futures::pin_mut;
-
     use super::*;
-    use crate::waker::new_waker;
-    use crate::waker::WeakWake;
-    use crate::EventAsync;
-    use crate::Executor;
+    use crate::Event;
+
+    struct SimpleWaker {
+        wake_tx: mpsc::Sender<()>,
+    }
 
-    struct FakeWaker {}
-    impl WeakWake for FakeWaker {
-        fn wake_by_ref(_weak_self: &Weak<Self>) {
-            // Do nothing.
+    impl futures::task::ArcWake for SimpleWaker {
+        fn wake_by_ref(arc_self: &Arc<Self>) {
+            let _ = arc_self.wake_tx.send(());
         }
     }
 
     #[test]
     fn test_unsignaled_event() {
-        async fn wait_on_unsignaled_event(evt: EventAsync) {
-            evt.next_val().await.unwrap();
-            panic!("await should never terminate");
-        }
-
-        let fake_waker = Arc::new(FakeWaker {});
-        let waker = new_waker(Arc::downgrade(&fake_waker));
+        let (wake_tx, _wake_rx) = mpsc::channel();
+        let waker = futures::task::waker(Arc::new(SimpleWaker { wake_tx }));
         let mut cx = Context::from_waker(&waker);
 
-        let ex = Executor::new().unwrap();
         let evt = Event::new().unwrap();
-        let async_evt = EventAsync::new(evt, &ex).unwrap();
-
-        let fut = wait_on_unsignaled_event(async_evt);
-        pin_mut!(fut);
-
+        let mut fut = std::pin::pin!(async { async_wait_for_single_object(&evt).await.unwrap() });
         // Assert we make it to the pending state. This means we've registered a wait.
-        assert_eq!(fut.poll(&mut cx), Poll::Pending);
+        assert_eq!(fut.as_mut().poll(&mut cx), Poll::Pending);
 
         // If this test doesn't crash trying to drop the future, it is considered successful.
     }
 
     #[test]
     fn test_signaled_event() {
-        let join_handle = spawn_with_timeout(|| {
-            async fn wait_on_signaled_event(evt: EventAsync) {
-                evt.next_val().await.unwrap();
-            }
+        let (wake_tx, wake_rx) = mpsc::channel();
+        let waker = futures::task::waker(Arc::new(SimpleWaker { wake_tx }));
+        let mut cx = Context::from_waker(&waker);
 
-            let ex = Executor::new().unwrap();
-            let evt = Event::new().unwrap();
-            evt.signal().unwrap();
-            let async_evt = EventAsync::new(evt, &ex).unwrap();
+        let evt = Event::new().unwrap();
+        let mut fut = std::pin::pin!(async { async_wait_for_single_object(&evt).await.unwrap() });
+        // Should be pending.
+        assert_eq!(fut.as_mut().poll(&mut cx), Poll::Pending);
+        // Should still be pending.
+        assert_eq!(fut.as_mut().poll(&mut cx), Poll::Pending);
+        // Signal, wait for wake, then the future should be ready.
+        evt.signal().unwrap();
+        wake_rx
+            .recv_timeout(Duration::from_secs(5))
+            .expect("timeout waiting for wake");
+        assert_eq!(fut.as_mut().poll(&mut cx), Poll::Ready(()));
+    }
 
-            let fut = wait_on_signaled_event(async_evt);
-            pin_mut!(fut);
+    #[test]
+    fn test_already_signaled_event() {
+        let (wake_tx, wake_rx) = mpsc::channel();
+        let waker = futures::task::waker(Arc::new(SimpleWaker { wake_tx }));
+        let mut cx = Context::from_waker(&waker);
 
-            ex.run_until(fut).unwrap();
-        });
-        join_handle
-            .try_join(Duration::from_secs(5))
-            .expect("async wait never returned from signaled event.");
+        let evt = Event::new().unwrap();
+        evt.signal().unwrap();
+        let mut fut = std::pin::pin!(async { async_wait_for_single_object(&evt).await.unwrap() });
+        // First call is always pending and registers the wait.
+        assert_eq!(fut.as_mut().poll(&mut cx), Poll::Pending);
+        // Wait for wake, then the future should be ready.
+        wake_rx
+            .recv_timeout(Duration::from_secs(5))
+            .expect("timeout waiting for wake");
+        assert_eq!(fut.as_mut().poll(&mut cx), Poll::Ready(()));
     }
 }
diff --git a/base/src/sys/windows/file_traits.rs b/base/src/sys/windows/file_traits.rs
index 3e9cdc689..645f42767 100644
--- a/base/src/sys/windows/file_traits.rs
+++ b/base/src/sys/windows/file_traits.rs
@@ -99,7 +99,7 @@ impl FileReadWriteVolatile for File {
 }
 
 impl FileReadWriteAtVolatile for File {
-    fn read_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<usize> {
+    fn read_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize> {
         // The unix implementation uses pread, which doesn't modify the file
         // pointer. Windows doesn't have an option for that, unfortunately.
 
@@ -129,7 +129,7 @@ impl FileReadWriteAtVolatile for File {
         }
     }
 
-    fn read_vectored_at_volatile(&mut self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+    fn read_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
         if bufs.is_empty() {
             return Ok(0);
         }
@@ -148,7 +148,7 @@ impl FileReadWriteAtVolatile for File {
         Ok(ret)
     }
 
-    fn write_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> Result<usize> {
+    fn write_at_volatile(&self, slice: VolatileSlice, offset: u64) -> Result<usize> {
         // The unix implementation uses pwrite, which doesn't modify the file
         // pointer. Windows doesn't have an option for that, unfortunately.
 
@@ -178,7 +178,7 @@ impl FileReadWriteAtVolatile for File {
         }
     }
 
-    fn write_vectored_at_volatile(&mut self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
+    fn write_vectored_at_volatile(&self, bufs: &[VolatileSlice], offset: u64) -> Result<usize> {
         if bufs.is_empty() {
             return Ok(0);
         }
@@ -200,7 +200,7 @@ impl FileReadWriteAtVolatile for File {
 }
 
 impl FileAllocate for File {
-    fn allocate(&mut self, offset: u64, len: u64) -> Result<()> {
+    fn allocate(&self, offset: u64, len: u64) -> Result<()> {
         // The Windows equivalent of fallocate's default mode (allocate a zeroed block of space in a
         // file) is to just call write_zeros_at. There are not, at the time of writing, any syscalls
         // that will extend the file and zero the range while maintaining the disk allocation in a
diff --git a/base/src/sys/windows/file_util.rs b/base/src/sys/windows/file_util.rs
index f4a61b260..786c7eddb 100644
--- a/base/src/sys/windows/file_util.rs
+++ b/base/src/sys/windows/file_util.rs
@@ -31,14 +31,12 @@ pub fn open_file_or_duplicate<P: AsRef<Path>>(path: P, options: &OpenOptions) ->
 
 /// Marks the given file as sparse. Required if we want hole punching to be performant.
 /// (If a file is not marked as sparse, a hole punch will just write zeros.)
-/// # Safety
-///    handle *must* be File. We accept all AsRawDescriptors for convenience.
-pub fn set_sparse_file<T: AsRawDescriptor>(handle: &T) -> io::Result<()> {
+pub fn set_sparse_file(file: &File) -> io::Result<()> {
     // SAFETY:
     // Safe because we check the return value and handle is guaranteed to be a
     // valid file handle by the caller.
     let result = unsafe {
-        super::ioctl::ioctl_with_ptr(handle, FSCTL_SET_SPARSE, std::ptr::null_mut::<c_void>())
+        super::ioctl::ioctl_with_ptr(file, FSCTL_SET_SPARSE, std::ptr::null_mut::<c_void>())
     };
     if result != 0 {
         return Err(io::Error::from_raw_os_error(result));
diff --git a/base/src/sys/windows/get_filesystem_type.rs b/base/src/sys/windows/get_filesystem_type.rs
deleted file mode 100644
index 50b1d78af..000000000
--- a/base/src/sys/windows/get_filesystem_type.rs
+++ /dev/null
@@ -1,12 +0,0 @@
-// Copyright 2022 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-use std::fs::File;
-
-use super::Result;
-
-pub fn get_filesystem_type(_file: &File) -> Result<i64> {
-    // TODO (b/203574110): create a windows equivalent to get the filesystem type like fstatfs
-    Ok(0)
-}
diff --git a/base/src/sys/windows/ioctl.rs b/base/src/sys/windows/ioctl.rs
index 8591f77ba..521cf39c1 100644
--- a/base/src/sys/windows/ioctl.rs
+++ b/base/src/sys/windows/ioctl.rs
@@ -12,7 +12,6 @@ use std::ptr::null_mut;
 
 use winapi::um::errhandlingapi::GetLastError;
 use winapi::um::ioapiset::DeviceIoControl;
-pub use winapi::um::winioctl::CTL_CODE;
 pub use winapi::um::winioctl::FILE_ANY_ACCESS;
 pub use winapi::um::winioctl::METHOD_BUFFERED;
 
@@ -29,7 +28,7 @@ macro_rules! device_io_control_expr {
     //  just use that for now. However, we may need to support more
     //  options later.
     ($dtype:expr, $code:expr) => {
-        $crate::windows::CTL_CODE(
+        $crate::windows::ctl_code(
             $dtype,
             $code,
             $crate::windows::METHOD_BUFFERED,
@@ -43,9 +42,7 @@ macro_rules! device_io_control_expr {
 macro_rules! ioctl_ioc_nr {
     ($name:ident, $dtype:expr, $code:expr) => {
         #[allow(non_snake_case)]
-        pub fn $name() -> ::std::os::raw::c_ulong {
-            $crate::device_io_control_expr!($dtype, $code)
-        }
+        pub const $name: ::std::os::raw::c_ulong = $crate::device_io_control_expr!($dtype, $code);
     };
     ($name:ident, $dtype:expr, $code:expr, $($v:ident),+) => {
         #[allow(non_snake_case)]
@@ -128,6 +125,14 @@ macro_rules! ioctl_iowr_nr {
 
 pub type IoctlNr = c_ulong;
 
+/// Constructs an I/O control code.
+///
+/// Shifts control code components into the appropriate bitfield locations:
+/// <https://learn.microsoft.com/en-us/windows-hardware/drivers/kernel/defining-i-o-control-codes>
+pub const fn ctl_code(device_type: u32, function: u32, method: u32, access: u32) -> IoctlNr {
+    (device_type << 16) | (access << 14) | (function << 2) | method
+}
+
 /// Run an ioctl with no arguments.
 // (colindr) b/144457461 : This will probably not be used on windows.
 // It's only used on linux for the ioctls that override the exit code to
@@ -365,7 +370,7 @@ mod tests {
         // open our random file and write "foo" in it
         let mut f = OpenOptions::new()
             .write(true)
-            .create(true)
+            .create_new(true)
             .open(file_path)
             .unwrap();
         f.write_all(b"foo").expect("Failed to write bytes.");
@@ -449,7 +454,7 @@ mod tests {
         // open our random file and write "foo" in it
         let mut f = OpenOptions::new()
             .write(true)
-            .create(true)
+            .create_new(true)
             .open(file_path)
             .unwrap();
         f.write_all(b"foo").expect("Failed to write bytes.");
diff --git a/base/src/sys/windows/mmap.rs b/base/src/sys/windows/mmap.rs
index 236e680ff..ff0b4cfc1 100644
--- a/base/src/sys/windows/mmap.rs
+++ b/base/src/sys/windows/mmap.rs
@@ -297,11 +297,11 @@ mod tests {
     fn slice_overflow_error() {
         let shm = SharedMemory::new("test", 1028).unwrap();
         let m = to_crate_mmap(MemoryMapping::from_descriptor(&shm, 5).unwrap());
-        let res = m.get_slice(std::usize::MAX, 3).unwrap_err();
+        let res = m.get_slice(usize::MAX, 3).unwrap_err();
         assert_eq!(
             res,
             VolatileMemoryError::Overflow {
-                base: std::usize::MAX,
+                base: usize::MAX,
                 offset: 3,
             }
         );
diff --git a/base/src/sys/windows/mmap_platform.rs b/base/src/sys/windows/mmap_platform.rs
index 3e6eee3b1..565a10fed 100644
--- a/base/src/sys/windows/mmap_platform.rs
+++ b/base/src/sys/windows/mmap_platform.rs
@@ -165,8 +165,7 @@ impl MemoryMapping {
 
         // on windows, pages needed to be of fixed granular size, and the
         // maximum valid value is an i64.
-        if file_handle.1 % allocation_granularity() != 0 || file_handle.1 > i64::max_value() as u64
-        {
+        if file_handle.1 % allocation_granularity() != 0 || file_handle.1 > i64::MAX as u64 {
             return Err(Error::InvalidOffset);
         }
 
@@ -266,7 +265,7 @@ mod tests {
         let shm = SharedMemory::new("test", 1028).unwrap();
         let res = MemoryMappingBuilder::new(4096)
             .from_shared_memory(&shm)
-            .offset((i64::max_value() as u64) + 1)
+            .offset((i64::MAX as u64) + 1)
             .build()
             .unwrap_err();
         match res {
diff --git a/base/src/sys/windows/mod.rs b/base/src/sys/windows/mod.rs
index 1a1495c81..b1181c7f9 100644
--- a/base/src/sys/windows/mod.rs
+++ b/base/src/sys/windows/mod.rs
@@ -10,6 +10,7 @@
 pub mod ioctl;
 #[macro_use]
 pub mod syslog;
+mod async_wait_for_single_object;
 mod console;
 mod descriptor;
 mod event;
@@ -17,7 +18,6 @@ mod events;
 pub mod file_traits;
 mod file_util;
 mod foreground_window;
-mod get_filesystem_type;
 mod iobuf;
 mod mmap;
 mod mmap_platform;
@@ -42,6 +42,7 @@ pub mod thread;
 
 mod write_zeroes;
 
+pub use async_wait_for_single_object::async_wait_for_single_object;
 pub use console::*;
 pub use descriptor::*;
 pub use event::*;
@@ -50,7 +51,6 @@ pub use file_util::get_allocated_ranges;
 pub use file_util::open_file_or_duplicate;
 pub use file_util::set_sparse_file;
 pub use foreground_window::give_foregrounding_permission;
-pub use get_filesystem_type::*;
 pub use iobuf::IoBuf;
 pub use ioctl::*;
 pub use mmap::*;
@@ -65,7 +65,6 @@ pub use system_info::getpid;
 pub use system_info::number_of_logical_cores;
 pub use system_info::pagesize;
 pub use terminal::*;
-pub use timer::*;
 use winapi::shared::minwindef::DWORD;
 pub(crate) use write_zeroes::file_write_zeroes_at;
 
diff --git a/base/src/sys/windows/named_pipes.rs b/base/src/sys/windows/named_pipes.rs
index 78dfc019d..a18b3a957 100644
--- a/base/src/sys/windows/named_pipes.rs
+++ b/base/src/sys/windows/named_pipes.rs
@@ -25,6 +25,7 @@ use win_util::SelfRelativeSecurityDescriptor;
 use winapi::shared::minwindef::DWORD;
 use winapi::shared::minwindef::FALSE;
 use winapi::shared::minwindef::TRUE;
+use winapi::shared::winerror::ERROR_BROKEN_PIPE;
 use winapi::shared::winerror::ERROR_IO_INCOMPLETE;
 use winapi::shared::winerror::ERROR_IO_PENDING;
 use winapi::shared::winerror::ERROR_MORE_DATA;
@@ -588,6 +589,9 @@ impl PipeConnection {
         );
         match res {
             Ok(bytes_read) => Ok(bytes_read),
+            // Treat a closed pipe like an EOF.
+            // We check the raw error because `ErrorKind::BrokenPipe` is ambiguous on Windows.
+            Err(e) if e.raw_os_error() == Some(ERROR_BROKEN_PIPE as i32) => Ok(0),
             Err(e)
                 if blocking_mode == BlockingMode::NoWait
                     && e.raw_os_error() == Some(ERROR_NO_DATA as i32) =>
@@ -1632,4 +1636,30 @@ mod tests {
         exit_event.signal().unwrap();
         server.try_join(Duration::from_secs(10)).unwrap();
     }
+
+    #[test]
+    fn std_io_read_eof() {
+        let (mut w, mut r) = pair(&FramingMode::Byte, &BlockingMode::Wait, 0).unwrap();
+        std::io::Write::write(&mut w, &[1, 2, 3]).unwrap();
+        std::mem::drop(w);
+
+        let mut buffer: [u8; 4] = [0; 4];
+        assert_eq!(std::io::Read::read(&mut r, &mut buffer).unwrap(), 3);
+        assert_eq!(buffer, [1, 2, 3, 0]);
+        assert_eq!(std::io::Read::read(&mut r, &mut buffer).unwrap(), 0);
+        assert_eq!(std::io::Read::read(&mut r, &mut buffer).unwrap(), 0);
+    }
+
+    #[test]
+    fn std_io_write_eof() {
+        let (mut w, r) = pair(&FramingMode::Byte, &BlockingMode::Wait, 0).unwrap();
+        std::mem::drop(r);
+        let result = std::io::Write::write(&mut w, &[1, 2, 3]);
+        // Not required to return BrokenPipe here, something like Ok(0) is also acceptable.
+        assert!(
+            result.is_err()
+                && result.as_ref().unwrap_err().kind() == std::io::ErrorKind::BrokenPipe,
+            "expected Err(BrokenPipe), got {result:?}"
+        );
+    }
 }
diff --git a/base/src/sys/windows/read_write_wrappers.rs b/base/src/sys/windows/read_write_wrappers.rs
index e4edb4b18..2940d8b36 100644
--- a/base/src/sys/windows/read_write_wrappers.rs
+++ b/base/src/sys/windows/read_write_wrappers.rs
@@ -154,7 +154,6 @@ pub fn read_overlapped_blocking(
 mod tests {
     use std::fs::File;
     use std::fs::OpenOptions;
-    use std::io::Write;
     use std::os::windows::fs::OpenOptionsExt;
     use std::path::PathBuf;
 
@@ -171,7 +170,6 @@ mod tests {
 
     fn open_overlapped(path: &PathBuf) -> File {
         OpenOptions::new()
-            .create(true)
             .read(true)
             .write(true)
             .custom_flags(FILE_FLAG_OVERLAPPED)
@@ -179,23 +177,11 @@ mod tests {
             .unwrap()
     }
 
-    fn open_blocking(path: &PathBuf) -> File {
-        OpenOptions::new()
-            .create(true)
-            .read(true)
-            .write(true)
-            .open(path)
-            .unwrap()
-    }
-
     #[test]
     fn test_read_overlapped() {
         let (file_path, _tmpdir) = tempfile_path();
-        let mut f = open_blocking(&file_path);
         let data: [u8; 6] = [0, 1, 2, 3, 5, 6];
-        f.write_all(&data).unwrap();
-        f.flush().unwrap();
-        drop(f);
+        std::fs::write(&file_path, data).unwrap();
 
         let of = open_overlapped(&file_path);
         let mut buf: [u8; 3] = [0; 3];
diff --git a/base/src/sys/windows/stream_channel.rs b/base/src/sys/windows/stream_channel.rs
index 0ea5394b8..3587578b5 100644
--- a/base/src/sys/windows/stream_channel.rs
+++ b/base/src/sys/windows/stream_channel.rs
@@ -2,7 +2,6 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-use std::cell::RefCell;
 use std::io;
 use std::sync::Arc;
 
@@ -101,8 +100,8 @@ pub struct StreamChannel {
     // signal the channel has been closed when it was dropped, because a copy of it was sent to
     // another process. It is the copy's responsibility to close the pipe.
     #[serde(skip)]
-    #[serde(default = "create_true_cell")]
-    is_channel_closed_on_drop: RefCell<bool>,
+    #[serde(default = "create_true_mutex")]
+    is_channel_closed_on_drop: Mutex<bool>,
 
     // For StreamChannels created via pair_with_buffer_size, allows the channel to accept messages
     // up to that size.
@@ -113,8 +112,8 @@ fn create_read_lock() -> Arc<Mutex<()>> {
     Arc::new(Mutex::new(()))
 }
 
-fn create_true_cell() -> RefCell<bool> {
-    RefCell::new(true)
+fn create_true_mutex() -> Mutex<bool> {
+    Mutex::new(true)
 }
 
 /// Serialize is manually implemented because we need to tell the local copy that a remote copy
@@ -138,7 +137,7 @@ impl Serialize for StreamChannel {
         // Because this end has been serialized, the serialized copy is now responsible for setting
         // the close event.
         if ret.is_ok() {
-            *self.is_channel_closed_on_drop.borrow_mut() = false;
+            *self.is_channel_closed_on_drop.lock() = false;
         }
 
         ret
@@ -147,7 +146,7 @@ impl Serialize for StreamChannel {
 
 impl Drop for StreamChannel {
     fn drop(&mut self) {
-        if *self.is_channel_closed_on_drop.borrow() {
+        if *self.is_channel_closed_on_drop.lock() {
             if let Err(e) = self.pipe_closed.signal() {
                 warn!("failed to notify on channel drop: {}", e);
             }
@@ -178,7 +177,7 @@ impl StreamChannel {
             remote_write_lock: self.remote_write_lock.try_clone()?,
             local_write_lock: self.local_write_lock.try_clone()?,
             read_lock: self.read_lock.clone(),
-            is_channel_closed_on_drop: create_true_cell(),
+            is_channel_closed_on_drop: create_true_mutex(),
             send_buffer_size: self.send_buffer_size,
         })
     }
@@ -334,7 +333,7 @@ impl StreamChannel {
             local_write_lock: write_lock_a.try_clone()?,
             remote_write_lock: write_lock_b.try_clone()?,
             pipe_closed: pipe_closed.try_clone()?,
-            is_channel_closed_on_drop: create_true_cell(),
+            is_channel_closed_on_drop: create_true_mutex(),
             send_buffer_size,
         };
         let sock_b = StreamChannel {
@@ -345,7 +344,7 @@ impl StreamChannel {
             local_write_lock: write_lock_b,
             remote_write_lock: write_lock_a,
             pipe_closed,
-            is_channel_closed_on_drop: create_true_cell(),
+            is_channel_closed_on_drop: create_true_mutex(),
             send_buffer_size,
         };
         Ok((sock_a, sock_b))
@@ -388,6 +387,14 @@ impl StreamChannel {
     pub fn flush_blocking(&self) -> io::Result<()> {
         self.pipe_conn.flush_data_blocking()
     }
+
+    pub(crate) fn get_read_notifier_event(&self) -> &Event {
+        &self.read_notify
+    }
+
+    pub(crate) fn get_close_notifier_event(&self) -> &Event {
+        &self.pipe_closed
+    }
 }
 
 impl io::Write for StreamChannel {
diff --git a/base/src/sys/windows/timer.rs b/base/src/sys/windows/timer.rs
index 0f899a36d..9d135f991 100644
--- a/base/src/sys/windows/timer.rs
+++ b/base/src/sys/windows/timer.rs
@@ -67,9 +67,7 @@ impl Timer {
             interval: None,
         })
     }
-}
 
-impl TimerTrait for Timer {
     fn reset(&mut self, dur: Duration, mut interval: Option<Duration>) -> Result<()> {
         // If interval is 0 or None it means that this timer does not repeat. We
         // set self.interval to None in this case so it can easily be checked
@@ -120,6 +118,16 @@ impl TimerTrait for Timer {
 
         Ok(())
     }
+}
+
+impl TimerTrait for Timer {
+    fn reset_oneshot(&mut self, dur: Duration) -> Result<()> {
+        self.reset(dur, None)
+    }
+
+    fn reset_repeating(&mut self, interval: Duration) -> Result<()> {
+        self.reset(interval, Some(interval))
+    }
 
     fn wait(&mut self) -> Result<()> {
         // SAFETY:
diff --git a/base/src/sys/windows/tube.rs b/base/src/sys/windows/tube.rs
index b65350837..8e9c20bee 100644
--- a/base/src/sys/windows/tube.rs
+++ b/base/src/sys/windows/tube.rs
@@ -32,6 +32,7 @@ use crate::tube::Result;
 use crate::tube::SendTube;
 use crate::BlockingMode;
 use crate::CloseNotifier;
+use crate::Event;
 use crate::EventToken;
 use crate::FramingMode;
 use crate::PipeConnection;
@@ -206,6 +207,14 @@ impl Tube {
     pub fn set_recv_timeout(&self, _timeout: Option<Duration>) -> Result<()> {
         unimplemented!("To be removed/refactored upstream.");
     }
+
+    pub fn get_read_notifier_event(&self) -> &Event {
+        self.socket.get_read_notifier_event()
+    }
+
+    pub fn get_close_notifier_event(&self) -> &Event {
+        self.socket.get_close_notifier_event()
+    }
 }
 
 pub fn serialize_and_send<T: Serialize, F: Fn(&[u8]) -> io::Result<usize>>(
@@ -522,7 +531,7 @@ impl Drop for FlushOnDropTube {
 
 impl Error {
     fn map_io_error(e: io::Error, err_ctor: fn(io::Error) -> Error) -> Error {
-        if e.kind() == io::ErrorKind::BrokenPipe {
+        if e.kind() == io::ErrorKind::UnexpectedEof || e.kind() == io::ErrorKind::BrokenPipe {
             Error::Disconnected
         } else {
             err_ctor(e)
diff --git a/base/src/sys/windows/write_zeroes.rs b/base/src/sys/windows/write_zeroes.rs
index 753d7473e..166262c2f 100644
--- a/base/src/sys/windows/write_zeroes.rs
+++ b/base/src/sys/windows/write_zeroes.rs
@@ -10,11 +10,7 @@ use std::os::windows::fs::FileExt;
 use crate::PunchHole;
 
 // TODO(b/195151495): Fix so that this will extend a file size if needed.
-pub(crate) fn file_write_zeroes_at(
-    file: &mut File,
-    offset: u64,
-    length: usize,
-) -> io::Result<usize> {
+pub(crate) fn file_write_zeroes_at(file: &File, offset: u64, length: usize) -> io::Result<usize> {
     // Try to punch a hole first.
     if let Ok(()) = file.punch_hole(offset, length as u64) {
         return Ok(length);
diff --git a/base/src/timer.rs b/base/src/timer.rs
index 6ff1018b1..cd53bb946 100644
--- a/base/src/timer.rs
+++ b/base/src/timer.rs
@@ -21,10 +21,11 @@ use crate::descriptor::SafeDescriptor;
 /// A trait for timer objects that delivers timer expiration
 /// notifications to an underlying descriptor.
 pub trait TimerTrait: AsRawDescriptor + IntoRawDescriptor + Send {
-    /// Sets the timer to expire after `dur`.  If `interval` is not `None` and non-zero it
-    /// represents the period for repeated expirations after the initial expiration.  Otherwise
-    /// the timer will expire just once.  Cancels any existing duration and repeating interval.
-    fn reset(&mut self, dur: Duration, interval: Option<Duration>) -> Result<()>;
+    /// Sets the timer to expire after `dur` without repeating. Cancels any existing timer.
+    fn reset_oneshot(&mut self, dur: Duration) -> Result<()>;
+
+    /// Sets the timer to fire repeatedly at `dur` intervals. Cancels any existing timer.
+    fn reset_repeating(&mut self, dur: Duration) -> Result<()>;
 
     /// Waits until the timer expires.
     fn wait(&mut self) -> Result<()>;
@@ -114,6 +115,14 @@ impl FakeTimer {
         }
     }
 
+    fn reset(&mut self, dur: Duration) -> Result<()> {
+        let mut guard = self.clock.lock();
+        let deadline = guard.nanos() + dur.as_nanos() as u64;
+        self.deadline_ns = Some(deadline);
+        guard.add_event(deadline, self.event.try_clone()?);
+        Ok(())
+    }
+
     /// Waits until the timer expires or an optional wait timeout expires, whichever happens first.
     ///
     /// # Returns
@@ -158,13 +167,14 @@ impl FakeTimer {
 }
 
 impl TimerTrait for FakeTimer {
-    fn reset(&mut self, dur: Duration, interval: Option<Duration>) -> Result<()> {
-        let mut guard = self.clock.lock();
-        let deadline = guard.nanos() + dur.as_nanos() as u64;
-        self.deadline_ns = Some(deadline);
-        self.interval = interval;
-        guard.add_event(deadline, self.event.try_clone()?);
-        Ok(())
+    fn reset_oneshot(&mut self, dur: Duration) -> Result<()> {
+        self.interval = None;
+        self.reset(dur)
+    }
+
+    fn reset_repeating(&mut self, dur: Duration) -> Result<()> {
+        self.interval = Some(dur);
+        self.reset(dur)
     }
 
     fn wait(&mut self) -> Result<()> {
@@ -209,96 +219,79 @@ mod tests {
     use std::time::Instant;
 
     use super::*;
-
-    // clock error is 2*clock_resolution + 100 microseconds to handle
-    // time change from calling now() to arming timer
-    fn get_clock_error() -> Duration {
-        Timer::new()
-            .unwrap()
-            .resolution()
-            .expect("expected to be able to read timer resolution")
-            .checked_mul(2)
-            .expect("timer resolution x 2 should not overflow")
-            .checked_add(Duration::from_micros(100))
-            .expect("timer resolution x 2 + 100 microsecond should not overflow")
-    }
+    use crate::EventToken;
+    use crate::WaitContext;
 
     #[test]
-    #[ignore]
     fn one_shot() {
-        // This test relies on the host having a reliable clock and not being
-        // overloaded, so it's marked as "ignore".  You can run by running
-        // cargo test -p base timer -- --ignored
-
         let mut tfd = Timer::new().expect("failed to create Timer");
 
-        let dur = Duration::from_millis(1000);
-        let clock_error = get_clock_error();
-
+        let dur = Duration::from_millis(10);
         let now = Instant::now();
-        tfd.reset(dur, None).expect("failed to arm timer");
-
+        tfd.reset_oneshot(dur).expect("failed to arm timer");
         tfd.wait().expect("unable to wait for timer");
         let elapsed = now.elapsed();
-        // elapsed is within +-clock_error from expected duration
-        assert!(elapsed - clock_error <= dur);
-        assert!(elapsed + clock_error >= dur);
+        assert!(elapsed >= dur, "expected {:?} >= {:?}", elapsed, dur);
     }
 
     /// Similar to one_shot, except this one waits for a clone of the timer.
     #[test]
-    #[ignore]
     fn one_shot_cloned() {
         let mut tfd = Timer::new().expect("failed to create Timer");
-        let dur = Duration::from_millis(1000);
         let mut cloned_tfd = tfd.try_clone().expect("failed to clone timer");
 
-        // clock error is 2*clock_resolution + 100 microseconds to handle
-        // time change from calling now() to arming timer
-        let clock_error = get_clock_error();
-
+        let dur = Duration::from_millis(10);
         let now = Instant::now();
-        tfd.reset(dur, None).expect("failed to arm timer");
+        tfd.reset_oneshot(dur).expect("failed to arm timer");
         cloned_tfd.wait().expect("unable to wait for timer");
         let elapsed = now.elapsed();
-
-        // elapsed is within +-clock_error from expected duration
-        assert!(elapsed - clock_error <= dur);
-        assert!(elapsed + clock_error >= dur);
+        assert!(elapsed >= dur, "expected {:?} >= {:?}", elapsed, dur);
     }
 
     #[test]
-    #[ignore]
     fn repeating() {
-        // This test relies on the host having a reliable clock and not being
-        // overloaded, so it's marked as "ignore".  You can run by running
-        // cargo test -p base timer -- --ignored
-
         let mut tfd = Timer::new().expect("failed to create Timer");
 
-        let dur = Duration::from_millis(200);
-        // clock error is 2*clock_resolution + 100 microseconds to handle
-        // time change from calling now() to arming timer
-        let clock_error = Timer::new()
-            .unwrap()
-            .resolution()
-            .expect("expected to be able to read timer resolution")
-            .checked_mul(2)
-            .expect("timer resolution x 2 should not overflow")
-            .checked_add(Duration::from_micros(100))
-            .expect("timer resolution x 2 + 100 microsecond should not overflow");
-        let interval = Duration::from_millis(100);
+        let interval = Duration::from_millis(10);
         let now = Instant::now();
-        tfd.reset(dur, Some(interval)).expect("failed to arm timer");
+        tfd.reset_repeating(interval).expect("failed to arm timer");
 
         tfd.wait().expect("unable to wait for timer");
-        // should take "dur" duration for the first wait
-        assert!(now.elapsed() + clock_error >= dur);
+        // should take `interval` duration for the first wait
+        assert!(now.elapsed() >= interval);
         tfd.wait().expect("unable to wait for timer");
         // subsequent waits should take "interval" duration
-        assert!(now.elapsed() + clock_error >= dur + interval);
+        assert!(now.elapsed() >= interval * 2);
         tfd.wait().expect("unable to wait for timer");
-        assert!(now.elapsed() + clock_error >= dur + interval * 2);
+        assert!(now.elapsed() >= interval * 3);
+    }
+
+    #[test]
+    fn mark_waited_inactive() {
+        let mut tfd = Timer::new().expect("failed to create Timer");
+        // This ought to return true, but Windows always returns false, so we can't assert it here.
+        tfd.mark_waited().expect("mark_waited failed");
+    }
+
+    #[test]
+    fn mark_waited_active() {
+        let mut tfd = Timer::new().expect("failed to create Timer");
+        tfd.reset_oneshot(Duration::from_nanos(1))
+            .expect("failed to arm timer");
+
+        // Use a WaitContext to block until the timer has fired.
+        #[derive(EventToken)]
+        enum Token {
+            Timer,
+        }
+        let wait_ctx: WaitContext<Token> =
+            WaitContext::build_with(&[(&tfd, Token::Timer)]).unwrap();
+        let _events = wait_ctx.wait().unwrap();
+
+        assert!(
+            !tfd.mark_waited().expect("mark_waited failed"),
+            "expected mark_waited to return false",
+        );
     }
 
     #[test]
@@ -307,7 +300,7 @@ mod tests {
         let mut tfd = FakeTimer::new(clock.clone());
 
         let dur = Duration::from_nanos(200);
-        tfd.reset(dur, None).expect("failed to arm timer");
+        tfd.reset_oneshot(dur).expect("failed to arm timer");
 
         clock.lock().add_ns(200);
 
@@ -320,7 +313,7 @@ mod tests {
         let mut tfd = FakeTimer::new(clock.clone());
 
         let dur = Duration::from_nanos(200);
-        tfd.reset(dur, None).expect("failed to arm timer");
+        tfd.reset_oneshot(dur).expect("failed to arm timer");
 
         clock.lock().add_ns(100);
         let result = tfd
@@ -344,16 +337,15 @@ mod tests {
         let clock = Arc::new(Mutex::new(FakeClock::new()));
         let mut tfd = FakeTimer::new(clock.clone());
 
-        let dur = Duration::from_nanos(200);
         let interval = Duration::from_nanos(100);
-        tfd.reset(dur, Some(interval)).expect("failed to arm timer");
+        tfd.reset_repeating(interval).expect("failed to arm timer");
 
-        clock.lock().add_ns(300);
+        clock.lock().add_ns(150);
 
         // An expiration from the initial expiry and from 1 repeat.
         assert_eq!(tfd.wait().is_ok(), true);
 
-        clock.lock().add_ns(300);
+        clock.lock().add_ns(100);
         assert_eq!(tfd.wait().is_ok(), true);
     }
 }
diff --git a/base/src/tube.rs b/base/src/tube.rs
index 57a2a7d9c..9bcd83bfa 100644
--- a/base/src/tube.rs
+++ b/base/src/tube.rs
@@ -134,6 +134,8 @@ pub enum Error {
     Proto(protobuf::Error),
     #[error("failed to receive packet: {0}")]
     Recv(io::Error),
+    #[error("attempted to receive too many file descriptors")]
+    RecvTooManyFds,
     #[error("Received a message with a zero sized body. This should not happen.")]
     RecvUnexpectedEmptyBody,
     #[error("failed to send packet: {0}")]
diff --git a/base/src/volatile_memory.rs b/base/src/volatile_memory.rs
index c509ae754..5979cc8fb 100644
--- a/base/src/volatile_memory.rs
+++ b/base/src/volatile_memory.rs
@@ -14,7 +14,8 @@
 //! For the purposes of maintaining safety, volatile memory has some rules of its own:
 //! 1. No references or slices to volatile memory (`&` or `&mut`).
 //! 2. Access should always been done with a volatile read or write.
-//! The First rule is because having references of any kind to memory considered volatile would
+//!
+//! The first rule is because having references of any kind to memory considered volatile would
 //! violate pointer aliasing. The second is because unvolatile accesses are inherently undefined if
 //! done concurrently without synchronization. With volatile access we know that the compiler has
 //! not reordered or elided the access.
@@ -27,7 +28,6 @@ use std::ptr::write_bytes;
 use std::ptr::write_volatile;
 use std::result;
 use std::slice;
-use std::usize;
 
 use remain::sorted;
 use thiserror::Error;
@@ -385,8 +385,22 @@ impl PartialEq<VolatileSlice<'_>> for VolatileSlice<'_> {
 /// The `PartialEq` implementation for `VolatileSlice` is reflexive, symmetric, and transitive.
 impl Eq for VolatileSlice<'_> {}
 
+impl std::io::Write for VolatileSlice<'_> {
+    fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {
+        let len = buf.len().min(self.size());
+        self.copy_from(&buf[..len]);
+        self.advance(len);
+        Ok(len)
+    }
+
+    fn flush(&mut self) -> std::io::Result<()> {
+        Ok(())
+    }
+}
+
 #[cfg(test)]
 mod tests {
+    use std::io::Write;
     use std::sync::Arc;
     use std::sync::Barrier;
     use std::thread::spawn;
@@ -474,13 +488,12 @@ mod tests {
 
     #[test]
     fn slice_overflow_error() {
-        use std::usize::MAX;
         let a = VecMem::new(1);
-        let res = a.get_slice(MAX, 1).unwrap_err();
+        let res = a.get_slice(usize::MAX, 1).unwrap_err();
         assert_eq!(
             res,
             Error::Overflow {
-                base: MAX,
+                base: usize::MAX,
                 offset: 1,
             }
         );
@@ -550,4 +563,95 @@ mod tests {
         a.get_slice(17, 1).unwrap().write_bytes(1);
         assert!(slice.is_all_zero());
     }
+
+    #[test]
+    fn write_partial() {
+        let mem = VecMem::new(1024);
+        let mut slice = mem.get_slice(1, 16).unwrap();
+        slice.write_bytes(0xCC);
+
+        // Writing 4 bytes should succeed and advance the slice by 4 bytes.
+        let write_len = slice.write(&[1, 2, 3, 4]).unwrap();
+        assert_eq!(write_len, 4);
+        assert_eq!(slice.size(), 16 - 4);
+
+        // The written data should appear in the memory at offset 1.
+        assert_eq!(mem.mem[1..=4], [1, 2, 3, 4]);
+
+        // The next byte of the slice should be unmodified.
+        assert_eq!(mem.mem[5], 0xCC);
+    }
+
+    #[test]
+    fn write_multiple() {
+        let mem = VecMem::new(1024);
+        let mut slice = mem.get_slice(1, 16).unwrap();
+        slice.write_bytes(0xCC);
+
+        // Writing 4 bytes should succeed and advance the slice by 4 bytes.
+        let write_len = slice.write(&[1, 2, 3, 4]).unwrap();
+        assert_eq!(write_len, 4);
+        assert_eq!(slice.size(), 16 - 4);
+
+        // The next byte of the slice should be unmodified.
+        assert_eq!(mem.mem[5], 0xCC);
+
+        // Writing another 4 bytes should succeed and advance the slice again.
+        let write2_len = slice.write(&[5, 6, 7, 8]).unwrap();
+        assert_eq!(write2_len, 4);
+        assert_eq!(slice.size(), 16 - 4 - 4);
+
+        // The written data should appear in the memory at offset 1.
+        assert_eq!(mem.mem[1..=8], [1, 2, 3, 4, 5, 6, 7, 8]);
+
+        // The next byte of the slice should be unmodified.
+        assert_eq!(mem.mem[9], 0xCC);
+    }
+
+    #[test]
+    fn write_exact_slice_size() {
+        let mem = VecMem::new(1024);
+        let mut slice = mem.get_slice(1, 4).unwrap();
+        slice.write_bytes(0xCC);
+
+        // Writing 4 bytes should succeed and consume the entire slice.
+        let write_len = slice.write(&[1, 2, 3, 4]).unwrap();
+        assert_eq!(write_len, 4);
+        assert_eq!(slice.size(), 0);
+
+        // The written data should appear in the memory at offset 1.
+        assert_eq!(mem.mem[1..=4], [1, 2, 3, 4]);
+
+        // The byte after the slice should be unmodified.
+        assert_eq!(mem.mem[5], 0);
+    }
+
+    #[test]
+    fn write_more_than_slice_size() {
+        let mem = VecMem::new(1024);
+        let mut slice = mem.get_slice(1, 4).unwrap();
+        slice.write_bytes(0xCC);
+
+        // Attempting to write 5 bytes should succeed but only write 4 bytes.
+        let write_len = slice.write(&[1, 2, 3, 4, 5]).unwrap();
+        assert_eq!(write_len, 4);
+        assert_eq!(slice.size(), 0);
+
+        // The written data should appear in the memory at offset 1.
+        assert_eq!(mem.mem[1..=4], [1, 2, 3, 4]);
+
+        // The byte after the slice should be unmodified.
+        assert_eq!(mem.mem[5], 0);
+    }
+
+    #[test]
+    fn write_empty_slice() {
+        let mem = VecMem::new(1024);
+        let mut slice = mem.get_slice(1, 0).unwrap();
+
+        // Writing to an empty slice should always return 0.
+        assert_eq!(slice.write(&[1, 2, 3, 4]).unwrap(), 0);
+        assert_eq!(slice.write(&[5, 6, 7, 8]).unwrap(), 0);
+        assert_eq!(slice.write(&[]).unwrap(), 0);
+    }
 }
diff --git a/base/src/write_zeroes.rs b/base/src/write_zeroes.rs
index 6489afc69..36cf46da6 100644
--- a/base/src/write_zeroes.rs
+++ b/base/src/write_zeroes.rs
@@ -19,29 +19,17 @@ impl PunchHole for File {
     }
 }
 
-/// A trait for deallocating space in a file of a mutable reference
-pub trait PunchHoleMut {
-    /// Replace a range of bytes with a hole.
-    fn punch_hole_mut(&mut self, offset: u64, length: u64) -> io::Result<()>;
-}
-
-impl<T: PunchHole> PunchHoleMut for T {
-    fn punch_hole_mut(&mut self, offset: u64, length: u64) -> io::Result<()> {
-        self.punch_hole(offset, length)
-    }
-}
-
 /// A trait for writing zeroes to an arbitrary position in a file.
 pub trait WriteZeroesAt {
     /// Write up to `length` bytes of zeroes starting at `offset`, returning how many bytes were
     /// written.
-    fn write_zeroes_at(&mut self, offset: u64, length: usize) -> io::Result<usize>;
+    fn write_zeroes_at(&self, offset: u64, length: usize) -> io::Result<usize>;
 
     /// Write zeroes starting at `offset` until `length` bytes have been written.
     ///
     /// This method will continuously call `write_zeroes_at` until the requested
     /// `length` is satisfied or an error is encountered.
-    fn write_zeroes_all_at(&mut self, mut offset: u64, mut length: usize) -> io::Result<()> {
+    fn write_zeroes_all_at(&self, mut offset: u64, mut length: usize) -> io::Result<()> {
         while length > 0 {
             match self.write_zeroes_at(offset, length) {
                 Ok(0) => return Err(Error::from(ErrorKind::WriteZero)),
@@ -65,7 +53,7 @@ pub trait WriteZeroesAt {
 }
 
 impl WriteZeroesAt for File {
-    fn write_zeroes_at(&mut self, offset: u64, length: usize) -> io::Result<usize> {
+    fn write_zeroes_at(&self, offset: u64, length: usize) -> io::Result<usize> {
         crate::platform::file_write_zeroes_at(self, offset, length)
     }
 }
diff --git a/base/tests/syslog.rs b/base/tests/syslog.rs
index e538bd201..45fac262e 100644
--- a/base/tests/syslog.rs
+++ b/base/tests/syslog.rs
@@ -109,7 +109,7 @@ fn syslogger_char() {
     }
 
     syslogger
-        .write_all(&[b'\n'])
+        .write_all(b"\n")
         .expect("error writing newline char");
 
     std::mem::drop(syslogger);
diff --git a/base_tokio/Android.bp b/base_tokio/Android.bp
new file mode 100644
index 000000000..167fa7b94
--- /dev/null
+++ b/base_tokio/Android.bp
@@ -0,0 +1,60 @@
+// This file is generated by cargo_embargo.
+// Do not modify this file after the first "rust_*" or "genrule" module
+// because the changes will be overridden on upgrade.
+// Content before the first "rust_*" or "genrule" module is preserved.
+
+package {
+    // See: http://go/android-license-faq
+    // A large-scale-change added 'default_applicable_licenses' to import
+    // all of the 'license_kinds' from "external_crosvm_license"
+    // to get the below license kinds:
+    //   SPDX-license-identifier-BSD
+    default_applicable_licenses: ["external_crosvm_license"],
+}
+
+rust_test {
+    name: "base_tokio_test_src_lib",
+    defaults: ["crosvm_inner_defaults"],
+    host_supported: true,
+    crate_name: "base_tokio",
+    cargo_env_compat: true,
+    cargo_pkg_version: "0.1.0",
+    crate_root: "src/lib.rs",
+    test_suites: ["general-tests"],
+    auto_gen_config: true,
+    test_options: {
+        unit_test: true,
+    },
+    edition: "2021",
+    rustlibs: [
+        "libanyhow",
+        "libbase_rust",
+        "libcfg_if",
+        "libfutures",
+        "liblibc",
+        "libserde",
+        "libsync_rust",
+        "libtokio",
+    ],
+}
+
+rust_library {
+    name: "libbase_tokio",
+    defaults: ["crosvm_inner_defaults"],
+    host_supported: true,
+    crate_name: "base_tokio",
+    cargo_env_compat: true,
+    cargo_pkg_version: "0.1.0",
+    crate_root: "src/lib.rs",
+    edition: "2021",
+    rustlibs: [
+        "libanyhow",
+        "libbase_rust",
+        "libcfg_if",
+        "libfutures",
+        "liblibc",
+        "libserde",
+        "libsync_rust",
+        "libtokio",
+    ],
+}
diff --git a/base_tokio/Cargo.toml b/base_tokio/Cargo.toml
new file mode 100644
index 000000000..d33d46a4a
--- /dev/null
+++ b/base_tokio/Cargo.toml
@@ -0,0 +1,19 @@
+[package]
+name = "base_tokio"
+version = "0.1.0"
+authors = ["The ChromiumOS Authors"]
+edition = "2021"
+
+[dependencies]
+anyhow = "*"
+cfg-if = "1.0.0"
+futures = { version = "0.3" }
+libc = "*"
+serde = { version = "1" }
+tokio = { workspace = true }
+
+base = { path = "../base" }
+sync = { path = "../common/sync" }
+
+[target.'cfg(windows)'.dependencies]
+winapi = "*"
diff --git a/base_tokio/src/event.rs b/base_tokio/src/event.rs
new file mode 100644
index 000000000..4cafd78e1
--- /dev/null
+++ b/base_tokio/src/event.rs
@@ -0,0 +1,31 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#[cfg(test)]
+mod tests {
+    use base::Event;
+
+    use crate::EventTokio;
+
+    #[tokio::test]
+    async fn already_signaled() {
+        let event = Event::new().unwrap();
+        let async_event = EventTokio::new(event.try_clone().unwrap()).unwrap();
+
+        event.signal().unwrap();
+        async_event.wait().await.unwrap();
+    }
+
+    #[tokio::test]
+    async fn signaled_after_delay() {
+        let event = Event::new().unwrap();
+        let async_event = EventTokio::new(event.try_clone().unwrap()).unwrap();
+
+        tokio::spawn(async move {
+            tokio::time::sleep(std::time::Duration::from_millis(1)).await;
+            event.signal().unwrap();
+        });
+        async_event.wait().await.unwrap();
+    }
+}
diff --git a/base_tokio/src/lib.rs b/base_tokio/src/lib.rs
new file mode 100644
index 000000000..8d242b2c2
--- /dev/null
+++ b/base_tokio/src/lib.rs
@@ -0,0 +1,23 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Tokio versions of type's defined in crosvm's `base` crate.
+
+mod sys {
+    cfg_if::cfg_if! {
+        if #[cfg(any(target_os = "android", target_os = "linux"))] {
+            pub mod linux;
+            pub use linux::*;
+        } else if #[cfg(windows)] {
+            pub mod windows;
+            pub use windows::*;
+        }
+    }
+}
+
+mod event;
+mod tube;
+
+pub use sys::event::EventTokio;
+pub use sys::tube::TubeTokio;
diff --git a/base_tokio/src/sys/linux/event.rs b/base_tokio/src/sys/linux/event.rs
new file mode 100644
index 000000000..016b99eb6
--- /dev/null
+++ b/base_tokio/src/sys/linux/event.rs
@@ -0,0 +1,53 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::os::fd::AsRawFd;
+
+use tokio::io::unix::AsyncFd;
+
+/// An async version of `base::Event`.
+pub struct EventTokio(AsyncFd<base::SafeDescriptor>);
+
+impl EventTokio {
+    /// WARNING: Sets O_NONBLOCK internally, which will also affect all clones of the `Event`.
+    pub fn new(event: base::Event) -> anyhow::Result<Self> {
+        let fd: base::SafeDescriptor = event.into();
+        base::add_fd_flags(fd.as_raw_fd(), libc::O_NONBLOCK)?;
+        Ok(Self(AsyncFd::new(fd)?))
+    }
+
+    /// Blocks until the event is signaled and clears the signal.
+    ///
+    /// It is undefined behavior to wait on an event from multiple threads or processes
+    /// simultaneously.
+    pub async fn wait(&self) -> std::io::Result<()> {
+        loop {
+            let mut guard = self.0.readable().await?;
+            let io_result = guard.try_io(|inner| {
+                let mut buf: u64 = 0;
+                // SAFETY: This is safe because we made this fd and the pointer we pass can not
+                // overflow because we give the syscall's size parameter properly.
+                let ret = unsafe {
+                    libc::read(
+                        inner.as_raw_fd(),
+                        &mut buf as *mut u64 as *mut libc::c_void,
+                        std::mem::size_of::<u64>(),
+                    )
+                };
+                if ret < 0 {
+                    return Err(std::io::Error::last_os_error());
+                }
+                if ret as usize != std::mem::size_of::<u64>() {
+                    return Err(std::io::Error::from(std::io::ErrorKind::UnexpectedEof));
+                }
+                Ok(())
+            });
+
+            match io_result {
+                Ok(result) => return result,
+                Err(_would_block) => continue,
+            }
+        }
+    }
+}
diff --git a/base_tokio/src/sys/linux/mod.rs b/base_tokio/src/sys/linux/mod.rs
new file mode 100644
index 000000000..588ee9a11
--- /dev/null
+++ b/base_tokio/src/sys/linux/mod.rs
@@ -0,0 +1,6 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+pub mod event;
+pub mod tube;
diff --git a/base_tokio/src/sys/linux/tube.rs b/base_tokio/src/sys/linux/tube.rs
new file mode 100644
index 000000000..49b7ff077
--- /dev/null
+++ b/base_tokio/src/sys/linux/tube.rs
@@ -0,0 +1,89 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::os::fd::AsRawFd;
+
+use tokio::io::unix::AsyncFd;
+
+/// An async version of `base::Tube`.
+pub struct TubeTokio(AsyncFd<base::Tube>);
+
+impl TubeTokio {
+    pub fn new(tube: base::Tube) -> anyhow::Result<Self> {
+        base::add_fd_flags(tube.as_raw_fd(), libc::O_NONBLOCK)?;
+        Ok(Self(AsyncFd::new(tube)?))
+    }
+
+    pub async fn into_inner(self) -> base::Tube {
+        let tube = self.0.into_inner();
+        base::clear_fd_flags(tube.as_raw_fd(), libc::O_NONBLOCK)
+            .expect("failed to clear O_NONBLOCK");
+        tube
+    }
+
+    pub async fn send<T: serde::Serialize + Send + 'static>(
+        &mut self,
+        msg: T,
+    ) -> base::TubeResult<()> {
+        loop {
+            let mut guard = self.0.writable().await.map_err(base::TubeError::Send)?;
+            let io_result = guard.try_io(|inner| {
+                // Re-using the non-async send is potentially hazardous since it isn't explicitly
+                // written with O_NONBLOCK support. However, since it uses SOCK_SEQPACKET and a
+                // single write syscall, it should be OK.
+                let r = inner.get_ref().send(&msg);
+                // Transpose the `std::io::Error` errors outside so that `try_io` can check them
+                // for `WouldBlock`.
+                match r {
+                    Ok(x) => Ok(Ok(x)),
+                    Err(base::TubeError::Send(e)) => Err(e),
+                    Err(e) => Ok(Err(e)),
+                }
+            });
+
+            match io_result {
+                Ok(result) => {
+                    return match result {
+                        Ok(Ok(x)) => Ok(x),
+                        Ok(Err(e)) => Err(e),
+                        Err(e) => Err(base::TubeError::Send(e)),
+                    }
+                }
+                Err(_would_block) => continue,
+            }
+        }
+    }
+
+    pub async fn recv<T: serde::de::DeserializeOwned + Send + 'static>(
+        &mut self,
+    ) -> base::TubeResult<T> {
+        loop {
+            let mut guard = self.0.readable().await.map_err(base::TubeError::Recv)?;
+            let io_result = guard.try_io(|inner| {
+                // Re-using the non-async recv is potentially hazardous since it isn't explicitly
+                // written with O_NONBLOCK support. However, since it uses SOCK_SEQPACKET and a
+                // single read syscall, it should be OK.
+                let r = inner.get_ref().recv();
+                // Transpose the `std::io::Error` errors outside so that `try_io` can check them
+                // for `WouldBlock`.
+                match r {
+                    Ok(x) => Ok(Ok(x)),
+                    Err(base::TubeError::Recv(e)) => Err(e),
+                    Err(e) => Ok(Err(e)),
+                }
+            });
+
+            match io_result {
+                Ok(result) => {
+                    return match result {
+                        Ok(Ok(x)) => Ok(x),
+                        Ok(Err(e)) => Err(e),
+                        Err(e) => Err(base::TubeError::Recv(e)),
+                    }
+                }
+                Err(_would_block) => continue,
+            }
+        }
+    }
+}
diff --git a/base_tokio/src/sys/windows/event.rs b/base_tokio/src/sys/windows/event.rs
new file mode 100644
index 000000000..4cb95d6d7
--- /dev/null
+++ b/base_tokio/src/sys/windows/event.rs
@@ -0,0 +1,25 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+/// An async version of `base::Event`.
+pub struct EventTokio(base::Event);
+
+impl EventTokio {
+    /// Must be a manual-reset event (i.e. created by `base::Event::new()`).
+    ///
+    /// TODO: Add support for auto-reset events.
+    pub fn new(event: base::Event) -> anyhow::Result<Self> {
+        Ok(Self(event))
+    }
+
+    /// Blocks until the event is signaled and clears the signal.
+    ///
+    /// It is undefined behavior to wait on an event from multiple threads or processes
+    /// simultaneously.
+    pub async fn wait(&self) -> std::io::Result<()> {
+        base::sys::windows::async_wait_for_single_object(&self.0).await?;
+        self.0.reset()?;
+        Ok(())
+    }
+}
diff --git a/base_tokio/src/sys/windows/mod.rs b/base_tokio/src/sys/windows/mod.rs
new file mode 100644
index 000000000..588ee9a11
--- /dev/null
+++ b/base_tokio/src/sys/windows/mod.rs
@@ -0,0 +1,6 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+pub mod event;
+pub mod tube;
diff --git a/base_tokio/src/sys/windows/tube.rs b/base_tokio/src/sys/windows/tube.rs
new file mode 100644
index 000000000..31b24f6e1
--- /dev/null
+++ b/base_tokio/src/sys/windows/tube.rs
@@ -0,0 +1,100 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use base::warn;
+use base::AsRawDescriptor;
+use base::Descriptor;
+use base::Error;
+use base::Event;
+use base::Tube;
+use base::TubeError;
+use base::TubeResult;
+use tokio::sync::mpsc;
+use tokio::sync::oneshot;
+use winapi::um::ioapiset::CancelIoEx;
+
+/// An async version of `Tube`.
+///
+/// Implementation note: We don't trust `base::Tube::recv` to behave in a non-blocking manner even
+/// when the read notifier is signalled, so we offload the actual `send` and `recv` calls onto a
+/// blocking thread.
+pub struct TubeTokio {
+    worker: tokio::task::JoinHandle<Tube>,
+    cmd_tx: mpsc::Sender<Box<dyn FnOnce(&Tube) + Send>>,
+    // Clone of the tube's read notifier.
+    read_notifier: Event,
+    // Tube's RawDescriptor.
+    tube_descriptor: Descriptor,
+}
+
+impl TubeTokio {
+    pub fn new(mut tube: Tube) -> anyhow::Result<Self> {
+        let read_notifier = tube.get_read_notifier_event().try_clone()?;
+        let tube_descriptor = Descriptor(tube.as_raw_descriptor());
+
+        let (cmd_tx, mut cmd_rx) = mpsc::channel::<Box<dyn FnOnce(&Tube) + Send>>(1);
+        let worker = tokio::task::spawn_blocking(move || {
+            while let Some(f) = cmd_rx.blocking_recv() {
+                f(&mut tube)
+            }
+            tube
+        });
+        Ok(Self {
+            worker,
+            cmd_tx,
+            read_notifier,
+            tube_descriptor,
+        })
+    }
+
+    pub async fn into_inner(self) -> Tube {
+        drop(self.cmd_tx);
+
+        // Attempt to cancel any blocking IO the worker thread is doing so that we don't get stuck
+        // here if a `recv` call blocked. This is racy since we don't know if the queue'd up IO
+        // requests have actually started yet.
+        //
+        // SAFETY: The descriptor should still be valid since we own the tube in the blocking task.
+        if unsafe { CancelIoEx(self.tube_descriptor.0, std::ptr::null_mut()) } == 0 {
+            warn!(
+                "Cancel IO for handle:{:?} failed with {}",
+                self.tube_descriptor.0,
+                Error::last()
+            );
+        }
+
+        self.worker.await.expect("failed to join tube worker")
+    }
+
+    pub async fn send<T: serde::Serialize + Send + 'static>(&mut self, msg: T) -> TubeResult<()> {
+        // It is unlikely the tube is full given crosvm usage patterns, so request the blocking
+        // send immediately.
+        let (tx, rx) = oneshot::channel();
+        self.cmd_tx
+            .send(Box::new(move |tube| {
+                let _ = tx.send(tube.send(&msg));
+            }))
+            .await
+            .expect("worker missing");
+        rx.await.map_err(|_| TubeError::OperationCancelled)??;
+        Ok(())
+    }
+
+    pub async fn recv<T: serde::de::DeserializeOwned + Send + 'static>(&mut self) -> TubeResult<T> {
+        // `Tube`'s read notifier event is a manual-reset event and `Tube::recv` wants to
+        // handle the reset, so we bypass `EventAsync`.
+        base::sys::windows::async_wait_for_single_object(&self.read_notifier)
+            .await
+            .map_err(TubeError::Recv)?;
+
+        let (tx, rx) = oneshot::channel();
+        self.cmd_tx
+            .send(Box::new(move |tube| {
+                let _ = tx.send(tube.recv());
+            }))
+            .await
+            .expect("worker missing");
+        rx.await.map_err(|_| TubeError::OperationCancelled)?
+    }
+}
diff --git a/base_tokio/src/tube.rs b/base_tokio/src/tube.rs
new file mode 100644
index 000000000..0834d1df9
--- /dev/null
+++ b/base_tokio/src/tube.rs
@@ -0,0 +1,25 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#[cfg(test)]
+mod tests {
+    use base::Tube;
+
+    use crate::TubeTokio;
+
+    #[tokio::test]
+    async fn recv_send() {
+        let (a, b) = Tube::pair().unwrap();
+        let mut b = TubeTokio::new(b).unwrap();
+
+        let blocking_task = tokio::task::spawn_blocking(move || {
+            a.send(&5u8).unwrap();
+            a.recv::<u8>().unwrap()
+        });
+
+        assert_eq!(b.recv::<u8>().await.unwrap(), 5u8);
+        b.send(&16u8).await.unwrap();
+        assert_eq!(blocking_task.await.unwrap(), 16u8);
+    }
+}
diff --git a/bit_field/Android.bp b/bit_field/Android.bp
index 3873a8fa5..21278e1c8 100644
--- a/bit_field/Android.bp
+++ b/bit_field/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "test_enum",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/test_enum.rs"],
+    crate_root: "tests/test_enum.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -37,7 +37,7 @@ rust_test {
     crate_name: "test_tuple_struct",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/test_tuple_struct.rs"],
+    crate_root: "tests/test_tuple_struct.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -55,7 +55,7 @@ rust_library {
     crate_name: "bit_field",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     proc_macros: ["libbit_field_derive"],
 }
diff --git a/bit_field/bit_field_derive/Android.bp b/bit_field/bit_field_derive/Android.bp
index fb5b59d15..f119f13f5 100644
--- a/bit_field/bit_field_derive/Android.bp
+++ b/bit_field/bit_field_derive/Android.bp
@@ -15,10 +15,11 @@ package {
 rust_test_host {
     name: "bit_field_derive_test_bit_field_derive",
     defaults: ["crosvm_inner_defaults"],
+    host_cross_supported: false,
     crate_name: "bit_field_derive",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["bit_field_derive.rs"],
+    crate_root: "bit_field_derive.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -38,7 +39,7 @@ rust_proc_macro {
     crate_name: "bit_field_derive",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["bit_field_derive.rs"],
+    crate_root: "bit_field_derive.rs",
     edition: "2021",
     rustlibs: [
         "libproc_macro2",
diff --git a/bit_field/src/lib.rs b/bit_field/src/lib.rs
index ac37f3cbb..573508e23 100644
--- a/bit_field/src/lib.rs
+++ b/bit_field/src/lib.rs
@@ -325,7 +325,7 @@ pub fn max<T: BitFieldSpecifier>() -> u64 {
     if T::FIELD_WIDTH < 64 {
         (1 << T::FIELD_WIDTH) - 1
     } else {
-        u64::max_value()
+        u64::MAX
     }
 }
 
diff --git a/broker_ipc/Android.bp b/broker_ipc/Android.bp
index 85409085e..7f270f2af 100644
--- a/broker_ipc/Android.bp
+++ b/broker_ipc/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "broker_ipc",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/cargo2android_defaults.bp b/cargo2android_defaults.bp
index 80b397c1a..46204ac91 100644
--- a/cargo2android_defaults.bp
+++ b/cargo2android_defaults.bp
@@ -28,7 +28,8 @@ rust_defaults {
     ],
     defaults_visibility: [
         "//external/crosvm:__subpackages__",
-        "//packages/modules/Virtualization/authfs",
+        "//packages/modules/Virtualization/guest/authfs",
+        "//packages/modules/Virtualization/tests/authfs",
         // For QCOM's crosvm fork.
         "//vendor:__subpackages__",
     ],
diff --git a/cargo_embargo.json b/cargo_embargo.json
index a93672f4c..4a8f7685d 100644
--- a/cargo_embargo.json
+++ b/cargo_embargo.json
@@ -92,7 +92,6 @@
       "//vendor:__subpackages__"
     ],
     "libbase_rust": [
-      "//packages/modules/Virtualization/virtualizationmanager",
       // For QCOM's crosvm fork.
       "//vendor:__subpackages__"
     ],
@@ -101,13 +100,14 @@
       "//vendor:__subpackages__"
     ],
     "libdisk": [
-      "//packages/modules/Virtualization/virtualizationmanager",
+      "//packages/modules/Virtualization/android/virtmgr",
       // For QCOM's crosvm fork.
       "//vendor:__subpackages__"
     ],
     "libfuse_rust": [
-        "//packages/modules/Virtualization/authfs",
-        "//packages/modules/Virtualization/zipfuse"
+        "//packages/modules/Virtualization/guest/authfs",
+        "//packages/modules/Virtualization/guest/zipfuse",
+        "//packages/modules/Virtualization/tests/authfs"
     ],
     "libhypervisor": [
       // For QCOM's crosvm fork.
@@ -118,7 +118,7 @@
       "//vendor:__subpackages__"
     ],
     "libvm_control": [
-      "//packages/modules/Virtualization/virtualizationmanager"
+      "//packages/modules/Virtualization/android/virtmgr"
     ],
     "libvm_memory": [
       // For QCOM's crosvm fork.
@@ -200,7 +200,8 @@
       "no_presubmit": true
     },
     "power_monitor": {
-      "copy_out": true
+      "copy_out": true,
+      "patch": "power_monitor/patches/Android.bp.patch"
     },
     "protos": {
       "add_toplevel_block": "protos/cargo2android_protobuf.bp",
diff --git a/common/audio_streams/Android.bp b/common/audio_streams/Android.bp
index 9d535c076..5c4f36d51 100644
--- a/common/audio_streams/Android.bp
+++ b/common/audio_streams/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "audio_streams",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/audio_streams.rs"],
+    crate_root: "src/audio_streams.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -44,7 +44,7 @@ rust_library {
     crate_name: "audio_streams",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/audio_streams.rs"],
+    crate_root: "src/audio_streams.rs",
     edition: "2021",
     rustlibs: [
         "libfutures",
diff --git a/common/balloon_control/Android.bp b/common/balloon_control/Android.bp
index 561c23b2c..481eef8f6 100644
--- a/common/balloon_control/Android.bp
+++ b/common/balloon_control/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "balloon_control",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: ["libserde"],
 }
diff --git a/common/data_model/Android.bp b/common/data_model/Android.bp
index 461e626ce..ed98c156f 100644
--- a/common/data_model/Android.bp
+++ b/common/data_model/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "data_model",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.1-alpha.1",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -39,7 +39,7 @@ rust_library {
     crate_name: "data_model",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.1-alpha.1",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libserde",
diff --git a/common/sync/Android.bp b/common/sync/Android.bp
index af6260cc9..812256240 100644
--- a/common/sync/Android.bp
+++ b/common/sync/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "sync",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.99",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     visibility: ["//vendor:__subpackages__"],
 }
diff --git a/cros_async/Android.bp b/cros_async/Android.bp
index a74446941..585509ad1 100644
--- a/cros_async/Android.bp
+++ b/cros_async/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "cros_async",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.1",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -62,7 +62,7 @@ rust_test {
     crate_name: "executor",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.1",
-    srcs: ["tests/executor.rs"],
+    crate_root: "tests/executor.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -106,7 +106,7 @@ rust_library {
     crate_name: "cros_async",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.1",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/cros_async/Cargo.toml b/cros_async/Cargo.toml
index fb25c40ad..6a0f66e06 100644
--- a/cros_async/Cargo.toml
+++ b/cros_async/Cargo.toml
@@ -12,7 +12,7 @@ async-trait = "0.1.36"
 async-task = "4"
 cfg-if = "1.0.0"
 intrusive-collections = "0.9"
-libc = "*"
+libc = "0.2"
 once_cell = "1.7.2"
 paste = "1.0"
 pin-utils = "0.1.0-alpha.4"
@@ -23,26 +23,26 @@ base = { path = "../base" } # provided by ebuild
 thiserror = "1.0.20"
 audio_streams = { path = "../common/audio_streams" } # provided by ebuild
 anyhow = "1.0"
-serde = "*"
+serde = "1"
 serde_keyvalue = { path = "../serde_keyvalue", features = ["argh_derive"] } # provided by ebuild
 static_assertions = "1.1"
-tokio = { version = "1.29.1", optional = true, features = ["net", "rt-multi-thread"] }
+tokio = { workspace = true, optional = true }
 
 [target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
 io_uring = { path = "../io_uring" } # provided by ebuild
 
 [target.'cfg(windows)'.dependencies]
-winapi = "*"
+winapi = "0.3"
 win_util = { path = "../win_util" }
-smallvec = "*"
+smallvec = "1"
 
 [dependencies.futures]
-version = "*"
+version = "0.3"
 default-features = false
 features = ["alloc"]
 
 [dev-dependencies]
-futures = { version = "*", features = ["executor"] }
+futures = { version = "0.3", features = ["executor"] }
 futures-executor = { version = "0.3", features = ["thread-pool"] }
 futures-util = "0.3"
 tempfile = "3"
diff --git a/cros_async/src/sys/linux/timer.rs b/cros_async/src/sys/linux/timer.rs
index 8acefdfc7..7055f00fb 100644
--- a/cros_async/src/sys/linux/timer.rs
+++ b/cros_async/src/sys/linux/timer.rs
@@ -80,7 +80,7 @@ mod tests {
 
             let dur = Duration::from_millis(200);
             let now = Instant::now();
-            tfd.reset(dur, None).expect("failed to arm timer");
+            tfd.reset_oneshot(dur).expect("failed to arm timer");
 
             let t = TimerAsync::new_uring(tfd, ex).unwrap();
             t.wait().await.expect("unable to wait for timer");
@@ -99,7 +99,7 @@ mod tests {
 
             let dur = Duration::from_millis(200);
             let now = Instant::now();
-            tfd.reset(dur, None).expect("failed to arm timer");
+            tfd.reset_oneshot(dur).expect("failed to arm timer");
 
             let t = TimerAsync::new_poll(tfd, ex).unwrap();
             t.wait().await.expect("unable to wait for timer");
diff --git a/cros_async/src/sys/linux/tokio_source.rs b/cros_async/src/sys/linux/tokio_source.rs
index 4a8471296..90893d201 100644
--- a/cros_async/src/sys/linux/tokio_source.rs
+++ b/cros_async/src/sys/linux/tokio_source.rs
@@ -101,10 +101,10 @@ fn do_fsync(raw: Arc<OwnedFd>) -> io::Result<()> {
     }
 }
 
-fn do_read_to_mem(
+fn do_read_vectored(
     raw: Arc<OwnedFd>,
     file_offset: Option<u64>,
-    io_vecs: &Vec<VolatileSlice>,
+    io_vecs: &[VolatileSlice],
 ) -> io::Result<usize> {
     let ptr = io_vecs.as_ptr() as *const libc::iovec;
     let len = io_vecs.len() as i32;
@@ -120,18 +120,14 @@ fn do_read_to_mem(
         _ => Err(io::Error::last_os_error()),
     }
 }
-fn do_read_to_vec(
-    raw: Arc<OwnedFd>,
-    file_offset: Option<u64>,
-    vec: &mut Vec<u8>,
-) -> io::Result<usize> {
+fn do_read(raw: Arc<OwnedFd>, file_offset: Option<u64>, buf: &mut [u8]) -> io::Result<usize> {
     let fd = raw.as_raw_fd();
-    let ptr = vec.as_mut_ptr() as *mut libc::c_void;
+    let ptr = buf.as_mut_ptr() as *mut libc::c_void;
     let res = match file_offset {
         // SAFETY: we partially own `raw`, `ptr` has space up to vec.len()
-        Some(off) => unsafe { libc::pread64(fd, ptr, vec.len(), off as libc::off64_t) },
+        Some(off) => unsafe { libc::pread64(fd, ptr, buf.len(), off as libc::off64_t) },
         // SAFETY: we partially own `raw`, `ptr` has space up to vec.len()
-        None => unsafe { libc::read(fd, ptr, vec.len()) },
+        None => unsafe { libc::read(fd, ptr, buf.len()) },
     };
     match res {
         r if r >= 0 => Ok(res as usize),
@@ -139,18 +135,14 @@ fn do_read_to_vec(
     }
 }
 
-fn do_write_from_vec(
-    raw: Arc<OwnedFd>,
-    file_offset: Option<u64>,
-    vec: &Vec<u8>,
-) -> io::Result<usize> {
+fn do_write(raw: Arc<OwnedFd>, file_offset: Option<u64>, buf: &[u8]) -> io::Result<usize> {
     let fd = raw.as_raw_fd();
-    let ptr = vec.as_ptr() as *const libc::c_void;
+    let ptr = buf.as_ptr() as *const libc::c_void;
     let res = match file_offset {
         // SAFETY: we partially own `raw`, `ptr` has data up to vec.len()
-        Some(off) => unsafe { libc::pwrite64(fd, ptr, vec.len(), off as libc::off64_t) },
+        Some(off) => unsafe { libc::pwrite64(fd, ptr, buf.len(), off as libc::off64_t) },
         // SAFETY: we partially own `raw`, `ptr` has data up to vec.len()
-        None => unsafe { libc::write(fd, ptr, vec.len()) },
+        None => unsafe { libc::write(fd, ptr, buf.len()) },
     };
     match res {
         r if r >= 0 => Ok(res as usize),
@@ -158,10 +150,10 @@ fn do_write_from_vec(
     }
 }
 
-fn do_write_from_mem(
+fn do_write_vectored(
     raw: Arc<OwnedFd>,
     file_offset: Option<u64>,
-    io_vecs: &Vec<VolatileSlice>,
+    io_vecs: &[VolatileSlice],
 ) -> io::Result<usize> {
     let ptr = io_vecs.as_ptr() as *const libc::iovec;
     let len = io_vecs.len() as i32;
@@ -248,7 +240,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
             FdType::Async(async_fd) => {
                 let res = async_fd
                     .async_io(tokio::io::Interest::READABLE, |fd| {
-                        do_read_to_vec(fd.clone(), file_offset, &mut vec)
+                        do_read(fd.clone(), file_offset, &mut vec)
                     })
                     .await
                     .map_err(AsyncError::Io)?;
@@ -258,7 +250,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
                 let fd = blocking.clone();
                 self.runtime
                     .spawn_blocking(move || {
-                        let size = do_read_to_vec(fd, file_offset, &mut vec)?;
+                        let size = do_read(fd, file_offset, &mut vec)?;
                         Ok((size, vec))
                     })
                     .await
@@ -283,7 +275,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
                     .collect::<Vec<VolatileSlice>>();
                 async_fd
                     .async_io(tokio::io::Interest::READABLE, |fd| {
-                        do_read_to_mem(fd.clone(), file_offset, &iovecs)
+                        do_read_vectored(fd.clone(), file_offset, &iovecs)
                     })
                     .await
                     .map_err(AsyncError::Io)?
@@ -296,7 +288,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
                             .into_iter()
                             .filter_map(|mem_range| mem.get_volatile_slice(mem_range).ok())
                             .collect::<Vec<VolatileSlice>>();
-                        do_read_to_mem(fd, file_offset, &iovecs)
+                        do_read_vectored(fd, file_offset, &iovecs)
                     })
                     .await
                     .map_err(Error::Join)?
@@ -342,7 +334,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
                     .collect::<Vec<VolatileSlice>>();
                 async_fd
                     .async_io(tokio::io::Interest::WRITABLE, |fd| {
-                        do_write_from_mem(fd.clone(), file_offset, &iovecs)
+                        do_write_vectored(fd.clone(), file_offset, &iovecs)
                     })
                     .await
                     .map_err(AsyncError::Io)?
@@ -355,7 +347,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
                             .into_iter()
                             .filter_map(|mem_range| mem.get_volatile_slice(mem_range).ok())
                             .collect::<Vec<VolatileSlice>>();
-                        do_write_from_mem(fd, file_offset, &iovecs.clone())
+                        do_write_vectored(fd, file_offset, &iovecs)
                     })
                     .await
                     .map_err(Error::Join)?
@@ -373,7 +365,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
             FdType::Async(async_fd) => {
                 let res = async_fd
                     .async_io(tokio::io::Interest::WRITABLE, |fd| {
-                        do_write_from_vec(fd.clone(), file_offset, &vec)
+                        do_write(fd.clone(), file_offset, &vec)
                     })
                     .await
                     .map_err(AsyncError::Io)?;
@@ -383,7 +375,7 @@ impl<T: AsRawDescriptor> TokioSource<T> {
                 let fd = blocking.clone();
                 self.runtime
                     .spawn_blocking(move || {
-                        let size = do_write_from_vec(fd.clone(), file_offset, &vec)?;
+                        let size = do_write(fd.clone(), file_offset, &vec)?;
                         Ok((size, vec))
                     })
                     .await
diff --git a/cros_async/src/sys/linux/uring_executor.rs b/cros_async/src/sys/linux/uring_executor.rs
index ff18dff93..9d4a0e2f5 100644
--- a/cros_async/src/sys/linux/uring_executor.rs
+++ b/cros_async/src/sys/linux/uring_executor.rs
@@ -10,7 +10,7 @@
 //!
 //! There are two key issues managing asynchronous IO buffers in rust.
 //! 1) The kernel has a mutable reference to the memory until the completion is returned. Rust must
-//! not have any references to it during that time.
+//!    not have any references to it during that time.
 //! 2) The memory must remain valid as long as the kernel has a reference to it.
 //!
 //! ### The kernel's mutable borrow of the buffer
@@ -462,8 +462,8 @@ impl UringReactor {
         let src = ring
             .registered_sources
             .get(source.tag)
-            .map(Arc::clone)
-            .ok_or(Error::InvalidSource)?;
+            .ok_or(Error::InvalidSource)?
+            .clone();
         let entry = ring.ops.vacant_entry();
         let next_op_token = entry.key();
         self.ctx
@@ -490,8 +490,8 @@ impl UringReactor {
         let src = ring
             .registered_sources
             .get(source.tag)
-            .map(Arc::clone)
-            .ok_or(Error::InvalidSource)?;
+            .ok_or(Error::InvalidSource)?
+            .clone();
         let entry = ring.ops.vacant_entry();
         let next_op_token = entry.key();
         self.ctx
@@ -532,8 +532,8 @@ impl UringReactor {
         let src = ring
             .registered_sources
             .get(source.tag)
-            .map(Arc::clone)
-            .ok_or(Error::InvalidSource)?;
+            .ok_or(Error::InvalidSource)?
+            .clone();
         let entry = ring.ops.vacant_entry();
         let next_op_token = entry.key();
         self.ctx
@@ -574,8 +574,8 @@ impl UringReactor {
         let src = ring
             .registered_sources
             .get(source.tag)
-            .map(Arc::clone)
-            .ok_or(Error::InvalidSource)?;
+            .ok_or(Error::InvalidSource)?
+            .clone();
 
         let entry = ring.ops.vacant_entry();
         let next_op_token = entry.key();
@@ -630,8 +630,8 @@ impl UringReactor {
         let src = ring
             .registered_sources
             .get(source.tag)
-            .map(Arc::clone)
-            .ok_or(Error::InvalidSource)?;
+            .ok_or(Error::InvalidSource)?
+            .clone();
 
         let entry = ring.ops.vacant_entry();
         let next_op_token = entry.key();
diff --git a/cros_async/src/sys/windows.rs b/cros_async/src/sys/windows.rs
index 315426f33..bb92ffca6 100644
--- a/cros_async/src/sys/windows.rs
+++ b/cros_async/src/sys/windows.rs
@@ -13,7 +13,6 @@ pub mod overlapped_source;
 mod timer;
 #[cfg(feature = "tokio")]
 pub mod tokio_source;
-pub mod wait_for_handle;
 
 pub use error::AsyncErrorSys;
 pub use executor::ExecutorKindSys;
@@ -21,7 +20,6 @@ pub use handle_executor::HandleReactor;
 pub use handle_source::HandleSource;
 pub use handle_source::HandleWrapper;
 pub use overlapped_source::OverlappedSource;
-pub(crate) use wait_for_handle::WaitForHandle;
 
 use crate::Error;
 
diff --git a/cros_async/src/sys/windows/async_types.rs b/cros_async/src/sys/windows/async_types.rs
index 46c2b5250..342556305 100644
--- a/cros_async/src/sys/windows/async_types.rs
+++ b/cros_async/src/sys/windows/async_types.rs
@@ -8,7 +8,6 @@ use std::sync::Mutex;
 
 use base::AsRawDescriptor;
 use base::Descriptor;
-use base::ReadNotifier;
 use base::Tube;
 use base::TubeError;
 use base::TubeResult;
@@ -27,8 +26,9 @@ pub struct AsyncTube {
 
 impl AsyncTube {
     pub fn new(ex: &Executor, tube: Tube) -> io::Result<AsyncTube> {
-        let read_notifier = EventAsync::clone_raw_without_reset(tube.get_read_notifier(), ex)
-            .map_err(|e| io::Error::new(io::ErrorKind::Other, e))?;
+        let read_notifier =
+            EventAsync::new_without_reset(tube.get_read_notifier_event().try_clone()?, ex)
+                .map_err(|e| io::Error::new(io::ErrorKind::Other, e))?;
         let inner = Arc::new(Mutex::new(tube));
         Ok(AsyncTube {
             inner,
diff --git a/cros_async/src/sys/windows/handle_source.rs b/cros_async/src/sys/windows/handle_source.rs
index f6885677c..13553e5b5 100644
--- a/cros_async/src/sys/windows/handle_source.rs
+++ b/cros_async/src/sys/windows/handle_source.rs
@@ -52,7 +52,7 @@ pub enum Error {
     #[error("An error occurred trying to duplicate source handles: {0}.")]
     HandleDuplicationFailed(io::Error),
     #[error("An error occurred trying to wait on source handles: {0}.")]
-    HandleWaitFailed(base::Error),
+    HandleWaitFailed(io::Error),
     #[error("An error occurred trying to get a VolatileSlice into BackingMemory: {0}.")]
     BackingMemoryVolatileSliceFetchFailed(crate::mem::Error),
     #[error("HandleSource is gone, so no handles are available to fulfill the IO request.")]
@@ -74,7 +74,7 @@ impl From<Error> for io::Error {
             IoPunchHoleError(e) => e,
             IoWriteZeroesError(e) => e,
             HandleDuplicationFailed(e) => e,
-            HandleWaitFailed(e) => e.into(),
+            HandleWaitFailed(e) => e,
             BackingMemoryVolatileSliceFetchFailed(e) => io::Error::new(io::ErrorKind::Other, e),
             NoHandleSource => io::Error::new(io::ErrorKind::Other, NoHandleSource),
             OperationCancelled => io::Error::new(io::ErrorKind::Interrupted, OperationCancelled),
@@ -330,7 +330,7 @@ impl<F: AsRawDescriptor> HandleSource<F> {
             .blocking_pool
             .spawn(
                 move || {
-                    let mut file = get_thread_file(descriptors);
+                    let file = get_thread_file(descriptors);
                     // ZeroRange calls `punch_hole` which doesn't extend the File size if it needs
                     // to. Will fix if it becomes a problem.
                     file.write_zeroes_at(file_offset, len as usize)
@@ -385,8 +385,10 @@ impl<F: AsRawDescriptor> HandleSource<F> {
 
     /// If sources are not interchangeable, behavior is undefined.
     pub async fn wait_for_handle(&self) -> AsyncResult<()> {
-        let waiter = super::WaitForHandle::new(&self.source);
-        Ok(waiter.await?)
+        base::sys::windows::async_wait_for_single_object(&self.source)
+            .await
+            .map_err(Error::HandleWaitFailed)?;
+        Ok(())
     }
 }
 
diff --git a/cros_async/src/sys/windows/overlapped_source.rs b/cros_async/src/sys/windows/overlapped_source.rs
index 065018772..1ade8b889 100644
--- a/cros_async/src/sys/windows/overlapped_source.rs
+++ b/cros_async/src/sys/windows/overlapped_source.rs
@@ -345,7 +345,7 @@ impl<F: AsRawDescriptor> OverlappedSource<F> {
         }
         // SAFETY:
         // Safe because self.source lives as long as file.
-        let mut file = ManuallyDrop::new(unsafe {
+        let file = ManuallyDrop::new(unsafe {
             File::from_raw_descriptor(self.source.as_raw_descriptor())
         });
         // ZeroRange calls `punch_hole` which doesn't extend the File size if it needs to.
@@ -400,8 +400,10 @@ impl<F: AsRawDescriptor> OverlappedSource<F> {
     }
 
     pub async fn wait_for_handle(&self) -> AsyncResult<()> {
-        let waiter = super::WaitForHandle::new(&self.source);
-        Ok(waiter.await?)
+        base::sys::windows::async_wait_for_single_object(&self.source)
+            .await
+            .map_err(super::handle_source::Error::HandleWaitFailed)?;
+        Ok(())
     }
 }
 
@@ -429,7 +431,6 @@ mod tests {
 
     fn open_overlapped(path: &PathBuf) -> File {
         OpenOptions::new()
-            .create(true)
             .read(true)
             .write(true)
             .custom_flags(FILE_FLAG_OVERLAPPED)
@@ -437,11 +438,12 @@ mod tests {
             .unwrap()
     }
 
-    fn open_blocking(path: &PathBuf) -> File {
+    fn create_overlapped(path: &PathBuf) -> File {
         OpenOptions::new()
-            .create(true)
+            .create_new(true)
             .read(true)
             .write(true)
+            .custom_flags(FILE_FLAG_OVERLAPPED)
             .open(path)
             .unwrap()
     }
@@ -449,10 +451,7 @@ mod tests {
     #[test]
     fn test_read_vec() {
         let (file_path, _tmpdir) = tempfile_path();
-        let mut f = open_blocking(&file_path);
-        f.write_all("data".as_bytes()).unwrap();
-        f.flush().unwrap();
-        drop(f);
+        std::fs::write(&file_path, "data").unwrap();
 
         async fn read_data(src: &OverlappedSource<File>) {
             let buf: Vec<u8> = vec![0; 4];
@@ -469,10 +468,7 @@ mod tests {
     #[test]
     fn test_read_mem() {
         let (file_path, _tmpdir) = tempfile_path();
-        let mut f = open_blocking(&file_path);
-        f.write_all("data".as_bytes()).unwrap();
-        f.flush().unwrap();
-        drop(f);
+        std::fs::write(&file_path, "data").unwrap();
 
         async fn read_data(src: &OverlappedSource<File>) {
             let mem = Arc::new(VecIoWrapper::from(vec![0; 4]));
@@ -513,15 +509,13 @@ mod tests {
         }
 
         let ex = RawExecutor::<HandleReactor>::new().unwrap();
-        let f = open_overlapped(&file_path);
+        let f = create_overlapped(&file_path);
         let src = OverlappedSource::new(f, &ex, false).unwrap();
         ex.run_until(write_data(&src)).unwrap();
         drop(src);
 
-        let mut buf = vec![0; 4];
-        let mut f = open_blocking(&file_path);
-        f.read_exact(&mut buf).unwrap();
-        assert_eq!(std::str::from_utf8(buf.as_slice()).unwrap(), "data");
+        let buf = std::fs::read(&file_path).unwrap();
+        assert_eq!(buf, b"data");
     }
 
     #[test]
@@ -551,25 +545,20 @@ mod tests {
         }
 
         let ex = RawExecutor::<HandleReactor>::new().unwrap();
-        let f = open_overlapped(&file_path);
+        let f = create_overlapped(&file_path);
         let src = OverlappedSource::new(f, &ex, false).unwrap();
         ex.run_until(write_data(&src)).unwrap();
         drop(src);
 
-        let mut buf = vec![0; 4];
-        let mut f = open_blocking(&file_path);
-        f.read_exact(&mut buf).unwrap();
-        assert_eq!(std::str::from_utf8(buf.as_slice()).unwrap(), "data");
+        let buf = std::fs::read(&file_path).unwrap();
+        assert_eq!(buf, b"data");
     }
 
     #[cfg_attr(all(target_os = "windows", target_env = "gnu"), ignore)]
     #[test]
     fn test_punch_holes() {
         let (file_path, _tmpdir) = tempfile_path();
-        let mut temp_file = open_blocking(&file_path);
-        temp_file.write_all("abcdefghijk".as_bytes()).unwrap();
-        temp_file.flush().unwrap();
-        drop(temp_file);
+        std::fs::write(&file_path, "abcdefghijk").unwrap();
 
         async fn punch_hole(src: &OverlappedSource<File>) {
             let offset = 1;
@@ -583,13 +572,8 @@ mod tests {
         ex.run_until(punch_hole(&src)).unwrap();
         drop(src);
 
-        let mut buf = vec![0; 11];
-        let mut f = open_blocking(&file_path);
-        f.read_exact(&mut buf).unwrap();
-        assert_eq!(
-            std::str::from_utf8(buf.as_slice()).unwrap(),
-            "a\0\0\0efghijk"
-        );
+        let buf = std::fs::read(&file_path).unwrap();
+        assert_eq!(buf, b"a\0\0\0efghijk");
     }
 
     /// Test should fail because punch hole should not be allowed to allocate more memory
@@ -597,10 +581,7 @@ mod tests {
     #[test]
     fn test_punch_holes_fail_out_of_bounds() {
         let (file_path, _tmpdir) = tempfile_path();
-        let mut temp_file = open_blocking(&file_path);
-        temp_file.write_all("abcdefghijk".as_bytes()).unwrap();
-        temp_file.flush().unwrap();
-        drop(temp_file);
+        std::fs::write(&file_path, "abcdefghijk").unwrap();
 
         async fn punch_hole(src: &OverlappedSource<File>) {
             let offset = 9;
@@ -615,7 +596,11 @@ mod tests {
         drop(src);
 
         let mut buf = vec![0; 13];
-        let mut f = open_blocking(&file_path);
+        let mut f = OpenOptions::new()
+            .read(true)
+            .write(true)
+            .open(&file_path)
+            .unwrap();
         assert!(f.read_exact(&mut buf).is_err());
     }
 
diff --git a/cros_async/src/sys/windows/tokio_source.rs b/cros_async/src/sys/windows/tokio_source.rs
index 676edb7c2..7af52d6cf 100644
--- a/cros_async/src/sys/windows/tokio_source.rs
+++ b/cros_async/src/sys/windows/tokio_source.rs
@@ -212,8 +212,8 @@ impl<T: AsRawDescriptor> TokioSource<T> {
         unimplemented!();
     }
     pub async fn wait_for_handle(&self) -> AsyncResult<()> {
-        let waiter = super::wait_for_handle::WaitForHandle::new(self.source.as_ref().unwrap());
-        Ok(waiter.await?)
+        base::sys::windows::async_wait_for_single_object(self.source.as_ref().unwrap()).await?;
+        Ok(())
     }
     pub async fn write_from_mem(
         &self,
diff --git a/cros_async/src/timer.rs b/cros_async/src/timer.rs
index 2c47deabf..d2af8d12c 100644
--- a/cros_async/src/timer.rs
+++ b/cros_async/src/timer.rs
@@ -33,11 +33,14 @@ impl<T: TimerTrait + IntoAsync> TimerAsync<T> {
         self.wait_sys().await
     }
 
-    /// Sets the timer to expire after `dur`.  If `interval` is not `None` and non-zero it
-    /// represents the period for repeated expirations after the initial expiration.  Otherwise
-    /// the timer will expire just once.  Cancels any existing duration and repeating interval.
-    pub fn reset(&mut self, dur: Duration, interval: Option<Duration>) -> SysResult<()> {
-        self.io_source.as_source_mut().reset(dur, interval)
+    /// Sets the timer to expire after `dur`. Cancels any existing timer.
+    pub fn reset_oneshot(&mut self, dur: Duration) -> SysResult<()> {
+        self.io_source.as_source_mut().reset_oneshot(dur)
+    }
+
+    /// Sets the timer to expire repeatedly at intervals of `dur`. Cancels any existing timer.
+    pub fn reset_repeating(&mut self, dur: Duration) -> SysResult<()> {
+        self.io_source.as_source_mut().reset_repeating(dur)
     }
 
     /// Disarms the timer.
@@ -53,7 +56,7 @@ impl TimerAsync<Timer> {
     /// for details.
     pub async fn sleep(ex: &Executor, dur: Duration) -> std::result::Result<(), Error> {
         let mut tfd = Timer::new().map_err(Error::Timer)?;
-        tfd.reset(dur, None).map_err(Error::Timer)?;
+        tfd.reset_oneshot(dur).map_err(Error::Timer)?;
         let t = TimerAsync::new(tfd, ex).map_err(Error::TimerAsync)?;
         t.wait().await.map_err(Error::TimerAsync)?;
         Ok(())
diff --git a/cros_fdt/Android.bp b/cros_fdt/Android.bp
index 73c4d15ae..d25785f3b 100644
--- a/cros_fdt/Android.bp
+++ b/cros_fdt/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "cros_fdt",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -41,7 +41,7 @@ rust_library {
     crate_name: "cros_fdt",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/cros_fdt/Cargo.toml b/cros_fdt/Cargo.toml
index 836e6c852..6ba39ba38 100644
--- a/cros_fdt/Cargo.toml
+++ b/cros_fdt/Cargo.toml
@@ -5,7 +5,7 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
-indexmap = "*"
-remain = "*"
+anyhow = "1"
+indexmap = "1"
+remain = "0.2"
 thiserror = "1.0.20"
diff --git a/cros_fdt/src/overlay.rs b/cros_fdt/src/overlay.rs
index 5b685a40d..9068820d4 100644
--- a/cros_fdt/src/overlay.rs
+++ b/cros_fdt/src/overlay.rs
@@ -161,7 +161,7 @@ fn do_overlay_filter(filtered_paths: Vec<Path>, overlay: &mut Fdt) {
             tgt_node = tgt_node
                 .subnode_mut(node_name)
                 .expect("filtered paths reference valid nodes");
-            tgt_node.props = src_node.props.clone();
+            tgt_node.props.clone_from(&src_node.props);
         }
     }
     overlay.root = new_root;
diff --git a/cros_tracing/Android.bp b/cros_tracing/Android.bp
index b132421c1..ab9f7dd0e 100644
--- a/cros_tracing/Android.bp
+++ b/cros_tracing/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "cros_tracing",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/cros_tracing/Cargo.toml b/cros_tracing/Cargo.toml
index 4036d0c92..591171b06 100644
--- a/cros_tracing/Cargo.toml
+++ b/cros_tracing/Cargo.toml
@@ -17,8 +17,8 @@ trace_marker = []
 perfetto = ["dep:perfetto"]
 
 [dependencies]
-anyhow = "*"
-base = "*"
+anyhow = "1"
+base = { path = "../base" }
 cfg-if = "1.0.0"
 cros_tracing_types = { path = "../cros_tracing_types" }
 perfetto = { path = "../perfetto", optional = true }
diff --git a/cros_tracing_types/Android.bp b/cros_tracing_types/Android.bp
index fb9a25ba5..391ec1729 100644
--- a/cros_tracing_types/Android.bp
+++ b/cros_tracing_types/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "cros_tracing_types",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/cros_tracing_types/Cargo.toml b/cros_tracing_types/Cargo.toml
index cf9da2b4d..9888279c6 100644
--- a/cros_tracing_types/Cargo.toml
+++ b/cros_tracing_types/Cargo.toml
@@ -5,5 +5,5 @@ authors = ["The Chromium OS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 sync = { path = "../common/sync" }
diff --git a/crosvm_cli/Android.bp b/crosvm_cli/Android.bp
index ba356984c..c8cd17453 100644
--- a/crosvm_cli/Android.bp
+++ b/crosvm_cli/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "crosvm_cli",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/crosvm_cli/Cargo.toml b/crosvm_cli/Cargo.toml
index cb351f84d..b5bbac5bb 100644
--- a/crosvm_cli/Cargo.toml
+++ b/crosvm_cli/Cargo.toml
@@ -12,4 +12,4 @@ cfg-if = "1.0.0"
 
 [target.'cfg(windows)'.dependencies]
 win_util = { path = "../win_util" }
-winapi = "*"
+winapi = "0.3"
diff --git a/crosvm_cli/src/sys/windows/exit.rs b/crosvm_cli/src/sys/windows/exit.rs
index e6cc23a3a..9bdc0f715 100644
--- a/crosvm_cli/src/sys/windows/exit.rs
+++ b/crosvm_cli/src/sys/windows/exit.rs
@@ -337,7 +337,6 @@ pub enum Exit {
     ConnectTube = 0xE0000064,
     BalloonDeviceNew = 0xE0000065,
     BalloonStats = 0xE0000066,
-    BorrowVfioContainer = 0xE0000067,
     OpenCompositeFooterFile = 0xE0000068,
     OpenCompositeHeaderFile = 0xE0000069,
     OpenCompositeImageFile = 0xE0000070,
diff --git a/crosvm_control/Android.bp b/crosvm_control/Android.bp
index abed499c9..8d3755aae 100644
--- a/crosvm_control/Android.bp
+++ b/crosvm_control/Android.bp
@@ -19,9 +19,10 @@ rust_ffi_shared {
     crate_name: "crosvm_control",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
+        "libballoon_control",
         "libbase_rust",
         "liblibc",
         "libswap",
@@ -41,9 +42,10 @@ rust_ffi_static {
     crate_name: "crosvm_control",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
+        "libballoon_control",
         "libbase_rust",
         "liblibc",
         "libswap",
diff --git a/crosvm_control/Cargo.toml b/crosvm_control/Cargo.toml
index 4c466a7f9..c09ab8d6e 100644
--- a/crosvm_control/Cargo.toml
+++ b/crosvm_control/Cargo.toml
@@ -12,13 +12,14 @@ registered_events = ["vm_control/registered_events"]
 crate-type = ["cdylib", "staticlib"]
 
 [dependencies]
+balloon_control = { path = "../common/balloon_control" }
 base = { path = "../base" }
 libc = "0.2.65"
 swap = { path = "../swap", default-features = false }
 vm_control = { path = "../vm_control", features = [ "balloon" ] }
 
 [build-dependencies]
-anyhow = "*"
+anyhow = "1"
 cbindgen = "0.24.3"
-cc = "*"
-tempfile = "*"
+cc = "1"
+tempfile = "3"
diff --git a/crosvm_control/src/lib.rs b/crosvm_control/src/lib.rs
index 11368eccd..687c3c031 100644
--- a/crosvm_control/src/lib.rs
+++ b/crosvm_control/src/lib.rs
@@ -9,7 +9,13 @@
 //!
 //! Downstream projects rely on this library maintaining a stable API surface.
 //! Do not make changes to this library without consulting the crosvm externalization team.
-//! Email: crosvm-dev@chromium.org
+//! Email: <crosvm-dev@chromium.org>
+//!
+//! The API of this library should remain the same regardless of which crosvm features are enabled.
+//! Any missing functionality should be handled by returning an error at runtime, not conditional
+//! compilation, so that users can rely on the the same set of functions with the same prototypes
+//! regardless of how crosvm is configured.
+//!
 //! For more information see:
 //! <https://crosvm.dev/book/running_crosvm/programmatic_interaction.html#usage>
 
@@ -19,24 +25,32 @@ use std::ffi::CStr;
 use std::panic::catch_unwind;
 use std::path::Path;
 use std::path::PathBuf;
-#[cfg(any(target_os = "android", target_os = "linux"))]
 use std::time::Duration;
 
+use balloon_control::BalloonStats;
+use balloon_control::BalloonWS;
+use balloon_control::WSBucket;
 use libc::c_char;
 use libc::ssize_t;
 pub use swap::SwapStatus;
-use vm_control::client::*;
+use vm_control::client::do_modify_battery;
+use vm_control::client::do_net_add;
+use vm_control::client::do_net_remove;
+use vm_control::client::do_security_key_attach;
+use vm_control::client::do_usb_attach;
+use vm_control::client::do_usb_detach;
+use vm_control::client::do_usb_list;
+use vm_control::client::handle_request;
+use vm_control::client::handle_request_with_timeout;
+use vm_control::client::vms_request;
 use vm_control::BalloonControlCommand;
-use vm_control::BalloonStats;
-use vm_control::BalloonWS;
 use vm_control::DiskControlCommand;
-#[cfg(feature = "registered_events")]
 use vm_control::RegisteredEvent;
+use vm_control::SwapCommand;
 use vm_control::UsbControlAttachedDevice;
 use vm_control::UsbControlResult;
 use vm_control::VmRequest;
 use vm_control::VmResponse;
-use vm_control::WSBucket;
 use vm_control::USB_CONTROL_MAX_PORTS;
 
 pub const VIRTIO_BALLOON_WS_MAX_NUM_BINS: usize = 16;
@@ -172,7 +186,6 @@ pub unsafe extern "C" fn crosvm_client_balloon_vms(
 /// Function is unsafe due to raw pointer usage - a null pointer could be passed in. Usage of
 /// !raw_pointer.is_null() checks should prevent unsafe behavior but the caller should ensure no
 /// null pointers are passed.
-#[cfg(any(target_os = "android", target_os = "linux"))]
 #[no_mangle]
 pub unsafe extern "C" fn crosvm_client_balloon_vms_wait_with_timeout(
     socket_path: *const c_char,
@@ -398,7 +411,7 @@ pub unsafe extern "C" fn crosvm_client_usb_list(
             if entries.is_null() {
                 return -1;
             }
-            if let Ok(UsbControlResult::Devices(res)) = do_usb_list(&socket_path) {
+            if let Ok(UsbControlResult::Devices(res)) = do_usb_list(socket_path) {
                 let mut i = 0;
                 for entry in res.iter().filter(|x| x.valid()) {
                     if i >= entries_length {
@@ -772,13 +785,7 @@ pub unsafe extern "C" fn crosvm_client_balloon_stats(
     stats: *mut BalloonStatsFfi,
     actual: *mut u64,
 ) -> bool {
-    crosvm_client_balloon_stats_impl(
-        socket_path,
-        #[cfg(any(target_os = "android", target_os = "linux"))]
-        None,
-        stats,
-        actual,
-    )
+    crosvm_client_balloon_stats_impl(socket_path, None, stats, actual)
 }
 
 /// See crosvm_client_balloon_stats.
@@ -788,7 +795,6 @@ pub unsafe extern "C" fn crosvm_client_balloon_stats(
 /// Function is unsafe due to raw pointer usage - a null pointer could be passed in. Usage of
 /// !raw_pointer.is_null() checks should prevent unsafe behavior but the caller should ensure no
 /// null pointers are passed.
-#[cfg(any(target_os = "android", target_os = "linux"))]
 #[no_mangle]
 pub unsafe extern "C" fn crosvm_client_balloon_stats_with_timeout(
     socket_path: *const c_char,
@@ -806,16 +812,13 @@ pub unsafe extern "C" fn crosvm_client_balloon_stats_with_timeout(
 
 fn crosvm_client_balloon_stats_impl(
     socket_path: *const c_char,
-    #[cfg(any(target_os = "android", target_os = "linux"))] timeout_ms: Option<Duration>,
+    timeout_ms: Option<Duration>,
     stats: *mut BalloonStatsFfi,
     actual: *mut u64,
 ) -> bool {
     catch_unwind(|| {
         if let Some(socket_path) = validate_socket_path(socket_path) {
             let request = &VmRequest::BalloonCommand(BalloonControlCommand::Stats {});
-            #[cfg(not(unix))]
-            let resp = handle_request(request, socket_path);
-            #[cfg(any(target_os = "android", target_os = "linux"))]
             let resp = handle_request_with_timeout(request, socket_path, timeout_ms);
             if let Ok(VmResponse::BalloonStats {
                 stats: ref balloon_stats,
@@ -978,19 +981,14 @@ pub unsafe extern "C" fn crosvm_client_balloon_working_set(
 
 /// Publically exposed version of RegisteredEvent enum, implemented as an
 /// integral newtype for FFI safety.
-#[cfg(feature = "registered_events")]
 #[repr(C)]
 #[derive(Copy, Clone, PartialEq, Eq)]
 pub struct RegisteredEventFfi(u32);
 
-#[cfg(feature = "registered_events")]
 pub const REGISTERED_EVENT_VIRTIO_BALLOON_WS_REPORT: RegisteredEventFfi = RegisteredEventFfi(0);
-#[cfg(feature = "registered_events")]
 pub const REGISTERED_EVENT_VIRTIO_BALLOON_RESIZE: RegisteredEventFfi = RegisteredEventFfi(1);
-#[cfg(feature = "registered_events")]
 pub const REGISTERED_EVENT_VIRTIO_BALLOON_OOM_DEFLATION: RegisteredEventFfi = RegisteredEventFfi(2);
 
-#[cfg(feature = "registered_events")]
 impl TryFrom<RegisteredEventFfi> for RegisteredEvent {
     type Error = &'static str;
 
@@ -1013,7 +1011,6 @@ impl TryFrom<RegisteredEventFfi> for RegisteredEvent {
 /// Function is unsafe due to raw pointer usage - a null pointer could be passed in. Usage of
 /// !raw_pointer.is_null() checks should prevent unsafe behavior but the caller should ensure no
 /// null pointers are passed.
-#[cfg(feature = "registered_events")]
 #[no_mangle]
 pub unsafe extern "C" fn crosvm_client_register_events_listener(
     socket_path: *const c_char,
@@ -1051,7 +1048,6 @@ pub unsafe extern "C" fn crosvm_client_register_events_listener(
 /// Function is unsafe due to raw pointer usage - a null pointer could be passed in. Usage of
 /// !raw_pointer.is_null() checks should prevent unsafe behavior but the caller should ensure no
 /// null pointers are passed.
-#[cfg(feature = "registered_events")]
 #[no_mangle]
 pub unsafe extern "C" fn crosvm_client_unregister_events_listener(
     socket_path: *const c_char,
@@ -1089,7 +1085,6 @@ pub unsafe extern "C" fn crosvm_client_unregister_events_listener(
 /// Function is unsafe due to raw pointer usage - a null pointer could be passed in. Usage of
 /// !raw_pointer.is_null() checks should prevent unsafe behavior but the caller should ensure no
 /// null pointers are passed.
-#[cfg(feature = "registered_events")]
 #[no_mangle]
 pub unsafe extern "C" fn crosvm_client_unregister_listener(
     socket_path: *const c_char,
diff --git a/crosvm_plugin/Cargo.toml b/crosvm_plugin/Cargo.toml
index 94f7f734f..143eb45e8 100644
--- a/crosvm_plugin/Cargo.toml
+++ b/crosvm_plugin/Cargo.toml
@@ -13,7 +13,7 @@ crate-type = ["cdylib"]
 [dependencies]
 kvm = { path = "../kvm" }
 kvm_sys = { path = "../kvm_sys" }
-libc = "*"
+libc = "0.2"
 protobuf = "3.2"
 protos = { path = "../protos", features = ["plugin"] }
 base = { path = "../base" }
diff --git a/devices/Android.bp b/devices/Android.bp
index dfc59a2b2..8ca613244 100644
--- a/devices/Android.bp
+++ b/devices/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "devices",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -66,10 +66,10 @@ rust_test {
         "libfutures",
         "libgpu_display",
         "libhypervisor",
+        "libjail",
         "libkvm_sys",
         "liblibc",
         "liblinux_input_sys",
-        "libmemoffset",
         "libmetrics",
         "libminijail_rust",
         "libnamed_lock",
@@ -113,7 +113,7 @@ rust_test {
     crate_name: "irqchip",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/irqchip/main.rs"],
+    crate_root: "tests/irqchip/main.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -161,10 +161,10 @@ rust_test {
         "libfutures",
         "libgpu_display",
         "libhypervisor",
+        "libjail",
         "libkvm_sys",
         "liblibc",
         "liblinux_input_sys",
-        "libmemoffset",
         "libmetrics",
         "libminijail_rust",
         "libnamed_lock",
@@ -208,7 +208,7 @@ rust_library {
     crate_name: "devices",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "android_display",
@@ -248,10 +248,10 @@ rust_library {
         "libfutures",
         "libgpu_display",
         "libhypervisor",
+        "libjail",
         "libkvm_sys",
         "liblibc",
         "liblinux_input_sys",
-        "libmemoffset",
         "libmetrics",
         "libminijail_rust",
         "libnet_sys",
diff --git a/devices/Cargo.toml b/devices/Cargo.toml
index 86825608e..e161af4ec 100644
--- a/devices/Cargo.toml
+++ b/devices/Cargo.toml
@@ -40,7 +40,7 @@ noncoherent-dma = []
 argh = "0.1.7"
 async-task = "4"
 acpi_tables = {path = "../acpi_tables" }
-anyhow = "*"
+anyhow = "1"
 async-trait = "0.1.36"
 audio_streams = "*"
 audio_util = { path = "../audio_util" }
@@ -63,10 +63,9 @@ gpu_display = { path = "../gpu_display", optional = true }
 rutabaga_gfx = { path = "../rutabaga_gfx" }
 hypervisor = { path = "../hypervisor" }
 kvm_sys = { path = "../kvm_sys" }
-libc = "*"
+libc = "0.2"
 libvda = { path = "../media/libvda", optional = true }
 linux_input_sys = { path = "../linux_input_sys" }
-memoffset = { version = "0.6" }
 metrics = { path = "../metrics" }
 net_util = { path = "../net_util" }
 num-traits = "0.2"
@@ -75,7 +74,7 @@ power_monitor = { path = "../power_monitor" }
 protobuf = { version = "3.2", optional = true }
 protos = { path = "../protos", optional = true }
 rand = "0.8"
-remain = "*"
+remain = "0.2"
 resources = { path = "../resources" }
 serde = { version = "1", features = [ "derive", "rc" ] }
 serde_json = "1"
@@ -95,10 +94,11 @@ zerocopy = { version = "0.7", features = ["derive"] }
 [target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
 android_audio = { path = "../android_audio" }
 fuse = {path = "../fuse" }
+jail = { path = "../jail" }
 libcras = { version = "*", optional = true }
 minijail = "*"
 net_sys = { path = "../net_sys" }
-p9 = "*"
+p9 = "0.2"
 usb_util = { path = "../usb_util" }
 vfio_sys = { path = "../vfio_sys" }
 vhost = { path = "../vhost" }
@@ -108,10 +108,10 @@ broker_ipc = { path = "../broker_ipc" }
 tube_transporter = { path = "../tube_transporter" }
 win_audio = { path = "../win_audio"}
 win_util = { path = "../win_util"}
-winapi = "*"
+winapi = "0.3"
 
 [dependencies.futures]
-version = "*"
+version = "0.3"
 features = ["async-await", "std"]
 default-features = false
 
diff --git a/devices/src/acpi.rs b/devices/src/acpi.rs
index 7244e0290..7eadd2a0a 100644
--- a/devices/src/acpi.rs
+++ b/devices/src/acpi.rs
@@ -4,10 +4,8 @@
 
 use std::collections::BTreeMap;
 use std::str::FromStr;
-use std::sync::atomic::AtomicBool;
-use std::sync::atomic::Ordering;
 use std::sync::Arc;
-use std::time::Instant;
+use std::time::Duration;
 
 use acpi_tables::aml;
 use acpi_tables::aml::Aml;
@@ -19,13 +17,12 @@ use base::warn;
 use base::Error as SysError;
 use base::Event;
 use base::EventToken;
+use base::EventWaitResult;
 use base::SendTube;
 use base::Tube;
 use base::VmEventType;
 use base::WaitContext;
 use base::WorkerThread;
-use metrics::log_metric;
-use metrics::MetricEventType;
 use serde::Deserialize;
 use serde::Serialize;
 use sync::Mutex;
@@ -70,19 +67,42 @@ pub enum ACPIPMFixedEvent {
     RTC,
 }
 
-#[derive(Serialize, Deserialize, Clone)]
+#[derive(Serialize)]
 pub(crate) struct Pm1Resource {
     pub(crate) status: u16,
     enable: u16,
     control: u16,
+    #[serde(skip_serializing)]
+    suspend_tube: Arc<Mutex<SendTube>>,
+    #[serde(skip_serializing)]
+    rtc_clear_evt: Option<Event>,
 }
 
-#[derive(Serialize, Deserialize, Clone)]
+#[derive(Deserialize)]
+struct Pm1ResourceSerializable {
+    status: u16,
+    enable: u16,
+    control: u16,
+}
+
+#[derive(Serialize)]
 pub(crate) struct GpeResource {
     pub(crate) status: [u8; ACPIPM_RESOURCE_GPE0_BLK_LEN as usize / 2],
     enable: [u8; ACPIPM_RESOURCE_GPE0_BLK_LEN as usize / 2],
-    #[serde(skip_serializing, skip_deserializing)]
+    #[serde(skip_serializing)]
     pub(crate) gpe_notify: BTreeMap<u32, Vec<Arc<Mutex<dyn GpeNotify>>>>,
+    // For each triggered GPE, a vector of events to check when resampling
+    // sci_evt. If any events are un-signaled, then sci_evt should be re-asserted.
+    #[serde(skip_serializing)]
+    pending_clear_evts: BTreeMap<u32, Vec<Event>>,
+    #[serde(skip_serializing)]
+    suspend_tube: Arc<Mutex<SendTube>>,
+}
+
+#[derive(Deserialize)]
+struct GpeResourceSerializable {
+    status: [u8; ACPIPM_RESOURCE_GPE0_BLK_LEN as usize / 2],
+    enable: [u8; ACPIPM_RESOURCE_GPE0_BLK_LEN as usize / 2],
 }
 
 #[derive(Serialize, Deserialize, Clone)]
@@ -101,7 +121,7 @@ pub struct ACPIPMResource {
     #[serde(skip_serializing)]
     worker_thread: Option<WorkerThread<()>>,
     #[serde(skip_serializing)]
-    suspend_evt: Event,
+    suspend_tube: Arc<Mutex<SendTube>>,
     #[serde(skip_serializing)]
     exit_evt_wrtube: SendTube,
     #[serde(serialize_with = "serialize_arc_mutex")]
@@ -116,8 +136,8 @@ pub struct ACPIPMResource {
 
 #[derive(Deserialize)]
 struct ACPIPMResrourceSerializable {
-    pm1: Pm1Resource,
-    gpe0: GpeResource,
+    pm1: Pm1ResourceSerializable,
+    gpe0: GpeResourceSerializable,
 }
 
 impl ACPIPMResource {
@@ -125,7 +145,7 @@ impl ACPIPMResource {
     #[allow(dead_code)]
     pub fn new(
         sci_evt: IrqLevelEvent,
-        suspend_evt: Event,
+        suspend_tube: Arc<Mutex<SendTube>>,
         exit_evt_wrtube: SendTube,
         acdc: Option<Arc<Mutex<AcAdapter>>>,
     ) -> ACPIPMResource {
@@ -133,11 +153,15 @@ impl ACPIPMResource {
             status: 0,
             enable: 0,
             control: 0,
+            suspend_tube: suspend_tube.clone(),
+            rtc_clear_evt: None,
         };
         let gpe0 = GpeResource {
             status: Default::default(),
             enable: Default::default(),
             gpe_notify: BTreeMap::new(),
+            pending_clear_evts: BTreeMap::new(),
+            suspend_tube: suspend_tube.clone(),
         };
         let pci = PciResource {
             pme_notify: BTreeMap::new(),
@@ -146,7 +170,7 @@ impl ACPIPMResource {
         ACPIPMResource {
             sci_evt,
             worker_thread: None,
-            suspend_evt,
+            suspend_tube,
             exit_evt_wrtube,
             pm1: Arc::new(Mutex::new(pm1)),
             gpe0: Arc::new(Mutex::new(gpe0)),
@@ -173,6 +197,9 @@ impl ACPIPMResource {
 
 impl Suspendable for ACPIPMResource {
     fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        if !self.gpe0.lock().pending_clear_evts.is_empty() {
+            bail!("ACPIPMResource is busy");
+        }
         serde_json::to_value(&self)
             .with_context(|| format!("error serializing {}", self.debug_label()))
     }
@@ -182,7 +209,9 @@ impl Suspendable for ACPIPMResource {
             .with_context(|| format!("error deserializing {}", self.debug_label()))?;
         {
             let mut pm1 = self.pm1.lock();
-            *pm1 = acpi_snapshot.pm1;
+            pm1.status = acpi_snapshot.pm1.status;
+            pm1.enable = acpi_snapshot.pm1.enable;
+            pm1.control = acpi_snapshot.pm1.control;
         }
         {
             let mut gpe0 = self.gpe0.lock();
@@ -249,8 +278,8 @@ fn run_worker(
                     sci_evt.clear_resample();
 
                     // Re-trigger SCI if PM1 or GPE status is still not cleared.
-                    pm1.lock().trigger_sci(&sci_evt);
-                    gpe0.lock().trigger_sci(&sci_evt);
+                    pm1.lock().resample_clear_evts_and_trigger(&sci_evt);
+                    gpe0.lock().resample_clear_evts_and_trigger(&sci_evt);
                 }
                 Token::Kill => return Ok(()),
             }
@@ -264,8 +293,21 @@ impl Pm1Resource {
             if let Err(e) = sci_evt.trigger() {
                 error!("ACPIPM: failed to trigger sci event for pm1: {}", e);
             }
+            if let Err(e) = self.suspend_tube.lock().send(&false) {
+                error!("ACPIPM: failed to trigger wake event: {}", e);
+            }
         }
     }
+
+    fn resample_clear_evts_and_trigger(&mut self, sci_evt: &IrqLevelEvent) {
+        if let Some(clear_evt) = self.rtc_clear_evt.take() {
+            if clear_evt.wait_timeout(Duration::ZERO) == Ok(EventWaitResult::TimedOut) {
+                self.rtc_clear_evt = Some(clear_evt);
+                self.status |= ACPIPMFixedEvent::RTC.bitmask();
+            }
+        }
+        self.trigger_sci(sci_evt);
+    }
 }
 
 impl GpeResource {
@@ -274,6 +316,9 @@ impl GpeResource {
             if let Err(e) = sci_evt.trigger() {
                 error!("ACPIPM: failed to trigger sci event for gpe: {}", e);
             }
+            if let Err(e) = self.suspend_tube.lock().send(&false) {
+                error!("ACPIPM: failed to trigger wake event: {}", e);
+            }
         }
     }
 
@@ -285,6 +330,24 @@ impl GpeResource {
         }
         Ok(())
     }
+
+    pub fn resample_clear_evts_and_trigger(&mut self, sci_evt: &IrqLevelEvent) {
+        let mut retained = Vec::new();
+        self.pending_clear_evts.retain(|gpe, clear_evts| {
+            clear_evts.retain(|clear_evt| {
+                clear_evt.wait_timeout(Duration::ZERO) == Ok(EventWaitResult::TimedOut)
+            });
+            if !clear_evts.is_empty() {
+                retained.push(*gpe);
+            }
+            !clear_evts.is_empty()
+        });
+        for gpe in retained.into_iter() {
+            self.set_active(gpe).expect("bad gpe index");
+        }
+
+        self.trigger_sci(sci_evt);
+    }
 }
 
 /// the ACPI PM register length.
@@ -298,43 +361,43 @@ pub const ACPIPM_GPE_MAX: u16 = ACPIPM_RESOURCE_GPE0_BLK_LEN as u16 / 2 * 8 - 1;
 
 /// ACPI PM register value definitions
 
-/// 4.8.4.1.1 PM1 Status Registers, ACPI Spec Version 6.4
+/// Section 4.8.4.1.1 PM1 Status Registers, ACPI Spec Version 6.4
 /// Register Location: <PM1a_EVT_BLK / PM1b_EVT_BLK> System I/O or Memory Space (defined in FADT)
 /// Size: PM1_EVT_LEN / 2 (defined in FADT)
 const PM1_STATUS: u16 = 0;
 
-/// 4.8.4.1.2 PM1Enable Registers, ACPI Spec Version 6.4
+/// Section 4.8.4.1.2 PM1Enable Registers, ACPI Spec Version 6.4
 /// Register Location: <<PM1a_EVT_BLK / PM1b_EVT_BLK> + PM1_EVT_LEN / 2 System I/O or Memory Space
 /// (defined in FADT)
 /// Size: PM1_EVT_LEN / 2 (defined in FADT)
 const PM1_ENABLE: u16 = PM1_STATUS + (ACPIPM_RESOURCE_EVENTBLK_LEN as u16 / 2);
 
-/// 4.8.4.2.1 PM1 Control Registers, ACPI Spec Version 6.4
+/// Section 4.8.4.2.1 PM1 Control Registers, ACPI Spec Version 6.4
 /// Register Location: <PM1a_CNT_BLK / PM1b_CNT_BLK> System I/O or Memory Space (defined in FADT)
 /// Size: PM1_CNT_LEN (defined in FADT)
 const PM1_CONTROL: u16 = PM1_STATUS + ACPIPM_RESOURCE_EVENTBLK_LEN as u16;
 
-/// 4.8.5.1 General-Purpose Event Register Blocks, ACPI Spec Version 6.4
+/// Section 4.8.5.1 General-Purpose Event Register Blocks, ACPI Spec Version 6.4
 /// - Each register block contains two registers: an enable and a status register.
 /// - Each register block is 32-bit aligned.
 /// - Each register in the block is accessed as a byte.
-
-/// 4.8.5.1.1 General-Purpose Event 0 Register Block, ACPI Spec Version 6.4
+///
+/// Section 4.8.5.1.1 General-Purpose Event 0 Register Block, ACPI Spec Version 6.4
 /// This register block consists of two registers: The GPE0_STS and the GPE0_EN registers. Each
 /// registers length is defined to be half the length of the GPE0 register block, and is described
 /// in the ACPI FADTs GPE0_BLK and GPE0_BLK_LEN operators.
-
-/// 4.8.5.1.1.1 General-Purpose Event 0 Status Register, ACPI Spec Version 6.4
+///
+/// Section 4.8.5.1.1.1 General-Purpose Event 0 Status Register, ACPI Spec Version 6.4
 /// Register Location: <GPE0_STS> System I/O or System Memory Space (defined in FADT)
 /// Size: GPE0_BLK_LEN/2 (defined in FADT)
 const GPE0_STATUS: u16 = PM1_STATUS + ACPIPM_RESOURCE_EVENTBLK_LEN as u16 + 4; // ensure alignment
 
-/// 4.8.5.1.1.2 General-Purpose Event 0 Enable Register, ACPI Spec Version 6.4
+/// Section 4.8.5.1.1.2 General-Purpose Event 0 Enable Register, ACPI Spec Version 6.4
 /// Register Location: <GPE0_EN> System I/O or System Memory Space (defined in FADT)
 /// Size: GPE0_BLK_LEN/2 (defined in FADT)
 const GPE0_ENABLE: u16 = GPE0_STATUS + (ACPIPM_RESOURCE_GPE0_BLK_LEN as u16 / 2);
 
-/// 4.8.4.1.1, 4.8.4.1.2 Fixed event bits in both PM1 Status and PM1 Enable registers.
+/// Section 4.8.4.1.1, 4.8.4.1.2 Fixed event bits in both PM1 Status and PM1 Enable registers.
 const BITSHIFT_PM1_GBL: u16 = 5;
 const BITSHIFT_PM1_PWRBTN: u16 = 8;
 const BITSHIFT_PM1_SLPBTN: u16 = 9;
@@ -398,18 +461,26 @@ impl PmResource for ACPIPMResource {
         pm1.trigger_sci(&self.sci_evt);
     }
 
-    fn rtc_evt(&mut self) {
+    fn rtc_evt(&mut self, clear_evt: Event) {
         let mut pm1 = self.pm1.lock();
 
+        pm1.rtc_clear_evt = Some(clear_evt);
         pm1.status |= ACPIPMFixedEvent::RTC.bitmask();
         pm1.trigger_sci(&self.sci_evt);
     }
 
-    fn gpe_evt(&mut self, gpe: u32) {
+    fn gpe_evt(&mut self, gpe: u32, clear_evt: Option<Event>) {
         let mut gpe0 = self.gpe0.lock();
-
         match gpe0.set_active(gpe) {
-            Ok(_) => gpe0.trigger_sci(&self.sci_evt),
+            Ok(_) => {
+                if let Some(clear_evt) = clear_evt {
+                    gpe0.pending_clear_evts
+                        .entry(gpe)
+                        .or_default()
+                        .push(clear_evt);
+                }
+                gpe0.trigger_sci(&self.sci_evt)
+            }
             Err(e) => error!("{}", e),
         }
     }
@@ -564,7 +635,7 @@ impl BusDevice for ACPIPMResource {
                     v[j] = data[i];
                 }
                 pm1.enable = u16::from_ne_bytes(v);
-                pm1.trigger_sci(&self.sci_evt);
+                pm1.resample_clear_evts_and_trigger(&self.sci_evt);
             }
             PM1_CONTROL..=PM1_CONTROL_LAST => {
                 if data.len() > std::mem::size_of::<u16>()
@@ -587,7 +658,7 @@ impl BusDevice for ACPIPMResource {
                 if (val & BITMASK_PM1CNT_SLEEP_ENABLE) != 0 {
                     match val & BITMASK_PM1CNT_SLEEP_TYPE {
                         SLEEP_TYPE_S1 => {
-                            if let Err(e) = self.suspend_evt.signal() {
+                            if let Err(e) = self.suspend_tube.lock().send(&true) {
                                 error!("ACPIPM: failed to trigger suspend event: {}", e);
                             }
                         }
@@ -605,6 +676,13 @@ impl BusDevice for ACPIPMResource {
                     }
                 }
                 pm1.control = val & !BITMASK_PM1CNT_SLEEP_ENABLE;
+
+                // Re-trigger PM & GPEs in case there is a pending wakeup that should
+                // override us just having gone to sleep.
+                pm1.resample_clear_evts_and_trigger(&self.sci_evt);
+                self.gpe0
+                    .lock()
+                    .resample_clear_evts_and_trigger(&self.sci_evt);
             }
             // OSPM accesses GPE registers through byte accesses (regardless of their length)
             GPE0_STATUS..=GPE0_STATUS_LAST => {
@@ -626,8 +704,10 @@ impl BusDevice for ACPIPMResource {
                 }
                 let offset = (info.offset - GPE0_ENABLE as u64) as usize;
                 let mut gpe = self.gpe0.lock();
-                gpe.enable[offset] = data[0];
-                gpe.trigger_sci(&self.sci_evt);
+                if gpe.enable[offset] != data[0] {
+                    gpe.enable[offset] = data[0];
+                    gpe.resample_clear_evts_and_trigger(&self.sci_evt);
+                }
             }
             _ => {
                 warn!("ACPIPM: Bad write to {}", info);
@@ -663,67 +743,46 @@ impl Aml for ACPIPMResource {
 pub const PM_WAKEUP_GPIO: u32 = 0;
 
 pub struct PmWakeupEvent {
-    active: AtomicBool,
     vm_control_tube: Arc<Mutex<Tube>>,
     pm_config: Arc<Mutex<PmConfig>>,
-    metrics_event: MetricEventType,
-    armed_time: Arc<Mutex<Instant>>,
 }
 
 impl PmWakeupEvent {
-    pub fn new(
-        vm_control_tube: Arc<Mutex<Tube>>,
-        pm_config: Arc<Mutex<PmConfig>>,
-        metrics_event: MetricEventType,
-    ) -> Self {
+    pub fn new(vm_control_tube: Arc<Mutex<Tube>>, pm_config: Arc<Mutex<PmConfig>>) -> Self {
         Self {
-            active: AtomicBool::new(false),
             vm_control_tube,
             pm_config,
-            metrics_event,
-            // Not actually armed, but simpler than wrapping with an Option.
-            armed_time: Arc::new(Mutex::new(Instant::now())),
         }
     }
 
-    pub fn trigger_wakeup(&self) -> anyhow::Result<()> {
-        if self.active.load(Ordering::SeqCst) && self.pm_config.lock().should_trigger_pme() {
-            let elapsed = self.armed_time.lock().elapsed().as_millis();
-            log_metric(
-                self.metrics_event.clone(),
-                elapsed.try_into().unwrap_or(i64::MAX),
-            );
-
+    pub fn trigger_wakeup(&self) -> anyhow::Result<Option<Event>> {
+        if self.pm_config.lock().should_trigger_pme() {
+            let event = Event::new().context("failed to create clear event")?;
             let tube = self.vm_control_tube.lock();
-            tube.send(&VmRequest::Gpe(PM_WAKEUP_GPIO))
-                .with_context(|| format!("{:?} failed to send pme", self.metrics_event))?;
+            tube.send(&VmRequest::Gpe {
+                gpe: PM_WAKEUP_GPIO,
+                clear_evt: Some(event.try_clone().context("failed to clone clear event")?),
+            })
+            .context("failed to send pme")?;
             match tube.recv::<VmResponse>() {
-                Ok(VmResponse::Ok) => (),
-                e => bail!("{:?} pme failure {:?}", self.metrics_event, e),
+                Ok(VmResponse::Ok) => Ok(Some(event)),
+                e => bail!("pme failure {:?}", e),
             }
-        }
-        Ok(())
-    }
-
-    pub fn set_active(&self, active: bool) {
-        self.active.store(active, Ordering::SeqCst);
-        if active {
-            *self.armed_time.lock() = Instant::now();
+        } else {
+            Ok(None)
         }
     }
 }
 
 #[cfg(test)]
 mod tests {
-    use base::SendTube;
     use base::Tube;
 
     use super::*;
     use crate::suspendable_tests;
 
-    fn get_evt_tube() -> SendTube {
-        let (vm_evt_wrtube, _) = Tube::directional_pair().unwrap();
-        vm_evt_wrtube
+    fn get_send_tube() -> SendTube {
+        Tube::directional_pair().unwrap().0
     }
 
     fn get_irq_evt() -> IrqLevelEvent {
@@ -745,7 +804,12 @@ mod tests {
 
     suspendable_tests!(
         acpi,
-        ACPIPMResource::new(get_irq_evt(), Event::new().unwrap(), get_evt_tube(), None,),
+        ACPIPMResource::new(
+            get_irq_evt(),
+            Arc::new(Mutex::new(get_send_tube())),
+            get_send_tube(),
+            None,
+        ),
         modify_device
     );
 }
diff --git a/devices/src/bus.rs b/devices/src/bus.rs
index 44a2c5f41..755e7e9e7 100644
--- a/devices/src/bus.rs
+++ b/devices/src/bus.rs
@@ -12,13 +12,13 @@ use std::collections::BTreeMap;
 use std::collections::BTreeSet;
 use std::fmt;
 use std::result;
-use std::sync::mpsc;
 use std::sync::Arc;
 
 use anyhow::anyhow;
 use anyhow::Context;
 use base::debug;
 use base::error;
+use base::Event;
 use base::SharedMemory;
 use remain::sorted;
 use serde::Deserialize;
@@ -211,15 +211,18 @@ pub enum HotPlugKey {
 /// Trait for devices that notify hotplug event into guest
 pub trait HotPlugBus: Send {
     /// Request hot plug event. Returns error if the request is not sent. Upon success, optionally
-    /// returns a notification receiver, where a notification is sent when the guest OS completes
-    /// the request (by sending PCI_EXP_SLTCTL_CCIE). Returns None if no such mechanism is provided.
+    /// returns an event, which is triggerred once when the guest OS completes the request (by
+    /// sending PCI_EXP_SLTCTL_CCIE). Returns None if no such mechanism is provided.
     /// * 'addr' - the guest pci address for hotplug in device
-    fn hot_plug(&mut self, addr: PciAddress) -> anyhow::Result<Option<mpsc::Receiver<()>>>;
+    fn hot_plug(&mut self, addr: PciAddress) -> anyhow::Result<Option<Event>>;
     /// Request hot unplug event. Returns error if the request is not sent. Upon success, optionally
-    /// returns a notification receiver, where a notification is sent when the guest OS completes
-    /// the request (by sending PCI_EXP_SLTCTL_CCIE). Returns None if no such mechanism is provided.
+    /// returns an event, which is triggerred once when the guest OS completes the request (by
+    /// sending PCI_EXP_SLTCTL_CCIE). Returns None if no such mechanism is provided.
     /// * 'addr' - the guest pci address for hotplug out device
-    fn hot_unplug(&mut self, addr: PciAddress) -> anyhow::Result<Option<mpsc::Receiver<()>>>;
+    fn hot_unplug(&mut self, addr: PciAddress) -> anyhow::Result<Option<Event>>;
+    /// Get a notification event when the HotPlugBus is ready for hot plug commands. If the port is
+    /// already ready, then the notification event is triggerred immediately.
+    fn get_ready_notification(&mut self) -> anyhow::Result<Event>;
     /// Check whether the hotplug bus is available to add the new device
     ///
     /// - 'None': hotplug bus isn't match with host pci device
diff --git a/devices/src/cmos.rs b/devices/src/cmos.rs
index 0f99c1615..4ebe215b1 100644
--- a/devices/src/cmos.rs
+++ b/devices/src/cmos.rs
@@ -74,62 +74,64 @@ const RTC_REG_D_VRT: u8 = 0x80; // RAM and time valid
 
 pub type CmosNowFn = fn() -> DateTime<Utc>;
 
-/// A CMOS/RTC device commonly seen on x86 I/O port 0x70/0x71.
-#[derive(Serialize)]
-pub struct Cmos {
-    index: u8,
-    #[serde(serialize_with = "serialize_arr")]
-    data: [u8; DATA_LEN],
-    #[serde(skip_serializing)] // skip serializing time function.
-    now_fn: CmosNowFn,
-    #[serde(skip_serializing)] // skip serializing the timer
-    alarm: Arc<Mutex<Timer>>,
-    alarm_time: Option<DateTime<Utc>>,
-    #[serde(skip_serializing)] // skip serializing the alarm function
-    alarm_fn: Option<AlarmFn>,
-    #[serde(skip_serializing)] // skip serializing the worker thread
-    worker: Option<WorkerThread<AlarmFn>>,
-    #[serde(skip_serializing)] // skip serializing the armed time
-    armed_time: Option<Arc<Mutex<Instant>>>,
-}
-
-struct AlarmFn {
-    irq: IrqEdgeEvent,
+// Alarm state shared between Cmos and the alarm worker thread.
+struct AlarmState {
+    alarm: Timer,
     vm_control: Tube,
-    armed_time: Arc<Mutex<Instant>>,
+    irq: IrqEdgeEvent,
+    armed_time: Instant,
+    clear_evt: Option<Event>,
 }
 
-impl AlarmFn {
-    fn new(irq: IrqEdgeEvent, vm_control: Tube) -> Self {
-        Self {
-            irq,
-            vm_control,
-            // Not actually armed, but simpler than wrapping with an Option.
-            armed_time: Arc::new(Mutex::new(Instant::now())),
-        }
-    }
-
-    fn fire(&self) -> anyhow::Result<()> {
+impl AlarmState {
+    fn trigger_rtc_interrupt(&self) -> anyhow::Result<Event> {
         self.irq.trigger().context("failed to trigger irq")?;
 
-        let elapsed = self.armed_time.lock().elapsed().as_millis();
+        let elapsed = self.armed_time.elapsed().as_millis();
         log_metric(
             MetricEventType::RtcWakeup,
             elapsed.try_into().unwrap_or(i64::MAX),
         );
 
+        let msg = vm_control::VmRequest::Rtc {
+            clear_evt: Event::new().context("failed to create clear event")?,
+        };
+
         // The Linux kernel expects wakeups to come via ACPI when ACPI is enabled. There's
         // no real way to determine that here, so just send this unconditionally.
-        self.vm_control
-            .send(&vm_control::VmRequest::Rtc)
-            .context("send failed")?;
+        self.vm_control.send(&msg).context("send failed")?;
+
+        let vm_control::VmRequest::Rtc { clear_evt } = msg else {
+            unreachable!("message type failure");
+        };
+
         match self.vm_control.recv().context("recv failed")? {
-            VmResponse::Ok => Ok(()),
+            VmResponse::Ok => Ok(clear_evt),
             resp => Err(anyhow!("unexpected rtc response: {:?}", resp)),
         }
     }
 }
 
+/// A CMOS/RTC device commonly seen on x86 I/O port 0x70/0x71.
+#[derive(Serialize)]
+pub struct Cmos {
+    index: u8,
+    #[serde(serialize_with = "serialize_arr")]
+    data: [u8; DATA_LEN],
+    #[serde(skip_serializing)] // skip serializing time function.
+    now_fn: CmosNowFn,
+    // alarm_time is re-loaded from data on deserialization, so there's
+    // no need to explicitly serialize it.
+    #[serde(skip_serializing)]
+    alarm_time: Option<DateTime<Utc>>,
+    // alarm_state fields are either constant across snapshotting or
+    // reloaded from |data| on restore, so no need to serialize.
+    #[serde(skip_serializing)]
+    alarm_state: Arc<Mutex<AlarmState>>,
+    #[serde(skip_serializing)] // skip serializing the worker thread
+    worker: Option<WorkerThread<()>>,
+}
+
 impl Cmos {
     /// Constructs a CMOS/RTC device with initial data.
     /// `mem_below_4g` is the size of memory in bytes below the 32-bit gap.
@@ -141,20 +143,6 @@ impl Cmos {
         now_fn: CmosNowFn,
         vm_control: Tube,
         irq: IrqEdgeEvent,
-    ) -> anyhow::Result<Cmos> {
-        Self::new_inner(
-            mem_below_4g,
-            mem_above_4g,
-            now_fn,
-            Some(AlarmFn::new(irq, vm_control)),
-        )
-    }
-
-    fn new_inner(
-        mem_below_4g: u64,
-        mem_above_4g: u64,
-        now_fn: CmosNowFn,
-        alarm_fn: Option<AlarmFn>,
     ) -> anyhow::Result<Cmos> {
         let mut data = [0u8; DATA_LEN];
 
@@ -174,31 +162,33 @@ impl Cmos {
         data[0x5c] = (high_mem >> 8) as u8;
         data[0x5d] = (high_mem >> 16) as u8;
 
-        let armed_time = alarm_fn.as_ref().map(|a| a.armed_time.clone());
         Ok(Cmos {
             index: 0,
             data,
             now_fn,
-            alarm: Arc::new(Mutex::new(Timer::new().context("cmos timer")?)),
             alarm_time: None,
-            alarm_fn,
+            alarm_state: Arc::new(Mutex::new(AlarmState {
+                alarm: Timer::new().context("cmos timer")?,
+                irq,
+                vm_control,
+                // Not actually armed, but simpler than wrapping with an Option.
+                armed_time: Instant::now(),
+                clear_evt: None,
+            })),
             worker: None,
-            armed_time,
         })
     }
 
-    fn spawn_worker(&mut self) {
-        let alarm = self.alarm.clone();
-        let alarm_fn = self.alarm_fn.take().expect("no alarm function");
+    fn spawn_worker(&mut self, alarm_state: Arc<Mutex<AlarmState>>) {
         self.worker = Some(WorkerThread::start("CMOS_alarm", move |kill_evt| {
-            if let Err(e) = run_cmos_worker(alarm, kill_evt, &alarm_fn) {
+            if let Err(e) = run_cmos_worker(alarm_state, kill_evt) {
                 error!("Failed to spawn worker {:?}", e);
             }
-            alarm_fn
         }));
     }
 
     fn set_alarm(&mut self) {
+        let mut state = self.alarm_state.lock();
         if self.data[RTC_REG_B as usize] & RTC_REG_B_ALARM_ENABLE != 0 {
             let now = (self.now_fn)();
             let target = alarm_from_registers(now.year(), &self.data).and_then(|this_year| {
@@ -221,55 +211,64 @@ impl Cmos {
             if let Some(target) = target {
                 if Some(target) != self.alarm_time {
                     self.alarm_time = Some(target);
-
-                    if self.alarm_fn.is_some() {
-                        self.spawn_worker();
-                    }
-                    if let Some(armed_time) = self.armed_time.as_ref() {
-                        *armed_time.lock() = Instant::now();
-                    }
+                    state.armed_time = Instant::now();
 
                     let duration = target
                         .signed_duration_since(now)
                         .to_std()
                         .unwrap_or(Duration::new(0, 0));
-                    if let Err(e) = self.alarm.lock().reset(duration, None) {
+                    if let Err(e) = state.alarm.reset_oneshot(duration) {
                         error!("Failed to set alarm {:?}", e);
                     }
                 }
             }
         } else if self.alarm_time.take().is_some() {
-            if let Err(e) = self.alarm.lock().clear() {
+            if let Err(e) = state.alarm.clear() {
                 error!("Failed to clear alarm {:?}", e);
             }
+            if let Some(clear_evt) = state.clear_evt.take() {
+                if let Err(e) = clear_evt.signal() {
+                    error!("failed to clear rtc pm signal {:?}", e);
+                }
+            }
+        }
+
+        let needs_worker = self.alarm_time.is_some();
+        drop(state);
+
+        if needs_worker && self.worker.is_none() {
+            self.spawn_worker(self.alarm_state.clone());
         }
     }
 }
 
-fn run_cmos_worker(
-    alarm: Arc<Mutex<Timer>>,
-    kill_evt: Event,
-    alarm_fn: &AlarmFn,
-) -> anyhow::Result<()> {
+fn run_cmos_worker(alarm_state: Arc<Mutex<AlarmState>>, kill_evt: Event) -> anyhow::Result<()> {
     #[derive(EventToken)]
     enum Token {
         Alarm,
         Kill,
     }
 
-    let wait_ctx: WaitContext<Token> =
-        WaitContext::build_with(&[(&*alarm.lock(), Token::Alarm), (&kill_evt, Token::Kill)])
-            .context("worker context failed")?;
+    let wait_ctx: WaitContext<Token> = WaitContext::build_with(&[
+        (&alarm_state.lock().alarm, Token::Alarm),
+        (&kill_evt, Token::Kill),
+    ])
+    .context("worker context failed")?;
 
     loop {
         let events = wait_ctx.wait().context("wait failed")?;
+        let mut state = alarm_state.lock();
         for event in events.iter().filter(|e| e.is_readable) {
             match event.token {
                 Token::Alarm => {
-                    if alarm.lock().mark_waited().context("timer ack failed")? {
+                    if state.alarm.mark_waited().context("timer ack failed")? {
                         continue;
                     }
-                    alarm_fn.fire()?;
+
+                    match state.trigger_rtc_interrupt() {
+                        Ok(clear_evt) => state.clear_evt = Some(clear_evt),
+                        Err(e) => error!("Failed to send rtc {:?}", e),
+                    }
                 }
                 Token::Kill => return Ok(()),
             }
@@ -427,15 +426,13 @@ impl Suspendable for Cmos {
 
     fn sleep(&mut self) -> anyhow::Result<()> {
         if let Some(worker) = self.worker.take() {
-            self.alarm_fn = Some(worker.stop());
+            worker.stop();
         }
         Ok(())
     }
 
     fn wake(&mut self) -> anyhow::Result<()> {
-        if self.alarm_time.is_some() {
-            self.spawn_worker();
-        }
+        self.spawn_worker(self.alarm_state.clone());
         Ok(())
     }
 }
@@ -518,9 +515,14 @@ mod tests {
         timestamp_to_datetime(1483228800)
     }
 
+    fn new_cmos_for_test(now_fn: CmosNowFn) -> Cmos {
+        let irq = IrqEdgeEvent::new().unwrap();
+        Cmos::new(1024, 0, now_fn, Tube::pair().unwrap().0, irq).unwrap()
+    }
+
     #[test]
     fn cmos_write_index() {
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_party_like_its_1999, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_party_like_its_1999);
         // Write index.
         cmos.write(
             BusAccessInfo {
@@ -535,7 +537,7 @@ mod tests {
 
     #[test]
     fn cmos_write_data() {
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_party_like_its_1999, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_party_like_its_1999);
         // Write data 0x01 at index 0x41.
         cmos.write(
             BusAccessInfo {
@@ -575,7 +577,7 @@ mod tests {
 
     #[test]
     fn cmos_date_time_1999() {
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_party_like_its_1999, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_party_like_its_1999);
         assert_eq!(read_reg(&mut cmos, 0x00), 0x59); // seconds
         assert_eq!(read_reg(&mut cmos, 0x02), 0x59); // minutes
         assert_eq!(read_reg(&mut cmos, 0x04), 0x23); // hours
@@ -588,7 +590,7 @@ mod tests {
 
     #[test]
     fn cmos_date_time_2000() {
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_y2k_compliant, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_y2k_compliant);
         assert_eq!(read_reg(&mut cmos, 0x00), 0x00); // seconds
         assert_eq!(read_reg(&mut cmos, 0x02), 0x00); // minutes
         assert_eq!(read_reg(&mut cmos, 0x04), 0x00); // hours
@@ -601,7 +603,7 @@ mod tests {
 
     #[test]
     fn cmos_date_time_before_leap_second() {
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_2016_before_leap_second, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_2016_before_leap_second);
         assert_eq!(read_reg(&mut cmos, 0x00), 0x59); // seconds
         assert_eq!(read_reg(&mut cmos, 0x02), 0x59); // minutes
         assert_eq!(read_reg(&mut cmos, 0x04), 0x23); // hours
@@ -614,7 +616,7 @@ mod tests {
 
     #[test]
     fn cmos_date_time_after_leap_second() {
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_2017_after_leap_second, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_2017_after_leap_second);
         assert_eq!(read_reg(&mut cmos, 0x00), 0x00); // seconds
         assert_eq!(read_reg(&mut cmos, 0x02), 0x00); // minutes
         assert_eq!(read_reg(&mut cmos, 0x04), 0x00); // hours
@@ -629,7 +631,7 @@ mod tests {
     fn cmos_alarm() {
         // 2000-01-02T03:04:05+00:00
         let now_fn = || timestamp_to_datetime(946782245);
-        let mut cmos = Cmos::new_inner(1024, 0, now_fn, None).unwrap();
+        let mut cmos = new_cmos_for_test(now_fn);
 
         // A date later this year
         write_reg(&mut cmos, 0x01, 0x06); // seconds
@@ -671,14 +673,14 @@ mod tests {
 
     #[test]
     fn cmos_reg_d() {
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_party_like_its_1999, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_party_like_its_1999);
         assert_eq!(read_reg(&mut cmos, 0x0d), 0x80) // RAM and time are valid
     }
 
     #[test]
     fn cmos_snapshot_restore() -> anyhow::Result<()> {
         // time function doesn't matter in this case.
-        let mut cmos = Cmos::new_inner(1024, 0, test_now_party_like_its_1999, None).unwrap();
+        let mut cmos = new_cmos_for_test(test_now_party_like_its_1999);
 
         let info_index = BusAccessInfo {
             offset: 0,
@@ -715,9 +717,9 @@ mod tests {
     #[test]
     fn cmos_sleep_wake() {
         // 2000-01-02T03:04:05+00:00
+        let irq = IrqEdgeEvent::new().unwrap();
         let now_fn = || timestamp_to_datetime(946782245);
-        let alarm_fn = AlarmFn::new(IrqEdgeEvent::new().unwrap(), Tube::pair().unwrap().0);
-        let mut cmos = Cmos::new_inner(1024, 0, now_fn, Some(alarm_fn)).unwrap();
+        let mut cmos = Cmos::new(1024, 0, now_fn, Tube::pair().unwrap().0, irq).unwrap();
 
         // A date later this year
         write_reg(&mut cmos, 0x01, 0x06); // seconds
@@ -739,22 +741,22 @@ mod tests {
 
     suspendable_tests!(
         cmos1999,
-        Cmos::new_inner(1024, 0, test_now_party_like_its_1999, None).unwrap(),
+        new_cmos_for_test(test_now_party_like_its_1999),
         modify_device
     );
     suspendable_tests!(
         cmos2k,
-        Cmos::new_inner(1024, 0, test_now_y2k_compliant, None).unwrap(),
+        new_cmos_for_test(test_now_y2k_compliant),
         modify_device
     );
     suspendable_tests!(
         cmos2016,
-        Cmos::new_inner(1024, 0, test_now_2016_before_leap_second, None).unwrap(),
+        new_cmos_for_test(test_now_2016_before_leap_second),
         modify_device
     );
     suspendable_tests!(
         cmos2017,
-        Cmos::new_inner(1024, 0, test_now_2017_after_leap_second, None).unwrap(),
+        new_cmos_for_test(test_now_2017_after_leap_second),
         modify_device
     );
 }
diff --git a/devices/src/debugcon.rs b/devices/src/debugcon.rs
index a56e43e41..dfc3b7a4d 100644
--- a/devices/src/debugcon.rs
+++ b/devices/src/debugcon.rs
@@ -165,10 +165,10 @@ mod tests {
             Vec::new(),
         );
 
-        debugcon.write(ADDR, &[b'a']);
-        debugcon.write(ADDR, &[b'b']);
-        debugcon.write(ADDR, &[b'c']);
-        assert_eq!(debugcon_out.buf.lock().as_slice(), [b'a', b'b', b'c']);
+        debugcon.write(ADDR, b"a");
+        debugcon.write(ADDR, b"b");
+        debugcon.write(ADDR, b"c");
+        assert_eq!(debugcon_out.buf.lock().as_slice(), b"abc");
     }
 
     #[test]
diff --git a/devices/src/irqchip/apic.rs b/devices/src/irqchip/apic.rs
index 240199e75..ec22b9785 100644
--- a/devices/src/irqchip/apic.rs
+++ b/devices/src/irqchip/apic.rs
@@ -630,9 +630,22 @@ impl Apic {
         }
         let length = self.cycle_length * initial_count * self.get_timer_divide_control();
         let mode = self.get_reg(Reg::LOCAL_TIMER) & TIMER_MODE_MASK;
-        let (duration, interval) = match mode {
-            TIMER_MODE_ONE_SHOT => (length, None),
-            TIMER_MODE_PERIODIC => (length, Some(length)),
+        match mode {
+            TIMER_MODE_ONE_SHOT => {
+                if let Err(e) = self.timer.reset_oneshot(length) {
+                    error!("Failed to reset APIC timer to one-shot({:?}) {}", length, e);
+                    return;
+                }
+            }
+            TIMER_MODE_PERIODIC => {
+                if let Err(e) = self.timer.reset_repeating(length) {
+                    error!(
+                        "Failed to reset APIC timer to repeating({:?}) {}",
+                        length, e
+                    );
+                    return;
+                }
+            }
             TIMER_MODE_TSC_DEADLINE => {
                 warn!("APIC TSC-deadline timer not supported");
                 return;
@@ -644,13 +657,6 @@ impl Apic {
         };
 
         self.last_tick = Instant::now();
-        if let Err(e) = self.timer.reset(duration, interval) {
-            error!(
-                "Failed to reset APIC timer to duration={:?} interval={:?}: {}",
-                duration, interval, e
-            );
-            return;
-        }
         self.timer_length = Some(length);
     }
 
diff --git a/devices/src/irqchip/kvm/aarch64.rs b/devices/src/irqchip/kvm/aarch64.rs
index f88d99b0f..46ff79109 100644
--- a/devices/src/irqchip/kvm/aarch64.rs
+++ b/devices/src/irqchip/kvm/aarch64.rs
@@ -4,6 +4,7 @@
 
 use std::sync::Arc;
 
+use anyhow::Context;
 use base::errno_result;
 use base::ioctl_with_ref;
 use base::Result;
@@ -107,14 +108,14 @@ impl KvmKernelIrqChip {
 
         // SAFETY:
         // Safe because we allocated the struct that's being passed in
-        let ret = unsafe { ioctl_with_ref(&vgic, KVM_SET_DEVICE_ATTR(), &cpu_redist_attr) };
+        let ret = unsafe { ioctl_with_ref(&vgic, KVM_SET_DEVICE_ATTR, &cpu_redist_attr) };
         if ret != 0 {
             return errno_result();
         }
 
         // SAFETY:
         // Safe because we allocated the struct that's being passed in
-        let ret = unsafe { ioctl_with_ref(&vgic, KVM_SET_DEVICE_ATTR(), &dist_attr) };
+        let ret = unsafe { ioctl_with_ref(&vgic, KVM_SET_DEVICE_ATTR, &dist_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -130,7 +131,7 @@ impl KvmKernelIrqChip {
         };
         // SAFETY:
         // Safe because we allocated the struct that's being passed in
-        let ret = unsafe { ioctl_with_ref(&vgic, KVM_SET_DEVICE_ATTR(), &nr_irqs_attr) };
+        let ret = unsafe { ioctl_with_ref(&vgic, KVM_SET_DEVICE_ATTR, &nr_irqs_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -173,6 +174,32 @@ impl IrqChipAArch64 for KvmKernelIrqChip {
         self.device_kind
     }
 
+    fn snapshot(&self, _cpus_num: usize) -> anyhow::Result<serde_json::Value> {
+        if self.device_kind == DeviceKind::ArmVgicV3 {
+            let save_gic_attr = kvm_device_attr {
+                group: KVM_DEV_ARM_VGIC_GRP_CTRL,
+                attr: KVM_DEV_ARM_VGIC_SAVE_PENDING_TABLES as u64,
+                addr: 0,
+                flags: 0,
+            };
+            // SAFETY:
+            // Safe because we allocated the struct that's being passed in
+            // Safe because the device interrupts get stored in guest memory
+            let ret = unsafe { ioctl_with_ref(&self.vgic, KVM_SET_DEVICE_ATTR, &save_gic_attr) };
+            if ret != 0 {
+                return errno_result()
+                    .context("ioctl KVM_SET_DEVICE_ATTR for save_gic_attr failed.")?;
+            }
+        }
+        Ok(serde_json::Value::Null)
+    }
+
+    fn restore(&mut self, _data: serde_json::Value, _vcpus_num: usize) -> anyhow::Result<()> {
+        // SAVE_PENDING_TABLES operation wrote the pending tables into guest memory.
+        // Assumption is that no work is necessary on restore of IrqChip.
+        Ok(())
+    }
+
     fn finalize(&self) -> Result<()> {
         let init_gic_attr = kvm_device_attr {
             group: KVM_DEV_ARM_VGIC_GRP_CTRL,
@@ -183,7 +210,7 @@ impl IrqChipAArch64 for KvmKernelIrqChip {
 
         // SAFETY:
         // Safe because we allocated the struct that's being passed in
-        let ret = unsafe { ioctl_with_ref(&self.vgic, KVM_SET_DEVICE_ATTR(), &init_gic_attr) };
+        let ret = unsafe { ioctl_with_ref(&self.vgic, KVM_SET_DEVICE_ATTR, &init_gic_attr) };
         if ret != 0 {
             return errno_result();
         }
diff --git a/devices/src/irqchip/kvm/riscv64.rs b/devices/src/irqchip/kvm/riscv64.rs
index 0e653d669..56a0a2163 100644
--- a/devices/src/irqchip/kvm/riscv64.rs
+++ b/devices/src/irqchip/kvm/riscv64.rs
@@ -81,7 +81,7 @@ impl AiaDescriptor {
 
         // Safe because we allocated the struct that's being passed in, and raw_aia_mode is pointing
         // to a uniquely owned local, mutable variable.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR(), &init_attr) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR, &init_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -101,7 +101,7 @@ impl AiaDescriptor {
 
         // Safe because we allocated the struct that's being passed in, and raw_num_ids is pointing
         // to a uniquely owned local, mutable variable.
-        let ret = unsafe { ioctl_with_ref(self, KVM_GET_DEVICE_ATTR(), &aia_num_ids_attr) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_GET_DEVICE_ATTR, &aia_num_ids_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -119,7 +119,7 @@ impl AiaDescriptor {
         };
         // Safe because we allocated the struct that's being passed in, and raw_aia_mode is pointing
         // to a uniquely owned local, mutable variable.
-        let ret = unsafe { ioctl_with_ref(self, KVM_GET_DEVICE_ATTR(), &aia_mode_attr) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_GET_DEVICE_ATTR, &aia_mode_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -136,7 +136,7 @@ impl AiaDescriptor {
         };
         // Safe because we allocated the struct that's being passed in, and raw_aia_mode is pointing
         // to a uniquely owned local, mutable variable.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR(), &kvm_attr) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR, &kvm_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -153,7 +153,7 @@ impl AiaDescriptor {
         };
         // Safe because we allocated the struct that's being passed in, and raw_aia_mode is pointing
         // to a uniquely owned local, mutable variable.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR(), &kvm_attr) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR, &kvm_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -172,7 +172,7 @@ impl AiaDescriptor {
         };
         // Safe because we allocated the struct that's being passed in, and raw_aplic_addr is
         // pointing to a uniquely owned local, mutable variable.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR(), &kvm_attr) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR, &kvm_attr) };
         if ret != 0 {
             return errno_result();
         }
@@ -187,7 +187,7 @@ impl AiaDescriptor {
             };
             // Safe because we allocated the struct that's being passed in, and raw_imsic_addr is
             // pointing to a uniquely owned local, mutable variable.
-            let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR(), &kvm_attr) };
+            let ret = unsafe { ioctl_with_ref(self, KVM_SET_DEVICE_ATTR, &kvm_attr) };
             if ret != 0 {
                 return errno_result();
             }
diff --git a/devices/src/irqchip/kvm/x86_64.rs b/devices/src/irqchip/kvm/x86_64.rs
index 456380519..e8b9daefa 100644
--- a/devices/src/irqchip/kvm/x86_64.rs
+++ b/devices/src/irqchip/kvm/x86_64.rs
@@ -356,18 +356,15 @@ impl KvmSplitIrqChip {
         self.pic.lock().interrupt_requested()
     }
 
-    /// Check if the specified vcpu has any pending interrupts. Returns None for no interrupts,
-    /// otherwise Some(u32) should be the injected interrupt vector. For KvmSplitIrqChip
-    /// this calls get_external_interrupt on the pic.
-    pub fn get_external_interrupt(&self, vcpu_id: usize) -> Option<u32> {
+    /// Check if the specified vcpu has any pending interrupts. Returns [`None`] for no interrupts,
+    /// otherwise [`Some::<u8>`] should be the injected interrupt vector. For [`KvmSplitIrqChip`]
+    /// this calls `get_external_interrupt` on the pic.
+    pub fn get_external_interrupt(&self, vcpu_id: usize) -> Option<u8> {
         // Pic interrupts for the split irqchip only go to vcpu 0
         if vcpu_id != 0 {
             return None;
         }
-        self.pic
-            .lock()
-            .get_external_interrupt()
-            .map(|vector| vector as u32)
+        self.pic.lock().get_external_interrupt()
     }
 
     /// Register an event that can trigger an interrupt for a particular GSI.
diff --git a/devices/src/irqchip/userspace.rs b/devices/src/irqchip/userspace.rs
index 00bb65bed..e0fcd1b4d 100644
--- a/devices/src/irqchip/userspace.rs
+++ b/devices/src/irqchip/userspace.rs
@@ -566,7 +566,7 @@ impl<V: VcpuX86_64 + 'static> IrqChip for UserspaceIrqChip<V> {
             let mut pic = self.pic.lock();
             if vcpu_ready {
                 if let Some(vector) = pic.get_external_interrupt() {
-                    vcpu.interrupt(vector as u32)?;
+                    vcpu.interrupt(vector)?;
                     self.apics[vcpu_id].lock().set_mp_state(&MPState::Runnable);
                     // Already injected a PIC interrupt, so APIC fixed interrupt can't be injected.
                     vcpu_ready = false;
@@ -595,7 +595,7 @@ impl<V: VcpuX86_64 + 'static> IrqChip for UserspaceIrqChip<V> {
             };
 
             if do_interrupt {
-                vcpu.interrupt(vector as u32)?;
+                vcpu.interrupt(vector)?;
             }
         }
         for _ in 0..irqs.nmis {
diff --git a/devices/src/irqchip/whpx.rs b/devices/src/irqchip/whpx.rs
index e30033943..0af8be75e 100644
--- a/devices/src/irqchip/whpx.rs
+++ b/devices/src/irqchip/whpx.rs
@@ -161,16 +161,16 @@ impl WhpxSplitIrqChip {
         self.pic.lock().interrupt_requested()
     }
 
-    /// Check if the specified vcpu has any pending interrupts. Returns None for no interrupts,
-    /// otherwise Some(u32) should be the injected interrupt vector. For WhpxSplitIrqChip
-    /// this calls get_external_interrupt on the pic.
-    pub fn get_external_interrupt(&self, vcpu_id: usize) -> Result<Option<u32>> {
+    /// Check if the specified vcpu has any pending interrupts. Returns [`None`] for no interrupts,
+    /// otherwise [`Some::<u8>`] should be the injected interrupt vector. For [`WhpxSplitIrqChip`]
+    /// this calls `get_external_interrupt` on the pic.
+    pub fn get_external_interrupt(&self, vcpu_id: usize) -> Result<Option<u8>> {
         // Pic interrupts for the split irqchip only go to vcpu 0
         if vcpu_id != 0 {
             return Ok(None);
         }
         if let Some(vector) = self.pic.lock().get_external_interrupt() {
-            Ok(Some(vector as u32))
+            Ok(Some(vector))
         } else {
             Ok(None)
         }
@@ -386,7 +386,7 @@ impl IrqChip for WhpxSplitIrqChip {
         }
 
         if let Some(vector) = self.get_external_interrupt(vcpu_id)? {
-            vcpu.interrupt(vector as u32)?;
+            vcpu.interrupt(vector)?;
         }
 
         // The second interrupt request should be handled immediately, so ask vCPU to exit as soon
diff --git a/devices/src/lib.rs b/devices/src/lib.rs
index f6dfab0a8..28ab5a476 100644
--- a/devices/src/lib.rs
+++ b/devices/src/lib.rs
@@ -52,6 +52,8 @@ use base::Tube;
 use base::TubeError;
 use cros_async::AsyncTube;
 use cros_async::Executor;
+use serde::Deserialize;
+use serde::Serialize;
 use vm_control::DeviceControlCommand;
 use vm_control::DevicesState;
 use vm_control::VmResponse;
@@ -119,6 +121,7 @@ pub use self::pci::StubPciParameters;
 pub use self::pflash::Pflash;
 pub use self::pflash::PflashParameters;
 pub use self::pl030::Pl030;
+pub use self::pmc_virt::VirtualPmc;
 pub use self::serial::Serial;
 pub use self::serial_device::Error as SerialError;
 pub use self::serial_device::SerialDevice;
@@ -155,7 +158,6 @@ cfg_if::cfg_if! {
         };
         pub use self::platform::VfioPlatformDevice;
         pub use self::ac_adapter::AcAdapter;
-        pub use self::pmc_virt::VirtualPmc;
         pub use self::proxy::ChildProcIntf;
         pub use self::proxy::Error as ProxyError;
         pub use self::proxy::ProxyDevice;
@@ -175,9 +177,6 @@ cfg_if::cfg_if! {
 }
 
 /// Request CoIOMMU to unpin a specific range.
-use serde::Deserialize;
-/// Request CoIOMMU to unpin a specific range.
-use serde::Serialize;
 #[derive(Serialize, Deserialize, Debug)]
 pub struct UnpinRequest {
     /// The ranges presents (start gfn, count).
diff --git a/devices/src/pci/coiommu.rs b/devices/src/pci/coiommu.rs
index d58e6c06f..ff59cefba 100644
--- a/devices/src/pci/coiommu.rs
+++ b/devices/src/pci/coiommu.rs
@@ -746,8 +746,6 @@ impl UnpinWorker {
         let mut unpin_timer = if self.params.unpin_policy != CoIommuUnpinPolicy::Off
             && !self.params.unpin_interval.is_zero()
         {
-            let duration = self.params.unpin_interval;
-            let interval = Some(self.params.unpin_interval);
             let mut timer = match Timer::new() {
                 Ok(t) => t,
                 Err(e) => {
@@ -759,7 +757,7 @@ impl UnpinWorker {
                     return;
                 }
             };
-            if let Err(e) = timer.reset(duration, interval) {
+            if let Err(e) = timer.reset_repeating(self.params.unpin_interval) {
                 error!(
                     "{}: failed to start the unpin timer: {}",
                     self.debug_label(),
diff --git a/devices/src/pci/mod.rs b/devices/src/pci/mod.rs
index eac8e0e37..9aed04329 100644
--- a/devices/src/pci/mod.rs
+++ b/devices/src/pci/mod.rs
@@ -27,10 +27,7 @@ use libc::EINVAL;
 use serde::Deserialize;
 use serde::Serialize;
 
-pub use self::acpi::DeviceVcfgRegister;
-pub use self::acpi::DsmMethod;
 pub use self::acpi::GpeScope;
-pub use self::acpi::PowerResourceMethod;
 #[cfg(any(target_os = "android", target_os = "linux"))]
 pub use self::coiommu::CoIommuDev;
 #[cfg(any(target_os = "android", target_os = "linux"))]
@@ -47,20 +44,24 @@ pub use self::pci_configuration::PciBarConfiguration;
 pub use self::pci_configuration::PciBarIndex;
 pub use self::pci_configuration::PciBarPrefetchable;
 pub use self::pci_configuration::PciBarRegionType;
+pub use self::pci_configuration::PciBaseSystemPeripheralSubclass;
 pub use self::pci_configuration::PciCapability;
 pub use self::pci_configuration::PciCapabilityID;
 pub use self::pci_configuration::PciClassCode;
 pub use self::pci_configuration::PciConfiguration;
 pub use self::pci_configuration::PciDisplaySubclass;
 pub use self::pci_configuration::PciHeaderType;
+pub use self::pci_configuration::PciInputDeviceSubclass;
 pub use self::pci_configuration::PciMassStorageSubclass;
+pub use self::pci_configuration::PciMultimediaSubclass;
+pub use self::pci_configuration::PciNetworkControllerSubclass;
 pub use self::pci_configuration::PciProgrammingInterface;
 pub use self::pci_configuration::PciSerialBusSubClass;
+pub use self::pci_configuration::PciSimpleCommunicationControllerSubclass;
 pub use self::pci_configuration::PciSubclass;
-pub use self::pci_configuration::CAPABILITY_LIST_HEAD_OFFSET;
+pub use self::pci_configuration::PciWirelessControllerSubclass;
 pub use self::pci_device::BarRange;
 pub use self::pci_device::Error as PciDeviceError;
-pub use self::pci_device::IoEventError as PciIoEventError;
 pub use self::pci_device::PciBus;
 pub use self::pci_device::PciDevice;
 pub use self::pci_device::PreferredIrq;
diff --git a/devices/src/pci/msi.rs b/devices/src/pci/msi.rs
index 52c8ebe32..64497ef60 100644
--- a/devices/src/pci/msi.rs
+++ b/devices/src/pci/msi.rs
@@ -105,7 +105,7 @@ impl MsiConfig {
 
     pub fn read_msi_capability(&self, offset: u32, data: u32) -> u32 {
         if offset == 0 {
-            (self.ctrl as u32) << 16 | (data & u16::max_value() as u32)
+            (self.ctrl as u32) << 16 | (data & u16::MAX as u32)
         } else {
             data
         }
diff --git a/devices/src/pci/msix.rs b/devices/src/pci/msix.rs
index 2e091cc2c..db3ecf887 100644
--- a/devices/src/pci/msix.rs
+++ b/devices/src/pci/msix.rs
@@ -194,7 +194,7 @@ impl MsixConfig {
         if self.masked {
             msg_ctl |= FUNCTION_MASK_BIT;
         }
-        (msg_ctl as u32) << 16 | (data & u16::max_value() as u32)
+        (msg_ctl as u32) << 16 | (data & u16::MAX as u32)
     }
 
     /// Write to the MSI-X Capability Structure.
diff --git a/devices/src/pci/pci_configuration.rs b/devices/src/pci/pci_configuration.rs
index e7a1b9149..4e8e0e965 100644
--- a/devices/src/pci/pci_configuration.rs
+++ b/devices/src/pci/pci_configuration.rs
@@ -128,6 +128,7 @@ pub trait PciSubclass {
 #[derive(Copy, Clone)]
 pub enum PciMassStorageSubclass {
     Scsi = 0x00,
+    NonVolatileMemory = 0x08,
     Other = 0x80,
 }
 
@@ -137,6 +138,19 @@ impl PciSubclass for PciMassStorageSubclass {
     }
 }
 
+/// Subclasses of the NetworkController class.
+#[allow(dead_code)]
+#[derive(Copy, Clone)]
+pub enum PciNetworkControllerSubclass {
+    Other = 0x80,
+}
+
+impl PciSubclass for PciNetworkControllerSubclass {
+    fn get_register_value(&self) -> u8 {
+        *self as u8
+    }
+}
+
 /// Subclasses of the DisplayController class.
 #[allow(dead_code)]
 #[derive(Copy, Clone)]
@@ -194,6 +208,46 @@ impl PciSubclass for PciBridgeSubclass {
     }
 }
 
+/// Subclasses of the SimpleCommunicationController class.
+#[allow(dead_code)]
+#[derive(Copy, Clone)]
+pub enum PciSimpleCommunicationControllerSubclass {
+    Other = 0x80,
+}
+
+impl PciSubclass for PciSimpleCommunicationControllerSubclass {
+    fn get_register_value(&self) -> u8 {
+        *self as u8
+    }
+}
+
+/// Subclasses of the BaseSystemPeripheral class.
+#[allow(dead_code)]
+#[derive(Copy, Clone)]
+pub enum PciBaseSystemPeripheralSubclass {
+    Iommu = 0x06,
+    Other = 0x80,
+}
+
+impl PciSubclass for PciBaseSystemPeripheralSubclass {
+    fn get_register_value(&self) -> u8 {
+        *self as u8
+    }
+}
+
+/// Subclasses of the InputDevice class.
+#[allow(dead_code)]
+#[derive(Copy, Clone)]
+pub enum PciInputDeviceSubclass {
+    Other = 0x80,
+}
+
+impl PciSubclass for PciInputDeviceSubclass {
+    fn get_register_value(&self) -> u8 {
+        *self as u8
+    }
+}
+
 /// Subclass of the SerialBus
 #[allow(dead_code)]
 #[derive(Copy, Clone)]
@@ -210,6 +264,19 @@ impl PciSubclass for PciSerialBusSubClass {
     }
 }
 
+/// Subclasses of the WirelessController class.
+#[allow(dead_code)]
+#[derive(Copy, Clone)]
+pub enum PciWirelessControllerSubclass {
+    Other = 0x80,
+}
+
+impl PciSubclass for PciWirelessControllerSubclass {
+    fn get_register_value(&self) -> u8 {
+        *self as u8
+    }
+}
+
 /// Subclasses for PciClassCode Other.
 #[allow(dead_code)]
 #[derive(Copy, Clone)]
@@ -637,7 +704,7 @@ impl PciConfiguration {
             .ok_or(Error::BarAddressInvalid(config.addr, config.size))?;
         match config.region_type {
             PciBarRegionType::Memory32BitRegion | PciBarRegionType::IoRegion => {
-                if end_addr > u64::from(u32::max_value()) {
+                if end_addr > u64::from(u32::MAX) {
                     return Err(Error::BarAddressInvalid(config.addr, config.size));
                 }
             }
@@ -647,10 +714,6 @@ impl PciConfiguration {
                     return Err(Error::BarInvalid64(config.bar_idx));
                 }
 
-                if end_addr > u64::max_value() {
-                    return Err(Error::BarAddressInvalid(config.addr, config.size));
-                }
-
                 if self.bar_used[config.bar_idx + 1] {
                     return Err(Error::BarInUse64(config.bar_idx));
                 }
@@ -1037,7 +1100,7 @@ mod tests {
 
     use super::*;
 
-    #[repr(packed)]
+    #[repr(C, packed)]
     #[derive(Clone, Copy, AsBytes)]
     #[allow(dead_code)]
     struct TestCap {
diff --git a/devices/src/pci/pci_device.rs b/devices/src/pci/pci_device.rs
index 0a75d0178..87c0daaf9 100644
--- a/devices/src/pci/pci_device.rs
+++ b/devices/src/pci/pci_device.rs
@@ -39,8 +39,6 @@ use crate::pci::PciAddressError;
 use crate::pci::PciBarIndex;
 use crate::pci::PciInterruptPin;
 use crate::virtio::ipc_memory_mapper::IpcMemoryMapper;
-#[cfg(all(unix, feature = "audio"))]
-use crate::virtio::snd::vios_backend::Error as VioSError;
 use crate::BusAccessInfo;
 use crate::BusDevice;
 use crate::DeviceId;
@@ -79,25 +77,24 @@ pub enum Error {
     #[cfg(all(unix, feature = "audio", feature = "audio_cras"))]
     #[error("failed to create CRAS Client: {0}")]
     CreateCrasClientFailed(libcras::Error),
-    /// Create VioS client failed.
-    #[cfg(all(unix, feature = "audio"))]
-    #[error("failed to create VioS Client: {0}")]
-    CreateViosClientFailed(VioSError),
     /// Device is already on this bus
     #[error("pci device {0} has already been added to bus {1}")]
     DeviceAlreadyExist(PciAddress, u8),
     /// Device not exist on this bus
     #[error("pci device {0} does not located on bus {1}")]
     DeviceNotExist(PciAddress, u8),
+    /// Fail to clone an event.
+    #[error("failed to clone an event: {0}")]
+    EventCloneFailed(i32),
+    /// Fail to create an event.
+    #[error("failed to create an event: {0}")]
+    EventCreationFailed(i32),
+    /// Fail to signal on an event.
+    #[error("failed to signal an event: {0}")]
+    EventSignalFailed(i32),
     /// Allocating space for an IO BAR failed.
     #[error("failed to allocate space for an IO BAR, size={0}: {1}")]
     IoAllocationFailed(u64, SystemAllocatorFaliure),
-    /// ioevent registration failed.
-    #[error("IoEvent registration failed: {0}")]
-    IoEventRegisterFailed(IoEventError),
-    /// supports_iommu is false.
-    #[error("Iommu is not supported")]
-    IommuNotSupported,
     /// Registering an IO BAR failed.
     #[error("failed to register an IO BAR, addr={0} err={1}")]
     IoRegistrationFailed(u64, pci_configuration::Error),
@@ -113,9 +110,6 @@ pub enum Error {
     /// The new added bus does not located on this bus
     #[error("Added bus {0} does not located on bus {1}")]
     ParentBusNotExist(u8, u8),
-    /// PCI Address is not allocated.
-    #[error("PCI address is not allocated")]
-    PciAddressMissing,
     /// PCI Address parsing failure.
     #[error("PCI address '{0}' could not be parsed: {1}")]
     PciAddressParseFailure(String, PciAddressError),
@@ -130,23 +124,6 @@ pub enum Error {
     SizeZero,
 }
 
-/// Errors when io event registration fails:
-#[derive(Clone, Debug, Error)]
-pub enum IoEventError {
-    /// Event clone failed.
-    #[error("Event clone failed: {0}")]
-    CloneFail(base::Error),
-    /// Failed due to system error.
-    #[error("System error: {0}")]
-    SystemError(base::Error),
-    /// Tube for ioevent register failed.
-    #[error("IoEvent register Tube failed")]
-    TubeFail,
-    /// ioevent_register_request not implemented for PciDevice emitting it.
-    #[error("ioevent register not implemented")]
-    Unsupported,
-}
-
 pub type Result<T> = std::result::Result<T, Error>;
 
 /// Pci Bar Range information
diff --git a/devices/src/pci/pci_root.rs b/devices/src/pci/pci_root.rs
index b6d8d035c..325b73abd 100644
--- a/devices/src/pci/pci_root.rs
+++ b/devices/src/pci/pci_root.rs
@@ -830,7 +830,7 @@ impl BusDevice for PciConfigMmio {
         // Only allow reads to the register boundary.
         let start = info.offset as usize % 4;
         let end = start + data.len();
-        if end > 4 || info.offset > u32::max_value() as u64 {
+        if end > 4 || info.offset > u32::MAX as u64 {
             for d in data {
                 *d = 0xff;
             }
@@ -844,7 +844,7 @@ impl BusDevice for PciConfigMmio {
     }
 
     fn write(&mut self, info: BusAccessInfo, data: &[u8]) {
-        if info.offset > u32::max_value() as u64 {
+        if info.offset > u32::MAX as u64 {
             return;
         }
         self.config_space_write(info.offset as u32, info.offset % 4, data)
diff --git a/devices/src/pci/pcie/mod.rs b/devices/src/pci/pcie/mod.rs
index fbc25bb4c..6339eabab 100644
--- a/devices/src/pci/pcie/mod.rs
+++ b/devices/src/pci/pcie/mod.rs
@@ -47,7 +47,10 @@ const PCIE_SLTCAP_HPS: u32 = 0x20; // Hot-Plug Surprise
 const PCIE_SLTCAP_HPC: u32 = 0x40; // Hot-Plug Capable
 
 const PCIE_SLTCTL_OFFSET: usize = 0x18;
-const PCIE_SLTCTL_PIC_OFF: u16 = 0x300;
+const PCIE_SLTCTL_PIC: u16 = 0x300; // Power indicator
+const PCIE_SLTCTL_PIC_ON: u16 = 0x100; // Power indicator on
+const PCIE_SLTCTL_PIC_BLINK: u16 = 0x200; // Power indicator blink
+const PCIE_SLTCTL_PIC_OFF: u16 = 0x300; // Power indicator off
 const PCIE_SLTCTL_AIC_OFF: u16 = 0xC0;
 const PCIE_SLTCTL_ABPE: u16 = 0x01;
 const PCIE_SLTCTL_PDCE: u16 = 0x08;
diff --git a/devices/src/pci/pcie/pcie_port.rs b/devices/src/pci/pcie/pcie_port.rs
index 8804f135a..5fd8070e4 100644
--- a/devices/src/pci/pcie/pcie_port.rs
+++ b/devices/src/pci/pcie/pcie_port.rs
@@ -3,10 +3,11 @@
 // found in the LICENSE file.
 
 use std::str::FromStr;
-use std::sync::mpsc;
 use std::sync::Arc;
 
+use base::error;
 use base::warn;
+use base::Event;
 use resources::Alloc;
 use resources::SystemAllocator;
 use sync::Mutex;
@@ -309,6 +310,10 @@ impl PciePort {
         }
     }
 
+    pub fn get_slot_control(&self) -> u16 {
+        self.pcie_config.lock().get_slot_control()
+    }
+
     pub fn clone_interrupt(&mut self, msi_config: Arc<Mutex<MsiConfig>>) {
         if self.port_type == PcieDevicePortType::RootPort {
             self.root_cap.lock().clone_interrupt(msi_config.clone());
@@ -336,13 +341,16 @@ impl PciePort {
     }
 
     /// Has command completion pending.
-    pub fn is_cc_pending(&self) -> bool {
-        self.pcie_config.lock().cc_sender.is_some()
+    pub fn is_hpc_pending(&self) -> bool {
+        self.pcie_config.lock().hpc_sender.is_some()
     }
 
-    /// Sets a sender for notifying guest report command complete. Returns sender replaced.
-    pub fn set_cc_sender(&mut self, cc_sender: mpsc::Sender<()>) -> Option<mpsc::Sender<()>> {
-        self.pcie_config.lock().cc_sender.replace(cc_sender)
+    /// Sets a sender for hot plug or unplug complete.
+    pub fn set_hpc_sender(&mut self, event: Event) {
+        self.pcie_config
+            .lock()
+            .hpc_sender
+            .replace(HotPlugCompleteSender::new(event));
     }
 
     pub fn trigger_hp_or_pme_interrupt(&mut self) {
@@ -358,6 +366,17 @@ impl PciePort {
         self.pcie_host.is_some()
     }
 
+    /// Checks if the slot is enabled by guest and ready for hotplug events.
+    pub fn is_hotplug_ready(&self) -> bool {
+        self.pcie_config.lock().is_hotplug_ready()
+    }
+
+    /// Gets a notification when the port is ready for hotplug.  If the port is already ready, then
+    /// the notification event is triggerred immediately.
+    pub fn get_ready_notification(&mut self) -> std::result::Result<Event, PciDeviceError> {
+        self.pcie_config.lock().get_ready_notification()
+    }
+
     pub fn hot_unplug(&mut self) {
         if let Some(host) = self.pcie_host.as_mut() {
             host.hot_unplug()
@@ -376,6 +395,10 @@ impl PciePort {
         self.pcie_config.lock().removed_downstream_valid
     }
 
+    pub fn mask_slot_status(&mut self, mask: u16) {
+        self.pcie_config.lock().mask_slot_status(mask);
+    }
+
     pub fn set_slot_status(&mut self, flag: u16) {
         self.pcie_config.lock().set_slot_status(flag);
     }
@@ -389,6 +412,32 @@ impl PciePort {
     }
 }
 
+struct HotPlugCompleteSender {
+    sender: Event,
+    armed: bool,
+}
+
+impl HotPlugCompleteSender {
+    fn new(sender: Event) -> Self {
+        Self {
+            sender,
+            armed: false,
+        }
+    }
+
+    fn arm(&mut self) {
+        self.armed = true;
+    }
+
+    fn armed(&self) -> bool {
+        self.armed
+    }
+
+    fn signal(&self) -> base::Result<()> {
+        self.sender.signal()
+    }
+}
+
 pub struct PcieConfig {
     msi_config: Option<Arc<Mutex<MsiConfig>>>,
 
@@ -400,10 +449,12 @@ pub struct PcieConfig {
     root_cap: Arc<Mutex<PcieRootCap>>,
     port_type: PcieDevicePortType,
 
-    cc_sender: Option<mpsc::Sender<()>>,
+    hpc_sender: Option<HotPlugCompleteSender>,
     hp_interrupt_pending: bool,
     removed_downstream_valid: bool,
 
+    enabled: bool,
+    hot_plug_ready_notifications: Vec<Event>,
     cap_mapping: Option<PciCapMapping>,
 }
 
@@ -426,10 +477,12 @@ impl PcieConfig {
             root_cap,
             port_type,
 
-            cc_sender: None,
+            hpc_sender: None,
             hp_interrupt_pending: false,
             removed_downstream_valid: false,
 
+            enabled: false,
+            hot_plug_ready_notifications: Vec::new(),
             cap_mapping: None,
         }
     }
@@ -450,6 +503,34 @@ impl PcieConfig {
         }
     }
 
+    // Checks if the slot is enabled by guest and ready for hotplug events.
+    fn is_hotplug_ready(&self) -> bool {
+        // The hotplug capability flags are set when the guest enables the device. Checks all flags
+        // required by the hotplug mechanism.
+        let slot_control = self.get_slot_control();
+        (slot_control & (PCIE_SLTCTL_PDCE | PCIE_SLTCTL_ABPE)) != 0
+            && (slot_control & PCIE_SLTCTL_CCIE) != 0
+            && (slot_control & PCIE_SLTCTL_HPIE) != 0
+    }
+
+    /// Gets a notification when the port is ready for hotplug. If the port is already ready, then
+    /// the notification event is triggerred immediately.
+    fn get_ready_notification(&mut self) -> std::result::Result<Event, PciDeviceError> {
+        let event = Event::new().map_err(|e| PciDeviceError::EventCreationFailed(e.errno()))?;
+        if self.is_hotplug_ready() {
+            event
+                .signal()
+                .map_err(|e| PciDeviceError::EventSignalFailed(e.errno()))?;
+        } else {
+            self.hot_plug_ready_notifications.push(
+                event
+                    .try_clone()
+                    .map_err(|e| PciDeviceError::EventCloneFailed(e.errno()))?,
+            );
+        }
+        Ok(event)
+    }
+
     fn write_pcie_cap(&mut self, offset: usize, data: &[u8]) {
         self.removed_downstream_valid = false;
         match offset {
@@ -461,6 +542,19 @@ impl PcieConfig {
                         return;
                     }
                 };
+                if !self.enabled
+                    && (value & (PCIE_SLTCTL_PDCE | PCIE_SLTCTL_ABPE)) != 0
+                    && (value & PCIE_SLTCTL_CCIE) != 0
+                    && (value & PCIE_SLTCTL_HPIE) != 0
+                {
+                    // Device is getting enabled by the guest.
+                    for notf_event in self.hot_plug_ready_notifications.drain(..) {
+                        if let Err(e) = notf_event.signal() {
+                            error!("Failed to signal hot plug ready: {}", e);
+                        }
+                    }
+                    self.enabled = true;
+                }
 
                 // if slot is populated, power indicator is off,
                 // it will detach devices
@@ -470,8 +564,8 @@ impl PcieConfig {
                     None => return,
                 }
                 if (self.slot_status & PCIE_SLTSTA_PDS != 0)
-                    && (value & PCIE_SLTCTL_PIC_OFF == PCIE_SLTCTL_PIC_OFF)
-                    && (old_control & PCIE_SLTCTL_PIC_OFF != PCIE_SLTCTL_PIC_OFF)
+                    && (value & PCIE_SLTCTL_PIC == PCIE_SLTCTL_PIC_OFF)
+                    && (old_control & PCIE_SLTCTL_PIC != PCIE_SLTCTL_PIC_OFF)
                 {
                     self.removed_downstream_valid = true;
                     self.slot_status &= !PCIE_SLTSTA_PDS;
@@ -489,10 +583,19 @@ impl PcieConfig {
                 }
 
                 if old_control != value {
-                    // send Command completed events
-                    if let Some(sender) = self.cc_sender.take() {
-                        if let Err(e) = sender.send(()) {
-                            warn!("Failed to notify command complete for slot event: {:#}", &e);
+                    let old_pic_state = old_control & PCIE_SLTCTL_PIC;
+                    let pic_state = value & PCIE_SLTCTL_PIC;
+                    if old_pic_state == PCIE_SLTCTL_PIC_BLINK && old_pic_state != pic_state {
+                        // The power indicator (PIC) is controled by the guest to indicate the power
+                        // state of the slot.
+                        // For successful hotplug: OFF => BLINK => (board enabled) => ON
+                        // For failed hotplug: OFF => BLINK => (board enable failed) => OFF
+                        // For hot unplug: ON => BLINK => (board disabled) => OFF
+                        // hot (un)plug is completed at next slot status write after it changed to
+                        // ON or OFF state.
+
+                        if let Some(sender) = self.hpc_sender.as_mut() {
+                            sender.arm();
                         }
                     }
                     self.slot_status |= PCIE_SLTSTA_CC;
@@ -503,6 +606,14 @@ impl PcieConfig {
                 if self.slot_control.is_none() {
                     return;
                 }
+                if let Some(hpc_sender) = self.hpc_sender.as_mut() {
+                    if hpc_sender.armed() {
+                        if let Err(e) = hpc_sender.signal() {
+                            error!("Failed to send hot un/plug complete signal: {}", e);
+                        }
+                        self.hpc_sender = None;
+                    }
+                }
                 let value = match u16::read_from(data) {
                     Some(v) => v,
                     None => {
@@ -587,6 +698,17 @@ impl PcieConfig {
         }
     }
 
+    fn mask_slot_status(&mut self, mask: u16) {
+        self.slot_status &= mask;
+        if let Some(mapping) = self.cap_mapping.as_mut() {
+            mapping.set_reg(
+                PCIE_SLTCTL_OFFSET / 4,
+                (self.slot_status as u32) << 16,
+                0xffff0000,
+            );
+        }
+    }
+
     fn set_slot_status(&mut self, flag: u16) {
         self.slot_status |= flag;
         if let Some(mapping) = self.cap_mapping.as_mut() {
diff --git a/devices/src/pci/pcie/pcie_rp.rs b/devices/src/pci/pcie/pcie_rp.rs
index 89988c017..35c50a3a2 100644
--- a/devices/src/pci/pcie/pcie_rp.rs
+++ b/devices/src/pci/pcie/pcie_rp.rs
@@ -3,11 +3,11 @@
 // found in the LICENSE file.
 
 use std::collections::BTreeMap;
-use std::sync::mpsc;
 
 use anyhow::bail;
 use anyhow::Context;
 use anyhow::Result;
+use base::Event;
 use vm_control::GpeNotify;
 use vm_control::PmeNotify;
 
@@ -88,23 +88,33 @@ impl PciePortVariant for PcieRootPort {
 }
 
 impl HotPlugBus for PcieRootPort {
-    fn hot_plug(&mut self, addr: PciAddress) -> Result<Option<mpsc::Receiver<()>>> {
-        if self.pcie_port.is_cc_pending() {
-            bail!("Slot busy: plugging too early or guest does not support PCIe hotplug.");
+    fn hot_plug(&mut self, addr: PciAddress) -> Result<Option<Event>> {
+        if self.pcie_port.is_hpc_pending() {
+            bail!("Hot plug fail: previous slot event is pending.");
+        }
+        if !self.pcie_port.is_hotplug_ready() {
+            bail!("Hot unplug fail: slot is not enabled by the guest yet.");
         }
         self.downstream_devices
             .get(&addr)
             .context("No downstream devices.")?;
 
-        let (cc_sender, cc_recvr) = mpsc::channel();
-        self.pcie_port.set_cc_sender(cc_sender);
+        let hpc_sender = Event::new()?;
+        let hpc_recvr = hpc_sender.try_clone()?;
+        self.pcie_port.set_hpc_sender(hpc_sender);
         self.pcie_port
             .set_slot_status(PCIE_SLTSTA_PDS | PCIE_SLTSTA_ABP);
         self.pcie_port.trigger_hp_or_pme_interrupt();
-        Ok(Some(cc_recvr))
+        Ok(Some(hpc_recvr))
     }
 
-    fn hot_unplug(&mut self, addr: PciAddress) -> Result<Option<mpsc::Receiver<()>>> {
+    fn hot_unplug(&mut self, addr: PciAddress) -> Result<Option<Event>> {
+        if self.pcie_port.is_hpc_pending() {
+            bail!("Hot unplug fail: previous slot event is pending.");
+        }
+        if !self.pcie_port.is_hotplug_ready() {
+            bail!("Hot unplug fail: slot is not enabled by the guest yet.");
+        }
         self.downstream_devices
             .remove(&addr)
             .context("No downstream devices.")?;
@@ -120,17 +130,36 @@ impl HotPlugBus for PcieRootPort {
             self.removed_downstream.push(*guest_pci_addr);
         }
 
-        let (cc_sender, cc_recvr) = mpsc::channel();
-        if self.pcie_port.set_cc_sender(cc_sender).is_some() {
-            bail!("Slot busy: unplugging too early or guest does not support PCIe hotplug.");
+        let hpc_sender = Event::new()?;
+        let hpc_recvr = hpc_sender.try_clone()?;
+        let slot_control = self.pcie_port.get_slot_control();
+        match slot_control & PCIE_SLTCTL_PIC {
+            PCIE_SLTCTL_PIC_ON => {
+                self.pcie_port.set_hpc_sender(hpc_sender);
+                self.pcie_port.set_slot_status(PCIE_SLTSTA_ABP);
+                self.pcie_port.trigger_hp_or_pme_interrupt();
+            }
+            PCIE_SLTCTL_PIC_OFF => {
+                // Do not press attention button, as the slot is already off. Likely caused by
+                // previous hot plug failed.
+                self.pcie_port.mask_slot_status(!PCIE_SLTSTA_PDS);
+                hpc_sender.signal()?;
+            }
+            _ => {
+                // Power indicator in blinking state.
+                // Should not be possible, since the previous slot event is pending.
+                bail!("Hot unplug fail: Power indicator is blinking.");
+            }
         }
-        self.pcie_port.set_slot_status(PCIE_SLTSTA_ABP);
-        self.pcie_port.trigger_hp_or_pme_interrupt();
 
         if self.pcie_port.is_host() {
             self.pcie_port.hot_unplug()
         }
-        Ok(Some(cc_recvr))
+        Ok(Some(hpc_recvr))
+    }
+
+    fn get_ready_notification(&mut self) -> anyhow::Result<Event> {
+        Ok(self.pcie_port.get_ready_notification()?)
     }
 
     fn get_address(&self) -> Option<PciAddress> {
diff --git a/devices/src/pci/pcie/pcie_switch.rs b/devices/src/pci/pcie/pcie_switch.rs
index c3090cba9..13892692f 100644
--- a/devices/src/pci/pcie/pcie_switch.rs
+++ b/devices/src/pci/pcie/pcie_switch.rs
@@ -4,10 +4,10 @@
 
 use std::collections::BTreeMap;
 use std::str::FromStr;
-use std::sync::mpsc;
 
 use anyhow::bail;
 use base::error;
+use base::Event;
 
 use crate::bus::HotPlugBus;
 use crate::bus::HotPlugKey;
@@ -85,16 +85,20 @@ impl PciePortVariant for PcieUpstreamPort {
 // hotplug out.
 impl HotPlugBus for PcieUpstreamPort {
     // Do nothing. We are not a real hotplug bus.
-    fn hot_plug(&mut self, _addr: PciAddress) -> anyhow::Result<Option<mpsc::Receiver<()>>> {
+    fn hot_plug(&mut self, _addr: PciAddress) -> anyhow::Result<Option<Event>> {
         bail!("hot plug not supported on upstream port.")
     }
 
     // Just remove the downstream device.
-    fn hot_unplug(&mut self, addr: PciAddress) -> anyhow::Result<Option<mpsc::Receiver<()>>> {
+    fn hot_unplug(&mut self, addr: PciAddress) -> anyhow::Result<Option<Event>> {
         self.downstream_devices.remove(&addr);
         Ok(None)
     }
 
+    fn get_ready_notification(&mut self) -> anyhow::Result<Event> {
+        bail!("hot plug not supported on upstream port.")
+    }
+
     fn get_secondary_bus_number(&self) -> Option<u8> {
         Some(self.pcie_port.get_bus_range()?.secondary)
     }
@@ -213,26 +217,32 @@ impl PciePortVariant for PcieDownstreamPort {
 }
 
 impl HotPlugBus for PcieDownstreamPort {
-    fn hot_plug(&mut self, addr: PciAddress) -> anyhow::Result<Option<mpsc::Receiver<()>>> {
+    fn hot_plug(&mut self, addr: PciAddress) -> anyhow::Result<Option<Event>> {
         if !self.pcie_port.hotplug_implemented() {
             bail!("hotplug not implemented.");
         }
-        if self.downstream_devices.get(&addr).is_none() {
+        if !self.downstream_devices.contains_key(&addr) {
             bail!("no downstream devices.");
         }
+        if !self.pcie_port.is_hotplug_ready() {
+            bail!("Hot unplug fail: slot is not enabled by the guest yet.");
+        }
         self.pcie_port
             .set_slot_status(PCIE_SLTSTA_PDS | PCIE_SLTSTA_ABP);
         self.pcie_port.trigger_hp_or_pme_interrupt();
         Ok(None)
     }
 
-    fn hot_unplug(&mut self, addr: PciAddress) -> anyhow::Result<Option<mpsc::Receiver<()>>> {
+    fn hot_unplug(&mut self, addr: PciAddress) -> anyhow::Result<Option<Event>> {
         if !self.pcie_port.hotplug_implemented() {
             bail!("hotplug not implemented.");
         }
         if self.downstream_devices.remove(&addr).is_none() {
             bail!("no downstream devices.");
         }
+        if !self.pcie_port.is_hotplug_ready() {
+            bail!("Hot unplug fail: slot is not enabled by the guest yet.");
+        }
 
         if !self.hotplug_out_begin {
             self.removed_downstream.clear();
@@ -243,6 +253,22 @@ impl HotPlugBus for PcieDownstreamPort {
             }
             self.pcie_port.set_slot_status(PCIE_SLTSTA_ABP);
             self.pcie_port.trigger_hp_or_pme_interrupt();
+            let slot_control = self.pcie_port.get_slot_control();
+            match slot_control & PCIE_SLTCTL_PIC {
+                PCIE_SLTCTL_PIC_ON => {
+                    self.pcie_port.set_slot_status(PCIE_SLTSTA_ABP);
+                    self.pcie_port.trigger_hp_or_pme_interrupt();
+                }
+                PCIE_SLTCTL_PIC_OFF => {
+                    // Do not press attention button, as the slot is already off. Likely caused by
+                    // previous hot plug failed.
+                    self.pcie_port.mask_slot_status(!PCIE_SLTSTA_PDS);
+                }
+                _ => {
+                    // Power indicator in blinking state.
+                    bail!("Hot unplug fail: Power indicator is blinking.");
+                }
+            }
 
             if self.pcie_port.is_host() {
                 self.pcie_port.hot_unplug()
@@ -253,6 +279,10 @@ impl HotPlugBus for PcieDownstreamPort {
         Ok(None)
     }
 
+    fn get_ready_notification(&mut self) -> anyhow::Result<Event> {
+        Ok(self.pcie_port.get_ready_notification()?)
+    }
+
     fn get_address(&self) -> Option<PciAddress> {
         self.pcie_port.get_address()
     }
diff --git a/devices/src/pci/pm.rs b/devices/src/pci/pm.rs
index d14bc0d78..3b5244408 100644
--- a/devices/src/pci/pm.rs
+++ b/devices/src/pci/pm.rs
@@ -69,10 +69,13 @@ impl PciPmCap {
         }
     }
     pub fn default_cap() -> u16 {
-        PM_CAP_VERSION
-            | PM_CAP_PME_SUPPORT_D0
-            | PM_CAP_PME_SUPPORT_D3_HOT
-            | PM_CAP_PME_SUPPORT_D3_COLD
+        let mut cap = PM_CAP_VERSION;
+        // We use ACPI GPEs for PMEs, which are x86_64 only. We should
+        // implement support for native PCIe PMEs to support non-ACPI platforms.
+        if cfg!(target_arch = "x86_64") {
+            cap |= PM_CAP_PME_SUPPORT_D0 | PM_CAP_PME_SUPPORT_D3_HOT | PM_CAP_PME_SUPPORT_D3_COLD
+        }
+        cap
     }
 }
 
diff --git a/devices/src/pci/vfio_pci.rs b/devices/src/pci/vfio_pci.rs
index 94cfd7e75..132286dd3 100644
--- a/devices/src/pci/vfio_pci.rs
+++ b/devices/src/pci/vfio_pci.rs
@@ -11,7 +11,6 @@ use std::path::Path;
 use std::path::PathBuf;
 use std::str::FromStr;
 use std::sync::Arc;
-use std::u32;
 
 use acpi_tables::aml::Aml;
 use base::debug;
@@ -608,7 +607,10 @@ impl VfioPciWorker {
                         if let Some(gpe) = gpe {
                             if let Ok(val) = base::EventExt::read_count(&acpi_notify_evt) {
                                 notification_val.lock().push(val as u32);
-                                let request = VmRequest::Gpe(gpe);
+                                let request = VmRequest::Gpe {
+                                    gpe,
+                                    clear_evt: None,
+                                };
                                 if self.vm_socket.send(&request).is_ok() {
                                     if let Err(e) = self.vm_socket.recv::<VmResponse>() {
                                         error!("{} failed to send GPE: {}", self.name.clone(), e);
@@ -819,7 +821,7 @@ impl VfioPciDevice {
             base_class_code == PciClassCode::DisplayController && vendor_id == PCI_VENDOR_ID_INTEL;
         let device_data = if is_intel_gfx {
             Some(DeviceData::IntelGfxData {
-                opregion_index: u32::max_value(),
+                opregion_index: u32::MAX,
             })
         } else {
             None
diff --git a/devices/src/pflash.rs b/devices/src/pflash.rs
index 1e50cd014..4edc636ea 100644
--- a/devices/src/pflash.rs
+++ b/devices/src/pflash.rs
@@ -264,7 +264,7 @@ mod tests {
     const BLOCK_SIZE: u32 = 4 * (1 << 10); // 4K
 
     fn empty_image() -> Box<dyn DiskFile> {
-        let mut f = Box::new(tempfile().unwrap());
+        let f = Box::new(tempfile().unwrap());
         f.write_all_at_volatile(VolatileSlice::new(&mut [0xff].repeat(IMAGE_SIZE)), 0)
             .unwrap();
         f
@@ -284,7 +284,7 @@ mod tests {
 
     #[test]
     fn read() {
-        let mut f = empty_image();
+        let f = empty_image();
         let mut want = [0xde, 0xad, 0xbe, 0xef];
         let offset = 0x1000;
         f.write_all_at_volatile(VolatileSlice::new(&mut want), offset)
@@ -334,7 +334,7 @@ mod tests {
 
     #[test]
     fn erase() {
-        let mut f = empty_image();
+        let f = empty_image();
         let mut data = [0xde, 0xad, 0xbe, 0xef];
         let offset = 0x1000;
         f.write_all_at_volatile(VolatileSlice::new(&mut data), offset)
@@ -365,7 +365,7 @@ mod tests {
 
     #[test]
     fn status() {
-        let mut f = empty_image();
+        let f = empty_image();
         let mut data = [0xde, 0xad, 0xbe, 0xff];
         let offset = 0x0;
         f.write_all_at_volatile(VolatileSlice::new(&mut data), offset)
diff --git a/devices/src/pit.rs b/devices/src/pit.rs
index e244bdcd1..b892668ff 100644
--- a/devices/src/pit.rs
+++ b/devices/src/pit.rs
@@ -722,14 +722,25 @@ impl PitCounter {
         }
 
         let timer_len = Duration::from_nanos(u64::from(self.count) * NANOS_PER_SEC / FREQUENCY_HZ);
+        let safe_timer_len = if timer_len == Duration::new(0, 0) {
+            Duration::from_nanos(1)
+        } else {
+            timer_len
+        };
 
-        let period_ns = match self.get_command_mode() {
+        match self.get_command_mode() {
             Some(CommandMode::CommandInterrupt)
             | Some(CommandMode::CommandHWOneShot)
             | Some(CommandMode::CommandSWStrobe)
-            | Some(CommandMode::CommandHWStrobe) => None,
+            | Some(CommandMode::CommandHWStrobe) => {
+                if let Err(e) = self.timer.reset_oneshot(safe_timer_len) {
+                    error!("failed to reset oneshot timer: {}", e);
+                }
+            }
             Some(CommandMode::CommandRateGen) | Some(CommandMode::CommandSquareWaveGen) => {
-                Some(timer_len)
+                if let Err(e) = self.timer.reset_repeating(safe_timer_len) {
+                    error!("failed to reset repeating timer: {}", e);
+                }
             }
             // Don't arm timer if invalid mode.
             None => {
@@ -748,9 +759,8 @@ impl PitCounter {
                 warn!("Invalid command mode based on command {:#x}", self.command);
                 return;
             }
-        };
+        }
 
-        self.safe_arm_timer(timer_len, period_ns);
         self.timer_valid = true;
     }
 
@@ -837,16 +847,6 @@ impl PitCounter {
         }
     }
 
-    fn safe_arm_timer(&mut self, mut due: Duration, period: Option<Duration>) {
-        if due == Duration::new(0, 0) {
-            due = Duration::from_nanos(1);
-        }
-
-        if let Err(e) = self.timer.reset(due, period) {
-            error!("failed to reset timer: {}", e);
-        }
-    }
-
     fn get_ticks_passed(&self) -> u64 {
         match self.start {
             None => 0,
diff --git a/devices/src/pl030.rs b/devices/src/pl030.rs
index d473a21c2..35c49d508 100644
--- a/devices/src/pl030.rs
+++ b/devices/src/pl030.rs
@@ -6,7 +6,10 @@ use std::convert::TryFrom;
 use std::time::SystemTime;
 use std::time::UNIX_EPOCH;
 
+use anyhow::Context;
 use base::warn;
+use serde::Deserialize;
+use serde::Serialize;
 
 use crate::pci::CrosvmDeviceId;
 use crate::BusAccessInfo;
@@ -58,6 +61,13 @@ pub struct Pl030 {
     interrupt_active: bool,
 }
 
+#[derive(Debug, Serialize, Deserialize)]
+struct Pl030Snapshot {
+    counter_delta_time: u32,
+    match_value: u32,
+    interrupt_active: bool,
+}
+
 fn get_epoch_time() -> u32 {
     let epoch_time = SystemTime::now()
         .duration_since(UNIX_EPOCH)
@@ -156,7 +166,33 @@ impl BusDevice for Pl030 {
     }
 }
 
-impl Suspendable for Pl030 {}
+impl Suspendable for Pl030 {
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        serde_json::to_value(Pl030Snapshot {
+            counter_delta_time: self.counter_delta_time,
+            match_value: self.match_value,
+            interrupt_active: self.interrupt_active,
+        })
+        .with_context(|| format!("error serializing {}", self.debug_label()))
+    }
+
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
+        let deser: Pl030Snapshot = serde_json::from_value(data)
+            .with_context(|| format!("failed to deserialize {}", self.debug_label()))?;
+        self.counter_delta_time = deser.counter_delta_time;
+        self.match_value = deser.match_value;
+        self.interrupt_active = deser.interrupt_active;
+        Ok(())
+    }
+
+    fn sleep(&mut self) -> anyhow::Result<()> {
+        Ok(())
+    }
+
+    fn wake(&mut self) -> anyhow::Result<()> {
+        Ok(())
+    }
+}
 
 #[cfg(test)]
 mod tests {
diff --git a/devices/src/platform/vfio_platform.rs b/devices/src/platform/vfio_platform.rs
index 6d80fbdcf..a93f38acd 100644
--- a/devices/src/platform/vfio_platform.rs
+++ b/devices/src/platform/vfio_platform.rs
@@ -4,14 +4,11 @@
 
 use std::fs::File;
 use std::sync::Arc;
-use std::u32;
 
 use anyhow::bail;
 use anyhow::Context;
 use anyhow::Result;
 use base::error;
-#[cfg(any(target_os = "android", target_os = "linux"))]
-use base::linux::MemoryMappingBuilderUnix;
 use base::pagesize;
 use base::AsRawDescriptor;
 use base::AsRawDescriptors;
@@ -19,8 +16,6 @@ use base::Event;
 use base::MappedRegion;
 use base::MemoryMapping;
 use base::MemoryMappingBuilder;
-#[cfg(windows)]
-use base::MemoryMappingBuilderWindows;
 use base::Protection;
 use base::RawDescriptor;
 use hypervisor::MemCacheType;
@@ -202,7 +197,7 @@ impl VfioPlatformDevice {
             let offset = region_offset + mmap_offset;
 
             let mmap = match MemoryMappingBuilder::new(mmap_size as usize)
-                .from_descriptor(self.device.device_file())
+                .from_file(self.device.device_file())
                 .offset(offset)
                 .build()
             {
diff --git a/devices/src/proxy.rs b/devices/src/proxy.rs
index f44678c94..c4cbfc814 100644
--- a/devices/src/proxy.rs
+++ b/devices/src/proxy.rs
@@ -9,7 +9,6 @@ use std::fs;
 use anyhow::anyhow;
 use base::error;
 use base::info;
-use base::linux::process::fork_process;
 use base::AsRawDescriptor;
 #[cfg(feature = "swap")]
 use base::AsRawDescriptors;
@@ -17,6 +16,7 @@ use base::RawDescriptor;
 use base::SharedMemory;
 use base::Tube;
 use base::TubeError;
+use jail::fork::fork_process;
 use libc::pid_t;
 use minijail::Minijail;
 use remain::sorted;
@@ -115,7 +115,11 @@ fn child_proc<D: BusDevice>(tube: Tube, mut device: D) {
     match tube.recv() {
         Ok(Command::Activate) => {
             if let Err(e) = tube.send(&CommandResult::Ok) {
-                error!("sending activation result failed: {:?}", &e);
+                error!(
+                    "sending {} activation result failed: {}",
+                    device.debug_label(),
+                    e,
+                );
                 return;
             }
         }
@@ -125,7 +129,11 @@ fn child_proc<D: BusDevice>(tube: Tube, mut device: D) {
         }
         // Most likely tube error is caused by other end is dropped, release resource.
         Err(e) => {
-            error!("device failed before activation: {:?}. Dropping device", e);
+            error!(
+                "{} device failed before activation: {}. Dropping device",
+                device.debug_label(),
+                e,
+            );
             drop(device);
             return;
         }
@@ -133,8 +141,12 @@ fn child_proc<D: BusDevice>(tube: Tube, mut device: D) {
     loop {
         let cmd = match tube.recv() {
             Ok(cmd) => cmd,
-            Err(err) => {
-                error!("child device process failed recv: {}", err);
+            Err(e) => {
+                error!(
+                    "recv from {} child device process failed: {}",
+                    device.debug_label(),
+                    e,
+                );
                 break;
             }
         };
@@ -225,7 +237,11 @@ fn child_proc<D: BusDevice>(tube: Tube, mut device: D) {
             }
         };
         if let Err(e) = res {
-            error!("child device process failed send: {}", e);
+            error!(
+                "send to {} child device process failed: {}",
+                device.debug_label(),
+                e,
+            );
         }
     }
 }
diff --git a/devices/src/serial.rs b/devices/src/serial.rs
index aef9eb633..2b4bf475f 100644
--- a/devices/src/serial.rs
+++ b/devices/src/serial.rs
@@ -251,7 +251,7 @@ impl Serial {
                                     Ok(0) => {
                                         return rx;
                                     }
-                                    Ok(_) => {
+                                    Ok(_n) => {
                                         if send_channel.send(rx_buf[0]).is_err() {
                                             // The receiver has disconnected.
                                             return rx;
@@ -679,10 +679,10 @@ mod tests {
             Vec::new(),
         );
 
-        serial.write(serial_bus_address(DATA), &[b'a']);
-        serial.write(serial_bus_address(DATA), &[b'b']);
-        serial.write(serial_bus_address(DATA), &[b'c']);
-        assert_eq!(serial_out.buf.lock().as_slice(), &[b'a', b'b', b'c']);
+        serial.write(serial_bus_address(DATA), b"a");
+        serial.write(serial_bus_address(DATA), b"b");
+        serial.write(serial_bus_address(DATA), b"c");
+        assert_eq!(serial_out.buf.lock().as_slice(), b"abc");
     }
 
     #[test]
@@ -701,7 +701,7 @@ mod tests {
         );
 
         serial.write(serial_bus_address(IER), &[IER_RECV_BIT]);
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
 
         assert_eq!(intr_evt.wait(), Ok(()));
         let mut data = [0u8; 1];
@@ -729,7 +729,7 @@ mod tests {
         );
 
         serial.write(serial_bus_address(IER), &[IER_RECV_BIT]);
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
 
         assert_eq!(intr_evt.wait(), Ok(()));
         let mut data = [0u8; 1];
@@ -778,7 +778,7 @@ mod tests {
         );
 
         serial.write(serial_bus_address(IER), &[IER_RECV_BIT]);
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
 
         assert_eq!(intr_evt.wait(), Ok(()));
         let mut data = [0u8; 1];
@@ -817,7 +817,7 @@ mod tests {
         );
 
         serial.write(serial_bus_address(IER), &[IER_RECV_BIT]);
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
 
         assert_eq!(intr_evt.wait(), Ok(()));
         let mut data = [0u8; 1];
@@ -826,7 +826,7 @@ mod tests {
         // Take snapshot after reading b'a'. Serial still contains b'b' and b'c'.
         let snap = serial.snapshot().expect("failed to snapshot serial");
         serial.clear_in_buffer();
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
         serial.read(serial_bus_address(DATA), &mut data[..]);
         assert_eq!(data[0], b'a');
         serial.read(serial_bus_address(DATA), &mut data[..]);
@@ -864,7 +864,7 @@ mod tests {
         );
 
         serial.write(serial_bus_address(IER), &[IER_RECV_BIT]);
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
 
         assert_eq!(intr_evt.wait(), Ok(()));
         let mut data = [0u8; 1];
@@ -924,7 +924,7 @@ mod tests {
         );
 
         serial.write(serial_bus_address(IER), &[IER_RECV_BIT]);
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
 
         assert_eq!(intr_evt.wait(), Ok(()));
         let mut data = [0u8; 1];
@@ -948,7 +948,7 @@ mod tests {
 
     fn modify_device(serial: &mut Serial) {
         serial.clear_in_buffer();
-        serial.queue_input_bytes(&[b'a', b'b', b'c']).unwrap();
+        serial.queue_input_bytes(b"abc").unwrap();
     }
 
     suspendable_tests!(
@@ -999,18 +999,18 @@ mod tests {
             Vec::new(),
         );
 
-        serial.write(serial_bus_address(DATA), &[b'a']);
-        serial.write(serial_bus_address(DATA), &[b'\n']);
+        serial.write(serial_bus_address(DATA), b"a");
+        serial.write(serial_bus_address(DATA), b"\n");
         assert_timestamp_is_present(serial_out.buf.lock().as_slice(), "a");
         serial_out.buf.lock().clear();
 
-        serial.write(serial_bus_address(DATA), &[b'b']);
-        serial.write(serial_bus_address(DATA), &[b'\n']);
+        serial.write(serial_bus_address(DATA), b"b");
+        serial.write(serial_bus_address(DATA), b"\n");
         assert_timestamp_is_present(serial_out.buf.lock().as_slice(), "b");
         serial_out.buf.lock().clear();
 
-        serial.write(serial_bus_address(DATA), &[b'c']);
-        serial.write(serial_bus_address(DATA), &[b'\n']);
+        serial.write(serial_bus_address(DATA), b"c");
+        serial.write(serial_bus_address(DATA), b"\n");
         assert_timestamp_is_present(serial_out.buf.lock().as_slice(), "c");
         serial_out.buf.lock().clear();
     }
diff --git a/devices/src/serial/sys/windows.rs b/devices/src/serial/sys/windows.rs
index ca95e14df..1ae78f038 100644
--- a/devices/src/serial/sys/windows.rs
+++ b/devices/src/serial/sys/windows.rs
@@ -10,6 +10,7 @@ use std::time::Duration;
 
 use base::error;
 use base::named_pipes::PipeConnection;
+use base::AsRawDescriptor;
 use base::Event;
 use base::EventToken;
 use base::FileSync;
@@ -18,6 +19,7 @@ use base::Result;
 use base::TimerTrait;
 use base::WaitContext;
 use hypervisor::ProtectionType;
+use winapi::um::ioapiset::CancelIoEx;
 
 use crate::bus::BusDevice;
 use crate::serial_device::SerialInput;
@@ -56,7 +58,7 @@ impl Serial {
             };
             self.system_params.kill_evt = Some(self_kill_evt);
 
-            match thread::Builder::new()
+            let thread_result = thread::Builder::new()
                 .name(format!("{} sync thread", self.debug_label()))
                 .spawn(move || {
                     let mut worker = SyncWorker {
@@ -65,7 +67,9 @@ impl Serial {
                     };
                     worker.run();
                     worker
-                }) {
+                });
+
+            match thread_result {
                 Err(e) => {
                     error!("failed to spawn sync thread: {}", e);
                 }
@@ -139,6 +143,12 @@ impl Drop for Serial {
             let _ = kill_evt.signal();
         }
 
+        // TODO: only do this if serial stdin is enabled?
+        // SAFETY: We pass a valid file descriptor to `CancelIoEx`.
+        unsafe {
+            CancelIoEx(std::io::stdin().as_raw_descriptor(), std::ptr::null_mut());
+        }
+
         if let Some(sync_thread) = self.system_params.sync_thread.take() {
             let _ = sync_thread.join();
         }
@@ -161,7 +171,7 @@ impl SyncWorker {
             Ok(timer) => timer,
         };
 
-        if let Err(e) = timer.reset(Duration::from_secs(1), Some(Duration::from_secs(1))) {
+        if let Err(e) = timer.reset_repeating(Duration::from_secs(1)) {
             error!("failed to set timer for SyncWorker: {}", e);
             return;
         }
@@ -194,6 +204,7 @@ impl SyncWorker {
             for event in events.iter().filter(|e| e.is_readable) {
                 match event.token {
                     Token::Sync => {
+                        timer.mark_waited().unwrap();
                         if let Err(e) = self.file.fsync() {
                             error!("failed to fsync serial device, stopping sync thread: {}", e);
                             return;
diff --git a/devices/src/serial_device.rs b/devices/src/serial_device.rs
index dd4771161..3330a9ca2 100644
--- a/devices/src/serial_device.rs
+++ b/devices/src/serial_device.rs
@@ -105,9 +105,9 @@ impl Display for SerialType {
 #[serde(rename_all = "kebab-case")]
 pub enum SerialHardware {
     Serial,              // Standard PC-style (8250/16550 compatible) UART
-    VirtioConsole,       // virtio-console device (AsyncConsole)
+    VirtioConsole,       // virtio-console device
     Debugcon,            // Bochs style debug port
-    LegacyVirtioConsole, // legacy virtio-console device (Console)
+    LegacyVirtioConsole, // legacy virtio-console device (alias for VirtioConsole)
 }
 
 impl Default for SerialHardware {
diff --git a/devices/src/usb/backend/fido_backend/hid_utils.rs b/devices/src/usb/backend/fido_backend/hid_utils.rs
index 597521b1b..99101e63e 100644
--- a/devices/src/usb/backend/fido_backend/hid_utils.rs
+++ b/devices/src/usb/backend/fido_backend/hid_utils.rs
@@ -35,7 +35,7 @@ pub fn verify_is_fido_device(hidraw: &File) -> Result<()> {
     unsafe {
         let ret = handle_eintr_errno!(base::ioctl_with_mut_ref(
             hidraw,
-            HIDIOCGRDESCSIZE(),
+            HIDIOCGRDESCSIZE,
             &mut desc_size
         ));
         if ret < 0 || (desc_size as usize) < constants::HID_REPORT_DESC_HEADER.len() {
@@ -55,7 +55,7 @@ pub fn verify_is_fido_device(hidraw: &File) -> Result<()> {
     unsafe {
         let ret = handle_eintr_errno!(base::ioctl_with_mut_ref(
             hidraw,
-            HIDIOCGRDESC(),
+            HIDIOCGRDESC,
             &mut descriptor
         ));
         if ret < 0 {
diff --git a/devices/src/usb/backend/fido_backend/poll_thread.rs b/devices/src/usb/backend/fido_backend/poll_thread.rs
index 87ff3cbe5..a2bf92cb4 100644
--- a/devices/src/usb/backend/fido_backend/poll_thread.rs
+++ b/devices/src/usb/backend/fido_backend/poll_thread.rs
@@ -60,7 +60,7 @@ impl PollTimer {
     /// Arms the timer with its initialized interval.
     pub fn arm(&mut self) -> Result<()> {
         self.timer
-            .reset(self.interval, None)
+            .reset_oneshot(self.interval)
             .map_err(|error| Error::CannotArmPollTimer {
                 name: self.name.clone(),
                 error,
diff --git a/devices/src/vfio.rs b/devices/src/vfio.rs
index 53efbeb28..e09ae8fdb 100644
--- a/devices/src/vfio.rs
+++ b/devices/src/vfio.rs
@@ -2,7 +2,6 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-use std::cell::RefCell;
 use std::collections::HashMap;
 use std::ffi::CString;
 use std::fs::File;
@@ -17,7 +16,6 @@ use std::path::PathBuf;
 use std::ptr::addr_of_mut;
 use std::slice;
 use std::sync::Arc;
-use std::u32;
 
 use base::error;
 use base::ioctl;
@@ -58,8 +56,6 @@ use crate::IommuDevType;
 #[sorted]
 #[derive(Error, Debug)]
 pub enum VfioError {
-    #[error("failed to borrow global vfio container")]
-    BorrowVfioContainer,
     #[error("failed to duplicate VfioContainer")]
     ContainerDupError,
     #[error("failed to set container's IOMMU driver type as {0:?}: {1}")]
@@ -222,18 +218,13 @@ impl KvmVfioPviommu {
 
         // SAFETY:
         // Safe as we are the owner of vfio_dev_attr, which is valid.
-        let ret = unsafe {
-            ioctl_with_ref(
-                kvm_vfio_file,
-                kvm_sys::KVM_SET_DEVICE_ATTR(),
-                &vfio_dev_attr,
-            )
-        };
+        let ret =
+            unsafe { ioctl_with_ref(kvm_vfio_file, kvm_sys::KVM_SET_DEVICE_ATTR, &vfio_dev_attr) };
 
         if ret < 0 {
             Err(VfioError::KvmSetDeviceAttr(get_error()))
         } else {
-            // Safe as we verify the return value.
+            // SAFETY: Safe as we verify the return value.
             Ok(unsafe { File::from_raw_descriptor(ret) })
         }
     }
@@ -286,13 +277,8 @@ impl KvmVfioPviommu {
 
         // SAFETY:
         // Safe as we are the owner of vfio_dev_attr, which is valid.
-        let ret = unsafe {
-            ioctl_with_ref(
-                kvm_vfio_file,
-                kvm_sys::KVM_SET_DEVICE_ATTR(),
-                &vfio_dev_attr,
-            )
-        };
+        let ret =
+            unsafe { ioctl_with_ref(kvm_vfio_file, kvm_sys::KVM_SET_DEVICE_ATTR, &vfio_dev_attr) };
 
         if ret < 0 {
             Err(VfioError::KvmSetDeviceAttr(get_error()))
@@ -351,7 +337,7 @@ impl VfioContainer {
     pub fn new_from_container(container: File) -> Result<Self> {
         // SAFETY:
         // Safe as file is vfio container descriptor and ioctl is defined by kernel.
-        let version = unsafe { ioctl(&container, VFIO_GET_API_VERSION()) };
+        let version = unsafe { ioctl(&container, VFIO_GET_API_VERSION) };
         if version as u8 != VFIO_API_VERSION {
             return Err(VfioError::VfioApiVersion);
         }
@@ -364,20 +350,20 @@ impl VfioContainer {
     }
 
     fn is_group_set(&self, group_id: u32) -> bool {
-        self.groups.get(&group_id).is_some()
+        self.groups.contains_key(&group_id)
     }
 
     fn check_extension(&self, val: IommuType) -> bool {
         // SAFETY:
         // Safe as file is vfio container and make sure val is valid.
-        let ret = unsafe { ioctl_with_val(self, VFIO_CHECK_EXTENSION(), val as c_ulong) };
+        let ret = unsafe { ioctl_with_val(self, VFIO_CHECK_EXTENSION, val as c_ulong) };
         ret != 0
     }
 
     fn set_iommu(&mut self, val: IommuType) -> i32 {
         // SAFETY:
         // Safe as file is vfio container and make sure val is valid.
-        unsafe { ioctl_with_val(self, VFIO_SET_IOMMU(), val as c_ulong) }
+        unsafe { ioctl_with_val(self, VFIO_SET_IOMMU, val as c_ulong) }
     }
 
     fn set_iommu_checked(&mut self, val: IommuType) -> Result<()> {
@@ -434,7 +420,7 @@ impl VfioContainer {
             dma_map.flags |= VFIO_DMA_MAP_FLAG_WRITE;
         }
 
-        let ret = ioctl_with_ref(self, VFIO_IOMMU_MAP_DMA(), &dma_map);
+        let ret = ioctl_with_ref(self, VFIO_IOMMU_MAP_DMA, &dma_map);
         if ret != 0 {
             return Err(VfioError::IommuDmaMap(get_error()));
         }
@@ -466,7 +452,7 @@ impl VfioContainer {
         // SAFETY:
         // Safe as file is vfio container, dma_unmap is constructed by us, and
         // we check the return value
-        let ret = unsafe { ioctl_with_mut_ref(self, VFIO_IOMMU_UNMAP_DMA(), &mut dma_unmap) };
+        let ret = unsafe { ioctl_with_mut_ref(self, VFIO_IOMMU_UNMAP_DMA, &mut dma_unmap) };
         if ret != 0 || dma_unmap.size != size {
             return Err(VfioError::IommuDmaUnmap(get_error()));
         }
@@ -497,7 +483,7 @@ impl VfioContainer {
         // SAFETY:
         // Safe as file is vfio container, iommu_info has valid values,
         // and we check the return value
-        let ret = unsafe { ioctl_with_mut_ref(self, VFIO_IOMMU_GET_INFO(), &mut iommu_info) };
+        let ret = unsafe { ioctl_with_mut_ref(self, VFIO_IOMMU_GET_INFO, &mut iommu_info) };
         if ret != 0 || (iommu_info.flags & VFIO_IOMMU_INFO_PGSIZES) == 0 {
             return Err(VfioError::IommuGetInfo(get_error()));
         }
@@ -529,7 +515,7 @@ impl VfioContainer {
         // SAFETY:
         // Safe as file is vfio container, iommu_info_argsz has valid values,
         // and we check the return value
-        let ret = unsafe { ioctl_with_mut_ref(self, VFIO_IOMMU_GET_INFO(), &mut iommu_info_argsz) };
+        let ret = unsafe { ioctl_with_mut_ref(self, VFIO_IOMMU_GET_INFO, &mut iommu_info_argsz) };
         if ret != 0 {
             return Err(VfioError::IommuGetInfo(get_error()));
         }
@@ -546,7 +532,7 @@ impl VfioContainer {
             // SAFETY:
             // Safe as file is vfio container, iommu_info has valid values,
             // and we check the return value
-            unsafe { ioctl_with_mut_ptr(self, VFIO_IOMMU_GET_INFO(), iommu_info.as_mut_ptr()) };
+            unsafe { ioctl_with_mut_ptr(self, VFIO_IOMMU_GET_INFO, iommu_info.as_mut_ptr()) };
         if ret != 0 {
             return Err(VfioError::IommuGetInfo(get_error()));
         }
@@ -748,7 +734,7 @@ impl VfioGroup {
         let mut ret =
             // SAFETY:
             // Safe as we are the owner of group_file and group_status which are valid value.
-            unsafe { ioctl_with_mut_ref(&group_file, VFIO_GROUP_GET_STATUS(), &mut group_status) };
+            unsafe { ioctl_with_mut_ref(&group_file, VFIO_GROUP_GET_STATUS, &mut group_status) };
         if ret < 0 {
             return Err(VfioError::GetGroupStatus(get_error()));
         }
@@ -764,7 +750,7 @@ impl VfioGroup {
         ret = unsafe {
             ioctl_with_ref(
                 &group_file,
-                VFIO_GROUP_SET_CONTAINER(),
+                VFIO_GROUP_SET_CONTAINER,
                 &container_raw_descriptor,
             )
         };
@@ -820,11 +806,7 @@ impl VfioGroup {
         // Safe as we are the owner of vfio_dev_descriptor and vfio_dev_attr which are valid value,
         // and we verify the return value.
         if 0 != unsafe {
-            ioctl_with_ref(
-                kvm_vfio_file,
-                kvm_sys::KVM_SET_DEVICE_ATTR(),
-                &vfio_dev_attr,
-            )
+            ioctl_with_ref(kvm_vfio_file, kvm_sys::KVM_SET_DEVICE_ATTR, &vfio_dev_attr)
         } {
             return Err(VfioError::KvmSetDeviceAttr(get_error()));
         }
@@ -838,7 +820,7 @@ impl VfioGroup {
 
         // SAFETY:
         // Safe as we are the owner of self and path_ptr which are valid value.
-        let ret = unsafe { ioctl_with_ptr(self, VFIO_GROUP_GET_DEVICE_FD(), path_ptr) };
+        let ret = unsafe { ioctl_with_ptr(self, VFIO_GROUP_GET_DEVICE_FD, path_ptr) };
         if ret < 0 {
             return Err(VfioError::GroupGetDeviceFD(get_error()));
         }
@@ -867,122 +849,91 @@ impl AsRawDescriptor for VfioGroup {
     }
 }
 
-/// A helper trait for managing VFIO setup
-pub trait VfioCommonTrait: Send + Sync {
+/// A helper struct for managing VFIO containers
+#[derive(Default)]
+pub struct VfioContainerManager {
+    /// One VFIO container shared by all VFIO devices that don't attach to any IOMMU device.
+    no_iommu_container: Option<Arc<Mutex<VfioContainer>>>,
+
+    /// For IOMMU enabled devices, all VFIO groups that share the same IOVA space are managed by
+    /// one VFIO container.
+    iommu_containers: Vec<Arc<Mutex<VfioContainer>>>,
+
+    /// One VFIO container shared by all VFIO devices that attach to the CoIOMMU device.
+    coiommu_container: Option<Arc<Mutex<VfioContainer>>>,
+
+    /// One VFIO container shared by all VFIO devices that attach to pKVM.
+    pkvm_iommu_container: Option<Arc<Mutex<VfioContainer>>>,
+}
+
+impl VfioContainerManager {
+    pub fn new() -> Self {
+        Self::default()
+    }
+
     /// The single place to create a VFIO container for a PCI endpoint.
     ///
     /// The policy to determine whether an individual or a shared VFIO container
     /// will be created for this device is governed by the physical PCI topology,
-    /// and the argument iommu_enabled.
+    /// and the argument iommu_type.
     ///
     ///  # Arguments
     ///
     ///  * `sysfspath` - the path to the PCI device, e.g. /sys/bus/pci/devices/0000:02:00.0
-    ///  * `iommu_enabled` - whether virtio IOMMU is enabled on this device
-    fn vfio_get_container<P: AsRef<Path>>(
-        iommu_dev: IommuDevType,
-        sysfspath: Option<P>,
-    ) -> Result<Arc<Mutex<VfioContainer>>>;
-}
-
-thread_local! {
-
-    // One VFIO container is shared by all VFIO devices that don't
-    // attach to the virtio IOMMU device
-    static NO_IOMMU_CONTAINER: RefCell<Option<Arc<Mutex<VfioContainer>>>> = RefCell::new(None);
-
-    // For IOMMU enabled devices, all VFIO groups that share the same IOVA space
-    // are managed by one VFIO container
-    static IOMMU_CONTAINERS: RefCell<Option<Vec<Arc<Mutex<VfioContainer>>>>> = RefCell::new(Some(Default::default()));
-
-    // One VFIO container is shared by all VFIO devices that
-    // attach to the CoIOMMU device
-    static COIOMMU_CONTAINER: RefCell<Option<Arc<Mutex<VfioContainer>>>> = RefCell::new(None);
-
-    // One VFIO container is shared by all VFIO devices that attach to pKVM
-    static PKVM_IOMMU_CONTAINER: RefCell<Option<Arc<Mutex<VfioContainer>>>> = RefCell::new(None);
-}
-
-pub struct VfioCommonSetup;
-
-impl VfioCommonTrait for VfioCommonSetup {
-    fn vfio_get_container<P: AsRef<Path>>(
-        iommu_dev: IommuDevType,
+    ///  * `iommu_type` - which type of IOMMU is enabled on this device
+    pub fn get_container<P: AsRef<Path>>(
+        &mut self,
+        iommu_type: IommuDevType,
         sysfspath: Option<P>,
     ) -> Result<Arc<Mutex<VfioContainer>>> {
-        match iommu_dev {
+        match iommu_type {
             IommuDevType::NoIommu => {
-                // One VFIO container is used for all IOMMU disabled groups
-                NO_IOMMU_CONTAINER.with(|v| {
-                    if v.borrow().is_some() {
-                        if let Some(ref container) = *v.borrow() {
-                            Ok(container.clone())
-                        } else {
-                            Err(VfioError::BorrowVfioContainer)
-                        }
-                    } else {
-                        let container = Arc::new(Mutex::new(VfioContainer::new()?));
-                        *v.borrow_mut() = Some(container.clone());
-                        Ok(container)
-                    }
-                })
+                // One VFIO container is used for all IOMMU disabled groups.
+                if let Some(container) = &self.no_iommu_container {
+                    Ok(container.clone())
+                } else {
+                    let container = Arc::new(Mutex::new(VfioContainer::new()?));
+                    self.no_iommu_container = Some(container.clone());
+                    Ok(container)
+                }
             }
             IommuDevType::VirtioIommu => {
                 let path = sysfspath.ok_or(VfioError::InvalidPath)?;
                 let group_id = VfioGroup::get_group_id(path)?;
 
-                // One VFIO container is used for all devices belong to one VFIO group
+                // One VFIO container is used for all devices that belong to one VFIO group.
                 // NOTE: vfio_wrapper relies on each container containing exactly one group.
-                IOMMU_CONTAINERS.with(|v| {
-                    if let Some(ref mut containers) = *v.borrow_mut() {
-                        let container = containers
-                            .iter()
-                            .find(|container| container.lock().is_group_set(group_id));
-
-                        match container {
-                            None => {
-                                let container = Arc::new(Mutex::new(VfioContainer::new()?));
-                                containers.push(container.clone());
-                                Ok(container)
-                            }
-                            Some(container) => Ok(container.clone()),
-                        }
-                    } else {
-                        Err(VfioError::BorrowVfioContainer)
-                    }
-                })
+                if let Some(container) = self
+                    .iommu_containers
+                    .iter()
+                    .find(|container| container.lock().is_group_set(group_id))
+                {
+                    Ok(container.clone())
+                } else {
+                    let container = Arc::new(Mutex::new(VfioContainer::new()?));
+                    self.iommu_containers.push(container.clone());
+                    Ok(container)
+                }
             }
             IommuDevType::CoIommu => {
                 // One VFIO container is used for devices attached to CoIommu
-                COIOMMU_CONTAINER.with(|v| {
-                    if v.borrow().is_some() {
-                        if let Some(ref container) = *v.borrow() {
-                            Ok(container.clone())
-                        } else {
-                            Err(VfioError::BorrowVfioContainer)
-                        }
-                    } else {
-                        let container = Arc::new(Mutex::new(VfioContainer::new()?));
-                        *v.borrow_mut() = Some(container.clone());
-                        Ok(container)
-                    }
-                })
+                if let Some(container) = &self.coiommu_container {
+                    Ok(container.clone())
+                } else {
+                    let container = Arc::new(Mutex::new(VfioContainer::new()?));
+                    self.coiommu_container = Some(container.clone());
+                    Ok(container)
+                }
             }
             IommuDevType::PkvmPviommu => {
                 // One VFIO container is used for devices attached to pKVM
-                PKVM_IOMMU_CONTAINER.with(|v| {
-                    if v.borrow().is_some() {
-                        if let Some(ref container) = *v.borrow() {
-                            Ok(container.clone())
-                        } else {
-                            Err(VfioError::BorrowVfioContainer)
-                        }
-                    } else {
-                        let container = Arc::new(Mutex::new(VfioContainer::new()?));
-                        *v.borrow_mut() = Some(container.clone());
-                        Ok(container)
-                    }
-                })
+                if let Some(container) = &self.pkvm_iommu_container {
+                    Ok(container.clone())
+                } else {
+                    let container = Arc::new(Mutex::new(VfioContainer::new()?));
+                    self.pkvm_iommu_container = Some(container.clone());
+                    Ok(container)
+                }
             }
         }
     }
@@ -1202,7 +1153,7 @@ impl VfioDevice {
         device_feature[0].flags = VFIO_DEVICE_FEATURE_SET | VFIO_DEVICE_FEATURE_LOW_POWER_ENTRY;
         // SAFETY:
         // Safe as we are the owner of self and power_management which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_FEATURE(), &device_feature[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_FEATURE, &device_feature[0]) };
         if ret < 0 {
             Err(VfioError::VfioPmLowPowerEnter(get_error()))
         } else {
@@ -1234,7 +1185,7 @@ impl VfioDevice {
         }
         // SAFETY:
         // Safe as we are the owner of self and power_management which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_FEATURE(), &device_feature[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_FEATURE, &device_feature[0]) };
         if ret < 0 {
             Err(VfioError::VfioPmLowPowerEnter(get_error()))
         } else {
@@ -1249,7 +1200,7 @@ impl VfioDevice {
         device_feature[0].flags = VFIO_DEVICE_FEATURE_SET | VFIO_DEVICE_FEATURE_LOW_POWER_EXIT;
         // SAFETY:
         // Safe as we are the owner of self and power_management which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_FEATURE(), &device_feature[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_FEATURE, &device_feature[0]) };
         if ret < 0 {
             Err(VfioError::VfioPmLowPowerExit(get_error()))
         } else {
@@ -1270,7 +1221,7 @@ impl VfioDevice {
         }
         // SAFETY:
         // Safe as we are the owner of self and dsm which are valid value
-        let ret = unsafe { ioctl_with_mut_ref(&self.dev, VFIO_DEVICE_ACPI_DSM(), &mut dsm[0]) };
+        let ret = unsafe { ioctl_with_mut_ref(&self.dev, VFIO_DEVICE_ACPI_DSM, &mut dsm[0]) };
         if ret < 0 {
             Err(VfioError::VfioAcpiDsm(get_error()))
         } else {
@@ -1304,7 +1255,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioAcpiNotificationEnable(get_error()))
         } else {
@@ -1323,7 +1274,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioAcpiNotificationDisable(get_error()))
         } else {
@@ -1350,7 +1301,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioAcpiNotificationTest(get_error()))
         } else {
@@ -1397,7 +1348,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioIrqEnable(get_error()))
         } else {
@@ -1434,7 +1385,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioIrqEnable(get_error()))
         } else {
@@ -1453,7 +1404,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioIrqDisable(get_error()))
         } else {
@@ -1472,7 +1423,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioIrqUnmask(get_error()))
         } else {
@@ -1491,7 +1442,7 @@ impl VfioDevice {
 
         // SAFETY:
         // Safe as we are the owner of self and irq_set which are valid value
-        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS(), &irq_set[0]) };
+        let ret = unsafe { ioctl_with_ref(&self.dev, VFIO_DEVICE_SET_IRQS, &irq_set[0]) };
         if ret < 0 {
             Err(VfioError::VfioIrqMask(get_error()))
         } else {
@@ -1512,7 +1463,7 @@ impl VfioDevice {
         // SAFETY:
         // Safe as we are the owner of device_file and dev_info which are valid value,
         // and we verify the return value.
-        let ret = unsafe { ioctl_with_mut_ref(device_file, VFIO_DEVICE_GET_INFO(), &mut dev_info) };
+        let ret = unsafe { ioctl_with_mut_ref(device_file, VFIO_DEVICE_GET_INFO, &mut dev_info) };
         if ret < 0 {
             return Err(VfioError::VfioDeviceGetInfo(get_error()));
         }
@@ -1551,11 +1502,7 @@ impl VfioDevice {
             // Safe as we are the owner of dev and irq_info which are valid value,
             // and we verify the return value.
             let ret = unsafe {
-                ioctl_with_mut_ref(
-                    self.device_file(),
-                    VFIO_DEVICE_GET_IRQ_INFO(),
-                    &mut irq_info,
-                )
+                ioctl_with_mut_ref(self.device_file(), VFIO_DEVICE_GET_IRQ_INFO, &mut irq_info)
             };
             if ret < 0 || irq_info.count != 1 {
                 return Err(VfioError::VfioDeviceGetInfo(get_error()));
@@ -1587,7 +1534,7 @@ impl VfioDevice {
                 // SAFETY:
                 // Safe as we are the owner of dev and reg_info which are valid value,
                 // and we verify the return value.
-                unsafe { ioctl_with_mut_ref(dev, VFIO_DEVICE_GET_REGION_INFO(), &mut reg_info) };
+                unsafe { ioctl_with_mut_ref(dev, VFIO_DEVICE_GET_REGION_INFO, &mut reg_info) };
             if ret < 0 {
                 continue;
             }
@@ -1610,7 +1557,7 @@ impl VfioDevice {
                 let ret = unsafe {
                     ioctl_with_mut_ref(
                         dev,
-                        VFIO_DEVICE_GET_REGION_INFO(),
+                        VFIO_DEVICE_GET_REGION_INFO,
                         &mut (region_with_cap[0].region_info),
                     )
                 };
diff --git a/devices/src/virtcpufreq.rs b/devices/src/virtcpufreq.rs
index c01ac4e31..f5c23b708 100644
--- a/devices/src/virtcpufreq.rs
+++ b/devices/src/virtcpufreq.rs
@@ -9,6 +9,9 @@ use base::Error;
 use std::os::unix::net::UnixStream;
 use std::sync::Arc;
 
+use anyhow::Context;
+use serde::Deserialize;
+use serde::Serialize;
 use sync::Mutex;
 
 use crate::pci::CrosvmDeviceId;
@@ -19,17 +22,23 @@ use crate::Suspendable;
 
 const CPUFREQ_GOV_SCALE_FACTOR_DEFAULT: u32 = 100;
 const CPUFREQ_GOV_SCALE_FACTOR_SCHEDUTIL: u32 = 80;
+const SCHED_SCALE_CAPACITY: u32 = 1024;
 
 const SCHED_FLAG_RESET_ON_FORK: u64 = 0x1;
 const SCHED_FLAG_KEEP_POLICY: u64 = 0x08;
 const SCHED_FLAG_KEEP_PARAMS: u64 = 0x10;
 const SCHED_FLAG_UTIL_CLAMP_MIN: u64 = 0x20;
+const SCHED_FLAG_UTIL_CLAMP_MAX: u64 = 0x40;
 
 const SCHED_FLAG_KEEP_ALL: u64 = SCHED_FLAG_KEEP_POLICY | SCHED_FLAG_KEEP_PARAMS;
 
+#[derive(Serialize, Deserialize)]
 pub struct VirtCpufreq {
-    cpu_fmax: u32,
-    cpu_capacity: u32,
+    pcpu_fmax: u32,
+    pcpu_capacity: u32,
+    vcpu_fmax: u32,
+    vcpu_capacity: u32,
+    vcpu_relative_capacity: u32,
     pcpu: u32,
     util_factor: u32,
 }
@@ -73,14 +82,18 @@ fn get_cpu_util_factor(cpu_id: u32) -> Result<u32, Error> {
 }
 
 impl VirtCpufreq {
-    pub fn new(pcpu: u32, _socket: Option<Arc<Mutex<UnixStream>>>) -> Self {
-        let cpu_capacity = get_cpu_capacity(pcpu).expect("Error reading capacity");
-        let cpu_fmax = get_cpu_maxfreq_khz(pcpu).expect("Error reading max freq");
+    pub fn new(pcpu: u32, cpu_capacity: u32, cpu_fmax: u32) -> Self {
         let util_factor = get_cpu_util_factor(pcpu).expect("Error getting util factor");
+        let pcpu_capacity = get_cpu_capacity(pcpu).expect("Error reading capacity");
+        let pcpu_fmax = get_cpu_maxfreq_khz(pcpu).expect("Error reading max freq");
+        let vcpu_relative_capacity = u32::try_from((u64::from(cpu_capacity) * u64::from(pcpu_fmax) / u64::from(cpu_fmax))).unwrap();
 
         VirtCpufreq {
-            cpu_fmax,
-            cpu_capacity,
+            pcpu_fmax,
+            pcpu_capacity,
+            vcpu_fmax: cpu_fmax,
+            vcpu_capacity: cpu_capacity,
+            vcpu_relative_capacity,
             pcpu,
             util_factor,
         }
@@ -107,7 +120,9 @@ impl BusDevice for VirtCpufreq {
         }
         // TODO(davidai): Evaluate opening file and re-reading the same fd.
         let freq = match get_cpu_curfreq_khz(self.pcpu) {
-            Ok(freq) => freq,
+            Ok(freq) => {
+                u32::try_from((u64::from(freq) * u64::from(self.pcpu_capacity) / u64::from(self.vcpu_relative_capacity))).unwrap()
+            },
             Err(e) => panic!("{}: Error reading freq: {}", self.debug_label(), e),
         };
 
@@ -129,18 +144,44 @@ impl BusDevice for VirtCpufreq {
         };
 
         // Util margin depends on the cpufreq governor on the host
-        let cpu_cap_scaled = self.cpu_capacity * self.util_factor / CPUFREQ_GOV_SCALE_FACTOR_DEFAULT;
-        let util = cpu_cap_scaled * freq / self.cpu_fmax;
+        let cpu_cap_scaled = self.vcpu_capacity * self.util_factor / CPUFREQ_GOV_SCALE_FACTOR_DEFAULT;
+        let util = u32::try_from(u64::from(cpu_cap_scaled) * u64::from(freq) / u64::from(self.vcpu_fmax)).unwrap();
 
         let mut sched_attr = sched_attr::default();
         sched_attr.sched_flags =
-            SCHED_FLAG_KEEP_ALL | SCHED_FLAG_UTIL_CLAMP_MIN | SCHED_FLAG_RESET_ON_FORK;
+            SCHED_FLAG_KEEP_ALL | SCHED_FLAG_UTIL_CLAMP_MIN | SCHED_FLAG_UTIL_CLAMP_MAX | SCHED_FLAG_RESET_ON_FORK;
         sched_attr.sched_util_min = util;
 
+        if self.vcpu_fmax != self.pcpu_fmax {
+            sched_attr.sched_util_max = util;
+        } else {
+            sched_attr.sched_util_max = 1024;
+        }
+
         if let Err(e) = sched_setattr(0, &mut sched_attr, 0) {
             panic!("{}: Error setting util value: {}", self.debug_label(), e);
         }
     }
 }
 
-impl Suspendable for VirtCpufreq {}
+impl Suspendable for VirtCpufreq {
+    // Device only active through MMIO writes. Vcpus are frozen before the device tries to sleep,
+    // so the device will not be active at time of calling function.
+    fn sleep(&mut self) -> anyhow::Result<()> {
+        Ok(())
+    }
+
+    fn wake(&mut self) -> anyhow::Result<()> {
+        Ok(())
+    }
+
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        serde_json::to_value(&self).with_context(|| format!("failed to serialize"))
+    }
+
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
+        let deser: Self = serde_json::from_value(data).with_context(|| format!("failed to deserialize"))?;
+        *self = deser;
+        Ok(())
+    }
+}
diff --git a/devices/src/virtio/async_device.rs b/devices/src/virtio/async_device.rs
deleted file mode 100644
index ff9c45434..000000000
--- a/devices/src/virtio/async_device.rs
+++ /dev/null
@@ -1,117 +0,0 @@
-// Copyright 2022 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-//! Provides helpers that make it easier to process virtio queues on an async executor.
-
-#![cfg_attr(windows, allow(dead_code))]
-
-use anyhow::bail;
-use anyhow::Context;
-use base::warn;
-use cros_async::AsyncResult;
-use cros_async::Executor;
-use cros_async::TaskHandle;
-use futures::future::AbortHandle;
-use futures::future::Abortable;
-use futures::future::Pending;
-use futures::Future;
-
-/// A queue for which processing can be started on an async executor.
-///
-/// `T` is the resource type of the queue, i.e. the device-specific data it needs in order to run.
-/// For instance, a block device will likely need a file to provide its data.
-pub enum AsyncQueueState<T: 'static> {
-    /// Queue is currently stopped.
-    Stopped(T),
-    /// Queue is being processed as a `Task` on an `Executor`, and can be stopped by aborting the
-    /// `AbortHandle`.
-    Running((TaskHandle<T>, Executor, AbortHandle)),
-    /// Something terrible happened and this queue is in a non-recoverable state.
-    Broken,
-}
-
-impl<T: 'static> AsyncQueueState<T> {
-    /// Start processing of the queue on `ex`, or stop and restart it with the new parameters if
-    /// it was already running.
-    ///
-    /// `fut_provider` is a closure that is passed the resource of the queue, as well as a
-    /// `Abortable` future. It must return a `Future` that takes ownership of the device's resource
-    /// and processes the queue for as long as possible, but immediately quits and returns the
-    /// device resource when the `Abortable` is signaled.
-    ///
-    /// If `fut_provider` or the `Future` it returns end with an error, the queue is considered
-    /// broken and cannot be used anymore.
-    ///
-    /// The task is only scheduled and no processing actually starts in this method. The task is
-    /// scheduled locally, which implies that `ex` must be run on the current thread.
-    pub fn start<
-        U: Future<Output = T> + 'static,
-        F: FnOnce(T, Abortable<Pending<()>>) -> anyhow::Result<U>,
-    >(
-        &mut self,
-        ex: &Executor,
-        fut_provider: F,
-    ) -> anyhow::Result<()> {
-        if matches!(self, AsyncQueueState::Running(_)) {
-            warn!("queue is already running, stopping it first");
-            self.stop().context("while trying to restart queue")?;
-        }
-
-        let resource = match std::mem::replace(self, AsyncQueueState::Broken) {
-            AsyncQueueState::Stopped(resource) => resource,
-            _ => bail!("queue is in a bad state and cannot be started"),
-        };
-
-        let (wait_fut, abort_handle) = futures::future::abortable(futures::future::pending::<()>());
-        let queue_future = fut_provider(resource, wait_fut)?;
-        let task = ex.spawn_local(queue_future);
-
-        *self = AsyncQueueState::Running((task, ex.clone(), abort_handle));
-        Ok(())
-    }
-
-    /// Stops a previously started queue.
-    ///
-    /// The executor on which the task has been started will be run if needed in order to retrieve
-    /// the queue's resource.
-    ///
-    /// Returns `true` if the queue was running, `false` if it wasn't.
-    pub fn stop(&mut self) -> AsyncResult<bool> {
-        // TODO: schuffelen - All callers should use stop_async instead.
-        match std::mem::replace(self, AsyncQueueState::Broken) {
-            AsyncQueueState::Running((task, ex, handle)) => {
-                // Abort the task and run it to completion to retrieve the queue's resource.
-                handle.abort();
-                let resource = ex.run_until(task)?;
-                *self = AsyncQueueState::Stopped(resource);
-                Ok(true)
-            }
-            state => {
-                *self = state;
-                Ok(false)
-            }
-        }
-    }
-    /// Stops a previously started queue.
-    ///
-    /// The executor on which the task has been started will be run if needed in order to retrieve
-    /// the queue's resource.
-    ///
-    /// Returns `true` if the queue was running, `false` if it wasn't.
-    pub async fn stop_async(&mut self) -> AsyncResult<bool> {
-        match std::mem::replace(self, AsyncQueueState::Broken) {
-            AsyncQueueState::Running((task, _, handle)) => {
-                // Abort the task and run it to completion to retrieve the queue's resource.
-                handle.abort();
-                let resource = task.await;
-                *self = AsyncQueueState::Stopped(resource);
-                Ok(true)
-            }
-            state => {
-                *self = state;
-                Ok(false)
-            }
-        }
-    }
-}
diff --git a/devices/src/virtio/balloon.rs b/devices/src/virtio/balloon.rs
index 461f8d92c..7a5d8ea96 100644
--- a/devices/src/virtio/balloon.rs
+++ b/devices/src/virtio/balloon.rs
@@ -101,11 +101,18 @@ pub enum BalloonError {
 }
 pub type Result<T> = std::result::Result<T, BalloonError>;
 
-// Balloon implements six virt IO queues: Inflate, Deflate, Stats, Event, WsData, WsCmd.
+// Balloon implements five virt IO queues: Inflate, Deflate, Stats, WsData, WsCmd.
 const QUEUE_SIZE: u16 = 128;
-const QUEUE_SIZES: &[u16] = &[
-    QUEUE_SIZE, QUEUE_SIZE, QUEUE_SIZE, QUEUE_SIZE, QUEUE_SIZE, QUEUE_SIZE,
-];
+const QUEUE_SIZES: &[u16] = &[QUEUE_SIZE, QUEUE_SIZE, QUEUE_SIZE, QUEUE_SIZE, QUEUE_SIZE];
+
+// Virtqueue indexes
+const INFLATEQ: usize = 0;
+const DEFLATEQ: usize = 1;
+const STATSQ: usize = 2;
+const _FREE_PAGE_VQ: usize = 3;
+const REPORTING_VQ: usize = 4;
+const WS_DATA_VQ: usize = 5;
+const WS_OP_VQ: usize = 6;
 
 const VIRTIO_BALLOON_PFN_SHIFT: u32 = 12;
 const VIRTIO_BALLOON_PF_SIZE: u64 = 1 << VIRTIO_BALLOON_PFN_SHIFT;
@@ -128,11 +135,6 @@ pub enum BalloonFeatures {
     WSReporting = VIRTIO_BALLOON_F_WS_REPORTING,
 }
 
-// These feature bits are part of the proposal:
-//  https://lists.oasis-open.org/archives/virtio-comment/202201/msg00139.html
-const VIRTIO_BALLOON_F_RESPONSIVE_DEVICE: u32 = 6; // Device actively watching guest memory
-const VIRTIO_BALLOON_F_EVENTS_VQ: u32 = 7; // Event vq is enabled
-
 // virtio_balloon_config is the balloon device configuration space defined by the virtio spec.
 #[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
 #[repr(C)]
@@ -202,15 +204,6 @@ impl BalloonStat {
     }
 }
 
-const VIRTIO_BALLOON_EVENT_PRESSURE: u32 = 1;
-const VIRTIO_BALLOON_EVENT_PUFF_FAILURE: u32 = 2;
-
-#[repr(C)]
-#[derive(Copy, Clone, Default, AsBytes, FromZeroes, FromBytes)]
-struct virtio_balloon_event_header {
-    evt_type: Le32,
-}
-
 // virtio_balloon_ws is used to deserialize from the ws data vq.
 #[repr(C)]
 #[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
@@ -353,7 +346,6 @@ async fn handle_queue<F>(
     mut queue: Queue,
     mut queue_event: EventAsync,
     release_memory_tube: Option<&Tube>,
-    interrupt: Interrupt,
     mut desc_handler: F,
     mut stop_rx: oneshot::Receiver<()>,
 ) -> Queue
@@ -378,7 +370,7 @@ where
             error!("balloon: failed to process inflate addresses: {}", e);
         }
         queue.add_used(avail_desc, 0);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
 }
 
@@ -406,7 +398,6 @@ async fn handle_reporting_queue<F>(
     mut queue: Queue,
     mut queue_event: EventAsync,
     release_memory_tube: Option<&Tube>,
-    interrupt: Interrupt,
     mut desc_handler: F,
     mut stop_rx: oneshot::Receiver<()>,
 ) -> Queue
@@ -430,7 +421,7 @@ where
             error!("balloon: failed to process reported buffer: {}", e);
         }
         queue.add_used(avail_desc, 0);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
 }
 
@@ -459,7 +450,6 @@ async fn handle_stats_queue(
     command_tube: &AsyncTube,
     #[cfg(feature = "registered_events")] registered_evt_q: Option<&SendTubeAsync>,
     state: Arc<AsyncRwLock<BalloonState>>,
-    interrupt: Interrupt,
     mut stop_rx: oneshot::Receiver<()>,
 ) -> Queue {
     let mut avail_desc = match queue
@@ -493,7 +483,7 @@ async fn handle_stats_queue(
 
         // Request a new stats_desc to the guest.
         queue.add_used(avail_desc, 0);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
 
         avail_desc = match queue.next_async(&mut queue_event).await {
             Err(e) => {
@@ -535,66 +525,6 @@ async fn send_adjusted_response(
     tube.send(result).await
 }
 
-async fn handle_event(
-    state: Arc<AsyncRwLock<BalloonState>>,
-    interrupt: Interrupt,
-    r: &mut Reader,
-    command_tube: &AsyncTube,
-) -> Result<()> {
-    match r.read_obj::<virtio_balloon_event_header>() {
-        Ok(hdr) => match hdr.evt_type.to_native() {
-            VIRTIO_BALLOON_EVENT_PRESSURE => {
-                // TODO(b/213962590): See how this can be integrated this into memory rebalancing
-            }
-            VIRTIO_BALLOON_EVENT_PUFF_FAILURE => {
-                let mut state = state.lock().await;
-                if state.failable_update {
-                    state.num_pages = state.actual_pages;
-                    interrupt.signal_config_changed();
-
-                    state.failable_update = false;
-                    send_adjusted_response(command_tube, state.actual_pages)
-                        .await
-                        .map_err(BalloonError::SendResponse)?;
-                }
-            }
-            _ => {
-                warn!("Unknown event {}", hdr.evt_type.to_native());
-            }
-        },
-        Err(e) => error!("Failed to parse event header {:?}", e),
-    }
-    Ok(())
-}
-
-// Async task that handles the events queue.
-async fn handle_events_queue(
-    mut queue: Queue,
-    mut queue_event: EventAsync,
-    state: Arc<AsyncRwLock<BalloonState>>,
-    interrupt: Interrupt,
-    command_tube: &AsyncTube,
-    mut stop_rx: oneshot::Receiver<()>,
-) -> Result<Queue> {
-    while let Some(mut avail_desc) = queue
-        .next_async_interruptable(&mut queue_event, &mut stop_rx)
-        .await
-        .map_err(BalloonError::AsyncAwait)?
-    {
-        handle_event(
-            state.clone(),
-            interrupt.clone(),
-            &mut avail_desc.reader,
-            command_tube,
-        )
-        .await?;
-
-        queue.add_used(avail_desc, 0);
-        queue.trigger_interrupt(&interrupt);
-    }
-    Ok(queue)
-}
-
 enum WSOp {
     WSReport,
     WSConfig {
@@ -609,7 +539,6 @@ async fn handle_ws_op_queue(
     mut queue_event: EventAsync,
     mut ws_op_rx: mpsc::Receiver<WSOp>,
     state: Arc<AsyncRwLock<BalloonState>>,
-    interrupt: Interrupt,
     mut stop_rx: oneshot::Receiver<()>,
 ) -> Result<Queue> {
     loop {
@@ -670,7 +599,7 @@ async fn handle_ws_op_queue(
 
         let len = writer.bytes_written() as u32;
         queue.add_used(avail_desc, len);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
 
     Ok(queue)
@@ -707,7 +636,6 @@ async fn handle_ws_data_queue(
     command_tube: &AsyncTube,
     #[cfg(feature = "registered_events")] registered_evt_q: Option<&SendTubeAsync>,
     state: Arc<AsyncRwLock<BalloonState>>,
-    interrupt: Interrupt,
     mut stop_rx: oneshot::Receiver<()>,
 ) -> Result<Queue> {
     loop {
@@ -748,7 +676,7 @@ async fn handle_ws_data_queue(
         }
 
         queue.add_used(avail_desc, 0);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
 }
 
@@ -855,8 +783,8 @@ struct BalloonQueues {
     deflate: Queue,
     stats: Option<Queue>,
     reporting: Option<Queue>,
-    events: Option<Queue>,
-    ws: (Option<Queue>, Option<Queue>),
+    ws_data: Option<Queue>,
+    ws_op: Option<Queue>,
 }
 
 impl BalloonQueues {
@@ -866,8 +794,8 @@ impl BalloonQueues {
             deflate,
             stats: None,
             reporting: None,
-            events: None,
-            ws: (None, None),
+            ws_data: None,
+            ws_op: None,
         }
     }
 }
@@ -878,8 +806,8 @@ struct PausedQueues {
     deflate: Queue,
     stats: Option<Queue>,
     reporting: Option<Queue>,
-    events: Option<Queue>,
-    ws: (Option<Queue>, Option<Queue>),
+    ws_data: Option<Queue>,
+    ws_op: Option<Queue>,
 }
 
 impl PausedQueues {
@@ -889,8 +817,8 @@ impl PausedQueues {
             deflate,
             stats: None,
             reporting: None,
-            events: None,
-            ws: (None, None),
+            ws_data: None,
+            ws_op: None,
         }
     }
 }
@@ -911,9 +839,8 @@ impl From<Box<PausedQueues>> for BTreeMap<usize, Queue> {
         ret.push(queues.deflate);
         apply_if_some(queues.stats, |stats| ret.push(stats));
         apply_if_some(queues.reporting, |reporting| ret.push(reporting));
-        apply_if_some(queues.events, |events| ret.push(events));
-        apply_if_some(queues.ws.0, |ws_data| ret.push(ws_data));
-        apply_if_some(queues.ws.1, |ws_op| ret.push(ws_op));
+        apply_if_some(queues.ws_data, |ws_data| ret.push(ws_data));
+        apply_if_some(queues.ws_op, |ws_op| ret.push(ws_op));
         // WARNING: We don't use the indices from the virito spec on purpose, see comment in
         // get_queues_from_map for the rationale.
         ret.into_iter().enumerate().collect()
@@ -938,8 +865,8 @@ fn run_worker(
     deflate_queue: Queue,
     stats_queue: Option<Queue>,
     reporting_queue: Option<Queue>,
-    events_queue: Option<Queue>,
-    ws_queues: (Option<Queue>, Option<Queue>),
+    ws_data_queue: Option<Queue>,
+    ws_op_queue: Option<Queue>,
     command_tube: Tube,
     vm_memory_client: VmMemoryClient,
     release_memory_tube: Option<Tube>,
@@ -972,7 +899,6 @@ fn run_worker(
             inflate_queue,
             EventAsync::new(inflate_queue_evt, &ex).expect("failed to create async event"),
             release_memory_tube.as_ref(),
-            interrupt.clone(),
             |guest_address, len| {
                 sys::free_memory(
                     &guest_address,
@@ -995,7 +921,6 @@ fn run_worker(
             deflate_queue,
             EventAsync::new(deflate_queue_evt, &ex).expect("failed to create async event"),
             None,
-            interrupt.clone(),
             |guest_address, len| {
                 sys::reclaim_memory(
                     &guest_address,
@@ -1025,7 +950,6 @@ fn run_worker(
                 #[cfg(feature = "registered_events")]
                 registered_evt_q_async.as_ref(),
                 state.clone(),
-                interrupt.clone(),
                 stop_rx,
             )
             .left_future()
@@ -1047,7 +971,6 @@ fn run_worker(
                 reporting_queue,
                 EventAsync::new(reporting_queue_evt, &ex).expect("failed to create async event"),
                 release_memory_tube.as_ref(),
-                interrupt.clone(),
                 |guest_address, len| {
                     sys::free_memory(
                         &guest_address,
@@ -1066,8 +989,8 @@ fn run_worker(
 
         // If VIRTIO_BALLOON_F_WS_REPORTING is set 2 queues must handled - one for WS data and one
         // for WS notifications.
-        let has_ws_data_queue = ws_queues.0.is_some();
-        let ws_data = if let Some(ws_data_queue) = ws_queues.0 {
+        let has_ws_data_queue = ws_data_queue.is_some();
+        let ws_data = if let Some(ws_data_queue) = ws_data_queue {
             let stop_rx = create_stop_oneshot(&mut stop_queue_oneshots);
             let ws_data_queue_evt = ws_data_queue
                 .event()
@@ -1080,7 +1003,6 @@ fn run_worker(
                 #[cfg(feature = "registered_events")]
                 registered_evt_q_async.as_ref(),
                 state.clone(),
-                interrupt.clone(),
                 stop_rx,
             )
             .left_future()
@@ -1091,8 +1013,8 @@ fn run_worker(
         pin_mut!(ws_data);
 
         let (ws_op_tx, ws_op_rx) = mpsc::channel::<WSOp>(1);
-        let has_ws_op_queue = ws_queues.1.is_some();
-        let ws_op = if let Some(ws_op_queue) = ws_queues.1 {
+        let has_ws_op_queue = ws_op_queue.is_some();
+        let ws_op = if let Some(ws_op_queue) = ws_op_queue {
             let stop_rx = create_stop_oneshot(&mut stop_queue_oneshots);
             let ws_op_queue_evt = ws_op_queue
                 .event()
@@ -1103,7 +1025,6 @@ fn run_worker(
                 EventAsync::new(ws_op_queue_evt, &ex).expect("failed to create async event"),
                 ws_op_rx,
                 state.clone(),
-                interrupt.clone(),
                 stop_rx,
             )
             .left_future()
@@ -1141,29 +1062,6 @@ fn run_worker(
         let kill = async_utils::await_and_exit(&ex, kill_evt);
         pin_mut!(kill);
 
-        // The next queue is used for events if VIRTIO_BALLOON_F_EVENTS_VQ is negotiated.
-        let has_events_queue = events_queue.is_some();
-        let events = if let Some(events_queue) = events_queue {
-            let stop_rx = create_stop_oneshot(&mut stop_queue_oneshots);
-            let events_queue_evt = events_queue
-                .event()
-                .try_clone()
-                .expect("failed to clone queue event");
-            handle_events_queue(
-                events_queue,
-                EventAsync::new(events_queue_evt, &ex).expect("failed to create async event"),
-                state.clone(),
-                interrupt,
-                &command_tube,
-                stop_rx,
-            )
-            .left_future()
-        } else {
-            std::future::pending().right_future()
-        };
-        let events = events.fuse();
-        pin_mut!(events);
-
         let pending_adjusted = handle_pending_adjusted_responses(
             EventAsync::new(pending_adjusted_response_event, &ex)
                 .expect("failed to create async event"),
@@ -1182,7 +1080,6 @@ fn run_worker(
                 _ = command.fuse() => return Err(anyhow!("command stopped unexpectedly")),
                 _ = ws_op => return Err(anyhow!("ws_op stopped unexpectedly")),
                 _ = resample.fuse() => return Err(anyhow!("resample stopped unexpectedly")),
-                _ = events => return Err(anyhow!("events stopped unexpectedly")),
                 _ = pending_adjusted.fuse() => return Err(anyhow!("pending_adjusted stopped unexpectedly")),
                 _ = ws_data => return Err(anyhow!("ws_data stopped unexpectedly")),
                 _ = target_reached.fuse() => return Err(anyhow!("target_reached stopped unexpectedly")),
@@ -1205,17 +1102,14 @@ fn run_worker(
             if has_reporting_queue {
                 paused_queues.reporting = Some(reporting.await);
             }
-            if has_events_queue {
-                paused_queues.events = Some(events.await.context("failed to stop events queue")?);
-            }
             if has_stats_queue {
                 paused_queues.stats = Some(stats.await);
             }
-            if has_ws_op_queue {
-                paused_queues.ws.0 = Some(ws_op.await.context("failed to stop ws_op queue")?);
-            }
             if has_ws_data_queue {
-                paused_queues.ws.1 = Some(ws_data.await.context("failed to stop ws_data queue")?);
+                paused_queues.ws_data = Some(ws_data.await.context("failed to stop ws_data queue")?);
+            }
+            if has_ws_op_queue {
+                paused_queues.ws_op = Some(ws_op.await.context("failed to stop ws_op queue")?);
             }
             Ok(paused_queues)
         });
@@ -1294,15 +1188,6 @@ struct BalloonSnapshot {
     ws_num_bins: u8,
 }
 
-/// Operation mode of the balloon.
-#[derive(PartialEq, Eq)]
-pub enum BalloonMode {
-    /// The driver can access pages in the balloon (i.e. F_DEFLATE_ON_OOM)
-    Relaxed,
-    /// The driver cannot access pages in the balloon. Implies F_RESPONSIVE_DEVICE.
-    Strict,
-}
-
 impl Balloon {
     /// Creates a new virtio balloon device.
     /// To let Balloon able to successfully release the memory which are pinned
@@ -1315,7 +1200,6 @@ impl Balloon {
         vm_memory_client: VmMemoryClient,
         release_memory_tube: Option<Tube>,
         init_balloon_size: u64,
-        mode: BalloonMode,
         enabled_features: u64,
         #[cfg(feature = "registered_events")] registered_evt_q: Option<SendTube>,
         ws_num_bins: u8,
@@ -1323,13 +1207,8 @@ impl Balloon {
         let features = base_features
             | 1 << VIRTIO_BALLOON_F_MUST_TELL_HOST
             | 1 << VIRTIO_BALLOON_F_STATS_VQ
-            | 1 << VIRTIO_BALLOON_F_EVENTS_VQ
-            | enabled_features
-            | if mode == BalloonMode::Strict {
-                1 << VIRTIO_BALLOON_F_RESPONSIVE_DEVICE
-            } else {
-                1 << VIRTIO_BALLOON_F_DEFLATE_ON_OOM
-            };
+            | 1 << VIRTIO_BALLOON_F_DEFLATE_ON_OOM
+            | enabled_features;
 
         Ok(Balloon {
             command_tube: Some(command_tube),
@@ -1369,29 +1248,6 @@ impl Balloon {
         }
     }
 
-    fn num_expected_queues(acked_features: u64) -> usize {
-        // at minimum we have inflate and deflate vqueues.
-        let mut num_queues = 2;
-        // stats vqueue
-        if acked_features & (1 << VIRTIO_BALLOON_F_STATS_VQ) != 0 {
-            num_queues += 1;
-        }
-        // events vqueue
-        if acked_features & (1 << VIRTIO_BALLOON_F_EVENTS_VQ) != 0 {
-            num_queues += 1;
-        }
-        // page reporting vqueue
-        if acked_features & (1 << VIRTIO_BALLOON_F_PAGE_REPORTING) != 0 {
-            num_queues += 1;
-        }
-        // working set vqueues
-        if acked_features & (1 << VIRTIO_BALLOON_F_WS_REPORTING) != 0 {
-            num_queues += 2;
-        }
-
-        num_queues
-    }
-
     fn stop_worker(&mut self) -> StoppedWorker<PausedQueues> {
         if let Some(worker_thread) = self.worker_thread.take() {
             let worker_ret = worker_thread.stop();
@@ -1420,36 +1276,46 @@ impl Balloon {
         &self,
         mut queues: BTreeMap<usize, Queue>,
     ) -> anyhow::Result<BalloonQueues> {
-        let expected_queues = Balloon::num_expected_queues(self.acked_features);
-        if queues.len() != expected_queues {
-            return Err(anyhow!(
-                "expected {} queues, got {}",
-                expected_queues,
-                queues.len()
-            ));
+        fn pop_queue(
+            queues: &mut BTreeMap<usize, Queue>,
+            expected_index: usize,
+            name: &str,
+        ) -> anyhow::Result<Queue> {
+            let (queue_index, queue) = queues
+                .pop_first()
+                .with_context(|| format!("missing {}", name))?;
+
+            if queue_index == expected_index {
+                debug!("{name} index {queue_index}");
+            } else {
+                warn!("expected {name} index {expected_index}, got {queue_index}");
+            }
+
+            Ok(queue)
         }
 
         // WARNING: We use `pop_first` instead of explicitly using the indices from the virtio spec
-        // because the Linux virtio drivers only "allocates" queue indices that are used.
-        let inflate_queue = queues.pop_first().unwrap().1;
-        let deflate_queue = queues.pop_first().unwrap().1;
+        // because the Linux virtio drivers only "allocates" queue indices that are used, so queues
+        // need to be removed in order of ascending virtqueue index.
+        let inflate_queue = pop_queue(&mut queues, INFLATEQ, "inflateq")?;
+        let deflate_queue = pop_queue(&mut queues, DEFLATEQ, "deflateq")?;
         let mut queue_struct = BalloonQueues::new(inflate_queue, deflate_queue);
 
         if self.acked_features & (1 << VIRTIO_BALLOON_F_STATS_VQ) != 0 {
-            queue_struct.stats = Some(queues.pop_first().unwrap().1);
+            queue_struct.stats = Some(pop_queue(&mut queues, STATSQ, "statsq")?);
         }
         if self.acked_features & (1 << VIRTIO_BALLOON_F_PAGE_REPORTING) != 0 {
-            queue_struct.reporting = Some(queues.pop_first().unwrap().1);
-        }
-        if self.acked_features & (1 << VIRTIO_BALLOON_F_EVENTS_VQ) != 0 {
-            queue_struct.events = Some(queues.pop_first().unwrap().1);
+            queue_struct.reporting = Some(pop_queue(&mut queues, REPORTING_VQ, "reporting_vq")?);
         }
         if self.acked_features & (1 << VIRTIO_BALLOON_F_WS_REPORTING) != 0 {
-            queue_struct.ws = (
-                Some(queues.pop_first().unwrap().1),
-                Some(queues.pop_first().unwrap().1),
-            );
+            queue_struct.ws_data = Some(pop_queue(&mut queues, WS_DATA_VQ, "ws_data_vq")?);
+            queue_struct.ws_op = Some(pop_queue(&mut queues, WS_OP_VQ, "ws_op_vq")?);
+        }
+
+        if !queues.is_empty() {
+            return Err(anyhow!("unexpected queues {:?}", queues.into_keys()));
         }
+
         Ok(queue_struct)
     }
 
@@ -1483,8 +1349,8 @@ impl Balloon {
                 queues.deflate,
                 queues.stats,
                 queues.reporting,
-                queues.events,
-                queues.ws,
+                queues.ws_data,
+                queues.ws_op,
                 command_tube,
                 vm_memory_client,
                 release_memory_tube,
@@ -1691,39 +1557,6 @@ mod tests {
         );
     }
 
-    #[test]
-    fn num_expected_queues() {
-        let to_feature_bits =
-            |features: &[u32]| -> u64 { features.iter().fold(0, |acc, f| acc | (1_u64 << f)) };
-
-        assert_eq!(2, Balloon::num_expected_queues(0));
-        assert_eq!(
-            2,
-            Balloon::num_expected_queues(to_feature_bits(&[VIRTIO_BALLOON_F_MUST_TELL_HOST]))
-        );
-        assert_eq!(
-            3,
-            Balloon::num_expected_queues(to_feature_bits(&[VIRTIO_BALLOON_F_STATS_VQ]))
-        );
-        assert_eq!(
-            5,
-            Balloon::num_expected_queues(to_feature_bits(&[
-                VIRTIO_BALLOON_F_STATS_VQ,
-                VIRTIO_BALLOON_F_EVENTS_VQ,
-                VIRTIO_BALLOON_F_PAGE_REPORTING
-            ]))
-        );
-        assert_eq!(
-            7,
-            Balloon::num_expected_queues(to_feature_bits(&[
-                VIRTIO_BALLOON_F_STATS_VQ,
-                VIRTIO_BALLOON_F_EVENTS_VQ,
-                VIRTIO_BALLOON_F_PAGE_REPORTING,
-                VIRTIO_BALLOON_F_WS_REPORTING
-            ]))
-        );
-    }
-
     struct BalloonContext {
         _ctrl_tube: Tube,
         _mem_client_tube: Tube,
@@ -1747,7 +1580,6 @@ mod tests {
                 VmMemoryClient::new(mem_client_tube_device),
                 None,
                 1024,
-                BalloonMode::Relaxed,
                 0,
                 #[cfg(feature = "registered_events")]
                 None,
diff --git a/devices/src/virtio/block/asynchronous.rs b/devices/src/virtio/block/asynchronous.rs
index 813149d02..0238fc517 100644
--- a/devices/src/virtio/block/asynchronous.rs
+++ b/devices/src/virtio/block/asynchronous.rs
@@ -16,7 +16,6 @@ use std::sync::atomic::AtomicU64;
 use std::sync::atomic::Ordering;
 use std::sync::Arc;
 use std::time::Duration;
-use std::u32;
 
 use anyhow::Context;
 use base::debug;
@@ -276,7 +275,6 @@ async fn process_one_chain(
     queue: &RefCell<Queue>,
     mut avail_desc: DescriptorChain,
     disk_state: &AsyncRwLock<DiskState>,
-    interrupt: &Interrupt,
     flush_timer: &RefCell<TimerAsync<Timer>>,
     flush_timer_armed: &RefCell<bool>,
 ) {
@@ -293,7 +291,7 @@ async fn process_one_chain(
 
     let mut queue = queue.borrow_mut();
     queue.add_used(avail_desc, len as u32);
-    queue.trigger_interrupt(interrupt);
+    queue.trigger_interrupt();
 }
 
 // There is one async task running `handle_queue` per virtio queue in use.
@@ -303,7 +301,6 @@ async fn handle_queue(
     disk_state: Rc<AsyncRwLock<DiskState>>,
     queue: Queue,
     evt: EventAsync,
-    interrupt: Interrupt,
     flush_timer: Rc<RefCell<TimerAsync<Timer>>>,
     flush_timer_armed: Rc<RefCell<bool>>,
     mut stop_rx: oneshot::Receiver<()>,
@@ -340,7 +337,6 @@ async fn handle_queue(
                 &queue,
                 descriptor_chain,
                 &disk_state,
-                &interrupt,
                 &flush_timer,
                 &flush_timer_armed,
             ));
@@ -350,7 +346,7 @@ async fn handle_queue(
 
 async fn handle_command_tube(
     command_tube: &Option<AsyncTube>,
-    interrupt: Interrupt,
+    interrupt: &RefCell<Option<Interrupt>>,
     disk_state: Rc<AsyncRwLock<DiskState>>,
 ) -> Result<(), ExecuteError> {
     let command_tube = match command_tube {
@@ -373,7 +369,9 @@ async fn handle_command_tube(
                     .await
                     .map_err(ExecuteError::SendingResponse)?;
                 if let DiskControlResult::Ok = resp {
-                    interrupt.signal_config_changed();
+                    if let Some(interrupt) = &*interrupt.borrow() {
+                        interrupt.signal_config_changed();
+                    }
                 }
             }
             Err(e) => return Err(ExecuteError::ReceivingCommand(e)),
@@ -384,7 +382,7 @@ async fn handle_command_tube(
 async fn resize(disk_state: &AsyncRwLock<DiskState>, new_size: u64) -> DiskControlResult {
     // Acquire exclusive, mutable access to the state so the virtqueue task won't be able to read
     // the state while resizing.
-    let mut disk_state = disk_state.lock().await;
+    let disk_state = disk_state.lock().await;
     // Prevent any other worker threads won't be able to do IO.
     let worker_shared_state = Arc::clone(&disk_state.worker_shared_state);
     let worker_shared_state = worker_shared_state.lock().await;
@@ -447,7 +445,6 @@ enum WorkerCmd {
     StartQueue {
         index: usize,
         queue: Queue,
-        interrupt: Interrupt,
     },
     StopQueue {
         index: usize,
@@ -455,6 +452,12 @@ enum WorkerCmd {
         // `None` indicates that there was no queue at the given index.
         response_tx: oneshot::Sender<Option<Queue>>,
     },
+    // Stop all queues without recovering the queues' state and without completing any queued up
+    // work .
+    AbortQueues {
+        // Once the queues are stopped, a `()` value will be sent back over `response_tx`.
+        response_tx: oneshot::Sender<()>,
+    },
 }
 
 // The main worker thread. Initialized the asynchronous worker tasks and passes them to the executor
@@ -465,7 +468,6 @@ enum WorkerCmd {
 // resizing command.
 async fn run_worker(
     ex: &Executor,
-    interrupt: Interrupt,
     disk_state: &Rc<AsyncRwLock<DiskState>>,
     control_tube: &Option<AsyncTube>,
     mut worker_rx: mpsc::UnboundedReceiver<WorkerCmd>,
@@ -476,7 +478,8 @@ async fn run_worker(
     let flush_timer_armed = Rc::new(RefCell::new(false));
 
     // Handles control requests.
-    let control = handle_command_tube(control_tube, interrupt.clone(), disk_state.clone()).fuse();
+    let control_interrupt = RefCell::new(None);
+    let control = handle_command_tube(control_tube, &control_interrupt, disk_state.clone()).fuse();
     pin_mut!(control);
 
     // Handle all the queues in one sub-select call.
@@ -499,7 +502,9 @@ async fn run_worker(
     pin_mut!(kill);
 
     // Process any requests to resample the irq value.
-    let resample_future = async_utils::handle_irq_resample(ex, interrupt.clone()).fuse();
+    let resample_future = std::future::pending::<anyhow::Result<()>>()
+        .fuse()
+        .left_future();
     pin_mut!(resample_future);
 
     // Running queue handlers.
@@ -517,14 +522,24 @@ async fn run_worker(
             worker_cmd = worker_rx.next() => {
                 match worker_cmd {
                     None => anyhow::bail!("worker control channel unexpectedly closed"),
-                    Some(WorkerCmd::StartQueue{index, queue, interrupt}) => {
+                    Some(WorkerCmd::StartQueue{index, queue}) => {
+                        if matches!(&*resample_future, futures::future::Either::Left(_)) {
+                            resample_future.set(
+                                async_utils::handle_irq_resample(ex, queue.interrupt().clone())
+                                    .fuse()
+                                    .right_future(),
+                            );
+                        }
+                        if control_interrupt.borrow().is_none() {
+                            *control_interrupt.borrow_mut() = Some(queue.interrupt().clone());
+                        }
+
                         let (tx, rx) = oneshot::channel();
                         let kick_evt = queue.event().try_clone().expect("Failed to clone queue event");
                         let (handle_queue_future, remote_handle) = handle_queue(
                             Rc::clone(disk_state),
                             queue,
                             EventAsync::new(kick_evt, ex).expect("Failed to create async event for queue"),
-                            interrupt,
                             Rc::clone(&flush_timer),
                             Rc::clone(&flush_timer_armed),
                             rx,
@@ -570,10 +585,29 @@ async fn run_worker(
                                         queue = fut => break queue,
                                     }
                                 };
+
+                                // If this is the last queue, drop references to the interrupt so
+                                // that, when queues are started up again, we'll use the new
+                                // interrupt passed with the first queue.
+                                if queue_handlers.is_empty() {
+                                    resample_future.set(std::future::pending().fuse().left_future());
+                                    *control_interrupt.borrow_mut() = None;
+                                }
+
                                 let _ = response_tx.send(Some(queue));
                             }
                             None => { let _ = response_tx.send(None); },
                         }
+
+                    }
+                    Some(WorkerCmd::AbortQueues{response_tx}) => {
+                        queue_handlers.clear();
+                        queue_handler_stop_fns.clear();
+
+                        resample_future.set(std::future::pending().fuse().left_future());
+                        *control_interrupt.borrow_mut() = None;
+
+                        let _ = response_tx.send(());
                     }
                 }
             }
@@ -600,13 +634,12 @@ pub struct BlockAsync {
     pub(super) executor_kind: ExecutorKind,
     // If `worker_per_queue == true`, `worker_threads` contains the worker for each running queue
     // by index. Otherwise, contains the monolithic worker for all queues at index 0.
-    worker_threads: BTreeMap<
-        usize,
-        (
-            WorkerThread<(Box<dyn DiskFile>, Option<Tube>)>,
-            mpsc::UnboundedSender<WorkerCmd>,
-        ),
-    >,
+    //
+    // Once a thread is started, we never stop it, except when `BlockAsync` itself is dropped. That
+    // is because we cannot easily convert the `AsyncDisk` back to a `DiskFile` when backed by
+    // Overlapped I/O on Windows because the file becomes permanently associated with the IOCP
+    // instance of the async executor.
+    worker_threads: BTreeMap<usize, (WorkerThread<()>, mpsc::UnboundedSender<WorkerCmd>)>,
     shared_state: Arc<AsyncRwLock<WorkerSharedState>>,
     // Whether to run worker threads in parallel for each queue
     worker_per_queue: bool,
@@ -640,7 +673,7 @@ impl BlockAsync {
             base::warn!("multiple workers requested, but not supported by disk image type");
             worker_per_queue = false;
         }
-        let executor_kind = disk_option.async_executor;
+        let executor_kind = disk_option.async_executor.unwrap_or_default();
         let boot_index = disk_option.bootindex;
         #[cfg(windows)]
         let io_concurrency = disk_option.io_concurrency.get();
@@ -677,7 +710,6 @@ impl BlockAsync {
             Self::build_avail_features(base_features, read_only, sparse, multi_queue, packed_queue);
 
         let seg_max = get_seg_max(q_size);
-        let executor_kind = executor_kind.unwrap_or_default();
 
         let disk_size = Arc::new(AtomicU64::new(disk_size));
         let shared_state = Arc::new(AsyncRwLock::new(WorkerSharedState {
@@ -828,7 +860,7 @@ impl BlockAsync {
                     let flush_delay = Duration::from_secs(60);
                     flush_timer
                         .borrow_mut()
-                        .reset(flush_delay, None)
+                        .reset_oneshot(flush_delay)
                         .map_err(ExecuteError::TimerReset)?;
                 }
             }
@@ -951,11 +983,7 @@ impl BlockAsync {
     fn start_worker(
         &mut self,
         idx: usize,
-        interrupt: Interrupt,
-    ) -> anyhow::Result<&(
-        WorkerThread<(Box<dyn DiskFile>, Option<Tube>)>,
-        mpsc::UnboundedSender<WorkerCmd>,
-    )> {
+    ) -> anyhow::Result<&(WorkerThread<()>, mpsc::UnboundedSender<WorkerCmd>)> {
         let key = if self.worker_per_queue { idx } else { 0 };
         if self.worker_threads.contains_key(&key) {
             return Ok(self.worker_threads.get(&key).unwrap());
@@ -999,15 +1027,7 @@ impl BlockAsync {
 
             if let Err(err_string) = ex
                 .run_until(async {
-                    let r = run_worker(
-                        &ex,
-                        interrupt,
-                        &disk_state,
-                        &async_control,
-                        worker_rx,
-                        kill_evt,
-                    )
-                    .await;
+                    let r = run_worker(&ex, &disk_state, &async_control, worker_rx, kill_evt).await;
                     // Flush any in-memory disk image state to file.
                     if let Err(e) = disk_state.lock().await.disk_image.flush().await {
                         error!("failed to flush disk image when stopping worker: {e:?}");
@@ -1018,15 +1038,6 @@ impl BlockAsync {
             {
                 error!("{:#}", err_string);
             }
-
-            let disk_state = match Rc::try_unwrap(disk_state) {
-                Ok(d) => d.into_inner(),
-                Err(_) => panic!("too many refs to the disk"),
-            };
-            (
-                disk_state.disk_image.into_inner(),
-                async_control.map(Tube::from),
-            )
         });
         match self.worker_threads.entry(key) {
             std::collections::btree_map::Entry::Occupied(_) => unreachable!(),
@@ -1041,15 +1052,10 @@ impl BlockAsync {
         idx: usize,
         queue: Queue,
         _mem: GuestMemory,
-        doorbell: Interrupt,
     ) -> anyhow::Result<()> {
-        let (_, worker_tx) = self.start_worker(idx, doorbell.clone())?;
+        let (_, worker_tx) = self.start_worker(idx)?;
         worker_tx
-            .unbounded_send(WorkerCmd::StartQueue {
-                index: idx,
-                queue,
-                interrupt: doorbell,
-            })
+            .unbounded_send(WorkerCmd::StartQueue { index: idx, queue })
             .expect("worker channel closed early");
         self.activated_queues.insert(idx);
         Ok(())
@@ -1123,44 +1129,35 @@ impl VirtioDevice for BlockAsync {
     fn activate(
         &mut self,
         mem: GuestMemory,
-        interrupt: Interrupt,
+        _interrupt: Interrupt,
         queues: BTreeMap<usize, Queue>,
     ) -> anyhow::Result<()> {
         for (i, q) in queues {
-            self.start_queue(i, q, mem.clone(), interrupt.clone())?;
+            self.start_queue(i, q, mem.clone())?;
         }
         Ok(())
     }
 
     fn reset(&mut self) -> anyhow::Result<()> {
-        while let Some((_, (worker_thread, _))) = self.worker_threads.pop_first() {
-            let (disk_image, control_tube) = worker_thread.stop();
-            self.disk_image = Some(disk_image);
-            if let Some(control_tube) = control_tube {
-                self.control_tube = Some(control_tube);
-            }
+        for (_, (_, worker_tx)) in self.worker_threads.iter_mut() {
+            let (response_tx, response_rx) = oneshot::channel();
+            worker_tx
+                .unbounded_send(WorkerCmd::AbortQueues { response_tx })
+                .expect("worker channel closed early");
+            cros_async::block_on(async { response_rx.await.expect("response_rx closed early") });
         }
         self.activated_queues.clear();
         Ok(())
     }
 
     fn virtio_sleep(&mut self) -> anyhow::Result<Option<BTreeMap<usize, Queue>>> {
-        if self.worker_threads.is_empty() {
-            return Ok(None); // Not activated.
-        }
-
         // Reclaim the queues from workers.
         let mut queues = BTreeMap::new();
         for index in self.activated_queues.clone() {
             queues.insert(index, self.stop_queue(index)?);
         }
-        // Shutdown the workers.
-        while let Some((_, (worker_thread, _))) = self.worker_threads.pop_first() {
-            let (disk_image, control_tube) = worker_thread.stop();
-            self.disk_image = Some(disk_image);
-            if let Some(control_tube) = control_tube {
-                self.control_tube = Some(control_tube);
-            }
+        if queues.is_empty() {
+            return Ok(None); // Not activated.
         }
         Ok(Some(queues))
     }
@@ -1169,9 +1166,9 @@ impl VirtioDevice for BlockAsync {
         &mut self,
         queues_state: Option<(GuestMemory, Interrupt, BTreeMap<usize, Queue>)>,
     ) -> anyhow::Result<()> {
-        if let Some((mem, interrupt, queues)) = queues_state {
+        if let Some((mem, _interrupt, queues)) = queues_state {
             for (i, q) in queues {
-                self.start_queue(i, q, mem.clone(), interrupt.clone())?
+                self.start_queue(i, q, mem.clone())?
             }
         }
         Ok(())
@@ -1265,6 +1262,10 @@ mod tests {
         let mut path = tempdir.path().to_owned();
         path.push("disk_image");
 
+        // Feature bits 0-23 and 50-127 are specific for the device type, but
+        // at the moment crosvm only supports 64 bits of feature bits.
+        const DEVICE_FEATURE_BITS: u64 = 0xffffff;
+
         // read-write block device
         {
             let f = File::create(&path).unwrap();
@@ -1272,9 +1273,9 @@ mod tests {
             let disk_option = DiskOption::default();
             let b = BlockAsync::new(features, Box::new(f), &disk_option, None, None, None).unwrap();
             // writable device should set VIRTIO_BLK_F_FLUSH + VIRTIO_BLK_F_DISCARD
-            // + VIRTIO_BLK_F_WRITE_ZEROES + VIRTIO_F_VERSION_1 + VIRTIO_BLK_F_BLK_SIZE
-            // + VIRTIO_BLK_F_SEG_MAX + VIRTIO_BLK_F_MQ + VIRTIO_RING_F_EVENT_IDX
-            assert_eq!(0x120007244, b.features());
+            // + VIRTIO_BLK_F_WRITE_ZEROES + VIRTIO_BLK_F_BLK_SIZE + VIRTIO_BLK_F_SEG_MAX
+            // + VIRTIO_BLK_F_MQ
+            assert_eq!(0x7244, b.features() & DEVICE_FEATURE_BITS);
         }
 
         // read-write block device, non-sparse
@@ -1287,9 +1288,8 @@ mod tests {
             };
             let b = BlockAsync::new(features, Box::new(f), &disk_option, None, None, None).unwrap();
             // writable device should set VIRTIO_F_FLUSH + VIRTIO_BLK_F_RO
-            // + VIRTIO_F_VERSION_1 + VIRTIO_BLK_F_BLK_SIZE + VIRTIO_BLK_F_SEG_MAX
-            // + VIRTIO_BLK_F_MQ + VIRTIO_RING_F_EVENT_IDX
-            assert_eq!(0x120005244, b.features());
+            // + VIRTIO_BLK_F_BLK_SIZE + VIRTIO_BLK_F_SEG_MAX + VIRTIO_BLK_F_MQ
+            assert_eq!(0x5244, b.features() & DEVICE_FEATURE_BITS);
         }
 
         // read-only block device
@@ -1302,9 +1302,8 @@ mod tests {
             };
             let b = BlockAsync::new(features, Box::new(f), &disk_option, None, None, None).unwrap();
             // read-only device should set VIRTIO_BLK_F_RO
-            // + VIRTIO_F_VERSION_1 + VIRTIO_BLK_F_BLK_SIZE + VIRTIO_BLK_F_SEG_MAX
-            // + VIRTIO_BLK_F_MQ + VIRTIO_RING_F_EVENT_IDX
-            assert_eq!(0x120001064, b.features());
+            // + VIRTIO_BLK_F_BLK_SIZE + VIRTIO_BLK_F_SEG_MAX + VIRTIO_BLK_F_MQ
+            assert_eq!(0x1064, b.features() & DEVICE_FEATURE_BITS);
         }
     }
 
@@ -1571,26 +1570,34 @@ mod tests {
         assert_eq!(returned_id, *id);
     }
 
-    // TODO(b/270225199): enable this test on Windows once IoSource::into_source is implemented
-    #[cfg(any(target_os = "android", target_os = "linux"))]
     #[test]
     fn reset_and_reactivate_single_worker() {
-        reset_and_reactivate(false);
+        reset_and_reactivate(false, None);
     }
 
-    // TODO(b/270225199): enable this test on Windows once IoSource::into_source is implemented
-    #[cfg(any(target_os = "android", target_os = "linux"))]
     #[test]
     fn reset_and_reactivate_multiple_workers() {
-        reset_and_reactivate(true);
+        reset_and_reactivate(true, None);
     }
 
-    #[cfg(any(target_os = "android", target_os = "linux"))]
-    fn reset_and_reactivate(enables_multiple_workers: bool) {
+    #[test]
+    #[cfg(windows)]
+    fn reset_and_reactivate_overrlapped_io() {
+        reset_and_reactivate(
+            false,
+            Some(
+                cros_async::sys::windows::ExecutorKindSys::Overlapped { concurrency: None }.into(),
+            ),
+        );
+    }
+
+    fn reset_and_reactivate(
+        enables_multiple_workers: bool,
+        async_executor: Option<cros_async::ExecutorKind>,
+    ) {
         // Create an empty disk image
-        let f = tempfile().unwrap();
-        f.set_len(0x1000).unwrap();
-        let disk_image: Box<dyn DiskFile> = Box::new(f);
+        let f = tempfile::NamedTempFile::new().unwrap();
+        f.as_file().set_len(0x1000).unwrap();
 
         // Create an empty guest memory
         let mem = GuestMemory::new(&[(GuestAddress(0u64), 4 * 1024 * 1024)])
@@ -1605,15 +1612,18 @@ mod tests {
         let features = base_features(ProtectionType::Unprotected);
         let id = b"Block serial number\0";
         let disk_option = DiskOption {
+            path: f.path().to_owned(),
             read_only: true,
             id: Some(*id),
             sparse: false,
             multiple_workers: enables_multiple_workers,
+            async_executor,
             ..Default::default()
         };
+        let disk_image = disk_option.open().unwrap();
         let mut b = BlockAsync::new(
             features,
-            disk_image.try_clone().unwrap(),
+            disk_image,
             &disk_option,
             Some(control_tube_device),
             None,
@@ -1621,25 +1631,23 @@ mod tests {
         )
         .unwrap();
 
+        let interrupt = Interrupt::new_for_test();
+
         // activate with queues of an arbitrary size.
         let mut q0 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q0.set_ready(true);
         let q0 = q0
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
         let mut q1 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q1.set_ready(true);
         let q1 = q1
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
-        b.activate(
-            mem.clone(),
-            Interrupt::new_for_test(),
-            BTreeMap::from([(0, q0), (1, q1)]),
-        )
-        .expect("activate should succeed");
+        b.activate(mem.clone(), interrupt, BTreeMap::from([(0, q0), (1, q1)]))
+            .expect("activate should succeed");
         // assert resources are consumed
         if !enables_multiple_workers {
             assert!(
@@ -1651,51 +1659,52 @@ mod tests {
             b.control_tube.is_none(),
             "BlockAsync should not have a control tube"
         );
+        assert_eq!(
+            b.worker_threads.len(),
+            if enables_multiple_workers { 2 } else { 1 }
+        );
 
-        // reset and assert resources are got back
+        // reset and assert resources are still not back (should be in the worker thread)
         assert!(b.reset().is_ok(), "reset should succeed");
+        if !enables_multiple_workers {
+            assert!(
+                b.disk_image.is_none(),
+                "BlockAsync should not have a disk image"
+            );
+        }
         assert!(
-            b.disk_image.is_some(),
-            "BlockAsync should have a disk image"
+            b.control_tube.is_none(),
+            "BlockAsync should not have a control tube"
         );
-        assert!(
-            b.control_tube.is_some(),
-            "BlockAsync should have a control tube"
+        assert_eq!(
+            b.worker_threads.len(),
+            if enables_multiple_workers { 2 } else { 1 }
         );
         assert_eq!(b.id, Some(*b"Block serial number\0"));
 
         // re-activate should succeed
+        let interrupt = Interrupt::new_for_test();
         let mut q0 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q0.set_ready(true);
         let q0 = q0
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
         let mut q1 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q1.set_ready(true);
         let q1 = q1
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
-        b.activate(
-            mem,
-            Interrupt::new_for_test(),
-            BTreeMap::from([(0, q0), (1, q1)]),
-        )
-        .expect("re-activate should succeed");
+        b.activate(mem, interrupt, BTreeMap::from([(0, q0), (1, q1)]))
+            .expect("re-activate should succeed");
     }
 
-    // TODO(b/270225199): enable this test on Windows once IoSource::into_source is implemented,
-    // or after finding a good way to prevent BlockAsync::drop() from panicking due to that.
-    #[cfg(any(target_os = "android", target_os = "linux"))]
     #[test]
     fn resize_with_single_worker() {
         resize(false);
     }
 
-    // TODO(b/270225199): enable this test on Windows once IoSource::into_source is implemented,
-    // or after finding a good way to prevent BlockAsync::drop() from panicking due to that.
-    #[cfg(any(target_os = "android", target_os = "linux"))]
     #[test]
     fn resize_with_multiple_workers() {
         // Test resize handled by one worker affect the whole state
@@ -1736,20 +1745,21 @@ mod tests {
         )
         .unwrap();
 
+        let interrupt = Interrupt::new_for_test();
+
         // activate with queues of an arbitrary size.
         let mut q0 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q0.set_ready(true);
         let q0 = q0
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
         let mut q1 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q1.set_ready(true);
         let q1 = q1
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
-        let interrupt = Interrupt::new_for_test();
         b.activate(mem, interrupt.clone(), BTreeMap::from([(0, q0), (1, q1)]))
             .expect("activate should succeed");
 
@@ -1812,9 +1822,6 @@ mod tests {
         );
     }
 
-    // TODO(b/270225199): enable this test on Windows once IoSource::into_source is implemented,
-    // or after finding a good way to prevent BlockAsync::drop() from panicking due to that.
-    #[cfg(any(target_os = "android", target_os = "linux"))]
     #[test]
     fn run_worker_threads() {
         // Create an empty duplicable disk image
@@ -1840,24 +1847,21 @@ mod tests {
         .unwrap();
 
         // activate with queues of an arbitrary size.
+        let interrupt = Interrupt::new_for_test();
         let mut q0 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q0.set_ready(true);
         let q0 = q0
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
         let mut q1 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q1.set_ready(true);
         let q1 = q1
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
-        b.activate(
-            mem.clone(),
-            Interrupt::new_for_test(),
-            BTreeMap::from([(0, q0), (1, q1)]),
-        )
-        .expect("activate should succeed");
+        b.activate(mem.clone(), interrupt, BTreeMap::from([(0, q0), (1, q1)]))
+            .expect("activate should succeed");
 
         assert_eq!(b.worker_threads.len(), 1, "1 threads should be spawned.");
         drop(b);
@@ -1873,24 +1877,21 @@ mod tests {
         let mut b = BlockAsync::new(features, disk_image, &disk_option, None, None, None).unwrap();
 
         // activate should succeed
+        let interrupt = Interrupt::new_for_test();
         let mut q0 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q0.set_ready(true);
         let q0 = q0
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
         let mut q1 = QueueConfig::new(DEFAULT_QUEUE_SIZE, 0);
         q1.set_ready(true);
         let q1 = q1
-            .activate(&mem, Event::new().unwrap())
+            .activate(&mem, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
-        b.activate(
-            mem,
-            Interrupt::new_for_test(),
-            BTreeMap::from([(0, q0), (1, q1)]),
-        )
-        .expect("activate should succeed");
+        b.activate(mem, interrupt, BTreeMap::from([(0, q0), (1, q1)]))
+            .expect("activate should succeed");
 
         assert_eq!(b.worker_threads.len(), 2, "2 threads should be spawned.");
     }
diff --git a/devices/src/virtio/block/mod.rs b/devices/src/virtio/block/mod.rs
index b06f31115..3b4cf640a 100644
--- a/devices/src/virtio/block/mod.rs
+++ b/devices/src/virtio/block/mod.rs
@@ -22,6 +22,9 @@ pub use asynchronous::BlockAsync;
 fn block_option_sparse_default() -> bool {
     true
 }
+fn block_option_lock_default() -> bool {
+    true
+}
 fn block_option_block_size_default() -> u32 {
     512
 }
@@ -93,6 +96,9 @@ pub struct DiskOption {
     // camel_case variant allowed for backward compatibility.
     #[serde(default, alias = "o_direct")]
     pub direct: bool,
+    /// Whether to lock the disk files. Uses flock on Unix and FILE_SHARE_* flags on Windows.
+    #[serde(default = "block_option_lock_default")]
+    pub lock: bool,
     // camel_case variant allowed for backward compatibility.
     #[serde(default = "block_option_block_size_default", alias = "block_size")]
     pub block_size: u32,
@@ -141,6 +147,7 @@ impl Default for DiskOption {
             root: false,
             sparse: block_option_sparse_default(),
             direct: false,
+            lock: block_option_lock_default(),
             block_size: block_option_block_size_default(),
             id: None,
             #[cfg(windows)]
@@ -200,6 +207,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -222,6 +230,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -244,6 +253,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -266,6 +276,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -288,6 +299,7 @@ mod tests {
                 root: true,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -310,6 +322,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -330,6 +343,7 @@ mod tests {
                 root: false,
                 sparse: false,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -352,6 +366,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: true,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -374,6 +389,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: true,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -396,6 +412,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 128,
                 id: None,
                 #[cfg(windows)]
@@ -418,6 +435,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 128,
                 id: None,
                 async_executor: None,
@@ -442,6 +460,7 @@ mod tests {
                     root: false,
                     sparse: true,
                     direct: false,
+                    lock: true,
                     block_size: 512,
                     id: None,
                     io_concurrency: NonZeroU32::new(4).unwrap(),
@@ -461,6 +480,7 @@ mod tests {
                     root: false,
                     sparse: true,
                     direct: false,
+                    lock: true,
                     block_size: 512,
                     id: None,
                     io_concurrency: NonZeroU32::new(1).unwrap(),
@@ -482,6 +502,7 @@ mod tests {
                     root: false,
                     sparse: true,
                     direct: false,
+                    lock: true,
                     block_size: 512,
                     id: None,
                     io_concurrency: NonZeroU32::new(1).unwrap(),
@@ -509,6 +530,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: Some(*b"DISK\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"),
                 #[cfg(windows)]
@@ -544,6 +566,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -566,6 +589,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -588,6 +612,7 @@ mod tests {
                 root: false,
                 sparse: true,
                 direct: false,
+                lock: true,
                 block_size: 512,
                 id: None,
                 #[cfg(windows)]
@@ -604,6 +629,51 @@ mod tests {
             }
         );
 
+        // lock=true
+        let params = from_block_arg("/path/to/disk.img,lock=true").unwrap();
+        assert_eq!(
+            params,
+            DiskOption {
+                path: "/path/to/disk.img".into(),
+                read_only: false,
+                root: false,
+                sparse: true,
+                direct: false,
+                lock: true,
+                block_size: 512,
+                id: None,
+                #[cfg(windows)]
+                io_concurrency: NonZeroU32::new(1).unwrap(),
+                multiple_workers: false,
+                async_executor: None,
+                packed_queue: false,
+                bootindex: None,
+                pci_address: None,
+            }
+        );
+        // lock=false
+        let params = from_block_arg("/path/to/disk.img,lock=false").unwrap();
+        assert_eq!(
+            params,
+            DiskOption {
+                path: "/path/to/disk.img".into(),
+                read_only: false,
+                root: false,
+                sparse: true,
+                direct: false,
+                lock: false,
+                block_size: 512,
+                id: None,
+                #[cfg(windows)]
+                io_concurrency: NonZeroU32::new(1).unwrap(),
+                multiple_workers: false,
+                async_executor: None,
+                packed_queue: false,
+                bootindex: None,
+                pci_address: None,
+            }
+        );
+
         // All together
         let params = from_block_arg(&format!(
             "/some/path.img,block_size=256,ro,root,sparse=false,id=DISK_LABEL\
@@ -618,6 +688,7 @@ mod tests {
                 root: true,
                 sparse: false,
                 direct: true,
+                lock: true,
                 block_size: 256,
                 id: Some(*b"DISK_LABEL\0\0\0\0\0\0\0\0\0\0"),
                 #[cfg(windows)]
@@ -644,6 +715,7 @@ mod tests {
             root: false,
             sparse: true,
             direct: false,
+            lock: true,
             block_size: 512,
             id: None,
             #[cfg(windows)]
@@ -665,6 +737,7 @@ mod tests {
             root: false,
             sparse: true,
             direct: false,
+            lock: true,
             block_size: 512,
             id: Some(*b"BLK\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"),
             #[cfg(windows)]
@@ -686,6 +759,7 @@ mod tests {
             root: false,
             sparse: true,
             direct: false,
+            lock: true,
             block_size: 512,
             id: Some(*b"QWERTYUIOPASDFGHJKL:"),
             #[cfg(windows)]
diff --git a/devices/src/virtio/block/sys/linux.rs b/devices/src/virtio/block/sys/linux.rs
index 56b3949a8..1dd20b2c5 100644
--- a/devices/src/virtio/block/sys/linux.rs
+++ b/devices/src/virtio/block/sys/linux.rs
@@ -4,16 +4,9 @@
 
 use std::cmp::max;
 use std::cmp::min;
-use std::fs::File;
-use std::fs::OpenOptions;
-use std::os::fd::AsRawFd;
 
 use anyhow::Context;
-use base::add_fd_flags;
-use base::flock;
-use base::open_file_or_duplicate;
 use base::unix::iov_max;
-use base::FlockOperation;
 use cros_async::Executor;
 use disk::DiskFile;
 
@@ -21,7 +14,7 @@ use crate::virtio::block::DiskOption;
 use crate::virtio::BlockAsync;
 
 pub fn get_seg_max(queue_size: u16) -> u32 {
-    let seg_max = min(max(iov_max(), 1), u32::max_value() as usize) as u32;
+    let seg_max = min(max(iov_max(), 1), u32::MAX as usize) as u32;
 
     // Since we do not currently support indirect descriptors, the maximum
     // number of segments must be smaller than the queue size.
@@ -32,30 +25,16 @@ pub fn get_seg_max(queue_size: u16) -> u32 {
 impl DiskOption {
     /// Open the specified disk file.
     pub fn open(&self) -> anyhow::Result<Box<dyn DiskFile>> {
-        let mut options = OpenOptions::new();
-        options.read(true).write(!self.read_only);
-
-        let raw_image: File = open_file_or_duplicate(&self.path, &options)
-            .with_context(|| format!("failed to load disk image {}", self.path.display()))?;
-        // Lock the disk image to prevent other crosvm instances from using it.
-        let lock_op = if self.read_only {
-            FlockOperation::LockShared
-        } else {
-            FlockOperation::LockExclusive
-        };
-        flock(&raw_image, lock_op, true)
-            .with_context(|| format!("failed to lock disk image {}", self.path.display()))?;
-
-        // If O_DIRECT is requested, set the flag via fcntl. It is not done at
-        // open_file_or_reuse time because it will reuse existing fd and will
-        // not actually use the given OpenOptions.
-        if self.direct {
-            add_fd_flags(raw_image.as_raw_fd(), libc::O_DIRECT)
-                .with_context(|| format!("failed to set O_DIRECT to {}", &self.path.display()))?;
-        }
-
-        disk::create_disk_file(raw_image, self.sparse, disk::MAX_NESTING_DEPTH, &self.path)
-            .context("create_disk_file failed")
+        disk::open_disk_file(disk::DiskFileParams {
+            path: self.path.clone(),
+            is_read_only: self.read_only,
+            is_sparse_file: self.sparse,
+            is_overlapped: false,
+            is_direct: self.direct,
+            lock: self.lock,
+            depth: 0,
+        })
+        .context("open_disk_file failed")
     }
 }
 
diff --git a/devices/src/virtio/block/sys/windows.rs b/devices/src/virtio/block/sys/windows.rs
index 7b66a1ab6..a977b7d25 100644
--- a/devices/src/virtio/block/sys/windows.rs
+++ b/devices/src/virtio/block/sys/windows.rs
@@ -2,19 +2,11 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-use std::fs::File;
-use std::fs::OpenOptions;
-use std::os::windows::fs::OpenOptionsExt;
-
 use anyhow::Context;
 use base::warn;
 use cros_async::sys::windows::ExecutorKindSys;
 use cros_async::Executor;
 use cros_async::ExecutorKind;
-use winapi::um::winbase::FILE_FLAG_NO_BUFFERING;
-use winapi::um::winbase::FILE_FLAG_OVERLAPPED;
-use winapi::um::winnt::FILE_SHARE_READ;
-use winapi::um::winnt::FILE_SHARE_WRITE;
 
 use crate::virtio::block::DiskOption;
 use crate::virtio::BlockAsync;
@@ -27,44 +19,18 @@ pub fn get_seg_max(_queue_size: u16) -> u32 {
 impl DiskOption {
     /// Open the specified disk file.
     pub fn open(&self) -> anyhow::Result<Box<dyn disk::DiskFile>> {
-        let mut open_option = OpenOptions::new();
-        open_option
-            .read(true)
-            .write(!self.read_only)
-            .share_mode(FILE_SHARE_READ | FILE_SHARE_WRITE);
-
-        let mut flags = 0;
-        if self.direct {
-            warn!("Opening disk file with no buffering");
-            flags |= FILE_FLAG_NO_BUFFERING;
-        }
-
-        let is_overlapped = matches!(
-            self.async_executor,
-            Some(ExecutorKind::SysVariants(
-                ExecutorKindSys::Overlapped { .. }
-            ))
-        );
-        if is_overlapped {
-            warn!("Opening disk file for overlapped IO");
-            flags |= FILE_FLAG_OVERLAPPED;
-        }
-
-        if flags != 0 {
-            open_option.custom_flags(flags);
-        }
-
-        let file = open_option
-            .open(&self.path)
-            .context("Failed to open disk file")?;
-        let image_type = disk::detect_image_type(&file, is_overlapped)?;
-        Ok(disk::create_disk_file_of_type(
-            file,
-            self.sparse,
-            disk::MAX_NESTING_DEPTH,
-            &self.path,
-            image_type,
-        )?)
+        Ok(disk::open_disk_file(disk::DiskFileParams {
+            path: self.path.clone(),
+            is_read_only: self.read_only,
+            is_sparse_file: self.sparse,
+            is_overlapped: matches!(
+                self.async_executor.unwrap_or_default(),
+                ExecutorKind::SysVariants(ExecutorKindSys::Overlapped { .. })
+            ),
+            is_direct: self.direct,
+            lock: self.lock,
+            depth: 0,
+        })?)
     }
 }
 
diff --git a/devices/src/virtio/console.rs b/devices/src/virtio/console.rs
index 2ade6f149..52d48c874 100644
--- a/devices/src/virtio/console.rs
+++ b/devices/src/virtio/console.rs
@@ -2,303 +2,58 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-//! Legacy console device that uses a polling thread. This is kept because it is still used by
-//! Windows ; outside of this use-case, please use [[asynchronous::AsyncConsole]] instead.
+//! Virtio console device.
+
+pub mod control;
+pub mod device;
+pub mod input;
+pub mod output;
+pub mod port;
+pub mod worker;
 
-pub mod asynchronous;
-mod multiport;
 mod sys;
 
 use std::collections::BTreeMap;
-use std::collections::VecDeque;
-use std::io;
-use std::io::Read;
-use std::io::Write;
-use std::ops::DerefMut;
-use std::result;
-use std::sync::Arc;
-
-use anyhow::anyhow;
+
 use anyhow::Context;
-use base::error;
-use base::AsRawDescriptor;
-use base::Descriptor;
-use base::Event;
-use base::EventToken;
 use base::RawDescriptor;
-#[cfg(windows)]
-use base::ReadNotifier;
-use base::WaitContext;
-use base::WorkerThread;
-use data_model::Le16;
-use data_model::Le32;
 use hypervisor::ProtectionType;
-use remain::sorted;
-use serde::Deserialize;
-use serde::Serialize;
-use sync::Mutex;
-use thiserror::Error as ThisError;
 use vm_memory::GuestMemory;
-use zerocopy::AsBytes;
-use zerocopy::FromBytes;
-use zerocopy::FromZeroes;
 
 use crate::serial::sys::InStreamType;
-use crate::virtio::base_features;
-use crate::virtio::copy_config;
+use crate::virtio::console::device::ConsoleDevice;
+use crate::virtio::console::device::ConsoleSnapshot;
+use crate::virtio::console::port::ConsolePort;
 use crate::virtio::DeviceType;
 use crate::virtio::Interrupt;
 use crate::virtio::Queue;
-use crate::virtio::Reader;
 use crate::virtio::VirtioDevice;
 use crate::PciAddress;
 
-pub(crate) const QUEUE_SIZE: u16 = 256;
-
-// For now, just implement port 0 (receiveq and transmitq).
-// If VIRTIO_CONSOLE_F_MULTIPORT is implemented, more queues will be needed.
-const QUEUE_SIZES: &[u16] = &[QUEUE_SIZE, QUEUE_SIZE];
-
-#[sorted]
-#[derive(ThisError, Debug)]
-pub enum ConsoleError {
-    /// There are no more available descriptors to receive into
-    #[error("no rx descriptors available")]
-    RxDescriptorsExhausted,
-}
-
-#[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
-#[repr(C)]
-pub struct virtio_console_config {
-    pub cols: Le16,
-    pub rows: Le16,
-    pub max_nr_ports: Le32,
-    pub emerg_wr: Le32,
-}
-
-/// Checks for input from `buffer` and transfers it to the receive queue, if any.
-///
-/// # Arguments
-///
-/// * `interrupt` - Interrupt used to signal that the queue has been used
-/// * `buffer` - Ring buffer providing data to put into the guest
-/// * `receive_queue` - The receive virtio Queue
-fn handle_input(
-    interrupt: &Interrupt,
-    buffer: &mut VecDeque<u8>,
-    receive_queue: &Arc<Mutex<Queue>>,
-) -> result::Result<(), ConsoleError> {
-    let mut receive_queue = receive_queue
-        .try_lock()
-        .expect("Lock should not be unavailable");
-    loop {
-        let mut desc = receive_queue
-            .peek()
-            .ok_or(ConsoleError::RxDescriptorsExhausted)?;
-
-        let writer = &mut desc.writer;
-        while writer.available_bytes() > 0 && !buffer.is_empty() {
-            let (buffer_front, buffer_back) = buffer.as_slices();
-            let buffer_chunk = if !buffer_front.is_empty() {
-                buffer_front
-            } else {
-                buffer_back
-            };
-            let written = writer.write(buffer_chunk).unwrap();
-            drop(buffer.drain(..written));
-        }
-
-        let bytes_written = writer.bytes_written() as u32;
-
-        if bytes_written > 0 {
-            let desc = desc.pop();
-            receive_queue.add_used(desc, bytes_written);
-            receive_queue.trigger_interrupt(interrupt);
-        }
-
-        if bytes_written == 0 {
-            return Ok(());
-        }
-    }
-}
-
-/// Writes the available data from the reader into the given output queue.
-///
-/// # Arguments
-///
-/// * `reader` - The Reader with the data we want to write.
-/// * `output` - The output sink we are going to write the data to.
-fn process_transmit_request(reader: &mut Reader, output: &mut dyn io::Write) -> io::Result<()> {
-    let len = reader.available_bytes();
-    let mut data = vec![0u8; len];
-    reader.read_exact(&mut data)?;
-    output.write_all(&data)?;
-    output.flush()?;
-    Ok(())
-}
-
-/// Processes the data taken from the given transmit queue into the output sink.
-///
-/// # Arguments
-///
-/// * `interrupt` - Interrupt used to signal (if required) that the queue has been used
-/// * `transmit_queue` - The transmit virtio Queue
-/// * `output` - The output sink we are going to write the data into
-fn process_transmit_queue(
-    interrupt: &Interrupt,
-    transmit_queue: &Arc<Mutex<Queue>>,
-    output: &mut dyn io::Write,
-) {
-    let mut needs_interrupt = false;
-    let mut transmit_queue = transmit_queue
-        .try_lock()
-        .expect("Lock should not be unavailable");
-    while let Some(mut avail_desc) = transmit_queue.pop() {
-        process_transmit_request(&mut avail_desc.reader, output)
-            .unwrap_or_else(|e| error!("console: process_transmit_request failed: {}", e));
-
-        transmit_queue.add_used(avail_desc, 0);
-        needs_interrupt = true;
-    }
-
-    if needs_interrupt {
-        transmit_queue.trigger_interrupt(interrupt);
-    }
-}
-
-struct Worker {
-    interrupt: Interrupt,
-    input: Option<Arc<Mutex<VecDeque<u8>>>>,
-    output: Box<dyn io::Write + Send>,
-    kill_evt: Event,
-    in_avail_evt: Event,
-    receive_queue: Arc<Mutex<Queue>>,
-    transmit_queue: Arc<Mutex<Queue>>,
-}
-
-impl Worker {
-    fn run(&mut self) -> anyhow::Result<()> {
-        #[derive(EventToken)]
-        enum Token {
-            ReceiveQueueAvailable,
-            TransmitQueueAvailable,
-            InputAvailable,
-            InterruptResample,
-            Kill,
-        }
-
-        let wait_ctx: WaitContext<Token> = WaitContext::build_with(&[
-            (
-                self.transmit_queue.lock().event(),
-                Token::TransmitQueueAvailable,
-            ),
-            (
-                self.receive_queue.lock().event(),
-                Token::ReceiveQueueAvailable,
-            ),
-            (&self.in_avail_evt, Token::InputAvailable),
-            (&self.kill_evt, Token::Kill),
-        ])?;
-        if let Some(resample_evt) = self.interrupt.get_resample_evt() {
-            wait_ctx.add(resample_evt, Token::InterruptResample)?;
-        }
-
-        let mut running = true;
-        while running {
-            let events = wait_ctx.wait()?;
-
-            for event in events.iter().filter(|e| e.is_readable) {
-                match event.token {
-                    Token::TransmitQueueAvailable => {
-                        self.transmit_queue
-                            .lock()
-                            .event()
-                            .wait()
-                            .context("failed reading transmit queue Event")?;
-                        process_transmit_queue(
-                            &self.interrupt,
-                            &self.transmit_queue,
-                            &mut self.output,
-                        );
-                    }
-                    Token::ReceiveQueueAvailable => {
-                        self.receive_queue
-                            .lock()
-                            .event()
-                            .wait()
-                            .context("failed reading receive queue Event")?;
-                        if let Some(in_buf_ref) = self.input.as_ref() {
-                            let _ = handle_input(
-                                &self.interrupt,
-                                in_buf_ref.lock().deref_mut(),
-                                &self.receive_queue,
-                            );
-                        }
-                    }
-                    Token::InputAvailable => {
-                        self.in_avail_evt
-                            .wait()
-                            .context("failed reading in_avail_evt")?;
-                        if let Some(in_buf_ref) = self.input.as_ref() {
-                            let _ = handle_input(
-                                &self.interrupt,
-                                in_buf_ref.lock().deref_mut(),
-                                &self.receive_queue,
-                            );
-                        }
-                    }
-                    Token::InterruptResample => {
-                        self.interrupt.interrupt_resample();
-                    }
-                    Token::Kill => running = false,
-                }
-            }
-        }
-        Ok(())
-    }
-}
+const QUEUE_SIZE: u16 = 256;
 
 /// Virtio console device.
 pub struct Console {
-    base_features: u64,
-    in_avail_evt: Event,
-    worker_thread: Option<WorkerThread<Worker>>,
-    input: Option<InStreamType>,
-    output: Option<Box<dyn io::Write + Send>>,
-    keep_descriptors: Vec<Descriptor>,
-    input_thread: Option<WorkerThread<InStreamType>>,
-    // input_buffer is not continuously updated. It holds the state of the buffer when a snapshot
-    // happens, or when a restore is performed. On a fresh startup, it will be empty. On a restore,
-    // it will contain whatever data was remaining in the buffer in the snapshot.
-    input_buffer: VecDeque<u8>,
+    console: ConsoleDevice,
+    queue_sizes: Vec<u16>,
     pci_address: Option<PciAddress>,
 }
 
-#[derive(Serialize, Deserialize)]
-struct ConsoleSnapshot {
-    base_features: u64,
-    input_buffer: VecDeque<u8>,
-}
-
 impl Console {
     fn new(
         protection_type: ProtectionType,
         input: Option<InStreamType>,
-        output: Option<Box<dyn io::Write + Send>>,
-        mut keep_rds: Vec<RawDescriptor>,
+        output: Option<Box<dyn std::io::Write + Send>>,
+        keep_rds: Vec<RawDescriptor>,
         pci_address: Option<PciAddress>,
     ) -> Console {
-        let in_avail_evt = Event::new().expect("failed creating Event");
-        keep_rds.push(in_avail_evt.as_raw_descriptor());
+        let port = ConsolePort::new(input, output, None, keep_rds);
+        let console = ConsoleDevice::new_single_port(protection_type, port);
+        let queue_sizes = vec![QUEUE_SIZE; console.max_queues()];
+
         Console {
-            base_features: base_features(protection_type),
-            in_avail_evt,
-            worker_thread: None,
-            input,
-            output,
-            keep_descriptors: keep_rds.iter().map(|rd| Descriptor(*rd)).collect(),
-            input_thread: None,
-            input_buffer: VecDeque::new(),
+            console,
+            queue_sizes,
             pci_address,
         }
     }
@@ -306,15 +61,11 @@ impl Console {
 
 impl VirtioDevice for Console {
     fn keep_rds(&self) -> Vec<RawDescriptor> {
-        // return the raw descriptors as opposed to descriptor.
-        self.keep_descriptors
-            .iter()
-            .map(|descr| descr.as_raw_descriptor())
-            .collect()
+        self.console.keep_rds()
     }
 
     fn features(&self) -> u64 {
-        self.base_features
+        self.console.features()
     }
 
     fn device_type(&self) -> DeviceType {
@@ -322,71 +73,26 @@ impl VirtioDevice for Console {
     }
 
     fn queue_max_sizes(&self) -> &[u16] {
-        QUEUE_SIZES
+        &self.queue_sizes
     }
 
     fn read_config(&self, offset: u64, data: &mut [u8]) {
-        let config = virtio_console_config {
-            max_nr_ports: 1.into(),
-            ..Default::default()
-        };
-        copy_config(data, 0, config.as_bytes(), offset);
+        self.console.read_config(offset, data);
+    }
+
+    fn on_device_sandboxed(&mut self) {
+        self.console.start_input_threads();
     }
 
     fn activate(
         &mut self,
         _mem: GuestMemory,
-        interrupt: Interrupt,
-        mut queues: BTreeMap<usize, Queue>,
+        _interrupt: Interrupt,
+        queues: BTreeMap<usize, Queue>,
     ) -> anyhow::Result<()> {
-        if queues.len() < 2 {
-            return Err(anyhow!("expected 2 queues, got {}", queues.len()));
+        for (idx, queue) in queues.into_iter() {
+            self.console.start_queue(idx, queue)?
         }
-
-        let receive_queue = queues.remove(&0).unwrap();
-        let transmit_queue = queues.remove(&1).unwrap();
-
-        let in_avail_evt = self
-            .in_avail_evt
-            .try_clone()
-            .context("failed creating input available Event pair")?;
-
-        // Spawn a separate thread to poll self.input.
-        // A thread is used because io::Read only provides a blocking interface, and there is no
-        // generic way to add an io::Read instance to a poll context (it may not be backed by a file
-        // descriptor).  Moving the blocking read call to a separate thread and sending data back to
-        // the main worker thread with an event for notification bridges this gap.
-        let input = match self.input.take() {
-            Some(read) => {
-                let (buffer, thread) = sys::spawn_input_thread(
-                    read,
-                    &self.in_avail_evt,
-                    std::mem::take(&mut self.input_buffer),
-                );
-                self.input_thread = Some(thread);
-                Some(buffer)
-            }
-            None => None,
-        };
-        let output = self.output.take().unwrap_or_else(|| Box::new(io::sink()));
-
-        self.worker_thread = Some(WorkerThread::start("v_console", move |kill_evt| {
-            let mut worker = Worker {
-                interrupt,
-                input,
-                output,
-                in_avail_evt,
-                kill_evt,
-                // Device -> driver
-                receive_queue: Arc::new(Mutex::new(receive_queue)),
-                // Driver -> device
-                transmit_queue: Arc::new(Mutex::new(transmit_queue)),
-            };
-            if let Err(e) = worker.run() {
-                error!("console run failure: {:?}", e);
-            };
-            worker
-        }));
         Ok(())
     }
 
@@ -395,100 +101,50 @@ impl VirtioDevice for Console {
     }
 
     fn reset(&mut self) -> anyhow::Result<()> {
-        if let Some(input_thread) = self.input_thread.take() {
-            self.input = Some(input_thread.stop());
-        }
-        if let Some(worker_thread) = self.worker_thread.take() {
-            let worker = worker_thread.stop();
-            // NOTE: Even though we are reseting the device, it still makes sense to preserve the
-            // pending input bytes that the host sent but the guest hasn't accepted yet.
-            self.input_buffer = worker
-                .input
-                .map_or(VecDeque::new(), |arc_mutex| arc_mutex.lock().clone());
-            self.output = Some(worker.output);
-        }
-        Ok(())
+        self.console.reset()
     }
 
     fn virtio_sleep(&mut self) -> anyhow::Result<Option<BTreeMap<usize, Queue>>> {
-        if let Some(input_thread) = self.input_thread.take() {
-            self.input = Some(input_thread.stop());
+        // Stop and collect all the queues.
+        let mut queues = BTreeMap::new();
+        for idx in 0..self.console.max_queues() {
+            if let Some(queue) = self
+                .console
+                .stop_queue(idx)
+                .with_context(|| format!("failed to stop queue {idx}"))?
+            {
+                queues.insert(idx, queue);
+            }
         }
-        if let Some(worker_thread) = self.worker_thread.take() {
-            let worker = worker_thread.stop();
-            self.input_buffer = worker
-                .input
-                .map_or(VecDeque::new(), |arc_mutex| arc_mutex.lock().clone());
-            self.output = Some(worker.output);
-            let receive_queue = match Arc::try_unwrap(worker.receive_queue) {
-                Ok(mutex) => mutex.into_inner(),
-                Err(_) => return Err(anyhow!("failed to retrieve receive queue to sleep device.")),
-            };
-            let transmit_queue = match Arc::try_unwrap(worker.transmit_queue) {
-                Ok(mutex) => mutex.into_inner(),
-                Err(_) => {
-                    return Err(anyhow!(
-                        "failed to retrieve transmit queue to sleep device."
-                    ))
-                }
-            };
-            return Ok(Some(BTreeMap::from([
-                (0, receive_queue),
-                (1, transmit_queue),
-            ])));
+
+        if !queues.is_empty() {
+            Ok(Some(queues))
+        } else {
+            Ok(None)
         }
-        Ok(None)
     }
 
     fn virtio_wake(
         &mut self,
         queues_state: Option<(GuestMemory, Interrupt, BTreeMap<usize, Queue>)>,
     ) -> anyhow::Result<()> {
-        match queues_state {
-            None => Ok(()),
-            Some((mem, interrupt, queues)) => {
-                // TODO(khei): activate is just what we want at the moment, but we should probably
-                // move it into a "start workers" function to make it obvious that
-                // it isn't strictly used for activate events.
-                self.activate(mem, interrupt, queues)?;
-                Ok(())
+        if let Some((_mem, _interrupt, queues)) = queues_state {
+            for (idx, queue) in queues.into_iter() {
+                self.console.start_queue(idx, queue)?;
             }
         }
+        Ok(())
     }
 
     fn virtio_snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
-        if let Some(read) = self.input.as_mut() {
-            // If the device was not activated yet, we still read the input.
-            // It's fine to do so since the the data is not lost. It will get queued in the
-            // input_buffer and restored. When the device activates, the data will still be
-            // available, and if there's any new data, that new data will get appended.
-            let input_buffer = Arc::new(Mutex::new(std::mem::take(&mut self.input_buffer)));
-
-            let kill_evt = Event::new().unwrap();
-            let _ = kill_evt.signal();
-            sys::read_input(read, &self.in_avail_evt, input_buffer.clone(), kill_evt);
-            self.input_buffer = std::mem::take(&mut input_buffer.lock());
-        };
-        serde_json::to_value(ConsoleSnapshot {
-            // Snapshot base_features as a safeguard when restoring the console device. Saving this
-            // info allows us to validate that the proper config was used for the console.
-            base_features: self.base_features,
-            input_buffer: self.input_buffer.clone(),
-        })
-        .context("failed to snapshot virtio console")
+        let snap = self.console.snapshot()?;
+        serde_json::to_value(snap).context("failed to snapshot virtio console")
     }
 
     fn virtio_restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
-        let deser: ConsoleSnapshot =
+        let snap: ConsoleSnapshot =
             serde_json::from_value(data).context("failed to deserialize virtio console")?;
-        anyhow::ensure!(
-            self.base_features == deser.base_features,
-            "Virtio console incorrect base features for restore:\n Expected: {}, Actual: {}",
-            self.base_features,
-            deser.base_features,
-        );
-        self.input_buffer = deser.input_buffer;
-        Ok(())
+        self.console.restore(&snap)
     }
 }
 
@@ -504,51 +160,95 @@ mod tests {
 
     struct ConsoleContext {
         #[cfg(windows)]
-        input_peer: named_pipes::PipeConnection,
+        input_pipe_client: named_pipes::PipeConnection,
     }
 
     fn modify_device(_context: &mut ConsoleContext, b: &mut Console) {
-        b.input_buffer.push_back(0);
+        let input_buffer = b.console.ports[0].clone_input_buffer();
+        input_buffer.lock().push_back(0);
     }
 
+    #[cfg(any(target_os = "android", target_os = "linux"))]
     fn create_device() -> (ConsoleContext, Console) {
-        #[cfg(any(target_os = "android", target_os = "linux"))]
-        let (input, context) = (Box::new(tempfile().unwrap()), ConsoleContext {});
-        #[cfg(windows)]
-        let (input, context) = {
-            let (x, y) = named_pipes::pair(
-                &named_pipes::FramingMode::Byte,
-                &named_pipes::BlockingMode::NoWait,
-                0,
-            )
-            .unwrap();
-            (Box::new(x), ConsoleContext { input_peer: y })
-        };
-
+        let input = Box::new(tempfile().unwrap());
         let output = Box::new(tempfile().unwrap());
-        (
-            context,
-            Console::new(
-                hypervisor::ProtectionType::Unprotected,
-                Some(input),
-                Some(output),
-                Vec::new(),
-                None,
-            ),
+
+        let console = Console::new(
+            hypervisor::ProtectionType::Unprotected,
+            Some(input),
+            Some(output),
+            Vec::new(),
+            None,
+        );
+
+        let context = ConsoleContext {};
+        (context, console)
+    }
+
+    #[cfg(windows)]
+    fn create_device() -> (ConsoleContext, Console) {
+        let (input_pipe_server, input_pipe_client) = named_pipes::pair(
+            &named_pipes::FramingMode::Byte,
+            &named_pipes::BlockingMode::NoWait,
+            0,
         )
+        .unwrap();
+
+        let input = Box::new(input_pipe_server);
+        let output = Box::new(tempfile().unwrap());
+
+        let console = Console::new(
+            hypervisor::ProtectionType::Unprotected,
+            Some(input),
+            Some(output),
+            Vec::new(),
+            None,
+        );
+
+        let context = ConsoleContext { input_pipe_client };
+
+        (context, console)
     }
 
     suspendable_virtio_tests!(console, create_device, 2, modify_device);
 
     #[test]
     fn test_inactive_sleep_resume() {
-        let (_ctx, device) = &mut create_device();
+        let (_ctx, mut device) = create_device();
+
+        let input_buffer = device.console.ports[0].clone_input_buffer();
+
+        // Initialize the device, starting the input thread, but don't activate any queues.
+        device.on_device_sandboxed();
+
+        // No queues were started, so `virtio_sleep()` should return `None`.
         let sleep_result = device.virtio_sleep().expect("failed to sleep");
         assert!(sleep_result.is_none());
-        device.virtio_snapshot().expect("failed to snapshot");
+
+        // Inject some input data.
+        input_buffer.lock().extend(b"Hello".iter());
+
+        // Ensure snapshot does not fail and contains the buffered input data.
+        let snapshot = device.virtio_snapshot().expect("failed to snapshot");
+
+        let snapshot_input_buffer = snapshot
+            .get("ports")
+            .unwrap()
+            .get(0)
+            .unwrap()
+            .get("input_buffer")
+            .unwrap()
+            .as_array()
+            .unwrap();
+
+        assert_eq!(snapshot_input_buffer.len(), b"Hello".len());
+        assert_eq!(snapshot_input_buffer[0].as_i64(), Some(b'H' as i64));
+        assert_eq!(snapshot_input_buffer[1].as_i64(), Some(b'e' as i64));
+        assert_eq!(snapshot_input_buffer[2].as_i64(), Some(b'l' as i64));
+        assert_eq!(snapshot_input_buffer[3].as_i64(), Some(b'l' as i64));
+        assert_eq!(snapshot_input_buffer[4].as_i64(), Some(b'o' as i64));
+
+        // Wake up the device, which should start the input thread again.
         device.virtio_wake(None).expect("failed to wake");
-        // Make sure the input and output haven't been dropped.
-        assert!(device.input.is_some());
-        assert!(device.output.is_some());
     }
 }
diff --git a/devices/src/virtio/console/asynchronous.rs b/devices/src/virtio/console/asynchronous.rs
deleted file mode 100644
index b98480b98..000000000
--- a/devices/src/virtio/console/asynchronous.rs
+++ /dev/null
@@ -1,565 +0,0 @@
-// Copyright 2020 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-//! Asynchronous console device which implementation can be shared by VMM and vhost-user.
-
-use std::collections::BTreeMap;
-use std::collections::VecDeque;
-use std::io;
-use std::sync::Arc;
-
-use anyhow::anyhow;
-use anyhow::Context;
-use base::error;
-#[cfg(windows)]
-use base::named_pipes;
-use base::AsRawDescriptor;
-use base::Descriptor;
-use base::Event;
-use base::FileSync;
-use base::RawDescriptor;
-use base::WorkerThread;
-use cros_async::select2;
-use cros_async::AsyncResult;
-use cros_async::EventAsync;
-use cros_async::Executor;
-use cros_async::IntoAsync;
-use cros_async::IoSource;
-use futures::FutureExt;
-use hypervisor::ProtectionType;
-use sync::Mutex;
-use vm_memory::GuestMemory;
-use vmm_vhost::VHOST_USER_F_PROTOCOL_FEATURES;
-use zerocopy::AsBytes;
-
-use super::handle_input;
-use super::process_transmit_queue;
-use super::QUEUE_SIZES;
-use crate::serial_device::SerialInput;
-use crate::serial_device::SerialOptions;
-use crate::virtio;
-use crate::virtio::async_device::AsyncQueueState;
-use crate::virtio::async_utils;
-use crate::virtio::base_features;
-use crate::virtio::console::multiport::ConsolePortInfo;
-use crate::virtio::console::multiport::ControlPort;
-use crate::virtio::console::virtio_console_config;
-use crate::virtio::console::ConsoleError;
-use crate::virtio::copy_config;
-use crate::virtio::device_constants::console::VIRTIO_CONSOLE_F_MULTIPORT;
-use crate::virtio::DeviceType;
-use crate::virtio::Interrupt;
-use crate::virtio::Queue;
-use crate::virtio::VirtioDevice;
-use crate::PciAddress;
-use crate::SerialDevice;
-
-/// Wrapper that makes any `SerialInput` usable as an async source by providing an implementation of
-/// `IntoAsync`.
-struct AsyncSerialInput(Box<dyn SerialInput>);
-impl AsRawDescriptor for AsyncSerialInput {
-    fn as_raw_descriptor(&self) -> RawDescriptor {
-        self.0.get_read_notifier().as_raw_descriptor()
-    }
-}
-impl IntoAsync for AsyncSerialInput {}
-
-async fn run_tx_queue(
-    queue: &Arc<Mutex<virtio::Queue>>,
-    doorbell: Interrupt,
-    kick_evt: EventAsync,
-    output: &mut Box<dyn io::Write + Send>,
-) {
-    loop {
-        if let Err(e) = kick_evt.next_val().await {
-            error!("Failed to read kick event for tx queue: {}", e);
-            break;
-        }
-        process_transmit_queue(&doorbell, queue, output.as_mut());
-    }
-}
-
-async fn run_rx_queue(
-    queue: &Arc<Mutex<virtio::Queue>>,
-    doorbell: Interrupt,
-    kick_evt: EventAsync,
-    input: &IoSource<AsyncSerialInput>,
-) {
-    // Staging buffer, required because of `handle_input`'s API. We can probably remove this once
-    // the regular virtio device is switched to async.
-    let mut in_buffer = VecDeque::<u8>::new();
-    let mut rx_buf = vec![0u8; 4096];
-
-    loop {
-        match input.read_to_vec(None, rx_buf).await {
-            // Input source has closed.
-            Ok((0, _)) => break,
-            Ok((size, v)) => {
-                in_buffer.extend(&v[0..size]);
-                rx_buf = v;
-            }
-            Err(e) => {
-                error!("Failed to read console input: {}", e);
-                return;
-            }
-        }
-
-        // Submit all the data obtained during this read.
-        while !in_buffer.is_empty() {
-            match handle_input(&doorbell, &mut in_buffer, queue) {
-                Ok(()) => {}
-                Err(ConsoleError::RxDescriptorsExhausted) => {
-                    // Wait until a descriptor becomes available and try again.
-                    if let Err(e) = kick_evt.next_val().await {
-                        error!("Failed to read kick event for rx queue: {}", e);
-                        return;
-                    }
-                }
-            }
-        }
-    }
-}
-
-pub struct ConsolePort {
-    input: Option<AsyncQueueState<AsyncSerialInput>>,
-    output: AsyncQueueState<Box<dyn io::Write + Send>>,
-    info: ConsolePortInfo,
-}
-
-impl SerialDevice for ConsolePort {
-    fn new(
-        _protection_type: ProtectionType,
-        _evt: Event,
-        input: Option<Box<dyn SerialInput>>,
-        output: Option<Box<dyn io::Write + Send>>,
-        _sync: Option<Box<dyn FileSync + Send>>,
-        options: SerialOptions,
-        _keep_rds: Vec<RawDescriptor>,
-    ) -> ConsolePort {
-        let input = input.map(AsyncSerialInput).map(AsyncQueueState::Stopped);
-        let output = AsyncQueueState::Stopped(output.unwrap_or_else(|| Box::new(io::sink())));
-        let info = ConsolePortInfo {
-            console: options.console,
-            name: options.name.unwrap_or_default(),
-        };
-
-        ConsolePort {
-            input,
-            output,
-            info,
-        }
-    }
-
-    #[cfg(windows)]
-    fn new_with_pipe(
-        _protection_type: ProtectionType,
-        _interrupt_evt: Event,
-        _pipe_in: named_pipes::PipeConnection,
-        _pipe_out: named_pipes::PipeConnection,
-        _options: SerialOptions,
-        _keep_rds: Vec<RawDescriptor>,
-    ) -> ConsolePort {
-        unimplemented!("new_with_pipe unimplemented for ConsolePort");
-    }
-}
-
-impl ConsolePort {
-    pub fn start_receive_queue(
-        &mut self,
-        ex: &Executor,
-        queue: Arc<Mutex<virtio::Queue>>,
-        doorbell: Interrupt,
-    ) -> anyhow::Result<()> {
-        let input_queue = match self.input.as_mut() {
-            Some(input_queue) => input_queue,
-            None => return Ok(()),
-        };
-
-        let kick_evt = queue
-            .lock()
-            .event()
-            .try_clone()
-            .context("Failed to clone queue event")?;
-        let kick_evt =
-            EventAsync::new(kick_evt, ex).context("Failed to create EventAsync for kick_evt")?;
-
-        let closure_ex = ex.clone();
-        let rx_future = move |input, abort| {
-            let async_input = closure_ex
-                .async_from(input)
-                .context("failed to create async input")?;
-
-            Ok(async move {
-                select2(
-                    run_rx_queue(&queue, doorbell, kick_evt, &async_input).boxed_local(),
-                    abort,
-                )
-                .await;
-
-                async_input.into_source()
-            })
-        };
-
-        input_queue.start(ex, rx_future)
-    }
-
-    pub fn stop_receive_queue(&mut self) -> AsyncResult<bool> {
-        if let Some(queue) = self.input.as_mut() {
-            queue.stop()
-        } else {
-            Ok(false)
-        }
-    }
-
-    pub fn start_transmit_queue(
-        &mut self,
-        ex: &Executor,
-        queue: Arc<Mutex<virtio::Queue>>,
-        doorbell: Interrupt,
-    ) -> anyhow::Result<()> {
-        let kick_evt = queue
-            .lock()
-            .event()
-            .try_clone()
-            .context("Failed to clone queue event")?;
-        let kick_evt =
-            EventAsync::new(kick_evt, ex).context("Failed to create EventAsync for kick_evt")?;
-
-        let tx_future = |mut output, abort| {
-            Ok(async move {
-                select2(
-                    run_tx_queue(&queue, doorbell, kick_evt, &mut output).boxed_local(),
-                    abort,
-                )
-                .await;
-
-                output
-            })
-        };
-
-        self.output.start(ex, tx_future)
-    }
-
-    pub fn stop_transmit_queue(&mut self) -> AsyncResult<bool> {
-        self.output.stop()
-    }
-}
-
-/// Console device with an optional control port to support for multiport
-pub struct ConsoleDevice {
-    avail_features: u64,
-    // Port 0 always exists.
-    port0: ConsolePort,
-    // Control port, if multiport is in use.
-    control_port: Option<ControlPort>,
-    // Port 1..n, if they exist.
-    extra_ports: Vec<ConsolePort>,
-}
-
-impl ConsoleDevice {
-    /// Create a console device with the multiport feature enabled
-    /// The multiport feature is referred to virtio spec.
-    pub fn new_multi_port(
-        protection_type: ProtectionType,
-        port0: ConsolePort,
-        extra_ports: Vec<ConsolePort>,
-    ) -> ConsoleDevice {
-        let avail_features =
-            virtio::base_features(protection_type) | (1 << VIRTIO_CONSOLE_F_MULTIPORT);
-
-        let info = std::iter::once(&port0)
-            .chain(extra_ports.iter())
-            .map(|port| port.info.clone())
-            .collect::<Vec<_>>();
-
-        ConsoleDevice {
-            avail_features,
-            port0,
-            control_port: Some(ControlPort::new(info)),
-            extra_ports,
-        }
-    }
-
-    /// Return available features
-    pub fn avail_features(&self) -> u64 {
-        self.avail_features
-    }
-
-    /// Return whether current console device supports multiport feature
-    pub fn is_multi_port(&self) -> bool {
-        self.avail_features & (1 << VIRTIO_CONSOLE_F_MULTIPORT) != 0
-    }
-
-    /// Return the number of the port initiated by the console device
-    pub fn max_ports(&self) -> usize {
-        1 + self.extra_ports.len()
-    }
-
-    /// Returns the maximum number of queues supported by this device.
-    pub fn max_queues(&self) -> usize {
-        // The port 0 receive and transmit queues always exist;
-        // other queues only exist if VIRTIO_CONSOLE_F_MULTIPORT is set.
-        if self.is_multi_port() {
-            let port_num = self.max_ports();
-
-            // Extra 1 is for control port; each port has two queues (tx & rx)
-            (port_num + 1) * 2
-        } else {
-            2
-        }
-    }
-
-    /// Return the reference of the console port by port_id
-    fn get_console_port(&mut self, port_id: usize) -> anyhow::Result<&mut ConsolePort> {
-        match port_id {
-            0 => Ok(&mut self.port0),
-            port_id => self
-                .extra_ports
-                .get_mut(port_id - 1)
-                .with_context(|| format!("failed to get console port {}", port_id)),
-        }
-    }
-
-    /// Start the queue with the index `idx`
-    pub fn start_queue(
-        &mut self,
-        ex: &Executor,
-        idx: usize,
-        queue: Arc<Mutex<virtio::Queue>>,
-        doorbell: Interrupt,
-    ) -> anyhow::Result<()> {
-        match idx {
-            // rxq (port0)
-            0 => self.port0.start_receive_queue(ex, queue, doorbell),
-            // txq (port0)
-            1 => self.port0.start_transmit_queue(ex, queue, doorbell),
-            // control port rxq
-            2 => self
-                .control_port
-                .as_mut()
-                .unwrap()
-                .start_receive_queue(ex, queue, doorbell),
-            // control port txq
-            3 => self
-                .control_port
-                .as_mut()
-                .unwrap()
-                .start_transmit_queue(ex, queue, doorbell),
-            // {4, 5} -> port1 {rxq, txq} if exist
-            // {6, 7} -> port2 {rxq, txq} if exist
-            // ...
-            _ => {
-                let port_id = idx / 2 - 1;
-                let port = self.get_console_port(port_id)?;
-                match idx % 2 {
-                    0 => port.start_receive_queue(ex, queue, doorbell),
-                    1 => port.start_transmit_queue(ex, queue, doorbell),
-                    _ => unreachable!(),
-                }
-            }
-        }
-    }
-
-    /// Stop the queue with the index `idx`
-    pub fn stop_queue(&mut self, idx: usize) -> anyhow::Result<bool> {
-        match idx {
-            0 => self
-                .port0
-                .stop_receive_queue()
-                .context("failed to stop rx queue"),
-            1 => self
-                .port0
-                .stop_transmit_queue()
-                .context("failed to stop tx queue"),
-            2 => self.control_port.as_mut().unwrap().stop_receive_queue(),
-            3 => self.control_port.as_mut().unwrap().stop_transmit_queue(),
-            _ => {
-                let port_id = idx / 2 - 1;
-                let port = self.get_console_port(port_id)?;
-                match idx % 2 {
-                    0 => port.stop_receive_queue().context("failed to stop rx queue"),
-                    1 => port
-                        .stop_transmit_queue()
-                        .context("failed to stop tx queue"),
-                    _ => unreachable!(),
-                }
-            }
-        }
-    }
-}
-
-impl SerialDevice for ConsoleDevice {
-    /// Create a default console device, without multiport support
-    fn new(
-        protection_type: ProtectionType,
-        evt: Event,
-        input: Option<Box<dyn SerialInput>>,
-        output: Option<Box<dyn io::Write + Send>>,
-        sync: Option<Box<dyn FileSync + Send>>,
-        options: SerialOptions,
-        keep_rds: Vec<RawDescriptor>,
-    ) -> ConsoleDevice {
-        let avail_features =
-            virtio::base_features(protection_type) | 1 << VHOST_USER_F_PROTOCOL_FEATURES;
-        let port0 = ConsolePort::new(protection_type, evt, input, output, sync, options, keep_rds);
-
-        ConsoleDevice {
-            avail_features,
-            port0,
-            control_port: None,
-            extra_ports: vec![],
-        }
-    }
-
-    #[cfg(windows)]
-    fn new_with_pipe(
-        _protection_type: ProtectionType,
-        _interrupt_evt: Event,
-        _pipe_in: named_pipes::PipeConnection,
-        _pipe_out: named_pipes::PipeConnection,
-        _options: SerialOptions,
-        _keep_rds: Vec<RawDescriptor>,
-    ) -> ConsoleDevice {
-        unimplemented!("new_with_pipe unimplemented for ConsoleDevice");
-    }
-}
-
-/// Virtio console device.
-pub struct AsyncConsole {
-    console_device: Option<ConsoleDevice>,
-    worker_thread: Option<WorkerThread<anyhow::Result<ConsoleDevice>>>,
-    base_features: u64,
-    keep_descriptors: Vec<Descriptor>,
-    pci_address: Option<PciAddress>,
-}
-
-impl SerialDevice for AsyncConsole {
-    fn new(
-        protection_type: ProtectionType,
-        evt: Event,
-        input: Option<Box<dyn SerialInput>>,
-        output: Option<Box<dyn io::Write + Send>>,
-        sync: Option<Box<dyn FileSync + Send>>,
-        options: SerialOptions,
-        keep_rds: Vec<RawDescriptor>,
-    ) -> AsyncConsole {
-        let pci_address = options.pci_address;
-        AsyncConsole {
-            console_device: Some(ConsoleDevice::new(
-                protection_type,
-                evt,
-                input,
-                output,
-                sync,
-                options,
-                Default::default(),
-            )),
-            worker_thread: None,
-            base_features: base_features(protection_type),
-            keep_descriptors: keep_rds.iter().copied().map(Descriptor).collect(),
-            pci_address,
-        }
-    }
-
-    #[cfg(windows)]
-    fn new_with_pipe(
-        _protection_type: ProtectionType,
-        _interrupt_evt: Event,
-        _pipe_in: named_pipes::PipeConnection,
-        _pipe_out: named_pipes::PipeConnection,
-        _options: SerialOptions,
-        _keep_rds: Vec<RawDescriptor>,
-    ) -> AsyncConsole {
-        unimplemented!("new_with_pipe unimplemented for AsyncConsole");
-    }
-}
-
-impl VirtioDevice for AsyncConsole {
-    fn keep_rds(&self) -> Vec<RawDescriptor> {
-        self.keep_descriptors
-            .iter()
-            .map(Descriptor::as_raw_descriptor)
-            .collect()
-    }
-
-    fn features(&self) -> u64 {
-        self.base_features
-    }
-
-    fn device_type(&self) -> DeviceType {
-        DeviceType::Console
-    }
-
-    fn queue_max_sizes(&self) -> &[u16] {
-        QUEUE_SIZES
-    }
-
-    fn read_config(&self, offset: u64, data: &mut [u8]) {
-        let config = virtio_console_config {
-            max_nr_ports: 1.into(),
-            ..Default::default()
-        };
-        copy_config(data, 0, config.as_bytes(), offset);
-    }
-
-    fn activate(
-        &mut self,
-        _mem: GuestMemory,
-        interrupt: Interrupt,
-        mut queues: BTreeMap<usize, Queue>,
-    ) -> anyhow::Result<()> {
-        if queues.len() < 2 {
-            return Err(anyhow!("expected 2 queues, got {}", queues.len()));
-        }
-
-        let console = self.console_device.take().context("no console_device")?;
-
-        let ex = Executor::new().expect("failed to create an executor");
-        let receive_queue = queues.remove(&0).unwrap();
-        let transmit_queue = queues.remove(&1).unwrap();
-
-        self.worker_thread = Some(WorkerThread::start("v_console", move |kill_evt| {
-            let mut console = console;
-            let receive_queue = Arc::new(Mutex::new(receive_queue));
-            let transmit_queue = Arc::new(Mutex::new(transmit_queue));
-
-            // Start transmit queue of port 0
-            console.start_queue(&ex, 0, receive_queue, interrupt.clone())?;
-            // Start receive queue of port 0
-            console.start_queue(&ex, 1, transmit_queue, interrupt.clone())?;
-
-            // Run until the kill event is signaled and cancel all tasks.
-            ex.run_until(async {
-                async_utils::await_and_exit(&ex, kill_evt).await?;
-                let port = &mut console.port0;
-                if let Some(input) = port.input.as_mut() {
-                    input
-                        .stop_async()
-                        .await
-                        .context("failed to stop rx queue")?;
-                }
-                port.output
-                    .stop_async()
-                    .await
-                    .context("failed to stop tx queue")?;
-
-                Ok(console)
-            })?
-        }));
-
-        Ok(())
-    }
-
-    fn pci_address(&self) -> Option<PciAddress> {
-        self.pci_address
-    }
-
-    fn reset(&mut self) -> anyhow::Result<()> {
-        if let Some(worker_thread) = self.worker_thread.take() {
-            let console = worker_thread.stop()?;
-            self.console_device = Some(console);
-        }
-        Ok(())
-    }
-}
diff --git a/devices/src/virtio/console/control.rs b/devices/src/virtio/console/control.rs
new file mode 100644
index 000000000..09aa0d373
--- /dev/null
+++ b/devices/src/virtio/console/control.rs
@@ -0,0 +1,177 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Virtio console device control queue handling.
+
+use std::collections::VecDeque;
+use std::io::Write;
+
+use anyhow::anyhow;
+use anyhow::Context;
+use base::debug;
+use base::error;
+use zerocopy::AsBytes;
+
+use crate::virtio::console::worker::WorkerPort;
+use crate::virtio::device_constants::console::virtio_console_control;
+use crate::virtio::device_constants::console::VIRTIO_CONSOLE_CONSOLE_PORT;
+use crate::virtio::device_constants::console::VIRTIO_CONSOLE_DEVICE_ADD;
+use crate::virtio::device_constants::console::VIRTIO_CONSOLE_DEVICE_READY;
+use crate::virtio::device_constants::console::VIRTIO_CONSOLE_PORT_NAME;
+use crate::virtio::device_constants::console::VIRTIO_CONSOLE_PORT_OPEN;
+use crate::virtio::device_constants::console::VIRTIO_CONSOLE_PORT_READY;
+use crate::virtio::Queue;
+use crate::virtio::Reader;
+
+pub type ControlMsgBytes = Box<[u8]>;
+
+fn control_msg(id: u32, event: u16, value: u16, extra_bytes: &[u8]) -> ControlMsgBytes {
+    virtio_console_control {
+        id: id.into(),
+        event: event.into(),
+        value: value.into(),
+    }
+    .as_bytes()
+    .iter()
+    .chain(extra_bytes.iter())
+    .copied()
+    .collect()
+}
+
+fn process_control_msg(
+    reader: &mut Reader,
+    ports: &[WorkerPort],
+    pending_receive_control_msgs: &mut VecDeque<ControlMsgBytes>,
+) -> anyhow::Result<()> {
+    let ctrl_msg: virtio_console_control =
+        reader.read_obj().context("failed to read from reader")?;
+    let id = ctrl_msg.id.to_native();
+    let event = ctrl_msg.event.to_native();
+    let value = ctrl_msg.value.to_native();
+
+    match event {
+        VIRTIO_CONSOLE_DEVICE_READY => {
+            // value of 1 indicates success, and 0 indicates failure
+            if value != 1 {
+                return Err(anyhow!("console device ready failure ({value})"));
+            }
+
+            for (index, port) in ports.iter().enumerate() {
+                let port_id = index as u32;
+                // TODO(dverkamp): cap the size of `pending_receive_control_msgs` somehow
+                pending_receive_control_msgs.push_back(control_msg(
+                    port_id,
+                    VIRTIO_CONSOLE_DEVICE_ADD,
+                    0,
+                    &[],
+                ));
+
+                if let Some(name) = port.name() {
+                    pending_receive_control_msgs.push_back(control_msg(
+                        port_id,
+                        VIRTIO_CONSOLE_PORT_NAME,
+                        0,
+                        name.as_bytes(),
+                    ));
+                }
+            }
+            Ok(())
+        }
+        VIRTIO_CONSOLE_PORT_READY => {
+            // value of 1 indicates success, and 0 indicates failure
+            if value != 1 {
+                return Err(anyhow!("console port{id} ready failure ({value})"));
+            }
+
+            let port = ports
+                .get(id as usize)
+                .with_context(|| format!("invalid port id {id}"))?;
+
+            pending_receive_control_msgs.push_back(control_msg(
+                id,
+                VIRTIO_CONSOLE_PORT_OPEN,
+                1,
+                &[],
+            ));
+
+            if port.is_console() {
+                pending_receive_control_msgs.push_back(control_msg(
+                    id,
+                    VIRTIO_CONSOLE_CONSOLE_PORT,
+                    1,
+                    &[],
+                ));
+            }
+            Ok(())
+        }
+        VIRTIO_CONSOLE_PORT_OPEN => {
+            match value {
+                // Currently, port state change is not supported, default is open.
+                // And only print debug info here.
+                0 => debug!("console port{id} close"),
+                1 => debug!("console port{id} open"),
+                _ => error!("console port{id} unknown value {value}"),
+            }
+            Ok(())
+        }
+        _ => Err(anyhow!("unexpected control event {}", event)),
+    }
+}
+
+pub fn process_control_transmit_queue(
+    queue: &mut Queue,
+    ports: &[WorkerPort],
+    pending_receive_control_msgs: &mut VecDeque<ControlMsgBytes>,
+) {
+    let mut needs_interrupt = false;
+
+    while let Some(mut avail_desc) = queue.pop() {
+        if let Err(e) =
+            process_control_msg(&mut avail_desc.reader, ports, pending_receive_control_msgs)
+        {
+            error!("failed to handle control msg: {:#}", e);
+        }
+
+        queue.add_used(avail_desc, 0);
+        needs_interrupt = true;
+    }
+
+    if needs_interrupt {
+        queue.trigger_interrupt();
+    }
+}
+
+pub fn process_control_receive_queue(
+    queue: &mut Queue,
+    pending_receive_control_msgs: &mut VecDeque<ControlMsgBytes>,
+) {
+    let mut needs_interrupt = false;
+
+    while !pending_receive_control_msgs.is_empty() {
+        let Some(mut avail_desc) = queue.pop() else {
+            break;
+        };
+
+        // Get a reply to copy into `avail_desc`. This should never fail since we check that
+        // `pending_receive_control_msgs` is not empty in the loop condition.
+        let reply = pending_receive_control_msgs
+            .pop_front()
+            .expect("missing reply");
+
+        let len = match avail_desc.writer.write_all(&reply) {
+            Ok(()) => avail_desc.writer.bytes_written() as u32,
+            Err(e) => {
+                error!("failed to write control receiveq reply: {}", e);
+                0
+            }
+        };
+
+        queue.add_used(avail_desc, len);
+        needs_interrupt = true;
+    }
+
+    if needs_interrupt {
+        queue.trigger_interrupt();
+    }
+}
diff --git a/devices/src/virtio/console/device.rs b/devices/src/virtio/console/device.rs
new file mode 100644
index 000000000..f1f9844a1
--- /dev/null
+++ b/devices/src/virtio/console/device.rs
@@ -0,0 +1,177 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! virtio-console and vhost-user-console device shared backend implementation
+
+use base::RawDescriptor;
+use data_model::Le32;
+use hypervisor::ProtectionType;
+use serde::Deserialize;
+use serde::Serialize;
+use zerocopy::AsBytes;
+
+use crate::virtio::base_features;
+use crate::virtio::console::port::ConsolePort;
+use crate::virtio::console::port::ConsolePortSnapshot;
+use crate::virtio::console::worker::WorkerHandle;
+use crate::virtio::console::worker::WorkerPort;
+use crate::virtio::copy_config;
+use crate::virtio::device_constants::console::virtio_console_config;
+use crate::virtio::device_constants::console::VIRTIO_CONSOLE_F_MULTIPORT;
+use crate::virtio::Interrupt;
+use crate::virtio::Queue;
+
+pub struct ConsoleDevice {
+    avail_features: u64,
+    pub(crate) ports: Vec<ConsolePort>,
+    worker: Option<WorkerHandle>,
+}
+
+#[derive(Serialize, Deserialize)]
+pub struct ConsoleSnapshot {
+    avail_features: u64,
+    ports: Vec<ConsolePortSnapshot>,
+}
+
+impl ConsoleDevice {
+    /// Create a console device that does not support the multiport feature.
+    pub fn new_single_port(protection_type: ProtectionType, port: ConsolePort) -> ConsoleDevice {
+        ConsoleDevice {
+            avail_features: base_features(protection_type),
+            ports: vec![port],
+            worker: None,
+        }
+    }
+
+    /// Create a console device with the multiport feature enabled.
+    pub fn new_multi_port(
+        protection_type: ProtectionType,
+        ports: Vec<ConsolePort>,
+    ) -> ConsoleDevice {
+        // Port 0 must always exist.
+        assert!(!ports.is_empty());
+
+        let avail_features = base_features(protection_type) | (1 << VIRTIO_CONSOLE_F_MULTIPORT);
+
+        ConsoleDevice {
+            avail_features,
+            ports,
+            worker: None,
+        }
+    }
+
+    pub fn features(&self) -> u64 {
+        self.avail_features
+    }
+
+    pub fn max_ports(&self) -> usize {
+        self.ports.len()
+    }
+
+    /// Returns the maximum number of queues supported by this device.
+    pub fn max_queues(&self) -> usize {
+        // The port 0 receive and transmit queues always exist;
+        // other queues only exist if VIRTIO_CONSOLE_F_MULTIPORT is set.
+        let num_queues = self.ports.len().max(1);
+        if self.avail_features & (1 << VIRTIO_CONSOLE_F_MULTIPORT) != 0 {
+            // Each port has two queues (tx & rx), plus 2 for control receiveq and transmitq.
+            num_queues * 2 + 2
+        } else {
+            // port0 receiveq + transmitq
+            2
+        }
+    }
+
+    pub fn read_config(&self, offset: u64, data: &mut [u8]) {
+        let max_nr_ports = self.max_ports();
+        let config = virtio_console_config {
+            max_nr_ports: Le32::from(max_nr_ports as u32),
+            ..Default::default()
+        };
+        copy_config(data, 0, config.as_bytes(), offset);
+    }
+
+    pub fn keep_rds(&self) -> Vec<RawDescriptor> {
+        self.ports.iter().flat_map(ConsolePort::keep_rds).collect()
+    }
+
+    fn ensure_worker_started(&mut self, interrupt: Interrupt) -> &mut WorkerHandle {
+        self.worker.get_or_insert_with(|| {
+            let ports = self
+                .ports
+                .iter_mut()
+                .map(WorkerPort::from_console_port)
+                .collect();
+            WorkerHandle::new(interrupt, ports).expect("failed to create console worker")
+        })
+    }
+
+    fn ensure_worker_stopped(&mut self) {
+        if let Some(worker) = self.worker.take() {
+            let ports = worker.stop();
+            for (worker_port, port) in ports.into_iter().zip(self.ports.iter_mut()) {
+                worker_port.into_console_port(port);
+            }
+        }
+    }
+
+    pub fn start_queue(&mut self, idx: usize, queue: Queue) -> anyhow::Result<()> {
+        let worker = self.ensure_worker_started(queue.interrupt().clone());
+        worker.start_queue(idx, queue)
+    }
+
+    pub fn stop_queue(&mut self, idx: usize) -> anyhow::Result<Option<Queue>> {
+        match self.worker.as_mut() {
+            Some(worker) => worker.stop_queue(idx),
+            None => Ok(None),
+        }
+    }
+
+    pub fn reset(&mut self) -> anyhow::Result<()> {
+        for idx in 0..self.max_queues() {
+            let _ = self.stop_queue(idx);
+        }
+        self.ensure_worker_stopped();
+        Ok(())
+    }
+
+    pub fn start_input_threads(&mut self) {
+        for port in self.ports.iter_mut() {
+            port.start_input_thread();
+        }
+    }
+
+    pub fn stop_input_threads(&mut self) {
+        for port in self.ports.iter_mut() {
+            port.stop_input_thread();
+        }
+    }
+
+    pub fn snapshot(&mut self) -> anyhow::Result<ConsoleSnapshot> {
+        let mut ports = Vec::new();
+        for port in &mut self.ports {
+            ports.push(port.snapshot());
+        }
+
+        Ok(ConsoleSnapshot {
+            avail_features: self.avail_features,
+            ports,
+        })
+    }
+
+    pub fn restore(&mut self, snap: &ConsoleSnapshot) -> anyhow::Result<()> {
+        anyhow::ensure!(
+            self.avail_features == snap.avail_features,
+            "Virtio console incorrect features for restore: Expected: {}, Actual: {}",
+            self.avail_features,
+            snap.avail_features,
+        );
+
+        for (port, port_snap) in self.ports.iter_mut().zip(snap.ports.iter()) {
+            port.restore(port_snap);
+        }
+
+        Ok(())
+    }
+}
diff --git a/devices/src/virtio/console/input.rs b/devices/src/virtio/console/input.rs
new file mode 100644
index 000000000..0ee6d50bf
--- /dev/null
+++ b/devices/src/virtio/console/input.rs
@@ -0,0 +1,45 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Virtio console device input handling.
+
+use std::collections::VecDeque;
+use std::io::Write;
+
+use crate::virtio::Queue;
+
+/// Checks for input from `buffer` and transfers it to the receive queue, if any.
+///
+/// # Arguments
+///
+/// * `interrupt` - Interrupt used to signal that the queue has been used
+/// * `buffer` - Ring buffer providing data to put into the guest
+/// * `receive_queue` - The receive virtio Queue
+pub fn process_receive_queue(buffer: &mut VecDeque<u8>, receive_queue: &mut Queue) {
+    while let Some(mut desc) = receive_queue.peek() {
+        if buffer.is_empty() {
+            break;
+        }
+
+        let writer = &mut desc.writer;
+        while writer.available_bytes() > 0 && !buffer.is_empty() {
+            let (buffer_front, buffer_back) = buffer.as_slices();
+            let buffer_chunk = if !buffer_front.is_empty() {
+                buffer_front
+            } else {
+                buffer_back
+            };
+            let written = writer.write(buffer_chunk).unwrap();
+            drop(buffer.drain(..written));
+        }
+
+        let bytes_written = writer.bytes_written() as u32;
+
+        if bytes_written > 0 {
+            let desc = desc.pop();
+            receive_queue.add_used(desc, bytes_written);
+            receive_queue.trigger_interrupt();
+        }
+    }
+}
diff --git a/devices/src/virtio/console/multiport.rs b/devices/src/virtio/console/multiport.rs
deleted file mode 100644
index 477d55951..000000000
--- a/devices/src/virtio/console/multiport.rs
+++ /dev/null
@@ -1,324 +0,0 @@
-// Copyright 2023 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-//! Implementation of control port used for multi-port enabled virtio-console
-
-use std::collections::VecDeque;
-use std::sync::Arc;
-
-use anyhow::anyhow;
-use anyhow::Context;
-use anyhow::Result;
-use base::debug;
-use base::error;
-use cros_async::select2;
-use cros_async::EventAsync;
-use cros_async::Executor;
-use data_model::Le16;
-use data_model::Le32;
-use futures::channel::mpsc;
-use futures::FutureExt;
-use futures::SinkExt;
-use futures::StreamExt;
-use sync::Mutex;
-use zerocopy::AsBytes;
-use zerocopy::FromBytes;
-use zerocopy::FromZeroes;
-
-use super::handle_input;
-use crate::virtio;
-use crate::virtio::async_device::AsyncQueueState;
-use crate::virtio::console::ConsoleError;
-use crate::virtio::Interrupt;
-use crate::virtio::Queue;
-use crate::virtio::Reader;
-
-type ControlMsgBytes = VecDeque<u8>;
-
-#[derive(Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
-#[repr(C)]
-struct ControlMsg {
-    id: Le32,
-    event: Le16,
-    value: Le16,
-}
-
-impl ControlMsg {
-    fn new(id: u32, event: ControlEvent, value: u16) -> ControlMsg {
-        ControlMsg {
-            id: Le32::from(id),
-            event: Le16::from(event as u16),
-            value: Le16::from(value),
-        }
-    }
-}
-
-#[derive(Debug, PartialEq, enumn::N)]
-enum ControlEvent {
-    DeviceReady = 0,
-    DeviceAdd = 1,
-    DeviceRemove = 2,
-    PortReady = 3,
-    ConsolePort = 4,
-    Resize = 5,
-    PortOpen = 6,
-    PortName = 7,
-}
-impl TryFrom<u16> for ControlEvent {
-    type Error = anyhow::Error;
-
-    fn try_from(value: u16) -> Result<Self> {
-        match ControlEvent::n(value) {
-            Some(event) => Ok(event),
-            None => Err(anyhow!("unsupported event {}", value)),
-        }
-    }
-}
-
-fn process_tx_ctrl_msg(
-    reader: &mut Reader,
-    ports: &Vec<ConsolePortInfo>,
-) -> Result<Vec<ControlMsgBytes>> {
-    let mut messages = Vec::<ControlMsgBytes>::new();
-    let ports_num = ports.len() as u32;
-    let ctrl_msg: ControlMsg = reader.read_obj().context("failed to read from reader")?;
-    let id = ctrl_msg.id.to_native();
-    let event = ControlEvent::try_from(ctrl_msg.event.to_native())?;
-    let value: u16 = ctrl_msg.value.to_native();
-
-    if id >= ports_num && event != ControlEvent::DeviceReady {
-        return Err(anyhow!("console: id {} out of range", id));
-    }
-
-    match event {
-        ControlEvent::DeviceReady => {
-            // value of 1 indicates success, and 0 indicates failure
-            if value == 1 {
-                for id in 0..ports_num {
-                    let msg = ControlMsg::new(id, ControlEvent::DeviceAdd, 0);
-                    let _ = msg.as_bytes();
-                    messages.push(msg.as_bytes().to_owned().into());
-
-                    let name = ports[id as usize].name.clone();
-                    let msg = ControlMsg::new(id, ControlEvent::PortName, 0);
-                    let mut reply: ControlMsgBytes = msg.as_bytes().to_owned().into();
-                    reply.extend(name.as_bytes());
-                    messages.push(reply);
-                }
-            } else {
-                error!("console: received event {:?} value {}", event, value);
-            }
-        }
-        ControlEvent::PortReady => {
-            // value of 1 indicates success, and 0 indicates failure
-            if value == 1 {
-                let msg = ControlMsg::new(id, ControlEvent::PortOpen, 1);
-                messages.push(msg.as_bytes().to_owned().into());
-
-                let is_console = ports[id as usize].console;
-                if is_console {
-                    let msg = ControlMsg::new(id, ControlEvent::ConsolePort, 1);
-                    messages.push(msg.as_bytes().to_owned().into());
-                }
-            } else {
-                error!("console: received event {:?} value {}", event, value);
-            }
-        }
-        ControlEvent::PortOpen => match value {
-            // Currently, port state change is not supported, default is open.
-            // And only print debug info here.
-            0 => debug!("console port{} close", id),
-            1 => debug!("console port{} open", id),
-            _ => error!("console port{} open {}", id, value),
-        },
-        _ => {
-            return Err(anyhow!("console: unexpected control event {:?}", event));
-        }
-    }
-
-    Ok(messages)
-}
-
-fn process_tx_ctrl_queue(
-    queue: &Arc<Mutex<Queue>>,
-    doorbell: &Interrupt,
-    ports: &Vec<ConsolePortInfo>,
-) -> Vec<ControlMsgBytes> {
-    let mut needs_interrupt = false;
-    let mut messages = Vec::<ControlMsgBytes>::new();
-    let mut queue = queue.try_lock().expect("Lock should not be unavailable");
-
-    while let Some(mut avail_desc) = queue.pop() {
-        match process_tx_ctrl_msg(&mut avail_desc.reader, ports) {
-            Ok(mut msg) => messages.append(&mut msg),
-            Err(e) => {
-                error!("console: failed to handle control msg: {}", e);
-            }
-        }
-
-        queue.add_used(avail_desc, 0);
-        needs_interrupt = true;
-    }
-
-    if needs_interrupt {
-        queue.trigger_interrupt(doorbell);
-    }
-
-    messages
-}
-
-async fn run_tx_ctrl_queue(
-    queue: &Arc<Mutex<Queue>>,
-    doorbell: Interrupt,
-    kick_evt: EventAsync,
-    sender: &mut mpsc::UnboundedSender<Vec<ControlMsgBytes>>,
-    ports: Vec<ConsolePortInfo>,
-) {
-    loop {
-        if let Err(e) = kick_evt.next_val().await {
-            error!("Failed to read kick event for tx queue: {}", e);
-            break;
-        }
-
-        let messages = process_tx_ctrl_queue(queue, &doorbell, &ports);
-
-        if let Err(e) = sender.send(messages).await {
-            error!("console: failed to send control msg: {}", e);
-            break;
-        }
-    }
-}
-
-async fn run_rx_ctrl_queue(
-    queue: &Arc<Mutex<Queue>>,
-    doorbell: Interrupt,
-    kick_evt: EventAsync,
-    receiver: &mut mpsc::UnboundedReceiver<Vec<ControlMsgBytes>>,
-) {
-    loop {
-        let messages = receiver.next().await;
-
-        if let Some(messages) = messages {
-            for mut msg in messages.into_iter() {
-                while !msg.is_empty() {
-                    match handle_input(&doorbell, &mut msg, queue) {
-                        Ok(()) => {}
-                        Err(ConsoleError::RxDescriptorsExhausted) => {
-                            // Wait until a descriptor becomes available and try again.
-                            if let Err(e) = kick_evt.next_val().await {
-                                error!("Failed to read kick event for rx-ctrl queue: {}", e);
-                                return;
-                            }
-                        }
-                    }
-                }
-            }
-        }
-    }
-}
-
-/// Each port info for multi-port virtio-console
-#[derive(Default, Clone)]
-pub struct ConsolePortInfo {
-    pub console: bool,
-    pub name: String,
-}
-
-/// Control port for multi-port virtio-console
-pub struct ControlPort {
-    sender: AsyncQueueState<mpsc::UnboundedSender<Vec<ControlMsgBytes>>>,
-    receiver: AsyncQueueState<mpsc::UnboundedReceiver<Vec<ControlMsgBytes>>>,
-    ports: Vec<ConsolePortInfo>,
-}
-
-impl ControlPort {
-    /// Create a control port with the given port info
-    pub fn new(ports: Vec<ConsolePortInfo>) -> ControlPort {
-        let (sender, receiver) = mpsc::unbounded::<Vec<ControlMsgBytes>>();
-
-        ControlPort {
-            sender: AsyncQueueState::Stopped(sender),
-            receiver: AsyncQueueState::Stopped(receiver),
-            ports,
-        }
-    }
-
-    /// Start the control receiveq
-    pub fn start_receive_queue(
-        &mut self,
-        ex: &Executor,
-        queue: Arc<Mutex<virtio::Queue>>,
-        doorbell: Interrupt,
-    ) -> Result<()> {
-        let kick_evt = queue
-            .lock()
-            .event()
-            .try_clone()
-            .context("Failed to clone queue event")?;
-        let kick_evt =
-            EventAsync::new(kick_evt, ex).context("Failed to create EventAsync for kick_evt")?;
-
-        let receiver = &mut self.receiver;
-        let rx_future = |mut receiver, abort| {
-            Ok(async move {
-                select2(
-                    run_rx_ctrl_queue(&queue, doorbell, kick_evt, &mut receiver).boxed_local(),
-                    abort,
-                )
-                .await;
-
-                receiver
-            })
-        };
-
-        receiver.start(ex, rx_future)
-    }
-
-    /// Stop the control receiveq
-    pub fn stop_receive_queue(&mut self) -> anyhow::Result<bool> {
-        self.receiver
-            .stop()
-            .context("failed to stop control rx queue")
-    }
-
-    /// Start the control transmitq
-    pub fn start_transmit_queue(
-        &mut self,
-        ex: &Executor,
-        queue: Arc<Mutex<virtio::Queue>>,
-        doorbell: Interrupt,
-    ) -> Result<()> {
-        let kick_evt = queue
-            .lock()
-            .event()
-            .try_clone()
-            .context("Failed to clone queue event")?;
-        let kick_evt =
-            EventAsync::new(kick_evt, ex).context("Failed to create EventAsync for kick_evt")?;
-
-        let sender = &mut self.sender;
-        let ports = self.ports.clone();
-
-        let tx_future = |mut sender, abort| {
-            Ok(async move {
-                select2(
-                    run_tx_ctrl_queue(&queue, doorbell, kick_evt, &mut sender, ports).boxed_local(),
-                    abort,
-                )
-                .await;
-
-                sender
-            })
-        };
-
-        sender.start(ex, tx_future)
-    }
-
-    /// Stop the control transmitq
-    pub fn stop_transmit_queue(&mut self) -> anyhow::Result<bool> {
-        self.sender
-            .stop()
-            .context("failed to stop control tx queue")
-    }
-}
diff --git a/devices/src/virtio/console/output.rs b/devices/src/virtio/console/output.rs
new file mode 100644
index 000000000..142963a51
--- /dev/null
+++ b/devices/src/virtio/console/output.rs
@@ -0,0 +1,51 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Virtio console device output handling.
+
+use std::io;
+use std::io::Read;
+
+use base::error;
+
+use crate::virtio::Queue;
+use crate::virtio::Reader;
+
+/// Writes the available data from the reader into the given output queue.
+///
+/// # Arguments
+///
+/// * `reader` - The Reader with the data we want to write.
+/// * `output` - The output sink we are going to write the data to.
+fn process_transmit_request(reader: &mut Reader, output: &mut dyn io::Write) -> io::Result<()> {
+    let len = reader.available_bytes();
+    let mut data = vec![0u8; len];
+    reader.read_exact(&mut data)?;
+    output.write_all(&data)?;
+    output.flush()?;
+    Ok(())
+}
+
+/// Processes the data taken from the given transmit queue into the output sink.
+///
+/// # Arguments
+///
+/// * `interrupt` - Interrupt used to signal (if required) that the queue has been used
+/// * `transmit_queue` - The transmit virtio Queue
+/// * `output` - The output sink we are going to write the data into
+pub fn process_transmit_queue(transmit_queue: &mut Queue, output: &mut dyn io::Write) {
+    let mut needs_interrupt = false;
+    while let Some(mut avail_desc) = transmit_queue.pop() {
+        if let Err(e) = process_transmit_request(&mut avail_desc.reader, output) {
+            error!("console: process_transmit_request failed: {}", e);
+        }
+
+        transmit_queue.add_used(avail_desc, 0);
+        needs_interrupt = true;
+    }
+
+    if needs_interrupt {
+        transmit_queue.trigger_interrupt();
+    }
+}
diff --git a/devices/src/virtio/console/port.rs b/devices/src/virtio/console/port.rs
new file mode 100644
index 000000000..a8486ed05
--- /dev/null
+++ b/devices/src/virtio/console/port.rs
@@ -0,0 +1,154 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Virtio console device per-port functionality.
+
+use std::collections::VecDeque;
+use std::sync::Arc;
+
+use anyhow::Context;
+use base::AsRawDescriptor;
+use base::Descriptor;
+use base::Event;
+use base::RawDescriptor;
+use base::WorkerThread;
+use serde::Deserialize;
+use serde::Serialize;
+use sync::Mutex;
+
+use crate::serial::sys::InStreamType;
+use crate::virtio::console::sys::spawn_input_thread;
+
+/// Each port info for multi-port virtio-console
+#[derive(Clone, Debug)]
+pub struct ConsolePortInfo {
+    pub console: bool,
+    pub name: Option<String>,
+}
+
+impl ConsolePortInfo {
+    pub fn name(&self) -> Option<&str> {
+        self.name.as_deref()
+    }
+}
+
+pub struct ConsolePort {
+    pub(crate) input: Option<InStreamType>,
+    pub(crate) output: Option<Box<dyn std::io::Write + Send>>,
+
+    info: Option<ConsolePortInfo>,
+
+    // input_buffer is shared with the input_thread while it is running.
+    input_buffer: Arc<Mutex<VecDeque<u8>>>,
+
+    // `in_avail_evt` will be signaled by the input thread to notify the worker when new input is
+    // available in `input_buffer`.
+    in_avail_evt: Event,
+
+    input_thread: Option<WorkerThread<InStreamType>>,
+
+    keep_descriptors: Vec<Descriptor>,
+}
+
+#[derive(Serialize, Deserialize)]
+pub struct ConsolePortSnapshot {
+    input_buffer: Vec<u8>,
+}
+
+impl ConsolePort {
+    pub fn new(
+        input: Option<InStreamType>,
+        output: Option<Box<dyn std::io::Write + Send>>,
+        info: Option<ConsolePortInfo>,
+        mut keep_rds: Vec<RawDescriptor>,
+    ) -> Self {
+        let input_buffer = Arc::new(Mutex::new(VecDeque::new()));
+        let in_avail_evt = Event::new().expect("Event::new() failed");
+        keep_rds.push(in_avail_evt.as_raw_descriptor());
+        ConsolePort {
+            input,
+            output,
+            info,
+            input_buffer,
+            in_avail_evt,
+            input_thread: None,
+            keep_descriptors: keep_rds.iter().map(|rd| Descriptor(*rd)).collect(),
+        }
+    }
+
+    pub fn clone_in_avail_evt(&self) -> anyhow::Result<Event> {
+        self.in_avail_evt
+            .try_clone()
+            .context("clone_in_avail_evt failed")
+    }
+
+    pub fn clone_input_buffer(&self) -> Arc<Mutex<VecDeque<u8>>> {
+        self.input_buffer.clone()
+    }
+
+    pub fn take_output(&mut self) -> Option<Box<dyn std::io::Write + Send>> {
+        self.output.take()
+    }
+
+    pub fn restore_output(&mut self, output: Box<dyn std::io::Write + Send>) {
+        self.output = Some(output);
+    }
+
+    pub fn port_info(&self) -> Option<&ConsolePortInfo> {
+        self.info.as_ref()
+    }
+
+    pub fn start_input_thread(&mut self) {
+        // Spawn a separate thread to poll input.
+        // A thread is used because io::Read only provides a blocking interface, and there is no
+        // generic way to add an io::Read instance to a poll context (it may not be backed by a
+        // file descriptor).  Moving the blocking read call to a separate thread and
+        // sending data back to the main worker thread with an event for
+        // notification bridges this gap.
+        if let Some(input) = self.input.take() {
+            assert!(self.input_thread.is_none());
+
+            let thread_in_avail_evt = self
+                .clone_in_avail_evt()
+                .expect("failed creating input available Event pair");
+
+            let thread = spawn_input_thread(input, thread_in_avail_evt, self.input_buffer.clone());
+            self.input_thread = Some(thread);
+        }
+    }
+
+    pub fn stop_input_thread(&mut self) {
+        if let Some(input_thread) = self.input_thread.take() {
+            let input = input_thread.stop();
+            self.input = Some(input);
+        }
+    }
+
+    pub fn snapshot(&mut self) -> ConsolePortSnapshot {
+        // This is only guaranteed to return a consistent state while the input thread is stopped.
+        self.stop_input_thread();
+        let input_buffer = self.input_buffer.lock().iter().copied().collect();
+        self.start_input_thread();
+        ConsolePortSnapshot { input_buffer }
+    }
+
+    pub fn restore(&mut self, snap: &ConsolePortSnapshot) {
+        self.stop_input_thread();
+
+        // Set the input buffer, discarding any currently buffered data.
+        let mut input_buffer = self.input_buffer.lock();
+        input_buffer.clear();
+        input_buffer.extend(snap.input_buffer.iter());
+        drop(input_buffer);
+
+        self.start_input_thread();
+    }
+
+    pub fn keep_rds(&self) -> Vec<RawDescriptor> {
+        self.keep_descriptors
+            .iter()
+            .map(|descr| descr.as_raw_descriptor())
+            .collect()
+    }
+}
diff --git a/devices/src/virtio/console/sys.rs b/devices/src/virtio/console/sys.rs
index 3b585c9e0..3ba004433 100644
--- a/devices/src/virtio/console/sys.rs
+++ b/devices/src/virtio/console/sys.rs
@@ -12,5 +12,4 @@ cfg_if::cfg_if! {
     }
 }
 
-pub(in crate::virtio::console) use platform::read_input;
 pub(in crate::virtio::console) use platform::spawn_input_thread;
diff --git a/devices/src/virtio/console/sys/linux.rs b/devices/src/virtio/console/sys/linux.rs
index cabb2c689..92ef89244 100644
--- a/devices/src/virtio/console/sys/linux.rs
+++ b/devices/src/virtio/console/sys/linux.rs
@@ -8,6 +8,7 @@ use std::sync::Arc;
 use std::time::Duration;
 use std::time::Instant;
 
+use anyhow::Context;
 use base::error;
 use base::Event;
 use base::EventToken;
@@ -20,6 +21,9 @@ use sync::Mutex;
 use crate::serial::sys::InStreamType;
 use crate::serial_device::SerialInput;
 use crate::serial_device::SerialOptions;
+use crate::virtio::console::device::ConsoleDevice;
+use crate::virtio::console::port::ConsolePort;
+use crate::virtio::console::port::ConsolePortInfo;
 use crate::virtio::console::Console;
 use crate::virtio::ProtectionType;
 use crate::SerialDevice;
@@ -29,91 +33,114 @@ impl SerialDevice for Console {
         protection_type: ProtectionType,
         _event: Event,
         input: Option<Box<dyn SerialInput>>,
-        out: Option<Box<dyn io::Write + Send>>,
+        output: Option<Box<dyn io::Write + Send>>,
         // TODO(b/171331752): connect filesync functionality.
         _sync: Option<Box<dyn FileSync + Send>>,
         options: SerialOptions,
         keep_rds: Vec<RawDescriptor>,
     ) -> Console {
-        Console::new(protection_type, input, out, keep_rds, options.pci_address)
+        Console::new(
+            protection_type,
+            input,
+            output,
+            keep_rds,
+            options.pci_address,
+        )
     }
 }
 
-fn is_a_fatal_input_error(e: &io::Error) -> bool {
-    e.kind() != io::ErrorKind::Interrupted
+impl SerialDevice for ConsoleDevice {
+    fn new(
+        protection_type: ProtectionType,
+        _event: Event,
+        input: Option<Box<dyn SerialInput>>,
+        output: Option<Box<dyn io::Write + Send>>,
+        _sync: Option<Box<dyn FileSync + Send>>,
+        options: SerialOptions,
+        keep_rds: Vec<RawDescriptor>,
+    ) -> ConsoleDevice {
+        let info = ConsolePortInfo {
+            name: options.name,
+            console: options.console,
+        };
+        let port = ConsolePort::new(input, output, Some(info), keep_rds);
+        ConsoleDevice::new_single_port(protection_type, port)
+    }
 }
 
-/// Starts a thread that reads rx and sends the input back via the returned buffer.
+impl SerialDevice for ConsolePort {
+    fn new(
+        _protection_type: ProtectionType,
+        _event: Event,
+        input: Option<Box<dyn SerialInput>>,
+        output: Option<Box<dyn io::Write + Send>>,
+        // TODO(b/171331752): connect filesync functionality.
+        _sync: Option<Box<dyn FileSync + Send>>,
+        options: SerialOptions,
+        keep_rds: Vec<RawDescriptor>,
+    ) -> ConsolePort {
+        let info = ConsolePortInfo {
+            name: options.name,
+            console: options.console,
+        };
+        ConsolePort::new(input, output, Some(info), keep_rds)
+    }
+}
+
+/// Starts a thread that reads input and sends the input back via the provided buffer.
 ///
 /// The caller should listen on `in_avail_evt` for events. When `in_avail_evt` signals that data
-/// is available, the caller should lock the returned `Mutex` and read data out of the inner
+/// is available, the caller should lock `input_buffer` and read data out of the inner
 /// `VecDeque`. The data should be removed from the beginning of the `VecDeque` as it is processed.
 ///
 /// # Arguments
 ///
-/// * `rx` - Data source that the reader thread will wait on to send data back to the buffer
+/// * `input` - Data source that the reader thread will wait on to send data back to the buffer
 /// * `in_avail_evt` - Event triggered by the thread when new input is available on the buffer
 pub(in crate::virtio::console) fn spawn_input_thread(
-    mut rx: InStreamType,
-    in_avail_evt: &Event,
-    input_buffer: VecDeque<u8>,
-) -> (Arc<Mutex<VecDeque<u8>>>, WorkerThread<InStreamType>) {
-    let buffer = Arc::new(Mutex::new(input_buffer));
-    let buffer_cloned = buffer.clone();
-
-    let thread_in_avail_evt = in_avail_evt
-        .try_clone()
-        .expect("failed to clone in_avail_evt");
-
-    let res = WorkerThread::start("v_console_input", move |kill_evt| {
+    mut input: InStreamType,
+    in_avail_evt: Event,
+    input_buffer: Arc<Mutex<VecDeque<u8>>>,
+) -> WorkerThread<InStreamType> {
+    WorkerThread::start("v_console_input", move |kill_evt| {
         // If there is already data, signal immediately.
-        if !buffer.lock().is_empty() {
-            thread_in_avail_evt.signal().unwrap();
+        if !input_buffer.lock().is_empty() {
+            in_avail_evt.signal().unwrap();
         }
-        read_input(&mut rx, &thread_in_avail_evt, buffer, kill_evt);
-        rx
-    });
-    (buffer_cloned, res)
+        if let Err(e) = read_input(&mut input, &in_avail_evt, input_buffer, kill_evt) {
+            error!("console input thread exited with error: {:#}", e);
+        }
+        input
+    })
 }
 
-pub(in crate::virtio::console) fn read_input(
-    rx: &mut InStreamType,
+fn read_input(
+    input: &mut InStreamType,
     thread_in_avail_evt: &Event,
     buffer: Arc<Mutex<VecDeque<u8>>>,
     kill_evt: Event,
-) {
+) -> anyhow::Result<()> {
     #[derive(EventToken)]
     enum Token {
         ConsoleEvent,
         Kill,
     }
 
-    let wait_ctx: WaitContext<Token> = match WaitContext::build_with(&[
+    let wait_ctx: WaitContext<Token> = WaitContext::build_with(&[
         (&kill_evt, Token::Kill),
-        (rx.get_read_notifier(), Token::ConsoleEvent),
-    ]) {
-        Ok(ctx) => ctx,
-        Err(e) => {
-            error!("failed creating WaitContext {:?}", e);
-            return;
-        }
-    };
+        (input.get_read_notifier(), Token::ConsoleEvent),
+    ])
+    .context("failed creating WaitContext")?;
 
     let mut kill_timeout = None;
     let mut rx_buf = [0u8; 1 << 12];
     'wait: loop {
-        let events = match wait_ctx.wait() {
-            Ok(events) => events,
-            Err(e) => {
-                error!("Failed to wait for events. {}", e);
-                return;
-            }
-        };
+        let events = wait_ctx.wait().context("Failed to wait for events")?;
         for event in events.iter() {
             match event.token {
                 Token::Kill => {
                     // Ignore the kill event until there are no other events to process so that
-                    // we drain `rx` as much as possible. The next `wait_ctx.wait()` call will
+                    // we drain `input` as much as possible. The next `wait_ctx.wait()` call will
                     // immediately re-entry this case since we don't call `kill_evt.wait()`.
                     if events.iter().all(|e| matches!(e.token, Token::Kill)) {
                         break 'wait;
@@ -135,25 +162,22 @@ pub(in crate::virtio::console) fn read_input(
                     }
                 }
                 Token::ConsoleEvent => {
-                    match rx.read(&mut rx_buf) {
+                    match input.read(&mut rx_buf) {
                         Ok(0) => break 'wait, // Assume the stream of input has ended.
                         Ok(size) => {
                             buffer.lock().extend(&rx_buf[0..size]);
                             thread_in_avail_evt.signal().unwrap();
                         }
+                        // Being interrupted is not an error, but everything else is.
+                        Err(e) if e.kind() == io::ErrorKind::Interrupted => {}
                         Err(e) => {
-                            // Being interrupted is not an error, but everything else is.
-                            if is_a_fatal_input_error(&e) {
-                                error!(
-                                    "failed to read for bytes to queue into console device: {}",
-                                    e
-                                );
-                                break 'wait;
-                            }
+                            return Err(e).context("failed to read console input");
                         }
                     }
                 }
             }
         }
     }
+
+    Ok(())
 }
diff --git a/devices/src/virtio/console/sys/windows.rs b/devices/src/virtio/console/sys/windows.rs
index 1d122fcea..4096aa838 100644
--- a/devices/src/virtio/console/sys/windows.rs
+++ b/devices/src/virtio/console/sys/windows.rs
@@ -90,23 +90,13 @@ fn is_a_fatal_input_error(e: &io::Error) -> bool {
 /// * `in_avail_evt` - Event triggered by the thread when new input is available on the buffer
 pub(in crate::virtio::console) fn spawn_input_thread(
     mut rx: Box<named_pipes::PipeConnection>,
-    in_avail_evt: &Event,
-    input_buffer: VecDeque<u8>,
-) -> (
-    Arc<Mutex<VecDeque<u8>>>,
-    WorkerThread<Box<named_pipes::PipeConnection>>,
-) {
-    let buffer = Arc::new(Mutex::new(input_buffer));
-    let buffer_cloned = buffer.clone();
-
-    let thread_in_avail_evt = in_avail_evt
-        .try_clone()
-        .expect("failed to clone in_avail_evt");
-
-    let res = WorkerThread::start("v_console_input", move |kill_evt| {
+    in_avail_evt: Event,
+    input_buffer: Arc<Mutex<VecDeque<u8>>>,
+) -> WorkerThread<Box<named_pipes::PipeConnection>> {
+    WorkerThread::start("v_console_input", move |kill_evt| {
         // If there is already data, signal immediately.
-        if !buffer.lock().is_empty() {
-            thread_in_avail_evt.signal().unwrap();
+        if !input_buffer.lock().is_empty() {
+            in_avail_evt.signal().unwrap();
         }
 
         match rx.wait_for_client_connection_overlapped_blocking(&kill_evt) {
@@ -115,13 +105,12 @@ pub(in crate::virtio::console) fn spawn_input_thread(
             Ok(()) => (),
         }
 
-        read_input(&mut rx, &thread_in_avail_evt, buffer, kill_evt);
+        read_input(&mut rx, &in_avail_evt, input_buffer, kill_evt);
         rx
-    });
-    (buffer_cloned, res)
+    })
 }
 
-pub(in crate::virtio::console) fn read_input(
+fn read_input(
     rx: &mut Box<named_pipes::PipeConnection>,
     thread_in_avail_evt: &Event,
     buffer: Arc<Mutex<VecDeque<u8>>>,
diff --git a/devices/src/virtio/console/worker.rs b/devices/src/virtio/console/worker.rs
new file mode 100644
index 000000000..3c4417d93
--- /dev/null
+++ b/devices/src/virtio/console/worker.rs
@@ -0,0 +1,443 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Virtio console device worker thread.
+
+use std::collections::BTreeMap;
+use std::collections::VecDeque;
+use std::sync::mpsc;
+use std::sync::Arc;
+
+use anyhow::anyhow;
+use anyhow::Context;
+use base::error;
+use base::Event;
+use base::EventToken;
+use base::WaitContext;
+use base::WorkerThread;
+use sync::Mutex;
+
+use crate::virtio::console::control::process_control_receive_queue;
+use crate::virtio::console::control::process_control_transmit_queue;
+use crate::virtio::console::control::ControlMsgBytes;
+use crate::virtio::console::input::process_receive_queue;
+use crate::virtio::console::output::process_transmit_queue;
+use crate::virtio::console::port::ConsolePort;
+use crate::virtio::console::port::ConsolePortInfo;
+use crate::virtio::Interrupt;
+use crate::virtio::Queue;
+
+const PORT0_RECEIVEQ_IDX: usize = 0;
+const PORT0_TRANSMITQ_IDX: usize = 1;
+const CONTROL_RECEIVEQ_IDX: usize = 2;
+const CONTROL_TRANSMITQ_IDX: usize = 3;
+const PORT1_RECEIVEQ_IDX: usize = 4;
+const PORT1_TRANSMITQ_IDX: usize = 5;
+
+pub struct WorkerPort {
+    info: Option<ConsolePortInfo>,
+
+    in_avail_evt: Event,
+    input_buffer: Arc<Mutex<VecDeque<u8>>>,
+    output: Box<dyn std::io::Write + Send>,
+}
+
+impl WorkerPort {
+    pub fn from_console_port(port: &mut ConsolePort) -> WorkerPort {
+        let in_avail_evt = port.clone_in_avail_evt().unwrap();
+        let input_buffer = port.clone_input_buffer();
+        let output = port
+            .take_output()
+            .unwrap_or_else(|| Box::new(std::io::sink()));
+        let info = port.port_info().cloned();
+        WorkerPort {
+            info,
+            in_avail_evt,
+            input_buffer,
+            output,
+        }
+    }
+
+    /// Restore the state retrieved from `ConsolePort` by `WorkerPort::from_console_port()`.
+    pub fn into_console_port(self, console_port: &mut ConsolePort) {
+        console_port.restore_output(self.output);
+    }
+
+    pub fn is_console(&self) -> bool {
+        self.info
+            .as_ref()
+            .map(|info| info.console)
+            .unwrap_or_default()
+    }
+
+    pub fn name(&self) -> Option<&str> {
+        self.info.as_ref().and_then(ConsolePortInfo::name)
+    }
+}
+
+#[derive(EventToken)]
+enum Token {
+    ReceiveQueueAvailable(u32),
+    TransmitQueueAvailable(u32),
+    InputAvailable(u32),
+    ControlReceiveQueueAvailable,
+    ControlTransmitQueueAvailable,
+    InterruptResample,
+    WorkerRequest,
+    Kill,
+}
+
+pub enum WorkerRequest {
+    StartQueue {
+        idx: usize,
+        queue: Queue,
+        response_sender: mpsc::SyncSender<anyhow::Result<()>>,
+    },
+    StopQueue {
+        idx: usize,
+        response_sender: mpsc::SyncSender<Option<Queue>>,
+    },
+}
+
+pub struct Worker {
+    wait_ctx: WaitContext<Token>,
+    interrupt: Interrupt,
+
+    // Currently running queues.
+    queues: BTreeMap<usize, Queue>,
+
+    // Console ports indexed by port ID. At least port 0 will exist, and other ports may be
+    // available if `VIRTIO_CONSOLE_F_MULTIPORT` is enabled.
+    ports: Vec<WorkerPort>,
+
+    // Device-to-driver messages to be received by the driver via the control receiveq.
+    pending_receive_control_msgs: VecDeque<ControlMsgBytes>,
+
+    worker_receiver: mpsc::Receiver<WorkerRequest>,
+    worker_event: Event,
+}
+
+impl Worker {
+    pub fn new(
+        interrupt: Interrupt,
+        ports: Vec<WorkerPort>,
+        worker_receiver: mpsc::Receiver<WorkerRequest>,
+        worker_event: Event,
+    ) -> anyhow::Result<Self> {
+        let wait_ctx = WaitContext::new().context("WaitContext::new() failed")?;
+
+        wait_ctx.add(&worker_event, Token::WorkerRequest)?;
+
+        for (index, port) in ports.iter().enumerate() {
+            let port_id = index as u32;
+            wait_ctx.add(&port.in_avail_evt, Token::InputAvailable(port_id))?;
+        }
+
+        if let Some(resample_evt) = interrupt.get_resample_evt() {
+            wait_ctx.add(resample_evt, Token::InterruptResample)?;
+        }
+
+        Ok(Worker {
+            wait_ctx,
+            interrupt,
+            queues: BTreeMap::new(),
+            ports,
+            pending_receive_control_msgs: VecDeque::new(),
+            worker_receiver,
+            worker_event,
+        })
+    }
+
+    pub fn run(&mut self, kill_evt: &Event) -> anyhow::Result<()> {
+        self.wait_ctx.add(kill_evt, Token::Kill)?;
+        let res = self.run_loop();
+        self.wait_ctx.delete(kill_evt)?;
+        res
+    }
+
+    fn run_loop(&mut self) -> anyhow::Result<()> {
+        let mut running = true;
+        while running {
+            let events = self.wait_ctx.wait()?;
+
+            for event in events.iter().filter(|e| e.is_readable) {
+                match event.token {
+                    Token::TransmitQueueAvailable(port_id) => {
+                        if let (Some(port), Some(transmitq)) = (
+                            self.ports.get_mut(port_id as usize),
+                            transmitq_idx(port_id).and_then(|idx| self.queues.get_mut(&idx)),
+                        ) {
+                            transmitq
+                                .event()
+                                .wait()
+                                .context("failed reading transmit queue Event")?;
+                            process_transmit_queue(transmitq, &mut port.output);
+                        }
+                    }
+                    Token::ReceiveQueueAvailable(port_id) | Token::InputAvailable(port_id) => {
+                        let port = self.ports.get_mut(port_id as usize);
+                        let receiveq =
+                            receiveq_idx(port_id).and_then(|idx| self.queues.get_mut(&idx));
+
+                        let event = if matches!(event.token, Token::ReceiveQueueAvailable(..)) {
+                            receiveq.as_ref().map(|q| q.event())
+                        } else {
+                            port.as_ref().map(|p| &p.in_avail_evt)
+                        };
+                        if let Some(event) = event {
+                            event.wait().context("failed to clear receive event")?;
+                        }
+
+                        if let (Some(port), Some(receiveq)) = (port, receiveq) {
+                            let mut input_buffer = port.input_buffer.lock();
+                            process_receive_queue(&mut input_buffer, receiveq);
+                        }
+                    }
+                    Token::ControlReceiveQueueAvailable => {
+                        if let Some(ctrl_receiveq) = self.queues.get_mut(&CONTROL_RECEIVEQ_IDX) {
+                            ctrl_receiveq
+                                .event()
+                                .wait()
+                                .context("failed waiting on control event")?;
+                            process_control_receive_queue(
+                                ctrl_receiveq,
+                                &mut self.pending_receive_control_msgs,
+                            );
+                        }
+                    }
+                    Token::ControlTransmitQueueAvailable => {
+                        if let Some(ctrl_transmitq) = self.queues.get_mut(&CONTROL_TRANSMITQ_IDX) {
+                            ctrl_transmitq
+                                .event()
+                                .wait()
+                                .context("failed waiting on control event")?;
+                            process_control_transmit_queue(
+                                ctrl_transmitq,
+                                &self.ports,
+                                &mut self.pending_receive_control_msgs,
+                            );
+                        }
+
+                        // Attempt to send any new replies if there is space in the receiveq.
+                        if let Some(ctrl_receiveq) = self.queues.get_mut(&CONTROL_RECEIVEQ_IDX) {
+                            process_control_receive_queue(
+                                ctrl_receiveq,
+                                &mut self.pending_receive_control_msgs,
+                            )
+                        }
+                    }
+                    Token::InterruptResample => {
+                        self.interrupt.interrupt_resample();
+                    }
+                    Token::WorkerRequest => {
+                        self.worker_event.wait()?;
+                        self.process_worker_requests();
+                    }
+                    Token::Kill => running = false,
+                }
+            }
+        }
+        Ok(())
+    }
+
+    fn process_worker_requests(&mut self) {
+        while let Ok(request) = self.worker_receiver.try_recv() {
+            match request {
+                WorkerRequest::StartQueue {
+                    idx,
+                    queue,
+                    response_sender,
+                } => {
+                    let res = self.start_queue(idx, queue);
+                    let _ = response_sender.send(res);
+                }
+                WorkerRequest::StopQueue {
+                    idx,
+                    response_sender,
+                } => {
+                    let res = self.stop_queue(idx);
+                    let _ = response_sender.send(res);
+                }
+            }
+        }
+    }
+
+    fn start_queue(&mut self, idx: usize, queue: Queue) -> anyhow::Result<()> {
+        if let Some(port_id) = receiveq_port_id(idx) {
+            self.wait_ctx
+                .add(queue.event(), Token::ReceiveQueueAvailable(port_id))?;
+        } else if let Some(port_id) = transmitq_port_id(idx) {
+            self.wait_ctx
+                .add(queue.event(), Token::TransmitQueueAvailable(port_id))?;
+        } else if idx == CONTROL_RECEIVEQ_IDX {
+            self.wait_ctx
+                .add(queue.event(), Token::ControlReceiveQueueAvailable)?;
+        } else if idx == CONTROL_TRANSMITQ_IDX {
+            self.wait_ctx
+                .add(queue.event(), Token::ControlTransmitQueueAvailable)?;
+        } else {
+            return Err(anyhow!("unhandled queue idx {idx}"));
+        }
+
+        let prev = self.queues.insert(idx, queue);
+        assert!(prev.is_none());
+        Ok(())
+    }
+
+    fn stop_queue(&mut self, idx: usize) -> Option<Queue> {
+        if let Some(queue) = self.queues.remove(&idx) {
+            let _ = self.wait_ctx.delete(queue.event());
+            Some(queue)
+        } else {
+            None
+        }
+    }
+}
+
+pub struct WorkerHandle {
+    worker_thread: WorkerThread<Vec<WorkerPort>>,
+    worker_sender: mpsc::Sender<WorkerRequest>,
+    worker_event: Event,
+}
+
+impl WorkerHandle {
+    pub fn new(interrupt: Interrupt, ports: Vec<WorkerPort>) -> anyhow::Result<Self> {
+        let worker_event = Event::new().context("Event::new")?;
+        let worker_event_clone = worker_event.try_clone().context("Event::try_clone")?;
+        let (worker_sender, worker_receiver) = mpsc::channel();
+        let worker_thread = WorkerThread::start("v_console", move |kill_evt| {
+            let mut worker = Worker::new(interrupt, ports, worker_receiver, worker_event_clone)
+                .expect("console Worker::new() failed");
+            if let Err(e) = worker.run(&kill_evt) {
+                error!("console worker failed: {:#}", e);
+            }
+            worker.ports
+        });
+        Ok(WorkerHandle {
+            worker_thread,
+            worker_sender,
+            worker_event,
+        })
+    }
+
+    pub fn start_queue(&mut self, idx: usize, queue: Queue) -> anyhow::Result<()> {
+        let (response_sender, response_receiver) = mpsc::sync_channel(0);
+        self.worker_sender
+            .send(WorkerRequest::StartQueue {
+                idx,
+                queue,
+                response_sender,
+            })
+            .context("mpsc::Sender::send")?;
+        self.worker_event.signal().context("Event::signal")?;
+        response_receiver.recv().context("mpsc::Receiver::recv")?
+    }
+
+    pub fn stop_queue(&mut self, idx: usize) -> anyhow::Result<Option<Queue>> {
+        let (response_sender, response_receiver) = mpsc::sync_channel(0);
+        self.worker_sender
+            .send(WorkerRequest::StopQueue {
+                idx,
+                response_sender,
+            })
+            .context("mpsc::Sender::send")?;
+        self.worker_event.signal().context("Event::signal")?;
+        response_receiver.recv().context("mpsc::Receiver::recv")
+    }
+
+    pub fn stop(self) -> Vec<WorkerPort> {
+        self.worker_thread.stop()
+    }
+}
+
+fn receiveq_idx(port_id: u32) -> Option<usize> {
+    if port_id == 0 {
+        Some(PORT0_RECEIVEQ_IDX)
+    } else {
+        PORT1_RECEIVEQ_IDX.checked_add((port_id - 1).checked_mul(2)?.try_into().ok()?)
+    }
+}
+
+fn transmitq_idx(port_id: u32) -> Option<usize> {
+    if port_id == 0 {
+        Some(PORT0_TRANSMITQ_IDX)
+    } else {
+        PORT1_TRANSMITQ_IDX.checked_add((port_id - 1).checked_mul(2)?.try_into().ok()?)
+    }
+}
+
+fn receiveq_port_id(queue_idx: usize) -> Option<u32> {
+    if queue_idx == PORT0_RECEIVEQ_IDX {
+        Some(0)
+    } else if queue_idx >= PORT1_RECEIVEQ_IDX && (queue_idx & 1) == 0 {
+        ((queue_idx - PORT1_RECEIVEQ_IDX) / 2)
+            .checked_add(1)?
+            .try_into()
+            .ok()
+    } else {
+        None
+    }
+}
+
+fn transmitq_port_id(queue_idx: usize) -> Option<u32> {
+    if queue_idx == PORT0_TRANSMITQ_IDX {
+        Some(0)
+    } else if queue_idx >= PORT1_TRANSMITQ_IDX && (queue_idx & 1) == 1 {
+        ((queue_idx - PORT1_TRANSMITQ_IDX) / 2)
+            .checked_add(1)?
+            .try_into()
+            .ok()
+    } else {
+        None
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn test_receiveq_idx() {
+        assert_eq!(receiveq_idx(0), Some(0));
+        assert_eq!(receiveq_idx(1), Some(4));
+        assert_eq!(receiveq_idx(2), Some(6));
+        assert_eq!(receiveq_idx(3), Some(8));
+    }
+
+    #[test]
+    fn test_transmitq_idx() {
+        assert_eq!(transmitq_idx(0), Some(1));
+        assert_eq!(transmitq_idx(1), Some(5));
+        assert_eq!(transmitq_idx(2), Some(7));
+        assert_eq!(transmitq_idx(3), Some(9));
+    }
+
+    #[test]
+    fn test_receiveq_port_id() {
+        assert_eq!(receiveq_port_id(0), Some(0));
+        assert_eq!(receiveq_port_id(1), None); // port0 transmitq
+        assert_eq!(receiveq_port_id(2), None); // ctrl receiveq
+        assert_eq!(receiveq_port_id(3), None); // ctrl transmitq
+        assert_eq!(receiveq_port_id(4), Some(1));
+        assert_eq!(receiveq_port_id(5), None);
+        assert_eq!(receiveq_port_id(6), Some(2));
+        assert_eq!(receiveq_port_id(7), None);
+        assert_eq!(receiveq_port_id(8), Some(3));
+        assert_eq!(receiveq_port_id(9), None);
+    }
+
+    #[test]
+    fn test_transmitq_port_id() {
+        assert_eq!(transmitq_port_id(0), None); // port0 receiveq
+        assert_eq!(transmitq_port_id(1), Some(0));
+        assert_eq!(transmitq_port_id(2), None); // ctrl receiveq
+        assert_eq!(transmitq_port_id(3), None); // ctrl transmitq
+        assert_eq!(transmitq_port_id(4), None); // port1 receiveq
+        assert_eq!(transmitq_port_id(5), Some(1));
+        assert_eq!(transmitq_port_id(6), None);
+        assert_eq!(transmitq_port_id(7), Some(2));
+        assert_eq!(transmitq_port_id(8), None);
+        assert_eq!(transmitq_port_id(9), Some(3));
+    }
+}
diff --git a/devices/src/virtio/descriptor_utils.rs b/devices/src/virtio/descriptor_utils.rs
index e067ac489..7f43dd4eb 100644
--- a/devices/src/virtio/descriptor_utils.rs
+++ b/devices/src/virtio/descriptor_utils.rs
@@ -304,7 +304,7 @@ impl Reader {
     /// enough data in the descriptor chain buffer.
     pub fn read_to_at<F: FileReadWriteAtVolatile>(
         &mut self,
-        mut dst: F,
+        dst: &F,
         count: usize,
         off: u64,
     ) -> io::Result<usize> {
@@ -342,12 +342,12 @@ impl Reader {
     /// returning an error if 'count' bytes can't be read.
     pub fn read_exact_to_at<F: FileReadWriteAtVolatile>(
         &mut self,
-        mut dst: F,
+        dst: &F,
         mut count: usize,
         mut off: u64,
     ) -> io::Result<()> {
         while count > 0 {
-            match self.read_to_at(&mut dst, count, off) {
+            match self.read_to_at(dst, count, off) {
                 Ok(0) => {
                     return Err(io::Error::new(
                         io::ErrorKind::UnexpectedEof,
@@ -595,7 +595,7 @@ impl Writer {
     /// there isn't enough data in the descriptor chain buffer.
     pub fn write_from_at<F: FileReadWriteAtVolatile>(
         &mut self,
-        mut src: F,
+        src: &F,
         count: usize,
         off: u64,
     ) -> io::Result<usize> {
@@ -629,12 +629,12 @@ impl Writer {
 
     pub fn write_all_from_at<F: FileReadWriteAtVolatile>(
         &mut self,
-        mut src: F,
+        src: &F,
         mut count: usize,
         mut off: u64,
     ) -> io::Result<()> {
         while count > 0 {
-            match self.write_from_at(&mut src, count, off) {
+            match self.write_from_at(src, count, off) {
                 Ok(0) => {
                     return Err(io::Error::new(
                         io::ErrorKind::WriteZero,
@@ -1403,7 +1403,7 @@ mod tests {
         } = chain.reader;
 
         let drain = regions
-            .get_remaining_regions_with_count(::std::usize::MAX)
+            .get_remaining_regions_with_count(usize::MAX)
             .fold(0usize, |total, region| total + region.len);
         assert_eq!(drain, 128);
 
@@ -1456,7 +1456,7 @@ mod tests {
         } = chain.reader;
 
         let drain = regions
-            .get_remaining_with_count(&memory, ::std::usize::MAX)
+            .get_remaining_with_count(&memory, usize::MAX)
             .iter()
             .fold(0usize, |total, iov| total + iov.size());
         assert_eq!(drain, 128);
diff --git a/devices/src/virtio/device_constants.rs b/devices/src/virtio/device_constants.rs
index 4eee33efc..52edc1780 100644
--- a/devices/src/virtio/device_constants.rs
+++ b/devices/src/virtio/device_constants.rs
@@ -252,7 +252,46 @@ pub mod wl {
 }
 
 pub mod console {
+    use data_model::Le16;
+    use data_model::Le32;
+    use zerocopy::AsBytes;
+    use zerocopy::FromBytes;
+    use zerocopy::FromZeroes;
+
     pub const VIRTIO_CONSOLE_F_SIZE: u32 = 0;
     pub const VIRTIO_CONSOLE_F_MULTIPORT: u32 = 1;
     pub const VIRTIO_CONSOLE_F_EMERG_WRITE: u32 = 2;
+
+    #[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
+    #[repr(C)]
+    pub struct virtio_console_config {
+        pub cols: Le16,
+        pub rows: Le16,
+        pub max_nr_ports: Le32,
+        pub emerg_wr: Le32,
+    }
+
+    #[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+    #[repr(C)]
+    pub struct virtio_console_control {
+        pub id: Le32,
+        pub event: Le16,
+        pub value: Le16,
+    }
+
+    #[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+    #[repr(C)]
+    pub struct virtio_console_resize {
+        pub cols: Le16,
+        pub rows: Le16,
+    }
+
+    pub const VIRTIO_CONSOLE_DEVICE_READY: u16 = 0;
+    pub const VIRTIO_CONSOLE_DEVICE_ADD: u16 = 1;
+    pub const VIRTIO_CONSOLE_DEVICE_REMOVE: u16 = 2;
+    pub const VIRTIO_CONSOLE_PORT_READY: u16 = 3;
+    pub const VIRTIO_CONSOLE_CONSOLE_PORT: u16 = 4;
+    pub const VIRTIO_CONSOLE_RESIZE: u16 = 5;
+    pub const VIRTIO_CONSOLE_PORT_OPEN: u16 = 6;
+    pub const VIRTIO_CONSOLE_PORT_NAME: u16 = 7;
 }
diff --git a/devices/src/virtio/fs/arc_ioctl.rs b/devices/src/virtio/fs/arc_ioctl.rs
new file mode 100644
index 000000000..c3dc79f79
--- /dev/null
+++ b/devices/src/virtio/fs/arc_ioctl.rs
@@ -0,0 +1,61 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Data structures and logic for virtio-fs IOCTLs specific to ARCVM.
+
+use zerocopy::AsBytes;
+use zerocopy::FromBytes;
+use zerocopy::FromZeroes;
+
+pub const FS_IOCTL_PATH_MAX_LEN: usize = 128;
+pub const FS_IOCTL_XATTR_NAME_MAX_LEN: usize = 128;
+pub const FS_IOCTL_XATTR_VALUE_MAX_LEN: usize = 128;
+
+#[derive(Debug, Clone, PartialEq)]
+pub(crate) struct PermissionData {
+    pub guest_uid: libc::uid_t,
+    pub guest_gid: libc::gid_t,
+    pub host_uid: libc::uid_t,
+    pub host_gid: libc::gid_t,
+    pub umask: libc::mode_t,
+    pub perm_path: String,
+}
+
+impl PermissionData {
+    pub(crate) fn need_set_permission(&self, path: &str) -> bool {
+        path.starts_with(&self.perm_path)
+    }
+}
+
+#[repr(C)]
+#[derive(Clone, Copy, AsBytes, FromZeroes, FromBytes)]
+pub(crate) struct FsPermissionDataBuffer {
+    pub guest_uid: u32,
+    pub guest_gid: u32,
+    pub host_uid: u32,
+    pub host_gid: u32,
+    pub umask: u32,
+    pub pad: u32,
+    pub perm_path: [u8; FS_IOCTL_PATH_MAX_LEN],
+}
+
+#[derive(Debug, Clone, PartialEq)]
+pub(crate) struct XattrData {
+    pub xattr_name: String,
+    pub xattr_value: String,
+    pub xattr_path: String,
+}
+
+impl XattrData {
+    pub(crate) fn need_set_guest_xattr(&self, path: &str, name: &str) -> bool {
+        path.starts_with(&self.xattr_path) && (name == self.xattr_name)
+    }
+}
+#[repr(C)]
+#[derive(Clone, Copy, AsBytes, FromZeroes, FromBytes)]
+pub(crate) struct FsPathXattrDataBuffer {
+    pub path: [u8; FS_IOCTL_PATH_MAX_LEN],
+    pub xattr_name: [u8; FS_IOCTL_XATTR_NAME_MAX_LEN],
+    pub xattr_value: [u8; FS_IOCTL_XATTR_VALUE_MAX_LEN],
+}
diff --git a/devices/src/virtio/fs/config.rs b/devices/src/virtio/fs/config.rs
index 3a9269238..35d4075ef 100644
--- a/devices/src/virtio/fs/config.rs
+++ b/devices/src/virtio/fs/config.rs
@@ -46,6 +46,10 @@ const fn config_default_posix_acl() -> bool {
     true
 }
 
+const fn config_default_security_ctx() -> bool {
+    true
+}
+
 fn deserialize_timeout<'de, D: Deserializer<'de>>(deserializer: D) -> Result<Duration, D::Error> {
     let secs = u64::deserialize(deserializer)?;
 
@@ -168,6 +172,38 @@ pub struct Config {
     /// The default value for this option is `true`.
     #[serde(default = "config_default_posix_acl")]
     pub posix_acl: bool,
+
+    // Maximum number of dynamic permission paths.
+    //
+    // The dynamic permission paths are used to set specific paths certain uid/gid after virtiofs
+    // device is created. It is for arcvm special usage, normal device should not support
+    // this feature.
+    //
+    // The default value for this option is 0.
+    #[serde(default)]
+    pub max_dynamic_perm: usize,
+
+    // Maximum number of dynamic xattr paths.
+    //
+    // The dynamic xattr paths are used to set specific paths certain xattr after virtiofs
+    // device is created. It is for arcvm special usage, normal device should not support
+    // this feature.
+    //
+    // The default value for this option is 0.
+    #[serde(default)]
+    pub max_dynamic_xattr: usize,
+
+    // Controls whether fuse_security_context feature is enabled
+    //
+    // The FUSE_SECURITY_CONTEXT feature needs write data into /proc/thread-self/attr/fscreate.
+    // For the hosts that prohibit the write operation, the option should be set to false to
+    // disable the FUSE_SECURITY_CONTEXT feature. When FUSE_SECURITY_CONTEXT is disabled, the
+    // security context won't be passed with fuse request, which makes guest created files/dir
+    // having unlabeled security context or empty security context.
+    //
+    // The default value for this option is true
+    #[serde(default = "config_default_security_ctx")]
+    pub security_ctx: bool,
 }
 
 impl Default for Config {
@@ -183,6 +219,9 @@ impl Default for Config {
             privileged_quota_uids: Default::default(),
             use_dax: false,
             posix_acl: config_default_posix_acl(),
+            max_dynamic_perm: 0,
+            max_dynamic_xattr: 0,
+            security_ctx: config_default_security_ctx(),
         }
     }
 }
diff --git a/devices/src/virtio/fs/expiring_map.rs b/devices/src/virtio/fs/expiring_map.rs
index 0e4f5deef..4d529e3f9 100644
--- a/devices/src/virtio/fs/expiring_map.rs
+++ b/devices/src/virtio/fs/expiring_map.rs
@@ -2,6 +2,7 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
+use std::collections::btree_map::Entry;
 use std::collections::BTreeMap;
 use std::collections::VecDeque;
 use std::time::Duration;
@@ -50,13 +51,15 @@ where
         let now = Instant::now();
         self.cleanup(&now);
 
-        if self.map.get(key).is_some() {
-            Ok(self.map.get(key).map(|(v, _)| v).expect("must exist"))
-        } else {
-            self.dq.push_back((key.clone(), now));
-            self.map.insert(key.clone(), (f()?, now));
-            Ok(self.map.get(key).map(|(v, _)| v).expect("must exist"))
-        }
+        let (v, _) = match self.map.entry(key.clone()) {
+            Entry::Occupied(o) => o.into_mut(),
+            Entry::Vacant(v) => {
+                let value = f()?;
+                self.dq.push_back((key.clone(), now));
+                v.insert((value, now))
+            }
+        };
+        Ok(v)
     }
 
     pub fn get_mut(&mut self, key: &K) -> Option<&mut V> {
@@ -67,11 +70,6 @@ where
 
     pub fn remove(&mut self, key: &K) {
         self.map.remove(key);
-        self.dq = self
-            .dq
-            .iter()
-            .filter(|(k, _)| k != key)
-            .map(|(k, time)| (k.clone(), *time))
-            .collect();
+        self.dq.retain(|(k, _)| k != key);
     }
 }
diff --git a/devices/src/virtio/fs/mod.rs b/devices/src/virtio/fs/mod.rs
index 78956c159..869324885 100644
--- a/devices/src/virtio/fs/mod.rs
+++ b/devices/src/virtio/fs/mod.rs
@@ -40,6 +40,8 @@ use crate::virtio::Queue;
 use crate::virtio::VirtioDevice;
 use crate::virtio::VirtioPciShmCap;
 
+#[cfg(feature = "arc_quota")]
+mod arc_ioctl;
 mod caps;
 mod config;
 mod expiring_map;
@@ -239,7 +241,7 @@ impl VirtioDevice for Fs {
                 .send(&request)
                 .expect("failed to send allocation message");
             slot = match socket.recv() {
-                Ok(VmResponse::RegisterMemory { pfn: _, slot }) => slot,
+                Ok(VmResponse::RegisterMemory { gfn: _, slot }) => slot,
                 Ok(VmResponse::Err(e)) => panic!("failed to allocate shared memory region: {}", e),
                 r => panic!(
                     "unexpected response to allocate shared memory region: {:?}",
diff --git a/devices/src/virtio/fs/passthrough.rs b/devices/src/virtio/fs/passthrough.rs
index cc581100a..d985ae147 100644
--- a/devices/src/virtio/fs/passthrough.rs
+++ b/devices/src/virtio/fs/passthrough.rs
@@ -24,8 +24,12 @@ use std::sync::atomic::AtomicU64;
 use std::sync::atomic::Ordering;
 use std::sync::Arc;
 use std::sync::MutexGuard;
+#[cfg(feature = "arc_quota")]
+use std::sync::RwLock;
 use std::time::Duration;
 
+#[cfg(feature = "arc_quota")]
+use base::debug;
 use base::error;
 use base::ioctl_ior_nr;
 use base::ioctl_iow_nr;
@@ -37,6 +41,7 @@ use base::unix::FileFlags;
 use base::warn;
 use base::AsRawDescriptor;
 use base::FromRawDescriptor;
+use base::IoctlNr;
 use base::Protection;
 use base::RawDescriptor;
 use fuse::filesystem::Context;
@@ -69,6 +74,14 @@ use zerocopy::AsBytes;
 use zerocopy::FromBytes;
 use zerocopy::FromZeroes;
 
+#[cfg(feature = "arc_quota")]
+use crate::virtio::fs::arc_ioctl::FsPathXattrDataBuffer;
+#[cfg(feature = "arc_quota")]
+use crate::virtio::fs::arc_ioctl::FsPermissionDataBuffer;
+#[cfg(feature = "arc_quota")]
+use crate::virtio::fs::arc_ioctl::PermissionData;
+#[cfg(feature = "arc_quota")]
+use crate::virtio::fs::arc_ioctl::XattrData;
 use crate::virtio::fs::caps::Capability;
 use crate::virtio::fs::caps::Caps;
 use crate::virtio::fs::caps::Set as CapSet;
@@ -180,6 +193,11 @@ ioctl_iow_nr!(FS_IOC32_SETFLAGS, 'f' as u32, 2, u32);
 ioctl_ior_nr!(FS_IOC64_GETFLAGS, 'f' as u32, 1, u64);
 ioctl_iow_nr!(FS_IOC64_SETFLAGS, 'f' as u32, 2, u64);
 
+#[cfg(feature = "arc_quota")]
+ioctl_iow_nr!(FS_IOC_SETPERMISSION, 'f' as u32, 1, FsPermissionDataBuffer);
+#[cfg(feature = "arc_quota")]
+ioctl_iow_nr!(FS_IOC_SETPATHXATTR, 'f' as u32, 1, FsPathXattrDataBuffer);
+
 #[repr(C)]
 #[derive(Clone, Copy, AsBytes, FromZeroes, FromBytes)]
 struct fsverity_enable_arg {
@@ -354,7 +372,7 @@ fn set_creds(
     ScopedGid::new(gid, oldgid).and_then(|gid| Ok((ScopedUid::new(uid, olduid)?, gid)))
 }
 
-thread_local!(static THREAD_FSCREATE: RefCell<Option<File>> = RefCell::new(None));
+thread_local!(static THREAD_FSCREATE: RefCell<Option<File>> = const { RefCell::new(None) });
 
 // Opens and returns a write-only handle to /proc/thread-self/attr/fscreate. Panics if it fails to
 // open the file.
@@ -492,7 +510,7 @@ fn eexist() -> io::Error {
 }
 
 fn stat<F: AsRawDescriptor + ?Sized>(f: &F) -> io::Result<libc::stat64> {
-    let mut st = MaybeUninit::<libc::stat64>::zeroed();
+    let mut st: MaybeUninit<libc::stat64> = MaybeUninit::<libc::stat64>::zeroed();
 
     // SAFETY: this is a constant value that is a nul-terminated string without interior nul bytes.
     let pathname = unsafe { CStr::from_bytes_with_nul_unchecked(EMPTY_CSTR) };
@@ -655,7 +673,6 @@ pub struct PassthroughFs {
     process_lock: Mutex<()>,
     // virtio-fs tag that the guest uses when mounting. This is only used for debugging
     // when tracing is enabled.
-    #[cfg_attr(not(feature = "trace_marker"), allow(dead_code))]
     tag: String,
 
     // File descriptors for various points in the file system tree.
@@ -697,6 +714,14 @@ pub struct PassthroughFs {
     // if we use PassthroughFs in multi-threaded environments.
     expiring_casefold_lookup_caches: Option<Mutex<ExpiringCasefoldLookupCaches>>,
 
+    // paths and coresponding permission setting set by `crosvm_client_fs_permission_set` API
+    #[cfg(feature = "arc_quota")]
+    permission_paths: RwLock<Vec<PermissionData>>,
+
+    // paths and coresponding xattr setting set by `crosvm_client_fs_xattr_set` API
+    #[cfg(feature = "arc_quota")]
+    xattr_paths: RwLock<Vec<XattrData>>,
+
     cfg: Config,
 }
 
@@ -775,6 +800,10 @@ impl PassthroughFs {
             #[cfg(feature = "arc_quota")]
             dbus_fd,
             expiring_casefold_lookup_caches,
+            #[cfg(feature = "arc_quota")]
+            permission_paths: RwLock::new(Vec::new()),
+            #[cfg(feature = "arc_quota")]
+            xattr_paths: RwLock::new(Vec::new()),
             cfg,
         };
 
@@ -820,11 +849,7 @@ impl PassthroughFs {
     }
 
     fn find_inode(&self, inode: Inode) -> io::Result<Arc<InodeData>> {
-        self.inodes
-            .lock()
-            .get(&inode)
-            .map(Arc::clone)
-            .ok_or_else(ebadf)
+        self.inodes.lock().get(&inode).cloned().ok_or_else(ebadf)
     }
 
     fn find_handle(&self, handle: Handle, inode: Inode) -> io::Result<Arc<HandleData>> {
@@ -832,7 +857,7 @@ impl PassthroughFs {
             .lock()
             .get(&handle)
             .filter(|hd| hd.inode == inode)
-            .map(Arc::clone)
+            .cloned()
             .ok_or_else(ebadf)
     }
 
@@ -898,7 +923,16 @@ impl PassthroughFs {
     // Creates a new entry for `f` or increases the refcount of the existing entry for `f`.
     // The inodes mutex lock must not be already taken by the same thread otherwise this
     // will deadlock.
-    fn add_entry(&self, f: File, st: libc::stat64, open_flags: libc::c_int, path: String) -> Entry {
+    fn add_entry(
+        &self,
+        f: File,
+        #[cfg(feature = "arc_quota")] mut st: libc::stat64,
+        #[cfg(not(feature = "arc_quota"))] st: libc::stat64,
+        open_flags: libc::c_int,
+        path: String,
+    ) -> Entry {
+        #[cfg(feature = "arc_quota")]
+        self.set_permission(&mut st, &path);
         let mut inodes = self.inodes.lock();
 
         let altkey = InodeAltKey {
@@ -974,6 +1008,9 @@ impl PassthroughFs {
     }
 
     fn do_lookup(&self, parent: &InodeData, name: &CStr) -> io::Result<Entry> {
+        #[cfg(feature = "arc_quota")]
+        let mut st = statat(parent, name)?;
+        #[cfg(not(feature = "arc_quota"))]
         let st = statat(parent, name)?;
 
         let altkey = InodeAltKey {
@@ -981,9 +1018,17 @@ impl PassthroughFs {
             dev: st.st_dev,
         };
 
+        let path = format!(
+            "{}/{}",
+            parent.path.clone(),
+            name.to_str().unwrap_or("<non UTF-8 str>")
+        );
+
         // Check if we already have an entry before opening a new file.
         if let Some(data) = self.inodes.lock().get_alt(&altkey) {
             // Return the same inode with the reference counter increased.
+            #[cfg(feature = "arc_quota")]
+            self.set_permission(&mut st, &path);
             return Ok(Entry {
                 inode: self.increase_inode_refcount(data),
                 generation: 0,
@@ -1038,11 +1083,6 @@ impl PassthroughFs {
 
         // SAFETY: safe because we own the fd.
         let f = unsafe { File::from_raw_descriptor(fd) };
-        let path = format!(
-            "{}/{}",
-            parent.path.clone(),
-            name.to_str().unwrap_or("<non UTF-8 str>")
-        );
         // We made sure the lock acquired for `self.inodes` is released automatically when
         // the if block above is exited, so a call to `self.add_entry()` should not cause a deadlock
         // here. This would not be the case if this were executed in an else block instead.
@@ -1149,8 +1189,12 @@ impl PassthroughFs {
     }
 
     fn do_getattr(&self, inode: &InodeData) -> io::Result<(libc::stat64, Duration)> {
+        #[cfg(feature = "arc_quota")]
+        let mut st = stat(inode)?;
+        #[cfg(feature = "arc_quota")]
+        self.set_permission(&mut st, &inode.path);
+        #[cfg(not(feature = "arc_quota"))]
         let st = stat(inode)?;
-
         Ok((st, self.cfg.timeout))
     }
 
@@ -1273,7 +1317,7 @@ impl PassthroughFs {
 
         let res =
             // SAFETY: the kernel will only write to `arg` and we check the return value.
-            unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_GET_ENCRYPTION_POLICY_EX(), &mut arg) };
+            unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_GET_ENCRYPTION_POLICY_EX, &mut arg) };
         if res < 0 {
             Ok(IoctlReply::Done(Err(io::Error::last_os_error())))
         } else {
@@ -1292,7 +1336,7 @@ impl PassthroughFs {
         let mut buf = MaybeUninit::<fsxattr>::zeroed();
 
         // SAFETY: the kernel will only write to `buf` and we check the return value.
-        let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_FSGETXATTR(), buf.as_mut_ptr()) };
+        let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_FSGETXATTR, buf.as_mut_ptr()) };
         if res < 0 {
             Ok(IoctlReply::Done(Err(io::Error::last_os_error())))
         } else {
@@ -1328,7 +1372,7 @@ impl PassthroughFs {
             // Get the current fsxattr.
             let mut buf = MaybeUninit::<fsxattr>::zeroed();
             // SAFETY: the kernel will only write to `buf` and we check the return value.
-            let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_FSGETXATTR(), buf.as_mut_ptr()) };
+            let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_FSGETXATTR, buf.as_mut_ptr()) };
             if res < 0 {
                 return Ok(IoctlReply::Done(Err(io::Error::last_os_error())));
             }
@@ -1367,7 +1411,7 @@ impl PassthroughFs {
         }
 
         //  SAFETY: this doesn't modify any memory and we check the return value.
-        let res = unsafe { ioctl_with_ptr(&*data, FS_IOC_FSSETXATTR(), &in_attr) };
+        let res = unsafe { ioctl_with_ptr(&*data, FS_IOC_FSSETXATTR, &in_attr) };
         if res < 0 {
             Ok(IoctlReply::Done(Err(io::Error::last_os_error())))
         } else {
@@ -1386,7 +1430,7 @@ impl PassthroughFs {
         let mut flags: c_int = 0;
 
         // SAFETY: the kernel will only write to `flags` and we check the return value.
-        let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_GETFLAGS(), &mut flags) };
+        let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_GETFLAGS, &mut flags) };
         if res < 0 {
             Ok(IoctlReply::Done(Err(io::Error::last_os_error())))
         } else {
@@ -1420,7 +1464,7 @@ impl PassthroughFs {
             // Get the current flag.
             let mut buf = MaybeUninit::<c_int>::zeroed();
             // SAFETY: the kernel will only write to `buf` and we check the return value.
-            let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_GETFLAGS(), buf.as_mut_ptr()) };
+            let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_GETFLAGS, buf.as_mut_ptr()) };
             if res < 0 {
                 return Ok(IoctlReply::Done(Err(io::Error::last_os_error())));
             }
@@ -1458,7 +1502,7 @@ impl PassthroughFs {
         }
 
         // SAFETY: this doesn't modify any memory and we check the return value.
-        let res = unsafe { ioctl_with_ptr(&*data, FS_IOC_SETFLAGS(), &in_flags) };
+        let res = unsafe { ioctl_with_ptr(&*data, FS_IOC_SETFLAGS, &in_flags) };
         if res < 0 {
             Ok(IoctlReply::Done(Err(io::Error::last_os_error())))
         } else {
@@ -1555,7 +1599,7 @@ impl PassthroughFs {
         }
 
         // SAFETY: this doesn't modify any memory and we check the return value.
-        let res = unsafe { ioctl_with_ptr(&*data, FS_IOC_ENABLE_VERITY(), &arg) };
+        let res = unsafe { ioctl_with_ptr(&*data, FS_IOC_ENABLE_VERITY, &arg) };
         if res < 0 {
             Ok(IoctlReply::Done(Err(io::Error::last_os_error())))
         } else {
@@ -1599,7 +1643,7 @@ impl PassthroughFs {
         };
 
         // SAFETY: this will only modify `buf` and we check the return value.
-        let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_MEASURE_VERITY(), buf.as_mut_ptr()) };
+        let res = unsafe { ioctl_with_mut_ptr(&*data, FS_IOC_MEASURE_VERITY, buf.as_mut_ptr()) };
         if res < 0 {
             Ok(IoctlReply::Done(Err(io::Error::last_os_error())))
         } else {
@@ -1633,6 +1677,228 @@ impl PassthroughFs {
     }
 }
 
+#[cfg(feature = "arc_quota")]
+impl PassthroughFs {
+    /// Convert u8 slice to string
+    fn string_from_u8_slice(&self, buf: &[u8]) -> io::Result<String> {
+        match CStr::from_bytes_until_nul(buf).map(|s| s.to_string_lossy().to_string()) {
+            Ok(s) => Ok(s),
+            Err(e) => {
+                error!("fail to convert u8 slice to string: {}", e);
+                Err(io::Error::from_raw_os_error(libc::EINVAL))
+            }
+        }
+    }
+
+    /// Set permission according to path
+    fn set_permission(&self, st: &mut libc::stat64, path: &str) {
+        for perm_data in self
+            .permission_paths
+            .read()
+            .expect("acquire permission_paths read lock")
+            .iter()
+        {
+            if perm_data.need_set_permission(path) {
+                st.st_uid = perm_data.guest_uid;
+                st.st_gid = perm_data.guest_gid;
+                st.st_mode = (st.st_mode & libc::S_IFMT) | (0o777 & !perm_data.umask);
+            }
+        }
+    }
+
+    /// Set host uid/gid to configured value according to path
+    fn change_creds(&self, ctx: &Context, parent_data: &InodeData, name: &CStr) -> (u32, u32) {
+        let path = format!(
+            "{}/{}",
+            parent_data.path.clone(),
+            name.to_str().unwrap_or("<non UTF-8 str>")
+        );
+
+        for perm_data in self
+            .permission_paths
+            .read()
+            .expect("acquire permission_paths read lock")
+            .iter()
+        {
+            if perm_data.need_set_permission(&path) {
+                return (perm_data.host_uid, perm_data.host_gid);
+            }
+        }
+
+        (ctx.uid, ctx.gid)
+    }
+
+    fn read_permission_data<R: io::Read>(&self, mut r: R) -> io::Result<PermissionData> {
+        let mut fs_permission_data = FsPermissionDataBuffer::new_zeroed();
+        r.read_exact(fs_permission_data.as_bytes_mut())?;
+
+        let perm_path = self.string_from_u8_slice(&fs_permission_data.perm_path)?;
+        if !perm_path.starts_with('/') {
+            error!("FS_IOC_SETPERMISSION: perm path must start with '/'");
+            return Err(io::Error::from_raw_os_error(libc::EINVAL));
+        }
+        Ok(PermissionData {
+            guest_uid: fs_permission_data.guest_uid,
+            guest_gid: fs_permission_data.guest_gid,
+            host_uid: fs_permission_data.host_uid,
+            host_gid: fs_permission_data.host_gid,
+            umask: fs_permission_data.umask,
+            perm_path,
+        })
+    }
+
+    /// Sets uid/gid/umask for all files and directories under a specific path.
+    ///
+    /// This ioctl does not correspond to any upstream FUSE feature. It is used for arcvm
+    /// It associates the specified path with the provide uid, gid, and umask values within the
+    /// filesystem metadata.
+    ///
+    /// During subsequent lookup operations, the stored uid/gid/umask values are retrieved and
+    /// applied to all files and directories found under the registered path. Before sending
+    /// file stat information to the client, the uid and gid are substituted by `guest_uid` and
+    /// `guest_gid` if the file falls under the registered path. The file mode is masked by the
+    ///  umask.
+    ///
+    /// When the guest creates a file within the specified path, the file gid/uid stat in host
+    /// will be overwritten to `host_uid` and `host_gid` values.
+    ///
+    /// This functionality enables dynamic configuration of ownership and permissions for a
+    /// specific directory hierarchy within the filesystem.
+    ///
+    /// # Notes
+    /// - This method affects all existing and future files under the registered path.
+    /// - The original file ownership and permissions are overridden by the provided values.
+    /// - The registered path should not be renamed
+    /// - Refer go/remove-mount-passthrough-fuse for more design details
+    fn set_permission_by_path<R: io::Read>(&self, r: R) -> IoctlReply {
+        if self
+            .permission_paths
+            .read()
+            .expect("acquire permission_paths read lock")
+            .len()
+            >= self.cfg.max_dynamic_perm
+        {
+            error!(
+                "FS_IOC_SETPERMISSION exceeds limits of max_dynamic_perm: {}",
+                self.cfg.max_dynamic_perm
+            );
+            return IoctlReply::Done(Err(io::Error::from_raw_os_error(libc::EPERM)));
+        }
+
+        let perm_data = match self.read_permission_data(r) {
+            Ok(data) => data,
+            Err(e) => {
+                error!("fail to read permission data: {}", e);
+                return IoctlReply::Done(Err(e));
+            }
+        };
+
+        self.permission_paths
+            .write()
+            .expect("acquire permission_paths write lock")
+            .push(perm_data);
+
+        IoctlReply::Done(Ok(Vec::new()))
+    }
+
+    // Get xattr value according to path and name
+    fn get_xattr_by_path(&self, path: &str, name: &str) -> Option<String> {
+        self.xattr_paths
+            .read()
+            .expect("acquire permission_paths read lock")
+            .iter()
+            .find(|data| data.need_set_guest_xattr(path, name))
+            .map(|data| data.xattr_value.clone())
+    }
+
+    fn skip_host_set_xattr(&self, path: &str, name: &str) -> bool {
+        self.get_xattr_by_path(path, name).is_some()
+    }
+
+    fn read_xattr_data<R: io::Read>(&self, mut r: R) -> io::Result<XattrData> {
+        let mut fs_path_xattr_data = FsPathXattrDataBuffer::new_zeroed();
+        r.read_exact(fs_path_xattr_data.as_bytes_mut())?;
+
+        let xattr_path = self.string_from_u8_slice(&fs_path_xattr_data.path)?;
+        if !xattr_path.starts_with('/') {
+            error!("FS_IOC_SETPATHXATTR: perm path must start with '/'");
+            return Err(io::Error::from_raw_os_error(libc::EINVAL));
+        }
+        let xattr_name = self.string_from_u8_slice(&fs_path_xattr_data.xattr_name)?;
+        let xattr_value = self.string_from_u8_slice(&fs_path_xattr_data.xattr_value)?;
+
+        Ok(XattrData {
+            xattr_path,
+            xattr_name,
+            xattr_value,
+        })
+    }
+
+    /// Sets xattr value for all files and directories under a specific path.
+    ///
+    /// This ioctl does not correspond to any upstream FUSE feature. It is used for arcvm.
+    /// It associates the specified path and xattr name with a value.
+    ///
+    /// When the getxattr is called for the specified path and name, the predefined
+    /// value is returned.
+    ///
+    /// # Notes
+    /// - This method affects all existing and future files under the registered path.
+    /// - The SECURITY_CONTEXT feature will be disabled if this ioctl is enabled.
+    /// - The registered path should not be renamed
+    /// - Refer go/remove-mount-passthrough-fuse for more design details
+    fn set_xattr_by_path<R: io::Read>(&self, r: R) -> IoctlReply {
+        if self
+            .xattr_paths
+            .read()
+            .expect("acquire xattr_paths read lock")
+            .len()
+            >= self.cfg.max_dynamic_xattr
+        {
+            error!(
+                "FS_IOC_SETPATHXATTR exceeds limits of max_dynamic_xattr: {}",
+                self.cfg.max_dynamic_xattr
+            );
+            return IoctlReply::Done(Err(io::Error::from_raw_os_error(libc::EPERM)));
+        }
+
+        let xattr_data = match self.read_xattr_data(r) {
+            Ok(data) => data,
+            Err(e) => {
+                error!("fail to read xattr data: {}", e);
+                return IoctlReply::Done(Err(e));
+            }
+        };
+
+        self.xattr_paths
+            .write()
+            .expect("acquire xattr_paths write lock")
+            .push(xattr_data);
+
+        IoctlReply::Done(Ok(Vec::new()))
+    }
+
+    fn do_getxattr_with_filter(
+        &self,
+        data: Arc<InodeData>,
+        name: Cow<CStr>,
+        buf: &mut [u8],
+    ) -> io::Result<usize> {
+        let res: usize = match self.get_xattr_by_path(&data.path, &name.to_string_lossy()) {
+            Some(predifined_xattr) => {
+                let x = predifined_xattr.into_bytes();
+                if x.len() > buf.len() {
+                    return Err(io::Error::from_raw_os_error(libc::ERANGE));
+                }
+                buf[..x.len()].copy_from_slice(&x);
+                x.len()
+            }
+            None => self.do_getxattr(&data, &name, &mut buf[..])?,
+        };
+        Ok(res)
+    }
+}
+
 /// Decrements the refcount of the inode.
 /// Returns `true` if the refcount became 0.
 fn forget_one(
@@ -1753,8 +2019,15 @@ impl FileSystem for PassthroughFs {
             | FsOptions::READDIRPLUS_AUTO
             | FsOptions::EXPORT_SUPPORT
             | FsOptions::DONT_MASK
-            | FsOptions::CACHE_SYMLINKS
-            | FsOptions::SECURITY_CONTEXT;
+            | FsOptions::CACHE_SYMLINKS;
+
+        // Device using dynamic xattr feature will have different security context in
+        // host and guests. The SECURITY_CONTEXT feature should not be enabled in the
+        // device.
+        if self.cfg.max_dynamic_xattr == 0 && self.cfg.security_ctx {
+            opts |= FsOptions::SECURITY_CONTEXT;
+        }
+
         if self.cfg.posix_acl {
             opts |= FsOptions::POSIX_ACL;
         }
@@ -1887,7 +2160,12 @@ impl FileSystem for PassthroughFs {
             .map(|ctx| ScopedSecurityContext::new(&self.proc, ctx))
             .transpose()?;
 
-        let (_uid, _gid) = set_creds(ctx.uid, ctx.gid)?;
+        #[cfg(feature = "arc_quota")]
+        let (uid, gid) = self.change_creds(&ctx, &data, name);
+        #[cfg(not(feature = "arc_quota"))]
+        let (uid, gid) = (ctx.uid, ctx.gid);
+
+        let (_uid, _gid) = set_creds(uid, gid)?;
         {
             let casefold_cache = self.lock_casefold_lookup_caches();
             let _scoped_umask = ScopedUmask::new(umask);
@@ -1994,13 +2272,17 @@ impl FileSystem for PassthroughFs {
             .map(|ctx| ScopedSecurityContext::new(&self.proc, ctx))
             .transpose()?;
 
-        let (_uid, _gid) = set_creds(ctx.uid, ctx.gid)?;
-
         let tmpflags = libc::O_RDWR | libc::O_TMPFILE | libc::O_CLOEXEC | libc::O_NOFOLLOW;
 
         // SAFETY: This string is nul-terminated and does not contain any interior nul bytes
         let current_dir = unsafe { CStr::from_bytes_with_nul_unchecked(b".\0") };
 
+        #[cfg(feature = "arc_quota")]
+        let (uid, gid) = self.change_creds(&ctx, &data, current_dir);
+        #[cfg(not(feature = "arc_quota"))]
+        let (uid, gid) = (ctx.uid, ctx.gid);
+        let (_uid, _gid) = set_creds(uid, gid)?;
+
         let fd = {
             let _scoped_umask = ScopedUmask::new(umask);
 
@@ -2018,7 +2300,6 @@ impl FileSystem for PassthroughFs {
 
         // SAFETY: safe because we just opened this fd.
         let tmpfile = unsafe { File::from_raw_descriptor(fd) };
-
         let st = stat(&tmpfile)?;
         let path = format!(
             "{}/{}",
@@ -2055,10 +2336,15 @@ impl FileSystem for PassthroughFs {
             .map(|ctx| ScopedSecurityContext::new(&self.proc, ctx))
             .transpose()?;
 
-        let (_uid, _gid) = set_creds(ctx.uid, ctx.gid)?;
+        #[cfg(feature = "arc_quota")]
+        let (uid, gid) = self.change_creds(&ctx, &data, name);
+        #[cfg(not(feature = "arc_quota"))]
+        let (uid, gid) = (ctx.uid, ctx.gid);
+        let (_uid, _gid) = set_creds(uid, gid)?;
 
+        let flags = self.update_open_flags(flags as i32);
         let create_flags =
-            (flags as i32 | libc::O_CREAT | libc::O_CLOEXEC | libc::O_NOFOLLOW) & !libc::O_DIRECT;
+            (flags | libc::O_CREAT | libc::O_CLOEXEC | libc::O_NOFOLLOW) & !libc::O_DIRECT;
 
         let fd = {
             let _scoped_umask = ScopedUmask::new(umask);
@@ -2096,7 +2382,7 @@ impl FileSystem for PassthroughFs {
                 data,
                 name,
                 entry.inode,
-                flags & !((libc::O_CREAT | libc::O_EXCL | libc::O_NOCTTY) as u32),
+                flags as u32 & !((libc::O_CREAT | libc::O_EXCL | libc::O_NOCTTY) as u32),
             )
             .map_err(|e| {
                 // Don't leak the entry.
@@ -2241,17 +2527,16 @@ impl FileSystem for PassthroughFs {
         let _trace = fs_trace!(self.tag, "setattr", inode, handle);
         let inode_data = self.find_inode(inode)?;
 
-        enum Data {
-            Handle(Arc<HandleData>, RawDescriptor),
+        enum Data<'a> {
+            Handle(MutexGuard<'a, File>),
             ProcPath(CString),
         }
 
         // If we have a handle then use it otherwise get a new fd from the inode.
+        let hd;
         let data = if let Some(handle) = handle.filter(|&h| h != 0) {
-            let hd = self.find_handle(handle, inode)?;
-
-            let fd = hd.file.lock().as_raw_descriptor();
-            Data::Handle(hd, fd)
+            hd = self.find_handle(handle, inode)?;
+            Data::Handle(hd.file.lock())
         } else {
             let pathname = CString::new(format!("self/fd/{}", inode_data.as_raw_descriptor()))
                 .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))?;
@@ -2262,7 +2547,7 @@ impl FileSystem for PassthroughFs {
             // SAFETY: this doesn't modify any memory and we check the return value.
             syscall!(unsafe {
                 match data {
-                    Data::Handle(_, fd) => libc::fchmod(fd, attr.st_mode),
+                    Data::Handle(ref fd) => libc::fchmod(fd.as_raw_descriptor(), attr.st_mode),
                     Data::ProcPath(ref p) => {
                         libc::fchmodat(self.proc.as_raw_descriptor(), p.as_ptr(), attr.st_mode, 0)
                     }
@@ -2275,13 +2560,13 @@ impl FileSystem for PassthroughFs {
                 attr.st_uid
             } else {
                 // Cannot use -1 here because these are unsigned values.
-                ::std::u32::MAX
+                u32::MAX
             };
             let gid = if valid.contains(SetattrValid::GID) {
                 attr.st_gid
             } else {
                 // Cannot use -1 here because these are unsigned values.
-                ::std::u32::MAX
+                u32::MAX
             };
 
             // SAFETY: this is a constant value that is a nul-terminated string without interior
@@ -2302,9 +2587,9 @@ impl FileSystem for PassthroughFs {
 
         if valid.contains(SetattrValid::SIZE) {
             syscall!(match data {
-                Data::Handle(_, fd) => {
+                Data::Handle(ref fd) => {
                     // SAFETY: this doesn't modify any memory and we check the return value.
-                    unsafe { libc::ftruncate64(fd, attr.st_size) }
+                    unsafe { libc::ftruncate64(fd.as_raw_descriptor(), attr.st_size) }
                 }
                 _ => {
                     // There is no `ftruncateat` so we need to get a new fd and truncate it.
@@ -2344,7 +2629,7 @@ impl FileSystem for PassthroughFs {
             // SAFETY: this doesn't modify any memory and we check the return value.
             syscall!(unsafe {
                 match data {
-                    Data::Handle(_, fd) => libc::futimens(fd, tvs.as_ptr()),
+                    Data::Handle(ref fd) => libc::futimens(fd.as_raw_descriptor(), tvs.as_ptr()),
                     Data::ProcPath(ref p) => {
                         libc::utimensat(self.proc.as_raw_descriptor(), p.as_ptr(), tvs.as_ptr(), 0)
                     }
@@ -2420,7 +2705,11 @@ impl FileSystem for PassthroughFs {
             .map(|ctx| ScopedSecurityContext::new(&self.proc, ctx))
             .transpose()?;
 
-        let (_uid, _gid) = set_creds(ctx.uid, ctx.gid)?;
+        #[cfg(feature = "arc_quota")]
+        let (uid, gid) = self.change_creds(&ctx, &data, name);
+        #[cfg(not(feature = "arc_quota"))]
+        let (uid, gid) = (ctx.uid, ctx.gid);
+        let (_uid, _gid) = set_creds(uid, gid)?;
         {
             let _scoped_umask = ScopedUmask::new(umask);
             let casefold_cache = self.lock_casefold_lookup_caches();
@@ -2492,7 +2781,11 @@ impl FileSystem for PassthroughFs {
             .map(|ctx| ScopedSecurityContext::new(&self.proc, ctx))
             .transpose()?;
 
-        let (_uid, _gid) = set_creds(ctx.uid, ctx.gid)?;
+        #[cfg(feature = "arc_quota")]
+        let (uid, gid) = self.change_creds(&ctx, &data, name);
+        #[cfg(not(feature = "arc_quota"))]
+        let (uid, gid) = (ctx.uid, ctx.gid);
+        let (_uid, _gid) = set_creds(uid, gid)?;
         {
             let casefold_cache = self.lock_casefold_lookup_caches();
             // SAFETY: this doesn't modify any memory and we check the return value.
@@ -2659,6 +2952,17 @@ impl FileSystem for PassthroughFs {
 
         let data = self.find_inode(inode)?;
         let name = self.rewrite_xattr_name(name);
+
+        #[cfg(feature = "arc_quota")]
+        if self.skip_host_set_xattr(&data.path, &name.to_string_lossy()) {
+            debug!(
+                "ignore setxattr for path:{} xattr_name:{}",
+                &data.path,
+                &name.to_string_lossy()
+            );
+            return Ok(());
+        }
+
         let file = data.file.lock();
         let o_path_file = (file.1 & libc::O_PATH) != 0;
         if o_path_file {
@@ -2717,8 +3021,12 @@ impl FileSystem for PassthroughFs {
         let name = self.rewrite_xattr_name(name);
         let mut buf = vec![0u8; size as usize];
 
-        // SAFETY: this will only modify the contents of `buf`.
+        #[cfg(feature = "arc_quota")]
+        let res = self.do_getxattr_with_filter(data, name, &mut buf)?;
+
+        #[cfg(not(feature = "arc_quota"))]
         let res = self.do_getxattr(&data, &name, &mut buf[..])?;
+
         if size == 0 {
             Ok(GetxattrReply::Count(res as u32))
         } else {
@@ -2874,54 +3182,44 @@ impl FileSystem for PassthroughFs {
     ) -> io::Result<IoctlReply> {
         let _trace = fs_trace!(self.tag, "ioctl", inode, handle, cmd, in_size, out_size);
 
-        const GET_ENCRYPTION_POLICY_EX: u32 = FS_IOC_GET_ENCRYPTION_POLICY_EX() as u32;
-        const GET_FSXATTR: u32 = FS_IOC_FSGETXATTR() as u32;
-        const SET_FSXATTR: u32 = FS_IOC_FSSETXATTR() as u32;
-        const GET_FLAGS32: u32 = FS_IOC32_GETFLAGS() as u32;
-        const SET_FLAGS32: u32 = FS_IOC32_SETFLAGS() as u32;
-        const GET_FLAGS64: u32 = FS_IOC64_GETFLAGS() as u32;
-        const SET_FLAGS64: u32 = FS_IOC64_SETFLAGS() as u32;
-        const ENABLE_VERITY: u32 = FS_IOC_ENABLE_VERITY() as u32;
-        const MEASURE_VERITY: u32 = FS_IOC_MEASURE_VERITY() as u32;
-
-        match cmd {
-            GET_ENCRYPTION_POLICY_EX => self.get_encryption_policy_ex(inode, handle, r),
-            GET_FSXATTR => {
+        match cmd as IoctlNr {
+            FS_IOC_GET_ENCRYPTION_POLICY_EX => self.get_encryption_policy_ex(inode, handle, r),
+            FS_IOC_FSGETXATTR => {
                 if out_size < size_of::<fsxattr>() as u32 {
                     Err(io::Error::from_raw_os_error(libc::ENOMEM))
                 } else {
                     self.get_fsxattr(inode, handle)
                 }
             }
-            SET_FSXATTR => {
+            FS_IOC_FSSETXATTR => {
                 if in_size < size_of::<fsxattr>() as u32 {
                     Err(io::Error::from_raw_os_error(libc::EINVAL))
                 } else {
                     self.set_fsxattr(ctx, inode, handle, r)
                 }
             }
-            GET_FLAGS32 | GET_FLAGS64 => {
+            FS_IOC32_GETFLAGS | FS_IOC64_GETFLAGS => {
                 if out_size < size_of::<c_int>() as u32 {
                     Err(io::Error::from_raw_os_error(libc::ENOMEM))
                 } else {
                     self.get_flags(inode, handle)
                 }
             }
-            SET_FLAGS32 | SET_FLAGS64 => {
+            FS_IOC32_SETFLAGS | FS_IOC64_SETFLAGS => {
                 if in_size < size_of::<c_int>() as u32 {
                     Err(io::Error::from_raw_os_error(libc::ENOMEM))
                 } else {
                     self.set_flags(ctx, inode, handle, r)
                 }
             }
-            ENABLE_VERITY => {
+            FS_IOC_ENABLE_VERITY => {
                 if in_size < size_of::<fsverity_enable_arg>() as u32 {
                     Err(io::Error::from_raw_os_error(libc::ENOMEM))
                 } else {
                     self.enable_verity(inode, handle, r)
                 }
             }
-            MEASURE_VERITY => {
+            FS_IOC_MEASURE_VERITY => {
                 if in_size < size_of::<fsverity_digest>() as u32
                     || out_size < size_of::<fsverity_digest>() as u32
                 {
@@ -2930,6 +3228,24 @@ impl FileSystem for PassthroughFs {
                     self.measure_verity(inode, handle, r, out_size)
                 }
             }
+            // The following is ARCVM-specific ioctl
+            // Refer go/remove-mount-passthrough-fuse for more design details
+            #[cfg(feature = "arc_quota")]
+            FS_IOC_SETPERMISSION => {
+                if in_size != size_of::<FsPermissionDataBuffer>() as u32 {
+                    Err(io::Error::from_raw_os_error(libc::EINVAL))
+                } else {
+                    Ok(self.set_permission_by_path(r))
+                }
+            }
+            #[cfg(feature = "arc_quota")]
+            FS_IOC_SETPATHXATTR => {
+                if in_size != size_of::<FsPathXattrDataBuffer>() as u32 {
+                    Err(io::Error::from_raw_os_error(libc::EINVAL))
+                } else {
+                    Ok(self.set_xattr_by_path(r))
+                }
+            }
             _ => Err(io::Error::from_raw_os_error(libc::ENOTTY)),
         }
     }
@@ -3088,11 +3404,15 @@ impl FileSystem for PassthroughFs {
             umask,
             security_ctx
         );
-        let (_uid, _gid) = set_creds(ctx.uid, ctx.gid)?;
-
         // Perform lookup but not create negative dentry
         let data = self.find_inode(parent)?;
 
+        #[cfg(feature = "arc_quota")]
+        let (uid, gid) = self.change_creds(&ctx, &data, name);
+        #[cfg(not(feature = "arc_quota"))]
+        let (uid, gid) = (ctx.uid, ctx.gid);
+        let (_uid, _gid) = set_creds(uid, gid)?;
+
         // This lookup serves two purposes:
         // 1. If the O_CREATE flag is not set, it retrieves the d_entry for the file.
         // 2. If the O_CREATE flag is set, it checks whether the file exists.
@@ -3147,6 +3467,12 @@ mod tests {
     use tempfile::TempDir;
 
     use super::*;
+    #[cfg(feature = "arc_quota")]
+    use crate::virtio::fs::arc_ioctl::FS_IOCTL_PATH_MAX_LEN;
+    #[cfg(feature = "arc_quota")]
+    use crate::virtio::fs::arc_ioctl::FS_IOCTL_XATTR_NAME_MAX_LEN;
+    #[cfg(feature = "arc_quota")]
+    use crate::virtio::fs::arc_ioctl::FS_IOCTL_XATTR_VALUE_MAX_LEN;
 
     const UNITTEST_LOCK_NAME: &str = "passthroughfs_unittest_lock";
 
@@ -3193,6 +3519,25 @@ mod tests {
         Ok(inode)
     }
 
+    /// Looks up the given `path` in `fs`.
+    #[cfg(feature = "arc_quota")]
+    fn lookup_ent(fs: &PassthroughFs, path: &Path) -> io::Result<Entry> {
+        let mut inode = 1;
+        let ctx = get_context();
+        let mut entry = Entry::new_negative(Duration::from_secs(10));
+        for name in path.iter() {
+            let name = CString::new(name.to_str().unwrap()).unwrap();
+            entry = match fs.lookup(ctx, inode, &name) {
+                Ok(ent) => ent,
+                Err(e) => {
+                    return Err(e);
+                }
+            };
+            inode = entry.inode;
+        }
+        Ok(entry)
+    }
+
     /// Creates a file at the given `path`.
     fn create(fs: &PassthroughFs, path: &Path) -> io::Result<Entry> {
         let parent = path.parent().unwrap();
@@ -3271,6 +3616,48 @@ mod tests {
         fs.symlink(ctx, &linkname, inode, &name, security_ctx)
     }
 
+    // In this ioctl inode,handle,flags,arg and out_size is irrelavant, set to empty value.
+    #[cfg(feature = "arc_quota")]
+    fn fs_ioc_setpermission<R: io::Read>(
+        fs: &PassthroughFs,
+        in_size: u32,
+        r: R,
+    ) -> io::Result<IoctlReply> {
+        let ctx = get_context();
+        fs.ioctl(
+            ctx,
+            0,
+            0,
+            IoctlFlags::empty(),
+            FS_IOC_SETPERMISSION as u32,
+            0,
+            in_size,
+            0,
+            r,
+        )
+    }
+
+    // In this ioctl inode,handle,flags,arg and out_size is irrelavant, set to empty value.
+    #[cfg(feature = "arc_quota")]
+    fn fs_ioc_setpathxattr<R: io::Read>(
+        fs: &PassthroughFs,
+        in_size: u32,
+        r: R,
+    ) -> io::Result<IoctlReply> {
+        let ctx = get_context();
+        fs.ioctl(
+            ctx,
+            0,
+            0,
+            IoctlFlags::empty(),
+            FS_IOC_SETPATHXATTR as u32,
+            0,
+            in_size,
+            0,
+            r,
+        )
+    }
+
     #[test]
     fn rewrite_xattr_names() {
         // Since PassthroughFs may executes process-wide operations such as `fchdir`, acquire
@@ -3883,4 +4270,453 @@ mod tests {
         assert!(handler.is_none());
         assert_eq!(open_options, OpenOptions::empty());
     }
+
+    #[test]
+    #[cfg(feature = "arc_quota")]
+    fn set_permission_ioctl_valid_data() {
+        // Since PassthroughFs may executes process-wide operations such as `fchdir`, acquire
+        // `NamedLock` before starting each unit test creating a `PassthroughFs` instance.
+        let lock = NamedLock::create(UNITTEST_LOCK_NAME).expect("create named lock");
+        let _guard = lock.lock().expect("acquire named lock");
+
+        let cfg = Config {
+            max_dynamic_perm: 1,
+            ..Default::default()
+        };
+        let p = PassthroughFs::new("tag", cfg).expect("Failed to create PassthroughFs");
+
+        let perm_path_string = String::from("/test");
+        let fs_permission_data_buffer = FsPermissionDataBuffer {
+            guest_uid: 1,
+            guest_gid: 2,
+            host_uid: 3,
+            host_gid: 4,
+            umask: 5,
+            pad: 0,
+            perm_path: {
+                let mut perm_path: [u8; FS_IOCTL_PATH_MAX_LEN] = [0; FS_IOCTL_PATH_MAX_LEN];
+                perm_path[..perm_path_string.len()].copy_from_slice(perm_path_string.as_bytes());
+                perm_path
+            },
+        };
+        let r = std::io::Cursor::new(fs_permission_data_buffer.as_bytes());
+
+        let res = fs_ioc_setpermission(
+            &p,
+            mem::size_of_val(&fs_permission_data_buffer) as u32,
+            r.clone(),
+        )
+        .expect("valid input should get IoctlReply");
+        assert!(matches!(res, IoctlReply::Done(Ok(data)) if data.is_empty()));
+
+        let read_guard = p
+            .permission_paths
+            .read()
+            .expect("read permission_paths failed");
+        let permission_data = read_guard
+            .first()
+            .expect("permission path should not be empty");
+
+        // Check expected data item is added to permission_paths.
+        let expected_data = PermissionData {
+            guest_uid: 1,
+            guest_gid: 2,
+            host_uid: 3,
+            host_gid: 4,
+            umask: 5,
+            perm_path: perm_path_string,
+        };
+        assert_eq!(*permission_data, expected_data);
+
+        // Second ioctl should not succeed since max_dynamic_perm is set to 1
+        let res = fs_ioc_setpermission(
+            &p,
+            mem::size_of_val(&fs_permission_data_buffer) as u32,
+            r.clone(),
+        )
+        .expect("valid input should get IoctlReply");
+        assert!(
+            matches!(res, IoctlReply::Done(Err(err)) if err.raw_os_error().is_some_and(|errno| {
+                errno == libc::EPERM
+            }))
+        );
+    }
+
+    #[test]
+    #[cfg(feature = "arc_quota")]
+    fn set_permission_ioctl_invalid_data() {
+        // Since PassthroughFs may executes process-wide operations such as `fchdir`, acquire
+        // `NamedLock` before starting each unit test creating a `PassthroughFs` instance.
+        let lock = NamedLock::create(UNITTEST_LOCK_NAME).expect("create named lock");
+        let _guard = lock.lock().expect("acquire named lock");
+
+        let cfg = Config {
+            max_dynamic_perm: 1,
+            ..Default::default()
+        };
+        let p = PassthroughFs::new("tag", cfg).expect("Failed to create PassthroughFs");
+
+        // The perm_path is not valid since it does not start with /.
+        let perm_path_string = String::from("test");
+        let fs_permission_data_buffer = FsPermissionDataBuffer {
+            guest_uid: 1,
+            guest_gid: 2,
+            host_uid: 3,
+            host_gid: 4,
+            umask: 5,
+            pad: 0,
+            perm_path: {
+                let mut perm_path: [u8; FS_IOCTL_PATH_MAX_LEN] = [0; FS_IOCTL_PATH_MAX_LEN];
+                perm_path[..perm_path_string.len()].copy_from_slice(perm_path_string.as_bytes());
+                perm_path
+            },
+        };
+
+        let r = std::io::Cursor::new(fs_permission_data_buffer.as_bytes());
+        // In this ioctl inode,handle,flags,arg and out_size is irrelavant, set to empty value.
+        // This call is supposed to get EINVAL ioctlReply, since the perm_path is invalid.
+        let res = fs_ioc_setpermission(&p, mem::size_of_val(&fs_permission_data_buffer) as u32, r)
+            .expect("invalid perm_path should get IoctlReply");
+        assert!(
+            matches!(res, IoctlReply::Done(Err(err)) if err.raw_os_error().is_some_and(|errno| {
+                errno == libc::EINVAL
+            }))
+        );
+
+        let fake_data_buffer: [u8; 128] = [0; 128];
+        let r = std::io::Cursor::new(fake_data_buffer.as_bytes());
+
+        // This call is supposed to get EINVAL ioctlReply, since the in_size is not the size of
+        // struct FsPermissionDataBuffer.
+        let res = fs_ioc_setpermission(&p, mem::size_of_val(&fake_data_buffer) as u32, r)
+            .expect_err("invalid in_size should get Error");
+        assert!(res
+            .raw_os_error()
+            .is_some_and(|errno| { errno == libc::EINVAL }));
+    }
+
+    #[test]
+    #[cfg(feature = "arc_quota")]
+    fn permission_data_path_matching() {
+        let ctx = get_context();
+        let temp_dir = TempDir::new().unwrap();
+        // Prepare `a.txt` before starting the test.
+        create_test_data(&temp_dir, &["dir"], &["a.txt", "dir/a.txt"]);
+
+        let cfg = Config {
+            max_dynamic_perm: 1,
+            ..Default::default()
+        };
+        let fs = PassthroughFs::new("tag", cfg).unwrap();
+
+        let capable = FsOptions::empty();
+        fs.init(capable).unwrap();
+
+        const BY_PATH_UID: u32 = 655360;
+        const BY_PATH_GID: u32 = 655361;
+        const BY_PATH_UMASK: u32 = 0o007;
+
+        let dir_path = temp_dir.path().join("dir");
+        let permission_data = PermissionData {
+            guest_uid: BY_PATH_UID,
+            guest_gid: BY_PATH_GID,
+            host_uid: ctx.uid,
+            host_gid: ctx.gid,
+            umask: BY_PATH_UMASK,
+            perm_path: dir_path.to_string_lossy().into_owned(),
+        };
+        fs.permission_paths
+            .write()
+            .expect("permission_path lock must be acquired")
+            .push(permission_data);
+
+        // a_path is the path with out set permission by path
+        let a_path = temp_dir.path().join("a.txt");
+        let in_dir_a_path = dir_path.join("a.txt");
+
+        // a.txt should not be set with guest_uid/guest_uid/umask by path
+        let a_entry = lookup_ent(&fs, &a_path).expect("a.txt must exist");
+        assert_ne!(a_entry.attr.st_uid, BY_PATH_UID);
+        assert_ne!(a_entry.attr.st_gid, BY_PATH_GID);
+
+        // a.txt in dir should be set guest_uid/guest_uid/umask by path
+        let in_dir_a_entry = lookup_ent(&fs, &in_dir_a_path).expect("dir/a.txt must exist");
+        assert_eq!(in_dir_a_entry.attr.st_uid, BY_PATH_UID);
+        assert_eq!(in_dir_a_entry.attr.st_gid, BY_PATH_GID);
+        assert_eq!(in_dir_a_entry.attr.st_mode & 0o777, !BY_PATH_UMASK & 0o777);
+
+        // Create dir/b.txt.
+        let in_dir_b_path = dir_path.join("b.txt");
+        create(&fs, &in_dir_b_path).expect("create b.txt");
+
+        // newly created b.txt in dir should be set guest_uid/guest_uid/umask by path
+        let in_dir_b_entry = lookup_ent(&fs, &in_dir_a_path).expect("dir/b.txt must exist");
+        assert_eq!(in_dir_b_entry.attr.st_uid, BY_PATH_UID);
+        assert_eq!(in_dir_b_entry.attr.st_gid, BY_PATH_GID);
+        assert_eq!(in_dir_b_entry.attr.st_mode & 0o777, !BY_PATH_UMASK & 0o777);
+    }
+
+    #[test]
+    #[cfg(feature = "arc_quota")]
+    fn set_path_xattr_ioctl_valid_data() {
+        // Since PassthroughFs may executes process-wide operations such as `fchdir`, acquire
+        // `NamedLock` before starting each unit test creating a `PassthroughFs` instance.
+        let lock = NamedLock::create(UNITTEST_LOCK_NAME).expect("create named lock");
+        let _guard = lock.lock().expect("acquire named lock");
+
+        let cfg: Config = Config {
+            max_dynamic_xattr: 1,
+            ..Default::default()
+        };
+        let p = PassthroughFs::new("tag", cfg).expect("Failed to create PassthroughFs");
+
+        let path_string = String::from("/test");
+        let xattr_name_string = String::from("test_name");
+        let xattr_value_string = String::from("test_value");
+        let fs_path_xattr_data_buffer = FsPathXattrDataBuffer {
+            path: {
+                let mut path: [u8; FS_IOCTL_PATH_MAX_LEN] = [0; FS_IOCTL_PATH_MAX_LEN];
+                path[..path_string.len()].copy_from_slice(path_string.as_bytes());
+                path
+            },
+            xattr_name: {
+                let mut xattr_name: [u8; FS_IOCTL_XATTR_NAME_MAX_LEN] =
+                    [0; FS_IOCTL_XATTR_NAME_MAX_LEN];
+                xattr_name[..xattr_name_string.len()].copy_from_slice(xattr_name_string.as_bytes());
+                xattr_name
+            },
+            xattr_value: {
+                let mut xattr_value: [u8; FS_IOCTL_XATTR_VALUE_MAX_LEN] =
+                    [0; FS_IOCTL_XATTR_VALUE_MAX_LEN];
+                xattr_value[..xattr_value_string.len()]
+                    .copy_from_slice(xattr_value_string.as_bytes());
+                xattr_value
+            },
+        };
+        let r = std::io::Cursor::new(fs_path_xattr_data_buffer.as_bytes());
+
+        let res = fs_ioc_setpathxattr(
+            &p,
+            mem::size_of_val(&fs_path_xattr_data_buffer) as u32,
+            r.clone(),
+        )
+        .expect("valid input should get IoctlReply");
+        assert!(matches!(res, IoctlReply::Done(Ok(data)) if data.is_empty()));
+
+        let read_guard = p.xattr_paths.read().expect("read xattr_paths failed");
+        let xattr_data = read_guard.first().expect("xattr_paths should not be empty");
+
+        // Check expected data item is added to permission_paths.
+        let expected_data = XattrData {
+            xattr_path: path_string,
+            xattr_name: xattr_name_string,
+            xattr_value: xattr_value_string,
+        };
+        assert_eq!(*xattr_data, expected_data);
+
+        // Second ioctl should not succeed since max_dynamic_perm is set to 1
+        let res = fs_ioc_setpathxattr(
+            &p,
+            mem::size_of_val(&fs_path_xattr_data_buffer) as u32,
+            r.clone(),
+        )
+        .expect("valid input should get IoctlReply");
+        assert!(
+            matches!(res, IoctlReply::Done(Err(err)) if err.raw_os_error().is_some_and(|errno| {
+                errno == libc::EPERM
+            }))
+        );
+    }
+    #[test]
+    #[cfg(feature = "arc_quota")]
+    fn set_path_xattr_ioctl_invalid_data() {
+        // Since PassthroughFs may executes process-wide operations such as `fchdir`, acquire
+        // `NamedLock` before starting each unit test creating a `PassthroughFs` instance.
+        let lock = NamedLock::create(UNITTEST_LOCK_NAME).expect("create named lock");
+        let _guard = lock.lock().expect("acquire named lock");
+
+        let cfg: Config = Config {
+            max_dynamic_xattr: 1,
+            ..Default::default()
+        };
+        let p = PassthroughFs::new("tag", cfg).expect("Failed to create PassthroughFs");
+
+        let path_string = String::from("test");
+        let xattr_name_string = String::from("test_name");
+        let xattr_value_string = String::from("test_value");
+        let fs_path_xattr_data_buffer = FsPathXattrDataBuffer {
+            path: {
+                let mut path: [u8; FS_IOCTL_PATH_MAX_LEN] = [0; FS_IOCTL_PATH_MAX_LEN];
+                path[..path_string.len()].copy_from_slice(path_string.as_bytes());
+                path
+            },
+            xattr_name: {
+                let mut xattr_name: [u8; FS_IOCTL_XATTR_NAME_MAX_LEN] =
+                    [0; FS_IOCTL_XATTR_NAME_MAX_LEN];
+                xattr_name[..xattr_name_string.len()].copy_from_slice(xattr_name_string.as_bytes());
+                xattr_name
+            },
+            xattr_value: {
+                let mut xattr_value: [u8; FS_IOCTL_XATTR_VALUE_MAX_LEN] =
+                    [0; FS_IOCTL_XATTR_VALUE_MAX_LEN];
+                xattr_value[..xattr_value_string.len()]
+                    .copy_from_slice(xattr_value_string.as_bytes());
+                xattr_value
+            },
+        };
+        let r = std::io::Cursor::new(fs_path_xattr_data_buffer.as_bytes());
+
+        // This call is supposed to get EINVAL ioctlReply, since the perm_path is invalid.
+        let res = fs_ioc_setpathxattr(
+            &p,
+            mem::size_of_val(&fs_path_xattr_data_buffer) as u32,
+            r.clone(),
+        )
+        .expect("valid input should get IoctlReply");
+        assert!(
+            matches!(res, IoctlReply::Done(Err(err)) if err.raw_os_error().is_some_and(|errno| {
+                errno == libc::EINVAL
+            }))
+        );
+
+        let fake_data_buffer: [u8; 128] = [0; 128];
+        let r = std::io::Cursor::new(fake_data_buffer.as_bytes());
+        // This call is supposed to get EINVAL ioctlReply, since the in_size is not the size of
+        // struct FsPathXattrDataBuffer.
+        let res = fs_ioc_setpathxattr(&p, mem::size_of_val(&fake_data_buffer) as u32, r.clone())
+            .expect_err("valid input should get IoctlReply");
+        assert!(res
+            .raw_os_error()
+            .is_some_and(|errno| { errno == libc::EINVAL }));
+    }
+
+    #[test]
+    #[cfg(feature = "arc_quota")]
+    fn xattr_data_path_matching() {
+        let ctx = get_context();
+        let temp_dir = TempDir::new().unwrap();
+        // Prepare `a.txt` before starting the test.
+        create_test_data(&temp_dir, &["dir"], &["a.txt", "dir/a.txt"]);
+
+        let cfg = Config {
+            max_dynamic_xattr: 1,
+            ..Default::default()
+        };
+        let fs = PassthroughFs::new("tag", cfg).unwrap();
+
+        let capable = FsOptions::empty();
+        fs.init(capable).unwrap();
+
+        let dir_path = temp_dir.path().join("dir");
+        let xattr_name_string = String::from("test_name");
+        let xattr_name_cstring = CString::new(xattr_name_string.clone()).expect("create c string");
+        let xattr_value_string = String::from("test_value");
+        let xattr_value_bytes = xattr_value_string.clone().into_bytes();
+
+        let xattr_data = XattrData {
+            xattr_name: xattr_name_string,
+            xattr_value: xattr_value_string,
+            xattr_path: dir_path.to_string_lossy().into_owned(),
+        };
+        fs.xattr_paths
+            .write()
+            .expect("xattr_paths lock must be acquired")
+            .push(xattr_data);
+
+        // a_path is the path with out set xattr by path
+        let a_path: std::path::PathBuf = temp_dir.path().join("a.txt");
+        let in_dir_a_path = dir_path.join("a.txt");
+
+        let a_node = lookup(&fs, a_path.as_path()).expect("lookup a node");
+        // a.txt should not be set with xattr by path
+        assert!(fs
+            .getxattr(
+                ctx,
+                a_node,
+                &xattr_name_cstring,
+                xattr_value_bytes.len() as u32
+            )
+            .is_err());
+
+        let in_dir_a_node = lookup(&fs, in_dir_a_path.as_path()).expect("lookup in dir a node");
+        // a.txt in dir should be set xattr by path
+        let in_dir_a_reply = fs
+            .getxattr(
+                ctx,
+                in_dir_a_node,
+                &xattr_name_cstring,
+                xattr_value_bytes.len() as u32,
+            )
+            .expect("Getxattr should success");
+        assert!(matches!(in_dir_a_reply, GetxattrReply::Value(v) if v == xattr_value_bytes));
+        // Create dir/b.txt.
+        let in_dir_b_path = dir_path.join("b.txt");
+        create(&fs, &in_dir_b_path).expect("create b.txt");
+
+        // newly created b.txt in dir should be set xattr by path
+        let in_dir_b_node = lookup(&fs, in_dir_a_path.as_path()).expect("lookup in dir b node");
+        let in_dir_b_reply = fs
+            .getxattr(
+                ctx,
+                in_dir_b_node,
+                &xattr_name_cstring,
+                xattr_value_bytes.len() as u32,
+            )
+            .expect("Getxattr should success");
+        assert!(matches!(in_dir_b_reply, GetxattrReply::Value(v) if v == xattr_value_bytes));
+    }
+
+    /// Creates and open a new file by atomic_open with O_APPEND flag.
+    /// We check O_APPEND is properly handled, depending on writeback cache is enabled or not.
+    fn atomic_open_create_o_append(writeback: bool) {
+        // Since PassthroughFs may executes process-wide operations such as `fchdir`, acquire
+        // `NamedLock` before starting each unit test creating a `PassthroughFs` instance.
+        let lock = NamedLock::create(UNITTEST_LOCK_NAME).expect("create named lock");
+        let _guard = lock.lock().expect("acquire named lock");
+
+        let temp_dir = TempDir::new().unwrap();
+
+        let cfg = Config {
+            cache_policy: CachePolicy::Always,
+            writeback,
+            ..Default::default()
+        };
+        let fs = PassthroughFs::new("tag", cfg).unwrap();
+
+        let capable = FsOptions::ZERO_MESSAGE_OPEN | FsOptions::WRITEBACK_CACHE;
+        fs.init(capable).unwrap();
+
+        let (entry, _, _) = atomic_open(
+            &fs,
+            &temp_dir.path().join("a.txt"),
+            0o666,
+            (libc::O_RDWR | libc::O_CREAT | libc::O_APPEND) as u32,
+            0,
+            None,
+        )
+        .expect("atomic_open");
+        assert_ne!(entry.inode, 0);
+
+        let inodes = fs.inodes.lock();
+        let data = inodes.get(&entry.inode).unwrap();
+        let flags = data.file.lock().1;
+        if writeback {
+            // When writeback is enabled, O_APPEND must be handled by the guest kernel.
+            // So, it must be cleared.
+            assert_eq!(flags & libc::O_APPEND, 0);
+        } else {
+            // Without writeback cache, O_APPEND must not be cleared.
+            assert_eq!(flags & libc::O_APPEND, libc::O_APPEND);
+        }
+    }
+
+    #[test]
+    fn test_atomic_open_create_o_append_no_writeback() {
+        atomic_open_create_o_append(false);
+    }
+
+    #[test]
+    fn test_atomic_open_create_o_append_writeback() {
+        atomic_open_create_o_append(true);
+    }
 }
diff --git a/devices/src/virtio/fs/worker.rs b/devices/src/virtio/fs/worker.rs
index 2f4afbc01..aa3c7b07f 100644
--- a/devices/src/virtio/fs/worker.rs
+++ b/devices/src/virtio/fs/worker.rs
@@ -147,7 +147,6 @@ pub struct Worker<F: FileSystem + Sync> {
 }
 
 pub fn process_fs_queue<F: FileSystem + Sync>(
-    interrupt: &Interrupt,
     queue: &mut Queue,
     server: &Arc<fuse::Server<F>>,
     tube: &Arc<Mutex<Tube>>,
@@ -159,7 +158,7 @@ pub fn process_fs_queue<F: FileSystem + Sync>(
             server.handle_message(&mut avail_desc.reader, &mut avail_desc.writer, &mapper)?;
 
         queue.add_used(avail_desc, total as u32);
-        queue.trigger_interrupt(interrupt);
+        queue.trigger_interrupt();
     }
 
     Ok(())
@@ -252,13 +251,9 @@ impl<F: FileSystem + Sync> Worker<F> {
                 match event.token {
                     Token::QueueReady => {
                         self.queue.event().wait().map_err(Error::ReadQueueEvent)?;
-                        if let Err(e) = process_fs_queue(
-                            &self.irq,
-                            &mut self.queue,
-                            &self.server,
-                            &self.tube,
-                            self.slot,
-                        ) {
+                        if let Err(e) =
+                            process_fs_queue(&mut self.queue, &self.server, &self.tube, self.slot)
+                        {
                             error!("virtio-fs transport error: {}", e);
                             return Err(e);
                         }
diff --git a/devices/src/virtio/gpu/mod.rs b/devices/src/virtio/gpu/mod.rs
index c26bc0a67..4d5229e54 100644
--- a/devices/src/virtio/gpu/mod.rs
+++ b/devices/src/virtio/gpu/mod.rs
@@ -18,6 +18,7 @@ use std::sync::mpsc;
 use std::sync::Arc;
 
 use anyhow::anyhow;
+use anyhow::bail;
 use anyhow::Context;
 use base::debug;
 use base::error;
@@ -41,6 +42,8 @@ use base::WorkerThread;
 use data_model::*;
 pub use gpu_display::EventDevice;
 use gpu_display::*;
+use hypervisor::MemCacheType;
+pub use parameters::AudioDeviceMode;
 pub use parameters::GpuParameters;
 use rutabaga_gfx::*;
 use serde::Deserialize;
@@ -83,6 +86,7 @@ use super::Interrupt;
 use super::Queue;
 use super::Reader;
 use super::SharedMemoryMapper;
+use super::SharedMemoryPrepareType;
 use super::SharedMemoryRegion;
 use super::VirtioDevice;
 use super::Writer;
@@ -182,14 +186,12 @@ pub trait QueueReader {
 
 struct LocalQueueReader {
     queue: RefCell<Queue>,
-    interrupt: Interrupt,
 }
 
 impl LocalQueueReader {
-    fn new(queue: Queue, interrupt: Interrupt) -> Self {
+    fn new(queue: Queue) -> Self {
         Self {
             queue: RefCell::new(queue),
-            interrupt,
         }
     }
 }
@@ -204,21 +206,19 @@ impl QueueReader for LocalQueueReader {
     }
 
     fn signal_used(&self) {
-        self.queue.borrow_mut().trigger_interrupt(&self.interrupt);
+        self.queue.borrow_mut().trigger_interrupt();
     }
 }
 
 #[derive(Clone)]
 struct SharedQueueReader {
     queue: Arc<Mutex<Queue>>,
-    interrupt: Interrupt,
 }
 
 impl SharedQueueReader {
-    fn new(queue: Queue, interrupt: Interrupt) -> Self {
+    fn new(queue: Queue) -> Self {
         Self {
             queue: Arc::new(Mutex::new(queue)),
-            interrupt,
         }
     }
 }
@@ -233,7 +233,7 @@ impl QueueReader for SharedQueueReader {
     }
 
     fn signal_used(&self) {
-        self.queue.lock().trigger_interrupt(&self.interrupt);
+        self.queue.lock().trigger_interrupt();
     }
 }
 
@@ -447,6 +447,7 @@ impl Frontend {
                     info.r.y.to_native(),
                     info.r.width.to_native(),
                     info.r.height.to_native(),
+                    info.offset.to_native(),
                 );
                 self.virtio_gpu.transfer_write(0, resource_id, transfer)
             }
@@ -1753,10 +1754,11 @@ impl VirtioDevice for Gpu {
             ));
         }
 
-        let ctrl_queue = SharedQueueReader::new(queues.remove(&0).unwrap(), interrupt.clone());
-        let cursor_queue = LocalQueueReader::new(queues.remove(&1).unwrap(), interrupt.clone());
+        let ctrl_queue = SharedQueueReader::new(queues.remove(&0).unwrap());
+        let cursor_queue = LocalQueueReader::new(queues.remove(&1).unwrap());
 
-        self.worker_thread
+        match self
+            .worker_thread
             .as_mut()
             .expect("worker thread missing on activate")
             .0
@@ -1766,10 +1768,13 @@ impl VirtioDevice for Gpu {
                 ctrl_queue,
                 cursor_queue,
                 worker_snapshot: self.worker_snapshot.take(),
-            })
-            .expect("failed to send activation resources to worker thread");
-
-        Ok(())
+            }) {
+            Err(mpsc::SendError(gpu_activation_resources)) => {
+                self.worker_snapshot = gpu_activation_resources.worker_snapshot;
+                bail!("failed to send activation resources to worker thread");
+            }
+            Ok(()) => Ok(()),
+        }
     }
 
     fn pci_address(&self) -> Option<PciAddress> {
@@ -1792,6 +1797,19 @@ impl VirtioDevice for Gpu {
         !self.fixed_blob_mapping
     }
 
+    fn get_shared_memory_prepare_type(&mut self) -> SharedMemoryPrepareType {
+        if self.fixed_blob_mapping {
+            let cache_type = if cfg!(feature = "noncoherent-dma") {
+                MemCacheType::CacheNonCoherent
+            } else {
+                MemCacheType::CacheCoherent
+            };
+            SharedMemoryPrepareType::SingleMappingOnFirst(cache_type)
+        } else {
+            SharedMemoryPrepareType::DynamicPerMapping
+        }
+    }
+
     // Notes on sleep/wake/snapshot/restore functionality.
     //
     //   * Only 2d mode is supported so far.
diff --git a/devices/src/virtio/gpu/parameters.rs b/devices/src/virtio/gpu/parameters.rs
index 3e97627b3..783437fc7 100644
--- a/devices/src/virtio/gpu/parameters.rs
+++ b/devices/src/virtio/gpu/parameters.rs
@@ -37,6 +37,14 @@ mod serde_capset_mask {
     }
 }
 
+#[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
+pub enum AudioDeviceMode {
+    #[serde(rename = "per-surface")]
+    PerSurface,
+    #[serde(rename = "one-global")]
+    OneGlobal,
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize, FromKeyValues)]
 #[serde(deny_unknown_fields, default, rename_all = "kebab-case")]
 pub struct GpuParameters {
@@ -44,6 +52,8 @@ pub struct GpuParameters {
     pub mode: GpuMode,
     #[serde(default = "default_max_num_displays")]
     pub max_num_displays: u32,
+    #[serde(default = "default_audio_device_mode")]
+    pub audio_device_mode: AudioDeviceMode,
     #[serde(rename = "displays")]
     pub display_params: Vec<DisplayParameters>,
     // `width` and `height` are supported for CLI backwards compatibility.
@@ -85,6 +95,7 @@ impl Default for GpuParameters {
     fn default() -> Self {
         GpuParameters {
             max_num_displays: default_max_num_displays(),
+            audio_device_mode: default_audio_device_mode(),
             display_params: vec![],
             __width_compat: None,
             __height_compat: None,
@@ -117,6 +128,10 @@ fn default_max_num_displays() -> u32 {
     VIRTIO_GPU_MAX_SCANOUTS as u32
 }
 
+fn default_audio_device_mode() -> AudioDeviceMode {
+    AudioDeviceMode::PerSurface
+}
+
 #[cfg(test)]
 mod tests {
     use serde_json::*;
diff --git a/devices/src/virtio/gpu/protocol.rs b/devices/src/virtio/gpu/protocol.rs
index 9ad80229e..5847b2c42 100644
--- a/devices/src/virtio/gpu/protocol.rs
+++ b/devices/src/virtio/gpu/protocol.rs
@@ -155,7 +155,7 @@ pub fn virtio_gpu_cmd_str(cmd: u32) -> &'static str {
 
 pub const VIRTIO_GPU_FLAG_FENCE: u32 = 1 << 0;
 pub const VIRTIO_GPU_FLAG_INFO_RING_IDX: u32 = 1 << 1;
-pub const VIRTIO_GPU_FLAG_FENCE_SHAREABLE: u32 = 1 << 2;
+pub const VIRTIO_GPU_FLAG_FENCE_HOST_SHAREABLE: u32 = 1 << 2;
 
 #[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
 #[repr(C)]
diff --git a/devices/src/virtio/gpu/virtio_gpu.rs b/devices/src/virtio/gpu/virtio_gpu.rs
index c453fcd07..6e885a726 100644
--- a/devices/src/virtio/gpu/virtio_gpu.rs
+++ b/devices/src/virtio/gpu/virtio_gpu.rs
@@ -382,7 +382,7 @@ impl VirtioGpuScanout {
             .framebuffer_region(surface_id, 0, 0, self.width, self.height)
             .ok_or(ErrUnspec)?;
 
-        let mut transfer = Transfer3D::new_2d(0, 0, self.width, self.height);
+        let mut transfer = Transfer3D::new_2d(0, 0, self.width, self.height, 0);
         transfer.stride = fb.stride();
         let fb_slice = fb.as_volatile_slice();
         let buf = IoSliceMut::new(
@@ -596,8 +596,12 @@ impl VirtioGpu {
 
     // Connects new displays to the device.
     fn add_displays(&mut self, displays: Vec<DisplayParameters>) -> GpuControlResult {
-        if self.scanouts.len() + displays.len() > VIRTIO_GPU_MAX_SCANOUTS {
-            return GpuControlResult::TooManyDisplays(VIRTIO_GPU_MAX_SCANOUTS);
+        let requested_num_scanouts = self.scanouts.len() + displays.len();
+        if requested_num_scanouts > VIRTIO_GPU_MAX_SCANOUTS {
+            return GpuControlResult::TooManyDisplays {
+                allowed: VIRTIO_GPU_MAX_SCANOUTS,
+                requested: requested_num_scanouts,
+            };
         }
 
         let mut available_scanout_ids = (0..VIRTIO_GPU_MAX_SCANOUTS)
@@ -642,29 +646,16 @@ impl VirtioGpu {
 
     /// Removes the specified displays from the device.
     fn remove_displays(&mut self, display_ids: Vec<u32>) -> GpuControlResult {
-        let display_ids_to_remove = Set::from_iter(display_ids.iter());
-        display_ids_to_remove
-            .into_iter()
-            .try_for_each(|display_id| {
-                self.scanouts
-                    .get_mut(display_id)
-                    .ok_or(GpuControlResult::NoSuchDisplay {
-                        display_id: *display_id,
-                    })
-                    .map(|scanout| {
-                        scanout.release_surface(&self.display);
-                        scanout
-                    })?;
-
-                self.scanouts.remove(display_id);
+        for display_id in display_ids {
+            if let Some(mut scanout) = self.scanouts.remove(&display_id) {
+                scanout.release_surface(&self.display);
+            } else {
+                return GpuControlResult::NoSuchDisplay { display_id };
+            }
+        }
 
-                Ok(())
-            })
-            .err()
-            .unwrap_or_else(|| {
-                self.scanouts_updated.store(true, Ordering::Relaxed);
-                GpuControlResult::DisplaysUpdated
-            })
+        self.scanouts_updated.store(true, Ordering::Relaxed);
+        GpuControlResult::DisplaysUpdated
     }
 
     fn set_display_mouse_mode(
@@ -844,7 +835,7 @@ impl VirtioGpu {
     }
 
     /// If supported, export the fence with the given `fence_id` to a file.
-    pub fn export_fence(&self, fence_id: u64) -> ResourceResponse {
+    pub fn export_fence(&mut self, fence_id: u64) -> ResourceResponse {
         match self.rutabaga.export_fence(fence_id) {
             Ok(handle) => ResourceResponse::Resource(ResourceInfo::Fence {
                 handle: to_safe_descriptor(handle.os_handle),
@@ -855,12 +846,25 @@ impl VirtioGpu {
 
     /// Gets rutabaga's capset information associated with `index`.
     pub fn get_capset_info(&self, index: u32) -> VirtioGpuResult {
-        let (capset_id, version, size) = self.rutabaga.get_capset_info(index)?;
-        Ok(OkCapsetInfo {
-            capset_id,
-            version,
-            size,
-        })
+        if let Ok((capset_id, version, size)) = self.rutabaga.get_capset_info(index) {
+            Ok(OkCapsetInfo {
+                capset_id,
+                version,
+                size,
+            })
+        } else {
+            // Any capset_id > 63 is invalid according to the virtio-gpu spec, so we can
+            // intentionally poison the capset without stalling the guest kernel driver.
+            base::warn!(
+                "virtio-gpu get_capset_info(index={}) failed. intentionally poisoning response",
+                index
+            );
+            Ok(OkCapsetInfo {
+                capset_id: u32::MAX,
+                version: 0,
+                size: 0,
+            })
+        }
     }
 
     /// Gets a capset from rutabaga.
diff --git a/devices/src/virtio/input/defaults.rs b/devices/src/virtio/input/defaults.rs
index f18ee2227..db34ce55a 100644
--- a/devices/src/virtio/input/defaults.rs
+++ b/devices/src/virtio/input/defaults.rs
@@ -11,12 +11,6 @@ use super::virtio_input_bitmap;
 use super::virtio_input_device_ids;
 use super::VirtioInputConfig;
 
-fn name_with_index(device_name: &[u8], idx: u32) -> Vec<u8> {
-    let mut ret = device_name.to_vec();
-    ret.extend_from_slice(idx.to_string().as_bytes());
-    ret
-}
-
 /// Instantiates a VirtioInputConfig object with the default configuration for a trackpad. It
 /// supports touch, left button and right button events, as well as X and Y axis.
 pub fn new_trackpad_config(
@@ -26,25 +20,44 @@ pub fn new_trackpad_config(
     name: Option<&str>,
 ) -> VirtioInputConfig {
     let name = name
-        .map(|name| name.as_bytes().to_vec())
-        .unwrap_or(name_with_index(b"Crosvm Virtio Trackpad ", idx));
+        .map(str::to_owned)
+        .unwrap_or(format!("Crosvm Virtio Trackpad {idx}"));
     VirtioInputConfig::new(
         virtio_input_device_ids::new(0, 0, 0, 0),
         name,
-        name_with_index(b"virtio-trackpad-", idx),
+        format!("virtio-trackpad-{idx}"),
         virtio_input_bitmap::new([0u8; 128]),
         default_trackpad_events(),
         default_trackpad_absinfo(width, height),
     )
 }
 
+pub fn new_multitouch_trackpad_config(
+    idx: u32,
+    width: u32,
+    height: u32,
+    name: Option<&str>,
+) -> VirtioInputConfig {
+    let name = name
+        .map(str::to_owned)
+        .unwrap_or(format!("Crosvm Virtio Multi-touch Trackpad {idx}"));
+    VirtioInputConfig::new(
+        virtio_input_device_ids::new(0, 0, 0, 0),
+        name,
+        format!("virtio-multi-touch-trackpad-{idx}"),
+        virtio_input_bitmap::from_bits(&[INPUT_PROP_POINTER, INPUT_PROP_BUTTONPAD]),
+        default_multitouchpad_events(),
+        default_multitouchpad_absinfo(width, height, 10, 65536),
+    )
+}
+
 /// Instantiates a VirtioInputConfig object with the default configuration for a mouse.
 /// It supports left, right and middle buttons, as wel as X, Y and wheel relative axes.
 pub fn new_mouse_config(idx: u32) -> VirtioInputConfig {
     VirtioInputConfig::new(
         virtio_input_device_ids::new(0, 0, 0, 0),
-        name_with_index(b"Crosvm Virtio Mouse ", idx),
-        name_with_index(b"virtio-mouse-", idx),
+        format!("Crosvm Virtio Mouse {idx}"),
+        format!("virtio-mouse-{idx}"),
         virtio_input_bitmap::new([0u8; 128]),
         default_mouse_events(),
         BTreeMap::new(),
@@ -56,8 +69,8 @@ pub fn new_mouse_config(idx: u32) -> VirtioInputConfig {
 pub fn new_keyboard_config(idx: u32) -> VirtioInputConfig {
     VirtioInputConfig::new(
         virtio_input_device_ids::new(0, 0, 0, 0),
-        name_with_index(b"Crosvm Virtio Keyboard ", idx),
-        name_with_index(b"virtio-keyboard-", idx),
+        format!("Crosvm Virtio Keyboard {idx}"),
+        format!("virtio-keyboard-{idx}"),
         virtio_input_bitmap::new([0u8; 128]),
         default_keyboard_events(),
         BTreeMap::new(),
@@ -69,8 +82,8 @@ pub fn new_keyboard_config(idx: u32) -> VirtioInputConfig {
 pub fn new_switches_config(idx: u32) -> VirtioInputConfig {
     VirtioInputConfig::new(
         virtio_input_device_ids::new(0, 0, 0, 0),
-        name_with_index(b"Crosvm Virtio Switches ", idx),
-        name_with_index(b"virtio-switches-", idx),
+        format!("Crosvm Virtio Switches {idx}"),
+        format!("virtio-switches-{idx}"),
         virtio_input_bitmap::new([0u8; 128]),
         default_switch_events(),
         BTreeMap::new(),
@@ -82,8 +95,8 @@ pub fn new_switches_config(idx: u32) -> VirtioInputConfig {
 pub fn new_rotary_config(idx: u32) -> VirtioInputConfig {
     VirtioInputConfig::new(
         virtio_input_device_ids::new(0, 0, 0, 0),
-        name_with_index(b"Crosvm Virtio Rotary ", idx),
-        name_with_index(b"virtio-rotary-", idx),
+        format!("Crosvm Virtio Rotary {idx}"),
+        format!("virtio-rotary-{idx}"),
         virtio_input_bitmap::new([0u8; 128]),
         default_rotary_events(),
         BTreeMap::new(),
@@ -99,12 +112,12 @@ pub fn new_single_touch_config(
     name: Option<&str>,
 ) -> VirtioInputConfig {
     let name = name
-        .map(|name| name.as_bytes().to_vec())
-        .unwrap_or(name_with_index(b"Crosvm Virtio Touchscreen ", idx));
+        .map(str::to_owned)
+        .unwrap_or(format!("Crosvm Virtio Touchscreen {idx}"));
     VirtioInputConfig::new(
         virtio_input_device_ids::new(0, 0, 0, 0),
         name,
-        name_with_index(b"virtio-touchscreen-", idx),
+        format!("virtio-touchscreen-{idx}"),
         virtio_input_bitmap::from_bits(&[INPUT_PROP_DIRECT]),
         default_touchscreen_events(),
         default_touchscreen_absinfo(width, height),
@@ -120,15 +133,12 @@ pub fn new_multi_touch_config(
     name: Option<&str>,
 ) -> VirtioInputConfig {
     let name = name
-        .map(|name| name.as_bytes().to_vec())
-        .unwrap_or(name_with_index(
-            b"Crosvm Virtio Multitouch Touchscreen ",
-            idx,
-        ));
+        .map(str::to_owned)
+        .unwrap_or(format!("Crosvm Virtio Multitouch Touchscreen {idx}"));
     VirtioInputConfig::new(
         virtio_input_device_ids::new(0, 0, 0, 0),
         name,
-        name_with_index(b"virtio-touchscreen-", idx),
+        format!("virtio-touchscreen-{idx}"),
         virtio_input_bitmap::from_bits(&[INPUT_PROP_DIRECT]),
         default_multitouchscreen_events(),
         default_multitouchscreen_absinfo(width, height, 10, 10),
@@ -158,6 +168,8 @@ fn default_multitouchscreen_absinfo(
     let mut absinfo: BTreeMap<u16, virtio_input_absinfo> = BTreeMap::new();
     absinfo.insert(ABS_MT_SLOT, virtio_input_absinfo::new(0, slot, 0, 0));
     absinfo.insert(ABS_MT_TRACKING_ID, virtio_input_absinfo::new(0, id, 0, 0));
+    absinfo.insert(ABS_X, virtio_input_absinfo::new(0, width, 0, 0));
+    absinfo.insert(ABS_Y, virtio_input_absinfo::new(0, height, 0, 0));
     absinfo.insert(ABS_MT_POSITION_X, virtio_input_absinfo::new(0, width, 0, 0));
     absinfo.insert(
         ABS_MT_POSITION_Y,
@@ -176,6 +188,66 @@ fn default_multitouchscreen_events() -> BTreeMap<u16, virtio_input_bitmap> {
             ABS_MT_TRACKING_ID,
             ABS_MT_POSITION_X,
             ABS_MT_POSITION_Y,
+            ABS_X,
+            ABS_Y,
+        ]),
+    );
+    supported_events
+}
+
+fn default_multitouchpad_absinfo(
+    width: u32,
+    height: u32,
+    slot: u32,
+    id: u32,
+) -> BTreeMap<u16, virtio_input_absinfo> {
+    let mut absinfo: BTreeMap<u16, virtio_input_absinfo> = BTreeMap::new();
+    absinfo.insert(ABS_MT_SLOT, virtio_input_absinfo::new(0, slot, 0, 0));
+    absinfo.insert(ABS_MT_TRACKING_ID, virtio_input_absinfo::new(0, id, 0, 0));
+    // TODO(b/347253952): make them configurable if necessary
+    absinfo.insert(ABS_MT_PRESSURE, virtio_input_absinfo::new(0, 255, 0, 0));
+    absinfo.insert(ABS_PRESSURE, virtio_input_absinfo::new(0, 255, 0, 0));
+    absinfo.insert(ABS_MT_TOUCH_MAJOR, virtio_input_absinfo::new(0, 4095, 0, 0));
+    absinfo.insert(ABS_MT_TOUCH_MINOR, virtio_input_absinfo::new(0, 4095, 0, 0));
+    absinfo.insert(ABS_X, virtio_input_absinfo::new(0, width, 0, 0));
+    absinfo.insert(ABS_Y, virtio_input_absinfo::new(0, height, 0, 0));
+    absinfo.insert(ABS_MT_POSITION_X, virtio_input_absinfo::new(0, width, 0, 0));
+    absinfo.insert(ABS_MT_TOOL_TYPE, virtio_input_absinfo::new(0, 2, 0, 0));
+    absinfo.insert(
+        ABS_MT_POSITION_Y,
+        virtio_input_absinfo::new(0, height, 0, 0),
+    );
+    absinfo
+}
+
+fn default_multitouchpad_events() -> BTreeMap<u16, virtio_input_bitmap> {
+    let mut supported_events: BTreeMap<u16, virtio_input_bitmap> = BTreeMap::new();
+    supported_events.insert(
+        EV_KEY,
+        virtio_input_bitmap::from_bits(&[
+            BTN_TOUCH,
+            BTN_TOOL_FINGER,
+            BTN_TOOL_DOUBLETAP,
+            BTN_TOOL_TRIPLETAP,
+            BTN_TOOL_QUADTAP,
+            BTN_LEFT,
+        ]),
+    );
+    supported_events.insert(
+        EV_ABS,
+        virtio_input_bitmap::from_bits(&[
+            ABS_MT_SLOT,
+            ABS_MT_TRACKING_ID,
+            ABS_MT_POSITION_X,
+            ABS_MT_POSITION_Y,
+            ABS_MT_TOOL_TYPE,
+            ABS_MT_PRESSURE,
+            ABS_X,
+            ABS_Y,
+            ABS_PRESSURE,
+            ABS_MT_TOUCH_MAJOR,
+            ABS_MT_TOUCH_MINOR,
+            ABS_PRESSURE,
         ]),
     );
     supported_events
@@ -378,7 +450,7 @@ mod tests {
     #[test]
     fn test_new_switches_config() {
         let config = new_switches_config(0);
-        assert_eq!(config.serial_name, b"virtio-switches-0".to_vec());
+        assert_eq!(config.serial_name, "virtio-switches-0");
 
         let events = config.supported_events;
         assert_eq!(events.len(), 1);
diff --git a/devices/src/virtio/input/evdev.rs b/devices/src/virtio/input/evdev.rs
index 07a2e2f2d..4f346c26e 100644
--- a/devices/src/virtio/input/evdev.rs
+++ b/devices/src/virtio/input/evdev.rs
@@ -112,6 +112,14 @@ fn errno() -> base::Error {
     base::Error::last()
 }
 
+fn string_from_bytes_with_nul(buffer: &[u8], mut len: usize) -> Result<String> {
+    // Trim NUL byte.
+    if len > 0 && buffer[len] == 0 {
+        len -= 1;
+    }
+    String::from_utf8(buffer[0..len].to_vec()).map_err(InputError::InvalidString)
+}
+
 /// Gets id information from an event device (see EVIOCGID ioctl for details).
 pub fn device_ids<T: AsRawDescriptor>(descriptor: &T) -> Result<virtio_input_device_ids> {
     let mut dev_id = evdev_id::new();
@@ -119,7 +127,7 @@ pub fn device_ids<T: AsRawDescriptor>(descriptor: &T) -> Result<virtio_input_dev
         // SAFETY:
         // Safe because the kernel won't write more than size of evdev_id and we check the return
         // value
-        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGID(), &mut dev_id) }
+        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGID, &mut dev_id) }
     };
     if len < 0 {
         return Err(InputError::EvdevIdError(errno()));
@@ -133,33 +141,33 @@ pub fn device_ids<T: AsRawDescriptor>(descriptor: &T) -> Result<virtio_input_dev
 }
 
 /// Gets the name of an event device (see EVIOCGNAME ioctl for details).
-pub fn name<T: AsRawDescriptor>(descriptor: &T) -> Result<Vec<u8>> {
+pub fn name<T: AsRawDescriptor>(descriptor: &T) -> Result<String> {
     let mut name = evdev_buffer::new();
     let len = {
         // SAFETY:
         // Safe because the kernel won't write more than size of evdev_buffer and we check the
         // return value
-        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGNAME(), &mut name) }
+        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGNAME, &mut name) }
     };
     if len < 0 {
         return Err(InputError::EvdevNameError(errno()));
     }
-    Ok(name.buffer[0..len as usize].to_vec())
+    string_from_bytes_with_nul(&name.buffer, len as usize)
 }
 
 /// Gets the unique (serial) name of an event device (see EVIOCGUNIQ ioctl for details).
-pub fn serial_name<T: AsRawDescriptor>(descriptor: &T) -> Result<Vec<u8>> {
+pub fn serial_name<T: AsRawDescriptor>(descriptor: &T) -> Result<String> {
     let mut uniq = evdev_buffer::new();
     let len = {
         // SAFETY:
         // Safe because the kernel won't write more than size of evdev_buffer and we check the
         // return value
-        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGUNIQ(), &mut uniq) }
+        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGUNIQ, &mut uniq) }
     };
     if len < 0 {
         return Err(InputError::EvdevSerialError(errno()));
     }
-    Ok(uniq.buffer[0..len as usize].to_vec())
+    string_from_bytes_with_nul(&uniq.buffer, len as usize)
 }
 
 /// Gets the properties of an event device (see EVIOCGPROP ioctl for details).
@@ -169,7 +177,7 @@ pub fn properties<T: AsRawDescriptor>(descriptor: &T) -> Result<virtio_input_bit
         // SAFETY:
         // Safe because the kernel won't write more than size of evdev_buffer and we check the
         // return value
-        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGPROP(), &mut props) }
+        unsafe { ioctl_with_mut_ref(descriptor, EVIOCGPROP, &mut props) }
     };
     if len < 0 {
         return Err(InputError::EvdevPropertiesError(errno()));
@@ -245,7 +253,7 @@ pub fn grab_evdev<T: AsRawDescriptor>(descriptor: &mut T) -> Result<()> {
     let ret = {
         // SAFETY:
         // Safe because the kernel only read the value of the ptr and we check the return value
-        unsafe { ioctl_with_ref(descriptor, EVIOCGRAB(), &val) }
+        unsafe { ioctl_with_ref(descriptor, EVIOCGRAB, &val) }
     };
     if ret == 0 {
         Ok(())
@@ -259,7 +267,7 @@ pub fn ungrab_evdev<T: AsRawDescriptor>(descriptor: &mut T) -> Result<()> {
         // SAFETY:
         // Safe because the kernel only reads the value of the ptr (doesn't dereference) and
         // we check the return value
-        unsafe { ioctl_with_ptr(descriptor, EVIOCGRAB(), null::<u32>()) }
+        unsafe { ioctl_with_ptr(descriptor, EVIOCGRAB, null::<u32>()) }
     };
     if ret == 0 {
         Ok(())
diff --git a/devices/src/virtio/input/mod.rs b/devices/src/virtio/input/mod.rs
index 146bf0c4d..d956958ff 100644
--- a/devices/src/virtio/input/mod.rs
+++ b/devices/src/virtio/input/mod.rs
@@ -85,6 +85,9 @@ pub enum InputError {
     // Detected error on guest side
     #[error("detected error on guest side: {0}")]
     GuestError(String),
+    // Invalid UTF-8 string
+    #[error("invalid UTF-8 string: {0}")]
+    InvalidString(std::string::FromUtf8Error),
     // Error while reading from virtqueue
     #[error("failed to read from virtqueue: {0}")]
     ReadQueue(std::io::Error),
@@ -172,6 +175,10 @@ impl virtio_input_config {
         }
     }
 
+    fn set_payload_str(&mut self, s: &str) {
+        self.set_payload_slice(s.as_bytes());
+    }
+
     fn set_payload_bitmap(&mut self, bitmap: &virtio_input_bitmap) {
         self.size = bitmap.min_size();
         self.payload.copy_from_slice(&bitmap.bitmap);
@@ -238,8 +245,8 @@ pub struct VirtioInputConfig {
     select: u8,
     subsel: u8,
     device_ids: virtio_input_device_ids,
-    name: Vec<u8>,
-    serial_name: Vec<u8>,
+    name: String,
+    serial_name: String,
     properties: virtio_input_bitmap,
     supported_events: BTreeMap<u16, virtio_input_bitmap>,
     axis_info: BTreeMap<u16, virtio_input_absinfo>,
@@ -248,8 +255,8 @@ pub struct VirtioInputConfig {
 impl VirtioInputConfig {
     fn new(
         device_ids: virtio_input_device_ids,
-        name: Vec<u8>,
-        serial_name: Vec<u8>,
+        name: String,
+        serial_name: String,
         properties: virtio_input_bitmap,
         supported_events: BTreeMap<u16, virtio_input_bitmap>,
         axis_info: BTreeMap<u16, virtio_input_absinfo>,
@@ -283,10 +290,10 @@ impl VirtioInputConfig {
         cfg.subsel = self.subsel;
         match self.select {
             VIRTIO_INPUT_CFG_ID_NAME => {
-                cfg.set_payload_slice(&self.name);
+                cfg.set_payload_str(&self.name);
             }
             VIRTIO_INPUT_CFG_ID_SERIAL => {
-                cfg.set_payload_slice(&self.serial_name);
+                cfg.set_payload_str(&self.serial_name);
             }
             VIRTIO_INPUT_CFG_PROP_BITS => {
                 cfg.set_payload_bitmap(&self.properties);
@@ -347,6 +354,7 @@ struct Worker<T: EventSource> {
     event_source: T,
     event_queue: Queue,
     status_queue: Queue,
+    name: String,
 }
 
 impl<T: EventSource> Worker<T> {
@@ -512,11 +520,19 @@ impl<T: EventSource> Worker<T> {
                     }
                 }
             }
+
+            for event in wait_events.iter().filter(|e| e.is_hungup) {
+                if let Token::InputEventsAvailable = event.token {
+                    warn!("input event source for '{}' disconnected", self.name);
+                    let _ = wait_ctx.delete(&self.event_source);
+                }
+            }
+
             if eventq_needs_interrupt {
-                self.event_queue.trigger_interrupt(&self.interrupt);
+                self.event_queue.trigger_interrupt();
             }
             if statusq_needs_interrupt {
-                self.status_queue.trigger_interrupt(&self.interrupt);
+                self.status_queue.trigger_interrupt();
             }
         }
 
@@ -586,6 +602,7 @@ where
         let event_queue = queues.remove(&0).unwrap();
         let status_queue = queues.remove(&1).unwrap();
 
+        let name = self.config.name.clone();
         let source = self
             .source
             .take()
@@ -596,6 +613,7 @@ where
                 event_source: source,
                 event_queue,
                 status_queue,
+                name,
             };
             worker.run(kill_evt);
             worker
@@ -729,6 +747,27 @@ where
     })
 }
 
+/// Creates a new virtio trackpad device which supports multi touch, primary and secondary
+/// buttons as well as X and Y axis.
+pub fn new_multitouch_trackpad<T>(
+    idx: u32,
+    source: T,
+    width: u32,
+    height: u32,
+    name: Option<&str>,
+    virtio_features: u64,
+) -> Result<Input<SocketEventSource<T>>>
+where
+    T: Read + Write + AsRawDescriptor + Send + 'static,
+{
+    Ok(Input {
+        worker_thread: None,
+        config: defaults::new_multitouch_trackpad_config(idx, width, height, name),
+        source: Some(SocketEventSource::new(source)),
+        virtio_features,
+    })
+}
+
 /// Creates a new virtio mouse which supports primary, secondary, wheel and REL events.
 pub fn new_mouse<T>(
     idx: u32,
diff --git a/devices/src/virtio/interrupt.rs b/devices/src/virtio/interrupt.rs
index 8fc6b85e9..c0197a2c1 100644
--- a/devices/src/virtio/interrupt.rs
+++ b/devices/src/virtio/interrupt.rs
@@ -2,13 +2,20 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
+use std::fmt;
 use std::sync::atomic::AtomicUsize;
 use std::sync::atomic::Ordering;
 use std::sync::Arc;
+#[cfg(target_arch = "x86_64")]
+use std::time::Instant;
 
 #[cfg(target_arch = "x86_64")]
 use base::error;
 use base::Event;
+#[cfg(target_arch = "x86_64")]
+use metrics::log_metric;
+#[cfg(target_arch = "x86_64")]
+use metrics::MetricEventType;
 use serde::Deserialize;
 use serde::Serialize;
 use sync::Mutex;
@@ -45,8 +52,7 @@ struct InterruptInner {
     interrupt_status: AtomicUsize,
     transport: Transport,
     async_intr_status: bool,
-    #[cfg(target_arch = "x86_64")]
-    wakeup_event: Option<PmWakeupEvent>,
+    pm_state: Arc<Mutex<PmState>>,
 }
 
 impl InterruptInner {
@@ -70,6 +76,12 @@ pub struct Interrupt {
     inner: Arc<InterruptInner>,
 }
 
+impl fmt::Debug for Interrupt {
+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
+        write!(f, "Interrupt")
+    }
+}
+
 #[derive(Serialize, Deserialize)]
 pub struct InterruptSnapshot {
     interrupt_status: usize,
@@ -81,12 +93,15 @@ impl Interrupt {
     /// If MSI-X is enabled in this device, MSI-X interrupt is preferred.
     /// Write to the irqfd to VMM to deliver virtual interrupt to the guest
     pub fn signal(&self, vector: u16, interrupt_status_mask: u32) {
-        #[cfg(target_arch = "x86_64")]
-        if let Some(wakeup_event) = self.inner.wakeup_event.as_ref() {
-            if let Err(e) = wakeup_event.trigger_wakeup() {
-                error!("Wakeup trigger failed {:?}", e);
-            }
+        if self
+            .inner
+            .pm_state
+            .lock()
+            .handle_interrupt(vector, interrupt_status_mask)
+        {
+            return;
         }
+
         match &self.inner.transport {
             Transport::Pci { pci } => {
                 // Don't need to set ISR for MSI-X interrupts
@@ -164,7 +179,7 @@ impl Interrupt {
         irq_evt_lvl: IrqLevelEvent,
         msix_config: Option<Arc<Mutex<MsixConfig>>>,
         config_msix_vector: u16,
-        #[cfg(target_arch = "x86_64")] wakeup_event: Option<PmWakeupEvent>,
+        #[cfg(target_arch = "x86_64")] wakeup_event: Option<(PmWakeupEvent, MetricEventType)>,
     ) -> Interrupt {
         Interrupt {
             inner: Arc::new(InterruptInner {
@@ -177,8 +192,10 @@ impl Interrupt {
                         config_msix_vector,
                     },
                 },
-                #[cfg(target_arch = "x86_64")]
-                wakeup_event,
+                pm_state: PmState::new(
+                    #[cfg(target_arch = "x86_64")]
+                    wakeup_event,
+                ),
             }),
         }
     }
@@ -191,7 +208,7 @@ impl Interrupt {
         msix_config: Option<Arc<Mutex<MsixConfig>>>,
         config_msix_vector: u16,
         snapshot: InterruptSnapshot,
-        #[cfg(target_arch = "x86_64")] wakeup_event: Option<PmWakeupEvent>,
+        #[cfg(target_arch = "x86_64")] wakeup_event: Option<(PmWakeupEvent, MetricEventType)>,
     ) -> Interrupt {
         Interrupt {
             inner: Arc::new(InterruptInner {
@@ -204,8 +221,10 @@ impl Interrupt {
                         config_msix_vector,
                     },
                 },
-                #[cfg(target_arch = "x86_64")]
-                wakeup_event,
+                pm_state: PmState::new(
+                    #[cfg(target_arch = "x86_64")]
+                    wakeup_event,
+                ),
             }),
         }
     }
@@ -216,8 +235,10 @@ impl Interrupt {
                 interrupt_status: AtomicUsize::new(0),
                 transport: Transport::Mmio { irq_evt_edge },
                 async_intr_status,
-                #[cfg(target_arch = "x86_64")]
-                wakeup_event: None,
+                pm_state: PmState::new(
+                    #[cfg(target_arch = "x86_64")]
+                    None,
+                ),
             }),
         }
     }
@@ -236,8 +257,10 @@ impl Interrupt {
                     signal_config_changed_fn,
                 },
                 async_intr_status: false,
-                #[cfg(target_arch = "x86_64")]
-                wakeup_event: None,
+                pm_state: PmState::new(
+                    #[cfg(target_arch = "x86_64")]
+                    None,
+                ),
             }),
         }
     }
@@ -325,10 +348,118 @@ impl Interrupt {
         }
     }
 
+    pub fn set_suspended(&self, suspended: bool) {
+        let retrigger_evts = self.inner.pm_state.lock().set_suspended(suspended);
+        for (vector, interrupt_status_mask) in retrigger_evts.into_iter() {
+            self.signal(vector, interrupt_status_mask);
+        }
+    }
+
     #[cfg(target_arch = "x86_64")]
     pub fn set_wakeup_event_active(&self, active: bool) {
-        if let Some(wakeup_event) = self.inner.wakeup_event.as_ref() {
-            wakeup_event.set_active(active);
+        self.inner.pm_state.lock().set_wakeup_event_active(active);
+    }
+}
+
+#[cfg(target_arch = "x86_64")]
+struct WakeupState {
+    wakeup_event: PmWakeupEvent,
+    wakeup_enabled: bool,
+    armed_time: Instant,
+    metrics_event: MetricEventType,
+    wakeup_clear_evt: Option<Event>,
+}
+
+#[cfg(target_arch = "x86_64")]
+impl WakeupState {
+    fn new(wakeup_event: Option<(PmWakeupEvent, MetricEventType)>) -> Option<Self> {
+        wakeup_event.map(|(wakeup_event, metrics_event)| Self {
+            wakeup_event,
+            wakeup_enabled: false,
+            // Not actually armed, but simpler than wrapping with an Option.
+            armed_time: Instant::now(),
+            metrics_event,
+            wakeup_clear_evt: None,
+        })
+    }
+
+    fn trigger_wakeup(&mut self) {
+        if self.wakeup_clear_evt.is_some() {
+            return;
+        }
+
+        let elapsed = self.armed_time.elapsed().as_millis();
+        log_metric(
+            self.metrics_event.clone(),
+            elapsed.try_into().unwrap_or(i64::MAX),
+        );
+
+        match self.wakeup_event.trigger_wakeup() {
+            Ok(clear_evt) => self.wakeup_clear_evt = clear_evt,
+            Err(err) => error!("Wakeup trigger failed {:?}", err),
+        }
+    }
+}
+
+// Power management state of the interrupt.
+struct PmState {
+    // Whether or not the virtio device that owns this interrupt is suspended. A
+    // suspended virtio device MUST NOT send notifications (i.e. interrupts) to the
+    // driver.
+    suspended: bool,
+    // The queue of interrupts that the virtio device has generated while suspended.
+    // These are deferred and sent in order when the device is un-suspended.
+    pending_signals: Vec<(u16, u32)>,
+    #[cfg(target_arch = "x86_64")]
+    wakeup_state: Option<WakeupState>,
+}
+
+impl PmState {
+    fn new(
+        #[cfg(target_arch = "x86_64")] wakeup_event: Option<(PmWakeupEvent, MetricEventType)>,
+    ) -> Arc<Mutex<Self>> {
+        Arc::new(Mutex::new(Self {
+            suspended: false,
+            pending_signals: Vec::new(),
+            #[cfg(target_arch = "x86_64")]
+            wakeup_state: WakeupState::new(wakeup_event),
+        }))
+    }
+
+    fn handle_interrupt(&mut self, vector: u16, mask: u32) -> bool {
+        if self.suspended {
+            self.pending_signals.push((vector, mask));
+            #[cfg(target_arch = "x86_64")]
+            if let Some(wakeup_state) = self.wakeup_state.as_mut() {
+                if wakeup_state.wakeup_enabled {
+                    wakeup_state.trigger_wakeup();
+                }
+            }
+        }
+        self.suspended
+    }
+
+    fn set_suspended(&mut self, suspended: bool) -> Vec<(u16, u32)> {
+        self.suspended = suspended;
+        std::mem::take(&mut self.pending_signals)
+    }
+
+    #[cfg(target_arch = "x86_64")]
+    fn set_wakeup_event_active(&mut self, active: bool) {
+        let Some(wakeup_state) = self.wakeup_state.as_mut() else {
+            return;
+        };
+
+        wakeup_state.wakeup_enabled = active;
+        if active {
+            wakeup_state.armed_time = Instant::now();
+            if !self.pending_signals.is_empty() {
+                wakeup_state.trigger_wakeup();
+            }
+        } else if let Some(clear_evt) = wakeup_state.wakeup_clear_evt.take() {
+            if let Err(e) = clear_evt.signal() {
+                error!("failed to signal clear event {}", e);
+            }
         }
     }
 }
diff --git a/devices/src/virtio/iommu.rs b/devices/src/virtio/iommu.rs
index 7ea967e36..93d377690 100644
--- a/devices/src/virtio/iommu.rs
+++ b/devices/src/virtio/iommu.rs
@@ -45,10 +45,10 @@ use cros_async::Executor;
 use data_model::Le64;
 use futures::select;
 use futures::FutureExt;
-use hypervisor::MemSlot;
 use remain::sorted;
 use sync::Mutex;
 use thiserror::Error;
+use vm_control::VmMemoryRegionId;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 use vm_memory::GuestMemoryError;
@@ -160,8 +160,8 @@ type DomainMap = BTreeMap<u32, (u32, Arc<Mutex<Box<dyn MemoryMapperTrait>>>)>;
 
 struct DmabufRegionEntry {
     mmap: MemoryMapping,
-    mem_slot: MemSlot,
-    len: u64,
+    region_id: VmMemoryRegionId,
+    size: u64,
 }
 
 // Shared state for the virtio-iommu device.
@@ -359,12 +359,22 @@ impl State {
     ) -> Result<usize> {
         let req: virtio_iommu_req_map = reader.read_obj().map_err(IommuError::GuestMemoryRead)?;
 
+        let phys_start = u64::from(req.phys_start);
+        let virt_start = u64::from(req.virt_start);
+        let virt_end = u64::from(req.virt_end);
+
+        // enforce driver requirement: virt_end MUST be strictly greater than virt_start.
+        if virt_start >= virt_end {
+            tail.status = VIRTIO_IOMMU_S_INVAL;
+            return Ok(0);
+        }
+
         // If virt_start, phys_start or (virt_end + 1) is not aligned
         // on the page granularity, the device SHOULD reject the
         // request and set status to VIRTIO_IOMMU_S_RANGE
-        if self.page_mask & u64::from(req.phys_start) != 0
-            || self.page_mask & u64::from(req.virt_start) != 0
-            || self.page_mask & (u64::from(req.virt_end) + 1) != 0
+        if self.page_mask & phys_start != 0
+            || self.page_mask & virt_start != 0
+            || self.page_mask & (virt_end + 1) != 0
         {
             tail.status = VIRTIO_IOMMU_S_RANGE;
             return Ok(0);
@@ -390,19 +400,26 @@ impl State {
         let write_en = u32::from(req.flags) & VIRTIO_IOMMU_MAP_F_WRITE != 0;
 
         if let Some(mapper) = self.domain_map.get(&domain) {
-            let size = u64::from(req.virt_end) - u64::from(req.virt_start) + 1u64;
-
-            let dmabuf_map = self
-                .dmabuf_mem
-                .range(..=u64::from(req.phys_start))
-                .next_back()
-                .and_then(|(addr, region)| {
-                    if u64::from(req.phys_start) + size <= addr + region.len {
-                        Some(region.mmap.as_ptr() as u64 + (u64::from(req.phys_start) - addr))
-                    } else {
-                        None
-                    }
-                });
+            let gpa = phys_start;
+            let iova = virt_start;
+            let Some(size) = u64::checked_add(virt_end - virt_start, 1) else {
+                // implementation doesn't support unlikely request for size == U64::MAX+1
+                tail.status = VIRTIO_IOMMU_S_DEVERR;
+                return Ok(0);
+            };
+
+            let dmabuf_map =
+                self.dmabuf_mem
+                    .range(..=gpa)
+                    .next_back()
+                    .and_then(|(base_gpa, region)| {
+                        if gpa + size <= base_gpa + region.size {
+                            let offset = gpa - base_gpa;
+                            Some(region.mmap.as_ptr() as u64 + offset)
+                        } else {
+                            None
+                        }
+                    });
 
             let prot = match write_en {
                 true => Protection::read_write(),
@@ -414,14 +431,11 @@ impl State {
                 // Safe because [dmabuf_map, dmabuf_map + size) refers to an external mmap'ed
                 // region.
                 Some(dmabuf_map) => unsafe {
-                    mapper
-                        .1
-                        .lock()
-                        .vfio_dma_map(req.virt_start.into(), dmabuf_map, size, prot)
+                    mapper.1.lock().vfio_dma_map(iova, dmabuf_map, size, prot)
                 },
                 None => mapper.1.lock().add_map(MappingInfo {
-                    iova: req.virt_start.into(),
-                    gpa: GuestAddress(req.phys_start.into()),
+                    iova,
+                    gpa: GuestAddress(gpa),
                     size,
                     prot,
                 }),
@@ -584,7 +598,6 @@ async fn request_queue(
     state: &Rc<RefCell<State>>,
     mut queue: Queue,
     mut queue_event: EventAsync,
-    interrupt: Interrupt,
 ) -> Result<()> {
     loop {
         let mut avail_desc = queue
@@ -614,7 +627,7 @@ async fn request_queue(
         }
 
         queue.add_used(avail_desc, len as u32);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
 }
 
@@ -637,7 +650,7 @@ fn run(
         .expect("Failed to clone queue event");
     let req_evt = EventAsync::new(req_evt, &ex).expect("Failed to create async event for queue");
 
-    let f_resample = async_utils::handle_irq_resample(&ex, interrupt.clone());
+    let f_resample = async_utils::handle_irq_resample(&ex, interrupt);
     let f_kill = async_utils::await_and_exit(&ex, kill_evt);
 
     let request_tube = translate_request_rx
@@ -655,7 +668,7 @@ fn run(
 
     let f_handle_translate_request =
         sys::handle_translate_request(&ex, &state, request_tube, response_tubes);
-    let f_request = request_queue(&state, req_queue, req_evt, interrupt);
+    let f_request = request_queue(&state, req_queue, req_evt);
 
     let command_tube = AsyncTube::new(&ex, iommu_device_tube).unwrap();
     // Future to handle command messages from host, such as passing vfio containers.
diff --git a/devices/src/virtio/iommu/sys/linux.rs b/devices/src/virtio/iommu/sys/linux.rs
index 733ae7cca..6dfa071d9 100644
--- a/devices/src/virtio/iommu/sys/linux.rs
+++ b/devices/src/virtio/iommu/sys/linux.rs
@@ -15,12 +15,12 @@ use base::MemoryMappingBuilder;
 use base::TubeError;
 use cros_async::AsyncTube;
 use cros_async::Executor;
-use hypervisor::MemSlot;
 use sync::Mutex;
 use vm_control::VirtioIOMMURequest;
 use vm_control::VirtioIOMMUResponse;
 use vm_control::VirtioIOMMUVfioCommand;
 use vm_control::VirtioIOMMUVfioResult;
+use vm_control::VmMemoryRegionId;
 
 use self::vfio_wrapper::VfioWrapper;
 use crate::virtio::iommu::ipc_memory_mapper::IommuRequest;
@@ -31,8 +31,6 @@ use crate::virtio::iommu::State;
 use crate::virtio::IommuError;
 use crate::VfioContainer;
 
-const VIRTIO_IOMMU_PAGE_SHIFT: u32 = 12;
-
 impl State {
     pub(in crate::virtio::iommu) fn handle_add_vfio_device(
         &mut self,
@@ -73,11 +71,15 @@ impl State {
 
     pub(in crate::virtio::iommu) fn handle_map_dmabuf(
         &mut self,
-        mem_slot: MemSlot,
-        gfn: u64,
+        region_id: VmMemoryRegionId,
+        gpa: u64,
         size: u64,
         dma_buf: File,
     ) -> VirtioIOMMUVfioResult {
+        if gpa & self.page_mask != 0 {
+            error!("cannot map dmabuf to non-page-aligned guest physical address");
+            return VirtioIOMMUVfioResult::InvalidParam;
+        }
         let mmap = match MemoryMappingBuilder::new(size as usize)
             .from_file(&dma_buf)
             .build()
@@ -89,11 +91,11 @@ impl State {
             }
         };
         self.dmabuf_mem.insert(
-            gfn << VIRTIO_IOMMU_PAGE_SHIFT,
+            gpa,
             DmabufRegionEntry {
                 mmap,
-                mem_slot,
-                len: size,
+                region_id,
+                size,
             },
         );
 
@@ -102,12 +104,12 @@ impl State {
 
     pub(in crate::virtio::iommu) fn handle_unmap_dmabuf(
         &mut self,
-        mem_slot: MemSlot,
+        region_id: VmMemoryRegionId,
     ) -> VirtioIOMMUVfioResult {
         if let Some(range) = self
             .dmabuf_mem
             .iter()
-            .find(|(_, dmabuf_entry)| dmabuf_entry.mem_slot == mem_slot)
+            .find(|(_, dmabuf_entry)| dmabuf_entry.region_id == region_id)
             .map(|entry| *entry.0)
         {
             self.dmabuf_mem.remove(&range);
@@ -140,12 +142,12 @@ impl State {
             },
             VfioDeviceDel { endpoint_addr } => self.handle_del_vfio_device(endpoint_addr),
             VfioDmabufMap {
-                mem_slot,
-                gfn,
+                region_id,
+                gpa,
                 size,
                 dma_buf,
-            } => self.handle_map_dmabuf(mem_slot, gfn, size, File::from(dma_buf)),
-            VfioDmabufUnmap(mem_slot) => self.handle_unmap_dmabuf(mem_slot),
+            } => self.handle_map_dmabuf(region_id, gpa, size, File::from(dma_buf)),
+            VfioDmabufUnmap(region_id) => self.handle_unmap_dmabuf(region_id),
         };
         VirtioIOMMUResponse::VfioResponse(vfio_result)
     }
diff --git a/devices/src/virtio/mod.rs b/devices/src/virtio/mod.rs
index 4cd17d616..e159e3910 100644
--- a/devices/src/virtio/mod.rs
+++ b/devices/src/virtio/mod.rs
@@ -4,7 +4,6 @@
 
 //! Implements virtio devices, queues, and transport mechanisms.
 
-mod async_device;
 mod async_utils;
 #[cfg(feature = "balloon")]
 mod balloon;
@@ -45,8 +44,6 @@ pub mod vsock;
 pub use self::balloon::Balloon;
 #[cfg(feature = "balloon")]
 pub use self::balloon::BalloonFeatures;
-#[cfg(feature = "balloon")]
-pub use self::balloon::BalloonMode;
 pub use self::block::BlockAsync;
 pub use self::console::Console;
 pub use self::descriptor_chain::DescriptorChain;
@@ -101,6 +98,7 @@ pub use self::vhost_user_frontend::VhostUserFrontend;
 #[cfg(any(feature = "video-decoder", feature = "video-encoder"))]
 pub use self::video::VideoDevice;
 pub use self::virtio_device::SharedMemoryMapper;
+pub use self::virtio_device::SharedMemoryPrepareType;
 pub use self::virtio_device::SharedMemoryRegion;
 pub use self::virtio_device::VirtioDevice;
 pub use self::virtio_device::VirtioTransportType;
@@ -127,6 +125,8 @@ cfg_if::cfg_if! {
         pub use self::net::VHOST_NET_DEFAULT_PATH;
         pub use self::p9::P9;
         pub use self::pmem::Pmem;
+        pub use self::pmem::PmemConfig;
+        pub use self::pmem::MemSlotConfig;
         #[cfg(feature = "audio")]
         pub use self::snd::new_sound;
         pub use self::wl::Wl;
@@ -145,6 +145,7 @@ use hypervisor::ProtectionType;
 use serde::Deserialize;
 use serde::Serialize;
 use virtio_sys::virtio_config::VIRTIO_F_ACCESS_PLATFORM;
+use virtio_sys::virtio_config::VIRTIO_F_SUSPEND;
 use virtio_sys::virtio_config::VIRTIO_F_VERSION_1;
 use virtio_sys::virtio_ids;
 use virtio_sys::virtio_ring::VIRTIO_RING_F_EVENT_IDX;
@@ -272,7 +273,8 @@ pub fn copy_config(dst: &mut [u8], dst_offset: u64, src: &[u8], src_offset: u64)
 
 /// Returns the set of reserved base features common to all virtio devices.
 pub fn base_features(protection_type: ProtectionType) -> u64 {
-    let mut features: u64 = 1 << VIRTIO_F_VERSION_1 | 1 << VIRTIO_RING_F_EVENT_IDX;
+    let mut features: u64 =
+        1 << VIRTIO_F_VERSION_1 | 1 << VIRTIO_RING_F_EVENT_IDX | 1 << VIRTIO_F_SUSPEND;
 
     if protection_type != ProtectionType::Unprotected {
         features |= 1 << VIRTIO_F_ACCESS_PLATFORM;
diff --git a/devices/src/virtio/net.rs b/devices/src/virtio/net.rs
index 7f0acb1a4..3bf20dc07 100644
--- a/devices/src/virtio/net.rs
+++ b/devices/src/virtio/net.rs
@@ -283,7 +283,6 @@ fn process_ctrl_request<T: TapT>(
 }
 
 pub fn process_ctrl<T: TapT>(
-    interrupt: &Interrupt,
     ctrl_queue: &mut Queue,
     tap: &mut T,
     acked_features: u64,
@@ -307,7 +306,7 @@ pub fn process_ctrl<T: TapT>(
         ctrl_queue.add_used(desc_chain, len);
     }
 
-    ctrl_queue.trigger_interrupt(interrupt);
+    ctrl_queue.trigger_interrupt();
     Ok(())
 }
 
@@ -352,7 +351,7 @@ where
     T: TapT + ReadNotifier,
 {
     fn process_tx(&mut self) {
-        process_tx(&self.interrupt, &mut self.tx_queue, &mut self.tap)
+        process_tx(&mut self.tx_queue, &mut self.tap)
     }
 
     fn process_ctrl(&mut self) -> Result<(), NetError> {
@@ -362,7 +361,6 @@ where
         };
 
         process_ctrl(
-            &self.interrupt,
             ctrl_queue,
             &mut self.tap,
             self.acked_features,
diff --git a/devices/src/virtio/net/sys/linux.rs b/devices/src/virtio/net/sys/linux.rs
index 7b4bf7ddc..8f47738c0 100644
--- a/devices/src/virtio/net/sys/linux.rs
+++ b/devices/src/virtio/net/sys/linux.rs
@@ -17,7 +17,6 @@ use virtio_sys::virtio_net::virtio_net_hdr_v1;
 use super::super::super::net::NetError;
 use super::super::super::net::Token;
 use super::super::super::net::Worker;
-use super::super::super::Interrupt;
 use super::super::super::Queue;
 
 // Ensure that the tap interface has the correct flags and sets the offload and VNET header size
@@ -81,11 +80,7 @@ pub fn virtio_features_to_tap_offload(features: u64) -> u32 {
     tap_offloads
 }
 
-pub fn process_rx<T: TapT>(
-    interrupt: &Interrupt,
-    rx_queue: &mut Queue,
-    mut tap: &mut T,
-) -> result::Result<(), NetError> {
+pub fn process_rx<T: TapT>(rx_queue: &mut Queue, mut tap: &mut T) -> result::Result<(), NetError> {
     let mut needs_interrupt = false;
     let mut exhausted_queue = false;
 
@@ -128,7 +123,7 @@ pub fn process_rx<T: TapT>(
     }
 
     if needs_interrupt {
-        rx_queue.trigger_interrupt(interrupt);
+        rx_queue.trigger_interrupt();
     }
 
     if exhausted_queue {
@@ -138,7 +133,7 @@ pub fn process_rx<T: TapT>(
     }
 }
 
-pub fn process_tx<T: TapT>(interrupt: &Interrupt, tx_queue: &mut Queue, mut tap: &mut T) {
+pub fn process_tx<T: TapT>(tx_queue: &mut Queue, mut tap: &mut T) {
     while let Some(mut desc_chain) = tx_queue.pop() {
         let reader = &mut desc_chain.reader;
         let expected_count = reader.available_bytes();
@@ -160,7 +155,7 @@ pub fn process_tx<T: TapT>(interrupt: &Interrupt, tx_queue: &mut Queue, mut tap:
         tx_queue.add_used(desc_chain, 0);
     }
 
-    tx_queue.trigger_interrupt(interrupt);
+    tx_queue.trigger_interrupt();
 }
 
 impl<T> Worker<T>
@@ -195,6 +190,6 @@ where
         Ok(())
     }
     pub(super) fn process_rx(&mut self) -> result::Result<(), NetError> {
-        process_rx(&self.interrupt, &mut self.rx_queue, &mut self.tap)
+        process_rx(&mut self.rx_queue, &mut self.tap)
     }
 }
diff --git a/devices/src/virtio/net/sys/windows.rs b/devices/src/virtio/net/sys/windows.rs
index 69d62f70e..643a093dc 100644
--- a/devices/src/virtio/net/sys/windows.rs
+++ b/devices/src/virtio/net/sys/windows.rs
@@ -77,7 +77,6 @@ fn rx_single_frame(rx_queue: &mut Queue, rx_buf: &mut [u8], rx_count: usize) ->
 }
 
 pub fn process_rx<T: TapT>(
-    interrupt: &Interrupt,
     rx_queue: &mut Queue,
     tap: &mut T,
     rx_buf: &mut [u8],
@@ -103,7 +102,7 @@ pub fn process_rx<T: TapT>(
                     *deferred_rx = true;
                     break;
                 } else if first_frame {
-                    interrupt.signal_used_queue(rx_queue.vector());
+                    rx_queue.trigger_interrupt();
                     first_frame = false;
                 } else {
                     needs_interrupt = true;
@@ -155,7 +154,7 @@ pub fn process_rx<T: TapT>(
     needs_interrupt
 }
 
-pub fn process_tx<T: TapT>(interrupt: &Interrupt, tx_queue: &mut Queue, tap: &mut T) {
+pub fn process_tx<T: TapT>(tx_queue: &mut Queue, tap: &mut T) {
     // Reads up to `buf.len()` bytes or until there is no more data in `r`, whichever
     // is smaller.
     fn read_to_end(r: &mut Reader, buf: &mut [u8]) -> io::Result<usize> {
@@ -187,7 +186,7 @@ pub fn process_tx<T: TapT>(interrupt: &Interrupt, tx_queue: &mut Queue, tap: &mu
         tx_queue.add_used(desc_chain, 0);
     }
 
-    tx_queue.trigger_interrupt(interrupt);
+    tx_queue.trigger_interrupt();
 }
 
 impl<T> Worker<T>
@@ -196,7 +195,6 @@ where
 {
     pub(super) fn process_rx_slirp(&mut self) -> bool {
         process_rx(
-            &self.interrupt,
             &mut self.rx_queue,
             &mut self.tap,
             &mut self.rx_buf,
diff --git a/devices/src/virtio/p9.rs b/devices/src/virtio/p9.rs
index 4678678a8..f015c8f98 100644
--- a/devices/src/virtio/p9.rs
+++ b/devices/src/virtio/p9.rs
@@ -60,7 +60,7 @@ pub enum P9Error {
     #[error("failed to signal used queue: {0}")]
     SignalUsedQueue(SysError),
     /// The tag for the 9P device was too large to fit in the config space.
-    #[error("P9 device tag is too long: len = {0}, max = {}", ::std::u16::MAX)]
+    #[error("P9 device tag is too long: len = {0}, max = {}", u16::MAX)]
     TagTooLong(usize),
     /// Error while polling for events.
     #[error("failed to wait for events: {0}")]
@@ -86,7 +86,7 @@ impl Worker {
 
             self.queue.add_used(avail_desc, len);
         }
-        self.queue.trigger_interrupt(&self.interrupt);
+        self.queue.trigger_interrupt();
 
         Ok(())
     }
@@ -142,7 +142,7 @@ pub struct P9 {
 
 impl P9 {
     pub fn new(base_features: u64, tag: &str, p9_cfg: p9::Config) -> P9Result<P9> {
-        if tag.len() > ::std::u16::MAX as usize {
+        if tag.len() > u16::MAX as usize {
             return Err(P9Error::TagTooLong(tag.len()));
         }
 
diff --git a/devices/src/virtio/pmem.rs b/devices/src/virtio/pmem.rs
index df5f45685..652be6e16 100644
--- a/devices/src/virtio/pmem.rs
+++ b/devices/src/virtio/pmem.rs
@@ -5,6 +5,8 @@
 use std::collections::BTreeMap;
 use std::fs::File;
 use std::io;
+use std::mem::size_of;
+use std::time::Duration;
 
 use anyhow::anyhow;
 use anyhow::Context;
@@ -14,19 +16,24 @@ use base::Error as SysError;
 use base::Event;
 use base::RawDescriptor;
 use base::Result as SysResult;
+use base::Timer;
 use base::Tube;
+use base::TubeError;
 use base::WorkerThread;
 use cros_async::select3;
+use cros_async::select4;
+use cros_async::AsyncError;
 use cros_async::EventAsync;
 use cros_async::Executor;
+use cros_async::TimerAsync;
 use data_model::Le32;
 use data_model::Le64;
 use futures::pin_mut;
 use remain::sorted;
 use thiserror::Error;
 use vm_control::MemSlot;
-use vm_control::VmMsyncRequest;
-use vm_control::VmMsyncResponse;
+use vm_control::VmMemoryMappingRequest;
+use vm_control::VmMemoryMappingResponse;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 use zerocopy::AsBytes;
@@ -44,7 +51,11 @@ use super::VirtioDevice;
 const QUEUE_SIZE: u16 = 256;
 const QUEUE_SIZES: &[u16] = &[QUEUE_SIZE];
 
+/* Feature bits */
+const VIRTIO_PMEM_F_DISCARD: u32 = 63;
+
 const VIRTIO_PMEM_REQ_TYPE_FLUSH: u32 = 0;
+const VIRTIO_PMEM_REQ_TYPE_DISCARD: u32 = u32::MAX;
 const VIRTIO_PMEM_RESP_TYPE_OK: u32 = 0;
 const VIRTIO_PMEM_RESP_TYPE_EIO: u32 = 1;
 
@@ -67,12 +78,30 @@ struct virtio_pmem_req {
     type_: Le32,
 }
 
+#[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
+#[repr(C)]
+struct virtio_pmem_range_req {
+    type_: Le32,
+    padding_: Le32,
+    start_address: Le64,
+    size: Le64,
+}
+
 #[sorted]
 #[derive(Error, Debug)]
 enum Error {
+    /// Failed to get value from pageout timer.
+    #[error("failed to get value from pageout timer: {0}")]
+    PageoutTimer(AsyncError),
     /// Failed to read from virtqueue.
     #[error("failed to read from virtqueue: {0}")]
     ReadQueue(io::Error),
+    /// Failed to receive tube response.
+    #[error("failed to receive tube response: {0}")]
+    ReceiveResponse(TubeError),
+    /// Failed to send tube request.
+    #[error("failed to send tube request: {0}")]
+    SendingRequest(TubeError),
     /// Failed to write to virtqueue.
     #[error("failed to write to virtqueue: {0}")]
     WriteQueue(io::Error),
@@ -80,15 +109,54 @@ enum Error {
 
 type Result<T> = ::std::result::Result<T, Error>;
 
+async fn pageout(
+    ex: &Executor,
+    swap_interval: Duration,
+    pmem_device_tube: &Tube,
+    mapping_arena_slot: u32,
+    mapping_size: usize,
+) -> Result<()> {
+    let timer = Timer::new().expect("Failed to create a timer");
+    let mut pageout_timer =
+        TimerAsync::new(timer, ex).expect("Failed to create an async pageout timer");
+    pageout_timer
+        .reset_repeating(swap_interval)
+        .expect("Failed to reset pageout timer");
+
+    loop {
+        pageout_timer.wait().await.map_err(Error::PageoutTimer)?;
+        let request = VmMemoryMappingRequest::MadvisePageout {
+            slot: mapping_arena_slot,
+            offset: 0,
+            size: mapping_size,
+        };
+
+        pmem_device_tube
+            .send(&request)
+            .map_err(Error::SendingRequest)?;
+        match pmem_device_tube
+            .recv::<VmMemoryMappingResponse>()
+            .map_err(Error::ReceiveResponse)?
+        {
+            VmMemoryMappingResponse::Ok => {}
+            VmMemoryMappingResponse::Err(e) => {
+                error!("failed to page out the memory mapping: {}", e);
+            }
+        };
+    }
+}
+
 fn execute_request(
-    request: virtio_pmem_req,
+    request_type: u32,
+    start_address: u64,
+    size: u64,
     pmem_device_tube: &Tube,
     mapping_arena_slot: u32,
     mapping_size: usize,
 ) -> u32 {
-    match request.type_.to_native() {
+    match request_type {
         VIRTIO_PMEM_REQ_TYPE_FLUSH => {
-            let request = VmMsyncRequest::MsyncArena {
+            let request = VmMemoryMappingRequest::MsyncArena {
                 slot: mapping_arena_slot,
                 offset: 0, // The pmem backing file is always at offset 0 in the arena.
                 size: mapping_size,
@@ -101,8 +169,8 @@ fn execute_request(
 
             match pmem_device_tube.recv() {
                 Ok(response) => match response {
-                    VmMsyncResponse::Ok => VIRTIO_PMEM_RESP_TYPE_OK,
-                    VmMsyncResponse::Err(e) => {
+                    VmMemoryMappingResponse::Ok => VIRTIO_PMEM_RESP_TYPE_OK,
+                    VmMemoryMappingResponse::Err(e) => {
                         error!("failed flushing disk image: {}", e);
                         VIRTIO_PMEM_RESP_TYPE_EIO
                     }
@@ -113,8 +181,36 @@ fn execute_request(
                 }
             }
         }
+
+        VIRTIO_PMEM_REQ_TYPE_DISCARD => {
+            let request = VmMemoryMappingRequest::MadviseRemove {
+                slot: mapping_arena_slot,
+                offset: usize::try_from(start_address).unwrap(),
+                size: usize::try_from(size).unwrap(),
+            };
+
+            if let Err(e) = pmem_device_tube.send(&request) {
+                error!("failed to send request: {}", e);
+                return VIRTIO_PMEM_RESP_TYPE_EIO;
+            }
+
+            match pmem_device_tube.recv() {
+                Ok(response) => match response {
+                    VmMemoryMappingResponse::Ok => VIRTIO_PMEM_RESP_TYPE_OK,
+                    VmMemoryMappingResponse::Err(e) => {
+                        error!("failed to discard memory range: {}", e);
+                        VIRTIO_PMEM_RESP_TYPE_EIO
+                    }
+                },
+                Err(e) => {
+                    error!("failed to receive data: {}", e);
+                    VIRTIO_PMEM_RESP_TYPE_EIO
+                }
+            }
+        }
+
         _ => {
-            error!("unknown request type: {}", request.type_.to_native());
+            error!("unknown request type: {}", request_type);
             VIRTIO_PMEM_RESP_TYPE_EIO
         }
     }
@@ -126,11 +222,32 @@ fn handle_request(
     mapping_arena_slot: u32,
     mapping_size: usize,
 ) -> Result<usize> {
-    let status_code = avail_desc
-        .reader
-        .read_obj()
-        .map(|request| execute_request(request, pmem_device_tube, mapping_arena_slot, mapping_size))
-        .map_err(Error::ReadQueue)?;
+    let (request_type, start_address, size) =
+        if avail_desc.reader.available_bytes() == size_of::<virtio_pmem_req>() {
+            let request = avail_desc
+                .reader
+                .read_obj::<virtio_pmem_req>()
+                .map_err(Error::ReadQueue)?;
+            (request.type_.to_native(), 0, 0)
+        } else {
+            let request = avail_desc
+                .reader
+                .read_obj::<virtio_pmem_range_req>()
+                .map_err(Error::ReadQueue)?;
+            (
+                request.type_.to_native(),
+                request.start_address.to_native(),
+                request.size.to_native(),
+            )
+        };
+    let status_code = execute_request(
+        request_type,
+        start_address,
+        size,
+        pmem_device_tube,
+        mapping_arena_slot,
+        mapping_size,
+    );
 
     let response = virtio_pmem_resp {
         status_code: status_code.into(),
@@ -147,7 +264,6 @@ fn handle_request(
 async fn handle_queue(
     queue: &mut Queue,
     mut queue_event: EventAsync,
-    interrupt: Interrupt,
     pmem_device_tube: &Tube,
     mapping_arena_slot: u32,
     mapping_size: usize,
@@ -174,7 +290,7 @@ async fn handle_queue(
             }
         };
         queue.add_used(avail_desc, written as u32);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
 }
 
@@ -185,6 +301,7 @@ fn run_worker(
     kill_evt: Event,
     mapping_arena_slot: u32,
     mapping_size: usize,
+    swap_interval: Option<Duration>,
 ) {
     let ex = Executor::new().unwrap();
 
@@ -198,7 +315,6 @@ fn run_worker(
     let queue_fut = handle_queue(
         queue,
         queue_evt,
-        interrupt.clone(),
         pmem_device_tube,
         mapping_arena_slot,
         mapping_size,
@@ -213,19 +329,48 @@ fn run_worker(
     let kill = async_utils::await_and_exit(&ex, kill_evt);
     pin_mut!(kill);
 
-    if let Err(e) = ex.run_until(select3(queue_fut, resample, kill)) {
-        error!("error happened in executor: {}", e);
+    let interval = swap_interval.unwrap_or(Duration::ZERO);
+    if interval.is_zero() {
+        if let Err(e) = ex.run_until(select3(queue_fut, resample, kill)) {
+            error!("error happened in executor: {}", e);
+        }
+    } else {
+        let pageout_fut = pageout(
+            &ex,
+            interval,
+            pmem_device_tube,
+            mapping_arena_slot,
+            mapping_size,
+        );
+        pin_mut!(pageout_fut);
+        if let Err(e) = ex.run_until(select4(queue_fut, resample, kill, pageout_fut)) {
+            error!("error happened in executor: {}", e);
+        }
     }
 }
 
+/// Specifies how memory slot is initialized.
+pub enum MemSlotConfig {
+    /// The memory region has already been mapped to the guest.
+    MemSlot {
+        /// index of the guest-mapped memory regions.
+        idx: MemSlot,
+    },
+    /// The memory region that is not initialized yet and whose slot index will be provided via
+    /// `Tube` later. e.g. pmem-ext2 device, where fs construction will be done in the main
+    /// process.
+    LazyInit { tube: Tube },
+}
+
 pub struct Pmem {
     worker_thread: Option<WorkerThread<(Queue, Tube)>>,
-    base_features: u64,
+    features: u64,
     disk_image: Option<File>,
     mapping_address: GuestAddress,
-    mapping_arena_slot: MemSlot,
+    mem_slot: MemSlotConfig,
     mapping_size: u64,
     pmem_device_tube: Option<Tube>,
+    swap_interval: Option<Duration>,
 }
 
 #[derive(serde::Serialize, serde::Deserialize)]
@@ -234,27 +379,49 @@ struct PmemSnapshot {
     mapping_size: u64,
 }
 
+/// Configuration of a virtio-pmem device.
+pub struct PmemConfig {
+    /// Disk image exposed to the guest.
+    /// If the memory region is not backed by a file, this should be `None`.
+    pub disk_image: Option<File>,
+    /// Guest physical address where the memory will be mapped.
+    pub mapping_address: GuestAddress,
+    pub mem_slot: MemSlotConfig,
+    /// The size of the mapped region.
+    pub mapping_size: u64,
+    /// A communication channel to the main process to send memory requests.
+    pub pmem_device_tube: Tube,
+    /// Interval for periodic swap out of memory mapping
+    pub swap_interval: Option<Duration>,
+    /// Whether the region is writeble or not.
+    pub mapping_writable: bool,
+}
+
 impl Pmem {
-    pub fn new(
-        base_features: u64,
-        disk_image: File,
-        mapping_address: GuestAddress,
-        mapping_arena_slot: MemSlot,
-        mapping_size: u64,
-        pmem_device_tube: Tube,
-    ) -> SysResult<Pmem> {
-        if mapping_size > usize::max_value() as u64 {
+    pub fn new(base_features: u64, cfg: PmemConfig) -> SysResult<Pmem> {
+        if cfg.mapping_size > usize::MAX as u64 {
             return Err(SysError::new(libc::EOVERFLOW));
         }
 
+        let mut avail_features = base_features;
+        if cfg.mapping_writable {
+            if let MemSlotConfig::LazyInit { .. } = cfg.mem_slot {
+                error!("pmem-ext2 must be a read-only device");
+                return Err(SysError::new(libc::EINVAL));
+            }
+
+            avail_features |= 1 << VIRTIO_PMEM_F_DISCARD;
+        }
+
         Ok(Pmem {
             worker_thread: None,
-            base_features,
-            disk_image: Some(disk_image),
-            mapping_address,
-            mapping_arena_slot,
-            mapping_size,
-            pmem_device_tube: Some(pmem_device_tube),
+            features: avail_features,
+            disk_image: cfg.disk_image,
+            mapping_address: cfg.mapping_address,
+            mem_slot: cfg.mem_slot,
+            mapping_size: cfg.mapping_size,
+            pmem_device_tube: Some(cfg.pmem_device_tube),
+            swap_interval: cfg.swap_interval,
         })
     }
 }
@@ -269,6 +436,11 @@ impl VirtioDevice for Pmem {
         if let Some(ref pmem_device_tube) = self.pmem_device_tube {
             keep_rds.push(pmem_device_tube.as_raw_descriptor());
         }
+
+        if let MemSlotConfig::LazyInit { tube } = &self.mem_slot {
+            keep_rds.push(tube.as_raw_descriptor());
+        }
+
         keep_rds
     }
 
@@ -281,7 +453,7 @@ impl VirtioDevice for Pmem {
     }
 
     fn features(&self) -> u64 {
-        self.base_features
+        self.features
     }
 
     fn read_config(&self, offset: u64, data: &mut [u8]) {
@@ -304,7 +476,6 @@ impl VirtioDevice for Pmem {
 
         let mut queue = queues.remove(&0).unwrap();
 
-        let mapping_arena_slot = self.mapping_arena_slot;
         // We checked that this fits in a usize in `Pmem::new`.
         let mapping_size = self.mapping_size as usize;
 
@@ -313,6 +484,15 @@ impl VirtioDevice for Pmem {
             .take()
             .context("missing pmem device tube")?;
 
+        let swap_interval = self.swap_interval;
+
+        let mapping_arena_slot = match &self.mem_slot {
+            MemSlotConfig::MemSlot { idx } => *idx,
+            MemSlotConfig::LazyInit { tube } => tube
+                .recv::<u32>()
+                .context("failed to receive memory slot for ext2 pmem device")?,
+        };
+
         self.worker_thread = Some(WorkerThread::start("v_pmem", move |kill_event| {
             run_worker(
                 &mut queue,
@@ -321,6 +501,7 @@ impl VirtioDevice for Pmem {
                 kill_event,
                 mapping_arena_slot,
                 mapping_size,
+                swap_interval,
             );
             (queue, pmem_device_tube)
         }));
diff --git a/devices/src/virtio/pvclock.rs b/devices/src/virtio/pvclock.rs
index a0820c5b4..e584f5ea8 100644
--- a/devices/src/virtio/pvclock.rs
+++ b/devices/src/virtio/pvclock.rs
@@ -43,7 +43,8 @@
 //! However, it doesn't address the difference between CLOCK_BOOTTIME and CLOCK_MONOTONIC related
 //! to host's suspend/resume, as it is designed to maintain the CLOCK_REALTIME in sync mainly.
 
-use std::arch::x86_64::_rdtsc;
+#[cfg(target_arch = "aarch64")]
+use std::arch::asm;
 use std::collections::BTreeMap;
 use std::mem::replace;
 use std::mem::size_of;
@@ -110,6 +111,79 @@ const VIRTIO_PVCLOCK_S_IOERR: u8 = 1;
 
 const VIRTIO_PVCLOCK_CLOCKSOURCE_RATING: u32 = 450;
 
+#[cfg(any(target_arch = "x86", target_arch = "x86_64"))]
+fn read_clock_counter() -> u64 {
+    // SAFETY: rdtsc is unprivileged and have no side effects.
+    unsafe { std::arch::x86_64::_rdtsc() }
+}
+
+#[cfg(target_arch = "aarch64")]
+fn read_clock_counter() -> u64 {
+    let mut x: u64;
+    // SAFETY: This instruction have no side effect apart from storing the current timestamp counter
+    //         into the specified register.
+    unsafe {
+        asm!("mrs {x}, cntvct_el0",
+            x = out(reg) x,
+        );
+    }
+    x
+}
+
+/// Calculate a (multiplier, shift) pair for scaled math of clocks.
+/// The values are passed on to `pvclock_scale_delta` in the guest kernel and satisfy the following
+/// (approximate) equality:
+/// `n * scaled_hz / base_hz ~= ((n << shift) * multiplier) >> 32`
+/// The logic here is roughly based on `kvm_get_time_scale` (but simplified as we can use u128).
+/// # Arguments
+/// * `scaled_hz` - Frequency to convert to. When dealing with clocksources, this is NSEC_PER_SEC.
+/// * `base_hz` - Frequency to convert from. When dealing with clocksources, this is the counter
+///   frequency.
+fn freq_scale_shift(scaled_hz: u64, base_hz: u64) -> (u32, i8) {
+    assert!(scaled_hz > 0 && base_hz > 0);
+    // We treat `multiplier` as a 0.32 fixed-point number by folding the >> 32 into its definition.
+    // With this definition, `multiplier` can be calculated as `(scaled_hz / base_hz) >> shift`
+    // with a corresponding `shift`.
+    //
+    // The value of `shift` should satisfy a few constraints:
+    // 1. `multiplier` needs to be < 1.0 due to the representable range of 0.32 fixed-point (maximum
+    //    (2^32-1)/2^32).
+    // 2. `shift` should be minimized because `pvclock_scale_delta` applies `shift` on the 64-bit
+    //    TSC value before extending to 128-bit and large positive shifts reduce the TSC rollover
+    //    time.
+    //
+    // Minimizing `shift` means maximizing `multiplier`. From the < 1.0 constraint, this is
+    // equivalent to having a multiplier within [0.5, 1.0). The logic below picks a multiplier
+    // satisfying that, while updating `shift` accordingly when we double or halve the multiplier.
+    let mut shift = 0;
+    // Convert to u128 so that overflow handling becomes much easier.
+    let mut scaled_hz = scaled_hz as u128;
+    let mut base_hz = base_hz as u128;
+    if scaled_hz >= base_hz {
+        while scaled_hz >= base_hz {
+            // `multiplier` >= 1.0; iteratively scale it down
+            // scaled_hz is at most 64 bits, so after this loop base_hz is at most 65 bits.
+            base_hz <<= 1;
+            shift += 1;
+        }
+    } else {
+        while base_hz > 2 * scaled_hz {
+            // `multiplier` < 0.5; iteratively scale it up
+            // base_hz is at most 64 bits. If the loop condition passes then scaled_hz is at most 63
+            // bits, otherwise at most 64 bits. Post-loop scaled_hz is at most 64 bits.
+            scaled_hz <<= 1;
+            shift -= 1;
+        }
+    }
+    // From above, we know that the values are at most 65 bits. This provides sufficient headroom
+    // for scaled_hz << 32 below.
+    assert!(base_hz < (1u128 << 65) && scaled_hz < (1u128 << 65));
+    let mult: u32 = ((scaled_hz << 32) / base_hz)
+        .try_into()
+        .expect("should not overflow");
+    (mult, shift)
+}
+
 // The config structure being exposed to the guest to tell them how much suspend time should be
 // injected to the guest's CLOCK_BOOTTIME.
 #[derive(Debug, Clone, Copy, Default, AsBytes, FromZeroes, FromBytes)]
@@ -199,27 +273,7 @@ impl PvclockSharedData {
     }
 
     pub fn set_tsc_frequency(&mut self, frequency: u64) -> Result<()> {
-        // TSC values are converted to timestamps using the following algorithm:
-        //   delta = _rdtsc() - tsc_suspended_delta
-        //   if tsc_frequency_shift > 0:
-        //     delta <<= tsc_frequency_shift
-        //   else:
-        //     delta >>= -tsc_frequency_shift
-        //   return (delta * tsc_frequency_multiplier) >> 32
-        //
-        // So, tsc_frequency_multiplier needs to be something like 1e9/tsc_frquency, in which case
-        // tsc_frequency_shift would be 32 (to counteract the final 32 right shift). But
-        // 1e9/tsc_frequency is <1 so we actually need to scale that value up and scale down
-        // the tsc_frequency_shift so we don't lose precision in the frequency. Our tsc_frequency
-        // isn't *that* precise, so we scale it up by 16 and scale down the tsc_frequency_shift by
-        // 16 (so it's also 16).
-        let shift = 16i8;
-        let multiplier: u32 = ((1_000_000_000u128 << shift) / frequency as u128)
-            .try_into()
-            .context(format!(
-                "tsc frequency multiplier overflow, frequency {}Hz is too small",
-                frequency
-            ))?;
+        let (multiplier, shift): (u32, i8) = freq_scale_shift(1_000_000_000, frequency);
 
         self.mem
             .write_obj_at_addr(multiplier, self.tsc_frequency_multiplier_addr)
@@ -310,6 +364,7 @@ impl PvClock {
         let last_state = replace(&mut self.worker_state, PvClockWorkerState::None);
         if let PvClockWorkerState::Idle(suspend_tube) = last_state {
             if queues.len() != QUEUE_SIZES.len() {
+                self.worker_state = PvClockWorkerState::Idle(suspend_tube);
                 return Err(anyhow!(
                     "expected {} queues, got {}",
                     QUEUE_SIZES.len(),
@@ -495,14 +550,11 @@ impl PvClockWorker {
         }
         self.suspend_time = Some(PvclockInstant {
             time: Utc::now(),
-            // SAFETY:
-            // Safe because _rdtsc takes no arguments, and we trust _rdtsc to not modify any other
-            // memory.
-            tsc_value: unsafe { _rdtsc() },
+            tsc_value: read_clock_counter(),
         });
     }
 
-    pub fn resume(&mut self) -> Result<()> {
+    pub fn resume(&mut self) -> Result<u64> {
         // First, increment the sequence lock by 1 before writing to the pvclock page.
         self.increment_pvclock_seqlock()?;
 
@@ -511,13 +563,13 @@ impl PvClockWorker {
         // writes to other fields.
         std::sync::atomic::fence(Ordering::SeqCst);
 
-        // Set the tsc suspended delta and guest_stopped_bit in pvclock struct. We only need to set
+        // Set the guest_stopped_bit and tsc suspended delta in pvclock struct. We only need to set
         // the bit, the guest will unset it once the guest has handled the stoppage.
         // We get the result here because we want to call increment_pvclock_seqlock regardless of
         // the result of these calls.
         let result = self
-            .set_suspended_time()
-            .and_then(|_| self.set_guest_stopped_bit());
+            .set_guest_stopped_bit()
+            .and_then(|_| self.set_suspended_time());
 
         // The guest makes sure there are memory barriers in between reads of the seqlock and other
         // fields, we should make sure there are memory barriers in between writes of seqlock and
@@ -545,18 +597,15 @@ impl PvClockWorker {
         }
     }
 
-    fn set_suspended_time(&mut self) -> Result<()> {
+    fn set_suspended_time(&mut self) -> Result<u64> {
         let (this_suspend_duration, this_suspend_tsc_delta) =
             if let Some(suspend_time) = self.suspend_time.take() {
                 (
                     Self::get_suspended_duration(&suspend_time),
-                    // SAFETY:
-                    // Safe because _rdtsc takes no arguments, and we trust _rdtsc to not modify
-                    // any other memory.
                     // NB: This calculation may wrap around, as TSC can be reset to zero when
                     // the device has resumed from the "deep" suspend state (it may not happen for
                     // s2idle cases). It also happens when the tsc value itself wraps.
-                    unsafe { _rdtsc() }.wrapping_sub(suspend_time.tsc_value),
+                    read_clock_counter().wrapping_sub(suspend_time.tsc_value),
                 )
             } else {
                 return Err(Error::new(libc::ENOTSUP))
@@ -586,7 +635,7 @@ impl PvClockWorker {
         self.total_injected_ns
             .fetch_add(this_suspend_duration.as_nanos() as u64, Ordering::SeqCst);
 
-        Ok(())
+        Ok(self.total_suspend_tsc_delta)
     }
 
     fn increment_pvclock_seqlock(&mut self) -> Result<()> {
@@ -805,7 +854,7 @@ fn run_main_worker(
                     };
 
                     set_pvclock_page_queue.add_used(desc_chain, len);
-                    set_pvclock_page_queue.trigger_interrupt(&interrupt);
+                    set_pvclock_page_queue.trigger_interrupt();
                 }
                 Token::SuspendResume => {
                     let req = match suspend_tube.recv::<PvClockCommand>() {
@@ -822,13 +871,20 @@ fn run_main_worker(
                             PvClockCommandResponse::Ok
                         }
                         PvClockCommand::Resume => {
-                            if let Err(e) = worker.resume() {
-                                error!("Failed to resume pvclock: {:#}", e);
-                                PvClockCommandResponse::Err(pvclock_response_error_from_anyhow(e))
-                            } else {
-                                // signal to the driver that the total_suspend_ns has changed
-                                interrupt.signal_config_changed();
-                                PvClockCommandResponse::Ok
+                            match worker.resume() {
+                                Ok(total_suspended_ticks) => {
+                                    // signal to the driver that the total_suspend_ns has changed
+                                    interrupt.signal_config_changed();
+                                    PvClockCommandResponse::Resumed {
+                                        total_suspended_ticks,
+                                    }
+                                }
+                                Err(e) => {
+                                    error!("Failed to resume pvclock: {:#}", e);
+                                    PvClockCommandResponse::Err(pvclock_response_error_from_anyhow(
+                                        e,
+                                    ))
+                                }
                             }
                         }
                     };
@@ -915,15 +971,25 @@ impl VirtioDevice for PvClock {
 
     fn virtio_sleep(&mut self) -> anyhow::Result<Option<BTreeMap<usize, Queue>>> {
         let last_state = replace(&mut self.worker_state, PvClockWorkerState::None);
-        if let PvClockWorkerState::Main(main_worker_thread) = last_state {
-            let main_worker_ret = main_worker_thread.stop();
-            let mut queues = BTreeMap::new();
-            queues.insert(0, main_worker_ret.set_pvclock_page_queue);
-            self.worker_state = PvClockWorkerState::Idle(main_worker_ret.suspend_tube);
-            self.state.paused_main_worker = Some(main_worker_ret.worker.into());
-            Ok(Some(queues))
-        } else {
-            Ok(None)
+        match last_state {
+            PvClockWorkerState::Main(main_worker_thread) => {
+                let main_worker_ret = main_worker_thread.stop();
+                let mut queues = BTreeMap::new();
+                queues.insert(0, main_worker_ret.set_pvclock_page_queue);
+                self.worker_state = PvClockWorkerState::Idle(main_worker_ret.suspend_tube);
+                self.state.paused_main_worker = Some(main_worker_ret.worker.into());
+                Ok(Some(queues))
+            }
+            PvClockWorkerState::Stub(stub_worker_thread) => {
+                let stub_ret = stub_worker_thread.stop();
+                self.worker_state = PvClockWorkerState::Idle(stub_ret.suspend_tube);
+                Ok(None)
+            }
+            PvClockWorkerState::Idle(suspend_tube) => {
+                self.worker_state = PvClockWorkerState::Idle(suspend_tube);
+                Ok(None)
+            }
+            PvClockWorkerState::None => panic!("invalid state transition"),
         }
     }
 
@@ -945,6 +1011,10 @@ impl VirtioDevice for PvClock {
             );
             // Use unchecked as no worker is running at this point
             self.start_main_worker(interrupt, worker, queues)?;
+        } else {
+            // If the device wasn't activated, we should bring up the stub worker since that's
+            // what is supposed to be running for an un-activated device.
+            self.start_stub_worker();
         }
         Ok(())
     }
@@ -1008,11 +1078,17 @@ mod tests {
         let mut fake_queue = QueueConfig::new(TEST_QUEUE_SIZE, 0);
         fake_queue.set_ready(true);
         let mem = GuestMemory::new(&[(GuestAddress(0), 0x10000)]).unwrap();
+        let interrupt = make_interrupt();
         pvclock_device
             .activate(
                 mem.clone(),
-                make_interrupt(),
-                BTreeMap::from([(0, fake_queue.activate(&mem, Event::new().unwrap()).unwrap())]),
+                interrupt.clone(),
+                BTreeMap::from([(
+                    0,
+                    fake_queue
+                        .activate(&mem, Event::new().unwrap(), interrupt)
+                        .unwrap(),
+                )]),
             )
             .expect("activate should succeed");
         let queues = pvclock_device
@@ -1033,9 +1109,15 @@ mod tests {
         // by the device in these tests.
         let mut wake_queues = BTreeMap::new();
         let mut fake_queue = QueueConfig::new(TEST_QUEUE_SIZE, 0);
+        let interrupt = make_interrupt();
         fake_queue.set_ready(true);
-        wake_queues.insert(0, fake_queue.activate(mem, Event::new().unwrap()).unwrap());
-        let queues_state = (mem.clone(), make_interrupt(), wake_queues);
+        wake_queues.insert(
+            0,
+            fake_queue
+                .activate(mem, Event::new().unwrap(), interrupt.clone())
+                .unwrap(),
+        );
+        let queues_state = (mem.clone(), interrupt, wake_queues);
         pvclock_device
             .virtio_wake(Some(queues_state))
             .expect("wake should succeed");
@@ -1081,4 +1163,73 @@ mod tests {
 
         assert_wake_successful(&mut pvclock_device, &mem);
     }
+
+    /// A simplified clone of `pvclock_scale_delta` from Linux kernel to emulate
+    /// what the kernel does when converting TSC to ktime.
+    fn pvclock_scale_tsc(mult: u32, shift: i8, tsc: u64) -> u64 {
+        let shifted = if shift < 0 {
+            tsc >> -shift
+        } else {
+            tsc << shift
+        };
+        let product = shifted as u128 * mult as u128;
+        (product >> 32).try_into().expect("should not overflow")
+    }
+
+    /// Helper function for checking the behavior of `freq_scale_shift`.
+    fn check_freq_scale(f: u64, input: u64) {
+        // We only test `scaled_hz` = 1GHz because that is the only value used in the code base.
+        let (mult, shift) = freq_scale_shift(1_000_000_000, f);
+
+        let scaled = pvclock_scale_tsc(mult, shift, input);
+
+        // Use relative error <= 1e-8 as the target. TSC can be huge so this isn't really a super
+        // accurate target, and our goal is to simply sanity check the math without adding too many
+        // requirements about rounding errors.
+        let expected: u64 = (input as u128 * 1_000_000_000u128 / f as u128) as u64;
+        let expected_lo: u64 = (input as u128 * 999_999_990u128 / f as u128) as u64;
+        let expected_hi: u64 = (input as u128 * 1_000_000_010u128 / f as u128) as u64;
+        assert!(
+            (expected_lo..=expected_hi).contains(&scaled),
+            "{scaled} should be close to {expected} (base_hz={f}, mult={mult}, shift={shift})"
+        );
+    }
+
+    #[test]
+    fn test_freq_scale_shift_accuracy() {
+        // Basic check for formula correctness: scaling `scaled_hz` to `base_hz` should yield
+        // `base_hz`.
+        for f in (1..=50).map(|n| n * 100_000_000) {
+            check_freq_scale(f, f);
+        }
+    }
+
+    #[test]
+    fn test_freq_scale_shift_overflow_high_freq() {
+        // For scale factors < 1.0, test that we can correctly convert the maximum TSC value without
+        // overflow. We must be able to handle values as large as it realistically can be, as the
+        // kernel clock breaks if the calculated ktime goes backwards (b/342168920).
+        for f in (11..=50).map(|n| n * 100_000_000) {
+            check_freq_scale(f, u64::MAX);
+        }
+    }
+
+    #[test]
+    fn test_freq_scale_shift_overflow_low_freq() {
+        fn prev_power_of_two(n: u64) -> u64 {
+            assert_ne!(n, 0);
+            let highest_bit_set = 63 - n.leading_zeros();
+            1 << highest_bit_set
+        }
+        // Same test as above, but for scale factors >= 1.0. The difference is that for scale
+        // factors >= 1.0 we first round up the factor, then apply a multiplier (< 1.0). We reflect
+        // this limitation in our tested maximum value.
+        for f in (1..=10).map(|n| n * 100_000_000) {
+            // Truncate the remainder since prev_power_of_two rounds down anyway.
+            let factor = 1_000_000_000 / f;
+            // This is like (exp2(floor(log2(factor)) + 1)).
+            let target = u64::MAX / (prev_power_of_two(factor) << 1);
+            check_freq_scale(f, target);
+        }
+    }
 }
diff --git a/devices/src/virtio/queue.rs b/devices/src/virtio/queue.rs
index 7d1f9207d..281469785 100644
--- a/devices/src/virtio/queue.rs
+++ b/devices/src/virtio/queue.rs
@@ -260,7 +260,12 @@ impl QueueConfig {
     }
 
     /// Convert the queue configuration into an active queue.
-    pub fn activate(&mut self, mem: &GuestMemory, event: Event) -> Result<Queue> {
+    pub fn activate(
+        &mut self,
+        mem: &GuestMemory,
+        event: Event,
+        interrupt: Interrupt,
+    ) -> Result<Queue> {
         if !self.ready {
             bail!("attempted to activate a non-ready queue");
         }
@@ -271,12 +276,12 @@ impl QueueConfig {
         // If VIRTIO_F_RING_PACKED feature bit is set, create a packed queue, otherwise create a
         // split queue
         let queue: Queue = if ((self.acked_features >> VIRTIO_F_RING_PACKED) & 1) != 0 {
-            let pq =
-                PackedQueue::new(self, mem, event).context("Failed to create a packed queue.")?;
+            let pq = PackedQueue::new(self, mem, event, interrupt)
+                .context("Failed to create a packed queue.")?;
             Queue::PackedVirtQueue(pq)
         } else {
-            let sq =
-                SplitQueue::new(self, mem, event).context("Failed to create a split queue.")?;
+            let sq = SplitQueue::new(self, mem, event, interrupt)
+                .context("Failed to create a split queue.")?;
             Queue::SplitVirtQueue(sq)
         };
 
@@ -436,10 +441,10 @@ impl Queue {
     /// inject interrupt into guest on this queue
     /// return true: interrupt is injected into guest for this queue
     ///        false: interrupt isn't injected
-    pub fn trigger_interrupt(&mut self, interrupt: &Interrupt) -> bool {
+    pub fn trigger_interrupt(&mut self) -> bool {
         match self {
-            Queue::SplitVirtQueue(sq) => sq.trigger_interrupt(interrupt),
-            Queue::PackedVirtQueue(pq) => pq.trigger_interrupt(interrupt),
+            Queue::SplitVirtQueue(sq) => sq.trigger_interrupt(),
+            Queue::PackedVirtQueue(pq) => pq.trigger_interrupt(),
         }
     }
 
@@ -449,11 +454,35 @@ impl Queue {
         queue_value: serde_json::Value,
         mem: &GuestMemory,
         event: Event,
+        interrupt: Interrupt,
     ) -> anyhow::Result<Queue> {
         if queue_config.acked_features & 1 << VIRTIO_F_RING_PACKED != 0 {
-            PackedQueue::restore(queue_value, mem, event).map(Queue::PackedVirtQueue)
+            PackedQueue::restore(queue_value, mem, event, interrupt).map(Queue::PackedVirtQueue)
         } else {
-            SplitQueue::restore(queue_value, mem, event).map(Queue::SplitVirtQueue)
+            SplitQueue::restore(queue_value, mem, event, interrupt).map(Queue::SplitVirtQueue)
+        }
+    }
+
+    /// "Reclaim" a queue that was given to a vhost-user backend and is now being taken back using
+    /// VHOST_USER_GET_VRING_BASE.
+    ///
+    /// The `Queue` will have stale fields if the vhost-user backend fulfilled any virtqueue
+    /// requests. This function updates the `Queue` to pick up where the backend left off.
+    pub fn vhost_user_reclaim(&mut self, vring_base: u16) {
+        match self {
+            Queue::SplitVirtQueue(q) => q.vhost_user_reclaim(vring_base),
+            Queue::PackedVirtQueue(q) => q.vhost_user_reclaim(vring_base),
+        }
+    }
+
+    /// Getter for the next index of the available ring that device will process.
+    ///
+    /// Not to be confused with the available ring's index field, which is the next index for the
+    /// driver to fill.
+    pub fn next_avail_to_process(&self) -> u16 {
+        match self {
+            Queue::SplitVirtQueue(q) => q.next_avail_to_process(),
+            Queue::PackedVirtQueue(q) => q.next_avail_to_process(),
         }
     }
 
@@ -494,6 +523,12 @@ impl Queue {
         &Event,
     );
 
+    define_queue_method!(
+        /// Get a reference to the queue's interrupt.
+        interrupt,
+        &Interrupt,
+    );
+
     define_queue_method!(
         /// Puts an available descriptor head into the used ring for use by the guest.
         add_used,
diff --git a/devices/src/virtio/queue/packed_queue.rs b/devices/src/virtio/queue/packed_queue.rs
index 9c243b03e..b8a5aa9c8 100644
--- a/devices/src/virtio/queue/packed_queue.rs
+++ b/devices/src/virtio/queue/packed_queue.rs
@@ -85,6 +85,7 @@ pub struct PackedQueue {
     mem: GuestMemory,
 
     event: Event,
+    interrupt: Interrupt,
 
     // The queue size in elements the driver selected
     size: u16,
@@ -125,7 +126,12 @@ pub struct PackedQueueSnapshot {
 
 impl PackedQueue {
     /// Constructs an empty virtio queue with the given `max_size`.
-    pub fn new(config: &QueueConfig, mem: &GuestMemory, event: Event) -> Result<Self> {
+    pub fn new(
+        config: &QueueConfig,
+        mem: &GuestMemory,
+        event: Event,
+        interrupt: Interrupt,
+    ) -> Result<Self> {
         let size = config.size();
 
         let desc_table = config.desc_table();
@@ -154,6 +160,7 @@ impl PackedQueue {
         Ok(PackedQueue {
             mem: mem.clone(),
             event,
+            interrupt,
             size,
             vector: config.vector(),
             desc_table: config.desc_table(),
@@ -166,6 +173,15 @@ impl PackedQueue {
         })
     }
 
+    pub fn vhost_user_reclaim(&mut self, _vring_base: u16) {
+        // TODO: b/331466964 - Need more than `vring_base` to reclaim a packed virtqueue.
+        unimplemented!()
+    }
+
+    pub fn next_avail_to_process(&self) -> u16 {
+        self.avail_index.index.0
+    }
+
     /// Return the actual size of the queue, as the driver may not set up a
     /// queue as big as the device allows.
     pub fn size(&self) -> u16 {
@@ -197,6 +213,11 @@ impl PackedQueue {
         &self.event
     }
 
+    /// Get a reference to the queue's interrupt
+    pub fn interrupt(&self) -> &Interrupt {
+        &self.interrupt
+    }
+
     fn area_sizes(
         queue_size: u16,
         desc_table: GuestAddress,
@@ -387,9 +408,9 @@ impl PackedQueue {
     /// inject interrupt into guest on this queue
     /// return true: interrupt is injected into guest for this queue
     ///        false: interrupt isn't injected
-    pub fn trigger_interrupt(&mut self, interrupt: &Interrupt) -> bool {
+    pub fn trigger_interrupt(&mut self) -> bool {
         if self.queue_wants_interrupt() {
-            interrupt.signal_used_queue(self.vector);
+            self.interrupt.signal_used_queue(self.vector);
             true
         } else {
             false
@@ -413,6 +434,7 @@ impl PackedQueue {
         _queue_value: serde_json::Value,
         _mem: &GuestMemory,
         _event: Event,
+        _interrupt: Interrupt,
     ) -> Result<PackedQueue> {
         bail!("Restore for packed virtqueue not implemented.");
     }
diff --git a/devices/src/virtio/queue/split_queue.rs b/devices/src/virtio/queue/split_queue.rs
index ab13f0571..187b36001 100644
--- a/devices/src/virtio/queue/split_queue.rs
+++ b/devices/src/virtio/queue/split_queue.rs
@@ -37,6 +37,7 @@ pub struct SplitQueue {
     mem: GuestMemory,
 
     event: Event,
+    interrupt: Interrupt,
 
     /// The queue size in elements the driver selected. This is always guaranteed to be a power of
     /// two, as required for split virtqueues.
@@ -84,7 +85,12 @@ struct virtq_used_elem {
 
 impl SplitQueue {
     /// Constructs an activated split virtio queue with the given configuration.
-    pub fn new(config: &QueueConfig, mem: &GuestMemory, event: Event) -> Result<SplitQueue> {
+    pub fn new(
+        config: &QueueConfig,
+        mem: &GuestMemory,
+        event: Event,
+        interrupt: Interrupt,
+    ) -> Result<SplitQueue> {
         let size = config.size();
         if !size.is_power_of_two() {
             bail!("split queue size {size} is not a power of 2");
@@ -114,6 +120,7 @@ impl SplitQueue {
         Ok(SplitQueue {
             mem: mem.clone(),
             event,
+            interrupt,
             size,
             vector: config.vector(),
             desc_table: config.desc_table(),
@@ -126,6 +133,29 @@ impl SplitQueue {
         })
     }
 
+    pub fn vhost_user_reclaim(&mut self, vring_base: u16) {
+        self.next_avail = Wrapping(vring_base);
+        // The vhost-user spec says:
+        //
+        //     For the Used Ring, the device only needs the next descriptor index at which to put
+        //     new descriptors, which is the value in the vring structure in memory, so this value
+        //     is not covered by this message.
+        //
+        // So, we read the value from guest memory.
+        let used_index_addr = self.used_ring.unchecked_add(2);
+        self.next_used = self
+            .mem
+            .read_obj_from_addr_volatile(used_index_addr)
+            .unwrap();
+        // We assume the vhost-user backend sent interrupts for any descriptors it marked used
+        // before it stopped processing the queue, so `last_used == next_used`.
+        self.last_used = self.next_used;
+    }
+
+    pub fn next_avail_to_process(&self) -> u16 {
+        self.next_avail.0
+    }
+
     /// Return the actual size of the queue, as the driver may not set up a
     /// queue as big as the device allows.
     pub fn size(&self) -> u16 {
@@ -157,6 +187,11 @@ impl SplitQueue {
         &self.event
     }
 
+    /// Get a reference to the queue's interrupt
+    pub fn interrupt(&self) -> &Interrupt {
+        &self.interrupt
+    }
+
     // Return `index` modulo the currently configured queue size.
     fn wrap_queue_index(&self, index: Wrapping<u16>) -> u16 {
         // We know that `self.size` is a power of two (enforced by `new()`), so the modulus can
@@ -450,10 +485,10 @@ impl SplitQueue {
     /// inject interrupt into guest on this queue
     /// return true: interrupt is injected into guest for this queue
     ///        false: interrupt isn't injected
-    pub fn trigger_interrupt(&mut self, interrupt: &Interrupt) -> bool {
+    pub fn trigger_interrupt(&mut self) -> bool {
         if self.queue_wants_interrupt() {
             self.last_used = self.next_used;
-            interrupt.signal_used_queue(self.vector);
+            self.interrupt.signal_used_queue(self.vector);
             true
         } else {
             false
@@ -479,11 +514,13 @@ impl SplitQueue {
         queue_value: serde_json::Value,
         mem: &GuestMemory,
         event: Event,
+        interrupt: Interrupt,
     ) -> anyhow::Result<SplitQueue> {
         let s: SplitQueueSnapshot = serde_json::from_value(queue_value)?;
         let queue = SplitQueue {
             mem: mem.clone(),
             event,
+            interrupt,
             size: s.size,
             vector: s.vector,
             desc_table: s.desc_table,
@@ -501,11 +538,11 @@ impl SplitQueue {
 #[cfg(test)]
 mod tests {
     use std::convert::TryInto;
+    use std::mem::offset_of;
 
     use data_model::Le16;
     use data_model::Le32;
     use data_model::Le64;
-    use memoffset::offset_of;
     use zerocopy::AsBytes;
     use zerocopy::FromBytes;
 
@@ -514,7 +551,6 @@ mod tests {
     use crate::virtio::Desc;
     use crate::virtio::Interrupt;
     use crate::virtio::Queue;
-    use crate::IrqLevelEvent;
 
     const GUEST_MEMORY_SIZE: u64 = 0x10000;
     const DESC_OFFSET: u64 = 0;
@@ -602,7 +638,7 @@ mod tests {
         queue.set_ready(true);
 
         queue
-            .activate(mem, Event::new().unwrap())
+            .activate(mem, Event::new().unwrap(), Interrupt::new_for_test())
             .expect("QueueConfig::activate failed")
     }
 
@@ -619,14 +655,6 @@ mod tests {
         let mem = GuestMemory::new(&[(memory_start_addr, GUEST_MEMORY_SIZE)]).unwrap();
         let mut queue = setup_vq(&mut queue, &mem);
 
-        let interrupt = Interrupt::new(
-            IrqLevelEvent::new().unwrap(),
-            None,
-            10,
-            #[cfg(target_arch = "x86_64")]
-            None,
-        );
-
         // Offset of used_event within Avail structure
         let used_event_offset = offset_of!(Avail, used_event) as u64;
         let used_event_address = GuestAddress(AVAIL_OFFSET + used_event_offset);
@@ -640,7 +668,7 @@ mod tests {
 
         // At this moment driver hasn't handled any interrupts yet, so it
         // should inject interrupt.
-        assert_eq!(queue.trigger_interrupt(&interrupt), true);
+        assert_eq!(queue.trigger_interrupt(), true);
 
         // Driver handle all the interrupts and update avail.used_event to 0x100
         let mut driver_handled = device_generate;
@@ -648,18 +676,18 @@ mod tests {
 
         // At this moment driver have handled all the interrupts, and
         // device doesn't generate more data, so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
 
         // Assume driver submit another u16::MAX - 0x100 req to device,
         // Device has handled all of them, so increase self.next_used to u16::MAX
-        for _ in device_generate.0..u16::max_value() {
+        for _ in device_generate.0..u16::MAX {
             queue.add_used(fake_desc_chain(&mem), BUFFER_LEN);
         }
-        device_generate = Wrapping(u16::max_value());
+        device_generate = Wrapping(u16::MAX);
 
         // At this moment driver just handled 0x100 interrupts, so it
         // should inject interrupt.
-        assert_eq!(queue.trigger_interrupt(&interrupt), true);
+        assert_eq!(queue.trigger_interrupt(), true);
 
         // driver handle all the interrupts and update avail.used_event to u16::MAX
         driver_handled = device_generate;
@@ -667,7 +695,7 @@ mod tests {
 
         // At this moment driver have handled all the interrupts, and
         // device doesn't generate more data, so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
 
         // Assume driver submit another 1 request,
         // device has handled it, so wrap self.next_used to 0
@@ -676,7 +704,7 @@ mod tests {
 
         // At this moment driver has handled all the previous interrupts, so it
         // should inject interrupt again.
-        assert_eq!(queue.trigger_interrupt(&interrupt), true);
+        assert_eq!(queue.trigger_interrupt(), true);
 
         // driver handle that interrupts and update avail.used_event to 0
         driver_handled = device_generate;
@@ -684,7 +712,7 @@ mod tests {
 
         // At this moment driver have handled all the interrupts, and
         // device doesn't generate more data, so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
     }
 
     #[test]
@@ -695,14 +723,6 @@ mod tests {
         let mem = GuestMemory::new(&[(memory_start_addr, GUEST_MEMORY_SIZE)]).unwrap();
         let mut queue = setup_vq(&mut queue, &mem);
 
-        let interrupt = Interrupt::new(
-            IrqLevelEvent::new().unwrap(),
-            None,
-            10,
-            #[cfg(target_arch = "x86_64")]
-            None,
-        );
-
         // Offset of used_event within Avail structure
         let used_event_offset = offset_of!(Avail, used_event) as u64;
         let used_event_address = GuestAddress(AVAIL_OFFSET + used_event_offset);
@@ -716,7 +736,7 @@ mod tests {
 
         // At this moment driver hasn't handled any interrupts yet, so it
         // should inject interrupt.
-        assert_eq!(queue.trigger_interrupt(&interrupt), true);
+        assert_eq!(queue.trigger_interrupt(), true);
 
         // Driver handle part of the interrupts and update avail.used_event to 0x80
         let mut driver_handled = Wrapping(0x80);
@@ -724,7 +744,7 @@ mod tests {
 
         // At this moment driver hasn't finished last interrupt yet,
         // so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
 
         // Assume driver submit another 1 request,
         // device has handled it, so increment self.next_used.
@@ -733,18 +753,18 @@ mod tests {
 
         // At this moment driver hasn't finished last interrupt yet,
         // so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
 
         // Assume driver submit another u16::MAX - 0x101 req to device,
         // Device has handled all of them, so increase self.next_used to u16::MAX
-        for _ in device_generate.0..u16::max_value() {
+        for _ in device_generate.0..u16::MAX {
             queue.add_used(fake_desc_chain(&mem), BUFFER_LEN);
         }
-        device_generate = Wrapping(u16::max_value());
+        device_generate = Wrapping(u16::MAX);
 
         // At this moment driver hasn't finished last interrupt yet,
         // so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
 
         // driver handle most of the interrupts and update avail.used_event to u16::MAX - 1,
         driver_handled = device_generate - Wrapping(1);
@@ -757,7 +777,7 @@ mod tests {
 
         // At this moment driver has already finished the last interrupt(0x100),
         // and device service other request, so new interrupt is needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), true);
+        assert_eq!(queue.trigger_interrupt(), true);
 
         // Assume driver submit another 1 request,
         // device has handled it, so increment self.next_used to 1
@@ -766,7 +786,7 @@ mod tests {
 
         // At this moment driver hasn't finished last interrupt((Wrapping(0)) yet,
         // so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
 
         // driver handle all the remain interrupts and wrap avail.used_event to 0x1.
         driver_handled = device_generate;
@@ -774,7 +794,7 @@ mod tests {
 
         // At this moment driver has handled all the interrupts, and
         // device doesn't generate more data, so interrupt isn't needed.
-        assert_eq!(queue.trigger_interrupt(&interrupt), false);
+        assert_eq!(queue.trigger_interrupt(), false);
 
         // Assume driver submit another 1 request,
         // device has handled it, so increase self.next_used.
@@ -783,6 +803,6 @@ mod tests {
 
         // At this moment driver has finished all the previous interrupts, so it
         // should inject interrupt again.
-        assert_eq!(queue.trigger_interrupt(&interrupt), true);
+        assert_eq!(queue.trigger_interrupt(), true);
     }
 }
diff --git a/devices/src/virtio/rng.rs b/devices/src/virtio/rng.rs
index 3bb52dffe..1efd70677 100644
--- a/devices/src/virtio/rng.rs
+++ b/devices/src/virtio/rng.rs
@@ -57,7 +57,7 @@ impl Worker {
         }
 
         if needs_interrupt {
-            self.queue.trigger_interrupt(&self.interrupt);
+            self.queue.trigger_interrupt();
         }
     }
 
diff --git a/devices/src/virtio/scsi/device.rs b/devices/src/virtio/scsi/device.rs
index 4a8576e41..ec18f4882 100644
--- a/devices/src/virtio/scsi/device.rs
+++ b/devices/src/virtio/scsi/device.rs
@@ -759,7 +759,6 @@ async fn run_worker(
     let queue_handler = handle_queue(
         Rc::new(RefCell::new(queue)),
         EventAsync::new(kick_evt, ex).expect("Failed to create async event for queue"),
-        interrupt,
         queue_type,
         sense_size,
         cdb_size,
@@ -777,7 +776,6 @@ async fn run_worker(
 async fn handle_queue(
     queue: Rc<RefCell<Queue>>,
     evt: EventAsync,
-    interrupt: Interrupt,
     queue_type: QueueType,
     sense_size: u32,
     cdb_size: u32,
@@ -800,7 +798,6 @@ async fn handle_queue(
             background_tasks.push(process_one_chain(
                 &queue,
                 chain,
-                &interrupt,
                 &queue_type,
                 sense_size,
                 cdb_size,
@@ -812,7 +809,6 @@ async fn handle_queue(
 async fn process_one_chain(
     queue: &RefCell<Queue>,
     mut avail_desc: DescriptorChain,
-    interrupt: &Interrupt,
     queue_type: &QueueType,
     sense_size: u32,
     cdb_size: u32,
@@ -821,7 +817,7 @@ async fn process_one_chain(
     let len = process_one_request(&mut avail_desc, queue_type, sense_size, cdb_size).await;
     let mut queue = queue.borrow_mut();
     queue.add_used(avail_desc, len as u32);
-    queue.trigger_interrupt(interrupt);
+    queue.trigger_interrupt();
 }
 
 async fn process_one_request(
diff --git a/devices/src/virtio/scsi/mod.rs b/devices/src/virtio/scsi/mod.rs
index e0034bf01..8a81580f8 100644
--- a/devices/src/virtio/scsi/mod.rs
+++ b/devices/src/virtio/scsi/mod.rs
@@ -16,6 +16,9 @@ mod device;
 pub use device::Controller;
 pub use device::DiskConfig;
 
+fn scsi_option_lock_default() -> bool {
+    true
+}
 fn scsi_option_block_size_default() -> u32 {
     512
 }
@@ -29,6 +32,9 @@ pub struct ScsiOption {
     // Indicates whether the device is ready only.
     #[serde(default, rename = "ro")]
     pub read_only: bool,
+    /// Whether to lock the disk files. Uses flock on Unix and FILE_SHARE_* flags on Windows.
+    #[serde(default = "scsi_option_lock_default")]
+    pub lock: bool,
     // The block size of the device.
     #[serde(default = "scsi_option_block_size_default")]
     pub block_size: u32,
@@ -54,6 +60,7 @@ mod tests {
             ScsiOption {
                 path: Path::new("/path/to/image").to_path_buf(),
                 read_only: false,
+                lock: scsi_option_lock_default(),
                 block_size: 512,
                 root: false,
             }
@@ -65,6 +72,7 @@ mod tests {
             ScsiOption {
                 path: Path::new("/path/to/image").to_path_buf(),
                 read_only: true,
+                lock: scsi_option_lock_default(),
                 block_size: 512,
                 root: false,
             }
@@ -76,6 +84,7 @@ mod tests {
             ScsiOption {
                 path: Path::new("/path/to/image").to_path_buf(),
                 read_only: false,
+                lock: scsi_option_lock_default(),
                 block_size: 1024,
                 root: false,
             }
@@ -88,6 +97,7 @@ mod tests {
             ScsiOption {
                 path: Path::new("/path/to/image").to_path_buf(),
                 read_only: false,
+                lock: scsi_option_lock_default(),
                 block_size: 1024,
                 root: true,
             }
diff --git a/devices/src/virtio/scsi/sys/linux.rs b/devices/src/virtio/scsi/sys/linux.rs
index 67117afdf..4211d2a18 100644
--- a/devices/src/virtio/scsi/sys/linux.rs
+++ b/devices/src/virtio/scsi/sys/linux.rs
@@ -2,35 +2,23 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-use std::fs::File;
-use std::fs::OpenOptions;
-
 use anyhow::Context;
-use base::flock;
-use base::open_file_or_duplicate;
-use base::FlockOperation;
 use disk::DiskFile;
 
 use crate::virtio::scsi::ScsiOption;
 
 impl ScsiOption {
     pub fn open(&self) -> anyhow::Result<Box<dyn DiskFile>> {
-        let mut options = OpenOptions::new();
-        options.read(true).write(!self.read_only);
-
-        let raw_image: File = open_file_or_duplicate(&self.path, &options)
-            .with_context(|| format!("failed to load disk image {}", self.path.display()))?;
-        // Lock the disk image to prevent other crosvm instances from using it.
-        let lock_op = if self.read_only {
-            FlockOperation::LockShared
-        } else {
-            FlockOperation::LockExclusive
-        };
-        flock(&raw_image, lock_op, true)
-            .with_context(|| format!("failed to lock disk image {}", self.path.display()))?;
-
         // We only support sparse disks for now.
-        disk::create_disk_file(raw_image, true, disk::MAX_NESTING_DEPTH, &self.path)
-            .context("create_disk_file failed")
+        disk::open_disk_file(disk::DiskFileParams {
+            path: self.path.clone(),
+            is_read_only: self.read_only,
+            is_sparse_file: true,
+            is_overlapped: false,
+            is_direct: false,
+            lock: self.lock,
+            depth: 0,
+        })
+        .context("open_disk_file failed")
     }
 }
diff --git a/devices/src/virtio/snd/common_backend/async_funcs.rs b/devices/src/virtio/snd/common_backend/async_funcs.rs
index 3f8b453a3..402083ae0 100644
--- a/devices/src/virtio/snd/common_backend/async_funcs.rs
+++ b/devices/src/virtio/snd/common_backend/async_funcs.rs
@@ -41,7 +41,6 @@ use crate::virtio::snd::common_backend::PcmResponse;
 use crate::virtio::snd::constants::*;
 use crate::virtio::snd::layout::*;
 use crate::virtio::DescriptorChain;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 use crate::virtio::Reader;
 use crate::virtio::Writer;
@@ -150,14 +149,15 @@ async fn process_pcm_ctrl(
     cmd: VirtioSndPcmCmd,
     writer: &mut Writer,
     stream_id: usize,
+    card_index: usize,
 ) -> Result<(), Error> {
     let streams = streams.read_lock().await;
     let mut stream = match streams.get(stream_id) {
         Some(stream_info) => stream_info.lock().await,
         None => {
             error!(
-                "Stream id={} not found for {}. Error code: VIRTIO_SND_S_BAD_MSG",
-                stream_id, cmd
+                "[Card {}] Stream id={} not found for {}. Error code: VIRTIO_SND_S_BAD_MSG",
+                card_index, stream_id, cmd
             );
             return writer
                 .write_obj(VIRTIO_SND_S_BAD_MSG)
@@ -165,15 +165,15 @@ async fn process_pcm_ctrl(
         }
     };
 
-    debug!("{} for stream id={}", cmd, stream_id);
+    debug!("[Card {}] {} for stream id={}", card_index, cmd, stream_id);
 
     let result = match cmd {
         VirtioSndPcmCmd::SetParams { set_params } => {
             let result = stream.set_params(set_params).await;
             if result.is_ok() {
                 debug!(
-                    "VIRTIO_SND_R_PCM_SET_PARAMS for stream id={}. Stream info: {:#?}",
-                    stream_id, *stream
+                    "[Card {}] VIRTIO_SND_R_PCM_SET_PARAMS for stream id={}. Stream info: {:#?}",
+                    card_index, stream_id, *stream
                 );
             }
             result
@@ -189,8 +189,8 @@ async fn process_pcm_ctrl(
             .map_err(Error::WriteResponse),
         Err(Error::OperationNotSupported) => {
             error!(
-                "{} for stream id={} failed. Error code: VIRTIO_SND_S_NOT_SUPP.",
-                cmd, stream_id
+                "[Card {}] {} for stream id={} failed. Error code: VIRTIO_SND_S_NOT_SUPP.",
+                card_index, cmd, stream_id
             );
 
             writer
@@ -201,8 +201,8 @@ async fn process_pcm_ctrl(
             // Runtime/internal error would be more appropriate, but there's
             // no such error type
             error!(
-                "{} for stream id={} failed. Error code: VIRTIO_SND_S_IO_ERR. Actual error: {}",
-                cmd, stream_id, e
+                "[Card {}] {} for stream id={} failed. Error code: VIRTIO_SND_S_IO_ERR. Actual error: {}",
+                card_index, cmd, stream_id, e
             );
             writer
                 .write_obj(VIRTIO_SND_S_IO_ERR)
@@ -319,6 +319,7 @@ pub async fn start_pcm_worker(
     status_mutex: Rc<AsyncRwLock<WorkerStatus>>,
     mut sender: mpsc::UnboundedSender<PcmResponse>,
     period_dur: Duration,
+    card_index: usize,
     release_signal: Rc<(AsyncRwLock<bool>, Condvar)>,
 ) -> Result<(), Error> {
     let res = pcm_worker_loop(
@@ -328,13 +329,15 @@ pub async fn start_pcm_worker(
         &status_mutex,
         &mut sender,
         period_dur,
+        card_index,
         release_signal,
     )
     .await;
     *status_mutex.lock().await = WorkerStatus::Quit;
     if res.is_err() {
         error!(
-            "pcm_worker error: {:#?}. Draining desc_receiver",
+            "[Card {}] pcm_worker error: {:#?}. Draining desc_receiver",
+            card_index,
             res.as_ref().err()
         );
         // On error, guaranteed that desc_receiver has not been drained, so drain it here.
@@ -351,6 +354,7 @@ async fn pcm_worker_loop(
     status_mutex: &Rc<AsyncRwLock<WorkerStatus>>,
     sender: &mut mpsc::UnboundedSender<PcmResponse>,
     period_dur: Duration,
+    card_index: usize,
     release_signal: Rc<(AsyncRwLock<bool>, Condvar)>,
 ) -> Result<(), Error> {
     let on_release = async {
@@ -358,7 +362,10 @@ async fn pcm_worker_loop(
         // After receiving release signal, wait for up to 2 periods,
         // giving it a chance to respond to the last buffer.
         if let Err(e) = TimerAsync::sleep(&ex, period_dur * 2).await {
-            error!("Error on sleep after receiving reset signal: {}", e)
+            error!(
+                "[Card {}] Error on sleep after receiving reset signal: {}",
+                card_index, e
+            )
         }
     }
     .fuse();
@@ -397,7 +404,10 @@ async fn pcm_worker_loop(
                 WorkerStatus::Quit => {
                     drain_desc_receiver(desc_receiver, sender).await?;
                     if let Err(e) = write_data(dst_buf, None, buffer_writer).await {
-                        error!("Error on write_data after worker quit: {}", e)
+                        error!(
+                            "[Card {}] Error on write_data after worker quit: {}",
+                            card_index, e
+                        )
                     }
                     break Ok(());
                 }
@@ -406,11 +416,14 @@ async fn pcm_worker_loop(
                 }
                 WorkerStatus::Running => match desc_receiver.try_next() {
                     Err(e) => {
-                        error!("Underrun. No new DescriptorChain while running: {}", e);
+                        error!(
+                            "[Card {}] Underrun. No new DescriptorChain while running: {}",
+                            card_index, e
+                        );
                         write_data(dst_buf, None, buffer_writer).await?;
                     }
                     Ok(None) => {
-                        error!("Unreachable. status should be Quit when the channel is closed");
+                        error!("[Card {}] Unreachable. status should be Quit when the channel is closed", card_index);
                         write_data(dst_buf, None, buffer_writer).await?;
                         return Err(Error::InvalidPCMWorkerState);
                     }
@@ -449,7 +462,10 @@ async fn pcm_worker_loop(
                 WorkerStatus::Quit => {
                     drain_desc_receiver(desc_receiver, sender).await?;
                     if let Err(e) = read_data(src_buf, None, period_bytes).await {
-                        error!("Error on read_data after worker quit: {}", e)
+                        error!(
+                            "[Card {}] Error on read_data after worker quit: {}",
+                            card_index, e
+                        )
                     }
                     break Ok(());
                 }
@@ -458,11 +474,14 @@ async fn pcm_worker_loop(
                 }
                 WorkerStatus::Running => match desc_receiver.try_next() {
                     Err(e) => {
-                        error!("Overrun. No new DescriptorChain while running: {}", e);
+                        error!(
+                            "[Card {}] Overrun. No new DescriptorChain while running: {}",
+                            card_index, e
+                        );
                         read_data(src_buf, None, period_bytes).await?;
                     }
                     Ok(None) => {
-                        error!("Unreachable. status should be Quit when the channel is closed");
+                        error!("[Card {}] Unreachable. status should be Quit when the channel is closed", card_index);
                         read_data(src_buf, None, period_bytes).await?;
                         return Err(Error::InvalidPCMWorkerState);
                     }
@@ -504,7 +523,6 @@ async fn defer_pcm_response_to_worker(
 fn send_pcm_response(
     mut desc_chain: DescriptorChain,
     queue: &mut Queue,
-    interrupt: &Interrupt,
     status: virtio_snd_pcm_status,
 ) -> Result<(), Error> {
     let writer = &mut desc_chain.writer;
@@ -517,7 +535,7 @@ fn send_pcm_response(
     writer.write_obj(status).map_err(Error::WriteResponse)?;
     let len = writer.bytes_written() as u32;
     queue.add_used(desc_chain, len);
-    queue.trigger_interrupt(interrupt);
+    queue.trigger_interrupt();
     Ok(())
 }
 
@@ -536,7 +554,6 @@ async fn await_reset_signal(reset_signal_option: Option<&(AsyncRwLock<bool>, Con
 
 pub async fn send_pcm_response_worker(
     queue: Rc<AsyncRwLock<Queue>>,
-    interrupt: Interrupt,
     recv: &mut mpsc::UnboundedReceiver<PcmResponse>,
     reset_signal: Option<&(AsyncRwLock<bool>, Condvar)>,
 ) -> Result<(), Error> {
@@ -553,7 +570,7 @@ pub async fn send_pcm_response_worker(
         };
 
         if let Some(r) = res {
-            send_pcm_response(r.desc_chain, &mut *queue.lock().await, &interrupt, r.status)?;
+            send_pcm_response(r.desc_chain, &mut *queue.lock().await, r.status)?;
 
             // Resume pcm_worker
             if let Some(done) = r.done {
@@ -574,6 +591,7 @@ pub async fn handle_pcm_queue(
     mut response_sender: mpsc::UnboundedSender<PcmResponse>,
     queue: Rc<AsyncRwLock<Queue>>,
     queue_event: &EventAsync,
+    card_index: usize,
     reset_signal: Option<&(AsyncRwLock<bool>, Condvar)>,
 ) -> Result<(), Error> {
     let on_reset = await_reset_signal(reset_signal).fuse();
@@ -607,7 +625,8 @@ pub async fn handle_pcm_queue(
             Some(stream_info) => stream_info.read_lock().await,
             None => {
                 error!(
-                    "stream_id ({}) >= num_streams ({})",
+                    "[Card {}] stream_id ({}) >= num_streams ({})",
+                    card_index,
                     stream_id,
                     streams.len()
                 );
@@ -633,7 +652,8 @@ pub async fn handle_pcm_queue(
             None => {
                 if !stream_info.just_reset {
                     error!(
-                        "stream {} is not ready. state: {}",
+                        "[Card {}] stream {} is not ready. state: {}",
+                        card_index,
                         stream_id,
                         get_virtio_snd_r_pcm_cmd_name(stream_info.state)
                     );
@@ -657,9 +677,9 @@ pub async fn handle_ctrl_queue(
     snd_data: &SndData,
     queue: Rc<AsyncRwLock<Queue>>,
     queue_event: &mut EventAsync,
-    interrupt: Interrupt,
     tx_send: mpsc::UnboundedSender<PcmResponse>,
     rx_send: mpsc::UnboundedSender<PcmResponse>,
+    card_index: usize,
     reset_signal: Option<&(AsyncRwLock<bool>, Condvar)>,
 ) -> Result<(), Error> {
     let on_reset = await_reset_signal(reset_signal).fuse();
@@ -695,8 +715,9 @@ pub async fn handle_ctrl_queue(
                     let count: usize = u32::from(query_info.count) as usize;
                     if start_id + count > snd_data.jack_info.len() {
                         error!(
-                            "start_id({}) + count({}) must be smaller than \
+                            "[Card {}] start_id({}) + count({}) must be smaller than \
                             the number of jacks ({})",
+                            card_index,
                             start_id,
                             count,
                             snd_data.jack_info.len()
@@ -725,8 +746,9 @@ pub async fn handle_ctrl_queue(
                     let count: usize = u32::from(query_info.count) as usize;
                     if start_id + count > snd_data.pcm_info.len() {
                         error!(
-                            "start_id({}) + count({}) must be smaller than \
+                            "[Card {}] start_id({}) + count({}) must be smaller than \
                             the number of streams ({})",
+                            card_index,
                             start_id,
                             count,
                             snd_data.pcm_info.len()
@@ -755,8 +777,9 @@ pub async fn handle_ctrl_queue(
                     let count: usize = u32::from(query_info.count) as usize;
                     if start_id + count > snd_data.chmap_info.len() {
                         error!(
-                            "start_id({}) + count({}) must be smaller than \
+                            "[Card {}] start_id({}) + count({}) must be smaller than \
                             the number of chmaps ({})",
+                            card_index,
                             start_id,
                             count,
                             snd_data.chmap_info.len()
@@ -795,7 +818,8 @@ pub async fn handle_ctrl_queue(
                                 || set_params.channels > pcm_info.channels_max
                             {
                                 error!(
-                                    "Number of channels ({}) must be between {} and {}",
+                                    "[Card {}] Number of channels ({}) must be between {} and {}",
+                                    card_index,
                                     set_params.channels,
                                     pcm_info.channels_min,
                                     pcm_info.channels_max
@@ -805,13 +829,19 @@ pub async fn handle_ctrl_queue(
                                     .map_err(Error::WriteResponse);
                             }
                             if (u64::from(pcm_info.formats) & (1 << set_params.format)) == 0 {
-                                error!("PCM format {} is not supported.", set_params.format);
+                                error!(
+                                    "[Card {}] PCM format {} is not supported.",
+                                    card_index, set_params.format
+                                );
                                 return writer
                                     .write_obj(VIRTIO_SND_S_NOT_SUPP)
                                     .map_err(Error::WriteResponse);
                             }
                             if (u64::from(pcm_info.rates) & (1 << set_params.rate)) == 0 {
-                                error!("PCM frame rate {} is not supported.", set_params.rate);
+                                error!(
+                                    "[Card {}] PCM frame rate {} is not supported.",
+                                    card_index, set_params.rate
+                                );
                                 return writer
                                     .write_obj(VIRTIO_SND_S_NOT_SUPP)
                                     .map_err(Error::WriteResponse);
@@ -821,7 +851,8 @@ pub async fn handle_ctrl_queue(
                         }
                         None => {
                             error!(
-                                "stream_id {} < streams {}",
+                                "[Card {}] stream_id {} < streams {}",
+                                card_index,
                                 stream_id,
                                 snd_data.pcm_info.len()
                             );
@@ -832,7 +863,7 @@ pub async fn handle_ctrl_queue(
                     };
 
                     if set_params.features != 0 {
-                        error!("No feature is supported");
+                        error!("[Card {}] No feature is supported", card_index);
                         return writer
                             .write_obj(VIRTIO_SND_S_NOT_SUPP)
                             .map_err(Error::WriteResponse);
@@ -840,8 +871,8 @@ pub async fn handle_ctrl_queue(
 
                     if buffer_bytes % period_bytes != 0 {
                         error!(
-                            "buffer_bytes({}) must be dividable by period_bytes({})",
-                            buffer_bytes, period_bytes
+                            "[Card {}] buffer_bytes({}) must be dividable by period_bytes({})",
+                            card_index, buffer_bytes, period_bytes
                         );
                         return writer
                             .write_obj(VIRTIO_SND_S_BAD_MSG)
@@ -856,6 +887,7 @@ pub async fn handle_ctrl_queue(
                         VirtioSndPcmCmd::with_set_params_and_direction(set_params, dir),
                         writer,
                         stream_id,
+                        card_index,
                     )
                     .await
                 }
@@ -868,19 +900,24 @@ pub async fn handle_ctrl_queue(
                     let cmd = match VirtioSndPcmCmd::try_from(code) {
                         Ok(cmd) => cmd,
                         Err(err) => {
-                            error!("Error converting code to command: {}", err);
+                            error!(
+                                "[Card {}] Error converting code to command: {}",
+                                card_index, err
+                            );
                             return writer
                                 .write_obj(VIRTIO_SND_S_BAD_MSG)
                                 .map_err(Error::WriteResponse);
                         }
                     };
-                    process_pcm_ctrl(ex, &tx_send, &rx_send, streams, cmd, writer, stream_id)
-                        .await
-                        .and(Ok(()))?;
+                    process_pcm_ctrl(
+                        ex, &tx_send, &rx_send, streams, cmd, writer, stream_id, card_index,
+                    )
+                    .await
+                    .and(Ok(()))?;
                     Ok(())
                 }
                 c => {
-                    error!("Unrecognized code: {}", c);
+                    error!("[Card {}] Unrecognized code: {}", card_index, c);
                     return writer
                         .write_obj(VIRTIO_SND_S_BAD_MSG)
                         .map_err(Error::WriteResponse);
@@ -891,7 +928,7 @@ pub async fn handle_ctrl_queue(
         handle_ctrl_msg.await?;
         let len = writer.bytes_written() as u32;
         queue.add_used(desc_chain, len);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
     Ok(())
 }
@@ -900,7 +937,6 @@ pub async fn handle_ctrl_queue(
 pub async fn handle_event_queue(
     mut queue: Queue,
     mut queue_event: EventAsync,
-    interrupt: Interrupt,
 ) -> Result<(), Error> {
     loop {
         let desc_chain = queue
@@ -910,6 +946,6 @@ pub async fn handle_event_queue(
 
         // TODO(woodychow): Poll and forward events from cras asynchronously (API to be added)
         queue.add_used(desc_chain, 0);
-        queue.trigger_interrupt(&interrupt);
+        queue.trigger_interrupt();
     }
 }
diff --git a/devices/src/virtio/snd/common_backend/mod.rs b/devices/src/virtio/snd/common_backend/mod.rs
index f15508ef5..9620717e4 100644
--- a/devices/src/virtio/snd/common_backend/mod.rs
+++ b/devices/src/virtio/snd/common_backend/mod.rs
@@ -34,7 +34,6 @@ use futures::future::FusedFuture;
 use futures::join;
 use futures::pin_mut;
 use futures::select;
-use futures::Future;
 use futures::FutureExt;
 use serde::Deserialize;
 use serde::Serialize;
@@ -205,6 +204,7 @@ pub struct VirtioSnd {
     worker_thread: Option<WorkerThread<Result<WorkerReturn, String>>>,
     keep_rds: Vec<Descriptor>,
     streams_state: Option<Vec<StreamInfoSnapshot>>,
+    card_index: usize,
 }
 
 #[derive(Serialize, Deserialize)]
@@ -224,7 +224,8 @@ impl VirtioSnd {
         let avail_features = base_features;
         let mut keep_rds: Vec<RawDescriptor> = Vec::new();
 
-        let stream_info_builders = create_stream_info_builders(&params, &snd_data, &mut keep_rds)?;
+        let stream_info_builders =
+            create_stream_info_builders(&params, &snd_data, &mut keep_rds, params.card_index)?;
 
         Ok(VirtioSnd {
             cfg,
@@ -236,6 +237,7 @@ impl VirtioSnd {
             worker_thread: None,
             keep_rds: keep_rds.iter().map(|rd| Descriptor(*rd)).collect(),
             streams_state: None,
+            card_index: params.card_index,
         })
     }
 }
@@ -265,6 +267,7 @@ pub(crate) fn create_stream_info_builders(
     params: &Parameters,
     snd_data: &SndData,
     keep_rds: &mut Vec<RawDescriptor>,
+    card_index: usize,
 ) -> Result<Vec<StreamInfoBuilder>, Error> {
     Ok(create_stream_source_generators(params, snd_data, keep_rds)?
         .into_iter()
@@ -272,7 +275,8 @@ pub(crate) fn create_stream_info_builders(
         .zip(snd_data.pcm_info_iter())
         .map(|(generator, pcm_info)| {
             let device_params = params.get_device_params(pcm_info).unwrap_or_default();
-            StreamInfo::builder(generator).effects(device_params.effects.unwrap_or_default())
+            StreamInfo::builder(generator, card_index)
+                .effects(device_params.effects.unwrap_or_default())
         })
         .collect())
 }
@@ -453,6 +457,7 @@ impl VirtioDevice for VirtioSnd {
         let snd_data = self.snd_data.clone();
         let stream_info_builders = self.stream_info_builders.to_vec();
         let streams_state = self.streams_state.take();
+        let card_index = self.card_index;
         self.worker_thread = Some(WorkerThread::start("v_snd_common", move |kill_evt| {
             let _thread_priority_handle = set_audio_thread_priority();
             if let Err(e) = _thread_priority_handle {
@@ -465,6 +470,7 @@ impl VirtioDevice for VirtioSnd {
                 kill_evt,
                 stream_info_builders,
                 streams_state,
+                card_index,
             )
         }));
 
@@ -568,6 +574,7 @@ fn run_worker(
     kill_evt: Event,
     stream_info_builders: Vec<StreamInfoBuilder>,
     streams_state: Option<Vec<StreamInfoSnapshot>>,
+    card_index: usize,
 ) -> Result<WorkerReturn, String> {
     let ex = Executor::new().expect("Failed to create an executor");
 
@@ -650,7 +657,6 @@ fn run_worker(
         if run_worker_once(
             &ex,
             &streams,
-            interrupt.clone(),
             &snd_data,
             &mut f_kill,
             &mut f_resample,
@@ -664,6 +670,7 @@ fn run_worker(
             &rx_queue_evt,
             rx_send.clone(),
             &mut rx_recv,
+            card_index,
         ) == LoopState::Break
         {
             break;
@@ -672,7 +679,6 @@ fn run_worker(
         if let Err(e) = reset_streams(
             &ex,
             &streams,
-            interrupt.clone(),
             &tx_queue,
             &mut tx_recv,
             &rx_queue,
@@ -736,10 +742,9 @@ async fn notify_reset_signal(reset_signal: &(AsyncRwLock<bool>, Condvar)) {
 fn run_worker_once(
     ex: &Executor,
     streams: &Rc<AsyncRwLock<Vec<AsyncRwLock<StreamInfo>>>>,
-    interrupt: Interrupt,
     snd_data: &SndData,
-    mut f_kill: &mut (impl Future<Output = anyhow::Result<()>> + FusedFuture + Unpin),
-    mut f_resample: &mut (impl Future<Output = anyhow::Result<()>> + FusedFuture + Unpin),
+    mut f_kill: &mut (impl FusedFuture<Output = anyhow::Result<()>> + Unpin),
+    mut f_resample: &mut (impl FusedFuture<Output = anyhow::Result<()>> + Unpin),
     ctrl_queue: Rc<AsyncRwLock<Queue>>,
     ctrl_queue_evt: &mut EventAsync,
     tx_queue: Rc<AsyncRwLock<Queue>>,
@@ -750,6 +755,7 @@ fn run_worker_once(
     rx_queue_evt: &EventAsync,
     rx_send: mpsc::UnboundedSender<PcmResponse>,
     rx_recv: &mut mpsc::UnboundedReceiver<PcmResponse>,
+    card_index: usize,
 ) -> LoopState {
     let tx_send2 = tx_send.clone();
     let rx_send2 = rx_send.clone();
@@ -762,9 +768,9 @@ fn run_worker_once(
         snd_data,
         ctrl_queue,
         ctrl_queue_evt,
-        interrupt.clone(),
         tx_send,
         rx_send,
+        card_index,
         Some(&reset_signal),
     )
     .fuse();
@@ -781,21 +787,21 @@ fn run_worker_once(
         tx_send2,
         tx_queue.clone(),
         tx_queue_evt,
+        card_index,
         Some(&reset_signal),
     )
     .fuse();
-    let f_tx_response =
-        send_pcm_response_worker(tx_queue, interrupt.clone(), tx_recv, Some(&reset_signal)).fuse();
+    let f_tx_response = send_pcm_response_worker(tx_queue, tx_recv, Some(&reset_signal)).fuse();
     let f_rx = handle_pcm_queue(
         streams,
         rx_send2,
         rx_queue.clone(),
         rx_queue_evt,
+        card_index,
         Some(&reset_signal),
     )
     .fuse();
-    let f_rx_response =
-        send_pcm_response_worker(rx_queue, interrupt, rx_recv, Some(&reset_signal)).fuse();
+    let f_rx_response = send_pcm_response_worker(rx_queue, rx_recv, Some(&reset_signal)).fuse();
 
     pin_mut!(f_ctrl, f_tx, f_tx_response, f_rx, f_rx_response);
 
@@ -858,7 +864,6 @@ fn run_worker_once(
 fn reset_streams(
     ex: &Executor,
     streams: &Rc<AsyncRwLock<Vec<AsyncRwLock<StreamInfo>>>>,
-    interrupt: Interrupt,
     tx_queue: &Rc<AsyncRwLock<Queue>>,
     tx_recv: &mut mpsc::UnboundedReceiver<PcmResponse>,
     rx_queue: &Rc<AsyncRwLock<Queue>>,
@@ -890,26 +895,16 @@ fn reset_streams(
 
     // Run these in a loop to ensure that they will survive until do_reset is finished
     let f_tx_response = async {
-        while send_pcm_response_worker(
-            tx_queue.clone(),
-            interrupt.clone(),
-            tx_recv,
-            Some(&reset_signal),
-        )
-        .await
-        .is_err()
+        while send_pcm_response_worker(tx_queue.clone(), tx_recv, Some(&reset_signal))
+            .await
+            .is_err()
         {}
     };
 
     let f_rx_response = async {
-        while send_pcm_response_worker(
-            rx_queue.clone(),
-            interrupt.clone(),
-            rx_recv,
-            Some(&reset_signal),
-        )
-        .await
-        .is_err()
+        while send_pcm_response_worker(rx_queue.clone(), rx_recv, Some(&reset_signal))
+            .await
+            .is_err()
         {}
     };
 
diff --git a/devices/src/virtio/snd/common_backend/stream_info.rs b/devices/src/virtio/snd/common_backend/stream_info.rs
index 77022bc3c..bb6d48762 100644
--- a/devices/src/virtio/snd/common_backend/stream_info.rs
+++ b/devices/src/virtio/snd/common_backend/stream_info.rs
@@ -51,6 +51,9 @@ pub struct SetParams {
 pub struct StreamInfoBuilder {
     stream_source_generator: Arc<SysAudioStreamSourceGenerator>,
     effects: Vec<StreamEffect>,
+    card_index: usize,
+    #[cfg(windows)]
+    audio_client_guid: Option<String>,
 }
 
 impl StreamInfoBuilder {
@@ -58,10 +61,17 @@ impl StreamInfoBuilder {
     ///
     /// * `stream_source_generator`: Generator which generates stream source in
     ///   [`StreamInfo::prepare()`].
-    pub fn new(stream_source_generator: Arc<SysAudioStreamSourceGenerator>) -> Self {
+    /// * `card_index`: The ALSA card index.
+    pub fn new(
+        stream_source_generator: Arc<SysAudioStreamSourceGenerator>,
+        card_index: usize,
+    ) -> Self {
         StreamInfoBuilder {
             stream_source_generator,
             effects: vec![],
+            card_index,
+            #[cfg(windows)]
+            audio_client_guid: None,
         }
     }
 
@@ -72,6 +82,12 @@ impl StreamInfoBuilder {
         self
     }
 
+    #[cfg(windows)]
+    pub fn audio_client_guid(mut self, audio_client_guid: Option<String>) -> Self {
+        self.audio_client_guid = audio_client_guid;
+        self
+    }
+
     /// Builds a [`StreamInfo`].
     pub fn build(self) -> StreamInfo {
         self.into()
@@ -103,12 +119,15 @@ pub struct StreamInfo {
     pub sender: Option<mpsc::UnboundedSender<DescriptorChain>>,
     worker_future: Option<Box<dyn Future<Output = Result<(), Error>> + Unpin>>,
     release_signal: Option<Rc<(AsyncRwLock<bool>, Condvar)>>, // Signal worker on release
+    card_index: usize,
     ex: Option<Executor>, // Executor provided on `prepare()`. Used on `drop()`.
     #[cfg(windows)]
     pub(crate) playback_stream_cache: Option<(
         Arc<AsyncRwLock<Box<dyn audio_streams::AsyncPlaybackBufferStream>>>,
         Rc<AsyncRwLock<Box<dyn PlaybackBufferWriter>>>,
     )>,
+    #[cfg(windows)]
+    pub(crate) audio_client_guid: Option<String>,
 }
 
 #[derive(Clone, Serialize, Deserialize)]
@@ -178,9 +197,12 @@ impl From<StreamInfoBuilder> for StreamInfo {
             sender: None,
             worker_future: None,
             release_signal: None,
+            card_index: builder.card_index,
             ex: None,
             #[cfg(windows)]
             playback_stream_cache: None,
+            #[cfg(windows)]
+            audio_client_guid: builder.audio_client_guid,
         }
     }
 }
@@ -190,8 +212,9 @@ impl StreamInfo {
     /// the description of each parameter.
     pub fn builder(
         stream_source_generator: Arc<SysAudioStreamSourceGenerator>,
+        card_index: usize,
     ) -> StreamInfoBuilder {
-        StreamInfoBuilder::new(stream_source_generator)
+        StreamInfoBuilder::new(stream_source_generator, card_index)
     }
 
     /// Sets parameters of the stream, putting it into [`VIRTIO_SND_R_PCM_SET_PARAMS`] state.
@@ -204,7 +227,8 @@ impl StreamInfo {
             && self.state != VIRTIO_SND_R_PCM_RELEASE
         {
             error!(
-                "Invalid PCM state transition from {} to {}",
+                "[Card {}] Invalid PCM state transition from {} to {}",
+                self.card_index,
                 get_virtio_snd_r_pcm_cmd_name(self.state),
                 get_virtio_snd_r_pcm_cmd_name(VIRTIO_SND_R_PCM_SET_PARAMS)
             );
@@ -244,7 +268,8 @@ impl StreamInfo {
             && self.state != VIRTIO_SND_R_PCM_RELEASE
         {
             error!(
-                "Invalid PCM state transition from {} to {}",
+                "[Card {}] Invalid PCM state transition from {} to {}",
+                self.card_index,
                 get_virtio_snd_r_pcm_cmd_name(self.state),
                 get_virtio_snd_r_pcm_cmd_name(VIRTIO_SND_R_PCM_PREPARE)
             );
@@ -256,7 +281,10 @@ impl StreamInfo {
         }
         let frame_size = self.channels as usize * self.format.sample_bytes();
         if self.period_bytes % frame_size != 0 {
-            error!("period_bytes must be divisible by frame size");
+            error!(
+                "[Card {}] period_bytes must be divisible by frame size",
+                self.card_index
+            );
             return Err(Error::OperationNotSupported);
         }
         self.stream_source = Some(
@@ -266,7 +294,14 @@ impl StreamInfo {
         );
         let stream_objects = match self.direction {
             VIRTIO_SND_D_OUTPUT => SysAsyncStreamObjects {
-                stream: self.create_directionstream_output(frame_size, ex).await?,
+                stream: self
+                    .create_directionstream_output(
+                        frame_size,
+                        #[cfg(windows)]
+                        self.audio_client_guid.clone(),
+                        ex,
+                    )
+                    .await?,
                 pcm_sender: tx_send.clone(),
             },
             VIRTIO_SND_D_INPUT => {
@@ -296,6 +331,7 @@ impl StreamInfo {
             self.status_mutex.clone(),
             stream_objects.pcm_sender,
             period_dur,
+            self.card_index,
             release_signal,
         );
         self.worker_future = Some(Box::new(ex.spawn_local(f).into_future()));
@@ -310,7 +346,8 @@ impl StreamInfo {
         }
         if self.state != VIRTIO_SND_R_PCM_PREPARE && self.state != VIRTIO_SND_R_PCM_STOP {
             error!(
-                "Invalid PCM state transition from {} to {}",
+                "[Card {}] Invalid PCM state transition from {} to {}",
+                self.card_index,
                 get_virtio_snd_r_pcm_cmd_name(self.state),
                 get_virtio_snd_r_pcm_cmd_name(VIRTIO_SND_R_PCM_START)
             );
@@ -331,7 +368,8 @@ impl StreamInfo {
         }
         if self.state != VIRTIO_SND_R_PCM_START {
             error!(
-                "Invalid PCM state transition from {} to {}",
+                "[Card {}] Invalid PCM state transition from {} to {}",
+                self.card_index,
                 get_virtio_snd_r_pcm_cmd_name(self.state),
                 get_virtio_snd_r_pcm_cmd_name(VIRTIO_SND_R_PCM_STOP)
             );
@@ -352,7 +390,8 @@ impl StreamInfo {
         }
         if self.state != VIRTIO_SND_R_PCM_PREPARE && self.state != VIRTIO_SND_R_PCM_STOP {
             error!(
-                "Invalid PCM state transition from {} to {}",
+                "[Card {}] Invalid PCM state transition from {} to {}",
+                self.card_index,
                 get_virtio_snd_r_pcm_cmd_name(self.state),
                 get_virtio_snd_r_pcm_cmd_name(VIRTIO_SND_R_PCM_RELEASE)
             );
@@ -379,7 +418,12 @@ impl StreamInfo {
 
         if let Some(f) = self.worker_future.take() {
             f.await
-                .map_err(|error| warn!("Failure on releasing the worker_future: {}", error))
+                .map_err(|error| {
+                    warn!(
+                        "[Card {}] Failure on releasing the worker_future: {}",
+                        self.card_index, error
+                    )
+                })
                 .ok();
         }
         self.ex.take(); // Remove ex as the worker is finished
@@ -407,7 +451,7 @@ impl StreamInfo {
         self.buffer_bytes = state.buffer_bytes;
         self.period_bytes = state.period_bytes;
         self.direction = state.direction;
-        self.effects = state.effects.clone();
+        self.effects.clone_from(&state.effects);
         self.just_reset = state.just_reset;
     }
 }
@@ -419,7 +463,12 @@ mod tests {
     use super::*;
 
     fn new_stream() -> StreamInfo {
-        StreamInfo::builder(Arc::new(Box::new(NoopStreamSourceGenerator::new()))).build()
+        let card_index = 0;
+        StreamInfo::builder(
+            Arc::new(Box::new(NoopStreamSourceGenerator::new())),
+            card_index,
+        )
+        .build()
     }
 
     fn stream_set_params(
@@ -718,8 +767,12 @@ mod tests {
 
     #[test]
     fn test_stream_info_builder() {
-        let builder = StreamInfo::builder(Arc::new(Box::new(NoopStreamSourceGenerator::new())))
-            .effects(vec![StreamEffect::EchoCancellation]);
+        let card_index = 0;
+        let builder = StreamInfo::builder(
+            Arc::new(Box::new(NoopStreamSourceGenerator::new())),
+            card_index,
+        )
+        .effects(vec![StreamEffect::EchoCancellation]);
 
         let stream = builder.build();
         assert_eq!(stream.effects, vec![StreamEffect::EchoCancellation]);
diff --git a/devices/src/virtio/snd/parameters.rs b/devices/src/virtio/snd/parameters.rs
index b17402dbc..65c5c5ea1 100644
--- a/devices/src/virtio/snd/parameters.rs
+++ b/devices/src/virtio/snd/parameters.rs
@@ -108,6 +108,7 @@ pub struct Parameters {
     pub socket_type: CrasSocketType,
     pub output_device_config: Vec<PCMDeviceParameters>,
     pub input_device_config: Vec<PCMDeviceParameters>,
+    pub card_index: usize,
 }
 
 impl Default for Parameters {
@@ -127,6 +128,7 @@ impl Default for Parameters {
             socket_type: CrasSocketType::Unified,
             output_device_config: vec![],
             input_device_config: vec![],
+            card_index: 0,
         }
     }
 }
diff --git a/devices/src/virtio/snd/sys/windows.rs b/devices/src/virtio/snd/sys/windows.rs
index 93ab06f7c..196223448 100644
--- a/devices/src/virtio/snd/sys/windows.rs
+++ b/devices/src/virtio/snd/sys/windows.rs
@@ -105,6 +105,7 @@ impl StreamInfo {
     async fn set_up_async_playback_stream(
         &mut self,
         frame_size: usize,
+        audio_client_guid: Option<String>,
         ex: &Executor,
     ) -> Result<Box<dyn AsyncPlaybackBufferStream>, Error> {
         let (async_playback_buffer_stream, _) = self
@@ -123,6 +124,7 @@ impl StreamInfo {
                 // Therefore, `buffer_size` in `audio_streams` == `period_bytes` in virtio-snd.
                 self.period_bytes / frame_size,
                 ex,
+                audio_client_guid,
             )
             .map_err(Error::CreateStream)?;
         Ok(async_playback_buffer_stream)
@@ -152,11 +154,13 @@ impl StreamInfo {
     pub(crate) async fn create_directionstream_output(
         &mut self,
         frame_size: usize,
+        audio_client_guid: Option<String>,
         ex: &Executor,
     ) -> Result<DirectionalStream, Error> {
         if self.playback_stream_cache.is_none() {
-            let async_playback_buffer_stream =
-                self.set_up_async_playback_stream(frame_size, ex).await?;
+            let async_playback_buffer_stream = self
+                .set_up_async_playback_stream(frame_size, audio_client_guid, ex)
+                .await?;
 
             let buffer_writer = WinBufferWriter::new(self.period_bytes);
 
diff --git a/devices/src/virtio/snd/vios_backend/streams.rs b/devices/src/virtio/snd/vios_backend/streams.rs
index 30e69e896..a64c4cb8e 100644
--- a/devices/src/virtio/snd/vios_backend/streams.rs
+++ b/devices/src/virtio/snd/vios_backend/streams.rs
@@ -28,7 +28,6 @@ use crate::virtio::snd::common::from_virtio_frame_rate;
 use crate::virtio::snd::constants::*;
 use crate::virtio::snd::layout::*;
 use crate::virtio::DescriptorChain;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 
 /// Messages that the worker can send to the stream (thread).
@@ -58,7 +57,6 @@ pub struct Stream {
     vios_client: Arc<Mutex<VioSClient>>,
     control_queue: Arc<Mutex<Queue>>,
     io_queue: Arc<Mutex<Queue>>,
-    interrupt: Interrupt,
     capture: bool,
     current_state: StreamState,
     period: Duration,
@@ -79,7 +77,6 @@ impl Stream {
     pub fn try_new(
         stream_id: u32,
         vios_client: Arc<Mutex<VioSClient>>,
-        interrupt: Interrupt,
         control_queue: Arc<Mutex<Queue>>,
         io_queue: Arc<Mutex<Queue>>,
         capture: bool,
@@ -111,7 +108,6 @@ impl Stream {
                     vios_client: vios_client.clone(),
                     control_queue,
                     io_queue,
-                    interrupt,
                     capture,
                     current_state,
                     period,
@@ -249,7 +245,7 @@ impl Stream {
                 return Ok(false);
             }
         };
-        reply_control_op_status(code, desc, &self.control_queue, &self.interrupt)?;
+        reply_control_op_status(code, desc, &self.control_queue)?;
         self.current_state = next_state;
         Ok(true)
     }
@@ -310,7 +306,7 @@ impl Stream {
                     {
                         let mut io_queue_lock = self.io_queue.lock();
                         io_queue_lock.add_used(desc, len);
-                        io_queue_lock.trigger_interrupt(&self.interrupt);
+                        io_queue_lock.trigger_interrupt();
                     }
                 }
             }
@@ -322,13 +318,7 @@ impl Stream {
                 // guarantee if a buffer arrives after release is requested. Luckily it seems to
                 // work fine if the buffer is released after the release command is completed.
                 while let Some(desc) = self.buffer_queue.pop_front() {
-                    reply_pcm_buffer_status(
-                        VIRTIO_SND_S_OK,
-                        0,
-                        desc,
-                        &self.io_queue,
-                        &self.interrupt,
-                    )?;
+                    reply_pcm_buffer_status(VIRTIO_SND_S_OK, 0, desc, &self.io_queue)?;
                 }
             }
             StreamState::Prepared => {} // Do nothing, any buffers will be processed after start
@@ -351,13 +341,7 @@ impl Drop for Stream {
 
         // Also release any pending buffer
         while let Some(desc) = self.buffer_queue.pop_front() {
-            if let Err(e) = reply_pcm_buffer_status(
-                VIRTIO_SND_S_IO_ERR,
-                0,
-                desc,
-                &self.io_queue,
-                &self.interrupt,
-            ) {
+            if let Err(e) = reply_pcm_buffer_status(VIRTIO_SND_S_IO_ERR, 0, desc, &self.io_queue) {
                 error!(
                     "virtio-snd: Failed to reply buffer on stream {}: {}",
                     self.stream_id, e
@@ -443,7 +427,6 @@ pub fn reply_control_op_status(
     code: u32,
     mut desc: DescriptorChain,
     queue: &Arc<Mutex<Queue>>,
-    interrupt: &Interrupt,
 ) -> Result<()> {
     let writer = &mut desc.writer;
     writer
@@ -455,7 +438,7 @@ pub fn reply_control_op_status(
     {
         let mut queue_lock = queue.lock();
         queue_lock.add_used(desc, len);
-        queue_lock.trigger_interrupt(interrupt);
+        queue_lock.trigger_interrupt();
     }
     Ok(())
 }
@@ -466,7 +449,6 @@ pub fn reply_pcm_buffer_status(
     latency_bytes: u32,
     mut desc: DescriptorChain,
     queue: &Arc<Mutex<Queue>>,
-    interrupt: &Interrupt,
 ) -> Result<()> {
     let writer = &mut desc.writer;
     if writer.available_bytes() > std::mem::size_of::<virtio_snd_pcm_status>() {
@@ -483,7 +465,7 @@ pub fn reply_pcm_buffer_status(
     {
         let mut queue_lock = queue.lock();
         queue_lock.add_used(desc, len);
-        queue_lock.trigger_interrupt(interrupt);
+        queue_lock.trigger_interrupt();
     }
     Ok(())
 }
diff --git a/devices/src/virtio/snd/vios_backend/worker.rs b/devices/src/virtio/snd/vios_backend/worker.rs
index 5c8df288c..5619dfb67 100644
--- a/devices/src/virtio/snd/vios_backend/worker.rs
+++ b/devices/src/virtio/snd/vios_backend/worker.rs
@@ -67,7 +67,6 @@ impl Worker {
                 streams.push(Stream::try_new(
                     stream_id,
                     vios_client.clone(),
-                    interrupt.clone(),
                     control_queue.clone(),
                     io_queue.clone(),
                     capture,
@@ -79,7 +78,6 @@ impl Worker {
             .and_then(|e| Ok((e.try_clone()?, e)))
             .map_err(SoundError::CreateEvent)?;
 
-        let interrupt_clone = interrupt.clone();
         let senders: Vec<Sender<Box<StreamMsg>>> =
             streams.iter().map(|sp| sp.msg_sender().clone()).collect();
         let tx_queue_thread = tx_queue.clone();
@@ -89,13 +87,7 @@ impl Worker {
             .spawn(move || {
                 try_set_real_time_priority();
 
-                io_loop(
-                    interrupt_clone,
-                    tx_queue_thread,
-                    rx_queue_thread,
-                    senders,
-                    kill_io,
-                )
+                io_loop(tx_queue_thread, rx_queue_thread, senders, kill_io)
             })
             .map_err(SoundError::CreateThread)?;
         Ok(Worker {
@@ -223,7 +215,6 @@ impl Worker {
                     VIRTIO_SND_S_BAD_MSG,
                     avail_desc,
                     &self.control_queue,
-                    &self.interrupt,
                 );
             }
             let mut read_buf = vec![0u8; available_bytes];
@@ -300,7 +291,7 @@ impl Worker {
                     {
                         let mut queue_lock = self.control_queue.lock();
                         queue_lock.add_used(avail_desc, len);
-                        queue_lock.trigger_interrupt(&self.interrupt);
+                        queue_lock.trigger_interrupt();
                     }
                 }
                 VIRTIO_SND_R_CHMAP_INFO => {
@@ -386,7 +377,6 @@ impl Worker {
                         VIRTIO_SND_S_NOT_SUPP,
                         avail_desc,
                         &self.control_queue,
-                        &self.interrupt,
                     )?;
                 }
             }
@@ -401,7 +391,7 @@ impl Worker {
                 writer.write_obj(evt).map_err(SoundError::QueueIO)?;
                 let len = writer.bytes_written() as u32;
                 event_queue.add_used(desc, len);
-                event_queue.trigger_interrupt(&self.interrupt);
+                event_queue.trigger_interrupt();
             } else {
                 warn!("virtio-snd: Dropping event because there are no buffers in virtqueue");
             }
@@ -431,12 +421,7 @@ impl Worker {
                 "virtio-snd: The driver sent a buffer of the wrong size for a set_params struct: {}",
                 read_buf.len()
                 );
-            return reply_control_op_status(
-                VIRTIO_SND_S_BAD_MSG,
-                desc,
-                &self.control_queue,
-                &self.interrupt,
-            );
+            return reply_control_op_status(VIRTIO_SND_S_BAD_MSG, desc, &self.control_queue);
         }
         let mut params: virtio_snd_pcm_set_params = Default::default();
         params.as_bytes_mut().copy_from_slice(read_buf);
@@ -448,12 +433,7 @@ impl Worker {
                 "virtio-snd: Driver requested operation on invalid stream: {}",
                 stream_id
             );
-            reply_control_op_status(
-                VIRTIO_SND_S_BAD_MSG,
-                desc,
-                &self.control_queue,
-                &self.interrupt,
-            )
+            reply_control_op_status(VIRTIO_SND_S_BAD_MSG, desc, &self.control_queue)
         }
     }
 
@@ -474,7 +454,6 @@ impl Worker {
                     _ => panic!("virtio-snd: Can't handle message. This is a BUG!!"),
                 },
                 &self.control_queue,
-                &self.interrupt,
             );
         }
         let mut pcm_hdr: virtio_snd_pcm_hdr = Default::default();
@@ -497,7 +476,6 @@ impl Worker {
                     _ => panic!("virtio-snd: Can't handle message. This is a BUG!!"),
                 },
                 &self.control_queue,
-                &self.interrupt,
             )
         }
     }
@@ -521,7 +499,7 @@ impl Worker {
         {
             let mut queue_lock = self.control_queue.lock();
             queue_lock.add_used(desc, len);
-            queue_lock.trigger_interrupt(&self.interrupt);
+            queue_lock.trigger_interrupt();
         }
         Ok(())
     }
@@ -534,7 +512,6 @@ impl Drop for Worker {
 }
 
 fn io_loop(
-    interrupt: Interrupt,
     tx_queue: Arc<Mutex<Queue>>,
     rx_queue: Arc<Mutex<Queue>>,
     senders: Vec<Sender<Box<StreamMsg>>>,
@@ -587,7 +564,7 @@ fn io_loop(
                         "virtio-snd: Driver sent buffer for invalid stream: {}",
                         stream_id
                     );
-                    reply_pcm_buffer_status(VIRTIO_SND_S_IO_ERR, 0, avail_desc, queue, &interrupt)?;
+                    reply_pcm_buffer_status(VIRTIO_SND_S_IO_ERR, 0, avail_desc, queue)?;
                 } else {
                     StreamProxy::send_msg(
                         &senders[stream_id as usize],
diff --git a/devices/src/virtio/tpm.rs b/devices/src/virtio/tpm.rs
index d81917c73..ca591cd99 100644
--- a/devices/src/virtio/tpm.rs
+++ b/devices/src/virtio/tpm.rs
@@ -98,7 +98,7 @@ impl Worker {
         needs_interrupt
     }
 
-    fn run(mut self, kill_evt: Event) {
+    fn run(mut self, kill_evt: Event) -> anyhow::Result<()> {
         #[derive(EventToken, Debug)]
         enum Token {
             // A request is ready on the queue.
@@ -109,50 +109,35 @@ impl Worker {
             Kill,
         }
 
-        let wait_ctx = match WaitContext::build_with(&[
+        let wait_ctx = WaitContext::build_with(&[
             (self.queue.event(), Token::QueueAvailable),
             (&kill_evt, Token::Kill),
         ])
-        .and_then(|wc| {
-            if let Some(resample_evt) = self.interrupt.get_resample_evt() {
-                wc.add(resample_evt, Token::InterruptResample)?;
-            }
-            Ok(wc)
-        }) {
-            Ok(pc) => pc,
-            Err(e) => {
-                error!("vtpm failed creating WaitContext: {}", e);
-                return;
-            }
-        };
+        .context("WaitContext::build_with")?;
 
-        'wait: loop {
-            let events = match wait_ctx.wait() {
-                Ok(v) => v,
-                Err(e) => {
-                    error!("vtpm failed waiting for events: {}", e);
-                    break;
-                }
-            };
+        if let Some(resample_evt) = self.interrupt.get_resample_evt() {
+            wait_ctx
+                .add(resample_evt, Token::InterruptResample)
+                .context("WaitContext::add")?;
+        }
 
+        loop {
+            let events = wait_ctx.wait().context("WaitContext::wait")?;
             let mut needs_interrupt = NeedsInterrupt::No;
             for event in events.iter().filter(|e| e.is_readable) {
                 match event.token {
                     Token::QueueAvailable => {
-                        if let Err(e) = self.queue.event().wait() {
-                            error!("vtpm failed reading queue Event: {}", e);
-                            break 'wait;
-                        }
+                        self.queue.event().wait().context("Event::wait")?;
                         needs_interrupt |= self.process_queue();
                     }
                     Token::InterruptResample => {
                         self.interrupt.interrupt_resample();
                     }
-                    Token::Kill => break 'wait,
+                    Token::Kill => return Ok(()),
                 }
             }
             if needs_interrupt == NeedsInterrupt::Yes {
-                self.queue.trigger_interrupt(&self.interrupt);
+                self.queue.trigger_interrupt();
             }
         }
     }
@@ -212,7 +197,9 @@ impl VirtioDevice for Tpm {
         };
 
         self.worker_thread = Some(WorkerThread::start("v_tpm", |kill_evt| {
-            worker.run(kill_evt)
+            if let Err(e) = worker.run(kill_evt) {
+                error!("virtio-tpm worker failed: {:#}", e);
+            }
         }));
 
         Ok(())
diff --git a/devices/src/virtio/vhost/net.rs b/devices/src/virtio/vhost/net.rs
index 39ccbb30e..e9d97f5ce 100644
--- a/devices/src/virtio/vhost/net.rs
+++ b/devices/src/virtio/vhost/net.rs
@@ -397,6 +397,9 @@ pub mod tests {
     #[test]
     fn features() {
         let net = create_net_common();
+        // Feature bits 0-23 and 50-127 are specific for the device type, but
+        // at the moment crosvm only supports 64 bits of feature bits.
+        const DEVICE_FEATURE_BITS: u64 = 0xffffff;
         let expected_features = 1 << 0 // VIRTIO_NET_F_CSUM
             | 1 << 1 // VIRTIO_NET_F_GUEST_CSUM
             | 1 << 5 // VIRTIO_NET_F_MAC
@@ -404,10 +407,8 @@ pub mod tests {
             | 1 << 10 // VIRTIO_NET_F_GUEST_UFO
             | 1 << 11 // VIRTIO_NET_F_HOST_TSO4
             | 1 << 14 // VIRTIO_NET_F_HOST_UFO
-            | 1 << 15 // VIRTIO_NET_F_MRG_RXBUF
-            | 1 << 29 // VIRTIO_RING_F_EVENT_IDX
-            | 1 << 32; // VIRTIO_F_VERSION_1
-        assert_eq!(net.features(), expected_features);
+            | 1 << 15; // VIRTIO_NET_F_MRG_RXBUF
+        assert_eq!(net.features() & DEVICE_FEATURE_BITS, expected_features);
     }
 
     #[test]
@@ -422,24 +423,21 @@ pub mod tests {
     fn activate() {
         let mut net = create_net_common();
         let guest_memory = create_guest_memory().unwrap();
+        let interrupt = Interrupt::new_for_test();
 
         let mut q0 = QueueConfig::new(1, 0);
         q0.set_ready(true);
         let q0 = q0
-            .activate(&guest_memory, Event::new().unwrap())
+            .activate(&guest_memory, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
         let mut q1 = QueueConfig::new(1, 0);
         q1.set_ready(true);
         let q1 = q1
-            .activate(&guest_memory, Event::new().unwrap())
+            .activate(&guest_memory, Event::new().unwrap(), interrupt.clone())
             .expect("QueueConfig::activate");
 
         // Just testing that we don't panic, for now
-        let _ = net.activate(
-            guest_memory,
-            Interrupt::new_for_test(),
-            BTreeMap::from([(0, q0), (1, q1)]),
-        );
+        let _ = net.activate(guest_memory, interrupt, BTreeMap::from([(0, q0), (1, q1)]));
     }
 }
diff --git a/devices/src/virtio/vhost/user/device/block.rs b/devices/src/virtio/vhost/user/device/block.rs
index df3def6fa..5316f9065 100644
--- a/devices/src/virtio/vhost/user/device/block.rs
+++ b/devices/src/virtio/vhost/user/device/block.rs
@@ -4,8 +4,6 @@
 
 mod sys;
 
-use anyhow::anyhow;
-use anyhow::bail;
 use anyhow::Context;
 use cros_async::Executor;
 use serde::Deserialize;
@@ -20,7 +18,6 @@ use crate::virtio::block::asynchronous::BlockAsync;
 use crate::virtio::vhost::user::device::handler::DeviceRequestHandler;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
 use crate::virtio::vhost::user::device::VhostUserDeviceBuilder;
-use crate::virtio::Interrupt;
 use crate::virtio::VirtioDevice;
 
 const NUM_QUEUES: u16 = 16;
@@ -29,17 +26,13 @@ struct BlockBackend {
     inner: Box<BlockAsync>,
 
     avail_features: u64,
-    acked_features: u64,
-    acked_protocol_features: VhostUserProtocolFeatures,
 }
 
 #[derive(Serialize, Deserialize)]
 struct BlockBackendSnapshot {
-    acked_features: u64,
-    // `avail_features` and `acked_protocol_features` don't need to be snapshotted, but they are
+    // `avail_features` don't need to be snapshotted, but they are
     // to be used to make sure that the proper features are used on `restore`.
     avail_features: u64,
-    acked_protocol_features: u64,
 }
 
 impl VhostUserDeviceBuilder for BlockAsync {
@@ -48,8 +41,6 @@ impl VhostUserDeviceBuilder for BlockAsync {
         let backend = BlockBackend {
             inner: self,
             avail_features,
-            acked_features: 0,
-            acked_protocol_features: VhostUserProtocolFeatures::empty(),
         };
         let handler = DeviceRequestHandler::new(backend);
         Ok(Box::new(handler))
@@ -65,37 +56,11 @@ impl VhostUserDevice for BlockBackend {
         self.avail_features
     }
 
-    fn ack_features(&mut self, value: u64) -> anyhow::Result<()> {
-        let unrequested_features = value & !self.avail_features;
-        if unrequested_features != 0 {
-            bail!("invalid features are given: {:#x}", unrequested_features);
-        }
-
-        self.acked_features |= value;
-
-        Ok(())
-    }
-
-    fn acked_features(&self) -> u64 {
-        self.acked_features
-    }
-
     fn protocol_features(&self) -> VhostUserProtocolFeatures {
         VhostUserProtocolFeatures::CONFIG
             | VhostUserProtocolFeatures::MQ
             | VhostUserProtocolFeatures::BACKEND_REQ
-    }
-
-    fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-        let features = VhostUserProtocolFeatures::from_bits(features)
-            .ok_or_else(|| anyhow!("invalid protocol features are given: {:#x}", features))?;
-        let supported = self.protocol_features();
-        self.acked_protocol_features = features & supported;
-        Ok(())
-    }
-
-    fn acked_protocol_features(&self) -> u64 {
-        self.acked_protocol_features.bits()
+            | VhostUserProtocolFeatures::DEVICE_STATE
     }
 
     fn read_config(&self, offset: u64, data: &mut [u8]) {
@@ -113,51 +78,39 @@ impl VhostUserDevice for BlockBackend {
         idx: usize,
         queue: virtio::Queue,
         mem: GuestMemory,
-        doorbell: Interrupt,
     ) -> anyhow::Result<()> {
-        self.inner.start_queue(idx, queue, mem, doorbell)
+        self.inner.start_queue(idx, queue, mem)
     }
 
     fn stop_queue(&mut self, idx: usize) -> anyhow::Result<virtio::Queue> {
         self.inner.stop_queue(idx)
     }
 
-    fn stop_non_queue_workers(&mut self) -> anyhow::Result<()> {
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
         // TODO: This assumes that `reset` only stops workers which might not be true in the
         // future. Consider moving the `reset` code into a `stop_all_workers` method or, maybe,
         // make `stop_queue` implicitly stop a worker thread when there is no active queue.
-        self.inner.reset()
+        self.inner.reset()?;
+        Ok(())
     }
 
-    fn snapshot(&self) -> anyhow::Result<Vec<u8>> {
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
         // The queue states are being snapshotted in the device handler.
-        let serialized_bytes = serde_json::to_vec(&BlockBackendSnapshot {
-            acked_features: self.acked_features,
+        serde_json::to_value(BlockBackendSnapshot {
             avail_features: self.avail_features,
-            acked_protocol_features: self.acked_protocol_features.bits(),
         })
-        .context("Failed to serialize BlockBackendSnapshot")?;
-
-        Ok(serialized_bytes)
+        .context("Failed to serialize BlockBackendSnapshot")
     }
 
-    fn restore(&mut self, data: Vec<u8>) -> anyhow::Result<()> {
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
         let block_backend_snapshot: BlockBackendSnapshot =
-            serde_json::from_slice(&data).context("Failed to deserialize BlockBackendSnapshot")?;
+            serde_json::from_value(data).context("Failed to deserialize BlockBackendSnapshot")?;
         anyhow::ensure!(
             self.avail_features == block_backend_snapshot.avail_features,
             "Vhost user block restored avail_features do not match. Live: {:?}, snapshot: {:?}",
             self.avail_features,
             block_backend_snapshot.avail_features,
         );
-        anyhow::ensure!(
-            self.acked_protocol_features.bits() == block_backend_snapshot.acked_protocol_features,
-            "Vhost user block restored acked_protocol_features do not match. Live: {:?}, \
-            snapshot: {:?}",
-            self.acked_protocol_features,
-            block_backend_snapshot.acked_protocol_features
-        );
-        self.acked_features = block_backend_snapshot.acked_features;
         Ok(())
     }
 }
diff --git a/devices/src/virtio/vhost/user/device/block/sys/linux.rs b/devices/src/virtio/vhost/user/device/block/sys/linux.rs
index 9b6cfcd8a..77dd55ee2 100644
--- a/devices/src/virtio/vhost/user/device/block/sys/linux.rs
+++ b/devices/src/virtio/vhost/user/device/block/sys/linux.rs
@@ -10,8 +10,8 @@ use hypervisor::ProtectionType;
 
 use crate::virtio::base_features;
 use crate::virtio::block::DiskOption;
-use crate::virtio::vhost::user::device::listener::sys::VhostUserListener;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
+use crate::virtio::vhost::user::device::connection::sys::VhostUserListener;
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::BlockAsync;
 
 #[derive(FromArgs)]
@@ -50,7 +50,7 @@ pub fn start_device(opts: Options) -> anyhow::Result<()> {
         None,
     )?);
 
-    let listener = VhostUserListener::new_socket(&opts.socket, None)?;
+    let listener = VhostUserListener::new(&opts.socket)?;
     info!("vhost-user disk device ready, starting run loop...");
 
     listener.run_device(ex, block)
diff --git a/devices/src/virtio/vhost/user/device/block/sys/windows.rs b/devices/src/virtio/vhost/user/device/block/sys/windows.rs
index 0aa56707f..3dd73f22f 100644
--- a/devices/src/virtio/vhost/user/device/block/sys/windows.rs
+++ b/devices/src/virtio/vhost/user/device/block/sys/windows.rs
@@ -67,9 +67,7 @@ pub fn start_device(opts: Options) -> anyhow::Result<()> {
 
     info!("using {:?} executor.", disk_option.async_executor);
 
-    let kind = disk_option
-        .async_executor
-        .unwrap_or(ExecutorKindSys::Handle.into());
+    let kind = disk_option.async_executor.unwrap_or_default();
     let ex = Executor::with_executor_kind(kind).context("failed to create executor")?;
 
     let block = Box::new(BlockAsync::new(
diff --git a/devices/src/virtio/vhost/user/device/listener.rs b/devices/src/virtio/vhost/user/device/connection.rs
similarity index 69%
rename from devices/src/virtio/vhost/user/device/listener.rs
rename to devices/src/virtio/vhost/user/device/connection.rs
index 22becbd33..620f51518 100644
--- a/devices/src/virtio/vhost/user/device/listener.rs
+++ b/devices/src/virtio/vhost/user/device/connection.rs
@@ -6,42 +6,30 @@ pub mod sys;
 use std::any::Any;
 use std::pin::Pin;
 
-use base::RawDescriptor;
 use cros_async::Executor;
 use futures::Future;
-pub use sys::VhostUserListener;
 
 use crate::virtio::vhost::user::device::handler::DeviceRequestHandler;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
 use crate::virtio::vhost::user::VhostUserDeviceBuilder;
 
-/// Trait that the platform-specific type `VhostUserListener` needs to implement. It contains all
+/// Trait that the platform-specific type `VhostUserConnection` needs to implement. It contains all
 /// the methods that are ok to call from non-platform specific code.
-pub trait VhostUserListenerTrait {
-    /// Creates a VhostUserListener from `path`, which is a platform-specific string describing how
-    /// to establish the vhost-user channel. For instance, it can be a path to a socket.
-    ///
-    /// `keep_rds` is a vector of `RawDescriptor`s to which the descriptors needed for this listener
-    /// to operate properly will be added if it is `Some()`.
-    fn new(
-        path: &str,
-        keep_rds: Option<&mut Vec<RawDescriptor>>,
-    ) -> anyhow::Result<VhostUserListener>;
-
+pub trait VhostUserConnectionTrait {
     /// Take and return resources owned by the parent process in case of a incoming fork.
     ///
-    /// This method needs to be called only if you are going to use the listener in a jailed child
-    /// process. In this case, the listener will belong to the child and the parent will drop it,
+    /// This method needs to be called only if you are going to use the connection in a jailed child
+    /// process. In this case, the connection will belong to the child and the parent will drop it,
     /// but the child may lack the rights to drop some resources created at construction time. One
     /// such example is the socket file of a regular vhost-user device, that cannot be dropped by
     /// the child unless it gets extra permissions.
     ///
     /// This method returns an opaque object that, upon being dropped, will free these resources.
     /// That way, the child process does not need extra rights to clear them, and the parent can
-    /// drop the listener after forking and just need to keep that object alive until the child
+    /// drop the connection after forking and just need to keep that object alive until the child
     /// exits to do housekeeping properly.
     ///
-    /// The default implementation returns nothing as that's what most listeners would need anyway.
+    /// The default implementation returns nothing as that's what most connection would need anyway.
     fn take_parent_process_resources(&mut self) -> Option<Box<dyn Any>> {
         None
     }
@@ -69,8 +57,8 @@ pub trait VhostUserListenerTrait {
         self.run_req_handler(Box::new(DeviceRequestHandler::new(backend)), ex)
     }
 
-    /// Start processing requests for a `VhostUserDevice` on `listener`. Returns when the front-end
-    /// side disconnects or an error occurs.
+    /// Start processing requests for a `VhostUserDevice` on `connection`. Returns when the
+    /// front-end side disconnects or an error occurs.
     fn run_device(self, ex: Executor, device: Box<dyn VhostUserDeviceBuilder>) -> anyhow::Result<()>
     where
         Self: Sized,
diff --git a/devices/src/virtio/vhost/user/device/listener/sys.rs b/devices/src/virtio/vhost/user/device/connection/sys.rs
similarity index 92%
rename from devices/src/virtio/vhost/user/device/listener/sys.rs
rename to devices/src/virtio/vhost/user/device/connection/sys.rs
index 4996e3ef0..f41d6d916 100644
--- a/devices/src/virtio/vhost/user/device/listener/sys.rs
+++ b/devices/src/virtio/vhost/user/device/connection/sys.rs
@@ -13,3 +13,4 @@ cfg_if::cfg_if! {
 }
 
 pub use platform::VhostUserListener;
+pub use platform::VhostUserStream;
diff --git a/x86_64/tests/integration/sys.rs b/devices/src/virtio/vhost/user/device/connection/sys/linux.rs
similarity index 57%
rename from x86_64/tests/integration/sys.rs
rename to devices/src/virtio/vhost/user/device/connection/sys/linux.rs
index e70ead595..1fe06ab8b 100644
--- a/x86_64/tests/integration/sys.rs
+++ b/devices/src/virtio/vhost/user/device/connection/sys/linux.rs
@@ -2,8 +2,8 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-cfg_if::cfg_if! {
-    if #[cfg(any(target_os = "android", target_os = "linux"))] {
-        mod linux;
-    }
-}
+mod listener;
+mod stream;
+
+pub use listener::VhostUserListener;
+pub use stream::VhostUserStream;
diff --git a/devices/src/virtio/vhost/user/device/listener/sys/linux.rs b/devices/src/virtio/vhost/user/device/connection/sys/linux/listener.rs
similarity index 74%
rename from devices/src/virtio/vhost/user/device/listener/sys/linux.rs
rename to devices/src/virtio/vhost/user/device/connection/sys/linux/listener.rs
index a8a444a62..f56dba9ac 100644
--- a/devices/src/virtio/vhost/user/device/listener/sys/linux.rs
+++ b/devices/src/virtio/vhost/user/device/connection/sys/linux/listener.rs
@@ -1,4 +1,4 @@
-// Copyright 2022 The ChromiumOS Authors
+// Copyright 2024 The ChromiumOS Authors
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
@@ -15,30 +15,27 @@ use vmm_vhost::connection::Listener;
 use vmm_vhost::unix::SocketListener;
 use vmm_vhost::BackendServer;
 
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::handler::sys::linux::run_handler;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
 
 /// On Unix we can listen to a socket.
 pub struct VhostUserListener(SocketListener);
 
 impl VhostUserListener {
-    /// Creates a new regular vhost-user listener, listening on `path`.
-    ///
-    /// `keep_rds` can be specified to retrieve the raw descriptors that must be preserved for this
-    /// listener to keep working after forking.
-    pub fn new_socket(
-        path: &str,
-        keep_rds: Option<&mut Vec<RawDescriptor>>,
-    ) -> anyhow::Result<Self> {
+    /// Create a vhost-user listener from a UNIX domain socket path.
+    pub fn new(path: &str) -> anyhow::Result<Self> {
         let listener = SocketListener::new(path, true)?;
-        if let Some(rds) = keep_rds {
-            rds.push(listener.as_raw_descriptor());
-        }
 
         Ok(VhostUserListener(listener))
     }
 }
 
+impl AsRawDescriptor for VhostUserListener {
+    fn as_raw_descriptor(&self) -> RawDescriptor {
+        self.0.as_raw_descriptor()
+    }
+}
+
 /// Attaches to an already bound socket via `listener` and handles incoming messages from the
 /// VMM, which are dispatched to the device backend via the `VhostUserDevice` trait methods.
 async fn run_with_handler(
@@ -74,15 +71,7 @@ async fn run_with_handler(
     }
 }
 
-impl VhostUserListenerTrait for VhostUserListener {
-    /// Create a vhost-user listener from a UNIX domain socket path.
-    ///
-    /// `keep_rds` can be specified to retrieve the raw descriptors that must be preserved for this
-    /// listener to keep working after forking.
-    fn new(path: &str, keep_rds: Option<&mut Vec<RawDescriptor>>) -> anyhow::Result<Self> {
-        Self::new_socket(path, keep_rds)
-    }
-
+impl VhostUserConnectionTrait for VhostUserListener {
     fn run_req_handler<'e>(
         self,
         handler: Box<dyn vmm_vhost::Backend>,
diff --git a/devices/src/virtio/vhost/user/device/connection/sys/linux/stream.rs b/devices/src/virtio/vhost/user/device/connection/sys/linux/stream.rs
new file mode 100644
index 000000000..31efd5d78
--- /dev/null
+++ b/devices/src/virtio/vhost/user/device/connection/sys/linux/stream.rs
@@ -0,0 +1,84 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::fs;
+use std::os::unix::fs::FileTypeExt;
+use std::os::unix::net::UnixStream;
+use std::path::Path;
+use std::path::PathBuf;
+use std::pin::Pin;
+
+use base::safe_descriptor_from_cmdline_fd;
+use base::AsRawDescriptor;
+use base::RawDescriptor;
+use cros_async::Executor;
+use futures::Future;
+use futures::FutureExt;
+use vmm_vhost::BackendServer;
+use vmm_vhost::Connection;
+use vmm_vhost::Error::SocketFromFdError;
+
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
+use crate::virtio::vhost::user::device::handler::sys::linux::run_handler;
+
+/// Connection from connected socket
+pub struct VhostUserStream(UnixStream);
+
+fn path_is_socket(path: &Path) -> bool {
+    match fs::metadata(path) {
+        Ok(metadata) => metadata.file_type().is_socket(),
+        Err(_) => false, // Assume not a socket if we can't get metadata
+    }
+}
+
+impl VhostUserStream {
+    /// Creates a new vhost-user listener from an existing connected socket file descriptor.
+    ///
+    /// `keep_rds` can be specified to retrieve the raw descriptor that must be preserved for this
+    /// listener to keep working after forking.
+    ///
+    /// # Errors
+    ///
+    /// Returns an error if:
+    /// - The provided file descriptor is not a socket.
+    /// - An error occurs while creating the underlying `SocketListener`.
+    pub fn new_socket_from_fd(
+        socket_fd: RawDescriptor,
+        keep_rds: Option<&mut Vec<RawDescriptor>>,
+    ) -> anyhow::Result<Self> {
+        let path = PathBuf::from(format!("/proc/self/fd/{}", socket_fd));
+        if !path_is_socket(&path) {
+            return Err(SocketFromFdError(path).into());
+        }
+
+        let safe_fd = safe_descriptor_from_cmdline_fd(&socket_fd)?;
+
+        if let Some(rds) = keep_rds {
+            rds.push(safe_fd.as_raw_descriptor());
+        }
+
+        let stream = UnixStream::from(safe_fd);
+
+        Ok(VhostUserStream(stream))
+    }
+}
+
+impl VhostUserConnectionTrait for VhostUserStream {
+    fn run_req_handler<'e>(
+        self,
+        handler: Box<dyn vmm_vhost::Backend>,
+        ex: &'e Executor,
+    ) -> Pin<Box<dyn Future<Output = anyhow::Result<()>> + 'e>> {
+        async { stream_run_with_handler(self.0, handler, ex).await }.boxed_local()
+    }
+}
+
+async fn stream_run_with_handler(
+    stream: UnixStream,
+    handler: Box<dyn vmm_vhost::Backend>,
+    ex: &Executor,
+) -> anyhow::Result<()> {
+    let req_handler = BackendServer::new(Connection::try_from(stream)?, handler);
+    run_handler(req_handler, ex).await
+}
diff --git a/devices/src/virtio/vhost/user/device/listener/sys/windows.rs b/devices/src/virtio/vhost/user/device/connection/sys/windows.rs
similarity index 66%
rename from devices/src/virtio/vhost/user/device/listener/sys/windows.rs
rename to devices/src/virtio/vhost/user/device/connection/sys/windows.rs
index 890ec1094..422c73227 100644
--- a/devices/src/virtio/vhost/user/device/listener/sys/windows.rs
+++ b/devices/src/virtio/vhost/user/device/connection/sys/windows.rs
@@ -8,19 +8,26 @@ use base::RawDescriptor;
 use cros_async::Executor;
 use futures::Future;
 
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
 
 /// TODO implement this. On Windows the `vhost_user_tube` can be provided through the `path`
 /// constructor string, and the future returned by `run_backend` can be listened to alonside the
 /// close and exit events.
 pub struct VhostUserListener;
+pub struct VhostUserStream;
 
-impl VhostUserListenerTrait for VhostUserListener {
-    fn new(_path: &str, _keep_rds: Option<&mut Vec<RawDescriptor>>) -> anyhow::Result<Self> {
+impl VhostUserConnectionTrait for VhostUserListener {
+    fn run_req_handler<'e>(
+        self,
+        _handler: Box<dyn vmm_vhost::Backend>,
+        _ex: &'e Executor,
+    ) -> Pin<Box<dyn Future<Output = anyhow::Result<()>> + 'e>> {
         todo!()
     }
+}
 
+impl VhostUserConnectionTrait for VhostUserStream {
     fn run_req_handler<'e>(
         self,
         _handler: Box<dyn vmm_vhost::Backend>,
diff --git a/devices/src/virtio/vhost/user/device/console.rs b/devices/src/virtio/vhost/user/device/console.rs
index 4f3e0ddba..ebc7a75d4 100644
--- a/devices/src/virtio/vhost/user/device/console.rs
+++ b/devices/src/virtio/vhost/user/device/console.rs
@@ -3,7 +3,6 @@
 // found in the LICENSE file.
 
 use std::path::PathBuf;
-use std::sync::Arc;
 
 use anyhow::anyhow;
 use anyhow::bail;
@@ -14,26 +13,19 @@ use base::Event;
 use base::RawDescriptor;
 use base::Terminal;
 use cros_async::Executor;
-use data_model::Le32;
 use hypervisor::ProtectionType;
-use sync::Mutex;
 use vm_memory::GuestMemory;
 use vmm_vhost::message::VhostUserProtocolFeatures;
 use vmm_vhost::VHOST_USER_F_PROTOCOL_FEATURES;
-use zerocopy::AsBytes;
 
-use crate::virtio;
-use crate::virtio::console::asynchronous::ConsoleDevice;
-use crate::virtio::console::asynchronous::ConsolePort;
-use crate::virtio::console::virtio_console_config;
-use crate::virtio::copy_config;
+use crate::virtio::console::device::ConsoleDevice;
+use crate::virtio::console::device::ConsoleSnapshot;
+use crate::virtio::console::port::ConsolePort;
+use crate::virtio::vhost::user::device::connection::sys::VhostUserListener;
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::handler::DeviceRequestHandler;
-use crate::virtio::vhost::user::device::handler::Error as DeviceError;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
-use crate::virtio::vhost::user::device::listener::sys::VhostUserListener;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
 use crate::virtio::vhost::user::device::VhostUserDeviceBuilder;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 use crate::SerialHardware;
 use crate::SerialParameters;
@@ -60,7 +52,7 @@ impl Drop for VhostUserConsoleDevice {
 }
 
 impl VhostUserDeviceBuilder for VhostUserConsoleDevice {
-    fn build(self: Box<Self>, ex: &Executor) -> anyhow::Result<Box<dyn vmm_vhost::Backend>> {
+    fn build(mut self: Box<Self>, _ex: &Executor) -> anyhow::Result<Box<dyn vmm_vhost::Backend>> {
         if self.raw_stdin {
             // Set stdin() to raw mode so we can send over individual keystrokes unbuffered
             std::io::stdin()
@@ -68,16 +60,9 @@ impl VhostUserDeviceBuilder for VhostUserConsoleDevice {
                 .context("failed to set terminal in raw mode")?;
         }
 
-        let queue_num = self.console.max_queues();
-        let active_queues = vec![None; queue_num];
+        self.console.start_input_threads();
 
-        let backend = ConsoleBackend {
-            device: *self,
-            acked_features: 0,
-            acked_protocol_features: VhostUserProtocolFeatures::empty(),
-            ex: ex.clone(),
-            active_queues,
-        };
+        let backend = ConsoleBackend { device: *self };
 
         let handler = DeviceRequestHandler::new(backend);
         Ok(Box::new(handler))
@@ -86,10 +71,6 @@ impl VhostUserDeviceBuilder for VhostUserConsoleDevice {
 
 struct ConsoleBackend {
     device: VhostUserConsoleDevice,
-    acked_features: u64,
-    acked_protocol_features: VhostUserProtocolFeatures,
-    ex: Executor,
-    active_queues: Vec<Option<Arc<Mutex<Queue>>>>,
 }
 
 impl VhostUserDevice for ConsoleBackend {
@@ -98,88 +79,50 @@ impl VhostUserDevice for ConsoleBackend {
     }
 
     fn features(&self) -> u64 {
-        self.device.console.avail_features() | 1 << VHOST_USER_F_PROTOCOL_FEATURES
-    }
-
-    fn ack_features(&mut self, value: u64) -> anyhow::Result<()> {
-        let unrequested_features = value & !self.features();
-        if unrequested_features != 0 {
-            bail!("invalid features are given: {:#x}", unrequested_features);
-        }
-
-        self.acked_features |= value;
-
-        Ok(())
-    }
-
-    fn acked_features(&self) -> u64 {
-        self.acked_features
+        self.device.console.features() | 1 << VHOST_USER_F_PROTOCOL_FEATURES
     }
 
     fn protocol_features(&self) -> VhostUserProtocolFeatures {
-        VhostUserProtocolFeatures::CONFIG | VhostUserProtocolFeatures::MQ
+        VhostUserProtocolFeatures::CONFIG
+            | VhostUserProtocolFeatures::MQ
+            | VhostUserProtocolFeatures::DEVICE_STATE
     }
 
-    fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-        let features = VhostUserProtocolFeatures::from_bits(features)
-            .ok_or_else(|| anyhow!("invalid protocol features are given: {:#x}", features))?;
-        let supported = self.protocol_features();
-        self.acked_protocol_features = features & supported;
-        Ok(())
+    fn read_config(&self, offset: u64, data: &mut [u8]) {
+        self.device.console.read_config(offset, data);
     }
 
-    fn acked_protocol_features(&self) -> u64 {
-        self.acked_protocol_features.bits()
+    fn reset(&mut self) {
+        if let Err(e) = self.device.console.reset() {
+            error!("console reset failed: {:#}", e);
+        }
     }
 
-    fn read_config(&self, offset: u64, data: &mut [u8]) {
-        let max_nr_ports = self.device.console.max_ports();
-        let config = virtio_console_config {
-            max_nr_ports: Le32::from(max_nr_ports as u32),
-            ..Default::default()
-        };
-        copy_config(data, 0, config.as_bytes(), offset);
+    fn start_queue(&mut self, idx: usize, queue: Queue, _mem: GuestMemory) -> anyhow::Result<()> {
+        self.device.console.start_queue(idx, queue)
     }
 
-    fn reset(&mut self) {
-        for queue_num in 0..self.max_queue_num() {
-            if let Err(e) = self.stop_queue(queue_num) {
-                error!("Failed to stop_queue during reset: {}", e);
-            }
+    fn stop_queue(&mut self, idx: usize) -> anyhow::Result<Queue> {
+        match self.device.console.stop_queue(idx) {
+            Ok(Some(queue)) => Ok(queue),
+            Ok(None) => Err(anyhow!("queue {idx} not started")),
+            Err(e) => Err(e).with_context(|| format!("failed to stop queue {idx}")),
         }
     }
 
-    fn start_queue(
-        &mut self,
-        idx: usize,
-        queue: virtio::Queue,
-        _mem: GuestMemory,
-        doorbell: Interrupt,
-    ) -> anyhow::Result<()> {
-        let queue = Arc::new(Mutex::new(queue));
-        let res = self
-            .device
-            .console
-            .start_queue(&self.ex, idx, queue.clone(), doorbell);
-
-        self.active_queues[idx].replace(queue);
-
-        res
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
+        Ok(())
     }
 
-    fn stop_queue(&mut self, idx: usize) -> anyhow::Result<virtio::Queue> {
-        if let Err(e) = self.device.console.stop_queue(idx) {
-            error!("error while stopping queue {}: {}", idx, e);
-        }
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        let snap = self.device.console.snapshot()?;
+        serde_json::to_value(snap).context("failed to snapshot vhost-user console")
+    }
 
-        if let Some(active_queue) = self.active_queues[idx].take() {
-            let queue = Arc::try_unwrap(active_queue)
-                .expect("failed to recover queue from worker")
-                .into_inner();
-            Ok(queue)
-        } else {
-            Err(anyhow::Error::new(DeviceError::WorkerNotFound))
-        }
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
+        let snap: ConsoleSnapshot =
+            serde_json::from_value(data).context("failed to deserialize vhost-user console")?;
+        self.device.console.restore(&snap)
     }
 }
 
@@ -208,7 +151,7 @@ fn create_vu_multi_port_device(
     params: &[SerialParameters],
     keep_rds: &mut Vec<RawDescriptor>,
 ) -> anyhow::Result<VhostUserConsoleDevice> {
-    let mut ports = params
+    let ports = params
         .iter()
         .map(|x| {
             let port = x
@@ -225,8 +168,7 @@ fn create_vu_multi_port_device(
         })
         .collect::<anyhow::Result<Vec<_>>>()?;
 
-    let port0 = ports.remove(0);
-    let device = ConsoleDevice::new_multi_port(ProtectionType::Unprotected, port0, ports);
+    let device = ConsoleDevice::new_multi_port(ProtectionType::Unprotected, ports);
 
     Ok(VhostUserConsoleDevice {
         console: device,
@@ -245,7 +187,7 @@ fn run_multi_port_device(opts: Options) -> anyhow::Result<()> {
     let device = Box::new(create_vu_multi_port_device(&opts.port, &mut Vec::new())?);
     let ex = Executor::new().context("Failed to create executor")?;
 
-    let listener = VhostUserListener::new_socket(&opts.socket, None)?;
+    let listener = VhostUserListener::new(&opts.socket)?;
 
     listener.run_device(ex, device)
 }
@@ -314,7 +256,7 @@ pub fn run_console_device(opts: Options) -> anyhow::Result<()> {
     let device = Box::new(create_vu_console_device(&params, &mut Vec::new())?);
     let ex = Executor::new().context("Failed to create executor")?;
 
-    let listener = VhostUserListener::new_socket(&opts.socket, None)?;
+    let listener = VhostUserListener::new(&opts.socket)?;
 
     listener.run_device(ex, device)
 }
diff --git a/devices/src/virtio/vhost/user/device/fs.rs b/devices/src/virtio/vhost/user/device/fs.rs
index 874856aef..8dc3ed42f 100644
--- a/devices/src/virtio/vhost/user/device/fs.rs
+++ b/devices/src/virtio/vhost/user/device/fs.rs
@@ -9,7 +9,6 @@ use std::path::PathBuf;
 use std::rc::Rc;
 use std::sync::Arc;
 
-use anyhow::anyhow;
 use anyhow::bail;
 use anyhow::Context;
 use argh::FromArgs;
@@ -40,14 +39,12 @@ use crate::virtio::fs::Config;
 use crate::virtio::vhost::user::device::handler::Error as DeviceError;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
 use crate::virtio::vhost::user::device::handler::WorkerState;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 
 const MAX_QUEUE_NUM: usize = 2; /* worker queue and high priority queue */
 
 async fn handle_fs_queue(
     queue: Rc<RefCell<virtio::Queue>>,
-    doorbell: Interrupt,
     kick_evt: EventAsync,
     server: Arc<fuse::Server<PassthroughFs>>,
     tube: Arc<Mutex<Tube>>,
@@ -60,7 +57,7 @@ async fn handle_fs_queue(
             error!("Failed to read kick event for fs queue: {}", e);
             break;
         }
-        if let Err(e) = process_fs_queue(&doorbell, &mut queue.borrow_mut(), &server, &tube, slot) {
+        if let Err(e) = process_fs_queue(&mut queue.borrow_mut(), &server, &tube, slot) {
             error!("Process FS queue failed: {}", e);
             break;
         }
@@ -72,8 +69,6 @@ struct FsBackend {
     server: Arc<fuse::Server<PassthroughFs>>,
     tag: [u8; FS_MAX_TAG_LEN],
     avail_features: u64,
-    acked_features: u64,
-    acked_protocol_features: VhostUserProtocolFeatures,
     workers: [Option<WorkerState<Rc<RefCell<Queue>>, ()>>; MAX_QUEUE_NUM],
     keep_rds: Vec<RawDescriptor>,
 }
@@ -109,8 +104,6 @@ impl FsBackend {
             server,
             tag: fs_tag,
             avail_features,
-            acked_features: 0,
-            acked_protocol_features: VhostUserProtocolFeatures::empty(),
             workers: Default::default(),
             keep_rds,
         })
@@ -126,37 +119,10 @@ impl VhostUserDevice for FsBackend {
         self.avail_features
     }
 
-    fn ack_features(&mut self, value: u64) -> anyhow::Result<()> {
-        let unrequested_features = value & !self.avail_features;
-        if unrequested_features != 0 {
-            bail!("invalid features are given: {:#x}", unrequested_features);
-        }
-
-        self.acked_features |= value;
-
-        Ok(())
-    }
-
-    fn acked_features(&self) -> u64 {
-        self.acked_features
-    }
-
     fn protocol_features(&self) -> VhostUserProtocolFeatures {
         VhostUserProtocolFeatures::CONFIG | VhostUserProtocolFeatures::MQ
     }
 
-    fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-        let features = VhostUserProtocolFeatures::from_bits(features)
-            .ok_or_else(|| anyhow!("invalid protocol features are given: {:#x}", features))?;
-        let supported = self.protocol_features();
-        self.acked_protocol_features = features & supported;
-        Ok(())
-    }
-
-    fn acked_protocol_features(&self) -> u64 {
-        self.acked_protocol_features.bits()
-    }
-
     fn read_config(&self, offset: u64, data: &mut [u8]) {
         let config = virtio_fs_config {
             tag: self.tag,
@@ -176,7 +142,6 @@ impl VhostUserDevice for FsBackend {
         idx: usize,
         queue: virtio::Queue,
         _mem: GuestMemory,
-        doorbell: Interrupt,
     ) -> anyhow::Result<()> {
         if self.workers[idx].is_some() {
             warn!("Starting new queue handler without stopping old handler");
@@ -194,7 +159,6 @@ impl VhostUserDevice for FsBackend {
         let queue = Rc::new(RefCell::new(queue));
         let queue_task = self.ex.spawn_local(handle_fs_queue(
             queue.clone(),
-            doorbell,
             kick_evt,
             self.server.clone(),
             Arc::new(Mutex::new(fs_device_tube)),
@@ -219,6 +183,19 @@ impl VhostUserDevice for FsBackend {
             Err(anyhow::Error::new(DeviceError::WorkerNotFound))
         }
     }
+
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
+        // No non-queue workers.
+        Ok(())
+    }
+
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        bail!("snapshot not implemented for vhost-user fs");
+    }
+
+    fn restore(&mut self, _data: serde_json::Value) -> anyhow::Result<()> {
+        bail!("snapshot not implemented for vhost-user fs");
+    }
 }
 
 #[derive(FromArgs)]
@@ -226,8 +203,14 @@ impl VhostUserDevice for FsBackend {
 /// FS Device
 pub struct Options {
     #[argh(option, arg_name = "PATH")]
-    /// path to a vhost-user socket
-    socket: String,
+    /// the UDS path to a vhost-user socket.
+    /// If this flag is set, --fd cannot be specified.
+    socket: Option<String>,
+    #[cfg(unix)]
+    #[argh(option, arg_name = "FD")]
+    /// file descriptor of a connected vhost-user socket.
+    /// If this flag is set, --socket cannot be specified.
+    fd: Option<i32>,
     #[argh(option, arg_name = "TAG")]
     /// the virtio-fs tag
     tag: String,
@@ -264,4 +247,11 @@ pub struct Options {
     /// gid of the device process in the new user namespace created by minijail.
     /// Default: 0.
     gid: u32,
+    #[argh(switch)]
+    /// disable-sandbox controls whether vhost-user-fs device uses minijail sandbox.
+    /// By default, it is false, the vhost-user-fs will enter new mnt/user/pid/net
+    /// namespace. If the this option is true, the vhost-user-fs device only create
+    /// a new mount namespace and run without seccomp filter.
+    /// Default: false.
+    disable_sandbox: bool,
 }
diff --git a/devices/src/virtio/vhost/user/device/fs/sys/linux.rs b/devices/src/virtio/vhost/user/device/fs/sys/linux.rs
index 7236bb1b8..034eb143d 100644
--- a/devices/src/virtio/vhost/user/device/fs/sys/linux.rs
+++ b/devices/src/virtio/vhost/user/device/fs/sys/linux.rs
@@ -2,21 +2,24 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-use std::io;
 use std::path::Path;
 use std::path::PathBuf;
 
 use anyhow::bail;
 use anyhow::Context;
 use base::linux::max_open_files;
+use base::AsRawDescriptor;
 use base::RawDescriptor;
 use cros_async::Executor;
+use jail::create_base_minijail;
+use jail::set_embedded_bpf_program;
 use minijail::Minijail;
 
+use crate::virtio::vhost::user::device::connection::sys::VhostUserListener;
+use crate::virtio::vhost::user::device::connection::sys::VhostUserStream;
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::fs::FsBackend;
 use crate::virtio::vhost::user::device::fs::Options;
-use crate::virtio::vhost::user::device::listener::sys::VhostUserListener;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
 
 fn default_uidmap() -> String {
     // SAFETY: trivially safe
@@ -30,6 +33,7 @@ fn default_gidmap() -> String {
     format!("{} {} 1", egid, egid)
 }
 
+#[allow(clippy::unnecessary_cast)]
 fn jail_and_fork(
     mut keep_rds: Vec<RawDescriptor>,
     dir_path: PathBuf,
@@ -37,39 +41,49 @@ fn jail_and_fork(
     gid: u32,
     uid_map: Option<String>,
     gid_map: Option<String>,
+    disable_sandbox: bool,
 ) -> anyhow::Result<i32> {
+    let limit = max_open_files()
+        .context("failed to get max open files")?
+        .rlim_max;
     // Create new minijail sandbox
-    let mut j = Minijail::new()?;
-
-    j.namespace_pids();
-    j.namespace_user();
-    j.namespace_user_disable_setgroups();
-    if uid != 0 {
-        j.change_uid(uid);
-    }
-    if gid != 0 {
-        j.change_gid(gid);
-    }
-    j.uidmap(&uid_map.unwrap_or_else(default_uidmap))?;
-    j.gidmap(&gid_map.unwrap_or_else(default_gidmap))?;
-    j.run_as_init();
-
-    j.namespace_vfs();
-    j.namespace_net();
-    j.no_new_privs();
+    let jail = if disable_sandbox {
+        create_base_minijail(dir_path.as_path(), limit)?
+    } else {
+        let mut j: Minijail = Minijail::new()?;
+        j.namespace_pids();
+        j.namespace_user();
+        j.namespace_user_disable_setgroups();
+        if uid != 0 {
+            j.change_uid(uid);
+        }
+        if gid != 0 {
+            j.change_gid(gid);
+        }
+        j.uidmap(&uid_map.unwrap_or_else(default_uidmap))?;
+        j.gidmap(&gid_map.unwrap_or_else(default_gidmap))?;
+        j.run_as_init();
 
-    // Only pivot_root if we are not re-using the current root directory.
-    if dir_path != Path::new("/") {
-        // It's safe to call `namespace_vfs` multiple times.
         j.namespace_vfs();
-        j.enter_pivot_root(&dir_path)?;
-    }
-    j.set_remount_mode(libc::MS_SLAVE);
+        j.namespace_net();
+        j.no_new_privs();
+
+        // Only pivot_root if we are not re-using the current root directory.
+        if dir_path != Path::new("/") {
+            // It's safe to call `namespace_vfs` multiple times.
+            j.namespace_vfs();
+            j.enter_pivot_root(&dir_path)?;
+        }
+        j.set_remount_mode(libc::MS_SLAVE);
 
-    let limit = max_open_files().context("failed to get max open files")?;
-    j.set_rlimit(libc::RLIMIT_NOFILE as i32, limit, limit)?;
-    // vvu locks around 512k memory. Just give 1M.
-    j.set_rlimit(libc::RLIMIT_MEMLOCK as i32, 1 << 20, 1 << 20)?;
+        j.set_rlimit(libc::RLIMIT_NOFILE as i32, limit, limit)?;
+        // vvu locks around 512k memory. Just give 1M.
+        j.set_rlimit(libc::RLIMIT_MEMLOCK as i32, 1 << 20, 1 << 20)?;
+        #[cfg(not(feature = "seccomp_trace"))]
+        set_embedded_bpf_program(&mut j, "fs_device_vhost_user")?;
+        j.use_seccomp_filter();
+        j
+    };
 
     // Make sure there are no duplicates in keep_rds
     keep_rds.sort_unstable();
@@ -77,7 +91,7 @@ fn jail_and_fork(
 
     // fork on the jail here
     // SAFETY: trivially safe
-    let pid = unsafe { j.fork(Some(&keep_rds))? };
+    let pid = unsafe { jail.fork(Some(&keep_rds))? };
 
     if pid > 0 {
         // Current FS driver jail does not use seccomp and jail_and_fork() does not have other
@@ -100,7 +114,20 @@ pub fn start_device(opts: Options) -> anyhow::Result<()> {
     let fs_device = FsBackend::new(&ex, &opts.tag, opts.cfg)?;
 
     let mut keep_rds = fs_device.keep_rds.clone();
-    let listener = VhostUserListener::new_socket(&opts.socket, Some(&mut keep_rds))?;
+
+    let (listener, stream) = match (opts.socket, opts.fd) {
+        (Some(socket), None) => {
+            let listener = VhostUserListener::new(&socket)?;
+            keep_rds.push(listener.as_raw_descriptor());
+            (Some(listener), None)
+        }
+        (None, Some(fd)) => {
+            let stream = VhostUserStream::new_socket_from_fd(fd, Some(&mut keep_rds))?;
+            (None, Some(stream))
+        }
+        (Some(_), Some(_)) => bail!("Cannot specify both a socket path and a file descriptor"),
+        (None, None) => bail!("Must specify either a socket or a file descriptor"),
+    };
 
     base::syslog::push_descriptors(&mut keep_rds);
     cros_tracing::push_descriptors!(&mut keep_rds);
@@ -113,6 +140,7 @@ pub fn start_device(opts: Options) -> anyhow::Result<()> {
         opts.gid,
         opts.uid_map,
         opts.gid_map,
+        opts.disable_sandbox,
     )?;
 
     // Parent, nothing to do but wait and then exit
@@ -122,29 +150,34 @@ pub fn start_device(opts: Options) -> anyhow::Result<()> {
         return Ok(());
     }
 
-    // We need to set the no setuid fixup secure bit so that we don't drop capabilities when
-    // changing the thread uid/gid. Without this, creating new entries can fail in some corner
-    // cases.
-    const SECBIT_NO_SETUID_FIXUP: i32 = 1 << 2;
-
     // TODO(crbug.com/1199487): Remove this once libc provides the wrapper for all targets.
     #[cfg(target_os = "linux")]
     {
+        // We need to set the no setuid fixup secure bit so that we don't drop capabilities when
+        // changing the thread uid/gid. Without this, creating new entries can fail in some corner
+        // cases.
+        const SECBIT_NO_SETUID_FIXUP: i32 = 1 << 2;
+
         // SAFETY:
         // Safe because this doesn't modify any memory and we check the return value.
         let mut securebits = unsafe { libc::prctl(libc::PR_GET_SECUREBITS) };
         if securebits < 0 {
-            bail!(io::Error::last_os_error());
+            bail!(std::io::Error::last_os_error());
         }
         securebits |= SECBIT_NO_SETUID_FIXUP;
         // SAFETY:
         // Safe because this doesn't modify any memory and we check the return value.
         let ret = unsafe { libc::prctl(libc::PR_SET_SECUREBITS, securebits) };
         if ret < 0 {
-            bail!(io::Error::last_os_error());
+            bail!(std::io::Error::last_os_error());
         }
     }
 
-    // run_until() returns an Result<Result<..>> which the ? operator lets us flatten.
-    ex.run_until(listener.run_backend(fs_device, &ex))?
+    if let Some(listener) = listener {
+        // run_until() returns an Result<Result<..>> which the ? operator lets us flatten.
+        ex.run_until(listener.run_backend(fs_device, &ex))?
+    } else {
+        let stream = stream.expect("if listener is none, the stream should be some");
+        ex.run_until(stream.run_backend(fs_device, &ex))?
+    }
 }
diff --git a/devices/src/virtio/vhost/user/device/gpu.rs b/devices/src/virtio/vhost/user/device/gpu.rs
index f2cd560e0..aea86d5f0 100644
--- a/devices/src/virtio/vhost/user/device/gpu.rs
+++ b/devices/src/virtio/vhost/user/device/gpu.rs
@@ -33,7 +33,6 @@ use crate::virtio::vhost::user::device::handler::VhostUserDevice;
 use crate::virtio::vhost::user::device::handler::WorkerState;
 use crate::virtio::DescriptorChain;
 use crate::virtio::Gpu;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 use crate::virtio::SharedMemoryMapper;
 use crate::virtio::SharedMemoryRegion;
@@ -44,7 +43,6 @@ const MAX_QUEUE_NUM: usize = NUM_QUEUES;
 #[derive(Clone)]
 struct SharedReader {
     queue: Arc<Mutex<Queue>>,
-    doorbell: Interrupt,
 }
 
 impl gpu::QueueReader for SharedReader {
@@ -57,7 +55,7 @@ impl gpu::QueueReader for SharedReader {
     }
 
     fn signal_used(&self) {
-        self.queue.lock().trigger_interrupt(&self.doorbell);
+        self.queue.lock().trigger_interrupt();
     }
 }
 
@@ -86,7 +84,6 @@ struct GpuBackend {
     ex: Executor,
     gpu: Rc<RefCell<Gpu>>,
     resource_bridges: Arc<Mutex<Vec<Tube>>>,
-    acked_protocol_features: u64,
     state: Option<Rc<RefCell<gpu::Frontend>>>,
     fence_state: Arc<Mutex<gpu::FenceState>>,
     queue_workers: [Option<WorkerState<Arc<Mutex<Queue>>, ()>>; MAX_QUEUE_NUM],
@@ -94,6 +91,15 @@ struct GpuBackend {
     shmem_mapper: Arc<Mutex<Option<Box<dyn SharedMemoryMapper>>>>,
 }
 
+impl GpuBackend {
+    fn stop_non_queue_workers(&mut self) -> anyhow::Result<()> {
+        for handle in self.platform_workers.borrow_mut().drain(..) {
+            let _ = self.ex.run_until(handle.cancel());
+        }
+        Ok(())
+    }
+}
+
 impl VhostUserDevice for GpuBackend {
     fn max_queue_num(&self) -> usize {
         MAX_QUEUE_NUM
@@ -108,29 +114,12 @@ impl VhostUserDevice for GpuBackend {
         Ok(())
     }
 
-    fn acked_features(&self) -> u64 {
-        self.features()
-    }
-
     fn protocol_features(&self) -> VhostUserProtocolFeatures {
         VhostUserProtocolFeatures::CONFIG
             | VhostUserProtocolFeatures::BACKEND_REQ
             | VhostUserProtocolFeatures::MQ
             | VhostUserProtocolFeatures::SHARED_MEMORY_REGIONS
-    }
-
-    fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-        let unrequested_features = features & !self.protocol_features().bits();
-        if unrequested_features != 0 {
-            bail!("Unexpected protocol features: {:#x}", unrequested_features);
-        }
-
-        self.acked_protocol_features |= features;
-        Ok(())
-    }
-
-    fn acked_protocol_features(&self) -> u64 {
-        self.acked_protocol_features
+            | VhostUserProtocolFeatures::DEVICE_STATE
     }
 
     fn read_config(&self, offset: u64, dst: &mut [u8]) {
@@ -141,18 +130,14 @@ impl VhostUserDevice for GpuBackend {
         self.gpu.borrow_mut().write_config(offset, data)
     }
 
-    fn start_queue(
-        &mut self,
-        idx: usize,
-        queue: Queue,
-        mem: GuestMemory,
-        doorbell: Interrupt,
-    ) -> anyhow::Result<()> {
+    fn start_queue(&mut self, idx: usize, queue: Queue, mem: GuestMemory) -> anyhow::Result<()> {
         if self.queue_workers[idx].is_some() {
             warn!("Starting new queue handler without stopping old handler");
             self.stop_queue(idx)?;
         }
 
+        let doorbell = queue.interrupt().clone();
+
         // Create a refcounted queue. The GPU control queue uses a SharedReader which allows us to
         // handle fences in the RutabagaFenceHandler, and also handle queue messages in
         // `run_ctrl_queue`.
@@ -173,7 +158,6 @@ impl VhostUserDevice for GpuBackend {
                     .context("failed to create EventAsync for kick_evt")?;
                 let reader = SharedReader {
                     queue: queue.clone(),
-                    doorbell: doorbell.clone(),
                 };
 
                 let state = if let Some(s) = self.state.as_ref() {
@@ -250,10 +234,8 @@ impl VhostUserDevice for GpuBackend {
         }
     }
 
-    fn stop_non_queue_workers(&mut self) -> anyhow::Result<()> {
-        for handle in self.platform_workers.borrow_mut().drain(..) {
-            let _ = self.ex.run_until(handle.cancel());
-        }
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
+        self.stop_non_queue_workers()?;
         Ok(())
     }
 
@@ -287,16 +269,13 @@ impl VhostUserDevice for GpuBackend {
         }
     }
 
-    fn snapshot(&self) -> anyhow::Result<Vec<u8>> {
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
         // TODO(b/289431114): Snapshot more fields if needed. Right now we just need a bare bones
         // snapshot of the GPU to create a POC.
-        serde_json::to_vec(&serde_json::Value::Null)
-            .context("Failed to serialize Null in the GPU device")
+        Ok(serde_json::Value::Null)
     }
 
-    fn restore(&mut self, data: Vec<u8>) -> anyhow::Result<()> {
-        let data: serde_json::Value = serde_json::from_slice(data.as_slice())
-            .context("Failed to deserialize NULL in the GPU device")?;
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
         anyhow::ensure!(
             data.is_null(),
             "unexpected snapshot data: should be null, got {}",
diff --git a/devices/src/virtio/vhost/user/device/gpu/sys/linux.rs b/devices/src/virtio/vhost/user/device/gpu/sys/linux.rs
index 57df8cf47..b2356447e 100644
--- a/devices/src/virtio/vhost/user/device/gpu/sys/linux.rs
+++ b/devices/src/virtio/vhost/user/device/gpu/sys/linux.rs
@@ -25,9 +25,9 @@ use sync::Mutex;
 use crate::virtio;
 use crate::virtio::gpu;
 use crate::virtio::gpu::ProcessDisplayResult;
+use crate::virtio::vhost::user::device::connection::sys::VhostUserListener;
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::gpu::GpuBackend;
-use crate::virtio::vhost::user::device::listener::sys::VhostUserListener;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
 use crate::virtio::vhost::user::device::wl::parse_wayland_sock;
 use crate::virtio::Gpu;
 use crate::virtio::GpuDisplayParameters;
@@ -220,7 +220,7 @@ pub fn run_gpu_device(opts: Options) -> anyhow::Result<()> {
 
     let base_features = virtio::base_features(ProtectionType::Unprotected);
 
-    let listener = VhostUserListener::new_socket(&socket, None)?;
+    let listener = VhostUserListener::new(&socket)?;
 
     let gpu = Rc::new(RefCell::new(Gpu::new(
         exit_evt_wrtube,
@@ -241,7 +241,6 @@ pub fn run_gpu_device(opts: Options) -> anyhow::Result<()> {
         ex: ex.clone(),
         gpu,
         resource_bridges,
-        acked_protocol_features: 0,
         state: None,
         fence_state: Default::default(),
         queue_workers: Default::default(),
diff --git a/devices/src/virtio/vhost/user/device/gpu/sys/windows.rs b/devices/src/virtio/vhost/user/device/gpu/sys/windows.rs
index f44562194..98e50f7f2 100644
--- a/devices/src/virtio/vhost/user/device/gpu/sys/windows.rs
+++ b/devices/src/virtio/vhost/user/device/gpu/sys/windows.rs
@@ -314,7 +314,6 @@ pub fn run_gpu_device_worker(
         ex: ex.clone(),
         gpu,
         resource_bridges: Default::default(),
-        acked_protocol_features: 0,
         state: None,
         fence_state: Default::default(),
         queue_workers: Default::default(),
diff --git a/devices/src/virtio/vhost/user/device/handler.rs b/devices/src/virtio/vhost/user/device/handler.rs
index daa39a0c3..3161e35e6 100644
--- a/devices/src/virtio/vhost/user/device/handler.rs
+++ b/devices/src/virtio/vhost/user/device/handler.rs
@@ -59,13 +59,13 @@ use anyhow::Context;
 #[cfg(any(target_os = "android", target_os = "linux"))]
 use base::clear_fd_flags;
 use base::error;
+use base::trace;
 use base::warn;
 use base::Event;
-use base::FromRawDescriptor;
-use base::IntoRawDescriptor;
 use base::Protection;
 use base::SafeDescriptor;
 use base::SharedMemory;
+use base::WorkerThread;
 use cros_async::TaskHandle;
 use hypervisor::MemCacheType;
 use serde::Deserialize;
@@ -82,11 +82,13 @@ use vmm_vhost::message::VhostUserExternalMapMsg;
 use vmm_vhost::message::VhostUserGpuMapMsg;
 use vmm_vhost::message::VhostUserInflight;
 use vmm_vhost::message::VhostUserMemoryRegion;
+use vmm_vhost::message::VhostUserMigrationPhase;
 use vmm_vhost::message::VhostUserProtocolFeatures;
 use vmm_vhost::message::VhostUserShmemMapMsg;
 use vmm_vhost::message::VhostUserShmemMapMsgFlags;
 use vmm_vhost::message::VhostUserShmemUnmapMsg;
 use vmm_vhost::message::VhostUserSingleMemoryRegion;
+use vmm_vhost::message::VhostUserTransferDirection;
 use vmm_vhost::message::VhostUserVringAddrFlags;
 use vmm_vhost::message::VhostUserVringState;
 use vmm_vhost::BackendReq;
@@ -133,20 +135,19 @@ pub trait VhostUserDevice {
     fn features(&self) -> u64;
 
     /// Acknowledges that this set of features should be enabled.
-    fn ack_features(&mut self, value: u64) -> anyhow::Result<()>;
-
-    /// Returns the set of enabled features.
-    fn acked_features(&self) -> u64;
+    ///
+    /// Implementations only need to handle device-specific feature bits; the `DeviceRequestHandler`
+    /// framework will manage generic vhost and vring features.
+    ///
+    /// `DeviceRequestHandler` checks for valid features before calling this function, so the
+    /// features in `value` will always be a subset of those advertised by `features()`.
+    fn ack_features(&mut self, _value: u64) -> anyhow::Result<()> {
+        Ok(())
+    }
 
     /// The set of protocol feature bits that this backend supports.
     fn protocol_features(&self) -> VhostUserProtocolFeatures;
 
-    /// Acknowledges that this set of protocol features should be enabled.
-    fn ack_protocol_features(&mut self, _value: u64) -> anyhow::Result<()>;
-
-    /// Returns the set of enabled protocol features.
-    fn acked_protocol_features(&self) -> u64;
-
     /// Reads this device configuration space at `offset`.
     fn read_config(&self, offset: u64, dst: &mut [u8]);
 
@@ -156,13 +157,7 @@ pub trait VhostUserDevice {
     /// Indicates that the backend should start processing requests for virtio queue number `idx`.
     /// This method must not block the current thread so device backends should either spawn an
     /// async task or another thread to handle messages from the Queue.
-    fn start_queue(
-        &mut self,
-        idx: usize,
-        queue: Queue,
-        mem: GuestMemory,
-        doorbell: Interrupt,
-    ) -> anyhow::Result<()>;
+    fn start_queue(&mut self, idx: usize, queue: Queue, mem: GuestMemory) -> anyhow::Result<()>;
 
     /// Indicates that the backend should stop processing requests for virtio queue number `idx`.
     /// This method should return the queue passed to `start_queue` for the corresponding `idx`.
@@ -185,30 +180,27 @@ pub trait VhostUserDevice {
     ///
     /// This method will be called when `VhostUserProtocolFeatures::BACKEND_REQ` is
     /// negotiated.
-    fn set_backend_req_connection(&mut self, _conn: Arc<VhostBackendReqConnection>) {
-        error!("set_backend_req_connection is not implemented");
-    }
+    fn set_backend_req_connection(&mut self, _conn: Arc<VhostBackendReqConnection>) {}
 
-    /// Used to stop non queue workers that `VhostUserDevice::stop_queue` can't stop. May or may
-    /// not also stop all queue workers.
-    fn stop_non_queue_workers(&mut self) -> anyhow::Result<()> {
-        error!("sleep not implemented for vhost user device");
-        // TODO(rizhang): Return error once basic devices support this.
-        Ok(())
-    }
+    /// Enter the "suspended device state" described in the vhost-user spec. See the spec for
+    /// requirements.
+    ///
+    /// One reasonably foolproof way to satisfy the requirements is to stop all worker threads.
+    ///
+    /// Called after a `stop_queue` call if there are no running queues left. Also called soon
+    /// after device creation to ensure the device is acting suspended immediately on construction.
+    ///
+    /// The next `start_queue` call implicitly exits the "suspend device state".
+    ///
+    /// * Ok(())    => device successfully suspended
+    /// * Err(_)    => unrecoverable error
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()>;
 
-    /// Snapshot device and return serialized bytes.
-    fn snapshot(&self) -> anyhow::Result<Vec<u8>> {
-        error!("snapshot not implemented for vhost user device");
-        // TODO(rizhang): Return error once basic devices support this.
-        Ok(Vec::new())
-    }
+    /// Snapshot device and return serialized state.
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value>;
 
-    fn restore(&mut self, _data: Vec<u8>) -> anyhow::Result<()> {
-        error!("restore not implemented for vhost user device");
-        // TODO(rizhang): Return error once basic devices support this.
-        Ok(())
-    }
+    /// Restore device state from a snapshot.
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()>;
 }
 
 /// A virtio ring entry.
@@ -217,17 +209,6 @@ struct Vring {
     queue: QueueConfig,
     doorbell: Option<Interrupt>,
     enabled: bool,
-    // Active queue that is only `Some` when the device is sleeping.
-    paused_queue: Option<Queue>,
-}
-
-#[derive(Serialize, Deserialize)]
-struct VringSnapshot {
-    // Snapshot of queue config.
-    queue: serde_json::Value,
-    // Snapshot of the activated queue state.
-    paused_queue: Option<serde_json::Value>,
-    enabled: bool,
 }
 
 impl Vring {
@@ -236,7 +217,6 @@ impl Vring {
             queue: QueueConfig::new(max_size, features),
             doorbell: None,
             enabled: false,
-            paused_queue: None,
         }
     }
 
@@ -244,41 +224,6 @@ impl Vring {
         self.queue.reset();
         self.doorbell = None;
         self.enabled = false;
-        self.paused_queue = None;
-    }
-
-    fn snapshot(&self) -> anyhow::Result<VringSnapshot> {
-        Ok(VringSnapshot {
-            queue: self.queue.snapshot()?,
-            enabled: self.enabled,
-            paused_queue: self
-                .paused_queue
-                .as_ref()
-                .map(Queue::snapshot)
-                .transpose()?,
-        })
-    }
-
-    fn restore(
-        &mut self,
-        vring_snapshot: VringSnapshot,
-        mem: &GuestMemory,
-        event: Option<Event>,
-    ) -> anyhow::Result<()> {
-        self.queue.restore(vring_snapshot.queue)?;
-        self.enabled = vring_snapshot.enabled;
-        self.paused_queue = vring_snapshot
-            .paused_queue
-            .map(|value| {
-                Queue::restore(
-                    &self.queue,
-                    value,
-                    mem,
-                    event.context("missing queue event")?,
-                )
-            })
-            .transpose()?;
-        Ok(())
     }
 }
 
@@ -362,35 +307,61 @@ pub struct DeviceRequestHandler<T: VhostUserDevice> {
     owned: bool,
     vmm_maps: Option<Vec<MappingInfo>>,
     mem: Option<GuestMemory>,
+    acked_features: u64,
+    acked_protocol_features: VhostUserProtocolFeatures,
     backend: T,
     backend_req_connection: Arc<Mutex<VhostBackendReqConnectionState>>,
+    // Thread processing active device state FD.
+    device_state_thread: Option<DeviceStateThread>,
+}
+
+enum DeviceStateThread {
+    Save(WorkerThread<serde_json::Result<()>>),
+    Load(WorkerThread<serde_json::Result<DeviceRequestHandlerSnapshot>>),
 }
 
 #[derive(Serialize, Deserialize)]
 pub struct DeviceRequestHandlerSnapshot {
-    vrings: Vec<VringSnapshot>,
-    backend: Vec<u8>,
+    acked_features: u64,
+    acked_protocol_features: u64,
+    backend: serde_json::Value,
 }
 
 impl<T: VhostUserDevice> DeviceRequestHandler<T> {
     /// Creates a vhost-user handler instance for `backend`.
-    pub(crate) fn new(backend: T) -> Self {
+    pub(crate) fn new(mut backend: T) -> Self {
         let mut vrings = Vec::with_capacity(backend.max_queue_num());
         for _ in 0..backend.max_queue_num() {
             vrings.push(Vring::new(Queue::MAX_SIZE, backend.features()));
         }
 
+        // VhostUserDevice implementations must support `enter_suspended_state()`.
+        // Call it on startup to ensure it works and to initialize the device in a suspended state.
+        backend
+            .enter_suspended_state()
+            .expect("enter_suspended_state failed on device init");
+
         DeviceRequestHandler {
             vrings,
             owned: false,
             vmm_maps: None,
             mem: None,
+            acked_features: 0,
+            acked_protocol_features: VhostUserProtocolFeatures::empty(),
             backend,
             backend_req_connection: Arc::new(Mutex::new(
                 VhostBackendReqConnectionState::NoConnection,
             )),
+            device_state_thread: None,
         }
     }
+
+    /// Check if all queues are stopped.
+    ///
+    /// The device can be suspended with `enter_suspended_state()` only when all queues are stopped.
+    fn all_queues_stopped(&self) -> bool {
+        self.vrings.iter().all(|vring| !vring.queue.ready())
+    }
 }
 
 impl<T: VhostUserDevice> AsRef<T> for DeviceRequestHandler<T> {
@@ -416,6 +387,7 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
 
     fn reset_owner(&mut self) -> VhostResult<()> {
         self.owned = false;
+        self.acked_features = 0;
         self.backend.reset();
         Ok(())
     }
@@ -430,7 +402,9 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
             return Err(VhostError::InvalidOperation);
         }
 
-        if (features & !(self.backend.features())) != 0 {
+        let unexpected_features = features & !self.backend.features();
+        if unexpected_features != 0 {
+            error!("unexpected set_features {:#x}", unexpected_features);
             return Err(VhostError::InvalidParam);
         }
 
@@ -439,6 +413,8 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
             return Err(VhostError::InvalidOperation);
         }
 
+        self.acked_features |= features;
+
         // If VHOST_USER_F_PROTOCOL_FEATURES has not been negotiated, the ring is initialized in an
         // enabled state.
         // If VHOST_USER_F_PROTOCOL_FEATURES has been negotiated, the ring is initialized in a
@@ -446,8 +422,7 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
         // Client must not pass data to/from the backend until ring is enabled by
         // VHOST_USER_SET_VRING_ENABLE with parameter 1, or after it has been disabled by
         // VHOST_USER_SET_VRING_ENABLE with parameter 0.
-        let acked_features = self.backend.acked_features();
-        let vring_enabled = acked_features & 1 << VHOST_USER_F_PROTOCOL_FEATURES != 0;
+        let vring_enabled = self.acked_features & 1 << VHOST_USER_F_PROTOCOL_FEATURES != 0;
         for v in &mut self.vrings {
             v.enabled = vring_enabled;
         }
@@ -460,10 +435,18 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
     }
 
     fn set_protocol_features(&mut self, features: u64) -> VhostResult<()> {
-        if let Err(e) = self.backend.ack_protocol_features(features) {
-            error!("failed to set protocol features 0x{:x}: {}", features, e);
-            return Err(VhostError::InvalidOperation);
-        }
+        let features = match VhostUserProtocolFeatures::from_bits(features) {
+            Some(proto_features) => proto_features,
+            None => {
+                error!(
+                    "unsupported bits in VHOST_USER_SET_PROTOCOL_FEATURES: {:#x}",
+                    features
+                );
+                return Err(VhostError::InvalidOperation);
+            }
+        };
+        let supported = self.backend.protocol_features();
+        self.acked_protocol_features = features & supported;
         Ok(())
     }
 
@@ -539,18 +522,32 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
         // "The back-end must [...] stop ring upon receiving VHOST_USER_GET_VRING_BASE."
         // We only call `queue.set_ready()` when starting the queue, so if the queue is ready, that
         // means it is started and should be stopped.
-        if vring.queue.ready() {
-            if let Err(e) = self.backend.stop_queue(index as usize) {
-                error!("Failed to stop queue in get_vring_base: {:#}", e);
-            }
+        let vring_base = if vring.queue.ready() {
+            let queue = match self.backend.stop_queue(index as usize) {
+                Ok(q) => q,
+                Err(e) => {
+                    error!("Failed to stop queue in get_vring_base: {:#}", e);
+                    return Err(VhostError::BackendInternalError);
+                }
+            };
+
+            trace!("stopped queue {index}");
 
             vring.reset();
-        }
 
-        Ok(VhostUserVringState::new(
-            index,
-            vring.queue.next_avail().0 as u32,
-        ))
+            if self.all_queues_stopped() {
+                trace!("all queues stopped; entering suspended state");
+                self.backend
+                    .enter_suspended_state()
+                    .map_err(VhostError::EnterSuspendedState)?;
+            }
+
+            queue.next_avail_to_process()
+        } else {
+            0
+        };
+
+        Ok(VhostUserVringState::new(index, vring_base.into()))
     }
 
     fn set_vring_kick(&mut self, index: u8, file: Option<File>) -> VhostResult<()> {
@@ -567,7 +564,7 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
         let kick_evt = VhostUserRegularOps::set_vring_kick(index, file)?;
 
         // Enable any virtqueue features that were negotiated (like VIRTIO_RING_F_EVENT_IDX).
-        vring.queue.ack_features(self.backend.acked_features());
+        vring.queue.ack_features(self.acked_features);
         vring.queue.set_ready(true);
 
         let mem = self
@@ -576,7 +573,9 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
             .cloned()
             .ok_or(VhostError::InvalidOperation)?;
 
-        let queue = match vring.queue.activate(&mem, kick_evt) {
+        let doorbell = vring.doorbell.clone().ok_or(VhostError::InvalidOperation)?;
+
+        let queue = match vring.queue.activate(&mem, kick_evt, doorbell) {
             Ok(queue) => queue,
             Err(e) => {
                 error!("failed to activate vring: {:#}", e);
@@ -584,16 +583,13 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
             }
         };
 
-        let doorbell = vring.doorbell.clone().ok_or(VhostError::InvalidOperation)?;
-
-        if let Err(e) = self
-            .backend
-            .start_queue(index as usize, queue, mem, doorbell)
-        {
+        if let Err(e) = self.backend.start_queue(index as usize, queue, mem) {
             error!("Failed to start queue {}: {}", index, e);
             return Err(VhostError::BackendInternalError);
         }
 
+        trace!("started queue {index}");
+
         Ok(())
     }
 
@@ -631,7 +627,7 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
 
         // This request should be handled only when VHOST_USER_F_PROTOCOL_FEATURES
         // has been negotiated.
-        if self.backend.acked_features() & 1 << VHOST_USER_F_PROTOCOL_FEATURES == 0 {
+        if self.acked_features & 1 << VHOST_USER_F_PROTOCOL_FEATURES == 0 {
             return Err(VhostError::InvalidOperation);
         }
 
@@ -711,116 +707,95 @@ impl<T: VhostUserDevice> vmm_vhost::Backend for DeviceRequestHandler<T> {
         Ok(())
     }
 
-    fn get_shared_memory_regions(&mut self) -> VhostResult<Vec<VhostSharedMemoryRegion>> {
-        Ok(if let Some(r) = self.backend.get_shared_memory_region() {
-            vec![VhostSharedMemoryRegion::new(r.id, r.length)]
-        } else {
-            Vec::new()
-        })
-    }
-
-    fn sleep(&mut self) -> VhostResult<()> {
-        for (index, vring) in self
-            .vrings
-            .iter_mut()
-            .enumerate()
-            .filter(|(_index, vring)| vring.queue.ready())
-        {
-            match self.backend.stop_queue(index) {
-                Ok(queue) => vring.paused_queue = Some(queue),
-                Err(e) => {
-                    error!("failed to stop queue index {}: {:#}", index, e);
-                    return Err(VhostError::StopQueueError(e));
-                }
-            }
+    fn set_device_state_fd(
+        &mut self,
+        transfer_direction: VhostUserTransferDirection,
+        migration_phase: VhostUserMigrationPhase,
+        mut fd: File,
+    ) -> VhostResult<Option<File>> {
+        if migration_phase != VhostUserMigrationPhase::Stopped {
+            return Err(VhostError::InvalidOperation);
         }
-        self.backend
-            .stop_non_queue_workers()
-            .map_err(VhostError::SleepError)
-    }
-
-    fn wake(&mut self) -> VhostResult<()> {
-        for (index, vring) in self.vrings.iter_mut().enumerate() {
-            if let Some(queue) = vring.paused_queue.take() {
-                let mem = self.mem.clone().ok_or(VhostError::BackendInternalError)?;
-                let doorbell = vring.doorbell.clone().expect("Failed to clone doorbell");
-
-                if let Err(e) = self.backend.start_queue(index, queue, mem, doorbell) {
-                    error!("Failed to start queue {}: {}", index, e);
-                    return Err(VhostError::BackendInternalError);
-                }
+        if !self.all_queues_stopped() {
+            return Err(VhostError::InvalidOperation);
+        }
+        if self.device_state_thread.is_some() {
+            error!("must call check_device_state before starting new state transfer");
+            return Err(VhostError::InvalidOperation);
+        }
+        // `set_device_state_fd` is designed to allow snapshot/restore concurrently with other
+        // methods, but, for simplicitly, we do those operations inline and only spawn a thread to
+        // handle the serialization and data transfer (the latter which seems necessary to
+        // implement the API correctly without, e.g., deadlocking because a pipe is full).
+        match transfer_direction {
+            VhostUserTransferDirection::Save => {
+                // Snapshot the state.
+                let snapshot = DeviceRequestHandlerSnapshot {
+                    acked_features: self.acked_features,
+                    acked_protocol_features: self.acked_protocol_features.bits(),
+                    backend: self.backend.snapshot().map_err(VhostError::SnapshotError)?,
+                };
+                // Spawn thread to write the serialized bytes.
+                self.device_state_thread = Some(DeviceStateThread::Save(WorkerThread::start(
+                    "device_state_save",
+                    move |_kill_event| serde_json::to_writer(&mut fd, &snapshot),
+                )));
+                Ok(None)
+            }
+            VhostUserTransferDirection::Load => {
+                // Spawn a thread to read the bytes and deserialize. Restore will happen in
+                // `check_device_state`.
+                self.device_state_thread = Some(DeviceStateThread::Load(WorkerThread::start(
+                    "device_state_load",
+                    move |_kill_event| serde_json::from_reader(&mut fd),
+                )));
+                Ok(None)
             }
         }
-        Ok(())
     }
 
-    fn snapshot(&mut self) -> VhostResult<Vec<u8>> {
-        match serde_json::to_vec(&DeviceRequestHandlerSnapshot {
-            vrings: self
-                .vrings
-                .iter()
-                .map(|vring| vring.snapshot())
-                .collect::<anyhow::Result<Vec<VringSnapshot>>>()
-                .map_err(VhostError::SnapshotError)?,
-            backend: self.backend.snapshot().map_err(VhostError::SnapshotError)?,
-        }) {
-            Ok(serialized_json) => Ok(serialized_json),
-            Err(e) => {
-                error!("Failed to serialize DeviceRequestHandlerSnapshot: {}", e);
-                Err(VhostError::SerializationFailed)
+    fn check_device_state(&mut self) -> VhostResult<()> {
+        let Some(thread) = self.device_state_thread.take() else {
+            error!("check_device_state: no active state transfer");
+            return Err(VhostError::InvalidOperation);
+        };
+        match thread {
+            DeviceStateThread::Save(worker) => {
+                worker.stop().map_err(|e| {
+                    error!("device state save thread failed: {:#}", e);
+                    VhostError::BackendInternalError
+                })?;
+                Ok(())
+            }
+            DeviceStateThread::Load(worker) => {
+                let snapshot = worker.stop().map_err(|e| {
+                    error!("device state load thread failed: {:#}", e);
+                    VhostError::BackendInternalError
+                })?;
+                self.acked_features = snapshot.acked_features;
+                self.acked_protocol_features =
+                    VhostUserProtocolFeatures::from_bits(snapshot.acked_protocol_features)
+                        .with_context(|| {
+                            format!(
+                                "unsupported bits in acked_protocol_features: {:#x}",
+                                snapshot.acked_protocol_features
+                            )
+                        })
+                        .map_err(VhostError::RestoreError)?;
+                self.backend
+                    .restore(snapshot.backend)
+                    .map_err(VhostError::RestoreError)?;
+                Ok(())
             }
         }
     }
 
-    fn restore(&mut self, data_bytes: &[u8], queue_evts: Vec<File>) -> VhostResult<()> {
-        let device_request_handler_snapshot: DeviceRequestHandlerSnapshot =
-            serde_json::from_slice(data_bytes).map_err(|e| {
-                error!("Failed to deserialize DeviceRequestHandlerSnapshot: {}", e);
-                VhostError::DeserializationFailed
-            })?;
-
-        let mem = self.mem.as_ref().ok_or(VhostError::InvalidOperation)?;
-
-        let snapshotted_vrings = device_request_handler_snapshot.vrings;
-        assert_eq!(snapshotted_vrings.len(), self.vrings.len());
-
-        let mut queue_evts_iter = if queue_evts.is_empty() {
-            None
+    fn get_shared_memory_regions(&mut self) -> VhostResult<Vec<VhostSharedMemoryRegion>> {
+        Ok(if let Some(r) = self.backend.get_shared_memory_region() {
+            vec![VhostSharedMemoryRegion::new(r.id, r.length)]
         } else {
-            Some(queue_evts.into_iter())
-        };
-
-        for (index, (vring, snapshotted_vring)) in self
-            .vrings
-            .iter_mut()
-            .zip(snapshotted_vrings.into_iter())
-            .enumerate()
-        {
-            let queue_evt = if let Some(queue_evts_iter) = &mut queue_evts_iter {
-                // TODO(b/288596005): It is assumed that the index of `queue_evts` should map to the
-                // index of `self.vrings`. However, this assumption may break in the future, so a
-                // Map of indexes to queue_evt should be used to support sparse activated queues.
-                let queue_evt_file = queue_evts_iter
-                    .next()
-                    .ok_or(VhostError::VringIndexNotFound(index))?;
-                Some(VhostUserRegularOps::set_vring_kick(
-                    index as u8,
-                    Some(queue_evt_file),
-                )?)
-            } else {
-                None
-            };
-
-            vring
-                .restore(snapshotted_vring, mem, queue_evt)
-                .map_err(VhostError::RestoreError)?;
-        }
-
-        self.backend
-            .restore(device_request_handler_snapshot.backend)
-            .map_err(VhostError::RestoreError)?;
-
-        Ok(())
+            Vec::new()
+        })
     }
 }
 
@@ -936,12 +911,7 @@ impl SharedMemoryMapper for VhostShmemMapper {
                     } => (descriptor, offset, size),
                     VmMemorySource::SharedMemory(shmem) => {
                         let size = shmem.size();
-                        let descriptor =
-                            // SAFETY:
-                            // Safe because we own shmem.
-                            unsafe {
-                                SafeDescriptor::from_raw_descriptor(shmem.into_raw_descriptor())
-                            };
+                        let descriptor = SafeDescriptor::from(shmem);
                         (descriptor, 0, size)
                     }
                     _ => bail!("unsupported source"),
@@ -998,7 +968,6 @@ mod tests {
     use std::sync::mpsc::channel;
     use std::sync::Barrier;
 
-    use anyhow::anyhow;
     use anyhow::bail;
     use base::Event;
     use vmm_vhost::BackendServer;
@@ -1007,7 +976,6 @@ mod tests {
     use zerocopy::FromBytes;
     use zerocopy::FromZeroes;
 
-    use super::sys::test_helpers;
     use super::*;
     use crate::virtio::vhost_user_frontend::VhostUserFrontend;
     use crate::virtio::DeviceType;
@@ -1025,12 +993,16 @@ mod tests {
     pub(super) struct FakeBackend {
         avail_features: u64,
         acked_features: u64,
-        acked_protocol_features: VhostUserProtocolFeatures,
         active_queues: Vec<Option<Queue>>,
         allow_backend_req: bool,
         backend_conn: Option<Arc<VhostBackendReqConnection>>,
     }
 
+    #[derive(Deserialize, Serialize)]
+    struct FakeBackendSnapshot {
+        data: Vec<u8>,
+    }
+
     impl FakeBackend {
         const MAX_QUEUE_NUM: usize = 16;
 
@@ -1040,7 +1012,6 @@ mod tests {
             Self {
                 avail_features: 1 << VHOST_USER_F_PROTOCOL_FEATURES,
                 acked_features: 0,
-                acked_protocol_features: VhostUserProtocolFeatures::empty(),
                 active_queues,
                 allow_backend_req: false,
                 backend_conn: None,
@@ -1069,32 +1040,15 @@ mod tests {
             Ok(())
         }
 
-        fn acked_features(&self) -> u64 {
-            self.acked_features
-        }
-
         fn protocol_features(&self) -> VhostUserProtocolFeatures {
-            let mut features = VhostUserProtocolFeatures::CONFIG;
+            let mut features =
+                VhostUserProtocolFeatures::CONFIG | VhostUserProtocolFeatures::DEVICE_STATE;
             if self.allow_backend_req {
                 features |= VhostUserProtocolFeatures::BACKEND_REQ;
             }
             features
         }
 
-        fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-            let features = VhostUserProtocolFeatures::from_bits(features).ok_or(anyhow!(
-                "invalid protocol features are given: 0x{:x}",
-                features
-            ))?;
-            let supported = self.protocol_features();
-            self.acked_protocol_features = features & supported;
-            Ok(())
-        }
-
-        fn acked_protocol_features(&self) -> u64 {
-            self.acked_protocol_features.bits()
-        }
-
         fn read_config(&self, offset: u64, dst: &mut [u8]) {
             dst.copy_from_slice(&FAKE_CONFIG_DATA.as_bytes()[offset as usize..]);
         }
@@ -1106,7 +1060,6 @@ mod tests {
             idx: usize,
             queue: Queue,
             _mem: GuestMemory,
-            _doorbell: Interrupt,
         ) -> anyhow::Result<()> {
             self.active_queues[idx] = Some(queue);
             Ok(())
@@ -1121,23 +1074,42 @@ mod tests {
         fn set_backend_req_connection(&mut self, conn: Arc<VhostBackendReqConnection>) {
             self.backend_conn = Some(conn);
         }
+
+        fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
+            Ok(())
+        }
+
+        fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+            serde_json::to_value(FakeBackendSnapshot {
+                data: vec![1, 2, 3],
+            })
+            .context("failed to serialize snapshot")
+        }
+
+        fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
+            let snapshot: FakeBackendSnapshot =
+                serde_json::from_value(data).context("failed to deserialize snapshot")?;
+            assert_eq!(snapshot.data, vec![1, 2, 3], "bad snapshot data");
+            Ok(())
+        }
     }
 
     #[test]
-    fn test_vhost_user_activate() {
-        test_vhost_user_activate_parameterized(false);
+    fn test_vhost_user_lifecycle() {
+        test_vhost_user_lifecycle_parameterized(false);
     }
 
     #[test]
     #[cfg(not(windows))] // Windows requries more complex connection setup.
-    fn test_vhost_user_activate_with_backend_req() {
-        test_vhost_user_activate_parameterized(true);
+    fn test_vhost_user_lifecycle_with_backend_req() {
+        test_vhost_user_lifecycle_parameterized(true);
     }
 
-    fn test_vhost_user_activate_parameterized(allow_backend_req: bool) {
+    fn test_vhost_user_lifecycle_parameterized(allow_backend_req: bool) {
         const QUEUES_NUM: usize = 2;
 
-        let (dev, vmm) = test_helpers::setup();
+        let (client_connection, server_connection) =
+            vmm_vhost::Connection::<FrontendReq>::pair().unwrap();
 
         let vmm_bar = Arc::new(Barrier::new(2));
         let dev_bar = vmm_bar.clone();
@@ -1149,10 +1121,9 @@ mod tests {
             // VMM side
             ready_rx.recv().unwrap(); // Ensure the device is ready.
 
-            let connection = test_helpers::connect(vmm);
-
             let mut vmm_device =
-                VhostUserFrontend::new(DeviceType::Console, 0, connection, None, None).unwrap();
+                VhostUserFrontend::new(DeviceType::Console, 0, client_connection, None, None)
+                    .unwrap();
 
             println!("read_config");
             let mut buf = vec![0; std::mem::size_of::<FakeConfig>()];
@@ -1170,7 +1141,7 @@ mod tests {
                     let mut queue = QueueConfig::new(0x10, 0);
                     queue.set_ready(true);
                     let queue = queue
-                        .activate(&mem, Event::new().unwrap())
+                        .activate(&mem, Event::new().unwrap(), interrupt.clone())
                         .expect("QueueConfig::activate");
                     queues.insert(idx, queue);
                 }
@@ -1194,10 +1165,26 @@ mod tests {
             activate(&mut vmm_device);
 
             println!("virtio_sleep");
-            vmm_device.virtio_sleep().unwrap();
+            let queues = vmm_device
+                .virtio_sleep()
+                .unwrap()
+                .expect("virtio_sleep unexpectedly returned None");
+
+            println!("virtio_snapshot");
+            let snapshot = vmm_device
+                .virtio_snapshot()
+                .expect("virtio_snapshot failed");
+            println!("virtio_restore");
+            vmm_device
+                .virtio_restore(snapshot)
+                .expect("virtio_restore failed");
 
             println!("virtio_wake");
-            vmm_device.virtio_wake(None).unwrap();
+            let mem = GuestMemory::new(&[(GuestAddress(0x0), 0x10000)]).unwrap();
+            let interrupt = Interrupt::new_for_test_with_msix();
+            vmm_device
+                .virtio_wake(Some((mem, interrupt, queues)))
+                .unwrap();
 
             println!("wait for shutdown signal");
             shutdown_rx.recv().unwrap();
@@ -1216,7 +1203,7 @@ mod tests {
         // Notify listener is ready.
         ready_tx.send(()).unwrap();
 
-        let mut req_handler = test_helpers::listen(dev, handler);
+        let mut req_handler = BackendServer::new(server_connection, handler);
 
         // VhostUserFrontend::new()
         handle_request(&mut req_handler, FrontendReq::SET_OWNER).unwrap();
@@ -1272,10 +1259,28 @@ mod tests {
         }
 
         // VhostUserFrontend::virtio_sleep()
-        handle_request(&mut req_handler, FrontendReq::SLEEP).unwrap();
+        for _ in 0..QUEUES_NUM {
+            handle_request(&mut req_handler, FrontendReq::SET_VRING_ENABLE).unwrap();
+            handle_request(&mut req_handler, FrontendReq::GET_VRING_BASE).unwrap();
+        }
+
+        // VhostUserFrontend::virtio_snapshot()
+        handle_request(&mut req_handler, FrontendReq::SET_DEVICE_STATE_FD).unwrap();
+        handle_request(&mut req_handler, FrontendReq::CHECK_DEVICE_STATE).unwrap();
+        // VhostUserFrontend::virtio_restore()
+        handle_request(&mut req_handler, FrontendReq::SET_DEVICE_STATE_FD).unwrap();
+        handle_request(&mut req_handler, FrontendReq::CHECK_DEVICE_STATE).unwrap();
 
         // VhostUserFrontend::virtio_wake()
-        handle_request(&mut req_handler, FrontendReq::WAKE).unwrap();
+        handle_request(&mut req_handler, FrontendReq::SET_MEM_TABLE).unwrap();
+        for _ in 0..QUEUES_NUM {
+            handle_request(&mut req_handler, FrontendReq::SET_VRING_NUM).unwrap();
+            handle_request(&mut req_handler, FrontendReq::SET_VRING_ADDR).unwrap();
+            handle_request(&mut req_handler, FrontendReq::SET_VRING_BASE).unwrap();
+            handle_request(&mut req_handler, FrontendReq::SET_VRING_CALL).unwrap();
+            handle_request(&mut req_handler, FrontendReq::SET_VRING_KICK).unwrap();
+            handle_request(&mut req_handler, FrontendReq::SET_VRING_ENABLE).unwrap();
+        }
 
         if allow_backend_req {
             // Make sure the connection still works even after sleep/wake.
diff --git a/devices/src/virtio/vhost/user/device/handler/sys.rs b/devices/src/virtio/vhost/user/device/handler/sys.rs
index 1c0e093b8..dd795951f 100644
--- a/devices/src/virtio/vhost/user/device/handler/sys.rs
+++ b/devices/src/virtio/vhost/user/device/handler/sys.rs
@@ -5,11 +5,7 @@
 cfg_if::cfg_if! {
     if #[cfg(any(target_os = "android", target_os = "linux"))] {
         pub mod linux;
-        #[cfg(test)]
-        pub use linux::test_helpers;
     } else if #[cfg(windows)] {
         pub mod windows;
-        #[cfg(test)]
-        pub use windows::test_helpers;
     }
 }
diff --git a/devices/src/virtio/vhost/user/device/handler/sys/linux.rs b/devices/src/virtio/vhost/user/device/handler/sys/linux.rs
index cf8d0ee0d..f3029b045 100644
--- a/devices/src/virtio/vhost/user/device/handler/sys/linux.rs
+++ b/devices/src/virtio/vhost/user/device/handler/sys/linux.rs
@@ -50,39 +50,3 @@ where
         backend_server.process_message(hdr, files)?;
     }
 }
-
-#[cfg(test)]
-pub mod test_helpers {
-    use std::os::unix::net::UnixStream;
-
-    use tempfile::TempDir;
-    use vmm_vhost::connection::Listener;
-    use vmm_vhost::unix::SocketListener;
-    use vmm_vhost::BackendServer;
-
-    pub(crate) fn setup() -> (SocketListener, TempDir) {
-        let dir = tempfile::Builder::new()
-            .prefix("/tmp/vhost_test")
-            .tempdir()
-            .unwrap();
-        let mut path = dir.path().to_owned();
-        path.push("sock");
-        let listener = SocketListener::new(&path, true).unwrap();
-
-        (listener, dir)
-    }
-
-    pub(crate) fn connect(dir: tempfile::TempDir) -> UnixStream {
-        let mut path = dir.path().to_owned();
-        path.push("sock");
-        UnixStream::connect(path).unwrap()
-    }
-
-    pub(crate) fn listen<S: vmm_vhost::Backend>(
-        mut listener: SocketListener,
-        handler: S,
-    ) -> BackendServer<S> {
-        let connection = listener.accept().unwrap().unwrap();
-        BackendServer::new(connection, handler)
-    }
-}
diff --git a/devices/src/virtio/vhost/user/device/handler/sys/windows.rs b/devices/src/virtio/vhost/user/device/handler/sys/windows.rs
index f7b771893..1e9d6e26f 100644
--- a/devices/src/virtio/vhost/user/device/handler/sys/windows.rs
+++ b/devices/src/virtio/vhost/user/device/handler/sys/windows.rs
@@ -23,6 +23,7 @@ use tube_transporter::TubeTransporterReader;
 use vmm_vhost::message::FrontendReq;
 use vmm_vhost::message::VhostUserMsgHeader;
 use vmm_vhost::BackendServer;
+use vmm_vhost::Connection;
 
 pub fn read_from_tube_transporter(
     raw_transport_tube: RawDescriptor,
@@ -50,16 +51,22 @@ pub async fn run_handler(
     exit_event: Event,
     ex: &Executor,
 ) -> Result<()> {
-    let read_notifier = vhost_user_tube.get_read_notifier();
-    let close_notifier = vhost_user_tube.get_close_notifier();
+    let read_notifier = vhost_user_tube
+        .get_read_notifier_event()
+        .try_clone()
+        .context("failed to clone event")?;
+    let close_notifier = vhost_user_tube
+        .get_close_notifier_event()
+        .try_clone()
+        .context("failed to clone event")?;
 
-    let read_event = EventAsync::clone_raw_without_reset(read_notifier, ex)
+    let read_event = EventAsync::new_without_reset(read_notifier, ex)
         .context("failed to create an async event")?;
-    let close_event = EventAsync::clone_raw_without_reset(close_notifier, ex)
+    let close_event = EventAsync::new_without_reset(close_notifier, ex)
         .context("failed to create an async event")?;
     let exit_event = EventAsync::new(exit_event, ex).context("failed to create an async event")?;
 
-    let mut backend_server = BackendServer::from_stream(vhost_user_tube, handler);
+    let mut backend_server = BackendServer::new(Connection::from(vhost_user_tube), handler);
 
     let read_event_fut = read_event.next_val().fuse();
     let close_event_fut = close_event.next_val().fuse();
@@ -107,22 +114,3 @@ pub async fn run_handler(
         }
     }
 }
-
-#[cfg(test)]
-pub mod test_helpers {
-    use base::Tube;
-    use vmm_vhost::message::FrontendReq;
-    use vmm_vhost::BackendServer;
-
-    pub(crate) fn setup() -> (Tube, Tube) {
-        Tube::pair().unwrap()
-    }
-
-    pub(crate) fn connect(tube: Tube) -> Tube {
-        tube
-    }
-
-    pub(crate) fn listen<S: vmm_vhost::Backend>(dev_tube: Tube, handler: S) -> BackendServer<S> {
-        BackendServer::from_stream(dev_tube, handler)
-    }
-}
diff --git a/devices/src/virtio/vhost/user/device/mod.rs b/devices/src/virtio/vhost/user/device/mod.rs
index 03af3d104..556351aac 100644
--- a/devices/src/virtio/vhost/user/device/mod.rs
+++ b/devices/src/virtio/vhost/user/device/mod.rs
@@ -3,10 +3,10 @@
 // found in the LICENSE file.
 
 mod block;
+mod connection;
 #[cfg(feature = "gpu")]
 pub mod gpu;
 mod handler;
-mod listener;
 #[cfg(feature = "net")]
 mod net;
 #[cfg(feature = "audio")]
@@ -14,6 +14,9 @@ pub mod snd;
 
 pub use block::run_block_device;
 pub use block::Options as BlockOptions;
+pub use connection::sys::VhostUserListener;
+pub use connection::sys::VhostUserStream;
+pub use connection::VhostUserConnectionTrait;
 use cros_async::Executor;
 #[cfg(feature = "gpu")]
 pub use gpu::run_gpu_device;
@@ -21,8 +24,6 @@ pub use gpu::run_gpu_device;
 pub use gpu::Options as GpuOptions;
 pub use handler::VhostBackendReqConnectionState;
 pub use handler::VhostUserDevice;
-pub use listener::sys::VhostUserListener;
-pub use listener::VhostUserListenerTrait;
 #[cfg(feature = "net")]
 pub use net::run_net_device;
 #[cfg(feature = "net")]
diff --git a/devices/src/virtio/vhost/user/device/net.rs b/devices/src/virtio/vhost/user/device/net.rs
index 1ed1e06b2..f0fd6e948 100644
--- a/devices/src/virtio/vhost/user/device/net.rs
+++ b/devices/src/virtio/vhost/user/device/net.rs
@@ -5,7 +5,6 @@
 pub mod sys;
 
 use anyhow::anyhow;
-use anyhow::bail;
 use anyhow::Context;
 use base::error;
 use base::AsRawDescriptors;
@@ -36,11 +35,10 @@ use crate::virtio::vhost::user::device::handler::DeviceRequestHandler;
 use crate::virtio::vhost::user::device::handler::Error as DeviceError;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
 use crate::virtio::vhost::user::VhostUserDeviceBuilder;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 
 thread_local! {
-    pub(crate) static NET_EXECUTOR: OnceCell<Executor> = OnceCell::new();
+    pub(crate) static NET_EXECUTOR: OnceCell<Executor> = const { OnceCell::new() };
 }
 
 // TODO(b/188947559): Come up with better way to include these constants. Compiler errors happen
@@ -50,7 +48,6 @@ const MAX_QUEUE_NUM: usize = 3; /* rx, tx, ctrl */
 async fn run_tx_queue<T: TapT>(
     mut queue: Queue,
     mut tap: T,
-    doorbell: Interrupt,
     kick_evt: EventAsync,
     mut stop_rx: oneshot::Receiver<()>,
 ) -> Queue {
@@ -70,7 +67,7 @@ async fn run_tx_queue<T: TapT>(
             }
         }
 
-        process_tx(&doorbell, &mut queue, &mut tap);
+        process_tx(&mut queue, &mut tap);
     }
     queue
 }
@@ -78,7 +75,6 @@ async fn run_tx_queue<T: TapT>(
 async fn run_ctrl_queue<T: TapT>(
     mut queue: Queue,
     mut tap: T,
-    doorbell: Interrupt,
     kick_evt: EventAsync,
     acked_features: u64,
     vq_pairs: u16,
@@ -100,7 +96,7 @@ async fn run_ctrl_queue<T: TapT>(
             }
         }
 
-        if let Err(e) = process_ctrl(&doorbell, &mut queue, &mut tap, acked_features, vq_pairs) {
+        if let Err(e) = process_ctrl(&mut queue, &mut tap, acked_features, vq_pairs) {
             error!("Failed to process ctrl queue: {}", e);
             break;
         }
@@ -112,7 +108,6 @@ pub struct NetBackend<T: TapT + IntoAsync> {
     tap: T,
     avail_features: u64,
     acked_features: u64,
-    acked_protocol_features: VhostUserProtocolFeatures,
     mtu: u16,
     #[cfg(all(windows, feature = "slirp"))]
     slirp_kill_event: base::Event,
@@ -155,11 +150,6 @@ where
     }
 
     fn ack_features(&mut self, value: u64) -> anyhow::Result<()> {
-        let unrequested_features = value & !self.avail_features;
-        if unrequested_features != 0 {
-            bail!("invalid features are given: {:#x}", unrequested_features);
-        }
-
         self.acked_features |= value;
 
         self.tap
@@ -169,24 +159,8 @@ where
         Ok(())
     }
 
-    fn acked_features(&self) -> u64 {
-        self.acked_features
-    }
-
     fn protocol_features(&self) -> VhostUserProtocolFeatures {
-        VhostUserProtocolFeatures::CONFIG
-    }
-
-    fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-        let features = VhostUserProtocolFeatures::from_bits(features)
-            .ok_or_else(|| anyhow!("invalid protocol features are given: {:#x}", features))?;
-        let supported = self.protocol_features();
-        self.acked_protocol_features = features & supported;
-        Ok(())
-    }
-
-    fn acked_protocol_features(&self) -> u64 {
-        self.acked_protocol_features.bits()
+        VhostUserProtocolFeatures::CONFIG | VhostUserProtocolFeatures::DEVICE_STATE
     }
 
     fn read_config(&self, offset: u64, data: &mut [u8]) {
@@ -201,9 +175,8 @@ where
         idx: usize,
         queue: virtio::Queue,
         mem: GuestMemory,
-        doorbell: Interrupt,
     ) -> anyhow::Result<()> {
-        sys::start_queue(self, idx, queue, mem, doorbell)
+        sys::start_queue(self, idx, queue, mem)
     }
 
     fn stop_queue(&mut self, idx: usize) -> anyhow::Result<virtio::Queue> {
@@ -226,16 +199,21 @@ where
         }
     }
 
-    fn snapshot(&self) -> anyhow::Result<Vec<u8>> {
-        serde_json::to_vec(&NetBackendSnapshot {
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
+        // No non-queue workers.
+        Ok(())
+    }
+
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        serde_json::to_value(NetBackendSnapshot {
             acked_feature: self.acked_features,
         })
         .context("Failed to serialize NetBackendSnapshot")
     }
 
-    fn restore(&mut self, data: Vec<u8>) -> anyhow::Result<()> {
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
         let net_backend_snapshot: NetBackendSnapshot =
-            serde_json::from_slice(&data).context("Failed to deserialize NetBackendSnapshot")?;
+            serde_json::from_value(data).context("Failed to deserialize NetBackendSnapshot")?;
         self.acked_features = net_backend_snapshot.acked_feature;
         Ok(())
     }
diff --git a/devices/src/virtio/vhost/user/device/net/sys/linux.rs b/devices/src/virtio/vhost/user/device/net/sys/linux.rs
index aacc20dc3..cf0ef08bd 100644
--- a/devices/src/virtio/vhost/user/device/net/sys/linux.rs
+++ b/devices/src/virtio/vhost/user/device/net/sys/linux.rs
@@ -28,21 +28,19 @@ use net_util::MacAddress;
 use net_util::TapT;
 use virtio_sys::virtio_net;
 use vm_memory::GuestMemory;
-use vmm_vhost::message::VhostUserProtocolFeatures;
 use vmm_vhost::VHOST_USER_F_PROTOCOL_FEATURES;
 
 use crate::virtio;
 use crate::virtio::net::process_rx;
 use crate::virtio::net::validate_and_configure_tap;
 use crate::virtio::net::NetError;
+use crate::virtio::vhost::user::device::connection::sys::VhostUserListener;
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
-use crate::virtio::vhost::user::device::listener::sys::VhostUserListener;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
 use crate::virtio::vhost::user::device::net::run_ctrl_queue;
 use crate::virtio::vhost::user::device::net::run_tx_queue;
 use crate::virtio::vhost::user::device::net::NetBackend;
 use crate::virtio::vhost::user::device::net::NET_EXECUTOR;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 
 struct TapConfig {
@@ -96,6 +94,11 @@ where
         Self::new(tap)
     }
 
+    fn new_from_name(name: &str) -> anyhow::Result<Self> {
+        let tap = T::new_with_name(name.as_bytes(), true, false).map_err(NetError::TapOpen)?;
+        Self::new(tap)
+    }
+
     pub fn new_from_tap_fd(tap_fd: RawDescriptor) -> anyhow::Result<Self> {
         let tap_fd = validate_raw_descriptor(tap_fd).context("failed to validate tap fd")?;
         // SAFETY:
@@ -128,7 +131,6 @@ where
             tap,
             avail_features,
             acked_features: 0,
-            acked_protocol_features: VhostUserProtocolFeatures::empty(),
             mtu,
             workers: Default::default(),
         })
@@ -138,7 +140,6 @@ where
 async fn run_rx_queue<T: TapT>(
     mut queue: Queue,
     mut tap: IoSource<T>,
-    doorbell: Interrupt,
     kick_evt: EventAsync,
     mut stop_rx: oneshot::Receiver<()>,
 ) -> Queue {
@@ -159,7 +160,7 @@ async fn run_rx_queue<T: TapT>(
             }
         }
 
-        match process_rx(&doorbell, &mut queue, tap.as_source_mut()) {
+        match process_rx(&mut queue, tap.as_source_mut()) {
             Ok(()) => {}
             Err(NetError::RxDescriptorsExhausted) => {
                 if let Err(e) = kick_evt.next_val().await {
@@ -182,7 +183,6 @@ pub(in crate::virtio::vhost::user::device::net) fn start_queue<T: 'static + Into
     idx: usize,
     queue: virtio::Queue,
     _mem: GuestMemory,
-    doorbell: Interrupt,
 ) -> anyhow::Result<()> {
     if backend.workers[idx].is_some() {
         warn!("Starting new queue handler without stopping old handler");
@@ -211,14 +211,14 @@ pub(in crate::virtio::vhost::user::device::net) fn start_queue<T: 'static + Into
 
                 let (stop_tx, stop_rx) = futures::channel::oneshot::channel();
                 (
-                    ex.spawn_local(run_rx_queue(queue, tap, doorbell, kick_evt, stop_rx)),
+                    ex.spawn_local(run_rx_queue(queue, tap, kick_evt, stop_rx)),
                     stop_tx,
                 )
             }
             1 => {
                 let (stop_tx, stop_rx) = futures::channel::oneshot::channel();
                 (
-                    ex.spawn_local(run_tx_queue(queue, tap, doorbell, kick_evt, stop_rx)),
+                    ex.spawn_local(run_tx_queue(queue, tap, kick_evt, stop_rx)),
                     stop_tx,
                 )
             }
@@ -228,7 +228,6 @@ pub(in crate::virtio::vhost::user::device::net) fn start_queue<T: 'static + Into
                     ex.spawn_local(run_ctrl_queue(
                         queue,
                         tap,
-                        doorbell,
                         kick_evt,
                         backend.acked_features,
                         1, /* vq_pairs */
@@ -255,6 +254,9 @@ pub struct Options {
     #[argh(option, arg_name = "SOCKET_PATH,TAP_FD")]
     /// TAP FD with a socket path"
     tap_fd: Vec<String>,
+    #[argh(option, arg_name = "SOCKET_PATH,TAP_NAME")]
+    /// TAP NAME with a socket path
+    tap_name: Vec<String>,
 }
 
 enum Connection {
@@ -276,6 +278,21 @@ fn new_backend_from_device_arg(arg: &str) -> anyhow::Result<(String, NetBackend<
     Ok((conn.to_string(), backend))
 }
 
+fn new_backend_from_tap_name(arg: &str) -> anyhow::Result<(String, NetBackend<Tap>)> {
+    let pos = match arg.find(',') {
+        Some(p) => p,
+        None => {
+            bail!("device must take comma-separated argument");
+        }
+    };
+    let conn = &arg[0..pos];
+    let tap_name = &arg[pos + 1..];
+
+    let backend =
+        NetBackend::<Tap>::new_from_name(tap_name).context("failed to create NetBackend")?;
+    Ok((conn.to_string(), backend))
+}
+
 fn new_backend_from_tapfd_arg(arg: &str) -> anyhow::Result<(String, NetBackend<Tap>)> {
     let pos = match arg.find(',') {
         Some(p) => p,
@@ -296,7 +313,7 @@ fn new_backend_from_tapfd_arg(arg: &str) -> anyhow::Result<(String, NetBackend<T
 /// Starts a vhost-user net device.
 /// Returns an error if the given `args` is invalid or the device fails to run.
 pub fn start_device(opts: Options) -> anyhow::Result<()> {
-    let num_devices = opts.device.len() + opts.tap_fd.len();
+    let num_devices = opts.device.len() + opts.tap_fd.len() + opts.tap_name.len();
 
     if num_devices == 0 {
         bail!("no device option was passed");
@@ -311,6 +328,12 @@ pub fn start_device(opts: Options) -> anyhow::Result<()> {
                 .map(|(s, backend)| (Connection::Socket(s), backend))?,
         );
     }
+
+    for arg in opts.tap_name.iter() {
+        devices.push(
+            new_backend_from_tap_name(arg).map(|(s, backend)| (Connection::Socket(s), backend))?,
+        );
+    }
     for arg in opts.tap_fd.iter() {
         devices.push(
             new_backend_from_tapfd_arg(arg).map(|(s, backend)| (Connection::Socket(s), backend))?,
@@ -328,7 +351,7 @@ pub fn start_device(opts: Options) -> anyhow::Result<()> {
                     NET_EXECUTOR.with(|thread_ex| {
                         let _ = thread_ex.set(ex.clone());
                     });
-                    let listener = VhostUserListener::new_socket(&socket, None)?;
+                    let listener = VhostUserListener::new(&socket)?;
                     // run_until() returns an Result<Result<..>> which the ? operator lets us
                     // flatten.
                     ex.run_until(listener.run_backend(backend, &ex))?
diff --git a/devices/src/virtio/vhost/user/device/net/sys/windows.rs b/devices/src/virtio/vhost/user/device/net/sys/windows.rs
index 150e5bd64..768343436 100644
--- a/devices/src/virtio/vhost/user/device/net/sys/windows.rs
+++ b/devices/src/virtio/vhost/user/device/net/sys/windows.rs
@@ -38,7 +38,6 @@ use sync::Mutex;
 use tube_transporter::TubeToken;
 use virtio_sys::virtio_net;
 use vm_memory::GuestMemory;
-use vmm_vhost::message::VhostUserProtocolFeatures;
 use vmm_vhost::VHOST_USER_F_PROTOCOL_FEATURES;
 
 use crate::virtio;
@@ -77,7 +76,6 @@ where
             tap: slirp,
             avail_features,
             acked_features: 0,
-            acked_protocol_features: VhostUserProtocolFeatures::empty(),
             mtu: 1500,
             slirp_kill_event,
             workers: Default::default(),
@@ -88,7 +86,6 @@ where
 async fn run_rx_queue<T: TapT>(
     mut queue: Queue,
     mut tap: IoSource<T>,
-    call_evt: Interrupt,
     kick_evt: EventAsync,
     read_notifier: EventAsync,
     mut overlapped_wrapper: OverlappedWrapper,
@@ -134,7 +131,6 @@ async fn run_rx_queue<T: TapT>(
         }
 
         let needs_interrupt = process_rx(
-            &call_evt,
             &mut queue,
             tap.as_source_mut(),
             &mut rx_buf,
@@ -143,7 +139,7 @@ async fn run_rx_queue<T: TapT>(
             &mut overlapped_wrapper,
         );
         if needs_interrupt {
-            call_evt.signal_used_queue(queue.vector());
+            queue.trigger_interrupt();
         }
 
         // There aren't any RX descriptors available for us to write packets to. Wait for the guest
@@ -173,7 +169,6 @@ pub(in crate::virtio::vhost::user::device::net) fn start_queue<T: 'static + Into
     idx: usize,
     queue: virtio::Queue,
     _mem: GuestMemory,
-    doorbell: Interrupt,
 ) -> anyhow::Result<()> {
     if backend.workers.get(idx).is_some() {
         warn!("Starting new queue handler without stopping old handler");
@@ -215,7 +210,6 @@ pub(in crate::virtio::vhost::user::device::net) fn start_queue<T: 'static + Into
                     ex.spawn_local(run_rx_queue(
                         queue,
                         tap,
-                        doorbell,
                         kick_evt,
                         read_notifier,
                         overlapped_wrapper,
@@ -227,7 +221,7 @@ pub(in crate::virtio::vhost::user::device::net) fn start_queue<T: 'static + Into
             1 => {
                 let (stop_tx, stop_rx) = futures::channel::oneshot::channel();
                 (
-                    ex.spawn_local(run_tx_queue(queue, tap, doorbell, kick_evt, stop_rx)),
+                    ex.spawn_local(run_tx_queue(queue, tap, kick_evt, stop_rx)),
                     stop_tx,
                 )
             }
@@ -237,7 +231,6 @@ pub(in crate::virtio::vhost::user::device::net) fn start_queue<T: 'static + Into
                     ex.spawn_local(run_ctrl_queue(
                         queue,
                         tap,
-                        doorbell,
                         kick_evt,
                         backend.acked_features,
                         1, /* vq_pairs */
diff --git a/devices/src/virtio/vhost/user/device/snd.rs b/devices/src/virtio/vhost/user/device/snd.rs
index e54436a97..759b2a306 100644
--- a/devices/src/virtio/vhost/user/device/snd.rs
+++ b/devices/src/virtio/vhost/user/device/snd.rs
@@ -18,7 +18,6 @@ use cros_async::Executor;
 use futures::channel::mpsc;
 use futures::FutureExt;
 use hypervisor::ProtectionType;
-use once_cell::sync::OnceCell;
 use serde::Deserialize;
 use serde::Serialize;
 pub use sys::run_snd_device;
@@ -52,11 +51,8 @@ use crate::virtio::vhost::user::device::handler::Error as DeviceError;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
 use crate::virtio::vhost::user::device::handler::WorkerState;
 use crate::virtio::vhost::user::VhostUserDeviceBuilder;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 
-static SND_EXECUTOR: OnceCell<Executor> = OnceCell::new();
-
 // Async workers:
 // 0 - ctrl
 // 1 - event
@@ -64,10 +60,9 @@ static SND_EXECUTOR: OnceCell<Executor> = OnceCell::new();
 // 3 - rx
 const PCM_RESPONSE_WORKER_IDX_OFFSET: usize = 2;
 struct SndBackend {
+    ex: Executor,
     cfg: virtio_snd_config,
     avail_features: u64,
-    acked_features: u64,
-    acked_protocol_features: VhostUserProtocolFeatures,
     workers: [Option<WorkerState<Rc<AsyncRwLock<Queue>>, Result<(), Error>>>; MAX_QUEUE_NUM],
     // tx and rx
     response_workers: [Option<WorkerState<Rc<AsyncRwLock<Queue>>, Result<(), Error>>>; 2],
@@ -77,37 +72,48 @@ struct SndBackend {
     rx_send: mpsc::UnboundedSender<PcmResponse>,
     tx_recv: Option<mpsc::UnboundedReceiver<PcmResponse>>,
     rx_recv: Option<mpsc::UnboundedReceiver<PcmResponse>>,
+    // Appended to logs for when there are mutliple audio devices.
+    card_index: usize,
 }
 
 #[derive(Serialize, Deserialize)]
 struct SndBackendSnapshot {
     avail_features: u64,
-    acked_features: u64,
-    acked_protocol_features: u64,
     stream_infos: Option<Vec<StreamInfoSnapshot>>,
     snd_data: SndData,
 }
 
 impl SndBackend {
-    pub fn new(params: Parameters) -> anyhow::Result<Self> {
+    pub fn new(
+        ex: &Executor,
+        params: Parameters,
+        #[cfg(windows)] audio_client_guid: Option<String>,
+        card_index: usize,
+    ) -> anyhow::Result<Self> {
         let cfg = hardcoded_virtio_snd_config(&params);
         let avail_features = virtio::base_features(ProtectionType::Unprotected)
             | 1 << VHOST_USER_F_PROTOCOL_FEATURES;
 
         let snd_data = hardcoded_snd_data(&params);
         let mut keep_rds = Vec::new();
-        let builders = create_stream_info_builders(&params, &snd_data, &mut keep_rds)?;
+        let builders = create_stream_info_builders(&params, &snd_data, &mut keep_rds, card_index)?;
 
         if snd_data.pcm_info_len() != builders.len() {
             error!(
-                "snd: expected {} stream info builders, got {}",
+                "[Card {}] snd: expected {} stream info builders, got {}",
+                card_index,
                 snd_data.pcm_info_len(),
                 builders.len(),
             )
         }
 
-        let streams = builders
-            .into_iter()
+        let streams = builders.into_iter();
+
+        #[cfg(windows)]
+        let streams = streams
+            .map(|stream_builder| stream_builder.audio_client_guid(audio_client_guid.clone()));
+
+        let streams = streams
             .map(StreamInfoBuilder::build)
             .map(AsyncRwLock::new)
             .collect();
@@ -117,10 +123,9 @@ impl SndBackend {
         let (rx_send, rx_recv) = mpsc::unbounded();
 
         Ok(SndBackend {
+            ex: ex.clone(),
             cfg,
             avail_features,
-            acked_features: 0,
-            acked_protocol_features: VhostUserProtocolFeatures::empty(),
             workers: Default::default(),
             response_workers: Default::default(),
             snd_data: Rc::new(snd_data),
@@ -129,6 +134,7 @@ impl SndBackend {
             rx_send,
             tx_recv: Some(tx_recv),
             rx_recv: Some(rx_recv),
+            card_index,
         })
     }
 }
@@ -149,35 +155,10 @@ impl VhostUserDevice for SndBackend {
         self.avail_features
     }
 
-    fn ack_features(&mut self, value: u64) -> anyhow::Result<()> {
-        let unrequested_features = value & !self.avail_features;
-        if unrequested_features != 0 {
-            bail!("invalid features are given: {:#x}", unrequested_features);
-        }
-
-        self.acked_features |= value;
-
-        Ok(())
-    }
-
-    fn acked_features(&self) -> u64 {
-        self.acked_features
-    }
-
     fn protocol_features(&self) -> VhostUserProtocolFeatures {
-        VhostUserProtocolFeatures::CONFIG | VhostUserProtocolFeatures::MQ
-    }
-
-    fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-        let features = VhostUserProtocolFeatures::from_bits(features)
-            .ok_or_else(|| anyhow!("invalid protocol features are given: {:#x}", features))?;
-        let supported = self.protocol_features();
-        self.acked_protocol_features = features & supported;
-        Ok(())
-    }
-
-    fn acked_protocol_features(&self) -> u64 {
-        self.acked_protocol_features.bits()
+        VhostUserProtocolFeatures::CONFIG
+            | VhostUserProtocolFeatures::MQ
+            | VhostUserProtocolFeatures::DEVICE_STATE
     }
 
     fn read_config(&self, offset: u64, data: &mut [u8]) {
@@ -185,9 +166,8 @@ impl VhostUserDevice for SndBackend {
     }
 
     fn reset(&mut self) {
-        let ex = SND_EXECUTOR.get().expect("Executor not initialized");
         for worker in self.workers.iter_mut().filter_map(Option::take) {
-            let _ = ex.run_until(worker.queue_task.cancel());
+            let _ = self.ex.run_until(worker.queue_task.cancel());
         }
     }
 
@@ -196,23 +176,25 @@ impl VhostUserDevice for SndBackend {
         idx: usize,
         queue: virtio::Queue,
         _mem: GuestMemory,
-        doorbell: Interrupt,
     ) -> anyhow::Result<()> {
         if self.workers[idx].is_some() {
-            warn!("Starting new queue handler without stopping old handler");
+            warn!(
+                "[Card {}] Starting new queue handler without stopping old handler",
+                self.card_index
+            );
             self.stop_queue(idx)?;
         }
 
-        // Safe because the executor is initialized in main() below.
-        let ex = SND_EXECUTOR.get().expect("Executor not initialized");
-
-        let kick_evt = queue
-            .event()
-            .try_clone()
-            .context("failed to clone queue event")?;
-        let mut kick_evt =
-            EventAsync::new(kick_evt, ex).context("failed to create EventAsync for kick_evt")?;
+        let kick_evt = queue.event().try_clone().context(format!(
+            "[Card {}] failed to clone queue event",
+            self.card_index
+        ))?;
+        let mut kick_evt = EventAsync::new(kick_evt, &self.ex).context(format!(
+            "[Card {}] failed to create EventAsync for kick_evt",
+            self.card_index
+        ))?;
         let queue = Rc::new(AsyncRwLock::new(queue));
+        let card_index = self.card_index;
         let queue_task = match idx {
             0 => {
                 // ctrl queue
@@ -221,16 +203,18 @@ impl VhostUserDevice for SndBackend {
                 let tx_send = self.tx_send.clone();
                 let rx_send = self.rx_send.clone();
                 let ctrl_queue = queue.clone();
-                Some(ex.spawn_local(async move {
+
+                let ex_clone = self.ex.clone();
+                Some(self.ex.spawn_local(async move {
                     handle_ctrl_queue(
-                        ex,
+                        &ex_clone,
                         &streams,
                         &snd_data,
                         ctrl_queue,
                         &mut kick_evt,
-                        doorbell,
                         tx_send,
                         rx_send,
+                        card_index,
                         None,
                     )
                     .await
@@ -242,23 +226,26 @@ impl VhostUserDevice for SndBackend {
             // the Queue so we can return it back in stop_queue. As such, we create a do nothing
             // future to "run" this queue so that we track a WorkerState for it (which is how
             // we return the Queue back).
-            1 => Some(ex.spawn_local(async move { Ok(()) })),
+            1 => Some(self.ex.spawn_local(async move { Ok(()) })),
             2 | 3 => {
                 let (send, recv) = if idx == 2 {
                     (self.tx_send.clone(), self.tx_recv.take())
                 } else {
                     (self.rx_send.clone(), self.rx_recv.take())
                 };
-                let mut recv = recv.ok_or_else(|| anyhow!("queue restart is not supported"))?;
+                let mut recv = recv.ok_or_else(|| {
+                    anyhow!("[Card {}] queue restart is not supported", self.card_index)
+                })?;
                 let streams = Rc::clone(&self.streams);
                 let queue_pcm_queue = queue.clone();
-                let queue_task = ex.spawn_local(async move {
-                    handle_pcm_queue(&streams, send, queue_pcm_queue, &kick_evt, None).await
+                let queue_task = self.ex.spawn_local(async move {
+                    handle_pcm_queue(&streams, send, queue_pcm_queue, &kick_evt, card_index, None)
+                        .await
                 });
 
                 let queue_response_queue = queue.clone();
-                let response_queue_task = ex.spawn_local(async move {
-                    send_pcm_response_worker(queue_response_queue, doorbell, &mut recv, None).await
+                let response_queue_task = self.ex.spawn_local(async move {
+                    send_pcm_response_worker(queue_response_queue, &mut recv, None).await
                 });
 
                 self.response_workers[idx - PCM_RESPONSE_WORKER_IDX_OFFSET] = Some(WorkerState {
@@ -268,7 +255,11 @@ impl VhostUserDevice for SndBackend {
 
                 Some(queue_task)
             }
-            _ => bail!("attempted to start unknown queue: {}", idx),
+            _ => bail!(
+                "[Card {}] attempted to start unknown queue: {}",
+                self.card_index,
+                idx
+            ),
         };
 
         if let Some(queue_task) = queue_task {
@@ -278,14 +269,13 @@ impl VhostUserDevice for SndBackend {
     }
 
     fn stop_queue(&mut self, idx: usize) -> anyhow::Result<virtio::Queue> {
-        let ex = SND_EXECUTOR.get().expect("Executor not initialized");
         let worker_queue_rc = self
             .workers
             .get_mut(idx)
             .and_then(Option::take)
             .map(|worker| {
                 // Wait for queue_task to be aborted.
-                let _ = ex.run_until(worker.queue_task.cancel());
+                let _ = self.ex.run_until(worker.queue_task.cancel());
                 worker.queue
             });
 
@@ -296,21 +286,24 @@ impl VhostUserDevice for SndBackend {
                 .and_then(Option::take)
             {
                 // Wait for queue_task to be aborted.
-                let _ = ex.run_until(worker.queue_task.cancel());
+                let _ = self.ex.run_until(worker.queue_task.cancel());
             }
         }
 
         if let Some(queue_rc) = worker_queue_rc {
             match Rc::try_unwrap(queue_rc) {
                 Ok(queue_mutex) => Ok(queue_mutex.into_inner()),
-                Err(_) => panic!("failed to recover queue from worker"),
+                Err(_) => panic!(
+                    "[Card {}] failed to recover queue from worker",
+                    self.card_index
+                ),
             }
         } else {
             Err(anyhow::Error::new(DeviceError::WorkerNotFound))
         }
     }
 
-    fn snapshot(&self) -> anyhow::Result<Vec<u8>> {
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
         // now_or_never will succeed here because no workers are running.
         let stream_info_snaps = if let Some(stream_infos) = &self.streams.lock().now_or_never() {
             let mut snaps = Vec::new();
@@ -319,7 +312,12 @@ impl VhostUserDevice for SndBackend {
                     stream_info
                         .lock()
                         .now_or_never()
-                        .expect("failed to lock audio state during snapshot")
+                        .unwrap_or_else(|| {
+                            panic!(
+                                "[Card {}] failed to lock audio state during snapshot",
+                                self.card_index
+                            )
+                        })
                         .snapshot(),
                 );
             }
@@ -328,50 +326,45 @@ impl VhostUserDevice for SndBackend {
             None
         };
         let snd_data_ref: &SndData = self.snd_data.borrow();
-        serde_json::to_vec(&SndBackendSnapshot {
+        serde_json::to_value(SndBackendSnapshot {
             avail_features: self.avail_features,
-            acked_protocol_features: self.acked_protocol_features.bits(),
-            acked_features: self.acked_features,
             stream_infos: stream_info_snaps,
             snd_data: snd_data_ref.clone(),
         })
-        .context("Failed to serialize SndBackendSnapshot")
+        .context(format!(
+            "[Card {}] Failed to serialize SndBackendSnapshot",
+            self.card_index
+        ))
     }
 
-    fn restore(&mut self, data: Vec<u8>) -> anyhow::Result<()> {
-        let deser: SndBackendSnapshot = serde_json::from_slice(data.as_slice())
-            .context("Failed to deserialize SndBackendSnapshot")?;
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
+        let deser: SndBackendSnapshot = serde_json::from_value(data).context(format!(
+            "[Card {}] Failed to deserialize SndBackendSnapshot",
+            self.card_index
+        ))?;
         anyhow::ensure!(
             deser.avail_features == self.avail_features,
-            "avail features doesn't match on restore: expected: {}, got: {}",
+            "[Card {}] avail features doesn't match on restore: expected: {}, got: {}",
+            self.card_index,
             deser.avail_features,
             self.avail_features
         );
-        anyhow::ensure!(
-            self.acked_protocol_features.bits() == deser.acked_protocol_features,
-            "Vhost user snd restored acked_protocol_features do not match. Live: {:?}, \
-            snapshot: {:?}",
-            self.acked_protocol_features,
-            deser.acked_protocol_features,
-        );
         let snd_data = self.snd_data.borrow();
         anyhow::ensure!(
             &deser.snd_data == snd_data,
-            "snd data doesn't match on restore: expected: {:?}, got: {:?}",
+            "[Card {}] snd data doesn't match on restore: expected: {:?}, got: {:?}",
+            self.card_index,
             deser.snd_data,
             snd_data,
         );
-        self.acked_features = deser.acked_features;
 
-        // Wondering why we can pass ex to a move block *and* still use it
-        // afterwards? It's a &'static, which is the only kind of reference that
-        // can taken by a future run via spawn/spawn_local.
-        let ex = SND_EXECUTOR.get().expect("executor must be initialized");
+        let ex_clone = self.ex.clone();
         let streams_rc = self.streams.clone();
         let tx_send_clone = self.tx_send.clone();
         let rx_send_clone = self.rx_send.clone();
 
-        let restore_task = ex.spawn_local(async move {
+        let card_index = self.card_index;
+        let restore_task = self.ex.spawn_local(async move {
             if let Some(stream_infos) = &deser.stream_infos {
                 for (stream, stream_info) in streams_rc.lock().await.iter().zip(stream_infos.iter())
                 {
@@ -382,27 +375,27 @@ impl VhostUserDevice for SndBackend {
                         stream
                             .lock()
                             .await
-                            .prepare(ex, &tx_send_clone, &rx_send_clone)
+                            .prepare(&ex_clone, &tx_send_clone, &rx_send_clone)
                             .await
-                            .expect("failed to prepare PCM");
+                            .unwrap_or_else(|_| {
+                                panic!("[Card {}] failed to prepare PCM", card_index)
+                            });
                     }
                     if stream_info.state == VIRTIO_SND_R_PCM_START {
-                        stream
-                            .lock()
-                            .await
-                            .start()
-                            .await
-                            .expect("failed to start PCM");
+                        stream.lock().await.start().await.unwrap_or_else(|_| {
+                            panic!("[Card {}] failed to start PCM", card_index)
+                        });
                     }
                 }
             }
         });
-        ex.run_until(restore_task)
-            .expect("failed to restore streams");
+        self.ex
+            .run_until(restore_task)
+            .unwrap_or_else(|_| panic!("[Card {}] failed to restore streams", self.card_index));
         Ok(())
     }
 
-    fn stop_non_queue_workers(&mut self) -> anyhow::Result<()> {
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
         // This device has no non-queue workers to stop.
         Ok(())
     }
diff --git a/devices/src/virtio/vhost/user/device/snd/sys/linux.rs b/devices/src/virtio/vhost/user/device/snd/sys/linux.rs
index f841f75aa..f810e199e 100644
--- a/devices/src/virtio/vhost/user/device/snd/sys/linux.rs
+++ b/devices/src/virtio/vhost/user/device/snd/sys/linux.rs
@@ -7,10 +7,9 @@ use argh::FromArgs;
 use cros_async::Executor;
 
 use crate::virtio::snd::parameters::Parameters;
-use crate::virtio::vhost::user::device::listener::sys::VhostUserListener;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
+use crate::virtio::vhost::user::device::connection::sys::VhostUserListener;
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::snd::SndBackend;
-use crate::virtio::vhost::user::device::snd::SND_EXECUTOR;
 
 #[derive(FromArgs)]
 #[argh(subcommand, name = "snd")]
@@ -48,12 +47,10 @@ fn snd_parameters_from_str(input: &str) -> Result<Parameters, String> {
 /// Starts a vhost-user snd device.
 /// Returns an error if the given `args` is invalid or the device fails to run.
 pub fn run_snd_device(opts: Options) -> anyhow::Result<()> {
-    let snd_device = Box::new(SndBackend::new(opts.params)?);
-
     let ex = Executor::new().context("Failed to create executor")?;
-    let _ = SND_EXECUTOR.set(ex.clone());
+    let snd_device = Box::new(SndBackend::new(&ex, opts.params, 0)?);
 
-    let listener = VhostUserListener::new_socket(&opts.socket, None)?;
+    let listener = VhostUserListener::new(&opts.socket)?;
 
     listener.run_device(ex, snd_device)
 }
diff --git a/devices/src/virtio/vhost/user/device/snd/sys/windows.rs b/devices/src/virtio/vhost/user/device/snd/sys/windows.rs
index 1a06c9b80..f9f462915 100644
--- a/devices/src/virtio/vhost/user/device/snd/sys/windows.rs
+++ b/devices/src/virtio/vhost/user/device/snd/sys/windows.rs
@@ -22,7 +22,6 @@ use crate::virtio::snd::sys::set_audio_thread_priority;
 use crate::virtio::vhost::user::device::handler::sys::windows::read_from_tube_transporter;
 use crate::virtio::vhost::user::device::handler::sys::windows::run_handler;
 use crate::virtio::vhost::user::device::snd::SndBackend;
-use crate::virtio::vhost::user::device::snd::SND_EXECUTOR;
 use crate::virtio::vhost::user::VhostUserDeviceBuilder;
 
 pub mod generic;
@@ -44,6 +43,10 @@ pub struct Options {
 pub struct SndVmmConfig {
     // Tube for setting up the vhost-user connection. May not exist if not using vhost-user.
     pub main_vhost_user_tube: Option<Tube>,
+    // GUID that will be passed into `IAudioClient::Initialize`.
+    pub audio_client_guid: String,
+    // Used to identify the device backend.
+    pub card_index: usize,
     // Product related configuration.
     pub product_config: product::SndVmmConfig,
 }
@@ -58,6 +61,10 @@ pub struct SndBackendConfig {
     pub exit_event: Event,
     // Sound device parameters.
     pub parameters: Parameters,
+    // This field is used to pass this GUID to `IAudioClient::Initialize`.
+    pub audio_client_guid: String,
+    // Used to append to logs in the vhost user device backends.
+    pub card_index: usize,
     // Product related configuration.
     pub product_config: product::SndBackendConfig,
 }
@@ -88,15 +95,6 @@ pub fn run_snd_device(opts: Options) -> anyhow::Result<()> {
         .recv()
         .context("failed to parse Snd backend config from bootstrap tube")?;
 
-    let vhost_user_tube = config
-        .device_vhost_user_tube
-        .expect("vhost-user Snd tube must be set");
-
-    let ex = Executor::new().context("Failed to create executor")?;
-    let _ = SND_EXECUTOR.set(ex.clone());
-
-    let snd_device = Box::new(SndBackend::new(config.parameters)?);
-
     // TODO(b/213170185): Uncomment once sandbox is upstreamed.
     // if sandbox::is_sandbox_target() {
     //     sandbox::TargetServices::get()
@@ -105,22 +103,47 @@ pub fn run_snd_device(opts: Options) -> anyhow::Result<()> {
     //         .lower_token();
     // }
 
+    run_snd_device_worker(config)
+}
+
+/// Run the SND device worker.
+pub fn run_snd_device_worker(config: SndBackendConfig) -> anyhow::Result<()> {
+    let card_index = config.card_index;
+    let vhost_user_tube = config
+        .device_vhost_user_tube
+        .unwrap_or_else(|| panic!("[Card {}] vhost-user Snd tube must be set", card_index));
+
+    let ex = Executor::new().context(format!("[Card {}] Failed to create executor", card_index))?;
+
+    let snd_device = Box::new(SndBackend::new(
+        &ex,
+        config.parameters,
+        Some(config.audio_client_guid),
+        config.card_index,
+    )?);
+
     // Set the audio thread priority here. This assumes our executor is running on a single thread.
     let _thread_priority_handle = set_audio_thread_priority();
     if let Err(e) = _thread_priority_handle {
-        warn!("Failed to set audio thread to real time: {}", e);
+        warn!(
+            "[Card {}] Failed to set audio thread to real time: {}",
+            card_index, e
+        );
     };
 
     let handler = snd_device.build(&ex)?;
 
-    info!("vhost-user snd device ready, starting run loop...");
+    info!(
+        "[Card {}] vhost-user snd device ready, starting run loop...",
+        card_index
+    );
     if let Err(e) = ex.run_until(run_handler(
         handler,
         vhost_user_tube,
         config.exit_event,
         &ex,
     )) {
-        bail!("error occurred: {}", e);
+        bail!("[Card {}] error occurred: {}", card_index, e);
     }
 
     Ok(())
diff --git a/devices/src/virtio/vhost/user/device/vsock.rs b/devices/src/virtio/vhost/user/device/vsock.rs
index 25bb9c390..d0333c61a 100644
--- a/devices/src/virtio/vhost/user/device/vsock.rs
+++ b/devices/src/virtio/vhost/user/device/vsock.rs
@@ -27,8 +27,10 @@ use vmm_vhost::message::VhostSharedMemoryRegion;
 use vmm_vhost::message::VhostUserConfigFlags;
 use vmm_vhost::message::VhostUserInflight;
 use vmm_vhost::message::VhostUserMemoryRegion;
+use vmm_vhost::message::VhostUserMigrationPhase;
 use vmm_vhost::message::VhostUserProtocolFeatures;
 use vmm_vhost::message::VhostUserSingleMemoryRegion;
+use vmm_vhost::message::VhostUserTransferDirection;
 use vmm_vhost::message::VhostUserVringAddrFlags;
 use vmm_vhost::message::VhostUserVringState;
 use vmm_vhost::Error;
@@ -40,9 +42,9 @@ use crate::virtio::device_constants::vsock::NUM_QUEUES;
 use crate::virtio::vhost::user::device::handler::vmm_va_to_gpa;
 use crate::virtio::vhost::user::device::handler::MappingInfo;
 use crate::virtio::vhost::user::device::handler::VhostUserRegularOps;
+use crate::virtio::vhost::user::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::VhostUserDeviceBuilder;
 use crate::virtio::vhost::user::VhostUserListener;
-use crate::virtio::vhost::user::VhostUserListenerTrait;
 use crate::virtio::Queue;
 use crate::virtio::QueueConfig;
 
@@ -420,28 +422,21 @@ impl vmm_vhost::Backend for VsockBackend {
         Err(Error::InvalidOperation)
     }
 
-    fn get_shared_memory_regions(&mut self) -> Result<Vec<VhostSharedMemoryRegion>> {
-        Ok(vec![])
-    }
-
-    fn sleep(&mut self) -> Result<()> {
-        base::warn!("Sleep not implemented for vsock.");
-        Ok(())
-    }
-
-    fn wake(&mut self) -> Result<()> {
-        base::warn!("wake not implemented for vsock.");
-        Ok(())
+    fn set_device_state_fd(
+        &mut self,
+        _transfer_direction: VhostUserTransferDirection,
+        _migration_phase: VhostUserMigrationPhase,
+        _fd: File,
+    ) -> Result<Option<File>> {
+        Err(Error::InvalidOperation)
     }
 
-    fn snapshot(&mut self) -> Result<Vec<u8>> {
-        base::warn!("snapshot not implemented for vsock.");
-        Ok(Vec::new())
+    fn check_device_state(&mut self) -> Result<()> {
+        Err(Error::InvalidOperation)
     }
 
-    fn restore(&mut self, _data_bytes: &[u8], _queue_evts: Vec<File>) -> Result<()> {
-        base::warn!("restore not implemented for vsock.");
-        Ok(())
+    fn get_shared_memory_regions(&mut self) -> Result<Vec<VhostSharedMemoryRegion>> {
+        Ok(vec![])
     }
 }
 
@@ -468,7 +463,7 @@ pub struct Options {
 pub fn run_vsock_device(opts: Options) -> anyhow::Result<()> {
     let ex = Executor::new().context("failed to create executor")?;
 
-    let listener = VhostUserListener::new_socket(&opts.socket, None)?;
+    let listener = VhostUserListener::new(&opts.socket)?;
 
     let vsock_device = Box::new(VhostUserVsockDevice::new(opts.cid, opts.vhost_socket)?);
 
diff --git a/devices/src/virtio/vhost/user/device/wl.rs b/devices/src/virtio/vhost/user/device/wl.rs
index e5c34144a..2f5d6535f 100644
--- a/devices/src/virtio/vhost/user/device/wl.rs
+++ b/devices/src/virtio/vhost/user/device/wl.rs
@@ -11,7 +11,6 @@ use std::thread;
 use std::time::Duration;
 use std::time::Instant;
 
-use anyhow::anyhow;
 use anyhow::bail;
 use anyhow::Context;
 use argh::FromArgs;
@@ -39,21 +38,19 @@ use crate::virtio::device_constants::wl::NUM_QUEUES;
 use crate::virtio::device_constants::wl::VIRTIO_WL_F_SEND_FENCES;
 use crate::virtio::device_constants::wl::VIRTIO_WL_F_TRANS_FLAGS;
 use crate::virtio::device_constants::wl::VIRTIO_WL_F_USE_SHMEM;
+use crate::virtio::vhost::user::device::connection::sys::VhostUserListener;
+use crate::virtio::vhost::user::device::connection::VhostUserConnectionTrait;
 use crate::virtio::vhost::user::device::handler::Error as DeviceError;
 use crate::virtio::vhost::user::device::handler::VhostBackendReqConnection;
 use crate::virtio::vhost::user::device::handler::VhostBackendReqConnectionState;
 use crate::virtio::vhost::user::device::handler::VhostUserDevice;
 use crate::virtio::vhost::user::device::handler::WorkerState;
-use crate::virtio::vhost::user::device::listener::sys::VhostUserListener;
-use crate::virtio::vhost::user::device::listener::VhostUserListenerTrait;
 use crate::virtio::wl;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 use crate::virtio::SharedMemoryRegion;
 
 async fn run_out_queue(
     queue: Rc<RefCell<Queue>>,
-    doorbell: Interrupt,
     kick_evt: EventAsync,
     wlstate: Rc<RefCell<wl::WlState>>,
 ) {
@@ -63,17 +60,12 @@ async fn run_out_queue(
             break;
         }
 
-        wl::process_out_queue(
-            &doorbell,
-            &mut queue.borrow_mut(),
-            &mut wlstate.borrow_mut(),
-        );
+        wl::process_out_queue(&mut queue.borrow_mut(), &mut wlstate.borrow_mut());
     }
 }
 
 async fn run_in_queue(
     queue: Rc<RefCell<Queue>>,
-    doorbell: Interrupt,
     kick_evt: EventAsync,
     wlstate: Rc<RefCell<wl::WlState>>,
     wlstate_ctx: IoSource<AsyncWrapper<SafeDescriptor>>,
@@ -87,11 +79,8 @@ async fn run_in_queue(
             break;
         }
 
-        if wl::process_in_queue(
-            &doorbell,
-            &mut queue.borrow_mut(),
-            &mut wlstate.borrow_mut(),
-        ) == Err(wl::DescriptorsExhausted)
+        if wl::process_in_queue(&mut queue.borrow_mut(), &mut wlstate.borrow_mut())
+            == Err(wl::DescriptorsExhausted)
         {
             if let Err(e) = kick_evt.next_val().await {
                 error!("Failed to read kick event for in queue: {}", e);
@@ -152,11 +141,6 @@ impl VhostUserDevice for WlBackend {
     }
 
     fn ack_features(&mut self, value: u64) -> anyhow::Result<()> {
-        let unrequested_features = value & !self.features();
-        if unrequested_features != 0 {
-            bail!("invalid features are given: {:#x}", unrequested_features);
-        }
-
         self.acked_features |= value;
 
         if value & (1 << VIRTIO_WL_F_TRANS_FLAGS) != 0 {
@@ -172,43 +156,13 @@ impl VhostUserDevice for WlBackend {
         Ok(())
     }
 
-    fn acked_features(&self) -> u64 {
-        self.acked_features
-    }
-
     fn protocol_features(&self) -> VhostUserProtocolFeatures {
         VhostUserProtocolFeatures::BACKEND_REQ | VhostUserProtocolFeatures::SHARED_MEMORY_REGIONS
     }
 
-    fn ack_protocol_features(&mut self, features: u64) -> anyhow::Result<()> {
-        if features & self.protocol_features().bits() != self.protocol_features().bits() {
-            Err(anyhow!(
-                "Acked features {:#x} missing required protocol features",
-                features
-            ))
-        } else if features & !self.protocol_features().bits() != 0 {
-            Err(anyhow!(
-                "Acked features {:#x} contains unexpected features",
-                features
-            ))
-        } else {
-            Ok(())
-        }
-    }
-
-    fn acked_protocol_features(&self) -> u64 {
-        VhostUserProtocolFeatures::empty().bits()
-    }
-
     fn read_config(&self, _offset: u64, _dst: &mut [u8]) {}
 
-    fn start_queue(
-        &mut self,
-        idx: usize,
-        queue: Queue,
-        _mem: GuestMemory,
-        doorbell: Interrupt,
-    ) -> anyhow::Result<()> {
+    fn start_queue(&mut self, idx: usize, queue: Queue, _mem: GuestMemory) -> anyhow::Result<()> {
         if self.workers[idx].is_some() {
             warn!("Starting new queue handler without stopping old handler");
             self.stop_queue(idx)?;
@@ -278,17 +232,12 @@ impl VhostUserDevice for WlBackend {
                             .context("failed to create async WaitContext")
                     })?;
 
-                self.ex.spawn_local(run_in_queue(
-                    queue.clone(),
-                    doorbell,
-                    kick_evt,
-                    wlstate,
-                    wlstate_ctx,
-                ))
+                self.ex
+                    .spawn_local(run_in_queue(queue.clone(), kick_evt, wlstate, wlstate_ctx))
             }
             1 => self
                 .ex
-                .spawn_local(run_out_queue(queue.clone(), doorbell, kick_evt, wlstate)),
+                .spawn_local(run_out_queue(queue.clone(), kick_evt, wlstate)),
             _ => bail!("attempted to start unknown queue: {}", idx),
         };
         self.workers[idx] = Some(WorkerState { queue_task, queue });
@@ -331,6 +280,19 @@ impl VhostUserDevice for WlBackend {
 
         self.backend_req_conn = VhostBackendReqConnectionState::Connected(conn);
     }
+
+    fn enter_suspended_state(&mut self) -> anyhow::Result<()> {
+        // No non-queue workers.
+        Ok(())
+    }
+
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        bail!("snapshot not implemented for vhost-user wl");
+    }
+
+    fn restore(&mut self, _data: serde_json::Value) -> anyhow::Result<()> {
+        bail!("snapshot not implemented for vhost-user wl");
+    }
 }
 
 pub fn parse_wayland_sock(value: &str) -> Result<(String, PathBuf), String> {
@@ -403,7 +365,7 @@ pub fn run_wl_device(opts: Options) -> anyhow::Result<()> {
 
     let ex = Executor::new().context("failed to create executor")?;
 
-    let listener = VhostUserListener::new_socket(&socket, None)?;
+    let listener = VhostUserListener::new(&socket)?;
 
     let backend = WlBackend::new(&ex, wayland_paths, resource_bridge);
     // run_until() returns an Result<Result<..>> which the ? operator lets us flatten.
diff --git a/devices/src/virtio/vhost/user/snapshot_extensions.md b/devices/src/virtio/vhost/user/snapshot_extensions.md
index 2b20446eb..d06e8bfa2 100644
--- a/devices/src/virtio/vhost/user/snapshot_extensions.md
+++ b/devices/src/virtio/vhost/user/snapshot_extensions.md
@@ -9,80 +9,22 @@ we can send it upstream as a proposal.
 These extensions might be redundant with the VHOST_USER_PROTOCOL_F_DEVICE_STATE features recently
 added to the spec.
 
-## Protocol features
+## Suspended device state
 
-TODO: Include a protocol feature for backends to advertise snapshotting support.
+(proposed additions are **bold**)
 
-## Front-end message types
+While all vrings are stopped, the device is suspended. In addition to not processing any vring
+(because they are stopped), the device must:
 
-### VHOST_USER_SLEEP
+- not write to any guest memory regions,
+- not send any notifications to the guest,
+- not send any messages to the front-end,
+- **NEW: not interact with host resources. For example, a block device should not read or modify the
+  disk image file**
+- still process and reply to messages from the front-end.
 
-id: 1000 (temporary)
-
-equivalent ioctl: N/A
-
-request payload: N/A
-
-reply payload: i8
-
-Backend should stop all active queues. If the backend interacts with resources on the host, e.g. if
-it writes to a socket, it is expected that all activity with those resources stops before the
-VHOST_USER_SLEEP response is sent. This requirement allows other host side processes to snapshot
-their own state without the risk of race conditions. For example, if a virtio-blk flushed pending
-writes after VHOST_USER_SLEEP, then a disk image snapshot taken by the VMM could be missing data.
-
-The first byte of the response should be 1 to indicate success or 0 to indicate failure.
-
-### VHOST_USER_WAKE
-
-id: 1001 (temporary)
-
-equivalent ioctl: N/A
-
-request payload: N/A
-
-reply payload: i8
-
-Backend should start all active queues and may restart any interactions with host side resources.
-
-The first byte of the response should be 1 to indicate success or 0 to indicate failure.
-
-### VHOST_USER_SNAPSHOT
-
-id: 1002 (temporary)
-
-equivalent ioctl: N/A
-
-request payload: N/A
-
-reply payload: i8, followed by (payload size - 1) bytes of opaque snapshot data
-
-Backend should create a snapshot of all state needed to perform a restore.
-
-The first byte of the response should be 1 to indicate success or 0 to indicate failure. The rest of
-the response is the snapshot bytes, which are opaque from the perspective of the frontend.
-
-### VHOST_USER_RESTORE
-
-id: 1003 (temporary)
-
-equivalent ioctl: N/A
-
-request payload: (payload size) bytes of opaque snapshot data
-
-reply payload: i8
-
-Backend should restore itself to state of the snapshot provided in the request payload. The request
-will contain the exact same bytes returned from a previous VHOST_USER_SNAPSHOT request.
-
-The frontend must send the VHOST_USER_SET_MEM_TABLE request before VHOST_USER_RESTORE so that the
-backend has enough information to perform the vring restore.
-
-The event file descriptors for adding buffers to the vrings (normally passed via
-VHOST_USER_SET_VRING_KICK) are included in the ancillary data. The index of the file descriptor in
-the ancillary data is the index of the queue it belongs to.
-
-The one byte response should be 1 to indicate success or 0 to indicate failure.
+**NEW: The frontend can assume those requirements are obeyed both (1) before the first queue is
+started and (2) as soon as it receives a response for the message that stopped the last queue.**
 
 ## Snapshot-Restore
 
@@ -95,25 +37,34 @@ Snapshot sequence:
 1. Frontend connects to vhost-user devices.
 1. ... proceed as usual ...
 1. For each vhost-user device
-   - Frontend sends VHOST_USER_SLEEP request.
+   - Frontend stops all the queues using VHOST_USER_GET_VRING_BASE and saves the vring bases
+     somewhere.
+   - Backend enters the "suspended device state" when the last queue is stopped.
 1. For each vhost-user device
-   - Frontend sends VHOST_USER_SNAPSHOT request and saves the response payload somewhere.
+   - Frontend sends VHOST_USER_SET_DEVICE_STATE_FD and VHOST_USER_CHECK_DEVICE_STATE requests with
+     transfer direction "save" to save the device state somewhere.
 1. For each vhost-user device
-   - Frontend sends VHOST_USER_WAKE request.
+   - Frontend sends VHOST_USER_SET_MEM_TABLE request.
+   - Frontend starts all the queues as if from scratch, using the saved vring base in the
+     VHOST_USER_SET_VRING_BASE request.
+   - Backend exits the "suspended device state" (as early as) when the first queue is started.
 1. ... proceed as usual ...
 
 Restore sequence:
 
 1. Frontend connects to vhost-user devices.
 1. For each vhost-user device
-   - Frontend sends VHOST_USER_SLEEP request.
+   - Frontend stops all the queues using VHOST_USER_GET_VRING_BASE and saves the vring bases
+     somewhere.
+   - Backend enters the "suspended device state" when the last queue is stopped.
 1. For each vhost-user device
-   - Frontend sends VHOST_USER_SET_MEM_TABLE request.
-   - For every queue that was active at the time of snapshotting, frontend sends a
-     VHOST_USER_SET_VRING_CALL request for that queue.
-   - Frontend sends VHOST_USER_RESTORE request.
+   - Frontend sends VHOST_USER_SET_DEVICE_STATE_FD and VHOST_USER_CHECK_DEVICE_STATE requests with
+     transfer direction "load" restore the device state.
 1. For each vhost-user device
-   - Frontend sends VHOST_USER_WAKE request.
+   - Frontend sends VHOST_USER_SET_MEM_TABLE request.
+   - Frontend starts all the queues as if from scratch, using the saved vring base in the
+     VHOST_USER_SET_VRING_BASE request.
+   - Backend exits the "suspended device state" (as early as) when the first queue is started.
 1. ... proceed as usual ...
 
 ### Backend
diff --git a/devices/src/virtio/vhost/vsock.rs b/devices/src/virtio/vhost/vsock.rs
index 405a17b54..162bdde98 100644
--- a/devices/src/virtio/vhost/vsock.rs
+++ b/devices/src/virtio/vhost/vsock.rs
@@ -213,7 +213,7 @@ impl VirtioDevice for Vsock {
                 .expect("failed to write transport reset event");
             let len = avail_desc.writer.bytes_written() as u32;
             event_queue.add_used(avail_desc, len);
-            event_queue.trigger_interrupt(&interrupt);
+            event_queue.trigger_interrupt();
         }
         self.event_queue = Some(event_queue);
 
@@ -246,6 +246,31 @@ impl VirtioDevice for Vsock {
         Ok(())
     }
 
+    fn reset(&mut self) -> anyhow::Result<()> {
+        if let Some(worker_thread) = self.worker_thread.take() {
+            let worker = worker_thread.stop();
+            worker
+                .vhost_handle
+                .stop()
+                .context("failed to stop vrings")?;
+            // Call get_vring_base to stop the queues.
+            for (pos, _) in worker.queues.iter() {
+                worker
+                    .vhost_handle
+                    .get_vring_base(*pos)
+                    .context("get_vring_base failed")?;
+            }
+
+            self.vhost_handle = Some(worker.vhost_handle);
+            self.interrupts = Some(worker.vhost_interrupt);
+        }
+        self.acked_features = 0;
+        self.vrings_base = None;
+        self.event_queue = None;
+        self.needs_transport_reset = false;
+        Ok(())
+    }
+
     fn on_device_sandboxed(&mut self) {
         // ignore the error but to log the error. We don't need to do
         // anything here because when activate, the other vhost set up
diff --git a/devices/src/virtio/vhost_user_frontend/error.rs b/devices/src/virtio/vhost_user_frontend/error.rs
index 1b2f5e9fc..0d376cba8 100644
--- a/devices/src/virtio/vhost_user_frontend/error.rs
+++ b/devices/src/virtio/vhost_user_frontend/error.rs
@@ -115,6 +115,9 @@ pub enum Error {
     /// Too many shmem regions.
     #[error("too many shmem regions: {0} > 1")]
     TooManyShmemRegions(usize),
+    /// vring base from vhost-user backend is too big.
+    #[error("vring base returned by vhost-user backend is too big: {0}")]
+    VringBaseTooBig(u32),
     /// failed to wake the vhost user device.
     #[error("failed to wake the vhost user device.")]
     Wake(VhostError),
diff --git a/devices/src/virtio/vhost_user_frontend/fs.rs b/devices/src/virtio/vhost_user_frontend/fs.rs
index e4ba05f14..125e91f41 100644
--- a/devices/src/virtio/vhost_user_frontend/fs.rs
+++ b/devices/src/virtio/vhost_user_frontend/fs.rs
@@ -15,7 +15,7 @@ use crate::virtio::DeviceType;
 impl VhostUserFrontend {
     pub fn new_fs(
         base_features: u64,
-        connection: vmm_vhost::SystemStream,
+        connection: vmm_vhost::Connection<vmm_vhost::FrontendReq>,
         max_queue_size: Option<u16>,
         tag: Option<&str>,
     ) -> Result<VhostUserFrontend> {
diff --git a/devices/src/virtio/vhost_user_frontend/mod.rs b/devices/src/virtio/vhost_user_frontend/mod.rs
index 37f7dd58a..cdcce1b44 100644
--- a/devices/src/virtio/vhost_user_frontend/mod.rs
+++ b/devices/src/virtio/vhost_user_frontend/mod.rs
@@ -12,8 +12,10 @@ mod worker;
 
 use std::cell::RefCell;
 use std::collections::BTreeMap;
-use std::sync::Arc;
+use std::io::Read;
+use std::io::Write;
 
+use anyhow::bail;
 use anyhow::Context;
 use base::error;
 use base::trace;
@@ -22,16 +24,16 @@ use base::Event;
 use base::RawDescriptor;
 use base::WorkerThread;
 use serde_json::Value;
-use sync::Mutex;
 use vm_memory::GuestMemory;
 use vmm_vhost::message::VhostUserConfigFlags;
+use vmm_vhost::message::VhostUserMigrationPhase;
 use vmm_vhost::message::VhostUserProtocolFeatures;
+use vmm_vhost::message::VhostUserTransferDirection;
 use vmm_vhost::BackendClient;
 use vmm_vhost::VhostUserMemoryRegionInfo;
 use vmm_vhost::VringConfigData;
 use vmm_vhost::VHOST_USER_F_PROTOCOL_FEATURES;
 
-use crate::pci::MsixConfig;
 use crate::virtio::copy_config;
 use crate::virtio::device_constants::VIRTIO_DEVICE_TYPE_SPECIFIC_FEATURES_MASK;
 use crate::virtio::vhost_user_frontend::error::Error;
@@ -43,7 +45,6 @@ use crate::virtio::vhost_user_frontend::worker::Worker;
 use crate::virtio::DeviceType;
 use crate::virtio::Interrupt;
 use crate::virtio::Queue;
-use crate::virtio::QueueConfig;
 use crate::virtio::SharedMemoryMapper;
 use crate::virtio::SharedMemoryRegion;
 use crate::virtio::VirtioDevice;
@@ -68,6 +69,11 @@ pub struct VhostUserFrontend {
     cfg: Option<Vec<u8>>,
     expose_shmem_descriptors_with_viommu: bool,
     pci_address: Option<PciAddress>,
+
+    // Queues that have been sent to the backend. Always `Some` when active and not asleep. Saved
+    // for use in `virtio_sleep`. Since the backend is managing them, the local state of the queue
+    // is likely stale.
+    sent_queues: Option<BTreeMap<usize, Queue>>,
 }
 
 // Returns the largest power of two that is less than or equal to `val`.
@@ -94,7 +100,7 @@ impl VhostUserFrontend {
     pub fn new(
         device_type: DeviceType,
         base_features: u64,
-        connection: vmm_vhost::SystemStream,
+        connection: vmm_vhost::Connection<vmm_vhost::FrontendReq>,
         max_queue_size: Option<u16>,
         pci_address: Option<PciAddress>,
     ) -> Result<VhostUserFrontend> {
@@ -119,7 +125,7 @@ impl VhostUserFrontend {
     /// - `cfg`: bytes to return for the virtio configuration space (queried from device if not
     ///   specified)
     pub(crate) fn new_internal(
-        connection: vmm_vhost::SystemStream,
+        connection: vmm_vhost::Connection<vmm_vhost::FrontendReq>,
         device_type: DeviceType,
         max_queue_size: Option<u16>,
         mut base_features: u64,
@@ -140,7 +146,7 @@ impl VhostUserFrontend {
         #[cfg(windows)]
         let backend_pid = connection.target_pid();
 
-        let mut backend_client = BackendClient::from_stream(connection);
+        let mut backend_client = BackendClient::new(connection);
 
         backend_client.set_owner().map_err(Error::SetOwner)?;
 
@@ -153,7 +159,8 @@ impl VhostUserFrontend {
 
         let mut allow_protocol_features = VhostUserProtocolFeatures::CONFIG
             | VhostUserProtocolFeatures::MQ
-            | VhostUserProtocolFeatures::BACKEND_REQ;
+            | VhostUserProtocolFeatures::BACKEND_REQ
+            | VhostUserProtocolFeatures::DEVICE_STATE;
 
         // HACK: the crosvm vhost-user GPU backend supports the non-standard
         // VHOST_USER_PROTOCOL_FEATURE_SHARED_MEMORY_REGIONS. This should either be standardized
@@ -241,6 +248,7 @@ impl VhostUserFrontend {
             cfg: cfg.map(|cfg| cfg.to_vec()),
             expose_shmem_descriptors_with_viommu,
             pci_address,
+            sent_queues: None,
         })
     }
 
@@ -294,7 +302,7 @@ impl VhostUserFrontend {
             .map_err(Error::SetVringAddr)?;
 
         self.backend_client
-            .set_vring_base(queue_index, 0)
+            .set_vring_base(queue_index, queue.next_avail_to_process())
             .map_err(Error::SetVringBase)?;
 
         self.backend_client
@@ -315,6 +323,24 @@ impl VhostUserFrontend {
         Ok(())
     }
 
+    /// Stops the vring for the given `queue`, returning its base index.
+    fn deactivate_vring(&self, queue_index: usize) -> Result<u16> {
+        if self.acked_features & 1 << VHOST_USER_F_PROTOCOL_FEATURES != 0 {
+            self.backend_client
+                .set_vring_enable(queue_index, false)
+                .map_err(Error::SetVringEnable)?;
+        }
+
+        let vring_base = self
+            .backend_client
+            .get_vring_base(queue_index)
+            .map_err(Error::GetVringBase)?;
+
+        vring_base
+            .try_into()
+            .map_err(|_| Error::VringBaseTooBig(vring_base))
+    }
+
     /// Helper to start up the worker thread that will be used with handling interrupts and requests
     /// from the device process.
     fn start_worker(&mut self, interrupt: Interrupt, non_msix_evt: Event) {
@@ -351,6 +377,11 @@ impl VhostUserFrontend {
 }
 
 impl VirtioDevice for VhostUserFrontend {
+    // Override the default debug label to differentiate vhost-user devices from virtio.
+    fn debug_label(&self) -> String {
+        format!("vu-{}", self.device_type())
+    }
+
     fn keep_rds(&self) -> Vec<RawDescriptor> {
         Vec::new()
     }
@@ -448,6 +479,8 @@ impl VirtioDevice for VhostUserFrontend {
             self.activate_vring(&mem, queue_index, queue, irqfd)?;
         }
 
+        self.sent_queues = Some(queues);
+
         drop(msix_config);
 
         self.start_worker(interrupt, non_msix_evt);
@@ -455,16 +488,12 @@ impl VirtioDevice for VhostUserFrontend {
     }
 
     fn reset(&mut self) -> anyhow::Result<()> {
-        for queue_index in 0..self.queue_sizes.len() {
-            if self.acked_features & 1 << VHOST_USER_F_PROTOCOL_FEATURES != 0 {
-                self.backend_client
-                    .set_vring_enable(queue_index, false)
-                    .context("set_vring_enable failed during reset")?;
+        if let Some(sent_queues) = self.sent_queues.take() {
+            for queue_index in sent_queues.into_keys() {
+                let _vring_base = self
+                    .deactivate_vring(queue_index)
+                    .context("deactivate_vring failed during reset")?;
             }
-            let _vring_base = self
-                .backend_client
-                .get_vring_base(queue_index)
-                .context("get_vring_base failed during reset")?;
         }
 
         if let Some(w) = self.worker_thread.take() {
@@ -548,84 +577,125 @@ impl VirtioDevice for VhostUserFrontend {
     }
 
     fn virtio_sleep(&mut self) -> anyhow::Result<Option<BTreeMap<usize, Queue>>> {
-        self.backend_client.sleep().map_err(Error::Sleep)?;
+        let Some(mut queues) = self.sent_queues.take() else {
+            return Ok(None);
+        };
+
+        for (&queue_index, queue) in queues.iter_mut() {
+            let vring_base = self
+                .deactivate_vring(queue_index)
+                .context("deactivate_vring failed during sleep")?;
+            queue.vhost_user_reclaim(vring_base);
+        }
+
+        if let Some(w) = self.worker_thread.take() {
+            self.backend_req_handler = w.stop();
+        }
 
-        // Vhost user devices won't return queues on sleep, so return an empty Vec so that
-        // VirtioPciDevice can set the sleep state properly.
-        Ok(Some(BTreeMap::new()))
+        Ok(Some(queues))
     }
 
     fn virtio_wake(
         &mut self,
         // Vhost user doesn't need to pass queue_states back to the device process, since it will
         // already have it.
-        _queues_state: Option<(GuestMemory, Interrupt, BTreeMap<usize, Queue>)>,
+        queues_state: Option<(GuestMemory, Interrupt, BTreeMap<usize, Queue>)>,
     ) -> anyhow::Result<()> {
-        self.backend_client.wake().map_err(Error::Wake)?;
+        if let Some((mem, interrupt, queues)) = queues_state {
+            self.activate(mem, interrupt, queues)?;
+        }
         Ok(())
     }
 
     fn virtio_snapshot(&mut self) -> anyhow::Result<Value> {
-        let snapshot_bytes = self.backend_client.snapshot().map_err(Error::Snapshot)?;
+        if !self
+            .protocol_features
+            .contains(VhostUserProtocolFeatures::DEVICE_STATE)
+        {
+            bail!("snapshot requires VHOST_USER_PROTOCOL_F_DEVICE_STATE");
+        }
+        // Send the backend an FD to write the device state to. If it gives us an FD back, then
+        // we need to read from that instead.
+        let (mut r, w) = new_pipe_pair()?;
+        let backend_r = self
+            .backend_client
+            .set_device_state_fd(
+                VhostUserTransferDirection::Save,
+                VhostUserMigrationPhase::Stopped,
+                &w,
+            )
+            .context("failed to negotiate device state fd")?;
+        // EOF signals end of the device state bytes, so it is important to close our copy of
+        // the write FD before we start reading.
+        std::mem::drop(w);
+        // Read the device state.
+        let mut snapshot_bytes = Vec::new();
+        if let Some(mut backend_r) = backend_r {
+            backend_r.read_to_end(&mut snapshot_bytes)
+        } else {
+            r.read_to_end(&mut snapshot_bytes)
+        }
+        .context("failed to read device state")?;
+        // Call `check_device_state` to ensure the data transfer was successful.
+        self.backend_client
+            .check_device_state()
+            .context("failed to transfer device state")?;
         Ok(serde_json::to_value(snapshot_bytes).map_err(Error::SliceToSerdeValue)?)
     }
 
-    fn virtio_restore(&mut self, _data: Value) -> anyhow::Result<()> {
-        panic!("virtio_restore should not be called for vhost-user devices.")
-    }
-
-    fn is_vhost_user(&self) -> bool {
-        true
-    }
-
-    fn vhost_user_restore(
-        &mut self,
-        data: Value,
-        queue_configs: &[QueueConfig],
-        queue_evts: Option<Vec<Event>>,
-        interrupt: Option<Interrupt>,
-        mem: GuestMemory,
-        msix_config: &Arc<Mutex<MsixConfig>>,
-        device_activated: bool,
-    ) -> anyhow::Result<()> {
-        // Other aspects of the restore operation will depend on the mem table
-        // being set.
-        self.set_mem_table(&mem)?;
-
-        if device_activated {
-            let non_msix_evt = Event::new().context("Failed to create event")?;
-            queue_configs
-                .iter()
-                .enumerate()
-                .filter(|(_, q)| q.ready())
-                .try_for_each(|(queue_index, queue)| {
-                    let msix_lock = msix_config.lock();
-                    let irqfd = msix_lock
-                        .get_irqfd(queue.vector() as usize)
-                        .unwrap_or(&non_msix_evt);
-
-                    self.backend_client
-                        .set_vring_call(queue_index, irqfd)
-                        .map_err(Error::SetVringCall)
-                        .context("Failed to restore irqfd")?;
-
-                    Ok::<(), anyhow::Error>(())
-                })?;
-
-            self.start_worker(
-                interrupt.expect(
-                    "Interrupt doesn't exist. This shouldn't \
-                        happen since the device is activated.",
-                ),
-                non_msix_evt,
-            );
+    fn virtio_restore(&mut self, data: Value) -> anyhow::Result<()> {
+        if !self
+            .protocol_features
+            .contains(VhostUserProtocolFeatures::DEVICE_STATE)
+        {
+            bail!("restore requires VHOST_USER_PROTOCOL_F_DEVICE_STATE");
         }
 
         let data_bytes: Vec<u8> = serde_json::from_value(data).map_err(Error::SerdeValueToSlice)?;
+        // Send the backend an FD to read the device state from. If it gives us an FD back,
+        // then we need to write to that instead.
+        let (r, w) = new_pipe_pair()?;
+        let backend_w = self
+            .backend_client
+            .set_device_state_fd(
+                VhostUserTransferDirection::Load,
+                VhostUserMigrationPhase::Stopped,
+                &r,
+            )
+            .context("failed to negotiate device state fd")?;
+        // Write the device state.
+        {
+            // EOF signals the end of the device state bytes, so we need to ensure the write
+            // objects are dropped before the `check_device_state` call. Done here by moving
+            // them into this scope.
+            let backend_w = backend_w;
+            let mut w = w;
+            if let Some(mut backend_w) = backend_w {
+                backend_w.write_all(data_bytes.as_slice())
+            } else {
+                w.write_all(data_bytes.as_slice())
+            }
+            .context("failed to write device state")?;
+        }
+        // Call `check_device_state` to ensure the data transfer was successful.
         self.backend_client
-            .restore(data_bytes.as_slice(), queue_evts)
-            .map_err(Error::Restore)?;
-
+            .check_device_state()
+            .context("failed to transfer device state")?;
         Ok(())
     }
 }
+
+#[cfg(unix)]
+fn new_pipe_pair() -> anyhow::Result<(impl AsRawDescriptor + Read, impl AsRawDescriptor + Write)> {
+    base::pipe().context("failed to create pipe")
+}
+
+#[cfg(windows)]
+fn new_pipe_pair() -> anyhow::Result<(impl AsRawDescriptor + Read, impl AsRawDescriptor + Write)> {
+    base::named_pipes::pair(
+        &base::named_pipes::FramingMode::Byte,
+        &base::named_pipes::BlockingMode::Wait,
+        /* timeout= */ 0,
+    )
+    .context("failed to create named pipes")
+}
diff --git a/devices/src/virtio/video/decoder/backend/ffmpeg.rs b/devices/src/virtio/video/decoder/backend/ffmpeg.rs
index 22ceb3a40..fafb832ad 100644
--- a/devices/src/virtio/video/decoder/backend/ffmpeg.rs
+++ b/devices/src/virtio/video/decoder/backend/ffmpeg.rs
@@ -561,7 +561,7 @@ impl DecoderSession for FfmpegDecoderSession {
             .context("while importing output buffer")
             .map_err(VideoError::BackendFailure)?;
         self.try_decode()
-            .context("while importing output buffer")
+            .context("while decoding output buffer")
             .map_err(VideoError::BackendFailure)
     }
 
diff --git a/devices/src/virtio/video/decoder/backend/mod.rs b/devices/src/virtio/video/decoder/backend/mod.rs
index cf8236e7d..96aa9fda5 100644
--- a/devices/src/virtio/video/decoder/backend/mod.rs
+++ b/devices/src/virtio/video/decoder/backend/mod.rs
@@ -104,7 +104,57 @@ pub trait DecoderSession {
     fn read_event(&mut self) -> VideoResult<DecoderEvent>;
 }
 
-pub trait DecoderBackend {
+impl<S: AsMut<dyn DecoderSession> + AsRef<dyn DecoderSession> + ?Sized> DecoderSession for S {
+    fn set_output_parameters(&mut self, buffer_count: usize, format: Format) -> VideoResult<()> {
+        self.as_mut().set_output_parameters(buffer_count, format)
+    }
+
+    fn decode(
+        &mut self,
+        resource_id: u32,
+        timestamp: u64,
+        resource: GuestResourceHandle,
+        offset: u32,
+        bytes_used: u32,
+    ) -> VideoResult<()> {
+        self.as_mut()
+            .decode(resource_id, timestamp, resource, offset, bytes_used)
+    }
+
+    fn flush(&mut self) -> VideoResult<()> {
+        self.as_mut().flush()
+    }
+
+    fn reset(&mut self) -> VideoResult<()> {
+        self.as_mut().reset()
+    }
+
+    fn clear_output_buffers(&mut self) -> VideoResult<()> {
+        self.as_mut().clear_output_buffers()
+    }
+
+    fn event_pipe(&self) -> &dyn AsRawDescriptor {
+        self.as_ref().event_pipe()
+    }
+
+    fn use_output_buffer(
+        &mut self,
+        picture_buffer_id: i32,
+        resource: GuestResource,
+    ) -> VideoResult<()> {
+        self.as_mut().use_output_buffer(picture_buffer_id, resource)
+    }
+
+    fn reuse_output_buffer(&mut self, picture_buffer_id: i32) -> VideoResult<()> {
+        self.as_mut().reuse_output_buffer(picture_buffer_id)
+    }
+
+    fn read_event(&mut self) -> VideoResult<DecoderEvent> {
+        self.as_mut().read_event()
+    }
+}
+
+pub trait DecoderBackend: Send {
     type Session: DecoderSession;
 
     /// Return the decoding capabilities for this backend instance.
@@ -112,6 +162,53 @@ pub trait DecoderBackend {
 
     /// Create a new decoding session for the passed `format`.
     fn new_session(&mut self, format: Format) -> VideoResult<Self::Session>;
+
+    /// Turn this backend into a trait object, allowing the same decoder to operate on a set of
+    /// different backends.
+    fn into_trait_object(self) -> Box<dyn DecoderBackend<Session = Box<dyn DecoderSession>>>
+    where
+        Self: Sized + 'static,
+    {
+        Box::new(GenericDecoderBackend(self)) as Box<dyn DecoderBackend<Session = _>>
+    }
+}
+
+/// Type that changes the `Session` associated type to `Box<dyn DecoderSession>`, allowing us to
+/// use trait objects for backends.
+struct GenericDecoderBackend<S: DecoderBackend>(pub S);
+
+impl<S> DecoderBackend for GenericDecoderBackend<S>
+where
+    S: DecoderBackend,
+    <S as DecoderBackend>::Session: 'static,
+{
+    type Session = Box<dyn DecoderSession>;
+
+    fn get_capabilities(&self) -> Capability {
+        self.0.get_capabilities()
+    }
+
+    fn new_session(&mut self, format: Format) -> VideoResult<Self::Session> {
+        self.0
+            .new_session(format)
+            .map(|s| Box::new(s) as Box<dyn DecoderSession>)
+    }
+}
+
+impl<S> DecoderBackend for Box<S>
+where
+    S: ?Sized,
+    S: DecoderBackend,
+{
+    type Session = S::Session;
+
+    fn get_capabilities(&self) -> Capability {
+        self.as_ref().get_capabilities()
+    }
+
+    fn new_session(&mut self, format: Format) -> VideoResult<Self::Session> {
+        self.as_mut().new_session(format)
+    }
 }
 
 #[derive(Debug)]
diff --git a/devices/src/virtio/video/decoder/backend/vaapi.rs b/devices/src/virtio/video/decoder/backend/vaapi.rs
index 452e0b8c6..17a296001 100644
--- a/devices/src/virtio/video/decoder/backend/vaapi.rs
+++ b/devices/src/virtio/video/decoder/backend/vaapi.rs
@@ -244,7 +244,7 @@ impl VaapiDecoder {
                 libva::VASurfaceAttribType::VASurfaceAttribMinWidth,
             )?;
 
-            let min_width = match min_width.get(0) {
+            let min_width = match min_width.first() {
                 Some(libva::GenericValue::Integer(i)) => *i as u32,
                 Some(other) => panic!("Unexpected VAGenericValue {:?}", other),
                 None => 1,
@@ -253,7 +253,7 @@ impl VaapiDecoder {
             let min_height = config.query_surface_attributes_by_type(
                 libva::VASurfaceAttribType::VASurfaceAttribMinHeight,
             )?;
-            let min_height = match min_height.get(0) {
+            let min_height = match min_height.first() {
                 Some(libva::GenericValue::Integer(i)) => *i as u32,
                 Some(other) => panic!("Unexpected VAGenericValue {:?}", other),
                 None => 1,
@@ -262,7 +262,7 @@ impl VaapiDecoder {
             let max_width = config.query_surface_attributes_by_type(
                 libva::VASurfaceAttribType::VASurfaceAttribMaxWidth,
             )?;
-            let max_width = match max_width.get(0) {
+            let max_width = match max_width.first() {
                 Some(libva::GenericValue::Integer(i)) => *i as u32,
                 Some(other) => panic!("Unexpected VAGenericValue {:?}", other),
                 None => coded_cap.max_width,
@@ -271,7 +271,7 @@ impl VaapiDecoder {
             let max_height = config.query_surface_attributes_by_type(
                 libva::VASurfaceAttribType::VASurfaceAttribMaxHeight,
             )?;
-            let max_height = match max_height.get(0) {
+            let max_height = match max_height.first() {
                 Some(libva::GenericValue::Integer(i)) => *i as u32,
                 Some(other) => panic!("Unexpected VAGenericValue {:?}", other),
                 None => coded_cap.max_height,
@@ -491,6 +491,7 @@ impl<'a, T: AsBufferHandle> AsMut<[u8]> for BufferMapping<'a, T> {
 /// decoded and is waiting for us to release it (`Decoded`), or because we temporarily removed it
 /// from the decoder pool after a reset and are waiting for the client to tell us we can use it
 /// (`Held`).
+#[allow(dead_code)] // TODO: b/344974550
 enum BorrowedFrame {
     Decoded(Box<dyn DecodedHandle<Descriptor = BufferDescWithPicId>>),
     Held(Box<dyn AsRef<BufferDescWithPicId>>),
diff --git a/devices/src/virtio/video/decoder/backend/vda.rs b/devices/src/virtio/video/decoder/backend/vda.rs
index 22cdc7bcf..e3d516bae 100644
--- a/devices/src/virtio/video/decoder/backend/vda.rs
+++ b/devices/src/virtio/video/decoder/backend/vda.rs
@@ -286,6 +286,9 @@ impl DecoderSession for VdaDecoderSession {
 /// A VDA decoder backend that can be passed to `Decoder::new` in order to create a working decoder.
 pub struct LibvdaDecoder(libvda::decode::VdaInstance);
 
+/// SAFETY: safe because the Rcs in `VdaInstance` are always used from the same thread.
+unsafe impl Send for LibvdaDecoder {}
+
 impl LibvdaDecoder {
     /// Create a decoder backend instance that can be used to instantiate an decoder.
     pub fn new(backend_type: libvda::decode::VdaImplType) -> VideoResult<Self> {
@@ -314,7 +317,7 @@ impl DecoderBackend for LibvdaDecoder {
 
         // Raise the first |# of supported raw formats|-th bits because we can assume that any
         // combination of (a coded format, a raw format) is valid in Chrome.
-        let mask = !(u64::max_value() << caps.output_formats.len());
+        let mask = !(u64::MAX << caps.output_formats.len());
 
         let mut in_fmts = vec![];
         let mut profiles: BTreeMap<Format, Vec<Profile>> = Default::default();
@@ -386,7 +389,7 @@ impl DecoderBackend for LibvdaDecoder {
 
         // Raise the first |# of supported coded formats|-th bits because we can assume that any
         // combination of (a coded format, a raw format) is valid in Chrome.
-        let mask = !(u64::max_value() << caps.input_formats.len());
+        let mask = !(u64::MAX << caps.input_formats.len());
         let out_fmts = caps
             .output_formats
             .iter()
diff --git a/devices/src/virtio/video/decoder/mod.rs b/devices/src/virtio/video/decoder/mod.rs
index d1a0e7597..e72462c6e 100644
--- a/devices/src/virtio/video/decoder/mod.rs
+++ b/devices/src/virtio/video/decoder/mod.rs
@@ -554,7 +554,7 @@ impl<D: DecoderBackend> Decoder<D> {
             return Err(VideoError::InvalidArgument);
         } else {
             // unwrap() is safe because we just tested that `plane_entries` had exactly one element.
-            plane_entries.get(0).unwrap()
+            plane_entries.first().unwrap()
         };
 
         // Now try to resolve our resource.
@@ -574,7 +574,7 @@ impl<D: DecoderBackend> Decoder<D> {
                     // Safe because we confirmed the correct type for the resource.
                     // unwrap() is also safe here because we just tested above that `entries` had
                     // exactly one element.
-                    unsafe { entries.get(0).unwrap().object },
+                    unsafe { entries.first().unwrap().object },
                     &self.resource_bridge,
                     params,
                 )
diff --git a/devices/src/virtio/video/encoder/mod.rs b/devices/src/virtio/video/encoder/mod.rs
index bbee51155..be5478dc7 100644
--- a/devices/src/virtio/video/encoder/mod.rs
+++ b/devices/src/virtio/video/encoder/mod.rs
@@ -646,7 +646,7 @@ impl<T: Encoder> EncoderDevice<T> {
             return Err(VideoError::InvalidArgument);
         } else {
             // unwrap() is safe because we just tested that `plane_entries` had exactly one element.
-            plane_entries.get(0).unwrap()
+            plane_entries.first().unwrap()
         };
 
         match queue_type {
@@ -673,7 +673,7 @@ impl<T: Encoder> EncoderDevice<T> {
                             // Safe because we confirmed the correct type for the resource.
                             // unwrap() is also safe here because we just tested above that
                             // `entries` had exactly one element.
-                            unsafe { entries.get(0).unwrap().object },
+                            unsafe { entries.first().unwrap().object },
                             &self.resource_bridge,
                             &stream.src_params,
                         )
@@ -723,7 +723,7 @@ impl<T: Encoder> EncoderDevice<T> {
                             // Safe because we confirmed the correct type for the resource.
                             // unwrap() is also safe here because we just tested above that
                             // `entries` had exactly one element.
-                            unsafe { entries.get(0).unwrap().object },
+                            unsafe { entries.first().unwrap().object },
                             &self.resource_bridge,
                             &stream.dst_params,
                         )
@@ -1087,7 +1087,7 @@ impl<T: Encoder> EncoderDevice<T> {
                         desired_format,
                         frame_width,
                         frame_height,
-                        plane_formats.get(0).map(|fmt| fmt.stride).unwrap_or(0),
+                        plane_formats.first().map(|fmt| fmt.stride).unwrap_or(0),
                     )?;
 
                     stream.dst_params.frame_width = frame_width;
@@ -1672,7 +1672,7 @@ impl EncoderCapabilities {
             .find(|&format_desc| format_desc.format == desired_format)
             .unwrap_or(
                 self.input_format_descs
-                    .get(0)
+                    .first()
                     .ok_or(VideoError::InvalidFormat)?,
             );
 
@@ -1707,7 +1707,7 @@ impl EncoderCapabilities {
             .find(move |&format_desc| format_desc.format == desired_format)
             .unwrap_or(
                 self.output_format_descs
-                    .get(0)
+                    .first()
                     .ok_or(VideoError::InvalidFormat)?,
             );
         dst_params.format = Some(format_desc.format);
@@ -1727,7 +1727,7 @@ impl EncoderCapabilities {
 
     pub fn get_default_profile(&self, coded_format: &Format) -> Option<Profile> {
         let profiles = self.get_profiles(coded_format)?;
-        match profiles.get(0) {
+        match profiles.first() {
             None => {
                 error!("Format {} exists but no available profiles.", coded_format);
                 None
diff --git a/devices/src/virtio/video/mod.rs b/devices/src/virtio/video/mod.rs
index c8be3e2d9..3dc3e0137 100644
--- a/devices/src/virtio/video/mod.rs
+++ b/devices/src/virtio/video/mod.rs
@@ -214,7 +214,7 @@ impl VirtioDevice for VideoDevice {
     fn activate(
         &mut self,
         mem: GuestMemory,
-        interrupt: Interrupt,
+        _interrupt: Interrupt,
         mut queues: BTreeMap<usize, Queue>,
     ) -> anyhow::Result<()> {
         if queues.len() != QUEUE_SIZES.len() {
@@ -237,7 +237,7 @@ impl VirtioDevice for VideoDevice {
             .resource_bridge
             .take()
             .context("no resource bridge is passed")?;
-        let mut worker = Worker::new(cmd_queue, interrupt.clone(), event_queue, interrupt);
+        let mut worker = Worker::new(cmd_queue, event_queue);
 
         let worker_result = match &self.device_type {
             #[cfg(feature = "video-decoder")]
@@ -329,45 +329,51 @@ pub fn create_decoder_device(
     resource_bridge: Tube,
     mem: GuestMemory,
 ) -> Result<Box<dyn Device>> {
-    Ok(match backend {
+    use decoder::backend::DecoderBackend;
+
+    let backend = match backend {
         #[cfg(feature = "libvda")]
         VideoBackendType::Libvda => {
-            let vda = decoder::backend::vda::LibvdaDecoder::new(libvda::decode::VdaImplType::Gavda)
+            decoder::backend::vda::LibvdaDecoder::new(libvda::decode::VdaImplType::Gavda)
                 .map_err(|e| {
                     Error::DeviceCreationFailed(format!(
                         "Failed to initialize VDA for decoder: {}",
                         e
                     ))
-                })?;
-            Box::new(decoder::Decoder::new(vda, resource_bridge, mem))
+                })?
+                .into_trait_object()
         }
         #[cfg(feature = "libvda")]
         VideoBackendType::LibvdaVd => {
-            let vda = decoder::backend::vda::LibvdaDecoder::new(libvda::decode::VdaImplType::Gavd)
+            decoder::backend::vda::LibvdaDecoder::new(libvda::decode::VdaImplType::Gavd)
                 .map_err(|e| {
                     Error::DeviceCreationFailed(format!(
                         "Failed to initialize VD for decoder: {}",
                         e
                     ))
-                })?;
-            Box::new(decoder::Decoder::new(vda, resource_bridge, mem))
+                })?
+                .into_trait_object()
         }
         #[cfg(feature = "ffmpeg")]
         VideoBackendType::Ffmpeg => {
-            let ffmpeg = decoder::backend::ffmpeg::FfmpegDecoder::new();
-            Box::new(decoder::Decoder::new(ffmpeg, resource_bridge, mem))
+            decoder::backend::ffmpeg::FfmpegDecoder::new().into_trait_object()
         }
         #[cfg(feature = "vaapi")]
-        VideoBackendType::Vaapi => {
-            let va = decoder::backend::vaapi::VaapiDecoder::new().map_err(|e| {
+        VideoBackendType::Vaapi => decoder::backend::vaapi::VaapiDecoder::new()
+            .map_err(|e| {
                 Error::DeviceCreationFailed(format!(
                     "Failed to initialize VA-API driver for decoder: {}",
                     e
                 ))
-            })?;
-            Box::new(decoder::Decoder::new(va, resource_bridge, mem))
-        }
-    })
+            })?
+            .into_trait_object(),
+    };
+
+    Ok(Box::new(decoder::Decoder::new(
+        backend,
+        resource_bridge,
+        mem,
+    )))
 }
 
 /// Manages the zero-length, EOS-marked buffer signaling the end of a stream.
diff --git a/devices/src/virtio/video/protocol.rs b/devices/src/virtio/video/protocol.rs
index 5f0177e7d..e6f57413e 100644
--- a/devices/src/virtio/video/protocol.rs
+++ b/devices/src/virtio/video/protocol.rs
@@ -32,11 +32,6 @@ use zerocopy::AsBytes;
 use zerocopy::FromBytes;
 use zerocopy::FromZeroes;
 
-pub use crate::virtio::device_constants::video::virtio_video_config;
-pub use crate::virtio::device_constants::video::VIRTIO_VIDEO_F_RESOURCE_GUEST_PAGES;
-pub use crate::virtio::device_constants::video::VIRTIO_VIDEO_F_RESOURCE_NON_CONTIG;
-pub use crate::virtio::device_constants::video::VIRTIO_VIDEO_F_RESOURCE_VIRTIO_OBJECT;
-
 pub const VIRTIO_VIDEO_MAX_PLANES: u32 = 8;
 pub const VIRTIO_VIDEO_FORMAT_RAW_MIN: virtio_video_format = 1;
 pub const VIRTIO_VIDEO_FORMAT_ARGB8888: virtio_video_format = 1;
diff --git a/devices/src/virtio/video/worker.rs b/devices/src/virtio/video/worker.rs
index aa40ef8fd..0ab9418c8 100644
--- a/devices/src/virtio/video/worker.rs
+++ b/devices/src/virtio/video/worker.rs
@@ -36,19 +36,14 @@ use crate::virtio::video::response::Response;
 use crate::virtio::video::Error;
 use crate::virtio::video::Result;
 use crate::virtio::DescriptorChain;
-use crate::virtio::Interrupt;
 use crate::virtio::Queue;
 
 /// Worker that takes care of running the virtio video device.
 pub struct Worker {
     /// VirtIO queue for Command queue
     cmd_queue: Queue,
-    /// Device-to-driver notification for command queue
-    cmd_queue_interrupt: Interrupt,
     /// VirtIO queue for Event queue
     event_queue: Queue,
-    /// Device-to-driver notification for the event queue.
-    event_queue_interrupt: Interrupt,
     /// Stores descriptor chains in which responses for asynchronous commands will be written
     desc_map: AsyncCmdDescMap,
 }
@@ -57,17 +52,10 @@ pub struct Worker {
 type WritableResp = (DescriptorChain, response::CmdResponse);
 
 impl Worker {
-    pub fn new(
-        cmd_queue: Queue,
-        cmd_queue_interrupt: Interrupt,
-        event_queue: Queue,
-        event_queue_interrupt: Interrupt,
-    ) -> Self {
+    pub fn new(cmd_queue: Queue, event_queue: Queue) -> Self {
         Self {
             cmd_queue,
-            cmd_queue_interrupt,
             event_queue,
-            event_queue_interrupt,
             desc_map: Default::default(),
         }
     }
@@ -87,7 +75,7 @@ impl Worker {
             let len = desc.writer.bytes_written() as u32;
             self.cmd_queue.add_used(desc, len);
         }
-        self.cmd_queue.trigger_interrupt(&self.cmd_queue_interrupt);
+        self.cmd_queue.trigger_interrupt();
         Ok(())
     }
 
@@ -103,8 +91,7 @@ impl Worker {
             .map_err(|error| Error::WriteEventFailure { event, error })?;
         let len = desc.writer.bytes_written() as u32;
         self.event_queue.add_used(desc, len);
-        self.event_queue
-            .trigger_interrupt(&self.event_queue_interrupt);
+        self.event_queue.trigger_interrupt();
         Ok(())
     }
 
@@ -305,8 +292,7 @@ impl Worker {
     ///
     /// * `device` - Instance of backend device
     /// * `stream_id` - Stream session ID of the event
-    /// * `wait_ctx` - `device` may deregister the completed `Token::BufferBarrier` from
-    /// `wait_ctx`.
+    /// * `wait_ctx` - `device` may deregister the completed `Token::BufferBarrier` from `wait_ctx`.
     fn handle_buffer_barrier(
         &mut self,
         device: &mut dyn Device,
@@ -334,7 +320,7 @@ impl Worker {
         .and_then(|wc| {
             // resampling event exists per-PCI-INTx basis, so the two queues have the same event.
             // Thus, checking only cmd_queue_interrupt suffices.
-            if let Some(resample_evt) = self.cmd_queue_interrupt.get_resample_evt() {
+            if let Some(resample_evt) = self.cmd_queue.interrupt().get_resample_evt() {
                 wc.add(resample_evt, Token::InterruptResample)?;
             }
             Ok(wc)
@@ -364,11 +350,12 @@ impl Worker {
                         // resample exists. resampling event exists per-PCI-INTx basis, so the
                         // two queues have the same event.
                         let _ = self
-                            .cmd_queue_interrupt
+                            .cmd_queue
+                            .interrupt()
                             .get_resample_evt()
                             .expect("resample event for the command queue doesn't exist")
                             .wait();
-                        self.cmd_queue_interrupt.do_interrupt_resample();
+                        self.cmd_queue.interrupt().do_interrupt_resample();
                     }
                     Token::Kill => return Ok(()),
                 }
diff --git a/devices/src/virtio/virtio_device.rs b/devices/src/virtio/virtio_device.rs
index 295a0501f..63d0af223 100644
--- a/devices/src/virtio/virtio_device.rs
+++ b/devices/src/virtio/virtio_device.rs
@@ -3,29 +3,24 @@
 // found in the LICENSE file.
 
 use std::collections::BTreeMap;
-use std::sync::Arc;
 
 #[cfg(target_arch = "x86_64")]
 use acpi_tables::sdt::SDT;
 use anyhow::anyhow;
 use anyhow::Result;
-use base::Event;
 use base::Protection;
 use base::RawDescriptor;
 use hypervisor::MemCacheType;
-use sync::Mutex;
 use vm_control::VmMemorySource;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 
 use super::*;
-use crate::pci::MsixConfig;
 use crate::pci::MsixStatus;
 use crate::pci::PciAddress;
 use crate::pci::PciBarConfiguration;
 use crate::pci::PciBarIndex;
 use crate::pci::PciCapability;
-use crate::virtio::queue::QueueConfig;
 
 #[derive(Clone, Copy, Debug, PartialEq, Eq)]
 pub enum VirtioTransportType {
@@ -33,6 +28,15 @@ pub enum VirtioTransportType {
     Mmio,
 }
 
+/// Type of Virtio device memory mapping to use.
+pub enum SharedMemoryPrepareType {
+    /// On first attempted mapping, the entire SharedMemoryRegion is configured with declared
+    /// MemCacheType.
+    SingleMappingOnFirst(MemCacheType),
+    /// No mapping preparation is performed. each mapping is handled individually
+    DynamicPerMapping,
+}
+
 #[derive(Clone)]
 pub struct SharedMemoryRegion {
     /// The id of the shared memory region. A device may have multiple regions, but each
@@ -201,6 +205,14 @@ pub trait VirtioDevice: Send {
     /// devices can remain backwards compatible with older drivers.
     fn set_shared_memory_region_base(&mut self, _addr: GuestAddress) {}
 
+    /// Queries the implementation whether a single prepared hypervisor memory mapping with explicit
+    /// caching type should be setup lazily on first mapping request, or whether to dynamically
+    /// setup a hypervisor mapping with every request's caching type.
+    fn get_shared_memory_prepare_type(&mut self) -> SharedMemoryPrepareType {
+        // default to lazy-prepare of a single memslot with explicit caching type
+        SharedMemoryPrepareType::SingleMappingOnFirst(MemCacheType::CacheCoherent)
+    }
+
     /// Pause all processing.
     ///
     /// Gives up the queues so that a higher layer can potentially snapshot them. The
@@ -237,30 +249,6 @@ pub trait VirtioDevice: Send {
         anyhow::bail!("virtio_restore not implemented for {}", self.debug_label());
     }
 
-    /// Returns true if the device uses the vhost user protocol.
-    fn is_vhost_user(&self) -> bool {
-        false
-    }
-
-    /// Vhost user device specific restore to be called instead of `virtio_restore`. This will
-    /// rewire irqfds, queue_evts, start up the worker if needed, and send a RESTORE request to
-    /// the device process.
-    fn vhost_user_restore(
-        &mut self,
-        _data: serde_json::Value,
-        _queue_configs: &[QueueConfig],
-        _queue_evts: Option<Vec<Event>>,
-        _interrupt: Option<Interrupt>,
-        _mem: GuestMemory,
-        _msix_config: &Arc<Mutex<MsixConfig>>,
-        _device_activated: bool,
-    ) -> anyhow::Result<()> {
-        anyhow::bail!(
-            "vhost_user_restore not implemented for {}",
-            self.debug_label()
-        );
-    }
-
     // Returns a tuple consisting of the non-arch specific part of the OpenFirmware path,
     // represented as bytes, and the boot index of a device. The non-arch specific part of path for
     // a virtio-blk device, for example, would consist of everything after the first '/' below:
@@ -307,6 +295,7 @@ macro_rules! suspendable_virtio_tests {
                 num_queues: usize,
                 queue_size: u16,
                 mem: &GuestMemory,
+                interrupt: Interrupt,
             ) -> BTreeMap<usize, Queue> {
                 let mut queues = BTreeMap::new();
                 for i in 0..num_queues {
@@ -314,7 +303,7 @@ macro_rules! suspendable_virtio_tests {
                     let mut queue = QueueConfig::new(queue_size, 0);
                     queue.set_ready(true);
                     let queue = queue
-                        .activate(mem, Event::new().unwrap())
+                        .activate(mem, base::Event::new().unwrap(), interrupt.clone())
                         .expect("QueueConfig::activate");
                     queues.insert(i, queue);
                 }
@@ -343,6 +332,7 @@ macro_rules! suspendable_virtio_tests {
                         .cloned()
                         .expect("missing queue size"),
                     &mem,
+                    interrupt.clone(),
                 );
                 device
                     .activate(mem.clone(), interrupt.clone(), queues)
@@ -370,6 +360,7 @@ macro_rules! suspendable_virtio_tests {
                         .cloned()
                         .expect("missing queue size"),
                     &mem,
+                    interrupt.clone(),
                 );
                 device
                     .activate(mem.clone(), interrupt.clone(), queues)
@@ -386,7 +377,7 @@ macro_rules! suspendable_virtio_tests {
                 device
                     .virtio_wake(Some((mem.clone(), interrupt.clone(), sleep_result)))
                     .expect("failed to wake");
-                let (_, device) = &mut $dev();
+                let (_ctx2, mut device) = $dev();
                 device
                     .virtio_restore(snap.clone())
                     .expect("failed to restore");
diff --git a/devices/src/virtio/virtio_mmio_device.rs b/devices/src/virtio/virtio_mmio_device.rs
index 02f68e456..d111a0fb8 100644
--- a/devices/src/virtio/virtio_mmio_device.rs
+++ b/devices/src/virtio/virtio_mmio_device.rs
@@ -156,7 +156,7 @@ impl VirtioMmioDevice {
                 Ok((
                     queue_index,
                     queue
-                        .activate(&mem, queue_evt)
+                        .activate(&mem, queue_evt, interrupt.clone())
                         .context("failed to activate queue")?,
                 ))
             })
diff --git a/devices/src/virtio/virtio_pci_common_config.rs b/devices/src/virtio/virtio_pci_common_config.rs
index 050657b33..f53b6b44f 100644
--- a/devices/src/virtio/virtio_pci_common_config.rs
+++ b/devices/src/virtio/virtio_pci_common_config.rs
@@ -15,24 +15,24 @@ use super::*;
 /// device.
 ///
 /// * Registers:
-/// ** About the whole device.
-/// le32 device_feature_select;     // read-write
-/// le32 device_feature;            // read-only for driver
-/// le32 driver_feature_select;     // read-write
-/// le32 driver_feature;            // read-write
-/// le16 msix_config;               // read-write
-/// le16 num_queues;                // read-only for driver
-/// u8 device_status;               // read-write (driver_status)
-/// u8 config_generation;           // read-only for driver
-/// ** About a specific virtqueue.
-/// le16 queue_select;              // read-write
-/// le16 queue_size;                // read-write, power of 2, or 0.
-/// le16 queue_msix_vector;         // read-write
-/// le16 queue_enable;              // read-write (Ready)
-/// le16 queue_notify_off;          // read-only for driver
-/// le64 queue_desc;                // read-write
-/// le64 queue_avail;               // read-write
-/// le64 queue_used;                // read-write
+///   * About the whole device.
+///     * le32 device_feature_select;     // read-write
+///     * le32 device_feature;            // read-only for driver
+///     * le32 driver_feature_select;     // read-write
+///     * le32 driver_feature;            // read-write
+///     * le16 msix_config;               // read-write
+///     * le16 num_queues;                // read-only for driver
+///     * u8 device_status;               // read-write (driver_status)
+///     * u8 config_generation;           // read-only for driver
+///   * About a specific virtqueue.
+///     * le16 queue_select;              // read-write
+///     * le16 queue_size;                // read-write, power of 2, or 0.
+///     * le16 queue_msix_vector;         // read-write
+///     * le16 queue_enable;              // read-write (Ready)
+///     * le16 queue_notify_off;          // read-only for driver
+///     * le64 queue_desc;                // read-write
+///     * le64 queue_avail;               // read-write
+///     * le64 queue_used;                // read-write
 #[derive(Copy, Clone, Serialize, Deserialize)]
 pub struct VirtioPciCommonConfig {
     pub driver_status: u8,
diff --git a/devices/src/virtio/virtio_pci_device.rs b/devices/src/virtio/virtio_pci_device.rs
index 7dbbc74bd..01f4ebd9a 100644
--- a/devices/src/virtio/virtio_pci_device.rs
+++ b/devices/src/virtio/virtio_pci_device.rs
@@ -9,6 +9,7 @@ use std::sync::Arc;
 use acpi_tables::sdt::SDT;
 use anyhow::anyhow;
 use anyhow::Context;
+use base::debug;
 use base::error;
 use base::trace;
 use base::AsRawDescriptor;
@@ -37,6 +38,7 @@ use virtio_sys::virtio_config::VIRTIO_CONFIG_S_DRIVER_OK;
 use virtio_sys::virtio_config::VIRTIO_CONFIG_S_FAILED;
 use virtio_sys::virtio_config::VIRTIO_CONFIG_S_FEATURES_OK;
 use virtio_sys::virtio_config::VIRTIO_CONFIG_S_NEEDS_RESET;
+use virtio_sys::virtio_config::VIRTIO_CONFIG_S_SUSPEND;
 use vm_control::api::VmMemoryClient;
 use vm_control::VmMemoryDestination;
 use vm_control::VmMemoryRegionId;
@@ -65,6 +67,7 @@ use crate::pci::PciBarConfiguration;
 use crate::pci::PciBarIndex;
 use crate::pci::PciBarPrefetchable;
 use crate::pci::PciBarRegionType;
+use crate::pci::PciBaseSystemPeripheralSubclass;
 use crate::pci::PciCapability;
 use crate::pci::PciCapabilityID;
 use crate::pci::PciClassCode;
@@ -74,9 +77,14 @@ use crate::pci::PciDeviceError;
 use crate::pci::PciDisplaySubclass;
 use crate::pci::PciHeaderType;
 use crate::pci::PciId;
+use crate::pci::PciInputDeviceSubclass;
 use crate::pci::PciInterruptPin;
 use crate::pci::PciMassStorageSubclass;
+use crate::pci::PciMultimediaSubclass;
+use crate::pci::PciNetworkControllerSubclass;
+use crate::pci::PciSimpleCommunicationControllerSubclass;
 use crate::pci::PciSubclass;
+use crate::pci::PciWirelessControllerSubclass;
 use crate::virtio::ipc_memory_mapper::IpcMemoryMapper;
 #[cfg(feature = "pci-hotplug")]
 use crate::HotPluggable;
@@ -238,19 +246,6 @@ impl VirtioPciShmCap {
     }
 }
 
-/// Subclasses for virtio.
-#[allow(dead_code)]
-#[derive(Copy, Clone)]
-pub enum PciVirtioSubclass {
-    NonTransitionalBase = 0xff,
-}
-
-impl PciSubclass for PciVirtioSubclass {
-    fn get_register_value(&self) -> u8 {
-        *self as u8
-    }
-}
-
 // Allocate one bar for the structs pointed to by the capability structures.
 const COMMON_CONFIG_BAR_OFFSET: u64 = 0x0000;
 const COMMON_CONFIG_SIZE: u64 = 56;
@@ -382,17 +377,89 @@ impl VirtioPciDevice {
         let pci_device_id = VIRTIO_PCI_DEVICE_ID_BASE + device.device_type() as u16;
 
         let (pci_device_class, pci_device_subclass) = match device.device_type() {
+            DeviceType::Net => (
+                PciClassCode::NetworkController,
+                &PciNetworkControllerSubclass::Other as &dyn PciSubclass,
+            ),
             DeviceType::Block => (
                 PciClassCode::MassStorage,
                 &PciMassStorageSubclass::Other as &dyn PciSubclass,
             ),
+            DeviceType::Console => (
+                PciClassCode::SimpleCommunicationController,
+                &PciSimpleCommunicationControllerSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Rng => (
+                PciClassCode::BaseSystemPeripheral,
+                &PciBaseSystemPeripheralSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Balloon => (
+                PciClassCode::BaseSystemPeripheral,
+                &PciBaseSystemPeripheralSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Scsi => (
+                PciClassCode::MassStorage,
+                &PciMassStorageSubclass::Scsi as &dyn PciSubclass,
+            ),
+            DeviceType::P9 => (
+                PciClassCode::NetworkController,
+                &PciNetworkControllerSubclass::Other as &dyn PciSubclass,
+            ),
             DeviceType::Gpu => (
                 PciClassCode::DisplayController,
                 &PciDisplaySubclass::Other as &dyn PciSubclass,
             ),
-            _ => (
-                PciClassCode::TooOld,
-                &PciVirtioSubclass::NonTransitionalBase as &dyn PciSubclass,
+            DeviceType::Input => (
+                PciClassCode::InputDevice,
+                &PciInputDeviceSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Vsock => (
+                PciClassCode::NetworkController,
+                &PciNetworkControllerSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Iommu => (
+                PciClassCode::BaseSystemPeripheral,
+                &PciBaseSystemPeripheralSubclass::Iommu as &dyn PciSubclass,
+            ),
+            DeviceType::Sound => (
+                PciClassCode::MultimediaController,
+                &PciMultimediaSubclass::AudioController as &dyn PciSubclass,
+            ),
+            DeviceType::Fs => (
+                PciClassCode::MassStorage,
+                &PciMassStorageSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Pmem => (
+                PciClassCode::MassStorage,
+                &PciMassStorageSubclass::NonVolatileMemory as &dyn PciSubclass,
+            ),
+            DeviceType::Mac80211HwSim => (
+                PciClassCode::WirelessController,
+                &PciWirelessControllerSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::VideoEncoder => (
+                PciClassCode::MultimediaController,
+                &PciMultimediaSubclass::VideoController as &dyn PciSubclass,
+            ),
+            DeviceType::VideoDecoder => (
+                PciClassCode::MultimediaController,
+                &PciMultimediaSubclass::VideoController as &dyn PciSubclass,
+            ),
+            DeviceType::Scmi => (
+                PciClassCode::BaseSystemPeripheral,
+                &PciBaseSystemPeripheralSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Wl => (
+                PciClassCode::DisplayController,
+                &PciDisplaySubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Tpm => (
+                PciClassCode::BaseSystemPeripheral,
+                &PciBaseSystemPeripheralSubclass::Other as &dyn PciSubclass,
+            ),
+            DeviceType::Pvclock => (
+                PciClassCode::BaseSystemPeripheral,
+                &PciBaseSystemPeripheralSubclass::Other as &dyn PciSubclass,
             ),
         };
 
@@ -459,6 +526,10 @@ impl VirtioPciDevice {
             && self.common_config.driver_status & VIRTIO_CONFIG_S_FAILED as u8 == 0
     }
 
+    fn is_device_suspended(&self) -> bool {
+        (self.common_config.driver_status & VIRTIO_CONFIG_S_SUSPEND as u8) != 0
+    }
+
     /// Determines if the driver has requested the device reset itself
     fn is_reset_requested(&self) -> bool {
         self.common_config.driver_status == DEVICE_RESET as u8
@@ -547,9 +618,8 @@ impl VirtioPciDevice {
             Some(self.msix_config.clone()),
             self.common_config.msix_config,
             #[cfg(target_arch = "x86_64")]
-            Some(PmWakeupEvent::new(
-                self.vm_control_tube.clone(),
-                self.pm_config.clone(),
+            Some((
+                PmWakeupEvent::new(self.vm_control_tube.clone(), self.pm_config.clone()),
                 MetricEventType::VirtioWakeup {
                     virtio_id: self.device.device_type() as u32,
                 },
@@ -582,7 +652,7 @@ impl VirtioPciDevice {
                 Ok((
                     queue_index,
                     queue
-                        .activate(&self.mem, queue_evt)
+                        .activate(&self.mem, queue_evt, interrupt.clone())
                         .context("failed to activate queue")?,
                 ))
             })
@@ -846,6 +916,8 @@ impl PciDevice for VirtioPciDevice {
     }
 
     fn write_bar(&mut self, bar_index: usize, offset: u64, data: &[u8]) {
+        let was_suspended = self.is_device_suspended();
+
         if bar_index == self.settings_bar {
             match offset {
                 COMMON_CONFIG_BAR_OFFSET..=COMMON_CONFIG_LAST => self.common_config.write(
@@ -903,6 +975,13 @@ impl PciDevice for VirtioPciDevice {
             }
         }
 
+        let is_suspended = self.is_device_suspended();
+        if is_suspended != was_suspended {
+            if let Some(interrupt) = self.interrupt.as_mut() {
+                interrupt.set_suspended(is_suspended);
+            }
+        }
+
         // Device has been reset by the driver
         if self.device_activated && self.is_reset_requested() {
             if let Err(e) = self.device.reset() {
@@ -1015,19 +1094,25 @@ where
             bar: config.bar_index() as u8,
         };
 
+        let vm_memory_client = virtio_pci_device
+            .shared_memory_vm_memory_client
+            .take()
+            .expect("missing shared_memory_tube");
+
+        // See comment VmMemoryRequest::execute
+        let can_prepare = !virtio_pci_device
+            .device
+            .expose_shmem_descriptors_with_viommu();
+        let prepare_type = if can_prepare {
+            virtio_pci_device.device.get_shared_memory_prepare_type()
+        } else {
+            SharedMemoryPrepareType::DynamicPerMapping
+        };
+
+        let vm_requester = Box::new(VmRequester::new(vm_memory_client, alloc, prepare_type));
         virtio_pci_device
             .device
-            .set_shared_memory_mapper(Box::new(VmRequester::new(
-                virtio_pci_device
-                    .shared_memory_vm_memory_client
-                    .take()
-                    .expect("missing shared_memory_tube"),
-                alloc,
-                // See comment VmMemoryRequest::execute
-                !virtio_pci_device
-                    .device
-                    .expose_shmem_descriptors_with_viommu(),
-            )));
+            .set_shared_memory_mapper(vm_requester);
 
         vec![config]
     };
@@ -1130,13 +1215,6 @@ impl Suspendable for VirtioPciDevice {
             return Ok(());
         }
 
-        // Don't call `self.device.virtio_sleep()` for vhost user devices if the device is not
-        // activated yet, since it will always return an empty Vec.
-        if !self.device_activated && self.device.is_vhost_user() {
-            // This will need to be set, so that a cold restore will work.
-            self.sleep_state = Some(SleepState::Inactive);
-            return Ok(());
-        }
         if let Some(queues) = self.device.virtio_sleep()? {
             anyhow::ensure!(
                 self.device_activated,
@@ -1162,11 +1240,6 @@ impl Suspendable for VirtioPciDevice {
     }
 
     fn wake(&mut self) -> anyhow::Result<()> {
-        // A vhost user device that isn't activated doesn't need to be woken up.
-        if !self.device_activated && self.device.is_vhost_user() {
-            self.sleep_state = None;
-            return Ok(());
-        }
         match self.sleep_state.take() {
             None => {
                 // If the device is already awake, we should not request it to wake again.
@@ -1250,6 +1323,30 @@ impl Suspendable for VirtioPciDevice {
         self.msix_config.lock().restore(deser.msix_config)?;
         self.common_config = deser.common_config;
 
+        // Restore the interrupt. This must be done after restoring the MSI-X configuration, but
+        // before restoring the queues.
+        if let Some(deser_interrupt) = deser.interrupt {
+            self.interrupt = Some(Interrupt::new_from_snapshot(
+                self.interrupt_evt
+                    .as_ref()
+                    .ok_or_else(|| anyhow!("{} interrupt_evt is none", self.debug_label()))?
+                    .try_clone()
+                    .with_context(|| {
+                        format!("{} failed to clone interrupt_evt", self.debug_label())
+                    })?,
+                Some(self.msix_config.clone()),
+                self.common_config.msix_config,
+                deser_interrupt,
+                #[cfg(target_arch = "x86_64")]
+                Some((
+                    PmWakeupEvent::new(self.vm_control_tube.clone(), self.pm_config.clone()),
+                    MetricEventType::VirtioWakeup {
+                        virtio_id: self.device.device_type() as u32,
+                    },
+                )),
+            ));
+        }
+
         assert_eq!(
             self.queues.len(),
             deser.queues.len(),
@@ -1271,6 +1368,10 @@ impl Suspendable for VirtioPciDevice {
         };
         // Restore `sleep_state`.
         if let Some(activated_queues_snapshot) = deser.activated_queues {
+            let interrupt = self
+                .interrupt
+                .as_ref()
+                .context("tried to restore active queues without an interrupt")?;
             let mut activated_queues = BTreeMap::new();
             for (index, queue_snapshot) in activated_queues_snapshot {
                 let queue_config = self
@@ -1286,7 +1387,13 @@ impl Suspendable for VirtioPciDevice {
                     .context("failed to clone queue event")?;
                 activated_queues.insert(
                     index,
-                    Queue::restore(queue_config, queue_snapshot, &self.mem, queue_evt)?,
+                    Queue::restore(
+                        queue_config,
+                        queue_snapshot,
+                        &self.mem,
+                        queue_evt,
+                        interrupt.clone(),
+                    )?,
                 );
             }
 
@@ -1296,33 +1403,6 @@ impl Suspendable for VirtioPciDevice {
             self.sleep_state = Some(SleepState::Inactive);
         }
 
-        // Also replicate the other work in activate: initialize the interrupt and queues
-        // events. This could just as easily be done in `wake` instead.
-        // NOTE: Needs to be done last in `restore` because it relies on the other VirtioPciDevice
-        // fields.
-        if let Some(deser_interrupt) = deser.interrupt {
-            self.interrupt = Some(Interrupt::new_from_snapshot(
-                self.interrupt_evt
-                    .as_ref()
-                    .ok_or_else(|| anyhow!("{} interrupt_evt is none", self.debug_label()))?
-                    .try_clone()
-                    .with_context(|| {
-                        format!("{} failed to clone interrupt_evt", self.debug_label())
-                    })?,
-                Some(self.msix_config.clone()),
-                self.common_config.msix_config,
-                deser_interrupt,
-                #[cfg(target_arch = "x86_64")]
-                Some(PmWakeupEvent::new(
-                    self.vm_control_tube.clone(),
-                    self.pm_config.clone(),
-                    MetricEventType::VirtioWakeup {
-                        virtio_id: self.device.device_type() as u32,
-                    },
-                )),
-            ));
-        }
-
         // Call register_io_events for the activated queue events.
         let bar0 = self.config_regs.get_bar_addr(self.settings_bar);
         let notify_base = bar0 + NOTIFICATION_BAR_OFFSET;
@@ -1358,42 +1438,7 @@ impl Suspendable for VirtioPciDevice {
                 .context("failed to wake doorbell")
         })?;
 
-        if self.device.is_vhost_user() {
-            let (queue_evts, interrupt) = if self.device_activated {
-                (
-                    Some(
-                        self.queue_evts
-                            .iter()
-                            .map(|queue_evt| {
-                                queue_evt
-                                    .event
-                                    .try_clone()
-                                    .context("Failed to clone queue_evt")
-                            })
-                            .collect::<anyhow::Result<Vec<_>>>()?,
-                    ),
-                    Some(
-                        self.interrupt
-                            .as_ref()
-                            .expect("Interrupt should not be empty if device was activated.")
-                            .clone(),
-                    ),
-                )
-            } else {
-                (None, None)
-            };
-            self.device.vhost_user_restore(
-                deser.inner_device,
-                &self.queues,
-                queue_evts,
-                interrupt,
-                self.mem.clone(),
-                &self.msix_config,
-                self.device_activated,
-            )?;
-        } else {
-            self.device.virtio_restore(deser.inner_device)?;
-        }
+        self.device.virtio_restore(deser.inner_device)?;
 
         Ok(())
     }
@@ -1403,16 +1448,22 @@ struct VmRequester {
     vm_memory_client: VmMemoryClient,
     alloc: Alloc,
     mappings: BTreeMap<u64, VmMemoryRegionId>,
-    needs_prepare: bool,
+    prepare_type: SharedMemoryPrepareType,
+    prepared: bool,
 }
 
 impl VmRequester {
-    fn new(vm_memory_client: VmMemoryClient, alloc: Alloc, do_prepare: bool) -> Self {
+    fn new(
+        vm_memory_client: VmMemoryClient,
+        alloc: Alloc,
+        prepare_type: SharedMemoryPrepareType,
+    ) -> Self {
         Self {
             vm_memory_client,
             alloc,
             mappings: BTreeMap::new(),
-            needs_prepare: do_prepare,
+            prepare_type,
+            prepared: false,
         }
     }
 }
@@ -1425,11 +1476,31 @@ impl SharedMemoryMapper for VmRequester {
         prot: Protection,
         cache: MemCacheType,
     ) -> anyhow::Result<()> {
-        if self.needs_prepare {
-            self.vm_memory_client
-                .prepare_shared_memory_region(self.alloc, cache)
-                .context("prepare_shared_memory_region failed")?;
-            self.needs_prepare = false;
+        if !self.prepared {
+            if let SharedMemoryPrepareType::SingleMappingOnFirst(prepare_cache_type) =
+                self.prepare_type
+            {
+                debug!(
+                    "lazy prepare_shared_memory_region with {:?}",
+                    prepare_cache_type
+                );
+                self.vm_memory_client
+                    .prepare_shared_memory_region(self.alloc, prepare_cache_type)
+                    .context("lazy prepare_shared_memory_region failed")?;
+            }
+            self.prepared = true;
+        }
+
+        // devices must implement VirtioDevice::get_shared_memory_prepare_type(), returning
+        // SharedMemoryPrepareType::SingleMappingOnFirst(MemCacheType::CacheNonCoherent) in order to
+        // add any mapping that requests MemCacheType::CacheNonCoherent.
+        if cache == MemCacheType::CacheNonCoherent {
+            if let SharedMemoryPrepareType::SingleMappingOnFirst(MemCacheType::CacheCoherent) =
+                self.prepare_type
+            {
+                error!("invalid request to map with CacheNonCoherent for device with prepared CacheCoherent memory");
+                return Err(anyhow!("invalid MemCacheType"));
+            }
         }
 
         let id = self
diff --git a/devices/src/virtio/vsock/sys/windows/protocol.rs b/devices/src/virtio/vsock/sys/windows/protocol.rs
index a495b97cf..e7d73b150 100644
--- a/devices/src/virtio/vsock/sys/windows/protocol.rs
+++ b/devices/src/virtio/vsock/sys/windows/protocol.rs
@@ -20,7 +20,7 @@ pub struct virtio_vsock_config {
 
 /// The message header for data packets sent on the tx/rx queues
 #[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
-#[repr(packed)]
+#[repr(C, packed)]
 #[allow(non_camel_case_types)]
 pub struct virtio_vsock_hdr {
     pub src_cid: Le64,
diff --git a/devices/src/virtio/vsock/sys/windows/vsock.rs b/devices/src/virtio/vsock/sys/windows/vsock.rs
index b23420d5c..ec65a5a4f 100644
--- a/devices/src/virtio/vsock/sys/windows/vsock.rs
+++ b/devices/src/virtio/vsock/sys/windows/vsock.rs
@@ -721,7 +721,7 @@ impl Worker {
             }
 
             queue.add_used(avail_desc, 0);
-            queue.trigger_interrupt(&self.interrupt);
+            queue.trigger_interrupt();
         }
 
         Ok(queue)
@@ -1379,7 +1379,7 @@ impl Worker {
         let bytes_written = writer.bytes_written() as u32;
         if bytes_written > 0 {
             queue.add_used(desc_chain, bytes_written);
-            queue.trigger_interrupt(&self.interrupt);
+            queue.trigger_interrupt();
             Ok(())
         } else {
             error!("vsock: failed to write bytes to queue");
diff --git a/devices/src/virtio/wl.rs b/devices/src/virtio/wl.rs
index 10e4dd37a..ecf4f4ed2 100644
--- a/devices/src/virtio/wl.rs
+++ b/devices/src/virtio/wl.rs
@@ -72,7 +72,6 @@ use base::Error;
 use base::Event;
 use base::EventToken;
 use base::EventType;
-use base::FromRawDescriptor;
 #[cfg(feature = "gpu")]
 use base::IntoRawDescriptor;
 #[cfg(feature = "minigbm")]
@@ -234,7 +233,7 @@ fn is_fence(f: &File) -> bool {
     let info = sync_file_info::default();
     // SAFETY:
     // Safe as f is a valid file
-    unsafe { ioctl_with_ref(f, SYNC_IOC_FILE_INFO(), &info) == 0 }
+    unsafe { ioctl_with_ref(f, SYNC_IOC_FILE_INFO, &info) == 0 }
 }
 
 #[cfg(feature = "minigbm")]
@@ -464,7 +463,7 @@ struct VmRequester {
 fn to_safe_descriptor(r: RutabagaDescriptor) -> SafeDescriptor {
     // SAFETY:
     // Safe because we own the SafeDescriptor at this point.
-    unsafe { SafeDescriptor::from_raw_descriptor(r.into_raw_descriptor()) }
+    unsafe { base::FromRawDescriptor::from_raw_descriptor(r.into_raw_descriptor()) }
 }
 
 impl VmRequester {
@@ -673,7 +672,6 @@ struct CtrlVfdNewDmabuf {
 #[cfg(feature = "minigbm")]
 #[repr(C)]
 #[derive(Copy, Clone, Default, AsBytes, FromZeroes, FromBytes)]
-#[cfg(feature = "minigbm")]
 struct CtrlVfdDmabufSync {
     hdr: CtrlHeader,
     id: Le32,
@@ -918,7 +916,7 @@ impl WlVfd {
                 };
                 // SAFETY:
                 // Safe as descriptor is a valid dmabuf and incorrect flags will return an error.
-                if unsafe { ioctl_with_ref(descriptor, DMA_BUF_IOCTL_SYNC(), &sync) } < 0 {
+                if unsafe { ioctl_with_ref(descriptor, DMA_BUF_IOCTL_SYNC, &sync) } < 0 {
                     return Err(WlError::DmabufSync(io::Error::last_os_error()));
                 }
 
@@ -1054,14 +1052,14 @@ impl WlVfd {
                 .send_vectored_with_fds(&data.get_remaining(), rds)
                 .map_err(WlError::SendVfd)?;
             // All remaining data in `data` is now considered consumed.
-            data.consume(::std::usize::MAX);
+            data.consume(usize::MAX);
             Ok(WlResp::Ok)
         } else if let Some((_, local_pipe)) = &mut self.local_pipe {
             // Impossible to send descriptors over a simple pipe.
             if !rds.is_empty() {
                 return Ok(WlResp::InvalidType);
             }
-            data.read_to(local_pipe, usize::max_value())
+            data.read_to(local_pipe, usize::MAX)
                 .map_err(WlError::WritePipe)?;
             Ok(WlResp::Ok)
         } else {
@@ -1494,7 +1492,9 @@ impl WlState {
                             *descriptor = dup.into_raw_descriptor();
                             // SAFETY:
                             // Safe because the fd comes from a valid SafeDescriptor.
-                            let file = unsafe { File::from_raw_descriptor(*descriptor) };
+                            let file: File = unsafe {
+                                base::FromRawDescriptor::from_raw_descriptor(*descriptor)
+                            };
                             bridged_files.push(file);
                         }
                         Err(_) => return Ok(WlResp::InvalidId),
@@ -1765,7 +1765,6 @@ pub struct DescriptorsExhausted;
 
 /// Handle incoming events and forward them to the VM over the input queue.
 pub fn process_in_queue(
-    interrupt: &Interrupt,
     in_queue: &mut Queue,
     state: &mut WlState,
 ) -> ::std::result::Result<(), DescriptorsExhausted> {
@@ -1804,7 +1803,7 @@ pub fn process_in_queue(
     }
 
     if needs_interrupt {
-        in_queue.trigger_interrupt(interrupt);
+        in_queue.trigger_interrupt();
     }
 
     if exhausted_queue {
@@ -1815,7 +1814,7 @@ pub fn process_in_queue(
 }
 
 /// Handle messages from the output queue and forward them to the display sever, if necessary.
-pub fn process_out_queue(interrupt: &Interrupt, out_queue: &mut Queue, state: &mut WlState) {
+pub fn process_out_queue(out_queue: &mut Queue, state: &mut WlState) {
     let mut needs_interrupt = false;
     while let Some(mut desc) = out_queue.pop() {
         let resp = match state.execute(&mut desc.reader) {
@@ -1836,7 +1835,7 @@ pub fn process_out_queue(interrupt: &Interrupt, out_queue: &mut Queue, state: &m
     }
 
     if needs_interrupt {
-        out_queue.trigger_interrupt(interrupt);
+        out_queue.trigger_interrupt();
     }
 }
 
@@ -1927,12 +1926,12 @@ impl Worker {
                     }
                     Token::OutQueue => {
                         let _ = self.out_queue.event().wait();
-                        process_out_queue(&self.interrupt, &mut self.out_queue, &mut self.state);
+                        process_out_queue(&mut self.out_queue, &mut self.state);
                     }
                     Token::Kill => break 'wait,
                     Token::State => {
                         if let Err(DescriptorsExhausted) =
-                            process_in_queue(&self.interrupt, &mut self.in_queue, &mut self.state)
+                            process_in_queue(&mut self.in_queue, &mut self.state)
                         {
                             if let Err(e) =
                                 wait_ctx.modify(&self.state.wait_ctx, EventType::None, Token::State)
diff --git a/devices/src/vmwdt.rs b/devices/src/vmwdt.rs
index 25eb67b97..1ed2b0f47 100644
--- a/devices/src/vmwdt.rs
+++ b/devices/src/vmwdt.rs
@@ -6,16 +6,16 @@
 //! on the vCPUs and resets the guest when no 'pet' events are received.
 //! <https://docs.google.com/document/d/1DYmk2roxlwHZsOfcJi8xDMdWOHAmomvs2SDh7KPud3Y/edit?usp=sharing&resourcekey=0-oSNabc-t040a1q0K4cyI8Q>
 
+use std::collections::BTreeMap;
 use std::convert::TryFrom;
 use std::fs;
-use std::io::Error as IoError;
-use std::process;
 use std::sync::Arc;
 use std::time::Duration;
 
+use anyhow::Context;
+use base::custom_serde::serialize_arc_mutex;
 use base::debug;
 use base::error;
-use base::gettid;
 use base::warn;
 use base::AsRawDescriptor;
 use base::Descriptor;
@@ -25,17 +25,20 @@ use base::EventToken;
 use base::SendTube;
 use base::Timer;
 use base::TimerTrait;
+use base::Tube;
 use base::VmEventType;
 use base::WaitContext;
 use base::WorkerThread;
-use remain::sorted;
+use serde::Deserialize;
+use serde::Serialize;
 use sync::Mutex;
-use thiserror::Error;
+use vm_control::VmResponse;
 
 use crate::pci::CrosvmDeviceId;
 use crate::BusAccessInfo;
 use crate::BusDevice;
 use crate::DeviceId;
+use crate::IrqEdgeEvent;
 use crate::Suspendable;
 
 // Registers offsets
@@ -53,64 +56,84 @@ pub const VMWDT_DEFAULT_CLOCK_HZ: u32 = 2;
 // Proc stat indexes
 const PROCSTAT_GUEST_TIME_INDX: usize = 42;
 
-#[sorted]
-#[derive(Error, Debug)]
-pub enum VmwdtError {
-    /// Error while creating event.
-    #[error("failed to create event: {0}")]
-    CreateEvent(SysError),
-    /// Error while trying to create worker thread.
-    #[error("failed to spawn thread: {0}")]
-    SpawnThread(IoError),
-    /// Error while trying to create timer.
-    #[error("failed to create vmwdt counter due to timer fd: {0}")]
-    TimerCreateError(SysError),
-    #[error("failed to wait for events: {0}")]
-    WaitError(SysError),
-}
-
-type VmwdtResult<T> = std::result::Result<T, VmwdtError>;
-
+#[derive(Serialize)]
 pub struct VmwdtPerCpu {
     // Flag which indicated if the watchdog is started
     is_enabled: bool,
     // Timer used to generate periodic events at `timer_freq_hz` frequency
+    #[serde(skip_serializing)]
     timer: Timer,
     // The frequency of the `timer`
     timer_freq_hz: u64,
     // Timestamp measured in miliseconds of the last guest activity
     last_guest_time_ms: i64,
-    // The pid of the thread this vcpu belongs to
-    pid: u32,
+    // The thread_id of the thread this vcpu belongs to
+    thread_id: u32,
     // The process id of the task this vcpu belongs to
-    ppid: u32,
+    process_id: u32,
     // The pre-programmed one-shot expiration interval. If the guest runs in this
     // interval but we don't receive a periodic event, the guest is stalled.
     next_expiration_interval_ms: i64,
+    // Keep track if the watchdog PPI raised.
+    stall_evt_ppi_triggered: bool,
+    // Keep track if the time was armed with oneshot mode or with repeating interval
+    repeating_interval: Option<Duration>,
+}
+
+#[derive(Deserialize)]
+struct VmwdtPerCpuRestore {
+    is_enabled: bool,
+    timer_freq_hz: u64,
+    last_guest_time_ms: i64,
+    next_expiration_interval_ms: i64,
+    repeating_interval: Option<Duration>,
 }
 
 pub struct Vmwdt {
     vm_wdts: Arc<Mutex<Vec<VmwdtPerCpu>>>,
     // The worker thread that waits on the timer fd
-    worker_thread: Option<WorkerThread<()>>,
+    worker_thread: Option<WorkerThread<Tube>>,
     // TODO: @sebastianene add separate reset event for the watchdog
     // Reset source if the device is not responding
     reset_evt_wrtube: SendTube,
     activated: bool,
+    // Event to be used to interrupt the guest on detected stalls
+    stall_evt: IrqEdgeEvent,
+    vm_ctrl_tube: Option<Tube>,
+}
+
+#[derive(Serialize)]
+struct VmwdtSnapshot {
+    #[serde(serialize_with = "serialize_arc_mutex")]
+    vm_wdts: Arc<Mutex<Vec<VmwdtPerCpu>>>,
+    activated: bool,
+}
+
+#[derive(Deserialize)]
+struct VmwdtRestore {
+    vm_wdts: Vec<VmwdtPerCpuRestore>,
+    activated: bool,
 }
 
 impl Vmwdt {
-    pub fn new(cpu_count: usize, reset_evt_wrtube: SendTube) -> VmwdtResult<Vmwdt> {
+    pub fn new(
+        cpu_count: usize,
+        reset_evt_wrtube: SendTube,
+        evt: IrqEdgeEvent,
+        vm_ctrl_tube: Tube,
+    ) -> anyhow::Result<Vmwdt> {
         let mut vec = Vec::new();
         for _ in 0..cpu_count {
             vec.push(VmwdtPerCpu {
                 last_guest_time_ms: 0,
-                pid: 0,
-                ppid: 0,
+                thread_id: 0,
+                process_id: 0,
                 is_enabled: false,
-                timer: Timer::new().unwrap(),
+                stall_evt_ppi_triggered: false,
+                timer: Timer::new().context("failed to create Timer")?,
                 timer_freq_hz: 0,
                 next_expiration_interval_ms: 0,
+                repeating_interval: None,
             });
         }
         let vm_wdts = Arc::new(Mutex::new(vec));
@@ -120,6 +143,8 @@ impl Vmwdt {
             worker_thread: None,
             reset_evt_wrtube,
             activated: false,
+            stall_evt: evt,
+            vm_ctrl_tube: Some(vm_ctrl_tube),
         })
     }
 
@@ -127,62 +152,111 @@ impl Vmwdt {
         vm_wdts: Arc<Mutex<Vec<VmwdtPerCpu>>>,
         kill_evt: Event,
         reset_evt_wrtube: SendTube,
-    ) {
+        stall_evt: IrqEdgeEvent,
+        vm_ctrl_tube: Tube,
+        worker_started_send: Option<SendTube>,
+    ) -> anyhow::Result<Tube> {
+        let msg = vm_control::VmRequest::VcpuPidTid;
+        vm_ctrl_tube
+            .send(&msg)
+            .context("failed to send request to fetch Vcpus PID and TID")?;
+        let vcpus_pid_tid: BTreeMap<usize, (u32, u32)> = match vm_ctrl_tube
+            .recv()
+            .context("failed to receive vmwdt pids and tids")?
+        {
+            VmResponse::VcpuPidTidResponse { pid_tid_map } => pid_tid_map,
+            _ => {
+                return Err(anyhow::anyhow!(
+                    "Receive incorrect message type when trying to get vcpu pid tid map"
+                ));
+            }
+        };
+        {
+            let mut vm_wdts = vm_wdts.lock();
+            for (i, vmwdt) in (*vm_wdts).iter_mut().enumerate() {
+                let pid_tid = vcpus_pid_tid
+                    .get(&i)
+                    .context("vmwdts empty, which could indicate no vcpus are initialized")?;
+                vmwdt.process_id = pid_tid.0;
+                vmwdt.thread_id = pid_tid.1;
+            }
+        }
+        if let Some(worker_started_send) = worker_started_send {
+            worker_started_send
+                .send(&())
+                .context("failed to send vmwdt worker started")?;
+        }
         #[derive(EventToken)]
         enum Token {
             Kill,
             Timer(usize),
         }
 
-        let wait_ctx: WaitContext<Token> = WaitContext::new().unwrap();
-        wait_ctx.add(&kill_evt, Token::Kill).unwrap();
+        let wait_ctx: WaitContext<Token> =
+            WaitContext::new().context("Failed to create wait_ctx")?;
+        wait_ctx
+            .add(&kill_evt, Token::Kill)
+            .context("Failed to add Tokens to wait_ctx")?;
 
         let len = vm_wdts.lock().len();
         for clock_id in 0..len {
             let timer_fd = vm_wdts.lock()[clock_id].timer.as_raw_descriptor();
             wait_ctx
                 .add(&Descriptor(timer_fd), Token::Timer(clock_id))
-                .unwrap();
+                .context("Failed to link FDs to Tokens")?;
         }
 
         loop {
-            let events = wait_ctx.wait().unwrap();
+            let events = wait_ctx.wait().context("Failed to wait for events")?;
             for event in events.iter().filter(|e| e.is_readable) {
                 match event.token {
                     Token::Kill => {
-                        return;
+                        return Ok(vm_ctrl_tube);
                     }
                     Token::Timer(cpu_id) => {
                         let mut wdts_locked = vm_wdts.lock();
                         let watchdog = &mut wdts_locked[cpu_id];
-                        if let Err(_e) = watchdog.timer.wait() {
-                            error!("error waiting for timer event on vcpu {}", cpu_id);
+                        match watchdog.timer.mark_waited() {
+                            Ok(true) => continue, // timer not actually ready
+                            Ok(false) => {}
+                            Err(e) => {
+                                error!("error waiting for timer event on vcpu {cpu_id}: {e:#}");
+                                continue;
+                            }
                         }
 
-                        let current_guest_time_ms_result =
-                            Vmwdt::get_guest_time_ms(watchdog.ppid, watchdog.pid);
-                        let current_guest_time_ms = match current_guest_time_ms_result {
-                            Ok(value) => value,
-                            Err(_e) => return,
-                        };
+                        let current_guest_time_ms =
+                            Vmwdt::get_guest_time_ms(watchdog.process_id, watchdog.thread_id)
+                                .context("get_guest_time_ms failed")?;
                         let remaining_time_ms = watchdog.next_expiration_interval_ms
                             - (current_guest_time_ms - watchdog.last_guest_time_ms);
 
                         if remaining_time_ms > 0 {
                             watchdog.next_expiration_interval_ms = remaining_time_ms;
-                            if let Err(_e) = watchdog
+                            if let Err(e) = watchdog
                                 .timer
-                                .reset(Duration::from_millis(remaining_time_ms as u64), None)
+                                .reset_oneshot(Duration::from_millis(remaining_time_ms as u64))
                             {
-                                error!("failed to reset internal timer on vcpu {}", cpu_id);
+                                error!(
+                                    "failed to reset internal timer on vcpu {}: {:#}",
+                                    cpu_id, e
+                                );
                             }
+                            watchdog.repeating_interval = None;
                         } else {
-                            // The guest ran but it did not send the periodic event
-                            if let Err(_e) =
-                                reset_evt_wrtube.send::<VmEventType>(&VmEventType::WatchdogReset)
-                            {
-                                error!("failed to send reset event from vcpu {}", cpu_id)
+                            if watchdog.stall_evt_ppi_triggered {
+                                if let Err(e) = reset_evt_wrtube
+                                    .send::<VmEventType>(&VmEventType::WatchdogReset)
+                                {
+                                    error!("{} failed to send reset event from vcpu {}", e, cpu_id)
+                                }
                             }
+
+                            stall_evt
+                                .trigger()
+                                .context("Failed to trigger stall event")?;
+                            watchdog.stall_evt_ppi_triggered = true;
+                            watchdog.last_guest_time_ms = current_guest_time_ms;
                         }
                     }
                 }
@@ -190,14 +264,28 @@ impl Vmwdt {
         }
     }
 
-    fn start(&mut self) {
+    fn start(&mut self, worker_started_send: Option<SendTube>) -> anyhow::Result<()> {
         let vm_wdts = self.vm_wdts.clone();
         let reset_evt_wrtube = self.reset_evt_wrtube.try_clone().unwrap();
+        let stall_event = self.stall_evt.try_clone().unwrap();
+        let vm_ctrl_tube = self
+            .vm_ctrl_tube
+            .take()
+            .context("missing vm control tube")?;
 
         self.activated = true;
         self.worker_thread = Some(WorkerThread::start("vmwdt worker", |kill_evt| {
-            Vmwdt::vmwdt_worker_thread(vm_wdts, kill_evt, reset_evt_wrtube)
+            Vmwdt::vmwdt_worker_thread(
+                vm_wdts,
+                kill_evt,
+                reset_evt_wrtube,
+                stall_event,
+                vm_ctrl_tube,
+                worker_started_send,
+            )
+            .expect("failed to start vmwdt worker thread")
         }));
+        Ok(())
     }
 
     fn ensure_started(&mut self) {
@@ -205,13 +293,19 @@ impl Vmwdt {
             return;
         }
 
-        self.start();
+        let (worker_started_send, worker_started_recv) =
+            Tube::directional_pair().expect("failed to create vmwdt worker started tubes");
+        self.start(Some(worker_started_send))
+            .expect("failed to start Vmwdt");
+        worker_started_recv
+            .recv::<()>()
+            .expect("failed to receive vmwdt worker started");
     }
 
     #[cfg(any(target_os = "linux", target_os = "android"))]
-    pub fn get_guest_time_ms(ppid: u32, pid: u32) -> Result<i64, SysError> {
+    pub fn get_guest_time_ms(process_id: u32, thread_id: u32) -> Result<i64, SysError> {
         // TODO: @sebastianene check if we can avoid open-read-close on each call
-        let stat_path = format!("/proc/{}/task/{}/stat", ppid, pid);
+        let stat_path = format!("/proc/{}/task/{}/stat", process_id, thread_id);
         let contents = fs::read_to_string(stat_path)?;
 
         let gtime_ticks = contents
@@ -227,7 +321,7 @@ impl Vmwdt {
     }
 
     #[cfg(not(any(target_os = "linux", target_os = "android")))]
-    pub fn get_guest_time_ms(ppid: u32, pid: u32) -> Result<i64, SysError> {
+    pub fn get_guest_time_ms(process_id: u32, thread_id: u32) -> Result<i64, SysError> {
         Ok(0)
     }
 }
@@ -270,39 +364,47 @@ impl BusDevice for Vmwdt {
                 cpu_watchdog.is_enabled = reg_val != 0;
 
                 if reg_val != 0 {
-                    let due = Duration::from_nanos(1);
                     let interval = Duration::from_millis(1000 / cpu_watchdog.timer_freq_hz);
-                    cpu_watchdog.timer.reset(due, Some(interval)).unwrap();
+                    cpu_watchdog.repeating_interval = Some(interval);
+                    cpu_watchdog
+                        .timer
+                        .reset_repeating(interval)
+                        .expect("Failed to reset timer repeating interval");
                 } else {
-                    cpu_watchdog.timer.clear().unwrap();
+                    cpu_watchdog.repeating_interval = None;
+                    cpu_watchdog
+                        .timer
+                        .clear()
+                        .expect("Failed to clear cpu watchdog timer");
                 }
             }
             VMWDT_REG_LOAD_CNT => {
-                let ppid = process::id();
-                let pid = gettid();
-                let guest_time_ms_result = Vmwdt::get_guest_time_ms(ppid, pid as u32);
-                let guest_time_ms = match guest_time_ms_result {
-                    Ok(time) => time,
-                    Err(_e) => return,
+                self.ensure_started();
+                let (process_id, thread_id) = {
+                    let mut wdts_locked = self.vm_wdts.lock();
+                    let cpu_watchdog = &mut wdts_locked[cpu_index];
+                    (cpu_watchdog.process_id, cpu_watchdog.thread_id)
                 };
+                let guest_time_ms = Vmwdt::get_guest_time_ms(process_id, thread_id)
+                    .expect("get_guest_time_ms failed");
 
                 let mut wdts_locked = self.vm_wdts.lock();
                 let cpu_watchdog = &mut wdts_locked[cpu_index];
                 let next_expiration_interval_ms =
                     reg_val as u64 * 1000 / cpu_watchdog.timer_freq_hz;
 
-                cpu_watchdog.pid = pid as u32;
-                cpu_watchdog.ppid = ppid;
                 cpu_watchdog.last_guest_time_ms = guest_time_ms;
+                cpu_watchdog.stall_evt_ppi_triggered = false;
                 cpu_watchdog.next_expiration_interval_ms = next_expiration_interval_ms as i64;
 
                 if cpu_watchdog.is_enabled {
                     if let Err(_e) = cpu_watchdog
                         .timer
-                        .reset(Duration::from_millis(next_expiration_interval_ms), None)
+                        .reset_oneshot(Duration::from_millis(next_expiration_interval_ms))
                     {
                         error!("failed to reset one-shot vcpu time {}", cpu_index);
                     }
+                    cpu_watchdog.repeating_interval = None;
                 }
             }
             VMWDT_REG_CURRENT_CNT => {
@@ -326,23 +428,71 @@ impl BusDevice for Vmwdt {
 impl Suspendable for Vmwdt {
     fn sleep(&mut self) -> anyhow::Result<()> {
         if let Some(worker) = self.worker_thread.take() {
-            worker.stop();
+            self.vm_ctrl_tube = Some(worker.stop());
         }
         Ok(())
     }
 
     fn wake(&mut self) -> anyhow::Result<()> {
         if self.activated {
-            self.start();
+            // We do not pass a tube to notify that the worker thread has started on wake.
+            // At this stage, vm_control is blocked on resuming devices and cannot provide the vcpu
+            // PIDs/TIDs yet.
+            // At the same time, the Vcpus are still frozen, which means no MMIO will get
+            // processed, and write will not get triggered.
+            // The request to get PIDs/TIDs should get processed before any MMIO request occurs.
+            self.start(None)?;
+            let mut vm_wdts = self.vm_wdts.lock();
+            for vmwdt in vm_wdts.iter_mut() {
+                if let Some(interval) = &vmwdt.repeating_interval {
+                    vmwdt
+                        .timer
+                        .reset_repeating(*interval)
+                        .context("failed to write repeating interval")?;
+                } else if vmwdt.is_enabled {
+                    vmwdt
+                        .timer
+                        .reset_oneshot(Duration::from_millis(
+                            vmwdt.next_expiration_interval_ms as u64,
+                        ))
+                        .context("failed to write oneshot interval")?;
+                }
+            }
         }
         Ok(())
     }
+
+    fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+        serde_json::to_value(&VmwdtSnapshot {
+            vm_wdts: self.vm_wdts.clone(),
+            activated: self.activated,
+        })
+        .context("failed to snapshot Vmwdt")
+    }
+
+    fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
+        let deser: VmwdtRestore =
+            serde_json::from_value(data).context("failed to deserialize Vmwdt")?;
+        let mut vm_wdts = self.vm_wdts.lock();
+        for (vmwdt_restore, vmwdt) in deser.vm_wdts.iter().zip(vm_wdts.iter_mut()) {
+            vmwdt.is_enabled = vmwdt_restore.is_enabled;
+            vmwdt.timer_freq_hz = vmwdt_restore.timer_freq_hz;
+            vmwdt.last_guest_time_ms = vmwdt_restore.last_guest_time_ms;
+            vmwdt.next_expiration_interval_ms = vmwdt_restore.next_expiration_interval_ms;
+            vmwdt.repeating_interval = vmwdt_restore.repeating_interval;
+        }
+        self.activated = deser.activated;
+        Ok(())
+    }
 }
 
 #[cfg(test)]
 mod tests {
+    use std::process;
     use std::thread::sleep;
 
+    #[cfg(any(target_os = "linux", target_os = "android"))]
+    use base::gettid;
     use base::poll_assert;
     use base::Tube;
 
@@ -362,7 +512,17 @@ mod tests {
     #[test]
     fn test_watchdog_internal_timer() {
         let (vm_evt_wrtube, _vm_evt_rdtube) = Tube::directional_pair().unwrap();
-        let mut device = Vmwdt::new(TEST_VMWDT_CPU_NO, vm_evt_wrtube).unwrap();
+        let (vm_ctrl_wrtube, vm_ctrl_rdtube) = Tube::pair().unwrap();
+        let irq = IrqEdgeEvent::new().unwrap();
+        #[cfg(any(target_os = "linux", target_os = "android"))]
+        {
+            vm_ctrl_wrtube
+                .send(&VmResponse::VcpuPidTidResponse {
+                    pid_tid_map: BTreeMap::from([(0, (process::id(), gettid() as u32))]),
+                })
+                .unwrap();
+        }
+        let mut device = Vmwdt::new(TEST_VMWDT_CPU_NO, vm_evt_wrtube, irq, vm_ctrl_rdtube).unwrap();
 
         // Configure the watchdog device, 2Hz internal clock
         device.write(
@@ -391,7 +551,17 @@ mod tests {
     #[test]
     fn test_watchdog_expiration() {
         let (vm_evt_wrtube, vm_evt_rdtube) = Tube::directional_pair().unwrap();
-        let mut device = Vmwdt::new(TEST_VMWDT_CPU_NO, vm_evt_wrtube).unwrap();
+        let (vm_ctrl_wrtube, vm_ctrl_rdtube) = Tube::pair().unwrap();
+        let irq = IrqEdgeEvent::new().unwrap();
+        #[cfg(any(target_os = "linux", target_os = "android"))]
+        {
+            vm_ctrl_wrtube
+                .send(&VmResponse::VcpuPidTidResponse {
+                    pid_tid_map: BTreeMap::from([(0, (process::id(), gettid() as u32))]),
+                })
+                .unwrap();
+        }
+        let mut device = Vmwdt::new(TEST_VMWDT_CPU_NO, vm_evt_wrtube, irq, vm_ctrl_rdtube).unwrap();
 
         // Configure the watchdog device, 2Hz internal clock
         device.write(
@@ -404,6 +574,16 @@ mod tests {
         // the function get_guest_time() returns 0
         device.vm_wdts.lock()[0].last_guest_time_ms = -100;
 
+        // Check that the interrupt has raised
+        poll_assert!(10, || {
+            sleep(Duration::from_millis(50));
+            let vmwdt_locked = device.vm_wdts.lock();
+            vmwdt_locked[0].stall_evt_ppi_triggered
+        });
+
+        // Simulate that the time has passed since the last expiration
+        device.vm_wdts.lock()[0].last_guest_time_ms = -100;
+
         // Poll multiple times as we don't get a signal when the watchdog thread has run.
         poll_assert!(10, || {
             sleep(Duration::from_millis(50));
diff --git a/devices/tests/irqchip/userspace.rs b/devices/tests/irqchip/userspace.rs
index 7f521f691..440d8f661 100644
--- a/devices/tests/irqchip/userspace.rs
+++ b/devices/tests/irqchip/userspace.rs
@@ -39,7 +39,6 @@ use hypervisor::DebugRegs;
 use hypervisor::DeliveryMode;
 use hypervisor::DestinationMode;
 use hypervisor::Fpu;
-use hypervisor::HypervHypercall;
 use hypervisor::IoParams;
 use hypervisor::IoapicRedirectionTableEntry;
 use hypervisor::IrqRoute;
@@ -626,12 +625,12 @@ struct FakeVcpu {
     id: usize,
     requested: Arc<Mutex<bool>>,
     ready: Arc<Mutex<bool>>,
-    injected: Arc<Mutex<Option<u32>>>,
+    injected: Arc<Mutex<Option<u8>>>,
 }
 
 impl FakeVcpu {
     /// Returns and clears the last interrupt set by `interrupt`.
-    fn clear_injected(&self) -> Option<u32> {
+    fn clear_injected(&self) -> Option<u8> {
         self.injected.lock().take()
     }
 
@@ -675,21 +674,15 @@ impl Vcpu for FakeVcpu {
         unimplemented!()
     }
 
-    fn handle_mmio(&self, _handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
+    fn handle_mmio(
+        &self,
+        _handle_fn: &mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>,
+    ) -> Result<()> {
         unimplemented!()
     }
     fn handle_io(&self, _handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
         unimplemented!()
     }
-    fn handle_hyperv_hypercall(&self, _func: &mut dyn FnMut(HypervHypercall) -> u64) -> Result<()> {
-        unimplemented!()
-    }
-    fn handle_rdmsr(&self, _data: u64) -> Result<()> {
-        unimplemented!()
-    }
-    fn handle_wrmsr(&self) {
-        unimplemented!()
-    }
     fn on_suspend(&self) -> Result<()> {
         unimplemented!()
     }
@@ -707,7 +700,7 @@ impl VcpuX86_64 for FakeVcpu {
         *self.ready.lock()
     }
 
-    fn interrupt(&self, irq: u32) -> Result<()> {
+    fn interrupt(&self, irq: u8) -> Result<()> {
         *self.injected.lock() = Some(irq);
         Ok(())
     }
@@ -773,9 +766,6 @@ impl VcpuX86_64 for FakeVcpu {
     fn handle_cpuid(&mut self, _entry: &CpuIdEntry) -> Result<()> {
         unimplemented!()
     }
-    fn get_hyperv_cpuid(&self) -> Result<CpuId> {
-        unimplemented!()
-    }
     fn set_guest_debug(&self, _addrs: &[GuestAddress], _enable_singlestep: bool) -> Result<()> {
         unimplemented!()
     }
diff --git a/devices/tests/irqchip/whpx.rs b/devices/tests/irqchip/whpx.rs
index 6a7f3aac4..a28e65fd0 100644
--- a/devices/tests/irqchip/whpx.rs
+++ b/devices/tests/irqchip/whpx.rs
@@ -7,6 +7,7 @@
 use base::EventWaitResult;
 use base::Tube;
 use devices::Bus;
+use devices::BusType;
 use devices::CrosvmDeviceId;
 use devices::DeviceId;
 use devices::IrqChip;
@@ -195,8 +196,8 @@ fn finalize_devices() {
     }
     let mut chip = get_chip(1);
 
-    let mmio_bus = Bus::new();
-    let io_bus = Bus::new();
+    let mmio_bus = Bus::new(BusType::Mmio);
+    let io_bus = Bus::new(BusType::Io);
     let mut resources = SystemAllocator::new(
         SystemAllocatorConfig {
             io: Some(AddressRange {
@@ -318,8 +319,8 @@ fn broadcast_eoi() {
     }
     let mut chip = get_chip(1);
 
-    let mmio_bus = Bus::new();
-    let io_bus = Bus::new();
+    let mmio_bus = Bus::new(BusType::Mmio);
+    let io_bus = Bus::new(BusType::Io);
     let mut resources = SystemAllocator::new(
         SystemAllocatorConfig {
             io: Some(AddressRange {
diff --git a/disk/Android.bp b/disk/Android.bp
index 4e4b37f6d..a61efa253 100644
--- a/disk/Android.bp
+++ b/disk/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "disk",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/disk.rs"],
+    crate_root: "src/disk.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -62,7 +62,7 @@ rust_library {
     crate_name: "disk",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/disk.rs"],
+    crate_root: "src/disk.rs",
     edition: "2021",
     features: [
         "android-sparse",
@@ -81,7 +81,6 @@ rust_library {
         "libprotos", // Added manually
         "libserde",
         "libsync_rust",
-        "libtempfile",
         "libthiserror",
         "libuuid", // Added manually
         "libvm_memory",
@@ -92,7 +91,7 @@ rust_library {
         "libremain",
     ],
     visibility: [
-        "//packages/modules/Virtualization/virtualizationmanager",
+        "//packages/modules/Virtualization/android/virtmgr",
         "//vendor:__subpackages__",
     ],
 }
diff --git a/disk/Cargo.toml b/disk/Cargo.toml
index 28fc13dbf..39f4b47eb 100644
--- a/disk/Cargo.toml
+++ b/disk/Cargo.toml
@@ -13,24 +13,29 @@ composite-disk = ["crc32fast", "protos", "protobuf", "uuid"]
 qcow = []
 
 [dependencies]
-async-trait = "*"
+async-trait = "0.1.36"
 base = { path = "../base" }
 cfg-if = "1.0.0"
 crc32fast = { version = "1.2.1", optional = true }
 cros_async = { path = "../cros_async" }
 data_model = { path = "../common/data_model" }
-libc = "*"
+libc = "0.2"
 protobuf = { version = "3.2", optional = true }
 protos = { path = "../protos", features = ["composite-disk"], optional = true }
-remain = "*"
+remain = "0.2"
 serde = { version = "1", features = [ "derive" ] }
 sync = { path = "../common/sync" }
-thiserror = "*"
-tempfile = "3"
+thiserror = "1"
 uuid = { version = "1", features = ["v4"], optional = true }
 vm_memory = { path = "../vm_memory" }
 zerocopy = { version = "0.7", features = ["derive"] }
 
+[target.'cfg(windows)'.dependencies]
+winapi = "0.3"
+
 [dependencies.futures]
-version = "*"
+version = "0.3"
 default-features = false
+
+[dev-dependencies]
+tempfile = "3"
diff --git a/disk/patches/Android.bp.patch b/disk/patches/Android.bp.patch
index aa443eb4f..736a238c6 100644
--- a/disk/patches/Android.bp.patch
+++ b/disk/patches/Android.bp.patch
@@ -1,8 +1,8 @@
 diff --git a/disk/Android.bp b/disk/Android.bp
-index ab4c44322..75dbbb9d5 100644
+index ef8395e82..088ac60b8 100644
 --- a/disk/Android.bp
 +++ b/disk/Android.bp
-@@ -26,19 +26,24 @@ rust_test {
+@@ -28,19 +28,24 @@ rust_test {
      edition: "2021",
      features: [
          "android-sparse",
@@ -27,7 +27,7 @@ index ab4c44322..75dbbb9d5 100644
          "libvm_memory",
          "libzerocopy",
      ],
-@@ -59,19 +64,24 @@ rust_library {
+@@ -61,18 +66,23 @@ rust_library {
      edition: "2021",
      features: [
          "android-sparse",
@@ -46,7 +46,6 @@ index ab4c44322..75dbbb9d5 100644
 +        "libprotos", // Added manually
          "libserde",
          "libsync_rust",
-         "libtempfile",
          "libthiserror",
 +        "libuuid", // Added manually
          "libvm_memory",
diff --git a/disk/src/android_sparse.rs b/disk/src/android_sparse.rs
index 204b9fa1e..5a1d3dc39 100644
--- a/disk/src/android_sparse.rs
+++ b/disk/src/android_sparse.rs
@@ -256,7 +256,7 @@ impl AsRawDescriptor for AndroidSparse {
 
 // Performs reads up to the chunk boundary.
 impl FileReadWriteAtVolatile for AndroidSparse {
-    fn read_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
+    fn read_at_volatile(&self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
         let found_chunk = self.chunks.range(..=offset).next_back();
         let (
             chunk_start,
@@ -301,7 +301,7 @@ impl FileReadWriteAtVolatile for AndroidSparse {
             }
         }
     }
-    fn write_at_volatile(&mut self, _slice: VolatileSlice, _offset: u64) -> io::Result<usize> {
+    fn write_at_volatile(&self, _slice: VolatileSlice, _offset: u64) -> io::Result<usize> {
         Err(io::Error::new(
             ErrorKind::PermissionDenied,
             "unsupported operation",
@@ -345,7 +345,7 @@ impl FileSetLen for AsyncAndroidSparse {
 }
 
 impl FileAllocate for AsyncAndroidSparse {
-    fn allocate(&mut self, _offset: u64, _length: u64) -> io::Result<()> {
+    fn allocate(&self, _offset: u64, _length: u64) -> io::Result<()> {
         Err(io::Error::new(
             ErrorKind::PermissionDenied,
             "unsupported operation",
@@ -355,14 +355,6 @@ impl FileAllocate for AsyncAndroidSparse {
 
 #[async_trait(?Send)]
 impl AsyncDisk for AsyncAndroidSparse {
-    fn into_inner(self: Box<Self>) -> Box<dyn DiskFile> {
-        Box::new(AndroidSparse {
-            file: self.inner.into_source(),
-            total_size: self.total_size,
-            chunks: self.chunks,
-        })
-    }
-
     async fn flush(&self) -> crate::Result<()> {
         // android sparse is read-only, nothing to flush.
         Ok(())
@@ -562,7 +554,7 @@ mod tests {
             chunk: Chunk::DontCare,
             expanded_size: 100,
         }];
-        let mut image = test_image(chunks);
+        let image = test_image(chunks);
         let mut input_memory = [55u8; 100];
         image
             .read_exact_at_volatile(VolatileSlice::new(&mut input_memory[..]), 0)
@@ -577,7 +569,7 @@ mod tests {
             chunk: Chunk::Fill([10, 20, 10, 20]),
             expanded_size: 8,
         }];
-        let mut image = test_image(chunks);
+        let image = test_image(chunks);
         let mut input_memory = [55u8; 8];
         image
             .read_exact_at_volatile(VolatileSlice::new(&mut input_memory[..]), 0)
@@ -592,7 +584,7 @@ mod tests {
             chunk: Chunk::Fill([10, 20, 30, 40]),
             expanded_size: 8,
         }];
-        let mut image = test_image(chunks);
+        let image = test_image(chunks);
         let mut input_memory = [55u8; 6];
         image
             .read_exact_at_volatile(VolatileSlice::new(&mut input_memory[..]), 1)
@@ -613,7 +605,7 @@ mod tests {
                 expanded_size: 100,
             },
         ];
-        let mut image = test_image(chunks);
+        let image = test_image(chunks);
         let mut input_memory = [55u8; 7];
         image
             .read_exact_at_volatile(VolatileSlice::new(&mut input_memory[..]), 39)
@@ -650,7 +642,7 @@ mod tests {
                 expanded_size: 4,
             },
         ];
-        let mut image = test_image(chunks);
+        let image = test_image(chunks);
         let mut input_memory = [55u8; 8];
         image
             .read_exact_at_volatile(VolatileSlice::new(&mut input_memory[..]), 0)
@@ -917,25 +909,4 @@ mod tests {
         })
         .unwrap();
     }
-
-    // Convert to sync and back again. There was once a bug where `into_inner` converted the
-    // AndroidSparse into a raw file.
-    //
-    // Skip on windows because `into_source` isn't supported.
-    #[cfg(not(windows))]
-    #[test]
-    fn async_roundtrip_read_dontcare() {
-        let ex = Executor::new().unwrap();
-        ex.run_until(async {
-            let chunks = vec![ChunkWithSize {
-                chunk: Chunk::DontCare,
-                expanded_size: 100,
-            }];
-            let image = test_async_image(chunks, &ex).unwrap();
-            let image = image.into_inner().to_async_disk(&ex).unwrap();
-            let buf = read_exact_at(&*image, 0, 100).await;
-            assert!(buf.iter().all(|x| *x == 0));
-        })
-        .unwrap();
-    }
 }
diff --git a/disk/src/asynchronous.rs b/disk/src/asynchronous.rs
index 62471cb0c..017e8850c 100644
--- a/disk/src/asynchronous.rs
+++ b/disk/src/asynchronous.rs
@@ -13,13 +13,12 @@ use base::AsRawDescriptors;
 use base::FileAllocate;
 use base::FileSetLen;
 use base::FileSync;
-use base::PunchHoleMut;
+use base::PunchHole;
 use base::RawDescriptor;
 use base::WriteZeroesAt;
 use cros_async::BackingMemory;
 use cros_async::BlockingPool;
 use cros_async::Executor;
-use sync::Mutex;
 
 use crate::AsyncDisk;
 use crate::DiskFile;
@@ -33,7 +32,7 @@ use crate::Result;
 /// formats should be migrated to support async instead (b/219595052).
 pub struct AsyncDiskFileWrapper<T: DiskFile + Send> {
     blocking_pool: BlockingPool,
-    inner: Arc<Mutex<T>>,
+    inner: Arc<T>,
 }
 
 impl<T: DiskFile + Send> AsyncDiskFileWrapper<T> {
@@ -41,38 +40,38 @@ impl<T: DiskFile + Send> AsyncDiskFileWrapper<T> {
     pub fn new(disk_file: T, _ex: &Executor) -> Self {
         Self {
             blocking_pool: BlockingPool::new(1, Duration::from_secs(10)),
-            inner: Arc::new(Mutex::new(disk_file)),
+            inner: Arc::new(disk_file),
         }
     }
 }
 
 impl<T: DiskFile + Send> DiskGetLen for AsyncDiskFileWrapper<T> {
     fn get_len(&self) -> io::Result<u64> {
-        self.inner.lock().get_len()
+        self.inner.get_len()
     }
 }
 
 impl<T: DiskFile + Send + FileSetLen> FileSetLen for AsyncDiskFileWrapper<T> {
     fn set_len(&self, len: u64) -> io::Result<()> {
-        self.inner.lock().set_len(len)
+        self.inner.set_len(len)
     }
 }
 
 impl<T: DiskFile + Send + FileAllocate> FileAllocate for AsyncDiskFileWrapper<T> {
-    fn allocate(&mut self, offset: u64, len: u64) -> io::Result<()> {
-        self.inner.lock().allocate(offset, len)
+    fn allocate(&self, offset: u64, len: u64) -> io::Result<()> {
+        self.inner.allocate(offset, len)
     }
 }
 
 impl<T: DiskFile + Send> AsRawDescriptors for AsyncDiskFileWrapper<T> {
     fn as_raw_descriptors(&self) -> Vec<RawDescriptor> {
-        self.inner.lock().as_raw_descriptors()
+        self.inner.as_raw_descriptors()
     }
 }
 
 pub trait DiskFlush {
     /// Flush intermediary buffers and/or dirty state to file. fsync not required.
-    fn flush(&mut self) -> io::Result<()>;
+    fn flush(&self) -> io::Result<()>;
 }
 
 #[async_trait(?Send)]
@@ -81,48 +80,32 @@ impl<
             + DiskFile
             + DiskFlush
             + Send
+            + Sync
             + FileAllocate
             + FileSetLen
             + FileSync
-            + PunchHoleMut
+            + PunchHole
             + WriteZeroesAt,
     > AsyncDisk for AsyncDiskFileWrapper<T>
 {
-    fn into_inner(self: Box<Self>) -> Box<dyn DiskFile> {
-        self.blocking_pool
-            .shutdown(None)
-            .expect("AsyncDiskFile pool shutdown failed");
-        let mtx: Mutex<T> = Arc::try_unwrap(self.inner).expect("AsyncDiskFile arc unwrap failed");
-        Box::new(mtx.into_inner())
-    }
-
     async fn flush(&self) -> Result<()> {
         let inner_clone = self.inner.clone();
         self.blocking_pool
-            .spawn(move || {
-                let mut disk_file = inner_clone.lock();
-                disk_file.flush().map_err(Error::IoFlush)
-            })
+            .spawn(move || inner_clone.flush().map_err(Error::IoFlush))
             .await
     }
 
     async fn fsync(&self) -> Result<()> {
         let inner_clone = self.inner.clone();
         self.blocking_pool
-            .spawn(move || {
-                let mut disk_file = inner_clone.lock();
-                disk_file.fsync().map_err(Error::IoFsync)
-            })
+            .spawn(move || inner_clone.fsync().map_err(Error::IoFsync))
             .await
     }
 
     async fn fdatasync(&self) -> Result<()> {
         let inner_clone = self.inner.clone();
         self.blocking_pool
-            .spawn(move || {
-                let mut disk_file = inner_clone.lock();
-                disk_file.fdatasync().map_err(Error::IoFdatasync)
-            })
+            .spawn(move || inner_clone.fdatasync().map_err(Error::IoFdatasync))
             .await
     }
 
@@ -136,11 +119,10 @@ impl<
         let mem_offsets: Vec<cros_async::MemRegion> = mem_offsets.collect();
         self.blocking_pool
             .spawn(move || {
-                let mut disk_file = inner_clone.lock();
                 let mut size = 0;
                 for region in mem_offsets {
                     let mem_slice = mem.get_volatile_slice(region).unwrap();
-                    let bytes_read = disk_file
+                    let bytes_read = inner_clone
                         .read_at_volatile(mem_slice, file_offset)
                         .map_err(Error::ReadingData)?;
                     size += bytes_read;
@@ -164,11 +146,10 @@ impl<
         let mem_offsets: Vec<cros_async::MemRegion> = mem_offsets.collect();
         self.blocking_pool
             .spawn(move || {
-                let mut disk_file = inner_clone.lock();
                 let mut size = 0;
                 for region in mem_offsets {
                     let mem_slice = mem.get_volatile_slice(region).unwrap();
-                    let bytes_written = disk_file
+                    let bytes_written = inner_clone
                         .write_at_volatile(mem_slice, file_offset)
                         .map_err(Error::ReadingData)?;
                     size += bytes_written;
@@ -186,9 +167,8 @@ impl<
         let inner_clone = self.inner.clone();
         self.blocking_pool
             .spawn(move || {
-                let mut disk_file = inner_clone.lock();
-                disk_file
-                    .punch_hole_mut(file_offset, length)
+                inner_clone
+                    .punch_hole(file_offset, length)
                     .map_err(Error::IoPunchHole)
             })
             .await
@@ -198,8 +178,7 @@ impl<
         let inner_clone = self.inner.clone();
         self.blocking_pool
             .spawn(move || {
-                let mut disk_file = inner_clone.lock();
-                disk_file
+                inner_clone
                     .write_zeroes_all_at(file_offset, length as usize)
                     .map_err(Error::WriteZeroes)
             })
diff --git a/disk/src/composite.rs b/disk/src/composite.rs
index 8a4c033c7..ac64d8211 100644
--- a/disk/src/composite.rs
+++ b/disk/src/composite.rs
@@ -22,7 +22,6 @@ use std::sync::atomic::Ordering;
 use std::sync::Arc;
 
 use async_trait::async_trait;
-use base::open_file_or_duplicate;
 use base::AsRawDescriptors;
 use base::FileAllocate;
 use base::FileReadWriteAtVolatile;
@@ -42,7 +41,6 @@ use remain::sorted;
 use thiserror::Error;
 use uuid::Uuid;
 
-use crate::create_disk_file;
 use crate::gpt;
 use crate::gpt::write_gpt_header;
 use crate::gpt::write_protective_mbr;
@@ -53,8 +51,10 @@ use crate::gpt::GPT_HEADER_SIZE;
 use crate::gpt::GPT_NUM_PARTITIONS;
 use crate::gpt::GPT_PARTITION_ENTRY_SIZE;
 use crate::gpt::SECTOR_SIZE;
+use crate::open_disk_file;
 use crate::AsyncDisk;
 use crate::DiskFile;
+use crate::DiskFileParams;
 use crate::DiskGetLen;
 use crate::ImageType;
 use crate::ToAsyncDisk;
@@ -124,7 +124,7 @@ struct ComponentDiskPart {
     file: Box<dyn DiskFile>,
     offset: u64,
     length: u64,
-    needs_fsync: bool,
+    needs_fsync: AtomicBool,
 }
 
 impl ComponentDiskPart {
@@ -140,6 +140,8 @@ impl ComponentDiskPart {
 #[derive(Debug)]
 pub struct CompositeDiskFile {
     component_disks: Vec<ComponentDiskPart>,
+    // We keep the root composite file open so that the file lock is not dropped.
+    _disk_spec_file: File,
 }
 
 // TODO(b/271381851): implement `try_clone`. It allows virtio-blk to run multiple workers.
@@ -168,7 +170,7 @@ const COMPOSITE_DISK_VERSION: u64 = 2;
 pub const CDISK_MAGIC: &str = "composite_disk\x1d";
 
 impl CompositeDiskFile {
-    fn new(mut disks: Vec<ComponentDiskPart>) -> Result<CompositeDiskFile> {
+    fn new(mut disks: Vec<ComponentDiskPart>, disk_spec_file: File) -> Result<CompositeDiskFile> {
         disks.sort_by(|d1, d2| d1.offset.cmp(&d2.offset));
         for s in disks.windows(2) {
             if s[0].offset == s[1].offset {
@@ -180,18 +182,14 @@ impl CompositeDiskFile {
         }
         Ok(CompositeDiskFile {
             component_disks: disks,
+            _disk_spec_file: disk_spec_file,
         })
     }
 
     /// Set up a composite disk by reading the specification from a file. The file must consist of
     /// the CDISK_MAGIC string followed by one binary instance of the CompositeDisk protocol
     /// buffer. Returns an error if it could not read the file or if the specification was invalid.
-    pub fn from_file(
-        mut file: File,
-        is_sparse_file: bool,
-        max_nesting_depth: u32,
-        image_path: &Path,
-    ) -> Result<CompositeDiskFile> {
+    pub fn from_file(mut file: File, params: DiskFileParams) -> Result<CompositeDiskFile> {
         file.seek(SeekFrom::Start(0))
             .map_err(Error::ReadSpecificationError)?;
         let mut magic_space = [0u8; CDISK_MAGIC.len()];
@@ -209,20 +207,15 @@ impl CompositeDiskFile {
             .component_disks
             .iter()
             .map(|disk| {
-                let writable = disk.read_write_capability
-                    == cdisk_spec::ReadWriteCapability::READ_WRITE.into();
+                let writable = !params.is_read_only
+                    && disk.read_write_capability
+                        == cdisk_spec::ReadWriteCapability::READ_WRITE.into();
                 let component_path = PathBuf::from(&disk.file_path);
                 let path = if component_path.is_relative() || proto.version > 1 {
-                    image_path.parent().unwrap().join(component_path)
+                    params.path.parent().unwrap().join(component_path)
                 } else {
                     component_path
                 };
-                let comp_file = open_file_or_duplicate(
-                    &path,
-                    OpenOptions::new().read(true).write(writable), /* TODO(b/190435784): add
-                                                                    * support for O_DIRECT. */
-                )
-                .map_err(|e| Error::OpenFile(e.into(), disk.file_path.to_string()))?;
 
                 // Note that a read-only parts of a composite disk should NOT be marked sparse,
                 // as the action of marking them sparse is a write. This may seem a little hacky,
@@ -231,16 +224,20 @@ impl CompositeDiskFile {
                 //         part (the proto does not have fields for it).
                 //    (b)  this override of sorts always matches the correct user intent.
                 Ok(ComponentDiskPart {
-                    file: create_disk_file(
-                        comp_file,
-                        is_sparse_file && writable,
-                        max_nesting_depth,
-                        &path,
-                    )
+                    file: open_disk_file(DiskFileParams {
+                        path: path.to_owned(),
+                        is_read_only: !writable,
+                        is_sparse_file: params.is_sparse_file && writable,
+                        // TODO: Should pass `params.is_overlapped` through here. Needs testing.
+                        is_overlapped: false,
+                        is_direct: params.is_direct,
+                        lock: params.lock,
+                        depth: params.depth + 1,
+                    })
                     .map_err(|e| Error::DiskError(Box::new(e)))?,
                     offset: disk.offset,
                     length: 0, // Assigned later
-                    needs_fsync: false,
+                    needs_fsync: AtomicBool::new(false),
                 })
             })
             .collect::<Result<Vec<ComponentDiskPart>>>()?;
@@ -272,7 +269,7 @@ impl CompositeDiskFile {
             return Err(Error::InvalidSpecification(text));
         }
 
-        CompositeDiskFile::new(disks)
+        CompositeDiskFile::new(disks, file)
     }
 
     fn length(&self) -> u64 {
@@ -283,9 +280,9 @@ impl CompositeDiskFile {
         }
     }
 
-    fn disk_at_offset(&mut self, offset: u64) -> io::Result<&mut ComponentDiskPart> {
+    fn disk_at_offset(&self, offset: u64) -> io::Result<&ComponentDiskPart> {
         self.component_disks
-            .iter_mut()
+            .iter()
             .find(|disk| disk.range().contains(&offset))
             .ok_or(io::Error::new(
                 ErrorKind::InvalidData,
@@ -316,7 +313,7 @@ impl FileSetLen for CompositeDiskFile {
 // If one of the component disks does a partial read or write, that also gets passed
 // transparently to the parent.
 impl FileReadWriteAtVolatile for CompositeDiskFile {
-    fn read_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
+    fn read_at_volatile(&self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
         let cursor_location = offset;
         let disk = self.disk_at_offset(cursor_location)?;
         let subslice = if cursor_location + slice.size() as u64 > disk.offset + disk.length {
@@ -330,7 +327,7 @@ impl FileReadWriteAtVolatile for CompositeDiskFile {
         disk.file
             .read_at_volatile(subslice, cursor_location - disk.offset)
     }
-    fn write_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
+    fn write_at_volatile(&self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
         let cursor_location = offset;
         let disk = self.disk_at_offset(cursor_location)?;
         let subslice = if cursor_location + slice.size() as u64 > disk.offset + disk.length {
@@ -345,7 +342,7 @@ impl FileReadWriteAtVolatile for CompositeDiskFile {
         let bytes = disk
             .file
             .write_at_volatile(subslice, cursor_location - disk.offset)?;
-        disk.needs_fsync = true;
+        disk.needs_fsync.store(true, Ordering::SeqCst);
         Ok(bytes)
     }
 }
@@ -383,11 +380,11 @@ impl FileSetLen for AsyncCompositeDiskFile {
 }
 
 impl FileAllocate for AsyncCompositeDiskFile {
-    fn allocate(&mut self, offset: u64, length: u64) -> io::Result<()> {
+    fn allocate(&self, offset: u64, length: u64) -> io::Result<()> {
         let range = offset..(offset + length);
         let disks = self
             .component_disks
-            .iter_mut()
+            .iter()
             .filter(|disk| ranges_overlap(&disk.range(), &range));
         for disk in disks {
             if let Some(intersection) = range_intersection(&range, &disk.range()) {
@@ -413,7 +410,7 @@ impl ToAsyncDisk for CompositeDiskFile {
                         file: disk.file.to_async_disk(ex)?,
                         offset: disk.offset,
                         length: disk.length,
-                        needs_fsync: AtomicBool::new(disk.needs_fsync),
+                        needs_fsync: disk.needs_fsync,
                     })
                 })
                 .collect::<crate::Result<Vec<_>>>()?,
@@ -460,21 +457,6 @@ impl AsyncCompositeDiskFile {
 
 #[async_trait(?Send)]
 impl AsyncDisk for AsyncCompositeDiskFile {
-    fn into_inner(self: Box<Self>) -> Box<dyn DiskFile> {
-        Box::new(CompositeDiskFile {
-            component_disks: self
-                .component_disks
-                .into_iter()
-                .map(|disk| ComponentDiskPart {
-                    file: disk.file.into_inner(),
-                    offset: disk.offset,
-                    length: disk.length,
-                    needs_fsync: disk.needs_fsync.into_inner(),
-                })
-                .collect(),
-        })
-    }
-
     async fn flush(&self) -> crate::Result<()> {
         futures::future::try_join_all(self.component_disks.iter().map(|c| c.file.flush())).await?;
         Ok(())
@@ -582,6 +564,7 @@ pub struct PartitionInfo {
     pub partition_type: ImagePartitionType,
     pub writable: bool,
     pub size: u64,
+    pub part_guid: Option<Uuid>,
 }
 
 /// Round `val` up to the next multiple of 2**`align_log`.
@@ -684,7 +667,7 @@ fn create_gpt_entry(partition: &PartitionInfo, offset: u64) -> GptPartitionEntry
 
     GptPartitionEntry {
         partition_type_guid: partition.partition_type.guid(),
-        unique_partition_guid: Uuid::new_v4(),
+        unique_partition_guid: partition.part_guid.unwrap_or(Uuid::new_v4()),
         first_lba: offset / SECTOR_SIZE,
         last_lba: (offset + partition.aligned_size()) / SECTOR_SIZE - 1,
         attributes: 0,
@@ -857,6 +840,10 @@ mod tests {
 
     use super::*;
 
+    fn new_from_components(disks: Vec<ComponentDiskPart>) -> Result<CompositeDiskFile> {
+        CompositeDiskFile::new(disks, tempfile().unwrap())
+    }
+
     #[test]
     fn block_duplicate_offset_disks() {
         let file1 = tempfile().unwrap();
@@ -865,15 +852,15 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        assert!(CompositeDiskFile::new(vec![disk_part1, disk_part2]).is_err());
+        assert!(new_from_components(vec![disk_part1, disk_part2]).is_err());
     }
 
     #[test]
@@ -884,15 +871,15 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![disk_part1, disk_part2]).unwrap();
+        let composite = new_from_components(vec![disk_part1, disk_part2]).unwrap();
         let len = composite.get_len().unwrap();
         assert_eq!(len, 200);
     }
@@ -905,15 +892,15 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![disk_part1, disk_part2]).unwrap();
+        let composite = new_from_components(vec![disk_part1, disk_part2]).unwrap();
 
         let ex = Executor::new().unwrap();
         let composite = Box::new(composite).to_async_disk(&ex).unwrap();
@@ -928,9 +915,9 @@ mod tests {
             file: Box::new(file),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let mut composite = CompositeDiskFile::new(vec![disk_part]).unwrap();
+        let composite = new_from_components(vec![disk_part]).unwrap();
         let mut input_memory = [55u8; 5];
         let input_volatile_memory = VolatileSlice::new(&mut input_memory[..]);
         composite
@@ -951,9 +938,9 @@ mod tests {
             file: Box::new(file),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![disk_part]).unwrap();
+        let composite = new_from_components(vec![disk_part]).unwrap();
         let ex = Executor::new().unwrap();
         ex.run_until(async {
             let composite = Box::new(composite).to_async_disk(&ex).unwrap();
@@ -990,21 +977,21 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part3 = ComponentDiskPart {
             file: Box::new(file3),
             offset: 200,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![disk_part1, disk_part2, disk_part3]).unwrap();
+        let composite = new_from_components(vec![disk_part1, disk_part2, disk_part3]).unwrap();
         let mut out_descriptors = composite.as_raw_descriptors();
         out_descriptors.sort_unstable();
         assert_eq!(in_descriptors, out_descriptors);
@@ -1019,22 +1006,21 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part3 = ComponentDiskPart {
             file: Box::new(file3),
             offset: 200,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let mut composite =
-            CompositeDiskFile::new(vec![disk_part1, disk_part2, disk_part3]).unwrap();
+        let composite = new_from_components(vec![disk_part1, disk_part2, disk_part3]).unwrap();
         let mut input_memory = [55u8; 200];
         let input_volatile_memory = VolatileSlice::new(&mut input_memory[..]);
         composite
@@ -1057,21 +1043,21 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part3 = ComponentDiskPart {
             file: Box::new(file3),
             offset: 200,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![disk_part1, disk_part2, disk_part3]).unwrap();
+        let composite = new_from_components(vec![disk_part1, disk_part2, disk_part3]).unwrap();
         let ex = Executor::new().unwrap();
         ex.run_until(async {
             let composite = Box::new(composite).to_async_disk(&ex).unwrap();
@@ -1118,21 +1104,21 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part3 = ComponentDiskPart {
             file: Box::new(file3),
             offset: 200,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![disk_part1, disk_part2, disk_part3]).unwrap();
+        let composite = new_from_components(vec![disk_part1, disk_part2, disk_part3]).unwrap();
         let ex = Executor::new().unwrap();
         ex.run_until(async {
             let composite = Box::new(composite).to_async_disk(&ex).unwrap();
@@ -1198,21 +1184,21 @@ mod tests {
             file: Box::new(file1),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part2 = ComponentDiskPart {
             file: Box::new(file2),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let disk_part3 = ComponentDiskPart {
             file: Box::new(file3),
             offset: 200,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![disk_part1, disk_part2, disk_part3]).unwrap();
+        let composite = new_from_components(vec![disk_part1, disk_part2, disk_part3]).unwrap();
         let ex = Executor::new().unwrap();
         ex.run_until(async {
             let composite = Box::new(composite).to_async_disk(&ex).unwrap();
@@ -1287,15 +1273,15 @@ mod tests {
             file: Box::new(rw_file),
             offset: 0,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
         let ro_part = ComponentDiskPart {
             file: Box::new(ro_file),
             offset: 100,
             length: 100,
-            needs_fsync: false,
+            needs_fsync: AtomicBool::new(false),
         };
-        let composite = CompositeDiskFile::new(vec![rw_part, ro_part]).unwrap();
+        let composite = new_from_components(vec![rw_part, ro_part]).unwrap();
         let ex = Executor::new().unwrap();
         ex.run_until(async {
             let composite = Box::new(composite).to_async_disk(&ex).unwrap();
@@ -1402,6 +1388,7 @@ mod tests {
                     partition_type: ImagePartitionType::LinuxFilesystem,
                     writable: false,
                     size: 0,
+                    part_guid: None,
                 },
                 PartitionInfo {
                     label: "partition2".to_string(),
@@ -1409,6 +1396,7 @@ mod tests {
                     partition_type: ImagePartitionType::LinuxFilesystem,
                     writable: true,
                     size: 0,
+                    part_guid: Some(Uuid::from_u128(0x4049C8DC_6C2B_C740_A95A_BDAA629D4378)),
                 },
             ],
             Path::new("/zero_filler.img"),
@@ -1436,6 +1424,7 @@ mod tests {
                     partition_type: ImagePartitionType::LinuxFilesystem,
                     writable: false,
                     size: 0,
+                    part_guid: None,
                 },
                 PartitionInfo {
                     label: "label".to_string(),
@@ -1443,6 +1432,7 @@ mod tests {
                     partition_type: ImagePartitionType::LinuxFilesystem,
                     writable: true,
                     size: 0,
+                    part_guid: None,
                 },
             ],
             Path::new("/zero_filler.img"),
diff --git a/disk/src/disk.rs b/disk/src/disk.rs
index ba10a4729..324dcdc2d 100644
--- a/disk/src/disk.rs
+++ b/disk/src/disk.rs
@@ -10,11 +10,10 @@ use std::fs::File;
 use std::io;
 use std::io::Seek;
 use std::io::SeekFrom;
-use std::path::Path;
+use std::path::PathBuf;
 use std::sync::Arc;
 
 use async_trait::async_trait;
-use base::get_filesystem_type;
 use base::info;
 use base::AsRawDescriptors;
 use base::FileAllocate;
@@ -67,7 +66,7 @@ use android_sparse::SPARSE_HEADER_MAGIC;
 use sys::read_from_disk;
 
 /// Nesting depth limit for disk formats that can open other disk files.
-pub const MAX_NESTING_DEPTH: u32 = 10;
+const MAX_NESTING_DEPTH: u32 = 10;
 
 #[derive(ThisError, Debug)]
 pub enum Error {
@@ -83,10 +82,14 @@ pub enum Error {
     CreateCompositeDisk(composite::Error),
     #[error("failure creating single file disk: {0}")]
     CreateSingleFileDisk(cros_async::AsyncError),
+    #[error("failed to set O_DIRECT on disk image: {0}")]
+    DirectFailed(base::Error),
     #[error("failure with fdatasync: {0}")]
     Fdatasync(cros_async::AsyncError),
     #[error("failure with fsync: {0}")]
     Fsync(cros_async::AsyncError),
+    #[error("failed to lock file: {0}")]
+    LockFileFailure(base::Error),
     #[error("failure with fdatasync: {0}")]
     IoFdatasync(io::Error),
     #[error("failure with flush: {0}")]
@@ -99,6 +102,8 @@ pub enum Error {
     HostFsType(base::Error),
     #[error("maximum disk nesting depth exceeded")]
     MaxNestingDepthExceeded,
+    #[error("failed to open disk file \"{0}\": {1}")]
+    OpenFile(String, base::Error),
     #[error("failure to punch hole: {0}")]
     PunchHole(cros_async::AsyncError),
     #[error("failure to punch hole for block device file: {0}")]
@@ -198,20 +203,14 @@ pub enum ImageType {
     AndroidSparse,
 }
 
-fn log_host_fs_type(file: &File) -> Result<()> {
-    let fstype = get_filesystem_type(file).map_err(Error::HostFsType)?;
-    info!("Disk image file is hosted on file system type {:x}", fstype);
-    Ok(())
-}
-
 /// Detect the type of an image file by checking for a valid header of the supported formats.
 pub fn detect_image_type(file: &File, overlapped_mode: bool) -> Result<ImageType> {
     let mut f = file;
     let disk_size = f.get_len().map_err(Error::SeekingFile)?;
     let orig_seek = f.stream_position().map_err(Error::SeekingFile)?;
 
-    info!("disk size {}, ", disk_size);
-    log_host_fs_type(f)?;
+    info!("disk size {}", disk_size);
+
     // Try to read the disk in a nicely-aligned block size unless the whole file is smaller.
     const MAGIC_BLOCK_SIZE: usize = 4096;
     #[repr(align(4096))]
@@ -261,62 +260,45 @@ impl DiskFile for File {
     }
 }
 
-/// Inspect the image file type and create an appropriate disk file to match it.
-pub fn create_disk_file(
-    raw_image: File,
-    is_sparse_file: bool,
-    max_nesting_depth: u32,
-    image_path: &Path,
-) -> Result<Box<dyn DiskFile>> {
-    let image_type = detect_image_type(&raw_image, false)?;
-    create_disk_file_of_type(
-        raw_image,
-        is_sparse_file,
-        max_nesting_depth,
-        image_path,
-        image_type,
-    )
+pub struct DiskFileParams {
+    pub path: PathBuf,
+    pub is_read_only: bool,
+    // Whether to call `base::set_sparse_file` on the file. Currently only affects Windows and is
+    // irrelevant for read only files.
+    pub is_sparse_file: bool,
+    // Whether to open the file in overlapped mode. Only affects Windows.
+    pub is_overlapped: bool,
+    // Whether to disable OS page caches / buffering.
+    pub is_direct: bool,
+    // Whether to lock the file.
+    pub lock: bool,
+    // The nesting depth of the file. Used to avoid infinite recursion. Users outside the disk
+    // crate should set this to zero.
+    pub depth: u32,
 }
 
-/// create an appropriate disk file to match give image type.
-pub fn create_disk_file_of_type(
-    raw_image: File,
-    is_sparse_file: bool,
-    // max_nesting_depth is only used if the composite-disk or qcow features are enabled.
-    #[allow(unused_variables)] mut max_nesting_depth: u32,
-    // image_path is only used if the composite-disk feature is enabled.
-    #[allow(unused_variables)] image_path: &Path,
-    image_type: ImageType,
-) -> Result<Box<dyn DiskFile>> {
-    if max_nesting_depth == 0 {
+/// Inspect the image file type and create an appropriate disk file to match it.
+pub fn open_disk_file(params: DiskFileParams) -> Result<Box<dyn DiskFile>> {
+    if params.depth > MAX_NESTING_DEPTH {
         return Err(Error::MaxNestingDepthExceeded);
     }
-    #[allow(unused_assignments)]
-    {
-        max_nesting_depth -= 1;
-    }
 
+    let raw_image = sys::open_raw_disk_image(&params)?;
+    let image_type = detect_image_type(&raw_image, params.is_overlapped)?;
     Ok(match image_type {
         ImageType::Raw => {
-            sys::apply_raw_disk_file_options(&raw_image, is_sparse_file)?;
+            sys::apply_raw_disk_file_options(&raw_image, params.is_sparse_file)?;
             Box::new(raw_image) as Box<dyn DiskFile>
         }
         #[cfg(feature = "qcow")]
-        ImageType::Qcow2 => {
-            Box::new(QcowFile::from(raw_image, max_nesting_depth).map_err(Error::QcowError)?)
-                as Box<dyn DiskFile>
-        }
+        ImageType::Qcow2 => Box::new(QcowFile::from(raw_image, params).map_err(Error::QcowError)?)
+            as Box<dyn DiskFile>,
         #[cfg(feature = "composite-disk")]
         ImageType::CompositeDisk => {
             // Valid composite disk header present
             Box::new(
-                CompositeDiskFile::from_file(
-                    raw_image,
-                    is_sparse_file,
-                    max_nesting_depth,
-                    image_path,
-                )
-                .map_err(Error::CreateCompositeDisk)?,
+                CompositeDiskFile::from_file(raw_image, params)
+                    .map_err(Error::CreateCompositeDisk)?,
             ) as Box<dyn DiskFile>
         }
         #[cfg(feature = "android-sparse")]
@@ -332,9 +314,6 @@ pub fn create_disk_file_of_type(
 /// An asynchronously accessible disk.
 #[async_trait(?Send)]
 pub trait AsyncDisk: DiskGetLen + FileSetLen + FileAllocate {
-    /// Returns the inner file consuming self.
-    fn into_inner(self: Box<Self>) -> Box<dyn DiskFile>;
-
     /// Flush intermediary buffers and/or dirty state to file. fsync not required.
     async fn flush(&self) -> Result<()>;
 
@@ -432,17 +411,13 @@ impl FileSetLen for SingleFileDisk {
 }
 
 impl FileAllocate for SingleFileDisk {
-    fn allocate(&mut self, offset: u64, len: u64) -> io::Result<()> {
-        self.inner.as_source_mut().allocate(offset, len)
+    fn allocate(&self, offset: u64, len: u64) -> io::Result<()> {
+        self.inner.as_source().allocate(offset, len)
     }
 }
 
 #[async_trait(?Send)]
 impl AsyncDisk for SingleFileDisk {
-    fn into_inner(self: Box<Self>) -> Box<dyn DiskFile> {
-        Box::new(self.inner.into_source())
-    }
-
     async fn flush(&self) -> Result<()> {
         // Nothing to flush, all file mutations are immediately sent to the OS.
         Ok(())
diff --git a/disk/src/qcow/mod.rs b/disk/src/qcow/mod.rs
index 96fbc0e45..1e5a0e285 100644
--- a/disk/src/qcow/mod.rs
+++ b/disk/src/qcow/mod.rs
@@ -9,25 +9,23 @@ mod vec_cache;
 use std::cmp::max;
 use std::cmp::min;
 use std::fs::File;
-use std::fs::OpenOptions;
 use std::io;
 use std::io::Read;
 use std::io::Seek;
 use std::io::SeekFrom;
 use std::io::Write;
 use std::mem::size_of;
-use std::path::Path;
+use std::path::PathBuf;
 use std::str;
 
 use base::error;
-use base::open_file_or_duplicate;
 use base::AsRawDescriptor;
 use base::AsRawDescriptors;
 use base::FileAllocate;
 use base::FileReadWriteAtVolatile;
 use base::FileSetLen;
 use base::FileSync;
-use base::PunchHoleMut;
+use base::PunchHole;
 use base::RawDescriptor;
 use base::VolatileMemory;
 use base::VolatileSlice;
@@ -37,10 +35,11 @@ use libc::EINVAL;
 use libc::ENOSPC;
 use libc::ENOTSUP;
 use remain::sorted;
+use sync::Mutex;
 use thiserror::Error;
 
 use crate::asynchronous::DiskFlush;
-use crate::create_disk_file;
+use crate::open_disk_file;
 use crate::qcow::qcow_raw_file::QcowRawFile;
 use crate::qcow::refcount::RefCount;
 use crate::qcow::vec_cache::CacheMap;
@@ -49,6 +48,7 @@ use crate::qcow::vec_cache::VecCache;
 use crate::AsyncDisk;
 use crate::AsyncDiskFileWrapper;
 use crate::DiskFile;
+use crate::DiskFileParams;
 use crate::DiskGetLen;
 use crate::ToAsyncDisk;
 
@@ -397,11 +397,21 @@ fn max_refcount_clusters(refcount_order: u32, cluster_size: u32, num_clusters: u
 /// # Example
 ///
 /// ```
+/// # use std::path::PathBuf;
 /// # use base::FileReadWriteAtVolatile;
 /// # use disk::QcowFile;
+/// # use disk::DiskFileParams;
 /// # use base::VolatileSlice;
-/// # fn test(file: std::fs::File) -> std::io::Result<()> {
-///     let mut q = QcowFile::from(file, disk::MAX_NESTING_DEPTH).expect("Can't open qcow file");
+/// # fn test(file: std::fs::File, path: PathBuf) -> std::io::Result<()> {
+///     let mut q = QcowFile::from(file, DiskFileParams {
+///         path,
+///         is_read_only: false,
+///         is_sparse_file: false,
+///         is_overlapped: false,
+///         is_direct: false,
+///         lock: true,
+///         depth: 0,
+///     }).expect("Can't open qcow file");
 ///     let mut buf = [0u8; 12];
 ///     let mut vslice = VolatileSlice::new(&mut buf);
 ///     q.read_at_volatile(vslice, 10)?;
@@ -410,6 +420,13 @@ fn max_refcount_clusters(refcount_order: u32, cluster_size: u32, num_clusters: u
 /// ```
 #[derive(Debug)]
 pub struct QcowFile {
+    inner: Mutex<QcowFileInner>,
+    // Copy of `inner.header.size` outside the mutex.
+    virtual_size: u64,
+}
+
+#[derive(Debug)]
+struct QcowFileInner {
     raw_file: QcowRawFile,
     header: QcowHeader,
     l1_table: VecCache<u64>,
@@ -427,7 +444,7 @@ pub struct QcowFile {
 impl DiskFile for QcowFile {}
 
 impl DiskFlush for QcowFile {
-    fn flush(&mut self) -> io::Result<()> {
+    fn flush(&self) -> io::Result<()> {
         // Using fsync is overkill here, but, the code for flushing state to file tangled up with
         // the fsync, so it is best we can do for now.
         self.fsync()
@@ -436,7 +453,7 @@ impl DiskFlush for QcowFile {
 
 impl QcowFile {
     /// Creates a QcowFile from `file`. File must be a valid qcow2 image.
-    pub fn from(mut file: File, max_nesting_depth: u32) -> Result<QcowFile> {
+    pub fn from(mut file: File, params: DiskFileParams) -> Result<QcowFile> {
         let header = QcowHeader::new(&mut file)?;
 
         // Only v3 files are supported.
@@ -461,20 +478,18 @@ impl QcowFile {
         }
 
         let backing_file = if let Some(backing_file_path) = header.backing_file_path.as_ref() {
-            let path = backing_file_path.clone();
-            let backing_raw_file = open_file_or_duplicate(
-                Path::new(&path),
-                OpenOptions::new().read(true), // TODO(b/190435784): Add support for O_DIRECT.
-            )
-            .map_err(|e| Error::BackingFileIo(e.into()))?;
-            // is_sparse_file is false because qcow is internally sparse and we don't need file
-            // system sparseness on top of that.
-            let backing_file = create_disk_file(
-                backing_raw_file,
-                /* is_sparse_file= */ false,
-                max_nesting_depth,
-                Path::new(&path),
-            )
+            let backing_file = open_disk_file(DiskFileParams {
+                path: PathBuf::from(backing_file_path),
+                // The backing file is only read from.
+                is_read_only: true,
+                // Sparse isn't meaningful for read only files.
+                is_sparse_file: false,
+                // TODO: Should pass `params.is_overlapped` through here. Needs testing.
+                is_overlapped: false,
+                is_direct: params.is_direct,
+                lock: params.lock,
+                depth: params.depth + 1,
+            })
             .map_err(|e| Error::BackingFileOpen(Box::new(e)))?;
             Some(backing_file)
         } else {
@@ -525,7 +540,7 @@ impl QcowFile {
         let mut raw_file =
             QcowRawFile::from(file, cluster_size).ok_or(Error::InvalidClusterSize)?;
         if refcount_rebuild_required {
-            QcowFile::rebuild_refcounts(&mut raw_file, header.clone())?;
+            QcowFileInner::rebuild_refcounts(&mut raw_file, header.clone())?;
         }
 
         let l2_size = cluster_size / size_of::<u64>() as u64;
@@ -571,7 +586,7 @@ impl QcowFile {
 
         let l2_entries = cluster_size / size_of::<u64>() as u64;
 
-        let mut qcow = QcowFile {
+        let mut inner = QcowFileInner {
             raw_file,
             header,
             l1_table,
@@ -585,76 +600,83 @@ impl QcowFile {
         };
 
         // Check that the L1 and refcount tables fit in a 64bit address space.
-        qcow.header
+        inner
+            .header
             .l1_table_offset
-            .checked_add(qcow.l1_address_offset(qcow.virtual_size()))
+            .checked_add(inner.l1_address_offset(inner.virtual_size()))
             .ok_or(Error::InvalidL1TableOffset)?;
-        qcow.header
+        inner
+            .header
             .refcount_table_offset
-            .checked_add(u64::from(qcow.header.refcount_table_clusters) * cluster_size)
+            .checked_add(u64::from(inner.header.refcount_table_clusters) * cluster_size)
             .ok_or(Error::InvalidRefcountTableOffset)?;
 
-        qcow.find_avail_clusters()?;
+        inner.find_avail_clusters()?;
 
-        Ok(qcow)
+        let virtual_size = inner.virtual_size();
+        Ok(QcowFile {
+            inner: Mutex::new(inner),
+            virtual_size,
+        })
     }
 
     /// Creates a new QcowFile at the given path.
-    pub fn new(file: File, virtual_size: u64) -> Result<QcowFile> {
+    pub fn new(file: File, params: DiskFileParams, virtual_size: u64) -> Result<QcowFile> {
         let header = QcowHeader::create_for_size_and_path(virtual_size, None)?;
-        QcowFile::new_from_header(file, header, 1)
+        QcowFile::new_from_header(file, params, header)
     }
 
     /// Creates a new QcowFile at the given path.
     pub fn new_from_backing(
         file: File,
+        params: DiskFileParams,
         backing_file_name: &str,
-        backing_file_max_nesting_depth: u32,
     ) -> Result<QcowFile> {
-        let backing_path = Path::new(backing_file_name);
-        let backing_raw_file = open_file_or_duplicate(
-            backing_path,
-            OpenOptions::new().read(true), // TODO(b/190435784): add support for O_DIRECT.
-        )
-        .map_err(|e| Error::BackingFileIo(e.into()))?;
-        // is_sparse_file is false because qcow is internally sparse and we don't need file
-        // system sparseness on top of that.
-        let backing_file = create_disk_file(
-            backing_raw_file,
-            /* is_sparse_file= */ false,
-            backing_file_max_nesting_depth,
-            backing_path,
-        )
-        .map_err(|e| Error::BackingFileOpen(Box::new(e)))?;
-        let size = backing_file.get_len().map_err(Error::BackingFileIo)?;
+        // Open the backing file as a `DiskFile` to determine its size (which may not match the
+        // filesystem size).
+        let size = {
+            let backing_file = open_disk_file(DiskFileParams {
+                path: PathBuf::from(backing_file_name),
+                // The backing file is only read from.
+                is_read_only: true,
+                // Sparse isn't meaningful for read only files.
+                is_sparse_file: false,
+                // TODO: Should pass `params.is_overlapped` through here. Needs testing.
+                is_overlapped: false,
+                is_direct: params.is_direct,
+                lock: params.lock,
+                depth: params.depth + 1,
+            })
+            .map_err(|e| Error::BackingFileOpen(Box::new(e)))?;
+            backing_file.get_len().map_err(Error::BackingFileIo)?
+        };
         let header = QcowHeader::create_for_size_and_path(size, Some(backing_file_name))?;
-        let mut result = QcowFile::new_from_header(file, header, backing_file_max_nesting_depth)?;
-        result.backing_file = Some(backing_file);
-        Ok(result)
+        QcowFile::new_from_header(file, params, header)
     }
 
     fn new_from_header(
         mut file: File,
+        params: DiskFileParams,
         header: QcowHeader,
-        max_nesting_depth: u32,
     ) -> Result<QcowFile> {
         file.seek(SeekFrom::Start(0)).map_err(Error::SeekingFile)?;
         header.write_to(&mut file)?;
 
-        let mut qcow = Self::from(file, max_nesting_depth)?;
+        let mut qcow = Self::from(file, params)?;
+        let inner = qcow.inner.get_mut();
 
         // Set the refcount for each refcount table cluster.
-        let cluster_size = 0x01u64 << qcow.header.cluster_bits;
-        let refcount_table_base = qcow.header.refcount_table_offset;
+        let cluster_size = 0x01u64 << inner.header.cluster_bits;
+        let refcount_table_base = inner.header.refcount_table_offset;
         let end_cluster_addr =
-            refcount_table_base + u64::from(qcow.header.refcount_table_clusters) * cluster_size;
+            refcount_table_base + u64::from(inner.header.refcount_table_clusters) * cluster_size;
 
         let mut cluster_addr = 0;
         while cluster_addr < end_cluster_addr {
-            let mut unref_clusters = qcow
+            let mut unref_clusters = inner
                 .set_cluster_refcount(cluster_addr, 1)
                 .map_err(Error::SettingRefcountRefcount)?;
-            qcow.unref_clusters.append(&mut unref_clusters);
+            inner.unref_clusters.append(&mut unref_clusters);
             cluster_addr += cluster_size;
         }
 
@@ -662,11 +684,14 @@ impl QcowFile {
     }
 
     pub fn set_backing_file(&mut self, backing: Option<Box<dyn DiskFile>>) {
-        self.backing_file = backing;
+        self.inner.get_mut().backing_file = backing;
     }
+}
 
+impl QcowFileInner {
     /// Returns the first cluster in the file with a 0 refcount. Used for testing.
-    pub fn first_zero_refcount(&mut self) -> Result<Option<u64>> {
+    #[cfg(test)]
+    fn first_zero_refcount(&mut self) -> Result<Option<u64>> {
         let file_size = self
             .raw_file
             .file_mut()
@@ -1226,10 +1251,7 @@ impl QcowFile {
             // This cluster is no longer in use; deallocate the storage.
             // The underlying FS may not support FALLOC_FL_PUNCH_HOLE,
             // so don't treat an error as fatal.  Future reads will return zeros anyways.
-            let _ = self
-                .raw_file
-                .file_mut()
-                .punch_hole_mut(cluster_addr, cluster_size);
+            let _ = self.raw_file.file().punch_hole(cluster_addr, cluster_size);
             self.unref_clusters.push(cluster_addr);
         }
         Ok(())
@@ -1263,9 +1285,7 @@ impl QcowFile {
                 };
                 if let Some(offset) = offset {
                     // Partial cluster - zero it out.
-                    self.raw_file
-                        .file_mut()
-                        .write_zeroes_all_at(offset, count)?;
+                    self.raw_file.file().write_zeroes_all_at(offset, count)?;
                 }
             }
 
@@ -1438,14 +1458,17 @@ impl QcowFile {
 
 impl Drop for QcowFile {
     fn drop(&mut self) {
-        let _ = self.sync_caches();
+        let _ = self.inner.get_mut().sync_caches();
     }
 }
 
 impl AsRawDescriptors for QcowFile {
     fn as_raw_descriptors(&self) -> Vec<RawDescriptor> {
-        let mut descriptors = vec![self.raw_file.file().as_raw_descriptor()];
-        if let Some(backing) = &self.backing_file {
+        // Taking a lock here feels wrong, but this method is generally only used during
+        // sandboxing, so it should be OK.
+        let inner = self.inner.lock();
+        let mut descriptors = vec![inner.raw_file.file().as_raw_descriptor()];
+        if let Some(backing) = &inner.backing_file {
             descriptors.append(&mut backing.as_raw_descriptors());
         }
         descriptors
@@ -1454,10 +1477,11 @@ impl AsRawDescriptors for QcowFile {
 
 impl Read for QcowFile {
     fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {
+        let inner = self.inner.get_mut();
         let len = buf.len();
         let slice = VolatileSlice::new(buf);
-        let read_count = self.read_cb(
-            self.current_offset,
+        let read_count = inner.read_cb(
+            inner.current_offset,
             len,
             |file, already_read, offset, count| {
                 let sub_slice = slice.get_slice(already_read, count).unwrap();
@@ -1470,36 +1494,37 @@ impl Read for QcowFile {
                 }
             },
         )?;
-        self.current_offset += read_count as u64;
+        inner.current_offset += read_count as u64;
         Ok(read_count)
     }
 }
 
 impl Seek for QcowFile {
     fn seek(&mut self, pos: SeekFrom) -> std::io::Result<u64> {
+        let inner = self.inner.get_mut();
         let new_offset: Option<u64> = match pos {
             SeekFrom::Start(off) => Some(off),
             SeekFrom::End(off) => {
                 if off < 0 {
                     0i64.checked_sub(off)
-                        .and_then(|increment| self.virtual_size().checked_sub(increment as u64))
+                        .and_then(|increment| inner.virtual_size().checked_sub(increment as u64))
                 } else {
-                    self.virtual_size().checked_add(off as u64)
+                    inner.virtual_size().checked_add(off as u64)
                 }
             }
             SeekFrom::Current(off) => {
                 if off < 0 {
                     0i64.checked_sub(off)
-                        .and_then(|increment| self.current_offset.checked_sub(increment as u64))
+                        .and_then(|increment| inner.current_offset.checked_sub(increment as u64))
                 } else {
-                    self.current_offset.checked_add(off as u64)
+                    inner.current_offset.checked_add(off as u64)
                 }
             }
         };
 
         if let Some(o) = new_offset {
-            if o <= self.virtual_size() {
-                self.current_offset = o;
+            if o <= inner.virtual_size() {
+                inner.current_offset = o;
                 return Ok(o);
             }
         }
@@ -1509,15 +1534,16 @@ impl Seek for QcowFile {
 
 impl Write for QcowFile {
     fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {
-        let write_count = self.write_cb(
-            self.current_offset,
+        let inner = self.inner.get_mut();
+        let write_count = inner.write_cb(
+            inner.current_offset,
             buf.len(),
             |file, offset, raw_offset, count| {
                 file.seek(SeekFrom::Start(raw_offset))?;
                 file.write_all(&buf[offset..(offset + count)])
             },
         )?;
-        self.current_offset += write_count as u64;
+        inner.current_offset += write_count as u64;
         Ok(write_count)
     }
 
@@ -1527,8 +1553,9 @@ impl Write for QcowFile {
 }
 
 impl FileReadWriteAtVolatile for QcowFile {
-    fn read_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
-        self.read_cb(offset, slice.size(), |file, read, offset, count| {
+    fn read_at_volatile(&self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
+        let mut inner = self.inner.lock();
+        inner.read_cb(offset, slice.size(), |file, read, offset, count| {
             let sub_slice = slice.get_slice(read, count).unwrap();
             match file {
                 Some(f) => f.read_exact_at_volatile(sub_slice, offset),
@@ -1540,8 +1567,9 @@ impl FileReadWriteAtVolatile for QcowFile {
         })
     }
 
-    fn write_at_volatile(&mut self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
-        self.write_cb(offset, slice.size(), |file, offset, raw_offset, count| {
+    fn write_at_volatile(&self, slice: VolatileSlice, offset: u64) -> io::Result<usize> {
+        let mut inner = self.inner.lock();
+        inner.write_cb(offset, slice.size(), |file, offset, raw_offset, count| {
             let sub_slice = slice.get_slice(offset, count).unwrap();
             file.write_all_at_volatile(sub_slice, raw_offset)
         })
@@ -1549,13 +1577,15 @@ impl FileReadWriteAtVolatile for QcowFile {
 }
 
 impl FileSync for QcowFile {
-    fn fsync(&mut self) -> std::io::Result<()> {
-        self.sync_caches()?;
-        self.avail_clusters.append(&mut self.unref_clusters);
+    fn fsync(&self) -> std::io::Result<()> {
+        let mut inner = self.inner.lock();
+        inner.sync_caches()?;
+        let unref_clusters = std::mem::take(&mut inner.unref_clusters);
+        inner.avail_clusters.extend(unref_clusters);
         Ok(())
     }
 
-    fn fdatasync(&mut self) -> io::Result<()> {
+    fn fdatasync(&self) -> io::Result<()> {
         // QcowFile does not implement fdatasync. Just fall back to fsync.
         self.fsync()
     }
@@ -1572,15 +1602,16 @@ impl FileSetLen for QcowFile {
 
 impl DiskGetLen for QcowFile {
     fn get_len(&self) -> io::Result<u64> {
-        Ok(self.virtual_size())
+        Ok(self.virtual_size)
     }
 }
 
 impl FileAllocate for QcowFile {
-    fn allocate(&mut self, offset: u64, len: u64) -> io::Result<()> {
+    fn allocate(&self, offset: u64, len: u64) -> io::Result<()> {
+        let mut inner = self.inner.lock();
         // Call write_cb with a do-nothing callback, which will have the effect
         // of allocating all clusters in the specified range.
-        self.write_cb(
+        inner.write_cb(
             offset,
             len as usize,
             |_file, _offset, _raw_offset, _count| Ok(()),
@@ -1589,13 +1620,14 @@ impl FileAllocate for QcowFile {
     }
 }
 
-impl PunchHoleMut for QcowFile {
-    fn punch_hole_mut(&mut self, offset: u64, length: u64) -> std::io::Result<()> {
+impl PunchHole for QcowFile {
+    fn punch_hole(&self, offset: u64, length: u64) -> std::io::Result<()> {
+        let mut inner = self.inner.lock();
         let mut remaining = length;
         let mut offset = offset;
         while remaining > 0 {
-            let chunk_length = min(remaining, std::usize::MAX as u64) as usize;
-            self.zero_bytes(offset, chunk_length)?;
+            let chunk_length = min(remaining, usize::MAX as u64) as usize;
+            inner.zero_bytes(offset, chunk_length)?;
             remaining -= chunk_length as u64;
             offset += chunk_length as u64;
         }
@@ -1604,8 +1636,8 @@ impl PunchHoleMut for QcowFile {
 }
 
 impl WriteZeroesAt for QcowFile {
-    fn write_zeroes_at(&mut self, offset: u64, length: usize) -> io::Result<usize> {
-        self.punch_hole_mut(offset, length as u64)?;
+    fn write_zeroes_at(&self, offset: u64, length: usize) -> io::Result<usize> {
+        self.punch_hole(offset, length as u64)?;
         Ok(length)
     }
 }
@@ -1636,7 +1668,6 @@ mod tests {
     use tempfile::TempDir;
 
     use super::*;
-    use crate::MAX_NESTING_DEPTH;
 
     fn valid_header() -> Vec<u8> {
         vec![
@@ -1685,6 +1716,18 @@ mod tests {
         ]
     }
 
+    fn test_params() -> DiskFileParams {
+        DiskFileParams {
+            path: PathBuf::from("/foo"),
+            is_read_only: false,
+            is_sparse_file: false,
+            is_overlapped: false,
+            is_direct: false,
+            lock: true,
+            depth: 0,
+        }
+    }
+
     fn basic_file(header: &[u8]) -> File {
         let mut disk_file = tempfile().expect("failed to create temp file");
         disk_file.write_all(header).unwrap();
@@ -1705,7 +1748,7 @@ mod tests {
         F: FnMut(QcowFile),
     {
         let file = tempfile().expect("failed to create temp file");
-        let qcow_file = QcowFile::new(file, file_size).unwrap();
+        let qcow_file = QcowFile::new(file, test_params(), file_size).unwrap();
 
         testfn(qcow_file); // File closed when the function exits.
     }
@@ -1735,7 +1778,7 @@ mod tests {
             .write_to(&mut disk_file)
             .expect("Failed to write header to shm.");
         disk_file.seek(SeekFrom::Start(0)).unwrap();
-        QcowFile::from(disk_file, MAX_NESTING_DEPTH)
+        QcowFile::from(disk_file, test_params())
             .expect("Failed to create Qcow from default Header");
     }
 
@@ -1776,8 +1819,7 @@ mod tests {
         let mut header = valid_header();
         header[99] = 2;
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH)
-                .expect_err("Invalid refcount order worked.");
+            QcowFile::from(disk_file, test_params()).expect_err("Invalid refcount order worked.");
         });
     }
 
@@ -1786,7 +1828,7 @@ mod tests {
         let mut header = valid_header();
         header[23] = 3;
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH).expect_err("Failed to create file.");
+            QcowFile::from(disk_file, test_params()).expect_err("Failed to create file.");
         });
     }
 
@@ -1794,7 +1836,7 @@ mod tests {
     fn test_header_huge_file() {
         let header = test_huge_header();
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH).expect_err("Failed to create file.");
+            QcowFile::from(disk_file, test_params()).expect_err("Failed to create file.");
         });
     }
 
@@ -1803,7 +1845,7 @@ mod tests {
         let mut header = valid_header();
         header[24..32].copy_from_slice(&[0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x1e]);
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH).expect_err("Failed to create file.");
+            QcowFile::from(disk_file, test_params()).expect_err("Failed to create file.");
         });
     }
 
@@ -1812,7 +1854,7 @@ mod tests {
         let mut header = valid_header();
         header[36] = 0x12;
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH).expect_err("Failed to create file.");
+            QcowFile::from(disk_file, test_params()).expect_err("Failed to create file.");
         });
     }
 
@@ -1824,7 +1866,7 @@ mod tests {
         header[31] = 0;
         // 1 TB with the min cluster size makes the arrays too big, it should fail.
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH).expect_err("Failed to create file.");
+            QcowFile::from(disk_file, test_params()).expect_err("Failed to create file.");
         });
     }
 
@@ -1840,7 +1882,7 @@ mod tests {
         header[23] = 16;
         with_basic_file(&header, |disk_file: File| {
             let mut qcow =
-                QcowFile::from(disk_file, MAX_NESTING_DEPTH).expect("Failed to create file.");
+                QcowFile::from(disk_file, test_params()).expect("Failed to create file.");
             let value = 0x0000_0040_3f00_ffffu64;
             write_all_at(&mut qcow, &value.to_le_bytes(), 0x100_0000_0000 - 8)
                 .expect("failed to write data");
@@ -1852,7 +1894,7 @@ mod tests {
         let mut header = valid_header();
         header[56..60].copy_from_slice(&[0x02, 0x00, 0xe8, 0xff]);
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH)
+            QcowFile::from(disk_file, test_params())
                 .expect_err("Created disk with excessive refcount clusters");
         });
     }
@@ -1862,7 +1904,7 @@ mod tests {
         let mut header = valid_header();
         header[48..56].copy_from_slice(&[0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x02, 0x00]);
         with_basic_file(&header, |disk_file: File| {
-            QcowFile::from(disk_file, MAX_NESTING_DEPTH)
+            QcowFile::from(disk_file, test_params())
                 .expect_err("Created disk with excessive refcount offset");
         });
     }
@@ -1871,7 +1913,7 @@ mod tests {
     #[test]
     fn write_read_start() {
         with_basic_file(&valid_header(), |disk_file: File| {
-            let mut q = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+            let mut q = QcowFile::from(disk_file, test_params()).unwrap();
             write_all_at(&mut q, b"test first bytes", 0).expect("Failed to write test string.");
             let mut buf = [0u8; 4];
             read_exact_at(&mut q, &mut buf, 0).expect("Failed to read.");
@@ -1883,11 +1925,11 @@ mod tests {
     #[test]
     fn write_read_start_backing() {
         let disk_file = basic_file(&valid_header());
-        let mut backing = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+        let mut backing = QcowFile::from(disk_file, test_params()).unwrap();
         write_all_at(&mut backing, b"test first bytes", 0).expect("Failed to write test string.");
         let mut buf = [0u8; 4];
         let wrapping_disk_file = basic_file(&valid_header());
-        let mut wrapping = QcowFile::from(wrapping_disk_file, MAX_NESTING_DEPTH).unwrap();
+        let mut wrapping = QcowFile::from(wrapping_disk_file, test_params()).unwrap();
         wrapping.set_backing_file(Some(Box::new(backing)));
         read_exact_at(&mut wrapping, &mut buf, 0).expect("Failed to read.");
         assert_eq!(&buf, b"test");
@@ -1897,10 +1939,10 @@ mod tests {
     #[test]
     fn write_read_start_backing_overlap() {
         let disk_file = basic_file(&valid_header());
-        let mut backing = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+        let mut backing = QcowFile::from(disk_file, test_params()).unwrap();
         write_all_at(&mut backing, b"test first bytes", 0).expect("Failed to write test string.");
         let wrapping_disk_file = basic_file(&valid_header());
-        let mut wrapping = QcowFile::from(wrapping_disk_file, MAX_NESTING_DEPTH).unwrap();
+        let mut wrapping = QcowFile::from(wrapping_disk_file, test_params()).unwrap();
         wrapping.set_backing_file(Some(Box::new(backing)));
         write_all_at(&mut wrapping, b"TEST", 0).expect("Failed to write second test string.");
         let mut buf = [0u8; 10];
@@ -1912,7 +1954,7 @@ mod tests {
     #[test]
     fn offset_write_read() {
         with_basic_file(&valid_header(), |disk_file: File| {
-            let mut q = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+            let mut q = QcowFile::from(disk_file, test_params()).unwrap();
             let b = [0x55u8; 0x1000];
             write_all_at(&mut q, &b, 0xfff2000).expect("Failed to write test string.");
             let mut buf = [0u8; 4];
@@ -1925,7 +1967,7 @@ mod tests {
     #[test]
     fn write_zeroes_read() {
         with_basic_file(&valid_header(), |disk_file: File| {
-            let mut q = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+            let mut q = QcowFile::from(disk_file, test_params()).unwrap();
             // Write some test data.
             let b = [0x55u8; 0x1000];
             write_all_at(&mut q, &b, 0xfff2000).expect("Failed to write test string.");
@@ -1949,7 +1991,7 @@ mod tests {
         // valid_header uses cluster_bits = 12, which corresponds to a cluster size of 4096.
         const CHUNK_SIZE: usize = 4096 * 2 + 512;
         with_basic_file(&valid_header(), |disk_file: File| {
-            let mut q = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+            let mut q = QcowFile::from(disk_file, test_params()).unwrap();
             // Write some test data.
             let b = [0x55u8; CHUNK_SIZE];
             write_all_at(&mut q, &b, 0).expect("Failed to write test string.");
@@ -1968,12 +2010,12 @@ mod tests {
     #[test]
     fn write_zeroes_backing() {
         let disk_file = basic_file(&valid_header());
-        let mut backing = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+        let mut backing = QcowFile::from(disk_file, test_params()).unwrap();
         // Write some test data.
         let b = [0x55u8; 0x1000];
         write_all_at(&mut backing, &b, 0xfff2000).expect("Failed to write test string.");
         let wrapping_disk_file = basic_file(&valid_header());
-        let mut wrapping = QcowFile::from(wrapping_disk_file, MAX_NESTING_DEPTH).unwrap();
+        let mut wrapping = QcowFile::from(wrapping_disk_file, test_params()).unwrap();
         wrapping.set_backing_file(Some(Box::new(backing)));
         // Overwrite the test data with zeroes.
         // This should allocate new clusters in the wrapping file so that they can be zeroed.
@@ -1991,15 +2033,15 @@ mod tests {
     #[test]
     fn test_header() {
         with_basic_file(&valid_header(), |disk_file: File| {
-            let q = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
-            assert_eq!(q.virtual_size(), 0x20_0000_0000);
+            let mut q = QcowFile::from(disk_file, test_params()).unwrap();
+            assert_eq!(q.inner.get_mut().virtual_size(), 0x20_0000_0000);
         });
     }
 
     #[test]
     fn read_small_buffer() {
         with_basic_file(&valid_header(), |disk_file: File| {
-            let mut q = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+            let mut q = QcowFile::from(disk_file, test_params()).unwrap();
             let mut b = [5u8; 16];
             read_exact_at(&mut q, &mut b, 1000).expect("Failed to read.");
             assert_eq!(0, b[0]);
@@ -2011,7 +2053,7 @@ mod tests {
     #[test]
     fn replay_ext4() {
         with_basic_file(&valid_header(), |disk_file: File| {
-            let mut q = QcowFile::from(disk_file, MAX_NESTING_DEPTH).unwrap();
+            let mut q = QcowFile::from(disk_file, test_params()).unwrap();
             const BUF_SIZE: usize = 0x1000;
             let mut b = [0u8; BUF_SIZE];
 
@@ -2415,7 +2457,10 @@ mod tests {
                 }
             }
 
-            assert_eq!(qcow_file.first_zero_refcount().unwrap(), None);
+            assert_eq!(
+                qcow_file.inner.get_mut().first_zero_refcount().unwrap(),
+                None
+            );
         });
     }
 
@@ -2426,7 +2471,7 @@ mod tests {
             let cluster_size = 65536;
             let mut raw_file =
                 QcowRawFile::from(disk_file, cluster_size).expect("Failed to create QcowRawFile.");
-            QcowFile::rebuild_refcounts(&mut raw_file, header)
+            QcowFileInner::rebuild_refcounts(&mut raw_file, header)
                 .expect("Failed to rebuild recounts.");
         });
     }
@@ -2442,7 +2487,7 @@ mod tests {
         let _backing_file = OpenOptions::new()
             .read(true)
             .write(true)
-            .create(true)
+            .create_new(true)
             .open(&backing_file_path)
             .unwrap();
 
@@ -2450,21 +2495,21 @@ mod tests {
         let level1_qcow_file = OpenOptions::new()
             .read(true)
             .write(true)
-            .create(true)
+            .create_new(true)
             .open(&level1_qcow_file_path)
             .unwrap();
         let _level1_qcow_file = QcowFile::new_from_backing(
             level1_qcow_file,
+            test_params(),
             backing_file_path.to_str().unwrap(),
-            1000, /* allow deep nesting */
         )
         .unwrap();
 
         let level2_qcow_file = tempfile().unwrap();
         let _level2_qcow_file = QcowFile::new_from_backing(
             level2_qcow_file,
+            test_params(),
             level1_qcow_file_path.to_str().unwrap(),
-            1000, /* allow deep nesting */
         )
         .expect("failed to create level2 qcow file");
     }
diff --git a/disk/src/qcow/qcow_raw_file.rs b/disk/src/qcow/qcow_raw_file.rs
index f2a38f2e2..f13202f45 100644
--- a/disk/src/qcow/qcow_raw_file.rs
+++ b/disk/src/qcow/qcow_raw_file.rs
@@ -48,7 +48,7 @@ impl QcowRawFile {
     ) -> io::Result<Vec<u64>> {
         let mut table = vec![0; count as usize];
         self.file.seek(SeekFrom::Start(offset))?;
-        let mask = mask.unwrap_or(u64::max_value());
+        let mask = mask.unwrap_or(u64::MAX);
         for ptr in &mut table {
             let mut value = [0u8; 8];
             self.file.read_exact(&mut value)?;
diff --git a/disk/src/qcow/vec_cache.rs b/disk/src/qcow/vec_cache.rs
index 2bcf5f44e..ef6b0f4e2 100644
--- a/disk/src/qcow/vec_cache.rs
+++ b/disk/src/qcow/vec_cache.rs
@@ -137,6 +137,7 @@ impl<T: Cacheable> CacheMap<T> {
 mod tests {
     use super::*;
 
+    #[derive(Copy, Clone, Debug, Eq, PartialEq)]
     struct NumCache(pub u64);
     impl Cacheable for NumCache {
         fn dirty(&self) -> bool {
@@ -182,5 +183,6 @@ mod tests {
         let num_items = (0..=3).filter(|k| cache.contains_key(k)).count();
         assert_eq!(num_items, 3);
         assert!(cache.contains_key(&3));
+        assert_eq!(cache.get(&3), Some(&NumCache(8)));
     }
 }
diff --git a/disk/src/sys.rs b/disk/src/sys.rs
index bee303656..cbe6c8467 100644
--- a/disk/src/sys.rs
+++ b/disk/src/sys.rs
@@ -13,4 +13,5 @@ cfg_if::cfg_if! {
 }
 
 pub(crate) use platform::apply_raw_disk_file_options;
+pub(crate) use platform::open_raw_disk_image;
 pub(crate) use platform::read_from_disk;
diff --git a/disk/src/sys/linux.rs b/disk/src/sys/linux.rs
index 6c7b19975..42bcb999a 100644
--- a/disk/src/sys/linux.rs
+++ b/disk/src/sys/linux.rs
@@ -6,13 +6,42 @@ use std::fs::File;
 use std::io::Read;
 use std::io::Seek;
 use std::io::SeekFrom;
+use std::os::fd::AsRawFd;
 
 use cros_async::Executor;
 
+use crate::DiskFileParams;
 use crate::Error;
 use crate::Result;
 use crate::SingleFileDisk;
 
+pub fn open_raw_disk_image(params: &DiskFileParams) -> Result<File> {
+    let mut options = File::options();
+    options.read(true).write(!params.is_read_only);
+
+    let raw_image = base::open_file_or_duplicate(&params.path, &options)
+        .map_err(|e| Error::OpenFile(params.path.display().to_string(), e))?;
+
+    if params.lock {
+        // Lock the disk image to prevent other crosvm instances from using it.
+        let lock_op = if params.is_read_only {
+            base::FlockOperation::LockShared
+        } else {
+            base::FlockOperation::LockExclusive
+        };
+        base::flock(&raw_image, lock_op, true).map_err(Error::LockFileFailure)?;
+    }
+
+    // If O_DIRECT is requested, set the flag via fcntl. It is not done at
+    // open_file_or_reuse time because it will reuse existing fd and will
+    // not actually use the given OpenOptions.
+    if params.is_direct {
+        base::add_fd_flags(raw_image.as_raw_fd(), libc::O_DIRECT).map_err(Error::DirectFailed)?;
+    }
+
+    Ok(raw_image)
+}
+
 pub fn apply_raw_disk_file_options(_raw_image: &File, _is_sparse_file: bool) -> Result<()> {
     // No op on unix.
     Ok(())
diff --git a/disk/src/sys/windows.rs b/disk/src/sys/windows.rs
index f862302b6..99f413d01 100644
--- a/disk/src/sys/windows.rs
+++ b/disk/src/sys/windows.rs
@@ -6,10 +6,17 @@ use std::fs::File;
 use std::io::Read;
 use std::io::Seek;
 use std::io::SeekFrom;
+use std::os::windows::fs::OpenOptionsExt;
 
+use base::info;
 use base::read_overlapped_blocking;
 use cros_async::Executor;
+use winapi::um::winbase::FILE_FLAG_NO_BUFFERING;
+use winapi::um::winbase::FILE_FLAG_OVERLAPPED;
+use winapi::um::winnt::FILE_SHARE_READ;
+use winapi::um::winnt::FILE_SHARE_WRITE;
 
+use crate::DiskFileParams;
 use crate::Error;
 use crate::Result;
 use crate::SingleFileDisk;
@@ -22,6 +29,33 @@ impl SingleFileDisk {
     }
 }
 
+pub fn open_raw_disk_image(params: &DiskFileParams) -> Result<File> {
+    let mut options = File::options();
+    options.read(true).write(!params.is_read_only);
+    if params.lock {
+        // We only prevent file deletion and renaming right now.
+        options.share_mode(FILE_SHARE_READ | FILE_SHARE_WRITE);
+    }
+
+    let mut flags = 0;
+    if params.is_direct {
+        info!("Opening disk file with no buffering");
+        flags |= FILE_FLAG_NO_BUFFERING;
+    }
+    if params.is_overlapped {
+        info!("Opening disk file for overlapped IO");
+        flags |= FILE_FLAG_OVERLAPPED;
+    }
+    if flags != 0 {
+        options.custom_flags(flags);
+    }
+
+    let raw_image = base::open_file_or_duplicate(&params.path, &options)
+        .map_err(|e| Error::OpenFile(params.path.display().to_string(), e))?;
+
+    Ok(raw_image)
+}
+
 /// On Windows, if the file is sparse, we set the option. On Linux this is not needed.
 pub fn apply_raw_disk_file_options(raw_image: &File, is_sparse_file: bool) -> Result<()> {
     if is_sparse_file {
diff --git a/docs/book/src/appendix/memory_layout.md b/docs/book/src/appendix/memory_layout.md
index 56692e573..14d0f92a0 100644
--- a/docs/book/src/appendix/memory_layout.md
+++ b/docs/book/src/appendix/memory_layout.md
@@ -10,15 +10,16 @@ see the source. All addresses are in hexadecimal.
 | [`START_OF_RAM_32BITS`]      | `0000`        |                 |           | RAM                                                                                      |
 | [`ZERO_PAGE_OFFSET`]         | `7000`        |                 |           | Linux boot_params structure                                                              |
 | [`BOOT_STACK_POINTER`]       | `8000`        |                 |           | Boot SP value                                                                            |
-| [`boot_pml4_addr`]           | `9000`        |                 |           | Boot page table                                                                          |
-| [`boot_pdpte_addr`]          | `A000`        |                 |           | Boot page table                                                                          |
-| [`boot_pde_addr`]            | `B000`        |                 |           | Boot page table                                                                          |
+| [`boot_pml4_addr`]           | `9000`        | `A000`          | 4 KiB     | Boot page table                                                                          |
+| [`boot_pdpte_addr`]          | `A000`        | `B000`          | 4 KiB     | Boot page table                                                                          |
+| [`boot_pde_addr`]            | `B000`        | `F000`          | 16 KiB    | Boot page tables                                                                         |
 | [`CMDLINE_OFFSET`]           | `2_0000`      | `2_0800`        | 2 KiB     | Linux kernel command line                                                                |
 | [`SETUP_DATA_START`]         | `2_0800`      | `E_0000`        | 766 KiB   | Linux kernel `setup_data` linked list                                                    |
 | [`ACPI_HI_RSDP_WINDOW_BASE`] | `E_0000`      |                 |           | ACPI tables                                                                              |
 | [`KERNEL_START_OFFSET`]      | `20_0000`     |                 |           | Linux kernel image load address                                                          |
 | [`initrd_start`]             | after kernel  |                 |           | Initial RAM disk for Linux kernel (optional)                                             |
 | [`END_ADDR_BEFORE_32BITS`]   | after initrd  | `D000_0000`     | ~3.24 GiB | RAM (\<4G)                                                                               |
+| [`PROTECTED_VM_FW_START`]    | `CFC0_0000`   | `D000_0000`     | 4 MiB     | pVM firmware (if running a protected VM)                                                 |
 | [`END_ADDR_BEFORE_32BITS`]   | `D000_0000`   | `F400_0000`     | 576 MiB   | Low (\<4G) MMIO allocation area                                                          |
 | [`PCIE_CFG_MMIO_START`]      | `F400_0000`   | `F800_0000`     | 64 MiB    | PCIe enhanced config (ECAM)                                                              |
 | [`RESERVED_MEM_SIZE`]        | `F800_0000`   | `1_0000_0000`   | 128 MiB   | LAPIC/IOAPIC/HPET/                                                                      |
@@ -27,22 +28,23 @@ see the source. All addresses are in hexadecimal.
 |                              | `1_0000_0000` |                 |           | RAM (>4G)                                                                                |
 |                              | (end of RAM)  |                 |           | High (>4G) MMIO allocation area                                                          |
 
-[`start_of_ram_32bits`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=335?q=START_OF_RAM_32BITS
-[`zero_page_offset`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=338?q=ZERO_PAGE_OFFSET
-[`boot_stack_pointer`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=332?q=BOOT_STACK_POINTER
-[`boot_pml4_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/regs.rs;l=299?q=boot_pml4_addr
-[`boot_pdpte_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/regs.rs;l=300?q=boot_pdpte_addr
-[`boot_pde_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/regs.rs;l=301?q=boot_pde_addr
-[`cmdline_offset`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=342?q=CMDLINE_OFFSET
-[`setup_data_start`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=344?q=SETUP_DATA_START
-[`acpi_hi_rsdp_window_base`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=357?q=ACPI_HI_RSDP_WINDOW_BASE
-[`kernel_start_offset`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=341?q=KERNEL_START_OFFSET
-[`initrd_start`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=1633?q=initrd_start
-[`end_addr_before_32bits`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=230?q=END_ADDR_BEFORE_32BITS
-[`pcie_cfg_mmio_start`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=400?q=PCIE_CFG_MMIO_START
-[`reserved_mem_size`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=395?q=RESERVED_MEM_SIZE
-[`identity_map_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=339?q=identity_map_addr_start
-[`tss_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=339?q=tss_addr_start
+[`start_of_ram_32bits`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=351?q=START_OF_RAM_32BITS
+[`zero_page_offset`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=368?q=ZERO_PAGE_OFFSET
+[`boot_stack_pointer`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=350?q=BOOT_STACK_POINTER
+[`boot_pml4_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/regs.rs;l=297?q=boot_pml4_addr
+[`boot_pdpte_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/regs.rs;l=298?q=boot_pdpte_addr
+[`boot_pde_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/regs.rs;l=299?q=boot_pde_addr
+[`cmdline_offset`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=373?q=CMDLINE_OFFSET
+[`setup_data_start`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=375?q=SETUP_DATA_START
+[`acpi_hi_rsdp_window_base`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=388?q=ACPI_HI_RSDP_WINDOW_BASE
+[`kernel_start_offset`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=372?q=KERNEL_START_OFFSET
+[`initrd_start`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=1692?q=initrd_start
+[`protected_vm_fw_start`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=394?q=PROTECTED_VM_FW_START
+[`end_addr_before_32bits`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=356?q=END_ADDR_BEFORE_32BITS
+[`pcie_cfg_mmio_start`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=363?q=PCIE_CFG_MMIO_START
+[`reserved_mem_size`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=358?q=RESERVED_MEM_SIZE
+[`identity_map_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=500?q=identity_map_addr_start
+[`tss_addr`]: https://crsrc.org/o/src/platform/crosvm/x86_64/src/lib.rs;l=505?q=tss_addr_start
 
 ## aarch64 guest physical memory map
 
@@ -69,28 +71,37 @@ These apply for all boot modes.
 | [`AARCH64_AXI_BASE`]              | `4000_0000`     |                 |                | Seemingly unused? Is this hard-coded somewhere in the kernel? |
 | [`AARCH64_PROTECTED_VM_FW_START`] | `7fc0_0000`     | `8000_0000`     | 4 MiB          | pVM firmware (if running a protected VM)                      |
 | [`AARCH64_PHYS_MEM_START`]        | `8000_0000`     |                 | --mem size     | RAM (starts at IPA = 2 GiB)                                   |
-| [`get_swiotlb_addr`]              | after RAM       |                 | --swiotlb size | Only present for hypervisors requiring static swiotlb alloc   |
-| [`plat_mmio_base`]                | after swiotlb   | +0x800000       | 8 MiB          | Platform device MMIO region                                   |
+| [`plat_mmio_base`]                | after RAM       | +0x800000       | 8 MiB          | Platform device MMIO region                                   |
 | [`high_mmio_base`]                | after plat_mmio | max phys addr   |                | High MMIO allocation area                                     |
 
-### Layout when booting a kernel
+### RAM Layout
 
-These apply when no bootloader is passed, so crosvm boots a kernel directly.
+The RAM layout depends on the `--fdt-position` setting, which defaults to
+`start` when load using `--bios` and to `end` when using `--kernel`.
 
-| Name/source link          | Address           | End (exclusive) | Size  | Notes                        |
-| ------------------------- | ----------------- | --------------- | ----- | ---------------------------- |
-| [`AARCH64_KERNEL_OFFSET`] | `8000_0000`       |                 |       | Kernel load location in RAM  |
-| [`initrd_addr`]           | after kernel      |                 |       | Linux initrd location in RAM |
-| [`fdt_address`]           | before end of RAM |                 | 2 MiB | Flattened device tree in RAM |
+In `--kernel` mode, the initrd is always loaded immediately after the kernel,
+with a 16 MiB alignment.
 
-### Layout when booting a bootloader
+#### --fdt-position=start
 
-These apply when a bootloader is passed with `--bios`.
+| Name/source link          | Address           | End (exclusive) | Size  | Notes                            |
+| ------------------------- | ----------------- | --------------- | ----- | -------------------------------- |
+| [`fdt_address`]           | `8000_0000`       | `8020_0000`     | 2 MiB | Flattened device tree in RAM     |
+| [`payload_address`]       | `8020_0000`       |                 |       | Kernel/BIOS load location in RAM |
 
-| Name/source link                    | Address     | End (exclusive) | Size  | Notes                        |
-| ----------------------------------- | ----------- | --------------- | ----- | ---------------------------- |
-| [`AARCH64_FDT_OFFSET_IN_BIOS_MODE`] | `8000_0000` | `8020_0000`     | 2 MiB | Flattened device tree in RAM |
-| [`AARCH64_BIOS_OFFSET`]             | `8020_0000` |                 |       | Bootloader image in RAM      |
+#### --fdt-position=after-payload
+
+| Name/source link          | Address                             | End (exclusive) | Size  | Notes                            |
+| ------------------------- | ----------------------------------- | --------------- | ----- | -------------------------------- |
+| [`payload_address`]       | `8000_0000`                         |                 |       | Kernel/BIOS load location in RAM |
+| [`fdt_address`]           | after payload (2 MiB alignment)     |                 | 2 MiB | Flattened device tree in RAM     |
+
+#### --fdt-position=end
+
+| Name/source link          | Address                             | End (exclusive) | Size  | Notes                            |
+| ------------------------- | ----------------------------------- | --------------- | ----- | -------------------------------- |
+| [`payload_address`]       | `8000_0000`                         |                 |       | Kernel/BIOS load location in RAM |
+| [`fdt_address`]           | before end of RAM (2 MiB alignment) |                 | 2 MiB | Flattened device tree in RAM     |
 
 [serial_addr]: https://crsrc.org/o/src/platform/crosvm/arch/src/serial.rs;l=78?q=SERIAL_ADDR
 [`aarch64_rtc_addr`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=177?q=AARCH64_RTC_ADDR
@@ -104,11 +115,7 @@ These apply when a bootloader is passed with `--bios`.
 [`aarch64_pvtime_ipa_start`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=100?q=AARCH64_PVTIME_IPA_START
 [`aarch64_protected_vm_fw_start`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=96?q=AARCH64_PROTECTED_VM_FW_START
 [`aarch64_phys_mem_start`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=85?q=AARCH64_PHYS_MEM_START
-[`get_swiotlb_addr`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs?q=get_swiotlb_addr
 [`plat_mmio_base`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=835?q=plat_mmio_base
 [`high_mmio_base`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=838?q=high_mmio_base
-[`aarch64_kernel_offset`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=76?q=AARCH64_KERNEL_OFFSET
-[`initrd_addr`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=409?q=initrd_addr
 [`fdt_address`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=301?q=fdt_address
-[`aarch64_fdt_offset_in_bios_mode`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=90?q=AARCH64_FDT_OFFSET_IN_BIOS_MODE
-[`aarch64_bios_offset`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=92?q=AARCH64_BIOS_OFFSET
+[`payload_address`]: https://crsrc.org/o/src/platform/crosvm/aarch64/src/lib.rs;l=301?q=payload_address
diff --git a/docs/book/src/appendix/rutabaga_gfx.md b/docs/book/src/appendix/rutabaga_gfx.md
index 227ac1b19..2b9ec7976 100644
--- a/docs/book/src/appendix/rutabaga_gfx.md
+++ b/docs/book/src/appendix/rutabaga_gfx.md
@@ -26,11 +26,12 @@ common use case.
 sudo apt install libdrm libglm-dev libstb-dev
 ```
 
-### Build AEMU base
+### Install libaemu
 
 ```sh
 git clone https://android.googlesource.com/platform/hardware/google/aemu
 cd aemu/
+git checkout v0.1.2-aemu-release
 cmake -DAEMU_COMMON_GEN_PKGCONFIG=ON \
        -DAEMU_COMMON_BUILD_CONFIG=gfxstream \
        -DENABLE_VKCEREAL_TESTS=OFF -B build
@@ -38,39 +39,131 @@ cmake --build build -j
 sudo cmake --install build
 ```
 
-### Build gfxstream
+### Install gfxstream host
 
 ```sh
 git clone https://android.googlesource.com/platform/hardware/google/gfxstream
 cd gfxstream/
-meson setup -Ddefault_library=static build/
-meson install -C build
+meson setup host-build/
+meson install -C host-build/
 ```
 
-### Build FFI bindings to Rutabaga
+### Install FFI bindings to Rutabaga
 
 ```sh
 cd $(crosvm_dir)/rutabaga_gfx/ffi/
-make
-sudo make install
+meson setup rutabaga-ffi-build/
+meson install -C rutabaga-ffi-build/
 ```
 
-### Guest-side gfxstream libraries
+### Install virglrenderer host
 
-If your VMM boots to a Linux guest, it's possible to run gfxstream with that.
+Rutabaga's C API can also be built with virglrenderer enabled. To use virglrenderer feature first
+install virglrenderer on the host.
 
 ```sh
-git clone https://android.googlesource.com/platform/hardware/google/gfxstream
-cd gfxstream/guest
+git clone https://gitlab.freedesktop.org/virgl/virglrenderer.git
+cd virglrenderer/
+git checkout virglrenderer-1.0.1
 meson setup build/
-meson install -C build
+meson install -C build/
 ```
 
-Some headless Vulkan tests (`deqp-vk`, `vulkaninfo`) should work after that, but others may not
-(such as `vulkan-samples`).
-
 ### Latest releases for potential packaging
 
 - [Rutabaga FFI v0.1.2](https://crates.io/crates/rutabaga_gfx_ffi)
-- [gfxstream v0.1.2](https://android-review.googlesource.com/c/platform/hardware/google/gfxstream/+/2710135)
-- [AEMU v0.1.2](https://android-review.googlesource.com/c/platform/hardware/google/aemu/+/2708637)
+- [gfxstream v0.1.2](https://android.googlesource.com/platform/hardware/google/gfxstream/+/refs/tags/v0.1.2-gfxstream-release)
+- [AEMU v0.1.2](https://android.googlesource.com/platform/hardware/google/aemu/+/refs/tags/v0.1.2-aemu-release)
+- [virglrenderer v1.0.1](https://gitlab.freedesktop.org/virgl/virglrenderer/-/tree/virglrenderer-1.0.1)
+
+# Kumquat Media Server
+
+The Kumquat Media server provides a way to test virtio multi-media protocols without a virtual
+machine. The following example shows how to run GL and Vulkan apps with `virtio-gpu` +
+`gfxstream-vulkan`. Full windowing will only work on platforms that support `dma_buf` and
+`dma_fence`.
+
+Only headless apps are likely to work on Nvidia, and requires
+[this change](https://crrev.com/c/5698371).
+
+## Build GPU-enabled server
+
+First install [libaemu](#install-libaemu) and the [gfxstream-host](#install-gfxstream-host), then:
+
+```sh
+cd $(crosvm_dir)/rutabaga_gfx/kumquat/server/
+cargo build --features=gfxstream
+```
+
+## Build and install client library
+
+```sh
+cd $(crosvm_dir)/rutabaga_gfx/kumquat/gpu_client/
+meson setup client-build
+ninja -C client-build/ install
+```
+
+## Build gfxstream guest
+
+The same repo as gfxstream host is used, but with a different build configuration.
+
+```sh
+cd $(gfxstream_dir)
+meson setup guest-build/ -Dgfxstream-build=guest
+ninja -C guest-build/
+```
+
+## Run apps
+
+In one terminal:
+
+```sh
+cd $(crosvm_dir)/rutabaga_gfx/kumquat/server/
+./target/debug/kumquat
+```
+
+In another terminal, run:
+
+```sh
+export MESA_LOADER_DRIVER_OVERRIDE=zink
+export VIRTGPU_KUMQUAT=1
+export VK_ICD_FILENAMES=$(gfxstream_dir)/guest-build/guest/vulkan/gfxstream_vk_devenv_icd.x86_64.json
+vkcube
+```
+
+# Linux guests
+
+To test gfxstream with Debian guests, make sure your display environment is headless.
+
+```
+systemctl set-default multi-user.target
+```
+
+Build gfxstream-vk:
+
+```sh
+cd $(gfxstream_dir)
+meson setup guest-build/ -Dgfxstream-build=guest
+ninja -C guest-build/
+```
+
+Start the compositor:
+
+```sh
+export MESA_LOADER_DRIVER_OVERRIDE=zink
+export VK_ICD_FILENAMES=$(gfxstream_dir)/guest-build/guest/vulkan/gfxstream_vk_devenv_icd.x86_64.json
+weston --backend=drm
+```
+
+# Contributing to gfxstream
+
+To contribute to gfxstream without an Android tree:
+
+```sh
+git clone https://android.googlesource.com/platform/hardware/google/gfxstream
+git commit -a -m blah
+git push origin HEAD:refs/for/main
+```
+
+The AOSP Gerrit instance will ask for an identity. Follow the instructions, a Google account is
+needed.
diff --git a/docs/book/src/building_crosvm/linux.md b/docs/book/src/building_crosvm/linux.md
index 6f2cde0c4..3bbbbe407 100644
--- a/docs/book/src/building_crosvm/linux.md
+++ b/docs/book/src/building_crosvm/linux.md
@@ -61,8 +61,11 @@ you wish to start fresh, use the `--clean` flag.
 
 ## Building a binary
 
-If you simply want to try crosvm, run `cargo build`. Then the binary is generated at
-`./target/debug/crosvm`. Now you can move to [Example Usage](../running_crosvm/example_usage.md).
+If you simply want to try crosvm, run `cargo build`. Then the executable is generated at
+`./target/debug/crosvm`. In case you are using development container, the executable will be inside
+the dev container at `/scratch/cargo_target/debug/crosvm`.
+
+Now you can move to [Example Usage](../running_crosvm/example_usage.md).
 
 If you want to enable [additional features](../running_crosvm/features.md), use the `--features`
 flag. (e.g. `cargo build --features=gdb`)
@@ -129,7 +132,7 @@ trade off speed and accuracy.
 ## Cross-compilation
 
 Crosvm is built and tested on x86, aarch64, armhf, and riscv64. Your system needs some setup work to
-be able to cross-comple for other architectures, hence it is recommended to use the
+be able to cross-compile for other architectures, hence it is recommended to use the
 [development container](#using-the-development-container), which will have everything configured.
 
 Note: Cross-compilation is **not supported on gLinux**. Please use the development container.
@@ -177,6 +180,18 @@ example config to your cargo configuration:
 cat .cargo/config.debian.toml >> ${CARGO_HOME:-~/.cargo}/config.toml
 ```
 
+**Note**
+
+In case of cross-compilation, crosvm executable would be at `./target/debug/<target>/crosvm`. If
+cross-compiling inside development container, the executable would be inside dev container at
+`/scratch/cargo_target/<target>/debug/crosvm`.
+
+e.g For aarch64, `target` will be `aarch64-unknown-linux-gnu` and you can build using
+
+```sh
+cargo build --target aarch64-unknown-linux-gnu
+```
+
 ## Known issues
 
 - Devices can't be jailed if `/var/empty` doesn't exist. `sudo mkdir -p /var/empty` to work around
diff --git a/docs/book/src/devices/pmem.md b/docs/book/src/devices/pmem.md
index 2470a1e58..279d63141 100644
--- a/docs/book/src/devices/pmem.md
+++ b/docs/book/src/devices/pmem.md
@@ -5,24 +5,23 @@ memory device. The disk image is provided to the guest using a memory-mapped vie
 and this mapping can be directly mapped into the guest's address space if the guest operating system
 and filesystem support [DAX](https://www.kernel.org/doc/html/latest/filesystems/dax.html).
 
-Pmem devices may be added to crosvm using the `--pmem-device` (read only) or `--rw-pmem-device`
-(read-write) flag, specifying the filename of the backing image as the parameter.
+Pmem devices may be added to crosvm using the `--pmem` flag, specifying the filename of the backing
+image as the parameter. By default, the pmem device will be writable; add `ro=true` to create a
+read-only pmem device instead.
 
 ```sh
 crosvm run \
-  --pmem-device disk.img \
+  --pmem disk.img \
   ... # usual crosvm args
 ```
 
 The Linux virtio-pmem driver can be enabled with the `CONFIG_VIRTIO_PMEM` option. It will expose
 pmem devices as `/dev/pmem0`, `/dev/pmem1`, etc., which may be mounted like any other block device.
-A pmem device may also be used as a root filesystem by adding a `root=` kernel command line
-parameters:
+A pmem device may also be used as the root filesystem by adding `root=true` to the `--pmem` flag:
 
 ```sh
 crosvm run \
-  --pmem-device rootfs.img \
-  -p "root=/dev/pmem0 ro" \
+  --pmem rootfs.img,root=true,ro=true \
   ... # usual crosvm args
 ```
 
diff --git a/docs/book/src/testing/index.md b/docs/book/src/testing/index.md
index 0441e06b9..aeb43f807 100644
--- a/docs/book/src/testing/index.md
+++ b/docs/book/src/testing/index.md
@@ -53,7 +53,16 @@ are only executed when a device-under-test (DUT) is specified when running tests
 End to end tests live in the `e2e_tests` crate. The crate provides a framework to boot a guest with
 crosvm and execut commands in the guest to validate functionality at a high level.
 
-E2E tests are executed just like integration tests.
+E2E tests are executed just like integration tests. By giving
+[nextest's filter expressions](https://nexte.st/book/filter-expressions), you can run a subset of
+the tests.
+
+```sh
+# Run all e2e tests
+./tools/run_tests --dut=vm --filter-expr 'package(e2e_tests)'
+# Run e2e tests whose name contains the string 'boot'.
+./tools/run_tests --dut=vm --filter-expr 'package(e2e_tests) and test(boot)'
+```
 
 ### Downstream Product tests
 
diff --git a/docs/book/src/tracing.md b/docs/book/src/tracing.md
index ff5fb500a..684c4bbda 100644
--- a/docs/book/src/tracing.md
+++ b/docs/book/src/tracing.md
@@ -123,7 +123,7 @@ pub fn process_fs_queue<F: FileSystem + Sync>(
         let total = server.handle_message(reader, writer, &mapper)?;
 
         queue.add_used(mem, avail_desc.index, total as u32);
-        queue.trigger_interrupt(mem, &*interrupt);
+        queue.trigger_interrupt();
     }
 ```
 
@@ -157,7 +157,7 @@ pub fn process_fs_queue<F: FileSystem + Sync>(
         let total = server.handle_message(reader, writer, &mapper)?;
 
         queue.add_used(mem, avail_desc.index, total as u32);
-        queue.trigger_interrupt(mem, &*interrupt);
+        queue.trigger_interrupt();
     }
 ```
 
diff --git a/e2e_tests/Cargo.toml b/e2e_tests/Cargo.toml
index 8bb410606..ffaa8f232 100644
--- a/e2e_tests/Cargo.toml
+++ b/e2e_tests/Cargo.toml
@@ -5,16 +5,16 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dev-dependencies]
-anyhow = "*"
+anyhow = "1"
 fixture = { path = "fixture" }
-libc = "*"
+libc = "0.2"
 net_util = {path = "../net_util"}
 rand = "0.8"
 tempfile = "3"
 prebuilts = { path = "../prebuilts" }
 base = { path = "../base" }
 swap = { path= "../swap" }
-serde_json = "*"
+serde_json = "1"
 
 [target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
 net_sys = {path = "../net_sys"}
diff --git a/e2e_tests/fixture/Cargo.toml b/e2e_tests/fixture/Cargo.toml
index 966e895f9..b3e026057 100644
--- a/e2e_tests/fixture/Cargo.toml
+++ b/e2e_tests/fixture/Cargo.toml
@@ -5,19 +5,19 @@ authors = ["The Chromium OS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 arch = { path = "../../arch" }
-base = "*"
+base = { path = "../../base" }
 crc32fast = "1.3"
-cfg-if = "*"
+cfg-if = "1"
 libc = "0.2.65"
 rand = "0.8"
 tempfile = "3"
 prebuilts = { path = "../../prebuilts" }
-log = "*"
+log = "0.4"
 shlex = "1.3"
 url = "2.3"
 delegate = {path = "../guest_under_test/rootfs/delegate"}
-serde = {version = "*", features = ["derive"]}
-serde_json = "*"
+serde = {version = "1", features = ["derive"]}
+serde_json = "1"
 readclock = { path = "../guest_under_test/rootfs/readclock" }
diff --git a/e2e_tests/fixture/src/sys/linux.rs b/e2e_tests/fixture/src/sys/linux.rs
index 9bba2b996..caab43fc0 100644
--- a/e2e_tests/fixture/src/sys/linux.rs
+++ b/e2e_tests/fixture/src/sys/linux.rs
@@ -189,7 +189,7 @@ impl TestVmSys {
         // Open pipes. Apply timeout to `to_guest` and `from_guest` since it will block until crosvm
         // opens the other end.
         let start = Instant::now();
-        let (to_guest, from_guest) = match run_with_status_check(
+        let run_result = run_with_status_check(
             move || (File::create(to_guest_pipe), File::open(from_guest_pipe)),
             Duration::from_millis(200),
             || {
@@ -203,7 +203,9 @@ impl TestVmSys {
                     true
                 }
             },
-        ) {
+        );
+
+        let (to_guest, from_guest) = match run_result {
             Ok((to_guest, from_guest)) => (
                 to_guest.context("Cannot open to_guest pipe")?,
                 from_guest.context("Cannot open from_guest pipe")?,
diff --git a/e2e_tests/fixture/src/utils.rs b/e2e_tests/fixture/src/utils.rs
index 762c379fb..618b3ad1f 100644
--- a/e2e_tests/fixture/src/utils.rs
+++ b/e2e_tests/fixture/src/utils.rs
@@ -220,3 +220,38 @@ pub fn create_vu_block_config(cmd_type: CmdType, socket: &Path, disk: &Path) ->
         ]),
     }
 }
+
+pub fn create_vu_console_multiport_config(
+    socket: &Path,
+    file_path: Vec<(PathBuf, PathBuf)>,
+) -> VuConfig {
+    let socket_path = socket.to_str().unwrap();
+
+    let mut args = vec![
+        "console".to_string(),
+        "--socket".to_string(),
+        socket_path.to_string(),
+    ];
+
+    for (i, (output_file, input_file)) in file_path.iter().enumerate() {
+        args.push("--port".to_string());
+        match input_file.file_name().is_some() {
+            true => {
+                args.push(format!(
+                    "type=file,hardware=virtio-console,name=port{},path={},input={}",
+                    i,
+                    output_file.to_str().unwrap(),
+                    input_file.to_str().unwrap(),
+                ));
+            }
+            false => {
+                args.push(format!(
+                    "type=file,hardware=virtio-console,name=port{},path={}",
+                    i,
+                    output_file.to_str().unwrap(),
+                ));
+            }
+        };
+    }
+    VuConfig::new(CmdType::Device, "console").extra_args(args)
+}
diff --git a/e2e_tests/fixture/src/vm.rs b/e2e_tests/fixture/src/vm.rs
index ee5197832..756da92bf 100644
--- a/e2e_tests/fixture/src/vm.rs
+++ b/e2e_tests/fixture/src/vm.rs
@@ -269,7 +269,7 @@ impl Config {
     }
 
     pub fn with_stdout_hardware(mut self, hw_type: &str) -> Self {
-        self.console_hardware = hw_type.to_owned();
+        self.console_hardware = hw_type.into();
         self
     }
 
@@ -282,6 +282,14 @@ impl Config {
         ));
         self
     }
+
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    pub fn with_vhost_user_fs(mut self, socket_path: &Path, tag: &str) -> Self {
+        self.extra_args.push("--vhost-user-fs".to_string());
+        self.extra_args
+            .push(format!("{},tag={}", socket_path.to_str().unwrap(), tag));
+        self
+    }
 }
 
 static PREP_ONCE: Once = Once::new();
diff --git a/e2e_tests/guest_under_test/PREBUILT_VERSION b/e2e_tests/guest_under_test/PREBUILT_VERSION
index abb534b96..36ad70f3b 100644
--- a/e2e_tests/guest_under_test/PREBUILT_VERSION
+++ b/e2e_tests/guest_under_test/PREBUILT_VERSION
@@ -1,2 +1,2 @@
-r0014
+r0015
 
diff --git a/e2e_tests/guest_under_test/kernel/common.config b/e2e_tests/guest_under_test/kernel/common.config
index 3d0a6463c..5a94707ea 100644
--- a/e2e_tests/guest_under_test/kernel/common.config
+++ b/e2e_tests/guest_under_test/kernel/common.config
@@ -22,7 +22,6 @@ CONFIG_IKCONFIG_PROC=y
 # Virtio devices
 CONFIG_VIRTIO_VSOCKETS=y
 CONFIG_VIRTIO_PCI=y
-CONFIG_VIRTIO_PMEM=y
 CONFIG_VIRTIO_BALLOON=y
 CONFIG_VIRTIO_PVCLOCK=y
 CONFIG_VSOCKETS=y
@@ -71,3 +70,7 @@ CONFIG_RD_GZIP=y
 CONFIG_SCSI=y
 CONFIG_BLK_DEV_SD=y
 CONFIG_SCSI_VIRTIO=y
+
+# Pmem device
+CONFIG_LIBNVDIMM=y
+CONFIG_VIRTIO_PMEM=y
diff --git a/e2e_tests/guest_under_test/rootfs/delegate/Cargo.toml b/e2e_tests/guest_under_test/rootfs/delegate/Cargo.toml
index 0c733f014..af7ffb827 100644
--- a/e2e_tests/guest_under_test/rootfs/delegate/Cargo.toml
+++ b/e2e_tests/guest_under_test/rootfs/delegate/Cargo.toml
@@ -5,5 +5,5 @@ authors = ["The Chromium OS Authors"]
 edition = "2021"
 
 [dependencies]
-serde = {version = "*", features = ["derive"]}
-serde_json = "*"
+serde = {version = "1", features = ["derive"]}
+serde_json = "1"
diff --git a/e2e_tests/guest_under_test/rootfs/readclock/Android.bp b/e2e_tests/guest_under_test/rootfs/readclock/Android.bp
index 0cc1cc5f2..60c5675bf 100644
--- a/e2e_tests/guest_under_test/rootfs/readclock/Android.bp
+++ b/e2e_tests/guest_under_test/rootfs/readclock/Android.bp
@@ -14,7 +14,7 @@ rust_library {
     crate_name: "readclock",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
@@ -31,7 +31,7 @@ rust_binary {
     crate_name: "readclock",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/main.rs"],
+    crate_root: "src/main.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/e2e_tests/guest_under_test/rootfs/readclock/Cargo.toml b/e2e_tests/guest_under_test/rootfs/readclock/Cargo.toml
index 6f7f5a0c9..725d5b2a5 100644
--- a/e2e_tests/guest_under_test/rootfs/readclock/Cargo.toml
+++ b/e2e_tests/guest_under_test/rootfs/readclock/Cargo.toml
@@ -9,7 +9,7 @@ authors = ["The Chromium OS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
-libc = "*"
-serde = {version = "*", features = ["derive"]}
-serde_json = "*"
+anyhow = "1"
+libc = "0.2"
+serde = {version = "1", features = ["derive"]}
+serde_json = "1"
diff --git a/e2e_tests/tests/console.rs b/e2e_tests/tests/console.rs
new file mode 100644
index 000000000..06f9b3963
--- /dev/null
+++ b/e2e_tests/tests/console.rs
@@ -0,0 +1,273 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Testing virtio-console multiport feature.
+
+#![cfg(any(target_os = "android", target_os = "linux"))]
+
+use std::ffi::CString;
+use std::fs::read_to_string;
+use std::fs::OpenOptions;
+use std::io::Read;
+use std::io::Write;
+use std::path::PathBuf;
+
+use base::error;
+use base::EventToken;
+use base::WaitContext;
+use base::WorkerThread;
+use fixture::utils::create_vu_console_multiport_config;
+use fixture::vhost_user::VhostUserBackend;
+use fixture::vm::Config as VmConfig;
+use fixture::vm::TestVm;
+use tempfile::NamedTempFile;
+use tempfile::TempDir;
+
+fn run_vhost_user_console_multiport_test_portname(config: VmConfig) -> anyhow::Result<()> {
+    let socket = NamedTempFile::new().unwrap();
+    let temp_dir = TempDir::new()?;
+
+    // Prepare 2 virtio-console with only output
+    let file_path = vec![
+        (temp_dir.path().join("vconsole0.out"), PathBuf::new()),
+        (temp_dir.path().join("vconsole1.out"), PathBuf::new()),
+    ];
+    let vu_config = create_vu_console_multiport_config(socket.path(), file_path.clone());
+    let _vu_device = VhostUserBackend::new(vu_config).unwrap();
+
+    let config = config.extra_args(vec![
+        "--mem".to_owned(),
+        "512".to_owned(),
+        "--vhost-user-console".to_string(),
+        socket.path().to_str().unwrap().to_string(),
+    ]);
+    let mut vm = TestVm::new(config).unwrap();
+
+    // mount sysfs to check details
+    vm.exec_in_guest("mount -t sysfs sysfs /sys")?;
+
+    // Get portlist
+    let result = vm
+        .exec_in_guest("ls /sys/class/virtio-ports/")
+        .expect("No virtio-ports dir");
+    let mut portlist: Vec<&str> = result.stdout.trim_end().split('\n').collect();
+    // Remove serial virtio-console created defaultly
+    portlist.remove(0);
+    for (i, port) in portlist.into_iter().enumerate() {
+        let portname = vm
+            .exec_in_guest(format!("cat /sys/class/virtio-ports/{}/name", port).as_str())
+            .expect("Failed to read portname")
+            .stdout;
+        assert_eq!(portname.trim_end(), format!("port{}", i).as_str());
+    }
+    Ok(())
+}
+
+/// Tests vhost-user console device with `crosvm device`.
+#[test]
+fn vhost_user_console_portname_check() -> anyhow::Result<()> {
+    let config = VmConfig::new();
+    run_vhost_user_console_multiport_test_portname(config)?;
+    Ok(())
+}
+
+fn run_vhost_user_console_multiport_test_output(config: VmConfig) -> anyhow::Result<()> {
+    let socket = NamedTempFile::new().unwrap();
+    let temp_dir = TempDir::new()?;
+
+    // Prepare 2 virtio-console with only output
+    let file_path = vec![
+        (temp_dir.path().join("vconsole0.out"), PathBuf::new()),
+        (temp_dir.path().join("vconsole1.out"), PathBuf::new()),
+    ];
+    let vu_config = create_vu_console_multiport_config(socket.path(), file_path.clone());
+    let _vu_device = VhostUserBackend::new(vu_config).unwrap();
+
+    let config = config.extra_args(vec![
+        "--mem".to_owned(),
+        "512".to_owned(),
+        "--vhost-user-console".to_string(),
+        socket.path().to_str().unwrap().to_string(),
+    ]);
+    let mut vm = TestVm::new(config).unwrap();
+
+    // mount sysfs to check details
+    vm.exec_in_guest("mount -t sysfs sysfs /sys")?;
+
+    // Get portlist
+    let result = vm
+        .exec_in_guest("ls /sys/class/virtio-ports/")
+        .expect("No virtio-ports dir");
+    let mut portlist: Vec<&str> = result.stdout.trim_end().split('\n').collect();
+    // Remove serial virtio-console created defaultly
+    portlist.remove(0);
+
+    // Test output flow.
+    for (i, port) in portlist.into_iter().enumerate() {
+        vm.exec_in_guest(format!("echo \"hello {}\" > /dev/{}", port, port).as_str())
+            .expect("Failed to echo data to port");
+
+        let data = read_to_string(&file_path[i].0).expect("vu-console: read output failed");
+
+        assert_eq!(data.trim(), format!("hello {}", port).as_str());
+    }
+    Ok(())
+}
+
+#[test]
+fn vhost_user_console_check_output() -> anyhow::Result<()> {
+    let config = VmConfig::new();
+    run_vhost_user_console_multiport_test_output(config)?;
+    Ok(())
+}
+
+/// Generate the workthread to monitor input and transmit data to output fifo
+///
+/// Create fifo according to input and output name.
+/// Then spawn a thread to monitor them, simultaneously watch a kill_event to stop thread.
+fn generate_workthread_to_monitor_fifo(
+    idx: usize,
+    infile: PathBuf,
+    outfile: PathBuf,
+) -> WorkerThread<()> {
+    #[derive(EventToken)]
+    enum Token {
+        InputDataAvailable,
+        Kill,
+    }
+    let cpath_in = CString::new(infile.to_str().unwrap()).unwrap();
+    let cpath_out = CString::new(outfile.to_str().unwrap()).unwrap();
+    // SAFETY: make two fifos here for monitor thread, path is guaranteed to be valid
+    unsafe {
+        libc::mkfifo(cpath_in.as_ptr(), 0o777);
+        libc::mkfifo(cpath_out.as_ptr(), 0o777);
+    }
+    WorkerThread::start(format!("monitor_vconsole{}", idx), move |kill_event| {
+        let mut tx = OpenOptions::new().write(true).open(outfile).unwrap();
+        let mut rx = OpenOptions::new().read(true).open(infile).unwrap();
+        let mut msg = vec![0; 256];
+        let wait_ctx: WaitContext<Token> = match WaitContext::build_with(&[
+            (&rx, Token::InputDataAvailable),
+            (&kill_event, Token::Kill),
+        ]) {
+            Ok(wait_ctx) => wait_ctx,
+            Err(e) => {
+                error!("failed creating WaitContext: {}", e);
+                return;
+            }
+        };
+        'monitor_loop: loop {
+            let wait_events = match wait_ctx.wait() {
+                Ok(wait_events) => wait_events,
+                Err(e) => {
+                    error!("failed polling for events: {}", e);
+                    break;
+                }
+            };
+            for wait_event in wait_events.iter().filter(|e| e.is_readable) {
+                match wait_event.token {
+                    Token::InputDataAvailable => {
+                        let bytes = rx.read(&mut msg).expect("Failed to read from port");
+                        if bytes > 0 {
+                            if tx.write_all(&msg.to_ascii_uppercase()[..bytes]).is_err() {
+                                break 'monitor_loop;
+                            }
+                        }
+                    }
+                    Token::Kill => break 'monitor_loop,
+                }
+            }
+        }
+    })
+}
+
+/// Tests vhost-user-console input function with multiport feature.
+///
+/// If we want to test multiport function about input flow,
+/// we need to prepare monitor threads for each ports.
+/// The purpose of this thread is to get all data from rx queue, and transmit them to tx queue.
+/// To increase reliability, monitor thread changes data to uppercase.
+///
+/// Once monitor threads created, VhostUserBackend for console will work as expected.
+fn run_vhost_user_console_multiport_test_input(config: VmConfig) -> anyhow::Result<()> {
+    let socket = NamedTempFile::new().unwrap();
+    let temp_dir = TempDir::new()?;
+
+    // Prepare 2 virtio-console with both input and output
+    let mut file_path = vec![];
+    for idx in 0..2 {
+        let fifo_name_out = format!("vconsole{}.out", idx);
+        let fifo_name_in = format!("vconsole{}.in", idx);
+        file_path.push((
+            temp_dir.path().join(fifo_name_out),
+            temp_dir.path().join(fifo_name_in),
+        ));
+    }
+
+    let mut thread_vec = vec![];
+    for idx in 0..2 {
+        thread_vec.push(generate_workthread_to_monitor_fifo(
+            idx,
+            (*file_path.get(idx).unwrap().0).to_path_buf(),
+            (*file_path.get(idx).unwrap().1).to_path_buf(),
+        ));
+    }
+
+    let vu_config = create_vu_console_multiport_config(socket.path(), file_path.clone());
+    let _vu_device = VhostUserBackend::new(vu_config).unwrap();
+
+    let config = config.extra_args(vec![
+        "--mem".to_owned(),
+        "512".to_owned(),
+        "--vhost-user-console".to_string(),
+        socket.path().to_str().unwrap().to_string(),
+    ]);
+    let mut vm = TestVm::new(config).unwrap();
+
+    // mount sysfs to check details
+    vm.exec_in_guest("mount -t sysfs sysfs /sys")?;
+
+    // Get portlist
+    let result = vm
+        .exec_in_guest("ls /sys/class/virtio-ports/")
+        .expect("No virtio-ports dir");
+    let mut portlist: Vec<&str> = result.stdout.trim_end().split('\n').collect();
+    // Remove serial virtio-console created defaultly
+    portlist.remove(0);
+
+    let file_fd = 5;
+    // Test input flow.
+    for port in portlist.into_iter() {
+        // Bind file_fd to operate /dev/vportXpX, then write to fd, finnally read it.
+        let result = vm
+            .exec_in_guest(
+                format!(
+                    "exec {}<>/dev/{} && echo \"hello {}\" >&{} && head -1 <&{}",
+                    file_fd, port, port, file_fd, file_fd
+                )
+                .as_str(),
+            )
+            .expect("Failed to echo data to port")
+            .stdout;
+        // Close this fd
+        vm.exec_in_guest(format!("exec {}>&-", file_fd).as_str())
+            .expect("Failed to close device fd");
+        // In monitor thread, tx message will change to uppercase
+        assert_eq!(
+            result.trim_end(),
+            format!("hello {}", port).to_uppercase().as_str()
+        );
+    }
+    for handler in thread_vec.into_iter() {
+        handler.stop();
+    }
+    Ok(())
+}
+
+#[test]
+fn vhost_user_console_check_input() -> anyhow::Result<()> {
+    let config = VmConfig::new();
+    run_vhost_user_console_multiport_test_input(config)?;
+    Ok(())
+}
diff --git a/e2e_tests/tests/fs.rs b/e2e_tests/tests/fs.rs
index 6161e0f54..1e1a1c3f7 100644
--- a/e2e_tests/tests/fs.rs
+++ b/e2e_tests/tests/fs.rs
@@ -4,27 +4,80 @@
 
 //! Testing virtio-fs.
 
+#![cfg(any(target_os = "android", target_os = "linux"))]
+
+use std::path::Path;
+
+use fixture::vhost_user::CmdType;
+use fixture::vhost_user::Config as VuConfig;
+use fixture::vhost_user::VhostUserBackend;
 use fixture::vm::Config;
 use fixture::vm::TestVm;
+use tempfile::NamedTempFile;
+use tempfile::TempDir;
 
-/// Tests file copy on virtiofs
+/// Tests file copy
 ///
 /// 1. Create `original.txt` on a temporal directory.
 /// 2. Start a VM with a virtiofs device for the temporal directory.
 /// 3. Copy `original.txt` to `new.txt` in the guest.
 /// 4. Check that `new.txt` is created in the host.
-#[test]
-fn copy_file() {
+fn copy_file(mut vm: TestVm, tag: &str, dir: TempDir) {
     const ORIGINAL_FILE_NAME: &str = "original.txt";
     const NEW_FILE_NAME: &str = "new.txt";
     const TEST_DATA: &str = "virtiofs works!";
 
-    let temp_dir = tempfile::tempdir().unwrap();
-    let orig_file = temp_dir.path().join(ORIGINAL_FILE_NAME);
+    let orig_file = dir.path().join(ORIGINAL_FILE_NAME);
 
     std::fs::write(orig_file, TEST_DATA).unwrap();
 
+    // TODO(b/269137600): Split this into multiple lines instead of connecting commands with `&&`.
+    vm.exec_in_guest(&format!(
+        "mount -t virtiofs {tag} /mnt && cp /mnt/{} /mnt/{} && sync",
+        ORIGINAL_FILE_NAME, NEW_FILE_NAME,
+    ))
+    .unwrap();
+
+    let new_file = dir.path().join(NEW_FILE_NAME);
+    let contents = std::fs::read(new_file).unwrap();
+    assert_eq!(TEST_DATA.as_bytes(), &contents);
+}
+
+/// Tests mount/read/create/write
+/// 1. Create `read_file.txt` with test data in host's temporal directory.
+/// 2. Start a VM with a virtiofs device for the temporal directory.
+/// 3. Guest reads read_file.txt file & verify the content is test data
+/// 4. Guest creates a write_file.txt file in shared directory
+/// 5. Host reads file from host's temporal directory & verify content is test data
+fn mount_rw(mut vm: TestVm, tag: &str, dir: TempDir) {
+    const READ_FILE_NAME: &str = "read_test.txt";
+    const WRITE_FILE_NAME: &str = "write_test.txt";
+    const TEST_DATA: &str = "hello world";
+
+    let read_test_file = dir.path().join(READ_FILE_NAME);
+    let write_test_file = dir.path().join(WRITE_FILE_NAME);
+    std::fs::write(read_test_file, TEST_DATA).unwrap();
+
+    assert_eq!(
+        vm.exec_in_guest(&format!(
+            "mount -t virtiofs {tag} /mnt && cat /mnt/read_test.txt"
+        ))
+        .unwrap()
+        .stdout
+        .trim(),
+        TEST_DATA
+    );
+
+    const IN_FS_WRITE_FILE_PATH: &str = "/mnt/write_test.txt";
+    let _ = vm.exec_in_guest(&format!("echo -n {TEST_DATA} > {IN_FS_WRITE_FILE_PATH}"));
+    let read_contents = std::fs::read(write_test_file).unwrap();
+    assert_eq!(TEST_DATA.as_bytes(), &read_contents);
+}
+
+#[test]
+fn fs_copy_file() {
     let tag = "mtdtest";
+    let temp_dir = tempfile::tempdir().unwrap();
 
     let config = Config::new().extra_args(vec![
         "--shared-dir".to_string(),
@@ -34,17 +87,25 @@ fn copy_file() {
         ),
     ]);
 
-    let mut vm = TestVm::new(config).unwrap();
-    // TODO(b/269137600): Split this into multiple lines instead of connecting commands with `&&`.
-    vm.exec_in_guest(&format!(
-        "mount -t virtiofs {tag} /mnt && cp /mnt/{} /mnt/{} && sync",
-        ORIGINAL_FILE_NAME, NEW_FILE_NAME,
-    ))
-    .unwrap();
+    let vm = TestVm::new(config).unwrap();
+    copy_file(vm, tag, temp_dir)
+}
 
-    let new_file = temp_dir.path().join(NEW_FILE_NAME);
-    let contents = std::fs::read(new_file).unwrap();
-    assert_eq!(TEST_DATA.as_bytes(), &contents);
+#[test]
+fn fs_mount_rw() {
+    let tag = "mtdtest";
+    let temp_dir = tempfile::tempdir().unwrap();
+
+    let config = Config::new().extra_args(vec![
+        "--shared-dir".to_string(),
+        format!(
+            "{}:{tag}:type=fs:cache=auto",
+            temp_dir.path().to_str().unwrap()
+        ),
+    ]);
+
+    let vm = TestVm::new(config).unwrap();
+    mount_rw(vm, tag, temp_dir)
 }
 
 /// Tests file ownership seen by the VM.
@@ -54,7 +115,6 @@ fn copy_file() {
 /// 3. Start a VM with a virtiofs device for the temporal directory.
 /// 4. Check that `user_file.txt`'s uid is <mapped-uid> in the VM.
 /// 5. Verify gid similarly.
-#[cfg(any(target_os = "android", target_os = "linux"))]
 #[test]
 fn file_ugid() {
     const FILE_NAME: &str = "user_file.txt";
@@ -62,7 +122,7 @@ fn file_ugid() {
     let gid = base::getegid();
     let mapped_uid: u32 = rand::random();
     let mapped_gid: u32 = rand::random();
-    let uid_map = format!("{} {} 1", mapped_uid, uid);
+    let uid_map: String = format!("{} {} 1", mapped_uid, uid);
     let gid_map = format!("{} {} 1", mapped_gid, gid);
 
     let temp_dir = tempfile::tempdir().unwrap();
@@ -101,3 +161,55 @@ fn file_ugid() {
     assert!(output.stdout.contains(&format!("Uid: ({}/", mapped_uid)));
     assert!(output.stdout.contains(&format!("Gid: ({}/", mapped_gid)));
 }
+
+pub fn create_vu_fs_config(socket: &Path, shared_dir: &Path, tag: &str) -> VuConfig {
+    let uid = base::geteuid();
+    let gid = base::getegid();
+    let socket_path = socket.to_str().unwrap();
+    let shared_dir_path = shared_dir.to_str().unwrap();
+    println!("socket={socket_path}, tag={tag}, shared_dir={shared_dir_path}");
+    VuConfig::new(CmdType::Device, "vhost-user-fs").extra_args(vec![
+        "fs".to_string(),
+        format!("--socket={socket_path}"),
+        format!("--shared-dir={shared_dir_path}"),
+        format!("--tag={tag}"),
+        format!("--uid-map=0 {uid} 1"),
+        format!("--gid-map=0 {gid} 1"),
+    ])
+}
+
+/// Tests vhost-user fs device copy file.
+#[test]
+fn vhost_user_fs_copy_file() {
+    let socket = NamedTempFile::new().unwrap();
+    let temp_dir = tempfile::tempdir().unwrap();
+
+    let config = Config::new();
+    let tag = "mtdtest";
+
+    let vu_config = create_vu_fs_config(socket.path(), temp_dir.path(), tag);
+    let _vu_device = VhostUserBackend::new(vu_config).unwrap();
+
+    let config = config.with_vhost_user_fs(socket.path(), tag);
+    let vm = TestVm::new(config).unwrap();
+
+    copy_file(vm, tag, temp_dir);
+}
+
+/// Tests vhost-user fs device mount and read write.
+#[test]
+fn vhost_user_fs_mount_rw() {
+    let socket = NamedTempFile::new().unwrap();
+    let temp_dir = tempfile::tempdir().unwrap();
+
+    let config = Config::new();
+    let tag = "mtdtest";
+
+    let vu_config = create_vu_fs_config(socket.path(), temp_dir.path(), tag);
+    let _vu_device = VhostUserBackend::new(vu_config).unwrap();
+
+    let config = config.with_vhost_user_fs(socket.path(), tag);
+    let vm = TestVm::new(config).unwrap();
+
+    mount_rw(vm, tag, temp_dir);
+}
diff --git a/e2e_tests/tests/goldens/backcompat_test_simple_lspci.txt b/e2e_tests/tests/goldens/backcompat_test_simple_lspci.txt
index 0c94f9db2..6ac5cbc8d 100644
--- a/e2e_tests/tests/goldens/backcompat_test_simple_lspci.txt
+++ b/e2e_tests/tests/goldens/backcompat_test_simple_lspci.txt
@@ -1,8 +1,8 @@
 00:00.0 0600: 8086:1237
-00:01.0 00ff: 1af4:1043 (rev 01)
+00:01.0 0780: 1af4:1043 (rev 01)
 00:02.0 0180: 1af4:1042 (rev 01)
-00:03.0 00ff: 1af4:1044 (rev 01)
-00:04.0 00ff: 1af4:1045 (rev 01)
+00:03.0 0880: 1af4:1044 (rev 01)
+00:04.0 0880: 1af4:1045 (rev 01)
 00:05.0 0c03: 1b73:1400
 00:06.0 ffff: 1b36:0011 (rev 01)
 00:07.0 0604: 8086:3420
diff --git a/e2e_tests/tests/goldens/backcompat_test_simple_lspci_win.txt b/e2e_tests/tests/goldens/backcompat_test_simple_lspci_win.txt
index 28a4edcc5..cff87925f 100644
--- a/e2e_tests/tests/goldens/backcompat_test_simple_lspci_win.txt
+++ b/e2e_tests/tests/goldens/backcompat_test_simple_lspci_win.txt
@@ -1,8 +1,8 @@
 00:00.0 0600: 8086:1237
-00:01.0 00ff: 1af4:1043 (rev 01)
+00:01.0 0780: 1af4:1043 (rev 01)
 00:02.0 0180: 1af4:1042 (rev 01)
-00:03.0 00ff: 1af4:1044 (rev 01)
-00:04.0 00ff: 1af4:1045 (rev 01)
+00:03.0 0880: 1af4:1044 (rev 01)
+00:04.0 0880: 1af4:1045 (rev 01)
 00:05.0 0c03: 1b73:1400
 00:06.0 ffff: 1b36:0011 (rev 01)
 00:07.0 0604: 8086:3420
diff --git a/e2e_tests/tests/pci_hotplug.rs b/e2e_tests/tests/pci_hotplug.rs
index b0371f7d4..8bd8ae08f 100644
--- a/e2e_tests/tests/pci_hotplug.rs
+++ b/e2e_tests/tests/pci_hotplug.rs
@@ -49,7 +49,7 @@ fn setup_tap_device(tap_name: &[u8], ip_addr: Ipv4Addr, netmask: Ipv4Addr, mac_a
     let tap = Tap::new_with_name(tap_name, true, false).unwrap();
     // SAFETY:
     // ioctl is safe since we call it with a valid tap fd and check the return value.
-    let ret = unsafe { ioctl_with_val(&tap, net_sys::TUNSETPERSIST(), 1) };
+    let ret = unsafe { ioctl_with_val(&tap, net_sys::TUNSETPERSIST, 1) };
     if ret < 0 {
         panic!("Failed to persist tap interface");
     }
@@ -74,7 +74,7 @@ fn tap_hotplug_two_impl() {
     let config = Config::new().extra_args(vec!["--pci-hotplug-slots".to_owned(), "2".to_owned()]);
     let mut vm = TestVm::new(config).unwrap();
 
-    //Setup test taps.
+    //Setup test taps. tap_name has to be distinct per test, or it may appear flaky (b/333090169).
     let tap1_name = "test_tap1";
     setup_tap_device(
         tap1_name.as_bytes(),
@@ -151,8 +151,8 @@ fn tap_hotplug_add_remove_add_impl() {
     let config = Config::new().extra_args(vec!["--pci-hotplug-slots".to_owned(), "1".to_owned()]);
     let mut vm = TestVm::new(config).unwrap();
 
-    //Setup test tap
-    let tap_name = "test_tap";
+    //Setup test tap. tap_name has to be distinct per test, or it may appear flaky (b/333090169).
+    let tap_name = "test_tap3";
     setup_tap_device(
         tap_name.as_bytes(),
         "100.115.92.5".parse().unwrap(),
@@ -201,7 +201,6 @@ fn tap_hotplug_add_remove_add_impl() {
 
 /// Checks tap hotplug works with a device added, removed, then added again.
 #[test]
-#[ignore = "b/333090169 test is flaky"]
 fn tap_hotplug_add_remove_add() {
     call_test_with_sudo("tap_hotplug_add_remove_add_impl");
 }
@@ -217,11 +216,19 @@ fn tap_hotplug_add_remove_rapid_add_impl() {
     let config = Config::new().extra_args(vec!["--pci-hotplug-slots".to_owned(), "1".to_owned()]);
     let mut vm = TestVm::new(config).unwrap();
 
-    //Setup test tap
-    let tap_name = "test_tap";
+    //Setup test tap. tap_name has to be distinct per test, or it may appear flaky (b/333090169).
+    let tap_name_a = "test_tap4";
     setup_tap_device(
-        tap_name.as_bytes(),
-        "100.115.92.5".parse().unwrap(),
+        tap_name_a.as_bytes(),
+        "100.115.92.9".parse().unwrap(),
+        "255.255.255.252".parse().unwrap(),
+        "a0:b0:c0:d0:e0:f0".parse().unwrap(),
+    );
+
+    let tap_name_b = "test_tap5";
+    setup_tap_device(
+        tap_name_b.as_bytes(),
+        "100.115.92.1".parse().unwrap(),
         "255.255.255.252".parse().unwrap(),
         "a0:b0:c0:d0:e0:f0".parse().unwrap(),
     );
@@ -232,7 +239,7 @@ fn tap_hotplug_add_remove_rapid_add_impl() {
         wait_timeout
     ));
     // Hotplug tap.
-    vm.hotplug_tap(tap_name).unwrap();
+    vm.hotplug_tap(tap_name_a).unwrap();
     // Wait until virtio-net device appears in guest OS.
     assert!(poll_until_true(
         &mut vm,
@@ -242,7 +249,7 @@ fn tap_hotplug_add_remove_rapid_add_impl() {
 
     // Remove hotplugged tap device, then hotplug again without waiting for guest.
     vm.remove_pci_device(1).unwrap();
-    vm.hotplug_tap(tap_name).unwrap();
+    vm.hotplug_tap(tap_name_b).unwrap();
 
     // Wait for a while that the guest likely noticed the removal.
     thread::sleep(Duration::from_millis(500));
@@ -256,14 +263,17 @@ fn tap_hotplug_add_remove_rapid_add_impl() {
 
     drop(vm);
     Command::new("ip")
-        .args(["link", "delete", tap_name])
+        .args(["link", "delete", tap_name_a])
+        .status()
+        .unwrap();
+    Command::new("ip")
+        .args(["link", "delete", tap_name_b])
         .status()
         .unwrap();
 }
 
 /// Checks tap hotplug works with a device added, removed, then rapidly added again.
 #[test]
-#[ignore = "b/333090169 test is flaky"]
 fn tap_hotplug_add_remove_rapid_add() {
     call_test_with_sudo("tap_hotplug_add_remove_rapid_add_impl");
 }
diff --git a/e2e_tests/tests/pmem.rs b/e2e_tests/tests/pmem.rs
new file mode 100644
index 000000000..ed10b8502
--- /dev/null
+++ b/e2e_tests/tests/pmem.rs
@@ -0,0 +1,54 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Testing virtio-pmem.
+
+#![cfg(any(target_os = "android", target_os = "linux"))]
+
+use fixture::utils::prepare_disk_img;
+use fixture::vm::Config as VmConfig;
+use fixture::vm::TestVm;
+
+/// Tests virtio-pmem device is mountable.
+#[test]
+fn test_mount_pmem() {
+    mount_pmem(VmConfig::new());
+}
+
+/// Tests virtio-pmem device is mountable with sandbox disabled.
+#[test]
+fn test_mount_pmem_disable_sandbox() {
+    mount_pmem(VmConfig::new().disable_sandbox());
+}
+
+fn mount_pmem(config: VmConfig) {
+    let disk = prepare_disk_img();
+    let disk_path = disk.path().to_str().unwrap();
+    let config = config.extra_args(vec!["--pmem".to_string(), format!("{},ro", disk_path)]);
+
+    let mut vm = TestVm::new(config).unwrap();
+    vm.exec_in_guest("mount -t ext4 /dev/pmem0 /mnt")
+        .expect("Failed to mount pmem device");
+}
+
+/// Tests VMA virtio-pmem to be created successfully with the correct size.
+#[test]
+fn test_vma_pmem() {
+    let vma_size = 1 << 30; // 1GiB
+    let config = VmConfig::new().extra_args(vec![
+        "--pmem".to_string(),
+        format!("vma_pmem,vma-size={},swap-interval-ms=0", vma_size),
+    ]);
+
+    let mut vm = TestVm::new(config).unwrap();
+    assert_eq!(
+        vm.exec_in_guest("blockdev --getsize64 /dev/pmem0")
+            .unwrap()
+            .stdout
+            .trim()
+            .parse::<u64>()
+            .unwrap(),
+        vma_size
+    );
+}
diff --git a/e2e_tests/tests/pmem_ext2.rs b/e2e_tests/tests/pmem_ext2.rs
new file mode 100644
index 000000000..34b6d00be
--- /dev/null
+++ b/e2e_tests/tests/pmem_ext2.rs
@@ -0,0 +1,212 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Testing pmem-ext2 device.
+
+#![cfg(any(target_os = "android", target_os = "linux"))]
+
+use std::os::unix::fs::symlink;
+
+use fixture::vm::Config;
+use fixture::vm::TestVm;
+
+/// Check file contents on pmem-ext2
+#[test]
+fn pmem_ext2() -> anyhow::Result<()> {
+    // /temp_dir/
+    //  a.txt
+    //  dir
+    //      b.txt
+    //      symlink_a -> ../a.txt
+
+    const A_TXT_NAME: &str = "a.txt";
+    const A_TXT_DATA: &str = "Hello!";
+    const DIR_NAME: &str = "dir";
+    const B_TXT_NAME: &str = "b.txt";
+    const B_TXT_DATA: &str = "test test test\ntest test test";
+    const SYMLINK_A_NAME: &str = "symlink_a";
+    const SYMLINK_A_DEST: &str = "../a.txt";
+
+    let temp_dir = tempfile::tempdir()?;
+    let a_txt = temp_dir.path().join(A_TXT_NAME);
+    std::fs::write(a_txt, A_TXT_DATA)?;
+    let dir = temp_dir.path().join(DIR_NAME);
+    std::fs::create_dir(&dir)?;
+    let b_txt = dir.join(B_TXT_NAME);
+    std::fs::write(b_txt, B_TXT_DATA)?;
+    let symlink_a = dir.join(SYMLINK_A_NAME);
+    symlink(SYMLINK_A_DEST, symlink_a)?;
+
+    let config = Config::new().extra_args(vec![
+        "--pmem-ext2".to_string(),
+        temp_dir.path().to_str().unwrap().to_string(),
+    ]);
+
+    let mut vm = TestVm::new(config)?;
+    vm.exec_in_guest("mount -t ext2 /dev/pmem0 /mnt/")?;
+
+    // List all files
+    let find_result = vm
+        .exec_in_guest_async("find /mnt/ | sort")?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm)?;
+    assert_eq!(
+        find_result.stdout.trim(),
+        r"/mnt/
+/mnt/a.txt
+/mnt/dir
+/mnt/dir/b.txt
+/mnt/dir/symlink_a
+/mnt/lost+found"
+    );
+
+    let a_result = vm
+        .exec_in_guest_async(&format!("cat /mnt/{A_TXT_NAME}"))?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm)?;
+    assert_eq!(a_result.stdout.trim(), A_TXT_DATA);
+    let b_result = vm
+        .exec_in_guest_async(&format!("cat /mnt/{DIR_NAME}/{B_TXT_NAME}"))?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm)?;
+    assert_eq!(b_result.stdout.trim(), B_TXT_DATA);
+
+    // Trying to read a non-existent file should return an error
+    let non_existent_result = vm
+        .exec_in_guest_async(&format!("cat /mnt/{DIR_NAME}/non-existent"))?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm);
+    assert!(non_existent_result.is_err());
+
+    let readlink_result = vm
+        .exec_in_guest_async(&format!("readlink /mnt/{DIR_NAME}/{SYMLINK_A_NAME}"))?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm)?;
+    assert_eq!(readlink_result.stdout.trim(), SYMLINK_A_DEST);
+
+    let symlink_a_result = vm
+        .exec_in_guest_async(&format!("cat /mnt/{DIR_NAME}/{SYMLINK_A_NAME}"))?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm)?;
+    assert_eq!(symlink_a_result.stdout.trim(), A_TXT_DATA);
+
+    Ok(())
+}
+
+/// Check a case with 1000 files in a directory.
+#[test]
+fn pmem_ext2_manyfiles() -> anyhow::Result<()> {
+    // /temp_dir/
+    //  0.txt
+    // ...
+    //  999.txt
+
+    let temp_dir = tempfile::tempdir()?;
+    for i in 0..1000 {
+        let f = temp_dir.path().join(&format!("{i}.txt"));
+        std::fs::write(f, &format!("{i}"))?;
+    }
+
+    let config = Config::new().extra_args(vec![
+        "--pmem-ext2".to_string(),
+        temp_dir.path().to_str().unwrap().to_string(),
+    ]);
+
+    let mut vm = TestVm::new(config)?;
+    vm.exec_in_guest("mount -t ext2 /dev/pmem0 /mnt/")?;
+
+    // `ls -l` returns 1002 lines because 1000 files + 'lost+found' and the total line.
+    let ls_result = vm
+        .exec_in_guest_async("ls -l /mnt/ | wc -l")?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm)?;
+    assert_eq!(ls_result.stdout.trim(), "1002");
+
+    Ok(())
+}
+
+/// Starts pmem-ext2 device with the given uid/gid setting and share a file created by the current
+/// user with the guest. Returns (uid, gid) in the guest.
+fn start_with_ugid_map(
+    uid: u32,
+    uid_map: &str,
+    gid: u32,
+    gid_map: &str,
+) -> anyhow::Result<(u32, u32)> {
+    let temp_dir = tempfile::tempdir()?;
+    let a = temp_dir.path().join("a.txt");
+    std::fs::write(a, "A")?;
+
+    let dir_path = temp_dir.path().to_str().unwrap().to_string();
+    let config = Config::new().extra_args(vec![
+        "--pmem-ext2".to_string(),
+        format!("{dir_path}:uidmap={uid_map}:gidmap={gid_map}:uid={uid}:gid={gid}"),
+    ]);
+
+    let mut vm = TestVm::new(config)?;
+    vm.exec_in_guest("mount -t ext2 /dev/pmem0 /mnt/")?;
+
+    let result = vm
+        .exec_in_guest_async("stat --printf '%u %g' /mnt/a.txt")?
+        .with_timeout(std::time::Duration::from_secs(1))
+        .wait_ok(&mut vm)?;
+    let out = result.stdout.trim();
+    println!("guest ugid: {out}");
+    let ids = out
+        .split(" ")
+        .map(|s| s.parse::<u32>())
+        .collect::<Result<Vec<u32>, _>>()
+        .unwrap();
+    assert_eq!(ids.len(), 2);
+    Ok((ids[0], ids[1])) // (uid, gid)
+}
+
+fn geteugid() -> (u32, u32) {
+    // SAFETY: geteuid never fails.
+    let euid = unsafe { libc::geteuid() };
+    // SAFETY: getegid never fails.
+    let egid = unsafe { libc::getegid() };
+    (euid, egid)
+}
+
+/// Maps to the same id in the guest.
+#[test]
+fn pmem_ext2_ugid_map_identical() {
+    let (host_uid, host_gid) = geteugid();
+
+    let uid_map = format!("{host_uid} {host_uid} 1");
+    let gid_map = format!("{host_gid} {host_gid} 1");
+    let (guest_uid, guest_gid) =
+        start_with_ugid_map(host_uid, &uid_map, host_gid, &gid_map).unwrap();
+    assert_eq!(host_uid, guest_uid);
+    assert_eq!(host_gid, guest_gid);
+}
+
+/// Maps to the root in the guest.
+#[test]
+fn pmem_ext2_ugid_map_to_root() {
+    let (host_uid, host_gid) = geteugid();
+
+    let uid_map = format!("0 {host_uid} 1");
+    let gid_map = format!("0 {host_gid} 1");
+    let (guest_uid, guest_gid) = start_with_ugid_map(0, &uid_map, 0, &gid_map).unwrap();
+    assert_eq!(guest_uid, 0);
+    assert_eq!(guest_gid, 0);
+}
+
+/// Maps to fake ids in the guest.
+#[test]
+fn pmem_ext2_ugid_map_fake_ids() {
+    let (host_uid, host_gid) = geteugid();
+
+    let fake_uid = 1234;
+    let fake_gid = 5678;
+
+    let uid_map = format!("{fake_uid} {host_uid} 1");
+    let gid_map = format!("{fake_gid} {host_gid} 1");
+    let (guest_uid, guest_gid) =
+        start_with_ugid_map(fake_uid, &uid_map, fake_gid, &gid_map).unwrap();
+    assert_eq!(guest_uid, fake_uid);
+    assert_eq!(guest_gid, fake_gid);
+}
diff --git a/e2e_tests/tests/suspend_resume.rs b/e2e_tests/tests/suspend_resume.rs
index 6e6456145..65be6726c 100644
--- a/e2e_tests/tests/suspend_resume.rs
+++ b/e2e_tests/tests/suspend_resume.rs
@@ -64,8 +64,8 @@ fn suspend_resume_system(disabled_sandbox: bool) -> anyhow::Result<()> {
         let mut config = Config::new();
         config = config.with_stdout_hardware("legacy-virtio-console");
         config = config.extra_args(vec![
-            "--pmem-device".to_string(),
-            pmem_file.path().display().to_string(),
+            "--pmem".to_string(),
+            format!("{},ro=true", pmem_file.path().display().to_string()),
         ]);
         // TODO: Remove once USB has snapshot/restore support.
         config = config.extra_args(vec!["--no-usb".to_string()]);
diff --git a/e2e_tests/tests/vsock.rs b/e2e_tests/tests/vsock.rs
index dfdb13c00..361c925c2 100644
--- a/e2e_tests/tests/vsock.rs
+++ b/e2e_tests/tests/vsock.rs
@@ -44,6 +44,7 @@ fn generate_vhost_port() -> u32 {
 }
 
 #[test]
+#[ignore = "Test failing in latest version of debian. b/346365355"]
 fn host_to_guest() {
     let guest_port = generate_vhost_port();
     let guest_cid = generate_guest_cid();
@@ -53,6 +54,7 @@ fn host_to_guest() {
 }
 
 #[test]
+#[ignore = "Test failing in latest version of debian. b/346365355"]
 fn host_to_guest_disable_sandbox() {
     let guest_port = generate_vhost_port();
     let guest_cid = generate_guest_cid();
@@ -64,6 +66,7 @@ fn host_to_guest_disable_sandbox() {
 }
 
 #[test]
+#[ignore = "Test failing in latest version of debian. b/346365355"]
 fn host_to_guest_snapshot_restore() {
     let guest_port = generate_vhost_port();
     let guest_cid = generate_guest_cid();
@@ -94,6 +97,7 @@ fn host_to_guest_snapshot_restore() {
 }
 
 #[test]
+#[ignore = "Test failing in latest version of debian. b/346365355"]
 fn host_to_guest_disable_sandbox_snapshot_restore() {
     let guest_port = generate_vhost_port();
     let guest_cid = generate_guest_cid();
diff --git a/ext2/Android.bp b/ext2/Android.bp
new file mode 100644
index 000000000..445ee6f1d
--- /dev/null
+++ b/ext2/Android.bp
@@ -0,0 +1,96 @@
+// This file is generated by cargo_embargo.
+// Do not modify this file after the first "rust_*" or "genrule" module
+// because the changes will be overridden on upgrade.
+// Content before the first "rust_*" or "genrule" module is preserved.
+
+package {
+    // See: http://go/android-license-faq
+    // A large-scale-change added 'default_applicable_licenses' to import
+    // all of the 'license_kinds' from "external_crosvm_license"
+    // to get the below license kinds:
+    //   SPDX-license-identifier-BSD
+    default_applicable_licenses: ["external_crosvm_license"],
+}
+
+rust_test {
+    name: "ext2_test_src_lib",
+    defaults: ["crosvm_inner_defaults"],
+    host_supported: true,
+    crate_name: "ext2",
+    cargo_env_compat: true,
+    cargo_pkg_version: "0.1.0",
+    crate_root: "src/lib.rs",
+    test_suites: ["general-tests"],
+    auto_gen_config: true,
+    test_options: {
+        unit_test: true,
+    },
+    edition: "2021",
+    rustlibs: [
+        "libanyhow",
+        "libargh",
+        "libbase_rust",
+        "liblibc",
+        "libtempfile",
+        "libuuid",
+        "libwalkdir",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libzerocopy_derive",
+    ],
+}
+
+rust_test {
+    name: "ext2_test_tests_tests",
+    defaults: ["crosvm_inner_defaults"],
+    host_supported: true,
+    crate_name: "tests",
+    cargo_env_compat: true,
+    cargo_pkg_version: "0.1.0",
+    crate_root: "tests/tests.rs",
+    test_suites: ["general-tests"],
+    auto_gen_config: true,
+    test_options: {
+        unit_test: true,
+    },
+    edition: "2021",
+    rustlibs: [
+        "libanyhow",
+        "libargh",
+        "libbase_rust",
+        "libext2",
+        "liblibc",
+        "libtempfile",
+        "libuuid",
+        "libwalkdir",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libzerocopy_derive",
+    ],
+}
+
+rust_library {
+    name: "libext2",
+    defaults: ["crosvm_inner_defaults"],
+    host_supported: true,
+    crate_name: "ext2",
+    cargo_env_compat: true,
+    cargo_pkg_version: "0.1.0",
+    crate_root: "src/lib.rs",
+    edition: "2021",
+    rustlibs: [
+        "libanyhow",
+        "libbase_rust",
+        "liblibc",
+        "libuuid",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libzerocopy_derive",
+    ],
+}
diff --git a/ext2/Cargo.toml b/ext2/Cargo.toml
new file mode 100644
index 000000000..dd201eb54
--- /dev/null
+++ b/ext2/Cargo.toml
@@ -0,0 +1,22 @@
+[package]
+name = "ext2"
+version = "0.1.0"
+authors = ["The ChromiumOS Authors"]
+edition = "2021"
+
+[dependencies]
+anyhow = "1"
+base = { path = "../base/" }
+enumn = "0.1"
+libc = "0.2"
+uuid = { version = "1", features = ["v4"] }
+zerocopy = "0.7.29" # >=0.7.29 is required for our 'AsBytes'
+zerocopy-derive = "0.7"
+
+[[example]]
+name = "mkfs"
+
+[dev-dependencies]
+argh = "0.1"
+tempfile = "3"
+walkdir = "2.3"
diff --git a/ext2/README.md b/ext2/README.md
new file mode 100644
index 000000000..e4795b105
--- /dev/null
+++ b/ext2/README.md
@@ -0,0 +1,19 @@
+# ext2
+
+This crate provides utilities to create ext2 file system on memory or a file.
+
+`examples/mkfs.rs` shows how to use this library. This program is our alternative to `mkfs.ext2`
+that create an ext2 file system on a file and useful for debugging this ext2 itself with existing
+utilities in `e2fsprogs` such as `fsck` and `dumpe2fs`.
+
+```console
+$ cargo run --release --example mkfs -- --path disk.img
+Create disk.img
+$ dumpe2fs disk.img
+dumpe2fs 1.47.0 (5-Feb-2023)
+Filesystem volume name:   <none>
+Last mounted on:          <not available>
+Filesystem UUID:          c6e49d8f-106f-4472-b0e8-6babcc3fa496
+Filesystem magic number:  0xEF53
+...
+```
diff --git a/ext2/examples/mkfs.rs b/ext2/examples/mkfs.rs
new file mode 100644
index 000000000..7613ae01a
--- /dev/null
+++ b/ext2/examples/mkfs.rs
@@ -0,0 +1,87 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+// To allow compiling this file on non-Linux platforms, main logic is
+// behind the `linux` module.
+#[cfg(target_os = "linux")]
+mod linux {
+    use std::fs::OpenOptions;
+    use std::io::Write;
+    use std::path::Path;
+
+    use argh::FromArgs;
+    use base::MappedRegion;
+
+    #[derive(FromArgs)]
+    /// Create ext2 filesystem.
+    struct Args {
+        /// path to the disk,
+        #[argh(option)]
+        output: String,
+
+        /// path to the source directory to copy files from,
+        #[argh(option)]
+        src: Option<String>,
+
+        /// number of blocks for each group
+        #[argh(option, default = "1024")]
+        blocks_per_group: u32,
+
+        /// number of inodes for each group
+        #[argh(option, default = "1024")]
+        inodes_per_group: u32,
+
+        /// size of memory region in bytes.
+        /// If it's not a multiple of 4096, it will be rounded up to the next multiple of 4096.
+        #[argh(option, default = "4194304")]
+        size: u32,
+
+        /// if sepecified, create a file systeon on RAM, but do not write to disk.
+        #[argh(switch, short = 'j')]
+        dry_run: bool,
+    }
+
+    pub fn main() -> anyhow::Result<()> {
+        let args: Args = argh::from_env();
+        let src_dir = args.src.as_ref().map(|s| Path::new(s.as_str()));
+        let builder = ext2::Builder {
+            blocks_per_group: args.blocks_per_group,
+            inodes_per_group: args.inodes_per_group,
+            size: args.size,
+        };
+        let mem = builder
+            .allocate_memory()?
+            .build_mmap_info(src_dir)?
+            .do_mmap()?;
+        if args.dry_run {
+            println!("Done!");
+            return Ok(());
+        }
+
+        // SAFETY: `mem` has a valid pointer and its size.
+        let buf = unsafe { std::slice::from_raw_parts(mem.as_ptr(), mem.size()) };
+        let mut file = OpenOptions::new()
+            .write(true)
+            .create(true)
+            .truncate(true)
+            .open(&args.output)
+            .unwrap();
+
+        file.write_all(buf).unwrap();
+
+        println!("{} is written!", args.output);
+
+        Ok(())
+    }
+}
+
+fn main() -> anyhow::Result<()> {
+    #[cfg(target_os = "linux")]
+    linux::main()?;
+
+    #[cfg(not(target_os = "linux"))]
+    println!("Not supported on non-Linux platforms");
+
+    Ok(())
+}
diff --git a/ext2/src/arena.rs b/ext2/src/arena.rs
new file mode 100644
index 000000000..dbe628036
--- /dev/null
+++ b/ext2/src/arena.rs
@@ -0,0 +1,289 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Defines an arena allocator backed by `base::MemoryMapping`.
+
+use std::cell::RefCell;
+use std::collections::BTreeSet;
+use std::fs::File;
+
+use anyhow::anyhow;
+use anyhow::bail;
+use anyhow::Context;
+use anyhow::Result;
+use base::MappedRegion;
+use base::MemoryMapping;
+use zerocopy::AsBytes;
+use zerocopy::FromBytes;
+
+#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
+struct Region {
+    start: usize,
+    len: usize,
+}
+
+/// Manages a set of regions that are not overlapping each other.
+#[derive(Default)]
+struct RegionManager(BTreeSet<Region>);
+
+impl RegionManager {
+    fn allocate(&mut self, start: usize, len: usize) -> Result<()> {
+        // Allocation needs to fail if there exists a region that overlaps with [start, start+len).
+        // A region r is overlapping with [start, start+len) if and only if:
+        // r.start <= (start+len) && start <= (r.start+r.len)
+        //
+        // So, we first find the last region where r.start <= (start+len) holds.
+        let left = self
+            .0
+            .range(
+                ..Region {
+                    start: start + len,
+                    len: 0,
+                },
+            )
+            .next_back()
+            .copied();
+
+        // New region to be added.
+        let new = match left {
+            None => Region { start, len },
+            Some(r) => {
+                if start < r.start + r.len {
+                    bail!(
+                        "range overlaps: existing: {:?}, new: {:?}",
+                        left,
+                        Region { start, len }
+                    );
+                }
+
+                // if `r` and the new region is adjacent, merge them.
+                // otherwise, just return the new region.
+                if start == r.start + r.len {
+                    let new = Region {
+                        start: r.start,
+                        len: r.len + len,
+                    };
+                    self.0.remove(&r);
+                    new
+                } else {
+                    Region { start, len }
+                }
+            }
+        };
+
+        // If there exists a region that starts from `new.start + new.len`,
+        // it should be merged with `new`.
+        let right = self
+            .0
+            .range(
+                Region {
+                    start: new.start + new.len,
+                    len: 0,
+                }..,
+            )
+            .next()
+            .copied();
+        match right {
+            Some(r) if r.start == new.start + new.len => {
+                // merge and insert
+                let merged = Region {
+                    start: new.start,
+                    len: new.len + r.len,
+                };
+                self.0.remove(&r);
+                self.0.insert(merged);
+            }
+            Some(_) | None => {
+                // just insert
+                self.0.insert(new);
+            }
+        }
+
+        Ok(())
+    }
+
+    #[cfg(test)]
+    fn to_vec(&self) -> Vec<&Region> {
+        self.0.iter().collect()
+    }
+}
+
+#[test]
+fn test_region_manager() {
+    let mut rm: RegionManager = Default::default();
+
+    rm.allocate(0, 5).unwrap();
+    assert_eq!(rm.to_vec(), vec![&Region { start: 0, len: 5 }]);
+    rm.allocate(10, 5).unwrap();
+    rm.allocate(15, 5).unwrap(); // will be merged into the previous one
+    assert_eq!(
+        rm.to_vec(),
+        vec![&Region { start: 0, len: 5 }, &Region { start: 10, len: 10 }]
+    );
+    rm.allocate(3, 5).unwrap_err(); // fail
+    rm.allocate(8, 5).unwrap_err(); // fail
+
+    rm.allocate(25, 5).unwrap();
+    assert_eq!(
+        rm.to_vec(),
+        vec![
+            &Region { start: 0, len: 5 },
+            &Region { start: 10, len: 10 },
+            &Region { start: 25, len: 5 }
+        ]
+    );
+
+    rm.allocate(5, 5).unwrap(); // will be merged to the existing two regions
+    assert_eq!(
+        rm.to_vec(),
+        vec![&Region { start: 0, len: 20 }, &Region { start: 25, len: 5 }]
+    );
+    rm.allocate(20, 5).unwrap();
+    assert_eq!(rm.to_vec(), vec![&Region { start: 0, len: 30 },]);
+}
+
+#[derive(Debug, Clone, Copy, AsBytes)]
+#[repr(C)]
+/// Represents a ID of a disk block.
+pub struct BlockId(u32);
+
+impl From<u32> for BlockId {
+    fn from(value: u32) -> Self {
+        BlockId(value)
+    }
+}
+
+impl From<BlockId> for u32 {
+    fn from(value: BlockId) -> Self {
+        value.0
+    }
+}
+
+impl BlockId {
+    pub fn as_bytes(&self) -> &[u8] {
+        self.0.as_bytes()
+    }
+}
+
+/// Information on how to mmap a host file to ext2 blocks.
+pub struct FileMappingInfo {
+    /// Offset in the memory that a file is mapped to.
+    pub mem_offset: usize,
+    /// The file to be mmap'd.
+    pub file: File,
+    /// The length of the mapping.
+    pub length: usize,
+    /// Offset in the file to start the mapping.
+    pub file_offset: usize,
+}
+
+/// Memory arena backed by `base::MemoryMapping`.
+///
+/// This struct takes a mutable referencet to the memory mapping so this arena won't arena the
+/// region.
+pub struct Arena<'a> {
+    mem: &'a mut MemoryMapping,
+    block_size: usize,
+    /// A set of regions that are not overlapping each other.
+    /// Use `RefCell` for interior mutability because the mutablity of `RegionManager` should be
+    /// independent from the mutability of the memory mapping.
+    regions: RefCell<RegionManager>,
+
+    mappings: RefCell<Vec<FileMappingInfo>>,
+}
+
+impl<'a> Arena<'a> {
+    /// Create a new arena backed by `len` bytes of `base::MemoryMapping`.
+    pub fn new(block_size: usize, mem: &'a mut MemoryMapping) -> Result<Self> {
+        Ok(Self {
+            mem,
+            block_size,
+            regions: Default::default(),
+            mappings: Default::default(),
+        })
+    }
+
+    /// A helper function to mark a region as reserved.
+    fn reserve(&self, mem_offset: usize, len: usize) -> Result<()> {
+        let mem_end = mem_offset.checked_add(len).context("mem_end overflow")?;
+
+        if mem_end > self.mem.size() {
+            bail!(
+                "out of memory region: {mem_offset} + {len} > {}",
+                self.mem.size()
+            );
+        }
+
+        self.regions.borrow_mut().allocate(mem_offset, len)?;
+
+        Ok(())
+    }
+
+    /// Reserves a region for mmap and stores the mmap information.
+    /// Note that `Arena` will not call  mmap(). Instead, the owner of `Arena` instance must call
+    /// `into_mapping_info()` to retrieve the mapping information and call mmap later instead.
+    pub fn reserve_for_mmap(
+        &self,
+        mem_offset: usize,
+        length: usize,
+        file: File,
+        file_offset: usize,
+    ) -> Result<()> {
+        self.reserve(mem_offset, length)?;
+        self.mappings.borrow_mut().push(FileMappingInfo {
+            mem_offset,
+            length,
+            file: file.try_clone()?,
+            file_offset,
+        });
+
+        Ok(())
+    }
+
+    /// Allocate a new slice on an anonymous memory.
+    /// `Arena` structs guarantees that this area is not overlapping with other regions.
+    pub fn allocate_slice(
+        &self,
+        block: BlockId,
+        block_offset: usize,
+        len: usize,
+    ) -> Result<&'a mut [u8]> {
+        let offset = u32::from(block) as usize * self.block_size + block_offset;
+        self.reserve(offset, len)?;
+
+        let new_addr = (self.mem.as_ptr() as usize)
+            .checked_add(offset)
+            .context("address overflow")?;
+
+        // SAFETY: the memory region [new_addr, new_addr+len) is guaranteed to be valid.
+        let slice = unsafe { std::slice::from_raw_parts_mut(new_addr as *mut u8, len) };
+        Ok(slice)
+    }
+
+    /// Allocate a new region for a value with type `T`.
+    pub fn allocate<T: AsBytes + FromBytes + Sized>(
+        &self,
+        block: BlockId,
+        block_offset: usize,
+    ) -> Result<&'a mut T> {
+        let slice = self.allocate_slice(block, block_offset, std::mem::size_of::<T>())?;
+        T::mut_from(slice).ok_or_else(|| anyhow!("failed to interpret"))
+    }
+
+    pub fn write_to_mem<T: AsBytes + FromBytes + Sized>(
+        &self,
+        block_id: BlockId,
+        block_offset: usize,
+        value: &T,
+    ) -> Result<()> {
+        let slice = self.allocate_slice(block_id, block_offset, std::mem::size_of::<T>())?;
+        slice.copy_from_slice(value.as_bytes());
+        Ok(())
+    }
+
+    /// Consumes `Arena` and retrieve mmap information.
+    pub fn into_mapping_info(self) -> Vec<FileMappingInfo> {
+        self.mappings.take()
+    }
+}
diff --git a/ext2/src/bitmap.rs b/ext2/src/bitmap.rs
new file mode 100644
index 000000000..e821a0cec
--- /dev/null
+++ b/ext2/src/bitmap.rs
@@ -0,0 +1,91 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Defines bitmap types.
+
+use anyhow::bail;
+use anyhow::Result;
+
+pub struct BitMap<'a> {
+    inner: &'a mut [u8],
+}
+
+impl<'a> BitMap<'a> {
+    /// Creates a new bitmap from an underlying buffer.
+    pub fn from_slice_mut(inner: &'a mut [u8]) -> Self {
+        Self { inner }
+    }
+
+    /// Sets the bit at the given index.
+    pub fn set(&mut self, index: usize, value: bool) -> Result<()> {
+        let i = index / 8;
+        let j = index % 8;
+        if i >= self.inner.len() {
+            bail!("index out of range");
+        }
+        if value {
+            self.inner[i] |= 1 << j;
+        } else {
+            self.inner[i] &= !(1 << j);
+        }
+        Ok(())
+    }
+
+    /// Marks the first `n` bits in the bitmap with the given value.
+    pub fn mark_first_elems(&mut self, n: usize, value: bool) {
+        self.inner
+            .iter_mut()
+            .take(n / 8)
+            .for_each(|v| *v = if value { 0xff } else { 0 });
+        if n % 8 != 0 {
+            if value {
+                self.inner[n / 8] |= 0xff >> (8 - n % 8);
+            } else {
+                self.inner[n / 8] &= !(0xff >> (8 - n % 8));
+            }
+        }
+    }
+
+    // Returns the number of bits in the bitmap.
+    pub fn len(&self) -> usize {
+        self.inner.len() * 8
+    }
+}
+
+// Implements test utility methods.
+#[cfg(test)]
+impl<'a> BitMap<'a> {
+    // Returns the number of bits in the bitmap that are set.
+    pub fn count_zeros(&self) -> usize {
+        self.inner.iter().map(|b| b.count_zeros() as usize).sum()
+    }
+
+    pub fn as_slice(&self) -> &[u8] {
+        self.inner
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn test_mark_first_elems() {
+        let mut s = [0; 10];
+        let mut b = BitMap::from_slice_mut(&mut s);
+        b.mark_first_elems(28, true);
+        // (28 + 1) = 8 * 3 + 4. So, the first 3 bytes and 4 bits should be set.
+        assert_eq!(b.as_slice(), &[0xff, 0xff, 0xff, 0b1111, 0, 0, 0, 0, 0, 0]);
+    }
+
+    #[test]
+    fn test_set() {
+        let mut s = [0; 10];
+        let mut b = BitMap::from_slice_mut(&mut s);
+        b.set(42, true).unwrap();
+        // (42 +  1) == 8 * 5 + 3. So, 3rd bit at 6th byte should be set.
+        // Note that "+1" is needed as this is 0-indexed.
+        assert_eq!(b.as_slice(), &[0, 0, 0, 0, 0, 0b100, 0, 0, 0, 0]);
+    }
+}
diff --git a/ext2/src/blockgroup.rs b/ext2/src/blockgroup.rs
new file mode 100644
index 000000000..456524ae5
--- /dev/null
+++ b/ext2/src/blockgroup.rs
@@ -0,0 +1,225 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Defines structs for metadata of block groups.
+
+use std::collections::BTreeMap;
+
+use anyhow::Result;
+use zerocopy::AsBytes;
+use zerocopy_derive::FromBytes;
+use zerocopy_derive::FromZeroes;
+
+use crate::arena::Arena;
+use crate::arena::BlockId;
+use crate::bitmap::BitMap;
+use crate::inode::Inode;
+use crate::inode::InodeNum;
+use crate::superblock::SuperBlock;
+
+/// The size of a block in bytes.
+/// We only support 4K-byte blocks.
+pub const BLOCK_SIZE: usize = 4096;
+
+/// A block group descriptor.
+///
+/// See [the specification](https://www.nongnu.org/ext2-doc/ext2.html#block-group-descriptor-table) for the details.
+#[repr(C)]
+#[derive(Default, Debug, Copy, Clone, FromZeroes, FromBytes, AsBytes)]
+pub(crate) struct BlockGroupDescriptor {
+    /// Index of the first block of the block bitmap.
+    pub block_bitmap: u32,
+    /// Index of the first block of the inode bitmap.
+    pub inode_bitmap: u32,
+    /// Index of the first block of the inode table.
+    pub inode_table: u32,
+    /// Number of free blocks.
+    pub free_blocks_count: u16,
+    /// Number of free inodes.
+    pub free_inodes_count: u16,
+    /// Number of directories.
+    pub used_dirs_count: u16,
+    pad: u16,
+    reserved: [u8; 12],
+}
+
+pub(crate) struct GroupMetaData<'a> {
+    pub group_desc: &'a mut BlockGroupDescriptor,
+    pub block_bitmap: BitMap<'a>,
+    pub inode_bitmap: BitMap<'a>,
+
+    pub inode_table: BTreeMap<InodeNum, &'a mut Inode>,
+
+    pub first_free_block: u32,
+    pub first_free_inode: u32,
+}
+
+impl<'a> GroupMetaData<'a> {
+    // Write GroupMetaData to the first block group.
+    // This data need to be copied to other block gropups' descriptor tables.
+    pub fn new(arena: &'a Arena<'a>, sb: &mut SuperBlock, group_id: u16) -> Result<Self> {
+        let gd_size = std::mem::size_of::<BlockGroupDescriptor>() as u32;
+        let num_blocks_for_gds = (gd_size * sb.num_groups() as u32).div_ceil(BLOCK_SIZE as u32);
+
+        let inodes_per_block = BLOCK_SIZE as u64 / sb.inode_size as u64;
+        let num_blocks_for_inode_table =
+            (sb.inodes_per_group as usize).div_ceil(inodes_per_block as usize);
+
+        // Allocate a block group descriptor at Block 1.
+        let group_desc = arena.allocate::<BlockGroupDescriptor>(
+            BlockId::from(1),
+            std::mem::size_of::<BlockGroupDescriptor>() * group_id as usize,
+        )?;
+
+        // First blocks for block_bitmap, inode_bitmap, and inode_table.
+        let super_block_id = group_id as u32 * sb.blocks_per_group;
+        let group_desc_id = super_block_id + 1;
+        group_desc.block_bitmap = group_desc_id + num_blocks_for_gds;
+        group_desc.inode_bitmap = group_desc.block_bitmap + 1;
+        group_desc.inode_table = group_desc.inode_bitmap + 1;
+
+        // First free block is the one after inode table.
+        let first_free_block = group_desc.inode_table + num_blocks_for_inode_table as u32;
+        // Free blocks are from `first_free_block` to `blocks_per_group`, inclusive.
+        group_desc.free_blocks_count =
+            (sb.blocks_per_group * (group_id as u32 + 1) - first_free_block) as u16;
+        sb.free_blocks_count += group_desc.free_blocks_count as u32;
+
+        // 10 inodes should be reserved in ext2.
+        let reserved_inode = if group_id == 0 { 10 } else { 0 };
+        let first_free_inode = group_id as u32 * sb.inodes_per_group + reserved_inode + 1;
+        group_desc.free_inodes_count = sb.inodes_per_group as u16 - reserved_inode as u16;
+        sb.free_inodes_count -= reserved_inode;
+
+        // Initialize block bitmap block.
+        let bmap = arena.allocate::<[u8; BLOCK_SIZE]>(BlockId::from(group_desc.block_bitmap), 0)?;
+        let valid_bmap_bytes = (sb.blocks_per_group / 8) as usize;
+        // Unused parts in the block is marked as 1.
+        bmap[valid_bmap_bytes..].iter_mut().for_each(|x| *x = 0xff);
+        // Interpret the region as BitMap and mask bits for blocks used for metadata.
+        let mut block_bitmap = BitMap::from_slice_mut(&mut bmap[..valid_bmap_bytes]);
+        block_bitmap.mark_first_elems(
+            (first_free_block - group_id as u32 * sb.blocks_per_group) as usize,
+            true,
+        );
+
+        let imap = arena.allocate::<[u8; BLOCK_SIZE]>(BlockId::from(group_desc.inode_bitmap), 0)?;
+        let valid_imap_bytes = (sb.inodes_per_group / 8) as usize;
+        // Unused parts in the block is marked as 1.
+        imap[valid_imap_bytes..].iter_mut().for_each(|x| *x = 0xff);
+        // Interpret the region as BitMap and mask bits for reserved inodes.
+        let mut inode_bitmap =
+            BitMap::from_slice_mut(&mut imap[..(sb.inodes_per_group / 8) as usize]);
+        inode_bitmap.mark_first_elems(reserved_inode as usize, true);
+
+        Ok(GroupMetaData {
+            group_desc,
+            block_bitmap,
+            inode_bitmap,
+
+            inode_table: BTreeMap::new(),
+
+            first_free_block,
+            first_free_inode,
+        })
+    }
+}
+
+#[cfg(test)]
+mod test {
+    use base::MemoryMappingBuilder;
+
+    use super::*;
+    use crate::Builder;
+
+    // Check if `GroupMetaData` is correctly initialized from `SuperBlock` with one block group.
+    #[test]
+    fn test_group_metadata_with_one_block_group() {
+        let blocks_per_group = 1024;
+        let num_groups = 1;
+        let size = BLOCK_SIZE as u32 * blocks_per_group * num_groups;
+        let mut mem = MemoryMappingBuilder::new(size as usize).build().unwrap();
+        let arena = Arena::new(BLOCK_SIZE, &mut mem).unwrap();
+        let sb = SuperBlock::new(
+            &arena,
+            &Builder {
+                inodes_per_group: 1024,
+                blocks_per_group,
+                size,
+            },
+        )
+        .unwrap();
+        let group = GroupMetaData::new(&arena, sb, 0).unwrap();
+
+        assert_eq!(sb.block_group_nr, 1);
+
+        // First a few blocks are used for specific purposes.
+        // Their indexes are arbitrary but we can assume the following values unless we use much
+        // larger parameters:
+        // 0: 1024-byte offset + superblock
+        // 1: group descriptor(s)
+        // 2: block bitmap
+        // 3: inode bitmap
+        // 4+ : inode table
+        assert_eq!(group.group_desc.block_bitmap, 2);
+        assert_eq!(group.group_desc.inode_bitmap, 3);
+        assert_eq!(group.group_desc.inode_table, 4);
+
+        assert_eq!(
+            group.group_desc.free_blocks_count as u32,
+            sb.free_blocks_count
+        );
+        assert_eq!(
+            group.group_desc.free_inodes_count as u32,
+            sb.free_inodes_count
+        );
+        assert_eq!(group.block_bitmap.len(), sb.blocks_per_group as usize);
+        assert_eq!(
+            group.block_bitmap.count_zeros(),
+            group.group_desc.free_blocks_count as usize,
+        );
+        assert_eq!(
+            group.inode_bitmap.count_zeros(),
+            group.group_desc.free_inodes_count as usize,
+        );
+    }
+
+    #[test]
+    fn test_group_metadata_with_multiple_block_groups() {
+        let blocks_per_group = 1024u32;
+        let num_groups = 10u32;
+        let mem_size = BLOCK_SIZE as u32 * blocks_per_group * num_groups;
+        let mut mem = MemoryMappingBuilder::new(mem_size as usize)
+            .build()
+            .unwrap();
+        let arena = Arena::new(BLOCK_SIZE, &mut mem).unwrap();
+        let sb = SuperBlock::new(
+            &arena,
+            &Builder {
+                inodes_per_group: 512,
+                blocks_per_group,
+                size: mem_size,
+            },
+        )
+        .unwrap();
+
+        let groups = (0..num_groups)
+            .map(|group_id| GroupMetaData::new(&arena, sb, group_id as u16).unwrap())
+            .collect::<Vec<_>>();
+        assert_eq!(
+            groups
+                .iter()
+                .map(|gd| gd.group_desc.free_blocks_count as u32)
+                .sum::<u32>(),
+            sb.free_blocks_count
+        );
+        assert_eq!(
+            groups
+                .iter()
+                .map(|gd| gd.group_desc.free_inodes_count as u32)
+                .sum::<u32>(),
+            sb.free_inodes_count
+        );
+    }
+}
diff --git a/ext2/src/builder.rs b/ext2/src/builder.rs
new file mode 100644
index 000000000..0c0365fe1
--- /dev/null
+++ b/ext2/src/builder.rs
@@ -0,0 +1,142 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Provides structs and logic to build ext2 file system with configurations.
+
+use std::path::Path;
+
+use anyhow::bail;
+use anyhow::Context;
+use anyhow::Result;
+use base::MappedRegion;
+use base::MemoryMapping;
+use base::MemoryMappingArena;
+use base::MemoryMappingBuilder;
+use base::Protection;
+use base::SharedMemory;
+
+use crate::arena::Arena;
+use crate::arena::FileMappingInfo;
+use crate::fs::Ext2;
+use crate::BLOCK_SIZE;
+
+/// A struct to represent the configuration of an ext2 filesystem.
+pub struct Builder {
+    /// The number of blocks per group.
+    pub blocks_per_group: u32,
+    /// The number of inodes per group.
+    pub inodes_per_group: u32,
+    /// The size of the memory region.
+    pub size: u32,
+}
+
+impl Default for Builder {
+    fn default() -> Self {
+        Self {
+            blocks_per_group: 4096,
+            inodes_per_group: 4096,
+            size: 4096 * 4096,
+        }
+    }
+}
+
+impl Builder {
+    /// Validates field values and adjusts them if needed.
+    fn validate(&mut self) -> Result<()> {
+        let block_group_size = BLOCK_SIZE as u32 * self.blocks_per_group;
+        if self.size < block_group_size {
+            bail!(
+            "memory size {} is too small to have a block group: block_size={},  block_per_group={}",
+            self.size,
+            BLOCK_SIZE,
+            block_group_size
+        );
+        }
+        if self.size % block_group_size != 0 {
+            // Round down to the largest multiple of block_group_size that is smaller than self.size
+            self.size = self.size.next_multiple_of(block_group_size) - block_group_size
+        };
+        Ok(())
+    }
+
+    /// Allocates memory region with the given configuration.
+    pub fn allocate_memory(mut self) -> Result<MemRegion> {
+        self.validate()
+            .context("failed to validate the ext2 config")?;
+        let mem = MemoryMappingBuilder::new(self.size as usize)
+            .build()
+            .context("failed to allocate memory for ext2")?;
+        Ok(MemRegion { cfg: self, mem })
+    }
+
+    /// Builds memory region on the given shared memory.
+    pub fn build_on_shm(self, shm: &SharedMemory) -> Result<MemRegion> {
+        let mem = MemoryMappingBuilder::new(shm.size() as usize)
+            .from_shared_memory(shm)
+            .build()
+            .expect("failed to build MemoryMapping from shared memory");
+        Ok(MemRegion { cfg: self, mem })
+    }
+}
+
+/// Memory region for ext2 with its config.
+pub struct MemRegion {
+    cfg: Builder,
+    mem: MemoryMapping,
+}
+
+impl MemRegion {
+    /// Constructs an ext2 metadata by traversing `src_dir`.
+    pub fn build_mmap_info(mut self, src_dir: Option<&Path>) -> Result<MemRegionWithMappingInfo> {
+        let arena = Arena::new(BLOCK_SIZE, &mut self.mem).context("failed to allocate arena")?;
+        let mut ext2 = Ext2::new(&self.cfg, &arena).context("failed to create Ext2 struct")?;
+        if let Some(dir) = src_dir {
+            ext2.copy_dirtree(&arena, dir)
+                .context("failed to copy directory tree")?;
+        }
+        ext2.copy_backup_metadata(&arena)
+            .context("failed to copy metadata for backup")?;
+        let mapping_info = arena.into_mapping_info();
+
+        self.mem
+            .msync()
+            .context("failed to msyn of ext2's memory region")?;
+        Ok(MemRegionWithMappingInfo {
+            mem: self.mem,
+            mapping_info,
+        })
+    }
+}
+
+/// Memory regions where ext2 metadata were written with information of mmap operations to be done.
+pub struct MemRegionWithMappingInfo {
+    mem: MemoryMapping,
+    pub mapping_info: Vec<FileMappingInfo>,
+}
+
+impl MemRegionWithMappingInfo {
+    /// Do mmap and returns the memory region where ext2 was created.
+    pub fn do_mmap(self) -> Result<MemoryMappingArena> {
+        let mut mmap_arena = MemoryMappingArena::from(self.mem);
+        for FileMappingInfo {
+            mem_offset,
+            file,
+            length,
+            file_offset,
+        } in self.mapping_info
+        {
+            mmap_arena
+                .add_fd_mapping(
+                    mem_offset,
+                    length,
+                    &file,
+                    file_offset as u64, /* fd_offset */
+                    Protection::read(),
+                )
+                .context("failed mmaping an fd for ext2")?;
+        }
+
+        Ok(mmap_arena)
+    }
+}
diff --git a/ext2/src/fs.rs b/ext2/src/fs.rs
new file mode 100644
index 000000000..6cf8b818d
--- /dev/null
+++ b/ext2/src/fs.rs
@@ -0,0 +1,784 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Defines a struct to represent an ext2 filesystem and implements methods to create
+// a filesystem in memory.
+
+use std::collections::BTreeMap;
+use std::ffi::OsStr;
+use std::ffi::OsString;
+use std::fs::DirEntry;
+use std::fs::File;
+use std::os::unix::ffi::OsStrExt;
+use std::path::Path;
+
+use anyhow::anyhow;
+use anyhow::bail;
+use anyhow::Context;
+use anyhow::Result;
+use base::info;
+use zerocopy::AsBytes;
+use zerocopy::FromBytes;
+use zerocopy::FromZeroes;
+
+use crate::arena::Arena;
+use crate::arena::BlockId;
+use crate::blockgroup::BlockGroupDescriptor;
+use crate::blockgroup::GroupMetaData;
+use crate::blockgroup::BLOCK_SIZE;
+use crate::builder::Builder;
+use crate::inode::Inode;
+use crate::inode::InodeBlock;
+use crate::inode::InodeBlocksCount;
+use crate::inode::InodeNum;
+use crate::inode::InodeType;
+use crate::superblock::SuperBlock;
+
+#[repr(C)]
+#[derive(Copy, Clone, FromZeroes, FromBytes, AsBytes, Debug)]
+struct DirEntryRaw {
+    inode: u32,
+    rec_len: u16,
+    name_len: u8,
+    file_type: u8,
+}
+
+struct DirEntryWithName<'a> {
+    de: &'a mut DirEntryRaw,
+    name: OsString,
+}
+
+impl<'a> std::fmt::Debug for DirEntryWithName<'a> {
+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+        f.debug_struct("DirEntry")
+            .field("de", &self.de)
+            .field("name", &self.name)
+            .finish()
+    }
+}
+
+impl<'a> DirEntryWithName<'a> {
+    fn new(
+        arena: &'a Arena<'a>,
+        inode: InodeNum,
+        typ: InodeType,
+        name_str: &OsStr,
+        dblock: &mut DirEntryBlock,
+    ) -> Result<Self> {
+        let cs = name_str.as_bytes();
+        let name_len = cs.len();
+        let aligned_name_len = name_len
+            .checked_next_multiple_of(4)
+            .expect("name length must be 4-byte aligned");
+
+        // rec_len = |inode| + |file_type| + |name_len| + |rec_len| + name + padding
+        //         = 4 + 1 + 1 + 2 + |name| + padding
+        //         = 8 + |name| + padding
+        // The padding is inserted because the name is 4-byte aligned.
+        let rec_len = 8 + aligned_name_len as u16;
+
+        let de = arena.allocate(dblock.block_id, dblock.offset)?;
+        *de = DirEntryRaw {
+            inode: inode.into(),
+            rec_len,
+            name_len: name_len as u8,
+            file_type: typ.into_dir_entry_file_type(),
+        };
+        dblock.offset += std::mem::size_of::<DirEntryRaw>();
+
+        let name_slice = arena.allocate_slice(dblock.block_id, dblock.offset, aligned_name_len)?;
+        dblock.offset += aligned_name_len;
+        name_slice[..cs.len()].copy_from_slice(cs);
+
+        if dblock.entries.is_empty() {
+            de.rec_len = BLOCK_SIZE as u16;
+        } else {
+            let last = dblock
+                .entries
+                .last_mut()
+                .expect("parent_dir must not be empty");
+            let last_rec_len = last.de.rec_len;
+            last.de.rec_len = (8 + last.name.as_os_str().as_bytes().len() as u16)
+                .checked_next_multiple_of(4)
+                .expect("overflow to calculate rec_len");
+            de.rec_len = last_rec_len - last.de.rec_len;
+        }
+
+        Ok(Self {
+            de,
+            name: name_str.into(),
+        })
+    }
+}
+
+#[derive(Debug)]
+struct DirEntryBlock<'a> {
+    block_id: BlockId,
+    offset: usize,
+    entries: Vec<DirEntryWithName<'a>>,
+}
+
+impl DirEntryBlock<'_> {
+    fn has_enough_space(&self, name: &OsStr) -> bool {
+        let dir_entry_size = std::mem::size_of::<DirEntryRaw>();
+        let aligned_name_len = name
+            .as_bytes()
+            .len()
+            .checked_next_multiple_of(4)
+            .expect("length must be < 256 bytes so it must not overflow");
+        self.offset + dir_entry_size + aligned_name_len <= BLOCK_SIZE
+    }
+}
+
+/// A struct to represent an ext2 filesystem.
+pub struct Ext2<'a> {
+    sb: &'a mut SuperBlock,
+    cur_block_group: usize,
+    cur_inode_table: usize,
+
+    group_metadata: Vec<GroupMetaData<'a>>,
+
+    dir_entries: BTreeMap<InodeNum, Vec<DirEntryBlock<'a>>>,
+}
+
+impl<'a> Ext2<'a> {
+    /// Create a new ext2 filesystem.
+    pub(crate) fn new(cfg: &Builder, arena: &'a Arena<'a>) -> Result<Self> {
+        let sb = SuperBlock::new(arena, cfg)?;
+
+        let mut group_metadata = vec![];
+        for i in 0..sb.num_groups() {
+            group_metadata.push(GroupMetaData::new(arena, sb, i)?);
+        }
+
+        let mut ext2 = Ext2 {
+            sb,
+            cur_block_group: 0,
+            cur_inode_table: 0,
+            group_metadata,
+            dir_entries: BTreeMap::new(),
+        };
+
+        // Add rootdir
+        let root_inode = InodeNum::new(2)?;
+        ext2.add_reserved_dir(arena, root_inode, root_inode, OsStr::new("/"))?;
+        let lost_found_inode = ext2.allocate_inode()?;
+        ext2.add_reserved_dir(
+            arena,
+            lost_found_inode,
+            root_inode,
+            OsStr::new("lost+found"),
+        )?;
+
+        Ok(ext2)
+    }
+
+    fn allocate_inode(&mut self) -> Result<InodeNum> {
+        if self.sb.free_inodes_count == 0 {
+            bail!(
+                "no free inodes: run out of s_inodes_count={}",
+                self.sb.inodes_count
+            );
+        }
+
+        if self.group_metadata[self.cur_inode_table]
+            .group_desc
+            .free_inodes_count
+            == 0
+        {
+            self.cur_inode_table += 1;
+        }
+
+        let gm = &mut self.group_metadata[self.cur_inode_table];
+        let alloc_inode = InodeNum::new(gm.first_free_inode)?;
+        // (alloc_inode - 1) because inode is 1-indexed.
+        gm.inode_bitmap
+            .set(
+                (usize::from(alloc_inode) - 1) % self.sb.inodes_per_group as usize,
+                true,
+            )
+            .context("failed to set inode bitmap")?;
+
+        gm.first_free_inode += 1;
+        gm.group_desc.free_inodes_count -= 1;
+        self.sb.free_inodes_count -= 1;
+        Ok(alloc_inode)
+    }
+
+    fn allocate_block(&mut self) -> Result<BlockId> {
+        self.allocate_contiguous_blocks(1).map(|v| v[0][0])
+    }
+
+    fn allocate_contiguous_blocks(&mut self, n: u16) -> Result<Vec<Vec<BlockId>>> {
+        if n == 0 {
+            bail!("n must be positive");
+        }
+        if self.sb.free_blocks_count < n as u32 {
+            bail!(
+                "no free blocks: run out of free_blocks_count={} < {n}",
+                self.sb.free_blocks_count
+            );
+        }
+
+        let mut contig_blocks = vec![];
+        let mut remaining = n;
+        while remaining > 0 {
+            let alloc_block_num = std::cmp::min(
+                remaining,
+                self.group_metadata[self.cur_block_group]
+                    .group_desc
+                    .free_blocks_count,
+            ) as u32;
+
+            let gm = &mut self.group_metadata[self.cur_block_group];
+            let alloc_blocks = (gm.first_free_block..gm.first_free_block + alloc_block_num)
+                .map(BlockId::from)
+                .collect();
+            gm.first_free_block += alloc_block_num;
+            gm.group_desc.free_blocks_count -= alloc_block_num as u16;
+            self.sb.free_blocks_count -= alloc_block_num;
+            for &b in &alloc_blocks {
+                let index = u32::from(b) as usize
+                    - self.cur_block_group * self.sb.blocks_per_group as usize;
+                gm.block_bitmap
+                    .set(index, true)
+                    .with_context(|| format!("failed to set block_bitmap at {index}"))?;
+            }
+            remaining -= alloc_block_num as u16;
+            if self.group_metadata[self.cur_block_group]
+                .group_desc
+                .free_blocks_count
+                == 0
+            {
+                self.cur_block_group += 1;
+            }
+            contig_blocks.push(alloc_blocks);
+        }
+
+        Ok(contig_blocks)
+    }
+
+    fn group_num_for_inode(&self, inode: InodeNum) -> usize {
+        inode.to_table_index() / self.sb.inodes_per_group as usize
+    }
+
+    fn get_inode_mut(&mut self, num: InodeNum) -> Result<&mut &'a mut Inode> {
+        let group_id = self.group_num_for_inode(num);
+        self.group_metadata[group_id]
+            .inode_table
+            .get_mut(&num)
+            .ok_or_else(|| anyhow!("{:?} not found", num))
+    }
+
+    fn allocate_dir_entry(
+        &mut self,
+        arena: &'a Arena<'a>,
+        parent: InodeNum,
+        inode: InodeNum,
+        typ: InodeType,
+        name: &OsStr,
+    ) -> Result<()> {
+        if name.is_empty() {
+            bail!("directory name must not be empty");
+        } else if name.len() > 255 {
+            bail!("name length must not exceed 255: {:?}", name);
+        }
+
+        // Disable false-positive `clippy::map_entry`.
+        // https://github.com/rust-lang/rust-clippy/issues/9470
+        #[allow(clippy::map_entry)]
+        if !self.dir_entries.contains_key(&parent) {
+            let block_id = self.allocate_block()?;
+            let inode = self.get_inode_mut(parent)?;
+            inode.block.set_direct_blocks(&[block_id])?;
+            inode.blocks = InodeBlocksCount::from_bytes_len(BLOCK_SIZE as u32);
+            self.dir_entries.insert(
+                parent,
+                vec![DirEntryBlock {
+                    block_id,
+                    offset: 0,
+                    entries: Vec::new(),
+                }],
+            );
+        }
+
+        // Allocates  a new block for dir entries if needed.
+        if !self
+            .dir_entries
+            .get(&parent)
+            .ok_or_else(|| anyhow!("parent {:?} not found for {:?}", parent, inode))?
+            .last()
+            .expect("directory entries must not be empty")
+            .has_enough_space(name)
+        {
+            let idx = self.dir_entries.get(&parent).unwrap().len();
+            let block_id = self.allocate_block()?;
+            let parent_inode = self.get_inode_mut(parent)?;
+            parent_inode.block.set_block_id(idx, &block_id)?;
+            parent_inode.blocks.add(BLOCK_SIZE as u32);
+            parent_inode.size += BLOCK_SIZE as u32;
+            self.dir_entries
+                .get_mut(&parent)
+                .unwrap()
+                .push(DirEntryBlock {
+                    block_id,
+                    offset: 0,
+                    entries: Vec::new(),
+                });
+        }
+
+        if typ == InodeType::Directory {
+            let parent = self.get_inode_mut(parent)?;
+            parent.links_count += 1;
+        }
+
+        let parent_dir = self
+            .dir_entries
+            .get_mut(&parent)
+            .ok_or_else(|| anyhow!("parent {:?} not found for {:?}", parent, inode))?
+            .last_mut()
+            .expect("directory entries must not be empty");
+
+        let dir_entry = DirEntryWithName::new(arena, inode, typ, name, parent_dir)?;
+
+        parent_dir.entries.push(dir_entry);
+
+        Ok(())
+    }
+
+    fn add_inode(&mut self, num: InodeNum, inode: &'a mut Inode) -> Result<()> {
+        let typ = inode.typ().ok_or_else(|| anyhow!("unknown inode type"))?;
+        let group_id = self.group_num_for_inode(num);
+        let gm = &mut self.group_metadata[group_id];
+        if gm.inode_table.contains_key(&num) {
+            bail!("inode {:?} already exists", &num);
+        }
+
+        if typ == InodeType::Directory {
+            gm.group_desc.used_dirs_count += 1;
+        }
+
+        gm.inode_table.insert(num, inode);
+        let inode_index = num.to_table_index() % self.sb.inodes_per_group as usize;
+        gm.inode_bitmap
+            .set(inode_index, true)
+            .with_context(|| format!("failed to set inode bitmap at {}", num.to_table_index()))?;
+
+        Ok(())
+    }
+
+    // Creates a reserved directory such as "root" or "lost+found".
+    // So, inode is constructed from scratch.
+    fn add_reserved_dir(
+        &mut self,
+        arena: &'a Arena<'a>,
+        inode_num: InodeNum,
+        parent_inode: InodeNum,
+        name: &OsStr,
+    ) -> Result<()> {
+        let group_id = self.group_num_for_inode(inode_num);
+        let inode = Inode::new(
+            arena,
+            &mut self.group_metadata[group_id],
+            inode_num,
+            InodeType::Directory,
+            BLOCK_SIZE as u32,
+        )?;
+        self.add_inode(inode_num, inode)?;
+
+        self.allocate_dir_entry(
+            arena,
+            inode_num,
+            inode_num,
+            InodeType::Directory,
+            OsStr::new("."),
+        )?;
+        self.allocate_dir_entry(
+            arena,
+            inode_num,
+            parent_inode,
+            InodeType::Directory,
+            OsStr::new(".."),
+        )?;
+
+        if inode_num != parent_inode {
+            self.allocate_dir_entry(arena, parent_inode, inode_num, InodeType::Directory, name)?;
+        }
+
+        Ok(())
+    }
+
+    fn add_dir(
+        &mut self,
+        arena: &'a Arena<'a>,
+        inode_num: InodeNum,
+        parent_inode: InodeNum,
+        path: &Path,
+    ) -> Result<()> {
+        let group_id = self.group_num_for_inode(inode_num);
+
+        let inode = Inode::from_metadata(
+            arena,
+            &mut self.group_metadata[group_id],
+            inode_num,
+            &std::fs::metadata(path)?,
+            BLOCK_SIZE as u32,
+            0,
+            InodeBlocksCount::from_bytes_len(0),
+            InodeBlock::default(),
+        )?;
+
+        self.add_inode(inode_num, inode)?;
+
+        self.allocate_dir_entry(
+            arena,
+            inode_num,
+            inode_num,
+            InodeType::Directory,
+            OsStr::new("."),
+        )?;
+        self.allocate_dir_entry(
+            arena,
+            inode_num,
+            parent_inode,
+            InodeType::Directory,
+            OsStr::new(".."),
+        )?;
+
+        if inode_num != parent_inode {
+            let name = path
+                .file_name()
+                .ok_or_else(|| anyhow!("failed to get directory name"))?;
+            self.allocate_dir_entry(arena, parent_inode, inode_num, InodeType::Directory, name)?;
+        }
+
+        Ok(())
+    }
+
+    /// Registers a file to be mmaped to the memory region.
+    /// This function just reserves a region for mmap() on `arena` and doesn't call mmap().
+    /// It's `arena`'s owner's responsibility to call mmap() for the registered files at the end.
+    fn register_mmap_file(
+        &mut self,
+        arena: &'a Arena<'a>,
+        block_num: usize,
+        file: &File,
+        file_size: usize,
+        mut file_offset: usize,
+    ) -> Result<(Vec<BlockId>, usize)> {
+        let contig_blocks = self.allocate_contiguous_blocks(block_num as u16)?;
+
+        let mut remaining = std::cmp::min(file_size - file_offset, block_num * BLOCK_SIZE);
+        let mut written = 0;
+        for blocks in &contig_blocks {
+            if remaining == 0 {
+                panic!("remaining == 0. This is a bug");
+            }
+            let length = std::cmp::min(remaining, BLOCK_SIZE * blocks.len());
+            let start_block = blocks[0];
+            let mem_offset = u32::from(start_block) as usize * BLOCK_SIZE;
+            // Reserve the region in arena to prevent from overwriting metadata.
+            arena
+                .reserve_for_mmap(
+                    mem_offset,
+                    length,
+                    file.try_clone().context("failed to clone file")?,
+                    file_offset,
+                )
+                .context("mmap for direct_block is already occupied")?;
+            remaining -= length;
+            written += length;
+            file_offset += length;
+        }
+        Ok((contig_blocks.concat(), written))
+    }
+
+    fn fill_indirect_block(
+        &mut self,
+        arena: &'a Arena<'a>,
+        indirect_table: BlockId,
+        file: &File,
+        file_size: usize,
+        file_offset: usize,
+    ) -> Result<usize> {
+        // We use a block as a table of indirect blocks.
+        // So, the maximum number of blocks supported by single indirect blocks is limited by the
+        // maximum number of entries in one block, which is (BLOCK_SIZE / 4) where 4 is the size of
+        // int.
+        let max_num_blocks = BLOCK_SIZE / 4;
+        let max_data_len = max_num_blocks * BLOCK_SIZE;
+
+        let length = std::cmp::min(file_size - file_offset, max_data_len);
+        let block_num = length.div_ceil(BLOCK_SIZE);
+
+        let (allocated_blocks, length) = self
+            .register_mmap_file(arena, block_num, file, file_size, file_offset)
+            .context("failed to reserve mmap regions on indirect block")?;
+
+        let slice = arena.allocate_slice(indirect_table, 0, 4 * block_num)?;
+        slice.copy_from_slice(allocated_blocks.as_bytes());
+
+        Ok(length)
+    }
+
+    fn add_file(
+        &mut self,
+        arena: &'a Arena<'a>,
+        parent_inode: InodeNum,
+        path: &Path,
+    ) -> Result<()> {
+        let inode_num = self.allocate_inode()?;
+
+        let name = path
+            .file_name()
+            .ok_or_else(|| anyhow!("failed to get directory name"))?;
+        let file = File::open(path)?;
+        let file_size = file.metadata()?.len() as usize;
+        let mut block = InodeBlock::default();
+
+        let mut written = 0;
+        let mut used_blocks = 0;
+
+        if file_size > 0 {
+            let block_num = std::cmp::min(
+                file_size.div_ceil(BLOCK_SIZE),
+                InodeBlock::NUM_DIRECT_BLOCKS,
+            );
+            let (allocated_blocks, len) = self
+                .register_mmap_file(arena, block_num, &file, file_size, 0)
+                .context("failed to reserve mmap regions on direct block")?;
+
+            block.set_direct_blocks(&allocated_blocks)?;
+            written += len;
+            used_blocks += block_num;
+        }
+
+        // Indirect data block
+        if written < file_size {
+            let indirect_table = self.allocate_block()?;
+            block.set_indirect_block_table(&indirect_table)?;
+            used_blocks += 1;
+
+            let length =
+                self.fill_indirect_block(arena, indirect_table, &file, file_size, written)?;
+            written += length;
+            used_blocks += length.div_ceil(BLOCK_SIZE);
+        }
+
+        // Double-indirect data block
+        // Supporting double-indirect data block allows storing ~4GB files if 4GB block size is
+        // used.
+        if written < file_size {
+            let d_indirect_table = self.allocate_block()?;
+            block.set_double_indirect_block_table(&d_indirect_table)?;
+            used_blocks += 1;
+
+            let mut indirect_blocks: Vec<BlockId> = vec![];
+            // Iterate (BLOCK_SIZE / 4) times, as each block id is 4-byte.
+            for _ in 0..BLOCK_SIZE / 4 {
+                if written >= file_size {
+                    break;
+                }
+                let indirect_table = self.allocate_block()?;
+                indirect_blocks.push(indirect_table);
+                used_blocks += 1;
+
+                let length = self
+                    .fill_indirect_block(arena, indirect_table, &file, file_size, written)
+                    .context("failed to indirect block for doubly-indirect table")?;
+                written += length;
+                used_blocks += length.div_ceil(BLOCK_SIZE);
+            }
+
+            let d_table = arena.allocate_slice(d_indirect_table, 0, indirect_blocks.len() * 4)?;
+            d_table.copy_from_slice(indirect_blocks.as_bytes());
+        }
+
+        if written != file_size {
+            unimplemented!("Triple-indirect block is not supported");
+        }
+
+        let blocks = InodeBlocksCount::from_bytes_len((used_blocks * BLOCK_SIZE) as u32);
+        let group_id = self.group_num_for_inode(inode_num);
+        let size = file_size as u32;
+        let inode = Inode::from_metadata(
+            arena,
+            &mut self.group_metadata[group_id],
+            inode_num,
+            &std::fs::metadata(path)?,
+            size,
+            1,
+            blocks,
+            block,
+        )?;
+
+        self.add_inode(inode_num, inode)?;
+
+        self.allocate_dir_entry(arena, parent_inode, inode_num, InodeType::Regular, name)?;
+
+        Ok(())
+    }
+
+    fn add_symlink(
+        &mut self,
+        arena: &'a Arena<'a>,
+        parent: InodeNum,
+        entry: &DirEntry,
+    ) -> Result<()> {
+        let link = entry.path();
+        let dst_path = std::fs::read_link(&link)?;
+        let dst = dst_path
+            .to_str()
+            .context("failed to convert symlink destination to str")?;
+
+        if dst.len() >= InodeBlock::max_inline_symlink_len() {
+            return self.add_long_symlink(arena, parent, &link, dst);
+        }
+
+        let inode_num = self.allocate_inode()?;
+        let mut block = InodeBlock::default();
+        block.set_inline_symlink(dst)?;
+        let group_id = self.group_num_for_inode(inode_num);
+        let inode = Inode::from_metadata(
+            arena,
+            &mut self.group_metadata[group_id],
+            inode_num,
+            &std::fs::symlink_metadata(&link)?,
+            dst.len() as u32,
+            1, //links_count,
+            InodeBlocksCount::from_bytes_len(0),
+            block,
+        )?;
+        self.add_inode(inode_num, inode)?;
+
+        let link_name = link.file_name().context("failed to get symlink name")?;
+        self.allocate_dir_entry(arena, parent, inode_num, InodeType::Symlink, link_name)?;
+
+        Ok(())
+    }
+
+    fn add_long_symlink(
+        &mut self,
+        arena: &'a Arena<'a>,
+        parent: InodeNum,
+        link: &Path,
+        dst: &str,
+    ) -> Result<()> {
+        let dst_len = dst.len();
+        if dst_len > BLOCK_SIZE {
+            bail!("symlink longer than block size: {:?}", dst);
+        }
+
+        // Copy symlink's destination to the block.
+        let symlink_block = self.allocate_block()?;
+        let buf = arena.allocate_slice(symlink_block, 0, dst_len)?;
+        buf.copy_from_slice(dst.as_bytes());
+
+        let inode_num = self.allocate_inode()?;
+        let mut block = InodeBlock::default();
+        block.set_direct_blocks(&[symlink_block])?;
+
+        let group_id = self.group_num_for_inode(inode_num);
+        let inode = Inode::from_metadata(
+            arena,
+            &mut self.group_metadata[group_id],
+            inode_num,
+            &std::fs::symlink_metadata(link)?,
+            dst_len as u32,
+            1, //links_count,
+            InodeBlocksCount::from_bytes_len(BLOCK_SIZE as u32),
+            block,
+        )?;
+        self.add_inode(inode_num, inode)?;
+
+        let link_name = link.file_name().context("failed to get symlink name")?;
+        self.allocate_dir_entry(arena, parent, inode_num, InodeType::Symlink, link_name)?;
+
+        Ok(())
+    }
+
+    /// Walks through `src_dir` and copies directories and files to the new file system.
+    pub(crate) fn copy_dirtree<P: AsRef<Path>>(
+        &mut self,
+        arena: &'a Arena<'a>,
+        src_dir: P,
+    ) -> Result<()> {
+        // Update the root directory's metadata with the metadata of `src_dir`.
+        let root_inode_num = InodeNum::new(2).expect("2 is a valid inode number");
+        let group_id = self.group_num_for_inode(root_inode_num);
+        let gm = &mut self.group_metadata[group_id];
+        let inode: &mut &mut Inode = gm
+            .inode_table
+            .get_mut(&root_inode_num)
+            .expect("root dir is not stored");
+        let metadata = src_dir
+            .as_ref()
+            .metadata()
+            .with_context(|| format!("failed to get metadata of {:?}", src_dir.as_ref()))?;
+        inode.update_metadata(&metadata);
+
+        self.copy_dirtree_rec(arena, InodeNum(2), src_dir)
+    }
+
+    fn copy_dirtree_rec<P: AsRef<Path>>(
+        &mut self,
+        arena: &'a Arena<'a>,
+        parent_inode: InodeNum,
+        src_dir: P,
+    ) -> Result<()> {
+        for entry in std::fs::read_dir(&src_dir)? {
+            let entry = entry?;
+            let ftype = entry.file_type()?;
+            if ftype.is_dir() {
+                // Since we creates `/lost+found` on the root directory, ignore the existing one.
+                if parent_inode.0 == 2 && entry.path().file_name() == Some(OsStr::new("lost+found"))
+                {
+                    info!("ext2: Ignore the existing /lost+found directory");
+                    continue;
+                }
+                let inode = self.allocate_inode()?;
+                self.add_dir(arena, inode, parent_inode, &entry.path())
+                    .with_context(|| {
+                        format!(
+                            "failed to add directory {:?} as inode={:?}",
+                            entry.path(),
+                            inode
+                        )
+                    })?;
+                self.copy_dirtree_rec(arena, inode, entry.path())?;
+            } else if ftype.is_file() {
+                self.add_file(arena, parent_inode, &entry.path())
+                    .with_context(|| {
+                        format!(
+                            "failed to add file {:?} in inode={:?}",
+                            entry.path(),
+                            parent_inode
+                        )
+                    })?;
+            } else if ftype.is_symlink() {
+                self.add_symlink(arena, parent_inode, &entry)?;
+            } else {
+                bail!("unknown file type {:?} for {:?}", ftype, entry.file_name());
+            }
+        }
+
+        Ok(())
+    }
+
+    pub(crate) fn copy_backup_metadata(self, arena: &'a Arena<'a>) -> Result<()> {
+        // Copy superblock and group_metadata to every block group
+        for i in 1..self.sb.num_groups() as usize {
+            let super_block_id = BlockId::from(self.sb.blocks_per_group * i as u32);
+            let bg_desc_block_id = BlockId::from(u32::from(super_block_id) + 1);
+            self.sb.block_group_nr = i as u16;
+            arena.write_to_mem(super_block_id, 0, self.sb)?;
+            let mut offset = 0;
+            for gm in &self.group_metadata {
+                arena.write_to_mem(bg_desc_block_id, offset, gm.group_desc)?;
+                offset += std::mem::size_of::<BlockGroupDescriptor>();
+            }
+        }
+        Ok(())
+    }
+}
diff --git a/ext2/src/inode.rs b/ext2/src/inode.rs
new file mode 100644
index 000000000..29dda22d6
--- /dev/null
+++ b/ext2/src/inode.rs
@@ -0,0 +1,357 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Defines the inode structure.
+
+use std::os::unix::fs::MetadataExt;
+
+use anyhow::bail;
+use anyhow::Result;
+use enumn::N;
+use zerocopy::AsBytes;
+use zerocopy_derive::FromBytes;
+use zerocopy_derive::FromZeroes;
+
+use crate::arena::Arena;
+use crate::arena::BlockId;
+use crate::blockgroup::GroupMetaData;
+
+/// Types of inodes.
+#[derive(Debug, PartialEq, Eq, Clone, Copy, N)]
+pub enum InodeType {
+    Fifo = 0x1,
+    Char = 0x2,
+    Directory = 0x4,
+    Block = 0x6,
+    Regular = 0x8,
+    Symlink = 0xa,
+    Socket = 0xc,
+}
+
+impl InodeType {
+    /// Converts to a file type for directory entry.
+    /// The value is defined in "Table 4.2. Defined Inode File Type Values" in the spec.
+    pub fn into_dir_entry_file_type(self) -> u8 {
+        match self {
+            InodeType::Regular => 1,
+            InodeType::Directory => 2,
+            InodeType::Char => 3,
+            InodeType::Block => 4,
+            InodeType::Fifo => 5,
+            InodeType::Socket => 6,
+            InodeType::Symlink => 7,
+        }
+    }
+}
+
+// Represents an inode number.
+// This is 1-indexed.
+#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
+pub(crate) struct InodeNum(pub u32);
+
+impl InodeNum {
+    pub fn new(inode: u32) -> Result<Self> {
+        if inode == 0 {
+            bail!("inode number is 1-indexed");
+        }
+        Ok(Self(inode))
+    }
+
+    // Returns index in the inode table.
+    pub fn to_table_index(self) -> usize {
+        // (num - 1) because inode is 1-indexed.
+        self.0 as usize - 1
+    }
+}
+
+impl From<InodeNum> for u32 {
+    fn from(inode: InodeNum) -> Self {
+        inode.0
+    }
+}
+
+impl From<InodeNum> for usize {
+    fn from(inode: InodeNum) -> Self {
+        inode.0 as usize
+    }
+}
+
+/// Size of the `block` field in Inode.
+const INODE_BLOCK_LEN: usize = 60;
+/// Represents 60-byte region for block in Inode.
+/// This region is used for various ways depending on the file type.
+/// For regular files and directories, it's used for storing 32-bit indices of blocks.
+///
+/// This is a wrapper of `[u8; 60]` to implement `Default` manually.
+#[repr(C)]
+#[derive(Debug, Copy, Clone, FromZeroes, FromBytes, AsBytes)]
+pub(crate) struct InodeBlock(pub [u8; INODE_BLOCK_LEN]);
+
+impl Default for InodeBlock {
+    fn default() -> Self {
+        Self([0; INODE_BLOCK_LEN])
+    }
+}
+
+impl InodeBlock {
+    // Each inode contains 12 direct pointers (0-11), one singly indirect pointer (12), one
+    // doubly indirect block pointer (13), and one triply indirect pointer (14).
+    pub const NUM_DIRECT_BLOCKS: usize = 12;
+    const INDIRECT_BLOCK_TABLE_ID: usize = Self::NUM_DIRECT_BLOCKS;
+    const DOUBLE_INDIRECT_BLOCK_TABLE_ID: usize = 13;
+
+    /// Set a block id at the given index.
+    pub fn set_block_id(&mut self, index: usize, block_id: &BlockId) -> Result<()> {
+        let offset = index * std::mem::size_of::<BlockId>();
+        let bytes = block_id.as_bytes();
+        if self.0.len() < offset + bytes.len() {
+            bail!("index out of bounds when setting block_id to InodeBlock: index={index}, block_id: {:?}", block_id);
+        }
+        self.0[offset..offset + bytes.len()].copy_from_slice(bytes);
+        Ok(())
+    }
+
+    /// Set an array of direct block IDs.
+    pub fn set_direct_blocks_from(
+        &mut self,
+        start_idx: usize,
+        block_ids: &[BlockId],
+    ) -> Result<()> {
+        let bytes = block_ids.as_bytes();
+        if bytes.len() + start_idx * 4 > self.0.len() {
+            bail!(
+                "length of direct blocks is {} bytes, but it must not exceed {}",
+                bytes.len(),
+                self.0.len()
+            );
+        }
+        self.0[start_idx * 4..(start_idx * 4 + bytes.len())].copy_from_slice(bytes);
+        Ok(())
+    }
+
+    /// Set an array of direct block IDs.
+    pub fn set_direct_blocks(&mut self, block_ids: &[BlockId]) -> Result<()> {
+        self.set_direct_blocks_from(0, block_ids)
+    }
+
+    /// Set a block id to be used as the indirect block table.
+    pub fn set_indirect_block_table(&mut self, block_id: &BlockId) -> Result<()> {
+        self.set_block_id(Self::INDIRECT_BLOCK_TABLE_ID, block_id)
+    }
+
+    /// Set a block id to be used as the double indirect block table.
+    pub fn set_double_indirect_block_table(&mut self, block_id: &BlockId) -> Result<()> {
+        self.set_block_id(Self::DOUBLE_INDIRECT_BLOCK_TABLE_ID, block_id)
+    }
+
+    /// Returns the max length of symbolic links that can be stored in the inode data.
+    /// This length contains the trailing `\0`.
+    pub const fn max_inline_symlink_len() -> usize {
+        INODE_BLOCK_LEN
+    }
+
+    /// Stores a given string as an inlined symbolic link data.
+    pub fn set_inline_symlink(&mut self, symlink: &str) -> Result<()> {
+        let bytes = symlink.as_bytes();
+        if bytes.len() >= Self::max_inline_symlink_len() {
+            bail!(
+                "symlink '{symlink}' exceeds or equals tomax length: {} >= {}",
+                bytes.len(),
+                Self::max_inline_symlink_len()
+            );
+        }
+        self.0[..bytes.len()].copy_from_slice(bytes);
+        Ok(())
+    }
+}
+
+/// The ext2 inode.
+///
+/// The field names are based on [the specification](https://www.nongnu.org/ext2-doc/ext2.html#inode-table).
+#[repr(C)]
+#[derive(Default, Debug, Copy, Clone, FromZeroes, FromBytes, AsBytes)]
+pub(crate) struct Inode {
+    mode: u16,
+    uid: u16,
+    pub size: u32,
+    atime: u32,
+    ctime: u32,
+    mtime: u32,
+    _dtime: u32,
+    gid: u16,
+    pub links_count: u16,
+    pub blocks: InodeBlocksCount,
+    _flags: u32,
+    _osd1: u32,
+    pub block: InodeBlock,
+    _generation: u32,
+    _file_acl: u32,
+    _dir_acl: u32,
+    _faddr: u32,
+    _fragment_num: u8,
+    _fragment_size: u8,
+    _reserved1: u16,
+    uid_high: u16,
+    gid_high: u16,
+    _reserved2: u32,
+}
+
+/// Used in `Inode` to represent how many 512-byte blocks are used by a file.
+///
+/// The block size '512' byte is fixed and not related to the actual block size of the file system.
+/// For more details, see notes for `i_blocks_lo` in the specification.
+#[repr(C)]
+#[derive(Default, Debug, Copy, Clone, FromZeroes, FromBytes, AsBytes)]
+pub struct InodeBlocksCount(u32);
+
+impl InodeBlocksCount {
+    const INODE_BLOCKS_SIZE: u32 = 512;
+
+    pub fn from_bytes_len(len: u32) -> Self {
+        Self(len / Self::INODE_BLOCKS_SIZE)
+    }
+
+    pub fn add(&mut self, v: u32) {
+        self.0 += v / Self::INODE_BLOCKS_SIZE;
+    }
+}
+
+impl Inode {
+    /// Size of the inode record in bytes.
+    /// Its return value must be stored in `Superblock` and used to calculate the size of
+    /// inode tables.
+    ///
+    /// Note that inode "record" size can be larger that inode "structure" size.
+    /// The gap between the end of the inode structure and the end of the inode record can be used
+    /// to store extended attributes.
+    pub fn inode_record_size() -> u16 {
+        // TODO(b/333988434): Support larger inode size (258 bytes) for extended attributes.
+        const EXT2_GOOD_OLD_INODE_SIZE: u16 = 128;
+        EXT2_GOOD_OLD_INODE_SIZE
+    }
+
+    pub fn new<'a>(
+        arena: &'a Arena<'a>,
+        group: &mut GroupMetaData,
+        inode_num: InodeNum,
+        typ: InodeType,
+        size: u32,
+    ) -> Result<&'a mut Self> {
+        const EXT2_S_IRUSR: u16 = 0x0100; // user read
+        const EXT2_S_IXUSR: u16 = 0x0040; // user execute
+        const EXT2_S_IRGRP: u16 = 0x0020; // group read
+        const EXT2_S_IXGRP: u16 = 0x0008; // group execute
+        const EXT2_S_IROTH: u16 = 0x0004; // others read
+        const EXT2_S_IXOTH: u16 = 0x0001; // others execute
+
+        let inode_offset = inode_num.to_table_index() * Inode::inode_record_size() as usize;
+        let inode =
+            arena.allocate::<Inode>(BlockId::from(group.group_desc.inode_table), inode_offset)?;
+
+        // Give read and execute permissions
+        let mode = ((typ as u16) << 12)
+            | EXT2_S_IRUSR
+            | EXT2_S_IXUSR
+            | EXT2_S_IRGRP
+            | EXT2_S_IXGRP
+            | EXT2_S_IROTH
+            | EXT2_S_IXOTH;
+
+        let now = std::time::SystemTime::now()
+            .duration_since(std::time::UNIX_EPOCH)?
+            .as_secs() as u32;
+
+        // SAFETY: geteuid never fail.
+        let uid = unsafe { libc::geteuid() };
+        let uid_high = (uid >> 16) as u16;
+        let uid_low = uid as u16;
+        // SAFETY: getegid never fail.
+        let gid = unsafe { libc::getegid() };
+        let gid_high = (gid >> 16) as u16;
+        let gid_low = gid as u16;
+
+        // TODO(b/333988434): Support extended attributes.
+        *inode = Self {
+            mode,
+            size,
+            atime: now,
+            ctime: now,
+            mtime: now,
+            uid: uid_low,
+            gid: gid_low,
+            uid_high,
+            gid_high,
+            ..Default::default()
+        };
+        Ok(inode)
+    }
+
+    pub fn from_metadata<'a>(
+        arena: &'a Arena<'a>,
+        group: &mut GroupMetaData,
+        inode_num: InodeNum,
+        m: &std::fs::Metadata,
+        size: u32,
+        links_count: u16,
+        blocks: InodeBlocksCount,
+        block: InodeBlock,
+    ) -> Result<&'a mut Self> {
+        let inodes_per_group = group.inode_bitmap.len();
+        // (inode_num - 1) because inode is 1-indexed.
+        let inode_offset =
+            ((usize::from(inode_num) - 1) % inodes_per_group) * Inode::inode_record_size() as usize;
+        let inode =
+            arena.allocate::<Inode>(BlockId::from(group.group_desc.inode_table), inode_offset)?;
+
+        let mode = m.mode() as u16;
+
+        let uid = m.uid();
+        let uid_high = (uid >> 16) as u16;
+        let uid_low: u16 = uid as u16;
+        let gid = m.gid();
+        let gid_high = (gid >> 16) as u16;
+        let gid_low: u16 = gid as u16;
+
+        let atime = m.atime() as u32;
+        let ctime = m.ctime() as u32;
+        let mtime = m.mtime() as u32;
+
+        *inode = Inode {
+            mode,
+            uid: uid_low,
+            gid: gid_low,
+            size,
+            atime,
+            ctime,
+            mtime,
+            links_count,
+            blocks,
+            block,
+            uid_high,
+            gid_high,
+            ..Default::default()
+        };
+
+        Ok(inode)
+    }
+
+    pub fn update_metadata(&mut self, m: &std::fs::Metadata) {
+        self.mode = m.mode() as u16;
+
+        let uid: u32 = m.uid();
+        self.uid_high = (uid >> 16) as u16;
+        self.uid = uid as u16;
+        let gid = m.gid();
+        self.gid_high = (gid >> 16) as u16;
+        self.gid = gid as u16;
+
+        self.atime = m.atime() as u32;
+        self.ctime = m.ctime() as u32;
+        self.mtime = m.mtime() as u32;
+    }
+
+    pub fn typ(&self) -> Option<InodeType> {
+        InodeType::n((self.mode >> 12) as u8)
+    }
+}
diff --git a/ext2/src/lib.rs b/ext2/src/lib.rs
new file mode 100644
index 000000000..2d6a7b9bc
--- /dev/null
+++ b/ext2/src/lib.rs
@@ -0,0 +1,19 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! This crate provides a logic for creating an ext2 filesystem on memory.
+
+#![cfg(any(target_os = "android", target_os = "linux"))]
+#![deny(missing_docs)]
+
+mod arena;
+mod bitmap;
+mod blockgroup;
+mod builder;
+mod fs;
+mod inode;
+mod superblock;
+
+pub use blockgroup::BLOCK_SIZE;
+pub use builder::Builder;
diff --git a/ext2/src/superblock.rs b/ext2/src/superblock.rs
new file mode 100644
index 000000000..f3ac0edca
--- /dev/null
+++ b/ext2/src/superblock.rs
@@ -0,0 +1,120 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Defines the superblock structure.
+
+use anyhow::Result;
+use zerocopy::AsBytes;
+use zerocopy_derive::FromBytes;
+use zerocopy_derive::FromZeroes;
+
+use crate::arena::Arena;
+use crate::arena::BlockId;
+use crate::blockgroup::BLOCK_SIZE;
+use crate::builder::Builder;
+use crate::inode::Inode;
+
+/// A struct to represent the configuration of an ext2 filesystem.
+
+/// The ext2 superblock.
+///
+/// The field names are based on [the specification](https://www.nongnu.org/ext2-doc/ext2.html#superblock).
+/// Note that this struct only holds the fields at the beginning of the superblock. All fields after
+/// the fields supported by this structure are filled with zeros.
+#[repr(C)]
+#[derive(Default, Debug, Copy, Clone, FromZeroes, FromBytes, AsBytes)]
+pub(crate) struct SuperBlock {
+    pub inodes_count: u32,
+    pub blocks_count: u32,
+    _r_blocks_count: u32,
+    pub free_blocks_count: u32,
+    pub free_inodes_count: u32,
+    _first_data_block: u32,
+    _log_block_size: u32,
+    log_frag_size: u32,
+    pub blocks_per_group: u32,
+    frags_per_group: u32,
+    pub inodes_per_group: u32,
+    mtime: u32,
+    wtime: u32,
+    _mnt_count: u16,
+    _max_mnt_count: u16,
+    magic: u16,
+    state: u16,
+    errors: u16,
+    _minor_rev_level: u16,
+    _lastcheck: u32,
+    _checkinterval: u32,
+    _creator_os: u32,
+    rev_level: u32,
+    _def_resuid: u16,
+    _def_resgid: u16,
+    first_ino: u32,
+    pub inode_size: u16,
+    pub block_group_nr: u16,
+    feature_compat: u32,
+    feature_incompat: u32,
+    _feature_ro_compat: u32,
+    uuid: [u8; 16],
+    // Add more fields if needed.
+}
+
+impl SuperBlock {
+    pub fn new<'a>(arena: &'a Arena<'a>, cfg: &Builder) -> Result<&'a mut SuperBlock> {
+        const EXT2_MAGIC_NUMBER: u16 = 0xEF53;
+        const COMPAT_EXT_ATTR: u32 = 0x8;
+
+        let num_groups = cfg.size / (cfg.blocks_per_group * BLOCK_SIZE as u32);
+        let blocks_per_group = cfg.blocks_per_group;
+        let inodes_per_group = cfg.inodes_per_group;
+
+        let log_block_size = 2; // (1024 << log_block_size) = 4K bytes
+
+        let now = std::time::SystemTime::now()
+            .duration_since(std::time::UNIX_EPOCH)?
+            .as_secs() as u32;
+
+        let uuid = uuid::Uuid::new_v4().into_bytes();
+        let inodes_count = inodes_per_group * num_groups;
+        let blocks_count = blocks_per_group * num_groups;
+
+        // Reserve 10 inodes. Usually inode 11 is used for the lost+found directory.
+        // <https://docs.kernel.org/filesystems/ext4/special_inodes.html>.
+        let first_ino = 11;
+
+        // Superblock is located at 1024 bytes in the first block.
+        let sb = arena.allocate::<SuperBlock>(BlockId::from(0), 1024)?;
+        *sb = Self {
+            inodes_count,
+            blocks_count,
+            free_blocks_count: 0, //blocks_count, // All blocks are free
+            free_inodes_count: inodes_count, // All inodes are free
+            _log_block_size: log_block_size,
+            log_frag_size: log_block_size,
+            blocks_per_group,
+            frags_per_group: blocks_per_group,
+            inodes_per_group,
+            mtime: now,
+            wtime: now,
+            magic: EXT2_MAGIC_NUMBER,
+            state: 1,  // clean
+            errors: 1, // continue on errors
+            rev_level: 1,
+            first_ino,
+            inode_size: Inode::inode_record_size(),
+            block_group_nr: 1, // super block is in block group 1
+            feature_compat: COMPAT_EXT_ATTR,
+            feature_incompat: 0x2, // Directory entries contain a type field
+            uuid,
+            ..Default::default()
+        };
+
+        Ok(sb)
+    }
+
+    #[inline]
+    pub fn num_groups(&self) -> u16 {
+        (self.inodes_count / self.inodes_per_group) as u16
+    }
+}
diff --git a/ext2/tests/tests.rs b/ext2/tests/tests.rs
new file mode 100644
index 000000000..96dd0cbca
--- /dev/null
+++ b/ext2/tests/tests.rs
@@ -0,0 +1,702 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#![cfg(target_os = "linux")]
+
+use std::collections::BTreeSet;
+use std::fs;
+use std::fs::create_dir;
+use std::fs::read_link;
+use std::fs::symlink_metadata;
+use std::fs::File;
+use std::fs::OpenOptions;
+use std::io::BufWriter;
+use std::io::Seek;
+use std::io::SeekFrom;
+use std::io::Write;
+use std::os::unix::fs::symlink;
+use std::path::Path;
+use std::path::PathBuf;
+use std::process::Command;
+
+use base::MappedRegion;
+use ext2::Builder;
+use tempfile::tempdir;
+use tempfile::TempDir;
+use walkdir::WalkDir;
+
+const FSCK_PATH: &str = "/usr/sbin/e2fsck";
+const DEBUGFS_PATH: &str = "/usr/sbin/debugfs";
+
+const BLOCK_SIZE: u32 = 4096;
+
+fn run_fsck(path: &PathBuf) {
+    // Run fsck and scheck its exit code is 0.
+    // Passing 'y' to stop attempting interactive repair.
+    let output = Command::new(FSCK_PATH)
+        .arg("-fvy")
+        .arg(path)
+        .output()
+        .unwrap();
+    println!("status: {}", output.status);
+    println!("stdout: {}", String::from_utf8_lossy(&output.stdout));
+    println!("stderr: {}", String::from_utf8_lossy(&output.stderr));
+    assert!(output.status.success());
+}
+
+fn run_debugfs_cmd(args: &[&str], disk: &PathBuf) -> String {
+    let output = Command::new(DEBUGFS_PATH)
+        .arg("-R")
+        .args(args)
+        .arg(disk)
+        .output()
+        .unwrap();
+
+    let stdout = String::from_utf8_lossy(&output.stdout);
+    let stderr = String::from_utf8_lossy(&output.stderr);
+    println!("status: {}", output.status);
+    println!("stdout: {stdout}");
+    println!("stderr: {stderr}");
+    assert!(output.status.success());
+
+    stdout.trim_start().trim_end().to_string()
+}
+
+fn mkfs(td: &TempDir, builder: Builder, src_dir: Option<&Path>) -> PathBuf {
+    let path = td.path().join("empty.ext2");
+    let mem = builder
+        .allocate_memory()
+        .unwrap()
+        .build_mmap_info(src_dir)
+        .unwrap()
+        .do_mmap()
+        .unwrap();
+    // SAFETY: `mem` has a valid pointer and its size.
+    let buf = unsafe { std::slice::from_raw_parts(mem.as_ptr(), mem.size()) };
+    let mut file = OpenOptions::new()
+        .write(true)
+        .create(true)
+        .truncate(true)
+        .open(&path)
+        .unwrap();
+    file.write_all(buf).unwrap();
+
+    run_fsck(&path);
+
+    path
+}
+
+#[test]
+fn test_mkfs_empty() {
+    let td = tempdir().unwrap();
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 1024,
+            inodes_per_group: 1024,
+            ..Default::default()
+        },
+        None,
+    );
+
+    // Ensure the content of the generated disk image with `debugfs`.
+    // It contains the following entries:
+    // - `.`: the rootdir whose inode is 2 and rec_len is 12.
+    // - `..`: this is also the rootdir with same inode and the same rec_len.
+    // - `lost+found`: inode is 11 and rec_len is 4072 (= block_size - 2*12).
+    assert_eq!(
+        run_debugfs_cmd(&["ls"], &disk),
+        "2  (12) .    2  (12) ..    11  (4072) lost+found"
+    );
+}
+
+#[test]
+fn test_mkfs_empty_multi_block_groups() {
+    let td = tempdir().unwrap();
+    let blocks_per_group = 2048;
+    let num_groups = 2;
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group,
+            inodes_per_group: 4096,
+            size: 4096 * blocks_per_group * num_groups,
+        },
+        None,
+    );
+    assert_eq!(
+        run_debugfs_cmd(&["ls"], &disk),
+        "2  (12) .    2  (12) ..    11  (4072) lost+found"
+    );
+}
+
+fn collect_paths(dir: &Path, skip_lost_found: bool) -> BTreeSet<(String, PathBuf)> {
+    WalkDir::new(dir)
+        .into_iter()
+        .filter_map(|entry| {
+            entry.ok().and_then(|e| {
+                let name = e
+                    .path()
+                    .strip_prefix(dir)
+                    .unwrap()
+                    .to_string_lossy()
+                    .into_owned();
+                let path = e.path().to_path_buf();
+                if name.is_empty() {
+                    return None;
+                }
+                if skip_lost_found && name == "lost+found" {
+                    return None;
+                }
+
+                Some((name, path))
+            })
+        })
+        .collect()
+}
+
+fn assert_eq_dirs(td: &TempDir, dir: &Path, disk: &PathBuf) {
+    // dump the disk contents to `dump_dir`.
+    let dump_dir = td.path().join("dump");
+    std::fs::create_dir(&dump_dir).unwrap();
+    run_debugfs_cmd(
+        &[&format!(
+            "rdump / {}",
+            dump_dir.as_os_str().to_str().unwrap()
+        )],
+        disk,
+    );
+
+    let paths1 = collect_paths(dir, true);
+    let paths2 = collect_paths(&dump_dir, true);
+    if paths1.len() != paths2.len() {
+        panic!(
+            "number of entries mismatch: {:?}={:?}, {:?}={:?}",
+            dir,
+            paths1.len(),
+            dump_dir,
+            paths2.len()
+        );
+    }
+
+    for ((name1, path1), (name2, path2)) in paths1.iter().zip(paths2.iter()) {
+        assert_eq!(name1, name2);
+        let m1 = symlink_metadata(path1).unwrap();
+        let m2 = symlink_metadata(path2).unwrap();
+        assert_eq!(
+            m1.file_type(),
+            m2.file_type(),
+            "file type mismatch ({name1})"
+        );
+
+        if m1.file_type().is_symlink() {
+            let dst1 = read_link(path1).unwrap();
+            let dst2 = read_link(path2).unwrap();
+            assert_eq!(
+                dst1, dst2,
+                "symlink mismatch ({name1}): {:?}->{:?} vs {:?}->{:?}",
+                path1, dst1, path2, dst2
+            );
+        } else {
+            assert_eq!(m1.len(), m2.len(), "length mismatch ({name1})");
+        }
+
+        assert_eq!(
+            m1.permissions(),
+            m2.permissions(),
+            "permissions mismatch ({name1})"
+        );
+
+        if m1.file_type().is_file() {
+            let c1 = std::fs::read_to_string(path1).unwrap();
+            let c2 = std::fs::read_to_string(path2).unwrap();
+            assert_eq!(c1, c2, "content mismatch: ({name1})");
+        }
+    }
+}
+
+#[test]
+fn test_simple_dir() {
+    // testdata
+    //  a.txt
+    //  b.txt
+    //  dir
+    //      c.txt
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+    create_dir(&dir).unwrap();
+    File::create(dir.join("a.txt")).unwrap();
+    File::create(dir.join("b.txt")).unwrap();
+    create_dir(dir.join("dir")).unwrap();
+    File::create(dir.join("dir/c.txt")).unwrap();
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+
+    td.close().unwrap(); // make sure that tempdir is properly deleted.
+}
+
+#[test]
+fn test_nested_dirs() {
+    // testdata
+    //  dir1
+    //      a.txt
+    //      dir2
+    //          b.txt
+    //          dir3
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+    create_dir(&dir).unwrap();
+    let dir1 = &dir.join("dir1");
+    create_dir(dir1).unwrap();
+    File::create(dir1.join("a.txt")).unwrap();
+    let dir2 = dir1.join("dir2");
+    create_dir(&dir2).unwrap();
+    File::create(dir2.join("b.txt")).unwrap();
+    let dir3 = dir2.join("dir3");
+    create_dir(dir3).unwrap();
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_file_contents() {
+    // testdata
+    //  hello.txt (content: "Hello!\n")
+    //  big.txt (content: 10KB of data, which doesn't fit in one block)
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+    create_dir(&dir).unwrap();
+    let mut hello = File::create(dir.join("hello.txt")).unwrap();
+    hello.write_all(b"Hello!\n").unwrap();
+    let mut big = BufWriter::new(File::create(dir.join("big.txt")).unwrap());
+    let data = b"123456789\n";
+    for _ in 0..1024 {
+        big.write_all(data).unwrap();
+    }
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_max_file_name() {
+    // testdata
+    //  aa..aa (whose file name length is 255, which is the ext2/3/4's maximum file name length)
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+    create_dir(&dir).unwrap();
+    let long_name = "a".repeat(255);
+    File::create(dir.join(long_name)).unwrap();
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_mkfs_indirect_block() {
+    // testdata
+    //  big.txt (80KiB), which requires indirect blocks
+    //  huge.txt (8MiB), which requires doubly indirect blocks
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+    std::fs::create_dir(&dir).unwrap();
+    let mut big = std::fs::File::create(dir.join("big.txt")).unwrap();
+    big.seek(SeekFrom::Start(80 * 1024)).unwrap();
+    big.write_all(&[0]).unwrap();
+
+    let mut huge = std::fs::File::create(dir.join("huge.txt")).unwrap();
+    huge.seek(SeekFrom::Start(8 * 1024 * 1024)).unwrap();
+    huge.write_all(&[0]).unwrap();
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 4096,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_mkfs_symlink() {
+    // testdata
+    //  a.txt
+    //  self -> ./self
+    //  symlink0 -> ./a.txt
+    //  symlink1 -> ./symlink0
+    //  dir
+    //      upper-a -> ../a.txt
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+    create_dir(&dir).unwrap();
+
+    let mut f = File::create(dir.join("a.txt")).unwrap();
+    f.write_all("Hello".as_bytes()).unwrap();
+
+    symlink("./self", dir.join("self")).unwrap();
+
+    symlink("./a.txt", dir.join("symlink0")).unwrap();
+    symlink("./symlink0", dir.join("symlink1")).unwrap();
+
+    create_dir(dir.join("dir")).unwrap();
+    symlink("../a.txt", dir.join("dir/upper-a")).unwrap();
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_mkfs_abs_symlink() {
+    // testdata
+    //  a.txt
+    //  a -> /testdata/a
+    //  self -> /testdata/self
+    //  tmp -> /tmp
+    //  abc -> /a/b/c
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    std::fs::create_dir(&dir).unwrap();
+    File::create(dir.join("a.txt")).unwrap();
+    symlink(dir.join("a.txt"), dir.join("a")).unwrap();
+    symlink(dir.join("self"), dir.join("self")).unwrap();
+    symlink("/tmp/", dir.join("tmp")).unwrap();
+    symlink("/a/b/c", dir.join("abc")).unwrap();
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_mkfs_symlink_to_deleted() {
+    // testdata
+    //  (deleted)
+    //  symlink_to_deleted -> (deleted)
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    std::fs::create_dir(&dir).unwrap();
+    File::create(dir.join("deleted")).unwrap();
+    symlink("./deleted", dir.join("symlink_to_deleted")).unwrap();
+    fs::remove_file(dir.join("deleted")).unwrap();
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_mkfs_long_symlink() {
+    // testdata
+    //  /(long name directory)/a.txt
+    //  symlink -> /(long name directory)/a.txt
+    //  (60-byte filename)
+    //  symlink60 -> (60-byte filename)
+
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    create_dir(&dir).unwrap();
+
+    const LONG_DIR_NAME: &str =
+        "this_is_a_very_long_directory_name_so_that_name_cannoot_fit_in_60_characters_in_inode";
+    assert!(LONG_DIR_NAME.len() > 60);
+
+    let long_dir = dir.join(LONG_DIR_NAME);
+    create_dir(&long_dir).unwrap();
+    File::create(long_dir.join("a.txt")).unwrap();
+    symlink(long_dir.join("a.txt"), dir.join("symlink")).unwrap();
+
+    const SIXTY_CHAR_DIR_NAME: &str =
+        "./this_is_just_60_byte_long_so_it_can_work_as_a_corner_case.";
+    assert_eq!(SIXTY_CHAR_DIR_NAME.len(), 60);
+    File::create(dir.join(SIXTY_CHAR_DIR_NAME)).unwrap();
+    symlink(SIXTY_CHAR_DIR_NAME, dir.join("symlink60")).unwrap();
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+#[test]
+fn test_ignore_lost_found() {
+    // Ignore /lost+found/ directory in source to avoid conflict.
+    //
+    // testdata
+    //  lost+found (ignored and recreated as an empty dir)
+    //     should_be_ignored.txt
+    //  sub
+    //      lost+found (not ignored)
+    //          a.txt
+
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    create_dir(&dir).unwrap();
+    create_dir(dir.join("lost+found")).unwrap();
+    File::create(dir.join("lost+found").join("should_be_ignored.txt")).unwrap();
+    create_dir(dir.join("sub")).unwrap();
+    create_dir(dir.join("sub").join("lost+found")).unwrap();
+    File::create(dir.join("sub").join("lost+found").join("a.txt")).unwrap();
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    // dump the disk contents to `dump_dir`.
+    let dump_dir = td.path().join("dump");
+    std::fs::create_dir(&dump_dir).unwrap();
+    run_debugfs_cmd(
+        &[&format!(
+            "rdump / {}",
+            dump_dir.as_os_str().to_str().unwrap()
+        )],
+        &disk,
+    );
+
+    let paths = collect_paths(&dump_dir, false /* skip_lost_found */)
+        .into_iter()
+        .map(|(path, _)| path)
+        .collect::<BTreeSet<_>>();
+    assert_eq!(
+        paths,
+        BTreeSet::from([
+            "lost+found".to_string(),
+            // 'lost+found/should_be_ignored.txt' must not in the result.
+            "sub".to_string(),
+            "sub/lost+found".to_string(),
+            "sub/lost+found/a.txt".to_string()
+        ])
+    );
+}
+
+#[test]
+fn test_multiple_block_directory_entry() {
+    // Creates a many files in a directory.
+    // So the sum of the sizes of directory entries exceeds 4KB and they need to be stored in
+    // multiple blocks.
+    //
+    // testdata
+    //   0.txt
+    //   1.txt
+    // ...
+    //  999.txt
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    std::fs::create_dir(&dir).unwrap();
+
+    for i in 0..1000 {
+        let path = dir.join(&format!("{i}.txt"));
+        File::create(&path).unwrap();
+    }
+
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group: 2048,
+            inodes_per_group: 4096,
+            ..Default::default()
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+// Test a case where the inode tables spans multiple block groups.
+#[test]
+fn test_multiple_bg_multi_inode_bitmap() {
+    // testdata
+    //   0.txt
+    //   1.txt
+    // ...
+    //  999.txt
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    std::fs::create_dir(&dir).unwrap();
+
+    for i in 0..1000 {
+        let fname = format!("{i}.txt");
+        let path = dir.join(&fname);
+        let mut f = File::create(&path).unwrap();
+        // Write a file name to the file.
+        f.write_all(fname.as_bytes()).unwrap();
+    }
+
+    let blocks_per_group = 1024;
+    // Set `inodes_per_group` to a smaller value than the number of files.
+    // So, the inode table in the 2nd block group will be used.
+    let inodes_per_group = 512;
+    let num_groups = 2;
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group,
+            inodes_per_group,
+            size: BLOCK_SIZE * blocks_per_group * num_groups,
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+/// Test a case where the block tables spans multiple block groups.
+#[test]
+fn test_multiple_bg_multi_block_bitmap() {
+    // testdata
+    //   0.txt
+    //   1.txt
+    // ...
+    //  999.txt
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    std::fs::create_dir(&dir).unwrap();
+
+    for i in 0..1000 {
+        let fname = format!("{i}.txt");
+        let path = dir.join(&fname);
+        let mut f = File::create(&path).unwrap();
+        // Write a file name to the file.
+        f.write_all(fname.as_bytes()).unwrap();
+    }
+
+    // Set `blocks_per_group` to a smaller value than the number of files.
+    // So, the block table in the 2nd block group will be used.
+    let blocks_per_group = 512;
+    let inodes_per_group = 2048;
+    let num_groups = 4;
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group,
+            inodes_per_group,
+            size: BLOCK_SIZE * blocks_per_group * num_groups,
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
+
+// Test a case where a file spans multiple block groups.
+#[test]
+fn test_multiple_bg_big_files() {
+    // testdata
+    //   0.txt (200 * 5000 bytes)
+    //   1.txt (200 * 5000 bytes)
+    // ...
+    //  9.txt (200 * 5000 bytes)
+    let td = tempdir().unwrap();
+    let dir = td.path().join("testdata");
+
+    std::fs::create_dir(&dir).unwrap();
+
+    // Prepare a large data.
+    let data = vec!["0123456789"; 5000 * 20].concat();
+    for i in 0..10 {
+        let path = dir.join(&format!("{i}.txt"));
+        let mut f = File::create(&path).unwrap();
+        f.write_all(data.as_bytes()).unwrap();
+    }
+
+    // Set `blocks_per_group` to a value smaller than |size of a file| / 4K.
+    // So, each file spans multiple block groups.
+    let blocks_per_group = 128;
+    let num_groups = 30;
+    let disk = mkfs(
+        &td,
+        Builder {
+            blocks_per_group,
+            inodes_per_group: 1024,
+            size: BLOCK_SIZE * blocks_per_group * num_groups,
+        },
+        Some(&dir),
+    );
+
+    assert_eq_dirs(&td, &dir, &disk);
+}
diff --git a/fuse/Android.bp b/fuse/Android.bp
index 5d6c6fd4c..9374a70c8 100644
--- a/fuse/Android.bp
+++ b/fuse/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "fuse",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -48,7 +48,7 @@ rust_library {
     crate_name: "fuse",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
@@ -64,7 +64,8 @@ rust_library {
         "libremain",
     ],
     visibility: [
-        "//packages/modules/Virtualization/authfs",
-        "//packages/modules/Virtualization/zipfuse",
+        "//packages/modules/Virtualization/guest/authfs",
+        "//packages/modules/Virtualization/guest/zipfuse",
+        "//packages/modules/Virtualization/tests/authfs",
     ],
 }
diff --git a/fuse/Cargo.toml b/fuse/Cargo.toml
index e256534a4..b41dc8fb6 100644
--- a/fuse/Cargo.toml
+++ b/fuse/Cargo.toml
@@ -8,12 +8,12 @@ edition = "2021"
 path = "src/lib.rs"
 
 [dependencies]
-base = "*"
+base = { path = "../base" }
 bitflags = "2.2.1"
 crossbeam-utils = "0.8"
 cros_tracing = { path = "../cros_tracing" }
 enumn = "0.1.0"
-libc = { version = "*", features = ["extra_traits"] }
+libc = { version = "0.2", features = ["extra_traits"] }
 remain = "0.2"
 thiserror = "1.0.20"
 zerocopy = { version = "0.7", features = ["derive"] }
diff --git a/fuse/src/filesystem.rs b/fuse/src/filesystem.rs
index 3ce1c671e..2a2bf9c38 100644
--- a/fuse/src/filesystem.rs
+++ b/fuse/src/filesystem.rs
@@ -119,6 +119,7 @@ pub struct DirEntry<'a> {
 }
 
 /// A reply to a `getxattr` method call.
+#[derive(Debug)]
 pub enum GetxattrReply {
     /// The value of the requested extended attribute. This can be arbitrary textual or binary data
     /// and does not need to be nul-terminated.
@@ -147,6 +148,7 @@ pub enum ListxattrReply {
 }
 
 /// A reply to an `ioctl` method call.
+#[derive(Debug)]
 pub enum IoctlReply {
     /// Indicates that the ioctl should be retried. This is only a valid reply when the `flags`
     /// field of the ioctl request contains `IoctlFlags::UNRESTRICTED`. The kernel will read in
@@ -231,7 +233,7 @@ pub trait ZeroCopyReader {
     fn copy_to_end(&mut self, f: &mut File, mut off: u64) -> io::Result<usize> {
         let mut out = 0;
         loop {
-            match self.read_to(f, ::std::usize::MAX, off) {
+            match self.read_to(f, usize::MAX, off) {
                 Ok(0) => return Ok(out),
                 Ok(n) => {
                     off = off.saturating_add(n as u64);
@@ -324,7 +326,7 @@ pub trait ZeroCopyWriter {
     fn copy_to_end(&mut self, f: &mut File, mut off: u64) -> io::Result<usize> {
         let mut out = 0;
         loop {
-            match self.write_from(f, ::std::usize::MAX, off) {
+            match self.write_from(f, usize::MAX, off) {
                 Ok(0) => return Ok(out),
                 Ok(n) => {
                     off = off.saturating_add(n as u64);
@@ -1269,8 +1271,8 @@ pub trait FileSystem {
     ///
     /// b) File exist already (exception is O_EXCL)
     ///    - O_CREAT:
-    ///     - Open the file
-    ///     - Return d_entry and file handler
+    ///      - Open the file
+    ///      - Return d_entry and file handler
     ///    - O_EXCL:
     ///      - EEXIST
     ///
diff --git a/fuse/src/server.rs b/fuse/src/server.rs
index 3b988bf55..5fac9a789 100644
--- a/fuse/src/server.rs
+++ b/fuse/src/server.rs
@@ -1038,8 +1038,8 @@ impl<F: FileSystem + Sync> Server<F> {
                     minor: KERNEL_MINOR_VERSION,
                     max_readahead,
                     flags: enabled.bits() as u32,
-                    max_background: ::std::u16::MAX,
-                    congestion_threshold: (::std::u16::MAX / 4) * 3,
+                    max_background: u16::MAX,
+                    congestion_threshold: (u16::MAX / 4) * 3,
                     max_write,
                     time_gran: 1, // nanoseconds
                     max_pages,
@@ -1206,13 +1206,15 @@ impl<F: FileSystem + Sync> Server<F> {
                     let mut total_written = 0;
                     while let Some(dirent) = entries.next() {
                         let mut entry_inode = None;
-                        match self
+                        let dirent_result = self
                             .lookup_dirent_attribute(&in_header, &dirent)
                             .and_then(|e| {
                                 entry_inode = Some(e.inode);
                                 let remaining = (size as usize).saturating_sub(total_written);
                                 add_dirent(cursor, remaining, &dirent, Some(e))
-                            }) {
+                            });
+
+                        match dirent_result {
                             Ok(0) => {
                                 // No more space left in the buffer but we need to undo the lookup
                                 // that created the Entry or we will end up with mismatched lookup
@@ -1880,7 +1882,7 @@ fn add_dirent<W: Writer>(
 ) -> io::Result<usize> {
     // Strip the trailing '\0'.
     let name = d.name.to_bytes();
-    if name.len() > ::std::u32::MAX as usize {
+    if name.len() > u32::MAX as usize {
         return Err(io::Error::from_raw_os_error(libc::EOVERFLOW));
     }
 
@@ -1938,18 +1940,18 @@ fn add_dirent<W: Writer>(
 /// # Arguments
 ///
 /// * `buf` - a byte array that contains the contents following any expected byte string parameters
-/// of the FUSE request from the server. It begins with a struct `SecctxHeader`, and then the
-/// subsequent entry is a struct `Secctx` followed by a nul-terminated string with the xattribute
-/// name and then another nul-terminated string with the value for that xattr.
+///   of the FUSE request from the server. It begins with a struct `SecctxHeader`, and then the
+///   subsequent entry is a struct `Secctx` followed by a nul-terminated string with the xattribute
+///   name and then another nul-terminated string with the value for that xattr.
 ///
 /// # Errors
 ///
 /// * `Error::InvalidHeaderLength` - indicates that there is an inconsistency between the size of
-/// the data read from `buf` and the stated `size` of the `SecctxHeader`, the respective `Secctx`
-/// struct, or `buf` itself.
+///   the data read from `buf` and the stated `size` of the `SecctxHeader`, the respective `Secctx`
+///   struct, or `buf` itself.
 /// * `Error::DecodeMessage` - indicates that the expected structs cannot be read from `buf`.
 /// * `Error::MissingParameter` - indicates that either a security context `name` or `value` is
-/// missing from a security context entry.
+///   missing from a security context entry.
 fn parse_selinux_xattr(buf: &[u8]) -> Result<Option<&CStr>> {
     // Return early if request was not followed by context information
     if buf.is_empty() {
diff --git a/fuzz/Cargo.toml b/fuzz/Cargo.toml
index 99b4a5802..2cd2ed17c 100644
--- a/fuzz/Cargo.toml
+++ b/fuzz/Cargo.toml
@@ -13,13 +13,13 @@ disk = { path = "../disk" }
 fuse = { path = "../fuse" }
 hypervisor = { path = "../hypervisor" }
 kernel_loader = { path = "../kernel_loader" }
-libc = "*"
+libc = "0.2"
 rand = "0.8"
 base = { path = "../base" }
 tempfile = "3"
 usb_util = { path = "../usb_util" }
 vm_memory = { path = "../vm_memory" }
-p9 = "*"
+p9 = "0.2"
 rand_core = {version = "0.6", features = ["std"]}
 cfg-if = "1.0"
 
diff --git a/fuzz/fuzz_targets/block_fuzzer.rs b/fuzz/fuzz_targets/block_fuzzer.rs
index 3a86aaad0..573ba165b 100644
--- a/fuzz/fuzz_targets/block_fuzzer.rs
+++ b/fuzz/fuzz_targets/block_fuzzer.rs
@@ -79,11 +79,19 @@ fuzz_target!(|bytes| {
         return;
     }
 
+    let interrupt = Interrupt::new(
+        IrqLevelEvent::new().unwrap(),
+        None,   // msix_config
+        0xFFFF, // VIRTIO_MSI_NO_VECTOR
+        #[cfg(target_arch = "x86_64")]
+        None,
+    );
+
     let mut q = QueueConfig::new(QUEUE_SIZE, 0);
     q.set_size(QUEUE_SIZE / 2);
     q.set_ready(true);
     let q = q
-        .activate(&mem, Event::new().unwrap())
+        .activate(&mem, Event::new().unwrap(), interrupt.clone())
         .expect("QueueConfig::activate");
     let queue_evt = q.event().try_clone().unwrap();
 
@@ -102,17 +110,7 @@ fuzz_target!(|bytes| {
     .unwrap();
 
     block
-        .activate(
-            mem,
-            Interrupt::new(
-                IrqLevelEvent::new().unwrap(),
-                None,   // msix_config
-                0xFFFF, // VIRTIO_MSI_NO_VECTOR
-                #[cfg(target_arch = "x86_64")]
-                None,
-            ),
-            BTreeMap::from([(0, q)]),
-        )
+        .activate(mem, interrupt, BTreeMap::from([(0, q)]))
         .unwrap();
 
     queue_evt.signal().unwrap(); // Rings the doorbell
diff --git a/fuzz/fuzz_targets/qcow_fuzzer.rs b/fuzz/fuzz_targets/qcow_fuzzer.rs
index 4dd403ce3..e06af8212 100644
--- a/fuzz/fuzz_targets/qcow_fuzzer.rs
+++ b/fuzz/fuzz_targets/qcow_fuzzer.rs
@@ -27,11 +27,21 @@ fuzz_target!(|bytes| {
     let mut disk_image = Cursor::new(bytes);
     let addr = read_u64(&mut disk_image);
     let value = read_u64(&mut disk_image);
-    let max_nesting_depth = 10;
     let mut disk_file = tempfile::tempfile().unwrap();
     disk_file.write_all(&bytes[16..]).unwrap();
     disk_file.seek(SeekFrom::Start(0)).unwrap();
-    if let Ok(mut qcow) = QcowFile::from(disk_file, max_nesting_depth) {
+    if let Ok(qcow) = QcowFile::from(
+        disk_file,
+        disk::DiskFileParams {
+            path: "/foo".into(),
+            is_read_only: false,
+            is_sparse_file: false,
+            is_overlapped: false,
+            is_direct: false,
+            lock: true,
+            depth: 0,
+        },
+    ) {
         let mut mem = value.to_le_bytes().to_owned();
         let vslice = VolatileSlice::new(&mut mem);
         let _ = qcow.write_all_at_volatile(vslice, addr);
diff --git a/fuzz/fuzz_targets/virtqueue_fuzzer.rs b/fuzz/fuzz_targets/virtqueue_fuzzer.rs
index be7a726a8..fee987216 100644
--- a/fuzz/fuzz_targets/virtqueue_fuzzer.rs
+++ b/fuzz/fuzz_targets/virtqueue_fuzzer.rs
@@ -12,7 +12,9 @@ use std::mem::size_of;
 use base::Event;
 use crosvm_fuzz::fuzz_target;
 use crosvm_fuzz::rand::FuzzRng;
+use devices::virtio::Interrupt;
 use devices::virtio::QueueConfig;
+use devices::IrqLevelEvent;
 use rand::Rng;
 use rand::RngCore;
 use vm_memory::GuestAddress;
@@ -58,6 +60,14 @@ struct virtq_used {
 }
 
 fuzz_target!(|data: &[u8]| {
+    let interrupt = Interrupt::new(
+        IrqLevelEvent::new().unwrap(),
+        None,   // msix_config
+        0xFFFF, // VIRTIO_MSI_NO_VECTOR
+        #[cfg(target_arch = "x86_64")]
+        None,
+    );
+
     let mut q = QueueConfig::new(MAX_QUEUE_SIZE, 0);
     let mut rng = FuzzRng::new(data);
     q.set_size(rng.gen());
@@ -75,7 +85,7 @@ fuzz_target!(|data: &[u8]| {
     q.set_ready(true);
 
     GUEST_MEM.with(|mem| {
-        let mut q = if let Ok(q) = q.activate(mem, Event::new().unwrap()) {
+        let mut q = if let Ok(q) = q.activate(mem, Event::new().unwrap(), interrupt) {
             q
         } else {
             return;
diff --git a/gpu_display/Android.bp b/gpu_display/Android.bp
index e96b71db4..39ba03909 100644
--- a/gpu_display/Android.bp
+++ b/gpu_display/Android.bp
@@ -25,7 +25,7 @@ rust_library {
     crate_name: "gpu_display",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "android_display",
diff --git a/gpu_display/Cargo.toml b/gpu_display/Cargo.toml
index 651e638df..b9231a104 100644
--- a/gpu_display/Cargo.toml
+++ b/gpu_display/Cargo.toml
@@ -16,13 +16,13 @@ android_display = []
 android_display_stub = []
 
 [dependencies]
-anyhow = "*"
-libc = "*"
+anyhow = "1"
+libc = "0.2"
 base = { path = "../base" }
 linux_input_sys = { path = "../linux_input_sys" }
-remain = "*"
-thiserror = "*"
-cfg-if = "*"
+remain = "0.2"
+thiserror = "1"
+cfg-if = "1"
 serde = { version = "1", features = [ "derive" ] }
 vm_control = { path = "../vm_control", features = ["gpu"] }
 zerocopy = { version = "0.7", features = ["derive"] }
@@ -31,19 +31,19 @@ ash = { version = "0.37.0", optional = true }
 rand = { version = "0.8.5", optional = true }
 protos = { path = "../protos", optional = true }
 protobuf = { version = "3.2", optional = true }
-euclid = { version = "*", optional = true }
-smallvec = { version = "*", optional = true }
+euclid = { version = "0.22", optional = true }
+smallvec = { version = "1", optional = true }
 sync = { path = "../common/sync" }
 
 [target.'cfg(windows)'.dependencies]
 cros_tracing = { path = "../cros_tracing" }
 metrics = { path = "../metrics" }
-num-traits = "*"
-winapi = "*"
+num-traits = "0.2"
+winapi = "0.3"
 win_util = { path = "../win_util" }
-smallvec = "*"
+smallvec = "1"
 sync = { path = "../common/sync" }
-euclid = "*"
+euclid = "0.22"
 
 [build-dependencies]
 cc = "1.0.25"
diff --git a/gpu_display/OWNERS b/gpu_display/OWNERS
new file mode 100644
index 000000000..db4e6f866
--- /dev/null
+++ b/gpu_display/OWNERS
@@ -0,0 +1,12 @@
+# ChromeOS
+ryanneph@google.com
+
+# Cuttlefish
+natsu@google.com
+
+# Auto
+gurchetansingh@chromium.org
+
+# Windows
+kaiyili@google.com
+colindr@google.com
diff --git a/gpu_display/src/display_wl.c b/gpu_display/src/display_wl.c
index d3c5f3d9f..73a954cc3 100644
--- a/gpu_display/src/display_wl.c
+++ b/gpu_display/src/display_wl.c
@@ -723,6 +723,8 @@ static void error_callback_stub(const char *message) {
 struct dwl_context *dwl_context_new(dwl_error_callback_type error_callback)
 {
 	struct dwl_context *ctx = calloc(1, sizeof(struct dwl_context));
+	if (!ctx)
+		return NULL;
 	ctx->ifaces.context = ctx;
 	ctx->error_callback = error_callback ? error_callback : error_callback_stub;
 	return ctx;
diff --git a/gpu_display/src/dwl.rs b/gpu_display/src/dwl.rs
index 1f0a2860c..4831248ae 100644
--- a/gpu_display/src/dwl.rs
+++ b/gpu_display/src/dwl.rs
@@ -11,6 +11,7 @@
 /// - @subpage page_iface_zxdg_surface_v6 - desktop user interface surface base interface
 /// - @subpage page_iface_zxdg_toplevel_v6 - toplevel surface
 /// - @subpage page_iface_zxdg_popup_v6 - short-lived, popup surfaces for menus
+///
 /// @section page_copyright_xdg_shell_unstable_v6 Copyright
 /// <pre>
 ///
diff --git a/gpu_display/src/gpu_display_android.rs b/gpu_display/src/gpu_display_android.rs
index 27753ff88..4d418373f 100644
--- a/gpu_display/src/gpu_display_android.rs
+++ b/gpu_display/src/gpu_display_android.rs
@@ -35,7 +35,7 @@ pub(crate) struct AndroidDisplayContext {
 
 // Opaque blob
 #[repr(C)]
-pub(crate) struct ANativeWindow {
+pub(crate) struct AndroidDisplaySurface {
     _data: [u8; 0],
     _marker: core::marker::PhantomData<(*mut u8, core::marker::PhantomPinned)>,
 }
@@ -79,11 +79,14 @@ extern "C" {
         width: u32,
         height: u32,
         for_cursor: bool,
-    ) -> *mut ANativeWindow;
+    ) -> *mut AndroidDisplaySurface;
 
     /// Destroys the Android surface created from `create_android_surface`.
     #[allow(dead_code)]
-    fn destroy_android_surface(ctx: *mut AndroidDisplayContext, surface: *mut ANativeWindow);
+    fn destroy_android_surface(
+        ctx: *mut AndroidDisplayContext,
+        surface: *mut AndroidDisplaySurface,
+    );
 
     /// Obtains one buffer from the given Android Surface. The information about the buffer (buffer
     /// address, size, stride, etc) is reported via the `ANativeWindow_Buffer` struct. It shouldn't
@@ -94,7 +97,7 @@ extern "C" {
     /// returned), then the caller shouldn't try to read `out_buffer` or use the buffer in any way.
     fn get_android_surface_buffer(
         ctx: *mut AndroidDisplayContext,
-        surface: *mut ANativeWindow,
+        surface: *mut AndroidDisplaySurface,
         out_buffer: *mut ANativeWindow_Buffer,
     ) -> bool;
 
@@ -103,7 +106,10 @@ extern "C" {
     /// Posts the buffer obtained from `get_android_surface_buffer` to the Android display system
     /// so that it can be displayed on the screen. Once this is called, the caller shouldn't use
     /// the buffer any more.
-    fn post_android_surface_buffer(ctx: *mut AndroidDisplayContext, surface: *mut ANativeWindow);
+    fn post_android_surface_buffer(
+        ctx: *mut AndroidDisplayContext,
+        surface: *mut AndroidDisplaySurface,
+    );
 }
 
 unsafe extern "C" fn error_callback(message: *const c_char) {
@@ -156,7 +162,7 @@ impl From<ANativeWindow_Buffer> for GpuDisplayFramebuffer<'_> {
 
 struct AndroidSurface {
     context: Rc<AndroidDisplayContextWrapper>,
-    surface: NonNull<ANativeWindow>,
+    surface: NonNull<AndroidDisplaySurface>,
 }
 
 impl GpuDisplaySurface for AndroidSurface {
diff --git a/gpu_display/src/gpu_display_android_stub.rs b/gpu_display/src/gpu_display_android_stub.rs
index ff1889a3c..100eef26d 100644
--- a/gpu_display/src/gpu_display_android_stub.rs
+++ b/gpu_display/src/gpu_display_android_stub.rs
@@ -10,9 +10,9 @@
 
 use std::ffi::c_char;
 
-use crate::gpu_display_android::ANativeWindow;
 use crate::gpu_display_android::ANativeWindow_Buffer;
 use crate::gpu_display_android::AndroidDisplayContext;
+use crate::gpu_display_android::AndroidDisplaySurface;
 use crate::gpu_display_android::ErrorCallback;
 
 #[no_mangle]
@@ -34,14 +34,14 @@ extern "C" fn create_android_surface(
     _width: u32,
     _height: u32,
     _for_cursor: bool,
-) -> *mut ANativeWindow {
+) -> *mut AndroidDisplaySurface {
     unimplemented!();
 }
 
 #[no_mangle]
 extern "C" fn destroy_android_surface(
     _ctx: *mut AndroidDisplayContext,
-    _surface: *mut ANativeWindow,
+    _surface: *mut AndroidDisplaySurface,
 ) {
     unimplemented!();
 }
@@ -54,7 +54,7 @@ extern "C" fn set_android_surface_position(_ctx: *mut AndroidDisplayContext, _x:
 #[no_mangle]
 extern "C" fn get_android_surface_buffer(
     _ctx: *mut AndroidDisplayContext,
-    _surface: *mut ANativeWindow,
+    _surface: *mut AndroidDisplaySurface,
     _out_buffer: *mut ANativeWindow_Buffer,
 ) -> u32 {
     unimplemented!();
@@ -63,7 +63,7 @@ extern "C" fn get_android_surface_buffer(
 #[no_mangle]
 extern "C" fn post_android_surface_buffer(
     _ctx: *mut AndroidDisplayContext,
-    _surface: *mut ANativeWindow,
+    _surface: *mut AndroidDisplaySurface,
 ) {
     unimplemented!();
 }
diff --git a/gpu_display/src/gpu_display_win/window_procedure_thread.rs b/gpu_display/src/gpu_display_win/window_procedure_thread.rs
index 84253e762..0e6485910 100644
--- a/gpu_display/src/gpu_display_win/window_procedure_thread.rs
+++ b/gpu_display/src/gpu_display_win/window_procedure_thread.rs
@@ -253,7 +253,7 @@ impl WindowProcedureThread {
             .try_clone()
             .map_err(|e| anyhow!("Failed to clone close_requested_event: {}", e))?;
 
-        let thread = match ThreadBuilder::new()
+        let thread = ThreadBuilder::new()
             .name("gpu_display_wndproc".into())
             .spawn(move || {
                 match close_requested_event_clone.try_clone() {
@@ -272,10 +272,8 @@ impl WindowProcedureThread {
                 if let Err(e) = close_requested_event_clone.signal() {
                     error!("Failed to signal close requested event: {}", e);
                 }
-            }) {
-            Ok(thread) => thread,
-            Err(e) => bail!("Failed to spawn WndProc thread: {}", e),
-        };
+            })
+            .context("Failed to spawn WndProc thread")?;
 
         match message_router_handle_receiver.recv() {
             Ok(message_router_handle_res) => match message_router_handle_res {
diff --git a/gpu_display/src/gpu_display_wl.rs b/gpu_display/src/gpu_display_wl.rs
index c163ee7ed..628288aca 100644
--- a/gpu_display/src/gpu_display_wl.rs
+++ b/gpu_display/src/gpu_display_wl.rs
@@ -7,6 +7,7 @@
 extern crate base;
 
 #[path = "dwl.rs"]
+#[allow(dead_code)]
 mod dwl;
 
 use std::cell::Cell;
@@ -341,6 +342,7 @@ impl DisplayT for DisplayWl {
                     virtio_input_event::multitouch_tracking_id(tracking_id),
                     virtio_input_event::multitouch_absolute_x(max(0, event.params[0])),
                     virtio_input_event::multitouch_absolute_y(max(0, event.params[1])),
+                    virtio_input_event::touch(true),
                 ];
                 Some(GpuDisplayEvents {
                     events,
@@ -351,6 +353,7 @@ impl DisplayT for DisplayWl {
                 let events = vec![
                     virtio_input_event::multitouch_slot(0),
                     virtio_input_event::multitouch_tracking_id(-1),
+                    virtio_input_event::touch(false),
                 ];
                 Some(GpuDisplayEvents {
                     events,
diff --git a/gpu_display/src/vulkan.rs b/gpu_display/src/vulkan.rs
index 0eb1645d0..8af14e722 100644
--- a/gpu_display/src/vulkan.rs
+++ b/gpu_display/src/vulkan.rs
@@ -314,14 +314,7 @@ impl<T: WindowEventLoop<VulkanState>> VulkanDisplayImpl<T> {
             array_2d_compatible,
             block_texel_view_compatible,
             _ne: _,
-        } = vk::ImageCreateFlags::from_raw(image_create_flags)
-            .try_into()
-            .map_err(|_| {
-                format_err!(
-                    "Failed to convert flags {} to an image create flags.",
-                    image_create_flags
-                )
-            })?;
+        } = vk::ImageCreateFlags::from_raw(image_create_flags).into();
         assert!(
             !(sparse_binding || sparse_residency || sparse_aliased),
             "unsupported image create flags {:#x}",
@@ -359,9 +352,7 @@ impl<T: WindowEventLoop<VulkanState>> VulkanDisplayImpl<T> {
         };
         let image_usage = {
             let usage = metadata.usage;
-            vk::ImageUsageFlags::from_raw(usage)
-                .try_into()
-                .map_err(|_| format_err!("Failed to convert {:#x} to image usage.", usage))?
+            vk::ImageUsageFlags::from_raw(usage).into()
         };
         let image_sharing = {
             let sharing_mode = metadata.sharing_mode;
diff --git a/hypervisor/Android.bp b/hypervisor/Android.bp
index 896f91eb9..004ff142c 100644
--- a/hypervisor/Android.bp
+++ b/hypervisor/Android.bp
@@ -15,7 +15,7 @@ rust_test {
     crate_name: "hypervisor",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -23,9 +23,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -38,19 +35,19 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -60,7 +57,7 @@ rust_test {
     crate_name: "dirty_log",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/dirty_log.rs"],
+    crate_root: "tests/dirty_log.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -68,9 +65,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -83,20 +77,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -106,7 +100,7 @@ rust_test {
     crate_name: "hypervisor_virtualization",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/hypervisor_virtualization.rs"],
+    crate_root: "tests/hypervisor_virtualization.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -114,9 +108,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -129,20 +120,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -152,7 +143,7 @@ rust_test {
     crate_name: "kvm",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/kvm/main.rs"],
+    crate_root: "tests/kvm/main.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -160,9 +151,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -175,20 +163,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -198,7 +186,7 @@ rust_test {
     crate_name: "mmio_and_pio",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/mmio_and_pio.rs"],
+    crate_root: "tests/mmio_and_pio.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -206,9 +194,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -221,20 +206,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -244,7 +229,7 @@ rust_test {
     crate_name: "read_only_memory",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/read_only_memory.rs"],
+    crate_root: "tests/read_only_memory.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -252,9 +237,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -267,20 +249,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -290,7 +272,7 @@ rust_test {
     crate_name: "real_run_addr",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/real_run_addr.rs"],
+    crate_root: "tests/real_run_addr.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -298,9 +280,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -313,20 +292,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -336,7 +315,7 @@ rust_test {
     crate_name: "remove_memory",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/remove_memory.rs"],
+    crate_root: "tests/remove_memory.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -344,9 +323,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -359,20 +335,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_test {
@@ -382,7 +358,7 @@ rust_test {
     crate_name: "tsc_offsets",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/tsc_offsets.rs"],
+    crate_root: "tests/tsc_offsets.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -390,9 +366,6 @@ rust_test {
     },
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -405,20 +378,20 @@ rust_test {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
         "libhypervisor",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
         "libsync_rust",
         "libvm_memory",
+        "libzerocopy",
+    ],
+    proc_macros: [
+        "libenumn",
+        "libhypervisor_test_macro",
     ],
-    proc_macros: ["libenumn"],
 }
 
 rust_library {
@@ -428,12 +401,9 @@ rust_library {
     crate_name: "hypervisor",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
-        "gdb",
-        "gdbstub",
-        "gdbstub_arch",
         "geniezone",
         "gunyah",
     ],
@@ -446,12 +416,8 @@ rust_library {
         "libdata_model",
         "libdowncast_rs",
         "libfnv",
-        "libgdbstub",
-        "libgdbstub_arch",
-        "libkvm",
         "libkvm_sys",
         "liblibc",
-        "libmemoffset",
         "libonce_cell",
         "libserde",
         "libserde_json",
diff --git a/hypervisor/Cargo.toml b/hypervisor/Cargo.toml
index 3ea794b38..73ce7bdac 100644
--- a/hypervisor/Cargo.toml
+++ b/hypervisor/Cargo.toml
@@ -7,13 +7,12 @@ edition = "2021"
 [features]
 haxm = []
 whpx = []
-gdb = ["gdbstub", "gdbstub_arch"]
 geniezone = []
 gunyah = []
 noncoherent-dma = []
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 bit_field = { path = "../bit_field" }
 bitflags = "2.2.1"
 cros_fdt = { path = "../cros_fdt" }
@@ -21,10 +20,7 @@ data_model = { path = "../common/data_model" }
 downcast-rs = "1.2.0"
 enumn = "0.1.0"
 fnv = "1"
-gdbstub = { version = "0.7.0", optional = true }
-gdbstub_arch = { version = "0.3.0", optional = true }
-libc = "*"
-memoffset = "0.6"
+libc = "0.2"
 once_cell = "1.7"
 serde = { version = "1", features = [ "derive" ] }
 serde_json = { version = "1" }
@@ -33,19 +29,23 @@ base = { path = "../base" }
 vm_memory = { path = "../vm_memory" }
 
 [target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
-kvm = { path = "../kvm" }
 kvm_sys = { path = "../kvm_sys" }
 
+[target.'cfg(target_arch = "x86_64")'.dev-dependencies]
+hypervisor_test_macro = { path = "hypervisor_test_macro" }
+zerocopy = { version = "0.7", features = ["derive"] }
+
 [target.'cfg(windows)'.dependencies]
-thiserror = "*"
-winapi = "*"
+thiserror = "1"
+winapi = "0.3"
 win_util = { path = "../win_util" }
 
 [target.'cfg(windows)'.dependencies.windows]
 version = "0.39.0"
 features = [
     "Win32_Foundation",
+    "Win32_System_Memory",
 ]
 
 [target.'cfg(windows)'.dev-dependencies]
-tempfile = "*"
+tempfile = "3"
diff --git a/hypervisor/hypervisor_test_macro/Android.bp b/hypervisor/hypervisor_test_macro/Android.bp
new file mode 100644
index 000000000..2a3f37a8e
--- /dev/null
+++ b/hypervisor/hypervisor_test_macro/Android.bp
@@ -0,0 +1,25 @@
+// This file is generated by cargo_embargo.
+// Do not modify this file after the first "rust_*" or "genrule" module
+// because the changes will be overridden on upgrade.
+// Content before the first "rust_*" or "genrule" module is preserved.
+
+package {
+    default_applicable_licenses: ["external_crosvm_license"],
+    default_team: "trendy_team_foundation_security_rust_pkvm_",
+}
+
+rust_proc_macro {
+    name: "libhypervisor_test_macro",
+    defaults: ["crosvm_inner_defaults"],
+    crate_name: "hypervisor_test_macro",
+    cargo_env_compat: true,
+    cargo_pkg_version: "0.1.0",
+    crate_root: "src/lib.rs",
+    edition: "2021",
+    rustlibs: [
+        "libproc_macro2",
+        "libquote",
+        "librand",
+        "libsyn",
+    ],
+}
diff --git a/hypervisor/hypervisor_test_macro/Cargo.toml b/hypervisor/hypervisor_test_macro/Cargo.toml
new file mode 100644
index 000000000..1d6a49e3c
--- /dev/null
+++ b/hypervisor/hypervisor_test_macro/Cargo.toml
@@ -0,0 +1,14 @@
+[package]
+name = "hypervisor_test_macro"
+version = "0.1.0"
+authors = ["The ChromiumOS Authors"]
+edition = "2021"
+
+[lib]
+proc-macro = true
+
+[dependencies]
+proc-macro2 = { version = "^1", features = ["span-locations"] }
+quote = "^1"
+syn = "2"
+rand = "0.8"
diff --git a/hypervisor/hypervisor_test_macro/src/lib.rs b/hypervisor/hypervisor_test_macro/src/lib.rs
new file mode 100644
index 000000000..5923627d9
--- /dev/null
+++ b/hypervisor/hypervisor_test_macro/src/lib.rs
@@ -0,0 +1,239 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#![warn(missing_docs)]
+#![recursion_limit = "128"]
+
+//! Macros for hypervisor tests
+
+use std::collections::hash_map::DefaultHasher;
+use std::hash::Hash;
+use std::hash::Hasher;
+use std::sync::atomic::AtomicU64;
+
+use proc_macro::TokenStream;
+use proc_macro2::Span;
+use proc_macro2::TokenStream as TokenStream2;
+use quote::quote;
+use rand::Rng;
+use syn::parse::Parse;
+use syn::parse_macro_input;
+use syn::Error;
+use syn::Ident;
+use syn::LitStr;
+use syn::Token;
+use syn::Visibility;
+
+/// Embed the compiled assembly as an array.
+///
+/// This macro will generate a module with the given `$name` and provides a `data` function in the
+/// module to allow accessing the compiled machine code as an array.
+///
+/// Note that this macro uses [`std::arch::global_asm`], so we can only use this macro in a global
+/// scope, outside a function.
+///
+/// # Example
+///
+/// Given the following x86 assembly:
+/// ```Text
+/// 0:  01 d8                   add    eax,ebx
+/// 2:  f4                      hlt
+/// ```
+///
+/// ```rust
+/// # use hypervisor_test_macro::global_asm_data;
+/// global_asm_data!(
+///     my_code,
+///     ".code64",
+///     "add eax, ebx",
+///     "hlt",
+/// );
+/// # fn main() {
+/// assert_eq!([0x01, 0xd8, 0xf4], my_code::data());
+/// # }
+/// ```
+///
+/// It is supported to pass arbitrary supported [`std::arch::global_asm`] operands and options.
+/// ```rust
+/// # use hypervisor_test_macro::global_asm_data;
+/// fn f() {}
+/// global_asm_data!(
+///     my_code1,
+///     ".global {0}",
+///     ".code64",
+///     "add eax, ebx",
+///     "hlt",
+///     sym f,
+/// );
+/// global_asm_data!(
+///     my_code2,
+///     ".code64",
+///     "add eax, ebx",
+///     "hlt",
+///     options(raw),
+/// );
+/// # fn main() {
+/// assert_eq!([0x01, 0xd8, 0xf4], my_code1::data());
+/// assert_eq!([0x01, 0xd8, 0xf4], my_code2::data());
+/// # }
+/// ```
+///
+/// It is also supported to specify the visibility of the generated module. Note that the below
+/// example won't work if the `pub` in the macro is missing.
+/// ```rust
+/// # use hypervisor_test_macro::global_asm_data;
+/// mod my_mod {
+///     // This use is needed to import the global_asm_data macro to this module.
+///     use super::*;
+///
+///     global_asm_data!(
+///         // pub is needed so that my_mod::my_code is visible to the outer scope.
+///         pub my_code,
+///         ".code64",
+///         "add eax, ebx",
+///         "hlt",
+///     );
+/// }
+/// # fn main() {
+/// assert_eq!([0x01, 0xd8, 0xf4], my_mod::my_code::data());
+/// # }
+/// ```
+#[proc_macro]
+pub fn global_asm_data(item: TokenStream) -> TokenStream {
+    let args = parse_macro_input!(item as GlobalAsmDataArgs);
+    global_asm_data_impl(args).unwrap_or_else(|e| e.to_compile_error().into())
+}
+
+struct GlobalAsmDataArgs {
+    visibility: Visibility,
+    mod_name: Ident,
+    global_asm_strings: Vec<LitStr>,
+    global_asm_rest_args: TokenStream2,
+}
+
+impl Parse for GlobalAsmDataArgs {
+    fn parse(input: syn::parse::ParseStream) -> syn::Result<Self> {
+        // The first argument is visibilty + identifier, e.g. my_code or pub my_code. The identifier
+        // will be used as the name of the gnerated module.
+        let visibility: Visibility = input.parse()?;
+        let mod_name: Ident = input.parse()?;
+        // There must be following arguments, so we consume the first argument separator here.
+        input.parse::<Token![,]>()?;
+
+        // Retrieve the input assemblies, which are a list of comma separated string literals. We
+        // need to obtain the list of assemblies explicitly, so that we can insert the begin tag and
+        // the end tag to the global_asm! call when we generate the result code.
+        let mut global_asm_strings = vec![];
+        loop {
+            let lookahead = input.lookahead1();
+            if !lookahead.peek(LitStr) {
+                // If the upcoming tokens are not string literal, we hit the end of the input
+                // assemblies.
+                break;
+            }
+            global_asm_strings.push(input.parse::<LitStr>()?);
+
+            if input.is_empty() {
+                // In case the current string literal is the last argument.
+                break;
+            }
+            input.parse::<Token![,]>()?;
+            if input.is_empty() {
+                // In case the current string literal is the last argument with a trailing comma.
+                break;
+            }
+        }
+
+        // We store the rest of the arguments, and we will forward them as is to global_asm!.
+        let global_asm_rest_args: TokenStream2 = input.parse()?;
+        Ok(Self {
+            visibility,
+            mod_name,
+            global_asm_strings,
+            global_asm_rest_args,
+        })
+    }
+}
+
+static COUNTER: AtomicU64 = AtomicU64::new(0);
+
+fn global_asm_data_impl(
+    GlobalAsmDataArgs {
+        visibility,
+        mod_name,
+        global_asm_strings,
+        global_asm_rest_args,
+    }: GlobalAsmDataArgs,
+) -> Result<TokenStream, Error> {
+    let span = Span::call_site();
+
+    // Generate the unique tags based on the macro input, code location and a random number to avoid
+    // symbol collision.
+    let tag_base_name = {
+        let content_id = {
+            let mut hasher = DefaultHasher::new();
+            span.source_text().hash(&mut hasher);
+            hasher.finish()
+        };
+        let location_id = format!(
+            "{}_{}_{}_{}",
+            span.start().line,
+            span.start().column,
+            span.end().line,
+            span.end().column
+        );
+        let rand_id = rand::thread_rng().gen::<u64>();
+        let static_counter_id = COUNTER.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
+        let prefix = "crosvm_hypervisor_test_macro_global_asm_data";
+        format!(
+            "{}_{}_{}_{}_{}_{}",
+            prefix, mod_name, content_id, location_id, static_counter_id, rand_id
+        )
+    };
+    let start_tag = format!("{}_start", tag_base_name);
+    let end_tag = format!("{}_end", tag_base_name);
+
+    let global_directive = LitStr::new(&format!(".global {}, {}", start_tag, end_tag), span);
+    let start_tag_asm = LitStr::new(&format!("{}:", start_tag), span);
+    let end_tag_asm = LitStr::new(&format!("{}:", end_tag), span);
+    let start_tag_ident = Ident::new(&start_tag, span);
+    let end_tag_ident = Ident::new(&end_tag, span);
+
+    Ok(quote! {
+        #visibility mod #mod_name {
+            use super::*;
+
+            extern {
+                static #start_tag_ident: u8;
+                static #end_tag_ident: u8;
+            }
+
+            std::arch::global_asm!(
+                #global_directive,
+                #start_tag_asm,
+                #(#global_asm_strings),*,
+                #end_tag_asm,
+                #global_asm_rest_args
+            );
+            pub fn data() -> &'static [u8] {
+                // SAFETY:
+                // * The extern statics are u8, and any arbitrary bit patterns are valid for u8.
+                // * The data starting from start to end is valid u8.
+                // * Without unsafe block, one can't mutate the value between start and end. In
+                //   addition, it is likely that the data is written to a readonly block, and can't
+                //   be mutated at all.
+                // * The address shouldn't be too large, and won't wrap around.
+                unsafe {
+                    let ptr = std::ptr::addr_of!(#start_tag_ident);
+                    let len = std::ptr::addr_of!(#end_tag_ident).offset_from(ptr);
+                    std::slice::from_raw_parts(
+                        ptr,
+                        len.try_into().expect("length must be positive")
+                    )
+                }
+            }
+        }
+    }
+    .into())
+}
diff --git a/hypervisor/src/aarch64.rs b/hypervisor/src/aarch64.rs
index c838196b3..bae426743 100644
--- a/hypervisor/src/aarch64.rs
+++ b/hypervisor/src/aarch64.rs
@@ -4,16 +4,12 @@
 
 use std::collections::BTreeMap;
 use std::convert::TryFrom;
+use std::fmt::Debug;
 
-use anyhow::anyhow;
 use base::Error;
 use base::Result;
 use cros_fdt::Fdt;
 use downcast_rs::impl_downcast;
-#[cfg(feature = "gdb")]
-use gdbstub::arch::Arch;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::aarch64::AArch64 as GdbArch;
 use libc::EINVAL;
 use serde::Deserialize;
 use serde::Serialize;
@@ -51,15 +47,117 @@ impl TryFrom<u32> for PsciVersion {
     }
 }
 
+// Aarch64 does not provide a concrete number as to how many registers exist.
+// The list of registers available exceeds 600 registers
+pub const AARCH64_MAX_REG_COUNT: usize = 1024;
+
 pub const PSCI_0_2: PsciVersion = PsciVersion { major: 0, minor: 2 };
 pub const PSCI_1_0: PsciVersion = PsciVersion { major: 1, minor: 0 };
 
+/// AArch64 system register as used in MSR/MRS instructions.
+#[derive(Copy, Clone, Eq, PartialEq, Ord, PartialOrd, Deserialize, Serialize)]
+#[serde(transparent)]
+pub struct AArch64SysRegId(u16);
+
+impl AArch64SysRegId {
+    /// Construct a system register ID from Op0, Op1, CRn, CRm, Op2.
+    ///
+    /// The meanings of the arguments are described in the ARMv8 Architecture Reference Manual
+    /// "System instruction class encoding overview" section.
+    pub fn new(op0: u8, op1: u8, crn: u8, crm: u8, op2: u8) -> Result<Self> {
+        if op0 > 0b11 || op1 > 0b111 || crn > 0b1111 || crm > 0b1111 || op2 > 0b111 {
+            return Err(Error::new(EINVAL));
+        }
+
+        Ok(Self::new_unchecked(op0, op1, crn, crm, op2))
+    }
+
+    /// Construct a system register ID from Op0, Op1, CRn, CRm, Op2.
+    ///
+    /// Out-of-range values will be silently truncated.
+    pub const fn new_unchecked(op0: u8, op1: u8, crn: u8, crm: u8, op2: u8) -> Self {
+        let op0 = (op0 as u16 & 0b11) << 14;
+        let op1 = (op1 as u16 & 0b111) << 11;
+        let crn = (crn as u16 & 0b1111) << 7;
+        let crm = (crm as u16 & 0b1111) << 3;
+        let op2 = op2 as u16 & 0b111;
+        Self(op0 | op1 | crn | crm | op2)
+    }
+
+    pub fn from_encoded(v: u16) -> Self {
+        Self(v)
+    }
+
+    #[inline]
+    pub const fn op0(&self) -> u8 {
+        ((self.0 >> 14) & 0b11) as u8
+    }
+
+    #[inline]
+    pub const fn op1(&self) -> u8 {
+        ((self.0 >> 11) & 0b111) as u8
+    }
+
+    #[inline]
+    pub const fn crn(&self) -> u8 {
+        ((self.0 >> 7) & 0b1111) as u8
+    }
+
+    #[inline]
+    pub const fn crm(&self) -> u8 {
+        ((self.0 >> 3) & 0b1111) as u8
+    }
+
+    #[inline]
+    pub const fn op2(&self) -> u8 {
+        (self.0 & 0b111) as u8
+    }
+
+    /// Returns the system register as encoded in bits 5-20 of MRS and MSR instructions.
+    pub const fn encoded(&self) -> u16 {
+        self.0
+    }
+}
+
+impl Debug for AArch64SysRegId {
+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+        f.debug_struct("AArch64SysRegId")
+            .field("Op0", &self.op0())
+            .field("Op1", &self.op1())
+            .field("CRn", &self.crn())
+            .field("CRm", &self.crm())
+            .field("Op2", &self.op2())
+            .finish()
+    }
+}
+
+#[rustfmt::skip]
+#[allow(non_upper_case_globals)]
+impl AArch64SysRegId {
+    //                                                         Op0    Op1     CRn     CRm    Op2
+    pub const MPIDR_EL1: Self           = Self::new_unchecked(0b11, 0b000, 0b0000, 0b0000, 0b101);
+    pub const CCSIDR_EL1: Self          = Self::new_unchecked(0b11, 0b001, 0b0000, 0b0000, 0b000);
+    pub const CSSELR_EL1: Self          = Self::new_unchecked(0b11, 0b010, 0b0000, 0b0000, 0b000);
+    pub const FPCR: Self                = Self::new_unchecked(0b11, 0b011, 0b0100, 0b0100, 0b000);
+    pub const FPSR: Self                = Self::new_unchecked(0b11, 0b011, 0b0100, 0b0100, 0b001);
+    pub const SPSR_EL1: Self            = Self::new_unchecked(0b11, 0b000, 0b0100, 0b0000, 0b000);
+    pub const SPSR_irq: Self            = Self::new_unchecked(0b11, 0b100, 0b0100, 0b0011, 0b000);
+    pub const SPSR_abt: Self            = Self::new_unchecked(0b11, 0b100, 0b0100, 0b0011, 0b001);
+    pub const SPSR_und: Self            = Self::new_unchecked(0b11, 0b100, 0b0100, 0b0011, 0b010);
+    pub const SPSR_fiq: Self            = Self::new_unchecked(0b11, 0b100, 0b0100, 0b0011, 0b011);
+    pub const ELR_EL1: Self             = Self::new_unchecked(0b11, 0b000, 0b0100, 0b0000, 0b001);
+    pub const SP_EL1: Self              = Self::new_unchecked(0b11, 0b100, 0b0100, 0b0001, 0b000);
+    pub const CNTVCT_EL0: Self          = Self::new_unchecked(0b11, 0b011, 0b1110, 0b0000, 0b010);
+    pub const CNTV_CVAL_EL0: Self       = Self::new_unchecked(0b11, 0b011, 0b1110, 0b0011, 0b010);
+}
+
 #[derive(Copy, Clone, Eq, PartialEq, Ord, PartialOrd)]
 pub enum VcpuRegAArch64 {
     X(u8),
     Sp,
     Pc,
     Pstate,
+    System(AArch64SysRegId),
 }
 
 /// A wrapper for using a VM on aarch64 and getting/setting its state.
@@ -88,6 +186,12 @@ pub trait VmAArch64: Vm {
         fdt_address: GuestAddress,
         fdt_size: usize,
     ) -> Result<()>;
+
+    /// Set an offset that describes a number of counter cycles that are subtracted from both
+    /// virtual and physical counter views.
+    fn set_counter_offset(&self, _offset: u64) -> Result<()> {
+        Err(Error::new(libc::ENOSYS))
+    }
 }
 
 /// A wrapper around creating and using a VCPU on aarch64.
@@ -120,6 +224,15 @@ pub trait VcpuAArch64: Vcpu {
     /// Gets the value of a Neon vector register (V0-V31) on this VCPU.
     fn get_vector_reg(&self, reg_num: u8) -> Result<u128>;
 
+    /// Gets the set of system registers accessible by the hypervisor
+    fn get_system_regs(&self) -> Result<BTreeMap<AArch64SysRegId, u64>>;
+
+    /// Gets the hypervisor specific data for snapshot
+    fn hypervisor_specific_snapshot(&self) -> anyhow::Result<serde_json::Value>;
+
+    /// Restores the hypervisor specific data
+    fn hypervisor_specific_restore(&self, _data: serde_json::Value) -> anyhow::Result<()>;
+
     /// Gets the value of MPIDR_EL1 on this VCPU.
     fn get_mpidr(&self) -> Result<u64> {
         const RES1: u64 = 1 << 31;
@@ -134,47 +247,78 @@ pub trait VcpuAArch64: Vcpu {
     /// Gets the current PSCI version.
     fn get_psci_version(&self) -> Result<PsciVersion>;
 
-    #[cfg(feature = "gdb")]
     /// Sets up debug registers and configure vcpu for handling guest debug events.
     fn set_guest_debug(&self, addrs: &[GuestAddress], enable_singlestep: bool) -> Result<()>;
 
-    #[cfg(feature = "gdb")]
-    /// Sets the VCPU general registers used by GDB 'G' packets.
-    fn set_gdb_registers(&self, regs: &<GdbArch as Arch>::Registers) -> Result<()>;
-
-    #[cfg(feature = "gdb")]
-    /// Gets the VCPU general registers used by GDB 'g' packets.
-    fn get_gdb_registers(&self, regs: &mut <GdbArch as Arch>::Registers) -> Result<()>;
-
-    #[cfg(feature = "gdb")]
     /// Gets the max number of hardware breakpoints.
     fn get_max_hw_bps(&self) -> Result<usize>;
 
-    #[cfg(feature = "gdb")]
-    /// Sets the value of a single register on this VCPU.
-    fn set_gdb_register(&self, reg: <GdbArch as Arch>::RegId, data: &[u8]) -> Result<()>;
+    /// Gets the cache architecture information for all cache levels.
+    /// The keys of the map are the lower 4 lower significant bits of CSSELR_EL1, which represents
+    /// the cache level. cache level is actually located in bits [3:1], but the value saves also
+    /// if the cache is an instruction or data.
+    /// The values of the map are CCSIDR_EL1, which is the configuration of the cache.
+    fn get_cache_info(&self) -> Result<BTreeMap<u8, u64>>;
 
-    #[cfg(feature = "gdb")]
-    /// Gets the value of a single register on this VCPU.
-    fn get_gdb_register(&self, reg: <GdbArch as Arch>::RegId, data: &mut [u8]) -> Result<usize>;
+    /// Sets the cache architecture information for all cache levels.
+    fn set_cache_info(&self, cache_info: BTreeMap<u8, u64>) -> Result<()>;
 
-    /// Snapshot VCPU
     fn snapshot(&self) -> anyhow::Result<VcpuSnapshot> {
-        Err(anyhow!("not yet implemented"))
+        let mut snap = VcpuSnapshot {
+            vcpu_id: self.id(),
+            sp: self.get_one_reg(VcpuRegAArch64::Sp)?,
+            pc: self.get_one_reg(VcpuRegAArch64::Pc)?,
+            pstate: self.get_one_reg(VcpuRegAArch64::Pstate)?,
+            hypervisor_data: self.hypervisor_specific_snapshot()?,
+            sys: self.get_system_regs()?,
+            cache_arch_info: self.get_cache_info()?,
+            ..Default::default()
+        };
+
+        for (n, xn) in snap.x.iter_mut().enumerate() {
+            *xn = self.get_one_reg(VcpuRegAArch64::X(n as u8))?;
+        }
+
+        for (n, vn) in snap.v.iter_mut().enumerate() {
+            *vn = self.get_vector_reg(n as u8)?;
+        }
+
+        Ok(snap)
     }
 
     /// Restore VCPU
-    fn restore(&self, _snapshot: &VcpuSnapshot) -> anyhow::Result<()> {
-        Err(anyhow!("not yet implemented"))
+    fn restore(&self, snapshot: &VcpuSnapshot) -> anyhow::Result<()> {
+        self.set_one_reg(VcpuRegAArch64::Sp, snapshot.sp)?;
+        self.set_one_reg(VcpuRegAArch64::Pc, snapshot.pc)?;
+        self.set_one_reg(VcpuRegAArch64::Pstate, snapshot.pstate)?;
+
+        for (n, xn) in snapshot.x.iter().enumerate() {
+            self.set_one_reg(VcpuRegAArch64::X(n as u8), *xn)?;
+        }
+        for (n, vn) in snapshot.v.iter().enumerate() {
+            self.set_vector_reg(n as u8, *vn)?;
+        }
+        for (id, val) in &snapshot.sys {
+            self.set_one_reg(VcpuRegAArch64::System(*id), *val)?;
+        }
+        self.set_cache_info(snapshot.cache_arch_info.clone())?;
+        self.hypervisor_specific_restore(snapshot.hypervisor_data.clone())?;
+        Ok(())
     }
 }
 
 /// Aarch64 specific vCPU snapshot.
-///
-/// Not implemented yet.
-#[derive(Clone, Debug, Serialize, Deserialize)]
+#[derive(Clone, Debug, Default, Serialize, Deserialize)]
 pub struct VcpuSnapshot {
     pub vcpu_id: usize,
+    pub sp: u64,
+    pub pc: u64,
+    pub pstate: u64,
+    pub x: [u64; 31],
+    pub v: [u128; 32],
+    pub sys: BTreeMap<AArch64SysRegId, u64>,
+    pub cache_arch_info: BTreeMap<u8, u64>,
+    pub hypervisor_data: serde_json::Value,
 }
 
 impl_downcast!(VcpuAArch64);
@@ -213,3 +357,89 @@ pub enum VcpuFeature {
     /// Starts the VCPU in a power-off state.
     PowerOff,
 }
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn sysreg_new() {
+        let sysreg = AArch64SysRegId::new(1, 2, 3, 4, 5).unwrap();
+        assert_eq!(sysreg.op0(), 1);
+        assert_eq!(sysreg.op1(), 2);
+        assert_eq!(sysreg.crn(), 3);
+        assert_eq!(sysreg.crm(), 4);
+        assert_eq!(sysreg.op2(), 5);
+        assert_eq!(sysreg.encoded(), 0x51A5);
+    }
+
+    #[test]
+    fn sysreg_new_max() {
+        let sysreg = AArch64SysRegId::new(0b11, 0b111, 0b1111, 0b1111, 0b111).unwrap();
+        assert_eq!(sysreg.op0(), 3);
+        assert_eq!(sysreg.op1(), 7);
+        assert_eq!(sysreg.crn(), 15);
+        assert_eq!(sysreg.crm(), 15);
+        assert_eq!(sysreg.op2(), 7);
+        assert_eq!(sysreg.encoded(), 0xFFFF);
+    }
+
+    #[test]
+    fn sysreg_new_out_of_range() {
+        AArch64SysRegId::new(4, 0, 0, 0, 0).expect_err("invalid Op0");
+        AArch64SysRegId::new(0, 8, 0, 0, 0).expect_err("invalid Op1");
+        AArch64SysRegId::new(0, 0, 16, 0, 0).expect_err("invalid CRn");
+        AArch64SysRegId::new(0, 0, 0, 16, 0).expect_err("invalid CRm");
+        AArch64SysRegId::new(0, 0, 0, 0, 8).expect_err("invalid Op2");
+    }
+
+    #[test]
+    fn sysreg_encoding_mpidr_el1() {
+        assert_eq!(AArch64SysRegId::MPIDR_EL1.op0(), 3);
+        assert_eq!(AArch64SysRegId::MPIDR_EL1.op1(), 0);
+        assert_eq!(AArch64SysRegId::MPIDR_EL1.crn(), 0);
+        assert_eq!(AArch64SysRegId::MPIDR_EL1.crm(), 0);
+        assert_eq!(AArch64SysRegId::MPIDR_EL1.op2(), 5);
+        assert_eq!(AArch64SysRegId::MPIDR_EL1.encoded(), 0xC005);
+        assert_eq!(
+            AArch64SysRegId::MPIDR_EL1,
+            AArch64SysRegId::new(3, 0, 0, 0, 5).unwrap()
+        );
+    }
+
+    #[test]
+    fn sysreg_encoding_cntvct_el0() {
+        assert_eq!(AArch64SysRegId::CNTVCT_EL0.op0(), 3);
+        assert_eq!(AArch64SysRegId::CNTVCT_EL0.op1(), 3);
+        assert_eq!(AArch64SysRegId::CNTVCT_EL0.crn(), 14);
+        assert_eq!(AArch64SysRegId::CNTVCT_EL0.crm(), 0);
+        assert_eq!(AArch64SysRegId::CNTVCT_EL0.op2(), 2);
+        assert_eq!(AArch64SysRegId::CNTVCT_EL0.encoded(), 0xDF02);
+        assert_eq!(
+            AArch64SysRegId::CNTVCT_EL0,
+            AArch64SysRegId::new(3, 3, 14, 0, 2).unwrap()
+        );
+    }
+
+    #[test]
+    fn sysreg_encoding_cntv_cval_el0() {
+        assert_eq!(AArch64SysRegId::CNTV_CVAL_EL0.op0(), 3);
+        assert_eq!(AArch64SysRegId::CNTV_CVAL_EL0.op1(), 3);
+        assert_eq!(AArch64SysRegId::CNTV_CVAL_EL0.crn(), 14);
+        assert_eq!(AArch64SysRegId::CNTV_CVAL_EL0.crm(), 3);
+        assert_eq!(AArch64SysRegId::CNTV_CVAL_EL0.op2(), 2);
+        assert_eq!(AArch64SysRegId::CNTV_CVAL_EL0.encoded(), 0xDF1A);
+        assert_eq!(
+            AArch64SysRegId::CNTV_CVAL_EL0,
+            AArch64SysRegId::new(3, 3, 14, 3, 2).unwrap()
+        );
+    }
+
+    #[test]
+    fn sysreg_debug() {
+        assert_eq!(
+            format!("{:?}", AArch64SysRegId::MPIDR_EL1),
+            "AArch64SysRegId { Op0: 3, Op1: 0, CRn: 0, CRm: 0, Op2: 5 }"
+        );
+    }
+}
diff --git a/hypervisor/src/geniezone/mod.rs b/hypervisor/src/geniezone/mod.rs
index 3440b6393..6b27947ba 100644
--- a/hypervisor/src/geniezone/mod.rs
+++ b/hypervisor/src/geniezone/mod.rs
@@ -9,6 +9,7 @@ use std::collections::BTreeMap;
 use std::collections::BinaryHeap;
 use std::convert::TryFrom;
 use std::ffi::CString;
+use std::mem::offset_of;
 use std::os::raw::c_ulong;
 use std::os::unix::prelude::OsStrExt;
 use std::path::Path;
@@ -34,12 +35,6 @@ use base::RawDescriptor;
 use base::Result;
 use base::SafeDescriptor;
 use cros_fdt::Fdt;
-#[cfg(feature = "gdb")]
-use gdbstub::arch::Arch;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::aarch64::reg::id::AArch64RegId;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::aarch64::AArch64 as GdbArch;
 pub use geniezone_sys::*;
 use libc::open;
 use libc::EFAULT;
@@ -57,12 +52,12 @@ use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 use vm_memory::MemoryRegionPurpose;
 
+use crate::AArch64SysRegId;
 use crate::BalloonEvent;
 use crate::ClockState;
 use crate::Config;
 use crate::Datamatch;
 use crate::DeviceKind;
-use crate::HypervHypercall;
 use crate::Hypervisor;
 use crate::HypervisorCap;
 use crate::IoEventAddress;
@@ -88,13 +83,8 @@ impl Geniezone {
     pub fn get_guest_phys_addr_bits(&self) -> u8 {
         // SAFETY:
         // Safe because we know self is a real geniezone fd
-        match unsafe {
-            ioctl_with_val(
-                self,
-                GZVM_CHECK_EXTENSION(),
-                GZVM_CAP_ARM_VM_IPA_SIZE.into(),
-            )
-        } {
+        match unsafe { ioctl_with_val(self, GZVM_CHECK_EXTENSION, GZVM_CAP_ARM_VM_IPA_SIZE.into()) }
+        {
             // Default physical address size is 40 bits if the extension is not supported.
             ret if ret <= 0 => 40,
             ipa => ipa as u8,
@@ -204,7 +194,7 @@ impl VmAArch64 for GeniezoneVm {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will modify exactly the size
         // of the struct.
-        let ret = unsafe { ioctl_with_ref(self, GZVM_SET_DTB_CONFIG(), &dtb_config) };
+        let ret = unsafe { ioctl_with_ref(self, GZVM_SET_DTB_CONFIG, &dtb_config) };
         if ret == 0 {
             Ok(())
         } else {
@@ -232,7 +222,7 @@ impl GeniezoneVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, GZVM_SET_ONE_REG(), &onereg) };
+        let ret = unsafe { ioctl_with_ref(self, GZVM_SET_ONE_REG, &onereg) };
         if ret == 0 {
             Ok(())
         } else {
@@ -261,7 +251,7 @@ impl GeniezoneVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, GZVM_GET_ONE_REG(), &onereg) };
+        let ret = unsafe { ioctl_with_ref(self, GZVM_GET_ONE_REG, &onereg) };
         if ret == 0 {
             Ok(())
         } else {
@@ -281,22 +271,12 @@ pub enum GeniezoneVcpuRegister {
     Pc,
     /// Processor State
     Pstate,
-    /// Stack Pointer (EL1)
-    SpEl1,
-    /// Exception Link Register (EL1)
-    ElrEl1,
-    /// Saved Program Status Register (EL1, abt, und, irq, fiq)
-    Spsr(u8),
     /// FP & SIMD Registers V0-V31
     V(u8),
-    /// Floating-point Status Register
-    Fpsr,
-    /// Floating-point Control Register
-    Fpcr,
     /// Geniezone Firmware Pseudo-Registers
     Firmware(u16),
-    /// Generic System Registers by (Op0, Op1, CRn, CRm, Op2)
-    System(u16),
+    /// System Registers
+    System(AArch64SysRegId),
     /// CCSIDR_EL1 Demultiplexed by CSSELR_EL1
     Ccsidr(u8),
 }
@@ -318,15 +298,17 @@ impl From<GeniezoneVcpuRegister> for u64 {
             gzvm_regs_reg(GZVM_REG_SIZE_U64, offset)
         }
 
+        fn spsr_reg(spsr_reg: u32) -> u64 {
+            let n = std::mem::size_of::<u64>() * (spsr_reg as usize);
+            gzvm_reg(offset_of!(gzvm_regs, spsr) + n)
+        }
+
         fn user_pt_reg(offset: usize) -> u64 {
-            gzvm_regs_reg(
-                GZVM_REG_SIZE_U64,
-                memoffset::offset_of!(gzvm_regs, regs) + offset,
-            )
+            gzvm_regs_reg(GZVM_REG_SIZE_U64, offset_of!(gzvm_regs, regs) + offset)
         }
 
         fn user_fpsimd_state_reg(size: u64, offset: usize) -> u64 {
-            gzvm_regs_reg(size, memoffset::offset_of!(gzvm_regs, fp_regs) + offset)
+            gzvm_regs_reg(size, offset_of!(gzvm_regs, fp_regs) + offset)
         }
 
         const fn reg_u64(kind: u64, fields: u64) -> u64 {
@@ -346,61 +328,47 @@ impl From<GeniezoneVcpuRegister> for u64 {
             GeniezoneVcpuRegister::X(n @ 0..=30) => {
                 let n = std::mem::size_of::<u64>() * (n as usize);
 
-                user_pt_reg(memoffset::offset_of!(user_pt_regs, regs) + n)
+                user_pt_reg(offset_of!(user_pt_regs, regs) + n)
             }
             GeniezoneVcpuRegister::X(n) => {
                 unreachable!("invalid GeniezoneVcpuRegister Xn index: {n}")
             }
-            GeniezoneVcpuRegister::Sp => user_pt_reg(memoffset::offset_of!(user_pt_regs, sp)),
-            GeniezoneVcpuRegister::Pc => user_pt_reg(memoffset::offset_of!(user_pt_regs, pc)),
-            GeniezoneVcpuRegister::Pstate => {
-                user_pt_reg(memoffset::offset_of!(user_pt_regs, pstate))
-            }
-            GeniezoneVcpuRegister::SpEl1 => gzvm_reg(memoffset::offset_of!(gzvm_regs, sp_el1)),
-            GeniezoneVcpuRegister::ElrEl1 => gzvm_reg(memoffset::offset_of!(gzvm_regs, elr_el1)),
-            GeniezoneVcpuRegister::Spsr(n @ 0..=4) => {
-                let n = std::mem::size_of::<u64>() * (n as usize);
-                gzvm_reg(memoffset::offset_of!(gzvm_regs, spsr) + n)
-            }
-            GeniezoneVcpuRegister::Spsr(n) => {
-                unreachable!("invalid GeniezoneVcpuRegister Spsr index: {n}")
-            }
+            GeniezoneVcpuRegister::Sp => user_pt_reg(offset_of!(user_pt_regs, sp)),
+            GeniezoneVcpuRegister::Pc => user_pt_reg(offset_of!(user_pt_regs, pc)),
+            GeniezoneVcpuRegister::Pstate => user_pt_reg(offset_of!(user_pt_regs, pstate)),
             GeniezoneVcpuRegister::V(n @ 0..=31) => {
                 let n = std::mem::size_of::<u128>() * (n as usize);
-                user_fpsimd_state_reg(
-                    GZVM_REG_SIZE_U128,
-                    memoffset::offset_of!(user_fpsimd_state, vregs) + n,
-                )
+                user_fpsimd_state_reg(GZVM_REG_SIZE_U128, offset_of!(user_fpsimd_state, vregs) + n)
             }
             GeniezoneVcpuRegister::V(n) => {
                 unreachable!("invalid GeniezoneVcpuRegister Vn index: {n}")
             }
-            GeniezoneVcpuRegister::Fpsr => user_fpsimd_state_reg(
-                GZVM_REG_SIZE_U32,
-                memoffset::offset_of!(user_fpsimd_state, fpsr),
-            ),
-            GeniezoneVcpuRegister::Fpcr => user_fpsimd_state_reg(
-                GZVM_REG_SIZE_U32,
-                memoffset::offset_of!(user_fpsimd_state, fpcr),
-            ),
+            GeniezoneVcpuRegister::System(AArch64SysRegId::FPSR) => {
+                user_fpsimd_state_reg(GZVM_REG_SIZE_U32, offset_of!(user_fpsimd_state, fpsr))
+            }
+            GeniezoneVcpuRegister::System(AArch64SysRegId::FPCR) => {
+                user_fpsimd_state_reg(GZVM_REG_SIZE_U32, offset_of!(user_fpsimd_state, fpcr))
+            }
+            GeniezoneVcpuRegister::System(AArch64SysRegId::SPSR_EL1) => spsr_reg(0),
+            GeniezoneVcpuRegister::System(AArch64SysRegId::SPSR_abt) => spsr_reg(1),
+            GeniezoneVcpuRegister::System(AArch64SysRegId::SPSR_und) => spsr_reg(2),
+            GeniezoneVcpuRegister::System(AArch64SysRegId::SPSR_irq) => spsr_reg(3),
+            GeniezoneVcpuRegister::System(AArch64SysRegId::SPSR_fiq) => spsr_reg(4),
+            GeniezoneVcpuRegister::System(AArch64SysRegId::SP_EL1) => {
+                gzvm_reg(offset_of!(gzvm_regs, sp_el1))
+            }
+            GeniezoneVcpuRegister::System(AArch64SysRegId::ELR_EL1) => {
+                gzvm_reg(offset_of!(gzvm_regs, elr_el1))
+            }
+            GeniezoneVcpuRegister::System(sysreg) => {
+                reg_u64(GZVM_REG_ARM64_SYSREG.into(), sysreg.encoded().into())
+            }
             GeniezoneVcpuRegister::Firmware(n) => reg_u64(GZVM_REG_ARM, n.into()),
-            GeniezoneVcpuRegister::System(n) => reg_u64(GZVM_REG_ARM64_SYSREG.into(), n.into()),
             GeniezoneVcpuRegister::Ccsidr(n) => demux_reg(GZVM_REG_SIZE_U32, 0, n.into()),
         }
     }
 }
 
-#[cfg(feature = "gdb")]
-impl TryFrom<AArch64RegId> for GeniezoneVcpuRegister {
-    type Error = Error;
-
-    fn try_from(_reg: <GdbArch as Arch>::RegId) -> std::result::Result<Self, Self::Error> {
-        // TODO: Geniezone not support gdb currently
-        error!("Geniezone: not support gdb");
-        Err(Error::new(EINVAL))
-    }
-}
-
 impl From<VcpuRegAArch64> for GeniezoneVcpuRegister {
     fn from(reg: VcpuRegAArch64) -> Self {
         match reg {
@@ -409,6 +377,7 @@ impl From<VcpuRegAArch64> for GeniezoneVcpuRegister {
             VcpuRegAArch64::Sp => Self::Sp,
             VcpuRegAArch64::Pc => Self::Pc,
             VcpuRegAArch64::Pstate => Self::Pstate,
+            VcpuRegAArch64::System(sysreg) => Self::System(sysreg),
         }
     }
 }
@@ -457,45 +426,44 @@ impl VcpuAArch64 for GeniezoneVcpu {
         Ok(PSCI_0_2)
     }
 
-    #[cfg(feature = "gdb")]
     fn get_max_hw_bps(&self) -> Result<usize> {
         // TODO: Geniezone not support gdb currently
         error!("Geniezone: not support get_max_hw_bps");
         Err(Error::new(EINVAL))
     }
 
-    #[cfg(feature = "gdb")]
-    fn set_guest_debug(&self, _addrs: &[GuestAddress], _enable_singlestep: bool) -> Result<()> {
-        // TODO: Geniezone not support gdb currently
-        error!("Geniezone: not support set_gdb_registers");
+    fn get_system_regs(&self) -> Result<BTreeMap<AArch64SysRegId, u64>> {
+        error!("Geniezone: not support get_system_regs");
         Err(Error::new(EINVAL))
     }
 
-    #[cfg(feature = "gdb")]
-    fn set_gdb_registers(&self, _regs: &<GdbArch as Arch>::Registers) -> Result<()> {
-        // TODO: Geniezone not support gdb currently
-        error!("Geniezone: not support set_gdb_registers");
+    fn get_cache_info(&self) -> Result<BTreeMap<u8, u64>> {
+        error!("Geniezone: not support get_cache_info");
         Err(Error::new(EINVAL))
     }
 
-    #[cfg(feature = "gdb")]
-    fn get_gdb_registers(&self, _regs: &mut <GdbArch as Arch>::Registers) -> Result<()> {
-        // TODO: Geniezone not support gdb currently
-        error!("Geniezone: not support get_gdb_registers");
+    fn set_cache_info(&self, _cache_info: BTreeMap<u8, u64>) -> Result<()> {
+        error!("Geniezone: not support set_cache_info");
         Err(Error::new(EINVAL))
     }
 
-    #[cfg(feature = "gdb")]
-    fn set_gdb_register(&self, _reg: <GdbArch as Arch>::RegId, _data: &[u8]) -> Result<()> {
+    fn hypervisor_specific_snapshot(&self) -> anyhow::Result<serde_json::Value> {
         // TODO: Geniezone not support gdb currently
-        error!("Geniezone: not support set_gdb_register");
-        Err(Error::new(EINVAL))
+        Err(anyhow::anyhow!(
+            "Geniezone: not support hypervisor_specific_snapshot"
+        ))
     }
 
-    #[cfg(feature = "gdb")]
-    fn get_gdb_register(&self, _reg: <GdbArch as Arch>::RegId, _data: &mut [u8]) -> Result<usize> {
+    fn hypervisor_specific_restore(&self, _data: serde_json::Value) -> anyhow::Result<()> {
         // TODO: Geniezone not support gdb currently
-        error!("Geniezone: not support get_gdb_register");
+        Err(anyhow::anyhow!(
+            "Geniezone: not support hypervisor_specific_restore"
+        ))
+    }
+
+    fn set_guest_debug(&self, _addrs: &[GuestAddress], _enable_singlestep: bool) -> Result<()> {
+        // TODO: Geniezone not support gdb currently
+        error!("Geniezone: not support set_guest_debug");
         Err(Error::new(EINVAL))
     }
 }
@@ -523,7 +491,7 @@ unsafe fn set_user_memory_region(
         userspace_addr: userspace_addr as u64,
     };
 
-    let ret = ioctl_with_ref(descriptor, GZVM_SET_USER_MEMORY_REGION(), &region);
+    let ret = ioctl_with_ref(descriptor, GZVM_SET_USER_MEMORY_REGION, &region);
     if ret == 0 {
         Ok(())
     } else {
@@ -622,7 +590,7 @@ impl GeniezoneVm {
         // SAFETY:
         // Safe because we know gzvm is a real gzvm fd as this module is the only one that can make
         // gzvm objects.
-        let ret = unsafe { ioctl(geniezone, GZVM_CREATE_VM()) };
+        let ret = unsafe { ioctl(geniezone, GZVM_CREATE_VM) };
         if ret < 0 {
             return errno_result();
         }
@@ -669,7 +637,7 @@ impl GeniezoneVm {
         let fd =
             // SAFETY:
             // Safe because we know that our file is a VM fd and we verify the return result.
-            unsafe { ioctl_with_val(self, GZVM_CREATE_VCPU(), c_ulong::try_from(id).unwrap()) };
+            unsafe { ioctl_with_val(self, GZVM_CREATE_VCPU, c_ulong::try_from(id).unwrap()) };
 
         if fd < 0 {
             return errno_result();
@@ -699,7 +667,7 @@ impl GeniezoneVm {
     pub fn create_irq_chip(&self) -> Result<()> {
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let ret = unsafe { ioctl(self, GZVM_CREATE_IRQCHIP()) };
+        let ret = unsafe { ioctl(self, GZVM_CREATE_IRQCHIP) };
         if ret == 0 {
             Ok(())
         } else {
@@ -716,7 +684,7 @@ impl GeniezoneVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, GZVM_IRQ_LINE(), &irq_level) };
+        let ret = unsafe { ioctl_with_ref(self, GZVM_IRQ_LINE, &irq_level) };
         if ret == 0 {
             Ok(())
         } else {
@@ -746,7 +714,7 @@ impl GeniezoneVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, GZVM_IRQFD(), &irqfd) };
+        let ret = unsafe { ioctl_with_ref(self, GZVM_IRQFD, &irqfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -769,7 +737,7 @@ impl GeniezoneVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, GZVM_IRQFD(), &irqfd) };
+        let ret = unsafe { ioctl_with_ref(self, GZVM_IRQFD, &irqfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -827,7 +795,7 @@ impl GeniezoneVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, GZVM_IOEVENTFD(), &ioeventfd) };
+        let ret = unsafe { ioctl_with_ref(self, GZVM_IOEVENTFD, &ioeventfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -842,7 +810,7 @@ impl GeniezoneVm {
         // Safe because we know that our file is a GZVM fd, and if the cap is invalid GZVM assumes
         // it's an unavailable extension and returns 0.
         unsafe {
-            ioctl_with_ref(self, GZVM_CHECK_EXTENSION(), &cap);
+            ioctl_with_ref(self, GZVM_CHECK_EXTENSION, &cap);
         }
         cap == 1
     }
@@ -866,7 +834,7 @@ impl GeniezoneVm {
         };
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct, and because we assume the caller has allocated the args appropriately.
-        let ret = ioctl_with_ref(self, GZVM_ENABLE_CAP(), &gzvm_cap);
+        let ret = ioctl_with_ref(self, GZVM_ENABLE_CAP, &gzvm_cap);
         if ret == 0 {
             Ok(gzvm_cap)
         } else {
@@ -878,7 +846,7 @@ impl GeniezoneVm {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will modify exactly the size
         // of the struct and the return value is checked.
-        let ret = unsafe { base::ioctl_with_ref(self, GZVM_CREATE_DEVICE(), &dev) };
+        let ret = unsafe { base::ioctl_with_ref(self, GZVM_CREATE_DEVICE, &dev) };
         if ret == 0 {
             Ok(())
         } else {
@@ -998,6 +966,24 @@ impl Vm for GeniezoneVm {
         })
     }
 
+    fn madvise_pageout_memory_region(
+        &mut self,
+        _slot: MemSlot,
+        _offset: usize,
+        _size: usize,
+    ) -> Result<()> {
+        Err(Error::new(ENOTSUP))
+    }
+
+    fn madvise_remove_memory_region(
+        &mut self,
+        _slot: MemSlot,
+        _offset: usize,
+        _size: usize,
+    ) -> Result<()> {
+        Err(Error::new(ENOTSUP))
+    }
+
     fn remove_memory_region(&mut self, slot: MemSlot) -> Result<Box<dyn MappedRegion>> {
         let mut regions = self.mem_regions.lock();
         if !regions.contains_key(&slot) {
@@ -1172,7 +1158,7 @@ impl Vcpu for GeniezoneVcpu {
     fn run(&mut self) -> Result<VcpuExit> {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd and we verify the return result.
-        let ret = unsafe { ioctl_with_val(self, GZVM_RUN(), self.run_mmap.as_ptr() as u64) };
+        let ret = unsafe { ioctl_with_val(self, GZVM_RUN, self.run_mmap.as_ptr() as u64) };
         if ret != 0 {
             return errno_result();
         }
@@ -1217,13 +1203,16 @@ impl Vcpu for GeniezoneVcpu {
                 }
             }
             GZVM_EXIT_INTERNAL_ERROR => Ok(VcpuExit::InternalError),
-            GZVM_EXIT_SHUTDOWN => Ok(VcpuExit::Shutdown),
+            GZVM_EXIT_SHUTDOWN => Ok(VcpuExit::Shutdown(Ok(()))),
             GZVM_EXIT_UNKNOWN => panic!("unknown gzvm exit reason\n"),
             r => panic!("unknown gzvm exit reason: {}", r),
         }
     }
 
-    fn handle_mmio(&self, handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
+    fn handle_mmio(
+        &self,
+        handle_fn: &mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>,
+    ) -> Result<()> {
         // SAFETY:
         // Safe because we know we mapped enough memory to hold the gzvm_vcpu_run struct because the
         // kernel told us how large it was. The pointer is page aligned so casting to a different
@@ -1245,13 +1234,13 @@ impl Vcpu for GeniezoneVcpu {
                 address,
                 size,
                 operation: IoOperation::Write { data: mmio.data },
-            });
+            })?;
             Ok(())
         } else if let Some(data) = handle_fn(IoParams {
             address,
             size,
             operation: IoOperation::Read,
-        }) {
+        })? {
             mmio.data[..size].copy_from_slice(&data[..size]);
             Ok(())
         } else {
@@ -1262,19 +1251,6 @@ impl Vcpu for GeniezoneVcpu {
     fn handle_io(&self, _handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
         Err(Error::new(EINVAL))
     }
-
-    fn handle_hyperv_hypercall(
-        &self,
-        _handle_fn: &mut dyn FnMut(HypervHypercall) -> u64,
-    ) -> Result<()> {
-        Err(Error::new(EINVAL))
-    }
-
-    fn handle_rdmsr(&self, _data: u64) -> Result<()> {
-        Err(Error::new(EINVAL))
-    }
-
-    fn handle_wrmsr(&self) {}
 }
 
 impl AsRawDescriptor for GeniezoneVcpu {
diff --git a/hypervisor/src/gunyah/aarch64.rs b/hypervisor/src/gunyah/aarch64.rs
index 2bf7557c7..c50654faf 100644
--- a/hypervisor/src/gunyah/aarch64.rs
+++ b/hypervisor/src/gunyah/aarch64.rs
@@ -16,6 +16,7 @@ use vm_memory::MemoryRegionPurpose;
 
 use super::GunyahVcpu;
 use super::GunyahVm;
+use crate::AArch64SysRegId;
 use crate::Hypervisor;
 use crate::PsciVersion;
 use crate::VcpuAArch64;
@@ -229,47 +230,31 @@ impl VcpuAArch64 for GunyahVcpu {
         Ok(PSCI_0_2)
     }
 
-    #[cfg(feature = "gdb")]
     fn set_guest_debug(&self, _addrs: &[GuestAddress], _enable_singlestep: bool) -> Result<()> {
         Err(Error::new(ENOTSUP))
     }
 
-    #[cfg(feature = "gdb")]
-    fn set_gdb_registers(
-        &self,
-        _regs: &<gdbstub_arch::aarch64::AArch64 as gdbstub::arch::Arch>::Registers,
-    ) -> Result<()> {
+    fn get_max_hw_bps(&self) -> Result<usize> {
         Err(Error::new(ENOTSUP))
     }
 
-    #[cfg(feature = "gdb")]
-    fn get_gdb_registers(
-        &self,
-        _regs: &mut <gdbstub_arch::aarch64::AArch64 as gdbstub::arch::Arch>::Registers,
-    ) -> Result<()> {
+    fn get_system_regs(&self) -> Result<BTreeMap<AArch64SysRegId, u64>> {
         Err(Error::new(ENOTSUP))
     }
 
-    #[cfg(feature = "gdb")]
-    fn get_max_hw_bps(&self) -> Result<usize> {
+    fn get_cache_info(&self) -> Result<BTreeMap<u8, u64>> {
         Err(Error::new(ENOTSUP))
     }
 
-    #[cfg(feature = "gdb")]
-    fn set_gdb_register(
-        &self,
-        _reg: <gdbstub_arch::aarch64::AArch64 as gdbstub::arch::Arch>::RegId,
-        _data: &[u8],
-    ) -> Result<()> {
+    fn set_cache_info(&self, _cache_info: BTreeMap<u8, u64>) -> Result<()> {
         Err(Error::new(ENOTSUP))
     }
 
-    #[cfg(feature = "gdb")]
-    fn get_gdb_register(
-        &self,
-        _reg: <gdbstub_arch::aarch64::AArch64 as gdbstub::arch::Arch>::RegId,
-        _data: &mut [u8],
-    ) -> Result<usize> {
-        Err(Error::new(ENOTSUP))
+    fn hypervisor_specific_snapshot(&self) -> anyhow::Result<serde_json::Value> {
+        unimplemented!()
+    }
+
+    fn hypervisor_specific_restore(&self, _data: serde_json::Value) -> anyhow::Result<()> {
+        unimplemented!()
     }
 }
diff --git a/hypervisor/src/gunyah/mod.rs b/hypervisor/src/gunyah/mod.rs
index 71503c8b9..8987a43cf 100644
--- a/hypervisor/src/gunyah/mod.rs
+++ b/hypervisor/src/gunyah/mod.rs
@@ -12,6 +12,7 @@ use std::collections::BTreeMap;
 use std::collections::BinaryHeap;
 use std::collections::HashSet;
 use std::ffi::CString;
+use std::fs::File;
 use std::mem::size_of;
 use std::os::raw::c_ulong;
 use std::os::unix::prelude::OsStrExt;
@@ -24,7 +25,6 @@ use base::info;
 use base::ioctl;
 use base::ioctl_with_ref;
 use base::ioctl_with_val;
-use base::linux::MemoryMappingBuilderUnix;
 use base::pagesize;
 use base::warn;
 use base::Error;
@@ -40,6 +40,7 @@ use libc::EINVAL;
 use libc::EIO;
 use libc::ENOENT;
 use libc::ENOSPC;
+use libc::ENOTSUP;
 use libc::EOVERFLOW;
 use libc::O_CLOEXEC;
 use libc::O_RDWR;
@@ -126,7 +127,7 @@ unsafe fn android_lend_user_memory_region(
         userspace_addr: userspace_addr as u64,
     };
 
-    let ret = ioctl_with_ref(vm, GH_VM_ANDROID_LEND_USER_MEM(), &region);
+    let ret = ioctl_with_ref(vm, GH_VM_ANDROID_LEND_USER_MEM, &region);
     if ret == 0 {
         Ok(())
     } else {
@@ -162,7 +163,7 @@ unsafe fn set_user_memory_region(
         userspace_addr: userspace_addr as u64,
     };
 
-    let ret = ioctl_with_ref(vm, GH_VM_SET_USER_MEM_REGION(), &region);
+    let ret = ioctl_with_ref(vm, GH_VM_SET_USER_MEM_REGION, &region);
     if ret == 0 {
         Ok(())
     } else {
@@ -198,7 +199,7 @@ impl GunyahVm {
         // SAFETY:
         // Safe because we know gunyah is a real gunyah fd as this module is the only one that can
         // make Gunyah objects.
-        let ret = unsafe { ioctl_with_val(gh, GH_CREATE_VM(), 0 as c_ulong) };
+        let ret = unsafe { ioctl_with_val(gh, GH_CREATE_VM, 0 as c_ulong) };
         if ret < 0 {
             return errno_result();
         }
@@ -272,7 +273,7 @@ impl GunyahVm {
 
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let fd = unsafe { ioctl_with_ref(self, GH_VM_ADD_FUNCTION(), &function_desc) };
+        let fd = unsafe { ioctl_with_ref(self, GH_VM_ADD_FUNCTION, &function_desc) };
         if fd < 0 {
             return errno_result();
         }
@@ -280,18 +281,18 @@ impl GunyahVm {
         // SAFETY:
         // Wrap the vcpu now in case the following ? returns early. This is safe because we verified
         // the value of the fd and we own the fd.
-        let vcpu = unsafe { SafeDescriptor::from_raw_descriptor(fd) };
+        let vcpu = unsafe { File::from_raw_descriptor(fd) };
 
         // SAFETY:
         // Safe because we know this is a Gunyah VCPU
-        let res = unsafe { ioctl(&vcpu, GH_VCPU_MMAP_SIZE()) };
+        let res = unsafe { ioctl(&vcpu, GH_VCPU_MMAP_SIZE) };
         if res < 0 {
             return errno_result();
         }
         let run_mmap_size = res as usize;
 
         let run_mmap = MemoryMappingBuilder::new(run_mmap_size)
-            .from_descriptor(&vcpu)
+            .from_file(&vcpu)
             .build()
             .map_err(|_| Error::new(ENOSPC))?;
 
@@ -320,7 +321,7 @@ impl GunyahVm {
         };
 
         // SAFETY: safe because the return value is checked.
-        let ret = unsafe { ioctl_with_ref(self, GH_VM_ADD_FUNCTION(), &function_desc) };
+        let ret = unsafe { ioctl_with_ref(self, GH_VM_ADD_FUNCTION, &function_desc) };
         if ret == 0 {
             self.routes
                 .lock()
@@ -345,7 +346,7 @@ impl GunyahVm {
         };
 
         // SAFETY: safe because memory is not modified and the return value is checked.
-        let ret = unsafe { ioctl_with_ref(self, GH_VM_REMOVE_FUNCTION(), &function_desc) };
+        let ret = unsafe { ioctl_with_ref(self, GH_VM_REMOVE_FUNCTION, &function_desc) };
         if ret == 0 {
             Ok(())
         } else {
@@ -376,7 +377,7 @@ impl GunyahVm {
 
         // SAFETY:
         // Safe because we know this is a Gunyah VM
-        let ret = unsafe { ioctl_with_ref(self, GH_VM_SET_DTB_CONFIG(), &dtb_config) };
+        let ret = unsafe { ioctl_with_ref(self, GH_VM_SET_DTB_CONFIG, &dtb_config) };
         if ret == 0 {
             Ok(())
         } else {
@@ -392,7 +393,7 @@ impl GunyahVm {
 
         // SAFETY:
         // Safe because we know this is a Gunyah VM
-        let ret = unsafe { ioctl_with_ref(self, GH_VM_ANDROID_SET_FW_CONFIG(), &fw_config) };
+        let ret = unsafe { ioctl_with_ref(self, GH_VM_ANDROID_SET_FW_CONFIG, &fw_config) };
         if ret == 0 {
             Ok(())
         } else {
@@ -402,7 +403,7 @@ impl GunyahVm {
 
     fn start(&self) -> Result<()> {
         // SAFETY: safe because memory is not modified and the return value is checked.
-        let ret = unsafe { ioctl(self, GH_VM_START()) };
+        let ret = unsafe { ioctl(self, GH_VM_START) };
         if ret == 0 {
             Ok(())
         } else {
@@ -508,6 +509,24 @@ impl Vm for GunyahVm {
         })
     }
 
+    fn madvise_pageout_memory_region(
+        &mut self,
+        _slot: MemSlot,
+        _offset: usize,
+        _size: usize,
+    ) -> Result<()> {
+        Err(Error::new(ENOTSUP))
+    }
+
+    fn madvise_remove_memory_region(
+        &mut self,
+        _slot: MemSlot,
+        _offset: usize,
+        _size: usize,
+    ) -> Result<()> {
+        Err(Error::new(ENOTSUP))
+    }
+
     fn remove_memory_region(&mut self, _slot: MemSlot) -> Result<Box<dyn MappedRegion>> {
         unimplemented!()
     }
@@ -573,7 +592,7 @@ impl Vm for GunyahVm {
         };
 
         // SAFETY: safe because memory is not modified and the return value is checked.
-        let ret = unsafe { ioctl_with_ref(self, GH_VM_ADD_FUNCTION(), &function_desc) };
+        let ret = unsafe { ioctl_with_ref(self, GH_VM_ADD_FUNCTION, &function_desc) };
         if ret == 0 {
             Ok(())
         } else {
@@ -605,7 +624,7 @@ impl Vm for GunyahVm {
         };
 
         // SAFETY: safe because memory is not modified and the return value is checked.
-        let ret = unsafe { ioctl_with_ref(self, GH_VM_REMOVE_FUNCTION(), &function_desc) };
+        let ret = unsafe { ioctl_with_ref(self, GH_VM_REMOVE_FUNCTION, &function_desc) };
         if ret == 0 {
             Ok(())
         } else {
@@ -671,7 +690,7 @@ const GH_RM_EXIT_TYPE_VM_FORCE_STOPPED: u16 = 7;
 
 pub struct GunyahVcpu {
     vm: SafeDescriptor,
-    vcpu: SafeDescriptor,
+    vcpu: File,
     id: usize,
     run_mmap: Arc<MemoryMapping>,
 }
@@ -719,7 +738,7 @@ impl Vcpu for GunyahVcpu {
     fn run(&mut self) -> Result<VcpuExit> {
         // SAFETY:
         // Safe because we know our file is a VCPU fd and we verify the return result.
-        let ret = unsafe { ioctl(self, GH_VCPU_RUN()) };
+        let ret = unsafe { ioctl(self, GH_VCPU_RUN) };
         if ret != 0 {
             return errno_result();
         }
@@ -791,7 +810,10 @@ impl Vcpu for GunyahVcpu {
         }
     }
 
-    fn handle_mmio(&self, handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
+    fn handle_mmio(
+        &self,
+        handle_fn: &mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>,
+    ) -> Result<()> {
         // SAFETY:
         // Safe because we know we mapped enough memory to hold the gh_vcpu_run struct because the
         // kernel told us how large it was. The pointer is page aligned so casting to a different
@@ -810,13 +832,13 @@ impl Vcpu for GunyahVcpu {
                 address,
                 size,
                 operation: IoOperation::Write { data: mmio.data },
-            });
+            })?;
             Ok(())
         } else if let Some(data) = handle_fn(IoParams {
             address,
             size,
             operation: IoOperation::Read,
-        }) {
+        })? {
             mmio.data[..size].copy_from_slice(&data[..size]);
             Ok(())
         } else {
@@ -828,18 +850,6 @@ impl Vcpu for GunyahVcpu {
         unreachable!()
     }
 
-    fn handle_hyperv_hypercall(&self, _func: &mut dyn FnMut(HypervHypercall) -> u64) -> Result<()> {
-        unreachable!()
-    }
-
-    fn handle_rdmsr(&self, _data: u64) -> Result<()> {
-        unreachable!()
-    }
-
-    fn handle_wrmsr(&self) {
-        unreachable!()
-    }
-
     fn on_suspend(&self) -> Result<()> {
         Ok(())
     }
diff --git a/hypervisor/src/haxm/haxm_sys/bindings.rs b/hypervisor/src/haxm/haxm_sys/bindings.rs
index e42ac7c5d..e6c31d802 100644
--- a/hypervisor/src/haxm/haxm_sys/bindings.rs
+++ b/hypervisor/src/haxm/haxm_sys/bindings.rs
@@ -1,4 +1,4 @@
-/* automatically generated by rust-bindgen 0.69.2
+/* automatically generated by rust-bindgen 0.69.4
 
 See instructions from: https://rust-lang.github.io/rust-bindgen/print.html
   Download LLVM from: https://releases.llvm.org/download.html
@@ -17,10 +17,9 @@ See instructions from: https://rust-lang.github.io/rust-bindgen/print.html
   structs, there's a bindgen bug for this:
   https://github.com/rust-lang/rust-bindgen/issues/1538
 
-  I removed the align from:
-    - interruptibility_state_t__bindgen_ty_1
+  I removed the align attr. from:
     - segment_desc_t__bindgen_ty_1__bindgen_ty_1
-*/
+ */
 #![allow(clippy::undocumented_unsafe_blocks)]
 
 #[repr(C)]
@@ -178,6 +177,7 @@ pub const HAX_CAP_IMPLICIT_RAMBLOCK: u32 = 256;
 pub const HAX_CAP_CPUID: u32 = 512;
 pub const HAX_CAP_VM_LOG: u32 = 1024;
 pub const HAX_RAM_INFO_ROM: u32 = 1;
+pub const HAX_RAM_INFO_UNPIN: u32 = 32;
 pub const HAX_RAM_INFO_STANDALONE: u32 = 64;
 pub const HAX_RAM_INFO_INVALID: u32 = 128;
 pub const HAX_RAM_PERM_NONE: u32 = 0;
@@ -188,6 +188,7 @@ pub const HAX_DEBUG_STEP: u32 = 2;
 pub const HAX_DEBUG_USE_SW_BP: u32 = 4;
 pub const HAX_DEBUG_USE_HW_BP: u32 = 8;
 pub const HAX_MAX_CPUID_ENTRIES: u32 = 64;
+pub const HAX_DEVICE_APIC: u32 = 1;
 pub type va_list = *mut ::std::os::raw::c_char;
 extern "C" {
     pub fn __va_start(arg1: *mut *mut ::std::os::raw::c_char, ...);
@@ -251,6 +252,14 @@ fn bindgen_test_layout_interruptibility_state_t__bindgen_ty_1() {
             stringify!(interruptibility_state_t__bindgen_ty_1)
         )
     );
+    assert_eq!(
+        ::std::mem::align_of::<interruptibility_state_t__bindgen_ty_1>(),
+        4usize,
+        concat!(
+            "Alignment of ",
+            stringify!(interruptibility_state_t__bindgen_ty_1)
+        )
+    );
 }
 impl interruptibility_state_t__bindgen_ty_1 {
     #[inline]
@@ -389,7 +398,7 @@ impl Default for interruptibility_state_t {
 #[derive(Copy, Clone)]
 pub struct segment_desc_t {
     pub selector: u16,
-    pub _dummy: u16,
+    pub dummy: u16,
     pub limit: u32,
     pub base: u64,
     pub __bindgen_anon_1: segment_desc_t__bindgen_ty_1,
@@ -417,6 +426,14 @@ fn bindgen_test_layout_segment_desc_t__bindgen_ty_1__bindgen_ty_1() {
             stringify!(segment_desc_t__bindgen_ty_1__bindgen_ty_1)
         )
     );
+    assert_eq!(
+        ::std::mem::align_of::<segment_desc_t__bindgen_ty_1__bindgen_ty_1>(),
+        1usize,
+        concat!(
+            "Alignment of ",
+            stringify!(segment_desc_t__bindgen_ty_1__bindgen_ty_1)
+        )
+    );
 }
 impl segment_desc_t__bindgen_ty_1__bindgen_ty_1 {
     #[inline]
@@ -630,13 +647,13 @@ fn bindgen_test_layout_segment_desc_t() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dummy) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dummy) as usize - ptr as usize },
         2usize,
         concat!(
             "Offset of field: ",
             stringify!(segment_desc_t),
             "::",
-            stringify!(_dummy)
+            stringify!(dummy)
         )
     );
     assert_eq!(
@@ -685,39 +702,39 @@ pub struct vcpu_state_t {
     pub __bindgen_anon_1: vcpu_state_t__bindgen_ty_1,
     pub __bindgen_anon_2: vcpu_state_t__bindgen_ty_2,
     pub __bindgen_anon_3: vcpu_state_t__bindgen_ty_3,
-    pub _cs: segment_desc_t,
-    pub _ss: segment_desc_t,
-    pub _ds: segment_desc_t,
-    pub _es: segment_desc_t,
-    pub _fs: segment_desc_t,
-    pub _gs: segment_desc_t,
-    pub _ldt: segment_desc_t,
-    pub _tr: segment_desc_t,
-    pub _gdt: segment_desc_t,
-    pub _idt: segment_desc_t,
-    pub _cr0: u64,
-    pub _cr2: u64,
-    pub _cr3: u64,
-    pub _cr4: u64,
-    pub _dr0: u64,
-    pub _dr1: u64,
-    pub _dr2: u64,
-    pub _dr3: u64,
-    pub _dr6: u64,
-    pub _dr7: u64,
-    pub _pde: u64,
-    pub _efer: u32,
-    pub _sysenter_cs: u32,
-    pub _sysenter_eip: u64,
-    pub _sysenter_esp: u64,
-    pub _activity_state: u32,
+    pub cs: segment_desc_t,
+    pub ss: segment_desc_t,
+    pub ds: segment_desc_t,
+    pub es: segment_desc_t,
+    pub fs: segment_desc_t,
+    pub gs: segment_desc_t,
+    pub ldt: segment_desc_t,
+    pub tr: segment_desc_t,
+    pub gdt: segment_desc_t,
+    pub idt: segment_desc_t,
+    pub cr0: u64,
+    pub cr2: u64,
+    pub cr3: u64,
+    pub cr4: u64,
+    pub dr0: u64,
+    pub dr1: u64,
+    pub dr2: u64,
+    pub dr3: u64,
+    pub dr6: u64,
+    pub dr7: u64,
+    pub pde: u64,
+    pub efer: u32,
+    pub sysenter_cs: u32,
+    pub sysenter_eip: u64,
+    pub sysenter_esp: u64,
+    pub activity_state: u32,
     pub pad: u32,
-    pub _interruptibility_state: interruptibility_state_t,
+    pub interruptibility_state: interruptibility_state_t,
 }
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1 {
-    pub _regs: [u64; 16usize],
+    pub regs: [u64; 16usize],
     pub __bindgen_anon_1: vcpu_state_t__bindgen_ty_1__bindgen_ty_1,
 }
 #[repr(C)]
@@ -731,28 +748,28 @@ pub struct vcpu_state_t__bindgen_ty_1__bindgen_ty_1 {
     pub __bindgen_anon_6: vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6,
     pub __bindgen_anon_7: vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7,
     pub __bindgen_anon_8: vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_8,
-    pub _r8: u64,
-    pub _r9: u64,
-    pub _r10: u64,
-    pub _r11: u64,
-    pub _r12: u64,
-    pub _r13: u64,
-    pub _r14: u64,
-    pub _r15: u64,
+    pub r8: u64,
+    pub r9: u64,
+    pub r10: u64,
+    pub r11: u64,
+    pub r12: u64,
+    pub r13: u64,
+    pub r14: u64,
+    pub r15: u64,
 }
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
     pub __bindgen_anon_1: vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
-    pub _ax: u16,
-    pub _eax: u32,
-    pub _rax: u64,
+    pub ax: u16,
+    pub eax: u32,
+    pub rax: u64,
 }
 #[repr(C)]
 #[derive(Debug, Default, Copy, Clone)]
 pub struct vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
-    pub _al: u8,
-    pub _ah: u8,
+    pub al: u8,
+    pub ah: u8,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1() {
@@ -779,23 +796,23 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__b
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._al) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).al) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_al)
+            stringify!(al)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ah) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ah) as usize - ptr as usize },
         1usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_ah)
+            stringify!(ah)
         )
     );
 }
@@ -821,33 +838,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ax) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ax) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_ax)
+            stringify!(ax)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._eax) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).eax) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_eax)
+            stringify!(eax)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rax) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rax) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_rax)
+            stringify!(rax)
         )
     );
 }
@@ -864,15 +881,15 @@ impl Default for vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2 {
     pub __bindgen_anon_1: vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
-    pub _cx: u16,
-    pub _ecx: u32,
-    pub _rcx: u64,
+    pub cx: u16,
+    pub ecx: u32,
+    pub rcx: u64,
 }
 #[repr(C)]
 #[derive(Debug, Default, Copy, Clone)]
 pub struct vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
-    pub _cl: u8,
-    pub _ch: u8,
+    pub cl: u8,
+    pub ch: u8,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1() {
@@ -899,23 +916,23 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__b
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cl) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cl) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1),
             "::",
-            stringify!(_cl)
+            stringify!(cl)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ch) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ch) as usize - ptr as usize },
         1usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1),
             "::",
-            stringify!(_ch)
+            stringify!(ch)
         )
     );
 }
@@ -941,33 +958,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2),
             "::",
-            stringify!(_cx)
+            stringify!(cx)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ecx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ecx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2),
             "::",
-            stringify!(_ecx)
+            stringify!(ecx)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rcx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rcx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2),
             "::",
-            stringify!(_rcx)
+            stringify!(rcx)
         )
     );
 }
@@ -984,15 +1001,15 @@ impl Default for vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2 {
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3 {
     pub __bindgen_anon_1: vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3__bindgen_ty_1,
-    pub _dx: u16,
-    pub _edx: u32,
-    pub _rdx: u64,
+    pub dx: u16,
+    pub edx: u32,
+    pub rdx: u64,
 }
 #[repr(C)]
 #[derive(Debug, Default, Copy, Clone)]
 pub struct vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3__bindgen_ty_1 {
-    pub _dl: u8,
-    pub _dh: u8,
+    pub dl: u8,
+    pub dh: u8,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3__bindgen_ty_1() {
@@ -1019,23 +1036,23 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3__b
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dl) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dl) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3__bindgen_ty_1),
             "::",
-            stringify!(_dl)
+            stringify!(dl)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dh) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dh) as usize - ptr as usize },
         1usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3__bindgen_ty_1),
             "::",
-            stringify!(_dh)
+            stringify!(dh)
         )
     );
 }
@@ -1061,33 +1078,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3),
             "::",
-            stringify!(_dx)
+            stringify!(dx)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._edx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).edx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3),
             "::",
-            stringify!(_edx)
+            stringify!(edx)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rdx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rdx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3),
             "::",
-            stringify!(_rdx)
+            stringify!(rdx)
         )
     );
 }
@@ -1104,15 +1121,15 @@ impl Default for vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_3 {
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4 {
     pub __bindgen_anon_1: vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4__bindgen_ty_1,
-    pub _bx: u16,
-    pub _ebx: u32,
-    pub _rbx: u64,
+    pub bx: u16,
+    pub ebx: u32,
+    pub rbx: u64,
 }
 #[repr(C)]
 #[derive(Debug, Default, Copy, Clone)]
 pub struct vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4__bindgen_ty_1 {
-    pub _bl: u8,
-    pub _bh: u8,
+    pub bl: u8,
+    pub bh: u8,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4__bindgen_ty_1() {
@@ -1139,23 +1156,23 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4__b
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._bl) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).bl) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4__bindgen_ty_1),
             "::",
-            stringify!(_bl)
+            stringify!(bl)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._bh) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).bh) as usize - ptr as usize },
         1usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4__bindgen_ty_1),
             "::",
-            stringify!(_bh)
+            stringify!(bh)
         )
     );
 }
@@ -1181,33 +1198,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._bx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).bx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4),
             "::",
-            stringify!(_bx)
+            stringify!(bx)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ebx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ebx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4),
             "::",
-            stringify!(_ebx)
+            stringify!(ebx)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rbx) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rbx) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4),
             "::",
-            stringify!(_rbx)
+            stringify!(rbx)
         )
     );
 }
@@ -1223,9 +1240,9 @@ impl Default for vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_4 {
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_5 {
-    pub _sp: u16,
-    pub _esp: u32,
-    pub _rsp: u64,
+    pub sp: u16,
+    pub esp: u32,
+    pub rsp: u64,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_5() {
@@ -1249,33 +1266,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_5()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._sp) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).sp) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_5),
             "::",
-            stringify!(_sp)
+            stringify!(sp)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._esp) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).esp) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_5),
             "::",
-            stringify!(_esp)
+            stringify!(esp)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rsp) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rsp) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_5),
             "::",
-            stringify!(_rsp)
+            stringify!(rsp)
         )
     );
 }
@@ -1291,9 +1308,9 @@ impl Default for vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_5 {
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6 {
-    pub _bp: u16,
-    pub _ebp: u32,
-    pub _rbp: u64,
+    pub bp: u16,
+    pub ebp: u32,
+    pub rbp: u64,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6() {
@@ -1317,33 +1334,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._bp) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).bp) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6),
             "::",
-            stringify!(_bp)
+            stringify!(bp)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ebp) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ebp) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6),
             "::",
-            stringify!(_ebp)
+            stringify!(ebp)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rbp) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rbp) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6),
             "::",
-            stringify!(_rbp)
+            stringify!(rbp)
         )
     );
 }
@@ -1359,9 +1376,9 @@ impl Default for vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_6 {
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7 {
-    pub _si: u16,
-    pub _esi: u32,
-    pub _rsi: u64,
+    pub si: u16,
+    pub esi: u32,
+    pub rsi: u64,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7() {
@@ -1385,33 +1402,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._si) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).si) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7),
             "::",
-            stringify!(_si)
+            stringify!(si)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._esi) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).esi) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7),
             "::",
-            stringify!(_esi)
+            stringify!(esi)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rsi) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rsi) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7),
             "::",
-            stringify!(_rsi)
+            stringify!(rsi)
         )
     );
 }
@@ -1427,9 +1444,9 @@ impl Default for vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_7 {
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_8 {
-    pub _di: u16,
-    pub _edi: u32,
-    pub _rdi: u64,
+    pub di: u16,
+    pub edi: u32,
+    pub rdi: u64,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_8() {
@@ -1453,33 +1470,33 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_8()
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._di) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).di) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_8),
             "::",
-            stringify!(_di)
+            stringify!(di)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._edi) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).edi) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_8),
             "::",
-            stringify!(_edi)
+            stringify!(edi)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rdi) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rdi) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1__bindgen_ty_8),
             "::",
-            stringify!(_rdi)
+            stringify!(rdi)
         )
     );
 }
@@ -1514,83 +1531,83 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1__bindgen_ty_1() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r8) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r8) as usize - ptr as usize },
         64usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r8)
+            stringify!(r8)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r9) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r9) as usize - ptr as usize },
         72usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r9)
+            stringify!(r9)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r10) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r10) as usize - ptr as usize },
         80usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r10)
+            stringify!(r10)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r11) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r11) as usize - ptr as usize },
         88usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r11)
+            stringify!(r11)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r12) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r12) as usize - ptr as usize },
         96usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r12)
+            stringify!(r12)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r13) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r13) as usize - ptr as usize },
         104usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r13)
+            stringify!(r13)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r14) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r14) as usize - ptr as usize },
         112usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r14)
+            stringify!(r14)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._r15) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).r15) as usize - ptr as usize },
         120usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_r15)
+            stringify!(r15)
         )
     );
 }
@@ -1619,13 +1636,13 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_1() {
         concat!("Alignment of ", stringify!(vcpu_state_t__bindgen_ty_1))
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._regs) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).regs) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_1),
             "::",
-            stringify!(_regs)
+            stringify!(regs)
         )
     );
 }
@@ -1641,8 +1658,8 @@ impl Default for vcpu_state_t__bindgen_ty_1 {
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_2 {
-    pub _eip: u32,
-    pub _rip: u64,
+    pub eip: u32,
+    pub rip: u64,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_2() {
@@ -1660,23 +1677,23 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_2() {
         concat!("Alignment of ", stringify!(vcpu_state_t__bindgen_ty_2))
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._eip) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).eip) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_2),
             "::",
-            stringify!(_eip)
+            stringify!(eip)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rip) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rip) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_2),
             "::",
-            stringify!(_rip)
+            stringify!(rip)
         )
     );
 }
@@ -1692,8 +1709,8 @@ impl Default for vcpu_state_t__bindgen_ty_2 {
 #[repr(C)]
 #[derive(Copy, Clone)]
 pub union vcpu_state_t__bindgen_ty_3 {
-    pub _eflags: u32,
-    pub _rflags: u64,
+    pub eflags: u32,
+    pub rflags: u64,
 }
 #[test]
 fn bindgen_test_layout_vcpu_state_t__bindgen_ty_3() {
@@ -1711,23 +1728,23 @@ fn bindgen_test_layout_vcpu_state_t__bindgen_ty_3() {
         concat!("Alignment of ", stringify!(vcpu_state_t__bindgen_ty_3))
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._eflags) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).eflags) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_3),
             "::",
-            stringify!(_eflags)
+            stringify!(eflags)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._rflags) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rflags) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t__bindgen_ty_3),
             "::",
-            stringify!(_rflags)
+            stringify!(rflags)
         )
     );
 }
@@ -1755,263 +1772,263 @@ fn bindgen_test_layout_vcpu_state_t() {
         concat!("Alignment of ", stringify!(vcpu_state_t))
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cs) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cs) as usize - ptr as usize },
         144usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_cs)
+            stringify!(cs)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ss) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ss) as usize - ptr as usize },
         168usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_ss)
+            stringify!(ss)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ds) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ds) as usize - ptr as usize },
         192usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_ds)
+            stringify!(ds)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._es) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).es) as usize - ptr as usize },
         216usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_es)
+            stringify!(es)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._fs) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).fs) as usize - ptr as usize },
         240usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_fs)
+            stringify!(fs)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._gs) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).gs) as usize - ptr as usize },
         264usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_gs)
+            stringify!(gs)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._ldt) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).ldt) as usize - ptr as usize },
         288usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_ldt)
+            stringify!(ldt)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._tr) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).tr) as usize - ptr as usize },
         312usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_tr)
+            stringify!(tr)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._gdt) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).gdt) as usize - ptr as usize },
         336usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_gdt)
+            stringify!(gdt)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._idt) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).idt) as usize - ptr as usize },
         360usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_idt)
+            stringify!(idt)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr0) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr0) as usize - ptr as usize },
         384usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_cr0)
+            stringify!(cr0)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr2) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr2) as usize - ptr as usize },
         392usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_cr2)
+            stringify!(cr2)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr3) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr3) as usize - ptr as usize },
         400usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_cr3)
+            stringify!(cr3)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr4) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr4) as usize - ptr as usize },
         408usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_cr4)
+            stringify!(cr4)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dr0) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dr0) as usize - ptr as usize },
         416usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_dr0)
+            stringify!(dr0)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dr1) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dr1) as usize - ptr as usize },
         424usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_dr1)
+            stringify!(dr1)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dr2) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dr2) as usize - ptr as usize },
         432usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_dr2)
+            stringify!(dr2)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dr3) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dr3) as usize - ptr as usize },
         440usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_dr3)
+            stringify!(dr3)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dr6) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dr6) as usize - ptr as usize },
         448usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_dr6)
+            stringify!(dr6)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._dr7) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).dr7) as usize - ptr as usize },
         456usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_dr7)
+            stringify!(dr7)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._pde) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).pde) as usize - ptr as usize },
         464usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_pde)
+            stringify!(pde)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._efer) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).efer) as usize - ptr as usize },
         472usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_efer)
+            stringify!(efer)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._sysenter_cs) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).sysenter_cs) as usize - ptr as usize },
         476usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_sysenter_cs)
+            stringify!(sysenter_cs)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._sysenter_eip) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).sysenter_eip) as usize - ptr as usize },
         480usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_sysenter_eip)
+            stringify!(sysenter_eip)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._sysenter_esp) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).sysenter_esp) as usize - ptr as usize },
         488usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_sysenter_esp)
+            stringify!(sysenter_esp)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._activity_state) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).activity_state) as usize - ptr as usize },
         496usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_activity_state)
+            stringify!(activity_state)
         )
     );
     assert_eq!(
@@ -2025,13 +2042,13 @@ fn bindgen_test_layout_vcpu_state_t() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._interruptibility_state) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).interruptibility_state) as usize - ptr as usize },
         504usize,
         concat!(
             "Offset of field: ",
             stringify!(vcpu_state_t),
             "::",
-            stringify!(_interruptibility_state)
+            stringify!(interruptibility_state)
         )
     );
 }
@@ -2503,17 +2520,100 @@ fn bindgen_test_layout_hax_msr_data() {
         )
     );
 }
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_UNKNOWN: vcpu_panic_reason = 0;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_IN_VMX_EXECUTE:
+    vcpu_panic_reason = 1;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_IN_VMX_VMWRITE:
+    vcpu_panic_reason = 2;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_WHILE_VCPU_PREPARE:
+    vcpu_panic_reason = 3;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_IN_VCPU_PREPARE:
+    vcpu_panic_reason = 4;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_WHILE_VCPU_VMREAD_ALL:
+    vcpu_panic_reason = 5;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_WHILE_EXIT_CR_ACCESS:
+    vcpu_panic_reason = 6;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_WHILE_CLTS: vcpu_panic_reason =
+    7;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_WHILE_LMSW: vcpu_panic_reason =
+    8;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_ON_VCPU_SET_REGS:
+    vcpu_panic_reason = 9;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_LOAD_FAILED_IN_VMREAD: vcpu_panic_reason =
+    10;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_PUT_FAILED_WHILE_VCPU_VMREAD_ALL:
+    vcpu_panic_reason = 11;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_PUT_FAILED_IN_VMX_VMWRITE:
+    vcpu_panic_reason = 12;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_PUT_FAILED_WHILE_EXIT_CR_ACCESS:
+    vcpu_panic_reason = 13;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_PUT_FAILED_WHILE_CLTS: vcpu_panic_reason =
+    14;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_PUT_FAILED_WHILE_LMSW: vcpu_panic_reason =
+    15;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_PUT_FAILED_ON_VCPU_SET_REGS:
+    vcpu_panic_reason = 16;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VMCS_PUT_FAILED_IN_VMREAD: vcpu_panic_reason = 17;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_PUT_VMCS_FAILED: vcpu_panic_reason = 18;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_PUT_VMCS_FAILED_BEFORE_VMEXIT: vcpu_panic_reason =
+    19;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_READ_GUEST_VIRTUAL_ERROR: vcpu_panic_reason = 20;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_READ_GUEST_VIRTUAL_ERROR_IN_STRING_IO:
+    vcpu_panic_reason = 21;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_WRITE_GUEST_VIRTUAL_ERROR: vcpu_panic_reason = 22;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_WRITE_GUEST_VIRTUAL_FAILED: vcpu_panic_reason =
+    23;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_IO_POST_UNEXPECTED_PAGE_FAULT: vcpu_panic_reason =
+    24;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_MMIO_FETCH_INSTRUCTION_FAILED: vcpu_panic_reason =
+    25;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_EM_DECODE_INS_FAILED: vcpu_panic_reason = 26;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_EM_EMULATE_INS_FAILED: vcpu_panic_reason = 27;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_EM_EMULATE_INS_FAILED_IN_VCPU_EXECUTE:
+    vcpu_panic_reason = 28;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VCPU_READ_GPR_INVALID_REGISTER_INDEX:
+    vcpu_panic_reason = 29;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_VCPU_WRITE_GPR_INVALID_REGISTER_INDEX:
+    vcpu_panic_reason = 30;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_TRIPLE_FAULT: vcpu_panic_reason = 31;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_INVALID_GUEST_STATE: vcpu_panic_reason = 32;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_PAGE_FAULT_WHILE_EPT_IS_ENABLED:
+    vcpu_panic_reason = 33;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_MACHINE_CHECK: vcpu_panic_reason = 34;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_DOUBLE_FAULT: vcpu_panic_reason = 35;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_FAILED_TO_RELOAD_PDPT_FOR_EPT_PAE_MODE:
+    vcpu_panic_reason = 36;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_64_BIT_GUEST_NOT_ALLOWED_ON_32_BIT_HOST:
+    vcpu_panic_reason = 37;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_UNEXPECTED_EPT_MISCONFIGURATION:
+    vcpu_panic_reason = 38;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_INCORRECT_EPT_SETTING: vcpu_panic_reason = 39;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_EPT_HANDLE_ACCESS_VIOLATION_RETURNED_ERROR:
+    vcpu_panic_reason = 40;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_UNHANDLED_VMX_VMEXIT_REASON: vcpu_panic_reason =
+    41;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_AMD_UNIMPLEMENTED: vcpu_panic_reason = 42;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_RVI_HANDLE_ACCESS_VIOLATION_RETURNED_EEXIST:
+    vcpu_panic_reason = 43;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_ATTEMPTED_TO_USE_UNSET_NRIP: vcpu_panic_reason =
+    44;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_ATTEMPTED_TO_USE_UNSET_EXIT_GPA:
+    vcpu_panic_reason = 45;
+pub const vcpu_panic_reason_HAX_VCPU_PANIC_REASON_ILLEGAL_GUEST_WRITE_TO_IA32_EFER_SVME:
+    vcpu_panic_reason = 46;
+pub type vcpu_panic_reason = ::std::os::raw::c_int;
 #[repr(C, packed)]
 #[derive(Copy, Clone)]
 pub struct hax_tunnel {
-    pub _exit_reason: u32,
+    pub exit_reason: u32,
     pub pad0: u32,
-    pub _exit_status: u32,
+    pub exit_status: u32,
     pub user_event_pending: u32,
     pub ready_for_interrupt_injection: ::std::os::raw::c_int,
     pub request_interrupt_window: ::std::os::raw::c_int,
     pub __bindgen_anon_1: hax_tunnel__bindgen_ty_1,
     pub apic_base: u64,
+    pub vcpu_panic_reason: u32,
 }
 #[repr(C)]
 #[derive(Copy, Clone)]
@@ -2521,22 +2621,22 @@ pub union hax_tunnel__bindgen_ty_1 {
     pub io: hax_tunnel__bindgen_ty_1__bindgen_ty_1,
     pub mmio: hax_tunnel__bindgen_ty_1__bindgen_ty_2,
     pub pagefault: hax_tunnel__bindgen_ty_1__bindgen_ty_3,
-    pub state: hax_tunnel__bindgen_ty_1__bindgen_ty_4,
-    pub debug: hax_tunnel__bindgen_ty_1__bindgen_ty_5,
+    pub debug: hax_tunnel__bindgen_ty_1__bindgen_ty_4,
+    pub eoi: hax_tunnel__bindgen_ty_1__bindgen_ty_5,
 }
 #[repr(C)]
 #[derive(Debug, Default, Copy, Clone)]
 pub struct hax_tunnel__bindgen_ty_1__bindgen_ty_1 {
-    pub _direction: u8,
-    pub _df: u8,
-    pub _size: u16,
-    pub _port: u16,
-    pub _count: u16,
-    pub _flags: u8,
-    pub _pad0: u8,
-    pub _pad1: u16,
-    pub _pad2: u32,
-    pub _vaddr: hax_vaddr_t,
+    pub direction: u8,
+    pub df: u8,
+    pub size: u16,
+    pub port: u16,
+    pub count: u16,
+    pub flags: u8,
+    pub pad0: u8,
+    pub pad1: u16,
+    pub pad2: u32,
+    pub vaddr: hax_vaddr_t,
 }
 #[test]
 fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_1() {
@@ -2560,103 +2660,103 @@ fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_1() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._direction) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).direction) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_direction)
+            stringify!(direction)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._df) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).df) as usize - ptr as usize },
         1usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_df)
+            stringify!(df)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._size) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).size) as usize - ptr as usize },
         2usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_size)
+            stringify!(size)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._port) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).port) as usize - ptr as usize },
         4usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_port)
+            stringify!(port)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._count) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).count) as usize - ptr as usize },
         6usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_count)
+            stringify!(count)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._flags) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).flags) as usize - ptr as usize },
         8usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_flags)
+            stringify!(flags)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._pad0) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).pad0) as usize - ptr as usize },
         9usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_pad0)
+            stringify!(pad0)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._pad1) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).pad1) as usize - ptr as usize },
         10usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_pad1)
+            stringify!(pad1)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._pad2) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).pad2) as usize - ptr as usize },
         12usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_pad2)
+            stringify!(pad2)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._vaddr) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).vaddr) as usize - ptr as usize },
         16usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_1),
             "::",
-            stringify!(_vaddr)
+            stringify!(vaddr)
         )
     );
 }
@@ -2770,7 +2870,9 @@ fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_3() {
 #[repr(C)]
 #[derive(Debug, Default, Copy, Clone)]
 pub struct hax_tunnel__bindgen_ty_1__bindgen_ty_4 {
-    pub dummy: hax_paddr_t,
+    pub rip: u64,
+    pub dr6: u64,
+    pub dr7: u64,
 }
 #[test]
 fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_4() {
@@ -2779,7 +2881,7 @@ fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_4() {
     let ptr = UNINIT.as_ptr();
     assert_eq!(
         ::std::mem::size_of::<hax_tunnel__bindgen_ty_1__bindgen_ty_4>(),
-        8usize,
+        24usize,
         concat!(
             "Size of: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_4)
@@ -2794,22 +2896,40 @@ fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_4() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr).dummy) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).rip) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_4),
             "::",
-            stringify!(dummy)
+            stringify!(rip)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).dr6) as usize - ptr as usize },
+        8usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_4),
+            "::",
+            stringify!(dr6)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).dr7) as usize - ptr as usize },
+        16usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_4),
+            "::",
+            stringify!(dr7)
         )
     );
 }
 #[repr(C)]
 #[derive(Debug, Default, Copy, Clone)]
 pub struct hax_tunnel__bindgen_ty_1__bindgen_ty_5 {
-    pub rip: u64,
-    pub dr6: u64,
-    pub dr7: u64,
+    pub vector: u8,
 }
 #[test]
 fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_5() {
@@ -2818,7 +2938,7 @@ fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_5() {
     let ptr = UNINIT.as_ptr();
     assert_eq!(
         ::std::mem::size_of::<hax_tunnel__bindgen_ty_1__bindgen_ty_5>(),
-        24usize,
+        1usize,
         concat!(
             "Size of: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_5)
@@ -2826,40 +2946,20 @@ fn bindgen_test_layout_hax_tunnel__bindgen_ty_1__bindgen_ty_5() {
     );
     assert_eq!(
         ::std::mem::align_of::<hax_tunnel__bindgen_ty_1__bindgen_ty_5>(),
-        8usize,
+        1usize,
         concat!(
             "Alignment of ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_5)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr).rip) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).vector) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_5),
             "::",
-            stringify!(rip)
-        )
-    );
-    assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr).dr6) as usize - ptr as usize },
-        8usize,
-        concat!(
-            "Offset of field: ",
-            stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_5),
-            "::",
-            stringify!(dr6)
-        )
-    );
-    assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr).dr7) as usize - ptr as usize },
-        16usize,
-        concat!(
-            "Offset of field: ",
-            stringify!(hax_tunnel__bindgen_ty_1__bindgen_ty_5),
-            "::",
-            stringify!(dr7)
+            stringify!(vector)
         )
     );
 }
@@ -2909,23 +3009,23 @@ fn bindgen_test_layout_hax_tunnel__bindgen_ty_1() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr).state) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).debug) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1),
             "::",
-            stringify!(state)
+            stringify!(debug)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr).debug) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).eoi) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel__bindgen_ty_1),
             "::",
-            stringify!(debug)
+            stringify!(eoi)
         )
     );
 }
@@ -2944,7 +3044,7 @@ fn bindgen_test_layout_hax_tunnel() {
     let ptr = UNINIT.as_ptr();
     assert_eq!(
         ::std::mem::size_of::<hax_tunnel>(),
-        56usize,
+        60usize,
         concat!("Size of: ", stringify!(hax_tunnel))
     );
     assert_eq!(
@@ -2953,13 +3053,13 @@ fn bindgen_test_layout_hax_tunnel() {
         concat!("Alignment of ", stringify!(hax_tunnel))
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._exit_reason) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).exit_reason) as usize - ptr as usize },
         0usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel),
             "::",
-            stringify!(_exit_reason)
+            stringify!(exit_reason)
         )
     );
     assert_eq!(
@@ -2973,13 +3073,13 @@ fn bindgen_test_layout_hax_tunnel() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._exit_status) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).exit_status) as usize - ptr as usize },
         8usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_tunnel),
             "::",
-            stringify!(_exit_status)
+            stringify!(exit_status)
         )
     );
     assert_eq!(
@@ -3024,6 +3124,16 @@ fn bindgen_test_layout_hax_tunnel() {
             stringify!(apic_base)
         )
     );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).vcpu_panic_reason) as usize - ptr as usize },
+        56usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_tunnel),
+            "::",
+            stringify!(vcpu_panic_reason)
+        )
+    );
 }
 impl Default for hax_tunnel {
     fn default() -> Self {
@@ -3043,10 +3153,10 @@ pub struct hax_fastmmio {
     pub direction: u8,
     pub reg_index: u16,
     pub pad0: u32,
-    pub _cr0: u64,
-    pub _cr2: u64,
-    pub _cr3: u64,
-    pub _cr4: u64,
+    pub cr0: u64,
+    pub cr2: u64,
+    pub cr3: u64,
+    pub cr4: u64,
 }
 #[repr(C)]
 #[derive(Copy, Clone)]
@@ -3164,43 +3274,43 @@ fn bindgen_test_layout_hax_fastmmio() {
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr0) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr0) as usize - ptr as usize },
         24usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_fastmmio),
             "::",
-            stringify!(_cr0)
+            stringify!(cr0)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr2) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr2) as usize - ptr as usize },
         32usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_fastmmio),
             "::",
-            stringify!(_cr2)
+            stringify!(cr2)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr3) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr3) as usize - ptr as usize },
         40usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_fastmmio),
             "::",
-            stringify!(_cr3)
+            stringify!(cr3)
         )
     );
     assert_eq!(
-        unsafe { ::std::ptr::addr_of!((*ptr)._cr4) as usize - ptr as usize },
+        unsafe { ::std::ptr::addr_of!((*ptr).cr4) as usize - ptr as usize },
         48usize,
         concat!(
             "Offset of field: ",
             stringify!(hax_fastmmio),
             "::",
-            stringify!(_cr4)
+            stringify!(cr4)
         )
     );
 }
@@ -4049,3 +4159,141 @@ impl Default for hax_log_file {
         }
     }
 }
+#[repr(C, packed)]
+#[derive(Debug, Default, Copy, Clone)]
+pub struct hax_create_device_info {
+    pub type_: u32,
+    pub flags: u32,
+    pub size: u32,
+}
+#[test]
+fn bindgen_test_layout_hax_create_device_info() {
+    const UNINIT: ::std::mem::MaybeUninit<hax_create_device_info> =
+        ::std::mem::MaybeUninit::uninit();
+    let ptr = UNINIT.as_ptr();
+    assert_eq!(
+        ::std::mem::size_of::<hax_create_device_info>(),
+        12usize,
+        concat!("Size of: ", stringify!(hax_create_device_info))
+    );
+    assert_eq!(
+        ::std::mem::align_of::<hax_create_device_info>(),
+        1usize,
+        concat!("Alignment of ", stringify!(hax_create_device_info))
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).type_) as usize - ptr as usize },
+        0usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_create_device_info),
+            "::",
+            stringify!(type_)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).flags) as usize - ptr as usize },
+        4usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_create_device_info),
+            "::",
+            stringify!(flags)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).size) as usize - ptr as usize },
+        8usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_create_device_info),
+            "::",
+            stringify!(size)
+        )
+    );
+}
+#[repr(C, packed)]
+#[derive(Debug, Default, Copy, Clone)]
+pub struct hax_msi {
+    pub vector: u8,
+    pub dest_id: u8,
+    pub dest_mode: u8,
+    pub trigger_mode: u8,
+    pub delivery_mode: u8,
+    pub level: u8,
+}
+#[test]
+fn bindgen_test_layout_hax_msi() {
+    const UNINIT: ::std::mem::MaybeUninit<hax_msi> = ::std::mem::MaybeUninit::uninit();
+    let ptr = UNINIT.as_ptr();
+    assert_eq!(
+        ::std::mem::size_of::<hax_msi>(),
+        6usize,
+        concat!("Size of: ", stringify!(hax_msi))
+    );
+    assert_eq!(
+        ::std::mem::align_of::<hax_msi>(),
+        1usize,
+        concat!("Alignment of ", stringify!(hax_msi))
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).vector) as usize - ptr as usize },
+        0usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_msi),
+            "::",
+            stringify!(vector)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).dest_id) as usize - ptr as usize },
+        1usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_msi),
+            "::",
+            stringify!(dest_id)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).dest_mode) as usize - ptr as usize },
+        2usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_msi),
+            "::",
+            stringify!(dest_mode)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).trigger_mode) as usize - ptr as usize },
+        3usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_msi),
+            "::",
+            stringify!(trigger_mode)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).delivery_mode) as usize - ptr as usize },
+        4usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_msi),
+            "::",
+            stringify!(delivery_mode)
+        )
+    );
+    assert_eq!(
+        unsafe { ::std::ptr::addr_of!((*ptr).level) as usize - ptr as usize },
+        5usize,
+        concat!(
+            "Offset of field: ",
+            stringify!(hax_msi),
+            "::",
+            stringify!(level)
+        )
+    );
+}
diff --git a/hypervisor/src/haxm/vcpu.rs b/hypervisor/src/haxm/vcpu.rs
index 700cbb02f..2f93e20f1 100644
--- a/hypervisor/src/haxm/vcpu.rs
+++ b/hypervisor/src/haxm/vcpu.rs
@@ -33,7 +33,7 @@ use crate::CpuIdEntry;
 use crate::DebugRegs;
 use crate::DescriptorTable;
 use crate::Fpu;
-use crate::HypervHypercall;
+use crate::FpuReg;
 use crate::IoOperation;
 use crate::IoParams;
 use crate::Regs;
@@ -41,6 +41,8 @@ use crate::Segment;
 use crate::Sregs;
 use crate::Vcpu;
 use crate::VcpuExit;
+use crate::VcpuShutdownError;
+use crate::VcpuShutdownErrorKind;
 use crate::VcpuX86_64;
 use crate::Xsave;
 
@@ -58,11 +60,12 @@ const HAX_EXIT_REALMODE: u32 = 3;
 // Also used when vcpu thread receives a signal
 const HAX_EXIT_INTERRUPT: u32 = 4;
 // Unknown vmexit, mostly trigger reboot
+#[allow(dead_code)]
 const HAX_EXIT_UNKNOWN: u32 = 5;
 // HALT from guest
 const HAX_EXIT_HLT: u32 = 6;
-// Reboot request, like because of triple fault in guest
-const HAX_EXIT_STATECHANGE: u32 = 7;
+// VCPU panic, like because of triple fault in guest
+const HAX_EXIT_VCPU_PANIC: u32 = 7;
 // Paused by crosvm setting _exit_reason to HAX_EXIT_PAUSED before entry
 pub(crate) const HAX_EXIT_PAUSED: u32 = 8;
 // MMIO instruction emulation through io_buffer
@@ -103,26 +106,26 @@ impl HaxmVcpu {
         let mut state = vcpu_state_t::default();
 
         // SAFETY: trivially safe with return value checked.
-        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_GET_REGS(), &mut state) };
+        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_GET_REGS, &mut state) };
         if ret != 0 {
             return errno_result();
         }
 
         // Also read efer MSR
-        state._efer = self.get_msr(IA32_EFER)? as u32;
+        state.efer = self.get_msr(IA32_EFER)? as u32;
 
         Ok(VcpuState { state })
     }
 
     fn set_vcpu_state(&self, state: &mut VcpuState) -> Result<()> {
         // SAFETY: trivially safe with return value checked.
-        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_SET_REGS(), &mut state.state) };
+        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_SET_REGS, &mut state.state) };
         if ret != 0 {
             return errno_result();
         }
 
         // Also set efer MSR
-        self.set_msr(IA32_EFER, state.state._efer as u64)
+        self.set_msr(IA32_EFER, state.state.efer as u64)
     }
 }
 
@@ -153,7 +156,7 @@ impl Vcpu for HaxmVcpu {
         // Crosvm's HAXM implementation does not use the _exit_reason, so it's fine if we
         // overwrite it.
         unsafe {
-            (*self.tunnel)._exit_reason = if exit { HAX_EXIT_PAUSED } else { 0 };
+            (*self.tunnel).exit_reason = if exit { HAX_EXIT_PAUSED } else { 0 };
         }
     }
 
@@ -174,13 +177,16 @@ impl Vcpu for HaxmVcpu {
     /// Once called, it will determine whether a mmio read or mmio write was the reason for the mmio
     /// exit, call `handle_fn` with the respective IoOperation to perform the mmio read or
     /// write, and set the return data in the vcpu so that the vcpu can resume running.
-    fn handle_mmio(&self, handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
+    fn handle_mmio(
+        &self,
+        handle_fn: &mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>,
+    ) -> Result<()> {
         // SAFETY:
         // Safe because we know we mapped enough memory to hold the hax_tunnel struct because the
         // kernel told us how large it was.
         // Verify that the handler is called for mmio context only.
         unsafe {
-            assert!((*self.tunnel)._exit_status == HAX_EXIT_FAST_MMIO);
+            assert!((*self.tunnel).exit_status == HAX_EXIT_FAST_MMIO);
         }
         let mmio = self.io_buffer as *mut hax_fastmmio;
         let (address, size, direction) =
@@ -195,7 +201,12 @@ impl Vcpu for HaxmVcpu {
                     address,
                     size,
                     operation: IoOperation::Read,
-                }) {
+                })
+                // We have to unwrap/panic here because HAXM doesn't have a
+                // facility to inject a GP fault here. Once HAXM can do that, we
+                // should inject a GP fault & bubble the error.
+                .unwrap()
+                {
                     let data = u64::from_ne_bytes(data);
                     // SAFETY:
                     // Safe because we know this is an mmio read, so we need to put data into the
@@ -216,7 +227,9 @@ impl Vcpu for HaxmVcpu {
                     operation: IoOperation::Write {
                         data: data.to_ne_bytes(),
                     },
-                });
+                })
+                // Similarly to the read direction, we MUST panic here.
+                .unwrap();
                 Ok(())
             }
             _ => Err(Error::new(EINVAL)),
@@ -235,15 +248,15 @@ impl Vcpu for HaxmVcpu {
         // kernel told us how large it was.
         // Verify that the handler is called for io context only.
         unsafe {
-            assert!((*self.tunnel)._exit_status == HAX_EXIT_IO);
+            assert!((*self.tunnel).exit_status == HAX_EXIT_IO);
         }
         // SAFETY:
         // Safe because the exit_reason (which comes from the kernel) told us which
         // union field to use.
         let io = unsafe { (*self.tunnel).__bindgen_anon_1.io };
-        let address = io._port.into();
-        let size = (io._count as usize) * (io._size as usize);
-        match io._direction as u32 {
+        let address = io.port.into();
+        let size = (io.count as usize) * (io.size as usize);
+        match io.direction as u32 {
             HAX_EXIT_DIRECTION_PIO_IN => {
                 if let Some(data) = handle_fn(IoParams {
                     address,
@@ -281,33 +294,13 @@ impl Vcpu for HaxmVcpu {
         }
     }
 
-    /// haxm does not handle hypervcalls.
-    fn handle_hyperv_hypercall(&self, _func: &mut dyn FnMut(HypervHypercall) -> u64) -> Result<()> {
-        Err(Error::new(libc::ENXIO))
-    }
-
-    /// This function should be called after `Vcpu::run` returns `VcpuExit::RdMsr`,
-    /// and in the same thread as run.
-    ///
-    /// It will put `data` into the user buffer and return.
-    fn handle_rdmsr(&self, _data: u64) -> Result<()> {
-        // TODO(b/233766326): Implement.
-        Err(Error::new(libc::ENXIO))
-    }
-
-    /// This function should be called after `Vcpu::run` returns `VcpuExit::WrMsr`,
-    /// and in the same thread as run.
-    fn handle_wrmsr(&self) {
-        // TODO(b/233766326): Implement.
-    }
-
     #[allow(clippy::cast_ptr_alignment)]
     // The pointer is page aligned so casting to a different type is well defined, hence the clippy
     // allow attribute.
     fn run(&mut self) -> Result<VcpuExit> {
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl(self, HAX_VCPU_IOCTL_RUN()) };
+        let ret = unsafe { ioctl(self, HAX_VCPU_IOCTL_RUN) };
         if ret != 0 {
             return errno_result();
         }
@@ -315,14 +308,22 @@ impl Vcpu for HaxmVcpu {
         // SAFETY:
         // Safe because we know we mapped enough memory to hold the hax_tunnel struct because the
         // kernel told us how large it was.
-        let exit_status = unsafe { (*self.tunnel)._exit_status };
+        let exit_status = unsafe { (*self.tunnel).exit_status };
 
         match exit_status {
             HAX_EXIT_IO => Ok(VcpuExit::Io),
             HAX_EXIT_INTERRUPT => Ok(VcpuExit::Intr),
-            HAX_EXIT_UNKNOWN => Ok(VcpuExit::Unknown),
             HAX_EXIT_HLT => Ok(VcpuExit::Hlt),
-            HAX_EXIT_STATECHANGE => Ok(VcpuExit::Shutdown),
+            HAX_EXIT_VCPU_PANIC => {
+                // SAFETY:
+                // 1) we mapped enough memory to hold the hax_tunnel struct because the kernel told
+                //    us how large it was. That memory is still alive here.
+                let panic_reason = unsafe { (*self.tunnel).vcpu_panic_reason };
+                Ok(VcpuExit::Shutdown(Err(VcpuShutdownError::new(
+                    VcpuShutdownErrorKind::Other,
+                    panic_reason as u64,
+                ))))
+            }
             HAX_EXIT_FAST_MMIO => Ok(VcpuExit::Mmio),
             HAX_EXIT_PAGEFAULT => Ok(VcpuExit::Exception),
             HAX_EXIT_DEBUG => Ok(VcpuExit::Debug),
@@ -353,10 +354,11 @@ impl VcpuX86_64 for HaxmVcpu {
     }
 
     /// Injects interrupt vector `irq` into the VCPU.
-    fn interrupt(&self, irq: u32) -> Result<()> {
+    fn interrupt(&self, irq: u8) -> Result<()> {
+        let irq: u32 = irq.into();
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_ref(self, HAX_VCPU_IOCTL_INTERRUPT(), &irq) };
+        let ret = unsafe { ioctl_with_ref(self, HAX_VCPU_IOCTL_INTERRUPT, &irq) };
         if ret != 0 {
             return errno_result();
         }
@@ -400,7 +402,7 @@ impl VcpuX86_64 for HaxmVcpu {
         let mut fpu = fx_layout::default();
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_GET_FPU(), &mut fpu) };
+        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_GET_FPU, &mut fpu) };
 
         if ret != 0 {
             return errno_result();
@@ -414,7 +416,7 @@ impl VcpuX86_64 for HaxmVcpu {
         let mut current_fpu = fx_layout::default();
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_GET_FPU(), &mut current_fpu) };
+        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_GET_FPU, &mut current_fpu) };
 
         if ret != 0 {
             return errno_result();
@@ -428,7 +430,7 @@ impl VcpuX86_64 for HaxmVcpu {
 
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_ref(self, HAX_VCPU_IOCTL_SET_FPU(), &new_fpu) };
+        let ret = unsafe { ioctl_with_ref(self, HAX_VCPU_IOCTL_SET_FPU, &new_fpu) };
 
         if ret != 0 {
             return errno_result();
@@ -488,7 +490,7 @@ impl VcpuX86_64 for HaxmVcpu {
 
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_GET_MSRS(), &mut msr_data) };
+        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_GET_MSRS, &mut msr_data) };
         if ret != 0 {
             return errno_result();
         }
@@ -511,7 +513,7 @@ impl VcpuX86_64 for HaxmVcpu {
 
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_SET_MSRS(), &mut msr_data) };
+        let ret = unsafe { ioctl_with_mut_ref(self, HAX_VCPU_IOCTL_SET_MSRS, &mut msr_data) };
         if ret != 0 {
             return errno_result();
         }
@@ -536,7 +538,7 @@ impl VcpuX86_64 for HaxmVcpu {
         let ret = unsafe {
             ioctl_with_ptr_sized(
                 self,
-                HAX_VCPU_IOCTL_SET_CPUID(),
+                HAX_VCPU_IOCTL_SET_CPUID,
                 hax.as_ptr(),
                 size_of::<hax_cpuid>() + total * size_of::<hax_cpuid_entry>(),
             )
@@ -556,12 +558,6 @@ impl VcpuX86_64 for HaxmVcpu {
         Err(Error::new(ENXIO))
     }
 
-    /// Gets the system emulated hyper-v CPUID values.
-    fn get_hyperv_cpuid(&self) -> Result<CpuId> {
-        // HaxmVcpu does not support hyperv_cpuid
-        Err(Error::new(libc::ENXIO))
-    }
-
     fn set_guest_debug(&self, _addrs: &[GuestAddress], _enable_singlestep: bool) -> Result<()> {
         // TODO(b/173807302): Implement this
         Err(Error::new(ENOENT))
@@ -598,59 +594,59 @@ impl VcpuState {
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_1
-                    ._rax,
+                    .rax,
                 rbx: self
                     .state
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_4
-                    ._rbx,
+                    .rbx,
                 rcx: self
                     .state
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_2
-                    ._rcx,
+                    .rcx,
                 rdx: self
                     .state
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_3
-                    ._rdx,
+                    .rdx,
                 rsi: self
                     .state
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_7
-                    ._rsi,
+                    .rsi,
                 rdi: self
                     .state
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_8
-                    ._rdi,
+                    .rdi,
                 rsp: self
                     .state
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_5
-                    ._rsp,
+                    .rsp,
                 rbp: self
                     .state
                     .__bindgen_anon_1
                     .__bindgen_anon_1
                     .__bindgen_anon_6
-                    ._rbp,
-                r8: self.state.__bindgen_anon_1.__bindgen_anon_1._r8,
-                r9: self.state.__bindgen_anon_1.__bindgen_anon_1._r9,
-                r10: self.state.__bindgen_anon_1.__bindgen_anon_1._r10,
-                r11: self.state.__bindgen_anon_1.__bindgen_anon_1._r11,
-                r12: self.state.__bindgen_anon_1.__bindgen_anon_1._r12,
-                r13: self.state.__bindgen_anon_1.__bindgen_anon_1._r13,
-                r14: self.state.__bindgen_anon_1.__bindgen_anon_1._r14,
-                r15: self.state.__bindgen_anon_1.__bindgen_anon_1._r15,
-                rip: self.state.__bindgen_anon_2._rip,
-                rflags: self.state.__bindgen_anon_3._rflags,
+                    .rbp,
+                r8: self.state.__bindgen_anon_1.__bindgen_anon_1.r8,
+                r9: self.state.__bindgen_anon_1.__bindgen_anon_1.r9,
+                r10: self.state.__bindgen_anon_1.__bindgen_anon_1.r10,
+                r11: self.state.__bindgen_anon_1.__bindgen_anon_1.r11,
+                r12: self.state.__bindgen_anon_1.__bindgen_anon_1.r12,
+                r13: self.state.__bindgen_anon_1.__bindgen_anon_1.r13,
+                r14: self.state.__bindgen_anon_1.__bindgen_anon_1.r14,
+                r15: self.state.__bindgen_anon_1.__bindgen_anon_1.r15,
+                rip: self.state.__bindgen_anon_2.rip,
+                rflags: self.state.__bindgen_anon_3.rflags,
             }
         }
     }
@@ -660,114 +656,114 @@ impl VcpuState {
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_1
-            ._rax = regs.rax;
+            .rax = regs.rax;
         self.state
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_4
-            ._rbx = regs.rbx;
+            .rbx = regs.rbx;
         self.state
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_2
-            ._rcx = regs.rcx;
+            .rcx = regs.rcx;
         self.state
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_3
-            ._rdx = regs.rdx;
+            .rdx = regs.rdx;
         self.state
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_7
-            ._rsi = regs.rsi;
+            .rsi = regs.rsi;
         self.state
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_8
-            ._rdi = regs.rdi;
+            .rdi = regs.rdi;
         self.state
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_5
-            ._rsp = regs.rsp;
+            .rsp = regs.rsp;
         self.state
             .__bindgen_anon_1
             .__bindgen_anon_1
             .__bindgen_anon_6
-            ._rbp = regs.rbp;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r8 = regs.r8;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r9 = regs.r9;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r10 = regs.r10;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r11 = regs.r11;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r12 = regs.r12;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r13 = regs.r13;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r14 = regs.r14;
-        self.state.__bindgen_anon_1.__bindgen_anon_1._r15 = regs.r15;
-        self.state.__bindgen_anon_2._rip = regs.rip;
-        self.state.__bindgen_anon_3._rflags = regs.rflags;
+            .rbp = regs.rbp;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r8 = regs.r8;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r9 = regs.r9;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r10 = regs.r10;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r11 = regs.r11;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r12 = regs.r12;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r13 = regs.r13;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r14 = regs.r14;
+        self.state.__bindgen_anon_1.__bindgen_anon_1.r15 = regs.r15;
+        self.state.__bindgen_anon_2.rip = regs.rip;
+        self.state.__bindgen_anon_3.rflags = regs.rflags;
     }
 
     fn get_sregs(&self) -> Sregs {
         Sregs {
-            cs: Segment::from(&self.state._cs),
-            ds: Segment::from(&self.state._ds),
-            es: Segment::from(&self.state._es),
-            fs: Segment::from(&self.state._fs),
-            gs: Segment::from(&self.state._gs),
-            ss: Segment::from(&self.state._ss),
-            tr: Segment::from(&self.state._tr),
-            ldt: Segment::from(&self.state._ldt),
-            gdt: DescriptorTable::from(&self.state._gdt),
-            idt: DescriptorTable::from(&self.state._idt),
-            cr0: self.state._cr0,
-            cr2: self.state._cr2,
-            cr3: self.state._cr3,
-            cr4: self.state._cr4,
+            cs: Segment::from(&self.state.cs),
+            ds: Segment::from(&self.state.ds),
+            es: Segment::from(&self.state.es),
+            fs: Segment::from(&self.state.fs),
+            gs: Segment::from(&self.state.gs),
+            ss: Segment::from(&self.state.ss),
+            tr: Segment::from(&self.state.tr),
+            ldt: Segment::from(&self.state.ldt),
+            gdt: DescriptorTable::from(&self.state.gdt),
+            idt: DescriptorTable::from(&self.state.idt),
+            cr0: self.state.cr0,
+            cr2: self.state.cr2,
+            cr3: self.state.cr3,
+            cr4: self.state.cr4,
             // HAXM does not support setting cr8
             cr8: 0,
-            efer: self.state._efer as u64,
+            efer: self.state.efer as u64,
         }
     }
 
     fn set_sregs(&mut self, sregs: &Sregs) {
-        self.state._cs = segment_desc_t::from(&sregs.cs);
-        self.state._ds = segment_desc_t::from(&sregs.ds);
-        self.state._es = segment_desc_t::from(&sregs.es);
-        self.state._fs = segment_desc_t::from(&sregs.fs);
-        self.state._gs = segment_desc_t::from(&sregs.gs);
-        self.state._ss = segment_desc_t::from(&sregs.ss);
-        self.state._tr = segment_desc_t::from(&sregs.tr);
-        self.state._ldt = segment_desc_t::from(&sregs.ldt);
-        self.state._gdt = segment_desc_t::from(&sregs.gdt);
-        self.state._idt = segment_desc_t::from(&sregs.idt);
-        self.state._cr0 = sregs.cr0;
-        self.state._cr2 = sregs.cr2;
-        self.state._cr3 = sregs.cr3;
-        self.state._cr4 = sregs.cr4;
-        self.state._efer = sregs.efer as u32;
+        self.state.cs = segment_desc_t::from(&sregs.cs);
+        self.state.ds = segment_desc_t::from(&sregs.ds);
+        self.state.es = segment_desc_t::from(&sregs.es);
+        self.state.fs = segment_desc_t::from(&sregs.fs);
+        self.state.gs = segment_desc_t::from(&sregs.gs);
+        self.state.ss = segment_desc_t::from(&sregs.ss);
+        self.state.tr = segment_desc_t::from(&sregs.tr);
+        self.state.ldt = segment_desc_t::from(&sregs.ldt);
+        self.state.gdt = segment_desc_t::from(&sregs.gdt);
+        self.state.idt = segment_desc_t::from(&sregs.idt);
+        self.state.cr0 = sregs.cr0;
+        self.state.cr2 = sregs.cr2;
+        self.state.cr3 = sregs.cr3;
+        self.state.cr4 = sregs.cr4;
+        self.state.efer = sregs.efer as u32;
     }
 
     fn get_debugregs(&self) -> DebugRegs {
         DebugRegs {
             db: [
-                self.state._dr0,
-                self.state._dr1,
-                self.state._dr2,
-                self.state._dr3,
+                self.state.dr0,
+                self.state.dr1,
+                self.state.dr2,
+                self.state.dr3,
             ],
-            dr6: self.state._dr6,
-            dr7: self.state._dr7,
+            dr6: self.state.dr6,
+            dr7: self.state.dr7,
         }
     }
 
     fn set_debugregs(&mut self, debugregs: &DebugRegs) {
-        self.state._dr0 = debugregs.db[0];
-        self.state._dr1 = debugregs.db[1];
-        self.state._dr2 = debugregs.db[2];
-        self.state._dr3 = debugregs.db[3];
-        self.state._dr6 = debugregs.dr6;
-        self.state._dr7 = debugregs.dr7;
+        self.state.dr0 = debugregs.db[0];
+        self.state.dr1 = debugregs.db[1];
+        self.state.dr2 = debugregs.db[2];
+        self.state.dr3 = debugregs.db[3];
+        self.state.dr6 = debugregs.dr6;
+        self.state.dr7 = debugregs.dr7;
     }
 }
 
@@ -784,7 +780,7 @@ impl From<&segment_desc_t> for Segment {
         unsafe {
             Segment {
                 base: item.base,
-                limit: item.limit,
+                limit_bytes: item.limit,
                 selector: item.selector,
                 type_: item.__bindgen_anon_1.__bindgen_anon_1.type_() as u8,
                 present: item.__bindgen_anon_1.__bindgen_anon_1.present() as u8,
@@ -803,7 +799,7 @@ impl From<&Segment> for segment_desc_t {
     fn from(item: &Segment) -> Self {
         let mut segment = segment_desc_t {
             base: item.base,
-            limit: item.limit,
+            limit: item.limit_bytes,
             selector: item.selector,
             ..Default::default()
         };
@@ -871,7 +867,7 @@ impl From<&DescriptorTable> for segment_desc_t {
 impl From<&fx_layout> for Fpu {
     fn from(item: &fx_layout) -> Self {
         let mut fpu = Fpu {
-            fpr: item.st_mm,
+            fpr: FpuReg::from_16byte_arrays(&item.st_mm),
             fcw: item.fcw,
             fsw: item.fsw,
             ftwx: item.ftw,
@@ -907,7 +903,7 @@ impl From<&Fpu> for fx_layout {
             },
             mxcsr: item.mxcsr,
             mxcsr_mask: 0,
-            st_mm: item.fpr,
+            st_mm: FpuReg::to_16byte_arrays(&item.fpr),
             mmx_1: [[0; 16]; 8],
             mmx_2: [[0; 16]; 8],
             pad: [0; 96],
@@ -965,6 +961,7 @@ mod tests {
     const EFER_SCE: u64 = 0x00000001;
     const EFER_LME: u64 = 0x00000100;
     const EFER_LMA: u64 = 0x00000400;
+    const EFER_SVME: u64 = 1 << 12;
 
     // CR0 bits
     const CR0_PG: u64 = 1 << 31;
@@ -1047,7 +1044,7 @@ mod tests {
 
         let mut sregs = vcpu.get_sregs().expect("failed to get sregs");
         // Initial value should be 0
-        assert_eq!(sregs.efer, 0);
+        assert_eq!(sregs.efer & !EFER_SVME, 0);
 
         // Enable and activate long mode
         sregs.efer = EFER_LMA | EFER_LME;
@@ -1057,11 +1054,11 @@ mod tests {
 
         // Verify that setting stuck
         let sregs = vcpu.get_sregs().expect("failed to get sregs");
-        assert_eq!(sregs.efer, EFER_LMA | EFER_LME);
+        assert_eq!(sregs.efer & !EFER_SVME, EFER_LMA | EFER_LME);
 
         // IA32_EFER register value should match
         let efer = vcpu.get_msr(IA32_EFER).expect("failed to get msr");
-        assert_eq!(efer, EFER_LMA | EFER_LME);
+        assert_eq!(efer & !EFER_SVME, EFER_LMA | EFER_LME);
 
         // Enable SCE via set_msrs
         vcpu.set_msr(IA32_EFER, efer | EFER_SCE)
@@ -1069,8 +1066,8 @@ mod tests {
 
         // Verify that setting stuck
         let sregs = vcpu.get_sregs().expect("failed to get sregs");
-        assert_eq!(sregs.efer, EFER_SCE | EFER_LME | EFER_LMA);
+        assert_eq!(sregs.efer & !EFER_SVME, EFER_SCE | EFER_LME | EFER_LMA);
         let new_efer = vcpu.get_msr(IA32_EFER).expect("failed to get msrs");
-        assert_eq!(new_efer, EFER_SCE | EFER_LME | EFER_LMA);
+        assert_eq!(new_efer & !EFER_SVME, EFER_SCE | EFER_LME | EFER_LMA);
     }
 }
diff --git a/hypervisor/src/haxm/vm.rs b/hypervisor/src/haxm/vm.rs
index def8d054d..d82a6d002 100644
--- a/hypervisor/src/haxm/vm.rs
+++ b/hypervisor/src/haxm/vm.rs
@@ -78,7 +78,7 @@ impl HaxmVm {
         // SAFETY:
         // Safe because we know descriptor is a real haxm descriptor as this module is the only
         // one that can make Haxm objects.
-        let ret = unsafe { ioctl_with_mut_ref(haxm, HAX_IOCTL_CREATE_VM(), &mut vm_id) };
+        let ret = unsafe { ioctl_with_mut_ref(haxm, HAX_IOCTL_CREATE_VM, &mut vm_id) };
         if ret != 0 {
             return errno_result();
         }
@@ -116,12 +116,19 @@ impl HaxmVm {
         let ret =
             // SAFETY:
             // Safe because we know that our file is a VM fd and we verify the return result.
-            unsafe { ioctl_with_mut_ref(&self.haxm, HAX_IOCTL_CAPABILITY(), &mut capability_info) };
+            unsafe { ioctl_with_mut_ref(&self.haxm, HAX_IOCTL_CAPABILITY, &mut capability_info) };
 
         if ret != 0 {
             return false;
         }
 
+        // If wstatus is zero, HAXM is not usable.
+        // In this case, the winfo bits indicate why, rather than communicating capability
+        // information.
+        if capability_info.wstatus == 0 {
+            return false;
+        }
+
         (cap & capability_info.winfo as u32) != 0
     }
 
@@ -144,7 +151,7 @@ impl HaxmVm {
 
             // SAFETY:
             // Safe because we know that our file is a VM fd and we verify the return result.
-            let ret = unsafe { ioctl_with_ref(self, HAX_VM_IOCTL_REGISTER_LOG_FILE(), &log_file) };
+            let ret = unsafe { ioctl_with_ref(self, HAX_VM_IOCTL_REGISTER_LOG_FILE, &log_file) };
 
             if ret != 0 {
                 return errno_result();
@@ -194,7 +201,7 @@ unsafe fn set_user_memory_region(
 
     // SAFETY:
     // Safe because we know that our file is a VM fd and we verify the return result.
-    let ret = ioctl_with_ref(descriptor, HAX_VM_IOCTL_SET_RAM2(), &ram_info);
+    let ret = ioctl_with_ref(descriptor, HAX_VM_IOCTL_SET_RAM2, &ram_info);
     if ret != 0 {
         return errno_result();
     }
@@ -439,7 +446,7 @@ impl VmX86_64 for HaxmVm {
     fn create_vcpu(&self, id: usize) -> Result<Box<dyn VcpuX86_64>> {
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let fd = unsafe { ioctl_with_ref(self, HAX_VM_IOCTL_VCPU_CREATE(), &(id as u32)) };
+        let fd = unsafe { ioctl_with_ref(self, HAX_VM_IOCTL_VCPU_CREATE, &(id as u32)) };
         if fd < 0 {
             return errno_result();
         }
@@ -452,7 +459,7 @@ impl VmX86_64 for HaxmVm {
         // SAFETY:
         // Safe because we created tunnel_info and we check the return code for errors
         let ret = unsafe {
-            ioctl_with_mut_ref(&descriptor, HAX_VCPU_IOCTL_SETUP_TUNNEL(), &mut tunnel_info)
+            ioctl_with_mut_ref(&descriptor, HAX_VCPU_IOCTL_SETUP_TUNNEL, &mut tunnel_info)
         };
 
         if ret != 0 {
diff --git a/hypervisor/src/kvm/aarch64.rs b/hypervisor/src/kvm/aarch64.rs
index 5d1a2b8ed..3c06085f9 100644
--- a/hypervisor/src/kvm/aarch64.rs
+++ b/hypervisor/src/kvm/aarch64.rs
@@ -8,7 +8,9 @@
 
 use std::collections::BTreeMap;
 use std::convert::TryFrom;
+use std::mem::offset_of;
 
+use anyhow::Context;
 use base::errno_result;
 use base::error;
 use base::ioctl_with_mut_ref;
@@ -18,23 +20,14 @@ use base::warn;
 use base::Error;
 use base::Result;
 use cros_fdt::Fdt;
-#[cfg(feature = "gdb")]
-use gdbstub::arch::Arch;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::aarch64::reg::id::AArch64RegId;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::aarch64::AArch64 as GdbArch;
+use data_model::vec_with_array_field;
 use kvm_sys::*;
 use libc::EINVAL;
-#[cfg(feature = "gdb")]
-use libc::ENOBUFS;
-#[cfg(feature = "gdb")]
-use libc::ENOENT;
 use libc::ENOMEM;
 use libc::ENOTSUP;
-#[cfg(feature = "gdb")]
-use libc::ENOTUNIQ;
 use libc::ENXIO;
+use serde::Deserialize;
+use serde::Serialize;
 use vm_memory::GuestAddress;
 
 use super::Config;
@@ -42,6 +35,7 @@ use super::Kvm;
 use super::KvmCap;
 use super::KvmVcpu;
 use super::KvmVm;
+use crate::AArch64SysRegId;
 use crate::ClockState;
 use crate::DeviceKind;
 use crate::Hypervisor;
@@ -54,6 +48,7 @@ use crate::VcpuFeature;
 use crate::VcpuRegAArch64;
 use crate::VmAArch64;
 use crate::VmCap;
+use crate::AARCH64_MAX_REG_COUNT;
 use crate::PSCI_0_2;
 
 impl Kvm {
@@ -65,7 +60,7 @@ impl Kvm {
         // SAFETY:
         // Safe because we know self is a real kvm fd
         let ipa_size = match unsafe {
-            ioctl_with_val(self, KVM_CHECK_EXTENSION(), KVM_CAP_ARM_VM_IPA_SIZE.into())
+            ioctl_with_val(self, KVM_CHECK_EXTENSION, KVM_CAP_ARM_VM_IPA_SIZE.into())
         } {
             // Not supported? Use 0 as the machine type, which implies 40bit IPA
             ret if ret < 0 => 0,
@@ -84,8 +79,7 @@ impl Kvm {
     pub fn get_guest_phys_addr_bits(&self) -> u8 {
         // SAFETY:
         // Safe because we know self is a real kvm fd
-        match unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION(), KVM_CAP_ARM_VM_IPA_SIZE.into()) }
-        {
+        match unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION, KVM_CAP_ARM_VM_IPA_SIZE.into()) } {
             // Default physical address size is 40 bits if the extension is not supported.
             ret if ret <= 0 => 40,
             ipa => ipa as u8,
@@ -232,6 +226,19 @@ impl VmAArch64 for KvmVm {
     ) -> Result<()> {
         Ok(())
     }
+
+    fn set_counter_offset(&self, offset: u64) -> Result<()> {
+        let off = kvm_arm_counter_offset {
+            counter_offset: offset,
+            reserved: 0,
+        };
+        // SAFETY: self.vm is a valid KVM fd
+        let ret = unsafe { ioctl_with_ref(&self.vm, KVM_ARM_SET_COUNTER_OFFSET, &off) };
+        if ret != 0 {
+            return errno_result();
+        }
+        Ok(())
+    }
 }
 
 impl KvmVcpu {
@@ -253,6 +260,27 @@ impl KvmVcpu {
         Ok(VcpuExit::SystemEventReset)
     }
 
+    fn kvm_reg_id(&self, reg: VcpuRegAArch64) -> Result<KvmVcpuRegister> {
+        match reg {
+            VcpuRegAArch64::X(n @ 0..=30) => Ok(KvmVcpuRegister::X(n)),
+            VcpuRegAArch64::Sp => Ok(KvmVcpuRegister::Sp),
+            VcpuRegAArch64::Pc => Ok(KvmVcpuRegister::Pc),
+            VcpuRegAArch64::Pstate => Ok(KvmVcpuRegister::Pstate),
+            // Special case for multiplexed KVM registers
+            VcpuRegAArch64::System(AArch64SysRegId::CCSIDR_EL1) => {
+                let csselr =
+                    self.get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::CSSELR_EL1))?;
+                Ok(KvmVcpuRegister::Ccsidr(csselr as u8))
+            }
+            VcpuRegAArch64::System(sysreg) => Ok(KvmVcpuRegister::System(sysreg)),
+            _ => Err(Error::new(EINVAL)),
+        }
+    }
+
+    fn set_one_kvm_reg_u32(&self, kvm_reg_id: KvmVcpuRegister, data: u32) -> Result<()> {
+        self.set_one_kvm_reg(kvm_reg_id, data.to_ne_bytes().as_slice())
+    }
+
     fn set_one_kvm_reg_u64(&self, kvm_reg_id: KvmVcpuRegister, data: u64) -> Result<()> {
         self.set_one_kvm_reg(kvm_reg_id, data.to_ne_bytes().as_slice())
     }
@@ -262,8 +290,10 @@ impl KvmVcpu {
     }
 
     fn set_one_kvm_reg(&self, kvm_reg_id: KvmVcpuRegister, data: &[u8]) -> Result<()> {
+        assert_eq!(kvm_reg_id.size(), data.len());
+        let id: u64 = kvm_reg_id.into();
         let onereg = kvm_one_reg {
-            id: kvm_reg_id.into(),
+            id,
             addr: (data.as_ptr() as usize)
                 .try_into()
                 .expect("can't represent usize as u64"),
@@ -271,7 +301,7 @@ impl KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_ONE_REG(), &onereg) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_ONE_REG, &onereg) };
         if ret == 0 {
             Ok(())
         } else {
@@ -279,6 +309,12 @@ impl KvmVcpu {
         }
     }
 
+    fn get_one_kvm_reg_u32(&self, kvm_reg_id: KvmVcpuRegister) -> Result<u32> {
+        let mut bytes = 0u32.to_ne_bytes();
+        self.get_one_kvm_reg(kvm_reg_id, bytes.as_mut_slice())?;
+        Ok(u32::from_ne_bytes(bytes))
+    }
+
     fn get_one_kvm_reg_u64(&self, kvm_reg_id: KvmVcpuRegister) -> Result<u64> {
         let mut bytes = 0u64.to_ne_bytes();
         self.get_one_kvm_reg(kvm_reg_id, bytes.as_mut_slice())?;
@@ -292,8 +328,10 @@ impl KvmVcpu {
     }
 
     fn get_one_kvm_reg(&self, kvm_reg_id: KvmVcpuRegister, data: &mut [u8]) -> Result<()> {
+        assert_eq!(kvm_reg_id.size(), data.len());
+        let id: u64 = kvm_reg_id.into();
         let onereg = kvm_one_reg {
-            id: kvm_reg_id.into(),
+            id,
             addr: (data.as_mut_ptr() as usize)
                 .try_into()
                 .expect("can't represent usize as u64"),
@@ -302,48 +340,43 @@ impl KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, KVM_GET_ONE_REG(), &onereg) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_GET_ONE_REG, &onereg) };
         if ret == 0 {
             Ok(())
         } else {
             errno_result()
         }
     }
-}
-
-#[cfg(feature = "gdb")]
-impl KvmVcpu {
-    fn set_one_kvm_reg_u32(&self, kvm_reg_id: KvmVcpuRegister, data: u32) -> Result<()> {
-        self.set_one_kvm_reg(kvm_reg_id, data.to_ne_bytes().as_slice())
-    }
 
-    fn get_one_kvm_reg_u32(&self, kvm_reg_id: KvmVcpuRegister) -> Result<u32> {
-        let mut bytes = 0u32.to_ne_bytes();
-        self.get_one_kvm_reg(kvm_reg_id, bytes.as_mut_slice())?;
-        Ok(u32::from_ne_bytes(bytes))
+    #[inline]
+    pub(crate) fn handle_vm_exit_arch(&self, _run: &mut kvm_run) -> Option<VcpuExit> {
+        // No aarch64-specific exits (for now)
+        None
     }
 
-    /// Retrieves the value of the currently active "version" of a multiplexed registers.
-    fn demux_register(&self, reg: &<GdbArch as Arch>::RegId) -> Result<Option<KvmVcpuRegister>> {
-        match *reg {
-            AArch64RegId::CCSIDR_EL1 => {
-                let csselr = KvmVcpuRegister::try_from(AArch64RegId::CSSELR_EL1)
-                    .expect("can't map AArch64RegId::CSSELR_EL1 to KvmVcpuRegister");
-                if let Ok(csselr) = self.get_one_kvm_reg_u64(csselr) {
-                    Ok(Some(KvmVcpuRegister::Ccsidr(csselr as u8)))
-                } else {
-                    Ok(None)
-                }
-            }
-            _ => {
-                error!("Register {:?} is not multiplexed", reg);
-                Err(Error::new(EINVAL))
-            }
+    fn get_reg_list(&self) -> Result<Vec<u64>> {
+        let mut kvm_reg_list = vec_with_array_field::<kvm_reg_list, u64>(AARCH64_MAX_REG_COUNT);
+        kvm_reg_list[0].n = AARCH64_MAX_REG_COUNT as u64;
+        let ret =
+            // SAFETY:
+            // We trust the kernel not to read/write past the end of kvm_reg_list struct.
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_REG_LIST, &mut kvm_reg_list[0]) };
+        if ret < 0 {
+            return errno_result();
         }
+        let n = kvm_reg_list[0].n;
+        assert!(
+            n <= AARCH64_MAX_REG_COUNT as u64,
+            "Get reg list returned more registers than possible"
+        );
+        // SAFETY:
+        // Mapping the unsized array to a slice is unsafe because the length isn't known.
+        // Providing the length used to create the struct guarantees the entire slice is valid.
+        let reg_list: &[u64] = unsafe { kvm_reg_list[0].reg.as_slice(n as usize) };
+        Ok(reg_list.to_vec())
     }
 }
 
-#[allow(dead_code)]
 /// KVM registers as used by the `GET_ONE_REG`/`SET_ONE_REG` ioctl API
 ///
 /// These variants represent the registers as exposed by KVM which must be different from
@@ -351,6 +384,7 @@ impl KvmVcpu {
 /// pseudo-registers (`Firmware`) and multiplexed registers (`Ccsidr`).
 ///
 /// See https://docs.kernel.org/virt/kvm/api.html for more details.
+#[derive(Debug, Copy, Clone, Serialize, Deserialize)]
 pub enum KvmVcpuRegister {
     /// General Purpose Registers X0-X30
     X(u8),
@@ -360,29 +394,17 @@ pub enum KvmVcpuRegister {
     Pc,
     /// Processor State
     Pstate,
-    /// Stack Pointer (EL1)
-    SpEl1,
-    /// Exception Link Register (EL1)
-    ElrEl1,
-    /// Saved Program Status Register (EL1, abt, und, irq, fiq)
-    Spsr(u8),
     /// FP & SIMD Registers V0-V31
     V(u8),
-    /// Floating-point Status Register
-    Fpsr,
-    /// Floating-point Control Register
-    Fpcr,
     /// KVM Firmware Pseudo-Registers
     Firmware(u16),
-    /// Generic System Registers by (Op0, Op1, CRn, CRm, Op2)
-    System(u16),
+    /// System Registers
+    System(AArch64SysRegId),
     /// CCSIDR_EL1 Demultiplexed by CSSELR_EL1
     Ccsidr(u8),
 }
 
 impl KvmVcpuRegister {
-    pub const MPIDR_EL1: Self = Self::from_encoding(0b11, 0b000, 0b0000, 0b0000, 0b101);
-
     // Firmware pseudo-registers are part of the ARM KVM interface:
     //     https://docs.kernel.org/virt/kvm/arm/hypercalls.html
     pub const PSCI_VERSION: Self = Self::Firmware(0);
@@ -390,14 +412,24 @@ impl KvmVcpuRegister {
     pub const SMCCC_ARCH_WORKAROUND_2: Self = Self::Firmware(2);
     pub const SMCCC_ARCH_WORKAROUND_3: Self = Self::Firmware(3);
 
-    const fn from_encoding(op0: u8, op1: u8, crn: u8, crm: u8, op2: u8) -> Self {
-        let op0 = (op0 as u16 & 0b11) << 14;
-        let op1 = (op1 as u16 & 0b111) << 11;
-        let crn = (crn as u16 & 0b1111) << 7;
-        let crm = (crm as u16 & 0b1111) << 3;
-        let op2 = op2 as u16 & 0b111;
-
-        Self::System(op0 | op1 | crn | crm | op2)
+    /// Size of this register in bytes.
+    pub fn size(&self) -> usize {
+        let kvm_reg = u64::from(*self);
+        let size_field = kvm_reg & KVM_REG_SIZE_MASK;
+        const REG_SIZE_U8: u64 = KVM_REG_SIZE_U8 as u64; // cast from bindgen's u32 to u64
+        match size_field {
+            REG_SIZE_U8 => 1,
+            KVM_REG_SIZE_U16 => 2,
+            KVM_REG_SIZE_U32 => 4,
+            KVM_REG_SIZE_U64 => 8,
+            KVM_REG_SIZE_U128 => 16,
+            KVM_REG_SIZE_U256 => 32,
+            KVM_REG_SIZE_U512 => 64,
+            KVM_REG_SIZE_U1024 => 128,
+            KVM_REG_SIZE_U2048 => 256,
+            // `From<KvmVcpuRegister> for u64` should always include a valid size.
+            _ => panic!("invalid size field {}", size_field),
+        }
     }
 }
 
@@ -420,15 +452,17 @@ impl From<KvmVcpuRegister> for u64 {
             kvm_regs_reg(KVM_REG_SIZE_U64, offset)
         }
 
+        fn spsr_reg(spsr_reg: u32) -> u64 {
+            let n = std::mem::size_of::<u64>() * (spsr_reg as usize);
+            kvm_reg(offset_of!(kvm_regs, spsr) + n)
+        }
+
         fn user_pt_reg(offset: usize) -> u64 {
-            kvm_regs_reg(
-                KVM_REG_SIZE_U64,
-                memoffset::offset_of!(kvm_regs, regs) + offset,
-            )
+            kvm_regs_reg(KVM_REG_SIZE_U64, offset_of!(kvm_regs, regs) + offset)
         }
 
         fn user_fpsimd_state_reg(size: u64, offset: usize) -> u64 {
-            kvm_regs_reg(size, memoffset::offset_of!(kvm_regs, fp_regs) + offset)
+            kvm_regs_reg(size, offset_of!(kvm_regs, fp_regs) + offset)
         }
 
         const fn reg_u64(kind: u64, fields: u64) -> u64 {
@@ -447,113 +481,53 @@ impl From<KvmVcpuRegister> for u64 {
             KvmVcpuRegister::X(n @ 0..=30) => {
                 let n = std::mem::size_of::<u64>() * (n as usize);
 
-                user_pt_reg(memoffset::offset_of!(user_pt_regs, regs) + n)
+                user_pt_reg(offset_of!(user_pt_regs, regs) + n)
             }
             KvmVcpuRegister::X(n) => unreachable!("invalid KvmVcpuRegister Xn index: {n}"),
-            KvmVcpuRegister::Sp => user_pt_reg(memoffset::offset_of!(user_pt_regs, sp)),
-            KvmVcpuRegister::Pc => user_pt_reg(memoffset::offset_of!(user_pt_regs, pc)),
-            KvmVcpuRegister::Pstate => user_pt_reg(memoffset::offset_of!(user_pt_regs, pstate)),
-            KvmVcpuRegister::SpEl1 => kvm_reg(memoffset::offset_of!(kvm_regs, sp_el1)),
-            KvmVcpuRegister::ElrEl1 => kvm_reg(memoffset::offset_of!(kvm_regs, elr_el1)),
-            KvmVcpuRegister::Spsr(n @ 0..=4) => {
-                let n = std::mem::size_of::<u64>() * (n as usize);
-
-                kvm_reg(memoffset::offset_of!(kvm_regs, spsr) + n)
-            }
-            KvmVcpuRegister::Spsr(n) => unreachable!("invalid KvmVcpuRegister Spsr index: {n}"),
+            KvmVcpuRegister::Sp => user_pt_reg(offset_of!(user_pt_regs, sp)),
+            KvmVcpuRegister::Pc => user_pt_reg(offset_of!(user_pt_regs, pc)),
+            KvmVcpuRegister::Pstate => user_pt_reg(offset_of!(user_pt_regs, pstate)),
             KvmVcpuRegister::V(n @ 0..=31) => {
                 let n = std::mem::size_of::<u128>() * (n as usize);
 
-                user_fpsimd_state_reg(
-                    KVM_REG_SIZE_U128,
-                    memoffset::offset_of!(user_fpsimd_state, vregs) + n,
-                )
+                user_fpsimd_state_reg(KVM_REG_SIZE_U128, offset_of!(user_fpsimd_state, vregs) + n)
             }
             KvmVcpuRegister::V(n) => unreachable!("invalid KvmVcpuRegister Vn index: {n}"),
-            KvmVcpuRegister::Fpsr => user_fpsimd_state_reg(
-                KVM_REG_SIZE_U32,
-                memoffset::offset_of!(user_fpsimd_state, fpsr),
+            KvmVcpuRegister::System(AArch64SysRegId::FPSR) => {
+                user_fpsimd_state_reg(KVM_REG_SIZE_U32, offset_of!(user_fpsimd_state, fpsr))
+            }
+            KvmVcpuRegister::System(AArch64SysRegId::FPCR) => {
+                user_fpsimd_state_reg(KVM_REG_SIZE_U32, offset_of!(user_fpsimd_state, fpcr))
+            }
+            KvmVcpuRegister::System(AArch64SysRegId::SPSR_EL1) => spsr_reg(KVM_SPSR_EL1),
+            KvmVcpuRegister::System(AArch64SysRegId::SPSR_abt) => spsr_reg(KVM_SPSR_ABT),
+            KvmVcpuRegister::System(AArch64SysRegId::SPSR_und) => spsr_reg(KVM_SPSR_UND),
+            KvmVcpuRegister::System(AArch64SysRegId::SPSR_irq) => spsr_reg(KVM_SPSR_IRQ),
+            KvmVcpuRegister::System(AArch64SysRegId::SPSR_fiq) => spsr_reg(KVM_SPSR_FIQ),
+            KvmVcpuRegister::System(AArch64SysRegId::SP_EL1) => {
+                kvm_reg(offset_of!(kvm_regs, sp_el1))
+            }
+            KvmVcpuRegister::System(AArch64SysRegId::ELR_EL1) => {
+                kvm_reg(offset_of!(kvm_regs, elr_el1))
+            }
+            // The KVM API accidentally swapped CNTV_CVAL_EL0 and CNTVCT_EL0.
+            KvmVcpuRegister::System(AArch64SysRegId::CNTV_CVAL_EL0) => reg_u64(
+                KVM_REG_ARM64_SYSREG.into(),
+                AArch64SysRegId::CNTVCT_EL0.encoded().into(),
             ),
-            KvmVcpuRegister::Fpcr => user_fpsimd_state_reg(
-                KVM_REG_SIZE_U32,
-                memoffset::offset_of!(user_fpsimd_state, fpcr),
+            KvmVcpuRegister::System(AArch64SysRegId::CNTVCT_EL0) => reg_u64(
+                KVM_REG_ARM64_SYSREG.into(),
+                AArch64SysRegId::CNTV_CVAL_EL0.encoded().into(),
             ),
+            KvmVcpuRegister::System(sysreg) => {
+                reg_u64(KVM_REG_ARM64_SYSREG.into(), sysreg.encoded().into())
+            }
             KvmVcpuRegister::Firmware(n) => reg_u64(KVM_REG_ARM_FW.into(), n.into()),
-            KvmVcpuRegister::System(n) => reg_u64(KVM_REG_ARM64_SYSREG.into(), n.into()),
             KvmVcpuRegister::Ccsidr(n) => demux_reg(KVM_REG_SIZE_U32, 0, n.into()),
         }
     }
 }
 
-#[cfg(feature = "gdb")]
-/// Returns whether KVM matches more than one KVM_GET_ONE_REG target to the given arch register.
-const fn kvm_multiplexes(reg: &<GdbArch as Arch>::RegId) -> bool {
-    matches!(*reg, AArch64RegId::CCSIDR_EL1)
-}
-
-#[cfg(feature = "gdb")]
-impl TryFrom<AArch64RegId> for KvmVcpuRegister {
-    type Error = Error;
-
-    fn try_from(reg: <GdbArch as Arch>::RegId) -> std::result::Result<Self, Self::Error> {
-        if kvm_multiplexes(&reg) {
-            // Many-to-one mapping between the register and its KVM_GET_ONE_REG values.
-            error!(
-                "Can't map multiplexed register {:?} to unique KVM value",
-                reg
-            );
-            return Err(Error::new(ENOTUNIQ));
-        }
-
-        let kvm_reg = match reg {
-            AArch64RegId::X(n @ 0..=30) => Self::X(n),
-            AArch64RegId::X(n) => unreachable!("invalid AArch64RegId Xn index: {n}"),
-            AArch64RegId::V(n @ 0..=31) => Self::V(n),
-            AArch64RegId::V(n) => unreachable!("invalid AArch64RegId Vn index: {n}"),
-            AArch64RegId::Sp => Self::Sp,
-            AArch64RegId::Pc => Self::Pc,
-            AArch64RegId::Pstate => Self::Pstate,
-            AArch64RegId::ELR_EL1 => Self::ElrEl1,
-            AArch64RegId::SP_EL1 => Self::SpEl1,
-            AArch64RegId::SPSR_EL1 => Self::Spsr(KVM_SPSR_EL1 as u8),
-            AArch64RegId::SPSR_ABT => Self::Spsr(KVM_SPSR_ABT as u8),
-            AArch64RegId::SPSR_UND => Self::Spsr(KVM_SPSR_UND as u8),
-            AArch64RegId::SPSR_IRQ => Self::Spsr(KVM_SPSR_IRQ as u8),
-            AArch64RegId::SPSR_FIQ => Self::Spsr(KVM_SPSR_FIQ as u8),
-            AArch64RegId::FPSR => Self::Fpsr,
-            AArch64RegId::FPCR => Self::Fpcr,
-            // The KVM API accidentally swapped CNTV_CVAL_EL0 and CNTVCT_EL0
-            AArch64RegId::CNTV_CVAL_EL0 => match AArch64RegId::CNTVCT_EL0 {
-                AArch64RegId::System(op) => Self::System(op),
-                _ => unreachable!("AArch64RegId::CNTVCT_EL0 not a AArch64RegId::System"),
-            },
-            AArch64RegId::CNTVCT_EL0 => match AArch64RegId::CNTV_CVAL_EL0 {
-                AArch64RegId::System(op) => Self::System(op),
-                _ => unreachable!("AArch64RegId::CNTV_CVAL_EL0 not a AArch64RegId::System"),
-            },
-            AArch64RegId::System(op) => Self::System(op),
-            _ => {
-                error!("Unexpected AArch64RegId: {:?}", reg);
-                return Err(Error::new(EINVAL));
-            }
-        };
-
-        Ok(kvm_reg)
-    }
-}
-
-impl From<VcpuRegAArch64> for KvmVcpuRegister {
-    fn from(reg: VcpuRegAArch64) -> Self {
-        match reg {
-            VcpuRegAArch64::X(n @ 0..=30) => Self::X(n),
-            VcpuRegAArch64::X(n) => unreachable!("invalid VcpuRegAArch64 index: {n}"),
-            VcpuRegAArch64::Sp => Self::Sp,
-            VcpuRegAArch64::Pc => Self::Pc,
-            VcpuRegAArch64::Pstate => Self::Pstate,
-        }
-    }
-}
-
 impl VcpuAArch64 for KvmVcpu {
     fn init(&self, features: &[VcpuFeature]) -> Result<()> {
         let mut kvi = kvm_vcpu_init {
@@ -563,7 +537,7 @@ impl VcpuAArch64 for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will write exactly the size
         // of the struct.
-        let ret = unsafe { ioctl_with_mut_ref(&self.vm, KVM_ARM_PREFERRED_TARGET(), &mut kvi) };
+        let ret = unsafe { ioctl_with_mut_ref(&self.vm, KVM_ARM_PREFERRED_TARGET, &mut kvi) };
         if ret != 0 {
             return errno_result();
         }
@@ -580,7 +554,7 @@ impl VcpuAArch64 for KvmVcpu {
         let check_extension = |ext: u32| -> bool {
             // SAFETY:
             // Safe because we know self.vm is a real kvm fd
-            unsafe { ioctl_with_val(&self.vm, KVM_CHECK_EXTENSION(), ext.into()) == 1 }
+            unsafe { ioctl_with_val(&self.vm, KVM_CHECK_EXTENSION, ext.into()) == 1 }
         };
         if check_extension(KVM_CAP_ARM_PTRAUTH_ADDRESS)
             && check_extension(KVM_CAP_ARM_PTRAUTH_GENERIC)
@@ -592,7 +566,7 @@ impl VcpuAArch64 for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, KVM_ARM_VCPU_INIT(), &kvi) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_ARM_VCPU_INIT, &kvi) };
         if ret == 0 {
             Ok(())
         } else {
@@ -615,7 +589,7 @@ impl VcpuAArch64 for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_HAS_DEVICE_ATTR(), &irq_attr) };
+        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_HAS_DEVICE_ATTR, &irq_attr) };
         if ret < 0 {
             return errno_result();
         }
@@ -623,7 +597,7 @@ impl VcpuAArch64 for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_SET_DEVICE_ATTR(), &irq_attr) };
+        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_SET_DEVICE_ATTR, &irq_attr) };
         if ret < 0 {
             return errno_result();
         }
@@ -637,7 +611,7 @@ impl VcpuAArch64 for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_SET_DEVICE_ATTR(), &init_attr) };
+        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_SET_DEVICE_ATTR, &init_attr) };
         if ret < 0 {
             return errno_result();
         }
@@ -657,7 +631,7 @@ impl VcpuAArch64 for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_HAS_DEVICE_ATTR(), &pvtime_attr) };
+        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_HAS_DEVICE_ATTR, &pvtime_attr) };
         ret >= 0
     }
 
@@ -676,7 +650,7 @@ impl VcpuAArch64 for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_SET_DEVICE_ATTR(), &pvtime_attr) };
+        let ret = unsafe { ioctl_with_ref(self, kvm_sys::KVM_SET_DEVICE_ATTR, &pvtime_attr) };
         if ret < 0 {
             return errno_result();
         }
@@ -685,11 +659,21 @@ impl VcpuAArch64 for KvmVcpu {
     }
 
     fn set_one_reg(&self, reg_id: VcpuRegAArch64, data: u64) -> Result<()> {
-        self.set_one_kvm_reg_u64(KvmVcpuRegister::from(reg_id), data)
+        let kvm_reg = self.kvm_reg_id(reg_id)?;
+        match kvm_reg.size() {
+            4 => self.set_one_kvm_reg_u32(kvm_reg, data as u32),
+            8 => self.set_one_kvm_reg_u64(kvm_reg, data),
+            size => panic!("bad reg size {size}"),
+        }
     }
 
     fn get_one_reg(&self, reg_id: VcpuRegAArch64) -> Result<u64> {
-        self.get_one_kvm_reg_u64(KvmVcpuRegister::from(reg_id))
+        let kvm_reg = self.kvm_reg_id(reg_id)?;
+        match kvm_reg.size() {
+            4 => self.get_one_kvm_reg_u32(kvm_reg).map(u64::from),
+            8 => self.get_one_kvm_reg_u64(kvm_reg),
+            size => panic!("bad reg size {size}"),
+        }
     }
 
     fn set_vector_reg(&self, reg_num: u8, data: u128) -> Result<()> {
@@ -707,7 +691,7 @@ impl VcpuAArch64 for KvmVcpu {
     }
 
     fn get_mpidr(&self) -> Result<u64> {
-        self.get_one_kvm_reg_u64(KvmVcpuRegister::MPIDR_EL1)
+        self.get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::MPIDR_EL1))
     }
 
     fn get_psci_version(&self) -> Result<PsciVersion> {
@@ -728,14 +712,13 @@ impl VcpuAArch64 for KvmVcpu {
         }
     }
 
-    #[cfg(feature = "gdb")]
     fn get_max_hw_bps(&self) -> Result<usize> {
         // SAFETY:
         // Safe because the kernel will only return the result of the ioctl.
         let max_hw_bps = unsafe {
             ioctl_with_val(
                 &self.vm,
-                KVM_CHECK_EXTENSION(),
+                KVM_CHECK_EXTENSION,
                 KVM_CAP_GUEST_DEBUG_HW_BPS.into(),
             )
         };
@@ -747,7 +730,92 @@ impl VcpuAArch64 for KvmVcpu {
         }
     }
 
-    #[cfg(feature = "gdb")]
+    fn get_system_regs(&self) -> Result<BTreeMap<AArch64SysRegId, u64>> {
+        let reg_list = self.get_reg_list()?;
+        let cntvct_el0: u16 = AArch64SysRegId::CNTVCT_EL0.encoded();
+        let cntv_cval_el0: u16 = AArch64SysRegId::CNTV_CVAL_EL0.encoded();
+        let mut sys_regs = BTreeMap::new();
+        for reg in reg_list {
+            if (reg as u32) & KVM_REG_ARM_COPROC_MASK == KVM_REG_ARM64_SYSREG {
+                if reg as u16 == cntvct_el0 {
+                    sys_regs.insert(
+                        AArch64SysRegId::CNTV_CVAL_EL0,
+                        self.get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::CNTV_CVAL_EL0))?,
+                    );
+                } else if reg as u16 == cntv_cval_el0 {
+                    sys_regs.insert(
+                        AArch64SysRegId::CNTVCT_EL0,
+                        self.get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::CNTVCT_EL0))?,
+                    );
+                } else {
+                    sys_regs.insert(
+                        AArch64SysRegId::from_encoded((reg & 0xFFFF) as u16),
+                        self.get_one_reg(VcpuRegAArch64::System(AArch64SysRegId::from_encoded(
+                            (reg & 0xFFFF) as u16,
+                        )))?,
+                    );
+                }
+            }
+        }
+        Ok(sys_regs)
+    }
+
+    fn get_cache_info(&self) -> Result<BTreeMap<u8, u64>> {
+        const KVM_REG_CCSIDR: u64 = KVM_REG_ARM64 | KVM_REG_SIZE_U32 | (KVM_REG_ARM_DEMUX as u64);
+        const CCSIDR_INDEX_MASK: u64 = 0xFF;
+        let reg_list = self.get_reg_list()?;
+        let mut cache_info = BTreeMap::new();
+        for reg in reg_list {
+            if (reg & !CCSIDR_INDEX_MASK) == KVM_REG_CCSIDR {
+                let idx = reg as u8;
+                cache_info.insert(
+                    idx,
+                    self.get_one_kvm_reg_u32(KvmVcpuRegister::Ccsidr(idx))?
+                        .into(),
+                );
+            }
+        }
+        Ok(cache_info)
+    }
+
+    fn set_cache_info(&self, cache_info: BTreeMap<u8, u64>) -> Result<()> {
+        for (idx, val) in cache_info {
+            self.set_one_kvm_reg_u32(
+                KvmVcpuRegister::Ccsidr(idx),
+                val.try_into()
+                    .expect("trying to set a u32 register with a u64 value"),
+            )?;
+        }
+        Ok(())
+    }
+
+    fn hypervisor_specific_snapshot(&self) -> anyhow::Result<serde_json::Value> {
+        let reg_list = self.get_reg_list()?;
+        let mut firmware_regs = BTreeMap::new();
+        for reg in reg_list {
+            if (reg as u32) & KVM_REG_ARM_COPROC_MASK == KVM_REG_ARM_FW {
+                firmware_regs.insert(
+                    reg as u16,
+                    self.get_one_kvm_reg_u64(KvmVcpuRegister::Firmware(reg as u16))?,
+                );
+            }
+        }
+
+        serde_json::to_value(KvmSnapshot { firmware_regs })
+            .context("Failed to serialize KVM specific data")
+    }
+
+    fn hypervisor_specific_restore(&self, data: serde_json::Value) -> anyhow::Result<()> {
+        let deser: KvmSnapshot =
+            serde_json::from_value(data).context("Failed to deserialize KVM specific data")?;
+        // TODO: need to set firmware registers before "create_fdt" is called, earlier in the
+        // stack.
+        for (id, val) in &deser.firmware_regs {
+            self.set_one_kvm_reg_u64(KvmVcpuRegister::Firmware(*id), *val)?;
+        }
+        Ok(())
+    }
+
     #[allow(clippy::unusual_byte_groupings)]
     fn set_guest_debug(&self, addrs: &[GuestAddress], enable_singlestep: bool) -> Result<()> {
         let mut dbg = kvm_guest_debug {
@@ -786,97 +854,18 @@ impl VcpuAArch64 for KvmVcpu {
 
         // SAFETY:
         // Safe because the kernel won't read past the end of the kvm_guest_debug struct.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_GUEST_DEBUG(), &dbg) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_GUEST_DEBUG, &dbg) };
         if ret == 0 {
             Ok(())
         } else {
             errno_result()
         }
     }
+}
 
-    #[cfg(feature = "gdb")]
-    fn set_gdb_registers(&self, regs: &<GdbArch as Arch>::Registers) -> Result<()> {
-        assert!(
-            regs.x.len() == 31,
-            "unexpected number of Xn general purpose registers"
-        );
-        for (i, reg) in regs.x.iter().enumerate() {
-            let n = u8::try_from(i).expect("invalid Xn general purpose register index");
-            self.set_one_kvm_reg_u64(KvmVcpuRegister::X(n), *reg)?;
-        }
-        self.set_one_kvm_reg_u64(KvmVcpuRegister::Sp, regs.sp)?;
-        self.set_one_kvm_reg_u64(KvmVcpuRegister::Pc, regs.pc)?;
-        // GDB gives a 32-bit value for "CPSR" but KVM wants a 64-bit Pstate.
-        let pstate = self.get_one_kvm_reg_u64(KvmVcpuRegister::Pstate)?;
-        let pstate = (pstate & 0xffff_ffff_0000_0000) | (regs.cpsr as u64);
-        self.set_one_kvm_reg_u64(KvmVcpuRegister::Pstate, pstate)?;
-        for (i, reg) in regs.v.iter().enumerate() {
-            let n = u8::try_from(i).expect("invalid Vn general purpose register index");
-            self.set_vector_reg(n, *reg)?;
-        }
-        self.set_one_kvm_reg_u32(KvmVcpuRegister::Fpcr, regs.fpcr)?;
-        self.set_one_kvm_reg_u32(KvmVcpuRegister::Fpsr, regs.fpsr)?;
-
-        Ok(())
-    }
-
-    #[cfg(feature = "gdb")]
-    fn get_gdb_registers(&self, regs: &mut <GdbArch as Arch>::Registers) -> Result<()> {
-        assert!(
-            regs.x.len() == 31,
-            "unexpected number of Xn general purpose registers"
-        );
-        for (i, reg) in regs.x.iter_mut().enumerate() {
-            let n = u8::try_from(i).expect("invalid Xn general purpose register index");
-            *reg = self.get_one_kvm_reg_u64(KvmVcpuRegister::X(n))?;
-        }
-        regs.sp = self.get_one_kvm_reg_u64(KvmVcpuRegister::Sp)?;
-        regs.pc = self.get_one_kvm_reg_u64(KvmVcpuRegister::Pc)?;
-        // KVM gives a 64-bit value for Pstate but GDB wants a 32-bit "CPSR".
-        regs.cpsr = self.get_one_kvm_reg_u64(KvmVcpuRegister::Pstate)? as u32;
-        for (i, reg) in regs.v.iter_mut().enumerate() {
-            let n = u8::try_from(i).expect("invalid Vn general purpose register index");
-            *reg = self.get_vector_reg(n)?;
-        }
-        regs.fpcr = self.get_one_kvm_reg_u32(KvmVcpuRegister::Fpcr)?;
-        regs.fpsr = self.get_one_kvm_reg_u32(KvmVcpuRegister::Fpsr)?;
-
-        Ok(())
-    }
-
-    #[cfg(feature = "gdb")]
-    fn set_gdb_register(&self, reg: <GdbArch as Arch>::RegId, data: &[u8]) -> Result<()> {
-        let len = reg.len().ok_or(Error::new(EINVAL))?;
-        if data.len() < len {
-            return Err(Error::new(ENOBUFS));
-        }
-        let kvm_reg = if kvm_multiplexes(&reg) {
-            self.demux_register(&reg)?.ok_or(Error::new(ENOENT))?
-        } else {
-            KvmVcpuRegister::try_from(reg)?
-        };
-        self.set_one_kvm_reg(kvm_reg, &data[..len])
-    }
-
-    #[cfg(feature = "gdb")]
-    fn get_gdb_register(&self, reg: <GdbArch as Arch>::RegId, data: &mut [u8]) -> Result<usize> {
-        let len = reg.len().ok_or(Error::new(EINVAL))?;
-        if data.len() < len {
-            return Err(Error::new(ENOBUFS));
-        }
-        let kvm_reg = if !kvm_multiplexes(&reg) {
-            KvmVcpuRegister::try_from(reg)?
-        } else if let Some(r) = self.demux_register(&reg)? {
-            r
-        } else {
-            return Ok(0); // Unavailable register
-        };
-
-        self.get_one_kvm_reg(kvm_reg, &mut data[..len])
-            .and(Ok(len))
-            // ENOENT is returned when KVM is aware of the register but it is unavailable
-            .or_else(|e| if e.errno() == ENOENT { Ok(0) } else { Err(e) })
-    }
+#[derive(Debug, Serialize, Deserialize)]
+struct KvmSnapshot {
+    firmware_regs: BTreeMap<u16, u64>,
 }
 
 // This function translates an IrqSrouceChip to the kvm u32 equivalent. It has a different
@@ -893,3 +882,24 @@ pub(super) fn chip_to_kvm_chip(chip: IrqSourceChip) -> u32 {
         }
     }
 }
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn system_timer_register_mixup() {
+        // Per https://docs.kernel.org/virt/kvm/api.html ARM64 system register encoding docs,
+        // KVM_REG_ARM_TIMER_CVAL and KVM_REG_ARM_TIMER_CNT were accidentally defined backwards.
+        // Ensure the AArch64SysRegId to KvmVcpuRegister encoding maps these to the expected
+        // values.
+
+        const KVM_REG_ARM_TIMER_CVAL: u64 = 0x6030_0000_0013_DF02;
+        let cntv_cval_el0_kvm = KvmVcpuRegister::System(AArch64SysRegId::CNTV_CVAL_EL0);
+        assert_eq!(u64::from(cntv_cval_el0_kvm), KVM_REG_ARM_TIMER_CVAL);
+
+        const KVM_REG_ARM_TIMER_CNT: u64 = 0x6030_0000_0013_DF1A;
+        let cntvct_el0_kvm = KvmVcpuRegister::System(AArch64SysRegId::CNTVCT_EL0);
+        assert_eq!(u64::from(cntvct_el0_kvm), KVM_REG_ARM_TIMER_CNT);
+    }
+}
diff --git a/hypervisor/src/kvm/cap.rs b/hypervisor/src/kvm/cap.rs
new file mode 100644
index 000000000..f5c59d581
--- /dev/null
+++ b/hypervisor/src/kvm/cap.rs
@@ -0,0 +1,129 @@
+// Copyright 2017 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use kvm_sys::*;
+
+/// A capability the kernel's KVM interface can possibly expose.
+#[derive(Clone, Copy, Debug, PartialEq, Eq)]
+#[repr(u32)]
+pub enum KvmCap {
+    Irqchip = KVM_CAP_IRQCHIP,
+    Hlt = KVM_CAP_HLT,
+    MmuShadowCacheControl = KVM_CAP_MMU_SHADOW_CACHE_CONTROL,
+    UserMemory = KVM_CAP_USER_MEMORY,
+    SetTssAddr = KVM_CAP_SET_TSS_ADDR,
+    Vapic = KVM_CAP_VAPIC,
+    ExtCpuid = KVM_CAP_EXT_CPUID,
+    Clocksource = KVM_CAP_CLOCKSOURCE,
+    NrVcpus = KVM_CAP_NR_VCPUS,
+    NrMemslots = KVM_CAP_NR_MEMSLOTS,
+    Pit = KVM_CAP_PIT,
+    NopIoDelay = KVM_CAP_NOP_IO_DELAY,
+    PvMmu = KVM_CAP_PV_MMU,
+    MpState = KVM_CAP_MP_STATE,
+    CoalescedMmio = KVM_CAP_COALESCED_MMIO,
+    SyncMmu = KVM_CAP_SYNC_MMU,
+    Iommu = KVM_CAP_IOMMU,
+    DestroyMemoryRegionWorks = KVM_CAP_DESTROY_MEMORY_REGION_WORKS,
+    UserNmi = KVM_CAP_USER_NMI,
+    #[cfg(any(target_arch = "x86_64", target_arch = "arm", target_arch = "aarch64"))]
+    SetGuestDebug = KVM_CAP_SET_GUEST_DEBUG,
+    #[cfg(target_arch = "x86_64")]
+    ReinjectControl = KVM_CAP_REINJECT_CONTROL,
+    IrqRouting = KVM_CAP_IRQ_ROUTING,
+    IrqInjectStatus = KVM_CAP_IRQ_INJECT_STATUS,
+    AssignDevIrq = KVM_CAP_ASSIGN_DEV_IRQ,
+    JoinMemoryRegionsWorks = KVM_CAP_JOIN_MEMORY_REGIONS_WORKS,
+    #[cfg(target_arch = "x86_64")]
+    Mce = KVM_CAP_MCE,
+    Irqfd = KVM_CAP_IRQFD,
+    #[cfg(target_arch = "x86_64")]
+    Pit2 = KVM_CAP_PIT2,
+    SetBootCpuId = KVM_CAP_SET_BOOT_CPU_ID,
+    #[cfg(target_arch = "x86_64")]
+    PitState2 = KVM_CAP_PIT_STATE2,
+    Ioeventfd = KVM_CAP_IOEVENTFD,
+    SetIdentityMapAddr = KVM_CAP_SET_IDENTITY_MAP_ADDR,
+    #[cfg(target_arch = "x86_64")]
+    XenHvm = KVM_CAP_XEN_HVM,
+    AdjustClock = KVM_CAP_ADJUST_CLOCK,
+    InternalErrorData = KVM_CAP_INTERNAL_ERROR_DATA,
+    #[cfg(target_arch = "x86_64")]
+    VcpuEvents = KVM_CAP_VCPU_EVENTS,
+    S390Psw = KVM_CAP_S390_PSW,
+    PpcSegstate = KVM_CAP_PPC_SEGSTATE,
+    Hyperv = KVM_CAP_HYPERV,
+    HypervVapic = KVM_CAP_HYPERV_VAPIC,
+    HypervSpin = KVM_CAP_HYPERV_SPIN,
+    PciSegment = KVM_CAP_PCI_SEGMENT,
+    PpcPairedSingles = KVM_CAP_PPC_PAIRED_SINGLES,
+    IntrShadow = KVM_CAP_INTR_SHADOW,
+    #[cfg(target_arch = "x86_64")]
+    Debugregs = KVM_CAP_DEBUGREGS,
+    X86RobustSinglestep = KVM_CAP_X86_ROBUST_SINGLESTEP,
+    PpcOsi = KVM_CAP_PPC_OSI,
+    PpcUnsetIrq = KVM_CAP_PPC_UNSET_IRQ,
+    EnableCap = KVM_CAP_ENABLE_CAP,
+    #[cfg(target_arch = "x86_64")]
+    Xsave = KVM_CAP_XSAVE,
+    #[cfg(target_arch = "x86_64")]
+    Xcrs = KVM_CAP_XCRS,
+    PpcGetPvinfo = KVM_CAP_PPC_GET_PVINFO,
+    PpcIrqLevel = KVM_CAP_PPC_IRQ_LEVEL,
+    AsyncPf = KVM_CAP_ASYNC_PF,
+    TscControl = KVM_CAP_TSC_CONTROL,
+    GetTscKhz = KVM_CAP_GET_TSC_KHZ,
+    PpcBookeSregs = KVM_CAP_PPC_BOOKE_SREGS,
+    SpaprTce = KVM_CAP_SPAPR_TCE,
+    PpcSmt = KVM_CAP_PPC_SMT,
+    PpcRma = KVM_CAP_PPC_RMA,
+    MaxVcpus = KVM_CAP_MAX_VCPUS,
+    PpcHior = KVM_CAP_PPC_HIOR,
+    PpcPapr = KVM_CAP_PPC_PAPR,
+    SwTlb = KVM_CAP_SW_TLB,
+    OneReg = KVM_CAP_ONE_REG,
+    S390Gmap = KVM_CAP_S390_GMAP,
+    TscDeadlineTimer = KVM_CAP_TSC_DEADLINE_TIMER,
+    S390Ucontrol = KVM_CAP_S390_UCONTROL,
+    SyncRegs = KVM_CAP_SYNC_REGS,
+    Pci23 = KVM_CAP_PCI_2_3,
+    KvmclockCtrl = KVM_CAP_KVMCLOCK_CTRL,
+    SignalMsi = KVM_CAP_SIGNAL_MSI,
+    PpcGetSmmuInfo = KVM_CAP_PPC_GET_SMMU_INFO,
+    S390Cow = KVM_CAP_S390_COW,
+    PpcAllocHtab = KVM_CAP_PPC_ALLOC_HTAB,
+    ReadonlyMem = KVM_CAP_READONLY_MEM,
+    IrqfdResample = KVM_CAP_IRQFD_RESAMPLE,
+    PpcBookeWatchdog = KVM_CAP_PPC_BOOKE_WATCHDOG,
+    PpcHtabFd = KVM_CAP_PPC_HTAB_FD,
+    S390CssSupport = KVM_CAP_S390_CSS_SUPPORT,
+    PpcEpr = KVM_CAP_PPC_EPR,
+    ArmPsci = KVM_CAP_ARM_PSCI,
+    ArmSetDeviceAddr = KVM_CAP_ARM_SET_DEVICE_ADDR,
+    DeviceCtrl = KVM_CAP_DEVICE_CTRL,
+    IrqMpic = KVM_CAP_IRQ_MPIC,
+    PpcRtas = KVM_CAP_PPC_RTAS,
+    IrqXics = KVM_CAP_IRQ_XICS,
+    ArmEl132bit = KVM_CAP_ARM_EL1_32BIT,
+    SpaprMultitce = KVM_CAP_SPAPR_MULTITCE,
+    ExtEmulCpuid = KVM_CAP_EXT_EMUL_CPUID,
+    HypervTime = KVM_CAP_HYPERV_TIME,
+    IoapicPolarityIgnored = KVM_CAP_IOAPIC_POLARITY_IGNORED,
+    EnableCapVm = KVM_CAP_ENABLE_CAP_VM,
+    S390Irqchip = KVM_CAP_S390_IRQCHIP,
+    IoeventfdNoLength = KVM_CAP_IOEVENTFD_NO_LENGTH,
+    VmAttributes = KVM_CAP_VM_ATTRIBUTES,
+    ArmPsci02 = KVM_CAP_ARM_PSCI_0_2,
+    PpcFixupHcall = KVM_CAP_PPC_FIXUP_HCALL,
+    PpcEnableHcall = KVM_CAP_PPC_ENABLE_HCALL,
+    CheckExtensionVm = KVM_CAP_CHECK_EXTENSION_VM,
+    S390UserSigp = KVM_CAP_S390_USER_SIGP,
+    ImmediateExit = KVM_CAP_IMMEDIATE_EXIT,
+    ArmPmuV3 = KVM_CAP_ARM_PMU_V3,
+    ArmProtectedVm = KVM_CAP_ARM_PROTECTED_VM,
+    ArmMte = KVM_CAP_ARM_MTE,
+    #[cfg(target_arch = "x86_64")]
+    BusLockDetect = KVM_CAP_X86_BUS_LOCK_EXIT,
+    MemNoncoherentDma = KVM_CAP_USER_CONFIGURE_NONCOHERENT_DMA,
+}
diff --git a/hypervisor/src/kvm/mod.rs b/hypervisor/src/kvm/mod.rs
index 2022b54b9..be9d7aabf 100644
--- a/hypervisor/src/kvm/mod.rs
+++ b/hypervisor/src/kvm/mod.rs
@@ -7,6 +7,9 @@ mod aarch64;
 #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
 pub use aarch64::*;
 
+mod cap;
+pub use cap::KvmCap;
+
 #[cfg(target_arch = "riscv64")]
 mod riscv64;
 
@@ -19,11 +22,11 @@ use std::collections::BTreeMap;
 use std::collections::BinaryHeap;
 use std::convert::TryFrom;
 use std::ffi::CString;
+use std::fs::File;
 use std::os::raw::c_ulong;
 use std::os::raw::c_void;
 use std::os::unix::prelude::OsStrExt;
 use std::path::Path;
-use std::path::PathBuf;
 use std::ptr::copy_nonoverlapping;
 use std::sync::Arc;
 
@@ -33,7 +36,6 @@ use base::ioctl;
 use base::ioctl_with_mut_ref;
 use base::ioctl_with_ref;
 use base::ioctl_with_val;
-use base::linux::MemoryMappingBuilderUnix;
 use base::pagesize;
 use base::AsRawDescriptor;
 use base::Error;
@@ -72,7 +74,6 @@ use crate::ClockState;
 use crate::Config;
 use crate::Datamatch;
 use crate::DeviceKind;
-use crate::HypervHypercall;
 use crate::Hypervisor;
 use crate::HypervisorCap;
 use crate::IoEventAddress;
@@ -120,7 +121,7 @@ unsafe fn set_user_memory_region(
         userspace_addr: userspace_addr as u64,
     };
 
-    let ret = ioctl_with_ref(descriptor, KVM_SET_USER_MEMORY_REGION(), &region);
+    let ret = ioctl_with_ref(descriptor, KVM_SET_USER_MEMORY_REGION, &region);
     if ret == 0 {
         Ok(())
     } else {
@@ -141,10 +142,9 @@ pub fn dirty_log_bitmap_size(size: usize) -> usize {
 
 pub struct Kvm {
     kvm: SafeDescriptor,
+    vcpu_mmap_size: usize,
 }
 
-pub type KvmCap = kvm::Cap;
-
 impl Kvm {
     pub fn new_with_path(device_path: &Path) -> Result<Kvm> {
         let c_path = CString::new(device_path.as_os_str().as_bytes()).unwrap();
@@ -160,7 +160,7 @@ impl Kvm {
 
         // SAFETY:
         // Safe because we know that the descriptor is valid and we verify the return result.
-        let version = unsafe { ioctl(&kvm, KVM_GET_API_VERSION()) };
+        let version = unsafe { ioctl(&kvm, KVM_GET_API_VERSION) };
         if version < 0 {
             return errno_result();
         }
@@ -175,24 +175,23 @@ impl Kvm {
             return Err(Error::new(ENOSYS));
         }
 
-        Ok(Kvm { kvm })
-    }
-
-    /// Opens `/dev/kvm/` and returns a Kvm object on success.
-    pub fn new() -> Result<Kvm> {
-        Kvm::new_with_path(&PathBuf::from("/dev/kvm"))
-    }
-
-    /// Gets the size of the mmap required to use vcpu's `kvm_run` structure.
-    pub fn get_vcpu_mmap_size(&self) -> Result<usize> {
         // SAFETY:
         // Safe because we know that our file is a KVM fd and we verify the return result.
-        let res = unsafe { ioctl(self, KVM_GET_VCPU_MMAP_SIZE()) };
-        if res > 0 {
-            Ok(res as usize)
-        } else {
-            errno_result()
+        let res = unsafe { ioctl(&kvm, KVM_GET_VCPU_MMAP_SIZE) };
+        if res <= 0 {
+            return errno_result();
         }
+        let vcpu_mmap_size = res as usize;
+
+        Ok(Kvm {
+            kvm,
+            vcpu_mmap_size,
+        })
+    }
+
+    /// Opens `/dev/kvm` and returns a Kvm object on success.
+    pub fn new() -> Result<Kvm> {
+        Kvm::new_with_path(Path::new("/dev/kvm"))
     }
 }
 
@@ -206,6 +205,7 @@ impl Hypervisor for Kvm {
     fn try_clone(&self) -> Result<Self> {
         Ok(Kvm {
             kvm: self.kvm.try_clone()?,
+            vcpu_mmap_size: self.vcpu_mmap_size,
         })
     }
 
@@ -214,7 +214,7 @@ impl Hypervisor for Kvm {
             // SAFETY:
             // this ioctl is safe because we know this kvm descriptor is valid,
             // and we are copying over the kvm capability (u32) as a c_ulong value.
-            unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION(), kvm_cap as c_ulong) == 1 }
+            unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION, kvm_cap as c_ulong) == 1 }
         } else {
             // this capability cannot be converted on this platform, so return false
             false
@@ -230,6 +230,7 @@ pub struct KvmVm {
     mem_regions: Arc<Mutex<BTreeMap<MemSlot, Box<dyn MappedRegion>>>>,
     /// A min heap of MemSlot numbers that were used and then removed and can now be re-used
     mem_slot_gaps: Arc<Mutex<BinaryHeap<Reverse<MemSlot>>>>,
+    cap_kvmclock_ctrl: bool,
 }
 
 impl KvmVm {
@@ -241,7 +242,7 @@ impl KvmVm {
         let ret = unsafe {
             ioctl_with_val(
                 kvm,
-                KVM_CREATE_VM(),
+                KVM_CREATE_VM,
                 kvm.get_vm_type(cfg.protection_type)? as c_ulong,
             )
         };
@@ -268,23 +269,23 @@ impl KvmVm {
             }?;
         }
 
-        let vm = KvmVm {
+        let mut vm = KvmVm {
             kvm: kvm.try_clone()?,
             vm: vm_descriptor,
             guest_mem,
             mem_regions: Arc::new(Mutex::new(BTreeMap::new())),
             mem_slot_gaps: Arc::new(Mutex::new(BinaryHeap::new())),
+            cap_kvmclock_ctrl: false,
         };
+        vm.cap_kvmclock_ctrl = vm.check_raw_capability(KvmCap::KvmclockCtrl);
         vm.init_arch(&cfg)?;
         Ok(vm)
     }
 
     pub fn create_kvm_vcpu(&self, id: usize) -> Result<KvmVcpu> {
-        let run_mmap_size = self.kvm.get_vcpu_mmap_size()?;
-
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let fd = unsafe { ioctl_with_val(self, KVM_CREATE_VCPU(), c_ulong::try_from(id).unwrap()) };
+        let fd = unsafe { ioctl_with_val(self, KVM_CREATE_VCPU, c_ulong::try_from(id).unwrap()) };
         if fd < 0 {
             return errno_result();
         }
@@ -292,25 +293,23 @@ impl KvmVm {
         // SAFETY:
         // Wrap the vcpu now in case the following ? returns early. This is safe because we verified
         // the value of the fd and we own the fd.
-        let vcpu = unsafe { SafeDescriptor::from_raw_descriptor(fd) };
+        let vcpu = unsafe { File::from_raw_descriptor(fd) };
 
         // The VCPU mapping is held by an `Arc` inside `KvmVcpu`, and it can also be cloned by
         // `signal_handle()` for use in `KvmVcpuSignalHandle`. The mapping will not be destroyed
         // until all references are dropped, so it is safe to reference `kvm_run` fields via the
         // `as_ptr()` function during either type's lifetime.
-        let run_mmap = MemoryMappingBuilder::new(run_mmap_size)
-            .from_descriptor(&vcpu)
+        let run_mmap = MemoryMappingBuilder::new(self.kvm.vcpu_mmap_size)
+            .from_file(&vcpu)
             .build()
             .map_err(|_| Error::new(ENOSPC))?;
 
-        let cap_kvmclock_ctrl = self.check_raw_capability(KvmCap::KvmclockCtrl);
-
         Ok(KvmVcpu {
             kvm: self.kvm.try_clone()?,
             vm: self.vm.try_clone()?,
             vcpu,
             id,
-            cap_kvmclock_ctrl,
+            cap_kvmclock_ctrl: self.cap_kvmclock_ctrl,
             run_mmap: Arc::new(run_mmap),
         })
     }
@@ -321,7 +320,7 @@ impl KvmVm {
     pub fn create_irq_chip(&self) -> Result<()> {
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let ret = unsafe { ioctl(self, KVM_CREATE_IRQCHIP()) };
+        let ret = unsafe { ioctl(self, KVM_CREATE_IRQCHIP) };
         if ret == 0 {
             Ok(())
         } else {
@@ -338,7 +337,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IRQ_LINE(), &irq_level) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IRQ_LINE, &irq_level) };
         if ret == 0 {
             Ok(())
         } else {
@@ -368,7 +367,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD(), &irqfd) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD, &irqfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -391,7 +390,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD(), &irqfd) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD, &irqfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -416,7 +415,7 @@ impl KvmVm {
 
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_GSI_ROUTING(), &irq_routing[0]) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_GSI_ROUTING, &irq_routing[0]) };
         if ret == 0 {
             Ok(())
         } else {
@@ -474,7 +473,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IOEVENTFD(), &ioeventfd) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IOEVENTFD, &ioeventfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -487,7 +486,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a KVM fd, and if the cap is invalid KVM assumes
         // it's an unavailable extension and returns 0.
-        let ret = unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION(), capability as c_ulong) };
+        let ret = unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION, capability as c_ulong) };
         match capability {
             #[cfg(target_arch = "x86_64")]
             KvmCap::BusLockDetect => {
@@ -524,7 +523,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct, and because we assume the caller has allocated the args appropriately.
-        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP(), &kvm_cap);
+        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP, &kvm_cap);
         if ret == 0 {
             Ok(())
         } else {
@@ -554,6 +553,7 @@ impl Vm for KvmVm {
             guest_mem: self.guest_mem.clone(),
             mem_regions: self.mem_regions.clone(),
             mem_slot_gaps: self.mem_slot_gaps.clone(),
+            cap_kvmclock_ctrl: self.cap_kvmclock_ctrl,
         })
     }
 
@@ -673,6 +673,42 @@ impl Vm for KvmVm {
         })
     }
 
+    fn madvise_pageout_memory_region(
+        &mut self,
+        slot: MemSlot,
+        offset: usize,
+        size: usize,
+    ) -> Result<()> {
+        let mut regions = self.mem_regions.lock();
+        let mem = regions.get_mut(&slot).ok_or_else(|| Error::new(ENOENT))?;
+
+        mem.madvise(offset, size, libc::MADV_PAGEOUT)
+            .map_err(|err| match err {
+                MmapError::InvalidAddress => Error::new(EFAULT),
+                MmapError::NotPageAligned => Error::new(EINVAL),
+                MmapError::SystemCallFailed(e) => e,
+                _ => Error::new(EIO),
+            })
+    }
+
+    fn madvise_remove_memory_region(
+        &mut self,
+        slot: MemSlot,
+        offset: usize,
+        size: usize,
+    ) -> Result<()> {
+        let mut regions = self.mem_regions.lock();
+        let mem = regions.get_mut(&slot).ok_or_else(|| Error::new(ENOENT))?;
+
+        mem.madvise(offset, size, libc::MADV_REMOVE)
+            .map_err(|err| match err {
+                MmapError::InvalidAddress => Error::new(EFAULT),
+                MmapError::NotPageAligned => Error::new(EINVAL),
+                MmapError::SystemCallFailed(e) => e,
+                _ => Error::new(EIO),
+            })
+    }
+
     fn remove_memory_region(&mut self, slot: MemSlot) -> Result<Box<dyn MappedRegion>> {
         let mut regions = self.mem_regions.lock();
         if !regions.contains_key(&slot) {
@@ -698,7 +734,7 @@ impl Vm for KvmVm {
     }
 
     fn create_device(&self, kind: DeviceKind) -> Result<SafeDescriptor> {
-        let device = if let Some(dev) = self.get_device_params_arch(kind) {
+        let mut device = if let Some(dev) = self.get_device_params_arch(kind) {
             dev
         } else {
             match kind {
@@ -717,7 +753,7 @@ impl Vm for KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only write correct
         // amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { base::ioctl_with_ref(self, KVM_CREATE_DEVICE(), &device) };
+        let ret = unsafe { base::ioctl_with_mut_ref(self, KVM_CREATE_DEVICE, &mut device) };
         if ret == 0 {
             Ok(
                 // SAFETY:
@@ -745,7 +781,7 @@ impl Vm for KvmVm {
         // SAFETY:
         // Safe because the `dirty_bitmap` pointer assigned above is guaranteed to be valid (because
         // it's from a slice) and we checked that it will be large enough to hold the entire log.
-        let ret = unsafe { ioctl_with_ref(self, KVM_GET_DIRTY_LOG(), &dirty_log_kvm) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_GET_DIRTY_LOG, &dirty_log_kvm) };
         if ret == 0 {
             Ok(())
         } else {
@@ -848,7 +884,7 @@ impl VcpuSignalHandleInner for KvmVcpuSignalHandle {
 pub struct KvmVcpu {
     kvm: Kvm,
     vm: SafeDescriptor,
-    vcpu: SafeDescriptor,
+    vcpu: File,
     id: usize,
     cap_kvmclock_ctrl: bool,
     run_mmap: Arc<MemoryMapping>,
@@ -903,8 +939,12 @@ impl Vcpu for KvmVcpu {
         if self.cap_kvmclock_ctrl {
             // SAFETY:
             // The ioctl is safe because it does not read or write memory in this process.
-            if unsafe { ioctl(self, KVM_KVMCLOCK_CTRL()) } != 0 {
-                return errno_result();
+            if unsafe { ioctl(self, KVM_KVMCLOCK_CTRL) } != 0 {
+                // Even if the host kernel supports the capability, it may not be configured by
+                // the guest - for example, when the guest kernel offlines a CPU.
+                if Error::last().errno() != libc::EINVAL {
+                    return errno_result();
+                }
             }
         }
 
@@ -920,7 +960,7 @@ impl Vcpu for KvmVcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct, and because we assume the caller has allocated the args appropriately.
-        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP(), &kvm_cap);
+        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP, &kvm_cap);
         if ret == 0 {
             Ok(())
         } else {
@@ -934,7 +974,7 @@ impl Vcpu for KvmVcpu {
     fn run(&mut self) -> Result<VcpuExit> {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd and we verify the return result.
-        let ret = unsafe { ioctl(self, KVM_RUN()) };
+        let ret = unsafe { ioctl(self, KVM_RUN) };
         if ret != 0 {
             return errno_result();
         }
@@ -943,24 +983,20 @@ impl Vcpu for KvmVcpu {
         // Safe because we know we mapped enough memory to hold the kvm_run struct because the
         // kernel told us how large it was.
         let run = unsafe { &mut *(self.run_mmap.as_ptr() as *mut kvm_run) };
+
+        // Check for architecture-specific VM exit reasons first in case the architecture wants to
+        // override the default handling.
+        if let Some(vcpu_exit) = self.handle_vm_exit_arch(run) {
+            return Ok(vcpu_exit);
+        }
+
         match run.exit_reason {
-            KVM_EXIT_IO => Ok(VcpuExit::Io),
             KVM_EXIT_MMIO => Ok(VcpuExit::Mmio),
-            KVM_EXIT_IOAPIC_EOI => {
-                // SAFETY:
-                // Safe because the exit_reason (which comes from the kernel) told us which
-                // union field to use.
-                let vector = unsafe { run.__bindgen_anon_1.eoi.vector };
-                Ok(VcpuExit::IoapicEoi { vector })
-            }
-            KVM_EXIT_HYPERV => Ok(VcpuExit::HypervHypercall),
-            KVM_EXIT_UNKNOWN => Ok(VcpuExit::Unknown),
             KVM_EXIT_EXCEPTION => Ok(VcpuExit::Exception),
             KVM_EXIT_HYPERCALL => Ok(VcpuExit::Hypercall),
             KVM_EXIT_DEBUG => Ok(VcpuExit::Debug),
-            KVM_EXIT_HLT => Ok(VcpuExit::Hlt),
             KVM_EXIT_IRQ_WINDOW_OPEN => Ok(VcpuExit::IrqWindowOpen),
-            KVM_EXIT_SHUTDOWN => Ok(VcpuExit::Shutdown),
+            KVM_EXIT_SHUTDOWN => Ok(VcpuExit::Shutdown(Ok(()))),
             KVM_EXIT_FAIL_ENTRY => {
                 // SAFETY:
                 // Safe because the exit_reason (which comes from the kernel) told us which
@@ -975,19 +1011,7 @@ impl Vcpu for KvmVcpu {
                 })
             }
             KVM_EXIT_INTR => Ok(VcpuExit::Intr),
-            KVM_EXIT_SET_TPR => Ok(VcpuExit::SetTpr),
-            KVM_EXIT_TPR_ACCESS => Ok(VcpuExit::TprAccess),
-            KVM_EXIT_S390_SIEIC => Ok(VcpuExit::S390Sieic),
-            KVM_EXIT_S390_RESET => Ok(VcpuExit::S390Reset),
-            KVM_EXIT_DCR => Ok(VcpuExit::Dcr),
-            KVM_EXIT_NMI => Ok(VcpuExit::Nmi),
             KVM_EXIT_INTERNAL_ERROR => Ok(VcpuExit::InternalError),
-            KVM_EXIT_OSI => Ok(VcpuExit::Osi),
-            KVM_EXIT_PAPR_HCALL => Ok(VcpuExit::PaprHcall),
-            KVM_EXIT_S390_UCONTROL => Ok(VcpuExit::S390Ucontrol),
-            KVM_EXIT_WATCHDOG => Ok(VcpuExit::Watchdog),
-            KVM_EXIT_S390_TSCH => Ok(VcpuExit::S390Tsch),
-            KVM_EXIT_EPR => Ok(VcpuExit::Epr),
             KVM_EXIT_SYSTEM_EVENT => {
                 // SAFETY:
                 // Safe because we know the exit reason told us this union
@@ -1011,59 +1035,14 @@ impl Vcpu for KvmVcpu {
                     }
                 }
             }
-            KVM_EXIT_X86_RDMSR => {
-                // SAFETY:
-                // Safe because the exit_reason (which comes from the kernel) told us which
-                // union field to use.
-                let msr = unsafe { &mut run.__bindgen_anon_1.msr };
-                let index = msr.index;
-                // By default fail the MSR read unless it was handled later.
-                msr.error = 1;
-                Ok(VcpuExit::RdMsr { index })
-            }
-            KVM_EXIT_X86_WRMSR => {
-                // SAFETY:
-                // Safe because the exit_reason (which comes from the kernel) told us which
-                // union field to use.
-                let msr = unsafe { &mut run.__bindgen_anon_1.msr };
-                // By default fail the MSR write.
-                msr.error = 1;
-                let index = msr.index;
-                let data = msr.data;
-                Ok(VcpuExit::WrMsr { index, data })
-            }
-            KVM_EXIT_X86_BUS_LOCK => Ok(VcpuExit::BusLock),
-            #[cfg(target_arch = "riscv64")]
-            KVM_EXIT_RISCV_SBI => {
-                // Safe because we trust the kernel to correctly fill in the union
-                let extension_id = unsafe { run.__bindgen_anon_1.riscv_sbi.extension_id };
-                let function_id = unsafe { run.__bindgen_anon_1.riscv_sbi.function_id };
-                let args = unsafe { run.__bindgen_anon_1.riscv_sbi.args };
-                Ok(VcpuExit::Sbi {
-                    extension_id,
-                    function_id,
-                    args,
-                })
-            }
-            #[cfg(target_arch = "riscv64")]
-            KVM_EXIT_RISCV_CSR => {
-                // Safe because we trust the kernel to correctly fill in the union
-                let csr_num = unsafe { run.__bindgen_anon_1.riscv_csr.csr_num };
-                let new_value = unsafe { run.__bindgen_anon_1.riscv_csr.new_value };
-                let write_mask = unsafe { run.__bindgen_anon_1.riscv_csr.write_mask };
-                let ret_value = unsafe { run.__bindgen_anon_1.riscv_csr.ret_value };
-                Ok(VcpuExit::RiscvCsr {
-                    csr_num,
-                    new_value,
-                    write_mask,
-                    ret_value,
-                })
-            }
             r => panic!("unknown kvm exit reason: {}", r),
         }
     }
 
-    fn handle_mmio(&self, handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
+    fn handle_mmio(
+        &self,
+        handle_fn: &mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>,
+    ) -> Result<()> {
         // SAFETY:
         // Safe because we know we mapped enough memory to hold the kvm_run struct because the
         // kernel told us how large it was. The pointer is page aligned so casting to a different
@@ -1082,13 +1061,13 @@ impl Vcpu for KvmVcpu {
                 address,
                 size,
                 operation: IoOperation::Write { data: mmio.data },
-            });
+            })?;
             Ok(())
         } else if let Some(data) = handle_fn(IoParams {
             address,
             size,
             operation: IoOperation::Read,
-        }) {
+        })? {
             mmio.data[..size].copy_from_slice(&data[..size]);
             Ok(())
         } else {
@@ -1155,77 +1134,6 @@ impl Vcpu for KvmVcpu {
             _ => Err(Error::new(EINVAL)),
         }
     }
-
-    fn handle_hyperv_hypercall(
-        &self,
-        handle_fn: &mut dyn FnMut(HypervHypercall) -> u64,
-    ) -> Result<()> {
-        // SAFETY:
-        // Safe because we know we mapped enough memory to hold the kvm_run struct because the
-        // kernel told us how large it was.
-        let run = unsafe { &mut *(self.run_mmap.as_ptr() as *mut kvm_run) };
-        // Verify that the handler is called in the right context.
-        assert!(run.exit_reason == KVM_EXIT_HYPERV);
-        // SAFETY:
-        // Safe because the exit_reason (which comes from the kernel) told us which
-        // union field to use.
-        let hyperv = unsafe { &mut run.__bindgen_anon_1.hyperv };
-        match hyperv.type_ {
-            KVM_EXIT_HYPERV_SYNIC => {
-                // TODO(b/315998194): Add safety comment
-                #[allow(clippy::undocumented_unsafe_blocks)]
-                let synic = unsafe { &hyperv.u.synic };
-                handle_fn(HypervHypercall::HypervSynic {
-                    msr: synic.msr,
-                    control: synic.control,
-                    evt_page: synic.evt_page,
-                    msg_page: synic.msg_page,
-                });
-                Ok(())
-            }
-            KVM_EXIT_HYPERV_HCALL => {
-                // TODO(b/315998194): Add safety comment
-                #[allow(clippy::undocumented_unsafe_blocks)]
-                let hcall = unsafe { &mut hyperv.u.hcall };
-                hcall.result = handle_fn(HypervHypercall::HypervHcall {
-                    input: hcall.input,
-                    params: hcall.params,
-                });
-                Ok(())
-            }
-            _ => Err(Error::new(EINVAL)),
-        }
-    }
-
-    fn handle_rdmsr(&self, data: u64) -> Result<()> {
-        // SAFETY:
-        // Safe because we know we mapped enough memory to hold the kvm_run struct because the
-        // kernel told us how large it was.
-        let run = unsafe { &mut *(self.run_mmap.as_ptr() as *mut kvm_run) };
-        // Verify that the handler is called in the right context.
-        assert!(run.exit_reason == KVM_EXIT_X86_RDMSR);
-        // SAFETY:
-        // Safe because the exit_reason (which comes from the kernel) told us which
-        // union field to use.
-        let msr = unsafe { &mut run.__bindgen_anon_1.msr };
-        msr.data = data;
-        msr.error = 0;
-        Ok(())
-    }
-
-    fn handle_wrmsr(&self) {
-        // SAFETY:
-        // Safe because we know we mapped enough memory to hold the kvm_run struct because the
-        // kernel told us how large it was.
-        let run = unsafe { &mut *(self.run_mmap.as_ptr() as *mut kvm_run) };
-        // Verify that the handler is called in the right context.
-        assert!(run.exit_reason == KVM_EXIT_X86_WRMSR);
-        // SAFETY:
-        // Safe because the exit_reason (which comes from the kernel) told us which
-        // union field to use.
-        let msr = unsafe { &mut run.__bindgen_anon_1.msr };
-        msr.error = 0;
-    }
 }
 
 impl KvmVcpu {
@@ -1244,7 +1152,7 @@ impl KvmVcpu {
             // Safe because we know that our file is a VCPU fd, we know the kernel will only write
             // the correct amount of memory to our pointer, and we verify the return
             // result.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_MP_STATE(), &mut state) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_MP_STATE, &mut state) }
         };
         if ret < 0 {
             return errno_result();
@@ -1263,7 +1171,7 @@ impl KvmVcpu {
         let ret = {
             // SAFETY:
             // The ioctl is safe because the kernel will only read from the kvm_mp_state struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_MP_STATE(), state) }
+            unsafe { ioctl_with_ref(self, KVM_SET_MP_STATE, state) }
         };
         if ret < 0 {
             return errno_result();
diff --git a/hypervisor/src/kvm/riscv64.rs b/hypervisor/src/kvm/riscv64.rs
index e3aba00d3..252f20b9a 100644
--- a/hypervisor/src/kvm/riscv64.rs
+++ b/hypervisor/src/kvm/riscv64.rs
@@ -105,6 +105,37 @@ impl KvmVcpu {
     pub fn system_event_reset(&self, _event_flags: u64) -> Result<VcpuExit> {
         Ok(VcpuExit::SystemEventReset)
     }
+
+    #[inline]
+    pub(crate) fn handle_vm_exit_arch(&self, run: &mut kvm_run) -> Option<VcpuExit> {
+        match run.exit_reason {
+            KVM_EXIT_RISCV_SBI => {
+                // SAFETY: Safe because we trust the kernel to correctly fill in the union
+                let extension_id = unsafe { run.__bindgen_anon_1.riscv_sbi.extension_id };
+                let function_id = unsafe { run.__bindgen_anon_1.riscv_sbi.function_id };
+                let args = unsafe { run.__bindgen_anon_1.riscv_sbi.args };
+                Some(VcpuExit::Sbi {
+                    extension_id,
+                    function_id,
+                    args,
+                })
+            }
+            KVM_EXIT_RISCV_CSR => {
+                // SAFETY: Safe because we trust the kernel to correctly fill in the union
+                let csr_num = unsafe { run.__bindgen_anon_1.riscv_csr.csr_num };
+                let new_value = unsafe { run.__bindgen_anon_1.riscv_csr.new_value };
+                let write_mask = unsafe { run.__bindgen_anon_1.riscv_csr.write_mask };
+                let ret_value = unsafe { run.__bindgen_anon_1.riscv_csr.ret_value };
+                Some(VcpuExit::RiscvCsr {
+                    csr_num,
+                    new_value,
+                    write_mask,
+                    ret_value,
+                })
+            }
+            _ => None,
+        }
+    }
 }
 
 impl VcpuRiscv64 for KvmVcpu {
@@ -116,7 +147,7 @@ impl VcpuRiscv64 for KvmVcpu {
         };
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_ONE_REG(), &onereg) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_ONE_REG, &onereg) };
         if ret == 0 {
             Ok(())
         } else {
@@ -133,7 +164,7 @@ impl VcpuRiscv64 for KvmVcpu {
 
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = unsafe { ioctl_with_ref(self, KVM_GET_ONE_REG(), &onereg) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_GET_ONE_REG, &onereg) };
         if ret == 0 {
             Ok(val)
         } else {
diff --git a/hypervisor/src/kvm/x86_64.rs b/hypervisor/src/kvm/x86_64.rs
index 31d95075f..a8c897898 100644
--- a/hypervisor/src/kvm/x86_64.rs
+++ b/hypervisor/src/kvm/x86_64.rs
@@ -19,8 +19,10 @@ use base::IoctlNr;
 use base::MappedRegion;
 use base::Result;
 use data_model::vec_with_array_field;
+use data_model::FlexibleArrayWrapper;
 use kvm_sys::*;
 use libc::E2BIG;
+use libc::EAGAIN;
 use libc::EIO;
 use libc::ENXIO;
 use serde::Deserialize;
@@ -39,6 +41,7 @@ use crate::DebugRegs;
 use crate::DescriptorTable;
 use crate::DeviceKind;
 use crate::Fpu;
+use crate::FpuReg;
 use crate::HypervisorX86_64;
 use crate::IoapicRedirectionTableEntry;
 use crate::IoapicState;
@@ -59,7 +62,7 @@ use crate::VmX86_64;
 use crate::Xsave;
 use crate::NUM_IOAPIC_PINS;
 
-type KvmCpuId = kvm::CpuId;
+type KvmCpuId = FlexibleArrayWrapper<kvm_cpuid2, kvm_cpuid_entry2>;
 const KVM_XSAVE_MAX_SIZE: usize = 4096;
 const MSR_IA32_APICBASE: u32 = 0x0000001b;
 
@@ -155,11 +158,11 @@ impl Kvm {
 
     // The x86 machine type is always 0. Protected VMs are not supported.
     pub fn get_vm_type(&self, protection_type: ProtectionType) -> Result<u32> {
-        if protection_type == ProtectionType::Unprotected {
-            Ok(0)
-        } else {
+        if protection_type.isolates_memory() {
             error!("Protected mode is not supported on x86_64.");
             Err(Error::new(libc::EINVAL))
+        } else {
+            Ok(0)
         }
     }
 
@@ -172,11 +175,11 @@ impl Kvm {
 
 impl HypervisorX86_64 for Kvm {
     fn get_supported_cpuid(&self) -> Result<CpuId> {
-        self.get_cpuid(KVM_GET_SUPPORTED_CPUID())
+        self.get_cpuid(KVM_GET_SUPPORTED_CPUID)
     }
 
     fn get_emulated_cpuid(&self) -> Result<CpuId> {
-        self.get_cpuid(KVM_GET_EMULATED_CPUID())
+        self.get_cpuid(KVM_GET_EMULATED_CPUID)
     }
 
     fn get_msr_index_list(&self) -> Result<Vec<u32>> {
@@ -190,7 +193,7 @@ impl HypervisorX86_64 for Kvm {
             // ioctl is unsafe. The kernel is trusted not to write beyond the bounds of the memory
             // allocated for the struct. The limit is read from nmsrs, which is set to the allocated
             // size (MAX_KVM_MSR_ENTRIES) above.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_MSR_INDEX_LIST(), &mut msr_list[0]) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_MSR_INDEX_LIST, &mut msr_list[0]) }
         };
         if ret < 0 {
             return errno_result();
@@ -245,7 +248,7 @@ impl KvmVm {
             // SAFETY:
             // Safe because we know that our file is a VM fd, we know the kernel will only write correct
             // amount of memory to our pointer, and we verify the return result.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_CLOCK(), &mut clock_data) };
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_CLOCK, &mut clock_data) };
         if ret == 0 {
             Ok(ClockState::from(&clock_data))
         } else {
@@ -259,7 +262,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read correct
         // amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_CLOCK(), &clock_data) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_CLOCK, &clock_data) };
         if ret == 0 {
             Ok(())
         } else {
@@ -279,7 +282,7 @@ impl KvmVm {
             // SAFETY:
             // Safe because we know our file is a VM fd, we know the kernel will only write
             // correct amount of memory to our pointer, and we verify the return result.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_IRQCHIP(), &mut irqchip_state) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_IRQCHIP, &mut irqchip_state) }
         };
         if ret == 0 {
             Ok(
@@ -305,7 +308,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP(), &irqchip_state) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP, &irqchip_state) };
         if ret == 0 {
             Ok(())
         } else {
@@ -330,7 +333,7 @@ impl KvmVm {
             // SAFETY:
             // Safe because we know our file is a VM fd, we know the kernel will only write
             // correct amount of memory to our pointer, and we verify the return result.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_IRQCHIP(), &mut irqchip_state) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_IRQCHIP, &mut irqchip_state) }
         };
         if ret == 0 {
             Ok(
@@ -356,7 +359,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP(), &irqchip_state) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP, &irqchip_state) };
         if ret == 0 {
             Ok(())
         } else {
@@ -372,7 +375,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_CREATE_PIT2(), &pit_config) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_CREATE_PIT2, &pit_config) };
         if ret == 0 {
             Ok(())
         } else {
@@ -388,7 +391,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only write
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_PIT2(), &mut pit_state) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_PIT2, &mut pit_state) };
         if ret == 0 {
             Ok(pit_state)
         } else {
@@ -403,7 +406,7 @@ impl KvmVm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_PIT2(), pit_state) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_PIT2, pit_state) };
         if ret == 0 {
             Ok(())
         } else {
@@ -411,28 +414,6 @@ impl KvmVm {
         }
     }
 
-    /// Enable userspace msr.
-    pub fn enable_userspace_msr(&self) -> Result<()> {
-        let mut cap = kvm_enable_cap {
-            cap: KVM_CAP_X86_USER_SPACE_MSR,
-            ..Default::default()
-        };
-        cap.args[0] = (KVM_MSR_EXIT_REASON_UNKNOWN
-            | KVM_MSR_EXIT_REASON_INVAL
-            | KVM_MSR_EXIT_REASON_FILTER) as u64;
-
-        // SAFETY:
-        // Safe because we know that our file is a VM fd, we know that the
-        // kernel will only read correct amount of memory from our pointer, and
-        // we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_ENABLE_CAP(), &cap) };
-        if ret < 0 {
-            errno_result()
-        } else {
-            Ok(())
-        }
-    }
-
     /// Set MSR_PLATFORM_INFO read access.
     pub fn set_platform_info_read_access(&self, allow_read: bool) -> Result<()> {
         let mut cap = kvm_enable_cap {
@@ -445,73 +426,7 @@ impl KvmVm {
         // Safe because we know that our file is a VM fd, we know that the
         // kernel will only read correct amount of memory from our pointer, and
         // we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_ENABLE_CAP(), &cap) };
-        if ret < 0 {
-            errno_result()
-        } else {
-            Ok(())
-        }
-    }
-
-    /// Set msr filter.
-    pub fn set_msr_filter(&self, msr_list: (Vec<u32>, Vec<u32>)) -> Result<()> {
-        let mut rd_nmsrs: u32 = 0;
-        let mut wr_nmsrs: u32 = 0;
-        let mut rd_msr_bitmap: [u8; KVM_MSR_FILTER_RANGE_MAX_BYTES] =
-            [0xff; KVM_MSR_FILTER_RANGE_MAX_BYTES];
-        let mut wr_msr_bitmap: [u8; KVM_MSR_FILTER_RANGE_MAX_BYTES] =
-            [0xff; KVM_MSR_FILTER_RANGE_MAX_BYTES];
-        let (rd_msrs, wr_msrs) = msr_list;
-
-        for index in rd_msrs {
-            // currently we only consider the MSR lower than
-            // KVM_MSR_FILTER_RANGE_MAX_BITS
-            if index >= (KVM_MSR_FILTER_RANGE_MAX_BITS as u32) {
-                continue;
-            }
-            rd_nmsrs += 1;
-            rd_msr_bitmap[(index / 8) as usize] &= !(1 << (index & 0x7));
-        }
-        for index in wr_msrs {
-            // currently we only consider the MSR lower than
-            // KVM_MSR_FILTER_RANGE_MAX_BITS
-            if index >= (KVM_MSR_FILTER_RANGE_MAX_BITS as u32) {
-                continue;
-            }
-            wr_nmsrs += 1;
-            wr_msr_bitmap[(index / 8) as usize] &= !(1 << (index & 0x7));
-        }
-
-        let mut msr_filter = kvm_msr_filter {
-            flags: KVM_MSR_FILTER_DEFAULT_ALLOW,
-            ..Default::default()
-        };
-
-        let mut count = 0;
-        if rd_nmsrs > 0 {
-            msr_filter.ranges[count].flags = KVM_MSR_FILTER_READ;
-            msr_filter.ranges[count].nmsrs = KVM_MSR_FILTER_RANGE_MAX_BITS as u32;
-            msr_filter.ranges[count].base = 0x0;
-            msr_filter.ranges[count].bitmap = rd_msr_bitmap.as_mut_ptr();
-            count += 1;
-        }
-        if wr_nmsrs > 0 {
-            msr_filter.ranges[count].flags = KVM_MSR_FILTER_WRITE;
-            msr_filter.ranges[count].nmsrs = KVM_MSR_FILTER_RANGE_MAX_BITS as u32;
-            msr_filter.ranges[count].base = 0x0;
-            msr_filter.ranges[count].bitmap = wr_msr_bitmap.as_mut_ptr();
-            count += 1;
-        }
-
-        let mut ret = 0;
-        if count > 0 {
-            // SAFETY:
-            // Safe because we know that our file is a VM fd, we know that the
-            // kernel will only read correct amount of memory from our pointer, and
-            // we verify the return result.
-            ret = unsafe { ioctl_with_ref(self, KVM_X86_SET_MSR_FILTER(), &msr_filter) };
-        }
-
+        let ret = unsafe { ioctl_with_ref(self, KVM_ENABLE_CAP, &cap) };
         if ret < 0 {
             errno_result()
         } else {
@@ -529,7 +444,7 @@ impl KvmVm {
         // SAFETY:
         // safe becuase we allocated the struct and we know the kernel will read
         // exactly the size of the struct
-        let ret = unsafe { ioctl_with_ref(self, KVM_ENABLE_CAP(), &cap) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_ENABLE_CAP, &cap) };
         if ret < 0 {
             errno_result()
         } else {
@@ -555,7 +470,7 @@ impl VmX86_64 for KvmVm {
     fn set_tss_addr(&self, addr: GuestAddress) -> Result<()> {
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let ret = unsafe { ioctl_with_val(self, KVM_SET_TSS_ADDR(), addr.offset()) };
+        let ret = unsafe { ioctl_with_val(self, KVM_SET_TSS_ADDR, addr.offset()) };
         if ret == 0 {
             Ok(())
         } else {
@@ -569,7 +484,7 @@ impl VmX86_64 for KvmVm {
     fn set_identity_map_addr(&self, addr: GuestAddress) -> Result<()> {
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IDENTITY_MAP_ADDR(), &addr.offset()) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IDENTITY_MAP_ADDR, &addr.offset()) };
         if ret == 0 {
             Ok(())
         } else {
@@ -595,7 +510,7 @@ impl KvmVcpu {
         let size = {
             // SAFETY:
             // Safe because we know that our file is a valid VM fd
-            unsafe { ioctl_with_val(&self.vm, KVM_CHECK_EXTENSION(), KVM_CAP_XSAVE2 as u64) }
+            unsafe { ioctl_with_val(&self.vm, KVM_CHECK_EXTENSION, KVM_CAP_XSAVE2 as u64) }
         };
         if size < 0 {
             return errno_result();
@@ -604,6 +519,25 @@ impl KvmVcpu {
         let size: usize = size.try_into().unwrap();
         Ok(size.max(KVM_XSAVE_MAX_SIZE))
     }
+
+    #[inline]
+    pub(crate) fn handle_vm_exit_arch(&self, run: &mut kvm_run) -> Option<VcpuExit> {
+        match run.exit_reason {
+            KVM_EXIT_IO => Some(VcpuExit::Io),
+            KVM_EXIT_IOAPIC_EOI => {
+                // SAFETY:
+                // Safe because the exit_reason (which comes from the kernel) told us which
+                // union field to use.
+                let vector = unsafe { run.__bindgen_anon_1.eoi.vector };
+                Some(VcpuExit::IoapicEoi { vector })
+            }
+            KVM_EXIT_HLT => Some(VcpuExit::Hlt),
+            KVM_EXIT_SET_TPR => Some(VcpuExit::SetTpr),
+            KVM_EXIT_TPR_ACCESS => Some(VcpuExit::TprAccess),
+            KVM_EXIT_X86_BUS_LOCK => Some(VcpuExit::BusLock),
+            _ => None,
+        }
+    }
 }
 
 impl VcpuX86_64 for KvmVcpu {
@@ -631,12 +565,16 @@ impl VcpuX86_64 for KvmVcpu {
     ///
     /// While this ioctl exists on PPC and MIPS as well as x86, the semantics are different and
     /// ChromeOS doesn't support PPC or MIPS.
-    fn interrupt(&self, irq: u32) -> Result<()> {
-        let interrupt = kvm_interrupt { irq };
+    fn interrupt(&self, irq: u8) -> Result<()> {
+        if !self.ready_for_interrupt() {
+            return Err(Error::new(EAGAIN));
+        }
+
+        let interrupt = kvm_interrupt { irq: irq.into() };
         // SAFETY:
         // safe becuase we allocated the struct and we know the kernel will read
         // exactly the size of the struct
-        let ret = unsafe { ioctl_with_ref(self, KVM_INTERRUPT(), &interrupt) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_INTERRUPT, &interrupt) };
         if ret == 0 {
             Ok(())
         } else {
@@ -647,7 +585,7 @@ impl VcpuX86_64 for KvmVcpu {
     fn inject_nmi(&self) -> Result<()> {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd.
-        let ret = unsafe { ioctl(self, KVM_NMI()) };
+        let ret = unsafe { ioctl(self, KVM_NMI) };
         if ret == 0 {
             Ok(())
         } else {
@@ -662,7 +600,7 @@ impl VcpuX86_64 for KvmVcpu {
             // Safe because we know that our file is a VCPU fd, we know the kernel will only read
             // the correct amount of memory from our pointer, and we verify the return
             // result.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_REGS(), &mut regs) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_REGS, &mut regs) }
         };
         if ret == 0 {
             Ok(Regs::from(&regs))
@@ -678,7 +616,7 @@ impl VcpuX86_64 for KvmVcpu {
             // Safe because we know that our file is a VCPU fd, we know the kernel will only read
             // the correct amount of memory from our pointer, and we verify the return
             // result.
-            unsafe { ioctl_with_ref(self, KVM_SET_REGS(), &regs) }
+            unsafe { ioctl_with_ref(self, KVM_SET_REGS, &regs) }
         };
         if ret == 0 {
             Ok(())
@@ -694,7 +632,7 @@ impl VcpuX86_64 for KvmVcpu {
             // Safe because we know that our file is a VCPU fd, we know the kernel will only write
             // the correct amount of memory to our pointer, and we verify the return
             // result.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS(), &mut regs) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS, &mut regs) }
         };
         if ret == 0 {
             Ok(Sregs::from(&regs))
@@ -710,7 +648,7 @@ impl VcpuX86_64 for KvmVcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS(), &mut kvm_sregs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS, &mut kvm_sregs) };
         if ret != 0 {
             return errno_result();
         }
@@ -735,7 +673,7 @@ impl VcpuX86_64 for KvmVcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_SREGS(), &kvm_sregs) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_SREGS, &kvm_sregs) };
         if ret == 0 {
             Ok(())
         } else {
@@ -748,7 +686,7 @@ impl VcpuX86_64 for KvmVcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_FPU(), &mut fpu) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_FPU, &mut fpu) };
         if ret == 0 {
             Ok(Fpu::from(&fpu))
         } else {
@@ -761,7 +699,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_fpu struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_FPU(), &fpu) }
+            unsafe { ioctl_with_ref(self, KVM_SET_FPU, &fpu) }
         };
         if ret == 0 {
             Ok(())
@@ -774,9 +712,9 @@ impl VcpuX86_64 for KvmVcpu {
     fn get_xsave(&self) -> Result<Xsave> {
         let size = self.xsave_size()?;
         let ioctl_nr = if size > KVM_XSAVE_MAX_SIZE {
-            KVM_GET_XSAVE2()
+            KVM_GET_XSAVE2
         } else {
-            KVM_GET_XSAVE()
+            KVM_GET_XSAVE
         };
         let mut xsave = Xsave::new(size);
 
@@ -804,7 +742,7 @@ impl VcpuX86_64 for KvmVcpu {
         // correct amount of memory to our pointer, and we verify the return result.
         // Because of the len check above, and because the layout of `struct kvm_xsave` is
         // compatible with a slice of `u32`, we can pass the pointer to `xsave` directly.
-        let ret = unsafe { ioctl_with_ptr(self, KVM_SET_XSAVE(), xsave.as_ptr()) };
+        let ret = unsafe { ioctl_with_ptr(self, KVM_SET_XSAVE, xsave.as_ptr()) };
         if ret == 0 {
             Ok(())
         } else {
@@ -819,7 +757,7 @@ impl VcpuX86_64 for KvmVcpu {
             // Safe because we know that our file is a VCPU fd, we know the kernel will only write
             // the correct amount of memory to our pointer, and we verify the return
             // result.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_VCPU_EVENTS(), &mut vcpu_evts) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_VCPU_EVENTS, &mut vcpu_evts) }
         };
         if ret == 0 {
             Ok(
@@ -844,7 +782,7 @@ impl VcpuX86_64 for KvmVcpu {
             // Safe because we know that our file is a VCPU fd, we know the kernel will only read
             // the correct amount of memory from our pointer, and we verify the return
             // result.
-            unsafe { ioctl_with_ref(self, KVM_SET_VCPU_EVENTS(), &vcpu_events) }
+            unsafe { ioctl_with_ref(self, KVM_SET_VCPU_EVENTS, &vcpu_events) }
         };
         if ret == 0 {
             Ok(())
@@ -858,7 +796,7 @@ impl VcpuX86_64 for KvmVcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_DEBUGREGS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_DEBUGREGS, &mut regs) };
         if ret == 0 {
             Ok(DebugRegs::from(&regs))
         } else {
@@ -871,7 +809,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_debugregs struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_DEBUGREGS(), &dregs) }
+            unsafe { ioctl_with_ref(self, KVM_SET_DEBUGREGS, &dregs) }
         };
         if ret == 0 {
             Ok(())
@@ -885,7 +823,7 @@ impl VcpuX86_64 for KvmVcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_XCRS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_XCRS, &mut regs) };
         if ret < 0 {
             return errno_result();
         }
@@ -909,7 +847,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_xcrs struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_XCRS(), &kvm_xcr) }
+            unsafe { ioctl_with_ref(self, KVM_SET_XCRS, &kvm_xcr) }
         };
         if ret == 0 {
             Ok(())
@@ -931,7 +869,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read or write past the end of the kvm_msrs struct.
-            unsafe { ioctl_with_ref(self, KVM_GET_MSRS(), &msrs[0]) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_MSRS, &mut msrs[0]) }
         };
         if ret < 0 {
             return errno_result();
@@ -971,7 +909,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read or write past the end of the kvm_msrs struct.
-            unsafe { ioctl_with_ref(self, KVM_GET_MSRS(), &kvm_msrs[0]) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_MSRS, &mut kvm_msrs[0]) }
         };
         if ret < 0 {
             return errno_result();
@@ -1017,7 +955,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_msrs struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_MSRS(), &kvm_msrs[0]) }
+            unsafe { ioctl_with_ref(self, KVM_SET_MSRS, &kvm_msrs[0]) }
         };
         if ret < 0 {
             return errno_result();
@@ -1037,7 +975,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_msrs struct.
-            unsafe { ioctl_with_ptr(self, KVM_SET_CPUID2(), cpuid.as_ptr()) }
+            unsafe { ioctl_with_ptr(self, KVM_SET_CPUID2, cpuid.as_ptr()) }
         };
         if ret == 0 {
             Ok(())
@@ -1046,11 +984,6 @@ impl VcpuX86_64 for KvmVcpu {
         }
     }
 
-    fn get_hyperv_cpuid(&self) -> Result<CpuId> {
-        const KVM_MAX_ENTRIES: usize = 256;
-        get_cpuid_with_initial_capacity(self, KVM_GET_SUPPORTED_HV_CPUID(), KVM_MAX_ENTRIES)
-    }
-
     fn set_guest_debug(&self, addrs: &[GuestAddress], enable_singlestep: bool) -> Result<()> {
         use kvm_sys::*;
         let mut dbg: kvm_guest_debug = Default::default();
@@ -1082,7 +1015,7 @@ impl VcpuX86_64 for KvmVcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_guest_debug struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_GUEST_DEBUG(), &dbg) }
+            unsafe { ioctl_with_ref(self, KVM_SET_GUEST_DEBUG, &dbg) }
         };
         if ret == 0 {
             Ok(())
@@ -1114,7 +1047,7 @@ impl KvmVcpu {
             // SAFETY:
             // The ioctl is unsafe unless you trust the kernel not to write past the end of the
             // local_apic struct.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_LAPIC(), &mut klapic) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_LAPIC, &mut klapic) }
         };
         if ret < 0 {
             return errno_result();
@@ -1130,7 +1063,7 @@ impl KvmVcpu {
         let ret = {
             // SAFETY:
             // The ioctl is safe because the kernel will only read from the klapic struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_LAPIC(), klapic) }
+            unsafe { ioctl_with_ref(self, KVM_SET_LAPIC, klapic) }
         };
         if ret < 0 {
             return errno_result();
@@ -1160,7 +1093,7 @@ impl KvmVcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS, &mut regs) };
         if ret >= 0 {
             Ok(regs.interrupt_bitmap)
         } else {
@@ -1179,14 +1112,14 @@ impl KvmVcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS, &mut regs) };
         if ret >= 0 {
             regs.interrupt_bitmap = interrupt_bitmap;
             // SAFETY:
             // Safe because we know that our file is a VCPU fd, we know the kernel will only read
             // the correct amount of memory from our pointer, and we verify the return
             // result.
-            let ret = unsafe { ioctl_with_ref(self, KVM_SET_SREGS(), &regs) };
+            let ret = unsafe { ioctl_with_ref(self, KVM_SET_SREGS, &regs) };
             if ret >= 0 {
                 Ok(())
             } else {
@@ -1665,7 +1598,7 @@ impl From<&kvm_segment> for Segment {
     fn from(s: &kvm_segment) -> Self {
         Segment {
             base: s.base,
-            limit: s.limit,
+            limit_bytes: s.limit,
             selector: s.selector,
             type_: s.type_,
             present: s.present,
@@ -1683,7 +1616,7 @@ impl From<&Segment> for kvm_segment {
     fn from(s: &Segment) -> Self {
         kvm_segment {
             base: s.base,
-            limit: s.limit,
+            limit: s.limit_bytes,
             selector: s.selector,
             type_: s.type_,
             present: s.present,
@@ -1747,7 +1680,7 @@ impl From<&kvm_sregs> for Sregs {
 impl From<&kvm_fpu> for Fpu {
     fn from(r: &kvm_fpu) -> Self {
         Fpu {
-            fpr: r.fpr,
+            fpr: FpuReg::from_16byte_arrays(&r.fpr),
             fcw: r.fcw,
             fsw: r.fsw,
             ftwx: r.ftwx,
@@ -1763,7 +1696,7 @@ impl From<&kvm_fpu> for Fpu {
 impl From<&Fpu> for kvm_fpu {
     fn from(r: &Fpu) -> Self {
         kvm_fpu {
-            fpr: r.fpr,
+            fpr: FpuReg::to_16byte_arrays(&r.fpr),
             fcw: r.fcw,
             fsw: r.fsw,
             ftwx: r.ftwx,
diff --git a/hypervisor/src/lib.rs b/hypervisor/src/lib.rs
index 247af37dc..ede57408d 100644
--- a/hypervisor/src/lib.rs
+++ b/hypervisor/src/lib.rs
@@ -56,9 +56,27 @@ pub struct MemRegion {
     pub size: u64,
 }
 
+/// Signal to the hypervisor on kernels that support the KVM_CAP_USER_CONFIGURE_NONCOHERENT_DMA (or
+/// equivalent) that during user memory region (memslot) configuration, a guest page's memtype
+/// should be considered in SLAT effective memtype determination rather than implicitly respecting
+/// only the host page's memtype.
+///
+/// This explicit control is needed for Virtio devices (e.g. gpu) that configure memslots for host
+/// WB page mappings with guest WC page mappings. See b/316337317, b/360295883 for more detail.
 #[derive(Copy, Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
 pub enum MemCacheType {
+    /// Don't provide any explicit instruction to the hypervisor on how it should determine a
+    /// memslot's effective memtype.
+    ///
+    /// On KVM-VMX (Intel), this means that the memslot is flagged with VMX_EPT_IPAT_BIT such that
+    /// only the host memtype is respected.
     CacheCoherent,
+    /// explicitly instruct the hypervisor to respect the guest page's memtype when determining the
+    /// memslot's effective memtype.
+    ///
+    /// On KVM-VMX (Intel), this means the memslot is NOT flagged with VMX_EPT_IPAT_BIT, and the
+    /// effective memtype will generally decay to the weaker amongst the host/guest memtypes and
+    /// the MTRR for the physical address.
     CacheNonCoherent,
 }
 
@@ -146,6 +164,28 @@ pub trait Vm: Send {
     /// `offset` from the start of the region.  `offset` must be page aligned.
     fn msync_memory_region(&mut self, slot: MemSlot, offset: usize, size: usize) -> Result<()>;
 
+    /// Gives a MADV_PAGEOUT advice to the memory region mapped at `slot`, with the address range
+    /// starting at `offset` from the start of the region, and with size `size`. `offset`
+    /// must be page aligned.
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    fn madvise_pageout_memory_region(
+        &mut self,
+        slot: MemSlot,
+        offset: usize,
+        size: usize,
+    ) -> Result<()>;
+
+    /// Gives a MADV_REMOVE advice to the memory region mapped at `slot`, with the address range
+    /// starting at `offset` from the start of the region, and with size `size`. `offset`
+    /// must be page aligned.
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    fn madvise_remove_memory_region(
+        &mut self,
+        slot: MemSlot,
+        offset: usize,
+        size: usize,
+    ) -> Result<()>;
+
     /// Removes and drops the `UserMemoryRegion` that was previously added at the given slot.
     fn remove_memory_region(&mut self, slot: MemSlot) -> Result<Box<dyn MappedRegion>>;
 
@@ -310,7 +350,10 @@ pub trait Vcpu: downcast_rs::DowncastSync {
     /// Once called, it will determine whether a MMIO read or MMIO write was the reason for the MMIO
     /// exit, call `handle_fn` with the respective IoParams to perform the MMIO read or write, and
     /// set the return data in the vcpu so that the vcpu can resume running.
-    fn handle_mmio(&self, handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()>;
+    fn handle_mmio(
+        &self,
+        handle_fn: &mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>,
+    ) -> Result<()>;
 
     /// Handles an incoming PIO from the guest.
     ///
@@ -322,29 +365,6 @@ pub trait Vcpu: downcast_rs::DowncastSync {
     /// the return data in the vcpu so that the vcpu can resume running.
     fn handle_io(&self, handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()>;
 
-    /// Handles the HYPERV_HYPERCALL exit from a vcpu.
-    ///
-    /// This function should be called after `Vcpu::run` returns `VcpuExit::HypervHcall`, and in the
-    /// same thread as run.
-    ///
-    /// Once called, it will parse the appropriate input parameters to the provided function to
-    /// handle the hyperv call, and then set the return data into the vcpu so it can resume running.
-    fn handle_hyperv_hypercall(&self, func: &mut dyn FnMut(HypervHypercall) -> u64) -> Result<()>;
-
-    /// Handles a RDMSR exit from the guest.
-    ///
-    /// This function should be called after `Vcpu::run` returns `VcpuExit::RdMsr`,
-    /// and in the same thread as run.
-    ///
-    /// It will put `data` into the guest buffer and return.
-    fn handle_rdmsr(&self, data: u64) -> Result<()>;
-
-    /// Handles a WRMSR exit from the guest by removing any error indication for the operation.
-    ///
-    /// This function should be called after `Vcpu::run` returns `VcpuExit::WrMsr`,
-    /// and in the same thread as run.
-    fn handle_wrmsr(&self);
-
     /// Signals to the hypervisor that this Vcpu is being paused by userspace.
     fn on_suspend(&self) -> Result<()>;
 
@@ -377,6 +397,40 @@ pub enum Datamatch {
     U64(Option<u64>),
 }
 
+#[derive(Copy, Clone, Debug)]
+pub enum VcpuShutdownErrorKind {
+    DoubleFault,
+    TripleFault,
+    Other,
+}
+
+/// A Vcpu shutdown may signify an error, such as a double or triple fault,
+/// or hypervisor specific reasons. This error covers all such cases.
+#[derive(Copy, Clone, Debug)]
+pub struct VcpuShutdownError {
+    kind: VcpuShutdownErrorKind,
+    raw_error_code: u64,
+}
+
+impl VcpuShutdownError {
+    pub fn new(kind: VcpuShutdownErrorKind, raw_error_code: u64) -> VcpuShutdownError {
+        Self {
+            kind,
+            raw_error_code,
+        }
+    }
+    pub fn kind(&self) -> VcpuShutdownErrorKind {
+        self.kind
+    }
+    pub fn get_raw_error_code(&self) -> u64 {
+        self.raw_error_code
+    }
+}
+
+// Note that when adding entries to the VcpuExit enum you may want to add corresponding entries in
+// crosvm::stats::exit_to_index and crosvm::stats::exit_index_to_str if you don't want the new
+// exit type to be categorized as "Unknown".
+
 /// A reason why a VCPU exited. One of these returns every time `Vcpu::run` is called.
 #[derive(Debug, Clone, Copy)]
 pub enum VcpuExit {
@@ -389,41 +443,22 @@ pub enum VcpuExit {
     IoapicEoi {
         vector: u8,
     },
-    HypervHypercall,
-    Unknown,
     Exception,
     Hypercall,
     Debug,
     Hlt,
     IrqWindowOpen,
-    Shutdown,
+    Shutdown(std::result::Result<(), VcpuShutdownError>),
     FailEntry {
         hardware_entry_failure_reason: u64,
     },
     Intr,
     SetTpr,
     TprAccess,
-    S390Sieic,
-    S390Reset,
-    Dcr,
-    Nmi,
     InternalError,
-    Osi,
-    PaprHcall,
-    S390Ucontrol,
-    Watchdog,
-    S390Tsch,
-    Epr,
     SystemEventShutdown,
     SystemEventReset,
     SystemEventCrash,
-    RdMsr {
-        index: u32,
-    },
-    WrMsr {
-        index: u32,
-        data: u64,
-    },
     /// An invalid vcpu register was set while running.
     InvalidVpRegister,
     /// incorrect setup for vcpu requiring an unsupported feature
@@ -462,21 +497,6 @@ pub enum VcpuExit {
     },
 }
 
-/// A hypercall with parameters being made from the guest.
-#[derive(Debug)]
-pub enum HypervHypercall {
-    HypervSynic {
-        msr: u32,
-        control: u64,
-        evt_page: u64,
-        msg_page: u64,
-    },
-    HypervHcall {
-        input: u64,
-        params: [u64; 2],
-    },
-}
-
 /// A device type to create with `Vm.create_device`.
 #[derive(Clone, Copy, Debug, PartialEq, Eq)]
 pub enum DeviceKind {
@@ -576,7 +596,7 @@ impl ProtectionType {
     }
 
     /// Returns whether the VMM needs to load the pVM firmware.
-    pub fn loads_firmware(&self) -> bool {
+    pub fn needs_firmware_loaded(&self) -> bool {
         matches!(
             self,
             Self::UnprotectedWithFirmware | Self::ProtectedWithCustomFirmware
@@ -585,7 +605,7 @@ impl ProtectionType {
 
     /// Returns whether the VM runs a pVM firmware.
     pub fn runs_firmware(&self) -> bool {
-        self.loads_firmware() || matches!(self, Self::Protected)
+        self.needs_firmware_loaded() || matches!(self, Self::Protected)
     }
 }
 
diff --git a/hypervisor/src/whpx/types.rs b/hypervisor/src/whpx/types.rs
index 9c61c3cc9..3826a7fcf 100644
--- a/hypervisor/src/whpx/types.rs
+++ b/hypervisor/src/whpx/types.rs
@@ -13,6 +13,7 @@ use crate::CpuIdEntry;
 use crate::DebugRegs;
 use crate::DescriptorTable;
 use crate::Fpu;
+use crate::FpuReg;
 use crate::LapicState;
 use crate::Regs;
 use crate::Segment;
@@ -124,7 +125,7 @@ impl From<&Segment> for WHV_X64_SEGMENT_REGISTER {
         );
         WHV_X64_SEGMENT_REGISTER {
             Base: segment.base,
-            Limit: segment.limit,
+            Limit: segment.limit_bytes,
             Selector: segment.selector,
             __bindgen_anon_1: WHV_X64_SEGMENT_REGISTER__bindgen_ty_1 {
                 __bindgen_anon_1: WHV_X64_SEGMENT_REGISTER__bindgen_ty_1__bindgen_ty_1 {
@@ -142,7 +143,7 @@ impl From<&WHV_X64_SEGMENT_REGISTER> for Segment {
         let attributes = unsafe { whpx_segment.__bindgen_anon_1.__bindgen_anon_1 };
         Segment {
             base: whpx_segment.Base,
-            limit: whpx_segment.Limit,
+            limit_bytes: whpx_segment.Limit,
             selector: whpx_segment.Selector,
             type_: attributes.SegmentType() as u8,
             present: attributes.Present() as u8,
@@ -280,22 +281,35 @@ impl From<&WhpxSregs> for Sregs {
     }
 }
 
-impl From<&[u8; 16]> for WHV_UINT128 {
-    fn from(bytes: &[u8; 16]) -> WHV_UINT128 {
+impl From<u128> for WHV_UINT128 {
+    fn from(v: u128) -> WHV_UINT128 {
         WHV_UINT128 {
-            // safe because the u8, 16 should really be a u128. We are just transmuting
-            // to fill in the union field.
-            Dword: unsafe { std::mem::transmute::<[u8; 16], [u32; 4]>(*bytes) },
+            __bindgen_anon_1: WHV_UINT128__bindgen_ty_1 {
+                Low64: v as u64,
+                High64: (v >> 64) as u64,
+            },
         }
     }
 }
 
-impl From<&WHV_UINT128> for u128 {
-    fn from(regs: &WHV_UINT128) -> u128 {
-        // whpx bindings have two u64 or an array of u32 which we can transmute into u128.
-        // whpx does not have a union that interprets them as bytes so we can use from/to_ne_bytes.
-        // safe because this is union, that can be safely casted as a u128.
-        unsafe { std::mem::transmute::<[u32; 4], u128>(regs.Dword) }
+impl From<WHV_UINT128> for u128 {
+    fn from(v: WHV_UINT128) -> u128 {
+        // SAFETY: Accessing u64 fields of the union is always safe since all bit patterns are valid
+        // for u64.
+        let (low64, high64) = unsafe { (v.__bindgen_anon_1.Low64, v.__bindgen_anon_1.High64) };
+        u128::from(low64) | (u128::from(high64) << 64)
+    }
+}
+
+impl WHV_UINT128 {
+    #[inline]
+    pub fn from_ne_bytes(bytes: [u8; 16]) -> WHV_UINT128 {
+        WHV_UINT128::from(u128::from_ne_bytes(bytes))
+    }
+
+    #[inline]
+    pub fn to_ne_bytes(self) -> [u8; 16] {
+        u128::from(self).to_ne_bytes()
     }
 }
 
@@ -344,50 +358,26 @@ impl WhpxFpu {
     }
 }
 
+fn whpx_register_from_fpu_reg(fpr: FpuReg) -> WHV_REGISTER_VALUE {
+    WHV_REGISTER_VALUE {
+        Fp: WHV_X64_FP_REGISTER {
+            AsUINT128: WHV_UINT128::from_ne_bytes(fpr.into()),
+        },
+    }
+}
+
 impl From<&Fpu> for WhpxFpu {
     fn from(fpu: &Fpu) -> Self {
         WhpxFpu {
             register_values: [
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[0]),
-                    },
-                },
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[1]),
-                    },
-                },
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[2]),
-                    },
-                },
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[3]),
-                    },
-                },
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[4]),
-                    },
-                },
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[5]),
-                    },
-                },
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[6]),
-                    },
-                },
-                WHV_REGISTER_VALUE {
-                    Fp: WHV_X64_FP_REGISTER {
-                        AsUINT128: WHV_UINT128::from(&fpu.fpr[7]),
-                    },
-                },
+                whpx_register_from_fpu_reg(fpu.fpr[0]),
+                whpx_register_from_fpu_reg(fpu.fpr[1]),
+                whpx_register_from_fpu_reg(fpu.fpr[2]),
+                whpx_register_from_fpu_reg(fpu.fpr[3]),
+                whpx_register_from_fpu_reg(fpu.fpr[4]),
+                whpx_register_from_fpu_reg(fpu.fpr[5]),
+                whpx_register_from_fpu_reg(fpu.fpr[6]),
+                whpx_register_from_fpu_reg(fpu.fpr[7]),
                 WHV_REGISTER_VALUE {
                     FpControlStatus: WHV_X64_FP_CONTROL_STATUS_REGISTER {
                         __bindgen_anon_1: WHV_X64_FP_CONTROL_STATUS_REGISTER__bindgen_ty_1 {
@@ -416,58 +406,67 @@ impl From<&Fpu> for WhpxFpu {
                     },
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[0]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[0]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[1]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[1]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[2]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[2]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[3]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[3]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[4]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[4]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[5]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[5]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[6]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[6]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[7]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[7]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[8]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[8]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[9]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[9]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[10]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[10]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[11]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[11]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[12]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[12]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[13]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[13]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[14]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[14]),
                 },
                 WHV_REGISTER_VALUE {
-                    Reg128: WHV_UINT128::from(&fpu.xmm[15]),
+                    Reg128: WHV_UINT128::from_ne_bytes(fpu.xmm[15]),
                 },
             ],
         }
     }
 }
 
+fn fpu_reg_from_whpx_register(whpx_reg: &WHV_REGISTER_VALUE) -> FpuReg {
+    let fp_reg_bytes: [u8; 10] = unsafe {
+        whpx_reg.Fp.AsUINT128.to_ne_bytes()[0..10]
+            .try_into()
+            .unwrap()
+    };
+    FpuReg::from(fp_reg_bytes)
+}
+
 impl From<&WhpxFpu> for Fpu {
     fn from(whpx_regs: &WhpxFpu) -> Self {
         unsafe {
@@ -479,14 +478,14 @@ impl From<&WhpxFpu> for Fpu {
                 .__bindgen_anon_1;
             Fpu {
                 fpr: [
-                    u128::from(&whpx_regs.register_values[0].Fp.AsUINT128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[1].Fp.AsUINT128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[2].Fp.AsUINT128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[3].Fp.AsUINT128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[4].Fp.AsUINT128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[5].Fp.AsUINT128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[6].Fp.AsUINT128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[7].Fp.AsUINT128).to_ne_bytes(),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[0]),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[1]),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[2]),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[3]),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[4]),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[5]),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[6]),
+                    fpu_reg_from_whpx_register(&whpx_regs.register_values[7]),
                 ],
                 fcw: fp_control.FpControl,
                 fsw: fp_control.FpStatus,
@@ -495,22 +494,22 @@ impl From<&WhpxFpu> for Fpu {
                 last_ip: fp_control.__bindgen_anon_1.LastFpRip,
                 last_dp: xmm_control.__bindgen_anon_1.LastFpRdp,
                 xmm: [
-                    u128::from(&whpx_regs.register_values[10].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[11].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[12].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[13].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[14].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[15].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[16].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[17].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[18].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[19].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[20].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[21].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[22].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[23].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[24].Reg128).to_ne_bytes(),
-                    u128::from(&whpx_regs.register_values[25].Reg128).to_ne_bytes(),
+                    whpx_regs.register_values[10].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[11].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[12].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[13].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[14].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[15].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[16].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[17].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[18].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[19].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[20].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[21].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[22].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[23].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[24].Reg128.to_ne_bytes(),
+                    whpx_regs.register_values[25].Reg128.to_ne_bytes(),
                 ],
                 mxcsr: xmm_control.XmmStatusControl,
             }
diff --git a/hypervisor/src/whpx/vcpu.rs b/hypervisor/src/whpx/vcpu.rs
index fd3e93bb2..5f6297ced 100644
--- a/hypervisor/src/whpx/vcpu.rs
+++ b/hypervisor/src/whpx/vcpu.rs
@@ -25,7 +25,6 @@ use crate::CpuId;
 use crate::CpuIdEntry;
 use crate::DebugRegs;
 use crate::Fpu;
-use crate::HypervHypercall;
 use crate::IoOperation;
 use crate::IoParams;
 use crate::Regs;
@@ -106,7 +105,7 @@ trait InstructionEmulatorCallbacks {
 struct InstructionEmulatorContext<'a> {
     vm_partition: Arc<SafePartition>,
     index: u32,
-    handle_mmio: Option<&'a mut dyn FnMut(IoParams) -> Option<[u8; 8]>>,
+    handle_mmio: Option<&'a mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>>,
     handle_io: Option<&'a mut dyn FnMut(IoParams) -> Option<[u8; 8]>>,
 }
 
@@ -175,32 +174,43 @@ impl InstructionEmulatorCallbacks for SafeInstructionEmulator {
         let size = memory_access_info.AccessSize as usize;
         match memory_access_info.Direction {
             WHPX_EXIT_DIRECTION_MMIO_READ => {
-                if let Some(handle_mmio) = &mut ctx.handle_mmio {
-                    if let Some(data) = handle_mmio(IoParams {
-                        address,
-                        size,
-                        operation: IoOperation::Read,
-                    }) {
-                        memory_access_info.Data = data;
-                    }
-                    S_OK
-                } else {
-                    E_UNEXPECTED
-                }
+                ctx.handle_mmio
+                    .as_mut()
+                    .map_or(E_UNEXPECTED, |handle_mmio| {
+                        handle_mmio(IoParams {
+                            address,
+                            size,
+                            operation: IoOperation::Read,
+                        })
+                        .map_err(|e| {
+                            error!("handle_mmio failed with {e}");
+                            e
+                        })
+                        .ok()
+                        .flatten()
+                        .map_or(E_UNEXPECTED, |data| {
+                            memory_access_info.Data = data;
+                            S_OK
+                        })
+                    })
             }
             WHPX_EXIT_DIRECTION_MMIO_WRITE => {
-                if let Some(handle_mmio) = &mut ctx.handle_mmio {
-                    handle_mmio(IoParams {
-                        address,
-                        size,
-                        operation: IoOperation::Write {
-                            data: memory_access_info.Data,
-                        },
-                    });
-                    S_OK
-                } else {
-                    E_UNEXPECTED
-                }
+                ctx.handle_mmio
+                    .as_mut()
+                    .map_or(E_UNEXPECTED, |handle_mmio| {
+                        handle_mmio(IoParams {
+                            address,
+                            size,
+                            operation: IoOperation::Write {
+                                data: memory_access_info.Data,
+                            },
+                        })
+                        .map_err(|e| {
+                            error!("handle_mmio failed with {e}");
+                            e
+                        })
+                        .map_or(E_UNEXPECTED, |_| S_OK)
+                    })
             }
             _ => E_UNEXPECTED,
         }
@@ -549,7 +559,10 @@ impl Vcpu for WhpxVcpu {
     /// Once called, it will determine whether a mmio read or mmio write was the reason for the mmio
     /// exit, call `handle_fn` with the respective IoOperation to perform the mmio read or
     /// write, and set the return data in the vcpu so that the vcpu can resume running.
-    fn handle_mmio(&self, handle_fn: &mut dyn FnMut(IoParams) -> Option<[u8; 8]>) -> Result<()> {
+    fn handle_mmio(
+        &self,
+        handle_fn: &mut dyn FnMut(IoParams) -> Result<Option<[u8; 8]>>,
+    ) -> Result<()> {
         let mut status: WHV_EMULATOR_STATUS = Default::default();
         let mut ctx = InstructionEmulatorContext {
             vm_partition: self.vm_partition.clone(),
@@ -572,6 +585,7 @@ impl Vcpu for WhpxVcpu {
         if success {
             Ok(())
         } else {
+            self.inject_gp_fault()?;
             // safe because we trust the kernel to fill in the union field properly.
             Err(Error::new(unsafe { status.AsUINT32 }))
         }
@@ -609,26 +623,6 @@ impl Vcpu for WhpxVcpu {
         }
     }
 
-    /// this is unhandled currently since we don't emulate hypercall instructions for whpx.
-    fn handle_hyperv_hypercall(&self, _func: &mut dyn FnMut(HypervHypercall) -> u64) -> Result<()> {
-        Ok(())
-    }
-
-    /// This function should be called after `Vcpu::run` returns `VcpuExit::RdMsr`,
-    /// and in the same thread as run.
-    ///
-    /// It will put `data` into the user buffer and return.
-    fn handle_rdmsr(&self, _data: u64) -> Result<()> {
-        // TODO(b/235691411): Implement.
-        Err(Error::new(libc::ENXIO))
-    }
-
-    /// This function should be called after `Vcpu::run` returns `VcpuExit::WrMsr`,
-    /// and in the same thread as run.
-    fn handle_wrmsr(&self) {
-        // TODO(b/235691411): Implement.
-    }
-
     #[allow(non_upper_case_globals)]
     fn run(&mut self) -> Result<VcpuExit> {
         // safe because we own this whpx virtual processor index, and assume the vm partition is
@@ -644,7 +638,6 @@ impl Vcpu for WhpxVcpu {
         })?;
 
         match self.last_exit_context.ExitReason {
-            WHV_RUN_VP_EXIT_REASON_WHvRunVpExitReasonNone => Ok(VcpuExit::Unknown),
             WHV_RUN_VP_EXIT_REASON_WHvRunVpExitReasonMemoryAccess => Ok(VcpuExit::Mmio),
             WHV_RUN_VP_EXIT_REASON_WHvRunVpExitReasonX64IoPortAccess => Ok(VcpuExit::Io),
             WHV_RUN_VP_EXIT_REASON_WHvRunVpExitReasonUnrecoverableException => {
@@ -802,7 +795,7 @@ impl VcpuX86_64 for WhpxVcpu {
     }
 
     /// Injects interrupt vector `irq` into the VCPU.
-    fn interrupt(&self, irq: u32) -> Result<()> {
+    fn interrupt(&self, irq: u8) -> Result<()> {
         const REG_NAMES: [WHV_REGISTER_NAME; 1] =
             [WHV_REGISTER_NAME_WHvRegisterPendingInterruption];
         let mut pending_interrupt: WHV_X64_PENDING_INTERRUPTION_REGISTER__bindgen_ty_1 =
@@ -810,7 +803,7 @@ impl VcpuX86_64 for WhpxVcpu {
         pending_interrupt.set_InterruptionPending(1);
         pending_interrupt
             .set_InterruptionType(WHV_X64_PENDING_INTERRUPTION_TYPE_WHvX64PendingInterrupt as u32);
-        pending_interrupt.set_InterruptionVector(irq);
+        pending_interrupt.set_InterruptionVector(irq.into());
         let interrupt = WHV_REGISTER_VALUE {
             PendingInterruption: WHV_X64_PENDING_INTERRUPTION_REGISTER {
                 __bindgen_anon_1: pending_interrupt,
@@ -1183,17 +1176,24 @@ impl VcpuX86_64 for WhpxVcpu {
 
     /// Sets the value of a single model-specific register.
     fn set_msr(&self, msr_index: u32, value: u64) -> Result<()> {
-        let msr_name = get_msr_name(msr_index).ok_or(Error::new(libc::ENOENT))?;
-        let msr_value = WHV_REGISTER_VALUE { Reg64: value };
-        check_whpx!(unsafe {
-            WHvSetVirtualProcessorRegisters(
-                self.vm_partition.partition,
-                self.index,
-                &msr_name,
-                /* RegisterCount */ 1,
-                &msr_value,
-            )
-        })
+        match get_msr_name(msr_index) {
+            Some(msr_name) => {
+                let msr_value = WHV_REGISTER_VALUE { Reg64: value };
+                check_whpx!(unsafe {
+                    WHvSetVirtualProcessorRegisters(
+                        self.vm_partition.partition,
+                        self.index,
+                        &msr_name,
+                        /* RegisterCount */ 1,
+                        &msr_value,
+                    )
+                })
+            }
+            None => {
+                warn!("msr 0x{msr_index:X} write unsupported by WHPX, dropping");
+                Ok(())
+            }
+        }
     }
 
     /// Sets up the data returned by the CPUID instruction.
@@ -1252,12 +1252,6 @@ impl VcpuX86_64 for WhpxVcpu {
         })
     }
 
-    /// Gets the system emulated hyper-v CPUID values.
-    /// For WHPX, this is not valid on the vcpu, and needs to be setup on the vm.
-    fn get_hyperv_cpuid(&self) -> Result<CpuId> {
-        Err(Error::new(ENXIO))
-    }
-
     /// Sets up debug registers and configure vcpu for handling guest debug events.
     fn set_guest_debug(&self, _addrs: &[GuestAddress], _enable_singlestep: bool) -> Result<()> {
         // TODO(b/173807302): Implement this
@@ -1415,10 +1409,10 @@ mod tests {
         let vcpu = vm.create_vcpu(0).expect("failed to create vcpu");
 
         let mut fpu = vcpu.get_fpu().unwrap();
-        fpu.fpr[0][0] += 3;
+        fpu.fpr[0].significand += 3;
         vcpu.set_fpu(&fpu).unwrap();
         let fpu2 = vcpu.get_fpu().unwrap();
-        assert_eq!(fpu.fpr[0][0], fpu2.fpr[0][0]);
+        assert_eq!(fpu.fpr, fpu2.fpr);
     }
 
     #[test]
diff --git a/hypervisor/src/whpx/whpx_sys/hyperv_tlfs.rs b/hypervisor/src/whpx/whpx_sys/hyperv_tlfs.rs
index 1d838b956..a376b0c43 100644
--- a/hypervisor/src/whpx/whpx_sys/hyperv_tlfs.rs
+++ b/hypervisor/src/whpx/whpx_sys/hyperv_tlfs.rs
@@ -4,7 +4,7 @@
 
 /// Constants from Hyper-V Top Level Functional Specification.
 /// This comes from the document published here:
-/// https://github.com/MicrosoftDocs/Virtualization-Documentation/raw/live/tlfs/Hypervisor%20Top%20Level%20Functional%20Specification%20v6.0b.pdf
+/// <https://github.com/MicrosoftDocs/Virtualization-Documentation/raw/live/tlfs/Hypervisor%20Top%20Level%20Functional%20Specification%20v6.0b.pdf>
 
 /// CPUID Leaf Range Register.
 pub const HYPERV_CPUID_VENDOR_AND_MAX_FUNCTIONS: u32 = 0x40000000;
diff --git a/hypervisor/src/x86_64.rs b/hypervisor/src/x86_64.rs
index fb8a77489..077da2e24 100644
--- a/hypervisor/src/x86_64.rs
+++ b/hypervisor/src/x86_64.rs
@@ -80,7 +80,17 @@ pub trait VcpuX86_64: Vcpu {
     fn ready_for_interrupt(&self) -> bool;
 
     /// Injects interrupt vector `irq` into the VCPU.
-    fn interrupt(&self, irq: u32) -> Result<()>;
+    ///
+    /// This function should only be called when [`Self::ready_for_interrupt`] returns true.
+    /// Otherwise the interrupt injection may fail or the next VCPU run may fail. However, if
+    /// [`Self::interrupt`] returns [`Ok`], the implementation must guarantee that the interrupt
+    /// isn't injected in an uninterruptible window (e.g. right after the mov ss instruction).
+    ///
+    /// The caller should avoid calling this function more than 1 time for one VMEXIT, because the
+    /// hypervisor may behave differently: some hypervisors(e.g. WHPX, KVM) will only try to inject
+    /// the last `irq` requested, while some other hypervisors(e.g. HAXM) may try to inject all
+    /// `irq`s requested.
+    fn interrupt(&self, irq: u8) -> Result<()>;
 
     /// Injects a non-maskable interrupt into the VCPU.
     fn inject_nmi(&self) -> Result<()>;
@@ -141,9 +151,6 @@ pub trait VcpuX86_64: Vcpu {
     /// Sets up the data returned by the CPUID instruction.
     fn set_cpuid(&self, cpuid: &CpuId) -> Result<()>;
 
-    /// Gets the system emulated hyper-v CPUID values.
-    fn get_hyperv_cpuid(&self) -> Result<CpuId>;
-
     /// Sets up debug registers and configure vcpu for handling guest debug events.
     fn set_guest_debug(&self, addrs: &[GuestAddress], enable_singlestep: bool) -> Result<()>;
 
@@ -179,9 +186,9 @@ pub trait VcpuX86_64: Vcpu {
     ///
     /// It sets TSC_OFFSET (VMCS / CB field) by setting the TSC MSR to the current
     /// host TSC value plus the desired offset. We rely on the fact that hypervisors
-    /// determine the value of TSC_OFFSET by computing TSC_OFFSET = new_tsc_value
-    /// - _rdtsc() = _rdtsc() + offset - _rdtsc() ~= offset. Note that the ~= is
-    /// important: this is an approximate operation, because the two _rdtsc() calls
+    /// determine the value of TSC_OFFSET by computing TSC_OFFSET = `new_tsc_value - _rdtsc()` =
+    /// `_rdtsc() + offset - _rdtsc()` ~= `offset`. Note that the ~= is important: this is an
+    /// approximate operation, because the two _rdtsc() calls
     /// are separated by at least a few ticks.
     ///
     /// Note: TSC_OFFSET, host TSC, guest TSC, and TSC MSR are all different
@@ -801,10 +808,11 @@ impl Default for Regs {
 
 /// State of a memory segment.
 #[repr(C)]
-#[derive(Debug, Default, Copy, Clone, Serialize, Deserialize)]
+#[derive(Debug, Default, Copy, Clone, Serialize, Deserialize, PartialEq, Eq)]
 pub struct Segment {
     pub base: u64,
-    pub limit: u32,
+    /// Limit of the segment - always in bytes, regardless of granularity (`g`) field.
+    pub limit_bytes: u32,
     pub selector: u16,
     pub type_: u8,
     pub present: u8,
@@ -864,7 +872,7 @@ impl Default for Sregs {
         // 16-bit real-mode code segment (reset vector).
         let code_seg = Segment {
             base: 0xffff0000,
-            limit: 0xffff,
+            limit_bytes: 0xffff,
             selector: 0xf000,
             type_: SEG_TYPE_CODE | SEG_TYPE_CODE_READABLE | SEG_TYPE_ACCESSED, // 11
             present: 1,
@@ -875,7 +883,7 @@ impl Default for Sregs {
         // 16-bit real-mode data segment.
         let data_seg = Segment {
             base: 0,
-            limit: 0xffff,
+            limit_bytes: 0xffff,
             selector: 0,
             type_: SEG_TYPE_DATA | SEG_TYPE_DATA_WRITABLE | SEG_TYPE_ACCESSED, // 3
             present: 1,
@@ -886,7 +894,7 @@ impl Default for Sregs {
         // 16-bit TSS segment.
         let task_seg = Segment {
             base: 0,
-            limit: 0xffff,
+            limit_bytes: 0xffff,
             selector: 0,
             type_: SEG_TYPE_CODE | SEG_TYPE_CODE_READABLE | SEG_TYPE_ACCESSED, // 11
             present: 1,
@@ -897,7 +905,7 @@ impl Default for Sregs {
         // Local descriptor table.
         let ldt = Segment {
             base: 0,
-            limit: 0xffff,
+            limit_bytes: 0xffff,
             selector: 0,
             type_: SEG_TYPE_DATA | SEG_TYPE_DATA_WRITABLE, // 2
             present: 1,
@@ -941,11 +949,83 @@ impl Default for Sregs {
     }
 }
 
+/// x87 80-bit floating point value.
+#[repr(C)]
+#[derive(Copy, Clone, Debug, Default, Eq, PartialEq, Serialize, Deserialize)]
+pub struct FpuReg {
+    /// 64-bit mantissa.
+    pub significand: u64,
+
+    /// 15-bit biased exponent and sign bit.
+    pub sign_exp: u16,
+}
+
+impl FpuReg {
+    /// Convert an array of 8x16-byte arrays to an array of 8 `FpuReg`.
+    ///
+    /// Ignores any data in the upper 6 bytes of each element; the values represent 80-bit FPU
+    /// registers, so the upper 48 bits are unused.
+    pub fn from_16byte_arrays(byte_arrays: &[[u8; 16]; 8]) -> [FpuReg; 8] {
+        let mut regs = [FpuReg::default(); 8];
+        for (dst, src) in regs.iter_mut().zip(byte_arrays.iter()) {
+            let tbyte: [u8; 10] = src[0..10].try_into().unwrap();
+            *dst = FpuReg::from(tbyte);
+        }
+        regs
+    }
+
+    /// Convert an array of 8 `FpuReg` into 8x16-byte arrays.
+    pub fn to_16byte_arrays(regs: &[FpuReg; 8]) -> [[u8; 16]; 8] {
+        let mut byte_arrays = [[0u8; 16]; 8];
+        for (dst, src) in byte_arrays.iter_mut().zip(regs.iter()) {
+            *dst = (*src).into();
+        }
+        byte_arrays
+    }
+}
+
+impl From<[u8; 10]> for FpuReg {
+    /// Construct a `FpuReg` from an 80-bit representation.
+    fn from(value: [u8; 10]) -> FpuReg {
+        // These array sub-slices can't fail, but there's no (safe) way to express that in Rust
+        // without an `unwrap()`.
+        let significand_bytes = value[0..8].try_into().unwrap();
+        let significand = u64::from_le_bytes(significand_bytes);
+        let sign_exp_bytes = value[8..10].try_into().unwrap();
+        let sign_exp = u16::from_le_bytes(sign_exp_bytes);
+        FpuReg {
+            significand,
+            sign_exp,
+        }
+    }
+}
+
+impl From<FpuReg> for [u8; 10] {
+    /// Convert an `FpuReg` into its 80-bit "TBYTE" representation.
+    fn from(value: FpuReg) -> [u8; 10] {
+        let mut bytes = [0u8; 10];
+        bytes[0..8].copy_from_slice(&value.significand.to_le_bytes());
+        bytes[8..10].copy_from_slice(&value.sign_exp.to_le_bytes());
+        bytes
+    }
+}
+
+impl From<FpuReg> for [u8; 16] {
+    /// Convert an `FpuReg` into its 80-bit representation plus 6 unused upper bytes.
+    /// This is a convenience function for converting to hypervisor types.
+    fn from(value: FpuReg) -> [u8; 16] {
+        let mut bytes = [0u8; 16];
+        bytes[0..8].copy_from_slice(&value.significand.to_le_bytes());
+        bytes[8..10].copy_from_slice(&value.sign_exp.to_le_bytes());
+        bytes
+    }
+}
+
 /// State of a VCPU's floating point unit.
 #[repr(C)]
 #[derive(Debug, Copy, Clone, Serialize, Deserialize)]
 pub struct Fpu {
-    pub fpr: [[u8; 16usize]; 8usize],
+    pub fpr: [FpuReg; 8],
     pub fcw: u16,
     pub fsw: u16,
     pub ftwx: u8,
diff --git a/hypervisor/tests/hypervisor_virtualization.rs b/hypervisor/tests/hypervisor_virtualization.rs
index 3a1440aaf..db5fd1f09 100644
--- a/hypervisor/tests/hypervisor_virtualization.rs
+++ b/hypervisor/tests/hypervisor_virtualization.rs
@@ -5,107 +5,4267 @@
 #![cfg(target_arch = "x86_64")]
 #![cfg(any(feature = "whpx", feature = "gvm", feature = "haxm", unix))]
 
+use core::mem;
+use std::arch::asm;
+use std::cell::RefCell;
+use std::ffi::c_void;
+use std::sync::atomic::AtomicU8;
+use std::sync::atomic::Ordering;
+use std::sync::Arc;
+
+use base::set_cpu_affinity;
+use base::MappedRegion;
+use base::MemoryMappingBuilder;
+use base::SharedMemory;
+#[cfg(feature = "gvm")]
+use hypervisor::gvm::*;
+#[cfg(all(windows, feature = "haxm"))]
+use hypervisor::haxm::*;
+#[cfg(any(target_os = "android", target_os = "linux"))]
+use hypervisor::kvm::*;
+#[cfg(all(windows, feature = "whpx"))]
+use hypervisor::whpx::*;
+#[cfg(any(target_os = "android", target_os = "linux"))]
+use hypervisor::MemCacheType::CacheCoherent;
 use hypervisor::*;
+use hypervisor_test_macro::global_asm_data;
+use sync::Mutex;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
+#[cfg(windows)]
+use windows::Win32::System::Memory::VirtualLock;
+#[cfg(windows)]
+use windows::Win32::System::Memory::VirtualUnlock;
+use zerocopy::AsBytes;
+
+const FLAGS_IF_BIT: u64 = 0x200;
+
+#[derive(Debug, Clone, Copy, Hash, PartialEq, Eq)]
+pub enum HypervisorType {
+    Kvm,
+    Whpx,
+    Haxm,
+    Gvm,
+}
+
+#[repr(C, packed)]
+#[derive(AsBytes)]
+/// Define IDTR value used in real mode or 32bit protected mode.
+struct Idtr32 {
+    // The lower 2 bytes are limit.
+    limit: u16,
+    // The higher 4 bytes are base address.
+    base_address: u32,
+}
+
+#[repr(C, packed)]
+#[derive(AsBytes, Debug, Copy, Clone)]
+/// IDT entries for long mode.
+struct IdtEntry64 {
+    address_low: u16,
+    selector: u16,
+    ist: u8,
+    flags: u8,
+    address_mid: u16,
+    address_high: u32,
+    reserved: u32,
+}
+
+impl IdtEntry64 {
+    pub fn new(handler_addr: u64) -> Self {
+        IdtEntry64 {
+            address_low: (handler_addr & 0xFFFF) as u16,
+            selector: 0x10, // Our long mode CS is the third entry (0x0, 0x8, 0x10).
+            ist: 0,
+            flags: 0x8E, // Present, interrupt gate, DPL 0
+            address_mid: ((handler_addr >> 16) & 0xFFFF) as u16,
+            address_high: (handler_addr >> 32) as u32,
+            reserved: 0,
+        }
+    }
+}
+
+impl std::fmt::Display for HypervisorType {
+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+        match self {
+            HypervisorType::Kvm => write!(f, "KVM"),
+            HypervisorType::Whpx => write!(f, "WHPX"),
+            HypervisorType::Haxm => write!(f, "HAXM"),
+            HypervisorType::Gvm => write!(f, "GVM"),
+        }
+    }
+}
+
+pub trait HypervisorTestSetup {
+    type Hypervisor: Hypervisor;
+    type Vm: VmX86_64;
+
+    fn create_vm(guest_mem: GuestMemory) -> (Self::Hypervisor, Self::Vm);
+}
 
-#[test]
 #[cfg(any(target_os = "android", target_os = "linux"))]
-fn test_kvm_minimal_virtualization() {
-    use hypervisor::kvm::*;
-    test_minimal_virtualization(|guest_mem| {
+impl HypervisorTestSetup for Kvm {
+    type Hypervisor = Kvm;
+    type Vm = KvmVm;
+
+    fn create_vm(guest_mem: GuestMemory) -> (Self::Hypervisor, Self::Vm) {
         let kvm = Kvm::new().expect("failed to create kvm");
         let vm = KvmVm::new(&kvm, guest_mem, Default::default()).expect("failed to create vm");
         (kvm, vm)
-    });
+    }
+}
+
+#[cfg(all(windows, feature = "whpx"))]
+impl HypervisorTestSetup for Whpx {
+    type Hypervisor = Whpx;
+    type Vm = WhpxVm;
+
+    fn create_vm(guest_mem: GuestMemory) -> (Self::Hypervisor, Self::Vm) {
+        let whpx = Whpx::new().expect("failed to create whpx");
+        let vm = WhpxVm::new(&whpx, 1, guest_mem, CpuId::new(0), false, None)
+            .expect("failed to create vm");
+        (whpx, vm)
+    }
 }
 
-#[test]
 #[cfg(all(windows, feature = "haxm"))]
-fn test_haxm_minimal_virtualization() {
-    use hypervisor::haxm::*;
-    test_minimal_virtualization(|guest_mem| {
+impl HypervisorTestSetup for Haxm {
+    type Hypervisor = Haxm;
+    type Vm = HaxmVm;
+
+    fn create_vm(guest_mem: GuestMemory) -> (Self::Hypervisor, Self::Vm) {
         let haxm = Haxm::new().expect("failed to create haxm");
         let vm = HaxmVm::new(&haxm, guest_mem).expect("failed to create vm");
         (haxm, vm)
-    });
+    }
 }
 
-#[test]
 #[cfg(feature = "gvm")]
-fn test_gvm_minimal_virtualization() {
-    use hypervisor::gvm::*;
-    test_minimal_virtualization(|guest_mem| {
+impl HypervisorTestSetup for Gvm {
+    type Hypervisor = Gvm;
+    type Vm = GvmVm;
+
+    fn create_vm(guest_mem: GuestMemory) -> (Self::Hypervisor, Self::Vm) {
         let gvm = Gvm::new().expect("failed to create gvm");
         let vm = GvmVm::new(&gvm, guest_mem).expect("failed to create vm");
         (gvm, vm)
-    });
+    }
 }
 
-#[test]
-#[cfg(all(windows, feature = "whpx"))]
-fn test_whpx_minimal_virtualization() {
-    use hypervisor::whpx::*;
-    test_minimal_virtualization(|guest_mem| {
-        let whpx = Whpx::new().expect("failed to create whpx");
-        let vm = WhpxVm::new(&whpx, 1, guest_mem, CpuId::new(0), false, None)
-            .expect("failed to create vm");
-        (whpx, vm)
-    });
+pub struct TestSetup {
+    pub assembly: Vec<u8>,
+    pub load_addr: GuestAddress,
+    pub mem_size: u64,
+    pub initial_regs: Regs,
+    pub extra_vm_setup: Option<Box<dyn Fn(&mut dyn VcpuX86_64, &mut dyn Vm) + Send>>,
+    pub memory_initializations: Vec<(GuestAddress, Vec<u8>)>,
+    pub expect_run_success: bool,
+
+    /// Whether the `exit_matcher` should recieve [`VcpuExit::Intr`]. Default to `false`.
+    ///
+    /// Hypervisors may occasinally receive [`VcpuExit::Intr`] if external interrupt intercept is
+    /// enabled. In such case, we should proceed to the next VCPU run to handle it. HAXM doesn't
+    /// distinguish between [`VcpuExit::Intr`] and [`VcpuExit::IrqWindowOpen`], so it may be
+    /// necessary to intercept [`VcpuExit::Intr`] for testing
+    /// [`VcpuX86_64::set_interrupt_window_requested`].
+    pub intercept_intr: bool,
 }
 
-// This runs a minimal program under virtualization.
-// It should require only the ability to execute instructions under virtualization, physical
-// memory, the ability to get and set some guest VM registers, and intercepting HLT.
-fn test_minimal_virtualization<CreateVm, HypervisorT, VmT>(create_vm: CreateVm)
-where
-    CreateVm: FnOnce(GuestMemory) -> (HypervisorT, VmT),
-    HypervisorT: Hypervisor,
-    VmT: VmX86_64,
-{
-    /*
-    0x0000000000000002:  01 D8       add ax, bx
-    0x0000000000000002:  F4          hlt
-    */
-
-    let code: [u8; 3] = [0x01, 0xd8, 0xf4];
-    let mem_size = 0x2000;
-    let load_addr = GuestAddress(0x1000);
+impl Default for TestSetup {
+    fn default() -> Self {
+        TestSetup {
+            assembly: Vec::new(),
+            load_addr: GuestAddress(0),
+            mem_size: 0xF000, // Big enough default for long mode setup
+            initial_regs: Regs::default(),
+            extra_vm_setup: None,
+            memory_initializations: Vec::new(),
+            expect_run_success: true,
+            intercept_intr: false,
+        }
+    }
+}
+
+impl TestSetup {
+    pub fn new() -> Self {
+        Default::default()
+    }
+
+    pub fn add_memory_initialization(&mut self, addr: GuestAddress, data: Vec<u8>) {
+        self.memory_initializations.push((addr, data));
+    }
+}
+
+pub fn run_configurable_test<H: HypervisorTestSetup>(
+    hypervisor_type: HypervisorType,
+    setup: &TestSetup,
+    regs_matcher: impl Fn(HypervisorType, &Regs, &Sregs),
+    mut exit_matcher: impl FnMut(HypervisorType, &VcpuExit, &mut dyn VcpuX86_64, &mut dyn Vm) -> bool,
+) {
+    println!("Running test on hypervisor: {}", hypervisor_type);
 
     let guest_mem =
-        GuestMemory::new(&[(GuestAddress(0), mem_size)]).expect("failed to create guest mem");
+        GuestMemory::new(&[(GuestAddress(0), setup.mem_size)]).expect("failed to create guest mem");
+
+    for (addr, data) in &setup.memory_initializations {
+        guest_mem
+            .write_at_addr(data, *addr)
+            .expect("failed to write memory initialization");
+    }
+
     guest_mem
-        .write_at_addr(&code[..], load_addr)
+        .write_at_addr(&setup.assembly, setup.load_addr)
         .expect("failed to write to guest memory");
 
-    let (_, vm) = create_vm(guest_mem);
+    let (_, mut vm) = H::create_vm(guest_mem);
+
     let mut vcpu = vm.create_vcpu(0).expect("new vcpu failed");
-    let mut vcpu_sregs = vcpu.get_sregs().expect("get sregs failed");
-    vcpu_sregs.cs.base = 0;
-    vcpu_sregs.cs.selector = 0;
 
-    vcpu.set_sregs(&vcpu_sregs).expect("set sregs failed");
+    let mut sregs = vcpu.get_sregs().expect("get sregs failed");
+    sregs.cs.base = 0;
+    sregs.cs.selector = 0;
+    vcpu.set_sregs(&sregs).expect("set sregs failed");
+    vcpu.set_regs(&setup.initial_regs).expect("set regs failed");
+
+    if let Some(ref setup_fn) = setup.extra_vm_setup {
+        setup_fn(&mut *vcpu, &mut vm);
+    }
+
+    if !vm.check_capability(VmCap::EarlyInitCpuid) {
+        let cpuid = vm
+            .get_hypervisor()
+            .get_supported_cpuid()
+            .expect("get_supported_cpuid() failed");
+        vcpu.set_cpuid(&cpuid).expect("set_cpuid() failed");
+    }
+
+    loop {
+        match vcpu.run() {
+            Ok(exit) => match exit {
+                // Handle interrupts by continuing the loop
+                VcpuExit::Intr if !setup.intercept_intr => continue,
+                other_exit => {
+                    if !setup.expect_run_success {
+                        panic!("Expected vcpu.run() to fail, but it succeeded");
+                    }
+                    if exit_matcher(hypervisor_type, &other_exit, &mut *vcpu, &mut vm) {
+                        break;
+                    }
+                }
+            },
+            Err(e) => {
+                if setup.expect_run_success {
+                    panic!(
+                        "Expected vcpu.run() to succeed, but it failed with error: {:?}",
+                        e
+                    );
+                } else {
+                    println!("Expected failure occurred: {:?}", e);
+                    break;
+                }
+            }
+        }
+    }
+
+    let final_regs = vcpu.get_regs().expect("failed to get regs");
+    let final_sregs = vcpu.get_sregs().expect("failed to get sregs");
+
+    regs_matcher(hypervisor_type, &final_regs, &final_sregs);
+}
+
+macro_rules! run_tests {
+    ($setup:expr, $regs_matcher:expr, $exit_matcher:expr) => {
+        #[cfg(any(target_os = "android", target_os = "linux"))]
+        run_configurable_test::<Kvm>(HypervisorType::Kvm, &$setup, $regs_matcher, $exit_matcher);
+
+        #[cfg(all(windows, feature = "whpx"))]
+        run_configurable_test::<Whpx>(HypervisorType::Whpx, &$setup, $regs_matcher, $exit_matcher);
+
+        #[cfg(all(windows, feature = "haxm"))]
+        run_configurable_test::<Haxm>(HypervisorType::Haxm, &$setup, $regs_matcher, $exit_matcher);
+
+        #[cfg(feature = "gvm")]
+        run_configurable_test::<Gvm>(HypervisorType::Gvm, &$setup, $regs_matcher, $exit_matcher);
+    };
+}
+
+const DEFAULT_GDT_OFFSET: u64 = 0x1500;
+const DEFAULT_IDT_OFFSET: u64 = 0x1528;
+
+const DESC_ACCESS_EXEC: u8 = 1 << 3;
+const DESC_ACCESS_RW: u8 = 1 << 1;
+const DESC_ACCESS_ACCESSED: u8 = 1 << 0;
+
+#[derive(Debug, Clone, Copy)]
+struct LongModePageTableEntry {
+    execute_disable: bool,
+    protection_key: u8,
+    address: u64,
+    global: bool,
+    page_attribute_table: bool,
+    dirty: bool,
+    accessed: bool,
+    cache_disable: bool,
+    write_through: bool,
+    user_supervisor: bool,
+    read_write: bool,
+    present: bool,
+}
+
+impl LongModePageTableEntry {
+    fn from_address(address: u64) -> Self {
+        assert!(address < 1 << 52, "the address must fit in 52 bits");
+        assert!(address & 0xFFF == 0, "the address must be aligned to 4k");
+        Self {
+            execute_disable: false,
+            protection_key: 0,
+            address,
+            global: false,
+            page_attribute_table: false,
+            dirty: false,
+            accessed: false,
+            cache_disable: false,
+            write_through: false,
+            user_supervisor: false,
+            read_write: false,
+            present: false,
+        }
+    }
+}
+
+impl From<LongModePageTableEntry> for u64 {
+    fn from(page_table_entry: LongModePageTableEntry) -> Self {
+        let mut res = 0;
+        if page_table_entry.present {
+            res |= 1;
+        }
+        if page_table_entry.read_write {
+            res |= 1 << 1;
+        }
+        if page_table_entry.user_supervisor {
+            res |= 1 << 2;
+        }
+        if page_table_entry.write_through {
+            res |= 1 << 3;
+        }
+        if page_table_entry.cache_disable {
+            res |= 1 << 4;
+        }
+        if page_table_entry.accessed {
+            res |= 1 << 5;
+        }
+        if page_table_entry.dirty {
+            res |= 1 << 6;
+        }
+        if page_table_entry.page_attribute_table {
+            res |= 1 << 7;
+        }
+        if page_table_entry.global {
+            res |= 1 << 8;
+        }
+        assert!(page_table_entry.address < 1 << 52);
+        assert!(page_table_entry.address & 0xFFF == 0);
+        res |= page_table_entry.address;
+        assert!(page_table_entry.protection_key < 1 << 4);
+        res |= u64::from(page_table_entry.protection_key) << 59;
+        if page_table_entry.execute_disable {
+            res |= 1 << 63;
+        }
+        res
+    }
+}
+
+#[derive(Debug, Clone)]
+struct ModeConfig {
+    idt: Vec<u8>,
+    idt_base_addr: u64,
+    gdt: Vec<Segment>,
+    gdt_base_addr: u64,
+    code_segment_index: u16,
+    task_segment_index: Option<u16>,
+    page_table: Option<Box<[u8; 0x1000]>>,
+    long_mode: bool,
+}
+
+impl ModeConfig {
+    const IDT64_SIZE: usize = std::mem::size_of::<IdtEntry64>() * 256;
+    const IDT32_SIZE: usize = 8 * 256;
+
+    /// Set the IDT for long mode.
+    fn set_idt_long_mode(&mut self, idt: impl IntoIterator<Item = IdtEntry64>) -> &mut Self {
+        let entries = idt.into_iter().collect::<Vec<_>>();
+        assert_eq!(entries.len(), 256, "IDT must contain 256 entries");
+        self.idt = entries
+            .into_iter()
+            .flat_map(|entry| entry.as_bytes().to_owned())
+            .collect();
+        self
+    }
+
+    fn set_idt_base_addr(&mut self, idt_base_addr: u64) -> &mut Self {
+        self.idt_base_addr = idt_base_addr;
+        self
+    }
+
+    fn default_code_segment_long_mode() -> Segment {
+        Segment {
+            base: 0,
+            limit_bytes: 0xffff_ffff,
+            type_: DESC_ACCESS_EXEC | DESC_ACCESS_RW | DESC_ACCESS_ACCESSED,
+            present: 1,
+            dpl: 0,
+            db: 0,
+            s: 1,
+            l: 1,
+            g: 1,
+            ..Default::default()
+        }
+    }
+
+    fn default_code_segment_protected_mode() -> Segment {
+        Segment {
+            base: 0,
+            limit_bytes: 0xffff_ffff,
+            type_: DESC_ACCESS_EXEC | DESC_ACCESS_RW | DESC_ACCESS_ACCESSED,
+            present: 1,
+            dpl: 0,
+            db: 1,
+            s: 1,
+            l: 0,
+            g: 1,
+            ..Default::default()
+        }
+    }
+
+    fn segment_to_bytes(segment: &Segment, long_mode: bool) -> Vec<u8> {
+        if *segment == Segment::default() {
+            // Special handle for null descriptor, so that it won't be recognized as a 64
+            // bit system segment.
+            return vec![0u8; 8];
+        }
+        let Segment {
+            base,
+            limit_bytes,
+            type_,
+            present,
+            dpl,
+            db,
+            s,
+            l,
+            g,
+            ..
+        } = *segment;
+
+        let limit = if g != 0 {
+            // 4096-byte granularity
+            limit_bytes / 4096
+        } else {
+            // 1-byte granularity
+            limit_bytes
+        };
+
+        assert!(limit < (1 << 20)); // limit value must fit in 20 bits
+        let flags = {
+            let mut flags = 0;
+            if g != 0 {
+                flags |= 1 << 3;
+            }
+            if db != 0 {
+                flags |= 1 << 2;
+            }
+            if l != 0 {
+                flags |= 1 << 1;
+            }
+            flags << 4
+        };
+        assert!(flags & 0x0F == 0x00); // flags must be in the high 4 bits only
+        let access = {
+            assert!(type_ < (1 << 4), "type must fit in 4 bits");
+            let mut access = type_;
+            if present != 0 {
+                access |= 1 << 7;
+            }
+            assert!(dpl < (1 << 2), "DPL must fit in 2 bits");
+            access |= dpl << 5;
+            if s != 0 {
+                access |= 1 << 4;
+            }
+            access
+        };
+
+        let limit_lo = (limit & 0xffff).try_into().unwrap();
+        let base_lo = (base & 0xffff).try_into().unwrap();
+        let base_mid0 = ((base >> 16) & 0xff).try_into().unwrap();
+        let limit_hi_and_flags = u8::try_from((limit >> 16) & 0xf).unwrap() | flags;
+        let base_mid1 = ((base >> 24) & 0xff).try_into().unwrap();
+        let base_hi = (base >> 32).try_into().unwrap();
 
-    let vcpu_regs = Regs {
-        rip: load_addr.offset(),
-        rflags: 2,
-        rax: 1,
-        rbx: 2,
+        if long_mode && s == 0 {
+            // 64 bit system segment descriptor.
+            #[repr(C, packed)]
+            #[derive(AsBytes)]
+            struct Descriptor {
+                limit_lo: u16,
+                base_lo: u16,
+                base_mid0: u8,
+                access: u8,
+                limit_hi_and_flags: u8,
+                base_mid1: u8,
+                base_hi: u32,
+                _reserved: [u8; 4],
+            }
+
+            Descriptor {
+                limit_lo,
+                base_lo,
+                base_mid0,
+                access,
+                limit_hi_and_flags,
+                base_mid1,
+                base_hi,
+                _reserved: [0; 4],
+            }
+            .as_bytes()
+            .to_owned()
+        } else {
+            #[repr(C, packed)]
+            #[derive(AsBytes)]
+            struct Descriptor {
+                limit_lo: u16,
+                base_lo: u16,
+                base_mid: u8,
+                access: u8,
+                limit_hi_and_flags: u8,
+                base_hi: u8,
+            }
+
+            assert_eq!(base_hi, 0, "the base address must be within 32 bit range");
+            Descriptor {
+                limit_lo,
+                base_lo,
+                base_mid: base_mid0,
+                access,
+                limit_hi_and_flags,
+                base_hi: base_mid1,
+            }
+            .as_bytes()
+            .to_owned()
+        }
+    }
+
+    fn get_gdt_bytes(&self) -> Vec<u8> {
+        self.gdt
+            .iter()
+            .flat_map(|segment| Self::segment_to_bytes(segment, self.long_mode))
+            .collect()
+    }
+
+    fn configure_gdt_memory(&self, guest_mem: &GuestMemory) {
+        let gdt_bytes = self.get_gdt_bytes();
+        let gdt_start_addr = GuestAddress(self.gdt_base_addr);
+        let gdt_end_addr = gdt_start_addr
+            .checked_add(
+                gdt_bytes
+                    .len()
+                    .try_into()
+                    .expect("the GDT size must be within usize"),
+            )
+            .expect("the end of GDT address shouldn't overflow");
+        assert!(
+            guest_mem.range_overlap(GuestAddress(self.gdt_base_addr), gdt_end_addr),
+            "the address for GDT is not mapped"
+        );
+        guest_mem
+            .write_at_addr(&gdt_bytes, GuestAddress(self.gdt_base_addr))
+            .expect("Failed to write GDT entry to guest memory");
+    }
+
+    fn configure_idt_memory(&self, guest_mem: &GuestMemory) {
+        let expected_length = if self.long_mode {
+            Self::IDT64_SIZE
+        } else {
+            Self::IDT32_SIZE
+        };
+
+        let idt_addr = GuestAddress(self.idt_base_addr);
+        assert_eq!(self.idt.len(), expected_length);
+        assert!(
+            guest_mem.range_overlap(
+                idt_addr,
+                idt_addr
+                    .checked_add(
+                        self.idt
+                            .len()
+                            .try_into()
+                            .expect("The IDT length must be within the u64 range.")
+                    )
+                    .expect("The end address of IDT should not overflow")
+            ),
+            "The IDT that starts at {:#x} isn't properly mapped as the guest memory.",
+            self.idt_base_addr
+        );
+        guest_mem
+            .write_at_addr(&self.idt, idt_addr)
+            .expect("failed to write IDT entry to guest memory");
+    }
+
+    fn get_idtr_value(&self) -> DescriptorTable {
+        DescriptorTable {
+            base: self.idt_base_addr,
+            limit: {
+                let expected_length = if self.long_mode {
+                    Self::IDT64_SIZE
+                } else {
+                    Self::IDT32_SIZE
+                };
+                assert_eq!(self.idt.len(), expected_length, "the IDT size should match",);
+                // The IDT limit should be the number of bytes of IDT - 1.
+                (self.idt.len() - 1)
+                    .try_into()
+                    .expect("the IDT limit should be within the range of u16")
+            },
+        }
+    }
+
+    fn get_gdtr_value(&self) -> DescriptorTable {
+        DescriptorTable {
+            base: self.gdt_base_addr,
+            limit: (self.get_gdt_bytes().len() - 1)
+                .try_into()
+                .expect("the GDT limit should fit in 16 bits"),
+        }
+    }
+
+    fn get_segment_register_value(&self, segment_index: u16) -> Segment {
+        let offset: usize = self
+            .gdt
+            .iter()
+            .take(segment_index.into())
+            .map(|segment| Self::segment_to_bytes(segment, self.long_mode).len())
+            .sum();
+        Segment {
+            selector: offset
+                .try_into()
+                .expect("the offset should be within the range of u16"),
+            ..self.gdt[usize::from(segment_index)]
+        }
+    }
+
+    pub fn configure_long_mode_memory(&self, vm: &mut dyn Vm) {
+        let guest_mem = vm.get_memory();
+
+        self.configure_gdt_memory(guest_mem);
+        self.configure_idt_memory(guest_mem);
+
+        // Setup paging
+        let pml4_addr = GuestAddress(0x9000);
+        let pdpte_addr = GuestAddress(0xa000);
+        let pde_addr = GuestAddress(0xb000);
+        let pte_addr = GuestAddress(0xc000);
+
+        assert!(
+            guest_mem.range_overlap(GuestAddress(0x9000), GuestAddress(0xd000)),
+            "the memory range for page tables should be mapped."
+        );
+
+        // Pointing to PDPTE with present and RW flags
+        guest_mem
+            .write_at_addr(&(pdpte_addr.0 | 3).to_le_bytes(), pml4_addr)
+            .expect("failed to write PML4 entry");
+
+        // Pointing to PD with present and RW flags
+        guest_mem
+            .write_at_addr(&(pde_addr.0 | 3).to_le_bytes(), pdpte_addr)
+            .expect("failed to write PDPTE entry");
+
+        for i in 0..512 {
+            // All pages are present and RW.
+            let flags: u64 = if i == 0 {
+                3
+            } else {
+                // The first 2MiB are 4K pages, the rest are 2M pages.
+                0x83
+            };
+            let addr = if i == 0 { pte_addr.offset() } else { i << 21 };
+            let pd_entry_bytes = (addr | flags).to_le_bytes();
+            guest_mem
+                .write_at_addr(
+                    &pd_entry_bytes,
+                    pde_addr.unchecked_add(i * mem::size_of::<u64>() as u64),
+                )
+                .expect("Failed to write PDE entry");
+        }
+
+        guest_mem
+            .write_at_addr(
+                self.page_table
+                    .as_ref()
+                    .expect("page table must present for long mode")
+                    .as_slice(),
+                pte_addr,
+            )
+            .expect("Failed to write PTE entry");
+    }
+
+    pub fn enter_long_mode(&self, vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm) {
+        self.configure_long_mode_memory(vm);
+
+        let mut sregs = vcpu.get_sregs().expect("failed to get sregs");
+
+        sregs.gdt = self.get_gdtr_value();
+        sregs.idt = self.get_idtr_value();
+        sregs.cs = self.get_segment_register_value(self.code_segment_index);
+
+        if let Some(task_segment_index) = self.task_segment_index {
+            sregs.tr = self.get_segment_register_value(task_segment_index);
+        }
+
+        // Long mode
+        let pml4_addr = GuestAddress(0x9000);
+        sregs.cr0 |= 0x1 | 0x80000000; // PE & PG
+        sregs.efer |= 0x100 | 0x400; // LME & LMA (Must be auto-enabled with CR0_PG)
+        sregs.cr3 = pml4_addr.offset();
+        sregs.cr4 |= 0x80 | 0x20; // PGE & PAE
+
+        vcpu.set_sregs(&sregs).expect("failed to set sregs");
+    }
+
+    pub fn configure_flat_protected_mode_memory(&self, vm: &mut dyn Vm) {
+        let guest_mem = vm.get_memory();
+
+        self.configure_gdt_memory(guest_mem);
+        self.configure_idt_memory(guest_mem);
+    }
+
+    pub fn enter_protected_mode(&self, vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm) {
+        self.configure_flat_protected_mode_memory(vm);
+
+        let mut sregs = vcpu.get_sregs().expect("failed to get sregs");
+
+        sregs.cs = self.get_segment_register_value(self.code_segment_index);
+        sregs.gdt = self.get_gdtr_value();
+        sregs.idt = self.get_idtr_value();
+
+        assert!(
+            self.task_segment_index.is_none(),
+            "task segment not supported for protected mode yet."
+        );
+
+        assert!(
+            self.page_table.is_none(),
+            "setting page tables for protected mode is not supported yet"
+        );
+        // 32-bit protected mode, paging disabled
+        sregs.cr0 |= 0x1; // PE
+        sregs.cr0 &= !0x80000000; // ~PG
+
+        vcpu.set_sregs(&sregs).expect("failed to set sregs");
+    }
+
+    fn default_long_mode() -> Self {
+        let page_table = (0u64..512)
+            .flat_map(|page_frame_number| {
+                let page_table_entry = LongModePageTableEntry {
+                    present: true,
+                    read_write: true,
+                    ..LongModePageTableEntry::from_address(page_frame_number << 12)
+                };
+                u64::from(page_table_entry).as_bytes().to_owned()
+            })
+            .collect::<Box<[u8]>>()
+            .try_into()
+            .expect("the length of the slice must match");
+        Self {
+            idt_base_addr: DEFAULT_IDT_OFFSET,
+            idt: vec![0; Self::IDT64_SIZE],
+            gdt_base_addr: DEFAULT_GDT_OFFSET,
+            gdt: vec![
+                Segment::default(),
+                Segment::default(),
+                Self::default_code_segment_long_mode(),
+            ],
+            code_segment_index: 2,
+            task_segment_index: None,
+            page_table: Some(page_table),
+            long_mode: true,
+        }
+    }
+
+    fn default_protected_mode() -> Self {
+        Self {
+            idt_base_addr: DEFAULT_IDT_OFFSET,
+            idt: vec![0; Self::IDT32_SIZE],
+            gdt_base_addr: DEFAULT_GDT_OFFSET,
+            gdt: vec![
+                Segment::default(),
+                Segment::default(),
+                Self::default_code_segment_protected_mode(),
+            ],
+            code_segment_index: 2,
+            task_segment_index: None,
+            page_table: None,
+            long_mode: false,
+        }
+    }
+}
+
+global_asm_data!(
+    test_minimal_virtualization_code,
+    ".code16",
+    "add ax, bx",
+    "hlt"
+);
+
+// This runs a minimal program under virtualization.
+// It should require only the ability to execute instructions under virtualization, physical
+// memory, the ability to get and set some guest VM registers, and intercepting HLT.
+#[test]
+fn test_minimal_virtualization() {
+    let assembly = test_minimal_virtualization_code::data().to_vec();
+    let setup = TestSetup {
+        assembly: assembly.clone(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 1,
+            rbx: 2,
+            rflags: 2,
+            ..Default::default()
+        },
         ..Default::default()
     };
-    vcpu.set_regs(&vcpu_regs).expect("set regs failed");
 
-    loop {
-        match vcpu.run().expect("run failed") {
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(regs.rax, 3); // 1 + 2
+
+            // For VMEXIT caused by HLT, the hypervisor will automatically advance the rIP register.
+            assert_eq!(regs.rip, 0x1000 + assembly.len() as u64);
+        },
+        |_, exit: &_, _: &mut _, _: &mut _| -> bool { matches!(exit, VcpuExit::Hlt) }
+    );
+}
+
+global_asm_data!(
+    test_io_exit_handler_code,
+    ".code16",
+    "out 0x10, al",
+    "in al, 0x20",
+    "add ax, bx",
+    "hlt",
+);
+
+#[test]
+fn test_io_exit_handler() {
+    // Use the OUT/IN instructions, which cause an Io exit in order to
+    // read/write data using a given port.
+    let load_addr = GuestAddress(0x1000);
+    let setup = TestSetup {
+        assembly: test_io_exit_handler_code::data().to_vec(),
+        load_addr,
+        initial_regs: Regs {
+            rip: load_addr.offset(),
+            rax: 0x34, // Only AL (lower byte of RAX) is used
+            rbx: 0x42,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher = |_, regs: &Regs, _: &_| {
+        // The result in AX should be double the initial value of AX
+        // plus the initial value of BX.
+        assert_eq!(regs.rax, (0x34 * 2) + 0x42);
+    };
+
+    let cached_byte = AtomicU8::new(0);
+    let exit_matcher =
+        move |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+            VcpuExit::Io => {
+                vcpu.handle_io(&mut |IoParams {
+                                         address,
+                                         size,
+                                         operation,
+                                     }| {
+                    match operation {
+                        IoOperation::Read => {
+                            let mut data = [0u8; 8];
+                            assert_eq!(address, 0x20);
+                            assert_eq!(size, 1);
+                            // The original number written below will be doubled and
+                            // passed back.
+                            data[0] = cached_byte.load(Ordering::SeqCst) * 2;
+                            Some(data)
+                        }
+                        IoOperation::Write { data } => {
+                            assert_eq!(address, 0x10);
+                            assert_eq!(size, 1);
+                            assert_eq!(data[0], 0x34);
+                            cached_byte.fetch_add(data[0], Ordering::SeqCst);
+                            None
+                        }
+                    }
+                })
+                .expect("failed to set the data");
+                false // Continue VM runloop
+            }
             VcpuExit::Hlt => {
-                break;
+                true // Break VM runloop
             }
-            // Continue on external interrupt or signal
-            VcpuExit::Intr => continue,
             r => panic!("unexpected exit reason: {:?}", r),
+        };
+    run_tests!(setup, regs_matcher, &exit_matcher);
+}
+
+global_asm_data!(
+    test_mmio_exit_cross_page_code,
+    ".code16",
+    "mov byte ptr [ebx], al",
+    "mov al, byte ptr [ecx]",
+    "hlt",
+);
+
+// This test is similar to mmio_fetch_memory.rs (remove eventually)
+// but applies to all hypervisors.
+#[test]
+fn test_mmio_exit_cross_page() {
+    let page_size = 4096u64;
+    let load_addr = GuestAddress(page_size - 1); // Last byte of the first page
+
+    let setup = TestSetup {
+        assembly: test_mmio_exit_cross_page_code::data().to_vec(),
+        load_addr,
+        mem_size: 0x2000,
+        initial_regs: Regs {
+            rip: load_addr.offset(),
+            rax: 0x33,
+            rbx: 0x3000,
+            rcx: 0x3010,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher = |_, regs: &Regs, _: &_| {
+        assert_eq!(regs.rax, 0x66, "Should match the MMIO read bytes below");
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Mmio => {
+            vcpu.handle_mmio(&mut |IoParams {
+                                       address,
+                                       size,
+                                       operation,
+                                   }| {
+                match operation {
+                    IoOperation::Read => {
+                        match (address, size) {
+                            // First MMIO read asks to load the first 8 bytes
+                            // of a new execution page, when an instruction
+                            // crosses page boundary.
+                            // Return the rest of instructions that are
+                            // supposed to be on the second page.
+                            (0x1000, 8) => {
+                                // Ensure this instruction is the first read
+                                // in the sequence.
+                                Ok(Some([0x88, 0x03, 0x67, 0x8a, 0x01, 0xf4, 0, 0]))
+                            }
+                            // Second MMIO read is a regular read from an
+                            // unmapped memory (pointed to by initial EAX).
+                            (0x3010, 1) => Ok(Some([0x66, 0, 0, 0, 0, 0, 0, 0])),
+                            _ => {
+                                panic!("invalid address({:#x})/size({})", address, size)
+                            }
+                        }
+                    }
+                    IoOperation::Write { data } => {
+                        assert_eq!(address, 0x3000);
+                        assert_eq!(data[0], 0x33);
+                        assert_eq!(size, 1);
+                        Ok(None)
+                    }
+                }
+            })
+            .expect("failed to set the data");
+            false // Continue VM runloop
         }
-    }
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_mmio_exit_readonly_memory_code,
+    ".code16",
+    "mov al,BYTE PTR es:[bx]",
+    "add al, 0x1",
+    "mov BYTE PTR es:[bx], al",
+    "hlt",
+);
+
+#[test]
+#[cfg(any(target_os = "android", target_os = "linux"))] // Not working for WHXP yet.
+fn test_mmio_exit_readonly_memory() {
+    // Read from read-only memory and then write back to it,
+    // which should trigger an MMIO exit.
+    let setup = TestSetup {
+        assembly: test_mmio_exit_readonly_memory_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        mem_size: 0x2000,
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 1,
+            rbx: 0,
+            rflags: 2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            // Add a read-only region of memory to the VM, at address 0x5000.
+            let prot_mem_size = 0x1000;
+            let prot_mem =
+                SharedMemory::new("test", prot_mem_size).expect("failed to create shared memory");
+            let mmap_ro = MemoryMappingBuilder::new(prot_mem_size as usize)
+                .from_shared_memory(&prot_mem)
+                .build()
+                .expect("failed to create memory mapping");
+            mmap_ro
+                .write_obj(0x66, 0)
+                .expect("failed writing data to ro memory");
+            vm.add_memory_region(
+                GuestAddress(0x5000),
+                Box::new(
+                    MemoryMappingBuilder::new(prot_mem_size as usize)
+                        .from_shared_memory(&prot_mem)
+                        .build()
+                        .expect("failed to create memory mapping"),
+                ),
+                true,
+                false,
+                CacheCoherent,
+            )
+            .expect("failed to register memory");
+
+            // Set up segments needed by the assembly addressing above.
+            let mut sregs = vcpu.get_sregs().expect("get sregs failed");
+            sregs.cs.s = 1;
+            sregs.cs.type_ = 0b1011;
+            sregs.es.base = 0x5000;
+            sregs.es.selector = 0;
+            sregs.es.s = 1;
+            sregs.es.type_ = 0b1011;
+
+            vcpu.set_sregs(&sregs).expect("set sregs failed");
+        })),
+        ..Default::default()
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Mmio => {
+            vcpu.handle_mmio(&mut |IoParams {
+                                       address,
+                                       size,
+                                       operation,
+                                   }| match operation {
+                IoOperation::Read => {
+                    panic!("unexpected mmio read call");
+                }
+                IoOperation::Write { data } => {
+                    assert_eq!(size, 1);
+                    assert_eq!(address, 0x5000);
+                    assert_eq!(data[0], 0x67);
+                    Ok(None)
+                }
+            })
+            .expect("failed to set the data");
+            false // Continue VM runloop
+        }
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(regs.rax, 0x67);
+        },
+        exit_matcher
+    );
+}
+
+#[rustfmt::skip::macros(global_asm_data)]
+global_asm_data!(
+    test_cpuid_exit_handler_code,
+    ".code16",
+    "cpuid",
+    "hlt",
+);
+
+#[test]
+fn test_cpuid_exit_handler() {
+    let setup = TestSetup {
+        assembly: test_cpuid_exit_handler_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 1, // CPUID input EAX=1 to get virtualization bits.
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher = move |hypervisor_type: HypervisorType, regs: &Regs, _: &_| {
+        if hypervisor_type == HypervisorType::Haxm {
+            let hypervisor_bit = regs.rcx & (1 << 31) != 0;
+            assert!(hypervisor_bit, "Hypervisor bit in CPUID should be set!");
+            assert_eq!(regs.rip, 0x1003, "CPUID did not execute correctly.");
+        }
+    };
+
+    let exit_matcher =
+        |hypervisor_type, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match hypervisor_type {
+                HypervisorType::Whpx => match exit {
+                    VcpuExit::Cpuid { entry } => {
+                        println!("Got Cpuid {:?}", entry);
+                        true // Break runloop
+                    }
+                    r => panic!("unexpected exit reason: {:?}", r),
+                },
+                _ => match exit {
+                    VcpuExit::Hlt => {
+                        true // Break VM runloop
+                    }
+                    r => panic!("unexpected exit reason: {:?}", r),
+                },
+            }
+        };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_control_register_access_invalid_code,
+    ".code16",
+    // Test setting an unused bit in addition to the Protected Mode Enable and Monitor co-processor
+    // bits, which causes a triple fault and hence the invalid bit should never make it to RCX.
+    "mov cr0, eax",
+    "mov ecx, cr0",
+    "hlt",
+);
+
+#[test]
+fn test_control_register_access_invalid() {
+    let setup = TestSetup {
+        assembly: test_control_register_access_invalid_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 0x80000011,
+            rcx: 0,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    // Matcher to check that the RAX value never made it to RCX.
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, _: &_| {
+        assert_eq!(
+            regs.rcx, 0,
+            "RCX value mismatch: expected 0, found {:X}",
+            regs.rcx
+        )
+    };
+
+    let exit_matcher =
+        move |hypervisor_type, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match hypervisor_type {
+                HypervisorType::Kvm | HypervisorType::Haxm => {
+                    match exit {
+                        VcpuExit::Shutdown(_) => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+                _ => {
+                    match exit {
+                        VcpuExit::UnrecoverableException => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+            }
+        };
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_control_register_access_valid_code,
+    // Set the 0th bit (Protected Mode Enable) of CR0, which should succeed.
+    ".code16",
+    "mov cr0, eax",
+    "mov eax, cr0",
+    "hlt",
+);
+
+#[test]
+fn test_control_register_access_valid() {
+    let setup = TestSetup {
+        assembly: test_control_register_access_invalid_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 0x1,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    // Matcher to check the final state of EAX after reading from CR0
+    let regs_matcher = |_: HypervisorType, regs: &Regs, _: &_| {
+        assert!(
+            (regs.rax & 0x1) != 0,
+            "CR0 value mismatch: expected the 0th bit to be set, found {:X}",
+            regs.rax
+        );
+    };
+
+    let exit_matcher =
+        move |_, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+            VcpuExit::Hlt => {
+                true // Break VM runloop
+            }
+            r => panic!("unexpected exit reason: {:?}", r),
+        };
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_debug_register_access_code,
+    ".code16",
+    "mov dr2, eax",
+    "mov ebx, dr2",
+    "hlt",
+);
+
+#[test]
+fn test_debug_register_access() {
+    let setup = TestSetup {
+        assembly: test_debug_register_access_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 0x1234,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher = |_: HypervisorType, regs: &Regs, _: &_| {
+        assert_eq!(
+            regs.rbx, 0x1234,
+            "DR2 value mismatch: expected 0x1234, found {:X}",
+            regs.rbx
+        );
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+// This test only succeeds (by failing Vcpu::Run) on haxm.
+#[cfg(all(windows, feature = "haxm"))]
+#[test]
+fn test_msr_access_invalid() {
+    let msr_index = 0xC0000080; // EFER MSR
+
+    let setup = TestSetup {
+        /*
+            0:  0f 32                   rdmsr
+            2:  83 c8 02                or     ax,0x2 (1st bit is reserved)
+            5:  0f 30                   wrmsr
+            7:  f4                      hlt
+        */
+        assembly: vec![0x0F, 0x32, 0x83, 0xC8, 0x02, 0x0F, 0x30, 0xF4],
+        mem_size: 0x5000,
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rcx: msr_index, // MSR index to read/write
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Shutdown(..) => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(regs.rip, 0x1005); // Should stop at the wrmsr
+        },
+        exit_matcher
+    );
+}
+
+global_asm_data!(
+    test_msr_access_valid_code,
+    ".code16",
+    "rdmsr",
+    "add ax, 1",
+    "wrmsr",
+    "hlt",
+);
+
+#[test]
+fn test_msr_access_valid() {
+    let msr_index = 0x10; // TSC MSR index
+
+    let setup = TestSetup {
+        assembly: test_msr_access_valid_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rcx: msr_index, // MSR index for TSC
+            rflags: 0x2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, _: &_| {
+        assert!(regs.rax > 0x0, "TSC value should be >0");
+        assert_eq!(regs.rip, 0x1008, "Should stop after the hlt instruction");
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[rustfmt::skip::macros(global_asm_data)]
+global_asm_data!(
+    test_getsec_instruction_code,
+    ".code16",
+    "getsec",
+    "hlt",
+);
+
+#[test]
+fn test_getsec_instruction() {
+    let setup = TestSetup {
+        assembly: test_getsec_instruction_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        ..Default::default()
+    };
+
+    let regs_matcher =
+        move |hypervisor_type: HypervisorType, regs: &Regs, _: &_| match hypervisor_type {
+            HypervisorType::Whpx => {}
+            HypervisorType::Haxm => {}
+            _ => {
+                assert_eq!(regs.rip, 0x1000, "GETSEC; expected RIP at 0x1002");
+            }
+        };
+
+    let exit_matcher =
+        move |hypervisor_type, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match hypervisor_type {
+                HypervisorType::Whpx => {
+                    match exit {
+                        VcpuExit::UnrecoverableException => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+                _ => {
+                    match exit {
+                        VcpuExit::Shutdown(_) => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+            }
+        };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[rustfmt::skip::macros(global_asm_data)]
+global_asm_data!(
+    test_invd_instruction_code,
+    ".code16",
+    "invd",
+    "hlt",
+);
+
+#[test]
+fn test_invd_instruction() {
+    let setup = TestSetup {
+        assembly: test_invd_instruction_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher =
+        move |hypervisor_type: HypervisorType, regs: &Regs, _: &_| match hypervisor_type {
+            HypervisorType::Haxm => {}
+            _ => {
+                assert_eq!(regs.rip, 0x1003, "INVD; expected RIP at 0x1003");
+            }
+        };
+    let exit_matcher =
+        move |hypervisor_type, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match hypervisor_type {
+                HypervisorType::Haxm => {
+                    match exit {
+                        VcpuExit::Shutdown(_) => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+                _ => {
+                    match exit {
+                        VcpuExit::Hlt => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+            }
+        };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_xsetbv_instruction_code,
+    ".code16",
+    "mov eax, cr4",
+    // Set the OSXSAVE bit in CR4 (bit 9)
+    "or ax, 0x200",
+    "mov cr4, eax",
+    "xgetbv",
+    "xsetbv",
+    "hlt",
+);
+
+#[test]
+fn test_xsetbv_instruction() {
+    let setup = TestSetup {
+        assembly: test_xsetbv_instruction_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 1, // Set bit 0 in EAX
+            rdx: 0, // XSETBV also uses EDX:EAX, must be initialized
+            rcx: 0, // XCR0
+            rflags: 2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        ..Default::default()
+    };
+
+    let regs_matcher =
+        move |hypervisor_type: HypervisorType, regs: &Regs, _: &_| match hypervisor_type {
+            HypervisorType::Whpx => {}
+            HypervisorType::Haxm => {}
+            HypervisorType::Kvm => {}
+            _ => {
+                assert_eq!(regs.rip, 0x100D, "XSETBV; expected RIP at 0x100D");
+            }
+        };
+
+    let exit_matcher = |_, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+        match exit {
+            VcpuExit::Mmio => {
+                true // Break VM runloop
+            }
+            r => panic!("unexpected exit reason: {:?}", r),
+        }
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_invept_instruction_code,
+    ".code16",
+    "invept eax, [eax]",
+    "hlt",
+);
+
+#[test]
+fn test_invept_instruction() {
+    let setup = TestSetup {
+        assembly: test_invept_instruction_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rax: 0x2000,
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        ..Default::default()
+    };
+
+    let regs_matcher =
+        move |hypervisor_type: HypervisorType, regs: &Regs, _: &_| match hypervisor_type {
+            HypervisorType::Whpx => {}
+            HypervisorType::Haxm => {}
+            HypervisorType::Kvm => {}
+            _ => {
+                assert_eq!(regs.rip, 0x1005, "invept; expected RIP at 0x1005");
+            }
+        };
+
+    let exit_matcher =
+        move |hypervisor_type, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match hypervisor_type {
+                HypervisorType::Whpx => {
+                    match exit {
+                        VcpuExit::UnrecoverableException => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+                _ => {
+                    match exit {
+                        VcpuExit::Shutdown(_) => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+            }
+        };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_invvpid_instruction_code,
+    ".code16",
+    "invvpid eax, [eax]",
+    "hlt",
+);
+
+// TODO(b/342183625): invvpid instruction is not valid in real mode. Reconsider how we should write
+// this test.
+#[test]
+fn test_invvpid_instruction() {
+    let setup = TestSetup {
+        assembly: test_invvpid_instruction_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rax: 0x1500,
+            rflags: 2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_, regs: &Regs, _: &_| {
+        assert_eq!(regs.rip, 0x1000, "INVVPID; expected RIP at 0x1000");
+    };
+
+    let exit_matcher =
+        move |_, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+            VcpuExit::Mmio | VcpuExit::Shutdown(_) | VcpuExit::InternalError => {
+                true // Break VM runloop
+            }
+            r => panic!("unexpected exit reason: {:?}", r),
+        };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[test]
+fn test_vm_instruction_set() {
+    let instructions = vec![
+        (vec![0x0F, 0x01, 0xC1], 0x1000, "VMCALL"), // VMCALL
+        (vec![0x66, 0x0F, 0xC7, 0x30], 0x1004, "VMCLEAR"), // VMCLEAR
+        (vec![0x0F, 0x01, 0xC2], 0x1003, "VMLAUNCH"), // VMLAUNCH
+        (vec![0x0F, 0xC7, 0x30], 0x1003, "VMPTRLD"), // VMPTRLD
+        (vec![0x0F, 0xC7, 0x31], 0x1003, "VMPTRST"), // VMPTRST
+        (vec![0x0F, 0x01, 0xC3], 0x1003, "VMRESUME"), // VMRESUME
+        (vec![0x0F, 0x01, 0xC4], 0x1003, "VMXOFF"), // VMXOFF
+        (vec![0x0F, 0x01, 0xC4], 0x1003, "VMXON"),  // VMXON
+    ];
+
+    for (bytes, expected_rip, name) in instructions {
+        let mut assembly = bytes;
+        assembly.push(0xF4); // Append HLT to each instruction set
+
+        let setup = TestSetup {
+            assembly,
+            load_addr: GuestAddress(0x1000),
+            initial_regs: Regs {
+                rip: 0x1000,
+                rflags: 2,
+                ..Default::default()
+            },
+            ..Default::default()
+        };
+
+        let regs_matcher =
+            move |hypervisor_type: HypervisorType, regs: &Regs, _: &_| match hypervisor_type {
+                HypervisorType::Whpx => {}
+                HypervisorType::Kvm => {}
+                HypervisorType::Haxm => {}
+                _ => {
+                    assert_eq!(
+                        regs.rip, expected_rip,
+                        "{}; expected RIP at {}",
+                        name, expected_rip
+                    );
+                }
+            };
+
+        let exit_matcher =
+            |hypervisor_type, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+                match hypervisor_type {
+                    HypervisorType::Whpx => {
+                        match exit {
+                            VcpuExit::Mmio => {
+                                true // Break VM runloop
+                            }
+                            r => panic!("unexpected exit reason: {:?}", r),
+                        }
+                    }
+                    HypervisorType::Kvm => {
+                        true // Break VM runloop
+                    }
+                    _ => {
+                        match exit {
+                            VcpuExit::Shutdown(_) => {
+                                true // Break VM runloop
+                            }
+                            r => panic!("unexpected exit reason: {:?}", r),
+                        }
+                    }
+                }
+            };
+
+        run_tests!(setup, regs_matcher, exit_matcher);
+    }
+}
+
+#[rustfmt::skip::macros(global_asm_data)]
+global_asm_data!(
+    test_software_interrupt_code,
+    "int 0x80",
+    "hlt",
+);
+
+#[test]
+fn test_software_interrupt() {
+    let start_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: test_software_interrupt_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: start_addr,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher =
+        move |hypervisor_type: HypervisorType, regs: &Regs, _: &_| match hypervisor_type {
+            HypervisorType::Whpx => {}
+            HypervisorType::Haxm => {}
+            HypervisorType::Kvm => {}
+            _ => {
+                let expect_rip_addr = start_addr
+                    + u64::try_from(test_software_interrupt_code::data().len())
+                        .expect("the code length should within the range of u64");
+                assert_eq!(
+                    regs.rip, expect_rip_addr,
+                    "Expected RIP at {:#x}",
+                    expect_rip_addr
+                );
+            }
+        };
+
+    let exit_matcher =
+        |hypervisor_type, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match hypervisor_type {
+                HypervisorType::Kvm | HypervisorType::Whpx => {
+                    match exit {
+                        VcpuExit::Mmio => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+                _ => {
+                    match exit {
+                        VcpuExit::Shutdown(_) => {
+                            true // Break VM runloop
+                        }
+                        r => panic!("unexpected exit reason: {:?}", r),
+                    }
+                }
+            }
+        };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[rustfmt::skip::macros(global_asm_data)]
+global_asm_data!(
+    test_rdtsc_instruction_code,
+    ".code16",
+    "rdtsc",
+    "hlt",
+);
+
+#[test]
+fn test_rdtsc_instruction() {
+    let setup = TestSetup {
+        assembly: test_rdtsc_instruction_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    // This matcher checks that the timestamp counter has been incremented and read into EAX and EDX
+    let regs_matcher = |_: HypervisorType, regs: &Regs, _: &_| {
+        assert!(
+            regs.rax != 0 || regs.rdx != 0,
+            "RDTSC returned a zero value, which is unlikely."
+        );
+    };
+
+    let exit_matcher = |_: HypervisorType,
+                        exit: &VcpuExit,
+                        _: &mut dyn VcpuX86_64,
+                        _: &mut dyn Vm| { matches!(exit, VcpuExit::Hlt) };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+global_asm_data!(
+    test_register_access_code,
+    ".code16",
+    "xchg ax, bx",
+    "xchg cx, dx",
+    "xchg sp, bp",
+    "xchg si, di",
+    "hlt",
+);
+
+// This tests that we can write and read GPRs to/from the VM.
+#[test]
+fn test_register_access() {
+    let start_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: test_register_access_code::data().to_vec(),
+        load_addr: GuestAddress(start_addr),
+        initial_regs: Regs {
+            rip: start_addr,
+            rax: 2,
+            rbx: 1,
+            rcx: 4,
+            rdx: 3,
+            rsp: 6,
+            rbp: 5,
+            rsi: 8,
+            rdi: 7,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(regs.rax, 1);
+            assert_eq!(regs.rbx, 2);
+            assert_eq!(regs.rcx, 3);
+            assert_eq!(regs.rdx, 4);
+            assert_eq!(regs.rsp, 5);
+            assert_eq!(regs.rbp, 6);
+            assert_eq!(regs.rsi, 7);
+            assert_eq!(regs.rdi, 8);
+            assert_eq!(
+                regs.rip,
+                start_addr + test_register_access_code::data().len() as u64
+            );
+        },
+        |_, exit, _, _: &mut dyn Vm| matches!(exit, VcpuExit::Hlt)
+    );
+}
+
+global_asm_data!(
+    test_flags_register_code,
+    ".code16",
+    "jnz fin",
+    "test ax, ax",
+    "fin:",
+    "hlt",
+);
+
+// This tests that we can get/set the flags register from the VMM.
+#[test]
+fn test_flags_register() {
+    let start_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: test_flags_register_code::data().to_vec(),
+        load_addr: GuestAddress(start_addr),
+        initial_regs: Regs {
+            rip: start_addr,
+            rax: 0xffffffff,
+            rflags: 0x42, // zero flag set, sign flag clear
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(regs.rflags & 0x40, 0); // zero flag is clear
+            assert_ne!(regs.rflags & 0x80, 0); // sign flag is set
+            assert_eq!(
+                regs.rip,
+                start_addr + test_flags_register_code::data().len() as u64
+            );
+        },
+        |_, exit, _, _: &mut dyn Vm| matches!(exit, VcpuExit::Hlt)
+    );
+}
+
+global_asm_data!(
+    test_vmm_set_segs_code,
+    ".code16",
+    "mov ax, ds:0",
+    "mov bx, es:0",
+    "mov cx, fs:0",
+    "mov dx, gs:0",
+    "mov sp, ss:0",
+    "hlt",
+);
+
+// This tests that the VMM can set segment registers and have them used by the VM.
+#[test]
+fn test_vmm_set_segs() {
+    let start_addr = 0x1000;
+    let data_addr = 0x2000;
+    let setup = TestSetup {
+        assembly: test_vmm_set_segs_code::data().to_vec(),
+        load_addr: GuestAddress(start_addr),
+        mem_size: 0x4000,
+        initial_regs: Regs {
+            rip: start_addr,
+            rflags: 0x42,
+            ..Default::default()
+        },
+        // simple memory pattern where the value of a byte is (addr - data_addr + 1)
+        memory_initializations: vec![(GuestAddress(data_addr), (1..=32).collect())],
+        extra_vm_setup: Some(Box::new(move |vcpu: &mut dyn VcpuX86_64, _| {
+            let mut sregs = vcpu.get_sregs().expect("failed to get sregs");
+            sregs.ds.base = data_addr;
+            sregs.ds.selector = 0;
+            sregs.es.base = data_addr + 4;
+            sregs.es.selector = 0;
+            sregs.fs.base = data_addr + 8;
+            sregs.fs.selector = 0;
+            sregs.gs.base = data_addr + 12;
+            sregs.gs.selector = 0;
+            sregs.ss.base = data_addr + 16;
+            sregs.ss.selector = 0;
+            vcpu.set_sregs(&sregs).expect("failed to set sregs");
+        })),
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, sregs| {
+            assert_eq!(sregs.ds.base, data_addr);
+            assert_eq!(sregs.es.base, data_addr + 4);
+            assert_eq!(sregs.fs.base, data_addr + 8);
+            assert_eq!(sregs.gs.base, data_addr + 12);
+            assert_eq!(sregs.ss.base, data_addr + 16);
+
+            // ax was loaded from ds:0, which has offset 0, so is [1, 2]
+            assert_eq!(regs.rax, 0x0201);
+            // bx was loaded from es:0, which has offset 4, so is [5, 6]
+            assert_eq!(regs.rbx, 0x0605);
+            // cx was loaded from fs:0, which has offset 8, so is [9, 10]
+            assert_eq!(regs.rcx, 0x0a09);
+            // dx was loaded from gs:0, which has offset 12, so is [13, 14]
+            assert_eq!(regs.rdx, 0x0e0d);
+            // sp was loaded from ss:0, which has offset 16, so is [17, 18]
+            assert_eq!(regs.rsp, 0x1211);
+
+            let expect_rip_addr = start_addr
+                + u64::try_from(test_vmm_set_segs_code::data().len())
+                    .expect("the code length should within the range of u64");
+            assert_eq!(
+                regs.rip, expect_rip_addr,
+                "Expected RIP at {:#x}",
+                expect_rip_addr
+            );
+        },
+        |_, exit, _, _: &mut dyn Vm| matches!(exit, VcpuExit::Hlt)
+    );
+}
+
+global_asm_data!(
+    test_set_cr_vmm_code,
+    ".code16",
+    "mov eax, cr0",
+    "mov ebx, cr3",
+    "mov ecx, cr4",
+    "hlt",
+);
+
+// Tests that the VMM can read and write CRs and they become visible in the guest.
+#[test]
+fn test_set_cr_vmm() {
+    let asm_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: test_set_cr_vmm_code::data().to_vec(),
+        load_addr: GuestAddress(asm_addr),
+        initial_regs: Regs {
+            rip: asm_addr,
+            rflags: 2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, _| {
+            let mut sregs = vcpu.get_sregs().expect("failed to get sregs");
+            sregs.cr0 |= 1 << 18; // Alignment Mask; does nothing without other config bits
+            sregs.cr3 = 0xfeedface; // arbitrary value; CR3 is not used in this configuration
+            sregs.cr4 |= 1 << 2; // Time Stamp Disable; not relevant here
+            vcpu.set_sregs(&sregs).expect("failed to set sregs");
+        })),
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, sregs| {
+            assert_eq!(regs.rax, sregs.cr0);
+            assert_eq!(regs.rbx, sregs.cr3);
+            assert_eq!(regs.rcx, sregs.cr4);
+            assert_eq!(sregs.cr3, 0xfeedface);
+            assert_ne!(sregs.cr0 & (1 << 18), 0);
+            assert_ne!(sregs.cr4 & (1 << 2), 0);
+            assert_eq!(regs.rip, asm_addr + setup.assembly.len() as u64); // after hlt
+        },
+        |_, exit, _, _: &mut dyn Vm| matches!(exit, VcpuExit::Hlt)
+    );
+}
+
+global_asm_data!(
+    test_set_cr_guest_code,
+    ".code16",
+    "mov eax, cr0",
+    "or eax, (1 << 18)",
+    "mov cr0, eax",
+    "mov ebx, 0xfeedface",
+    "mov cr3, ebx",
+    "mov ecx, cr4",
+    "or ecx, (1 << 2)",
+    "mov cr4, ecx",
+    "hlt",
+);
+
+// Tests that the guest can read and write CRs and they become visible to the VMM.
+#[test]
+fn test_set_cr_guest() {
+    let asm_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: test_set_cr_guest_code::data().to_vec(),
+        load_addr: GuestAddress(asm_addr),
+        initial_regs: Regs {
+            rip: asm_addr,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, sregs| {
+            assert_eq!(regs.rax, sregs.cr0);
+            assert_eq!(regs.rbx, sregs.cr3);
+            assert_eq!(regs.rcx, sregs.cr4);
+            assert_eq!(sregs.cr3, 0xfeedface);
+            assert_ne!(sregs.cr0 & (1 << 18), 0);
+            assert_ne!(sregs.cr4 & (1 << 2), 0);
+            assert_eq!(regs.rip, asm_addr + setup.assembly.len() as u64); // after hlt
+        },
+        |_, exit, _, _: &mut dyn Vm| matches!(exit, VcpuExit::Hlt)
+    );
+}
+
+mod test_minimal_interrupt_injection_code {
+    use super::*;
+
+    global_asm_data!(
+        pub init,
+        ".code16",
+        // Set the IDT
+        "lidt [0x200]",
+        // Set up the stack, which will be used when CPU transfers the control to the ISR on
+        // interrupt.
+        "mov sp, 0x900",
+        "mov eax, 902",
+        // We inject our exception on this hlt command.
+        "hlt",
+        "mov ebx, 990",
+        "hlt"
+    );
+
+    global_asm_data!(
+        pub isr,
+        ".code16",
+        "mov eax, 888",
+        "iret"
+    );
+}
+
+#[test]
+fn test_minimal_interrupt_injection() {
+    let start_addr: u32 = 0x200;
+    // Allocate exceed 0x900, where we set up our stack.
+    let mem_size: u32 = 0x1000;
+
+    let mut setup = TestSetup {
+        load_addr: GuestAddress(start_addr.into()),
+        initial_regs: Regs {
+            rax: 0,
+            rbx: 0,
+            // Set RFLAGS.IF to enable interrupt.
+            rflags: 2 | FLAGS_IF_BIT,
+            ..Default::default()
+        },
+        mem_size: mem_size.into(),
+        ..Default::default()
+    };
+
+    let mut cur_addr = start_addr;
+
+    let idtr_size: u32 = 6;
+    assert_eq!(
+        Ok(std::mem::size_of::<Idtr32>()),
+        usize::try_from(idtr_size)
+    );
+    // The limit is calculated from 256 entries timed by 4 bytes per entry.
+    let idt_size = 256u16 * 4u16;
+    let idtr = Idtr32 {
+        limit: idt_size - 1,
+        // The IDT right follows the IDTR.
+        base_address: start_addr + idtr_size,
+    };
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idtr.as_bytes().to_vec());
+    cur_addr += idtr_size;
+
+    let idt_entry = (start_addr + idtr_size + u32::from(idt_size)).to_ne_bytes();
+    // IDT entries are far pointers(CS:IP pair) to the only ISR, which locates right after the IDT.
+    // We set all entries to the same ISR.
+    let idt = (0..256).flat_map(|_| idt_entry).collect::<Vec<_>>();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idt.clone());
+    cur_addr += u32::try_from(idt.len()).expect("IDT size should be within u32");
+
+    let isr_assembly = test_minimal_interrupt_injection_code::isr::data().to_vec();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), isr_assembly.clone());
+    cur_addr += u32::try_from(isr_assembly.len()).expect("ISR size should be within u32");
+
+    let init_assembly = test_minimal_interrupt_injection_code::init::data().to_vec();
+    setup.initial_regs.rip = cur_addr.into();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), init_assembly.clone());
+    cur_addr += u32::try_from(init_assembly.len()).expect("init size should be within u32");
+    let init_end_addr = cur_addr;
+
+    assert!(mem_size > cur_addr);
+
+    let mut counter = 0;
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(regs.rip, u64::from(init_end_addr));
+            assert_eq!(regs.rax, 888);
+            assert_eq!(regs.rbx, 990);
+        },
+        |_, exit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match exit {
+                VcpuExit::Hlt => {
+                    let regs = vcpu
+                        .get_regs()
+                        .expect("should retrieve registers successfully");
+                    counter += 1;
+                    if counter > 1 {
+                        return true;
+                    }
+                    assert!(vcpu.ready_for_interrupt());
+                    assert_eq!(regs.rax, 902);
+                    assert_eq!(regs.rbx, 0);
+                    // Inject an external custom interrupt.
+                    vcpu.interrupt(32)
+                        .expect("should be able to inject an interrupt");
+                    false
+                }
+                r => panic!("unexpected VMEXIT reason: {:?}", r),
+            }
+        }
+    );
+}
+
+mod test_multiple_interrupt_injection_code {
+    use super::*;
+
+    global_asm_data!(
+        pub init,
+        ".code16",
+        // Set the IDT
+        "lidt [0x200]",
+        // Set up the stack, which will be used when CPU transfers the control to the ISR on
+        // interrupt.
+        "mov esp, 0x900",
+        "mov eax, 1",
+        "mov ebx, 2",
+        "mov ecx, 3",
+        "mov edx, 4",
+        // We inject our interrupts on this hlt command.
+        "hlt",
+        "mov edx, 281",
+        "hlt",
+    );
+
+    global_asm_data!(
+        pub isr_intr_32,
+        ".code16",
+        "mov eax, 32",
+        "iret",
+    );
+
+    global_asm_data!(
+        pub isr_intr_33,
+        ".code16",
+        "mov ebx, 33",
+        "iret",
+    );
+
+    global_asm_data!(
+        pub isr_default,
+        ".code16",
+        "mov ecx, 761",
+        "iret",
+    );
+}
+
+#[test]
+fn test_multiple_interrupt_injection() {
+    let start_addr: u32 = 0x200;
+    // Allocate exceed 0x900, where we set up our stack.
+    let mem_size: u32 = 0x1000;
+
+    let mut setup = TestSetup {
+        load_addr: GuestAddress(start_addr.into()),
+        initial_regs: Regs {
+            rax: 0,
+            rbx: 0,
+            rcx: 0,
+            rdx: 0,
+            // Set RFLAGS.IF to enable interrupt.
+            rflags: 2 | FLAGS_IF_BIT,
+            ..Default::default()
+        },
+        mem_size: mem_size.into(),
+        ..Default::default()
+    };
+
+    let mut cur_addr = start_addr;
+
+    let idtr_size: u32 = 6;
+    assert_eq!(
+        Ok(std::mem::size_of::<Idtr32>()),
+        usize::try_from(idtr_size)
+    );
+    // The limit is calculated from 256 entries timed by 4 bytes per entry.
+    let idt_size = 256u16 * 4u16;
+    let idtr = Idtr32 {
+        limit: idt_size - 1,
+        // The IDT right follows the IDTR.
+        base_address: start_addr + idtr_size,
+    };
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idtr.as_bytes().to_vec());
+    cur_addr += idtr_size;
+
+    let isr_intr_32_assembly = test_multiple_interrupt_injection_code::isr_intr_32::data().to_vec();
+    let isr_intr_33_assembly = test_multiple_interrupt_injection_code::isr_intr_33::data().to_vec();
+    let isr_default_assembly = test_multiple_interrupt_injection_code::isr_default::data().to_vec();
+    // The ISR for intr 32 right follows the IDT.
+    let isr_intr_32_addr = cur_addr + u32::from(idt_size);
+    // The ISR for intr 33 right follows the ISR for intr 32.
+    let isr_intr_33_addr = isr_intr_32_addr
+        + u32::try_from(isr_intr_32_assembly.len())
+            .expect("the size of the ISR for intr 32 should be within the u32 range");
+    // The ISR for other interrupts right follows the ISR for intr 33.
+    let isr_default_addr = isr_intr_33_addr
+        + u32::try_from(isr_intr_33_assembly.len())
+            .expect("the size of the ISR for intr 33 should be within the u32 range");
+
+    // IDT entries are far pointers(CS:IP pair) to the correspondent ISR.
+    let idt = (0..256)
+        .map(|intr_vec| match intr_vec {
+            32 => isr_intr_32_addr,
+            33 => isr_intr_33_addr,
+            _ => isr_default_addr,
+        })
+        .flat_map(u32::to_ne_bytes)
+        .collect::<Vec<_>>();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idt.clone());
+    assert_eq!(idt.len(), usize::from(idt_size));
+    cur_addr += u32::try_from(idt.len()).expect("IDT size should be within u32");
+
+    assert_eq!(cur_addr, isr_intr_32_addr);
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), isr_intr_32_assembly.clone());
+    cur_addr += u32::try_from(isr_intr_32_assembly.len()).expect("ISR size should be within u32");
+
+    assert_eq!(cur_addr, isr_intr_33_addr);
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), isr_intr_33_assembly.clone());
+    cur_addr += u32::try_from(isr_intr_33_assembly.len()).expect("ISR size should be within u32");
+
+    assert_eq!(cur_addr, isr_default_addr);
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), isr_default_assembly.clone());
+    cur_addr += u32::try_from(isr_default_assembly.len()).expect("ISR size should be within u32");
+
+    let init_assembly = test_multiple_interrupt_injection_code::init::data().to_vec();
+    setup.initial_regs.rip = cur_addr.into();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), init_assembly.clone());
+    cur_addr += u32::try_from(init_assembly.len()).expect("init size should be within u32");
+    let init_end_addr = cur_addr;
+
+    assert!(mem_size > cur_addr);
+
+    let mut counter = 0;
+    run_tests!(
+        setup,
+        |hypervisor_type, regs, _| {
+            // Different hypervisors behave differently on how the first injected exception should
+            // handled: for WHPX and KVM, the later injected interrupt overrides the earlier
+            // injected interrupt, while for HAXM, both interrupts are marked as pending.
+            match hypervisor_type {
+                HypervisorType::Haxm => assert_eq!(regs.rax, 32),
+                _ => assert_eq!(regs.rax, 1),
+            }
+
+            assert_eq!(regs.rip, u64::from(init_end_addr));
+            assert_eq!(regs.rbx, 33);
+            assert_eq!(regs.rcx, 3);
+            assert_eq!(regs.rdx, 281);
+        },
+        |_, exit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match exit {
+                VcpuExit::Hlt => {
+                    let regs = vcpu
+                        .get_regs()
+                        .expect("should retrieve registers successfully");
+                    counter += 1;
+                    if counter > 1 {
+                        return true;
+                    }
+                    assert_eq!(regs.rax, 1);
+                    assert_eq!(regs.rbx, 2);
+                    assert_eq!(regs.rcx, 3);
+                    assert_eq!(regs.rdx, 4);
+                    // Inject external custom interrupts.
+                    assert!(vcpu.ready_for_interrupt());
+                    vcpu.interrupt(32)
+                        .expect("should be able to inject an interrupt");
+                    assert!(vcpu.ready_for_interrupt());
+                    vcpu.interrupt(33)
+                        .expect("should be able to inject an interrupt");
+                    false
+                }
+                r => panic!("unexpected VMEXIT reason: {:?}", r),
+            }
+        }
+    );
+}
+
+mod test_interrupt_ready_when_not_interruptible_code {
+    use super::*;
+
+    #[derive(Debug, PartialEq, Eq, Clone, Copy)]
+    pub enum Instrumentation {
+        BeforeMovSs,
+        AfterMovSs,
+        AfterAfterMovSs,
+        BeforeSti,
+        AfterSti,
+        AfterAfterSti,
+        InIsr,
+    }
+
+    impl From<u64> for Instrumentation {
+        fn from(value: u64) -> Self {
+            match value {
+                0x10 => Instrumentation::BeforeMovSs,
+                0x20 => Instrumentation::AfterMovSs,
+                0x30 => Instrumentation::AfterAfterMovSs,
+                0x40 => Instrumentation::BeforeSti,
+                0x50 => Instrumentation::AfterSti,
+                0x60 => Instrumentation::AfterAfterSti,
+                0xf0 => Instrumentation::InIsr,
+                _ => panic!("Unknown instrumentation IO port: {}", value),
+            }
+        }
+    }
+
+    // We use port IO to trigger the VMEXIT instead of MMIO, because access to out of bound memory
+    // doesn't trigger MMIO VMEXIT on WHPX under simple real-mode set up.
+    global_asm_data!(
+        pub init,
+        ".code16",
+        // Set up the stack, which will be used when CPU transfers the control to the ISR on
+        // interrupt.
+        "mov sp, 0x1900",
+        // Set the IDT.
+        "lidt [0x200]",
+        // Load the ss register, so that the later mov ss instruction is actually a no-op.
+        "mov ax, ss",
+        "out 0x10, ax",
+        // Hypervisors shouldn't allow interrupt injection right after the mov ss instruction.
+        "mov ss, ax",
+        "out 0x20, ax",
+        // On WHPX we need some other instructions to bring the interuptibility back to normal.
+        // While this is not needed for other hypervisors, we add this instruction unconditionally.
+        "nop",
+        "out 0x30, ax",
+        "out 0x40, ax",
+        // Test hypervisors' interruptibilities right after sti instruction when FLAGS.IF is
+        // cleared.
+        "cli",
+        "sti",
+        "out 0x50, ax",
+        // On WHPX we need some other instructions to bring the interuptibility back to normal.
+        // While this is not needed for other hypervisors, we add this instruction unconditionally.
+        "nop",
+        "out 0x60, ax",
+        "hlt",
+    );
+
+    global_asm_data!(
+        pub isr,
+        ".code16",
+        "out 0xf0, ax",
+        "iret",
+    );
+}
+
+// Physical x86 processor won't allow interrupt to be injected after mov ss or sti, while VM can.
+#[test]
+fn test_interrupt_ready_when_normally_not_interruptible() {
+    use test_interrupt_ready_when_not_interruptible_code::Instrumentation;
+
+    let start_addr: u32 = 0x200;
+    // Allocate exceed 0x1900, where we set up our stack.
+    let mem_size: u32 = 0x2000;
+
+    let mut setup = TestSetup {
+        load_addr: GuestAddress(start_addr.into()),
+        initial_regs: Regs {
+            rax: 0,
+            rbx: 0,
+            // Set RFLAGS.IF to enable interrupt.
+            rflags: 2 | 0x202,
+            ..Default::default()
+        },
+        mem_size: mem_size.into(),
+        ..Default::default()
+    };
+
+    let mut cur_addr = start_addr;
+
+    let idtr_size: u32 = 6;
+    assert_eq!(
+        Ok(std::mem::size_of::<Idtr32>()),
+        usize::try_from(idtr_size)
+    );
+    // The limit is calculated from 256 entries timed by 4 bytes per entry.
+    let idt_size = 256u16 * 4u16;
+    let idtr = Idtr32 {
+        limit: idt_size - 1,
+        // The IDT right follows the IDTR.
+        base_address: start_addr + idtr_size,
+    };
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idtr.as_bytes().to_vec());
+    cur_addr += idtr_size;
+
+    let idt_entry = (start_addr + idtr_size + u32::from(idt_size)).to_ne_bytes();
+    // IDT entries are far pointers(CS:IP pair) to the only ISR, which locates right after the IDT.
+    // We set all entries to the same ISR.
+    let idt = (0..256).flat_map(|_| idt_entry).collect::<Vec<_>>();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idt.clone());
+    cur_addr += u32::try_from(idt.len()).expect("IDT size should be within u32");
+
+    let isr_assembly = test_interrupt_ready_when_not_interruptible_code::isr::data().to_vec();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), isr_assembly.clone());
+    cur_addr += u32::try_from(isr_assembly.len()).expect("ISR size should be within u32");
+
+    let init_assembly = test_interrupt_ready_when_not_interruptible_code::init::data().to_vec();
+    setup.initial_regs.rip = cur_addr.into();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), init_assembly.clone());
+    cur_addr += u32::try_from(init_assembly.len()).expect("init size should be within u32");
+
+    assert!(mem_size > cur_addr);
+
+    // This helps us check the interruptibility under different situations.
+    let interruptibility_traces = RefCell::<Vec<_>>::default();
+    // This helps us check when the interrupt actually delivers.
+    let instrumentation_traces = RefCell::<Vec<_>>::default();
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            use Instrumentation::*;
+            assert_eq!(
+                *interruptibility_traces.borrow(),
+                [
+                    (BeforeMovSs, true),
+                    // Hypervisors don't allow interrupt injection right after mov ss.
+                    (AfterMovSs, false),
+                    (AfterAfterMovSs, true),
+                    (BeforeSti, true),
+                    // Hypervisors don't allow interrupt injection right after sti when FLAGS.IF is
+                    // not set.
+                    (AfterSti, false),
+                    (AfterAfterSti, true)
+                ]
+            );
+            // Hypervisors always deliver the interrupt right after we inject it in the next VCPU
+            // run.
+            assert_eq!(
+                *instrumentation_traces.borrow(),
+                [
+                    BeforeMovSs,
+                    InIsr,
+                    AfterMovSs,
+                    AfterAfterMovSs,
+                    InIsr,
+                    BeforeSti,
+                    InIsr,
+                    AfterSti,
+                    AfterAfterSti,
+                    InIsr,
+                ]
+            );
+            assert_eq!(regs.rip, u64::from(cur_addr));
+        },
+        |_, exit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match exit {
+                VcpuExit::Io => {
+                    let ready_for_interrupt = vcpu.ready_for_interrupt();
+                    let mut should_inject_interrupt = ready_for_interrupt;
+                    vcpu.handle_io(&mut |io_params| {
+                        let instrumentation = Instrumentation::from(io_params.address);
+                        match instrumentation {
+                            Instrumentation::InIsr => {
+                                // Only inject interrupt outside ISR.
+                                should_inject_interrupt = false;
+                            }
+                            _ => {
+                                // Only the interuptibility outside the ISR is important for this
+                                // test.
+                                interruptibility_traces
+                                    .borrow_mut()
+                                    .push((instrumentation, ready_for_interrupt));
+                            }
+                        }
+                        instrumentation_traces.borrow_mut().push(instrumentation);
+                        // We are always handling out IO port, so no data to return.
+                        None
+                    })
+                    .expect("should handle IO successfully");
+                    if should_inject_interrupt {
+                        vcpu.interrupt(32)
+                            .expect("interrupt injection should succeed when ready for interrupt");
+                    }
+                    false
+                }
+                VcpuExit::Hlt => true,
+                r => panic!("unexpected VMEXIT reason: {:?}", r),
+            }
+        }
+    );
+}
+
+global_asm_data!(
+    test_interrupt_ready_when_interrupt_enable_flag_not_set_code,
+    ".code16",
+    "cli",
+    // We can't use hlt for VMEXIT, because HAXM unconditionally allows interrupt injection for
+    // hlt.
+    "out 0x10, ax",
+    "sti",
+    // nop is necessary to avoid the one instruction ineterrupt disable window for sti when
+    // FLAGS.IF is not set.
+    "nop",
+    "out 0x20, ax",
+    "hlt",
+);
+
+#[test]
+fn test_interrupt_ready_when_interrupt_enable_flag_not_set() {
+    let assembly = test_interrupt_ready_when_interrupt_enable_flag_not_set_code::data().to_vec();
+    let setup = TestSetup {
+        assembly: assembly.clone(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            // For VMEXIT caused by HLT, the hypervisor will automatically advance the rIP register.
+            assert_eq!(regs.rip, 0x1000 + assembly.len() as u64);
+        },
+        |_, exit, vcpu, _: &mut dyn Vm| {
+            match exit {
+                VcpuExit::Io => {
+                    let mut addr = 0;
+                    vcpu.handle_io(&mut |io_params| {
+                        addr = io_params.address;
+                        // We are always handling out IO port, so no data to return.
+                        None
+                    })
+                    .expect("should handle IO successfully");
+                    let regs = vcpu
+                        .get_regs()
+                        .expect("should retrieve the registers successfully");
+                    match addr {
+                        0x10 => {
+                            assert_eq!(regs.rflags & FLAGS_IF_BIT, 0);
+                            assert!(!vcpu.ready_for_interrupt());
+                        }
+                        0x20 => {
+                            assert_eq!(regs.rflags & FLAGS_IF_BIT, FLAGS_IF_BIT);
+                            assert!(vcpu.ready_for_interrupt());
+                        }
+                        _ => panic!("unexpected addr: {}", addr),
+                    }
+                    false
+                }
+                VcpuExit::Hlt => true,
+                r => panic!("unexpected VMEXIT reason: {:?}", r),
+            }
+        }
+    );
+}
+
+#[test]
+fn test_enter_long_mode_direct() {
+    global_asm_data!(
+        pub long_mode_asm,
+        ".code64",
+        "mov rdx, rax",
+        "mov rbx, [0x10000]",
+        "hlt"
+    );
+
+    let bigly_mem_value: u64 = 0x1_0000_0000;
+    let biglier_mem_value: u64 = 0x1_0000_0001;
+    let mut setup = TestSetup {
+        assembly: long_mode_asm::data().to_vec(),
+        mem_size: 0x11000,
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rax: bigly_mem_value,
+            rip: 0x1000,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+
+        ..Default::default()
+    };
+
+    setup.add_memory_initialization(
+        GuestAddress(0x10000),
+        biglier_mem_value.to_le_bytes().to_vec(),
+    );
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, sregs: &Sregs| {
+        assert!((sregs.efer & 0x400) != 0, "Long-Mode Active bit not set");
+        assert_eq!(
+            regs.rdx, bigly_mem_value,
+            "Did not execute instructions correctly in long mode."
+        );
+        assert_eq!(
+            regs.rbx, biglier_mem_value,
+            "Was not able to access translated memory in long mode."
+        );
+        assert_eq!((sregs.cs.l), 1, "Long-mode bit not set in CS");
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[test]
+fn test_enter_long_mode_asm() {
+    global_asm_data!(
+        pub enter_long_mode_asm,
+        ".code16",
+        "lidt [0xd100]",             // Address of the IDT limit + base
+        "mov eax, cr4",
+        "or ax, 1 << 7 | 1 << 5",    // Set the PAE-bit (bit 5) and  PGE (bit 7).
+        "mov cr4, eax",
+
+        "mov bx, 0x9000",            // Address of the page table.
+        "mov cr3, ebx",
+
+        "mov ecx, 0xC0000080",       // Set ECX to EFER MSR (0xC0000080)
+        "rdmsr",                     // Read from the MSR
+        "or ax, 1 << 8",             // Set the LM-bit (bit 8).
+        "wrmsr",                     // Write to the MSR
+
+        "mov eax, cr0",
+        "or eax, 1 << 31 | 1 << 0",  // Set PG (31nd bit) & PM (0th bit).
+        "mov cr0, eax",
+
+        "lgdt [0xd000]",             // Address of the GDT limit + base
+        "ljmp 16, 0xe000"            // Address of long_mode_asm
+    );
+
+    global_asm_data!(
+        pub long_mode_asm,
+        ".code64",
+        "mov rdx, r8",
+        "mov rbx, [0x10000]",
+        "hlt"
+    );
+
+    let bigly_mem_value: u64 = 0x1_0000_0000;
+    let biglier_mem_value: u64 = 0x1_0000_0001;
+    let mut setup = TestSetup {
+        assembly: enter_long_mode_asm::data().to_vec(),
+        mem_size: 0x13000,
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            r8: bigly_mem_value,
+            rip: 0x1000,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|_: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            // TODO(b/354901961): configure_long_mode_memory loads GDT and IDT for 64 bit usage, and
+            // the ABI doesn't match real mode and protected mode, but in this test, we first launch
+            // in real mode.
+
+            ModeConfig::default_long_mode().configure_long_mode_memory(vm);
+        })),
+
+        ..Default::default()
+    };
+
+    setup.add_memory_initialization(
+        GuestAddress(0x10000),
+        biglier_mem_value.to_le_bytes().to_vec(),
+    );
+    setup.add_memory_initialization(GuestAddress(0xe000), long_mode_asm::data().to_vec());
+
+    // GDT limit + base, to be loaded by the lgdt instruction.
+    // Must be within 0xFFFF as it's executed in real-mode.
+    setup.add_memory_initialization(GuestAddress(0xd000), 0xFFFF_u32.to_le_bytes().to_vec());
+    setup.add_memory_initialization(
+        GuestAddress(0xd000 + 2),
+        (DEFAULT_GDT_OFFSET as u32).to_le_bytes().to_vec(),
+    );
+
+    // IDT limit + base, to be loaded by the lidt instruction.
+    // Must be within 0xFFFF as it's executed in real-mode.
+    setup.add_memory_initialization(GuestAddress(0xd100), 0xFFFF_u32.to_le_bytes().to_vec());
+    setup.add_memory_initialization(
+        GuestAddress(0xd100 + 2),
+        (DEFAULT_IDT_OFFSET as u32).to_le_bytes().to_vec(),
+    );
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, sregs: &Sregs| {
+        assert!((sregs.efer & 0x400) != 0, "Long-Mode Active bit not set");
+        assert_eq!(
+            regs.rdx, bigly_mem_value,
+            "Did not execute instructions correctly in long mode."
+        );
+        assert_eq!(
+            regs.rbx, biglier_mem_value,
+            "Was not able to access translated memory in long mode."
+        );
+        assert_eq!((sregs.cs.l), 1, "Long-mode bit not set in CS");
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[test]
+fn test_request_interrupt_window() {
+    global_asm_data!(
+        assembly,
+        ".code16",
+        // Disable the interrupt, and the interrupt window shouldn't cause a vcpu exit until the
+        // interrupt is enabled again.
+        "cli",
+        // vcpu exit here to request an interrupt window when interrupt is not ready. We can't use
+        // hlt for VMEXIT, because HAXM unconditionally allows interrupt injection for hlt.
+        "out 0x10, ax",
+        // Enable the interrupt.
+        "sti",
+        // Another instruction window for interrupt delivery after sti. We shouldn't receive the
+        // interrupt window exit until we complete this instruction. We use another intercepted
+        // instruction here to make sure the hypervisor doesn't shadow the not delivered interrupt
+        // request window on an intercepted instruction.
+        "out 0x10, ax",
+        // WHPX requires another not intercepted instruction to restore from the not interruptible
+        // state.
+        "nop",
+        // The interrupt window exit should happen either right before nop or right after nop.
+        "hlt",
+    );
+
+    let assembly = assembly::data().to_vec();
+    let setup = TestSetup {
+        assembly: assembly.clone(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        intercept_intr: true,
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| assert_eq!(regs.rip, 0x1000 + assembly.len() as u64),
+        {
+            let mut io_counter = 0;
+            let mut irq_window_received = false;
+            move |hypervisor_type, exit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+                let is_irq_window = if hypervisor_type == HypervisorType::Haxm {
+                    matches!(exit, VcpuExit::Intr) && io_counter == 2
+                } else {
+                    matches!(exit, VcpuExit::IrqWindowOpen)
+                };
+                if is_irq_window {
+                    assert_eq!(io_counter, 2);
+                    assert!(vcpu.ready_for_interrupt());
+                    vcpu.set_interrupt_window_requested(false);
+
+                    irq_window_received = true;
+                    return false;
+                }
+                match exit {
+                    VcpuExit::Intr => false,
+                    VcpuExit::Io => {
+                        // We are always handling out IO port, so no data to return.
+                        vcpu.handle_io(&mut |_| None)
+                            .expect("should handle IO successfully");
+
+                        assert!(!vcpu.ready_for_interrupt());
+
+                        // Only set the interrupt window request on the first out instruction.
+                        if io_counter == 0 {
+                            vcpu.set_interrupt_window_requested(true);
+                        }
+                        io_counter += 1;
+                        false
+                    }
+                    VcpuExit::Hlt => {
+                        assert!(irq_window_received);
+                        true
+                    }
+                    r => panic!("unexpected VMEXIT: {:?}", r),
+                }
+            }
+        }
+    );
+}
+
+#[test]
+fn test_fsgsbase() {
+    global_asm_data!(
+        pub fsgsbase_asm,
+        ".code64",
+        "wrfsbase rax",
+        "wrgsbase rbx",
+        "rdfsbase rcx",
+        "rdgsbase rdx",
+        "mov rax, fs:0",
+        "mov rbx, gs:0",
+        "hlt"
+    );
+
+    let code_addr = 0x1000;
+    let fs = 0x10000;
+    let gs = 0x10100;
+
+    let setup = TestSetup {
+        assembly: fsgsbase_asm::data().to_vec(),
+        mem_size: 0x11000,
+        load_addr: GuestAddress(code_addr),
+        initial_regs: Regs {
+            rax: fs,
+            rbx: gs,
+            rip: code_addr,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+
+            let mut sregs = vcpu.get_sregs().expect("unable to get sregs");
+            sregs.cr4 |= 1 << 16; // FSGSBASE (bit 16)
+            vcpu.set_sregs(&sregs).expect("unable to set sregs");
+        })),
+        memory_initializations: vec![
+            (GuestAddress(fs), [0xaa; 8].into()),
+            (GuestAddress(gs), [0xbb; 8].into()),
+        ],
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, sregs: &Sregs| {
+        assert_eq!(regs.rcx, fs);
+        assert_eq!(regs.rdx, gs);
+        assert_eq!(regs.rax, 0xaaaaaaaaaaaaaaaa);
+        assert_eq!(regs.rbx, 0xbbbbbbbbbbbbbbbb);
+        assert_eq!(sregs.fs.base, fs);
+        assert_eq!(sregs.gs.base, gs);
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+/// Tests whether MMX state is being preserved by the hypervisor correctly (e.g. the hypervisor is
+/// properly using fxsave/fxrstor, or xsave/xrstor (or xsaves/xrstors)).
+#[test]
+fn test_mmx_state_is_preserved_by_hypervisor() {
+    // This program stores a sentinel value into mm0 (the first MMX register) and verifies
+    // that after a vmexit, that value is properly restored (we copy it to rbx so it can be checked
+    // by the reg matcher when the VM hlts). In the vmexit handler function below, we make sure the
+    // sentinel value is NOT in mm0. This way we know the mm0 value has changed, so we're guaranteed
+    // the hypervisor has to restore the guest's sentinel value for the test to pass. (The read
+    // from mm0 to rbx happens *after* the vmexit, so the hypervisor has to restore the guest's
+    // mm0 otherwise there will be random garbage in there from the host. This would also be a
+    // security issue.)
+    //
+    // Note: this program also verifies the guest has MMX support. If it does not, rdx will be 1 and
+    // no MMX instructions will be attempted.
+    let sentinel_mm0_value = 0x1337FFFFu64;
+    global_asm_data!(
+        pub mmx_ops_asm,
+        ".code64",
+        "mov eax, 1",
+        "cpuid",
+        "bt edx, 23",
+        "jc HasMMX",
+        "mov rdx, 1",
+        "hlt",
+        "HasMMX:",
+        "xor rdx, rdx",
+        "mov rax, 0x1337FFFF",
+        "mov rbx, 0x0",
+        "movq mm0, rax",
+        "out 0x5, al",
+        "movq rbx, mm0",
+        "emms",
+        "hlt",
+    );
+
+    let code_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: mmx_ops_asm::data().to_vec(),
+        mem_size: 0x12000,
+        load_addr: GuestAddress(code_addr),
+        initial_regs: Regs {
+            rip: code_addr,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        memory_initializations: vec![],
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, _: &_| {
+        assert_ne!(regs.rdx, 1, "guest has no MMX support");
+        assert_eq!(
+            regs.rbx, sentinel_mm0_value,
+            "guest MMX register not restored by hypervisor"
+        );
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        VcpuExit::Cpuid { entry } => {
+            vcpu.handle_cpuid(entry)
+                .expect("should handle cpuid successfully");
+            false
+        }
+        VcpuExit::Io => {
+            vcpu.handle_io(&mut |_| None)
+                .expect("should handle IO successfully");
+
+            // kaiyili@ pointed out we should check the XSAVE state exposed by the hypervisor via
+            // its API (e.g. vm.get_xsave_state). This is used in snapshotting, so if it's wrong,
+            // that would break things. It's also a good cross-check that the hypervisor is properly
+            // handling xsave state.
+            //
+            // There are a couple of things blocking us from doing that today:
+            //      1. gHAXM, our hypervisor of interest, doesn't expose its xsave area state for
+            //         the guest.
+            //      2. We don't have an xsave area parser (yet).
+
+            // mm0 MUST NOT have the guest's sentinel value. If it somehow does, the hypervisor
+            // didn't save the guest's FPU/MMX state / restore the host's state before exiting to
+            // CrosVM.
+            //
+            // Note: MMX is ubiquitous on x86_64, so we don't check for support on the host (the
+            // guest checks, so unless the guest's support is software implemented, it's highly
+            // likely the host has MMX support).
+            let mut mm0_value: u64;
+            // SAFETY: we do not clobber any undeclared registers. Technically emms changes some
+            // x87 state, so there's some UB risk here, but it is not explicitly called out by
+            // the Rust docs as a bad idea.
+            unsafe {
+                asm!(
+                    "movq rax, mm0",
+                    "emms",
+                    out("rax") mm0_value);
+            }
+            assert_ne!(
+                mm0_value, sentinel_mm0_value,
+                "host mm0 value is the same as the guest sentinel value"
+            );
+            false
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+/// Tests whether AVX state is being preserved by the hypervisor correctly (e.g. the hypervisor is
+/// properly using xsave/xrstor (or xsaves/xrstors)). This is very similar to the MMX test, but
+/// AVX state is *not* captured by fxsave, so that's how we guarantee xsave state of some kind is
+/// being handled properly.
+#[test]
+fn test_avx_state_is_preserved_by_hypervisor() {
+    if !is_x86_feature_detected!("avx") {
+        panic!("this test requires host AVX support and it was not detected");
+    }
+
+    let sentinel_value = 0x1337FFFFu64;
+    global_asm_data!(
+        pub avx_ops_asm,
+        ".code64",
+        "mov eax, 1",
+        "cpuid",
+        "bt ecx, 28",
+        "jc HasAVX",
+        "mov rdx, 1",
+        "hlt",
+        "HasAVX:",
+
+        // Turn on OSXSAVE (we can't touch XCR0 without it).
+        "mov rax, cr4",
+        "or eax, 1 << 18",
+        "mov cr4, rax",
+
+        // AVX won't work unless we enable it.
+        //
+        // Set the relevant XCR0 bits:
+        //   0: X87
+        //   1: SSE
+        //   2: AVX
+        "xor rcx, rcx",
+        "xgetbv",
+        // (7 = 111b)
+        "or eax, 7",
+        "xsetbv",
+
+        // Now that AVX is ready to use, let's start with a clean slate (and signify we have AVX
+        // support to the test assert below by zeroing rdx).
+        "xor rdx, rdx",
+        "xor rax, rax",
+        "xor rbx, rbx",
+        "vzeroall",
+
+        // Here's the actual test (finally). Since AVX is a little tricky to follow, here's what
+        // the test does:
+        //      1. We load 0x1337FFFF into ymm1 via xmm0.
+        //      2. We perform port IO to exit out to CrosVM (our vmexit handler below).
+        //      3. The vmexit handler makes sure ymm1 does NOT contain 0x1337FFFF.
+        //      4. We return to this program. Then we dump the value of ymm1 into ebx. The exit
+        //         register matcher verifies that 0x1337FFFF is in ebx. This means the hypervisor
+        //         properly restored ymm1 for the guest on vmenter.
+        "mov eax, 0x1337FFFF",
+        "vpinsrd xmm0, xmm1, eax, 3",
+        "vinserti128 ymm1, ymm2, xmm0, 1",
+        "out 0x5, al",
+        "vextracti128 xmm3, ymm1, 1",
+        "vpextrd ebx, xmm3, 3",
+        "hlt",
+    );
+
+    let code_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: avx_ops_asm::data().to_vec(),
+        mem_size: 0x12000,
+        load_addr: GuestAddress(code_addr),
+        initial_regs: Regs {
+            rip: code_addr,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        memory_initializations: vec![],
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, _: &_| {
+        assert_ne!(regs.rdx, 1, "guest has no AVX support");
+        assert_eq!(
+            regs.rbx, sentinel_value,
+            "guest AVX register not restored by hypervisor"
+        );
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        VcpuExit::Cpuid { entry } => {
+            vcpu.handle_cpuid(entry)
+                .expect("should handle cpuid successfully");
+            false
+        }
+        VcpuExit::Io => {
+            vcpu.handle_io(&mut |_| None)
+                .expect("should handle IO successfully");
+
+            // kaiyili@ pointed out we should check the XSAVE state exposed by the hypervisor via
+            // its API (e.g. vm.get_xsave_state). This is used in snapshotting, so if it's wrong,
+            // that would break things. It's also a good cross-check that the hypervisor is properly
+            // handling xsave state.
+            //
+            // There are a couple of things blocking us from doing that today:
+            //      1. gHAXM, our hypervisor of interest, doesn't expose its xsave area state for
+            //         the guest.
+            //      2. We don't have a xsave area parser (yet).
+
+            // ymm1 MUST NOT have the guest's sentinel value. If it somehow does, the hypervisor
+            // didn't save the guest's AVX state / restore the host's state before exiting to
+            // CrosVM.
+            //
+            // Note: AVX is ubiquitous on x86_64, so we don't check for support on the host (the
+            // guest checks, so unless the guest's support is software implemented, it's highly
+            // likely the host has AVX support).
+            let mut ymm1_sub_value: u64;
+            // SAFETY: we don't clobber any undeclared registers.
+            unsafe {
+                asm!(
+                "vextracti128 xmm4, ymm1, 1",
+                "vpextrd eax, xmm4, 3",
+                out("rax") ymm1_sub_value,
+                out("xmm4") _);
+            }
+            assert_ne!(
+                ymm1_sub_value, sentinel_value,
+                "host ymm1 value is the same as the guest sentinel value. Hypervisor likely didn't \
+                    save guest's state."
+            );
+            false
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+/// Tests whether XSAVE works inside a guest.
+#[test]
+fn test_xsave() {
+    let sentinel_xmm0_value = 0x1337FFFFu64;
+    global_asm_data!(
+        pub xsave_ops_asm,
+        ".code64",
+
+        // Make sure XSAVE is supported.
+        "mov eax, 1",
+        "mov ecx, 0",
+        "cpuid",
+        "bt ecx, 26",
+        "jc HasXSAVE",
+        "mov rdx, 1",
+        "hlt",
+        "HasXSAVE:",
+        "xor rdx, rdx",
+
+        // Turn on OSXSAVE.
+        "mov rax, cr4",
+        "or eax, 1 << 18",
+        "mov cr4, rax",
+
+        // Enable X87, SSE, and AVX.
+        //
+        // Set the relevant XCR0 bits:
+        //   0: X87
+        //   1: SSE
+        //   3: AVX
+        "xor rcx, rcx",
+        "xgetbv",
+        // (7 = 111b)
+        "or eax, 7",
+        "xsetbv",
+
+        // Put the sentinel value in xmm0, and save it off.
+        "mov eax, 0x1337FFFF",
+        "vzeroall",
+        "vpinsrd xmm0, xmm1, eax, 3",
+        "xor edx, edx",
+        "mov eax, 7",
+        "xsave dword ptr [0x10000]",
+
+        // Clear xmm0.
+        "vpxor xmm0, xmm0, xmm0",
+
+        // Restoring should put the sentinel value back.
+        "xor edx, edx",
+        "mov eax, 7",
+        "xrstor dword ptr [0x10000]",
+
+        "xor rbx, rbx",
+        "vpextrd ebx, xmm0, 3",
+        "hlt",
+    );
+
+    let code_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: xsave_ops_asm::data().to_vec(),
+        mem_size: 0x12000,
+        load_addr: GuestAddress(code_addr),
+        initial_regs: Regs {
+            rip: code_addr,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        memory_initializations: vec![(GuestAddress(0x10000), vec![0; 0x1000])],
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, _: &_| {
+        assert_ne!(regs.rdx, 1, "guest has no XSAVE support");
+        assert_eq!(
+            regs.rbx, sentinel_xmm0_value,
+            "guest SSE register not restored by XRSTOR",
+        );
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        VcpuExit::Cpuid { entry } => {
+            vcpu.handle_cpuid(entry)
+                .expect("should handle cpuid successfully");
+            false
+        }
+        VcpuExit::MsrAccess => false, // MsrAccess handled by hypervisor impl
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+/// Tests whether XSAVES works inside a guest.
+///
+/// Ignored because CET is not available in some nested virtualization
+/// environments (such as CI). (CET is the feature we use to test XSAVES.)
+#[ignore]
+#[cfg(feature = "whpx")]
+#[test]
+fn test_xsaves() {
+    global_asm_data!(
+        pub xsaves_ops_asm,
+        ".code64",
+
+        // Make sure XSAVES is supported.
+        "mov eax, 0xd",
+        "mov ecx, 1",
+        "cpuid",
+        "bt eax, 3",
+        "jc HasXSAVES",
+        "mov rdx, 1",
+        "hlt",
+        "HasXSAVES:",
+
+        // Make sure CET is supported.
+        "mov eax, 7",
+        "mov ecx, 0",
+        "cpuid",
+        "bt ecx, 7",
+        "jc HasCET",
+        "mov rdx, 2",
+        "hlt",
+        "HasCET:",
+
+        // Turn on write protection for ring 0 (required by CET).
+        "mov rax, cr0",
+        "or eax, 1 << 16",
+        "mov cr0, rax",
+
+        // Turn on OSXSAVE (18) and CET (23).
+        "mov rax, cr4",
+        "or eax, 1 << 18",
+        "or eax, 1 << 23",
+        "mov cr4, rax",
+
+        // Set up XSAVES to manage CET state.
+        // IA32_XSS = 0x0DA0
+        "mov ecx, 0x0DA0",
+        "rdmsr",
+        "or eax, 1 << 12",
+        "wrmsr",
+
+        // Enable CET.
+        "mov ecx, 0x6A2",
+        "rdmsr",
+        "or eax, 1",
+        "wrmsr",
+
+        // Now CET is usable and managed by XSAVES. Let's set a sentinel value and make sure xsaves
+        // restores it as expected. Note that PL0_SSP's linear address must be 8 byte aligned.
+        // PL0_SSP = 0x06A5
+        "mov ecx, 0x06A4",
+        "xor edx, edx",
+        "xor eax, eax",
+        "mov eax, 0x13370000",
+        "wrmsr",
+
+        // Set the RFBM / feature mask to include CET.
+        "xor edx, edx",
+        "mov eax, 1 << 12",
+        "xsaves dword ptr [0x10000]",
+
+        // Clear PL0_SSP
+        "xor edx, edx",
+        "xor eax, eax",
+        "mov ecx, 0x06A4",
+        "wrmsr",
+
+        // Set the RFBM / feature mask to include CET.
+        "xor edx, edx",
+        "mov eax, 1 << 12",
+        "xrstors dword ptr [0x10000]",
+
+        // Check to see if PL0_SSP was restored.
+        "mov ecx, 0x06A4",
+        "rdmsr",
+        "cmp eax, 0x13370000",
+        "jz TestPasses",
+        "mov rdx, 3",
+        "hlt",
+        "TestPasses:",
+        "xor rdx, rdx",
+        "hlt",
+    );
+
+    let code_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: xsaves_ops_asm::data().to_vec(),
+        mem_size: 0x12000,
+        load_addr: GuestAddress(code_addr),
+        initial_regs: Regs {
+            rip: code_addr,
+            rdx: 0x4,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        memory_initializations: vec![(GuestAddress(0x10000), vec![0; 0x1000])],
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, _: &_| {
+        assert_ne!(regs.rdx, 1, "guest has no XSAVES support");
+        assert_ne!(regs.rdx, 2, "guest has no CET support");
+        assert_ne!(regs.rdx, 3, "guest didn't restore PL0_SSP as expected");
+        assert_eq!(regs.rdx, 0, "test failed unexpectedly");
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        VcpuExit::Cpuid { entry } => {
+            vcpu.handle_cpuid(entry)
+                .expect("should handle cpuid successfully");
+            false
+        }
+        VcpuExit::MsrAccess => false, // MsrAccess handled by hypervisor impl
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+/// Tests that XSAVES is disabled in gHAXM (it's unsupported).
+///
+/// Note: this test passing in CI is not necessarily a signal that gHAXM is working correctly
+/// because XSAVES is disabled in some nested virtualization environments (e.g. CI).
+#[cfg(feature = "haxm")]
+#[test]
+fn test_xsaves_is_disabled_on_haxm() {
+    global_asm_data!(
+        pub no_xsaves_asm,
+        ".code64",
+
+        "mov eax, 0xd",
+        "mov ecx, 1",
+        "cpuid",
+        "bt eax, 3",
+        "jnc NoXSAVES",
+        "mov rdx, 1",
+        "hlt",
+        "NoXSAVES:",
+        "mov rdx, 0",
+        "hlt",
+    );
+
+    let code_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: no_xsaves_asm::data().to_vec(),
+        mem_size: 0x12000,
+        load_addr: GuestAddress(code_addr),
+        initial_regs: Regs {
+            rip: code_addr,
+            rdx: 0x2,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        memory_initializations: vec![],
+        ..Default::default()
+    };
+
+    let regs_matcher = move |_: HypervisorType, regs: &Regs, _: &_| {
+        assert_ne!(regs.rdx, 1, "guest has XSAVES support and shouldn't");
+        assert_eq!(regs.rdx, 0, "test failed unexpectedly");
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        VcpuExit::Cpuid { entry } => {
+            vcpu.handle_cpuid(entry)
+                .expect("should handle cpuid successfully");
+            false
+        }
+        VcpuExit::MsrAccess => false, // MsrAccess handled by hypervisor impl
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+/// Tests whether SLAT is updated properly when a region is removed from the guest. A correctly
+/// implemented hypervisor will flush the TLB such that this immediately hits a SLAT fault and comes
+/// to us as MMIO. If we don't see that, and the guest actually reads from the removed region, the
+/// test will fail. In the real world, this would be a guest read from a random pfn, which is
+/// UB (and a major security problem).
+///
+/// Flakes should be treated as real failures (this test can show a false negative, but never a
+/// false positive).
+#[test]
+fn test_slat_on_region_removal_is_mmio() {
+    global_asm_data!(
+        pub test_asm,
+        ".code64",
+
+        // Load the TLB with a mapping for the test region.
+        "mov al, byte ptr [0x20000]",
+
+        // Signal to the host that VM is running. On this vmexit, the host will unmap the test
+        // region.
+        "out 0x5, al",
+
+        // This read should result in MMIO, and if it does, the test passes. If we hit the hlt, then
+        // the test fails (since it means we were able to satisfy this read without exiting).
+        "mov al, byte ptr [0x20000]",
+        "hlt"
+    );
+
+    const TEST_MEM_REGION_SIZE: usize = 0x1000;
+    let memslot: Arc<Mutex<Option<MemSlot>>> = Arc::new(Mutex::new(None));
+    let memslot_for_func = memslot.clone();
+
+    let code_addr = 0x1000;
+    let setup = TestSetup {
+        assembly: test_asm::data().to_vec(),
+        mem_size: 0x12000,
+        load_addr: GuestAddress(code_addr),
+        initial_regs: Regs {
+            rip: code_addr,
+            rflags: 0x2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(
+            move |vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+                ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+
+                // Create a test pinned memory region that is all 0xFF.
+                let shm = SharedMemory::new("test", TEST_MEM_REGION_SIZE as u64).unwrap();
+                let test_region = Box::new(
+                    MemoryMappingBuilder::new(TEST_MEM_REGION_SIZE)
+                        .from_shared_memory(&shm)
+                        .build()
+                        .unwrap(),
+                );
+                let ff_init = [0xFFu8; TEST_MEM_REGION_SIZE];
+                test_region.write_slice(&ff_init, 0).unwrap();
+                let test_region = Box::new(
+                    PinnedMemoryRegion::new(test_region).expect("failed to pin test region"),
+                );
+                *memslot_for_func.lock() = Some(
+                    vm.add_memory_region(
+                        GuestAddress(0x20000),
+                        test_region,
+                        false,
+                        false,
+                        MemCacheType::CacheCoherent,
+                    )
+                    .unwrap(),
+                );
+            },
+        )),
+        memory_initializations: vec![],
+        ..Default::default()
+    };
+
+    // Holds the test memory region after it's unmapped and the VM is still running. Without this,
+    // incorrect access to the region by the VM would be unsafe / UB.
+    let test_region_arc: Arc<Mutex<Option<Box<dyn MappedRegion>>>> = Arc::new(Mutex::new(None));
+    let test_region_arc_for_exit = test_region_arc.clone();
+
+    let exit_matcher =
+        move |_, exit: &VcpuExit, vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| match exit {
+            VcpuExit::Io => {
+                // WHPX insists on data being returned here or it throws MemoryCallbackFailed.
+                //
+                // We strictly don't care what this data is, since the VM exits before running any
+                // further instructions.
+                vcpu.handle_io(&mut |_| None)
+                    .expect("should handle IO successfully");
+
+                // Remove the test memory region to cause a SLAT fault (in the passing case).
+                //
+                // This also ensures the memory region remains pinned in host physical memory so any
+                // incorrect accesses to it by the VM will remain safe.
+                *test_region_arc_for_exit.lock() =
+                    Some(vm.remove_memory_region(memslot.lock().unwrap()).unwrap());
+                false
+            }
+            VcpuExit::Mmio => {
+                vcpu.handle_mmio(&mut |IoParams {
+                                           address,
+                                           size,
+                                           operation,
+                                       }| {
+                    assert_eq!(address, 0x20000, "MMIO for wrong address");
+                    assert_eq!(size, 1);
+                    assert!(
+                        matches!(operation, IoOperation::Read),
+                        "got unexpected IO operation {:?}",
+                        operation
+                    );
+                    // We won't vmenter again, so there's no need to actually satisfy the MMIO by
+                    // returning data; however, some hypervisors (WHPX) require it.
+                    Ok(Some([0u8; 8]))
+                })
+                .unwrap();
+                true
+            }
+            VcpuExit::Hlt => {
+                panic!("VM should not reach the hlt instruction (MMIO should've ended the VM)");
+            }
+            r => panic!("unexpected exit reason: {:?}", r),
+        };
+
+    // We want to catch if the hypervisor doesn't clear the VM's TLB. If we hop between CPUs, then
+    // we're likely to end up with a clean TLB on another CPU.
+    set_cpu_affinity(vec![0]).unwrap();
+
+    run_tests!(setup, move |_, _, _| {}, &exit_matcher);
+}
+
+struct PinnedMemoryRegion {
+    mem_region: Box<dyn MappedRegion>,
+}
+
+impl PinnedMemoryRegion {
+    fn new(mem_region: Box<dyn MappedRegion>) -> base::Result<Self> {
+        // SAFETY:
+        // ptr is a valid pointer and points to a region of the supplied size.
+        unsafe { pin_memory(mem_region.as_ptr() as *mut _, mem_region.size()) }?;
+        Ok(Self { mem_region })
+    }
+}
+
+// SAFETY:
+// Safe because ptr & size a memory range owned by this MemoryMapping that won't be unmapped
+// until it's dropped.
+unsafe impl MappedRegion for PinnedMemoryRegion {
+    fn as_ptr(&self) -> *mut u8 {
+        self.mem_region.as_ptr()
+    }
+
+    fn size(&self) -> usize {
+        self.mem_region.size()
+    }
+}
+
+impl Drop for PinnedMemoryRegion {
+    fn drop(&mut self) {
+        // SAFETY:
+        // memory region passed is a valid pointer and points to a region of the
+        // supplied size. We also panic on failure.
+        unsafe { unpin_memory(self.mem_region.as_ptr() as *mut _, self.mem_region.size()) }
+            .expect("failed to unpin memory")
+    }
+}
+
+unsafe fn pin_memory(ptr: *mut c_void, len: usize) -> base::Result<()> {
+    #[cfg(windows)]
+    {
+        if VirtualLock(ptr, len).into() {
+            Ok(())
+        } else {
+            Err(base::Error::last())
+        }
+    }
+    #[cfg(unix)]
+    {
+        if libc::mlock(ptr, len) != 0 {
+            Err(base::Error::last())
+        } else {
+            Ok(())
+        }
+    }
+}
+
+unsafe fn unpin_memory(ptr: *mut c_void, len: usize) -> base::Result<()> {
+    #[cfg(windows)]
+    {
+        if VirtualUnlock(ptr, len).into() {
+            Ok(())
+        } else {
+            Err(base::Error::last())
+        }
+    }
+    #[cfg(unix)]
+    {
+        if libc::munlock(ptr, len) != 0 {
+            Err(base::Error::last())
+        } else {
+            Ok(())
+        }
+    }
+}
+
+#[test]
+fn test_interrupt_injection_when_not_ready() {
+    // This test ensures that if we inject an interrupt when it's not ready for interrupt, we
+    // shouldn't end up with crash or hang. And if the interrupt is delivered, it shouldn't be
+    // delivered before we reenable the interrupt.
+    mod assembly {
+        use super::*;
+
+        global_asm_data!(
+            pub init,
+            ".code16",
+            // Set the IDT
+            "lidt [0x200]",
+            // Set up the stack, which will be used when CPU transfers the control to the ISR on
+            // interrupt.
+            "mov sp, 0x900",
+            // Set ax to 0.
+            "xor ax, ax",
+            // Set the address 0x910 to 1 when we disable the interrupt, and restore it to 0 after
+            // we renable the interrupt.
+            "mov word ptr [0x910], 1",
+            "cli",
+            // We can't use hlt for VMEXIT, because HAXM unconditionally allows interrupt injection
+            // for hlt. We will inject an interrupt here although all hypervisors should report not
+            // ready for injection an interrupt. And we don't care if the injection succeeds or not.
+            "out 0x10, ax",
+            "sti",
+            // Set the address 0x910 to 0 when we renable the interrupt.
+            "mov word ptr [0x910], 0",
+            // For hypervisor that injects the interrupt later when it's ready, the interrupt will
+            // be delivered here.
+            "nop",
+            "hlt",
+        );
+
+        // We still need an ISR in case the hypervisor actually delivers an interrupt.
+        global_asm_data!(
+            pub isr,
+            ".code16",
+            // ax will be 0 if the interrupt is delivered after we reenable the interrupt.
+            // Otherwise, ax will be 1, and the test fails.
+            "mov ax, word ptr [0x910]",
+            "iret",
+        );
+    }
+
+    let start_addr: u32 = 0x200;
+    // Allocate exceed 0x900, where we set up our stack.
+    let mem_size: u32 = 0x1000;
+
+    let mut setup = TestSetup {
+        load_addr: GuestAddress(start_addr.into()),
+        initial_regs: Regs {
+            rax: 0,
+            // Set RFLAGS.IF to enable interrupt at the beginning.
+            rflags: 2 | FLAGS_IF_BIT,
+            ..Default::default()
+        },
+        mem_size: mem_size.into(),
+        ..Default::default()
+    };
+
+    let mut cur_addr = start_addr;
+
+    let idtr_size: u32 = 6;
+    assert_eq!(
+        Ok(std::mem::size_of::<Idtr32>()),
+        usize::try_from(idtr_size)
+    );
+    // The limit is calculated from 256 entries timed by 4 bytes per entry.
+    let idt_size = 256u16 * 4u16;
+    let idtr = Idtr32 {
+        limit: idt_size - 1,
+        // The IDT right follows the IDTR.
+        base_address: start_addr + idtr_size,
+    };
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idtr.as_bytes().to_vec());
+    cur_addr += idtr_size;
+
+    let idt_entry = (start_addr + idtr_size + u32::from(idt_size)).to_ne_bytes();
+    // IDT entries are far pointers(CS:IP pair) to the only ISR, which locates right after the IDT.
+    // We set all entries to the same ISR.
+    let idt = (0..256).flat_map(|_| idt_entry).collect::<Vec<_>>();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), idt.clone());
+    cur_addr += u32::try_from(idt.len()).expect("IDT size should be within u32");
+
+    let isr_assembly = assembly::isr::data().to_vec();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), isr_assembly.clone());
+    cur_addr += u32::try_from(isr_assembly.len()).expect("ISR size should be within u32");
+
+    let init_assembly = assembly::init::data().to_vec();
+    setup.initial_regs.rip = cur_addr.into();
+    setup.add_memory_initialization(GuestAddress(cur_addr.into()), init_assembly.clone());
+    cur_addr += u32::try_from(init_assembly.len()).expect("init size should be within u32");
+
+    assert!(mem_size > cur_addr);
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(
+                regs.rax, 0,
+                "the interrupt should be either not delivered(ax is kept as the initial value 0) \
+                 or is delivered after we reenable the interrupt(when the ax is set from 0x910, \
+                 0x910 is 0)"
+            );
+        },
+        |_, exit, vcpu: &mut dyn VcpuX86_64, _: &mut dyn Vm| {
+            match exit {
+                // We exit and pass the test either the VCPU run fails or we hit hlt.
+                VcpuExit::FailEntry { .. } | VcpuExit::Shutdown(..) | VcpuExit::Hlt => true,
+                VcpuExit::Io => {
+                    // We are always handling out IO port, so no data to return.
+                    vcpu.handle_io(&mut |_| None)
+                        .expect("should handle IO successfully");
+                    assert!(!vcpu.ready_for_interrupt());
+                    // We don't care whether we inject the interrupt successfully or not.
+                    let _ = vcpu.interrupt(32);
+                    false
+                }
+                r => panic!("unexpected VMEXIT reason: {:?}", r),
+            }
+        }
+    );
+}
+
+#[test]
+fn test_ready_for_interrupt_for_intercepted_instructions() {
+    global_asm_data!(
+        assembly,
+        // We will use out instruction to cause VMEXITs and test ready_for_interrupt then.
+        ".code16",
+        // Disable the interrupt.
+        "cli",
+        // ready_for_interrupt should be false here.
+        "out 0x10, ax",
+        "sti",
+        // ready_for_interrupt should be false here, because of the one instruction
+        // interruptibility window for sti. And this is also an intercepted instruction.
+        "out 0x20, ax",
+        // ready_for_interrupt should be true here except for WHPX.
+        "out 0x30, ax",
+        // Restore the interruptibility for WHPX.
+        "nop",
+        "mov ax, ss",
+        "mov ss, ax",
+        // ready_for_interrupt should be false here, because of the one instruction
+        // interruptibility window for mov ss. And this is also an intercepted instruction.
+        "out 0x40, ax",
+        // ready_for_interrupt should be true here except for WHPX.
+        "out 0x50, ax",
+        "hlt"
+    );
+
+    let assembly = assembly::data().to_vec();
+    let setup = TestSetup {
+        assembly: assembly.clone(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            // For VMEXIT caused by HLT, the hypervisor will automatically advance the rIP register.
+            assert_eq!(regs.rip, 0x1000 + assembly.len() as u64);
+        },
+        |hypervisor_type, exit, vcpu, _: &mut dyn Vm| {
+            match exit {
+                VcpuExit::Hlt => true,
+                VcpuExit::Io => {
+                    let ready_for_interrupt = vcpu.ready_for_interrupt();
+                    let mut io_port = 0;
+                    vcpu.handle_io(&mut |params| {
+                        io_port = params.address;
+                        // We are always handling out IO port, so no data to return.
+                        None
+                    })
+                    .expect("should handle port IO successfully");
+                    match io_port {
+                        0x10 | 0x20 | 0x40 => assert!(!ready_for_interrupt),
+                        0x30 | 0x50 => {
+                            // WHPX needs a not intercepted instruction to recover to the proper
+                            // interruptibility state.
+                            if hypervisor_type != HypervisorType::Whpx {
+                                assert!(ready_for_interrupt);
+                            }
+                        }
+                        _ => panic!("unexpected port {}", io_port),
+                    }
+                    false
+                }
+                r => panic!("unexpected exit reason: {:?}", r),
+            }
+        }
+    );
+}
+
+#[cfg(feature = "haxm")]
+#[test]
+fn test_cpuid_mwait_not_supported() {
+    global_asm_data!(
+        cpuid_code,
+        ".code64",
+        "mov eax, 1", // CPUID function 1
+        "cpuid",
+        "hlt"
+    );
+
+    let setup = TestSetup {
+        assembly: cpuid_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        ..Default::default()
+    };
+
+    let regs_matcher = |_: HypervisorType, regs: &Regs, _: &Sregs| {
+        // Check if MWAIT is not supported
+        assert_eq!(
+            regs.rcx & (1 << 3),
+            0,
+            "MWAIT is supported, but it should not be."
+        );
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[test]
+fn test_hardware_breakpoint_with_isr() {
+    global_asm_data!(
+        setup_debug_handler_code,
+        ".code64",
+        // Set up the stack
+        "mov sp, 0x900",
+        "mov rax, 0x1019", // Address of the instruction to trigger the breakpoint
+        "mov dr0, rax",
+        "mov rax, 0x00000001", // Enable the first breakpoint (local, exact) for execution
+        "mov dr7, rax",
+        "nop", // This should trigger the debug exception
+        "nop",
+        "hlt"
+    );
+
+    global_asm_data!(
+        debug_isr_code,
+        ".code64",
+        "mov rbx, 0xf00dbabe", // Set a value to indicate the ISR was called
+        "mov rax, 0",
+        "mov dr7, rax", // Disable debugging again
+        "mov rax, dr6",
+        "iretq" // Return from interrupt
+    );
+
+    global_asm_data!(
+        null_isr_code,
+        ".code64",
+        "mov rbx, 0xbaadf00d", // This ISR should never get called
+        "hlt"
+    );
+
+    let debug_isr_offset = 0x800;
+    let null_isr_offset = 0x700;
+    let debug_idt_entry = IdtEntry64::new(debug_isr_offset);
+    let null_idt_entry = IdtEntry64::new(null_isr_offset);
+
+    let setup = TestSetup {
+        assembly: setup_debug_handler_code::data().to_vec(),
+        load_addr: GuestAddress(0x1000),
+        mem_size: 0x20000,
+        initial_regs: Regs {
+            rip: 0x1000,
+            rflags: 2 | FLAGS_IF_BIT,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(
+            move |vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+                let guest_mem = vm.get_memory();
+
+                guest_mem
+                    .write_at_addr(
+                        debug_isr_code::data().to_vec().as_bytes(),
+                        GuestAddress(debug_isr_offset),
+                    )
+                    .expect("Failed to write debug ISR entry");
+
+                guest_mem
+                    .write_at_addr(
+                        null_isr_code::data().to_vec().as_bytes(),
+                        GuestAddress(null_isr_offset),
+                    )
+                    .expect("Failed to write null ISR entry");
+
+                let mut long_mode_config = ModeConfig::default_long_mode();
+                long_mode_config
+                    .set_idt_long_mode((0..256).map(|i| {
+                        if i == 0x01 {
+                            debug_idt_entry
+                        } else {
+                            null_idt_entry
+                        }
+                    }))
+                    .set_idt_base_addr(0x12_000);
+                long_mode_config.enter_long_mode(vcpu, vm);
+            },
+        )),
+        ..Default::default()
+    };
+
+    let regs_matcher = |_: HypervisorType, regs: &Regs, _: &Sregs| {
+        assert_eq!(regs.rax & 1, 1, "Breakpoint #0 not hit");
+        assert_eq!(
+            regs.rip,
+            0x1000 + (setup_debug_handler_code::data().len() as u64),
+            "rIP not at the right HLT"
+        );
+        assert_eq!(regs.rbx, 0xf00dbabe, "Debug ISR was not called");
+    };
+
+    let exit_matcher = |_, exit: &VcpuExit, _: &mut dyn VcpuX86_64, _: &mut dyn Vm| match exit {
+        VcpuExit::Hlt => {
+            true // Break VM runloop
+        }
+        r => panic!("unexpected exit reason: {:?}", r),
+    };
+
+    run_tests!(setup, regs_matcher, exit_matcher);
+}
+
+#[test]
+fn test_debug_register_persistence() {
+    global_asm_data!(
+        test_debug_registers_code,
+        ".code64",
+        "mov dr0, rax",
+        "inc rax",
+        "mov dr1, rax",
+        "inc rax",
+        "mov dr2, rax",
+        "inc rax",
+        "mov dr3, rax",
+        // Perform HLT to cause VMEXIT
+        "hlt",
+        "mov r8, dr0",
+        "mov r9, dr1",
+        "mov r10, dr2",
+        "mov r11, dr3",
+        "hlt"
+    );
+
+    let initial_dr_value: u64 = 0x12345678;
+
+    let setup = TestSetup {
+        assembly: test_debug_registers_code::data().to_vec(),
+        mem_size: 0x11000,
+        load_addr: GuestAddress(0x1000),
+        initial_regs: Regs {
+            rax: initial_dr_value,
+            rip: 0x1000,
+            rflags: 2,
+            ..Default::default()
+        },
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_long_mode().enter_long_mode(vcpu, vm);
+        })),
+        ..Default::default()
+    };
+
+    let mut hlt_count = 0;
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            assert_eq!(regs.r8, initial_dr_value, "DR0 value mismatch after VMEXIT");
+            assert_eq!(
+                regs.r9,
+                initial_dr_value + 1,
+                "DR1 value mismatch after VMEXIT"
+            );
+            assert_eq!(
+                regs.r10,
+                initial_dr_value + 2,
+                "DR2 value mismatch after VMEXIT"
+            );
+            assert_eq!(
+                regs.r11,
+                initial_dr_value + 3,
+                "DR3 value mismatch after VMEXIT"
+            );
+        },
+        |_, exit, _, _: &mut dyn Vm| match exit {
+            VcpuExit::Hlt => {
+                hlt_count += 1;
+                hlt_count > 1 // Halt execution after the second HLT
+            }
+            r => panic!("unexpected exit reason: {:?}", r),
+        }
+    );
+}
+
+#[test]
+fn test_minimal_exception_injection() {
+    // This test tries to write an invalid MSR, causing a General Protection exception to be
+    // injected by the hypervisor (since MSR writes cause a VMEXIT). We run it in long mode since
+    // real mode exception handling isn't always well supported (failed on Intel HAXM).
+    mod assembly {
+        use super::*;
+
+        // An ISR that handles any generic interrupt.
+        global_asm_data!(
+            pub isr_generic,
+            ".code64",
+            // Set EBX to 888 to observe this is where we halted.
+            "mov ebx, 888",
+            "hlt"
+        );
+
+        // An ISR that handles the General Protection fault specifically.
+        global_asm_data!(
+            pub isr_gp,
+            ".code64",
+            // Set EBX to 999 to observe this is where we halted.
+            "mov ebx, 999",
+            "hlt"
+        );
+
+        // Our VM entry (in long mode).
+        global_asm_data!(
+            pub init,
+            ".code64",
+            // Set up the stack, which will be used when CPU transfers the control to the ISR. If
+            // not set up, can cause faults (stack should be aligned).
+            "mov esp, 0x900",
+            // We will verify EBX, set it here first.
+            "mov ebx, 777",
+            // Should trigger GP fault when we try to write to MSR 0.
+            "wrmsr",
+            // We should never get here since we halt in the fault handlers.
+            "hlt",
+        );
+    }
+
+    let mem_size: u64 = 0x20000;
+
+    let setup = TestSetup {
+        initial_regs: Regs {
+            // WRMSR will try to write to ECX, we set it to zero to point to an old read-only MSR
+            // (IA32_P5_MC_ADDR).
+            rcx: 0,
+            // Intentionally not setting IF flag since exceptions don't check it.
+            rflags: 2,
+            ..Default::default()
+        },
+        mem_size,
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            let start_addr: u64 = 0x1000;
+            let guest_mem = vm.get_memory();
+
+            let isr_assembly = assembly::isr_generic::data().to_vec();
+            let isr_assembly_len =
+                u64::try_from(isr_assembly.len()).expect("ISR size should be within u64");
+
+            let isr_gp_assembly = assembly::isr_gp::data().to_vec();
+            let isr_gp_assembly_len =
+                u64::try_from(isr_gp_assembly.len()).expect("GP ISR size should be within u64");
+
+            let mut cur_addr = start_addr;
+
+            guest_mem
+                .write_at_addr(&isr_assembly, GuestAddress(cur_addr))
+                .expect("Failed to write ISR to guest memory");
+            cur_addr += isr_assembly_len;
+
+            guest_mem
+                .write_at_addr(&isr_gp_assembly, GuestAddress(cur_addr))
+                .expect("Failed to write ISR to guest memory");
+            cur_addr += isr_gp_assembly_len;
+
+            let mut regs = vcpu.get_regs().expect("Failed to get regs");
+            regs.rip = cur_addr;
+            vcpu.set_regs(&regs).expect("Failed to set regs");
+
+            let init_assembly = assembly::init::data().to_vec();
+            guest_mem
+                .write_at_addr(&init_assembly, GuestAddress(cur_addr))
+                .expect("Failed to write init assembly to guest memory");
+
+            let idt_entry_generic = IdtEntry64::new(start_addr);
+            let idt_entry_gp = IdtEntry64::new(start_addr + isr_assembly_len);
+
+            let mut long_mode_config = ModeConfig::default_long_mode();
+            long_mode_config
+                .set_idt_long_mode((0..256).map(|i| {
+                    // GP handler is vector 13.
+                    if i == 0x0D {
+                        idt_entry_gp
+                    } else {
+                        idt_entry_generic
+                    }
+                }))
+                .set_idt_base_addr(0x12_000);
+            long_mode_config.enter_long_mode(vcpu, vm);
+        })),
+        ..Default::default()
+    };
+
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            // If EBX is 999 the GP handler ran.
+            assert_eq!(regs.rbx, 999);
+        },
+        |_, exit, _, _: &mut dyn Vm| matches!(exit, VcpuExit::Hlt)
+    );
+}
+
+#[test]
+fn test_pmode_segment_limit() {
+    // This test configures 32-bit protected mode and verifies that segment limits are converted
+    // correctly. The test setup configures a segment with the 20-bit limit field set to 0xFFFFF and
+    // the 4096-byte granularity bit set, which should result in a 4 GB limit (0xFFFFFFFF).
+    mod assembly {
+        use super::*;
+
+        global_asm_data!(
+            pub init,
+            ".code32",
+            // Load the CS segment limit into EAX.
+            "mov cx, cs",
+            "lsl eax, cx",
+            "hlt",
+        );
+    }
+
+    let mem_size: u64 = 0x20000;
+
+    let setup = TestSetup {
+        initial_regs: Regs {
+            ..Default::default()
+        },
+        mem_size,
+        extra_vm_setup: Some(Box::new(|vcpu: &mut dyn VcpuX86_64, vm: &mut dyn Vm| {
+            ModeConfig::default_protected_mode().enter_protected_mode(vcpu, vm);
+
+            let guest_mem = vm.get_memory();
+
+            let mut regs = vcpu.get_regs().expect("Failed to get regs");
+            regs.rax = 12345;
+            regs.rip = 0x1000;
+            vcpu.set_regs(&regs).expect("Failed to set regs");
+
+            let init_assembly = assembly::init::data().to_vec();
+            guest_mem
+                .write_at_addr(&init_assembly, GuestAddress(0x1000))
+                .expect("Failed to write init assembly to guest memory");
+        })),
+        ..Default::default()
+    };
 
-    let regs: Regs = vcpu.get_regs().expect("failed to get regs");
-    assert_eq!(regs.rax, 3);
+    run_tests!(
+        setup,
+        |_, regs, _| {
+            // The output of the LSL instruction should be 4GB - 1.
+            assert_eq!(regs.rax, 0xFFFFFFFF);
+        },
+        |_, exit, _, _: &mut dyn Vm| matches!(exit, VcpuExit::Hlt)
+    );
 }
diff --git a/hypervisor/tests/kvm/main.rs b/hypervisor/tests/kvm/main.rs
index 00b4e80dd..8f2a76ab2 100644
--- a/hypervisor/tests/kvm/main.rs
+++ b/hypervisor/tests/kvm/main.rs
@@ -21,6 +21,7 @@ use base::MemoryMappingArena;
 use base::MemoryMappingBuilder;
 use hypervisor::kvm::dirty_log_bitmap_size;
 use hypervisor::kvm::Kvm;
+use hypervisor::kvm::KvmCap;
 use hypervisor::kvm::KvmVm;
 use hypervisor::Datamatch;
 use hypervisor::Hypervisor;
@@ -34,7 +35,6 @@ use hypervisor::VmAArch64;
 use hypervisor::VmRiscv64;
 #[cfg(target_arch = "x86_64")]
 use hypervisor::VmX86_64;
-use kvm::Cap;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 
@@ -92,9 +92,9 @@ fn check_vm_capability() {
     let kvm = Kvm::new().unwrap();
     let gm = GuestMemory::new(&[(GuestAddress(0), pagesize() as u64)]).unwrap();
     let vm = KvmVm::new(&kvm, gm, Default::default()).unwrap();
-    assert!(vm.check_raw_capability(Cap::UserMemory));
+    assert!(vm.check_raw_capability(KvmCap::UserMemory));
     // I assume nobody is testing this on s390
-    assert!(!vm.check_raw_capability(Cap::S390UserSigp));
+    assert!(!vm.check_raw_capability(KvmCap::S390UserSigp));
 }
 
 #[test]
@@ -289,15 +289,6 @@ fn irqfd_resample() {
     let _ = resample_evt.into_raw_descriptor(); // Don't try to close the invalid fd.
 }
 
-#[test]
-fn vcpu_mmap_size() {
-    let kvm = Kvm::new().unwrap();
-    let mmap_size = kvm.get_vcpu_mmap_size().unwrap();
-    let page_size = pagesize();
-    assert!(mmap_size >= page_size);
-    assert!(mmap_size % page_size == 0);
-}
-
 #[test]
 fn register_ioevent() {
     let kvm = Kvm::new().unwrap();
diff --git a/hypervisor/tests/kvm/x86_64.rs b/hypervisor/tests/kvm/x86_64.rs
index b8b45154a..f3ea2cf02 100644
--- a/hypervisor/tests/kvm/x86_64.rs
+++ b/hypervisor/tests/kvm/x86_64.rs
@@ -30,7 +30,6 @@ use hypervisor::Vm;
 use hypervisor::VmCap;
 use hypervisor::VmX86_64;
 use kvm_sys::*;
-use libc::EINVAL;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 
@@ -58,7 +57,7 @@ fn get_msr_index_list() {
 #[test]
 fn entries_double_on_error() {
     let hypervisor = Kvm::new().unwrap();
-    let cpuid = get_cpuid_with_initial_capacity(&hypervisor, KVM_GET_SUPPORTED_CPUID(), 4).unwrap();
+    let cpuid = get_cpuid_with_initial_capacity(&hypervisor, KVM_GET_SUPPORTED_CPUID, 4).unwrap();
     assert!(cpuid.cpu_id_entries.len() > 4);
 }
 
@@ -410,19 +409,3 @@ fn set_msr_unsupported() {
         Err(base::Error::new(libc::EPERM))
     );
 }
-
-#[test]
-fn get_hyperv_cpuid() {
-    let kvm = Kvm::new().unwrap();
-    let gm = GuestMemory::new(&[(GuestAddress(0), 0x10000)]).unwrap();
-    let vm = KvmVm::new(&kvm, gm, Default::default()).unwrap();
-    let vcpu = vm.create_vcpu(0).unwrap();
-    let cpuid = vcpu.get_hyperv_cpuid();
-    // Older kernels don't support so tolerate this kind of failure.
-    match cpuid {
-        Ok(_) => {}
-        Err(e) => {
-            assert_eq!(e.errno(), EINVAL);
-        }
-    }
-}
diff --git a/hypervisor/tests/mmio_and_pio.rs b/hypervisor/tests/mmio_and_pio.rs
index 7001b7027..2e0f5489d 100644
--- a/hypervisor/tests/mmio_and_pio.rs
+++ b/hypervisor/tests/mmio_and_pio.rs
@@ -81,8 +81,6 @@ where
     let mem_size = 0x2000;
     let load_addr = GuestAddress(0x1000);
 
-    // GuestMemory requires an initial set of memory, so we just
-    // setup some at 0x8000, it won't be used though.
     let guest_mem =
         GuestMemory::new(&[(GuestAddress(0), mem_size)]).expect("failed to create guest mem");
     guest_mem
@@ -126,14 +124,14 @@ where
                             exits.fetch_add(1, Ordering::SeqCst);
                             // this number will be read into al register
                             data.copy_from_slice(&0x66_u64.to_ne_bytes());
-                            Some(data)
+                            Ok(Some(data))
                         }
                         IoOperation::Write { data } => {
                             assert_eq!(address, 0x3000);
                             assert_eq!(data[0], 0x33);
                             assert_eq!(size, 1);
                             exits.fetch_add(1, Ordering::SeqCst);
-                            None
+                            Ok(None)
                         }
                     }
                 })
@@ -179,3 +177,299 @@ where
     let regs: Regs = vcpu.get_regs().expect("failed to get regs");
     assert_eq!(regs.rax, 0x77);
 }
+
+#[test]
+#[cfg(any(target_os = "android", target_os = "linux"))]
+fn test_kvm_pio_out() {
+    use hypervisor::kvm::*;
+    test_pio_out(|guest_mem| {
+        let kvm = Kvm::new().expect("failed to create kvm");
+        let vm = KvmVm::new(&kvm, guest_mem, Default::default()).expect("failed to create vm");
+        (kvm, vm)
+    });
+}
+
+#[test]
+#[cfg(all(windows, feature = "haxm"))]
+fn test_haxm_pio_out() {
+    use hypervisor::haxm::*;
+    test_pio_out(|guest_mem| {
+        let haxm = Haxm::new().expect("failed to create haxm");
+        let vm = HaxmVm::new(&haxm, guest_mem).expect("failed to create vm");
+        (haxm, vm)
+    });
+}
+
+#[test]
+#[cfg(all(windows, feature = "whpx"))]
+fn test_whpx_pio_out() {
+    use hypervisor::whpx::*;
+    if !Whpx::is_enabled() {
+        return;
+    }
+    test_pio_out(|guest_mem| {
+        let whpx = Whpx::new().expect("failed to create whpx");
+        let vm =
+            WhpxVm::new(&whpx, 1, guest_mem, CpuId::new(0), false).expect("failed to create vm");
+        (whpx, vm)
+    });
+}
+
+#[test]
+#[cfg(feature = "gvm")]
+fn test_gvm_pio_out() {
+    use hypervisor::gvm::*;
+    test_pio_out(|guest_mem| {
+        let gvm = Gvm::new().expect("failed to create gvm");
+        let vm = GvmVm::new(&gvm, guest_mem).expect("failed to create vm");
+        (gvm, vm)
+    });
+}
+
+fn test_pio_out<CreateVm, HypervisorT, VmT>(create_vm: CreateVm)
+where
+    CreateVm: FnOnce(GuestMemory) -> (HypervisorT, VmT),
+    HypervisorT: Hypervisor,
+    VmT: VmX86_64,
+{
+    /*
+      0x00: 31 c0      xor ax, ax   (ax = 0)
+      0x02: 40         inc ax       (ax = 1)
+      0x03: e7 01      out 0x1, ax  (OUT 0x0001 to port 1)
+      0x05: 40         inc ax       (ax = 2)
+      0x06: e6 02      out 0x2, al  (OUT 0x02 to port 2)
+      0x08: 40         inc ax       (ax = 3)
+      0x09: 89 c2      mov dx, ax   (dx = 3)
+      0x0b: ef         out dx, ax   (OUT 0x0003 to port 3)
+      0x0c: 40         inc ax       (ax = 4)
+      0x0d: 42         inc dx       (dx = 4)
+      0x0e: ee         out dx, al   (OUT 0x04 to port 4)
+      0x0f: f4         hlt
+    */
+
+    let code: [u8; 16] = [
+        0x31, 0xc0, 0x40, 0xe7, 0x01, 0x40, 0xe6, 0x02, 0x40, 0x89, 0xc2, 0xef, 0x40, 0x42, 0xee,
+        0xf4,
+    ];
+    let mem_size = 0x2000;
+    let load_addr = GuestAddress(0x1000);
+
+    let guest_mem =
+        GuestMemory::new(&[(GuestAddress(0), mem_size)]).expect("failed to create guest mem");
+    guest_mem
+        .write_at_addr(&code[..], load_addr)
+        .expect("failed to write to guest memory");
+
+    let (_, vm) = create_vm(guest_mem);
+    let mut vcpu = vm.create_vcpu(0).expect("new vcpu failed");
+    let mut vcpu_sregs = vcpu.get_sregs().expect("get sregs failed");
+    vcpu_sregs.cs.base = 0;
+    vcpu_sregs.cs.selector = 0;
+
+    vcpu.set_sregs(&vcpu_sregs).expect("set sregs failed");
+
+    let vcpu_regs = Regs {
+        rip: load_addr.offset(),
+        rflags: 2,
+        ..Default::default()
+    };
+    vcpu.set_regs(&vcpu_regs).expect("set regs failed");
+
+    // Ensure we get the expected PIO exits
+    let exit_count = AtomicU16::new(0);
+    let exit_bits = AtomicU16::new(0);
+
+    loop {
+        match vcpu.run().expect("run failed") {
+            VcpuExit::Io => {
+                vcpu.handle_io(&mut |IoParams {
+                                         address,
+                                         size,
+                                         operation,
+                                     }| {
+                    match operation {
+                        IoOperation::Read => panic!("unexpected PIO read"),
+                        IoOperation::Write { data } => {
+                            assert!((1..=4).contains(&address));
+                            if address % 2 == 0 {
+                                assert_eq!(size, 1);
+                                assert_eq!(data[0], address as u8);
+                            } else {
+                                assert_eq!(size, 2);
+                                assert_eq!(data[0], address as u8);
+                                assert_eq!(data[1], 0);
+                            }
+                            exit_bits.fetch_or(1 << (address - 1), Ordering::SeqCst);
+                            exit_count.fetch_add(1, Ordering::SeqCst);
+                            None
+                        }
+                    }
+                })
+                .expect("failed to set the data");
+            }
+            VcpuExit::Hlt => {
+                break;
+            }
+            // Continue on external interrupt or signal
+            VcpuExit::Intr => continue,
+            r => panic!("unexpected exit reason: {:?}", r),
+        }
+    }
+
+    // bits 0 through 3 have been set
+    assert_eq!(exit_bits.load(Ordering::SeqCst), 0xf);
+    assert_eq!(exit_count.load(Ordering::SeqCst), 4);
+}
+
+#[test]
+#[cfg(any(target_os = "android", target_os = "linux"))]
+fn test_kvm_pio_in() {
+    use hypervisor::kvm::*;
+    test_pio_in(|guest_mem| {
+        let kvm = Kvm::new().expect("failed to create kvm");
+        let vm = KvmVm::new(&kvm, guest_mem, Default::default()).expect("failed to create vm");
+        (kvm, vm)
+    });
+}
+
+#[test]
+#[cfg(all(windows, feature = "haxm"))]
+fn test_haxm_pio_in() {
+    use hypervisor::haxm::*;
+    test_pio_in(|guest_mem| {
+        let haxm = Haxm::new().expect("failed to create haxm");
+        let vm = HaxmVm::new(&haxm, guest_mem).expect("failed to create vm");
+        (haxm, vm)
+    });
+}
+
+#[test]
+#[cfg(all(windows, feature = "whpx"))]
+fn test_whpx_pio_in() {
+    use hypervisor::whpx::*;
+    if !Whpx::is_enabled() {
+        return;
+    }
+    test_pio_in(|guest_mem| {
+        let whpx = Whpx::new().expect("failed to create whpx");
+        let vm =
+            WhpxVm::new(&whpx, 1, guest_mem, CpuId::new(0), false).expect("failed to create vm");
+        (whpx, vm)
+    });
+}
+
+#[test]
+#[cfg(feature = "gvm")]
+fn test_gvm_pio_in() {
+    use hypervisor::gvm::*;
+    test_pio_in(|guest_mem| {
+        let gvm = Gvm::new().expect("failed to create gvm");
+        let vm = GvmVm::new(&gvm, guest_mem).expect("failed to create vm");
+        (gvm, vm)
+    });
+}
+
+fn test_pio_in<CreateVm, HypervisorT, VmT>(create_vm: CreateVm)
+where
+    CreateVm: FnOnce(GuestMemory) -> (HypervisorT, VmT),
+    HypervisorT: Hypervisor,
+    VmT: VmX86_64,
+{
+    /*
+      0x00: e5 01      in ax, 0x1   (IN 16 bits from port 1)
+      0x02: 89 c6      mov si, ax   (si = value from port 1)
+      0x04: 31 c0      xor ax, ax   (clear ax, since IN will only write the lower byte)
+      0x06: e4 02      in al, 0x02  (IN 8 bits from port 2)
+      0x08: 89 c3      mov bx, ax   (bx = value from port 2)
+      0x0a: ba 03 00   mov dx, 0x03 (dx = 3)
+      0x0d: ed         in ax, dx    (IN 16 bits from port 3)
+      0x0e: 89 c1      mov cx, ax   (cx = value from port 3)
+      0x10: 42         inc dx       (dx = 4)
+      0x11: 31 c0      xor ax, ax   (clear ax, since IN will only write the lower byte)
+      0x13: ec         in al, dx    (IN 8 bits from port 4)
+      0x14: 89 c2      mov dx, ax   (dx = value from port 4)
+      0x16: 89 f0      mov ax, si   (ax = value from port 1)
+      0x18: f4         hlt
+    */
+
+    let code: [u8; 25] = [
+        0xe5, 0x01, 0x89, 0xc6, 0x31, 0xc0, 0xe4, 0x02, 0x89, 0xc3, 0xba, 0x03, 0x00, 0xed, 0x89,
+        0xc1, 0x42, 0x31, 0xc0, 0xec, 0x89, 0xc2, 0x89, 0xf0, 0xf4,
+    ];
+    let mem_size = 0x2000;
+    let load_addr = GuestAddress(0x1000);
+
+    let guest_mem =
+        GuestMemory::new(&[(GuestAddress(0), mem_size)]).expect("failed to create guest mem");
+    guest_mem
+        .write_at_addr(&code[..], load_addr)
+        .expect("failed to write to guest memory");
+
+    let (_, vm) = create_vm(guest_mem);
+    let mut vcpu = vm.create_vcpu(0).expect("new vcpu failed");
+    let mut vcpu_sregs = vcpu.get_sregs().expect("get sregs failed");
+    vcpu_sregs.cs.base = 0;
+    vcpu_sregs.cs.selector = 0;
+
+    vcpu.set_sregs(&vcpu_sregs).expect("set sregs failed");
+
+    let vcpu_regs = Regs {
+        rip: load_addr.offset(),
+        rflags: 2,
+        ..Default::default()
+    };
+    vcpu.set_regs(&vcpu_regs).expect("set regs failed");
+
+    // Ensure we get the expected PIO exits
+    let exit_count = AtomicU16::new(0);
+    let exit_bits = AtomicU16::new(0);
+
+    loop {
+        match vcpu.run().expect("run failed") {
+            VcpuExit::Io => {
+                vcpu.handle_io(&mut |IoParams {
+                                         address,
+                                         size,
+                                         operation,
+                                     }| {
+                    match operation {
+                        IoOperation::Read => {
+                            let mut data = [0u8; 8];
+                            assert!((1..=4).contains(&address));
+
+                            if address % 2 == 0 {
+                                assert_eq!(size, 1);
+                                data[0] = address as u8;
+                            } else {
+                                assert_eq!(size, 2);
+                                data[0] = address as u8;
+                                data[1] = address as u8;
+                            }
+
+                            exit_bits.fetch_or(1 << (address - 1), Ordering::SeqCst);
+                            exit_count.fetch_add(1, Ordering::SeqCst);
+                            Some(data)
+                        }
+                        IoOperation::Write { .. } => panic!("unexpected PIO write"),
+                    }
+                })
+                .expect("failed to set the data");
+            }
+            VcpuExit::Hlt => {
+                break;
+            }
+            // Continue on external interrupt or signal
+            VcpuExit::Intr => continue,
+            r => panic!("unexpected exit reason: {:?}", r),
+        }
+    }
+
+    // bits 0 through 3 have been set
+    assert_eq!(exit_bits.load(Ordering::SeqCst), 0xf);
+    assert_eq!(exit_count.load(Ordering::SeqCst), 4);
+    let regs: Regs = vcpu.get_regs().expect("failed to get regs");
+    assert_eq!(regs.rax, 0x0101);
+    assert_eq!(regs.rbx, 0x02);
+    assert_eq!(regs.rcx, 0x0303);
+    assert_eq!(regs.rdx, 0x04);
+}
diff --git a/hypervisor/tests/mmio_fetch_memory.rs b/hypervisor/tests/mmio_fetch_memory.rs
index 19a77413c..162c26841 100644
--- a/hypervisor/tests/mmio_fetch_memory.rs
+++ b/hypervisor/tests/mmio_fetch_memory.rs
@@ -99,11 +99,11 @@ fn test_whpx_mmio_fetch_memory() {
                                     // Ensure this instruction is the first read
                                     // in the sequence.
                                     assert_eq!(memory_reads.load(Ordering::SeqCst), 1);
-                                    Some([0x88, 0x03, 0x67, 0x8a, 0x01, 0xf4, 0, 0])
+                                    Ok(Some([0x88, 0x03, 0x67, 0x8a, 0x01, 0xf4, 0, 0]))
                                 }
                                 // Second MMIO read is a regular read from an
                                 // unmapped memory.
-                                (0x3010, 1) => Some([0x66, 0, 0, 0, 0, 0, 0, 0]),
+                                (0x3010, 1) => Ok(Some([0x66, 0, 0, 0, 0, 0, 0, 0])),
                                 _ => {
                                     panic!("invalid address({:#x})/size({})", address, size)
                                 }
@@ -114,7 +114,7 @@ fn test_whpx_mmio_fetch_memory() {
                             assert_eq!(data[0], 0x33);
                             assert_eq!(size, 1);
                             memory_writes.fetch_add(1, Ordering::SeqCst);
-                            None
+                            Ok(None)
                         }
                     }
                 })
diff --git a/hypervisor/tests/read_only_memory.rs b/hypervisor/tests/read_only_memory.rs
index afba700cc..187ba176a 100644
--- a/hypervisor/tests/read_only_memory.rs
+++ b/hypervisor/tests/read_only_memory.rs
@@ -176,7 +176,7 @@ where
                         assert_eq!(address, vcpu_sregs.es.base);
                         assert_eq!(data[0], 0x67);
                         exits.fetch_add(1, Ordering::SeqCst);
-                        None
+                        Ok(None)
                     }
                 })
                 .expect("failed to set the data");
diff --git a/hypervisor/tests/remove_memory.rs b/hypervisor/tests/remove_memory.rs
index f6243c910..7384d671e 100644
--- a/hypervisor/tests/remove_memory.rs
+++ b/hypervisor/tests/remove_memory.rs
@@ -178,7 +178,7 @@ where
                         assert_eq!(address, 0x3000);
                         assert_eq!(size, 1);
                         data.copy_from_slice(&0x44_u64.to_ne_bytes());
-                        Some(data)
+                        Ok(Some(data))
                     }
                     IoOperation::Write { .. } => {
                         panic!("unexpected mmio write");
diff --git a/infra/README.recipes.md b/infra/README.recipes.md
index d85ef1593..c20bbfb32 100644
--- a/infra/README.recipes.md
+++ b/infra/README.recipes.md
@@ -15,6 +15,7 @@
   * [crosvm:examples/host_build_context](#recipes-crosvm_examples_host_build_context)
   * [crosvm:examples/source_context](#recipes-crosvm_examples_source_context)
   * [health_check](#recipes-health_check)
+  * [presubmit](#recipes-presubmit)
   * [push_to_github](#recipes-push_to_github)
   * [update_chromeos_merges](#recipes-update_chromeos_merges)
 ## Recipe Modules
@@ -161,6 +162,12 @@ This recipe requires ambient luci authentication. To test locally run:
 
 
 &mdash; **def [RunSteps](/infra/recipes/health_check.py#17)(api):**
+### *recipes* / [presubmit](/infra/recipes/presubmit.py)
+
+[DEPS](/infra/recipes/presubmit.py#13): [crosvm](#recipe_modules-crosvm), [recipe\_engine/buildbucket][recipe_engine/recipe_modules/buildbucket], [recipe\_engine/context][recipe_engine/recipe_modules/context], [recipe\_engine/json][recipe_engine/recipe_modules/json], [recipe\_engine/properties][recipe_engine/recipe_modules/properties], [recipe\_engine/raw\_io][recipe_engine/recipe_modules/raw_io], [recipe\_engine/step][recipe_engine/recipe_modules/step]
+
+
+&mdash; **def [RunSteps](/infra/recipes/presubmit.py#26)(api, properties):**
 ### *recipes* / [push\_to\_github](/infra/recipes/push_to_github.py)
 
 [DEPS](/infra/recipes/push_to_github.py#7): [crosvm](#recipe_modules-crosvm), [recipe\_engine/buildbucket][recipe_engine/recipe_modules/buildbucket], [recipe\_engine/context][recipe_engine/recipe_modules/context], [recipe\_engine/file][recipe_engine/recipe_modules/file], [recipe\_engine/path][recipe_engine/recipe_modules/path], [recipe\_engine/raw\_io][recipe_engine/recipe_modules/raw_io], [recipe\_engine/step][recipe_engine/recipe_modules/step]
@@ -174,19 +181,19 @@ This recipe requires ambient luci authentication. To test locally run:
 
 &mdash; **def [RunSteps](/infra/recipes/update_chromeos_merges.py#14)(api):**
 
-[depot_tools/recipe_modules/bot_update]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/5a584405cae6e1fd08a6054ce9ba61b645b4d591/recipes/README.recipes.md#recipe_modules-bot_update
-[depot_tools/recipe_modules/depot_tools]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/5a584405cae6e1fd08a6054ce9ba61b645b4d591/recipes/README.recipes.md#recipe_modules-depot_tools
-[depot_tools/recipe_modules/gclient]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/5a584405cae6e1fd08a6054ce9ba61b645b4d591/recipes/README.recipes.md#recipe_modules-gclient
-[depot_tools/recipe_modules/git]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/5a584405cae6e1fd08a6054ce9ba61b645b4d591/recipes/README.recipes.md#recipe_modules-git
-[depot_tools/recipe_modules/gsutil]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/5a584405cae6e1fd08a6054ce9ba61b645b4d591/recipes/README.recipes.md#recipe_modules-gsutil
-[recipe_engine/recipe_modules/buildbucket]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-buildbucket
-[recipe_engine/recipe_modules/cipd]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-cipd
-[recipe_engine/recipe_modules/context]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-context
-[recipe_engine/recipe_modules/file]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-file
-[recipe_engine/recipe_modules/json]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-json
-[recipe_engine/recipe_modules/path]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-path
-[recipe_engine/recipe_modules/platform]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-platform
-[recipe_engine/recipe_modules/properties]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-properties
-[recipe_engine/recipe_modules/raw_io]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-raw_io
-[recipe_engine/recipe_modules/step]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/README.recipes.md#recipe_modules-step
-[recipe_engine/wkt/RecipeApi]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/f967fa68fd4bd3e76140de7ffa449fa3a45a72f4/recipe_engine/recipe_api.py#471
+[depot_tools/recipe_modules/bot_update]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/d1259b49c5b41bc4939ba7c5bb8e8e08083a05f6/recipes/README.recipes.md#recipe_modules-bot_update
+[depot_tools/recipe_modules/depot_tools]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/d1259b49c5b41bc4939ba7c5bb8e8e08083a05f6/recipes/README.recipes.md#recipe_modules-depot_tools
+[depot_tools/recipe_modules/gclient]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/d1259b49c5b41bc4939ba7c5bb8e8e08083a05f6/recipes/README.recipes.md#recipe_modules-gclient
+[depot_tools/recipe_modules/git]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/d1259b49c5b41bc4939ba7c5bb8e8e08083a05f6/recipes/README.recipes.md#recipe_modules-git
+[depot_tools/recipe_modules/gsutil]: https://chromium.googlesource.com/chromium/tools/depot_tools.git/+/d1259b49c5b41bc4939ba7c5bb8e8e08083a05f6/recipes/README.recipes.md#recipe_modules-gsutil
+[recipe_engine/recipe_modules/buildbucket]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-buildbucket
+[recipe_engine/recipe_modules/cipd]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-cipd
+[recipe_engine/recipe_modules/context]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-context
+[recipe_engine/recipe_modules/file]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-file
+[recipe_engine/recipe_modules/json]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-json
+[recipe_engine/recipe_modules/path]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-path
+[recipe_engine/recipe_modules/platform]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-platform
+[recipe_engine/recipe_modules/properties]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-properties
+[recipe_engine/recipe_modules/raw_io]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-raw_io
+[recipe_engine/recipe_modules/step]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/README.recipes.md#recipe_modules-step
+[recipe_engine/wkt/RecipeApi]: https://chromium.googlesource.com/infra/luci/recipes-py.git/+/c291dd7687aee4b10811b3d3b517fd20c83e8333/recipe_engine/recipe_api.py#433
diff --git a/infra/config/generated/cr-buildbucket.cfg b/infra/config/generated/cr-buildbucket.cfg
index b3670ddc8..ce8fe5c8d 100644
--- a/infra/config/generated/cr-buildbucket.cfg
+++ b/infra/config/generated/cr-buildbucket.cfg
@@ -14,6 +14,24 @@ buckets {
     group: "mdb/crosvm-acl-luci-admin"
   }
   swarming {
+    builders {
+      name: "android-aarch64"
+      swarming_host: "chromium-swarm.appspot.com"
+      dimensions: "cpu:x86-64"
+      dimensions: "os:Ubuntu"
+      dimensions: "pool:luci.crosvm.ci"
+      recipe {
+        name: "presubmit"
+        cipd_package: "infra/recipe_bundles/chromium.googlesource.com/crosvm/crosvm"
+        cipd_version: "refs/heads/main"
+        properties_j: "group_name:\"android-aarch64\""
+      }
+      caches {
+        name: "linux_builder_cache"
+        path: "builder"
+      }
+      service_account: "crosvm-luci-ci-builder@crosvm-infra.iam.gserviceaccount.com"
+    }
     builders {
       name: "build_docs"
       swarming_host: "chromium-swarm.appspot.com"
@@ -47,9 +65,10 @@ buckets {
       dimensions: "os:Ubuntu"
       dimensions: "pool:luci.crosvm.ci"
       recipe {
-        name: "health_check"
+        name: "presubmit"
         cipd_package: "infra/recipe_bundles/chromium.googlesource.com/crosvm/crosvm"
         cipd_version: "refs/heads/main"
+        properties_j: "group_name:\"health_checks\""
       }
       caches {
         name: "linux_builder_cache"
@@ -193,9 +212,10 @@ buckets {
       dimensions: "os:Ubuntu"
       dimensions: "pool:luci.crosvm.try"
       recipe {
-        name: "health_check"
+        name: "presubmit"
         cipd_package: "infra/recipe_bundles/chromium.googlesource.com/crosvm/crosvm"
         cipd_version: "refs/heads/main"
+        properties_j: "group_name:\"health_checks\""
       }
       caches {
         name: "linux_builder_cache"
diff --git a/infra/config/generated/luci-milo.cfg b/infra/config/generated/luci-milo.cfg
index 69cd44c53..194376b5d 100644
--- a/infra/config/generated/luci-milo.cfg
+++ b/infra/config/generated/luci-milo.cfg
@@ -38,6 +38,10 @@ consoles {
     name: "buildbucket/luci.crosvm.ci/health_check"
     category: "linux"
   }
+  builders {
+    name: "buildbucket/luci.crosvm.ci/android-aarch64"
+    category: "android"
+  }
 }
 consoles {
   id: "Presubmit"
diff --git a/infra/config/generated/luci-notify.cfg b/infra/config/generated/luci-notify.cfg
index 435cd5860..ba2e13fa9 100644
--- a/infra/config/generated/luci-notify.cfg
+++ b/infra/config/generated/luci-notify.cfg
@@ -4,6 +4,21 @@
 # For the schema of this file, see ProjectConfig message:
 #   https://config.luci.app/schemas/projects:luci-notify.cfg
 
+notifiers {
+  notifications {
+    on_change: true
+    email {
+      recipients: "crosvm-uprev@grotations.appspotmail.com"
+      recipients: "crosvm-uprev-apac@grotations.appspotmail.com"
+      recipients: "denniskempin@google.com"
+    }
+  }
+  builders {
+    bucket: "ci"
+    name: "android-aarch64"
+    repository: "https://chromium.googlesource.com/crosvm/crosvm"
+  }
+}
 notifiers {
   notifications {
     on_change: true
diff --git a/infra/config/generated/luci-scheduler.cfg b/infra/config/generated/luci-scheduler.cfg
index 24079c0e9..b04a85d94 100644
--- a/infra/config/generated/luci-scheduler.cfg
+++ b/infra/config/generated/luci-scheduler.cfg
@@ -4,6 +4,16 @@
 # For the schema of this file, see ProjectConfig message:
 #   https://config.luci.app/schemas/projects:luci-scheduler.cfg
 
+job {
+  id: "android-aarch64"
+  realm: "ci"
+  acl_sets: "ci"
+  buildbucket {
+    server: "cr-buildbucket.appspot.com"
+    bucket: "ci"
+    builder: "android-aarch64"
+  }
+}
 job {
   id: "build_docs"
   realm: "ci"
@@ -109,6 +119,7 @@ trigger {
   id: "main source"
   realm: "ci"
   acl_sets: "ci"
+  triggers: "android-aarch64"
   triggers: "build_docs"
   triggers: "chromeos_hatch"
   triggers: "health_check"
diff --git a/infra/config/generated/project.cfg b/infra/config/generated/project.cfg
index d7c804668..c838992b2 100644
--- a/infra/config/generated/project.cfg
+++ b/infra/config/generated/project.cfg
@@ -7,7 +7,7 @@
 name: "crosvm"
 access: "group:all"
 lucicfg {
-  version: "1.43.5"
+  version: "1.43.8"
   package_dir: ".."
   config_dir: "generated"
   entry_point: "main.star"
diff --git a/infra/config/main.star b/infra/config/main.star
index fa6f316f2..8611e6312 100755
--- a/infra/config/main.star
+++ b/infra/config/main.star
@@ -343,14 +343,37 @@ verify_builder(
         "cpu": "x86-64",
     },
     executable = luci.recipe(
-        name = "health_check",
+        name = "presubmit",
     ),
+    properties = {
+        "group_name": "health_checks",
+    },
     caches = [
         swarming.cache("builder", name = "linux_builder_cache"),
     ],
     category = "linux",
 )
 
+verify_builder(
+    name = "android-aarch64",
+    dimensions = {
+        "os": "Ubuntu",
+        "cpu": "x86-64",
+    },
+    executable = luci.recipe(
+        name = "presubmit",
+    ),
+    properties = {
+        "group_name": "android-aarch64",
+    },
+    caches = [
+        swarming.cache("builder", name = "linux_builder_cache"),
+    ],
+    category = "android",
+    # TODO(b/349907813): Enable in presubmit once stabilized
+    presubmit = False,
+)
+
 infra_builder(
     name = "push_to_github",
     executable = luci.recipe(
diff --git a/infra/config/recipes.cfg b/infra/config/recipes.cfg
index ec7d3746e..f32176259 100644
--- a/infra/config/recipes.cfg
+++ b/infra/config/recipes.cfg
@@ -20,12 +20,12 @@
   "deps": {
     "depot_tools": {
       "branch": "refs/heads/main",
-      "revision": "5a584405cae6e1fd08a6054ce9ba61b645b4d591",
+      "revision": "d1259b49c5b41bc4939ba7c5bb8e8e08083a05f6",
       "url": "https://chromium.googlesource.com/chromium/tools/depot_tools.git"
     },
     "recipe_engine": {
       "branch": "refs/heads/main",
-      "revision": "f967fa68fd4bd3e76140de7ffa449fa3a45a72f4",
+      "revision": "c291dd7687aee4b10811b3d3b517fd20c83e8333",
       "url": "https://chromium.googlesource.com/infra/luci/recipes-py.git"
     }
   },
diff --git a/infra/recipe_modules/crosvm/api.py b/infra/recipe_modules/crosvm/api.py
index 7308a19aa..f126bee32 100644
--- a/infra/recipe_modules/crosvm/api.py
+++ b/infra/recipe_modules/crosvm/api.py
@@ -14,31 +14,31 @@ class CrosvmApi(recipe_api.RecipeApi):
     @property
     def source_dir(self):
         "Where the crosvm source will be checked out."
-        return self.builder_cache.join("crosvm")
+        return self.builder_cache / "crosvm"
 
     @property
     def rustup_home(self):
         "RUSTUP_HOME is cached between runs."
-        return self.builder_cache.join("rustup")
+        return self.builder_cache / "rustup"
 
     @property
     def cargo_home(self):
         "CARGO_HOME is cached between runs."
-        return self.builder_cache.join("cargo_home")
+        return self.builder_cache / "cargo_home"
 
     @property
     def cargo_target_dir(self):
         "CARGO_TARGET_DIR is cleaned up between runs"
-        return self.m.path["cleanup"].join("cargo_target")
+        return self.m.path.cleanup_dir / "cargo_target"
 
     @property
     def local_bin(self):
         "Directory used to install local tools required by the build."
-        return self.builder_cache.join("local_bin")
+        return self.builder_cache / "local_bin"
 
     @property
     def dev_container_cache(self):
-        return self.builder_cache.join("dev_container")
+        return self.builder_cache / "dev_container"
 
     @property
     def builder_cache(self):
@@ -47,7 +47,7 @@ class CrosvmApi(recipe_api.RecipeApi):
 
         Luci will try to run each builder on the same bot as previously to keep this cache present.
         """
-        return self.m.path["cache"].join("builder")
+        return self.m.path.cache_dir / "builder"
 
     def source_context(self):
         """
@@ -92,7 +92,7 @@ class CrosvmApi(recipe_api.RecipeApi):
                     "Stop existing cros containers",
                     [
                         "vpython3",
-                        self.source_dir.join("tools/dev_container"),
+                        self.source_dir / "tools/dev_container",
                         "--verbose",
                         "--stop",
                         "--cros",
@@ -102,7 +102,7 @@ class CrosvmApi(recipe_api.RecipeApi):
                     "Force pull cros_container",
                     [
                         "vpython3",
-                        self.source_dir.join("tools/dev_container"),
+                        self.source_dir / "tools/dev_container",
                         "--pull",
                         "--cros",
                     ],
@@ -131,7 +131,7 @@ class CrosvmApi(recipe_api.RecipeApi):
                 }
                 env_prefixes = {
                     "PATH": [
-                        self.cargo_home.join("bin"),
+                        self.cargo_home / "bin",
                         self.local_bin,
                     ],
                 }
@@ -149,7 +149,7 @@ class CrosvmApi(recipe_api.RecipeApi):
             step_name,
             [
                 "vpython3",
-                self.source_dir.join("tools/dev_container"),
+                self.source_dir / "tools/dev_container",
                 "--no-interactive",
                 "--verbose",
             ]
@@ -160,7 +160,7 @@ class CrosvmApi(recipe_api.RecipeApi):
 
     def prepare_git(self):
         with self.m.step.nest("Prepare git"):
-            with self.m.context(cwd=self.m.path["start_dir"]):
+            with self.m.context(cwd=self.m.path.start_dir):
                 name = self.m.git.config_get("user.name")
                 email = self.m.git.config_get("user.email")
                 if not name or not email:
@@ -221,9 +221,9 @@ class CrosvmApi(recipe_api.RecipeApi):
         Note: You want to run this after prepare_source to ensure the correct version is installed.
         """
         with self.m.step.nest("Prepare rust"):
-            if not self.m.path.exists(
-                self.cargo_home.join("bin/rustup")
-            ) and not self.m.path.exists(self.cargo_home.join("bin/rustup.exe")):
+            if not self.m.path.exists(self.cargo_home / "bin/rustup") and not self.m.path.exists(
+                self.cargo_home / "bin/rustup.exe"
+            ):
                 rustup_init = self.m.cipd.ensure_tool("crosvm/rustup-init/${platform}", "latest")
                 self.m.step("Install rustup", [rustup_init, "-y", "--default-toolchain", "none"])
 
@@ -306,7 +306,7 @@ class CrosvmApi(recipe_api.RecipeApi):
                     "Stop existing dev containers",
                     [
                         "vpython3",
-                        self.source_dir.join("tools/dev_container"),
+                        self.source_dir / "tools/dev_container",
                         "--verbose",
                         "--stop",
                     ],
@@ -315,7 +315,7 @@ class CrosvmApi(recipe_api.RecipeApi):
                     "Force pull dev_container",
                     [
                         "vpython3",
-                        self.source_dir.join("tools/dev_container"),
+                        self.source_dir / "tools/dev_container",
                         "--pull",
                     ],
                 )
diff --git a/infra/recipe_modules/crosvm/examples/container_build_context.expected/basic.json b/infra/recipe_modules/crosvm/examples/container_build_context.expected/basic.json
index d706e7b75..80baadf95 100644
--- a/infra/recipe_modules/crosvm/examples/container_build_context.expected/basic.json
+++ b/infra/recipe_modules/crosvm/examples/container_build_context.expected/basic.json
@@ -159,8 +159,7 @@
       "@@@STEP_LOG_LINE@json.output@      \"revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\"@@@",
       "@@@STEP_LOG_LINE@json.output@    }@@@",
       "@@@STEP_LOG_LINE@json.output@  },@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_failure\": false,@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": \"crosvm\",@@@",
+      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": null,@@@",
       "@@@STEP_LOG_LINE@json.output@  \"properties\": {@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\",@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision_cp\": \"refs/heads/main@{#119844}\"@@@",
diff --git a/infra/recipe_modules/crosvm/examples/cros_container_build_context.expected/basic.json b/infra/recipe_modules/crosvm/examples/cros_container_build_context.expected/basic.json
index 0a59eea24..9f3633893 100644
--- a/infra/recipe_modules/crosvm/examples/cros_container_build_context.expected/basic.json
+++ b/infra/recipe_modules/crosvm/examples/cros_container_build_context.expected/basic.json
@@ -159,8 +159,7 @@
       "@@@STEP_LOG_LINE@json.output@      \"revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\"@@@",
       "@@@STEP_LOG_LINE@json.output@    }@@@",
       "@@@STEP_LOG_LINE@json.output@  },@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_failure\": false,@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": \"crosvm\",@@@",
+      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": null,@@@",
       "@@@STEP_LOG_LINE@json.output@  \"properties\": {@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\",@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision_cp\": \"refs/heads/main@{#119844}\"@@@",
diff --git a/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_linux.json b/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_linux.json
index 3427f4187..b145f4cad 100644
--- a/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_linux.json
+++ b/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_linux.json
@@ -159,8 +159,7 @@
       "@@@STEP_LOG_LINE@json.output@      \"revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\"@@@",
       "@@@STEP_LOG_LINE@json.output@    }@@@",
       "@@@STEP_LOG_LINE@json.output@  },@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_failure\": false,@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": \"crosvm\",@@@",
+      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": null,@@@",
       "@@@STEP_LOG_LINE@json.output@  \"properties\": {@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\",@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision_cp\": \"refs/heads/main@{#119844}\"@@@",
diff --git a/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_windows.json b/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_windows.json
index 8ce368421..82132a473 100644
--- a/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_windows.json
+++ b/infra/recipe_modules/crosvm/examples/host_build_context.expected/basic_windows.json
@@ -144,8 +144,7 @@
       "@@@STEP_LOG_LINE@json.output@      \"revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\"@@@",
       "@@@STEP_LOG_LINE@json.output@    }@@@",
       "@@@STEP_LOG_LINE@json.output@  },@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_failure\": false,@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": \"crosvm\",@@@",
+      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": null,@@@",
       "@@@STEP_LOG_LINE@json.output@  \"properties\": {@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\",@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision_cp\": \"refs/heads/main@{#119844}\"@@@",
diff --git a/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_ci.json b/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_ci.json
index 422f4d071..9bd976e5a 100644
--- a/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_ci.json
+++ b/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_ci.json
@@ -235,8 +235,7 @@
       "@@@STEP_LOG_LINE@json.output@      \"revision\": \"2d72510e447ab60a9728aeea2362d8be2cbd7789\"@@@",
       "@@@STEP_LOG_LINE@json.output@    }@@@",
       "@@@STEP_LOG_LINE@json.output@  },@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_failure\": false,@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": \"crosvm\",@@@",
+      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": null,@@@",
       "@@@STEP_LOG_LINE@json.output@  \"properties\": {@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision\": \"2d72510e447ab60a9728aeea2362d8be2cbd7789\",@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision_cp\": \"refs/heads/main@{#119844}\"@@@",
diff --git a/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_try.json b/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_try.json
index e547e8fee..405968915 100644
--- a/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_try.json
+++ b/infra/recipe_modules/crosvm/examples/source_context.expected/prepare_source_for_try.json
@@ -296,7 +296,6 @@
       "@@@STEP_LOG_LINE@json.output@      \"revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\"@@@",
       "@@@STEP_LOG_LINE@json.output@    }@@@",
       "@@@STEP_LOG_LINE@json.output@  },@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_failure\": false,@@@",
       "@@@STEP_LOG_LINE@json.output@  \"patch_root\": \"crosvm\",@@@",
       "@@@STEP_LOG_LINE@json.output@  \"properties\": {@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision\": \"2e31dd442a44af9e1e51e96aeca18017ddb9922c\",@@@",
diff --git a/infra/recipe_modules/crosvm/examples/source_context.expected/repair_submodules.json b/infra/recipe_modules/crosvm/examples/source_context.expected/repair_submodules.json
index b531eeb26..d2ba2f671 100644
--- a/infra/recipe_modules/crosvm/examples/source_context.expected/repair_submodules.json
+++ b/infra/recipe_modules/crosvm/examples/source_context.expected/repair_submodules.json
@@ -238,8 +238,7 @@
       "@@@STEP_LOG_LINE@json.output@      \"revision\": \"2d72510e447ab60a9728aeea2362d8be2cbd7789\"@@@",
       "@@@STEP_LOG_LINE@json.output@    }@@@",
       "@@@STEP_LOG_LINE@json.output@  },@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_failure\": false,@@@",
-      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": \"crosvm\",@@@",
+      "@@@STEP_LOG_LINE@json.output@  \"patch_root\": null,@@@",
       "@@@STEP_LOG_LINE@json.output@  \"properties\": {@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision\": \"2d72510e447ab60a9728aeea2362d8be2cbd7789\",@@@",
       "@@@STEP_LOG_LINE@json.output@    \"got_revision_cp\": \"refs/heads/main@{#119844}\"@@@",
diff --git a/infra/recipes.py b/infra/recipes.py
index 05ca94164..c6ef83add 100755
--- a/infra/recipes.py
+++ b/infra/recipes.py
@@ -235,13 +235,10 @@ def main():
   if not shutil.which(vpython):
     return f'Required binary is not found on PATH: {vpython}'
 
-  # We unset PYTHONPATH here in case the user has conflicting environmental
-  # things we don't want them to leak through into the recipe_engine which
-  # manages its environment entirely via vpython.
-  #
-  # NOTE: os.unsetenv unhelpfully doesn't exist on all platforms until python3.9
-  # so we have to use the cutesy `pop` formulation below until then...
-  os.environ.pop("PYTHONPATH", None)
+  # We overwrite PYTHONPATH here on purpose; We don't want any conflicting
+  # environmental path leaking through into the recipe_engine which manages its
+  # environment entirely via vpython.
+  os.environ['PYTHONPATH'] = engine_path
 
   spec = '.vpython3'
   debugger = os.environ.get('RECIPE_DEBUGGER', '')
diff --git a/infra/recipes/build_linux.py b/infra/recipes/build_linux.py
index 39fe52bbb..73e765069 100644
--- a/infra/recipes/build_linux.py
+++ b/infra/recipes/build_linux.py
@@ -78,7 +78,7 @@ def RunSteps(api, properties):
             "List checks to run",
             [
                 "vpython3",
-                api.crosvm.source_dir.join("tools/presubmit"),
+                api.crosvm.source_dir / "tools/presubmit",
                 "--list-checks",
                 presubmit_group,
             ],
diff --git a/infra/recipes/health_check.py b/infra/recipes/health_check.py
index a5fcc6685..e24bf28d5 100644
--- a/infra/recipes/health_check.py
+++ b/infra/recipes/health_check.py
@@ -20,7 +20,7 @@ def RunSteps(api):
             "Self-test dev-container",
             [
                 "vpython3",
-                api.crosvm.source_dir.join("tools/dev_container"),
+                api.crosvm.source_dir / "tools/dev_container",
                 "--verbose",
                 "--self-test",
             ],
@@ -29,7 +29,7 @@ def RunSteps(api):
             "List checks to run",
             [
                 "vpython3",
-                api.crosvm.source_dir.join("tools/presubmit"),
+                api.crosvm.source_dir / "tools/presubmit",
                 "--list-checks",
                 "health_checks",
             ],
diff --git a/infra/recipes/presubmit.expected/basic.json b/infra/recipes/presubmit.expected/basic.json
new file mode 100644
index 000000000..986c9ac9d
--- /dev/null
+++ b/infra/recipes/presubmit.expected/basic.json
@@ -0,0 +1,83 @@
+[
+  {
+    "cmd": [
+      "vpython3",
+      "[CACHE]/builder/crosvm/tools/presubmit",
+      "--list-checks",
+      "basic"
+    ],
+    "cwd": "[CACHE]/builder/crosvm",
+    "env": {
+      "CROSVM_CONTAINER_CACHE": "[CACHE]/builder/dev_container"
+    },
+    "luci_context": {
+      "realm": {
+        "name": "crosvm/crosvm:ci"
+      },
+      "resultdb": {
+        "current_invocation": {
+          "name": "invocations/build:8945511751514863184",
+          "update_token": "token"
+        },
+        "hostname": "rdbhost"
+      }
+    },
+    "name": "List checks to run"
+  },
+  {
+    "cmd": [
+      "vpython3",
+      "[CACHE]/builder/crosvm/tools/dev_container",
+      "--no-interactive",
+      "--verbose",
+      "tools/presubmit",
+      "--no-delta",
+      "check_a"
+    ],
+    "cwd": "[CACHE]/builder/crosvm",
+    "env": {
+      "CROSVM_CONTAINER_CACHE": "[CACHE]/builder/dev_container"
+    },
+    "luci_context": {
+      "realm": {
+        "name": "crosvm/crosvm:ci"
+      },
+      "resultdb": {
+        "current_invocation": {
+          "name": "invocations/build:8945511751514863184",
+          "update_token": "token"
+        },
+        "hostname": "rdbhost"
+      }
+    },
+    "name": "tools/presubmit check_a"
+  },
+  {
+    "cmd": [
+      "vpython3",
+      "[CACHE]/builder/crosvm/tools/dev_container",
+      "--no-interactive",
+      "--verbose",
+      "tools/presubmit",
+      "--no-delta",
+      "check_b"
+    ],
+    "cwd": "[CACHE]/builder/crosvm",
+    "env": {
+      "CROSVM_CONTAINER_CACHE": "[CACHE]/builder/dev_container"
+    },
+    "luci_context": {
+      "realm": {
+        "name": "crosvm/crosvm:ci"
+      },
+      "resultdb": {
+        "current_invocation": {
+          "name": "invocations/build:8945511751514863184",
+          "update_token": "token"
+        },
+        "hostname": "rdbhost"
+      }
+    },
+    "name": "tools/presubmit check_b"
+  }
+]
\ No newline at end of file
diff --git a/infra/recipes/presubmit.proto b/infra/recipes/presubmit.proto
new file mode 100644
index 000000000..0442bd53a
--- /dev/null
+++ b/infra/recipes/presubmit.proto
@@ -0,0 +1,12 @@
+// Copyright 2022 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+syntax = "proto3";
+
+package recipes.crosvm.presubmit;
+
+message PresubmitProperties {
+  // Name of presubmit group to run. See `crosvm/tools/presubmit`
+  optional string group_name = 1;
+}
diff --git a/infra/recipes/presubmit.py b/infra/recipes/presubmit.py
new file mode 100644
index 000000000..e74b497ef
--- /dev/null
+++ b/infra/recipes/presubmit.py
@@ -0,0 +1,57 @@
+# Copyright 2022 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# Runs tools/presubmit on all checks within a group
+
+import json
+
+from recipe_engine.recipe_api import Property
+from recipe_engine.post_process import DropExpectation, StatusFailure, Filter
+from PB.recipes.crosvm.presubmit import PresubmitProperties
+
+DEPS = [
+    "crosvm",
+    "recipe_engine/buildbucket",
+    "recipe_engine/context",
+    "recipe_engine/json",
+    "recipe_engine/properties",
+    "recipe_engine/raw_io",
+    "recipe_engine/step",
+]
+
+PROPERTIES = PresubmitProperties
+
+
+def RunSteps(api, properties):
+    with api.crosvm.container_build_context():
+        result = api.step(
+            "List checks to run",
+            [
+                "vpython3",
+                api.crosvm.source_dir / "tools/presubmit",
+                "--list-checks",
+                properties.group_name,
+            ],
+            stdout=api.raw_io.output_text(),
+        )
+        check_list = result.stdout.strip().split("\n")
+        for check in check_list:
+            api.crosvm.step_in_container(
+                "tools/presubmit %s" % check, ["tools/presubmit", "--no-delta", check]
+            )
+
+
+def GenTests(api):
+    yield (
+        api.test(
+            "basic",
+            api.buildbucket.ci_build(project="crosvm/crosvm"),
+        )
+        + api.properties(PresubmitProperties(group_name="basic"))
+        + api.step_data(
+            "List checks to run",
+            stdout=api.raw_io.output_text("check_a\ncheck_b"),
+        )
+        + api.post_process(Filter("List checks to run").include_re(r"tools/presubmit .*"))
+    )
diff --git a/io_uring/Android.bp b/io_uring/Android.bp
index dc4efe19d..cb72137eb 100644
--- a/io_uring/Android.bp
+++ b/io_uring/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "io_uring",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.1",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/io_uring/tests/uring.rs b/io_uring/tests/uring.rs
index bb3cd53e4..381bbbd84 100644
--- a/io_uring/tests/uring.rs
+++ b/io_uring/tests/uring.rs
@@ -308,8 +308,7 @@ fn fallocate_fsync() {
         let mut f = OpenOptions::new()
             .read(true)
             .write(true)
-            .create(true)
-            .truncate(true)
+            .create_new(true)
             .open(&file_path)
             .unwrap();
         f.write_all(&buf).unwrap();
@@ -321,6 +320,7 @@ fn fallocate_fsync() {
         .read(true)
         .write(true)
         .create(true)
+        .truncate(false)
         .open(&file_path)
         .unwrap();
 
diff --git a/jail/Android.bp b/jail/Android.bp
index dd72dcb45..a1ce5ba32 100644
--- a/jail/Android.bp
+++ b/jail/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "jail",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -31,6 +31,8 @@ rust_test {
         "libbase_rust",
         "libcfg_if",
         "liblibc",
+        "liblibtest_mimic",
+        "liblog_rust",
         "libminijail_rust",
         "libonce_cell",
         "libserde",
@@ -47,12 +49,13 @@ rust_library {
     crate_name: "jail",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
         "libbase_rust",
         "liblibc",
+        "liblog_rust",
         "libminijail_rust",
         "libonce_cell",
         "libserde",
diff --git a/jail/Cargo.toml b/jail/Cargo.toml
index 6b1353f25..4ac0dcc51 100644
--- a/jail/Cargo.toml
+++ b/jail/Cargo.toml
@@ -4,17 +4,25 @@ version = "0.1.0"
 authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
+# The process tests will use fork, which requires a custom test harness to enforce single threaded
+# execution.
+[[test]]
+name = "fork"
+path = "tests/fork.rs"
+harness = false
+
 [features]
 seccomp_trace = []
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 base = { path = "../base" }
-libc = "*"
-once_cell = "*"
-serde = "*"
+libc = "0.2"
+log = "0.4"
+once_cell = "1.7"
+serde = "1"
 serde_keyvalue = { path = "../serde_keyvalue", features = ["argh_derive"] }
-static_assertions = "*"
+static_assertions = "1.1"
 zerocopy = { version = "0.7", features = ["derive"] }
 
 [target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
@@ -25,4 +33,5 @@ which = "4"
 rayon = "1.5.3"
 
 [dev-dependencies]
-cfg-if = "*"
+cfg-if = "1"
+libtest-mimic = "0.6"
diff --git a/jail/seccomp/aarch64/fs_device_vhost_user.policy b/jail/seccomp/aarch64/fs_device_vhost_user.policy
new file mode 100644
index 000000000..61b48a2d4
--- /dev/null
+++ b/jail/seccomp/aarch64/fs_device_vhost_user.policy
@@ -0,0 +1,7 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+@include /usr/share/policy/crosvm/vhost_user.policy
+
+@include /usr/share/policy/crosvm/fs_device.policy
diff --git a/jail/seccomp/aarch64/pmem_device.policy b/jail/seccomp/aarch64/pmem_device.policy
index 34b76dcfc..2920dc5f3 100644
--- a/jail/seccomp/aarch64/pmem_device.policy
+++ b/jail/seccomp/aarch64/pmem_device.policy
@@ -8,3 +8,6 @@ fdatasync: 1
 fsync: 1
 openat: return ENOENT
 prctl: arg0 == PR_SET_NAME
+timerfd_create: 1
+timerfd_gettime: 1
+timerfd_settime: 1
diff --git a/jail/seccomp/aarch64/pvclock_device.policy b/jail/seccomp/aarch64/pvclock_device.policy
new file mode 100644
index 000000000..7935c9311
--- /dev/null
+++ b/jail/seccomp/aarch64/pvclock_device.policy
@@ -0,0 +1,8 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+@include /usr/share/policy/crosvm/common_device.policy
+
+openat: return ENOENT
+prctl: arg0 == PR_SET_NAME
diff --git a/jail/seccomp/aarch64/vhost_user.policy b/jail/seccomp/aarch64/vhost_user.policy
new file mode 100644
index 000000000..d9e32b6e2
--- /dev/null
+++ b/jail/seccomp/aarch64/vhost_user.policy
@@ -0,0 +1,14 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# Policy file for the vhost-user transport over a socket.
+
+# FIONBIO: for setting non-blocking mode over the socket.
+# TCGETS/TCSETS: used on FD 0, probably for serial.
+# b/239779171: try moving this to the serial device once we can extend ioctls across policy files.
+ioctl: arg1 == FIONBIO || arg1 == TCGETS || arg1 == TCSETS
+# For accepting a client connection over the socket.
+accept4: 1
+# For creating a socket if the specified socket path does not exits
+socketpair: arg0 == AF_UNIX
diff --git a/jail/seccomp/aarch64/video_device.policy b/jail/seccomp/aarch64/video_device.policy
index 1646cb520..bd8cc87aa 100644
--- a/jail/seccomp/aarch64/video_device.policy
+++ b/jail/seccomp/aarch64/video_device.policy
@@ -18,6 +18,7 @@ ioctl: arg1 & 0x6400
 openat: 1
 setpriority: 1
 socket: arg0 == AF_UNIX
+socketpair: arg0 == AF_UNIX
 prctl: arg0 == PR_SET_NAME
 # for libmojo used by libvda
 process_vm_readv: 1
diff --git a/jail/seccomp/aarch64/virtual_ext2.policy b/jail/seccomp/aarch64/virtual_ext2.policy
new file mode 100644
index 000000000..429685d33
--- /dev/null
+++ b/jail/seccomp/aarch64/virtual_ext2.policy
@@ -0,0 +1,23 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+close: 1
+exit_group: 1
+fcntl: arg1 == F_GETFD || arg1 == F_SETFD || arg1 == F_DUPFD_CLOEXEC
+fstat: 1
+getdents64: 1
+getegid: 1
+geteuid: 1
+getrandom: 1
+msync: 1
+mmap: arg2 in ~PROT_EXEC
+munmap: 1
+newfstatat: 1
+openat: arg3 in O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY
+readlinkat: 1
+recvfrom: 1
+recvmsg: 1
+sendmsg: 1
+sigaltstack: 1
+statx: 1
diff --git a/jail/seccomp/arm/pmem_device.policy b/jail/seccomp/arm/pmem_device.policy
index 790178997..22b34b3a2 100644
--- a/jail/seccomp/arm/pmem_device.policy
+++ b/jail/seccomp/arm/pmem_device.policy
@@ -9,3 +9,6 @@ fsync: 1
 open: return ENOENT
 openat: return ENOENT
 prctl: arg0 == PR_SET_NAME
+timerfd_create: 1
+timerfd_gettime: 1
+timerfd_settime: 1
diff --git a/jail/seccomp/arm/video_device.policy b/jail/seccomp/arm/video_device.policy
index 16ab371b8..20f7a7239 100644
--- a/jail/seccomp/arm/video_device.policy
+++ b/jail/seccomp/arm/video_device.policy
@@ -25,6 +25,7 @@ openat: 1
 send: 1
 setpriority: 1
 socket: arg0 == AF_UNIX
+socketpair: arg0 == AF_UNIX
 statx: 1
 stat64: 1
 prctl: arg0 == PR_SET_NAME
diff --git a/jail/seccomp/arm/virtual_ext2.policy b/jail/seccomp/arm/virtual_ext2.policy
new file mode 100644
index 000000000..0eecb331f
--- /dev/null
+++ b/jail/seccomp/arm/virtual_ext2.policy
@@ -0,0 +1,24 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+close: 1
+exit_group: 1
+fcntl: arg1 == F_GETFD || arg1 == F_SETFD || arg1 == F_DUPFD_CLOEXEC
+fstatat64: 1
+fstatfs: 1
+fstatfs64: 1
+getdents64: 1
+getegid: 1
+geteuid: 1
+getrandom: 1
+mmap2: arg2 in ~PROT_EXEC
+msync: 1
+munmap: 1
+openat: arg3 in O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY
+readlinkat: 1
+recvfrom: 1
+recvmsg: 1
+sendmsg: 1
+sigaltstack: 1
+statx: 1
diff --git a/jail/seccomp/x86_64/fs_device_vhost_user.policy b/jail/seccomp/x86_64/fs_device_vhost_user.policy
new file mode 100644
index 000000000..61b48a2d4
--- /dev/null
+++ b/jail/seccomp/x86_64/fs_device_vhost_user.policy
@@ -0,0 +1,7 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+@include /usr/share/policy/crosvm/vhost_user.policy
+
+@include /usr/share/policy/crosvm/fs_device.policy
diff --git a/jail/seccomp/x86_64/pmem_device.policy b/jail/seccomp/x86_64/pmem_device.policy
index 790178997..22b34b3a2 100644
--- a/jail/seccomp/x86_64/pmem_device.policy
+++ b/jail/seccomp/x86_64/pmem_device.policy
@@ -9,3 +9,6 @@ fsync: 1
 open: return ENOENT
 openat: return ENOENT
 prctl: arg0 == PR_SET_NAME
+timerfd_create: 1
+timerfd_gettime: 1
+timerfd_settime: 1
diff --git a/jail/seccomp/x86_64/vhost_user.policy b/jail/seccomp/x86_64/vhost_user.policy
index ef02356d4..608530834 100644
--- a/jail/seccomp/x86_64/vhost_user.policy
+++ b/jail/seccomp/x86_64/vhost_user.policy
@@ -11,3 +11,5 @@
 ioctl: arg1 == FIONBIO || arg1 == TCGETS || arg1 == TCSETS || arg1 == 0x1277
 # For accepting a client connection over the socket.
 accept4: 1
+# For creating a socket if the specified socket path does not exits
+socketpair: arg0 == AF_UNIX
diff --git a/jail/seccomp/x86_64/video_device.policy b/jail/seccomp/x86_64/video_device.policy
index 7aa0d5474..688e11195 100644
--- a/jail/seccomp/x86_64/video_device.policy
+++ b/jail/seccomp/x86_64/video_device.policy
@@ -79,6 +79,7 @@ newfstatat: 1
 openat: 1
 setpriority: 1
 socket: arg0 == AF_UNIX
+socketpair: arg0 == AF_UNIX
 stat: 1
 fstat: 1
 fstatfs: 1
diff --git a/jail/seccomp/x86_64/virtual_ext2.policy b/jail/seccomp/x86_64/virtual_ext2.policy
new file mode 100644
index 000000000..e96ef723c
--- /dev/null
+++ b/jail/seccomp/x86_64/virtual_ext2.policy
@@ -0,0 +1,31 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+brk: 1
+close: 1
+exit_group: 1
+# 1034 is F_GET_SEALS
+fcntl: arg1 == F_GETFD || arg1 == F_SETFD || arg1 == 1034 || arg1 == F_DUPFD_CLOEXEC
+fstat: 1
+getdents64: 1
+getdents: 1
+getegid: 1
+geteuid: 1
+getpid: 1
+getrandom: 1
+mmap: arg2 in ~PROT_EXEC
+madvise: 1
+mremap: 1
+msync: 1
+munmap: 1
+newfstatat: 1
+openat: arg3 in O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY
+readlink: 1
+recvfrom: 1
+recvmsg: 1
+sendmsg: 1
+sigaltstack: 1
+statx: 1
+write: 1
+prctl: 1
diff --git a/base/src/sys/linux/process.rs b/jail/src/fork.rs
similarity index 96%
rename from base/src/sys/linux/process.rs
rename to jail/src/fork.rs
index c52079f53..783a698a3 100644
--- a/base/src/sys/linux/process.rs
+++ b/jail/src/fork.rs
@@ -11,16 +11,15 @@ use std::mem::ManuallyDrop;
 use std::os::unix::process::ExitStatusExt;
 use std::process;
 
+use base::error;
+use base::linux::wait_for_pid;
+use base::Pid;
+use base::RawDescriptor;
 #[cfg(feature = "seccomp_trace")]
 use log::debug;
 use log::warn;
 use minijail::Minijail;
 
-use crate::error;
-use crate::linux::wait_for_pid;
-use crate::linux::Pid;
-use crate::RawDescriptor;
-
 /// Child represents the forked process.
 pub struct Child {
     /// The pid of the child process.
@@ -29,7 +28,7 @@ pub struct Child {
 
 impl Child {
     /// Wait for the child process exit using `waitpid(2)`.
-    pub fn wait(self) -> crate::Result<u8> {
+    pub fn wait(self) -> base::Result<u8> {
         // Suppress warning from the drop().
         let pid = self.into_pid();
         let (_, status) = wait_for_pid(pid, 0)?;
@@ -65,7 +64,7 @@ impl Child {
 
 impl Drop for Child {
     fn drop(&mut self) {
-        warn!("the child process have not been waited.");
+        warn!("the child process have not been waited.: {}", self.pid);
     }
 }
 
diff --git a/jail/src/helpers.rs b/jail/src/helpers.rs
index 29ee6b4ae..68a37cab5 100644
--- a/jail/src/helpers.rs
+++ b/jail/src/helpers.rs
@@ -111,6 +111,7 @@ impl Drop for ScopedMinijail {
 ///
 /// * `root` - The root path to be changed to by minijail.
 /// * `max_open_files` - The maximum number of file descriptors to allow a jailed process to open.
+#[allow(clippy::unnecessary_cast)]
 pub fn create_base_minijail(root: &Path, max_open_files: u64) -> Result<Minijail> {
     // Validate new root directory. Path::is_dir() also checks the existence.
     if !root.is_dir() {
@@ -288,20 +289,7 @@ pub fn create_sandbox_minijail(
                 })?;
         }
     } else {
-        let bpf_program = EMBEDDED_BPFS
-            .get(&config.seccomp_policy_name)
-            .with_context(|| {
-                format!(
-                    "failed to find embedded seccomp policy: {}",
-                    &config.seccomp_policy_name
-                )
-            })?;
-        jail.parse_seccomp_bytes(bpf_program).with_context(|| {
-            format!(
-                "failed to parse embedded seccomp policy: {}",
-                &config.seccomp_policy_name
-            )
-        })?;
+        set_embedded_bpf_program(&mut jail, config.seccomp_policy_name)?;
     }
 
     jail.use_seccomp_filter();
@@ -482,3 +470,20 @@ fn add_current_user_to_jail(jail: &mut Minijail) -> Result<()> {
     }
     Ok(())
 }
+
+/// Set the seccomp policy for a jail from embedded bpfs
+pub fn set_embedded_bpf_program(jail: &mut Minijail, seccomp_policy_name: &str) -> Result<()> {
+    let bpf_program = EMBEDDED_BPFS.get(seccomp_policy_name).with_context(|| {
+        format!(
+            "failed to find embedded seccomp policy: {}",
+            seccomp_policy_name
+        )
+    })?;
+    jail.parse_seccomp_bytes(bpf_program).with_context(|| {
+        format!(
+            "failed to parse embedded seccomp policy: {}",
+            seccomp_policy_name
+        )
+    })?;
+    Ok(())
+}
diff --git a/jail/src/lib.rs b/jail/src/lib.rs
index 97316dee1..4b409da09 100644
--- a/jail/src/lib.rs
+++ b/jail/src/lib.rs
@@ -4,10 +4,14 @@
 
 mod config;
 #[cfg(any(target_os = "android", target_os = "linux"))]
+pub mod fork;
+#[cfg(any(target_os = "android", target_os = "linux"))]
 mod helpers;
 
 pub use crate::config::JailConfig;
 #[cfg(any(target_os = "android", target_os = "linux"))]
+pub use crate::fork::fork_process;
+#[cfg(any(target_os = "android", target_os = "linux"))]
 pub use crate::helpers::*;
 
 // TODO(b/268407006): We define Minijail as an empty struct as a stub for minijail::Minijail on
diff --git a/base/tests/process.rs b/jail/tests/fork.rs
similarity index 99%
rename from base/tests/process.rs
rename to jail/tests/fork.rs
index 30f71accd..1dc86c5fe 100644
--- a/base/tests/process.rs
+++ b/jail/tests/fork.rs
@@ -8,9 +8,9 @@ mod test {
     use std::time::Duration;
 
     use base::getpid;
-    use base::linux::process::fork_process;
     use base::AsRawDescriptor;
     use base::Tube;
+    use jail::fork::fork_process;
     use minijail::Minijail;
 
     pub fn pid_diff() {
diff --git a/kernel_cmdline/Android.bp b/kernel_cmdline/Android.bp
index 7fcb23798..ebacb79a6 100644
--- a/kernel_cmdline/Android.bp
+++ b/kernel_cmdline/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "kernel_cmdline",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/kernel_cmdline.rs"],
+    crate_root: "src/kernel_cmdline.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -40,7 +40,7 @@ rust_library {
     crate_name: "kernel_cmdline",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/kernel_cmdline.rs"],
+    crate_root: "src/kernel_cmdline.rs",
     edition: "2021",
     rustlibs: [
         "liblibc",
diff --git a/kernel_cmdline/Cargo.toml b/kernel_cmdline/Cargo.toml
index aacbe0528..1dbdb1c7c 100644
--- a/kernel_cmdline/Cargo.toml
+++ b/kernel_cmdline/Cargo.toml
@@ -4,9 +4,9 @@ version = "0.1.0"
 edition = "2021"
 
 [dependencies]
-libc = "*"
-remain = "*"
-thiserror = "*"
+libc = "0.2"
+remain = "0.2"
+thiserror = "1"
 
 [lib]
 path = "src/kernel_cmdline.rs"
diff --git a/kernel_cmdline/src/kernel_cmdline.rs b/kernel_cmdline/src/kernel_cmdline.rs
index 99bffe1d1..60e7c2f28 100644
--- a/kernel_cmdline/src/kernel_cmdline.rs
+++ b/kernel_cmdline/src/kernel_cmdline.rs
@@ -23,8 +23,8 @@ pub enum Error {
     #[error("string contains non-printable ASCII character")]
     InvalidAscii,
     /// Operation would have made the command line too large.
-    #[error("inserting string would make command line too long")]
-    TooLarge,
+    #[error("command line length {0} exceeds maximum {1}")]
+    TooLarge(usize, usize),
 }
 
 /// Specialized Result type for command line operations.
@@ -54,45 +54,24 @@ fn valid_element(s: &str) -> Result<()> {
     }
 }
 
-/// A builder for a kernel command line string that validates the string as its being built. A
-/// `CString` can be constructed from this directly using `CString::new`.
+/// A builder for a kernel command line string that validates the string as it is built.
+#[derive(Default)]
 pub struct Cmdline {
     line: String,
-    capacity: usize,
 }
 
 impl Cmdline {
-    /// Constructs an empty Cmdline with the given capacity, which includes the nul terminator.
-    /// Capacity must be greater than 0.
-    pub fn new(capacity: usize) -> Cmdline {
-        assert_ne!(capacity, 0);
-        Cmdline {
-            line: String::new(),
-            capacity,
-        }
-    }
-
-    fn has_capacity(&self, more: usize) -> Result<()> {
-        let needs_space = if self.line.is_empty() { 0 } else { 1 };
-        if self.line.len() + more + needs_space < self.capacity {
-            Ok(())
-        } else {
-            Err(Error::TooLarge)
-        }
+    /// Constructs an empty Cmdline.
+    pub fn new() -> Cmdline {
+        Cmdline::default()
     }
 
-    fn start_push(&mut self) {
+    fn push_space_if_needed(&mut self) {
         if !self.line.is_empty() {
             self.line.push(' ');
         }
     }
 
-    fn end_push(&mut self) {
-        // This assert is always true because of the `has_capacity` check that each insert method
-        // uses.
-        assert!(self.line.len() < self.capacity);
-    }
-
     /// Validates and inserts a key value pair into this command line
     pub fn insert<T: AsRef<str>>(&mut self, key: T, val: T) -> Result<()> {
         let k = key.as_ref();
@@ -100,13 +79,11 @@ impl Cmdline {
 
         valid_element(k)?;
         valid_element(v)?;
-        self.has_capacity(k.len() + v.len() + 1)?;
 
-        self.start_push();
+        self.push_space_if_needed();
         self.line.push_str(k);
         self.line.push('=');
         self.line.push_str(v);
-        self.end_push();
 
         Ok(())
     }
@@ -116,11 +93,8 @@ impl Cmdline {
         let s = slug.as_ref();
         valid_str(s)?;
 
-        self.has_capacity(s.len())?;
-
-        self.start_push();
+        self.push_space_if_needed();
         self.line.push_str(s);
-        self.end_push();
 
         Ok(())
     }
@@ -129,34 +103,56 @@ impl Cmdline {
     pub fn as_str(&self) -> &str {
         self.line.as_str()
     }
-}
 
-impl From<Cmdline> for Vec<u8> {
-    fn from(c: Cmdline) -> Vec<u8> {
-        c.line.into_bytes()
+    /// Returns the current command line as a string with a maximum length.
+    ///
+    /// # Arguments
+    ///
+    /// `max_len`: maximum number of bytes (not including NUL terminator)
+    pub fn as_str_with_max_len(&self, max_len: usize) -> Result<&str> {
+        let s = self.line.as_str();
+        if s.len() <= max_len {
+            Ok(s)
+        } else {
+            Err(Error::TooLarge(s.len(), max_len))
+        }
+    }
+
+    /// Converts the command line into a `Vec<u8>` with a maximum length.
+    ///
+    /// # Arguments
+    ///
+    /// `max_len`: maximum number of bytes (not including NUL terminator)
+    pub fn into_bytes_with_max_len(self, max_len: usize) -> Result<Vec<u8>> {
+        let bytes: Vec<u8> = self.line.into_bytes();
+        if bytes.len() <= max_len {
+            Ok(bytes)
+        } else {
+            Err(Error::TooLarge(bytes.len(), max_len))
+        }
     }
 }
 
 #[cfg(test)]
 mod tests {
-    use std::ffi::CString;
-
     use super::*;
 
     #[test]
     fn insert_hello_world() {
-        let mut cl = Cmdline::new(100);
+        let mut cl = Cmdline::new();
         assert_eq!(cl.as_str(), "");
         assert!(cl.insert("hello", "world").is_ok());
         assert_eq!(cl.as_str(), "hello=world");
 
-        let s = CString::new(cl).expect("failed to create CString from Cmdline");
-        assert_eq!(s, CString::new("hello=world").unwrap());
+        let bytes = cl
+            .into_bytes_with_max_len(100)
+            .expect("failed to convert Cmdline into bytes");
+        assert_eq!(bytes, b"hello=world");
     }
 
     #[test]
     fn insert_multi() {
-        let mut cl = Cmdline::new(100);
+        let mut cl = Cmdline::new();
         assert!(cl.insert("hello", "world").is_ok());
         assert!(cl.insert("foo", "bar").is_ok());
         assert_eq!(cl.as_str(), "hello=world foo=bar");
@@ -164,7 +160,7 @@ mod tests {
 
     #[test]
     fn insert_space() {
-        let mut cl = Cmdline::new(100);
+        let mut cl = Cmdline::new();
         assert_eq!(cl.insert("a ", "b"), Err(Error::HasSpace));
         assert_eq!(cl.insert("a", "b "), Err(Error::HasSpace));
         assert_eq!(cl.insert("a ", "b "), Err(Error::HasSpace));
@@ -174,7 +170,7 @@ mod tests {
 
     #[test]
     fn insert_equals() {
-        let mut cl = Cmdline::new(100);
+        let mut cl = Cmdline::new();
         assert_eq!(cl.insert("a=", "b"), Err(Error::HasEquals));
         assert_eq!(cl.insert("a", "b="), Err(Error::HasEquals));
         assert_eq!(cl.insert("a=", "b "), Err(Error::HasEquals));
@@ -185,7 +181,7 @@ mod tests {
 
     #[test]
     fn insert_emoji() {
-        let mut cl = Cmdline::new(100);
+        let mut cl = Cmdline::new();
         assert_eq!(cl.insert("heart", ""), Err(Error::InvalidAscii));
         assert_eq!(cl.insert("", "love"), Err(Error::InvalidAscii));
         assert_eq!(cl.as_str(), "");
@@ -193,7 +189,7 @@ mod tests {
 
     #[test]
     fn insert_string() {
-        let mut cl = Cmdline::new(13);
+        let mut cl = Cmdline::new();
         assert_eq!(cl.as_str(), "");
         assert!(cl.insert_str("noapic").is_ok());
         assert_eq!(cl.as_str(), "noapic");
@@ -202,19 +198,25 @@ mod tests {
     }
 
     #[test]
-    fn insert_too_large() {
-        let mut cl = Cmdline::new(4);
-        assert_eq!(cl.insert("hello", "world"), Err(Error::TooLarge));
-        assert_eq!(cl.insert("a", "world"), Err(Error::TooLarge));
-        assert_eq!(cl.insert("hello", "b"), Err(Error::TooLarge));
-        assert!(cl.insert("a", "b").is_ok());
-        assert_eq!(cl.insert("a", "b"), Err(Error::TooLarge));
-        assert_eq!(cl.insert_str("a"), Err(Error::TooLarge));
+    fn as_str_too_large() {
+        let mut cl = Cmdline::new();
+        assert!(cl.insert("a", "b").is_ok()); // start off with 3.
         assert_eq!(cl.as_str(), "a=b");
+        assert_eq!(cl.as_str_with_max_len(2), Err(Error::TooLarge(3, 2)));
+        assert_eq!(cl.as_str_with_max_len(3), Ok("a=b"));
 
-        let mut cl = Cmdline::new(10);
+        let mut cl = Cmdline::new();
         assert!(cl.insert("ab", "ba").is_ok()); // adds 5 length
-        assert_eq!(cl.insert("c", "da"), Err(Error::TooLarge)); // adds 5 (including space) length
         assert!(cl.insert("c", "d").is_ok()); // adds 4 (including space) length
+        assert_eq!(cl.as_str(), "ab=ba c=d");
+        assert_eq!(cl.as_str_with_max_len(8), Err(Error::TooLarge(9, 8)));
+        assert_eq!(cl.as_str_with_max_len(9), Ok("ab=ba c=d"));
+
+        let mut cl = Cmdline::new();
+        assert!(cl.insert("ab", "ba").is_ok()); // adds 5 length
+        assert!(cl.insert_str("123").is_ok()); // adds 4 (including space) length
+        assert_eq!(cl.as_str(), "ab=ba 123");
+        assert_eq!(cl.as_str_with_max_len(8), Err(Error::TooLarge(9, 8)));
+        assert_eq!(cl.as_str_with_max_len(9), Ok("ab=ba 123"));
     }
 }
diff --git a/kernel_loader/Android.bp b/kernel_loader/Android.bp
index d3fc0df56..907f4debb 100644
--- a/kernel_loader/Android.bp
+++ b/kernel_loader/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "kernel_loader",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -47,7 +47,7 @@ rust_library {
     crate_name: "kernel_loader",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/kernel_loader/Cargo.toml b/kernel_loader/Cargo.toml
index ff246b1b3..c18b212d2 100644
--- a/kernel_loader/Cargo.toml
+++ b/kernel_loader/Cargo.toml
@@ -5,12 +5,12 @@ edition = "2021"
 
 [dependencies]
 data_model = { path = "../common/data_model" }
-libc = "*"
+libc = "0.2"
 base = { path = "../base" }
 lz4_flex = "0.11"
-remain = "*"
+remain = "0.2"
 resources = { path = "../resources" }
-thiserror = "*"
+thiserror = "1"
 vm_memory = { path = "../vm_memory" }
 zerocopy = { version = "0.7", features = ["derive"] }
 
diff --git a/kernel_loader/src/arm64.rs b/kernel_loader/src/arm64.rs
index a5b80b1bd..89823ade1 100644
--- a/kernel_loader/src/arm64.rs
+++ b/kernel_loader/src/arm64.rs
@@ -140,7 +140,7 @@ fn load_arm64_kernel_from_reader<F: BufRead>(
         .ok_or(Error::InvalidKernelSize)?;
     loop {
         let buf = match kernel_image.fill_buf() {
-            Ok(buf) if buf.is_empty() => break,
+            Ok([]) => break,
             Ok(buf) => buf,
             Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
             Err(_) => return Err(Error::ReadKernelImage),
diff --git a/kernel_loader/src/lib.rs b/kernel_loader/src/lib.rs
index 8b96340e4..77c3058bc 100644
--- a/kernel_loader/src/lib.rs
+++ b/kernel_loader/src/lib.rs
@@ -4,7 +4,6 @@
 
 //! Linux kernel ELF file loader.
 
-use std::ffi::CStr;
 use std::mem;
 
 use base::FileReadWriteAtVolatile;
@@ -17,6 +16,8 @@ use vm_memory::GuestMemory;
 use zerocopy::AsBytes;
 use zerocopy::FromBytes;
 
+mod multiboot;
+
 #[allow(dead_code)]
 #[allow(non_camel_case_types)]
 #[allow(non_snake_case)]
@@ -28,22 +29,22 @@ mod arm64;
 
 pub use arm64::load_arm64_kernel;
 pub use arm64::load_arm64_kernel_lz4;
+pub use multiboot::load_multiboot;
+pub use multiboot::multiboot_header_from_file;
 
 #[sorted]
 #[derive(Error, Debug, PartialEq, Eq)]
 pub enum Error {
     #[error("trying to load big-endian binary on little-endian machine")]
     BigEndianOnLittle,
-    #[error("failed writing command line to guest memory")]
-    CommandLineCopy,
-    #[error("command line overflowed guest memory")]
-    CommandLineOverflow,
     #[error("invalid elf class")]
     InvalidElfClass,
     #[error("invalid elf version")]
     InvalidElfVersion,
     #[error("invalid entry point")]
     InvalidEntryPoint,
+    #[error("invalid flags")]
+    InvalidFlags,
     #[error("invalid kernel offset")]
     InvalidKernelOffset,
     #[error("invalid kernel size")]
@@ -249,37 +250,6 @@ where
     })
 }
 
-/// Writes the command line string to the given memory slice.
-///
-/// # Arguments
-///
-/// * `guest_mem` - A u8 slice that will be partially overwritten by the command line.
-/// * `guest_addr` - The address in `guest_mem` at which to load the command line.
-/// * `cmdline` - The kernel command line.
-pub fn load_cmdline(
-    guest_mem: &GuestMemory,
-    guest_addr: GuestAddress,
-    cmdline: &CStr,
-) -> Result<()> {
-    let len = cmdline.to_bytes().len();
-    if len == 0 {
-        return Ok(());
-    }
-
-    let end = guest_addr
-        .checked_add(len as u64 + 1)
-        .ok_or(Error::CommandLineOverflow)?; // Extra for null termination.
-    if end > guest_mem.end_addr() {
-        return Err(Error::CommandLineOverflow);
-    }
-
-    guest_mem
-        .write_at_addr(cmdline.to_bytes_with_nul(), guest_addr)
-        .map_err(|_| Error::CommandLineCopy)?;
-
-    Ok(())
-}
-
 struct Elf64 {
     file_header: elf::Elf64_Ehdr,
     program_headers: Vec<elf::Elf64_Phdr>,
@@ -414,48 +384,6 @@ mod test {
         GuestMemory::new(&[(GuestAddress(0x0), MEM_SIZE)]).unwrap()
     }
 
-    #[test]
-    fn cmdline_overflow() {
-        let gm = create_guest_mem();
-        let cmdline_address = GuestAddress(MEM_SIZE - 5);
-        assert_eq!(
-            Err(Error::CommandLineOverflow),
-            load_cmdline(
-                &gm,
-                cmdline_address,
-                CStr::from_bytes_with_nul(b"12345\0").unwrap()
-            )
-        );
-    }
-
-    #[test]
-    fn cmdline_write_end() {
-        let gm = create_guest_mem();
-        let mut cmdline_address = GuestAddress(45);
-        assert_eq!(
-            Ok(()),
-            load_cmdline(
-                &gm,
-                cmdline_address,
-                CStr::from_bytes_with_nul(b"1234\0").unwrap()
-            )
-        );
-        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
-        assert_eq!(val, b'1');
-        cmdline_address = cmdline_address.unchecked_add(1);
-        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
-        assert_eq!(val, b'2');
-        cmdline_address = cmdline_address.unchecked_add(1);
-        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
-        assert_eq!(val, b'3');
-        cmdline_address = cmdline_address.unchecked_add(1);
-        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
-        assert_eq!(val, b'4');
-        cmdline_address = cmdline_address.unchecked_add(1);
-        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
-        assert_eq!(val, b'\0');
-    }
-
     // Elf32 image that prints hello world on x86.
     fn make_elf32_bin() -> File {
         // test_elf32.bin built on Linux with gcc -m32 -static-pie
diff --git a/kernel_loader/src/multiboot.rs b/kernel_loader/src/multiboot.rs
new file mode 100644
index 000000000..5473ef8b2
--- /dev/null
+++ b/kernel_loader/src/multiboot.rs
@@ -0,0 +1,356 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Multiboot kernel loader
+//!
+//! Only Multiboot (version 0.6.96) is supported, not Multiboot2.
+
+use std::fs::File;
+use std::mem::size_of;
+use std::num::NonZeroU32;
+
+use base::error;
+use base::trace;
+use base::FileReadWriteAtVolatile;
+use base::VolatileSlice;
+use resources::AddressRange;
+use vm_memory::GuestAddress;
+use vm_memory::GuestMemory;
+
+use crate::Error;
+use crate::LoadedKernel;
+use crate::Result;
+
+/// Multiboot header retrieved from a kernel image.
+#[derive(Clone, Debug)]
+pub struct MultibootKernel {
+    /// Byte offset of the beginning of the multiboot header in the kernel image.
+    pub offset: u32,
+
+    /// Kernel requires that boot modules are aligned to 4 KB.
+    pub boot_modules_page_aligned: bool,
+
+    /// Kernel requires available memory information (`mem_*` fields).
+    pub need_available_memory: bool,
+
+    /// Kernel load address.
+    ///
+    /// If present, this overrides any other executable format headers (e.g. ELF).
+    pub load: Option<MultibootLoad>,
+
+    /// Kernel preferred video mode.
+    ///
+    /// If present, the kernel also requires information about the video mode table.
+    pub preferred_video_mode: Option<MultibootVideoMode>,
+}
+
+/// Multiboot kernel load parameters.
+#[derive(Clone, Debug)]
+pub struct MultibootLoad {
+    /// File byte offset to load the kernel's code and initialized data from.
+    pub file_load_offset: u64,
+
+    /// Number of bytes to read from the file at `file_load_offset`.
+    pub file_load_size: usize,
+
+    /// Physical memory address where the kernel should be loaded.
+    pub load_addr: GuestAddress,
+
+    /// Physical address of the kernel entry point.
+    pub entry_addr: GuestAddress,
+
+    /// BSS physical memory starting address to zero fill, if present in kernel.
+    pub bss_addr: Option<GuestAddress>,
+
+    /// BSS size in bytes (0 if no BSS region is present).
+    pub bss_size: usize,
+}
+
+/// Multiboot kernel video mode specification.
+#[derive(Clone, Debug)]
+pub struct MultibootVideoMode {
+    /// Preferred video mode type (text or graphics).
+    pub mode_type: MultibootVideoModeType,
+
+    /// Width of the requested mode.
+    ///
+    /// For text modes, this is in units of characters. For graphics modes, this is in units of
+    /// pixels.
+    pub width: Option<NonZeroU32>,
+
+    /// Height of the requested mode.
+    ///
+    /// For text modes, this is in units of characters. For graphics modes, this is in units of
+    /// pixels.
+    pub height: Option<NonZeroU32>,
+
+    /// Requested bits per pixel (only relevant in graphics modes).
+    pub depth: Option<NonZeroU32>,
+}
+
+#[derive(Copy, Clone, Debug)]
+pub enum MultibootVideoModeType {
+    LinearGraphics,
+    EgaText,
+    Other(u32),
+}
+
+/// Scan the provided kernel file to find a Multiboot header, if present.
+///
+/// # Returns
+///
+/// - `Ok(None)`: kernel file did not contain a Multiboot header.
+/// - `Ok(Some(...))`: kernel file contained a valid Multiboot header, which is returned.
+/// - `Err(...)`: kernel file contained a Multiboot header with a valid checksum but other fields in
+///   the header were invalid.
+pub fn multiboot_header_from_file(kernel_file: &mut File) -> Result<Option<MultibootKernel>> {
+    const MIN_HEADER_SIZE: usize = 3 * size_of::<u32>();
+    const ALIGNMENT: usize = 4;
+
+    // Read up to 8192 bytes from the beginning of the file.
+    let kernel_file_len = kernel_file.metadata().map_err(|_| Error::ReadHeader)?.len();
+    let kernel_prefix_len = kernel_file_len.min(8192) as usize;
+
+    if kernel_prefix_len < MIN_HEADER_SIZE {
+        return Ok(None);
+    }
+
+    let mut kernel_bytes = vec![0u8; kernel_prefix_len];
+    kernel_file
+        .read_exact_at_volatile(VolatileSlice::new(&mut kernel_bytes), 0)
+        .map_err(|_| Error::ReadHeader)?;
+
+    for offset in (0..kernel_prefix_len).step_by(ALIGNMENT) {
+        let Some(hdr) = kernel_bytes.get(offset..) else {
+            break;
+        };
+        match multiboot_header(hdr, offset as u64, kernel_file_len) {
+            Ok(None) => continue,
+            Ok(Some(multiboot)) => return Ok(Some(multiboot)),
+            Err(e) => return Err(e),
+        }
+    }
+
+    // The file did not contain a valid Multiboot header.
+    Ok(None)
+}
+
+/// Attempt to parse a Multiboot header from the prefix of a slice.
+///
+/// # Returns
+///
+/// - `Ok(None)`: no multiboot header here.
+/// - `Ok(Some(...))`: valid multiboot header is returned.
+/// - `Err(...)`: valid multiboot header checksum at this position in the file (meaning this is the
+///   real header location), but there is an invalid field later in the multiboot header (e.g. an
+///   impossible combination of load addresses).
+fn multiboot_header(
+    hdr: &[u8],
+    offset: u64,
+    kernel_file_len: u64,
+) -> Result<Option<MultibootKernel>> {
+    const MAGIC: u32 = 0x1BADB002;
+
+    let Ok(magic) = get_le32(hdr, 0) else {
+        return Ok(None);
+    };
+    if magic != MAGIC {
+        return Ok(None);
+    }
+
+    // Failing to read these fields means we ran out of data at the end of the slice and did not
+    // actually find a Multiboot header, so return `Ok(None)` to indicate no Multiboot header was
+    // found instead of using `?`, which would return an error.
+    let Ok(flags) = get_le32(hdr, 4) else {
+        return Ok(None);
+    };
+    let Ok(checksum) = get_le32(hdr, 8) else {
+        return Ok(None);
+    };
+
+    if magic.wrapping_add(flags).wrapping_add(checksum) != 0 {
+        // Checksum did not match, so this is not a real Multiboot header. Keep searching.
+        return Ok(None);
+    }
+
+    trace!("found Multiboot header with valid checksum at {offset:#X}");
+
+    const F_BOOT_MODULE_PAGE_ALIGN: u32 = 1 << 0;
+    const F_AVAILABLE_MEMORY: u32 = 1 << 1;
+    const F_VIDEO_MODE: u32 = 1 << 2;
+    const F_ADDRESS: u32 = 1 << 16;
+
+    const KNOWN_FLAGS: u32 =
+        F_BOOT_MODULE_PAGE_ALIGN | F_AVAILABLE_MEMORY | F_VIDEO_MODE | F_ADDRESS;
+
+    let unknown_flags = flags & !KNOWN_FLAGS;
+    if unknown_flags != 0 {
+        error!("unknown flags {unknown_flags:#X}");
+        return Err(Error::InvalidFlags);
+    }
+
+    let boot_modules_page_aligned = flags & F_BOOT_MODULE_PAGE_ALIGN != 0;
+    let need_available_memory = flags & F_AVAILABLE_MEMORY != 0;
+    let need_video_mode_table = flags & F_VIDEO_MODE != 0;
+    let load_address_available = flags & F_ADDRESS != 0;
+
+    let load = if load_address_available {
+        let header_addr = get_le32(hdr, 12)?;
+        let load_addr = get_le32(hdr, 16)?;
+        let load_end_addr = get_le32(hdr, 20)?;
+        let bss_end_addr = get_le32(hdr, 24)?;
+        let entry_addr = get_le32(hdr, 28)?;
+
+        if header_addr < load_addr {
+            error!("header_addr {header_addr:#X} < load_addr {load_addr:#X}");
+            return Err(Error::InvalidKernelOffset);
+        }
+
+        // The beginning of the area to load from the file starts `load_offset` bytes before the
+        // multiboot header.
+        let load_offset = u64::from(header_addr - load_addr);
+        if load_offset > offset {
+            error!("load_offset {load_offset:#X} > offset {offset:#X}");
+            return Err(Error::InvalidKernelOffset);
+        }
+        let file_load_offset = offset - load_offset;
+
+        let file_load_size = if load_end_addr == 0 {
+            // Zero `load_end_addr` means the loadable data extends to the end of the file.
+            (kernel_file_len - file_load_offset)
+                .try_into()
+                .map_err(|_| Error::InvalidKernelOffset)?
+        } else if load_end_addr < load_addr {
+            error!("load_end_addr {load_end_addr:#X} < load_addr {load_addr:#X}");
+            return Err(Error::InvalidKernelOffset);
+        } else {
+            load_end_addr - load_addr
+        };
+
+        let load_end_addr = load_addr
+            .checked_add(file_load_size)
+            .ok_or(Error::InvalidKernelOffset)?;
+
+        // The bss region immediately follows the load-from-file region in memory.
+        let bss_addr = load_addr + file_load_size;
+
+        let bss_size = if bss_end_addr == 0 {
+            // Zero `bss_end_addr` means no bss segment is present.
+            0
+        } else if bss_end_addr < bss_addr {
+            error!("bss_end_addr {bss_end_addr:#X} < bss_addr {bss_addr:#X}");
+            return Err(Error::InvalidKernelOffset);
+        } else {
+            bss_end_addr - bss_addr
+        };
+
+        let bss_addr = if bss_size > 0 {
+            Some(GuestAddress(bss_addr.into()))
+        } else {
+            None
+        };
+
+        if entry_addr < load_addr || entry_addr >= load_end_addr {
+            error!(
+                "entry_addr {entry_addr:#X} not in load range {load_addr:#X}..{load_end_addr:#X}"
+            );
+            return Err(Error::InvalidKernelOffset);
+        }
+
+        Some(MultibootLoad {
+            file_load_offset,
+            file_load_size: file_load_size as usize,
+            load_addr: GuestAddress(load_addr.into()),
+            entry_addr: GuestAddress(entry_addr.into()),
+            bss_addr,
+            bss_size: bss_size as usize,
+        })
+    } else {
+        None
+    };
+
+    let preferred_video_mode = if need_video_mode_table {
+        let mode_type = get_le32(hdr, 32)?;
+        let width = get_le32(hdr, 36)?;
+        let height = get_le32(hdr, 40)?;
+        let depth = get_le32(hdr, 44)?;
+
+        let mode_type = match mode_type {
+            0 => MultibootVideoModeType::LinearGraphics,
+            1 => MultibootVideoModeType::EgaText,
+            _ => MultibootVideoModeType::Other(mode_type),
+        };
+
+        Some(MultibootVideoMode {
+            mode_type,
+            width: NonZeroU32::new(width),
+            height: NonZeroU32::new(height),
+            depth: NonZeroU32::new(depth),
+        })
+    } else {
+        None
+    };
+
+    let multiboot = MultibootKernel {
+        offset: offset as u32,
+        boot_modules_page_aligned,
+        need_available_memory,
+        load,
+        preferred_video_mode,
+    };
+
+    trace!("validated header: {multiboot:?}");
+
+    Ok(Some(multiboot))
+}
+
+fn get_le32(bytes: &[u8], offset: usize) -> Result<u32> {
+    let le32_bytes = bytes.get(offset..offset + 4).ok_or(Error::ReadHeader)?;
+    // This can't fail because the slice is always 4 bytes long.
+    let le32_array: [u8; 4] = le32_bytes.try_into().unwrap();
+    Ok(u32::from_le_bytes(le32_array))
+}
+
+/// Load a Multiboot kernel image into memory.
+///
+/// The `MultibootLoad` information can be retrieved from the optional `load` field of a
+/// `MultibootKernel` returned by [`multiboot_header_from_file()`].
+pub fn load_multiboot<F>(
+    guest_mem: &GuestMemory,
+    kernel_image: &mut F,
+    multiboot_load: &MultibootLoad,
+) -> Result<LoadedKernel>
+where
+    F: FileReadWriteAtVolatile,
+{
+    let guest_slice = guest_mem
+        .get_slice_at_addr(multiboot_load.load_addr, multiboot_load.file_load_size)
+        .map_err(|_| Error::ReadKernelImage)?;
+    kernel_image
+        .read_exact_at_volatile(guest_slice, multiboot_load.file_load_offset)
+        .map_err(|_| Error::ReadKernelImage)?;
+
+    if let Some(bss_addr) = multiboot_load.bss_addr {
+        let bss_slice = guest_mem
+            .get_slice_at_addr(bss_addr, multiboot_load.bss_size)
+            .map_err(|_| Error::ReadKernelImage)?;
+        bss_slice.write_bytes(0);
+    }
+
+    let size: u64 = multiboot_load
+        .file_load_size
+        .checked_add(multiboot_load.bss_size)
+        .ok_or(Error::InvalidProgramHeaderSize)?
+        .try_into()
+        .map_err(|_| Error::InvalidProgramHeaderSize)?;
+
+    let address_range = AddressRange::from_start_and_size(multiboot_load.load_addr.offset(), size)
+        .ok_or(Error::InvalidProgramHeaderSize)?;
+
+    Ok(LoadedKernel {
+        address_range,
+        size,
+        entry: multiboot_load.entry_addr,
+    })
+}
diff --git a/kvm/Android.bp b/kvm/Android.bp
index d87e60fcc..25e5607d6 100644
--- a/kvm/Android.bp
+++ b/kvm/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "dirty_log",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/dirty_log.rs"],
+    crate_root: "tests/dirty_log.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -44,7 +44,7 @@ rust_test {
     crate_name: "kvm_tests",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/kvm_tests.rs"],
+    crate_root: "tests/kvm_tests.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -69,7 +69,7 @@ rust_test {
     crate_name: "read_only_memory",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/read_only_memory.rs"],
+    crate_root: "tests/read_only_memory.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -94,7 +94,7 @@ rust_test {
     crate_name: "real_run_adder",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/real_run_adder.rs"],
+    crate_root: "tests/real_run_adder.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -119,7 +119,7 @@ rust_library {
     crate_name: "kvm",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/kvm/Cargo.toml b/kvm/Cargo.toml
index 062a0bc81..3fe807c09 100644
--- a/kvm/Cargo.toml
+++ b/kvm/Cargo.toml
@@ -7,7 +7,7 @@ edition = "2021"
 [dependencies]
 data_model = { path = "../common/data_model" }
 kvm_sys = { path = "../kvm_sys" }
-libc = "*"
+libc = "0.2"
 base = { path = "../base" }
 sync = { path = "../common/sync" }
 vm_memory = { path = "../vm_memory" }
diff --git a/kvm/src/lib.rs b/kvm/src/lib.rs
index 6a0284b87..4dcf4b957 100644
--- a/kvm/src/lib.rs
+++ b/kvm/src/lib.rs
@@ -23,7 +23,6 @@ use std::ops::DerefMut;
 use std::os::raw::*;
 use std::os::unix::prelude::OsStrExt;
 use std::path::Path;
-use std::path::PathBuf;
 use std::ptr::copy_nonoverlapping;
 use std::sync::Arc;
 
@@ -113,7 +112,7 @@ unsafe fn set_user_memory_region<F: AsRawDescriptor>(
         userspace_addr: userspace_addr as u64,
     };
 
-    let ret = ioctl_with_ref(fd, KVM_SET_USER_MEMORY_REGION(), &region);
+    let ret = ioctl_with_ref(fd, KVM_SET_USER_MEMORY_REGION, &region);
     if ret == 0 {
         Ok(())
     } else {
@@ -141,9 +140,9 @@ pub struct Kvm {
 }
 
 impl Kvm {
-    /// Opens `/dev/kvm/` and returns a Kvm object on success.
+    /// Opens `/dev/kvm` and returns a Kvm object on success.
     pub fn new() -> Result<Kvm> {
-        Kvm::new_with_path(&PathBuf::from("/dev/kvm"))
+        Kvm::new_with_path(Path::new("/dev/kvm"))
     }
 
     /// Opens a KVM device at `device_path` and returns a Kvm object on success.
@@ -168,7 +167,7 @@ impl Kvm {
         // SAFETY:
         // Safe because we know that our file is a KVM fd and that the extension is one of the ones
         // defined by kernel.
-        unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION(), c as c_ulong) }
+        unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION, c as c_ulong) }
     }
 
     /// Checks if a particular `Cap` is available.
@@ -180,7 +179,7 @@ impl Kvm {
     pub fn get_vcpu_mmap_size(&self) -> Result<usize> {
         // SAFETY:
         // Safe because we know that our file is a KVM fd and we verify the return result.
-        let res = unsafe { ioctl(self, KVM_GET_VCPU_MMAP_SIZE()) };
+        let res = unsafe { ioctl(self, KVM_GET_VCPU_MMAP_SIZE) };
         if res > 0 {
             Ok(res as usize)
         } else {
@@ -208,13 +207,13 @@ impl Kvm {
     /// X86 specific call to get the system supported CPUID values
     #[cfg(target_arch = "x86_64")]
     pub fn get_supported_cpuid(&self) -> Result<CpuId> {
-        self.get_cpuid(KVM_GET_SUPPORTED_CPUID())
+        self.get_cpuid(KVM_GET_SUPPORTED_CPUID)
     }
 
     /// X86 specific call to get the system emulated CPUID values
     #[cfg(target_arch = "x86_64")]
     pub fn get_emulated_cpuid(&self) -> Result<CpuId> {
-        self.get_cpuid(KVM_GET_EMULATED_CPUID())
+        self.get_cpuid(KVM_GET_EMULATED_CPUID)
     }
 
     /// X86 specific call to get list of supported MSRS
@@ -231,7 +230,7 @@ impl Kvm {
         // ioctl is unsafe. The kernel is trusted not to write beyond the bounds of the memory
         // allocated for the struct. The limit is read from nmsrs, which is set to the allocated
         // size (MAX_KVM_MSR_ENTRIES) above.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_MSR_INDEX_LIST(), &mut msr_list[0]) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_MSR_INDEX_LIST, &mut msr_list[0]) };
         if ret < 0 {
             return errno_result();
         }
@@ -266,8 +265,7 @@ impl Kvm {
     pub fn get_vm_type(&self) -> c_ulong {
         // SAFETY:
         // Safe because we know self is a real kvm fd
-        match unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION(), KVM_CAP_ARM_VM_IPA_SIZE.into()) }
-        {
+        match unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION, KVM_CAP_ARM_VM_IPA_SIZE.into()) } {
             // Not supported? Use 0 as the machine type, which implies 40bit IPA
             ret if ret < 0 => 0,
             // Use the lower 8 bits representing the IPA space as the machine type
@@ -351,7 +349,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know kvm is a real kvm fd as this module is the only one that can make
         // Kvm objects.
-        let ret = unsafe { ioctl_with_val(kvm, KVM_CREATE_VM(), kvm.get_vm_type()) };
+        let ret = unsafe { ioctl_with_val(kvm, KVM_CREATE_VM, kvm.get_vm_type()) };
         if ret >= 0 {
             // SAFETY:
             // Safe because we verify the value of ret and we are the owners of the fd.
@@ -392,7 +390,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a KVM fd and that the extension is one of the ones
         // defined by kernel.
-        unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION(), c as c_ulong) == 1 }
+        unsafe { ioctl_with_val(self, KVM_CHECK_EXTENSION, c as c_ulong) == 1 }
     }
 
     /// Inserts the given `mem` into the VM's address space at `guest_addr`.
@@ -495,7 +493,7 @@ impl Vm {
                 // Safe because the `dirty_bitmap` pointer assigned above is guaranteed to be valid
                 // (because it's from a slice) and we checked that it will be large enough to hold
                 // the entire log.
-                let ret = unsafe { ioctl_with_ref(self, KVM_GET_DIRTY_LOG(), &dirty_log_kvm) };
+                let ret = unsafe { ioctl_with_ref(self, KVM_GET_DIRTY_LOG, &dirty_log_kvm) };
                 if ret == 0 {
                     Ok(())
                 } else {
@@ -521,7 +519,7 @@ impl Vm {
     pub fn set_identity_map_addr(&self, addr: GuestAddress) -> Result<()> {
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IDENTITY_MAP_ADDR(), &addr.offset()) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IDENTITY_MAP_ADDR, &addr.offset()) };
         if ret == 0 {
             Ok(())
         } else {
@@ -539,7 +537,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only write
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_CLOCK(), &mut clock_data) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_CLOCK, &mut clock_data) };
         if ret == 0 {
             Ok(clock_data)
         } else {
@@ -555,7 +553,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_CLOCK(), clock_data) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_CLOCK, clock_data) };
         if ret == 0 {
             Ok(())
         } else {
@@ -570,7 +568,7 @@ impl Vm {
     pub fn create_irq_chip(&self) -> Result<()> {
         // SAFETY:
         // Safe because we know that our file is a VM fd and we verify the return result.
-        let ret = unsafe { ioctl(self, KVM_CREATE_IRQCHIP()) };
+        let ret = unsafe { ioctl(self, KVM_CREATE_IRQCHIP) };
         if ret == 0 {
             Ok(())
         } else {
@@ -590,7 +588,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know our file is a VM fd, we know the kernel will only write
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_IRQCHIP(), &mut irqchip_state) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_IRQCHIP, &mut irqchip_state) };
         if ret == 0 {
             Ok(
                 // SAFETY:
@@ -616,7 +614,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP(), &irqchip_state) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP, &irqchip_state) };
         if ret == 0 {
             Ok(())
         } else {
@@ -638,7 +636,7 @@ impl Vm {
             // Safe because we know our file is a VM fd, we know the kernel will only write
             // correct amount of memory to our pointer, and we verify the return result.
             unsafe {
-                ioctl_with_mut_ref(self, KVM_GET_IRQCHIP(), &mut irqchip_state)
+                ioctl_with_mut_ref(self, KVM_GET_IRQCHIP, &mut irqchip_state)
         };
         if ret == 0 {
             Ok(
@@ -665,7 +663,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP(), &irqchip_state) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_IRQCHIP, &irqchip_state) };
         if ret == 0 {
             Ok(())
         } else {
@@ -683,7 +681,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IRQ_LINE(), &irq_level) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IRQ_LINE, &irq_level) };
         if ret == 0 {
             Ok(())
         } else {
@@ -700,7 +698,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_CREATE_PIT2(), &pit_config) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_CREATE_PIT2, &pit_config) };
         if ret == 0 {
             Ok(())
         } else {
@@ -718,7 +716,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only write
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_PIT2(), &mut pit_state) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_PIT2, &mut pit_state) };
         if ret == 0 {
             Ok(pit_state)
         } else {
@@ -734,7 +732,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_PIT2(), pit_state) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_PIT2, pit_state) };
         if ret == 0 {
             Ok(())
         } else {
@@ -822,7 +820,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IOEVENTFD(), &ioeventfd) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IOEVENTFD, &ioeventfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -849,7 +847,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD(), &irqfd) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD, &irqfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -873,7 +871,7 @@ impl Vm {
         // SAFETY:
         // Safe because we know that our file is a VM fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD(), &irqfd) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD, &irqfd) };
         if ret == 0 {
             Ok(())
         } else {
@@ -914,7 +912,7 @@ impl Vm {
 
         // TODO(b/315998194): Add safety comment
         #[allow(clippy::undocumented_unsafe_blocks)]
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_GSI_ROUTING(), &irq_routing[0]) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_GSI_ROUTING, &irq_routing[0]) };
         if ret == 0 {
             Ok(())
         } else {
@@ -930,7 +928,7 @@ impl Vm {
     pub unsafe fn kvm_enable_cap(&self, cap: &kvm_enable_cap) -> Result<()> {
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP(), cap);
+        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP, cap);
         if ret < 0 {
             errno_result()
         } else {
@@ -1033,7 +1031,7 @@ pub struct VcpuThread {
     signal_num: Option<c_int>,
 }
 
-thread_local!(static VCPU_THREAD: RefCell<Option<VcpuThread>> = RefCell::new(None));
+thread_local!(static VCPU_THREAD: RefCell<Option<VcpuThread>> = const { RefCell::new(None) });
 
 impl Vcpu {
     /// Constructs a new VCPU for `vm`.
@@ -1044,7 +1042,7 @@ impl Vcpu {
 
         // SAFETY:
         // Safe because we know that vm a VM fd and we verify the return result.
-        let vcpu_fd = unsafe { ioctl_with_val(vm, KVM_CREATE_VCPU(), id) };
+        let vcpu_fd = unsafe { ioctl_with_val(vm, KVM_CREATE_VCPU, id) };
         if vcpu_fd < 0 {
             return errno_result();
         }
@@ -1201,7 +1199,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_REGS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_REGS, &mut regs) };
         if ret != 0 {
             return errno_result();
         }
@@ -1214,7 +1212,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_REGS(), regs) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_REGS, regs) };
         if ret != 0 {
             return errno_result();
         }
@@ -1229,7 +1227,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_SREGS, &mut regs) };
         if ret != 0 {
             return errno_result();
         }
@@ -1242,7 +1240,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only read the
         // correct amount of memory from our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_SREGS(), sregs) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_SREGS, sregs) };
         if ret != 0 {
             return errno_result();
         }
@@ -1257,7 +1255,7 @@ impl Vcpu {
         let mut regs = unsafe { std::mem::zeroed() };
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_FPU(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_FPU, &mut regs) };
         if ret != 0 {
             return errno_result();
         }
@@ -1272,7 +1270,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_fpu struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_FPU(), fpu) }
+            unsafe { ioctl_with_ref(self, KVM_SET_FPU, fpu) }
         };
         if ret < 0 {
             return errno_result();
@@ -1288,7 +1286,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_DEBUGREGS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_DEBUGREGS, &mut regs) };
         if ret != 0 {
             return errno_result();
         }
@@ -1301,7 +1299,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_fpu struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_DEBUGREGS(), dregs) }
+            unsafe { ioctl_with_ref(self, KVM_SET_DEBUGREGS, dregs) }
         };
         if ret < 0 {
             return errno_result();
@@ -1317,7 +1315,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only write the
         // correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_XCRS(), &mut regs) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_XCRS, &mut regs) };
         if ret != 0 {
             return errno_result();
         }
@@ -1330,7 +1328,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_xcrs struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_XCRS(), xcrs) }
+            unsafe { ioctl_with_ref(self, KVM_SET_XCRS, xcrs) }
         };
         if ret < 0 {
             return errno_result();
@@ -1357,7 +1355,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read or write past the end of the kvm_msrs struct.
-            unsafe { ioctl_with_ref(self, KVM_GET_MSRS(), &msrs[0]) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_MSRS, &mut msrs[0]) }
         };
         if ret < 0 {
             // KVM_SET_MSRS actually returns the number of msr entries written.
@@ -1383,7 +1381,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_msrs struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_MSRS(), msrs) }
+            unsafe { ioctl_with_ref(self, KVM_SET_MSRS, msrs) }
         };
         if ret < 0 {
             // KVM_SET_MSRS actually returns the number of msr entries written.
@@ -1400,7 +1398,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // Here we trust the kernel not to read past the end of the kvm_msrs struct.
-            unsafe { ioctl_with_ptr(self, KVM_SET_CPUID2(), cpuid.as_ptr()) }
+            unsafe { ioctl_with_ptr(self, KVM_SET_CPUID2, cpuid.as_ptr()) }
         };
         if ret < 0 {
             return errno_result();
@@ -1419,7 +1417,7 @@ impl Vcpu {
             // ioctl is unsafe. The kernel is trusted not to write beyond the bounds of the memory
             // allocated for the struct. The limit is read from nent, which is set to the allocated
             // size(MAX_KVM_CPUID_ENTRIES) above.
-            unsafe { ioctl_with_mut_ptr(self, KVM_GET_SUPPORTED_HV_CPUID(), cpuid.as_mut_ptr()) }
+            unsafe { ioctl_with_mut_ptr(self, KVM_GET_SUPPORTED_HV_CPUID, cpuid.as_mut_ptr()) }
         };
         if ret < 0 {
             return errno_result();
@@ -1439,7 +1437,7 @@ impl Vcpu {
             // SAFETY:
             // The ioctl is unsafe unless you trust the kernel not to write past the end of the
             // local_apic struct.
-            unsafe { ioctl_with_mut_ref(self, KVM_GET_LAPIC(), &mut klapic) }
+            unsafe { ioctl_with_mut_ref(self, KVM_GET_LAPIC, &mut klapic) }
         };
         if ret < 0 {
             return errno_result();
@@ -1456,7 +1454,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // The ioctl is safe because the kernel will only read from the klapic struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_LAPIC(), klapic) }
+            unsafe { ioctl_with_ref(self, KVM_SET_LAPIC, klapic) }
         };
         if ret < 0 {
             return errno_result();
@@ -1478,7 +1476,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd, we know the kernel will only
         // write correct amount of memory to our pointer, and we verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_MP_STATE(), &mut state) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_MP_STATE, &mut state) };
         if ret < 0 {
             return errno_result();
         }
@@ -1497,7 +1495,7 @@ impl Vcpu {
         let ret = {
             // SAFETY:
             // The ioctl is safe because the kernel will only read from the kvm_mp_state struct.
-            unsafe { ioctl_with_ref(self, KVM_SET_MP_STATE(), state) }
+            unsafe { ioctl_with_ref(self, KVM_SET_MP_STATE, state) }
         };
         if ret < 0 {
             return errno_result();
@@ -1516,7 +1514,7 @@ impl Vcpu {
         // Safe because we know that our file is a VCPU fd, we know the kernel
         // will only write correct amount of memory to our pointer, and we
         // verify the return result.
-        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_VCPU_EVENTS(), &mut events) };
+        let ret = unsafe { ioctl_with_mut_ref(self, KVM_GET_VCPU_EVENTS, &mut events) };
         if ret < 0 {
             return errno_result();
         }
@@ -1532,7 +1530,7 @@ impl Vcpu {
             // SAFETY:
             // The ioctl is safe because the kernel will only read from the
             // kvm_vcpu_events.
-            unsafe { ioctl_with_ref(self, KVM_SET_VCPU_EVENTS(), events) }
+            unsafe { ioctl_with_ref(self, KVM_SET_VCPU_EVENTS, events) }
         };
         if ret < 0 {
             return errno_result();
@@ -1549,7 +1547,7 @@ impl Vcpu {
         // SAFETY:
         // Safe because we allocated the struct and we know the kernel will read exactly the size of
         // the struct.
-        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP(), cap);
+        let ret = ioctl_with_ref(self, KVM_ENABLE_CAP, cap);
         if ret < 0 {
             return errno_result();
         }
@@ -1585,7 +1583,7 @@ impl Vcpu {
             // SAFETY:
             // The ioctl is safe because the kernel will only read from the
             // kvm_signal_mask structure.
-            unsafe { ioctl_with_ref(self, KVM_SET_SIGNAL_MASK(), &kvm_sigmask[0]) }
+            unsafe { ioctl_with_ref(self, KVM_SET_SIGNAL_MASK, &kvm_sigmask[0]) }
         };
         if ret < 0 {
             return errno_result();
@@ -1605,7 +1603,7 @@ impl Vcpu {
         // SAFETY:
         // safe because we allocated the struct and we know the kernel will read
         // exactly the size of the struct
-        let ret = unsafe { ioctl_with_ref(self, KVM_SET_ONE_REG(), &onereg) };
+        let ret = unsafe { ioctl_with_ref(self, KVM_SET_ONE_REG, &onereg) };
         if ret < 0 {
             return errno_result();
         }
@@ -1640,7 +1638,7 @@ impl RunnableVcpu {
     pub fn run(&self) -> Result<VcpuExit> {
         // SAFETY:
         // Safe because we know that our file is a VCPU fd and we verify the return result.
-        let ret = unsafe { ioctl(self, KVM_RUN()) };
+        let ret = unsafe { ioctl(self, KVM_RUN) };
         if ret == 0 {
             // SAFETY:
             // Safe because we know we mapped enough memory to hold the kvm_run struct because the
diff --git a/kvm/tests/dirty_log.rs b/kvm/tests/dirty_log.rs
index 75dfa58b9..23a1b49f3 100644
--- a/kvm/tests/dirty_log.rs
+++ b/kvm/tests/dirty_log.rs
@@ -62,11 +62,9 @@ fn test_run() {
         .expect("failed to register memory");
 
     let runnable_vcpu = vcpu.to_runnable(None).unwrap();
-    loop {
-        match runnable_vcpu.run().expect("run failed") {
-            VcpuExit::Hlt => break,
-            r => panic!("unexpected exit reason: {:?}", r),
-        }
+    let run_result = runnable_vcpu.run().expect("run failed");
+    if !matches!(run_result, VcpuExit::Hlt) {
+        panic!("unexpected exit reason: {:?}", run_result);
     }
 
     let mut dirty_log = [0x0, 0x0];
diff --git a/kvm_sys/Android.bp b/kvm_sys/Android.bp
index e693e6b33..2a25073ee 100644
--- a/kvm_sys/Android.bp
+++ b/kvm_sys/Android.bp
@@ -19,7 +19,7 @@ rust_test {
     crate_name: "basic",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/basic.rs"],
+    crate_root: "tests/basic.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -42,7 +42,7 @@ rust_library {
     crate_name: "kvm_sys",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/kvm_sys/Cargo.toml b/kvm_sys/Cargo.toml
index 8ca49646a..3d79d17e3 100644
--- a/kvm_sys/Cargo.toml
+++ b/kvm_sys/Cargo.toml
@@ -6,6 +6,6 @@ edition = "2021"
 
 [dependencies]
 data_model = { path = "../common/data_model" }
-libc = "*"
+libc = "0.2"
 base = { path = "../base" }
 zerocopy = {version = "0.7", features = ["derive"]}
diff --git a/kvm_sys/bindgen.sh b/kvm_sys/bindgen.sh
index 28dc64399..0b417715e 100755
--- a/kvm_sys/bindgen.sh
+++ b/kvm_sys/bindgen.sh
@@ -39,8 +39,7 @@ pub struct kvm_vfio_iommu_config {
     pub device_fd: i32,
     pub sid_idx: u32,
     pub vsid: u32,
-}
-pub const KVM_PVIOMMU_SET_CONFIG: i32 = 1;"
+}"
 
 X86_64_EXTRAS="
 // This is how zerocopy's author deal with bindings for __BindgenBitfieldUnit<Storage>, see:
diff --git a/kvm_sys/src/aarch64/bindings.rs b/kvm_sys/src/aarch64/bindings.rs
index 43ec6f18d..4790df549 100644
--- a/kvm_sys/src/aarch64/bindings.rs
+++ b/kvm_sys/src/aarch64/bindings.rs
@@ -38,7 +38,6 @@ pub struct kvm_vfio_iommu_config {
     pub sid_idx: u32,
     pub vsid: u32,
 }
-pub const KVM_PVIOMMU_SET_CONFIG: i32 = 1;
 
 #[repr(C)]
 #[derive(Default)]
diff --git a/kvm_sys/src/lib.rs b/kvm_sys/src/lib.rs
index 5d3f1737d..5962d42b9 100644
--- a/kvm_sys/src/lib.rs
+++ b/kvm_sys/src/lib.rs
@@ -13,27 +13,26 @@ use base::ioctl_io_nr;
 use base::ioctl_ior_nr;
 use base::ioctl_iow_nr;
 use base::ioctl_iowr_nr;
-#[cfg(target_arch = "x86_64")]
-use data_model::flexible_array_impl;
-// Each of the below modules defines ioctls specific to their platform.
 
-#[cfg(target_arch = "x86_64")]
-pub const KVM_MSR_FILTER_RANGE_MAX_BITS: usize = 0x2000;
-#[cfg(target_arch = "x86_64")]
-pub const KVM_MSR_FILTER_RANGE_MAX_BYTES: usize = KVM_MSR_FILTER_RANGE_MAX_BITS / 8;
+// Each of the below modules defines ioctls specific to their platform.
+// Along with the common ioctls, we reexport the ioctls of the current
+// platform.
 
 #[cfg(target_arch = "x86_64")]
 pub mod x86 {
-    // generated with bindgen /usr/include/linux/kvm.h --no-unstable-rust --constified-enum '*'
-    // --with-derive-default
-    #[allow(clippy::all)]
     pub mod bindings;
     use base::ioctl_ior_nr;
     use base::ioctl_iow_nr;
     use base::ioctl_iowr_nr;
+    use data_model::flexible_array_impl;
 
     pub use crate::bindings::*;
 
+    flexible_array_impl!(kvm_cpuid2, kvm_cpuid_entry2, nent, entries);
+
+    pub const KVM_MSR_FILTER_RANGE_MAX_BITS: usize = 0x2000;
+    pub const KVM_MSR_FILTER_RANGE_MAX_BYTES: usize = KVM_MSR_FILTER_RANGE_MAX_BITS / 8;
+
     ioctl_iowr_nr!(KVM_GET_MSR_INDEX_LIST, KVMIO, 0x02, kvm_msr_list);
     ioctl_iowr_nr!(KVM_GET_SUPPORTED_CPUID, KVMIO, 0x05, kvm_cpuid2);
     ioctl_iowr_nr!(KVM_GET_EMULATED_CPUID, KVMIO, 0x09, kvm_cpuid2);
@@ -59,28 +58,44 @@ pub mod x86 {
     ioctl_ior_nr!(KVM_GET_XCRS, KVMIO, 0xa6, kvm_xcrs);
     ioctl_iow_nr!(KVM_SET_XCRS, KVMIO, 0xa7, kvm_xcrs);
     ioctl_iowr_nr!(KVM_GET_SUPPORTED_HV_CPUID, KVMIO, 0xc1, kvm_cpuid2);
+    ioctl_iow_nr!(KVM_X86_SET_MSR_FILTER, KVMIO, 0xc6, kvm_msr_filter);
     ioctl_ior_nr!(KVM_GET_XSAVE2, KVMIO, 0xcf, kvm_xsave);
 }
+#[cfg(target_arch = "x86_64")]
+pub use crate::x86::*;
 
 #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
 pub mod aarch64 {
-    // generated with bindgen <arm sysroot>/usr/include/linux/kvm.h --no-unstable-rust
-    // --constified-enum '*' --with-derive-default -- -I<arm sysroot>/usr/include
     pub mod bindings;
     use base::ioctl_ior_nr;
     use base::ioctl_iow_nr;
+    #[cfg(target_os = "android")]
+    use base::ioctl_iowr_nr;
     pub use bindings::*;
 
     ioctl_iow_nr!(KVM_ARM_SET_DEVICE_ADDR, KVMIO, 0xab, kvm_arm_device_addr);
     ioctl_iow_nr!(KVM_ARM_VCPU_INIT, KVMIO, 0xae, kvm_vcpu_init);
     ioctl_ior_nr!(KVM_ARM_PREFERRED_TARGET, KVMIO, 0xaf, kvm_vcpu_init);
+    ioctl_iow_nr!(
+        KVM_ARM_SET_COUNTER_OFFSET,
+        KVMIO,
+        0xb5,
+        kvm_arm_counter_offset
+    );
+
+    #[cfg(target_os = "android")]
+    ioctl_iowr_nr!(KVM_PVIOMMU_SET_CONFIG, KVMIO, 0x1, kvm_vfio_iommu_config);
 }
+#[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
+pub use crate::aarch64::*;
 
 #[cfg(target_arch = "riscv64")]
 pub mod riscv64 {
     pub mod bindings;
     pub use bindings::*;
 }
+#[cfg(target_arch = "riscv64")]
+pub use crate::riscv64::*;
 
 // These ioctls are commonly defined on all/multiple platforms.
 ioctl_io_nr!(KVM_GET_API_VERSION, KVMIO, 0x00);
@@ -145,11 +160,7 @@ ioctl_iow_nr!(KVM_SET_DEVICE_ATTR, KVMIO, 0xe1, kvm_device_attr);
 ioctl_iow_nr!(KVM_GET_DEVICE_ATTR, KVMIO, 0xe2, kvm_device_attr);
 ioctl_iow_nr!(KVM_HAS_DEVICE_ATTR, KVMIO, 0xe3, kvm_device_attr);
 ioctl_io_nr!(KVM_RUN, KVMIO, 0x80);
-// The following two ioctls are commonly defined but specifically excluded
-// from arm platforms.
-#[cfg(not(any(target_arch = "arm", target_arch = "aarch64")))]
 ioctl_ior_nr!(KVM_GET_REGS, KVMIO, 0x81, kvm_regs);
-#[cfg(not(any(target_arch = "arm", target_arch = "aarch64")))]
 ioctl_iow_nr!(KVM_SET_REGS, KVMIO, 0x82, kvm_regs);
 ioctl_ior_nr!(KVM_GET_SREGS, KVMIO, 0x83, kvm_sregs);
 ioctl_iow_nr!(KVM_SET_SREGS, KVMIO, 0x84, kvm_sregs);
@@ -171,20 +182,3 @@ ioctl_iow_nr!(KVM_SET_ONE_REG, KVMIO, 0xac, kvm_one_reg);
 ioctl_io_nr!(KVM_KVMCLOCK_CTRL, KVMIO, 0xad);
 ioctl_iowr_nr!(KVM_GET_REG_LIST, KVMIO, 0xb0, kvm_reg_list);
 ioctl_io_nr!(KVM_SMI, KVMIO, 0xb7);
-#[cfg(target_arch = "x86_64")]
-ioctl_iow_nr!(KVM_X86_SET_MSR_FILTER, KVMIO, 0xc6, kvm_msr_filter);
-
-// Along with the common ioctls, we reexport the ioctls of the current
-// platform.
-
-#[cfg(target_arch = "x86_64")]
-pub use crate::x86::*;
-
-#[cfg(target_arch = "x86_64")]
-flexible_array_impl!(kvm_cpuid2, kvm_cpuid_entry2, nent, entries);
-
-#[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
-pub use aarch64::*;
-
-#[cfg(target_arch = "riscv64")]
-pub use crate::riscv64::*;
diff --git a/kvm_sys/tests/basic.rs b/kvm_sys/tests/basic.rs
index 1c2ac910f..69af95357 100644
--- a/kvm_sys/tests/basic.rs
+++ b/kvm_sys/tests/basic.rs
@@ -19,7 +19,7 @@ fn get_version() {
     assert!(sys_fd >= 0);
 
     // SAFETY: sys_fd is expected to be valid and return value is checked.
-    let ret = unsafe { ioctl(sys_fd, KVM_GET_API_VERSION(), 0) };
+    let ret = unsafe { ioctl(sys_fd, KVM_GET_API_VERSION, 0) };
     assert_eq!(ret as u32, KVM_API_VERSION);
 }
 
@@ -30,7 +30,7 @@ fn create_vm_fd() {
     assert!(sys_fd >= 0);
 
     // SAFETY: sys_fd is expected to be valid and return value is checked.
-    let vm_fd = unsafe { ioctl(sys_fd, KVM_CREATE_VM(), 0) };
+    let vm_fd = unsafe { ioctl(sys_fd, KVM_CREATE_VM, 0) };
     assert!(vm_fd >= 0);
 }
 
@@ -41,6 +41,6 @@ fn check_vm_extension() {
     assert!(sys_fd >= 0);
 
     // SAFETY: sys_fd is expected to be valid and return value is checked.
-    let has_user_memory = unsafe { ioctl(sys_fd, KVM_CHECK_EXTENSION(), KVM_CAP_USER_MEMORY) };
+    let has_user_memory = unsafe { ioctl(sys_fd, KVM_CHECK_EXTENSION, KVM_CAP_USER_MEMORY) };
     assert_eq!(has_user_memory, 1);
 }
diff --git a/libcras_stub/Android.bp b/libcras_stub/Android.bp
index dd00bdabb..fa7197ac1 100644
--- a/libcras_stub/Android.bp
+++ b/libcras_stub/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "libcras",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/libcras.rs"],
+    crate_root: "src/libcras.rs",
     edition: "2021",
     rustlibs: [
         "libaudio_streams",
diff --git a/libcras_stub/Cargo.toml b/libcras_stub/Cargo.toml
index 4962cd164..80d0e5743 100644
--- a/libcras_stub/Cargo.toml
+++ b/libcras_stub/Cargo.toml
@@ -9,4 +9,4 @@ path = "src/libcras.rs"
 
 [dependencies]
 audio_streams = "*"
-serde = "*"
+serde = "1"
diff --git a/linux_input_sys/Android.bp b/linux_input_sys/Android.bp
index 44ee82c5a..e649e0dd5 100644
--- a/linux_input_sys/Android.bp
+++ b/linux_input_sys/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "linux_input_sys",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/linux_input_sys/Cargo.toml b/linux_input_sys/Cargo.toml
index 1e856f71b..6036868c7 100644
--- a/linux_input_sys/Cargo.toml
+++ b/linux_input_sys/Cargo.toml
@@ -6,6 +6,6 @@ edition = "2021"
 
 [dependencies]
 data_model = { path = "../common/data_model" }
-libc = "*"
+libc = "0.2"
 base = { path = "../base" }
 zerocopy = { version = "0.7", features = ["derive"] }
diff --git a/media/ffmpeg/Cargo.toml b/media/ffmpeg/Cargo.toml
index ccc247f18..213d60a5f 100644
--- a/media/ffmpeg/Cargo.toml
+++ b/media/ffmpeg/Cargo.toml
@@ -5,10 +5,10 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
-libc = "*"
-thiserror = "*"
+anyhow = "1"
+libc = "0.2"
+thiserror = "1"
 
 [build-dependencies]
 bindgen = "0.63"
-pkg-config = "*"
+pkg-config = "0.3"
diff --git a/media/ffmpeg/build.rs b/media/ffmpeg/build.rs
index 571b56b26..3e081ea95 100644
--- a/media/ffmpeg/build.rs
+++ b/media/ffmpeg/build.rs
@@ -17,6 +17,11 @@ fn main() {
         return;
     }
 
+    // ffmgeg is not supported by CI on 32-bit arm
+    if std::env::var("CARGO_CFG_TARGET_ARCH").unwrap() == "arm" {
+        return;
+    }
+
     // Match all ffmpeg 6.0+ versions.
     Config::new()
         .atleast_version("60")
diff --git a/media/ffmpeg/src/lib.rs b/media/ffmpeg/src/lib.rs
index 4d327e994..673e62ae1 100644
--- a/media/ffmpeg/src/lib.rs
+++ b/media/ffmpeg/src/lib.rs
@@ -2,7 +2,10 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-#![cfg(any(target_os = "android", target_os = "linux"))]
+#![cfg(all(
+    any(target_os = "android", target_os = "linux"),
+    not(target_arch = "arm")
+))]
 
 pub mod avcodec;
 mod avutil;
@@ -18,6 +21,9 @@ mod ffi {
     #![allow(non_snake_case)]
     #![allow(dead_code)]
     include!(concat!(env!("OUT_DIR"), "/bindings.rs"));
+
+    /// SAFETY: `AVCodec` instances are all static and thus safe to share.
+    unsafe impl Sync for AVCodec {}
 }
 pub mod swscale;
 
diff --git a/media/ffmpeg/src/swscale.rs b/media/ffmpeg/src/swscale.rs
index a0103dc3c..e3e72edf4 100644
--- a/media/ffmpeg/src/swscale.rs
+++ b/media/ffmpeg/src/swscale.rs
@@ -10,6 +10,7 @@ use thiserror::Error as ThisError;
 
 use crate::avcodec::AvError;
 use crate::avcodec::AvFrame;
+use crate::avcodec::Dimensions;
 use crate::ffi;
 
 /// A struct able to copy a decoded `AvFrame` into an `OutputBuffer`'s memory, converting the pixel
@@ -27,8 +28,8 @@ pub enum ConversionError {
         frame: ffi::AVPixelFormat,
         converter: ffi::AVPixelFormat,
     },
-    #[error("source AvFrame's dimension does not match destination's")]
-    DimensionMismatch,
+    #[error("source AvFrame's dimension {0:?} does not match destination's {1:?}")]
+    DimensionMismatch(Dimensions, Dimensions),
     #[error("destination AvFrame needs to be refcounted with refcount=1")]
     NotWritable,
     #[error("error during conversion with libswscale: {0}")]
@@ -107,7 +108,10 @@ impl SwConverter {
         }
 
         if src.dimensions() != dst.dimensions() {
-            return Err(ConversionError::DimensionMismatch);
+            return Err(ConversionError::DimensionMismatch(
+                src.dimensions(),
+                dst.dimensions(),
+            ));
         }
 
         if !dst.is_writable() {
diff --git a/media/libvda/Cargo.toml b/media/libvda/Cargo.toml
index afb8f5ffe..272867849 100644
--- a/media/libvda/Cargo.toml
+++ b/media/libvda/Cargo.toml
@@ -10,7 +10,7 @@ libvda-stub = []
 
 [dependencies]
 enumn = "0.1.0"
-libc = "*"
+libc = "0.2"
 
 [build-dependencies]
-pkg-config = "*"
+pkg-config = "0.3"
diff --git a/media/libvda/README.md b/media/libvda/README.md
index 94206a239..e02d96bf9 100644
--- a/media/libvda/README.md
+++ b/media/libvda/README.md
@@ -1,7 +1,7 @@
 # Libvda Rust wrapper
 
 Note: This crate is specific to ChromeOS and requires the native
-(libvda)\[https://source.chromium.org/chromiumos/chromiumos/codesearch/+/main:src/platform2/arc/vm/libvda\]
+[libvda](https://source.chromium.org/chromiumos/chromiumos/codesearch/+/main:src/platform2/arc/vm/libvda)
 library at link time.
 
 Rust wrapper for libvda. This library is used to enable communication with Chrome's GPU process to
diff --git a/metrics/Android.bp b/metrics/Android.bp
index 275ec22f8..2d1f08749 100644
--- a/metrics/Android.bp
+++ b/metrics/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "metrics",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
@@ -40,7 +40,7 @@ rust_test {
     crate_name: "metrics",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/metrics/Cargo.toml b/metrics/Cargo.toml
index 078509cdd..139bacea1 100644
--- a/metrics/Cargo.toml
+++ b/metrics/Cargo.toml
@@ -4,10 +4,14 @@ version = "0.1.0"
 authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
+[features]
+collect = []
+experimental = []
+
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 base = { path = "../base" }
-cfg-if = "*"
+cfg-if = "1"
 serde = { version = "1", features = ["derive"] }
 sync = { path = "../common/sync" }
 metrics_events = { path = "../metrics_events" }
@@ -15,4 +19,4 @@ metrics_product = { path = "../vendor/generic/metrics", package = "metrics_gener
 
 [target.'cfg(windows)'.dependencies]
 chrono = { version = "0.4.34", default-features = false, features = ["now"] }
-winapi = { version = "*" }
+winapi = { version = "0.3" }
diff --git a/metrics/src/local_stats.rs b/metrics/src/local_stats.rs
index 9f6601cb2..3b32ed6e2 100644
--- a/metrics/src/local_stats.rs
+++ b/metrics/src/local_stats.rs
@@ -571,9 +571,9 @@ mod tests {
             simple_stats.add(v);
         }
 
-        bucket_check(histogram.buckets.get(0).unwrap(), &[0, 9, 5]);
-        bucket_check(histogram.buckets.get(1).unwrap(), &[20, 50]);
-        bucket_check(histogram.buckets.get(2).unwrap(), &[199, 120]);
+        bucket_check(&histogram.buckets[0], &[0, 9, 5]);
+        bucket_check(&histogram.buckets[1], &[20, 50]);
+        bucket_check(&histogram.buckets[2], &[199, 120]);
         assert_eq!(histogram.buckets.len(), 3);
         assert_eq!(histogram.simple_stat(), simple_stats);
         assert_eq!(histogram.values, None);
@@ -592,16 +592,19 @@ mod tests {
             simple_stats.add(v);
         }
 
-        bucket_check(histogram.buckets.get(1).unwrap(), &[4, 9, 5]);
-        bucket_check(histogram.buckets.get(2).unwrap(), &[20, 50]);
-        bucket_check(histogram.buckets.get(3).unwrap(), &[199, 120]);
+        bucket_check(&histogram.buckets[1], &[4, 9, 5]);
+        bucket_check(&histogram.buckets[2], &[20, 50]);
+        bucket_check(&histogram.buckets[3], &[199, 120]);
         assert_eq!(histogram.buckets.len(), 5);
         assert_eq!(histogram.simple_stat(), simple_stats);
         assert_eq!(histogram.values, None);
     }
 
+    #[cfg(feature = "experimental")]
     #[derive(Clone, Debug, PartialEq)]
     struct MyDetails(u64, u64);
+
+    #[cfg(feature = "experimental")]
     impl Details<u64> for MyDetails {
         fn value(&self) -> u64 {
             self.1 - self.0
@@ -637,9 +640,9 @@ mod tests {
             histogram.add(v.clone()).unwrap();
         }
 
-        bucket_check(histogram.buckets.get(0).unwrap(), &[4, 9, 5]);
-        bucket_check(histogram.buckets.get(1).unwrap(), &[20, 50]);
-        bucket_check(histogram.buckets.get(2).unwrap(), &[199, 120]);
+        bucket_check(histogram.buckets[0], &[4, 9, 5]);
+        bucket_check(histogram.buckets[1], &[20, 50]);
+        bucket_check(histogram.buckets[2], &[199, 120]);
         assert_eq!(histogram.buckets.len(), 3);
         assert_eq!(histogram.simple_stat(), simple_stats);
         assert_eq!(histogram.values, Some(values));
@@ -661,11 +664,11 @@ mod tests {
             histogram.add(v.clone()).unwrap();
         }
 
-        bucket_check(histogram.buckets.get(0).unwrap(), &[]);
-        bucket_check(histogram.buckets.get(4).unwrap(), &[]);
-        bucket_check(histogram.buckets.get(1).unwrap(), &[4, 9, 5]);
-        bucket_check(histogram.buckets.get(2).unwrap(), &[20, 50]);
-        bucket_check(histogram.buckets.get(3).unwrap(), &[199, 120]);
+        bucket_check(histogram.buckets[0], &[]);
+        bucket_check(histogram.buckets[4], &[]);
+        bucket_check(histogram.buckets[1], &[4, 9, 5]);
+        bucket_check(histogram.buckets[2], &[20, 50]);
+        bucket_check(histogram.buckets[3], &[199, 120]);
         assert_eq!(histogram.buckets.len(), 5);
         assert_eq!(histogram.simple_stat(), simple_stats);
         assert_eq!(histogram.values, Some(values));
diff --git a/metrics_events/Android.bp b/metrics_events/Android.bp
index 87a087eb8..35784bcc0 100644
--- a/metrics_events/Android.bp
+++ b/metrics_events/Android.bp
@@ -14,7 +14,7 @@ rust_library {
     crate_name: "metrics_events",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/metrics_events/Cargo.toml b/metrics_events/Cargo.toml
index 498b09a71..fddca78f0 100644
--- a/metrics_events/Cargo.toml
+++ b/metrics_events/Cargo.toml
@@ -5,8 +5,8 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
-cfg-if = "*"
+anyhow = "1"
+cfg-if = "1"
 serde = { version = "1", features = ["derive"] }
 metrics_events_product = { path = "../vendor/generic/metrics_events", package = "metrics_events_generic" }
 
diff --git a/metrics_events/src/event_types.rs b/metrics_events/src/event_types.rs
index f1fde88c4..c67523e49 100644
--- a/metrics_events/src/event_types.rs
+++ b/metrics_events/src/event_types.rs
@@ -49,6 +49,7 @@ pub enum MetricEventType {
     VirtioWakeup {
         virtio_id: u32,
     },
+    VcpuShutdownError,
     Other(i64),
     Vendor(VendorMetricEventType),
 }
diff --git a/net_sys/Android.bp b/net_sys/Android.bp
index be808c61f..e92a9b000 100644
--- a/net_sys/Android.bp
+++ b/net_sys/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "net_sys",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/net_sys/Cargo.toml b/net_sys/Cargo.toml
index afcb57825..29cf2b5f6 100644
--- a/net_sys/Cargo.toml
+++ b/net_sys/Cargo.toml
@@ -6,4 +6,4 @@ edition = "2021"
 
 [dependencies]
 base = { path = "../base" }
-libc = "*"
+libc = "0.2"
diff --git a/net_util/Android.bp b/net_util/Android.bp
index af80e9383..6fca166cf 100644
--- a/net_util/Android.bp
+++ b/net_util/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "net_util",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
@@ -43,7 +43,7 @@ rust_test {
     crate_name: "net_util",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -73,7 +73,7 @@ rust_test {
     crate_name: "unix_tap",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/unix_tap.rs"],
+    crate_root: "tests/unix_tap.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/net_util/Cargo.toml b/net_util/Cargo.toml
index 17902a9ee..3d11c4145 100644
--- a/net_util/Cargo.toml
+++ b/net_util/Cargo.toml
@@ -15,12 +15,12 @@ slirp-ring-capture = ["slirp"]
 base = { path = "../base" }
 cfg-if = "1.0.0"
 cros_async = { path = "../cros_async" }
-libc = "*"
+libc = "0.2"
 pcap-file = { version = "1.1.0", optional = true }
-remain = "*"
+remain = "0.2"
 serde = { version = "1", features = [ "derive" ] }
-smallvec = "*"
-thiserror = "*"
+smallvec = "1"
+thiserror = "1"
 virtio_sys = { path = "../virtio_sys" }
 zerocopy = { version = "0.7", features = ["derive"] }
 
@@ -29,12 +29,12 @@ net_sys = { path = "../net_sys" }
 
 [target.'cfg(windows)'.dependencies]
 metrics = { path = "../metrics" }
-winapi = { version = "*", features = ["everything", "std", "impl-default"] }
+winapi = { version = "0.3", features = ["everything", "std", "impl-default"] }
 libslirp-sys = { version = "4.2.1", optional = true }
 
 [build-dependencies]
-anyhow = "*"
+anyhow = "1"
 prebuilts = { path = "../prebuilts" }
 
 [dev-dependencies]
-serde_json = "*"
+serde_json = "1"
diff --git a/net_util/src/slirp/sys/windows/handler.rs b/net_util/src/slirp/sys/windows/handler.rs
index c656b8e84..9ac679a6e 100644
--- a/net_util/src/slirp/sys/windows/handler.rs
+++ b/net_util/src/slirp/sys/windows/handler.rs
@@ -183,7 +183,7 @@ impl CallbackHandler for Handler {
             - Duration::from_nanos(self.clock_get_ns() as u64);
 
         timer
-            .reset(timer_duration, None)
+            .reset_oneshot(timer_duration)
             .expect("failed to modify network timer");
     }
 
diff --git a/net_util/src/sys/linux/tap.rs b/net_util/src/sys/linux/tap.rs
index a5b804604..cf707c1be 100644
--- a/net_util/src/sys/linux/tap.rs
+++ b/net_util/src/sys/linux/tap.rs
@@ -62,7 +62,7 @@ impl Tap {
 
         // Get the interface name since we will need it for some ioctls.
         let mut ifreq: net_sys::ifreq = Default::default();
-        let ret = ioctl_with_mut_ref(&tap_file, net_sys::TUNGETIFF(), &mut ifreq);
+        let ret = ioctl_with_mut_ref(&tap_file, net_sys::TUNGETIFF, &mut ifreq);
 
         if ret < 0 {
             return Err(Error::IoctlError(SysError::last()));
@@ -95,7 +95,7 @@ impl Tap {
         // SAFETY:
         // ioctl is safe since we call it with a valid tap fd and check the return
         // value.
-        let ret = unsafe { ioctl_with_mut_ref(&tuntap, net_sys::TUNSETIFF(), ifreq) };
+        let ret = unsafe { ioctl_with_mut_ref(&tuntap, net_sys::TUNSETIFF, ifreq) };
 
         if ret < 0 {
             return Err(Error::CreateTap(SysError::last()));
@@ -389,7 +389,7 @@ impl TapTCommon for Tap {
         let ret =
         // SAFETY:
         // ioctl is safe. Called with a valid tap descriptor, and we check the return.
-            unsafe { ioctl_with_val(&self.tap_file, net_sys::TUNSETOFFLOAD(), flags as c_ulong) };
+            unsafe { ioctl_with_val(&self.tap_file, net_sys::TUNSETOFFLOAD, flags as c_ulong) };
         if ret < 0 {
             return Err(Error::IoctlError(SysError::last()));
         }
@@ -431,7 +431,7 @@ impl TapTLinux for Tap {
         let size = size as c_int;
         // SAFETY:
         // ioctl is safe. Called with a valid tap descriptor, and we check the return.
-        let ret = unsafe { ioctl_with_ref(&self.tap_file, net_sys::TUNSETVNETHDRSZ(), &size) };
+        let ret = unsafe { ioctl_with_ref(&self.tap_file, net_sys::TUNSETVNETHDRSZ, &size) };
         if ret < 0 {
             return Err(Error::IoctlError(SysError::last()));
         }
diff --git a/perfetto/Cargo.toml b/perfetto/Cargo.toml
index 13b052bd7..f4ac3824d 100644
--- a/perfetto/Cargo.toml
+++ b/perfetto/Cargo.toml
@@ -13,14 +13,14 @@ default = ["openssl"]
 pure-rust-hashes = ["sha2"]
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 base = { path = "../base" }
 cfg-if = "1.0.0"
 cros_tracing_types = { path = "../cros_tracing_types" }
-openssl = { version = "*", optional = true }
+openssl = { version = "0.10", optional = true }
 protobuf = "3.2"
 serde = { version = "1", features = [ "derive" ] }
-sha2 = { version = "*", optional = true }
+sha2 = { version = "0.10", optional = true }
 sync = { path = "../common/sync" }
 zerocopy = { version = "0.7", features = ["derive"] }
 
diff --git a/power_monitor/Android.bp b/power_monitor/Android.bp
index 6dad7a4c2..dd5547d9d 100644
--- a/power_monitor/Android.bp
+++ b/power_monitor/Android.bp
@@ -26,15 +26,15 @@ rust_library {
     crate_name: "power_monitor",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: [
-        "src/lib.rs",
-        ":copy_power_monitor_build_out",
-    ],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
         "libprotobuf",
         "libthiserror",
     ],
+    srcs: [
+        ":copy_power_monitor_build_out",
+    ],
     proc_macros: ["libremain"],
 }
diff --git a/power_monitor/patches/Android.bp.patch b/power_monitor/patches/Android.bp.patch
new file mode 100644
index 000000000..ad701c224
--- /dev/null
+++ b/power_monitor/patches/Android.bp.patch
@@ -0,0 +1,27 @@
+diff --git a/power_monitor/Android.bp b/power_monitor/Android.bp
+index 524ba3aaa..dd5547d9d 100644
+--- a/power_monitor/Android.bp
++++ b/power_monitor/Android.bp
+@@ -12,6 +12,13 @@ package {
+     default_applicable_licenses: ["external_crosvm_license"],
+ }
+ 
++genrule {
++    name: "copy_power_monitor_build_out",
++    srcs: ["out/*"],
++    cmd: "cp $(in) $(genDir)",
++    out: ["generated.rs"],
++}
++
+ rust_library {
+     name: "libpower_monitor",
+     defaults: ["crosvm_inner_defaults"],
+@@ -26,5 +33,8 @@ rust_library {
+         "libprotobuf",
+         "libthiserror",
+     ],
++    srcs: [
++        ":copy_power_monitor_build_out",
++    ],
+     proc_macros: ["libremain"],
+ }
diff --git a/prebuilts/Cargo.toml b/prebuilts/Cargo.toml
index 13e703c9d..f322ac80d 100644
--- a/prebuilts/Cargo.toml
+++ b/prebuilts/Cargo.toml
@@ -5,6 +5,6 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
-cfg-if = "*"
+anyhow = "1"
+cfg-if = "1"
 named-lock = "0.3"
diff --git a/protos/Android.bp b/protos/Android.bp
index 3c72b0e76..61b635751 100644
--- a/protos/Android.bp
+++ b/protos/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "protos",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "composite-disk",
diff --git a/resources/Android.bp b/resources/Android.bp
index a7c7354d6..78932b874 100644
--- a/resources/Android.bp
+++ b/resources/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "resources",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
@@ -37,7 +37,7 @@ rust_test {
     crate_name: "resources",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/resources/Cargo.toml b/resources/Cargo.toml
index f6d874a77..583980929 100644
--- a/resources/Cargo.toml
+++ b/resources/Cargo.toml
@@ -5,8 +5,8 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dependencies]
-libc = "*"
+libc = "0.2"
 base = { path = "../base" }
 serde = { version = "1", features = ["derive"] }
-remain = "*"
-thiserror = "*"
+remain = "0.2"
+thiserror = "1"
diff --git a/resources/src/system_allocator.rs b/resources/src/system_allocator.rs
index 4e11a98f5..ac3729f54 100644
--- a/resources/src/system_allocator.rs
+++ b/resources/src/system_allocator.rs
@@ -2,6 +2,7 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
+use std::collections::btree_map;
 use std::collections::BTreeMap;
 
 use base::pagesize;
@@ -270,36 +271,34 @@ impl SystemAllocator {
     }
 
     fn get_pci_allocator_mut(&mut self, bus: u8) -> Option<&mut AddressAllocator> {
-        // pci root is 00:00.0, Bus 0 next device is 00:01.0 with mandatory function
-        // number zero.
-        if self.pci_allocator.get(&bus).is_none() {
-            let base = if bus == 0 { 8 } else { 0 };
-
-            // Each bus supports up to 32 (devices) x 8 (functions).
-            // Prefer allocating at device granularity (preferred_align = 8), but fall back to
-            // allocating individual functions (min_align = 1) when we run out of devices.
-            match AddressAllocator::new(
-                AddressRange {
-                    start: base,
-                    end: (32 * 8) - 1,
-                },
-                Some(1),
-                Some(8),
-            ) {
-                Ok(v) => self.pci_allocator.insert(bus, v),
-                Err(_) => return None,
-            };
+        match self.pci_allocator.entry(bus) {
+            btree_map::Entry::Occupied(entry) => Some(entry.into_mut()),
+            btree_map::Entry::Vacant(entry) => {
+                // pci root is 00:00.0, Bus 0 next device is 00:01.0 with mandatory function number
+                // zero.
+                let base = if bus == 0 { 8 } else { 0 };
+
+                // Each bus supports up to 32 (devices) x 8 (functions).
+                // Prefer allocating at device granularity (preferred_align = 8), but fall back to
+                // allocating individual functions (min_align = 1) when we run out of devices.
+                let pci_alloc = AddressAllocator::new(
+                    AddressRange {
+                        start: base,
+                        end: (32 * 8) - 1,
+                    },
+                    Some(1),
+                    Some(8),
+                )
+                .ok()?;
+
+                Some(entry.insert(pci_alloc))
+            }
         }
-        self.pci_allocator.get_mut(&bus)
     }
 
     // Check whether devices exist or not on the specified bus
     pub fn pci_bus_empty(&self, bus: u8) -> bool {
-        if self.pci_allocator.get(&bus).is_none() {
-            true
-        } else {
-            false
-        }
+        !self.pci_allocator.contains_key(&bus)
     }
 
     /// Allocate PCI slot location.
diff --git a/riscv64/Android.bp b/riscv64/Android.bp
index d964f7925..366a1bd32 100644
--- a/riscv64/Android.bp
+++ b/riscv64/Android.bp
@@ -14,7 +14,7 @@ rust_library {
     crate_name: "riscv64",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "gdb",
@@ -30,8 +30,6 @@ rust_library {
         "libgdbstub_arch",
         "libhypervisor",
         "libkernel_cmdline",
-        "libkvm",
-        "libkvm_sys",
         "liblibc",
         "libminijail_rust",
         "librand",
diff --git a/riscv64/Cargo.toml b/riscv64/Cargo.toml
index b7255df1f..4ee165431 100644
--- a/riscv64/Cargo.toml
+++ b/riscv64/Cargo.toml
@@ -5,7 +5,7 @@ authors = ["Rivos Inc."]
 edition = "2021"
 
 [features]
-gdb = ["gdbstub", "gdbstub_arch", "arch/gdb", "hypervisor/gdb"]
+gdb = ["gdbstub", "gdbstub_arch", "arch/gdb"]
 
 [dependencies]
 arch = { path = "../arch" }
@@ -15,14 +15,12 @@ gdbstub = { version = "0.7.0", optional = true }
 gdbstub_arch = { version = "0.3.0", optional = true }
 hypervisor = { path = "../hypervisor" }
 kernel_cmdline = { path = "../kernel_cmdline" }
-kvm = { path = "../kvm" }
-kvm_sys = { path = "../kvm_sys" }
-libc = "*"
+libc = "0.2"
 rand = "0.8"
-remain = "*"
+remain = "0.2"
 resources = { path = "../resources" }
 sync = { path = "../common/sync" }
-thiserror = "*"
+thiserror = "1"
 base = { path = "../base" }
 vm_control = { path = "../vm_control" }
 vm_memory = { path = "../vm_memory" }
diff --git a/riscv64/src/lib.rs b/riscv64/src/lib.rs
index 8472b9664..24aae8b34 100644
--- a/riscv64/src/lib.rs
+++ b/riscv64/src/lib.rs
@@ -15,12 +15,14 @@ use std::sync::Arc;
 use arch::get_serial_cmdline;
 use arch::CpuSet;
 use arch::DtbOverlay;
+use arch::FdtPosition;
 use arch::GetSerialCmdlineError;
 use arch::RunnableLinuxVm;
 use arch::VmComponents;
 use arch::VmImage;
 use base::Event;
 use base::SendTube;
+use base::Tube;
 use devices::serial_device::SerialHardware;
 use devices::serial_device::SerialParameters;
 use devices::Bus;
@@ -54,7 +56,6 @@ use remain::sorted;
 use resources::AddressRange;
 use resources::SystemAllocator;
 use resources::SystemAllocatorConfig;
-#[cfg(any(target_os = "android", target_os = "linux"))]
 use sync::Condvar;
 use sync::Mutex;
 use thiserror::Error;
@@ -71,6 +72,9 @@ const RISCV64_KERNEL_OFFSET: u64 = 0x20_0000;
 const RISCV64_INITRD_ALIGN: u64 = 8;
 const RISCV64_FDT_ALIGN: u64 = 0x40_0000;
 
+// Maximum Linux riscv kernel command line size (arch/riscv/include/uapi/asm/setup.h).
+const RISCV64_CMDLINE_MAX_SIZE: usize = 1024;
+
 // This indicates the start of DRAM inside the physical address space.
 const RISCV64_PHYS_MEM_START: u64 = 0x8000_0000;
 
@@ -191,10 +195,9 @@ impl arch::LinuxArch for Riscv64 {
         _dump_device_tree_blob: Option<PathBuf>,
         _debugcon_jail: Option<Minijail>,
         #[cfg(feature = "swap")] swap_controller: &mut Option<swap::SwapController>,
-        #[cfg(any(target_os = "android", target_os = "linux"))] _guest_suspended_cvar: Option<
-            Arc<(Mutex<bool>, Condvar)>,
-        >,
+        _guest_suspended_cvar: Option<Arc<(Mutex<bool>, Condvar)>>,
         device_tree_overlays: Vec<DtbOverlay>,
+        fdt_position: Option<FdtPosition>,
     ) -> std::result::Result<RunnableLinuxVm<V, Vcpu>, Self::Error>
     where
         V: VmRiscv64,
@@ -292,7 +295,7 @@ impl arch::LinuxArch for Riscv64 {
         }
 
         // Event used by PMDevice to notify crosvm that guest OS is trying to suspend.
-        let suspend_evt = Event::new().map_err(Error::CreateEvent)?;
+        let (suspend_tube_send, suspend_tube_recv) = Tube::directional_pair().unwrap();
 
         // separate out image loading from other setup to get a specific error for
         // image loading
@@ -302,9 +305,8 @@ impl arch::LinuxArch for Riscv64 {
                 return Err(Error::ImageTypeUnsupported);
             }
             VmImage::Kernel(ref mut kernel_image) => {
-                let kernel_size =
-                    arch::load_image(&mem, kernel_image, get_kernel_addr(), u64::max_value())
-                        .map_err(Error::KernelLoadFailure)?;
+                let kernel_size = arch::load_image(&mem, kernel_image, get_kernel_addr(), u64::MAX)
+                    .map_err(Error::KernelLoadFailure)?;
                 let kernel_end = get_kernel_addr().offset() + kernel_size as u64;
                 initrd = match components.initrd_image {
                     Some(initrd_file) => {
@@ -366,6 +368,10 @@ impl arch::LinuxArch for Riscv64 {
             })
             .collect();
 
+        assert!(
+            matches!(fdt_position, None | Some(FdtPosition::AfterPayload)),
+            "fdt_position={fdt_position:?} not supported"
+        );
         let fdt_offset = (kernel_initrd_end + (RISCV64_FDT_ALIGN - 1)) & !(RISCV64_FDT_ALIGN - 1);
 
         let timebase_freq: u32 = vcpus[0]
@@ -385,7 +391,9 @@ impl arch::LinuxArch for Riscv64 {
             fdt_offset,
             aia_num_ids,
             aia_num_sources,
-            cmdline.as_str(),
+            cmdline
+                .as_str_with_max_len(RISCV64_CMDLINE_MAX_SIZE - 1)
+                .map_err(Error::Cmdline)?,
             initrd,
             timebase_freq,
             device_tree_overlays,
@@ -414,13 +422,13 @@ impl arch::LinuxArch for Riscv64 {
             hotplug_bus: BTreeMap::new(),
             rt_cpus: components.rt_cpus,
             delay_rt: components.delay_rt,
-            suspend_evt,
+            suspend_tube: (Arc::new(Mutex::new(suspend_tube_send)), suspend_tube_recv),
             bat_control: None,
             #[cfg(feature = "gdb")]
             gdb: components.gdb,
             pm: None,
             devices_thread: None,
-            vm_request_tube: None,
+            vm_request_tubes: Vec::new(),
         })
     }
 
@@ -463,6 +471,10 @@ impl arch::LinuxArch for Riscv64 {
         Ok(BTreeMap::new())
     }
 
+    fn get_host_cpu_max_freq_khz() -> Result<BTreeMap<usize, u32>> {
+        Ok(BTreeMap::new())
+    }
+
     fn get_host_cpu_capacity() -> Result<BTreeMap<usize, u32>> {
         Ok(BTreeMap::new())
     }
@@ -538,7 +550,7 @@ fn get_high_mmio_base_size(mem_size: u64, guest_phys_addr_bits: u8) -> (u64, u64
 }
 
 fn get_base_linux_cmdline() -> kernel_cmdline::Cmdline {
-    let mut cmdline = kernel_cmdline::Cmdline::new(base::pagesize());
+    let mut cmdline = kernel_cmdline::Cmdline::new();
     cmdline.insert_str("panic=-1").unwrap();
     cmdline
 }
diff --git a/rust-toolchain b/rust-toolchain
index bf7cf5657..5d46f6a5e 100644
--- a/rust-toolchain
+++ b/rust-toolchain
@@ -1,3 +1,3 @@
 [toolchain]
-channel = "1.73.0"
+channel = "1.77.2"
 components = [ "rustfmt", "clippy", "llvm-tools-preview" ]
diff --git a/rutabaga_gfx/Android.bp b/rutabaga_gfx/Android.bp
index 6c37c03da..4964f3118 100644
--- a/rutabaga_gfx/Android.bp
+++ b/rutabaga_gfx/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "rutabaga_gfx",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.3",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "gfxstream",
@@ -58,8 +58,6 @@ rust_library {
     },
     static_libs: [
         "libepoxy",
-        "libgbm",
-        "libdrm",
         "libgfxstream_backend",
         "libvirglrenderer",
     ],
@@ -67,7 +65,6 @@ rust_library {
 
 rust_library {
     name: "librutabaga_gfx_gfxstream",
-    defaults: ["crosvm_inner_defaults"],
     host_supported: true,
     vendor_available: true,
     crate_name: "rutabaga_gfx",
@@ -84,22 +81,28 @@ rust_library {
         "libzerocopy",
     ],
     proc_macros: ["libremain"],
-    cfgs: [
-        "gfxstream_unstable",
-    ],
-    features: [
-        "gfxstream",
-    ],
-    shared_libs: [
-        "libgfxstream_backend",
-    ],
     target: {
         host: {
-            features: ["vulkano"],
+            cfgs: [
+                "gfxstream_unstable",
+            ],
+            features: [
+                "gfxstream",
+                "vulkano",
+            ],
+            shared_libs: [
+                "libgfxstream_backend",
+            ],
+            compile_multilib: "64",
             rustlibs: [
                 "libvulkano",
             ],
         },
+        android: {
+            cfgs: [
+                "gfxstream_unstable",
+            ],
+        },
     },
 }
 
@@ -110,7 +113,7 @@ rust_test {
     crate_name: "rutabaga_gfx",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.3",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -132,11 +135,7 @@ rust_test {
     proc_macros: ["libremain"],
     shared_libs: [
         "libepoxy",
-        "libgbm",
         "libgfxstream_backend",
         "libvirglrenderer",
     ],
-    static_libs: [
-        "libdrm",
-    ],
 }
diff --git a/rutabaga_gfx/OWNERS b/rutabaga_gfx/OWNERS
new file mode 100644
index 000000000..0fd5b5747
--- /dev/null
+++ b/rutabaga_gfx/OWNERS
@@ -0,0 +1,13 @@
+# ChromeOS
+ryanneph@google.com
+dawnhan@google.com
+
+# Cuttlefish
+natsu@google.com
+
+# Auto
+gurchetansingh@chromium.org
+
+# Windows
+kaiyili@google.com
+colindr@google.com
diff --git a/rutabaga_gfx/build.rs b/rutabaga_gfx/build.rs
index 3acb58ea4..875504cc8 100644
--- a/rutabaga_gfx/build.rs
+++ b/rutabaga_gfx/build.rs
@@ -278,6 +278,9 @@ fn gfxstream() -> Result<()> {
 }
 
 fn main() -> Result<()> {
+    println!("cargo:rustc-check-cfg=cfg(gfxstream_unstable)");
+    println!("cargo:rustc-check-cfg=cfg(virgl_renderer_unstable)");
+
     // Skip installing dependencies when generating documents.
     if env::var("CARGO_DOC").is_ok() {
         return Ok(());
diff --git a/rutabaga_gfx/ffi/Makefile b/rutabaga_gfx/ffi/Makefile
deleted file mode 100644
index f8c7820bf..000000000
--- a/rutabaga_gfx/ffi/Makefile
+++ /dev/null
@@ -1,76 +0,0 @@
-# Copyright 2023 The ChromiumOS Authors
-# Use of this source code is governed by a BSD-style license that can be
-# found in the LICENSE file.
-
-prefix ?= /usr/local
-libdir = ${prefix}/lib
-includedir = ${prefix}/include/rutabaga_gfx
-
-UNAME := $(shell uname -s)
-
-GFXSTREAM_DEP = gfxstream_backend
-
-ifdef debug
-  release :=
-  target :=debug
-  extension :=debug
-  OUT = target/debug
-else
-  release :=--release
-  target :=release
-  extension :=
-  OUT = target/release
-endif
-
-# Remember to change ffi/build.rs if this changes.
-RUTABAGA_VERSION_MAJOR := 0
-SRC ?= src
-
-ifeq ($(UNAME), Linux)
-LIB_NAME := librutabaga_gfx_ffi.so
-endif
-
-ifeq ($(UNAME), Darwin)
-LIB_NAME := librutabaga_gfx_ffi.dylib
-endif
-
-gfxstream_feature :=
-ifeq ($(shell pkg-config --exists $(GFXSTREAM_DEP) && echo 1),1)
-    gfxstream_feature :=--features=gfxstream
-endif
-
-RUTABAGA_VERSION := $(RUTABAGA_VERSION_MAJOR).1.3
-
-all: build
-
-build:
-	cargo build $(gfxstream_feature) $(release)
-
-install: build
-ifeq ($(UNAME), Linux)
-	install -D -m 755 $(OUT)/$(LIB_NAME) $(DESTDIR)$(libdir)/$(LIB_NAME).$(RUTABAGA_VERSION)
-endif
-ifeq ($(UNAME), Darwin)
-	install_name_tool -id $(DESTDIR)$(libdir)/$(LIB_NAME).$(RUTABAGA_VERSION) $(DESTDIR)$(libdir)/$(LIB_NAME)
-endif
-
-	ln -sf $(LIB_NAME).$(RUTABAGA_VERSION) $(DESTDIR)$(libdir)/$(LIB_NAME).$(RUTABAGA_VERSION_MAJOR)
-	ln -sf $(LIB_NAME).$(RUTABAGA_VERSION) $(DESTDIR)$(libdir)/$(LIB_NAME)
-
-ifeq ($(UNAME), Linux)
-	install -D -m 0644 $(OUT)/rutabaga_gfx_ffi.pc $(DESTDIR)$(libdir)/pkgconfig/rutabaga_gfx_ffi.pc
-	install -D -m 0644 $(SRC)/include/rutabaga_gfx_ffi.h $(DESTDIR)$(includedir)/rutabaga_gfx_ffi.h
-endif
-ifeq ($(UNAME), Darwin)
-	install -m 0644 $(OUT)/rutabaga_gfx_ffi.pc $(DESTDIR)$(libdir)/pkgconfig/rutabaga_gfx_ffi.pc
-	install -m 0644 $(SRC)/include/rutabaga_gfx_ffi.h $(DESTDIR)$(includedir)/rutabaga_gfx_ffi.h
-endif
-
-clean:
-	cargo clean $(release)
-
-distclean:
-	cargo clean $(release)
-
-help:
-	@echo "usage: make $(prog) [debug=1]"
diff --git a/rutabaga_gfx/ffi/build.sh b/rutabaga_gfx/ffi/build.sh
new file mode 100644
index 000000000..9308400c1
--- /dev/null
+++ b/rutabaga_gfx/ffi/build.sh
@@ -0,0 +1,31 @@
+#!/bin/bash
+
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+
+FEATURES="$1"
+TARGET_DIR="$2"
+SHARED_LIB="$3"
+VERSION="$4"
+BUILDTYPE="$5"
+CARGO_RELEASE="$6"
+
+SHARED_LIB_FULL="$SHARED_LIB"".$VERSION"
+SHARED_LIB_MAJOR="$SHARED_LIB"".0"
+
+# The following returns true if $CARGO_RELASE is the empty string
+if [[ -z "$CARGO_RELEASE" ]]
+then
+  CARGO_TARGET_DIR="$TARGET_DIR" cargo build --features="$FEATURES" --target-dir="$TARGET_DIR"
+else
+  CARGO_TARGET_DIR="$TARGET_DIR" cargo build --features="$FEATURES" --target-dir="$TARGET_DIR" --release
+fi
+
+rm "$SHARED_LIB" 2>/dev/null
+rm "$SHARED_LIB_FULL" 2>/dev/null
+rm "$SHARED_LIB_MAJOR" 2>/dev/null
+cp "$BUILDTYPE"/"$SHARED_LIB" "$SHARED_LIB_FULL"
+ln -s "$SHARED_LIB_FULL" "$SHARED_LIB"
+ln -s "$SHARED_LIB_FULL" "$SHARED_LIB_MAJOR"
diff --git a/rutabaga_gfx/ffi/meson.build b/rutabaga_gfx/ffi/meson.build
new file mode 100644
index 000000000..a384202e2
--- /dev/null
+++ b/rutabaga_gfx/ffi/meson.build
@@ -0,0 +1,59 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+project('rutabaga_gfx_ffi', ['rust', 'c'],
+         version: '0.1.3')
+
+target_os = host_machine.system()
+
+# By default cargo would generate rutabaga_gfx_ffi.dll (without the lib
+# prefix) for a Windows cdylib
+if target_os == 'windows'
+  shared_lib = 'rutabaga_gfx_ffi.dll'
+endif
+if target_os == 'darwin'
+  shared_lib = 'librutabaga_gfx_ffi.dylib'
+endif
+if target_os == 'linux'
+  shared_lib = 'librutabaga_gfx_ffi.so'
+endif
+
+shared_lib_major = '@0@.0'.format(shared_lib)
+shared_lib_full_ver = '@0@.@1@'.format(shared_lib, meson.project_version())
+
+build_script = find_program('build.sh')
+with_gfxstream = get_option('gfxstream')
+features = ''
+if with_gfxstream
+  features += 'gfxstream'
+endif
+
+buildtype = 'debug'
+cargo_release = ''
+if get_option('buildtype') == 'release'
+  buildtype = 'release'
+  cargo_release = '--release'
+endif
+
+rutabaga_gfx_ffi_ct = custom_target(
+  'rutabaga_gfx_ffi_build',
+  output: [shared_lib, shared_lib_major, shared_lib_full_ver],
+  input: ['src/lib.rs', 'Cargo.toml', 'build.rs', 'build.sh'],
+  command: [build_script, features, meson.current_build_dir(),
+            shared_lib, meson.project_version(), buildtype, cargo_release],
+  install: true,
+  install_dir: get_option('libdir'),
+)
+
+pkg = import('pkgconfig')
+pkg.generate(
+  libraries: '-L${libdir} -lrutabaga_gfx_ffi',
+  name: 'rutabaga_gfx_ffi',
+  version: meson.project_version(),
+  description: 'C FFI bindings to Rutabaga VGI',
+)
+
+rutabaga_gfx_ffi_h = files('src/include/rutabaga_gfx_ffi.h')
+install_headers(rutabaga_gfx_ffi_h,
+                subdir: 'rutabaga_gfx')
diff --git a/rutabaga_gfx/ffi/meson_options.txt b/rutabaga_gfx/ffi/meson_options.txt
new file mode 100644
index 000000000..8366814c2
--- /dev/null
+++ b/rutabaga_gfx/ffi/meson_options.txt
@@ -0,0 +1,8 @@
+# 2024 Android Open Source Project
+# SPDX-License-Identifier: MIT
+option(
+  'gfxstream',
+  type : 'boolean',
+  value : false,
+  description : 'Build gfxstream in rutabaga_gfx_ffi',
+)
diff --git a/rutabaga_gfx/ffi/src/lib.rs b/rutabaga_gfx/ffi/src/lib.rs
index e17e37c16..83e078180 100644
--- a/rutabaga_gfx/ffi/src/lib.rs
+++ b/rutabaga_gfx/ffi/src/lib.rs
@@ -27,7 +27,25 @@ use std::slice::from_raw_parts_mut;
 use libc::iovec;
 use libc::EINVAL;
 use libc::ESRCH;
-use rutabaga_gfx::*;
+use rutabaga_gfx::ResourceCreate3D;
+use rutabaga_gfx::ResourceCreateBlob;
+use rutabaga_gfx::Rutabaga;
+use rutabaga_gfx::RutabagaBuilder;
+use rutabaga_gfx::RutabagaChannel;
+use rutabaga_gfx::RutabagaComponentType;
+use rutabaga_gfx::RutabagaDebug;
+use rutabaga_gfx::RutabagaDebugHandler;
+use rutabaga_gfx::RutabagaDescriptor;
+use rutabaga_gfx::RutabagaFence;
+use rutabaga_gfx::RutabagaFenceHandler;
+use rutabaga_gfx::RutabagaFromRawDescriptor;
+use rutabaga_gfx::RutabagaHandle;
+use rutabaga_gfx::RutabagaIntoRawDescriptor;
+use rutabaga_gfx::RutabagaIovec;
+use rutabaga_gfx::RutabagaResult;
+use rutabaga_gfx::RutabagaWsi;
+use rutabaga_gfx::Transfer3D;
+use rutabaga_gfx::RUTABAGA_DEBUG_ERROR;
 
 #[cfg(not(unix))]
 #[repr(C)]
@@ -282,7 +300,7 @@ pub unsafe extern "C" fn rutabaga_init(builder: &rutabaga_builder, ptr: &mut *mu
 #[no_mangle]
 pub extern "C" fn rutabaga_finish(ptr: &mut *mut rutabaga) -> i32 {
     catch_unwind(AssertUnwindSafe(|| {
-        unsafe { Box::from_raw(*ptr) };
+        let _ = unsafe { Box::from_raw(*ptr) };
         *ptr = null_mut();
         NO_ERROR
     }))
@@ -508,7 +526,11 @@ pub unsafe extern "C" fn rutabaga_resource_create_blob(
     catch_unwind(AssertUnwindSafe(|| {
         let mut iovecs_opt: Option<Vec<RutabagaIovec>> = None;
         if let Some(iovs) = iovecs {
-            let slice = from_raw_parts((*iovs).iovecs, (*iovs).num_iovecs);
+            let slice = if iovs.num_iovecs != 0 {
+                from_raw_parts(iovs.iovecs, iovs.num_iovecs)
+            } else {
+                &[]
+            };
             let vecs = slice
                 .iter()
                 .map(|iov| RutabagaIovec {
@@ -616,8 +638,17 @@ pub unsafe extern "C" fn rutabaga_submit_command(
     cmd: &rutabaga_command,
 ) -> i32 {
     catch_unwind(AssertUnwindSafe(|| {
-        let cmd_slice = from_raw_parts_mut(cmd.cmd, cmd.cmd_size as usize);
-        let fence_ids = from_raw_parts(cmd.fence_ids, cmd.num_in_fences as usize);
+        let cmd_slice = if cmd.cmd_size != 0 {
+            from_raw_parts_mut(cmd.cmd, cmd.cmd_size as usize)
+        } else {
+            &mut []
+        };
+        let fence_ids = if cmd.num_in_fences != 0 {
+            from_raw_parts(cmd.fence_ids, cmd.num_in_fences as usize)
+        } else {
+            &mut []
+        };
+
         let result = ptr.submit_command(cmd.ctx_id, cmd_slice, fence_ids);
         return_result(result)
     }))
diff --git a/rutabaga_gfx/kumquat/gpu_client/Android.bp b/rutabaga_gfx/kumquat/gpu_client/Android.bp
new file mode 100644
index 000000000..57ca00692
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/Android.bp
@@ -0,0 +1,46 @@
+package {
+    // See: http://go/android-license-faq
+    // A large-scale-change added 'default_applicable_licenses' to import
+    // all of the 'license_kinds' from "external_crosvm_license"
+    // to get the below license kinds:
+    //   SPDX-license-identifier-BSD
+    default_applicable_licenses: ["external_crosvm_license"],
+}
+
+cc_library_headers {
+    name: "virtgpu_kumquat_ffi_headers",
+    host_supported: true,
+    vendor_available: true,
+    export_include_dirs: ["src/include"],
+}
+
+// The following shared library is used by gfxstream guest libraries (for
+// example, libgfxstream_vulkan.so) for end2end testing (b:354706346) via
+// Kumquat:
+//
+// https://crosvm.dev/book/appendix/rutabaga_gfx.html#kumquat-media-server
+//
+// Since traditionally guest-side libraries link against it,
+// libvirtgpu_kumquat_ffi and it's main dependency (librutabaga_gfx_gfxstream)
+// support a wider degree of ABIs than crosvm itself does.  This simplifies the
+// guest gfxstream build.
+rust_ffi_shared {
+    name: "libvirtgpu_kumquat_ffi",
+    crate_name: "virtgpu_kumquat_ffi",
+    host_supported: true,
+    vendor_available: true,
+    srcs: ["src/lib.rs"],
+    rustlibs: [
+        "librutabaga_gfx_gfxstream",
+        "liblibc",
+        "liblog_rust",
+        "libnix",
+        "libthiserror",
+        "libzerocopy",
+    ],
+    target: {
+        host: {
+            compile_multilib: "64",
+        },
+    },
+}
diff --git a/rutabaga_gfx/kumquat/gpu_client/Cargo.toml b/rutabaga_gfx/kumquat/gpu_client/Cargo.toml
new file mode 100644
index 000000000..289aa1919
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/Cargo.toml
@@ -0,0 +1,26 @@
+[package]
+name = "virtgpu_kumquat_ffi"
+version = "0.1.3"
+authors = ["Android Open Source Project"]
+edition = "2021"
+description = "Library for virtgpu syscalls"
+license-file = "LICENSE"
+
+[lib]
+name = "virtgpu_kumquat_ffi"
+crate-type = ["cdylib", "staticlib"]
+
+[dependencies]
+rutabaga_gfx = { path = "../../", version = "0.1.3"}
+zerocopy = { version = "0.7", features = ["derive"] }
+libc = "0.2.93"
+log = "0.4"
+
+[profile.dev]
+lto = true
+incremental = false
+
+[target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
+nix = { version = "0.28", features = ["event", "feature", "fs", "mman", "socket", "uio", "ioctl"] }
+
+[workspace]
diff --git a/rutabaga_gfx/kumquat/gpu_client/build.sh b/rutabaga_gfx/kumquat/gpu_client/build.sh
new file mode 100644
index 000000000..93eb5499b
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/build.sh
@@ -0,0 +1,30 @@
+#!/bin/bash
+
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+TARGET_DIR="$1"
+SHARED_LIB="$2"
+VERSION="$3"
+BUILDTYPE="$4"
+CARGO_RELEASE="$5"
+
+SHARED_LIB_FULL="$SHARED_LIB"".$VERSION"
+SHARED_LIB_MAJOR="$SHARED_LIB"".0"
+
+# The following returns true if $CARGO_RELASE is the empty string
+if [[ -z "$CARGO_RELEASE" ]]
+then
+  CARGO_TARGET_DIR="$TARGET_DIR" cargo build --features="$FEATURES" --target-dir="$TARGET_DIR"
+else
+  CARGO_TARGET_DIR="$TARGET_DIR" cargo build --features="$FEATURES" --target-dir="$TARGET_DIR" --release
+fi
+
+CARGO_TARGET_DIR="$TARGET_DIR" cargo build --target-dir="$TARGET_DIR"
+rm "$SHARED_LIB" 2>/dev/null
+rm "$SHARED_LIB_FULL" 2>/dev/null
+rm "$SHARED_LIB_MAJOR" 2>/dev/null
+cp "$BUILDTYPE"/"$SHARED_LIB" "$SHARED_LIB_FULL"
+ln -s "$SHARED_LIB_FULL" "$SHARED_LIB"
+ln -s "$SHARED_LIB_FULL" "$SHARED_LIB_MAJOR"
diff --git a/rutabaga_gfx/kumquat/gpu_client/meson.build b/rutabaga_gfx/kumquat/gpu_client/meson.build
new file mode 100644
index 000000000..6ef613447
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/meson.build
@@ -0,0 +1,52 @@
+# Copyright 2024 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+project('virtgpu_kumquat_ffi', ['rust', 'c'],
+         version: '0.1.3')
+
+target_os = host_machine.system()
+
+if target_os == 'windows'
+  shared_lib = 'virtgpu_kumquat_ffi.dll'
+endif
+if target_os == 'darwin'
+  shared_lib = 'libvirtgpu_kumquat_ffi.dylib'
+endif
+if target_os == 'linux'
+  shared_lib = 'libvirtgpu_kumquat_ffi.so'
+endif
+
+shared_lib_major = '@0@.0'.format(shared_lib)
+shared_lib_full_ver = '@0@.@1@'.format(shared_lib, meson.project_version())
+
+build_script = find_program('build.sh')
+
+buildtype = 'debug'
+cargo_release = ''
+if get_option('buildtype') == 'release'
+  buildtype = 'release'
+  cargo_release = '--release'
+endif
+
+virtgpu_kumquat_ffi_ct = custom_target(
+  'virtgpu_kumquat_ffi_build',
+  output: [shared_lib, shared_lib_major, shared_lib_full_ver],
+  input: ['src/lib.rs', 'Cargo.toml', 'build.sh'],
+  command: [build_script, meson.current_build_dir(), shared_lib,
+            meson.project_version(), buildtype, cargo_release],
+  install: true,
+  install_dir: get_option('libdir'),
+)
+
+pkg = import('pkgconfig')
+pkg.generate(
+  libraries: '-L${libdir} -lvirtgpu_kumquat_ffi',
+  name: 'virtgpu_kumquat_ffi',
+  version: meson.project_version(),
+  description: 'C FFI bindings to Rutabaga VGI',
+)
+
+virtgpu_kumquat_ffi_h = files('src/include/virtgpu_kumquat_ffi.h')
+install_headers(virtgpu_kumquat_ffi_h,
+                subdir: 'virtgpu_kumquat')
diff --git a/rutabaga_gfx/kumquat/gpu_client/src/include/.clang-format b/rutabaga_gfx/kumquat/gpu_client/src/include/.clang-format
new file mode 100644
index 000000000..05120f017
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/src/include/.clang-format
@@ -0,0 +1,15 @@
+# Copyright 2021 The ChromiumOS Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+BasedOnStyle: LLVM
+AllowShortFunctionsOnASingleLine: None
+AllowShortIfStatementsOnASingleLine: false
+AllowShortLoopsOnASingleLine: false
+BreakBeforeBraces: Linux
+ColumnLimit: 100
+IndentWidth: 4
+TabWidth: 4
+UseTab: Never
+Cpp11BracedListStyle: false
+IndentCaseLabels: false
diff --git a/rutabaga_gfx/kumquat/gpu_client/src/include/virtgpu_kumquat_ffi.h b/rutabaga_gfx/kumquat/gpu_client/src/include/virtgpu_kumquat_ffi.h
new file mode 100644
index 000000000..33e534483
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/src/include/virtgpu_kumquat_ffi.h
@@ -0,0 +1,273 @@
+/*
+ * Copyright 2024 The ChromiumOS Authors
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include <stdarg.h>
+#include <stdbool.h>
+#include <stdint.h>
+#include <stdlib.h>
+
+#ifndef VIRTGPU_KUMQUAT_FFI_H
+#define VIRTGPU_KUMQUAT_FFI_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+struct virtgpu_kumquat;
+
+struct drm_kumquat_map {
+    uint32_t bo_handle;
+
+    // out
+    void *ptr;
+    uint64_t size;
+};
+
+#define VIRTGPU_KUMQUAT_EXECBUF_SYNCOBJ_RESET 0x01
+#define VIRTGPU_KUMQUAT_EXECBUF_SYNCOBJ_FLAGS (VIRTGPU_KUMQUAT_EXECBUF_SYNCOBJ_RESET | 0)
+struct drm_kumquat_execbuffer_syncobj {
+    uint32_t handle;
+    uint32_t flags;
+    uint64_t point;
+};
+
+#define VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_IN 0x01
+#define VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_OUT 0x02
+#define VIRTGPU_KUMQUAT_EXECBUF_RING_IDX 0x04
+#define VIRTGPU_KUMQUAT_EXECBUF_SHAREABLE_IN 0x08
+#define VIRTGPU_KUMQUAT_EXECBUF_SHAREABLE_OUT 0x10
+
+#define VIRTGPU_KUMQUAT_EXECBUF_FLAGS                                                              \
+    (VIRTGPU_EXECBUF_FENCE_FD_IN | VIRTGPU_EXECBUF_FENCE_FD_OUT | VIRTGPU_EXECBUF_RING_IDX |       \
+     VIRTGPU_EXECBUF_SHAREABLE_IN | VIRTGPU_EXECBUF_SHAREABLE_OUT | 0)
+
+/* fence_fd is modified on success if VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_OUT flag is set. */
+struct drm_kumquat_execbuffer {
+    uint32_t flags;
+    uint32_t size;
+    uint64_t command; /* void* */
+    uint64_t bo_handles;
+    uint32_t num_bo_handles;
+    int32_t fence_fd;        /* in/out fence fd (see VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_IN/OUT) */
+    uint32_t ring_idx;       /* command ring index (see VIRTGPU_KUMQUAT_EXECBUF_RING_IDX) */
+    uint32_t syncobj_stride; /* size of @drm_kumquat_execbuffer_syncobj */
+    uint32_t num_in_syncobjs;
+    uint32_t num_out_syncobjs;
+    uint64_t in_syncobjs;
+    uint64_t out_syncobjs;
+};
+
+#define VIRTGPU_KUMQUAT_PARAM_3D_FEATURES 1          /* do we have 3D features in the hw */
+#define VIRTGPU_KUMQUAT_PARAM_CAPSET_QUERY_FIX 2     /* do we have the capset fix */
+#define VIRTGPU_KUMQUAT_PARAM_RESOURCE_BLOB 3        /* DRM_VIRTGPU_RESOURCE_CREATE_BLOB */
+#define VIRTGPU_KUMQUAT_PARAM_HOST_VISIBLE 4         /* Host blob resources are mappable */
+#define VIRTGPU_KUMQUAT_PARAM_CROSS_DEVICE 5         /* Cross virtio-device resource sharing  */
+#define VIRTGPU_KUMQUAT_PARAM_CONTEXT_INIT 6         /* DRM_VIRTGPU_KUMQUAT_CONTEXT_INIT */
+#define VIRTGPU_KUMQUAT_PARAM_SUPPORTED_CAPSET_IDs 7 /* Bitmask of supported capability set ids */
+#define VIRTGPU_KUMQUAT_PARAM_EXPLICIT_DEBUG_NAME 8  /* Ability to set debug name from userspace */
+#define VIRTGPU_KUMQUAT_PARAM_FENCE_PASSING 9        /* Host shareable fences */
+#define VIRTGPU_KUMQUAT_PARAM_CREATE_GUEST_HANDLE 10
+
+struct drm_kumquat_getparam {
+    uint64_t param;
+    uint64_t value;
+};
+
+struct drm_kumquat_resource_create_3d {
+    uint32_t target;
+    uint32_t format;
+    uint32_t bind;
+    uint32_t width;
+    uint32_t height;
+    uint32_t depth;
+    uint32_t array_size;
+    uint32_t last_level;
+    uint32_t nr_samples;
+    uint32_t flags;
+    uint32_t bo_handle;
+    uint32_t res_handle;
+    uint32_t size;
+    uint32_t stride;
+};
+
+struct drm_kumquat_resource_info {
+    uint32_t bo_handle;
+    uint32_t res_handle;
+    uint32_t size;
+    uint32_t blob_mem;
+};
+
+struct drm_kumquat_3d_box {
+    uint32_t x;
+    uint32_t y;
+    uint32_t z;
+    uint32_t w;
+    uint32_t h;
+    uint32_t d;
+};
+
+struct drm_kumquat_transfer_to_host {
+    uint32_t bo_handle;
+    struct drm_kumquat_3d_box box;
+    uint32_t level;
+    uint32_t offset;
+    uint32_t stride;
+    uint32_t layer_stride;
+};
+
+struct drm_kumquat_transfer_from_host {
+    uint32_t bo_handle;
+    struct drm_kumquat_3d_box box;
+    uint32_t level;
+    uint32_t offset;
+    uint32_t stride;
+    uint32_t layer_stride;
+};
+
+struct drm_kumquat_wait {
+    uint32_t handle; /* 0 is an invalid handle */
+    uint32_t flags;
+};
+
+struct drm_kumquat_get_caps {
+    uint32_t cap_set_id;
+    uint32_t cap_set_ver;
+    uint64_t addr;
+    uint32_t size;
+    uint32_t pad;
+};
+
+struct drm_kumquat_resource_create_blob {
+#define VIRTGPU_KUMQUAT_MEM_GUEST 0x0001
+#define VIRTGPU_KUMQUAT_MEM_HOST3D 0x0002
+#define VIRTGPU_KUMQUAT_MEM_HOST3D_GUEST 0x0003
+
+#define VIRTGPU_KUMQUAT_FLAG_USE_MAPPABLE 0x0001
+#define VIRTGPU_KUMQUAT_FLAG_USE_SHAREABLE 0x0002
+#define VIRTGPU_KUMQUAT_FLAG_USE_CROSS_DEVICE 0x0004
+    /* zero is invalid blob_mem */
+    uint32_t blob_mem;
+    uint32_t blob_flags;
+    uint32_t bo_handle;
+    uint32_t res_handle;
+    uint64_t size;
+
+    /*
+     * for 3D contexts with VIRTGPU_KUMQUAT_MEM_HOST3D_GUEST and
+     * VIRTGPU_KUMQUAT_MEM_HOST3D otherwise, must be zero.
+     */
+    uint32_t pad;
+    uint32_t cmd_size;
+    uint64_t cmd;
+    uint64_t blob_id;
+};
+
+struct drm_kumquat_resource_unref {
+    uint32_t bo_handle;
+    uint32_t pad;
+};
+
+#define VIRTGPU_KUMQUAT_CONTEXT_PARAM_CAPSET_ID 0x0001
+#define VIRTGPU_KUMQUAT_CONTEXT_PARAM_NUM_RINGS 0x0002
+#define VIRTGPU_KUMQUAT_CONTEXT_PARAM_POLL_RINGS_MASK 0x0003
+#define VIRTGPU_KUMQUAT_CONTEXT_PARAM_DEBUG_NAME 0x0004
+struct drm_kumquat_context_set_param {
+    uint64_t param;
+    uint64_t value;
+};
+
+struct drm_kumquat_context_init {
+    uint32_t num_params;
+    uint32_t pad;
+
+    /* pointer to drm_kumquat_context_set_param array */
+    uint64_t ctx_set_params;
+};
+
+/*
+ * Without VIRTGPU_KUMQUAT_EMULATED_EXPORT, the server side descriptor will
+ * be provided.
+ *
+ * With VIRTGPU_KUMQUAT_EMULATED_EXPORT, a shared memory descriptor embedded
+ * with resource will be provided.
+ */
+#define VIRTGPU_KUMQUAT_EMULATED_EXPORT 0x0001
+
+#define VIRTGPU_KUMQUAT_MEM_HANDLE_TYPE_OPAQUE_FD 0x1
+#define VIRTGPU_KUMQUAT_MEM_HANDLE_TYPE_DMABUF 0x2
+#define VIRTGPU_KUMQUAT_MEM_HANDLE_TYPE_OPAQUE_WIN32 0x3
+#define VIRTGPU_KUMQUAT_MEM_HANDLE_TYPE_SHM 0x4
+#define VIRTGPU_KUMQUAT_MEM_HANDLE_TYPE_ZIRCON 0x5
+
+#define VIRTGPU_KUMQUAT_FENCE_HANDLE_TYPE_OPAQUE_FD 0x6
+#define VIRTGPU_KUMQUAT_FENCE_HANDLE_TYPE_SYNC_FD 0x7
+#define VIRTGPU_KUMQUAT_FENCE_HANDLE_TYPE_OPAQUE_WIN32 0x8
+#define VIRTGPU_KUMQUAT_FENCE_HANDLE_TYPE_ZIRCON 0x9
+struct drm_kumquat_resource_export {
+    uint32_t bo_handle;
+    uint32_t flags;
+    int64_t os_handle;
+    uint32_t handle_type;
+};
+
+struct drm_kumquat_resource_import {
+    int64_t os_handle;
+    uint32_t handle_type;
+    uint32_t bo_handle;
+    uint32_t res_handle;
+    uint64_t size;
+};
+
+int32_t virtgpu_kumquat_init(struct virtgpu_kumquat **ptr, const char *gpu_socket);
+
+int32_t virtgpu_kumquat_finish(struct virtgpu_kumquat **ptr);
+
+int32_t virtgpu_kumquat_get_param(struct virtgpu_kumquat *ptr, struct drm_kumquat_getparam *cmd);
+
+int32_t virtgpu_kumquat_get_caps(struct virtgpu_kumquat *ptr, struct drm_kumquat_get_caps *cmd);
+
+int32_t virtgpu_kumquat_context_init(struct virtgpu_kumquat *ptr,
+                                     struct drm_kumquat_context_init *cmd);
+
+int32_t virtgpu_kumquat_resource_create_3d(struct virtgpu_kumquat *ptr,
+                                           struct drm_kumquat_resource_create_3d *cmd);
+
+int32_t virtgpu_kumquat_resource_create_blob(struct virtgpu_kumquat *ptr,
+                                             struct drm_kumquat_resource_create_blob *cmd);
+
+int32_t virtgpu_kumquat_resource_unref(struct virtgpu_kumquat *ptr,
+                                       struct drm_kumquat_resource_unref *cmd);
+
+int32_t virtgpu_kumquat_resource_map(struct virtgpu_kumquat *ptr, struct drm_kumquat_map *cmd);
+
+int32_t virtgpu_kumquat_resource_unmap(struct virtgpu_kumquat *ptr, uint32_t bo_handle);
+
+int32_t virtgpu_kumquat_transfer_to_host(struct virtgpu_kumquat *ptr,
+                                         struct drm_kumquat_transfer_to_host *cmd);
+
+int32_t virtgpu_kumquat_transfer_from_host(struct virtgpu_kumquat *ptr,
+                                           struct drm_kumquat_transfer_from_host *cmd);
+
+int32_t virtgpu_kumquat_execbuffer(struct virtgpu_kumquat *ptr, struct drm_kumquat_execbuffer *cmd);
+
+int32_t virtgpu_kumquat_wait(struct virtgpu_kumquat *ptr, struct drm_kumquat_wait *cmd);
+
+// The following commands are more emulated than the rest.
+int32_t virtgpu_kumquat_resource_export(struct virtgpu_kumquat *ptr,
+                                        struct drm_kumquat_resource_export *cmd);
+
+int32_t virtgpu_kumquat_resource_import(struct virtgpu_kumquat *ptr,
+                                        struct drm_kumquat_resource_import *cmd);
+
+int32_t virtgpu_kumquat_snapshot_save(struct virtgpu_kumquat *ptr);
+
+int32_t virtgpu_kumquat_snapshot_restore(struct virtgpu_kumquat *ptr);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/rutabaga_gfx/kumquat/gpu_client/src/lib.rs b/rutabaga_gfx/kumquat/gpu_client/src/lib.rs
new file mode 100644
index 000000000..5b582d688
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/src/lib.rs
@@ -0,0 +1,371 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+extern crate rutabaga_gfx;
+
+mod virtgpu;
+
+use std::boxed::Box;
+use std::ffi::CStr;
+use std::os::raw::c_char;
+use std::os::raw::c_void;
+use std::panic::catch_unwind;
+use std::panic::AssertUnwindSafe;
+use std::ptr::null_mut;
+use std::slice::from_raw_parts;
+use std::slice::from_raw_parts_mut;
+use std::sync::Mutex;
+
+use libc::EINVAL;
+use libc::ESRCH;
+use log::error;
+use rutabaga_gfx::RutabagaDescriptor;
+use rutabaga_gfx::RutabagaFromRawDescriptor;
+use rutabaga_gfx::RutabagaHandle;
+use rutabaga_gfx::RutabagaIntoRawDescriptor;
+use rutabaga_gfx::RutabagaRawDescriptor;
+use rutabaga_gfx::RutabagaResult;
+use virtgpu::defines::*;
+use virtgpu::VirtGpuKumquat;
+
+const NO_ERROR: i32 = 0;
+
+fn return_result<T>(result: RutabagaResult<T>) -> i32 {
+    if let Err(e) = result {
+        error!("An error occurred: {}", e);
+        -EINVAL
+    } else {
+        NO_ERROR
+    }
+}
+
+macro_rules! return_on_error {
+    ($result:expr) => {
+        match $result {
+            Ok(t) => t,
+            Err(e) => {
+                error!("An error occurred: {}", e);
+                return -EINVAL;
+            }
+        }
+    };
+}
+
+#[allow(non_camel_case_types)]
+type virtgpu_kumquat = Mutex<VirtGpuKumquat>;
+
+// The following structs (in define.rs) must be ABI-compatible with FFI header
+// (virtgpu_kumquat_ffi.h).
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_getparam = VirtGpuParam;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_resource_unref = VirtGpuResourceUnref;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_get_caps = VirtGpuGetCaps;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_context_init = VirtGpuContextInit;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_resource_create_3d = VirtGpuResourceCreate3D;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_resource_create_blob = VirtGpuResourceCreateBlob;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_transfer_to_host = VirtGpuTransfer;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_transfer_from_host = VirtGpuTransfer;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_execbuffer = VirtGpuExecBuffer;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_wait = VirtGpuWait;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_resource_map = VirtGpuResourceMap;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_resource_export = VirtGpuResourceExport;
+
+#[allow(non_camel_case_types)]
+type drm_kumquat_resource_import = VirtGpuResourceImport;
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_init(
+    ptr: &mut *mut virtgpu_kumquat,
+    gpu_socket: Option<&c_char>,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let gpu_socket_str = match gpu_socket {
+            Some(value) => {
+                let c_str_slice = CStr::from_ptr(value);
+                let result = c_str_slice.to_str();
+                return_on_error!(result)
+            }
+            None => "/tmp/kumquat-gpu-0",
+        };
+
+        let result = VirtGpuKumquat::new(gpu_socket_str);
+        let kmqt = return_on_error!(result);
+        *ptr = Box::into_raw(Box::new(Mutex::new(kmqt))) as _;
+        NO_ERROR
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub extern "C" fn virtgpu_kumquat_finish(ptr: &mut *mut virtgpu_kumquat) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let _ = unsafe { Box::from_raw(*ptr) };
+        *ptr = null_mut();
+        NO_ERROR
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_get_param(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_getparam,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().get_param(cmd);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_get_caps(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &drm_kumquat_get_caps,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let caps_slice = from_raw_parts_mut(cmd.addr as *mut u8, cmd.size as usize);
+        let result = ptr.lock().unwrap().get_caps(cmd.cap_set_id, caps_slice);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_context_init(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &drm_kumquat_context_init,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let context_params: &[VirtGpuParam] = from_raw_parts(
+            cmd.ctx_set_params as *const VirtGpuParam,
+            cmd.num_params as usize,
+        );
+
+        let mut capset_id: u64 = 0;
+
+        for param in context_params {
+            match param.param {
+                VIRTGPU_KUMQUAT_CONTEXT_PARAM_CAPSET_ID => {
+                    capset_id = param.value;
+                }
+                _ => (),
+            }
+        }
+
+        let result = ptr.lock().unwrap().context_create(capset_id, "");
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_resource_create_3d(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_resource_create_3d,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().resource_create_3d(cmd);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_resource_create_blob(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_resource_create_blob,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let blob_cmd = from_raw_parts(cmd.cmd as *const u8, cmd.cmd_size as usize);
+        let result = ptr.lock().unwrap().resource_create_blob(cmd, blob_cmd);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_resource_unref(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_resource_unref,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().resource_unref(cmd.bo_handle);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_resource_map(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_resource_map,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().map(cmd.bo_handle);
+        let internal_map = return_on_error!(result);
+        (*cmd).ptr = internal_map.ptr as *mut c_void;
+        (*cmd).size = internal_map.size;
+        NO_ERROR
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_resource_unmap(
+    ptr: &mut virtgpu_kumquat,
+    bo_handle: u32,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().unmap(bo_handle);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_transfer_to_host(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_transfer_to_host,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().transfer_to_host(cmd);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_transfer_from_host(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_transfer_from_host,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().transfer_from_host(cmd);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_execbuffer(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_execbuffer,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let bo_handles = from_raw_parts(cmd.bo_handles as *const u32, cmd.num_bo_handles as usize);
+        let cmd_buf = from_raw_parts(cmd.command as *const u8, cmd.size as usize);
+
+        // TODO
+        let in_fences: &[u64] = &[0; 0];
+
+        let result = ptr.lock().unwrap().submit_command(
+            cmd.flags,
+            bo_handles,
+            cmd_buf,
+            cmd.ring_idx,
+            in_fences,
+            &mut cmd.fence_fd as &mut RutabagaRawDescriptor,
+        );
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_wait(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_wait,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().wait(cmd.bo_handle);
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub extern "C" fn virtgpu_kumquat_resource_export(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_resource_export,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr
+            .lock()
+            .unwrap()
+            .resource_export(cmd.bo_handle, cmd.flags);
+        let hnd = return_on_error!(result);
+
+        (*cmd).handle_type = hnd.handle_type;
+        (*cmd).os_handle = hnd.os_handle.into_raw_descriptor() as i64;
+        NO_ERROR
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_resource_import(
+    ptr: &mut virtgpu_kumquat,
+    cmd: &mut drm_kumquat_resource_import,
+) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let handle = RutabagaHandle {
+            os_handle: RutabagaDescriptor::from_raw_descriptor(
+                (*cmd).os_handle.try_into().unwrap(),
+            ),
+            handle_type: (*cmd).handle_type,
+        };
+
+        let result = ptr.lock().unwrap().resource_import(
+            handle,
+            &mut cmd.bo_handle,
+            &mut cmd.res_handle,
+            &mut cmd.size,
+        );
+
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_snapshot_save(ptr: &mut virtgpu_kumquat) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().snapshot();
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
+
+#[no_mangle]
+pub unsafe extern "C" fn virtgpu_kumquat_snapshot_restore(ptr: &mut virtgpu_kumquat) -> i32 {
+    catch_unwind(AssertUnwindSafe(|| {
+        let result = ptr.lock().unwrap().restore();
+        return_result(result)
+    }))
+    .unwrap_or(-ESRCH)
+}
diff --git a/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/defines.rs b/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/defines.rs
new file mode 100644
index 000000000..0f2dd81a3
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/defines.rs
@@ -0,0 +1,176 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::os::raw::c_void;
+
+pub const VIRTGPU_KUMQUAT_PARAM_3D_FEATURES: u64 = 1;
+pub const VIRTGPU_KUMQUAT_PARAM_CAPSET_QUERY_FIX: u64 = 2;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_PARAM_RESOURCE_BLOB: u64 = 3;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_PARAM_HOST_VISIBLE: u64 = 4;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_PARAM_CROSS_DEVICE: u64 = 5;
+pub const VIRTGPU_KUMQUAT_PARAM_CONTEXT_INIT: u64 = 6;
+pub const VIRTGPU_KUMQUAT_PARAM_SUPPORTED_CAPSET_IDS: u64 = 7;
+pub const VIRTGPU_KUMQUAT_PARAM_EXPLICIT_DEBUG_NAME: u64 = 8;
+pub const VIRTGPU_KUMQUAT_PARAM_FENCE_PASSING: u64 = 9;
+
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_IN: u32 = 0x01;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_OUT: u32 = 0x02;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_EXECBUF_RING_IDX: u32 = 0x04;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_EXECBUF_SHAREABLE_IN: u32 = 0x08;
+pub const VIRTGPU_KUMQUAT_EXECBUF_SHAREABLE_OUT: u32 = 0x10;
+
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_CONTEXT_PARAM_CAPSET_ID: u64 = 0x01;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_CONTEXT_PARAM_NUM_RINGS: u64 = 0x02;
+#[allow(unused)]
+pub const VIRTGPU_KUMQUAT_CONTEXT_PARAM_POLL_RING_MASK: u64 = 0x03;
+
+pub const VIRTGPU_KUMQUAT_EMULATED_EXPORT: u32 = 0x01;
+pub const VIRTGPU_KUMQUAT_PAGE_SIZE: usize = 4096;
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuParam {
+    pub param: u64,
+    pub value: u64,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuGetCaps {
+    pub cap_set_id: u32,
+    pub cap_set_ver: u32,
+    pub addr: u64,
+    pub size: u32,
+    pub pad: u32,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuContextInit {
+    pub num_params: u32,
+    pub pad: u32,
+    pub ctx_set_params: u64,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuResourceCreate3D {
+    pub target: u32,
+    pub format: u32,
+    pub bind: u32,
+    pub width: u32,
+    pub height: u32,
+    pub depth: u32,
+    pub array_size: u32,
+    pub last_level: u32,
+    pub nr_samples: u32,
+    pub flags: u32,
+    pub bo_handle: u32,
+    pub res_handle: u32,
+    pub size: u32,
+    pub stride: u32,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuBox {
+    pub x: u32,
+    pub y: u32,
+    pub z: u32,
+    pub w: u32,
+    pub h: u32,
+    pub d: u32,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuTransfer {
+    pub bo_handle: u32,
+    pub _box: VirtGpuBox,
+    pub level: u32,
+    pub offset: u64,
+    pub stride: u32,
+    pub layer_stride: u32,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuResourceCreateBlob {
+    pub blob_mem: u32,
+    pub blob_flags: u32,
+    pub bo_handle: u32,
+    pub res_handle: u32,
+    pub size: u64,
+    pub pad: u32,
+    pub cmd_size: u32,
+    pub cmd: u64,
+    pub blob_id: u64,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuResourceUnref {
+    pub bo_handle: u32,
+    pub pad: u32,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuExecBuffer {
+    pub flags: u32,
+    pub size: u32,
+    pub command: u64,
+    pub bo_handles: u64,
+    pub num_bo_handles: u32,
+    pub fence_fd: i32,
+    pub ring_idx: u32,
+    pub syncobj_stride: u32,
+    pub num_in_syncobjs: u32,
+    pub num_out_syncobjs: u32,
+    pub in_syncobjs: u64,
+    pub out_syncobjs: u64,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuWait {
+    pub bo_handle: u32,
+    pub flags: u32,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuResourceMap {
+    pub bo_handle: u32,
+    pub ptr: *mut c_void,
+    pub size: u64,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuResourceExport {
+    pub bo_handle: u32,
+    pub flags: u32,
+    pub os_handle: i64,
+    pub handle_type: u32,
+}
+
+#[repr(C)]
+#[derive(Copy, Clone, Debug)]
+pub struct VirtGpuResourceImport {
+    pub os_handle: i64,
+    pub handle_type: u32,
+    pub bo_handle: u32,
+    pub res_handle: u32,
+    pub size: u64,
+}
diff --git a/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/mod.rs b/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/mod.rs
new file mode 100644
index 000000000..96d63e384
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/mod.rs
@@ -0,0 +1,8 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+mod virtgpu_kumquat;
+
+pub mod defines;
+pub use virtgpu_kumquat::VirtGpuKumquat;
diff --git a/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/virtgpu_kumquat.rs b/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/virtgpu_kumquat.rs
new file mode 100644
index 000000000..8ad07be81
--- /dev/null
+++ b/rutabaga_gfx/kumquat/gpu_client/src/virtgpu/virtgpu_kumquat.rs
@@ -0,0 +1,770 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::cmp::min;
+use std::collections::BTreeMap as Map;
+use std::convert::TryInto;
+use std::fs::File;
+use std::os::fd::AsRawFd;
+use std::os::fd::OwnedFd;
+use std::path::PathBuf;
+use std::slice::from_raw_parts_mut;
+use std::sync::Mutex;
+use std::sync::OnceLock;
+
+use nix::sys::eventfd::EfdFlags;
+use nix::sys::eventfd::EventFd;
+use nix::unistd::read;
+use rutabaga_gfx::kumquat_support::kumquat_gpu_protocol::*;
+use rutabaga_gfx::kumquat_support::RutabagaMemoryMapping;
+use rutabaga_gfx::kumquat_support::RutabagaReader;
+use rutabaga_gfx::kumquat_support::RutabagaSharedMemory;
+use rutabaga_gfx::kumquat_support::RutabagaStream;
+use rutabaga_gfx::kumquat_support::RutabagaTube;
+use rutabaga_gfx::kumquat_support::RutabagaWriter;
+use rutabaga_gfx::RutabagaDescriptor;
+use rutabaga_gfx::RutabagaError;
+use rutabaga_gfx::RutabagaFromRawDescriptor;
+use rutabaga_gfx::RutabagaGralloc;
+use rutabaga_gfx::RutabagaGrallocBackendFlags;
+use rutabaga_gfx::RutabagaHandle;
+use rutabaga_gfx::RutabagaIntoRawDescriptor;
+use rutabaga_gfx::RutabagaMappedRegion;
+use rutabaga_gfx::RutabagaMapping;
+use rutabaga_gfx::RutabagaRawDescriptor;
+use rutabaga_gfx::RutabagaResult;
+use rutabaga_gfx::VulkanInfo;
+use rutabaga_gfx::RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD;
+use rutabaga_gfx::RUTABAGA_FLAG_FENCE;
+use rutabaga_gfx::RUTABAGA_FLAG_FENCE_HOST_SHAREABLE;
+use rutabaga_gfx::RUTABAGA_FLAG_INFO_RING_IDX;
+use rutabaga_gfx::RUTABAGA_MAP_ACCESS_RW;
+use rutabaga_gfx::RUTABAGA_MAP_CACHE_CACHED;
+use rutabaga_gfx::RUTABAGA_MEM_HANDLE_TYPE_OPAQUE_FD;
+
+use crate::virtgpu::defines::*;
+
+const VK_ICD_FILENAMES: &str = "VK_ICD_FILENAMES";
+
+// The Tesla V-100 driver seems to enter a power management mode and stops being available to the
+// Vulkan loader if more than a certain number of VK instances are created in the same process.
+//
+// This behavior is reproducible via:
+//
+// GfxstreamEnd2EndTests --gtest_filter="*MultiThreadedVkMapMemory*"
+//
+// Workaround this by having a singleton gralloc per-process.
+fn gralloc() -> &'static Mutex<RutabagaGralloc> {
+    static GRALLOC: OnceLock<Mutex<RutabagaGralloc>> = OnceLock::new();
+    GRALLOC.get_or_init(|| {
+        // The idea is to make sure the gfxstream ICD isn't loaded when gralloc starts
+        // up. The Nvidia ICD should be loaded.
+        //
+        // This is mostly useful for developers.  For AOSP hermetic gfxstream end2end
+        // testing, VK_ICD_FILENAMES shouldn't be defined.  For deqp-vk, this is
+        // useful, but not safe for multi-threaded tests.  For now, since this is only
+        // used for end2end tests, we should be good.
+        let vk_icd_name_opt = match std::env::var(VK_ICD_FILENAMES) {
+            Ok(vk_icd_name) => {
+                std::env::remove_var(VK_ICD_FILENAMES);
+                Some(vk_icd_name)
+            }
+            Err(_) => None,
+        };
+
+        let gralloc = Mutex::new(RutabagaGralloc::new(RutabagaGrallocBackendFlags::new()).unwrap());
+
+        if let Some(vk_icd_name) = vk_icd_name_opt {
+            std::env::set_var(VK_ICD_FILENAMES, vk_icd_name);
+        }
+
+        gralloc
+    })
+}
+
+pub struct VirtGpuResource {
+    resource_id: u32,
+    size: usize,
+    handle: RutabagaHandle,
+    attached_fences: Vec<RutabagaHandle>,
+    vulkan_info: VulkanInfo,
+    system_mapping: Option<RutabagaMemoryMapping>,
+    gpu_mapping: Option<Box<dyn RutabagaMappedRegion>>,
+}
+
+impl VirtGpuResource {
+    pub fn new(
+        resource_id: u32,
+        size: usize,
+        handle: RutabagaHandle,
+        vulkan_info: VulkanInfo,
+    ) -> VirtGpuResource {
+        VirtGpuResource {
+            resource_id,
+            size,
+            handle,
+            attached_fences: Vec::new(),
+            vulkan_info,
+            system_mapping: None,
+            gpu_mapping: None,
+        }
+    }
+}
+
+pub struct VirtGpuKumquat {
+    context_id: u32,
+    id_allocator: u32,
+    capset_mask: u64,
+    stream: RutabagaStream,
+    capsets: Map<u32, Vec<u8>>,
+    resources: Map<u32, VirtGpuResource>,
+}
+
+impl VirtGpuKumquat {
+    pub fn new(gpu_socket: &str) -> RutabagaResult<VirtGpuKumquat> {
+        let path = PathBuf::from(gpu_socket);
+        let connection = RutabagaTube::new(path)?;
+        let mut stream = RutabagaStream::new(connection);
+
+        let get_num_capsets = kumquat_gpu_protocol_ctrl_hdr {
+            type_: KUMQUAT_GPU_PROTOCOL_GET_NUM_CAPSETS,
+            ..Default::default()
+        };
+
+        stream.write(KumquatGpuProtocolWrite::Cmd(get_num_capsets))?;
+        let mut protocols = stream.read()?;
+        let num_capsets = match protocols.remove(0) {
+            KumquatGpuProtocol::RespNumCapsets(num) => num,
+            _ => return Err(RutabagaError::Unsupported),
+        };
+
+        let mut capset_mask = 0;
+        let mut capsets: Map<u32, Vec<u8>> = Default::default();
+        for capset_index in 0..num_capsets {
+            let get_capset_info = kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_GET_CAPSET_INFO,
+                payload: capset_index,
+            };
+
+            stream.write(KumquatGpuProtocolWrite::Cmd(get_capset_info))?;
+            protocols = stream.read()?;
+            let resp_capset_info = match protocols.remove(0) {
+                KumquatGpuProtocol::RespCapsetInfo(info) => info,
+                _ => return Err(RutabagaError::Unsupported),
+            };
+
+            let get_capset = kumquat_gpu_protocol_get_capset {
+                hdr: kumquat_gpu_protocol_ctrl_hdr {
+                    type_: KUMQUAT_GPU_PROTOCOL_GET_CAPSET,
+                    ..Default::default()
+                },
+                capset_id: resp_capset_info.capset_id,
+                capset_version: resp_capset_info.version,
+            };
+
+            stream.write(KumquatGpuProtocolWrite::Cmd(get_capset))?;
+            protocols = stream.read()?;
+            let capset = match protocols.remove(0) {
+                KumquatGpuProtocol::RespCapset(capset) => capset,
+                _ => return Err(RutabagaError::Unsupported),
+            };
+
+            capset_mask = 1u64 << resp_capset_info.capset_id | capset_mask;
+            capsets.insert(resp_capset_info.capset_id, capset);
+        }
+
+        Ok(VirtGpuKumquat {
+            context_id: 0,
+            id_allocator: 0,
+            capset_mask,
+            stream,
+            capsets,
+            resources: Default::default(),
+        })
+    }
+
+    pub fn allocate_id(&mut self) -> u32 {
+        self.id_allocator = self.id_allocator + 1;
+        self.id_allocator
+    }
+
+    pub fn get_param(&self, getparam: &mut VirtGpuParam) -> RutabagaResult<()> {
+        getparam.value = match getparam.param {
+            VIRTGPU_KUMQUAT_PARAM_3D_FEATURES => (self.capset_mask != 0) as u64,
+            VIRTGPU_KUMQUAT_PARAM_CAPSET_QUERY_FIX..=VIRTGPU_KUMQUAT_PARAM_CONTEXT_INIT => 1,
+            VIRTGPU_KUMQUAT_PARAM_SUPPORTED_CAPSET_IDS => self.capset_mask,
+            VIRTGPU_KUMQUAT_PARAM_EXPLICIT_DEBUG_NAME => 0,
+            VIRTGPU_KUMQUAT_PARAM_FENCE_PASSING => 1,
+            _ => return Err(RutabagaError::Unsupported),
+        };
+
+        Ok(())
+    }
+
+    pub fn get_caps(&self, capset_id: u32, slice: &mut [u8]) -> RutabagaResult<()> {
+        let caps = self
+            .capsets
+            .get(&capset_id)
+            .ok_or(RutabagaError::InvalidCapset)?;
+        let length = min(slice.len(), caps.len());
+        slice.copy_from_slice(&caps[0..length]);
+        Ok(())
+    }
+
+    pub fn context_create(&mut self, capset_id: u64, name: &str) -> RutabagaResult<u32> {
+        let mut debug_name = [0u8; 64];
+        debug_name
+            .iter_mut()
+            .zip(name.bytes())
+            .for_each(|(dst, src)| *dst = src);
+
+        let context_create = kumquat_gpu_protocol_ctx_create {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_CTX_CREATE,
+                ..Default::default()
+            },
+            nlen: 0,
+            context_init: capset_id.try_into()?,
+            debug_name,
+        };
+
+        self.stream
+            .write(KumquatGpuProtocolWrite::Cmd(context_create))?;
+        let mut protocols = self.stream.read()?;
+        self.context_id = match protocols.remove(0) {
+            KumquatGpuProtocol::RespContextCreate(ctx_id) => ctx_id,
+            _ => return Err(RutabagaError::Unsupported),
+        };
+
+        Ok(self.context_id)
+    }
+
+    pub fn resource_create_3d(
+        &mut self,
+        create_3d: &mut VirtGpuResourceCreate3D,
+    ) -> RutabagaResult<()> {
+        let resource_create_3d = kumquat_gpu_protocol_resource_create_3d {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_RESOURCE_CREATE_3D,
+                ..Default::default()
+            },
+            target: create_3d.target,
+            format: create_3d.format,
+            bind: create_3d.bind,
+            width: create_3d.width,
+            height: create_3d.height,
+            depth: create_3d.depth,
+            array_size: create_3d.array_size,
+            last_level: create_3d.last_level,
+            nr_samples: create_3d.nr_samples,
+            flags: create_3d.flags,
+            size: create_3d.size,
+            stride: create_3d.stride,
+            ctx_id: self.context_id,
+        };
+
+        self.stream
+            .write(KumquatGpuProtocolWrite::Cmd(resource_create_3d))?;
+        let mut protocols = self.stream.read()?;
+        let resource = match protocols.remove(0) {
+            KumquatGpuProtocol::RespResourceCreate(resp, handle) => {
+                let size: usize = create_3d.size.try_into()?;
+                VirtGpuResource::new(resp.resource_id, size, handle, resp.vulkan_info)
+            }
+            _ => return Err(RutabagaError::Unsupported),
+        };
+
+        create_3d.res_handle = resource.resource_id;
+        create_3d.bo_handle = self.allocate_id();
+        self.resources.insert(create_3d.bo_handle, resource);
+
+        Ok(())
+    }
+
+    pub fn resource_create_blob(
+        &mut self,
+        create_blob: &mut VirtGpuResourceCreateBlob,
+        blob_cmd: &[u8],
+    ) -> RutabagaResult<()> {
+        if blob_cmd.len() != 0 {
+            let submit_command = kumquat_gpu_protocol_cmd_submit {
+                hdr: kumquat_gpu_protocol_ctrl_hdr {
+                    type_: KUMQUAT_GPU_PROTOCOL_SUBMIT_3D,
+                    ..Default::default()
+                },
+                ctx_id: self.context_id,
+                pad: 0,
+                size: blob_cmd.len().try_into()?,
+                num_in_fences: 0,
+                flags: 0,
+                ring_idx: 0,
+                padding: Default::default(),
+            };
+
+            let mut data: Vec<u8> = vec![0; blob_cmd.len()];
+            data.copy_from_slice(blob_cmd);
+
+            self.stream
+                .write(KumquatGpuProtocolWrite::CmdWithData(submit_command, data))?;
+        }
+
+        let resource_create_blob = kumquat_gpu_protocol_resource_create_blob {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_RESOURCE_CREATE_BLOB,
+                ..Default::default()
+            },
+            ctx_id: self.context_id,
+            blob_mem: create_blob.blob_mem,
+            blob_flags: create_blob.blob_flags,
+            padding: 0,
+            blob_id: create_blob.blob_id,
+            size: create_blob.size,
+        };
+
+        self.stream
+            .write(KumquatGpuProtocolWrite::Cmd(resource_create_blob))?;
+        let mut protocols = self.stream.read()?;
+        let resource = match protocols.remove(0) {
+            KumquatGpuProtocol::RespResourceCreate(resp, handle) => {
+                let size: usize = create_blob.size.try_into()?;
+                VirtGpuResource::new(resp.resource_id, size, handle, resp.vulkan_info)
+            }
+            _ => {
+                return Err(RutabagaError::Unsupported);
+            }
+        };
+
+        create_blob.res_handle = resource.resource_id;
+        create_blob.bo_handle = self.allocate_id();
+        self.resources.insert(create_blob.bo_handle, resource);
+        Ok(())
+    }
+
+    pub fn resource_unref(&mut self, bo_handle: u32) -> RutabagaResult<()> {
+        let resource = self
+            .resources
+            .remove(&bo_handle)
+            .ok_or(RutabagaError::InvalidResourceId)?;
+
+        let detach_resource = kumquat_gpu_protocol_ctx_resource {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_CTX_DETACH_RESOURCE,
+                ..Default::default()
+            },
+            ctx_id: self.context_id,
+            resource_id: resource.resource_id,
+        };
+
+        self.stream
+            .write(KumquatGpuProtocolWrite::Cmd(detach_resource))?;
+
+        Ok(())
+    }
+
+    pub fn map(&mut self, bo_handle: u32) -> RutabagaResult<RutabagaMapping> {
+        let resource = self
+            .resources
+            .get_mut(&bo_handle)
+            .ok_or(RutabagaError::InvalidResourceId)?;
+
+        if let Some(ref system_mapping) = resource.system_mapping {
+            let rutabaga_mapping = system_mapping.as_rutabaga_mapping();
+            Ok(rutabaga_mapping)
+        } else if let Some(ref gpu_mapping) = resource.gpu_mapping {
+            let rutabaga_mapping = gpu_mapping.as_rutabaga_mapping();
+            Ok(rutabaga_mapping)
+        } else {
+            let clone = resource.handle.try_clone()?;
+
+            if clone.handle_type == RUTABAGA_MEM_HANDLE_TYPE_OPAQUE_FD {
+                let region = gralloc().lock().unwrap().import_and_map(
+                    clone,
+                    resource.vulkan_info,
+                    resource.size as u64,
+                )?;
+
+                let rutabaga_mapping = region.as_rutabaga_mapping();
+                resource.gpu_mapping = Some(region);
+                Ok(rutabaga_mapping)
+            } else {
+                let mapping = RutabagaMemoryMapping::from_safe_descriptor(
+                    clone.os_handle,
+                    resource.size,
+                    RUTABAGA_MAP_CACHE_CACHED | RUTABAGA_MAP_ACCESS_RW,
+                )?;
+
+                let rutabaga_mapping = mapping.as_rutabaga_mapping();
+                resource.system_mapping = Some(mapping);
+                Ok(rutabaga_mapping)
+            }
+        }
+    }
+
+    pub fn unmap(&mut self, bo_handle: u32) -> RutabagaResult<()> {
+        let resource = self
+            .resources
+            .get_mut(&bo_handle)
+            .ok_or(RutabagaError::InvalidResourceId)?;
+
+        resource.system_mapping = None;
+        resource.gpu_mapping = None;
+        Ok(())
+    }
+
+    pub fn transfer_to_host(&mut self, transfer: &VirtGpuTransfer) -> RutabagaResult<()> {
+        let resource = self
+            .resources
+            .get_mut(&transfer.bo_handle)
+            .ok_or(RutabagaError::InvalidResourceId)?;
+
+        // TODO(b/356504311): We should really move EventFd creation into rutabaga_os..
+        let owned: OwnedFd = EventFd::from_flags(EfdFlags::empty())?.into();
+        let eventfd: File = owned.into();
+
+        // SAFETY: Safe because the eventfd is valid and owned by us.
+        let emulated_fence = RutabagaHandle {
+            os_handle: unsafe {
+                RutabagaDescriptor::from_raw_descriptor(eventfd.into_raw_descriptor())
+            },
+            handle_type: RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD,
+        };
+
+        resource.attached_fences.push(emulated_fence.try_clone()?);
+
+        let transfer_to_host = kumquat_gpu_protocol_transfer_host_3d {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_TRANSFER_TO_HOST_3D,
+                ..Default::default()
+            },
+            box_: kumquat_gpu_protocol_box {
+                x: transfer._box.x,
+                y: transfer._box.y,
+                z: transfer._box.z,
+                w: transfer._box.w,
+                h: transfer._box.h,
+                d: transfer._box.d,
+            },
+            offset: transfer.offset,
+            level: transfer.level,
+            stride: transfer.stride,
+            layer_stride: transfer.layer_stride,
+            ctx_id: self.context_id,
+            resource_id: resource.resource_id,
+            padding: 0,
+        };
+
+        self.stream.write(KumquatGpuProtocolWrite::CmdWithHandle(
+            transfer_to_host,
+            emulated_fence,
+        ))?;
+        Ok(())
+    }
+
+    pub fn transfer_from_host(&mut self, transfer: &VirtGpuTransfer) -> RutabagaResult<()> {
+        let resource = self
+            .resources
+            .get_mut(&transfer.bo_handle)
+            .ok_or(RutabagaError::InvalidResourceId)?;
+
+        // TODO(b/356504311): We should really move EventFd creation into rutabaga_os..
+        let owned: OwnedFd = EventFd::from_flags(EfdFlags::empty())?.into();
+        let eventfd: File = owned.into();
+
+        // SAFETY: Safe because the eventfd is valid and owned by us.
+        let emulated_fence = RutabagaHandle {
+            os_handle: unsafe {
+                RutabagaDescriptor::from_raw_descriptor(eventfd.into_raw_descriptor())
+            },
+            handle_type: RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD,
+        };
+
+        resource.attached_fences.push(emulated_fence.try_clone()?);
+        let transfer_from_host = kumquat_gpu_protocol_transfer_host_3d {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_TRANSFER_FROM_HOST_3D,
+                ..Default::default()
+            },
+            box_: kumquat_gpu_protocol_box {
+                x: transfer._box.x,
+                y: transfer._box.y,
+                z: transfer._box.z,
+                w: transfer._box.w,
+                h: transfer._box.h,
+                d: transfer._box.d,
+            },
+            offset: transfer.offset,
+            level: transfer.level,
+            stride: transfer.stride,
+            layer_stride: transfer.layer_stride,
+            ctx_id: self.context_id,
+            resource_id: resource.resource_id,
+            padding: 0,
+        };
+
+        self.stream.write(KumquatGpuProtocolWrite::CmdWithHandle(
+            transfer_from_host,
+            emulated_fence,
+        ))?;
+
+        Ok(())
+    }
+
+    pub fn submit_command(
+        &mut self,
+        flags: u32,
+        bo_handles: &[u32],
+        cmd: &[u8],
+        ring_idx: u32,
+        in_fences: &[u64],
+        raw_descriptor: &mut RutabagaRawDescriptor,
+    ) -> RutabagaResult<()> {
+        let mut fence_opt: Option<RutabagaHandle> = None;
+        let mut data: Vec<u8> = vec![0; cmd.len()];
+        let mut host_flags = 0;
+
+        if flags & VIRTGPU_KUMQUAT_EXECBUF_RING_IDX != 0 {
+            host_flags = RUTABAGA_FLAG_INFO_RING_IDX;
+        }
+
+        let need_fence =
+            bo_handles.len() != 0 || (flags & VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_OUT) != 0;
+
+        let actual_fence = (flags & VIRTGPU_KUMQUAT_EXECBUF_SHAREABLE_OUT) != 0
+            && (flags & VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_OUT) != 0;
+
+        // Should copy from in-fences when gfxstream supports it.
+        data.copy_from_slice(cmd);
+
+        if actual_fence {
+            host_flags |= RUTABAGA_FLAG_FENCE_HOST_SHAREABLE;
+            host_flags |= RUTABAGA_FLAG_FENCE;
+        } else if need_fence {
+            host_flags |= RUTABAGA_FLAG_FENCE;
+        }
+
+        let submit_command = kumquat_gpu_protocol_cmd_submit {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_SUBMIT_3D,
+                ..Default::default()
+            },
+            ctx_id: self.context_id,
+            pad: 0,
+            size: cmd.len().try_into()?,
+            num_in_fences: in_fences.len().try_into()?,
+            flags: host_flags,
+            ring_idx: ring_idx.try_into()?,
+            padding: Default::default(),
+        };
+
+        if need_fence {
+            self.stream
+                .write(KumquatGpuProtocolWrite::CmdWithData(submit_command, data))?;
+
+            let mut protocols = self.stream.read()?;
+            let fence = match protocols.remove(0) {
+                KumquatGpuProtocol::RespCmdSubmit3d(_fence_id, handle) => handle,
+                _ => {
+                    return Err(RutabagaError::Unsupported);
+                }
+            };
+
+            for handle in bo_handles {
+                // We could support implicit sync with real fences, but the need does not exist.
+                if actual_fence {
+                    return Err(RutabagaError::Unsupported);
+                }
+
+                let resource = self
+                    .resources
+                    .get_mut(handle)
+                    .ok_or(RutabagaError::InvalidResourceId)?;
+
+                resource.attached_fences.push(fence.try_clone()?);
+            }
+
+            fence_opt = Some(fence);
+        } else {
+            self.stream
+                .write(KumquatGpuProtocolWrite::CmdWithData(submit_command, data))?;
+        }
+
+        if flags & VIRTGPU_KUMQUAT_EXECBUF_FENCE_FD_OUT != 0 {
+            *raw_descriptor = fence_opt
+                .ok_or(RutabagaError::SpecViolation("no fence found"))?
+                .os_handle
+                .into_raw_descriptor();
+        }
+
+        Ok(())
+    }
+
+    pub fn wait(&mut self, bo_handle: u32) -> RutabagaResult<()> {
+        let resource = self
+            .resources
+            .get_mut(&bo_handle)
+            .ok_or(RutabagaError::InvalidResourceId)?;
+
+        let new_fences: Vec<RutabagaHandle> = std::mem::take(&mut resource.attached_fences);
+        for fence in new_fences {
+            let file = unsafe { File::from_raw_descriptor(fence.os_handle.into_raw_descriptor()) };
+            read(file.as_raw_fd(), &mut 1u64.to_ne_bytes())?;
+        }
+
+        Ok(())
+    }
+
+    pub fn resource_export(
+        &mut self,
+        bo_handle: u32,
+        flags: u32,
+    ) -> RutabagaResult<RutabagaHandle> {
+        let resource = self
+            .resources
+            .get_mut(&bo_handle)
+            .ok_or(RutabagaError::InvalidResourceId)?;
+
+        if flags & VIRTGPU_KUMQUAT_EMULATED_EXPORT != 0 {
+            let descriptor: RutabagaDescriptor =
+                RutabagaSharedMemory::new("virtgpu_export", VIRTGPU_KUMQUAT_PAGE_SIZE as u64)?
+                    .into();
+
+            let clone = descriptor.try_clone()?;
+
+            // Creating the mapping closes the cloned descriptor.
+            let mapping = RutabagaMemoryMapping::from_safe_descriptor(
+                clone,
+                VIRTGPU_KUMQUAT_PAGE_SIZE,
+                RUTABAGA_MAP_CACHE_CACHED | RUTABAGA_MAP_ACCESS_RW,
+            )?;
+            let rutabaga_mapping = mapping.as_rutabaga_mapping();
+
+            let mut slice: &mut [u8] = unsafe {
+                from_raw_parts_mut(rutabaga_mapping.ptr as *mut u8, VIRTGPU_KUMQUAT_PAGE_SIZE)
+            };
+            let mut writer = RutabagaWriter::new(&mut slice);
+            writer.write_obj(resource.resource_id)?;
+
+            // Opaque to users of this API, shared memory internally
+            Ok(RutabagaHandle {
+                os_handle: descriptor,
+                handle_type: RUTABAGA_MEM_HANDLE_TYPE_OPAQUE_FD,
+            })
+        } else {
+            let clone = resource.handle.try_clone()?;
+            Ok(clone)
+        }
+    }
+
+    pub fn resource_import(
+        &mut self,
+        handle: RutabagaHandle,
+        bo_handle: &mut u32,
+        resource_handle: &mut u32,
+        size: &mut u64,
+    ) -> RutabagaResult<()> {
+        let clone = handle.try_clone()?;
+        let mapping = RutabagaMemoryMapping::from_safe_descriptor(
+            clone.os_handle,
+            VIRTGPU_KUMQUAT_PAGE_SIZE,
+            RUTABAGA_MAP_CACHE_CACHED | RUTABAGA_MAP_ACCESS_RW,
+        )?;
+
+        let rutabaga_mapping = mapping.as_rutabaga_mapping();
+
+        let mut slice: &mut [u8] = unsafe {
+            from_raw_parts_mut(rutabaga_mapping.ptr as *mut u8, VIRTGPU_KUMQUAT_PAGE_SIZE)
+        };
+
+        let mut reader = RutabagaReader::new(&mut slice);
+        *resource_handle = reader.read_obj()?;
+
+        let attach_resource = kumquat_gpu_protocol_ctx_resource {
+            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_CTX_ATTACH_RESOURCE,
+                ..Default::default()
+            },
+            ctx_id: self.context_id,
+            resource_id: *resource_handle,
+        };
+
+        self.stream
+            .write(KumquatGpuProtocolWrite::Cmd(attach_resource))?;
+        let resource = VirtGpuResource::new(
+            *resource_handle,
+            VIRTGPU_KUMQUAT_PAGE_SIZE,
+            handle,
+            Default::default(),
+        );
+
+        *bo_handle = self.allocate_id();
+        // Should ask the server about the size long-term.
+        *size = VIRTGPU_KUMQUAT_PAGE_SIZE as u64;
+        self.resources.insert(*bo_handle, resource);
+
+        Ok(())
+    }
+
+    pub fn snapshot(&mut self) -> RutabagaResult<()> {
+        let snapshot_save = kumquat_gpu_protocol_ctrl_hdr {
+            type_: KUMQUAT_GPU_PROTOCOL_SNAPSHOT_SAVE,
+            ..Default::default()
+        };
+
+        self.stream
+            .write(KumquatGpuProtocolWrite::Cmd(snapshot_save))?;
+
+        let mut protocols = self.stream.read()?;
+        match protocols.remove(0) {
+            KumquatGpuProtocol::RespOkSnapshot => Ok(()),
+            _ => Err(RutabagaError::Unsupported),
+        }
+    }
+
+    pub fn restore(&mut self) -> RutabagaResult<()> {
+        let snapshot_restore = kumquat_gpu_protocol_ctrl_hdr {
+            type_: KUMQUAT_GPU_PROTOCOL_SNAPSHOT_RESTORE,
+            ..Default::default()
+        };
+
+        self.stream
+            .write(KumquatGpuProtocolWrite::Cmd(snapshot_restore))?;
+
+        let mut protocols = self.stream.read()?;
+        match protocols.remove(0) {
+            KumquatGpuProtocol::RespOkSnapshot => Ok(()),
+            _ => Err(RutabagaError::Unsupported),
+        }
+    }
+}
+
+impl Drop for VirtGpuKumquat {
+    fn drop(&mut self) {
+        if self.context_id != 0 {
+            for (_, resource) in self.resources.iter() {
+                let detach_resource = kumquat_gpu_protocol_ctx_resource {
+                    hdr: kumquat_gpu_protocol_ctrl_hdr {
+                        type_: KUMQUAT_GPU_PROTOCOL_CTX_DETACH_RESOURCE,
+                        ..Default::default()
+                    },
+                    ctx_id: self.context_id,
+                    resource_id: resource.resource_id,
+                };
+
+                let _ = self
+                    .stream
+                    .write(KumquatGpuProtocolWrite::Cmd(detach_resource));
+            }
+
+            self.resources.clear();
+            let context_destroy = kumquat_gpu_protocol_ctrl_hdr {
+                type_: KUMQUAT_GPU_PROTOCOL_CTX_DESTROY,
+                payload: self.context_id,
+            };
+
+            let _ = self
+                .stream
+                .write(KumquatGpuProtocolWrite::Cmd(context_destroy));
+        }
+    }
+}
diff --git a/rutabaga_gfx/ffi/Android.bp b/rutabaga_gfx/kumquat/server/Android.bp
similarity index 71%
rename from rutabaga_gfx/ffi/Android.bp
rename to rutabaga_gfx/kumquat/server/Android.bp
index bf80c202e..98f37e3ac 100644
--- a/rutabaga_gfx/ffi/Android.bp
+++ b/rutabaga_gfx/kumquat/server/Android.bp
@@ -7,19 +7,22 @@ package {
     default_applicable_licenses: ["external_crosvm_license"],
 }
 
-cc_library_headers {
-    name: "rutabaga_gfx_ffi_headers",
+rust_binary {
+    name: "kumquat",
+    crate_name: "kumquat",
     host_supported: true,
     vendor_available: true,
-    export_include_dirs: ["src/include"],
-}
-
-rust_ffi_shared {
-    name: "librutabaga_gfx_ffi",
-    crate_name: "rutabaga_gfx_ffi",
-    host_supported: true,
-    vendor_available: true,
-    srcs: ["src/lib.rs"],
+    prefer_rlib: true,
+    cargo_env_compat: true,
+    crate_root: "src/main.rs",
+    cargo_pkg_version: "0.1.3",
+    edition: "2021",
+    cfgs: [
+        "gfxstream_unstable",
+    ],
+    features: [
+        "gfxstream",
+    ],
     rustlibs: [
         "librutabaga_gfx_gfxstream",
         "liblibc",
@@ -27,6 +30,7 @@ rust_ffi_shared {
         "libnix",
         "libthiserror",
         "libzerocopy",
+        "libclap",
     ],
     shared_libs: [
         "libgfxstream_backend",
diff --git a/rutabaga_gfx/kumquat/server/Cargo.toml b/rutabaga_gfx/kumquat/server/Cargo.toml
new file mode 100644
index 000000000..d71af60d0
--- /dev/null
+++ b/rutabaga_gfx/kumquat/server/Cargo.toml
@@ -0,0 +1,27 @@
+[package]
+name = "kumquat"
+version = "0.1.3"
+authors = ["Android Open Source Project"]
+edition = "2021"
+description = "Handling virtio multi-media protocols via a Rust server"
+license-file = "LICENSE"
+
+[[bin]]
+name = "kumquat"
+path = "src/main.rs"
+
+[features]
+gfxstream = ["rutabaga_gfx/gfxstream"]
+
+[dependencies]
+rutabaga_gfx = { path = "../../", version = "0.1.3"}
+nix = { version = "0.28", features = ["event", "feature", "fs", "mman", "socket", "uio", "ioctl"] }
+zerocopy = { version = "0.7", features = ["derive"] }
+log = "0.4"
+clap = { version = "4.1.8", features = ["derive"] }
+
+[profile.dev]
+lto = true
+incremental = false
+
+[workspace]
diff --git a/rutabaga_gfx/kumquat/server/src/kumquat.rs b/rutabaga_gfx/kumquat/server/src/kumquat.rs
new file mode 100644
index 000000000..6cfcc9487
--- /dev/null
+++ b/rutabaga_gfx/kumquat/server/src/kumquat.rs
@@ -0,0 +1,73 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::collections::btree_map::Entry;
+use std::collections::BTreeMap as Map;
+use std::time::Duration;
+
+use rutabaga_gfx::kumquat_support::RutabagaWaitContext;
+use rutabaga_gfx::RutabagaError;
+use rutabaga_gfx::RutabagaResult;
+
+use crate::kumquat_gpu::KumquatGpu;
+use crate::kumquat_gpu::KumquatGpuConnection;
+
+pub struct Kumquat {
+    kumquat_gpu: KumquatGpu,
+    wait_ctx: RutabagaWaitContext,
+    connections: Map<u64, KumquatGpuConnection>,
+}
+
+impl Kumquat {
+    pub fn new(capset_names: String, renderer_features: String) -> RutabagaResult<Kumquat> {
+        Ok(Kumquat {
+            kumquat_gpu: KumquatGpu::new(capset_names, renderer_features)?,
+            wait_ctx: RutabagaWaitContext::new()?,
+            connections: Default::default(),
+        })
+    }
+
+    pub fn add_connection(
+        &mut self,
+        connection_id: u64,
+        connection: KumquatGpuConnection,
+    ) -> RutabagaResult<()> {
+        let _ = self.wait_ctx.add(connection_id, &connection);
+        self.connections.insert(connection_id, connection);
+        Ok(())
+    }
+
+    pub fn run(&mut self) -> RutabagaResult<()> {
+        if self.connections.is_empty() {
+            return Ok(());
+        }
+
+        // TODO(b/356504311): This is necessary in case client B connects to the socket when the
+        // thread is waiting on a client A command (which never happens without client B). The
+        // correct solution would be to add the listner to the WaitContext in the future.
+        let events = self.wait_ctx.wait(Some(Duration::from_millis(100)))?;
+        for event in events {
+            let mut hung_up = false;
+            match self.connections.entry(event.connection_id) {
+                Entry::Occupied(mut o) => {
+                    let connection = o.get_mut();
+                    if event.readable {
+                        hung_up =
+                            !connection.process_command(&mut self.kumquat_gpu)? && event.hung_up;
+                    }
+
+                    if hung_up {
+                        self.wait_ctx.delete(&connection)?;
+                        o.remove_entry();
+                    }
+                }
+                Entry::Vacant(_) => {
+                    return Err(RutabagaError::SpecViolation("no connection found"))
+                }
+            }
+        }
+
+        Ok(())
+    }
+}
diff --git a/rutabaga_gfx/kumquat/server/src/kumquat_gpu/mod.rs b/rutabaga_gfx/kumquat/server/src/kumquat_gpu/mod.rs
new file mode 100644
index 000000000..45f379485
--- /dev/null
+++ b/rutabaga_gfx/kumquat/server/src/kumquat_gpu/mod.rs
@@ -0,0 +1,516 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::collections::btree_map::Entry;
+use std::collections::BTreeMap as Map;
+use std::collections::BTreeSet as Set;
+use std::fs::File;
+use std::io::Cursor;
+use std::io::Write;
+use std::os::fd::AsFd;
+use std::os::fd::BorrowedFd;
+use std::os::fd::OwnedFd;
+use std::os::raw::c_void;
+use std::sync::Arc;
+use std::sync::Mutex;
+
+use log::error;
+use nix::sys::eventfd::EfdFlags;
+use nix::sys::eventfd::EventFd;
+use rutabaga_gfx::calculate_capset_mask;
+use rutabaga_gfx::kumquat_support::kumquat_gpu_protocol::*;
+use rutabaga_gfx::kumquat_support::RutabagaMemoryMapping;
+use rutabaga_gfx::kumquat_support::RutabagaSharedMemory;
+use rutabaga_gfx::kumquat_support::RutabagaStream;
+use rutabaga_gfx::kumquat_support::RutabagaTube;
+use rutabaga_gfx::ResourceCreate3D;
+use rutabaga_gfx::ResourceCreateBlob;
+use rutabaga_gfx::Rutabaga;
+use rutabaga_gfx::RutabagaBuilder;
+use rutabaga_gfx::RutabagaComponentType;
+use rutabaga_gfx::RutabagaDescriptor;
+use rutabaga_gfx::RutabagaError;
+use rutabaga_gfx::RutabagaFence;
+use rutabaga_gfx::RutabagaFenceHandler;
+use rutabaga_gfx::RutabagaFromRawDescriptor;
+use rutabaga_gfx::RutabagaHandle;
+use rutabaga_gfx::RutabagaIntoRawDescriptor;
+use rutabaga_gfx::RutabagaIovec;
+use rutabaga_gfx::RutabagaResult;
+use rutabaga_gfx::RutabagaWsi;
+use rutabaga_gfx::Transfer3D;
+use rutabaga_gfx::VulkanInfo;
+use rutabaga_gfx::RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD;
+use rutabaga_gfx::RUTABAGA_FLAG_FENCE;
+use rutabaga_gfx::RUTABAGA_FLAG_FENCE_HOST_SHAREABLE;
+use rutabaga_gfx::RUTABAGA_MAP_ACCESS_RW;
+use rutabaga_gfx::RUTABAGA_MAP_CACHE_CACHED;
+use rutabaga_gfx::RUTABAGA_MEM_HANDLE_TYPE_SHM;
+
+const SNAPSHOT_DIR: &str = "/tmp/";
+
+pub struct KumquatGpuConnection {
+    stream: RutabagaStream,
+}
+
+pub struct KumquatGpuResource {
+    attached_contexts: Set<u32>,
+    mapping: Option<RutabagaMemoryMapping>,
+}
+
+pub struct FenceData {
+    pub pending_fences: Map<u64, RutabagaHandle>,
+}
+
+pub type FenceState = Arc<Mutex<FenceData>>;
+
+pub fn create_fence_handler(fence_state: FenceState) -> RutabagaFenceHandler {
+    RutabagaFenceHandler::new(move |completed_fence: RutabagaFence| {
+        let mut state = fence_state.lock().unwrap();
+        match (*state).pending_fences.entry(completed_fence.fence_id) {
+            Entry::Occupied(o) => {
+                let (_, signaled_fence) = o.remove_entry();
+                let mut file = unsafe {
+                    File::from_raw_descriptor(signaled_fence.os_handle.into_raw_descriptor())
+                };
+                file.write(&mut 1u64.to_ne_bytes()).unwrap();
+            }
+            Entry::Vacant(_) => {
+                // This is fine, since an actual fence doesn't create emulated sync
+                // entry
+            }
+        }
+    })
+}
+
+pub struct KumquatGpu {
+    rutabaga: Rutabaga,
+    fence_state: FenceState,
+    snapshot_buffer: Cursor<Vec<u8>>,
+    id_allocator: u32,
+    resources: Map<u32, KumquatGpuResource>,
+}
+
+impl KumquatGpu {
+    pub fn new(capset_names: String, renderer_features: String) -> RutabagaResult<KumquatGpu> {
+        let capset_mask = calculate_capset_mask(capset_names.as_str().split(":"));
+        let fence_state = Arc::new(Mutex::new(FenceData {
+            pending_fences: Default::default(),
+        }));
+
+        let fence_handler = create_fence_handler(fence_state.clone());
+
+        let renderer_features_opt = if renderer_features.is_empty() {
+            None
+        } else {
+            Some(renderer_features)
+        };
+
+        let rutabaga = RutabagaBuilder::new(RutabagaComponentType::CrossDomain, capset_mask)
+            .set_use_external_blob(true)
+            .set_use_egl(true)
+            .set_wsi(RutabagaWsi::Surfaceless)
+            .set_renderer_features(renderer_features_opt)
+            .build(fence_handler, None)?;
+
+        Ok(KumquatGpu {
+            rutabaga,
+            fence_state,
+            snapshot_buffer: Cursor::new(Vec::new()),
+            id_allocator: 0,
+            resources: Default::default(),
+        })
+    }
+
+    pub fn allocate_id(&mut self) -> u32 {
+        self.id_allocator = self.id_allocator + 1;
+        self.id_allocator
+    }
+}
+
+impl KumquatGpuConnection {
+    pub fn new(connection: RutabagaTube) -> KumquatGpuConnection {
+        KumquatGpuConnection {
+            stream: RutabagaStream::new(connection),
+        }
+    }
+
+    pub fn process_command(&mut self, kumquat_gpu: &mut KumquatGpu) -> RutabagaResult<bool> {
+        let mut hung_up = false;
+        let protocols = self.stream.read()?;
+
+        for protocol in protocols {
+            match protocol {
+                KumquatGpuProtocol::GetNumCapsets => {
+                    let resp = kumquat_gpu_protocol_ctrl_hdr {
+                        type_: KUMQUAT_GPU_PROTOCOL_RESP_NUM_CAPSETS,
+                        payload: kumquat_gpu.rutabaga.get_num_capsets(),
+                    };
+
+                    self.stream.write(KumquatGpuProtocolWrite::Cmd(resp))?;
+                }
+                KumquatGpuProtocol::GetCapsetInfo(capset_index) => {
+                    let (capset_id, version, size) =
+                        kumquat_gpu.rutabaga.get_capset_info(capset_index)?;
+
+                    let resp = kumquat_gpu_protocol_resp_capset_info {
+                        hdr: kumquat_gpu_protocol_ctrl_hdr {
+                            type_: KUMQUAT_GPU_PROTOCOL_RESP_CAPSET_INFO,
+                            ..Default::default()
+                        },
+                        capset_id,
+                        version,
+                        size,
+                        ..Default::default()
+                    };
+
+                    self.stream.write(KumquatGpuProtocolWrite::Cmd(resp))?;
+                }
+                KumquatGpuProtocol::GetCapset(cmd) => {
+                    let capset = kumquat_gpu
+                        .rutabaga
+                        .get_capset(cmd.capset_id, cmd.capset_version)?;
+
+                    let resp = kumquat_gpu_protocol_ctrl_hdr {
+                        type_: KUMQUAT_GPU_PROTOCOL_RESP_CAPSET,
+                        payload: capset.len().try_into()?,
+                    };
+
+                    self.stream
+                        .write(KumquatGpuProtocolWrite::CmdWithData(resp, capset))?;
+                }
+                KumquatGpuProtocol::CtxCreate(cmd) => {
+                    let context_id = kumquat_gpu.allocate_id();
+                    let context_name: Option<String> =
+                        String::from_utf8(cmd.debug_name.to_vec()).ok();
+
+                    kumquat_gpu.rutabaga.create_context(
+                        context_id,
+                        cmd.context_init,
+                        context_name.as_deref(),
+                    )?;
+
+                    let resp = kumquat_gpu_protocol_ctrl_hdr {
+                        type_: KUMQUAT_GPU_PROTOCOL_RESP_CONTEXT_CREATE,
+                        payload: context_id,
+                    };
+
+                    self.stream.write(KumquatGpuProtocolWrite::Cmd(resp))?;
+                }
+                KumquatGpuProtocol::CtxDestroy(ctx_id) => {
+                    kumquat_gpu.rutabaga.destroy_context(ctx_id)?;
+                }
+                KumquatGpuProtocol::CtxAttachResource(cmd) => {
+                    kumquat_gpu
+                        .rutabaga
+                        .context_attach_resource(cmd.ctx_id, cmd.resource_id)?;
+                }
+                KumquatGpuProtocol::CtxDetachResource(cmd) => {
+                    kumquat_gpu
+                        .rutabaga
+                        .context_detach_resource(cmd.ctx_id, cmd.resource_id)?;
+
+                    let mut resource = kumquat_gpu
+                        .resources
+                        .remove(&cmd.resource_id)
+                        .ok_or(RutabagaError::InvalidResourceId)?;
+
+                    resource.attached_contexts.remove(&cmd.ctx_id);
+                    if resource.attached_contexts.len() == 0 {
+                        if resource.mapping.is_some() {
+                            kumquat_gpu.rutabaga.detach_backing(cmd.resource_id)?;
+                        }
+
+                        kumquat_gpu.rutabaga.unref_resource(cmd.resource_id)?;
+                    } else {
+                        kumquat_gpu.resources.insert(cmd.resource_id, resource);
+                    }
+                }
+                KumquatGpuProtocol::ResourceCreate3d(cmd) => {
+                    let resource_create_3d = ResourceCreate3D {
+                        target: cmd.target,
+                        format: cmd.format,
+                        bind: cmd.bind,
+                        width: cmd.width,
+                        height: cmd.height,
+                        depth: cmd.depth,
+                        array_size: cmd.array_size,
+                        last_level: cmd.last_level,
+                        nr_samples: cmd.nr_samples,
+                        flags: cmd.flags,
+                    };
+
+                    let size = cmd.size as usize;
+                    let descriptor: RutabagaDescriptor =
+                        RutabagaSharedMemory::new("rutabaga_server", size as u64)?.into();
+
+                    let clone = descriptor.try_clone()?;
+                    let mut vecs: Vec<RutabagaIovec> = Vec::new();
+
+                    // Creating the mapping closes the cloned descriptor.
+                    let mapping = RutabagaMemoryMapping::from_safe_descriptor(
+                        clone,
+                        size,
+                        RUTABAGA_MAP_CACHE_CACHED | RUTABAGA_MAP_ACCESS_RW,
+                    )?;
+                    let rutabaga_mapping = mapping.as_rutabaga_mapping();
+
+                    vecs.push(RutabagaIovec {
+                        base: rutabaga_mapping.ptr as *mut c_void,
+                        len: size,
+                    });
+
+                    let resource_id = kumquat_gpu.allocate_id();
+
+                    kumquat_gpu
+                        .rutabaga
+                        .resource_create_3d(resource_id, resource_create_3d)?;
+
+                    kumquat_gpu.rutabaga.attach_backing(resource_id, vecs)?;
+                    kumquat_gpu.resources.insert(
+                        resource_id,
+                        KumquatGpuResource {
+                            attached_contexts: Default::default(),
+                            mapping: Some(mapping),
+                        },
+                    );
+
+                    kumquat_gpu
+                        .rutabaga
+                        .context_attach_resource(cmd.ctx_id, resource_id)?;
+
+                    let resp = kumquat_gpu_protocol_resp_resource_create {
+                        hdr: kumquat_gpu_protocol_ctrl_hdr {
+                            type_: KUMQUAT_GPU_PROTOCOL_RESP_RESOURCE_CREATE,
+                            ..Default::default()
+                        },
+                        resource_id,
+                        ..Default::default()
+                    };
+
+                    self.stream.write(KumquatGpuProtocolWrite::CmdWithHandle(
+                        resp,
+                        RutabagaHandle {
+                            os_handle: descriptor,
+                            handle_type: RUTABAGA_MEM_HANDLE_TYPE_SHM,
+                        },
+                    ))?;
+                }
+                KumquatGpuProtocol::TransferToHost3d(cmd, emulated_fence) => {
+                    let resource_id = cmd.resource_id;
+
+                    let transfer = Transfer3D {
+                        x: cmd.box_.x,
+                        y: cmd.box_.y,
+                        z: cmd.box_.z,
+                        w: cmd.box_.w,
+                        h: cmd.box_.h,
+                        d: cmd.box_.d,
+                        level: cmd.level,
+                        stride: cmd.stride,
+                        layer_stride: cmd.layer_stride,
+                        offset: cmd.offset,
+                    };
+
+                    kumquat_gpu
+                        .rutabaga
+                        .transfer_write(cmd.ctx_id, resource_id, transfer)?;
+
+                    // SAFETY: Safe because the emulated fence and owned by us.
+                    let mut file = unsafe {
+                        File::from_raw_descriptor(emulated_fence.os_handle.into_raw_descriptor())
+                    };
+
+                    // TODO(b/356504311): An improvement would be `impl From<RutabagaHandle> for
+                    // RutabagaEvent` + `RutabagaEvent::signal`
+                    file.write(&mut 1u64.to_ne_bytes())?;
+                }
+                KumquatGpuProtocol::TransferFromHost3d(cmd, emulated_fence) => {
+                    let resource_id = cmd.resource_id;
+
+                    let transfer = Transfer3D {
+                        x: cmd.box_.x,
+                        y: cmd.box_.y,
+                        z: cmd.box_.z,
+                        w: cmd.box_.w,
+                        h: cmd.box_.h,
+                        d: cmd.box_.d,
+                        level: cmd.level,
+                        stride: cmd.stride,
+                        layer_stride: cmd.layer_stride,
+                        offset: cmd.offset,
+                    };
+
+                    kumquat_gpu
+                        .rutabaga
+                        .transfer_read(cmd.ctx_id, resource_id, transfer, None)?;
+
+                    // SAFETY: Safe because the emulated fence and owned by us.
+                    let mut file = unsafe {
+                        File::from_raw_descriptor(emulated_fence.os_handle.into_raw_descriptor())
+                    };
+
+                    // TODO(b/356504311): An improvement would be `impl From<RutabagaHandle> for
+                    // RutabagaEvent` + `RutabagaEvent::signal`
+                    file.write(&mut 1u64.to_ne_bytes())?;
+                }
+                KumquatGpuProtocol::CmdSubmit3d(cmd, mut cmd_buf, fence_ids) => {
+                    kumquat_gpu.rutabaga.submit_command(
+                        cmd.ctx_id,
+                        &mut cmd_buf[..],
+                        &fence_ids[..],
+                    )?;
+
+                    if cmd.flags & RUTABAGA_FLAG_FENCE != 0 {
+                        let fence_id = kumquat_gpu.allocate_id() as u64;
+                        let fence = RutabagaFence {
+                            flags: cmd.flags,
+                            fence_id,
+                            ctx_id: cmd.ctx_id,
+                            ring_idx: cmd.ring_idx,
+                        };
+
+                        let mut fence_descriptor_opt: Option<RutabagaHandle> = None;
+                        let actual_fence = cmd.flags & RUTABAGA_FLAG_FENCE_HOST_SHAREABLE != 0;
+                        if !actual_fence {
+                            // This code should really be rutabaga_os.
+                            let owned: OwnedFd = EventFd::from_flags(EfdFlags::empty())?.into();
+                            let eventfd: File = owned.into();
+
+                            let emulated_fence = RutabagaHandle {
+                                os_handle: unsafe {
+                                    RutabagaDescriptor::from_raw_descriptor(
+                                        eventfd.into_raw_descriptor(),
+                                    )
+                                },
+                                handle_type: RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD,
+                            };
+
+                            fence_descriptor_opt = Some(emulated_fence.try_clone()?);
+                            let mut fence_state = kumquat_gpu.fence_state.lock().unwrap();
+                            (*fence_state)
+                                .pending_fences
+                                .insert(fence_id, emulated_fence);
+                        }
+
+                        kumquat_gpu.rutabaga.create_fence(fence)?;
+
+                        if actual_fence {
+                            fence_descriptor_opt =
+                                Some(kumquat_gpu.rutabaga.export_fence(fence_id)?);
+                            kumquat_gpu.rutabaga.destroy_fences(&[fence_id])?;
+                        }
+
+                        let fence_descriptor = fence_descriptor_opt
+                            .ok_or(RutabagaError::SpecViolation("No fence descriptor"))?;
+
+                        let resp = kumquat_gpu_protocol_resp_cmd_submit_3d {
+                            hdr: kumquat_gpu_protocol_ctrl_hdr {
+                                type_: KUMQUAT_GPU_PROTOCOL_RESP_CMD_SUBMIT_3D,
+                                ..Default::default()
+                            },
+                            fence_id,
+                            handle_type: fence_descriptor.handle_type,
+                            ..Default::default()
+                        };
+
+                        self.stream.write(KumquatGpuProtocolWrite::CmdWithHandle(
+                            resp,
+                            fence_descriptor,
+                        ))?;
+                    }
+                }
+                KumquatGpuProtocol::ResourceCreateBlob(cmd) => {
+                    let resource_id = kumquat_gpu.allocate_id();
+
+                    let resource_create_blob = ResourceCreateBlob {
+                        blob_mem: cmd.blob_mem,
+                        blob_flags: cmd.blob_flags,
+                        blob_id: cmd.blob_id,
+                        size: cmd.size,
+                    };
+
+                    kumquat_gpu.rutabaga.resource_create_blob(
+                        cmd.ctx_id,
+                        resource_id,
+                        resource_create_blob,
+                        None,
+                        None,
+                    )?;
+
+                    let handle = kumquat_gpu.rutabaga.export_blob(resource_id)?;
+                    let mut vk_info: VulkanInfo = Default::default();
+                    if let Ok(vulkan_info) = kumquat_gpu.rutabaga.vulkan_info(resource_id) {
+                        vk_info = vulkan_info;
+                    }
+
+                    kumquat_gpu.resources.insert(
+                        resource_id,
+                        KumquatGpuResource {
+                            attached_contexts: Set::from([cmd.ctx_id]),
+                            mapping: None,
+                        },
+                    );
+
+                    let resp = kumquat_gpu_protocol_resp_resource_create {
+                        hdr: kumquat_gpu_protocol_ctrl_hdr {
+                            type_: KUMQUAT_GPU_PROTOCOL_RESP_RESOURCE_CREATE,
+                            ..Default::default()
+                        },
+                        resource_id,
+                        handle_type: handle.handle_type,
+                        vulkan_info: vk_info,
+                    };
+
+                    self.stream
+                        .write(KumquatGpuProtocolWrite::CmdWithHandle(resp, handle))?;
+
+                    kumquat_gpu
+                        .rutabaga
+                        .context_attach_resource(cmd.ctx_id, resource_id)?;
+                }
+                KumquatGpuProtocol::SnapshotSave => {
+                    kumquat_gpu.snapshot_buffer.set_position(0);
+                    kumquat_gpu
+                        .rutabaga
+                        .snapshot(&mut kumquat_gpu.snapshot_buffer, SNAPSHOT_DIR)?;
+
+                    let resp = kumquat_gpu_protocol_ctrl_hdr {
+                        type_: KUMQUAT_GPU_PROTOCOL_RESP_OK_SNAPSHOT,
+                        payload: 0,
+                    };
+
+                    self.stream.write(KumquatGpuProtocolWrite::Cmd(resp))?;
+                }
+                KumquatGpuProtocol::SnapshotRestore => {
+                    kumquat_gpu
+                        .rutabaga
+                        .restore(&mut kumquat_gpu.snapshot_buffer, SNAPSHOT_DIR)?;
+
+                    let resp = kumquat_gpu_protocol_ctrl_hdr {
+                        type_: KUMQUAT_GPU_PROTOCOL_RESP_OK_SNAPSHOT,
+                        payload: 0,
+                    };
+
+                    self.stream.write(KumquatGpuProtocolWrite::Cmd(resp))?;
+                }
+                KumquatGpuProtocol::OkNoData => {
+                    hung_up = true;
+                }
+                _ => {
+                    error!("Unsupported protocol {:?}", protocol);
+                    return Err(RutabagaError::Unsupported);
+                }
+            };
+        }
+
+        Ok(hung_up)
+    }
+}
+
+impl AsFd for KumquatGpuConnection {
+    fn as_fd(&self) -> BorrowedFd<'_> {
+        self.stream.as_borrowed_file()
+    }
+}
diff --git a/rutabaga_gfx/kumquat/server/src/main.rs b/rutabaga_gfx/kumquat/server/src/main.rs
new file mode 100644
index 000000000..e1c285a32
--- /dev/null
+++ b/rutabaga_gfx/kumquat/server/src/main.rs
@@ -0,0 +1,78 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+mod kumquat;
+mod kumquat_gpu;
+
+use std::convert::TryInto;
+use std::fs::File;
+use std::io::Error as IoError;
+use std::io::ErrorKind as IoErrorKind;
+use std::io::Write;
+use std::path::PathBuf;
+
+use clap::Parser;
+use kumquat::Kumquat;
+use kumquat_gpu::KumquatGpuConnection;
+use rutabaga_gfx::kumquat_support::RutabagaListener;
+use rutabaga_gfx::RutabagaError;
+use rutabaga_gfx::RutabagaFromRawDescriptor;
+use rutabaga_gfx::RutabagaResult;
+
+#[derive(Parser, Debug)]
+#[command(version, about = None, long_about = None)]
+struct Args {
+    /// Colon-separated list of virtio-gpu capsets.  For example,
+    /// "--capset-names=gfxstream-vulkan:cross-domain"
+    #[arg(long, default_value = "gfxstream-vulkan")]
+    capset_names: String,
+
+    /// Path to the emulated virtio-gpu socket.
+    #[arg(long, default_value = "/tmp/kumquat-gpu-0")]
+    gpu_socket_path: String,
+
+    /// Opaque renderer specific features
+    #[arg(long, default_value = "")]
+    renderer_features: String,
+
+    /// An OS-specific pipe descriptor to the parent process
+    #[arg(long, default_value = "0")]
+    pipe_descriptor: i64,
+}
+
+fn main() -> RutabagaResult<()> {
+    let args = Args::parse();
+
+    let mut kumquat = Kumquat::new(args.capset_names, args.renderer_features)?;
+    let mut connection_id: u64 = 0;
+
+    // Remove path if it exists
+    let path = PathBuf::from(&args.gpu_socket_path);
+    let _ = std::fs::remove_file(&path);
+
+    let listener = RutabagaListener::bind(path)?;
+
+    if args.pipe_descriptor != 0 {
+        // SAFETY: We trust the user to provide a valid descriptor. The subsequent write call
+        // should fail otherwise.
+        let mut pipe: File = unsafe { File::from_raw_descriptor(args.pipe_descriptor.try_into()?) };
+        pipe.write(&1u64.to_ne_bytes())?;
+    }
+
+    loop {
+        match listener.accept() {
+            Ok(stream) => {
+                connection_id += 1;
+                kumquat.add_connection(connection_id, KumquatGpuConnection::new(stream))?;
+            }
+            Err(RutabagaError::IoError(e)) => match e.kind() {
+                IoErrorKind::WouldBlock => (),
+                kind => return Err(IoError::from(kind).into()),
+            },
+            Err(e) => return Err(e),
+        };
+
+        kumquat.run()?;
+    }
+}
diff --git a/rutabaga_gfx/patches/Android.bp.patch b/rutabaga_gfx/patches/Android.bp.patch
index 6c55ba9c2..aa33a6805 100644
--- a/rutabaga_gfx/patches/Android.bp.patch
+++ b/rutabaga_gfx/patches/Android.bp.patch
@@ -1,5 +1,5 @@
 diff --git a/rutabaga_gfx/Android.bp b/rutabaga_gfx/Android.bp
-index b99e49886..6c37c03da 100644
+index c69e8a386..4964f3118 100644
 --- a/rutabaga_gfx/Android.bp
 +++ b/rutabaga_gfx/Android.bp
 @@ -23,7 +23,6 @@ rust_library {
@@ -10,13 +10,16 @@ index b99e49886..6c37c03da 100644
          "virgl_renderer",
      ],
      rustlibs: [
-@@ -35,14 +34,75 @@ rust_library {
+@@ -35,16 +34,78 @@ rust_library {
          "libzerocopy",
      ],
      proc_macros: ["libremain"],
+-    static_libs: [
+-        "libgbm",
+-        "libvirglrenderer",
 +    cfgs: [
 +        "gfxstream_unstable",
-+    ],
+     ],
      shared_libs: [
 -        "libdrm",
 +        "libc++",
@@ -39,16 +42,13 @@ index b99e49886..6c37c03da 100644
 +    },
 +    static_libs: [
          "libepoxy",
-         "libgbm",
-+        "libdrm",
 +        "libgfxstream_backend",
-         "libvirglrenderer",
++        "libvirglrenderer",
      ],
  }
  
 +rust_library {
 +    name: "librutabaga_gfx_gfxstream",
-+    defaults: ["crosvm_inner_defaults"],
 +    host_supported: true,
 +    vendor_available: true,
 +    crate_name: "rutabaga_gfx",
@@ -65,29 +65,35 @@ index b99e49886..6c37c03da 100644
 +        "libzerocopy",
 +    ],
 +    proc_macros: ["libremain"],
-+    cfgs: [
-+        "gfxstream_unstable",
-+    ],
-+    features: [
-+        "gfxstream",
-+    ],
-+    shared_libs: [
-+        "libgfxstream_backend",
-+    ],
 +    target: {
 +        host: {
-+            features: ["vulkano"],
++            cfgs: [
++                "gfxstream_unstable",
++            ],
++            features: [
++                "gfxstream",
++                "vulkano",
++            ],
++            shared_libs: [
++                "libgfxstream_backend",
++            ],
++            compile_multilib: "64",
 +            rustlibs: [
 +                "libvulkano",
 +            ],
 +        },
++        android: {
++            cfgs: [
++                "gfxstream_unstable",
++            ],
++        },
 +    },
 +}
 +
  rust_test {
      name: "rutabaga_gfx_test_src_lib",
      defaults: ["crosvm_inner_defaults"],
-@@ -59,7 +119,6 @@ rust_test {
+@@ -61,7 +122,6 @@ rust_test {
      edition: "2021",
      features: [
          "gfxstream",
@@ -95,17 +101,18 @@ index b99e49886..6c37c03da 100644
          "virgl_renderer",
      ],
      rustlibs: [
-@@ -72,9 +131,12 @@ rust_test {
+@@ -73,12 +133,9 @@ rust_test {
+         "libzerocopy",
      ],
      proc_macros: ["libremain"],
+-    static_libs: [
+-        "libgbm",
+-        "libvirglrenderer",
+-    ],
      shared_libs: [
 -        "libdrm",
          "libepoxy",
-         "libgbm",
 +        "libgfxstream_backend",
-         "libvirglrenderer",
++        "libvirglrenderer",
      ],
-+    static_libs: [
-+        "libdrm",
-+    ],
  }
diff --git a/rutabaga_gfx/src/bytestream/mod.rs b/rutabaga_gfx/src/bytestream/mod.rs
new file mode 100644
index 000000000..27b2aca0f
--- /dev/null
+++ b/rutabaga_gfx/src/bytestream/mod.rs
@@ -0,0 +1,90 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::io::BufRead;
+use std::io::Error as IoError;
+use std::io::ErrorKind as IoErrorKind;
+use std::io::Read;
+use std::io::Result as IoResult;
+use std::mem::size_of;
+
+use zerocopy::AsBytes;
+use zerocopy::FromBytes;
+
+pub struct Reader<'slice> {
+    data: &'slice [u8],
+}
+
+impl<'slice> Reader<'slice> {
+    /// Construct a new Reader wrapper over `data`.
+    pub fn new(data: &[u8]) -> Reader {
+        Reader { data }
+    }
+
+    /// Reads and consumes an object from the buffer.
+    pub fn read_obj<T: FromBytes>(&mut self) -> IoResult<T> {
+        let obj = <T>::read_from_prefix(self.data.as_bytes())
+            .ok_or(IoError::from(IoErrorKind::UnexpectedEof))?;
+        self.consume(size_of::<T>());
+        Ok(obj)
+    }
+
+    #[allow(dead_code)]
+    fn read(&mut self, buf: &mut [u8]) -> IoResult<usize> {
+        self.data.read(buf)
+    }
+
+    pub fn available_bytes(&self) -> usize {
+        self.data.len()
+    }
+
+    /// Reads an object from the buffer without consuming it.
+    pub fn peek_obj<T: FromBytes>(&self) -> IoResult<T> {
+        let obj = <T>::read_from_prefix(self.data.as_bytes())
+            .ok_or(IoError::from(IoErrorKind::UnexpectedEof))?;
+        Ok(obj)
+    }
+
+    pub fn read_exact(&mut self, buf: &mut [u8]) -> IoResult<()> {
+        self.data.read_exact(buf)
+    }
+
+    /// Consumes `amt` bytes from the underlying buffer. If `amt` is larger than the
+    /// remaining data left in this `Reader`, then all remaining data will be consumed.
+    pub fn consume(&mut self, amt: usize) {
+        self.data.consume(amt);
+    }
+}
+
+pub struct Writer<'slice> {
+    data: &'slice mut [u8],
+    index: usize,
+}
+
+impl<'slice> Writer<'slice> {
+    pub fn new(data: &mut [u8]) -> Writer {
+        Writer { data, index: 0 }
+    }
+
+    /// Writes an object to the buffer.
+    pub fn write_obj<T: FromBytes + AsBytes>(&mut self, val: T) -> IoResult<()> {
+        self.write_all(val.as_bytes())
+    }
+
+    pub fn write_all(&mut self, buf: &[u8]) -> IoResult<()> {
+        let new_index = self.index + buf.len();
+
+        if new_index >= self.data.len() {
+            return Err(IoError::from(IoErrorKind::UnexpectedEof));
+        }
+
+        self.data[self.index..new_index].copy_from_slice(buf);
+        self.index = new_index;
+        Ok(())
+    }
+
+    pub fn bytes_written(&self) -> usize {
+        self.index
+    }
+}
diff --git a/rutabaga_gfx/src/cross_domain/mod.rs b/rutabaga_gfx/src/cross_domain/mod.rs
index 782e5013e..1e1ade2b8 100644
--- a/rutabaga_gfx/src/cross_domain/mod.rs
+++ b/rutabaga_gfx/src/cross_domain/mod.rs
@@ -30,12 +30,13 @@ use crate::cross_domain::sys::read_volatile;
 use crate::cross_domain::sys::write_volatile;
 use crate::cross_domain::sys::Receiver;
 use crate::cross_domain::sys::Sender;
-use crate::cross_domain::sys::SystemStream;
-use crate::cross_domain::sys::WaitContext;
 use crate::rutabaga_core::RutabagaComponent;
 use crate::rutabaga_core::RutabagaContext;
 use crate::rutabaga_core::RutabagaResource;
+use crate::rutabaga_os::RawDescriptor;
 use crate::rutabaga_os::SafeDescriptor;
+use crate::rutabaga_os::Tube;
+use crate::rutabaga_os::WaitContext;
 use crate::rutabaga_utils::*;
 use crate::DrmFormat;
 use crate::ImageAllocationInfo;
@@ -47,22 +48,9 @@ use crate::RutabagaGrallocFlags;
 mod cross_domain_protocol;
 mod sys;
 
-#[allow(dead_code)]
-const WAIT_CONTEXT_MAX: usize = 16;
-
-pub struct CrossDomainEvent {
-    token: CrossDomainToken,
-    hung_up: bool,
-    readable: bool,
-}
-
-#[derive(Copy, Clone, PartialEq, Eq)]
-pub enum CrossDomainToken {
-    ContextChannel,
-    WaylandReadPipe(u32),
-    Resample,
-    Kill,
-}
+const CROSS_DOMAIN_CONTEXT_CHANNEL_ID: u64 = 1;
+const CROSS_DOMAIN_RESAMPLE_ID: u64 = 2;
+const CROSS_DOMAIN_KILL_ID: u64 = 3;
 
 const CROSS_DOMAIN_DEFAULT_BUFFER_SIZE: usize = 4096;
 const CROSS_DOMAIN_MAX_SEND_RECV_SIZE: usize =
@@ -105,12 +93,11 @@ pub(crate) struct CrossDomainItems {
     table: Map<u32, CrossDomainItem>,
 }
 
-pub(crate) struct CrossDomainState {
+struct CrossDomainState {
     context_resources: CrossDomainResources,
     query_ring_id: u32,
     channel_ring_id: u32,
-    #[allow(dead_code)] // `connection` is never used on Windows.
-    pub(crate) connection: Option<SystemStream>,
+    connection: Option<Tube>,
     jobs: CrossDomainJobs,
     jobs_cvar: Condvar,
 }
@@ -126,7 +113,7 @@ pub(crate) struct CrossDomainContext {
     #[allow(dead_code)] // `channels` is unused on Windows.
     pub(crate) channels: Option<Vec<RutabagaChannel>>,
     gralloc: Arc<Mutex<RutabagaGralloc>>,
-    pub(crate) state: Option<Arc<CrossDomainState>>,
+    state: Option<Arc<CrossDomainState>>,
     pub(crate) context_resources: CrossDomainResources,
     pub(crate) item_state: CrossDomainItemState,
     fence_handler: RutabagaFenceHandler,
@@ -186,7 +173,7 @@ impl CrossDomainState {
         query_ring_id: u32,
         channel_ring_id: u32,
         context_resources: CrossDomainResources,
-        connection: Option<SystemStream>,
+        connection: Option<Tube>,
     ) -> CrossDomainState {
         CrossDomainState {
             query_ring_id,
@@ -198,6 +185,21 @@ impl CrossDomainState {
         }
     }
 
+    #[allow(dead_code)]
+    fn send_msg(&self, opaque_data: &[u8], descriptors: &[RawDescriptor]) -> RutabagaResult<usize> {
+        match self.connection {
+            Some(ref connection) => connection.send(opaque_data, descriptors),
+            None => Err(RutabagaError::InvalidCrossDomainChannel),
+        }
+    }
+
+    pub fn receive_msg(&self, opaque_data: &mut [u8]) -> RutabagaResult<(usize, Vec<File>)> {
+        match self.connection {
+            Some(ref connection) => connection.receive(opaque_data),
+            None => Err(RutabagaError::InvalidCrossDomainChannel),
+        }
+    }
+
     pub(crate) fn add_job(&self, job: CrossDomainJob) {
         let mut jobs = self.jobs.lock().unwrap();
         if let Some(queue) = jobs.as_mut() {
@@ -297,7 +299,7 @@ impl CrossDomainWorker {
         thread_resample_evt: &Receiver,
         receive_buf: &mut [u8],
     ) -> RutabagaResult<()> {
-        let events = self.wait_ctx.wait()?;
+        let events = self.wait_ctx.wait(None)?;
 
         // The worker thread must:
         //
@@ -315,8 +317,8 @@ impl CrossDomainWorker {
         // The CrossDomainJob queue gurantees a new fence has been generated before polling is
         // resumed.
         if let Some(event) = events.first() {
-            match event.token {
-                CrossDomainToken::ContextChannel => {
+            match event.connection_id {
+                CROSS_DOMAIN_CONTEXT_CHANNEL_ID => {
                     let (len, files) = self.state.receive_msg(receive_buf)?;
                     if len != 0 || !files.is_empty() {
                         let mut cmd_receive: CrossDomainSendReceive = Default::default();
@@ -359,7 +361,7 @@ impl CrossDomainWorker {
                         self.fence_handler.call(fence);
                     }
                 }
-                CrossDomainToken::Resample => {
+                CROSS_DOMAIN_RESAMPLE_ID => {
                     // The resample event is triggered when the job queue is in the following state:
                     //
                     // [CrossDomain::AddReadPipe(..)] -> END
@@ -373,9 +375,13 @@ impl CrossDomainWorker {
                     channel_wait(thread_resample_evt)?;
                     self.state.add_job(CrossDomainJob::HandleFence(fence));
                 }
-                CrossDomainToken::WaylandReadPipe(pipe_id) => {
+                CROSS_DOMAIN_KILL_ID => {
+                    self.fence_handler.call(fence);
+                }
+                _ => {
                     let mut items = self.item_state.lock().unwrap();
                     let mut cmd_read: CrossDomainReadWrite = Default::default();
+                    let pipe_id: u32 = event.connection_id.try_into()?;
                     let bytes_read;
 
                     cmd_read.hdr.cmd = CROSS_DOMAIN_CMD_READ;
@@ -397,8 +403,7 @@ impl CrossDomainWorker {
 
                             // Zero bytes read indicates end-of-file on POSIX.
                             if event.hung_up && bytes_read == 0 {
-                                self.wait_ctx
-                                    .delete(CrossDomainToken::WaylandReadPipe(pipe_id), file)?;
+                                self.wait_ctx.delete(file)?;
                             }
                         }
                         _ => return Err(RutabagaError::InvalidCrossDomainItemType),
@@ -410,9 +415,6 @@ impl CrossDomainWorker {
 
                     self.fence_handler.call(fence);
                 }
-                CrossDomainToken::Kill => {
-                    self.fence_handler.call(fence);
-                }
             }
         }
 
@@ -425,9 +427,8 @@ impl CrossDomainWorker {
         thread_resample_evt: Receiver,
     ) -> RutabagaResult<()> {
         self.wait_ctx
-            .add(CrossDomainToken::Resample, &thread_resample_evt)?;
-        self.wait_ctx
-            .add(CrossDomainToken::Kill, &thread_kill_evt)?;
+            .add(CROSS_DOMAIN_RESAMPLE_ID, &thread_resample_evt)?;
+        self.wait_ctx.add(CROSS_DOMAIN_KILL_ID, &thread_kill_evt)?;
         let mut receive_buf: Vec<u8> = vec![0; CROSS_DOMAIN_MAX_SEND_RECV_SIZE];
 
         while let Some(job) = self.state.wait_for_job() {
@@ -449,9 +450,9 @@ impl CrossDomainWorker {
                         .ok_or(RutabagaError::InvalidCrossDomainItemId)?;
 
                     match item {
-                        CrossDomainItem::WaylandReadPipe(file) => self
-                            .wait_ctx
-                            .add(CrossDomainToken::WaylandReadPipe(read_pipe_id), file)?,
+                        CrossDomainItem::WaylandReadPipe(file) => {
+                            self.wait_ctx.add(read_pipe_id as u64, file)?
+                        }
                         _ => return Err(RutabagaError::InvalidCrossDomainItemType),
                     }
                 }
@@ -480,6 +481,20 @@ impl CrossDomain {
 }
 
 impl CrossDomainContext {
+    pub fn get_connection(&mut self, cmd_init: &CrossDomainInit) -> RutabagaResult<Tube> {
+        let channels = self
+            .channels
+            .take()
+            .ok_or(RutabagaError::InvalidCrossDomainChannel)?;
+        let base_channel = &channels
+            .iter()
+            .find(|channel| channel.channel_type == cmd_init.channel_type)
+            .ok_or(RutabagaError::InvalidCrossDomainChannel)?
+            .base_channel;
+
+        Tube::new(base_channel.clone())
+    }
+
     fn initialize(&mut self, cmd_init: &CrossDomainInit) -> RutabagaResult<()> {
         if !self
             .context_resources
@@ -511,18 +526,13 @@ impl CrossDomainContext {
             let (resample_evt, thread_resample_evt) = channel()?;
 
             let mut wait_ctx = WaitContext::new()?;
-            match &connection {
-                Some(connection) => {
-                    wait_ctx.add(CrossDomainToken::ContextChannel, connection)?;
-                }
-                None => return Err(RutabagaError::Unsupported),
-            };
+            wait_ctx.add(CROSS_DOMAIN_CONTEXT_CHANNEL_ID, &connection)?;
 
             let state = Arc::new(CrossDomainState::new(
                 query_ring_id,
                 channel_ring_id,
                 context_resources,
-                connection,
+                Some(connection),
             ));
 
             let thread_state = state.clone();
@@ -765,11 +775,12 @@ impl RutabagaContext for CrossDomainContext {
         }
     }
 
-    fn submit_cmd(&mut self, mut commands: &mut [u8], fence_ids: &[u64]) -> RutabagaResult<()> {
-        if !fence_ids.is_empty() {
-            return Err(RutabagaError::Unsupported);
-        }
-
+    fn submit_cmd(
+        &mut self,
+        mut commands: &mut [u8],
+        _fence_ids: &[u64],
+        _shareable_fences: Vec<RutabagaHandle>,
+    ) -> RutabagaResult<()> {
         while !commands.is_empty() {
             let hdr = CrossDomainHeader::read_from_prefix(commands.as_bytes())
                 .ok_or(RutabagaError::InvalidCommandBuffer)?;
@@ -876,7 +887,10 @@ impl RutabagaContext for CrossDomainContext {
             .remove(&resource.resource_id);
     }
 
-    fn context_create_fence(&mut self, fence: RutabagaFence) -> RutabagaResult<()> {
+    fn context_create_fence(
+        &mut self,
+        fence: RutabagaFence,
+    ) -> RutabagaResult<Option<RutabagaHandle>> {
         match fence.ring_idx as u32 {
             CROSS_DOMAIN_QUERY_RING => self.fence_handler.call(fence),
             CROSS_DOMAIN_CHANNEL_RING => {
@@ -887,7 +901,7 @@ impl RutabagaContext for CrossDomainContext {
             _ => return Err(RutabagaError::SpecViolation("unexpected ring type")),
         }
 
-        Ok(())
+        Ok(None)
     }
 
     fn component_type(&self) -> RutabagaComponentType {
@@ -904,7 +918,7 @@ impl RutabagaComponent for CrossDomain {
         let mut caps: CrossDomainCapabilities = Default::default();
         if let Some(ref channels) = self.channels {
             for channel in channels {
-                caps.supported_channels = 1 << channel.channel_type;
+                caps.supported_channels |= 1 << channel.channel_type;
             }
         }
 
diff --git a/rutabaga_gfx/src/cross_domain/sys/epoll_internal.rs b/rutabaga_gfx/src/cross_domain/sys/epoll_internal.rs
deleted file mode 100644
index 8a93a118f..000000000
--- a/rutabaga_gfx/src/cross_domain/sys/epoll_internal.rs
+++ /dev/null
@@ -1,131 +0,0 @@
-// Copyright 2023 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-use std::mem;
-use std::os::unix::io::AsFd;
-use std::os::unix::io::AsRawFd;
-use std::os::unix::io::FromRawFd;
-use std::os::unix::io::OwnedFd;
-
-use libc::c_int;
-use nix::errno::Errno;
-use nix::sys::epoll::EpollCreateFlags;
-use nix::sys::epoll::EpollFlags;
-use nix::sys::epoll::EpollOp;
-use nix::Result;
-
-#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]
-#[repr(transparent)]
-pub struct EpollEvent {
-    event: libc::epoll_event,
-}
-
-impl EpollEvent {
-    pub fn new(events: EpollFlags, data: u64) -> Self {
-        EpollEvent {
-            event: libc::epoll_event {
-                events: events.bits() as u32,
-                u64: data,
-            },
-        }
-    }
-
-    pub fn empty() -> Self {
-        // SAFETY: trivially safe
-        unsafe { mem::zeroed::<EpollEvent>() }
-    }
-
-    pub fn events(&self) -> EpollFlags {
-        EpollFlags::from_bits(self.event.events as c_int).unwrap()
-    }
-
-    pub fn data(&self) -> u64 {
-        self.event.u64
-    }
-}
-
-// This is a function is unreleased nix 0.27 -- when it is released, we can delete this.
-#[derive(Debug)]
-pub struct Epoll(pub OwnedFd);
-impl Epoll {
-    /// Creates a new epoll instance and returns a file descriptor referring to that instance.
-    ///
-    /// [`epoll_create1`](https://man7.org/linux/man-pages/man2/epoll_create1.2.html).
-    pub fn new(flags: EpollCreateFlags) -> Result<Self> {
-        // TODO(b/315870313): Add safety comment
-        #[allow(clippy::undocumented_unsafe_blocks)]
-        let res = unsafe { libc::epoll_create1(flags.bits()) };
-        let fd = Errno::result(res)?;
-        // TODO(b/315870313): Add safety comment
-        #[allow(clippy::undocumented_unsafe_blocks)]
-        let owned_fd = unsafe { OwnedFd::from_raw_fd(fd) };
-        Ok(Self(owned_fd))
-    }
-    /// Add an entry to the interest list of the epoll file descriptor for
-    /// specified in events.
-    ///
-    /// [`epoll_ctl`](https://man7.org/linux/man-pages/man2/epoll_ctl.2.html) with `EPOLL_CTL_ADD`.
-    pub fn add<Fd: AsFd>(&self, fd: Fd, mut event: EpollEvent) -> Result<()> {
-        self.epoll_ctl(EpollOp::EpollCtlAdd, fd, &mut event)
-    }
-    /// Remove (deregister) the target file descriptor `fd` from the interest list.
-    ///
-    /// [`epoll_ctl`](https://man7.org/linux/man-pages/man2/epoll_ctl.2.html) with `EPOLL_CTL_DEL` .
-    pub fn delete<Fd: AsFd>(&self, fd: Fd) -> Result<()> {
-        self.epoll_ctl(EpollOp::EpollCtlDel, fd, None)
-    }
-    /// Change the settings associated with `fd` in the interest list to the new settings specified
-    /// in `event`.
-    ///
-    /// [`epoll_ctl`](https://man7.org/linux/man-pages/man2/epoll_ctl.2.html) with `EPOLL_CTL_MOD`.
-    #[allow(dead_code)]
-    pub fn modify<Fd: AsFd>(&self, fd: Fd, event: &mut EpollEvent) -> Result<()> {
-        self.epoll_ctl(EpollOp::EpollCtlMod, fd, event)
-    }
-    /// Waits for I/O events, blocking the calling thread if no events are currently available.
-    /// (This can be thought of as fetching items from the ready list of the epoll instance.)
-    ///
-    /// [`epoll_wait`](https://man7.org/linux/man-pages/man2/epoll_wait.2.html)
-    pub fn wait(&self, events: &mut [EpollEvent], timeout: isize) -> Result<usize> {
-        // TODO(b/315870313): Add safety comment
-        #[allow(clippy::undocumented_unsafe_blocks)]
-        let res = unsafe {
-            libc::epoll_wait(
-                self.0.as_raw_fd(),
-                events.as_mut_ptr() as *mut libc::epoll_event,
-                events.len() as c_int,
-                timeout as c_int,
-            )
-        };
-
-        Errno::result(res).map(|r| r as usize)
-    }
-    /// This system call is used to add, modify, or remove entries in the interest list of the epoll
-    /// instance referred to by `self`. It requests that the operation `op` be performed for the
-    /// target file descriptor, `fd`.
-    ///
-    /// When possible prefer [`Epoll::add`], [`Epoll::delete`] and [`Epoll::modify`].
-    ///
-    /// [`epoll_ctl`](https://man7.org/linux/man-pages/man2/epoll_ctl.2.html)
-    fn epoll_ctl<'a, Fd: AsFd, T>(&self, op: EpollOp, fd: Fd, event: T) -> Result<()>
-    where
-        T: Into<Option<&'a mut EpollEvent>>,
-    {
-        let event: Option<&mut EpollEvent> = event.into();
-        let ptr = event
-            .map(|x| &mut x.event as *mut libc::epoll_event)
-            .unwrap_or(std::ptr::null_mut());
-        // TODO(b/315870313): Add safety comment
-        #[allow(clippy::undocumented_unsafe_blocks)]
-        unsafe {
-            Errno::result(libc::epoll_ctl(
-                self.0.as_raw_fd(),
-                op as c_int,
-                fd.as_fd().as_raw_fd(),
-                ptr,
-            ))
-            .map(drop)
-        }
-    }
-}
diff --git a/rutabaga_gfx/src/cross_domain/sys/linux.rs b/rutabaga_gfx/src/cross_domain/sys/linux.rs
index 6aaef8cdb..4e706774d 100644
--- a/rutabaga_gfx/src/cross_domain/sys/linux.rs
+++ b/rutabaga_gfx/src/cross_domain/sys/linux.rs
@@ -3,33 +3,17 @@
 // found in the LICENSE file.
 
 use std::fs::File;
-use std::io::IoSlice;
-use std::io::IoSliceMut;
 use std::io::Seek;
 use std::io::SeekFrom;
+use std::os::fd::AsFd;
 use std::os::unix::io::AsRawFd;
-use std::os::unix::prelude::AsFd;
 
 use libc::O_ACCMODE;
 use libc::O_WRONLY;
-use nix::cmsg_space;
 use nix::fcntl::fcntl;
 use nix::fcntl::FcntlArg;
-use nix::sys::epoll::EpollCreateFlags;
-use nix::sys::epoll::EpollFlags;
 use nix::sys::eventfd::EfdFlags;
 use nix::sys::eventfd::EventFd;
-use nix::sys::socket::connect;
-use nix::sys::socket::recvmsg;
-use nix::sys::socket::sendmsg;
-use nix::sys::socket::socket;
-use nix::sys::socket::AddressFamily;
-use nix::sys::socket::ControlMessage;
-use nix::sys::socket::ControlMessageOwned;
-use nix::sys::socket::MsgFlags;
-use nix::sys::socket::SockFlag;
-use nix::sys::socket::SockType;
-use nix::sys::socket::UnixAddr;
 use nix::unistd::pipe;
 use nix::unistd::read;
 use nix::unistd::write;
@@ -43,21 +27,10 @@ use super::super::cross_domain_protocol::CROSS_DOMAIN_MAX_IDENTIFIERS;
 use super::super::CrossDomainContext;
 use super::super::CrossDomainItem;
 use super::super::CrossDomainJob;
-use super::super::CrossDomainState;
-use super::epoll_internal::Epoll;
-use super::epoll_internal::EpollEvent;
-use crate::cross_domain::cross_domain_protocol::CrossDomainInit;
-use crate::cross_domain::CrossDomainEvent;
-use crate::cross_domain::CrossDomainToken;
-use crate::cross_domain::WAIT_CONTEXT_MAX;
 use crate::rutabaga_os::AsRawDescriptor;
-use crate::rutabaga_os::FromRawDescriptor;
-use crate::rutabaga_os::RawDescriptor;
 use crate::RutabagaError;
 use crate::RutabagaResult;
 
-pub type SystemStream = File;
-
 // Determine type of OS-specific descriptor.  See `from_file` in wl.rs  for explantation on the
 // current, Linux-based method.
 pub fn descriptor_analysis(
@@ -83,89 +56,7 @@ pub fn descriptor_analysis(
     }
 }
 
-impl CrossDomainState {
-    fn send_msg(&self, opaque_data: &[u8], descriptors: &[RawDescriptor]) -> RutabagaResult<usize> {
-        let cmsg = ControlMessage::ScmRights(descriptors);
-        if let Some(connection) = &self.connection {
-            let bytes_sent = sendmsg::<()>(
-                connection.as_raw_descriptor(),
-                &[IoSlice::new(opaque_data)],
-                &[cmsg],
-                MsgFlags::empty(),
-                None,
-            )?;
-
-            return Ok(bytes_sent);
-        }
-
-        Err(RutabagaError::InvalidCrossDomainChannel)
-    }
-
-    pub(crate) fn receive_msg(&self, opaque_data: &mut [u8]) -> RutabagaResult<(usize, Vec<File>)> {
-        // If any errors happen, the socket will get dropped, preventing more reading.
-        let mut iovecs = [IoSliceMut::new(opaque_data)];
-        let mut cmsgspace = cmsg_space!([RawDescriptor; CROSS_DOMAIN_MAX_IDENTIFIERS]);
-        let flags = MsgFlags::empty();
-
-        if let Some(connection) = &self.connection {
-            let r = recvmsg::<()>(
-                connection.as_raw_descriptor(),
-                &mut iovecs,
-                Some(&mut cmsgspace),
-                flags,
-            )?;
-            let len = r.bytes;
-
-            let files = match r.cmsgs().next() {
-                Some(ControlMessageOwned::ScmRights(fds)) => {
-                    fds.into_iter()
-                        .map(|fd| {
-                            // SAFETY:
-                            // Safe since the descriptors from recv_with_fds(..) are owned by us and
-                            // valid.
-                            unsafe { File::from_raw_descriptor(fd) }
-                        })
-                        .collect()
-                }
-                Some(_) => return Err(RutabagaError::Unsupported),
-                None => Vec::new(),
-            };
-
-            Ok((len, files))
-        } else {
-            Err(RutabagaError::InvalidCrossDomainChannel)
-        }
-    }
-}
-
 impl CrossDomainContext {
-    pub(crate) fn get_connection(
-        &mut self,
-        cmd_init: &CrossDomainInit,
-    ) -> RutabagaResult<Option<SystemStream>> {
-        let channels = self
-            .channels
-            .take()
-            .ok_or(RutabagaError::InvalidCrossDomainChannel)?;
-        let base_channel = &channels
-            .iter()
-            .find(|channel| channel.channel_type == cmd_init.channel_type)
-            .ok_or(RutabagaError::InvalidCrossDomainChannel)?
-            .base_channel;
-
-        let socket_fd = socket(
-            AddressFamily::Unix,
-            SockType::Stream,
-            SockFlag::SOCK_CLOEXEC,
-            None,
-        )?;
-
-        let unix_addr = UnixAddr::new(base_channel)?;
-        connect(socket_fd.as_raw_fd(), &unix_addr)?;
-        let stream = socket_fd.into();
-        Ok(Some(stream))
-    }
-
     pub(crate) fn send(
         &self,
         cmd_send: &CrossDomainSendReceive,
@@ -284,66 +175,3 @@ pub fn channel() -> RutabagaResult<(Sender, Receiver)> {
     let receiver = sender.as_fd().try_clone_to_owned()?.into();
     Ok((sender, receiver))
 }
-
-pub struct WaitContext {
-    epoll_ctx: Epoll,
-    data: u64,
-    vec: Vec<(u64, CrossDomainToken)>,
-}
-
-impl WaitContext {
-    pub fn new() -> RutabagaResult<WaitContext> {
-        let epoll = Epoll::new(EpollCreateFlags::empty())?;
-        Ok(WaitContext {
-            epoll_ctx: epoll,
-            data: 0,
-            vec: Default::default(),
-        })
-    }
-
-    pub fn add<Waitable: AsFd>(
-        &mut self,
-        token: CrossDomainToken,
-        waitable: Waitable,
-    ) -> RutabagaResult<()> {
-        self.data += 1;
-        self.epoll_ctx
-            .add(waitable, EpollEvent::new(EpollFlags::EPOLLIN, self.data))?;
-        self.vec.push((self.data, token));
-        Ok(())
-    }
-
-    fn calculate_token(&self, data: u64) -> RutabagaResult<CrossDomainToken> {
-        if let Some(item) = self.vec.iter().find(|item| item.0 == data) {
-            return Ok(item.1);
-        }
-
-        Err(RutabagaError::SpecViolation("unable to find token"))
-    }
-
-    pub fn wait(&mut self) -> RutabagaResult<Vec<CrossDomainEvent>> {
-        let mut events = [EpollEvent::empty(); WAIT_CONTEXT_MAX];
-        let count = self.epoll_ctx.wait(&mut events, isize::MAX)?;
-        let events = events[0..count]
-            .iter()
-            .map(|e| CrossDomainEvent {
-                token: self.calculate_token(e.data()).unwrap(),
-                readable: e.events() & EpollFlags::EPOLLIN == EpollFlags::EPOLLIN,
-                hung_up: e.events() & EpollFlags::EPOLLHUP == EpollFlags::EPOLLHUP
-                    || e.events() & EpollFlags::EPOLLRDHUP != EpollFlags::EPOLLRDHUP,
-            })
-            .collect();
-
-        Ok(events)
-    }
-
-    pub fn delete<Waitable: AsFd>(
-        &mut self,
-        token: CrossDomainToken,
-        waitable: Waitable,
-    ) -> RutabagaResult<()> {
-        self.epoll_ctx.delete(waitable)?;
-        self.vec.retain(|item| item.1 != token);
-        Ok(())
-    }
-}
diff --git a/rutabaga_gfx/src/cross_domain/sys/mod.rs b/rutabaga_gfx/src/cross_domain/sys/mod.rs
index 51f40cd25..f92c83866 100644
--- a/rutabaga_gfx/src/cross_domain/sys/mod.rs
+++ b/rutabaga_gfx/src/cross_domain/sys/mod.rs
@@ -5,7 +5,6 @@
 cfg_if::cfg_if! {
     if #[cfg(any(target_os = "android", target_os = "linux"))] {
         pub(crate) mod linux;
-        mod epoll_internal;
         use linux as platform;
     } else if #[cfg(any(target_os = "fuchsia",target_os = "windows", target_os = "macos",
                         target_os = "nto"))] {
@@ -24,5 +23,3 @@ pub use platform::read_volatile;
 pub use platform::write_volatile;
 pub use platform::Receiver;
 pub use platform::Sender;
-pub use platform::SystemStream;
-pub use platform::WaitContext;
diff --git a/rutabaga_gfx/src/cross_domain/sys/stub.rs b/rutabaga_gfx/src/cross_domain/sys/stub.rs
index e6d25474e..9080292b6 100644
--- a/rutabaga_gfx/src/cross_domain/sys/stub.rs
+++ b/rutabaga_gfx/src/cross_domain/sys/stub.rs
@@ -4,17 +4,13 @@
 
 use std::fs::File;
 
-use super::super::cross_domain_protocol::CrossDomainInit;
 use super::super::cross_domain_protocol::CrossDomainSendReceive;
 use super::super::CrossDomainContext;
-use super::super::CrossDomainState;
-use crate::cross_domain::CrossDomainEvent;
-use crate::cross_domain::CrossDomainToken;
+use crate::rutabaga_os::WaitTrait;
 use crate::rutabaga_utils::RutabagaError;
 use crate::rutabaga_utils::RutabagaResult;
 
 pub struct Stub(());
-pub type SystemStream = Stub;
 
 // Determine type of OS-specific descriptor.
 pub fn descriptor_analysis(
@@ -25,23 +21,7 @@ pub fn descriptor_analysis(
     Err(RutabagaError::Unsupported)
 }
 
-impl CrossDomainState {
-    pub(crate) fn receive_msg(
-        &self,
-        _opaque_data: &mut [u8],
-    ) -> RutabagaResult<(usize, Vec<File>)> {
-        Err(RutabagaError::Unsupported)
-    }
-}
-
 impl CrossDomainContext {
-    pub(crate) fn get_connection(
-        &mut self,
-        _cmd_init: &CrossDomainInit,
-    ) -> RutabagaResult<Option<SystemStream>> {
-        Err(RutabagaError::Unsupported)
-    }
-
     pub(crate) fn send(
         &self,
         _cmd_send: &CrossDomainSendReceive,
@@ -54,6 +34,12 @@ impl CrossDomainContext {
 pub type Sender = Stub;
 pub type Receiver = Stub;
 
+impl WaitTrait for Stub {}
+impl WaitTrait for &Stub {}
+impl WaitTrait for File {}
+impl WaitTrait for &File {}
+impl WaitTrait for &mut File {}
+
 pub fn channel_signal(_sender: &Sender) -> RutabagaResult<()> {
     Err(RutabagaError::Unsupported)
 }
@@ -73,38 +59,3 @@ pub fn write_volatile(_file: &File, _opaque_data: &[u8]) -> RutabagaResult<()> {
 pub fn channel() -> RutabagaResult<(Sender, Receiver)> {
     Err(RutabagaError::Unsupported)
 }
-
-pub type WaitContext = Stub;
-
-pub trait WaitTrait {}
-impl WaitTrait for Stub {}
-impl WaitTrait for &Stub {}
-impl WaitTrait for File {}
-impl WaitTrait for &File {}
-impl WaitTrait for &mut File {}
-
-impl WaitContext {
-    pub fn new() -> RutabagaResult<WaitContext> {
-        Err(RutabagaError::Unsupported)
-    }
-
-    pub fn add<Waitable: WaitTrait>(
-        &mut self,
-        _token: CrossDomainToken,
-        _waitable: Waitable,
-    ) -> RutabagaResult<()> {
-        Err(RutabagaError::Unsupported)
-    }
-
-    pub fn wait(&mut self) -> RutabagaResult<Vec<CrossDomainEvent>> {
-        Err(RutabagaError::Unsupported)
-    }
-
-    pub fn delete<Waitable: WaitTrait>(
-        &mut self,
-        _token: CrossDomainToken,
-        _waitable: Waitable,
-    ) -> RutabagaResult<()> {
-        Err(RutabagaError::Unsupported)
-    }
-}
diff --git a/rutabaga_gfx/src/gfxstream.rs b/rutabaga_gfx/src/gfxstream.rs
index bec7790a1..fc044a38d 100644
--- a/rutabaga_gfx/src/gfxstream.rs
+++ b/rutabaga_gfx/src/gfxstream.rs
@@ -148,6 +148,8 @@ extern "C" {
         num_iovs: *mut c_int,
     );
     fn stream_renderer_create_fence(fence: *const stream_renderer_fence) -> c_int;
+    #[cfg(gfxstream_unstable)]
+    fn stream_renderer_export_fence(fence_id: u64, handle: *mut stream_renderer_handle) -> c_int;
     fn stream_renderer_ctx_attach_resource(ctx_id: c_int, res_handle: c_int);
     fn stream_renderer_ctx_detach_resource(ctx_id: c_int, res_handle: c_int);
     fn stream_renderer_get_cap_set(set: u32, max_ver: *mut u32, max_size: *mut u32);
@@ -200,12 +202,40 @@ struct GfxstreamContext {
     fence_handler: RutabagaFenceHandler,
 }
 
-impl RutabagaContext for GfxstreamContext {
-    fn submit_cmd(&mut self, commands: &mut [u8], fence_ids: &[u64]) -> RutabagaResult<()> {
-        if !fence_ids.is_empty() {
-            return Err(RutabagaError::Unsupported);
-        }
+impl GfxstreamContext {
+    #[cfg(gfxstream_unstable)]
+    fn export_fence(&self, fence_id: u64) -> RutabagaResult<RutabagaHandle> {
+        let mut stream_handle: stream_renderer_handle = Default::default();
+        // SAFETY:
+        // Safe because a correctly formatted stream_handle is given to gfxstream.
+        let ret = unsafe { stream_renderer_export_fence(fence_id, &mut stream_handle) };
+        ret_to_res(ret)?;
+
+        let raw_descriptor = stream_handle.os_handle as RawDescriptor;
+        // SAFETY:
+        // Safe because the handle was just returned by a successful gfxstream call so it must
+        // be valid and owned by us.
+        let handle = unsafe { SafeDescriptor::from_raw_descriptor(raw_descriptor) };
+
+        Ok(RutabagaHandle {
+            os_handle: handle,
+            handle_type: stream_handle.handle_type,
+        })
+    }
 
+    #[cfg(not(gfxstream_unstable))]
+    fn export_fence(&self, _fence_id: u64) -> RutabagaResult<RutabagaHandle> {
+        Err(RutabagaError::Unsupported)
+    }
+}
+
+impl RutabagaContext for GfxstreamContext {
+    fn submit_cmd(
+        &mut self,
+        commands: &mut [u8],
+        _fence_ids: &[u64],
+        _shareable_fences: Vec<RutabagaHandle>,
+    ) -> RutabagaResult<()> {
         if commands.len() % size_of::<u32>() != 0 {
             return Err(RutabagaError::InvalidCommandSize(commands.len()));
         }
@@ -248,17 +278,26 @@ impl RutabagaContext for GfxstreamContext {
         RutabagaComponentType::Gfxstream
     }
 
-    fn context_create_fence(&mut self, fence: RutabagaFence) -> RutabagaResult<()> {
+    fn context_create_fence(
+        &mut self,
+        fence: RutabagaFence,
+    ) -> RutabagaResult<Option<RutabagaHandle>> {
         if fence.ring_idx as u32 == 1 {
             self.fence_handler.call(fence);
-            return Ok(());
+            return Ok(None);
         }
 
         // SAFETY:
         // Safe because RutabagaFences and stream_renderer_fence are ABI identical
         let ret = unsafe { stream_renderer_create_fence(&fence as *const stream_renderer_fence) };
+        ret_to_res(ret)?;
 
-        ret_to_res(ret)
+        let mut hnd: Option<RutabagaHandle> = None;
+        if fence.flags & RUTABAGA_FLAG_FENCE_HOST_SHAREABLE != 0 {
+            hnd = Some(self.export_fence(fence.fence_id)?);
+        }
+
+        Ok(hnd)
     }
 }
 
diff --git a/rutabaga_gfx/src/ipc/kumquat_gpu_protocol.rs b/rutabaga_gfx/src/ipc/kumquat_gpu_protocol.rs
new file mode 100644
index 000000000..d720d052b
--- /dev/null
+++ b/rutabaga_gfx/src/ipc/kumquat_gpu_protocol.rs
@@ -0,0 +1,239 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Protocol based on ${crosvm_src}/devices/src/virtio/gpu/protocol.rs
+
+#![allow(dead_code)]
+
+use zerocopy::AsBytes;
+use zerocopy::FromBytes;
+use zerocopy::FromZeroes;
+
+use crate::rutabaga_utils::RutabagaHandle;
+use crate::rutabaga_utils::VulkanInfo;
+
+/* 2d commands */
+pub const KUMQUAT_GPU_PROTOCOL_RESOURCE_UNREF: u32 = 0x100;
+pub const KUMQUAT_GPU_PROTOCOL_GET_NUM_CAPSETS: u32 = 0x101;
+pub const KUMQUAT_GPU_PROTOCOL_GET_CAPSET_INFO: u32 = 0x102;
+pub const KUMQUAT_GPU_PROTOCOL_GET_CAPSET: u32 = 0x103;
+pub const KUMQUAT_GPU_PROTOCOL_RESOURCE_CREATE_BLOB: u32 = 0x104;
+
+/* 3d commands */
+pub const KUMQUAT_GPU_PROTOCOL_CTX_CREATE: u32 = 0x200;
+pub const KUMQUAT_GPU_PROTOCOL_CTX_DESTROY: u32 = 0x201;
+pub const KUMQUAT_GPU_PROTOCOL_CTX_ATTACH_RESOURCE: u32 = 0x202;
+pub const KUMQUAT_GPU_PROTOCOL_CTX_DETACH_RESOURCE: u32 = 0x203;
+pub const KUMQUAT_GPU_PROTOCOL_RESOURCE_CREATE_3D: u32 = 0x204;
+pub const KUMQUAT_GPU_PROTOCOL_TRANSFER_TO_HOST_3D: u32 = 0x205;
+pub const KUMQUAT_GPU_PROTOCOL_TRANSFER_FROM_HOST_3D: u32 = 0x206;
+pub const KUMQUAT_GPU_PROTOCOL_SUBMIT_3D: u32 = 0x207;
+pub const KUMQUAT_GPU_PROTOCOL_RESOURCE_MAP_BLOB: u32 = 0x208;
+pub const KUMQUAT_GPU_PROTOCOL_RESOURCE_UNMAP_BLOB: u32 = 0x209;
+pub const KUMQUAT_GPU_PROTOCOL_SNAPSHOT_SAVE: u32 = 0x208;
+pub const KUMQUAT_GPU_PROTOCOL_SNAPSHOT_RESTORE: u32 = 0x209;
+
+/* success responses */
+pub const KUMQUAT_GPU_PROTOCOL_RESP_NODATA: u32 = 0x3001;
+pub const KUMQUAT_GPU_PROTOCOL_RESP_NUM_CAPSETS: u32 = 0x3002;
+pub const KUMQUAT_GPU_PROTOCOL_RESP_CAPSET_INFO: u32 = 0x3003;
+pub const KUMQUAT_GPU_PROTOCOL_RESP_CAPSET: u32 = 0x3004;
+pub const KUMQUAT_GPU_PROTOCOL_RESP_CONTEXT_CREATE: u32 = 0x3005;
+pub const KUMQUAT_GPU_PROTOCOL_RESP_RESOURCE_CREATE: u32 = 0x3006;
+pub const KUMQUAT_GPU_PROTOCOL_RESP_CMD_SUBMIT_3D: u32 = 0x3007;
+pub const KUMQUAT_GPU_PROTOCOL_RESP_OK_SNAPSHOT: u32 = 0x3008;
+
+#[derive(Copy, Clone, Debug, Default, AsBytes, FromZeroes, FromBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_ctrl_hdr {
+    pub type_: u32,
+    pub payload: u32,
+}
+
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_box {
+    pub x: u32,
+    pub y: u32,
+    pub z: u32,
+    pub w: u32,
+    pub h: u32,
+    pub d: u32,
+}
+
+/* KUMQUAT_GPU_PROTOCOL_TRANSFER_TO_HOST_3D, KUMQUAT_GPU_PROTOCOL_TRANSFER_FROM_HOST_3D */
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_transfer_host_3d {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub box_: kumquat_gpu_protocol_box,
+    pub offset: u64,
+    pub level: u32,
+    pub stride: u32,
+    pub layer_stride: u32,
+    pub ctx_id: u32,
+    pub resource_id: u32,
+    pub padding: u32,
+}
+
+/* KUMQUAT_GPU_PROTOCOL_RESOURCE_CREATE_3D */
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_resource_create_3d {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub target: u32,
+    pub format: u32,
+    pub bind: u32,
+    pub width: u32,
+    pub height: u32,
+    pub depth: u32,
+    pub array_size: u32,
+    pub last_level: u32,
+    pub nr_samples: u32,
+    pub flags: u32,
+    pub size: u32,
+    pub stride: u32,
+    pub ctx_id: u32,
+}
+
+#[derive(Debug, Copy, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_ctx_create {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub nlen: u32,
+    pub context_init: u32,
+    pub debug_name: [u8; 64],
+}
+
+impl Default for kumquat_gpu_protocol_ctx_create {
+    fn default() -> Self {
+        // SAFETY: trivially safe
+        unsafe { ::std::mem::zeroed() }
+    }
+}
+
+impl Clone for kumquat_gpu_protocol_ctx_create {
+    fn clone(&self) -> kumquat_gpu_protocol_ctx_create {
+        *self
+    }
+}
+
+/* KUMQUAT_GPU_PROTOCOL_CTX_ATTACH_RESOURCE, KUMQUAT_GPU_PROTOCOL_CTX_DETACH_RESOURCE */
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_ctx_resource {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub ctx_id: u32,
+    pub resource_id: u32,
+}
+
+/* KUMQUAT_GPU_PROTOCOL_SUBMIT_3D */
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_cmd_submit {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub ctx_id: u32,
+    pub pad: u32,
+    pub size: u32,
+
+    // The in-fence IDs are prepended to the cmd_buf and memory layout
+    // of the KUMQUAT_GPU_PROTOCOL_SUBMIT_3D buffer looks like this:
+    //   _________________
+    //   | CMD_SUBMIT_3D |
+    //   -----------------
+    //   |  header       |
+    //   |  in-fence IDs |
+    //   |  cmd_buf      |
+    //   -----------------
+    //
+    // This makes in-fence IDs naturally aligned to the sizeof(u64) inside
+    // of the virtio buffer.
+    pub num_in_fences: u32,
+    pub flags: u32,
+    pub ring_idx: u8,
+    pub padding: [u8; 3],
+}
+
+/* KUMQUAT_GPU_PROTOCOL_RESP_CAPSET_INFO */
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_resp_capset_info {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub capset_id: u32,
+    pub version: u32,
+    pub size: u32,
+    pub padding: u32,
+}
+
+/* KUMQUAT_GPU_PROTOCOL_GET_CAPSET */
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_get_capset {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub capset_id: u32,
+    pub capset_version: u32,
+}
+
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_resource_create_blob {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub ctx_id: u32,
+    pub blob_mem: u32,
+    pub blob_flags: u32,
+    pub padding: u32,
+    pub blob_id: u64,
+    pub size: u64,
+}
+
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_resp_resource_create {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub resource_id: u32,
+    pub handle_type: u32,
+    pub vulkan_info: VulkanInfo,
+}
+
+#[derive(Copy, Clone, Debug, Default, FromZeroes, FromBytes, AsBytes)]
+#[repr(C)]
+pub struct kumquat_gpu_protocol_resp_cmd_submit_3d {
+    pub hdr: kumquat_gpu_protocol_ctrl_hdr,
+    pub fence_id: u64,
+    pub handle_type: u32,
+    pub padding: u32,
+}
+
+/// A virtio gpu command and associated metadata specific to each command.
+#[derive(Debug)]
+pub enum KumquatGpuProtocol {
+    OkNoData,
+    GetNumCapsets,
+    GetCapsetInfo(u32),
+    GetCapset(kumquat_gpu_protocol_get_capset),
+    CtxCreate(kumquat_gpu_protocol_ctx_create),
+    CtxDestroy(u32),
+    CtxAttachResource(kumquat_gpu_protocol_ctx_resource),
+    CtxDetachResource(kumquat_gpu_protocol_ctx_resource),
+    ResourceCreate3d(kumquat_gpu_protocol_resource_create_3d),
+    TransferToHost3d(kumquat_gpu_protocol_transfer_host_3d, RutabagaHandle),
+    TransferFromHost3d(kumquat_gpu_protocol_transfer_host_3d, RutabagaHandle),
+    CmdSubmit3d(kumquat_gpu_protocol_cmd_submit, Vec<u8>, Vec<u64>),
+    ResourceCreateBlob(kumquat_gpu_protocol_resource_create_blob),
+    SnapshotSave,
+    SnapshotRestore,
+    RespNumCapsets(u32),
+    RespCapsetInfo(kumquat_gpu_protocol_resp_capset_info),
+    RespCapset(Vec<u8>),
+    RespContextCreate(u32),
+    RespResourceCreate(kumquat_gpu_protocol_resp_resource_create, RutabagaHandle),
+    RespCmdSubmit3d(u64, RutabagaHandle),
+    RespOkSnapshot,
+}
+
+pub enum KumquatGpuProtocolWrite<T: AsBytes + FromBytes> {
+    Cmd(T),
+    CmdWithHandle(T, RutabagaHandle),
+    CmdWithData(T, Vec<u8>),
+}
diff --git a/rutabaga_gfx/src/ipc/mod.rs b/rutabaga_gfx/src/ipc/mod.rs
new file mode 100644
index 000000000..b8267514e
--- /dev/null
+++ b/rutabaga_gfx/src/ipc/mod.rs
@@ -0,0 +1,8 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+pub mod kumquat_gpu_protocol;
+pub mod rutabaga_stream;
+
+pub use rutabaga_stream::RutabagaStream;
diff --git a/rutabaga_gfx/src/ipc/rutabaga_stream.rs b/rutabaga_gfx/src/ipc/rutabaga_stream.rs
new file mode 100644
index 000000000..173cc53fc
--- /dev/null
+++ b/rutabaga_gfx/src/ipc/rutabaga_stream.rs
@@ -0,0 +1,261 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::collections::VecDeque;
+use std::fs::File;
+use std::mem::size_of;
+#[cfg(any(target_os = "android", target_os = "linux"))]
+use std::os::fd::AsFd;
+#[cfg(any(target_os = "android", target_os = "linux"))]
+use std::os::fd::BorrowedFd;
+
+use zerocopy::AsBytes;
+use zerocopy::FromBytes;
+
+use crate::bytestream::Reader;
+use crate::bytestream::Writer;
+use crate::ipc::kumquat_gpu_protocol::*;
+use crate::rutabaga_os::AsRawDescriptor;
+use crate::rutabaga_os::FromRawDescriptor;
+use crate::rutabaga_os::IntoRawDescriptor;
+use crate::rutabaga_os::RawDescriptor;
+use crate::rutabaga_os::SafeDescriptor;
+use crate::rutabaga_os::Tube;
+use crate::rutabaga_os::DEFAULT_RAW_DESCRIPTOR;
+use crate::rutabaga_utils::RutabagaError;
+use crate::rutabaga_utils::RutabagaHandle;
+use crate::rutabaga_utils::RutabagaResult;
+use crate::rutabaga_utils::RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD;
+
+const MAX_DESCRIPTORS: usize = 1;
+const MAX_COMMAND_SIZE: usize = 4096;
+
+pub struct RutabagaStream {
+    stream: Tube,
+    write_buffer: [u8; MAX_COMMAND_SIZE],
+    read_buffer: [u8; MAX_COMMAND_SIZE],
+    descriptors: [RawDescriptor; MAX_DESCRIPTORS],
+}
+
+impl RutabagaStream {
+    pub fn new(stream: Tube) -> RutabagaStream {
+        RutabagaStream {
+            stream,
+            write_buffer: [0; MAX_COMMAND_SIZE],
+            read_buffer: [0; MAX_COMMAND_SIZE],
+            descriptors: [DEFAULT_RAW_DESCRIPTOR; MAX_DESCRIPTORS],
+        }
+    }
+
+    pub fn write<T: FromBytes + AsBytes>(
+        &mut self,
+        encode: KumquatGpuProtocolWrite<T>,
+    ) -> RutabagaResult<()> {
+        let mut writer = Writer::new(&mut self.write_buffer);
+        let mut num_descriptors = 0;
+
+        let _handle_opt: Option<RutabagaHandle> = match encode {
+            KumquatGpuProtocolWrite::Cmd(cmd) => {
+                writer.write_obj(cmd)?;
+                None
+            }
+            KumquatGpuProtocolWrite::CmdWithHandle(cmd, handle) => {
+                writer.write_obj(cmd)?;
+                num_descriptors = 1;
+                self.descriptors[0] = handle.os_handle.as_raw_descriptor();
+                Some(handle)
+            }
+            KumquatGpuProtocolWrite::CmdWithData(cmd, data) => {
+                writer.write_obj(cmd)?;
+                writer.write_all(&data)?;
+                None
+            }
+        };
+
+        let bytes_written = writer.bytes_written();
+        self.stream.send(
+            &self.write_buffer[0..bytes_written],
+            &self.descriptors[0..num_descriptors],
+        )?;
+        Ok(())
+    }
+
+    pub fn read(&mut self) -> RutabagaResult<Vec<KumquatGpuProtocol>> {
+        let mut vec: Vec<KumquatGpuProtocol> = Vec::new();
+        let (bytes_read, files_vec) = self.stream.receive(&mut self.read_buffer)?;
+        let mut files: VecDeque<File> = files_vec.into();
+
+        if bytes_read == 0 {
+            vec.push(KumquatGpuProtocol::OkNoData);
+            return Ok(vec);
+        }
+
+        let mut reader = Reader::new(&self.read_buffer[0..bytes_read]);
+        while reader.available_bytes() != 0 {
+            let hdr = reader.peek_obj::<kumquat_gpu_protocol_ctrl_hdr>()?;
+            let protocol = match hdr.type_ {
+                KUMQUAT_GPU_PROTOCOL_GET_NUM_CAPSETS => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::GetNumCapsets
+                }
+                KUMQUAT_GPU_PROTOCOL_GET_CAPSET_INFO => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::GetCapsetInfo(hdr.payload)
+                }
+                KUMQUAT_GPU_PROTOCOL_GET_CAPSET => {
+                    KumquatGpuProtocol::GetCapset(reader.read_obj()?)
+                }
+                KUMQUAT_GPU_PROTOCOL_CTX_CREATE => {
+                    KumquatGpuProtocol::CtxCreate(reader.read_obj()?)
+                }
+                KUMQUAT_GPU_PROTOCOL_CTX_DESTROY => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::CtxDestroy(hdr.payload)
+                }
+                KUMQUAT_GPU_PROTOCOL_CTX_ATTACH_RESOURCE => {
+                    KumquatGpuProtocol::CtxAttachResource(reader.read_obj()?)
+                }
+                KUMQUAT_GPU_PROTOCOL_CTX_DETACH_RESOURCE => {
+                    KumquatGpuProtocol::CtxDetachResource(reader.read_obj()?)
+                }
+                KUMQUAT_GPU_PROTOCOL_RESOURCE_CREATE_3D => {
+                    KumquatGpuProtocol::ResourceCreate3d(reader.read_obj()?)
+                }
+                KUMQUAT_GPU_PROTOCOL_TRANSFER_TO_HOST_3D => {
+                    let file = files.pop_front().ok_or(RutabagaError::InvalidResourceId)?;
+                    let resp: kumquat_gpu_protocol_transfer_host_3d = reader.read_obj()?;
+
+                    // SAFETY: Safe because we know the underlying OS descriptor is valid and
+                    // owned by us.
+                    let os_handle =
+                        unsafe { SafeDescriptor::from_raw_descriptor(file.into_raw_descriptor()) };
+
+                    let handle = RutabagaHandle {
+                        os_handle,
+                        handle_type: RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD,
+                    };
+
+                    KumquatGpuProtocol::TransferToHost3d(resp, handle)
+                }
+                KUMQUAT_GPU_PROTOCOL_TRANSFER_FROM_HOST_3D => {
+                    let file = files.pop_front().ok_or(RutabagaError::InvalidResourceId)?;
+                    let resp: kumquat_gpu_protocol_transfer_host_3d = reader.read_obj()?;
+
+                    // SAFETY: Safe because we know the underlying OS descriptor is valid and
+                    // owned by us.
+                    let os_handle =
+                        unsafe { SafeDescriptor::from_raw_descriptor(file.into_raw_descriptor()) };
+
+                    let handle = RutabagaHandle {
+                        os_handle,
+                        handle_type: RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD,
+                    };
+
+                    KumquatGpuProtocol::TransferFromHost3d(resp, handle)
+                }
+                KUMQUAT_GPU_PROTOCOL_SUBMIT_3D => {
+                    let cmd: kumquat_gpu_protocol_cmd_submit = reader.read_obj()?;
+                    if reader.available_bytes() < cmd.size.try_into()? {
+                        // Large command buffers should handled via shared memory.
+                        return Err(RutabagaError::InvalidCommandBuffer);
+                    } else if reader.available_bytes() != 0 {
+                        let num_in_fences = cmd.num_in_fences as usize;
+                        let cmd_size = cmd.size as usize;
+                        let mut cmd_buf = vec![0; cmd_size];
+                        let mut fence_ids: Vec<u64> = Vec::with_capacity(num_in_fences);
+                        for _ in 0..num_in_fences {
+                            match reader.read_obj::<u64>() {
+                                Ok(fence_id) => {
+                                    fence_ids.push(fence_id);
+                                }
+                                Err(_) => return Err(RutabagaError::InvalidIovec),
+                            }
+                        }
+                        reader.read_exact(&mut cmd_buf[..])?;
+                        KumquatGpuProtocol::CmdSubmit3d(cmd, cmd_buf, fence_ids)
+                    } else {
+                        KumquatGpuProtocol::CmdSubmit3d(cmd, Vec::new(), Vec::new())
+                    }
+                }
+                KUMQUAT_GPU_PROTOCOL_RESOURCE_CREATE_BLOB => {
+                    KumquatGpuProtocol::ResourceCreateBlob(reader.read_obj()?)
+                }
+                KUMQUAT_GPU_PROTOCOL_SNAPSHOT_SAVE => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::SnapshotSave
+                }
+                KUMQUAT_GPU_PROTOCOL_SNAPSHOT_RESTORE => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::SnapshotRestore
+                }
+                KUMQUAT_GPU_PROTOCOL_RESP_NUM_CAPSETS => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::RespNumCapsets(hdr.payload)
+                }
+                KUMQUAT_GPU_PROTOCOL_RESP_CAPSET_INFO => {
+                    KumquatGpuProtocol::RespCapsetInfo(reader.read_obj()?)
+                }
+                KUMQUAT_GPU_PROTOCOL_RESP_CAPSET => {
+                    let len: usize = hdr.payload.try_into()?;
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    let mut capset: Vec<u8> = vec![0; len];
+                    reader.read_exact(&mut capset)?;
+                    KumquatGpuProtocol::RespCapset(capset)
+                }
+                KUMQUAT_GPU_PROTOCOL_RESP_CONTEXT_CREATE => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::RespContextCreate(hdr.payload)
+                }
+                KUMQUAT_GPU_PROTOCOL_RESP_RESOURCE_CREATE => {
+                    let file = files.pop_front().ok_or(RutabagaError::InvalidResourceId)?;
+                    let resp: kumquat_gpu_protocol_resp_resource_create = reader.read_obj()?;
+
+                    // SAFETY: Safe because we know the underlying OS descriptor is valid and
+                    // owned by us.
+                    let os_handle =
+                        unsafe { SafeDescriptor::from_raw_descriptor(file.into_raw_descriptor()) };
+
+                    let handle = RutabagaHandle {
+                        os_handle,
+                        handle_type: resp.handle_type,
+                    };
+
+                    KumquatGpuProtocol::RespResourceCreate(resp, handle)
+                }
+                KUMQUAT_GPU_PROTOCOL_RESP_CMD_SUBMIT_3D => {
+                    let file = files.pop_front().ok_or(RutabagaError::InvalidResourceId)?;
+                    let resp: kumquat_gpu_protocol_resp_cmd_submit_3d = reader.read_obj()?;
+
+                    // SAFETY: Safe because we know the underlying OS descriptor is valid and
+                    // owned by us.
+                    let os_handle =
+                        unsafe { SafeDescriptor::from_raw_descriptor(file.into_raw_descriptor()) };
+
+                    let handle = RutabagaHandle {
+                        os_handle,
+                        handle_type: resp.handle_type,
+                    };
+
+                    KumquatGpuProtocol::RespCmdSubmit3d(resp.fence_id, handle)
+                }
+                KUMQUAT_GPU_PROTOCOL_RESP_OK_SNAPSHOT => {
+                    reader.consume(size_of::<kumquat_gpu_protocol_ctrl_hdr>());
+                    KumquatGpuProtocol::RespOkSnapshot
+                }
+                _ => {
+                    return Err(RutabagaError::Unsupported);
+                }
+            };
+
+            vec.push(protocol);
+        }
+
+        Ok(vec)
+    }
+
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    pub fn as_borrowed_file(&self) -> BorrowedFd<'_> {
+        self.stream.as_fd()
+    }
+}
diff --git a/rutabaga_gfx/src/lib.rs b/rutabaga_gfx/src/lib.rs
index 2ddbc5947..6f721799f 100644
--- a/rutabaga_gfx/src/lib.rs
+++ b/rutabaga_gfx/src/lib.rs
@@ -11,6 +11,8 @@ mod gfxstream;
 mod gfxstream_stub;
 #[macro_use]
 mod macros;
+mod bytestream;
+mod ipc;
 #[cfg(any(feature = "gfxstream", feature = "virgl_renderer"))]
 mod renderer_utils;
 mod rutabaga_2d;
@@ -35,5 +37,18 @@ pub use crate::rutabaga_os::AsRawDescriptor;
 pub use crate::rutabaga_os::FromRawDescriptor as RutabagaFromRawDescriptor;
 pub use crate::rutabaga_os::IntoRawDescriptor as RutabagaIntoRawDescriptor;
 pub use crate::rutabaga_os::MappedRegion as RutabagaMappedRegion;
+pub use crate::rutabaga_os::RawDescriptor as RutabagaRawDescriptor;
 pub use crate::rutabaga_os::SafeDescriptor as RutabagaDescriptor;
 pub use crate::rutabaga_utils::*;
+
+pub mod kumquat_support {
+    pub use crate::bytestream::Reader as RutabagaReader;
+    pub use crate::bytestream::Writer as RutabagaWriter;
+    pub use crate::ipc::kumquat_gpu_protocol;
+    pub use crate::ipc::RutabagaStream;
+    pub use crate::rutabaga_os::Listener as RutabagaListener;
+    pub use crate::rutabaga_os::MemoryMapping as RutabagaMemoryMapping;
+    pub use crate::rutabaga_os::SharedMemory as RutabagaSharedMemory;
+    pub use crate::rutabaga_os::Tube as RutabagaTube;
+    pub use crate::rutabaga_os::WaitContext as RutabagaWaitContext;
+}
diff --git a/rutabaga_gfx/src/rutabaga_core.rs b/rutabaga_gfx/src/rutabaga_core.rs
index b332adf5d..b0ea5111b 100644
--- a/rutabaga_gfx/src/rutabaga_core.rs
+++ b/rutabaga_gfx/src/rutabaga_core.rs
@@ -223,7 +223,12 @@ pub trait RutabagaContext {
     }
 
     /// Implementations must handle the context-specific command stream.
-    fn submit_cmd(&mut self, _commands: &mut [u8], _fence_ids: &[u64]) -> RutabagaResult<()>;
+    fn submit_cmd(
+        &mut self,
+        _commands: &mut [u8],
+        _fence_ids: &[u64],
+        shareable_fences: Vec<RutabagaHandle>,
+    ) -> RutabagaResult<()>;
 
     /// Implementations may use `resource` in this context's command stream.
     fn attach(&mut self, _resource: &mut RutabagaResource);
@@ -233,7 +238,13 @@ pub trait RutabagaContext {
 
     /// Implementations must create a fence on specified `ring_idx` in `fence`.  This
     /// allows for multiple synchronizations timelines per RutabagaContext.
-    fn context_create_fence(&mut self, _fence: RutabagaFence) -> RutabagaResult<()> {
+    ///
+    /// If RUTABAGA_FLAG_FENCE_HOST_SHAREABLE is set, a rutabaga handle must be returned on
+    /// success.
+    fn context_create_fence(
+        &mut self,
+        _fence: RutabagaFence,
+    ) -> RutabagaResult<Option<RutabagaHandle>> {
         Err(RutabagaError::Unsupported)
     }
 
@@ -338,6 +349,8 @@ fn calculate_component(component_mask: u8) -> RutabagaResult<RutabagaComponentTy
 /// thread-safe is more difficult.
 pub struct Rutabaga {
     resources: Map<u32, RutabagaResource>,
+    #[cfg(gfxstream_unstable)]
+    shareable_fences: Map<u64, RutabagaHandle>,
     contexts: Map<u32, Box<dyn RutabagaContext>>,
     // Declare components after resources and contexts such that it is dropped last.
     components: Map<RutabagaComponentType, Box<dyn RutabagaComponent>>,
@@ -529,7 +542,14 @@ impl Rutabaga {
                 .get_mut(&fence.ctx_id)
                 .ok_or(RutabagaError::InvalidContextId)?;
 
-            ctx.context_create_fence(fence)?;
+            #[allow(unused_variables)]
+            let handle_opt = ctx.context_create_fence(fence)?;
+
+            #[cfg(gfxstream_unstable)]
+            if fence.flags & RUTABAGA_FLAG_FENCE_HOST_SHAREABLE != 0 {
+                let handle = handle_opt.unwrap();
+                self.shareable_fences.insert(fence.fence_id, handle);
+            }
         } else {
             let component = self
                 .components
@@ -869,7 +889,12 @@ impl Rutabaga {
     }
 
     /// Exports the given fence for import into other processes.
-    pub fn export_fence(&self, fence_id: u64) -> RutabagaResult<RutabagaHandle> {
+    pub fn export_fence(&mut self, fence_id: u64) -> RutabagaResult<RutabagaHandle> {
+        #[cfg(gfxstream_unstable)]
+        if let Some(handle) = self.shareable_fences.get_mut(&fence_id) {
+            return handle.try_clone();
+        }
+
         let component = self
             .components
             .get(&self.default_component)
@@ -964,7 +989,33 @@ impl Rutabaga {
             .get_mut(&ctx_id)
             .ok_or(RutabagaError::InvalidContextId)?;
 
-        ctx.submit_cmd(commands, fence_ids)
+        #[allow(unused_mut)]
+        let mut shareable_fences: Vec<RutabagaHandle> = Vec::with_capacity(fence_ids.len());
+
+        #[cfg(gfxstream_unstable)]
+        for (i, fence_id) in fence_ids.iter().enumerate() {
+            let handle = self
+                .shareable_fences
+                .get_mut(&fence_id)
+                .ok_or(RutabagaError::InvalidRutabagaHandle)?;
+
+            let clone = handle.try_clone()?;
+            shareable_fences.insert(i, clone);
+        }
+
+        ctx.submit_cmd(commands, fence_ids, shareable_fences)
+    }
+
+    /// destroy fences that are still outstanding
+    #[cfg(gfxstream_unstable)]
+    pub fn destroy_fences(&mut self, fence_ids: &[u64]) -> RutabagaResult<()> {
+        for fence_id in fence_ids {
+            self.shareable_fences
+                .remove(&fence_id)
+                .ok_or(RutabagaError::InvalidRutabagaHandle)?;
+        }
+
+        Ok(())
     }
 }
 
@@ -1177,23 +1228,26 @@ impl RutabagaBuilder {
             ));
         }
 
-        if self.default_component == RutabagaComponentType::Rutabaga2D {
-            let rutabaga_2d = Rutabaga2D::init(fence_handler.clone())?;
-            rutabaga_components.insert(RutabagaComponentType::Rutabaga2D, rutabaga_2d);
-        } else {
+        #[allow(unused_mut)]
+        let mut fallback_2d = false;
+        if self.default_component != RutabagaComponentType::Rutabaga2D {
             #[cfg(feature = "virgl_renderer")]
             if self.default_component == RutabagaComponentType::VirglRenderer {
-                let virgl = VirglRenderer::init(
+                if let Ok(virgl) = VirglRenderer::init(
                     self.virglrenderer_flags,
                     fence_handler.clone(),
                     rutabaga_server_descriptor,
-                )?;
-                rutabaga_components.insert(RutabagaComponentType::VirglRenderer, virgl);
+                ) {
+                    rutabaga_components.insert(RutabagaComponentType::VirglRenderer, virgl);
 
-                push_capset(RUTABAGA_CAPSET_VIRGL);
-                push_capset(RUTABAGA_CAPSET_VIRGL2);
-                push_capset(RUTABAGA_CAPSET_VENUS);
-                push_capset(RUTABAGA_CAPSET_DRM);
+                    push_capset(RUTABAGA_CAPSET_VIRGL);
+                    push_capset(RUTABAGA_CAPSET_VIRGL2);
+                    push_capset(RUTABAGA_CAPSET_VENUS);
+                    push_capset(RUTABAGA_CAPSET_DRM);
+                } else {
+                    log::warn!("error initializing gpu backend=virglrenderer, falling back to 2d.");
+                    fallback_2d = true;
+                };
             }
 
             #[cfg(feature = "gfxstream")]
@@ -1220,8 +1274,15 @@ impl RutabagaBuilder {
             push_capset(RUTABAGA_CAPSET_CROSS_DOMAIN);
         }
 
+        if self.default_component == RutabagaComponentType::Rutabaga2D || fallback_2d {
+            let rutabaga_2d = Rutabaga2D::init(fence_handler.clone())?;
+            rutabaga_components.insert(RutabagaComponentType::Rutabaga2D, rutabaga_2d);
+        }
+
         Ok(Rutabaga {
             resources: Default::default(),
+            #[cfg(gfxstream_unstable)]
+            shareable_fences: Default::default(),
             contexts: Default::default(),
             components: rutabaga_components,
             default_component: self.default_component,
diff --git a/rutabaga_gfx/src/rutabaga_gralloc/minigbm.rs b/rutabaga_gfx/src/rutabaga_gralloc/minigbm.rs
index a7c12ae56..638a070f5 100644
--- a/rutabaga_gfx/src/rutabaga_gralloc/minigbm.rs
+++ b/rutabaga_gfx/src/rutabaga_gralloc/minigbm.rs
@@ -111,7 +111,10 @@ impl Gralloc for MinigbmDevice {
         }
 
         let mut reqs: ImageMemoryRequirements = Default::default();
-        let gbm_buffer = MinigbmBuffer(bo, self.clone());
+        let gbm_buffer = MinigbmBuffer {
+            bo,
+            _device: self.clone(),
+        };
 
         if gbm_buffer.cached() {
             reqs.map_info = RUTABAGA_MAP_CACHE_CACHED;
@@ -174,7 +177,10 @@ impl Gralloc for MinigbmDevice {
             return Err(RutabagaError::IoError(Error::last_os_error()));
         }
 
-        let gbm_buffer = MinigbmBuffer(bo, self.clone());
+        let gbm_buffer = MinigbmBuffer {
+            bo,
+            _device: self.clone(),
+        };
         let dmabuf = gbm_buffer.export()?.into();
         Ok(RutabagaHandle {
             os_handle: dmabuf,
@@ -184,7 +190,10 @@ impl Gralloc for MinigbmDevice {
 }
 
 /// An allocation from a `MinigbmDevice`.
-pub struct MinigbmBuffer(*mut gbm_bo, MinigbmDevice);
+pub struct MinigbmBuffer {
+    bo: *mut gbm_bo,
+    _device: MinigbmDevice,
+}
 
 // SAFETY:
 // Safe because minigbm handles synchronization internally.
@@ -198,56 +207,56 @@ impl MinigbmBuffer {
     pub fn width(&self) -> u32 {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { gbm_bo_get_width(self.0) }
+        unsafe { gbm_bo_get_width(self.bo) }
     }
 
     /// Height in pixels.
     pub fn height(&self) -> u32 {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { gbm_bo_get_height(self.0) }
+        unsafe { gbm_bo_get_height(self.bo) }
     }
 
     /// `DrmFormat` of the buffer.
     pub fn format(&self) -> DrmFormat {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { DrmFormat(gbm_bo_get_format(self.0)) }
+        unsafe { DrmFormat(gbm_bo_get_format(self.bo)) }
     }
 
     /// DrmFormat modifier flags for the buffer.
     pub fn format_modifier(&self) -> u64 {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { gbm_bo_get_modifier(self.0) }
+        unsafe { gbm_bo_get_modifier(self.bo) }
     }
 
     /// Number of planes present in this buffer.
     pub fn num_planes(&self) -> usize {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { gbm_bo_get_plane_count(self.0) as usize }
+        unsafe { gbm_bo_get_plane_count(self.bo) as usize }
     }
 
     /// Offset in bytes for the given plane.
     pub fn plane_offset(&self, plane: usize) -> u32 {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { gbm_bo_get_offset(self.0, plane) }
+        unsafe { gbm_bo_get_offset(self.bo, plane) }
     }
 
     /// Length in bytes of one row for the given plane.
     pub fn plane_stride(&self, plane: usize) -> u32 {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { gbm_bo_get_stride_for_plane(self.0, plane) }
+        unsafe { gbm_bo_get_stride_for_plane(self.bo, plane) }
     }
 
     /// Should buffer use cached mapping to guest
     pub fn cached(&self) -> bool {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        let mode = unsafe { gbm_bo_get_map_info(self.0) };
+        let mode = unsafe { gbm_bo_get_map_info(self.bo) };
         mode == gbm_bo_map_cache_mode::GBM_BO_MAP_CACHE_CACHED
     }
 
@@ -255,7 +264,7 @@ impl MinigbmBuffer {
     pub fn export(&self) -> RutabagaResult<File> {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        match unsafe { gbm_bo_get_fd(self.0) } {
+        match unsafe { gbm_bo_get_fd(self.bo) } {
             fd if fd >= 0 => {
                 // SAFETY: fd is expected to be valid.
                 let dmabuf = unsafe { File::from_raw_descriptor(fd) };
@@ -270,6 +279,6 @@ impl Drop for MinigbmBuffer {
     fn drop(&mut self) {
         // SAFETY:
         // This is always safe to call with a valid gbm_bo pointer.
-        unsafe { gbm_bo_destroy(self.0) }
+        unsafe { gbm_bo_destroy(self.bo) }
     }
 }
diff --git a/rutabaga_gfx/src/rutabaga_gralloc/vulkano_gralloc.rs b/rutabaga_gfx/src/rutabaga_gralloc/vulkano_gralloc.rs
index cfcb61575..c4d7c8bc6 100644
--- a/rutabaga_gfx/src/rutabaga_gralloc/vulkano_gralloc.rs
+++ b/rutabaga_gfx/src/rutabaga_gralloc/vulkano_gralloc.rs
@@ -99,6 +99,21 @@ unsafe impl MappedRegion for VulkanoMapping {
     fn size(&self) -> usize {
         self.size
     }
+
+    /// Returns rutabaga mapping representation of the region
+    fn as_rutabaga_mapping(&self) -> RutabagaMapping {
+        let ptr: u64 = unsafe {
+            // Will not panic since the requested range of the device memory was verified on
+            // creation
+            let x = self.mapped_memory.write(0..self.size as u64).unwrap();
+            x.as_mut_ptr() as u64
+        };
+
+        RutabagaMapping {
+            ptr,
+            size: self.size as u64,
+        }
+    }
 }
 
 trait DeviceExt {
diff --git a/rutabaga_gfx/src/rutabaga_os/descriptor.rs b/rutabaga_gfx/src/rutabaga_os/descriptor.rs
index abeb247b0..4f362216e 100644
--- a/rutabaga_gfx/src/rutabaga_os/descriptor.rs
+++ b/rutabaga_gfx/src/rutabaga_os/descriptor.rs
@@ -35,15 +35,6 @@ pub trait AsRawDescriptor {
     fn as_raw_descriptor(&self) -> RawDescriptor;
 }
 
-/// A trait similar to `AsRawDescriptor` but supports an arbitrary number of descriptors.
-pub trait AsRawDescriptors {
-    /// Returns the underlying raw descriptors.
-    ///
-    /// Please refer to the documentation of [`AsRawDescriptor::as_raw_descriptor`] for limitations
-    /// and recommended use.
-    fn as_raw_descriptors(&self) -> Vec<RawDescriptor>;
-}
-
 pub trait FromRawDescriptor {
     /// # Safety
     /// Safe only if the caller ensures nothing has access to the descriptor after passing it to
@@ -57,15 +48,6 @@ impl AsRawDescriptor for SafeDescriptor {
     }
 }
 
-impl<T> AsRawDescriptors for T
-where
-    T: AsRawDescriptor,
-{
-    fn as_raw_descriptors(&self) -> Vec<RawDescriptor> {
-        vec![self.as_raw_descriptor()]
-    }
-}
-
 impl IntoRawDescriptor for SafeDescriptor {
     fn into_raw_descriptor(self) -> RawDescriptor {
         let descriptor = self.descriptor;
diff --git a/rutabaga_gfx/src/rutabaga_os/mod.rs b/rutabaga_gfx/src/rutabaga_os/mod.rs
index 7d0dd4430..ef38a4c8f 100644
--- a/rutabaga_gfx/src/rutabaga_os/mod.rs
+++ b/rutabaga_gfx/src/rutabaga_os/mod.rs
@@ -8,14 +8,31 @@ mod shm;
 pub mod sys;
 
 pub use descriptor::AsRawDescriptor;
-pub use descriptor::AsRawDescriptors;
 pub use descriptor::FromRawDescriptor;
 pub use descriptor::IntoRawDescriptor;
 pub use descriptor::SafeDescriptor;
 pub use memory_mapping::MemoryMapping;
 pub use shm::SharedMemory;
 pub use sys::platform::descriptor::RawDescriptor;
+pub use sys::platform::descriptor::DEFAULT_RAW_DESCRIPTOR;
 pub use sys::platform::shm::round_up_to_page_size;
+pub use sys::platform::tube::Listener;
+pub use sys::platform::tube::Tube;
+pub use sys::platform::wait_context::WaitContext;
+
+use crate::rutabaga_utils::RutabagaMapping;
+
+pub struct WaitEvent {
+    pub connection_id: u64,
+    pub hung_up: bool,
+    pub readable: bool,
+}
+
+#[allow(dead_code)]
+const WAIT_CONTEXT_MAX: usize = 16;
+
+#[allow(dead_code)]
+pub trait WaitTrait {}
 
 /// # Safety
 ///
@@ -28,4 +45,7 @@ pub unsafe trait MappedRegion: Send + Sync {
 
     /// Returns the size of the memory region in bytes.
     fn size(&self) -> usize;
+
+    /// Returns rutabaga mapping representation of the region
+    fn as_rutabaga_mapping(&self) -> RutabagaMapping;
 }
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/linux/descriptor.rs b/rutabaga_gfx/src/rutabaga_os/sys/linux/descriptor.rs
index f286ae116..b23278e12 100644
--- a/rutabaga_gfx/src/rutabaga_os/sys/linux/descriptor.rs
+++ b/rutabaga_gfx/src/rutabaga_os/sys/linux/descriptor.rs
@@ -22,6 +22,7 @@ type Error = std::io::Error;
 type Result<T> = std::result::Result<T, Error>;
 
 pub type RawDescriptor = RawFd;
+pub const DEFAULT_RAW_DESCRIPTOR: RawDescriptor = -1;
 
 /// Clones `fd`, returning a new file descriptor that refers to the same open file description as
 /// `fd`. The cloned fd will have the `FD_CLOEXEC` flag set but will not share any other file
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/linux/mod.rs b/rutabaga_gfx/src/rutabaga_os/sys/linux/mod.rs
index 3d948362b..f617bafad 100644
--- a/rutabaga_gfx/src/rutabaga_os/sys/linux/mod.rs
+++ b/rutabaga_gfx/src/rutabaga_os/sys/linux/mod.rs
@@ -5,7 +5,8 @@
 pub mod descriptor;
 pub mod memory_mapping;
 pub mod shm;
+pub mod tube;
+pub mod wait_context;
 
 pub use memory_mapping::MemoryMapping;
-pub use shm::round_up_to_page_size;
 pub use shm::SharedMemory;
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/linux/tube.rs b/rutabaga_gfx/src/rutabaga_os/sys/linux/tube.rs
new file mode 100644
index 000000000..2ac1cb3f3
--- /dev/null
+++ b/rutabaga_gfx/src/rutabaga_os/sys/linux/tube.rs
@@ -0,0 +1,155 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::fs::File;
+use std::io::Error as IoError;
+use std::io::IoSlice;
+use std::io::IoSliceMut;
+use std::os::fd::AsFd;
+use std::os::fd::AsRawFd;
+use std::os::fd::BorrowedFd;
+use std::os::fd::OwnedFd;
+use std::path::Path;
+
+use nix::cmsg_space;
+use nix::fcntl::fcntl;
+use nix::fcntl::FcntlArg;
+use nix::fcntl::OFlag;
+use nix::sys::socket::accept;
+use nix::sys::socket::bind;
+use nix::sys::socket::connect;
+use nix::sys::socket::listen;
+use nix::sys::socket::recvmsg;
+use nix::sys::socket::sendmsg;
+use nix::sys::socket::socket;
+use nix::sys::socket::AddressFamily;
+use nix::sys::socket::Backlog;
+use nix::sys::socket::ControlMessage;
+use nix::sys::socket::ControlMessageOwned;
+use nix::sys::socket::MsgFlags;
+use nix::sys::socket::SockFlag;
+use nix::sys::socket::SockType;
+use nix::sys::socket::UnixAddr;
+use nix::NixPath;
+
+use crate::rutabaga_os::AsRawDescriptor;
+use crate::rutabaga_os::FromRawDescriptor;
+use crate::rutabaga_os::RawDescriptor;
+use crate::rutabaga_utils::RutabagaError;
+use crate::rutabaga_utils::RutabagaResult;
+
+const MAX_IDENTIFIERS: usize = 28;
+
+pub struct Tube {
+    socket: File,
+}
+
+impl Tube {
+    pub fn new<P: AsRef<Path> + NixPath>(path: P) -> RutabagaResult<Tube> {
+        let socket_fd = socket(
+            AddressFamily::Unix,
+            SockType::SeqPacket,
+            SockFlag::empty(),
+            None,
+        )?;
+
+        let unix_addr = UnixAddr::new(&path)?;
+        connect(socket_fd.as_raw_fd(), &unix_addr)?;
+        let socket: File = socket_fd.into();
+
+        Ok(Tube { socket })
+    }
+
+    pub fn send(&self, opaque_data: &[u8], descriptors: &[RawDescriptor]) -> RutabagaResult<usize> {
+        let cmsg = ControlMessage::ScmRights(descriptors);
+        let bytes_sent = sendmsg::<()>(
+            self.socket.as_raw_descriptor(),
+            &[IoSlice::new(opaque_data)],
+            &[cmsg],
+            MsgFlags::empty(),
+            None,
+        )?;
+
+        Ok(bytes_sent)
+    }
+
+    pub fn receive(&self, opaque_data: &mut [u8]) -> RutabagaResult<(usize, Vec<File>)> {
+        let mut iovecs = [IoSliceMut::new(opaque_data)];
+        let mut cmsgspace = cmsg_space!([RawDescriptor; MAX_IDENTIFIERS]);
+        let flags = MsgFlags::empty();
+
+        let r = recvmsg::<()>(
+            self.socket.as_raw_descriptor(),
+            &mut iovecs,
+            Some(&mut cmsgspace),
+            flags,
+        )?;
+
+        let len = r.bytes;
+        let files = match r.cmsgs().next() {
+            Some(ControlMessageOwned::ScmRights(fds)) => {
+                fds.into_iter()
+                    .map(|fd| {
+                        // SAFETY:
+                        // Safe since the descriptors from recvmsg(..) are owned by us and
+                        // valid.
+                        unsafe { File::from_raw_descriptor(fd) }
+                    })
+                    .collect()
+            }
+            Some(_) => return Err(RutabagaError::Unsupported),
+            None => Vec::new(),
+        };
+
+        Ok((len, files))
+    }
+}
+
+impl AsFd for Tube {
+    fn as_fd(&self) -> BorrowedFd {
+        self.socket.as_fd()
+    }
+}
+
+impl From<File> for Tube {
+    fn from(file: File) -> Tube {
+        Tube { socket: file }
+    }
+}
+
+pub struct Listener {
+    socket: OwnedFd,
+}
+
+impl Listener {
+    /// Creates a new `Listener` bound to the given path.
+    pub fn bind<P: AsRef<Path> + NixPath>(path: P) -> RutabagaResult<Listener> {
+        let socket = socket(
+            AddressFamily::Unix,
+            SockType::SeqPacket,
+            SockFlag::empty(),
+            None,
+        )?;
+
+        let unix_addr = UnixAddr::new(&path)?;
+        bind(socket.as_raw_fd(), &unix_addr)?;
+        listen(&socket, Backlog::new(128)?)?;
+
+        fcntl(socket.as_raw_fd(), FcntlArg::F_SETFL(OFlag::O_NONBLOCK))?;
+
+        Ok(Listener { socket })
+    }
+
+    pub fn accept(&self) -> RutabagaResult<Tube> {
+        let sock = match accept(self.socket.as_raw_fd()) {
+            Ok(socket) => socket,
+            Err(_) => return Err(IoError::last_os_error().into()),
+        };
+
+        // SAFETY: Safe because we know the underlying OS descriptor is valid and
+        // owned by us.
+        let descriptor: File = unsafe { File::from_raw_descriptor(sock) };
+        Ok(descriptor.into())
+    }
+}
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/linux/wait_context.rs b/rutabaga_gfx/src/rutabaga_os/sys/linux/wait_context.rs
new file mode 100644
index 000000000..f145a6531
--- /dev/null
+++ b/rutabaga_gfx/src/rutabaga_os/sys/linux/wait_context.rs
@@ -0,0 +1,78 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::os::fd::AsFd;
+use std::time::Duration;
+
+use nix::sys::epoll::Epoll;
+use nix::sys::epoll::EpollCreateFlags;
+use nix::sys::epoll::EpollEvent;
+use nix::sys::epoll::EpollFlags;
+use nix::sys::epoll::EpollTimeout;
+
+use crate::rutabaga_os::WaitEvent;
+use crate::rutabaga_os::WAIT_CONTEXT_MAX;
+use crate::rutabaga_utils::RutabagaResult;
+
+pub struct WaitContext {
+    epoll_ctx: Epoll,
+}
+
+impl WaitContext {
+    pub fn new() -> RutabagaResult<WaitContext> {
+        let epoll = Epoll::new(EpollCreateFlags::empty())?;
+        Ok(WaitContext { epoll_ctx: epoll })
+    }
+
+    pub fn add<Waitable: AsFd>(
+        &mut self,
+        connection_id: u64,
+        waitable: Waitable,
+    ) -> RutabagaResult<()> {
+        self.epoll_ctx.add(
+            waitable,
+            EpollEvent::new(EpollFlags::EPOLLIN, connection_id),
+        )?;
+        Ok(())
+    }
+
+    pub fn wait(&mut self, duration_opt: Option<Duration>) -> RutabagaResult<Vec<WaitEvent>> {
+        let mut events = [EpollEvent::empty(); WAIT_CONTEXT_MAX];
+
+        let epoll_timeout = duration_opt
+            .map(|duration| {
+                if duration.is_zero() {
+                    EpollTimeout::ZERO
+                } else {
+                    // We shouldn't need timeouts greater than 60s.
+                    let timeout: u16 = duration.as_millis().try_into().unwrap_or(u16::MAX);
+                    EpollTimeout::from(timeout)
+                }
+            })
+            .unwrap_or(EpollTimeout::NONE);
+
+        let count = loop {
+            match self.epoll_ctx.wait(&mut events, epoll_timeout) {
+                Err(nix::errno::Errno::EINTR) => (),
+                result => break result?,
+            }
+        };
+
+        let events = events[0..count]
+            .iter()
+            .map(|e| WaitEvent {
+                connection_id: e.data(),
+                readable: e.events() & EpollFlags::EPOLLIN == EpollFlags::EPOLLIN,
+                hung_up: e.events() & EpollFlags::EPOLLHUP == EpollFlags::EPOLLHUP,
+            })
+            .collect();
+
+        Ok(events)
+    }
+
+    pub fn delete<Waitable: AsFd>(&mut self, waitable: Waitable) -> RutabagaResult<()> {
+        self.epoll_ctx.delete(waitable)?;
+        Ok(())
+    }
+}
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/stub/descriptor.rs b/rutabaga_gfx/src/rutabaga_os/sys/stub/descriptor.rs
index af0296d5d..8d501fe0c 100644
--- a/rutabaga_gfx/src/rutabaga_os/sys/stub/descriptor.rs
+++ b/rutabaga_gfx/src/rutabaga_os/sys/stub/descriptor.rs
@@ -13,6 +13,7 @@ type Error = std::io::Error;
 type Result<T> = std::result::Result<T, Error>;
 
 pub type RawDescriptor = i64;
+pub const DEFAULT_RAW_DESCRIPTOR: RawDescriptor = -1;
 
 impl Drop for SafeDescriptor {
     fn drop(&mut self) {
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/stub/mod.rs b/rutabaga_gfx/src/rutabaga_os/sys/stub/mod.rs
index 3d948362b..f617bafad 100644
--- a/rutabaga_gfx/src/rutabaga_os/sys/stub/mod.rs
+++ b/rutabaga_gfx/src/rutabaga_os/sys/stub/mod.rs
@@ -5,7 +5,8 @@
 pub mod descriptor;
 pub mod memory_mapping;
 pub mod shm;
+pub mod tube;
+pub mod wait_context;
 
 pub use memory_mapping::MemoryMapping;
-pub use shm::round_up_to_page_size;
 pub use shm::SharedMemory;
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/stub/tube.rs b/rutabaga_gfx/src/rutabaga_os/sys/stub/tube.rs
new file mode 100644
index 000000000..57b8d60ca
--- /dev/null
+++ b/rutabaga_gfx/src/rutabaga_os/sys/stub/tube.rs
@@ -0,0 +1,47 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::fs::File;
+use std::path::Path;
+
+use crate::rutabaga_os::RawDescriptor;
+use crate::rutabaga_os::WaitTrait;
+use crate::rutabaga_utils::RutabagaError;
+use crate::rutabaga_utils::RutabagaResult;
+
+pub struct Stub(());
+pub type Tube = Stub;
+pub type Listener = Stub;
+
+impl Tube {
+    pub fn new<P: AsRef<Path>>(_path: P) -> RutabagaResult<Tube> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn send(
+        &self,
+        _opaque_data: &[u8],
+        _descriptors: &[RawDescriptor],
+    ) -> RutabagaResult<usize> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn receive(&self, _opaque_data: &mut [u8]) -> RutabagaResult<(usize, Vec<File>)> {
+        Err(RutabagaError::Unsupported)
+    }
+}
+
+impl WaitTrait for Tube {}
+impl WaitTrait for &Tube {}
+
+impl Listener {
+    /// Creates a new `Listener` bound to the given path.
+    pub fn bind<P: AsRef<Path>>(_path: P) -> RutabagaResult<Listener> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn accept(&self) -> RutabagaResult<Tube> {
+        Err(RutabagaError::Unsupported)
+    }
+}
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/stub/wait_context.rs b/rutabaga_gfx/src/rutabaga_os/sys/stub/wait_context.rs
new file mode 100644
index 000000000..1c2303bd9
--- /dev/null
+++ b/rutabaga_gfx/src/rutabaga_os/sys/stub/wait_context.rs
@@ -0,0 +1,35 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::time::Duration;
+
+use crate::rutabaga_os::WaitEvent;
+use crate::rutabaga_os::WaitTrait;
+use crate::rutabaga_utils::RutabagaError;
+use crate::rutabaga_utils::RutabagaResult;
+
+pub struct Stub(());
+pub type WaitContext = Stub;
+
+impl WaitContext {
+    pub fn new() -> RutabagaResult<WaitContext> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn add<Waitable: WaitTrait>(
+        &mut self,
+        _connection_id: u64,
+        _waitable: Waitable,
+    ) -> RutabagaResult<()> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn wait(&mut self, _duration_opt: Option<Duration>) -> RutabagaResult<Vec<WaitEvent>> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn delete<Waitable: WaitTrait>(&mut self, _waitable: Waitable) -> RutabagaResult<()> {
+        Err(RutabagaError::Unsupported)
+    }
+}
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/windows/descriptor.rs b/rutabaga_gfx/src/rutabaga_os/sys/windows/descriptor.rs
index 6535863b8..1d1aaba11 100644
--- a/rutabaga_gfx/src/rutabaga_os/sys/windows/descriptor.rs
+++ b/rutabaga_gfx/src/rutabaga_os/sys/windows/descriptor.rs
@@ -12,6 +12,7 @@ use std::os::windows::io::AsRawHandle;
 use std::os::windows::io::FromRawHandle;
 use std::os::windows::io::IntoRawHandle;
 use std::os::windows::io::RawHandle;
+use std::os::windows::raw::HANDLE;
 
 use winapi::shared::minwindef::FALSE;
 use winapi::shared::minwindef::TRUE;
@@ -30,6 +31,8 @@ type Error = std::io::Error;
 type Result<T> = std::result::Result<T, Error>;
 
 pub type RawDescriptor = RawHandle;
+// Same as winapi::um::handleapi::INVALID_HANDLE_VALUE, but avoids compile issues.
+pub const DEFAULT_RAW_DESCRIPTOR: RawDescriptor = -1isize as HANDLE;
 
 impl Drop for SafeDescriptor {
     fn drop(&mut self) {
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/windows/mod.rs b/rutabaga_gfx/src/rutabaga_os/sys/windows/mod.rs
index 3d948362b..f617bafad 100644
--- a/rutabaga_gfx/src/rutabaga_os/sys/windows/mod.rs
+++ b/rutabaga_gfx/src/rutabaga_os/sys/windows/mod.rs
@@ -5,7 +5,8 @@
 pub mod descriptor;
 pub mod memory_mapping;
 pub mod shm;
+pub mod tube;
+pub mod wait_context;
 
 pub use memory_mapping::MemoryMapping;
-pub use shm::round_up_to_page_size;
 pub use shm::SharedMemory;
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/windows/tube.rs b/rutabaga_gfx/src/rutabaga_os/sys/windows/tube.rs
new file mode 100644
index 000000000..57b8d60ca
--- /dev/null
+++ b/rutabaga_gfx/src/rutabaga_os/sys/windows/tube.rs
@@ -0,0 +1,47 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::fs::File;
+use std::path::Path;
+
+use crate::rutabaga_os::RawDescriptor;
+use crate::rutabaga_os::WaitTrait;
+use crate::rutabaga_utils::RutabagaError;
+use crate::rutabaga_utils::RutabagaResult;
+
+pub struct Stub(());
+pub type Tube = Stub;
+pub type Listener = Stub;
+
+impl Tube {
+    pub fn new<P: AsRef<Path>>(_path: P) -> RutabagaResult<Tube> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn send(
+        &self,
+        _opaque_data: &[u8],
+        _descriptors: &[RawDescriptor],
+    ) -> RutabagaResult<usize> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn receive(&self, _opaque_data: &mut [u8]) -> RutabagaResult<(usize, Vec<File>)> {
+        Err(RutabagaError::Unsupported)
+    }
+}
+
+impl WaitTrait for Tube {}
+impl WaitTrait for &Tube {}
+
+impl Listener {
+    /// Creates a new `Listener` bound to the given path.
+    pub fn bind<P: AsRef<Path>>(_path: P) -> RutabagaResult<Listener> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn accept(&self) -> RutabagaResult<Tube> {
+        Err(RutabagaError::Unsupported)
+    }
+}
diff --git a/rutabaga_gfx/src/rutabaga_os/sys/windows/wait_context.rs b/rutabaga_gfx/src/rutabaga_os/sys/windows/wait_context.rs
new file mode 100644
index 000000000..1c2303bd9
--- /dev/null
+++ b/rutabaga_gfx/src/rutabaga_os/sys/windows/wait_context.rs
@@ -0,0 +1,35 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+use std::time::Duration;
+
+use crate::rutabaga_os::WaitEvent;
+use crate::rutabaga_os::WaitTrait;
+use crate::rutabaga_utils::RutabagaError;
+use crate::rutabaga_utils::RutabagaResult;
+
+pub struct Stub(());
+pub type WaitContext = Stub;
+
+impl WaitContext {
+    pub fn new() -> RutabagaResult<WaitContext> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn add<Waitable: WaitTrait>(
+        &mut self,
+        _connection_id: u64,
+        _waitable: Waitable,
+    ) -> RutabagaResult<()> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn wait(&mut self, _duration_opt: Option<Duration>) -> RutabagaResult<Vec<WaitEvent>> {
+        Err(RutabagaError::Unsupported)
+    }
+
+    pub fn delete<Waitable: WaitTrait>(&mut self, _waitable: Waitable) -> RutabagaResult<()> {
+        Err(RutabagaError::Unsupported)
+    }
+}
diff --git a/rutabaga_gfx/src/rutabaga_utils.rs b/rutabaga_gfx/src/rutabaga_utils.rs
index 8177057ee..62a57f008 100644
--- a/rutabaga_gfx/src/rutabaga_utils.rs
+++ b/rutabaga_gfx/src/rutabaga_utils.rs
@@ -32,6 +32,9 @@ use vulkano::memory::MemoryMapError;
 use vulkano::LoadingError;
 #[cfg(feature = "vulkano")]
 use vulkano::VulkanError;
+use zerocopy::AsBytes;
+use zerocopy::FromBytes;
+use zerocopy::FromZeroes;
 
 use crate::rutabaga_os::SafeDescriptor;
 
@@ -108,14 +111,42 @@ pub struct Resource3DInfo {
 }
 
 /// A unique identifier for a device.
-#[derive(Copy, Clone, Debug, Default, PartialEq, Eq, PartialOrd, Ord, Hash)]
+#[derive(
+    Copy,
+    Clone,
+    Debug,
+    Default,
+    PartialEq,
+    Eq,
+    PartialOrd,
+    Ord,
+    Hash,
+    FromZeroes,
+    FromBytes,
+    AsBytes,
+)]
+#[repr(C)]
 pub struct DeviceId {
     pub device_uuid: [u8; 16],
     pub driver_uuid: [u8; 16],
 }
 
 /// Memory index and physical device id of the associated VkDeviceMemory.
-#[derive(Copy, Clone, Default)]
+#[derive(
+    Copy,
+    Clone,
+    Debug,
+    Default,
+    PartialEq,
+    Eq,
+    PartialOrd,
+    Ord,
+    Hash,
+    FromZeroes,
+    FromBytes,
+    AsBytes,
+)]
+#[repr(C)]
 pub struct VulkanInfo {
     pub memory_idx: u32,
     pub device_id: DeviceId,
@@ -127,7 +158,7 @@ pub const RUTABAGA_CONTEXT_INIT_CAPSET_ID_MASK: u32 = 0x00ff;
 /// Rutabaga flags for creating fences.
 pub const RUTABAGA_FLAG_FENCE: u32 = 1 << 0;
 pub const RUTABAGA_FLAG_INFO_RING_IDX: u32 = 1 << 1;
-pub const RUTABAGA_FLAG_FENCE_SHAREABLE: u32 = 1 << 2;
+pub const RUTABAGA_FLAG_FENCE_HOST_SHAREABLE: u32 = 1 << 2;
 
 /// Convenience struct for Rutabaga fences
 #[repr(C)]
@@ -585,7 +616,7 @@ pub struct Transfer3D {
 impl Transfer3D {
     /// Constructs a 2 dimensional XY box in 3 dimensional space with unit depth and zero
     /// displacement on the Z axis.
-    pub fn new_2d(x: u32, y: u32, w: u32, h: u32) -> Transfer3D {
+    pub fn new_2d(x: u32, y: u32, w: u32, h: u32, offset: u64) -> Transfer3D {
         Transfer3D {
             x,
             y,
@@ -596,7 +627,7 @@ impl Transfer3D {
             level: 0,
             stride: 0,
             layer_stride: 0,
-            offset: 0,
+            offset,
         }
     }
 
@@ -640,12 +671,20 @@ pub const RUTABAGA_FENCE_HANDLE_TYPE_SYNC_FD: u32 = 0x0007;
 pub const RUTABAGA_FENCE_HANDLE_TYPE_OPAQUE_WIN32: u32 = 0x0008;
 pub const RUTABAGA_FENCE_HANDLE_TYPE_ZIRCON: u32 = 0x0009;
 
+pub const RUTABAGA_FENCE_HANDLE_TYPE_EVENT_FD: u32 = 0x000a;
+
 /// Handle to OS-specific memory or synchronization objects.
 pub struct RutabagaHandle {
     pub os_handle: SafeDescriptor,
     pub handle_type: u32,
 }
 
+impl fmt::Debug for RutabagaHandle {
+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        f.debug_struct("Handle debug").finish()
+    }
+}
+
 impl RutabagaHandle {
     /// Clones an existing rutabaga handle, by using OS specific mechanisms.
     pub fn try_clone(&self) -> RutabagaResult<RutabagaHandle> {
diff --git a/rutabaga_gfx/src/virgl_renderer.rs b/rutabaga_gfx/src/virgl_renderer.rs
index c61891c46..648a30c3f 100644
--- a/rutabaga_gfx/src/virgl_renderer.rs
+++ b/rutabaga_gfx/src/virgl_renderer.rs
@@ -88,7 +88,12 @@ fn import_resource(resource: &mut RutabagaResource) -> RutabagaResult<()> {
 }
 
 impl RutabagaContext for VirglRendererContext {
-    fn submit_cmd(&mut self, commands: &mut [u8], fence_ids: &[u64]) -> RutabagaResult<()> {
+    fn submit_cmd(
+        &mut self,
+        commands: &mut [u8],
+        fence_ids: &[u64],
+        _shareable_fences: Vec<RutabagaHandle>,
+    ) -> RutabagaResult<()> {
         #[cfg(not(virgl_renderer_unstable))]
         if !fence_ids.is_empty() {
             return Err(RutabagaError::Unsupported);
@@ -151,7 +156,10 @@ impl RutabagaContext for VirglRendererContext {
         RutabagaComponentType::VirglRenderer
     }
 
-    fn context_create_fence(&mut self, fence: RutabagaFence) -> RutabagaResult<()> {
+    fn context_create_fence(
+        &mut self,
+        fence: RutabagaFence,
+    ) -> RutabagaResult<Option<RutabagaHandle>> {
         // RutabagaFence::flags are not compatible with virglrenderer's fencing API and currently
         // virglrenderer context's assume all fences on a single timeline are MERGEABLE, and enforce
         // this assumption.
@@ -167,7 +175,8 @@ impl RutabagaContext for VirglRendererContext {
                 fence.fence_id,
             )
         };
-        ret_to_res(ret)
+        ret_to_res(ret)?;
+        Ok(None)
     }
 }
 
diff --git a/sandbox/Cargo.toml b/sandbox/Cargo.toml
index 6070e5a87..f5876925f 100644
--- a/sandbox/Cargo.toml
+++ b/sandbox/Cargo.toml
@@ -9,8 +9,8 @@ base = { path = "../base" }
 
 [target.'cfg(windows)'.dependencies]
 win_util = { path = "../win_util"}
-winapi = { version = "*", features = ["everything", "std", "impl-default"] }
+winapi = { version = "0.3", features = ["everything", "std", "impl-default"] }
 
 [build-dependencies]
-anyhow = "*"
+anyhow = "1"
 prebuilts = { path = "../prebuilts" }
diff --git a/serde_keyvalue/Android.bp b/serde_keyvalue/Android.bp
index 92080a453..c03758aad 100644
--- a/serde_keyvalue/Android.bp
+++ b/serde_keyvalue/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "serde_keyvalue",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "argh",
@@ -46,7 +46,7 @@ rust_test {
     crate_name: "serde_keyvalue",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/serde_keyvalue/Cargo.toml b/serde_keyvalue/Cargo.toml
index f14133c18..bddb40b56 100644
--- a/serde_keyvalue/Cargo.toml
+++ b/serde_keyvalue/Cargo.toml
@@ -12,7 +12,7 @@ argh = { version = "0.1.7", optional = true }
 serde_keyvalue_derive = { path = "serde_keyvalue_derive", optional = true } # provided by ebuild
 serde = "1"
 thiserror = { version = "1.0.20" }
-remain = "*"
+remain = "0.2"
 num-traits = "0.2"
 nom = { version = "7.1.0", features = ["alloc"] }
 
diff --git a/serde_keyvalue/serde_keyvalue_derive/Android.bp b/serde_keyvalue/serde_keyvalue_derive/Android.bp
index 15d9f0f6e..2e2585a76 100644
--- a/serde_keyvalue/serde_keyvalue_derive/Android.bp
+++ b/serde_keyvalue/serde_keyvalue_derive/Android.bp
@@ -18,7 +18,7 @@ rust_proc_macro {
     crate_name: "serde_keyvalue_derive",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libargh",
diff --git a/src/crosvm/cmdline.rs b/src/crosvm/cmdline.rs
index 8c182cf24..82e26f8c8 100644
--- a/src/crosvm/cmdline.rs
+++ b/src/crosvm/cmdline.rs
@@ -7,8 +7,10 @@ cfg_if::cfg_if! {
         use base::RawDescriptor;
         use devices::virtio::vhost::user::device::parse_wayland_sock;
 
+        use crate::crosvm::sys::config::parse_pmem_ext2_option;
         use crate::crosvm::sys::config::VfioOption;
         use crate::crosvm::sys::config::SharedDir;
+        use crate::crosvm::sys::config::PmemExt2Option;
     }
 }
 
@@ -21,6 +23,7 @@ use std::sync::atomic::AtomicUsize;
 use std::sync::atomic::Ordering;
 
 use arch::CpuSet;
+use arch::FdtPosition;
 use arch::Pstore;
 #[cfg(target_arch = "x86_64")]
 use arch::SmbiosOptions;
@@ -66,6 +69,7 @@ use serde::Serialize;
 #[cfg(feature = "gpu")]
 use serde_keyvalue::FromKeyValues;
 
+use super::config::PmemOption;
 #[cfg(feature = "gpu")]
 use super::gpu_config::fixup_gpu_display_options;
 #[cfg(feature = "gpu")]
@@ -76,6 +80,11 @@ use crate::crosvm::config::from_key_values;
 use crate::crosvm::config::parse_bus_id_addr;
 use crate::crosvm::config::parse_cpu_affinity;
 use crate::crosvm::config::parse_cpu_capacity;
+#[cfg(all(
+    any(target_arch = "arm", target_arch = "aarch64"),
+    any(target_os = "android", target_os = "linux")
+))]
+use crate::crosvm::config::parse_cpu_frequencies;
 use crate::crosvm::config::parse_dynamic_power_coefficient;
 #[cfg(target_arch = "x86_64")]
 use crate::crosvm::config::parse_memory_region;
@@ -227,7 +236,7 @@ pub struct CreateCompositeCommand {
     #[argh(positional, arg_name = "PATH")]
     /// image path
     pub path: String,
-    #[argh(positional, arg_name = "LABEL:PARTITION<:writable>")]
+    #[argh(positional, arg_name = "LABEL:PARTITION[:writable][:<GUID>]")]
     /// partitions
     pub partitions: Vec<String>,
 }
@@ -671,7 +680,7 @@ pub struct UsbDetachCommand {
 }
 
 #[derive(FromArgs)]
-/// Detach usb device
+/// List currently attached USB devices
 #[argh(subcommand, name = "list")]
 pub struct UsbListCommand {
     #[argh(positional, arg_name = "VM_SOCKET")]
@@ -1130,6 +1139,20 @@ pub struct RunCommand {
     /// group the given CPUs into a cluster (default: no clusters)
     pub cpu_cluster: Vec<CpuSet>,
 
+    #[cfg(all(
+        any(target_arch = "arm", target_arch = "aarch64"),
+        any(target_os = "android", target_os = "linux")
+    ))]
+    #[argh(
+        option,
+        arg_name = "CPU=FREQS[,CPU=FREQS[,...]]",
+        from_str_fn(parse_cpu_frequencies)
+    )]
+    #[serde(skip)]
+    #[merge(strategy = overwrite_option)]
+    /// set the list of frequencies in KHz for the given CPU (default: no frequencies)
+    pub cpu_frequencies_khz: Option<BTreeMap<usize, Vec<u32>>>, // CPU index -> frequencies
+
     #[argh(option, short = 'c')]
     #[merge(strategy = overwrite_option)]
     /// cpu parameters.
@@ -1194,8 +1217,9 @@ pub struct RunCommand {
     #[argh(option, short = 'd', arg_name = "PATH[,key=value[,key=value[,...]]]")]
     #[serde(skip)] // Deprecated - use `block` instead.
     #[merge(strategy = append)]
+    // (DEPRECATED): Use `block` instead.
     /// path to a disk image followed by optional comma-separated
-    /// options.  Deprecated - use `block` instead.
+    /// options.
     /// Valid keys:
     ///    sparse=BOOL - Indicates whether the disk should support
     ///        the discard operation (default: true)
@@ -1270,6 +1294,18 @@ pub struct RunCommand {
     /// gather and display statistics on Vm Exits and Bus Reads/Writes.
     pub exit_stats: Option<bool>,
 
+    #[argh(option)]
+    #[serde(skip)]
+    #[merge(strategy = overwrite)]
+    /// where the FDT is placed in memory.
+    ///
+    /// On x86_64, no effect.
+    ///
+    /// On aarch64, defaults to `end` for kernel payloads and to `start` for BIOS payloads.
+    ///
+    /// On riscv64, defaults to `after-payload`.
+    pub fdt_position: Option<FdtPosition>,
+
     #[argh(
         option,
         arg_name = "addr=NUM,size=SIZE,path=PATH[,offset=NUM][,rw][,sync]"
@@ -1488,6 +1524,7 @@ pub struct RunCommand {
     ///     single-touch[path=PATH,width=W,height=H,name=N]
     ///     switches[path=PATH]
     ///     trackpad[path=PATH,width=W,height=H,name=N]
+    ///     multi-touch-trackpad[path=PATH,width=W,height=H,name=N]
     /// See <https://crosvm.dev/book/devices/input.html> for more
     /// information.
     pub input: Vec<InputDeviceOption>,
@@ -1807,11 +1844,69 @@ pub struct RunCommand {
     /// absolute path to a directory that will become root filesystem for the plugin process.
     pub plugin_root: Option<PathBuf>,
 
+    #[argh(option)]
+    #[serde(default)]
+    #[merge(strategy = append)]
+    /// parameters for setting up a virtio-pmem device.
+    /// Valid keys:
+    ///     path=PATH - Path to the disk image. Can be specified
+    ///         without the key as the first argument.
+    ///     ro=BOOL - Whether the pmem device should be read-only.
+    ///         (default: false)
+    ///     vma-size=BYTES - (Experimental) Size in bytes
+    ///        of an anonymous virtual memory area that is
+    ///        created to back this device. When this
+    ///        option is specified, the disk image path
+    ///        is used to name the memory area
+    ///     swap-interval-ms=NUM - (Experimental) Interval
+    ///        in milliseconds for periodic swap out of
+    ///        memory mapping created by this device. 0
+    ///        means the memory mapping won't be swapped
+    ///        out by crosvm
+    pub pmem: Vec<PmemOption>,
+
     #[argh(option, arg_name = "PATH")]
     #[serde(skip)] // TODO(b/255223604)
     #[merge(strategy = append)]
+    /// (DEPRECATED): Use --pmem instead.
     /// path to a disk image
-    pub pmem_device: Vec<DiskOption>,
+    pmem_device: Vec<DiskOption>,
+
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    #[argh(
+        option,
+        arg_name = "PATH[,key=value[,key=value[,...]]]",
+        from_str_fn(parse_pmem_ext2_option)
+    )]
+    #[serde(default)]
+    #[merge(strategy = append)]
+    /// (EXPERIMENTAL): construct an ext2 file system on a pmem
+    /// device from the given directory. The argument is the form of
+    /// "PATH[,key=value[,key=value[,...]]]".
+    /// Valid keys:
+    ///     blocks_per_group=NUM - Number of blocks in a block
+    ///       group. (default: 4096)
+    ///     inodes_per_group=NUM - Number of inodes in a block
+    ///       group. (default: 1024)
+    ///     size=BYTES - Size of the memory region allocated by this
+    ///       device. A file system will be built on the region. If
+    ///       the filesystem doesn't fit within this size, crosvm
+    ///       will fail to start with an error.
+    ///       The number of block groups in the file system is
+    ///       calculated from this value and other given parameters.
+    ///       The value of `size` must be larger than (4096 *
+    ///        blocks_per_group.) (default: 16777216)
+    ///     uid=UID - uid of the mkfs process in the user
+    ///       namespace created by minijail. (default: 0)
+    ///     gid=GID - gid of the mkfs process in the user
+    ///       namespace created by minijail. (default: 0)
+    ///     uidmap=UIDMAP - a uid map in the format
+    ///       "inner outer count[,inner outer count]". This format
+    ///       is same as one for minijail.
+    ///       (default: "0 <current euid> 1")
+    ///     gidmap=GIDMAP - a gid map in the same format as uidmap
+    ///       (default: "0 <current egid> 1")
+    pub pmem_ext2: Vec<PmemExt2Option>,
 
     #[cfg(feature = "process-invariants")]
     #[argh(option, arg_name = "PATH")]
@@ -1874,6 +1969,7 @@ pub struct RunCommand {
     ///     [--pstore <path=PATH,size=SIZE>]
     pub pstore: Option<Pstore>,
 
+    #[cfg(feature = "pvclock")]
     #[argh(switch)]
     #[serde(skip)] // TODO(b/255223604)
     #[merge(strategy = overwrite_option)]
@@ -1890,8 +1986,9 @@ pub struct RunCommand {
     #[argh(option, arg_name = "PATH[,key=value[,key=value[,...]]]", short = 'r')]
     #[serde(skip)] // Deprecated - use `block` instead.
     #[merge(strategy = overwrite_option)]
+    // (DEPRECATED): Use `block` instead.
     /// path to a disk image followed by optional comma-separated
-    /// options.  Deprecated - use `block` instead.
+    /// options.
     /// Valid keys:
     ///     sparse=BOOL - Indicates whether the disk should support
     ///         the discard operation (default: true)
@@ -1917,14 +2014,16 @@ pub struct RunCommand {
     #[argh(option, arg_name = "PATH")]
     #[serde(skip)] // TODO(b/255223604)
     #[merge(strategy = append)]
+    /// (DEPRECATED): Use --pmem instead.
     /// path to a writable disk image
     rw_pmem_device: Vec<DiskOption>,
 
     #[argh(option, arg_name = "PATH[,key=value[,key=value[,...]]]")]
     #[serde(skip)] // Deprecated - use `block` instead.
     #[merge(strategy = append)]
+    // (DEPRECATED): Use `block` instead.
     /// path to a read-write disk image followed by optional
-    /// comma-separated options. Deprecated - use `block` instead.
+    /// comma-separated options.
     /// Valid keys:
     ///     sparse=BOOL - Indicates whether the disk should support
     ///        the discard operation (default: true)
@@ -1938,8 +2037,9 @@ pub struct RunCommand {
     #[argh(option, arg_name = "PATH[,key=value[,key=value[,...]]]")]
     #[serde(skip)] // Deprecated - use `block` instead.
     #[merge(strategy = overwrite_option)]
+    // (DEPRECATED) Use `block` instead.
     /// path to a read-write root disk image followed by optional
-    /// comma-separated options.  Deprecated - use `block` instead.
+    /// comma-separated options.
     /// Valid keys:
     ///     sparse=BOOL - Indicates whether the disk should support
     ///       the discard operation (default: true)
@@ -2093,6 +2193,23 @@ pub struct RunCommand {
     ///        namespace created by minijail. (default: 0)
     ///     gid=GID - gid of the device process in the user
     ///        namespace created by minijail. (default: 0)
+    ///     max_dynamic_perm=uint - Indicates maximum number of
+    ///        dynamic permissions that the shared directory allows.
+    ///         (default: 0). The fuse server will return EPERM
+    ///         Error when FS_IOC_SETPERMISSION ioctl is called
+    ///         in the device if current dyamic permission path is
+    ///         lager or equal to this value.
+    ///     max_dynamic_xattr=uint - Indicates maximum number of
+    ///        dynamic xattrs that the shared directory allows.
+    ///         (default: 0). The fuse server will return EPERM
+    ///         Error when FS_IOC_SETPATHXATTR ioctl is called
+    ///         in the device if current dyamic permission path is
+    ///         lager or equal to this value.
+    ///     security_ctx=BOOL - Enables FUSE_SECURITY_CONTEXT
+    ///        feature(default: true). This should be set to false
+    ///        in case the when the host not allowing write to
+    ///        /proc/<pid>/attr/fscreate, or guest directory does
+    ///        not care about the security context.
     ///     Options uid and gid are useful when the crosvm process
     ///     has no CAP_SETGID/CAP_SETUID but an identity mapping of
     ///     the current user/group between the VM and the host is
@@ -2162,13 +2279,6 @@ pub struct RunCommand {
     /// (EXPERIMENTAL) enable split-irqchip support
     pub split_irqchip: Option<bool>,
 
-    #[cfg(feature = "balloon")]
-    #[argh(switch)]
-    #[serde(skip)] // TODO(b/255223604)
-    #[merge(strategy = overwrite_option)]
-    /// don't allow guest to use pages from the balloon
-    pub strict_balloon: Option<bool>,
-
     #[argh(
         option,
         arg_name = "DOMAIN:BUS:DEVICE.FUNCTION[,vendor=NUM][,device=NUM][,class=NUM][,subsystem_vendor=NUM][,subsystem_device=NUM][,revision=NUM]"
@@ -2357,6 +2467,13 @@ pub struct RunCommand {
     /// path to a socket for vhost-user block
     pub vhost_user_blk: Vec<VhostUserOption>,
 
+    #[argh(option)]
+    #[serde(skip)]
+    #[merge(strategy = overwrite_option)]
+    /// number of milliseconds to retry if the socket path is missing or has no listener. Defaults
+    /// to no retries.
+    pub vhost_user_connect_timeout_ms: Option<u64>,
+
     #[argh(option, arg_name = "SOCKET_PATH")]
     #[serde(skip)] // Deprecated - use `vhost-user` instead.
     #[merge(strategy = append)]
@@ -2455,16 +2572,6 @@ pub struct RunCommand {
     /// enable a virtual cpu freq device
     pub virt_cpufreq: Option<bool>,
 
-    #[cfg(all(
-        any(target_arch = "arm", target_arch = "aarch64"),
-        any(target_os = "android", target_os = "linux")
-    ))]
-    #[argh(option, arg_name = "SOCKET_PATH")]
-    #[serde(skip)]
-    #[merge(strategy = overwrite_option)]
-    /// (EXPERIMENTAL) use UDS for a virtual cpu freq device
-    pub virt_cpufreq_socket: Option<PathBuf>,
-
     #[cfg(feature = "audio")]
     #[argh(
         option,
@@ -2661,7 +2768,9 @@ impl TryFrom<RunCommand> for super::config::Config {
         ))]
         {
             cfg.virt_cpufreq = cmd.virt_cpufreq.unwrap_or_default();
-            cfg.virt_cpufreq_socket = cmd.virt_cpufreq_socket;
+            if let Some(frequencies) = cmd.cpu_frequencies_khz {
+                cfg.cpu_frequencies_khz = frequencies;
+            }
         }
 
         cfg.vcpu_cgroup_path = cmd.vcpu_cgroup_path;
@@ -2680,13 +2789,13 @@ impl TryFrom<RunCommand> for super::config::Config {
         #[cfg(target_arch = "aarch64")]
         {
             if cmd.mte.unwrap_or_default()
-                && !(cmd.pmem_device.is_empty()
+                && !(cmd.pmem.is_empty()
+                    && cmd.pmem_device.is_empty()
                     && cmd.pstore.is_none()
                     && cmd.rw_pmem_device.is_empty())
             {
                 return Err(
-                    "--mte cannot be specified together with --pmem-device, --pstore or --rw-pmem-device"
-                        .to_string(),
+                    "--mte cannot be specified together with --pstore or pmem flags".to_string(),
                 );
             }
             cfg.mte = cmd.mte.unwrap_or_default();
@@ -2758,6 +2867,13 @@ impl TryFrom<RunCommand> for super::config::Config {
             cfg.serial_parameters.insert(key, serial_params);
         }
 
+        if !(cmd.root.is_none()
+            && cmd.rwroot.is_none()
+            && cmd.disk.is_empty()
+            && cmd.rwdisk.is_empty())
+        {
+            log::warn!("Deprecated disk flags such as --[rw]disk or --[rw]root are passed. Use --block instead.");
+        }
         // Aggregate all the disks with the expected read-only and root values according to the
         // option they have been passed with.
         let mut disks = cmd
@@ -2788,51 +2904,82 @@ impl TryFrom<RunCommand> for super::config::Config {
 
         // Sort all our disks by index.
         disks.sort_by_key(|d| d.index);
+        cfg.disks = disks.into_iter().map(|d| d.disk_option).collect();
 
-        // Check that we don't have more than one root disk.
-        if disks.iter().filter(|d| d.disk_option.root).count() > 1
-            || cmd.scsi_block.iter().filter(|s| s.root).count() > 1
-            || disks.iter().any(|d| d.disk_option.root) && cmd.scsi_block.iter().any(|s| s.root)
-        {
-            return Err("only one root disk can be specified".to_string());
-        }
+        cfg.scsis = cmd.scsi_block;
 
-        // If we have a root disk, add the corresponding command-line parameters.
-        if let Some(d) = disks.iter().find(|d| d.disk_option.root) {
-            if d.index >= 26 {
-                return Err("ran out of letters for to assign to root disk".to_string());
-            }
-            cfg.params.push(format!(
-                "root=/dev/vd{} {}",
-                char::from(b'a' + d.index as u8),
-                if d.disk_option.read_only { "ro" } else { "rw" }
-            ));
+        cfg.pmems = cmd.pmem;
+
+        if !cmd.pmem_device.is_empty() || !cmd.rw_pmem_device.is_empty() {
+            log::warn!(
+                "--pmem-device and --rw-pmem-device are deprecated. Please use --pmem instead."
+            );
         }
 
-        // Pass the sorted disks to the VM config.
-        cfg.disks = disks.into_iter().map(|d| d.disk_option).collect();
+        // Convert the deprecated `pmem_device` and `rw_pmem_device` into `pmem_devices`.
+        for disk_option in cmd.pmem_device.into_iter() {
+            cfg.pmems.push(PmemOption {
+                path: disk_option.path,
+                ro: true, // read-only
+                ..PmemOption::default()
+            });
+        }
+        for disk_option in cmd.rw_pmem_device.into_iter() {
+            cfg.pmems.push(PmemOption {
+                path: disk_option.path,
+                ro: false, // writable
+                ..PmemOption::default()
+            });
+        }
 
-        // If we have a root scsi disk, add the corresponding command-line parameters.
-        if let Some((i, s)) = cmd.scsi_block.iter().enumerate().find(|(_, s)| s.root) {
+        // Find the device to use as the kernel `root=` parameter. There can only be one.
+        let virtio_blk_root_devs = cfg
+            .disks
+            .iter()
+            .enumerate()
+            .filter(|(_, d)| d.root)
+            .map(|(i, d)| (format_disk_letter("/dev/vd", i), d.read_only));
+
+        let virtio_scsi_root_devs = cfg
+            .scsis
+            .iter()
+            .enumerate()
+            .filter(|(_, s)| s.root)
+            .map(|(i, s)| (format_disk_letter("/dev/sd", i), s.read_only));
+
+        let virtio_pmem_root_devs = cfg
+            .pmems
+            .iter()
+            .enumerate()
+            .filter(|(_, p)| p.root)
+            .map(|(i, p)| (format!("/dev/pmem{}", i), p.ro));
+
+        let mut root_devs = virtio_blk_root_devs
+            .chain(virtio_scsi_root_devs)
+            .chain(virtio_pmem_root_devs);
+        if let Some((root_dev, read_only)) = root_devs.next() {
             cfg.params.push(format!(
-                "root=/dev/sd{} {}",
-                char::from(b'a' + i as u8),
-                if s.read_only { "ro" } else { "rw" }
+                "root={} {}",
+                root_dev,
+                if read_only { "ro" } else { "rw" }
             ));
+
+            // If the iterator is not exhausted, the user specified `root=true` on more than one
+            // device, which is an error.
+            if root_devs.next().is_some() {
+                return Err("only one root disk can be specified".to_string());
+            }
         }
 
-        cfg.scsis = cmd.scsi_block;
+        #[cfg(any(target_os = "android", target_os = "linux"))]
+        {
+            cfg.pmem_ext2 = cmd.pmem_ext2;
+        }
 
-        for (mut pmem, read_only) in cmd
-            .pmem_device
-            .into_iter()
-            .map(|p| (p, true))
-            .chain(cmd.rw_pmem_device.into_iter().map(|p| (p, false)))
+        #[cfg(feature = "pvclock")]
         {
-            pmem.read_only = read_only;
-            cfg.pmem_devices.push(pmem);
+            cfg.pvclock = cmd.pvclock.unwrap_or_default();
         }
-        cfg.pvclock = cmd.pvclock.unwrap_or_default();
 
         #[cfg(windows)]
         {
@@ -2865,12 +3012,7 @@ impl TryFrom<RunCommand> for super::config::Config {
         }
         cfg.pstore = cmd.pstore;
 
-        cfg.enable_fw_cfg = if let Some(fw) = cmd.enable_fw_cfg {
-            fw
-        } else {
-            false
-        };
-
+        cfg.enable_fw_cfg = cmd.enable_fw_cfg.unwrap_or_default();
         cfg.fw_cfg_parameters = cmd.fw_cfg;
 
         #[cfg(any(target_os = "android", target_os = "linux"))]
@@ -3133,7 +3275,6 @@ impl TryFrom<RunCommand> for super::config::Config {
             cfg.balloon_page_reporting = cmd.balloon_page_reporting.unwrap_or_default();
             cfg.balloon_ws_num_bins = cmd.balloon_ws_num_bins.unwrap_or(4);
             cfg.balloon_ws_reporting = cmd.balloon_ws_reporting.unwrap_or_default();
-            cfg.strict_balloon = cmd.strict_balloon.unwrap_or_default();
             cfg.init_memory = cmd.init_mem;
         }
 
@@ -3150,14 +3291,19 @@ impl TryFrom<RunCommand> for super::config::Config {
             }
             cfg.gpu_parameters = cmd.gpu.into_iter().map(|p| p.0).take(1).next();
             if !cmd.gpu_display.is_empty() {
+                log::warn!("'--gpu-display' is deprecated; please use `--gpu displays=[...]`");
                 cfg.gpu_parameters
                     .get_or_insert_with(Default::default)
                     .display_params
                     .extend(cmd.gpu_display.into_iter().map(|p| p.0));
+            }
 
-                #[cfg(feature = "android_display")]
-                {
-                    cfg.android_display_service = cmd.android_display_service;
+            #[cfg(feature = "android_display")]
+            {
+                if let Some(gpu_parameters) = &cfg.gpu_parameters {
+                    if !gpu_parameters.display_params.is_empty() {
+                        cfg.android_display_service = cmd.android_display_service;
+                    }
                 }
             }
 
@@ -3406,6 +3552,8 @@ impl TryFrom<RunCommand> for super::config::Config {
 
         cfg.vhost_user = cmd.vhost_user;
 
+        cfg.vhost_user_connect_timeout_ms = cmd.vhost_user_connect_timeout_ms;
+
         // Convert an option from `VhostUserOption` to `VhostUserFrontendOption` with the given
         // device type.
         fn vu(
@@ -3454,6 +3602,8 @@ impl TryFrom<RunCommand> for super::config::Config {
 
         cfg.stub_pci_devices = cmd.stub_pci_device;
 
+        cfg.fdt_position = cmd.fdt_position;
+
         cfg.file_backed_mappings = cmd.file_backed_mapping;
 
         #[cfg(target_os = "android")]
@@ -3501,9 +3651,27 @@ impl TryFrom<RunCommand> for super::config::Config {
     }
 }
 
+// Produce a block device path as used by Linux block devices.
+//
+// Examples for "/dev/vdX":
+// /dev/vda, /dev/vdb, ..., /dev/vdz, /dev/vdaa, /dev/vdab, ...
+fn format_disk_letter(dev_prefix: &str, mut i: usize) -> String {
+    const ALPHABET_LEN: usize = 26; // a to z
+    let mut s = dev_prefix.to_string();
+    let insert_idx = dev_prefix.len();
+    loop {
+        s.insert(insert_idx, char::from(b'a' + (i % ALPHABET_LEN) as u8));
+        i /= ALPHABET_LEN;
+        if i == 0 {
+            break;
+        }
+        i -= 1;
+    }
+    s
+}
+
 #[cfg(test)]
 mod tests {
-    #[cfg(feature = "config-file")]
     use super::*;
 
     #[test]
@@ -3543,4 +3711,20 @@ mod tests {
             ]
         );
     }
+
+    #[test]
+    fn disk_letter() {
+        assert_eq!(format_disk_letter("/dev/sd", 0), "/dev/sda");
+        assert_eq!(format_disk_letter("/dev/sd", 1), "/dev/sdb");
+        assert_eq!(format_disk_letter("/dev/sd", 25), "/dev/sdz");
+        assert_eq!(format_disk_letter("/dev/sd", 26), "/dev/sdaa");
+        assert_eq!(format_disk_letter("/dev/sd", 27), "/dev/sdab");
+        assert_eq!(format_disk_letter("/dev/sd", 51), "/dev/sdaz");
+        assert_eq!(format_disk_letter("/dev/sd", 52), "/dev/sdba");
+        assert_eq!(format_disk_letter("/dev/sd", 53), "/dev/sdbb");
+        assert_eq!(format_disk_letter("/dev/sd", 78), "/dev/sdca");
+        assert_eq!(format_disk_letter("/dev/sd", 701), "/dev/sdzz");
+        assert_eq!(format_disk_letter("/dev/sd", 702), "/dev/sdaaa");
+        assert_eq!(format_disk_letter("/dev/sd", 703), "/dev/sdaab");
+    }
 }
diff --git a/src/crosvm/config.rs b/src/crosvm/config.rs
index 8caeda29c..a3cd1ac8f 100644
--- a/src/crosvm/config.rs
+++ b/src/crosvm/config.rs
@@ -9,9 +9,11 @@ use std::arch::x86_64::__cpuid_count;
 use std::collections::BTreeMap;
 use std::path::PathBuf;
 use std::str::FromStr;
+use std::time::Duration;
 
 use arch::set_default_serial_parameters;
 use arch::CpuSet;
+use arch::FdtPosition;
 use arch::Pstore;
 #[cfg(target_arch = "x86_64")]
 use arch::SmbiosOptions;
@@ -53,6 +55,7 @@ use hypervisor::ProtectionType;
 use jail::JailConfig;
 use resources::AddressRange;
 use serde::Deserialize;
+use serde::Deserializer;
 use serde::Serialize;
 use serde_keyvalue::FromKeyValues;
 use vm_control::BatteryType;
@@ -159,6 +162,42 @@ pub struct MemOptions {
     pub size: Option<u64>,
 }
 
+fn deserialize_swap_interval<'de, D: Deserializer<'de>>(
+    deserializer: D,
+) -> Result<Option<Duration>, D::Error> {
+    let ms = Option::<u64>::deserialize(deserializer)?;
+    match ms {
+        None => Ok(None),
+        Some(ms) => Ok(Some(Duration::from_millis(ms))),
+    }
+}
+
+#[derive(
+    Clone, Debug, Default, Serialize, Deserialize, PartialEq, Eq, serde_keyvalue::FromKeyValues,
+)]
+#[serde(deny_unknown_fields, rename_all = "kebab-case")]
+pub struct PmemOption {
+    /// Path to the diks image.
+    pub path: PathBuf,
+    /// Whether the disk is read-only.
+    #[serde(default)]
+    pub ro: bool,
+    /// If set, add a kernel command line option making this the root device. Can only be set once.
+    #[serde(default)]
+    pub root: bool,
+    /// Experimental option to specify the size in bytes of an anonymous virtual memory area that
+    /// will be created to back this device.
+    #[serde(default)]
+    pub vma_size: Option<u64>,
+    /// Experimental option to specify interval for periodic swap out of memory mapping
+    #[serde(
+        default,
+        deserialize_with = "deserialize_swap_interval",
+        rename = "swap-interval-ms"
+    )]
+    pub swap_interval: Option<Duration>,
+}
+
 #[derive(Serialize, Deserialize, FromKeyValues)]
 #[serde(deny_unknown_fields, rename_all = "kebab-case")]
 pub struct VhostUserOption {
@@ -188,7 +227,10 @@ pub struct VhostUserFrontendOption {
 #[derive(Serialize, Deserialize, FromKeyValues)]
 #[serde(deny_unknown_fields, rename_all = "kebab-case")]
 pub struct VhostUserFsOption {
-    pub socket: PathBuf,
+    #[serde(alias = "socket")]
+    pub socket_path: Option<PathBuf>,
+    /// File descriptor of connected socket
+    pub socket_fd: Option<u32>,
     pub tag: Option<String>,
 
     /// Maximum number of entries per queue (default: 32768)
@@ -223,9 +265,10 @@ pub fn parse_vhost_user_fs_option(param: &str) -> Result<VhostUserFsOption, Stri
         );
 
         Ok(VhostUserFsOption {
-            socket,
+            socket_path: Some(socket),
             tag: Some(tag),
             max_queue_size: None,
+            socket_fd: None,
         })
     } else {
         from_key_values::<VhostUserFsOption>(param)
@@ -329,6 +372,12 @@ pub enum InputDeviceOption {
         height: Option<u32>,
         name: Option<String>,
     },
+    MultiTouchTrackpad {
+        path: PathBuf,
+        width: Option<u32>,
+        height: Option<u32>,
+        name: Option<String>,
+    },
 }
 
 #[derive(Debug, Serialize, Deserialize, FromKeyValues)]
@@ -553,6 +602,37 @@ pub fn parse_dynamic_power_coefficient(s: &str) -> Result<BTreeMap<usize, u32>,
     Ok(dyn_power_coefficient)
 }
 
+#[cfg(all(
+    any(target_arch = "arm", target_arch = "aarch64"),
+    any(target_os = "android", target_os = "linux")
+))]
+pub fn parse_cpu_frequencies(s: &str) -> Result<BTreeMap<usize, Vec<u32>>, String> {
+    let mut cpu_frequencies: BTreeMap<usize, Vec<u32>> = BTreeMap::default();
+    for cpufreq_assigns in s.split(';') {
+        let assignment: Vec<&str> = cpufreq_assigns.split('=').collect();
+        if assignment.len() != 2 {
+            return Err(invalid_value_err(
+                cpufreq_assigns,
+                "invalid CPU freq syntax",
+            ));
+        }
+        let cpu = assignment[0].parse().map_err(|_| {
+            invalid_value_err(assignment[0], "CPU index must be a non-negative integer")
+        })?;
+        let freqs = assignment[1]
+            .split(',')
+            .map(|x| x.parse::<u32>().unwrap())
+            .collect::<Vec<_>>();
+        if cpu_frequencies.insert(cpu, freqs).is_some() {
+            return Err(invalid_value_err(
+                cpufreq_assigns,
+                "CPU index must be unique",
+            ));
+        }
+    }
+    Ok(cpu_frequencies)
+}
+
 pub fn from_key_values<'a, T: Deserialize<'a>>(value: &'a str) -> Result<T, String> {
     serde_keyvalue::from_key_values(value).map_err(|e| e.to_string())
 }
@@ -673,6 +753,11 @@ pub struct Config {
     pub core_scheduling: bool,
     pub cpu_capacity: BTreeMap<usize, u32>, // CPU index -> capacity
     pub cpu_clusters: Vec<CpuSet>,
+    #[cfg(all(
+        any(target_arch = "arm", target_arch = "aarch64"),
+        any(target_os = "android", target_os = "linux")
+    ))]
+    pub cpu_frequencies_khz: BTreeMap<usize, Vec<u32>>, // CPU index -> frequencies
     #[cfg(feature = "crash-report")]
     pub crash_pipe_name: Option<String>,
     #[cfg(feature = "crash-report")]
@@ -692,6 +777,7 @@ pub struct Config {
     pub executable_path: Option<Executable>,
     #[cfg(windows)]
     pub exit_stats: bool,
+    pub fdt_position: Option<FdtPosition>,
     pub file_backed_mappings: Vec<FileBackedMappingParameters>,
     pub force_calibrated_tsc_leaf: bool,
     pub force_s2idle: bool,
@@ -757,7 +843,9 @@ pub struct Config {
     #[cfg(feature = "plugin")]
     pub plugin_mounts: Vec<crate::crosvm::plugin::BindMount>,
     pub plugin_root: Option<PathBuf>,
-    pub pmem_devices: Vec<DiskOption>,
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    pub pmem_ext2: Vec<crate::crosvm::sys::config::PmemExt2Option>,
+    pub pmems: Vec<PmemOption>,
     #[cfg(feature = "process-invariants")]
     pub process_invariants_data_handle: Option<u64>,
     #[cfg(feature = "process-invariants")]
@@ -770,6 +858,7 @@ pub struct Config {
     pub product_version: Option<String>,
     pub protection_type: ProtectionType,
     pub pstore: Option<Pstore>,
+    #[cfg(feature = "pvclock")]
     pub pvclock: bool,
     /// Must be `Some` iff `protection_type == ProtectionType::UnprotectedWithFirmware`.
     pub pvm_fw: Option<PathBuf>,
@@ -789,12 +878,10 @@ pub struct Config {
     #[cfg(target_arch = "x86_64")]
     pub smbios: SmbiosOptions,
     #[cfg(all(windows, feature = "audio"))]
-    pub snd_split_config: Option<SndSplitConfig>,
+    pub snd_split_configs: Vec<SndSplitConfig>,
     pub socket_path: Option<PathBuf>,
     #[cfg(feature = "audio")]
     pub sound: Option<PathBuf>,
-    #[cfg(feature = "balloon")]
-    pub strict_balloon: bool,
     pub stub_pci_devices: Vec<StubPciParameters>,
     pub suspended: bool,
     pub swap_dir: Option<PathBuf>,
@@ -820,6 +907,7 @@ pub struct Config {
     #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
     pub vhost_scmi_device: PathBuf,
     pub vhost_user: Vec<VhostUserFrontendOption>,
+    pub vhost_user_connect_timeout_ms: Option<u64>,
     pub vhost_user_fs: Vec<VhostUserFsOption>,
     #[cfg(feature = "video-decoder")]
     pub video_dec: Vec<VideoDeviceConfig>,
@@ -830,7 +918,6 @@ pub struct Config {
         any(target_os = "android", target_os = "linux")
     ))]
     pub virt_cpufreq: bool,
-    pub virt_cpufreq_socket: Option<PathBuf>,
     pub virtio_input: Vec<InputDeviceOption>,
     #[cfg(feature = "audio")]
     #[serde(skip)]
@@ -887,6 +974,11 @@ impl Default for Config {
             crash_report_uuid: None,
             cpu_capacity: BTreeMap::new(),
             cpu_clusters: Vec::new(),
+            #[cfg(all(
+                any(target_arch = "arm", target_arch = "aarch64"),
+                any(target_os = "android", target_os = "linux")
+            ))]
+            cpu_frequencies_khz: BTreeMap::new(),
             delay_rt: false,
             device_tree_overlay: Vec::new(),
             disks: Vec::new(),
@@ -902,6 +994,7 @@ impl Default for Config {
             executable_path: None,
             #[cfg(windows)]
             exit_stats: false,
+            fdt_position: None,
             file_backed_mappings: Vec::new(),
             force_calibrated_tsc_leaf: false,
             force_s2idle: false,
@@ -977,7 +1070,9 @@ impl Default for Config {
             #[cfg(feature = "plugin")]
             plugin_mounts: Vec::new(),
             plugin_root: None,
-            pmem_devices: Vec::new(),
+            #[cfg(any(target_os = "android", target_os = "linux"))]
+            pmem_ext2: Vec::new(),
+            pmems: Vec::new(),
             #[cfg(feature = "process-invariants")]
             process_invariants_data_handle: None,
             #[cfg(feature = "process-invariants")]
@@ -986,6 +1081,7 @@ impl Default for Config {
             product_name: None,
             protection_type: ProtectionType::Unprotected,
             pstore: None,
+            #[cfg(feature = "pvclock")]
             pvclock: false,
             pvm_fw: None,
             restore_path: None,
@@ -1002,12 +1098,10 @@ impl Default for Config {
             #[cfg(target_arch = "x86_64")]
             smbios: SmbiosOptions::default(),
             #[cfg(all(windows, feature = "audio"))]
-            snd_split_config: None,
+            snd_split_configs: Vec::new(),
             socket_path: None,
             #[cfg(feature = "audio")]
             sound: None,
-            #[cfg(feature = "balloon")]
-            strict_balloon: false,
             stub_pci_devices: Vec::new(),
             suspended: false,
             swap_dir: None,
@@ -1033,6 +1127,7 @@ impl Default for Config {
             #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
             vhost_scmi_device: PathBuf::from(VHOST_SCMI_PATH),
             vhost_user: Vec::new(),
+            vhost_user_connect_timeout_ms: None,
             vhost_user_fs: Vec::new(),
             vsock: None,
             #[cfg(feature = "video-decoder")]
@@ -1044,7 +1139,6 @@ impl Default for Config {
                 any(target_os = "android", target_os = "linux")
             ))]
             virt_cpufreq: false,
-            virt_cpufreq_socket: None,
             virtio_input: Vec::new(),
             #[cfg(feature = "audio")]
             virtio_snds: Vec::new(),
@@ -1135,6 +1229,23 @@ pub fn validate_config(cfg: &mut Config) -> std::result::Result<(), String> {
         cfg.boot_cpu = 0;
     }
 
+    #[cfg(all(
+        any(target_arch = "arm", target_arch = "aarch64"),
+        any(target_os = "android", target_os = "linux")
+    ))]
+    if !cfg.cpu_frequencies_khz.is_empty() {
+        if !cfg.virt_cpufreq {
+            return Err("`cpu-frequencies` requires `virt-cpufreq`".to_string());
+        }
+
+        if cfg.host_cpu_topology {
+            return Err(
+                "`host-cpu-topology` cannot be used with 'cpu-frequencies` at the same time"
+                    .to_string(),
+            );
+        }
+    }
+
     #[cfg(all(
         any(target_arch = "arm", target_arch = "aarch64"),
         any(target_os = "android", target_os = "linux")
@@ -1240,6 +1351,10 @@ pub fn validate_config(cfg: &mut Config) -> std::result::Result<(), String> {
         validate_file_backed_mapping(mapping)?;
     }
 
+    for pmem in cfg.pmems.iter() {
+        validate_pmem(pmem)?;
+    }
+
     // Validate platform specific things
     super::sys::config::validate_config(cfg)
 }
@@ -1262,6 +1377,24 @@ fn validate_file_backed_mapping(mapping: &mut FileBackedMappingParameters) -> Re
     Ok(())
 }
 
+fn validate_pmem(pmem: &PmemOption) -> Result<(), String> {
+    if (pmem.swap_interval.is_some() && pmem.vma_size.is_none())
+        || (pmem.swap_interval.is_none() && pmem.vma_size.is_some())
+    {
+        return Err(
+            "--pmem vma-size and swap-interval parameters must be specified together".to_string(),
+        );
+    }
+
+    if pmem.ro && pmem.swap_interval.is_some() {
+        return Err(
+            "--pmem swap-interval parameter can only be set for writable pmem device".to_string(),
+        );
+    }
+
+    Ok(())
+}
+
 #[cfg(test)]
 #[allow(clippy::needless_update)]
 mod tests {
@@ -1942,9 +2075,11 @@ mod tests {
 
         assert_eq!(cfg.vhost_user_fs.len(), 1);
         let fs = &cfg.vhost_user_fs[0];
-        assert_eq!(fs.socket.to_str(), Some("my_socket"));
+        let socket = fs.socket_path.as_ref().unwrap();
+        assert_eq!(socket.to_str(), Some("my_socket"));
         assert_eq!(fs.tag, Some("my_tag".to_string()));
         assert_eq!(fs.max_queue_size, None);
+        assert_eq!(fs.socket_fd, None);
     }
 
     #[test]
@@ -1960,7 +2095,31 @@ mod tests {
 
         assert_eq!(cfg.vhost_user_fs.len(), 1);
         let fs = &cfg.vhost_user_fs[0];
-        assert_eq!(fs.socket.to_str(), Some("my_socket"));
+        let socket = fs.socket_path.as_ref().unwrap();
+        assert_eq!(socket.to_str(), Some("my_socket"));
+        assert_eq!(fs.tag, Some("my_tag".to_string()));
+        assert_eq!(fs.max_queue_size, None);
+    }
+
+    #[test]
+    fn parse_vhost_user_fs_explict_socket() {
+        let cfg = TryInto::<Config>::try_into(
+            crate::crosvm::cmdline::RunCommand::from_args(
+                &[],
+                &[
+                    "--vhost-user-fs",
+                    "socket=my_socket,tag=my_tag",
+                    "/dev/null",
+                ],
+            )
+            .unwrap(),
+        )
+        .unwrap();
+
+        assert_eq!(cfg.vhost_user_fs.len(), 1);
+        let fs = &cfg.vhost_user_fs[0];
+        let socket = fs.socket_path.as_ref().unwrap();
+        assert_eq!(socket.to_str(), Some("my_socket"));
         assert_eq!(fs.tag, Some("my_tag".to_string()));
         assert_eq!(fs.max_queue_size, None);
     }
@@ -1982,7 +2141,8 @@ mod tests {
 
         assert_eq!(cfg.vhost_user_fs.len(), 1);
         let fs = &cfg.vhost_user_fs[0];
-        assert_eq!(fs.socket.to_str(), Some("my_socket"));
+        let socket = fs.socket_path.as_ref().unwrap();
+        assert_eq!(socket.to_str(), Some("my_socket"));
         assert_eq!(fs.tag, Some("my_tag".to_string()));
         assert_eq!(fs.max_queue_size, Some(256));
     }
@@ -2000,11 +2160,35 @@ mod tests {
 
         assert_eq!(cfg.vhost_user_fs.len(), 1);
         let fs = &cfg.vhost_user_fs[0];
-        assert_eq!(fs.socket.to_str(), Some("my_socket"));
+        let socket = fs.socket_path.as_ref().unwrap();
+        assert_eq!(socket.to_str(), Some("my_socket"));
         assert_eq!(fs.tag, None);
         assert_eq!(fs.max_queue_size, None);
     }
 
+    #[test]
+    fn parse_vhost_user_fs_socket_fd() {
+        let cfg = TryInto::<Config>::try_into(
+            crate::crosvm::cmdline::RunCommand::from_args(
+                &[],
+                &[
+                    "--vhost-user-fs",
+                    "tag=my_tag,max-queue-size=256,socket-fd=1234",
+                    "/dev/null",
+                ],
+            )
+            .unwrap(),
+        )
+        .unwrap();
+
+        assert_eq!(cfg.vhost_user_fs.len(), 1);
+        let fs = &cfg.vhost_user_fs[0];
+        assert!(fs.socket_path.is_none());
+        assert_eq!(fs.tag, Some("my_tag".to_string()));
+        assert_eq!(fs.max_queue_size, Some(256));
+        assert_eq!(fs.socket_fd.unwrap(), 1234_u32);
+    }
+
     #[cfg(target_arch = "x86_64")]
     #[test]
     fn parse_smbios_uuid() {
@@ -2288,4 +2472,62 @@ mod tests {
             }
         );
     }
+
+    #[test]
+    fn parse_pmem_options_missing_path() {
+        assert!(from_key_values::<PmemOption>("")
+            .unwrap_err()
+            .contains("missing field `path`"));
+    }
+
+    #[test]
+    fn parse_pmem_options_default_values() {
+        let pmem = from_key_values::<PmemOption>("/path/to/disk.img").unwrap();
+        assert_eq!(
+            pmem,
+            PmemOption {
+                path: "/path/to/disk.img".into(),
+                ro: false,
+                root: false,
+                vma_size: None,
+                swap_interval: None,
+            }
+        );
+    }
+
+    #[test]
+    fn parse_pmem_options_virtual_swap() {
+        let pmem =
+            from_key_values::<PmemOption>("virtual_path,vma-size=12345,swap-interval-ms=1000")
+                .unwrap();
+        assert_eq!(
+            pmem,
+            PmemOption {
+                path: "virtual_path".into(),
+                ro: false,
+                root: false,
+                vma_size: Some(12345),
+                swap_interval: Some(Duration::new(1, 0)),
+            }
+        );
+    }
+
+    #[test]
+    fn validate_pmem_missing_virtual_swap_param() {
+        let pmem = from_key_values::<PmemOption>("virtual_path,swap-interval-ms=1000").unwrap();
+        assert!(validate_pmem(&pmem)
+            .unwrap_err()
+            .contains("vma-size and swap-interval parameters must be specified together"));
+    }
+
+    #[test]
+    fn validate_pmem_read_only_virtual_swap() {
+        let pmem = from_key_values::<PmemOption>(
+            "virtual_path,ro=true,vma-size=12345,swap-interval-ms=1000",
+        )
+        .unwrap();
+        assert!(validate_pmem(&pmem)
+            .unwrap_err()
+            .contains("swap-interval parameter can only be set for writable pmem device"));
+    }
 }
diff --git a/src/crosvm/gpu_config.rs b/src/crosvm/gpu_config.rs
index c8ef82184..55c41fd50 100644
--- a/src/crosvm/gpu_config.rs
+++ b/src/crosvm/gpu_config.rs
@@ -2,6 +2,7 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
+use base::warn;
 use devices::virtio::gpu::VIRTIO_GPU_MAX_SCANOUTS;
 use devices::virtio::GpuDisplayMode;
 use devices::virtio::GpuDisplayParameters;
@@ -29,6 +30,10 @@ pub(crate) fn fixup_gpu_options(
         .map(|p| fixup_gpu_display_options(p).map(|p| p.0))
         .collect::<Result<Vec<_>, _>>()?;
 
+    if gpu_params.__width_compat.is_some() || gpu_params.__height_compat.is_some() {
+        warn!("'width' and 'height' in '--gpu' are deprecated; please use `displays=[...]`");
+    }
+
     match (
         gpu_params.__width_compat.take(),
         gpu_params.__height_compat.take(),
@@ -71,6 +76,9 @@ pub(crate) fn fixup_gpu_display_options(
         display_params.__horizontal_dpi_compat.take(),
         display_params.__vertical_dpi_compat.take(),
     );
+    if horizontal_dpi_compat.is_some() || vertical_dpi_compat.is_some() {
+        warn!("'horizontal-dpi' and 'vertical-dpi' are deprecated; please use `dpi=[...]`");
+    }
     // Make sure `display_params.dpi` is always populated.
     display_params.dpi = Some(match display_params.dpi {
         Some(dpi) => {
diff --git a/src/crosvm/plugin/vcpu.rs b/src/crosvm/plugin/vcpu.rs
index cfad4cf90..c1f11d91e 100644
--- a/src/crosvm/plugin/vcpu.rs
+++ b/src/crosvm/plugin/vcpu.rs
@@ -480,15 +480,13 @@ impl PluginVcpu {
                     let mut stream = CodedOutputStream::vec(&mut response_buffer);
                     match response.write_length_delimited_to(&mut stream) {
                         Ok(_) => {
-                            match stream.flush() {
-                                Ok(_) => {}
-                                Err(e) => error!("failed to flush to vec: {}", e),
+                            if let Err(e) = stream.flush() {
+                                error!("failed to flush to vec: {}", e);
                             }
                             drop(stream);
                             let mut write_pipe = &self.write_pipe;
-                            match write_pipe.write(&response_buffer[..]) {
-                                Ok(_) => {}
-                                Err(e) => error!("failed to write to pipe: {}", e),
+                            if let Err(e) = write_pipe.write_all(&response_buffer) {
+                                error!("failed to write to pipe: {}", e);
                             }
                         }
                         Err(e) => error!("failed to write to buffer: {}", e),
diff --git a/src/crosvm/sys/linux.rs b/src/crosvm/sys/linux.rs
index 38c7630a0..abf6150aa 100644
--- a/src/crosvm/sys/linux.rs
+++ b/src/crosvm/sys/linux.rs
@@ -7,6 +7,7 @@ mod android;
 pub mod cmdline;
 pub mod config;
 mod device_helpers;
+pub(crate) mod ext2;
 #[cfg(feature = "gpu")]
 pub(crate) mod gpu;
 #[cfg(feature = "pci-hotplug")]
@@ -17,6 +18,8 @@ pub(crate) mod pci_hotplug_helpers;
 pub(crate) mod pci_hotplug_manager;
 mod vcpu;
 
+#[cfg(all(feature = "pvclock", target_arch = "aarch64"))]
+use std::arch::asm;
 use std::cmp::max;
 use std::collections::BTreeMap;
 use std::collections::BTreeSet;
@@ -75,10 +78,9 @@ use cros_async::Executor;
 use device_helpers::*;
 use devices::create_devices_worker_thread;
 use devices::serial_device::SerialHardware;
-#[cfg(feature = "pvclock")]
+#[cfg(all(feature = "pvclock", target_arch = "x86_64"))]
 use devices::tsc::get_tsc_sync_mitigations;
-use devices::vfio::VfioCommonSetup;
-use devices::vfio::VfioCommonTrait;
+use devices::vfio::VfioContainerManager;
 #[cfg(feature = "gpu")]
 use devices::virtio;
 #[cfg(any(feature = "video-decoder", feature = "video-encoder"))]
@@ -88,12 +90,10 @@ use devices::virtio::gpu::EventDevice;
 #[cfg(target_arch = "x86_64")]
 use devices::virtio::memory_mapper::MemoryMapper;
 use devices::virtio::memory_mapper::MemoryMapperTrait;
+use devices::virtio::vhost::user::VhostUserConnectionTrait;
 use devices::virtio::vhost::user::VhostUserListener;
-use devices::virtio::vhost::user::VhostUserListenerTrait;
 #[cfg(feature = "balloon")]
 use devices::virtio::BalloonFeatures;
-#[cfg(feature = "balloon")]
-use devices::virtio::BalloonMode;
 #[cfg(feature = "pci-hotplug")]
 use devices::virtio::NetParameters;
 #[cfg(feature = "pci-hotplug")]
@@ -206,6 +206,7 @@ use crate::crosvm::ratelimit::Ratelimit;
 use crate::crosvm::sys::cmdline::DevicesCommand;
 use crate::crosvm::sys::config::SharedDir;
 use crate::crosvm::sys::config::SharedDirKind;
+use crate::crosvm::sys::platform::vcpu::VcpuPidTid;
 
 const KVM_PATH: &str = "/dev/kvm";
 #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
@@ -216,7 +217,7 @@ static GUNYAH_PATH: &str = "/dev/gunyah";
 
 fn create_virtio_devices(
     cfg: &Config,
-    vm: &mut impl Vm,
+    vm: &mut impl VmArch,
     resources: &mut SystemAllocator,
     #[cfg_attr(not(feature = "gpu"), allow(unused_variables))] vm_evt_wrtube: &SendTube,
     #[cfg(feature = "balloon")] balloon_device_tube: Option<Tube>,
@@ -225,7 +226,9 @@ fn create_virtio_devices(
     #[cfg(feature = "balloon")] dynamic_mapping_device_tube: Option<Tube>,
     disk_device_tubes: &mut Vec<Tube>,
     pmem_device_tubes: &mut Vec<Tube>,
+    pmem_ext2_mem_clients: &mut Vec<VmMemoryClient>,
     fs_device_tubes: &mut Vec<Tube>,
+    worker_process_pids: &mut BTreeSet<Pid>,
     #[cfg(feature = "gpu")] gpu_control_tube: Tube,
     #[cfg(feature = "gpu")] render_server_fd: Option<SafeDescriptor>,
     #[cfg(feature = "gpu")] has_vfio_gfx_device: bool,
@@ -390,7 +393,7 @@ fn create_virtio_devices(
         );
     }
 
-    for (index, pmem_disk) in cfg.pmem_devices.iter().enumerate() {
+    for (index, pmem_disk) in cfg.pmems.iter().enumerate() {
         let pmem_device_tube = pmem_device_tubes.remove(0);
         devs.push(create_pmem_device(
             cfg.protection_type,
@@ -403,28 +406,67 @@ fn create_virtio_devices(
         )?);
     }
 
+    for (index, pmem_ext2) in cfg.pmem_ext2.iter().enumerate() {
+        let pmem_device_tube = pmem_device_tubes.remove(0);
+        let vm_memory_client = pmem_ext2_mem_clients.remove(0);
+        devs.push(create_pmem_ext2_device(
+            cfg.protection_type,
+            &cfg.jail_config,
+            resources,
+            pmem_ext2,
+            index,
+            vm_memory_client,
+            pmem_device_tube,
+            worker_process_pids,
+        )?);
+    }
+
     if cfg.rng {
         devs.push(create_rng_device(cfg.protection_type, &cfg.jail_config)?);
     }
 
     #[cfg(feature = "pvclock")]
     if let Some(suspend_tube) = pvclock_device_tube {
-        let tsc_state = devices::tsc::tsc_state()?;
-        let tsc_sync_mitigations =
-            get_tsc_sync_mitigations(&tsc_state, cfg.vcpu_count.unwrap_or(1));
-        if tsc_state.core_grouping.size() > 1 {
-            // Host TSCs are not in sync. Log what mitigations are applied.
-            warn!(
-                "Host TSCs are not in sync, applying the following mitigations: {:?}",
-                tsc_sync_mitigations
-            );
+        let frequency: u64;
+        #[cfg(target_arch = "x86_64")]
+        {
+            let tsc_state = devices::tsc::tsc_state()?;
+            let tsc_sync_mitigations =
+                get_tsc_sync_mitigations(&tsc_state, cfg.vcpu_count.unwrap_or(1));
+            if tsc_state.core_grouping.size() > 1 {
+                // Host TSCs are not in sync. Log what mitigations are applied.
+                warn!(
+                    "Host TSCs are not in sync, applying the following mitigations: {:?}",
+                    tsc_sync_mitigations
+                );
+            }
+            frequency = tsc_state.frequency;
+        }
+        #[cfg(target_arch = "aarch64")]
+        {
+            let mut x: u64;
+            // SAFETY: This instruction have no side effect apart from storing the current timestamp
+            //         frequency into the specified register.
+            unsafe {
+                asm!("mrs {x}, cntfrq_el0",
+                    x = out(reg) x,
+                );
+            }
+            frequency = x;
+
+            // If unset, KVM defaults to an offset that is calculated from VM boot time. Explicitly
+            // set it to zero on boot. When updating the offset, we always set it to the total
+            // amount of time the VM has been suspended.
+            vm.set_counter_offset(0)
+                .context("failed to set up pvclock")?;
         }
-        devs.push(create_pvclock_device(
+        let dev = create_pvclock_device(
             cfg.protection_type,
             &cfg.jail_config,
-            tsc_state.frequency,
+            frequency,
             suspend_tube,
-        )?);
+        )?;
+        devs.push(dev);
         info!("virtio-pvclock is enabled for this vm");
     }
 
@@ -445,6 +487,7 @@ fn create_virtio_devices(
     let mut multi_touch_idx = 0;
     let mut single_touch_idx = 0;
     let mut trackpad_idx = 0;
+    let mut multi_touch_trackpad_idx = 0;
     for input in &cfg.virtio_input {
         let input_dev = match input {
             InputDeviceOption::Evdev { path } => {
@@ -564,6 +607,24 @@ fn create_virtio_devices(
                 trackpad_idx += 1;
                 dev
             }
+            InputDeviceOption::MultiTouchTrackpad {
+                path,
+                width,
+                height,
+                name,
+            } => {
+                let dev = create_multitouch_trackpad_device(
+                    cfg.protection_type,
+                    &cfg.jail_config,
+                    path.as_path(),
+                    width.unwrap_or(DEFAULT_TOUCH_DEVICE_WIDTH),
+                    height.unwrap_or(DEFAULT_TOUCH_DEVICE_HEIGHT),
+                    name.as_deref(),
+                    multi_touch_trackpad_idx,
+                )?;
+                multi_touch_trackpad_idx += 1;
+                dev
+            }
         };
         devs.push(input_dev);
     }
@@ -578,11 +639,6 @@ fn create_virtio_devices(
         devs.push(create_balloon_device(
             cfg.protection_type,
             &cfg.jail_config,
-            if cfg.strict_balloon {
-                BalloonMode::Strict
-            } else {
-                BalloonMode::Relaxed
-            },
             balloon_device_tube,
             balloon_inflate_tube,
             init_balloon_size,
@@ -606,11 +662,13 @@ fn create_virtio_devices(
 
     #[cfg(feature = "audio")]
     {
-        for virtio_snd in &cfg.virtio_snds {
+        for (card_index, virtio_snd) in cfg.virtio_snds.iter().enumerate() {
+            let mut snd_params = virtio_snd.clone();
+            snd_params.card_index = card_index;
             devs.push(create_virtio_snd_device(
                 cfg.protection_type,
                 &cfg.jail_config,
-                virtio_snd.clone(),
+                snd_params,
             )?);
         }
     }
@@ -717,7 +775,11 @@ fn create_virtio_devices(
     }
 
     for opt in &cfg.vhost_user {
-        devs.push(create_vhost_user_frontend(cfg.protection_type, opt)?);
+        devs.push(create_vhost_user_frontend(
+            cfg.protection_type,
+            opt,
+            cfg.vhost_user_connect_timeout_ms,
+        )?);
     }
 
     Ok(devs)
@@ -725,7 +787,7 @@ fn create_virtio_devices(
 
 fn create_devices(
     cfg: &Config,
-    vm: &mut impl Vm,
+    vm: &mut impl VmArch,
     resources: &mut SystemAllocator,
     vm_evt_wrtube: &SendTube,
     iommu_attached_endpoints: &mut BTreeMap<u32, Arc<Mutex<Box<dyn MemoryMapperTrait>>>>,
@@ -737,6 +799,7 @@ fn create_devices(
     #[cfg(feature = "balloon")] dynamic_mapping_device_tube: Option<Tube>,
     disk_device_tubes: &mut Vec<Tube>,
     pmem_device_tubes: &mut Vec<Tube>,
+    pmem_ext2_mem_clients: &mut Vec<VmMemoryClient>,
     fs_device_tubes: &mut Vec<Tube>,
     #[cfg(feature = "usb")] usb_provider: DeviceProvider,
     #[cfg(feature = "gpu")] gpu_control_tube: Tube,
@@ -744,6 +807,9 @@ fn create_devices(
     iova_max_addr: &mut Option<u64>,
     #[cfg(feature = "registered_events")] registered_evt_q: &SendTube,
     #[cfg(feature = "pvclock")] pvclock_device_tube: Option<Tube>,
+    vfio_container_manager: &mut VfioContainerManager,
+    // Stores a set of PID of child processes that are suppose to exit cleanly.
+    worker_process_pids: &mut BTreeSet<Pid>,
 ) -> DeviceResult<Vec<(Box<dyn BusDeviceObj>, Option<Minijail>)>> {
     let mut devices: Vec<(Box<dyn BusDeviceObj>, Option<Minijail>)> = Vec::new();
     #[cfg(feature = "balloon")]
@@ -768,6 +834,7 @@ fn create_devices(
                 Some(&mut coiommu_attached_endpoints),
                 vfio_dev.iommu,
                 vfio_dev.dt_symbol.clone(),
+                vfio_container_manager,
             )?;
             match dev {
                 VfioDeviceVariant::Pci(vfio_pci_device) => {
@@ -828,9 +895,9 @@ fn create_devices(
         #[cfg(not(feature = "balloon"))]
         let coiommu_tube: Option<Tube> = None;
         if !coiommu_attached_endpoints.is_empty() {
-            let vfio_container =
-                VfioCommonSetup::vfio_get_container(IommuDevType::CoIommu, None as Option<&Path>)
-                    .context("failed to get vfio container")?;
+            let vfio_container = vfio_container_manager
+                .get_container(IommuDevType::CoIommu, None as Option<&Path>)
+                .context("failed to get vfio container")?;
             let (coiommu_host_tube, coiommu_device_tube) =
                 Tube::pair().context("failed to create coiommu tube")?;
             vm_memory_control_tubes.push(VmMemoryTube {
@@ -879,7 +946,9 @@ fn create_devices(
         dynamic_mapping_device_tube,
         disk_device_tubes,
         pmem_device_tubes,
+        pmem_ext2_mem_clients,
         fs_device_tubes,
+        worker_process_pids,
         #[cfg(feature = "gpu")]
         gpu_control_tube,
         #[cfg(feature = "gpu")]
@@ -1185,49 +1254,7 @@ fn setup_vm_components(cfg: &Config) -> Result<VmComponents> {
     #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
     let mut cpu_frequencies = BTreeMap::new();
     #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
-    let mut virt_cpufreq_socket = None;
-
-    #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
-    if cfg.virt_cpufreq {
-        let host_cpu_frequencies = Arch::get_host_cpu_frequencies_khz()?;
-
-        for cpu_id in 0..cfg.vcpu_count.unwrap_or(1) {
-            let vcpu_affinity = match cfg.vcpu_affinity.clone() {
-                Some(VcpuAffinity::Global(v)) => v,
-                Some(VcpuAffinity::PerVcpu(mut m)) => m.remove(&cpu_id).unwrap_or_default(),
-                None => {
-                    panic!("There must be some vcpu_affinity setting with VirtCpufreq enabled!")
-                }
-            };
-
-            // Check that the physical CPUs that the vCPU is affined to all share the same
-            // frequency domain.
-            if let Some(freq_domain) = host_cpu_frequencies.get(&vcpu_affinity[0]) {
-                for cpu in vcpu_affinity.iter() {
-                    if let Some(frequencies) = host_cpu_frequencies.get(cpu) {
-                        if frequencies != freq_domain {
-                            panic!("Affined CPUs do not share a frequency domain!");
-                        }
-                    }
-                }
-                cpu_frequencies.insert(cpu_id, freq_domain.clone());
-            } else {
-                panic!("No frequency domain for cpu:{}", cpu_id);
-            }
-        }
-
-        virt_cpufreq_socket = if let Some(path) = &cfg.virt_cpufreq_socket {
-            let file = base::open_file_or_duplicate(path, OpenOptions::new().write(true))
-                .with_context(|| {
-                    format!("failed to open virt_cpufreq_socket {}", path.display())
-                })?;
-            let fd: std::os::fd::OwnedFd = file.into();
-            let socket: std::os::unix::net::UnixStream = fd.into();
-            Some(socket)
-        } else {
-            None
-        };
-    }
+    let mut normalized_cpu_capacities = BTreeMap::new();
 
     // if --enable-fw-cfg or --fw-cfg was given, we want to enable fw_cfg
     let fw_cfg_enable = cfg.enable_fw_cfg || !cfg.fw_cfg_parameters.is_empty();
@@ -1240,6 +1267,62 @@ fn setup_vm_components(cfg: &Config) -> Result<VmComponents> {
         (cfg.cpu_clusters.clone(), cfg.cpu_capacity.clone())
     };
 
+    #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
+    if cfg.virt_cpufreq {
+        if !cfg.cpu_frequencies_khz.is_empty() {
+            cpu_frequencies = cfg.cpu_frequencies_khz.clone();
+        } else {
+            let host_cpu_frequencies = Arch::get_host_cpu_frequencies_khz()?;
+
+            for cpu_id in 0..cfg.vcpu_count.unwrap_or(1) {
+                let vcpu_affinity = match cfg.vcpu_affinity.clone() {
+                    Some(VcpuAffinity::Global(v)) => v,
+                    Some(VcpuAffinity::PerVcpu(mut m)) => m.remove(&cpu_id).unwrap_or_default(),
+                    None => {
+                        panic!("There must be some vcpu_affinity setting with VirtCpufreq enabled!")
+                    }
+                };
+
+                // Check that the physical CPUs that the vCPU is affined to all share the same
+                // frequency domain.
+                if let Some(freq_domain) = host_cpu_frequencies.get(&vcpu_affinity[0]) {
+                    for cpu in vcpu_affinity.iter() {
+                        if let Some(frequencies) = host_cpu_frequencies.get(cpu) {
+                            if frequencies != freq_domain {
+                                panic!("Affined CPUs do not share a frequency domain!");
+                            }
+                        }
+                    }
+                    cpu_frequencies.insert(cpu_id, freq_domain.clone());
+                } else {
+                    panic!("No frequency domain for cpu:{}", cpu_id);
+                }
+            }
+        }
+        let mut max_freqs = Vec::new();
+
+        for (_cpu, frequencies) in cpu_frequencies.iter() {
+            max_freqs.push(*frequencies.iter().max().ok_or(Error::new(libc::EINVAL))?)
+        }
+
+        let host_max_freqs = Arch::get_host_cpu_max_freq_khz()?;
+        let largest_host_max_freq = host_max_freqs
+            .values()
+            .max()
+            .ok_or(Error::new(libc::EINVAL))?;
+
+        for (cpu_id, max_freq) in max_freqs.iter().enumerate() {
+            let normalized_cpu_capacity = (u64::from(*cpu_capacity.get(&cpu_id).unwrap())
+                * u64::from(*max_freq))
+            .checked_div(u64::from(*largest_host_max_freq))
+            .ok_or(Error::new(libc::EINVAL))?;
+            normalized_cpu_capacities.insert(
+                cpu_id,
+                u32::try_from(normalized_cpu_capacity).map_err(|_| Error::new(libc::EINVAL))?,
+            );
+        }
+    }
+
     Ok(VmComponents {
         #[cfg(target_arch = "x86_64")]
         ac_adapter: cfg.ac_adapter,
@@ -1257,11 +1340,11 @@ fn setup_vm_components(cfg: &Config) -> Result<VmComponents> {
         vcpu_affinity: cfg.vcpu_affinity.clone(),
         #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
         cpu_frequencies,
-        #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
-        virt_cpufreq_socket,
         fw_cfg_parameters: cfg.fw_cfg_parameters.clone(),
         cpu_clusters,
         cpu_capacity,
+        #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
+        normalized_cpu_capacities,
         no_smt: cfg.no_smt,
         hugepages: cfg.hugepages,
         hv_cfg: hypervisor::Config {
@@ -1637,11 +1720,6 @@ fn get_default_hypervisor() -> Option<HypervisorKind> {
 }
 
 pub fn run_config(cfg: Config) -> Result<ExitState> {
-    if let Some(async_executor) = cfg.async_executor {
-        Executor::set_default_executor_kind(async_executor)
-            .context("Failed to set the default async executor")?;
-    }
-
     let components = setup_vm_components(&cfg)?;
 
     let hypervisor = cfg
@@ -1796,12 +1874,25 @@ where
     }
 
     let mut pmem_device_tubes = Vec::new();
-    let pmem_count = cfg.pmem_devices.len();
+    let pmem_count = cfg.pmems.len() + cfg.pmem_ext2.len();
     for _ in 0..pmem_count {
         let (pmem_host_tube, pmem_device_tube) = Tube::pair().context("failed to create tube")?;
         pmem_device_tubes.push(pmem_device_tube);
         control_tubes.push(TaggedControlTube::VmMsync(pmem_host_tube));
     }
+    let mut pmem_ext2_mem_client = Vec::new();
+    for _ in 0..cfg.pmem_ext2.len() {
+        let (pmem_ext2_host_tube, pmem_ext2_device_tube) =
+            Tube::pair().context("failed to create tube")?;
+        // Prepare two communication channels for pmem-ext2 device
+        // - pmem_ext2_mem_client: To send a request for mmap() and memory registeration.
+        // - vm_memory_control_tubes: To receive a memory slot number once the memory is registered.
+        pmem_ext2_mem_client.push(VmMemoryClient::new(pmem_ext2_device_tube));
+        vm_memory_control_tubes.push(VmMemoryTube {
+            tube: pmem_ext2_host_tube,
+            expose_with_viommu: false,
+        });
+    }
 
     if let Some(ioapic_host_tube) = ioapic_host_tube {
         irq_control_tubes.push(ioapic_host_tube);
@@ -1895,6 +1986,8 @@ where
         BTreeMap::new();
     let mut iova_max_addr: Option<u64> = None;
 
+    let mut vfio_container_manager = VfioContainerManager::new();
+
     // pvclock gets a tube for handling suspend/resume requests from the main thread.
     #[cfg(feature = "pvclock")]
     let (pvclock_host_tube, pvclock_device_tube) = if cfg.pvclock {
@@ -1903,15 +1996,13 @@ where
     } else {
         (None, None)
     };
-    #[cfg(not(feature = "pvclock"))]
-    if cfg.pvclock {
-        bail!("pvclock device is only supported when crosvm is built with a feature 'pvclock'");
-    }
 
     #[cfg(feature = "registered_events")]
     let (reg_evt_wrtube, reg_evt_rdtube) =
         Tube::directional_pair().context("failed to create registered event tube")?;
 
+    let mut worker_process_pids = BTreeSet::new();
+
     let mut devices = create_devices(
         &cfg,
         &mut vm,
@@ -1929,6 +2020,7 @@ where
         dynamic_mapping_device_tube,
         &mut disk_device_tubes,
         &mut pmem_device_tubes,
+        &mut pmem_ext2_mem_client,
         &mut fs_device_tubes,
         #[cfg(feature = "usb")]
         usb_provider,
@@ -1941,6 +2033,8 @@ where
         &reg_evt_wrtube,
         #[cfg(feature = "pvclock")]
         pvclock_device_tube,
+        &mut vfio_container_manager,
+        &mut worker_process_pids,
     )?;
 
     #[cfg(feature = "pci-hotplug")]
@@ -2126,10 +2220,11 @@ where
         &mut swap_controller,
         guest_suspended_cvar.clone(),
         dt_overlays,
+        cfg.fdt_position,
     )
     .context("the architecture failed to build the vm")?;
 
-    if let Some(tube) = linux.vm_request_tube.take() {
+    for tube in linux.vm_request_tubes.drain(..) {
         control_tubes.push(TaggedControlTube::Vm(tube));
     }
 
@@ -2220,6 +2315,8 @@ where
         #[cfg(feature = "pvclock")]
         pvclock_host_tube,
         metrics_recv,
+        vfio_container_manager,
+        worker_process_pids,
     )
 }
 
@@ -2263,9 +2360,9 @@ fn start_pci_root_worker(
                 })
                 .context("failed to send request")?;
             match self.vm_control_tube.recv::<VmMemoryResponse>() {
-                Ok(VmMemoryResponse::RegisterMemory(slot)) => {
+                Ok(VmMemoryResponse::RegisterMemory { region_id, .. }) => {
                     let cur_id = self.next_id;
-                    self.registered_regions.insert(cur_id, slot);
+                    self.registered_regions.insert(cur_id, region_id);
                     self.next_id += 1;
                     Ok(cur_id)
                 }
@@ -2332,6 +2429,7 @@ fn add_hotplug_device<V: VmArch, Vcpu: VcpuArch>(
     iommu_host_tube: Option<&Tube>,
     device: &HotPlugDeviceInfo,
     #[cfg(feature = "swap")] swap_controller: &mut Option<SwapController>,
+    vfio_container_manager: &mut VfioContainerManager,
 ) -> Result<()> {
     let host_addr = PciAddress::from_path(&device.path)
         .context("failed to parse hotplug device's PCI address")?;
@@ -2407,6 +2505,7 @@ fn add_hotplug_device<V: VmArch, Vcpu: VcpuArch>(
                     IommuDevType::NoIommu
                 },
                 None,
+                vfio_container_manager,
             )?;
             let vfio_pci_device = match vfio_device {
                 VfioDeviceVariant::Pci(pci) => Box::new(pci),
@@ -2718,7 +2817,7 @@ pub fn trigger_vm_suspend_and_wait_for_entry(
     guest_suspended_cvar: Arc<(Mutex<bool>, Condvar)>,
     tube: &SendTube,
     response: vm_control::VmResponse,
-    suspend_evt: Event,
+    suspend_tube: Arc<Mutex<SendTube>>,
     pm: Option<Arc<Mutex<dyn PmResource + Send>>>,
 ) {
     let (lock, cvar) = &*guest_suspended_cvar;
@@ -2745,7 +2844,7 @@ pub fn trigger_vm_suspend_and_wait_for_entry(
         info!("Guest suspended");
     }
 
-    if let Err(e) = suspend_evt.signal() {
+    if let Err(e) = suspend_tube.lock().send(&true) {
         error!("failed to trigger suspend event: {}", e);
     }
     // Now we ready to send response over the tube and communicate that VM suspend has finished
@@ -2755,21 +2854,48 @@ pub fn trigger_vm_suspend_and_wait_for_entry(
 }
 
 #[cfg(feature = "pvclock")]
-fn send_pvclock_cmd(tube: &Tube, command: PvClockCommand) -> Result<()> {
+#[derive(Debug)]
+/// The action requested by the pvclock device to perform on the main thread.
+enum PvClockAction {
+    #[cfg(target_arch = "aarch64")]
+    /// Update the counter offset with VmAarch64::set_counter_offset.
+    SetCounterOffset(u64),
+}
+
+#[cfg(feature = "pvclock")]
+fn send_pvclock_cmd(tube: &Tube, command: PvClockCommand) -> Result<Option<PvClockAction>> {
     tube.send(&command)
         .with_context(|| format!("failed to send pvclock command {:?}", command))?;
     let resp = tube
         .recv::<PvClockCommandResponse>()
         .context("failed to receive pvclock command response")?;
-    if let PvClockCommandResponse::Err(e) = resp {
-        bail!("pvclock encountered error on {:?}: {}", command, e);
-    }
-    if let PvClockCommandResponse::DeviceInactive = resp {
-        warn!("Tried to send {command:?} but pvclock device was inactive");
-    } else {
-        info!("{command:?} completed with {resp:?}");
+    match resp {
+        PvClockCommandResponse::Err(e) => {
+            bail!("pvclock encountered error on {:?}: {}", command, e);
+        }
+        PvClockCommandResponse::DeviceInactive => {
+            warn!("Tried to send {command:?} but pvclock device was inactive");
+            Ok(None)
+        }
+        PvClockCommandResponse::Resumed {
+            total_suspended_ticks,
+        } => {
+            info!("{command:?} completed with {total_suspended_ticks} total_suspended_ticks");
+            cfg_if::cfg_if! {
+                if #[cfg(target_arch = "aarch64")] {
+                    Ok(Some(PvClockAction::SetCounterOffset(total_suspended_ticks)))
+                } else {
+                    // For non-AArch64 platforms this is handled by directly updating the offset in
+                    // shared memory in the pvclock device worker.
+                    Ok(None)
+                }
+            }
+        }
+        PvClockCommandResponse::Ok => {
+            info!("{command:?} completed with {resp:?}");
+            Ok(None)
+        }
     }
-    Ok(())
 }
 
 #[cfg(target_arch = "x86_64")]
@@ -2785,6 +2911,7 @@ fn handle_hotplug_command<V: VmArch, Vcpu: VcpuArch>(
     device: &HotPlugDeviceInfo,
     add: bool,
     #[cfg(feature = "swap")] swap_controller: &mut Option<SwapController>,
+    vfio_container_manager: &mut VfioContainerManager,
 ) -> VmResponse {
     let iommu_host_tube = if cfg.vfio_isolate_hotplug {
         iommu_host_tube
@@ -2805,6 +2932,7 @@ fn handle_hotplug_command<V: VmArch, Vcpu: VcpuArch>(
             device,
             #[cfg(feature = "swap")]
             swap_controller,
+            vfio_container_manager,
         )
     } else {
         remove_hotplug_device(linux, sys_allocator, iommu_host_tube, device)
@@ -2850,6 +2978,20 @@ struct ControlLoopState<'a, V: VmArch, Vcpu: VcpuArch> {
     registered_evt_tubes: &'a mut HashMap<RegisteredEvent, HashSet<AddressedProtoTube>>,
     #[cfg(feature = "pvclock")]
     pvclock_host_tube: Option<Arc<Tube>>,
+    vfio_container_manager: &'a mut VfioContainerManager,
+    suspended_pvclock_state: &'a mut Option<hypervisor::ClockState>,
+    vcpus_pid_tid: &'a BTreeMap<usize, (u32, u32)>,
+}
+
+struct VmRequestResult {
+    response: Option<VmResponse>,
+    exit: bool,
+}
+
+impl VmRequestResult {
+    fn new(response: Option<VmResponse>, exit: bool) -> Self {
+        VmRequestResult { response, exit }
+    }
 }
 
 fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
@@ -2862,16 +3004,16 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
         allow(unused_variables, clippy::ptr_arg)
     )]
     add_tubes: &mut Vec<TaggedControlTube>,
-) -> Result<(Option<VmResponse>, bool, Option<VmRunMode>)> {
-    let mut suspend_requested = false;
-    let mut run_mode_opt = None;
-
+) -> Result<VmRequestResult> {
     #[cfg(any(target_arch = "x86_64", feature = "pci-hotplug"))]
     let mut add_irq_control_tubes = Vec::new();
     #[cfg(any(target_arch = "x86_64", feature = "pci-hotplug"))]
     let mut add_vm_memory_control_tubes = Vec::new();
 
     let response = match request {
+        VmRequest::Exit => {
+            return Ok(VmRequestResult::new(Some(VmResponse::Ok), true));
+        }
         VmRequest::HotPlugVfioCommand { device, add } => {
             #[cfg(target_arch = "x86_64")]
             {
@@ -2888,6 +3030,7 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                     add,
                     #[cfg(feature = "swap")]
                     state.swap_controller,
+                    state.vfio_container_manager,
                 )
             }
 
@@ -2895,6 +3038,7 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
             {
                 // Suppress warnings.
                 let _ = (device, add);
+                let _ = &state.vfio_container_manager;
                 VmResponse::Ok
             }
         }
@@ -2956,26 +3100,59 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
         VmRequest::BalloonCommand(cmd) => {
             if let Some(tube) = state.balloon_tube.as_mut() {
                 let Some((r, key)) = tube.send_cmd(cmd, Some(id)) else {
-                    return Ok((None, false, None));
+                    return Ok(VmRequestResult::new(None, false));
                 };
                 if key != id {
                     let Some(TaggedControlTube::Vm(tube)) = state.control_tubes.get(&key) else {
-                        return Ok((None, false, None));
+                        return Ok(VmRequestResult::new(None, false));
                     };
                     if let Err(e) = tube.send(&r) {
                         error!("failed to send VmResponse: {}", e);
                     }
-                    return Ok((None, false, None));
+                    return Ok(VmRequestResult::new(None, false));
                 }
                 r
             } else {
                 VmResponse::Err(base::Error::new(libc::ENOTSUP))
             }
         }
+        VmRequest::VcpuPidTid => VmResponse::VcpuPidTidResponse {
+            pid_tid_map: state.vcpus_pid_tid.clone(),
+        },
         _ => {
+            if !state.cfg.force_s2idle {
+                #[cfg(feature = "pvclock")]
+                if let Some(ref pvclock_host_tube) = state.pvclock_host_tube {
+                    // Update clock offset when pvclock is used.
+                    if let VmRequest::ResumeVcpus = request {
+                        let cmd = PvClockCommand::Resume;
+                        match send_pvclock_cmd(pvclock_host_tube, cmd.clone()) {
+                            Ok(action) => {
+                                info!("{:?} command successfully processed", cmd);
+                                if let Some(action) = action {
+                                    match action {
+                                        #[cfg(target_arch = "aarch64")]
+                                        PvClockAction::SetCounterOffset(offset) => {
+                                            state.linux.vm.set_counter_offset(offset)?;
+                                        }
+                                    }
+                                }
+                            }
+                            Err(e) => error!("{:?} command failed: {:#}", cmd, e),
+                        };
+                    }
+                }
+            }
+            let kick_all_vcpus = |msg| {
+                if let VcpuControl::RunState(VmRunMode::Running) = msg {
+                    for dev in &state.linux.resume_notify_devices {
+                        dev.lock().resume_imminent();
+                    }
+                }
+                vcpu::kick_all_vcpus(state.vcpu_handles, state.linux.irq_chip.as_irq_chip(), msg);
+            };
             let response = request.execute(
                 &state.linux.vm,
-                &mut run_mode_opt,
                 state.disk_host_tubes,
                 &mut state.linux.pm,
                 #[cfg(feature = "gpu")]
@@ -2987,13 +3164,7 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                 #[cfg(not(feature = "usb"))]
                 None,
                 &mut state.linux.bat_control,
-                |msg| {
-                    vcpu::kick_all_vcpus(
-                        state.vcpu_handles,
-                        state.linux.irq_chip.as_irq_chip(),
-                        msg,
-                    )
-                },
+                kick_all_vcpus,
                 state.cfg.force_s2idle,
                 #[cfg(feature = "swap")]
                 state.swap_controller.as_ref(),
@@ -3001,14 +3172,13 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                 state.vcpu_handles.len(),
                 state.irq_handler_control,
                 || state.linux.irq_chip.snapshot(state.linux.vcpu_count),
+                state.suspended_pvclock_state,
             );
             if state.cfg.force_s2idle {
                 if let VmRequest::SuspendVcpus = request {
-                    suspend_requested = true;
-
                     // Spawn s2idle wait thread.
                     let send_tube = tube.try_clone_send_tube().unwrap();
-                    let suspend_evt = state.linux.suspend_evt.try_clone().unwrap();
+                    let suspend_tube = state.linux.suspend_tube.0.clone();
                     let guest_suspended_cvar = state.guest_suspended_cvar.clone();
                     let delayed_response = response.clone();
                     let pm = state.linux.pm.clone();
@@ -3020,30 +3190,31 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                                 guest_suspended_cvar.unwrap(),
                                 &send_tube,
                                 delayed_response,
-                                suspend_evt,
+                                suspend_tube,
                                 pm,
                             )
                         })
                         .context("failed to spawn s2idle_wait thread")?;
+
+                    // For s2idle, omit the response since it will be sent by
+                    // s2idle_wait thread when suspension actually happens.
+                    return Ok(VmRequestResult::new(None, false));
                 }
             } else {
-                // if not doing s2idle, the guest clock should
-                // behave as the host does, so let the guest
-                // know about the suspend / resume via
-                // virtio-pvclock.
                 #[cfg(feature = "pvclock")]
                 if let Some(ref pvclock_host_tube) = state.pvclock_host_tube {
-                    let cmd = match request {
-                        VmRequest::SuspendVcpus => Some(PvClockCommand::Suspend),
-                        VmRequest::ResumeVcpus => Some(PvClockCommand::Resume),
-                        _ => None,
-                    };
-                    if let Some(cmd) = cmd {
-                        if let Err(e) = send_pvclock_cmd(pvclock_host_tube, cmd.clone()) {
-                            error!("{:?} command failed: {:#}", cmd, e);
-                        } else {
-                            info!("{:?} command successfully processed", cmd);
-                        }
+                    // Record the time after VCPUs are suspended to track suspension duration.
+                    if let VmRequest::SuspendVcpus = request {
+                        let cmd = PvClockCommand::Suspend;
+                        match send_pvclock_cmd(pvclock_host_tube, cmd.clone()) {
+                            Ok(action) => {
+                                info!("{:?} command successfully processed", cmd);
+                                if let Some(action) = action {
+                                    error!("Unexpected action {:?} requested for suspend", action);
+                                }
+                            }
+                            Err(e) => error!("{:?} command failed: {:#}", cmd, e),
+                        };
                     }
                 }
             }
@@ -3070,7 +3241,7 @@ fn process_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
         }
     }
 
-    Ok((Some(response), suspend_requested, run_mode_opt))
+    Ok(VmRequestResult::new(Some(response), false))
 }
 
 fn process_vm_control_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
@@ -3083,44 +3254,16 @@ fn process_vm_control_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     match socket {
         TaggedControlTube::Vm(tube) => match tube.recv::<VmRequest>() {
             Ok(request) => {
-                let (response, suspend_requested, run_mode_opt) =
-                    process_vm_request(state, id, tube, request, &mut add_tubes)?;
-
-                if let Some(response) = response {
-                    // If suspend requested skip that step since it will be
-                    // performed by s2idle_wait thread when suspension actually
-                    // happens.
-                    if !suspend_requested {
-                        if let Err(e) = tube.send(&response) {
-                            error!("failed to send VmResponse: {}", e);
-                        }
+                let res = process_vm_request(state, id, tube, request, &mut add_tubes)?;
+
+                if let Some(response) = res.response {
+                    if let Err(e) = tube.send(&response) {
+                        error!("failed to send VmResponse: {}", e);
                     }
                 }
 
-                if let Some(run_mode) = run_mode_opt {
-                    info!("control socket changed run mode to {}", run_mode);
-                    match run_mode {
-                        VmRunMode::Exiting => {
-                            return Ok((true, Vec::new(), Vec::new()));
-                        }
-                        other => {
-                            if other == VmRunMode::Running {
-                                for dev in &state.linux.resume_notify_devices {
-                                    dev.lock().resume_imminent();
-                                }
-                            }
-                            // If suspend requested skip that step since it
-                            // will be performed by s2idle_wait thread when
-                            // needed.
-                            if !suspend_requested {
-                                vcpu::kick_all_vcpus(
-                                    state.vcpu_handles,
-                                    state.linux.irq_chip.as_irq_chip(),
-                                    VcpuControl::RunState(other),
-                                );
-                            }
-                        }
-                    }
+                if res.exit {
+                    return Ok((true, Vec::new(), Vec::new()));
                 }
             }
             Err(e) => {
@@ -3131,7 +3274,7 @@ fn process_vm_control_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                 }
             }
         },
-        TaggedControlTube::VmMsync(tube) => match tube.recv::<VmMsyncRequest>() {
+        TaggedControlTube::VmMsync(tube) => match tube.recv::<VmMemoryMappingRequest>() {
             Ok(request) => {
                 let response = request.execute(&mut state.linux.vm);
                 if let Err(e) = tube.send(&response) {
@@ -3274,6 +3417,9 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     guest_suspended_cvar: Option<Arc<(Mutex<bool>, Condvar)>>,
     #[cfg(feature = "pvclock")] pvclock_host_tube: Option<Tube>,
     metrics_tube: RecvTube,
+    mut vfio_container_manager: VfioContainerManager,
+    // A set of PID of child processes whose clean exit is expected and can be ignored.
+    mut worker_process_pids: BTreeSet<Pid>,
 ) -> Result<ExitState> {
     #[derive(EventToken)]
     enum Token {
@@ -3297,7 +3443,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     let iommu_host_tube = iommu_host_tube.map(|t| Arc::new(Mutex::new(t)));
 
     let wait_ctx = WaitContext::build_with(&[
-        (&linux.suspend_evt, Token::Suspend),
+        (&linux.suspend_tube.1, Token::Suspend),
         (&sigchld_fd, Token::ChildSignal),
         (&vm_evt_rdtube, Token::VmEvent),
         #[cfg(feature = "registered_events")]
@@ -3389,7 +3535,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
         None => None,
         Some(cgroup_path) => {
             // Move main process to cgroup_path
-            let mut f = File::create(&cgroup_path.join("tasks")).with_context(|| {
+            let mut f = File::create(cgroup_path.join("tasks")).with_context(|| {
                 format!(
                     "failed to create vcpu-cgroup-path {}",
                     cgroup_path.display(),
@@ -3457,6 +3603,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     // Architecture-specific code must supply a vcpu_init element for each VCPU.
     assert_eq!(vcpus.len(), linux.vcpu_init.len());
 
+    let (vcpu_pid_tid_sender, vcpu_pid_tid_receiver) = mpsc::channel();
     for ((cpu_id, vcpu), vcpu_init) in vcpus.into_iter().enumerate().zip(linux.vcpu_init.drain(..))
     {
         let (to_vcpu_channel, from_main_channel) = mpsc::channel();
@@ -3528,10 +3675,30 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
             bus_lock_ratelimit_ctrl,
             run_mode,
             cfg.boost_uclamp,
+            vcpu_pid_tid_sender.clone(),
         )?;
         vcpu_handles.push((handle, to_vcpu_channel));
     }
 
+    let mut vcpus_pid_tid = BTreeMap::new();
+    for _ in 0..vcpu_handles.len() {
+        let vcpu_pid_tid: VcpuPidTid = vcpu_pid_tid_receiver
+            .recv()
+            .context("failed receiving vcpu pid/tid")?;
+        if vcpus_pid_tid
+            .insert(
+                vcpu_pid_tid.vcpu_id,
+                (vcpu_pid_tid.process_id, vcpu_pid_tid.thread_id),
+            )
+            .is_some()
+        {
+            return Err(anyhow!(
+                "Vcpu {} returned more than 1 PID and TID",
+                vcpu_pid_tid.vcpu_id
+            ));
+        }
+    }
+
     #[cfg(feature = "gdb")]
     // Spawn GDB thread.
     if let Some((gdb_port_num, gdb_control_tube)) = linux.gdb.take() {
@@ -3589,12 +3756,14 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
 
     vcpu_thread_barrier.wait();
 
+    // See comment on `VmRequest::execute`.
+    let mut suspended_pvclock_state: Option<hypervisor::ClockState> = None;
+
     // Restore VM (if applicable).
     // Must happen after the vCPU barrier to avoid deadlock.
     if let Some(path) = &cfg.restore_path {
         vm_control::do_restore(
-            path.clone(),
-            &linux.vm,
+            path,
             |msg| vcpu::kick_all_vcpus(&vcpu_handles, linux.irq_chip.as_irq_chip(), msg),
             |msg, index| {
                 vcpu::kick_vcpu(&vcpu_handles.get(index), linux.irq_chip.as_irq_chip(), msg)
@@ -3609,6 +3778,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                     .restore(image, linux.vcpu_count)
             },
             /* require_encrypted= */ false,
+            &mut suspended_pvclock_state,
         )?;
         // Allow the vCPUs to start for real.
         vcpu::kick_all_vcpus(
@@ -3725,15 +3895,27 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                         break 'wait;
                     }
                 }
-                Token::Suspend => {
-                    info!("VM requested suspend");
-                    linux.suspend_evt.wait().unwrap();
-                    vcpu::kick_all_vcpus(
-                        &vcpu_handles,
-                        linux.irq_chip.as_irq_chip(),
-                        VcpuControl::RunState(VmRunMode::Suspending),
-                    );
-                }
+                Token::Suspend => match linux.suspend_tube.1.recv::<bool>() {
+                    Ok(is_suspend_request) => {
+                        let mode = if is_suspend_request {
+                            VmRunMode::Suspending
+                        } else {
+                            for dev in &linux.resume_notify_devices {
+                                dev.lock().resume_imminent();
+                            }
+                            VmRunMode::Running
+                        };
+                        info!("VM requested {}", mode);
+                        vcpu::kick_all_vcpus(
+                            &vcpu_handles,
+                            linux.irq_chip.as_irq_chip(),
+                            VcpuControl::RunState(mode),
+                        );
+                    }
+                    Err(err) => {
+                        warn!("Failed to read suspend tube {:?}", err);
+                    }
+                },
                 Token::ChildSignal => {
                     // Print all available siginfo structs, then exit the loop if child process has
                     // been exited except CLD_STOPPED and CLD_CONTINUED. the two should be ignored
@@ -3771,6 +3953,16 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                             continue;
                         }
 
+                        // Allow clean exits of a child process in `worker_process_pids`.
+                        if siginfo.ssi_signo == libc::SIGCHLD as u32
+                            && siginfo.ssi_code == libc::CLD_EXITED
+                            && siginfo.ssi_status == 0
+                            && worker_process_pids.remove(&(pid as Pid))
+                        {
+                            info!("child {pid} exited successfully");
+                            continue;
+                        }
+
                         error!(
                             "child {} exited: signo {}, status {}, code {}",
                             pid_label, siginfo.ssi_signo, siginfo.ssi_status, siginfo.ssi_code
@@ -3832,6 +4024,9 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                             registered_evt_tubes: &mut registered_evt_tubes,
                             #[cfg(feature = "pvclock")]
                             pvclock_host_tube: pvclock_host_tube.clone(),
+                            vfio_container_manager: &mut vfio_container_manager,
+                            suspended_pvclock_state: &mut suspended_pvclock_state,
+                            vcpus_pid_tid: &vcpus_pid_tid,
                         };
                         let (exit_requested, mut ids_to_remove, add_tubes) =
                             process_vm_control_event(&mut state, id, socket)?;
@@ -4263,7 +4458,7 @@ fn vm_memory_handler_thread(
             .context("failed to add descriptor to wait context")?;
     }
 
-    let mut region_state = VmMemoryRegionState::new();
+    let mut region_state: VmMemoryRegionState = Default::default();
 
     'wait: loop {
         let events = {
@@ -4312,6 +4507,7 @@ fn vm_memory_handler_thread(
                         match tube.recv::<VmMemoryRequest>() {
                             Ok(request) => {
                                 let response = request.execute(
+                                    tube,
                                     &mut vm,
                                     &mut sys_allocator_mutex.lock(),
                                     &mut gralloc,
@@ -4446,8 +4642,9 @@ fn jail_and_start_vu_device<T: VirtioDeviceBuilder>(
     let device = params
         .create_vhost_user_device(&mut keep_rds)
         .context("failed to create vhost-user device")?;
-    let mut listener = VhostUserListener::new(vhost, Some(&mut keep_rds))
-        .context("failed to create the vhost listener")?;
+    let mut listener =
+        VhostUserListener::new(vhost).context("failed to create the vhost listener")?;
+    keep_rds.push(listener.as_raw_descriptor());
     let parent_resources = listener.take_parent_process_resources();
 
     // Executor must be created before jail in order to prevent the jailed process from creating
diff --git a/src/crosvm/sys/linux/android.rs b/src/crosvm/sys/linux/android.rs
index d1eefa527..8b9310673 100644
--- a/src/crosvm/sys/linux/android.rs
+++ b/src/crosvm/sys/linux/android.rs
@@ -4,7 +4,6 @@
 
 #![cfg(target_os = "android")]
 
-use std::ffi::CStr;
 use std::ffi::CString;
 
 use anyhow::anyhow;
@@ -22,8 +21,8 @@ extern "C" {
 }
 
 // Apply the listed task profiles to all tasks (current and future) in this process.
-pub fn set_process_profiles(profiles: &Vec<String>) -> Result<()> {
-    if (profiles.is_empty()) {
+pub fn set_process_profiles(profiles: &[String]) -> Result<()> {
+    if profiles.is_empty() {
         return Ok(());
     }
     let owned: Vec<CString> = profiles
@@ -34,8 +33,7 @@ pub fn set_process_profiles(profiles: &Vec<String>) -> Result<()> {
     // SAFETY: the ownership of the array of string is not passed. The function copies it
     // internally.
     unsafe {
-        if (android_set_process_profiles(libc::getuid(), libc::getpid(), ptrs.len(), ptrs.as_ptr()))
-        {
+        if android_set_process_profiles(libc::getuid(), libc::getpid(), ptrs.len(), ptrs.as_ptr()) {
             Ok(())
         } else {
             Err(anyhow!("failed to set task profiles"))
diff --git a/src/crosvm/sys/linux/config.rs b/src/crosvm/sys/linux/config.rs
index f7c593396..597156d2e 100644
--- a/src/crosvm/sys/linux/config.rs
+++ b/src/crosvm/sys/linux/config.rs
@@ -116,6 +116,47 @@ impl Default for SharedDir {
     }
 }
 
+struct UgidConfig {
+    uid: Option<u32>,
+    gid: Option<u32>,
+    uid_map: String,
+    gid_map: String,
+}
+
+impl Default for UgidConfig {
+    fn default() -> Self {
+        Self {
+            uid: None,
+            gid: None,
+            // SAFETY: geteuid never fails.
+            uid_map: format!("0 {} 1", unsafe { geteuid() }),
+            // SAFETY: getegid never fails.
+            gid_map: format!("0 {} 1", unsafe { getegid() }),
+        }
+    }
+}
+
+impl UgidConfig {
+    /// Parse a key-value pair of ugid config to update `UgidConfig`.
+    /// Returns whether `self` was updated or not.
+    fn parse_ugid_config(&mut self, kind: &str, value: &str) -> anyhow::Result<bool> {
+        match kind {
+            "uid" => {
+                self.uid = Some(value.parse().context("`uid` must be an integer")?);
+            }
+            "gid" => {
+                self.gid = Some(value.parse().context("`gid` must be an integer")?);
+            }
+            "uidmap" => self.uid_map = value.into(),
+            "gidmap" => self.gid_map = value.into(),
+            _ => {
+                return Ok(false);
+            }
+        }
+        Ok(true)
+    }
+}
+
 impl FromStr for SharedDir {
     type Err = anyhow::Error;
 
@@ -137,6 +178,12 @@ impl FromStr for SharedDir {
         //   (default: 0)
         // * gid=GID - gid of the device process in the user namespace created by minijail.
         //   (default: 0)
+        // * max_dynamic_perm=uint - number of maximum number of dynamic permissions paths (default:
+        //   0) This feature is arc_quota specific feature.
+        // * max_dynamic_xattr=uint - number of maximum number of dynamic xattr paths (default: 0).
+        //   This feature is arc_quota specific feature.
+        // * security_ctx=BOOL - indicates whether use FUSE_SECURITY_CONTEXT feature or not.
+        //
         // These two options (uid/gid) are useful when the crosvm process has no
         // CAP_SETGID/CAP_SETUID but an identity mapping of the current user/group
         // between the VM and the host is required.
@@ -168,6 +215,7 @@ impl FromStr for SharedDir {
             ..Default::default()
         };
         let mut type_opts = vec![];
+        let mut ugid_cfg = UgidConfig::default();
         for opt in components {
             let mut o = opt.splitn(2, '=');
             let kind = o.next().context("`shared-dir` options must not be empty")?;
@@ -175,23 +223,24 @@ impl FromStr for SharedDir {
                 .next()
                 .context("`shared-dir` options must be of the form `kind=value`")?;
 
-            match kind {
-                "type" => {
-                    shared_dir.kind = value.parse().with_context(|| {
-                        anyhow!("`type` must be one of `fs` or `9p` but {value}")
-                    })?
+            if !ugid_cfg
+                .parse_ugid_config(kind, value)
+                .context("failed to parse ugid config")?
+            {
+                match kind {
+                    "type" => {
+                        shared_dir.kind = value.parse().with_context(|| {
+                            anyhow!("`type` must be one of `fs` or `9p` but {value}")
+                        })?
+                    }
+                    _ => type_opts.push(opt),
                 }
-                "uidmap" => shared_dir.uid_map = value.into(),
-                "gidmap" => shared_dir.gid_map = value.into(),
-                "uid" => {
-                    shared_dir.ugid.0 = Some(value.parse().context("`uid` must be an integer")?);
-                }
-                "gid" => {
-                    shared_dir.ugid.1 = Some(value.parse().context("`gid` must be an integer")?);
-                }
-                _ => type_opts.push(opt),
             }
         }
+        shared_dir.ugid = (ugid_cfg.uid, ugid_cfg.gid);
+        shared_dir.uid_map = ugid_cfg.uid_map;
+        shared_dir.gid_map = ugid_cfg.gid_map;
+
         match shared_dir.kind {
             SharedDirKind::FS => {
                 shared_dir.fs_cfg = from_key_values(&type_opts.join(","))
@@ -220,6 +269,84 @@ impl FromStr for SharedDir {
     }
 }
 
+#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]
+#[serde(deny_unknown_fields)]
+pub struct PmemExt2Option {
+    pub path: PathBuf,
+    pub blocks_per_group: u32,
+    pub inodes_per_group: u32,
+    pub size: u32,
+    pub ugid: (Option<u32>, Option<u32>),
+    pub uid_map: String,
+    pub gid_map: String,
+}
+
+impl Default for PmemExt2Option {
+    fn default() -> Self {
+        let blocks_per_group = 4096;
+        let inodes_per_group = 1024;
+        let size = ext2::BLOCK_SIZE as u32 * blocks_per_group; // only one block group
+        let ugid_cfg = UgidConfig::default();
+        Self {
+            path: Default::default(),
+            blocks_per_group,
+            inodes_per_group,
+            size,
+            ugid: (ugid_cfg.uid, ugid_cfg.gid),
+            uid_map: ugid_cfg.uid_map,
+            gid_map: ugid_cfg.gid_map,
+        }
+    }
+}
+
+pub fn parse_pmem_ext2_option(param: &str) -> Result<PmemExt2Option, String> {
+    let mut opt = PmemExt2Option::default();
+    let mut components = param.split(':');
+    opt.path = PathBuf::from(
+        components
+            .next()
+            .ok_or("missing source path for `pmem-ext2`")?,
+    );
+
+    let mut ugid_cfg = UgidConfig::default();
+    for c in components {
+        let mut o = c.splitn(2, '=');
+        let kind = o.next().ok_or("`pmem-ext2` options must not be empty")?;
+        let value = o
+            .next()
+            .ok_or("`pmem-ext2` options must be of the form `kind=value`")?;
+
+        if !ugid_cfg
+            .parse_ugid_config(kind, value)
+            .map_err(|e| format!("failed to parse ugid config for pmem-ext2: {:#}", e))?
+        {
+            match kind {
+                "blocks_per_group" => {
+                    opt.blocks_per_group = value.parse().map_err(|e| {
+                        format!("failed to parse blocks_per_groups '{value}': {:#}", e)
+                    })?
+                }
+                "inodes_per_group" => {
+                    opt.inodes_per_group = value.parse().map_err(|e| {
+                        format!("failed to parse inodes_per_groups '{value}': {:#}", e)
+                    })?
+                }
+                "size" => {
+                    opt.size = value
+                        .parse()
+                        .map_err(|e| format!("failed to parse memory size '{value}': {:#}", e))?
+                }
+                _ => return Err(format!("invalid `pmem-ext2` option: {}", kind)),
+            }
+        }
+    }
+    opt.ugid = (ugid_cfg.uid, ugid_cfg.gid);
+    opt.uid_map = ugid_cfg.uid_map;
+    opt.gid_map = ugid_cfg.gid_map;
+
+    Ok(opt)
+}
+
 #[cfg(test)]
 mod tests {
     use std::path::Path;
@@ -761,4 +888,45 @@ mod tests {
                 .use_dax
         );
     }
+
+    #[test]
+    fn parse_pmem_ext2() {
+        let config: Config = crate::crosvm::cmdline::RunCommand::from_args(
+            &[],
+            &["--pmem-ext2", "/path/to/dir", "/dev/null"],
+        )
+        .unwrap()
+        .try_into()
+        .unwrap();
+
+        let opt = config.pmem_ext2.first().unwrap();
+
+        assert_eq!(opt.path, PathBuf::from("/path/to/dir"));
+    }
+
+    #[test]
+    fn parse_pmem_ext2_size() {
+        let blocks_per_group = 2048;
+        let inodes_per_group = 1024;
+        let size = 4096 * blocks_per_group;
+
+        let config: Config = crate::crosvm::cmdline::RunCommand::from_args(
+            &[],
+            &[
+                "--pmem-ext2",
+                &format!("/path/to/dir:blocks_per_group={blocks_per_group}:inodes_per_group={inodes_per_group}:size={size}"),
+                "/dev/null",
+            ],
+        )
+        .unwrap()
+        .try_into()
+        .unwrap();
+
+        let opt = config.pmem_ext2.first().unwrap();
+
+        assert_eq!(opt.path, PathBuf::from("/path/to/dir"));
+        assert_eq!(opt.blocks_per_group, blocks_per_group);
+        assert_eq!(opt.inodes_per_group, inodes_per_group);
+        assert_eq!(opt.size, size);
+    }
 }
diff --git a/src/crosvm/sys/linux/device_helpers.rs b/src/crosvm/sys/linux/device_helpers.rs
index 1ea3fd11a..327761eef 100644
--- a/src/crosvm/sys/linux/device_helpers.rs
+++ b/src/crosvm/sys/linux/device_helpers.rs
@@ -3,30 +3,36 @@
 // found in the LICENSE file.
 
 use std::collections::BTreeMap;
+use std::collections::BTreeSet;
 use std::convert::TryFrom;
+use std::fs;
+use std::fs::File;
 use std::fs::OpenOptions;
+use std::io::ErrorKind;
 use std::ops::RangeInclusive;
+use std::os::unix::fs::FileTypeExt;
 use std::os::unix::net::UnixStream;
 use std::path::Path;
 use std::path::PathBuf;
 use std::str;
 use std::sync::Arc;
+use std::time::Duration;
+use std::time::Instant;
 
 use anyhow::anyhow;
 use anyhow::bail;
 use anyhow::Context;
 use anyhow::Result;
 use arch::VirtioDeviceStub;
+use base::linux::MemfdSeals;
+use base::sys::SharedMemoryLinux;
 use base::ReadNotifier;
 use base::*;
-use devices::serial_device::SerialHardware;
 use devices::serial_device::SerialParameters;
 use devices::serial_device::SerialType;
-use devices::vfio::VfioCommonSetup;
-use devices::vfio::VfioCommonTrait;
+use devices::vfio::VfioContainerManager;
 use devices::virtio;
 use devices::virtio::block::DiskOption;
-use devices::virtio::console::asynchronous::AsyncConsole;
 #[cfg(any(feature = "video-decoder", feature = "video-encoder"))]
 use devices::virtio::device_constants::video::VideoBackendType;
 #[cfg(any(feature = "video-decoder", feature = "video-encoder"))]
@@ -46,15 +52,15 @@ use devices::virtio::vhost::user::NetBackend;
 use devices::virtio::vhost::user::VhostUserDeviceBuilder;
 use devices::virtio::vhost::user::VhostUserVsockDevice;
 use devices::virtio::vsock::VsockConfig;
-#[cfg(feature = "balloon")]
-use devices::virtio::BalloonMode;
 use devices::virtio::Console;
+use devices::virtio::MemSlotConfig;
 #[cfg(feature = "net")]
 use devices::virtio::NetError;
 #[cfg(feature = "net")]
 use devices::virtio::NetParameters;
 #[cfg(feature = "net")]
 use devices::virtio::NetParametersMode;
+use devices::virtio::PmemConfig;
 use devices::virtio::VhostUserFrontend;
 use devices::virtio::VirtioDevice;
 use devices::virtio::VirtioDeviceType;
@@ -86,8 +92,10 @@ use sync::Mutex;
 use vm_control::api::VmMemoryClient;
 use vm_memory::GuestAddress;
 
+use crate::crosvm::config::PmemOption;
 use crate::crosvm::config::VhostUserFrontendOption;
 use crate::crosvm::config::VhostUserFsOption;
+use crate::crosvm::sys::config::PmemExt2Option;
 
 pub enum TaggedControlTube {
     Fs(Tube),
@@ -323,23 +331,85 @@ impl<'a> VirtioDeviceBuilder for &'a ScsiConfig<'a> {
     }
 }
 
-fn vhost_user_connection(path: &Path) -> Result<UnixStream> {
-    UnixStream::connect(path).with_context(|| {
-        format!(
-            "failed to connect to vhost-user socket path {}",
-            path.display()
-        )
-    })
+fn vhost_user_connection(
+    path: &Path,
+    connect_timeout_ms: Option<u64>,
+) -> Result<vmm_vhost::Connection<vmm_vhost::FrontendReq>> {
+    let deadline = connect_timeout_ms.map(|t| Instant::now() + Duration::from_millis(t));
+    let mut first = true;
+    loop {
+        match UnixStream::connect(path) {
+            Ok(sock) => {
+                let connection = sock
+                    .try_into()
+                    .context("failed to construct Connection from UnixStream")?;
+                return Ok(connection);
+            }
+            Err(e) => {
+                // ConnectionRefused => Might be a stale file the backend hasn't deleted yet.
+                // NotFound => Might be the backend hasn't bound the socket yet.
+                if e.kind() == ErrorKind::ConnectionRefused || e.kind() == ErrorKind::NotFound {
+                    if let Some(deadline) = deadline {
+                        if first {
+                            first = false;
+                            warn!(
+                                "vhost-user socket path {} not available. retrying up to {} ms",
+                                path.display(),
+                                connect_timeout_ms.unwrap()
+                            );
+                        }
+                        if Instant::now() > deadline {
+                            anyhow::bail!(
+                                "timeout waiting for vhost-user socket path {}: final error: {e:#}",
+                                path.display()
+                            );
+                        }
+                        std::thread::sleep(Duration::from_millis(1));
+                        continue;
+                    }
+                }
+                return Err(e).with_context(|| {
+                    format!(
+                        "failed to connect to vhost-user socket path {}",
+                        path.display()
+                    )
+                });
+            }
+        }
+    }
+}
+
+fn is_socket(path: &PathBuf) -> bool {
+    match fs::metadata(path) {
+        Ok(metadata) => metadata.file_type().is_socket(),
+        Err(_) => false, // Assume not a socket if we can't get metadata
+    }
+}
+
+fn vhost_user_connection_from_socket_fd(
+    fd: u32,
+) -> Result<vmm_vhost::Connection<vmm_vhost::FrontendReq>> {
+    let path = PathBuf::from(format!("/proc/self/fd/{}", fd));
+    if !is_socket(&path) {
+        anyhow::bail!("path {} is not socket", path.display());
+    }
+
+    let safe_fd = safe_descriptor_from_cmdline_fd(&(fd as i32))?;
+
+    safe_fd
+        .try_into()
+        .context("failed to create vhost-user connection from fd")
 }
 
 pub fn create_vhost_user_frontend(
     protection_type: ProtectionType,
     opt: &VhostUserFrontendOption,
+    connect_timeout_ms: Option<u64>,
 ) -> DeviceResult {
     let dev = VhostUserFrontend::new(
         opt.type_,
         virtio::base_features(protection_type),
-        vhost_user_connection(&opt.socket)?,
+        vhost_user_connection(&opt.socket, connect_timeout_ms)?,
         opt.max_queue_size,
         opt.pci_address,
     )
@@ -356,9 +426,15 @@ pub fn create_vhost_user_fs_device(
     protection_type: ProtectionType,
     option: &VhostUserFsOption,
 ) -> DeviceResult {
+    let connection = match (&option.socket_path, option.socket_fd) {
+        (Some(socket), None) => vhost_user_connection(socket, None)?,
+        (None, Some(fd)) => vhost_user_connection_from_socket_fd(fd)?,
+        (Some(_), Some(_)) => bail!("Cannot specify both a UDS path and a file descriptor"),
+        (None, None) => bail!("Must specify either a socket or a file descriptor"),
+    };
     let dev = VhostUserFrontend::new_fs(
         virtio::base_features(protection_type),
-        vhost_user_connection(&option.socket)?,
+        connection,
         option.max_queue_size,
         option.tag.as_deref(),
     )
@@ -405,7 +481,7 @@ pub fn create_virtio_snd_device(
         Backend::Sys(virtio::snd::sys::StreamSourceBackend::AAUDIO) => "snd_aaudio_device",
         #[cfg(feature = "audio_cras")]
         Backend::Sys(virtio::snd::sys::StreamSourceBackend::CRAS) => "snd_cras_device",
-        #[cfg(not(feature = "audio_cras"))]
+        #[cfg(not(any(feature = "audio_cras", feature = "audio_aaudio")))]
         _ => unreachable!(),
     };
 
@@ -548,6 +624,35 @@ pub fn create_trackpad_device<T: IntoUnixStream>(
     })
 }
 
+pub fn create_multitouch_trackpad_device<T: IntoUnixStream>(
+    protection_type: ProtectionType,
+    jail_config: &Option<JailConfig>,
+    trackpad_socket: T,
+    width: u32,
+    height: u32,
+    name: Option<&str>,
+    idx: u32,
+) -> DeviceResult {
+    let socket = trackpad_socket
+        .into_unix_stream()
+        .context("failed configuring virtio trackpad")?;
+
+    let dev = virtio::input::new_multitouch_trackpad(
+        idx,
+        socket,
+        width,
+        height,
+        name,
+        virtio::base_features(protection_type),
+    )
+    .context("failed to set up input device")?;
+
+    Ok(VirtioDeviceStub {
+        dev: Box::new(dev),
+        jail: simple_jail(jail_config, "input_device")?,
+    })
+}
+
 pub fn create_mouse_device<T: IntoUnixStream>(
     protection_type: ProtectionType,
     jail_config: &Option<JailConfig>,
@@ -648,7 +753,6 @@ pub fn create_vinput_device(
 pub fn create_balloon_device(
     protection_type: ProtectionType,
     jail_config: &Option<JailConfig>,
-    mode: BalloonMode,
     tube: Tube,
     inflate_tube: Option<Tube>,
     init_balloon_size: u64,
@@ -663,7 +767,6 @@ pub fn create_balloon_device(
         VmMemoryClient::new(dynamic_mapping_device_tube),
         inflate_tube,
         init_balloon_size,
-        mode,
         enabled_features,
         #[cfg(feature = "registered_events")]
         registered_evt_q,
@@ -896,8 +999,8 @@ pub fn create_video_device(
             let sys_devices_path = Path::new("/sys/devices");
             jail.mount_bind(sys_devices_path, sys_devices_path, false)?;
 
-            // Required for loading dri libraries loaded by minigbm on AMD devices.
-            jail_mount_bind_if_exists(&mut jail, &["/usr/lib64", "/usr/lib"])?;
+            // Required for loading dri or vulkan libraries loaded by minigbm on AMD devices.
+            jail_mount_bind_if_exists(&mut jail, &["/usr/lib64", "/usr/lib", "/usr/share/vulkan"])?;
         }
 
         // Device nodes required by libchrome which establishes Mojo connection in libvda.
@@ -996,8 +1099,9 @@ pub fn create_fs_device(
     fs_cfg: virtio::fs::Config,
     device_tube: Tube,
 ) -> DeviceResult {
-    let max_open_files =
-        base::linux::max_open_files().context("failed to get max number of open files")?;
+    let max_open_files = base::linux::max_open_files()
+        .context("failed to get max number of open files")?
+        .rlim_max;
     let j = if let Some(jail_config) = jail_config {
         let mut config = SandboxConfig::new(jail_config, "fs_device");
         config.limit_caps = false;
@@ -1037,8 +1141,9 @@ pub fn create_9p_device(
     tag: &str,
     mut p9_cfg: p9::Config,
 ) -> DeviceResult {
-    let max_open_files =
-        base::linux::max_open_files().context("failed to get max number of open files")?;
+    let max_open_files = base::linux::max_open_files()
+        .context("failed to get max number of open files")?
+        .rlim_max;
     let (jail, root) = if let Some(jail_config) = jail_config {
         let mut config = SandboxConfig::new(jail_config, "9p_device");
         config.limit_caps = false;
@@ -1077,42 +1182,39 @@ pub fn create_pmem_device(
     jail_config: &Option<JailConfig>,
     vm: &mut impl Vm,
     resources: &mut SystemAllocator,
-    disk: &DiskOption,
+    pmem: &PmemOption,
     index: usize,
     pmem_device_tube: Tube,
 ) -> DeviceResult {
-    let fd = open_file_or_duplicate(
-        &disk.path,
-        OpenOptions::new().read(true).write(!disk.read_only),
-    )
-    .with_context(|| format!("failed to load disk image {}", disk.path.display()))?;
-
-    let (disk_size, arena_size) = {
-        let metadata = std::fs::metadata(&disk.path).with_context(|| {
-            format!("failed to get disk image {} metadata", disk.path.display())
-        })?;
-        let disk_len = metadata.len();
-        // Linux requires pmem region sizes to be 2 MiB aligned. Linux will fill any partial page
-        // at the end of an mmap'd file and won't write back beyond the actual file length, but if
-        // we just align the size of the file to 2 MiB then access beyond the last page of the
-        // mapped file will generate SIGBUS. So use a memory mapping arena that will provide
-        // padding up to 2 MiB.
-        let alignment = 2 * 1024 * 1024;
-        let align_adjust = if disk_len % alignment != 0 {
-            alignment - (disk_len % alignment)
-        } else {
-            0
-        };
-        (
-            disk_len,
-            disk_len
-                .checked_add(align_adjust)
-                .ok_or_else(|| anyhow!("pmem device image too big"))?,
-        )
+    let (fd, disk_size) = match pmem.vma_size {
+        None => {
+            let disk_image =
+                open_file_or_duplicate(&pmem.path, OpenOptions::new().read(true).write(!pmem.ro))
+                    .with_context(|| format!("failed to load disk image {}", pmem.path.display()))?;
+            let metadata = std::fs::metadata(&pmem.path).with_context(|| {
+                format!("failed to get disk image {} metadata", pmem.path.display())
+            })?;
+            (disk_image, metadata.len())
+        }
+        Some(size) => {
+            let anon_file =
+                create_anonymous_file(&pmem.path, size).context("failed to create anon file")?;
+            (anon_file, size)
+        }
     };
 
+    // Linux requires pmem region sizes to be 2 MiB aligned. Linux will fill any partial page
+    // at the end of an mmap'd file and won't write back beyond the actual file length, but if
+    // we just align the size of the file to 2 MiB then access beyond the last page of the
+    // mapped file will generate SIGBUS. So use a memory mapping arena that will provide
+    // padding up to 2 MiB.
+    let alignment = 2 * 1024 * 1024;
+    let arena_size = disk_size
+        .checked_next_multiple_of(alignment)
+        .ok_or_else(|| anyhow!("pmem device image too big"))?;
+
     let protection = {
-        if disk.read_only {
+        if pmem.ro {
             Protection::read()
         } else {
             Protection::read_write()
@@ -1145,36 +1247,45 @@ pub fn create_pmem_device(
         arena
     };
 
-    let mapping_address = resources
-        .allocate_mmio(
-            arena_size,
-            Alloc::PmemDevice(index),
-            format!("pmem_disk_image_{}", index),
-            AllocOptions::new()
+    let mapping_address = GuestAddress(
+        resources
+            .allocate_mmio(
+                arena_size,
+                Alloc::PmemDevice(index),
+                format!("pmem_disk_image_{}", index),
+                AllocOptions::new()
                 .top_down(true)
                 .prefetchable(true)
                 // Linux kernel requires pmem namespaces to be 128 MiB aligned.
+                // cf. https://github.com/pmem/ndctl/issues/76
                 .align(128 * 1024 * 1024), /* 128 MiB */
-        )
-        .context("failed to allocate memory for pmem device")?;
-
-    let slot = vm
-        .add_memory_region(
-            GuestAddress(mapping_address),
-            Box::new(arena),
-            /* read_only = */ disk.read_only,
-            /* log_dirty_pages = */ false,
-            MemCacheType::CacheCoherent,
-        )
-        .context("failed to add pmem device memory")?;
+            )
+            .context("failed to allocate memory for pmem device")?,
+    );
+
+    let mem_slot = MemSlotConfig::MemSlot {
+        idx: vm
+            .add_memory_region(
+                mapping_address,
+                Box::new(arena),
+                /* read_only = */ pmem.ro,
+                /* log_dirty_pages = */ false,
+                MemCacheType::CacheCoherent,
+            )
+            .context("failed to add pmem device memory")?,
+    };
 
     let dev = virtio::Pmem::new(
         virtio::base_features(protection_type),
-        fd,
-        GuestAddress(mapping_address),
-        slot,
-        arena_size,
-        pmem_device_tube,
+        PmemConfig {
+            disk_image: Some(fd),
+            mapping_address,
+            mem_slot,
+            mapping_size: arena_size,
+            pmem_device_tube,
+            swap_interval: pmem.swap_interval,
+            mapping_writable: !pmem.ro,
+        },
     )
     .context("failed to create pmem device")?;
 
@@ -1184,6 +1295,103 @@ pub fn create_pmem_device(
     })
 }
 
+pub fn create_pmem_ext2_device(
+    protection_type: ProtectionType,
+    jail_config: &Option<JailConfig>,
+    resources: &mut SystemAllocator,
+    opts: &PmemExt2Option,
+    index: usize,
+    vm_memory_client: VmMemoryClient,
+    pmem_device_tube: Tube,
+    worker_process_pids: &mut BTreeSet<Pid>,
+) -> DeviceResult {
+    let mapping_size = opts.size as u64;
+    let builder = ext2::Builder {
+        inodes_per_group: opts.inodes_per_group,
+        blocks_per_group: opts.blocks_per_group,
+        size: mapping_size as u32,
+    };
+
+    let max_open_files = base::linux::max_open_files()
+        .context("failed to get max number of open files")?
+        .rlim_max;
+    let mapping_address = GuestAddress(
+        resources
+            .allocate_mmio(
+                mapping_size,
+                Alloc::PmemDevice(index),
+                format!("pmem_ext2_image_{}", index),
+                AllocOptions::new()
+                .top_down(true)
+                .prefetchable(true)
+                // 2MB alignment for DAX
+                // cf. https://docs.pmem.io/persistent-memory/getting-started-guide/creating-development-environments/linux-environments/advanced-topics/i-o-alignment-considerations#verifying-io-alignment
+                .align(2 * 1024 * 1024),
+            )
+            .context("failed to allocate memory for pmem device")?,
+    );
+
+    let (mkfs_tube, mkfs_device_tube) = Tube::pair().context("failed to create tube")?;
+
+    let ext2_proc_pid = crate::crosvm::sys::linux::ext2::launch(
+        mapping_address,
+        vm_memory_client,
+        mkfs_tube,
+        &opts.path,
+        &opts.ugid,
+        (&opts.uid_map, &opts.gid_map),
+        builder,
+        jail_config,
+    )
+    .context("failed to spawn mkfs process")?;
+
+    worker_process_pids.insert(ext2_proc_pid);
+
+    let dev = virtio::Pmem::new(
+        virtio::base_features(protection_type),
+        PmemConfig {
+            disk_image: None,
+            mapping_address,
+            mem_slot: MemSlotConfig::LazyInit {
+                tube: mkfs_device_tube,
+            },
+            mapping_size,
+            pmem_device_tube,
+            swap_interval: None,
+            mapping_writable: false,
+        },
+    )
+    .context("failed to create pmem device")?;
+
+    let j = if let Some(jail_config) = jail_config {
+        let mut config = SandboxConfig::new(jail_config, "pmem_device");
+        config.limit_caps = false;
+        create_sandbox_minijail(&opts.path, max_open_files, &config)?
+    } else {
+        create_base_minijail(&opts.path, max_open_files)?
+    };
+    Ok(VirtioDeviceStub {
+        dev: Box::new(dev) as Box<dyn VirtioDevice>,
+        jail: Some(j),
+    })
+}
+
+pub fn create_anonymous_file<P: AsRef<Path>>(path: P, size: u64) -> Result<File> {
+    let file_name = path
+        .as_ref()
+        .to_str()
+        .ok_or_else(|| Error::new(libc::EINVAL))?;
+    let mut shm = SharedMemory::new(file_name, size)?;
+    let mut seals = MemfdSeals::new();
+
+    seals.set_shrink_seal();
+    seals.set_grow_seal();
+    seals.set_seal_seal();
+    shm.add_seals(seals)?;
+
+    Ok(shm.descriptor.into())
+}
+
 pub fn create_iommu_device(
     protection_type: ProtectionType,
     jail_config: &Option<JailConfig>,
@@ -1236,18 +1444,10 @@ impl VirtioDeviceBuilder for &SerialParameters {
         let mut keep_rds = Vec::new();
         let evt = Event::new().context("failed to create event")?;
 
-        // TODO(b/243198718): Switch back to AsyncConsole in android (remove the `true ||`).
-        if true || self.hardware == SerialHardware::LegacyVirtioConsole {
-            Ok(Box::new(
-                self.create_serial_device::<Console>(protection_type, &evt, &mut keep_rds)
-                    .context("failed to create console device")?,
-            ))
-        } else {
-            Ok(Box::new(
-                self.create_serial_device::<AsyncConsole>(protection_type, &evt, &mut keep_rds)
-                    .context("failed to create console device")?,
-            ))
-        }
+        Ok(Box::new(
+            self.create_serial_device::<Console>(protection_type, &evt, &mut keep_rds)
+                .context("failed to create console device")?,
+        ))
     }
 
     fn create_vhost_user_device(
@@ -1314,8 +1514,10 @@ pub fn create_vfio_device(
     coiommu_endpoints: Option<&mut Vec<u16>>,
     iommu_dev: IommuDevType,
     dt_symbol: Option<String>,
+    vfio_container_manager: &mut VfioContainerManager,
 ) -> DeviceResult<(VfioDeviceVariant, Option<Minijail>, Option<VfioWrapper>)> {
-    let vfio_container = VfioCommonSetup::vfio_get_container(iommu_dev, Some(vfio_path))
+    let vfio_container = vfio_container_manager
+        .get_container(iommu_dev, Some(vfio_path))
         .context("failed to get vfio container")?;
 
     let (vfio_host_tube_mem, vfio_device_tube_mem) =
diff --git a/src/crosvm/sys/linux/ext2.rs b/src/crosvm/sys/linux/ext2.rs
new file mode 100644
index 000000000..375a44e87
--- /dev/null
+++ b/src/crosvm/sys/linux/ext2.rs
@@ -0,0 +1,130 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! Provides a function to lanunches a process of creating ext2 filesystem on memory region
+//! asynchronously for pmem-ext2 device.
+//!
+//! The ext2 file system is created in the memory area for pmem by the following three processes:
+//! (a). The main process
+//! (b). ext2 process launched by the `launch()` below.
+//! (c). The virtio-pmem process
+//!
+//! By executing mkfs in the multiple processes, mkfs won't block other initalization steps. Also,
+//! we can use different seccopm poliy for (b) and (c).
+//!
+//! The overall workflow is like the followings:
+//! 1. At (a): `launch()` is called from (a)
+//! 2. At (a): (b) is foked from (a) in `launch()`
+//! 3. At (b): The given directory is traversed and metadata is constructed.
+//! 4. At (b): File descriptors are sent to (a) with `VmMemoryRequest::MmapAndRegisterMemory`.
+//! 5. At (a): mmap() for the file descriptors are called. The reply is sent to (b).
+//! 6. At (b): memory slot number is sent to (c).
+//! 7. At (c): device activation finished.
+
+use std::path::Path;
+
+use anyhow::Context;
+use anyhow::Result;
+use base::error;
+use base::AsRawDescriptor;
+use base::Pid;
+use base::SharedMemory;
+use base::Tube;
+use jail::create_base_minijail;
+use jail::create_sandbox_minijail;
+use jail::fork_process;
+use jail::JailConfig;
+use jail::RunAsUser;
+use jail::SandboxConfig;
+use vm_control::api::VmMemoryClient;
+use vm_control::VmMemoryFileMapping;
+use vm_memory::GuestAddress;
+
+/// Starts a process to create an ext2 filesystem on a given shared memory region.
+pub fn launch(
+    mapping_address: GuestAddress,
+    vm_memory_client: VmMemoryClient,
+    device_tube: Tube, // Connects to a virtio device to send a memory slot number.
+    path: &Path,
+    ugid: &(Option<u32>, Option<u32>),
+    ugid_map: (&str, &str),
+    builder: ext2::Builder,
+    jail_config: &Option<JailConfig>,
+) -> Result<Pid> {
+    let max_open_files = base::linux::max_open_files()
+        .context("failed to get max number of open files")?
+        .rlim_max;
+
+    let jail = if let Some(jail_config) = jail_config {
+        let mut config = SandboxConfig::new(jail_config, "virtual_ext2");
+        config.limit_caps = false;
+        config.ugid_map = Some(ugid_map);
+        // We want bind mounts from the parent namespaces to propagate into the mkfs's
+        // namespace.
+        config.remount_mode = Some(libc::MS_SLAVE);
+        config.run_as = match *ugid {
+            (None, None) => RunAsUser::Unspecified,
+            (uid_opt, gid_opt) => RunAsUser::Specified(uid_opt.unwrap_or(0), gid_opt.unwrap_or(0)),
+        };
+        create_sandbox_minijail(path, max_open_files, &config)?
+    } else {
+        create_base_minijail(path, max_open_files)?
+    };
+
+    let shm = SharedMemory::new("pmem_ext2_shm", builder.size as u64)
+        .context("failed to create shared memory")?;
+    let mut keep_rds = vec![
+        shm.as_raw_descriptor(),
+        vm_memory_client.as_raw_descriptor(),
+        device_tube.as_raw_descriptor(),
+    ];
+    base::syslog::push_descriptors(&mut keep_rds);
+
+    let child_process = fork_process(jail, keep_rds, Some(String::from("mkfs process")), || {
+        if let Err(e) = mkfs_callback(vm_memory_client, mapping_address, device_tube, builder, shm)
+        {
+            error!("failed to create file system: {:#}", e);
+            // SAFETY: exit() is trivially safe.
+            unsafe { libc::exit(1) };
+        }
+    })
+    .context("failed to fork a process for mkfs")?;
+    Ok(child_process.pid)
+}
+
+/// A callback to create a ext2 file system on `shm`.
+/// This is supposed to be run in a jailed child process so operations are sandboxed and limited.
+fn mkfs_callback(
+    mem_client: VmMemoryClient,
+    mapping_address: GuestAddress,
+    device_tube: Tube, // Connects to a virtio device to send a memory slot number.
+    builder: ext2::Builder,
+    shm: SharedMemory,
+) -> Result<()> {
+    let jailed_root = Some(std::path::Path::new("/"));
+    let file_mappings = builder
+        .build_on_shm(&shm)
+        .context("failed to build memory region")?
+        .build_mmap_info(jailed_root)
+        .context("failed to build ext2")?
+        .mapping_info;
+
+    let file_mapping_info: Vec<_> = file_mappings
+        .into_iter()
+        .map(|info| VmMemoryFileMapping {
+            file: info.file,
+            length: info.length,
+            mem_offset: info.mem_offset,
+            file_offset: info.file_offset as u64,
+        })
+        .collect();
+
+    let slot = mem_client
+        .mmap_and_register_memory(mapping_address, shm, file_mapping_info)
+        .context("failed to request mmaping and registering memory")?;
+    device_tube
+        .send(&slot)
+        .context("failed to send VmMemoryRequest::RegisterMemory")?;
+    Ok(())
+}
diff --git a/src/crosvm/sys/linux/gpu.rs b/src/crosvm/sys/linux/gpu.rs
index 64879a6ee..fcad67083 100644
--- a/src/crosvm/sys/linux/gpu.rs
+++ b/src/crosvm/sys/linux/gpu.rs
@@ -249,6 +249,11 @@ fn get_gpu_render_server_environment(
         }
     }
 
+    // TODO(b/323284290): workaround to advertise 2 graphics queues in ANV
+    if !env.contains_key("ANV_QUEUE_OVERRIDE") {
+        env.insert("ANV_QUEUE_OVERRIDE".to_string(), "gc=2".to_string());
+    }
+
     // TODO(b/237493180, b/284517235): workaround to enable ETC2/ASTC format emulation in Mesa
     // TODO(b/284361281, b/328827736): workaround to enable legacy sparse binding in RADV
     let driconf_options = [
@@ -263,6 +268,14 @@ fn get_gpu_render_server_environment(
         }
     }
 
+    // TODO(b/339766043): workaround to disable Vulkan protected memory feature in Mali
+    if !env.contains_key("MALI_BASE_PROTECTED_MEMORY_HEAP_SIZE") {
+        env.insert(
+            "MALI_BASE_PROTECTED_MEMORY_HEAP_SIZE".to_string(),
+            "0".to_string(),
+        );
+    }
+
     Ok(env.iter().map(|(k, v)| format!("{}={}", k, v)).collect())
 }
 
diff --git a/src/crosvm/sys/linux/jail_warden.rs b/src/crosvm/sys/linux/jail_warden.rs
index cee109ed6..38c28962f 100644
--- a/src/crosvm/sys/linux/jail_warden.rs
+++ b/src/crosvm/sys/linux/jail_warden.rs
@@ -14,8 +14,6 @@ use anyhow::Context;
 use anyhow::Result;
 use base::error;
 use base::info;
-use base::linux::process::fork_process;
-use base::linux::process::Child;
 use base::syslog;
 use base::AsRawDescriptor;
 #[cfg(feature = "swap")]
@@ -30,6 +28,8 @@ use devices::ProxyDevice;
 use devices::ResourceCarrier;
 use jail::create_base_minijail;
 use jail::create_sandbox_minijail;
+use jail::fork::fork_process;
+use jail::fork::Child;
 use jail::RunAsUser;
 use jail::SandboxConfig;
 use jail::MAX_OPEN_FILES_FOR_JAIL_WARDEN;
diff --git a/src/crosvm/sys/linux/pci_hotplug_manager.rs b/src/crosvm/sys/linux/pci_hotplug_manager.rs
index c912563fc..861f779ad 100644
--- a/src/crosvm/sys/linux/pci_hotplug_manager.rs
+++ b/src/crosvm/sys/linux/pci_hotplug_manager.rs
@@ -5,12 +5,12 @@
 //! A high-level manager for hotplug PCI devices.
 
 // TODO(b/243767476): Support aarch64.
+use std::cmp::Ordering;
 use std::collections::BTreeMap;
 use std::collections::HashMap;
+use std::collections::VecDeque;
 use std::sync::mpsc;
 use std::sync::Arc;
-use std::thread;
-use std::time::Duration;
 
 use anyhow::anyhow;
 use anyhow::bail;
@@ -19,6 +19,13 @@ use anyhow::Error;
 use arch::RunnableLinuxVm;
 use arch::VcpuArch;
 use arch::VmArch;
+use base::AsRawDescriptor;
+use base::Event;
+use base::EventToken;
+use base::RawDescriptor;
+use base::WaitContext;
+use base::WorkerThread;
+use devices::BusDevice;
 use devices::HotPlugBus;
 use devices::HotPlugKey;
 use devices::IrqEventSource;
@@ -27,7 +34,6 @@ use devices::PciAddress;
 use devices::PciInterruptPin;
 use devices::PciRootCommand;
 use devices::ResourceCarrier;
-use log::debug;
 use log::error;
 use resources::SystemAllocator;
 #[cfg(feature = "swap")]
@@ -42,87 +48,641 @@ use crate::Config;
 
 pub type Result<T> = std::result::Result<T, Error>;
 
-const PCI_SLOT_TIMEOUT: Duration = Duration::from_secs(1);
-
 /// PciHotPlugManager manages hotplug ports, and handles PCI device hot plug and hot removal.
 pub struct PciHotPlugManager {
-    /// map of empty ports available.
-    ///
-    /// empty ports are sorted such to ensure the ordering of the hotplugged devices. Specifically,
-    /// if multiple devices are hotplugged before PCI enumeration, they will appear in the guest OS
-    /// in the same order hotplug_device is called.
-    port_pool: PortPool,
-    /// map of occupied ports, indexed by downstream bus number
-    occupied_ports: HashMap<u8, PortStub>,
+    /// map of ports managed
+    port_stubs: BTreeMap<PciAddress, PortManagerStub>,
+    /// map of downstream bus to upstream PCI address
+    bus_address_map: BTreeMap<u8, PciAddress>,
     /// JailWarden for jailing hotplug devices
     jail_warden: Box<dyn JailWarden>,
-    /// control channel to root bus
-    rootbus_controller: Option<mpsc::Sender<PciRootCommand>>,
+    /// Client on Manager side of PciHotPlugWorker
+    worker_client: Option<WorkerClient>,
 }
 
-/// HotPlugAvailability indicates when a port is available for hotplug.
-#[derive(Debug)]
-enum HotPlugAvailability {
-    /// available now
-    Now,
-    /// available after notification is received.
-    After(mpsc::Receiver<()>),
+/// WorkerClient is a wrapper of the worker methods.
+struct WorkerClient {
+    /// event to signal control command is sent
+    control_evt: Event,
+    /// control channel to worker
+    command_sender: mpsc::Sender<WorkerCommand>,
+    /// response channel from worker
+    response_receiver: mpsc::Receiver<WorkerResponse>,
+    _worker_thread: WorkerThread<Result<()>>,
 }
 
-/// PortStub contains a hotplug port and set of hotplug devices on it.
-struct PortStub {
-    /// PCI address of the port (at upstream)
-    pci_address: PciAddress,
+impl WorkerClient {
+    /// Constructs PciHotPlugWorker with its client.
+    fn new(rootbus_controller: mpsc::Sender<PciRootCommand>) -> Result<Self> {
+        let (command_sender, command_receiver) = mpsc::channel();
+        let (response_sender, response_receiver) = mpsc::channel();
+        let control_evt = Event::new()?;
+        let control_evt_cpy = control_evt.try_clone()?;
+        let worker_thread = WorkerThread::start("pcihp_mgr_workr", move |kill_evt| {
+            let mut worker = PciHotPlugWorker::new(
+                rootbus_controller,
+                command_receiver,
+                response_sender,
+                control_evt_cpy,
+                &kill_evt,
+            )?;
+            worker.run(kill_evt).map_err(|e| {
+                error!("Worker exited with error: {:?}", &e);
+                e
+            })
+        });
+        Ok(WorkerClient {
+            control_evt,
+            command_sender,
+            response_receiver,
+            _worker_thread: worker_thread,
+        })
+    }
+
+    /// Sends worker command, and wait for its response.
+    fn send_worker_command(&self, command: WorkerCommand) -> Result<WorkerResponse> {
+        self.command_sender.send(command)?;
+        self.control_evt.signal()?;
+        Ok(self.response_receiver.recv()?)
+    }
+}
+
+/// PortManagerStub is the manager-side copy of a port.
+struct PortManagerStub {
     /// index of downstream bus
     downstream_bus: u8,
-    /// hotplug port
-    port: Arc<Mutex<dyn HotPlugBus>>,
     /// Map of hotplugged devices, and system resources that can be released when device is
     /// removed.
     devices: HashMap<PciAddress, RecoverableResource>,
 }
 
-impl PortStub {
-    /// Sends hotplug signal on the port.
-    fn send_hotplug_signal(&mut self) -> Result<()> {
-        let base_pci_address = PciAddress::new(0, self.downstream_bus.into(), 0, 0)?;
-        self.port.lock().hot_plug(base_pci_address)?;
+/// System resources that can be released when a hotplugged device is removed.
+struct RecoverableResource {
+    irq_num: u32,
+    irq_evt: IrqLevelEvent,
+}
+
+/// Control commands to worker.
+enum WorkerCommand {
+    /// Add port to the worker.
+    AddPort(PciAddress, PortWorkerStub),
+    /// Get the state of the port.
+    GetPortState(PciAddress),
+    /// Get an empty port for hotplug. Returns the least port sorted by PortKey.
+    GetEmptyPort,
+    /// Signals hot plug on port. Changes an empty port to occupied.
+    SignalHotPlug(SignalHotPlugCommand),
+    /// Signals hot unplug on port. Changes an occupied port to empty.
+    SignalHotUnplug(PciAddress),
+}
+
+#[derive(Clone)]
+struct GuestDeviceStub {
+    pci_addr: PciAddress,
+    key: HotPlugKey,
+    device: Arc<Mutex<dyn BusDevice>>,
+}
+
+#[derive(Clone)]
+struct SignalHotPlugCommand {
+    /// the upstream address of hotplug port
+    upstream_address: PciAddress,
+    /// the array of guest devices on the port
+    guest_devices: Vec<GuestDeviceStub>,
+}
+
+impl SignalHotPlugCommand {
+    fn new(upstream_address: PciAddress, guest_devices: Vec<GuestDeviceStub>) -> Result<Self> {
+        if guest_devices.is_empty() {
+            bail!("No guest devices");
+        }
+        Ok(Self {
+            upstream_address,
+            guest_devices,
+        })
+    }
+}
+
+/// PortWorkerStub is the worker-side copy of a port.
+#[derive(Clone)]
+struct PortWorkerStub {
+    /// The downstream base address of the port. Needed to send plug and unplug signal.
+    base_address: PciAddress,
+    /// Currently attached devices that should be removed.
+    attached_devices: Vec<PciAddress>,
+    /// Devices to be added each time send_hot_plug_signal is called.
+    devices_to_add: VecDeque<Vec<GuestDeviceStub>>,
+    /// hotplug port
+    port: Arc<Mutex<dyn HotPlugBus>>,
+}
+
+impl PortWorkerStub {
+    fn new(port: Arc<Mutex<dyn HotPlugBus>>, downstream_bus: u8) -> Result<Self> {
+        let base_address = PciAddress::new(0, downstream_bus.into(), 0, 0)?;
+        Ok(Self {
+            base_address,
+            devices_to_add: VecDeque::new(),
+            attached_devices: Vec::new(),
+            port,
+        })
+    }
+
+    fn add_hotplug_devices(&mut self, devices: Vec<GuestDeviceStub>) -> Result<()> {
+        if devices.is_empty() {
+            bail!("No guest devices");
+        }
+        self.devices_to_add.push_back(devices);
         Ok(())
     }
 
-    /// Sends hotplug signal after notification on the port.
-    fn send_hotplug_signal_after_notification(
+    fn cancel_queued_add(&mut self) -> Result<()> {
+        self.devices_to_add
+            .pop_back()
+            .context("No guest device add queued")?;
+        Ok(())
+    }
+
+    fn send_hot_plug_signal(
         &mut self,
-        notf_recvr: mpsc::Receiver<()>,
-    ) -> Result<()> {
-        let base_pci_address = PciAddress::new(0, self.downstream_bus.into(), 0, 0)?;
-        let weak_port = Arc::downgrade(&self.port);
-        thread::spawn(move || {
-            if let Err(e) = notf_recvr.recv_timeout(PCI_SLOT_TIMEOUT) {
-                error!(
-                    "failed to receive hot unplug command complete notification: {:#}",
-                    &e
-                );
-            }
-            match weak_port.upgrade() {
-                Some(port) => {
-                    if let Err(e) = port.lock().hot_plug(base_pci_address) {
-                        error!("hot plug failed: {:#}", &e);
+        rootbus_controller: &mpsc::Sender<PciRootCommand>,
+    ) -> Result<Event> {
+        let mut port_lock = self.port.lock();
+        let devices = self
+            .devices_to_add
+            .pop_front()
+            .context("Missing devices to add")?;
+        for device in devices {
+            rootbus_controller.send(PciRootCommand::Add(device.pci_addr, device.device))?;
+            self.attached_devices.push(device.pci_addr);
+            port_lock.add_hotplug_device(device.key, device.pci_addr);
+        }
+        port_lock
+            .hot_plug(self.base_address)?
+            .context("hotplug bus does not support command complete notification")
+    }
+
+    fn send_hot_unplug_signal(
+        &mut self,
+        rootbus_controller: &mpsc::Sender<PciRootCommand>,
+    ) -> Result<Event> {
+        for pci_addr in self.attached_devices.drain(..) {
+            rootbus_controller.send(PciRootCommand::Remove(pci_addr))?;
+        }
+        self.port
+            .lock()
+            .hot_unplug(self.base_address)?
+            .context("hotplug bus does not support command complete notification")
+    }
+}
+
+/// Control response from worker.
+#[derive(Debug)]
+enum WorkerResponse {
+    /// AddPort success.
+    AddPortOk,
+    /// GetEmptyPort success, use port at PciAddress.
+    GetEmptyPortOk(PciAddress),
+    /// GetPortState success. The "steps behind" field shall be considered expired, and the guest
+    /// is "less than or equal to" n steps behind.
+    GetPortStateOk(PortState),
+    /// SignalHotPlug or SignalHotUnplug success.
+    SignalOk,
+    /// Command fail because it is not valid.
+    InvalidCommand(Error),
+}
+
+impl PartialEq for WorkerResponse {
+    fn eq(&self, other: &Self) -> bool {
+        match (self, other) {
+            (Self::GetEmptyPortOk(l0), Self::GetEmptyPortOk(r0)) => l0 == r0,
+            (Self::GetPortStateOk(l0), Self::GetPortStateOk(r0)) => l0 == r0,
+            (Self::InvalidCommand(_), Self::InvalidCommand(_)) => true,
+            _ => core::mem::discriminant(self) == core::mem::discriminant(other),
+        }
+    }
+}
+
+#[derive(Debug, EventToken)]
+enum Token {
+    Kill,
+    ManagerCommand,
+    PortReady(RawDescriptor),
+    PlugComplete(RawDescriptor),
+    UnplugComplete(RawDescriptor),
+}
+
+/// PciHotPlugWorker is a worker that handles the asynchrony of slot states between crosvm and the
+/// guest OS. It is responsible for scheduling the PCIe slot control signals and handle its result.
+struct PciHotPlugWorker {
+    event_map: BTreeMap<RawDescriptor, (Event, PciAddress)>,
+    port_state_map: BTreeMap<PciAddress, PortState>,
+    port_map: BTreeMap<PortKey, PortWorkerStub>,
+    manager_evt: Event,
+    wait_ctx: WaitContext<Token>,
+    command_receiver: mpsc::Receiver<WorkerCommand>,
+    response_sender: mpsc::Sender<WorkerResponse>,
+    rootbus_controller: mpsc::Sender<PciRootCommand>,
+}
+
+impl PciHotPlugWorker {
+    fn new(
+        rootbus_controller: mpsc::Sender<PciRootCommand>,
+        command_receiver: mpsc::Receiver<WorkerCommand>,
+        response_sender: mpsc::Sender<WorkerResponse>,
+        manager_evt: Event,
+        kill_evt: &Event,
+    ) -> Result<Self> {
+        let wait_ctx: WaitContext<Token> = WaitContext::build_with(&[
+            (&manager_evt, Token::ManagerCommand),
+            (kill_evt, Token::Kill),
+        ])?;
+        Ok(Self {
+            event_map: BTreeMap::new(),
+            port_state_map: BTreeMap::new(),
+            port_map: BTreeMap::new(),
+            manager_evt,
+            wait_ctx,
+            command_receiver,
+            response_sender,
+            rootbus_controller,
+        })
+    }
+
+    /// Starts the worker. Runs until received kill request, or an error that the worker is in an
+    /// invalid state.
+    fn run(&mut self, kill_evt: Event) -> Result<()> {
+        'wait: loop {
+            let events = self.wait_ctx.wait()?;
+            for triggered_event in events.iter().filter(|e| e.is_readable) {
+                match triggered_event.token {
+                    Token::ManagerCommand => {
+                        self.manager_evt.wait()?;
+                        self.handle_manager_command()?;
+                    }
+                    Token::PortReady(descriptor) => {
+                        let (event, pci_address) = self
+                            .event_map
+                            .remove(&descriptor)
+                            .context("Cannot find event")?;
+                        event.wait()?;
+                        self.wait_ctx.delete(&event)?;
+                        self.handle_port_ready(pci_address)?;
+                    }
+                    Token::PlugComplete(descriptor) => {
+                        let (event, pci_address) = self
+                            .event_map
+                            .remove(&descriptor)
+                            .context("Cannot find event")?;
+                        event.wait()?;
+                        self.wait_ctx.delete(&event)?;
+                        self.handle_plug_complete(pci_address)?;
+                    }
+                    Token::UnplugComplete(descriptor) => {
+                        let (event, pci_address) = self
+                            .event_map
+                            .remove(&descriptor)
+                            .context("Cannot find event")?;
+                        self.wait_ctx.delete(&event)?;
+                        self.handle_unplug_complete(pci_address)?;
+                    }
+                    Token::Kill => {
+                        let _ = kill_evt.wait();
+                        break 'wait;
                     }
                 }
-                None => {
-                    error!("hotplug signal cancelled since port is out of scope");
+            }
+        }
+        Ok(())
+    }
+
+    fn handle_manager_command(&mut self) -> Result<()> {
+        let response = match self.command_receiver.recv()? {
+            WorkerCommand::AddPort(pci_address, port) => self.handle_add_port(pci_address, port),
+            WorkerCommand::GetPortState(pci_address) => self.handle_get_port_state(pci_address),
+            WorkerCommand::GetEmptyPort => self.handle_get_empty_port(),
+            WorkerCommand::SignalHotPlug(hotplug_command) => {
+                self.handle_plug_request(hotplug_command)
+            }
+            WorkerCommand::SignalHotUnplug(pci_address) => self.handle_unplug_request(pci_address),
+        }?;
+        Ok(self.response_sender.send(response)?)
+    }
+
+    /// Handles add port: Initiate port in EmptyNotReady state.
+    fn handle_add_port(
+        &mut self,
+        pci_address: PciAddress,
+        port: PortWorkerStub,
+    ) -> Result<WorkerResponse> {
+        if self.port_state_map.contains_key(&pci_address) {
+            return Ok(WorkerResponse::InvalidCommand(anyhow!(
+                "Conflicting upstream PCI address"
+            )));
+        }
+        let port_state = PortState::EmptyNotReady;
+        let port_ready_event = port.port.lock().get_ready_notification()?;
+        self.wait_ctx.add(
+            &port_ready_event,
+            Token::PortReady(port_ready_event.as_raw_descriptor()),
+        )?;
+        self.event_map.insert(
+            port_ready_event.as_raw_descriptor(),
+            (port_ready_event, pci_address),
+        );
+        self.port_state_map.insert(pci_address, port_state);
+        self.port_map.insert(
+            PortKey {
+                port_state,
+                pci_address,
+            },
+            port,
+        );
+        Ok(WorkerResponse::AddPortOk)
+    }
+
+    /// Handles get port state: returns the PortState.
+    fn handle_get_port_state(&self, pci_address: PciAddress) -> Result<WorkerResponse> {
+        match self.get_port_state(pci_address) {
+            Ok(ps) => Ok(WorkerResponse::GetPortStateOk(ps)),
+            Err(e) => Ok(WorkerResponse::InvalidCommand(e)),
+        }
+    }
+
+    /// Handle getting empty port: Find the most empty port, or return error if all are occupied.
+    fn handle_get_empty_port(&self) -> Result<WorkerResponse> {
+        let most_empty_port = match self.port_map.first_key_value() {
+            Some(p) => p.0,
+            None => return Ok(WorkerResponse::InvalidCommand(anyhow!("No ports added"))),
+        };
+        match most_empty_port.port_state {
+            PortState::Empty(_) | PortState::EmptyNotReady => {
+                Ok(WorkerResponse::GetEmptyPortOk(most_empty_port.pci_address))
+            }
+            PortState::Occupied(_) | PortState::OccupiedNotReady => {
+                Ok(WorkerResponse::InvalidCommand(anyhow!("No empty port")))
+            }
+        }
+    }
+
+    /// Handles plug request: Moves PortState from EmptyNotReady to OccupiedNotReady, Empty(n) to
+    /// Occupied(n+1), and schedules the next plug event if n == 0.
+    fn handle_plug_request(
+        &mut self,
+        hotplug_command: SignalHotPlugCommand,
+    ) -> Result<WorkerResponse> {
+        let pci_address = hotplug_command.upstream_address;
+        let next_state = match self.get_port_state(pci_address) {
+            Ok(PortState::Empty(n)) => {
+                self.get_port_mut(pci_address)?
+                    .add_hotplug_devices(hotplug_command.guest_devices)?;
+                if n == 0 {
+                    self.schedule_plug_event(pci_address)?;
                 }
+                PortState::Occupied(n + 1)
             }
-        });
+            Ok(PortState::EmptyNotReady) => {
+                self.get_port_mut(pci_address)?
+                    .add_hotplug_devices(hotplug_command.guest_devices)?;
+                PortState::OccupiedNotReady
+            }
+            Ok(PortState::Occupied(_)) | Ok(PortState::OccupiedNotReady) => {
+                return Ok(WorkerResponse::InvalidCommand(anyhow!(
+                    "Attempt to plug into an occupied port"
+                )))
+            }
+            Err(e) => return Ok(WorkerResponse::InvalidCommand(e)),
+        };
+        self.set_port_state(pci_address, next_state)?;
+        Ok(WorkerResponse::SignalOk)
+    }
+
+    /// Handles unplug request: Moves PortState from OccupiedNotReady to EmptyNotReady, Occupied(n)
+    /// to Empty(n % 2 + 1), and schedules the next unplug event if n == 0.
+    ///
+    /// n % 2 + 1: When unplug request is made, it either schedule the unplug event
+    /// (n == 0 => 1 or n == 1 => 2), or cancels the corresponding plug event that has not started
+    /// (n == 2 => 1 or n == 3 => 2). Staring at the mapping, it maps n to either 1 or 2 of opposite
+    /// oddity. n % 2 + 1 is a good shorthand instead of the individual mappings.
+    fn handle_unplug_request(&mut self, pci_address: PciAddress) -> Result<WorkerResponse> {
+        let next_state = match self.get_port_state(pci_address) {
+            Ok(PortState::Occupied(n)) => {
+                if n >= 2 {
+                    self.get_port_mut(pci_address)?.cancel_queued_add()?;
+                }
+                if n == 0 {
+                    self.schedule_unplug_event(pci_address)?;
+                }
+                PortState::Empty(n % 2 + 1)
+            }
+            Ok(PortState::OccupiedNotReady) => PortState::EmptyNotReady,
+            Ok(PortState::Empty(_)) | Ok(PortState::EmptyNotReady) => {
+                return Ok(WorkerResponse::InvalidCommand(anyhow!(
+                    "Attempt to unplug from an empty port"
+                )))
+            }
+            Err(e) => return Ok(WorkerResponse::InvalidCommand(e)),
+        };
+        self.set_port_state(pci_address, next_state)?;
+        Ok(WorkerResponse::SignalOk)
+    }
+
+    /// Handles port ready: Moves PortState from EmptyNotReady to Empty(0), OccupiedNotReady to
+    /// Occupied(1), and schedules the next event if port is occupied
+    fn handle_port_ready(&mut self, pci_address: PciAddress) -> Result<()> {
+        let next_state = match self.get_port_state(pci_address)? {
+            PortState::EmptyNotReady => PortState::Empty(0),
+            PortState::OccupiedNotReady => {
+                self.schedule_plug_event(pci_address)?;
+                PortState::Occupied(1)
+            }
+            PortState::Empty(_) | PortState::Occupied(_) => {
+                bail!("Received port ready on an already enabled port");
+            }
+        };
+        self.set_port_state(pci_address, next_state)
+    }
+
+    /// Handles plug complete: Moves PortState from Any(n) to Any(n-1), and schedules the next
+    /// unplug event unless n == 1. (Any is either Empty or Occupied.)
+    fn handle_plug_complete(&mut self, pci_address: PciAddress) -> Result<()> {
+        let (n, next_state) = match self.get_port_state(pci_address)? {
+            // Note: n - 1 >= 0 as otherwise there would be no pending events.
+            PortState::Empty(n) => (n, PortState::Empty(n - 1)),
+            PortState::Occupied(n) => (n, PortState::Occupied(n - 1)),
+            PortState::EmptyNotReady | PortState::OccupiedNotReady => {
+                bail!("Received plug completed on a not enabled port");
+            }
+        };
+        if n > 1 {
+            self.schedule_unplug_event(pci_address)?;
+        }
+        self.set_port_state(pci_address, next_state)
+    }
+
+    /// Handles unplug complete: Moves PortState from Any(n) to Any(n-1), and schedules the next
+    /// plug event unless n == 1. (Any is either Empty or Occupied.)
+    fn handle_unplug_complete(&mut self, pci_address: PciAddress) -> Result<()> {
+        let (n, next_state) = match self.get_port_state(pci_address)? {
+            // Note: n - 1 >= 0 as otherwise there would be no pending events.
+            PortState::Empty(n) => (n, PortState::Empty(n - 1)),
+            PortState::Occupied(n) => (n, PortState::Occupied(n - 1)),
+            PortState::EmptyNotReady | PortState::OccupiedNotReady => {
+                bail!("Received unplug completed on a not enabled port");
+            }
+        };
+        if n > 1 {
+            self.schedule_plug_event(pci_address)?;
+        }
+        self.set_port_state(pci_address, next_state)
+    }
+
+    fn get_port_state(&self, pci_address: PciAddress) -> Result<PortState> {
+        Ok(*self
+            .port_state_map
+            .get(&pci_address)
+            .context(format!("Cannot find port state on {}", pci_address))?)
+    }
+
+    fn set_port_state(&mut self, pci_address: PciAddress, port_state: PortState) -> Result<()> {
+        let old_port_state = self.get_port_state(pci_address)?;
+        let port = self
+            .port_map
+            .remove(&PortKey {
+                port_state: old_port_state,
+                pci_address,
+            })
+            .context("Cannot find port")?;
+        self.port_map.insert(
+            PortKey {
+                port_state,
+                pci_address,
+            },
+            port,
+        );
+        self.port_state_map.insert(pci_address, port_state);
         Ok(())
     }
+
+    fn schedule_plug_event(&mut self, pci_address: PciAddress) -> Result<()> {
+        let rootbus_controller = self.rootbus_controller.clone();
+        let plug_event = self
+            .get_port_mut(pci_address)?
+            .send_hot_plug_signal(&rootbus_controller)?;
+        self.wait_ctx.add(
+            &plug_event,
+            Token::PlugComplete(plug_event.as_raw_descriptor()),
+        )?;
+        self.event_map
+            .insert(plug_event.as_raw_descriptor(), (plug_event, pci_address));
+        Ok(())
+    }
+
+    fn schedule_unplug_event(&mut self, pci_address: PciAddress) -> Result<()> {
+        let rootbus_controller = self.rootbus_controller.clone();
+        let unplug_event = self
+            .get_port_mut(pci_address)?
+            .send_hot_unplug_signal(&rootbus_controller)?;
+        self.wait_ctx.add(
+            &unplug_event,
+            Token::UnplugComplete(unplug_event.as_raw_descriptor()),
+        )?;
+        self.event_map.insert(
+            unplug_event.as_raw_descriptor(),
+            (unplug_event, pci_address),
+        );
+        Ok(())
+    }
+
+    fn get_port_mut(&mut self, pci_address: PciAddress) -> Result<&mut PortWorkerStub> {
+        let port_state = self.get_port_state(pci_address)?;
+        self.port_map
+            .get_mut(&PortKey {
+                port_state,
+                pci_address,
+            })
+            .context("PciHotPlugWorker is in invalid state")
+    }
 }
 
-/// System resources that can be released when a hotplugged device is removed.
-struct RecoverableResource {
-    irq_num: u32,
-    irq_evt: IrqLevelEvent,
+/// PortState indicates the state of the port.
+///
+/// The initial PortState is EmptyNotReady (EmpNR). 9 PortStates are possible, and transition
+/// between the states are only possible by the following 3 groups of functions:
+/// handle_port_ready(R): guest notification of port ready to accept hot plug events.
+/// handle_plug_request(P) and handle_unplug_request(U): host initated requests.
+/// handle_plug_complete(PC) and handle_unplug_complete(UC): guest notification of event completion.
+/// When a port is not ready, PC and UC are not expected as no events are scheduled.
+/// The state transition is as follows:
+///    Emp0<-UC--Emp1<-PC--Emp2            |
+///  ^     \    ^    \^   ^    \^          |
+/// /       P  /      P\ /      P\         |
+/// |        \/        \\        \\        |
+/// |        /\        /\\        \\       |
+/// R       U  \      U  \U        \U      |
+/// |      /    v    /    v\        v\     |
+/// |  Occ0<-PC--Occ1<-UC--Occ2<-PC--Occ3  |
+/// |              ^                       |
+/// \              R                       |
+///   EmpNR<-P,U->OccNR                    |
+
+#[derive(Clone, Copy, Debug, PartialEq, Eq)]
+enum PortState {
+    /// Port is empty on crosvm. The state on the guest OS is n steps behind.
+    Empty(u8),
+    /// Port is empty on crosvm. The port is not enabled on the guest OS yet.
+    EmptyNotReady,
+    /// Port is occupied on crosvm. The state on the guest OS is n steps behind.
+    Occupied(u8),
+    /// Port is occupied on crosvm. The port is not enabled on the guest OS yet.
+    OccupiedNotReady,
+}
+
+impl PortState {
+    fn variant_order_index(&self) -> u8 {
+        match self {
+            PortState::Empty(_) => 0,
+            PortState::EmptyNotReady => 1,
+            PortState::Occupied(_) => 2,
+            PortState::OccupiedNotReady => 3,
+        }
+    }
+}
+
+/// Ordering on PortState defined by "most empty".
+impl Ord for PortState {
+    fn cmp(&self, other: &Self) -> Ordering {
+        // First compare by the variant: Empty < EmptyNotReady < Occupied < OccupiedNotReady.
+        match self.variant_order_index().cmp(&other.variant_order_index()) {
+            Ordering::Less => {
+                return Ordering::Less;
+            }
+            Ordering::Equal => {}
+            Ordering::Greater => return Ordering::Greater,
+        }
+        // For the diagonals, prioritize ones with less step behind.
+        match (self, other) {
+            (PortState::Empty(lhs), PortState::Empty(rhs)) => lhs.cmp(rhs),
+            (PortState::Occupied(lhs), PortState::Occupied(rhs)) => lhs.cmp(rhs),
+            _ => Ordering::Equal,
+        }
+    }
+}
+
+impl PartialOrd for PortState {
+    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
+        Some(self.cmp(other))
+    }
+}
+
+/// PortKey is a unique identifier of ports with an ordering defined on it.
+///
+/// Ports are ordered by whose downstream device would be discovered first by the guest OS.
+/// Empty ports without pending events are ordered before those with pending events. When multiple
+/// empty ports without pending events are available, they are ordered by PCI enumeration.
+#[derive(PartialEq, Eq, PartialOrd, Ord)]
+struct PortKey {
+    port_state: PortState,
+    pci_address: PciAddress,
 }
 
 impl PciHotPlugManager {
@@ -156,10 +716,10 @@ impl PciHotPlugManager {
             ),
         };
         Ok(Self {
-            port_pool: PortPool::new(),
-            occupied_ports: HashMap::new(),
             jail_warden,
-            rootbus_controller: None,
+            port_stubs: BTreeMap::new(),
+            bus_address_map: BTreeMap::new(),
+            worker_client: None,
         })
     }
 
@@ -174,7 +734,8 @@ impl PciHotPlugManager {
         &mut self,
         rootbus_controller: mpsc::Sender<PciRootCommand>,
     ) -> Result<()> {
-        self.rootbus_controller = Some(rootbus_controller);
+        // Spins the PciHotPlugWorker.
+        self.worker_client = Some(WorkerClient::new(rootbus_controller)?);
         Ok(())
     }
 
@@ -184,6 +745,10 @@ impl PciHotPlugManager {
     /// TODO(293801301): Remove unused_variables after aarch64 support
     #[allow(unused)]
     pub fn add_port(&mut self, port: Arc<Mutex<dyn HotPlugBus>>) -> Result<()> {
+        let worker_client = self
+            .worker_client
+            .as_ref()
+            .context("No worker thread. Is set_rootbus_controller not called?")?;
         let port_lock = port.lock();
         // Rejects hotplug bus with downstream devices.
         if !port_lock.is_empty() {
@@ -201,13 +766,27 @@ impl PciHotPlugManager {
             .get_secondary_bus_number()
             .context("cannot get downstream bus")?;
         drop(port_lock);
-        self.port_pool.insert(PortStub {
+        if let Some(prev_address) = self.bus_address_map.insert(downstream_bus, pci_address) {
+            bail!(
+                "Downstream bus of new port is conflicting with previous port at {}",
+                &prev_address
+            );
+        }
+        self.port_stubs.insert(
             pci_address,
-            downstream_bus,
-            port,
-            devices: HashMap::new(),
-        });
-        Ok(())
+            PortManagerStub {
+                downstream_bus,
+                devices: HashMap::new(),
+            },
+        );
+        match worker_client.send_worker_command(WorkerCommand::AddPort(
+            pci_address,
+            PortWorkerStub::new(port, downstream_bus)?,
+        ))? {
+            WorkerResponse::AddPortOk => Ok(()),
+            WorkerResponse::InvalidCommand(e) => Err(e),
+            r => bail!("Unexpected response from worker: {:?}", &r),
+        }
     }
 
     /// hotplugs up to 8 PCI devices as "functions of a device" (in PCI Bus Device Function sense).
@@ -219,14 +798,24 @@ impl PciHotPlugManager {
         linux: &mut RunnableLinuxVm<V, Vcpu>,
         resources: &mut SystemAllocator,
     ) -> Result<u8> {
+        let worker_client = self
+            .worker_client
+            .as_ref()
+            .context("No worker thread. Is set_rootbus_controller not called?")?;
         if resource_carriers.len() > 8 || resource_carriers.is_empty() {
             bail!("PCI function count has to be 1 to 8 inclusive");
         }
-        let (mut port_stub, port_availability) = self.port_pool.pop_first()?;
+        let pci_address = match worker_client.send_worker_command(WorkerCommand::GetEmptyPort)? {
+            WorkerResponse::GetEmptyPortOk(p) => Ok(p),
+            WorkerResponse::InvalidCommand(e) => Err(e),
+            r => bail!("Unexpected response from worker: {:?}", &r),
+        }?;
+        let port_stub = self
+            .port_stubs
+            .get_mut(&pci_address)
+            .context("Cannot find port")?;
         let downstream_bus = port_stub.downstream_bus;
-        if self.occupied_ports.contains_key(&downstream_bus) {
-            bail!("Downstream bus {} already used", downstream_bus);
-        }
+        let mut devices = Vec::new();
         for (func_num, mut resource_carrier) in resource_carriers.into_iter().enumerate() {
             let device_address = PciAddress::new(0, downstream_bus as u32, 0, func_num as u32)?;
             let hotplug_key = HotPlugKey::GuestDevice {
@@ -260,31 +849,23 @@ impl PciHotPlugManager {
             if pid > 0 {
                 linux.pid_debug_label_map.insert(pid, device_name);
             }
-            self.rootbus_controller
-                .as_ref()
-                .context("rootbus_controller not set: set_rootbus_controller not called?")?
-                .send(PciRootCommand::Add(device_address, proxy_device))?;
-            port_stub
-                .port
-                .lock()
-                .add_hotplug_device(hotplug_key, device_address);
+            devices.push(GuestDeviceStub {
+                pci_addr: device_address,
+                key: hotplug_key,
+                device: proxy_device,
+            });
             port_stub
                 .devices
                 .insert(device_address, RecoverableResource { irq_num, irq_evt });
         }
-        // Send hotplug signal after all functions are added.
-        match port_availability {
-            HotPlugAvailability::Now => port_stub.send_hotplug_signal()?,
-            HotPlugAvailability::After(cc_recvr) => {
-                debug!(
-                    "Hotplug signal delayed since port {} is busy",
-                    &port_stub.pci_address,
-                );
-                port_stub.send_hotplug_signal_after_notification(cc_recvr)?;
-            }
+        // Ask worker to schedule hotplug signal.
+        match worker_client.send_worker_command(WorkerCommand::SignalHotPlug(
+            SignalHotPlugCommand::new(pci_address, devices)?,
+        ))? {
+            WorkerResponse::SignalOk => Ok(downstream_bus),
+            WorkerResponse::InvalidCommand(e) => Err(e),
+            r => bail!("Unexpected response from worker: {:?}", &r),
         }
-        self.occupied_ports.insert(downstream_bus, port_stub);
-        Ok(downstream_bus)
     }
 
     /// Removes all hotplugged devices on the hotplug bus.
@@ -294,167 +875,566 @@ impl PciHotPlugManager {
         linux: &mut RunnableLinuxVm<V, Vcpu>,
         resources: &mut SystemAllocator,
     ) -> Result<()> {
-        // Unlike hotplug, HotPlugBus removes all downstream devices when eject signal is sent.
-        let cc_recvr = self.remove_device_from_port(bus)?;
-        let port_stub = self
-            .occupied_ports
-            .get_mut(&bus)
-            .context("invalid hotplug bus number")?;
+        let worker_client = self
+            .worker_client
+            .as_ref()
+            .context("No worker thread. Is set_rootbus_controller not called?")?;
+        let pci_address = self
+            .bus_address_map
+            .get(&bus)
+            .context(format!("Port {} is not known", &bus))?;
+        match worker_client.send_worker_command(WorkerCommand::GetPortState(*pci_address))? {
+            WorkerResponse::GetPortStateOk(PortState::Occupied(_)) => {}
+            WorkerResponse::GetPortStateOk(PortState::Empty(_)) => {
+                bail!("Port {} is empty", &bus)
+            }
+            WorkerResponse::InvalidCommand(e) => {
+                return Err(e);
+            }
+            wr => bail!("Unexpected response from worker: {:?}", &wr),
+        };
+        // Performs a surprise removal. That is, not waiting for hot removal completion before
+        // deleting the resources.
+        match worker_client.send_worker_command(WorkerCommand::SignalHotUnplug(*pci_address))? {
+            WorkerResponse::SignalOk => {}
+            WorkerResponse::InvalidCommand(e) => {
+                return Err(e);
+            }
+            wr => bail!("Unexpected response from worker: {:?}", &wr),
+        }
         // Remove all devices on the hotplug bus.
-        for (pci_address, recoverable_resource) in port_stub.devices.drain() {
-            self.rootbus_controller
-                .as_ref()
-                .context("rootbus_controller not set: set_rootbus_controller not called?")?
-                .send(PciRootCommand::Remove(pci_address))?;
+        let port_stub = self
+            .port_stubs
+            .get_mut(pci_address)
+            .context(format!("Port {} is not known", &bus))?;
+        for (downstream_address, recoverable_resource) in port_stub.devices.drain() {
             // port_stub.port does not have remove_hotplug_device method, as devices are removed
             // when hot_unplug is called.
-            resources.release_pci(pci_address.bus, pci_address.dev, pci_address.func);
+            resources.release_pci(
+                downstream_address.bus,
+                downstream_address.dev,
+                downstream_address.func,
+            );
             linux.irq_chip.unregister_level_irq_event(
                 recoverable_resource.irq_num,
                 &recoverable_resource.irq_evt,
             )?;
         }
-        if let Some(port_stub) = self.occupied_ports.remove(&bus) {
-            self.port_pool
-                .insert_after_notification(port_stub, cc_recvr)?;
-        } else {
-            bail!("Failed to release bus {}", bus);
-        }
         Ok(())
     }
+}
 
-    /// Sends eject signal on the port, and removes downstream devices on the port.
-    fn remove_device_from_port(&self, bus: u8) -> Result<mpsc::Receiver<()>> {
-        let port_stub = self
-            .occupied_ports
-            .get(&bus)
-            .ok_or(anyhow!("invalid bus number for device removal: {}", bus))?;
-        let base_pci_address = PciAddress::new(0, bus as u32, 0, 0)?;
-        port_stub
-            .port
-            .lock()
-            .hot_unplug(base_pci_address)?
-            .context("no notifier for hot unplug completion.")
+#[cfg(test)]
+mod tests {
+    use std::thread;
+    use std::time::Duration;
+
+    use devices::DeviceId;
+    use devices::Suspendable;
+    use serde::Deserialize;
+    use serde::Serialize;
+
+    use super::*;
+
+    /// A MockPort that only supports hot_plug and hot_unplug commands, and signaling command
+    /// complete manually, which is sufficient for PciHotPlugWorker unit test.
+    struct MockPort {
+        cc_event: Event,
+        downstream_bus: u8,
+        ready_events: Vec<Event>,
     }
-}
 
-/// PortPool is a pool available PCI ports where ports can be added asynchronously.
-struct PortPool {
-    /// map of empty ports that are available
-    ports_available: BTreeMap<PciAddress, PortStub>,
-    /// map of ports that will soon be available
-    ports_pending: BTreeMap<PciAddress, (mpsc::Receiver<()>, PortStub)>,
-}
+    impl MockPort {
+        fn new(downstream_bus: u8) -> Self {
+            Self {
+                cc_event: Event::new().unwrap(),
+                downstream_bus,
+                ready_events: Vec::new(),
+            }
+        }
 
-impl PortPool {
-    /// constructor
-    fn new() -> Self {
-        Self {
-            ports_available: BTreeMap::new(),
-            ports_pending: BTreeMap::new(),
+        fn signal_cc(&self) {
+            self.cc_event.reset().unwrap();
+            self.cc_event.signal().unwrap();
         }
-    }
 
-    /// Insert a port_stub that is available immediately.
-    fn insert(&mut self, port_stub: PortStub) -> Result<()> {
-        self.update_port_availability();
-        let pci_addr = port_stub.pci_address;
-        self.ports_available.insert(pci_addr, port_stub);
-        Ok(())
+        fn signal_ready(&mut self) {
+            for event in self.ready_events.drain(..) {
+                event.reset().unwrap();
+                event.signal().unwrap();
+            }
+        }
     }
 
-    /// Insert a port_stub that will be available after notification received. Returns immediately.
-    fn insert_after_notification(
-        &mut self,
-        port_stub: PortStub,
-        cc_recvr: mpsc::Receiver<()>,
-    ) -> Result<()> {
-        self.update_port_availability();
-        self.ports_pending
-            .insert(port_stub.pci_address, (cc_recvr, port_stub));
-        Ok(())
-    }
+    #[derive(Copy, Clone, Serialize, Deserialize, Eq, PartialEq, Debug)]
+    struct MockDevice;
 
-    /// Pop the first available port in the order of PCI enumeration. If no port is available now,
-    /// pop the first in the order of PCI enumeration.
-    fn pop_first(&mut self) -> Result<(PortStub, HotPlugAvailability)> {
-        self.update_port_availability();
-        if let Some((_, port_stub)) = self.ports_available.pop_first() {
-            return Ok((port_stub, HotPlugAvailability::Now));
+    impl Suspendable for MockDevice {
+        fn snapshot(&mut self) -> anyhow::Result<serde_json::Value> {
+            serde_json::to_value(self).context("error serializing")
         }
-        match self.ports_pending.pop_first() {
-            Some((_, (cc_recvr, port_stub))) => {
-                Ok((port_stub, HotPlugAvailability::After(cc_recvr)))
-            }
-            None => Err(anyhow!("No PCI ports available.")),
+
+        fn restore(&mut self, data: serde_json::Value) -> anyhow::Result<()> {
+            *self = serde_json::from_value(data).context("error deserializing")?;
+            Ok(())
+        }
+
+        fn sleep(&mut self) -> anyhow::Result<()> {
+            Ok(())
+        }
+
+        fn wake(&mut self) -> anyhow::Result<()> {
+            Ok(())
         }
     }
 
-    /// Move pending ports to available ports if notification is received.
-    fn update_port_availability(&mut self) {
-        let mut new_ports_pending = BTreeMap::new();
-        while let Some((pci_addr, (cc_recvr, port_stub))) = self.ports_pending.pop_first() {
-            if cc_recvr.try_recv().is_ok() {
-                let pci_addr = port_stub.pci_address;
-                self.ports_available.insert(pci_addr, port_stub);
-            } else {
-                new_ports_pending.insert(pci_addr, (cc_recvr, port_stub));
-            }
+    impl BusDevice for MockDevice {
+        fn device_id(&self) -> DeviceId {
+            DeviceId::try_from(0xdead_beef).unwrap()
+        }
+        fn debug_label(&self) -> String {
+            "mock device".to_owned()
         }
-        self.ports_pending = new_ports_pending;
     }
-}
 
-#[cfg(test)]
-mod tests {
-    use devices::PcieRootPort;
+    impl HotPlugBus for MockPort {
+        fn hot_plug(&mut self, _addr: PciAddress) -> anyhow::Result<Option<Event>> {
+            self.cc_event = Event::new().unwrap();
+            Ok(Some(self.cc_event.try_clone().unwrap()))
+        }
 
-    use super::*;
+        fn hot_unplug(&mut self, _addr: PciAddress) -> anyhow::Result<Option<Event>> {
+            self.cc_event = Event::new().unwrap();
+            Ok(Some(self.cc_event.try_clone().unwrap()))
+        }
 
-    fn new_mock_port_stub(pci_address: PciAddress) -> PortStub {
-        let hotplug_port = PcieRootPort::new(0, true);
-        PortStub {
-            pci_address,
-            downstream_bus: 0,
-            port: Arc::new(Mutex::new(hotplug_port)),
-            devices: HashMap::new(),
+        fn get_ready_notification(&mut self) -> anyhow::Result<Event> {
+            let event = Event::new()?;
+            self.ready_events.push(event.try_clone()?);
+            Ok(event)
+        }
+
+        fn is_match(&self, _host_addr: PciAddress) -> Option<u8> {
+            None
+        }
+
+        fn get_address(&self) -> Option<PciAddress> {
+            None
+        }
+
+        fn get_secondary_bus_number(&self) -> Option<u8> {
+            Some(self.downstream_bus)
+        }
+
+        fn add_hotplug_device(&mut self, _hotplug_key: HotPlugKey, _guest_addr: PciAddress) {}
+
+        fn get_hotplug_device(&self, _hotplug_key: HotPlugKey) -> Option<PciAddress> {
+            None
+        }
+
+        fn is_empty(&self) -> bool {
+            true
         }
+
+        fn get_hotplug_key(&self) -> Option<HotPlugKey> {
+            None
+        }
+    }
+
+    fn new_port(downstream_bus: u8) -> Arc<Mutex<MockPort>> {
+        Arc::new(Mutex::new(MockPort::new(downstream_bus)))
+    }
+
+    fn poll_until_with_timeout<F>(f: F, timeout: Duration) -> bool
+    where
+        F: Fn() -> bool,
+    {
+        for _ in 0..timeout.as_millis() {
+            if f() {
+                return true;
+            }
+            thread::sleep(Duration::from_millis(1));
+        }
+        false
     }
 
     #[test]
-    fn port_pool_pop_before_completion() {
-        let mut port_pool = PortPool::new();
-        let mock_port = new_mock_port_stub(PciAddress::new(0, 1, 0, 0).unwrap());
-        let (_cc_sender, cc_recvr) = mpsc::channel();
-        port_pool
-            .insert_after_notification(mock_port, cc_recvr)
-            .unwrap();
-        let (_port_stub, port_availability) = port_pool.pop_first().unwrap();
-        assert!(matches!(port_availability, HotPlugAvailability::After(_)));
+    fn worker_empty_port_ordering() {
+        let (rootbus_controller, _rootbus_recvr) = mpsc::channel();
+        let client = WorkerClient::new(rootbus_controller).unwrap();
+        // Port A: upstream 00:01.1, downstream 2.
+        let upstream_addr_a = PciAddress {
+            bus: 0,
+            dev: 1,
+            func: 1,
+        };
+        let bus_a = 2;
+        let downstream_addr_a = PciAddress {
+            bus: bus_a,
+            dev: 0,
+            func: 0,
+        };
+        let hotplug_key_a = HotPlugKey::GuestDevice {
+            guest_addr: downstream_addr_a,
+        };
+        let device_a = GuestDeviceStub {
+            pci_addr: downstream_addr_a,
+            key: hotplug_key_a,
+            device: Arc::new(Mutex::new(MockDevice)),
+        };
+        let hotplug_command_a =
+            SignalHotPlugCommand::new(upstream_addr_a, [device_a].to_vec()).unwrap();
+        let port_a = new_port(bus_a);
+        // Port B: upstream 00:01.0, downstream 3.
+        let upstream_addr_b = PciAddress {
+            bus: 0,
+            dev: 1,
+            func: 0,
+        };
+        let bus_b = 3;
+        let downstream_addr_b = PciAddress {
+            bus: bus_b,
+            dev: 0,
+            func: 0,
+        };
+        let hotplug_key_b = HotPlugKey::GuestDevice {
+            guest_addr: downstream_addr_b,
+        };
+        let device_b = GuestDeviceStub {
+            pci_addr: downstream_addr_b,
+            key: hotplug_key_b,
+            device: Arc::new(Mutex::new(MockDevice)),
+        };
+        let hotplug_command_b =
+            SignalHotPlugCommand::new(upstream_addr_b, [device_b].to_vec()).unwrap();
+        let port_b = new_port(bus_b);
+        // Port C: upstream 00:02.0, downstream 4.
+        let upstream_addr_c = PciAddress {
+            bus: 0,
+            dev: 2,
+            func: 0,
+        };
+        let bus_c = 4;
+        let downstream_addr_c = PciAddress {
+            bus: bus_c,
+            dev: 0,
+            func: 0,
+        };
+        let hotplug_key_c = HotPlugKey::GuestDevice {
+            guest_addr: downstream_addr_c,
+        };
+        let device_c = GuestDeviceStub {
+            pci_addr: downstream_addr_c,
+            key: hotplug_key_c,
+            device: Arc::new(Mutex::new(MockDevice)),
+        };
+        let hotplug_command_c =
+            SignalHotPlugCommand::new(upstream_addr_c, [device_c].to_vec()).unwrap();
+        let port_c = new_port(bus_c);
+        assert_eq!(
+            WorkerResponse::AddPortOk,
+            client
+                .send_worker_command(WorkerCommand::AddPort(
+                    upstream_addr_a,
+                    PortWorkerStub::new(port_a.clone(), bus_a).unwrap()
+                ))
+                .unwrap()
+        );
+        assert_eq!(
+            WorkerResponse::AddPortOk,
+            client
+                .send_worker_command(WorkerCommand::AddPort(
+                    upstream_addr_b,
+                    PortWorkerStub::new(port_b.clone(), bus_b).unwrap()
+                ))
+                .unwrap()
+        );
+        assert_eq!(
+            WorkerResponse::AddPortOk,
+            client
+                .send_worker_command(WorkerCommand::AddPort(
+                    upstream_addr_c,
+                    PortWorkerStub::new(port_c.clone(), bus_c).unwrap()
+                ))
+                .unwrap()
+        );
+        port_a.lock().signal_ready();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr_a))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Empty(0)),
+            Duration::from_millis(500)
+        ));
+        port_b.lock().signal_ready();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr_b))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Empty(0)),
+            Duration::from_millis(500)
+        ));
+        port_c.lock().signal_ready();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr_c))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Empty(0)),
+            Duration::from_millis(500)
+        ));
+        // All ports empty and in sync. Should get port B.
+        assert_eq!(
+            WorkerResponse::GetEmptyPortOk(upstream_addr_b),
+            client
+                .send_worker_command(WorkerCommand::GetEmptyPort)
+                .unwrap()
+        );
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotPlug(hotplug_command_b))
+                .unwrap()
+        );
+        // Should get port A.
+        assert_eq!(
+            WorkerResponse::GetEmptyPortOk(upstream_addr_a),
+            client
+                .send_worker_command(WorkerCommand::GetEmptyPort)
+                .unwrap()
+        );
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotPlug(hotplug_command_a))
+                .unwrap()
+        );
+        // Should get port C.
+        assert_eq!(
+            WorkerResponse::GetEmptyPortOk(upstream_addr_c),
+            client
+                .send_worker_command(WorkerCommand::GetEmptyPort)
+                .unwrap()
+        );
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotPlug(hotplug_command_c))
+                .unwrap()
+        );
+        // Should get an error since no port is empty.
+        if let WorkerResponse::InvalidCommand(_) = client
+            .send_worker_command(WorkerCommand::GetEmptyPort)
+            .unwrap()
+        {
+            // Assert result is of Error type.
+        } else {
+            unreachable!();
+        }
+        // Remove device from port A, immediately it should be available.
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotUnplug(upstream_addr_a))
+                .unwrap()
+        );
+        assert_eq!(
+            WorkerResponse::GetEmptyPortOk(upstream_addr_a),
+            client
+                .send_worker_command(WorkerCommand::GetEmptyPort)
+                .unwrap()
+        );
+        // Moreover, it should be 2 steps behind.
+        assert_eq!(
+            WorkerResponse::GetPortStateOk(PortState::Empty(2)),
+            client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr_a))
+                .unwrap()
+        );
     }
 
     #[test]
-    fn port_pool_pop_after_completion() {
-        let mut port_pool = PortPool::new();
-        let mock_port = new_mock_port_stub(PciAddress::new(0, 1, 0, 0).unwrap());
-        let (cc_sender, cc_recvr) = mpsc::channel();
-        port_pool
-            .insert_after_notification(mock_port, cc_recvr)
-            .unwrap();
-        cc_sender.send(()).unwrap();
-        let (_port_stub, port_availability) = port_pool.pop_first().unwrap();
-        assert!(matches!(port_availability, HotPlugAvailability::Now));
+    fn worker_port_state_transitions() {
+        let (rootbus_controller, _rootbus_recvr) = mpsc::channel();
+        let client = WorkerClient::new(rootbus_controller).unwrap();
+        let upstream_addr = PciAddress {
+            bus: 0,
+            dev: 1,
+            func: 1,
+        };
+        let bus = 2;
+        let downstream_addr = PciAddress {
+            bus,
+            dev: 0,
+            func: 0,
+        };
+        let hotplug_key = HotPlugKey::GuestDevice {
+            guest_addr: downstream_addr,
+        };
+        let device = GuestDeviceStub {
+            pci_addr: downstream_addr,
+            key: hotplug_key,
+            device: Arc::new(Mutex::new(MockDevice)),
+        };
+        let hotplug_command = SignalHotPlugCommand::new(upstream_addr, [device].to_vec()).unwrap();
+        let port = new_port(bus);
+        assert_eq!(
+            WorkerResponse::AddPortOk,
+            client
+                .send_worker_command(WorkerCommand::AddPort(
+                    upstream_addr,
+                    PortWorkerStub::new(port.clone(), bus).unwrap()
+                ))
+                .unwrap()
+        );
+        port.lock().signal_ready();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Empty(0)),
+            Duration::from_millis(500)
+        ));
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotPlug(hotplug_command.clone()))
+                .unwrap()
+        );
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Occupied(1)),
+            Duration::from_millis(500)
+        ));
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotUnplug(upstream_addr))
+                .unwrap()
+        );
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Empty(2)),
+            Duration::from_millis(500)
+        ));
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotPlug(hotplug_command.clone()))
+                .unwrap()
+        );
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Occupied(3)),
+            Duration::from_millis(500)
+        ));
+        port.lock().signal_cc();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Occupied(2)),
+            Duration::from_millis(500)
+        ));
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotUnplug(upstream_addr))
+                .unwrap()
+        );
+        // Moves from Occupied(2) to Empty(1) since it is redundant to unplug a device that is yet
+        // to be plugged in.
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Empty(1)),
+            Duration::from_millis(500)
+        ));
+        port.lock().signal_cc();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Empty(0)),
+            Duration::from_millis(500)
+        ));
     }
 
     #[test]
-    fn port_pool_pop_in_order() {
-        let mut port_pool = PortPool::new();
-        for bus_num in [2, 3, 4, 1, 0] {
-            let mock_port = new_mock_port_stub(PciAddress::new(0, bus_num, 0, 0).unwrap());
-            port_pool.insert(mock_port).unwrap();
-        }
-        for bus_num in 0..=4 {
-            assert_eq!(port_pool.pop_first().unwrap().0.pci_address.bus, bus_num);
-        }
+    fn worker_port_early_plug_state_transitions() {
+        let (rootbus_controller, _rootbus_recvr) = mpsc::channel();
+        let client = WorkerClient::new(rootbus_controller).unwrap();
+        let upstream_addr = PciAddress {
+            bus: 0,
+            dev: 1,
+            func: 1,
+        };
+        let bus = 2;
+        let downstream_addr = PciAddress {
+            bus,
+            dev: 0,
+            func: 0,
+        };
+        let hotplug_key = HotPlugKey::GuestDevice {
+            guest_addr: downstream_addr,
+        };
+        let device = GuestDeviceStub {
+            pci_addr: downstream_addr,
+            key: hotplug_key,
+            device: Arc::new(Mutex::new(MockDevice)),
+        };
+        let hotplug_command = SignalHotPlugCommand::new(upstream_addr, [device].to_vec()).unwrap();
+        let port = new_port(bus);
+        assert_eq!(
+            WorkerResponse::AddPortOk,
+            client
+                .send_worker_command(WorkerCommand::AddPort(
+                    upstream_addr,
+                    PortWorkerStub::new(port.clone(), bus).unwrap()
+                ))
+                .unwrap()
+        );
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::EmptyNotReady),
+            Duration::from_millis(500)
+        ));
+        assert_eq!(
+            WorkerResponse::SignalOk,
+            client
+                .send_worker_command(WorkerCommand::SignalHotPlug(hotplug_command.clone()))
+                .unwrap()
+        );
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::OccupiedNotReady),
+            Duration::from_millis(500)
+        ));
+        port.lock().signal_ready();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Occupied(1)),
+            Duration::from_millis(500)
+        ));
+        port.lock().signal_cc();
+        assert!(poll_until_with_timeout(
+            || client
+                .send_worker_command(WorkerCommand::GetPortState(upstream_addr))
+                .unwrap()
+                == WorkerResponse::GetPortStateOk(PortState::Occupied(0)),
+            Duration::from_millis(500)
+        ));
     }
 }
diff --git a/src/crosvm/sys/linux/vcpu.rs b/src/crosvm/sys/linux/vcpu.rs
index 5ae883526..80eff6838 100644
--- a/src/crosvm/sys/linux/vcpu.rs
+++ b/src/crosvm/sys/linux/vcpu.rs
@@ -5,6 +5,7 @@
 use std::cell::RefCell;
 use std::fs::File;
 use std::io::prelude::*;
+use std::process;
 use std::sync::mpsc;
 use std::sync::Arc;
 use std::sync::Barrier;
@@ -24,6 +25,7 @@ use arch::LinuxArch;
 use arch::VcpuArch;
 use arch::VcpuInitArch;
 use arch::VmArch;
+use base::gettid;
 use base::sched_attr;
 use base::sched_setattr;
 use base::signal::clear_signal_handler;
@@ -37,8 +39,11 @@ use hypervisor::IoParams;
 use hypervisor::VcpuExit;
 use hypervisor::VcpuSignalHandle;
 use libc::c_int;
+use metrics_events::MetricEventType;
 #[cfg(target_arch = "riscv64")]
 use riscv64::Riscv64 as Arch;
+use serde::Deserialize;
+use serde::Serialize;
 #[cfg(target_arch = "x86_64")]
 use sync::Mutex;
 use vm_control::*;
@@ -57,7 +62,6 @@ const SCHED_FLAG_KEEP_POLICY: u64 = 0x08;
 const SCHED_FLAG_KEEP_PARAMS: u64 = 0x10;
 const SCHED_FLAG_UTIL_CLAMP_MIN: u64 = 0x20;
 const SCHED_SCALE_CAPACITY: u32 = 1024;
-
 const SCHED_FLAG_KEEP_ALL: u64 = SCHED_FLAG_KEEP_POLICY | SCHED_FLAG_KEEP_PARAMS;
 
 fn bus_io_handler(bus: &Bus) -> impl FnMut(IoParams) -> Option<[u8; 8]> + '_ {
@@ -91,6 +95,7 @@ fn bus_io_handler(bus: &Bus) -> impl FnMut(IoParams) -> Option<[u8; 8]> + '_ {
 
 /// Set the VCPU thread affinity and other per-thread scheduler properties.
 /// This function will be called from each VCPU thread at startup.
+#[allow(clippy::unnecessary_cast)]
 pub fn set_vcpu_thread_scheduling(
     vcpu_affinity: CpuSet,
     core_scheduling: bool,
@@ -107,9 +112,9 @@ pub fn set_vcpu_thread_scheduling(
 
     if boost_uclamp {
         let mut sched_attr = sched_attr::default();
-        sched_attr.sched_flags = SCHED_FLAG_KEEP_ALL
+        sched_attr.sched_flags = SCHED_FLAG_KEEP_ALL as u64
             | SCHED_FLAG_UTIL_CLAMP_MIN
-            | SCHED_FLAG_RESET_ON_FORK;
+            | SCHED_FLAG_RESET_ON_FORK as u64;
         sched_attr.sched_util_min = SCHED_SCALE_CAPACITY;
 
         if let Err(e) = sched_setattr(0, &mut sched_attr, 0) {
@@ -191,7 +196,7 @@ where
     Ok(vcpu)
 }
 
-thread_local!(static VCPU_THREAD: RefCell<Option<VcpuSignalHandle>> = RefCell::new(None));
+thread_local!(static VCPU_THREAD: RefCell<Option<VcpuSignalHandle>> = const { RefCell::new(None) });
 
 fn set_vcpu_thread_local(vcpu: Option<&dyn VcpuArch>, signal_num: c_int) {
     // Block signal while we add -- if a signal fires (very unlikely,
@@ -399,7 +404,9 @@ where
                     }
                 }
                 Ok(VcpuExit::Mmio) => {
-                    if let Err(e) = vcpu.handle_mmio(&mut bus_io_handler(&mmio_bus)) {
+                    if let Err(e) =
+                        vcpu.handle_mmio(&mut |io_params| Ok(bus_io_handler(&mmio_bus)(io_params)))
+                    {
                         error!("failed to handle mmio: {}", e);
                     }
                 }
@@ -413,7 +420,15 @@ where
                 }
                 Ok(VcpuExit::IrqWindowOpen) => {}
                 Ok(VcpuExit::Hlt) => irq_chip.halted(cpu_id),
-                Ok(VcpuExit::Shutdown) => return ExitState::Stop,
+                Ok(VcpuExit::Shutdown(reason)) => {
+                    if let Err(e) = reason {
+                        metrics::log_descriptor(
+                            MetricEventType::VcpuShutdownError,
+                            e.get_raw_error_code() as i64,
+                        );
+                    }
+                    return ExitState::Stop;
+                }
                 Ok(VcpuExit::FailEntry {
                     hardware_entry_failure_reason,
                 }) => {
@@ -491,6 +506,13 @@ where
     }
 }
 
+#[derive(Serialize, Deserialize)]
+pub struct VcpuPidTid {
+    pub vcpu_id: usize,
+    pub process_id: u32,
+    pub thread_id: u32,
+}
+
 pub fn run_vcpu<V>(
     cpu_id: usize,
     vcpu_id: usize,
@@ -515,6 +537,7 @@ pub fn run_vcpu<V>(
     #[cfg(target_arch = "x86_64")] bus_lock_ratelimit_ctrl: Arc<Mutex<Ratelimit>>,
     run_mode: VmRunMode,
     boost_uclamp: bool,
+    vcpu_pid_tid_tube: mpsc::Sender<VcpuPidTid>,
 ) -> Result<JoinHandle<()>>
 where
     V: VcpuArch + 'static,
@@ -538,6 +561,15 @@ where
                     return ExitState::Stop;
                 }
 
+                if let Err(e) = vcpu_pid_tid_tube.send(VcpuPidTid {
+                    vcpu_id: cpu_id,
+                    process_id: process::id(),
+                    thread_id: gettid() as u32,
+                }) {
+                    error!("Failed to send vcpu process/thread id: {:#}", e);
+                    return ExitState::Crash;
+                }
+
                 #[cfg(feature = "gdb")]
                 let guest_mem = vm.get_memory().clone();
 
diff --git a/src/crosvm/sys/windows/broker.rs b/src/crosvm/sys/windows/broker.rs
index c5ba51821..96dee70e0 100644
--- a/src/crosvm/sys/windows/broker.rs
+++ b/src/crosvm/sys/windows/broker.rs
@@ -27,7 +27,6 @@ use anyhow::Context;
 use anyhow::Result;
 use base::enable_high_res_timers;
 use base::error;
-#[cfg(feature = "crash-report")]
 use base::generate_uuid;
 use base::info;
 use base::named_pipes;
@@ -72,6 +71,8 @@ use crosvm_cli::sys::windows::exit::ExitCodeWrapper;
 use crosvm_cli::sys::windows::exit::ExitContext;
 use crosvm_cli::sys::windows::exit::ExitContextAnyhow;
 #[cfg(feature = "audio")]
+use devices::virtio::gpu::AudioDeviceMode;
+#[cfg(feature = "audio")]
 use devices::virtio::snd::parameters::Parameters as SndParameters;
 #[cfg(feature = "gpu")]
 use devices::virtio::vhost::user::device::gpu::sys::windows::GpuBackendConfig;
@@ -595,7 +596,8 @@ fn run_internal(mut cfg: Config, log_args: LogArgs) -> Result<()> {
         false,
         /* use_sandbox= */
         cfg.jail_config.is_some(),
-        Vec::new(),
+        vec![],
+        &[],
         &cfg,
     )?;
     metrics_controller
@@ -616,7 +618,8 @@ fn run_internal(mut cfg: Config, log_args: LogArgs) -> Result<()> {
         false,
         /* use_sandbox= */
         cfg.jail_config.is_some(),
-        Vec::new(),
+        vec![],
+        &[],
         &cfg,
     )?;
 
@@ -647,7 +650,28 @@ fn run_internal(mut cfg: Config, log_args: LogArgs) -> Result<()> {
     )?;
 
     #[cfg(feature = "audio")]
-    let snd_cfg = platform_create_snd(&cfg, &mut main_child, &mut exit_events)?;
+    let num_audio_devices = if let Some(gpu_params) = cfg.gpu_parameters.as_ref() {
+        match gpu_params.audio_device_mode {
+            AudioDeviceMode::PerSurface => gpu_params.max_num_displays,
+            AudioDeviceMode::OneGlobal => 1,
+        }
+    } else {
+        1
+    };
+
+    #[cfg(feature = "audio")]
+    let mut snd_cfgs = Vec::new();
+    #[cfg(feature = "audio")]
+    {
+        for card_index in 0..num_audio_devices {
+            snd_cfgs.push(platform_create_snd(
+                &cfg,
+                card_index as usize,
+                &mut main_child,
+                &mut exit_events,
+            )?);
+        }
+    }
 
     #[cfg(feature = "audio")]
     let _snd_child = if !cfg
@@ -656,14 +680,13 @@ fn run_internal(mut cfg: Config, log_args: LogArgs) -> Result<()> {
         .any(|opt| opt.type_ == DeviceType::Sound)
     {
         // Pass both backend and frontend configs to main process.
-        cfg.snd_split_config = Some(snd_cfg);
+        cfg.snd_split_configs = snd_cfgs;
         None
     } else {
         Some(start_up_snd(
             &mut cfg,
             &log_args,
-            snd_cfg,
-            &mut main_child,
+            snd_cfgs,
             &mut children,
             &mut wait_ctx,
             &mut metric_tubes,
@@ -836,7 +859,7 @@ fn clean_up_metrics(metrics_child: ChildCleanup) -> Result<()> {
     let mut metrics_timeout =
         Timer::new().exit_context(Exit::CreateTimer, "failed to create metrics timeout timer")?;
     metrics_timeout
-        .reset(EXIT_TIMEOUT, None)
+        .reset_oneshot(EXIT_TIMEOUT)
         .exit_context(Exit::ResetTimer, "failed to reset timer")?;
     metrics_cleanup_wait.add(&metrics_timeout, 0).exit_context(
         Exit::WaitContextAdd,
@@ -977,7 +1000,7 @@ impl Supervisor {
         }
 
         let mut et = Timer::new().exit_context(Exit::CreateTimer, "failed to create timer")?;
-        et.reset(EXIT_TIMEOUT, None)
+        et.reset_oneshot(EXIT_TIMEOUT)
             .exit_context(Exit::ResetTimer, "failed to reset timer")?;
         self.wait_ctx.add(&et, timeout_token).exit_context(
             Exit::WaitContextAdd,
@@ -1258,6 +1281,7 @@ fn spawn_block_backend(
                 tube_token: TubeToken::VhostUser,
             },
         ],
+        &[],
         cfg,
     )?;
 
@@ -1503,6 +1527,7 @@ fn spawn_slirp(
         false,
         /* use_sandbox= */ cfg.jail_config.is_some(),
         vec![],
+        &[],
         cfg,
     )?;
 
@@ -1541,6 +1566,7 @@ fn spawn_net_backend(
             tube: vhost_user_device_tube,
             tube_token: TubeToken::VhostUser,
         }],
+        &[],
         cfg,
     )?;
 
@@ -1559,6 +1585,7 @@ fn spawn_net_backend(
 #[cfg(feature = "audio")]
 fn platform_create_snd(
     cfg: &Config,
+    card_index: usize,
     main_child: &mut ChildProcess,
     exit_events: &mut Vec<Event>,
 ) -> Result<SndSplitConfig> {
@@ -1569,8 +1596,13 @@ fn platform_create_snd(
             .exit_context(Exit::CloneEvent, "failed to clone event")?,
     );
 
-    let (backend_config_product, vmm_config_product) =
-        get_snd_product_configs(cfg, main_child.alias_pid)?;
+    let (mut main_vhost_user_tube, mut device_vhost_user_tube) =
+        Tube::pair().exit_context(Exit::CreateTube, "failed to create tube")?;
+    // Start off the vhost-user tube assuming it is in the main process.
+    main_vhost_user_tube.set_target_pid(main_child.alias_pid);
+    device_vhost_user_tube.set_target_pid(main_child.alias_pid);
+
+    let (backend_config_product, vmm_config_product) = get_snd_product_configs()?;
 
     let parameters = SndParameters {
         backend: "winaudio".try_into().unwrap(),
@@ -1579,16 +1611,22 @@ fn platform_create_snd(
         ..Default::default()
     };
 
+    let audio_client_guid = generate_uuid();
+
     let backend_config = Some(SndBackendConfig {
-        device_vhost_user_tube: None,
+        device_vhost_user_tube: Some(device_vhost_user_tube),
         exit_event,
         parameters,
         product_config: backend_config_product,
+        audio_client_guid: audio_client_guid.clone(),
+        card_index,
     });
 
     let vmm_config = Some(SndVmmConfig {
-        main_vhost_user_tube: None,
+        main_vhost_user_tube: Some(main_vhost_user_tube),
         product_config: vmm_config_product,
+        audio_client_guid,
+        card_index,
     });
 
     Ok(SndSplitConfig {
@@ -1598,26 +1636,27 @@ fn platform_create_snd(
 }
 
 /// Returns a snd child process for vhost-user sound.
+// TODO(b/292128227): This method is deprecated and is not used downstream. The following code
+// has not been converted to handle multiple devices. We don't want multiple snd backend processes
+// being spun up anyways.
 #[cfg(feature = "audio")]
 fn start_up_snd(
     cfg: &mut Config,
     log_args: &LogArgs,
-    mut snd_cfg: SndSplitConfig,
-    main_child: &mut ChildProcess,
+    mut snd_cfgs: Vec<SndSplitConfig>,
     children: &mut HashMap<u32, ChildCleanup>,
     wait_ctx: &mut WaitContext<Token>,
     metric_tubes: &mut Vec<RecvTube>,
     #[cfg(feature = "process-invariants")] process_invariants: &EmulatorProcessInvariants,
 ) -> Result<ChildProcess> {
     // Extract the backend config from the sound config, so it can run elsewhere.
-    let mut backend_cfg = snd_cfg
+    // TODO(b/292128227): Clean up when upstreamed.
+    let mut snd_cfg = snd_cfgs.swap_remove(0);
+    let backend_cfg = snd_cfg
         .backend_config
         .take()
         .expect("snd backend config must be set");
 
-    let (mut main_vhost_user_tube, mut device_host_user_tube) =
-        Tube::pair().exit_context(Exit::CreateTube, "failed to create tube")?;
-
     let snd_child = spawn_child(
         current_exe().unwrap().to_str().unwrap(),
         ["device", "snd"],
@@ -1632,6 +1671,7 @@ fn start_up_snd(
         /* use_sandbox= */
         cfg.jail_config.is_some(),
         vec![],
+        &[],
         cfg,
     )?;
 
@@ -1641,17 +1681,14 @@ fn start_up_snd(
         .exit_context(Exit::TubeTransporterInit, "failed to initialize tube")?;
 
     // Update target PIDs to new child.
-    device_host_user_tube.set_target_pid(main_child.alias_pid);
-    main_vhost_user_tube.set_target_pid(snd_child.alias_pid);
-
-    // Insert vhost-user tube to backend / frontend configs.
-    backend_cfg.device_vhost_user_tube = Some(device_host_user_tube);
     if let Some(vmm_config) = snd_cfg.vmm_config.as_mut() {
-        vmm_config.main_vhost_user_tube = Some(main_vhost_user_tube);
+        if let Some(tube) = vmm_config.main_vhost_user_tube.as_mut() {
+            tube.set_target_pid(snd_child.alias_pid);
+        }
     }
 
     // Send VMM config to main process.
-    cfg.snd_split_config = Some(snd_cfg);
+    cfg.snd_split_configs = snd_cfgs;
 
     let startup_args = CommonChildStartupArgs::new(
         log_args,
@@ -1722,6 +1759,9 @@ fn platform_create_window_procedure_thread_configs(
     main_alias_pid: u32,
     device_alias_pid: u32,
 ) -> Result<WindowProcedureThreadSplitConfig> {
+    if let Some(params) = cfg.gpu_parameters.as_ref() {
+        wndproc_thread_builder.set_max_num_windows(params.max_num_displays);
+    }
     let product_config = get_window_procedure_thread_product_configs(
         cfg,
         &mut wndproc_thread_builder,
@@ -1819,6 +1859,7 @@ fn start_up_gpu(
         /* use_sandbox= */
         cfg.jail_config.is_some(),
         vec![],
+        &[],
         cfg,
     )?;
 
@@ -1893,6 +1934,7 @@ fn spawn_child<I, S>(
     #[cfg(test)] skip_bootstrap: bool,
     use_sandbox: bool,
     mut tubes: Vec<TubeTransferData>,
+    handles_to_inherit: &[&dyn AsRawDescriptor],
     #[allow(unused_variables)] cfg: &Config,
 ) -> Result<ChildProcess>
 where
@@ -1934,27 +1976,23 @@ where
         None
     };
 
-    #[cfg(test)]
-    let bootstrap = if !skip_bootstrap {
-        vec![
-            "--bootstrap".to_string(),
-            (tube_transport_main_child.as_raw_descriptor() as usize).to_string(),
-        ]
-    } else {
-        vec![]
-    };
-    #[cfg(not(test))]
-    let bootstrap = vec![
+    let bootstrap = [
         "--bootstrap".to_string(),
         (tube_transport_main_child.as_raw_descriptor() as usize).to_string(),
     ];
 
+    #[cfg(test)]
+    let bootstrap: &[String] = if skip_bootstrap { &[] } else { &bootstrap };
+
     let input_args: Vec<S> = args.into_iter().collect();
     let args = input_args
         .iter()
         .map(|arg| arg.as_ref())
         .chain(bootstrap.iter().map(|arg| arg.as_ref()));
 
+    let mut handles_to_inherit = handles_to_inherit.to_vec();
+    handles_to_inherit.push(&tube_transport_main_child);
+
     #[cfg(feature = "sandbox")]
     let (process_id, child) = if use_sandbox {
         spawn_sandboxed_child(
@@ -1962,26 +2000,15 @@ where
             args,
             stdout_file,
             stderr_file,
-            vec![&tube_transport_main_child],
+            handles_to_inherit,
             process_policy(process_type, cfg),
         )?
     } else {
-        spawn_unsandboxed_child(
-            program,
-            args,
-            stdout_file,
-            stderr_file,
-            vec![&tube_transport_main_child],
-        )?
+        spawn_unsandboxed_child(program, args, stdout_file, stderr_file, handles_to_inherit)?
     };
     #[cfg(not(feature = "sandbox"))]
-    let (process_id, child) = spawn_unsandboxed_child(
-        program,
-        args,
-        stdout_file,
-        stderr_file,
-        vec![&tube_transport_main_child],
-    )?;
+    let (process_id, child) =
+        spawn_unsandboxed_child(program, args, stdout_file, stderr_file, handles_to_inherit)?;
 
     let (mut bootstrap_tube, bootstrap_tube_child) =
         Tube::pair().exit_context(Exit::CreateTube, "failed to create tube")?;
@@ -2070,7 +2097,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
 
@@ -2098,7 +2126,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
             let _child_device = spawn_child(
@@ -2111,7 +2140,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
 
@@ -2138,7 +2168,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
             let _child_device = spawn_child(
@@ -2151,7 +2182,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
 
@@ -2183,7 +2215,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
             let _child_device = spawn_child(
@@ -2196,7 +2229,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
 
@@ -2228,7 +2262,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
             let _child_device = spawn_child(
@@ -2241,7 +2276,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
 
@@ -2276,7 +2312,8 @@ mod tests {
                 &mut wait_ctx,
                 /* skip_bootstrap= */ true,
                 /* use_sandbox= */ false,
-                Vec::new(),
+                vec![],
+                &[],
                 &Config::default(),
             );
             wait_ctx.add(&sigterm_event, Token::Sigterm).unwrap();
diff --git a/src/crosvm/sys/windows/stats.rs b/src/crosvm/sys/windows/stats.rs
index 44b2a49b2..5e7da8eaa 100644
--- a/src/crosvm/sys/windows/stats.rs
+++ b/src/crosvm/sys/windows/stats.rs
@@ -147,7 +147,7 @@ fn exit_to_index(exit: &base::Result<VcpuExit>) -> usize {
         Ok(VcpuExit::IoapicEoi { .. }) => 2,
         Ok(VcpuExit::IrqWindowOpen) => 3,
         Ok(VcpuExit::Hlt) => 4,
-        Ok(VcpuExit::Shutdown) => 5,
+        Ok(VcpuExit::Shutdown(_)) => 5,
         Ok(VcpuExit::FailEntry { .. }) => 6,
         Ok(VcpuExit::SystemEventShutdown) => 7,
         Ok(VcpuExit::SystemEventReset) => 7,
diff --git a/src/main.rs b/src/main.rs
index 93ae51bc6..7e4f2af88 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -37,10 +37,12 @@ use devices::virtio::vhost::user::device::run_snd_device;
 #[cfg(feature = "composite-disk")]
 use disk::create_composite_disk;
 #[cfg(feature = "composite-disk")]
-use disk::create_disk_file;
-#[cfg(feature = "composite-disk")]
 use disk::create_zero_filler;
 #[cfg(feature = "composite-disk")]
+use disk::open_disk_file;
+#[cfg(any(feature = "composite-disk", feature = "qcow"))]
+use disk::DiskFileParams;
+#[cfg(feature = "composite-disk")]
 use disk::ImagePartitionType;
 #[cfg(feature = "composite-disk")]
 use disk::PartitionInfo;
@@ -52,6 +54,8 @@ use crosvm::cmdline::CrossPlatformCommands;
 use crosvm::cmdline::CrossPlatformDevicesCommands;
 #[cfg(windows)]
 use sys::windows::setup_metrics_reporting;
+#[cfg(feature = "composite-disk")]
+use uuid::Uuid;
 #[cfg(feature = "gpu")]
 use vm_control::client::do_gpu_display_add;
 #[cfg(feature = "gpu")]
@@ -170,6 +174,12 @@ fn run_vm(cmd: RunCommand, log_config: LogConfig) -> Result<CommandStatus> {
 
     init_log(log_config, &cfg)?;
     cros_tracing::init();
+
+    if let Some(async_executor) = cfg.async_executor {
+        cros_async::Executor::set_default_executor_kind(async_executor)
+            .context("Failed to set the default async executor")?;
+    }
+
     let exit_state = crate::sys::run_config(cfg)?;
     Ok(CommandStatus::from(exit_state))
 }
@@ -224,7 +234,13 @@ fn sleepbtn_vms(cmd: cmdline::SleepCommand) -> std::result::Result<(), ()> {
 }
 
 fn inject_gpe(cmd: cmdline::GpeCommand) -> std::result::Result<(), ()> {
-    vms_request(&VmRequest::Gpe(cmd.gpe), cmd.socket_path)
+    vms_request(
+        &VmRequest::Gpe {
+            gpe: cmd.gpe,
+            clear_evt: None,
+        },
+        cmd.socket_path,
+    )
 }
 
 #[cfg(feature = "balloon")]
@@ -338,20 +354,35 @@ fn modify_virtio_net(cmd: cmdline::VirtioNetCommand) -> std::result::Result<(),
 #[cfg(feature = "composite-disk")]
 fn parse_composite_partition_arg(
     partition_arg: &str,
-) -> std::result::Result<(String, String, bool), ()> {
+) -> std::result::Result<(String, String, bool, Option<Uuid>), ()> {
     let mut partition_fields = partition_arg.split(":");
 
     let label = partition_fields.next();
     let path = partition_fields.next();
     let opt = partition_fields.next();
+    let part_guid = partition_fields.next();
 
     if let (Some(label), Some(path)) = (label, path) {
         // By default, composite disk is read-only
         let writable = match opt {
             None => false,
-            Some(opt) => opt.contains("writable"),
+            Some("") => false,
+            Some("writable") => true,
+            Some(value) => {
+                error!(
+                    "Unrecognized option '{}'. Expected 'writable' or nothing.",
+                    value
+                );
+                return Err(());
+            }
         };
-        Ok((label.to_owned(), path.to_owned(), writable))
+
+        let part_guid = part_guid
+            .map(Uuid::parse_str)
+            .transpose()
+            .map_err(|e| error!("Invalid partition GUID: {}", e))?;
+
+        Ok((label.to_owned(), path.to_owned(), writable, part_guid))
     } else {
         error!(
             "Must specify label and path for partition '{}', like LABEL:PARTITION",
@@ -363,7 +394,6 @@ fn parse_composite_partition_arg(
 
 #[cfg(feature = "composite-disk")]
 fn create_composite(cmd: cmdline::CreateCompositeCommand) -> std::result::Result<(), ()> {
-    use std::fs::File;
     use std::path::PathBuf;
 
     let composite_image_path = &cmd.path;
@@ -418,19 +448,19 @@ fn create_composite(cmd: cmdline::CreateCompositeCommand) -> std::result::Result
         .partitions
         .into_iter()
         .map(|partition_arg| {
-            let (label, path, writable) = parse_composite_partition_arg(&partition_arg)?;
-
-            let partition_file =
-                File::open(&path).map_err(|e| error!("Failed to open partition image: {}", e))?;
+            let (label, path, writable, part_guid) = parse_composite_partition_arg(&partition_arg)?;
 
             // Sparseness for composite disks is not user provided on Linux
             // (e.g. via an option), and it has no runtime effect.
-            let size = create_disk_file(
-                partition_file,
-                /* is_sparse_file= */ true,
-                disk::MAX_NESTING_DEPTH,
-                Path::new(&path),
-            )
+            let size = open_disk_file(DiskFileParams {
+                path: PathBuf::from(&path),
+                is_read_only: !writable,
+                is_sparse_file: true,
+                is_overlapped: false,
+                is_direct: false,
+                lock: true,
+                depth: 0,
+            })
             .map_err(|e| error!("Failed to create DiskFile instance: {}", e))?
             .get_len()
             .map_err(|e| error!("Failed to get length of partition image: {}", e))?;
@@ -441,6 +471,7 @@ fn create_composite(cmd: cmdline::CreateCompositeCommand) -> std::result::Result
                 partition_type: ImagePartitionType::LinuxFilesystem,
                 writable,
                 size,
+                part_guid,
             })
         })
         .collect::<Result<Vec<PartitionInfo>, ()>>()?;
@@ -466,6 +497,8 @@ fn create_composite(cmd: cmdline::CreateCompositeCommand) -> std::result::Result
 
 #[cfg(feature = "qcow")]
 fn create_qcow2(cmd: cmdline::CreateQcow2Command) -> std::result::Result<(), ()> {
+    use std::path::PathBuf;
+
     if !(cmd.size.is_some() ^ cmd.backing_file.is_some()) {
         println!(
             "Create a new QCOW2 image at `PATH` of either the specified `SIZE` in bytes or
@@ -484,17 +517,23 @@ fn create_qcow2(cmd: cmdline::CreateQcow2Command) -> std::result::Result<(), ()>
             error!("Failed opening qcow file at '{}': {}", cmd.file_path, e);
         })?;
 
+    let params = DiskFileParams {
+        path: PathBuf::from(&cmd.file_path),
+        is_read_only: false,
+        is_sparse_file: false,
+        is_overlapped: false,
+        is_direct: false,
+        lock: true,
+        depth: 0,
+    };
     match (cmd.size, cmd.backing_file) {
-        (Some(size), None) => QcowFile::new(file, size).map_err(|e| {
+        (Some(size), None) => QcowFile::new(file, params, size).map_err(|e| {
             error!("Failed to create qcow file at '{}': {}", cmd.file_path, e);
         })?,
-        (None, Some(backing_file)) => {
-            QcowFile::new_from_backing(file, &backing_file, disk::MAX_NESTING_DEPTH).map_err(
-                |e| {
-                    error!("Failed to create qcow file at '{}': {}", cmd.file_path, e);
-                },
-            )?
-        }
+        (None, Some(backing_file)) => QcowFile::new_from_backing(file, params, &backing_file)
+            .map_err(|e| {
+                error!("Failed to create qcow file at '{}': {}", cmd.file_path, e);
+            })?,
         _ => unreachable!(),
     };
     Ok(())
@@ -669,11 +708,6 @@ fn prepare_argh_args<I: IntoIterator<Item = String>>(args_iter: I) -> Vec<String
                 eprintln!("Please use `--host-ip` instead");
                 args.push("--host-ip".to_string());
             }
-            "--balloon_bias_mib" => {
-                eprintln!("`--balloon_bias_mib` option is deprecated!");
-                eprintln!("Please use `--balloon-bias-mib` instead");
-                args.push("--balloon-bias-mib".to_string());
-            }
             "-h" => args.push("--help".to_string()),
             arg if is_flag(arg) => {
                 // Split `--arg=val` into `--arg val`, since argh doesn't support the former.
@@ -757,7 +791,7 @@ fn crosvm_main<I: IntoIterator<Item = String>>(args: I) -> Result<CommandStatus>
                          `crosvm --syslog-tag=\"{}\" run` instead",
                         syslog_tag
                     );
-                    log_config.log_args.proc_name = syslog_tag.clone();
+                    log_config.log_args.proc_name.clone_from(syslog_tag);
                 }
                 // We handle run_vm separately because it does not simply signal success/error
                 // but also indicates whether the guest requested reset or stop.
@@ -936,16 +970,6 @@ mod tests {
         );
     }
 
-    #[test]
-    fn args_balloon_bias_mib() {
-        assert_eq!(
-            prepare_argh_args(
-                ["crosvm", "run", "--balloon_bias_mib", "1234", "vm_kernel"].map(|x| x.to_string())
-            ),
-            ["crosvm", "run", "--balloon-bias-mib", "1234", "vm_kernel"]
-        );
-    }
-
     #[test]
     fn args_h() {
         assert_eq!(
@@ -1007,7 +1031,8 @@ mod tests {
             Ok((
                 String::from("LABEL1"),
                 String::from("/partition1.img"),
-                true
+                true,
+                None
             ))
         );
 
@@ -1018,9 +1043,41 @@ mod tests {
             Ok((
                 String::from("LABEL2"),
                 String::from("/partition2.img"),
-                false
+                false,
+                None
+            ))
+        );
+
+        let arg3 =
+            String::from("LABEL3:/partition3.img:writable:4049C8DC-6C2B-C740-A95A-BDAA629D4378");
+        let res3 = parse_composite_partition_arg(&arg3);
+        assert_eq!(
+            res3,
+            Ok((
+                String::from("LABEL3"),
+                String::from("/partition3.img"),
+                true,
+                Some(Uuid::from_u128(0x4049C8DC_6C2B_C740_A95A_BDAA629D4378))
+            ))
+        );
+
+        // third argument is an empty string. writable: false.
+        let arg4 = String::from("LABEL4:/partition4.img::4049C8DC-6C2B-C740-A95A-BDAA629D4378");
+        let res4 = parse_composite_partition_arg(&arg4);
+        assert_eq!(
+            res4,
+            Ok((
+                String::from("LABEL4"),
+                String::from("/partition4.img"),
+                false,
+                Some(Uuid::from_u128(0x4049C8DC_6C2B_C740_A95A_BDAA629D4378))
             ))
         );
+
+        // third argument is not "writable" or an empty string
+        let arg5 = String::from("LABEL5:/partition5.img:4049C8DC-6C2B-C740-A95A-BDAA629D4378");
+        let res5 = parse_composite_partition_arg(&arg5);
+        assert_eq!(res5, Err(()));
     }
 
     #[test]
diff --git a/src/sys/windows.rs b/src/sys/windows.rs
index a42644bf9..6eb817700 100644
--- a/src/sys/windows.rs
+++ b/src/sys/windows.rs
@@ -110,14 +110,17 @@ use devices::virtio::vhost::user::gpu::sys::windows::product::GpuBackendConfig a
 use devices::virtio::vhost::user::gpu::sys::windows::run_gpu_device_worker;
 #[cfg(feature = "audio")]
 use devices::virtio::vhost::user::snd::sys::windows::product::SndBackendConfig as SndBackendConfigProduct;
+#[cfg(feature = "audio")]
+use devices::virtio::vhost::user::snd::sys::windows::run_snd_device_worker;
+#[cfg(feature = "audio")]
+use devices::virtio::vhost::user::snd::sys::windows::SndSplitConfig;
 #[cfg(feature = "balloon")]
 use devices::virtio::BalloonFeatures;
-#[cfg(feature = "balloon")]
-use devices::virtio::BalloonMode;
 use devices::virtio::Console;
 #[cfg(feature = "gpu")]
 use devices::virtio::GpuParameters;
 use devices::BusDeviceObj;
+use devices::BusResumeDevice;
 #[cfg(feature = "gvm")]
 use devices::GvmIrqChip;
 #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
@@ -173,6 +176,7 @@ pub(crate) use panic_hook::set_panic_hook;
 use product::create_snd_mute_tube_pair;
 #[cfg(any(feature = "haxm", feature = "gvm", feature = "whpx"))]
 use product::create_snd_state_tube;
+#[cfg(feature = "pvclock")]
 use product::handle_pvclock_request;
 use product::merge_session_invariants;
 use product::run_ime_thread;
@@ -197,6 +201,7 @@ use vm_control::BalloonControlCommand;
 #[cfg(feature = "balloon")]
 use vm_control::BalloonTube;
 use vm_control::DeviceControlCommand;
+use vm_control::InitialAudioSessionState;
 use vm_control::IrqHandlerRequest;
 use vm_control::PvClockCommand;
 use vm_control::VcpuControl;
@@ -207,15 +212,13 @@ use vm_control::VmResponse;
 use vm_control::VmRunMode;
 use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
+use vmm_vhost::Connection;
+use vmm_vhost::FrontendReq;
 use win_util::ProcessType;
 #[cfg(feature = "whpx")]
 use x86_64::cpuid::adjust_cpuid;
 #[cfg(feature = "whpx")]
 use x86_64::cpuid::CpuIdContext;
-#[cfg(all(target_arch = "x86_64", feature = "haxm"))]
-use x86_64::get_cpu_manufacturer;
-#[cfg(all(target_arch = "x86_64", feature = "haxm"))]
-use x86_64::CpuManufacturer;
 #[cfg(target_arch = "x86_64")]
 use x86_64::X8664arch as Arch;
 
@@ -285,11 +288,14 @@ pub enum ExitState {
 
 type DeviceResult<T = VirtioDeviceStub> = Result<T>;
 
-fn create_vhost_user_block_device(cfg: &Config, disk_device_tube: Tube) -> DeviceResult {
+fn create_vhost_user_block_device(
+    cfg: &Config,
+    connection: Connection<FrontendReq>,
+) -> DeviceResult {
     let dev = virtio::VhostUserFrontend::new(
         virtio::DeviceType::Block,
         virtio::base_features(cfg.protection_type),
-        disk_device_tube,
+        connection,
         None,
         None,
     )
@@ -323,11 +329,14 @@ fn create_block_device(cfg: &Config, disk: &DiskOption, disk_device_tube: Tube)
 }
 
 #[cfg(feature = "gpu")]
-fn create_vhost_user_gpu_device(base_features: u64, vhost_user_tube: Tube) -> DeviceResult {
+fn create_vhost_user_gpu_device(
+    base_features: u64,
+    connection: Connection<FrontendReq>,
+) -> DeviceResult {
     let dev = virtio::VhostUserFrontend::new(
         virtio::DeviceType::Gpu,
         base_features,
-        vhost_user_tube,
+        connection,
         None,
         None,
     )
@@ -343,27 +352,14 @@ fn create_vhost_user_gpu_device(base_features: u64, vhost_user_tube: Tube) -> De
 }
 
 #[cfg(feature = "audio")]
-fn create_snd_device(
-    cfg: &Config,
-    parameters: SndParameters,
-    _product_args: SndBackendConfigProduct,
+fn create_vhost_user_snd_device(
+    base_features: u64,
+    connection: Connection<FrontendReq>,
 ) -> DeviceResult {
-    let features = virtio::base_features(cfg.protection_type);
-    let dev = VirtioSnd::new(features, parameters)
-        .exit_context(Exit::VirtioSoundDeviceNew, "failed to create snd device")?;
-
-    Ok(VirtioDeviceStub {
-        dev: Box::new(dev),
-        jail: None,
-    })
-}
-
-#[cfg(feature = "audio")]
-fn create_vhost_user_snd_device(base_features: u64, vhost_user_tube: Tube) -> DeviceResult {
     let dev = virtio::VhostUserFrontend::new(
         virtio::DeviceType::Sound,
         base_features,
-        vhost_user_tube,
+        connection,
         None,
         None,
     )
@@ -413,19 +409,14 @@ fn create_mouse_device(cfg: &Config, event_pipe: StreamChannel, idx: u32) -> Dev
 }
 
 #[cfg(feature = "slirp")]
-fn create_vhost_user_net_device(cfg: &Config, net_device_tube: Tube) -> DeviceResult {
+fn create_vhost_user_net_device(cfg: &Config, connection: Connection<FrontendReq>) -> DeviceResult {
     let features = virtio::base_features(cfg.protection_type);
-    let dev = virtio::VhostUserFrontend::new(
-        virtio::DeviceType::Net,
-        features,
-        net_device_tube,
-        None,
-        None,
-    )
-    .exit_context(
-        Exit::VhostUserNetDeviceNew,
-        "failed to set up vhost-user net device",
-    )?;
+    let dev =
+        virtio::VhostUserFrontend::new(virtio::DeviceType::Net, features, connection, None, None)
+            .exit_context(
+            Exit::VhostUserNetDeviceNew,
+            "failed to set up vhost-user net device",
+        )?;
 
     Ok(VirtioDeviceStub {
         dev: Box::new(dev),
@@ -472,11 +463,6 @@ fn create_balloon_device(
         VmMemoryClient::new(dynamic_mapping_device_tube),
         inflate_tube,
         init_balloon_size,
-        if cfg.strict_balloon {
-            BalloonMode::Strict
-        } else {
-            BalloonMode::Relaxed
-        },
         balloon_features,
         #[cfg(feature = "registered_events")]
         None,
@@ -517,8 +503,9 @@ fn create_virtio_devices(
     vm_evt_wrtube: &SendTube,
     #[allow(clippy::ptr_arg)] control_tubes: &mut Vec<TaggedControlTube>,
     disk_device_tubes: &mut Vec<Tube>,
+    initial_audio_session_states: &mut Vec<InitialAudioSessionState>,
     balloon_device_tube: Option<Tube>,
-    pvclock_device_tube: Option<Tube>,
+    #[cfg(feature = "pvclock")] pvclock_device_tube: Option<Tube>,
     dynamic_mapping_device_tube: Option<Tube>,
     inflate_tube: Option<Tube>,
     init_balloon_size: u64,
@@ -539,7 +526,8 @@ fn create_virtio_devices(
         info!("Starting up vhost user block backends...");
         for _disk in &cfg.disks {
             let disk_device_tube = cfg.block_vhost_user_tube.remove(0);
-            devs.push(create_vhost_user_block_device(cfg, disk_device_tube)?);
+            let connection = Connection::<FrontendReq>::from(disk_device_tube);
+            devs.push(create_vhost_user_block_device(cfg, connection)?);
         }
     }
 
@@ -553,39 +541,25 @@ fn create_virtio_devices(
     }
 
     #[cfg(feature = "audio")]
-    if product::virtio_sound_enabled() {
-        let snd_split_config = cfg
-            .snd_split_config
-            .as_mut()
-            .expect("snd_split_config must exist");
-        let snd_vmm_config = snd_split_config
-            .vmm_config
-            .as_mut()
-            .expect("snd_vmm_config must exist");
-        product::push_snd_control_tubes(control_tubes, snd_vmm_config);
-
-        match snd_split_config.backend_config.take() {
-            None => {
-                // No backend config present means the backend is running in another process.
-                devs.push(create_vhost_user_snd_device(
-                    virtio::base_features(cfg.protection_type),
-                    snd_vmm_config
-                        .main_vhost_user_tube
-                        .take()
-                        .expect("Snd VMM vhost-user tube should be set"),
-                )?);
-            }
-            Some(backend_config) => {
-                // Backend config present, so initialize Snd in this process.
-                devs.push(create_snd_device(
-                    cfg,
-                    backend_config.parameters,
-                    backend_config.product_config,
-                )?);
+    {
+        let snd_split_configs = std::mem::take(&mut cfg.snd_split_configs);
+        for mut snd_split_cfg in snd_split_configs.into_iter() {
+            devs.push(create_virtio_snd_device(
+                cfg,
+                &mut snd_split_cfg,
+                control_tubes,
+            )?);
+            if let Some(vmm_config) = snd_split_cfg.vmm_config {
+                let initial_audio_session_state = InitialAudioSessionState {
+                    audio_client_guid: vmm_config.audio_client_guid,
+                    card_index: vmm_config.card_index,
+                };
+                initial_audio_session_states.push(initial_audio_session_state);
             }
         }
     }
 
+    #[cfg(feature = "pvclock")]
     if let Some(tube) = pvclock_device_tube {
         product::push_pvclock_device(cfg, &mut devs, tsc_frequency, tube);
     }
@@ -594,7 +568,8 @@ fn create_virtio_devices(
 
     #[cfg(feature = "slirp")]
     if let Some(net_vhost_user_tube) = cfg.net_vhost_user_tube.take() {
-        devs.push(create_vhost_user_net_device(cfg, net_vhost_user_tube)?);
+        let connection = Connection::<FrontendReq>::from(net_vhost_user_tube);
+        devs.push(create_vhost_user_net_device(cfg, connection)?);
     }
 
     #[cfg(feature = "balloon")]
@@ -764,14 +739,42 @@ fn create_virtio_gpu_device(
     }
 
     // The GPU is always vhost-user, even if running in the main process.
-    create_vhost_user_gpu_device(
-        virtio::base_features(cfg.protection_type),
-        gpu_vmm_config
-            .main_vhost_user_tube
-            .take()
-            .expect("GPU VMM vhost-user tube should be set"),
-    )
-    .context("create vhost-user GPU device")
+    let gpu_device_tube = gpu_vmm_config
+        .main_vhost_user_tube
+        .take()
+        .expect("GPU VMM vhost-user tube should be set");
+    let connection = Connection::<FrontendReq>::from(gpu_device_tube);
+
+    create_vhost_user_gpu_device(virtio::base_features(cfg.protection_type), connection)
+        .context("create vhost-user GPU device")
+}
+
+#[cfg(feature = "audio")]
+fn create_virtio_snd_device(
+    cfg: &mut Config,
+    snd_split_config: &mut SndSplitConfig,
+    #[allow(clippy::ptr_arg)] control_tubes: &mut Vec<TaggedControlTube>,
+) -> DeviceResult<VirtioDeviceStub> {
+    let snd_vmm_config = snd_split_config
+        .vmm_config
+        .as_mut()
+        .expect("snd_vmm_config must exist");
+    product::push_snd_control_tubes(control_tubes, snd_vmm_config);
+
+    // If the SND backend is passed, start up the vhost-user worker in the main process.
+    if let Some(backend_config) = snd_split_config.backend_config.take() {
+        std::thread::spawn(move || run_snd_device_worker(backend_config));
+    }
+
+    // The SND is always vhost-user, even if running in the main process.
+    let snd_device_tube = snd_vmm_config
+        .main_vhost_user_tube
+        .take()
+        .expect("Snd VMM vhost-user tube should be set");
+    let connection = Connection::<FrontendReq>::from(snd_device_tube);
+
+    create_vhost_user_snd_device(virtio::base_features(cfg.protection_type), connection)
+        .context("create vhost-user SND device")
 }
 
 fn create_devices(
@@ -782,8 +785,9 @@ fn create_devices(
     vm_memory_control_tubes: &mut Vec<Tube>,
     control_tubes: &mut Vec<TaggedControlTube>,
     disk_device_tubes: &mut Vec<Tube>,
+    initial_audio_session_states: &mut Vec<InitialAudioSessionState>,
     balloon_device_tube: Option<Tube>,
-    pvclock_device_tube: Option<Tube>,
+    #[cfg(feature = "pvclock")] pvclock_device_tube: Option<Tube>,
     dynamic_mapping_device_tube: Option<Tube>,
     inflate_tube: Option<Tube>,
     init_balloon_size: u64,
@@ -796,7 +800,9 @@ fn create_devices(
         exit_evt_wrtube,
         control_tubes,
         disk_device_tubes,
+        initial_audio_session_states,
         balloon_device_tube,
+        #[cfg(feature = "pvclock")]
         pvclock_device_tube,
         dynamic_mapping_device_tube,
         inflate_tube,
@@ -865,13 +871,13 @@ fn handle_readable_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     control_tubes: &mut BTreeMap<usize, TaggedControlTube>,
     guest_os: &mut RunnableLinuxVm<V, Vcpu>,
     sys_allocator_mutex: &Arc<Mutex<SystemAllocator>>,
-    virtio_snd_host_mute_tube: &mut Option<Tube>,
+    virtio_snd_host_mute_tubes: &mut [Tube],
     proto_main_loop_tube: Option<&ProtoTube>,
     anti_tamper_main_thread_tube: &Option<ProtoTube>,
     #[cfg(feature = "balloon")] mut balloon_tube: Option<&mut BalloonTube>,
     memory_size_mb: u64,
     vcpu_boxes: &Mutex<Vec<Box<dyn VcpuArch>>>,
-    pvclock_host_tube: &Option<Tube>,
+    #[cfg(feature = "pvclock")] pvclock_host_tube: &Option<Tube>,
     run_mode_arc: &VcpuRunMode,
     region_state: &mut VmMemoryRegionState,
     vm_control_server: Option<&mut ControlServer>,
@@ -880,13 +886,15 @@ fn handle_readable_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     wait_ctx: &WaitContext<Token>,
     force_s2idle: bool,
     vcpu_control_channels: &[mpsc::Sender<VcpuControl>],
+    suspended_pvclock_state: &mut Option<hypervisor::ClockState>,
 ) -> Result<Option<ExitState>> {
-    let execute_vm_request = |request: VmRequest, guest_os: &mut RunnableLinuxVm<V, Vcpu>| {
-        let mut run_mode_opt = None;
+    let mut execute_vm_request = |request: VmRequest, guest_os: &mut RunnableLinuxVm<V, Vcpu>| {
+        if let VmRequest::Exit = request {
+            return (VmResponse::Ok, Some(VmRunMode::Exiting));
+        }
         let vcpu_size = vcpu_boxes.lock().len();
         let resp = request.execute(
             &guest_os.vm,
-            &mut run_mode_opt,
             disk_host_tubes,
             &mut guest_os.pm,
             #[cfg(feature = "gpu")]
@@ -901,7 +909,9 @@ fn handle_readable_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                     vcpu_control_channels,
                     vcpu_boxes,
                     guest_os.irq_chip.as_ref(),
+                    #[cfg(feature = "pvclock")]
                     pvclock_host_tube,
+                    &guest_os.resume_notify_devices,
                     msg,
                 );
             },
@@ -912,8 +922,9 @@ fn handle_readable_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
             vcpu_size,
             irq_handler_control,
             || guest_os.irq_chip.as_ref().snapshot(vcpu_size),
+            suspended_pvclock_state,
         );
-        (resp, run_mode_opt)
+        (resp, None)
     };
 
     match event.token {
@@ -979,7 +990,7 @@ fn handle_readable_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                     TaggedControlTube::Product(product_tube) => {
                         product::handle_tagged_control_tube_event(
                             product_tube,
-                            virtio_snd_host_mute_tube,
+                            virtio_snd_host_mute_tubes,
                             service_vm_state,
                             ipc_main_loop_tube,
                         )
@@ -1083,11 +1094,12 @@ fn handle_readable_event<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                 ipc_main_loop_tube,
                 memory_size_mb,
                 proto_main_loop_tube,
+                #[cfg(feature = "pvclock")]
                 pvclock_host_tube,
                 run_mode_arc,
                 service_vm_state,
                 vcpu_boxes,
-                virtio_snd_host_mute_tube,
+                virtio_snd_host_mute_tubes,
                 execute_vm_request,
             );
             if let Some(exit_state) = handle_run_mode_change_for_vm_request(&run_mode_opt, guest_os)
@@ -1113,13 +1125,7 @@ fn handle_run_mode_change_for_vm_request<V: VmArch + 'static, Vcpu: VcpuArch + '
         info!("control socket changed run mode to {}", run_mode);
         match run_mode {
             VmRunMode::Exiting => return Some(ExitState::Stop),
-            other => {
-                if other == &VmRunMode::Running {
-                    for dev in &guest_os.resume_notify_devices {
-                        dev.lock().resume_imminent();
-                    }
-                }
-            }
+            _ => unreachable!(),
         }
     }
     // No exit state change.
@@ -1156,7 +1162,7 @@ fn vm_memory_handler_thread(
             .context("failed to add descriptor to wait context")?;
     }
 
-    let mut region_state = VmMemoryRegionState::new();
+    let mut region_state: VmMemoryRegionState = Default::default();
 
     'wait: loop {
         let events = {
@@ -1261,8 +1267,9 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     #[cfg(feature = "gpu")] gpu_control_tube: Option<Tube>,
     broker_shutdown_evt: Option<Event>,
     balloon_host_tube: Option<Tube>,
-    pvclock_host_tube: Option<Tube>,
+    #[cfg(feature = "pvclock")] pvclock_host_tube: Option<Tube>,
     disk_host_tubes: Vec<Tube>,
+    initial_audio_session_states: Vec<InitialAudioSessionState>,
     gralloc: RutabagaGralloc,
     #[cfg(feature = "stats")] stats: Option<Arc<Mutex<StatisticsCollector>>>,
     service_pipe_name: Option<String>,
@@ -1271,7 +1278,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     tsc_sync_mitigations: TscSyncMitigations,
     force_calibrated_tsc_leaf: bool,
     mut product_args: RunControlArgs,
-    mut virtio_snd_host_mute_tube: Option<Tube>,
+    mut virtio_snd_host_mute_tubes: Vec<Tube>,
     restore_path: Option<PathBuf>,
     control_server_path: Option<PathBuf>,
     force_s2idle: bool,
@@ -1282,6 +1289,11 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
 
     let mut service_vm_state = product::create_service_vm_state(memory_size_mb);
 
+    let service_audio_states = product::create_service_audio_states_and_send_to_service(
+        initial_audio_session_states,
+        &ipc_main_loop_tube,
+    )?;
+
     let sys_allocator_mutex = Arc::new(Mutex::new(sys_allocator));
 
     let exit_evt = Event::new().exit_context(Exit::CreateEvent, "failed to create event")?;
@@ -1432,18 +1444,22 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
         force_calibrated_tsc_leaf,
     )?;
 
+    // See comment on `VmRequest::execute`.
+    let mut suspended_pvclock_state: Option<hypervisor::ClockState> = None;
+
     // Restore VM (if applicable).
     if let Some(path) = restore_path {
         vm_control::do_restore(
-            path,
-            &guest_os.vm,
+            &path,
             |msg| {
                 kick_all_vcpus(
                     run_mode_arc.as_ref(),
                     &vcpu_control_channels,
                     vcpu_boxes.as_ref(),
                     guest_os.irq_chip.as_ref(),
+                    #[cfg(feature = "pvclock")]
                     &pvclock_host_tube,
+                    &guest_os.resume_notify_devices,
                     msg,
                 )
             },
@@ -1453,7 +1469,6 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                     &vcpu_control_channels,
                     vcpu_boxes.as_ref(),
                     guest_os.irq_chip.as_ref(),
-                    &pvclock_host_tube,
                     index,
                     msg,
                 )
@@ -1468,6 +1483,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                     .restore(image, guest_os.vcpu_count)
             },
             /* require_encrypted= */ false,
+            &mut suspended_pvclock_state,
         )?;
         // Allow the vCPUs to start for real.
         kick_all_vcpus(
@@ -1475,7 +1491,9 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
             &vcpu_control_channels,
             vcpu_boxes.as_ref(),
             guest_os.irq_chip.as_ref(),
+            #[cfg(feature = "pvclock")]
             &pvclock_host_tube,
+            &guest_os.resume_notify_devices,
             // Other platforms (unix) have multiple modes they could start in (e.g. starting for
             // guest kernel debugging, etc). If/when we support those modes on Windows, we'll need
             // to enter that mode here rather than VmRunMode::Running.
@@ -1484,7 +1502,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
     }
 
     let mut exit_state = ExitState::Stop;
-    let mut region_state = VmMemoryRegionState::new();
+    let mut region_state: VmMemoryRegionState = Default::default();
 
     'poll: loop {
         let events = {
@@ -1512,13 +1530,14 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                 &mut control_tubes,
                 &mut guest_os,
                 &sys_allocator_mutex,
-                &mut virtio_snd_host_mute_tube,
+                &mut virtio_snd_host_mute_tubes,
                 proto_main_loop_tube.as_ref(),
                 &anti_tamper_main_thread_tube,
                 #[cfg(feature = "balloon")]
                 balloon_tube.as_mut(),
                 memory_size_mb,
                 vcpu_boxes.as_ref(),
+                #[cfg(feature = "pvclock")]
                 &pvclock_host_tube,
                 run_mode_arc.as_ref(),
                 &mut region_state,
@@ -1528,6 +1547,7 @@ fn run_control<V: VmArch + 'static, Vcpu: VcpuArch + 'static>(
                 &wait_ctx,
                 force_s2idle,
                 &vcpu_control_channels,
+                &mut suspended_pvclock_state,
             )?;
             if let Some(state) = state {
                 exit_state = state;
@@ -1677,18 +1697,34 @@ fn kick_all_vcpus(
     vcpu_control_channels: &[mpsc::Sender<VcpuControl>],
     vcpu_boxes: &Mutex<Vec<Box<dyn VcpuArch>>>,
     irq_chip: &dyn IrqChipArch,
-    pvclock_host_tube: &Option<Tube>,
+    #[cfg(feature = "pvclock")] pvclock_host_tube: &Option<Tube>,
+    resume_notify_devices: &[Arc<Mutex<dyn BusResumeDevice>>],
     msg: VcpuControl,
 ) {
     // On Windows, we handle run mode switching directly rather than delegating to the VCPU thread
     // like unix does.
     match &msg {
         VcpuControl::RunState(VmRunMode::Suspending) => {
-            suspend_all_vcpus(run_mode, vcpu_boxes, irq_chip, pvclock_host_tube);
+            suspend_all_vcpus(
+                run_mode,
+                vcpu_boxes,
+                irq_chip,
+                #[cfg(feature = "pvclock")]
+                pvclock_host_tube,
+            );
             return;
         }
         VcpuControl::RunState(VmRunMode::Running) => {
-            resume_all_vcpus(run_mode, vcpu_boxes, irq_chip, pvclock_host_tube);
+            for device in resume_notify_devices {
+                device.lock().resume_imminent();
+            }
+            resume_all_vcpus(
+                run_mode,
+                vcpu_boxes,
+                irq_chip,
+                #[cfg(feature = "pvclock")]
+                pvclock_host_tube,
+            );
             return;
         }
         _ => (),
@@ -1722,7 +1758,6 @@ fn kick_vcpu(
     vcpu_control_channels: &[mpsc::Sender<VcpuControl>],
     vcpu_boxes: &Mutex<Vec<Box<dyn VcpuArch>>>,
     irq_chip: &dyn IrqChipArch,
-    pvclock_host_tube: &Option<Tube>,
     index: usize,
     msg: VcpuControl,
 ) {
@@ -1762,7 +1797,7 @@ pub(crate) fn suspend_all_vcpus(
     run_mode: &VcpuRunMode,
     vcpu_boxes: &Mutex<Vec<Box<dyn VcpuArch>>>,
     irq_chip: &dyn IrqChipArch,
-    pvclock_host_tube: &Option<Tube>,
+    #[cfg(feature = "pvclock")] pvclock_host_tube: &Option<Tube>,
 ) {
     // VCPU threads MUST see the VmRunMode::Suspending flag first, otherwise
     // they may re-enter the VM.
@@ -1774,6 +1809,7 @@ pub(crate) fn suspend_all_vcpus(
     }
     irq_chip.kick_halted_vcpus();
 
+    #[cfg(feature = "pvclock")]
     handle_pvclock_request(pvclock_host_tube, PvClockCommand::Suspend)
         .unwrap_or_else(|e| error!("Error handling pvclock suspend: {:?}", e));
 }
@@ -1783,8 +1819,9 @@ pub(crate) fn resume_all_vcpus(
     run_mode: &VcpuRunMode,
     vcpu_boxes: &Mutex<Vec<Box<dyn VcpuArch>>>,
     irq_chip: &dyn IrqChipArch,
-    pvclock_host_tube: &Option<Tube>,
+    #[cfg(feature = "pvclock")] pvclock_host_tube: &Option<Tube>,
 ) {
+    #[cfg(feature = "pvclock")]
     handle_pvclock_request(pvclock_host_tube, PvClockCommand::Resume)
         .unwrap_or_else(|e| error!("Error handling pvclock resume: {:?}", e));
 
@@ -1952,13 +1989,10 @@ pub fn get_default_hypervisor() -> Option<HypervisorKind> {
     };
 
     #[cfg(feature = "haxm")]
-    if get_cpu_manufacturer() == CpuManufacturer::Intel {
-        // Make sure Haxm device can be opened before selecting it.
-        match Haxm::new() {
-            Ok(_) => return Some(HypervisorKind::Ghaxm),
-            Err(e) => warn!("Cannot initialize HAXM: {}", e),
-        };
-    }
+    match Haxm::new() {
+        Ok(_) => return Some(HypervisorKind::Ghaxm),
+        Err(e) => warn!("Cannot initialize HAXM: {}", e),
+    };
 
     #[cfg(feature = "gvm")]
     // Make sure Gvm device can be opened before selecting it.
@@ -2466,6 +2500,7 @@ where
     };
 
     // PvClock gets a tube for handling suspend/resume requests from the main thread.
+    #[cfg(feature = "pvclock")]
     let (pvclock_host_tube, pvclock_device_tube) = if cfg.pvclock {
         let (host, device) =
             Tube::pair().exit_context(Exit::CreateTube, "failed to create tube")?;
@@ -2579,6 +2614,8 @@ where
 
     let (virtio_snd_host_mute_tube, virtio_snd_device_mute_tube) = create_snd_mute_tube_pair()?;
 
+    let mut initial_audio_session_states: Vec<InitialAudioSessionState> = Vec::new();
+
     let pci_devices = create_devices(
         &mut cfg,
         vm.get_memory(),
@@ -2587,7 +2624,9 @@ where
         &mut vm_memory_control_tubes,
         &mut control_tubes,
         &mut disk_device_tubes,
+        &mut initial_audio_session_states,
         balloon_device_tube,
+        #[cfg(feature = "pvclock")]
         pvclock_device_tube,
         dynamic_mapping_device_tube,
         /* inflate_tube= */ None,
@@ -2599,6 +2638,7 @@ where
 
     let mut vcpu_ids = Vec::new();
 
+    let (vwmdt_host_tube, vmwdt_device_tube) = Tube::pair().context("failed to create tube")?;
     let windows = Arch::build_vm::<V, Vcpu>(
         components,
         &vm_evt_wrtube,
@@ -2615,7 +2655,9 @@ where
         /* debugcon_jail= */ None,
         None,
         None,
+        /* guest_suspended_cvar= */ None,
         dt_overlays,
+        cfg.fdt_position,
     )
     .exit_context(Exit::BuildVm, "the architecture failed to build the vm")?;
 
@@ -2638,8 +2680,10 @@ where
         gpu_control_tube,
         cfg.broker_shutdown_event.take(),
         balloon_host_tube,
+        #[cfg(feature = "pvclock")]
         pvclock_host_tube,
         disk_host_tubes,
+        initial_audio_session_states,
         gralloc,
         #[cfg(feature = "stats")]
         stats,
@@ -2649,7 +2693,10 @@ where
         tsc_sync_mitigations,
         cfg.force_calibrated_tsc_leaf,
         product_args,
-        virtio_snd_host_mute_tube,
+        match virtio_snd_host_mute_tube {
+            Some(virtio_snd_host_mute_tube) => vec![virtio_snd_host_mute_tube],
+            None => vec![],
+        },
         cfg.restore_path,
         cfg.socket_path,
         cfg.force_s2idle,
@@ -2668,7 +2715,7 @@ mod tests {
 
         let dummy_kernel_path = test_dir.path().join("dummy_kernel.txt");
         OpenOptions::new()
-            .create(true)
+            .create_new(true)
             .write(true)
             .open(&dummy_kernel_path)
             .expect("Could not open file!");
diff --git a/src/sys/windows/control_server.rs b/src/sys/windows/control_server.rs
index 5a6f6ba6b..a814aa4de 100644
--- a/src/sys/windows/control_server.rs
+++ b/src/sys/windows/control_server.rs
@@ -143,14 +143,16 @@ impl ControlServer {
             info!("control server: accepted client");
 
             loop {
-                match base::deserialize_and_recv::<VmRequest, _>(|buf| {
+                let recv_result = base::deserialize_and_recv::<VmRequest, _>(|buf| {
                     client_pipe_read.read_overlapped_blocking(
                         buf,
                         &mut read_overlapped,
                         &exit_evt,
                     )?;
                     Ok(buf.len())
-                }) {
+                });
+
+                match recv_result {
                     Ok(msg) => {
                         control_send.send(&msg).map_err(|e| {
                             error!("unexpected error in control server recv loop: {}", e);
diff --git a/src/sys/windows/generic.rs b/src/sys/windows/generic.rs
index 17b1ff66f..a44903ec9 100644
--- a/src/sys/windows/generic.rs
+++ b/src/sys/windows/generic.rs
@@ -60,6 +60,7 @@ pub(crate) use metrics::MetricEventType;
 use sync::Mutex;
 #[cfg(feature = "balloon")]
 use vm_control::BalloonTube;
+use vm_control::InitialAudioSessionState;
 use vm_control::PvClockCommand;
 use vm_control::VmRequest;
 use vm_control::VmResponse;
@@ -79,6 +80,8 @@ impl ServiceVmState {
     pub fn generate_send_state_message(&self) {}
 }
 
+pub struct ServiceAudioStates {}
+
 pub(super) struct RunControlArgs {}
 
 #[derive(Debug)]
@@ -132,6 +135,7 @@ pub(super) fn get_run_control_args(cfg: &mut Config) -> RunControlArgs {
 pub(super) fn merge_session_invariants(serialized_session_invariants: &[u8]) {}
 
 // Handles sending command to pvclock device.
+#[cfg(feature = "pvclock")]
 pub(super) fn handle_pvclock_request(tube: &Option<Tube>, command: PvClockCommand) -> Result<()> {
     Ok(())
 }
@@ -164,7 +168,7 @@ pub(super) fn start_service_ipc_listener(
 
 pub(super) fn handle_tagged_control_tube_event(
     product_tube: &TaggedControlTube,
-    virtio_snd_host_mute_tube: &mut Option<Tube>,
+    virtio_snd_host_mute_tubes: &mut [Tube],
     service_vm_state: &mut ServiceVmState,
     ipc_main_loop_tube: Option<&Tube>,
 ) {
@@ -192,11 +196,11 @@ pub(super) fn handle_received_token<'a, V: VmArch + 'static, Vcpu: VcpuArch + 's
     _ipc_main_loop_tube: Option<&Tube>,
     _memory_size_mb: u64,
     _proto_main_loop_tube: Option<&ProtoTube>,
-    _pvclock_host_tube: &Option<Tube>,
+    #[cfg(feature = "pvclock")] _pvclock_host_tube: &Option<Tube>,
     _run_mode_arc: &VcpuRunMode,
     _service_vm_state: &mut ServiceVmState,
     _vcpu_boxes: &Mutex<Vec<Box<dyn VcpuArch>>>,
-    _virtio_snd_host_mute_tube: &mut Option<Tube>,
+    _virtio_snd_host_mute_tube: &mut [Tube],
     _execute_vm_request: F,
 ) -> Option<VmRunMode>
 where
@@ -244,6 +248,13 @@ pub(super) fn create_gpu(
     ))
 }
 
+pub(super) fn create_service_audio_states_and_send_to_service(
+    initial_audio_session_states: Vec<InitialAudioSessionState>,
+    ipc_main_loop_tube: &Option<Tube>,
+) -> Result<ServiceAudioStates> {
+    Ok(ServiceAudioStates {})
+}
+
 #[cfg(feature = "gpu")]
 pub(super) fn push_window_procedure_thread_control_tubes(
     #[allow(clippy::ptr_arg)]
@@ -286,18 +297,10 @@ pub(crate) fn get_gpu_product_configs(
 }
 
 #[cfg(feature = "audio")]
-pub(crate) fn get_snd_product_configs(
-    _cfg: &Config,
-    _alias_pid: u32,
-) -> Result<(SndBackendConfigProduct, SndVmmConfigProduct)> {
+pub(crate) fn get_snd_product_configs() -> Result<(SndBackendConfigProduct, SndVmmConfigProduct)> {
     Ok((SndBackendConfigProduct {}, SndVmmConfigProduct {}))
 }
 
-#[cfg(feature = "audio")]
-pub(super) fn virtio_sound_enabled() -> bool {
-    false
-}
-
 pub(crate) fn run_metrics(_args: RunMetricsCommand) -> Result<()> {
     info!("sleep forever. We will get killed by broker");
     thread::sleep(Duration::MAX);
@@ -316,6 +319,7 @@ pub(super) fn push_mouse_device(
     Ok(())
 }
 
+#[cfg(feature = "pvclock")]
 pub(super) fn push_pvclock_device(
     cfg: &Config,
     devs: &mut [VirtioDeviceStub],
diff --git a/src/sys/windows/run_vcpu.rs b/src/sys/windows/run_vcpu.rs
index de973af27..8a0c64906 100644
--- a/src/sys/windows/run_vcpu.rs
+++ b/src/sys/windows/run_vcpu.rs
@@ -66,6 +66,7 @@ use hypervisor::IoOperation;
 use hypervisor::IoParams;
 use hypervisor::VcpuExit;
 use hypervisor::VcpuInitX86_64;
+use metrics_events::MetricEventType;
 use sync::Condvar;
 use sync::Mutex;
 use vm_control::VcpuControl;
@@ -362,13 +363,15 @@ impl VcpuRunThread {
                     )
                 };
 
-                let final_event_data = match vcpu_fn().unwrap_or_else(|e| {
+                let exit_state = vcpu_fn().unwrap_or_else(|e| {
                     error!(
                         "vcpu {} run loop exited with error: {:#}",
                         context.cpu_id, e
                     );
                     ExitState::Stop
-                }) {
+                });
+
+                let final_event_data = match exit_state {
                     ExitState::Stop => VmEventType::Exit,
                     _ => unreachable!(),
                 };
@@ -437,10 +440,7 @@ impl VcpuStallMonitor {
                 pin_mut!(exit_future);
                 'main: loop {
                     if reset_timer {
-                        timer.reset(
-                            Self::VCPU_CHECKUP_INTERVAL,
-                            Some(Self::VCPU_CHECKUP_INTERVAL),
-                        )?;
+                        timer.reset_repeating(Self::VCPU_CHECKUP_INTERVAL)?;
                         reset_timer = false;
                     }
                     let timer_future = timer.wait();
@@ -789,7 +789,7 @@ where
                                             });
                                     }
                                 }
-                                Some(data)
+                                Ok(Some(data))
                             }
                             IoOperation::Write { data } => {
                                 if size > data.len() {
@@ -814,7 +814,7 @@ where
                                             address, e
                                         ));
                                 }
-                                None
+                                Ok(None)
                             }
                         }
                     }).unwrap_or_else(|e| error!("failed to handle mmio: {}", e));
@@ -834,7 +834,15 @@ where
                 // Shutdown only for triple faults and other vcpu panics.  WHPX never exits
                 // with Shutdown.  Normal reboots and shutdowns, like window close, use
                 // the vm event tube and VmRunMode::Exiting instead of VcpuExit::Shutdown.
-                Ok(VcpuExit::Shutdown) => bail_exit_code!(Exit::VcpuShutdown, "vcpu shutdown"),
+                Ok(VcpuExit::Shutdown(reason)) => {
+                    if let Err(e) = reason {
+                        metrics::log_descriptor(
+                            MetricEventType::VcpuShutdownError,
+                            e.get_raw_error_code() as i64,
+                        );
+                    }
+                    bail_exit_code!(Exit::VcpuShutdown, "vcpu shutdown (reason: {:?})", reason)
+                }
                 Ok(VcpuExit::FailEntry {
                     hardware_entry_failure_reason,
                 }) => bail_exit_code!(
diff --git a/swap/Android.bp b/swap/Android.bp
index 742feb72a..d28c284c3 100644
--- a/swap/Android.bp
+++ b/swap/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "swap",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/swap/Cargo.toml b/swap/Cargo.toml
index 86d7e5587..fb58e797d 100644
--- a/swap/Cargo.toml
+++ b/swap/Cargo.toml
@@ -17,28 +17,28 @@ trace_marker = ["cros_tracing/trace_marker"]
 enable = ["userfaultfd", "userfaultfd-sys"]
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 base = { path = "../base" }
-cfg-if = "*"
+cfg-if = "1"
 cros_tracing = { path = "../cros_tracing" }
 jail = { path = "../jail" }
 metrics = { path = "../metrics" }
-num_cpus = "*"
-once_cell = "*"
-remain = "*"
+num_cpus = "1"
+once_cell = "1.7"
+remain = "0.2"
 serde = { version = "1", features = ["derive"] }
-serde_json = "*"
+serde_json = "1"
 sync = { path = "../common/sync" }               # provided by ebuild
-thiserror = "*"
+thiserror = "1"
 vm_memory = { path = "../vm_memory" }
 
 [target.'cfg(any(target_os = "android", target_os = "linux"))'.dependencies]
-libc = "*"
+libc = "0.2"
 
 [target.'cfg(target_os="linux")'.dependencies]
 userfaultfd = { version = "0.8.1", optional = true }
 userfaultfd-sys = { version = "0.5.0", optional = true }
 
-[dev_dependencies]
+[dev-dependencies]
 libtest-mimic = "0.6"
-tempfile = "*"
+tempfile = "3"
diff --git a/swap/src/controller.rs b/swap/src/controller.rs
index 928c2ac19..0aee82c23 100644
--- a/swap/src/controller.rs
+++ b/swap/src/controller.rs
@@ -23,8 +23,6 @@ use anyhow::Context;
 use base::debug;
 use base::error;
 use base::info;
-use base::linux::process::fork_process;
-use base::linux::process::Child;
 use base::linux::FileDataIterator;
 use base::syslog;
 use base::warn;
@@ -39,6 +37,8 @@ use base::TubeError;
 use base::WaitContext;
 use jail::create_base_minijail;
 use jail::create_sandbox_minijail;
+use jail::fork::fork_process;
+use jail::fork::Child;
 use jail::JailConfig;
 use jail::SandboxConfig;
 use jail::MAX_OPEN_FILES_DEFAULT;
diff --git a/swap/src/file.rs b/swap/src/file.rs
index 682858f05..aa4c08a89 100644
--- a/swap/src/file.rs
+++ b/swap/src/file.rs
@@ -188,10 +188,7 @@ impl FilePageStates {
                     .idx_page()
                     .unwrap_or_else(|| unreachable!("the page is not freed"))]
                 .is_present()
-        });
-        let Some(next_head_idx_offset) = next_head_idx_offset else {
-            return None;
-        };
+        })?;
         let idx_file = idx_file + next_head_idx_offset;
 
         let Some(head_idx_page) = self.states[idx_file].idx_page() else {
diff --git a/swap/src/file_truncator.rs b/swap/src/file_truncator.rs
index d8b91a4ea..61cbcd510 100644
--- a/swap/src/file_truncator.rs
+++ b/swap/src/file_truncator.rs
@@ -31,7 +31,6 @@ pub struct FileTruncator {
 // The particular values here are relatively arbitrary values that
 // result in a "slow-enough" background truncation.
 const TRUNCATE_STEP_BYTES: u64 = 64 * 1024 * 1024; // 64 MiB
-const TRUNCATE_INITIAL_WAIT: Duration = Duration::from_secs(30);
 const TRUNCATE_INTERVAL: Duration = Duration::from_secs(5);
 
 fn truncate_worker(
@@ -86,7 +85,7 @@ impl FileTruncator {
 
     fn new_inner(mut timer: Box<dyn TimerTrait>, file: File) -> Result<Self> {
         timer
-            .reset(TRUNCATE_INITIAL_WAIT, Some(TRUNCATE_INTERVAL))
+            .reset_repeating(TRUNCATE_INTERVAL)
             .context("failed to arm timer")?;
         Ok(Self {
             worker: Some(WorkerThread::start(
@@ -147,7 +146,7 @@ mod tests {
         file.set_len(2 * TRUNCATE_STEP_BYTES).unwrap();
 
         let worker = FileTruncator::new_inner(timer, file.try_clone().unwrap()).unwrap();
-        clock.lock().add_ns(TRUNCATE_INITIAL_WAIT.as_nanos() as u64);
+        clock.lock().add_ns(TRUNCATE_INTERVAL.as_nanos() as u64);
         wait_for_target_length(&mut file, TRUNCATE_STEP_BYTES);
         clock.lock().add_ns(TRUNCATE_INTERVAL.as_nanos() as u64);
         wait_for_target_length(&mut file, 0);
diff --git a/swap/src/pagesize.rs b/swap/src/pagesize.rs
index de7eb75ce..a6d38627f 100644
--- a/swap/src/pagesize.rs
+++ b/swap/src/pagesize.rs
@@ -54,15 +54,6 @@ fn load_transparent_hugepage_size() -> anyhow::Result<usize> {
     Ok(hugepage_size)
 }
 
-/// Helper methods to calculate values derived from page size.
-///
-/// This has performance benefits from:
-///
-/// * Avoiding calling `sysconf(_SC_PAGESIZE)` multiple times by caching the shift bit.
-/// * Using the (faster) shift instruction instead of (slower) multiply/divide instruction.
-#[derive(Clone, Copy, Debug)]
-pub struct PagesizeShift(u8);
-
 /// The page index of the page which contains the "addr".
 #[inline]
 pub fn addr_to_page_idx(addr: usize) -> usize {
diff --git a/swap/src/userfaultfd.rs b/swap/src/userfaultfd.rs
index 10b9df6e1..439d6eb9f 100644
--- a/swap/src/userfaultfd.rs
+++ b/swap/src/userfaultfd.rs
@@ -195,7 +195,7 @@ impl Factory {
             let res = unsafe {
                 ioctl_with_val(
                     dev_file,
-                    USERFAULTFD_IOC_NEW(),
+                    USERFAULTFD_IOC_NEW,
                     (libc::O_CLOEXEC | libc::O_NONBLOCK) as libc::c_ulong,
                 )
             };
@@ -213,7 +213,7 @@ impl Factory {
             };
             // SAFETY:
             // Safe because ioctl(2) UFFDIO_API with does not change Rust memory safety.
-            let res = unsafe { ioctl_with_mut_ref(&uffd, UFFDIO_API(), &mut api) };
+            let res = unsafe { ioctl_with_mut_ref(&uffd, UFFDIO_API, &mut api) };
             if res < 0 {
                 errno_result().context("UFFDIO_API")
             } else {
diff --git a/third_party/vmm_vhost/Android.bp b/third_party/vmm_vhost/Android.bp
index 13f98717f..341f27f5a 100644
--- a/third_party/vmm_vhost/Android.bp
+++ b/third_party/vmm_vhost/Android.bp
@@ -1,45 +1,16 @@
 // This file is generated by cargo_embargo.
-// Do not modify this file after the first "rust_*" or "genrule" module
-// because the changes will be overridden on upgrade.
-// Content before the first "rust_*" or "genrule" module is preserved.
+// Do not modify this file because the changes will be overridden on upgrade.
 
 package {
-    default_applicable_licenses: [
-        "external_crosvm_third_party_vmm_vhost_license",
-    ],
+    default_applicable_licenses: ["external_rust_crates_vmm_vhost_license"],
+    default_team: "trendy_team_android_rust",
 }
 
-// Added automatically by a large-scale-change that took the approach of
-// 'apply every license found to every target'. While this makes sure we respect
-// every license restriction, it may not be entirely correct.
-//
-// e.g. GPL in an MIT project might only apply to the contrib/ directory.
-//
-// Please consider splitting the single license below into multiple licenses,
-// taking care not to lose any license_kind information, and overriding the
-// default license using the 'licenses: [...]' property on targets as needed.
-//
-// For unused files, consider creating a 'fileGroup' with "//visibility:private"
-// to attach the license to, and including a comment whether the files may be
-// used in the current project.
-//
-// large-scale-change included anything that looked like it might be a license
-// text as a license_text. e.g. LICENSE, NOTICE, COPYING etc.
-//
-// Please consider removing redundant or irrelevant files from 'license_text:'.
-// See: http://go/android-license-faq
 license {
-    name: "external_crosvm_third_party_vmm_vhost_license",
+    name: "external_rust_crates_vmm_vhost_license",
     visibility: [":__subpackages__"],
-    license_kinds: [
-        "SPDX-license-identifier-Apache-2.0",
-        "SPDX-license-identifier-BSD",
-    ],
-    license_text: [
-        "LICENSE",
-        "LICENSE-BSD-3-Clause",
-        "LICENSE-BSD-Chromium",
-    ],
+    license_kinds: ["SPDX-license-identifier-Apache-2.0"],
+    license_text: ["LICENSE"],
 }
 
 rust_library {
@@ -49,7 +20,7 @@ rust_library {
     crate_name: "vmm_vhost",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: ["default"],
     rustlibs: [
@@ -58,7 +29,6 @@ rust_library {
         "libbitflags",
         "libcfg_if",
         "liblibc",
-        "libtempfile",
         "libthiserror",
         "libzerocopy",
     ],
@@ -75,7 +45,7 @@ rust_test {
     crate_name: "vmm_vhost",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/third_party/vmm_vhost/Cargo.toml b/third_party/vmm_vhost/Cargo.toml
index 18ff132ce..304817e64 100644
--- a/third_party/vmm_vhost/Cargo.toml
+++ b/third_party/vmm_vhost/Cargo.toml
@@ -14,18 +14,20 @@ edition = "2021"
 default = []
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 base = { path = "../../base" }
 bitflags = "2.3"
 cfg-if = "1.0.0"
 enumn = "0.1.0"
 libc = ">=0.2.39"
-remain = "*"
-tempfile = "*"
+remain = "0.2"
 thiserror = { version = "1.0.20" }
 zerocopy = { version = "0.7", features = ["derive"] }
 
 [target.'cfg(windows)'.dependencies]
 serde = { version = "1", features = [ "derive" ] }
-serde_json = "*"
+serde_json = "1"
 tube_transporter = { path = "../../tube_transporter" }
+
+[dev-dependencies]
+tempfile = "3"
diff --git a/third_party/vmm_vhost/src/backend_client.rs b/third_party/vmm_vhost/src/backend_client.rs
index b1bbfa609..eee561faa 100644
--- a/third_party/vmm_vhost/src/backend_client.rs
+++ b/third_party/vmm_vhost/src/backend_client.rs
@@ -3,9 +3,7 @@
 
 use std::fs::File;
 use std::mem;
-use std::path::Path;
 
-use anyhow::anyhow;
 use base::AsRawDescriptor;
 use base::Event;
 use base::RawDescriptor;
@@ -22,7 +20,6 @@ use crate::Error as VhostUserError;
 use crate::FrontendReq;
 use crate::Result as VhostUserResult;
 use crate::Result;
-use crate::SystemStream;
 
 /// Client for a vhost-user device. The API is a thin abstraction over the vhost-user protocol.
 pub struct BackendClient {
@@ -36,13 +33,8 @@ pub struct BackendClient {
 }
 
 impl BackendClient {
-    /// Create a new instance from a Unix stream socket.
-    pub fn from_stream(sock: SystemStream) -> Self {
-        Self::new(Connection::from(sock))
-    }
-
     /// Create a new instance.
-    fn new(connection: Connection<FrontendReq>) -> Self {
+    pub fn new(connection: Connection<FrontendReq>) -> Self {
         BackendClient {
             connection,
             virtio_features: 0,
@@ -51,35 +43,6 @@ impl BackendClient {
         }
     }
 
-    /// Create a new instance.
-    ///
-    /// Will retry as the backend may not be ready to accept the connection.
-    ///
-    /// # Arguments
-    /// * `path` - path of Unix domain socket listener to connect to
-    pub fn connect<P: AsRef<Path>>(path: P) -> Result<Self> {
-        let mut retry_count = 5;
-        let connection = loop {
-            match Connection::connect(&path) {
-                Ok(connection) => break Ok(connection),
-                Err(e) => match &e {
-                    VhostUserError::SocketConnect(why) => {
-                        if why.kind() == std::io::ErrorKind::ConnectionRefused && retry_count > 0 {
-                            std::thread::sleep(std::time::Duration::from_millis(100));
-                            retry_count -= 1;
-                            continue;
-                        } else {
-                            break Err(e);
-                        }
-                    }
-                    _ => break Err(e),
-                },
-            }
-        }?;
-
-        Ok(Self::new(connection))
-    }
-
     /// Get a bitmask of supported virtio/vhost features.
     pub fn get_features(&mut self) -> Result<u64> {
         let hdr = self.send_request_header(FrontendReq::GET_FEATURES, None)?;
@@ -246,70 +209,60 @@ impl BackendClient {
         self.wait_for_ack(&hdr)
     }
 
-    /// Put the device to sleep.
-    pub fn sleep(&self) -> Result<()> {
-        let hdr = self.send_request_header(FrontendReq::SLEEP, None)?;
-        let reply = self.recv_reply::<VhostUserSuccess>(&hdr)?;
-        if !reply.success() {
-            Err(VhostUserError::SleepError(anyhow!(
-                "Device process responded with a failure on SLEEP."
-            )))
-        } else {
-            Ok(())
+    /// Front-end and back-end negotiate a channel over which to transfer the back-ends internal
+    /// state during migration.
+    ///
+    /// Requires VHOST_USER_PROTOCOL_F_DEVICE_STATE to be negotiated.
+    pub fn set_device_state_fd(
+        &self,
+        transfer_direction: VhostUserTransferDirection,
+        migration_phase: VhostUserMigrationPhase,
+        fd: &impl AsRawDescriptor,
+    ) -> Result<Option<File>> {
+        if self.acked_protocol_features & VhostUserProtocolFeatures::DEVICE_STATE.bits() == 0 {
+            return Err(VhostUserError::InvalidOperation);
         }
-    }
-
-    /// Wake the device up.
-    pub fn wake(&self) -> Result<()> {
-        let hdr = self.send_request_header(FrontendReq::WAKE, None)?;
-        let reply = self.recv_reply::<VhostUserSuccess>(&hdr)?;
-        if !reply.success() {
-            Err(VhostUserError::WakeError(anyhow!(
-                "Device process responded with a failure on WAKE."
-            )))
-        } else {
-            Ok(())
+        // Send request.
+        let req = DeviceStateTransferParameters {
+            transfer_direction: match transfer_direction {
+                VhostUserTransferDirection::Save => 0,
+                VhostUserTransferDirection::Load => 1,
+            },
+            migration_phase: match migration_phase {
+                VhostUserMigrationPhase::Stopped => 0,
+            },
+        };
+        let hdr = self.send_request_with_body(
+            FrontendReq::SET_DEVICE_STATE_FD,
+            &req,
+            Some(&[fd.as_raw_descriptor()]),
+        )?;
+        // Receive reply.
+        let (reply, files) = self.recv_reply_with_files::<VhostUserU64>(&hdr)?;
+        let has_err = reply.value & 0xff != 0;
+        let invalid_fd = reply.value & 0x100 != 0;
+        if has_err {
+            return Err(VhostUserError::BackendInternalError);
         }
-    }
-
-    /// Snapshot the device and receive serialized state of the device.
-    pub fn snapshot(&self) -> Result<Vec<u8>> {
-        let hdr = self.send_request_header(FrontendReq::SNAPSHOT, None)?;
-        let (success_msg, buf_reply, _) = self.recv_reply_with_payload::<VhostUserSuccess>(&hdr)?;
-        if !success_msg.success() {
-            Err(VhostUserError::SnapshotError(anyhow!(
-                "Device process responded with a failure on SNAPSHOT."
-            )))
-        } else {
-            Ok(buf_reply)
+        match (invalid_fd, files.len()) {
+            (true, 0) => Ok(None),
+            (false, 1) => Ok(files.into_iter().next()),
+            _ => Err(VhostUserError::IncorrectFds),
         }
     }
 
-    /// Restore the device.
-    pub fn restore(&mut self, data_bytes: &[u8], queue_evts: Option<Vec<Event>>) -> Result<()> {
-        let body = VhostUserEmptyMsg;
-
-        let queue_evt_fds: Option<Vec<RawDescriptor>> = queue_evts.as_ref().map(|queue_evts| {
-            queue_evts
-                .iter()
-                .map(|queue_evt| queue_evt.as_raw_descriptor())
-                .collect()
-        });
-
-        let hdr = self.send_request_with_payload(
-            FrontendReq::RESTORE,
-            &body,
-            data_bytes,
-            queue_evt_fds.as_deref(),
-        )?;
-        let reply = self.recv_reply::<VhostUserSuccess>(&hdr)?;
-        if !reply.success() {
-            Err(VhostUserError::RestoreError(anyhow!(
-                "Device process responded with a failure on RESTORE."
-            )))
-        } else {
-            Ok(())
+    /// After transferring the back-ends internal state during migration, check whether the
+    /// back-end was able to successfully fully process the state.
+    pub fn check_device_state(&self) -> Result<()> {
+        if self.acked_protocol_features & VhostUserProtocolFeatures::DEVICE_STATE.bits() == 0 {
+            return Err(VhostUserError::InvalidOperation);
         }
+        let hdr = self.send_request_header(FrontendReq::CHECK_DEVICE_STATE, None)?;
+        let reply = self.recv_reply::<VhostUserU64>(&hdr)?;
+        if reply.value != 0 {
+            return Err(VhostUserError::BackendInternalError);
+        }
+        Ok(())
     }
 
     /// Get the protocol feature bitmask from the underlying vhost implementation.
@@ -319,12 +272,7 @@ impl BackendClient {
         }
         let hdr = self.send_request_header(FrontendReq::GET_PROTOCOL_FEATURES, None)?;
         let val = self.recv_reply::<VhostUserU64>(&hdr)?;
-        // Should we support forward compatibility?
-        // If so just mask out unrecognized flags instead of return errors.
-        match VhostUserProtocolFeatures::from_bits(val.value) {
-            Some(val) => Ok(val),
-            None => Err(VhostUserError::InvalidMessage),
-        }
+        Ok(VhostUserProtocolFeatures::from_bits_truncate(val.value))
     }
 
     /// Enable protocol features in the underlying vhost implementation.
@@ -642,7 +590,7 @@ impl BackendClient {
         }
 
         let (reply, body, files) = self.connection.recv_message::<T>()?;
-        if !reply.is_reply_for(hdr) || files.is_empty() || !body.is_valid() {
+        if !reply.is_reply_for(hdr) || !body.is_valid() {
             return Err(VhostUserError::InvalidMessage);
         }
         Ok((body, files))
@@ -724,9 +672,15 @@ mod tests {
     use tempfile::tempfile;
 
     use super::*;
-    use crate::tests::create_pair;
 
     const BUFFER_SIZE: usize = 0x1001;
+    const INVALID_PROTOCOL_FEATURE: u64 = 1 << 63;
+
+    fn create_pair() -> (BackendClient, Connection<FrontendReq>) {
+        let (client_connection, server_connection) = Connection::pair().unwrap();
+        let backend_client = BackendClient::new(client_connection);
+        (backend_client, server_connection)
+    }
 
     #[test]
     fn create_backend_client() {
@@ -815,7 +769,8 @@ mod tests {
 
         let pfeatures = VhostUserProtocolFeatures::all();
         let hdr = VhostUserMsgHeader::new(FrontendReq::GET_PROTOCOL_FEATURES, 0x4, 8);
-        let msg = VhostUserU64::new(pfeatures.bits());
+        // Unknown feature bits should be ignored.
+        let msg = VhostUserU64::new(pfeatures.bits() | INVALID_PROTOCOL_FEATURE);
         peer.send_message(&hdr, &msg, None).unwrap();
         let features = backend_client.get_protocol_features().unwrap();
         assert_eq!(features, pfeatures);
diff --git a/third_party/vmm_vhost/src/backend_server.rs b/third_party/vmm_vhost/src/backend_server.rs
index 29e4acc49..a527d35fc 100644
--- a/third_party/vmm_vhost/src/backend_server.rs
+++ b/third_party/vmm_vhost/src/backend_server.rs
@@ -4,22 +4,20 @@
 use std::fs::File;
 use std::mem;
 
-use base::error;
 use base::AsRawDescriptor;
 use base::RawDescriptor;
+use base::SafeDescriptor;
 use zerocopy::AsBytes;
 use zerocopy::FromBytes;
 use zerocopy::Ref;
 
 use crate::into_single_file;
 use crate::message::*;
-use crate::to_system_stream;
 use crate::BackendReq;
 use crate::Connection;
 use crate::Error;
 use crate::FrontendReq;
 use crate::Result;
-use crate::SystemStream;
 
 /// Trait for vhost-user backends.
 ///
@@ -69,15 +67,14 @@ pub trait Backend {
     fn get_max_mem_slots(&mut self) -> Result<u64>;
     fn add_mem_region(&mut self, region: &VhostUserSingleMemoryRegion, fd: File) -> Result<()>;
     fn remove_mem_region(&mut self, region: &VhostUserSingleMemoryRegion) -> Result<()>;
+    fn set_device_state_fd(
+        &mut self,
+        transfer_direction: VhostUserTransferDirection,
+        migration_phase: VhostUserMigrationPhase,
+        fd: File,
+    ) -> Result<Option<File>>;
+    fn check_device_state(&mut self) -> Result<()>;
     fn get_shared_memory_regions(&mut self) -> Result<Vec<VhostSharedMemoryRegion>>;
-    /// Request the device to sleep by stopping their workers. This should NOT be called if the
-    /// device is already asleep.
-    fn sleep(&mut self) -> Result<()>;
-    /// Request the device to wake up by starting up their workers. This should NOT be called if the
-    /// device is already awake.
-    fn wake(&mut self) -> Result<()>;
-    fn snapshot(&mut self) -> Result<Vec<u8>>;
-    fn restore(&mut self, data_bytes: &[u8], queue_evts: Vec<File>) -> Result<()>;
 }
 
 impl<T> Backend for T
@@ -197,24 +194,22 @@ where
         self.as_mut().remove_mem_region(region)
     }
 
-    fn get_shared_memory_regions(&mut self) -> Result<Vec<VhostSharedMemoryRegion>> {
-        self.as_mut().get_shared_memory_regions()
-    }
-
-    fn sleep(&mut self) -> Result<()> {
-        self.as_mut().sleep()
-    }
-
-    fn wake(&mut self) -> Result<()> {
-        self.as_mut().wake()
+    fn set_device_state_fd(
+        &mut self,
+        transfer_direction: VhostUserTransferDirection,
+        migration_phase: VhostUserMigrationPhase,
+        fd: File,
+    ) -> Result<Option<File>> {
+        self.as_mut()
+            .set_device_state_fd(transfer_direction, migration_phase, fd)
     }
 
-    fn snapshot(&mut self) -> Result<Vec<u8>> {
-        self.as_mut().snapshot()
+    fn check_device_state(&mut self) -> Result<()> {
+        self.as_mut().check_device_state()
     }
 
-    fn restore(&mut self, data_bytes: &[u8], queue_evts: Vec<File>) -> Result<()> {
-        self.as_mut().restore(data_bytes, queue_evts)
+    fn get_shared_memory_regions(&mut self) -> Result<Vec<VhostSharedMemoryRegion>> {
+        self.as_mut().get_shared_memory_regions()
     }
 }
 
@@ -234,13 +229,6 @@ pub struct BackendServer<S: Backend> {
     reply_ack_enabled: bool,
 }
 
-impl<S: Backend> BackendServer<S> {
-    /// Create a backend server from a connected socket.
-    pub fn from_stream(socket: SystemStream, backend: S) -> Self {
-        Self::new(Connection::from(socket), backend)
-    }
-}
-
 impl<S: Backend> AsRef<S> for BackendServer<S> {
     fn as_ref(&self) -> &S {
         &self.backend
@@ -350,12 +338,12 @@ impl<S: Backend> BackendServer<S> {
     /// See [`BackendServer::recv_header`]'s doc comment for the usage.
     ///
     /// # Return:
-    /// * - `Ok(())`: one request was successfully handled.
-    /// * - `Err(ClientExit)`: the frontend closed the connection properly. This isn't an actual
+    /// * `Ok(())`: one request was successfully handled.
+    /// * `Err(ClientExit)`: the frontend closed the connection properly. This isn't an actual
     ///   failure.
-    /// * - `Err(Disconnect)`: the connection was closed unexpectedly.
-    /// * - `Err(InvalidMessage)`: the vmm sent a illegal message.
-    /// * - other errors: failed to handle a request.
+    /// * `Err(Disconnect)`: the connection was closed unexpectedly.
+    /// * `Err(InvalidMessage)`: the vmm sent a illegal message.
+    /// * other errors: failed to handle a request.
     pub fn process_message(
         &mut self,
         hdr: VhostUserMsgHeader<FrontendReq>,
@@ -364,6 +352,9 @@ impl<S: Backend> BackendServer<S> {
         let buf = self.connection.recv_body_bytes(&hdr)?;
         let size = buf.len();
 
+        // TODO: The error handling here is inconsistent. Sometimes we report the error to the
+        // client and keep going, sometimes we report the error and then close the connection,
+        // sometimes we just close the connection.
         match hdr.get_code() {
             Ok(FrontendReq::SET_OWNER) => {
                 self.check_request_size(&hdr, size, 0)?;
@@ -599,6 +590,57 @@ impl<S: Backend> BackendServer<S> {
                 self.send_ack_message(&hdr, res.is_ok())?;
                 res?;
             }
+            Ok(FrontendReq::SET_DEVICE_STATE_FD) => {
+                if self.acked_protocol_features & VhostUserProtocolFeatures::DEVICE_STATE.bits()
+                    == 0
+                {
+                    return Err(Error::InvalidOperation);
+                }
+                // Read request.
+                let msg =
+                    self.extract_request_body::<DeviceStateTransferParameters>(&hdr, size, &buf)?;
+                let transfer_direction = match msg.transfer_direction {
+                    0 => VhostUserTransferDirection::Save,
+                    1 => VhostUserTransferDirection::Load,
+                    _ => return Err(Error::InvalidMessage),
+                };
+                let migration_phase = match msg.migration_phase {
+                    0 => VhostUserMigrationPhase::Stopped,
+                    _ => return Err(Error::InvalidMessage),
+                };
+                // Call backend.
+                let res = self.backend.set_device_state_fd(
+                    transfer_direction,
+                    migration_phase,
+                    files.into_iter().next().ok_or(Error::IncorrectFds)?,
+                );
+                // Send response.
+                let (msg, fds) = match &res {
+                    Ok(None) => (VhostUserU64::new(0x100), None),
+                    Ok(Some(file)) => (VhostUserU64::new(0), Some(file.as_raw_descriptor())),
+                    // Just in case, set the "invalid FD" flag on error.
+                    Err(_) => (VhostUserU64::new(0x101), None),
+                };
+                let reply_hdr: VhostUserMsgHeader<FrontendReq> =
+                    self.new_reply_header::<VhostUserU64>(&hdr, 0)?;
+                self.connection.send_message(
+                    &reply_hdr,
+                    &msg,
+                    fds.as_ref().map(std::slice::from_ref),
+                )?;
+                res?;
+            }
+            Ok(FrontendReq::CHECK_DEVICE_STATE) => {
+                if self.acked_protocol_features & VhostUserProtocolFeatures::DEVICE_STATE.bits()
+                    == 0
+                {
+                    return Err(Error::InvalidOperation);
+                }
+                let res = self.backend.check_device_state();
+                let msg = VhostUserU64::new(if res.is_ok() { 0 } else { 1 });
+                self.send_reply_message(&hdr, &msg)?;
+                res?;
+            }
             Ok(FrontendReq::GET_SHARED_MEMORY_REGIONS) => {
                 let regions = self.backend.get_shared_memory_regions()?;
                 let mut buf = Vec::new();
@@ -608,31 +650,6 @@ impl<S: Backend> BackendServer<S> {
                 }
                 self.send_reply_with_payload(&hdr, &msg, buf.as_slice())?;
             }
-            Ok(FrontendReq::SLEEP) => {
-                let res = self.backend.sleep();
-                let msg = VhostUserSuccess::new(res.is_ok());
-                self.send_reply_message(&hdr, &msg)?;
-            }
-            Ok(FrontendReq::WAKE) => {
-                let res = self.backend.wake();
-                let msg = VhostUserSuccess::new(res.is_ok());
-                self.send_reply_message(&hdr, &msg)?;
-            }
-            Ok(FrontendReq::SNAPSHOT) => {
-                let (success_msg, payload) = match self.backend.snapshot() {
-                    Ok(snapshot_payload) => (VhostUserSuccess::new(true), snapshot_payload),
-                    Err(e) => {
-                        error!("Failed to snapshot: {}", e);
-                        (VhostUserSuccess::new(false), Vec::new())
-                    }
-                };
-                self.send_reply_with_payload(&hdr, &success_msg, payload.as_slice())?;
-            }
-            Ok(FrontendReq::RESTORE) => {
-                let res = self.backend.restore(buf.as_slice(), files);
-                let msg = VhostUserSuccess::new(res.is_ok());
-                self.send_reply_message(&hdr, &msg)?;
-            }
             _ => {
                 return Err(Error::InvalidMessage);
             }
@@ -786,11 +803,9 @@ impl<S: Backend> BackendServer<S> {
 
     fn set_backend_req_fd(&mut self, files: Vec<File>) -> Result<()> {
         let file = into_single_file(files).ok_or(Error::InvalidMessage)?;
-        let fd = file.into();
-        // SAFETY: Safe because the protocol promises the file represents the appropriate file type
-        // for the platform.
-        let stream = unsafe { to_system_stream(fd) }?;
-        self.backend.set_backend_req_fd(Connection::from(stream));
+        let fd: SafeDescriptor = file.into();
+        let connection = Connection::try_from(fd).map_err(|_| Error::InvalidMessage)?;
+        self.backend.set_backend_req_fd(connection);
         Ok(())
     }
 
@@ -853,8 +868,8 @@ impl<S: Backend> BackendServer<S> {
             | Ok(FrontendReq::SET_LOG_FD)
             | Ok(FrontendReq::SET_BACKEND_REQ_FD)
             | Ok(FrontendReq::SET_INFLIGHT_FD)
-            | Ok(FrontendReq::RESTORE)
-            | Ok(FrontendReq::ADD_MEM_REG) => Ok(()),
+            | Ok(FrontendReq::ADD_MEM_REG)
+            | Ok(FrontendReq::SET_DEVICE_STATE_FD) => Ok(()),
             Err(_) => Err(Error::InvalidMessage),
             _ if !files.is_empty() => Err(Error::InvalidMessage),
             _ => Ok(()),
@@ -870,7 +885,7 @@ impl<S: Backend> BackendServer<S> {
         self.check_request_size(hdr, size, mem::size_of::<T>())?;
         T::read_from_prefix(buf)
             .filter(T::is_valid)
-            .map_or(Err(Error::InvalidMessage), Ok)
+            .ok_or(Error::InvalidMessage)
     }
 
     fn update_reply_ack_flag(&mut self) {
@@ -895,14 +910,12 @@ mod tests {
     use super::*;
     use crate::test_backend::TestBackend;
     use crate::Connection;
-    use crate::SystemStream;
 
     #[test]
     fn test_backend_server_new() {
-        let (p1, _p2) = SystemStream::pair().unwrap();
-        let connection = Connection::from(p1);
+        let (p1, _p2) = Connection::pair().unwrap();
         let backend = TestBackend::new();
-        let handler = BackendServer::new(connection, backend);
+        let handler = BackendServer::new(p1, backend);
 
         assert!(handler.as_raw_descriptor() != INVALID_DESCRIPTOR);
     }
diff --git a/third_party/vmm_vhost/src/connection.rs b/third_party/vmm_vhost/src/connection.rs
index 4824a85e5..26e652c5a 100644
--- a/third_party/vmm_vhost/src/connection.rs
+++ b/third_party/vmm_vhost/src/connection.rs
@@ -6,7 +6,6 @@
 use std::fs::File;
 use std::io::IoSliceMut;
 use std::mem;
-use std::path::Path;
 
 use base::AsRawDescriptor;
 use base::RawDescriptor;
@@ -19,7 +18,6 @@ use crate::message::*;
 use crate::sys::PlatformConnection;
 use crate::Error;
 use crate::Result;
-use crate::SystemStream;
 
 /// Listener for accepting connections.
 pub trait Listener: Sized {
@@ -58,32 +56,13 @@ fn advance_slices_mut(bufs: &mut &mut [&mut [u8]], mut count: usize) {
 /// bytes and file descriptors (a thin cross-platform abstraction for unix domain sockets).
 pub struct Connection<R: Req>(
     pub(crate) PlatformConnection,
-    std::marker::PhantomData<R>,
+    pub(crate) std::marker::PhantomData<R>,
     // Mark `Connection` as `!Sync` because message sends and recvs cannot safely be done
     // concurrently.
-    std::marker::PhantomData<std::cell::Cell<()>>,
+    pub(crate) std::marker::PhantomData<std::cell::Cell<()>>,
 );
 
-impl<R: Req> From<SystemStream> for Connection<R> {
-    fn from(sock: SystemStream) -> Self {
-        Self(
-            PlatformConnection::from(sock),
-            std::marker::PhantomData,
-            std::marker::PhantomData,
-        )
-    }
-}
-
 impl<R: Req> Connection<R> {
-    /// Create a new stream by connecting to server at `path`.
-    pub fn connect<P: AsRef<Path>>(path: P) -> Result<Self> {
-        Ok(Self(
-            PlatformConnection::connect(path)?,
-            std::marker::PhantomData,
-            std::marker::PhantomData,
-        ))
-    }
-
     /// Sends a header-only message with optional attached file descriptors.
     pub fn send_header_only_message(
         &self,
@@ -251,11 +230,10 @@ pub(crate) mod tests {
     use super::*;
     use crate::message::VhostUserEmptyMessage;
     use crate::message::VhostUserU64;
-    use crate::tests::create_connection_pair;
 
     #[test]
     fn send_header_only() {
-        let (client_connection, server_connection) = create_connection_pair();
+        let (client_connection, server_connection) = Connection::pair().unwrap();
         let hdr1 = VhostUserMsgHeader::new(FrontendReq::GET_FEATURES, 0, 0);
         client_connection
             .send_header_only_message(&hdr1, None)
@@ -269,7 +247,7 @@ pub(crate) mod tests {
 
     #[test]
     fn send_data() {
-        let (client_connection, server_connection) = create_connection_pair();
+        let (client_connection, server_connection) = Connection::pair().unwrap();
         let hdr1 = VhostUserMsgHeader::new(FrontendReq::SET_FEATURES, 0, 8);
         client_connection
             .send_message(&hdr1, &VhostUserU64::new(0xf00dbeefdeadf00d), None)
@@ -283,7 +261,7 @@ pub(crate) mod tests {
 
     #[test]
     fn send_fd() {
-        let (client_connection, server_connection) = create_connection_pair();
+        let (client_connection, server_connection) = Connection::pair().unwrap();
 
         let mut fd = tempfile().unwrap();
         write!(fd, "test").unwrap();
diff --git a/third_party/vmm_vhost/src/frontend_client.rs b/third_party/vmm_vhost/src/frontend_client.rs
index f32dc70b8..593ec27ef 100644
--- a/third_party/vmm_vhost/src/frontend_client.rs
+++ b/third_party/vmm_vhost/src/frontend_client.rs
@@ -15,7 +15,6 @@ use crate::Error;
 use crate::Frontend;
 use crate::HandlerResult;
 use crate::Result;
-use crate::SystemStream;
 
 /// Client for a vhost-user frontend. Allows a backend to send requests to the frontend.
 pub struct FrontendClient {
@@ -38,11 +37,6 @@ impl FrontendClient {
         }
     }
 
-    /// Create a new instance from a `SystemStream` object.
-    pub fn from_stream(connection: SystemStream) -> Self {
-        Self::new(Connection::from(connection))
-    }
-
     fn send_message<T>(
         &mut self,
         request: BackendReq,
@@ -143,14 +137,12 @@ impl Frontend for FrontendClient {
 
 #[cfg(test)]
 mod tests {
-
     use super::*;
-    use crate::SystemStream;
 
     #[test]
     fn test_backend_req_set_failed() {
-        let (p1, _p2) = SystemStream::pair().unwrap();
-        let mut frontend_client = FrontendClient::from_stream(p1);
+        let (p1, _p2) = Connection::pair().unwrap();
+        let mut frontend_client = FrontendClient::new(p1);
 
         assert!(frontend_client.error.is_none());
         frontend_client.set_failed(libc::EAGAIN);
diff --git a/third_party/vmm_vhost/src/frontend_server.rs b/third_party/vmm_vhost/src/frontend_server.rs
index 49730834f..57acaaa30 100644
--- a/third_party/vmm_vhost/src/frontend_server.rs
+++ b/third_party/vmm_vhost/src/frontend_server.rs
@@ -12,7 +12,6 @@ use crate::Connection;
 use crate::Error;
 use crate::HandlerResult;
 use crate::Result;
-use crate::SystemStream;
 
 /// Trait for vhost-user frontends to respond to requests from the backend.
 ///
@@ -67,10 +66,10 @@ pub struct FrontendServer<S: Frontend> {
 }
 
 impl<S: Frontend> FrontendServer<S> {
-    /// Create a server to handle requests from `stream`.
-    pub(crate) fn new(frontend: S, stream: SystemStream) -> Result<Self> {
+    /// Create a server to handle requests from `connection`.
+    pub(crate) fn new(frontend: S, connection: Connection<BackendReq>) -> Result<Self> {
         Ok(FrontendServer {
-            sub_sock: Connection::from(stream),
+            sub_sock: connection,
             reply_ack_negotiated: false,
             frontend,
         })
diff --git a/third_party/vmm_vhost/src/lib.rs b/third_party/vmm_vhost/src/lib.rs
index 5c36f42d0..8e4c711e9 100644
--- a/third_party/vmm_vhost/src/lib.rs
+++ b/third_party/vmm_vhost/src/lib.rs
@@ -49,8 +49,8 @@ mod sys;
 pub use connection::Connection;
 pub use message::BackendReq;
 pub use message::FrontendReq;
-pub use sys::SystemStream;
-pub use sys::*;
+#[cfg(unix)]
+pub use sys::unix;
 
 pub(crate) mod backend_client;
 pub use backend_client::BackendClient;
@@ -80,6 +80,8 @@ pub enum Error {
     /// If connection is closed properly, use `ClientExit` instead.
     #[error("client closed the connection")]
     Disconnect,
+    #[error("Failed to enter suspended state")]
+    EnterSuspendedState(anyhow::Error),
     /// Virtio/protocol features mismatch.
     #[error("virtio features mismatch")]
     FeatureMismatch,
@@ -139,6 +141,9 @@ pub enum Error {
     /// Generic socket errors.
     #[error("socket error: {0}")]
     SocketError(std::io::Error),
+    /// Fail to get socket from the fd
+    #[error("Failed get socket from the fd: {0}")]
+    SocketFromFdError(std::path::PathBuf),
     /// Should retry the socket operation again.
     #[error("temporary socket error: {0}")]
     SocketRetry(std::io::Error),
@@ -242,14 +247,23 @@ mod tests {
 
     use super::*;
     use crate::message::*;
-    pub(crate) use crate::sys::tests::create_client_server_pair;
-    pub(crate) use crate::sys::tests::create_connection_pair;
-    pub(crate) use crate::sys::tests::create_pair;
     use crate::test_backend::TestBackend;
     use crate::test_backend::VIRTIO_FEATURES;
     use crate::VhostUserMemoryRegionInfo;
     use crate::VringConfigData;
 
+    fn create_client_server_pair<S>(backend: S) -> (BackendClient, BackendServer<S>)
+    where
+        S: Backend,
+    {
+        let (client_connection, server_connection) = Connection::pair().unwrap();
+        let backend_client = BackendClient::new(client_connection);
+        (
+            backend_client,
+            BackendServer::<S>::new(server_connection, backend),
+        )
+    }
+
     /// Utility function to process a header and a message together.
     fn handle_request(h: &mut BackendServer<TestBackend>) -> Result<()> {
         // We assume that a header comes together with message body in tests so we don't wait before
diff --git a/third_party/vmm_vhost/src/message.rs b/third_party/vmm_vhost/src/message.rs
index 7f50c0813..9f555d891 100644
--- a/third_party/vmm_vhost/src/message.rs
+++ b/third_party/vmm_vhost/src/message.rs
@@ -144,16 +144,22 @@ pub enum FrontendReq {
     /// Query the backend for its device status as defined in the VIRTIO
     /// specification.
     GET_STATUS = 40,
+    /// Front-end and back-end negotiate a channel over which to transfer the back-ends internal
+    /// state during migration.
+    SET_DEVICE_STATE_FD = 42,
+    /// After transferring the back-ends internal state during migration, check whether the
+    /// back-end was able to successfully fully process the state.
+    CHECK_DEVICE_STATE = 43,
 
     // Non-standard message types.
     /// Stop all queue handlers and save each queue state.
-    SLEEP = 1000,
+    DEPRECATED__SLEEP = 1000,
     /// Start up all queue handlers with their saved queue state.
-    WAKE = 1001,
+    DEPRECATED__WAKE = 1001,
     /// Request serialized state of vhost process.
-    SNAPSHOT = 1002,
+    DEPRECATED__SNAPSHOT = 1002,
     /// Request to restore state of vhost process.
-    RESTORE = 1003,
+    DEPRECATED__RESTORE = 1003,
     /// Get a list of the device's shared memory regions.
     GET_SHARED_MEMORY_REGIONS = 1004,
 }
@@ -441,13 +447,15 @@ bitflags! {
         const STATUS = 0x0001_0000;
         /// Support Xen mmap.
         const XEN_MMAP = 0x0002_0000;
+        /// Support VHOST_USER_SET_DEVICE_STATE_FD and VHOST_USER_CHECK_DEVICE_STATE messages.
+        const DEVICE_STATE = 0x0008_0000;
         /// Support shared memory regions. (Non-standard.)
         const SHARED_MEMORY_REGIONS = 0x8000_0000;
     }
 }
 
 /// A generic message to encapsulate a 64-bit value.
-#[repr(packed)]
+#[repr(C, packed)]
 #[derive(Default, Clone, Copy, AsBytes, FromZeroes, FromBytes)]
 pub struct VhostUserU64 {
     /// The encapsulated 64-bit common value.
@@ -470,33 +478,6 @@ pub struct VhostUserEmptyMsg;
 
 impl VhostUserMsgValidator for VhostUserEmptyMsg {}
 
-/// A generic message to encapsulate a success or failure.
-/// use i8 instead of bool to allow FromBytes to be derived.
-/// type layout is same for all supported architectures.
-#[repr(C, packed)]
-#[derive(Default, Clone, Copy, AsBytes, FromZeroes, FromBytes)]
-pub struct VhostUserSuccess {
-    /// True if request was successful.
-    bool_store: i8,
-}
-
-impl VhostUserSuccess {
-    /// Create a new instance.
-    pub fn new(success: bool) -> Self {
-        VhostUserSuccess {
-            bool_store: success.into(),
-        }
-    }
-
-    /// Convert i8 storage back to bool
-    #[inline(always)]
-    pub fn success(&self) -> bool {
-        self.bool_store != 0
-    }
-}
-
-impl VhostUserMsgValidator for VhostUserSuccess {}
-
 /// A generic message for empty message.
 /// ZST in repr(C) has same type layout as repr(rust)
 #[repr(C)]
@@ -623,7 +604,7 @@ impl VhostUserMsgValidator for VhostUserSingleMemoryRegion {
 }
 
 /// Vring state descriptor.
-#[repr(packed)]
+#[repr(C, packed)]
 #[derive(Default, Clone, Copy, AsBytes, FromZeroes, FromBytes)]
 pub struct VhostUserVringState {
     /// Vring index.
@@ -735,7 +716,7 @@ bitflags! {
 }
 
 /// Message to read/write device configuration space.
-#[repr(packed)]
+#[repr(C, packed)]
 #[derive(Default, Clone, Copy, AsBytes, FromZeroes, FromBytes)]
 pub struct VhostUserConfig {
     /// Offset of virtio device's configuration space.
@@ -818,9 +799,26 @@ impl VhostUserMsgValidator for VhostUserInflight {
     }
 }
 
+/// VHOST_USER_SET_DEVICE_STATE_FD request payload.
+#[repr(C)]
+#[derive(Default, Clone, Copy, AsBytes, FromZeroes, FromBytes)]
+pub struct DeviceStateTransferParameters {
+    /// Direction in which the state is transferred
+    pub transfer_direction: u32,
+    /// State in which the VM guest and devices are.
+    pub migration_phase: u32,
+}
+
+impl VhostUserMsgValidator for DeviceStateTransferParameters {
+    fn is_valid(&self) -> bool {
+        // Validated elsewhere.
+        true
+    }
+}
+
 /*
  * TODO: support dirty log, live migration and IOTLB operations.
-#[repr(packed)]
+#[repr(C, packed)]
 pub struct VhostUserVringArea {
     pub index: u32,
     pub flags: u32,
@@ -828,13 +826,13 @@ pub struct VhostUserVringArea {
     pub offset: u64,
 }
 
-#[repr(packed)]
+#[repr(C, packed)]
 pub struct VhostUserLog {
     pub size: u64,
     pub offset: u64,
 }
 
-#[repr(packed)]
+#[repr(C, packed)]
 pub struct VhostUserIotlb {
     pub iova: u64,
     pub size: u64,
@@ -1057,7 +1055,7 @@ impl VhostUserShmemUnmapMsg {
 }
 
 /// Inflight I/O descriptor state for split virtqueues
-#[repr(packed)]
+#[repr(C, packed)]
 #[derive(Clone, Copy, Default)]
 pub struct DescStateSplit {
     /// Indicate whether this descriptor (only head) is inflight or not.
@@ -1078,7 +1076,7 @@ impl DescStateSplit {
 }
 
 /// Inflight I/O queue region for split virtqueues
-#[repr(packed)]
+#[repr(C, packed)]
 pub struct QueueRegionSplit {
     /// Features flags of this region
     pub features: u64,
@@ -1109,7 +1107,7 @@ impl QueueRegionSplit {
 }
 
 /// Inflight I/O descriptor state for packed virtqueues
-#[repr(packed)]
+#[repr(C, packed)]
 #[derive(Clone, Copy, Default)]
 pub struct DescStatePacked {
     /// Indicate whether this descriptor (only head) is inflight or not.
@@ -1142,7 +1140,7 @@ impl DescStatePacked {
 }
 
 /// Inflight I/O queue region for packed virtqueues
-#[repr(packed)]
+#[repr(C, packed)]
 pub struct QueueRegionPacked {
     /// Features flags of this region
     pub features: u64,
@@ -1188,7 +1186,7 @@ impl QueueRegionPacked {
 }
 
 /// Virtio shared memory descriptor.
-#[repr(packed)]
+#[repr(C, packed)]
 #[derive(Default, Copy, Clone, FromZeroes, FromBytes, AsBytes)]
 pub struct VhostSharedMemoryRegion {
     /// The shared memory region's shmid.
@@ -1210,6 +1208,17 @@ impl VhostSharedMemoryRegion {
     }
 }
 
+#[derive(Debug, PartialEq, Eq)]
+pub enum VhostUserTransferDirection {
+    Save,
+    Load,
+}
+
+#[derive(Debug, PartialEq, Eq)]
+pub enum VhostUserMigrationPhase {
+    Stopped,
+}
+
 #[cfg(test)]
 mod tests {
     use super::*;
diff --git a/third_party/vmm_vhost/src/sys.rs b/third_party/vmm_vhost/src/sys.rs
index 8229c5923..c22e24691 100644
--- a/third_party/vmm_vhost/src/sys.rs
+++ b/third_party/vmm_vhost/src/sys.rs
@@ -15,13 +15,4 @@ cfg_if::cfg_if! {
     }
 }
 
-pub use platform::to_system_stream;
 pub(crate) use platform::PlatformConnection;
-pub use platform::SystemStream;
-
-#[cfg(test)]
-pub(crate) mod tests {
-    pub(crate) use super::platform::tests::create_client_server_pair;
-    pub(crate) use super::platform::tests::create_connection_pair;
-    pub(crate) use super::platform::tests::create_pair;
-}
diff --git a/third_party/vmm_vhost/src/sys/unix.rs b/third_party/vmm_vhost/src/sys/unix.rs
index 7475cc8e3..035e633c4 100644
--- a/third_party/vmm_vhost/src/sys/unix.rs
+++ b/third_party/vmm_vhost/src/sys/unix.rs
@@ -22,6 +22,7 @@ use base::ScmSocket;
 use crate::connection::Listener;
 use crate::frontend_server::FrontendServer;
 use crate::message::FrontendReq;
+use crate::message::Req;
 use crate::message::MAX_ATTACHED_FD_ENTRIES;
 use crate::Connection;
 use crate::Error;
@@ -31,9 +32,6 @@ use crate::Result;
 /// Alias to enable platform independent code.
 pub type SystemListener = UnixListener;
 
-/// Alias to enable platform independent code.
-pub type SystemStream = UnixStream;
-
 pub use SocketPlatformConnection as PlatformConnection;
 
 /// Unix domain socket listener for accepting incoming connections.
@@ -90,7 +88,7 @@ impl Listener for SocketListener {
         loop {
             match self.fd.accept() {
                 Ok((stream, _addr)) => {
-                    return Ok(Some(Connection::from(stream)));
+                    return Ok(Some(Connection::try_from(stream)?));
                 }
                 Err(e) => {
                     match e.kind() {
@@ -125,16 +123,7 @@ impl AsRawDescriptor for SocketListener {
 
 /// Unix domain socket based vhost-user connection.
 pub struct SocketPlatformConnection {
-    sock: ScmSocket<SystemStream>,
-}
-
-// TODO: Switch to TryFrom to avoid the unwrap.
-impl From<SystemStream> for SocketPlatformConnection {
-    fn from(sock: SystemStream) -> Self {
-        Self {
-            sock: sock.try_into().unwrap(),
-        }
-    }
+    sock: ScmSocket<UnixStream>,
 }
 
 // Advance the internal cursor of the slices.
@@ -157,16 +146,6 @@ fn advance_slices(bufs: &mut &mut [&[u8]], mut count: usize) {
 }
 
 impl SocketPlatformConnection {
-    /// Create a new stream by connecting to server at `str`.
-    ///
-    /// # Return:
-    /// * - the new SocketPlatformConnection object on success.
-    /// * - SocketConnect: failed to connect to peer.
-    pub fn connect<P: AsRef<Path>>(path: P) -> Result<Self> {
-        let sock = SystemStream::connect(path).map_err(Error::SocketConnect)?;
-        Ok(Self::from(sock))
-    }
-
     /// Sends all bytes from scatter-gather vectors with optional attached file descriptors. Will
     /// loop until all data has been transfered.
     ///
@@ -224,6 +203,7 @@ impl SocketPlatformConnection {
     /// attached file descriptors, the receiver must obey following rules:
     ///   1) file descriptors are attached to a message.
     ///   2) message(packet) boundaries must be respected on the receive side.
+    ///
     /// In other words, recvmsg() operations must not cross the packet boundary, otherwise the
     /// attached file descriptors will get lost.
     /// Note that this function wraps received file descriptors as `File`.
@@ -263,19 +243,36 @@ impl AsRawDescriptor for SocketPlatformConnection {
     }
 }
 
-impl AsMut<SystemStream> for SocketPlatformConnection {
-    fn as_mut(&mut self) -> &mut SystemStream {
-        self.sock.inner_mut()
+impl<R: Req> TryFrom<SafeDescriptor> for Connection<R> {
+    type Error = Error;
+
+    fn try_from(fd: SafeDescriptor) -> Result<Self> {
+        UnixStream::from(fd).try_into()
     }
 }
 
-/// Convert a `SafeDescriptor` to a `UnixStream`.
-///
-/// # Safety
-///
-/// `file` must represent a unix domain socket.
-pub unsafe fn to_system_stream(fd: SafeDescriptor) -> Result<SystemStream> {
-    Ok(fd.into())
+impl<R: Req> TryFrom<UnixStream> for Connection<R> {
+    type Error = Error;
+
+    fn try_from(sock: UnixStream) -> Result<Self> {
+        Ok(Self(
+            SocketPlatformConnection {
+                sock: sock.try_into()?,
+            },
+            std::marker::PhantomData,
+            std::marker::PhantomData,
+        ))
+    }
+}
+
+impl<R: Req> Connection<R> {
+    /// Create a pair of unnamed vhost-user connections connected to each other.
+    pub fn pair() -> Result<(Self, Self)> {
+        let (client, server) = UnixStream::pair()?;
+        let client_connection = Connection::try_from(client)?;
+        let server_connection = Connection::try_from(server)?;
+        Ok((client_connection, server_connection))
+    }
 }
 
 impl<S: Frontend> AsRawDescriptor for FrontendServer<S> {
@@ -293,9 +290,10 @@ impl<S: Frontend> FrontendServer<S> {
     ///
     /// [BackendClient::set_slave_request_fd()]: struct.BackendClient.html#method.set_slave_request_fd
     pub fn with_stream(backend: S) -> Result<(Self, SafeDescriptor)> {
-        let (tx, rx) = SystemStream::pair()?;
+        let (tx, rx) = UnixStream::pair()?;
+        let rx_connection = Connection::try_from(rx)?;
         Ok((
-            Self::new(backend, rx)?,
+            Self::new(backend, rx_connection)?,
             SafeDescriptor::from(OwnedFd::from(tx)),
         ))
     }
@@ -308,8 +306,6 @@ pub(crate) mod tests {
 
     use super::*;
     use crate::backend_client::BackendClient;
-    use crate::backend_server::Backend;
-    use crate::backend_server::BackendServer;
     use crate::connection::Listener;
     use crate::message::FrontendReq;
     use crate::Connection;
@@ -318,40 +314,9 @@ pub(crate) mod tests {
         Builder::new().prefix("/tmp/vhost_test").tempdir().unwrap()
     }
 
-    pub(crate) fn create_pair() -> (BackendClient, Connection<FrontendReq>) {
-        let dir = temp_dir();
-        let mut path = dir.path().to_owned();
-        path.push("sock");
-        let mut listener = SocketListener::new(&path, true).unwrap();
-        listener.set_nonblocking(true).unwrap();
-        let backend_client = BackendClient::connect(path).unwrap();
-        let server_connection = listener.accept().unwrap().unwrap();
-        (backend_client, server_connection)
-    }
-
-    pub(crate) fn create_connection_pair() -> (Connection<FrontendReq>, Connection<FrontendReq>) {
-        let dir = temp_dir();
-        let mut path = dir.path().to_owned();
-        path.push("sock");
-        let mut listener = SocketListener::new(&path, true).unwrap();
-        listener.set_nonblocking(true).unwrap();
-        let client_connection = Connection::<FrontendReq>::connect(path).unwrap();
-        let server_connection = listener.accept().unwrap().unwrap();
-        (client_connection, server_connection)
-    }
-
-    pub(crate) fn create_client_server_pair<S>(backend: S) -> (BackendClient, BackendServer<S>)
-    where
-        S: Backend,
-    {
-        let dir = Builder::new().prefix("/tmp/vhost_test").tempdir().unwrap();
-        let mut path = dir.path().to_owned();
-        path.push("sock");
-        let mut listener = SocketListener::new(&path, true).unwrap();
-        let backend_client = BackendClient::connect(&path).unwrap();
-        let connection = listener.accept().unwrap().unwrap();
-        let req_handler = BackendServer::new(connection, backend);
-        (backend_client, req_handler)
+    fn connect(path: &Path) -> Result<Connection<FrontendReq>> {
+        let sock = UnixStream::connect(path).map_err(Error::SocketConnect)?;
+        Connection::try_from(sock)
     }
 
     #[test]
@@ -384,13 +349,14 @@ pub(crate) mod tests {
         path.push("sock");
         let _ = SocketListener::new(&path, true).unwrap();
         let _ = SocketListener::new(&path, false).is_err();
-        assert!(BackendClient::connect(&path).is_err());
+        assert!(connect(&path).is_err());
 
         let mut listener = SocketListener::new(&path, true).unwrap();
         assert!(SocketListener::new(&path, false).is_err());
         listener.set_nonblocking(true).unwrap();
 
-        let _backend_client = BackendClient::connect(&path).unwrap();
+        let backend_connection = connect(&path).unwrap();
+        let _backend_client = BackendClient::new(backend_connection);
         let _server_connection = listener.accept().unwrap().unwrap();
     }
 
diff --git a/third_party/vmm_vhost/src/sys/windows.rs b/third_party/vmm_vhost/src/sys/windows.rs
index 801dfb089..01ba3f0b3 100644
--- a/third_party/vmm_vhost/src/sys/windows.rs
+++ b/third_party/vmm_vhost/src/sys/windows.rs
@@ -6,7 +6,6 @@
 use std::cmp::min;
 use std::fs::File;
 use std::io::IoSliceMut;
-use std::path::Path;
 use std::ptr::copy_nonoverlapping;
 
 use base::AsRawDescriptor;
@@ -19,17 +18,15 @@ use base::Tube;
 use serde::Deserialize;
 use serde::Serialize;
 use tube_transporter::packed_tube;
+pub use TubePlatformConnection as PlatformConnection;
 
+use crate::message::Req;
+use crate::Connection;
 use crate::Error;
 use crate::Frontend;
 use crate::FrontendServer;
 use crate::Result;
 
-/// Alias to enable platform independent code.
-pub type SystemStream = Tube;
-
-pub use TubePlatformConnection as PlatformConnection;
-
 #[derive(Serialize, Deserialize)]
 struct RawDescriptorContainer {
     #[serde(with = "base::with_raw_descriptor")]
@@ -60,10 +57,6 @@ impl From<Tube> for TubePlatformConnection {
 }
 
 impl TubePlatformConnection {
-    pub fn connect<P: AsRef<Path>>(_path: P) -> Result<Self> {
-        unimplemented!("connections not supported on Tubes")
-    }
-
     /// Sends a single message over the socket with optional attached file descriptors.
     ///
     /// - `hdr`: vhost message header
@@ -172,15 +165,36 @@ impl TubePlatformConnection {
     }
 }
 
-/// Convert a`SafeDescriptor` to a `Tube`.
-///
-/// # Safety
-///
-/// `fd` must represent a packed tube.
-pub unsafe fn to_system_stream(fd: SafeDescriptor) -> Result<SystemStream> {
-    // SAFETY: Safe because the file represents a packed tube.
-    let tube = unsafe { packed_tube::unpack(fd).expect("unpacked Tube") };
-    Ok(tube)
+impl<R: Req> TryFrom<SafeDescriptor> for Connection<R> {
+    type Error = Error;
+
+    fn try_from(fd: SafeDescriptor) -> Result<Self> {
+        // SAFETY: Safe because the file represents a packed tube.
+        let tube = unsafe { packed_tube::unpack(fd).expect("unpacked Tube") };
+        Ok(tube.into())
+    }
+}
+
+impl<R: Req> From<Tube> for Connection<R> {
+    fn from(tube: Tube) -> Self {
+        Self(
+            PlatformConnection::from(tube),
+            std::marker::PhantomData,
+            std::marker::PhantomData,
+        )
+    }
+}
+
+impl<R: Req> Connection<R> {
+    /// Create a pair of unnamed vhost-user connections connected to each other.
+    pub fn pair() -> Result<(Self, Self)> {
+        let (client, server) = Tube::pair()?;
+        Ok((Self::from(client), Self::from(server)))
+    }
+
+    pub fn target_pid(&self) -> Option<u32> {
+        self.0.tube.target_pid()
+    }
 }
 
 impl AsRawDescriptor for TubePlatformConnection {
@@ -200,11 +214,12 @@ impl<S: Frontend> FrontendServer<S> {
     ///
     /// [BackendClient::set_slave_request_fd()]: struct.BackendClient.html#method.set_slave_request_fd
     pub fn with_tube(backend: S, backend_pid: u32) -> Result<(Self, SafeDescriptor)> {
-        let (tx, rx) = SystemStream::pair()?;
+        let (tx, rx) = Tube::pair()?;
+        let rx_connection = Connection::from(rx);
         // SAFETY:
         // Safe because we expect the tube to be unpacked in the other process.
         let tx = unsafe { packed_tube::pack(tx, backend_pid).expect("packed tube") };
-        Ok((Self::new(backend, rx)?, tx))
+        Ok((Self::new(backend, rx_connection)?, tx))
     }
 }
 
@@ -221,37 +236,3 @@ impl<S: Frontend> CloseNotifier for FrontendServer<S> {
         self.sub_sock.0.get_tube().get_close_notifier()
     }
 }
-
-#[cfg(test)]
-pub(crate) mod tests {
-    use crate::backend_client::BackendClient;
-    use crate::backend_server::Backend;
-    use crate::backend_server::BackendServer;
-    use crate::message::FrontendReq;
-    use crate::Connection;
-    use crate::SystemStream;
-
-    pub(crate) fn create_pair() -> (BackendClient, Connection<FrontendReq>) {
-        let (client_tube, server_tube) = SystemStream::pair().unwrap();
-        let backend_client = BackendClient::from_stream(client_tube);
-        (backend_client, Connection::from(server_tube))
-    }
-
-    pub(crate) fn create_connection_pair() -> (Connection<FrontendReq>, Connection<FrontendReq>) {
-        let (client_tube, server_tube) = SystemStream::pair().unwrap();
-        let backend_connection = Connection::<FrontendReq>::from(client_tube);
-        (backend_connection, Connection::from(server_tube))
-    }
-
-    pub(crate) fn create_client_server_pair<S>(backend: S) -> (BackendClient, BackendServer<S>)
-    where
-        S: Backend,
-    {
-        let (client_tube, server_tube) = SystemStream::pair().unwrap();
-        let backend_client = BackendClient::from_stream(client_tube);
-        (
-            backend_client,
-            BackendServer::<S>::from_stream(server_tube, backend),
-        )
-    }
-}
diff --git a/third_party/vmm_vhost/src/test_backend.rs b/third_party/vmm_vhost/src/test_backend.rs
index 5a6372618..1b7f46a89 100644
--- a/third_party/vmm_vhost/src/test_backend.rs
+++ b/third_party/vmm_vhost/src/test_backend.rs
@@ -264,23 +264,20 @@ impl Backend for TestBackend {
         Ok(())
     }
 
-    fn get_shared_memory_regions(&mut self) -> Result<Vec<VhostSharedMemoryRegion>> {
-        Ok(Vec::new())
-    }
-
-    fn sleep(&mut self) -> Result<()> {
-        Ok(())
+    fn set_device_state_fd(
+        &mut self,
+        _transfer_direction: VhostUserTransferDirection,
+        _migration_phase: VhostUserMigrationPhase,
+        _fd: File,
+    ) -> Result<Option<File>> {
+        Ok(None)
     }
 
-    fn wake(&mut self) -> Result<()> {
+    fn check_device_state(&mut self) -> Result<()> {
         Ok(())
     }
 
-    fn snapshot(&mut self) -> Result<Vec<u8>> {
+    fn get_shared_memory_regions(&mut self) -> Result<Vec<VhostSharedMemoryRegion>> {
         Ok(Vec::new())
     }
-
-    fn restore(&mut self, _data_bytes: &[u8], _queue_evts: Vec<File>) -> Result<()> {
-        Ok(())
-    }
 }
diff --git a/tools/clippy b/tools/clippy
index 49d88d141..a65495989 100755
--- a/tools/clippy
+++ b/tools/clippy
@@ -30,7 +30,7 @@ def main(
     chdir(CROSVM_ROOT)
 
     # Note: Clippy checks are configured in .cargo/config.toml
-    common_args = [
+    args = [
         "--message-format=json" if json else None,
         "--locked" if locked else None,
         "--all-targets",
@@ -38,22 +38,23 @@ def main(
         "-Dwarnings",
     ]
     if fix:
-        common_args = [
+        args = [
             "--fix",
             "--allow-no-vcs",
             "--allow-dirty",
             "--allow-staged",
-            *common_args,
+            *args,
         ]
+    # For experimental builds, don't clippy the whole workspace, just what's enabled by features.
+    if triple in (Triple.from_shorthand("riscv64"), Triple.from_shorthand("android")):
+        args = ["--no-default-features", *args]
+    else:
+        args = ["--workspace", *args]
+
     print("Clippy crosvm workspace")
-    exclude_args = []
-    if triple == Triple.from_shorthand("riscv64"):
-        exclude_args = ["--exclude=" + s for s in DO_NOT_BUILD_RISCV64]
     clippy(
-        "--workspace",
         f"--features={triple.feature_flag}",
-        *exclude_args,
-        *common_args,
+        *args,
     ).with_envs(triple.get_cargo_env()).fg()
 
 
diff --git a/tools/contrib/cros_tracing_analyser/Cargo.toml b/tools/contrib/cros_tracing_analyser/Cargo.toml
index 225ead068..82f544905 100644
--- a/tools/contrib/cros_tracing_analyser/Cargo.toml
+++ b/tools/contrib/cros_tracing_analyser/Cargo.toml
@@ -7,11 +7,11 @@ edition = "2021"
 
 [dependencies]
 anyhow = "1.0.75"
-argh = "*"
+argh = "0.1"
 libtracecmd = "0.2"
-log = "*"
+log = "0.4"
 once_cell = "1.18.0"
-serde = { version = "*", features = ["derive"] }
-serde_json = "*"
+serde = { version = "1", features = ["derive"] }
+serde_json = "1"
 
 [workspace]
diff --git a/tools/contrib/crosvmdump/Cargo.toml b/tools/contrib/crosvmdump/Cargo.toml
index 70a76dd7b..dfe375543 100644
--- a/tools/contrib/crosvmdump/Cargo.toml
+++ b/tools/contrib/crosvmdump/Cargo.toml
@@ -6,7 +6,7 @@ edition = "2021"
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
-rayon = "*"
-anyhow = "*"
+rayon = "1"
+anyhow = "1"
 
 [workspace]
diff --git a/tools/contrib/memstats_chart/Cargo.toml b/tools/contrib/memstats_chart/Cargo.toml
index 5c9bad609..bddc26ed5 100644
--- a/tools/contrib/memstats_chart/Cargo.toml
+++ b/tools/contrib/memstats_chart/Cargo.toml
@@ -6,13 +6,13 @@ edition = "2021"
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
-anyhow = "*"
-argh = "*"
-ctrlc = "*"
-env_logger = "*"
-log = "*"
-regex = "*"
-serde = { version = "*", features = ["derive"] }
-serde_json = "*"
+anyhow = "1"
+argh = "0.1"
+ctrlc = "3"
+env_logger = "0.9"
+log = "0.4"
+regex = "1.3"
+serde = { version = "1", features = ["derive"] }
+serde_json = "1"
 
 [workspace]
diff --git a/tools/contrib/vcpu_blocker_analyzer/Cargo.toml b/tools/contrib/vcpu_blocker_analyzer/Cargo.toml
index 8744ce9bd..31c44d3eb 100644
--- a/tools/contrib/vcpu_blocker_analyzer/Cargo.toml
+++ b/tools/contrib/vcpu_blocker_analyzer/Cargo.toml
@@ -11,12 +11,12 @@ argh = "0.1"
 env_logger = "0.10"
 log = "0.4"
 regex = "1.3"
-serde = { version = "*", features = ["derive"] }
+serde = { version = "1", features = ["derive"] }
 serde_json = "1"
 once_cell = "1"
 
 [dev-dependencies]
-rstest = "*"
+rstest = "0.19"
 
 
 [workspace]
diff --git a/tools/custom_checks b/tools/custom_checks
index 4f6a38b33..17b2efdce 100755
--- a/tools/custom_checks
+++ b/tools/custom_checks
@@ -76,7 +76,7 @@ def check_line_endings(*files: str):
         check_endings(wdir_endings)
 
 
-def check_rust_lockfiles(*_files: str):
+def check_rust_lockfiles(*files: str):
     "Verifies that none of the Cargo.lock files require updates."
     lockfiles = [Path("Cargo.lock"), *Path("common").glob("*/Cargo.lock")]
     for path in lockfiles:
@@ -99,7 +99,7 @@ KNOWN_DISABLED_FEATURES = [
 ]
 
 
-def check_rust_features(*_files: str):
+def check_rust_features(*files: str):
     "Verifies that all cargo features are included in the list of features we compile upstream."
     metadata = json.loads(cmd("cargo metadata --format-version=1").stdout())
     crosvm_metadata = next(p for p in metadata["packages"] if p["name"] == "crosvm")
@@ -128,6 +128,7 @@ def check_rust_features(*_files: str):
             *collect_features("all-mingw64"),
             *collect_features("all-msvc64"),
             *collect_features("all-riscv64"),
+            *collect_features("all-android"),
         )
     )
     disabled_features = [
diff --git a/tools/impl/catapult_converter/Cargo.toml b/tools/impl/catapult_converter/Cargo.toml
index b645ae775..aab66d355 100644
--- a/tools/impl/catapult_converter/Cargo.toml
+++ b/tools/impl/catapult_converter/Cargo.toml
@@ -4,9 +4,8 @@ version = "0.1.0"
 authors = ["The Chromium OS Authors"]
 edition = "2021"
 
-
 [dependencies]
-serde_json = "*"
-serde = { version = "*", features = ["derive"] }
-argh = "*"
+serde_json = "1"
+serde = { version = "1", features = ["derive"] }
+argh = "0.1"
 uuid = {version = "1", features = ["v4"]}
diff --git a/tools/impl/dev_container/version b/tools/impl/dev_container/version
index 0b2924127..e3d7a616d 100644
--- a/tools/impl/dev_container/version
+++ b/tools/impl/dev_container/version
@@ -1 +1 @@
-r0043
+r0047
diff --git a/tools/impl/testvm/cloud_init.yaml b/tools/impl/testvm/cloud_init.yaml
index 67fa63d08..1c36c227d 100644
--- a/tools/impl/testvm/cloud_init.yaml
+++ b/tools/impl/testvm/cloud_init.yaml
@@ -23,6 +23,7 @@ preserve_hostname: true
 # Runtime dependencies of crosvm binaries.
 # Note: Keep in sync with ./install-[aarch64-]deps.sh
 packages:
+    - e2fsprogs
     - gcc
     - libavcodec60
     - libavutil58
@@ -61,7 +62,11 @@ runcmd:
     - echo "* soft core unlimited" > /etc/security/limits.conf
 
     # Trim some fat
-    - [apt-get, remove, --yes, vim-runtime, iso-codes, perl, grub-common]
+{% if v1.machine == 'aarch64' %}
+    - [apt-get, remove, --yes, --allow-remove-essential, vim-runtime, grub-common]
+{% else %}
+    - [apt-get, remove, --yes, --allow-remove-essential, vim-runtime, grub-common, grub-efi-amd64-signed]
+{% endif %}
     - [apt-get, autoremove, --yes]
     - [apt-get, clean, --yes]
     - [rm, -rf, /var/lib/apt/lists]
diff --git a/tools/impl/testvm/version b/tools/impl/testvm/version
index ebe99f0b1..ccc8f88da 100644
--- a/tools/impl/testvm/version
+++ b/tools/impl/testvm/version
@@ -1 +1 @@
-r0012
+r0013
diff --git a/tools/impl/util.py b/tools/impl/util.py
index dfe627cf5..0a717e939 100644
--- a/tools/impl/util.py
+++ b/tools/impl/util.py
@@ -218,6 +218,7 @@ SHORTHANDS = {
     "aarch64": "aarch64-unknown-linux-gnu",
     "riscv64": "riscv64gc-unknown-linux-gnu",
     "x86_64": "x86_64-unknown-linux-gnu",
+    "android": "aarch64-linux-android",
 }
 
 
@@ -293,10 +294,22 @@ class Triple(NamedTuple):
         env["CARGO_BUILD_TARGET"] = cargo_target
         env["CARGO_TARGET_DIR"] = str(self.target_dir)
         env["CROSVM_TARGET_DIR"] = str(crosvm_target_dir())
+        # Android builds are not fully supported and can only be used to run clippy.
+        # Underlying libraries (e.g. minijail) will be built for linux instead
+        # TODO(denniskempin): This could be better done with [env] in Cargo.toml if it supported
+        # per-target configuration. See https://github.com/rust-lang/cargo/issues/10273
+        if str(self).endswith("-linux-android"):
+            env["MINIJAIL_DO_NOT_BUILD"] = "true"
+            env["MINIJAIL_BINDGEN_TARGET"] = f"{self.arch}-unknown-linux-gnu"
         return env
 
     def __str__(self):
-        return f"{self.arch}-{self.vendor}-{self.sys}-{self.abi}"
+        parts = [self.arch, self.vendor]
+        if self.sys:
+            parts = [*parts, self.sys]
+        if self.abi:
+            parts = [*parts, self.abi]
+        return "-".join(parts)
 
 
 def download_file(url: str, filename: Path, attempts: int = 3):
diff --git a/tools/install-armhf-deps b/tools/install-armhf-deps
index ab24f8b11..5fc828a3c 100755
--- a/tools/install-armhf-deps
+++ b/tools/install-armhf-deps
@@ -6,16 +6,12 @@ set -ex
 
 sudo apt-get install --yes --no-install-recommends \
     gcc-arm-linux-gnueabihf \
-    libavcodec-dev:armhf \
-    libavutil-dev:armhf \
     libc-dev:armhf \
     libcap-dev:armhf \
     libdbus-1-dev:armhf \
     libdrm-dev:armhf \
     libepoxy-dev:armhf \
     libssl-dev:armhf \
-    libswscale-dev:armhf \
-    libva-dev:armhf \
     libwayland-dev:armhf \
     libxext-dev:armhf
 
diff --git a/tools/install-deps b/tools/install-deps
index bc74b1347..9bf5bbb97 100755
--- a/tools/install-deps
+++ b/tools/install-deps
@@ -79,6 +79,9 @@ rustup component add llvm-tools-preview
 # Allow cross-compilation via mingw64
 rustup target add x86_64-pc-windows-gnu
 
+# Allow cross-compilation for android
+rustup target add aarch64-linux-android
+
 # Install nightly toolchain. Only used for rustfmt
 rustup toolchain install nightly --profile minimal --component rustfmt
 
diff --git a/tools/presubmit b/tools/presubmit
index 04541a254..1e01029a0 100755
--- a/tools/presubmit
+++ b/tools/presubmit
@@ -5,7 +5,7 @@
 
 import os
 import typing
-from typing import Generator, List, Literal, Optional, Tuple
+from typing import Generator, List, Literal, Optional, Tuple, Union
 
 from impl.common import (
     CROSVM_ROOT,
@@ -28,8 +28,11 @@ lucicfg = cmd("third_party/depot_tools/lucicfg")
 Platform = Literal["x86_64", "aarch64", "mingw64", "armhf"]
 PLATFORMS: Tuple[Platform, ...] = typing.get_args(Platform)
 
+ClippyOnlyPlatform = Literal["android"]
+CLIPPY_ONLY_PLATFORMS: Tuple[ClippyOnlyPlatform, ...] = typing.get_args(ClippyOnlyPlatform)
 
-def platform_is_supported(platform: Platform):
+
+def platform_is_supported(platform: Union[Platform, ClippyOnlyPlatform]):
     "Returns true if the platform is available as a target in rustup."
     triple = Triple.from_shorthand(platform)
     installed_toolchains = cmd("rustup target list --installed").lines()
@@ -158,7 +161,7 @@ def check_crosvm_build(
     return check
 
 
-def check_clippy(platform: Platform):
+def check_clippy(platform: Union[Platform, ClippyOnlyPlatform]):
     def check(context: CheckContext):
         if not platform_is_supported(platform):
             return None
@@ -294,7 +297,7 @@ CHECKS: List[Check] = [
             can_fix=True,
             priority=True,
         )
-        for platform in PLATFORMS
+        for platform in (*PLATFORMS, *CLIPPY_ONLY_PLATFORMS)
     ),
     Check(
         custom_check("check-copyright-header"),
@@ -373,13 +376,14 @@ GROUPS: List[Group] = [
         checks=[
             "health_checks",
             *(f"linux_{platform}" for platform in PLATFORMS),
+            *(f"clippy_{platform}" for platform in CLIPPY_ONLY_PLATFORMS),
         ],
     ),
     # Convenience groups for local usage:
     Group(
         name="clippy",
         doc="Runs clippy for all platforms",
-        checks=[f"clippy_{platform}" for platform in PLATFORMS],
+        checks=[f"clippy_{platform}" for platform in PLATFORMS + CLIPPY_ONLY_PLATFORMS],
     ),
     Group(
         name="unit_tests",
@@ -423,6 +427,13 @@ GROUPS: List[Group] = [
             "python_tests",
         ],
     ),
+    Group(
+        name="android-aarch64",
+        doc="Checks run on the android-aarch64 builder",
+        checks=[
+            "clippy_android",
+        ],
+    ),
     *(
         Group(
             name=f"linux_{platform}",
diff --git a/tube_transporter/Cargo.toml b/tube_transporter/Cargo.toml
index 7759b32ad..79cc20132 100644
--- a/tube_transporter/Cargo.toml
+++ b/tube_transporter/Cargo.toml
@@ -10,8 +10,8 @@ base = { path = "../base" }
 rand = "0.8"
 thiserror = "1.0.20"
 serde = { version = "1", features = [ "derive" ] }
-serde_json = "*"
+serde_json = "1"
 
 [target.'cfg(windows)'.dependencies]
 win_util = { path = "../win_util"}
-winapi = "*"
+winapi = "0.3"
diff --git a/usb_sys/Android.bp b/usb_sys/Android.bp
index f78cbf725..05b04130f 100644
--- a/usb_sys/Android.bp
+++ b/usb_sys/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "usb_sys",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: ["libbase_rust"],
 }
diff --git a/usb_util/Android.bp b/usb_util/Android.bp
index dcd10ce9d..61c81dabf 100644
--- a/usb_util/Android.bp
+++ b/usb_util/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "usb_util",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
@@ -41,7 +41,7 @@ rust_test {
     crate_name: "usb_util",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/usb_util/Cargo.toml b/usb_util/Cargo.toml
index 3e36ecfee..aa92d3898 100644
--- a/usb_util/Cargo.toml
+++ b/usb_util/Cargo.toml
@@ -7,9 +7,9 @@ edition = "2021"
 [dependencies]
 static_assertions = "1.1"
 data_model = { path = "../common/data_model" }
-libc = "*"
-remain = "*"
-thiserror = "*"
+libc = "0.2"
+remain = "0.2"
+thiserror = "1"
 base = { path = "../base" }
 usb_sys = { path = "../usb_sys" }
 sync = { path = "../common/sync" }
diff --git a/usb_util/src/descriptor.rs b/usb_util/src/descriptor.rs
index 2df39ecaa..626e5b136 100644
--- a/usb_util/src/descriptor.rs
+++ b/usb_util/src/descriptor.rs
@@ -221,10 +221,9 @@ pub fn parse_usbfs_descriptors(data: &[u8]) -> Result<DeviceDescriptorTree> {
             }
 
             for intf_idx in 0..config_descriptor.bNumInterfaces {
-                if config_descriptor
+                if !config_descriptor
                     .interface_descriptors
-                    .get(&(intf_idx, 0))
-                    .is_none()
+                    .contains_key(&(intf_idx, 0))
                 {
                     warn!("device interface {} has no interface descriptors", intf_idx);
                 }
diff --git a/usb_util/src/device.rs b/usb_util/src/device.rs
index bc338d88a..9bb391831 100644
--- a/usb_util/src/device.rs
+++ b/usb_util/src/device.rs
@@ -276,7 +276,7 @@ impl Device {
         // Safe because we control the lifetime of the URB via Arc::into_raw() and
         // Arc::from_raw() in poll_transfers().
         unsafe {
-            self.ioctl_with_mut_ptr(usb_sys::USBDEVFS_SUBMITURB(), urb_ptr)?;
+            self.ioctl_with_mut_ptr(usb_sys::USBDEVFS_SUBMITURB, urb_ptr)?;
         }
 
         let weak_transfer = Arc::downgrade(&rc_transfer);
@@ -296,7 +296,7 @@ impl Device {
             let result =
         // SAFETY:
             // Safe because we provide a valid urb_ptr to be filled by the kernel.
-                unsafe { self.ioctl_with_mut_ref(usb_sys::USBDEVFS_REAPURBNDELAY(), &mut urb_ptr) };
+                unsafe { self.ioctl_with_mut_ref(usb_sys::USBDEVFS_REAPURBNDELAY, &mut urb_ptr) };
             match result {
                 // EAGAIN indicates no more completed transfers right now.
                 Err(Error::IoctlFailed(_nr, e)) if e.errno() == EAGAIN => break,
@@ -350,7 +350,7 @@ impl Device {
 
         // SAFETY:
         // Safe because self.fd is a valid usbdevfs file descriptor.
-        let result = unsafe { self.ioctl(usb_sys::USBDEVFS_RESET()) };
+        let result = unsafe { self.ioctl(usb_sys::USBDEVFS_RESET) };
 
         if let Err(Error::IoctlFailed(_nr, errno_err)) = result {
             // The device may disappear after a reset if e.g. its firmware changed.
@@ -375,7 +375,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to a usbdevs_disconnect_claim structure.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_DISCONNECT_CLAIM(), &disconnect_claim)?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_DISCONNECT_CLAIM, &disconnect_claim)?;
         }
 
         Ok(())
@@ -388,7 +388,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to unsigned int.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_RELEASEINTERFACE(), &ifnum)?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_RELEASEINTERFACE, &ifnum)?;
         }
 
         Ok(())
@@ -408,7 +408,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to a usbdevfs_setinterface structure.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_SETINTERFACE(), &setinterface)?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_SETINTERFACE, &setinterface)?;
         }
         Ok(())
     }
@@ -420,7 +420,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to int.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_SETCONFIGURATION(), &config)?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_SETCONFIGURATION, &config)?;
         }
 
         Ok(())
@@ -487,7 +487,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to a usbdevfs_ctrltransfer structure.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_CONTROL(), &ctrl_transfer)?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_CONTROL, &ctrl_transfer)?;
         }
         Ok(active_config)
     }
@@ -504,7 +504,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to unsigned int.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_CLEAR_HALT(), &endpoint)?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_CLEAR_HALT, &endpoint)?;
         }
 
         Ok(())
@@ -513,7 +513,7 @@ impl Device {
     /// Get speed of this device.
     pub fn get_speed(&self) -> Result<Option<DeviceSpeed>> {
         // SAFETY: args are valid and the return value is checked
-        let speed = unsafe { self.ioctl(usb_sys::USBDEVFS_GET_SPEED()) }?;
+        let speed = unsafe { self.ioctl(usb_sys::USBDEVFS_GET_SPEED) }?;
         match speed {
             1 => Ok(Some(DeviceSpeed::Low)),       // Low Speed
             2 => Ok(Some(DeviceSpeed::Full)),      // Full Speed
@@ -541,7 +541,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to a usbdevfs_streams structure.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_ALLOC_STREAMS(), &streams[0])?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_ALLOC_STREAMS, &streams[0])?;
         }
         Ok(())
     }
@@ -558,7 +558,7 @@ impl Device {
         // Safe because self.fd is a valid usbdevfs file descriptor and we pass a valid
         // pointer to a usbdevfs_streams structure.
         unsafe {
-            self.ioctl_with_ref(usb_sys::USBDEVFS_FREE_STREAMS(), &streams[0])?;
+            self.ioctl_with_ref(usb_sys::USBDEVFS_FREE_STREAMS, &streams[0])?;
         }
         Ok(())
     }
@@ -699,13 +699,13 @@ impl TransferHandle {
         if unsafe {
             handle_eintr_errno!(base::ioctl_with_mut_ptr(
                 &*fd,
-                usb_sys::USBDEVFS_DISCARDURB(),
+                usb_sys::USBDEVFS_DISCARDURB,
                 urb_ptr
             ))
         } < 0
         {
             return Err(Error::IoctlFailed(
-                usb_sys::USBDEVFS_DISCARDURB(),
+                usb_sys::USBDEVFS_DISCARDURB,
                 base::Error::last(),
             ));
         }
diff --git a/vendor/generic/anti_tamper/Android.bp b/vendor/generic/anti_tamper/Android.bp
index b13eaa112..03589e5d6 100644
--- a/vendor/generic/anti_tamper/Android.bp
+++ b/vendor/generic/anti_tamper/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "anti_tamper",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: ["libbase_rust"],
 }
diff --git a/vendor/generic/broker_ipc/Android.bp b/vendor/generic/broker_ipc/Android.bp
index bec0cebbc..312a574fa 100644
--- a/vendor/generic/broker_ipc/Android.bp
+++ b/vendor/generic/broker_ipc/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "broker_ipc_product",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/vendor/generic/crash_report/Android.bp b/vendor/generic/crash_report/Android.bp
index 23becbc8d..3d27d2cbf 100644
--- a/vendor/generic/crash_report/Android.bp
+++ b/vendor/generic/crash_report/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "crash_report",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
diff --git a/vendor/generic/crypto/Android.bp b/vendor/generic/crypto/Android.bp
index 15db0799a..20e4f89da 100644
--- a/vendor/generic/crypto/Android.bp
+++ b/vendor/generic/crypto/Android.bp
@@ -19,14 +19,13 @@ rust_library {
     crate_name: "crypto_generic",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
         "libbase_rust",
         "libserde",
         "libserde_json",
-        "libtempfile",
         "libzeroize",
     ],
 }
diff --git a/vendor/generic/crypto/Cargo.toml b/vendor/generic/crypto/Cargo.toml
index db728c1cd..9832fe301 100644
--- a/vendor/generic/crypto/Cargo.toml
+++ b/vendor/generic/crypto/Cargo.toml
@@ -11,6 +11,8 @@ rustcrypto = []
 anyhow = "1.0.32"
 base = { path = "../../../base" }
 serde = { version = "1", features = ["derive"] }
-serde_json = "*"
-tempfile = "3"
+serde_json = "1"
 zeroize = "1.5.7"
+
+[dev-dependencies]
+tempfile = "3"
diff --git a/vendor/generic/metrics/Android.bp b/vendor/generic/metrics/Android.bp
index 42a670288..e6662cdb7 100644
--- a/vendor/generic/metrics/Android.bp
+++ b/vendor/generic/metrics/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "metrics_generic",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: ["default"],
     rustlibs: [
diff --git a/vendor/generic/metrics/Cargo.toml b/vendor/generic/metrics/Cargo.toml
index b5f57f8b5..cdc9bbf17 100644
--- a/vendor/generic/metrics/Cargo.toml
+++ b/vendor/generic/metrics/Cargo.toml
@@ -10,6 +10,6 @@ experimental = []
 collect = []
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 base = { path = "../../../base" }
 metrics_events = { path = "../../../metrics_events" }
diff --git a/vendor/generic/metrics/src/client.rs b/vendor/generic/metrics/src/client.rs
index f7e691ac9..da41ffbd8 100644
--- a/vendor/generic/metrics/src/client.rs
+++ b/vendor/generic/metrics/src/client.rs
@@ -27,9 +27,24 @@ pub fn set_auth_token(_: &str) {}
 pub fn set_graphics_api(_: &str) {}
 pub fn set_package_name(_: &str) {}
 pub fn merge_session_invariants(_: &[u8]) {}
-pub fn log_descriptor(_: MetricEventType, _: i64) {}
-pub fn log_event(_: MetricEventType) {}
-pub fn log_metric(_: MetricEventType, _: i64) {}
-pub fn log_histogram_metric(_: MetricEventType, _: i64) {}
-pub fn log_high_frequency_descriptor_event(_: MetricEventType, _: i64, _: i64) {}
-pub fn log_event_with_details(_: MetricEventType, _: &RecordDetails) {}
+
+/// Logs a counter with the given descriptor as aux. data. A descriptor is
+/// generally an enum value or error code.
+pub fn log_descriptor(_event_type: MetricEventType, _descriptor: i64) {}
+
+/// Logs a counter with no aux. data.
+pub fn log_event(_event_type: MetricEventType) {}
+
+/// Logs a real valued metric (e.g. a data transfer rate, a latency value, etc)
+/// with the supplied value.
+pub fn log_metric(_event_type: MetricEventType, _value: i64) {}
+
+/// Logs a histogram metric with the supplied value. Note: step is a value to
+/// be added to the distribution.
+pub fn log_histogram_metric(_event_type: MetricEventType, _step: i64) {}
+
+/// Logs a high frequency counter with the supplied aux. data and value.
+pub fn log_high_frequency_descriptor_event(_: MetricEventType, _descriptor: i64, _step: i64) {}
+
+/// Logs a counter with additional data.
+pub fn log_event_with_details(_event_type: MetricEventType, _details: &RecordDetails) {}
diff --git a/vendor/generic/metrics_events/Android.bp b/vendor/generic/metrics_events/Android.bp
index 90ea97aca..2c950f0bf 100644
--- a/vendor/generic/metrics_events/Android.bp
+++ b/vendor/generic/metrics_events/Android.bp
@@ -14,7 +14,7 @@ rust_library {
     crate_name: "metrics_events_generic",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: ["libserde"],
 }
diff --git a/vendor/generic/vm_control/Android.bp b/vendor/generic/vm_control/Android.bp
index 1371389cd..fa27268e5 100644
--- a/vendor/generic/vm_control/Android.bp
+++ b/vendor/generic/vm_control/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "vm_control_product",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: ["libserde"],
 }
diff --git a/vfio_sys/Android.bp b/vfio_sys/Android.bp
index a8024daa0..cbd3f4ecf 100644
--- a/vfio_sys/Android.bp
+++ b/vfio_sys/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "vfio_sys",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/vhost/Android.bp b/vhost/Android.bp
index 86146a2fe..d9c774e33 100644
--- a/vhost/Android.bp
+++ b/vhost/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "vhost",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
@@ -40,7 +40,7 @@ rust_test {
     crate_name: "linux",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["tests/linux.rs"],
+    crate_root: "tests/linux.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/vhost/Cargo.toml b/vhost/Cargo.toml
index ab013563c..8c8360f60 100644
--- a/vhost/Cargo.toml
+++ b/vhost/Cargo.toml
@@ -6,10 +6,10 @@ edition = "2021"
 
 [dependencies]
 static_assertions = "1.1"
-libc = "*"
+libc = "0.2"
 net_util = { path = "../net_util" }
 base = { path = "../base" }
-remain = "*"
-thiserror = "*"
+remain = "0.2"
+thiserror = "1"
 virtio_sys = { path = "../virtio_sys" }
 vm_memory = { path = "../vm_memory" }
diff --git a/vhost/src/lib.rs b/vhost/src/lib.rs
index 99f32e5db..b474bf2f7 100644
--- a/vhost/src/lib.rs
+++ b/vhost/src/lib.rs
@@ -82,7 +82,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
-        let ret = unsafe { ioctl(self, virtio_sys::VHOST_SET_OWNER()) };
+        let ret = unsafe { ioctl(self, virtio_sys::VHOST_SET_OWNER) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -95,7 +95,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost fd and has its
         // return value checked.
-        let ret = unsafe { ioctl(self, virtio_sys::VHOST_RESET_OWNER()) };
+        let ret = unsafe { ioctl(self, virtio_sys::VHOST_RESET_OWNER) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -109,7 +109,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
         let ret = unsafe {
-            ioctl_with_mut_ref(self, virtio_sys::VHOST_GET_FEATURES(), &mut avail_features)
+            ioctl_with_mut_ref(self, virtio_sys::VHOST_GET_FEATURES, &mut avail_features)
         };
         if ret < 0 {
             return ioctl_result();
@@ -126,7 +126,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
-        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_FEATURES(), &features) };
+        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_FEATURES, &features) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -171,7 +171,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // This ioctl is called with a pointer that is valid for the lifetime
         // of this function. The kernel will make its own copy of the memory
         // tables. As always, check the return value.
-        let ret = unsafe { ioctl_with_ptr(self, virtio_sys::VHOST_SET_MEM_TABLE(), vhost_memory) };
+        let ret = unsafe { ioctl_with_ptr(self, virtio_sys::VHOST_SET_MEM_TABLE, vhost_memory) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -195,7 +195,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
-        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_NUM(), &vring_state) };
+        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_NUM, &vring_state) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -300,7 +300,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
-        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_ADDR(), &vring_addr) };
+        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_ADDR, &vring_addr) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -321,7 +321,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
-        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_BASE(), &vring_state) };
+        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_BASE, &vring_state) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -340,9 +340,8 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
 
         // SAFETY:
         // Safe because this will only modify `vring_state` and we check the return value.
-        let ret = unsafe {
-            ioctl_with_mut_ref(self, virtio_sys::VHOST_GET_VRING_BASE(), &mut vring_state)
-        };
+        let ret =
+            unsafe { ioctl_with_mut_ref(self, virtio_sys::VHOST_GET_VRING_BASE, &mut vring_state) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -364,7 +363,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
-        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_CALL(), &vring_file) };
+        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_CALL, &vring_file) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -385,7 +384,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net fd and has its
         // return value checked.
-        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_ERR(), &vring_file) };
+        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_ERR, &vring_file) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -407,7 +406,7 @@ pub trait Vhost: AsRawDescriptor + std::marker::Sized {
         // SAFETY:
         // This ioctl is called on a valid vhost_net descriptor and has its
         // return value checked.
-        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_KICK(), &vring_file) };
+        let ret = unsafe { ioctl_with_ref(self, virtio_sys::VHOST_SET_VRING_KICK, &vring_file) };
         if ret < 0 {
             return ioctl_result();
         }
diff --git a/vhost/src/net.rs b/vhost/src/net.rs
index d3236a2cc..d846b755d 100644
--- a/vhost/src/net.rs
+++ b/vhost/src/net.rs
@@ -74,7 +74,7 @@ where
         let ret = unsafe {
             ioctl_with_ref(
                 &self.descriptor,
-                virtio_sys::VHOST_NET_SET_BACKEND(),
+                virtio_sys::VHOST_NET_SET_BACKEND,
                 &vring_file,
             )
         };
diff --git a/vhost/src/vsock.rs b/vhost/src/vsock.rs
index d61064ac8..fdf924eb0 100644
--- a/vhost/src/vsock.rs
+++ b/vhost/src/vsock.rs
@@ -35,7 +35,7 @@ impl Vsock {
     /// * `cid` - CID to assign to the guest
     pub fn set_cid(&self, cid: u64) -> Result<()> {
         // SAFETY: Safe because descriptor is valid and the return value is checked.
-        let ret = unsafe { ioctl_with_ref(&self.descriptor, VHOST_VSOCK_SET_GUEST_CID(), &cid) };
+        let ret = unsafe { ioctl_with_ref(&self.descriptor, VHOST_VSOCK_SET_GUEST_CID, &cid) };
         if ret < 0 {
             return ioctl_result();
         }
@@ -55,7 +55,7 @@ impl Vsock {
     fn set_running(&self, running: bool) -> Result<()> {
         let on = ::std::os::raw::c_int::from(running);
         // SAFETY: Safe because descriptor is valid and the return value is checked.
-        let ret = unsafe { ioctl_with_ref(&self.descriptor, VHOST_VSOCK_SET_RUNNING(), &on) };
+        let ret = unsafe { ioctl_with_ref(&self.descriptor, VHOST_VSOCK_SET_RUNNING, &on) };
 
         if ret < 0 {
             return ioctl_result();
diff --git a/virtio_sys/Android.bp b/virtio_sys/Android.bp
index da9f5cecb..85717a08c 100644
--- a/virtio_sys/Android.bp
+++ b/virtio_sys/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "virtio_sys",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libbase_rust",
diff --git a/virtio_sys/bindgen.sh b/virtio_sys/bindgen.sh
index 861cbd1cb..7dcefd904 100755
--- a/virtio_sys/bindgen.sh
+++ b/virtio_sys/bindgen.sh
@@ -19,7 +19,12 @@ bindgen_generate \
     | replace_linux_int_types \
     > virtio_sys/src/vhost.rs
 
+VIRTIO_CONFIG_EXTRA="// Added by virtio_sys/bindgen.sh
+pub const VIRTIO_CONFIG_S_SUSPEND: u32 = 16;
+pub const VIRTIO_F_SUSPEND: u32 = 42;"
+
 bindgen_generate \
+    --raw-line "${VIRTIO_CONFIG_EXTRA}" \
     --allowlist-var='VIRTIO_.*' \
     --allowlist-type='virtio_.*' \
     "${BINDGEN_LINUX_X86_HEADERS}/include/linux/virtio_config.h" \
diff --git a/virtio_sys/src/virtio_config.rs b/virtio_sys/src/virtio_config.rs
index 3f97df3f2..952bcf5d0 100644
--- a/virtio_sys/src/virtio_config.rs
+++ b/virtio_sys/src/virtio_config.rs
@@ -8,6 +8,10 @@
 #![allow(non_snake_case)]
 #![allow(dead_code)]
 
+// Added by virtio_sys/bindgen.sh
+pub const VIRTIO_CONFIG_S_SUSPEND: u32 = 16;
+pub const VIRTIO_F_SUSPEND: u32 = 42;
+
 pub const VIRTIO_CONFIG_S_ACKNOWLEDGE: u32 = 1;
 pub const VIRTIO_CONFIG_S_DRIVER: u32 = 2;
 pub const VIRTIO_CONFIG_S_DRIVER_OK: u32 = 4;
diff --git a/vm_control/Android.bp b/vm_control/Android.bp
index ff9274ca5..0f6930708 100644
--- a/vm_control/Android.bp
+++ b/vm_control/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "vm_control",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "balloon",
@@ -52,7 +52,7 @@ rust_library {
     ],
     proc_macros: ["libremain"],
     aliases: ["crypto_generic:crypto"],
-    visibility: ["//packages/modules/Virtualization/virtualizationmanager"],
+    visibility: ["//packages/modules/Virtualization/android/virtmgr"],
 }
 
 rust_test {
@@ -62,7 +62,7 @@ rust_test {
     crate_name: "vm_control",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/vm_control/Cargo.toml b/vm_control/Cargo.toml
index 6c2e482c7..6ca9f30cf 100644
--- a/vm_control/Cargo.toml
+++ b/vm_control/Cargo.toml
@@ -13,28 +13,28 @@ registered_events = ["balloon", "protos/registered_events"]
 swap = ["swap/enable"]
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 balloon_control = { path = "../common/balloon_control" }
 base = { path = "../base" }
-cfg-if = "*"
+cfg-if = "1"
 crypto = { path = "../vendor/generic/crypto", package = "crypto_generic" }
 gdbstub = { version = "0.7.0", optional = true }
 gdbstub_arch = { version = "0.3.0", optional = true }
 hypervisor = { path = "../hypervisor" }
-libc = "*"
+libc = "0.2"
 once_cell = "1.7.2"
 protos = { path = "../protos", optional = true }
-remain = "*"
+remain = "0.2"
 resources = { path = "../resources" }
 rutabaga_gfx = { path = "../rutabaga_gfx" }
 serde = { version = "1", features = ["derive"] }
-serde_json = "*"
+serde_json = "1"
 serde_keyvalue = { path = "../serde_keyvalue", features = ["argh_derive"] }
 swap = { path = "../swap" }
 sync = { path = "../common/sync" }
-thiserror = "*"
+thiserror = "1"
 vm_control_product = { path = "../vendor/generic/vm_control", package = "vm_control_product" }
 vm_memory = { path = "../vm_memory" }
 
 [target.'cfg(windows)'.dependencies]
-winapi = "*"
+winapi = "0.3"
diff --git a/vm_control/src/api.rs b/vm_control/src/api.rs
index 5f3de9fc9..500c9efa1 100644
--- a/vm_control/src/api.rs
+++ b/vm_control/src/api.rs
@@ -35,6 +35,8 @@ pub enum ApiClientError {
     RequestFailed(#[from] base::Error),
     #[error("API client tube send failed: {0}")]
     Send(TubeError),
+    #[error("API client tube sending FDs failed: {0}")]
+    SendFds(TubeError),
     #[error("Unexpected tube response")]
     UnexpectedResponse,
 }
@@ -87,11 +89,43 @@ impl VmMemoryClient {
         };
         match self.request(&request)? {
             VmMemoryResponse::Err(e) => Err(ApiClientError::RequestFailed(e)),
-            VmMemoryResponse::RegisterMemory(region_id) => Ok(region_id),
+            VmMemoryResponse::RegisterMemory { region_id, .. } => Ok(region_id),
             _other => Err(ApiClientError::UnexpectedResponse),
         }
     }
 
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    pub fn mmap_and_register_memory(
+        &self,
+        mapping_address: GuestAddress,
+        shm: base::SharedMemory,
+        file_mapping_info: Vec<crate::VmMemoryFileMapping>,
+    ) -> Result<u32> {
+        let num_file_mappings = file_mapping_info.len();
+        let req = VmMemoryRequest::MmapAndRegisterMemory {
+            shm,
+            dest: VmMemoryDestination::GuestPhysicalAddress(mapping_address.0),
+            num_file_mappings,
+        };
+
+        self.tube.send(&req).map_err(ApiClientError::Send)?;
+
+        // Since the number of FDs that can be sent via Tube at once is limited to
+        // SCM_MAX_FD, split `file_mappings` to chunks and send them
+        // repeatedly.
+        for m in file_mapping_info.chunks(base::unix::SCM_MAX_FD) {
+            self.tube
+                .send_with_max_fds(&m, m.len())
+                .map_err(ApiClientError::SendFds)?;
+        }
+
+        match self.tube.recv().map_err(ApiClientError::Recv)? {
+            VmMemoryResponse::RegisterMemory { slot, .. } => Ok(slot),
+            VmMemoryResponse::Err(e) => Err(ApiClientError::RequestFailed(e)),
+            _ => Err(ApiClientError::UnexpectedResponse),
+        }
+    }
+
     /// Call hypervisor to free the given memory range.
     pub fn dynamically_free_memory_range(
         &self,
diff --git a/vm_control/src/balloon_tube.rs b/vm_control/src/balloon_tube.rs
index 9f7148a4f..e78eb2c08 100644
--- a/vm_control/src/balloon_tube.rs
+++ b/vm_control/src/balloon_tube.rs
@@ -9,13 +9,8 @@ use std::collections::VecDeque;
 use anyhow::bail;
 use anyhow::Context;
 use anyhow::Result;
-pub use balloon_control::BalloonStats;
 use balloon_control::BalloonTubeCommand;
-pub use balloon_control::BalloonTubeResult;
-pub use balloon_control::BalloonWS;
-pub use balloon_control::WSBucket;
-pub use balloon_control::VIRTIO_BALLOON_WS_MAX_NUM_BINS;
-pub use balloon_control::VIRTIO_BALLOON_WS_MIN_NUM_BINS;
+use balloon_control::BalloonTubeResult;
 use base::error;
 use base::Error as SysError;
 use base::Tube;
@@ -94,7 +89,6 @@ pub struct BalloonTube {
     pending_adjust_with_completion: Option<(u64, usize)>,
 }
 
-#[cfg(feature = "balloon")]
 impl BalloonTube {
     pub fn new(tube: Tube) -> Self {
         BalloonTube {
@@ -211,6 +205,8 @@ impl BalloonTube {
 
 #[cfg(test)]
 mod tests {
+    use balloon_control::BalloonStats;
+
     use super::*;
 
     fn balloon_device_respond_stats(device: &Tube) {
diff --git a/vm_control/src/client.rs b/vm_control/src/client.rs
index 67e740500..73577e76c 100644
--- a/vm_control/src/client.rs
+++ b/vm_control/src/client.rs
@@ -14,11 +14,26 @@ use remain::sorted;
 use thiserror::Error;
 
 #[cfg(feature = "gpu")]
-pub use crate::gpu::*;
+pub use crate::gpu::do_gpu_display_add;
+#[cfg(feature = "gpu")]
+pub use crate::gpu::do_gpu_display_list;
+#[cfg(feature = "gpu")]
+pub use crate::gpu::do_gpu_display_remove;
+#[cfg(feature = "gpu")]
+pub use crate::gpu::do_gpu_set_display_mouse_mode;
+#[cfg(feature = "gpu")]
+pub use crate::gpu::ModifyGpuResult;
 pub use crate::sys::handle_request;
-#[cfg(any(target_os = "android", target_os = "linux"))]
 pub use crate::sys::handle_request_with_timeout;
-pub use crate::*;
+use crate::BatControlCommand;
+use crate::BatControlResult;
+use crate::BatteryType;
+use crate::SwapCommand;
+use crate::UsbControlCommand;
+use crate::UsbControlResult;
+use crate::VmRequest;
+use crate::VmResponse;
+use crate::USB_CONTROL_MAX_PORTS;
 
 #[sorted]
 #[derive(Error, Debug)]
@@ -64,7 +79,8 @@ pub fn do_net_add<T: AsRef<Path> + std::fmt::Debug>(
     tap_name: &str,
     socket_path: T,
 ) -> AnyHowResult<u8> {
-    let request = VmRequest::HotPlugNetCommand(NetControlCommand::AddTap(tap_name.to_owned()));
+    let request =
+        VmRequest::HotPlugNetCommand(crate::NetControlCommand::AddTap(tap_name.to_owned()));
     let response = handle_request(&request, socket_path).map_err(|()| anyhow!("socket error: "))?;
     match response {
         VmResponse::PciHotPlugResponse { bus } => Ok(bus),
@@ -78,7 +94,7 @@ pub fn do_net_add<T: AsRef<Path> + std::fmt::Debug>(
     _tap_name: &str,
     _socket_path: T,
 ) -> AnyHowResult<u8> {
-    bail!("Unsupported: pci-hotplug feature disabled");
+    anyhow::bail!("Unsupported: pci-hotplug feature disabled");
 }
 
 #[cfg(feature = "pci-hotplug")]
@@ -87,7 +103,7 @@ pub fn do_net_remove<T: AsRef<Path> + std::fmt::Debug>(
     bus_num: u8,
     socket_path: T,
 ) -> AnyHowResult<()> {
-    let request = VmRequest::HotPlugNetCommand(NetControlCommand::RemoveTap(bus_num));
+    let request = VmRequest::HotPlugNetCommand(crate::NetControlCommand::RemoveTap(bus_num));
     let response = handle_request(&request, socket_path).map_err(|()| anyhow!("socket error: "))?;
     match response {
         VmResponse::Ok => Ok(()),
@@ -101,7 +117,7 @@ pub fn do_net_remove<T: AsRef<Path> + std::fmt::Debug>(
     _bus_num: u8,
     _socket_path: T,
 ) -> AnyHowResult<()> {
-    bail!("Unsupported: pci-hotplug feature disabled");
+    anyhow::bail!("Unsupported: pci-hotplug feature disabled");
 }
 
 pub fn do_usb_attach<T: AsRef<Path> + std::fmt::Debug>(
diff --git a/vm_control/src/gpu.rs b/vm_control/src/gpu.rs
index afbb57a1b..d751f210d 100644
--- a/vm_control/src/gpu.rs
+++ b/vm_control/src/gpu.rs
@@ -142,7 +142,10 @@ pub enum GpuControlResult {
     DisplayList {
         displays: Map<u32, DisplayParameters>,
     },
-    TooManyDisplays(usize),
+    TooManyDisplays {
+        allowed: usize,
+        requested: usize,
+    },
     NoSuchDisplay {
         display_id: u32,
     },
@@ -164,7 +167,11 @@ impl Display for GpuControlResult {
                     serde_json::to_string_pretty(&json).map_err(|_| std::fmt::Error)?;
                 write!(f, "{}", json_pretty)
             }
-            TooManyDisplays(n) => write!(f, "too_many_displays {}", n),
+            TooManyDisplays { allowed, requested } => write!(
+                f,
+                "too_many_displays: allowed {}, requested {}",
+                allowed, requested
+            ),
             NoSuchDisplay { display_id } => write!(f, "no_such_display {}", display_id),
             DisplayMouseModeSet => write!(f, "display_mouse_mode_set"),
             ErrString(reason) => write!(f, "err_string {}", reason),
diff --git a/vm_control/src/lib.rs b/vm_control/src/lib.rs
index cf1608fe8..886c59c03 100644
--- a/vm_control/src/lib.rs
+++ b/vm_control/src/lib.rs
@@ -18,6 +18,10 @@ pub mod gpu;
 
 #[cfg(any(target_os = "android", target_os = "linux"))]
 use base::linux::MemoryMappingBuilderUnix;
+#[cfg(any(target_os = "android", target_os = "linux"))]
+use base::sys::call_with_extended_max_files;
+#[cfg(any(target_os = "android", target_os = "linux"))]
+use base::MemoryMappingArena;
 #[cfg(windows)]
 use base::MemoryMappingBuilderWindows;
 use hypervisor::BalloonEvent;
@@ -39,6 +43,7 @@ use std::convert::TryInto;
 use std::fmt;
 use std::fmt::Display;
 use std::fs::File;
+use std::path::Path;
 use std::path::PathBuf;
 use std::result::Result as StdResult;
 use std::str::FromStr;
@@ -96,10 +101,12 @@ use swap::SwapStatus;
 use sync::Mutex;
 #[cfg(any(target_os = "android", target_os = "linux"))]
 pub use sys::FsMappingRequest;
+#[cfg(windows)]
+pub use sys::InitialAudioSessionState;
 #[cfg(any(target_os = "android", target_os = "linux"))]
-pub use sys::VmMsyncRequest;
+pub use sys::VmMemoryMappingRequest;
 #[cfg(any(target_os = "android", target_os = "linux"))]
-pub use sys::VmMsyncResponse;
+pub use sys::VmMemoryMappingResponse;
 use thiserror::Error;
 pub use vm_control_product::GpuSendToMain;
 pub use vm_control_product::GpuSendToService;
@@ -107,7 +114,9 @@ pub use vm_control_product::ServiceSendToGpu;
 use vm_memory::GuestAddress;
 
 #[cfg(feature = "balloon")]
-pub use crate::balloon_tube::*;
+pub use crate::balloon_tube::BalloonControlCommand;
+#[cfg(feature = "balloon")]
+pub use crate::balloon_tube::BalloonTube;
 #[cfg(feature = "gdb")]
 pub use crate::gdb::VcpuDebug;
 #[cfg(feature = "gdb")]
@@ -184,8 +193,8 @@ pub trait PmeNotify: Send {
 pub trait PmResource {
     fn pwrbtn_evt(&mut self) {}
     fn slpbtn_evt(&mut self) {}
-    fn rtc_evt(&mut self) {}
-    fn gpe_evt(&mut self, _gpe: u32) {}
+    fn rtc_evt(&mut self, _clear_evt: Event) {}
+    fn gpe_evt(&mut self, _gpe: u32, _clear_evt: Option<Event>) {}
     fn pme_evt(&mut self, _requester_id: u16) {}
     fn register_gpe_notify_dev(&mut self, _gpe: u32, _notify_dev: Arc<Mutex<dyn GpeNotify>>) {}
     fn register_pme_notify_dev(&mut self, _bus: u8, _notify_dev: Arc<Mutex<dyn PmeNotify>>) {}
@@ -543,11 +552,25 @@ pub struct IoEventUpdateRequest {
     pub register: bool,
 }
 
+/// Request to mmap a file to a shared memory.
+/// This request is supposed to follow a `VmMemoryRequest::MmapAndRegisterMemory` request that
+/// contains `SharedMemory` that `file` is mmaped to.
+#[cfg(any(target_os = "android", target_os = "linux"))]
+#[derive(Serialize, Deserialize)]
+pub struct VmMemoryFileMapping {
+    #[serde(with = "with_as_descriptor")]
+    pub file: File,
+    pub length: usize,
+    pub mem_offset: usize,
+    pub file_offset: u64,
+}
+
 #[derive(Serialize, Deserialize)]
 pub enum VmMemoryRequest {
     /// Prepare a shared memory region to make later operations more efficient. This
     /// may be a no-op depending on underlying platform support.
     PrepareSharedMemoryRegion { alloc: Alloc, cache: MemCacheType },
+    /// Register a memory to be mapped to the guest.
     RegisterMemory {
         /// Source of the memory to register (mapped file descriptor, shared memory region, etc.)
         source: VmMemorySource,
@@ -558,6 +581,18 @@ pub enum VmMemoryRequest {
         /// Cache attribute for guest memory setting
         cache: MemCacheType,
     },
+    #[cfg(any(target_os = "android", target_os = "linux"))]
+    /// Call mmap to `shm` and register the memory region as a read-only guest memory.
+    /// This request is followed by an array of `VmMemoryFileMapping` with length
+    /// `num_file_mappings`
+    MmapAndRegisterMemory {
+        /// Source of the memory to register (mapped file descriptor, shared memory region, etc.)
+        shm: SharedMemory,
+        /// Where to map the memory in the guest.
+        dest: VmMemoryDestination,
+        /// Length of the array of `VmMemoryFileMapping` that follows.
+        num_file_mappings: usize,
+    },
     /// Call hypervisor to free the given memory range.
     DynamicallyFreeMemoryRange {
         guest_address: GuestAddress,
@@ -587,7 +622,7 @@ pub enum VmMemoryRequest {
 /// Struct for managing `VmMemoryRequest`s IOMMU related state.
 pub struct VmMemoryRequestIommuClient {
     tube: Arc<Mutex<Tube>>,
-    gpu_memory: BTreeSet<MemSlot>,
+    registered_memory: BTreeSet<VmMemoryRegionId>,
 }
 
 impl VmMemoryRequestIommuClient {
@@ -595,31 +630,31 @@ impl VmMemoryRequestIommuClient {
     pub fn new(tube: Arc<Mutex<Tube>>) -> Self {
         Self {
             tube,
-            gpu_memory: BTreeSet::new(),
+            registered_memory: BTreeSet::new(),
         }
     }
 }
 
-pub struct VmMemoryRegionState {
-    // alloc -> (pfn, slot)
-    slot_map: HashMap<Alloc, (u64, MemSlot)>,
-    // id -> (slot, Option<offset, size>)
-    mapped_regions: BTreeMap<VmMemoryRegionId, (MemSlot, Option<(usize, usize)>)>,
+enum RegisteredMemory {
+    FixedMapping {
+        slot: MemSlot,
+        offset: usize,
+        size: usize,
+    },
+    DynamicMapping {
+        slot: MemSlot,
+    },
 }
 
-impl VmMemoryRegionState {
-    pub fn new() -> VmMemoryRegionState {
-        Self {
-            slot_map: HashMap::new(),
-            mapped_regions: BTreeMap::new(),
-        }
-    }
+pub struct VmMappedMemoryRegion {
+    gfn: u64,
+    slot: MemSlot,
 }
 
-impl Default for VmMemoryRegionState {
-    fn default() -> Self {
-        Self::new()
-    }
+#[derive(Default)]
+pub struct VmMemoryRegionState {
+    mapped_regions: HashMap<Alloc, VmMappedMemoryRegion>,
+    registered_memory: BTreeMap<VmMemoryRegionId, RegisteredMemory>,
 }
 
 fn try_map_to_prepared_region(
@@ -629,11 +664,15 @@ fn try_map_to_prepared_region(
     dest: &VmMemoryDestination,
     prot: &Protection,
 ) -> Option<VmMemoryResponse> {
-    let VmMemoryDestination::ExistingAllocation { allocation, offset } = dest else {
+    let VmMemoryDestination::ExistingAllocation {
+        allocation,
+        offset: dest_offset,
+    } = dest
+    else {
         return None;
     };
 
-    let (pfn, slot) = region_state.slot_map.get(allocation)?;
+    let VmMappedMemoryRegion { gfn, slot } = region_state.mapped_regions.get(allocation)?;
 
     let (descriptor, file_offset, size) = match source {
         VmMemorySource::Descriptor {
@@ -659,7 +698,7 @@ fn try_map_to_prepared_region(
     };
     if let Err(err) = vm.add_fd_mapping(
         *slot,
-        *offset as usize,
+        *dest_offset as usize,
         size,
         &descriptor,
         file_offset,
@@ -667,12 +706,22 @@ fn try_map_to_prepared_region(
     ) {
         return Some(VmMemoryResponse::Err(err));
     }
-    let pfn = pfn + (offset >> 12);
-    region_state.mapped_regions.insert(
-        VmMemoryRegionId(pfn),
-        (*slot, Some((*offset as usize, size))),
+
+    let gfn = gfn + (dest_offset >> 12);
+    let region_id = VmMemoryRegionId(gfn);
+    region_state.registered_memory.insert(
+        region_id,
+        RegisteredMemory::FixedMapping {
+            slot: *slot,
+            offset: *dest_offset as usize,
+            size,
+        },
     );
-    Some(VmMemoryResponse::RegisterMemory(VmMemoryRegionId(pfn)))
+
+    Some(VmMemoryResponse::RegisterMemory {
+        region_id,
+        slot: *slot,
+    })
 }
 
 impl VmMemoryRequest {
@@ -687,6 +736,7 @@ impl VmMemoryRequest {
     /// that received this `VmMemoryResponse`.
     pub fn execute(
         self,
+        #[cfg(any(target_os = "android", target_os = "linux"))] tube: &Tube,
         vm: &mut impl Vm,
         sys_allocator: &mut SystemAllocator,
         gralloc: &mut RutabagaGralloc,
@@ -710,8 +760,8 @@ impl VmMemoryRequest {
                 }
 
                 match sys::prepare_shared_memory_region(vm, sys_allocator, alloc, cache) {
-                    Ok(info) => {
-                        region_state.slot_map.insert(alloc, info);
+                    Ok(region) => {
+                        region_state.mapped_regions.insert(alloc, region);
                         VmMemoryResponse::Ok
                     }
                     Err(e) => VmMemoryResponse::Err(e),
@@ -752,11 +802,12 @@ impl VmMemoryRequest {
                     Err(e) => return VmMemoryResponse::Err(e),
                 };
 
+                let region_id = VmMemoryRegionId(guest_addr.0 >> 12);
                 if let (Some(descriptor), Some(iommu_client)) = (descriptor, iommu_client) {
                     let request =
                         VirtioIOMMURequest::VfioCommand(VirtioIOMMUVfioCommand::VfioDmabufMap {
-                            mem_slot: slot,
-                            gfn: guest_addr.0 >> 12,
+                            region_id,
+                            gpa: guest_addr.0,
                             size,
                             dma_buf: descriptor,
                         });
@@ -771,22 +822,120 @@ impl VmMemoryRequest {
                         }
                     };
 
-                    iommu_client.gpu_memory.insert(slot);
+                    iommu_client.registered_memory.insert(region_id);
                 }
 
-                let pfn = guest_addr.0 >> 12;
                 region_state
-                    .mapped_regions
-                    .insert(VmMemoryRegionId(pfn), (slot, None));
-                VmMemoryResponse::RegisterMemory(VmMemoryRegionId(pfn))
+                    .registered_memory
+                    .insert(region_id, RegisteredMemory::DynamicMapping { slot });
+                VmMemoryResponse::RegisterMemory { region_id, slot }
+            }
+            #[cfg(any(target_os = "android", target_os = "linux"))]
+            MmapAndRegisterMemory {
+                shm,
+                dest,
+                num_file_mappings,
+            } => {
+                // Define a callback to be executed with extended limit of file counts.
+                // It recieves `num_file_mappings` FDs and call `add_fd_mapping` for each.
+                let callback = || {
+                    let mem = match MemoryMappingBuilder::new(shm.size() as usize)
+                        .from_shared_memory(&shm)
+                        .build()
+                    {
+                        Ok(mem) => mem,
+                        Err(e) => {
+                            error!("Failed to build MemoryMapping from shared memory: {:#}", e);
+                            return Err(VmMemoryResponse::Err(SysError::new(EINVAL)));
+                        }
+                    };
+                    let mut mmap_arena = MemoryMappingArena::from(mem);
+
+                    // If `num_file_mappings` exceeds `SCM_MAX_FD`, `file_mappings` are sent in
+                    // chunks of length `SCM_MAX_FD`.
+                    let mut file_mappings = Vec::with_capacity(num_file_mappings);
+                    let mut read = 0;
+                    while read < num_file_mappings {
+                        let len = std::cmp::min(num_file_mappings - read, base::unix::SCM_MAX_FD);
+                        let mps: Vec<VmMemoryFileMapping> = match tube.recv_with_max_fds(len) {
+                            Ok(m) => m,
+                            Err(e) => {
+                                error!(
+                                    "Failed to get {num_file_mappings} FDs to be mapped: {:#}",
+                                    e
+                                );
+                                return Err(VmMemoryResponse::Err(SysError::new(EINVAL)));
+                            }
+                        };
+                        file_mappings.extend(mps.into_iter());
+                        read += len;
+                    }
+
+                    for VmMemoryFileMapping {
+                        mem_offset,
+                        length,
+                        file,
+                        file_offset,
+                    } in file_mappings
+                    {
+                        if let Err(e) = mmap_arena.add_fd_mapping(
+                            mem_offset,
+                            length,
+                            &file,
+                            file_offset,
+                            Protection::read(),
+                        ) {
+                            error!("Failed to add fd mapping: {:#}", e);
+                            return Err(VmMemoryResponse::Err(SysError::new(EINVAL)));
+                        }
+                    }
+                    Ok(mmap_arena)
+                };
+                let mmap_arena = match call_with_extended_max_files(callback) {
+                    Ok(Ok(m)) => m,
+                    Ok(Err(e)) => {
+                        return e;
+                    }
+                    Err(e) => {
+                        error!("Failed to set max count of file descriptors: {e}");
+                        return VmMemoryResponse::Err(e);
+                    }
+                };
+
+                let size = shm.size();
+                let guest_addr = match dest.allocate(sys_allocator, size) {
+                    Ok(addr) => addr,
+                    Err(e) => return VmMemoryResponse::Err(e),
+                };
+
+                let slot = match vm.add_memory_region(
+                    guest_addr,
+                    Box::new(mmap_arena),
+                    true,
+                    false,
+                    MemCacheType::CacheCoherent,
+                ) {
+                    Ok(slot) => slot,
+                    Err(e) => return VmMemoryResponse::Err(e),
+                };
+
+                let region_id = VmMemoryRegionId(guest_addr.0 >> 12);
+
+                region_state
+                    .registered_memory
+                    .insert(region_id, RegisteredMemory::DynamicMapping { slot });
+
+                VmMemoryResponse::RegisterMemory { region_id, slot }
             }
-            UnregisterMemory(id) => match region_state.mapped_regions.remove(&id) {
-                Some((slot, None)) => match vm.remove_memory_region(slot) {
+            UnregisterMemory(id) => match region_state.registered_memory.remove(&id) {
+                Some(RegisteredMemory::DynamicMapping { slot }) => match vm
+                    .remove_memory_region(slot)
+                {
                     Ok(_) => {
                         if let Some(iommu_client) = iommu_client {
-                            if iommu_client.gpu_memory.remove(&slot) {
+                            if iommu_client.registered_memory.remove(&id) {
                                 let request = VirtioIOMMURequest::VfioCommand(
-                                    VirtioIOMMUVfioCommand::VfioDmabufUnmap(slot),
+                                    VirtioIOMMUVfioCommand::VfioDmabufUnmap(id),
                                 );
 
                                 match virtio_iommu_request(&iommu_client.tube.lock(), &request) {
@@ -807,10 +956,12 @@ impl VmMemoryRequest {
                     }
                     Err(e) => VmMemoryResponse::Err(e),
                 },
-                Some((slot, Some((offset, size)))) => match vm.remove_mapping(slot, offset, size) {
-                    Ok(()) => VmMemoryResponse::Ok,
-                    Err(e) => VmMemoryResponse::Err(e),
-                },
+                Some(RegisteredMemory::FixedMapping { slot, offset, size }) => {
+                    match vm.remove_mapping(slot, offset, size) {
+                        Ok(()) => VmMemoryResponse::Ok,
+                        Err(e) => VmMemoryResponse::Err(e),
+                    }
+                }
                 None => VmMemoryResponse::Err(SysError::new(EINVAL)),
             },
             DynamicallyFreeMemoryRange {
@@ -898,13 +1049,16 @@ impl VmMemoryRequest {
 
 #[derive(Serialize, Deserialize, Debug, PartialOrd, PartialEq, Eq, Ord, Clone, Copy)]
 /// Identifer for registered memory regions. Globally unique.
-// The current implementation uses pfn as the unique identifier.
+// The current implementation uses gfn as the unique identifier.
 pub struct VmMemoryRegionId(u64);
 
 #[derive(Serialize, Deserialize, Debug)]
 pub enum VmMemoryResponse {
     /// The request to register memory into guest address space was successful.
-    RegisterMemory(VmMemoryRegionId),
+    RegisterMemory {
+        region_id: VmMemoryRegionId,
+        slot: u32,
+    },
     Ok,
     Err(SysError),
 }
@@ -1263,6 +1417,7 @@ pub enum PvClockCommand {
 #[derive(Serialize, Deserialize, Debug)]
 pub enum PvClockCommandResponse {
     Ok,
+    Resumed { total_suspended_ticks: u64 },
     DeviceInactive,
     Err(SysError),
 }
@@ -1289,16 +1444,19 @@ pub enum VmRequest {
     Powerbtn,
     /// Trigger a sleep button event in the guest.
     Sleepbtn,
-    /// Trigger a RTC interrupt in the guest.
-    Rtc,
+    /// Trigger a RTC interrupt in the guest. When the irq associated with the RTC is
+    /// resampled, it will be re-asserted as long as `clear_evt` is not signaled.
+    Rtc { clear_evt: Event },
     /// Suspend the VM's VCPUs until resume.
     SuspendVcpus,
     /// Swap the memory content into files on a disk
     Swap(SwapCommand),
     /// Resume the VM's VCPUs that were previously suspended.
     ResumeVcpus,
-    /// Inject a general-purpose event.
-    Gpe(u32),
+    /// Inject a general-purpose event. If `clear_evt` is provided, when the irq associated
+    /// with the GPE is resampled, it will be re-asserted as long as `clear_evt` is not
+    /// signaled.
+    Gpe { gpe: u32, clear_evt: Option<Event> },
     /// Inject a PCI PME
     PciPme(u16),
     /// Make the VM's RT VCPU real-time.
@@ -1330,29 +1488,27 @@ pub enum VmRequest {
     /// Command to Snapshot devices
     Snapshot(SnapshotCommand),
     /// Register for event notification
-    #[cfg(feature = "registered_events")]
     RegisterListener {
         socket_addr: String,
         event: RegisteredEvent,
     },
     /// Unregister for notifications for event
-    #[cfg(feature = "registered_events")]
     UnregisterListener {
         socket_addr: String,
         event: RegisteredEvent,
     },
     /// Unregister for all event notification
-    #[cfg(feature = "registered_events")]
     Unregister { socket_addr: String },
     /// Suspend VM VCPUs and Devices until resume.
     SuspendVm,
     /// Resume VM VCPUs and Devices.
     ResumeVm,
+    /// Returns Vcpus PID/TID
+    VcpuPidTid,
 }
 
 /// NOTE: when making any changes to this enum please also update
 /// RegisteredEventFfi in crosvm_control/src/lib.rs
-#[cfg(feature = "registered_events")]
 #[derive(Serialize, Deserialize, Debug, PartialEq, Eq, Hash, Clone, Copy)]
 pub enum RegisteredEvent {
     VirtioBalloonWsReport,
@@ -1360,18 +1516,16 @@ pub enum RegisteredEvent {
     VirtioBalloonOOMDeflation,
 }
 
-#[cfg(feature = "registered_events")]
 #[derive(Serialize, Deserialize, Debug)]
 pub enum RegisteredEventWithData {
     VirtioBalloonWsReport {
-        ws_buckets: Vec<WSBucket>,
+        ws_buckets: Vec<balloon_control::WSBucket>,
         balloon_actual: u64,
     },
     VirtioBalloonResize,
     VirtioBalloonOOMDeflation,
 }
 
-#[cfg(feature = "registered_events")]
 impl RegisteredEventWithData {
     pub fn into_event(&self) -> RegisteredEvent {
         match self {
@@ -1381,6 +1535,7 @@ impl RegisteredEventWithData {
         }
     }
 
+    #[cfg(feature = "registered_events")]
     pub fn into_proto(&self) -> registered_events::RegisteredEvent {
         match self {
             Self::VirtioBalloonWsReport {
@@ -1416,7 +1571,7 @@ impl RegisteredEventWithData {
         }
     }
 
-    pub fn from_ws(ws: &BalloonWS, balloon_actual: u64) -> Self {
+    pub fn from_ws(ws: &balloon_control::BalloonWS, balloon_actual: u64) -> Self {
         RegisteredEventWithData::VirtioBalloonWsReport {
             ws_buckets: ws.ws.clone(),
             balloon_actual,
@@ -1463,7 +1618,9 @@ fn map_descriptor(
 }
 
 // Get vCPU state. vCPUs are expected to all hold the same state.
-// In this function, there may be a time where vCPUs are not
+// In this function, there may be a time where vCPUs are not holding the same state
+// as they transition from one state to the other. This is expected, and the final result
+// should be all vCPUs holding the same state.
 fn get_vcpu_state(kick_vcpus: impl Fn(VcpuControl), vcpu_num: usize) -> anyhow::Result<VmRunMode> {
     let (send_chan, recv_chan) = mpsc::channel();
     kick_vcpus(VcpuControl::GetStates(send_chan));
@@ -1608,10 +1765,18 @@ impl VmRequest {
     /// This does not return a result, instead encapsulating the success or failure in a
     /// `VmResponse` with the intended purpose of sending the response back over the  socket that
     /// received this `VmRequest`.
+    ///
+    /// `suspended_pvclock_state`: If the hypervisor has its own pvclock (not the same as
+    /// virtio-pvclock) and the VM is suspended (not just the vCPUs, but the full VM), then
+    /// `suspended_pvclock_state` will be used to store the ClockState saved just after the vCPUs
+    /// were suspended. It is important that we save the value right after the vCPUs are suspended
+    /// and restore it right before the vCPUs are resumed (instead of, more naturally, during the
+    /// snapshot/restore steps) because the pvclock continues to tick even when the vCPUs are
+    /// suspended.
+    #[allow(unused_variables)]
     pub fn execute(
         &self,
         vm: &impl Vm,
-        run_mode: &mut Option<VmRunMode>,
         disk_host_tubes: &[Tube],
         pm: &mut Option<Arc<Mutex<dyn PmResource + Send>>>,
         gpu_control_tube: Option<&Tube>,
@@ -1624,11 +1789,11 @@ impl VmRequest {
         vcpu_size: usize,
         irq_handler_control: &Tube,
         snapshot_irqchip: impl Fn() -> anyhow::Result<serde_json::Value>,
+        suspended_pvclock_state: &mut Option<hypervisor::ClockState>,
     ) -> VmResponse {
-        match *self {
+        match self {
             VmRequest::Exit => {
-                *run_mode = Some(VmRunMode::Exiting);
-                VmResponse::Ok
+                panic!("VmRequest::Exit should be handled by the platform run loop");
             }
             VmRequest::Powerbtn => {
                 if let Some(pm) = pm {
@@ -1648,17 +1813,39 @@ impl VmRequest {
                     VmResponse::Err(SysError::new(ENOTSUP))
                 }
             }
-            VmRequest::Rtc => {
-                if let Some(pm) = pm {
-                    pm.lock().rtc_evt();
-                    VmResponse::Ok
+            VmRequest::Rtc { clear_evt } => {
+                if let Some(pm) = pm.as_ref() {
+                    match clear_evt.try_clone() {
+                        Ok(clear_evt) => {
+                            // RTC event will asynchronously trigger wakeup.
+                            pm.lock().rtc_evt(clear_evt);
+                            VmResponse::Ok
+                        }
+                        Err(err) => {
+                            error!("Error cloning clear_evt: {:?}", err);
+                            VmResponse::Err(SysError::new(EIO))
+                        }
+                    }
                 } else {
                     error!("{:#?} not supported", *self);
                     VmResponse::Err(SysError::new(ENOTSUP))
                 }
             }
             VmRequest::SuspendVcpus => {
-                *run_mode = Some(VmRunMode::Suspending);
+                if !force_s2idle {
+                    kick_vcpus(VcpuControl::RunState(VmRunMode::Suspending));
+                    let current_mode = match get_vcpu_state(kick_vcpus, vcpu_size) {
+                        Ok(state) => state,
+                        Err(e) => {
+                            error!("failed to get vcpu state: {e}");
+                            return VmResponse::Err(SysError::new(EIO));
+                        }
+                    };
+                    if current_mode != VmRunMode::Suspending {
+                        error!("vCPUs failed to all suspend.");
+                        return VmResponse::Err(SysError::new(EIO));
+                    }
+                }
                 VmResponse::Ok
             }
             VmRequest::ResumeVcpus => {
@@ -1681,7 +1868,6 @@ impl VmRequest {
                     error!("Trying to wake Vcpus while Devices are asleep. Did you mean to use `crosvm resume --full`?");
                     return VmResponse::Err(SysError::new(EINVAL));
                 }
-                *run_mode = Some(VmRunMode::Running);
 
                 if force_s2idle {
                     // During resume also emulate powerbtn event which will allow to wakeup fully
@@ -1693,6 +1879,8 @@ impl VmRequest {
                         return VmResponse::Err(SysError::new(ENOTSUP));
                     }
                 }
+
+                kick_vcpus(VcpuControl::RunState(VmRunMode::Running));
                 VmResponse::Ok
             }
             VmRequest::Swap(SwapCommand::Enable) => {
@@ -1761,7 +1949,7 @@ impl VmRequest {
             }) => {
                 #[cfg(feature = "swap")]
                 if let Some(swap_controller) = swap_controller {
-                    return match swap_controller.disable(slow_file_cleanup) {
+                    return match swap_controller.disable(*slow_file_cleanup) {
                         Ok(()) => VmResponse::Ok,
                         Err(e) => {
                             error!("swap disable failed: {}", e);
@@ -1798,6 +1986,18 @@ impl VmRequest {
                     error!("vCPUs failed to all suspend.");
                     return VmResponse::Err(SysError::new(EIO));
                 }
+                // Snapshot the pvclock ASAP after stopping vCPUs.
+                if vm.check_capability(VmCap::PvClock) {
+                    if suspended_pvclock_state.is_none() {
+                        *suspended_pvclock_state = Some(match vm.get_pvclock() {
+                            Ok(x) => x,
+                            Err(e) => {
+                                error!("suspend_pvclock failed: {e:?}");
+                                return VmResponse::Err(SysError::new(EIO));
+                            }
+                        });
+                    }
+                }
                 if let Err(e) = device_control_tube
                     .send(&DeviceControlCommand::SleepDevices)
                     .context("send command to devices control socket")
@@ -1848,13 +2048,31 @@ impl VmRequest {
                         return VmResponse::Err(SysError::new(EIO));
                     }
                 }
+                // Resume the pvclock as late as possible before starting vCPUs.
+                if vm.check_capability(VmCap::PvClock) {
+                    // If None, then we aren't suspended, which is a valid case.
+                    if let Some(x) = suspended_pvclock_state {
+                        if let Err(e) = vm.set_pvclock(x) {
+                            error!("resume_pvclock failed: {e:?}");
+                            return VmResponse::Err(SysError::new(EIO));
+                        }
+                    }
+                }
                 kick_vcpus(VcpuControl::RunState(VmRunMode::Running));
                 VmResponse::Ok
             }
-            VmRequest::Gpe(gpe) => {
+            VmRequest::Gpe { gpe, clear_evt } => {
                 if let Some(pm) = pm.as_ref() {
-                    pm.lock().gpe_evt(gpe);
-                    VmResponse::Ok
+                    match clear_evt.as_ref().map(|e| e.try_clone()).transpose() {
+                        Ok(clear_evt) => {
+                            pm.lock().gpe_evt(*gpe, clear_evt);
+                            VmResponse::Ok
+                        }
+                        Err(err) => {
+                            error!("Error cloning clear_evt: {:?}", err);
+                            VmResponse::Err(SysError::new(EIO))
+                        }
+                    }
                 } else {
                     error!("{:#?} not supported", *self);
                     VmResponse::Err(SysError::new(ENOTSUP))
@@ -1862,7 +2080,7 @@ impl VmRequest {
             }
             VmRequest::PciPme(requester_id) => {
                 if let Some(pm) = pm.as_ref() {
-                    pm.lock().pme_evt(requester_id);
+                    pm.lock().pme_evt(*requester_id);
                     VmResponse::Ok
                 } else {
                     error!("{:#?} not supported", *self);
@@ -1878,7 +2096,7 @@ impl VmRequest {
             VmRequest::DiskCommand {
                 disk_index,
                 ref command,
-            } => match &disk_host_tubes.get(disk_index) {
+            } => match &disk_host_tubes.get(*disk_index) {
                 Some(tube) => handle_disk_command(command, tube),
                 None => VmResponse::Err(SysError::new(ENODEV)),
             },
@@ -1927,7 +2145,7 @@ impl VmRequest {
             VmRequest::BatCommand(type_, ref cmd) => {
                 match bat_control {
                     Some(battery) => {
-                        if battery.type_ != type_ {
+                        if battery.type_ != *type_ {
                             error!("ignored battery command due to battery type: expected {:?}, got {:?}", battery.type_, type_);
                             return VmResponse::Err(SysError::new(EINVAL));
                         }
@@ -1962,14 +2180,14 @@ impl VmRequest {
                 info!("Starting crosvm snapshot");
                 match do_snapshot(
                     snapshot_path.to_path_buf(),
-                    vm,
                     kick_vcpus,
                     irq_handler_control,
                     device_control_tube,
                     vcpu_size,
                     snapshot_irqchip,
-                    compress_memory,
-                    encrypt,
+                    *compress_memory,
+                    *encrypt,
+                    suspended_pvclock_state,
                 ) {
                     Ok(()) => {
                         info!("Finished crosvm snapshot successfully");
@@ -1981,18 +2199,16 @@ impl VmRequest {
                     }
                 }
             }
-            #[cfg(feature = "registered_events")]
             VmRequest::RegisterListener {
                 socket_addr: _,
                 event: _,
             } => VmResponse::Ok,
-            #[cfg(feature = "registered_events")]
             VmRequest::UnregisterListener {
                 socket_addr: _,
                 event: _,
             } => VmResponse::Ok,
-            #[cfg(feature = "registered_events")]
             VmRequest::Unregister { socket_addr: _ } => VmResponse::Ok,
+            VmRequest::VcpuPidTid => unreachable!(),
         }
     }
 }
@@ -2000,7 +2216,6 @@ impl VmRequest {
 /// Snapshot the VM to file at `snapshot_path`
 fn do_snapshot(
     snapshot_path: PathBuf,
-    vm: &impl Vm,
     kick_vcpus: impl Fn(VcpuControl),
     irq_handler_control: &Tube,
     device_control_tube: &Tube,
@@ -2008,6 +2223,7 @@ fn do_snapshot(
     snapshot_irqchip: impl Fn() -> anyhow::Result<serde_json::Value>,
     compress_memory: bool,
     encrypt: bool,
+    suspended_pvclock_state: &mut Option<hypervisor::ClockState>,
 ) -> anyhow::Result<()> {
     let _vcpu_guard = VcpuSuspendGuard::new(&kick_vcpus, vcpu_size)?;
     let _device_guard = DeviceSleepGuard::new(device_control_tube)?;
@@ -2058,12 +2274,7 @@ fn do_snapshot(
     let snapshot_writer = SnapshotWriter::new(snapshot_path, encrypt)?;
 
     // Snapshot hypervisor's paravirtualized clock.
-    let pvclock_snapshot = if vm.check_capability(VmCap::PvClock) {
-        serde_json::to_value(vm.get_pvclock()?)?
-    } else {
-        serde_json::Value::Null
-    };
-    snapshot_writer.write_fragment("pvclock", &pvclock_snapshot)?;
+    snapshot_writer.write_fragment("pvclock", &serde_json::to_value(suspended_pvclock_state)?)?;
 
     // Snapshot Vcpus
     info!("VCPUs snapshotting...");
@@ -2112,8 +2323,7 @@ fn do_snapshot(
 /// Same as `VmRequest::execute` with a `VmRequest::Restore`. Exposed as a separate function
 /// because not all the `VmRequest::execute` arguments are available in the "cold restore" flow.
 pub fn do_restore(
-    restore_path: PathBuf,
-    vm: &impl Vm,
+    restore_path: &Path,
     kick_vcpus: impl Fn(VcpuControl),
     kick_vcpu: impl Fn(VcpuControl, usize),
     irq_handler_control: &Tube,
@@ -2121,6 +2331,7 @@ pub fn do_restore(
     vcpu_size: usize,
     mut restore_irqchip: impl FnMut(serde_json::Value) -> anyhow::Result<()>,
     require_encrypted: bool,
+    suspended_pvclock_state: &mut Option<hypervisor::ClockState>,
 ) -> anyhow::Result<()> {
     let _guard = VcpuSuspendGuard::new(&kick_vcpus, vcpu_size);
     let _devices_guard = DeviceSleepGuard::new(device_control_tube)?;
@@ -2128,12 +2339,7 @@ pub fn do_restore(
     let snapshot_reader = SnapshotReader::new(restore_path, require_encrypted)?;
 
     // Restore hypervisor's paravirtualized clock.
-    let pvclock_snapshot: serde_json::Value = snapshot_reader.read_fragment("pvclock")?;
-    if vm.check_capability(VmCap::PvClock) {
-        vm.set_pvclock(&serde_json::from_value(pvclock_snapshot)?)?;
-    } else {
-        anyhow::ensure!(pvclock_snapshot == serde_json::Value::Null);
-    };
+    *suspended_pvclock_state = snapshot_reader.read_fragment("pvclock")?;
 
     // Restore IrqChip
     let irq_snapshot: serde_json::Value = snapshot_reader.read_fragment("irqchip")?;
@@ -2211,18 +2417,21 @@ pub enum VmResponse {
     Err(SysError),
     /// Indicates the request encountered some error during execution.
     ErrString(String),
-    /// The request to register memory into guest address space was successfully done at page frame
-    /// number `pfn` and memory slot number `slot`.
-    RegisterMemory { pfn: u64, slot: u32 },
+    /// The request to register memory into guest address space was successfully done at guest page
+    /// frame number `gfn` and memory slot number `slot`.
+    RegisterMemory { gfn: u64, slot: u32 },
     /// Results of balloon control commands.
     #[cfg(feature = "balloon")]
     BalloonStats {
-        stats: BalloonStats,
+        stats: balloon_control::BalloonStats,
         balloon_actual: u64,
     },
     /// Results of balloon WS-R command
     #[cfg(feature = "balloon")]
-    BalloonWS { ws: BalloonWS, balloon_actual: u64 },
+    BalloonWS {
+        ws: balloon_control::BalloonWS,
+        balloon_actual: u64,
+    },
     /// Results of PCI hot plug
     #[cfg(feature = "pci-hotplug")]
     PciHotPlugResponse { bus: u8 },
@@ -2237,6 +2446,10 @@ pub enum VmResponse {
     SwapStatus(SwapStatus),
     /// Gets the state of Devices (sleep/wake)
     DevicesState(DevicesState),
+    /// Map of the Vcpu PID/TIDs
+    VcpuPidTidResponse {
+        pid_tid_map: BTreeMap<usize, (u32, u32)>,
+    },
 }
 
 impl Display for VmResponse {
@@ -2247,10 +2460,10 @@ impl Display for VmResponse {
             Ok => write!(f, "ok"),
             Err(e) => write!(f, "error: {}", e),
             ErrString(e) => write!(f, "error: {}", e),
-            RegisterMemory { pfn, slot } => write!(
+            RegisterMemory { gfn, slot } => write!(
                 f,
-                "memory registered to page frame number {:#x} and memory slot {}",
-                pfn, slot
+                "memory registered to guest page frame number {:#x} and memory slot {}",
+                gfn, slot
             ),
             #[cfg(feature = "balloon")]
             VmResponse::BalloonStats {
@@ -2290,6 +2503,7 @@ impl Display for VmResponse {
                 )
             }
             DevicesState(status) => write!(f, "devices status: {:?}", status),
+            VcpuPidTidResponse { pid_tid_map } => write!(f, "vcpu pid tid map: {:?}", pid_tid_map),
         }
     }
 }
@@ -2329,13 +2543,13 @@ pub enum VirtioIOMMUVfioCommand {
     },
     // Map a dma-buf into vfio iommu table
     VfioDmabufMap {
-        mem_slot: MemSlot,
-        gfn: u64,
+        region_id: VmMemoryRegionId,
+        gpa: u64,
         size: u64,
         dma_buf: SafeDescriptor,
     },
     // Unmap a dma-buf from vfio iommu table
-    VfioDmabufUnmap(MemSlot),
+    VfioDmabufUnmap(VmMemoryRegionId),
 }
 
 #[derive(Serialize, Deserialize, Debug)]
diff --git a/vm_control/src/snapshot_format.rs b/vm_control/src/snapshot_format.rs
index 0e5a4c4c6..215769bb5 100644
--- a/vm_control/src/snapshot_format.rs
+++ b/vm_control/src/snapshot_format.rs
@@ -154,7 +154,7 @@ impl Debug for SnapshotReader {
 
 impl SnapshotReader {
     /// Reads a snapshot at `root`. Set require_encrypted to require an encrypted snapshot.
-    pub fn new(root: PathBuf, require_encrypted: bool) -> Result<Self> {
+    pub fn new(root: &Path, require_encrypted: bool) -> Result<Self> {
         let enc_metadata_path = root.join("enc_metadata");
         if Path::exists(&enc_metadata_path) {
             let key = Some(
@@ -163,13 +163,16 @@ impl SnapshotReader {
                 )
                 .context("failed to load snapshot key")?,
             );
-            return Ok(Self { dir: root, key });
+            return Ok(Self {
+                dir: root.to_path_buf(),
+                key,
+            });
         } else if require_encrypted {
             return Err(anyhow::anyhow!("snapshot was not encrypted"));
         }
 
         Ok(Self {
-            dir: root,
+            dir: root.to_path_buf(),
             key: None,
         })
     }
diff --git a/vm_control/src/sys.rs b/vm_control/src/sys.rs
index f95e96ec0..29bfdb6ef 100644
--- a/vm_control/src/sys.rs
+++ b/vm_control/src/sys.rs
@@ -6,10 +6,9 @@ cfg_if::cfg_if! {
     if #[cfg(any(target_os = "android", target_os = "linux"))] {
         pub mod linux;
         use linux as platform;
-        pub use platform::{VmMsyncRequest, VmMsyncResponse, FsMappingRequest};
+        pub use platform::{VmMemoryMappingRequest, VmMemoryMappingResponse, FsMappingRequest};
         #[cfg(feature = "gpu")]
         pub use platform::gpu::UnixDisplayMode as DisplayMode;
-        pub use platform::handle_request_with_timeout;
         #[cfg(feature = "gpu")]
         pub use platform::gpu::UnixMouseMode as MouseMode;
     } else if #[cfg(windows)] {
@@ -19,11 +18,13 @@ cfg_if::cfg_if! {
         pub type DisplayMode = platform::gpu::WinDisplayMode<platform::gpu::DisplayDataProvider>;
         #[cfg(feature = "gpu")]
         pub use platform::gpu::WinMouseMode as MouseMode;
+        pub use platform::InitialAudioSessionState;
     } else {
         compile_error!("Unsupported platform");
     }
 }
 
 pub use platform::handle_request;
+pub use platform::handle_request_with_timeout;
 pub use platform::prepare_shared_memory_region;
 pub use platform::should_prepare_memory_region;
diff --git a/vm_control/src/sys/linux.rs b/vm_control/src/sys/linux.rs
index 86be8889b..729749723 100644
--- a/vm_control/src/sys/linux.rs
+++ b/vm_control/src/sys/linux.rs
@@ -31,6 +31,7 @@ use serde::Serialize;
 use vm_memory::GuestAddress;
 
 use crate::client::HandleRequestResult;
+use crate::VmMappedMemoryRegion;
 use crate::VmRequest;
 use crate::VmResponse;
 
@@ -84,7 +85,7 @@ pub fn handle_request_with_timeout<T: AsRef<Path> + std::fmt::Debug>(
 }
 
 #[derive(Serialize, Deserialize, Debug)]
-pub enum VmMsyncRequest {
+pub enum VmMemoryMappingRequest {
     /// Flush the content of a memory mapping to its backing file.
     /// `slot` selects the arena (as returned by `Vm::add_mmap_arena`).
     /// `offset` is the offset of the mapping to sync within the arena.
@@ -94,15 +95,31 @@ pub enum VmMsyncRequest {
         offset: usize,
         size: usize,
     },
+
+    /// Gives a MADV_PAGEOUT advice to the memory region mapped at `slot`, with the address range
+    /// starting at `offset` from the start of the region, and with size `size`.
+    MadvisePageout {
+        slot: MemSlot,
+        offset: usize,
+        size: usize,
+    },
+
+    /// Gives a MADV_REMOVE advice to the memory region mapped at `slot`, with the address range
+    /// starting at `offset` from the start of the region, and with size `size`.
+    MadviseRemove {
+        slot: MemSlot,
+        offset: usize,
+        size: usize,
+    },
 }
 
 #[derive(Serialize, Deserialize, Debug)]
-pub enum VmMsyncResponse {
+pub enum VmMemoryMappingResponse {
     Ok,
     Err(SysError),
 }
 
-impl VmMsyncRequest {
+impl VmMemoryMappingRequest {
     /// Executes this request on the given Vm.
     ///
     /// # Arguments
@@ -111,13 +128,25 @@ impl VmMsyncRequest {
     /// This does not return a result, instead encapsulating the success or failure in a
     /// `VmMsyncResponse` with the intended purpose of sending the response back over the socket
     /// that received this `VmMsyncResponse`.
-    pub fn execute(&self, vm: &mut impl Vm) -> VmMsyncResponse {
-        use self::VmMsyncRequest::*;
+    pub fn execute(&self, vm: &mut impl Vm) -> VmMemoryMappingResponse {
+        use self::VmMemoryMappingRequest::*;
         match *self {
             MsyncArena { slot, offset, size } => match vm.msync_memory_region(slot, offset, size) {
-                Ok(()) => VmMsyncResponse::Ok,
-                Err(e) => VmMsyncResponse::Err(e),
+                Ok(()) => VmMemoryMappingResponse::Ok,
+                Err(e) => VmMemoryMappingResponse::Err(e),
             },
+            MadvisePageout { slot, offset, size } => {
+                match vm.madvise_pageout_memory_region(slot, offset, size) {
+                    Ok(()) => VmMemoryMappingResponse::Ok,
+                    Err(e) => VmMemoryMappingResponse::Err(e),
+                }
+            }
+            MadviseRemove { slot, offset, size } => {
+                match vm.madvise_remove_memory_region(slot, offset, size) {
+                    Ok(()) => VmMemoryMappingResponse::Ok,
+                    Err(e) => VmMemoryMappingResponse::Err(e),
+                }
+            }
         }
     }
 }
@@ -159,7 +188,7 @@ pub fn prepare_shared_memory_region(
     allocator: &mut SystemAllocator,
     alloc: Alloc,
     cache: MemCacheType,
-) -> Result<(u64, MemSlot), SysError> {
+) -> Result<VmMappedMemoryRegion, SysError> {
     if !matches!(alloc, Alloc::PciBar { .. }) {
         return Err(SysError::new(EINVAL));
     }
@@ -182,7 +211,10 @@ pub fn prepare_shared_memory_region(
                 false,
                 cache,
             ) {
-                Ok(slot) => Ok((range.start >> 12, slot)),
+                Ok(slot) => Ok(VmMappedMemoryRegion {
+                    gfn: range.start >> 12,
+                    slot,
+                }),
                 Err(e) => Err(e),
             }
         }
@@ -223,7 +255,9 @@ impl FsMappingRequest {
                     alloc,
                     MemCacheType::CacheCoherent,
                 ) {
-                    Ok((pfn, slot)) => VmResponse::RegisterMemory { pfn, slot },
+                    Ok(VmMappedMemoryRegion { gfn, slot }) => {
+                        VmResponse::RegisterMemory { gfn, slot }
+                    }
                     Err(e) => VmResponse::Err(e),
                 }
             }
diff --git a/vm_control/src/sys/windows.rs b/vm_control/src/sys/windows.rs
index f839fa1cf..b68ba6cb2 100644
--- a/vm_control/src/sys/windows.rs
+++ b/vm_control/src/sys/windows.rs
@@ -8,6 +8,7 @@ pub(crate) mod gpu;
 use std::io::Result;
 use std::mem::size_of;
 use std::path::Path;
+use std::time::Duration;
 
 use base::error;
 use base::named_pipes::BlockingMode;
@@ -18,12 +19,12 @@ use base::Error;
 use base::Event;
 use base::PipeTube;
 use hypervisor::MemCacheType;
-use hypervisor::MemSlot;
 use hypervisor::Vm;
 use resources::Alloc;
 use resources::SystemAllocator;
 
 use crate::client::HandleRequestResult;
+use crate::VmMappedMemoryRegion;
 use crate::VmRequest;
 
 pub const SERVICE_MESSAGE_HEADER_SIZE: usize = size_of::<u32>();
@@ -68,6 +69,19 @@ pub fn handle_request<T: AsRef<Path> + std::fmt::Debug>(
     }
 }
 
+pub fn handle_request_with_timeout<T: AsRef<Path> + std::fmt::Debug>(
+    request: &VmRequest,
+    socket_path: T,
+    timeout: Option<Duration>,
+) -> HandleRequestResult {
+    if timeout.is_none() {
+        handle_request(request, socket_path)
+    } else {
+        error!("handle_request_with_timeout() not implemented for Windows");
+        Err(())
+    }
+}
+
 /// Send the size header first and then the protbuf message.
 ///
 /// A helper function to keep communication with service consistent across crosvm code.
@@ -113,6 +127,15 @@ pub fn prepare_shared_memory_region(
     _allocator: &mut SystemAllocator,
     _alloc: Alloc,
     _cache: MemCacheType,
-) -> std::result::Result<(u64, MemSlot), Error> {
+) -> std::result::Result<VmMappedMemoryRegion, Error> {
     unimplemented!()
 }
+
+/// State of a specific audio device on boot.
+pub struct InitialAudioSessionState {
+    // Uniquely identify an audio device. In ALSA terminology, this is the card_index as opposed to
+    // a device index.
+    pub card_index: usize,
+    // GUID assigned to the device's IAudioClient
+    pub audio_client_guid: String,
+}
diff --git a/vm_memory/Android.bp b/vm_memory/Android.bp
index 5ab3db8e9..0edef3023 100644
--- a/vm_memory/Android.bp
+++ b/vm_memory/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "vm_memory",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     rustlibs: [
         "libanyhow",
@@ -46,7 +46,7 @@ rust_test {
     crate_name: "vm_memory",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
diff --git a/vm_memory/Cargo.toml b/vm_memory/Cargo.toml
index c825232d6..164837e05 100644
--- a/vm_memory/Cargo.toml
+++ b/vm_memory/Cargo.toml
@@ -10,15 +10,15 @@ anyhow = "1.0.32"
 cfg-if = "1.0.0"
 cros_async = { path = "../cros_async" }
 data_model = { path = "../common/data_model" }
-libc = "*"
+libc = "0.2"
 lz4_flex = "0.11"
 base = { path = "../base" }
 bitflags = "2.2.1"
-remain = "*"
+remain = "0.2"
 serde = { version = "1", features = [ "derive" ] }
-serde_json = "*"
-thiserror = "*"
+serde_json = "1"
+thiserror = "1"
 zerocopy = { version = "0.7", features = ["derive"] }
 
-[dev_dependencies]
+[dev-dependencies]
 tempfile = "3"
diff --git a/vm_memory/src/guest_address.rs b/vm_memory/src/guest_address.rs
index eb8e05cfb..df3a2a2d1 100644
--- a/vm_memory/src/guest_address.rs
+++ b/vm_memory/src/guest_address.rs
@@ -82,6 +82,17 @@ impl GuestAddress {
         }
         self.checked_add(align - 1).map(|a| a & !(align - 1))
     }
+
+    /// Returns the next lowest address that is a multiple of `align`, or an unchanged copy of the
+    /// address if it's already a multiple of `align`.
+    ///
+    /// `align` must be a power of 2.
+    pub fn align_down(self, align: u64) -> GuestAddress {
+        if align <= 1 {
+            return self;
+        }
+        self & !(align - 1)
+    }
 }
 
 impl BitAnd<u64> for GuestAddress {
@@ -190,4 +201,24 @@ mod tests {
         );
         assert_eq!(GuestAddress(u64::MAX).align(2), None);
     }
+
+    #[test]
+    fn align_down() {
+        assert_eq!(GuestAddress(12345).align_down(0), GuestAddress(12345));
+        assert_eq!(GuestAddress(12345).align_down(1), GuestAddress(12345));
+        assert_eq!(GuestAddress(12345).align_down(2), GuestAddress(12344));
+        assert_eq!(GuestAddress(0).align_down(4096), GuestAddress(0));
+        assert_eq!(GuestAddress(1).align_down(4096), GuestAddress(0));
+        assert_eq!(GuestAddress(4095).align_down(4096), GuestAddress(0));
+        assert_eq!(GuestAddress(4096).align_down(4096), GuestAddress(4096));
+        assert_eq!(GuestAddress(4097).align_down(4096), GuestAddress(4096));
+        assert_eq!(
+            GuestAddress(u64::MAX & !4095).align_down(4096),
+            GuestAddress(u64::MAX & !4095),
+        );
+        assert_eq!(
+            GuestAddress(u64::MAX).align_down(2),
+            GuestAddress(u64::MAX - 1)
+        );
+    }
 }
diff --git a/vm_memory/src/guest_memory.rs b/vm_memory/src/guest_memory.rs
index 89cd99ad4..a6b30e93f 100644
--- a/vm_memory/src/guest_memory.rs
+++ b/vm_memory/src/guest_memory.rs
@@ -58,8 +58,8 @@ pub enum Error {
     MemoryCreationFailed(#[source] SysError),
     #[error("failed to map guest memory: {0}")]
     MemoryMappingFailed(#[source] MmapError),
-    #[error("shm regions must be page aligned")]
-    MemoryNotAligned,
+    #[error("guest memory region {0}+{1:#x} is not page aligned")]
+    MemoryNotAligned(GuestAddress, u64),
     #[error("memory regions overlap")]
     MemoryRegionOverlap,
     #[error("memory region size {0} is too large")]
@@ -118,7 +118,6 @@ pub enum MemoryRegionPurpose {
     // General purpose guest memory
     #[default]
     GuestMemoryRegion,
-    #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
     ProtectedFirmwareRegion,
     #[cfg(any(target_arch = "arm", target_arch = "aarch64"))]
     StaticSwiotlbRegion,
@@ -250,7 +249,7 @@ impl GuestMemory {
         let pg_size = pagesize();
         for range in ranges {
             if range.1 % pg_size as u64 != 0 {
-                return Err(Error::MemoryNotAligned);
+                return Err(Error::MemoryNotAligned(range.0, range.1));
             }
 
             aligned_size += range.1;
diff --git a/vm_memory/src/guest_memory/sys/linux.rs b/vm_memory/src/guest_memory/sys/linux.rs
index e3c0a2922..265265bca 100644
--- a/vm_memory/src/guest_memory/sys/linux.rs
+++ b/vm_memory/src/guest_memory/sys/linux.rs
@@ -55,7 +55,7 @@ impl GuestMemory {
             return;
         }
 
-        for (_, region) in self.regions.iter().enumerate() {
+        for region in self.regions.iter() {
             if mem_policy.contains(MemoryPolicy::USE_HUGEPAGES) {
                 let ret = region.mapping.use_hugepages();
 
diff --git a/vm_memory/src/udmabuf/sys/linux.rs b/vm_memory/src/udmabuf/sys/linux.rs
index 2268cc609..9c26480b2 100644
--- a/vm_memory/src/udmabuf/sys/linux.rs
+++ b/vm_memory/src/udmabuf/sys/linux.rs
@@ -118,7 +118,7 @@ impl UdmabufDriverTrait for UnixUdmabufDriver {
         let fd = unsafe {
             let create_list = list.as_mut_ptr();
             (*create_list).flags = UDMABUF_FLAGS_CLOEXEC;
-            ioctl_with_ptr(&self.driver_fd, UDMABUF_CREATE_LIST(), create_list)
+            ioctl_with_ptr(&self.driver_fd, UDMABUF_CREATE_LIST, create_list)
         };
 
         if fd < 0 {
diff --git a/win_audio/Cargo.toml b/win_audio/Cargo.toml
index ea2097421..291520235 100644
--- a/win_audio/Cargo.toml
+++ b/win_audio/Cargo.toml
@@ -10,16 +10,16 @@ audio_streams = { path = "../common/audio_streams"}
 audio_util = { path = "../audio_util" }
 base = { path = "../base" }
 cros_async = { path = "../cros_async" }
-libc = "*"
+libc = "0.2"
 win_util = { path = "../win_util" }
-winapi = "*"
-wio = "*"
+winapi = "0.3"
+wio = "0.2"
 sync = { path = "../common/sync" }
-thiserror = "*"
+thiserror = "1"
 metrics = { path = "../metrics"}
 once_cell = "1.7.2"
 
 [build-dependencies]
-anyhow = "*"
+anyhow = "1"
 prebuilts = { path = "../prebuilts" }
 
diff --git a/win_audio/build.rs b/win_audio/build.rs
index 348523b99..4dd1a482a 100644
--- a/win_audio/build.rs
+++ b/win_audio/build.rs
@@ -26,7 +26,7 @@ fn main() {
         )
         .unwrap();
         let lib_dir = files
-            .get(0)
+            .first()
             .unwrap()
             .parent()
             .unwrap()
diff --git a/win_audio/src/lib.rs b/win_audio/src/lib.rs
index 2f4c2611d..35b88e2b6 100644
--- a/win_audio/src/lib.rs
+++ b/win_audio/src/lib.rs
@@ -112,6 +112,7 @@ pub trait WinAudioServer: StreamSource {
         _frame_rate: usize,
         _buffer_size: usize,
         _ex: &dyn audio_streams::AudioStreamsExecutor,
+        _audio_client_guid: Option<String>,
     ) -> Result<(Box<dyn AsyncPlaybackBufferStream>, AudioSharedFormat), BoxError> {
         unimplemented!()
     }
@@ -214,6 +215,7 @@ impl WinAudioServer for WinAudio {
         frame_rate: usize,
         buffer_size: usize,
         ex: &dyn audio_streams::AudioStreamsExecutor,
+        audio_client_guid: Option<String>,
     ) -> Result<(Box<dyn AsyncPlaybackBufferStream>, AudioSharedFormat), BoxError> {
         let hr = WinAudio::co_init_once_per_thread();
         let _ = check_hresult!(hr, WinAudioError::from(hr), "Co Initialized failed");
@@ -227,6 +229,7 @@ impl WinAudioServer for WinAudio {
             frame_rate as u32,
             buffer_size,
             ex,
+            audio_client_guid,
         ) {
             Ok(renderer) => {
                 let audio_shared_format = renderer.get_audio_shared_format();
@@ -349,6 +352,7 @@ impl WinAudioServer for NoopStreamSource {
         frame_rate: usize,
         buffer_size: usize,
         ex: &dyn audio_streams::AudioStreamsExecutor,
+        _audio_client_guid: Option<String>,
     ) -> Result<(Box<dyn AsyncPlaybackBufferStream>, AudioSharedFormat), BoxError> {
         let (_, playback_stream) = self
             .new_async_playback_stream(num_channels, format, frame_rate as u32, buffer_size, ex)
diff --git a/win_audio/src/win_audio_impl/async_stream.rs b/win_audio/src/win_audio_impl/async_stream.rs
index 50d243b2d..f40d55d36 100644
--- a/win_audio/src/win_audio_impl/async_stream.rs
+++ b/win_audio/src/win_audio_impl/async_stream.rs
@@ -69,7 +69,14 @@ impl WinAudio {
         let _ = check_hresult!(hr, WinAudioError::from(hr), "Co Initialized failed");
 
         let playback_buffer_stream: Box<dyn AsyncPlaybackBufferStream> =
-            match WinAudioRenderer::new_async(num_channels, format, frame_rate, buffer_size, ex) {
+            match WinAudioRenderer::new_async(
+                num_channels,
+                format,
+                frame_rate,
+                buffer_size,
+                ex,
+                None,
+            ) {
                 Ok(renderer) => Box::new(renderer),
                 Err(e) => {
                     warn!(
@@ -97,6 +104,7 @@ impl WinAudioRenderer {
         frame_rate: u32,
         incoming_buffer_size_in_frames: usize,
         ex: &dyn audio_streams::AudioStreamsExecutor,
+        audio_client_guid: Option<String>,
     ) -> Result<Self, RenderError> {
         let device = DeviceRendererWrapper::new(
             num_channels,
@@ -104,6 +112,7 @@ impl WinAudioRenderer {
             frame_rate,
             incoming_buffer_size_in_frames,
             Some(ex),
+            audio_client_guid.clone(),
         )
         .map_err(|e| {
             match &e {
@@ -122,7 +131,10 @@ impl WinAudioRenderer {
             e
         })?;
 
-        Ok(Self { device })
+        Ok(Self {
+            device,
+            audio_client_guid,
+        })
     }
 
     fn unregister_notification_client_and_make_new_device_renderer(
@@ -135,6 +147,7 @@ impl WinAudioRenderer {
             self.device.guest_frame_rate,
             self.device.incoming_buffer_size_in_frames,
             Some(ex),
+            self.audio_client_guid.clone(),
         )
         .map_err(|e| {
             match &e {
diff --git a/win_audio/src/win_audio_impl/mod.rs b/win_audio/src/win_audio_impl/mod.rs
index 1840e5160..e97a52152 100644
--- a/win_audio/src/win_audio_impl/mod.rs
+++ b/win_audio/src/win_audio_impl/mod.rs
@@ -11,6 +11,7 @@ mod wave_format;
 
 use std::convert::From;
 use std::fmt::Debug;
+use std::num::ParseIntError;
 use std::os::raw::c_void;
 use std::ptr::null_mut;
 use std::sync::atomic::AtomicBool;
@@ -89,7 +90,7 @@ pub const MONO_CHANNEL_COUNT: u16 = 1;
 const AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM: u32 = 0x80000000;
 const AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY: u32 = 0x08000000;
 
-thread_local!(static THREAD_ONCE_INIT: Once = Once::new());
+thread_local!(static THREAD_ONCE_INIT: Once = const { Once::new() });
 
 // Used to differentiate between S_FALSE and S_OK. This means `CoInitializeEx` did not get called.
 // Mainly used for testing.
@@ -190,6 +191,7 @@ impl StreamSource for WinAudio {
 /// `DeviceRenderer` on a new device.
 pub(crate) struct WinAudioRenderer {
     pub device: DeviceRendererWrapper,
+    audio_client_guid: Option<String>,
 }
 
 impl WinAudioRenderer {
@@ -206,8 +208,12 @@ impl WinAudioRenderer {
             frame_rate,
             incoming_buffer_size_in_frames,
             None,
+            None,
         )?;
-        Ok(Self { device })
+        Ok(Self {
+            device,
+            audio_client_guid: None,
+        })
     }
 
     fn handle_playback_logging_on_error(e: &RenderError) {
@@ -407,12 +413,14 @@ impl DeviceRendererWrapper {
         guest_frame_rate: u32,
         incoming_buffer_size_in_frames: usize,
         ex: Option<&dyn AudioStreamsExecutor>,
+        audio_client_guid: Option<String>,
     ) -> Result<Self, RenderError> {
         let renderer_stream = match Self::create_device_renderer_and_log_time(
             num_channels,
             guest_frame_rate,
             incoming_buffer_size_in_frames,
             ex,
+            audio_client_guid,
         ) {
             Ok(device) => {
                 let audio_shared_format = device.audio_shared_format;
@@ -514,10 +522,16 @@ impl DeviceRendererWrapper {
         frame_rate: u32,
         incoming_buffer_size_in_frames: usize,
         ex: Option<&dyn AudioStreamsExecutor>,
+        audio_client_guid: Option<String>,
     ) -> Result<DeviceRenderer, RenderError> {
         let start = std::time::Instant::now();
-        let device =
-            DeviceRenderer::new(num_channels, frame_rate, incoming_buffer_size_in_frames, ex)?;
+        let device = DeviceRenderer::new(
+            num_channels,
+            frame_rate,
+            incoming_buffer_size_in_frames,
+            ex,
+            audio_client_guid,
+        )?;
         // This can give us insights to how other long other machines take to initialize audio.
         // Eventually this should be a histogram metric.
         info!(
@@ -566,6 +580,7 @@ impl DeviceRenderer {
         guest_frame_rate: u32,
         incoming_buffer_size_in_frames: usize,
         ex: Option<&dyn AudioStreamsExecutor>,
+        audio_client_guid: Option<String>,
     ) -> Result<Self, RenderError> {
         if num_channels > 2 {
             return Err(RenderError::WinAudioError(
@@ -579,6 +594,16 @@ impl DeviceRenderer {
 
         let format = get_valid_mix_format(&audio_client).map_err(RenderError::WinAudioError)?;
 
+        let res = if let Some(audio_client_guid) = audio_client_guid {
+            info!(
+                "IAudioClient initializing with GUID: {:?}",
+                audio_client_guid
+            );
+            Some(Self::convert_session_string_to_guid(audio_client_guid)?)
+        } else {
+            None
+        };
+
         // SAFETY: `audio_client` is initialized
         let hr = unsafe {
             // Intializes the audio client by setting the buffer size in 100-nanoseconds and
@@ -596,7 +621,10 @@ impl DeviceRenderer {
                 0, /* hnsBufferDuration */
                 0, /* hnsPeriodicity */
                 format.as_ptr(),
-                null_mut(),
+                match res {
+                    Some(guid) => &guid as *const GUID,
+                    None => null_mut(),
+                },
             )
         };
         check_hresult!(
@@ -805,6 +833,46 @@ impl DeviceRenderer {
             ),
         ))
     }
+
+    fn convert_session_string_to_guid(audio_client_guid: String) -> Result<GUID, RenderError> {
+        let split_guid: Vec<&str> = audio_client_guid.split('-').collect();
+        if split_guid.len() != 5 {
+            return Err(RenderError::WinAudioError(
+                WinAudioError::GuidSplitWrongSize(split_guid.len()),
+            ));
+        }
+
+        let first = u32::from_str_radix(split_guid[0], 16)
+            .map_err(|e| RenderError::WinAudioError(WinAudioError::GuidParseIntError(e)))?;
+        let second = u16::from_str_radix(split_guid[1], 16)
+            .map_err(|e| RenderError::WinAudioError(WinAudioError::GuidParseIntError(e)))?;
+        let third = u16::from_str_radix(split_guid[2], 16)
+            .map_err(|e| RenderError::WinAudioError(WinAudioError::GuidParseIntError(e)))?;
+
+        let combined = split_guid[3].to_owned() + split_guid[4];
+        let fourth_vec: Vec<String> = combined
+            .chars()
+            .collect::<Vec<char>>()
+            .chunks(2)
+            .map(|chunk| chunk.iter().collect())
+            .collect();
+        let fourth: Vec<u8> = fourth_vec
+            .into_iter()
+            .map(|byte_str| {
+                u8::from_str_radix(&byte_str, 16)
+                    .map_err(|e| RenderError::WinAudioError(WinAudioError::GuidParseIntError(e)))
+            })
+            .collect::<Result<Vec<u8>, RenderError>>()?;
+
+        Ok(GUID {
+            Data1: first,
+            Data2: second,
+            Data3: third,
+            Data4: fourth
+                .try_into()
+                .map_err(|_| RenderError::WinAudioError(WinAudioError::GuidVecConversionError))?,
+        })
+    }
 }
 
 impl BufferCommit for DeviceRenderer {
@@ -1718,6 +1786,12 @@ pub enum WinAudioError {
     RegisterEndpointNotifError(i32),
     #[error("ReleaseBuffer failed. HResult: {0}")]
     ReleaseBufferError(i32),
+    #[error("Failed to parse part of a guid: {0}")]
+    GuidParseIntError(ParseIntError),
+    #[error("Guid split size is not len 5. It is: {0}")]
+    GuidSplitWrongSize(usize),
+    #[error("Failed to convert Vector to a slice")]
+    GuidVecConversionError,
 }
 
 impl From<&WinAudioError> for i64 {
@@ -1750,6 +1824,9 @@ impl From<&WinAudioError> for i64 {
             WinAudioError::GetBufferError(hr) => (24, *hr),
             WinAudioError::RegisterEndpointNotifError(hr) => (25, *hr),
             WinAudioError::ReleaseBufferError(hr) => (26, *hr),
+            WinAudioError::GuidParseIntError(_) => (27, 0),
+            WinAudioError::GuidSplitWrongSize(_) => (28, 0),
+            WinAudioError::GuidVecConversionError => (29, 0),
         };
         ((err_type as u64) << 32 | ((hr as u32) as u64)) as i64
     }
@@ -1866,11 +1943,31 @@ mod tests {
         assert_eq!(result, 100932191376);
     }
 
+    #[test]
+    fn test_device_renderer_convert_string_to_guid() {
+        let guid_string = "465c4ed4-cda1-4d65-b412-641299a39c2c";
+        let result_guid =
+            DeviceRenderer::convert_session_string_to_guid(guid_string.to_string()).unwrap();
+        assert_eq!(result_guid.Data1, 0x465c4ed4);
+        assert_eq!(result_guid.Data2, 0xcda1);
+        assert_eq!(result_guid.Data3, 0x4d65);
+
+        let data_4 = result_guid.Data4;
+        assert_eq!(data_4[0], 0xb4);
+        assert_eq!(data_4[1], 0x12);
+        assert_eq!(data_4[2], 0x64);
+        assert_eq!(data_4[3], 0x12);
+        assert_eq!(data_4[4], 0x99);
+        assert_eq!(data_4[5], 0xa3);
+        assert_eq!(data_4[6], 0x9c);
+        assert_eq!(data_4[7], 0x2c);
+    }
+
     #[ignore]
     #[test]
     fn test_create_win_audio_renderer_no_co_initliazed() {
         let _shared = SERIALIZE_LOCK.lock();
-        let win_audio_renderer = DeviceRenderer::new(2, 48000, 720, None);
+        let win_audio_renderer = DeviceRenderer::new(2, 48000, 720, None, None);
         assert!(win_audio_renderer.is_err());
     }
 
@@ -1887,7 +1984,7 @@ mod tests {
     fn test_create_win_audio_renderer() {
         let _shared = SERIALIZE_LOCK.lock();
         let _co_init = SafeCoInit::new_coinitialize();
-        let win_audio_renderer_result = DeviceRenderer::new(2, 48000, 480, None);
+        let win_audio_renderer_result = DeviceRenderer::new(2, 48000, 480, None, None);
         assert!(win_audio_renderer_result.is_ok());
         let win_audio_renderer = win_audio_renderer_result.unwrap();
         // This test is dependent on device format settings and machine. Ie. this will probably
@@ -1937,7 +2034,7 @@ mod tests {
     // there is no way to copy audio samples over succiently.
     fn test_guest_buffer_size_bigger_than_audio_render_client_buffer_size() {
         let _shared = SERIALIZE_LOCK.lock();
-        let win_audio_renderer = DeviceRenderer::new(2, 48000, 100000, None);
+        let win_audio_renderer = DeviceRenderer::new(2, 48000, 100000, None, None);
 
         assert!(win_audio_renderer.is_err());
     }
@@ -1974,7 +2071,8 @@ mod tests {
 
         let ex = Executor::new().expect("Failed to create executor.");
         let mut renderer_wrapper =
-            DeviceRendererWrapper::new(2, SampleFormat::S16LE, 48000, 480, Some(&ex)).unwrap();
+            DeviceRendererWrapper::new(2, SampleFormat::S16LE, 48000, 480, Some(&ex), None)
+                .unwrap();
         assert!(matches!(
             renderer_wrapper.renderer_stream,
             RendererStream::Device(_)
diff --git a/win_util/Cargo.toml b/win_util/Cargo.toml
index ee332268c..55452749e 100644
--- a/win_util/Cargo.toml
+++ b/win_util/Cargo.toml
@@ -5,15 +5,15 @@ authors = ["The ChromiumOS Authors"]
 edition = "2021"
 
 [dependencies]
-anyhow = "*"
+anyhow = "1"
 enumn = "0.1.0"
-libc = "*"
+libc = "0.2"
 once_cell = "1.7"
 serde = { version = "1", features = [ "derive" ] }
 zeroize = "1.5.7"
 
 [target.'cfg(windows)'.dependencies]
-winapi = { version = "*", features = ["everything", "std", "impl-default"] }
+winapi = { version = "0.3", features = ["everything", "std", "impl-default"] }
 
 [dependencies.windows]
 version = "0.39.0"
diff --git a/win_util/src/lib.rs b/win_util/src/lib.rs
index 60bc6070e..3b530f6bf 100644
--- a/win_util/src/lib.rs
+++ b/win_util/src/lib.rs
@@ -81,7 +81,7 @@ macro_rules! fail_if_zero {
 
 /// Returns the lower 32 bits of a u64 as a u32 (c_ulong/DWORD)
 pub fn get_low_order(number: u64) -> c_ulong {
-    (number & (u32::max_value() as u64)) as c_ulong
+    (number & (u32::MAX as u64)) as c_ulong
 }
 
 /// Returns the upper 32 bits of a u64 as a u32 (c_ulong/DWORD)
diff --git a/x86_64/Android.bp b/x86_64/Android.bp
index 4c882f24e..192744c1c 100644
--- a/x86_64/Android.bp
+++ b/x86_64/Android.bp
@@ -19,7 +19,7 @@ rust_library {
     crate_name: "x86_64",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     edition: "2021",
     features: [
         "gdb",
@@ -40,7 +40,6 @@ rust_library {
         "libkernel_cmdline",
         "libkernel_loader",
         "liblibc",
-        "libmemoffset",
         "libminijail_rust",
         "libonce_cell",
         "librand",
@@ -73,7 +72,7 @@ rust_test {
     crate_name: "x86_64",
     cargo_env_compat: true,
     cargo_pkg_version: "0.1.0",
-    srcs: ["src/lib.rs"],
+    crate_root: "src/lib.rs",
     test_suites: ["general-tests"],
     auto_gen_config: true,
     test_options: {
@@ -99,7 +98,6 @@ rust_test {
         "libkernel_cmdline",
         "libkernel_loader",
         "liblibc",
-        "libmemoffset",
         "libminijail_rust",
         "libonce_cell",
         "librand",
@@ -124,123 +122,3 @@ rust_test {
     },
 
 }
-
-rust_test {
-    name: "x86_64_test_tests_integration_main",
-    defaults: ["crosvm_inner_defaults"],
-    host_supported: true,
-    crate_name: "integration",
-    cargo_env_compat: true,
-    cargo_pkg_version: "0.1.0",
-    srcs: ["tests/integration/main.rs"],
-    test_suites: ["general-tests"],
-    auto_gen_config: true,
-    test_options: {
-        unit_test: false,
-    },
-    edition: "2021",
-    features: [
-        "gdb",
-        "gdbstub_arch",
-    ],
-    rustlibs: [
-        "libacpi_tables",
-        "libanyhow",
-        "libarch",
-        "libbase_rust",
-        "libcfg_if",
-        "libchrono",
-        "libcros_fdt",
-        "libdevices",
-        "libgdbstub_arch",
-        "libhypervisor",
-        "libjail",
-        "libkernel_cmdline",
-        "libkernel_loader",
-        "liblibc",
-        "libmemoffset",
-        "libminijail_rust",
-        "libonce_cell",
-        "librand",
-        "libresources",
-        "libswap",
-        "libsync_rust",
-        "libthiserror",
-        "libuuid",
-        "libvm_control",
-        "libvm_memory",
-        "libx86_64_rust",
-        "libzerocopy",
-    ],
-    proc_macros: ["libremain"],
-    // Exclude arm family manually
-    arch: {
-        arm: {
-            enabled: false,
-        },
-        arm64: {
-            enabled: false,
-        },
-    },
-
-}
-
-rust_test {
-    name: "x86_64_test_tests_linux",
-    defaults: ["crosvm_inner_defaults"],
-    host_supported: true,
-    crate_name: "linux",
-    cargo_env_compat: true,
-    cargo_pkg_version: "0.1.0",
-    srcs: ["tests/linux.rs"],
-    test_suites: ["general-tests"],
-    auto_gen_config: true,
-    test_options: {
-        unit_test: false,
-    },
-    edition: "2021",
-    features: [
-        "gdb",
-        "gdbstub_arch",
-    ],
-    rustlibs: [
-        "libacpi_tables",
-        "libanyhow",
-        "libarch",
-        "libbase_rust",
-        "libcfg_if",
-        "libchrono",
-        "libcros_fdt",
-        "libdevices",
-        "libgdbstub_arch",
-        "libhypervisor",
-        "libjail",
-        "libkernel_cmdline",
-        "libkernel_loader",
-        "liblibc",
-        "libmemoffset",
-        "libminijail_rust",
-        "libonce_cell",
-        "librand",
-        "libresources",
-        "libswap",
-        "libsync_rust",
-        "libthiserror",
-        "libuuid",
-        "libvm_control",
-        "libvm_memory",
-        "libx86_64_rust",
-        "libzerocopy",
-    ],
-    proc_macros: ["libremain"],
-    // Exclude arm family manually
-    arch: {
-        arm: {
-            enabled: false,
-        },
-        arm64: {
-            enabled: false,
-        },
-    },
-
-}
diff --git a/x86_64/Cargo.toml b/x86_64/Cargo.toml
index 963848bb1..a94631e28 100644
--- a/x86_64/Cargo.toml
+++ b/x86_64/Cargo.toml
@@ -12,7 +12,7 @@ swap = ["swap/enable"]
 [dependencies]
 acpi_tables = {path = "../acpi_tables" }
 arch = { path = "../arch" }
-anyhow = "*"
+anyhow = "1"
 cfg-if = "1.0.0"
 chrono = { version = "0.4.34", default-features = false }
 cros_fdt = { path = "../cros_fdt" }
@@ -22,14 +22,13 @@ hypervisor = { path = "../hypervisor" }
 jail = { path = "../jail" }
 kernel_cmdline = { path = "../kernel_cmdline" }
 kernel_loader = { path = "../kernel_loader" }
-libc = "*"
-memoffset = "0.6"
+libc = "0.2"
 once_cell = "1.7.2"
 rand = "0.8"
-remain = "*"
+remain = "0.2"
 resources = { path = "../resources" }
 sync = { path = "../common/sync" }
-thiserror = "*"
+thiserror = "1"
 uuid = { version = "1", features = ["v4"] }
 base = { path = "../base" }
 swap = { path = "../swap" }
diff --git a/x86_64/src/bootparam.rs b/x86_64/src/bootparam.rs
index 0b24a4e1d..6d92eb8c0 100644
--- a/x86_64/src/bootparam.rs
+++ b/x86_64/src/bootparam.rs
@@ -20,6 +20,11 @@ use zerocopy::AsBytes;
 use zerocopy::FromBytes;
 use zerocopy::FromZeroes;
 
+/// Set if kernel image has a 64-bit entry point at 0x200.
+pub const XLF_KERNEL_64: u16 = 1 << 0;
+/// Set if kernel/boot_params/cmdline/ramdisk can be above 4G.
+pub const XLF_CAN_BE_LOADED_ABOVE_4G: u16 = 1 << 1;
+
 #[repr(C)]
 #[derive(Default)]
 pub struct __IncompleteArrayField<T>(::std::marker::PhantomData<T>, [T; 0]);
diff --git a/x86_64/src/bzimage.rs b/x86_64/src/bzimage.rs
index 67ccf884c..c8e60e0a8 100644
--- a/x86_64/src/bzimage.rs
+++ b/x86_64/src/bzimage.rs
@@ -6,11 +6,11 @@
 //! <https://www.kernel.org/doc/Documentation/x86/boot.txt>
 
 use std::io;
+use std::mem::offset_of;
 
 use base::debug;
 use base::FileReadWriteAtVolatile;
 use base::VolatileSlice;
-use memoffset::offset_of;
 use remain::sorted;
 use thiserror::Error;
 use vm_memory::GuestAddress;
@@ -19,12 +19,18 @@ use vm_memory::GuestMemoryError;
 use zerocopy::AsBytes;
 
 use crate::bootparam::boot_params;
+use crate::bootparam::XLF_KERNEL_64;
+use crate::CpuMode;
+use crate::KERNEL_32BIT_ENTRY_OFFSET;
+use crate::KERNEL_64BIT_ENTRY_OFFSET;
 
 #[sorted]
 #[derive(Error, Debug)]
 pub enum Error {
     #[error("bad kernel header signature")]
     BadSignature,
+    #[error("entry point out of range")]
+    EntryPointOutOfRange,
     #[error("guest memory error {0}")]
     GuestMemoryError(GuestMemoryError),
     #[error("invalid setup_header_end value {0}")]
@@ -54,7 +60,7 @@ pub fn load_bzimage<F>(
     guest_mem: &GuestMemory,
     kernel_start: GuestAddress,
     kernel_image: &mut F,
-) -> Result<(boot_params, u64)>
+) -> Result<(boot_params, u64, GuestAddress, CpuMode)>
 where
     F: FileReadWriteAtVolatile,
 {
@@ -122,5 +128,20 @@ where
         .read_exact_at_volatile(guest_slice, kernel_offset)
         .map_err(Error::ReadKernelImage)?;
 
-    Ok((params, kernel_start.offset() + kernel_size as u64))
+    let (entry_offset, cpu_mode) = if params.hdr.xloadflags & XLF_KERNEL_64 != 0 {
+        (KERNEL_64BIT_ENTRY_OFFSET, CpuMode::LongMode)
+    } else {
+        (KERNEL_32BIT_ENTRY_OFFSET, CpuMode::FlatProtectedMode)
+    };
+
+    let bzimage_entry = guest_mem
+        .checked_offset(kernel_start, entry_offset)
+        .ok_or(Error::EntryPointOutOfRange)?;
+
+    Ok((
+        params,
+        kernel_start.offset() + kernel_size as u64,
+        bzimage_entry,
+        cpu_mode,
+    ))
 }
diff --git a/x86_64/src/fdt.rs b/x86_64/src/fdt.rs
index 5507a001a..96380d464 100644
--- a/x86_64/src/fdt.rs
+++ b/x86_64/src/fdt.rs
@@ -5,11 +5,14 @@
 #[cfg(any(target_os = "android", target_os = "linux"))]
 use std::collections::BTreeMap;
 use std::fs::File;
+use std::fs::OpenOptions;
+use std::io::Write;
 use std::path::PathBuf;
 
 use arch::android::create_android_fdt;
 use arch::apply_device_tree_overlays;
 use arch::DtbOverlay;
+use base::open_file_or_duplicate;
 use cros_fdt::Error;
 use cros_fdt::Fdt;
 
@@ -44,7 +47,16 @@ pub fn create_fdt(
     let fdt_final = fdt.finish()?;
 
     if let Some(file_path) = dump_device_tree_blob {
-        std::fs::write(&file_path, &fdt_final)
+        let mut fd = open_file_or_duplicate(
+            &file_path,
+            OpenOptions::new()
+                .read(true)
+                .create(true)
+                .truncate(true)
+                .write(true),
+        )
+        .map_err(|e| Error::FdtIoError(e.into()))?;
+        fd.write_all(&fdt_final)
             .map_err(|e| Error::FdtDumpIoError(e, file_path.clone()))?;
     }
 
diff --git a/x86_64/src/gdb.rs b/x86_64/src/gdb.rs
new file mode 100644
index 000000000..c70dfcef0
--- /dev/null
+++ b/x86_64/src/gdb.rs
@@ -0,0 +1,301 @@
+// Copyright 2024 The ChromiumOS Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+//! x86 architecture gdb debugging support.
+
+use gdbstub_arch::x86::reg::id::X86_64CoreRegId;
+use gdbstub_arch::x86::reg::X86SegmentRegs;
+use gdbstub_arch::x86::reg::X86_64CoreRegs;
+use gdbstub_arch::x86::reg::X87FpuInternalRegs;
+use hypervisor::x86_64::Regs;
+use hypervisor::x86_64::Sregs;
+use hypervisor::VcpuX86_64;
+use vm_memory::GuestAddress;
+use vm_memory::GuestMemory;
+
+use crate::Error;
+use crate::Result;
+use crate::X8664arch;
+
+impl<T: VcpuX86_64> arch::GdbOps<T> for X8664arch {
+    type Error = Error;
+
+    fn read_registers(vcpu: &T) -> Result<X86_64CoreRegs> {
+        // General registers: RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, r8-r15
+        let gregs = vcpu.get_regs().map_err(Error::ReadRegs)?;
+        let regs = [
+            gregs.rax, gregs.rbx, gregs.rcx, gregs.rdx, gregs.rsi, gregs.rdi, gregs.rbp, gregs.rsp,
+            gregs.r8, gregs.r9, gregs.r10, gregs.r11, gregs.r12, gregs.r13, gregs.r14, gregs.r15,
+        ];
+
+        // GDB exposes 32-bit eflags instead of 64-bit rflags.
+        // https://github.com/bminor/binutils-gdb/blob/master/gdb/features/i386/64bit-core.xml
+        let eflags = gregs.rflags as u32;
+        let rip = gregs.rip;
+
+        // Segment registers: CS, SS, DS, ES, FS, GS
+        let sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
+        let segments = X86SegmentRegs {
+            cs: sregs.cs.selector as u32,
+            ss: sregs.ss.selector as u32,
+            ds: sregs.ds.selector as u32,
+            es: sregs.es.selector as u32,
+            fs: sregs.fs.selector as u32,
+            gs: sregs.gs.selector as u32,
+        };
+
+        // x87 FPU internal state
+        // TODO(dverkamp): floating point tag word, instruction pointer, and data pointer
+        let fpu = vcpu.get_fpu().map_err(Error::ReadRegs)?;
+        let fpu_internal = X87FpuInternalRegs {
+            fctrl: u32::from(fpu.fcw),
+            fstat: u32::from(fpu.fsw),
+            fop: u32::from(fpu.last_opcode),
+            ..Default::default()
+        };
+
+        let mut regs = X86_64CoreRegs {
+            regs,
+            eflags,
+            rip,
+            segments,
+            st: Default::default(),
+            fpu: fpu_internal,
+            xmm: Default::default(),
+            mxcsr: fpu.mxcsr,
+        };
+
+        // x87 FPU registers: ST0-ST7
+        for (dst, src) in regs.st.iter_mut().zip(fpu.fpr.iter()) {
+            // `fpr` contains the x87 floating point registers in FXSAVE format.
+            // Each element contains an 80-bit floating point value.
+            *dst = (*src).into();
+        }
+
+        // SSE registers: XMM0-XMM15
+        for (dst, src) in regs.xmm.iter_mut().zip(fpu.xmm.iter()) {
+            *dst = u128::from_le_bytes(*src);
+        }
+
+        Ok(regs)
+    }
+
+    fn write_registers(vcpu: &T, regs: &X86_64CoreRegs) -> Result<()> {
+        // General purpose registers (RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, r8-r15) + RIP + rflags
+        let orig_gregs = vcpu.get_regs().map_err(Error::ReadRegs)?;
+        let gregs = Regs {
+            rax: regs.regs[0],
+            rbx: regs.regs[1],
+            rcx: regs.regs[2],
+            rdx: regs.regs[3],
+            rsi: regs.regs[4],
+            rdi: regs.regs[5],
+            rbp: regs.regs[6],
+            rsp: regs.regs[7],
+            r8: regs.regs[8],
+            r9: regs.regs[9],
+            r10: regs.regs[10],
+            r11: regs.regs[11],
+            r12: regs.regs[12],
+            r13: regs.regs[13],
+            r14: regs.regs[14],
+            r15: regs.regs[15],
+            rip: regs.rip,
+            // Update the lower 32 bits of rflags.
+            rflags: (orig_gregs.rflags & !(u32::MAX as u64)) | (regs.eflags as u64),
+        };
+        vcpu.set_regs(&gregs).map_err(Error::WriteRegs)?;
+
+        // Segment registers: CS, SS, DS, ES, FS, GS
+        // Since GDB care only selectors, we call get_sregs() first.
+        let mut sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
+        sregs.cs.selector = regs.segments.cs as u16;
+        sregs.ss.selector = regs.segments.ss as u16;
+        sregs.ds.selector = regs.segments.ds as u16;
+        sregs.es.selector = regs.segments.es as u16;
+        sregs.fs.selector = regs.segments.fs as u16;
+        sregs.gs.selector = regs.segments.gs as u16;
+
+        vcpu.set_sregs(&sregs).map_err(Error::WriteRegs)?;
+
+        // FPU and SSE registers
+        let mut fpu = vcpu.get_fpu().map_err(Error::ReadRegs)?;
+        fpu.fcw = regs.fpu.fctrl as u16;
+        fpu.fsw = regs.fpu.fstat as u16;
+        fpu.last_opcode = regs.fpu.fop as u16;
+        // TODO(dverkamp): floating point tag word, instruction pointer, and data pointer
+
+        // x87 FPU registers: ST0-ST7
+        for (dst, src) in fpu.fpr.iter_mut().zip(regs.st.iter()) {
+            *dst = (*src).into();
+        }
+
+        // SSE registers: XMM0-XMM15
+        for (dst, src) in fpu.xmm.iter_mut().zip(regs.xmm.iter()) {
+            dst.copy_from_slice(&src.to_le_bytes());
+        }
+
+        vcpu.set_fpu(&fpu).map_err(Error::WriteRegs)?;
+
+        Ok(())
+    }
+
+    #[inline]
+    fn read_register(_vcpu: &T, _reg: X86_64CoreRegId) -> Result<Vec<u8>> {
+        Err(Error::ReadRegIsUnsupported)
+    }
+
+    #[inline]
+    fn write_register(_vcpu: &T, _reg: X86_64CoreRegId, _buf: &[u8]) -> Result<()> {
+        Err(Error::WriteRegIsUnsupported)
+    }
+
+    fn read_memory(
+        vcpu: &T,
+        guest_mem: &GuestMemory,
+        vaddr: GuestAddress,
+        len: usize,
+    ) -> Result<Vec<u8>> {
+        let sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
+        let mut buf = vec![0; len];
+        let mut total_read = 0u64;
+        // Handle reads across page boundaries.
+
+        while total_read < len as u64 {
+            let (paddr, psize) = phys_addr(guest_mem, vaddr.0 + total_read, &sregs)?;
+            let read_len = std::cmp::min(len as u64 - total_read, psize - (paddr & (psize - 1)));
+            guest_mem
+                .get_slice_at_addr(GuestAddress(paddr), read_len as usize)
+                .map_err(Error::ReadingGuestMemory)?
+                .copy_to(&mut buf[total_read as usize..]);
+            total_read += read_len;
+        }
+        Ok(buf)
+    }
+
+    fn write_memory(
+        vcpu: &T,
+        guest_mem: &GuestMemory,
+        vaddr: GuestAddress,
+        buf: &[u8],
+    ) -> Result<()> {
+        let sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
+        let mut total_written = 0u64;
+        // Handle writes across page boundaries.
+        while total_written < buf.len() as u64 {
+            let (paddr, psize) = phys_addr(guest_mem, vaddr.0 + total_written, &sregs)?;
+            let write_len = std::cmp::min(
+                buf.len() as u64 - total_written,
+                psize - (paddr & (psize - 1)),
+            );
+
+            guest_mem
+                .write_all_at_addr(
+                    &buf[total_written as usize..(total_written as usize + write_len as usize)],
+                    GuestAddress(paddr),
+                )
+                .map_err(Error::WritingGuestMemory)?;
+            total_written += write_len;
+        }
+        Ok(())
+    }
+
+    fn enable_singlestep(vcpu: &T) -> Result<()> {
+        vcpu.set_guest_debug(&[], true /* enable_singlestep */)
+            .map_err(Error::EnableSinglestep)
+    }
+
+    fn get_max_hw_breakpoints(_vcpu: &T) -> Result<usize> {
+        Ok(4usize)
+    }
+
+    fn set_hw_breakpoints(vcpu: &T, breakpoints: &[GuestAddress]) -> Result<()> {
+        vcpu.set_guest_debug(breakpoints, false /* enable_singlestep */)
+            .map_err(Error::SetHwBreakpoint)
+    }
+}
+
+// return the translated address and the size of the page it resides in.
+fn phys_addr(mem: &GuestMemory, vaddr: u64, sregs: &Sregs) -> Result<(u64, u64)> {
+    const CR0_PG_MASK: u64 = 1 << 31;
+    const CR4_PAE_MASK: u64 = 1 << 5;
+    const CR4_LA57_MASK: u64 = 1 << 12;
+    const MSR_EFER_LMA: u64 = 1 << 10;
+    // bits 12 through 51 are the address in a PTE.
+    const PTE_ADDR_MASK: u64 = ((1 << 52) - 1) & !0x0fff;
+    const PAGE_PRESENT: u64 = 0x1;
+    const PAGE_PSE_MASK: u64 = 0x1 << 7;
+
+    const PAGE_SIZE_4K: u64 = 4 * 1024;
+    const PAGE_SIZE_2M: u64 = 2 * 1024 * 1024;
+    const PAGE_SIZE_1G: u64 = 1024 * 1024 * 1024;
+
+    fn next_pte(mem: &GuestMemory, curr_table_addr: u64, vaddr: u64, level: usize) -> Result<u64> {
+        let ent: u64 = mem
+            .read_obj_from_addr(GuestAddress(
+                (curr_table_addr & PTE_ADDR_MASK) + page_table_offset(vaddr, level),
+            ))
+            .map_err(|_| Error::TranslatingVirtAddr)?;
+        /* TODO - convert to a trace
+        println!(
+            "level {} vaddr {:x} table-addr {:x} mask {:x} ent {:x} offset {:x}",
+            level,
+            vaddr,
+            curr_table_addr,
+            PTE_ADDR_MASK,
+            ent,
+            page_table_offset(vaddr, level)
+        );
+        */
+        if ent & PAGE_PRESENT == 0 {
+            return Err(Error::PageNotPresent);
+        }
+        Ok(ent)
+    }
+
+    // Get the offset in to the page of `vaddr`.
+    fn page_offset(vaddr: u64, page_size: u64) -> u64 {
+        vaddr & (page_size - 1)
+    }
+
+    // Get the offset in to the page table of the given `level` specified by the virtual `address`.
+    // `level` is 1 through 5 in x86_64 to handle the five levels of paging.
+    fn page_table_offset(addr: u64, level: usize) -> u64 {
+        let offset = (level - 1) * 9 + 12;
+        ((addr >> offset) & 0x1ff) << 3
+    }
+
+    if sregs.cr0 & CR0_PG_MASK == 0 {
+        return Ok((vaddr, PAGE_SIZE_4K));
+    }
+
+    if sregs.cr4 & CR4_PAE_MASK == 0 {
+        return Err(Error::TranslatingVirtAddr);
+    }
+
+    if sregs.efer & MSR_EFER_LMA != 0 {
+        // TODO - check LA57
+        if sregs.cr4 & CR4_LA57_MASK != 0 {
+            todo!("handle LA57");
+        }
+        let p4_ent = next_pte(mem, sregs.cr3, vaddr, 4)?;
+        let p3_ent = next_pte(mem, p4_ent, vaddr, 3)?;
+        // TODO check if it's a 1G page with the PSE bit in p2_ent
+        if p3_ent & PAGE_PSE_MASK != 0 {
+            // It's a 1G page with the PSE bit in p3_ent
+            let paddr = p3_ent & PTE_ADDR_MASK | page_offset(vaddr, PAGE_SIZE_1G);
+            return Ok((paddr, PAGE_SIZE_1G));
+        }
+        let p2_ent = next_pte(mem, p3_ent, vaddr, 2)?;
+        if p2_ent & PAGE_PSE_MASK != 0 {
+            // It's a 2M page with the PSE bit in p2_ent
+            let paddr = p2_ent & PTE_ADDR_MASK | page_offset(vaddr, PAGE_SIZE_2M);
+            return Ok((paddr, PAGE_SIZE_2M));
+        }
+        let p1_ent = next_pte(mem, p2_ent, vaddr, 1)?;
+        let paddr = p1_ent & PTE_ADDR_MASK | page_offset(vaddr, PAGE_SIZE_4K);
+        return Ok((paddr, PAGE_SIZE_4K));
+    }
+    Err(Error::TranslatingVirtAddr)
+}
diff --git a/x86_64/src/gdt.rs b/x86_64/src/gdt.rs
index 45cd92017..47f0de73e 100644
--- a/x86_64/src/gdt.rs
+++ b/x86_64/src/gdt.rs
@@ -64,9 +64,19 @@ fn get_type(entry: u64) -> u8 {
 /// * `entry` - The gdt entry.
 /// * `table_index` - Index of the entry in the gdt table.
 pub fn segment_from_gdt(entry: u64, table_index: u8) -> Segment {
+    let g = get_g(entry);
+    let limit = get_limit(entry);
+    let limit_bytes = if g == 0 {
+        // 1-byte granularity
+        limit
+    } else {
+        // 4096-byte granularity
+        (limit * 4096) + 4095
+    };
+
     Segment {
         base: get_base(entry),
-        limit: get_limit(entry),
+        limit_bytes,
         selector: (table_index * 8) as u16,
         type_: get_type(entry),
         present: get_p(entry),
@@ -74,7 +84,7 @@ pub fn segment_from_gdt(entry: u64, table_index: u8) -> Segment {
         db: get_db(entry),
         s: get_s(entry),
         l: get_l(entry),
-        g: get_g(entry),
+        g,
         avl: get_avl(entry),
     }
 }
@@ -101,6 +111,6 @@ mod test {
         assert_eq!(0xB, seg.type_);
         // base and limit
         assert_eq!(0x100000, seg.base);
-        assert_eq!(0xfffff, seg.limit);
+        assert_eq!(0xffffffff, seg.limit_bytes);
     }
 }
diff --git a/x86_64/src/lib.rs b/x86_64/src/lib.rs
index 6202e2400..afbbcde0f 100644
--- a/x86_64/src/lib.rs
+++ b/x86_64/src/lib.rs
@@ -8,6 +8,9 @@
 
 mod fdt;
 
+#[cfg(feature = "gdb")]
+mod gdb;
+
 const SETUP_DTB: u32 = 2;
 const SETUP_RNG_SEED: u32 = 9;
 
@@ -38,10 +41,10 @@ pub mod smbios;
 
 use std::arch::x86_64::CpuidResult;
 use std::collections::BTreeMap;
-use std::ffi::CStr;
-use std::ffi::CString;
+use std::fmt;
 use std::fs::File;
 use std::io;
+use std::io::Write;
 use std::mem;
 use std::path::PathBuf;
 use std::sync::mpsc;
@@ -55,12 +58,13 @@ use arch::get_serial_cmdline;
 use arch::serial::SerialDeviceInfo;
 use arch::CpuSet;
 use arch::DtbOverlay;
+use arch::FdtPosition;
 use arch::GetSerialCmdlineError;
 use arch::RunnableLinuxVm;
 use arch::VmComponents;
 use arch::VmImage;
-#[cfg(feature = "seccomp_trace")]
 use base::debug;
+use base::info;
 use base::warn;
 #[cfg(any(target_os = "android", target_os = "linux"))]
 use base::AsRawDescriptors;
@@ -98,23 +102,10 @@ use devices::ProxyDevice;
 use devices::Serial;
 use devices::SerialHardware;
 use devices::SerialParameters;
-#[cfg(any(target_os = "android", target_os = "linux"))]
 use devices::VirtualPmc;
 use devices::FW_CFG_BASE_PORT;
 use devices::FW_CFG_MAX_FILE_SLOTS;
 use devices::FW_CFG_WIDTH;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::x86::reg::id::X86_64CoreRegId;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::x86::reg::X86SegmentRegs;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::x86::reg::X86_64CoreRegs;
-#[cfg(feature = "gdb")]
-use gdbstub_arch::x86::reg::X87FpuInternalRegs;
-#[cfg(feature = "gdb")]
-use hypervisor::x86_64::Regs;
-#[cfg(feature = "gdb")]
-use hypervisor::x86_64::Sregs;
 use hypervisor::CpuConfigX86_64;
 use hypervisor::Hypervisor;
 use hypervisor::HypervisorX86_64;
@@ -137,7 +128,6 @@ use remain::sorted;
 use resources::AddressRange;
 use resources::SystemAllocator;
 use resources::SystemAllocatorConfig;
-#[cfg(any(target_os = "android", target_os = "linux"))]
 use sync::Condvar;
 use sync::Mutex;
 use thiserror::Error;
@@ -147,11 +137,14 @@ use vm_memory::GuestAddress;
 use vm_memory::GuestMemory;
 use vm_memory::GuestMemoryError;
 use vm_memory::MemoryRegionOptions;
+use vm_memory::MemoryRegionPurpose;
 use zerocopy::AsBytes;
 use zerocopy::FromBytes;
 use zerocopy::FromZeroes;
 
 use crate::bootparam::boot_params;
+use crate::bootparam::setup_header;
+use crate::bootparam::XLF_CAN_BE_LOADED_ABOVE_4G;
 use crate::cpuid::EDX_HYBRID_CPU_SHIFT;
 
 #[sorted]
@@ -174,6 +167,10 @@ pub enum Error {
     CloneTube(TubeError),
     #[error("the given kernel command line was invalid: {0}")]
     Cmdline(kernel_cmdline::Error),
+    #[error("failed writing command line to guest memory")]
+    CommandLineCopy,
+    #[error("command line overflowed guest memory")]
+    CommandLineOverflow,
     #[error("failed to configure hotplugged pci device: {0}")]
     ConfigurePciDevice(arch::DeviceRegistrationError),
     #[error("failed to configure segment registers: {0}")]
@@ -207,6 +204,8 @@ pub enum Error {
     CreateSerialDevices(arch::DeviceRegistrationError),
     #[error("failed to create socket: {0}")]
     CreateSocket(io::Error),
+    #[error("failed to create tube: {0}")]
+    CreateTube(base::TubeError),
     #[error("failed to create VCPU: {0}")]
     CreateVcpu(base::Error),
     #[error("failed to create Virtio MMIO bus: {0}")]
@@ -229,8 +228,8 @@ pub enum Error {
     LoadBios(io::Error),
     #[error("error loading kernel bzImage: {0}")]
     LoadBzImage(bzimage::Error),
-    #[error("error loading command line: {0}")]
-    LoadCmdline(kernel_loader::Error),
+    #[error("error loading custom pVM firmware: {0}")]
+    LoadCustomPvmFw(arch::LoadImageError),
     #[error("error loading initrd: {0}")]
     LoadInitrd(arch::LoadImageError),
     #[error("error loading Kernel: {0}")]
@@ -239,6 +238,10 @@ pub enum Error {
     LoadPflash(io::Error),
     #[error("error translating address: Page not present")]
     PageNotPresent,
+    #[error("pci mmio overlaps with pVM firmware memory")]
+    PciMmioOverlapPvmFw,
+    #[error("pVM firmware not supported when bios is used on x86_64")]
+    PvmFwBiosUnsupported,
     #[error("error reading guest memory {0}")]
     ReadingGuestMemory(vm_memory::GuestMemoryError),
     #[error("single register read not supported on x86_64")]
@@ -328,19 +331,39 @@ pub struct SetupData {
     pub type_: SetupDataType,
 }
 
+#[derive(Copy, Clone, Debug)]
 enum E820Type {
     Ram = 0x01,
     Reserved = 0x2,
 }
 
+#[derive(Copy, Clone, Debug)]
+struct E820Entry {
+    pub address: GuestAddress,
+    pub len: u64,
+    pub mem_type: E820Type,
+}
+
 const MB: u64 = 1 << 20;
 const GB: u64 = 1 << 30;
 
 pub const BOOT_STACK_POINTER: u64 = 0x8000;
 const START_OF_RAM_32BITS: u64 = 0;
+const FIRST_ADDR_PAST_20BITS: u64 = 1 << 20;
 const FIRST_ADDR_PAST_32BITS: u64 = 1 << 32;
+// Make sure it align to 256MB for MTRR convenient
+const MEM_32BIT_GAP_SIZE: u64 = 768 * MB;
+const END_ADDR_BEFORE_32BITS: u64 = FIRST_ADDR_PAST_32BITS - MEM_32BIT_GAP_SIZE;
+// Reserved memory for nand_bios/LAPIC/IOAPIC/HPET/.....
+const RESERVED_MEM_SIZE: u64 = 0x800_0000;
+const PCI_MMIO_END: u64 = FIRST_ADDR_PAST_32BITS - RESERVED_MEM_SIZE - 1;
+// Reserve 64MB for pcie enhanced configuration
+const DEFAULT_PCIE_CFG_MMIO_SIZE: u64 = 0x400_0000;
+const DEFAULT_PCIE_CFG_MMIO_END: u64 = FIRST_ADDR_PAST_32BITS - RESERVED_MEM_SIZE - 1;
+const DEFAULT_PCIE_CFG_MMIO_START: u64 = DEFAULT_PCIE_CFG_MMIO_END - DEFAULT_PCIE_CFG_MMIO_SIZE + 1;
 // Linux (with 4-level paging) has a physical memory limit of 46 bits (64 TiB).
 const HIGH_MMIO_MAX_END: u64 = (1u64 << 46) - 1;
+pub const KERNEL_32BIT_ENTRY_OFFSET: u64 = 0x0;
 pub const KERNEL_64BIT_ENTRY_OFFSET: u64 = 0x200;
 pub const ZERO_PAGE_OFFSET: u64 = 0x7000;
 // Set BIOS max size to 16M: this is used only when `unrestricted guest` is disabled
@@ -364,6 +387,12 @@ pub const X86_64_SCI_IRQ: u32 = 5;
 pub const X86_64_IRQ_BASE: u32 = 9;
 const ACPI_HI_RSDP_WINDOW_BASE: u64 = 0x000E_0000;
 
+// pVM firmware memory. Should be within the low 4GB, so that it is identity-mapped
+// by setup_page_tables() when a protected VM boots in long mode, since the pVM firmware is
+// the VM entry point.
+const PROTECTED_VM_FW_MAX_SIZE: u64 = 0x40_0000;
+const PROTECTED_VM_FW_START: u64 = END_ADDR_BEFORE_32BITS - PROTECTED_VM_FW_MAX_SIZE;
+
 #[derive(Debug, PartialEq, Eq)]
 pub enum CpuManufacturer {
     Intel,
@@ -381,22 +410,18 @@ struct LowMemoryLayout {
     pci_mmio: AddressRange,
     // the pcie cfg mmio range
     pcie_cfg_mmio: AddressRange,
+    // the pVM firmware memory (if running a protected VM)
+    pvmfw_mem: Option<AddressRange>,
 }
 
 static LOW_MEMORY_LAYOUT: OnceCell<LowMemoryLayout> = OnceCell::new();
 
-pub fn init_low_memory_layout(pcie_ecam: Option<AddressRange>, pci_low_start: Option<u64>) {
+pub fn init_low_memory_layout(
+    pcie_ecam: Option<AddressRange>,
+    pci_low_start: Option<u64>,
+    has_protected_vm_firmware: bool,
+) -> Result<()> {
     LOW_MEMORY_LAYOUT.get_or_init(|| {
-        // Make sure it align to 256MB for MTRR convenient
-        const MEM_32BIT_GAP_SIZE: u64 = 768 * MB;
-        // Reserved memory for nand_bios/LAPIC/IOAPIC/HPET/.....
-        const RESERVED_MEM_SIZE: u64 = 0x800_0000;
-        const PCI_MMIO_END: u64 = FIRST_ADDR_PAST_32BITS - RESERVED_MEM_SIZE - 1;
-        // Reserve 64MB for pcie enhanced configuration
-        const DEFAULT_PCIE_CFG_MMIO_SIZE: u64 = 0x400_0000;
-        const DEFAULT_PCIE_CFG_MMIO_END: u64 = FIRST_ADDR_PAST_32BITS - RESERVED_MEM_SIZE - 1;
-        const DEFAULT_PCIE_CFG_MMIO_START: u64 =
-            DEFAULT_PCIE_CFG_MMIO_END - DEFAULT_PCIE_CFG_MMIO_SIZE + 1;
         const DEFAULT_PCIE_CFG_MMIO: AddressRange = AddressRange {
             start: DEFAULT_PCIE_CFG_MMIO_START,
             end: DEFAULT_PCIE_CFG_MMIO_END,
@@ -418,11 +443,32 @@ pub fn init_low_memory_layout(pcie_ecam: Option<AddressRange>, pci_low_start: Op
             }
         };
 
+        let pvmfw_mem = if has_protected_vm_firmware {
+            Some(AddressRange {
+                start: PROTECTED_VM_FW_START,
+                end: PROTECTED_VM_FW_START + PROTECTED_VM_FW_MAX_SIZE - 1,
+            })
+        } else {
+            None
+        };
+
         LowMemoryLayout {
             pci_mmio,
             pcie_cfg_mmio,
+            pvmfw_mem,
         }
     });
+
+    if has_protected_vm_firmware {
+        let pci_mmio = read_pci_mmio_before_32bit();
+        let pvmfw_mem = read_pvmfw_mem().unwrap();
+
+        if !pci_mmio.intersect(pvmfw_mem).is_empty() {
+            return Err(Error::PciMmioOverlapPvmFw);
+        }
+    }
+
+    Ok(())
 }
 
 pub fn read_pci_mmio_before_32bit() -> AddressRange {
@@ -431,6 +477,18 @@ pub fn read_pci_mmio_before_32bit() -> AddressRange {
 pub fn read_pcie_cfg_mmio() -> AddressRange {
     LOW_MEMORY_LAYOUT.get().unwrap().pcie_cfg_mmio
 }
+fn read_pvmfw_mem() -> Option<AddressRange> {
+    LOW_MEMORY_LAYOUT.get().unwrap().pvmfw_mem
+}
+
+fn max_ram_end_before_32bit(has_protected_vm_firmware: bool) -> u64 {
+    let pci_start = read_pci_mmio_before_32bit().start;
+    if has_protected_vm_firmware {
+        pci_start.min(PROTECTED_VM_FW_START)
+    } else {
+        pci_start
+    }
+}
 
 /// The x86 reset vector for i386+ and x86_64 puts the processor into an "unreal mode" where it
 /// can access the last 1 MB of the 32-bit address space in 16-bit mode, and starts the instruction
@@ -456,14 +514,12 @@ fn tss_addr_end() -> GuestAddress {
 
 fn configure_system(
     guest_mem: &GuestMemory,
-    kernel_addr: GuestAddress,
     cmdline_addr: GuestAddress,
-    cmdline_size: usize,
     setup_data: Option<GuestAddress>,
     initrd: Option<(GuestAddress, usize)>,
     mut params: boot_params,
+    e820_entries: &[E820Entry],
 ) -> Result<()> {
-    const EBDA_START: u64 = 0x0009_fc00;
     const KERNEL_BOOT_FLAG_MAGIC: u16 = 0xaa55;
     const KERNEL_HDR_MAGIC: u32 = 0x5372_6448;
     const KERNEL_LOADER_OTHER: u8 = 0xff;
@@ -474,59 +530,27 @@ fn configure_system(
     params.hdr.header = KERNEL_HDR_MAGIC;
     params.hdr.cmd_line_ptr = cmdline_addr.offset() as u32;
     params.ext_cmd_line_ptr = (cmdline_addr.offset() >> 32) as u32;
-    params.hdr.cmdline_size = cmdline_size as u32;
     params.hdr.kernel_alignment = KERNEL_MIN_ALIGNMENT_BYTES;
     if let Some(setup_data) = setup_data {
         params.hdr.setup_data = setup_data.offset();
     }
     if let Some((initrd_addr, initrd_size)) = initrd {
         params.hdr.ramdisk_image = initrd_addr.offset() as u32;
+        params.ext_ramdisk_image = (initrd_addr.offset() >> 32) as u32;
         params.hdr.ramdisk_size = initrd_size as u32;
+        params.ext_ramdisk_size = (initrd_size as u64 >> 32) as u32;
     }
 
-    add_e820_entry(
-        &mut params,
-        AddressRange {
-            start: START_OF_RAM_32BITS,
-            end: EBDA_START - 1,
-        },
-        E820Type::Ram,
-    )?;
-
-    // GuestMemory::end_addr() returns the first address past the end, so subtract 1 to get the
-    // inclusive end.
-    let guest_mem_end = guest_mem.end_addr().offset() - 1;
-    let ram_below_4g = AddressRange {
-        start: kernel_addr.offset(),
-        end: guest_mem_end.min(read_pci_mmio_before_32bit().start - 1),
-    };
-    let ram_above_4g = AddressRange {
-        start: FIRST_ADDR_PAST_32BITS,
-        end: guest_mem_end,
-    };
-    add_e820_entry(&mut params, ram_below_4g, E820Type::Ram)?;
-    if !ram_above_4g.is_empty() {
-        add_e820_entry(&mut params, ram_above_4g, E820Type::Ram)?
+    if e820_entries.len() >= params.e820_table.len() {
+        return Err(Error::E820Configuration);
     }
 
-    let pcie_cfg_mmio_range = read_pcie_cfg_mmio();
-    add_e820_entry(&mut params, pcie_cfg_mmio_range, E820Type::Reserved)?;
-
-    add_e820_entry(
-        &mut params,
-        X8664arch::get_pcie_vcfg_mmio_range(guest_mem, &pcie_cfg_mmio_range),
-        E820Type::Reserved,
-    )?;
-
-    // Reserve memory section for Identity map and TSS
-    add_e820_entry(
-        &mut params,
-        AddressRange {
-            start: identity_map_addr_start().offset(),
-            end: tss_addr_end().offset() - 1,
-        },
-        E820Type::Reserved,
-    )?;
+    for (src, dst) in e820_entries.iter().zip(params.e820_table.iter_mut()) {
+        dst.addr = src.address.offset();
+        dst.size = src.len;
+        dst.type_ = src.mem_type as u32;
+    }
+    params.e820_entries = e820_entries.len() as u8;
 
     let zero_page_addr = GuestAddress(ZERO_PAGE_OFFSET);
     if !guest_mem.is_valid_range(zero_page_addr, mem::size_of::<boot_params>() as u64) {
@@ -618,20 +642,64 @@ fn setup_data_rng_seed() -> SetupData {
 }
 
 /// Add an e820 region to the e820 map.
-/// Returns Ok(()) if successful, or an error if there is no space left in the map.
-fn add_e820_entry(params: &mut boot_params, range: AddressRange, mem_type: E820Type) -> Result<()> {
-    if params.e820_entries >= params.e820_table.len() as u8 {
-        return Err(Error::E820Configuration);
+fn add_e820_entry(
+    e820_entries: &mut Vec<E820Entry>,
+    range: AddressRange,
+    mem_type: E820Type,
+) -> Result<()> {
+    e820_entries.push(E820Entry {
+        address: GuestAddress(range.start),
+        len: range.len().ok_or(Error::E820Configuration)?,
+        mem_type,
+    });
+
+    Ok(())
+}
+
+/// Generate a memory map in INT 0x15 AX=0xE820 format.
+fn generate_e820_memory_map(
+    guest_mem: &GuestMemory,
+    ram_below_1m: AddressRange,
+    ram_below_4g: AddressRange,
+    ram_above_4g: AddressRange,
+    has_protected_vm_firmware: bool,
+) -> Result<Vec<E820Entry>> {
+    let mut e820_entries = Vec::new();
+
+    add_e820_entry(&mut e820_entries, ram_below_1m, E820Type::Ram)?;
+    add_e820_entry(&mut e820_entries, ram_below_4g, E820Type::Ram)?;
+    if !ram_above_4g.is_empty() {
+        add_e820_entry(&mut e820_entries, ram_above_4g, E820Type::Ram)?
     }
 
-    let size = range.len().ok_or(Error::E820Configuration)?;
+    if has_protected_vm_firmware {
+        // After the pVM firmware jumped to the guest, the pVM firmware itself
+        // is no longer running, so its memory is reusable by the guest OS.
+        // So add this memory as RAM rather than Reserved.
+        let pvmfw_range = read_pvmfw_mem().unwrap();
+        add_e820_entry(&mut e820_entries, pvmfw_range, E820Type::Ram)?;
+    }
 
-    params.e820_table[params.e820_entries as usize].addr = range.start;
-    params.e820_table[params.e820_entries as usize].size = size;
-    params.e820_table[params.e820_entries as usize].type_ = mem_type as u32;
-    params.e820_entries += 1;
+    let pcie_cfg_mmio_range = read_pcie_cfg_mmio();
+    add_e820_entry(&mut e820_entries, pcie_cfg_mmio_range, E820Type::Reserved)?;
 
-    Ok(())
+    add_e820_entry(
+        &mut e820_entries,
+        X8664arch::get_pcie_vcfg_mmio_range(guest_mem, &pcie_cfg_mmio_range),
+        E820Type::Reserved,
+    )?;
+
+    // Reserve memory section for Identity map and TSS
+    add_e820_entry(
+        &mut e820_entries,
+        AddressRange {
+            start: identity_map_addr_start().offset(),
+            end: tss_addr_end().offset() - 1,
+        },
+        E820Type::Reserved,
+    )?;
+
+    Ok(e820_entries)
 }
 
 /// Returns a Vec of the valid memory addresses.
@@ -641,23 +709,41 @@ fn add_e820_entry(params: &mut boot_params, range: AddressRange, mem_type: E820T
 pub fn arch_memory_regions(
     size: u64,
     bios_size: Option<u64>,
+    has_protected_vm_firmware: bool,
 ) -> Vec<(GuestAddress, u64, MemoryRegionOptions)> {
+    let mut mem_size = size;
+    let mut regions = Vec::new();
+
+    if has_protected_vm_firmware {
+        regions.push((
+            GuestAddress(PROTECTED_VM_FW_START),
+            PROTECTED_VM_FW_MAX_SIZE,
+            MemoryRegionOptions::new().purpose(MemoryRegionPurpose::ProtectedFirmwareRegion),
+        ));
+
+        // pVM firmware memory is a part of normal guest memory, since it is reusable
+        // by the guest OS once the pVM firmware jumped to the guest. So count its size
+        // as a part of the total guest memory size.
+        if mem_size > PROTECTED_VM_FW_MAX_SIZE {
+            mem_size -= PROTECTED_VM_FW_MAX_SIZE;
+        }
+    }
+
     let mem_start = START_OF_RAM_32BITS;
-    let mem_end = GuestAddress(size + mem_start);
+    let mem_end = GuestAddress(mem_size + mem_start);
 
     let first_addr_past_32bits = GuestAddress(FIRST_ADDR_PAST_32BITS);
-    let end_32bit_gap_start = GuestAddress(read_pci_mmio_before_32bit().start);
+    let max_end_32bits = GuestAddress(max_ram_end_before_32bit(has_protected_vm_firmware));
 
-    let mut regions = Vec::new();
-    if mem_end <= end_32bit_gap_start {
-        regions.push((GuestAddress(mem_start), size, Default::default()));
+    if mem_end <= max_end_32bits {
+        regions.push((GuestAddress(mem_start), mem_size, Default::default()));
         if let Some(bios_size) = bios_size {
             regions.push((bios_start(bios_size), bios_size, Default::default()));
         }
     } else {
         regions.push((
             GuestAddress(mem_start),
-            end_32bit_gap_start.offset() - mem_start,
+            max_end_32bits.offset() - mem_start,
             Default::default(),
         ));
         if let Some(bios_size) = bios_size {
@@ -665,7 +751,7 @@ pub fn arch_memory_regions(
         }
         regions.push((
             first_addr_past_32bits,
-            mem_end.offset_from(end_32bit_gap_start),
+            mem_end.offset_from(max_end_32bits),
             Default::default(),
         ));
     }
@@ -680,14 +766,24 @@ impl arch::LinuxArch for X8664arch {
         components: &VmComponents,
         _hypervisor: &impl Hypervisor,
     ) -> std::result::Result<Vec<(GuestAddress, u64, MemoryRegionOptions)>, Self::Error> {
-        init_low_memory_layout(components.pcie_ecam, components.pci_low_start);
+        let has_protected_vm_firmware = components.hv_cfg.protection_type.runs_firmware();
+
+        init_low_memory_layout(
+            components.pcie_ecam,
+            components.pci_low_start,
+            has_protected_vm_firmware,
+        )?;
 
         let bios_size = match &components.vm_image {
             VmImage::Bios(bios_file) => Some(bios_file.metadata().map_err(Error::LoadBios)?.len()),
             VmImage::Kernel(_) => None,
         };
 
-        Ok(arch_memory_regions(components.memory_size, bios_size))
+        Ok(arch_memory_regions(
+            components.memory_size,
+            bios_size,
+            has_protected_vm_firmware,
+        ))
     }
 
     fn get_system_allocator_config<V: Vm>(vm: &V) -> SystemAllocatorConfig {
@@ -720,16 +816,15 @@ impl arch::LinuxArch for X8664arch {
         pflash_jail: Option<Minijail>,
         fw_cfg_jail: Option<Minijail>,
         #[cfg(feature = "swap")] swap_controller: &mut Option<swap::SwapController>,
-        #[cfg(any(target_os = "android", target_os = "linux"))] guest_suspended_cvar: Option<
-            Arc<(Mutex<bool>, Condvar)>,
-        >,
+        guest_suspended_cvar: Option<Arc<(Mutex<bool>, Condvar)>>,
         device_tree_overlays: Vec<DtbOverlay>,
+        _fdt_position: Option<FdtPosition>,
     ) -> std::result::Result<RunnableLinuxVm<V, Vcpu>, Self::Error>
     where
         V: VmX86_64,
         Vcpu: VcpuX86_64,
     {
-        if components.hv_cfg.protection_type != ProtectionType::Unprotected {
+        if components.hv_cfg.protection_type.isolates_memory() {
             return Err(Error::UnsupportedProtectionType);
         }
 
@@ -843,7 +938,9 @@ impl arch::LinuxArch for X8664arch {
         pid_debug_label_map.append(&mut virtio_mmio_pid);
 
         // Event used to notify crosvm that guest OS is trying to suspend.
-        let suspend_evt = Event::new().map_err(Error::CreateEvent)?;
+        let (suspend_tube_send, suspend_tube_recv) =
+            Tube::directional_pair().map_err(Error::CreateTube)?;
+        let suspend_tube_send = Arc::new(Mutex::new(suspend_tube_send));
 
         if components.fw_cfg_enable {
             Self::setup_fw_cfg_device(
@@ -863,12 +960,18 @@ impl arch::LinuxArch for X8664arch {
                 vm_evt_wrtube.try_clone().map_err(Error::CloneTube)?,
             )?;
         }
-        let vm_request_tube = if !components.no_rtc {
+        let mut vm_request_tube = if !components.no_rtc {
             let (host_tube, device_tube) = Tube::pair()
                 .context("create tube")
                 .map_err(Error::SetupCmos)?;
-            Self::setup_legacy_cmos_device(&io_bus, irq_chip, device_tube, components.memory_size)
-                .map_err(Error::SetupCmos)?;
+            Self::setup_legacy_cmos_device(
+                &io_bus,
+                irq_chip,
+                device_tube,
+                components.memory_size,
+                components.hv_cfg.protection_type.runs_firmware(),
+            )
+            .map_err(Error::SetupCmos)?;
             Some(host_tube)
         } else {
             None
@@ -921,7 +1024,7 @@ impl arch::LinuxArch for X8664arch {
             &mem,
             &io_bus,
             system_allocator,
-            suspend_evt.try_clone().map_err(Error::CloneEvent)?,
+            suspend_tube_send.clone(),
             vm_evt_wrtube.try_clone().map_err(Error::CloneTube)?,
             components.acpi_sdts,
             irq_chip.as_irq_chip_mut(),
@@ -934,7 +1037,6 @@ impl arch::LinuxArch for X8664arch {
             swap_controller,
             #[cfg(any(target_os = "android", target_os = "linux"))]
             components.ac_adapter,
-            #[cfg(any(target_os = "android", target_os = "linux"))]
             guest_suspended_cvar,
             &pci_irqs,
         )?;
@@ -1006,47 +1108,100 @@ impl arch::LinuxArch for X8664arch {
         let mut vcpu_init = vec![VcpuInitX86_64::default(); vcpu_count];
         let mut msrs = BTreeMap::new();
 
+        let protection_type = components.hv_cfg.protection_type;
+
         match components.vm_image {
             VmImage::Bios(ref mut bios) => {
+                if protection_type.runs_firmware() {
+                    return Err(Error::PvmFwBiosUnsupported);
+                }
+
                 // Allow a bios to hardcode CMDLINE_OFFSET and read the kernel command line from it.
-                kernel_loader::load_cmdline(
+                Self::load_cmdline(
                     &mem,
                     GuestAddress(CMDLINE_OFFSET),
-                    &CString::new(cmdline).unwrap(),
-                )
-                .map_err(Error::LoadCmdline)?;
+                    cmdline,
+                    CMDLINE_MAX_SIZE as usize - 1,
+                )?;
                 Self::load_bios(&mem, bios)?;
                 regs::set_default_msrs(&mut msrs);
                 // The default values for `Regs` and `Sregs` already set up the reset vector.
             }
             VmImage::Kernel(ref mut kernel_image) => {
-                let (params, kernel_end, kernel_entry) = Self::load_kernel(&mem, kernel_image)?;
+                let (params, kernel_end, kernel_entry, cpu_mode, kernel_type) =
+                    Self::load_kernel(&mem, kernel_image)?;
+
+                info!("Loaded {} kernel", kernel_type);
 
                 Self::setup_system_memory(
                     &mem,
-                    &CString::new(cmdline).unwrap(),
+                    cmdline,
                     components.initrd_image,
                     components.android_fstab,
                     kernel_end,
                     params,
                     dump_device_tree_blob,
                     device_tree_overlays,
+                    protection_type.runs_firmware(),
                 )?;
 
-                // Configure the bootstrap VCPU for the Linux/x86 64-bit boot protocol.
-                // <https://www.kernel.org/doc/html/latest/x86/boot.html>
-                vcpu_init[0].regs.rip = kernel_entry.offset();
-                vcpu_init[0].regs.rsp = BOOT_STACK_POINTER;
-                vcpu_init[0].regs.rsi = ZERO_PAGE_OFFSET;
+                if protection_type.needs_firmware_loaded() {
+                    arch::load_image(
+                        &mem,
+                        &mut components
+                            .pvm_fw
+                            .expect("pvmfw must be available if ProtectionType loads it"),
+                        GuestAddress(PROTECTED_VM_FW_START),
+                        PROTECTED_VM_FW_MAX_SIZE,
+                    )
+                    .map_err(Error::LoadCustomPvmFw)?;
+                }
+
+                let entry_addr = if protection_type.runs_firmware() {
+                    PROTECTED_VM_FW_START
+                } else {
+                    kernel_entry.offset()
+                };
 
-                regs::set_long_mode_msrs(&mut msrs);
-                regs::set_mtrr_msrs(&mut msrs, &vm, pci_start);
+                vcpu_init[0].regs.rip = entry_addr;
+
+                match kernel_type {
+                    KernelType::BzImage | KernelType::Elf => {
+                        // Configure the bootstrap VCPU for the Linux/x86 boot protocol.
+                        // <https://www.kernel.org/doc/html/latest/x86/boot.html>
+                        vcpu_init[0].regs.rsp = BOOT_STACK_POINTER;
+                        vcpu_init[0].regs.rsi = ZERO_PAGE_OFFSET;
+                    }
+                }
+
+                if protection_type.runs_firmware() {
+                    // Pass pVM payload entry address to pVM firmware.
+                    // NOTE: this ABI is subject to change. Possibly we will pass
+                    // all the needed info (payload entry, start and size) in in-memory
+                    // structures (e.g. DTB) instead.
+                    vcpu_init[0].regs.rdi = kernel_entry.offset();
+                }
 
-                // Set up long mode and enable paging.
-                regs::configure_segments_and_sregs(&mem, &mut vcpu_init[0].sregs)
-                    .map_err(Error::ConfigureSegments)?;
-                regs::setup_page_tables(&mem, &mut vcpu_init[0].sregs)
-                    .map_err(Error::SetupPageTables)?;
+                match cpu_mode {
+                    CpuMode::LongMode => {
+                        regs::set_long_mode_msrs(&mut msrs);
+
+                        // Set up long mode and enable paging.
+                        regs::configure_segments_and_sregs(&mem, &mut vcpu_init[0].sregs)
+                            .map_err(Error::ConfigureSegments)?;
+                        regs::setup_page_tables(&mem, &mut vcpu_init[0].sregs)
+                            .map_err(Error::SetupPageTables)?;
+                    }
+                    CpuMode::FlatProtectedMode => {
+                        regs::set_default_msrs(&mut msrs);
+
+                        // Set up 32-bit protected mode with paging disabled.
+                        regs::configure_segments_and_sregs_flat32(&mem, &mut vcpu_init[0].sregs)
+                            .map_err(Error::ConfigureSegments)?;
+                    }
+                }
+
+                regs::set_mtrr_msrs(&mut msrs, &vm, pci_start);
             }
         }
 
@@ -1055,6 +1210,11 @@ impl arch::LinuxArch for X8664arch {
             vcpu.msrs = msrs.clone();
         }
 
+        let mut vm_request_tubes = Vec::new();
+        if let Some(req_tube) = vm_request_tube.take() {
+            vm_request_tubes.push(req_tube);
+        }
+
         Ok(RunnableLinuxVm {
             vm,
             vcpu_count,
@@ -1066,7 +1226,7 @@ impl arch::LinuxArch for X8664arch {
             io_bus,
             mmio_bus,
             pid_debug_label_map,
-            suspend_evt,
+            suspend_tube: (suspend_tube_send, suspend_tube_recv),
             resume_notify_devices,
             rt_cpus: components.rt_cpus,
             delay_rt: components.delay_rt,
@@ -1079,7 +1239,7 @@ impl arch::LinuxArch for X8664arch {
             platform_devices: Vec::new(),
             hotplug_bus: BTreeMap::new(),
             devices_thread: None,
-            vm_request_tube,
+            vm_request_tubes,
         })
     }
 
@@ -1161,6 +1321,10 @@ impl arch::LinuxArch for X8664arch {
         Ok(BTreeMap::new())
     }
 
+    fn get_host_cpu_max_freq_khz() -> Result<BTreeMap<usize, u32>> {
+        Ok(BTreeMap::new())
+    }
+
     fn get_host_cpu_capacity() -> Result<BTreeMap<usize, u32>> {
         Ok(BTreeMap::new())
     }
@@ -1170,291 +1334,6 @@ impl arch::LinuxArch for X8664arch {
     }
 }
 
-#[cfg(feature = "gdb")]
-impl<T: VcpuX86_64> arch::GdbOps<T> for X8664arch {
-    type Error = Error;
-
-    fn read_registers(vcpu: &T) -> Result<X86_64CoreRegs> {
-        // General registers: RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, r8-r15
-        let gregs = vcpu.get_regs().map_err(Error::ReadRegs)?;
-        let regs = [
-            gregs.rax, gregs.rbx, gregs.rcx, gregs.rdx, gregs.rsi, gregs.rdi, gregs.rbp, gregs.rsp,
-            gregs.r8, gregs.r9, gregs.r10, gregs.r11, gregs.r12, gregs.r13, gregs.r14, gregs.r15,
-        ];
-
-        // GDB exposes 32-bit eflags instead of 64-bit rflags.
-        // https://github.com/bminor/binutils-gdb/blob/master/gdb/features/i386/64bit-core.xml
-        let eflags = gregs.rflags as u32;
-        let rip = gregs.rip;
-
-        // Segment registers: CS, SS, DS, ES, FS, GS
-        let sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
-        let segments = X86SegmentRegs {
-            cs: sregs.cs.selector as u32,
-            ss: sregs.ss.selector as u32,
-            ds: sregs.ds.selector as u32,
-            es: sregs.es.selector as u32,
-            fs: sregs.fs.selector as u32,
-            gs: sregs.gs.selector as u32,
-        };
-
-        // x87 FPU internal state
-        // TODO(dverkamp): floating point tag word, instruction pointer, and data pointer
-        let fpu = vcpu.get_fpu().map_err(Error::ReadRegs)?;
-        let fpu_internal = X87FpuInternalRegs {
-            fctrl: u32::from(fpu.fcw),
-            fstat: u32::from(fpu.fsw),
-            fop: u32::from(fpu.last_opcode),
-            ..Default::default()
-        };
-
-        let mut regs = X86_64CoreRegs {
-            regs,
-            eflags,
-            rip,
-            segments,
-            st: Default::default(),
-            fpu: fpu_internal,
-            xmm: Default::default(),
-            mxcsr: fpu.mxcsr,
-        };
-
-        // x87 FPU registers: ST0-ST7
-        for (dst, src) in regs.st.iter_mut().zip(fpu.fpr.iter()) {
-            // `fpr` contains the x87 floating point registers in FXSAVE format.
-            // Each element contains an 80-bit floating point value in the low 10 bytes.
-            // The upper 6 bytes are reserved and can be ignored.
-            dst.copy_from_slice(&src[0..10])
-        }
-
-        // SSE registers: XMM0-XMM15
-        for (dst, src) in regs.xmm.iter_mut().zip(fpu.xmm.iter()) {
-            *dst = u128::from_le_bytes(*src);
-        }
-
-        Ok(regs)
-    }
-
-    fn write_registers(vcpu: &T, regs: &X86_64CoreRegs) -> Result<()> {
-        // General purpose registers (RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, r8-r15) + RIP + rflags
-        let orig_gregs = vcpu.get_regs().map_err(Error::ReadRegs)?;
-        let gregs = Regs {
-            rax: regs.regs[0],
-            rbx: regs.regs[1],
-            rcx: regs.regs[2],
-            rdx: regs.regs[3],
-            rsi: regs.regs[4],
-            rdi: regs.regs[5],
-            rbp: regs.regs[6],
-            rsp: regs.regs[7],
-            r8: regs.regs[8],
-            r9: regs.regs[9],
-            r10: regs.regs[10],
-            r11: regs.regs[11],
-            r12: regs.regs[12],
-            r13: regs.regs[13],
-            r14: regs.regs[14],
-            r15: regs.regs[15],
-            rip: regs.rip,
-            // Update the lower 32 bits of rflags.
-            rflags: (orig_gregs.rflags & !(u32::MAX as u64)) | (regs.eflags as u64),
-        };
-        vcpu.set_regs(&gregs).map_err(Error::WriteRegs)?;
-
-        // Segment registers: CS, SS, DS, ES, FS, GS
-        // Since GDB care only selectors, we call get_sregs() first.
-        let mut sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
-        sregs.cs.selector = regs.segments.cs as u16;
-        sregs.ss.selector = regs.segments.ss as u16;
-        sregs.ds.selector = regs.segments.ds as u16;
-        sregs.es.selector = regs.segments.es as u16;
-        sregs.fs.selector = regs.segments.fs as u16;
-        sregs.gs.selector = regs.segments.gs as u16;
-
-        vcpu.set_sregs(&sregs).map_err(Error::WriteRegs)?;
-
-        // FPU and SSE registers
-        let mut fpu = vcpu.get_fpu().map_err(Error::ReadRegs)?;
-        fpu.fcw = regs.fpu.fctrl as u16;
-        fpu.fsw = regs.fpu.fstat as u16;
-        fpu.last_opcode = regs.fpu.fop as u16;
-        // TODO(dverkamp): floating point tag word, instruction pointer, and data pointer
-
-        // x87 FPU registers: ST0-ST7
-        for (dst, src) in fpu.fpr.iter_mut().zip(regs.st.iter()) {
-            dst[0..10].copy_from_slice(src);
-        }
-
-        // SSE registers: XMM0-XMM15
-        for (dst, src) in fpu.xmm.iter_mut().zip(regs.xmm.iter()) {
-            dst.copy_from_slice(&src.to_le_bytes());
-        }
-
-        vcpu.set_fpu(&fpu).map_err(Error::WriteRegs)?;
-
-        Ok(())
-    }
-
-    #[inline]
-    fn read_register(_vcpu: &T, _reg: X86_64CoreRegId) -> Result<Vec<u8>> {
-        Err(Error::ReadRegIsUnsupported)
-    }
-
-    #[inline]
-    fn write_register(_vcpu: &T, _reg: X86_64CoreRegId, _buf: &[u8]) -> Result<()> {
-        Err(Error::WriteRegIsUnsupported)
-    }
-
-    fn read_memory(
-        vcpu: &T,
-        guest_mem: &GuestMemory,
-        vaddr: GuestAddress,
-        len: usize,
-    ) -> Result<Vec<u8>> {
-        let sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
-        let mut buf = vec![0; len];
-        let mut total_read = 0u64;
-        // Handle reads across page boundaries.
-
-        while total_read < len as u64 {
-            let (paddr, psize) = phys_addr(guest_mem, vaddr.0 + total_read, &sregs)?;
-            let read_len = std::cmp::min(len as u64 - total_read, psize - (paddr & (psize - 1)));
-            guest_mem
-                .get_slice_at_addr(GuestAddress(paddr), read_len as usize)
-                .map_err(Error::ReadingGuestMemory)?
-                .copy_to(&mut buf[total_read as usize..]);
-            total_read += read_len;
-        }
-        Ok(buf)
-    }
-
-    fn write_memory(
-        vcpu: &T,
-        guest_mem: &GuestMemory,
-        vaddr: GuestAddress,
-        buf: &[u8],
-    ) -> Result<()> {
-        let sregs = vcpu.get_sregs().map_err(Error::ReadRegs)?;
-        let mut total_written = 0u64;
-        // Handle writes across page boundaries.
-        while total_written < buf.len() as u64 {
-            let (paddr, psize) = phys_addr(guest_mem, vaddr.0 + total_written, &sregs)?;
-            let write_len = std::cmp::min(
-                buf.len() as u64 - total_written,
-                psize - (paddr & (psize - 1)),
-            );
-
-            guest_mem
-                .write_all_at_addr(
-                    &buf[total_written as usize..(total_written as usize + write_len as usize)],
-                    GuestAddress(paddr),
-                )
-                .map_err(Error::WritingGuestMemory)?;
-            total_written += write_len;
-        }
-        Ok(())
-    }
-
-    fn enable_singlestep(vcpu: &T) -> Result<()> {
-        vcpu.set_guest_debug(&[], true /* enable_singlestep */)
-            .map_err(Error::EnableSinglestep)
-    }
-
-    fn get_max_hw_breakpoints(_vcpu: &T) -> Result<usize> {
-        Ok(4usize)
-    }
-
-    fn set_hw_breakpoints(vcpu: &T, breakpoints: &[GuestAddress]) -> Result<()> {
-        vcpu.set_guest_debug(breakpoints, false /* enable_singlestep */)
-            .map_err(Error::SetHwBreakpoint)
-    }
-}
-
-#[cfg(feature = "gdb")]
-// return the translated address and the size of the page it resides in.
-fn phys_addr(mem: &GuestMemory, vaddr: u64, sregs: &Sregs) -> Result<(u64, u64)> {
-    const CR0_PG_MASK: u64 = 1 << 31;
-    const CR4_PAE_MASK: u64 = 1 << 5;
-    const CR4_LA57_MASK: u64 = 1 << 12;
-    const MSR_EFER_LMA: u64 = 1 << 10;
-    // bits 12 through 51 are the address in a PTE.
-    const PTE_ADDR_MASK: u64 = ((1 << 52) - 1) & !0x0fff;
-    const PAGE_PRESENT: u64 = 0x1;
-    const PAGE_PSE_MASK: u64 = 0x1 << 7;
-
-    const PAGE_SIZE_4K: u64 = 4 * 1024;
-    const PAGE_SIZE_2M: u64 = 2 * 1024 * 1024;
-    const PAGE_SIZE_1G: u64 = 1024 * 1024 * 1024;
-
-    fn next_pte(mem: &GuestMemory, curr_table_addr: u64, vaddr: u64, level: usize) -> Result<u64> {
-        let ent: u64 = mem
-            .read_obj_from_addr(GuestAddress(
-                (curr_table_addr & PTE_ADDR_MASK) + page_table_offset(vaddr, level),
-            ))
-            .map_err(|_| Error::TranslatingVirtAddr)?;
-        /* TODO - convert to a trace
-        println!(
-            "level {} vaddr {:x} table-addr {:x} mask {:x} ent {:x} offset {:x}",
-            level,
-            vaddr,
-            curr_table_addr,
-            PTE_ADDR_MASK,
-            ent,
-            page_table_offset(vaddr, level)
-        );
-        */
-        if ent & PAGE_PRESENT == 0 {
-            return Err(Error::PageNotPresent);
-        }
-        Ok(ent)
-    }
-
-    // Get the offset in to the page of `vaddr`.
-    fn page_offset(vaddr: u64, page_size: u64) -> u64 {
-        vaddr & (page_size - 1)
-    }
-
-    // Get the offset in to the page table of the given `level` specified by the virtual `address`.
-    // `level` is 1 through 5 in x86_64 to handle the five levels of paging.
-    fn page_table_offset(addr: u64, level: usize) -> u64 {
-        let offset = (level - 1) * 9 + 12;
-        ((addr >> offset) & 0x1ff) << 3
-    }
-
-    if sregs.cr0 & CR0_PG_MASK == 0 {
-        return Ok((vaddr, PAGE_SIZE_4K));
-    }
-
-    if sregs.cr4 & CR4_PAE_MASK == 0 {
-        return Err(Error::TranslatingVirtAddr);
-    }
-
-    if sregs.efer & MSR_EFER_LMA != 0 {
-        // TODO - check LA57
-        if sregs.cr4 & CR4_LA57_MASK != 0 {
-            todo!("handle LA57");
-        }
-        let p4_ent = next_pte(mem, sregs.cr3, vaddr, 4)?;
-        let p3_ent = next_pte(mem, p4_ent, vaddr, 3)?;
-        // TODO check if it's a 1G page with the PSE bit in p2_ent
-        if p3_ent & PAGE_PSE_MASK != 0 {
-            // It's a 1G page with the PSE bit in p3_ent
-            let paddr = p3_ent & PTE_ADDR_MASK | page_offset(vaddr, PAGE_SIZE_1G);
-            return Ok((paddr, PAGE_SIZE_1G));
-        }
-        let p2_ent = next_pte(mem, p3_ent, vaddr, 2)?;
-        if p2_ent & PAGE_PSE_MASK != 0 {
-            // It's a 2M page with the PSE bit in p2_ent
-            let paddr = p2_ent & PTE_ADDR_MASK | page_offset(vaddr, PAGE_SIZE_2M);
-            return Ok((paddr, PAGE_SIZE_2M));
-        }
-        let p1_ent = next_pte(mem, p2_ent, vaddr, 1)?;
-        let paddr = p1_ent & PTE_ADDR_MASK | page_offset(vaddr, PAGE_SIZE_4K);
-        return Ok((paddr, PAGE_SIZE_4K));
-    }
-    Err(Error::TranslatingVirtAddr)
-}
-
 // OSC returned status register in CDW1
 const OSC_STATUS_UNSUPPORT_UUID: u32 = 0x4;
 // pci host bridge OSC returned control register in CDW3
@@ -1537,6 +1416,29 @@ impl Aml for PciRootOSC {
     }
 }
 
+pub enum CpuMode {
+    /// 32-bit protected mode with paging disabled.
+    FlatProtectedMode,
+
+    /// 64-bit long mode.
+    LongMode,
+}
+
+#[derive(Copy, Clone, Debug, Eq, PartialEq)]
+pub enum KernelType {
+    BzImage,
+    Elf,
+}
+
+impl fmt::Display for KernelType {
+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
+        match self {
+            KernelType::BzImage => write!(f, "bzImage"),
+            KernelType::Elf => write!(f, "ELF"),
+        }
+    }
+}
+
 impl X8664arch {
     /// Loads the bios from an open file.
     ///
@@ -1604,6 +1506,37 @@ impl X8664arch {
         Ok(())
     }
 
+    /// Writes the command line string to the given memory slice.
+    ///
+    /// # Arguments
+    ///
+    /// * `guest_mem` - A u8 slice that will be partially overwritten by the command line.
+    /// * `guest_addr` - The address in `guest_mem` at which to load the command line.
+    /// * `cmdline` - The kernel command line.
+    /// * `kernel_max_cmdline_len` - The maximum command line length (without NUL terminator)
+    ///   supported by the kernel.
+    fn load_cmdline(
+        guest_mem: &GuestMemory,
+        guest_addr: GuestAddress,
+        cmdline: kernel_cmdline::Cmdline,
+        kernel_max_cmdline_len: usize,
+    ) -> Result<()> {
+        let mut cmdline_guest_mem_slice = guest_mem
+            .get_slice_at_addr(guest_addr, CMDLINE_MAX_SIZE as usize)
+            .map_err(|_| Error::CommandLineOverflow)?;
+
+        let mut cmdline_bytes: Vec<u8> = cmdline
+            .into_bytes_with_max_len(kernel_max_cmdline_len)
+            .map_err(Error::Cmdline)?;
+        cmdline_bytes.push(0u8); // Add NUL terminator.
+
+        cmdline_guest_mem_slice
+            .write_all(&cmdline_bytes)
+            .map_err(|_| Error::CommandLineOverflow)?;
+
+        Ok(())
+    }
+
     /// Loads the kernel from an open file.
     ///
     /// # Arguments
@@ -1614,31 +1547,43 @@ impl X8664arch {
     /// # Returns
     ///
     /// On success, returns the Linux x86_64 boot protocol parameters, the first address past the
-    /// end of the kernel, and the entry point (initial `RIP` value).
+    /// end of the kernel, the entry point (initial `RIP` value), the initial CPU mode, and the type
+    /// of kernel.
     fn load_kernel(
         mem: &GuestMemory,
         kernel_image: &mut File,
-    ) -> Result<(boot_params, u64, GuestAddress)> {
+    ) -> Result<(boot_params, u64, GuestAddress, CpuMode, KernelType)> {
         let kernel_start = GuestAddress(KERNEL_START_OFFSET);
         match kernel_loader::load_elf64(mem, kernel_start, kernel_image, 0) {
             Ok(loaded_kernel) => {
                 // ELF kernels don't contain a `boot_params` structure, so synthesize a default one.
-                let boot_params = Default::default();
+                let boot_params = boot_params {
+                    hdr: setup_header {
+                        cmdline_size: CMDLINE_MAX_SIZE as u32 - 1,
+                        ..Default::default()
+                    },
+                    ..Default::default()
+                };
                 Ok((
                     boot_params,
                     loaded_kernel.address_range.end,
                     loaded_kernel.entry,
+                    CpuMode::LongMode,
+                    KernelType::Elf,
                 ))
             }
             Err(kernel_loader::Error::InvalidMagicNumber) => {
                 // The image failed to parse as ELF, so try to load it as a bzImage.
-                let (boot_params, bzimage_end) =
+                let (boot_params, bzimage_end, bzimage_entry, cpu_mode) =
                     bzimage::load_bzimage(mem, kernel_start, kernel_image)
                         .map_err(Error::LoadBzImage)?;
-                let bzimage_entry = mem
-                    .checked_offset(kernel_start, KERNEL_64BIT_ENTRY_OFFSET)
-                    .ok_or(Error::KernelOffsetPastEnd)?;
-                Ok((boot_params, bzimage_end, bzimage_entry))
+                Ok((
+                    boot_params,
+                    bzimage_end,
+                    bzimage_entry,
+                    cpu_mode,
+                    KernelType::BzImage,
+                ))
             }
             Err(e) => Err(Error::LoadKernel(e)),
         }
@@ -1654,16 +1599,68 @@ impl X8664arch {
     /// * `initrd_file` - an initial ramdisk image
     pub fn setup_system_memory(
         mem: &GuestMemory,
-        cmdline: &CStr,
+        cmdline: kernel_cmdline::Cmdline,
         initrd_file: Option<File>,
         android_fstab: Option<File>,
         kernel_end: u64,
         params: boot_params,
         dump_device_tree_blob: Option<PathBuf>,
         device_tree_overlays: Vec<DtbOverlay>,
+        has_protected_vm_firmware: bool,
     ) -> Result<()> {
-        kernel_loader::load_cmdline(mem, GuestAddress(CMDLINE_OFFSET), cmdline)
-            .map_err(Error::LoadCmdline)?;
+        // Some guest kernels expect a typical PC memory layout where the region between 640 KB and
+        // 1 MB is reserved for device memory/ROMs and get confused if there is a RAM region
+        // spanning this area, so we provide the traditional 640 KB low memory and 1 MB+
+        // high memory regions.
+        let ram_below_1m_end = 640 * 1024;
+        let ram_below_1m = AddressRange {
+            start: START_OF_RAM_32BITS,
+            end: ram_below_1m_end - 1,
+        };
+
+        // GuestMemory::end_addr() returns the first address past the end, so subtract 1 to get the
+        // inclusive end.
+        let guest_mem_end = mem.end_addr().offset() - 1;
+
+        // Find the end of the part of guest memory below 4G that is not pVM firmware memory.
+        // This part of guest memory includes just one region, so just find the end of this region.
+        let max_ram_end_below_4g = max_ram_end_before_32bit(has_protected_vm_firmware) - 1;
+        let guest_mem_end_below_4g = mem
+            .regions()
+            .map(|r| r.guest_addr.offset() + r.size as u64 - 1)
+            .find(|&addr| addr <= max_ram_end_below_4g)
+            .expect("no memory region below 4G");
+
+        let ram_below_4g = AddressRange {
+            start: FIRST_ADDR_PAST_20BITS,
+            end: guest_mem_end_below_4g,
+        };
+        let ram_above_4g = AddressRange {
+            start: FIRST_ADDR_PAST_32BITS,
+            end: guest_mem_end,
+        };
+
+        let e820_entries = generate_e820_memory_map(
+            mem,
+            ram_below_1m,
+            ram_below_4g,
+            ram_above_4g,
+            has_protected_vm_firmware,
+        )?;
+
+        let kernel_max_cmdline_len = if params.hdr.cmdline_size == 0 {
+            // Old kernels have a maximum length of 255 bytes, not including the NUL.
+            255
+        } else {
+            params.hdr.cmdline_size as usize
+        };
+        debug!("kernel_max_cmdline_len={kernel_max_cmdline_len}");
+        Self::load_cmdline(
+            mem,
+            GuestAddress(CMDLINE_OFFSET),
+            cmdline,
+            kernel_max_cmdline_len,
+        )?;
 
         let mut setup_data = Vec::<SetupData>::new();
         if let Some(android_fstab) = android_fstab {
@@ -1683,22 +1680,23 @@ impl X8664arch {
 
         let initrd = match initrd_file {
             Some(mut initrd_file) => {
-                let mut initrd_addr_max = u64::from(params.hdr.initrd_addr_max);
-                // Default initrd_addr_max for old kernels (see Documentation/x86/boot.txt).
-                if initrd_addr_max == 0 {
-                    initrd_addr_max = 0x37FFFFFF;
-                }
-
-                let mem_max = mem.end_addr().offset() - 1;
-                if initrd_addr_max > mem_max {
-                    initrd_addr_max = mem_max;
-                }
+                let initrd_addr_max = if params.hdr.xloadflags & XLF_CAN_BE_LOADED_ABOVE_4G != 0 {
+                    u64::MAX
+                } else if params.hdr.initrd_addr_max == 0 {
+                    // Default initrd_addr_max for old kernels (see Documentation/x86/boot.txt).
+                    0x37FFFFFF
+                } else {
+                    u64::from(params.hdr.initrd_addr_max)
+                };
 
                 let (initrd_start, initrd_size) = arch::load_image_high(
                     mem,
                     &mut initrd_file,
                     GuestAddress(kernel_end),
                     GuestAddress(initrd_addr_max),
+                    Some(|region| {
+                        region.options.purpose != MemoryRegionPurpose::ProtectedFirmwareRegion
+                    }),
                     base::pagesize() as u64,
                 )
                 .map_err(Error::LoadInitrd)?;
@@ -1709,12 +1707,11 @@ impl X8664arch {
 
         configure_system(
             mem,
-            GuestAddress(KERNEL_START_OFFSET),
             GuestAddress(CMDLINE_OFFSET),
-            cmdline.to_bytes().len() + 1,
             setup_data,
             initrd,
             params,
+            &e820_entries,
         )?;
         Ok(())
     }
@@ -1745,7 +1742,7 @@ impl X8664arch {
 
     /// This returns a minimal kernel command for this architecture
     pub fn get_base_linux_cmdline() -> kernel_cmdline::Cmdline {
-        let mut cmdline = kernel_cmdline::Cmdline::new(CMDLINE_MAX_SIZE as usize);
+        let mut cmdline = kernel_cmdline::Cmdline::new();
         cmdline.insert_str("panic=-1").unwrap();
 
         cmdline
@@ -1754,9 +1751,9 @@ impl X8664arch {
     /// Sets up fw_cfg device.
     ///  # Arguments
     ///
-    /// * - `io_bus` - the IO bus object
-    /// * - `fw_cfg_parameters` - command-line specified data to add to device. May contain
-    /// all None fields if user did not specify data to add to the device
+    /// * `io_bus` - the IO bus object
+    /// * `fw_cfg_parameters` - command-line specified data to add to device. May contain all None
+    ///   fields if user did not specify data to add to the device
     fn setup_fw_cfg_device(
         io_bus: &Bus,
         fw_cfg_parameters: Vec<FwCfgParameters>,
@@ -1855,8 +1852,9 @@ impl X8664arch {
         irq_chip: &mut dyn IrqChipX86_64,
         vm_control: Tube,
         mem_size: u64,
+        has_protected_vm_firmware: bool,
     ) -> anyhow::Result<()> {
-        let mem_regions = arch_memory_regions(mem_size, None);
+        let mem_regions = arch_memory_regions(mem_size, None, has_protected_vm_firmware);
 
         let mem_below_4g = mem_regions
             .iter()
@@ -1899,21 +1897,21 @@ impl X8664arch {
     ///
     /// # Arguments
     ///
-    /// * - `io_bus` the I/O bus to add the devices to
-    /// * - `resources` the SystemAllocator to allocate IO and MMIO for acpi devices.
-    /// * - `suspend_evt` the event object which used to suspend the vm
-    /// * - `sdts` ACPI system description tables
-    /// * - `irq_chip` the IrqChip object for registering irq events
-    /// * - `battery` indicate whether to create the battery
-    /// * - `mmio_bus` the MMIO bus to add the devices to
-    /// * - `pci_irqs` IRQ assignment of PCI devices. Tuples of (PCI address, gsi, PCI interrupt
-    ///   pin). Note that this matches one of the return values of generate_pci_root.
+    /// * `io_bus` the I/O bus to add the devices to
+    /// * `resources` the SystemAllocator to allocate IO and MMIO for acpi devices.
+    /// * `suspend_tube` the tube object which used to suspend/resume the VM.
+    /// * `sdts` ACPI system description tables
+    /// * `irq_chip` the IrqChip object for registering irq events
+    /// * `battery` indicate whether to create the battery
+    /// * `mmio_bus` the MMIO bus to add the devices to
+    /// * `pci_irqs` IRQ assignment of PCI devices. Tuples of (PCI address, gsi, PCI interrupt pin).
+    ///   Note that this matches one of the return values of generate_pci_root.
     pub fn setup_acpi_devices(
         pci_root: Arc<Mutex<PciRoot>>,
         mem: &GuestMemory,
         io_bus: &Bus,
         resources: &mut SystemAllocator,
-        suspend_evt: Event,
+        suspend_tube: Arc<Mutex<SendTube>>,
         vm_evt_wrtube: SendTube,
         sdts: Vec<SDT>,
         irq_chip: &mut dyn IrqChip,
@@ -1924,9 +1922,7 @@ impl X8664arch {
         resume_notify_devices: &mut Vec<Arc<Mutex<dyn BusResumeDevice>>>,
         #[cfg(feature = "swap")] swap_controller: &mut Option<swap::SwapController>,
         #[cfg(any(target_os = "android", target_os = "linux"))] ac_adapter: bool,
-        #[cfg(any(target_os = "android", target_os = "linux"))] guest_suspended_cvar: Option<
-            Arc<(Mutex<bool>, Condvar)>,
-        >,
+        guest_suspended_cvar: Option<Arc<(Mutex<bool>, Condvar)>>,
         pci_irqs: &[(PciAddress, u32, PciInterruptPin)],
     ) -> Result<(acpi::AcpiDevResource, Option<BatControl>)> {
         // The AML data for the acpi devices
@@ -2016,7 +2012,6 @@ impl X8664arch {
         let acdc = None;
 
         //Virtual PMC
-        #[cfg(any(target_os = "android", target_os = "linux"))]
         if let Some(guest_suspended_cvar) = guest_suspended_cvar {
             let alloc = resources.get_anon_alloc();
             let mmio_base = resources
@@ -2042,7 +2037,7 @@ impl X8664arch {
 
         let mut pmresource = devices::ACPIPMResource::new(
             pm_sci_evt.try_clone().map_err(Error::CloneEvent)?,
-            suspend_evt,
+            suspend_tube,
             vm_evt_wrtube,
             acdc,
         );
@@ -2360,13 +2355,17 @@ mod tests {
     fn setup() {
         let pcie_ecam = Some(AddressRange::from_start_and_size(3 * GB, 256 * MB).unwrap());
         let pci_start = Some(2 * GB);
-        init_low_memory_layout(pcie_ecam, pci_start);
+        init_low_memory_layout(pcie_ecam, pci_start, false).expect("init_low_memory_layout");
     }
 
     #[test]
     fn regions_lt_4gb_nobios() {
         setup();
-        let regions = arch_memory_regions(512 * MB, /* bios_size */ None);
+        let regions = arch_memory_regions(
+            512 * MB,
+            /* bios_size */ None,
+            /* has_protected_vm_firmware */ false,
+        );
         assert_eq!(1, regions.len());
         assert_eq!(GuestAddress(START_OF_RAM_32BITS), regions[0].0);
         assert_eq!(1u64 << 29, regions[0].1);
@@ -2376,7 +2375,9 @@ mod tests {
     fn regions_gt_4gb_nobios() {
         setup();
         let size = 4 * GB + 0x8000;
-        let regions = arch_memory_regions(size, /* bios_size */ None);
+        let regions = arch_memory_regions(
+            size, /* bios_size */ None, /* has_protected_vm_firmware */ false,
+        );
         assert_eq!(2, regions.len());
         assert_eq!(GuestAddress(START_OF_RAM_32BITS), regions[0].0);
         assert_eq!(GuestAddress(4 * GB), regions[1].0);
@@ -2387,7 +2388,11 @@ mod tests {
     fn regions_lt_4gb_bios() {
         setup();
         let bios_len = 1 * MB;
-        let regions = arch_memory_regions(512 * MB, Some(bios_len));
+        let regions = arch_memory_regions(
+            512 * MB,
+            Some(bios_len),
+            /* has_protected_vm_firmware */ false,
+        );
         assert_eq!(2, regions.len());
         assert_eq!(GuestAddress(START_OF_RAM_32BITS), regions[0].0);
         assert_eq!(512 * MB, regions[0].1);
@@ -2402,7 +2407,11 @@ mod tests {
     fn regions_gt_4gb_bios() {
         setup();
         let bios_len = 1 * MB;
-        let regions = arch_memory_regions(4 * GB + 0x8000, Some(bios_len));
+        let regions = arch_memory_regions(
+            4 * GB + 0x8000,
+            Some(bios_len),
+            /* has_protected_vm_firmware */ false,
+        );
         assert_eq!(3, regions.len());
         assert_eq!(GuestAddress(START_OF_RAM_32BITS), regions[0].0);
         assert_eq!(
@@ -2420,6 +2429,7 @@ mod tests {
         let regions = arch_memory_regions(
             TEST_MEMORY_SIZE - START_OF_RAM_32BITS,
             /* bios_size */ None,
+            /* has_protected_vm_firmware */ false,
         );
         dbg!(&regions);
         assert_eq!(1, regions.len());
@@ -2432,7 +2442,11 @@ mod tests {
         setup();
         // Test with exact size of 4GB - the overhead.
         let bios_len = 1 * MB;
-        let regions = arch_memory_regions(TEST_MEMORY_SIZE - START_OF_RAM_32BITS, Some(bios_len));
+        let regions = arch_memory_regions(
+            TEST_MEMORY_SIZE - START_OF_RAM_32BITS,
+            Some(bios_len),
+            /* has_protected_vm_firmware */ false,
+        );
         assert_eq!(2, regions.len());
         assert_eq!(GuestAddress(START_OF_RAM_32BITS), regions[0].0);
         assert_eq!(TEST_MEMORY_SIZE - START_OF_RAM_32BITS, regions[0].1);
@@ -2535,4 +2549,42 @@ mod tests {
             entry2_data
         );
     }
+
+    #[test]
+    fn cmdline_overflow() {
+        const MEM_SIZE: u64 = 0x1000;
+        let gm = GuestMemory::new(&[(GuestAddress(0x0), MEM_SIZE)]).unwrap();
+        let mut cmdline = kernel_cmdline::Cmdline::new();
+        cmdline.insert_str("12345").unwrap();
+        let cmdline_address = GuestAddress(MEM_SIZE - 5);
+        let err =
+            X8664arch::load_cmdline(&gm, cmdline_address, cmdline, CMDLINE_MAX_SIZE as usize - 1)
+                .unwrap_err();
+        assert!(matches!(err, Error::CommandLineOverflow));
+    }
+
+    #[test]
+    fn cmdline_write_end() {
+        const MEM_SIZE: u64 = 0x1000;
+        let gm = GuestMemory::new(&[(GuestAddress(0x0), MEM_SIZE)]).unwrap();
+        let mut cmdline = kernel_cmdline::Cmdline::new();
+        cmdline.insert_str("1234").unwrap();
+        let mut cmdline_address = GuestAddress(45);
+        X8664arch::load_cmdline(&gm, cmdline_address, cmdline, CMDLINE_MAX_SIZE as usize - 1)
+            .unwrap();
+        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
+        assert_eq!(val, b'1');
+        cmdline_address = cmdline_address.unchecked_add(1);
+        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
+        assert_eq!(val, b'2');
+        cmdline_address = cmdline_address.unchecked_add(1);
+        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
+        assert_eq!(val, b'3');
+        cmdline_address = cmdline_address.unchecked_add(1);
+        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
+        assert_eq!(val, b'4');
+        cmdline_address = cmdline_address.unchecked_add(1);
+        let val: u8 = gm.read_obj_from_addr(cmdline_address).unwrap();
+        assert_eq!(val, b'\0');
+    }
 }
diff --git a/x86_64/src/mpspec.rs b/x86_64/src/mpspec.rs
index 7a59e4569..bc121bfe4 100644
--- a/x86_64/src/mpspec.rs
+++ b/x86_64/src/mpspec.rs
@@ -51,7 +51,7 @@ pub const MPC_OEM_SIGNATURE: &'static [u8; 5usize] = b"_OEM\x00";
 #[repr(C)]
 #[derive(Debug, Default, Copy, FromZeroes, FromBytes, AsBytes)]
 pub struct mpf_intel {
-    pub signature: [::std::os::raw::c_char; 4usize],
+    pub signature: [::std::os::raw::c_uchar; 4usize],
     pub physptr: ::std::os::raw::c_uint,
     pub length: ::std::os::raw::c_uchar,
     pub specification: ::std::os::raw::c_uchar,
@@ -193,12 +193,12 @@ impl Clone for mpf_intel {
 #[repr(C)]
 #[derive(Debug, Default, Copy, FromZeroes, FromBytes, AsBytes)]
 pub struct mpc_table {
-    pub signature: [::std::os::raw::c_char; 4usize],
+    pub signature: [::std::os::raw::c_uchar; 4usize],
     pub length: ::std::os::raw::c_ushort,
     pub spec: ::std::os::raw::c_char,
     pub checksum: ::std::os::raw::c_char,
-    pub oem: [::std::os::raw::c_char; 8usize],
-    pub productid: [::std::os::raw::c_char; 12usize],
+    pub oem: [::std::os::raw::c_uchar; 8usize],
+    pub productid: [::std::os::raw::c_uchar; 12usize],
     pub oemptr: ::std::os::raw::c_uint,
     pub oemsize: ::std::os::raw::c_ushort,
     pub oemcount: ::std::os::raw::c_ushort,
diff --git a/x86_64/src/mptable.rs b/x86_64/src/mptable.rs
index ac6caf2f3..6b20b2f2b 100644
--- a/x86_64/src/mptable.rs
+++ b/x86_64/src/mptable.rs
@@ -8,7 +8,6 @@ use std::result;
 
 use devices::PciAddress;
 use devices::PciInterruptPin;
-use libc::c_char;
 use remain::sorted;
 use thiserror::Error;
 use vm_memory::GuestAddress;
@@ -54,19 +53,14 @@ pub enum Error {
 
 pub type Result<T> = result::Result<T, Error>;
 
-// Convenience macro for making arrays of diverse character types.
-macro_rules! char_array {
-    ($t:ty; $( $c:expr ),*) => ( [ $( $c as $t ),* ] )
-}
-
 // Most of these variables are sourced from the Intel MP Spec 1.4.
-const SMP_MAGIC_IDENT: [c_char; 4] = char_array!(c_char; '_', 'M', 'P', '_');
-const MPC_SIGNATURE: [c_char; 4] = char_array!(c_char; 'P', 'C', 'M', 'P');
+const SMP_MAGIC_IDENT: [u8; 4] = *b"_MP_";
+const MPC_SIGNATURE: [u8; 4] = *b"PCMP";
 const MPC_SPEC: i8 = 4;
-const MPC_OEM: [c_char; 8] = char_array!(c_char; 'C', 'R', 'O', 'S', 'V', 'M', ' ', ' ');
-const MPC_PRODUCT_ID: [c_char; 12] = ['0' as c_char; 12];
-const BUS_TYPE_ISA: [u8; 6] = char_array!(u8; 'I', 'S', 'A', ' ', ' ', ' ');
-const BUS_TYPE_PCI: [u8; 6] = char_array!(u8; 'P', 'C', 'I', ' ', ' ', ' ');
+const MPC_OEM: [u8; 8] = *b"CROSVM  ";
+const MPC_PRODUCT_ID: [u8; 12] = *b"000000000000";
+const BUS_TYPE_ISA: [u8; 6] = *b"ISA   ";
+const BUS_TYPE_PCI: [u8; 6] = *b"PCI   ";
 // source: linux/arch/x86/include/asm/apicdef.h
 pub const IO_APIC_DEFAULT_PHYS_BASE: u32 = 0xfec00000;
 // source: linux/arch/x86/include/asm/apicdef.h
diff --git a/x86_64/src/regs.rs b/x86_64/src/regs.rs
index cbdd189ec..bb7c1b563 100644
--- a/x86_64/src/regs.rs
+++ b/x86_64/src/regs.rs
@@ -251,27 +251,85 @@ pub fn configure_segments_and_sregs(mem: &GuestMemory, sregs: &mut Sregs) -> Res
     Ok(())
 }
 
+/// Configures the GDT, IDT, and segment registers for 32-bit protected mode with paging disabled.
+pub fn configure_segments_and_sregs_flat32(mem: &GuestMemory, sregs: &mut Sregs) -> Result<()> {
+    // reference: https://docs.kernel.org/arch/x86/boot.html?highlight=__BOOT_CS#id1
+    let gdt_table: [u64; BOOT_GDT_MAX] = [
+        gdt::gdt_entry(0, 0, 0),            // NULL
+        gdt::gdt_entry(0, 0, 0),            // NULL
+        gdt::gdt_entry(0xc09b, 0, 0xfffff), // CODE
+        gdt::gdt_entry(0xc093, 0, 0xfffff), // DATA
+        gdt::gdt_entry(0x808b, 0, 0xfffff), // TSS
+    ];
+
+    let code_seg = gdt::segment_from_gdt(gdt_table[2], 2);
+    let data_seg = gdt::segment_from_gdt(gdt_table[3], 3);
+    let tss_seg = gdt::segment_from_gdt(gdt_table[4], 4);
+
+    // Write segments
+    write_gdt_table(&gdt_table[..], mem)?;
+    sregs.gdt.base = BOOT_GDT_OFFSET;
+    sregs.gdt.limit = mem::size_of_val(&gdt_table) as u16 - 1;
+
+    write_idt_value(0, mem)?;
+    sregs.idt.base = BOOT_IDT_OFFSET;
+    sregs.idt.limit = mem::size_of::<u64>() as u16 - 1;
+
+    sregs.cs = code_seg;
+    sregs.ds = data_seg;
+    sregs.es = data_seg;
+    sregs.fs = data_seg;
+    sregs.gs = data_seg;
+    sregs.ss = data_seg;
+    sregs.tr = tss_seg;
+
+    /* 32-bit protected mode with paging disabled */
+    sregs.cr0 |= X86_CR0_PE;
+    sregs.cr0 &= !X86_CR0_PG;
+
+    Ok(())
+}
+
 /// Configures the system page tables and control registers for long mode with paging.
+/// Prepares identity mapping for the low 4GB memory.
 pub fn setup_page_tables(mem: &GuestMemory, sregs: &mut Sregs) -> Result<()> {
     // Puts PML4 right after zero page but aligned to 4k.
     let boot_pml4_addr = GuestAddress(0x9000);
     let boot_pdpte_addr = GuestAddress(0xa000);
     let boot_pde_addr = GuestAddress(0xb000);
 
-    // Entry covering VA [0..512GB)
-    mem.write_obj_at_addr(boot_pdpte_addr.offset() | 0x03, boot_pml4_addr)
-        .map_err(|_| Error::WritePML4Address)?;
+    const PDE_FLAGS_TABLE_REFERENCE: u64 = 0x03; // Present | Read/Write
+    const PDE_FLAGS_PAGE_MAPPING: u64 = 0x83; // Present | Read/Write | Page Size
 
-    // Entry covering VA [0..1GB)
-    mem.write_obj_at_addr(boot_pde_addr.offset() | 0x03, boot_pdpte_addr)
+    // Entry covering VA [0..512GB)
+    mem.write_obj_at_addr(
+        boot_pdpte_addr.offset() | PDE_FLAGS_TABLE_REFERENCE,
+        boot_pml4_addr,
+    )
+    .map_err(|_| Error::WritePML4Address)?;
+
+    // Identity mapping for VA [0..4GB)
+    for i in 0..4 {
+        let pde_addr = boot_pde_addr.unchecked_add(i * 0x1000);
+
+        // Entry covering a single 1GB VA area
+        mem.write_obj_at_addr(
+            pde_addr.offset() | PDE_FLAGS_TABLE_REFERENCE,
+            boot_pdpte_addr.unchecked_add(i * 8),
+        )
         .map_err(|_| Error::WritePDPTEAddress)?;
 
-    // 512 2MB entries together covering VA [0..1GB). Note we are assuming
-    // CPU supports 2MB pages (/proc/cpuinfo has 'pse'). All modern CPUs do.
-    for i in 0..512 {
-        mem.write_obj_at_addr((i << 21) + 0x83u64, boot_pde_addr.unchecked_add(i * 8))
+        // 512 2MB entries together covering a single 1GB VA area. Note we are assuming
+        // CPU supports 2MB pages (/proc/cpuinfo has 'pse'). All modern CPUs do.
+        for j in 0..512 {
+            mem.write_obj_at_addr(
+                (i << 30) | (j << 21) | PDE_FLAGS_PAGE_MAPPING,
+                pde_addr.unchecked_add(j * 8),
+            )
             .map_err(|_| Error::WritePDEAddress)?;
+        }
     }
+
     sregs.cr3 = boot_pml4_addr.offset();
     sregs.cr4 |= X86_CR4_PAE;
     sregs.cr0 |= X86_CR0_PG;
@@ -308,7 +366,7 @@ mod tests {
         assert_eq!(0x0, read_u64(&gm, BOOT_IDT_OFFSET));
 
         assert_eq!(0, sregs.cs.base);
-        assert_eq!(0xfffff, sregs.ds.limit);
+        assert_eq!(0xffffffff, sregs.ds.limit_bytes);
         assert_eq!(0x10, sregs.cs.selector);
         assert_eq!(0x18, sregs.ds.selector);
         assert_eq!(0x18, sregs.es.selector);
@@ -317,7 +375,7 @@ mod tests {
         assert_eq!(1, sregs.gs.g);
         assert_eq!(0, sregs.ss.avl);
         assert_eq!(0, sregs.tr.base);
-        assert_eq!(0xfffff, sregs.tr.limit);
+        assert_eq!(0xffffffff, sregs.tr.limit_bytes);
         assert_eq!(0, sregs.tr.avl);
         assert_eq!(X86_CR0_PE, sregs.cr0 & X86_CR0_PE);
         assert_eq!(EFER_LME, sregs.efer);
diff --git a/x86_64/tests/integration/main.rs b/x86_64/tests/integration/main.rs
deleted file mode 100644
index 9c617b27f..000000000
--- a/x86_64/tests/integration/main.rs
+++ /dev/null
@@ -1,363 +0,0 @@
-// Copyright 2022 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// These tests are only implemented for kvm & gvm. Other hypervisors may be added in the future.
-#![cfg(all(any(feature = "gvm", unix), target_arch = "x86_64"))]
-
-mod sys;
-
-use std::collections::BTreeMap;
-use std::ffi::CString;
-use std::sync::Arc;
-use std::thread;
-
-use arch::LinuxArch;
-use arch::SmbiosOptions;
-use base::Event;
-use base::Tube;
-use devices::Bus;
-use devices::BusType;
-use devices::IrqChipX86_64;
-use devices::PciConfigIo;
-use hypervisor::CpuConfigX86_64;
-use hypervisor::HypervisorX86_64;
-use hypervisor::IoOperation;
-use hypervisor::IoParams;
-use hypervisor::ProtectionType;
-use hypervisor::Regs;
-use hypervisor::VcpuExit;
-use hypervisor::VcpuX86_64;
-use hypervisor::VmCap;
-use hypervisor::VmX86_64;
-use resources::AddressRange;
-use resources::SystemAllocator;
-use sync::Mutex;
-use vm_memory::GuestAddress;
-use vm_memory::GuestMemory;
-use x86_64::acpi;
-use x86_64::arch_memory_regions;
-use x86_64::bootparam;
-use x86_64::cpuid::setup_cpuid;
-use x86_64::init_low_memory_layout;
-use x86_64::interrupts::set_lint;
-use x86_64::mptable;
-use x86_64::read_pci_mmio_before_32bit;
-use x86_64::read_pcie_cfg_mmio;
-use x86_64::regs::configure_segments_and_sregs;
-use x86_64::regs::set_long_mode_msrs;
-use x86_64::regs::set_mtrr_msrs;
-use x86_64::regs::setup_page_tables;
-use x86_64::smbios;
-use x86_64::X8664arch;
-use x86_64::BOOT_STACK_POINTER;
-use x86_64::KERNEL_64BIT_ENTRY_OFFSET;
-use x86_64::KERNEL_START_OFFSET;
-use x86_64::X86_64_SCI_IRQ;
-use x86_64::ZERO_PAGE_OFFSET;
-
-enum TaggedControlTube {
-    VmMemory(Tube),
-    VmIrq(Tube),
-    Vm(Tube),
-}
-
-/// Tests the integration of x86_64 with some hypervisor and devices setup. This test can help
-/// narrow down whether boot issues are caused by the interaction between hypervisor and devices
-/// and x86_64, or if they are caused by an invalid kernel or image. You can also swap in parts
-/// of this function to load a real kernel and/or ramdisk.
-fn simple_vm_test<H, V, Vcpu, I, FV, FI>(create_vm: FV, create_irq_chip: FI)
-where
-    H: HypervisorX86_64 + 'static,
-    V: VmX86_64 + 'static,
-    Vcpu: VcpuX86_64 + 'static,
-    I: IrqChipX86_64 + 'static,
-    FV: FnOnce(GuestMemory) -> (H, V),
-    FI: FnOnce(V, /* vcpu_count: */ usize, Tube) -> I,
-{
-    /*
-    0x0000000000000000:  67 89 18    mov dword ptr [eax], ebx
-    0x0000000000000003:  89 D9       mov ecx, ebx
-    0x0000000000000005:  89 C8       mov eax, ecx
-    0x0000000000000007:  E6 FF       out 0xff, al
-    */
-    let code = [0x67, 0x89, 0x18, 0x89, 0xd9, 0x89, 0xc8, 0xe6, 0xff];
-
-    // 2GB memory
-    let memory_size = 0x80000000u64;
-    let start_addr = GuestAddress(KERNEL_START_OFFSET + KERNEL_64BIT_ENTRY_OFFSET);
-
-    // write to 4th page
-    let write_addr = GuestAddress(0x4000);
-
-    init_low_memory_layout(
-        Some(AddressRange {
-            start: 0xC000_0000,
-            end: 0xCFFF_FFFF,
-        }),
-        Some(0x8000_0000),
-    );
-    // guest mem is 400 pages
-    let arch_mem_regions = arch_memory_regions(memory_size, None);
-    let guest_mem = GuestMemory::new_with_options(&arch_mem_regions).unwrap();
-
-    let (hyp, mut vm) = create_vm(guest_mem.clone());
-    let mut resources =
-        SystemAllocator::new(X8664arch::get_system_allocator_config(&vm), None, &[])
-            .expect("failed to create system allocator");
-    let (irqchip_tube, device_tube) = Tube::pair().expect("failed to create irq tube");
-
-    let mut irq_chip = create_irq_chip(vm.try_clone().expect("failed to clone vm"), 1, device_tube);
-
-    let mmio_bus = Arc::new(Bus::new(BusType::Mmio));
-    let io_bus = Arc::new(Bus::new(BusType::Io));
-    let (exit_evt_wrtube, _) = Tube::directional_pair().unwrap();
-
-    let mut control_tubes = vec![TaggedControlTube::VmIrq(irqchip_tube)];
-    // Create one control socket per disk.
-    let mut disk_device_tubes = Vec::new();
-    let mut disk_host_tubes = Vec::new();
-    let disk_count = 0;
-    for _ in 0..disk_count {
-        let (disk_host_tube, disk_device_tube) = Tube::pair().unwrap();
-        disk_host_tubes.push(disk_host_tube);
-        disk_device_tubes.push(disk_device_tube);
-    }
-    let (gpu_host_tube, _gpu_device_tube) = Tube::pair().unwrap();
-
-    control_tubes.push(TaggedControlTube::VmMemory(gpu_host_tube));
-
-    let devices = vec![];
-
-    let (pci, pci_irqs, _pid_debug_label_map, _amls, _gpe_scope_amls) = arch::generate_pci_root(
-        devices,
-        &mut irq_chip,
-        mmio_bus.clone(),
-        GuestAddress(0),
-        12,
-        io_bus.clone(),
-        &mut resources,
-        &mut vm,
-        4,
-        None,
-        #[cfg(feature = "swap")]
-        &mut None,
-    )
-    .unwrap();
-    let pci = Arc::new(Mutex::new(pci));
-    let (pcibus_exit_evt_wrtube, _) = Tube::directional_pair().unwrap();
-    let pci_bus = Arc::new(Mutex::new(PciConfigIo::new(
-        pci.clone(),
-        false,
-        pcibus_exit_evt_wrtube,
-    )));
-    io_bus.insert(pci_bus, 0xcf8, 0x8).unwrap();
-
-    X8664arch::setup_legacy_i8042_device(
-        &io_bus,
-        irq_chip.pit_uses_speaker_port(),
-        exit_evt_wrtube.try_clone().unwrap(),
-    )
-    .unwrap();
-
-    let (host_cmos_tube, cmos_tube) = Tube::pair().unwrap();
-    X8664arch::setup_legacy_cmos_device(&io_bus, &mut irq_chip, cmos_tube, memory_size).unwrap();
-    control_tubes.push(TaggedControlTube::Vm(host_cmos_tube));
-
-    let mut serial_params = BTreeMap::new();
-
-    arch::set_default_serial_parameters(&mut serial_params, false);
-
-    X8664arch::setup_serial_devices(
-        ProtectionType::Unprotected,
-        &mut irq_chip,
-        &io_bus,
-        &serial_params,
-        None,
-        #[cfg(feature = "swap")]
-        &mut None,
-    )
-    .unwrap();
-
-    let param_args = "nokaslr acpi=noirq";
-
-    let mut cmdline = X8664arch::get_base_linux_cmdline();
-
-    cmdline.insert_str(param_args).unwrap();
-
-    let params = bootparam::boot_params::default();
-    // write our custom kernel code to start_addr
-    guest_mem.write_at_addr(&code[..], start_addr).unwrap();
-    let kernel_end = KERNEL_START_OFFSET + code.len() as u64;
-    let initrd_image = None;
-
-    // alternatively, load a real initrd and kernel from disk
-    // ```
-    // let initrd_image = Some(File::open("/mnt/host/source/src/avd/ramdisk.img").expect("failed to open ramdisk"));
-    // let mut kernel_image = File::open("/mnt/host/source/src/avd/vmlinux.uncompressed").expect("failed to open kernel");
-    // let (params, kernel_end) = X8664arch::load_kernel(&guest_mem, &mut kernel_image).expect("failed to load kernel");
-    // ````
-
-    let max_bus = (read_pcie_cfg_mmio().len().unwrap() / 0x100000 - 1) as u8;
-    let suspend_evt = Event::new().unwrap();
-    let mut resume_notify_devices = Vec::new();
-    let acpi_dev_resource = X8664arch::setup_acpi_devices(
-        pci,
-        &guest_mem,
-        &io_bus,
-        &mut resources,
-        suspend_evt
-            .try_clone()
-            .expect("unable to clone suspend_evt"),
-        exit_evt_wrtube
-            .try_clone()
-            .expect("unable to clone exit_evt_wrtube"),
-        Default::default(),
-        &mut irq_chip,
-        X86_64_SCI_IRQ,
-        (None, None),
-        &mmio_bus,
-        max_bus,
-        &mut resume_notify_devices,
-        #[cfg(feature = "swap")]
-        &mut None,
-        #[cfg(any(target_os = "android", target_os = "linux"))]
-        false,
-        Default::default(),
-        &pci_irqs,
-    )
-    .unwrap();
-
-    X8664arch::setup_system_memory(
-        &guest_mem,
-        &CString::new(cmdline).expect("failed to create cmdline"),
-        initrd_image,
-        None,
-        kernel_end,
-        params,
-        None,
-        Vec::new(),
-    )
-    .expect("failed to setup system_memory");
-
-    // Note that this puts the mptable at 0x9FC00 in guest physical memory.
-    mptable::setup_mptable(&guest_mem, 1, &pci_irqs).expect("failed to setup mptable");
-    smbios::setup_smbios(&guest_mem, &SmbiosOptions::default(), 0).expect("failed to setup smbios");
-
-    let mut apic_ids = Vec::new();
-    acpi::create_acpi_tables(
-        &guest_mem,
-        1,
-        X86_64_SCI_IRQ,
-        0xcf9,
-        6,
-        &acpi_dev_resource.0,
-        None,
-        &mut apic_ids,
-        &pci_irqs,
-        read_pcie_cfg_mmio().start,
-        max_bus,
-        false,
-    );
-
-    let guest_mem2 = guest_mem.clone();
-
-    let handle = thread::Builder::new()
-        .name("crosvm_simple_vm_vcpu".to_string())
-        .spawn(move || {
-            let mut vcpu = *vm
-                .create_vcpu(0)
-                .expect("failed to create vcpu")
-                .downcast::<Vcpu>()
-                .map_err(|_| ())
-                .expect("failed to downcast vcpu");
-
-            irq_chip
-                .add_vcpu(0, &vcpu)
-                .expect("failed to add vcpu to irqchip");
-
-            let cpu_config = CpuConfigX86_64::new(false, false, false, false, false, None);
-            if !vm.check_capability(VmCap::EarlyInitCpuid) {
-                setup_cpuid(&hyp, &irq_chip, &vcpu, 0, 1, cpu_config).unwrap();
-            }
-
-            let mut msrs = BTreeMap::new();
-            set_long_mode_msrs(&mut msrs);
-            set_mtrr_msrs(&mut msrs, &vm, read_pci_mmio_before_32bit().start);
-            for (msr_index, value) in msrs {
-                vcpu.set_msr(msr_index, value).unwrap();
-            }
-
-            let mut vcpu_regs = Regs {
-                rip: start_addr.offset(),
-                rsp: BOOT_STACK_POINTER,
-                rsi: ZERO_PAGE_OFFSET,
-                ..Default::default()
-            };
-
-            // instruction is
-            // mov [eax],ebx
-            // so we're writing 0x12 (the contents of ebx) to the address
-            // in eax (write_addr).
-            vcpu_regs.rax = write_addr.offset();
-            vcpu_regs.rbx = 0x12;
-            // ecx will contain 0, but after the second instruction it will
-            // also contain 0x12
-            vcpu_regs.rcx = 0x0;
-            vcpu.set_regs(&vcpu_regs).expect("set regs failed");
-
-            let vcpu_fpu_regs = Default::default();
-            vcpu.set_fpu(&vcpu_fpu_regs).expect("set fpu regs failed");
-
-            let mut sregs = vcpu.get_sregs().expect("get sregs failed");
-            configure_segments_and_sregs(&guest_mem, &mut sregs).unwrap();
-            setup_page_tables(&guest_mem, &mut sregs).unwrap();
-            vcpu.set_sregs(&sregs).expect("set sregs failed");
-
-            set_lint(0, &mut irq_chip).unwrap();
-
-            loop {
-                match vcpu.run().expect("run failed") {
-                    VcpuExit::Io => {
-                        vcpu.handle_io(&mut |IoParams {
-                                                 address,
-                                                 size,
-                                                 operation: direction,
-                                             }| {
-                            match direction {
-                                IoOperation::Write { data } => {
-                                    // We consider this test to be done when this particular
-                                    // one-byte port-io to port 0xff with the value of 0x12, which
-                                    // was in register eax
-                                    assert_eq!(address, 0xff);
-                                    assert_eq!(size, 1);
-                                    assert_eq!(data[0], 0x12);
-                                }
-                                _ => panic!("unexpected direction {:?}", direction),
-                            }
-                            None
-                        })
-                        .expect("vcpu.handle_io failed");
-                        break;
-                    }
-                    r => {
-                        panic!("unexpected exit {:?}", r);
-                    }
-                }
-            }
-            let regs = vcpu.get_regs().unwrap();
-            // ecx and eax should now contain 0x12
-            assert_eq!(regs.rcx, 0x12);
-            assert_eq!(regs.rax, 0x12);
-        })
-        .unwrap();
-
-    if let Err(e) = handle.join() {
-        panic!("failed to join vcpu thread: {:?}", e);
-    }
-
-    assert_eq!(
-        guest_mem2.read_obj_from_addr::<u64>(write_addr).unwrap(),
-        0x12
-    );
-}
diff --git a/x86_64/tests/integration/sys/linux.rs b/x86_64/tests/integration/sys/linux.rs
deleted file mode 100644
index cd011a6e8..000000000
--- a/x86_64/tests/integration/sys/linux.rs
+++ /dev/null
@@ -1,58 +0,0 @@
-// Copyright 2022 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// TODO(b/210705746): See if we can bring in the changes compiled out from go/playcl/50499
-use crate::simple_vm_test;
-
-#[test]
-fn simple_kvm_test() {
-    use devices::KvmKernelIrqChip;
-    use hypervisor::kvm::*;
-    simple_vm_test::<_, _, KvmVcpu, _, _, _>(
-        |guest_mem| {
-            let kvm = Kvm::new().expect("failed to create kvm");
-            let vm =
-                KvmVm::new(&kvm, guest_mem, Default::default()).expect("failed to create kvm vm");
-            (kvm, vm)
-        },
-        |vm, vcpu_count, _| {
-            KvmKernelIrqChip::new(vm, vcpu_count).expect("failed to create KvmKernelIrqChip")
-        },
-    );
-}
-
-#[test]
-fn simple_kvm_kernel_irqchip_test() {
-    use devices::KvmKernelIrqChip;
-    use hypervisor::kvm::*;
-    simple_vm_test::<_, _, KvmVcpu, _, _, _>(
-        |guest_mem| {
-            let kvm = Kvm::new().expect("failed to create kvm");
-            let vm =
-                KvmVm::new(&kvm, guest_mem, Default::default()).expect("failed to create kvm vm");
-            (kvm, vm)
-        },
-        |vm, vcpu_count, _| {
-            KvmKernelIrqChip::new(vm, vcpu_count).expect("failed to create KvmKernelIrqChip")
-        },
-    );
-}
-
-#[test]
-fn simple_kvm_split_irqchip_test() {
-    use devices::KvmSplitIrqChip;
-    use hypervisor::kvm::*;
-    simple_vm_test::<_, _, KvmVcpu, _, _, _>(
-        |guest_mem| {
-            let kvm = Kvm::new().expect("failed to create kvm");
-            let vm =
-                KvmVm::new(&kvm, guest_mem, Default::default()).expect("failed to create kvm vm");
-            (kvm, vm)
-        },
-        |vm, vcpu_count, device_tube| {
-            KvmSplitIrqChip::new(vm, vcpu_count, device_tube, None)
-                .expect("failed to create KvmSplitIrqChip")
-        },
-    );
-}
diff --git a/x86_64/tests/linux.rs b/x86_64/tests/linux.rs
deleted file mode 100644
index 79cfe96a3..000000000
--- a/x86_64/tests/linux.rs
+++ /dev/null
@@ -1,80 +0,0 @@
-// Copyright 2022 The ChromiumOS Authors
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#![cfg(all(unix, target_arch = "x86_64"))]
-
-use std::arch::x86_64::CpuidResult;
-use std::arch::x86_64::__cpuid;
-use std::arch::x86_64::__cpuid_count;
-
-use hypervisor::CpuConfigX86_64;
-use x86_64::cpuid::filter_cpuid;
-use x86_64::cpuid::EBX_CLFLUSH_CACHELINE;
-use x86_64::cpuid::EBX_CLFLUSH_SIZE_SHIFT;
-use x86_64::cpuid::EBX_CPUID_SHIFT;
-use x86_64::cpuid::EBX_CPU_COUNT_SHIFT;
-use x86_64::cpuid::ECX_HYPERVISOR_SHIFT;
-use x86_64::cpuid::EDX_HTT_SHIFT;
-use x86_64::CpuIdContext;
-
-#[test]
-fn feature_and_vendor_name() {
-    let mut cpuid = hypervisor::CpuId::new(2);
-    let guest_mem = vm_memory::GuestMemory::new(&[(vm_memory::GuestAddress(0), 0x10000)]).unwrap();
-    let kvm = hypervisor::kvm::Kvm::new().unwrap();
-    let vm = hypervisor::kvm::KvmVm::new(&kvm, guest_mem, Default::default()).unwrap();
-    let irq_chip = devices::KvmKernelIrqChip::new(vm, 1).unwrap();
-
-    let entries = &mut cpuid.cpu_id_entries;
-    entries.push(hypervisor::CpuIdEntry {
-        function: 0,
-        index: 0,
-        flags: 0,
-        cpuid: CpuidResult {
-            eax: 0,
-            ebx: 0,
-            ecx: 0,
-            edx: 0,
-        },
-    });
-    entries.push(hypervisor::CpuIdEntry {
-        function: 1,
-        index: 0,
-        flags: 0,
-        cpuid: CpuidResult {
-            eax: 0,
-            ebx: 0,
-            ecx: 0x10,
-            edx: 0,
-        },
-    });
-
-    let cpu_config = CpuConfigX86_64::new(false, false, false, false, false, None);
-    filter_cpuid(
-        &mut cpuid,
-        &CpuIdContext::new(
-            1,
-            2,
-            Some(&irq_chip),
-            cpu_config,
-            false,
-            __cpuid_count,
-            __cpuid,
-        ),
-    );
-
-    let entries = &mut cpuid.cpu_id_entries;
-    assert_eq!(entries[0].function, 0);
-    assert_eq!(1, (entries[1].cpuid.ebx >> EBX_CPUID_SHIFT) & 0x000000ff);
-    assert_eq!(
-        2,
-        (entries[1].cpuid.ebx >> EBX_CPU_COUNT_SHIFT) & 0x000000ff
-    );
-    assert_eq!(
-        EBX_CLFLUSH_CACHELINE,
-        (entries[1].cpuid.ebx >> EBX_CLFLUSH_SIZE_SHIFT) & 0x000000ff
-    );
-    assert_ne!(0, entries[1].cpuid.ecx & (1 << ECX_HYPERVISOR_SHIFT));
-    assert_ne!(0, entries[1].cpuid.edx & (1 << EDX_HTT_SHIFT));
-}
```

