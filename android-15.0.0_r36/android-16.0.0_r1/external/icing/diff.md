```diff
diff --git a/Android.bp b/Android.bp
index d6d3397..84e8c62 100644
--- a/Android.bp
+++ b/Android.bp
@@ -60,6 +60,62 @@ cc_defaults {
     apex_available: ["com.android.appsearch"],
 }
 
+cc_library_shared {
+    name: "libisolated_storage_service",
+    srcs: ["isolated_storage_service/payload/*.cc"],
+    shared_libs: [
+        "libbinder_ndk",
+        "libvm_payload#current",
+        "libprotobuf-cpp-lite",
+        "liblog",
+        "libicu",
+        "libbase",
+    ],
+    static_libs: [
+        "libicing.microdroid",
+        "icing-c-proto",
+        "libutf",
+        "libz",
+        "com.android.isolated_storage_service.aidl-ndk",
+    ],
+    min_sdk_version: "Tiramisu",
+    apex_available: ["com.android.appsearch"],
+}
+
+// Microdroid version of Icing has statically linked libz.
+cc_library_static {
+    name: "libicing.microdroid",
+    defaults: ["libicing_defaults"],
+    srcs: [
+        "icing/**/*.cc",
+    ],
+    exclude_srcs: [
+        "icing/**/*-test-*",
+        "icing/**/*-test.*",
+        "icing/**/*_test.cc",
+        "icing/**/*_benchmark.cc",
+        "icing/testing/**/*",
+        "icing/tokenization/reverse_jni/**/*",
+        "icing/tokenization/simple/**/*",
+        "icing/tools/**/*",
+        "icing/transform/map/**/*",
+        "icing/transform/simple/**/*",
+    ],
+    header_libs: ["jni_headers"],
+    static_libs: [
+        "icing-c-proto",
+        "libutf",
+        "libz",
+    ],
+    shared_libs: [
+        "libicu",
+        "liblog",
+        "libprotobuf-cpp-lite",
+    ],
+    version_script: "icing/jni.lds",
+    min_sdk_version: "Tiramisu",
+}
+
 // TODO(b/193244409): Use the filegroup libicing_test_common along with
 //                    libicing_defaults to build libicing.
 cc_library_shared {
@@ -151,6 +207,7 @@ cc_test {
         "libprotobuf-cpp-lite",
         "libz",
     ],
+    apex_available: ["//apex_available:platform"],
 }
 
 // TODO(cassiewang): Add build rules and a TEST_MAPPING for cc_tests
diff --git a/OWNERS b/OWNERS
index 93c8e30..b3f15f8 100644
--- a/OWNERS
+++ b/OWNERS
@@ -1,2 +1,3 @@
 adorokhine@google.com
 tjbarron@google.com
+include platform/system/core:/janitors/OWNERS #{LAST_RESORT_SUGGESTION}
diff --git a/build.gradle b/build.gradle
index 38ae38d..93b60c1 100644
--- a/build.gradle
+++ b/build.gradle
@@ -41,6 +41,7 @@ sourceSets {
 dependencies {
     compileOnly("androidx.annotation:annotation:1.1.0")
     compileOnly(SdkHelperKt.getSdkDependency(project))
+    compileOnly(libs.jspecify)
     compileOnly(libs.protobufLite)
 }
 
@@ -55,4 +56,6 @@ afterEvaluate {
 
 androidx {
     mavenVersion = LibraryVersions.APPSEARCH
+    // JSpecify lint is disabled since icing is developed externally
+    optOutJSpecify = true
 }
diff --git a/icing/absl_ports/canonical_errors.cc b/icing/absl_ports/canonical_errors.cc
index b7167d1..bf8b1f5 100644
--- a/icing/absl_ports/canonical_errors.cc
+++ b/icing/absl_ports/canonical_errors.cc
@@ -14,106 +14,188 @@
 
 #include "icing/absl_ports/canonical_errors.h"
 
+#include <string>
+#include <utility>
+
 #include "icing/text_classifier/lib3/utils/base/status.h"
 
 namespace icing {
 namespace lib {
 namespace absl_ports {
 
-libtextclassifier3::Status CancelledError(std::string_view error_message) {
+libtextclassifier3::Status CancelledError(const char* error_message) {
   return libtextclassifier3::Status(libtextclassifier3::StatusCode::CANCELLED,
                                     std::string(error_message));
 }
 
-libtextclassifier3::Status UnknownError(std::string_view error_message) {
+libtextclassifier3::Status UnknownError(const char* error_message) {
   return libtextclassifier3::Status(libtextclassifier3::StatusCode::UNKNOWN,
                                     std::string(error_message));
 }
 
-libtextclassifier3::Status InvalidArgumentError(
-    std::string_view error_message) {
+libtextclassifier3::Status InvalidArgumentError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::INVALID_ARGUMENT,
       std::string(error_message));
 }
 
-libtextclassifier3::Status DeadlineExceededError(
-    std::string_view error_message) {
+libtextclassifier3::Status DeadlineExceededError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::DEADLINE_EXCEEDED,
       std::string(error_message));
 }
 
-libtextclassifier3::Status NotFoundError(std::string_view error_message) {
+libtextclassifier3::Status NotFoundError(const char* error_message) {
   return libtextclassifier3::Status(libtextclassifier3::StatusCode::NOT_FOUND,
                                     std::string(error_message));
 }
 
-libtextclassifier3::Status AlreadyExistsError(std::string_view error_message) {
+libtextclassifier3::Status AlreadyExistsError(const char* error_message) {
   return libtextclassifier3::Status(
-      libtextclassifier3::StatusCode::ALREADY_EXISTS,
-      std::string(error_message));
+      libtextclassifier3::StatusCode::ALREADY_EXISTS, error_message);
 }
 
-libtextclassifier3::Status PermissionDeniedError(
-    std::string_view error_message) {
+libtextclassifier3::Status PermissionDeniedError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::PERMISSION_DENIED,
       std::string(error_message));
 }
 
-libtextclassifier3::Status ResourceExhaustedError(
-    std::string_view error_message) {
+libtextclassifier3::Status ResourceExhaustedError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED,
       std::string(error_message));
 }
 
-libtextclassifier3::Status FailedPreconditionError(
-    std::string_view error_message) {
+libtextclassifier3::Status FailedPreconditionError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::FAILED_PRECONDITION,
       std::string(error_message));
 }
 
-libtextclassifier3::Status AbortedError(std::string_view error_message) {
+libtextclassifier3::Status AbortedError(const char* error_message) {
   return libtextclassifier3::Status(libtextclassifier3::StatusCode::ABORTED,
                                     std::string(error_message));
 }
 
-libtextclassifier3::Status OutOfRangeError(std::string_view error_message) {
+libtextclassifier3::Status OutOfRangeError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::OUT_OF_RANGE, std::string(error_message));
 }
 
-libtextclassifier3::Status UnimplementedError(std::string_view error_message) {
+libtextclassifier3::Status UnimplementedError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::UNIMPLEMENTED,
       std::string(error_message));
 }
 
-libtextclassifier3::Status InternalError(std::string_view error_message) {
+libtextclassifier3::Status InternalError(const char* error_message) {
   return libtextclassifier3::Status(libtextclassifier3::StatusCode::INTERNAL,
                                     std::string(error_message));
 }
 
-libtextclassifier3::Status UnavailableError(std::string_view error_message) {
+libtextclassifier3::Status UnavailableError(const char* error_message) {
   return libtextclassifier3::Status(libtextclassifier3::StatusCode::UNAVAILABLE,
                                     std::string(error_message));
 }
 
-libtextclassifier3::Status DataLossError(std::string_view error_message) {
+libtextclassifier3::Status DataLossError(const char* error_message) {
   return libtextclassifier3::Status(libtextclassifier3::StatusCode::DATA_LOSS,
                                     std::string(error_message));
 }
 
-libtextclassifier3::Status UnauthenticatedError(
-    std::string_view error_message) {
+libtextclassifier3::Status UnauthenticatedError(const char* error_message) {
   return libtextclassifier3::Status(
       libtextclassifier3::StatusCode::UNAUTHENTICATED,
       std::string(error_message));
 }
 
+libtextclassifier3::Status CancelledError(std::string error_message) {
+  return libtextclassifier3::Status(libtextclassifier3::StatusCode::CANCELLED,
+                                    std::move(error_message));
+}
+
+libtextclassifier3::Status UnknownError(std::string error_message) {
+  return libtextclassifier3::Status(libtextclassifier3::StatusCode::UNKNOWN,
+                                    std::move(error_message));
+}
+
+libtextclassifier3::Status InvalidArgumentError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+      std::move(error_message));
+}
+
+libtextclassifier3::Status DeadlineExceededError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::DEADLINE_EXCEEDED,
+      std::move(error_message));
+}
+
+libtextclassifier3::Status NotFoundError(std::string error_message) {
+  return libtextclassifier3::Status(libtextclassifier3::StatusCode::NOT_FOUND,
+                                    std::move(error_message));
+}
+
+libtextclassifier3::Status AlreadyExistsError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::ALREADY_EXISTS, std::move(error_message));
+}
+
+libtextclassifier3::Status PermissionDeniedError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::PERMISSION_DENIED,
+      std::move(error_message));
+}
+
+libtextclassifier3::Status ResourceExhaustedError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED,
+      std::move(error_message));
+}
+
+libtextclassifier3::Status FailedPreconditionError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::FAILED_PRECONDITION,
+      std::move(error_message));
+}
+
+libtextclassifier3::Status AbortedError(std::string error_message) {
+  return libtextclassifier3::Status(libtextclassifier3::StatusCode::ABORTED,
+                                    std::move(error_message));
+}
+
+libtextclassifier3::Status OutOfRangeError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::OUT_OF_RANGE, std::move(error_message));
+}
+
+libtextclassifier3::Status UnimplementedError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::UNIMPLEMENTED, std::move(error_message));
+}
+
+libtextclassifier3::Status InternalError(std::string error_message) {
+  return libtextclassifier3::Status(libtextclassifier3::StatusCode::INTERNAL,
+                                    std::move(error_message));
+}
+
+libtextclassifier3::Status UnavailableError(std::string error_message) {
+  return libtextclassifier3::Status(libtextclassifier3::StatusCode::UNAVAILABLE,
+                                    std::move(error_message));
+}
+
+libtextclassifier3::Status DataLossError(std::string error_message) {
+  return libtextclassifier3::Status(libtextclassifier3::StatusCode::DATA_LOSS,
+                                    std::move(error_message));
+}
+
+libtextclassifier3::Status UnauthenticatedError(std::string error_message) {
+  return libtextclassifier3::Status(
+      libtextclassifier3::StatusCode::UNAUTHENTICATED,
+      std::move(error_message));
+}
+
 bool IsCancelled(const libtextclassifier3::Status& status) {
   return status.CanonicalCode() == libtextclassifier3::StatusCode::CANCELLED;
 }
diff --git a/icing/absl_ports/canonical_errors.h b/icing/absl_ports/canonical_errors.h
index 1a997ed..55bdcea 100644
--- a/icing/absl_ports/canonical_errors.h
+++ b/icing/absl_ports/canonical_errors.h
@@ -15,7 +15,7 @@
 #ifndef ICING_ABSL_PORTS_CANONICAL_ERRORS_H_
 #define ICING_ABSL_PORTS_CANONICAL_ERRORS_H_
 
-#include <string_view>
+#include <string>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 
@@ -23,26 +23,54 @@ namespace icing {
 namespace lib {
 namespace absl_ports {
 
-libtextclassifier3::Status CancelledError(std::string_view error_message);
-libtextclassifier3::Status UnknownError(std::string_view error_message);
-libtextclassifier3::Status InvalidArgumentError(std::string_view error_message);
-libtextclassifier3::Status DeadlineExceededError(
-    std::string_view error_message);
-libtextclassifier3::Status NotFoundError(std::string_view error_message);
-libtextclassifier3::Status AlreadyExistsError(std::string_view error_message);
-libtextclassifier3::Status PermissionDeniedError(
-    std::string_view error_message);
-libtextclassifier3::Status ResourceExhaustedError(
-    std::string_view error_message);
-libtextclassifier3::Status FailedPreconditionError(
-    std::string_view error_message);
-libtextclassifier3::Status AbortedError(std::string_view error_message);
-libtextclassifier3::Status OutOfRangeError(std::string_view error_message);
-libtextclassifier3::Status UnimplementedError(std::string_view error_message);
-libtextclassifier3::Status InternalError(std::string_view error_message);
-libtextclassifier3::Status UnavailableError(std::string_view error_message);
-libtextclassifier3::Status DataLossError(std::string_view error_message);
-libtextclassifier3::Status UnauthenticatedError(std::string_view error_message);
+// Overload both const char* and std::string to support 2 different callers:
+// `FooError(StrCat("text", a_str, " and ", b_str));` and
+// `FooError("simple text");`
+//
+// - std::string is used for the first call to avoid additional copies (Note:
+//   if using std::string_view, then the caller cannot move the string).
+// - const char* is used for the second call.
+//   - If const char* is not overloaded, then it is still valid for the second
+//     call to use std::string.
+//   - However, in Android the compiler will implicitly compile some conversion
+//     code (from const char* to std::string) **on the caller side** and
+//     increase most of the classes' size by ~1 KB, and the size of libicing.so
+//     will be increased by ~100 KBs.
+//   - From the experiment, overloading both const char* and std::string can
+//     avoid this binary size increase.
+libtextclassifier3::Status CancelledError(const char* error_message);
+libtextclassifier3::Status UnknownError(const char* error_message);
+libtextclassifier3::Status InvalidArgumentError(const char* error_message);
+libtextclassifier3::Status DeadlineExceededError(const char* error_message);
+libtextclassifier3::Status NotFoundError(const char* error_message);
+libtextclassifier3::Status AlreadyExistsError(const char* error_message);
+libtextclassifier3::Status PermissionDeniedError(const char* error_message);
+libtextclassifier3::Status ResourceExhaustedError(const char* error_message);
+libtextclassifier3::Status FailedPreconditionError(const char* error_message);
+libtextclassifier3::Status AbortedError(const char* error_message);
+libtextclassifier3::Status OutOfRangeError(const char* error_message);
+libtextclassifier3::Status UnimplementedError(const char* error_message);
+libtextclassifier3::Status InternalError(const char* error_message);
+libtextclassifier3::Status UnavailableError(const char* error_message);
+libtextclassifier3::Status DataLossError(const char* error_message);
+libtextclassifier3::Status UnauthenticatedError(const char* error_message);
+
+libtextclassifier3::Status CancelledError(std::string error_message);
+libtextclassifier3::Status UnknownError(std::string error_message);
+libtextclassifier3::Status InvalidArgumentError(std::string error_message);
+libtextclassifier3::Status DeadlineExceededError(std::string error_message);
+libtextclassifier3::Status NotFoundError(std::string error_message);
+libtextclassifier3::Status AlreadyExistsError(std::string error_message);
+libtextclassifier3::Status PermissionDeniedError(std::string error_message);
+libtextclassifier3::Status ResourceExhaustedError(std::string error_message);
+libtextclassifier3::Status FailedPreconditionError(std::string error_message);
+libtextclassifier3::Status AbortedError(std::string error_message);
+libtextclassifier3::Status OutOfRangeError(std::string error_message);
+libtextclassifier3::Status UnimplementedError(std::string error_message);
+libtextclassifier3::Status InternalError(std::string error_message);
+libtextclassifier3::Status UnavailableError(std::string error_message);
+libtextclassifier3::Status DataLossError(std::string error_message);
+libtextclassifier3::Status UnauthenticatedError(std::string error_message);
 
 bool IsCancelled(const libtextclassifier3::Status& status);
 bool IsUnknown(const libtextclassifier3::Status& status);
diff --git a/icing/feature-flags.h b/icing/feature-flags.h
index 63482f9..0231fe5 100644
--- a/icing/feature-flags.h
+++ b/icing/feature-flags.h
@@ -20,12 +20,25 @@ namespace lib {
 
 class FeatureFlags {
  public:
-  explicit FeatureFlags(bool enable_scorable_properties,
+  explicit FeatureFlags(bool allow_circular_schema_definitions,
+                        bool enable_scorable_properties,
                         bool enable_embedding_quantization,
-                        bool enable_repeated_field_joins)
-      : enable_scorable_properties_(enable_scorable_properties),
+                        bool enable_repeated_field_joins,
+                        bool enable_embedding_backup_generation,
+                        bool enable_schema_database,
+                        bool release_backup_schema_file_if_overlay_present)
+      : allow_circular_schema_definitions_(allow_circular_schema_definitions),
+        enable_scorable_properties_(enable_scorable_properties),
         enable_embedding_quantization_(enable_embedding_quantization),
-        enable_repeated_field_joins_(enable_repeated_field_joins) {}
+        enable_repeated_field_joins_(enable_repeated_field_joins),
+        enable_embedding_backup_generation_(enable_embedding_backup_generation),
+        enable_schema_database_(enable_schema_database),
+        release_backup_schema_file_if_overlay_present_(
+            release_backup_schema_file_if_overlay_present) {}
+
+  bool allow_circular_schema_definitions() const {
+    return allow_circular_schema_definitions_;
+  }
 
   bool enable_scorable_properties() const {
     return enable_scorable_properties_;
@@ -39,7 +52,21 @@ class FeatureFlags {
     return enable_repeated_field_joins_;
   }
 
+  bool enable_embedding_backup_generation() const {
+    return enable_embedding_backup_generation_;
+  }
+
+  bool enable_schema_database() const { return enable_schema_database_; }
+
+  bool release_backup_schema_file_if_overlay_present() const {
+    return release_backup_schema_file_if_overlay_present_;
+  }
+
  private:
+  // Whether to allow circular references in the schema definition. This was
+  // added in the Android U timeline and is not a trunk-stable flag.
+  bool allow_circular_schema_definitions_;
+
   bool enable_scorable_properties_;
 
   // Whether to enable quantization for embedding vectors. If false, all
@@ -48,6 +75,14 @@ class FeatureFlags {
   bool enable_embedding_quantization_;
 
   bool enable_repeated_field_joins_;
+
+  // Controls code that runs in backup schema producer to remove embedding
+  // properties.
+  bool enable_embedding_backup_generation_;
+
+  bool enable_schema_database_;
+
+  bool release_backup_schema_file_if_overlay_present_;
 };
 
 }  // namespace lib
diff --git a/icing/file/derived-file-util.h b/icing/file/derived-file-util.h
new file mode 100644
index 0000000..0a51ae4
--- /dev/null
+++ b/icing/file/derived-file-util.h
@@ -0,0 +1,113 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_FILE_DERIVED_FILE_UTIL_H_
+#define ICING_FILE_DERIVED_FILE_UTIL_H_
+
+namespace icing {
+namespace lib {
+
+namespace derived_file_util {
+
+// Contains information about whether the derived files of each component need
+// to be rebuild. Whether the derived files of a component need to be rebuilt
+// (during initialization) depends on the following conditions:
+// - Version change.
+// - Feature flag change.
+// - General marker file presence. It means that something wonky happened when
+//   we last tried to do some complex operations (e.g. SetSchema, Optimize).
+//
+// These flags only reflect whether each component should be rebuilt, but do not
+// handle any dependencies. The caller should handle the dependencies by
+// themselves.
+// e.g. - qualified id join index depends on document store derived files, but
+//        it's possible to have needs_document_store_derived_files_rebuild =
+//        true and needs_qualified_id_join_index_rebuild = false.
+//      - The caller should know that join index should also be rebuilt in this
+//        case even though needs_qualified_id_join_index_rebuild = false.
+struct DerivedFilesRebuildInfo {
+  bool needs_document_store_derived_files_rebuild = false;
+  bool needs_schema_store_derived_files_rebuild = false;
+  bool needs_term_index_rebuild = false;
+  bool needs_integer_index_rebuild = false;
+  bool needs_qualified_id_join_index_rebuild = false;
+  bool needs_embedding_index_rebuild = false;
+
+  DerivedFilesRebuildInfo() = default;
+
+  explicit DerivedFilesRebuildInfo(
+      bool needs_document_store_derived_files_rebuild_in,
+      bool needs_schema_store_derived_files_rebuild_in,
+      bool needs_term_index_rebuild_in, bool needs_integer_index_rebuild_in,
+      bool needs_qualified_id_join_index_rebuild_in,
+      bool needs_embedding_index_rebuild_in)
+      : needs_document_store_derived_files_rebuild(
+            needs_document_store_derived_files_rebuild_in),
+        needs_schema_store_derived_files_rebuild(
+            needs_schema_store_derived_files_rebuild_in),
+        needs_term_index_rebuild(needs_term_index_rebuild_in),
+        needs_integer_index_rebuild(needs_integer_index_rebuild_in),
+        needs_qualified_id_join_index_rebuild(
+            needs_qualified_id_join_index_rebuild_in),
+        needs_embedding_index_rebuild(needs_embedding_index_rebuild_in) {}
+
+  bool IsRebuildNeeded() const {
+    return needs_document_store_derived_files_rebuild ||
+           needs_schema_store_derived_files_rebuild ||
+           needs_term_index_rebuild || needs_integer_index_rebuild ||
+           needs_qualified_id_join_index_rebuild ||
+           needs_embedding_index_rebuild;
+  }
+
+  void RebuildAll() {
+    needs_document_store_derived_files_rebuild = true;
+    needs_schema_store_derived_files_rebuild = true;
+    needs_term_index_rebuild = true;
+    needs_integer_index_rebuild = true;
+    needs_qualified_id_join_index_rebuild = true;
+    needs_embedding_index_rebuild = true;
+  }
+
+  bool operator==(const DerivedFilesRebuildInfo& other) const {
+    return needs_document_store_derived_files_rebuild ==
+               other.needs_document_store_derived_files_rebuild &&
+           needs_schema_store_derived_files_rebuild ==
+               other.needs_schema_store_derived_files_rebuild &&
+           needs_term_index_rebuild == other.needs_term_index_rebuild &&
+           needs_integer_index_rebuild == other.needs_integer_index_rebuild &&
+           needs_qualified_id_join_index_rebuild ==
+               other.needs_qualified_id_join_index_rebuild &&
+           needs_embedding_index_rebuild == other.needs_embedding_index_rebuild;
+  }
+
+  DerivedFilesRebuildInfo& operator|=(const DerivedFilesRebuildInfo& other) {
+    needs_document_store_derived_files_rebuild |=
+        other.needs_document_store_derived_files_rebuild;
+    needs_schema_store_derived_files_rebuild |=
+        other.needs_schema_store_derived_files_rebuild;
+    needs_term_index_rebuild |= other.needs_term_index_rebuild;
+    needs_integer_index_rebuild |= other.needs_integer_index_rebuild;
+    needs_qualified_id_join_index_rebuild |=
+        other.needs_qualified_id_join_index_rebuild;
+    needs_embedding_index_rebuild |= other.needs_embedding_index_rebuild;
+    return *this;
+  }
+};
+
+}  // namespace derived_file_util
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_FILE_DERIVED_FILE_UTIL_H_
diff --git a/icing/file/marker-file.cc b/icing/file/marker-file.cc
new file mode 100644
index 0000000..99789f4
--- /dev/null
+++ b/icing/file/marker-file.cc
@@ -0,0 +1,91 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/file/marker-file.h"
+
+#include <memory>
+#include <string>
+#include <utility>
+
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/absl_ports/str_cat.h"
+#include "icing/file/file-backed-proto.h"
+#include "icing/file/filesystem.h"
+#include "icing/proto/initialize.pb.h"
+#include "icing/util/logging.h"
+#include "icing/util/status-macros.h"
+
+namespace icing {
+namespace lib {
+
+/* static */ libtextclassifier3::StatusOr<std::unique_ptr<MarkerFile>>
+MarkerFile::Create(
+    const Filesystem* filesystem, std::string filepath,
+    IcingSearchEngineMarkerProto::OperationType::Code operation_type) {
+  ICING_RETURN_ERROR_IF_NULL(filesystem);
+
+  if (operation_type == IcingSearchEngineMarkerProto::OperationType::UNKNOWN) {
+    return absl_ports::InvalidArgumentError(
+        "Cannot create marker file with UNKNOWN operation type.");
+  }
+
+  if (filesystem->FileExists(filepath.c_str())) {
+    return absl_ports::FailedPreconditionError(
+        absl_ports::StrCat("Marker file already exists: ", filepath));
+  }
+
+  // Create the instance.
+  auto file_backed_proto =
+      std::make_unique<FileBackedProto<IcingSearchEngineMarkerProto>>(
+          *filesystem, filepath);
+  auto marker_file = std::unique_ptr<MarkerFile>(new MarkerFile(
+      filesystem, std::move(filepath), std::move(file_backed_proto)));
+
+  // Initialize and write the proto with the given operation type.
+  auto marker_proto = std::make_unique<IcingSearchEngineMarkerProto>();
+  marker_proto->set_operation_type(operation_type);
+  ICING_RETURN_IF_ERROR(
+      marker_file->file_backed_proto_->Write(std::move(marker_proto)));
+
+  return marker_file;
+}
+
+/* static */ std::unique_ptr<IcingSearchEngineMarkerProto>
+MarkerFile::Postmortem(const Filesystem& filesystem,
+                       const std::string& filepath) {
+  if (!filesystem.FileExists(filepath.c_str())) {
+    return nullptr;
+  }
+
+  FileBackedProto<IcingSearchEngineMarkerProto> marker_file(filesystem,
+                                                            filepath);
+  libtextclassifier3::StatusOr<const IcingSearchEngineMarkerProto*>
+      marker_proto_or = marker_file.Read();
+  if (!marker_proto_or.ok()) {
+    // Since postmortem failure doesn't affect the correctness of the logic, we
+    // just log the error message without passing it up. But we should  still
+    // return a valid IcingSearchEngineMarkerProto with default values (with
+    // UNKNOWN previous operation) indicating that the general marker file is
+    // present on disk.
+    ICING_LOG(ERROR) << "Failed to read existing marker file: "
+                     << marker_proto_or.status().error_message();
+    return std::make_unique<IcingSearchEngineMarkerProto>();
+  }
+  return std::make_unique<IcingSearchEngineMarkerProto>(
+      *marker_proto_or.ValueOrDie());
+}
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/file/marker-file.h b/icing/file/marker-file.h
new file mode 100644
index 0000000..3144b99
--- /dev/null
+++ b/icing/file/marker-file.h
@@ -0,0 +1,89 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_FILE_MARKER_FILE_H_
+#define ICING_FILE_MARKER_FILE_H_
+
+#include <memory>
+#include <string>
+#include <utility>
+
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/file/file-backed-proto.h"
+#include "icing/file/filesystem.h"
+#include "icing/proto/initialize.pb.h"
+#include "icing/util/logging.h"
+
+namespace icing {
+namespace lib {
+
+class MarkerFile {
+ public:
+  // Creates a destructible marker file object with the given operation type.
+  // - If instantiation succeeds, then the marker file is created and a marker
+  //   proto with the given operation type is written to the file.
+  // - The marker file is deleted upon destruction of the marker file object.
+  //
+  // Returns:
+  //   - On success, a unique pointer to the marker file object.
+  //   - FAILED_PRECONDITION_ERROR if any of the pointer is null, or the marker
+  //     file already exists.
+  //   - INVALID_ARGUMENT_ERROR if the operation type is UNKNOWN.
+  //   - INTERNAL_ERROR on I/O errors.
+  //   - Any FileBackedProto errors.
+  static libtextclassifier3::StatusOr<std::unique_ptr<MarkerFile>> Create(
+      const Filesystem* filesystem, std::string filepath,
+      IcingSearchEngineMarkerProto::OperationType::Code operation_type);
+
+  // Attempts to read the marker file and returns the content (in proto format).
+  // - If the file exists, reads the content and returns the proto. If any error
+  //   occurs when reading, returns a default proto with UNKNOWN operation type.
+  // - If the file does not exist, returns nullptr.
+  //
+  // Returns:
+  //   - A unique pointer to IcingSearchEngineMarkerProto if the file exists.
+  //   - nullptr otherwise.
+  static std::unique_ptr<IcingSearchEngineMarkerProto> Postmortem(
+      const Filesystem& filesystem, const std::string& filepath);
+
+  ~MarkerFile() {
+    if (!filesystem_.DeleteFile(filepath_.c_str())) {
+      ICING_VLOG(1) << "Failed to delete marker file " << filepath_
+                    << " during destruction.";
+    }
+  }
+
+ private:
+  explicit MarkerFile(
+      const Filesystem* filesystem, std::string filepath,
+      std::unique_ptr<FileBackedProto<IcingSearchEngineMarkerProto>>
+          file_backed_proto)
+      : filesystem_(*filesystem),
+        filepath_(std::move(filepath)),
+        file_backed_proto_(std::move(file_backed_proto)) {}
+
+  const Filesystem& filesystem_;
+  std::string filepath_;
+
+  // The file-backed proto object that is used to read/write the marker file.
+  // Keep this instance alive, so in the future we can provide more methods to
+  // write new fields to the marker file.
+  std::unique_ptr<FileBackedProto<IcingSearchEngineMarkerProto>>
+      file_backed_proto_;
+};
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_FILE_MARKER_FILE_H_
diff --git a/icing/file/marker-file_test.cc b/icing/file/marker-file_test.cc
new file mode 100644
index 0000000..cd7d655
--- /dev/null
+++ b/icing/file/marker-file_test.cc
@@ -0,0 +1,194 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/file/marker-file.h"
+
+#include <memory>
+#include <string>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+#include "icing/file/file-backed-proto.h"
+#include "icing/file/filesystem.h"
+#include "icing/file/mock-filesystem.h"
+#include "icing/portable/equals-proto.h"
+#include "icing/testing/common-matchers.h"
+#include "icing/testing/tmp-directory.h"
+
+namespace icing {
+namespace lib {
+
+namespace {
+
+using ::icing::lib::portable_equals_proto::EqualsProto;
+using ::testing::Eq;
+using ::testing::HasSubstr;
+using ::testing::IsFalse;
+using ::testing::IsNull;
+using ::testing::IsTrue;
+using ::testing::Matcher;
+using ::testing::Pointee;
+using ::testing::Return;
+
+class MarkerFileTest : public ::testing::Test {
+ protected:
+  void SetUp() override {
+    test_dir_ = GetTestTempDir() + "/icing_marker_file_test";
+    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(test_dir_.c_str()),
+                IsTrue());
+  }
+
+  void TearDown() override {
+    filesystem_.DeleteDirectoryRecursively(test_dir_.c_str());
+  }
+
+  Filesystem filesystem_;
+  std::string test_dir_;
+};
+
+TEST_F(MarkerFileTest, CreateAndDestruct) {
+  std::string file_path = test_dir_ + "/marker_file";
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        std::unique_ptr<MarkerFile> marker_file,
+        MarkerFile::Create(
+            &filesystem_, file_path,
+            IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA));
+
+    EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsTrue());
+
+    {
+      // Use another FileBackedProto object to examine the content.
+      FileBackedProto<IcingSearchEngineMarkerProto> file_backed_proto(
+          filesystem_, file_path);
+      ICING_ASSERT_OK_AND_ASSIGN(
+          const IcingSearchEngineMarkerProto* marker_proto,
+          file_backed_proto.Read());
+      EXPECT_THAT(marker_proto->operation_type(),
+                  IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA);
+    }
+
+    EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsTrue());
+  }
+
+  // After leaving the scope, the marker file object is destructed, and the
+  // underlying file should be deleted.
+  EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsFalse());
+}
+
+TEST_F(MarkerFileTest, CreateWithUnknownOperationTypeShouldFail) {
+  std::string file_path = test_dir_ + "/marker_file";
+
+  EXPECT_THAT(
+      MarkerFile::Create(&filesystem_, file_path,
+                         IcingSearchEngineMarkerProto::OperationType::UNKNOWN),
+      StatusIs(
+          libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+          HasSubstr("Cannot create marker file with UNKNOWN operation type")));
+  // The marker file should not be created.
+  EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsFalse());
+}
+
+TEST_F(MarkerFileTest, CreateWithExistingFileShouldFail) {
+  std::string file_path = test_dir_ + "/marker_file";
+
+  {
+    // Create the file.
+    ScopedFd sfd(filesystem_.OpenForWrite(file_path.c_str()));
+    ASSERT_THAT(sfd.is_valid(), IsTrue());
+    ASSERT_THAT(filesystem_.Write(sfd.get(), "test", /*data_size=*/4),
+                IsTrue());
+  }
+  ASSERT_THAT(filesystem_.FileExists(file_path.c_str()), IsTrue());
+  ASSERT_THAT(filesystem_.GetFileSize(file_path.c_str()), Eq(4));
+
+  EXPECT_THAT(MarkerFile::Create(
+                  &filesystem_, file_path,
+                  IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA),
+              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION,
+                       HasSubstr("Marker file already exists")));
+  // The file should still exist and remain unchanged.
+  EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsTrue());
+  EXPECT_THAT(filesystem_.GetFileSize(file_path.c_str()), Eq(4));
+  char buf[4];
+  EXPECT_THAT(filesystem_.Read(file_path.c_str(), buf, /*buf_size=*/4),
+              IsTrue());
+  EXPECT_THAT(std::string(buf, 4), Eq("test"));
+}
+
+TEST_F(MarkerFileTest, WriteFailureShouldDeleteTheFile) {
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  std::string file_path = test_dir_ + "/marker_file";
+
+  // Mock Write to fail.
+  ON_CALL(*mock_filesystem, Write(Matcher<int>(_), _, _))
+      .WillByDefault(Return(false));
+
+  EXPECT_THAT(MarkerFile::Create(
+                  mock_filesystem.get(), file_path,
+                  IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA),
+              StatusIs(libtextclassifier3::StatusCode::INTERNAL,
+                       HasSubstr("Failed to write")));
+  // The marker file should be deleted after the write failure.
+  EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsFalse());
+}
+
+TEST_F(MarkerFileTest, PostmortemExistingMarkerFile) {
+  std::string file_path = test_dir_ + "/marker_file";
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<MarkerFile> marker_file,
+      MarkerFile::Create(
+          &filesystem_, file_path,
+          IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA));
+
+  EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsTrue());
+
+  IcingSearchEngineMarkerProto expected_proto;
+  expected_proto.set_operation_type(
+      IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA);
+  EXPECT_THAT(MarkerFile::Postmortem(filesystem_, file_path),
+              Pointee(EqualsProto(expected_proto)));
+}
+
+TEST_F(MarkerFileTest, PostmortemReadErrorShouldReturnDefaultMarkerProto) {
+  std::string file_path = test_dir_ + "/marker_file";
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<MarkerFile> marker_file,
+      MarkerFile::Create(
+          &filesystem_, file_path,
+          IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA));
+
+  EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsTrue());
+
+  // Mock Read to fail.
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  ON_CALL(*mock_filesystem, OpenForRead(Eq(file_path)))
+      .WillByDefault(Return(-1));
+  EXPECT_THAT(
+      MarkerFile::Postmortem(*mock_filesystem, file_path),
+      Pointee(EqualsProto(IcingSearchEngineMarkerProto::default_instance())));
+}
+
+TEST_F(MarkerFileTest, PostmortemNonExistingMarkerFileShouldReturnNullptr) {
+  std::string file_path = test_dir_ + "/marker_file";
+  ASSERT_THAT(filesystem_.FileExists(file_path.c_str()), IsFalse());
+
+  EXPECT_THAT(MarkerFile::Postmortem(filesystem_, file_path), IsNull());
+}
+
+}  // namespace
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/file/portable-file-backed-proto-log.h b/icing/file/portable-file-backed-proto-log.h
index 81010e8..b498563 100644
--- a/icing/file/portable-file-backed-proto-log.h
+++ b/icing/file/portable-file-backed-proto-log.h
@@ -390,8 +390,8 @@ class PortableFileBackedProtoLog {
   // }
   class Iterator {
    public:
-    Iterator(const Filesystem& filesystem, int fd, int64_t initial_offset,
-             int64_t file_size);
+    explicit Iterator(const Filesystem& filesystem, int fd,
+                      int64_t initial_offset, int64_t file_size);
 
     // Advances to the position of next proto whether it has been erased or not.
     //
@@ -402,7 +402,7 @@ class PortableFileBackedProtoLog {
     libtextclassifier3::Status Advance();
 
     // Returns the file offset of current proto.
-    int64_t GetOffset();
+    int64_t GetOffset() const;
 
    private:
     static constexpr int64_t kInvalidOffset = -1;
@@ -418,7 +418,7 @@ class PortableFileBackedProtoLog {
   // Returns an iterator of current proto log. The caller needs to keep the
   // proto log unchanged while using the iterator, otherwise unexpected
   // behaviors could happen.
-  Iterator GetIterator();
+  Iterator GetIterator() const;
 
   // Persists all changes since initialization or the last call to
   // PersistToDisk(). Any changes that aren't persisted may be lost if the
@@ -721,6 +721,11 @@ PortableFileBackedProtoLog<ProtoT>::InitializeExistingFile(
         absl_ports::StrCat("Invalid header checksum for: ", file_path));
   }
 
+  if (header->GetRewindOffset() < kHeaderReservedBytes) {
+    return absl_ports::InternalError(
+        absl_ports::StrCat("Invalid header rewind offset for: ", file_path));
+  }
+
   if (header->GetFileFormatVersion() != Header::kFileFormatVersion) {
     // If this changes, we might need to handle a migration rather than throwing
     // an error.
@@ -1130,13 +1135,13 @@ PortableFileBackedProtoLog<ProtoT>::Iterator::Advance() {
 }
 
 template <typename ProtoT>
-int64_t PortableFileBackedProtoLog<ProtoT>::Iterator::GetOffset() {
+int64_t PortableFileBackedProtoLog<ProtoT>::Iterator::GetOffset() const {
   return current_offset_;
 }
 
 template <typename ProtoT>
 typename PortableFileBackedProtoLog<ProtoT>::Iterator
-PortableFileBackedProtoLog<ProtoT>::GetIterator() {
+PortableFileBackedProtoLog<ProtoT>::GetIterator() const {
   return Iterator(*filesystem_, fd_.get(),
                   /*initial_offset=*/kHeaderReservedBytes, file_size_);
 }
diff --git a/icing/file/version-util.cc b/icing/file/version-util.cc
index af5ea50..e37c469 100644
--- a/icing/file/version-util.cc
+++ b/icing/file/version-util.cc
@@ -25,6 +25,7 @@
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/canonical_errors.h"
 #include "icing/absl_ports/str_cat.h"
+#include "icing/file/derived-file-util.h"
 #include "icing/file/file-backed-proto.h"
 #include "icing/file/filesystem.h"
 #include "icing/index/index.h"
@@ -221,13 +222,13 @@ StateChange GetVersionStateChange(const VersionInfo& existing_version_info,
   }
 }
 
-DerivedFilesRebuildResult CalculateRequiredDerivedFilesRebuild(
+derived_file_util::DerivedFilesRebuildInfo CalculateRequiredDerivedFilesRebuild(
     const IcingSearchEngineVersionProto& prev_version_proto,
     const IcingSearchEngineVersionProto& curr_version_proto) {
   // 1. Do version check using version and max_version numbers
   if (ShouldRebuildDerivedFiles(GetVersionInfoFromProto(prev_version_proto),
                                 curr_version_proto.version())) {
-    return DerivedFilesRebuildResult(
+    return derived_file_util::DerivedFilesRebuildInfo(
         /*needs_document_store_derived_files_rebuild=*/true,
         /*needs_schema_store_derived_files_rebuild=*/true,
         /*needs_term_index_rebuild=*/true,
@@ -248,7 +249,7 @@ DerivedFilesRebuildResult CalculateRequiredDerivedFilesRebuild(
   for (const auto& feature : curr_version_proto.enabled_features()) {
     curr_features.insert(feature.feature_type());
   }
-  DerivedFilesRebuildResult result;
+  derived_file_util::DerivedFilesRebuildInfo result;
   for (const auto& prev_feature : prev_features) {
     // If there is an UNKNOWN feature in the previous feature set (note that we
     // never use UNKNOWN  when writing the version proto), it means that:
@@ -258,7 +259,7 @@ DerivedFilesRebuildResult CalculateRequiredDerivedFilesRebuild(
     //   new enum value, and proto serialization defaults it to 0 (UNKNOWN).
     // - In this case we need to rebuild everything.
     if (prev_feature == IcingSearchEngineFeatureInfoProto::UNKNOWN) {
-      return DerivedFilesRebuildResult(
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/true,
           /*needs_schema_store_derived_files_rebuild=*/true,
           /*needs_term_index_rebuild=*/true,
@@ -267,16 +268,16 @@ DerivedFilesRebuildResult CalculateRequiredDerivedFilesRebuild(
           /*needs_embedding_index_rebuild=*/true);
     }
     if (curr_features.find(prev_feature) == curr_features.end()) {
-      DerivedFilesRebuildResult required_rebuilds =
-          GetFeatureDerivedFilesRebuildResult(prev_feature);
-      result.CombineWithOtherRebuildResultOr(required_rebuilds);
+      derived_file_util::DerivedFilesRebuildInfo required_rebuilds =
+          GetFeatureDerivedFilesRebuildInfo(prev_feature);
+      result |= required_rebuilds;
     }
   }
   for (const auto& curr_feature : curr_features) {
     if (prev_features.find(curr_feature) == prev_features.end()) {
-      DerivedFilesRebuildResult required_rebuilds =
-          GetFeatureDerivedFilesRebuildResult(curr_feature);
-      result.CombineWithOtherRebuildResultOr(required_rebuilds);
+      derived_file_util::DerivedFilesRebuildInfo required_rebuilds =
+          GetFeatureDerivedFilesRebuildInfo(curr_feature);
+      result |= required_rebuilds;
     }
   }
   return result;
@@ -306,6 +307,7 @@ bool ShouldRebuildDerivedFiles(const VersionInfo& existing_version_info,
   bool should_rebuild = false;
   int32_t existing_version = existing_version_info.version;
   while (existing_version < curr_version) {
+    // LINT.IfChange(should_rebuild_derived_files_upgrade_check)
     switch (existing_version) {
       case 1: {
         // version 1 -> version 2 upgrade, no need to rebuild
@@ -323,20 +325,29 @@ bool ShouldRebuildDerivedFiles(const VersionInfo& existing_version_info,
         // version 4 -> version 5 upgrade, no need to rebuild
         break;
       }
+      case 5: {
+        // version 5 -> version 6 upgrade, no need to rebuild
+        break;
+      }
+      case 6: {
+        // version 6 -> version 7 upgrade, no need to rebuild
+        break;
+      }
       default:
         // This should not happen. Rebuild anyway if unsure.
         should_rebuild |= true;
     }
+    // LINT.ThenChange(//depot/google3/icing/file/version-util.h:kVersion)
     ++existing_version;
   }
   return should_rebuild;
 }
 
-DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
+derived_file_util::DerivedFilesRebuildInfo GetFeatureDerivedFilesRebuildInfo(
     IcingSearchEngineFeatureInfoProto::FlaggedFeatureType feature) {
   switch (feature) {
     case IcingSearchEngineFeatureInfoProto::FEATURE_SCORABLE_PROPERTIES: {
-      return DerivedFilesRebuildResult(
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/true,
           /*needs_schema_store_derived_files_rebuild=*/false,
           /*needs_term_index_rebuild=*/false,
@@ -345,7 +356,7 @@ DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
           /*needs_embedding_index_rebuild=*/false);
     }
     case IcingSearchEngineFeatureInfoProto::FEATURE_HAS_PROPERTY_OPERATOR: {
-      return DerivedFilesRebuildResult(
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/false,
           /*needs_schema_store_derived_files_rebuild=*/false,
           /*needs_term_index_rebuild=*/true,
@@ -354,7 +365,7 @@ DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
           /*needs_embedding_index_rebuild=*/false);
     }
     case IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX: {
-      return DerivedFilesRebuildResult(
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/false,
           /*needs_schema_store_derived_files_rebuild=*/false,
           /*needs_term_index_rebuild=*/false,
@@ -363,7 +374,7 @@ DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
           /*needs_embedding_index_rebuild=*/true);
     }
     case IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_QUANTIZATION: {
-      return DerivedFilesRebuildResult(
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/false,
           /*needs_schema_store_derived_files_rebuild=*/false,
           /*needs_term_index_rebuild=*/false,
@@ -374,7 +385,7 @@ DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
     case IcingSearchEngineFeatureInfoProto::FEATURE_SCHEMA_DATABASE: {
       // The schema database feature requires schema-store migration, which is
       // done separately from derived files rebuild.
-      return DerivedFilesRebuildResult(
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/false,
           /*needs_schema_store_derived_files_rebuild=*/false,
           /*needs_term_index_rebuild=*/false,
@@ -383,8 +394,8 @@ DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
           /*needs_embedding_index_rebuild=*/false);
     }
     case IcingSearchEngineFeatureInfoProto::
-        FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM: {
-      return DerivedFilesRebuildResult(
+        FEATURE_QUALIFIED_ID_JOIN_INDEX_V3: {
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/false,
           /*needs_schema_store_derived_files_rebuild=*/false,
           /*needs_term_index_rebuild=*/false,
@@ -393,7 +404,7 @@ DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
           /*needs_embedding_index_rebuild=*/false);
     }
     case IcingSearchEngineFeatureInfoProto::UNKNOWN:
-      return DerivedFilesRebuildResult(
+      return derived_file_util::DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild=*/true,
           /*needs_schema_store_derived_files_rebuild=*/true,
           /*needs_term_index_rebuild=*/true,
@@ -424,8 +435,8 @@ IcingSearchEngineFeatureInfoProto GetFeatureInfoProto(
   IcingSearchEngineFeatureInfoProto info;
   info.set_feature_type(feature);
 
-  DerivedFilesRebuildResult result =
-      GetFeatureDerivedFilesRebuildResult(feature);
+  derived_file_util::DerivedFilesRebuildInfo result =
+      GetFeatureDerivedFilesRebuildInfo(feature);
   info.set_needs_document_store_rebuild(
       result.needs_document_store_derived_files_rebuild);
   info.set_needs_schema_store_rebuild(
@@ -466,11 +477,10 @@ void AddEnabledFeatures(const IcingSearchEngineOptions& options,
     enabled_features->Add(GetFeatureInfoProto(
         IcingSearchEngineFeatureInfoProto::FEATURE_SCHEMA_DATABASE));
   }
-  // QualifiedIdJoinIndex V3 and delete propagation type PROPAGATE_FROM feature
-  if (options.enable_qualified_id_join_index_v3_and_delete_propagate_from()) {
+  // QualifiedIdJoinIndex V3 feature
+  if (options.enable_qualified_id_join_index_v3()) {
     enabled_features->Add(GetFeatureInfoProto(
-        IcingSearchEngineFeatureInfoProto::
-            FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM));
+        IcingSearchEngineFeatureInfoProto::FEATURE_QUALIFIED_ID_JOIN_INDEX_V3));
   }
 }
 
diff --git a/icing/file/version-util.h b/icing/file/version-util.h
index 0f5e8a4..586a9c7 100644
--- a/icing/file/version-util.h
+++ b/icing/file/version-util.h
@@ -23,6 +23,7 @@
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/str_cat.h"
+#include "icing/file/derived-file-util.h"
 #include "icing/file/filesystem.h"
 #include "icing/proto/initialize.pb.h"
 
@@ -38,7 +39,7 @@ namespace version_util {
 // - Version 3: M-2024-02. Schema is compatible with v1 and v2.
 // - Version 4: Android V base. Schema is compatible with v1, v2 and v3.
 // - Version 5: M-2025-02. Schema is compatible with v1, v2, v3 and v4.
-inline static constexpr int32_t kVersion = 5;
+inline static constexpr int32_t kVersion = 7;
 inline static constexpr int32_t kVersionOne = 1;
 inline static constexpr int32_t kVersionTwo = 2;
 inline static constexpr int32_t kVersionThree = 3;
@@ -81,75 +82,6 @@ enum class StateChange {
   kVersionZeroRollForward,
 };
 
-// Contains information about which derived files need to be rebuild.
-//
-// These flags only reflect whether each component should be rebuilt, but do not
-// handle any dependencies. The caller should handle the dependencies by
-// themselves.
-// e.g. - qualified id join index depends on document store derived files, but
-//        it's possible to have needs_document_store_derived_files_rebuild =
-//        true and needs_qualified_id_join_index_rebuild = false.
-//      - The caller should know that join index should also be rebuilt in this
-//        case even though needs_qualified_id_join_index_rebuild = false.
-struct DerivedFilesRebuildResult {
-  bool needs_document_store_derived_files_rebuild = false;
-  bool needs_schema_store_derived_files_rebuild = false;
-  bool needs_term_index_rebuild = false;
-  bool needs_integer_index_rebuild = false;
-  bool needs_qualified_id_join_index_rebuild = false;
-  bool needs_embedding_index_rebuild = false;
-
-  DerivedFilesRebuildResult() = default;
-
-  explicit DerivedFilesRebuildResult(
-      bool needs_document_store_derived_files_rebuild_in,
-      bool needs_schema_store_derived_files_rebuild_in,
-      bool needs_term_index_rebuild_in, bool needs_integer_index_rebuild_in,
-      bool needs_qualified_id_join_index_rebuild_in,
-      bool needs_embedding_index_rebuild_in)
-      : needs_document_store_derived_files_rebuild(
-            needs_document_store_derived_files_rebuild_in),
-        needs_schema_store_derived_files_rebuild(
-            needs_schema_store_derived_files_rebuild_in),
-        needs_term_index_rebuild(needs_term_index_rebuild_in),
-        needs_integer_index_rebuild(needs_integer_index_rebuild_in),
-        needs_qualified_id_join_index_rebuild(
-            needs_qualified_id_join_index_rebuild_in),
-        needs_embedding_index_rebuild(needs_embedding_index_rebuild_in) {}
-
-  bool IsRebuildNeeded() const {
-    return needs_document_store_derived_files_rebuild ||
-           needs_schema_store_derived_files_rebuild ||
-           needs_term_index_rebuild || needs_integer_index_rebuild ||
-           needs_qualified_id_join_index_rebuild ||
-           needs_embedding_index_rebuild;
-  }
-
-  bool operator==(const DerivedFilesRebuildResult& other) const {
-    return needs_document_store_derived_files_rebuild ==
-               other.needs_document_store_derived_files_rebuild &&
-           needs_schema_store_derived_files_rebuild ==
-               other.needs_schema_store_derived_files_rebuild &&
-           needs_term_index_rebuild == other.needs_term_index_rebuild &&
-           needs_integer_index_rebuild == other.needs_integer_index_rebuild &&
-           needs_qualified_id_join_index_rebuild ==
-               other.needs_qualified_id_join_index_rebuild &&
-           needs_embedding_index_rebuild == other.needs_embedding_index_rebuild;
-  }
-
-  void CombineWithOtherRebuildResultOr(const DerivedFilesRebuildResult& other) {
-    needs_document_store_derived_files_rebuild |=
-        other.needs_document_store_derived_files_rebuild;
-    needs_schema_store_derived_files_rebuild |=
-        other.needs_schema_store_derived_files_rebuild;
-    needs_term_index_rebuild |= other.needs_term_index_rebuild;
-    needs_integer_index_rebuild |= other.needs_integer_index_rebuild;
-    needs_qualified_id_join_index_rebuild |=
-        other.needs_qualified_id_join_index_rebuild;
-    needs_embedding_index_rebuild |= other.needs_embedding_index_rebuild;
-  }
-};
-
 // There are two icing version files:
 // 1. V1 version file contains version and max_version info of the existing
 //    data.
@@ -234,8 +166,8 @@ StateChange GetVersionStateChange(const VersionInfo& existing_version_info,
 // REQUIRES: curr_version >= kFirstV2Version. We implement v2 version checking
 // in kFirstV2Version, so callers will always use a version # greater than this.
 //
-// RETURNS: DerivedFilesRebuildResult
-DerivedFilesRebuildResult CalculateRequiredDerivedFilesRebuild(
+// RETURNS: derived_file_util::DerivedFilesRebuildInfo
+derived_file_util::DerivedFilesRebuildInfo CalculateRequiredDerivedFilesRebuild(
     const IcingSearchEngineVersionProto& prev_version_proto,
     const IcingSearchEngineVersionProto& curr_version_proto);
 
@@ -258,7 +190,7 @@ bool SchemaDatabaseMigrationRequired(
     const IcingSearchEngineVersionProto& prev_version_proto);
 
 // Returns the derived files rebuilds required for a given feature.
-DerivedFilesRebuildResult GetFeatureDerivedFilesRebuildResult(
+derived_file_util::DerivedFilesRebuildInfo GetFeatureDerivedFilesRebuildInfo(
     IcingSearchEngineFeatureInfoProto::FlaggedFeatureType feature);
 
 // Constructs the IcingSearchEngineFeatureInfoProto for a given feature.
diff --git a/icing/file/version-util_test.cc b/icing/file/version-util_test.cc
index d881adc..deec9d1 100644
--- a/icing/file/version-util_test.cc
+++ b/icing/file/version-util_test.cc
@@ -23,6 +23,7 @@
 
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/file/derived-file-util.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/posting_list/flash-index-storage-header.h"
 #include "icing/portable/equals-proto.h"
@@ -36,10 +37,15 @@ namespace version_util {
 
 namespace {
 
+using derived_file_util::DerivedFilesRebuildInfo;
+
+using ::testing::Contains;
 using ::testing::Eq;
 using ::testing::IsEmpty;
 using ::testing::IsFalse;
 using ::testing::IsTrue;
+using ::testing::Not;
+using ::testing::Property;
 
 IcingSearchEngineVersionProto MakeTestVersionProto(
     const VersionInfo& version_info,
@@ -583,7 +589,7 @@ struct VersionUtilDerivedFilesRebuildTestParam {
   int32_t curr_version;
   std::unordered_set<IcingSearchEngineFeatureInfoProto::FlaggedFeatureType>
       curr_enabled_features;
-  DerivedFilesRebuildResult expected_derived_files_rebuild_result;
+  DerivedFilesRebuildInfo expected_derived_files_rebuild_info;
 
   explicit VersionUtilDerivedFilesRebuildTestParam(
       int32_t existing_version_in, int32_t max_version_in,
@@ -592,14 +598,14 @@ struct VersionUtilDerivedFilesRebuildTestParam {
       int32_t curr_version_in,
       std::unordered_set<IcingSearchEngineFeatureInfoProto::FlaggedFeatureType>
           curr_enabled_features_in,
-      DerivedFilesRebuildResult expected_derived_files_rebuild_result_in)
+      DerivedFilesRebuildInfo expected_derived_files_rebuild_info_in)
       : existing_version(existing_version_in),
         max_version(max_version_in),
         existing_enabled_features(std::move(existing_enabled_features_in)),
         curr_version(curr_version_in),
         curr_enabled_features(std::move(curr_enabled_features_in)),
-        expected_derived_files_rebuild_result(
-            std::move(expected_derived_files_rebuild_result_in)) {}
+        expected_derived_files_rebuild_info(
+            std::move(expected_derived_files_rebuild_info_in)) {}
 };
 
 class VersionUtilDerivedFilesRebuildTest
@@ -618,7 +624,7 @@ TEST_P(VersionUtilDerivedFilesRebuildTest,
                   MakeTestVersionProto(
                       VersionInfo(param.curr_version, param.max_version),
                       param.curr_enabled_features)),
-              Eq(param.expected_derived_files_rebuild_result));
+              Eq(param.expected_derived_files_rebuild_info));
 }
 
 INSTANTIATE_TEST_SUITE_P(
@@ -634,8 +640,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/-1, /*max_version_in=*/-1,
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/true,
                 /*needs_schema_store_derived_files_rebuild_in=*/true,
                 /*needs_term_index_rebuild_in=*/true,
@@ -653,8 +659,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/-1, /*max_version_in=*/-1,
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/true,
                 /*needs_schema_store_derived_files_rebuild_in=*/true,
                 /*needs_term_index_rebuild_in=*/true,
@@ -672,8 +678,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/3, /*max_version_in=*/3,
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -692,8 +698,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_HAS_PROPERTY_OPERATOR},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/true,
@@ -712,8 +718,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -731,8 +737,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/4, /*max_version_in=*/4,
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -750,8 +756,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/4, /*max_version_in=*/4,
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/5,
             /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -769,8 +775,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/4, /*max_version_in=*/5,
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/5,
             /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/true,
                 /*needs_schema_store_derived_files_rebuild_in=*/true,
                 /*needs_term_index_rebuild_in=*/true,
@@ -788,8 +794,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/5, /*max_version_in=*/5,
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/true,
                 /*needs_schema_store_derived_files_rebuild_in=*/true,
                 /*needs_term_index_rebuild_in=*/true,
@@ -808,8 +814,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_HAS_PROPERTY_OPERATOR},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/true,
@@ -828,8 +834,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -850,8 +856,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX,
              IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_QUANTIZATION},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -874,8 +880,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX,
              IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_QUANTIZATION},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -894,8 +900,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_HAS_PROPERTY_OPERATOR},
             /*curr_version_in=*/4, /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/true,
@@ -914,8 +920,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX},
             /*curr_version_in=*/4, /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -936,8 +942,8 @@ INSTANTIATE_TEST_SUITE_P(
             {IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX,
              IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_QUANTIZATION},
             /*curr_version_in=*/4, /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -959,8 +965,8 @@ INSTANTIATE_TEST_SUITE_P(
              IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_QUANTIZATION},
             /*curr_version_in=*/4, /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -980,8 +986,8 @@ INSTANTIATE_TEST_SUITE_P(
             {IcingSearchEngineFeatureInfoProto::UNKNOWN}, /*curr_version_in=*/4,
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_HAS_PROPERTY_OPERATOR},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/true,
                 /*needs_schema_store_derived_files_rebuild_in=*/true,
                 /*needs_term_index_rebuild_in=*/true,
@@ -1000,8 +1006,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/{}, /*curr_version_in=*/5,
             /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_HAS_PROPERTY_OPERATOR},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/true,
@@ -1020,8 +1026,8 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/{},
             /*curr_version_in=*/5, /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::FEATURE_SCHEMA_DATABASE},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -1032,8 +1038,7 @@ INSTANTIATE_TEST_SUITE_P(
         // - Existing version 5, max_version 5
         // - Existing enabled features = {}
         // - Current version = 5
-        // - Current enabled features =
-        //   {FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM}
+        // - Current enabled features = {FEATURE_QUALIFIED_ID_JOIN_INDEX_V3}
         //
         // - Result: rebuild qualified id join index
         VersionUtilDerivedFilesRebuildTestParam(
@@ -1041,9 +1046,9 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_enabled_features_in=*/{},
             /*curr_version_in=*/5, /*curr_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::
-                 FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+                 FEATURE_QUALIFIED_ID_JOIN_INDEX_V3},
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -1053,7 +1058,7 @@ INSTANTIATE_TEST_SUITE_P(
 
         // - Existing version 5, max_version 5
         // - Existing enabled features =
-        //   {FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM}
+        //   {FEATURE_QUALIFIED_ID_JOIN_INDEX_V3}
         // - Current version = 5
         // - Current enabled features = {}
         //
@@ -1062,10 +1067,10 @@ INSTANTIATE_TEST_SUITE_P(
             /*existing_version_in=*/5, /*max_version_in=*/5,
             /*existing_enabled_features_in=*/
             {IcingSearchEngineFeatureInfoProto::
-                 FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM},
+                 FEATURE_QUALIFIED_ID_JOIN_INDEX_V3},
             /*curr_version_in=*/5, /*curr_enabled_features_in=*/{},
-            /*expected_derived_files_rebuild_result_in=*/
-            DerivedFilesRebuildResult(
+            /*expected_derived_files_rebuild_info_in=*/
+            DerivedFilesRebuildInfo(
                 /*needs_document_store_derived_files_rebuild_in=*/false,
                 /*needs_schema_store_derived_files_rebuild_in=*/false,
                 /*needs_term_index_rebuild_in=*/false,
@@ -1210,10 +1215,10 @@ TEST(VersionUtilTest, Upgrade) {
               IsFalse());
 }
 
-TEST(VersionUtilTest, GetFeatureDerivedFilesRebuildResult_unknown) {
-  EXPECT_THAT(GetFeatureDerivedFilesRebuildResult(
+TEST(VersionUtilTest, GetFeatureDerivedFilesRebuildInfo_unknown) {
+  EXPECT_THAT(GetFeatureDerivedFilesRebuildInfo(
                   IcingSearchEngineFeatureInfoProto::UNKNOWN),
-              Eq(DerivedFilesRebuildResult(
+              Eq(DerivedFilesRebuildInfo(
                   /*needs_document_store_derived_files_rebuild_in=*/true,
                   /*needs_schema_store_derived_files_rebuild_in=*/true,
                   /*needs_term_index_rebuild_in=*/true,
@@ -1223,11 +1228,11 @@ TEST(VersionUtilTest, GetFeatureDerivedFilesRebuildResult_unknown) {
 }
 
 TEST(VersionUtilTest,
-     GetFeatureDerivedFilesRebuildResult_featureHasPropertyOperator) {
+     GetFeatureDerivedFilesRebuildInfo_featureHasPropertyOperator) {
   EXPECT_THAT(
-      GetFeatureDerivedFilesRebuildResult(
+      GetFeatureDerivedFilesRebuildInfo(
           IcingSearchEngineFeatureInfoProto::FEATURE_HAS_PROPERTY_OPERATOR),
-      Eq(DerivedFilesRebuildResult(
+      Eq(DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild_in=*/false,
           /*needs_schema_store_derived_files_rebuild_in=*/false,
           /*needs_term_index_rebuild_in=*/true,
@@ -1236,11 +1241,10 @@ TEST(VersionUtilTest,
           /*needs_embedding_index_rebuild_in=*/false)));
 }
 
-TEST(VersionUtilTest,
-     GetFeatureDerivedFilesRebuildResult_featureEmbeddingIndex) {
-  EXPECT_THAT(GetFeatureDerivedFilesRebuildResult(
+TEST(VersionUtilTest, GetFeatureDerivedFilesRebuildInfo_featureEmbeddingIndex) {
+  EXPECT_THAT(GetFeatureDerivedFilesRebuildInfo(
                   IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX),
-              Eq(DerivedFilesRebuildResult(
+              Eq(DerivedFilesRebuildInfo(
                   /*needs_document_store_derived_files_rebuild_in=*/false,
                   /*needs_schema_store_derived_files_rebuild_in=*/false,
                   /*needs_term_index_rebuild_in=*/false,
@@ -1250,11 +1254,11 @@ TEST(VersionUtilTest,
 }
 
 TEST(VersionUtilTest,
-     GetFeatureDerivedFilesRebuildResult_featureEmbeddingQuantization) {
+     GetFeatureDerivedFilesRebuildInfo_featureEmbeddingQuantization) {
   EXPECT_THAT(
-      GetFeatureDerivedFilesRebuildResult(
+      GetFeatureDerivedFilesRebuildInfo(
           IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_QUANTIZATION),
-      Eq(DerivedFilesRebuildResult(
+      Eq(DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild_in=*/false,
           /*needs_schema_store_derived_files_rebuild_in=*/false,
           /*needs_term_index_rebuild_in=*/false,
@@ -1263,11 +1267,10 @@ TEST(VersionUtilTest,
           /*needs_embedding_index_rebuild_in=*/true)));
 }
 
-TEST(VersionUtilTest,
-     GetFeatureDerivedFilesRebuildResult_featureSchemaDatabase) {
-  EXPECT_THAT(GetFeatureDerivedFilesRebuildResult(
+TEST(VersionUtilTest, GetFeatureDerivedFilesRebuildInfo_featureSchemaDatabase) {
+  EXPECT_THAT(GetFeatureDerivedFilesRebuildInfo(
                   IcingSearchEngineFeatureInfoProto::FEATURE_SCHEMA_DATABASE),
-              Eq(DerivedFilesRebuildResult(
+              Eq(DerivedFilesRebuildInfo(
                   /*needs_document_store_derived_files_rebuild_in=*/false,
                   /*needs_schema_store_derived_files_rebuild_in=*/false,
                   /*needs_term_index_rebuild_in=*/false,
@@ -1276,14 +1279,12 @@ TEST(VersionUtilTest,
                   /*needs_embedding_index_rebuild_in=*/false)));
 }
 
-TEST(
-    VersionUtilTest,
-    GetFeatureDerivedFilesRebuildResult_featureQualifiedIdJoinIndexV3AndDeletePropagateFrom) {
+TEST(VersionUtilTest,
+     GetFeatureDerivedFilesRebuildInfo_featureQualifiedIdJoinIndexV3) {
   EXPECT_THAT(
-      GetFeatureDerivedFilesRebuildResult(
-          IcingSearchEngineFeatureInfoProto::
-              FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM),
-      Eq(DerivedFilesRebuildResult(
+      GetFeatureDerivedFilesRebuildInfo(IcingSearchEngineFeatureInfoProto::
+                                            FEATURE_QUALIFIED_ID_JOIN_INDEX_V3),
+      Eq(DerivedFilesRebuildInfo(
           /*needs_document_store_derived_files_rebuild_in=*/false,
           /*needs_schema_store_derived_files_rebuild_in=*/false,
           /*needs_term_index_rebuild_in=*/false,
@@ -1336,6 +1337,34 @@ TEST(VersionUtilTest, SchemaDatabaseMigrationNotRequired) {
   EXPECT_FALSE(SchemaDatabaseMigrationRequired(previous_version_proto));
 }
 
+TEST(VersionUtilTest,
+     IcingSearchEngineOptionsToVersionProto_qualifiedIdJoinIndexV3_enabled) {
+  IcingSearchEngineOptions options;
+  options.set_enable_qualified_id_join_index_v3(true);
+
+  IcingSearchEngineVersionProto version_proto;
+  AddEnabledFeatures(options, &version_proto);
+  EXPECT_THAT(
+      version_proto.enabled_features(),
+      Contains(Property(&IcingSearchEngineFeatureInfoProto::feature_type,
+                        IcingSearchEngineFeatureInfoProto::
+                            FEATURE_QUALIFIED_ID_JOIN_INDEX_V3)));
+}
+
+TEST(VersionUtilTest,
+     IcingSearchEngineOptionsToVersionProto_qualifiedIdJoinIndexV3_disabled) {
+  IcingSearchEngineOptions options;
+  options.set_enable_qualified_id_join_index_v3(false);
+
+  IcingSearchEngineVersionProto version_proto;
+  AddEnabledFeatures(options, &version_proto);
+  EXPECT_THAT(
+      version_proto.enabled_features(),
+      Not(Contains(Property(&IcingSearchEngineFeatureInfoProto::feature_type,
+                            IcingSearchEngineFeatureInfoProto::
+                                FEATURE_QUALIFIED_ID_JOIN_INDEX_V3))));
+}
+
 class VersionUtilFeatureProtoTest
     : public ::testing::TestWithParam<
           IcingSearchEngineFeatureInfoProto::FlaggedFeatureType> {};
@@ -1343,25 +1372,25 @@ class VersionUtilFeatureProtoTest
 TEST_P(VersionUtilFeatureProtoTest, GetFeatureInfoProto) {
   IcingSearchEngineFeatureInfoProto::FlaggedFeatureType feature_type =
       GetParam();
-  DerivedFilesRebuildResult rebuild_result =
-      GetFeatureDerivedFilesRebuildResult(feature_type);
+  DerivedFilesRebuildInfo rebuild_info =
+      GetFeatureDerivedFilesRebuildInfo(feature_type);
 
   IcingSearchEngineFeatureInfoProto feature_info =
       GetFeatureInfoProto(feature_type);
   EXPECT_THAT(feature_info.feature_type(), Eq(feature_type));
 
   EXPECT_THAT(feature_info.needs_document_store_rebuild(),
-              Eq(rebuild_result.needs_document_store_derived_files_rebuild));
+              Eq(rebuild_info.needs_document_store_derived_files_rebuild));
   EXPECT_THAT(feature_info.needs_schema_store_rebuild(),
-              Eq(rebuild_result.needs_schema_store_derived_files_rebuild));
+              Eq(rebuild_info.needs_schema_store_derived_files_rebuild));
   EXPECT_THAT(feature_info.needs_term_index_rebuild(),
-              Eq(rebuild_result.needs_term_index_rebuild));
+              Eq(rebuild_info.needs_term_index_rebuild));
   EXPECT_THAT(feature_info.needs_integer_index_rebuild(),
-              Eq(rebuild_result.needs_integer_index_rebuild));
+              Eq(rebuild_info.needs_integer_index_rebuild));
   EXPECT_THAT(feature_info.needs_qualified_id_join_index_rebuild(),
-              Eq(rebuild_result.needs_qualified_id_join_index_rebuild));
+              Eq(rebuild_info.needs_qualified_id_join_index_rebuild));
   EXPECT_THAT(feature_info.needs_embedding_index_rebuild(),
-              Eq(rebuild_result.needs_embedding_index_rebuild));
+              Eq(rebuild_info.needs_embedding_index_rebuild));
 }
 
 INSTANTIATE_TEST_SUITE_P(
@@ -1373,8 +1402,7 @@ INSTANTIATE_TEST_SUITE_P(
         IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_INDEX,
         IcingSearchEngineFeatureInfoProto::FEATURE_EMBEDDING_QUANTIZATION,
         IcingSearchEngineFeatureInfoProto::FEATURE_SCHEMA_DATABASE,
-        IcingSearchEngineFeatureInfoProto::
-            FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM));
+        IcingSearchEngineFeatureInfoProto::FEATURE_QUALIFIED_ID_JOIN_INDEX_V3));
 
 }  // namespace
 
diff --git a/icing/icing-search-engine-initialize-icu-failure-test-jni-layer.cc b/icing/icing-search-engine-initialize-icu-failure-test-jni-layer.cc
new file mode 100644
index 0000000..1014c9a
--- /dev/null
+++ b/icing/icing-search-engine-initialize-icu-failure-test-jni-layer.cc
@@ -0,0 +1,37 @@
+// Copyright (C) 2019 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include <jni.h>
+
+#include "gtest/gtest.h"
+#include "icing/testing/logging-event-listener.h"
+
+// Global variable used so that the test implementation can access the JNIEnv.
+JNIEnv* g_jenv = nullptr;
+
+extern "C" JNIEXPORT jboolean JNICALL
+Java_icing_jni_IcingSearchEngineInitializeIcuFailureJniTest_testsMain(
+    JNIEnv* env, jclass ignored) {
+  g_jenv = env;
+
+  std::vector<char*> my_argv;
+  char arg[] = "jni-test-lib";
+  my_argv.push_back(arg);
+  int argc = 1;
+  char** argv = &(my_argv[0]);
+  testing::InitGoogleTest(&argc, argv);
+  testing::UnitTest::GetInstance()->listeners().Append(
+      new icing::lib::LoggingEventListener());
+  return RUN_ALL_TESTS() == 0;
+}
diff --git a/icing/icing-search-engine.cc b/icing/icing-search-engine.cc
index 8cfcef9..ee3fced 100644
--- a/icing/icing-search-engine.cc
+++ b/icing/icing-search-engine.cc
@@ -33,12 +33,14 @@
 #include "icing/absl_ports/mutex.h"
 #include "icing/absl_ports/str_cat.h"
 #include "icing/feature-flags.h"
-#include "icing/file/destructible-file.h"
+#include "icing/file/derived-file-util.h"
 #include "icing/file/file-backed-proto.h"
 #include "icing/file/filesystem.h"
+#include "icing/file/marker-file.h"
 #include "icing/file/version-util.h"
 #include "icing/index/data-indexing-handler.h"
 #include "icing/index/embed/embedding-index.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/index/embedding-indexing-handler.h"
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/index/index-processor.h"
@@ -78,6 +80,7 @@
 #include "icing/query/query-features.h"
 #include "icing/query/query-processor.h"
 #include "icing/query/query-results.h"
+#include "icing/query/query-terms.h"
 #include "icing/query/suggestion-processor.h"
 #include "icing/result/page-result.h"
 #include "icing/result/projection-tree.h"
@@ -95,11 +98,15 @@
 #include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/util/clock.h"
 #include "icing/util/data-loss.h"
+#include "icing/util/icu-data-file-helper.h"
 #include "icing/util/logging.h"
 #include "icing/util/status-macros.h"
+#include "icing/util/status-util.h"
 #include "icing/util/tokenized-document.h"
 #include "unicode/uloc.h"
 #include <google/protobuf/repeated_field.h>
@@ -109,6 +116,8 @@ namespace lib {
 
 namespace {
 
+using ::icing::lib::status_util::TransformStatus;
+
 constexpr std::string_view kDocumentSubfolderName = "document_dir";
 constexpr std::string_view kBlobSubfolderName = "blob_dir";
 constexpr std::string_view kIndexSubfolderName = "index_dir";
@@ -117,10 +126,16 @@ constexpr std::string_view kQualifiedIdJoinIndexSubfolderName =
     "qualified_id_join_index_dir";
 constexpr std::string_view kEmbeddingIndexSubfolderName = "embedding_index_dir";
 constexpr std::string_view kSchemaSubfolderName = "schema_dir";
-constexpr std::string_view kSetSchemaMarkerFilename = "set_schema_marker";
 constexpr std::string_view kInitMarkerFilename = "init_marker";
 constexpr std::string_view kOptimizeStatusFilename = "optimize_status";
 
+// - Before we only created a marker file for set schema.
+// - Now, we switch to a general marker file for different operations that are
+//   sensitive to power loss or crash.
+// - In order to make the change compatible with old versions for possible
+//   AppSearch mainline rollback, let's keep the old marker file name.
+constexpr std::string_view kGeneralMarkerFilename = "set_schema_marker";
+
 // The maximum number of unsuccessful initialization attempts from the current
 // state that we will tolerate before deleting all data and starting from a
 // fresh state.
@@ -285,7 +300,7 @@ CreateQualifiedIdJoinIndex(const Filesystem& filesystem,
                            std::string qualified_id_join_index_dir,
                            const IcingSearchEngineOptions& options,
                            const FeatureFlags& feature_flags) {
-  if (options.enable_qualified_id_join_index_v3_and_delete_propagate_from()) {
+  if (options.enable_qualified_id_join_index_v3()) {
     return QualifiedIdJoinIndexImplV3::Create(
         filesystem, std::move(qualified_id_join_index_dir), feature_flags);
   } else {
@@ -349,82 +364,39 @@ std::string MakeSchemaDirectoryPath(const std::string& base_dir) {
   return absl_ports::StrCat(base_dir, "/", kSchemaSubfolderName);
 }
 
-std::string MakeSetSchemaMarkerFilePath(const std::string& base_dir) {
-  return absl_ports::StrCat(base_dir, "/", kSetSchemaMarkerFilename);
-}
-
 std::string MakeInitMarkerFilePath(const std::string& base_dir) {
   return absl_ports::StrCat(base_dir, "/", kInitMarkerFilename);
 }
 
-void TransformStatus(const libtextclassifier3::Status& internal_status,
-                     StatusProto* status_proto) {
-  StatusProto::Code code;
-  if (!internal_status.ok()) {
-    ICING_LOG(WARNING) << "Error: " << internal_status.error_code()
-                       << ", Message: " << internal_status.error_message();
-  }
-  switch (internal_status.CanonicalCode()) {
-    case libtextclassifier3::StatusCode::OK:
-      code = StatusProto::OK;
-      break;
-    case libtextclassifier3::StatusCode::DATA_LOSS:
-      code = StatusProto::WARNING_DATA_LOSS;
-      break;
-    case libtextclassifier3::StatusCode::INVALID_ARGUMENT:
-      code = StatusProto::INVALID_ARGUMENT;
-      break;
-    case libtextclassifier3::StatusCode::NOT_FOUND:
-      code = StatusProto::NOT_FOUND;
-      break;
-    case libtextclassifier3::StatusCode::FAILED_PRECONDITION:
-      code = StatusProto::FAILED_PRECONDITION;
-      break;
-    case libtextclassifier3::StatusCode::ABORTED:
-      code = StatusProto::ABORTED;
-      break;
-    case libtextclassifier3::StatusCode::INTERNAL:
-      // TODO(b/147699081): Cleanup our internal use of INTERNAL since it
-      // doesn't match with what it *should* indicate as described in
-      // go/icing-library-apis.
-      code = StatusProto::INTERNAL;
-      break;
-    case libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED:
-      // TODO(b/147699081): Note that we don't detect all cases of OUT_OF_SPACE
-      // (e.g. if the document log is full). And we use RESOURCE_EXHAUSTED
-      // internally to indicate other resources are exhausted (e.g.
-      // DocHitInfos) - although none of these are exposed through the API.
-      // Consider separating the two cases out more clearly.
-      code = StatusProto::OUT_OF_SPACE;
-      break;
-    case libtextclassifier3::StatusCode::ALREADY_EXISTS:
-      code = StatusProto::ALREADY_EXISTS;
-      break;
-    case libtextclassifier3::StatusCode::CANCELLED:
-      [[fallthrough]];
-    case libtextclassifier3::StatusCode::UNKNOWN:
-      [[fallthrough]];
-    case libtextclassifier3::StatusCode::DEADLINE_EXCEEDED:
-      [[fallthrough]];
-    case libtextclassifier3::StatusCode::PERMISSION_DENIED:
-      [[fallthrough]];
-    case libtextclassifier3::StatusCode::OUT_OF_RANGE:
-      [[fallthrough]];
-    case libtextclassifier3::StatusCode::UNIMPLEMENTED:
-      [[fallthrough]];
-    case libtextclassifier3::StatusCode::UNAVAILABLE:
-      [[fallthrough]];
-    case libtextclassifier3::StatusCode::UNAUTHENTICATED:
-      // Other internal status codes aren't supported externally yet. If it
-      // should be supported, add another switch-case above.
-      ICING_LOG(ERROR) << "Internal status code "
-                       << internal_status.error_code()
-                       << " not supported in the external API";
-      code = StatusProto::UNKNOWN;
-      break;
-  }
-  status_proto->set_code(code);
-  status_proto->set_message(internal_status.error_message());
+std::string MakeGeneralMarkerFilePath(const std::string& base_dir) {
+  return absl_ports::StrCat(base_dir, "/", kGeneralMarkerFilename);
+}
+
+InitializeStatsProto::RecoveryCause TranslateMarkerProtoToRecoveryCause(
+    const IcingSearchEngineMarkerProto& marker_proto) {
+  switch (marker_proto.operation_type()) {
+    case IcingSearchEngineMarkerProto::OperationType::UNKNOWN:
+      return InitializeStatsProto::UNKNOWN_OUT_OF_SYNC;
+    case IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA:
+      return InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC;
+    case IcingSearchEngineMarkerProto::OperationType::OPTIMIZE:
+      return InitializeStatsProto::OPTIMIZE_OUT_OF_SYNC;
+  }
+}
+
+// Prepares the document for indexing. This includes tokenization and dependency
+// enforcement.
+libtextclassifier3::StatusOr<TokenizedDocument> PrepareDocumentForIndexing(
+    const SchemaStore* schema_store,
+    const LanguageSegmenter* language_segmenter, DocumentProto&& document) {
+  ICING_ASSIGN_OR_RETURN(
+      TokenizedDocument tokenized_document,
+      TokenizedDocument::Create(schema_store, language_segmenter,
+                                std::move(document)));
+
+  // TODO(b/384947619): apply dependency enforcement.
+
+  return tokenized_document;
 }
 
 libtextclassifier3::Status RetrieveAndAddDocumentInfo(
@@ -503,6 +475,19 @@ GetRankingStrategyFromScoringSpec(const ScoringSpecProto& scoring_spec) {
   return ScoringSpecProto::RankingStrategy::NONE;
 }
 
+// Calculates the time between the new optimize start time and the last optimize
+// run based on the times recorded in the OptimizeStatusProto.
+int64_t GetTimeSinceLastOptimizeMs(int64_t new_optimize_start_time_ms,
+                                   const OptimizeStatusProto& optimize_status) {
+  int64_t last_successful_optimize_run_time_ms =
+      optimize_status.last_successful_optimize_run_time_ms();
+  int64_t last_attemped_optimize_time =
+      optimize_status.last_attempted_optimize_run_time_ms();
+  return new_optimize_start_time_ms -
+         std::max(last_successful_optimize_run_time_ms,
+                  last_attemped_optimize_time);
+}
+
 }  // namespace
 
 IcingSearchEngine::IcingSearchEngine(const IcingSearchEngineOptions& options,
@@ -517,9 +502,13 @@ IcingSearchEngine::IcingSearchEngine(
     std::unique_ptr<const IcingFilesystem> icing_filesystem,
     std::unique_ptr<Clock> clock, std::unique_ptr<const JniCache> jni_cache)
     : options_(std::move(options)),
-      feature_flags_(options_.enable_scorable_properties(),
+      feature_flags_(options_.allow_circular_schema_definitions(),
+                     options_.enable_scorable_properties(),
                      options_.enable_embedding_quantization(),
-                     options_.enable_repeated_field_joins()),
+                     options_.enable_repeated_field_joins(),
+                     options_.enable_embedding_backup_generation(),
+                     options_.enable_schema_database(),
+                     options_.release_backup_schema_file_if_overlay_present()),
       filesystem_(std::move(filesystem)),
       icing_filesystem_(std::move(icing_filesystem)),
       clock_(std::move(clock)),
@@ -645,6 +634,15 @@ InitializeResultProto IcingSearchEngine::InternalInitialize() {
     return result_proto;
   }
 
+  if (options_.enable_delete_propagation_from() &&
+      !options_.enable_qualified_id_join_index_v3()) {
+    result_status->set_code(StatusProto::INVALID_ARGUMENT);
+    result_status->set_message(
+        "Delete propagation is enabled but qualified id join index v3 is not "
+        "enabled.");
+    return result_proto;
+  }
+
   // Now go ahead and try to initialize.
   libtextclassifier3::Status status = InitializeMembers(initialize_stats);
   if (status.ok() || absl_ports::IsDataLoss(status)) {
@@ -671,13 +669,19 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
         "Could not create directory: ", options_.base_dir()));
   }
 
-  // Check to see if the marker file exists and if we've already passed our max
-  // number of init attempts.
+  // Check to see if the init marker file exists and if we've already passed our
+  // max number of init attempts.
   libtextclassifier3::Status status = CheckInitMarkerFile(initialize_stats);
   if (!status.ok() && !absl_ports::IsDataLoss(status)) {
     return status;
   }
 
+  // Check to see if the general marker file exists and read its content.
+  std::string general_marker_filepath =
+      MakeGeneralMarkerFilePath(options_.base_dir());
+  std::unique_ptr<IcingSearchEngineMarkerProto> existing_marker_proto =
+      MarkerFile::Postmortem(*filesystem_, general_marker_filepath);
+
   // Do version and flags compatibility check
   // Read version file, determine the state change and rebuild derived files if
   // needed.
@@ -709,9 +713,12 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
       perform_schema_database_migration));
 
   // Step 2: Discard derived files that need to be rebuilt
-  version_util::DerivedFilesRebuildResult required_derived_files_rebuild =
+  derived_file_util::DerivedFilesRebuildInfo required_derived_files_rebuild =
       version_util::CalculateRequiredDerivedFilesRebuild(stored_version_proto,
                                                          current_version_proto);
+  if (existing_marker_proto != nullptr) {
+    required_derived_files_rebuild.RebuildAll();
+  }
   ICING_RETURN_IF_ERROR(DiscardDerivedFiles(required_derived_files_rebuild));
 
   // Step 3: update version files. We need to update both the V1 and V2
@@ -726,22 +733,36 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
 
   ICING_RETURN_IF_ERROR(InitializeSchemaStore(initialize_stats));
 
+  // Initialize ICU if the data file has been provided.
+  libtextclassifier3::Status icu_status =
+      absl_ports::InvalidArgumentError("ICU data file path is empty.");
+  if (!options_.icu_data_file_absolute_path().empty()) {
+    icu_status = icu_data_file_helper::SetUpIcuDataFile(
+        options_.icu_data_file_absolute_path());
+  }
+
+  bool enable_icu = icu_status.ok();
+  TransformStatus(icu_status,
+                  initialize_stats->mutable_initialize_icu_data_status());
+
   // TODO(b/156383798) : Resolve how to specify the locale.
   language_segmenter_factory::SegmenterOptions segmenter_options(
-      ULOC_US, jni_cache_.get());
+      ULOC_US, jni_cache_.get(), enable_icu);
   TC3_ASSIGN_OR_RETURN(language_segmenter_, language_segmenter_factory::Create(
                                                 std::move(segmenter_options)));
 
+  NormalizerOptions normalizer_options(
+      /*max_term_byte_size=*/options_.max_token_length(), enable_icu);
   TC3_ASSIGN_OR_RETURN(normalizer_,
-                       normalizer_factory::Create(options_.max_token_length()));
-
-  std::string marker_filepath =
-      MakeSetSchemaMarkerFilePath(options_.base_dir());
+                       normalizer_factory::Create(normalizer_options));
 
   libtextclassifier3::Status index_init_status;
   if (absl_ports::IsNotFound(schema_store_->GetSchema().status())) {
-    // The schema was either lost or never set before. Wipe out the doc store
-    // and index directories and initialize them from scratch.
+    // Case 1: schema not found.
+    //
+    // - The schema was either lost or never set before.
+    // - Wipe out the doc store and index directories and initialize them from
+    //   scratch.
     const std::string doc_store_dir =
         MakeDocumentDirectoryPath(options_.base_dir());
     const std::string integer_index_dir =
@@ -766,146 +787,101 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
           ", ", qualified_id_join_index_dir, ", ", embedding_index_dir, ", ",
           blob_store_dir, " and ", doc_store_dir));
     }
+
+    // Initialize (empty) blob store.
     if (options_.enable_blob_store()) {
       ICING_RETURN_IF_ERROR(
           InitializeBlobStore(options_.orphan_blob_time_to_live_ms(),
                               options_.blob_store_compression_level()));
     }
+
+    // Initialize (empty) document store.
     ICING_ASSIGN_OR_RETURN(
         bool document_store_derived_files_regenerated,
         InitializeDocumentStore(
             /*force_recovery_and_revalidate_documents=*/false,
             initialize_stats));
+
+    // Initialize (empty) index.
     index_init_status = InitializeIndex(
         document_store_derived_files_regenerated, initialize_stats);
     if (!index_init_status.ok() && !absl_ports::IsDataLoss(index_init_status)) {
       return index_init_status;
     }
-  } else if (filesystem_->FileExists(marker_filepath.c_str())) {
-    // If the marker file is still around then something wonky happened when we
-    // last tried to set the schema.
-    //
-    // Since we're going to rebuild all indices in this case, the return value
-    // of InitializeDocumentStore (document_store_derived_files_regenerated) is
-    // unused.
-    if (options_.enable_blob_store()) {
-      ICING_RETURN_IF_ERROR(
-          InitializeBlobStore(options_.orphan_blob_time_to_live_ms(),
-                              options_.blob_store_compression_level()));
-    }
-    ICING_RETURN_IF_ERROR(InitializeDocumentStore(
-        /*force_recovery_and_revalidate_documents=*/true, initialize_stats));
-
-    // We're going to need to build the index from scratch. So just delete its
-    // directory now.
-    // Discard index directory and instantiate a new one.
-    Index::Options index_options(index_dir, options_.index_merge_size(),
-                                 /*lite_index_sort_at_indexing=*/true,
-                                 options_.lite_index_sort_size());
-    if (!filesystem_->DeleteDirectoryRecursively(index_dir.c_str()) ||
-        !filesystem_->CreateDirectoryRecursively(index_dir.c_str())) {
-      return absl_ports::InternalError(
-          absl_ports::StrCat("Could not recreate directory: ", index_dir));
-    }
-    ICING_ASSIGN_OR_RETURN(index_,
-                           Index::Create(index_options, filesystem_.get(),
-                                         icing_filesystem_.get()));
 
-    // Discard integer index directory and instantiate a new one.
-    std::string integer_index_dir =
-        MakeIntegerIndexWorkingPath(options_.base_dir());
-    ICING_RETURN_IF_ERROR(
-        IntegerIndex::Discard(*filesystem_, integer_index_dir));
-    ICING_ASSIGN_OR_RETURN(
-        integer_index_,
-        IntegerIndex::Create(*filesystem_, std::move(integer_index_dir),
-                             options_.integer_index_bucket_split_threshold(),
-                             options_.pre_mapping_fbv()));
-
-    // Discard qualified id join index directory and instantiate a new one.
-    std::string qualified_id_join_index_dir =
-        MakeQualifiedIdJoinIndexWorkingPath(options_.base_dir());
-    ICING_RETURN_IF_ERROR(QualifiedIdJoinIndex::Discard(
-        *filesystem_, qualified_id_join_index_dir));
-    ICING_ASSIGN_OR_RETURN(
-        qualified_id_join_index_,
-        CreateQualifiedIdJoinIndex(*filesystem_,
-                                   std::move(qualified_id_join_index_dir),
-                                   options_, feature_flags_));
-
-    // Discard embedding index directory and instantiate a new one.
-    std::string embedding_index_dir =
-        MakeEmbeddingIndexWorkingPath(options_.base_dir());
-    ICING_RETURN_IF_ERROR(
-        EmbeddingIndex::Discard(*filesystem_, embedding_index_dir));
-    ICING_ASSIGN_OR_RETURN(
-        embedding_index_,
-        EmbeddingIndex::Create(filesystem_.get(), embedding_index_dir,
-                               clock_.get(), &feature_flags_));
-
-    std::unique_ptr<Timer> restore_timer = clock_->GetNewTimer();
-    IndexRestorationResult restore_result = RestoreIndexIfNeeded();
-    index_init_status = std::move(restore_result.status);
-    // DATA_LOSS means that we have successfully initialized and re-added
-    // content to the index. Some indexed content was lost, but otherwise the
-    // index is in a valid state and can be queried.
-    if (!index_init_status.ok() && !absl_ports::IsDataLoss(index_init_status)) {
-      return index_init_status;
-    }
-
-    // Delete the marker file to indicate that everything is now in sync with
-    // whatever changes were made to the schema.
-    filesystem_->DeleteFile(marker_filepath.c_str());
+    // Delete the marker file regardless of its existence. Normally when the
+    // schema is not found, the marker file should not exist. But in case it
+    // does, we should delete it indicating that everything is now in sync.
+    filesystem_->DeleteFile(general_marker_filepath.c_str());
+  } else if (existing_marker_proto != nullptr ||
+             version_state_change != version_util::StateChange::kCompatible) {
+    // Case 2: any of the following conditions is true:
+    // - Marker file presence: indicates inconsistent state, possibly due to
+    //   crash or power loss when we last tried to do some complex operations
+    //   (e.g. SetSchema, Optimize).
+    // - Incompatible version change: requires some derived files to be rebuilt.
+    //
+    // In either case, related derived files have already been discarded above.
+    // We just need to re-initialize each component here.
 
-    initialize_stats->set_index_restoration_latency_ms(
-        restore_timer->GetElapsedMilliseconds());
-    initialize_stats->set_index_restoration_cause(
-        InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC);
-    initialize_stats->set_integer_index_restoration_cause(
-        InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC);
-    initialize_stats->set_qualified_id_join_index_restoration_cause(
-        InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC);
-    initialize_stats->set_embedding_index_restoration_cause(
-        InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC);
-  } else if (version_state_change != version_util::StateChange::kCompatible) {
     if (options_.enable_blob_store()) {
       ICING_RETURN_IF_ERROR(
           InitializeBlobStore(options_.orphan_blob_time_to_live_ms(),
                               options_.blob_store_compression_level()));
     }
+
+    // Initialize document store. This also rebuilds all derived files in the
+    // document store.
     ICING_ASSIGN_OR_RETURN(bool document_store_derived_files_regenerated,
                            InitializeDocumentStore(
                                /*force_recovery_and_revalidate_documents=*/true,
                                initialize_stats));
+
     index_init_status = InitializeIndex(
         document_store_derived_files_regenerated, initialize_stats);
     if (!index_init_status.ok() && !absl_ports::IsDataLoss(index_init_status)) {
       return index_init_status;
     }
 
-    initialize_stats->set_schema_store_recovery_cause(
-        InitializeStatsProto::VERSION_CHANGED);
-    initialize_stats->set_document_store_recovery_cause(
-        InitializeStatsProto::VERSION_CHANGED);
-    initialize_stats->set_index_restoration_cause(
-        InitializeStatsProto::VERSION_CHANGED);
-    initialize_stats->set_integer_index_restoration_cause(
-        InitializeStatsProto::VERSION_CHANGED);
+    // Delete the marker file to indicate that everything is now in sync.
+    filesystem_->DeleteFile(general_marker_filepath.c_str());
+
+    // Set recovery cause according to the condition.
+    InitializeStatsProto::RecoveryCause recovery_cause =
+        existing_marker_proto != nullptr
+            ? TranslateMarkerProtoToRecoveryCause(*existing_marker_proto)
+            : InitializeStatsProto::VERSION_CHANGED;
+    initialize_stats->set_schema_store_recovery_cause(recovery_cause);
+    initialize_stats->set_document_store_recovery_cause(recovery_cause);
+    initialize_stats->set_index_restoration_cause(recovery_cause);
+    initialize_stats->set_integer_index_restoration_cause(recovery_cause);
     initialize_stats->set_qualified_id_join_index_restoration_cause(
-        InitializeStatsProto::VERSION_CHANGED);
-    initialize_stats->set_embedding_index_restoration_cause(
-        InitializeStatsProto::VERSION_CHANGED);
+        recovery_cause);
+    initialize_stats->set_embedding_index_restoration_cause(recovery_cause);
   } else {
+    // Case 3: normal initialization without version change, but it is still
+    //         possible that the feature flags have changed and some derived
+    //         files need to be rebuilt.
+    //
+    // - Incompatible derived files have already been discarded above. We just
+    //   need to re-initialize each component here.
+
+    // Initialize blob store.
     if (options_.enable_blob_store()) {
       ICING_RETURN_IF_ERROR(
           InitializeBlobStore(options_.orphan_blob_time_to_live_ms(),
                               options_.blob_store_compression_level()));
     }
+
+    // Initialize document store. This also rebuilds all derived files in the
+    // document store.
     ICING_ASSIGN_OR_RETURN(
         bool document_store_derived_files_regenerated,
         InitializeDocumentStore(
             /*force_recovery_and_revalidate_documents=*/false,
             initialize_stats));
+
+    // Initialize index. This also rebuilds all indices.
     index_init_status = InitializeIndex(
         document_store_derived_files_regenerated, initialize_stats);
     if (!index_init_status.ok() && !absl_ports::IsDataLoss(index_init_status)) {
@@ -966,8 +942,7 @@ libtextclassifier3::Status IcingSearchEngine::InitializeSchemaStore(
   ICING_ASSIGN_OR_RETURN(
       schema_store_,
       SchemaStore::Create(filesystem_.get(), schema_store_dir, clock_.get(),
-                          &feature_flags_, options_.enable_schema_database(),
-                          initialize_stats));
+                          &feature_flags_, initialize_stats));
 
   return libtextclassifier3::Status::OK;
 }
@@ -1008,7 +983,8 @@ libtextclassifier3::Status IcingSearchEngine::InitializeBlobStore(
       auto blob_store_or,
       BlobStore::Create(filesystem_.get(), blob_dir, clock_.get(),
                         orphan_blob_time_to_live_ms,
-                        blob_store_compression_level));
+                        blob_store_compression_level,
+                        options_.manage_blob_files()));
   blob_store_ = std::make_unique<BlobStore>(std::move(blob_store_or));
   return libtextclassifier3::Status::OK;
 }
@@ -1087,7 +1063,7 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
       MakeQualifiedIdJoinIndexWorkingPath(options_.base_dir());
   InitializeStatsProto::RecoveryCause qualified_id_join_index_recovery_cause;
   if (document_store_derived_files_regenerated &&
-      !options_.enable_qualified_id_join_index_v3_and_delete_propagate_from()) {
+      !options_.enable_qualified_id_join_index_v3()) {
     // V2 qualified id join index depends on document store derived files, so we
     // have to rebuild it from scratch if
     // document_store_derived_files_regenerated is true.
@@ -1155,24 +1131,27 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
 
   std::unique_ptr<Timer> restore_timer = clock_->GetNewTimer();
   IndexRestorationResult restore_result = RestoreIndexIfNeeded();
-  if (restore_result.index_needed_restoration ||
-      restore_result.integer_index_needed_restoration ||
-      restore_result.qualified_id_join_index_needed_restoration) {
+  if (restore_result.has_index_restored ||
+      restore_result.has_integer_index_restored ||
+      restore_result.has_qualified_id_join_index_restored ||
+      restore_result.has_embedding_index_restored) {
     initialize_stats->set_index_restoration_latency_ms(
         restore_timer->GetElapsedMilliseconds());
+    initialize_stats->set_num_failed_reindexed_documents(
+        restore_result.num_failed_reindexed_documents);
 
-    if (restore_result.index_needed_restoration) {
+    if (restore_result.has_index_restored) {
       initialize_stats->set_index_restoration_cause(index_recovery_cause);
     }
-    if (restore_result.integer_index_needed_restoration) {
+    if (restore_result.has_integer_index_restored) {
       initialize_stats->set_integer_index_restoration_cause(
           integer_index_recovery_cause);
     }
-    if (restore_result.qualified_id_join_index_needed_restoration) {
+    if (restore_result.has_qualified_id_join_index_restored) {
       initialize_stats->set_qualified_id_join_index_restoration_cause(
           qualified_id_join_index_recovery_cause);
     }
-    if (restore_result.embedding_index_needed_restoration) {
+    if (restore_result.has_embedding_index_restored) {
       initialize_stats->set_embedding_index_restoration_cause(
           embedding_index_recovery_cause);
     }
@@ -1187,6 +1166,16 @@ SetSchemaResultProto IcingSearchEngine::SetSchema(
 
 SetSchemaResultProto IcingSearchEngine::SetSchema(
     SchemaProto&& new_schema, bool ignore_errors_and_delete_documents) {
+  SetSchemaRequestProto set_schema_request;
+  *set_schema_request.mutable_schema() = std::move(new_schema);
+  set_schema_request.set_ignore_errors_and_delete_documents(
+      ignore_errors_and_delete_documents);
+
+  return SetSchema(std::move(set_schema_request));
+}
+
+SetSchemaResultProto IcingSearchEngine::SetSchema(
+    SetSchemaRequestProto&& set_schema_request) {
   ICING_VLOG(1) << "Setting new Schema";
 
   SetSchemaResultProto result_proto;
@@ -1209,18 +1198,27 @@ SetSchemaResultProto IcingSearchEngine::SetSchema(
   }
   bool lost_previous_schema = lost_previous_schema_or.ValueOrDie();
 
-  std::string marker_filepath =
-      MakeSetSchemaMarkerFilePath(options_.base_dir());
   // Create the marker file indicating that we are going to apply a schema
-  // change. No need to write anything to the marker file - its existence is the
-  // only thing that matters. The marker file is used to indicate if we
-  // encountered a crash or a power loss while updating the schema and other
-  // files. So set it up to be deleted as long as we return from this function.
-  DestructibleFile marker_file(marker_filepath, filesystem_.get());
-
-  auto set_schema_result_or = schema_store_->SetSchema(
-      std::move(new_schema), ignore_errors_and_delete_documents,
-      options_.allow_circular_schema_definitions());
+  // change.
+  // Normally it will be deleted when we return from this function, but if Icing
+  // crashes or loses power while updating the schema and other files, then the
+  // marker file will remain. During initialization when restarting, we will
+  // detect the marker file and rebuild all derived files to recover from any
+  // inconsistent state that may have been caused by the incomplete SetSchema.
+  std::string marker_filepath = MakeGeneralMarkerFilePath(options_.base_dir());
+  libtextclassifier3::StatusOr<std::unique_ptr<MarkerFile>> marker_file_or =
+      MarkerFile::Create(
+          filesystem_.get(), std::move(marker_filepath),
+          IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA);
+  if (!marker_file_or.ok()) {
+    TransformStatus(marker_file_or.status(), result_status);
+    return result_proto;
+  }
+  std::unique_ptr<MarkerFile> marker_file =
+      std::move(marker_file_or).ValueOrDie();
+
+  auto set_schema_result_or =
+      schema_store_->SetSchema(std::move(set_schema_request));
   if (!set_schema_result_or.ok()) {
     TransformStatus(set_schema_result_or.status(), result_status);
     return result_proto;
@@ -1412,6 +1410,28 @@ GetSchemaTypeResultProto IcingSearchEngine::GetSchemaType(
   return result_proto;
 }
 
+BatchPutResultProto IcingSearchEngine::BatchPut(
+    PutDocumentRequest&& put_document_request) {
+  BatchPutResultProto batch_put_result_proto;
+
+  // TODO(b/394875109): right now we lock in the Put(DocumentProto&&) for each
+  // document. We should considering just locking once for the whole batch here.
+  for (DocumentProto& document_proto :
+       *(put_document_request.mutable_documents())) {
+    batch_put_result_proto.mutable_put_result_protos()->Add(
+        Put(std::move(document_proto)));
+  }
+
+  if (put_document_request.persist_type() != PersistType::UNKNOWN) {
+    *batch_put_result_proto.mutable_persist_to_disk_result_proto() =
+        PersistToDisk(put_document_request.persist_type());
+  }
+
+  batch_put_result_proto.mutable_status()->set_code(StatusProto::OK);
+
+  return batch_put_result_proto;
+}
+
 PutResultProto IcingSearchEngine::Put(const DocumentProto& document) {
   return Put(DocumentProto(document));
 }
@@ -1420,6 +1440,8 @@ PutResultProto IcingSearchEngine::Put(DocumentProto&& document) {
   ICING_VLOG(1) << "Writing document to document store";
 
   PutResultProto result_proto;
+  result_proto.set_uri(document.uri());
+
   StatusProto* result_status = result_proto.mutable_status();
   PutDocumentStatsProto* put_document_stats =
       result_proto.mutable_put_document_stats();
@@ -1437,7 +1459,7 @@ PutResultProto IcingSearchEngine::Put(DocumentProto&& document) {
     return result_proto;
   }
 
-  auto tokenized_document_or = TokenizedDocument::Create(
+  auto tokenized_document_or = PrepareDocumentForIndexing(
       schema_store_.get(), language_segmenter_.get(), std::move(document));
   if (!tokenized_document_or.ok()) {
     TransformStatus(tokenized_document_or.status(), result_status);
@@ -1466,6 +1488,11 @@ PutResultProto IcingSearchEngine::Put(DocumentProto&& document) {
   IndexProcessor index_processor(
       std::move(data_indexing_handlers_or).ValueOrDie(), clock_.get());
 
+  // TODO(b/397769319): Currently, we may do a merge in the middle of a
+  // PutBatch. It might be better behavior to instead:
+  // - only merge before the last document if the LiteIndex is actually full
+  // - merge on the last document if the LiteIndex is full or wants_merge (lower
+  //   threshold)
   auto index_status = index_processor.IndexDocument(
       tokenized_document, document_id, old_document_id, put_document_stats);
   // Getting an internal error from the index could possibly mean that the index
@@ -1552,6 +1579,71 @@ GetResultProto IcingSearchEngine::Get(const std::string_view name_space,
   return result_proto;
 }
 
+BatchGetResultProto IcingSearchEngine::BatchGet(
+    GetResultSpecProto&& get_result_spec) {
+  const std::string& name_space = get_result_spec.namespace_requested();
+  BatchGetResultProto batch_get_result_proto;
+
+  if (get_result_spec.num_total_document_bytes_to_return() <= 0) {
+    StatusProto* result_status = batch_get_result_proto.mutable_status();
+    result_status->set_code(StatusProto::INVALID_ARGUMENT);
+    result_status->set_message(
+        "num_total_document_bytes_to_return must be greater than 0.");
+    return batch_get_result_proto;
+  }
+
+  // TODO(b/394875109) Right now we lock in Get(namespace, id, result_spec) for
+  // each id. We should consider locking here for the entire batch request.
+  int32_t total_docs_bytes_so_far = 0;
+  bool skip_remaining_docs = false;
+  for (std::string& id : *get_result_spec.mutable_ids()) {
+    if (skip_remaining_docs) {
+      // We simply set the status to OUT_OF_SPACE for the remaining docs, even
+      // if some docs might be small enough to fit in the result. We are doing
+      // this to avoid the worst case that all remaining docs are too big, and
+      // we read all of them out but fail to put them in the result.
+      GetResultProto result_proto;
+      // Id is redundant for a single Get call, so we only set it in BatchGet.
+      result_proto.set_uri(std::move(id));
+      StatusProto* result_status = result_proto.mutable_status();
+      result_status->set_code(StatusProto::ABORTED);
+      batch_get_result_proto.mutable_get_result_protos()->Add(
+          std::move(result_proto));
+      continue;
+    }
+
+    // We try to check each doc so smaller docs at the end of the list can
+    // still be put into the result.
+    GetResultProto result_proto = Get(name_space, id, get_result_spec);
+    // Id is redundant for a single Get call, so we only set it in BatchGet.
+    result_proto.set_uri(std::move(id));
+    if (result_proto.status().code() == StatusProto::OK) {
+      // We get the doc successfully. Check if we can add it to the result.
+      size_t document_bytes = result_proto.document().ByteSizeLong();
+      if (document_bytes <=
+          get_result_spec.num_total_document_bytes_to_return() -
+              total_docs_bytes_so_far) {
+        total_docs_bytes_so_far += document_bytes;
+      } else {
+        result_proto.clear_document();
+        StatusProto* result_status = result_proto.mutable_status();
+        result_status->set_code(StatusProto::ABORTED);
+        // We skip the remaining docs even if there might be smaller docs
+        // afterwards. This is to avoid the worst case that all remaining docs
+        // are too big, and we read all of them out but fail to put them in the
+        // result.
+        skip_remaining_docs = true;
+      }
+    }
+    batch_get_result_proto.mutable_get_result_protos()->Add(
+        std::move(result_proto));
+  }
+  batch_get_result_proto.mutable_status()->set_code(
+      icing::lib::StatusProto::OK);
+
+  return batch_get_result_proto;
+}
+
 ReportUsageResultProto IcingSearchEngine::ReportUsage(
     const UsageReport& usage_report) {
   ReportUsageResultProto result_proto;
@@ -1787,7 +1879,8 @@ DeleteByQueryResultProto IcingSearchEngine::DeleteByQuery(
 
   int64_t current_time_ms = clock_->GetSystemTimeMilliseconds();
   auto query_results_or = query_processor->ParseSearch(
-      search_spec, ScoringSpecProto::RankingStrategy::NONE, current_time_ms);
+      search_spec, ScoringSpecProto::RankingStrategy::NONE,
+      /*get_embedding_match_info=*/false, current_time_ms);
   if (!query_results_or.ok()) {
     TransformStatus(query_results_or.status(), result_status);
     delete_stats->set_parse_query_latency_ms(
@@ -1808,6 +1901,7 @@ DeleteByQueryResultProto IcingSearchEngine::DeleteByQuery(
       deleted_info_map;
 
   component_timer = clock_->GetNewTimer();
+  std::unordered_set<DocumentId> deleted_document_ids;
   while (query_results.root_iterator->Advance().ok()) {
     ICING_VLOG(3) << "Deleting doc "
                   << query_results.root_iterator->doc_hit_info().document_id();
@@ -1823,6 +1917,18 @@ DeleteByQueryResultProto IcingSearchEngine::DeleteByQuery(
         return result_proto;
       }
     }
+
+    // Insert the deleted document id into the set, regardless of whether it has
+    // been deleted or expired. This is to ensure that we propagate the delete
+    // operation for the document. If the document has already been deleted,
+    // then the delete propagation was completed in the previous delete request,
+    // and even though we still add the document id to the set, it will not
+    // affect the delete propagation.
+    //
+    // TODO(b/376913014): handle expiry propagation.
+    deleted_document_ids.insert(
+        query_results.root_iterator->doc_hit_info().document_id());
+
     status = document_store_->Delete(
         query_results.root_iterator->doc_hit_info().document_id(),
         current_time_ms);
@@ -1833,6 +1939,18 @@ DeleteByQueryResultProto IcingSearchEngine::DeleteByQuery(
       return result_proto;
     }
   }
+
+  // Propagate deletion.
+  libtextclassifier3::StatusOr<int> propagated_child_docs_deleted_or =
+      PropagateDelete(deleted_document_ids, current_time_ms);
+  if (!propagated_child_docs_deleted_or.ok()) {
+    TransformStatus(propagated_child_docs_deleted_or.status(), result_status);
+    delete_stats->set_document_removal_latency_ms(
+        component_timer->GetElapsedMilliseconds());
+    return result_proto;
+  }
+  num_deleted += propagated_child_docs_deleted_or.ValueOrDie();
+
   delete_stats->set_document_removal_latency_ms(
       component_timer->GetElapsedMilliseconds());
   int term_count = 0;
@@ -1857,13 +1975,21 @@ libtextclassifier3::StatusOr<int> IcingSearchEngine::PropagateDelete(
     int64_t current_time_ms) {
   int propagated_child_docs_deleted = 0;
 
-  if (!options_.enable_qualified_id_join_index_v3_and_delete_propagate_from() ||
-      qualified_id_join_index_->version() !=
-          QualifiedIdJoinIndex::Version::kV3) {
-    // No-op if delete propagation is disabled or the join index is not v3.
+  if (!options_.enable_delete_propagation_from()) {
+    // No-op if delete propagation is disabled.
     return propagated_child_docs_deleted;
   }
 
+  if (qualified_id_join_index_->version() !=
+      QualifiedIdJoinIndex::Version::kV3) {
+    // This should not happen since Icing should've failed initialization with
+    // delete propagation enabled and join index v3 disabled.
+    // But let's check it here again just in case.
+    return absl_ports::FailedPreconditionError(
+        "Delete propagation is enabled but qualified id join index v3 is not "
+        "used.");
+  }
+
   // Create join processor to get propagated child documents to delete.
   JoinProcessor join_processor(document_store_.get(), schema_store_.get(),
                                qualified_id_join_index_.get(), current_time_ms);
@@ -1928,11 +2054,59 @@ OptimizeResultProto IcingSearchEngine::Optimize() {
     return result_proto;
   }
 
+  int64_t optimize_start_time_ms = clock_->GetSystemTimeMilliseconds();
   OptimizeStatsProto* optimize_stats = result_proto.mutable_optimize_stats();
   ScopedTimer optimize_timer(
       clock_->GetNewTimer(),
       [optimize_stats](int64_t t) { optimize_stats->set_latency_ms(t); });
 
+  // Read the optimize status and assign previous_optimize_status. This is the
+  // time that we last ran optimize.
+  // previous_optimize_status will remain as nullptr if we have trouble reading
+  // the status or this is the first time that we've ever run.
+  std::unique_ptr<OptimizeStatusProto> previous_optimize_status;
+  std::string optimize_status_filename =
+      absl_ports::StrCat(options_.base_dir(), "/", kOptimizeStatusFilename);
+  FileBackedProto<OptimizeStatusProto> optimize_status_file(
+      *filesystem_, optimize_status_filename);
+  auto optimize_status_or = optimize_status_file.Read();
+  if (optimize_status_or.ok()) {
+    previous_optimize_status =
+        std::make_unique<OptimizeStatusProto>(*optimize_status_or.ValueOrDie());
+  }
+
+  if (options_.calculate_time_since_last_attempted_optimize()) {
+    // This is only initialized if we successfully read the status file. Skip
+    // this step if uninitialized.
+    if (previous_optimize_status != nullptr) {
+      int64_t time_since_last_optimize_ms = GetTimeSinceLastOptimizeMs(
+          optimize_start_time_ms, *previous_optimize_status);
+      optimize_stats->set_time_since_last_optimize_ms(
+          time_since_last_optimize_ms);
+      int64_t last_successful_optimize_run_time_ms =
+          previous_optimize_status->last_successful_optimize_run_time_ms();
+      optimize_stats->set_time_since_last_successful_optimize_ms(
+          optimize_start_time_ms - last_successful_optimize_run_time_ms);
+    }
+
+    // Copy the previous optimize status or initialize a default one if we
+    // failed to read it.
+    std::unique_ptr<OptimizeStatusProto> new_optimize_status =
+        previous_optimize_status != nullptr
+            ? std::make_unique<OptimizeStatusProto>(*previous_optimize_status)
+            : std::make_unique<OptimizeStatusProto>();
+
+    // Write the new optimize start time.
+    new_optimize_status->set_last_attempted_optimize_run_time_ms(
+        optimize_start_time_ms);
+    libtextclassifier3::Status write_status =
+        optimize_status_file.Write(std::move(new_optimize_status));
+    if (!write_status.ok()) {
+      ICING_LOG(ERROR) << "Failed to write optimize status:\n"
+                       << write_status.error_message();
+    }
+  }
+
   // Flushes data to disk before doing optimization
   auto status = InternalPersistToDisk(PersistType::FULL);
   if (!status.ok()) {
@@ -1940,17 +2114,40 @@ OptimizeResultProto IcingSearchEngine::Optimize() {
     return result_proto;
   }
 
-  int64_t before_size = filesystem_->GetDiskUsage(options_.base_dir().c_str());
-  optimize_stats->set_storage_size_before(
-      Filesystem::SanitizeFileSize(before_size));
-
-  // Get all expired blob handles
+  // Get all expired blob handles. This can be done before the marker file since
+  // it is a const function for computing "potentially optimizable blob handles"
+  // and won't change any underlying data.
   std::unordered_set<std::string> potentially_optimizable_blob_handles;
   if (blob_store_ != nullptr) {
     potentially_optimizable_blob_handles =
         blob_store_->GetPotentiallyOptimizableBlobHandles();
   }
 
+  std::unique_ptr<MarkerFile> marker_file;
+  if (options_.enable_marker_file_for_optimize()) {
+    // Create the marker file indicating that we are going to optimize.
+    // Normally it will be deleted when we return from this function, but if
+    // Icing crashes or loses power while optimizing, then the marker file will
+    // remain. During initialization when restarting, we will detect the marker
+    // file and rebuild all derived files to recover from any inconsistent state
+    // that may have been caused by the incomplete optimization.
+    std::string marker_filepath =
+        MakeGeneralMarkerFilePath(options_.base_dir());
+    libtextclassifier3::StatusOr<std::unique_ptr<MarkerFile>> marker_file_or =
+        MarkerFile::Create(
+            filesystem_.get(), marker_filepath,
+            IcingSearchEngineMarkerProto::OperationType::OPTIMIZE);
+    if (!marker_file_or.ok()) {
+      TransformStatus(marker_file_or.status(), result_status);
+      return result_proto;
+    }
+    marker_file = std::move(marker_file_or).ValueOrDie();
+  }
+
+  int64_t before_size = filesystem_->GetDiskUsage(options_.base_dir().c_str());
+  optimize_stats->set_storage_size_before(
+      Filesystem::SanitizeFileSize(before_size));
+
   // TODO(b/143646633): figure out if we need to optimize index and doc store
   // at the same time.
   std::unique_ptr<Timer> optimize_doc_store_timer = clock_->GetNewTimer();
@@ -1974,13 +2171,20 @@ OptimizeResultProto IcingSearchEngine::Optimize() {
       optimize_result_or.status();
   if (blob_store_ != nullptr && doc_store_optimize_result_status.ok()) {
     // optimize blob store
-    libtextclassifier3::Status blob_store_optimize_status =
-        blob_store_->Optimize(
+    libtextclassifier3::StatusOr<std::vector<std::string>>
+        blob_file_names_to_remove_or = blob_store_->Optimize(
             optimize_result_or.ValueOrDie().dead_blob_handles);
-    if (!blob_store_optimize_status.ok()) {
-      TransformStatus(status, result_status);
+    if (!blob_file_names_to_remove_or.ok()) {
+      TransformStatus(blob_file_names_to_remove_or.status(), result_status);
       return result_proto;
     }
+    result_proto.mutable_blob_file_names_to_remove()->Reserve(
+        blob_file_names_to_remove_or.ValueOrDie().size());
+    for (std::string& blob_file_name_to_remove :
+         blob_file_names_to_remove_or.ValueOrDie()) {
+      result_proto.add_blob_file_names_to_remove(
+          std::move(blob_file_name_to_remove));
+    }
   }
 
   // The status is either OK or DATA_LOSS. The optimized document store is
@@ -2084,25 +2288,25 @@ OptimizeResultProto IcingSearchEngine::Optimize() {
   optimize_stats->set_index_restoration_latency_ms(
       optimize_index_timer->GetElapsedMilliseconds());
 
-  // Read the optimize status to get the time that we last ran.
-  std::string optimize_status_filename =
-      absl_ports::StrCat(options_.base_dir(), "/", kOptimizeStatusFilename);
-  FileBackedProto<OptimizeStatusProto> optimize_status_file(
-      *filesystem_, optimize_status_filename);
-  auto optimize_status_or = optimize_status_file.Read();
-  int64_t current_time = clock_->GetSystemTimeMilliseconds();
-  if (optimize_status_or.ok()) {
-    // If we have trouble reading the status or this is the first time that
-    // we've ever run, don't set this field.
-    optimize_stats->set_time_since_last_optimize_ms(
-        current_time - optimize_status_or.ValueOrDie()
-                           ->last_successful_optimize_run_time_ms());
+  // Get the time since we last ran optimize using times recorded in the
+  // previous optimize status.
+  if (!options_.calculate_time_since_last_attempted_optimize()) {
+    if (previous_optimize_status) {
+      // This is only initialized if we successfully read the status. If we have
+      // trouble reading the status or this is the first time that we've ever
+      // run, don't set this field.
+      optimize_stats->set_time_since_last_optimize_ms(
+          optimize_start_time_ms -
+          previous_optimize_status->last_successful_optimize_run_time_ms());
+    }
   }
 
   // Update the status for this run and write it.
-  auto optimize_status = std::make_unique<OptimizeStatusProto>();
-  optimize_status->set_last_successful_optimize_run_time_ms(current_time);
-  auto write_status = optimize_status_file.Write(std::move(optimize_status));
+  auto new_optimize_status = std::make_unique<OptimizeStatusProto>();
+  new_optimize_status->set_last_successful_optimize_run_time_ms(
+      optimize_start_time_ms);
+  auto write_status =
+      optimize_status_file.Write(std::move(new_optimize_status));
   if (!write_status.ok()) {
     ICING_LOG(ERROR) << "Failed to write optimize status:\n"
                      << write_status.error_message();
@@ -2147,9 +2351,16 @@ GetOptimizeInfoResultProto IcingSearchEngine::GetOptimizeInfo() {
   if (optimize_status_or.ok()) {
     // If we have trouble reading the status or this is the first time that
     // we've ever run, don't set this field.
-    result_proto.set_time_since_last_optimize_ms(
-        current_time - optimize_status_or.ValueOrDie()
-                           ->last_successful_optimize_run_time_ms());
+    int64_t time_since_last_optimize_ms;
+    if (options_.calculate_time_since_last_attempted_optimize()) {
+      time_since_last_optimize_ms = GetTimeSinceLastOptimizeMs(
+          current_time, *optimize_status_or.ValueOrDie());
+    } else {
+      time_since_last_optimize_ms =
+          current_time - optimize_status_or.ValueOrDie()
+                             ->last_successful_optimize_run_time_ms();
+    }
+    result_proto.set_time_since_last_optimize_ms(time_since_last_optimize_ms);
   }
 
   // Get stats from DocumentStore
@@ -2396,7 +2607,9 @@ SearchResultProto IcingSearchEngine::InternalSearch(
 
   const JoinSpecProto& join_spec = search_spec.join_spec();
   std::unique_ptr<JoinChildrenFetcher> join_children_fetcher;
-  std::unique_ptr<ResultAdjustmentInfo> child_result_adjustment_info;
+  ScoringSpecProto child_scoring_spec;
+  EmbeddingQueryResults child_embedding_query_results;
+  SectionRestrictQueryTermsMap child_query_terms;
   int64_t current_time_ms = clock_->GetSystemTimeMilliseconds();
   if (!join_spec.parent_property_expression().empty() &&
       !join_spec.child_property_expression().empty()) {
@@ -2414,7 +2627,7 @@ SearchResultProto IcingSearchEngine::InternalSearch(
     //
     // TODO(b/379288742): Avoid making the copy of the parent schema type alias
     // map.
-    ScoringSpecProto child_scoring_spec = CopyParentSchemaTypeAliasMapToChild(
+    child_scoring_spec = CopyParentSchemaTypeAliasMapToChild(
         scoring_spec, search_spec.join_spec().nested_spec().scoring_spec());
 
     // Process child query
@@ -2442,12 +2655,9 @@ SearchResultProto IcingSearchEngine::InternalSearch(
       return result_proto;
     }
     join_children_fetcher = std::move(join_children_fetcher_or).ValueOrDie();
-
-    // Assign child's ResultAdjustmentInfo.
-    child_result_adjustment_info = std::make_unique<ResultAdjustmentInfo>(
-        join_spec.nested_spec().search_spec(), child_scoring_spec,
-        join_spec.nested_spec().result_spec(), schema_store_.get(),
-        std::move(nested_query_scoring_results.query_terms));
+    child_embedding_query_results =
+        std::move(nested_query_scoring_results.embedding_query_results);
+    child_query_terms = std::move(nested_query_scoring_results.query_terms);
   }
 
   // Process parent query
@@ -2475,11 +2685,7 @@ SearchResultProto IcingSearchEngine::InternalSearch(
     return result_proto;
   }
 
-  // Construct parent's result adjustment info.
-  auto parent_result_adjustment_info = std::make_unique<ResultAdjustmentInfo>(
-      search_spec, scoring_spec, result_spec, schema_store_.get(),
-      std::move(query_scoring_results.query_terms));
-
+  std::unique_ptr<ResultAdjustmentInfo> child_result_adjustment_info;
   std::unique_ptr<ScoredDocumentHitsRanker> ranker;
   if (join_children_fetcher != nullptr) {
     std::unique_ptr<Timer> join_timer = clock_->GetNewTimer();
@@ -2509,6 +2715,24 @@ SearchResultProto IcingSearchEngine::InternalSearch(
             ScoringSpecProto::Order::DESC);
     query_stats->set_ranking_latency_ms(
         component_timer->GetElapsedMilliseconds());
+
+    // Construct the child's result adjustment info.
+    bool get_child_embedding_match_info = join_spec.nested_spec()
+                                              .result_spec()
+                                              .snippet_spec()
+                                              .get_embedding_match_info();
+    std::unordered_set<DocumentId> documents_to_snippet_hint =
+        get_child_embedding_match_info
+            ? ranker->GetTopKChildDocumentIds(join_spec.nested_spec()
+                                                  .result_spec()
+                                                  .snippet_spec()
+                                                  .num_to_snippet())
+            : std::unordered_set<DocumentId>();
+    child_result_adjustment_info = std::make_unique<ResultAdjustmentInfo>(
+        join_spec.nested_spec().search_spec(), child_scoring_spec,
+        join_spec.nested_spec().result_spec(), schema_store_.get(),
+        child_embedding_query_results, std::move(documents_to_snippet_hint),
+        std::move(child_query_terms));
   } else {
     // Non-join query
     std::unique_ptr<Timer> component_timer = clock_->GetNewTimer();
@@ -2522,6 +2746,20 @@ SearchResultProto IcingSearchEngine::InternalSearch(
         component_timer->GetElapsedMilliseconds());
   }
 
+  // Construct the parent's result adjustment info.
+  bool get_embedding_match_info =
+      result_spec.snippet_spec().get_embedding_match_info();
+  std::unordered_set<DocumentId> documents_to_snippet_hint =
+      get_embedding_match_info
+          ? ranker->GetTopKDocumentIds(
+                result_spec.snippet_spec().num_to_snippet())
+          : std::unordered_set<DocumentId>();
+  auto parent_result_adjustment_info = std::make_unique<ResultAdjustmentInfo>(
+      search_spec, scoring_spec, result_spec, schema_store_.get(),
+      query_scoring_results.embedding_query_results,
+      std::move(documents_to_snippet_hint),
+      std::move(query_scoring_results.query_terms));
+
   std::unique_ptr<Timer> component_timer = clock_->GetNewTimer();
   // CacheAndRetrieveFirstPage and retrieves the document protos and snippets if
   // requested
@@ -2604,6 +2842,7 @@ IcingSearchEngine::QueryScoringResults IcingSearchEngine::ProcessQueryAndScore(
         component_timer->GetElapsedMilliseconds());
     return QueryScoringResults(std::move(query_processor_or).status(),
                                /*query_terms_in=*/{},
+                               /*embedding_query_results_in=*/{},
                                /*scored_document_hits_in=*/{});
   }
   std::unique_ptr<QueryProcessor> query_processor =
@@ -2613,7 +2852,8 @@ IcingSearchEngine::QueryScoringResults IcingSearchEngine::ProcessQueryAndScore(
   libtextclassifier3::StatusOr<QueryResults> query_results_or;
   if (ranking_strategy_or.ok()) {
     query_results_or = query_processor->ParseSearch(
-        search_spec, ranking_strategy_or.ValueOrDie(), current_time_ms,
+        search_spec, ranking_strategy_or.ValueOrDie(),
+        result_spec.snippet_spec().get_embedding_match_info(), current_time_ms,
         search_stats);
   } else {
     query_results_or = ranking_strategy_or.status();
@@ -2623,6 +2863,7 @@ IcingSearchEngine::QueryScoringResults IcingSearchEngine::ProcessQueryAndScore(
   if (!query_results_or.ok()) {
     return QueryScoringResults(std::move(query_results_or).status(),
                                /*query_terms_in=*/{},
+                               /*embedding_query_results_in=*/{},
                                /*scored_document_hits_in=*/{});
   }
   QueryResults query_results = std::move(query_results_or).ValueOrDie();
@@ -2649,6 +2890,7 @@ IcingSearchEngine::QueryScoringResults IcingSearchEngine::ProcessQueryAndScore(
   if (!scoring_processor_or.ok()) {
     return QueryScoringResults(std::move(scoring_processor_or).status(),
                                std::move(query_results.query_terms),
+                               std::move(query_results.embedding_query_results),
                                /*scored_document_hits_in=*/{});
   }
   std::unique_ptr<ScoringProcessor> scoring_processor =
@@ -2662,6 +2904,7 @@ IcingSearchEngine::QueryScoringResults IcingSearchEngine::ProcessQueryAndScore(
 
   return QueryScoringResults(libtextclassifier3::Status::OK,
                              std::move(query_results.query_terms),
+                             std::move(query_results.embedding_query_results),
                              std::move(scored_document_hits));
 }
 
@@ -2772,15 +3015,7 @@ BlobProto IcingSearchEngine::OpenWriteBlob(
     return blob_proto;
   }
 
-  libtextclassifier3::StatusOr<int> write_fd_or =
-      blob_store_->OpenWrite(blob_handle);
-  if (!write_fd_or.ok()) {
-    TransformStatus(write_fd_or.status(), status);
-    return blob_proto;
-  }
-  blob_proto.set_file_descriptor(write_fd_or.ValueOrDie());
-  status->set_code(StatusProto::OK);
-  return blob_proto;
+  return blob_store_->OpenWrite(blob_handle);
 }
 
 BlobProto IcingSearchEngine::RemoveBlob(
@@ -2801,13 +3036,7 @@ BlobProto IcingSearchEngine::RemoveBlob(
     return blob_proto;
   }
 
-  auto remove_result = blob_store_->RemoveBlob(blob_handle);
-  if (!remove_result.ok()) {
-    TransformStatus(remove_result, status);
-    return blob_proto;
-  }
-  status->set_code(StatusProto::OK);
-  return blob_proto;
+  return blob_store_->RemoveBlob(blob_handle);
 }
 
 BlobProto IcingSearchEngine::OpenReadBlob(
@@ -2829,14 +3058,7 @@ BlobProto IcingSearchEngine::OpenReadBlob(
     return blob_proto;
   }
 
-  auto read_fd_or = blob_store_->OpenRead(blob_handle);
-  if (!read_fd_or.ok()) {
-    TransformStatus(read_fd_or.status(), status);
-    return blob_proto;
-  }
-  blob_proto.set_file_descriptor(read_fd_or.ValueOrDie());
-  status->set_code(StatusProto::OK);
-  return blob_proto;
+  return blob_store_->OpenRead(blob_handle);
 }
 
 BlobProto IcingSearchEngine::CommitBlob(
@@ -2857,13 +3079,7 @@ BlobProto IcingSearchEngine::CommitBlob(
     return blob_proto;
   }
 
-  auto commit_result_or = blob_store_->CommitBlob(blob_handle);
-  if (!commit_result_or.ok()) {
-    TransformStatus(commit_result_or, status);
-    return blob_proto;
-  }
-  status->set_code(StatusProto::OK);
-  return blob_proto;
+  return blob_store_->CommitBlob(blob_handle);
 }
 
 libtextclassifier3::StatusOr<DocumentStore::OptimizeResult>
@@ -2993,6 +3209,8 @@ IcingSearchEngine::OptimizeDocumentStore(
 
 IcingSearchEngine::IndexRestorationResult
 IcingSearchEngine::RestoreIndexIfNeeded() {
+  int64_t current_time_ms = clock_->GetSystemTimeMilliseconds();
+
   DocumentId last_stored_document_id =
       document_store_->last_added_document_id();
   if (last_stored_document_id == index_->last_added_document_id() &&
@@ -3001,34 +3219,32 @@ IcingSearchEngine::RestoreIndexIfNeeded() {
           qualified_id_join_index_->last_added_document_id() &&
       last_stored_document_id == embedding_index_->last_added_document_id()) {
     // No need to recover.
-    return {libtextclassifier3::Status::OK, false, false, false, false};
+    return IndexRestorationResult(libtextclassifier3::Status::OK);
   }
 
   if (last_stored_document_id == kInvalidDocumentId) {
     // Document store is empty but index is not. Clear the index.
-    return {ClearAllIndices(), false, false, false, false};
+    return IndexRestorationResult(ClearAllIndices());
   }
 
   // Truncate indices first.
   auto truncate_result_or = TruncateIndicesTo(last_stored_document_id);
   if (!truncate_result_or.ok()) {
-    return {std::move(truncate_result_or).status(), false, false, false, false};
+    return IndexRestorationResult(std::move(truncate_result_or).status());
   }
   TruncateIndexResult truncate_result =
       std::move(truncate_result_or).ValueOrDie();
 
   if (truncate_result.first_document_to_reindex > last_stored_document_id) {
     // Nothing to restore. Just return.
-    return {libtextclassifier3::Status::OK, false, false, false, false};
+    return IndexRestorationResult(libtextclassifier3::Status::OK);
   }
 
   auto data_indexing_handlers_or = CreateDataIndexingHandlers();
   if (!data_indexing_handlers_or.ok()) {
-    return {data_indexing_handlers_or.status(),
-            truncate_result.index_needed_restoration,
-            truncate_result.integer_index_needed_restoration,
-            truncate_result.qualified_id_join_index_needed_restoration,
-            truncate_result.embedding_index_needed_restoration};
+    return IndexRestorationResult(std::move(data_indexing_handlers_or).status(),
+                                  /*num_failed_reindexed_documents_in=*/0,
+                                  truncate_result);
   }
   // By using recovery_mode for IndexProcessor, we're able to replay documents
   // from smaller document id and it will skip documents that are already been
@@ -3040,6 +3256,7 @@ IcingSearchEngine::RestoreIndexIfNeeded() {
   ICING_VLOG(1) << "Restoring index by replaying documents from document id "
                 << truncate_result.first_document_to_reindex
                 << " to document id " << last_stored_document_id;
+  std::unordered_set<DocumentId> failed_document_ids;
   libtextclassifier3::Status overall_status;
   for (DocumentId document_id = truncate_result.first_document_to_reindex;
        document_id <= last_stored_document_id; ++document_id) {
@@ -3053,52 +3270,75 @@ IcingSearchEngine::RestoreIndexIfNeeded() {
         continue;
       } else {
         // Returns other errors
-        return {document_or.status(), truncate_result.index_needed_restoration,
-                truncate_result.integer_index_needed_restoration,
-                truncate_result.qualified_id_join_index_needed_restoration,
-                truncate_result.embedding_index_needed_restoration};
+        return IndexRestorationResult(
+            std::move(document_or).status(),
+            /*num_failed_reindexed_documents_in=*/
+            static_cast<int>(failed_document_ids.size()), truncate_result);
       }
     }
     DocumentProto document(std::move(document_or).ValueOrDie());
 
+    libtextclassifier3::Status status;
     libtextclassifier3::StatusOr<TokenizedDocument> tokenized_document_or =
-        TokenizedDocument::Create(schema_store_.get(),
-                                  language_segmenter_.get(),
-                                  std::move(document));
+        PrepareDocumentForIndexing(schema_store_.get(),
+                                   language_segmenter_.get(),
+                                   std::move(document));
     if (!tokenized_document_or.ok()) {
-      return {tokenized_document_or.status(),
-              truncate_result.index_needed_restoration,
-              truncate_result.integer_index_needed_restoration,
-              truncate_result.qualified_id_join_index_needed_restoration,
-              truncate_result.embedding_index_needed_restoration};
-    }
-    TokenizedDocument tokenized_document(
-        std::move(tokenized_document_or).ValueOrDie());
-
-    // No valid old_document_id should be used here since we're in recovery mode
-    // and there is no "existing document replacement/update".
-    libtextclassifier3::Status status =
-        index_processor.IndexDocument(tokenized_document, document_id,
-                                      /*old_document_id=*/kInvalidDocumentId);
+      status = std::move(tokenized_document_or).status();
+    } else {
+      // No valid old_document_id should be used here since we're in recovery
+      // mode and there is no "existing document replacement/update".
+      status = index_processor.IndexDocument(
+          tokenized_document_or.ValueOrDie(), document_id,
+          /*old_document_id=*/kInvalidDocumentId);
+    }
+
     if (!status.ok()) {
-      if (!absl_ports::IsDataLoss(status)) {
-        // Real error. Stop recovering and pass it up.
-        return {status, truncate_result.index_needed_restoration,
-                truncate_result.integer_index_needed_restoration,
-                truncate_result.qualified_id_join_index_needed_restoration,
-                truncate_result.embedding_index_needed_restoration};
+      if (!absl_ports::IsDataLoss(status) &&
+          !options_.enable_soft_index_restoration()) {
+        // Stop recovering and pass it up. Skip data loss error.
+        return IndexRestorationResult(
+            std::move(status),
+            /*num_failed_reindexed_documents_in=*/
+            static_cast<int>(failed_document_ids.size()), truncate_result);
+      }
+
+      // Here, data loss error or soft index restoration is enabled.
+      // Soft index restoration: if failing to tokenize, enforce dependency or
+      // index the document, then log the error, add the document id into
+      // failed_document_ids (so we can delete it later), and continue
+      // restoration.
+      ICING_LOG(WARNING) << "Failed to restore index for document "
+                         << document_id << ": " << status.error_message();
+      if (options_.enable_soft_index_restoration()) {
+        failed_document_ids.insert(document_id);
+      }
+
+      // Set the overall status to data loss error.
+      overall_status = absl_ports::DataLossError(status.error_message());
+    }
+  }
+
+  // Finally, delete all failed documents.
+  if (options_.enable_soft_index_restoration()) {
+    for (DocumentId document_id : failed_document_ids) {
+      libtextclassifier3::Status delete_status =
+          document_store_->Delete(document_id, current_time_ms);
+      if (!delete_status.ok()) {
+        // This is pretty dire (and, hopefully, unlikely). Log the error and
+        // skip it.
+        ICING_LOG(WARNING) << "Cannot delete document " << document_id
+                           << " that which failed to index: "
+                           << delete_status.error_message();
       }
-      // FIXME: why can we skip data loss error here?
-      // Just a data loss. Keep trying to add the remaining docs, but report the
-      // data loss when we're done.
-      overall_status = status;
     }
+    // TODO(b/384947619): apply delete propagation on these failed documents.
   }
 
-  return {overall_status, truncate_result.index_needed_restoration,
-          truncate_result.integer_index_needed_restoration,
-          truncate_result.qualified_id_join_index_needed_restoration,
-          truncate_result.embedding_index_needed_restoration};
+  return IndexRestorationResult(std::move(overall_status),
+                                /*num_failed_reindexed_documents_in=*/
+                                static_cast<int>(failed_document_ids.size()),
+                                truncate_result);
 }
 
 libtextclassifier3::StatusOr<bool> IcingSearchEngine::LostPreviousSchema() {
@@ -3285,8 +3525,8 @@ IcingSearchEngine::TruncateIndicesTo(DocumentId last_stored_document_id) {
 }
 
 libtextclassifier3::Status IcingSearchEngine::DiscardDerivedFiles(
-    const version_util::DerivedFilesRebuildResult& rebuild_result) {
-  if (!rebuild_result.IsRebuildNeeded()) {
+    const derived_file_util::DerivedFilesRebuildInfo& rebuild_info) {
+  if (!rebuild_info.IsRebuildNeeded()) {
     return libtextclassifier3::Status::OK;
   }
 
@@ -3298,19 +3538,19 @@ libtextclassifier3::Status IcingSearchEngine::DiscardDerivedFiles(
   }
 
   // Schema store
-  if (rebuild_result.needs_schema_store_derived_files_rebuild) {
+  if (rebuild_info.needs_schema_store_derived_files_rebuild) {
     ICING_RETURN_IF_ERROR(SchemaStore::DiscardDerivedFiles(
         filesystem_.get(), MakeSchemaDirectoryPath(options_.base_dir())));
   }
 
   // Document store
-  if (rebuild_result.needs_document_store_derived_files_rebuild) {
+  if (rebuild_info.needs_document_store_derived_files_rebuild) {
     ICING_RETURN_IF_ERROR(DocumentStore::DiscardDerivedFiles(
         filesystem_.get(), MakeDocumentDirectoryPath(options_.base_dir())));
   }
 
   // Term index
-  if (rebuild_result.needs_term_index_rebuild) {
+  if (rebuild_info.needs_term_index_rebuild) {
     if (!filesystem_->DeleteDirectoryRecursively(
             MakeIndexDirectoryPath(options_.base_dir()).c_str())) {
       return absl_ports::InternalError("Failed to discard index");
@@ -3318,7 +3558,7 @@ libtextclassifier3::Status IcingSearchEngine::DiscardDerivedFiles(
   }
 
   // Integer index
-  if (rebuild_result.needs_integer_index_rebuild) {
+  if (rebuild_info.needs_integer_index_rebuild) {
     if (!filesystem_->DeleteDirectoryRecursively(
             MakeIntegerIndexWorkingPath(options_.base_dir()).c_str())) {
       return absl_ports::InternalError("Failed to discard integer index");
@@ -3326,7 +3566,7 @@ libtextclassifier3::Status IcingSearchEngine::DiscardDerivedFiles(
   }
 
   // Qualified id join index
-  if (rebuild_result.needs_qualified_id_join_index_rebuild) {
+  if (rebuild_info.needs_qualified_id_join_index_rebuild) {
     if (!filesystem_->DeleteDirectoryRecursively(
             MakeQualifiedIdJoinIndexWorkingPath(options_.base_dir()).c_str())) {
       return absl_ports::InternalError(
@@ -3335,7 +3575,7 @@ libtextclassifier3::Status IcingSearchEngine::DiscardDerivedFiles(
   }
 
   // Embedding index.
-  if (rebuild_result.needs_embedding_index_rebuild) {
+  if (rebuild_info.needs_embedding_index_rebuild) {
     ICING_RETURN_IF_ERROR(EmbeddingIndex::Discard(
         *filesystem_, MakeEmbeddingIndexWorkingPath(options_.base_dir())));
   }
diff --git a/icing/icing-search-engine.h b/icing/icing-search-engine.h
index d23767d..ac34063 100644
--- a/icing/icing-search-engine.h
+++ b/icing/icing-search-engine.h
@@ -28,10 +28,11 @@
 #include "icing/absl_ports/mutex.h"
 #include "icing/absl_ports/thread_annotations.h"
 #include "icing/feature-flags.h"
+#include "icing/file/derived-file-util.h"
 #include "icing/file/filesystem.h"
-#include "icing/file/version-util.h"
 #include "icing/index/data-indexing-handler.h"
 #include "icing/index/embed/embedding-index.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/index/index.h"
 #include "icing/index/numeric/numeric-index.h"
 #include "icing/jni/jni-cache.h"
@@ -62,6 +63,7 @@
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
+#include "icing/util/icu-data-file-helper.h"
 
 namespace icing {
 namespace lib {
@@ -104,9 +106,22 @@ class IcingSearchEngine {
   //   NOT_FOUND if missing some internal data
   InitializeResultProto Initialize() ICING_LOCKS_EXCLUDED(mutex_);
 
+  // TODO: b/337913932 - Remove this method once all callers are migrated to the
+  // new SetSchema method.
+  //
+  // This method is deprecated. Please use
+  // `IcingSearchEngine::SetSchema(SetSchemaRequestProto)` instead.
+  //
   // Specifies the schema to be applied on all Documents that are already
-  // stored as well as future documents. A schema can be 'invalid' and/or
-  // 'incompatible'. These are two independent concepts.
+  // stored as well as future documents.
+  //
+  // This SetSchema call only allows setting schemas in the default empty
+  // database. Any non-empty database field in `new_schema.types` invalidates
+  // this SetSchema request. To set a schema for a non-empty database, please
+  // use `IcingSearchEngine::SetSchema(SetSchemaRequestProto)`.
+  //
+  // A schema can be 'invalid' and/or 'incompatible'. These are two independent
+  // concepts.
   //
   // An 'invalid' schema is one that is not constructed properly. For example,
   // a PropertyConfigProto is missing the property name field. A schema can be
@@ -167,6 +182,63 @@ class IcingSearchEngine {
                                  bool ignore_errors_and_delete_documents =
                                      false) ICING_LOCKS_EXCLUDED(mutex_);
 
+  // Specifies the schema to be applied on all Documents that are already
+  // stored as well as future documents.
+  //
+  // This operation sets the schema for the single database specified in
+  // `set_schema_request.database()`. If unset, the default empty
+  // database is assumed.
+  //
+  // A schema can be 'invalid' and/or 'incompatible'. These are two independent
+  // concepts.
+  // - An 'invalid' schema is one that is not constructed properly.
+  //   - For example, a PropertyConfigProto is missing the property name field.
+  //   - A schema can be 'invalid' even if there is no previously existing
+  //     schema.
+  // - An 'incompatible' schema is one that is incompatible with a previously
+  //   existing schema.
+  //   - If there is no previously existing schema, then a new schema cannot be
+  //     incompatible. An incompatible schema is one that invalidates
+  //     pre-existing data.
+  //   - For example, a previously OPTIONAL field is now REQUIRED in the new
+  //     schema, and pre-existing data is considered invalid against the new
+  //     schema now.
+  //
+  // Default behavior will not allow a new schema to be set if it is invalid or
+  // incompatible.
+  // - `set_schema_request.ignore_errors_and_delete_documents' can be set to
+  //   true to force set an incompatible schema.
+  //   - In that case, documents that are invalidated by the new schema would be
+  //     deleted from Icing.
+  //   - This cannot be used to force set an invalid schema.
+  //
+  // This schema is persisted to disk and used across multiple instances.
+  // So, callers should only have to call this if the schema changed.
+  // However, calling it multiple times with the same schema is a no-op.
+  //
+  // On some errors, Icing will keep using the older schema, but on
+  // INTERNAL_ERROR, it is undefined to continue using Icing.
+  //
+  // Returns:
+  // - OK on success
+  // - ALREADY_EXISTS if 'set_schema_request.schema' contains multiple
+  //     definitions of the same type or contains a type that has multiple
+  //     properties with the same name.
+  // - INVALID_ARGUMENT if 'set_schema_request.schema' is invalid, or if
+  //     `set_schema_request.database` does not match the database fields of
+  //     `set_schema_request.schema.types`.
+  // - FAILED_PRECONDITION if 'set_schema_request.schema' is incompatible, or
+  //     IcingSearchEngine has not been initialized yet.
+  // - INTERNAL_ERROR if Icing failed to store the new schema or upgrade
+  //     existing data based on the new schema. Using Icing beyond this error is
+  //     undefined and may cause crashes.
+  // - DATA_LOSS_ERROR if 'set_schema_request.schema' requires the index to be
+  //     rebuilt and an IO error leads to some documents being excluded from the
+  //     index. These documents will still be retrievable via Get, but won't
+  //     match queries.
+  SetSchemaResultProto SetSchema(SetSchemaRequestProto&& set_schema_request)
+      ICING_LOCKS_EXCLUDED(mutex_);
+
   // Get Icing's current copy of the schema.
   //
   // Returns:
@@ -203,6 +275,16 @@ class IcingSearchEngine {
   GetSchemaTypeResultProto GetSchemaType(std::string_view schema_type)
       ICING_LOCKS_EXCLUDED(mutex_);
 
+  // Batch puts the documents into icing search engine so that they're stored
+  // and indexed. Documents are automatically written to disk, callers can also
+  // call PersistToDisk() to flush changes immediately.
+  //
+  // Returns: BatchPutResultProto with a list of PutResultProtos for each
+  // document, and a PersistToDiskResultProto if persist_type is set in the
+  // request.
+  BatchPutResultProto BatchPut(PutDocumentRequest&& put_document_request)
+      ICING_LOCKS_EXCLUDED(mutex_);
+
   // Puts the document into icing search engine so that it's stored and
   // indexed. Documents are automatically written to disk, callers can also
   // call PersistToDisk() to flush changes immediately.
@@ -239,6 +321,11 @@ class IcingSearchEngine {
   GetResultProto Get(std::string_view name_space, std::string_view uri,
                      const GetResultSpecProto& result_spec);
 
+  // Finds and returns the documents identified by the given GetResultSpecProto.
+  // Returns:
+  //   A BatchGetResultProto with a list of GetResultProto.
+  BatchGetResultProto BatchGet(GetResultSpecProto&& get_result_spec);
+
   // Reports usage. The corresponding usage scores of the specified document in
   // the report will be updated.
   //
@@ -367,49 +454,80 @@ class IcingSearchEngine {
       ICING_LOCKS_EXCLUDED(mutex_);
 
   // Gets or creates a file for write only purpose for the given blob handle.
-  // To mark the blob is completed written, commitBlob must be called. Once
-  // commitBlob is called, the blob is sealed and rewrite is not allowed.
+  // To mark the blob is completed written, CommitBlob must be called. Once
+  // CommitBlob is called, the blob is sealed and rewrite is not allowed.
+  //
+  // If Icing does not manage blob files, this method only creates necessary
+  // metadata for the blob but does not open or manage the file descriptor. The
+  // caller is responsible for opening, writing to, and closing the file using
+  // the returned file name.
+  //
+  // Otherwise, a file descriptor is returned, and it is the user's
+  // responsibility to close the file descriptor after writing is done and
+  // should not operate on the file descriptor after commit or remove it.
   //
   // Returns:
-  //   File descriptor on success
+  //   OK with results on success
   //   InvalidArgumentError on invalid blob handle
-  //   FailedPreconditionError on blob is already opened for write
-  //   AlreadyExistsError on blob is committed
-  //   INTERNAL_ERROR on IO error
-  BlobProto OpenWriteBlob(const PropertyProto::BlobHandleProto& blob_handle);
+  //   FailedPreconditionError if the blob is already opened for write
+  //   AlreadyExistsError if the blob is already committed
+  //   InternalError on IO error
+  BlobProto OpenWriteBlob(const PropertyProto::BlobHandleProto& blob_handle)
+      ICING_LOCKS_EXCLUDED(mutex_);
 
   // Removes a blob file and blob handle from the blob store.
   //
   // This will remove the blob on any state. No matter it's committed or not or
   // it has reference document links or not.
   //
+  // If Icing does not manage blob files, this method only removes the metadata
+  // entry from the blob store, but does not delete the actual blob file. The
+  // caller is responsible for deleting the blob file.
+  //
   // Returns:
+  //   OK with results on success
   //   InvalidArgumentError on invalid blob handle
-  //   NotFoundError on blob is not found
+  //   NotFoundError if the blob is not found
   //   InternalError on IO error
-  BlobProto RemoveBlob(const PropertyProto::BlobHandleProto& blob_handle);
+  BlobProto RemoveBlob(const PropertyProto::BlobHandleProto& blob_handle)
+      ICING_LOCKS_EXCLUDED(mutex_);
 
-  // Gets or creates a file for read only purpose for the given blob handle.
-  // The blob must be committed by calling commitBlob otherwise it is not
+  // Gets a file for read only purpose for the given blob handle.
+  // The blob must be committed by calling CommitBlob otherwise it is not
   // accessible.
   //
+  // If Icing does not manage blob files, this method only returns the file name
+  // associated with the blob but does not open or manage the file descriptor.
+  // The caller is responsible for opening, reading from, and closing the file
+  // using the returned file name.
+  //
+  // Otherwise, a file descriptor is returned, and it is the user's
+  // responsibility to close the file descriptor after reading.
+  //
   // Returns:
-  //   File descriptor on success
+  //   OK with results on success
   //   InvalidArgumentError on invalid blob handle
-  //   NotFoundError on blob is not found or is not committed
-  BlobProto OpenReadBlob(const PropertyProto::BlobHandleProto& blob_handle);
+  //   NotFoundError if the blob is not found or is not committed
+  BlobProto OpenReadBlob(const PropertyProto::BlobHandleProto& blob_handle)
+      ICING_LOCKS_EXCLUDED(mutex_);
 
-  // Commits the given blob, the blob is open to write via openWrite.
-  // Before the blob is committed, it is not visible to any reader via openRead.
-  // After the blob is committed, it is not allowed to rewrite or update the
-  // content.
+  // Commits the given blob when writing of the blob via OpenWrite is complete.
+  // Before the blob is committed, it is not visible to any reader
+  // via OpenRead. After the blob is committed, it is not allowed to rewrite or
+  // update the content.
+  //
+  // If Icing does not manage blob files, this method marks the blob as
+  // committed in the metadata store. The caller is responsible for verifying
+  // the digest of the blob file.
   //
   // Returns:
-  //   True on the blob is successfuly committed.
-  //   False on the blob is already committed.
-  //   InvalidArgumentError on invalid blob handle or digest is mismatch with
-  //     file content NotFoundError on blob is not found.
-  BlobProto CommitBlob(const PropertyProto::BlobHandleProto& blob_handle);
+  //   OK on success
+  //   AlreadyExistsError if the blob is already committed
+  //   InvalidArgumentError on invalid blob handle or if the digest is mismatch
+  //     with file content
+  //   NotFoundError if the blob is not found
+  BlobProto CommitBlob(const PropertyProto::BlobHandleProto& blob_handle)
+      ICING_LOCKS_EXCLUDED(mutex_);
 
   // Makes sure that every update/delete received till this point is flushed
   // to disk. If the app crashes after a call to PersistToDisk(), Icing
@@ -694,15 +812,22 @@ class IcingSearchEngine {
   //   Any other errors when processing the query or scoring
   struct QueryScoringResults {
     libtextclassifier3::Status status;
+    // This will be used to retrieve snippeting match info for the term query.
     SectionRestrictQueryTermsMap query_terms;
+    // Contains embedding match infos (scores and section info) from embedding
+    // based queries. This will be used to retrieve snippeting match info for
+    // the embedding query.
+    EmbeddingQueryResults embedding_query_results;
     std::vector<ScoredDocumentHit> scored_document_hits;
 
     explicit QueryScoringResults(
         libtextclassifier3::Status status_in,
         SectionRestrictQueryTermsMap&& query_terms_in,
+        EmbeddingQueryResults&& embedding_query_results_in,
         std::vector<ScoredDocumentHit>&& scored_document_hits_in)
         : status(std::move(status_in)),
           query_terms(std::move(query_terms_in)),
+          embedding_query_results(std::move(embedding_query_results_in)),
           scored_document_hits(std::move(scored_document_hits_in)) {}
   };
   QueryScoringResults ProcessQueryAndScore(
@@ -722,14 +847,14 @@ class IcingSearchEngine {
       const std::unordered_set<DocumentId>& deleted_document_ids,
       int64_t current_time_ms) ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
-  // Discards derived data that requires rebuild based on rebuild_result.
+  // Discards derived data that requires rebuild based on rebuild_info.
   //
   // Returns:
   //   OK on success
   //   FAILED_PRECONDITION_ERROR if those instances are valid (non nullptr)
   //   INTERNAL_ERROR on any I/O errors
   libtextclassifier3::Status DiscardDerivedFiles(
-      const version_util::DerivedFilesRebuildResult& rebuild_result)
+      const derived_file_util::DerivedFilesRebuildInfo& rebuild_info)
       ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
   // Repopulates derived data off our ground truths.
@@ -764,30 +889,6 @@ class IcingSearchEngine {
                         OptimizeStatsProto* optimize_stats)
       ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
-  // Helper method to restore missing document data in index_, integer_index_,
-  // and qualified_id_join_index_. All documents will be reindexed. This does
-  // not clear the index, so it is recommended to call ClearAllIndices,
-  // ClearSearchIndices, or ClearJoinIndices first if needed.
-  //
-  // Returns:
-  //   On success, OK and a bool indicating whether or not restoration was
-  //     needed.
-  //   DATA_LOSS, if an error during index merging caused us to lose indexed
-  //     data in the main index. Despite the data loss, this is still considered
-  //     a successful run and needed_restoration will be set to true.
-  //   RESOURCE_EXHAUSTED if the index fills up before finishing indexing
-  //   NOT_FOUND if some Document's schema type is not in the SchemaStore
-  //   INTERNAL_ERROR on any IO errors
-  struct IndexRestorationResult {
-    libtextclassifier3::Status status;
-    bool index_needed_restoration;
-    bool integer_index_needed_restoration;
-    bool qualified_id_join_index_needed_restoration;
-    bool embedding_index_needed_restoration;
-  };
-  IndexRestorationResult RestoreIndexIfNeeded()
-      ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
-
   // If we lost the schema during a previous failure, it may "look" the same as
   // not having a schema set before: we don't have a schema proto file. So do
   // some extra checks to differentiate between having-lost the schema, and
@@ -806,18 +907,29 @@ class IcingSearchEngine {
       std::vector<std::unique_ptr<DataIndexingHandler>>>
   CreateDataIndexingHandlers() ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
-  // Helper method to discard parts of (term, integer, qualified id join)
-  // indices if they contain data for document ids greater than
+  // Helper method to discard parts of (term, integer, qualified id join,
+  // embedding) indices if they contain data for document ids greater than
   // last_stored_document_id.
   //
+  // Also notify the caller whether additional restoration action (i.e. replay
+  // documents from document store and reindex them) is needed for each index.
+  // There are several possibilities for restoration:
+  // - This function detects last_added_document_id is ahead of
+  //   last_stored_document_id, so truncate the index and notify the caller to
+  //   restore the index.
+  // - The upper caller (e.g. InitializeMembers) has already discarded the
+  //   entire index before entering this function, so no truncation was done in
+  //   this function. However, since last_added_document_id is behind
+  //   last_stored_document_id now, restoration action must be taken.
+  //
   // REQUIRES: last_stored_document_id is valid (!= kInvalidDocumentId). Note:
   //   if we want to truncate everything in the index, then please call
   //   ClearSearchIndices/ClearJoinIndices/ClearAllIndices instead.
   //
   // Returns:
   //   On success, a DocumentId indicating the first document to start for
-  //     reindexing and 2 bool flags indicating whether term or integer index
-  //     needs restoration.
+  //     reindexing and bool flags indicating whether each index needs
+  //     restoration.
   //   INTERNAL on any I/O errors
   struct TruncateIndexResult {
     DocumentId first_document_to_reindex;
@@ -844,6 +956,62 @@ class IcingSearchEngine {
       DocumentId last_stored_document_id)
       ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
+  // Helper method to restore missing document data in index_, integer_index_,
+  // and qualified_id_join_index_. All documents will be reindexed. This does
+  // not clear the index, so it is recommended to call ClearAllIndices,
+  // ClearSearchIndices, or ClearJoinIndices first if needed.
+  //
+  // Returns:
+  //   IndexRestorationResult which contains the status of the restoration,
+  //   number of failed reindexed documents, and flags indicating whether each
+  //   index has been restored:
+  //   - True: the corresponding index was restored successfully only if the
+  //     status is OK or DATA_LOSS. Otherwise, the corresponding index was
+  //     attempted to be restored but failed or interrupted by other errors.
+  //   - False: the data in the index was consistent so no restoration action
+  //     was taken on it.
+  //
+  //   The following are the possible status codes:
+  //   - On success, OK.
+  //   - DATA_LOSS, if an error during index merging caused us to lose indexed
+  //     data in any index. Despite the data loss, this is still considered a
+  //     successful run and the corresponding boolean flag will be set to true
+  //     for the index that was restored.
+  //   - RESOURCE_EXHAUSTED if the index fills up before finishing indexing
+  //   - NOT_FOUND if some Document's schema type is not in the SchemaStore
+  //   - INTERNAL_ERROR on any IO errors
+  struct IndexRestorationResult {
+    libtextclassifier3::Status status;
+    int num_failed_reindexed_documents;
+    bool has_index_restored;
+    bool has_integer_index_restored;
+    bool has_qualified_id_join_index_restored;
+    bool has_embedding_index_restored;
+
+    explicit IndexRestorationResult(libtextclassifier3::Status status_in)
+        : status(std::move(status_in)),
+          num_failed_reindexed_documents(0),
+          has_index_restored(false),
+          has_integer_index_restored(false),
+          has_qualified_id_join_index_restored(false),
+          has_embedding_index_restored(false) {}
+
+    explicit IndexRestorationResult(libtextclassifier3::Status status_in,
+                                    int num_failed_reindexed_documents_in,
+                                    const TruncateIndexResult& truncate_result)
+        : status(std::move(status_in)),
+          num_failed_reindexed_documents(num_failed_reindexed_documents_in),
+          has_index_restored(truncate_result.index_needed_restoration),
+          has_integer_index_restored(
+              truncate_result.integer_index_needed_restoration),
+          has_qualified_id_join_index_restored(
+              truncate_result.qualified_id_join_index_needed_restoration),
+          has_embedding_index_restored(
+              truncate_result.embedding_index_needed_restoration) {}
+  };
+  IndexRestorationResult RestoreIndexIfNeeded()
+      ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
+
   // Helper method to discard search (term, integer) indices.
   //
   // Returns:
diff --git a/icing/icing-search-engine_benchmark.cc b/icing/icing-search-engine_benchmark.cc
index 91924dc..b27a9a0 100644
--- a/icing/icing-search-engine_benchmark.cc
+++ b/icing/icing-search-engine_benchmark.cc
@@ -150,6 +150,7 @@ class DestructibleDirectory {
   explicit DestructibleDirectory(const Filesystem& filesystem,
                                  const std::string& dir)
       : filesystem_(filesystem), dir_(dir) {
+    filesystem_.DeleteDirectoryRecursively(dir_.c_str());
     filesystem_.CreateDirectoryRecursively(dir_.c_str());
   }
   ~DestructibleDirectory() {
@@ -222,7 +223,6 @@ void BM_IndexLatency(benchmark::State& state) {
   // Create the index.
   IcingSearchEngineOptions options;
   options.set_base_dir(test_dir);
-  options.set_index_merge_size(kIcingFullIndexSize);
   std::unique_ptr<IcingSearchEngine> icing =
       std::make_unique<IcingSearchEngine>(options);
 
@@ -1114,7 +1114,8 @@ void BM_JoinQueryQualifiedId(benchmark::State& state) {
   options.set_base_dir(test_dir);
   options.set_index_merge_size(kIcingFullIndexSize);
   options.set_document_store_namespace_id_fingerprint(true);
-  options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(true);
+  options.set_enable_qualified_id_join_index_v3(true);
+  options.set_enable_delete_propagation_from(false);
   std::unique_ptr<IcingSearchEngine> icing =
       std::make_unique<IcingSearchEngine>(options);
 
diff --git a/icing/icing-search-engine_blob_test.cc b/icing/icing-search-engine_blob_test.cc
index 72655ae..b13d258 100644
--- a/icing/icing-search-engine_blob_test.cc
+++ b/icing/icing-search-engine_blob_test.cc
@@ -18,12 +18,12 @@
 #include <memory>
 #include <random>
 #include <string>
-#include <unordered_set>
 #include <utility>
 #include <vector>
 
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/absl_ports/str_cat.h"
 #include "icing/document-builder.h"
 #include "icing/file/filesystem.h"
 #include "icing/icing-search-engine.h"
@@ -50,6 +50,7 @@ using ::icing::lib::portable_equals_proto::EqualsProto;
 using ::testing::IsEmpty;
 using ::testing::SizeIs;
 using ::testing::UnorderedElementsAre;
+using ::testing::UnorderedElementsAreArray;
 
 // For mocking purpose, we allow tests to provide a custom Filesystem.
 class TestIcingSearchEngine : public IcingSearchEngine {
@@ -71,7 +72,7 @@ std::string GetTestBlobDir() { return GetTestTempDir() + "/icing/blob_dir"; }
 std::string GetTestBlobFileDir() { return GetTestBlobDir() + "/blob_files"; }
 
 // This test is meant to cover all tests relating to IcingSearchEngine::Delete*.
-class IcingSearchEngineBlobTest : public testing::Test {
+class IcingSearchEngineBlobTest : public ::testing::TestWithParam<bool> {
  protected:
   void SetUp() override {
     filesystem_.DeleteDirectoryRecursively(GetTestBaseDir().c_str());
@@ -84,6 +85,37 @@ class IcingSearchEngineBlobTest : public testing::Test {
 
   const Filesystem* filesystem() const { return &filesystem_; }
 
+  IcingSearchEngineOptions GetDefaultIcingOptions() {
+    IcingSearchEngineOptions icing_options;
+    icing_options.set_base_dir(GetTestBaseDir());
+    icing_options.set_enable_blob_store(true);
+    icing_options.set_orphan_blob_time_to_live_ms(kBlobInfoTTLMs);
+    icing_options.set_enable_marker_file_for_optimize(true);
+    icing_options.set_manage_blob_files(GetParam());
+    return icing_options;
+  }
+
+  std::string MakeBlobFilePath(const std::string& file_name) {
+    return absl_ports::StrCat(GetTestBlobFileDir(), "/", file_name);
+  }
+
+  ScopedFd GetScopedFdFromBlobProto(BlobProto blob_proto) {
+    bool manage_blob_files = GetParam();
+    if (manage_blob_files) {
+      return ScopedFd(blob_proto.file_descriptor());
+    } else {
+      return ScopedFd(filesystem_.OpenForWrite(
+          MakeBlobFilePath(blob_proto.file_name()).c_str()));
+    }
+  }
+
+  void RemoveBlobFilesFromOptimizeResult(OptimizeResultProto optimize_result) {
+    for (const std::string& file_name :
+         optimize_result.blob_file_names_to_remove()) {
+      filesystem_.DeleteFile(MakeBlobFilePath(file_name).c_str());
+    }
+  }
+
  private:
   Filesystem filesystem_;
 };
@@ -91,14 +123,6 @@ class IcingSearchEngineBlobTest : public testing::Test {
 // Non-zero value so we don't override it to be the current time
 constexpr int64_t kDefaultCreationTimestampMs = 1575492852000;
 
-IcingSearchEngineOptions GetDefaultIcingOptions() {
-  IcingSearchEngineOptions icing_options;
-  icing_options.set_base_dir(GetTestBaseDir());
-  icing_options.set_enable_blob_store(true);
-  icing_options.set_orphan_blob_time_to_live_ms(kBlobInfoTTLMs);
-  return icing_options;
-}
-
 std::vector<unsigned char> GenerateRandomBytes(size_t length) {
   std::random_device rd;
   std::mt19937 gen(rd());
@@ -139,7 +163,7 @@ DocumentProto CreateBlobDocument(std::string name_space, std::string uri,
       .Build();
 }
 
-TEST_F(IcingSearchEngineBlobTest, InvalidBlobHandle) {
+TEST_P(IcingSearchEngineBlobTest, InvalidBlobHandle) {
   PropertyProto::BlobHandleProto blob_handle;
   blob_handle.set_digest("invalid");
   blob_handle.set_namespace_("namespaceA");
@@ -158,9 +182,8 @@ TEST_F(IcingSearchEngineBlobTest, InvalidBlobHandle) {
               ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
 }
 
-TEST_F(IcingSearchEngineBlobTest, BlobStoreDisabled) {
-  IcingSearchEngineOptions icing_options;
-  icing_options.set_base_dir(GetTestBaseDir());
+TEST_P(IcingSearchEngineBlobTest, BlobStoreDisabled) {
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
   icing_options.set_enable_blob_store(false);
 
   IcingSearchEngine icing(icing_options, GetTestJniCache());
@@ -183,7 +206,7 @@ TEST_F(IcingSearchEngineBlobTest, BlobStoreDisabled) {
               ProtoStatusIs(StatusProto::FAILED_PRECONDITION));
 }
 
-TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlob) {
+TEST_P(IcingSearchEngineBlobTest, WriteAndReadBlob) {
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
 
@@ -196,7 +219,7 @@ TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlob) {
   BlobProto write_blob_proto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(write_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -206,7 +229,7 @@ TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlob) {
   BlobProto read_blob_proto = icing.OpenReadBlob(blob_handle);
   ASSERT_THAT(read_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd(read_blob_proto.file_descriptor());
+    ScopedFd read_fd(GetScopedFdFromBlobProto(read_blob_proto));
 
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<unsigned char[]> buf =
@@ -218,7 +241,9 @@ TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlob) {
   }
 }
 
-TEST_F(IcingSearchEngineBlobTest, RemovePendingBlob) {
+TEST_P(IcingSearchEngineBlobTest, RemovePendingBlob) {
+  bool manage_blob_files = GetParam();
+
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
 
@@ -231,7 +256,7 @@ TEST_F(IcingSearchEngineBlobTest, RemovePendingBlob) {
   BlobProto write_blob_proto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(write_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -250,11 +275,18 @@ TEST_F(IcingSearchEngineBlobTest, RemovePendingBlob) {
   file_names = std::vector<std::string>();
   ASSERT_TRUE(
       filesystem()->ListDirectory(GetTestBlobFileDir().c_str(), &file_names));
-  // The pending file is deleted.
-  EXPECT_THAT(file_names, IsEmpty());
+  if (manage_blob_files) {
+    // The pending file is deleted.
+    EXPECT_THAT(file_names, IsEmpty());
+  } else {
+    // The pending file is not deleted if Icing does not manage the blob files.
+    EXPECT_THAT(file_names, SizeIs(1));
+  }
 }
 
-TEST_F(IcingSearchEngineBlobTest, RemoveCommittedBlob) {
+TEST_P(IcingSearchEngineBlobTest, RemoveCommittedBlob) {
+  bool manage_blob_files = GetParam();
+
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
 
@@ -267,7 +299,7 @@ TEST_F(IcingSearchEngineBlobTest, RemoveCommittedBlob) {
   BlobProto write_blob_proto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(write_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -289,11 +321,16 @@ TEST_F(IcingSearchEngineBlobTest, RemoveCommittedBlob) {
   file_names = std::vector<std::string>();
   ASSERT_TRUE(
       filesystem()->ListDirectory(GetTestBlobFileDir().c_str(), &file_names));
-  // The pending file is deleted.
-  EXPECT_THAT(file_names, IsEmpty());
+  if (manage_blob_files) {
+    // The pending file is deleted.
+    EXPECT_THAT(file_names, IsEmpty());
+  } else {
+    // The pending file is not deleted if Icing does not manage the blob files.
+    EXPECT_THAT(file_names, SizeIs(1));
+  }
 }
 
-TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlobByDocument) {
+TEST_P(IcingSearchEngineBlobTest, WriteAndReadBlobByDocument) {
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
 
@@ -307,7 +344,7 @@ TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlobByDocument) {
   ASSERT_THAT(write_blob_proto.status(), ProtoIsOk());
 
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -331,7 +368,7 @@ TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlobByDocument) {
   BlobProto read_blob_proto = icing.OpenReadBlob(out_blob_handle);
   ASSERT_THAT(read_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd(read_blob_proto.file_descriptor());
+    ScopedFd read_fd(GetScopedFdFromBlobProto(read_blob_proto));
 
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
@@ -343,7 +380,13 @@ TEST_F(IcingSearchEngineBlobTest, WriteAndReadBlobByDocument) {
   }
 }
 
-TEST_F(IcingSearchEngineBlobTest, CommitDigestMisMatch) {
+TEST_P(IcingSearchEngineBlobTest, CommitDigestMisMatch) {
+  bool manage_blob_files = GetParam();
+  if (!manage_blob_files) {
+    GTEST_SKIP() << "Skipping test because digest is not checked if Icing does "
+                    "not manage blob files.";
+  }
+
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
 
@@ -359,7 +402,7 @@ TEST_F(IcingSearchEngineBlobTest, CommitDigestMisMatch) {
 
   std::vector<unsigned char> data2 = GenerateRandomBytes(24);
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data2.data(), data2.size()));
   }
@@ -369,7 +412,7 @@ TEST_F(IcingSearchEngineBlobTest, CommitDigestMisMatch) {
               ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
 }
 
-TEST_F(IcingSearchEngineBlobTest, ReadBlobWithoutPersistToDisk) {
+TEST_P(IcingSearchEngineBlobTest, ReadBlobWithoutPersistToDisk) {
   IcingSearchEngine icing1(GetDefaultIcingOptions(), GetTestJniCache());
   EXPECT_THAT(icing1.Initialize().status(), ProtoIsOk());
 
@@ -384,7 +427,7 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithoutPersistToDisk) {
   ASSERT_THAT(write_blob_proto.status(), ProtoIsOk());
 
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -400,7 +443,7 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithoutPersistToDisk) {
   EXPECT_THAT(read_blob_proto.status(), ProtoStatusIs(StatusProto::NOT_FOUND));
 }
 
-TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskFull) {
+TEST_P(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskFull) {
   IcingSearchEngine icing1(GetDefaultIcingOptions(), GetTestJniCache());
   EXPECT_THAT(icing1.Initialize().status(), ProtoIsOk());
   // set a schema to icing to avoid wipe out all directories.
@@ -416,7 +459,7 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskFull) {
   BlobProto write_blob_proto = icing1.OpenWriteBlob(blob_handle);
   ASSERT_THAT(write_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
   BlobProto commit_blob_proto = icing1.CommitBlob(blob_handle);
@@ -432,7 +475,7 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskFull) {
   BlobProto read_blob_proto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(read_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd(read_blob_proto.file_descriptor());
+    ScopedFd read_fd(GetScopedFdFromBlobProto(read_blob_proto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
     EXPECT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
@@ -442,7 +485,7 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskFull) {
   }
 }
 
-TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskLite) {
+TEST_P(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskLite) {
   IcingSearchEngine icing1(GetDefaultIcingOptions(), GetTestJniCache());
   EXPECT_THAT(icing1.Initialize().status(), ProtoIsOk());
   // set a schema to icing to avoid wipe out all directories.
@@ -459,7 +502,7 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskLite) {
   ASSERT_THAT(write_blob_proto.status(), ProtoIsOk());
 
   {
-    ScopedFd write_fd(write_blob_proto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(write_blob_proto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -476,7 +519,7 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskLite) {
   BlobProto read_blob_proto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(read_blob_proto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd(read_blob_proto.file_descriptor());
+    ScopedFd read_fd(GetScopedFdFromBlobProto(read_blob_proto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
     EXPECT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
@@ -486,7 +529,9 @@ TEST_F(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskLite) {
   }
 }
 
-TEST_F(IcingSearchEngineBlobTest, BlobOptimize) {
+TEST_P(IcingSearchEngineBlobTest, BlobOptimize) {
+  bool manage_blob_files = GetParam();
+
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -507,7 +552,7 @@ TEST_F(IcingSearchEngineBlobTest, BlobOptimize) {
   BlobProto writeBlobProto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(writeBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -536,7 +581,7 @@ TEST_F(IcingSearchEngineBlobTest, BlobOptimize) {
   // Blob remain before optimize
   BlobProto readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
-  ScopedFd read_fd(readBlobProto.file_descriptor());
+  ScopedFd read_fd(GetScopedFdFromBlobProto(readBlobProto));
 
   uint64_t size = filesystem()->GetFileSize(*read_fd);
   std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
@@ -547,21 +592,33 @@ TEST_F(IcingSearchEngineBlobTest, BlobOptimize) {
   std::string actual_data = std::string(buf.get(), buf.get() + size);
   EXPECT_EQ(expected_data, actual_data);
 
-  file_names = std::vector<std::string>();
-  ASSERT_TRUE(
-      filesystem()->ListDirectory(GetTestBlobDir().c_str(), &file_names));
-  int32_t cur_file_count = file_names.size();
+  std::vector<std::string> before_optimize_file_names =
+      std::vector<std::string>();
+  ASSERT_TRUE(filesystem()->ListDirectory(GetTestBlobFileDir().c_str(),
+                                          &before_optimize_file_names));
+  EXPECT_THAT(before_optimize_file_names, SizeIs(1));
   // Optimize remove the expired orphan blob.
-  EXPECT_THAT(icing2.Optimize().status(), ProtoIsOk());
+  OptimizeResultProto optimize_result = icing2.Optimize();
+  EXPECT_THAT(optimize_result.status(), ProtoIsOk());
   EXPECT_THAT(icing2.OpenReadBlob(blob_handle).status(),
               ProtoStatusIs(StatusProto::NOT_FOUND));
-  file_names = std::vector<std::string>();
-  ASSERT_TRUE(
-      filesystem()->ListDirectory(GetTestBlobDir().c_str(), &file_names));
-  EXPECT_THAT(file_names, SizeIs(cur_file_count));
+
+  std::vector<std::string> after_optimize_file_names;
+  ASSERT_TRUE(filesystem()->ListDirectory(GetTestBlobFileDir().c_str(),
+                                          &after_optimize_file_names));
+  if (manage_blob_files) {
+    EXPECT_THAT(after_optimize_file_names, IsEmpty());
+  } else {
+    // If Icing does not manage blob files, it is the caller's responsibility
+    // to delete the blob files returned by Optimize.
+    EXPECT_THAT(after_optimize_file_names,
+                UnorderedElementsAreArray(before_optimize_file_names));
+    EXPECT_THAT(optimize_result.blob_file_names_to_remove(),
+                UnorderedElementsAreArray(after_optimize_file_names));
+  }
 }
 
-TEST_F(IcingSearchEngineBlobTest, BlobOptimizeWithoutCommit) {
+TEST_P(IcingSearchEngineBlobTest, BlobOptimizeWithoutCommit) {
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -584,7 +641,7 @@ TEST_F(IcingSearchEngineBlobTest, BlobOptimizeWithoutCommit) {
   BlobProto writeBlobProto = icing.OpenWriteBlob(blob_handle1);
   ASSERT_THAT(writeBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data1.data(), data1.size()));
   }
@@ -597,7 +654,7 @@ TEST_F(IcingSearchEngineBlobTest, BlobOptimizeWithoutCommit) {
   writeBlobProto = icing.OpenWriteBlob(blob_handle2);
   ASSERT_THAT(writeBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data2.data(), data2.size()));
   }
@@ -622,7 +679,7 @@ TEST_F(IcingSearchEngineBlobTest, BlobOptimizeWithoutCommit) {
               ProtoStatusIs(StatusProto::NOT_FOUND));
 }
 
-TEST_F(IcingSearchEngineBlobTest, ReferenceCount) {
+TEST_P(IcingSearchEngineBlobTest, ReferenceCount) {
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -640,7 +697,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCount) {
   BlobProto writeBlobProto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(writeBlobProto.status(), ProtoIsOk());
 
-  ScopedFd write_fd(writeBlobProto.file_descriptor());
+  ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
   ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   close(write_fd.get());
 
@@ -671,7 +728,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCount) {
   BlobProto readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd(readBlobProto.file_descriptor());
+    ScopedFd read_fd(GetScopedFdFromBlobProto(readBlobProto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
     ASSERT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
@@ -687,7 +744,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCount) {
   readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd2(readBlobProto.file_descriptor());
+    ScopedFd read_fd2(GetScopedFdFromBlobProto(readBlobProto));
 
     uint64_t size = filesystem()->GetFileSize(*read_fd2);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
@@ -704,7 +761,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCount) {
               ProtoStatusIs(StatusProto::NOT_FOUND));
 }
 
-TEST_F(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
+TEST_P(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -722,7 +779,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
   BlobProto writeBlobProto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(writeBlobProto.status(), ProtoIsOk());
 
-  ScopedFd write_fd(writeBlobProto.file_descriptor());
+  ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
   ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   close(write_fd.get());
 
@@ -782,7 +839,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
   BlobProto readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd(readBlobProto.file_descriptor());
+    ScopedFd read_fd(GetScopedFdFromBlobProto(readBlobProto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
     ASSERT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
@@ -798,7 +855,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
   readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd2(readBlobProto.file_descriptor());
+    ScopedFd read_fd2(GetScopedFdFromBlobProto(readBlobProto));
 
     uint64_t size = filesystem()->GetFileSize(*read_fd2);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
@@ -815,7 +872,7 @@ TEST_F(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
               ProtoStatusIs(StatusProto::NOT_FOUND));
 }
 
-TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
+TEST_P(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -833,7 +890,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
   BlobProto writeBlobProto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(writeBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -870,7 +927,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
   BlobProto readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd(readBlobProto.file_descriptor());
+    ScopedFd read_fd(GetScopedFdFromBlobProto(readBlobProto));
 
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
@@ -890,7 +947,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
   readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd read_fd2(readBlobProto.file_descriptor());
+    ScopedFd read_fd2(GetScopedFdFromBlobProto(readBlobProto));
 
     uint64_t size = filesystem()->GetFileSize(*read_fd2);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
@@ -910,7 +967,9 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
               ProtoStatusIs(StatusProto::NOT_FOUND));
 }
 
-TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
+TEST_P(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
+  bool manage_blob_files = GetParam();
+
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -929,7 +988,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
   BlobProto writeBlobProto1 = icing.OpenWriteBlob(blob_handle1);
   ASSERT_THAT(writeBlobProto1.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto1.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto1));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data1.data(), data1.size()));
   }
@@ -946,7 +1005,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
   BlobProto writeBlobProto2 = icing.OpenWriteBlob(blob_handle2);
   ASSERT_THAT(writeBlobProto2.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto2.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto2));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data2.data(), data2.size()));
   }
@@ -963,7 +1022,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
   BlobProto writeBlobProto3 = icing.OpenWriteBlob(blob_handle3);
   ASSERT_THAT(writeBlobProto3.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto3.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto3));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data3.data(), data3.size()));
   }
@@ -1012,7 +1071,14 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
   ASSERT_THAT(icing2.Delete("namespace", "doc2").status(), ProtoIsOk());
 
   // First two orphan blobs are removed after optimize .
-  ASSERT_THAT(icing2.Optimize().status(), ProtoIsOk());
+  OptimizeResultProto optimize_result = icing2.Optimize();
+  ASSERT_THAT(optimize_result.status(), ProtoIsOk());
+  if (!manage_blob_files) {
+    // If Icing does not manage blob files, it is the caller's responsibility
+    // to delete the blob files returned by Optimize.
+    ASSERT_THAT(optimize_result.blob_file_names_to_remove(), SizeIs(2));
+    RemoveBlobFilesFromOptimizeResult(optimize_result);
+  }
   EXPECT_THAT(icing2.OpenReadBlob(blob_handle1).status(),
               ProtoStatusIs(StatusProto::NOT_FOUND));
   EXPECT_THAT(icing2.OpenReadBlob(blob_handle2).status(),
@@ -1028,7 +1094,14 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
   // remove the last reference document, now the all blobs become orphan.
   ASSERT_THAT(icing2.Delete("namespace", "doc3").status(), ProtoIsOk());
   // Optimize remove the expired orphan blob.
-  ASSERT_THAT(icing2.Optimize().status(), ProtoIsOk());
+  optimize_result = icing2.Optimize();
+  ASSERT_THAT(optimize_result.status(), ProtoIsOk());
+  if (!manage_blob_files) {
+    // If Icing does not manage blob files, it is the caller's responsibility
+    // to delete the blob files returned by Optimize.
+    ASSERT_THAT(optimize_result.blob_file_names_to_remove(), SizeIs(1));
+    RemoveBlobFilesFromOptimizeResult(optimize_result);
+  }
   EXPECT_THAT(icing2.OpenReadBlob(blob_handle3).status(),
               ProtoStatusIs(StatusProto::NOT_FOUND));
   file_names = std::vector<std::string>();
@@ -1038,12 +1111,10 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeMultipleBlobHandles) {
   ASSERT_THAT(file_names, SizeIs(0));
 }
 
-TEST_F(IcingSearchEngineBlobTest, OptimizeBlobHandlesNoTTL) {
+TEST_P(IcingSearchEngineBlobTest, OptimizeBlobHandlesNoTTL) {
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
-  IcingSearchEngineOptions icing_options;
-  icing_options.set_base_dir(GetTestBaseDir());
-  icing_options.set_enable_blob_store(true);
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
   // set orphan blob ttl to 0, which means no ttl
   icing_options.set_orphan_blob_time_to_live_ms(0);
   TestIcingSearchEngine icing(icing_options, std::make_unique<Filesystem>(),
@@ -1063,7 +1134,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeBlobHandlesNoTTL) {
   BlobProto writeBlobProto = icing.OpenWriteBlob(blob_handle);
   ASSERT_THAT(writeBlobProto.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
     ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
   }
 
@@ -1085,7 +1156,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeBlobHandlesNoTTL) {
   ASSERT_THAT(icing2.Optimize().status(), ProtoIsOk());
   BlobProto readBlobProto = icing2.OpenReadBlob(blob_handle);
   ASSERT_THAT(readBlobProto.status(), ProtoIsOk());
-  ScopedFd read_fd(readBlobProto.file_descriptor());
+  ScopedFd read_fd(GetScopedFdFromBlobProto(readBlobProto));
 
   uint64_t size = filesystem()->GetFileSize(*read_fd);
   std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
@@ -1097,7 +1168,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeBlobHandlesNoTTL) {
   EXPECT_EQ(expected_data, actual_data);
 }
 
-TEST_F(IcingSearchEngineBlobTest, EmptyNamespace) {
+TEST_P(IcingSearchEngineBlobTest, EmptyNamespace) {
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -1116,7 +1187,9 @@ TEST_F(IcingSearchEngineBlobTest, EmptyNamespace) {
               ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
 }
 
-TEST_F(IcingSearchEngineBlobTest, OptimizeNamespaceUsage) {
+TEST_P(IcingSearchEngineBlobTest, OptimizeNamespaceUsage) {
+  bool manage_blob_files = GetParam();
+
   auto fake_clock = std::make_unique<FakeClock>();
   fake_clock->SetSystemTimeMilliseconds(1000);
   TestIcingSearchEngine icing(GetDefaultIcingOptions(),
@@ -1134,7 +1207,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeNamespaceUsage) {
   BlobProto writeBlobProto1 = icing.OpenWriteBlob(blob_handle1);
   ASSERT_THAT(writeBlobProto1.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto1.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto1));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data1.data(), data1.size()));
   }
@@ -1149,7 +1222,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeNamespaceUsage) {
   BlobProto writeBlobProto2 = icing.OpenWriteBlob(blob_handle2);
   ASSERT_THAT(writeBlobProto2.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto2.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto2));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data2.data(), data2.size()));
   }
@@ -1164,7 +1237,7 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeNamespaceUsage) {
   BlobProto writeBlobProto3 = icing.OpenWriteBlob(blob_handle3);
   ASSERT_THAT(writeBlobProto3.status(), ProtoIsOk());
   {
-    ScopedFd write_fd(writeBlobProto3.file_descriptor());
+    ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto3));
     ASSERT_TRUE(
         filesystem()->Write(write_fd.get(), data3.data(), data3.size()));
   }
@@ -1185,16 +1258,24 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeNamespaceUsage) {
   EXPECT_THAT(storage_info_result.status(), ProtoIsOk());
   NamespaceBlobStorageInfoProto namespace_info_a;
   namespace_info_a.set_namespace_("namespaceA");
-  namespace_info_a.set_blob_size(12);
-  namespace_info_a.set_num_blobs(1);
   NamespaceBlobStorageInfoProto namespace_info_b;
   namespace_info_b.set_namespace_("namespaceB");
-  namespace_info_b.set_blob_size(24);
-  namespace_info_b.set_num_blobs(1);
   NamespaceBlobStorageInfoProto namespace_info_c;
   namespace_info_c.set_namespace_("namespaceC");
-  namespace_info_c.set_blob_size(36);
-  namespace_info_c.set_num_blobs(1);
+  // If Icing manages blob files, blob_size will be calculated and set;
+  // otherwise, blob_file_names will be set.
+  if (manage_blob_files) {
+    namespace_info_a.set_num_blobs(1);
+    namespace_info_b.set_num_blobs(1);
+    namespace_info_c.set_num_blobs(1);
+    namespace_info_a.set_blob_size(12);
+    namespace_info_b.set_blob_size(24);
+    namespace_info_c.set_blob_size(36);
+  } else {
+    namespace_info_a.add_blob_file_names(writeBlobProto1.file_name());
+    namespace_info_b.add_blob_file_names(writeBlobProto2.file_name());
+    namespace_info_c.add_blob_file_names(writeBlobProto3.file_name());
+  }
   EXPECT_THAT(storage_info_result.storage_info().namespace_blob_storage_info(),
               UnorderedElementsAre(EqualsProto(namespace_info_a),
                                    EqualsProto(namespace_info_b),
@@ -1219,6 +1300,9 @@ TEST_F(IcingSearchEngineBlobTest, OptimizeNamespaceUsage) {
               UnorderedElementsAre(EqualsProto(namespace_info_b)));
 }
 
+INSTANTIATE_TEST_SUITE_P(IcingSearchEngineBlobTest, IcingSearchEngineBlobTest,
+                         testing::Values(true, false));
+
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/icing-search-engine_delete_test.cc b/icing/icing-search-engine_delete_test.cc
index b85654f..a7e370c 100644
--- a/icing/icing-search-engine_delete_test.cc
+++ b/icing/icing-search-engine_delete_test.cc
@@ -118,8 +118,8 @@ constexpr int64_t kDefaultCreationTimestampMs = 1575492852000;
 IcingSearchEngineOptions GetDefaultIcingOptions() {
   IcingSearchEngineOptions icing_options;
   icing_options.set_base_dir(GetTestBaseDir());
-  icing_options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(
-      true);
+  icing_options.set_enable_qualified_id_join_index_v3(true);
+  icing_options.set_enable_delete_propagation_from(false);
   return icing_options;
 }
 
@@ -191,7 +191,7 @@ TEST_F(IcingSearchEngineDeleteTest, Delete) {
       EqualsProto(expected_get_result_proto));
 }
 
-TEST_F(IcingSearchEngineDeleteTest, DeleteWithJoinDeletePropagation) {
+TEST_F(IcingSearchEngineDeleteTest, DeleteWithDeletePropagation) {
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("Person").AddProperty(
@@ -275,7 +275,10 @@ TEST_F(IcingSearchEngineDeleteTest, DeleteWithJoinDeletePropagation) {
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
           .Build();
 
-  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  options.set_enable_delete_propagation_from(true);
+
+  IcingSearchEngine icing(options, GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
   ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
   ASSERT_THAT(icing.Put(person1).status(), ProtoIsOk());
@@ -956,6 +959,202 @@ TEST_F(IcingSearchEngineDeleteTest, DeleteByQueryNotFound) {
                                        expected_search_result_proto));
 }
 
+TEST_F(IcingSearchEngineDeleteTest, DeleteByQueryWithDeletePropagation) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("Person").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("name")
+                  .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                  .SetCardinality(CARDINALITY_OPTIONAL)))
+          .AddType(
+              SchemaTypeConfigBuilder()
+                  .SetType("Email")
+                  .AddProperty(
+                      PropertyConfigBuilder()
+                          .SetName("subject")
+                          .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                          .SetCardinality(CARDINALITY_OPTIONAL))
+                  .AddProperty(PropertyConfigBuilder()
+                                   .SetName("sender")
+                                   .SetDataTypeJoinableString(
+                                       JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                       DELETE_PROPAGATION_TYPE_PROPAGATE_FROM)
+                                   .SetCardinality(CARDINALITY_OPTIONAL)))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("Message")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("body")
+                                        .SetDataTypeString(TERM_MATCH_PREFIX,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_REQUIRED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("sender")
+                                        .SetDataTypeJoinableString(
+                                            JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                            DELETE_PROPAGATION_TYPE_NONE)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
+          .Build();
+
+  DocumentProto person1 =
+      DocumentBuilder()
+          .SetKey("namespace", "person1")
+          .SetSchema("Person")
+          .AddStringProperty("name", "Alice")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto person2 =
+      DocumentBuilder()
+          .SetKey("namespace", "person2")
+          .SetSchema("Person")
+          .AddStringProperty("name", "Bob")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto person3 =
+      DocumentBuilder()
+          .SetKey("namespace", "person3")
+          .SetSchema("Person")
+          .AddStringProperty("name", "Alice in Wonderland")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto email1 =
+      DocumentBuilder()
+          .SetKey("namespace", "email1")
+          .SetSchema("Email")
+          .AddStringProperty("subject", "test")
+          .AddStringProperty("sender", "namespace#person1")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto email2 =
+      DocumentBuilder()
+          .SetKey("namespace", "email2")
+          .SetSchema("Email")
+          .AddStringProperty("subject", "test")
+          .AddStringProperty("sender", "namespace#person2")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto email3 =
+      DocumentBuilder()
+          .SetKey("namespace", "email3")
+          .SetSchema("Email")
+          .AddStringProperty("subject", "test")
+          .AddStringProperty("sender", "namespace#person3")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto message1 =
+      DocumentBuilder()
+          .SetKey("namespace", "message1")
+          .SetSchema("Message")
+          .AddStringProperty("body", "test")
+          .AddStringProperty("sender", "namespace#person1")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto message2 =
+      DocumentBuilder()
+          .SetKey("namespace", "message2")
+          .SetSchema("Message")
+          .AddStringProperty("body", "test")
+          .AddStringProperty("sender", "namespace#person2")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto message3 =
+      DocumentBuilder()
+          .SetKey("namespace", "message3")
+          .SetSchema("Message")
+          .AddStringProperty("body", "test")
+          .AddStringProperty("sender", "namespace#person3")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  options.set_enable_delete_propagation_from(true);
+
+  IcingSearchEngine icing(options, GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(person1).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(person2).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(person3).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(email1).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(email2).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(email3).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(message1).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(message2).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(message3).status(), ProtoIsOk());
+
+  // Delete by query "alice".
+  SearchSpecProto search_spec;
+  search_spec.set_query("alice");
+  search_spec.set_term_match_type(TermMatchType::EXACT_ONLY);
+
+  DeleteByQueryResultProto result_proto = icing.DeleteByQuery(search_spec);
+  EXPECT_THAT(result_proto.status(), ProtoIsOk());
+  // Person1, person3, email1, and email3 should be deleted.
+  EXPECT_THAT(result_proto.delete_by_query_stats().num_documents_deleted(),
+              Eq(4));
+
+  // Verify Get API for email and message documents.
+  // Email1 should be deleted. The joinable property "sender" in schema type
+  // "Email" has delete propagation type PROPAGATE_FROM and the referenced
+  // document "person1" is deleted.
+  GetResultProto expected_get_result_proto1;
+  expected_get_result_proto1.mutable_status()->set_code(StatusProto::NOT_FOUND);
+  expected_get_result_proto1.mutable_status()->set_message(
+      "Document (namespace, email1) not found.");
+  EXPECT_THAT(
+      icing.Get("namespace", "email1", GetResultSpecProto::default_instance()),
+      EqualsProto(expected_get_result_proto1));
+
+  // Email2 should still exist. The joinable property "sender" in schema type
+  // "Email" has delete propagation type PROPAGATE_FROM but the referenced
+  // document "person2" is not deleted.
+  GetResultProto expected_get_result_google::protobuf;
+  expected_get_result_google::protobuf.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_google::protobuf.mutable_document() = email2;
+  EXPECT_THAT(
+      icing.Get("namespace", "email2", GetResultSpecProto::default_instance()),
+      EqualsProto(expected_get_result_google::protobuf));
+
+  // Email3 should be deleted. The joinable property "sender" in schema type
+  // "Email" has delete propagation type PROPAGATE_FROM and the referenced
+  // document "person3" is deleted.
+  GetResultProto expected_get_result_proto3;
+  expected_get_result_proto3.mutable_status()->set_code(StatusProto::NOT_FOUND);
+  expected_get_result_proto3.mutable_status()->set_message(
+      "Document (namespace, email3) not found.");
+  EXPECT_THAT(
+      icing.Get("namespace", "email3", GetResultSpecProto::default_instance()),
+      EqualsProto(expected_get_result_proto3));
+
+  // Message1 should still exist. The joinable property "sender" in schema type
+  // "Message" has delete propagation type NONE.
+  GetResultProto expected_get_result_proto4;
+  expected_get_result_proto4.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_proto4.mutable_document() = message1;
+  EXPECT_THAT(icing.Get("namespace", "message1",
+                        GetResultSpecProto::default_instance()),
+              EqualsProto(expected_get_result_proto4));
+
+  // Message2 should still exist. The joinable property "sender" in schema type
+  // "Message" has delete propagation type NONE, and the referenced document
+  // "person2" is not deleted.
+  GetResultProto expected_get_result_proto5;
+  expected_get_result_proto5.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_proto5.mutable_document() = message2;
+  EXPECT_THAT(icing.Get("namespace", "message2",
+                        GetResultSpecProto::default_instance()),
+              EqualsProto(expected_get_result_proto5));
+
+  // Message3 should still exist. The joinable property "sender" in schema type
+  // "Message" has delete propagation type NONE.
+  GetResultProto expected_get_result_proto6;
+  expected_get_result_proto6.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_proto6.mutable_document() = message3;
+  EXPECT_THAT(icing.Get("namespace", "message3",
+                        GetResultSpecProto::default_instance()),
+              EqualsProto(expected_get_result_proto6));
+}
+
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/icing-search-engine_initialization_test.cc b/icing/icing-search-engine_initialization_test.cc
index 7643e4c..5fc862b 100644
--- a/icing/icing-search-engine_initialization_test.cc
+++ b/icing/icing-search-engine_initialization_test.cc
@@ -29,6 +29,7 @@
 #include "icing/absl_ports/str_cat.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
+#include "icing/file/file-backed-proto.h"
 #include "icing/file/file-backed-vector.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/memory-mapped-file.h"
@@ -92,6 +93,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -111,12 +113,20 @@ using ::testing::EndsWith;
 using ::testing::Eq;
 using ::testing::HasSubstr;
 using ::testing::IsEmpty;
+using ::testing::IsTrue;
 using ::testing::Matcher;
 using ::testing::Ne;
 using ::testing::Pointee;
 using ::testing::Return;
 using ::testing::SizeIs;
 
+// - Before we only created a marker file for set schema.
+// - Now, we switch to a general marker file for different operations that are
+//   sensitive to power loss or crash.
+// - In order to make the change compatible with old versions for possible
+//   AppSearch mainline rollback, let's keep the old marker file name.
+constexpr std::string_view kGeneralMarkerFilename = "set_schema_marker";
+
 constexpr std::string_view kIpsumText =
     "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla convallis "
     "scelerisque orci quis hendrerit. Sed augue turpis, sodales eu gravida "
@@ -190,10 +200,10 @@ class IcingSearchEngineInitializationTest : public testing::Test {
         lang_segmenter_,
         language_segmenter_factory::Create(std::move(segmenter_options)));
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        normalizer_,
-        normalizer_factory::Create(
-            /*max_term_byte_size=*/std::numeric_limits<int32_t>::max()));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
   }
 
   void TearDown() override {
@@ -249,8 +259,9 @@ IcingSearchEngineOptions GetDefaultIcingOptions() {
   icing_options.set_enable_embedding_index(true);
   icing_options.set_enable_embedding_quantization(true);
   icing_options.set_enable_blob_store(true);
-  icing_options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(
-      true);
+  icing_options.set_enable_qualified_id_join_index_v3(true);
+  icing_options.set_enable_delete_propagation_from(false);
+  icing_options.set_enable_marker_file_for_optimize(true);
   return icing_options;
 }
 
@@ -319,6 +330,19 @@ ScoringSpecProto GetDefaultScoringSpec() {
   return scoring_spec;
 }
 
+SetSchemaRequestProto CreateSetSchemaRequestProto(
+    SchemaProto schema, std::string database,
+    bool ignore_errors_and_delete_documents) {
+  SetSchemaRequestProto set_schema_request;
+
+  *set_schema_request.mutable_schema() = std::move(schema);
+  set_schema_request.set_database(std::move(database));
+  set_schema_request.set_ignore_errors_and_delete_documents(
+      ignore_errors_and_delete_documents);
+
+  return set_schema_request;
+}
+
 // TODO(b/272145329): create SearchSpecBuilder, JoinSpecBuilder,
 // SearchResultProtoBuilder and ResultProtoBuilder for unit tests and build all
 // instances by them.
@@ -472,6 +496,21 @@ TEST_F(IcingSearchEngineInitializationTest,
               ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
 }
 
+TEST_F(IcingSearchEngineInitializationTest,
+       DeletePropagationEnabledAndJoinIndexV3DisabledReturnsInvalidArgument) {
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
+  icing_options.set_enable_qualified_id_join_index_v3(false);
+  icing_options.set_enable_delete_propagation_from(true);
+
+  IcingSearchEngine icing(icing_options, GetTestJniCache());
+  InitializeResultProto initialize_result_proto = icing.Initialize();
+  EXPECT_THAT(initialize_result_proto.status(),
+              ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
+  EXPECT_THAT(initialize_result_proto.status().message(),
+              HasSubstr("Delete propagation is enabled but qualified id join "
+                        "index v3 is not enabled."));
+}
+
 TEST_F(IcingSearchEngineInitializationTest, GoodCompressionLevelReturnsOk) {
   IcingSearchEngineOptions options = GetDefaultIcingOptions();
   options.set_compression_level(0);
@@ -729,6 +768,187 @@ TEST_F(IcingSearchEngineInitializationTest,
   ASSERT_FALSE(filesystem.FileExists(marker_filepath.c_str()));
 }
 
+TEST_F(IcingSearchEngineInitializationTest,
+       SoftIndexRestorationDisabledShouldFailIndexRestorationOnError) {
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
+  icing_options.set_enable_soft_index_restoration(false);
+
+  // Create a schema with indexable integer property "timestamp".
+  SchemaProto email_schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("Email")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("subject")
+                                        .SetDataTypeString(TERM_MATCH_PREFIX,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_REQUIRED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("timestamp")
+                                        .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
+          .Build();
+
+  DocumentProto email1 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("subject", "subject1")
+          .Build();
+  DocumentProto email2 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri2")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("subject", "subject2")
+          .AddInt64Property("timestamp", 123)
+          .Build();
+
+  {
+    // 1. Create an index with a few documents.
+    IcingSearchEngine icing(icing_options, GetTestJniCache());
+    InitializeResultProto init_result = icing.Initialize();
+    ASSERT_THAT(init_result.status(), ProtoIsOk());
+    ASSERT_THAT(init_result.initialize_stats().num_previous_init_failures(),
+                Eq(0));
+    ASSERT_THAT(icing.SetSchema(email_schema).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(email1).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(email2).status(), ProtoIsOk());
+  }
+
+  // 2. Delete integer index to trigger index restoration.
+  ASSERT_TRUE(
+      filesystem()->DeleteDirectoryRecursively(GetIntegerIndexDir().c_str()));
+
+  // 3. Mock filesystem to fail creating "timestamp" integer index storage.
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  ON_CALL(*mock_filesystem,
+          CreateDirectory(HasSubstr(GetIntegerIndexDir() + "/timestamp")))
+      .WillByDefault(Return(false));
+
+  // 4. Initialize IcingSearchEngine again with the mock filesystem. When
+  //    indexing document "uri2", it will fail to create "timestamp" integer
+  //    index storage and fail initialization.
+  TestIcingSearchEngine icing(icing_options, std::move(mock_filesystem),
+                              std::make_unique<IcingFilesystem>(),
+                              std::make_unique<FakeClock>(), GetTestJniCache());
+
+  InitializeResultProto initialize_result = icing.Initialize();
+  EXPECT_THAT(initialize_result.status(), ProtoStatusIs(StatusProto::INTERNAL));
+  EXPECT_THAT(initialize_result.status().message(),
+              HasSubstr("Failed to create directory"));
+}
+
+TEST_F(IcingSearchEngineInitializationTest,
+       SoftIndexRestorationEnabledShouldIgnoreErrorsAndReturnWarningDataLoss) {
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
+  icing_options.set_enable_soft_index_restoration(true);
+
+  // Create a schema with indexable integer property "timestamp".
+  SchemaProto email_schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("Email")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("subject")
+                                        .SetDataTypeString(TERM_MATCH_PREFIX,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_REQUIRED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("timestamp")
+                                        .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
+          .Build();
+
+  DocumentProto email1 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("subject", "subject1")
+          .Build();
+  DocumentProto email2 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri2")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("subject", "subject2")
+          .AddInt64Property("timestamp", 123)
+          .Build();
+
+  {
+    // 1. Create an index with a few documents.
+    IcingSearchEngine icing(icing_options, GetTestJniCache());
+    InitializeResultProto init_result = icing.Initialize();
+    ASSERT_THAT(init_result.status(), ProtoIsOk());
+    ASSERT_THAT(init_result.initialize_stats().num_previous_init_failures(),
+                Eq(0));
+    ASSERT_THAT(icing.SetSchema(email_schema).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(email1).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(email2).status(), ProtoIsOk());
+  }
+
+  // 2. Delete integer index to trigger index restoration.
+  ASSERT_TRUE(
+      filesystem()->DeleteDirectoryRecursively(GetIntegerIndexDir().c_str()));
+
+  // 3. Mock filesystem to fail creating "timestamp" integer index storage.
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  ON_CALL(*mock_filesystem,
+          CreateDirectory(HasSubstr(GetIntegerIndexDir() + "/timestamp")))
+      .WillByDefault(Return(false));
+
+  // 4. Initialize IcingSearchEngine again with the mock filesystem. When
+  //    indexing document "uri2", it will fail to create "timestamp" integer
+  //    index storage, but soft index restoration mechanism should skip the
+  //    error and delete the document without failing initialization.
+  auto fake_clock = std::make_unique<FakeClock>();
+  fake_clock->SetTimerElapsedMilliseconds(10);
+  TestIcingSearchEngine icing(icing_options, std::move(mock_filesystem),
+                              std::make_unique<IcingFilesystem>(),
+                              std::move(fake_clock), GetTestJniCache());
+
+  InitializeResultProto initialize_result = icing.Initialize();
+  EXPECT_THAT(initialize_result.status(),
+              ProtoStatusIs(StatusProto::WARNING_DATA_LOSS));
+
+  EXPECT_THAT(
+      initialize_result.initialize_stats().document_store_recovery_cause(),
+      Eq(InitializeStatsProto::NONE));
+  // Indices should be restored.
+  EXPECT_THAT(
+      initialize_result.initialize_stats().index_restoration_latency_ms(),
+      Eq(10));
+  EXPECT_THAT(
+      initialize_result.initialize_stats().num_failed_reindexed_documents(),
+      Eq(1));
+  EXPECT_THAT(initialize_result.initialize_stats().index_restoration_cause(),
+              Eq(InitializeStatsProto::NONE));
+  EXPECT_THAT(
+      initialize_result.initialize_stats().integer_index_restoration_cause(),
+      Eq(InitializeStatsProto::INCONSISTENT_WITH_GROUND_TRUTH));
+  EXPECT_THAT(initialize_result.initialize_stats()
+                  .qualified_id_join_index_restoration_cause(),
+              Eq(InitializeStatsProto::NONE));
+  EXPECT_THAT(
+      initialize_result.initialize_stats().embedding_index_restoration_cause(),
+      Eq(InitializeStatsProto::NONE));
+
+  // ("namespace", "uri1") should be found.
+  GetResultProto expected_get_result_proto;
+  expected_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_proto.mutable_document() = email1;
+  EXPECT_THAT(
+      icing.Get("namespace", "uri1", GetResultSpecProto::default_instance()),
+      EqualsProto(expected_get_result_proto));
+  // ("namespace", "uri2") should be deleted.
+  EXPECT_THAT(
+      icing.Get("namespace", "uri2", GetResultSpecProto::default_instance())
+          .status(),
+      ProtoStatusIs(StatusProto::NOT_FOUND));
+}
+
 TEST_F(IcingSearchEngineInitializationTest, RecoverFromMissingHeaderFile) {
   SearchSpecProto search_spec;
   search_spec.set_query("message");
@@ -927,11 +1147,15 @@ TEST_F(IcingSearchEngineInitializationTest,
                     .SetCardinality(CARDINALITY_OPTIONAL))
             .Build();
 
-    // Write the marker file
+    // Write the general marker file
+    auto marker_proto = std::make_unique<IcingSearchEngineMarkerProto>();
+    marker_proto->set_operation_type(
+        IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA);
     std::string marker_filepath =
-        absl_ports::StrCat(options.base_dir(), "/set_schema_marker");
-    ScopedFd sfd(filesystem()->OpenForWrite(marker_filepath.c_str()));
-    ASSERT_TRUE(sfd.is_valid());
+        absl_ports::StrCat(options.base_dir(), "/", kGeneralMarkerFilename);
+    FileBackedProto<IcingSearchEngineMarkerProto> marker_file(*filesystem(),
+                                                              marker_filepath);
+    ICING_ASSERT_OK(marker_file.Write(std::move(marker_proto)));
 
     // Write the new schema
     FakeClock fake_clock;
@@ -940,8 +1164,7 @@ TEST_F(IcingSearchEngineInitializationTest,
         SchemaStore::Create(filesystem(), GetSchemaDir(), &fake_clock,
                             feature_flags_.get()));
     ICING_EXPECT_OK(schema_store->SetSchema(
-        new_schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        new_schema, /*ignore_errors_and_delete_documents=*/false));
   }  // Will persist new schema
 
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
@@ -1007,6 +1230,152 @@ TEST_F(IcingSearchEngineInitializationTest,
                                         expected_search_result_google::protobuf));
 }
 
+TEST_F(IcingSearchEngineInitializationTest, RecoverFromInconsistentOptimize) {
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("icing", "fake_type/0")
+          .SetSchema("Message")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("body", "message body")
+          .AddInt64Property("indexableInteger", 123)
+          .Build();
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("icing", "fake_type/1")
+          .SetSchema("Message")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("body", "test")
+          .AddInt64Property("indexableInteger", 456)
+          .Build();
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  {
+    // Initialize and put document1.
+    IcingSearchEngine icing(options, GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+    ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+  }
+
+  {
+    // Manually merge lite index into main index. All hits for "fake_type/0"
+    // will be moved into main index.
+    Index::Options options(GetIndexDir(), /*index_merge_size=*/1024 * 1024,
+                           /*lite_index_sort_at_indexing=*/true,
+                           /*lite_index_sort_size=*/1024 * 8);
+    ICING_ASSERT_OK_AND_ASSIGN(
+        std::unique_ptr<Index> index,
+        Index::Create(options, filesystem(), icing_filesystem()));
+    ICING_ASSERT_OK(index->Merge());
+    ICING_ASSERT_OK(index->PersistToDisk());
+  }
+
+  {
+    // Initialize again and put document2. All hits for "fake_type/1" will be
+    // added into lite index.
+    IcingSearchEngine icing(options, GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
+
+    // Delete document1.
+    ASSERT_THAT(icing.Delete(document1.namespace_(), document1.uri()).status(),
+                ProtoIsOk());
+  }
+
+  {
+    FakeClock fake_clock;
+
+    // Simulate optimize where power is lost after document store is optimized,
+    // but indices are not.
+    ICING_ASSERT_OK_AND_ASSIGN(
+        std::unique_ptr<SchemaStore> schema_store,
+        SchemaStore::Create(filesystem(), GetSchemaDir(), &fake_clock,
+                            feature_flags_.get()));
+
+    std::string doc_store_dir = GetDocumentDir();
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::CreateResult create_result,
+        DocumentStore::Create(filesystem(), doc_store_dir, &fake_clock,
+                              schema_store.get(), feature_flags_.get(),
+                              /*force_recovery_and_revalidate_documents=*/false,
+                              /*pre_mapping_fbv=*/false,
+                              /*use_persistent_hash_map=*/true,
+                              PortableFileBackedProtoLog<
+                                  DocumentWrapper>::kDefaultCompressionLevel,
+                              /*initialize_stats=*/nullptr));
+    std::unique_ptr<DocumentStore> document_store =
+        std::move(create_result.document_store);
+
+    std::string temp_doc_store_dir = doc_store_dir + "_temp";
+    ASSERT_THAT(filesystem()->CreateDirectory(temp_doc_store_dir.c_str()),
+                IsTrue());
+    ICING_ASSERT_OK(document_store->OptimizeInto(temp_doc_store_dir,
+                                                 lang_segmenter_.get(),
+                                                 /*expired_blob_handles=*/{}));
+    ICING_ASSERT_OK(document_store->PersistToDisk(PersistType::FULL));
+    document_store.reset();
+
+    ASSERT_THAT(filesystem()->SwapFiles(doc_store_dir.c_str(),
+                                        temp_doc_store_dir.c_str()),
+                IsTrue());
+
+    // Write the general marker file
+    auto marker_proto = std::make_unique<IcingSearchEngineMarkerProto>();
+    marker_proto->set_operation_type(
+        IcingSearchEngineMarkerProto::OperationType::OPTIMIZE);
+    std::string marker_filepath =
+        absl_ports::StrCat(options.base_dir(), "/", kGeneralMarkerFilename);
+    FileBackedProto<IcingSearchEngineMarkerProto> marker_file(*filesystem(),
+                                                              marker_filepath);
+    ICING_ASSERT_OK(marker_file.Write(std::move(marker_proto)));
+  }
+
+  // Initialize should succeed and all derived files should be rebuilt.
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  EXPECT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+  // Before rebuilding:
+  // - Main index has document id 0 hit for "message".
+  // - Lite index has document id 1 hit for "test".
+  // - Last added document id:
+  //   - Document store: 0
+  //   - Lite index: 1
+  //   - Main index: 0
+  //
+  // Since "fake_type/0" is deleted and Optimize for document store has been
+  // done, document id 0 now represents "fake_type/1". If we don't have the
+  // optimize marker file, then Icing initialize mechanism will only throw away
+  // the lite index without rebuilding. Then, searching "message" or "test" will
+  // get hits of old document ids from the term index and therefore match the
+  // incorrect document(s).
+  //
+  // Here we verify 2 searches to make sure that indices should be rebuilt and
+  // the correct results are returned.
+
+  // Searching "message" will not get "fake_type/1".
+  SearchResultProto expected_search_result_proto1;
+  expected_search_result_proto1.mutable_status()->set_code(StatusProto::OK);
+  SearchSpecProto search_spec1;
+  search_spec1.set_query("message");
+  search_spec1.set_term_match_type(TermMatchType::EXACT_ONLY);
+  EXPECT_THAT(
+      icing.Search(search_spec1, GetDefaultScoringSpec(),
+                   ResultSpecProto::default_instance()),
+      EqualsSearchResultIgnoreStatsAndScores(expected_search_result_proto1));
+
+  // Searching "test" will get "fake_type/1".
+  SearchResultProto expected_search_result_google::protobuf;
+  expected_search_result_google::protobuf.mutable_status()->set_code(StatusProto::OK);
+  *expected_search_result_google::protobuf.mutable_results()->Add()->mutable_document() =
+      document2;
+  SearchSpecProto search_spec2;
+  search_spec2.set_query("test");
+  search_spec2.set_term_match_type(TermMatchType::EXACT_ONLY);
+  EXPECT_THAT(
+      icing.Search(search_spec2, GetDefaultScoringSpec(),
+                   ResultSpecProto::default_instance()),
+      EqualsSearchResultIgnoreStatsAndScores(expected_search_result_google::protobuf));
+}
+
 TEST_F(IcingSearchEngineInitializationTest,
        RecoverFromInconsistentDocumentStore) {
   // Test the following scenario: document store is ahead of term, integer and
@@ -1100,10 +1469,11 @@ TEST_F(IcingSearchEngineInitializationTest,
 
     ICING_ASSERT_OK_AND_ASSIGN(
         BlobStore blob_store,
-        BlobStore::Create(filesystem(), GetBlobDir(), &fake_clock,
-                          /*orphan_blob_time_to_live_ms=*/0,
-                          PortableFileBackedProtoLog<
-                              BlobInfoProto>::kDefaultCompressionLevel));
+        BlobStore::Create(
+            filesystem(), GetBlobDir(), &fake_clock,
+            /*orphan_blob_time_to_live_ms=*/0,
+            PortableFileBackedProtoLog<BlobInfoProto>::kDefaultCompressionLevel,
+            /*manage_blob_files=*/true));
 
     // Puts message2 into DocumentStore but doesn't index it.
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -4905,11 +5275,15 @@ TEST_F(IcingSearchEngineInitializationTest,
                                                         TOKENIZER_PLAIN)
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
-    // Write the marker file
+    // Write the general marker file
+    auto marker_proto = std::make_unique<IcingSearchEngineMarkerProto>();
+    marker_proto->set_operation_type(
+        IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA);
     std::string marker_filepath =
-        absl_ports::StrCat(options.base_dir(), "/set_schema_marker");
-    ScopedFd sfd(filesystem()->OpenForWrite(marker_filepath.c_str()));
-    ASSERT_TRUE(sfd.is_valid());
+        absl_ports::StrCat(options.base_dir(), "/", kGeneralMarkerFilename);
+    FileBackedProto<IcingSearchEngineMarkerProto> marker_file(*filesystem(),
+                                                              marker_filepath);
+    ICING_ASSERT_OK(marker_file.Write(std::move(marker_proto)));
 
     // Write the new schema
     FakeClock fake_clock;
@@ -4918,8 +5292,7 @@ TEST_F(IcingSearchEngineInitializationTest,
         SchemaStore::Create(filesystem(), GetSchemaDir(), &fake_clock,
                             feature_flags_.get()));
     ICING_EXPECT_OK(schema_store->SetSchema(
-        new_schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        new_schema, /*ignore_errors_and_delete_documents=*/false));
   }
 
   {
@@ -4932,18 +5305,16 @@ TEST_F(IcingSearchEngineInitializationTest,
                                 std::move(fake_clock), GetTestJniCache());
     InitializeResultProto initialize_result_proto = icing.Initialize();
     EXPECT_THAT(initialize_result_proto.status(), ProtoIsOk());
-    EXPECT_THAT(
-        initialize_result_proto.initialize_stats().index_restoration_cause(),
-        Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
-    EXPECT_THAT(initialize_result_proto.initialize_stats()
-                    .integer_index_restoration_cause(),
-                Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
+
+    // Schema store recovery stats.
     EXPECT_THAT(initialize_result_proto.initialize_stats()
-                    .qualified_id_join_index_restoration_cause(),
+                    .schema_store_recovery_cause(),
                 Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
     EXPECT_THAT(initialize_result_proto.initialize_stats()
-                    .index_restoration_latency_ms(),
+                    .schema_store_recovery_latency_ms(),
                 Eq(10));
+
+    // Document store recovery stats.
     EXPECT_THAT(initialize_result_proto.initialize_stats()
                     .document_store_recovery_cause(),
                 Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
@@ -4953,12 +5324,29 @@ TEST_F(IcingSearchEngineInitializationTest,
     EXPECT_THAT(
         initialize_result_proto.initialize_stats().document_store_data_status(),
         Eq(InitializeStatsProto::NO_DATA_LOSS));
+
+    // Term index recovery stats.
+    EXPECT_THAT(
+        initialize_result_proto.initialize_stats().index_restoration_cause(),
+        Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
     EXPECT_THAT(initialize_result_proto.initialize_stats()
-                    .schema_store_recovery_cause(),
-                Eq(InitializeStatsProto::NONE));
+                    .index_restoration_latency_ms(),
+                Eq(10));
+
+    // Integer index recovery stats.
     EXPECT_THAT(initialize_result_proto.initialize_stats()
-                    .schema_store_recovery_latency_ms(),
-                Eq(0));
+                    .integer_index_restoration_cause(),
+                Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
+
+    // Qualified id join index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .qualified_id_join_index_restoration_cause(),
+                Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
+
+    // Embedding index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .embedding_index_restoration_cause(),
+                Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
   }
 
   {
@@ -4971,18 +5359,198 @@ TEST_F(IcingSearchEngineInitializationTest,
                                 std::move(fake_clock), GetTestJniCache());
     InitializeResultProto initialize_result_proto = icing.Initialize();
     EXPECT_THAT(initialize_result_proto.status(), ProtoIsOk());
+
+    // Schema store recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .schema_store_recovery_cause(),
+                Eq(InitializeStatsProto::NONE));
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .schema_store_recovery_latency_ms(),
+                Eq(0));
+
+    // Document store recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .document_store_recovery_cause(),
+                Eq(InitializeStatsProto::NONE));
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .document_store_recovery_latency_ms(),
+                Eq(0));
+    EXPECT_THAT(
+        initialize_result_proto.initialize_stats().document_store_data_status(),
+        Eq(InitializeStatsProto::NO_DATA_LOSS));
+
+    // Term index recovery stats.
     EXPECT_THAT(
         initialize_result_proto.initialize_stats().index_restoration_cause(),
         Eq(InitializeStatsProto::NONE));
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .index_restoration_latency_ms(),
+                Eq(0));
+
+    // Integer index recovery stats.
     EXPECT_THAT(initialize_result_proto.initialize_stats()
                     .integer_index_restoration_cause(),
                 Eq(InitializeStatsProto::NONE));
+
+    // Qualified id join index recovery stats.
     EXPECT_THAT(initialize_result_proto.initialize_stats()
                     .qualified_id_join_index_restoration_cause(),
                 Eq(InitializeStatsProto::NONE));
+
+    // Embedding index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .embedding_index_restoration_cause(),
+                Eq(InitializeStatsProto::NONE));
+  }
+}
+
+TEST_F(IcingSearchEngineInitializationTest,
+       InitializeShouldLogRecoveryCauseOptimizeOutOfSync) {
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("icing", "fake_type/0")
+          .SetSchema("Message")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("body", "message body")
+          .AddInt64Property("indexableInteger", 123)
+          .Build();
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("icing", "fake_type/1")
+          .SetSchema("Message")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("body", "test")
+          .AddInt64Property("indexableInteger", 456)
+          .Build();
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  {
+    // Initialize and put document1.
+    IcingSearchEngine icing(options, GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+    ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+  }
+
+  auto fake_clock = std::make_unique<FakeClock>();
+  {
+    // Simulate optimize where power is lost after document store is optimized,
+    // but indices are not.
+    ICING_ASSERT_OK_AND_ASSIGN(
+        std::unique_ptr<SchemaStore> schema_store,
+        SchemaStore::Create(filesystem(), GetSchemaDir(), fake_clock.get(),
+                            feature_flags_.get()));
+
+    std::string doc_store_dir = GetDocumentDir();
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::CreateResult create_result,
+        DocumentStore::Create(filesystem(), doc_store_dir, fake_clock.get(),
+                              schema_store.get(), feature_flags_.get(),
+                              /*force_recovery_and_revalidate_documents=*/false,
+                              /*pre_mapping_fbv=*/false,
+                              /*use_persistent_hash_map=*/true,
+                              PortableFileBackedProtoLog<
+                                  DocumentWrapper>::kDefaultCompressionLevel,
+                              /*initialize_stats=*/nullptr));
+    std::unique_ptr<DocumentStore> document_store =
+        std::move(create_result.document_store);
+
+    std::string temp_doc_store_dir = doc_store_dir + "_temp";
+    ASSERT_THAT(filesystem()->CreateDirectory(temp_doc_store_dir.c_str()),
+                IsTrue());
+    ICING_ASSERT_OK(document_store->OptimizeInto(temp_doc_store_dir,
+                                                 lang_segmenter_.get(),
+                                                 /*expired_blob_handles=*/{}));
+    ICING_ASSERT_OK(document_store->PersistToDisk(PersistType::FULL));
+    document_store.reset();
+
+    ASSERT_THAT(filesystem()->SwapFiles(doc_store_dir.c_str(),
+                                        temp_doc_store_dir.c_str()),
+                IsTrue());
+
+    // Write the general marker file
+    auto marker_proto = std::make_unique<IcingSearchEngineMarkerProto>();
+    marker_proto->set_operation_type(
+        IcingSearchEngineMarkerProto::OperationType::OPTIMIZE);
+    std::string marker_filepath =
+        absl_ports::StrCat(options.base_dir(), "/", kGeneralMarkerFilename);
+    FileBackedProto<IcingSearchEngineMarkerProto> marker_file(*filesystem(),
+                                                              marker_filepath);
+    ICING_ASSERT_OK(marker_file.Write(std::move(marker_proto)));
+  }
+
+  {
+    // All derived files should be rebuilt.
+    fake_clock->SetTimerElapsedMilliseconds(10);
+    TestIcingSearchEngine icing(GetDefaultIcingOptions(),
+                                std::make_unique<Filesystem>(),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    InitializeResultProto initialize_result_proto = icing.Initialize();
+    EXPECT_THAT(initialize_result_proto.status(), ProtoIsOk());
+
+    // Schema store recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .schema_store_recovery_cause(),
+                Eq(InitializeStatsProto::OPTIMIZE_OUT_OF_SYNC));
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .schema_store_recovery_latency_ms(),
+                Eq(10));
+
+    // Document store recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .document_store_recovery_cause(),
+                Eq(InitializeStatsProto::OPTIMIZE_OUT_OF_SYNC));
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .document_store_recovery_latency_ms(),
+                Eq(10));
+    EXPECT_THAT(
+        initialize_result_proto.initialize_stats().document_store_data_status(),
+        Eq(InitializeStatsProto::NO_DATA_LOSS));
+
+    // Term index recovery stats.
+    EXPECT_THAT(
+        initialize_result_proto.initialize_stats().index_restoration_cause(),
+        Eq(InitializeStatsProto::OPTIMIZE_OUT_OF_SYNC));
     EXPECT_THAT(initialize_result_proto.initialize_stats()
                     .index_restoration_latency_ms(),
+                Eq(10));
+
+    // Integer index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .integer_index_restoration_cause(),
+                Eq(InitializeStatsProto::OPTIMIZE_OUT_OF_SYNC));
+
+    // Qualified id join index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .qualified_id_join_index_restoration_cause(),
+                Eq(InitializeStatsProto::OPTIMIZE_OUT_OF_SYNC));
+
+    // Embedding index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .embedding_index_restoration_cause(),
+                Eq(InitializeStatsProto::OPTIMIZE_OUT_OF_SYNC));
+  }
+
+  {
+    // Initialize again. No recovery should be needed.
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetTimerElapsedMilliseconds(10);
+    TestIcingSearchEngine icing(GetDefaultIcingOptions(),
+                                std::make_unique<Filesystem>(),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    InitializeResultProto initialize_result_proto = icing.Initialize();
+    EXPECT_THAT(initialize_result_proto.status(), ProtoIsOk());
+
+    // Schema store recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .schema_store_recovery_cause(),
+                Eq(InitializeStatsProto::NONE));
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .schema_store_recovery_latency_ms(),
                 Eq(0));
+
+    // Document store recovery stats.
     EXPECT_THAT(initialize_result_proto.initialize_stats()
                     .document_store_recovery_cause(),
                 Eq(InitializeStatsProto::NONE));
@@ -4992,12 +5560,29 @@ TEST_F(IcingSearchEngineInitializationTest,
     EXPECT_THAT(
         initialize_result_proto.initialize_stats().document_store_data_status(),
         Eq(InitializeStatsProto::NO_DATA_LOSS));
+
+    // Term index recovery stats.
+    EXPECT_THAT(
+        initialize_result_proto.initialize_stats().index_restoration_cause(),
+        Eq(InitializeStatsProto::NONE));
     EXPECT_THAT(initialize_result_proto.initialize_stats()
-                    .schema_store_recovery_cause(),
+                    .index_restoration_latency_ms(),
+                Eq(0));
+
+    // Integer index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .integer_index_restoration_cause(),
                 Eq(InitializeStatsProto::NONE));
+
+    // Qualified id join index recovery stats.
     EXPECT_THAT(initialize_result_proto.initialize_stats()
-                    .schema_store_recovery_latency_ms(),
-                Eq(0));
+                    .qualified_id_join_index_restoration_cause(),
+                Eq(InitializeStatsProto::NONE));
+
+    // Embedding index recovery stats.
+    EXPECT_THAT(initialize_result_proto.initialize_stats()
+                    .embedding_index_restoration_cause(),
+                Eq(InitializeStatsProto::NONE));
   }
 }
 
@@ -5503,10 +6088,11 @@ TEST_P(IcingSearchEngineInitializationVersionChangeTest,
 
     ICING_ASSERT_OK_AND_ASSIGN(
         BlobStore blob_store,
-        BlobStore::Create(filesystem(), GetBlobDir(), &fake_clock,
-                          /*orphan_blob_time_to_live_ms=*/0,
-                          PortableFileBackedProtoLog<
-                              BlobInfoProto>::kDefaultCompressionLevel));
+        BlobStore::Create(
+            filesystem(), GetBlobDir(), &fake_clock,
+            /*orphan_blob_time_to_live_ms=*/0,
+            PortableFileBackedProtoLog<BlobInfoProto>::kDefaultCompressionLevel,
+            /*manage_blob_files=*/true));
 
     // Put message into DocumentStore
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -6418,27 +7004,49 @@ TEST_P(IcingSearchEngineInitializationSchemaDatabaseMigrationTest,
                            .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
                            .SetCardinality(CARDINALITY_OPTIONAL))
           .Build();
-
+  SchemaTypeConfigProto db1_email_type_with_db =
+      SchemaTypeConfigBuilder(db1_email_type).SetDatabase("db1").Build();
+  SchemaTypeConfigProto db2_email_type_with_db =
+      SchemaTypeConfigBuilder(db2_email_type).SetDatabase("db2").Build();
+
+  SchemaProto previous_version_db1_schema;
+  SchemaProto previous_version_db2_schema;
+  SchemaBuilder previous_version_full_schema_builder;
+  SetSchemaRequestProto set_schema_request;
   if (previous_version_has_schema_database_enabled) {
-    // Populate the database field for the db1/email type.
-    db1_email_type =
-        SchemaTypeConfigBuilder(db1_email_type).SetDatabase("db1").Build();
+    // Set db1/email schema to always populate the database field.
+    previous_version_full_schema_builder.AddType(db1_email_type_with_db);
+    previous_version_db1_schema =
+        SchemaBuilder().AddType(db1_email_type_with_db).Build();
+
     if (existing_version >= version_util::kSchemaDatabaseVersion) {
       // Populate the database field for the db2/email type only if previous
       // version is a post schema-database version.
-      db2_email_type =
-          SchemaTypeConfigBuilder(db2_email_type).SetDatabase("db2").Build();
+      previous_version_full_schema_builder.AddType(db2_email_type_with_db);
+      previous_version_db2_schema =
+          SchemaBuilder().AddType(db2_email_type_with_db).Build();
+    } else {
+      // Otherwise, the database field is not populated for db2/email type. This
+      // is to simulate the following situation:
+      // 1. Icing is initialized on a version>kSchemaDatabaseVersion with schema
+      //    database enabled, and db1/email is set with the database field
+      //    populated.
+      // 2. Icing gets rolled back to pre-schema database version, db2/email is
+      //    set during this time so the database field is not populated.
+      previous_version_full_schema_builder.AddType(db2_email_type);
+      previous_version_db2_schema =
+          SchemaBuilder().AddType(db2_email_type).Build();
     }
-    // Otherwise, the database field is not populated for db2/email type. This
-    // is to simulate the following situation:
-    // 1. Icing is initialized on a version>kSchemaDatabaseVersion with schema
-    //    database enabled, and db1/email is set with the database field
-    //    populated.
-    // 2. Icing gets rolled back to pre-schema database version, db2/email is
-    //    set during this time so the database field is not populated.
+  } else {
+    previous_version_full_schema_builder.AddType(db1_email_type)
+        .AddType(db2_email_type);
+    previous_version_db1_schema =
+        SchemaBuilder().AddType(db1_email_type).Build();
+    previous_version_db2_schema =
+        SchemaBuilder().AddType(db2_email_type).Build();
   }
   SchemaProto previous_version_schema =
-      SchemaBuilder().AddType(db1_email_type).AddType(db2_email_type).Build();
+      previous_version_full_schema_builder.Build();
 
   DocumentProto db1_email_doc =
       DocumentBuilder()
@@ -6467,15 +7075,21 @@ TEST_P(IcingSearchEngineInitializationSchemaDatabaseMigrationTest,
     EXPECT_THAT(icing.Initialize().status(), ProtoIsOk());
     // 1. Set schema.
     if (options.enable_schema_database()) {
-      // Need to set schemas with a single database field at a time.
-      ASSERT_THAT(
-          icing.SetSchema(SchemaBuilder().AddType(db1_email_type).Build())
-              .status(),
-          ProtoIsOk());
-      ASSERT_THAT(
-          icing.SetSchema(SchemaBuilder().AddType(db2_email_type).Build())
-              .status(),
-          ProtoIsOk());
+      // Can only set schema for a single database at a time.
+      ASSERT_THAT(icing
+                      .SetSchema(CreateSetSchemaRequestProto(
+                          previous_version_db1_schema,
+                          previous_version_db1_schema.types(0).database(),
+                          /*ignore_errors_and_delete_documents=*/false))
+                      .status(),
+                  ProtoIsOk());
+      ASSERT_THAT(icing
+                      .SetSchema(CreateSetSchemaRequestProto(
+                          previous_version_db2_schema,
+                          previous_version_db2_schema.types(0).database(),
+                          /*ignore_errors_and_delete_documents=*/false))
+                      .status(),
+                  ProtoIsOk());
     } else {
       ASSERT_THAT(icing.SetSchema(previous_version_schema).status(),
                   ProtoIsOk());
@@ -6686,7 +7300,7 @@ TEST_P(IcingSearchEngineInitializationChangeEnableJoinIndexV3FlagTest,
 
   {
     IcingSearchEngineOptions options = GetDefaultIcingOptions();
-    options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(
+    options.set_enable_qualified_id_join_index_v3(
         enable_join_index_v3_flags.at(0));
     TestIcingSearchEngine icing(options, std::make_unique<Filesystem>(),
                                 std::make_unique<IcingFilesystem>(),
@@ -6700,7 +7314,7 @@ TEST_P(IcingSearchEngineInitializationChangeEnableJoinIndexV3FlagTest,
   }
 
   // Create icing multiple times with different
-  // enable_qualified_id_join_index_v3_and_propagate_delete flags.
+  // enable_qualified_id_join_index_v3 flags.
   for (int i = 1; i < enable_join_index_v3_flags.size(); ++i) {
     bool flag_changed =
         enable_join_index_v3_flags[i] != enable_join_index_v3_flags[i - 1];
@@ -6708,7 +7322,7 @@ TEST_P(IcingSearchEngineInitializationChangeEnableJoinIndexV3FlagTest,
     // Ensure that the qualified id join index is rebuilt if the flag is
     // changed.
     IcingSearchEngineOptions options = GetDefaultIcingOptions();
-    options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(
+    options.set_enable_qualified_id_join_index_v3(
         enable_join_index_v3_flags[i]);
     TestIcingSearchEngine icing(options, std::make_unique<Filesystem>(),
                                 std::make_unique<IcingFilesystem>(),
diff --git a/icing/icing-search-engine_initialize_icu_failure_test.cc b/icing/icing-search-engine_initialize_icu_failure_test.cc
new file mode 100644
index 0000000..c6a12b6
--- /dev/null
+++ b/icing/icing-search-engine_initialize_icu_failure_test.cc
@@ -0,0 +1,154 @@
+// Copyright (C) 2024 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include <cstdint>
+#include <string>
+#include <utility>
+
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+#include "icing/document-builder.h"
+#include "icing/file/filesystem.h"
+#include "icing/icing-search-engine.h"
+#include "icing/proto/document.pb.h"
+#include "icing/schema-builder.h"
+#include "icing/testing/common-matchers.h"
+#include "icing/testing/jni-test-helpers.h"
+#include "icing/testing/tmp-directory.h"
+
+namespace icing {
+namespace lib {
+
+namespace {
+
+using ::icing::lib::portable_equals_proto::EqualsProto;
+using ::testing::HasSubstr;
+using ::testing::SizeIs;
+
+std::string GetTestBaseDir() { return GetTestTempDir() + "/icing"; }
+
+// ICU initialization is effectively global and cannot be reset between tests.
+// In order to properly test ICU initialization failure cases, we need an
+// independent test class.
+// If ICU initialization is unsuccessful, Reverse JNI will be used to
+// support segmentation.
+class IcingSearchEngineInitializeIcuFailureTest : public testing::Test {
+ protected:
+  void SetUp() override {
+    filesystem_.CreateDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  void TearDown() override {
+    filesystem_.DeleteDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  const Filesystem* filesystem() const { return &filesystem_; }
+
+ private:
+  Filesystem filesystem_;
+};
+
+// Non-zero value so we don't override it to be the current time
+constexpr int64_t kDefaultCreationTimestampMs = 1575492852000;
+
+SchemaProto CreateMessageSchema() {
+  return SchemaBuilder()
+      .AddType(SchemaTypeConfigBuilder().SetType("Message").AddProperty(
+          PropertyConfigBuilder()
+              .SetName("body")
+              .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+              .SetCardinality(CARDINALITY_REQUIRED)))
+      .Build();
+}
+
+DocumentProto CreateMessageDocument(std::string name_space, std::string uri,
+                                    std::string string_value) {
+  return DocumentBuilder()
+      .SetKey(std::move(name_space), std::move(uri))
+      .SetSchema("Message")
+      .AddStringProperty("body", std::move(string_value))
+      .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+      .Build();
+}
+
+TEST_F(IcingSearchEngineInitializeIcuFailureTest,
+       InitializeIcuDataNotSpecifiedFails) {
+  IcingSearchEngineOptions icing_options;
+  icing_options.set_base_dir(GetTestBaseDir());
+  // ICU data file path is not specified.
+  IcingSearchEngine icing(icing_options, GetTestJniCache());
+
+  InitializeResultProto initialize_result = icing.Initialize();
+  ASSERT_THAT(initialize_result.status(), ProtoIsOk());
+  ASSERT_THAT(initialize_result.initialize_stats().initialize_icu_data_status(),
+              ProtoStatusIs(StatusProto::INVALID_ARGUMENT,
+                            HasSubstr("ICU data file path is empty.")));
+
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  DocumentProto document =
+      CreateMessageDocument("namespace1", "uri1", "foo bar baz qux");
+  ASSERT_THAT(icing.Put(document).status(), ProtoIsOk());
+
+  SearchSpecProto search_spec;
+  search_spec.set_term_match_type(TermMatchType::PREFIX);
+  search_spec.set_query("qux");
+
+  ScoringSpecProto scoring_spec;
+  scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::NONE);
+
+  SearchResultProto results = icing.Search(search_spec, scoring_spec,
+                                           ResultSpecProto::default_instance());
+  EXPECT_THAT(results.status(), ProtoIsOk());
+  EXPECT_THAT(results.results(), SizeIs(1));
+  EXPECT_THAT(results.results(0).document(), EqualsProto(document));
+}
+
+TEST_F(IcingSearchEngineInitializeIcuFailureTest,
+       InitializeIcuDataInvalidPathFails) {
+  const std::string icu_data_file_absolute_path = "invalid path";
+  IcingSearchEngineOptions icing_options;
+  icing_options.set_base_dir(GetTestBaseDir());
+  icing_options.set_icu_data_file_absolute_path(icu_data_file_absolute_path);
+  IcingSearchEngine icing(icing_options, GetTestJniCache());
+
+  InitializeResultProto initialize_result = icing.Initialize();
+  ASSERT_THAT(initialize_result.status(), ProtoIsOk());
+  ASSERT_THAT(initialize_result.initialize_stats().initialize_icu_data_status(),
+              ProtoStatusIs(StatusProto::INTERNAL));
+
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  DocumentProto document =
+      CreateMessageDocument("namespace1", "uri1", "foo bar");
+  ASSERT_THAT(icing.Put(document).status(), ProtoIsOk());
+
+  SearchSpecProto search_spec;
+  search_spec.set_term_match_type(TermMatchType::PREFIX);
+  search_spec.set_query("bar");
+
+  ScoringSpecProto scoring_spec;
+  scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::NONE);
+
+  SearchResultProto results = icing.Search(search_spec, scoring_spec,
+                                           ResultSpecProto::default_instance());
+  EXPECT_THAT(results.status(), ProtoIsOk());
+  EXPECT_THAT(results.results(), SizeIs(1));
+  EXPECT_THAT(results.results(0).document(), EqualsProto(document));
+}
+
+}  // namespace
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/icing-search-engine_initialize_icu_success_test.cc b/icing/icing-search-engine_initialize_icu_success_test.cc
new file mode 100644
index 0000000..f284bc6
--- /dev/null
+++ b/icing/icing-search-engine_initialize_icu_success_test.cc
@@ -0,0 +1,121 @@
+// Copyright (C) 2024 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include <cstdint>
+#include <string>
+#include <utility>
+
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+#include "icing/document-builder.h"
+#include "icing/file/filesystem.h"
+#include "icing/icing-search-engine.h"
+#include "icing/proto/document.pb.h"
+#include "icing/schema-builder.h"
+#include "icing/testing/common-matchers.h"
+#include "icing/testing/test-data.h"
+#include "icing/testing/tmp-directory.h"
+
+namespace icing {
+namespace lib {
+
+namespace {
+
+using ::icing::lib::portable_equals_proto::EqualsProto;
+using ::testing::SizeIs;
+
+std::string GetTestBaseDir() { return GetTestTempDir() + "/icing"; }
+
+// ICU initialization is effectively global and cannot be reset between tests.
+// In order to properly test ICU initialization success cases, we need an
+// independent test class.
+// If ICU initialization is successful, ICU will be used to
+// support segmentation.
+class IcingSearchEngineInitializeIcuSuccessTest : public testing::Test {
+ protected:
+  void SetUp() override {
+    filesystem_.CreateDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  void TearDown() override {
+    filesystem_.DeleteDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  const Filesystem* filesystem() const { return &filesystem_; }
+
+ private:
+  Filesystem filesystem_;
+};
+
+// Non-zero value so we don't override it to be the current time
+constexpr int64_t kDefaultCreationTimestampMs = 1575492852000;
+
+SchemaProto CreateMessageSchema() {
+  return SchemaBuilder()
+      .AddType(SchemaTypeConfigBuilder().SetType("Message").AddProperty(
+          PropertyConfigBuilder()
+              .SetName("body")
+              .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+              .SetCardinality(CARDINALITY_REQUIRED)))
+      .Build();
+}
+
+DocumentProto CreateMessageDocument(std::string name_space, std::string uri,
+                                    std::string string_value) {
+  return DocumentBuilder()
+      .SetKey(std::move(name_space), std::move(uri))
+      .SetSchema("Message")
+      .AddStringProperty("body", std::move(string_value))
+      .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+      .Build();
+}
+
+TEST_F(IcingSearchEngineInitializeIcuSuccessTest,
+       InitializeIcuDataValidPathSucceeds) {
+  std::string icu_data_file_absolute_path =
+      GetTestFilePath("icing/icu.dat");
+  IcingSearchEngineOptions icing_options;
+  icing_options.set_base_dir(GetTestBaseDir());
+  icing_options.set_icu_data_file_absolute_path(icu_data_file_absolute_path);
+  IcingSearchEngine icing(icing_options);
+
+  InitializeResultProto initialize_result = icing.Initialize();
+  ASSERT_THAT(initialize_result.status(), ProtoIsOk());
+  ASSERT_THAT(initialize_result.initialize_stats().initialize_icu_data_status(),
+              ProtoIsOk());
+
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  DocumentProto document =
+      CreateMessageDocument("namespace1", "uri1", "foo bar");
+  ASSERT_THAT(icing.Put(document).status(), ProtoIsOk());
+
+  SearchSpecProto search_spec;
+  search_spec.set_term_match_type(TermMatchType::PREFIX);
+  search_spec.set_query("bar");
+
+  ScoringSpecProto scoring_spec;
+  scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::NONE);
+
+  SearchResultProto results = icing.Search(search_spec, scoring_spec,
+                                           ResultSpecProto::default_instance());
+  EXPECT_THAT(results.status(), ProtoIsOk());
+  EXPECT_THAT(results.results(), SizeIs(1));
+  EXPECT_THAT(results.results(0).document(), EqualsProto(document));
+}
+
+}  // namespace
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/icing-search-engine_optimize_test.cc b/icing/icing-search-engine_optimize_test.cc
index f5c1ced..cd36074 100644
--- a/icing/icing-search-engine_optimize_test.cc
+++ b/icing/icing-search-engine_optimize_test.cc
@@ -18,19 +18,21 @@
 #include <limits>
 #include <memory>
 #include <string>
+#include <string_view>
 #include <utility>
 #include <vector>
 
-#include "icing/text_classifier/lib3/utils/base/status.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/absl_ports/str_cat.h"
 #include "icing/document-builder.h"
 #include "icing/file/filesystem.h"
+#include "icing/file/marker-file.h"
 #include "icing/file/mock-filesystem.h"
 #include "icing/icing-search-engine.h"
 #include "icing/jni/jni-cache.h"
 #include "icing/join/join-processor.h"
-#include "icing/portable/endian.h"
+#include "icing/legacy/index/icing-filesystem.h"
 #include "icing/portable/equals-proto.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/debug.pb.h"
@@ -49,13 +51,16 @@
 #include "icing/proto/term.pb.h"
 #include "icing/proto/usage.pb.h"
 #include "icing/query/query-features.h"
+#include "icing/result/result-state-manager.h"
 #include "icing/schema-builder.h"
 #include "icing/store/document-log-creator.h"
 #include "icing/testing/common-matchers.h"
+#include "icing/testing/embedding-test-utils.h"
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/jni-test-helpers.h"
 #include "icing/testing/test-data.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
 
 namespace icing {
@@ -71,6 +76,14 @@ using ::testing::Gt;
 using ::testing::HasSubstr;
 using ::testing::Lt;
 using ::testing::Return;
+using ::testing::SizeIs;
+
+// - Before we only created a marker file for set schema.
+// - Now, we switch to a general marker file for different operations that are
+//   sensitive to power loss or crash.
+// - In order to make the change compatible with old versions for possible
+//   AppSearch mainline rollback, let's keep the old marker file name.
+constexpr std::string_view kGeneralMarkerFilename = "set_schema_marker";
 
 // For mocking purpose, we allow tests to provide a custom Filesystem.
 class TestIcingSearchEngine : public IcingSearchEngine {
@@ -124,8 +137,10 @@ IcingSearchEngineOptions GetDefaultIcingOptions() {
   IcingSearchEngineOptions icing_options;
   icing_options.set_enable_scorable_properties(true);
   icing_options.set_base_dir(GetTestBaseDir());
-  icing_options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(
-      true);
+  icing_options.set_calculate_time_since_last_attempted_optimize(true);
+  icing_options.set_enable_qualified_id_join_index_v3(true);
+  icing_options.set_enable_delete_propagation_from(false);
+  icing_options.set_enable_marker_file_for_optimize(true);
   return icing_options;
 }
 
@@ -154,6 +169,16 @@ std::vector<double> GetScoresFromSearchResults(
   return result_scores;
 }
 
+EmbeddingMatchSnippetProto CreateEmbeddingMatchSnippetProto(
+    double score, int query_index,
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) {
+  EmbeddingMatchSnippetProto match_snippet;
+  match_snippet.set_semantic_score(score);
+  match_snippet.set_embedding_query_vector_index(query_index);
+  match_snippet.set_embedding_query_metric_type(metric_type);
+  return match_snippet;
+}
+
 // TODO(b/272145329): create SearchSpecBuilder, JoinSpecBuilder,
 // SearchResultProtoBuilder and ResultProtoBuilder for unit tests and build all
 // instances by them.
@@ -418,6 +443,336 @@ TEST_F(IcingSearchEngineOptimizeTest, GetOptimizeInfoHasCorrectStats) {
   }
 }
 
+TEST_F(IcingSearchEngineOptimizeTest,
+       TimeSinceLastOptimize_turnOnCalculateTimeSinceLastAttemptedOptimize) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("Message").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("body")
+                  .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                  .SetCardinality(CARDINALITY_REQUIRED)))
+          .Build();
+
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("Message")
+          .AddStringProperty("body", "message body one")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto document2 = DocumentBuilder()
+                                .SetKey("namespace", "uri2")
+                                .SetSchema("Message")
+                                .AddStringProperty("body", "message body two")
+                                .SetCreationTimestampMs(100)
+                                .SetTtlMs(500)
+                                .Build();
+
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
+  {
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(1000);
+
+    // Initialize icing with
+    // calculate_time_since_last_optimize_at_optimize_start disabled
+    icing_options.set_calculate_time_since_last_attempted_optimize(false);
+    TestIcingSearchEngine icing(icing_options, std::make_unique<Filesystem>(),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Just initialized, nothing is optimizable yet.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+
+    // Call some APIs
+    ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Delete("namespace", "uri1").status(), ProtoIsOk());
+    // Add a second document, but it'll be expired since the time (1000) is
+    // greater than the document's creation timestamp (100) + the document's ttl
+    // (500)
+    ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
+
+    optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(2));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+
+    // Optimize
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_result.optimize_stats().time_since_last_optimize_ms(),
+                Eq(0));
+    EXPECT_THAT(optimize_result.optimize_stats()
+                    .time_since_last_successful_optimize_ms(),
+                Eq(0));
+  }
+
+  {
+    // Create a mock filesystem in which DeleteDirectoryRecursively() always
+    // fails. This will fail IcingSearchEngine::OptimizeDocumentStore() and
+    // makes it return ABORTED_ERROR.
+    auto mock_filesystem = std::make_unique<MockFilesystem>();
+    ON_CALL(*mock_filesystem,
+            DeleteDirectoryRecursively(HasSubstr("document_dir_optimize_tmp")))
+        .WillByDefault(Return(false));
+
+    // Recreate with new time and mock filesystem, and with
+    // calculate_time_since_last_optimize_at_optimize_start disabled
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(1500);
+    icing_options.set_calculate_time_since_last_attempted_optimize(false);
+    TestIcingSearchEngine icing(icing_options, std::move(mock_filesystem),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Nothing is optimizable, but time since last optimize should be updated.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(500));
+
+    // Optimize again -- this should fail because of the mock filesystem.
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoStatusIs(StatusProto::ABORTED));
+  }
+
+  {
+    // Create a mock filesystem in which DeleteDirectoryRecursively() always
+    // fails. This will fail IcingSearchEngine::OptimizeDocumentStore() and
+    // makes it return ABORTED_ERROR.
+    auto mock_filesystem = std::make_unique<MockFilesystem>();
+    ON_CALL(*mock_filesystem,
+            DeleteDirectoryRecursively(HasSubstr("document_dir_optimize_tmp")))
+        .WillByDefault(Return(false));
+
+    // Recreate with new time and mock filesystem, and with
+    // calculate_time_since_last_optimize_at_optimize_start enabled
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(2300);
+    icing_options.set_calculate_time_since_last_attempted_optimize(true);
+    TestIcingSearchEngine icing(icing_options, std::move(mock_filesystem),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Nothing is optimizable. Time since last optimize would only capture the
+    // previous successful optimize run.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(1300));
+
+    // Optimize again -- this should fail because of the mock filesystem, but
+    // the time since last optimize should be populated.
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoStatusIs(StatusProto::ABORTED));
+    EXPECT_THAT(optimize_result.optimize_stats().time_since_last_optimize_ms(),
+                Eq(1300));
+    EXPECT_THAT(optimize_result.optimize_stats()
+                    .time_since_last_successful_optimize_ms(),
+                Eq(1300));
+  }
+
+  {
+    // Recreate with new time
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(5000);
+
+    // Initialize icing with
+    // calculate_time_since_last_optimize_at_optimize_start enabled
+    icing_options.set_calculate_time_since_last_attempted_optimize(true);
+    TestIcingSearchEngine icing(icing_options, std::make_unique<Filesystem>(),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Time since last optimize should reflect the previous optimize run even
+    // though it was aborted.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(2700));
+
+    // Optimize
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_result.optimize_stats().time_since_last_optimize_ms(),
+                Eq(2700));
+    EXPECT_THAT(optimize_result.optimize_stats()
+                    .time_since_last_successful_optimize_ms(),
+                Eq(4000));
+  }
+}
+
+TEST_F(IcingSearchEngineOptimizeTest,
+       TimeSinceLastOptimize_turnOffCalculateTimeSinceLastAttemptedOptimize) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("Message").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("body")
+                  .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                  .SetCardinality(CARDINALITY_REQUIRED)))
+          .Build();
+
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("Message")
+          .AddStringProperty("body", "message body one")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto document2 = DocumentBuilder()
+                                .SetKey("namespace", "uri2")
+                                .SetSchema("Message")
+                                .AddStringProperty("body", "message body two")
+                                .SetCreationTimestampMs(100)
+                                .SetTtlMs(500)
+                                .Build();
+
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
+  {
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(1000);
+
+    // Initialize icing with
+    // calculate_time_since_last_optimize_at_optimize_start enabled
+    icing_options.set_calculate_time_since_last_attempted_optimize(true);
+    TestIcingSearchEngine icing(icing_options, std::make_unique<Filesystem>(),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Just initialized, nothing is optimizable yet.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.estimated_optimizable_bytes(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+
+    // Call some APIs
+    ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Delete("namespace", "uri1").status(), ProtoIsOk());
+    // Add a second document, but it'll be expired since the time (1000) is
+    // greater than the document's creation timestamp (100) + the document's ttl
+    // (500)
+    ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
+
+    optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(2));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+
+    // Optimize
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_result.optimize_stats().time_since_last_optimize_ms(),
+                Eq(0));
+    EXPECT_THAT(optimize_result.optimize_stats()
+                    .time_since_last_successful_optimize_ms(),
+                Eq(0));
+  }
+
+  {
+    // Create a mock filesystem in which DeleteDirectoryRecursively() always
+    // fails. This will fail IcingSearchEngine::OptimizeDocumentStore() and
+    // makes it return ABORTED_ERROR.
+    auto mock_filesystem = std::make_unique<MockFilesystem>();
+    ON_CALL(*mock_filesystem,
+            DeleteDirectoryRecursively(HasSubstr("document_dir_optimize_tmp")))
+        .WillByDefault(Return(false));
+
+    // Recreate with new time and mock filesystem, and with
+    // calculate_time_since_last_optimize_at_optimize_start enabled.
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(1500);
+    icing_options.set_calculate_time_since_last_attempted_optimize(true);
+    TestIcingSearchEngine icing(icing_options, std::move(mock_filesystem),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Nothing is optimizable, but time since last optimize should be updated.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(500));
+
+    // Optimize again -- this should fail because of the mock filesystem.
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoStatusIs(StatusProto::ABORTED));
+    EXPECT_THAT(optimize_result.optimize_stats().time_since_last_optimize_ms(),
+                Eq(500));
+    EXPECT_THAT(optimize_result.optimize_stats()
+                    .time_since_last_successful_optimize_ms(),
+                Eq(500));
+  }
+
+  {
+    // Create a mock filesystem in which DeleteDirectoryRecursively() always
+    // fails. This will fail IcingSearchEngine::OptimizeDocumentStore() and
+    // makes it return ABORTED_ERROR.
+    auto mock_filesystem = std::make_unique<MockFilesystem>();
+    ON_CALL(*mock_filesystem,
+            DeleteDirectoryRecursively(HasSubstr("document_dir_optimize_tmp")))
+        .WillByDefault(Return(false));
+
+    // Recreate with new time and mock filesystem, and with
+    // calculate_time_since_last_optimize_at_optimize_start disabled
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(2300);
+    icing_options.set_calculate_time_since_last_attempted_optimize(false);
+    TestIcingSearchEngine icing(icing_options, std::move(mock_filesystem),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Nothing is optimizable. Time since last optimize should be calculated
+    // based on the last successful optimize run.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(1300));
+
+    // Optimize again -- this should fail because of the mock filesystem.
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoStatusIs(StatusProto::ABORTED));
+  }
+
+  {
+    // Recreate with new time
+    auto fake_clock = std::make_unique<FakeClock>();
+    fake_clock->SetSystemTimeMilliseconds(5000);
+
+    // Initialize icing with
+    // calculate_time_since_last_optimize_at_optimize_start disabled
+    icing_options.set_calculate_time_since_last_attempted_optimize(false);
+    TestIcingSearchEngine icing(icing_options, std::make_unique<Filesystem>(),
+                                std::make_unique<IcingFilesystem>(),
+                                std::move(fake_clock), GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Time since last optimize should be calculated based on the previous
+    // successful call.
+    GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(4000));
+
+    // Optimize
+    OptimizeResultProto optimize_result = icing.Optimize();
+    EXPECT_THAT(optimize_result.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_result.optimize_stats().time_since_last_optimize_ms(),
+                Eq(4000));
+  }
+}
+
 TEST_F(IcingSearchEngineOptimizeTest, GetAndPutShouldWorkAfterOptimization) {
   SchemaProto schema =
       SchemaBuilder()
@@ -1605,6 +1960,7 @@ TEST_F(IcingSearchEngineOptimizeTest, OptimizeThresholdTest) {
   expected.set_num_original_namespaces(1);
   expected.set_num_deleted_namespaces(0);
   expected.set_time_since_last_optimize_ms(10000);
+  expected.set_time_since_last_successful_optimize_ms(10000);
   expected.set_index_restoration_mode(OptimizeStatsProto::INDEX_TRANSLATION);
 
   // Run Optimize
@@ -1629,6 +1985,7 @@ TEST_F(IcingSearchEngineOptimizeTest, OptimizeThresholdTest) {
   expected.set_num_original_namespaces(1);
   expected.set_num_deleted_namespaces(1);
   expected.set_time_since_last_optimize_ms(0);
+  expected.set_time_since_last_successful_optimize_ms(0);
   // Should rebuild the index since all documents are removed.
   expected.set_index_restoration_mode(OptimizeStatsProto::FULL_INDEX_REBUILD);
 
@@ -1750,6 +2107,7 @@ TEST_F(IcingSearchEngineOptimizeTest, OptimizeStatsProtoTest) {
   expected.set_num_original_namespaces(1);
   expected.set_num_deleted_namespaces(0);
   expected.set_time_since_last_optimize_ms(10000);
+  expected.set_time_since_last_successful_optimize_ms(10000);
   expected.set_index_restoration_mode(OptimizeStatsProto::FULL_INDEX_REBUILD);
 
   // Run Optimize
@@ -1774,6 +2132,7 @@ TEST_F(IcingSearchEngineOptimizeTest, OptimizeStatsProtoTest) {
   expected.set_num_original_namespaces(1);
   expected.set_num_deleted_namespaces(1);
   expected.set_time_since_last_optimize_ms(0);
+  expected.set_time_since_last_successful_optimize_ms(0);
   expected.set_index_restoration_mode(OptimizeStatsProto::FULL_INDEX_REBUILD);
 
   // Run Optimize
@@ -2128,6 +2487,293 @@ TEST_F(IcingSearchEngineOptimizeTest,
   }
 }
 
+TEST_F(IcingSearchEngineOptimizeTest, OptimizeShouldCreateMarkerFile) {
+  std::string marker_file_path =
+      absl_ports::StrCat(GetTestBaseDir(), "/", kGeneralMarkerFilename);
+
+  // Marker file remains on disk only if any crash or power loss occurs during
+  // Optimize. In order to test the behavior of the marker file creation, we
+  // need to mock the filesystem to intentionally skip the marker file deletion
+  // upon destruction of the marker file object.
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  ON_CALL(*mock_filesystem, DeleteFile(Eq(marker_file_path)))
+      .WillByDefault(Return(true));
+
+  TestIcingSearchEngine icing(GetDefaultIcingOptions(),
+                              std::move(mock_filesystem),
+                              std::make_unique<IcingFilesystem>(),
+                              std::make_unique<FakeClock>(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  // Marker file should not exist before Optimize.
+  ASSERT_FALSE(filesystem()->FileExists(marker_file_path.c_str()));
+  ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+
+  EXPECT_TRUE(filesystem()->FileExists(marker_file_path.c_str()));
+  std::unique_ptr<IcingSearchEngineMarkerProto> marker_proto =
+      MarkerFile::Postmortem(*filesystem(), marker_file_path);
+  EXPECT_THAT(marker_proto->operation_type(),
+              Eq(IcingSearchEngineMarkerProto::OperationType::OPTIMIZE));
+}
+
+TEST_F(IcingSearchEngineOptimizeTest,
+       OptimizeShouldNotCreateMarkerFileWhenFlagDisabled) {
+  std::string marker_file_path =
+      absl_ports::StrCat(GetTestBaseDir(), "/", kGeneralMarkerFilename);
+
+  // Marker file remains on disk only if any crash or power loss occurs during
+  // Optimize. In order to test the behavior of the marker file creation, we
+  // need to mock the filesystem to intentionally skip the marker file deletion
+  // upon destruction of the marker file object.
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  ON_CALL(*mock_filesystem, DeleteFile(Eq(marker_file_path)))
+      .WillByDefault(Return(true));
+
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
+  icing_options.set_enable_marker_file_for_optimize(false);
+  TestIcingSearchEngine icing(icing_options, std::move(mock_filesystem),
+                              std::make_unique<IcingFilesystem>(),
+                              std::make_unique<FakeClock>(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  // Marker file should not exist before Optimize.
+  ASSERT_FALSE(filesystem()->FileExists(marker_file_path.c_str()));
+  ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+
+  // Marker file should not be created during Optimize.
+  EXPECT_FALSE(filesystem()->FileExists(marker_file_path.c_str()));
+}
+
+TEST_F(IcingSearchEngineOptimizeTest,
+       GetEmbeddingMatchInfoShouldWorkAfterDeleteAndOptimization) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("Email")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("body")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding1")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding2")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED)))
+          .Build();
+
+  DocumentProto document0 =
+      DocumentBuilder()
+          .SetKey("icing", "uri1")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(1)
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model_v1", {-0.1, 0.2, -0.3, -0.4, 0.5}))
+          .AddVectorProperty("embedding2",
+                             CreateVector("my_model_v2", {0.6, 0.7, -0.8}))
+          .Build();
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("icing", "uri0")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(1)
+          .AddStringProperty("body", "foo")
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model_v1", {0.1, 0.2, 0.3, 0.4, 0.5}),
+              CreateVector("my_model_v1", {1, 2, 3, 4, 5}),
+              CreateVector("my_model_v1", {0.6, 0.7, 0.8, 0.9, -1}))
+          .AddVectorProperty(
+              "embedding2",
+              CreateVector("my_model_v1", {-0.1, -0.2, -0.3, 0.4, 0.5}),
+              CreateVector("my_model_v2", {0.6, 0.7, 0.8}))
+          .Build();
+
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
+
+  ASSERT_THAT(icing.Put(document0).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+
+  SearchSpecProto search_spec;
+  search_spec.set_term_match_type(TermMatchType::EXACT_ONLY);
+  search_spec.set_embedding_query_metric_type(
+      SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT);
+  search_spec.add_enabled_features(
+      std::string(kListFilterQueryLanguageFeature));
+
+  // Add an embedding query with semantic scores:
+  // - document 0: -0.5 (embedding1[0]), -5 (embedding1[1]), 1 (embedding1[2]),
+  //                0.3 (embedding2[0])
+  // - document 1: -0.9 (embedding1[0])
+  *search_spec.add_embedding_query_vectors() =
+      CreateVector("my_model_v1", {1, -1, -1, 1, -1});
+  // Add an embedding query with semantic scores:
+  // - document 0: -0.5 (embedding2[1])
+  // - document 1: -2.1 (embedding2[0])
+  *search_spec.add_embedding_query_vectors() =
+      CreateVector("my_model_v2", {-1, -1, 1});
+
+  search_spec.set_query(
+      "semanticSearch(getEmbeddingParameter(0)) OR "
+      "semanticSearch(getEmbeddingParameter(1))");
+
+  ScoringSpecProto scoring_spec = GetDefaultScoringSpec();
+  scoring_spec.set_rank_by(
+      ScoringSpecProto::RankingStrategy::ADVANCED_SCORING_EXPRESSION);
+  scoring_spec.set_advanced_scoring_expression(
+      "sum(this.matchedSemanticScores(getEmbeddingParameter(0))) + "
+      "sum(this.matchedSemanticScores(getEmbeddingParameter(1)))");
+
+  ResultSpecProto result_spec = ResultSpecProto::default_instance();
+  result_spec.mutable_snippet_spec()->set_num_to_snippet(3);
+  result_spec.mutable_snippet_spec()->set_num_matches_per_property(5);
+  result_spec.mutable_snippet_spec()->set_get_embedding_match_info(true);
+
+  {
+    // The matched embeddings for each doc are:
+    // - document 0: -0.5 (embedding1[0]), -5 (embedding1[1]), 1
+    // (embedding1[2]),
+    //               0.3 (embedding2[0]), -0.5 (embedding2[1])
+    // - document 1: -0.9 (embedding1), -2.1 (embedding2)
+    // The scoring expression for each doc will be evaluated as:
+    // - document 0: sum({-0.5, -5, 1, 0.3}) + sum({-0.5}) = -0.7
+    // - document 1: sum({-0.9}) + sum({-2.1}) = -3
+    SearchResultProto results =
+        icing.Search(search_spec, scoring_spec, result_spec);
+    EXPECT_THAT(results.status(), ProtoIsOk());
+    EXPECT_THAT(results.results(), SizeIs(2));
+    EXPECT_THAT(results.results(0).document(), EqualsProto(document0));
+    EXPECT_THAT(results.results(0).score(), DoubleNear(-0.9 - 2.1, kEps));
+    EXPECT_THAT(results.results(1).document(), EqualsProto(document1));
+    EXPECT_THAT(results.results(1).score(),
+                DoubleNear(-0.5 - 5 + 1 + 0.3 - 0.5, kEps));
+    // Document 0
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(2));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("embedding1"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.9, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(1).property_name(),
+                Eq("embedding2"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(1).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-2.1, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    // Document 1
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(5));
+    EXPECT_THAT(results.results(1).snippet().entries(0).property_name(),
+                Eq("embedding1[0]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(1).property_name(),
+                Eq("embedding1[1]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(1).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(2).property_name(),
+                Eq("embedding1[2]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(2).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/1, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(3).property_name(),
+                Eq("embedding2[0]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(3).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/0.3, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(4).property_name(),
+                Eq("embedding2[1]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(4).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  }
+
+  {
+    ASSERT_THAT(icing.Delete(document0.namespace_(), document0.uri()).status(),
+                ProtoIsOk());
+    ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+
+    // Verify that the getEmbeddingMatchInfo is still working as expected.
+    // Only document 1 will be returned since document 0 is deleted.
+    SearchResultProto results =
+        icing.Search(search_spec, scoring_spec, result_spec);
+    EXPECT_THAT(results.status(), ProtoIsOk());
+    EXPECT_THAT(results.results(), SizeIs(1));
+    EXPECT_THAT(results.results(0).document(), EqualsProto(document1));
+    EXPECT_THAT(results.results(0).score(),
+                DoubleNear(-0.5 - 5 + 1 + 0.3 - 0.5, kEps));
+    // Document 1
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(5));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("embedding1[0]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(1).property_name(),
+                Eq("embedding1[1]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(1).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(2).property_name(),
+                Eq("embedding1[2]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(2).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/1, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(3).property_name(),
+                Eq("embedding2[0]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(3).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/0.3, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(4).property_name(),
+                Eq("embedding2[1]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(4).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  }
+}
+
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/icing-search-engine_put_test.cc b/icing/icing-search-engine_put_test.cc
index a6cc463..37df1a1 100644
--- a/icing/icing-search-engine_put_test.cc
+++ b/icing/icing-search-engine_put_test.cc
@@ -330,6 +330,25 @@ TEST_F(IcingSearchEnginePutTest, IndexingDocMergeFailureResets) {
   }
 }
 
+TEST_F(IcingSearchEnginePutTest, PutDocumentUriReturnedInResult) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("icing", "fake_type/0")
+                               .SetSchema("Message")
+                               .AddStringProperty("body", "message body")
+                               .Build();
+
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  options.set_index_merge_size(document.ByteSizeLong());
+  IcingSearchEngine icing(options, GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  PutResultProto put_result_proto = icing.Put(document);
+  EXPECT_THAT(put_result_proto.status(), ProtoIsOk());
+  EXPECT_THAT(put_result_proto.uri(), document.uri());
+  EXPECT_FALSE(put_result_proto.was_replacement());
+}
+
 TEST_F(IcingSearchEnginePutTest, PutDocumentReplacementSucceeds) {
   DocumentProto document = DocumentBuilder()
                                .SetKey("icing", "fake_type/0")
diff --git a/icing/icing-search-engine_schema_test.cc b/icing/icing-search-engine_schema_test.cc
index 89f9546..269daaa 100644
--- a/icing/icing-search-engine_schema_test.cc
+++ b/icing/icing-search-engine_schema_test.cc
@@ -16,13 +16,16 @@
 #include <limits>
 #include <memory>
 #include <string>
+#include <string_view>
 #include <utility>
 #include <vector>
 
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/absl_ports/str_cat.h"
 #include "icing/document-builder.h"
 #include "icing/file/filesystem.h"
+#include "icing/file/marker-file.h"
 #include "icing/file/mock-filesystem.h"
 #include "icing/icing-search-engine.h"
 #include "icing/jni/jni-cache.h"
@@ -65,6 +68,13 @@ using ::testing::HasSubstr;
 using ::testing::Not;
 using ::testing::Return;
 
+// - Before we only created a marker file for set schema.
+// - Now, we switch to a general marker file for different operations that are
+//   sensitive to power loss or crash.
+// - In order to make the change compatible with old versions for possible
+//   AppSearch mainline rollback, let's keep the old marker file name.
+constexpr std::string_view kGeneralMarkerFilename = "set_schema_marker";
+
 // For mocking purpose, we allow tests to provide a custom Filesystem.
 class TestIcingSearchEngine : public IcingSearchEngine {
  public:
@@ -120,8 +130,8 @@ IcingSearchEngineOptions GetDefaultIcingOptions() {
   icing_options.set_base_dir(GetTestBaseDir());
   icing_options.set_document_store_namespace_id_fingerprint(true);
   icing_options.set_enable_schema_database(true);
-  icing_options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(
-      true);
+  icing_options.set_enable_qualified_id_join_index_v3(true);
+  icing_options.set_enable_delete_propagation_from(false);
   return icing_options;
 }
 
@@ -159,6 +169,19 @@ ScoringSpecProto GetDefaultScoringSpec() {
   return scoring_spec;
 }
 
+SetSchemaRequestProto CreateSetSchemaRequestProto(
+    SchemaProto schema, std::string database,
+    bool ignore_errors_and_delete_documents) {
+  SetSchemaRequestProto set_schema_request;
+
+  *set_schema_request.mutable_schema() = std::move(schema);
+  set_schema_request.set_database(std::move(database));
+  set_schema_request.set_ignore_errors_and_delete_documents(
+      ignore_errors_and_delete_documents);
+
+  return set_schema_request;
+}
+
 // TODO(b/272145329): create SearchSpecBuilder, JoinSpecBuilder,
 // SearchResultProtoBuilder and ResultProtoBuilder for unit tests and build all
 // instances by them.
@@ -855,7 +878,9 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
                            .SetCardinality(CARDINALITY_REQUIRED))
           .Build();
   SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
-  SetSchemaResultProto set_schema_result = icing.SetSchema(db1_schema);
+  SetSchemaResultProto set_schema_result =
+      icing.SetSchema(CreateSetSchemaRequestProto(
+          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
@@ -918,7 +943,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
                            .SetCardinality(CARDINALITY_REQUIRED))
           .Build();
   SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
-  set_schema_result = icing.SetSchema(db2_schema);
+  set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
+      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
@@ -1006,7 +1032,9 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
                            .SetCardinality(CARDINALITY_REQUIRED))
           .Build();
   SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
-  SetSchemaResultProto set_schema_result = icing.SetSchema(db1_schema);
+  SetSchemaResultProto set_schema_result =
+      icing.SetSchema(CreateSetSchemaRequestProto(
+          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
@@ -1032,7 +1060,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
                            .SetCardinality(CARDINALITY_REQUIRED))
           .Build();
   SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
-  set_schema_result = icing.SetSchema(db2_schema);
+  set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
+      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
@@ -1108,7 +1137,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
           .SetCardinality(CARDINALITY_OPTIONAL)
           .Build());
   db1_schema = SchemaBuilder().AddType(db1_type).Build();
-  set_schema_result = icing.SetSchema(db1_schema);
+  set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
+      db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
@@ -1196,6 +1226,197 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
               EqualsProto(expected_get_schema_result_proto_db2_full));
 }
 
+TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+  // Create and set schema in db1 with 2 properties:
+  // - 'b': string type, indexed.
+  // - 'c': int64 type, indexed.
+  SchemaTypeConfigProto db1_type =
+      SchemaTypeConfigBuilder()
+          .SetType("db1_type")
+          .SetDatabase("db1")
+          .AddProperty(PropertyConfigBuilder()
+                           .SetName("b")
+                           .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
+                           .SetCardinality(CARDINALITY_REQUIRED))
+          .AddProperty(PropertyConfigBuilder()
+                           .SetName("c")
+                           .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
+                           .SetCardinality(CARDINALITY_REQUIRED))
+          .Build();
+  SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
+  SetSchemaResultProto set_schema_result =
+      icing.SetSchema(CreateSetSchemaRequestProto(
+          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/true));
+  // Ignore latency numbers. They're covered elsewhere.
+  set_schema_result.clear_latency_ms();
+  SetSchemaResultProto expected_set_schema_result;
+  expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1_type");
+  EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
+
+  // Add a schema for db2:
+  // - 'b': string type, indexed.
+  // - 'd': int64 type, indexed.
+  SchemaTypeConfigProto db2_type =
+      SchemaTypeConfigBuilder()
+          .SetType("db2_type")
+          .SetDatabase("db2")
+          .AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("b")
+                  .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                  .SetCardinality(CARDINALITY_REQUIRED))
+          .AddProperty(PropertyConfigBuilder()
+                           .SetName("d")
+                           .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
+                           .SetCardinality(CARDINALITY_REQUIRED))
+          .Build();
+  SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
+  set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
+      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/true));
+  // Ignore latency numbers. They're covered elsewhere.
+  set_schema_result.clear_latency_ms();
+  expected_set_schema_result = SetSchemaResultProto();
+  expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.mutable_new_schema_types()->Add("db2_type");
+  EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
+
+  // Add documents
+  DocumentProto db1_document1 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("db1_type")
+          .AddStringProperty("b", "message body")
+          .AddInt64Property("c", 123)
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto db2_document =
+      DocumentBuilder()
+          .SetKey("namespace", "uri2")
+          .SetSchema("db2_type")
+          .AddStringProperty("b", "message body")
+          .AddInt64Property("d", 123)
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  EXPECT_THAT(icing.Put(db1_document1).status(), ProtoIsOk());
+  EXPECT_THAT(icing.Put(db2_document).status(), ProtoIsOk());
+
+  // Verify term search. Should match both docs.
+  SearchSpecProto search_spec1;
+  search_spec1.set_query("b:message");
+  search_spec1.set_term_match_type(TermMatchType::EXACT_ONLY);
+
+  SearchResultProto expected_result_db1doc1;
+  expected_result_db1doc1.mutable_status()->set_code(StatusProto::OK);
+  *expected_result_db1doc1.mutable_results()->Add()->mutable_document() =
+      db1_document1;
+
+  SearchResultProto expected_result_db1doc1_db2;
+  expected_result_db1doc1_db2.mutable_status()->set_code(StatusProto::OK);
+  *expected_result_db1doc1_db2.mutable_results()->Add()->mutable_document() =
+      db2_document;
+  *expected_result_db1doc1_db2.mutable_results()->Add()->mutable_document() =
+      db1_document1;
+
+  SearchResultProto actual_results =
+      icing.Search(search_spec1, GetDefaultScoringSpec(),
+                   ResultSpecProto::default_instance());
+  EXPECT_THAT(actual_results, EqualsSearchResultIgnoreStatsAndScores(
+                                  expected_result_db1doc1_db2));
+
+  // Verify numeric (integer) search. Should only match db1_document1.
+  SearchSpecProto search_spec2;
+  search_spec2.set_query("c == 123");
+  search_spec2.add_enabled_features(std::string(kNumericSearchFeature));
+
+  actual_results = icing.Search(search_spec2, GetDefaultScoringSpec(),
+                                ResultSpecProto::default_instance());
+  EXPECT_THAT(actual_results,
+              EqualsSearchResultIgnoreStatsAndScores(expected_result_db1doc1));
+
+  // Clear db1 by setting an empty schema:
+  // - db1_schema (deleted)
+  // - db2_schema:
+  //   - 'b': string type, indexed.
+  //   - 'd': int64 type, indexed.
+  db1_schema = SchemaProto();
+  set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
+      db1_schema, "db1", /*ignore_errors_and_delete_documents=*/true));
+  // Ignore latency numbers. They're covered elsewhere.
+  set_schema_result.clear_latency_ms();
+  expected_set_schema_result = SetSchemaResultProto();
+  expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.mutable_deleted_schema_types()->Add("db1_type");
+  EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
+
+  // Adding new document fails because db1_type is deleted.
+  DocumentProto db1_document2 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri3")
+          .SetSchema("db1_type")
+          .AddStringProperty("a", "message body")
+          .AddStringProperty("b", "string value")
+          .AddInt64Property("c", 123)
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  EXPECT_THAT(icing.Put(db1_document2).status(),
+              ProtoStatusIs(StatusProto::NOT_FOUND));
+
+  // Check that original db1 docs are deleted, and that db2 docs are still
+  // searchable.
+  // Verify term search. "b:message" only matches db2_document.
+  actual_results = icing.Search(search_spec1, GetDefaultScoringSpec(),
+                                ResultSpecProto::default_instance());
+  SearchResultProto expected_result_db2doc;
+  expected_result_db2doc.mutable_status()->set_code(StatusProto::OK);
+  *expected_result_db2doc.mutable_results()->Add()->mutable_document() =
+      db2_document;
+  EXPECT_THAT(actual_results,
+              EqualsSearchResultIgnoreStatsAndScores(expected_result_db2doc));
+
+  // Verify numeric (integer) search. "c == 123" should not match anything.
+  actual_results = icing.Search(search_spec2, GetDefaultScoringSpec(),
+                                ResultSpecProto::default_instance());
+  SearchResultProto expected_result_empty;
+  expected_result_empty.mutable_status()->set_code(StatusProto::OK);
+  EXPECT_THAT(actual_results,
+              EqualsSearchResultIgnoreStatsAndScores(expected_result_empty));
+
+  // "message" should only match db2_document.
+  SearchSpecProto search_spec3;
+  search_spec3.set_query("message");
+  search_spec3.set_term_match_type(TermMatchType::PREFIX);
+
+  actual_results = icing.Search(search_spec3, GetDefaultScoringSpec(),
+                                ResultSpecProto::default_instance());
+  EXPECT_THAT(actual_results,
+              EqualsSearchResultIgnoreStatsAndScores(expected_result_db2doc));
+
+  // Get full schema
+  GetSchemaResultProto expected_get_schema_result_proto_full;
+  expected_get_schema_result_proto_full.mutable_status()->set_code(
+      StatusProto::OK);
+  *expected_get_schema_result_proto_full.mutable_schema() =
+      SchemaBuilder().AddType(db2_type).Build();
+  EXPECT_THAT(icing.GetSchema(),
+              EqualsProto(expected_get_schema_result_proto_full));
+
+  // Get db1 schema should return NOT_FOUND.
+  EXPECT_THAT(icing.GetSchema("db1").status(),
+              ProtoStatusIs(StatusProto::NOT_FOUND));
+
+  // Get db2 schema
+  GetSchemaResultProto expected_get_schema_result_proto_db2_full;
+  expected_get_schema_result_proto_db2_full.mutable_status()->set_code(
+      StatusProto::OK);
+  *expected_get_schema_result_proto_db2_full.mutable_schema() = db2_schema;
+  EXPECT_THAT(icing.GetSchema("db2"),
+              EqualsProto(expected_get_schema_result_proto_db2_full));
+}
+
 TEST_F(IcingSearchEngineSchemaTest,
        SetSchemaNewIndexedStringPropertyTriggersIndexRestorationAndReturnsOk) {
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
@@ -3315,7 +3536,9 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseOk) {
           .Build();
 
   SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
-  SetSchemaResultProto set_schema_result = icing.SetSchema(db1_schema);
+  SetSchemaResultProto set_schema_result =
+      icing.SetSchema(CreateSetSchemaRequestProto(
+          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
@@ -3340,7 +3563,8 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseOk) {
           .Build();
 
   SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
-  set_schema_result = icing.SetSchema(db2_schema);
+  set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
+      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
@@ -3399,7 +3623,9 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseNotFound) {
                                         .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
-  SetSchemaResultProto set_schema_result = icing.SetSchema(db1_schema);
+  SetSchemaResultProto set_schema_result =
+      icing.SetSchema(CreateSetSchemaRequestProto(
+          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
@@ -3898,6 +4124,34 @@ TEST_F(IcingSearchEngineSchemaTest, UpdatedPropertyDescriptionIsSaved) {
   ASSERT_THAT(get_result.schema(), Not(EqualsProto(old_schema)));
 }
 
+TEST_F(IcingSearchEngineSchemaTest, SetSchemaShouldCreateMarkerFile) {
+  std::string marker_file_path =
+      absl_ports::StrCat(GetTestBaseDir(), "/", kGeneralMarkerFilename);
+
+  // Marker file remains on disk only if any crash or power loss occurs during
+  // SetSchema. In order to test the behavior of the marker file creation, we
+  // need to mock the filesystem to intentionally skip the marker file deletion
+  // upon destruction of the marker file object.
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  ON_CALL(*mock_filesystem, DeleteFile(Eq(marker_file_path)))
+      .WillByDefault(Return(true));
+
+  TestIcingSearchEngine icing(GetDefaultIcingOptions(),
+                              std::move(mock_filesystem),
+                              std::make_unique<IcingFilesystem>(),
+                              std::make_unique<FakeClock>(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  // Marker file should not exist before SetSchema.
+  ASSERT_FALSE(filesystem()->FileExists(marker_file_path.c_str()));
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  EXPECT_TRUE(filesystem()->FileExists(marker_file_path.c_str()));
+  std::unique_ptr<IcingSearchEngineMarkerProto> marker_proto =
+      MarkerFile::Postmortem(*filesystem(), marker_file_path);
+  EXPECT_THAT(marker_proto->operation_type(),
+              Eq(IcingSearchEngineMarkerProto::OperationType::SET_SCHEMA));
+}
+
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/icing-search-engine_search_test.cc b/icing/icing-search-engine_search_test.cc
index 346bb19..46040a4 100644
--- a/icing/icing-search-engine_search_test.cc
+++ b/icing/icing-search-engine_search_test.cc
@@ -77,6 +77,7 @@ using ::testing::IsEmpty;
 using ::testing::Lt;
 using ::testing::Ne;
 using ::testing::SizeIs;
+using ::testing::UnorderedElementsAre;
 
 // For mocking purpose, we allow tests to provide a custom Filesystem.
 class TestIcingSearchEngine : public IcingSearchEngine {
@@ -136,8 +137,8 @@ IcingSearchEngineOptions GetDefaultIcingOptions() {
   icing_options.set_enable_embedding_index(true);
   icing_options.set_enable_scorable_properties(true);
   icing_options.set_enable_embedding_quantization(true);
-  icing_options.set_enable_qualified_id_join_index_v3_and_delete_propagate_from(
-      true);
+  icing_options.set_enable_qualified_id_join_index_v3(true);
+  icing_options.set_enable_delete_propagation_from(false);
   return icing_options;
 }
 
@@ -225,6 +226,16 @@ SchemaProto CreatePersonAndEmailSchema() {
       .Build();
 }
 
+EmbeddingMatchSnippetProto CreateEmbeddingMatchSnippetProto(
+    double score, int query_index,
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) {
+  EmbeddingMatchSnippetProto match_snippet;
+  match_snippet.set_semantic_score(score);
+  match_snippet.set_embedding_query_vector_index(query_index);
+  match_snippet.set_embedding_query_metric_type(metric_type);
+  return match_snippet;
+}
+
 ScoringSpecProto GetDefaultScoringSpec() {
   ScoringSpecProto scoring_spec;
   scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::DOCUMENT_SCORE);
@@ -6401,6 +6412,216 @@ TEST_F(IcingSearchEngineSearchTest, JoinSnippet) {
               ElementsAre("test"));
 }
 
+TEST_F(IcingSearchEngineSearchTest, JoinSnippetWithEmbedding) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("Person")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("firstName")
+                                        .SetDataTypeString(TERM_MATCH_PREFIX,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("lastName")
+                                        .SetDataTypeString(TERM_MATCH_PREFIX,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("emailAddress")
+                                        .SetDataTypeString(TERM_MATCH_PREFIX,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("Email")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("subject")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding1")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding2")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("personQualifiedId")
+                                        .SetDataTypeJoinableString(
+                                            JOINABLE_VALUE_TYPE_QUALIFIED_ID)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
+          .Build();
+
+  DocumentProto person =
+      DocumentBuilder()
+          .SetKey("pkg$db/namespace", "person")
+          .SetSchema("Person")
+          .AddStringProperty("firstName", "first name")
+          .AddStringProperty("lastName", "last")
+          .AddStringProperty("emailAddress", "email@gmail.com")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .SetScore(1)
+          .Build();
+
+  DocumentProto email0 =
+      DocumentBuilder()
+          .SetKey("icing", "uri0")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(1)
+          .AddStringProperty("subject", "test subject")
+          .AddStringProperty("personQualifiedId", "pkg$db/namespace#person")
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model_v1", {0.1, 0.2, 0.3, 0.4, 0.5}),
+              CreateVector("my_model_v1", {1, 2, 3, 4, 5}),
+              CreateVector("my_model_v1", {0.6, 0.7, 0.8, 0.9, -1}))
+          .AddVectorProperty(
+              "embedding2",
+              CreateVector("my_model_v1", {-0.1, -0.2, -0.3, 0.4, 0.5}),
+              CreateVector("my_model_v2", {0.6, 0.7, 0.8}))
+          .Build();
+  DocumentProto email1 =
+      DocumentBuilder()
+          .SetKey("icing", "uri1")
+          .SetSchema("Email")
+          .SetCreationTimestampMs(1)
+          .AddStringProperty("personQualifiedId", "pkg$db/namespace#person")
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model_v1", {-0.1, 0.2, -0.3, -0.4, 0.5}))
+          .AddVectorProperty("embedding2",
+                             CreateVector("my_model_v2", {0.6, 0.7, -0.8}))
+          .Build();
+
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(person).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(email0).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(email1).status(), ProtoIsOk());
+
+  // Parent SearchSpec
+  SearchSpecProto search_spec;
+  search_spec.set_term_match_type(TermMatchType::PREFIX);
+  search_spec.set_query("firstName:first");
+
+  // JoinSpec
+  JoinSpecProto* join_spec = search_spec.mutable_join_spec();
+  join_spec->set_parent_property_expression(
+      std::string(JoinProcessor::kQualifiedIdExpr));
+  join_spec->set_child_property_expression("personQualifiedId");
+  join_spec->set_aggregation_scoring_strategy(
+      JoinSpecProto::AggregationScoringStrategy::MAX);
+  JoinSpecProto::NestedSpecProto* nested_spec =
+      join_spec->mutable_nested_spec();
+
+  // Child SearchSpec
+  SearchSpecProto* nested_search_spec = nested_spec->mutable_search_spec();
+  nested_search_spec->set_term_match_type(TermMatchType::PREFIX);
+  nested_search_spec->set_embedding_query_metric_type(
+      SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT);
+  nested_search_spec->add_enabled_features(
+      std::string(kListFilterQueryLanguageFeature));
+  *nested_search_spec->add_embedding_query_vectors() =
+      CreateVector("my_model_v1", {1, -1, -1, 1, -1});
+  *nested_search_spec->add_embedding_query_vectors() =
+      CreateVector("my_model_v2", {-1, -1, 1});
+  // Create a hybrid query that matches email0 because of term-based search
+  // and email1 because of embedding-based search.
+  //
+  // The matched embeddings for each doc are:
+  // - document 1: -2.1 (embedding2)
+  // The scoring expression for each doc will be evaluated as:
+  // - document 0: sum({}) = 0
+  // - document 1: sum({-2.1}) = -2.1
+  nested_search_spec->set_query(
+      "subject:test OR semanticSearch(getEmbeddingParameter(1), -10, -1)");
+
+  // Child ScoringSpec
+  ScoringSpecProto* nested_scoring_spec = nested_spec->mutable_scoring_spec();
+  nested_scoring_spec->set_rank_by(
+      ScoringSpecProto::RankingStrategy::ADVANCED_SCORING_EXPRESSION);
+  nested_scoring_spec->set_advanced_scoring_expression(
+      "sum(this.matchedSemanticScores(getEmbeddingParameter(1)))");
+
+  // Child ResultSpec (with snippet)
+  ResultSpecProto* nested_result_spec = nested_spec->mutable_result_spec();
+  nested_result_spec->mutable_snippet_spec()->set_max_window_utf32_length(64);
+  nested_result_spec->mutable_snippet_spec()->set_num_matches_per_property(1);
+  nested_result_spec->mutable_snippet_spec()->set_num_to_snippet(2);
+  nested_result_spec->mutable_snippet_spec()->set_get_embedding_match_info(
+      true);
+  *nested_spec->mutable_scoring_spec() = GetDefaultScoringSpec();
+
+  // Parent ScoringSpec
+  ScoringSpecProto scoring_spec = GetDefaultScoringSpec();
+
+  // Parent ResultSpec
+  ResultSpecProto result_spec;
+  result_spec.set_num_per_page(1);
+  result_spec.set_max_joined_children_per_parent_to_return(
+      std::numeric_limits<int32_t>::max());
+  result_spec.mutable_snippet_spec()->set_max_window_utf32_length(64);
+  result_spec.mutable_snippet_spec()->set_num_to_snippet(1);
+  result_spec.mutable_snippet_spec()->set_num_matches_per_property(1);
+
+  SearchResultProto result =
+      icing.Search(search_spec, scoring_spec, result_spec);
+  EXPECT_THAT(result.status(), ProtoIsOk());
+  EXPECT_THAT(result.next_page_token(), Eq(kInvalidNextPageToken));
+
+  ASSERT_THAT(result.results(), SizeIs(1));
+  // Check parent doc (person).
+  const DocumentProto& result_parent_document = result.results(0).document();
+  const SnippetProto& result_parent_snippet = result.results(0).snippet();
+  EXPECT_THAT(result_parent_document, EqualsProto(person));
+  EXPECT_THAT(result_parent_snippet.entries(0).property_name(),
+              Eq("firstName"));
+  std::string_view content =
+      GetString(&result_parent_document,
+                result_parent_snippet.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_parent_snippet.entries(0)),
+              ElementsAre("first name"));
+  EXPECT_THAT(GetMatches(content, result_parent_snippet.entries(0)),
+              ElementsAre("first"));
+
+  // Check child doc
+  ASSERT_THAT(result.results(0).joined_results(), SizeIs(2));
+  // Email1
+  DocumentProto result_child_document =
+      std::move(result.results(0).joined_results(0).document());
+  SnippetProto result_child_snippet =
+      std::move(result.results(0).joined_results(0).snippet());
+  EXPECT_THAT(result_child_document, EqualsProto(email1));
+  EXPECT_THAT(result_child_snippet.entries(0).property_name(),
+              Eq("embedding2"));
+  EXPECT_THAT(
+      result_child_snippet.entries(0).embedding_matches(),
+      ElementsAre(
+          EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-2.1, /*query_index=*/1,
+              SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+
+  // Email0
+  result_child_document =
+      std::move(result.results(0).joined_results(1).document());
+  result_child_snippet =
+      std::move(result.results(0).joined_results(1).snippet());
+  EXPECT_THAT(result_child_document, EqualsProto(email0));
+  ASSERT_THAT(result_child_snippet.entries(), SizeIs(1));
+  EXPECT_THAT(result_child_snippet.entries(0).property_name(), Eq("subject"));
+  content = GetString(&result_child_document,
+                      result_child_snippet.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_child_snippet.entries(0)),
+              ElementsAre("test subject"));
+  EXPECT_THAT(GetMatches(content, result_child_snippet.entries(0)),
+              ElementsAre("test"));
+}
+
 TEST_F(IcingSearchEngineSearchTest, JoinProjection) {
   SchemaProto schema =
       SchemaBuilder()
@@ -7523,7 +7744,36 @@ TEST_F(IcingSearchEngineSearchTest, HasPropertyQueryNestedDocument) {
   EXPECT_THAT(results.results(), IsEmpty());
 }
 
-TEST_F(IcingSearchEngineSearchTest, EmbeddingSearch) {
+class IcingSearchEngineEmbeddingSearchTest
+    : public ::testing::TestWithParam<bool> {
+ protected:
+  void SetUp() override {
+    if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
+      // If we've specified using the reverse-JNI method for segmentation (i.e.
+      // not ICU), then we won't have the ICU data file included to set up.
+      // Technically, we could choose to use reverse-JNI for segmentation AND
+      // include an ICU data file, but that seems unlikely and our current BUILD
+      // setup doesn't do this.
+      // File generated via icu_data_file rule in //icing/BUILD.
+      std::string icu_data_file_path =
+          GetTestFilePath("icing/icu.dat");
+      ICING_ASSERT_OK(
+          icu_data_file_helper::SetUpIcuDataFile(icu_data_file_path));
+    }
+    filesystem_.CreateDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  void TearDown() override {
+    filesystem_.DeleteDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  const Filesystem* filesystem() const { return &filesystem_; }
+
+ private:
+  Filesystem filesystem_;
+};
+
+TEST_P(IcingSearchEngineEmbeddingSearchTest, EmbeddingSearch) {
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
@@ -7552,7 +7802,9 @@ TEST_F(IcingSearchEngineSearchTest, EmbeddingSearch) {
           .AddStringProperty("body", "foo")
           .AddVectorProperty(
               "embedding1",
-              CreateVector("my_model_v1", {0.1, 0.2, 0.3, 0.4, 0.5}))
+              CreateVector("my_model_v1", {0.1, 0.2, 0.3, 0.4, 0.5}),
+              CreateVector("my_model_v1", {1, 2, 3, 4, 5}),
+              CreateVector("my_model_v1", {0.6, 0.7, 0.8, 0.9, -1}))
           .AddVectorProperty(
               "embedding2",
               CreateVector("my_model_v1", {-0.1, -0.2, -0.3, 0.4, 0.5}),
@@ -7584,102 +7836,211 @@ TEST_F(IcingSearchEngineSearchTest, EmbeddingSearch) {
       std::string(kListFilterQueryLanguageFeature));
 
   // Add an embedding query with semantic scores:
-  // - document 0: -0.5 (embedding1), 0.3 (embedding2)
-  // - document 1: -0.9 (embedding1)
+  // - document 0: -0.5 (embedding1[0]), -5 (embedding1[1]), 1 (embedding1[2]),
+  //                0.3 (embedding2[0])
+  // - document 1: -0.9 (embedding1[0])
   *search_spec.add_embedding_query_vectors() =
       CreateVector("my_model_v1", {1, -1, -1, 1, -1});
   // Add an embedding query with semantic scores:
-  // - document 0: -0.5 (embedding2)
-  // - document 1: -2.1 (embedding2)
+  // - document 0: -0.5 (embedding2[1])
+  // - document 1: -2.1 (embedding2[0])
   *search_spec.add_embedding_query_vectors() =
       CreateVector("my_model_v2", {-1, -1, 1});
   ScoringSpecProto scoring_spec = GetDefaultScoringSpec();
   scoring_spec.set_rank_by(
       ScoringSpecProto::RankingStrategy::ADVANCED_SCORING_EXPRESSION);
 
+  bool get_embedding_match_info = GetParam();
+  ResultSpecProto result_spec = ResultSpecProto::default_instance();
+  result_spec.mutable_snippet_spec()->set_num_to_snippet(3);
+  result_spec.mutable_snippet_spec()->set_num_matches_per_property(5);
+  result_spec.mutable_snippet_spec()->set_get_embedding_match_info(
+      get_embedding_match_info);
+
   // Match documents that have embeddings with a similarity closer to 0 that is
   // greater than -1.
   //
   // The matched embeddings for each doc are:
-  // - document 0: -0.5 (embedding1), 0.3 (embedding2)
-  // - document 1: -0.9 (embedding1)
+  // - document 0: -0.5 (embedding1[0]), 1 (embedding1[2]), 0.3 (embedding2[0])
+  // - document 1: -0.9 (embedding1[0])
   // The scoring expression for each doc will be evaluated as:
-  // - document 0: sum({-0.5, 0.3}) + sum({}) = -0.2
+  // - document 0: sum({-0.5, 1, 0.3}) + sum({}) = 0.8
   // - document 1: sum({-0.9}) + sum({}) = -0.9
   search_spec.set_query("semanticSearch(getEmbeddingParameter(0), -1)");
   scoring_spec.set_advanced_scoring_expression(
       "sum(this.matchedSemanticScores(getEmbeddingParameter(0)))");
-  SearchResultProto results = icing.Search(search_spec, scoring_spec,
-                                           ResultSpecProto::default_instance());
+  SearchResultProto results =
+      icing.Search(search_spec, scoring_spec, result_spec);
   EXPECT_THAT(results.status(), ProtoIsOk());
   EXPECT_THAT(results.results(), SizeIs(2));
   EXPECT_THAT(results.results(0).document(), EqualsProto(document0));
-  EXPECT_THAT(results.results(0).score(), DoubleNear(-0.5 + 0.3, kEps));
+  EXPECT_THAT(results.results(0).score(), DoubleNear(-0.5 + 1 + 0.3, kEps));
   EXPECT_THAT(results.results(1).document(), EqualsProto(document1));
   EXPECT_THAT(results.results(1).score(), DoubleNear(-0.9, kEps));
+  if (get_embedding_match_info) {
+    // Document 0
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(3));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("embedding1[0]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(1).property_name(),
+                Eq("embedding1[2]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(1).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/1, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(2).property_name(),
+                Eq("embedding2[0]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(2).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/0.3, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+
+    // Document 1
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(1));
+    EXPECT_THAT(results.results(1).snippet().entries(0).property_name(),
+                Eq("embedding1"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.9, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  } else {
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(0));
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(0));
+  }
 
   // Create a query the same as above but with a section restriction, which
   // still matches document 0 and document 1 but the semantic score 0.3 should
   // be removed from document 0.
   //
   // The matched embeddings for each doc are:
-  // - document 0: -0.5 (embedding1)
+  // - document 0: -0.5 (embedding1[0]), 1 (embedding1[2]),
   // - document 1: -0.9 (embedding1)
   // The scoring expression for each doc will be evaluated as:
-  // - document 0: sum({-0.5}) = -0.5
+  // - document 0: sum({-0.5}, 1) = 0.5
   // - document 1: sum({-0.9}) = -0.9
   search_spec.set_query(
       "embedding1:semanticSearch(getEmbeddingParameter(0), -1)");
   scoring_spec.set_advanced_scoring_expression(
       "sum(this.matchedSemanticScores(getEmbeddingParameter(0)))");
-  results = icing.Search(search_spec, scoring_spec,
-                         ResultSpecProto::default_instance());
+  results = icing.Search(search_spec, scoring_spec, result_spec);
   EXPECT_THAT(results.status(), ProtoIsOk());
   EXPECT_THAT(results.results(), SizeIs(2));
   EXPECT_THAT(results.results(0).document(), EqualsProto(document0));
-  EXPECT_THAT(results.results(0).score(), DoubleNear(-0.5, kEps));
+  EXPECT_THAT(results.results(0).score(), DoubleNear(-0.5 + 1, kEps));
   EXPECT_THAT(results.results(1).document(), EqualsProto(document1));
   EXPECT_THAT(results.results(1).score(), DoubleNear(-0.9, kEps));
+  if (get_embedding_match_info) {
+    // Document 0
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(2));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("embedding1[0]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(1).property_name(),
+                Eq("embedding1[2]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(1).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/1, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    // Document 1
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(1));
+    EXPECT_THAT(results.results(1).snippet().entries(0).property_name(),
+                Eq("embedding1"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.9, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  } else {
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(0));
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(0));
+  }
 
   // Create a query that only matches document 0.
   //
   // The matched embeddings for each doc are:
-  // - document 0: -0.5 (embedding2)
+  // - document 0: -0.5 (embedding2[1])
   // The scoring expression for each doc will be evaluated as:
   // - document 0: sum({-0.5}) = -0.5
   search_spec.set_query("semanticSearch(getEmbeddingParameter(1), -1.5)");
   scoring_spec.set_advanced_scoring_expression(
       "sum(this.matchedSemanticScores(getEmbeddingParameter(1)))");
-  results = icing.Search(search_spec, scoring_spec,
-                         ResultSpecProto::default_instance());
+  results = icing.Search(search_spec, scoring_spec, result_spec);
   EXPECT_THAT(results.status(), ProtoIsOk());
   EXPECT_THAT(results.results(), SizeIs(1));
   EXPECT_THAT(results.results(0).document(), EqualsProto(document0));
   EXPECT_THAT(results.results(0).score(), DoubleNear(-0.5, kEps));
+  if (get_embedding_match_info) {
+    // Document 0
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(1));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("embedding2[1]"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  } else {
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(0));
+  }
 
   // Create a query that only matches document 1.
   //
   // The matched embeddings for each doc are:
-  // - document 1: -2.1 (embedding2)
+  // - document 1: -2.1 (embedding2])
   // The scoring expression for each doc will be evaluated as:
   // - document 1: sum({-2.1}) = -2.1
   search_spec.set_query("semanticSearch(getEmbeddingParameter(1), -10, -1)");
   scoring_spec.set_advanced_scoring_expression(
       "sum(this.matchedSemanticScores(getEmbeddingParameter(1)))");
-  results = icing.Search(search_spec, scoring_spec,
-                         ResultSpecProto::default_instance());
+  results = icing.Search(search_spec, scoring_spec, result_spec);
   EXPECT_THAT(results.status(), ProtoIsOk());
   EXPECT_THAT(results.results(), SizeIs(1));
   EXPECT_THAT(results.results(0).document(), EqualsProto(document1));
   EXPECT_THAT(results.results(0).score(), DoubleNear(-2.1, kEps));
+  if (get_embedding_match_info) {
+    // Document 1
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(1));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("embedding2"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-2.1, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  } else {
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(0));
+  }
 
   // Create a complex query that matches all hits from all documents.
   //
   // The matched embeddings for each doc are:
-  // - document 0: -0.5 (embedding1), 0.3 (embedding2), -0.5 (embedding2)
+  // - document 0: -0.5 (embedding1[0]), -5 (embedding1[1]), 1 (embedding1[2]),
+  //               0.3 (embedding2[0]), -0.5 (embedding2[1])
   // - document 1: -0.9 (embedding1), -2.1 (embedding2)
   // The scoring expression for each doc will be evaluated as:
-  // - document 0: sum({-0.5, 0.3}) + sum({-0.5}) = -0.7
+  // - document 0: sum({-0.5, -5, 1, 0.3}) + sum({-0.5}) = -0.7
   // - document 1: sum({-0.9}) + sum({-2.1}) = -3
   search_spec.set_query(
       "semanticSearch(getEmbeddingParameter(0)) OR "
@@ -7687,14 +8048,79 @@ TEST_F(IcingSearchEngineSearchTest, EmbeddingSearch) {
   scoring_spec.set_advanced_scoring_expression(
       "sum(this.matchedSemanticScores(getEmbeddingParameter(0))) + "
       "sum(this.matchedSemanticScores(getEmbeddingParameter(1)))");
-  results = icing.Search(search_spec, scoring_spec,
-                         ResultSpecProto::default_instance());
+  results = icing.Search(search_spec, scoring_spec, result_spec);
   EXPECT_THAT(results.status(), ProtoIsOk());
   EXPECT_THAT(results.results(), SizeIs(2));
-  EXPECT_THAT(results.results(0).document(), EqualsProto(document0));
-  EXPECT_THAT(results.results(0).score(), DoubleNear(-0.5 + 0.3 - 0.5, kEps));
-  EXPECT_THAT(results.results(1).document(), EqualsProto(document1));
-  EXPECT_THAT(results.results(1).score(), DoubleNear(-0.9 - 2.1, kEps));
+  EXPECT_THAT(results.results(0).document(), EqualsProto(document1));
+  EXPECT_THAT(results.results(0).score(), DoubleNear(-0.9 - 2.1, kEps));
+  EXPECT_THAT(results.results(1).document(), EqualsProto(document0));
+  EXPECT_THAT(results.results(1).score(),
+              DoubleNear(-0.5 - 5 + 1 + 0.3 - 0.5, kEps));
+  if (get_embedding_match_info) {
+    // Document 0
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(5));
+    EXPECT_THAT(results.results(1).snippet().entries(0).property_name(),
+                Eq("embedding1[0]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(1).property_name(),
+                Eq("embedding1[1]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(1).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-5, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(2).property_name(),
+                Eq("embedding1[2]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(2).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/1, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(3).property_name(),
+                Eq("embedding2[0]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(3).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/0.3, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(1).snippet().entries(4).property_name(),
+                Eq("embedding2[1]"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(4).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.5, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    // Document 1
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(2));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("embedding1"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-0.9, /*query_index=*/0,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+    EXPECT_THAT(results.results(0).snippet().entries(1).property_name(),
+                Eq("embedding2"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(1).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-2.1, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  } else {
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(0));
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(0));
+  }
 
   // Create a hybrid query that matches document 0 because of term-based search
   // and document 1 because of embedding-based search.
@@ -7708,8 +8134,7 @@ TEST_F(IcingSearchEngineSearchTest, EmbeddingSearch) {
       "foo OR semanticSearch(getEmbeddingParameter(1), -10, -1)");
   scoring_spec.set_advanced_scoring_expression(
       "sum(this.matchedSemanticScores(getEmbeddingParameter(1)))");
-  results = icing.Search(search_spec, scoring_spec,
-                         ResultSpecProto::default_instance());
+  results = icing.Search(search_spec, scoring_spec, result_spec);
   EXPECT_THAT(results.status(), ProtoIsOk());
   EXPECT_THAT(results.results(), SizeIs(2));
   EXPECT_THAT(results.results(0).document(), EqualsProto(document0));
@@ -7717,8 +8142,37 @@ TEST_F(IcingSearchEngineSearchTest, EmbeddingSearch) {
   EXPECT_THAT(results.results(0).score(), DoubleNear(0, kEps));
   EXPECT_THAT(results.results(1).document(), EqualsProto(document1));
   EXPECT_THAT(results.results(1).score(), DoubleNear(-2.1, kEps));
+  if (get_embedding_match_info) {
+    // Document 0
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(1));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("body"));
+    EXPECT_THAT(
+        results.results(0).snippet().entries(0).embedding_matches_size(),
+        Eq(0));
+    // Document 1
+    EXPECT_THAT(results.results(1).snippet().entries(), SizeIs(1));
+    EXPECT_THAT(results.results(1).snippet().entries(0).property_name(),
+                Eq("embedding2"));
+    EXPECT_THAT(
+        results.results(1).snippet().entries(0).embedding_matches(),
+        ElementsAre(
+            EqualsEmbeddingMatchSnippetProto(CreateEmbeddingMatchSnippetProto(
+                /*score=*/-2.1, /*query_index=*/1,
+                SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT))));
+  } else {
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(1));
+    EXPECT_THAT(results.results(0).snippet().entries(0).property_name(),
+                Eq("body"));
+    EXPECT_THAT(results.results(0).snippet().entries(), SizeIs(1));
+  }
 }
 
+INSTANTIATE_TEST_SUITE_P(IcingSearchEngineEmbeddingSearchTest,
+                         IcingSearchEngineEmbeddingSearchTest,
+                         testing::Values(/*enable_embedding_quantization=*/true,
+                                         false));
+
 TEST_F(IcingSearchEngineSearchTest, CannotScoreUnqueriedEmbedding) {
   SchemaProto schema =
       SchemaBuilder()
@@ -8621,27 +9075,18 @@ TEST_F(IcingSearchEngineSearchTest,
        SearchWithRankingByScorableProperty_WithInvalidPropertyName) {
   SchemaProto schema =
       SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder()
-                  .SetType("Person")
-                  .AddProperty(
-                      PropertyConfigBuilder()
-                          .SetName("name")
-                          .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
-                          .SetCardinality(CARDINALITY_OPTIONAL))
-                  .AddProperty(
-                      PropertyConfigBuilder()
-                          .SetName("income")
-                          .SetDataType(PropertyConfigProto::DataType::DOUBLE)
-                          .SetScorableType(SCORABLE_TYPE_ENABLED)
-                          .SetCardinality(CARDINALITY_REPEATED)))
+          .AddType(SchemaTypeConfigBuilder().SetType("Person").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("income")
+                  .SetDataType(PropertyConfigProto::DataType::DOUBLE)
+                  .SetScorableType(SCORABLE_TYPE_ENABLED)
+                  .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   DocumentProto document0 = DocumentBuilder()
                                 .SetKey("icing", "person0")
                                 .SetSchema("Person")
                                 .SetScore(10)
                                 .SetCreationTimestampMs(1)
-                                .AddStringProperty("name", "John")
                                 .AddDoubleProperty("income", 10000, 20000)
                                 .Build();
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
@@ -8659,17 +9104,17 @@ TEST_F(IcingSearchEngineSearchTest,
   AddSchemaTypeAliasMap(&scoring_spec, "Person", {"Person"});
   scoring_spec.add_scoring_feature_types_enabled(
       ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
-  SearchResultProto expected_search_result_proto;
-  expected_search_result_proto.mutable_status()->set_code(
-      StatusProto::INVALID_ARGUMENT);
-  expected_search_result_proto.mutable_status()->set_message(
-      "'not_exist' is not defined as a scorable property under schema type 0");
+  int expected_score = /*documentScore=*/10 + /*getScorableProperty=*/0;
 
-  SearchResultProto actual_search_result_proto = icing.Search(
+  SearchResultProto search_result_proto = icing.Search(
       search_spec, scoring_spec, ResultSpecProto::default_instance());
-  EXPECT_THAT(
-      actual_search_result_proto,
-      EqualsSearchResultIgnoreStatsAndScores(expected_search_result_proto));
+  EXPECT_THAT(search_result_proto.status(), ProtoIsOk());
+
+  // Verify that the search results are ranked as expected.
+  EXPECT_THAT(GetUrisFromSearchResults(search_result_proto),
+              ElementsAre("person0"));
+  EXPECT_THAT(GetScoresFromSearchResults(search_result_proto),
+              ElementsAre(expected_score));
 }
 
 TEST_F(IcingSearchEngineSearchTest,
@@ -9220,17 +9665,14 @@ TEST_F(IcingSearchEngineSearchTest,
   scoring_spec.set_advanced_scoring_expression(
       "sum(getScorableProperty(\"Person\", \"income\"))");
 
-  SearchResultProto expected_search_result_proto;
-  expected_search_result_proto.mutable_status()->set_code(
-      StatusProto::INVALID_ARGUMENT);
-  expected_search_result_proto.mutable_status()->set_message(
-      "'income' is not defined as a scorable property under schema type 0");
-
   SearchResultProto actual_search_result_proto = icing.Search(
       search_spec, scoring_spec, ResultSpecProto::default_instance());
-  EXPECT_THAT(
-      actual_search_result_proto,
-      EqualsSearchResultIgnoreStatsAndScores(expected_search_result_proto));
+  EXPECT_THAT(actual_search_result_proto.status(), ProtoIsOk());
+
+  EXPECT_THAT(GetUrisFromSearchResults(actual_search_result_proto),
+              UnorderedElementsAre("person0", "person1"));
+  EXPECT_THAT(GetScoresFromSearchResults(actual_search_result_proto),
+              ElementsAre(0, 0));
 
   // Update the schema to set Person.income as a scorable property.
   SchemaProto new_schema =
@@ -9326,16 +9768,15 @@ TEST_F(IcingSearchEngineSearchTest,
                           .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   EXPECT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
-  SearchResultProto expected_search_result_proto;
-  expected_search_result_proto.mutable_status()->set_code(
-      StatusProto::INVALID_ARGUMENT);
-  expected_search_result_proto.mutable_status()->set_message(
-      "'income' is not defined as a scorable property under schema type 0");
-  SearchResultProto actual_search_result_proto = icing.Search(
+
+  SearchResultProto search_result_proto = icing.Search(
       search_spec, scoring_spec, ResultSpecProto::default_instance());
-  EXPECT_THAT(
-      actual_search_result_proto,
-      EqualsSearchResultIgnoreStatsAndScores(expected_search_result_proto));
+  EXPECT_THAT(search_result_proto.status(), ProtoIsOk());
+
+  // Check the search results.
+  EXPECT_THAT(GetUrisFromSearchResults(search_result_proto),
+              ElementsAre("person0"));
+  EXPECT_THAT(GetScoresFromSearchResults(search_result_proto), ElementsAre(0));
 
   // Update the schema to set Person.income as scorable again. It would
   // re-populate the scorable property cache.
@@ -9358,8 +9799,8 @@ TEST_F(IcingSearchEngineSearchTest,
           .Build();
   EXPECT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
 
-  SearchResultProto search_result_proto = icing.Search(
-      search_spec, scoring_spec, ResultSpecProto::default_instance());
+  search_result_proto = icing.Search(search_spec, scoring_spec,
+                                     ResultSpecProto::default_instance());
   EXPECT_THAT(search_result_proto.status(), ProtoIsOk());
 
   // Check the search results.
diff --git a/icing/icing-search-engine_test.cc b/icing/icing-search-engine_test.cc
index 14b9b7d..cb17905 100644
--- a/icing/icing-search-engine_test.cc
+++ b/icing/icing-search-engine_test.cc
@@ -14,20 +14,18 @@
 
 #include "icing/icing-search-engine.h"
 
+#include <cstddef>
 #include <cstdint>
-#include <limits>
 #include <memory>
 #include <string>
 #include <utility>
 
-#include "icing/text_classifier/lib3/utils/base/status.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/document-builder.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/mock-filesystem.h"
 #include "icing/jni/jni-cache.h"
-#include "icing/portable/endian.h"
 #include "icing/portable/equals-proto.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/debug.pb.h"
@@ -132,6 +130,16 @@ DocumentProto CreateMessageDocument(std::string name_space, std::string uri) {
       .Build();
 }
 
+DocumentProto CreateMessageDocument(std::string name_space, std::string uri,
+                                    std::string document_string) {
+  return DocumentBuilder()
+      .SetKey(std::move(name_space), std::move(uri))
+      .SetSchema("Message")
+      .AddStringProperty("body", document_string)
+      .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+      .Build();
+}
+
 SchemaProto CreateMessageSchema() {
   return SchemaBuilder()
       .AddType(SchemaTypeConfigBuilder().SetType("Message").AddProperty(
@@ -227,6 +235,337 @@ TEST_F(IcingSearchEngineTest, GetDocument) {
               EqualsProto(expected_get_result_proto));
 }
 
+TEST_F(IcingSearchEngineTest, BatchGetDocumentResultSizeLimitOver1) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  DocumentProto document1 = CreateMessageDocument("namespace", "uri1");
+  DocumentProto biggerDocument2 =
+      CreateMessageDocument("namespace", "uri2ForBiggerDocument");
+  DocumentProto document3 = CreateMessageDocument("namespace", "uri3");
+  size_t doc1_size = document1.ByteSizeLong();
+  size_t doc3_size = document3.ByteSizeLong();
+
+  //
+  // Expected result
+  //
+  BatchGetResultProto expected_batch_get_result_proto;
+  expected_batch_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+
+  // doc1 should be OK
+  GetResultProto expected_get_result_proto1;
+  expected_get_result_proto1.mutable_status()->set_code(StatusProto::OK);
+  expected_get_result_proto1.set_uri("uri1");
+  *expected_get_result_proto1.mutable_document() = document1;
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto1));
+
+  // result for doc2 should be ABORTED
+  GetResultProto expected_get_result_google::protobuf;
+  expected_get_result_google::protobuf.mutable_status()->set_code(
+      StatusProto::ABORTED);
+  expected_get_result_google::protobuf.set_uri("uri2ForBiggerDocument");
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_google::protobuf));
+
+  // doc3 should be ABORTED
+  GetResultProto expected_get_result_proto3;
+  expected_get_result_proto3.set_uri("uri3");
+  expected_get_result_proto3.mutable_status()->set_code(
+      StatusProto::ABORTED);
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto3));
+
+  PutDocumentRequest put_document_request;
+  put_document_request.mutable_documents()->Add(std::move(document1));
+  put_document_request.mutable_documents()->Add(std::move(biggerDocument2));
+  put_document_request.mutable_documents()->Add(std::move(document3));
+
+  ASSERT_THAT(icing.BatchPut(std::move(put_document_request)).status(),
+              ProtoIsOk());
+
+  GetResultSpecProto get_result_spec;
+  get_result_spec.set_namespace_requested("namespace");
+  get_result_spec.add_ids("uri1");
+  get_result_spec.add_ids("uri2ForBiggerDocument");
+  get_result_spec.add_ids("uri3");
+  get_result_spec.set_num_total_document_bytes_to_return(doc1_size + doc3_size);
+  ASSERT_THAT(icing.BatchGet(std::move(get_result_spec)),
+              EqualsProto(expected_batch_get_result_proto));
+}
+
+TEST_F(IcingSearchEngineTest, BatchGetDocumentResultSizeLimitOver2) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  DocumentProto document1 = CreateMessageDocument("namespace", "uri1");
+  DocumentProto biggerDocument2 =
+      CreateMessageDocument("namespace", "uri2ForBiggerDocument");
+  DocumentProto document3 = CreateMessageDocument("namespace", "uri3");
+  size_t doc1_size = document1.ByteSizeLong();
+  size_t doc2_size = biggerDocument2.ByteSizeLong();
+  size_t doc3_size = document3.ByteSizeLong();
+
+  //
+  // Expected result
+  //
+  BatchGetResultProto expected_batch_get_result_proto;
+  expected_batch_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+
+  // doc1 should be OK
+  GetResultProto expected_get_result_proto1;
+  expected_get_result_proto1.mutable_status()->set_code(StatusProto::OK);
+  expected_get_result_proto1.set_uri("uri1");
+  *expected_get_result_proto1.mutable_document() = document1;
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto1));
+
+  // doc2 should be OK.
+  GetResultProto expected_get_result_google::protobuf;
+  expected_get_result_google::protobuf.mutable_status()->set_code(StatusProto::OK);
+  expected_get_result_google::protobuf.set_uri("uri2ForBiggerDocument");
+  *expected_get_result_google::protobuf.mutable_document() = biggerDocument2;
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_google::protobuf));
+
+  // doc3 should be ABORTED
+  GetResultProto expected_get_result_proto3;
+  expected_get_result_proto3.mutable_status()->set_code(
+      StatusProto::ABORTED);
+  expected_get_result_proto3.set_uri("uri3");
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto3));
+
+  PutDocumentRequest put_document_request;
+  put_document_request.mutable_documents()->Add(std::move(document1));
+  put_document_request.mutable_documents()->Add(std::move(biggerDocument2));
+  put_document_request.mutable_documents()->Add(std::move(document3));
+
+  ASSERT_THAT(icing.BatchPut(std::move(put_document_request)).status(),
+              ProtoIsOk());
+
+  GetResultSpecProto get_result_spec;
+  get_result_spec.set_namespace_requested("namespace");
+  get_result_spec.add_ids("uri1");
+  get_result_spec.add_ids("uri2ForBiggerDocument");
+  get_result_spec.add_ids("uri3");
+  get_result_spec.set_num_total_document_bytes_to_return(doc1_size + doc2_size +
+                                                         doc3_size - 1);
+  ASSERT_THAT(icing.BatchGet(std::move(get_result_spec)),
+              EqualsProto(expected_batch_get_result_proto));
+}
+
+TEST_F(IcingSearchEngineTest,
+       BatchGetDocumentResultSizeLimitOriginalErrorKept) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  DocumentProto document1 = CreateMessageDocument("namespace", "uri1");
+  DocumentProto document2 = CreateMessageDocument("namespace", "uri2");
+  DocumentProto biggerDocument3 =
+      CreateMessageDocument("namespace", "uri3ForBiggerDocument");
+  size_t doc1_size = document1.ByteSizeLong();
+
+  //
+  // Expected result
+  //
+  BatchGetResultProto expected_batch_get_result_proto;
+  expected_batch_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+
+  // doc1 should be OK
+  GetResultProto expected_get_result_proto1;
+  expected_get_result_proto1.mutable_status()->set_code(StatusProto::OK);
+  expected_get_result_proto1.set_uri("uri1");
+  *expected_get_result_proto1.mutable_document() = document1;
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto1));
+
+  // uriNotExist should not be found.
+  GetResultProto expected_get_result_google::protobuf;
+  expected_get_result_google::protobuf.set_uri("uriNotExist");
+  expected_get_result_google::protobuf.mutable_status()->set_code(StatusProto::NOT_FOUND);
+  expected_get_result_google::protobuf.mutable_status()->set_message(
+      "Document (namespace, uriNotExist) not found.");
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_google::protobuf));
+
+  // doc3 should be ABORTED
+  GetResultProto expected_get_result_proto3;
+  expected_get_result_proto3.mutable_status()->set_code(
+      StatusProto::ABORTED);
+  expected_get_result_proto3.set_uri("uri3ForBiggerDocument");
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto3));
+
+  // uriNotExist should be ABORTED as we have reached the limit.
+  // Even though the doc doesn't exist.
+  GetResultProto expected_get_result_proto4;
+  expected_get_result_proto4.mutable_status()->set_code(
+      StatusProto::ABORTED);
+  expected_get_result_proto4.set_uri("uriNotExist");
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto4));
+
+  PutDocumentRequest put_document_request;
+  put_document_request.mutable_documents()->Add(std::move(document1));
+  put_document_request.mutable_documents()->Add(std::move(document2));
+  put_document_request.mutable_documents()->Add(std::move(biggerDocument3));
+
+  ASSERT_THAT(icing.BatchPut(std::move(put_document_request)).status(),
+              ProtoIsOk());
+
+  GetResultSpecProto get_result_spec;
+  get_result_spec.set_namespace_requested("namespace");
+  get_result_spec.add_ids("uri1");
+  get_result_spec.add_ids("uriNotExist");
+  get_result_spec.add_ids("uri3ForBiggerDocument");
+  get_result_spec.add_ids("uriNotExist");
+  get_result_spec.set_num_total_document_bytes_to_return(doc1_size);
+  ASSERT_THAT(icing.BatchGet(std::move(get_result_spec)),
+              EqualsProto(expected_batch_get_result_proto));
+}
+
+TEST_F(IcingSearchEngineTest, BatchGetDocumentResultSizeLimitNotOver) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  DocumentProto document1 = CreateMessageDocument("namespace", "uri1");
+  DocumentProto biggerDocument2 =
+      CreateMessageDocument("namespace", "uri2ForBiggerDocument");
+  DocumentProto document3 = CreateMessageDocument("namespace", "uri3");
+  size_t doc1_size = document1.ByteSizeLong();
+  size_t doc2_size = biggerDocument2.ByteSizeLong();
+  size_t doc3_size = document3.ByteSizeLong();
+
+  //
+  // Expected result
+  //
+  BatchGetResultProto expected_batch_get_result_proto;
+  expected_batch_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+
+  // doc1 should be OK
+  GetResultProto expected_get_result_proto1;
+  expected_get_result_proto1.mutable_status()->set_code(StatusProto::OK);
+  expected_get_result_proto1.set_uri("uri1");
+  *expected_get_result_proto1.mutable_document() = document1;
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto1));
+
+  // doc2 should be OK.
+  GetResultProto expected_get_result_google::protobuf;
+  expected_get_result_google::protobuf.mutable_status()->set_code(StatusProto::OK);
+  expected_get_result_google::protobuf.set_uri("uri2ForBiggerDocument");
+  *expected_get_result_google::protobuf.mutable_document() = biggerDocument2;
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_google::protobuf));
+
+  // doc3 should be OK
+  GetResultProto expected_get_result_proto3;
+  expected_get_result_proto3.mutable_status()->set_code(StatusProto::OK);
+  expected_get_result_proto3.set_uri("uri3");
+  *expected_get_result_proto3.mutable_document() = document3;
+  expected_batch_get_result_proto.mutable_get_result_protos()->Add(
+      std::move(expected_get_result_proto3));
+
+  PutDocumentRequest put_document_request;
+  put_document_request.mutable_documents()->Add(std::move(document1));
+  put_document_request.mutable_documents()->Add(std::move(biggerDocument2));
+  put_document_request.mutable_documents()->Add(std::move(document3));
+
+  ASSERT_THAT(icing.BatchPut(std::move(put_document_request)).status(),
+              ProtoIsOk());
+
+  GetResultSpecProto get_result_spec1;
+  get_result_spec1.set_namespace_requested("namespace");
+  get_result_spec1.add_ids("uri1");
+  get_result_spec1.add_ids("uri2ForBiggerDocument");
+  get_result_spec1.add_ids("uri3");
+  get_result_spec1.set_num_total_document_bytes_to_return(
+      doc1_size + doc2_size + doc3_size);
+  ASSERT_THAT(icing.BatchGet(std::move(get_result_spec1)),
+              EqualsProto(expected_batch_get_result_proto));
+
+  // Return bytes limit with default value(INT_MAX).
+  GetResultSpecProto get_result_spec2;
+  get_result_spec2.set_namespace_requested("namespace");
+  get_result_spec2.add_ids("uri1");
+  get_result_spec2.add_ids("uri2ForBiggerDocument");
+  get_result_spec2.add_ids("uri3");
+
+  ASSERT_THAT(icing.BatchGet(std::move(get_result_spec2)),
+              EqualsProto(expected_batch_get_result_proto));
+}
+
+TEST_F(IcingSearchEngineTest, BatchGetDocumentResultSizeLimitInvalidValue) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  GetResultSpecProto get_result_spec;
+  get_result_spec.set_namespace_requested("namespace");
+
+  BatchGetResultProto expected_batch_get_result_proto;
+  expected_batch_get_result_proto.mutable_status()->set_code(
+      StatusProto::INVALID_ARGUMENT);
+  expected_batch_get_result_proto.mutable_status()->set_message(
+      "num_total_document_bytes_to_return must be greater than 0.");
+
+  get_result_spec.set_num_total_document_bytes_to_return(0);
+  ASSERT_THAT(icing.BatchGet(GetResultSpecProto(get_result_spec)),
+              EqualsProto(expected_batch_get_result_proto));
+
+  get_result_spec.set_num_total_document_bytes_to_return(-1);
+  ASSERT_THAT(icing.BatchGet(std::move(get_result_spec)),
+              EqualsProto(expected_batch_get_result_proto));
+}
+
+TEST_F(IcingSearchEngineTest, GetDocumentWithBadString) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  // Put and get for a document with a bad string
+  std::string name_space = "namespace";
+  std::string uri = "uri";
+  // Octal representation of hex: \x34F\x8F\xE2\x80\x8C\xC2\xA0 which is
+  // Unicode for CGJ ZWNJ NBSP
+  std::string bad_string = "\315\217\342\200\214\302\240";
+  DocumentProto document = CreateMessageDocument(name_space, uri, bad_string);
+  ASSERT_THAT(icing.Put(document).status(), ProtoIsOk());
+
+  GetResultProto expected_get_result_proto;
+  expected_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_proto.mutable_document() = document;
+  ASSERT_THAT(
+      icing.Get(name_space, uri, GetResultSpecProto::default_instance()),
+      EqualsProto(expected_get_result_proto));
+}
+
+TEST_F(IcingSearchEngineTest, GetDocumentWithNullTerminator) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  // Put and get for a document with a null terminator in the string.
+  std::string name_space = "namespace";
+  std::string uri = "uri";
+  std::string string_with_null_terminator = std::string("message\0body", 12);
+  DocumentProto document =
+      CreateMessageDocument(name_space, uri, string_with_null_terminator);
+  ASSERT_THAT(icing.Put(document).status(), ProtoIsOk());
+
+  GetResultProto expected_get_result_proto;
+  expected_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_proto.mutable_document() = document;
+  ASSERT_THAT(
+      icing.Get(name_space, uri, GetResultSpecProto::default_instance()),
+      EqualsProto(expected_get_result_proto));
+}
+
 TEST_F(IcingSearchEngineTest, GetDocumentProjectionEmpty) {
   IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
diff --git a/icing/index/embed/doc-hit-info-iterator-embedding.cc b/icing/index/embed/doc-hit-info-iterator-embedding.cc
index 1fa5fac..292fb03 100644
--- a/icing/index/embed/doc-hit-info-iterator-embedding.cc
+++ b/icing/index/embed/doc-hit-info-iterator-embedding.cc
@@ -16,7 +16,6 @@
 
 #include <cstdint>
 #include <memory>
-#include <string_view>
 #include <utility>
 #include <vector>
 
@@ -45,13 +44,13 @@ libtextclassifier3::StatusOr<std::unique_ptr<DocHitInfoIteratorEmbedding>>
 DocHitInfoIteratorEmbedding::Create(
     const PropertyProto::VectorProto* query,
     SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
-    double score_low, double score_high,
-    EmbeddingQueryResults::EmbeddingQueryScoreMap* score_map,
+    double score_low, double score_high, bool get_embedding_match_info,
+    EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map,
     const EmbeddingIndex* embedding_index, const DocumentStore* document_store,
     const SchemaStore* schema_store, int64_t current_time_ms) {
   ICING_RETURN_ERROR_IF_NULL(query);
   ICING_RETURN_ERROR_IF_NULL(embedding_index);
-  ICING_RETURN_ERROR_IF_NULL(score_map);
+  ICING_RETURN_ERROR_IF_NULL(info_map);
   ICING_RETURN_ERROR_IF_NULL(document_store);
   ICING_RETURN_ERROR_IF_NULL(schema_store);
 
@@ -75,8 +74,9 @@ DocHitInfoIteratorEmbedding::Create(
   return std::unique_ptr<DocHitInfoIteratorEmbedding>(
       new DocHitInfoIteratorEmbedding(
           query, metric_type, std::move(embedding_scorer), score_low,
-          score_high, score_map, embedding_index, std::move(pl_accessor),
-          document_store, schema_store, current_time_ms));
+          score_high, get_embedding_match_info, info_map, embedding_index,
+          std::move(pl_accessor), document_store, schema_store,
+          current_time_ms));
 }
 
 libtextclassifier3::StatusOr<const EmbeddingHit*>
@@ -121,8 +121,13 @@ DocHitInfoIteratorEmbedding::AdvanceToNextUnfilteredDocument() {
 
   doc_hit_info_ = DocHitInfo(kInvalidDocumentId, kSectionIdMaskNone);
   schema_type_id_ = kInvalidSchemaTypeId;
-  std::vector<double>* matched_scores = nullptr;
+  EmbeddingMatchInfos* matched_infos = nullptr;
   current_allowed_sections_mask_ = kSectionIdMaskAll;
+  SectionId current_section_id = kInvalidSectionId;
+  EmbeddingIndexingConfig::QuantizationType::Code quantization_type =
+      EmbeddingIndexingConfig::QuantizationType::NONE;
+  int current_section_match_count = 0;
+
   while (true) {
     ICING_ASSIGN_OR_RETURN(const EmbeddingHit* embedding_hit,
                            AdvanceToNextEmbeddingHit());
@@ -137,14 +142,21 @@ DocHitInfoIteratorEmbedding::AdvanceToNextUnfilteredDocument() {
       continue;
     }
 
-    // The schema type id is guaranteed to be valid here. Otherwise,
-    // current_allowed_sections_mask_ should be assigned to kSectionIdMaskNone
-    // by AdvanceToNextEmbeddingHit, and the embedding hit should have been
-    // skipped above.
-    ICING_ASSIGN_OR_RETURN(
-        EmbeddingIndexingConfig::QuantizationType::Code quantization_type,
-        schema_store_.GetQuantizationType(
-            schema_type_id_, embedding_hit->basic_hit().section_id()));
+    // We've reached a new section. Reset the match count and retrieve the
+    // quantization type for the new section.
+    if (current_section_id != embedding_hit->basic_hit().section_id()) {
+      current_section_match_count = 0;
+      current_section_id = embedding_hit->basic_hit().section_id();
+      // The schema type id is guaranteed to be valid here. Otherwise,
+      // current_allowed_sections_mask_ should be assigned to kSectionIdMaskNone
+      // by AdvanceToNextEmbeddingHit, and the embedding hit should have been
+      // skipped above.
+      ICING_ASSIGN_OR_RETURN(
+          quantization_type,
+          schema_store_.GetQuantizationType(
+              schema_type_id_, current_section_id));
+    }
+
     // Calculate the semantic score.
     ICING_ASSIGN_OR_RETURN(
         float semantic_score,
@@ -152,14 +164,20 @@ DocHitInfoIteratorEmbedding::AdvanceToNextUnfilteredDocument() {
                                            *embedding_hit, quantization_type));
 
     // If the semantic score is within the desired score range, update
-    // doc_hit_info_ and score_map_.
+    // doc_hit_info_ and info_map_.
     if (score_low_ <= semantic_score && semantic_score <= score_high_) {
       doc_hit_info_.UpdateSection(embedding_hit->basic_hit().section_id());
-      if (matched_scores == nullptr) {
-        matched_scores = &(score_map_[doc_hit_info_.document_id()]);
+      if (matched_infos == nullptr) {
+        matched_infos = &(info_map_[doc_hit_info_.document_id()]);
+      }
+      matched_infos->AppendScore(semantic_score);
+      if (get_embedding_match_info_) {
+        // Add the section info for this embedding match.
+        matched_infos->AppendSectionInfo(current_section_id,
+                                         current_section_match_count);
       }
-      matched_scores->push_back(semantic_score);
     }
+    ++current_section_match_count;
   }
 
   if (doc_hit_info_.document_id() == kInvalidDocumentId) {
diff --git a/icing/index/embed/doc-hit-info-iterator-embedding.h b/icing/index/embed/doc-hit-info-iterator-embedding.h
index 3076cd7..ed2f972 100644
--- a/icing/index/embed/doc-hit-info-iterator-embedding.h
+++ b/icing/index/embed/doc-hit-info-iterator-embedding.h
@@ -48,8 +48,8 @@ class DocHitInfoIteratorEmbedding
   // embedding matched with the provided query with a score in the range of
   // [score_low, score_high], using the provided metric_type.
   //
-  // The iterator will store the matched embedding scores in score_map to
-  // prepare for scoring.
+  // The iterator will store the matched embedding scores in info_map to
+  // prepare for scoring and snippeting.
   //
   // The iterator will handle the section restriction logic internally with the
   // help of DocHitInfoIteratorHandlingSectionRestrict.
@@ -61,8 +61,8 @@ class DocHitInfoIteratorEmbedding
       std::unique_ptr<DocHitInfoIteratorEmbedding>>
   Create(const PropertyProto::VectorProto* query,
          SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
-         double score_low, double score_high,
-         EmbeddingQueryResults::EmbeddingQueryScoreMap* score_map,
+         double score_low, double score_high, bool get_embedding_match_info,
+         EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map,
          const EmbeddingIndex* embedding_index,
          const DocumentStore* document_store, const SchemaStore* schema_store,
          int64_t current_time_ms);
@@ -95,8 +95,8 @@ class DocHitInfoIteratorEmbedding
       const PropertyProto::VectorProto* query,
       SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
       std::unique_ptr<EmbeddingScorer> embedding_scorer, double score_low,
-      double score_high,
-      EmbeddingQueryResults::EmbeddingQueryScoreMap* score_map,
+      double score_high, bool get_embedding_match_info,
+      EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map,
       const EmbeddingIndex* embedding_index,
       std::unique_ptr<PostingListEmbeddingHitAccessor> posting_list_accessor,
       const DocumentStore* document_store, const SchemaStore* schema_store,
@@ -106,7 +106,8 @@ class DocHitInfoIteratorEmbedding
         embedding_scorer_(std::move(embedding_scorer)),
         score_low_(score_low),
         score_high_(score_high),
-        score_map_(*score_map),
+        get_embedding_match_info_(get_embedding_match_info),
+        info_map_(*info_map),
         embedding_index_(*embedding_index),
         posting_list_accessor_(std::move(posting_list_accessor)),
         cached_embedding_hits_idx_(0),
@@ -152,8 +153,11 @@ class DocHitInfoIteratorEmbedding
   double score_low_;
   double score_high_;
 
-  // Score map
-  EmbeddingQueryResults::EmbeddingQueryScoreMap& score_map_;  // Does not own
+  // Snippet arguments
+  bool get_embedding_match_info_;
+
+  // MatchInfo map
+  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap& info_map_;  // Does not own
 
   // Access to embeddings index data
   const EmbeddingIndex& embedding_index_;
diff --git a/icing/index/embed/embedding-index.cc b/icing/index/embed/embedding-index.cc
index 663f53b..028d85a 100644
--- a/icing/index/embed/embedding-index.cc
+++ b/icing/index/embed/embedding-index.cc
@@ -56,8 +56,13 @@ namespace lib {
 
 namespace {
 
-constexpr uint32_t kEmbeddingHitListMapperMaxSize =
-    128 * 1024 * 1024;  // 128 MiB;
+// The maximum size of the embedding hit list mmapper.
+// We use 64MiB for 32-bit platforms and 128MiB for 64-bit platforms.
+#ifdef ICING_ARCH_BIT_64
+  constexpr uint32_t kEmbeddingHitListMapperMaxSize = 128 * 1024 * 1024;
+#else
+  constexpr uint32_t kEmbeddingHitListMapperMaxSize = 64 * 1024 * 1024;
+#endif
 
 // The maximum length returned by encode_util::EncodeIntToCString is 5 for
 // uint32_t.
diff --git a/icing/index/embed/embedding-index_test.cc b/icing/index/embed/embedding-index_test.cc
index ed44120..12ba95e 100644
--- a/icing/index/embed/embedding-index_test.cc
+++ b/icing/index/embed/embedding-index_test.cc
@@ -121,8 +121,7 @@ class EmbeddingIndexTest : public Test {
                                                QUANTIZATION_TYPE_QUANTIZE_8_BIT)
                             .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build(),
-        /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        /*ignore_errors_and_delete_documents=*/false));
     ICING_ASSERT_OK(document_store_->Put(
         DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
     ICING_ASSERT_OK(document_store_->Put(
diff --git a/icing/index/embed/embedding-query-results.h b/icing/index/embed/embedding-query-results.h
index 1679b2a..a90ad10 100644
--- a/icing/index/embed/embedding-query-results.h
+++ b/icing/index/embed/embedding-query-results.h
@@ -15,38 +15,99 @@
 #ifndef ICING_INDEX_EMBED_EMBEDDING_QUERY_RESULTS_H_
 #define ICING_INDEX_EMBED_EMBEDDING_QUERY_RESULTS_H_
 
+#include <memory>
 #include <unordered_map>
 #include <vector>
 
+#include "icing/legacy/core/icing-packed-pod.h"
 #include "icing/proto/search.pb.h"
+#include "icing/schema/section.h"
 #include "icing/store/document-id.h"
 
 namespace icing {
 namespace lib {
 
+struct EmbeddingMatchInfos {
+  // A vector of semantic scores of matched embeddings.
+  std::vector<double> scores;
+
+  struct EmbeddingMatchSectionInfo {
+    // The position of the matched embedding vector in a section relative to
+    // other vectors with the same (dimension, signature) combination. Note that
+    // this is not the universal position of the vector in the section.
+    //
+    // E.g. If a repeated vector property contains the following vectors:
+    // - vector1: [1, 2, 3] (signature = "signature1", dimension = 3)
+    // - vector2: [7, 8, 9] (signature = "signature1", dimension = 3)
+    // - vector3: [4, 5, 6, 8] (signature = "signature2", dimension = 4)
+    // - vector4: [10, 11, 12] (signature = "signature1", dimension = 3)
+    //
+    // Then the position values for each vector would be:
+    // - vector1: 0
+    // - vector2: 1
+    // - vector3: 0
+    // - vector4: 2
+    int position;
+
+    // The section id of an embedding vector.
+    SectionId section_id;
+  } __attribute__((packed));
+  static_assert(sizeof(EmbeddingMatchSectionInfo) == 5, "");
+  static_assert(icing_is_packed_pod<EmbeddingMatchSectionInfo>::value,
+                "go/icing-ubsan");
+
+  // A vector of section infos on the matched embeddings. This will be nullptr
+  // if embedding match info is not enabled for this query.
+  //
+  // When non-null, section_infos must have a 1:1 mapping with the scores
+  // vector.
+  std::unique_ptr<std::vector<EmbeddingMatchSectionInfo>> section_infos;
+
+  EmbeddingMatchInfos() = default;
+
+  EmbeddingMatchInfos(const EmbeddingMatchInfos& other) = delete;
+  EmbeddingMatchInfos& operator=(const EmbeddingMatchInfos& other) = delete;
+
+  // Appends a score to the scores vector.
+  void AppendScore(double score) { scores.push_back(score); }
+
+  // Appends a section info to the section_infos vector, allocating if needed.
+  void AppendSectionInfo(SectionId section_id, int position) {
+    if (!section_infos) {
+      section_infos =
+          std::make_unique<std::vector<EmbeddingMatchSectionInfo>>();
+    }
+    section_infos->push_back({.position = position, .section_id = section_id});
+  }
+};
+
 // A class to store results generated from embedding queries.
 struct EmbeddingQueryResults {
-  // Maps from DocumentId to the list of matched embedding scores for that
-  // document, which will be used in the advanced scoring language to
-  // determine the results for the "this.matchedSemanticScores(...)" function.
-  using EmbeddingQueryScoreMap =
-      std::unordered_map<DocumentId, std::vector<double>>;
+  // Maps from DocumentId to matched embedding infos for that document.
+  // For each document, its embedding match info consists of two vectors:
+  // - The scores vector, which will be used in the advanced scoring language
+  //   to determine the results for the "this.matchedSemanticScores(...)"
+  //   function.
+  // - The section infos vector, which will be used to retrieve snippeting
+  //   MatchInfo for the embedding query.
+  using EmbeddingQueryMatchInfoMap =
+      std::unordered_map<DocumentId, EmbeddingMatchInfos>;
 
-  // Maps from (query_vector_index, metric_type) to EmbeddingQueryScoreMap.
+  // Maps from (query_vector_index, metric_type) to EmbeddingQueryMatchInfoMap.
   std::unordered_map<
       int, std::unordered_map<SearchSpecProto::EmbeddingQueryMetricType::Code,
-                              EmbeddingQueryScoreMap>>
-      result_scores;
+                              EmbeddingQueryMatchInfoMap>>
+      result_infos;
 
-  // Get the score map for the given query_vector_index and metric_type. Returns
-  // nullptr if (query_vector_index, metric_type) does not exist in the
+  // Get the MatchedInfo map for the given query_vector_index and metric_type.
+  // Returns nullptr if (query_vector_index, metric_type) does not exist in the
   // result_scores map.
-  const EmbeddingQueryScoreMap* GetScoreMap(
+  const EmbeddingQueryMatchInfoMap* GetMatchInfoMap(
       int query_vector_index,
       SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) const {
     // Check if a mapping exists for the query_vector_index
-    auto outer_it = result_scores.find(query_vector_index);
-    if (outer_it == result_scores.end()) {
+    auto outer_it = result_infos.find(query_vector_index);
+    if (outer_it == result_infos.end()) {
       return nullptr;
     }
     // Check if a mapping exists for the metric_type
@@ -57,25 +118,40 @@ struct EmbeddingQueryResults {
     return &inner_it->second;
   }
 
-  // Returns the matched scores for the given query_vector_index, metric_type,
+  // Returns the matched infos for the given query_vector_index, metric_type,
   // and doc_id. Returns nullptr if (query_vector_index, metric_type, doc_id)
   // does not exist in the result_scores map.
-  const std::vector<double>* GetMatchedScoresForDocument(
+  const EmbeddingMatchInfos* GetMatchedInfosForDocument(
       int query_vector_index,
       SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
       DocumentId doc_id) const {
-    const EmbeddingQueryScoreMap* score_map =
-        GetScoreMap(query_vector_index, metric_type);
-    if (score_map == nullptr) {
+    const EmbeddingQueryMatchInfoMap* info_map =
+        GetMatchInfoMap(query_vector_index, metric_type);
+    if (info_map == nullptr) {
       return nullptr;
     }
-    // Check if the doc_id exists in the score_map
-    auto scores_it = score_map->find(doc_id);
-    if (scores_it == score_map->end()) {
+    // Check if the doc_id exists in the info_map
+    auto info_it = info_map->find(doc_id);
+    if (info_it == info_map->end()) {
       return nullptr;
     }
-    return &scores_it->second;
+    return &info_it->second;
   }
+
+  // Returns the matched scores for the given query_vector_index, metric_type,
+  // and doc_id. Returns nullptr if (query_vector_index, metric_type, doc_id)
+  // does not exist in the result_scores map.
+  const std::vector<double>* GetMatchedScoresForDocument(
+      int query_vector_index,
+      SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
+      DocumentId doc_id) const {
+    const EmbeddingMatchInfos* match_infos =
+        GetMatchedInfosForDocument(query_vector_index, metric_type, doc_id);
+    if (match_infos == nullptr) {
+      return nullptr;
+    }
+    return &match_infos->scores;
+  };
 };
 
 }  // namespace lib
diff --git a/icing/index/embedding-indexing-handler_test.cc b/icing/index/embedding-indexing-handler_test.cc
index 5cfbc87..f2352a5 100644
--- a/icing/index/embedding-indexing-handler_test.cc
+++ b/icing/index/embedding-indexing-handler_test.cc
@@ -192,8 +192,7 @@ class EmbeddingIndexingHandlerTest : public ::testing::Test {
                                  .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ASSERT_TRUE(
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
diff --git a/icing/index/index-processor_benchmark.cc b/icing/index/index-processor_benchmark.cc
index b849bad..7adaac4 100644
--- a/icing/index/index-processor_benchmark.cc
+++ b/icing/index/index-processor_benchmark.cc
@@ -44,6 +44,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -165,10 +166,9 @@ std::unique_ptr<Index> CreateIndex(const IcingFilesystem& icing_filesystem,
 }
 
 std::unique_ptr<Normalizer> CreateNormalizer() {
-  return normalizer_factory::Create(
-
-             /*max_term_byte_size=*/std::numeric_limits<int>::max())
-      .ValueOrDie();
+  NormalizerOptions normalizer_options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  return normalizer_factory::Create(normalizer_options).ValueOrDie();
 }
 
 std::unique_ptr<SchemaStore> CreateSchemaStore(
@@ -184,8 +184,7 @@ std::unique_ptr<SchemaStore> CreateSchemaStore(
   SchemaProto schema;
   CreateFakeTypeConfig(schema.add_types());
   auto set_schema_status = schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false);
+      schema, /*ignore_errors_and_delete_documents=*/false);
 
   if (!set_schema_status.ok()) {
     ICING_LOG(ERROR) << set_schema_status.status().error_message();
diff --git a/icing/index/index-processor_test.cc b/icing/index/index-processor_test.cc
index 6edcd52..cba75f6 100644
--- a/icing/index/index-processor_test.cc
+++ b/icing/index/index-processor_test.cc
@@ -43,7 +43,7 @@
 #include "icing/index/numeric/numeric-index.h"
 #include "icing/index/term-indexing-handler.h"
 #include "icing/index/term-property-id.h"
-#include "icing/join/qualified-id-join-index-impl-v1.h"
+#include "icing/join/qualified-id-join-index-impl-v3.h"
 #include "icing/join/qualified-id-join-index.h"
 #include "icing/join/qualified-id-join-indexing-handler.h"
 #include "icing/legacy/index/icing-filesystem.h"
@@ -66,6 +66,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/crc32.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -187,21 +188,20 @@ class IndexProcessorTest : public Test {
             IntegerIndex::kDefaultNumDataThresholdForBucketSplit,
             /*pre_mapping_fbv=*/false));
 
-    ICING_ASSERT_OK_AND_ASSIGN(qualified_id_join_index_,
-                               QualifiedIdJoinIndexImplV1::Create(
-                                   filesystem_, qualified_id_join_index_dir_,
-                                   /*pre_mapping_fbv=*/false,
-                                   /*use_persistent_hash_map=*/false));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        qualified_id_join_index_,
+        QualifiedIdJoinIndexImplV3::Create(
+            filesystem_, qualified_id_join_index_dir_, *feature_flags_));
 
     language_segmenter_factory::SegmenterOptions segmenter_options(ULOC_US);
     ICING_ASSERT_OK_AND_ASSIGN(
         lang_segmenter_,
         language_segmenter_factory::Create(std::move(segmenter_options)));
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        normalizer_,
-        normalizer_factory::Create(
-            /*max_term_byte_size=*/std::numeric_limits<int32_t>::max()));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     ASSERT_TRUE(
         filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str()));
@@ -283,8 +283,7 @@ class IndexProcessorTest : public Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ASSERT_TRUE(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()));
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -657,9 +656,9 @@ TEST_F(IndexProcessorTest, LexiconExhaustedTest) {
 TEST_F(IndexProcessorTest, TooLongTokens) {
   // Only allow the tokens of length four, truncating "hello", "world" and
   // "night".
+  NormalizerOptions normalizer_options(/*max_term_byte_size=*/4);
   ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
-                             normalizer_factory::Create(
-                                 /*max_term_byte_size=*/4));
+                             normalizer_factory::Create(normalizer_options));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<TermIndexingHandler> term_indexing_handler,
diff --git a/icing/index/integer-section-indexing-handler_test.cc b/icing/index/integer-section-indexing-handler_test.cc
index 00b435b..0f70387 100644
--- a/icing/index/integer-section-indexing-handler_test.cc
+++ b/icing/index/integer-section-indexing-handler_test.cc
@@ -163,8 +163,7 @@ class IntegerSectionIndexingHandlerTest : public ::testing::Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ASSERT_TRUE(
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
diff --git a/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc b/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc
index a11bf9e..b783c48 100644
--- a/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc
@@ -62,8 +62,7 @@ class DocHitInfoIteratorByUriTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
diff --git a/icing/index/iterator/doc-hit-info-iterator-filter_test.cc b/icing/index/iterator/doc-hit-info-iterator-filter_test.cc
index 38a628c..00cdb71 100644
--- a/icing/index/iterator/doc-hit-info-iterator-filter_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-filter_test.cc
@@ -90,8 +90,7 @@ class DocHitInfoIteratorDeletedFilterTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
@@ -269,8 +268,7 @@ class DocHitInfoIteratorNamespaceFilterTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
@@ -469,8 +467,7 @@ class DocHitInfoIteratorSchemaTypeFilterTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
@@ -754,8 +751,7 @@ class DocHitInfoIteratorExpirationFilterTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
@@ -962,8 +958,7 @@ class DocHitInfoIteratorFilterTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
diff --git a/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc b/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc
index 6fb84ce..3c29c1e 100644
--- a/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc
@@ -96,8 +96,7 @@ class DocHitInfoIteratorPropertyInSchemaTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema_, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema_, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
diff --git a/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc b/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc
index 34e206e..a97f2a8 100644
--- a/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc
@@ -101,8 +101,7 @@ class DocHitInfoIteratorSectionRestrictTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema_, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema_, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
diff --git a/icing/index/lite/doc-hit-info-iterator-term-lite.cc b/icing/index/lite/doc-hit-info-iterator-term-lite.cc
index c356203..c45cb7a 100644
--- a/icing/index/lite/doc-hit-info-iterator-term-lite.cc
+++ b/icing/index/lite/doc-hit-info-iterator-term-lite.cc
@@ -16,10 +16,8 @@
 
 #include <algorithm>
 #include <cstdint>
-#include <cstring>
 #include <numeric>
 #include <string>
-#include <utility>
 #include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
@@ -33,6 +31,7 @@
 #include "icing/index/term-id-codec.h"
 #include "icing/schema/section.h"
 #include "icing/util/logging.h"
+#include "icing/util/math-util.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -153,31 +152,9 @@ void DocHitInfoIteratorTermLitePrefix::SortDocumentIds() {
     // Now indices is a map from sorted index to current index. In other words,
     // the sorted cached_hits_[i] should be the current cached_hits_[indices[i]]
     // for every valid i.
-    std::vector<bool> done(indices.size());
-    // Apply permutation
-    for (int i = 0; i < indices.size(); ++i) {
-      if (done[i]) {
-        continue;
-      }
-      done[i] = true;
-      int curr = i;
-      int next = indices[i];
-      // Since every finite permutation is formed by disjoint cycles, we can
-      // start with the current element, at index i, and swap the element at
-      // this position with whatever element that *should* be here. Then,
-      // continue to swap the original element, at its updated positions, with
-      // the element that should be occupying that position until the original
-      // element has reached *its* correct position. This completes applying the
-      // single cycle in the permutation.
-      while (next != i) {
-        std::swap(cached_hits_[curr], cached_hits_[next]);
-        std::swap(cached_hit_term_frequency_[curr],
-                  cached_hit_term_frequency_[next]);
-        done[next] = true;
-        curr = next;
-        next = indices[next];
-      }
-    }
+
+    math_util::ApplyPermutation(indices, cached_hits_,
+                                cached_hit_term_frequency_);
   }
 }
 
diff --git a/icing/index/lite/lite-index.cc b/icing/index/lite/lite-index.cc
index cd03dd8..3862206 100644
--- a/icing/index/lite/lite-index.cc
+++ b/icing/index/lite/lite-index.cc
@@ -687,10 +687,16 @@ libtextclassifier3::Status LiteIndex::Optimize(
       tvi_to_delete.insert(curr_tvi);
     }
     DocumentId old_document_id = term_id_hit_pair.hit().document_id();
-    DocumentId new_document_id =
-        old_document_id >= 0 && old_document_id < document_id_old_to_new.size()
-            ? document_id_old_to_new[old_document_id]
-            : kInvalidDocumentId;
+    if (old_document_id < 0 ||
+        old_document_id >= document_id_old_to_new.size()) {
+      // If it happens, then the hit buffer is corrupted. Return error and let
+      // the caller rebuild everything.
+      return absl_ports::InternalError(
+          "Lite index hit document id is out of range. The index may have been "
+          "corrupted.");
+    }
+
+    DocumentId new_document_id = document_id_old_to_new[old_document_id];
     if (new_document_id == kInvalidDocumentId) {
       continue;
     }
diff --git a/icing/index/main/main-index-merger.cc b/icing/index/main/main-index-merger.cc
index 8397e2c..0e5016e 100644
--- a/icing/index/main/main-index-merger.cc
+++ b/icing/index/main/main-index-merger.cc
@@ -31,6 +31,7 @@
 #include "icing/index/term-id-codec.h"
 #include "icing/legacy/core/icing-string-util.h"
 #include "icing/util/logging.h"
+#include "icing/util/math-util.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -142,15 +143,37 @@ class HitSelector {
   TermIdHitPair prev_;
 };
 
-class HitComparator {
- public:
-  explicit HitComparator(
-      const TermIdCodec& term_id_codec,
-      const std::unordered_map<uint32_t, int>& main_tvi_to_block_index)
-      : term_id_codec_(&term_id_codec),
-        main_tvi_to_block_index_(&main_tvi_to_block_index) {}
+int GetIndexBlock(
+    uint32_t term_id,
+    const std::unordered_map<uint32_t, int>& main_tvi_to_block_index,
+    const TermIdCodec& term_id_codec) {
+  auto term_info_or = term_id_codec.DecodeTermInfo(term_id);
+  if (!term_info_or.ok()) {
+    ICING_LOG(WARNING)
+        << "Unable to decode term-info during merge. This shouldn't happen.";
+    return kInvalidBlockIndex;
+  }
+  TermIdCodec::DecodedTermInfo term_info = std::move(term_info_or).ValueOrDie();
+  auto itr = main_tvi_to_block_index.find(term_info.tvi);
+  if (itr == main_tvi_to_block_index.end()) {
+    return kInvalidBlockIndex;
+  }
+  return itr->second;
+}
 
-  bool operator()(const TermIdHitPair& lhs, const TermIdHitPair& rhs) const {
+void SortHits(std::vector<TermIdHitPair>& hits,
+              const std::unordered_map<uint32_t, int>& main_tvi_to_block_index,
+              const TermIdCodec& term_id_codec) {
+  std::vector<int> indices;
+  indices.reserve(hits.size());
+  std::vector<int> index_blocks;
+  index_blocks.reserve(hits.size());
+  for (int i = 0; i < hits.size(); ++i) {
+    indices.push_back(i);
+    index_blocks.push_back(GetIndexBlock(
+        hits[i].term_id(), main_tvi_to_block_index, term_id_codec));
+  }
+  std::sort(indices.begin(), indices.end(), [&](int i, int j) {
     // Primary sort by index block. This achieves two things:
     // 1. It reduces the number of flash writes by grouping together new hits
     // for terms whose posting lists might share the same index block.
@@ -158,35 +181,14 @@ class HitComparator {
     // will be populated first (because all newly added terms have an invalid
     // block index of 0) before any new hits are added to the postings lists
     // that they backfill from.
-    int lhs_index_block = GetIndexBlock(lhs.term_id());
-    int rhs_index_block = GetIndexBlock(rhs.term_id());
-    if (lhs_index_block == rhs_index_block) {
-      // Secondary sort by term_id and hit.
-      return lhs.value() < rhs.value();
+    if (index_blocks[i] == index_blocks[j]) {
+      return hits[i].value() < hits[j].value();
     }
-    return lhs_index_block < rhs_index_block;
-  }
+    return index_blocks[i] < index_blocks[j];
+  });
 
- private:
-  int GetIndexBlock(uint32_t term_id) const {
-    auto term_info_or = term_id_codec_->DecodeTermInfo(term_id);
-    if (!term_info_or.ok()) {
-      ICING_LOG(WARNING)
-          << "Unable to decode term-info during merge. This shouldn't happen.";
-      return kInvalidBlockIndex;
-    }
-    TermIdCodec::DecodedTermInfo term_info =
-        std::move(term_info_or).ValueOrDie();
-    auto itr = main_tvi_to_block_index_->find(term_info.tvi);
-    if (itr == main_tvi_to_block_index_->end()) {
-      return kInvalidBlockIndex;
-    }
-    return itr->second;
-  }
-
-  const TermIdCodec* term_id_codec_;
-  const std::unordered_map<uint32_t, int>* main_tvi_to_block_index_;
-};
+  math_util::ApplyPermutation(indices, hits);
+}
 
 // A helper function to dedupe hits stored in hits. Suppose that the lite index
 // contained a single document with two hits in a single prefix section: "foot"
@@ -211,8 +213,7 @@ void DedupeHits(
     const std::unordered_map<uint32_t, int>& main_tvi_to_block_index) {
   // Now all terms are grouped together and all hits for a term are sorted.
   // Merge equivalent hits into one.
-  std::sort(hits->begin(), hits->end(),
-            HitComparator(term_id_codec, main_tvi_to_block_index));
+  SortHits(*hits, main_tvi_to_block_index, term_id_codec);
   size_t current_offset = 0;
   HitSelector hit_selector;
   for (const TermIdHitPair& term_id_hit_pair : *hits) {
diff --git a/icing/index/main/main-index.cc b/icing/index/main/main-index.cc
index 997cf13..12e8ea9 100644
--- a/icing/index/main/main-index.cc
+++ b/icing/index/main/main-index.cc
@@ -771,14 +771,17 @@ libtextclassifier3::StatusOr<DocumentId> MainIndex::TransferAndAddHits(
                          old_pl_accessor.GetNextHitsBatch());
   while (!tmp.empty()) {
     for (const Hit& hit : tmp) {
-      // A safety check to add robustness to the codebase, so to make sure that
-      // we never access invalid memory, in case that hit from the posting list
-      // is corrupted.
-      if (hit.document_id() < 0 ||
-          hit.document_id() >= document_id_old_to_new.size()) {
-        continue;
+      DocumentId old_document_id = hit.document_id();
+      if (old_document_id < 0 ||
+          old_document_id >= document_id_old_to_new.size()) {
+        // If it happens, then the posting list is corrupted. Return error and
+        // let the caller rebuild everything.
+        return absl_ports::InternalError(
+            "Main index hit document id is out of range. The index may have "
+            "been corrupted.");
       }
-      DocumentId new_document_id = document_id_old_to_new[hit.document_id()];
+
+      DocumentId new_document_id = document_id_old_to_new[old_document_id];
       // Transfer the document id of the hit, if the document is not deleted
       // or outdated.
       if (new_document_id != kInvalidDocumentId) {
diff --git a/icing/index/numeric/dummy-numeric-index.h b/icing/index/numeric/dummy-numeric-index.h
index 0afcd42..a887d0a 100644
--- a/icing/index/numeric/dummy-numeric-index.h
+++ b/icing/index/numeric/dummy-numeric-index.h
@@ -332,11 +332,15 @@ libtextclassifier3::Status DummyNumericIndex<T>::Optimize(
     for (const auto& [key, hits] : old_property_map) {
       for (const BasicHit& hit : hits) {
         DocumentId old_doc_id = hit.document_id();
-        if (old_doc_id >= document_id_old_to_new.size() ||
-            document_id_old_to_new[old_doc_id] == kInvalidDocumentId) {
-          continue;
+        if (old_doc_id < 0 || old_doc_id >= document_id_old_to_new.size()) {
+          return absl_ports::InternalError(
+              "Dummy numeric index hit document id is out of range. The index "
+              "may have been corrupted.");
         }
 
+        if (document_id_old_to_new[old_doc_id] == kInvalidDocumentId) {
+          continue;
+        }
         new_property_map[key].push_back(
             BasicHit(hit.section_id(), document_id_old_to_new[old_doc_id]));
       }
diff --git a/icing/index/numeric/integer-index-storage.cc b/icing/index/numeric/integer-index-storage.cc
index 6a00bf1..9566737 100644
--- a/icing/index/numeric/integer-index-storage.cc
+++ b/icing/index/numeric/integer-index-storage.cc
@@ -717,11 +717,16 @@ libtextclassifier3::Status IntegerIndexStorage::TransferIndex(
       while (!batch_old_data.empty()) {
         for (const IntegerIndexData& old_data : batch_old_data) {
           DocumentId old_document_id = old_data.basic_hit().document_id();
-          DocumentId new_document_id =
-              old_document_id >= 0 &&
-                      old_document_id < document_id_old_to_new.size()
-                  ? document_id_old_to_new[old_document_id]
-                  : kInvalidDocumentId;
+          if (old_document_id < 0 ||
+              old_document_id >= document_id_old_to_new.size()) {
+            // If it happens, then the posting list is corrupted. Return error
+            // and let the caller rebuild everything.
+            return absl_ports::InternalError(
+                "Integer index hit document id is out of range. The index may "
+                "have been corrupted.");
+          }
+
+          DocumentId new_document_id = document_id_old_to_new[old_document_id];
           // Transfer the document id of the hit if the document is not deleted
           // or outdated.
           if (new_document_id != kInvalidDocumentId) {
diff --git a/icing/index/numeric/integer-index-storage_test.cc b/icing/index/numeric/integer-index-storage_test.cc
index f50e480..62c8e87 100644
--- a/icing/index/numeric/integer-index-storage_test.cc
+++ b/icing/index/numeric/integer-index-storage_test.cc
@@ -1874,8 +1874,8 @@ TEST_P(IntegerIndexStorageTest, TransferIndexOutOfRangeDocumentId) {
                                    /*new_keys=*/{-2000}));
   ASSERT_THAT(storage->num_data(), Eq(2));
 
-  // Create document_id_old_to_new with size = 2. TransferIndex should handle
-  // out of range DocumentId properly.
+  // Create document_id_old_to_new with size = 2. TransferIndex should return
+  // internal error for out of range document id.
   std::vector<DocumentId> document_id_old_to_new = {kInvalidDocumentId, 0};
 
   // Transfer to new storage.
@@ -1887,17 +1887,9 @@ TEST_P(IntegerIndexStorageTest, TransferIndexOutOfRangeDocumentId) {
                   /*pre_mapping_fbv_in=*/GetParam()),
           serializer_.get()));
   EXPECT_THAT(storage->TransferIndex(document_id_old_to_new, new_storage.get()),
-              IsOk());
-
-  // Verify after transferring.
-  std::vector<SectionId> expected_sections = {kDefaultSectionId};
-  EXPECT_THAT(new_storage->num_data(), Eq(1));
-  EXPECT_THAT(Query(new_storage.get(), /*key_lower=*/120, /*key_upper=*/120),
-              IsOkAndHolds(ElementsAre(
-                  EqualsDocHitInfo(/*document_id=*/0, expected_sections))));
-  EXPECT_THAT(
-      Query(new_storage.get(), /*key_lower=*/-2000, /*key_upper=*/-2000),
-      IsOkAndHolds(IsEmpty()));
+              StatusIs(libtextclassifier3::StatusCode::INTERNAL,
+                       HasSubstr("Integer index hit document id is out of "
+                                 "range. The index may have been corrupted.")));
 }
 
 TEST_P(IntegerIndexStorageTest, TransferEmptyIndex) {
diff --git a/icing/index/numeric/integer-index_test.cc b/icing/index/numeric/integer-index_test.cc
index 7bc684b..619abc4 100644
--- a/icing/index/numeric/integer-index_test.cc
+++ b/icing/index/numeric/integer-index_test.cc
@@ -408,9 +408,7 @@ TYPED_TEST(NumericIndexIntegerTest, WildcardStorageQuery) {
                                         .SetName("desiredProperty")))
           .Build();
   ICING_ASSERT_OK(this->schema_store_->SetSchema(
-      schema,
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Put 11 docs of "TypeA" into the document store.
   DocumentProto doc =
@@ -1035,21 +1033,16 @@ TYPED_TEST(NumericIndexIntegerTest, OptimizeOutOfRangeDocumentId) {
   Index(integer_index.get(), kDefaultTestPropertyPath, /*document_id=*/2,
         kDefaultSectionId, /*keys=*/{3});
 
-  // Create document_id_old_to_new with size = 2. Optimize should handle out of
-  // range DocumentId properly.
+  // Create document_id_old_to_new with size = 2. Optimize should return
+  // internal error for out of range document id.
   std::vector<DocumentId> document_id_old_to_new(2, kInvalidDocumentId);
 
   EXPECT_THAT(integer_index->Optimize(
                   document_id_old_to_new,
                   /*new_last_added_document_id=*/kInvalidDocumentId),
-              IsOk());
-  EXPECT_THAT(integer_index->last_added_document_id(), Eq(kInvalidDocumentId));
-
-  // Verify all data are discarded after Optimize().
-  EXPECT_THAT(this->Query(integer_index.get(), kDefaultTestPropertyPath,
-                          /*key_lower=*/std::numeric_limits<int64_t>::min(),
-                          /*key_upper=*/std::numeric_limits<int64_t>::max()),
-              IsOkAndHolds(IsEmpty()));
+              StatusIs(libtextclassifier3::StatusCode::INTERNAL,
+                       HasSubstr("document id is out of range. The index may "
+                                 "have been corrupted.")));
 }
 
 TYPED_TEST(NumericIndexIntegerTest, OptimizeDeleteAll) {
@@ -1644,9 +1637,7 @@ TEST_P(IntegerIndexTest, WildcardStoragePersistenceQuery) {
                                         .SetName("desiredProperty")))
           .Build();
   ICING_ASSERT_OK(this->schema_store_->SetSchema(
-      schema,
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Ids are assigned alphabetically, so the property ids are:
   // TypeA.desiredProperty = 0
@@ -2026,9 +2017,7 @@ TEST_P(IntegerIndexTest, WildcardStorageWorksAfterOptimize) {
                                         .SetName("desiredProperty")))
           .Build();
   ICING_ASSERT_OK(this->schema_store_->SetSchema(
-      schema,
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Ids are assigned alphabetically, so the property ids are:
   // TypeA.desiredProperty = 0
@@ -2319,9 +2308,7 @@ TEST_P(IntegerIndexTest, WildcardStorageAvailableIndicesAfterOptimize) {
                                         .SetName("undesiredProperty")))
           .Build();
   ICING_ASSERT_OK(this->schema_store_->SetSchema(
-      schema,
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Ids are assigned alphabetically, so the property ids are:
   // TypeA.desiredProperty = 0
diff --git a/icing/index/property-existence-indexing-handler_test.cc b/icing/index/property-existence-indexing-handler_test.cc
index 653bf0c..8905bc5 100644
--- a/icing/index/property-existence-indexing-handler_test.cc
+++ b/icing/index/property-existence-indexing-handler_test.cc
@@ -53,6 +53,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/tokenized-document.h"
@@ -101,10 +102,10 @@ class PropertyExistenceIndexingHandlerTest : public Test {
         lang_segmenter_,
         language_segmenter_factory::Create(std::move(segmenter_options)));
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        normalizer_,
-        normalizer_factory::Create(
-            /*max_term_byte_size=*/std::numeric_limits<int32_t>::max()));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     ASSERT_THAT(
         filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str()),
@@ -153,8 +154,7 @@ class PropertyExistenceIndexingHandlerTest : public Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/true));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ASSERT_TRUE(
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
diff --git a/icing/index/term-indexing-handler_test.cc b/icing/index/term-indexing-handler_test.cc
index a82541f..577e80b 100644
--- a/icing/index/term-indexing-handler_test.cc
+++ b/icing/index/term-indexing-handler_test.cc
@@ -57,6 +57,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/tokenized-document.h"
@@ -122,10 +123,10 @@ class TermIndexingHandlerTest : public Test {
         lang_segmenter_,
         language_segmenter_factory::Create(std::move(segmenter_options)));
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        normalizer_,
-        normalizer_factory::Create(
-            /*max_term_byte_size=*/std::numeric_limits<int32_t>::max()));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     ASSERT_THAT(
         filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str()),
@@ -169,8 +170,7 @@ class TermIndexingHandlerTest : public Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ASSERT_TRUE(
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
diff --git a/icing/jni.lds b/icing/jni.lds
index 64fae36..401682a 100644
--- a/icing/jni.lds
+++ b/icing/jni.lds
@@ -1,6 +1,7 @@
 VERS_1.0 {
   # Export JNI symbols.
   global:
+    Java_*;
     JNI_OnLoad;
 
   # Hide everything else
diff --git a/icing/jni/icing-search-engine-jni.cc b/icing/jni/icing-search-engine-jni.cc
index de431f5..4101b36 100644
--- a/icing/jni/icing-search-engine-jni.cc
+++ b/icing/jni/icing-search-engine-jni.cc
@@ -30,10 +30,10 @@
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/scoring.pb.h"
 #include "icing/proto/search.pb.h"
+#include "icing/proto/status.pb.h"
 #include "icing/proto/storage.pb.h"
 #include "icing/proto/usage.pb.h"
 #include "icing/util/logging.h"
-#include "icing/util/status-macros.h"
 #include <google/protobuf/message_lite.h>
 
 namespace {
@@ -129,6 +129,26 @@ jbyteArray nativeSetSchema(JNIEnv* env, jclass clazz, jobject object,
   return SerializeProtoToJniByteArray(env, set_schema_result_proto);
 }
 
+jbyteArray nativeSetSchemaWithRequestProto(
+    JNIEnv* env, jclass clazz, jobject object,
+    jbyteArray set_schema_request_bytes) {
+  icing::lib::IcingSearchEngine* icing =
+      GetIcingSearchEnginePointer(env, object);
+
+  icing::lib::SetSchemaRequestProto set_schema_request;
+  if (!ParseProtoFromJniByteArray(env, set_schema_request_bytes,
+                                  &set_schema_request)) {
+    ICING_LOG(icing::lib::ERROR)
+        << "Failed to parse SetSchemaRequestProto in nativeSetSchema";
+    return nullptr;
+  }
+
+  icing::lib::SetSchemaResultProto set_schema_result_proto =
+      icing->SetSchema(std::move(set_schema_request));
+
+  return SerializeProtoToJniByteArray(env, set_schema_result_proto);
+}
+
 jbyteArray nativeGetSchema(JNIEnv* env, jclass clazz, jobject object) {
   icing::lib::IcingSearchEngine* icing =
       GetIcingSearchEnginePointer(env, object);
@@ -138,11 +158,8 @@ jbyteArray nativeGetSchema(JNIEnv* env, jclass clazz, jobject object) {
   return SerializeProtoToJniByteArray(env, get_schema_result_proto);
 }
 
-// TODO : b/337913932 - pre-register this API once Jetpack build is dropped back
-// into g3
-JNIEXPORT jbyteArray JNICALL
-Java_com_google_android_icing_IcingSearchEngineImpl_nativeGetSchemaForDatabase(
-    JNIEnv* env, jclass clazz, jobject object, jstring database) {
+jbyteArray nativeGetSchemaForDatabase(JNIEnv* env, jclass clazz, jobject object,
+                                      jstring database) {
   icing::lib::IcingSearchEngine* icing =
       GetIcingSearchEnginePointer(env, object);
 
@@ -185,6 +202,27 @@ jbyteArray nativePut(JNIEnv* env, jclass clazz, jobject object,
   return SerializeProtoToJniByteArray(env, put_result_proto);
 }
 
+jbyteArray nativeBatchPut(JNIEnv* env, jclass clazz, jobject object,
+                          jbyteArray put_document_request_bytes) {
+  icing::lib::IcingSearchEngine* icing =
+      GetIcingSearchEnginePointer(env, object);
+
+  icing::lib::PutDocumentRequest put_document_request;
+  if (!ParseProtoFromJniByteArray(env, put_document_request_bytes,
+                                  &put_document_request)) {
+    ICING_LOG(icing::lib::ERROR)
+        << "Failed to parse DocumentProto in nativePut";
+    return nullptr;
+  }
+
+  icing::lib::BatchPutResultProto batch_put_result_proto =
+      icing->BatchPut(std::move(put_document_request));
+  batch_put_result_proto.mutable_status()->set_code(
+      icing::lib::StatusProto::OK);
+
+  return SerializeProtoToJniByteArray(env, batch_put_result_proto);
+}
+
 jbyteArray nativeGet(JNIEnv* env, jclass clazz, jobject object,
                      jstring name_space, jstring uri,
                      jbyteArray result_spec_bytes) {
@@ -206,6 +244,24 @@ jbyteArray nativeGet(JNIEnv* env, jclass clazz, jobject object,
   return SerializeProtoToJniByteArray(env, get_result_proto);
 }
 
+jbyteArray nativeBatchGet(JNIEnv* env, jclass clazz, jobject object,
+                          jbyteArray result_spec_bytes) {
+  icing::lib::IcingSearchEngine* icing =
+      GetIcingSearchEnginePointer(env, object);
+
+  icing::lib::GetResultSpecProto get_result_spec;
+  if (!ParseProtoFromJniByteArray(env, result_spec_bytes, &get_result_spec)) {
+    ICING_LOG(icing::lib::ERROR)
+        << "Failed to parse GetResultSpecProto in nativeGet";
+    return nullptr;
+  }
+
+  icing::lib::BatchGetResultProto batch_get_result_proto =
+      icing->BatchGet(std::move(get_result_spec));
+
+  return SerializeProtoToJniByteArray(env, batch_get_result_proto);
+}
+
 jbyteArray nativeReportUsage(JNIEnv* env, jclass clazz, jobject object,
                              jbyteArray usage_report_bytes) {
   icing::lib::IcingSearchEngine* icing =
@@ -575,8 +631,6 @@ jint JNI_OnLoad(JavaVM* vm, void* reserved) {
       env->GetFieldID(java_class, "nativePointer", "J");
 
   // Register your class' native methods.
-  // TODO(b/629896095): Add blob methods pre-register here when g3 JNI build
-  // pick up the blob APIs.
   static const JNINativeMethod methods[] = {
       {"nativeCreate", "([B)J", reinterpret_cast<void*>(nativeCreate)},
       {"nativeDestroy", "(Lcom/google/android/icing/IcingSearchEngineImpl;)V",
@@ -587,18 +641,30 @@ jint JNI_OnLoad(JavaVM* vm, void* reserved) {
       {"nativeSetSchema",
        "(Lcom/google/android/icing/IcingSearchEngineImpl;[BZ)[B",
        reinterpret_cast<void*>(nativeSetSchema)},
+      {"nativeSetSchemaWithRequestProto",
+       "(Lcom/google/android/icing/IcingSearchEngineImpl;[B)[B",
+       reinterpret_cast<void*>(nativeSetSchemaWithRequestProto)},
       {"nativeGetSchema",
        "(Lcom/google/android/icing/IcingSearchEngineImpl;)[B",
        reinterpret_cast<void*>(nativeGetSchema)},
+      {"nativeGetSchemaForDatabase",
+       "(Lcom/google/android/icing/IcingSearchEngineImpl;Ljava/lang/String;)[B",
+       reinterpret_cast<void*>(nativeGetSchemaForDatabase)},
       {"nativeGetSchemaType",
        "(Lcom/google/android/icing/IcingSearchEngineImpl;Ljava/lang/String;)[B",
        reinterpret_cast<void*>(nativeGetSchemaType)},
       {"nativePut", "(Lcom/google/android/icing/IcingSearchEngineImpl;[B)[B",
        reinterpret_cast<void*>(nativePut)},
+      {"nativeBatchPut",
+       "(Lcom/google/android/icing/IcingSearchEngineImpl;[B)[B",
+       reinterpret_cast<void*>(nativeBatchPut)},
       {"nativeGet",
        "(Lcom/google/android/icing/IcingSearchEngineImpl;Ljava/lang/"
        "String;Ljava/lang/String;[B)[B",
        reinterpret_cast<void*>(nativeGet)},
+      {"nativeBatchGet",
+       "(Lcom/google/android/icing/IcingSearchEngineImpl;[B)[B",
+       reinterpret_cast<void*>(nativeBatchGet)},
       {"nativeReportUsage",
        "(Lcom/google/android/icing/IcingSearchEngineImpl;[B)[B",
        reinterpret_cast<void*>(nativeReportUsage)},
diff --git a/icing/join/join-children-fetcher-impl-v3_test.cc b/icing/join/join-children-fetcher-impl-v3_test.cc
index e6e3251..9a39157 100644
--- a/icing/join/join-children-fetcher-impl-v3_test.cc
+++ b/icing/join/join-children-fetcher-impl-v3_test.cc
@@ -29,7 +29,6 @@
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/join/document-join-id-pair.h"
 #include "icing/join/join-processor.h"
-#include "icing/join/qualified-id-join-index-impl-v1.h"
 #include "icing/join/qualified-id-join-index-impl-v2.h"
 #include "icing/join/qualified-id-join-index-impl-v3.h"
 #include "icing/join/qualified-id-join-indexing-handler.h"
@@ -125,8 +124,7 @@ class JoinChildrenFetcherImplV3Test : public ::testing::Test {
 
             .Build();
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
 
     ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
@@ -232,14 +230,6 @@ TEST_F(JoinChildrenFetcherImplV3Test,
   join_spec.mutable_nested_spec()->mutable_scoring_spec()->set_order_by(
       ScoringSpecProto::Order::ASC);
 
-  std::string qualified_id_join_index_dir_v1 =
-      qualified_id_join_index_dir_ + "_v1";
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> qualified_id_join_index_v1,
-      QualifiedIdJoinIndexImplV1::Create(
-          filesystem_, std::move(qualified_id_join_index_dir_v1),
-          /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true));
-
   std::string qualified_id_join_index_dir_v2 =
       qualified_id_join_index_dir_ + "_v2";
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -248,13 +238,6 @@ TEST_F(JoinChildrenFetcherImplV3Test,
           filesystem_, std::move(qualified_id_join_index_dir_v2),
           /*pre_mapping_fbv=*/false));
 
-  EXPECT_THAT(JoinChildrenFetcherImplV3::Create(
-                  join_spec, schema_store_.get(), doc_store_.get(),
-                  qualified_id_join_index_v1.get(),
-                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
-                  /*child_scored_document_hits=*/{}),
-              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-
   EXPECT_THAT(JoinChildrenFetcherImplV3::Create(
                   join_spec, schema_store_.get(), doc_store_.get(),
                   qualified_id_join_index_v2.get(),
diff --git a/icing/join/join-processor.cc b/icing/join/join-processor.cc
index 38846a4..9b6aa2a 100644
--- a/icing/join/join-processor.cc
+++ b/icing/join/join-processor.cc
@@ -63,9 +63,6 @@ JoinProcessor::GetChildrenFetcher(
   }
 
   switch (qualified_id_join_index_->version()) {
-    case QualifiedIdJoinIndex::Version::kV1:
-      return GetChildrenFetcherV1(join_spec,
-                                  std::move(child_scored_document_hits));
     case QualifiedIdJoinIndex::Version::kV2:
       return GetChildrenFetcherV2(join_spec,
                                   std::move(child_scored_document_hits));
@@ -76,40 +73,6 @@ JoinProcessor::GetChildrenFetcher(
   }
 }
 
-libtextclassifier3::StatusOr<std::unique_ptr<JoinChildrenFetcher>>
-JoinProcessor::GetChildrenFetcherV1(
-    const JoinSpecProto& join_spec,
-    std::vector<ScoredDocumentHit>&& child_scored_document_hits) {
-  ScoredDocumentHitComparator score_comparator(
-      /*is_descending=*/join_spec.nested_spec().scoring_spec().order_by() ==
-      ScoringSpecProto::Order::DESC);
-  std::sort(child_scored_document_hits.begin(),
-            child_scored_document_hits.end(), score_comparator);
-
-  // Step 1: group child documents by parent documentId. Currently we only
-  //         support QualifiedId joining, so fetch the qualified id content of
-  //         child_property_expression, break it down into namespace + uri, and
-  //         lookup the DocumentId.
-  // The keys of this map are the DocumentIds of the parent docs the child
-  // ScoredDocumentHits refer to. The values in this map are vectors of child
-  // ScoredDocumentHits that refer to a parent DocumentId.
-  std::unordered_map<DocumentId, std::vector<ScoredDocumentHit>>
-      map_joinable_qualified_id;
-  for (const ScoredDocumentHit& child : child_scored_document_hits) {
-    ICING_ASSIGN_OR_RETURN(
-        DocumentId ref_doc_id,
-        FetchReferencedQualifiedId(child.document_id(),
-                                   join_spec.child_property_expression()));
-    if (ref_doc_id == kInvalidDocumentId) {
-      continue;
-    }
-
-    map_joinable_qualified_id[ref_doc_id].push_back(child);
-  }
-  return JoinChildrenFetcherImplDeprecated::Create(
-      join_spec, std::move(map_joinable_qualified_id));
-}
-
 libtextclassifier3::StatusOr<std::unique_ptr<JoinChildrenFetcher>>
 JoinProcessor::GetChildrenFetcherV2(
     const JoinSpecProto& join_spec,
@@ -321,53 +284,5 @@ JoinProcessor::GetPropagatedChildDocumentsToDelete(
   return child_documents_to_delete;
 }
 
-libtextclassifier3::StatusOr<DocumentId>
-JoinProcessor::FetchReferencedQualifiedId(
-    const DocumentId& child_document_id,
-    const std::string& property_path) const {
-  std::optional<DocumentFilterData> child_filter_data =
-      doc_store_->GetAliveDocumentFilterData(child_document_id,
-                                             current_time_ms_);
-  if (!child_filter_data) {
-    return kInvalidDocumentId;
-  }
-
-  ICING_ASSIGN_OR_RETURN(
-      const JoinablePropertyMetadata* metadata,
-      schema_store_->GetJoinablePropertyMetadata(
-          child_filter_data->schema_type_id(), property_path));
-  if (metadata == nullptr ||
-      metadata->value_type != JoinableConfig::ValueType::QUALIFIED_ID) {
-    // Currently we only support qualified id.
-    return kInvalidDocumentId;
-  }
-
-  DocumentJoinIdPair info(child_document_id, metadata->id);
-  libtextclassifier3::StatusOr<std::string_view> ref_qualified_id_str_or =
-      qualified_id_join_index_->Get(info);
-  if (!ref_qualified_id_str_or.ok()) {
-    if (absl_ports::IsNotFound(ref_qualified_id_str_or.status())) {
-      return kInvalidDocumentId;
-    }
-    return std::move(ref_qualified_id_str_or).status();
-  }
-
-  libtextclassifier3::StatusOr<QualifiedId> ref_qualified_id_or =
-      QualifiedId::Parse(std::move(ref_qualified_id_str_or).ValueOrDie());
-  if (!ref_qualified_id_or.ok()) {
-    // This shouldn't happen because we've validated it during indexing and only
-    // put valid qualified id strings into qualified id join index.
-    return kInvalidDocumentId;
-  }
-  QualifiedId qualified_id = std::move(ref_qualified_id_or).ValueOrDie();
-
-  libtextclassifier3::StatusOr<DocumentId> ref_document_id_or =
-      doc_store_->GetDocumentId(qualified_id.name_space(), qualified_id.uri());
-  if (!ref_document_id_or.ok()) {
-    return kInvalidDocumentId;
-  }
-  return std::move(ref_document_id_or).ValueOrDie();
-}
-
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/join/join-processor.h b/icing/join/join-processor.h
index 8174693..aa74395 100644
--- a/icing/join/join-processor.h
+++ b/icing/join/join-processor.h
@@ -76,16 +76,7 @@ class JoinProcessor {
       const std::unordered_set<DocumentId>& deleted_document_ids);
 
  private:
-  // TODO(b/275121148): deprecate v1, v2 after rollout v3.
-
-  // Helper function to construct JoinChildrenFetcher for
-  // QualfiedIdJoinIndexImplV1.
-  //
-  // Note: JoinChildrenFetcherImplDeprecated will be returned.
-  libtextclassifier3::StatusOr<std::unique_ptr<JoinChildrenFetcher>>
-  GetChildrenFetcherV1(
-      const JoinSpecProto& join_spec,
-      std::vector<ScoredDocumentHit>&& child_scored_document_hits);
+  // TODO(b/275121148): deprecate v2 after rollout v3.
 
   // Helper function to construct JoinChildrenFetcher for
   // QualfiedIdJoinIndexImplV2.
@@ -96,21 +87,6 @@ class JoinProcessor {
       const JoinSpecProto& join_spec,
       std::vector<ScoredDocumentHit>&& child_scored_document_hits);
 
-  // Fetches referenced document id of the given document under the given
-  // property path.
-  //
-  // TODO(b/256022027): validate joinable property (and its upper-level) should
-  //                    not have REPEATED cardinality.
-  //
-  // Returns:
-  //   - A valid referenced document id on success
-  //   - kInvalidDocumentId if the given document is not found, doesn't have
-  //     qualified id joinable type for the given property_path, or doesn't have
-  //     joinable value (an optional property)
-  //   - Any other QualifiedIdJoinIndex errors
-  libtextclassifier3::StatusOr<DocumentId> FetchReferencedQualifiedId(
-      const DocumentId& document_id, const std::string& property_path) const;
-
   const DocumentStore* doc_store_;  // Does not own.
   const SchemaStore* schema_store_;  // Does not own.
   const QualifiedIdJoinIndex* qualified_id_join_index_;  // Does not own.
diff --git a/icing/join/join-processor_test.cc b/icing/join/join-processor_test.cc
index 2cc1e25..dd88bd1 100644
--- a/icing/join/join-processor_test.cc
+++ b/icing/join/join-processor_test.cc
@@ -33,7 +33,6 @@
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/join/document-join-id-pair.h"
 #include "icing/join/join-children-fetcher.h"
-#include "icing/join/qualified-id-join-index-impl-v1.h"
 #include "icing/join/qualified-id-join-index-impl-v2.h"
 #include "icing/join/qualified-id-join-index-impl-v3.h"
 #include "icing/join/qualified-id-join-index.h"
@@ -76,7 +75,7 @@ using ::testing::Ne;
 using ::testing::UnorderedElementsAre;
 
 // TODO(b/275121148): remove template after deprecating
-// QualifiedIdJoinIndexImplV1.
+// QualifiedIdJoinIndexImplV2.
 template <typename T>
 class JoinProcessorTest : public ::testing::Test {
  protected:
@@ -180,8 +179,7 @@ class JoinProcessorTest : public ::testing::Test {
 
             .Build();
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
 
     ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
@@ -216,14 +214,6 @@ class JoinProcessorTest : public ::testing::Test {
     return absl_ports::InvalidArgumentError("Unknown type");
   }
 
-  template <>
-  libtextclassifier3::StatusOr<std::unique_ptr<QualifiedIdJoinIndex>>
-  CreateQualifiedIdJoinIndex<QualifiedIdJoinIndexImplV1>() {
-    return QualifiedIdJoinIndexImplV1::Create(
-        filesystem_, qualified_id_join_index_dir_, /*pre_mapping_fbv=*/false,
-        /*use_persistent_hash_map=*/false);
-  }
-
   template <>
   libtextclassifier3::StatusOr<std::unique_ptr<QualifiedIdJoinIndex>>
   CreateQualifiedIdJoinIndex<QualifiedIdJoinIndexImplV2>() {
@@ -291,8 +281,7 @@ class JoinProcessorTest : public ::testing::Test {
 };
 
 using TestTypes =
-    ::testing::Types<QualifiedIdJoinIndexImplV1, QualifiedIdJoinIndexImplV2,
-                     QualifiedIdJoinIndexImplV3>;
+    ::testing::Types<QualifiedIdJoinIndexImplV2, QualifiedIdJoinIndexImplV3>;
 TYPED_TEST_SUITE(JoinProcessorTest, TestTypes);
 
 TYPED_TEST(JoinProcessorTest, JoinByQualifiedId_allDocuments) {
diff --git a/icing/join/qualified-id-join-index-impl-v1.cc b/icing/join/qualified-id-join-index-impl-v1.cc
deleted file mode 100644
index da45e00..0000000
--- a/icing/join/qualified-id-join-index-impl-v1.cc
+++ /dev/null
@@ -1,517 +0,0 @@
-// Copyright (C) 2023 Google LLC
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//      http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-#include "icing/join/qualified-id-join-index-impl-v1.h"
-
-#include <cstdint>
-#include <cstring>
-#include <memory>
-#include <string>
-#include <string_view>
-#include <utility>
-#include <vector>
-
-#include "icing/text_classifier/lib3/utils/base/status.h"
-#include "icing/text_classifier/lib3/utils/base/statusor.h"
-#include "icing/absl_ports/canonical_errors.h"
-#include "icing/absl_ports/str_cat.h"
-#include "icing/file/destructible-directory.h"
-#include "icing/file/file-backed-vector.h"
-#include "icing/file/filesystem.h"
-#include "icing/file/memory-mapped-file.h"
-#include "icing/join/document-join-id-pair.h"
-#include "icing/join/qualified-id-join-index.h"
-#include "icing/store/document-id.h"
-#include "icing/store/dynamic-trie-key-mapper.h"
-#include "icing/store/key-mapper.h"
-#include "icing/store/namespace-id.h"
-#include "icing/store/persistent-hash-map-key-mapper.h"
-#include "icing/util/crc32.h"
-#include "icing/util/encode-util.h"
-#include "icing/util/logging.h"
-#include "icing/util/status-macros.h"
-
-namespace icing {
-namespace lib {
-
-namespace {
-
-// Set 1M for max # of qualified id entries and 10 bytes for key-value bytes.
-// This will take at most 23 MiB disk space and mmap for persistent hash map.
-static constexpr int32_t kDocumentJoinIdPairMapperMaxNumEntries = 1 << 20;
-static constexpr int32_t kDocumentJoinIdPairMapperAverageKVByteSize = 10;
-
-static constexpr int32_t kDocumentJoinIdPairMapperDynamicTrieMaxSize =
-    128 * 1024 * 1024;  // 128 MiB
-
-DocumentId GetNewDocumentId(
-    const std::vector<DocumentId>& document_id_old_to_new,
-    DocumentId old_document_id) {
-  if (old_document_id >= document_id_old_to_new.size()) {
-    return kInvalidDocumentId;
-  }
-  return document_id_old_to_new[old_document_id];
-}
-
-std::string GetMetadataFilePath(std::string_view working_path) {
-  return absl_ports::StrCat(working_path, "/metadata");
-}
-
-std::string GetDocumentJoinIdPairMapperPath(std::string_view working_path) {
-  // Use the old directory name "doc_join_info_mapper" to avoid rebuild. We just
-  // changed the class, variable and function name, so there is no need to
-  // change the directory name or rebuild the index.
-  return absl_ports::StrCat(working_path, "/doc_join_info_mapper");
-}
-
-std::string GetQualifiedIdStoragePath(std::string_view working_path) {
-  return absl_ports::StrCat(working_path, "/qualified_id_storage");
-}
-
-}  // namespace
-
-/* static */ libtextclassifier3::StatusOr<
-    std::unique_ptr<QualifiedIdJoinIndexImplV1>>
-QualifiedIdJoinIndexImplV1::Create(const Filesystem& filesystem,
-                                   std::string working_path,
-                                   bool pre_mapping_fbv,
-                                   bool use_persistent_hash_map) {
-  if (!filesystem.FileExists(GetMetadataFilePath(working_path).c_str()) ||
-      !filesystem.DirectoryExists(
-          GetDocumentJoinIdPairMapperPath(working_path).c_str()) ||
-      !filesystem.FileExists(GetQualifiedIdStoragePath(working_path).c_str())) {
-    // Discard working_path if any file/directory is missing, and reinitialize.
-    if (filesystem.DirectoryExists(working_path.c_str())) {
-      ICING_RETURN_IF_ERROR(
-          QualifiedIdJoinIndex::Discard(filesystem, working_path));
-    }
-    return InitializeNewFiles(filesystem, std::move(working_path),
-                              pre_mapping_fbv, use_persistent_hash_map);
-  }
-  return InitializeExistingFiles(filesystem, std::move(working_path),
-                                 pre_mapping_fbv, use_persistent_hash_map);
-}
-
-QualifiedIdJoinIndexImplV1::~QualifiedIdJoinIndexImplV1() {
-  if (!PersistToDisk().ok()) {
-    ICING_LOG(WARNING) << "Failed to persist qualified id type joinable index "
-                          "to disk while destructing "
-                       << working_path_;
-  }
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::Put(
-    const DocumentJoinIdPair& document_join_id_pair,
-    std::string_view ref_qualified_id_str) {
-  SetDirty();
-
-  if (!document_join_id_pair.is_valid()) {
-    return absl_ports::InvalidArgumentError(
-        "Cannot put data for an invalid DocumentJoinIdPair");
-  }
-
-  int32_t qualified_id_index = qualified_id_storage_->num_elements();
-  ICING_ASSIGN_OR_RETURN(
-      FileBackedVector<char>::MutableArrayView mutable_arr,
-      qualified_id_storage_->Allocate(ref_qualified_id_str.size() + 1));
-  mutable_arr.SetArray(/*idx=*/0, ref_qualified_id_str.data(),
-                       ref_qualified_id_str.size());
-  mutable_arr.SetArray(/*idx=*/ref_qualified_id_str.size(), /*arr=*/"\0",
-                       /*arr_len=*/1);
-
-  ICING_RETURN_IF_ERROR(document_join_id_pair_mapper_->Put(
-      encode_util::EncodeIntToCString(document_join_id_pair.value()),
-      qualified_id_index));
-
-  // TODO(b/268521214): add data into delete propagation storage
-
-  return libtextclassifier3::Status::OK;
-}
-
-libtextclassifier3::StatusOr<std::string_view> QualifiedIdJoinIndexImplV1::Get(
-    const DocumentJoinIdPair& document_join_id_pair) const {
-  if (!document_join_id_pair.is_valid()) {
-    return absl_ports::InvalidArgumentError(
-        "Cannot get data for an invalid DocumentJoinIdPair");
-  }
-
-  ICING_ASSIGN_OR_RETURN(
-      int32_t qualified_id_index,
-      document_join_id_pair_mapper_->Get(
-          encode_util::EncodeIntToCString(document_join_id_pair.value())));
-
-  const char* data = qualified_id_storage_->array() + qualified_id_index;
-  return std::string_view(data, strlen(data));
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::Optimize(
-    const std::vector<DocumentId>& document_id_old_to_new,
-    const std::vector<NamespaceId>& namespace_id_old_to_new,
-    DocumentId new_last_added_document_id) {
-  std::string temp_working_path = working_path_ + "_temp";
-  ICING_RETURN_IF_ERROR(
-      QualifiedIdJoinIndex::Discard(filesystem_, temp_working_path));
-
-  DestructibleDirectory temp_working_path_ddir(&filesystem_,
-                                               std::move(temp_working_path));
-  if (!temp_working_path_ddir.is_valid()) {
-    return absl_ports::InternalError(
-        "Unable to create temp directory to build new qualified id type "
-        "joinable index");
-  }
-
-  {
-    // Transfer all data from the current to new qualified id type joinable
-    // index. Also PersistToDisk and destruct the instance after finishing, so
-    // we can safely swap directories later.
-    ICING_ASSIGN_OR_RETURN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> new_index,
-        Create(filesystem_, temp_working_path_ddir.dir(), pre_mapping_fbv_,
-               use_persistent_hash_map_));
-    ICING_RETURN_IF_ERROR(
-        TransferIndex(document_id_old_to_new, new_index.get()));
-    new_index->set_last_added_document_id(new_last_added_document_id);
-    ICING_RETURN_IF_ERROR(new_index->PersistToDisk());
-  }
-
-  // Destruct current index's storage instances to safely swap directories.
-  // TODO(b/268521214): handle delete propagation storage
-  document_join_id_pair_mapper_.reset();
-  qualified_id_storage_.reset();
-
-  if (!filesystem_.SwapFiles(temp_working_path_ddir.dir().c_str(),
-                             working_path_.c_str())) {
-    return absl_ports::InternalError(
-        "Unable to apply new qualified id type joinable index due to failed "
-        "swap");
-  }
-
-  // Reinitialize qualified id type joinable index.
-  if (!filesystem_.PRead(GetMetadataFilePath(working_path_).c_str(),
-                         metadata_buffer_.get(), kMetadataFileSize,
-                         /*offset=*/0)) {
-    return absl_ports::InternalError("Fail to read metadata file");
-  }
-  if (use_persistent_hash_map_) {
-    ICING_ASSIGN_OR_RETURN(
-        document_join_id_pair_mapper_,
-        PersistentHashMapKeyMapper<int32_t>::Create(
-            filesystem_, GetDocumentJoinIdPairMapperPath(working_path_),
-            pre_mapping_fbv_,
-            /*max_num_entries=*/kDocumentJoinIdPairMapperMaxNumEntries,
-            /*average_kv_byte_size=*/
-            kDocumentJoinIdPairMapperAverageKVByteSize));
-  } else {
-    ICING_ASSIGN_OR_RETURN(
-        document_join_id_pair_mapper_,
-        DynamicTrieKeyMapper<int32_t>::Create(
-            filesystem_, GetDocumentJoinIdPairMapperPath(working_path_),
-            kDocumentJoinIdPairMapperDynamicTrieMaxSize));
-  }
-
-  ICING_ASSIGN_OR_RETURN(
-      qualified_id_storage_,
-      FileBackedVector<char>::Create(
-          filesystem_, GetQualifiedIdStoragePath(working_path_),
-          MemoryMappedFile::Strategy::READ_WRITE_AUTO_SYNC,
-          FileBackedVector<char>::kMaxFileSize,
-          /*pre_mapping_mmap_size=*/pre_mapping_fbv_ ? 1024 * 1024 : 0));
-
-  return libtextclassifier3::Status::OK;
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::Clear() {
-  SetDirty();
-
-  document_join_id_pair_mapper_.reset();
-  // Discard and reinitialize doc join info mapper.
-  std::string document_join_id_pair_mapper_path =
-      GetDocumentJoinIdPairMapperPath(working_path_);
-  if (use_persistent_hash_map_) {
-    ICING_RETURN_IF_ERROR(PersistentHashMapKeyMapper<int32_t>::Delete(
-        filesystem_, document_join_id_pair_mapper_path));
-    ICING_ASSIGN_OR_RETURN(
-        document_join_id_pair_mapper_,
-        PersistentHashMapKeyMapper<int32_t>::Create(
-            filesystem_, std::move(document_join_id_pair_mapper_path),
-            pre_mapping_fbv_,
-            /*max_num_entries=*/kDocumentJoinIdPairMapperMaxNumEntries,
-            /*average_kv_byte_size=*/
-            kDocumentJoinIdPairMapperAverageKVByteSize));
-  } else {
-    ICING_RETURN_IF_ERROR(DynamicTrieKeyMapper<int32_t>::Delete(
-        filesystem_, document_join_id_pair_mapper_path));
-    ICING_ASSIGN_OR_RETURN(document_join_id_pair_mapper_,
-                           DynamicTrieKeyMapper<int32_t>::Create(
-                               filesystem_, document_join_id_pair_mapper_path,
-                               kDocumentJoinIdPairMapperDynamicTrieMaxSize));
-  }
-
-  // Clear qualified_id_storage_.
-  if (qualified_id_storage_->num_elements() > 0) {
-    ICING_RETURN_IF_ERROR(qualified_id_storage_->TruncateTo(0));
-  }
-
-  // TODO(b/268521214): clear delete propagation storage
-
-  info().last_added_document_id = kInvalidDocumentId;
-  return libtextclassifier3::Status::OK;
-}
-
-/* static */ libtextclassifier3::StatusOr<
-    std::unique_ptr<QualifiedIdJoinIndexImplV1>>
-QualifiedIdJoinIndexImplV1::InitializeNewFiles(const Filesystem& filesystem,
-                                               std::string&& working_path,
-                                               bool pre_mapping_fbv,
-                                               bool use_persistent_hash_map) {
-  // Create working directory.
-  if (!filesystem.CreateDirectoryRecursively(working_path.c_str())) {
-    return absl_ports::InternalError(
-        absl_ports::StrCat("Failed to create directory: ", working_path));
-  }
-
-  // Initialize document_join_id_pair_mapper
-  std::unique_ptr<KeyMapper<int32_t>> document_join_id_pair_mapper;
-  if (use_persistent_hash_map) {
-    // TODO(b/263890397): decide PersistentHashMapKeyMapper size
-    ICING_ASSIGN_OR_RETURN(
-        document_join_id_pair_mapper,
-        PersistentHashMapKeyMapper<int32_t>::Create(
-            filesystem, GetDocumentJoinIdPairMapperPath(working_path),
-            pre_mapping_fbv,
-            /*max_num_entries=*/kDocumentJoinIdPairMapperMaxNumEntries,
-            /*average_kv_byte_size=*/
-            kDocumentJoinIdPairMapperAverageKVByteSize));
-  } else {
-    ICING_ASSIGN_OR_RETURN(
-        document_join_id_pair_mapper,
-        DynamicTrieKeyMapper<int32_t>::Create(
-            filesystem, GetDocumentJoinIdPairMapperPath(working_path),
-            kDocumentJoinIdPairMapperDynamicTrieMaxSize));
-  }
-
-  // Initialize qualified_id_storage
-  ICING_ASSIGN_OR_RETURN(
-      std::unique_ptr<FileBackedVector<char>> qualified_id_storage,
-      FileBackedVector<char>::Create(
-          filesystem, GetQualifiedIdStoragePath(working_path),
-          MemoryMappedFile::Strategy::READ_WRITE_AUTO_SYNC,
-          FileBackedVector<char>::kMaxFileSize,
-          /*pre_mapping_mmap_size=*/pre_mapping_fbv ? 1024 * 1024 : 0));
-
-  // Create instance.
-  auto new_index = std::unique_ptr<QualifiedIdJoinIndexImplV1>(
-      new QualifiedIdJoinIndexImplV1(
-          filesystem, std::move(working_path),
-          /*metadata_buffer=*/std::make_unique<uint8_t[]>(kMetadataFileSize),
-          std::move(document_join_id_pair_mapper),
-          std::move(qualified_id_storage), pre_mapping_fbv,
-          use_persistent_hash_map));
-  // Initialize info content.
-  new_index->info().magic = Info::kMagic;
-  new_index->info().last_added_document_id = kInvalidDocumentId;
-
-  // Initialize new PersistentStorage. The initial checksums will be computed
-  // and set via InitializeNewStorage.
-  ICING_RETURN_IF_ERROR(new_index->InitializeNewStorage());
-
-  return new_index;
-}
-
-/* static */ libtextclassifier3::StatusOr<
-    std::unique_ptr<QualifiedIdJoinIndexImplV1>>
-QualifiedIdJoinIndexImplV1::InitializeExistingFiles(
-    const Filesystem& filesystem, std::string&& working_path,
-    bool pre_mapping_fbv, bool use_persistent_hash_map) {
-  // PRead metadata file.
-  auto metadata_buffer = std::make_unique<uint8_t[]>(kMetadataFileSize);
-  if (!filesystem.PRead(GetMetadataFilePath(working_path).c_str(),
-                        metadata_buffer.get(), kMetadataFileSize,
-                        /*offset=*/0)) {
-    return absl_ports::InternalError("Fail to read metadata file");
-  }
-
-  // Initialize document_join_id_pair_mapper
-  bool dynamic_trie_key_mapper_dir_exists = filesystem.DirectoryExists(
-      absl_ports::StrCat(GetDocumentJoinIdPairMapperPath(working_path),
-                         "/key_mapper_dir")
-          .c_str());
-  if ((use_persistent_hash_map && dynamic_trie_key_mapper_dir_exists) ||
-      (!use_persistent_hash_map && !dynamic_trie_key_mapper_dir_exists)) {
-    // Return a failure here so that the caller can properly delete and rebuild
-    // this component.
-    return absl_ports::FailedPreconditionError("Key mapper type mismatch");
-  }
-
-  std::unique_ptr<KeyMapper<int32_t>> document_join_id_pair_mapper;
-  if (use_persistent_hash_map) {
-    ICING_ASSIGN_OR_RETURN(
-        document_join_id_pair_mapper,
-        PersistentHashMapKeyMapper<int32_t>::Create(
-            filesystem, GetDocumentJoinIdPairMapperPath(working_path),
-            pre_mapping_fbv,
-            /*max_num_entries=*/kDocumentJoinIdPairMapperMaxNumEntries,
-            /*average_kv_byte_size=*/
-            kDocumentJoinIdPairMapperAverageKVByteSize));
-  } else {
-    ICING_ASSIGN_OR_RETURN(
-        document_join_id_pair_mapper,
-        DynamicTrieKeyMapper<int32_t>::Create(
-            filesystem, GetDocumentJoinIdPairMapperPath(working_path),
-            kDocumentJoinIdPairMapperDynamicTrieMaxSize));
-  }
-
-  // Initialize qualified_id_storage
-  ICING_ASSIGN_OR_RETURN(
-      std::unique_ptr<FileBackedVector<char>> qualified_id_storage,
-      FileBackedVector<char>::Create(
-          filesystem, GetQualifiedIdStoragePath(working_path),
-          MemoryMappedFile::Strategy::READ_WRITE_AUTO_SYNC,
-          FileBackedVector<char>::kMaxFileSize,
-          /*pre_mapping_mmap_size=*/pre_mapping_fbv ? 1024 * 1024 : 0));
-
-  // Create instance.
-  auto type_joinable_index = std::unique_ptr<QualifiedIdJoinIndexImplV1>(
-      new QualifiedIdJoinIndexImplV1(filesystem, std::move(working_path),
-                                     std::move(metadata_buffer),
-                                     std::move(document_join_id_pair_mapper),
-                                     std::move(qualified_id_storage),
-                                     pre_mapping_fbv, use_persistent_hash_map));
-
-  // Initialize existing PersistentStorage. Checksums will be validated.
-  ICING_RETURN_IF_ERROR(type_joinable_index->InitializeExistingStorage());
-
-  // Validate magic.
-  if (type_joinable_index->info().magic != Info::kMagic) {
-    return absl_ports::FailedPreconditionError("Incorrect magic value");
-  }
-
-  return type_joinable_index;
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::TransferIndex(
-    const std::vector<DocumentId>& document_id_old_to_new,
-    QualifiedIdJoinIndexImplV1* new_index) const {
-  std::unique_ptr<KeyMapper<int32_t>::Iterator> iter =
-      document_join_id_pair_mapper_->GetIterator();
-  while (iter->Advance()) {
-    DocumentJoinIdPair old_document_join_id_pair(
-        encode_util::DecodeIntFromCString(iter->GetKey()));
-    int32_t qualified_id_index = iter->GetValue();
-
-    const char* data = qualified_id_storage_->array() + qualified_id_index;
-    std::string_view ref_qualified_id_str(data, strlen(data));
-
-    // Translate to new doc id.
-    DocumentId new_document_id = GetNewDocumentId(
-        document_id_old_to_new, old_document_join_id_pair.document_id());
-
-    if (new_document_id != kInvalidDocumentId) {
-      ICING_RETURN_IF_ERROR(new_index->Put(
-          DocumentJoinIdPair(new_document_id,
-                             old_document_join_id_pair.joinable_property_id()),
-          ref_qualified_id_str));
-    }
-  }
-
-  // TODO(b/268521214): transfer delete propagation storage
-  return libtextclassifier3::Status::OK;
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::PersistMetadataToDisk() {
-  if (is_initialized_ && !is_info_dirty() && !is_storage_dirty()) {
-    return libtextclassifier3::Status::OK;
-  }
-
-  std::string metadata_file_path = GetMetadataFilePath(working_path_);
-  ScopedFd sfd(filesystem_.OpenForWrite(metadata_file_path.c_str()));
-  ICING_RETURN_IF_ERROR(InternalWriteMetadata(sfd));
-  if (!filesystem_.DataSync(sfd.get())) {
-    return absl_ports::InternalError("Fail to sync metadata to disk");
-  }
-  is_info_dirty_ = false;
-  return libtextclassifier3::Status::OK;
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::PersistStoragesToDisk() {
-  if (is_initialized_ && !is_storage_dirty()) {
-    return libtextclassifier3::Status::OK;
-  }
-
-  ICING_RETURN_IF_ERROR(document_join_id_pair_mapper_->PersistToDisk());
-  ICING_RETURN_IF_ERROR(qualified_id_storage_->PersistToDisk());
-  is_storage_dirty_ = false;
-  return libtextclassifier3::Status::OK;
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::WriteMetadata() {
-  if (is_initialized_ && !is_info_dirty() && !is_storage_dirty()) {
-    return libtextclassifier3::Status::OK;
-  }
-
-  std::string metadata_file_path = GetMetadataFilePath(working_path_);
-  ScopedFd sfd(filesystem_.OpenForWrite(metadata_file_path.c_str()));
-  return InternalWriteMetadata(std::move(sfd));
-}
-
-libtextclassifier3::Status QualifiedIdJoinIndexImplV1::InternalWriteMetadata(
-    const ScopedFd& sfd) {
-  if (!sfd.is_valid()) {
-    return absl_ports::InternalError("Fail to open metadata file for write");
-  }
-  if (!filesystem_.PWrite(sfd.get(), /*offset=*/0, metadata_buffer_.get(),
-                          kMetadataFileSize)) {
-    return absl_ports::InternalError("Fail to write metadata file");
-  }
-  return libtextclassifier3::Status::OK;
-}
-
-libtextclassifier3::StatusOr<Crc32>
-QualifiedIdJoinIndexImplV1::UpdateStoragesChecksum() {
-  if (is_initialized_ && !is_storage_dirty()) {
-    return Crc32(crcs().component_crcs.storages_crc);
-  }
-
-  ICING_ASSIGN_OR_RETURN(Crc32 document_join_id_pair_mapper_crc,
-                         document_join_id_pair_mapper_->UpdateChecksum());
-  ICING_ASSIGN_OR_RETURN(Crc32 qualified_id_storage_crc,
-                         qualified_id_storage_->UpdateChecksum());
-  return Crc32(document_join_id_pair_mapper_crc.Get() ^
-               qualified_id_storage_crc.Get());
-}
-
-libtextclassifier3::StatusOr<Crc32>
-QualifiedIdJoinIndexImplV1::GetInfoChecksum() const {
-  // Info checksum is not cached and is calculated on the fly. Just call Get.
-  if (is_initialized_ && !is_info_dirty()) {
-    return Crc32(crcs().component_crcs.info_crc);
-  }
-  return info().GetChecksum();
-}
-
-libtextclassifier3::StatusOr<Crc32>
-QualifiedIdJoinIndexImplV1::GetStoragesChecksum() const {
-  if (is_initialized_ && !is_storage_dirty()) {
-    return Crc32(crcs().component_crcs.storages_crc);
-  }
-
-  ICING_ASSIGN_OR_RETURN(Crc32 document_join_id_pair_mapper_crc,
-                         document_join_id_pair_mapper_->GetChecksum());
-  Crc32 qualified_id_storage_crc = qualified_id_storage_->GetChecksum();
-  return Crc32(document_join_id_pair_mapper_crc.Get() ^
-               qualified_id_storage_crc.Get());
-}
-
-}  // namespace lib
-}  // namespace icing
diff --git a/icing/join/qualified-id-join-index-impl-v1.h b/icing/join/qualified-id-join-index-impl-v1.h
deleted file mode 100644
index 9a4a6fb..0000000
--- a/icing/join/qualified-id-join-index-impl-v1.h
+++ /dev/null
@@ -1,298 +0,0 @@
-// Copyright (C) 2023 Google LLC
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//      http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-#ifndef ICING_JOIN_QUALIFIED_ID_JOIN_INDEX_IMPL_V1_H_
-#define ICING_JOIN_QUALIFIED_ID_JOIN_INDEX_IMPL_V1_H_
-
-#include <cstdint>
-#include <memory>
-#include <string>
-#include <string_view>
-#include <utility>
-#include <vector>
-
-#include "icing/text_classifier/lib3/utils/base/status.h"
-#include "icing/text_classifier/lib3/utils/base/statusor.h"
-#include "icing/absl_ports/canonical_errors.h"
-#include "icing/file/file-backed-vector.h"
-#include "icing/file/filesystem.h"
-#include "icing/file/persistent-storage.h"
-#include "icing/join/document-join-id-pair.h"
-#include "icing/join/qualified-id-join-index.h"
-#include "icing/schema/joinable-property.h"
-#include "icing/store/document-filter-data.h"
-#include "icing/store/document-id.h"
-#include "icing/store/key-mapper.h"
-#include "icing/store/namespace-id-fingerprint.h"
-#include "icing/store/namespace-id.h"
-#include "icing/util/crc32.h"
-
-namespace icing {
-namespace lib {
-
-// QualifiedIdJoinIndexImplV1: a class to maintain data mapping
-// DocumentJoinIdPair to joinable qualified ids and delete propagation info.
-class QualifiedIdJoinIndexImplV1 : public QualifiedIdJoinIndex {
- public:
-  struct Info {
-    static constexpr int32_t kMagic = 0x48cabdc6;
-
-    int32_t magic;
-    DocumentId last_added_document_id;
-
-    Crc32 GetChecksum() const {
-      return Crc32(
-          std::string_view(reinterpret_cast<const char*>(this), sizeof(Info)));
-    }
-  } __attribute__((packed));
-  static_assert(sizeof(Info) == 8, "");
-
-  // Metadata file layout: <Crcs><Info>
-  static constexpr int32_t kCrcsMetadataBufferOffset = 0;
-  static constexpr int32_t kInfoMetadataBufferOffset =
-      static_cast<int32_t>(sizeof(Crcs));
-  static constexpr int32_t kMetadataFileSize = sizeof(Crcs) + sizeof(Info);
-  static_assert(kMetadataFileSize == 20, "");
-
-  // Creates a QualifiedIdJoinIndexImplV1 instance to store qualified ids for
-  // future joining search. If any of the underlying file is missing, then
-  // delete the whole working_path and (re)initialize with new ones. Otherwise
-  // initialize and create the instance by existing files.
-  //
-  // filesystem: Object to make system level calls
-  // working_path: Specifies the working path for PersistentStorage.
-  //               QualifiedIdJoinIndexImplV1 uses working path as working
-  //               directory and all related files will be stored under this
-  //               directory. It takes full ownership and of working_path_,
-  //               including creation/deletion. It is the caller's
-  //               responsibility to specify correct working path and avoid
-  //               mixing different persistent storages together under the same
-  //               path. Also the caller has the ownership for the parent
-  //               directory of working_path_, and it is responsible for parent
-  //               directory creation/deletion. See PersistentStorage for more
-  //               details about the concept of working_path.
-  // pre_mapping_fbv: flag indicating whether memory map max possible file size
-  //                  for underlying FileBackedVector before growing the actual
-  //                  file size.
-  // use_persistent_hash_map: flag indicating whether use persistent hash map as
-  //                          the key mapper (if false, then fall back to
-  //                          dynamic trie key mapper).
-  //
-  // Returns:
-  //   - FAILED_PRECONDITION_ERROR if the file checksum doesn't match the stored
-  //                               checksum
-  //   - INTERNAL_ERROR on I/O errors
-  //   - Any KeyMapper errors
-  static libtextclassifier3::StatusOr<
-      std::unique_ptr<QualifiedIdJoinIndexImplV1>>
-  Create(const Filesystem& filesystem, std::string working_path,
-         bool pre_mapping_fbv, bool use_persistent_hash_map);
-
-  // Delete copy and move constructor/assignment operator.
-  QualifiedIdJoinIndexImplV1(const QualifiedIdJoinIndexImplV1&) = delete;
-  QualifiedIdJoinIndexImplV1& operator=(const QualifiedIdJoinIndexImplV1&) =
-      delete;
-
-  QualifiedIdJoinIndexImplV1(QualifiedIdJoinIndexImplV1&&) = delete;
-  QualifiedIdJoinIndexImplV1& operator=(QualifiedIdJoinIndexImplV1&&) = delete;
-
-  ~QualifiedIdJoinIndexImplV1() override;
-
-  // v2 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::Status Put(
-      SchemaTypeId schema_type_id, JoinablePropertyId joinable_property_id,
-      DocumentId document_id,
-      std::vector<NamespaceIdFingerprint>&& ref_namespace_id_uri_fingerprints)
-      override {
-    return absl_ports::UnimplementedError("This API is not supported in V1");
-  }
-
-  // v2 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::StatusOr<std::unique_ptr<JoinDataIteratorBase>>
-  GetIterator(SchemaTypeId schema_type_id,
-              JoinablePropertyId joinable_property_id) const override {
-    return absl_ports::UnimplementedError("This API is not supported in V1");
-  }
-
-  // v3 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::Status Put(
-      const DocumentJoinIdPair& child_document_join_id_pair,
-      std::vector<DocumentId>&& parent_document_ids) override {
-    return absl_ports::UnimplementedError("This API is not supported in V1");
-  }
-
-  // v3 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::StatusOr<std::vector<DocumentJoinIdPair>> Get(
-      DocumentId parent_document_id) const override {
-    return absl_ports::UnimplementedError("This API is not supported in V1");
-  }
-
-  libtextclassifier3::Status Put(
-      const DocumentJoinIdPair& document_join_id_pair,
-      std::string_view ref_qualified_id_str) override;
-
-  libtextclassifier3::StatusOr<std::string_view> Get(
-      const DocumentJoinIdPair& document_join_id_pair) const override;
-
-  // No-op since v1 stores parent information in raw qualified id string format
-  // and does not require parent migration.
-  libtextclassifier3::Status MigrateParent(
-      DocumentId old_document_id, DocumentId new_document_id) override {
-    return libtextclassifier3::Status::OK;
-  }
-
-  libtextclassifier3::Status Optimize(
-      const std::vector<DocumentId>& document_id_old_to_new,
-      const std::vector<NamespaceId>& namespace_id_old_to_new,
-      DocumentId new_last_added_document_id) override;
-
-  libtextclassifier3::Status Clear() override;
-
-  QualifiedIdJoinIndex::Version version() const override {
-    return QualifiedIdJoinIndex::Version::kV1;
-  }
-
-  int32_t size() const override {
-    return document_join_id_pair_mapper_->num_keys();
-  }
-
-  bool empty() const override { return size() == 0; }
-
-  DocumentId last_added_document_id() const override {
-    return info().last_added_document_id;
-  }
-
-  void set_last_added_document_id(DocumentId document_id) override {
-    SetInfoDirty();
-
-    Info& info_ref = info();
-    if (info_ref.last_added_document_id == kInvalidDocumentId ||
-        document_id > info_ref.last_added_document_id) {
-      info_ref.last_added_document_id = document_id;
-    }
-  }
-
- private:
-  explicit QualifiedIdJoinIndexImplV1(
-      const Filesystem& filesystem, std::string&& working_path,
-      std::unique_ptr<uint8_t[]> metadata_buffer,
-      std::unique_ptr<KeyMapper<int32_t>> document_join_id_pair_mapper,
-      std::unique_ptr<FileBackedVector<char>> qualified_id_storage,
-      bool pre_mapping_fbv, bool use_persistent_hash_map)
-      : QualifiedIdJoinIndex(filesystem, std::move(working_path)),
-        metadata_buffer_(std::move(metadata_buffer)),
-        document_join_id_pair_mapper_(std::move(document_join_id_pair_mapper)),
-        qualified_id_storage_(std::move(qualified_id_storage)),
-        pre_mapping_fbv_(pre_mapping_fbv),
-        use_persistent_hash_map_(use_persistent_hash_map),
-        is_info_dirty_(false),
-        is_storage_dirty_(false) {}
-
-  static libtextclassifier3::StatusOr<
-      std::unique_ptr<QualifiedIdJoinIndexImplV1>>
-  InitializeNewFiles(const Filesystem& filesystem, std::string&& working_path,
-                     bool pre_mapping_fbv, bool use_persistent_hash_map);
-
-  static libtextclassifier3::StatusOr<
-      std::unique_ptr<QualifiedIdJoinIndexImplV1>>
-  InitializeExistingFiles(const Filesystem& filesystem,
-                          std::string&& working_path, bool pre_mapping_fbv,
-                          bool use_persistent_hash_map);
-
-  // Transfers qualified id join index data from the current to new_index and
-  // convert to new document id according to document_id_old_to_new. It is a
-  // helper function for Optimize.
-  //
-  // Returns:
-  //   - OK on success
-  //   - INTERNAL_ERROR on I/O error
-  libtextclassifier3::Status TransferIndex(
-      const std::vector<DocumentId>& document_id_old_to_new,
-      QualifiedIdJoinIndexImplV1* new_index) const;
-
-  libtextclassifier3::Status PersistMetadataToDisk() override;
-
-  libtextclassifier3::Status PersistStoragesToDisk() override;
-
-  libtextclassifier3::Status WriteMetadata() override;
-
-  libtextclassifier3::Status InternalWriteMetadata(const ScopedFd& sfd);
-
-  libtextclassifier3::StatusOr<Crc32> UpdateStoragesChecksum() override;
-
-  libtextclassifier3::StatusOr<Crc32> GetInfoChecksum() const override;
-
-  libtextclassifier3::StatusOr<Crc32> GetStoragesChecksum() const override;
-
-  Crcs& crcs() override {
-    return *reinterpret_cast<Crcs*>(metadata_buffer_.get() +
-                                    kCrcsMetadataBufferOffset);
-  }
-
-  const Crcs& crcs() const override {
-    return *reinterpret_cast<const Crcs*>(metadata_buffer_.get() +
-                                          kCrcsMetadataBufferOffset);
-  }
-
-  Info& info() {
-    return *reinterpret_cast<Info*>(metadata_buffer_.get() +
-                                    kInfoMetadataBufferOffset);
-  }
-
-  const Info& info() const {
-    return *reinterpret_cast<const Info*>(metadata_buffer_.get() +
-                                          kInfoMetadataBufferOffset);
-  }
-
-  void SetInfoDirty() { is_info_dirty_ = true; }
-
-  // When storage is dirty, we have to set info dirty as well. So just expose
-  // SetDirty to set both.
-  void SetDirty() {
-    SetInfoDirty();
-    is_storage_dirty_ = true;
-  }
-
-  bool is_info_dirty() const { return is_info_dirty_; }
-  bool is_storage_dirty() const { return is_storage_dirty_; }
-
-  // Metadata buffer
-  std::unique_ptr<uint8_t[]> metadata_buffer_;
-
-  // Persistent KeyMapper for mapping (encoded) DocumentJoinIdPair (DocumentId,
-  // JoinablePropertyId) to another referenced document's qualified id string
-  // index in qualified_id_storage_.
-  std::unique_ptr<KeyMapper<int32_t>> document_join_id_pair_mapper_;
-
-  // Storage for qualified id strings.
-  std::unique_ptr<FileBackedVector<char>> qualified_id_storage_;
-
-  // TODO(b/268521214): add delete propagation storage
-
-  // Flag indicating whether memory map max possible file size for underlying
-  // FileBackedVector before growing the actual file size.
-  bool pre_mapping_fbv_;
-
-  // Flag indicating whether use persistent hash map as the key mapper (if
-  // false, then fall back to dynamic trie key mapper).
-  bool use_persistent_hash_map_;
-
-  bool is_info_dirty_;
-  bool is_storage_dirty_;
-};
-
-}  // namespace lib
-}  // namespace icing
-
-#endif  // ICING_JOIN_QUALIFIED_ID_JOIN_INDEX_IMPL_V1_H_
diff --git a/icing/join/qualified-id-join-index-impl-v1_test.cc b/icing/join/qualified-id-join-index-impl-v1_test.cc
deleted file mode 100644
index 5af86fc..0000000
--- a/icing/join/qualified-id-join-index-impl-v1_test.cc
+++ /dev/null
@@ -1,995 +0,0 @@
-// Copyright (C) 2023 Google LLC
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//      http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-#include "icing/join/qualified-id-join-index-impl-v1.h"
-
-#include <cstdint>
-#include <memory>
-#include <string>
-#include <string_view>
-
-#include "icing/text_classifier/lib3/utils/base/status.h"
-#include "gmock/gmock.h"
-#include "gtest/gtest.h"
-#include "icing/file/file-backed-vector.h"
-#include "icing/file/filesystem.h"
-#include "icing/file/persistent-storage.h"
-#include "icing/join/document-join-id-pair.h"
-#include "icing/store/document-id.h"
-#include "icing/store/dynamic-trie-key-mapper.h"
-#include "icing/store/key-mapper.h"
-#include "icing/store/persistent-hash-map-key-mapper.h"
-#include "icing/testing/common-matchers.h"
-#include "icing/testing/tmp-directory.h"
-#include "icing/util/crc32.h"
-
-namespace icing {
-namespace lib {
-
-namespace {
-
-using ::testing::Eq;
-using ::testing::HasSubstr;
-using ::testing::IsEmpty;
-using ::testing::IsTrue;
-using ::testing::Lt;
-using ::testing::Ne;
-using ::testing::Not;
-using ::testing::Pointee;
-using ::testing::SizeIs;
-
-using Crcs = PersistentStorage::Crcs;
-using Info = QualifiedIdJoinIndexImplV1::Info;
-
-static constexpr int32_t kCorruptedValueOffset = 3;
-
-struct QualifiedIdJoinIndexImplV1TestParam {
-  bool pre_mapping_fbv;
-  bool use_persistent_hash_map;
-
-  explicit QualifiedIdJoinIndexImplV1TestParam(bool pre_mapping_fbv_in,
-                                               bool use_persistent_hash_map_in)
-      : pre_mapping_fbv(pre_mapping_fbv_in),
-        use_persistent_hash_map(use_persistent_hash_map_in) {}
-};
-
-class QualifiedIdJoinIndexImplV1Test
-    : public ::testing::TestWithParam<QualifiedIdJoinIndexImplV1TestParam> {
- protected:
-  void SetUp() override {
-    base_dir_ = GetTestTempDir() + "/icing";
-    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(base_dir_.c_str()),
-                IsTrue());
-
-    working_path_ = base_dir_ + "/qualified_id_join_index_test";
-  }
-
-  void TearDown() override {
-    filesystem_.DeleteDirectoryRecursively(base_dir_.c_str());
-  }
-
-  Filesystem filesystem_;
-  std::string base_dir_;
-  std::string working_path_;
-};
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, InvalidWorkingPath) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(
-                  filesystem_, "/dev/null/qualified_id_join_index_test",
-                  param.pre_mapping_fbv, param.use_persistent_hash_map),
-              StatusIs(libtextclassifier3::StatusCode::INTERNAL));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, InitializeNewFiles) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ASSERT_FALSE(filesystem_.DirectoryExists(working_path_.c_str()));
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    EXPECT_THAT(index, Pointee(IsEmpty()));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  // Metadata file should be initialized correctly for both info and crcs
-  // sections.
-  const std::string metadata_file_path =
-      absl_ports::StrCat(working_path_, "/metadata");
-  auto metadata_buffer = std::make_unique<uint8_t[]>(
-      QualifiedIdJoinIndexImplV1::kMetadataFileSize);
-  ASSERT_THAT(
-      filesystem_.PRead(metadata_file_path.c_str(), metadata_buffer.get(),
-                        QualifiedIdJoinIndexImplV1::kMetadataFileSize,
-                        /*offset=*/0),
-      IsTrue());
-
-  // Check info section
-  const Info* info = reinterpret_cast<const Info*>(
-      metadata_buffer.get() +
-      QualifiedIdJoinIndexImplV1::kInfoMetadataBufferOffset);
-  EXPECT_THAT(info->magic, Eq(Info::kMagic));
-  EXPECT_THAT(info->last_added_document_id, Eq(kInvalidDocumentId));
-
-  // Check crcs section
-  const Crcs* crcs = reinterpret_cast<const Crcs*>(
-      metadata_buffer.get() +
-      QualifiedIdJoinIndexImplV1::kCrcsMetadataBufferOffset);
-  // There are some initial info in KeyMapper, so storages_crc should be
-  // non-zero.
-  EXPECT_THAT(crcs->component_crcs.storages_crc, Ne(0));
-  EXPECT_THAT(crcs->component_crcs.info_crc,
-              Eq(Crc32(std::string_view(reinterpret_cast<const char*>(info),
-                                        sizeof(Info)))
-                     .Get()));
-  EXPECT_THAT(crcs->all_crc,
-              Eq(Crc32(std::string_view(
-                           reinterpret_cast<const char*>(&crcs->component_crcs),
-                           sizeof(Crcs::ComponentCrcs)))
-                     .Get()));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializationShouldFailWithoutPersistToDiskOrDestruction) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  // Create new qualified id join index
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  // Insert some data.
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(index->PersistToDisk());
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/3, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriB"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/5, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriC"));
-  // GetChecksum should succeed without updating the checksum.
-  ICING_EXPECT_OK(index->GetChecksum());
-
-  // Without calling PersistToDisk, checksums will not be recomputed or synced
-  // to disk, so initializing another instance on the same files should fail.
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                 param.pre_mapping_fbv,
-                                                 param.use_persistent_hash_map),
-              StatusIs(param.use_persistent_hash_map
-                           ? libtextclassifier3::StatusCode::FAILED_PRECONDITION
-                           : libtextclassifier3::StatusCode::INTERNAL));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializationShouldSucceedWithUpdateChecksums) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  // Create new qualified id join index
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index1,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  // Insert some data.
-  ICING_ASSERT_OK(index1->Put(
-      DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(index1->Put(
-      DocumentJoinIdPair(/*document_id=*/3, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriB"));
-  ICING_ASSERT_OK(index1->Put(
-      DocumentJoinIdPair(/*document_id=*/5, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriC"));
-  ASSERT_THAT(index1, Pointee(SizeIs(3)));
-
-  // After calling UpdateChecksums, all checksums should be recomputed and
-  // synced correctly to disk, so initializing another instance on the same
-  // files should succeed, and we should be able to get the same contents.
-  ICING_ASSERT_OK_AND_ASSIGN(Crc32 crc, index1->GetChecksum());
-  EXPECT_THAT(index1->UpdateChecksums(), IsOkAndHolds(Eq(crc)));
-  EXPECT_THAT(index1->GetChecksum(), IsOkAndHolds(Eq(crc)));
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index2,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-  EXPECT_THAT(index2, Pointee(SizeIs(3)));
-  EXPECT_THAT(index2->Get(DocumentJoinIdPair(/*document_id=*/1,
-                                             /*joinable_property_id=*/20)),
-              IsOkAndHolds(/*ref_qualified_id_str=*/"namespace#uriA"));
-  EXPECT_THAT(index2->Get(DocumentJoinIdPair(/*document_id=*/3,
-                                             /*joinable_property_id=*/20)),
-              IsOkAndHolds(/*ref_qualified_id_str=*/"namespace#uriB"));
-  EXPECT_THAT(index2->Get(DocumentJoinIdPair(/*document_id=*/5,
-                                             /*joinable_property_id=*/20)),
-              IsOkAndHolds(/*ref_qualified_id_str=*/"namespace#uriC"));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializationShouldSucceedWithPersistToDisk) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  // Create new qualified id join index
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index1,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  // Insert some data.
-  ICING_ASSERT_OK(index1->Put(
-      DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(index1->Put(
-      DocumentJoinIdPair(/*document_id=*/3, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriB"));
-  ICING_ASSERT_OK(index1->Put(
-      DocumentJoinIdPair(/*document_id=*/5, /*joinable_property_id=*/20),
-      /*ref_qualified_id_str=*/"namespace#uriC"));
-  ASSERT_THAT(index1, Pointee(SizeIs(3)));
-
-  // After calling PersistToDisk, all checksums should be recomputed and synced
-  // correctly to disk, so initializing another instance on the same files
-  // should succeed, and we should be able to get the same contents.
-  ICING_EXPECT_OK(index1->PersistToDisk());
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index2,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-  EXPECT_THAT(index2, Pointee(SizeIs(3)));
-  EXPECT_THAT(index2->Get(DocumentJoinIdPair(/*document_id=*/1,
-                                             /*joinable_property_id=*/20)),
-              IsOkAndHolds(/*ref_qualified_id_str=*/"namespace#uriA"));
-  EXPECT_THAT(index2->Get(DocumentJoinIdPair(/*document_id=*/3,
-                                             /*joinable_property_id=*/20)),
-              IsOkAndHolds(/*ref_qualified_id_str=*/"namespace#uriB"));
-  EXPECT_THAT(index2->Get(DocumentJoinIdPair(/*document_id=*/5,
-                                             /*joinable_property_id=*/20)),
-              IsOkAndHolds(/*ref_qualified_id_str=*/"namespace#uriC"));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializationShouldSucceedAfterDestruction) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-
-    // Insert some data.
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriA"));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/3, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriB"));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/5, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriC"));
-    ASSERT_THAT(index, Pointee(SizeIs(3)));
-  }
-
-  {
-    // The previous instance went out of scope and was destructed. Although we
-    // didn't call PersistToDisk explicitly, the destructor should invoke it and
-    // thus initializing another instance on the same files should succeed, and
-    // we should be able to get the same contents.
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    EXPECT_THAT(index, Pointee(SizeIs(3)));
-    EXPECT_THAT(index->Get(DocumentJoinIdPair(/*document_id=*/1,
-                                              /*joinable_property_id=*/20)),
-                IsOkAndHolds("namespace#uriA"));
-    EXPECT_THAT(index->Get(DocumentJoinIdPair(/*document_id=*/3,
-                                              /*joinable_property_id=*/20)),
-                IsOkAndHolds("namespace#uriB"));
-    EXPECT_THAT(index->Get(DocumentJoinIdPair(/*document_id=*/5,
-                                              /*joinable_property_id=*/20)),
-                IsOkAndHolds("namespace#uriC"));
-  }
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializeExistingFilesWithDifferentMagicShouldFail) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriA"));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  {
-    // Manually change magic and update checksum
-    const std::string metadata_file_path =
-        absl_ports::StrCat(working_path_, "/metadata");
-    ScopedFd metadata_sfd(filesystem_.OpenForWrite(metadata_file_path.c_str()));
-    ASSERT_THAT(metadata_sfd.is_valid(), IsTrue());
-
-    auto metadata_buffer = std::make_unique<uint8_t[]>(
-        QualifiedIdJoinIndexImplV1::kMetadataFileSize);
-    ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
-                                  QualifiedIdJoinIndexImplV1::kMetadataFileSize,
-                                  /*offset=*/0),
-                IsTrue());
-
-    // Manually change magic and update checksums.
-    Crcs* crcs = reinterpret_cast<Crcs*>(
-        metadata_buffer.get() +
-        QualifiedIdJoinIndexImplV1::kCrcsMetadataBufferOffset);
-    Info* info = reinterpret_cast<Info*>(
-        metadata_buffer.get() +
-        QualifiedIdJoinIndexImplV1::kInfoMetadataBufferOffset);
-    info->magic += kCorruptedValueOffset;
-    crcs->component_crcs.info_crc = info->GetChecksum().Get();
-    crcs->all_crc = crcs->component_crcs.GetChecksum().Get();
-    ASSERT_THAT(filesystem_.PWrite(
-                    metadata_sfd.get(), /*offset=*/0, metadata_buffer.get(),
-                    QualifiedIdJoinIndexImplV1::kMetadataFileSize),
-                IsTrue());
-  }
-
-  // Attempt to create the qualified id join index with different magic. This
-  // should fail.
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                 param.pre_mapping_fbv,
-                                                 param.use_persistent_hash_map),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION,
-                       HasSubstr("Incorrect magic value")));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializeExistingFilesWithWrongAllCrcShouldFail) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriA"));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  {
-    const std::string metadata_file_path =
-        absl_ports::StrCat(working_path_, "/metadata");
-    ScopedFd metadata_sfd(filesystem_.OpenForWrite(metadata_file_path.c_str()));
-    ASSERT_THAT(metadata_sfd.is_valid(), IsTrue());
-
-    auto metadata_buffer = std::make_unique<uint8_t[]>(
-        QualifiedIdJoinIndexImplV1::kMetadataFileSize);
-    ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
-                                  QualifiedIdJoinIndexImplV1::kMetadataFileSize,
-                                  /*offset=*/0),
-                IsTrue());
-
-    // Manually corrupt all_crc
-    Crcs* crcs = reinterpret_cast<Crcs*>(
-        metadata_buffer.get() +
-        QualifiedIdJoinIndexImplV1::kCrcsMetadataBufferOffset);
-    crcs->all_crc += kCorruptedValueOffset;
-
-    ASSERT_THAT(filesystem_.PWrite(
-                    metadata_sfd.get(), /*offset=*/0, metadata_buffer.get(),
-                    QualifiedIdJoinIndexImplV1::kMetadataFileSize),
-                IsTrue());
-  }
-
-  // Attempt to create the qualified id join index with metadata containing
-  // corrupted all_crc. This should fail.
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                 param.pre_mapping_fbv,
-                                                 param.use_persistent_hash_map),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION,
-                       HasSubstr("Invalid all crc")));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializeExistingFilesWithCorruptedInfoShouldFail) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriA"));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  {
-    const std::string metadata_file_path =
-        absl_ports::StrCat(working_path_, "/metadata");
-    ScopedFd metadata_sfd(filesystem_.OpenForWrite(metadata_file_path.c_str()));
-    ASSERT_THAT(metadata_sfd.is_valid(), IsTrue());
-
-    auto metadata_buffer = std::make_unique<uint8_t[]>(
-        QualifiedIdJoinIndexImplV1::kMetadataFileSize);
-    ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
-                                  QualifiedIdJoinIndexImplV1::kMetadataFileSize,
-                                  /*offset=*/0),
-                IsTrue());
-
-    // Modify info, but don't update the checksum. This would be similar to
-    // corruption of info.
-    Info* info = reinterpret_cast<Info*>(
-        metadata_buffer.get() +
-        QualifiedIdJoinIndexImplV1::kInfoMetadataBufferOffset);
-    info->last_added_document_id += kCorruptedValueOffset;
-
-    ASSERT_THAT(filesystem_.PWrite(
-                    metadata_sfd.get(), /*offset=*/0, metadata_buffer.get(),
-                    QualifiedIdJoinIndexImplV1::kMetadataFileSize),
-                IsTrue());
-  }
-
-  // Attempt to create the qualified id join index with info that doesn't match
-  // its checksum. This should fail.
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                 param.pre_mapping_fbv,
-                                                 param.use_persistent_hash_map),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION,
-                       HasSubstr("Invalid info crc")));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializeExistingFilesWithCorruptedDocumentJoinIdPairMapperShouldFail) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriA"));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  // Corrupt doc_join_info_mapper manually.
-  {
-    std::string mapper_working_path =
-        absl_ports::StrCat(working_path_, "/doc_join_info_mapper");
-    std::unique_ptr<KeyMapper<int32_t>> mapper;
-    if (param.use_persistent_hash_map) {
-      ICING_ASSERT_OK_AND_ASSIGN(
-          mapper, PersistentHashMapKeyMapper<int32_t>::Create(
-                      filesystem_, std::move(mapper_working_path),
-                      param.pre_mapping_fbv));
-    } else {
-      ICING_ASSERT_OK_AND_ASSIGN(mapper,
-                                 DynamicTrieKeyMapper<int32_t>::Create(
-                                     filesystem_, mapper_working_path,
-                                     /*maximum_size_bytes=*/128 * 1024 * 1024));
-    }
-    ICING_ASSERT_OK_AND_ASSIGN(Crc32 old_crc, mapper->UpdateChecksum());
-    ICING_ASSERT_OK(mapper->Put("foo", 12345));
-    ICING_ASSERT_OK(mapper->PersistToDisk());
-    ICING_ASSERT_OK_AND_ASSIGN(Crc32 new_crc, mapper->UpdateChecksum());
-    ASSERT_THAT(old_crc, Not(Eq(new_crc)));
-  }
-
-  // Attempt to create the qualified id join index with corrupted
-  // doc_join_info_mapper. This should fail.
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                 param.pre_mapping_fbv,
-                                                 param.use_persistent_hash_map),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION,
-                       HasSubstr("Invalid storages crc")));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test,
-       InitializeExistingFilesWithCorruptedQualifiedIdStorageShouldFail) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriA"));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  {
-    // Corrupt qualified_id_storage manually.
-    std::string qualified_id_storage_path =
-        absl_ports::StrCat(working_path_, "/qualified_id_storage");
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<FileBackedVector<char>> qualified_id_storage,
-        FileBackedVector<char>::Create(
-            filesystem_, qualified_id_storage_path,
-            MemoryMappedFile::Strategy::READ_WRITE_AUTO_SYNC));
-    ICING_ASSERT_OK_AND_ASSIGN(Crc32 old_crc,
-                               qualified_id_storage->UpdateChecksum());
-    ICING_ASSERT_OK(qualified_id_storage->Append('a'));
-    ICING_ASSERT_OK(qualified_id_storage->Append('b'));
-    ICING_ASSERT_OK(qualified_id_storage->PersistToDisk());
-    ICING_ASSERT_OK_AND_ASSIGN(Crc32 new_crc,
-                               qualified_id_storage->UpdateChecksum());
-    ASSERT_THAT(old_crc, Not(Eq(new_crc)));
-  }
-
-  // Attempt to create the qualified id join index with corrupted
-  // qualified_id_storage. This should fail.
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                 param.pre_mapping_fbv,
-                                                 param.use_persistent_hash_map),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION,
-                       HasSubstr("Invalid storages crc")));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, InvalidPut) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  // Create new qualified id join index
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  DocumentJoinIdPair default_invalid;
-  EXPECT_THAT(
-      index->Put(default_invalid, /*ref_qualified_id_str=*/"namespace#uriA"),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, InvalidGet) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  // Create new qualified id join index
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  DocumentJoinIdPair default_invalid;
-  EXPECT_THAT(index->Get(default_invalid),
-              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, PutAndGet) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  DocumentJoinIdPair target_id_pair1(/*document_id=*/1,
-                                     /*joinable_property_id=*/20);
-  std::string_view ref_qualified_id_str_a = "namespace#uriA";
-
-  DocumentJoinIdPair target_id_pair2(/*document_id=*/3,
-                                     /*joinable_property_id=*/13);
-  std::string_view ref_qualified_id_str_b = "namespace#uriB";
-
-  DocumentJoinIdPair target_id_pair3(/*document_id=*/4,
-                                     /*joinable_property_id=*/4);
-  std::string_view ref_qualified_id_str_c = "namespace#uriC";
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-
-    EXPECT_THAT(index->Put(target_id_pair1, ref_qualified_id_str_a), IsOk());
-    EXPECT_THAT(index->Put(target_id_pair2, ref_qualified_id_str_b), IsOk());
-    EXPECT_THAT(index->Put(target_id_pair3, ref_qualified_id_str_c), IsOk());
-    EXPECT_THAT(index, Pointee(SizeIs(3)));
-
-    EXPECT_THAT(index->Get(target_id_pair1),
-                IsOkAndHolds(ref_qualified_id_str_a));
-    EXPECT_THAT(index->Get(target_id_pair2),
-                IsOkAndHolds(ref_qualified_id_str_b));
-    EXPECT_THAT(index->Get(target_id_pair3),
-                IsOkAndHolds(ref_qualified_id_str_c));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  // Verify we can get all of them after destructing and re-initializing.
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-  EXPECT_THAT(index, Pointee(SizeIs(3)));
-  EXPECT_THAT(index->Get(target_id_pair1),
-              IsOkAndHolds(ref_qualified_id_str_a));
-  EXPECT_THAT(index->Get(target_id_pair2),
-              IsOkAndHolds(ref_qualified_id_str_b));
-  EXPECT_THAT(index->Get(target_id_pair3),
-              IsOkAndHolds(ref_qualified_id_str_c));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, GetShouldReturnNotFoundErrorIfNotExist) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  DocumentJoinIdPair target_id_pair(/*document_id=*/1,
-                                    /*joinable_property_id=*/20);
-  std::string_view ref_qualified_id_str = "namespace#uriA";
-
-  // Create new qualified id join index
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  // Verify entry is not found in the beginning.
-  EXPECT_THAT(index->Get(target_id_pair),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-
-  ICING_ASSERT_OK(index->Put(target_id_pair, ref_qualified_id_str));
-  ASSERT_THAT(index->Get(target_id_pair), IsOkAndHolds(ref_qualified_id_str));
-
-  // Get another non-existing entry. This should get NOT_FOUND_ERROR.
-  DocumentJoinIdPair another_target_id_pair(/*document_id=*/2,
-                                            /*joinable_property_id=*/20);
-  EXPECT_THAT(index->Get(another_target_id_pair),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, SetLastAddedDocumentId) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
-
-  constexpr DocumentId kDocumentId = 100;
-  index->set_last_added_document_id(kDocumentId);
-  EXPECT_THAT(index->last_added_document_id(), Eq(kDocumentId));
-
-  constexpr DocumentId kNextDocumentId = 123;
-  index->set_last_added_document_id(kNextDocumentId);
-  EXPECT_THAT(index->last_added_document_id(), Eq(kNextDocumentId));
-}
-
-TEST_P(
-    QualifiedIdJoinIndexImplV1Test,
-    SetLastAddedDocumentIdShouldIgnoreNewDocumentIdNotGreaterThanTheCurrent) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  constexpr DocumentId kDocumentId = 123;
-  index->set_last_added_document_id(kDocumentId);
-  ASSERT_THAT(index->last_added_document_id(), Eq(kDocumentId));
-
-  constexpr DocumentId kNextDocumentId = 100;
-  ASSERT_THAT(kNextDocumentId, Lt(kDocumentId));
-  index->set_last_added_document_id(kNextDocumentId);
-  // last_added_document_id() should remain unchanged.
-  EXPECT_THAT(index->last_added_document_id(), Eq(kDocumentId));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, Optimize) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/3, /*joinable_property_id=*/10),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/5, /*joinable_property_id=*/3),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/8, /*joinable_property_id=*/9),
-      /*ref_qualified_id_str=*/"namespace#uriB"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/13, /*joinable_property_id=*/4),
-      /*ref_qualified_id_str=*/"namespace#uriC"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/21, /*joinable_property_id=*/12),
-      /*ref_qualified_id_str=*/"namespace#uriC"));
-  index->set_last_added_document_id(21);
-
-  ASSERT_THAT(index, Pointee(SizeIs(5)));
-
-  // Delete doc id = 5, 8, compress and keep the rest.
-  std::vector<DocumentId> document_id_old_to_new(22, kInvalidDocumentId);
-  document_id_old_to_new[3] = 0;
-  document_id_old_to_new[13] = 1;
-  document_id_old_to_new[21] = 2;
-
-  DocumentId new_last_added_document_id = 2;
-  EXPECT_THAT(
-      index->Optimize(document_id_old_to_new, /*namespace_id_old_to_new=*/{},
-                      new_last_added_document_id),
-      IsOk());
-  EXPECT_THAT(index, Pointee(SizeIs(3)));
-  EXPECT_THAT(index->last_added_document_id(), Eq(new_last_added_document_id));
-
-  // Verify Put and Get API still work normally after Optimize().
-  // (old_doc_id=3, joinable_property_id=10), which is now (doc_id=0,
-  // joinable_property_id=10), has referenced qualified id str =
-  // "namespace#uriA".
-  EXPECT_THAT(index->Get(DocumentJoinIdPair(/*document_id=*/0,
-                                            /*joinable_property_id=*/10)),
-              IsOkAndHolds("namespace#uriA"));
-
-  // (old_doc_id=5, joinable_property_id=3) and (old_doc_id=8,
-  // joinable_property_id=9) are now not found since we've deleted old_doc_id =
-  // 5, 8. It is not testable via Get() because there is no valid doc_id mapping
-  // for old_doc_id = 5, 8 and we cannot generate a valid DocumentJoinIdPair for
-  // it.
-
-  // (old_doc_id=13, joinable_property_id=4), which is now (doc_id=1,
-  // joinable_property_id=4), has referenced qualified id str =
-  // "namespace#uriC".
-  EXPECT_THAT(index->Get(DocumentJoinIdPair(/*document_id=*/1,
-                                            /*joinable_property_id=*/4)),
-              IsOkAndHolds("namespace#uriC"));
-
-  // (old_doc_id=21, joinable_property_id=12), which is now (doc_id=2,
-  // joinable_property_id=12), has referenced qualified id str =
-  // "namespace#uriC".
-  EXPECT_THAT(index->Get(DocumentJoinIdPair(/*document_id=*/2,
-                                            /*joinable_property_id=*/12)),
-              IsOkAndHolds("namespace#uriC"));
-
-  // Joinable index should be able to work normally after Optimize().
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/99, /*joinable_property_id=*/2),
-      /*ref_qualified_id_str=*/"namespace#uriD"));
-  index->set_last_added_document_id(99);
-
-  EXPECT_THAT(index, Pointee(SizeIs(4)));
-  EXPECT_THAT(index->last_added_document_id(), Eq(99));
-  EXPECT_THAT(index->Get(DocumentJoinIdPair(/*document_id=*/99,
-                                            /*joinable_property_id=*/2)),
-              IsOkAndHolds("namespace#uriD"));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, OptimizeOutOfRangeDocumentId) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/99, /*joinable_property_id=*/10),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  index->set_last_added_document_id(99);
-
-  // Create document_id_old_to_new with size = 1. Optimize should handle out of
-  // range DocumentId properly.
-  std::vector<DocumentId> document_id_old_to_new = {kInvalidDocumentId};
-
-  // There shouldn't be any error due to vector index.
-  EXPECT_THAT(
-      index->Optimize(document_id_old_to_new, /*namespace_id_old_to_new=*/{},
-                      /*new_last_added_document_id=*/kInvalidDocumentId),
-      IsOk());
-  EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
-
-  // Verify all data are discarded after Optimize().
-  EXPECT_THAT(index, Pointee(IsEmpty()));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, OptimizeDeleteAll) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/3, /*joinable_property_id=*/10),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/5, /*joinable_property_id=*/3),
-      /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/8, /*joinable_property_id=*/9),
-      /*ref_qualified_id_str=*/"namespace#uriB"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/13, /*joinable_property_id=*/4),
-      /*ref_qualified_id_str=*/"namespace#uriC"));
-  ICING_ASSERT_OK(index->Put(
-      DocumentJoinIdPair(/*document_id=*/21, /*joinable_property_id=*/12),
-      /*ref_qualified_id_str=*/"namespace#uriC"));
-  index->set_last_added_document_id(21);
-
-  // Delete all documents.
-  std::vector<DocumentId> document_id_old_to_new(22, kInvalidDocumentId);
-
-  EXPECT_THAT(
-      index->Optimize(document_id_old_to_new, /*namespace_id_old_to_new=*/{},
-                      /*new_last_added_document_id=*/kInvalidDocumentId),
-      IsOk());
-  EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
-
-  // Verify all data are discarded after Optimize().
-  EXPECT_THAT(index, Pointee(IsEmpty()));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, Clear) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  DocumentJoinIdPair target_id_pair1(/*document_id=*/1,
-                                     /*joinable_property_id=*/20);
-  DocumentJoinIdPair target_id_pair2(/*document_id=*/3,
-                                     /*joinable_property_id=*/5);
-  DocumentJoinIdPair target_id_pair3(/*document_id=*/6,
-                                     /*joinable_property_id=*/13);
-
-  // Create new qualified id join index
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-      QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                         param.pre_mapping_fbv,
-                                         param.use_persistent_hash_map));
-  ICING_ASSERT_OK(
-      index->Put(target_id_pair1, /*ref_qualified_id_str=*/"namespace#uriA"));
-  ICING_ASSERT_OK(
-      index->Put(target_id_pair2, /*ref_qualified_id_str=*/"namespace#uriB"));
-  ICING_ASSERT_OK(
-      index->Put(target_id_pair3, /*ref_qualified_id_str=*/"namespace#uriC"));
-  ASSERT_THAT(index, Pointee(SizeIs(3)));
-  index->set_last_added_document_id(6);
-  ASSERT_THAT(index->last_added_document_id(), Eq(6));
-
-  // After resetting, last_added_document_id should be set to
-  // kInvalidDocumentId, and the previous added data should be deleted.
-  EXPECT_THAT(index->Clear(), IsOk());
-  EXPECT_THAT(index, Pointee(IsEmpty()));
-  EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
-  EXPECT_THAT(index->Get(target_id_pair1),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-  EXPECT_THAT(index->Get(target_id_pair2),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-  EXPECT_THAT(index->Get(target_id_pair3),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-
-  // Join index should be able to work normally after Clear().
-  DocumentJoinIdPair target_id_pair4(/*document_id=*/2,
-                                     /*joinable_property_id=*/19);
-  ICING_ASSERT_OK(
-      index->Put(target_id_pair4, /*ref_qualified_id_str=*/"namespace#uriD"));
-  index->set_last_added_document_id(2);
-
-  EXPECT_THAT(index->last_added_document_id(), Eq(2));
-  EXPECT_THAT(index->Get(target_id_pair4), IsOkAndHolds("namespace#uriD"));
-
-  ICING_ASSERT_OK(index->PersistToDisk());
-  index.reset();
-
-  // Verify index after reconstructing.
-  ICING_ASSERT_OK_AND_ASSIGN(
-      index, QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                param.pre_mapping_fbv,
-                                                param.use_persistent_hash_map));
-  EXPECT_THAT(index->last_added_document_id(), Eq(2));
-  EXPECT_THAT(index->Get(target_id_pair1),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-  EXPECT_THAT(index->Get(target_id_pair2),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-  EXPECT_THAT(index->Get(target_id_pair3),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-  EXPECT_THAT(index->Get(target_id_pair4), IsOkAndHolds("namespace#uriD"));
-}
-
-TEST_P(QualifiedIdJoinIndexImplV1Test, SwitchKeyMapperTypeShouldReturnError) {
-  const QualifiedIdJoinIndexImplV1TestParam& param = GetParam();
-
-  {
-    // Create new qualified id join index
-    ICING_ASSERT_OK_AND_ASSIGN(
-        std::unique_ptr<QualifiedIdJoinIndexImplV1> index,
-        QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                           param.pre_mapping_fbv,
-                                           param.use_persistent_hash_map));
-    ICING_ASSERT_OK(index->Put(
-        DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/20),
-        /*ref_qualified_id_str=*/"namespace#uriA"));
-
-    ICING_ASSERT_OK(index->PersistToDisk());
-  }
-
-  bool switch_key_mapper_flag = !param.use_persistent_hash_map;
-  EXPECT_THAT(QualifiedIdJoinIndexImplV1::Create(filesystem_, working_path_,
-                                                 param.pre_mapping_fbv,
-                                                 switch_key_mapper_flag),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
-}
-
-INSTANTIATE_TEST_SUITE_P(
-    QualifiedIdJoinIndexImplV1Test, QualifiedIdJoinIndexImplV1Test,
-    testing::Values(QualifiedIdJoinIndexImplV1TestParam(
-                        /*pre_mapping_fbv_in=*/true,
-                        /*use_persistent_hash_map_in=*/true),
-                    QualifiedIdJoinIndexImplV1TestParam(
-                        /*pre_mapping_fbv_in=*/true,
-                        /*use_persistent_hash_map_in=*/false),
-                    QualifiedIdJoinIndexImplV1TestParam(
-                        /*pre_mapping_fbv_in=*/false,
-                        /*use_persistent_hash_map_in=*/true),
-                    QualifiedIdJoinIndexImplV1TestParam(
-                        /*pre_mapping_fbv_in=*/false,
-                        /*use_persistent_hash_map_in=*/false)));
-
-}  // namespace
-
-}  // namespace lib
-}  // namespace icing
diff --git a/icing/join/qualified-id-join-index-impl-v2.cc b/icing/join/qualified-id-join-index-impl-v2.cc
index 0402be2..fb5bd33 100644
--- a/icing/join/qualified-id-join-index-impl-v2.cc
+++ b/icing/join/qualified-id-join-index-impl-v2.cc
@@ -59,24 +59,6 @@ static constexpr int32_t kSchemaJoinableIdToPostingListMapperMaxNumEntries =
 static constexpr int32_t kSchemaJoinableIdToPostingListMapperAverageKVByteSize =
     10;
 
-inline DocumentId GetNewDocumentId(
-    const std::vector<DocumentId>& document_id_old_to_new,
-    DocumentId old_document_id) {
-  if (old_document_id < 0 || old_document_id >= document_id_old_to_new.size()) {
-    return kInvalidDocumentId;
-  }
-  return document_id_old_to_new[old_document_id];
-}
-
-inline NamespaceId GetNewNamespaceId(
-    const std::vector<NamespaceId>& namespace_id_old_to_new,
-    NamespaceId namespace_id) {
-  if (namespace_id < 0 || namespace_id >= namespace_id_old_to_new.size()) {
-    return kInvalidNamespaceId;
-  }
-  return namespace_id_old_to_new[namespace_id];
-}
-
 libtextclassifier3::StatusOr<PostingListIdentifier> GetPostingListIdentifier(
     const KeyMapper<PostingListIdentifier>&
         schema_joinable_id_to_posting_list_mapper,
@@ -553,12 +535,31 @@ libtextclassifier3::Status QualifiedIdJoinIndexImplV2::TransferIndex(
                            old_pl_accessor->GetNextDataBatch());
     while (!batch_old_join_data.empty()) {
       for (const JoinDataType& old_join_data : batch_old_join_data) {
-        DocumentId new_document_id = GetNewDocumentId(
-            document_id_old_to_new, old_join_data.document_id());
-        NamespaceId new_ref_namespace_id = GetNewNamespaceId(
-            namespace_id_old_to_new, old_join_data.join_info().namespace_id());
+        DocumentId old_document_id = old_join_data.document_id();
+        if (old_document_id < 0 ||
+            old_document_id >= document_id_old_to_new.size()) {
+          // If it happens, then the posting list is corrupted. Return error
+          // and let the caller rebuild everything.
+          return absl_ports::InternalError(
+              "Qualified id join index data document id is out of range. The "
+              "index may have been corrupted.");
+        }
+
+        NamespaceId old_ref_namespace_id =
+            old_join_data.join_info().namespace_id();
+        if (old_ref_namespace_id < 0 ||
+            old_ref_namespace_id >= namespace_id_old_to_new.size()) {
+          // If it happens, then the posting list is corrupted. Return error
+          // and let the caller rebuild everything.
+          return absl_ports::InternalError(
+              "Qualified id join index data ref namespace id is out of range. "
+              "The index may have been corrupted.");
+        }
 
         // Transfer if the document and namespace are not deleted or outdated.
+        DocumentId new_document_id = document_id_old_to_new[old_document_id];
+        NamespaceId new_ref_namespace_id =
+            namespace_id_old_to_new[old_ref_namespace_id];
         if (new_document_id != kInvalidDocumentId &&
             new_ref_namespace_id != kInvalidNamespaceId) {
           // We can reuse the fingerprint from old_join_data, since document uri
diff --git a/icing/join/qualified-id-join-index-impl-v2.h b/icing/join/qualified-id-join-index-impl-v2.h
index 5b402cb..379f0b8 100644
--- a/icing/join/qualified-id-join-index-impl-v2.h
+++ b/icing/join/qualified-id-join-index-impl-v2.h
@@ -150,19 +150,6 @@ class QualifiedIdJoinIndexImplV2 : public QualifiedIdJoinIndex {
 
   ~QualifiedIdJoinIndexImplV2() override;
 
-  // v1 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::Status Put(
-      const DocumentJoinIdPair& document_join_id_pair,
-      std::string_view ref_qualified_id_str) override {
-    return absl_ports::UnimplementedError("This API is not supported in V2");
-  }
-
-  // v1 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::StatusOr<std::string_view> Get(
-      const DocumentJoinIdPair& document_join_id_pair) const override {
-    return absl_ports::UnimplementedError("This API is not supported in V2");
-  }
-
   // v3 only API. Returns UNIMPLEMENTED_ERROR.
   libtextclassifier3::Status Put(
       const DocumentJoinIdPair& child_document_join_id_pair,
diff --git a/icing/join/qualified-id-join-index-impl-v2_test.cc b/icing/join/qualified-id-join-index-impl-v2_test.cc
index fdfa8bc..01c972e 100644
--- a/icing/join/qualified-id-join-index-impl-v2_test.cc
+++ b/icing/join/qualified-id-join-index-impl-v2_test.cc
@@ -1027,22 +1027,17 @@ TEST_F(QualifiedIdJoinIndexImplV2Test, OptimizeOutOfRangeDocumentId) {
       IsOk());
   index->set_last_added_document_id(99);
 
-  // Create document_id_old_to_new with size = 1. Optimize should handle out of
-  // range DocumentId properly.
+  // Create document_id_old_to_new with size = 1. Optimize should return
+  // internal error for out of range document id.
   std::vector<DocumentId> document_id_old_to_new = {kInvalidDocumentId};
   std::vector<NamespaceId> namespace_id_old_to_new = {0, 1};
 
-  // There shouldn't be any error due to vector index.
   EXPECT_THAT(
       index->Optimize(document_id_old_to_new, namespace_id_old_to_new,
                       /*new_last_added_document_id=*/kInvalidDocumentId),
-      IsOk());
-  EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
-
-  // Verify all data are discarded after Optimize().
-  EXPECT_THAT(index, Pointee(IsEmpty()));
-  EXPECT_THAT(GetJoinData(*index, schema_type_id, joinable_property_id),
-              IsOkAndHolds(IsEmpty()));
+      StatusIs(libtextclassifier3::StatusCode::INTERNAL,
+               HasSubstr("Qualified id join index data document id is out of "
+                         "range. The index may have been corrupted.")));
 }
 
 TEST_F(QualifiedIdJoinIndexImplV2Test, OptimizeDeleteAllDocuments) {
@@ -1302,22 +1297,17 @@ TEST_F(QualifiedIdJoinIndexImplV2Test, OptimizeOutOfRangeNamespaceId) {
       IsOk());
   index->set_last_added_document_id(0);
 
-  // Create namespace_id_old_to_new with size = 1. Optimize should handle out of
-  // range NamespaceId properly.
+  // Create namespace_id_old_to_new with size = 1. Optimize should return
+  // internal error for out of range ref namespace id.
   std::vector<DocumentId> document_id_old_to_new = {0};
   std::vector<NamespaceId> namespace_id_old_to_new = {kInvalidNamespaceId};
 
-  // There shouldn't be any error due to vector index.
   EXPECT_THAT(
       index->Optimize(document_id_old_to_new, namespace_id_old_to_new,
                       /*new_last_added_document_id=*/kInvalidDocumentId),
-      IsOk());
-  EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
-
-  // Verify all data are discarded after Optimize().
-  EXPECT_THAT(index, Pointee(IsEmpty()));
-  EXPECT_THAT(GetJoinData(*index, schema_type_id, joinable_property_id),
-              IsOkAndHolds(IsEmpty()));
+      StatusIs(libtextclassifier3::StatusCode::INTERNAL,
+               HasSubstr("Qualified id join index data ref namespace id is out "
+                         "of range. The index may have been corrupted.")));
 }
 
 TEST_F(QualifiedIdJoinIndexImplV2Test, OptimizeDeleteAllNamespaces) {
diff --git a/icing/join/qualified-id-join-index-impl-v3.cc b/icing/join/qualified-id-join-index-impl-v3.cc
index bab844d..bff564e 100644
--- a/icing/join/qualified-id-join-index-impl-v3.cc
+++ b/icing/join/qualified-id-join-index-impl-v3.cc
@@ -205,8 +205,18 @@ libtextclassifier3::Status QualifiedIdJoinIndexImplV3::MigrateParent(
     return libtextclassifier3::Status::OK;
   }
 
-  ICING_RETURN_IF_ERROR(
+  ICING_ASSIGN_OR_RETURN(
+      bool is_extended,
       ExtendParentDocumentIdToChildArrayInfoIfNecessary(new_document_id));
+  if (is_extended) {
+    // If parent_document_id_to_child_array_info_ is extended, then it is
+    // possible that file size is extended and remap happens. We need to refresh
+    // mutable_old_array_info.
+    ICING_ASSIGN_OR_RETURN(
+        mutable_old_array_info,
+        parent_document_id_to_child_array_info_->GetMutable(old_document_id));
+  }
+
   ICING_RETURN_IF_ERROR(parent_document_id_to_child_array_info_->Set(
       new_document_id, mutable_old_array_info.Get()));
   mutable_old_array_info.Get() = kInvalidArrayInfo;
@@ -497,9 +507,10 @@ QualifiedIdJoinIndexImplV3::AppendChildDocumentJoinIdPairsForParent(
   return libtextclassifier3::Status::OK;
 }
 
-libtextclassifier3::Status
+libtextclassifier3::StatusOr<bool>
 QualifiedIdJoinIndexImplV3::ExtendParentDocumentIdToChildArrayInfoIfNecessary(
     DocumentId parent_document_id) {
+  bool is_extended = false;
   if (parent_document_id >=
       parent_document_id_to_child_array_info_->num_elements()) {
     int32_t num_to_extend =
@@ -509,8 +520,9 @@ QualifiedIdJoinIndexImplV3::ExtendParentDocumentIdToChildArrayInfoIfNecessary(
         FileBackedVector<ArrayInfo>::MutableArrayView mutable_arr,
         parent_document_id_to_child_array_info_->Allocate(num_to_extend));
     mutable_arr.Fill(/*idx=*/0, /*len=*/num_to_extend, kInvalidArrayInfo);
+    is_extended = true;
   }
-  return libtextclassifier3::Status::OK;
+  return is_extended;
 }
 
 libtextclassifier3::StatusOr<
@@ -679,8 +691,16 @@ libtextclassifier3::Status QualifiedIdJoinIndexImplV3::TransferIndex(
        old_parent_doc_id <
        parent_document_id_to_child_array_info_->num_elements();
        ++old_parent_doc_id) {
-    if (old_parent_doc_id >= document_id_old_to_new.size() ||
-        document_id_old_to_new[old_parent_doc_id] == kInvalidDocumentId) {
+    if (old_parent_doc_id < 0 ||
+        old_parent_doc_id >= document_id_old_to_new.size()) {
+      // If it happens, then the data is corrupted. Return error and let the
+      // caller rebuild everything.
+      return absl_ports::InternalError(
+          "Qualified id join index data parent document id is out of range. "
+          "The index may have been corrupted.");
+    }
+
+    if (document_id_old_to_new[old_parent_doc_id] == kInvalidDocumentId) {
       // Skip if the old parent document id is invalid after optimization.
       continue;
     }
@@ -700,11 +720,16 @@ libtextclassifier3::Status QualifiedIdJoinIndexImplV3::TransferIndex(
     new_child_doc_join_id_pairs.reserve(array_info->length);
     for (int i = 0; i < array_info->used_length; ++i) {
       DocumentId old_child_doc_id = ptr[i].document_id();
-      DocumentId new_child_doc_id =
-          old_child_doc_id >= 0 &&
-                  old_child_doc_id < document_id_old_to_new.size()
-              ? document_id_old_to_new[old_child_doc_id]
-              : kInvalidDocumentId;
+      if (old_child_doc_id < 0 ||
+          old_child_doc_id >= document_id_old_to_new.size()) {
+        // If it happens, then the data is corrupted. Return error and let the
+        // caller rebuild everything.
+        return absl_ports::InternalError(
+            "Qualified id join index data child document id is out of range. "
+            "The index may have been corrupted.");
+      }
+
+      DocumentId new_child_doc_id = document_id_old_to_new[old_child_doc_id];
       if (new_child_doc_id == kInvalidDocumentId) {
         continue;
       }
diff --git a/icing/join/qualified-id-join-index-impl-v3.h b/icing/join/qualified-id-join-index-impl-v3.h
index 2f5a8a5..30483df 100644
--- a/icing/join/qualified-id-join-index-impl-v3.h
+++ b/icing/join/qualified-id-join-index-impl-v3.h
@@ -176,19 +176,6 @@ class QualifiedIdJoinIndexImplV3 : public QualifiedIdJoinIndex {
   libtextclassifier3::Status MigrateParent(DocumentId old_document_id,
                                            DocumentId new_document_id) override;
 
-  // v1 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::Status Put(
-      const DocumentJoinIdPair& document_join_id_pair,
-      std::string_view ref_qualified_id_str) override {
-    return absl_ports::UnimplementedError("This API is not supported in V3");
-  }
-
-  // v1 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::StatusOr<std::string_view> Get(
-      const DocumentJoinIdPair& document_join_id_pair) const override {
-    return absl_ports::UnimplementedError("This API is not supported in V3");
-  }
-
   // v2 only API. Returns UNIMPLEMENTED_ERROR.
   libtextclassifier3::Status Put(
       SchemaTypeId schema_type_id, JoinablePropertyId joinable_property_id,
@@ -290,9 +277,12 @@ class QualifiedIdJoinIndexImplV3 : public QualifiedIdJoinIndex {
   // to the new parent document id.
   //
   // Returns:
-  //   - OK on success
+  //   - On success, true if extended, and the caller should invalidate or
+  //     refresh existing objects using related mmap addresses due to potential
+  //     remapping. False otherwise
   //   - Any FileBackedVector errors
-  libtextclassifier3::Status ExtendParentDocumentIdToChildArrayInfoIfNecessary(
+  libtextclassifier3::StatusOr<bool>
+  ExtendParentDocumentIdToChildArrayInfoIfNecessary(
       DocumentId parent_document_id);
 
   // Gets the DocumentJoinIdPair mutable array and extends it if necessary to
diff --git a/icing/join/qualified-id-join-index-impl-v3_test.cc b/icing/join/qualified-id-join-index-impl-v3_test.cc
index 529100b..114cab7 100644
--- a/icing/join/qualified-id-join-index-impl-v3_test.cc
+++ b/icing/join/qualified-id-join-index-impl-v3_test.cc
@@ -44,11 +44,13 @@ namespace {
 
 using ::testing::ElementsAre;
 using ::testing::Eq;
+using ::testing::Gt;
 using ::testing::HasSubstr;
 using ::testing::IsEmpty;
 using ::testing::IsFalse;
 using ::testing::IsTrue;
 using ::testing::Lt;
+using ::testing::Ne;
 using ::testing::Not;
 using ::testing::Pointee;
 using ::testing::SizeIs;
@@ -888,6 +890,90 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
 }
 
+TEST_F(QualifiedIdJoinIndexImplV3Test,
+       PutLargeParentShouldHandleAddressCorrectlyForRemap) {
+  // Create new qualified id join index
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
+                             QualifiedIdJoinIndexImplV3::Create(
+                                 filesystem_, working_path_, *feature_flags_));
+
+  const std::string array_working_path = absl_ports::StrCat(
+      working_path_, "/parent_document_id_to_child_array_info");
+
+  // Add a child for parent doc id 1 to the index.
+  DocumentId parent_doc_id1 = 1;
+  DocumentJoinIdPair child_join_id_pair1(/*document_id=*/100,
+                                         /*joinable_property_id=*/0);
+  EXPECT_THAT(
+      index->Put(
+          child_join_id_pair1,
+          /*parent_document_ids=*/std::vector<DocumentId>{parent_doc_id1}),
+      IsOk());
+  int64_t file_size_before =
+      filesystem_.GetFileSize(array_working_path.c_str());
+  ASSERT_THAT(file_size_before, Ne(Filesystem::kBadFileSize));
+
+  // Add another child with large parent document id to the index. This will
+  // cause parent_document_id_to_child_array_info being extended and remap. The
+  // test verifies that addresses after remap are handled correctly without
+  // crashing.
+  DocumentId parent_doc_id2 = 30000;
+  DocumentJoinIdPair child_join_id_pair2(/*document_id=*/101,
+                                         /*joinable_property_id=*/0);
+  EXPECT_THAT(
+      index->Put(
+          child_join_id_pair2,
+          /*parent_document_ids=*/std::vector<DocumentId>{parent_doc_id2}),
+      IsOk());
+  int64_t file_size_after = filesystem_.GetFileSize(array_working_path.c_str());
+  ASSERT_THAT(file_size_after, Ne(Filesystem::kBadFileSize));
+
+  // Sanity check that the file size is extended and remap happens.
+  EXPECT_THAT(file_size_after, Gt(file_size_before));
+}
+
+TEST_F(QualifiedIdJoinIndexImplV3Test,
+       PutLargeNumberOfDataShouldHandleRemapAddressCorrectly) {
+  // Create new qualified id join index
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
+                             QualifiedIdJoinIndexImplV3::Create(
+                                 filesystem_, working_path_, *feature_flags_));
+
+  DocumentId parent_doc_id = 0;
+  DocumentId child_doc_id = 30000;
+
+  // For the first grow of FBV, the file size is 65536. 12 bytes will be used
+  // for the header, so we can fit (65536 - 12) / 4 = 16378 children.
+  //
+  // Add 16378 unique parent and child pairs, so we allocate 16378
+  // DocumentJoinIdPair (extensible) arrays with size 1 for all parents, and
+  // FBV is full now.
+  constexpr int kNumChildrenToFillFbv = 16378;
+  for (int i = 0; i < kNumChildrenToFillFbv; ++i) {
+    DocumentJoinIdPair child_join_id_pair(child_doc_id++,
+                                          /*joinable_property_id=*/20);
+    EXPECT_THAT(
+        index->Put(
+            child_join_id_pair,
+            /*parent_document_ids=*/std::vector<DocumentId>{parent_doc_id++}),
+        IsOk());
+  }
+
+  // Put a child for parent doc_id=0 again. This will cause:
+  // - FBV file size is extended to 131072, and remap happens.
+  // - Parent 0's array is reallocated and extended to size 2.
+  //
+  // The test verifies that object related to mmap address is refreshed
+  // correctly after remap.
+  DocumentJoinIdPair additional_child_join_id_pair(child_doc_id++,
+                                                   /*joinable_property_id=*/20);
+  EXPECT_THAT(index->Put(additional_child_join_id_pair,
+                         /*parent_document_ids=*/std::vector<DocumentId>{0}),
+              IsOk());
+
+  EXPECT_THAT(index, Pointee(SizeIs(kNumChildrenToFillFbv + 1)));
+}
+
 TEST_F(QualifiedIdJoinIndexImplV3Test, PutShouldSkipInvalidParentDocumentId) {
   // Create new qualified id join index
   ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
@@ -998,7 +1084,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, MigrateParent) {
   DocumentId parent_doc_id1 = 1;
   DocumentId parent_doc_id2 = 1024;
 
-  // Add 6 children with their parents to the index.
+  // Add 2 children with their parents to the index.
   DocumentJoinIdPair child_join_id_pair1(/*document_id=*/100,
                                          /*joinable_property_id=*/0);
   DocumentJoinIdPair child_join_id_pair2(/*document_id=*/101,
@@ -1025,6 +1111,57 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, MigrateParent) {
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
 }
 
+TEST_F(QualifiedIdJoinIndexImplV3Test,
+       MigrateParentToLargeIdShouldHandleAddressCorrectlyForRemap) {
+  // Create new qualified id join index
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
+                             QualifiedIdJoinIndexImplV3::Create(
+                                 filesystem_, working_path_, *feature_flags_));
+
+  const std::string array_working_path = absl_ports::StrCat(
+      working_path_, "/parent_document_id_to_child_array_info");
+
+  DocumentId parent_doc_id1 = 1;
+  DocumentId parent_doc_id2 = 30000;
+
+  // Add 2 children for parent doc id 1 to the index.
+  DocumentJoinIdPair child_join_id_pair1(/*document_id=*/100,
+                                         /*joinable_property_id=*/0);
+  DocumentJoinIdPair child_join_id_pair2(/*document_id=*/101,
+                                         /*joinable_property_id=*/0);
+  ICING_ASSERT_OK(index->Put(
+      child_join_id_pair1,
+      /*parent_document_ids=*/std::vector<DocumentId>{parent_doc_id1}));
+  ICING_ASSERT_OK(index->Put(
+      child_join_id_pair2,
+      /*parent_document_ids=*/std::vector<DocumentId>{parent_doc_id1}));
+  int64_t file_size_before =
+      filesystem_.GetFileSize(array_working_path.c_str());
+  ASSERT_THAT(file_size_before, Ne(Filesystem::kBadFileSize));
+
+  // Sanity check.
+  ASSERT_THAT(index, Pointee(SizeIs(2)));
+  ASSERT_THAT(
+      index->Get(parent_doc_id1),
+      IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
+  ASSERT_THAT(index->Get(parent_doc_id2), IsOkAndHolds(IsEmpty()));
+
+  // Migrate parent document id 1 to 30000. This will
+  // cause parent_document_id_to_child_array_info being extended and remap. The
+  // test verifies that addresses after remap are handled correctly without
+  // crashing.
+  EXPECT_THAT(index->MigrateParent(parent_doc_id1, parent_doc_id2), IsOk());
+  EXPECT_THAT(index->Get(parent_doc_id1), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(
+      index->Get(parent_doc_id2),
+      IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
+  int64_t file_size_after = filesystem_.GetFileSize(array_working_path.c_str());
+  ASSERT_THAT(file_size_after, Ne(Filesystem::kBadFileSize));
+
+  // Sanity check that the file size is extended and remap happens.
+  EXPECT_THAT(file_size_after, Gt(file_size_before));
+}
+
 TEST_F(QualifiedIdJoinIndexImplV3Test, SetLastAddedDocumentId) {
   ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
                              QualifiedIdJoinIndexImplV3::Create(
@@ -1070,7 +1207,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Optimize) {
   // - Document 2: 102, 103, 105
   // - Document 3: 101, 106
   // - Document 4: 103
-  // Add 6 children with their parents to the index.
+  // Add 7 children with their parents to the index.
   DocumentJoinIdPair child_join_id_pair1(/*document_id=*/101,
                                          /*joinable_property_id=*/0);
   DocumentJoinIdPair child_join_id_pair2(/*document_id=*/102,
@@ -1188,7 +1325,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Optimize) {
               IsOkAndHolds(ElementsAre(another_child_join_id_pair)));
 }
 
-TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeOutOfRangeDocumentId) {
+TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeOutOfRangeParentDocumentId) {
   // Create new qualified id join index
   ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
                              QualifiedIdJoinIndexImplV3::Create(
@@ -1218,11 +1355,12 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeOutOfRangeDocumentId) {
   index->set_last_added_document_id(120);
   ASSERT_THAT(index->last_added_document_id(), Eq(120));
 
-  // Create document_id_old_to_new with size = 107 (from index 0 to 106), which
-  // makes parent document 120 and child document 108 out of range.
+  // Create document_id_old_to_new with size = 109 (from index 0 to 108), which
+  // makes parent document 120 out of range.
   //
-  // Optimize should handle out of range DocumentId properly without crashing.
-  std::vector<DocumentId> document_id_old_to_new(107, kInvalidDocumentId);
+  // Optimize should return internal error for out of range parent document id
+  // without crashing.
+  std::vector<DocumentId> document_id_old_to_new(109, kInvalidDocumentId);
   document_id_old_to_new[1] = 0;
   document_id_old_to_new[101] = 11;
   document_id_old_to_new[106] = 12;
@@ -1233,18 +1371,60 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeOutOfRangeDocumentId) {
   EXPECT_THAT(
       index->Optimize(document_id_old_to_new, /*namespace_id_old_to_new=*/{},
                       new_last_added_document_id),
-      IsOk());
-  EXPECT_THAT(index, Pointee(SizeIs(2)));
-  EXPECT_THAT(index->last_added_document_id(), Eq(new_last_added_document_id));
+      StatusIs(libtextclassifier3::StatusCode::INTERNAL,
+               HasSubstr("Qualified id join index data parent document id is "
+                         "out of range. The index may have been corrupted.")));
+}
 
-  // Verify document 0 (originally document 1)
-  // - Child doc 101, 106 become 11, 12.
-  // - Child doc 108 is out of range, so it should be deleted.
+TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeOutOfRangeChildDocumentId) {
+  // Create new qualified id join index
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
+                             QualifiedIdJoinIndexImplV3::Create(
+                                 filesystem_, working_path_, *feature_flags_));
+
+  // Create 2 parent and 3 child documents (with N to N joins):
+  // - Document 1: 101, 106, 108
+  // - Document 120: 101
+  // Add 3 children with their parents to the index.
+  DocumentJoinIdPair child_join_id_pair1(/*document_id=*/101,
+                                         /*joinable_property_id=*/0);
+  DocumentJoinIdPair child_join_id_pair2(/*document_id=*/106,
+                                         /*joinable_property_id=*/0);
+  DocumentJoinIdPair child_join_id_pair3(/*document_id=*/108,
+                                         /*joinable_property_id=*/0);
+  ICING_ASSERT_OK(
+      index->Put(child_join_id_pair1,
+                 /*parent_document_ids=*/std::vector<DocumentId>{1, 2}));
+  ICING_ASSERT_OK(
+      index->Put(child_join_id_pair2,
+                 /*parent_document_ids=*/std::vector<DocumentId>{1}));
+  ICING_ASSERT_OK(
+      index->Put(child_join_id_pair3,
+                 /*parent_document_ids=*/std::vector<DocumentId>{1}));
+
+  ASSERT_THAT(index, Pointee(SizeIs(4)));
+  index->set_last_added_document_id(120);
+  ASSERT_THAT(index->last_added_document_id(), Eq(120));
+
+  // Create document_id_old_to_new with size = 107 (from index 0 to 106), which
+  // makes child document 108 out of range.
+  //
+  // Optimize should return internal error for out of range child document id
+  // without crashing.
+  std::vector<DocumentId> document_id_old_to_new(107, kInvalidDocumentId);
+  document_id_old_to_new[1] = 0;
+  document_id_old_to_new[101] = 11;
+  document_id_old_to_new[106] = 12;
+
+  // Note: namespace_id_old_to_new is not used in
+  // QualifiedIdJoinIndexImplV3::Optimize.
+  DocumentId new_last_added_document_id = 12;
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/0),
-      IsOkAndHolds(ElementsAre(
-          DocumentJoinIdPair(/*document_id=*/11, /*joinable_property_id=*/0),
-          DocumentJoinIdPair(/*document_id=*/12, /*joinable_property_id=*/0))));
+      index->Optimize(document_id_old_to_new, /*namespace_id_old_to_new=*/{},
+                      new_last_added_document_id),
+      StatusIs(libtextclassifier3::StatusCode::INTERNAL,
+               HasSubstr("Qualified id join index data child document id is "
+                         "out of range. The index may have been corrupted.")));
 }
 
 TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeDeleteAllDocuments) {
@@ -1258,7 +1438,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeDeleteAllDocuments) {
   // - Document 2: 102, 103, 105
   // - Document 3: 101, 106
   // - Document 4: 103
-  // Add 6 children with their parents to the index.
+  // Add 7 children with their parents to the index.
   DocumentJoinIdPair child_join_id_pair1(/*document_id=*/101,
                                          /*joinable_property_id=*/0);
   DocumentJoinIdPair child_join_id_pair2(/*document_id=*/102,
@@ -1323,7 +1503,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Clear) {
                              QualifiedIdJoinIndexImplV3::Create(
                                  filesystem_, working_path_, *feature_flags_));
 
-  // Add 6 children with their parents to the index.
+  // Add 4 children with their parents to the index.
   DocumentJoinIdPair child_join_id_pair1(/*document_id=*/100,
                                          /*joinable_property_id=*/20);
   DocumentJoinIdPair child_join_id_pair2(/*document_id=*/101,
diff --git a/icing/join/qualified-id-join-index.h b/icing/join/qualified-id-join-index.h
index 4972c5e..55427c1 100644
--- a/icing/join/qualified-id-join-index.h
+++ b/icing/join/qualified-id-join-index.h
@@ -52,7 +52,7 @@ class QualifiedIdJoinIndex : public PersistentStorage {
         const = 0;
   };
 
-  enum class Version { kV1, kV2, kV3 };
+  enum class Version { kV2, kV3 };
 
   static constexpr WorkingPathType kWorkingPathType =
       WorkingPathType::kDirectory;
@@ -70,20 +70,6 @@ class QualifiedIdJoinIndex : public PersistentStorage {
 
   virtual ~QualifiedIdJoinIndex() override = default;
 
-  // (v1 only) Puts a new data into index: DocumentJoinIdPair (DocumentId,
-  // JoinablePropertyId) references to ref_qualified_id_str (the identifier of
-  // another document).
-  //
-  // REQUIRES: ref_qualified_id_str contains no '\0'.
-  //
-  // Returns:
-  //   - OK on success
-  //   - INVALID_ARGUMENT_ERROR if doc_join_info is invalid
-  //   - Any KeyMapper errors
-  virtual libtextclassifier3::Status Put(
-      const DocumentJoinIdPair& document_join_id_pair,
-      std::string_view ref_qualified_id_str) = 0;
-
   // (v2 only) Puts a list of referenced NamespaceIdFingerprint into index,
   // given the DocumentId, SchemaTypeId and JoinablePropertyId.
   //
@@ -109,18 +95,6 @@ class QualifiedIdJoinIndex : public PersistentStorage {
       const DocumentJoinIdPair& child_document_join_id_pair,
       std::vector<DocumentId>&& parent_document_ids) = 0;
 
-  // (v1 only) Gets the referenced document's qualified id string by
-  // DocumentJoinIdPair.
-  //
-  // Returns:
-  //   - A qualified id string referenced by the given DocumentJoinIdPair
-  //     (DocumentId, JoinablePropertyId) on success
-  //   - INVALID_ARGUMENT_ERROR if doc_join_info is invalid
-  //   - NOT_FOUND_ERROR if doc_join_info doesn't exist
-  //   - Any KeyMapper errors
-  virtual libtextclassifier3::StatusOr<std::string_view> Get(
-      const DocumentJoinIdPair& document_join_id_pair) const = 0;
-
   // (v2 only) Returns a JoinDataIterator for iterating through all join data of
   // the specified (schema_type_id, joinable_property_id).
   //
diff --git a/icing/join/qualified-id-join-indexing-handler-v1_test.cc b/icing/join/qualified-id-join-indexing-handler-v1_test.cc
deleted file mode 100644
index e1e3881..0000000
--- a/icing/join/qualified-id-join-indexing-handler-v1_test.cc
+++ /dev/null
@@ -1,573 +0,0 @@
-// Copyright (C) 2023 Google LLC
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//      http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-#include <memory>
-#include <string>
-#include <string_view>
-#include <utility>
-
-#include "icing/text_classifier/lib3/utils/base/status.h"
-#include "gmock/gmock.h"
-#include "gtest/gtest.h"
-#include "icing/document-builder.h"
-#include "icing/feature-flags.h"
-#include "icing/file/filesystem.h"
-#include "icing/file/portable-file-backed-proto-log.h"
-#include "icing/join/document-join-id-pair.h"
-#include "icing/join/qualified-id-join-index-impl-v1.h"
-#include "icing/join/qualified-id-join-index.h"
-#include "icing/join/qualified-id-join-indexing-handler.h"
-#include "icing/join/qualified-id.h"
-#include "icing/portable/platform.h"
-#include "icing/proto/document.pb.h"
-#include "icing/proto/schema.pb.h"
-#include "icing/schema-builder.h"
-#include "icing/schema/joinable-property.h"
-#include "icing/schema/schema-store.h"
-#include "icing/store/document-id.h"
-#include "icing/store/document-store.h"
-#include "icing/testing/common-matchers.h"
-#include "icing/testing/fake-clock.h"
-#include "icing/testing/test-data.h"
-#include "icing/testing/test-feature-flags.h"
-#include "icing/testing/tmp-directory.h"
-#include "icing/tokenization/language-segmenter-factory.h"
-#include "icing/tokenization/language-segmenter.h"
-#include "icing/util/icu-data-file-helper.h"
-#include "icing/util/tokenized-document.h"
-#include "unicode/uloc.h"
-
-namespace icing {
-namespace lib {
-
-namespace {
-
-using ::testing::Eq;
-using ::testing::IsEmpty;
-using ::testing::IsTrue;
-
-// Schema type for referenced documents: ReferencedType
-static constexpr std::string_view kReferencedType = "ReferencedType";
-static constexpr std::string_view kPropertyName = "name";
-
-// Joinable properties and joinable property id. Joinable property id is
-// determined by the lexicographical order of joinable property path.
-// Schema type with joinable property: FakeType
-static constexpr std::string_view kFakeType = "FakeType";
-static constexpr std::string_view kPropertyQualifiedId = "qualifiedId";
-
-static constexpr JoinablePropertyId kQualifiedIdJoinablePropertyId = 0;
-
-// Schema type with nested joinable properties: NestedType
-static constexpr std::string_view kNestedType = "NestedType";
-static constexpr std::string_view kPropertyNestedDoc = "nested";
-static constexpr std::string_view kPropertyQualifiedId2 = "qualifiedId2";
-
-static constexpr JoinablePropertyId kNestedQualifiedIdJoinablePropertyId = 0;
-static constexpr JoinablePropertyId kQualifiedId2JoinablePropertyId = 1;
-
-static constexpr DocumentId kDefaultDocumentId = 3;
-
-// TODO(b/275121148): remove this test after deprecating
-// QualifiedIdJoinIndexImplV1.
-class QualifiedIdJoinIndexingHandlerV1Test : public ::testing::Test {
- protected:
-  void SetUp() override {
-    feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
-    if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
-      ICING_ASSERT_OK(
-          // File generated via icu_data_file rule in //icing/BUILD.
-          icu_data_file_helper::SetUpIcuDataFile(
-              GetTestFilePath("icing/icu.dat")));
-    }
-
-    base_dir_ = GetTestTempDir() + "/icing_test";
-    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(base_dir_.c_str()),
-                IsTrue());
-
-    qualified_id_join_index_dir_ = base_dir_ + "/qualified_id_join_index";
-    schema_store_dir_ = base_dir_ + "/schema_store";
-    doc_store_dir_ = base_dir_ + "/doc_store";
-
-    ICING_ASSERT_OK_AND_ASSIGN(qualified_id_join_index_,
-                               QualifiedIdJoinIndexImplV1::Create(
-                                   filesystem_, qualified_id_join_index_dir_,
-                                   /*pre_mapping_fbv=*/false,
-                                   /*use_persistent_hash_map=*/false));
-
-    language_segmenter_factory::SegmenterOptions segmenter_options(ULOC_US);
-    ICING_ASSERT_OK_AND_ASSIGN(
-        lang_segmenter_,
-        language_segmenter_factory::Create(std::move(segmenter_options)));
-
-    ASSERT_THAT(
-        filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str()),
-        IsTrue());
-    ICING_ASSERT_OK_AND_ASSIGN(
-        schema_store_, SchemaStore::Create(&filesystem_, schema_store_dir_,
-                                           &fake_clock_, feature_flags_.get()));
-    SchemaProto schema =
-        SchemaBuilder()
-            .AddType(
-                SchemaTypeConfigBuilder()
-                    .SetType(kReferencedType)
-                    .AddProperty(PropertyConfigBuilder()
-                                     .SetName(kPropertyName)
-                                     .SetDataTypeString(TERM_MATCH_EXACT,
-                                                        TOKENIZER_PLAIN)
-                                     .SetCardinality(CARDINALITY_OPTIONAL)))
-            .AddType(SchemaTypeConfigBuilder().SetType(kFakeType).AddProperty(
-                PropertyConfigBuilder()
-                    .SetName(kPropertyQualifiedId)
-                    .SetDataTypeJoinableString(JOINABLE_VALUE_TYPE_QUALIFIED_ID)
-                    .SetCardinality(CARDINALITY_OPTIONAL)))
-            .AddType(
-                SchemaTypeConfigBuilder()
-                    .SetType(kNestedType)
-                    .AddProperty(
-                        PropertyConfigBuilder()
-                            .SetName(kPropertyNestedDoc)
-                            .SetDataTypeDocument(
-                                kFakeType, /*index_nested_properties=*/true)
-                            .SetCardinality(CARDINALITY_OPTIONAL))
-                    .AddProperty(PropertyConfigBuilder()
-                                     .SetName(kPropertyQualifiedId2)
-                                     .SetDataTypeJoinableString(
-                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID)
-                                     .SetCardinality(CARDINALITY_OPTIONAL)))
-            .Build();
-    ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
-
-    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
-                IsTrue());
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
-    doc_store_ = std::move(create_result.document_store);
-  }
-
-  void TearDown() override {
-    doc_store_.reset();
-    schema_store_.reset();
-    lang_segmenter_.reset();
-    qualified_id_join_index_.reset();
-
-    filesystem_.DeleteDirectoryRecursively(base_dir_.c_str());
-  }
-
-  std::unique_ptr<FeatureFlags> feature_flags_;
-  Filesystem filesystem_;
-  FakeClock fake_clock_;
-  std::string base_dir_;
-  std::string qualified_id_join_index_dir_;
-  std::string schema_store_dir_;
-  std::string doc_store_dir_;
-
-  std::unique_ptr<QualifiedIdJoinIndex> qualified_id_join_index_;
-  std::unique_ptr<LanguageSegmenter> lang_segmenter_;
-  std::unique_ptr<SchemaStore> schema_store_;
-  std::unique_ptr<DocumentStore> doc_store_;
-};
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test,
-       CreationWithNullPointerShouldFail) {
-  EXPECT_THAT(
-      QualifiedIdJoinIndexingHandler::Create(
-          /*clock=*/nullptr, doc_store_.get(), qualified_id_join_index_.get()),
-      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
-
-  EXPECT_THAT(
-      QualifiedIdJoinIndexingHandler::Create(
-          &fake_clock_, /*doc_store=*/nullptr, qualified_id_join_index_.get()),
-      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
-
-  EXPECT_THAT(
-      QualifiedIdJoinIndexingHandler::Create(
-          &fake_clock_, doc_store_.get(), /*qualified_id_join_index=*/nullptr),
-      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
-}
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test, HandleJoinableProperty) {
-  DocumentProto referenced_document =
-      DocumentBuilder()
-          .SetKey("pkg$db/ns", "ref_type/1")
-          .SetSchema(std::string(kReferencedType))
-          .AddStringProperty(std::string(kPropertyName), "one")
-          .Build();
-
-  DocumentProto document =
-      DocumentBuilder()
-          .SetKey("icing", "fake_type/1")
-          .SetSchema(std::string(kFakeType))
-          .AddStringProperty(std::string(kPropertyQualifiedId),
-                             "pkg$db/ns#ref_type/1")
-          .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
-
-  ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kInvalidDocumentId));
-  // Handle document.
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
-      QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
-                                             qualified_id_join_index_.get()));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      IsOk());
-
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedIdJoinablePropertyId)),
-              IsOkAndHolds("pkg$db/ns#ref_type/1"));
-}
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test, HandleNestedJoinableProperty) {
-  DocumentProto referenced_document1 =
-      DocumentBuilder()
-          .SetKey("pkg$db/ns", "ref_type/1")
-          .SetSchema(std::string(kReferencedType))
-          .AddStringProperty(std::string(kPropertyName), "one")
-          .Build();
-  DocumentProto referenced_document2 =
-      DocumentBuilder()
-          .SetKey("pkg$db/ns", "ref_type/2")
-          .SetSchema(std::string(kReferencedType))
-          .AddStringProperty(std::string(kPropertyName), "two")
-          .Build();
-
-  DocumentProto nested_document =
-      DocumentBuilder()
-          .SetKey("pkg$db/ns", "nested_type/1")
-          .SetSchema(std::string(kNestedType))
-          .AddDocumentProperty(
-              std::string(kPropertyNestedDoc),
-              DocumentBuilder()
-                  .SetKey("pkg$db/ns", "nested_fake_type/1")
-                  .SetSchema(std::string(kFakeType))
-                  .AddStringProperty(std::string(kPropertyQualifiedId),
-                                     "pkg$db/ns#ref_type/2")
-                  .Build())
-          .AddStringProperty(std::string(kPropertyQualifiedId2),
-                             "pkg$db/ns#ref_type/1")
-          .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                nested_document));
-
-  ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kInvalidDocumentId));
-  // Handle nested_document.
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
-      QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
-                                             qualified_id_join_index_.get()));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      IsOk());
-
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kNestedQualifiedIdJoinablePropertyId)),
-              IsOkAndHolds("pkg$db/ns#ref_type/2"));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedId2JoinablePropertyId)),
-              IsOkAndHolds("pkg$db/ns#ref_type/1"));
-}
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test,
-       HandleShouldSkipInvalidFormatQualifiedId) {
-  static constexpr std::string_view kInvalidFormatQualifiedId =
-      "invalid_format_qualified_id";
-  ASSERT_THAT(QualifiedId::Parse(kInvalidFormatQualifiedId),
-              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-
-  DocumentProto document =
-      DocumentBuilder()
-          .SetKey("icing", "fake_type/1")
-          .SetSchema(std::string(kFakeType))
-          .AddStringProperty(std::string(kPropertyQualifiedId),
-                             std::string(kInvalidFormatQualifiedId))
-          .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
-
-  ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kInvalidDocumentId));
-  // Handle document. Should ignore invalid format qualified id.
-  // Index data should remain unchanged since there is no valid qualified id,
-  // but last_added_document_id should be updated.
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
-      QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
-                                             qualified_id_join_index_.get()));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      IsOk());
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-}
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test, HandleShouldSkipEmptyQualifiedId) {
-  // Create a document without any qualified id.
-  DocumentProto document = DocumentBuilder()
-                               .SetKey("icing", "fake_type/1")
-                               .SetSchema(std::string(kFakeType))
-                               .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
-  ASSERT_THAT(tokenized_document.qualified_id_join_properties(), IsEmpty());
-
-  ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kInvalidDocumentId));
-  // Handle document. Index data should remain unchanged since there is no
-  // qualified id, but last_added_document_id should be updated.
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
-      QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
-                                             qualified_id_join_index_.get()));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      IsOk());
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-}
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test,
-       HandleInvalidDocumentIdShouldReturnInvalidArgumentError) {
-  DocumentProto referenced_document =
-      DocumentBuilder()
-          .SetKey("pkg$db/ns", "ref_type/1")
-          .SetSchema(std::string(kReferencedType))
-          .AddStringProperty(std::string(kPropertyName), "one")
-          .Build();
-
-  DocumentProto document =
-      DocumentBuilder()
-          .SetKey("icing", "fake_type/1")
-          .SetSchema(std::string(kFakeType))
-          .AddStringProperty(std::string(kPropertyQualifiedId),
-                             "pkg$db/ns#ref_type/1")
-          .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
-
-  qualified_id_join_index_->set_last_added_document_id(kDefaultDocumentId);
-  ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
-      QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
-                                             qualified_id_join_index_.get()));
-
-  // Handling document with kInvalidDocumentId should cause a failure, and both
-  // index data and last_added_document_id should remain unchanged.
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kInvalidDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kInvalidDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-
-  // Recovery mode should get the same result.
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kInvalidDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/true, /*put_document_stats=*/nullptr),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kInvalidDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-}
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test,
-       HandleOutOfOrderDocumentIdShouldReturnInvalidArgumentError) {
-  DocumentProto referenced_document =
-      DocumentBuilder()
-          .SetKey("pkg$db/ns", "ref_type/1")
-          .SetSchema(std::string(kReferencedType))
-          .AddStringProperty(std::string(kPropertyName), "one")
-          .Build();
-
-  DocumentProto document =
-      DocumentBuilder()
-          .SetKey("icing", "fake_type/1")
-          .SetSchema(std::string(kFakeType))
-          .AddStringProperty(std::string(kPropertyQualifiedId),
-                             "pkg$db/ns#ref_type/1")
-          .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
-
-  qualified_id_join_index_->set_last_added_document_id(kDefaultDocumentId);
-  ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
-      QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
-                                             qualified_id_join_index_.get()));
-
-  // Handling document with document_id < last_added_document_id should cause a
-  // failure, and both index data and last_added_document_id should remain
-  // unchanged.
-  ASSERT_THAT(IsDocumentIdValid(kDefaultDocumentId - 1), IsTrue());
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId - 1,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-
-  // Handling document with document_id == last_added_document_id should cause a
-  // failure, and both index data and last_added_document_id should remain
-  // unchanged.
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-}
-
-TEST_F(QualifiedIdJoinIndexingHandlerV1Test,
-       HandleRecoveryModeShouldIgnoreDocsLELastAddedDocId) {
-  DocumentProto referenced_document =
-      DocumentBuilder()
-          .SetKey("pkg$db/ns", "ref_type/1")
-          .SetSchema(std::string(kReferencedType))
-          .AddStringProperty(std::string(kPropertyName), "one")
-          .Build();
-
-  DocumentProto document =
-      DocumentBuilder()
-          .SetKey("icing", "fake_type/1")
-          .SetSchema(std::string(kFakeType))
-          .AddStringProperty(std::string(kPropertyQualifiedId),
-                             "pkg$db/ns#ref_type/1")
-          .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
-
-  qualified_id_join_index_->set_last_added_document_id(kDefaultDocumentId);
-  ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
-      QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
-                                             qualified_id_join_index_.get()));
-
-  // Handle document with document_id < last_added_document_id in recovery mode.
-  // We should not get any error, but the handler should ignore the document, so
-  // both index data and last_added_document_id should remain unchanged.
-  ASSERT_THAT(IsDocumentIdValid(kDefaultDocumentId - 1), IsTrue());
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId - 1,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/true, /*put_document_stats=*/nullptr),
-      IsOk());
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-
-  // Handle document with document_id == last_added_document_id in recovery
-  // mode. We should not get any error, but the handler should ignore the
-  // document, so both index data and last_added_document_id should remain
-  // unchanged.
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/true, /*put_document_stats=*/nullptr),
-      IsOk());
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId, kQualifiedIdJoinablePropertyId)),
-              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
-
-  // Handle document with document_id > last_added_document_id in recovery mode.
-  // The handler should index this document and update last_added_document_id.
-  ASSERT_THAT(IsDocumentIdValid(kDefaultDocumentId + 1), IsTrue());
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, kDefaultDocumentId + 1,
-                      /*old_document_id=*/kInvalidDocumentId,
-                      /*recovery_mode=*/true, /*put_document_stats=*/nullptr),
-      IsOk());
-  EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
-              Eq(kDefaultDocumentId + 1));
-  EXPECT_THAT(qualified_id_join_index_->Get(DocumentJoinIdPair(
-                  kDefaultDocumentId + 1, kQualifiedIdJoinablePropertyId)),
-              IsOkAndHolds("pkg$db/ns#ref_type/1"));
-}
-
-}  // namespace
-
-}  // namespace lib
-}  // namespace icing
diff --git a/icing/join/qualified-id-join-indexing-handler-v2_test.cc b/icing/join/qualified-id-join-indexing-handler-v2_test.cc
index 9c20d45..b131efc 100644
--- a/icing/join/qualified-id-join-indexing-handler-v2_test.cc
+++ b/icing/join/qualified-id-join-indexing-handler-v2_test.cc
@@ -147,8 +147,7 @@ class QualifiedIdJoinIndexingHandlerV2Test : public ::testing::Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
                 IsTrue());
diff --git a/icing/join/qualified-id-join-indexing-handler-v3_test.cc b/icing/join/qualified-id-join-indexing-handler-v3_test.cc
index 5c87e19..7649424 100644
--- a/icing/join/qualified-id-join-indexing-handler-v3_test.cc
+++ b/icing/join/qualified-id-join-indexing-handler-v3_test.cc
@@ -144,8 +144,7 @@ class QualifiedIdJoinIndexingHandlerV3Test : public ::testing::Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
                 IsTrue());
diff --git a/icing/join/qualified-id-join-indexing-handler.cc b/icing/join/qualified-id-join-indexing-handler.cc
index 14d8231..b90227f 100644
--- a/icing/join/qualified-id-join-indexing-handler.cc
+++ b/icing/join/qualified-id-join-indexing-handler.cc
@@ -83,9 +83,6 @@ libtextclassifier3::Status QualifiedIdJoinIndexingHandler::Handle(
   qualified_id_join_index_.set_last_added_document_id(document_id);
 
   switch (qualified_id_join_index_.version()) {
-    case QualifiedIdJoinIndex::Version::kV1:
-      ICING_RETURN_IF_ERROR(HandleV1(tokenized_document, document_id));
-      break;
     case QualifiedIdJoinIndex::Version::kV2:
       ICING_RETURN_IF_ERROR(HandleV2(tokenized_document, document_id));
       break;
@@ -103,39 +100,6 @@ libtextclassifier3::Status QualifiedIdJoinIndexingHandler::Handle(
   return libtextclassifier3::Status::OK;
 }
 
-libtextclassifier3::Status QualifiedIdJoinIndexingHandler::HandleV1(
-    const TokenizedDocument& tokenized_document, DocumentId document_id) {
-  for (const JoinableProperty<std::string_view>& qualified_id_property :
-       tokenized_document.qualified_id_join_properties()) {
-    if (qualified_id_property.values.empty()) {
-      continue;
-    }
-
-    DocumentJoinIdPair document_join_id_pair(document_id,
-                                             qualified_id_property.metadata.id);
-    // Currently we only support single (non-repeated) joinable value under a
-    // property.
-    std::string_view ref_qualified_id_str = qualified_id_property.values[0];
-
-    // Attempt to parse qualified id string to make sure the format is
-    // correct.
-    if (!QualifiedId::Parse(ref_qualified_id_str).ok()) {
-      // Skip incorrect format of qualified id string to save disk space.
-      continue;
-    }
-
-    libtextclassifier3::Status status = qualified_id_join_index_.Put(
-        document_join_id_pair, ref_qualified_id_str);
-    if (!status.ok()) {
-      ICING_LOG(WARNING)
-          << "Failed to add data into qualified id join index due to: "
-          << status.error_message();
-      return status;
-    }
-  }
-  return libtextclassifier3::Status::OK;
-}
-
 libtextclassifier3::Status QualifiedIdJoinIndexingHandler::HandleV2(
     const TokenizedDocument& tokenized_document, DocumentId document_id) {
   std::optional<DocumentFilterData> filter_data =
diff --git a/icing/join/qualified-id-join-indexing-handler.h b/icing/join/qualified-id-join-indexing-handler.h
index 53c166c..f321f4d 100644
--- a/icing/join/qualified-id-join-indexing-handler.h
+++ b/icing/join/qualified-id-join-indexing-handler.h
@@ -77,11 +77,7 @@ class QualifiedIdJoinIndexingHandler : public DataIndexingHandler {
         doc_store_(*doc_store),
         qualified_id_join_index_(*qualified_id_join_index) {}
 
-  // TODO(b/275121148): deprecate v1, v2 after rollout v3.
-
-  // Helper function to handle indexing for QualfiedIdJoinIndexImplV1.
-  libtextclassifier3::Status HandleV1(
-      const TokenizedDocument& tokenized_document, DocumentId document_id);
+  // TODO(b/275121148): deprecate v2 after rollout v3.
 
   // Helper function to handle indexing for QualfiedIdJoinIndexImplV2.
   libtextclassifier3::Status HandleV2(
diff --git a/icing/query/advanced_query_parser/query-visitor.cc b/icing/query/advanced_query_parser/query-visitor.cc
index 8a879f9..04624b7 100644
--- a/icing/query/advanced_query_parser/query-visitor.cc
+++ b/icing/query/advanced_query_parser/query-visitor.cc
@@ -352,8 +352,8 @@ libtextclassifier3::StatusOr<PendingValue> QueryVisitor::SearchFunction(
         &index_, &numeric_index_, &embedding_index_, &document_store_,
         &schema_store_, &normalizer_, &tokenizer_, join_children_fetcher_,
         search_spec_, filter_options_, needs_term_frequency_info_,
-        &feature_flags_, pending_property_restricts_, processing_not_,
-        current_time_ms_);
+        get_embedding_match_info_, &feature_flags_, pending_property_restricts_,
+        processing_not_, current_time_ms_);
     tree_root->Accept(&query_visitor);
     ICING_ASSIGN_OR_RETURN(query_result,
                            std::move(query_visitor).ConsumeResults());
@@ -462,14 +462,14 @@ libtextclassifier3::StatusOr<PendingValue> QueryVisitor::SemanticSearchFunction(
   }
 
   // Create and return iterator.
-  EmbeddingQueryResults::EmbeddingQueryScoreMap* score_map =
-      &embedding_query_results_.result_scores[vector_index][metric_type];
+  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map =
+      &embedding_query_results_.result_infos[vector_index][metric_type];
   ICING_ASSIGN_OR_RETURN(
       std::unique_ptr<DocHitInfoIterator> iterator,
       DocHitInfoIteratorEmbedding::Create(
           &search_spec_.embedding_query_vectors(vector_index), metric_type, low,
-          high, score_map, &embedding_index_, &document_store_, &schema_store_,
-          current_time_ms_));
+          high, get_embedding_match_info_, info_map, &embedding_index_,
+          &document_store_, &schema_store_, current_time_ms_));
   return PendingValue(std::move(iterator));
 }
 
diff --git a/icing/query/advanced_query_parser/query-visitor.h b/icing/query/advanced_query_parser/query-visitor.h
index cd9bedd..746d921 100644
--- a/icing/query/advanced_query_parser/query-visitor.h
+++ b/icing/query/advanced_query_parser/query-visitor.h
@@ -61,12 +61,13 @@ class QueryVisitor : public AbstractSyntaxTreeVisitor {
       const JoinChildrenFetcher* join_children_fetcher,
       const SearchSpecProto& search_spec,
       DocHitInfoIteratorFilter::Options filter_options,
-      bool needs_term_frequency_info, const FeatureFlags* feature_flags,
-      int64_t current_time_ms)
+      bool needs_term_frequency_info, bool get_embedding_match_info,
+      const FeatureFlags* feature_flags, int64_t current_time_ms)
       : QueryVisitor(index, numeric_index, embedding_index, document_store,
                      schema_store, normalizer, tokenizer, join_children_fetcher,
                      search_spec, filter_options, needs_term_frequency_info,
-                     feature_flags, PendingPropertyRestricts(),
+                     get_embedding_match_info, feature_flags,
+                     PendingPropertyRestricts(),
                      /*processing_not=*/false, current_time_ms) {}
 
   void VisitString(const StringNode* node) override;
@@ -119,7 +120,8 @@ class QueryVisitor : public AbstractSyntaxTreeVisitor {
       const JoinChildrenFetcher* join_children_fetcher,
       const SearchSpecProto& search_spec,
       DocHitInfoIteratorFilter::Options filter_options,
-      bool needs_term_frequency_info, const FeatureFlags* feature_flags,
+      bool needs_term_frequency_info, bool get_embedding_match_info,
+      const FeatureFlags* feature_flags,
       PendingPropertyRestricts pending_property_restricts, bool processing_not,
       int64_t current_time_ms)
       : index_(*index),
@@ -133,6 +135,7 @@ class QueryVisitor : public AbstractSyntaxTreeVisitor {
         search_spec_(search_spec),
         filter_options_(std::move(filter_options)),
         needs_term_frequency_info_(needs_term_frequency_info),
+        get_embedding_match_info_(get_embedding_match_info),
         feature_flags_(*feature_flags),
         pending_property_restricts_(std::move(pending_property_restricts)),
         processing_not_(processing_not),
@@ -387,6 +390,10 @@ class QueryVisitor : public AbstractSyntaxTreeVisitor {
   //  - whether the QueryTermIteratorsMap is populated in the QueryResults.
   bool needs_term_frequency_info_;
 
+  // Whether or not to get embedding match info. This affects whether
+  // SectionInfos are populated in the EmbeddingQueryResults.
+  bool get_embedding_match_info_;
+
   const FeatureFlags& feature_flags_;  // Does not own.
   // TODO(b/377215223): Pass enabled scoring features from top level.
   std::unordered_set<ScoringFeatureType> scoring_feature_types_enabled_;
diff --git a/icing/query/advanced_query_parser/query-visitor_test.cc b/icing/query/advanced_query_parser/query-visitor_test.cc
index 5a60808..3c50b4a 100644
--- a/icing/query/advanced_query_parser/query-visitor_test.cc
+++ b/icing/query/advanced_query_parser/query-visitor_test.cc
@@ -14,6 +14,7 @@
 
 #include "icing/query/advanced_query_parser/query-visitor.h"
 
+#include <cmath>
 #include <cstdint>
 #include <initializer_list>
 #include <iterator>
@@ -35,6 +36,7 @@
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/embed/embedding-index.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/index/hit/hit.h"
 #include "icing/index/index.h"
 #include "icing/index/iterator/doc-hit-info-iterator-filter.h"
@@ -69,6 +71,7 @@
 #include "icing/tokenization/tokenizer-factory.h"
 #include "icing/tokenization/tokenizer.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -162,12 +165,43 @@ SearchSpecProto CreateSearchSpec(std::string query,
       /*embedding_query_vectors=*/{}, EMBEDDING_METRIC_UNKNOWN);
 }
 
+bool ContainsMatchInfoEntry(const EmbeddingMatchInfos* match_info, double score,
+                            int position_in_section, SectionId section_id) {
+  if (match_info == nullptr || match_info->section_infos == nullptr ||
+      match_info->scores.empty()) {
+    return false;
+  }
+  if (match_info->scores.size() != match_info->section_infos->size()) {
+    return false;
+  }
+
+  for (int i = 0; i < match_info->scores.size(); ++i) {
+    if (std::fabs(match_info->scores[i] - score) < kEps &&
+        match_info->section_infos->at(i).position == position_in_section &&
+        match_info->section_infos->at(i).section_id == section_id) {
+      return true;
+    }
+  }
+  return false;
+}
+
 enum class QueryType {
   kPlain,
   kSearch,
 };
 
-class QueryVisitorTest : public ::testing::TestWithParam<QueryType> {
+struct QueryVisitorTestParams {
+  QueryType query_type;
+  bool get_embedding_match_info;
+
+  explicit QueryVisitorTestParams(QueryType query_type,
+                                  bool get_embedding_match_info)
+      : query_type(query_type),
+        get_embedding_match_info(get_embedding_match_info) {}
+};
+
+class QueryVisitorTest
+    : public ::testing::TestWithParam<QueryVisitorTestParams> {
  protected:
   void SetUp() override {
     feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
@@ -228,8 +262,10 @@ class QueryVisitorTest : public ::testing::TestWithParam<QueryType> {
         EmbeddingIndex::Create(&filesystem_, embedding_index_dir_, &clock_,
                                feature_flags_.get()));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/1000));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     language_segmenter_factory::SegmenterOptions segmenter_options(
         ULOC_US, jni_cache_.get());
@@ -254,13 +290,14 @@ class QueryVisitorTest : public ::testing::TestWithParam<QueryType> {
 
   libtextclassifier3::StatusOr<QueryResults> ProcessQuery(
       const SearchSpecProto& search_spec, const Node* root_node) {
+    bool get_embedding_match_info = GetParam().get_embedding_match_info;
     QueryVisitor query_visitor(
         index_.get(), numeric_index_.get(), embedding_index_.get(),
         document_store_.get(), schema_store_.get(), normalizer_.get(),
         tokenizer_.get(), /*join_children_fetcher=*/nullptr, search_spec,
         DocHitInfoIteratorFilter::Options(),
-        /*needs_term_frequency_info=*/true, feature_flags_.get(),
-        clock_.GetSystemTimeMilliseconds());
+        /*needs_term_frequency_info=*/true, get_embedding_match_info,
+        feature_flags_.get(), clock_.GetSystemTimeMilliseconds());
     root_node->Accept(&query_visitor);
     return std::move(query_visitor).ConsumeResults();
   }
@@ -287,7 +324,7 @@ class QueryVisitorTest : public ::testing::TestWithParam<QueryType> {
 
   std::string CreateQuery(std::string query,
                           std::string property_restrict = "") {
-    switch (GetParam()) {
+    switch (GetParam().query_type) {
       case QueryType::kPlain:
         if (property_restrict.empty()) {
           // CreateQuery("foo bar") returns `foo bar`
@@ -348,7 +385,7 @@ TEST_P(QueryVisitorTest, SimpleLessThan) {
 
   std::string query = CreateQuery("price < 2");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -383,7 +420,7 @@ TEST_P(QueryVisitorTest, SimpleLessThanEq) {
   std::string query = CreateQuery("price <= 1");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -418,7 +455,7 @@ TEST_P(QueryVisitorTest, SimpleEqual) {
   std::string query = CreateQuery("price == 2");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -453,7 +490,7 @@ TEST_P(QueryVisitorTest, SimpleGreaterThanEq) {
   std::string query = CreateQuery("price >= 1");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -488,7 +525,7 @@ TEST_P(QueryVisitorTest, SimpleGreaterThan) {
   std::string query = CreateQuery("price > 1");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -524,7 +561,7 @@ TEST_P(QueryVisitorTest, IntMinLessThanEqual) {
   std::string query = CreateQuery("price <= " + std::to_string(int_min));
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -560,7 +597,7 @@ TEST_P(QueryVisitorTest, IntMaxGreaterThanEqual) {
   std::string query = CreateQuery("price >= " + std::to_string(int_max));
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -597,7 +634,7 @@ TEST_P(QueryVisitorTest, NestedPropertyLessThan) {
   std::string query = CreateQuery("subscription.price < 2");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -713,7 +750,7 @@ TEST_P(QueryVisitorTest, LessThanNonExistentPropertyNotFound) {
 
   std::string query = CreateQuery("time < 25");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -733,8 +770,8 @@ TEST_P(QueryVisitorTest, NeverVisitedReturnsInvalid) {
       document_store_.get(), schema_store_.get(), normalizer_.get(),
       tokenizer_.get(), /*join_children_fetcher=*/nullptr, search_spec,
       DocHitInfoIteratorFilter::Options(),
-      /*needs_term_frequency_info=*/true, feature_flags_.get(),
-      clock_.GetSystemTimeMilliseconds());
+      /*needs_term_frequency_info=*/true, /*get_embedding_match_info=*/false,
+      feature_flags_.get(), clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(std::move(query_visitor).ConsumeResults(),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
@@ -795,8 +832,7 @@ TEST_P(QueryVisitorTest, NumericComparatorDoesntAffectLaterTerms) {
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("type"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Index three documents:
   // - Doc0: ["-2", "-1", "1", "2"] and [-2, -1, 1, 2]
@@ -843,7 +879,7 @@ TEST_P(QueryVisitorTest, NumericComparatorDoesntAffectLaterTerms) {
   // match.
   std::string query = CreateQuery("price == -1 -2");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kNumericSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -931,8 +967,8 @@ TEST_P(QueryVisitorTest, SingleTermTermFrequencyDisabled) {
       document_store_.get(), schema_store_.get(), normalizer_.get(),
       tokenizer_.get(), /*join_children_fetcher=*/nullptr, search_spec,
       DocHitInfoIteratorFilter::Options(),
-      /*needs_term_frequency_info=*/false, feature_flags_.get(),
-      clock_.GetSystemTimeMilliseconds());
+      /*needs_term_frequency_info=*/false, /*get_embedding_match_info=*/false,
+      feature_flags_.get(), clock_.GetSystemTimeMilliseconds());
   root_node->Accept(&query_visitor);
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results,
                              std::move(query_visitor).ConsumeResults());
@@ -1095,7 +1131,7 @@ TEST_P(QueryVisitorTest, SingleVerbatimTerm) {
 
   std::string query = CreateQuery("\"foo:bar(baz)\"");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1181,7 +1217,7 @@ TEST_P(QueryVisitorTest, VerbatimTermEscapingQuote) {
   // `foobar\"`
   std::string query = CreateQuery(R"(("foobar\""))");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1224,7 +1260,7 @@ TEST_P(QueryVisitorTest, VerbatimTermEscapingEscape) {
   // Issue a query for the verbatim token `foobar\`.
   std::string query = CreateQuery(R"(("foobar\\"))");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1269,7 +1305,7 @@ TEST_P(QueryVisitorTest, VerbatimTermEscapingNonSpecialChar) {
   // Issue a query for the verbatim token `foobary`.
   std::string query = CreateQuery(R"(("foobar\y"))");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1288,7 +1324,7 @@ TEST_P(QueryVisitorTest, VerbatimTermEscapingNonSpecialChar) {
   // Issue a query for the verbatim token `foobar\y`.
   query = CreateQuery(R"(("foobar\\y"))");
   ICING_ASSERT_OK_AND_ASSIGN(query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1334,7 +1370,7 @@ TEST_P(QueryVisitorTest, VerbatimTermNewLine) {
   // Issue a query for the verbatim token `foobar` + '\n'.
   std::string query = CreateQuery("\"foobar\n\"");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1353,7 +1389,7 @@ TEST_P(QueryVisitorTest, VerbatimTermNewLine) {
   query = CreateQuery(R"(("foobar\\n"))");
   ICING_ASSERT_OK_AND_ASSIGN(query_results, ProcessQuery(query));
 
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1393,7 +1429,7 @@ TEST_P(QueryVisitorTest, VerbatimTermEscapingComplex) {
   // Issue a query for the verbatim token `foo\"bar\nbaz"`.
   std::string query = CreateQuery(R"(("foo\\\"bar\\nbaz\""))");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kVerbatimSearchFeature,
                                      kListFilterQueryLanguageFeature));
@@ -1417,8 +1453,7 @@ TEST_P(QueryVisitorTest, SingleMinusTerm) {
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("type"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
@@ -1445,7 +1480,7 @@ TEST_P(QueryVisitorTest, SingleMinusTerm) {
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
   EXPECT_THAT(ExtractKeys(query_results.query_terms), IsEmpty());
   EXPECT_THAT(query_results.query_term_iterators, IsEmpty());
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1462,8 +1497,7 @@ TEST_P(QueryVisitorTest, SingleNotTerm) {
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("type"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
@@ -1503,8 +1537,7 @@ TEST_P(QueryVisitorTest, NestedNotTerms) {
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("type"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
@@ -1552,8 +1585,7 @@ TEST_P(QueryVisitorTest, DeeplyNestedNotTerms) {
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("type"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
@@ -1624,7 +1656,7 @@ TEST_P(QueryVisitorTest, ImplicitAndTerms) {
 
   std::string query = CreateQuery("foo bar");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1658,7 +1690,7 @@ TEST_P(QueryVisitorTest, ExplicitAndTerms) {
 
   std::string query = CreateQuery("foo AND bar");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1692,7 +1724,7 @@ TEST_P(QueryVisitorTest, OrTerms) {
 
   std::string query = CreateQuery("foo OR bar");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1728,7 +1760,7 @@ TEST_P(QueryVisitorTest, AndOrTermPrecedence) {
   // Should be interpreted like `foo (bar OR baz)`
   std::string query = CreateQuery("foo bar OR baz");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1745,7 +1777,7 @@ TEST_P(QueryVisitorTest, AndOrTermPrecedence) {
   // Should be interpreted like `(bar OR baz) foo`
   query = CreateQuery("bar OR baz foo");
   ICING_ASSERT_OK_AND_ASSIGN(query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1761,7 +1793,7 @@ TEST_P(QueryVisitorTest, AndOrTermPrecedence) {
 
   query = CreateQuery("(bar OR baz) foo");
   ICING_ASSERT_OK_AND_ASSIGN(query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1785,8 +1817,7 @@ TEST_P(QueryVisitorTest, AndOrNotPrecedence) {
                   .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
                   .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
@@ -1852,8 +1883,7 @@ TEST_P(QueryVisitorTest, PropertyFilter) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -1887,7 +1917,7 @@ TEST_P(QueryVisitorTest, PropertyFilter) {
   EXPECT_THAT(query_results.query_terms["prop1"], UnorderedElementsAre("foo"));
   EXPECT_THAT(ExtractKeys(query_results.query_term_iterators),
               UnorderedElementsAre("foo"));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -1897,7 +1927,7 @@ TEST_P(QueryVisitorTest, PropertyFilter) {
               ElementsAre(kDocumentId1, kDocumentId0));
 }
 
-TEST_F(QueryVisitorTest, MultiPropertyFilter) {
+TEST_P(QueryVisitorTest, MultiPropertyFilter) {
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
@@ -1918,8 +1948,7 @@ TEST_F(QueryVisitorTest, MultiPropertyFilter) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -1977,8 +2006,7 @@ TEST_P(QueryVisitorTest, PropertyFilterStringIsInvalid) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // "prop1" is a STRING token, which cannot be a property name.
   std::string query = CreateQuery(R"(("prop1":foo))");
@@ -2002,8 +2030,7 @@ TEST_P(QueryVisitorTest, PropertyFilterNonNormalized) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
   SectionId prop2_section_id = 1;
@@ -2036,7 +2063,7 @@ TEST_P(QueryVisitorTest, PropertyFilterNonNormalized) {
   EXPECT_THAT(query_results.query_terms["PROP1"], UnorderedElementsAre("foo"));
   EXPECT_THAT(ExtractKeys(query_results.query_term_iterators),
               UnorderedElementsAre("foo"));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -2062,8 +2089,7 @@ TEST_P(QueryVisitorTest, PropertyFilterWithGrouping) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -2121,8 +2147,7 @@ TEST_P(QueryVisitorTest, ValidNestedPropertyFilter) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -2191,8 +2216,7 @@ TEST_P(QueryVisitorTest, InvalidNestedPropertyFilter) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -2257,8 +2281,7 @@ TEST_P(QueryVisitorTest, NotWithPropertyFilter) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -2328,8 +2351,7 @@ TEST_P(QueryVisitorTest, PropertyFilterWithNot) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -2421,8 +2443,7 @@ TEST_P(QueryVisitorTest, SegmentationTest) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -2467,7 +2488,7 @@ TEST_P(QueryVisitorTest, SegmentationTest) {
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -2505,8 +2526,7 @@ TEST_P(QueryVisitorTest, PropertyRestrictsPopCorrectly) {
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop1"))
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop2")))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   SectionId prop0_id = 0;
   SectionId prop1_id = 1;
@@ -2587,7 +2607,7 @@ TEST_P(QueryVisitorTest, PropertyRestrictsPopCorrectly) {
   std::string query = absl_ports::StrCat(
       "val0 ", CreateQuery("val1", /*property_restrict=*/"prop1"), " val2");
   ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results, ProcessQuery(query));
-  if (GetParam() == QueryType::kSearch) {
+  if (GetParam().query_type == QueryType::kSearch) {
     EXPECT_THAT(query_results.features_in_use,
                 UnorderedElementsAre(kListFilterQueryLanguageFeature));
   } else {
@@ -2620,8 +2640,7 @@ TEST_P(QueryVisitorTest, UnsatisfiablePropertyRestrictsPopCorrectly) {
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop1"))
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop2")))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   SectionId prop0_id = 0;
   SectionId prop1_id = 1;
@@ -2716,25 +2735,25 @@ TEST_P(QueryVisitorTest, UnsatisfiablePropertyRestrictsPopCorrectly) {
               ElementsAre(docid3, docid2, docid0));
 }
 
-TEST_F(QueryVisitorTest, UnsupportedFunctionReturnsInvalidArgument) {
+TEST_P(QueryVisitorTest, UnsupportedFunctionReturnsInvalidArgument) {
   std::string query = "unsupportedFunction()";
   EXPECT_THAT(ProcessQuery(query),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest, SearchFunctionTooFewArgumentsReturnsInvalidArgument) {
+TEST_P(QueryVisitorTest, SearchFunctionTooFewArgumentsReturnsInvalidArgument) {
   std::string query = "search()";
   EXPECT_THAT(ProcessQuery(query),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest, SearchFunctionTooManyArgumentsReturnsInvalidArgument) {
+TEST_P(QueryVisitorTest, SearchFunctionTooManyArgumentsReturnsInvalidArgument) {
   std::string query = R"(search("foo", createList("subject"), "bar"))";
   EXPECT_THAT(ProcessQuery(query),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SearchFunctionWrongFirstArgumentTypeReturnsInvalidArgument) {
   // First argument type=TEXT, expected STRING.
   std::string query = "search(7)";
@@ -2747,7 +2766,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SearchFunctionWrongSecondArgumentTypeReturnsInvalidArgument) {
   // Second argument type=STRING, expected string list.
   std::string query = R"(search("foo", "bar"))";
@@ -2760,14 +2779,14 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SearchFunctionCreateListZeroPropertiesReturnsInvalidArgument) {
   std::string query = R"(search("foo", createList()))";
   EXPECT_THAT(ProcessQuery(query),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest, SearchFunctionNestedFunctionCalls) {
+TEST_P(QueryVisitorTest, SearchFunctionNestedFunctionCalls) {
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
@@ -2783,8 +2802,7 @@ TEST_F(QueryVisitorTest, SearchFunctionNestedFunctionCalls) {
                                                            TOKENIZER_PLAIN)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
@@ -2862,7 +2880,7 @@ TEST_F(QueryVisitorTest, SearchFunctionNestedFunctionCalls) {
 
 // This test will nest `search` calls together with the set of restricts
 // narrowing at each level so that the set of docs matching the query shrinks.
-TEST_F(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
+TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
   PropertyConfigProto prop =
       PropertyConfigBuilder()
           .SetName("prop0")
@@ -2883,8 +2901,7 @@ TEST_F(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop6"))
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop7")))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop0_id = 0;
@@ -3023,7 +3040,7 @@ TEST_F(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
 // This test will nest `search` calls together with the set of restricts
 // narrowing at each level so that the set of docs matching the query shrinks.
-TEST_F(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
+TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
   PropertyConfigProto prop =
       PropertyConfigBuilder()
           .SetName("prop0")
@@ -3044,8 +3061,7 @@ TEST_F(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop6"))
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop7")))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop0_id = 0;
@@ -3184,8 +3200,7 @@ TEST_P(QueryVisitorTest, QueryStringParameterHandlesPunctuation) {
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("type").AddProperty(prop))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop0_id = 0;
@@ -3302,8 +3317,7 @@ TEST_P(QueryVisitorTest, QueryStringParameterPropertyRestricts) {
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop1"))
                   .AddProperty(PropertyConfigBuilder(prop).SetName("prop2")))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Section ids are assigned alphabetically.
   SectionId prop0_id = 0;
@@ -3460,14 +3474,14 @@ TEST_P(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        PropertyDefinedFunctionWithNoArgumentReturnsInvalidArgument) {
   std::string query = "propertyDefined()";
   EXPECT_THAT(ProcessQuery(query),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(
+TEST_P(
     QueryVisitorTest,
     PropertyDefinedFunctionWithMoreThanOneTextArgumentReturnsInvalidArgument) {
   std::string query = "propertyDefined(\"foo\", \"bar\")";
@@ -3475,7 +3489,7 @@ TEST_F(
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        PropertyDefinedFunctionWithTextArgumentReturnsInvalidArgument) {
   // The argument type is TEXT, not STRING here.
   std::string query = "propertyDefined(foo)";
@@ -3483,7 +3497,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        PropertyDefinedFunctionWithNonTextArgumentReturnsInvalidArgument) {
   std::string query = "propertyDefined(1 < 2)";
   EXPECT_THAT(ProcessQuery(query),
@@ -3502,8 +3516,7 @@ TEST_P(QueryVisitorTest, PropertyDefinedFunctionReturnsMatchingDocuments) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .AddType(SchemaTypeConfigBuilder().SetType("typeWithoutUrl"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Document 0 has the term "foo" and its schema has the url property.
   ICING_ASSERT_OK(document_store_->Put(
@@ -3552,8 +3565,7 @@ TEST_P(QueryVisitorTest,
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .AddType(SchemaTypeConfigBuilder().SetType("typeWithoutUrl"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Document 0 has the term "foo" and its schema has the url property.
   ICING_ASSERT_OK(document_store_->Put(
@@ -3594,8 +3606,7 @@ TEST_P(QueryVisitorTest,
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .AddType(SchemaTypeConfigBuilder().SetType("typeWithoutUrl"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Document 0 has the term "foo" and its schema has the url property.
   ICING_ASSERT_OK(document_store_->Put(
@@ -3623,21 +3634,21 @@ TEST_P(QueryVisitorTest,
               UnorderedElementsAre(kDocumentId1));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        HasPropertyFunctionWithNoArgumentReturnsInvalidArgument) {
   std::string query = "hasProperty()";
   EXPECT_THAT(ProcessQuery(query),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        HasPropertyFunctionWithMoreThanOneStringArgumentReturnsInvalidArgument) {
   std::string query = "hasProperty(\"foo\", \"bar\")";
   EXPECT_THAT(ProcessQuery(query),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        HasPropertyFunctionWithTextArgumentReturnsInvalidArgument) {
   // The argument type is TEXT, not STRING here.
   std::string query = "hasProperty(foo)";
@@ -3645,7 +3656,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        HasPropertyFunctionWithNonStringArgumentReturnsInvalidArgument) {
   std::string query = "hasProperty(1 < 2)";
   EXPECT_THAT(ProcessQuery(query),
@@ -3666,8 +3677,7 @@ TEST_P(QueryVisitorTest, HasPropertyFunctionReturnsMatchingDocuments) {
                                         .SetDataType(TYPE_INT64)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Document 0 has the term "foo" and has the "price" property.
   ICING_ASSERT_OK(document_store_->Put(
@@ -3734,8 +3744,7 @@ TEST_P(QueryVisitorTest,
                                         .SetDataType(TYPE_INT64)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Document 0 has the term "foo" and has the "price" property.
   ICING_ASSERT_OK(document_store_->Put(
@@ -3766,7 +3775,7 @@ TEST_P(QueryVisitorTest,
   EXPECT_THAT(GetDocumentIds(query_results.root_iterator.get()), IsEmpty());
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithNoArgumentReturnsInvalidArgument) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3783,7 +3792,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithIncorrectArgumentTypeReturnsInvalidArgument) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3800,7 +3809,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithExtraArgumentReturnsInvalidArgument) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3818,7 +3827,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        GetEmbeddingParameterFunctionWithExtraArgumentReturnsInvalidArgument) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3836,7 +3845,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithNoVectorParamsIndexReturnsOutOfRange) {
   // The embedding query index is invalid, since there are no query embeddings.
   std::string query = "semanticSearch(getEmbeddingParameter(0))";
@@ -3847,7 +3856,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::OUT_OF_RANGE));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithNegativeIndexReturnsOutOfRange) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3865,7 +3874,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::OUT_OF_RANGE));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithTooHighIndexReturnsOutOfRange) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3883,7 +3892,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::OUT_OF_RANGE));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithInvalidMetricReturnsInvalidArgument) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3912,7 +3921,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionWithInvalidRangeReturnsInvalidArgument) {
   // Create two embedding queries.
   std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
@@ -3941,7 +3950,7 @@ TEST_F(QueryVisitorTest,
   EXPECT_THAT(ProcessQuery(search_spec, root_node.get()), IsOk());
 }
 
-TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
+TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
   // Set up
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
@@ -3958,8 +3967,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
                                             EMBEDDING_INDEXING_LINEAR_SEARCH)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
   ICING_ASSERT_OK(document_store_->Put(
@@ -4000,6 +4008,22 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0),
       Pointee(UnorderedElementsAre(DoubleNear(1, kEps))));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(
+        query_results.embedding_query_results
+            .GetMatchedInfosForDocument(
+                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
+            ->section_infos,
+        IsNull());
+  }
 
   // The query should match both vector0 and vector1.
   query = "semanticSearch(getEmbeddingParameter(0), -1.5)";
@@ -4020,6 +4044,37 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1),
       Pointee(UnorderedElementsAre(DoubleNear(-1, kEps))));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+
+    // Check section match info for document 1.
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-1,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(
+        query_results.embedding_query_results
+            .GetMatchedInfosForDocument(
+                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
+            ->section_infos,
+        IsNull());
+
+    EXPECT_THAT(
+        query_results.embedding_query_results
+            .GetMatchedInfosForDocument(
+                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1)
+            ->section_infos,
+        IsNull());
+  }
 
   // The query should match nothing, since there is no vector with a
   // score >= 1.01.
@@ -4034,7 +4089,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
   EXPECT_THAT(GetDocumentIds(query_results.root_iterator.get()), IsEmpty());
 }
 
-TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
+TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
   // Set up
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
@@ -4051,8 +4106,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
                                             EMBEDDING_INDEXING_LINEAR_SEARCH)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
   ICING_ASSERT_OK(document_store_->Put(
@@ -4093,6 +4147,22 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1),
       Pointee(UnorderedElementsAre(DoubleNear(-1, kEps))));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 1.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-1,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(
+        query_results.embedding_query_results
+            .GetMatchedInfosForDocument(
+                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1)
+            ->section_infos,
+        IsNull());
+  }
 
   // The query should match both vector0 and vector1.
   query = "semanticSearch(getEmbeddingParameter(0), -100, 1.5)";
@@ -4113,6 +4183,37 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1),
       Pointee(UnorderedElementsAre(DoubleNear(-1, kEps))));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+
+    // Check section match info for document 1.
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-1,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+
+  } else {
+    EXPECT_THAT(
+        query_results.embedding_query_results
+            .GetMatchedInfosForDocument(
+                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
+            ->section_infos,
+        IsNull());
+    EXPECT_THAT(
+        query_results.embedding_query_results
+            .GetMatchedInfosForDocument(
+                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1)
+            ->section_infos,
+        IsNull());
+  }
 
   // The query should match nothing, since there is no vector with a
   // score <= -1.01.
@@ -4127,7 +4228,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
   EXPECT_THAT(GetDocumentIds(query_results.root_iterator.get()), IsEmpty());
 }
 
-TEST_F(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
+TEST_P(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
   // Set up
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
@@ -4144,8 +4245,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
                                             EMBEDDING_INDEXING_LINEAR_SEARCH)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
 
@@ -4183,6 +4283,22 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0),
       Pointee(UnorderedElementsAre(DoubleNear(1, kEps))));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(
+        query_results.embedding_query_results
+            .GetMatchedInfosForDocument(
+                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
+            ->section_infos,
+        IsNull());
+  }
 
   // Create a query that overrides the metric to DOT_PRODUCT.
   query = "semanticSearch(getEmbeddingParameter(0), 0.1, 0.2, \"DOT_PRODUCT\")";
@@ -4199,6 +4315,24 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
       Pointee(UnorderedElementsAre(DoubleNear(0.14, kEps))));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0.14,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    // Check section match info for document 0.
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+  }
 
   // Create a query that overrides the metric to EUCLIDEAN.
   query =
@@ -4216,9 +4350,255 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_EUCLIDEAN, kDocumentId0),
       Pointee(UnorderedElementsAre(DoubleNear(0, kEps))));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_EUCLIDEAN, kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_EUCLIDEAN,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+  }
+}
+
+TEST_P(QueryVisitorTest, SemanticSearchFunctionRepeatedProperty) {
+  // Set up
+  ICING_ASSERT_OK(schema_store_->SetSchema(
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("type")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("prop1")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("prop2")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED)))
+          .Build(),
+      /*ignore_errors_and_delete_documents=*/false));
+  ICING_ASSERT_OK(document_store_->Put(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+
+  // Index vectors for document 0.
+  // Section 0
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId0),
+      CreateVector("my_model1", {1, -2, -3}), QUANTIZATION_TYPE_NONE));
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId0),
+      CreateVector("my_model2", {1, -2, 3, -4}), QUANTIZATION_TYPE_NONE));
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId0),
+      CreateVector("my_model1", {-1, -2, 3}), QUANTIZATION_TYPE_NONE));
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId0),
+      CreateVector("my_model1", {1, -2, -4}), QUANTIZATION_TYPE_NONE));
+  // Section 1
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId1, kDocumentId0),
+      CreateVector("my_model1", {-1, -2, -3}), QUANTIZATION_TYPE_NONE));
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId1, kDocumentId0),
+      CreateVector("my_model1", {-1, 2, 4}), QUANTIZATION_TYPE_NONE));
+
+  // Index embedding vectors for document 1.
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId1),
+      CreateVector("my_model1", {1, -2, 6}), QUANTIZATION_TYPE_NONE));
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId1),
+      CreateVector("my_model2", {1, -2, 3, 4}), QUANTIZATION_TYPE_NONE));
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId1),
+      CreateVector("my_model1", {-1, -2, -6}), QUANTIZATION_TYPE_NONE));
+  ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
+      BasicHit(kSectionId0, kDocumentId1),
+      CreateVector("my_model2", {-1, -2, -3, -4}), QUANTIZATION_TYPE_NONE));
+
+  ICING_ASSERT_OK(embedding_index_->CommitBufferToIndex());
+
+  // Create two embedding queries.
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      // Semantic scores for this query:
+      // - document 0:
+      //   - section 0: -2, 6, -3
+      //   - section 1: 0, 3
+      // - document 1:
+      //   - section 0: 7, -3
+      CreateVector("my_model1", {-1, -1, 1}),
+      // Semantic scores for this query:
+      // - document 0:
+      //   - section 0: -2
+      // - document 1:
+      //   - section 0: -10, 6
+      CreateVector("my_model2", {-1, 1, -1, -1})};
+
+  // The should match both documents:
+  // Document 0:
+  // - The "semanticSearch(getEmbeddingParameter(0), -5, 1)" part should match
+  //   scores {-2 (section0, index0), 0(section1, index0), -3(section0,
+  //   index2)}.
+  // - The "semanticSearch(getEmbeddingParameter(0), 3)" part should match
+  //   semantic scores {6 (section0, index1), 3 (section1, index1)}.
+  // - The "semanticSearch(getEmbeddingParameter(1), -2)" part should match
+  //   semantic scores {-2 (section0, index0)}.
+  // Document 1:
+  // - The "semanticSearch(getEmbeddingParameter(0), -5, 1)" part should match
+  //   semantic scores {-3 (section0, index2)}.
+  // - The "semanticSearch(getEmbeddingParameter(0), 3)" part should match
+  //   semantic scores {7 (section0, index0)}.
+  // - The "semanticSearch(getEmbeddingParameter(1), -2)" part should match
+  //   semantic scores {6 (section0, index1)}.
+  std::string query =
+      "semanticSearch(getEmbeddingParameter(0), -5, 1) OR "
+      "semanticSearch(getEmbeddingParameter(0), 3) OR "
+      "semanticSearch(getEmbeddingParameter(1), -2)";
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Node> root_node,
+                             ParseQueryHelper(query));
+  SearchSpecProto search_spec =
+      CreateSearchSpec(query, TERM_MATCH_PREFIX, embedding_query_vectors,
+                       EMBEDDING_METRIC_DOT_PRODUCT);
+  ICING_ASSERT_OK_AND_ASSIGN(QueryResults query_results,
+                             ProcessQuery(search_spec, root_node.get()));
+  EXPECT_THAT(ExtractKeys(query_results.query_term_iterators), IsEmpty());
+  EXPECT_THAT(query_results.query_terms, IsEmpty());
+  EXPECT_THAT(query_results.features_in_use,
+              UnorderedElementsAre(kListFilterQueryLanguageFeature));
+
+  DocHitInfoIterator* itr = query_results.root_iterator.get();
+  // Check results for document 1.
+  ICING_ASSERT_OK(itr->Advance());
+  EXPECT_THAT(
+      itr->doc_hit_info(),
+      EqualsDocHitInfo(kDocumentId1, std::vector<SectionId>{kSectionId0}));
+  EXPECT_THAT(
+      query_results.embedding_query_results.GetMatchedScoresForDocument(
+          /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
+      Pointee(UnorderedElementsAre(-3, 7)));
+  EXPECT_THAT(
+      query_results.embedding_query_results.GetMatchedScoresForDocument(
+          /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
+      Pointee(UnorderedElementsAre(6)));
+
+  // Check results for document 0.
+  ICING_ASSERT_OK(itr->Advance());
+  EXPECT_THAT(itr->doc_hit_info(),
+              EqualsDocHitInfo(kDocumentId0, std::vector<SectionId>{
+                                                 kSectionId0, kSectionId1}));
+  EXPECT_THAT(
+      query_results.embedding_query_results.GetMatchedScoresForDocument(
+          /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
+      Pointee(UnorderedElementsAre(-2, 0, -3, 6, 3)));
+  EXPECT_THAT(
+      query_results.embedding_query_results.GetMatchedScoresForDocument(
+          /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
+      Pointee(UnorderedElementsAre(-2)));
+  EXPECT_THAT(itr->Advance(),
+              StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
+
+  if (GetParam().get_embedding_match_info) {
+    // Check match info for document 0.
+    // Document 0 expected match info:
+    // - Query 0:
+    //   - {score=-2, position=0, section_id=0}
+    //   - {score=-3, position=2, section_id=0}
+    //   - {score=6, position=1, section_id=0}
+    //   - {score=0, position=0, section_id=1}
+    //   - {score=3, position=1, section_id=1}
+    // - Query 1:
+    //   - {score=-2, position=0, section_id=1}
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-3,
+                                       /*position_in_section=*/2,
+                                       /*section_id=*/kSectionId0));
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+                                       /*position_in_section=*/1,
+                                       /*section_id=*/kSectionId0));
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId1));
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/3,
+                                       /*position_in_section=*/1,
+                                       /*section_id=*/kSectionId1));
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+
+    // Check match info for document 1.
+    // Document 1 expected match info:
+    // - Query 0:
+    //   - {score=-3, position=1, section_id=0}
+    //   - {score=7, position=0, section_id=0}
+    // - Query 1:
+    //   - {score=6, position=1, section_id=0}
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-3,
+                                       /*position_in_section=*/1,
+                                       /*section_id=*/kSectionId0));
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/7,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+                                       /*position_in_section=*/1,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId1)
+                    ->section_infos,
+                IsNull());
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId1)
+                    ->section_infos,
+                IsNull());
+  }
 }
 
-TEST_F(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
+TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
   // Set up
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
@@ -4240,8 +4620,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
                                             EMBEDDING_INDEXING_LINEAR_SEARCH)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
   ICING_ASSERT_OK(document_store_->Put(
@@ -4313,16 +4692,49 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
       Pointee(UnorderedElementsAre(4)));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId1));
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/4,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId2));
+  } else {
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+  }
 
   // The query can match both document 0 and document 1:
   // For document 0:
   // - The "semanticSearch(getEmbeddingParameter(0), 1)" part should return
   //   semantic scores {}.
   // - The "semanticSearch(getEmbeddingParameter(1), 0.1)" part should return
-  //   semantic scores {4}.
+  //   semantic scores {4 (section2)}.
   // For document 1:
   // - The "semanticSearch(getEmbeddingParameter(0), 1)" part should return
-  //   semantic scores {6}.
+  //   semantic scores {6 (section0)}.
   // - The "semanticSearch(getEmbeddingParameter(1), 0.1)" part should return
   //   semantic scores {}.
   query =
@@ -4364,9 +4776,51 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
       Pointee(UnorderedElementsAre(4)));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_THAT(match_infos, IsNull());
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/4,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId2));
+
+    // Check section match info for document 1.
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId1);
+    EXPECT_THAT(match_infos, IsNull());
+  } else {
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId1)
+                    ->section_infos,
+                IsNull());
+  }
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        SemanticSearchFunctionMultipleQueriesScoresMergedRepeat) {
   // Set up
   ICING_ASSERT_OK(schema_store_->SetSchema(
@@ -4384,8 +4838,7 @@ TEST_F(QueryVisitorTest,
                                             EMBEDDING_INDEXING_LINEAR_SEARCH)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
   ICING_ASSERT_OK(document_store_->Put(
@@ -4448,6 +4901,51 @@ TEST_F(QueryVisitorTest,
       Pointee(UnorderedElementsAre(-2, 0)));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId1));
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_THAT(match_infos, IsNull());
+
+    // Check section match info for document 1.
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_THAT(match_infos, IsNull());
+  } else {
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId1)
+                    ->section_infos,
+                IsNull());
+  }
 
   // The same query appears twice, in which case all the scores in the results
   // should repeat twice.
@@ -4484,7 +4982,7 @@ TEST_F(QueryVisitorTest,
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
 }
 
-TEST_F(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
+TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
   // Set up
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
@@ -4501,8 +4999,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
                                             EMBEDDING_INDEXING_LINEAR_SEARCH)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
   ICING_ASSERT_OK(document_store_->Put(
@@ -4572,6 +5069,30 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
       IsNull());
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_THAT(match_infos, IsNull());
+
+    // Check section match info for document 1.
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId1)
+                    ->section_infos,
+                IsNull());
+  }
 
   // Perform another hybrid search:
   // - The "semanticSearch(getEmbeddingParameter(0), -5)" part matches both
@@ -4600,9 +5121,42 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
       Pointee(UnorderedElementsAre(-2)));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
+
+  if (GetParam().get_embedding_match_info) {
+    // Check section match info for document 0.
+    const EmbeddingMatchInfos* match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId0);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+
+    // Check section match info for document 1.
+    match_infos =
+        query_results.embedding_query_results.GetMatchedInfosForDocument(
+            /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+            kDocumentId1);
+    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+                                       /*position_in_section=*/0,
+                                       /*section_id=*/kSectionId0));
+  } else {
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId0)
+                    ->section_infos,
+                IsNull());
+    EXPECT_THAT(query_results.embedding_query_results
+                    .GetMatchedInfosForDocument(
+                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
+                        kDocumentId1)
+                    ->section_infos,
+                IsNull());
+  }
 }
 
-TEST_F(QueryVisitorTest, SemanticSearchFunctionSectionRestriction) {
+TEST_P(QueryVisitorTest, SemanticSearchFunctionSectionRestriction) {
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
@@ -4618,8 +5172,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSectionRestriction) {
                                             EMBEDDING_INDEXING_LINEAR_SEARCH)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
 
   // Create two documents.
   ICING_ASSERT_OK(document_store_->Put(
@@ -4683,7 +5236,7 @@ TEST_F(QueryVisitorTest, SemanticSearchFunctionSectionRestriction) {
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
 }
 
-TEST_F(QueryVisitorTest,
+TEST_P(QueryVisitorTest,
        MatchScoreExpressionFunctionWithInvalidRangeReturnsInvalidArgument) {
   // The expression is invalid, since low > high.
   EXPECT_THAT(ProcessQuery("matchScoreExpression(\"1 + 1\", 10, -10)"),
@@ -4698,14 +5251,13 @@ TEST_F(QueryVisitorTest,
               IsOk());
 }
 
-TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionSimpleLowerBound) {
+TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionSimpleLowerBound) {
   // Create two documents with different document scores.
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
                                            .SetKey("ns", "uri0")
                                            .SetSchema("Simple")
@@ -4750,14 +5302,13 @@ TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionSimpleLowerBound) {
   EXPECT_THAT(GetDocumentIds(query_results.root_iterator.get()), IsEmpty());
 }
 
-TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionSimpleUpperBound) {
+TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionSimpleUpperBound) {
   // Create two documents with different document scores.
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
                                            .SetKey("ns", "uri0")
                                            .SetSchema("Simple")
@@ -4803,13 +5354,12 @@ TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionSimpleUpperBound) {
   EXPECT_THAT(GetDocumentIds(query_results.root_iterator.get()), IsEmpty());
 }
 
-TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionComplex) {
+TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionComplex) {
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
                                            .SetKey("ns", "uri0")
                                            .SetSchema("Simple")
@@ -4847,14 +5397,13 @@ TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionComplex) {
               UnorderedElementsAre(kDocumentId1));
 }
 
-TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionWithEvaluationErrors) {
+TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionWithEvaluationErrors) {
   // Create two documents with different document scores.
   ICING_ASSERT_OK(schema_store_->SetSchema(
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
-      /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
                                            .SetKey("ns", "uri0")
                                            .SetSchema("Simple")
@@ -4880,9 +5429,12 @@ TEST_F(QueryVisitorTest, MatchScoreExpressionFunctionWithEvaluationErrors) {
               UnorderedElementsAre(kDocumentId0));
 }
 
-INSTANTIATE_TEST_SUITE_P(QueryVisitorTest, QueryVisitorTest,
-                         testing::Values(QueryType::kPlain,
-                                         QueryType::kSearch));
+INSTANTIATE_TEST_SUITE_P(
+    QueryVisitorTest, QueryVisitorTest,
+    testing::Values(QueryVisitorTestParams(QueryType::kSearch, true),
+                    QueryVisitorTestParams(QueryType::kSearch, false),
+                    QueryVisitorTestParams(QueryType::kPlain, true),
+                    QueryVisitorTestParams(QueryType::kPlain, false)));
 
 }  // namespace
 
diff --git a/icing/query/query-processor.cc b/icing/query/query-processor.cc
index c331bb8..7830dc5 100644
--- a/icing/query/query-processor.cc
+++ b/icing/query/query-processor.cc
@@ -101,9 +101,11 @@ QueryProcessor::QueryProcessor(
 libtextclassifier3::StatusOr<QueryResults> QueryProcessor::ParseSearch(
     const SearchSpecProto& search_spec,
     ScoringSpecProto::RankingStrategy::Code ranking_strategy,
-    int64_t current_time_ms, QueryStatsProto::SearchStats* search_stats) {
+    bool get_embedding_match_info, int64_t current_time_ms,
+    QueryStatsProto::SearchStats* search_stats) {
   ICING_ASSIGN_OR_RETURN(QueryResults results,
                          ParseAdvancedQuery(search_spec, ranking_strategy,
+                                            get_embedding_match_info,
                                             current_time_ms, search_stats));
 
   // Check that all new features used in the search have been enabled in the
@@ -153,7 +155,8 @@ libtextclassifier3::StatusOr<QueryResults> QueryProcessor::ParseSearch(
 libtextclassifier3::StatusOr<QueryResults> QueryProcessor::ParseAdvancedQuery(
     const SearchSpecProto& search_spec,
     ScoringSpecProto::RankingStrategy::Code ranking_strategy,
-    int64_t current_time_ms, QueryStatsProto::SearchStats* search_stats) const {
+    bool get_embedding_match_info, int64_t current_time_ms,
+    QueryStatsProto::SearchStats* search_stats) const {
   std::unique_ptr<Timer> lexer_timer = clock_.GetNewTimer();
   Lexer lexer(search_spec.query(), Lexer::Language::QUERY);
   ICING_ASSIGN_OR_RETURN(std::vector<Lexer::LexerToken> lexer_tokens,
@@ -189,7 +192,8 @@ libtextclassifier3::StatusOr<QueryResults> QueryProcessor::ParseAdvancedQuery(
       &index_, &numeric_index_, &embedding_index_, &document_store_,
       &schema_store_, &normalizer_, plain_tokenizer.get(),
       join_children_fetcher_, search_spec, std::move(options),
-      needs_term_frequency_info, &feature_flags_, current_time_ms);
+      needs_term_frequency_info, get_embedding_match_info, &feature_flags_,
+      current_time_ms);
   tree_root->Accept(&query_visitor);
   ICING_ASSIGN_OR_RETURN(QueryResults results,
                          std::move(query_visitor).ConsumeResults());
diff --git a/icing/query/query-processor.h b/icing/query/query-processor.h
index 7368ef6..03eb10b 100644
--- a/icing/query/query-processor.h
+++ b/icing/query/query-processor.h
@@ -73,7 +73,7 @@ class QueryProcessor {
   libtextclassifier3::StatusOr<QueryResults> ParseSearch(
       const SearchSpecProto& search_spec,
       ScoringSpecProto::RankingStrategy::Code ranking_strategy,
-      int64_t current_time_ms,
+      bool get_embedding_match_info, int64_t current_time_ms,
       QueryStatsProto::SearchStats* search_stats = nullptr);
 
  private:
@@ -97,7 +97,7 @@ class QueryProcessor {
   libtextclassifier3::StatusOr<QueryResults> ParseAdvancedQuery(
       const SearchSpecProto& search_spec,
       ScoringSpecProto::RankingStrategy::Code ranking_strategy,
-      int64_t current_time_ms,
+      bool get_embedding_match_info, int64_t current_time_ms,
       QueryStatsProto::SearchStats* search_stats) const;
 
   // Parse the query into a one DocHitInfoIterator that represents the root of a
diff --git a/icing/query/query-processor_benchmark.cc b/icing/query/query-processor_benchmark.cc
index 27120c6..ad125c9 100644
--- a/icing/query/query-processor_benchmark.cc
+++ b/icing/query/query-processor_benchmark.cc
@@ -46,6 +46,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -104,10 +105,9 @@ std::unique_ptr<Index> CreateIndex(const IcingFilesystem& icing_filesystem,
 }
 
 std::unique_ptr<Normalizer> CreateNormalizer() {
-  return normalizer_factory::Create(
-
-             /*max_term_byte_size=*/std::numeric_limits<int>::max())
-      .ValueOrDie();
+  NormalizerOptions normalizer_options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  return normalizer_factory::Create(normalizer_options).ValueOrDie();
 }
 
 libtextclassifier3::StatusOr<DocumentStore::CreateResult> CreateDocumentStore(
@@ -166,8 +166,7 @@ void BM_QueryOneTerm(benchmark::State& state) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem, schema_dir, &clock, &feature_flags));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   DocumentStore::CreateResult create_result =
       CreateDocumentStore(&filesystem, doc_store_dir, &clock,
@@ -210,6 +209,7 @@ void BM_QueryOneTerm(benchmark::State& state) {
         query_processor
             ->ParseSearch(search_spec,
                           ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+                          /*get_embedding_match_info=*/false,
                           clock.GetSystemTimeMilliseconds())
             .ValueOrDie();
     while (results.root_iterator->Advance().ok()) {
@@ -305,8 +305,7 @@ void BM_QueryFiveTerms(benchmark::State& state) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem, schema_dir, &clock, &feature_flags));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   DocumentStore::CreateResult create_result =
       CreateDocumentStore(&filesystem, doc_store_dir, &clock,
@@ -367,6 +366,7 @@ void BM_QueryFiveTerms(benchmark::State& state) {
         query_processor
             ->ParseSearch(search_spec,
                           ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+                          /*get_embedding_match_info=*/false,
                           clock.GetSystemTimeMilliseconds())
             .ValueOrDie();
     while (results.root_iterator->Advance().ok()) {
@@ -462,8 +462,7 @@ void BM_QueryDiacriticTerm(benchmark::State& state) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem, schema_dir, &clock, &feature_flags));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   DocumentStore::CreateResult create_result =
       CreateDocumentStore(&filesystem, doc_store_dir, &clock,
@@ -509,6 +508,7 @@ void BM_QueryDiacriticTerm(benchmark::State& state) {
         query_processor
             ->ParseSearch(search_spec,
                           ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+                          /*get_embedding_match_info=*/false,
                           clock.GetSystemTimeMilliseconds())
             .ValueOrDie();
     while (results.root_iterator->Advance().ok()) {
@@ -604,8 +604,7 @@ void BM_QueryHiragana(benchmark::State& state) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem, schema_dir, &clock, &feature_flags));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   DocumentStore::CreateResult create_result =
       CreateDocumentStore(&filesystem, doc_store_dir, &clock,
@@ -651,6 +650,7 @@ void BM_QueryHiragana(benchmark::State& state) {
         query_processor
             ->ParseSearch(search_spec,
                           ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+                          /*get_embedding_match_info=*/false,
                           clock.GetSystemTimeMilliseconds())
             .ValueOrDie();
     while (results.root_iterator->Advance().ok()) {
diff --git a/icing/query/query-processor_test.cc b/icing/query/query-processor_test.cc
index b5d3c57..b5d1f0f 100644
--- a/icing/query/query-processor_test.cc
+++ b/icing/query/query-processor_test.cc
@@ -16,6 +16,7 @@
 
 #include <array>
 #include <cstdint>
+#include <limits>
 #include <memory>
 #include <string>
 #include <unordered_map>
@@ -61,6 +62,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -150,8 +152,10 @@ class QueryProcessorTest : public ::testing::Test {
         language_segmenter_,
         language_segmenter_factory::Create(segmenter_options));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/1000));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         query_processor_,
@@ -278,14 +282,14 @@ TEST_F(QueryProcessorTest, EmptyGroupMatchAllDocuments) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   SearchSpecProto search_spec;
   search_spec.set_query("()");
   EXPECT_THAT(query_processor_->ParseSearch(
                   search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                  /*get_embedding_match_info=*/false,
                   fake_clock_.GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
@@ -296,8 +300,7 @@ TEST_F(QueryProcessorTest, EmptyQueryMatchAllDocuments) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
@@ -322,6 +325,7 @@ TEST_F(QueryProcessorTest, EmptyQueryMatchAllDocuments) {
       QueryResults results,
       query_processor_->ParseSearch(search_spec,
                                     ScoringSpecProto::RankingStrategy::NONE,
+                                    /*get_embedding_match_info=*/false,
                                     fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -337,8 +341,7 @@ TEST_F(QueryProcessorTest, QueryTermNormalized) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -371,6 +374,7 @@ TEST_F(QueryProcessorTest, QueryTermNormalized) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -398,8 +402,7 @@ TEST_F(QueryProcessorTest, OneTermPrefixMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -429,6 +432,7 @@ TEST_F(QueryProcessorTest, OneTermPrefixMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -454,8 +458,7 @@ TEST_F(QueryProcessorTest, OneTermPrefixMatchWithMaxSectionID) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -487,6 +490,7 @@ TEST_F(QueryProcessorTest, OneTermPrefixMatchWithMaxSectionID) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -512,8 +516,7 @@ TEST_F(QueryProcessorTest, OneTermExactMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -543,6 +546,7 @@ TEST_F(QueryProcessorTest, OneTermExactMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -568,8 +572,7 @@ TEST_F(QueryProcessorTest, AndSameTermExactMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -599,6 +602,7 @@ TEST_F(QueryProcessorTest, AndSameTermExactMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -626,8 +630,7 @@ TEST_F(QueryProcessorTest, AndTwoTermExactMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -660,6 +663,7 @@ TEST_F(QueryProcessorTest, AndTwoTermExactMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -687,8 +691,7 @@ TEST_F(QueryProcessorTest, AndSameTermPrefixMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -718,6 +721,7 @@ TEST_F(QueryProcessorTest, AndSameTermPrefixMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -745,8 +749,7 @@ TEST_F(QueryProcessorTest, AndTwoTermPrefixMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -779,6 +782,7 @@ TEST_F(QueryProcessorTest, AndTwoTermPrefixMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -807,8 +811,7 @@ TEST_F(QueryProcessorTest, AndTwoTermPrefixAndExactMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -841,6 +844,7 @@ TEST_F(QueryProcessorTest, AndTwoTermPrefixAndExactMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -869,8 +873,7 @@ TEST_F(QueryProcessorTest, OrTwoTermExactMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -909,6 +912,7 @@ TEST_F(QueryProcessorTest, OrTwoTermExactMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -945,8 +949,7 @@ TEST_F(QueryProcessorTest, OrTwoTermPrefixMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -985,6 +988,7 @@ TEST_F(QueryProcessorTest, OrTwoTermPrefixMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1021,8 +1025,7 @@ TEST_F(QueryProcessorTest, OrTwoTermPrefixAndExactMatch) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1060,6 +1063,7 @@ TEST_F(QueryProcessorTest, OrTwoTermPrefixAndExactMatch) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1095,8 +1099,7 @@ TEST_F(QueryProcessorTest, CombinedAndOrTerms) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1151,6 +1154,7 @@ TEST_F(QueryProcessorTest, CombinedAndOrTerms) {
         QueryResults results,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+            /*get_embedding_match_info=*/false,
             fake_clock_.GetSystemTimeMilliseconds()));
 
     // Only Document 1 matches since it has puppy AND dog
@@ -1186,6 +1190,7 @@ TEST_F(QueryProcessorTest, CombinedAndOrTerms) {
         QueryResults results,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+            /*get_embedding_match_info=*/false,
             fake_clock_.GetSystemTimeMilliseconds()));
 
     // Both Document 1 and 2 match since Document 1 has animal AND puppy, and
@@ -1237,6 +1242,7 @@ TEST_F(QueryProcessorTest, CombinedAndOrTerms) {
         QueryResults results,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+            /*get_embedding_match_info=*/false,
             fake_clock_.GetSystemTimeMilliseconds()));
 
     // Only Document 2 matches since it has both kitten and cat
@@ -1268,8 +1274,7 @@ TEST_F(QueryProcessorTest, OneGroup) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1316,6 +1321,7 @@ TEST_F(QueryProcessorTest, OneGroup) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1336,8 +1342,7 @@ TEST_F(QueryProcessorTest, TwoGroups) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1385,6 +1390,7 @@ TEST_F(QueryProcessorTest, TwoGroups) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1407,8 +1413,7 @@ TEST_F(QueryProcessorTest, ManyLevelNestedGrouping) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1455,6 +1460,7 @@ TEST_F(QueryProcessorTest, ManyLevelNestedGrouping) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1475,8 +1481,7 @@ TEST_F(QueryProcessorTest, OneLevelNestedGrouping) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1523,6 +1528,7 @@ TEST_F(QueryProcessorTest, OneLevelNestedGrouping) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1545,8 +1551,7 @@ TEST_F(QueryProcessorTest, ExcludeTerm) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1584,6 +1589,7 @@ TEST_F(QueryProcessorTest, ExcludeTerm) {
       QueryResults results,
       query_processor_->ParseSearch(search_spec,
                                     ScoringSpecProto::RankingStrategy::NONE,
+                                    /*get_embedding_match_info=*/false,
                                     fake_clock_.GetSystemTimeMilliseconds()));
 
   // We don't know have the section mask to indicate what section "world"
@@ -1601,8 +1607,7 @@ TEST_F(QueryProcessorTest, ExcludeNonexistentTerm) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1639,6 +1644,7 @@ TEST_F(QueryProcessorTest, ExcludeNonexistentTerm) {
       QueryResults results,
       query_processor_->ParseSearch(search_spec,
                                     ScoringSpecProto::RankingStrategy::NONE,
+                                    /*get_embedding_match_info=*/false,
                                     fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1655,8 +1661,7 @@ TEST_F(QueryProcessorTest, ExcludeAnd) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1702,6 +1707,7 @@ TEST_F(QueryProcessorTest, ExcludeAnd) {
         QueryResults results,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+            /*get_embedding_match_info=*/false,
             fake_clock_.GetSystemTimeMilliseconds()));
 
     // The query is interpreted as "exclude all documents that have animal,
@@ -1722,6 +1728,7 @@ TEST_F(QueryProcessorTest, ExcludeAnd) {
         QueryResults results,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+            /*get_embedding_match_info=*/false,
             fake_clock_.GetSystemTimeMilliseconds()));
 
     // The query is interpreted as "exclude all documents that have animal,
@@ -1741,8 +1748,7 @@ TEST_F(QueryProcessorTest, ExcludeOr) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1788,6 +1794,7 @@ TEST_F(QueryProcessorTest, ExcludeOr) {
         QueryResults results,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+            /*get_embedding_match_info=*/false,
             fake_clock_.GetSystemTimeMilliseconds()));
 
     // We don't have a section mask indicating which sections in this document
@@ -1809,6 +1816,7 @@ TEST_F(QueryProcessorTest, ExcludeOr) {
         QueryResults results,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+            /*get_embedding_match_info=*/false,
             fake_clock_.GetSystemTimeMilliseconds()));
 
     // Descending order of valid DocumentIds
@@ -1830,8 +1838,7 @@ TEST_F(QueryProcessorTest, WithoutTermFrequency) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1888,6 +1895,7 @@ TEST_F(QueryProcessorTest, WithoutTermFrequency) {
       QueryResults results,
       query_processor_->ParseSearch(search_spec,
                                     ScoringSpecProto::RankingStrategy::NONE,
+                                    /*get_embedding_match_info=*/false,
                                     fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1931,8 +1939,7 @@ TEST_F(QueryProcessorTest, DeletedFilter) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -1980,6 +1987,7 @@ TEST_F(QueryProcessorTest, DeletedFilter) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -1999,8 +2007,7 @@ TEST_F(QueryProcessorTest, NamespaceFilter) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2046,6 +2053,7 @@ TEST_F(QueryProcessorTest, NamespaceFilter) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -2067,8 +2075,7 @@ TEST_F(QueryProcessorTest, SchemaTypeFilter) {
           .AddType(SchemaTypeConfigBuilder().SetType("message"))
           .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2110,6 +2117,7 @@ TEST_F(QueryProcessorTest, SchemaTypeFilter) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -2136,8 +2144,7 @@ TEST_F(QueryProcessorTest, PropertyFilterForOneDocument) {
   // First and only indexed property, so it gets a section_id of 0
   int subject_section_id = 0;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2167,6 +2174,7 @@ TEST_F(QueryProcessorTest, PropertyFilterForOneDocument) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Descending order of valid DocumentIds
@@ -2209,8 +2217,7 @@ TEST_F(QueryProcessorTest, PropertyFilterAcrossSchemaTypes) {
   int email_foo_section_id = 1;
   int message_foo_section_id = 0;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2251,6 +2258,7 @@ TEST_F(QueryProcessorTest, PropertyFilterAcrossSchemaTypes) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Ordered by descending DocumentId, so message comes first since it was
@@ -2284,8 +2292,7 @@ TEST_F(QueryProcessorTest, PropertyFilterWithinSchemaType) {
   int email_foo_section_id = 0;
   int message_foo_section_id = 0;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2328,6 +2335,7 @@ TEST_F(QueryProcessorTest, PropertyFilterWithinSchemaType) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Shouldn't include the message document since we're only looking at email
@@ -2377,8 +2385,7 @@ TEST_F(QueryProcessorTest, NestedPropertyFilter) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2409,6 +2416,7 @@ TEST_F(QueryProcessorTest, NestedPropertyFilter) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Even though the section id is the same, we should be able to tell that it
@@ -2442,8 +2450,7 @@ TEST_F(QueryProcessorTest, PropertyFilterRespectsDifferentSectionIds) {
   int email_foo_section_id = 0;
   int message_foo_section_id = 0;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2487,6 +2494,7 @@ TEST_F(QueryProcessorTest, PropertyFilterRespectsDifferentSectionIds) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Even though the section id is the same, we should be able to tell that it
@@ -2507,8 +2515,7 @@ TEST_F(QueryProcessorTest, NonexistentPropertyFilterReturnsEmptyResults) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2539,6 +2546,7 @@ TEST_F(QueryProcessorTest, NonexistentPropertyFilterReturnsEmptyResults) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Even though the section id is the same, we should be able to tell that it
@@ -2565,8 +2573,7 @@ TEST_F(QueryProcessorTest, UnindexedPropertyFilterReturnsEmptyResults) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2597,6 +2604,7 @@ TEST_F(QueryProcessorTest, UnindexedPropertyFilterReturnsEmptyResults) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Even though the section id is the same, we should be able to tell that it
@@ -2626,8 +2634,7 @@ TEST_F(QueryProcessorTest, PropertyFilterTermAndUnrestrictedTerm) {
   int email_foo_section_id = 0;
   int message_foo_section_id = 0;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2671,6 +2678,7 @@ TEST_F(QueryProcessorTest, PropertyFilterTermAndUnrestrictedTerm) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Ordered by descending DocumentId, so message comes first since it was
@@ -2692,38 +2700,40 @@ TEST_F(QueryProcessorTest, TypePropertyFilter) {
   // Create the schema and document store
   SchemaProto schema =
       SchemaBuilder()
-          .AddType(SchemaTypeConfigBuilder().SetType("email")
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("foo")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("bar")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("baz")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL)))
-          .AddType(SchemaTypeConfigBuilder().SetType("message")
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("foo")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("bar")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("baz")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL)))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("email")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("foo")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("bar")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("baz")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("message")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("foo")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("bar")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("baz")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
   // SectionIds are assigned in ascending order per schema type,
   // alphabetically.
@@ -2734,8 +2744,7 @@ TEST_F(QueryProcessorTest, TypePropertyFilter) {
   int message_baz_section_id = 1;
   int message_foo_section_id = 2;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2784,13 +2793,13 @@ TEST_F(QueryProcessorTest, TypePropertyFilter) {
   search_spec.set_term_match_type(term_match_type);
 
   // email has property filters for foo and baz properties
-  TypePropertyMask *email_mask = search_spec.add_type_property_filters();
+  TypePropertyMask* email_mask = search_spec.add_type_property_filters();
   email_mask->set_schema_type("email");
   email_mask->add_paths("foo");
   email_mask->add_paths("baz");
 
   // message has property filters for bar and baz properties
-  TypePropertyMask *message_mask = search_spec.add_type_property_filters();
+  TypePropertyMask* message_mask = search_spec.add_type_property_filters();
   message_mask->set_schema_type("message");
   message_mask->add_paths("bar");
   message_mask->add_paths("baz");
@@ -2799,6 +2808,7 @@ TEST_F(QueryProcessorTest, TypePropertyFilter) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Ordered by descending DocumentId, so message comes first since it was
@@ -2821,38 +2831,40 @@ TEST_F(QueryProcessorTest, TypePropertyFilterWithSectionRestrict) {
   // Create the schema and document store
   SchemaProto schema =
       SchemaBuilder()
-          .AddType(SchemaTypeConfigBuilder().SetType("email")
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("foo")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("bar")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("baz")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL)))
-          .AddType(SchemaTypeConfigBuilder().SetType("message")
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("foo")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("bar")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL))
-              .AddProperty(
-                  PropertyConfigBuilder()
-                  .SetName("baz")
-                  .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
-                  .SetCardinality(CARDINALITY_OPTIONAL)))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("email")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("foo")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("bar")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("baz")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("message")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("foo")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("bar")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("baz")
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
   // SectionIds are assigned in ascending order per schema type,
   // alphabetically.
@@ -2863,8 +2875,7 @@ TEST_F(QueryProcessorTest, TypePropertyFilterWithSectionRestrict) {
   int message_baz_section_id = 1;
   int message_foo_section_id = 2;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -2914,13 +2925,13 @@ TEST_F(QueryProcessorTest, TypePropertyFilterWithSectionRestrict) {
   search_spec.set_term_match_type(term_match_type);
 
   // email has property filters for foo and baz properties
-  TypePropertyMask *email_mask = search_spec.add_type_property_filters();
+  TypePropertyMask* email_mask = search_spec.add_type_property_filters();
   email_mask->set_schema_type("email");
   email_mask->add_paths("foo");
   email_mask->add_paths("baz");
 
   // message has property filters for bar and baz properties
-  TypePropertyMask *message_mask = search_spec.add_type_property_filters();
+  TypePropertyMask* message_mask = search_spec.add_type_property_filters();
   message_mask->set_schema_type("message");
   message_mask->add_paths("bar");
   message_mask->add_paths("baz");
@@ -2929,6 +2940,7 @@ TEST_F(QueryProcessorTest, TypePropertyFilterWithSectionRestrict) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   // Only hits in sections allowed by both the property filters and section
@@ -2951,8 +2963,7 @@ TEST_F(QueryProcessorTest, DocumentBeforeTtlNotFilteredOut) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // Arbitrary value, just has to be less than the document's creation
@@ -3002,6 +3013,7 @@ TEST_F(QueryProcessorTest, DocumentBeforeTtlNotFilteredOut) {
       QueryResults results,
       local_query_processor->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::NONE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds()));
 
   DocHitInfo expectedDocHitInfo(document_id);
@@ -3016,8 +3028,7 @@ TEST_F(QueryProcessorTest, DocumentPastTtlFilteredOut) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // Arbitrary value, just has to be greater than the document's creation
@@ -3067,6 +3078,7 @@ TEST_F(QueryProcessorTest, DocumentPastTtlFilteredOut) {
       QueryResults results,
       local_query_processor->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::NONE,
+          /*get_embedding_match_info=*/false,
           fake_clock_local.GetSystemTimeMilliseconds()));
 
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()), IsEmpty());
@@ -3091,8 +3103,7 @@ TEST_F(QueryProcessorTest, NumericFilter) {
   SectionId cost_section_id = 0;
   SectionId price_section_id = 1;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
@@ -3135,6 +3146,7 @@ TEST_F(QueryProcessorTest, NumericFilter) {
       QueryResults results,
       query_processor_->ParseSearch(search_spec,
                                     ScoringSpecProto::RankingStrategy::NONE,
+                                    /*get_embedding_match_info=*/false,
                                     fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()),
               ElementsAre(EqualsDocHitInfo(
@@ -3144,6 +3156,7 @@ TEST_F(QueryProcessorTest, NumericFilter) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()),
               ElementsAre(EqualsDocHitInfo(
@@ -3153,6 +3166,7 @@ TEST_F(QueryProcessorTest, NumericFilter) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()), IsEmpty());
 
@@ -3160,6 +3174,7 @@ TEST_F(QueryProcessorTest, NumericFilter) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()),
               ElementsAre(EqualsDocHitInfo(
@@ -3169,6 +3184,7 @@ TEST_F(QueryProcessorTest, NumericFilter) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(
       GetDocHitInfos(results.root_iterator.get()),
@@ -3191,8 +3207,7 @@ TEST_F(QueryProcessorTest, NumericFilterWithoutEnablingFeatureFails) {
           .Build();
   SectionId price_section_id = 0;
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -3212,6 +3227,7 @@ TEST_F(QueryProcessorTest, NumericFilterWithoutEnablingFeatureFails) {
   libtextclassifier3::StatusOr<QueryResults> result_or =
       query_processor_->ParseSearch(search_spec,
                                     ScoringSpecProto::RankingStrategy::NONE,
+                                    /*get_embedding_match_info=*/false,
                                     fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(result_or,
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
@@ -3235,8 +3251,7 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   SectionId prop1_section_id = 0;
@@ -3303,6 +3318,7 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
       QueryResults results,
       query_processor_->ParseSearch(search_spec,
                                     ScoringSpecProto::RankingStrategy::NONE,
+                                    /*get_embedding_match_info=*/false,
                                     fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()),
               ElementsAre(EqualsDocHitInfo(
@@ -3313,6 +3329,7 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()), IsEmpty());
 
@@ -3321,6 +3338,7 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(GetDocHitInfos(results.root_iterator.get()),
               ElementsAre(EqualsDocHitInfo(
@@ -3332,6 +3350,7 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(
       GetDocHitInfos(results.root_iterator.get()),
@@ -3346,6 +3365,7 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
   ICING_ASSERT_OK_AND_ASSIGN(
       results, query_processor_->ParseSearch(
                    search_spec, ScoringSpecProto::RankingStrategy::NONE,
+                   /*get_embedding_match_info=*/false,
                    fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(
       GetDocHitInfos(results.root_iterator.get()),
@@ -3361,8 +3381,7 @@ TEST_F(QueryProcessorTest, ParseAdvancedQueryShouldSetSearchStats) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -3398,6 +3417,7 @@ TEST_F(QueryProcessorTest, ParseAdvancedQueryShouldSetSearchStats) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds(), &search_stats));
 
   ASSERT_THAT(results.root_iterator->Advance(), IsOk());
@@ -3414,8 +3434,7 @@ TEST_F(QueryProcessorTest, UriFiltersIsNotTheRightMostNode) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
   ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
                                            .SetKey("namespace", "uri1")
@@ -3435,6 +3454,7 @@ TEST_F(QueryProcessorTest, UriFiltersIsNotTheRightMostNode) {
       QueryResults results,
       query_processor_->ParseSearch(
           search_spec, ScoringSpecProto::RankingStrategy::NONE,
+          /*get_embedding_match_info=*/false,
           fake_clock_.GetSystemTimeMilliseconds(), &search_stats));
 
   ICING_ASSERT_OK_AND_ASSIGN(
diff --git a/icing/query/suggestion-processor.cc b/icing/query/suggestion-processor.cc
index cebd205..f464604 100644
--- a/icing/query/suggestion-processor.cc
+++ b/icing/query/suggestion-processor.cc
@@ -278,9 +278,9 @@ SuggestionProcessor::QuerySuggestions(
   }
   ICING_ASSIGN_OR_RETURN(
       QueryResults query_results,
-      query_processor->ParseSearch(search_spec,
-                                   ScoringSpecProto::RankingStrategy::NONE,
-                                   current_time_ms));
+      query_processor->ParseSearch(
+          search_spec, ScoringSpecProto::RankingStrategy::NONE,
+          /*get_embedding_match_info=*/false, current_time_ms));
 
   ICING_ASSIGN_OR_RETURN(
       DocHitInfoIterator::TrimmedNode trimmed_node,
diff --git a/icing/query/suggestion-processor_test.cc b/icing/query/suggestion-processor_test.cc
index ba6be86..567eeae 100644
--- a/icing/query/suggestion-processor_test.cc
+++ b/icing/query/suggestion-processor_test.cc
@@ -15,6 +15,7 @@
 #include "icing/query/suggestion-processor.h"
 
 #include <cstdint>
+#include <limits>
 #include <memory>
 #include <string>
 #include <utility>
@@ -49,6 +50,7 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer-factory.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -139,8 +141,10 @@ class SuggestionProcessorTest : public Test {
         language_segmenter_,
         language_segmenter_factory::Create(segmenter_options));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/1000));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         suggestion_processor_,
@@ -198,8 +202,7 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_And) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -247,8 +250,7 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_AndNary) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -300,8 +302,7 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_Or) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -355,8 +356,7 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_OrNary) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -424,8 +424,7 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_NormalizedTerm) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -488,8 +487,7 @@ TEST_F(SuggestionProcessorTest, NonExistentPrefixTest) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -525,8 +523,7 @@ TEST_F(SuggestionProcessorTest, PrefixTrailingSpaceTest) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -562,8 +559,7 @@ TEST_F(SuggestionProcessorTest, NormalizePrefixTest) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -616,8 +612,7 @@ TEST_F(SuggestionProcessorTest, ParenthesesOperatorPrefixTest) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -665,8 +660,7 @@ TEST_F(SuggestionProcessorTest, OtherSpecialPrefixTest) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -729,8 +723,7 @@ TEST_F(SuggestionProcessorTest, SemanticSearchPrefixTest) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
@@ -779,8 +772,7 @@ TEST_F(SuggestionProcessorTest, InvalidPrefixTest) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ASSERT_THAT(schema_store_->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // These documents don't actually match to the tokens in the index. We're
diff --git a/icing/result/result-adjustment-info.cc b/icing/result/result-adjustment-info.cc
index 00ac379..6ae911c 100644
--- a/icing/result/result-adjustment-info.cc
+++ b/icing/result/result-adjustment-info.cc
@@ -16,29 +16,115 @@
 
 #include <string>
 #include <unordered_map>
+#include <unordered_set>
+#include <utility>
+#include <vector>
 
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/proto/scoring.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
+#include "icing/query/query-terms.h"
 #include "icing/result/projection-tree.h"
 #include "icing/result/snippet-context.h"
 #include "icing/schema/schema-store.h"
+#include "icing/schema/section.h"
+#include "icing/store/document-id.h"
+#include "icing/util/logging.h"
 
 namespace icing {
 namespace lib {
 
 namespace {
 
-SnippetContext CreateSnippetContext(const SearchSpecProto& search_spec,
-                                    const ResultSpecProto& result_spec,
-                                    SectionRestrictQueryTermsMap query_terms) {
+// Returns a map of document_id to a vector of SectionEmbeddingMatchInfoEntries
+// for the given embedding query results. For each document, only results for
+// the top max_sections_per_doc sections are returned. Only results for the
+// given document_ids are returned and only includes the top
+// max_sections_per_doc sections per document.
+SnippetContext::DocumentEmbeddingMatchInfoMap GetMatchInfoByDocumentAndSection(
+    const EmbeddingQueryResults& embedding_query_results,
+    const std::unordered_set<DocumentId>& documents_to_include,
+    int num_matches_per_property) {
+  SnippetContext::DocumentEmbeddingMatchInfoMap result_map;
+  // Maps from (document_id, section_id) to the match count for that section.
+  std::unordered_map<DocumentId, std::unordered_map<SectionId, int>>
+      section_match_count;
+
+  for (const auto& [query_vector_index, metric_type_map] :
+       embedding_query_results.result_infos) {
+    for (const auto& [metric_type, info_map] : metric_type_map) {
+      for (const auto& [doc_id, match_infos] : info_map) {
+        if (documents_to_include.find(doc_id) == documents_to_include.end()) {
+          continue;
+        }
+
+        if (match_infos.section_infos == nullptr) {
+          // No section info indicates that embedding match info is not
+          // enabled.
+          continue;
+        }
+
+        if (match_infos.section_infos->size() != match_infos.scores.size()) {
+          // This should never happen.
+          ICING_LOG(ERROR)
+              << "EmbeddingMatchInfos has mismatched section_infos and "
+                 "scores vectors for document with id "
+              << doc_id
+              << ". Section_infos size: " << match_infos.section_infos->size()
+              << ", scores size: " << match_infos.scores.size();
+          continue;
+        }
+        for (int i = 0; i < match_infos.scores.size(); ++i) {
+          SectionId section_id = match_infos.section_infos->at(i).section_id;
+          if (section_match_count[doc_id][section_id] >=
+              num_matches_per_property) {
+            continue;
+          }
+          result_map[doc_id].push_back(SnippetContext::EmbeddingMatchInfoEntry(
+              match_infos.scores[i], metric_type,
+              match_infos.section_infos->at(i).position, query_vector_index,
+              section_id));
+          ++section_match_count[doc_id][section_id];
+        }
+      }
+    }
+  }
+  return result_map;
+}
+
+SnippetContext CreateSnippetContext(
+    const SearchSpecProto& search_spec, const ResultSpecProto& result_spec,
+    const EmbeddingQueryResults& embedding_query_results,
+    const std::unordered_set<DocumentId>& documents_to_snippet_hint,
+    SectionRestrictQueryTermsMap query_terms) {
   if (result_spec.snippet_spec().num_to_snippet() > 0 &&
       result_spec.snippet_spec().num_matches_per_property() > 0) {
     // Needs snippeting
-    return SnippetContext(std::move(query_terms), result_spec.snippet_spec(),
-                          search_spec.term_match_type());
+    SnippetContext::EmbeddingQueryVectorMetadataMap
+        embedding_query_vector_metadata;
+    SnippetContext::DocumentEmbeddingMatchInfoMap embedding_match_info_map;
+    if (result_spec.snippet_spec().get_embedding_match_info()) {
+      for (int i = 0; i < search_spec.embedding_query_vectors_size(); ++i) {
+        const PropertyProto::VectorProto& query_vector =
+            search_spec.embedding_query_vectors(i);
+        int dimension = query_vector.values().size();
+        std::string model_signature = query_vector.model_signature();
+        embedding_query_vector_metadata[dimension][std::move(model_signature)]
+            .insert(i);
+      }
+      embedding_match_info_map = GetMatchInfoByDocumentAndSection(
+          embedding_query_results, documents_to_snippet_hint,
+          result_spec.snippet_spec().num_matches_per_property());
+    }
+    return SnippetContext(
+        std::move(query_terms), std::move(embedding_query_vector_metadata),
+        std::move(embedding_match_info_map), result_spec.snippet_spec(),
+        search_spec.term_match_type());
   }
   return SnippetContext(/*query_terms_in=*/{},
+                        /*embedding_query_vector_metadata_in=*/{},
+                        /*embedding_match_info_map_in=*/{},
                         ResultSpecProto::SnippetSpecProto::default_instance(),
                         TermMatchType::UNKNOWN);
 }
@@ -48,10 +134,13 @@ SnippetContext CreateSnippetContext(const SearchSpecProto& search_spec,
 ResultAdjustmentInfo::ResultAdjustmentInfo(
     const SearchSpecProto& search_spec, const ScoringSpecProto& scoring_spec,
     const ResultSpecProto& result_spec, const SchemaStore* schema_store,
+    const EmbeddingQueryResults& embedding_query_results,
+    std::unordered_set<DocumentId> documents_to_snippet_hint,
     SectionRestrictQueryTermsMap query_terms)
-    : snippet_context(CreateSnippetContext(search_spec, result_spec,
-                                           std::move(query_terms))),
-      remaining_num_to_snippet(snippet_context.snippet_spec.num_to_snippet()) {
+    : snippet_context(CreateSnippetContext(
+          search_spec, result_spec, embedding_query_results,
+          documents_to_snippet_hint, std::move(query_terms))),
+      remaining_num_to_snippet(result_spec.snippet_spec().num_to_snippet()) {
   for (const SchemaStore::ExpandedTypePropertyMask& type_field_mask :
        schema_store->ExpandTypePropertyMasks(
            result_spec.type_property_masks())) {
diff --git a/icing/result/result-adjustment-info.h b/icing/result/result-adjustment-info.h
index e859492..735005b 100644
--- a/icing/result/result-adjustment-info.h
+++ b/icing/result/result-adjustment-info.h
@@ -17,12 +17,16 @@
 
 #include <string>
 #include <unordered_map>
+#include <unordered_set>
 
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/proto/scoring.pb.h"
 #include "icing/proto/search.pb.h"
+#include "icing/query/query-terms.h"
 #include "icing/result/projection-tree.h"
 #include "icing/result/snippet-context.h"
 #include "icing/schema/schema-store.h"
+#include "icing/store/document-id.h"
 
 namespace icing {
 namespace lib {
@@ -40,11 +44,16 @@ struct ResultAdjustmentInfo {
   // Information needed for projection.
   std::unordered_map<std::string, ProjectionTree> projection_tree_map;
 
-  explicit ResultAdjustmentInfo(const SearchSpecProto& search_spec,
-                                const ScoringSpecProto& scoring_spec,
-                                const ResultSpecProto& result_spec,
-                                const SchemaStore* schema_store,
-                                SectionRestrictQueryTermsMap query_terms);
+  // documents_to_snippet_hint is a precalculated set of documents that are
+  // eligible for snippeting. It's intended to optimize the memory usage in
+  // result retrieval by reducing the embedding match info that needs to be
+  // cached for embedding snippetting.
+  explicit ResultAdjustmentInfo(
+      const SearchSpecProto& search_spec, const ScoringSpecProto& scoring_spec,
+      const ResultSpecProto& result_spec, const SchemaStore* schema_store,
+      const EmbeddingQueryResults& embedding_query_results,
+      std::unordered_set<DocumentId> documents_to_snippet_hint,
+      SectionRestrictQueryTermsMap query_terms);
 };
 
 }  // namespace lib
diff --git a/icing/result/result-adjustment-info_test.cc b/icing/result/result-adjustment-info_test.cc
index fd0551e..d539016 100644
--- a/icing/result/result-adjustment-info_test.cc
+++ b/icing/result/result-adjustment-info_test.cc
@@ -16,19 +16,27 @@
 
 #include <memory>
 #include <string>
+#include <unordered_map>
 #include <unordered_set>
 #include <vector>
 
+#include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/feature-flags.h"
+#include "icing/file/filesystem.h"
+#include "icing/index/embed/embedding-query-results.h"
+#include "icing/proto/document.pb.h"
 #include "icing/proto/scoring.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
+#include "icing/query/query-terms.h"
 #include "icing/result/projection-tree.h"
 #include "icing/result/snippet-context.h"
 #include "icing/schema-builder.h"
 #include "icing/schema/schema-store.h"
+#include "icing/store/document-id.h"
 #include "icing/testing/common-matchers.h"
+#include "icing/testing/embedding-test-utils.h"
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
@@ -40,11 +48,24 @@ namespace {
 
 using ::icing::lib::portable_equals_proto::EqualsProto;
 using ::testing::AnyOf;
+using ::testing::Contains;
 using ::testing::Eq;
 using ::testing::IsEmpty;
+using ::testing::Key;
 using ::testing::Pair;
 using ::testing::UnorderedElementsAre;
 
+constexpr DocumentId kDocumentId0 = 0;
+constexpr DocumentId kDocumentId1 = 1;
+constexpr DocumentId kDocumentId2 = 2;
+constexpr DocumentId kDocumentId3 = 3;
+
+constexpr SearchSpecProto::EmbeddingQueryMetricType::Code
+    EMBEDDING_METRIC_DOT_PRODUCT =
+        SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT;
+constexpr SearchSpecProto::EmbeddingQueryMetricType::Code
+    EMBEDDING_METRIC_COSINE = SearchSpecProto::EmbeddingQueryMetricType::COSINE;
+
 class ResultAdjustmentInfoTest : public testing::Test {
  protected:
   ResultAdjustmentInfoTest() : test_dir_(GetTestTempDir() + "/icing") {
@@ -63,8 +84,7 @@ class ResultAdjustmentInfoTest : public testing::Test {
             .AddType(SchemaTypeConfigBuilder().SetType("Phone"))
             .Build();
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
   }
 
@@ -79,9 +99,15 @@ class ResultAdjustmentInfoTest : public testing::Test {
   FakeClock fake_clock_;
 };
 
-SearchSpecProto CreateSearchSpec(TermMatchType::Code match_type) {
+SearchSpecProto CreateSearchSpec(
+    TermMatchType::Code match_type,
+    const std::vector<PropertyProto::VectorProto>& embedding_query_vectors,
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) {
   SearchSpecProto search_spec;
   search_spec.set_term_match_type(match_type);
+  search_spec.mutable_embedding_query_vectors()->Add(
+      embedding_query_vectors.begin(), embedding_query_vectors.end());
+  search_spec.set_embedding_query_metric_type(metric_type);
   return search_spec;
 }
 
@@ -101,30 +127,383 @@ ResultSpecProto CreateResultSpec(
 }
 
 TEST_F(ResultAdjustmentInfoTest,
-       ShouldConstructSnippetContextAccordingToSpecs) {
+       ShouldConstructSnippetContextAccordingToSpecs_snippetAll) {
   ResultSpecProto result_spec =
       CreateResultSpec(/*num_per_page=*/2, ResultSpecProto::NAMESPACE);
   result_spec.mutable_snippet_spec()->set_num_to_snippet(5);
   result_spec.mutable_snippet_spec()->set_num_matches_per_property(5);
   result_spec.mutable_snippet_spec()->set_max_window_utf32_length(5);
+  result_spec.mutable_snippet_spec()->set_get_embedding_match_info(true);
 
   SectionRestrictQueryTermsMap query_terms_map;
   query_terms_map.emplace("term1", std::unordered_set<std::string>());
 
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      CreateVector("my_model1", {1, -2, -4}),
+      CreateVector("my_model2", {1, -2, 3, -4}),
+      CreateVector("my_model3", {0.1, -0.2, 0.3}),
+      CreateVector("my_model1", {1, -2, -5})};
+  SearchSpecProto search_spec =
+      CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
+                       EMBEDDING_METRIC_DOT_PRODUCT);
+
+  EmbeddingQueryResults embedding_query_results;
+  EmbeddingMatchInfos& info_query0_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/0]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query0_doc0.AppendScore(1);
+  info_query0_doc0.AppendScore(1.7);
+  info_query0_doc0.AppendScore(3.3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+  EmbeddingMatchInfos& info_query1_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query1_doc0.AppendScore(2);
+  info_query1_doc0.AppendScore(1.7);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+  EmbeddingMatchInfos& info_query1_doc1 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId1];
+  info_query1_doc1.AppendScore(6.66);
+  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+  EmbeddingMatchInfos& info_query0_doc2 =
+      embedding_query_results
+          .result_infos[/*query_index=*/0][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId2];
+  info_query0_doc2.AppendScore(5.25);
+  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+  info_query0_doc2.AppendScore(1.33);
+  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/4);
+  EmbeddingMatchInfos& info_query1_doc3 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId3];
+  info_query1_doc3.AppendScore(3.25);
+  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+  info_query1_doc3.AppendScore(2.33);
+  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/2);
+
   ResultAdjustmentInfo result_adjustment_info(
-      CreateSearchSpec(TermMatchType::EXACT_ONLY),
-      CreateScoringSpec(/*is_descending_order=*/true), result_spec,
-      schema_store_.get(), query_terms_map);
+      search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
+      schema_store_.get(),
+      embedding_query_results, /*documents_to_snippet_hint=*/
+      {kDocumentId0, kDocumentId1, kDocumentId2, kDocumentId3},
+      query_terms_map);
+  const SnippetContext& snippet_context =
+      result_adjustment_info.snippet_context;
+
+  // Snippet context should be derived from the specs above.
+  EXPECT_THAT(snippet_context.query_terms, Contains(Key("term1")));
+
+  EXPECT_THAT(snippet_context.embedding_query_vector_metadata_map,
+              UnorderedElementsAre(
+                  Pair(3, UnorderedElementsAre(
+                              Pair("my_model1", UnorderedElementsAre(0, 3)),
+                              Pair("my_model3", UnorderedElementsAre(2)))),
+                  Pair(4, UnorderedElementsAre(
+                              Pair("my_model2", UnorderedElementsAre(1))))));
+
+  // Check embedding match info map -- this should contain all match infos.
+  // Document 0
+  EXPECT_THAT(
+      snippet_context.embedding_match_info_map,
+      Contains(Pair(kDocumentId0,
+                    UnorderedElementsAre(
+                        EqualsEmbeddingMatchInfoEntry(
+                            SnippetContext::EmbeddingMatchInfoEntry(
+                                /*score_in=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+                                /*position=*/0, /*query_vector_index=*/0,
+                                /*section_id=*/0)),
+                        EqualsEmbeddingMatchInfoEntry(
+                            SnippetContext::EmbeddingMatchInfoEntry(
+                                /*score=*/1.7, EMBEDDING_METRIC_DOT_PRODUCT,
+                                /*position=*/3, /*query_vector_index=*/0,
+                                /*section_id=*/0)),
+                        EqualsEmbeddingMatchInfoEntry(
+                            SnippetContext::EmbeddingMatchInfoEntry(
+                                /*score=*/2, EMBEDDING_METRIC_DOT_PRODUCT,
+                                /*position=*/0, /*query_vector_index=*/1,
+                                /*section_id=*/0)),
+                        EqualsEmbeddingMatchInfoEntry(
+                            SnippetContext::EmbeddingMatchInfoEntry(
+                                /*score=*/3.3, EMBEDDING_METRIC_DOT_PRODUCT,
+                                /*position=*/1, /*query_vector_index=*/0,
+                                /*section_id=*/1)),
+                        EqualsEmbeddingMatchInfoEntry(
+                            SnippetContext::EmbeddingMatchInfoEntry(
+                                /*score=*/1.7, EMBEDDING_METRIC_DOT_PRODUCT,
+                                /*position=*/2, /*query_vector_index=*/1,
+                                /*section_id=*/3))))));
+  // Document 1
+  EXPECT_THAT(snippet_context.embedding_match_info_map,
+              Contains(Pair(kDocumentId1,
+                            UnorderedElementsAre(EqualsEmbeddingMatchInfoEntry(
+                                SnippetContext::EmbeddingMatchInfoEntry(
+                                    /*score=*/6.66, EMBEDDING_METRIC_COSINE,
+                                    /*position=*/0, /*query_vector_index=*/1,
+                                    /*section_id=*/1))))));
+  // Document 2
+  EXPECT_THAT(
+      snippet_context.embedding_match_info_map,
+      Contains(Pair(
+          kDocumentId2,
+          UnorderedElementsAre(
+              EqualsEmbeddingMatchInfoEntry(
+                  SnippetContext::EmbeddingMatchInfoEntry(
+                      /*score=*/5.25, EMBEDDING_METRIC_COSINE,
+                      /*position=*/0, /*query_vector_index=*/0,
+                      /*section_id=*/1)),
+              EqualsEmbeddingMatchInfoEntry(
+                  SnippetContext::EmbeddingMatchInfoEntry(
+                      /*score=*/1.33, EMBEDDING_METRIC_COSINE, /*position=*/4,
+                      /*query_vector_index=*/0, /*section_id=*/1))))));
+  // Document 3
+  EXPECT_THAT(
+      snippet_context.embedding_match_info_map,
+      Contains(Pair(
+          kDocumentId3,
+          UnorderedElementsAre(EqualsEmbeddingMatchInfoEntry(
+                                   SnippetContext::EmbeddingMatchInfoEntry(
+                                       /*score=*/3.25, EMBEDDING_METRIC_COSINE,
+                                       /*position=*/1, /*query_vector_index=*/1,
+                                       /*section_id=*/1)),
+                               EqualsEmbeddingMatchInfoEntry(
+                                   SnippetContext::EmbeddingMatchInfoEntry(
+                                       /*score=*/2.33, EMBEDDING_METRIC_COSINE,
+                                       /*position=*/2, /*query_vector_index=*/1,
+                                       /*section_id=*/1))))));
+
+  EXPECT_THAT(snippet_context.snippet_spec,
+              EqualsProto(result_spec.snippet_spec()));
+  EXPECT_THAT(snippet_context.match_type, Eq(TermMatchType::EXACT_ONLY));
+  EXPECT_THAT(result_adjustment_info.remaining_num_to_snippet, Eq(5));
+}
+
+TEST_F(
+    ResultAdjustmentInfoTest,
+    ShouldConstructSnippetContextAccordingToSpecs_hitsEmbeddingSnippetLimit) {
+  ResultSpecProto result_spec =
+      CreateResultSpec(/*num_per_page=*/2, ResultSpecProto::NAMESPACE);
+  result_spec.mutable_snippet_spec()->set_num_to_snippet(1);
+  result_spec.mutable_snippet_spec()->set_num_matches_per_property(2);
+  result_spec.mutable_snippet_spec()->set_max_window_utf32_length(5);
+  result_spec.mutable_snippet_spec()->set_get_embedding_match_info(true);
+
+  SectionRestrictQueryTermsMap query_terms_map;
+  query_terms_map.emplace("term1", std::unordered_set<std::string>());
+
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      CreateVector("my_model1", {1, -2, -4}),
+      CreateVector("my_model2", {1, -2, 3, -4}),
+      CreateVector("my_model3", {0.1, -0.2, 0.3}),
+      CreateVector("my_model1", {1, -2, -5})};
+  SearchSpecProto search_spec =
+      CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
+                       EMBEDDING_METRIC_DOT_PRODUCT);
+
+  EmbeddingQueryResults embedding_query_results;
+  EmbeddingMatchInfos& info_query0_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/0]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query0_doc0.AppendScore(1);
+  info_query0_doc0.AppendScore(1.7);
+  info_query0_doc0.AppendScore(3.3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+  EmbeddingMatchInfos& info_query1_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query1_doc0.AppendScore(2);
+  info_query1_doc0.AppendScore(1.7);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+  EmbeddingMatchInfos& info_query1_doc1 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId1];
+  info_query1_doc1.AppendScore(6.66);
+  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+  EmbeddingMatchInfos& info_query0_doc2 =
+      embedding_query_results
+          .result_infos[/*query_index=*/0][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId2];
+  info_query0_doc2.AppendScore(5.25);
+  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+  info_query0_doc2.AppendScore(1.33);
+  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/4);
+  EmbeddingMatchInfos& info_query1_doc3 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId3];
+  info_query1_doc3.AppendScore(3.25);
+  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+  info_query1_doc3.AppendScore(2.33);
+  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/2);
+
+  ResultAdjustmentInfo result_adjustment_info(
+      search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
+      schema_store_.get(), embedding_query_results,
+      /*documents_to_snippet_hint=*/{kDocumentId0}, query_terms_map);
   const SnippetContext snippet_context = result_adjustment_info.snippet_context;
 
   // Snippet context should be derived from the specs above.
-  EXPECT_TRUE(
-      result_adjustment_info.snippet_context.query_terms.find("term1") !=
-      result_adjustment_info.snippet_context.query_terms.end());
-  EXPECT_THAT(result_adjustment_info.snippet_context.snippet_spec,
+  EXPECT_THAT(snippet_context.query_terms, Contains(Key("term1")));
+
+  EXPECT_THAT(snippet_context.embedding_query_vector_metadata_map,
+              UnorderedElementsAre(
+                  Pair(3, UnorderedElementsAre(
+                              Pair("my_model1", UnorderedElementsAre(0, 3)),
+                              Pair("my_model3", UnorderedElementsAre(2)))),
+                  Pair(4, UnorderedElementsAre(
+                              Pair("my_model2", UnorderedElementsAre(1))))));
+
+  // Check embedding match info map
+  // Should only contain Document 0, with only the top 2 matches per property.
+  EXPECT_THAT(
+      snippet_context.embedding_match_info_map,
+      UnorderedElementsAre(Pair(
+          kDocumentId0, UnorderedElementsAre(
+                            EqualsEmbeddingMatchInfoEntry(
+                                SnippetContext::EmbeddingMatchInfoEntry(
+                                    /*score=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
+                                    /*position=*/0, /*query_vector_index=*/0,
+                                    /*section_id=*/0)),
+                            EqualsEmbeddingMatchInfoEntry(
+                                SnippetContext::EmbeddingMatchInfoEntry(
+                                    /*score=*/2, EMBEDDING_METRIC_DOT_PRODUCT,
+                                    /*position=*/0, /*query_vector_index=*/1,
+                                    /*section_id=*/0)),
+                            EqualsEmbeddingMatchInfoEntry(
+                                SnippetContext::EmbeddingMatchInfoEntry(
+                                    /*score=*/3.3, EMBEDDING_METRIC_DOT_PRODUCT,
+                                    /*position=*/1, /*query_vector_index=*/0,
+                                    /*section_id=*/1)),
+                            EqualsEmbeddingMatchInfoEntry(
+                                SnippetContext::EmbeddingMatchInfoEntry(
+                                    /*score=*/1.7, EMBEDDING_METRIC_DOT_PRODUCT,
+                                    /*position=*/2, /*query_vector_index=*/1,
+                                    /*section_id=*/3))))));
+
+  EXPECT_THAT(snippet_context.snippet_spec,
               EqualsProto(result_spec.snippet_spec()));
-  EXPECT_THAT(result_adjustment_info.snippet_context.match_type,
-              Eq(TermMatchType::EXACT_ONLY));
+  EXPECT_THAT(snippet_context.match_type, Eq(TermMatchType::EXACT_ONLY));
+  EXPECT_THAT(result_adjustment_info.remaining_num_to_snippet, Eq(1));
+}
+
+TEST_F(
+    ResultAdjustmentInfoTest,
+    ShouldConstructSnippetContextAccordingToSpecs_getEmbeddingMatchInfoFalse) {
+  ResultSpecProto result_spec =
+      CreateResultSpec(/*num_per_page=*/2, ResultSpecProto::NAMESPACE);
+  result_spec.mutable_snippet_spec()->set_num_to_snippet(5);
+  result_spec.mutable_snippet_spec()->set_num_matches_per_property(5);
+  result_spec.mutable_snippet_spec()->set_max_window_utf32_length(5);
+  result_spec.mutable_snippet_spec()->set_get_embedding_match_info(false);
+
+  SectionRestrictQueryTermsMap query_terms_map;
+  query_terms_map.emplace("term1", std::unordered_set<std::string>());
+
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      CreateVector("my_model1", {1, -2, -4}),
+      CreateVector("my_model2", {1, -2, 3, -4})};
+  SearchSpecProto search_spec =
+      CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
+                       EMBEDDING_METRIC_DOT_PRODUCT);
+  EmbeddingQueryResults embedding_query_results;
+  EmbeddingMatchInfos& info_query0_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/0]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query0_doc0.AppendScore(1);
+  info_query0_doc0.AppendScore(1.7);
+  info_query0_doc0.AppendScore(3.3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+  EmbeddingMatchInfos& info_query1_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query1_doc0.AppendScore(2);
+  info_query1_doc0.AppendScore(1.7);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+  EmbeddingMatchInfos& info_query1_doc1 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId1];
+  info_query1_doc1.AppendScore(6.66);
+  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+
+  ResultAdjustmentInfo result_adjustment_info(
+      search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
+      schema_store_.get(), embedding_query_results,
+      /*documents_to_snippet_hint=*/{kDocumentId0, kDocumentId1},
+      query_terms_map);
+  const SnippetContext snippet_context = result_adjustment_info.snippet_context;
+
+  // Snippet context should be derived from the specs above.
+  EXPECT_THAT(snippet_context.query_terms, Contains(Key("term1")));
+  EXPECT_THAT(snippet_context.snippet_spec,
+              EqualsProto(result_spec.snippet_spec()));
+  EXPECT_THAT(snippet_context.embedding_query_vector_metadata_map, IsEmpty());
+  EXPECT_THAT(result_adjustment_info.snippet_context.embedding_match_info_map,
+              IsEmpty());
+  EXPECT_THAT(snippet_context.match_type, Eq(TermMatchType::EXACT_ONLY));
+  EXPECT_THAT(result_adjustment_info.remaining_num_to_snippet, Eq(5));
+}
+
+TEST_F(
+    ResultAdjustmentInfoTest,
+    ShouldConstructSnippetContextAccordingToSpecs_emptyEmbeddingQueryResults) {
+  ResultSpecProto result_spec =
+      CreateResultSpec(/*num_per_page=*/2, ResultSpecProto::NAMESPACE);
+  result_spec.mutable_snippet_spec()->set_num_to_snippet(5);
+  result_spec.mutable_snippet_spec()->set_num_matches_per_property(5);
+  result_spec.mutable_snippet_spec()->set_max_window_utf32_length(5);
+  result_spec.mutable_snippet_spec()->set_get_embedding_match_info(false);
+
+  SectionRestrictQueryTermsMap query_terms_map;
+  query_terms_map.emplace("term1", std::unordered_set<std::string>());
+
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      CreateVector("my_model1", {1, -2, -4}),
+      CreateVector("my_model2", {1, -2, 3, -4})};
+  SearchSpecProto search_spec =
+      CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
+                       EMBEDDING_METRIC_DOT_PRODUCT);
+
+  ResultAdjustmentInfo result_adjustment_info(
+      search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
+      schema_store_.get(), EmbeddingQueryResults(),
+      /*documents_to_snippet_hint=*/{kDocumentId0, kDocumentId1},
+      query_terms_map);
+  const SnippetContext snippet_context = result_adjustment_info.snippet_context;
+
+  // Snippet context should be derived from the specs above.
+  EXPECT_THAT(snippet_context.snippet_spec,
+              EqualsProto(result_spec.snippet_spec()));
+  EXPECT_THAT(result_adjustment_info.snippet_context
+                  .embedding_query_vector_metadata_map,
+              IsEmpty());
+  EXPECT_THAT(result_adjustment_info.snippet_context.embedding_match_info_map,
+              IsEmpty());
+  EXPECT_THAT(snippet_context.match_type, Eq(TermMatchType::EXACT_ONLY));
   EXPECT_THAT(result_adjustment_info.remaining_num_to_snippet, Eq(5));
 }
 
@@ -136,19 +515,60 @@ TEST_F(ResultAdjustmentInfoTest, NoSnippetingShouldReturnNull) {
   result_spec.mutable_snippet_spec()->set_num_to_snippet(0);
   result_spec.mutable_snippet_spec()->set_num_matches_per_property(5);
   result_spec.mutable_snippet_spec()->set_max_window_utf32_length(5);
+  result_spec.mutable_snippet_spec()->set_get_embedding_match_info(true);
 
   SectionRestrictQueryTermsMap query_terms_map;
   query_terms_map.emplace("term1", std::unordered_set<std::string>());
 
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      CreateVector("my_model1", {1, -2, -4}),
+      CreateVector("my_model2", {1, -2, 3, -4})};
+  SearchSpecProto search_spec =
+      CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
+                       SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT);
+  EmbeddingQueryResults embedding_query_results;
+  EmbeddingMatchInfos& info_query0_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/0]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query0_doc0.AppendScore(1);
+  info_query0_doc0.AppendScore(1.7);
+  info_query0_doc0.AppendScore(3.3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
+  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+  EmbeddingMatchInfos& info_query1_doc0 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1]
+                       [search_spec.embedding_query_metric_type()]
+                       [kDocumentId0];
+  info_query1_doc0.AppendScore(2);
+  info_query1_doc0.AppendScore(1.7);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
+  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+  EmbeddingMatchInfos& info_query1_doc1 =
+      embedding_query_results
+          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
+                       [kDocumentId1];
+  info_query1_doc1.AppendScore(6.66);
+  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+
   ResultAdjustmentInfo result_adjustment_info(
-      CreateSearchSpec(TermMatchType::EXACT_ONLY),
-      CreateScoringSpec(/*is_descending_order=*/true), result_spec,
-      schema_store_.get(), query_terms_map);
+      search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
+      schema_store_.get(), embedding_query_results,
+      /*documents_to_snippet_hint=*/{kDocumentId0, kDocumentId1},
+      query_terms_map);
 
   EXPECT_THAT(result_adjustment_info.snippet_context.query_terms, IsEmpty());
   EXPECT_THAT(
       result_adjustment_info.snippet_context.snippet_spec,
       EqualsProto(ResultSpecProto::SnippetSpecProto::default_instance()));
+  EXPECT_THAT(result_adjustment_info.snippet_context
+                  .embedding_query_vector_metadata_map,
+              IsEmpty());
+  EXPECT_THAT(result_adjustment_info.snippet_context.embedding_match_info_map,
+              IsEmpty());
   EXPECT_THAT(result_adjustment_info.snippet_context.match_type,
               TermMatchType::UNKNOWN);
   EXPECT_THAT(result_adjustment_info.remaining_num_to_snippet, Eq(0));
@@ -175,9 +595,12 @@ TEST_F(ResultAdjustmentInfoTest,
   wildcard_type_property_mask->add_paths("wild.card");
 
   ResultAdjustmentInfo result_adjustment_info(
-      CreateSearchSpec(TermMatchType::EXACT_ONLY),
+      CreateSearchSpec(TermMatchType::EXACT_ONLY,
+                       /*embedding_query_vectors=*/{},
+                       SearchSpecProto::EmbeddingQueryMetricType::UNKNOWN),
       CreateScoringSpec(/*is_descending_order=*/true), result_spec,
-      schema_store_.get(),
+      schema_store_.get(), EmbeddingQueryResults(),
+      /*documents_to_snippet_hint=*/{kDocumentId0, kDocumentId1},
       /*query_terms=*/{});
 
   ProjectionTree email_projection_tree =
diff --git a/icing/result/result-retriever-v2.cc b/icing/result/result-retriever-v2.cc
index e50262b..4d221f3 100644
--- a/icing/result/result-retriever-v2.cc
+++ b/icing/result/result-retriever-v2.cc
@@ -37,6 +37,7 @@
 #include "icing/schema/section.h"
 #include "icing/scoring/scored-document-hit.h"
 #include "icing/store/document-filter-data.h"
+#include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/store/namespace-id.h"
 #include "icing/tokenization/language-segmenter.h"
@@ -72,7 +73,8 @@ void ApplyProjection(const ResultAdjustmentInfo* adjustment_info,
 
 bool ApplySnippet(ResultAdjustmentInfo* adjustment_info,
                   const SnippetRetriever& snippet_retriever,
-                  const DocumentProto& document, SectionIdMask section_id_mask,
+                  const DocumentProto& document, DocumentId doc_id,
+                  SectionIdMask section_id_mask,
                   SearchResultProto::ResultProto* result) {
   if (adjustment_info == nullptr) {
     return false;
@@ -84,8 +86,7 @@ bool ApplySnippet(ResultAdjustmentInfo* adjustment_info,
   if (snippet_context.snippet_spec.num_matches_per_property() > 0 &&
       remaining_num_to_snippet > 0) {
     SnippetProto snippet_proto = snippet_retriever.RetrieveSnippet(
-        snippet_context.query_terms, snippet_context.match_type,
-        snippet_context.snippet_spec, document, section_id_mask);
+        snippet_context, document, doc_id, section_id_mask);
     *result->mutable_snippet() = std::move(snippet_proto);
     --remaining_num_to_snippet;
     return true;
@@ -177,8 +178,10 @@ std::pair<PageResult, bool> ResultRetrieverV2::RetrieveNextPage(
       continue;
     }
 
-    libtextclassifier3::StatusOr<DocumentProto> document_or = doc_store_.Get(
-        next_best_document_hit.parent_scored_document_hit().document_id());
+    DocumentId doc_id =
+        next_best_document_hit.parent_scored_document_hit().document_id();
+    libtextclassifier3::StatusOr<DocumentProto> document_or =
+        doc_store_.Get(doc_id);
     if (!document_or.ok()) {
       // Skip the document if getting errors.
       ICING_LOG(WARNING) << "Fail to fetch document from document store: "
@@ -193,7 +196,7 @@ std::pair<PageResult, bool> ResultRetrieverV2::RetrieveNextPage(
     SearchResultProto::ResultProto result;
     // Add parent snippet if requested.
     if (ApplySnippet(result_state.parent_adjustment_info(), *snippet_retriever_,
-                     document,
+                     document, doc_id,
                      next_best_document_hit.parent_scored_document_hit()
                          .hit_section_id_mask(),
                      &result)) {
@@ -218,8 +221,9 @@ std::pair<PageResult, bool> ResultRetrieverV2::RetrieveNextPage(
         break;
       }
 
+      DocumentId child_doc_id = child_scored_document_hit.document_id();
       libtextclassifier3::StatusOr<DocumentProto> child_document_or =
-          doc_store_.Get(child_scored_document_hit.document_id());
+          doc_store_.Get(child_doc_id);
       if (!child_document_or.ok()) {
         // Skip the document if getting errors.
         ICING_LOG(WARNING)
@@ -235,7 +239,7 @@ std::pair<PageResult, bool> ResultRetrieverV2::RetrieveNextPage(
           result.add_joined_results();
       // Add child snippet if requested.
       ApplySnippet(result_state.child_adjustment_info(), *snippet_retriever_,
-                   child_document,
+                   child_document, child_doc_id,
                    child_scored_document_hit.hit_section_id_mask(),
                    child_result);
 
diff --git a/icing/result/result-retriever-v2_group-result-limiter_test.cc b/icing/result/result-retriever-v2_group-result-limiter_test.cc
index 0d59e41..964e92e 100644
--- a/icing/result/result-retriever-v2_group-result-limiter_test.cc
+++ b/icing/result/result-retriever-v2_group-result-limiter_test.cc
@@ -12,6 +12,8 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+#include <cstdint>
+#include <limits>
 #include <memory>
 #include <vector>
 
@@ -40,6 +42,7 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
@@ -81,16 +84,18 @@ class ResultRetrieverV2GroupResultLimiterTest : public testing::Test {
     ICING_ASSERT_OK_AND_ASSIGN(
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/10000));
+
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     SchemaProto schema;
     schema.add_types()->set_schema_type("Document");
     schema.add_types()->set_schema_type("Message");
     schema.add_types()->set_schema_type("Person");
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        std::move(schema), /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        std::move(schema), /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
diff --git a/icing/result/result-retriever-v2_projection_test.cc b/icing/result/result-retriever-v2_projection_test.cc
index 1ac0681..dfe7bb7 100644
--- a/icing/result/result-retriever-v2_projection_test.cc
+++ b/icing/result/result-retriever-v2_projection_test.cc
@@ -12,22 +12,28 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+#include <cstdint>
 #include <limits>
 #include <memory>
+#include <string>
+#include <unordered_set>
+#include <utility>
 #include <vector>
 
 #include "gtest/gtest.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
+#include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/portable/equals-proto.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
+#include "icing/query/query-terms.h"
 #include "icing/result/page-result.h"
-#include "icing/result/projection-tree.h"
 #include "icing/result/result-adjustment-info.h"
 #include "icing/result/result-retriever-v2.h"
 #include "icing/result/result-state-v2.h"
@@ -36,6 +42,7 @@
 #include "icing/schema/section.h"
 #include "icing/scoring/priority-queue-scored-document-hits-ranker.h"
 #include "icing/scoring/scored-document-hit.h"
+#include "icing/store/document-filter-data.h"
 #include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/testing/common-matchers.h"
@@ -44,7 +51,9 @@
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
@@ -79,8 +88,11 @@ class ResultRetrieverV2ProjectionTest : public testing::Test {
     ICING_ASSERT_OK_AND_ASSIGN(
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/10000));
+
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     SchemaProto schema =
         SchemaBuilder()
@@ -183,8 +195,7 @@ class ResultRetrieverV2ProjectionTest : public testing::Test {
                          .Build())
             .Build();
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
 
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -311,7 +322,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTopLevelLeadNodeFieldPath) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          /*documents_to_snippet=*/
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -414,7 +427,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionNestedLeafNodeFieldPath) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -528,7 +542,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionIntermediateNodeFieldPath) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -646,7 +661,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleNestedFieldPaths) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -747,7 +763,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionEmptyFieldPath) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -831,7 +848,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionInvalidFieldPath) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -916,7 +934,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionValidAndInvalidFieldPath) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -999,11 +1018,12 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesNoWildcards) {
       std::make_unique<
           PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
           std::move(scored_document_hits), /*is_descending=*/false),
-      //*parent_adjustment_info=*/
+      /*parent_adjustment_info=*/
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1094,7 +1114,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesWildcard) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1189,7 +1210,8 @@ TEST_F(ResultRetrieverV2ProjectionTest,
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1293,7 +1315,8 @@ TEST_F(ResultRetrieverV2ProjectionTest,
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1401,7 +1424,8 @@ TEST_F(ResultRetrieverV2ProjectionTest,
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1532,12 +1556,14 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionJoinDocuments) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), parent_result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), child_result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       parent_result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1641,7 +1667,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphism) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1728,7 +1755,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTransitivePolymorphism) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1802,7 +1830,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id},
+          SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1881,7 +1911,8 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphismMerge) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>(), SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1964,7 +1995,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleParentPolymorphism) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id},
+          SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
   ICING_ASSERT_OK_AND_ASSIGN(
diff --git a/icing/result/result-retriever-v2_snippet_test.cc b/icing/result/result-retriever-v2_snippet_test.cc
index 114637e..09b691e 100644
--- a/icing/result/result-retriever-v2_snippet_test.cc
+++ b/icing/result/result-retriever-v2_snippet_test.cc
@@ -12,21 +12,29 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+#include <cstdint>
 #include <limits>
 #include <memory>
+#include <string>
 #include <string_view>
+#include <unordered_set>
+#include <utility>
 #include <vector>
 
 #include "gtest/gtest.h"
+#include "icing/absl_ports/mutex.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
+#include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/portable/equals-proto.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
+#include "icing/query/query-terms.h"
 #include "icing/result/page-result.h"
 #include "icing/result/result-adjustment-info.h"
 #include "icing/result/result-retriever-v2.h"
@@ -36,15 +44,19 @@
 #include "icing/schema/section.h"
 #include "icing/scoring/priority-queue-scored-document-hits-ranker.h"
 #include "icing/scoring/scored-document-hit.h"
+#include "icing/store/document-filter-data.h"
 #include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/testing/common-matchers.h"
+#include "icing/testing/embedding-test-utils.h"
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-data.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/snippet-helpers.h"
@@ -61,6 +73,15 @@ using ::testing::Eq;
 using ::testing::IsEmpty;
 using ::testing::SizeIs;
 
+constexpr SearchSpecProto::EmbeddingQueryMetricType::Code
+    EMBEDDING_METRIC_UNKNOWN =
+        SearchSpecProto::EmbeddingQueryMetricType::UNKNOWN;
+constexpr SearchSpecProto::EmbeddingQueryMetricType::Code
+    EMBEDDING_METRIC_DOT_PRODUCT =
+        SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT;
+constexpr SearchSpecProto::EmbeddingQueryMetricType::Code
+    EMBEDDING_METRIC_COSINE = SearchSpecProto::EmbeddingQueryMetricType::COSINE;
+
 class ResultRetrieverV2SnippetTest : public testing::Test {
  protected:
   ResultRetrieverV2SnippetTest() : test_dir_(GetTestTempDir() + "/icing") {
@@ -83,8 +104,11 @@ class ResultRetrieverV2SnippetTest : public testing::Test {
     ICING_ASSERT_OK_AND_ASSIGN(
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/10000));
+
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     SchemaProto schema =
         SchemaBuilder()
@@ -100,7 +124,17 @@ class ResultRetrieverV2SnippetTest : public testing::Test {
                                      .SetName("body")
                                      .SetDataTypeString(TERM_MATCH_EXACT,
                                                         TOKENIZER_PLAIN)
-                                     .SetCardinality(CARDINALITY_OPTIONAL)))
+                                     .SetCardinality(CARDINALITY_OPTIONAL))
+                    .AddProperty(
+                        PropertyConfigBuilder()
+                            .SetName("embedding1")
+                            .SetDataTypeVector(EMBEDDING_INDEXING_LINEAR_SEARCH)
+                            .SetCardinality(CARDINALITY_REPEATED))
+                    .AddProperty(
+                        PropertyConfigBuilder()
+                            .SetName("embedding2")
+                            .SetDataTypeVector(EMBEDDING_INDEXING_LINEAR_SEARCH)
+                            .SetCardinality(CARDINALITY_REPEATED)))
             .AddType(SchemaTypeConfigBuilder().SetType("Person").AddProperty(
                 PropertyConfigBuilder()
                     .SetName("name")
@@ -108,8 +142,7 @@ class ResultRetrieverV2SnippetTest : public testing::Test {
                     .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
 
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -172,6 +205,13 @@ DocumentProto CreateEmailDocument(int id) {
       .SetSchema("Email")
       .AddStringProperty("subject", "subject foo " + std::to_string(id))
       .AddStringProperty("body", "body bar " + std::to_string(id))
+      .AddVectorProperty("embedding1",
+                         CreateVector("my_model1", {1, 2, 3 + (float)id}),
+                         CreateVector("my_model2", {1, 2, 3, 4 + (float)id}),
+                         CreateVector("my_model1", {2, 3, 4 + (float)id}))
+      .AddVectorProperty(
+          "embedding2", CreateVector("my_model2", {-1, -2, -3, -4 + (float)id}),
+          CreateVector("my_model1", {-1, -2, -6 + (float)id}))
       .SetCreationTimestampMs(1574365086666 + id)
       .Build();
 }
@@ -193,9 +233,15 @@ SectionIdMask CreateSectionIdMask(const std::vector<SectionId>& section_ids) {
   return mask;
 }
 
-SearchSpecProto CreateSearchSpec(TermMatchType::Code match_type) {
+SearchSpecProto CreateSearchSpec(
+    TermMatchType::Code match_type,
+    const std::vector<PropertyProto::VectorProto>& embedding_query_vectors = {},
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type =
+        EMBEDDING_METRIC_UNKNOWN) {
   SearchSpecProto search_spec;
   search_spec.set_term_match_type(match_type);
+  search_spec.mutable_embedding_query_vectors()->Add(
+      embedding_query_vectors.begin(), embedding_query_vectors.end());
   return search_spec;
 }
 
@@ -212,6 +258,49 @@ ResultSpecProto CreateResultSpec(int num_per_page) {
   return result_spec;
 }
 
+EmbeddingMatchSnippetProto CreateEmbeddingMatchSnippetProto(
+    double score, int query_index,
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) {
+  EmbeddingMatchSnippetProto match_snippet;
+  match_snippet.set_semantic_score(score);
+  match_snippet.set_embedding_query_vector_index(query_index);
+  match_snippet.set_embedding_query_metric_type(metric_type);
+  return match_snippet;
+}
+
+EmbeddingQueryResults CreateEmailEmbeddingQueryResults(int num_documents) {
+  SectionId embedding1_section_id = 1;
+  SectionId embedding2_section_id = 2;
+  EmbeddingQueryResults embedding_query_results;
+
+  for (int doc_id = 0; doc_id < num_documents; ++doc_id) {
+    EmbeddingMatchInfos& info_model1 =
+        embedding_query_results
+            .result_infos[/*query_index=*/0][EMBEDDING_METRIC_DOT_PRODUCT]
+                         [doc_id];
+    info_model1.AppendScore(1.1 + doc_id);
+    info_model1.AppendScore(2.2 + doc_id);
+    // {2, 3, 4 + doc_id}, position 2
+    info_model1.AppendSectionInfo(
+        embedding1_section_id,
+        /*position_in_section_for_dimension_and_signature=*/1);
+    // {-1, -2, -6 + doc_id}, position 1
+    info_model1.AppendSectionInfo(
+        embedding2_section_id,
+        /*position_in_section_for_dimension_and_signature=*/0);
+
+    EmbeddingMatchInfos& info_model2 =
+        embedding_query_results
+            .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE][doc_id];
+    info_model2.AppendScore(3.3 + doc_id);
+    // {1, 2, 3, 4 + doc_id}, position 1
+    info_model2.AppendSectionInfo(
+        embedding1_section_id,
+        /*position_in_section_for_dimension_and_signature=*/0);
+  }
+  return embedding_query_results;
+}
+
 TEST_F(ResultRetrieverV2SnippetTest,
        DefaultSnippetSpecShouldDisableSnippeting) {
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -249,7 +338,10 @@ TEST_F(ResultRetrieverV2SnippetTest,
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/true), result_spec,
-          schema_store_.get(), SectionRestrictQueryTermsMap()),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
+          SectionRestrictQueryTermsMap()),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
   PageResult page_result =
       result_retriever
@@ -304,7 +396,9 @@ TEST_F(ResultRetrieverV2SnippetTest, SimpleSnippeted) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
@@ -419,7 +513,9 @@ TEST_F(ResultRetrieverV2SnippetTest, OnlyOneDocumentSnippeted) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
@@ -461,7 +557,7 @@ TEST_F(ResultRetrieverV2SnippetTest, OnlyOneDocumentSnippeted) {
               EqualsProto(SnippetProto::default_instance()));
 }
 
-TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllResults) {
+TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfo) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
       document_store_->Put(CreateEmailDocument(/*id=*/1)));
@@ -475,8 +571,9 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllResults) {
       document_store_->Put(CreateEmailDocument(/*id=*/3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
-  std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "subject"),
-                                            GetSectionId("Email", "body")};
+  std::vector<SectionId> hit_section_ids = {
+      GetSectionId("Email", "subject"), GetSectionId("Email", "body"),
+      GetSectionId("Email", "embedding1"), GetSectionId("Email", "embedding2")};
   SectionIdMask hit_section_id_mask = CreateSectionIdMask(hit_section_ids);
   std::vector<ScoredDocumentHit> scored_document_hits = {
       {document_id1, hit_section_id_mask, /*score=*/0},
@@ -489,19 +586,206 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllResults) {
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
-  snippet_spec.set_num_to_snippet(5);
+  snippet_spec.set_get_embedding_match_info(true);
   ResultSpecProto result_spec = CreateResultSpec(/*num_per_page=*/3);
   *result_spec.mutable_snippet_spec() = std::move(snippet_spec);
 
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      CreateVector("my_model1", {-1, -1, 1}),
+      CreateVector("my_model2", {-1, 1, -1, -1})};
+  EmbeddingQueryResults embedding_query_results =
+      CreateEmailEmbeddingQueryResults(/*num_documents=*/2);
+
   ResultStateV2 result_state(
       std::make_unique<
           PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
           std::move(scored_document_hits), /*is_descending=*/false),
       /*parent_adjustment_info=*/
       std::make_unique<ResultAdjustmentInfo>(
-          CreateSearchSpec(TermMatchType::EXACT_ONLY),
+          CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
+                           EMBEDDING_METRIC_DOT_PRODUCT),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(),
+          schema_store_.get(), embedding_query_results,
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
+          SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
+      /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
+
+  PageResult page_result =
+      result_retriever
+          ->RetrieveNextPage(result_state,
+                             fake_clock_.GetSystemTimeMilliseconds())
+          .first;
+  ASSERT_THAT(page_result.results, SizeIs(3));
+  EXPECT_THAT(page_result.num_results_with_snippets, Eq(3));
+
+  // Document 1
+  const DocumentProto& result_document_one =
+      page_result.results.at(0).document();
+  const SnippetProto& result_snippet_one = page_result.results.at(0).snippet();
+  EXPECT_THAT(result_document_one, EqualsProto(CreateEmailDocument(/*id=*/1)));
+  EXPECT_THAT(result_snippet_one.entries(), SizeIs(5));
+
+  // 1 'body' snippet entry
+  EXPECT_THAT(result_snippet_one.entries(0).property_name(), Eq("body"));
+  std::string_view content = GetString(
+      &result_document_one, result_snippet_one.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_one.entries(0)),
+              ElementsAre("body bar 1"));
+  EXPECT_THAT(GetMatches(content, result_snippet_one.entries(0)),
+              ElementsAre("bar"));
+
+  // 2 'embedding1' snippet entries
+  EXPECT_THAT(result_snippet_one.entries(1).property_name(),
+              Eq("embedding1[1]"));
+  EXPECT_THAT(result_snippet_one.entries(1).embedding_matches(),
+              ElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+                  /*score=*/3.3, /*query_index=*/1, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(result_snippet_one.entries(2).property_name(),
+              Eq("embedding1[2]"));
+  EXPECT_THAT(
+      result_snippet_one.entries(2).embedding_matches(),
+      ElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/1.1, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT))));
+
+  // 1 'embedding2' snippet entry
+  EXPECT_THAT(result_snippet_one.entries(3).property_name(),
+              Eq("embedding2[1]"));
+  EXPECT_THAT(
+      result_snippet_one.entries(3).embedding_matches(),
+      ElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/2.2, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT))));
+
+  // 1 'subject' snippet entry
+  EXPECT_THAT(result_snippet_one.entries(4).property_name(), Eq("subject"));
+  content = GetString(&result_document_one,
+                      result_snippet_one.entries(4).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_one.entries(4)),
+              ElementsAre("subject foo 1"));
+  EXPECT_THAT(GetMatches(content, result_snippet_one.entries(4)),
+              ElementsAre("foo"));
+
+  // Document 2
+  const DocumentProto& result_document_two =
+      page_result.results.at(1).document();
+  const SnippetProto& result_snippet_two = page_result.results.at(1).snippet();
+  EXPECT_THAT(result_document_two, EqualsProto(CreateEmailDocument(/*id=*/2)));
+  EXPECT_THAT(result_snippet_two.entries(), SizeIs(5));
+  // 1 'body' snippet entry
+  EXPECT_THAT(result_snippet_two.entries(0).property_name(), Eq("body"));
+  content = GetString(&result_document_two,
+                      result_snippet_two.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_two.entries(0)),
+              ElementsAre("body bar 2"));
+  EXPECT_THAT(GetMatches(content, result_snippet_two.entries(0)),
+              ElementsAre("bar"));
+
+  // 2 'embedding1' snippet entries
+  EXPECT_THAT(result_snippet_two.entries(1).property_name(),
+              Eq("embedding1[1]"));
+  EXPECT_THAT(result_snippet_two.entries(1).embedding_matches(),
+              ElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+                  /*score=*/4.3,
+                  /*query_index=*/1, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(result_snippet_two.entries(2).property_name(),
+              Eq("embedding1[2]"));
+  EXPECT_THAT(result_snippet_two.entries(2).embedding_matches(),
+              ElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+                  /*score=*/2.1,
+                  /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT))));
+
+  // 1 'embedding2' snippet entry
+  EXPECT_THAT(result_snippet_two.entries(3).property_name(),
+              Eq("embedding2[1]"));
+  EXPECT_THAT(result_snippet_two.entries(3).embedding_matches(),
+              ElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+                  /*score=*/3.2,
+                  /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT))));
+
+  // 1 'subject' snippet entry
+  EXPECT_THAT(result_snippet_two.entries(4).property_name(), Eq("subject"));
+  content = GetString(&result_document_two,
+                      result_snippet_two.entries(4).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_two.entries(4)),
+              ElementsAre("subject foo 2"));
+  EXPECT_THAT(GetMatches(content, result_snippet_two.entries(4)),
+              ElementsAre("foo"));
+
+  // Document 3 should not have any embedding match info.
+  const DocumentProto& result_document_three =
+      page_result.results.at(2).document();
+  const SnippetProto& result_snippet_three =
+      page_result.results.at(2).snippet();
+  EXPECT_THAT(result_document_three,
+              EqualsProto(CreateEmailDocument(/*id=*/3)));
+  EXPECT_THAT(result_snippet_three.entries(), SizeIs(2));
+  EXPECT_THAT(result_snippet_three.entries(0).property_name(), Eq("body"));
+  content = GetString(&result_document_three,
+                      result_snippet_three.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_three.entries(0)),
+              ElementsAre("body bar 3"));
+  EXPECT_THAT(GetMatches(content, result_snippet_three.entries(0)),
+              ElementsAre("bar"));
+  EXPECT_THAT(result_snippet_three.entries(1).property_name(), Eq("subject"));
+  content = GetString(&result_document_three,
+                      result_snippet_three.entries(1).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_three.entries(1)),
+              ElementsAre("subject foo 3"));
+  EXPECT_THAT(GetMatches(content, result_snippet_three.entries(1)),
+              ElementsAre("foo"));
+}
+
+TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfoDisabled) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+  DocumentId document_id1 = put_result1.new_document_id;
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+  DocumentId document_id2 = put_result2.new_document_id;
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+  DocumentId document_id3 = put_result3.new_document_id;
+
+  std::vector<SectionId> hit_section_ids = {
+      GetSectionId("Email", "subject"), GetSectionId("Email", "body"),
+      GetSectionId("Email", "embedding1"), GetSectionId("Email", "embedding2")};
+  SectionIdMask hit_section_id_mask = CreateSectionIdMask(hit_section_ids);
+  std::vector<ScoredDocumentHit> scored_document_hits = {
+      {document_id1, hit_section_id_mask, /*score=*/0},
+      {document_id2, hit_section_id_mask, /*score=*/0},
+      {document_id3, hit_section_id_mask, /*score=*/0}};
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<ResultRetrieverV2> result_retriever,
+      ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
+                                language_segmenter_.get(), normalizer_.get()));
+
+  // Create ResultSpec with custom snippet spec.
+  ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
+  snippet_spec.set_get_embedding_match_info(false);
+  ResultSpecProto result_spec = CreateResultSpec(/*num_per_page=*/3);
+  *result_spec.mutable_snippet_spec() = std::move(snippet_spec);
+
+  std::vector<PropertyProto::VectorProto> embedding_query_vectors = {
+      CreateVector("my_model1", {-1, -1, 1}),
+      CreateVector("my_model2", {-1, 1, -1, -1})};
+  EmbeddingQueryResults embedding_query_results =
+      CreateEmailEmbeddingQueryResults(/*num_documents=*/2);
+
+  ResultStateV2 result_state(
+      std::make_unique<
+          PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+          std::move(scored_document_hits), /*is_descending=*/false),
+      /*parent_adjustment_info=*/
+      std::make_unique<ResultAdjustmentInfo>(
+          CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
+                           EMBEDDING_METRIC_DOT_PRODUCT),
+          CreateScoringSpec(/*is_descending_order=*/false), result_spec,
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
@@ -510,14 +794,70 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllResults) {
           ->RetrieveNextPage(result_state,
                              fake_clock_.GetSystemTimeMilliseconds())
           .first;
-  // num_to_snippet = 5, num_previously_returned_in = 0,
-  // We can return 5 - 0 = 5 snippets at most. We're able to return all 3
-  // snippets here.
   ASSERT_THAT(page_result.results, SizeIs(3));
-  EXPECT_THAT(page_result.results.at(0).snippet().entries(), Not(IsEmpty()));
-  EXPECT_THAT(page_result.results.at(1).snippet().entries(), Not(IsEmpty()));
-  EXPECT_THAT(page_result.results.at(2).snippet().entries(), Not(IsEmpty()));
   EXPECT_THAT(page_result.num_results_with_snippets, Eq(3));
+
+  const DocumentProto& result_document_one =
+      page_result.results.at(0).document();
+  const SnippetProto& result_snippet_one = page_result.results.at(0).snippet();
+  EXPECT_THAT(result_document_one, EqualsProto(CreateEmailDocument(/*id=*/1)));
+  EXPECT_THAT(result_snippet_one.entries(), SizeIs(2));
+  EXPECT_THAT(result_snippet_one.entries(0).property_name(), Eq("body"));
+  std::string_view content = GetString(
+      &result_document_one, result_snippet_one.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_one.entries(0)),
+              ElementsAre("body bar 1"));
+  EXPECT_THAT(GetMatches(content, result_snippet_one.entries(0)),
+              ElementsAre("bar"));
+  EXPECT_THAT(result_snippet_one.entries(1).property_name(), Eq("subject"));
+  content = GetString(&result_document_one,
+                      result_snippet_one.entries(1).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_one.entries(1)),
+              ElementsAre("subject foo 1"));
+  EXPECT_THAT(GetMatches(content, result_snippet_one.entries(1)),
+              ElementsAre("foo"));
+
+  const DocumentProto& result_document_two =
+      page_result.results.at(1).document();
+  const SnippetProto& result_snippet_two = page_result.results.at(1).snippet();
+  EXPECT_THAT(result_document_two, EqualsProto(CreateEmailDocument(/*id=*/2)));
+  EXPECT_THAT(result_snippet_two.entries(), SizeIs(2));
+  EXPECT_THAT(result_snippet_two.entries(0).property_name(), Eq("body"));
+  content = GetString(&result_document_two,
+                      result_snippet_two.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_two.entries(0)),
+              ElementsAre("body bar 2"));
+  EXPECT_THAT(GetMatches(content, result_snippet_two.entries(0)),
+              ElementsAre("bar"));
+  EXPECT_THAT(result_snippet_two.entries(1).property_name(), Eq("subject"));
+  content = GetString(&result_document_two,
+                      result_snippet_two.entries(1).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_two.entries(1)),
+              ElementsAre("subject foo 2"));
+  EXPECT_THAT(GetMatches(content, result_snippet_two.entries(1)),
+              ElementsAre("foo"));
+
+  const DocumentProto& result_document_three =
+      page_result.results.at(2).document();
+  const SnippetProto& result_snippet_three =
+      page_result.results.at(2).snippet();
+  EXPECT_THAT(result_document_three,
+              EqualsProto(CreateEmailDocument(/*id=*/3)));
+  EXPECT_THAT(result_snippet_three.entries(), SizeIs(2));
+  EXPECT_THAT(result_snippet_three.entries(0).property_name(), Eq("body"));
+  content = GetString(&result_document_three,
+                      result_snippet_three.entries(0).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_three.entries(0)),
+              ElementsAre("body bar 3"));
+  EXPECT_THAT(GetMatches(content, result_snippet_three.entries(0)),
+              ElementsAre("bar"));
+  EXPECT_THAT(result_snippet_three.entries(1).property_name(), Eq("subject"));
+  content = GetString(&result_document_three,
+                      result_snippet_three.entries(1).property_name());
+  EXPECT_THAT(GetWindows(content, result_snippet_three.entries(1)),
+              ElementsAre("subject foo 3"));
+  EXPECT_THAT(GetMatches(content, result_snippet_three.entries(1)),
+              ElementsAre("foo"));
 }
 
 TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeResults) {
@@ -560,7 +900,9 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeResults) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
   {
@@ -622,7 +964,9 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldNotSnippetAnyResults) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
   {
@@ -686,7 +1030,9 @@ TEST_F(ResultRetrieverV2SnippetTest,
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{document_id1, document_id2,
+                                         document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
 
@@ -801,13 +1147,17 @@ TEST_F(ResultRetrieverV2SnippetTest, JoinSnippeted) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), parent_result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{
+              person_document_id1, person_document_id2, person_document_id3},
           SectionRestrictQueryTermsMap({{"", {"person"}}})),
       /*child_adjustment_info=*/
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), child_result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{email_document_id1, email_document_id2,
+                                         email_document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       parent_result_spec, *document_store_);
 
@@ -1035,13 +1385,17 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllJoinedResults) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), parent_result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{person_document_id1,
+                                         person_document_id2},
           SectionRestrictQueryTermsMap({{"", {"person"}}})),
       /*child_adjustment_info=*/
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), child_result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{email_document_id1, email_document_id2,
+                                         email_document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       parent_result_spec, *document_store_);
 
@@ -1159,13 +1513,17 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeJoinedResults) {
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), parent_result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{person_document_id1,
+                                         person_document_id2},
           SectionRestrictQueryTermsMap({{"", {"person"}}})),
       /*child_adjustment_info=*/
       std::make_unique<ResultAdjustmentInfo>(
           CreateSearchSpec(TermMatchType::EXACT_ONLY),
           CreateScoringSpec(/*is_descending_order=*/false), child_result_spec,
-          schema_store_.get(),
+          schema_store_.get(), EmbeddingQueryResults(),
+          std::unordered_set<DocumentId>{email_document_id1, email_document_id2,
+                                         email_document_id3},
           SectionRestrictQueryTermsMap({{"", {"foo", "bar"}}})),
       parent_result_spec, *document_store_);
 
diff --git a/icing/result/result-retriever-v2_test.cc b/icing/result/result-retriever-v2_test.cc
index 77e6fa2..49899b1 100644
--- a/icing/result/result-retriever-v2_test.cc
+++ b/icing/result/result-retriever-v2_test.cc
@@ -17,6 +17,7 @@
 #include <atomic>
 #include <cstddef>
 #include <cstdint>
+#include <limits>
 #include <memory>
 #include <string>
 #include <unordered_map>
@@ -57,6 +58,7 @@
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -114,8 +116,11 @@ class ResultRetrieverV2Test : public ::testing::Test {
     ICING_ASSERT_OK_AND_ASSIGN(
         schema_store_, SchemaStore::Create(&filesystem_, test_dir_,
                                            &fake_clock_, feature_flags_.get()));
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/10000));
+
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     SchemaProto schema =
         SchemaBuilder()
@@ -152,8 +157,7 @@ class ResultRetrieverV2Test : public ::testing::Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
 
     num_total_hits_ = 0;
diff --git a/icing/result/result-state-manager_test.cc b/icing/result/result-state-manager_test.cc
index e998c99..463005e 100644
--- a/icing/result/result-state-manager_test.cc
+++ b/icing/result/result-state-manager_test.cc
@@ -14,21 +14,35 @@
 
 #include "icing/result/result-state-manager.h"
 
+#include <algorithm>
+#include <cstdint>
+#include <limits>
 #include <memory>
+#include <string>
+#include <unordered_set>
+#include <utility>
+#include <vector>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/platform.h"
+#include "icing/query/query-terms.h"
 #include "icing/result/page-result.h"
 #include "icing/result/result-adjustment-info.h"
 #include "icing/result/result-retriever-v2.h"
 #include "icing/schema/schema-store.h"
+#include "icing/schema/section.h"
 #include "icing/scoring/priority-queue-scored-document-hits-ranker.h"
+#include "icing/scoring/scored-document-hit.h"
 #include "icing/scoring/scored-document-hits-ranker.h"
+#include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/fake-clock.h"
@@ -36,9 +50,10 @@
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
-#include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -105,11 +120,12 @@ class ResultStateManagerTest : public testing::Test {
     SchemaProto schema;
     schema.add_types()->set_schema_type("Document");
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        std::move(schema), /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        std::move(schema), /*ignore_errors_and_delete_documents=*/false));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/10000));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult result,
@@ -458,32 +474,38 @@ TEST_F(ResultStateManagerTest,
 
   // Set time as 1s and add state 1.
   clock()->SetSystemTimeMilliseconds(1000);
+  std::unique_ptr<ScoredDocumentHitsRanker> ranker = std::make_unique<
+      PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+      std::move(scored_document_hits1), /*is_descending=*/true);
+  std::unordered_set<DocumentId> documents_to_snippet =
+      ranker->GetTopKDocumentIds(result_spec.snippet_spec().num_to_snippet());
+  std::unique_ptr<ResultAdjustmentInfo> parent_adjustment_info =
+      std::make_unique<ResultAdjustmentInfo>(
+          search_spec, scoring_spec, result_spec, &schema_store(),
+          EmbeddingQueryResults(), std::move(documents_to_snippet),
+          query_terms);
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info1,
       result_state_manager.CacheAndRetrieveFirstPage(
-          std::make_unique<
-              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
-              std::move(scored_document_hits1), /*is_descending=*/true),
-          /*parent_adjustment_info=*/
-          std::make_unique<ResultAdjustmentInfo>(search_spec, scoring_spec,
-                                                 result_spec, &schema_store(),
-                                                 query_terms),
+          std::move(ranker), std::move(parent_adjustment_info),
           /*child_adjustment_info=*/nullptr, result_spec, document_store(),
           result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info1.first, Not(Eq(kInvalidNextPageToken)));
 
   // Set time as 1hr1s and add state 2.
   clock()->SetSystemTimeMilliseconds(kDefaultResultStateTtlInMs + 1000);
+  ranker = std::make_unique<
+      PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+      std::move(scored_document_hits2), /*is_descending=*/true);
+  documents_to_snippet =
+      ranker->GetTopKDocumentIds(result_spec.snippet_spec().num_to_snippet());
+  parent_adjustment_info = std::make_unique<ResultAdjustmentInfo>(
+      search_spec, scoring_spec, result_spec, &schema_store(),
+      EmbeddingQueryResults(), std::move(documents_to_snippet), query_terms);
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info2,
       result_state_manager.CacheAndRetrieveFirstPage(
-          std::make_unique<
-              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
-              std::move(scored_document_hits2), /*is_descending=*/true),
-          /*parent_adjustment_info=*/
-          std::make_unique<ResultAdjustmentInfo>(search_spec, scoring_spec,
-                                                 result_spec, &schema_store(),
-                                                 query_terms),
+          std::move(ranker), std::move(parent_adjustment_info),
           /*child_adjustment_info=*/nullptr, result_spec, document_store(),
           result_retriever(), clock()->GetSystemTimeMilliseconds()));
 
diff --git a/icing/result/result-state-manager_thread-safety_test.cc b/icing/result/result-state-manager_thread-safety_test.cc
index 33cde3f..5578c54 100644
--- a/icing/result/result-state-manager_thread-safety_test.cc
+++ b/icing/result/result-state-manager_thread-safety_test.cc
@@ -13,6 +13,8 @@
 // limitations under the License.
 
 #include <algorithm>
+#include <cstdint>
+#include <limits>
 #include <memory>
 #include <optional>
 #include <thread>  // NOLINT
@@ -37,6 +39,7 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -97,11 +100,12 @@ class ResultStateManagerThreadSafetyTest : public testing::Test {
     SchemaProto schema;
     schema.add_types()->set_schema_type("Document");
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        std::move(schema), /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        std::move(schema), /*ignore_errors_and_delete_documents=*/false));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/10000));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult result,
diff --git a/icing/result/result-state-v2_test.cc b/icing/result/result-state-v2_test.cc
index bb2031c..6b8b4bd 100644
--- a/icing/result/result-state-v2_test.cc
+++ b/icing/result/result-state-v2_test.cc
@@ -73,8 +73,7 @@ class ResultStateV2Test : public ::testing::Test {
     SchemaProto schema;
     schema.add_types()->set_schema_type("Document");
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        std::move(schema), /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        std::move(schema), /*ignore_errors_and_delete_documents=*/false));
 
     doc_store_base_dir_ = GetTestTempDir() + "/document_store";
     filesystem_.CreateDirectoryRecursively(doc_store_base_dir_.c_str());
diff --git a/icing/result/snippet-context.h b/icing/result/snippet-context.h
index 34a0529..20464d4 100644
--- a/icing/result/snippet-context.h
+++ b/icing/result/snippet-context.h
@@ -15,9 +15,17 @@
 #ifndef ICING_RESULT_SNIPPET_CONTEXT_H_
 #define ICING_RESULT_SNIPPET_CONTEXT_H_
 
+#include <string>
+#include <unordered_map>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
 #include "icing/query/query-terms.h"
+#include "icing/schema/section.h"
+#include "icing/store/document-id.h"
 
 namespace icing {
 namespace lib {
@@ -25,16 +33,79 @@ namespace lib {
 // Stores data needed for snippeting. With SnippetContext we can fetch snippets
 // for queries with multiple pages.
 struct SnippetContext {
-  explicit SnippetContext(SectionRestrictQueryTermsMap query_terms_in,
-                          ResultSpecProto::SnippetSpecProto snippet_spec_in,
-                          TermMatchType::Code match_type_in)
+  // A struct to store the cache entry for embedding match info.
+  struct EmbeddingMatchInfoEntry {
+    double score;
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type;
+    // The position of the matched embedding vector in a section relative to
+    // other vectors with the same (dimension, signature) combination. Note that
+    // this is not the universal position of the vector in the section.
+    //
+    // E.g. If a repeated vector property contains the following vectors:
+    // - vector1: [1, 2, 3] (signature = "signature1", dimension = 3)
+    // - vector2: [7, 8, 9] (signature = "signature1", dimension = 3)
+    // - vector3: [4, 5, 6, 8] (signature = "signature2", dimension = 4)
+    // - vector4: [10, 11, 12] (signature = "signature1", dimension = 3)
+    //
+    // Then the position values for each vector would be:
+    // - vector1: 0
+    // - vector2: 1
+    // - vector3: 0
+    // - vector4: 2
+    int position;
+    int query_vector_index;
+    SectionId section_id;
+
+    explicit EmbeddingMatchInfoEntry(
+        double score_in,
+        SearchSpecProto::EmbeddingQueryMetricType::Code metric_type_in,
+        int position_in, int query_vector_index_in, SectionId section_id_in) {
+      score = score_in;
+      metric_type = metric_type_in;
+      position = position_in;
+      query_vector_index = query_vector_index_in;
+      section_id = section_id_in;
+    }
+  };
+
+  // Maps from document_id to a vector of EmbeddingMatchInfoEntry. This
+  // is used to retrieve the full embedding match info for a given document
+  // during snippeting.
+  using DocumentEmbeddingMatchInfoMap =
+      std::unordered_map<DocumentId, std::vector<EmbeddingMatchInfoEntry>>;
+
+  // Map of
+  // (query_vector_dimension -> (model_signature -> set of query_vector_index))
+  // for the embedding query vectors in the search spec.
+  using EmbeddingQueryVectorMetadataMap = std::unordered_map<
+      int, std::unordered_map<std::string, std::unordered_set<int>>>;
+
+  explicit SnippetContext(
+      SectionRestrictQueryTermsMap query_terms_in,
+      EmbeddingQueryVectorMetadataMap embedding_query_vector_metadata_map_in,
+      DocumentEmbeddingMatchInfoMap embedding_match_info_map_in,
+      ResultSpecProto::SnippetSpecProto snippet_spec_in,
+      TermMatchType::Code match_type_in)
       : query_terms(std::move(query_terms_in)),
+        embedding_query_vector_metadata_map(
+            std::move(embedding_query_vector_metadata_map_in)),
+        embedding_match_info_map(std::move(embedding_match_info_map_in)),
         snippet_spec(std::move(snippet_spec_in)),
         match_type(match_type_in) {}
 
   // Query terms that are used to find snippets
   SectionRestrictQueryTermsMap query_terms;
 
+  // Query vector metadata map for finding the global section positions for
+  // each embedding match.
+  //
+  // Map of (query_vector_dimension -> (model_signature -> query_vector_index))
+  // for the embedding query vectors in the search spec.
+  EmbeddingQueryVectorMetadataMap embedding_query_vector_metadata_map;
+
+  // Results retrieved from embedding queries.
+  DocumentEmbeddingMatchInfoMap embedding_match_info_map;
+
   // Spec that defines some quantities of snippeting
   ResultSpecProto::SnippetSpecProto snippet_spec;
 
diff --git a/icing/result/snippet-retriever.cc b/icing/result/snippet-retriever.cc
index 53bff43..59552c8 100644
--- a/icing/result/snippet-retriever.cc
+++ b/icing/result/snippet-retriever.cc
@@ -14,8 +14,7 @@
 
 #include "icing/result/snippet-retriever.h"
 
-#include <algorithm>
-#include <iterator>
+#include <map>
 #include <memory>
 #include <string>
 #include <string_view>
@@ -31,10 +30,12 @@
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
 #include "icing/query/query-terms.h"
+#include "icing/result/snippet-context.h"
 #include "icing/schema/property-util.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
 #include "icing/store/document-filter-data.h"
+#include "icing/store/document-id.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/tokenization/token.h"
 #include "icing/tokenization/tokenizer-factory.h"
@@ -135,8 +136,7 @@ CharacterIterator FindMatchEnd(const Normalizer& normalizer, const Token& token,
       // matched query term must be either equal to or a prefix of the token's
       // text. Therefore, the match must end at the end of the matched query
       // term.
-      CharacterIterator verbatim_match_end =
-          CharacterIterator(token.text, 0, 0, 0);
+      CharacterIterator verbatim_match_end(token.text);
       verbatim_match_end.AdvanceToUtf8(match_query_term.length());
       return verbatim_match_end;
     }
@@ -209,12 +209,12 @@ class TokenMatcher {
   // token.text that matches a query term. Note that the utf* indices will be
   // in relation to token.text's start.
   //
-  // If there is no match, then it will construct a CharacterIterator with all
-  // of its indices set to -1.
+  // If there is no match, then it will return an invalid CharacterIterator
+  // instance.
   //
   // Ex. With an exact matcher, query terms=["foo","bar"] and token.text="bar",
   // Matches will return a CharacterIterator(u8:3, u16:3, u32:3).
-  virtual CharacterIterator Matches(Token token) const = 0;
+  virtual CharacterIterator Matches(const Token& token) const = 0;
 };
 
 class TokenMatcherExact : public TokenMatcher {
@@ -227,7 +227,7 @@ class TokenMatcherExact : public TokenMatcher {
         restricted_query_terms_(restricted_query_terms),
         normalizer_(normalizer) {}
 
-  CharacterIterator Matches(Token token) const override {
+  CharacterIterator Matches(const Token& token) const override {
     Normalizer::NormalizedTerm normalized_term =
         NormalizeToken(normalizer_, token);
     auto itr = unrestricted_query_terms_.find(normalized_term.text);
@@ -239,7 +239,7 @@ class TokenMatcherExact : public TokenMatcher {
       return FindMatchEnd(normalizer_, token, *itr);
     }
 
-    return CharacterIterator(token.text, -1, -1, -1);
+    return CharacterIterator();
   }
 
  private:
@@ -258,7 +258,7 @@ class TokenMatcherPrefix : public TokenMatcher {
         restricted_query_terms_(restricted_query_terms),
         normalizer_(normalizer) {}
 
-  CharacterIterator Matches(Token token) const override {
+  CharacterIterator Matches(const Token& token) const override {
     Normalizer::NormalizedTerm normalized_term =
         NormalizeToken(normalizer_, token);
     for (const std::string& query_term : unrestricted_query_terms_) {
@@ -275,7 +275,7 @@ class TokenMatcherPrefix : public TokenMatcher {
         return FindMatchEnd(normalizer_, token, query_term);
       }
     }
-    return CharacterIterator(token.text, -1, -1, -1);
+    return CharacterIterator();
   }
 
  private:
@@ -326,7 +326,7 @@ libtextclassifier3::StatusOr<CharacterIterator> DetermineWindowStart(
 CharacterIterator IncludeTrailingPunctuation(
     std::string_view value, CharacterIterator window_end_exclusive,
     int window_end_max_exclusive_utf32) {
-  size_t max_search_index = value.length() - 1;
+  int max_search_index = static_cast<int>(value.length()) - 1;
   while (window_end_exclusive.utf8_index() <= max_search_index &&
          window_end_exclusive.utf32_index() < window_end_max_exclusive_utf32) {
     int char_len = 0;
@@ -490,6 +490,10 @@ void GetEntriesFromProperty(const PropertyProto* current_property,
                             const Tokenizer* tokenizer,
                             MatchOptions* match_options,
                             SnippetProto* snippet_proto) {
+  if (tokenizer == nullptr || matcher == nullptr) {
+    // This is the case if the property is not a string property.
+    return;
+  }
   // We're at the end. Let's check our values.
   for (int i = 0; i < current_property->string_values_size(); ++i) {
     SnippetProto::EntryProto snippet_entry;
@@ -522,9 +526,9 @@ void GetEntriesFromProperty(const PropertyProto* current_property,
       for (int i = 0; i < batch_tokens.size(); ++i) {
         const Token& token = batch_tokens.at(i);
         CharacterIterator submatch_end = matcher->Matches(token);
-        // If the token matched a query term, then submatch_end will point to an
-        // actual position within token.text.
-        if (submatch_end.utf8_index() == -1) {
+        // If the token didn't match, then we will get an invalid iterator
+        // instance.
+        if (!submatch_end.is_valid()) {
           continue;
         }
         // As snippet matching may move iterator around, we save a reset
@@ -596,9 +600,147 @@ void GetEntriesFromProperty(const PropertyProto* current_property,
   }
 }
 
+// Iterates through the PropertyProto to find the global section position
+// indices for each embedding match.
+//
+// The returned map maps a vector-query index to a list of global positions
+// within the property, in the order in which the vector appears in the
+// property.
+//
+// For example, if the property contains the following vectors:
+// - 0: [1, 2, 3] (signature a)
+// - 1: [4, 5, 6, 7] (signature b)
+// - 2: [7, 8, 9, 10, 2, 3] (signature c)
+// - 3: [10, 11, 12] (signature a)
+//
+// And the embedding queries are:
+// {0: dimension=3, signature=a; 1: dimension=5, signature=c}
+//
+// Then the returned map will be: {{0: [0, 3]}; {1: [2]}}
+std::unordered_map<int, std::vector<int>> GetGlobalEmbeddingSectionPositions(
+    const PropertyProto& property,
+    const SnippetContext::EmbeddingQueryVectorMetadataMap&
+        embedding_query_vector_metadata) {
+  std::unordered_map<int, std::vector<int>> global_embedding_section_positions;
+  for (int i = 0; i < property.vector_values_size(); ++i) {
+    const PropertyProto::VectorProto& vector_value = property.vector_values(i);
+    int dimension = vector_value.values().size();
+    std::string_view model_signature = vector_value.model_signature();
+    auto dimension_itr = embedding_query_vector_metadata.find(dimension);
+    if (dimension_itr == embedding_query_vector_metadata.end()) {
+      // No embedding query vector with this dimension.
+      continue;
+    }
+    auto signature_itr =
+        dimension_itr->second.find(std::string(model_signature));
+    if (signature_itr == dimension_itr->second.end()) {
+      // No embedding query vector with this dimension and signature.
+      continue;
+    }
+    for (int query_vector_index : signature_itr->second) {
+      global_embedding_section_positions[query_vector_index].push_back(i);
+    }
+  }
+  return global_embedding_section_positions;
+}
+
+// Retrieves embedding match info for the vector values in the given property.
+//
+// MatchOptions holds the snippet spec and number of desired matches remaining.
+// Each call to GetEntriesFromProperty will decrement max_matches_remaining
+// by the number of entries that it adds to snippet_proto.
+//
+// The SnippetEntries found for matched content will be added to snippet_proto.
+void GetEmbeddingMatchInfo(
+    DocumentId doc_id, SectionId section_id, const PropertyProto& property,
+    const std::string& property_path,
+    const SnippetContext::EmbeddingQueryVectorMetadataMap&
+        embedding_query_vector_metadata,
+    const SnippetContext::DocumentEmbeddingMatchInfoMap&
+        embedding_match_info_map,
+    MatchOptions* match_options, SnippetProto* snippet_proto) {
+  // Step 1: Get the matches for this document and section from
+  // embedding_match_info_map.
+  auto itr = embedding_match_info_map.find(doc_id);
+  if (itr == embedding_match_info_map.end()) {
+    // No embedding matches for this document.
+    return;
+  }
+  const std::vector<SnippetContext::EmbeddingMatchInfoEntry>&
+      embedding_matches = itr->second;
+
+  // Step 2: Get the global section positions for all embeddings in the
+  // property. This maps a vector query index to a list of global positions
+  // within the property, in the order in which the vector appears in the
+  // property.
+  std::unordered_map<int, std::vector<int>> global_embedding_section_positions =
+      GetGlobalEmbeddingSectionPositions(property,
+                                         embedding_query_vector_metadata);
+
+  // Step 3: Retrieve results and populate snippet entries.
+  // Maps from position in section to EmbeddingMatchSnippetProto entries. An
+  // ordered map is used so that we can return the match entries in the order
+  // in which the vector appears in the property.
+  std::map<int, std::vector<EmbeddingMatchSnippetProto>> match_info_entries;
+  for (const SnippetContext::EmbeddingMatchInfoEntry& match :
+       embedding_matches) {
+    if (match_options->max_matches_remaining <= 0) {
+      // We've reached the max number of matches. This shouldn't really happen
+      // because the match-info map should not contain more entries than needed,
+      // but break just in case.
+      break;
+    }
+    if (match.section_id != section_id) {
+      continue;
+    }
+    auto global_positions_itr =
+        global_embedding_section_positions.find(match.query_vector_index);
+    if (global_positions_itr == global_embedding_section_positions.end()) {
+      // This would indicate that the embedding query results recorded for the
+      // query is incorrect, which should never happen.
+      ICING_LOG(ERROR) << "Incorrect embedding query results match info "
+                          "recorded for query vector index "
+                       << match.query_vector_index << ", document " << doc_id
+                       << ", property " << property_path;
+      continue;
+    }
+    const std::vector<int>& global_positions = global_positions_itr->second;
+    if (match.position >= global_positions.size()) {
+      // This would indicate that the embedding query results recorded for the
+      // query is incorrect, which should never happen.
+      ICING_LOG(ERROR) << "Incorrect embedding query results match info "
+                          "recorded for query vector index "
+                       << match.query_vector_index << ", document " << doc_id
+                       << ", property " << property_path;
+      continue;
+    }
+
+    // Create the match proto and add it to the entries map.
+    EmbeddingMatchSnippetProto match_proto;
+    match_proto.set_semantic_score(match.score);
+    match_proto.set_embedding_query_vector_index(match.query_vector_index);
+    match_proto.set_embedding_query_metric_type(match.metric_type);
+    match_info_entries[global_positions.at(match.position)].push_back(
+        match_proto);
+
+    --match_options->max_matches_remaining;
+  }
+
+  // Step 5: Add the entries to the snippet proto.
+  for (auto& [position_in_section, entries] : match_info_entries) {
+    SnippetProto::EntryProto* snippet_entry = snippet_proto->add_entries();
+    snippet_entry->set_property_name(AddIndexToPath(
+        property.vector_values().size(), position_in_section, property_path));
+    for (EmbeddingMatchSnippetProto& match_proto : entries) {
+      *snippet_entry->add_embedding_matches() = std::move(match_proto);
+    }
+  }
+}
+
 // Retrieves snippets in document from content at section_path.
 // Tokenizer is provided to tokenize string content and matcher is provided to
-// indicate when a token matches content in the query.
+// indicate when a token matches content in the query. Both tokenizer and
+// matcher will be nullptr for non-string sections (i.e. vector).
 //
 // section_path_index refers to the current property that is held by document.
 // current_path is equivalent to the first section_path_index values in
@@ -617,11 +759,15 @@ void GetEntriesFromProperty(const PropertyProto* current_property,
 //
 // The SnippetEntries found for matched content will be added to snippet_proto.
 void RetrieveSnippetForSection(
-    const DocumentProto& document, const TokenMatcher* matcher,
-    const Tokenizer* tokenizer,
-    const std::vector<std::string_view>& section_path, int section_path_index,
-    const std::string& current_path, MatchOptions* match_options,
-    SnippetProto* snippet_proto) {
+    DocumentId document_id, const DocumentProto& document,
+    const TokenMatcher* matcher, const Tokenizer* tokenizer,
+    SectionId section_id, const std::vector<std::string_view>& section_path,
+    int section_path_index, const std::string& current_path,
+    const SnippetContext::EmbeddingQueryVectorMetadataMap&
+        embedding_query_vector_metadata,
+    const SnippetContext::DocumentEmbeddingMatchInfoMap&
+        embedding_match_info_map,
+    MatchOptions* match_options, SnippetProto* snippet_proto) {
   std::string_view next_property_name = section_path.at(section_path_index);
   const PropertyProto* current_property =
       property_util::GetPropertyProto(document, next_property_name);
@@ -634,17 +780,27 @@ void RetrieveSnippetForSection(
       current_path, next_property_name);
   if (section_path_index == section_path.size() - 1) {
     // We're at the end. Let's check our values.
-    GetEntriesFromProperty(current_property, property_path, matcher, tokenizer,
-                           match_options, snippet_proto);
+    if (tokenizer == nullptr || matcher == nullptr) {
+      // Vector section.
+      GetEmbeddingMatchInfo(document_id, section_id, *current_property,
+                            property_path, embedding_query_vector_metadata,
+                            embedding_match_info_map, match_options,
+                            snippet_proto);
+    } else {
+      // String section.
+      GetEntriesFromProperty(current_property, property_path, matcher,
+                             tokenizer, match_options, snippet_proto);
+    }
   } else {
     // Still got more to go. Let's look through our subdocuments.
-    std::vector<SnippetProto::EntryProto> entries;
     for (int i = 0; i < current_property->document_values_size(); ++i) {
       std::string new_path = AddIndexToPath(
           current_property->document_values_size(), /*index=*/i, property_path);
-      RetrieveSnippetForSection(current_property->document_values(i), matcher,
-                                tokenizer, section_path, section_path_index + 1,
-                                new_path, match_options, snippet_proto);
+      RetrieveSnippetForSection(
+          document_id, current_property->document_values(i), matcher, tokenizer,
+          section_id, section_path, section_path_index + 1, new_path,
+          embedding_query_vector_metadata, embedding_match_info_map,
+          match_options, snippet_proto);
       if (match_options->max_matches_remaining <= 0) {
         break;
       }
@@ -667,26 +823,26 @@ SnippetRetriever::Create(const SchemaStore* schema_store,
 }
 
 SnippetProto SnippetRetriever::RetrieveSnippet(
-    const SectionRestrictQueryTermsMap& query_terms,
-    TermMatchType::Code match_type,
-    const ResultSpecProto::SnippetSpecProto& snippet_spec,
-    const DocumentProto& document, SectionIdMask section_id_mask) const {
+    const SnippetContext& snippet_context, const DocumentProto& document,
+    DocumentId document_id, SectionIdMask section_id_mask) const {
   SnippetProto snippet_proto;
   ICING_ASSIGN_OR_RETURN(SchemaTypeId type_id,
                          schema_store_.GetSchemaTypeId(document.schema()),
                          snippet_proto);
   const std::unordered_set<std::string> empty_set;
+  const SectionRestrictQueryTermsMap& query_terms = snippet_context.query_terms;
   auto itr = query_terms.find("");
   const std::unordered_set<std::string>& unrestricted_set =
       (itr != query_terms.end()) ? itr->second : empty_set;
+
   while (section_id_mask != kSectionIdMaskNone) {
     SectionId section_id = __builtin_ctzll(section_id_mask);
     // Remove this section from the mask.
     section_id_mask &= ~(UINT64_C(1) << section_id);
 
-    MatchOptions match_options = {snippet_spec};
+    MatchOptions match_options = {snippet_context.snippet_spec};
     match_options.max_matches_remaining =
-        snippet_spec.num_matches_per_property();
+        snippet_context.snippet_spec.num_matches_per_property();
 
     // Determine the section name and match type.
     auto section_metadata_or =
@@ -702,7 +858,7 @@ SnippetProto SnippetRetriever::RetrieveSnippet(
     // snippet should only be included if both the query is Prefix and the
     // section has prefixes enabled.
     TermMatchType::Code section_match_type = TermMatchType::EXACT_ONLY;
-    if (match_type == TermMatchType::PREFIX &&
+    if (snippet_context.match_type == TermMatchType::PREFIX &&
         metadata->term_match_type == TermMatchType::PREFIX) {
       section_match_type = TermMatchType::PREFIX;
     }
@@ -710,24 +866,36 @@ SnippetProto SnippetRetriever::RetrieveSnippet(
     itr = query_terms.find(metadata->path);
     const std::unordered_set<std::string>& restricted_set =
         (itr != query_terms.end()) ? itr->second : empty_set;
-    libtextclassifier3::StatusOr<std::unique_ptr<TokenMatcher>> matcher_or =
-        CreateTokenMatcher(section_match_type, unrestricted_set, restricted_set,
-                           normalizer_);
-    if (!matcher_or.ok()) {
-      continue;
-    }
-    std::unique_ptr<TokenMatcher> matcher = std::move(matcher_or).ValueOrDie();
 
-    auto tokenizer_or = tokenizer_factory::CreateIndexingTokenizer(
-        metadata->tokenizer, &language_segmenter_);
-    if (!tokenizer_or.ok()) {
-      // If we couldn't create the tokenizer properly, just skip this section.
-      continue;
+    std::unique_ptr<TokenMatcher> matcher;
+    std::unique_ptr<Tokenizer> tokenizer;
+    if (metadata->data_type == PropertyConfigProto::DataType::STRING) {
+      // The tokenizer and matcher are only needed for string sections/queries.
+      // These will be null for other types (i.e. vector)
+      libtextclassifier3::StatusOr<std::unique_ptr<TokenMatcher>> matcher_or =
+          CreateTokenMatcher(section_match_type, unrestricted_set,
+                             restricted_set, normalizer_);
+      if (!matcher_or.ok()) {
+        // If we couldn't create the matcher properly, just skip this section.
+        continue;
+      }
+      matcher = std::move(matcher_or).ValueOrDie();
+
+      libtextclassifier3::StatusOr<std::unique_ptr<Tokenizer>> tokenizer_or =
+          tokenizer_factory::CreateIndexingTokenizer(metadata->tokenizer,
+                                                     &language_segmenter_);
+      if (!tokenizer_or.ok()) {
+        // If we couldn't create the tokenizer properly, just skip this section.
+        continue;
+      }
+      tokenizer = std::move(tokenizer_or).ValueOrDie();
     }
-    std::unique_ptr<Tokenizer> tokenizer = std::move(tokenizer_or).ValueOrDie();
     RetrieveSnippetForSection(
-        document, matcher.get(), tokenizer.get(), section_path,
-        /*section_path_index=*/0, "", &match_options, &snippet_proto);
+        document_id, document, matcher.get(), tokenizer.get(), section_id,
+        section_path, /*section_path_index=*/0, /*current_path=*/"",
+        snippet_context.embedding_query_vector_metadata_map,
+        snippet_context.embedding_match_info_map, &match_options,
+        &snippet_proto);
   }
   return snippet_proto;
 }
diff --git a/icing/result/snippet-retriever.h b/icing/result/snippet-retriever.h
index f68e18d..1bd56a3 100644
--- a/icing/result/snippet-retriever.h
+++ b/icing/result/snippet-retriever.h
@@ -21,9 +21,10 @@
 #include "icing/proto/document.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
-#include "icing/query/query-terms.h"
+#include "icing/result/snippet-context.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
+#include "icing/store/document-id.h"
 #include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer.h"
 
@@ -52,16 +53,15 @@ class SnippetRetriever {
       const LanguageSegmenter* language_segmenter,
       const Normalizer* normalizer);
 
-  // Retrieve the snippet information for content in document. terms in
+  // Retrieve the snippet information for content in document. Terms in
   // query_terms are matched to content in document according to match_type.
   // Only sections identified in section_id_mask are considered.
   //
   // Returns an empty SnippetProto if no snippets were found.
-  SnippetProto RetrieveSnippet(
-      const SectionRestrictQueryTermsMap& query_terms,
-      TermMatchType::Code match_type,
-      const ResultSpecProto::SnippetSpecProto& snippet_spec,
-      const DocumentProto& document, SectionIdMask section_id_mask) const;
+  SnippetProto RetrieveSnippet(const SnippetContext& snippet_context,
+                               const DocumentProto& document,
+                               DocumentId document_id,
+                               SectionIdMask section_id_mask) const;
 
  private:
   explicit SnippetRetriever(const SchemaStore* schema_store,
diff --git a/icing/result/snippet-retriever_benchmark.cc b/icing/result/snippet-retriever_benchmark.cc
index b4d10da..6dc43c5 100644
--- a/icing/result/snippet-retriever_benchmark.cc
+++ b/icing/result/snippet-retriever_benchmark.cc
@@ -12,25 +12,40 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+#include <cstddef>
+#include <limits>
+#include <memory>
+#include <random>
+#include <string>
+#include <utility>
+#include <vector>
+
 #include "testing/base/public/benchmark.h"
 #include "gmock/gmock.h"
 #include "third_party/absl/flags/flag.h"
+#include "icing/absl_ports/str_cat.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/search.pb.h"
+#include "icing/query/query-terms.h"
+#include "icing/result/snippet-context.h"
 #include "icing/result/snippet-retriever.h"
 #include "icing/schema-builder.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
+#include "icing/store/document-id.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/random-string.h"
 #include "icing/testing/test-data.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
+#include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/logging.h"
@@ -71,6 +86,8 @@ namespace {
 
 using ::testing::SizeIs;
 
+constexpr DocumentId kDocumentId0 = 0;
+
 void BM_SnippetOneProperty(benchmark::State& state) {
   bool run_via_adb = absl::GetFlag(FLAGS_adb);
   if (!run_via_adb) {
@@ -90,11 +107,10 @@ void BM_SnippetOneProperty(benchmark::State& state) {
   language_segmenter_factory::SegmenterOptions options(ULOC_US);
   std::unique_ptr<LanguageSegmenter> language_segmenter =
       language_segmenter_factory::Create(std::move(options)).ValueOrDie();
+  NormalizerOptions normalizer_options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
   std::unique_ptr<Normalizer> normalizer =
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max())
-          .ValueOrDie();
-
+      normalizer_factory::Create(normalizer_options).ValueOrDie();
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("type1").AddProperty(
@@ -108,8 +124,7 @@ void BM_SnippetOneProperty(benchmark::State& state) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem, schema_dir, &clock, &feature_flags));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   auto snippet_retriever =
       SnippetRetriever::Create(schema_store.get(), language_segmenter.get(),
@@ -154,9 +169,11 @@ void BM_SnippetOneProperty(benchmark::State& state) {
   SectionIdMask section_id_mask = 0x01;
   SnippetProto snippet_proto;
   for (auto _ : state) {
+    SnippetContext snippet_context(
+        query_terms, /*embedding_query_vector_metadata=*/{},
+        /*embedding_match_info_map=*/{}, snippet_spec, TERM_MATCH_PREFIX);
     snippet_proto = snippet_retriever->RetrieveSnippet(
-        query_terms, TERM_MATCH_PREFIX, snippet_spec, document,
-        section_id_mask);
+        snippet_context, document, kDocumentId0, section_id_mask);
     ASSERT_THAT(snippet_proto.entries(), SizeIs(1));
     ASSERT_THAT(snippet_proto.entries(0).snippet_matches(),
                 SizeIs(num_actual_matches));
@@ -220,10 +237,10 @@ void BM_SnippetRfcOneProperty(benchmark::State& state) {
   language_segmenter_factory::SegmenterOptions options(ULOC_US);
   std::unique_ptr<LanguageSegmenter> language_segmenter =
       language_segmenter_factory::Create(std::move(options)).ValueOrDie();
+  NormalizerOptions normalizer_options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
   std::unique_ptr<Normalizer> normalizer =
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max())
-          .ValueOrDie();
+      normalizer_factory::Create(normalizer_options).ValueOrDie();
 
   SchemaProto schema =
       SchemaBuilder()
@@ -238,8 +255,7 @@ void BM_SnippetRfcOneProperty(benchmark::State& state) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem, schema_dir, &clock, &feature_flags));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   auto snippet_retriever =
       SnippetRetriever::Create(schema_store.get(), language_segmenter.get(),
@@ -284,9 +300,11 @@ void BM_SnippetRfcOneProperty(benchmark::State& state) {
   SectionIdMask section_id_mask = 0x01;
   SnippetProto snippet_proto;
   for (auto _ : state) {
+    SnippetContext snippet_context(
+        query_terms, /*embedding_query_vector_metadata=*/{},
+        /*embedding_match_info_map=*/{}, snippet_spec, TERM_MATCH_PREFIX);
     snippet_proto = snippet_retriever->RetrieveSnippet(
-        query_terms, TERM_MATCH_PREFIX, snippet_spec, document,
-        section_id_mask);
+        snippet_context, document, kDocumentId0, section_id_mask);
     ASSERT_THAT(snippet_proto.entries(), SizeIs(1));
     ASSERT_THAT(snippet_proto.entries(0).snippet_matches(),
                 SizeIs(num_actual_matches));
diff --git a/icing/result/snippet-retriever_test.cc b/icing/result/snippet-retriever_test.cc
index 8c07e7a..45ee1ec 100644
--- a/icing/result/snippet-retriever_test.cc
+++ b/icing/result/snippet-retriever_test.cc
@@ -17,12 +17,18 @@
 #include <cstdint>
 #include <limits>
 #include <memory>
+#include <string>
+#include <string_view>
+#include <utility>
+#include <vector>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
-#include "icing/file/mock-filesystem.h"
+#include "icing/file/filesystem.h"
+#include "icing/jni/jni-cache.h"
 #include "icing/portable/equals-proto.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
@@ -30,12 +36,13 @@
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
 #include "icing/query/query-terms.h"
+#include "icing/result/snippet-context.h"
 #include "icing/schema-builder.h"
 #include "icing/schema/schema-store.h"
-#include "icing/schema/section-manager.h"
+#include "icing/schema/section.h"
 #include "icing/store/document-id.h"
-#include "icing/store/key-mapper.h"
 #include "icing/testing/common-matchers.h"
+#include "icing/testing/embedding-test-utils.h"
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/jni-test-helpers.h"
 #include "icing/testing/test-data.h"
@@ -43,8 +50,8 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
-#include "icing/transform/map/map-normalizer.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/snippet-helpers.h"
@@ -55,10 +62,21 @@ namespace lib {
 
 namespace {
 
+using ::icing::lib::portable_equals_proto::EqualsProto;
 using ::testing::ElementsAre;
 using ::testing::Eq;
 using ::testing::IsEmpty;
 using ::testing::SizeIs;
+using ::testing::UnorderedElementsAre;
+
+constexpr DocumentId kDocumentId0 = 0;
+constexpr DocumentId kDocumentId1 = 1;
+
+constexpr SearchSpecProto::EmbeddingQueryMetricType::Code
+    EMBEDDING_METRIC_DOT_PRODUCT =
+        SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT;
+constexpr SearchSpecProto::EmbeddingQueryMetricType::Code
+    EMBEDDING_METRIC_COSINE = SearchSpecProto::EmbeddingQueryMetricType::COSINE;
 
 // TODO (b/246964044): remove ifdef guard when url-tokenizer is ready for export
 // to Android. Also move it to schema-builder.h
@@ -75,6 +93,16 @@ std::vector<std::string_view> GetPropertyPaths(const SnippetProto& snippet) {
   return paths;
 }
 
+EmbeddingMatchSnippetProto CreateEmbeddingMatchSnippetProto(
+    double score, int query_index,
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) {
+  EmbeddingMatchSnippetProto match_info;
+  match_info.set_semantic_score(score);
+  match_info.set_embedding_query_vector_index(query_index);
+  match_info.set_embedding_query_metric_type(metric_type);
+  return match_info;
+}
+
 class SnippetRetrieverTest : public testing::Test {
  protected:
   void SetUp() override {
@@ -117,11 +145,13 @@ class SnippetRetrieverTest : public testing::Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
+
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/10000));
     ICING_ASSERT_OK_AND_ASSIGN(
         snippet_retriever_,
         SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
@@ -133,6 +163,7 @@ class SnippetRetrieverTest : public testing::Test {
     snippet_spec_.set_num_matches_per_property(
         std::numeric_limits<int32_t>::max());
     snippet_spec_.set_max_window_utf32_length(64);
+    snippet_spec_.set_get_embedding_match_info(true);
   }
 
   void TearDown() override {
@@ -181,8 +212,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowSizeSmallerThanMatch) {
   // Window starts at the beginning of "three" and ends in the middle of
   // "three". len=4, orig_window= "thre"
   snippet_spec_.set_max_window_utf32_length(4);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
+      snippet_context, document, kDocumentId0, section_mask);
 
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
@@ -207,9 +241,11 @@ TEST_F(SnippetRetrieverTest,
   // Window starts at the beginning of "three" and at the exact end of
   // "three". len=5, orig_window= "three"
   snippet_spec_.set_max_window_utf32_length(5);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -233,9 +269,11 @@ TEST_F(SnippetRetrieverTest,
   // Window starts at the beginning of "four" and at the exact end of
   // "four". len=4, orig_window= "four"
   snippet_spec_.set_max_window_utf32_length(4);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -265,9 +303,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowStartsInWhitespace) {
   //   2. trimmed, no-shifting window [4,13) "two three"
   //   3. trimmed, shifted window [4,18) "two three four"
   snippet_spec_.set_max_window_utf32_length(14);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -298,9 +338,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowStartsMidToken) {
   //   2. trimmed, no-shifting window [4,18) "two three four"
   //   3. trimmed, shifted window [4,20) "two three four.."
   snippet_spec_.set_max_window_utf32_length(16);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -324,9 +366,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowEndsInPunctuation) {
   // Window ends in the middle of all the punctuation and window starts at 0.
   // len=20, orig_window="one two three four.."
   snippet_spec_.set_max_window_utf32_length(20);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -352,9 +396,11 @@ TEST_F(SnippetRetrieverTest,
   // Window ends in the middle of all the punctuation and window starts at 0.
   // len=26, orig_window="pside down in Australia"
   snippet_spec_.set_max_window_utf32_length(24);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -380,9 +426,11 @@ TEST_F(SnippetRetrieverTest,
   // Window ends in the middle of all the punctuation and window starts at 0.
   // len=26, orig_window="upside down in Australia "
   snippet_spec_.set_max_window_utf32_length(26);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -413,9 +461,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowStartsBeforeValueStart) {
   //   2. trimmed, no-shifting window [0,21) "one two three four..."
   //   3. trimmed, shifted window [0,22) "one two three four...."
   snippet_spec_.set_max_window_utf32_length(22);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -439,9 +489,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowEndsInWhitespace) {
   // Window ends before "five" but after all the punctuation
   // len=26, orig_window="one two three four.... "
   snippet_spec_.set_max_window_utf32_length(26);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -472,9 +524,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowEndsMidToken) {
   //   2. trimmed, no-shifting window [0,26) "one two three four...."
   //   3. trimmed, shifted window [0,27) "one two three four.... five"
   snippet_spec_.set_max_window_utf32_length(32);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -498,9 +552,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowSizeEqualToValueSize) {
   // Max window size equals the size of the value.
   // len=34, orig_window="one two three four.... five"
   snippet_spec_.set_max_window_utf32_length(34);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -524,9 +580,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMaxWindowSizeLargerThanValueSize) {
   // Max window size exceeds the size of the value.
   // len=36, orig_window="one two three four.... five"
   snippet_spec_.set_max_window_utf32_length(36);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -558,9 +616,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMatchAtTextStart) {
   //   2. trimmed, no-shifting window [0,19) "one two three four."
   //   3. trimmed, shifted window [0,27) "one two three four.... five"
   snippet_spec_.set_max_window_utf32_length(28);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -592,9 +652,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMatchAtTextEnd) {
   //   2. trimmed, no-shifting window [14,31) "four.... five six"
   //   3. trimmed, shifted window [4,31) "two three four.... five six"
   snippet_spec_.set_max_window_utf32_length(28);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -626,9 +688,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMatchAtTextStartShortText) {
   //   2. trimmed, no-shifting window [0, 19) "one two three four."
   //   3. trimmed, shifted window [0, 22) "one two three four...."
   snippet_spec_.set_max_window_utf32_length(28);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -660,9 +724,11 @@ TEST_F(SnippetRetrieverTest, SnippetingWindowMatchAtTextEndShortText) {
   //   2. trimmed, no-shifting window [4, 22) "two three four...."
   //   3. trimmed, shifted window [0, 22) "one two three four...."
   snippet_spec_.set_max_window_utf32_length(28);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -681,9 +747,11 @@ TEST_F(SnippetRetrieverTest, PrefixSnippeting) {
           .Build();
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {"f"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Check the snippets. 'f' should match prefix-enabled property 'subject', but
   // not exact-only property 'body'
   EXPECT_THAT(snippet.entries(), SizeIs(1));
@@ -707,9 +775,11 @@ TEST_F(SnippetRetrieverTest, ExactSnippeting) {
 
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {"f"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Check the snippets
   EXPECT_THAT(snippet.entries(), IsEmpty());
 }
@@ -727,9 +797,11 @@ TEST_F(SnippetRetrieverTest, SimpleSnippetingNoWindowing) {
 
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {"foo"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Check the snippets
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("subject"));
@@ -761,9 +833,11 @@ TEST_F(SnippetRetrieverTest, SnippetingMultipleMatches) {
   // UTF-32 idx:   60  64      72        82   87  91
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {"foo", "bar"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Check the snippets
   EXPECT_THAT(snippet.entries(), SizeIs(2));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
@@ -819,9 +893,11 @@ TEST_F(SnippetRetrieverTest, SnippetingMultipleMatchesSectionRestrict) {
   // from that section should be returned by the SnippetRetriever.
   SectionIdMask section_mask = 0b00000001;
   SectionRestrictQueryTermsMap query_terms{{"", {"foo", "bar"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Check the snippets
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
@@ -871,9 +947,11 @@ TEST_F(SnippetRetrieverTest, SnippetingMultipleMatchesSectionRestrictedTerm) {
   // section.
   SectionRestrictQueryTermsMap query_terms{{"", {"subject"}},
                                            {"body", {"foo"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Check the snippets
   EXPECT_THAT(snippet.entries(), SizeIs(2));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
@@ -930,9 +1008,11 @@ TEST_F(SnippetRetrieverTest, SnippetingMultipleMatchesOneMatchPerProperty) {
 
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {"foo", "bar"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Check the snippets
   EXPECT_THAT(snippet.entries(), SizeIs(2));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
@@ -967,9 +1047,11 @@ TEST_F(SnippetRetrieverTest, PrefixSnippetingNormalization) {
           .Build();
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {"md"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("subject"));
   std::string_view content =
@@ -990,9 +1072,11 @@ TEST_F(SnippetRetrieverTest, ExactSnippetingNormalization) {
 
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {"zurich"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
   std::string_view content =
@@ -1027,8 +1111,7 @@ TEST_F(SnippetRetrieverTest, SnippetingTestOneLevel) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
       SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
@@ -1055,9 +1138,11 @@ TEST_F(SnippetRetrieverTest, SnippetingTestOneLevel) {
 
   SectionIdMask section_mask = 0b00000111;
   SectionRestrictQueryTermsMap query_terms{{"", {"polo"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(6));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("X[1]"));
   std::string_view content =
@@ -1118,8 +1203,7 @@ TEST_F(SnippetRetrieverTest, SnippetingTestMultiLevel) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
       SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
@@ -1159,9 +1243,11 @@ TEST_F(SnippetRetrieverTest, SnippetingTestMultiLevel) {
 
   SectionIdMask section_mask = 0b111111111;
   SectionRestrictQueryTermsMap query_terms{{"", {"polo"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(18));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("A.X[1]"));
   std::string_view content =
@@ -1225,8 +1311,7 @@ TEST_F(SnippetRetrieverTest, SnippetingTestMultiLevelRepeated) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
       SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
@@ -1269,9 +1354,11 @@ TEST_F(SnippetRetrieverTest, SnippetingTestMultiLevelRepeated) {
 
   SectionIdMask section_mask = 0b111111111;
   SectionRestrictQueryTermsMap query_terms{{"", {"polo"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(36));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("A[0].X[1]"));
   std::string_view content =
@@ -1340,8 +1427,7 @@ TEST_F(SnippetRetrieverTest, SnippetingTestMultiLevelSingleValue) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
       SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
@@ -1377,9 +1463,11 @@ TEST_F(SnippetRetrieverTest, SnippetingTestMultiLevelSingleValue) {
 
   SectionIdMask section_mask = 0b111111111;
   SectionRestrictQueryTermsMap query_terms{{"", {"polo"}}};
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   EXPECT_THAT(snippet.entries(), SizeIs(12));
   EXPECT_THAT(snippet.entries(0).property_name(), Eq("A[0].X"));
   std::string_view content =
@@ -1420,9 +1508,11 @@ TEST_F(SnippetRetrieverTest, CJKSnippetMatchTest) {
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {""}}};
 
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Ensure that one and only one property was matched and it was "body"
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   const SnippetProto::EntryProto* entry = &snippet.entries(0);
@@ -1481,9 +1571,11 @@ TEST_F(SnippetRetrieverTest, CJKSnippetWindowTest) {
   //   3. trimmed, shifted window [0, 6) ""
   snippet_spec_.set_max_window_utf32_length(6);
 
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Ensure that one and only one property was matched and it was "body"
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   const SnippetProto::EntryProto* entry = &snippet.entries(0);
@@ -1525,9 +1617,11 @@ TEST_F(SnippetRetrieverTest, Utf16MultiCodeUnitSnippetMatchTest) {
   SectionIdMask section_mask = 0b00000011;
   SectionRestrictQueryTermsMap query_terms{{"", {""}}};
 
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Ensure that one and only one property was matched and it was "body"
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   const SnippetProto::EntryProto* entry = &snippet.entries(0);
@@ -1580,9 +1674,11 @@ TEST_F(SnippetRetrieverTest, Utf16MultiCodeUnitWindowTest) {
   // UTF32 idx:      3   7
   snippet_spec_.set_max_window_utf32_length(6);
 
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // Ensure that one and only one property was matched and it was "body"
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   const SnippetProto::EntryProto* entry = &snippet.entries(0);
@@ -1614,8 +1710,7 @@ TEST_F(SnippetRetrieverTest, SnippettingVerbatimAscii) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
       SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
@@ -1631,9 +1726,11 @@ TEST_F(SnippetRetrieverTest, SnippettingVerbatimAscii) {
   SectionRestrictQueryTermsMap query_terms{{"", {"Hello, world!"}}};
 
   snippet_spec_.set_max_window_utf32_length(13);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_EXACT);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_EXACT, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // There should only be one snippet entry and match, the verbatim token in its
   // entirety.
   ASSERT_THAT(snippet.entries(), SizeIs(1));
@@ -1668,8 +1765,7 @@ TEST_F(SnippetRetrieverTest, SnippettingVerbatimCJK) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
       SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
@@ -1692,9 +1788,11 @@ TEST_F(SnippetRetrieverTest, SnippettingVerbatimCJK) {
   SectionRestrictQueryTermsMap query_terms{{"", {""}}};
 
   snippet_spec_.set_max_window_utf32_length(9);
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // There should only be one snippet entry and match, the verbatim token in its
   // entirety.
   ASSERT_THAT(snippet.entries(), SizeIs(1));
@@ -1727,8 +1825,7 @@ TEST_F(SnippetRetrieverTest, SnippettingRfc822Ascii) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
@@ -1751,9 +1848,11 @@ TEST_F(SnippetRetrieverTest, SnippettingRfc822Ascii) {
 
   snippet_spec_.set_max_window_utf32_length(35);
 
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "rfc822");
 
@@ -1772,8 +1871,11 @@ TEST_F(SnippetRetrieverTest, SnippettingRfc822Ascii) {
   query_terms = SectionRestrictQueryTermsMap{{"", {"tom"}}};
   snippet_spec_.set_max_window_utf32_length(36);
 
-  snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
+  snippet_context = SnippetContext(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
+  snippet = snippet_retriever_->RetrieveSnippet(snippet_context, document,
+                                                kDocumentId0, section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "rfc822");
@@ -1803,8 +1905,7 @@ TEST_F(SnippetRetrieverTest, SnippettingRfc822CJK) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       snippet_retriever_,
@@ -1824,9 +1925,11 @@ TEST_F(SnippetRetrieverTest, SnippettingRfc822CJK) {
 
   snippet_spec_.set_max_window_utf32_length(8);
 
+  SnippetContext snippet_context(
+      query_terms, /*embedding_query_vector_metadata=*/{},
+      /*embedding_match_info_map=*/{}, snippet_spec_, TERM_MATCH_PREFIX);
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, TERM_MATCH_PREFIX, snippet_spec_, document, section_mask);
-
+      snippet_context, document, kDocumentId0, section_mask);
   // There should only be one snippet entry and match, the local component token
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "rfc822");
@@ -1879,7 +1982,8 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
   snippet_spec_.set_max_window_utf32_length(40);
 
   SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, MATCH_PREFIX, snippet_spec_, document, section_mask);
+      query_terms, MATCH_PREFIX, snippet_spec_, document, kDocumentId0,
+      section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "url");
@@ -1896,8 +2000,9 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
   query_terms = SectionRestrictQueryTermsMap{{"", {"mail.goo"}}};
   snippet_spec_.set_max_window_utf32_length(40);
 
-  snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, MATCH_PREFIX, snippet_spec_, document, section_mask);
+  snippet = snippet_retriever_->RetrieveSnippet(query_terms, MATCH_PREFIX,
+                                                snippet_spec_, document,
+                                                kDocumentId0, section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "url");
@@ -1915,8 +2020,9 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
   query_terms = SectionRestrictQueryTermsMap{{"", {"goog"}}};
   snippet_spec_.set_max_window_utf32_length(40);
 
-  snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, MATCH_PREFIX, snippet_spec_, document, section_mask);
+  snippet = snippet_retriever_->RetrieveSnippet(query_terms, MATCH_PREFIX,
+                                                snippet_spec_, document,
+                                                kDocumentId0, section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "url");
@@ -1935,8 +2041,9 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
   query_terms = SectionRestrictQueryTermsMap{{"", {"mail"}}};
   snippet_spec_.set_max_window_utf32_length(40);
 
-  snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, MATCH_PREFIX, snippet_spec_, document, section_mask);
+  snippet = snippet_retriever_->RetrieveSnippet(query_terms, MATCH_PREFIX,
+                                                snippet_spec_, document,
+                                                kDocumentId0, section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "url");
@@ -1955,8 +2062,9 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
   query_terms = SectionRestrictQueryTermsMap{{"", {"http"}}};
   snippet_spec_.set_max_window_utf32_length(40);
 
-  snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, MATCH_PREFIX, snippet_spec_, document, section_mask);
+  snippet = snippet_retriever_->RetrieveSnippet(query_terms, MATCH_PREFIX,
+                                                snippet_spec_, document,
+                                                kDocumentId0, section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "url");
@@ -1975,8 +2083,9 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
   query_terms = SectionRestrictQueryTermsMap{{"", {"google"}}};
   snippet_spec_.set_max_window_utf32_length(10);
 
-  snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, MATCH_PREFIX, snippet_spec_, document, section_mask);
+  snippet = snippet_retriever_->RetrieveSnippet(query_terms, MATCH_PREFIX,
+                                                snippet_spec_, document,
+                                                kDocumentId0, section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(0));
 
@@ -1992,8 +2101,9 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
   query_terms = SectionRestrictQueryTermsMap{{"", {"google"}}};
   snippet_spec_.set_max_window_utf32_length(39);
 
-  snippet = snippet_retriever_->RetrieveSnippet(
-      query_terms, MATCH_PREFIX, snippet_spec_, document, section_mask);
+  snippet = snippet_retriever_->RetrieveSnippet(query_terms, MATCH_PREFIX,
+                                                snippet_spec_, document,
+                                                kDocumentId0, section_mask);
 
   ASSERT_THAT(snippet.entries(), SizeIs(1));
   EXPECT_THAT(snippet.entries(0).property_name(), "url");
@@ -2011,6 +2121,489 @@ TEST_F(SnippetRetrieverTest, SnippettingUrlAscii) {
 }
 #endif  // ENABLE_URL_TOKENIZER
 
+TEST_F(SnippetRetrieverTest, EmbeddingMatchInfo) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("type")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding1")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding2")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED)))
+          .Build();
+  ICING_ASSERT_OK(schema_store_->SetSchema(
+      schema, /*ignore_errors_and_delete_documents=*/true));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      snippet_retriever_,
+      SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
+                               normalizer_.get()));
+
+  DocumentProto document =
+      DocumentBuilder()
+          .SetKey("icing", "uri0")
+          .SetSchema("type")
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model1", {1, -2, -4}),     // query 0, score=0.5
+              CreateVector("my_model1", {-1, -2, 3}),     // query 0, no match
+              CreateVector("my_model2", {1, -2, 3, -4}),  // query 1, score=0.6
+              // query 0, score=-1; query 3, score=-0.4
+              CreateVector("my_model1", {1, -2, -3}),
+              CreateVector("my_model2", {1, -2, 5}))  // query 2, score=3
+          .AddVectorProperty(
+              "embedding2",
+              CreateVector("my_model2", {-1, -2, -3, -4}),  // query 1, no match
+              // query 0, score=2; query 3, score=0.2
+              CreateVector("my_model1", {-1, -2, -6}),
+              CreateVector("my_model2", {1, -2, 3, 4}))  // query 1, score=1
+          .Build();
+
+  // Params for RetrieveSnippet
+  SectionIdMask section_mask = 0b111111111;
+  SectionRestrictQueryTermsMap query_terms;
+
+  SnippetContext::EmbeddingQueryVectorMetadataMap
+      embedding_query_vector_metadata;
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model1"].insert(0);
+  embedding_query_vector_metadata[/*dimension=*/4]["my_model2"].insert(1);
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model2"].insert(2);
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model1"].insert(3);
+
+  SectionId embedding1_section_id = 0;
+  SectionId embedding2_section_id = 1;
+  SnippetContext::DocumentEmbeddingMatchInfoMap embedding_match_info_map;
+  std::vector<SnippetContext::EmbeddingMatchInfoEntry>& doc0_match_info =
+      embedding_match_info_map[kDocumentId0];
+  // embedding1[0]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/0.5, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding1_section_id));
+  // embedding1[3] - Matches both query 0 and query 3.
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-1, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/2,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding1_section_id));
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-0.4, EMBEDDING_METRIC_COSINE, /*position_in=*/2,
+      /*query_vector_index_in=*/3, /*section_id_in=*/embedding1_section_id));
+  // embedding1[2]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/0.6, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/1, /*section_id_in=*/embedding1_section_id));
+  // embedding1[4]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/3, EMBEDDING_METRIC_COSINE, /*position_in=*/0,
+      /*query_vector_index_in=*/2, /*section_id_in=*/embedding1_section_id));
+
+  // embedding2[1] - Matches both query 0 and query 3.
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/2, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding2_section_id));
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-0.2, EMBEDDING_METRIC_COSINE, /*position_in=*/0,
+      /*query_vector_index_in=*/3, /*section_id_in=*/embedding2_section_id));
+  // embedding2[2]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/1, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/1,
+      /*query_vector_index_in=*/1, /*section_id_in=*/embedding2_section_id));
+
+  SnippetContext snippet_context(query_terms, embedding_query_vector_metadata,
+                                 embedding_match_info_map, snippet_spec_,
+                                 TERM_MATCH_UNKNOWN);
+  SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
+      snippet_context, document, kDocumentId0, section_mask);
+
+  ASSERT_THAT(snippet.entries(), SizeIs(6));
+  // Section 0 matches
+  EXPECT_THAT(snippet.entries(0).property_name(), Eq("embedding1[0]"));
+  EXPECT_THAT(
+      snippet.entries(0).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/0.5, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT))));
+  EXPECT_THAT(snippet.entries(1).property_name(), Eq("embedding1[2]"));
+  EXPECT_THAT(
+      snippet.entries(1).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/0.6, /*query_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT))));
+  EXPECT_THAT(snippet.entries(2).property_name(), Eq("embedding1[3]"));
+  EXPECT_THAT(
+      snippet.entries(2).embedding_matches(),
+      UnorderedElementsAre(
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-1, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT)),
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-0.4, /*query_index=*/3, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(snippet.entries(3).property_name(), Eq("embedding1[4]"));
+  EXPECT_THAT(snippet.entries(3).embedding_matches(),
+              UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+                  /*score=*/3, /*query_index=*/2, EMBEDDING_METRIC_COSINE))));
+
+  // Section 1 matches
+  ASSERT_THAT(snippet.entries(4).property_name(), Eq("embedding2[1]"));
+  EXPECT_THAT(
+      snippet.entries(4).embedding_matches(),
+      UnorderedElementsAre(
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/2, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT)),
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-0.2, /*query_index=*/3, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(snippet.entries(5).property_name(), Eq("embedding2[2]"));
+  EXPECT_THAT(
+      snippet.entries(5).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/1, /*query_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT))));
+}
+
+TEST_F(SnippetRetrieverTest, EmbeddingMatchInfoDocumentWithNoMatch) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("type")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding1")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding2")
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED)))
+          .Build();
+  ICING_ASSERT_OK(schema_store_->SetSchema(
+      schema, /*ignore_errors_and_delete_documents=*/true));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      snippet_retriever_,
+      SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
+                               normalizer_.get()));
+
+  DocumentProto document0 =
+      DocumentBuilder()
+          .SetKey("icing", "uri0")
+          .SetSchema("type")
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model1", {1, -2, -4}),     // query 0, score=0.5
+              CreateVector("my_model1", {-1, -2, 3}),     // query 0, no match
+              CreateVector("my_model2", {1, -2, 3, -4}),  // query 1, score=0.6
+              // query 0, score=-1; query 3, score=-0.4
+              CreateVector("my_model1", {1, -2, -3}),
+              CreateVector("my_model2", {1, -2, 5}))  // query 2, score=3
+          .AddVectorProperty(
+              "embedding2",
+              CreateVector("my_model2", {-1, -2, -3, -4}),  // query 1, no match
+              // query 0, score=2; query 3, score=0.2
+              CreateVector("my_model1", {-1, -2, -6}),
+              CreateVector("my_model2", {1, -2, 3, 4}))  // query 1, score=1
+          .Build();
+
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("icing", "uri1")
+          .SetSchema("type")
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model1", {-1, -2, 6}))  // query 0, no match
+          .AddVectorProperty(
+              "embedding2",
+              CreateVector("my_model2", {-1, -2, -3, -8}))  // query 1, no match
+          .Build();
+
+  // Params for RetrieveSnippet
+  SectionIdMask section_mask = 0b111111111;
+  SectionRestrictQueryTermsMap query_terms;
+
+  SnippetContext::EmbeddingQueryVectorMetadataMap
+      embedding_query_vector_metadata;
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model1"].insert(0);
+  embedding_query_vector_metadata[/*dimension=*/4]["my_model2"].insert(1);
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model2"].insert(2);
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model1"].insert(3);
+
+  SectionId embedding1_section_id = 0;
+  SectionId embedding2_section_id = 1;
+  SnippetContext::DocumentEmbeddingMatchInfoMap embedding_match_info_map;
+  std::vector<SnippetContext::EmbeddingMatchInfoEntry>& doc0_match_info =
+      embedding_match_info_map[kDocumentId0];
+  // embedding1[0]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/0.5, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding1_section_id));
+  // embedding1[3] - Matches both query 0 and query 3.
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-1, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/2,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding1_section_id));
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-0.4, EMBEDDING_METRIC_COSINE, /*position_in=*/2,
+      /*query_vector_index_in=*/3, /*section_id_in=*/embedding1_section_id));
+  // embedding1[2]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/0.6, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/1, /*section_id_in=*/embedding1_section_id));
+  // embedding1[4]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/3, EMBEDDING_METRIC_COSINE, /*position_in=*/0,
+      /*query_vector_index_in=*/2, /*section_id_in=*/embedding1_section_id));
+
+  // embedding2[1] - Matches both query 0 and query 3.
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/2, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding2_section_id));
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-0.2, EMBEDDING_METRIC_COSINE, /*position_in=*/0,
+      /*query_vector_index_in=*/3, /*section_id_in=*/embedding2_section_id));
+  // embedding2[2]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/1, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/1,
+      /*query_vector_index_in=*/1, /*section_id_in=*/embedding2_section_id));
+
+  // Document 0 has 6 matches
+  SnippetContext snippet_context(query_terms, embedding_query_vector_metadata,
+                                 embedding_match_info_map, snippet_spec_,
+                                 TERM_MATCH_EXACT);
+  SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
+      snippet_context, document0, kDocumentId0, section_mask);
+
+  EXPECT_THAT(snippet.entries(), SizeIs(6));
+  // Section 0 matches
+  EXPECT_THAT(snippet.entries(0).property_name(), Eq("embedding1[0]"));
+  EXPECT_THAT(
+      snippet.entries(0).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/0.5, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT))));
+  EXPECT_THAT(snippet.entries(1).property_name(), Eq("embedding1[2]"));
+  EXPECT_THAT(
+      snippet.entries(1).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/0.6, /*query_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT))));
+  EXPECT_THAT(snippet.entries(2).property_name(), Eq("embedding1[3]"));
+  EXPECT_THAT(
+      snippet.entries(2).embedding_matches(),
+      UnorderedElementsAre(
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-1, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT)),
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-0.4, /*query_index=*/3, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(snippet.entries(3).property_name(), Eq("embedding1[4]"));
+  EXPECT_THAT(snippet.entries(3).embedding_matches(),
+              UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+                  /*score=*/3, /*query_index=*/2, EMBEDDING_METRIC_COSINE))));
+
+  // Section 1 matches
+  EXPECT_THAT(snippet.entries(4).property_name(), Eq("embedding2[1]"));
+  EXPECT_THAT(
+      snippet.entries(4).embedding_matches(),
+      UnorderedElementsAre(
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/2, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT)),
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-0.2, /*query_index=*/3, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(snippet.entries(5).property_name(), Eq("embedding2[2]"));
+  EXPECT_THAT(
+      snippet.entries(5).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/1, /*query_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT))));
+
+  // Document 1 has no matches
+  snippet = snippet_retriever_->RetrieveSnippet(snippet_context, document1,
+                                                kDocumentId1, section_mask);
+  EXPECT_THAT(snippet.entries(), IsEmpty());
+}
+
+TEST_F(SnippetRetrieverTest, HybridSearchSnippet) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("type")
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding1")  // SectionId 1
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("embedding2")  // SectionId 2
+                                        .SetDataTypeVector(
+                                            EMBEDDING_INDEXING_LINEAR_SEARCH)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("subject")  // SectionId 3
+                                        .SetDataTypeString(TERM_MATCH_EXACT,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_REPEATED))
+                       .AddProperty(PropertyConfigBuilder()
+                                        .SetName("body")  // SectionId 0
+                                        .SetDataTypeString(TERM_MATCH_PREFIX,
+                                                           TOKENIZER_PLAIN)
+                                        .SetCardinality(CARDINALITY_REPEATED)))
+          .Build();
+  ICING_ASSERT_OK(schema_store_->SetSchema(
+      schema, /*ignore_errors_and_delete_documents=*/true));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      snippet_retriever_,
+      SnippetRetriever::Create(schema_store_.get(), language_segmenter_.get(),
+                               normalizer_.get()));
+
+  DocumentProto document =
+      DocumentBuilder()
+          .SetKey("icing", "uri0")
+          .SetSchema("type")
+          .AddVectorProperty(
+              "embedding1",
+              CreateVector("my_model1", {1, -2, -4}),     // query 0, score=0.5
+              CreateVector("my_model1", {-1, -2, 3}),     // query 0, no match
+              CreateVector("my_model2", {1, -2, 3, -4}),  // query 1, score=0.6
+              // query 0, score=-1; query 3, score=-0.4
+              CreateVector("my_model1", {1, -2, -3}),
+              CreateVector("my_model2", {1, -2, 5}))  // query 2, score=3
+          .AddVectorProperty(
+              "embedding2",
+              CreateVector("my_model2", {-1, -2, -3, -4}),  // query 1, no match
+              // query 0, score=2; query 3, score=0.2
+              CreateVector("my_model1", {-1, -2, -6}),
+              CreateVector("my_model2", {1, -2, 3, 4}))  // query 1, score=1
+          .AddStringProperty("subject", "subject foo")
+          .AddStringProperty("body",
+                             "Concerning the subject of foo, we need to begin "
+                             "considering our options regarding body bar.")
+          .Build();
+
+  // Params for RetrieveSnippet
+  SectionIdMask section_mask = 0b111111111;
+  SectionRestrictQueryTermsMap query_terms{{"", {"subject"}},
+                                           {"body", {"foo"}}};
+
+  SnippetContext::EmbeddingQueryVectorMetadataMap
+      embedding_query_vector_metadata;
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model1"].insert(0);
+  embedding_query_vector_metadata[/*dimension=*/4]["my_model2"].insert(1);
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model2"].insert(2);
+  embedding_query_vector_metadata[/*dimension=*/3]["my_model1"].insert(3);
+
+  SectionId embedding1_section_id = 1;
+  SectionId embedding2_section_id = 2;
+  SnippetContext::DocumentEmbeddingMatchInfoMap embedding_match_info_map;
+  std::vector<SnippetContext::EmbeddingMatchInfoEntry>& doc0_match_info =
+      embedding_match_info_map[kDocumentId0];
+  // embedding1[0]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/0.5, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding1_section_id));
+  // embedding1[3] - Matches both query 0 and query 3.
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-1, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/2,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding1_section_id));
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-0.4, EMBEDDING_METRIC_COSINE, /*position_in=*/2,
+      /*query_vector_index_in=*/3, /*section_id_in=*/embedding1_section_id));
+  // embedding1[2]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/0.6, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/1, /*section_id_in=*/embedding1_section_id));
+  // embedding1[4]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/3, EMBEDDING_METRIC_COSINE, /*position_in=*/0,
+      /*query_vector_index_in=*/2, /*section_id_in=*/embedding1_section_id));
+
+  // embedding2[1] - Matches both query 0 and query 3.
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/2, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/0,
+      /*query_vector_index_in=*/0, /*section_id_in=*/embedding2_section_id));
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/-0.2, EMBEDDING_METRIC_COSINE, /*position_in=*/0,
+      /*query_vector_index_in=*/3, /*section_id_in=*/embedding2_section_id));
+  // embedding2[2]
+  doc0_match_info.push_back(SnippetContext::EmbeddingMatchInfoEntry(
+      /*score_in=*/1, EMBEDDING_METRIC_DOT_PRODUCT, /*position_in=*/1,
+      /*query_vector_index_in=*/1, /*section_id_in=*/embedding2_section_id));
+
+  SnippetContext snippet_context(query_terms, embedding_query_vector_metadata,
+                                 embedding_match_info_map, snippet_spec_,
+                                 TERM_MATCH_PREFIX);
+  SnippetProto snippet = snippet_retriever_->RetrieveSnippet(
+      snippet_context, document, kDocumentId0, section_mask);
+
+  // 6 embedding matches, 2 text matches.
+  EXPECT_THAT(snippet.entries(), SizeIs(8));
+
+  // 'body' text matches
+  EXPECT_THAT(snippet.entries(0).property_name(), Eq("body"));
+  std::string_view content =
+      GetString(&document, snippet.entries(0).property_name());
+  // The first window will be:
+  //   1. untrimmed, no-shifting window will be (-15,50).
+  //   2. trimmed, no-shifting window [0, 47) "Concerning... begin".
+  //   3. trimmed, shifted window [0, 63) "Concerning... our"
+  // The second window will be:
+  //   1. untrimmed, no-shifting window will be (-6,59).
+  //   2. trimmed, no-shifting window [0, 59) "Concerning... considering".
+  //   3. trimmed, shifted window [0, 63) "Concerning... our"
+  EXPECT_THAT(
+      GetWindows(content, snippet.entries(0)),
+      ElementsAre(
+          "Concerning the subject of foo, we need to begin considering our",
+          "Concerning the subject of foo, we need to begin considering our"));
+  EXPECT_THAT(GetMatches(content, snippet.entries(0)),
+              ElementsAre("subject", "foo"));
+  EXPECT_THAT(GetSubMatches(content, snippet.entries(0)),
+              ElementsAre("subject", "foo"));
+
+  // embedding1 matches
+  EXPECT_THAT(snippet.entries(1).property_name(), Eq("embedding1[0]"));
+  EXPECT_THAT(
+      snippet.entries(1).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/0.5, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT))));
+  EXPECT_THAT(snippet.entries(2).property_name(), Eq("embedding1[2]"));
+  EXPECT_THAT(
+      snippet.entries(2).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/0.6, /*query_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT))));
+  EXPECT_THAT(snippet.entries(3).property_name(), Eq("embedding1[3]"));
+  EXPECT_THAT(
+      snippet.entries(3).embedding_matches(),
+      UnorderedElementsAre(
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-1, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT)),
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-0.4, /*query_index=*/3, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(snippet.entries(4).property_name(), Eq("embedding1[4]"));
+  EXPECT_THAT(snippet.entries(4).embedding_matches(),
+              UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+                  /*score=*/3, /*query_index=*/2, EMBEDDING_METRIC_COSINE))));
+
+  // embedding2 matches
+  EXPECT_THAT(snippet.entries(5).property_name(), Eq("embedding2[1]"));
+  EXPECT_THAT(
+      snippet.entries(5).embedding_matches(),
+      UnorderedElementsAre(
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/2, /*query_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT)),
+          EqualsProto(CreateEmbeddingMatchSnippetProto(
+              /*score=*/-0.2, /*query_index=*/3, EMBEDDING_METRIC_COSINE))));
+  EXPECT_THAT(snippet.entries(6).property_name(), Eq("embedding2[2]"));
+  EXPECT_THAT(
+      snippet.entries(6).embedding_matches(),
+      UnorderedElementsAre(EqualsProto(CreateEmbeddingMatchSnippetProto(
+          /*score=*/1, /*query_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT))));
+
+  // 'subject' text matches
+  EXPECT_THAT(snippet.entries(7).property_name(), Eq("subject"));
+  content = GetString(&document, snippet.entries(7).property_name());
+  EXPECT_THAT(GetWindows(content, snippet.entries(7)),
+              ElementsAre("subject foo"));
+  EXPECT_THAT(GetMatches(content, snippet.entries(7)), ElementsAre("subject"));
+  EXPECT_THAT(GetSubMatches(content, snippet.entries(7)),
+              ElementsAre("subject"));
+}
+
 }  // namespace
 
 }  // namespace lib
diff --git a/icing/schema-builder.h b/icing/schema-builder.h
index ab14d7e..0c46159 100644
--- a/icing/schema-builder.h
+++ b/icing/schema-builder.h
@@ -15,7 +15,6 @@
 #ifndef ICING_SCHEMA_BUILDER_H_
 #define ICING_SCHEMA_BUILDER_H_
 
-#include <cstdint>
 #include <initializer_list>
 #include <string>
 #include <string_view>
diff --git a/icing/schema/backup-schema-producer.cc b/icing/schema/backup-schema-producer.cc
index d0a0554..2d3d28b 100644
--- a/icing/schema/backup-schema-producer.cc
+++ b/icing/schema/backup-schema-producer.cc
@@ -14,13 +14,18 @@
 
 #include "icing/schema/backup-schema-producer.h"
 
+#include <algorithm>
 #include <string_view>
 #include <unordered_map>
+#include <utility>
 #include <vector>
 
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/feature-flags.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/term.pb.h"
 #include "icing/schema/property-util.h"
+#include "icing/schema/section-manager.h"
 #include "icing/schema/section.h"
 #include "icing/util/status-macros.h"
 
@@ -53,6 +58,19 @@ std::unordered_map<std::string_view, int> CreateIndexedIdCountMap(
   return property_indexed_id_count_map;
 }
 
+bool PropertyHasInvalidIndexingType(const PropertyConfigProto& property) {
+  return property.string_indexing_config().tokenizer_type() ==
+         StringIndexingConfig::TokenizerType::RFC822;
+}
+
+bool PropertyHasInvalidDataType(const PropertyConfigProto& property,
+                                const FeatureFlags& feature_flags) {
+  if (feature_flags.enable_embedding_backup_generation()) {
+    return property.data_type() == PropertyConfigProto::DataType::VECTOR;
+  }
+  return false;
+}
+
 // Returns the indices (within schema.types()) of all types that are rollback
 // incompatible (old code cannot handle these types if they are unmodified).
 //
@@ -61,14 +79,15 @@ std::unordered_map<std::string_view, int> CreateIndexedIdCountMap(
 //   2. Use more than 16 indexed properties
 libtextclassifier3::StatusOr<std::vector<int>>
 GetRollbackIncompatibleTypeIndices(const SchemaProto& schema,
-                                   const SectionManager& type_manager) {
+                                   const SectionManager& type_manager,
+                                   const FeatureFlags& feature_flags) {
   std::vector<int> invalid_type_indices;
   for (int i = 0; i < schema.types_size(); ++i) {
     const SchemaTypeConfigProto& type = schema.types(i);
     bool rollback_incompatible = false;
     for (const PropertyConfigProto& property : type.properties()) {
-      if (property.string_indexing_config().tokenizer_type() ==
-          StringIndexingConfig::TokenizerType::RFC822) {
+      if (PropertyHasInvalidIndexingType(property) ||
+          (PropertyHasInvalidDataType(property, feature_flags))) {
         rollback_incompatible = true;
         break;
       }
@@ -87,16 +106,71 @@ GetRollbackIncompatibleTypeIndices(const SchemaProto& schema,
   return invalid_type_indices;
 }
 
+// Simulates the effects of marking property_name as unindexed. To do this, it:
+// 1. Decrements num_indexed_sections by the number of indexed ids consumed by
+//    property_name (and any sub-properties, if applicable).
+// 2. Removes property_name from property_indexed_id_count_map.
+void RemovePropertyIndexedIdCount(
+    std::string_view property_name, int& num_indexed_sections,
+    std::unordered_map<std::string_view, int>& property_indexed_id_count_map) {
+  auto indexed_count_itr = property_indexed_id_count_map.find(property_name);
+  if (indexed_count_itr != property_indexed_id_count_map.end()) {
+    num_indexed_sections -= indexed_count_itr->second;
+    property_indexed_id_count_map.erase(indexed_count_itr);
+  }
+}
+
+// Checks type for any properties that have invalid indexing types. Those
+// properties are marked as unindexed. num_indexed_sections and
+// property_indexed_id_count_map are updated to reflect this change.
+void HandleInvalidIndexingTypeProperties(
+    SchemaTypeConfigProto* type, int& num_indexed_sections,
+    std::unordered_map<std::string_view, int>& property_indexed_id_count_map) {
+  for (PropertyConfigProto& property : *type->mutable_properties()) {
+    // If the property uses the RFC tokenizer, then we need to set it to NONE
+    // and set match type UNKNOWN.
+    if (PropertyHasInvalidIndexingType(property)) {
+      property.clear_string_indexing_config();
+      RemovePropertyIndexedIdCount(property.property_name(),
+                                   num_indexed_sections,
+                                   property_indexed_id_count_map);
+    }
+  }
+}
+
+// Checks type for any properties that have invalid data types. Those properties
+// are removed entirely. num_indexed_sections and
+// property_indexed_id_count_map are updated to reflect this change.
+void RemoveInvalidDataTypeProperties(
+    SchemaTypeConfigProto* type, int& num_indexed_sections,
+    std::unordered_map<std::string_view, int>& property_indexed_id_count_map,
+    const FeatureFlags& feature_flags) {
+  auto itr = std::remove_if(
+      type->mutable_properties()->begin(), type->mutable_properties()->end(),
+      [&feature_flags](const PropertyConfigProto& property) {
+        return PropertyHasInvalidDataType(property, feature_flags);
+      });
+  // std::remove_if will simply move all of the matching elements to the end of
+  // the list and return an iterator to that first matching element. So we can
+  // iterate from that point to update the indexed id count and then erase the
+  // matching elements.
+  for (auto i = itr; i != type->mutable_properties()->end(); ++i) {
+    RemovePropertyIndexedIdCount(i->property_name(), num_indexed_sections,
+                                 property_indexed_id_count_map);
+  }
+  type->mutable_properties()->erase(itr, type->mutable_properties()->end());
+}
+
 }  // namespace
 
-/* static */ libtextclassifier3::StatusOr<BackupSchemaProducer>
-BackupSchemaProducer::Create(const SchemaProto& schema,
-                             const SectionManager& type_manager) {
+libtextclassifier3::StatusOr<BackupSchemaProducer::BackupSchemaResult>
+BackupSchemaProducer::Produce(const SchemaProto& schema,
+                              const SectionManager& type_manager) {
   ICING_ASSIGN_OR_RETURN(
       std::vector<int> invalid_type_indices,
-      GetRollbackIncompatibleTypeIndices(schema, type_manager));
+      GetRollbackIncompatibleTypeIndices(schema, type_manager, feature_flags_));
   if (invalid_type_indices.empty()) {
-    return BackupSchemaProducer();
+    return BackupSchemaResult();
   }
 
   SchemaProto backup_schema(schema);
@@ -104,6 +178,9 @@ BackupSchemaProducer::Create(const SchemaProto& schema,
   for (int i : invalid_type_indices) {
     SchemaTypeConfigProto* type = backup_schema.mutable_types(i);
 
+    // 1. Retrieve metadata on the set of indexed proeprties and (if necessary)
+    // populate the variables needed to track the indexed property counts.
+    //
     // This should never cause an error - every type should have an entry in the
     // type_manager.
     ICING_ASSIGN_OR_RETURN(const std::vector<SectionMetadata>* metadata_list,
@@ -114,21 +191,20 @@ BackupSchemaProducer::Create(const SchemaProto& schema,
       property_indexed_id_count_map = CreateIndexedIdCountMap(metadata_list);
     }
 
-    // Step 1. Switch all properties with RFC tokenizer as unindexed.
-    for (PropertyConfigProto& property : *type->mutable_properties()) {
-      // If the property uses the RFC tokenizer, then we need to set it to NONE
-      // and set match type UNKNOWN.
-      if (property.string_indexing_config().tokenizer_type() ==
-          StringIndexingConfig::TokenizerType::RFC822) {
-        property.clear_string_indexing_config();
-        --num_indexed_sections;
-        property_indexed_id_count_map.erase(property.property_name());
-      }
+    // 2. Remove any properties that are invalid for the backup schema.
+    if (feature_flags_.enable_embedding_backup_generation()) {
+      RemoveInvalidDataTypeProperties(type, num_indexed_sections,
+                                      property_indexed_id_count_map,
+                                      feature_flags_);
     }
 
-    // Step 2. If there are any types that exceed the old indexed property
-    // limit, then mark indexed properties as unindexed until we're back under
-    // the limit.
+    // 3. Mark any properties with an invalid indexing type as unindexed.
+    HandleInvalidIndexingTypeProperties(type, num_indexed_sections,
+                                        property_indexed_id_count_map);
+
+    // 4. If there are any types that exceed the old indexed property limit,
+    // then mark indexed properties as unindexed until we're back under the
+    // limit.
     if (num_indexed_sections <= kOldTotalNumSections) {
       continue;
     }
@@ -157,7 +233,7 @@ BackupSchemaProducer::Create(const SchemaProto& schema,
       }
     }
   }
-  return BackupSchemaProducer(std::move(backup_schema));
+  return BackupSchemaResult(std::move(backup_schema));
 }
 
 }  // namespace lib
diff --git a/icing/schema/backup-schema-producer.h b/icing/schema/backup-schema-producer.h
index 61dcde6..30645d9 100644
--- a/icing/schema/backup-schema-producer.h
+++ b/icing/schema/backup-schema-producer.h
@@ -16,37 +16,42 @@
 #define ICING_SCHEMA_BACKUP_SCHEMA_PRODUCER_H_
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/feature-flags.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/schema/section-manager.h"
-#include "icing/schema/section.h"
 
 namespace icing {
 namespace lib {
 
 class BackupSchemaProducer {
  public:
-  // Creates a BackupSchemaProducer based off of schema.
+  explicit BackupSchemaProducer(const FeatureFlags* feature_flags)
+      : feature_flags_(*feature_flags) {}
+
+  // Creates a BackupSchemaResult based off of schema.
   // If schema doesn't require a backup schema (because it is fully
-  // rollback-proof) then no copies will be made and `is_backup_necessary` will
-  // return false.
-  // If schema *does* require a backup schema, then `is_backup_necessary` will
-  // return true and the backup schema can be retrieved by calling `Produce`.
+  // rollback-proof) then `BackupSchemaResult::backup_schema_produced` will be
+  // false. No guarantee is made about the state of
+  // `BackupSchemaResult::backup_schema` in this case.
+  // If schema *does* require a backup schema, then
+  //`BackupSchemaResult::backup_schema_produced` will be true and
+  // `BackupSchemaResult::backup_schema` will be populated accordingly.
   // Returns:
-  //   - On success, a BackupSchemaProducer
+  //   - On success, a BackupSchemaResult
   //   - INTERNAL_ERROR if the schema is inconsistent with the type_manager.
-  static libtextclassifier3::StatusOr<BackupSchemaProducer> Create(
-      const SchemaProto& schema, const SectionManager& type_manager);
-
-  SchemaProto Produce() && { return std::move(cached_schema_); }
+  struct BackupSchemaResult {
+    BackupSchemaResult() : backup_schema(), backup_schema_produced(false) {}
+    explicit BackupSchemaResult(SchemaProto backup_schema_in)
+        : backup_schema(backup_schema_in), backup_schema_produced(true) {}
 
-  bool is_backup_necessary() const { return !cached_schema_.types().empty(); }
+    SchemaProto backup_schema;
+    bool backup_schema_produced;
+  };
+  libtextclassifier3::StatusOr<BackupSchemaProducer::BackupSchemaResult>
+  Produce(const SchemaProto& schema, const SectionManager& type_manager);
 
  private:
-  BackupSchemaProducer() = default;
-  explicit BackupSchemaProducer(SchemaProto&& schema)
-      : cached_schema_(std::move(schema)) {}
-
-  SchemaProto cached_schema_;
+  const FeatureFlags& feature_flags_;
 };
 
 }  // namespace lib
diff --git a/icing/schema/backup-schema-producer_test.cc b/icing/schema/backup-schema-producer_test.cc
index dbd033f..d0f609c 100644
--- a/icing/schema/backup-schema-producer_test.cc
+++ b/icing/schema/backup-schema-producer_test.cc
@@ -14,10 +14,12 @@
 
 #include "icing/schema/backup-schema-producer.h"
 
+#include <memory>
 #include <string>
 
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
 #include "icing/portable/equals-proto.h"
 #include "icing/proto/schema.pb.h"
@@ -26,7 +28,6 @@
 #include "icing/schema/schema-util.h"
 #include "icing/store/document-filter-data.h"
 #include "icing/store/dynamic-trie-key-mapper.h"
-#include "icing/store/key-mapper.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/tmp-directory.h"
 
@@ -39,12 +40,13 @@ using ::testing::Eq;
 using ::testing::Pointee;
 using ::testing::SizeIs;
 
-class BackupSchemaProducerTest : public ::testing::Test {
+class BackupSchemaProducerTest : public ::testing::TestWithParam<FeatureFlags> {
  protected:
   void SetUp() override {
     test_dir_ = GetTestTempDir() + "/icing";
     schema_store_dir_ = test_dir_ + "/schema_store";
     filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str());
+    feature_flags_ = std::make_unique<FeatureFlags>(GetParam());
   }
 
   void TearDown() override {
@@ -54,9 +56,10 @@ class BackupSchemaProducerTest : public ::testing::Test {
   Filesystem filesystem_;
   std::string test_dir_;
   std::string schema_store_dir_;
+  std::unique_ptr<FeatureFlags> feature_flags_;
 };
 
-TEST_F(BackupSchemaProducerTest, EmptySchema) {
+TEST_P(BackupSchemaProducerTest, EmptySchema) {
   SchemaProto empty;
   SchemaUtil::TypeConfigMap type_config_map;
   SchemaUtil::BuildTypeConfigMap(empty, &type_config_map);
@@ -68,14 +71,14 @@ TEST_F(BackupSchemaProducerTest, EmptySchema) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(empty,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(false));
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(empty, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(false));
 }
 
-TEST_F(BackupSchemaProducerTest, NoIndexedPropertySchema) {
+TEST_P(BackupSchemaProducerTest, NoIndexedPropertySchema) {
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
@@ -114,14 +117,14 @@ TEST_F(BackupSchemaProducerTest, NoIndexedPropertySchema) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(false));
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(false));
 }
 
-TEST_F(BackupSchemaProducerTest, RollbackCompatibleSchema) {
+TEST_P(BackupSchemaProducerTest, RollbackCompatibleSchema) {
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
@@ -162,14 +165,14 @@ TEST_F(BackupSchemaProducerTest, RollbackCompatibleSchema) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(false));
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(false));
 }
 
-TEST_F(BackupSchemaProducerTest, RemoveRfc822) {
+TEST_P(BackupSchemaProducerTest, RemoveRfc822) {
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("TypeA").AddProperty(
@@ -190,12 +193,11 @@ TEST_F(BackupSchemaProducerTest, RemoveRfc822) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(true));
-  SchemaProto backup = std::move(backup_producer).Produce();
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
 
   SchemaProto expected_backup =
       SchemaBuilder()
@@ -205,10 +207,11 @@ TEST_F(BackupSchemaProducerTest, RemoveRfc822) {
                   .SetCardinality(CARDINALITY_OPTIONAL)
                   .SetDataType(TYPE_STRING)))
           .Build();
-  EXPECT_THAT(backup, portable_equals_proto::EqualsProto(expected_backup));
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
 }
 
-TEST_F(BackupSchemaProducerTest, MakeExtraStringIndexedPropertiesUnindexed) {
+TEST_P(BackupSchemaProducerTest, MakeExtraStringIndexedPropertiesUnindexed) {
   PropertyConfigBuilder indexed_string_property_builder =
       PropertyConfigBuilder()
           .SetCardinality(CARDINALITY_OPTIONAL)
@@ -251,12 +254,11 @@ TEST_F(BackupSchemaProducerTest, MakeExtraStringIndexedPropertiesUnindexed) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(true));
-  SchemaProto backup = std::move(backup_producer).Produce();
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
 
   PropertyConfigBuilder unindexed_string_property_builder =
       PropertyConfigBuilder()
@@ -287,10 +289,11 @@ TEST_F(BackupSchemaProducerTest, MakeExtraStringIndexedPropertiesUnindexed) {
           .AddProperty(unindexed_string_property_builder.SetName("prop19"))
           .Build();
   SchemaProto expected_backup = SchemaBuilder().AddType(expected_type).Build();
-  EXPECT_THAT(backup, portable_equals_proto::EqualsProto(expected_backup));
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
 }
 
-TEST_F(BackupSchemaProducerTest, MakeExtraIntIndexedPropertiesUnindexed) {
+TEST_P(BackupSchemaProducerTest, MakeExtraIntIndexedPropertiesUnindexed) {
   PropertyConfigBuilder indexed_int_property_builder =
       PropertyConfigBuilder()
           .SetCardinality(CARDINALITY_OPTIONAL)
@@ -333,12 +336,11 @@ TEST_F(BackupSchemaProducerTest, MakeExtraIntIndexedPropertiesUnindexed) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(true));
-  SchemaProto backup = std::move(backup_producer).Produce();
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
 
   PropertyConfigBuilder unindexed_int_property_builder =
       PropertyConfigBuilder()
@@ -369,10 +371,11 @@ TEST_F(BackupSchemaProducerTest, MakeExtraIntIndexedPropertiesUnindexed) {
           .AddProperty(unindexed_int_property_builder.SetName("prop19"))
           .Build();
   SchemaProto expected_backup = SchemaBuilder().AddType(expected_type).Build();
-  EXPECT_THAT(backup, portable_equals_proto::EqualsProto(expected_backup));
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
 }
 
-TEST_F(BackupSchemaProducerTest, MakeExtraDocumentIndexedPropertiesUnindexed) {
+TEST_P(BackupSchemaProducerTest, MakeExtraDocumentIndexedPropertiesUnindexed) {
   PropertyConfigBuilder indexed_string_property_builder =
       PropertyConfigBuilder()
           .SetCardinality(CARDINALITY_OPTIONAL)
@@ -418,12 +421,11 @@ TEST_F(BackupSchemaProducerTest, MakeExtraDocumentIndexedPropertiesUnindexed) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(true));
-  SchemaProto backup = std::move(backup_producer).Produce();
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
 
   PropertyConfigProto unindexed_document_property =
       PropertyConfigBuilder()
@@ -441,10 +443,11 @@ TEST_F(BackupSchemaProducerTest, MakeExtraDocumentIndexedPropertiesUnindexed) {
           .Build();
   SchemaProto expected_backup =
       SchemaBuilder().AddType(expected_typeA).AddType(typeB).Build();
-  EXPECT_THAT(backup, portable_equals_proto::EqualsProto(expected_backup));
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
 }
 
-TEST_F(
+TEST_P(
     BackupSchemaProducerTest,
     MakeExtraDocumentIndexedPropertiesWithIndexableNestedPropertiesListUnindexed) {
   PropertyConfigBuilder indexed_string_property_builder =
@@ -504,12 +507,11 @@ TEST_F(
   ASSERT_THAT(schema_type_manager->section_manager().GetMetadataList("TypeA"),
               IsOkAndHolds(Pointee(SizeIs(18))));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(true));
-  SchemaProto backup = std::move(backup_producer).Produce();
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
 
   PropertyConfigProto unindexed_document_property =
       PropertyConfigBuilder()
@@ -531,14 +533,17 @@ TEST_F(
           .Build();
   SchemaProto expected_backup =
       SchemaBuilder().AddType(expected_typeA).AddType(typeB).Build();
-  EXPECT_THAT(backup, portable_equals_proto::EqualsProto(expected_backup));
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
 }
 
-TEST_F(BackupSchemaProducerTest, MakeRfcPropertiesUnindexedFirst) {
+TEST_P(BackupSchemaProducerTest, MakeRfcPropertiesUnindexedFirst) {
   PropertyConfigBuilder indexed_string_property_builder =
       PropertyConfigBuilder()
           .SetCardinality(CARDINALITY_OPTIONAL)
           .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN);
+  // Create a type with 16 indexed properties, one of which is an RFC822
+  // property.
   SchemaTypeConfigProto typeA =
       SchemaTypeConfigBuilder()
           .SetType("TypeA")
@@ -547,6 +552,7 @@ TEST_F(BackupSchemaProducerTest, MakeRfcPropertiesUnindexedFirst) {
           .AddProperty(indexed_string_property_builder.SetName("prop2"))
           .AddProperty(indexed_string_property_builder.SetName("prop3"))
           .AddProperty(indexed_string_property_builder.SetName("prop4"))
+          // "propRfc" takes the place of "prop5".
           .AddProperty(
               PropertyConfigBuilder()
                   .SetName("propRfc")
@@ -579,13 +585,14 @@ TEST_F(BackupSchemaProducerTest, MakeRfcPropertiesUnindexedFirst) {
       std::unique_ptr<SchemaTypeManager> schema_type_manager,
       SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(true));
-  SchemaProto backup = std::move(backup_producer).Produce();
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
 
+  // The RFC822 property should have been marked as unindexed first. This would
+  // leave only 15 indexed properties which is under the old limit of 16.
   SchemaTypeConfigProto expected_typeA =
       SchemaTypeConfigBuilder()
           .SetType("TypeA")
@@ -611,10 +618,11 @@ TEST_F(BackupSchemaProducerTest, MakeRfcPropertiesUnindexedFirst) {
           .AddProperty(indexed_string_property_builder.SetName("prop16"))
           .Build();
   SchemaProto expected_backup = SchemaBuilder().AddType(expected_typeA).Build();
-  EXPECT_THAT(backup, portable_equals_proto::EqualsProto(expected_backup));
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
 }
 
-TEST_F(BackupSchemaProducerTest, MakeExtraPropertiesUnindexedMultipleTypes) {
+TEST_P(BackupSchemaProducerTest, MakeExtraPropertiesUnindexedMultipleTypes) {
   PropertyConfigBuilder indexed_string_property_builder =
       PropertyConfigBuilder()
           .SetCardinality(CARDINALITY_OPTIONAL)
@@ -677,12 +685,11 @@ TEST_F(BackupSchemaProducerTest, MakeExtraPropertiesUnindexedMultipleTypes) {
   ASSERT_THAT(schema_type_manager->section_manager().GetMetadataList("TypeA"),
               IsOkAndHolds(Pointee(SizeIs(26))));
 
+  BackupSchemaProducer backup_producer(feature_flags_.get());
   ICING_ASSERT_OK_AND_ASSIGN(
-      BackupSchemaProducer backup_producer,
-      BackupSchemaProducer::Create(schema,
-                                   schema_type_manager->section_manager()));
-  EXPECT_THAT(backup_producer.is_backup_necessary(), Eq(true));
-  SchemaProto backup = std::move(backup_producer).Produce();
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
 
   PropertyConfigBuilder unindexed_string_property_builder =
       PropertyConfigBuilder()
@@ -728,9 +735,232 @@ TEST_F(BackupSchemaProducerTest, MakeExtraPropertiesUnindexedMultipleTypes) {
           .Build();
   SchemaProto expected_backup =
       SchemaBuilder().AddType(expected_typeA).AddType(typeB).Build();
-  EXPECT_THAT(backup, portable_equals_proto::EqualsProto(expected_backup));
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
 }
 
+TEST_P(BackupSchemaProducerTest,
+       EmbeddingBackupDisabledDoesNotRemoveEmbeddingProperty) {
+  if (feature_flags_->enable_embedding_backup_generation()) {
+    GTEST_SKIP() << "enable_embedding_backup_generation is enabled. Skipping.";
+  }
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("TypeA").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("prop1")
+                  .SetCardinality(CARDINALITY_OPTIONAL)
+                  .SetDataTypeVector(EmbeddingIndexingConfig::
+                                         EmbeddingIndexingType::LINEAR_SEARCH)))
+          .Build();
+
+  SchemaUtil::TypeConfigMap type_config_map;
+  SchemaUtil::BuildTypeConfigMap(schema, &type_config_map);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DynamicTrieKeyMapper<SchemaTypeId>> type_id_mapper,
+      DynamicTrieKeyMapper<SchemaTypeId>::Create(filesystem_, schema_store_dir_,
+                                                 /*maximum_size_bytes=*/10000));
+  ASSERT_THAT(type_id_mapper->Put("TypeA", 0), IsOk());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaTypeManager> schema_type_manager,
+      SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
+
+  BackupSchemaProducer backup_producer(feature_flags_.get());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(false));
+}
+
+TEST_P(BackupSchemaProducerTest, RemoveEmbeddingProperty) {
+  if (!feature_flags_->enable_embedding_backup_generation()) {
+    GTEST_SKIP() << "enable_embedding_backup_generation is disabled. Skipping.";
+  }
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("TypeA").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("prop1")
+                  .SetCardinality(CARDINALITY_OPTIONAL)
+                  .SetDataTypeVector(EmbeddingIndexingConfig::
+                                         EmbeddingIndexingType::LINEAR_SEARCH)))
+          .Build();
+
+  SchemaUtil::TypeConfigMap type_config_map;
+  SchemaUtil::BuildTypeConfigMap(schema, &type_config_map);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DynamicTrieKeyMapper<SchemaTypeId>> type_id_mapper,
+      DynamicTrieKeyMapper<SchemaTypeId>::Create(filesystem_, schema_store_dir_,
+                                                 /*maximum_size_bytes=*/10000));
+  ASSERT_THAT(type_id_mapper->Put("TypeA", 0), IsOk());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaTypeManager> schema_type_manager,
+      SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
+
+  BackupSchemaProducer backup_producer(feature_flags_.get());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
+
+  // The Embedding Property should have been removed from the backup schema.
+  SchemaProto expected_backup =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("TypeA"))
+          .Build();
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
+}
+
+// Even REQUIRED embedding properties should be removed.
+TEST_P(BackupSchemaProducerTest, RemoveRequiredEmbeddingProperty) {
+  if (!feature_flags_->enable_embedding_backup_generation()) {
+    GTEST_SKIP() << "enable_embedding_backup_generation is disabled. Skipping.";
+  }
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("TypeA").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("prop1")
+                  .SetCardinality(CARDINALITY_REQUIRED)
+                  .SetDataTypeVector(EmbeddingIndexingConfig::
+                                         EmbeddingIndexingType::LINEAR_SEARCH)))
+          .Build();
+
+  SchemaUtil::TypeConfigMap type_config_map;
+  SchemaUtil::BuildTypeConfigMap(schema, &type_config_map);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DynamicTrieKeyMapper<SchemaTypeId>> type_id_mapper,
+      DynamicTrieKeyMapper<SchemaTypeId>::Create(filesystem_, schema_store_dir_,
+                                                 /*maximum_size_bytes=*/10000));
+  ASSERT_THAT(type_id_mapper->Put("TypeA", 0), IsOk());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaTypeManager> schema_type_manager,
+      SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
+
+  BackupSchemaProducer backup_producer(feature_flags_.get());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
+
+  // The Embedding Property should have been removed from the backup schema.
+  SchemaProto expected_backup =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("TypeA"))
+          .Build();
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
+}
+
+// Embedding properties consume an indexed property id. We should remove them
+// first to minimize the number of indexed properties that we have to mark as
+// unindexed.
+TEST_P(BackupSchemaProducerTest, RemoveEmbeddingPropertyFirst) {
+  if (!feature_flags_->enable_embedding_backup_generation()) {
+    GTEST_SKIP() << "enable_embedding_backup_generation is disabled. Skipping.";
+  }
+
+  PropertyConfigBuilder indexed_string_property_builder =
+      PropertyConfigBuilder()
+          .SetCardinality(CARDINALITY_OPTIONAL)
+          .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN);
+  // Create a type with 16 indexed properties, one of which is an embedding
+  // property.
+  SchemaTypeConfigProto typeA =
+      SchemaTypeConfigBuilder()
+          .SetType("TypeA")
+          .AddProperty(indexed_string_property_builder.SetName("prop0"))
+          .AddProperty(indexed_string_property_builder.SetName("prop1"))
+          .AddProperty(indexed_string_property_builder.SetName("prop2"))
+          .AddProperty(indexed_string_property_builder.SetName("prop3"))
+          .AddProperty(indexed_string_property_builder.SetName("prop4"))
+          // "propEmbed" takes the place of "prop5".
+          .AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("propEmbed")
+                  .SetCardinality(CARDINALITY_OPTIONAL)
+                  .SetDataTypeVector(EmbeddingIndexingConfig::
+                                         EmbeddingIndexingType::LINEAR_SEARCH))
+          .AddProperty(indexed_string_property_builder.SetName("prop6"))
+          .AddProperty(indexed_string_property_builder.SetName("prop7"))
+          .AddProperty(indexed_string_property_builder.SetName("prop8"))
+          .AddProperty(indexed_string_property_builder.SetName("prop9"))
+          .AddProperty(indexed_string_property_builder.SetName("prop10"))
+          .AddProperty(indexed_string_property_builder.SetName("prop11"))
+          .AddProperty(indexed_string_property_builder.SetName("prop12"))
+          .AddProperty(indexed_string_property_builder.SetName("prop13"))
+          .AddProperty(indexed_string_property_builder.SetName("prop14"))
+          .AddProperty(indexed_string_property_builder.SetName("prop15"))
+          .AddProperty(indexed_string_property_builder.SetName("prop16"))
+          .Build();
+
+  SchemaProto schema = SchemaBuilder().AddType(typeA).Build();
+
+  SchemaUtil::TypeConfigMap type_config_map;
+  SchemaUtil::BuildTypeConfigMap(schema, &type_config_map);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DynamicTrieKeyMapper<SchemaTypeId>> type_id_mapper,
+      DynamicTrieKeyMapper<SchemaTypeId>::Create(filesystem_, schema_store_dir_,
+                                                 /*maximum_size_bytes=*/10000));
+  ASSERT_THAT(type_id_mapper->Put("TypeA", 0), IsOk());
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaTypeManager> schema_type_manager,
+      SchemaTypeManager::Create(type_config_map, type_id_mapper.get()));
+
+  BackupSchemaProducer backup_producer(feature_flags_.get());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      BackupSchemaProducer::BackupSchemaResult result,
+      backup_producer.Produce(schema, schema_type_manager->section_manager()));
+  EXPECT_THAT(result.backup_schema_produced, Eq(true));
+
+  // The Embedding Property should have been removed from the backup schema.
+  // This would leave only 15 indexed properties which is under the old limit of
+  // 16. All remaining properties should remain indexed.
+  SchemaTypeConfigProto expected_typeA =
+      SchemaTypeConfigBuilder()
+          .SetType("TypeA")
+          .AddProperty(indexed_string_property_builder.SetName("prop0"))
+          .AddProperty(indexed_string_property_builder.SetName("prop1"))
+          .AddProperty(indexed_string_property_builder.SetName("prop2"))
+          .AddProperty(indexed_string_property_builder.SetName("prop3"))
+          .AddProperty(indexed_string_property_builder.SetName("prop4"))
+          .AddProperty(indexed_string_property_builder.SetName("prop6"))
+          .AddProperty(indexed_string_property_builder.SetName("prop7"))
+          .AddProperty(indexed_string_property_builder.SetName("prop8"))
+          .AddProperty(indexed_string_property_builder.SetName("prop9"))
+          .AddProperty(indexed_string_property_builder.SetName("prop10"))
+          .AddProperty(indexed_string_property_builder.SetName("prop11"))
+          .AddProperty(indexed_string_property_builder.SetName("prop12"))
+          .AddProperty(indexed_string_property_builder.SetName("prop13"))
+          .AddProperty(indexed_string_property_builder.SetName("prop14"))
+          .AddProperty(indexed_string_property_builder.SetName("prop15"))
+          .AddProperty(indexed_string_property_builder.SetName("prop16"))
+          .Build();
+  SchemaProto expected_backup = SchemaBuilder().AddType(expected_typeA).Build();
+  EXPECT_THAT(result.backup_schema,
+              portable_equals_proto::EqualsProto(expected_backup));
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    BackupSchemaProducerTest, BackupSchemaProducerTest,
+    testing::Values(
+        FeatureFlags(/*allow_circular_schema_definitions=*/true,
+                     /*enable_scorable_properties=*/true,
+                     /*enable_embedding_quantization=*/true,
+                     /*enable_repeated_field_joins=*/true,
+                     /*enable_embedding_backup_generation=*/false,
+                     /*enable_schema_database=*/true,
+                     /*release_backup_schema_file_if_overlay_present=*/true),
+        FeatureFlags(/*allow_circular_schema_definitions=*/true,
+                     /*enable_scorable_properties=*/true,
+                     /*enable_embedding_quantization=*/true,
+                     /*enable_repeated_field_joins=*/true,
+                     /*enable_embedding_backup_generation=*/true,
+                     /*enable_schema_database=*/true,
+                     /*release_backup_schema_file_if_overlay_present=*/true)));
+
 }  // namespace
 
 }  // namespace lib
diff --git a/icing/schema/schema-store.cc b/icing/schema/schema-store.cc
index aaa9f84..dda7746 100644
--- a/icing/schema/schema-store.cc
+++ b/icing/schema/schema-store.cc
@@ -45,7 +45,6 @@
 #include "icing/proto/storage.pb.h"
 #include "icing/schema/backup-schema-producer.h"
 #include "icing/schema/joinable-property.h"
-#include "icing/schema/property-util.h"
 #include "icing/schema/schema-property-iterator.h"
 #include "icing/schema/schema-type-manager.h"
 #include "icing/schema/schema-util.h"
@@ -170,6 +169,40 @@ bool ParseAndPopulateAppSearchDatabaseField(SchemaProto& schema_proto) {
   return populated_database_field;
 }
 
+// Compares the schema types list defined in two schemas, ignoring order.
+//
+// Requires: old_schema.schema_database() == new_schema.schema_database()
+//
+// Returns: true if the types in `new_schema` are identical to the types
+// in `old_schema`, otherwise returns false.
+bool AreSchemaTypesEqual(const SchemaProto& old_schema,
+                         const SchemaProto& new_schema) {
+  if (old_schema.types().size() != new_schema.types().size()) {
+    return false;
+  }
+
+  // Create a map of old schema types to and check that the new schema's types
+  // are identical.
+  std::unordered_map<std::string_view, const SchemaTypeConfigProto&>
+      old_schema_types;
+  old_schema_types.reserve(old_schema.types().size());
+  for (const SchemaTypeConfigProto& old_type : old_schema.types()) {
+    old_schema_types.emplace(old_type.schema_type(), old_type);
+  }
+  for (const SchemaTypeConfigProto& new_type : new_schema.types()) {
+    auto old_type_itr = old_schema_types.find(new_type.schema_type());
+    if (old_type_itr == old_schema_types.end()) {
+      return false;
+    }
+    if (old_type_itr->second.SerializeAsString() !=
+        new_type.SerializeAsString()) {
+      return false;
+    }
+  }
+
+  return true;
+}
+
 }  // namespace
 
 /* static */ libtextclassifier3::StatusOr<SchemaStore::Header>
@@ -253,7 +286,7 @@ libtextclassifier3::Status SchemaStore::Header::PersistToDisk() {
 libtextclassifier3::StatusOr<std::unique_ptr<SchemaStore>> SchemaStore::Create(
     const Filesystem* filesystem, const std::string& base_dir,
     const Clock* clock, const FeatureFlags* feature_flags,
-    bool enable_schema_database, InitializeStatsProto* initialize_stats) {
+    InitializeStatsProto* initialize_stats) {
   ICING_RETURN_ERROR_IF_NULL(filesystem);
   ICING_RETURN_ERROR_IF_NULL(clock);
   ICING_RETURN_ERROR_IF_NULL(feature_flags);
@@ -262,17 +295,15 @@ libtextclassifier3::StatusOr<std::unique_ptr<SchemaStore>> SchemaStore::Create(
     return absl_ports::FailedPreconditionError(
         "Schema store base directory does not exist!");
   }
-  std::unique_ptr<SchemaStore> schema_store =
-      std::unique_ptr<SchemaStore>(new SchemaStore(
-          filesystem, base_dir, clock, feature_flags, enable_schema_database));
+  std::unique_ptr<SchemaStore> schema_store = std::unique_ptr<SchemaStore>(
+      new SchemaStore(filesystem, base_dir, clock, feature_flags));
   ICING_RETURN_IF_ERROR(schema_store->Initialize(initialize_stats));
   return schema_store;
 }
 
 libtextclassifier3::StatusOr<std::unique_ptr<SchemaStore>> SchemaStore::Create(
     const Filesystem* filesystem, const std::string& base_dir,
-    const Clock* clock, const FeatureFlags* feature_flags, SchemaProto schema,
-    bool enable_schema_database) {
+    const Clock* clock, const FeatureFlags* feature_flags, SchemaProto schema) {
   ICING_RETURN_ERROR_IF_NULL(filesystem);
   ICING_RETURN_ERROR_IF_NULL(clock);
   ICING_RETURN_ERROR_IF_NULL(feature_flags);
@@ -281,9 +312,8 @@ libtextclassifier3::StatusOr<std::unique_ptr<SchemaStore>> SchemaStore::Create(
     return absl_ports::FailedPreconditionError(
         "Schema store base directory does not exist!");
   }
-  std::unique_ptr<SchemaStore> schema_store =
-      std::unique_ptr<SchemaStore>(new SchemaStore(
-          filesystem, base_dir, clock, feature_flags, enable_schema_database));
+  std::unique_ptr<SchemaStore> schema_store = std::unique_ptr<SchemaStore>(
+      new SchemaStore(filesystem, base_dir, clock, feature_flags));
   ICING_RETURN_IF_ERROR(schema_store->Initialize(std::move(schema)));
   return schema_store;
 }
@@ -465,19 +495,16 @@ SchemaStore::HandleOverlaySchemaForVersionChange(
 }
 
 SchemaStore::SchemaStore(const Filesystem* filesystem, std::string base_dir,
-                         const Clock* clock, const FeatureFlags* feature_flags,
-                         bool enable_schema_database)
+                         const Clock* clock, const FeatureFlags* feature_flags)
     : filesystem_(filesystem),
       base_dir_(std::move(base_dir)),
       clock_(clock),
       feature_flags_(feature_flags),
-      schema_file_(std::make_unique<FileBackedProto<SchemaProto>>(
-          *filesystem, MakeSchemaFilename(base_dir_))),
-      enable_schema_database_(enable_schema_database) {}
+      schema_file_(filesystem, MakeSchemaFilename(base_dir_)) {}
 
 SchemaStore::~SchemaStore() {
-  if (has_schema_successfully_set_ && schema_file_ != nullptr &&
-      schema_type_mapper_ != nullptr && schema_type_manager_ != nullptr) {
+  if (has_schema_successfully_set_ && schema_type_mapper_ != nullptr &&
+      schema_type_manager_ != nullptr) {
     if (!PersistToDisk().ok()) {
       ICING_LOG(ERROR) << "Error persisting to disk in SchemaStore destructor";
     }
@@ -491,8 +518,9 @@ libtextclassifier3::Status SchemaStore::Initialize(SchemaProto new_schema) {
         "Incorrectly tried to initialize schema store with a new schema, when "
         "one is already set!");
   }
-  ICING_RETURN_IF_ERROR(schema_file_->Write(
-      std::make_unique<SchemaProto>(std::move(new_schema))));
+  // ResetSchemaFileIfNeeded() will be called in InitializeInternal below.
+  ICING_RETURN_IF_ERROR(
+      schema_file_.Write(std::make_unique<SchemaProto>(std::move(new_schema))));
   return InitializeInternal(/*create_overlay_if_necessary=*/true,
                             /*initialize_stats=*/nullptr);
 }
@@ -530,8 +558,9 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   bool overlay_schema_file_exists =
       filesystem_->FileExists(overlay_schema_filename.c_str());
 
-  libtextclassifier3::Status base_schema_state = schema_file_->Read().status();
+  libtextclassifier3::Status base_schema_state = schema_file_.Read().status();
   if (!base_schema_state.ok() && !absl_ports::IsNotFound(base_schema_state)) {
+    ResetSchemaFileIfNeeded();
     return base_schema_state;
   }
 
@@ -539,6 +568,7 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   // 1. Everything is missing. This is an empty schema store.
   if (!base_schema_state.ok() && !overlay_schema_file_exists &&
       !header_exists) {
+    ResetSchemaFileIfNeeded();
     return libtextclassifier3::Status::OK;
   }
 
@@ -547,6 +577,7 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   if (base_schema_state.ok() && !overlay_schema_file_exists && header_exists &&
       !header_->overlay_created()) {
     // Nothing else to do. Just return safely.
+    ResetSchemaFileIfNeeded();
     return libtextclassifier3::Status::OK;
   }
 
@@ -556,6 +587,7 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
       header_->overlay_created()) {
     overlay_schema_file_ = std::make_unique<FileBackedProto<SchemaProto>>(
         *filesystem_, MakeOverlaySchemaFilename(base_dir_));
+    ResetSchemaFileIfNeeded();
     return libtextclassifier3::Status::OK;
   }
 
@@ -563,6 +595,7 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   // Return an error.
   bool overlay_created = header_->overlay_created();
   bool base_schema_exists = base_schema_state.ok();
+  ResetSchemaFileIfNeeded();
   return absl_ports::InternalError(IcingStringUtil::StringPrintf(
       "Unable to properly load schema. Header {exists:%d, overlay_created:%d}, "
       "base schema exists: %d, overlay_schema_exists: %d",
@@ -628,14 +661,13 @@ libtextclassifier3::Status SchemaStore::RegenerateDerivedFiles(
   ICING_RETURN_IF_ERROR(BuildInMemoryCache());
 
   if (create_overlay_if_necessary) {
+    BackupSchemaProducer producer(feature_flags_);
     ICING_ASSIGN_OR_RETURN(
-        BackupSchemaProducer producer,
-        BackupSchemaProducer::Create(*schema_proto,
-                                     schema_type_manager_->section_manager()));
-
-    if (producer.is_backup_necessary()) {
-      SchemaProto base_schema = std::move(producer).Produce();
+        BackupSchemaProducer::BackupSchemaResult backup_result,
+        producer.Produce(*schema_proto,
+                         schema_type_manager_->section_manager()));
 
+    if (backup_result.backup_schema_produced) {
       // The overlay schema should be written to the overlay file location.
       overlay_schema_file_ = std::make_unique<FileBackedProto<SchemaProto>>(
           *filesystem_, MakeOverlaySchemaFilename(base_dir_));
@@ -644,8 +676,8 @@ libtextclassifier3::Status SchemaStore::RegenerateDerivedFiles(
 
       // The base schema should be written to the original file
       auto base_schema_ptr =
-          std::make_unique<SchemaProto>(std::move(base_schema));
-      ICING_RETURN_IF_ERROR(schema_file_->Write(std::move(base_schema_ptr)));
+          std::make_unique<SchemaProto>(std::move(backup_result.backup_schema));
+      ICING_RETURN_IF_ERROR(schema_file_.Write(std::move(base_schema_ptr)));
 
       // LINT.IfChange(min_overlay_version_compatibility)
       // Although the current version is 5, the schema is compatible with
@@ -662,6 +694,7 @@ libtextclassifier3::Status SchemaStore::RegenerateDerivedFiles(
 
   // Write the header
   ICING_RETURN_IF_ERROR(UpdateChecksum());
+  ResetSchemaFileIfNeeded();
   return libtextclassifier3::Status::OK;
 }
 
@@ -741,15 +774,13 @@ libtextclassifier3::Status SchemaStore::ResetSchemaTypeMapper() {
 }
 
 libtextclassifier3::StatusOr<Crc32> SchemaStore::GetChecksum() const {
-  ICING_ASSIGN_OR_RETURN(Crc32 schema_checksum, schema_file_->GetChecksum());
-  // We've gotten the schema_checksum successfully. This means that
-  // schema_file_->Read() will only return either a schema or NOT_FOUND.
-  // Sadly, we actually need to differentiate between an existing, but empty
-  // schema and a non-existent schema (both of which will have a checksum of 0).
-  // For existing, but empty schemas, we need to continue with the checksum
-  // calculation of the other components.
-  if (schema_checksum == Crc32() &&
-      absl_ports::IsNotFound(schema_file_->Read().status())) {
+  ICING_ASSIGN_OR_RETURN(Crc32 schema_checksum, schema_file_.GetChecksum());
+  // We've gotten the schema_checksum successfully. Sadly, we still need to
+  // differentiate between an existing, but empty schema and a non-existent
+  // schema (both of which will have a checksum of 0). For existing, but empty
+  // schemas, we need to continue with the checksum calculation of the other
+  // components.
+  if (schema_checksum == Crc32() && !has_schema_successfully_set_) {
     return schema_checksum;
   }
 
@@ -768,18 +799,13 @@ libtextclassifier3::StatusOr<Crc32> SchemaStore::GetChecksum() const {
 }
 
 libtextclassifier3::StatusOr<Crc32> SchemaStore::UpdateChecksum() {
-  // FileBackedProto always keeps its checksum up to date. So we just need to
-  // retrieve the checksum.
-  ICING_ASSIGN_OR_RETURN(Crc32 schema_checksum, schema_file_->GetChecksum());
-  // We've gotten the schema_checksum successfully. This means that
-  // schema_file_->Read() will only return either a schema or NOT_FOUND.
-  // Sadly, we actually need to differentiate between an existing, but empty
-  // schema and a non-existent schema (both of which will have a checksum of 0).
-  // For existing, but empty schemas, we need to continue with the checksum
-  // calculation of the other components so that we will correctly write the
-  // header.
-  if (schema_checksum == Crc32() &&
-      absl_ports::IsNotFound(schema_file_->Read().status())) {
+  ICING_ASSIGN_OR_RETURN(Crc32 schema_checksum, schema_file_.GetChecksum());
+  // We've gotten the schema_checksum successfully. Sadly, we still need to
+  // differentiate between an existing, but empty schema and a non-existent
+  // schema (both of which will have a checksum of 0). For existing, but empty
+  // schemas, we need to continue with the checksum calculation of the other
+  // components.
+  if (schema_checksum == Crc32() && !has_schema_successfully_set_) {
     return schema_checksum;
   }
   Crc32 total_checksum;
@@ -805,7 +831,8 @@ libtextclassifier3::StatusOr<const SchemaProto*> SchemaStore::GetSchema()
   if (overlay_schema_file_ != nullptr) {
     return overlay_schema_file_->Read();
   }
-  return schema_file_->Read();
+
+  return schema_file_.Read();
 }
 
 libtextclassifier3::StatusOr<SchemaProto> SchemaStore::GetSchema(
@@ -829,41 +856,45 @@ libtextclassifier3::StatusOr<SchemaProto> SchemaStore::GetSchema(
   return schema_proto;
 }
 
-// TODO(cassiewang): Consider removing this definition of SetSchema if it's not
-// needed by production code. It's currently being used by our tests, but maybe
-// it's trivial to change our test code to also use the
-// SetSchema(SchemaProto&& new_schema)
+// TODO - b/337913932 - Remove this method once all callers are migrated to
+// SetSchema(SetSchemaRequestProto&& set_schema_request). This should just be
+// used in our tests.
 libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult>
-SchemaStore::SetSchema(const SchemaProto& new_schema,
-                       bool ignore_errors_and_delete_documents,
-                       bool allow_circular_schema_definitions) {
-  return SetSchema(SchemaProto(new_schema), ignore_errors_and_delete_documents,
-                   allow_circular_schema_definitions);
+SchemaStore::SetSchema(SchemaProto new_schema,
+                       bool ignore_errors_and_delete_documents) {
+  SetSchemaRequestProto set_schema_request;
+  *set_schema_request.mutable_schema() = std::move(new_schema);
+  set_schema_request.set_ignore_errors_and_delete_documents(
+      ignore_errors_and_delete_documents);
+
+  return SetSchema(std::move(set_schema_request));
 }
 
 libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult>
-SchemaStore::SetSchema(SchemaProto&& new_schema,
-                       bool ignore_errors_and_delete_documents,
-                       bool allow_circular_schema_definitions) {
-  if (enable_schema_database_) {
+SchemaStore::SetSchema(SetSchemaRequestProto&& set_schema_request) {
+  bool ignore_errors_and_delete_documents =
+      set_schema_request.ignore_errors_and_delete_documents();
+
+  if (feature_flags_->enable_schema_database()) {
     // Step 1: (Only required if schema database is enabled)
     // Do some preliminary checks on the new schema before formal validation and
     // delta computation. This checks that:
-    // - The new schema only contains types from a single database.
+    // - The database field in the new schema's types match the provided
+    //   database.
     // - The new schema's type names are not already in use from other
-    // databases.
-    ICING_ASSIGN_OR_RETURN(std::string database,
-                           ValidateAndGetDatabase(new_schema));
+    //   databases.
+    ICING_RETURN_IF_ERROR(ValidateSchemaDatabase(
+        set_schema_request.schema(), set_schema_request.database()));
 
     // Step 2: Schema validation and delta computation -- try to get the
     // existing schema for the database to compare to the new schema.
     libtextclassifier3::StatusOr<SchemaProto> schema_proto =
-        GetSchema(database);
+        GetSchema(set_schema_request.database());
     if (absl_ports::IsNotFound(schema_proto.status())) {
       // Case 1: No preexisting schema for this database.
-      return SetInitialSchemaForDatabase(std::move(new_schema),
-                                         ignore_errors_and_delete_documents,
-                                         allow_circular_schema_definitions);
+      return SetInitialSchemaForDatabase(
+          std::move(*set_schema_request.mutable_schema()),
+          set_schema_request.database(), ignore_errors_and_delete_documents);
     }
 
     if (!schema_proto.ok()) {
@@ -874,18 +905,18 @@ SchemaStore::SetSchema(SchemaProto&& new_schema,
     // Case 3: At this point, we're guaranteed that we have an existing schema
     // for this database.
     const SchemaProto& old_schema = schema_proto.ValueOrDie();
-    return SetSchemaWithDatabaseOverride(std::move(new_schema), old_schema,
-                                         ignore_errors_and_delete_documents,
-                                         allow_circular_schema_definitions);
+    return SetSchemaWithDatabaseOverride(
+        std::move(*set_schema_request.mutable_schema()), old_schema,
+        set_schema_request.database(), ignore_errors_and_delete_documents);
   }
 
   // Get the full schema if schema database is disabled.
   libtextclassifier3::StatusOr<const SchemaProto*> schema_proto = GetSchema();
   if (absl_ports::IsNotFound(schema_proto.status())) {
     // Case 1: No preexisting schema
-    return SetInitialSchemaForDatabase(std::move(new_schema),
-                                       ignore_errors_and_delete_documents,
-                                       allow_circular_schema_definitions);
+    return SetInitialSchemaForDatabase(
+        std::move(*set_schema_request.mutable_schema()),
+        set_schema_request.database(), ignore_errors_and_delete_documents);
   }
 
   if (!schema_proto.ok()) {
@@ -895,19 +926,18 @@ SchemaStore::SetSchema(SchemaProto&& new_schema,
 
   // Case 3: At this point, we're guaranteed that we have an existing schema
   const SchemaProto& old_schema = *schema_proto.ValueOrDie();
-  return SetSchemaWithDatabaseOverride(std::move(new_schema), old_schema,
-                                       ignore_errors_and_delete_documents,
-                                       allow_circular_schema_definitions);
+  return SetSchemaWithDatabaseOverride(
+      std::move(*set_schema_request.mutable_schema()), old_schema,
+      set_schema_request.database(), ignore_errors_and_delete_documents);
 }
 
 libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult>
 SchemaStore::SetInitialSchemaForDatabase(
-    SchemaProto new_schema, bool ignore_errors_and_delete_documents,
-    bool allow_circular_schema_definitions) {
+    SchemaProto new_schema, const std::string& database,
+    bool ignore_errors_and_delete_documents) {
   SetSchemaResult result;
 
-  ICING_RETURN_IF_ERROR(SchemaUtil::Validate(
-      new_schema, *feature_flags_, allow_circular_schema_definitions));
+  ICING_RETURN_IF_ERROR(SchemaUtil::Validate(new_schema, *feature_flags_));
 
   result.success = true;
   for (const SchemaTypeConfigProto& type_config : new_schema.types()) {
@@ -918,7 +948,7 @@ SchemaStore::SetInitialSchemaForDatabase(
   // schema file.
   ICING_ASSIGN_OR_RETURN(
       SchemaProto full_new_schema,
-      GetFullSchemaProtoWithUpdatedDb(std::move(new_schema)));
+      GetFullSchemaProtoWithUpdatedDb(std::move(new_schema), database));
   ICING_RETURN_IF_ERROR(ApplySchemaChange(std::move(full_new_schema)));
   has_schema_successfully_set_ = true;
 
@@ -928,15 +958,36 @@ SchemaStore::SetInitialSchemaForDatabase(
 libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult>
 SchemaStore::SetSchemaWithDatabaseOverride(
     SchemaProto new_schema, const SchemaProto& old_schema,
-    bool ignore_errors_and_delete_documents,
-    bool allow_circular_schema_definitions) {
+    const std::string& database, bool ignore_errors_and_delete_documents) {
   // Assume we can set the schema unless proven otherwise.
   SetSchemaResult result;
   result.success = true;
 
-  if (new_schema.SerializeAsString() == old_schema.SerializeAsString()) {
-    // Same schema as before. No need to update anything
-    return result;
+  if (feature_flags_->enable_schema_database()) {
+    // Sanity check to make sure that we're comparing schemas from the same
+    // database.
+    // The new code path ensures that old_schema contains types from exactly one
+    // database since it's obtained using GetSchema(database), which is
+    // guaranteed to only return types from the single provided database.
+    libtextclassifier3::Status validate_old_schema_database =
+        ValidateSchemaDatabase(old_schema, database);
+    if (!validate_old_schema_database.ok()) {
+      return absl_ports::InvalidArgumentError(
+          "Schema database mismatch between new and old schemas. This should "
+          "never happen");
+    }
+
+    // Check if the schema types are the same between the new and old schema,
+    // ignoring order.
+    if (AreSchemaTypesEqual(new_schema, old_schema)) {
+      return result;
+    }
+  } else {
+    // Old equality check that is sensitive to type definition order.
+    if (new_schema.SerializeAsString() == old_schema.SerializeAsString()) {
+      // Same schema as before. No need to update anything
+      return result;
+    }
   }
 
   // Different schema -- we need to validate the schema and track the
@@ -944,10 +995,8 @@ SchemaStore::SetSchemaWithDatabaseOverride(
   //
   // Validate the new schema and compute the delta between the old and new
   // schema.
-  ICING_ASSIGN_OR_RETURN(
-      SchemaUtil::DependentMap new_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_,
-                           allow_circular_schema_definitions));
+  ICING_ASSIGN_OR_RETURN(SchemaUtil::DependentMap new_dependent_map,
+                         SchemaUtil::Validate(new_schema, *feature_flags_));
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_dependent_map, *feature_flags_);
 
@@ -991,7 +1040,7 @@ SchemaStore::SetSchemaWithDatabaseOverride(
   // for writing the full proto to the schema file.
   ICING_ASSIGN_OR_RETURN(
       SchemaProto full_new_schema,
-      GetFullSchemaProtoWithUpdatedDb(std::move(new_schema)));
+      GetFullSchemaProtoWithUpdatedDb(std::move(new_schema), database));
 
   // We still need to update old_schema_type_ids_changed. We need to retrieve
   // the entire old schema for this, as type ids are assigned for the entire
@@ -1060,8 +1109,7 @@ libtextclassifier3::Status SchemaStore::ApplySchemaChange(
   ICING_ASSIGN_OR_RETURN(
       std::unique_ptr<SchemaStore> new_schema_store,
       SchemaStore::Create(filesystem_, temp_schema_store_dir.dir(), clock_,
-                          feature_flags_, std::move(new_schema),
-                          enable_schema_database_));
+                          feature_flags_, std::move(new_schema)));
 
   // Then we swap the new schema file + new derived files with the old files.
   if (!filesystem_->SwapFiles(base_dir_.c_str(),
@@ -1078,7 +1126,7 @@ libtextclassifier3::Status SchemaStore::ApplySchemaChange(
   // even though they now point to files that are within old_base_dir.
   // Manually set them to the correct paths.
   base_dir_ = std::move(old_base_dir);
-  schema_file_->SetSwappedFilepath(MakeSchemaFilename(base_dir_));
+  schema_file_.SetSwappedFilepath(MakeSchemaFilename(base_dir_));
   if (overlay_schema_file_ != nullptr) {
     overlay_schema_file_->SetSwappedFilepath(
         MakeOverlaySchemaFilename(base_dir_));
@@ -1367,15 +1415,12 @@ SchemaStore::ConstructBlobPropertyMap() const {
   return blob_property_map;
 }
 
-libtextclassifier3::StatusOr<std::string> SchemaStore::ValidateAndGetDatabase(
-    const SchemaProto& new_schema) const {
-  std::string database;
-
-  if (!enable_schema_database_ || new_schema.types().empty()) {
-    return database;
+libtextclassifier3::Status SchemaStore::ValidateSchemaDatabase(
+    const SchemaProto& new_schema, const std::string& database) const {
+  if (!feature_flags_->enable_schema_database() || new_schema.types().empty()) {
+    return libtextclassifier3::Status::OK;
   }
 
-  database = new_schema.types(0).database();
   // Loop through new_schema's types and validate it. The input SchemaProto
   // contains a list of SchemaTypeConfigProtos without deduplication. We need to
   // check that:
@@ -1386,10 +1431,10 @@ libtextclassifier3::StatusOr<std::string> SchemaStore::ValidateAndGetDatabase(
   for (const SchemaTypeConfigProto& type_config : new_schema.types()) {
     // Check database consistency.
     if (database != type_config.database()) {
-      return absl_ports::InvalidArgumentError(
-          "SetSchema only accepts a SchemaProto with types from a single "
-          "database at a time. Please make separate calls for each database if "
-          "you need to set the schema for multiple databases.");
+      return absl_ports::InvalidArgumentError(absl_ports::StrCat(
+          "Mismatch between the set schema request's database and the new "
+          "schema types' database. Expected '",
+          database, "' but got '", type_config.database(), "'."));
     }
 
     // Check type name uniqueness. This is only necessary if there is a
@@ -1404,13 +1449,14 @@ libtextclassifier3::StatusOr<std::string> SchemaStore::ValidateAndGetDatabase(
       }
     }
   }
-  return database;
+  return libtextclassifier3::Status::OK;
 }
 
 libtextclassifier3::StatusOr<SchemaProto>
 SchemaStore::GetFullSchemaProtoWithUpdatedDb(
-    SchemaProto input_database_schema) const {
-  if (!enable_schema_database_) {
+    SchemaProto input_database_schema,
+    const std::string& database_to_update) const {
+  if (!feature_flags_->enable_schema_database()) {
     // If the schema database is not enabled, the input schema is already the
     // full schema, so we don't need to do any merges.
     return input_database_schema;
@@ -1435,13 +1481,8 @@ SchemaStore::GetFullSchemaProtoWithUpdatedDb(
 
   // At this point, we have a pre-existing schema -- we need to merge the
   // updated database with the existing schema.
-  if (input_database_schema.types().empty()) {
-    return *schema_proto.ValueOrDie();
-  }
-
-  std::string input_database = input_database_schema.types(0).database();
   if (database_type_map_.size() == 1 &&
-      database_type_map_.find(input_database) != database_type_map_.end()) {
+      database_type_map_.find(database_to_update) != database_type_map_.end()) {
     // No other databases in the schema -- we can return the input database
     // schema.
     return input_database_schema;
@@ -1452,18 +1493,18 @@ SchemaStore::GetFullSchemaProtoWithUpdatedDb(
 
   // 1. Add types from the existing schema, replacing existing types with the
   // input types if the database is the one being updated by the input schema.
-  // - For the input_database, we replace the existing types with the input
-  //   types. An exisiting type is deleted if it's not included in
-  //   input_database.
-  // - If there are more input types than existing types for the input_database,
+  // - For database_to_update, we replace the existing types with the input
+  //   types. Any existing type not included in input_database_schema is
+  //   deleted.
+  // - If there are more input types than existing types for database_to_update,
   //   the rest of the input types are appended to the end of the full_schema.
-  // - If there are fewer input types than existing types for the
-  //   input_database, we shift all existing that come after input_database
-  //   forward.
-  // - For existing types from other databases, we add the types in their
-  //   original order to full_schema. Note that the type-ids of existing types
-  //   might still change if some types deleted in input_database as this will
-  //   cause all subsequent types ids to shift forward.
+  // - If there are fewer input types than existing types for
+  //   database_to_update, we shift forward all existing types that appear after
+  //   the last input type.
+  // - For existing types from other databases, we preserve the existing order
+  //   after adding to full_schema. Note that the type-ids of existing types
+  //   might still change if some types are deleted in the database_to_update as
+  //   this will cause all subsequent types ids to shift forward.
   int input_schema_index = 0, existing_schema_index = 0;
   while (input_schema_index < input_database_schema.types().size() &&
          existing_schema_index < existing_schema->types().size()) {
@@ -1472,12 +1513,7 @@ SchemaStore::GetFullSchemaProtoWithUpdatedDb(
     SchemaTypeConfigProto& input_type_config =
         *input_database_schema.mutable_types(input_schema_index);
 
-    if (input_type_config.database() != input_database) {
-      return absl_ports::InvalidArgumentError(
-          "Can only update a single database at a time.");
-    }
-
-    if (existing_type_config.database() == input_database) {
+    if (existing_type_config.database() == database_to_update) {
       // If the database is the one being updated by the input schema, replace
       // the existing type with a type from the input schema.
       *full_schema.add_types() = std::move(input_type_config);
@@ -1506,7 +1542,7 @@ SchemaStore::GetFullSchemaProtoWithUpdatedDb(
     // that are from input_database, since existing types from input_database
     // are replaced with input_database_schema.
     if (existing_schema->types(existing_schema_index).database() !=
-        input_database) {
+        database_to_update) {
       *full_schema.add_types() = existing_schema->types(existing_schema_index);
     }
   }
diff --git a/icing/schema/schema-store.h b/icing/schema/schema-store.h
index e7b1e36..b5d89ce 100644
--- a/icing/schema/schema-store.h
+++ b/icing/schema/schema-store.h
@@ -49,6 +49,7 @@
 #include "icing/store/key-mapper.h"
 #include "icing/util/clock.h"
 #include "icing/util/crc32.h"
+#include "icing/util/logging.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -252,6 +253,8 @@ class SchemaStore {
 
   static constexpr std::string_view kSchemaTypeWildcard = "*";
 
+  static constexpr std::string_view kDefaultEmptySchemaDatabase = "";
+
   // Factory function to create a SchemaStore which does not take ownership
   // of any input components, and all pointers must refer to valid objects that
   // outlive the created SchemaStore instance. The base_dir must already exist.
@@ -267,7 +270,6 @@ class SchemaStore {
   static libtextclassifier3::StatusOr<std::unique_ptr<SchemaStore>> Create(
       const Filesystem* filesystem, const std::string& base_dir,
       const Clock* clock, const FeatureFlags* feature_flags,
-      bool enable_schema_database = false,
       InitializeStatsProto* initialize_stats = nullptr);
 
   // Migrates schema files (backup v.s. new schema) according to version state
@@ -323,9 +325,22 @@ class SchemaStore {
   // schema or schema with types from multiple databases. Compatibility rules
   // defined by SchemaUtil::ComputeCompatibilityDelta.
   //
-  // The schema types in the new schema proto must all be from a single
-  // database. Does not support setting schema types across multiple databases
-  // at once.
+  // NOTE: This method is deprecated. Please use
+  // `SetSchema(SetSchemaRequestProto&& set_schema_request)` instead.
+  //
+  // TODO: b/337913932 - Remove this method once all callers (currently only
+  // used in tests) are migrated to the new SetSchema method.
+  libtextclassifier3::StatusOr<SetSchemaResult> SetSchema(
+      SchemaProto new_schema, bool ignore_errors_and_delete_documents);
+
+  // Update our current schema if it's compatible. Does not accept incompatible
+  // schema or schema with types from multiple databases. Compatibility rules
+  // defined by SchemaUtil::ComputeCompatibilityDelta.
+  //
+  // Does not support setting the schema across multiple databases if
+  // `feature_flags_->enable_schema_database()` is true. This means that:
+  // - All types within the new schema must have their `database` field matching
+  //  `set_schema_request.database()`.
   //
   // If ignore_errors_and_delete_documents is set to true, then incompatible
   // schema are allowed and we'll force set the schema, meaning
@@ -337,14 +352,12 @@ class SchemaStore {
   //   - INTERNAL_ERROR on any IO errors
   //   - ALREADY_EXISTS_ERROR if type names in the new schema are already in use
   //     by a different database.
-  //   - INVALID_ARGUMENT_ERROR if the schema is invalid, or if the schema types
-  //     are from multiple databases (once schema database is enabled).
+  //   - INVALID_ARGUMENT_ERROR if the schema is invalid. This can happen if
+  //     the schema is malformed, if the new schema contains types where the
+  //     database field does not match the database field in the
+  //     set_schema_request.
   libtextclassifier3::StatusOr<SetSchemaResult> SetSchema(
-      const SchemaProto& new_schema, bool ignore_errors_and_delete_documents,
-      bool allow_circular_schema_definitions);
-  libtextclassifier3::StatusOr<SetSchemaResult> SetSchema(
-      SchemaProto&& new_schema, bool ignore_errors_and_delete_documents,
-      bool allow_circular_schema_definitions);
+      SetSchemaRequestProto&& set_schema_request);
 
   // Get the SchemaTypeConfigProto of schema_type name.
   //
@@ -579,13 +592,12 @@ class SchemaStore {
   //   INTERNAL_ERROR on any IO errors
   static libtextclassifier3::StatusOr<std::unique_ptr<SchemaStore>> Create(
       const Filesystem* filesystem, const std::string& base_dir,
-      const Clock* clock, const FeatureFlags* feature_flags, SchemaProto schema,
-      bool enable_schema_database);
+      const Clock* clock, const FeatureFlags* feature_flags,
+      SchemaProto schema);
 
   // Use SchemaStore::Create instead.
   explicit SchemaStore(const Filesystem* filesystem, std::string base_dir,
-                       const Clock* clock, const FeatureFlags* feature_flags,
-                       bool enable_schema_database);
+                       const Clock* clock, const FeatureFlags* feature_flags);
 
   // Deletes the overlay schema and ensures that the Header is correctly set.
   //
@@ -699,6 +711,11 @@ class SchemaStore {
 
   // Correctly loads the Header, schema_file_ and (if present) the
   // overlay_schema_file_.
+  //
+  // If feature_flags_->release_backup_schema_file_after_initialization() is
+  // true, then schema_file_ will be released if the overlay_schema_file_ is
+  // present.
+  //
   // RETURNS:
   //   - OK on success
   //   - INTERNAL if an IO error is encountered when reading the Header or
@@ -706,24 +723,36 @@ class SchemaStore {
   //     Or an invalid schema configuration is present.
   libtextclassifier3::Status LoadSchema();
 
+  // Resets the schema_file_'s cached FileBackedProto instance if needed.
+  //
+  // This is the case if the overlay_schema_file_ is present and
+  // feature_flags_->release_backup_schema_file_if_overlay_present is true.
+  void ResetSchemaFileIfNeeded() {
+    if (feature_flags_->release_backup_schema_file_if_overlay_present() &&
+        overlay_schema_file_ != nullptr) {
+      ICING_VLOG(2)
+          << "Freeing schema store's base schema file's "
+             "FileBackedProto instance since overlay_schema_file_ is present.";
+      schema_file_.ReleaseCachedSchemaFile();
+    }
+  }
+
   // Sets the schema for a database for the first time.
   //
   // Note that when schema database is disabled, this function sets the entire
-  // schema, with all under the default empty database.
+  // schema, with all types under the default empty database.
   //
   // Requires:
-  //   - All types in new_schema are from the same database.
-  //   - new_schema does not contain type names that are already in use by a
-  //     different database.
+  //   - `new_schema` is valid according to `ValidateSchemaDatabase'
   //
   // Returns:
   //   - SetSchemaResult that indicates if the new schema can be set.
   //   - INTERNAL_ERROR on any IO errors.
-  //   - INVALID_ARGUMENT_ERROR if the schema is invalid.
+  //   - INVALID_ARGUMENT_ERROR if the new schema is invalid.
   libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult>
   SetInitialSchemaForDatabase(SchemaProto new_schema,
-                              bool ignore_errors_and_delete_documents,
-                              bool allow_circular_schema_definitions);
+                              const std::string& database,
+                              bool ignore_errors_and_delete_documents);
 
   // Sets the schema for a database, overriding any existing schema for that
   // database.
@@ -732,20 +761,25 @@ class SchemaStore {
   // overrides the entire schema.
   //
   // Requires:
-  //   - All types in new_schema are from the same database.
-  //   - new_schema does not contain type names that are already in use by a
-  //     different database.
+  //   - `new_schema` and `database` are valid according to
+  //     `ValidateSchemaDatabase(new_schema, database)`
+  //   - Types in `new_schema` and `old_schema` all belong to the provided
+  //     database.
+  //     - The old schema is guaranteed to contain types from exactly one
+  //       database when schema database is enabled, because it was obtained
+  //       using `GetSchema(database)`.
   //
   // Returns:
   //   - SetSchemaResult that encapsulates the differences between the old and
   //     new schema, as well as if the new schema can be set.
   //   - INTERNAL_ERROR on any IO errors.
-  //   - INVALID_ARGUMENT_ERROR if the schema is invalid.
+  //   - INVALID_ARGUMENT_ERROR if the schema is invalid, or if there are
+  //     mismatches between the schema databases.
   libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult>
   SetSchemaWithDatabaseOverride(SchemaProto new_schema,
                                 const SchemaProto& old_schema,
-                                bool ignore_errors_and_delete_documents,
-                                bool allow_circular_schema_definitions);
+                                const std::string& database,
+                                bool ignore_errors_and_delete_documents);
 
   // Initial validation on the SchemaProto for SetSchema. This is intended as a
   // preliminary check before any expensive operations are performed during
@@ -755,22 +789,25 @@ class SchemaStore {
   // an empty string is returned as the database.
   //
   // Checks that:
-  // - The new schema only contains types from a single database.
+  // - The new schema only contains types from a single database, which matches
+  //   the provided database.
   // - The schema's type names are not already in use in other databases. This
   //   is done outside of `SchemaUtil::Validate` because we need to know all
   //   existing type names, which is stored in the SchemaStore and not known to
   //   SchemaUtil.
   //
   // Returns:
-  //   - new_schema's database on success
-  //   - INVALID_ARGUMENT_ERROR if new_schema contains types from multiple
-  //     databases
+  //   - OK on success
+  //   - INVALID_ARGUMENT_ERROR if new_schema.types's databases do not match the
+  //     provided database.
   //   - ALREADY_EXISTS_ERROR if new_schema's types names are not unique
-  libtextclassifier3::StatusOr<std::string> ValidateAndGetDatabase(
-      const SchemaProto& new_schema) const;
+  libtextclassifier3::Status ValidateSchemaDatabase(
+      const SchemaProto& new_schema, const std::string& database) const;
 
   // Returns a SchemaProto representing the full schema, which is a combination
-  // of the existing schema and the input database schema.
+  // of the existing schema and the input database schema. Deletes all types
+  // belonging to the specified database if input_database_schema is an empty
+  // proto.
   //
   // For the database being updated by the input database schema:
   // - If the existing schema does not contain the database, the input types
@@ -786,7 +823,8 @@ class SchemaStore {
   //     existing types from unaffected databases.
   //
   // Requires:
-  //   - input_database_schema must not contain types from multiple databases.
+  //   - input_database_schema is valid according to `ValidateSchemaDatabase`
+  //     and `SchemaUtil::Validate`.
   //
   // Returns:
   //   - SchemaProto on success
@@ -795,7 +833,8 @@ class SchemaStore {
   //   - INVALID_ARGUMENT_ERROR if the input schema contains types from multiple
   //     databases.
   libtextclassifier3::StatusOr<SchemaProto> GetFullSchemaProtoWithUpdatedDb(
-      SchemaProto input_database_schema) const;
+      SchemaProto input_database_schema,
+      const std::string& database_to_update) const;
 
   const Filesystem* filesystem_;
   std::string base_dir_;
@@ -807,8 +846,82 @@ class SchemaStore {
   // schema has ever been set.
   bool has_schema_successfully_set_ = false;
 
-  // Cached schema
-  std::unique_ptr<FileBackedProto<SchemaProto>> schema_file_;
+  // Wrapper class to store a cached schema file FileBackedProto instance and
+  // its checksum.
+  class SchemaFileCache {
+   public:
+    explicit SchemaFileCache(const Filesystem* filesystem,
+                             const std::string& schema_file_path)
+        : filesystem_(filesystem), schema_file_path_(schema_file_path) {}
+    // Returns a reference to the proto read from the schema FileBackedProto.
+    //
+    // NOTE: The caller does NOT get ownership of the object returned and
+    // the returned object is only valid till a new version of the proto is
+    // written to the file.
+    //
+    // Returns NOT_FOUND if the file was empty or never written to.
+    // Returns INTERNAL_ERROR if an IO error or a corruption was encountered.
+    libtextclassifier3::StatusOr<const SchemaProto*> Read() {
+      return GetCachedSchemaFile().Read();
+    }
+
+    // Writes the new schema_proto to schema_file_ and updates the cached
+    // checksum.
+    //
+    // Returns: INTERNAL_ERROR if any IO error is encountered.
+    libtextclassifier3::Status Write(
+        std::unique_ptr<SchemaProto> schema_proto) {
+      ICING_RETURN_IF_ERROR(
+          GetCachedSchemaFile().Write(std::move(schema_proto)));
+      ICING_ASSIGN_OR_RETURN(Crc32 checksum,
+                             GetCachedSchemaFile().GetChecksum());
+      checksum_ = std::make_unique<Crc32>(checksum);
+      return libtextclassifier3::Status::OK;
+    }
+
+    // Sets the swapped_to_file_path for the cached schema_file_ instance and
+    // the schema_file_path_.
+    void SetSwappedFilepath(std::string new_schema_file_path) {
+      if (schema_file_ != nullptr) {
+        schema_file_->SetSwappedFilepath(new_schema_file_path);
+      }
+      schema_file_path_ = std::move(new_schema_file_path);
+    }
+
+    // Releases the cached schema_file_ FileBackedProto instance.
+    void ReleaseCachedSchemaFile() { schema_file_.reset(); }
+
+    libtextclassifier3::StatusOr<Crc32> GetChecksum() {
+      if (checksum_ == nullptr) {
+        ICING_ASSIGN_OR_RETURN(Crc32 checksum,
+                               GetCachedSchemaFile().GetChecksum());
+        checksum_ = std::make_unique<Crc32>(std::move(checksum));
+      }
+      return *checksum_;
+    }
+
+   private:
+    FileBackedProto<SchemaProto>& GetCachedSchemaFile() {
+      if (schema_file_ == nullptr) {
+        schema_file_ = std::make_unique<FileBackedProto<SchemaProto>>(
+            *filesystem_, schema_file_path_);
+      }
+      return *schema_file_;
+    }
+
+    const Filesystem* filesystem_;
+    std::string schema_file_path_;
+    std::unique_ptr<FileBackedProto<SchemaProto>> schema_file_;
+    std::unique_ptr<Crc32> checksum_;
+  };
+
+  // Caches a FileBackedProto instance and the checksum for the schema file.
+  //
+  // If the overlay_schema_file_ is present and
+  // feature_flags_->release_backup_schema_file_if_overlay_present is true, then
+  // the cached schema FileBackedProto instance should be released and reloaded
+  // only during mutating SetSchema operations.
+  mutable SchemaFileCache schema_file_;
 
   // This schema holds the definition of any schema types that are not
   // compatible with older versions of Icing code.
@@ -855,14 +968,6 @@ class SchemaStore {
   std::unique_ptr<ScorablePropertyManager> scorable_property_manager_;
 
   std::unique_ptr<Header> header_;
-
-  // Whether to use the database field for the schema.
-  //
-  // This is a temporary flag to control the rollout of the schema database. It
-  // affects the `SetSchema` and `GetSchema(std::string database)` methods.
-  // TODO - b/337913932: Remove this flag once the schema database is fully
-  // rolled out.
-  bool enable_schema_database_ = false;
 };
 
 }  // namespace lib
diff --git a/icing/schema/schema-store_test.cc b/icing/schema/schema-store_test.cc
index 271ab4a..4993408 100644
--- a/icing/schema/schema-store_test.cc
+++ b/icing/schema/schema-store_test.cc
@@ -18,10 +18,12 @@
 #include <memory>
 #include <optional>
 #include <string>
+#include <string_view>
 #include <utility>
 #include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/absl_ports/str_cat.h"
@@ -57,6 +59,7 @@ using ::testing::Eq;
 using ::testing::Ge;
 using ::testing::Gt;
 using ::testing::HasSubstr;
+using ::testing::IsEmpty;
 using ::testing::Not;
 using ::testing::Pair;
 using ::testing::Pointee;
@@ -114,6 +117,19 @@ class SchemaStoreTest : public ::testing::Test {
   FakeClock fake_clock_;
 };
 
+SetSchemaRequestProto CreateSetSchemaRequestProto(
+    SchemaProto schema, std::string database,
+    bool ignore_errors_and_delete_documents) {
+  SetSchemaRequestProto set_schema_request;
+
+  *set_schema_request.mutable_schema() = std::move(schema);
+  set_schema_request.set_database(std::move(database));
+  set_schema_request.set_ignore_errors_and_delete_documents(
+      ignore_errors_and_delete_documents);
+
+  return set_schema_request;
+}
+
 TEST_F(SchemaStoreTest, CreationWithFilesystemNullPointerShouldFail) {
   EXPECT_THAT(SchemaStore::Create(/*filesystem=*/nullptr, schema_store_dir_,
                                   &fake_clock_, feature_flags_.get()),
@@ -149,8 +165,7 @@ TEST_F(SchemaStoreTest, SchemaStoreMoveConstructible) {
                           feature_flags_.get()));
 
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 expected_checksum,
                              schema_store->UpdateChecksum());
 
@@ -185,8 +200,7 @@ TEST_F(SchemaStoreTest, SchemaStoreMoveAssignment) {
                           feature_flags_.get()));
 
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema1, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema1, /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 expected_checksum,
                              schema_store->UpdateChecksum());
 
@@ -205,8 +219,7 @@ TEST_F(SchemaStoreTest, SchemaStoreMoveAssignment) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema2, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema2, /*ignore_errors_and_delete_documents=*/false));
 
   // Move assign the first instance into the second one.
   *move_assigned_schema_store = std::move(*schema_store);
@@ -234,8 +247,7 @@ TEST_F(SchemaStoreTest, CorruptSchemaError) {
     result.success = true;
     result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
     EXPECT_THAT(schema_store->SetSchema(
-                    schema_, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema_, /*ignore_errors_and_delete_documents=*/false),
                 IsOkAndHolds(EqualsSetSchemaResult(result)));
     ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                                schema_store->GetSchema());
@@ -275,8 +287,7 @@ TEST_F(SchemaStoreTest, RecoverCorruptDerivedFileOk) {
     result.success = true;
     result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
     EXPECT_THAT(schema_store->SetSchema(
-                    schema_, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema_, /*ignore_errors_and_delete_documents=*/false),
                 IsOkAndHolds(EqualsSetSchemaResult(result)));
     ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                                schema_store->GetSchema());
@@ -308,8 +319,7 @@ TEST_F(SchemaStoreTest, RecoverCorruptDerivedFileOk) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
-                          feature_flags_.get(),
-                          /*enable_schema_database=*/false, &initialize_stats));
+                          feature_flags_.get(), &initialize_stats));
   EXPECT_THAT(initialize_stats.schema_store_recovery_cause(),
               Eq(InitializeStatsProto::IO_ERROR));
   EXPECT_THAT(initialize_stats.schema_store_recovery_latency_ms(), Eq(123));
@@ -343,8 +353,7 @@ TEST_F(SchemaStoreTest, RecoverDiscardDerivedFilesOk) {
     result.success = true;
     result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
     EXPECT_THAT(schema_store->SetSchema(
-                    schema_, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema_, /*ignore_errors_and_delete_documents=*/false),
                 IsOkAndHolds(EqualsSetSchemaResult(result)));
     ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                                schema_store->GetSchema());
@@ -371,8 +380,7 @@ TEST_F(SchemaStoreTest, RecoverDiscardDerivedFilesOk) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
-                          feature_flags_.get(),
-                          /*enable_schema_database=*/false, &initialize_stats));
+                          feature_flags_.get(), &initialize_stats));
   EXPECT_THAT(initialize_stats.schema_store_recovery_cause(),
               Eq(InitializeStatsProto::IO_ERROR));
   EXPECT_THAT(initialize_stats.schema_store_recovery_latency_ms(), Eq(123));
@@ -406,8 +414,7 @@ TEST_F(SchemaStoreTest, RecoverBadChecksumOk) {
     result.success = true;
     result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
     EXPECT_THAT(schema_store->SetSchema(
-                    schema_, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema_, /*ignore_errors_and_delete_documents=*/false),
                 IsOkAndHolds(EqualsSetSchemaResult(result)));
     ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                                schema_store->GetSchema());
@@ -504,8 +511,7 @@ TEST_F(SchemaStoreTest, CreateWithPreviousSchemaOk) {
   result.success = true;
   result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   schema_store.reset();
@@ -533,8 +539,7 @@ TEST_F(SchemaStoreTest, MultipleCreateOk) {
   result.success = true;
   result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Verify that our in-memory structures are ok
@@ -601,8 +606,7 @@ TEST_F(SchemaStoreTest, SetNewSchemaOk) {
   result.success = true;
   result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -614,7 +618,6 @@ TEST_F(SchemaStoreTest, SetNewSchemaInDifferentDatabaseOk) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   SchemaProto db1_schema =
@@ -629,9 +632,9 @@ TEST_F(SchemaStoreTest, SetNewSchemaInDifferentDatabaseOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(db1_schema))));
@@ -651,9 +654,9 @@ TEST_F(SchemaStoreTest, SetNewSchemaInDifferentDatabaseOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("db2_email");
   result.schema_types_new_by_name.insert("db2_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the full schema. Databases that are updated last are appended to the
@@ -679,6 +682,56 @@ TEST_F(SchemaStoreTest, SetNewSchemaInDifferentDatabaseOk) {
               IsOkAndHolds(EqualsProto(db2_schema)));
 }
 
+TEST_F(SchemaStoreTest, SetEmptyDatabaseSchemaOk) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaStore> schema_store,
+      SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
+                          feature_flags_.get()));
+
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("email"))
+          .AddType(SchemaTypeConfigBuilder().SetType("message"))
+          .Build();
+  SchemaStore::SetSchemaResult result;
+  result.success = true;
+  result.schema_types_new_by_name.insert("email");
+  result.schema_types_new_by_name.insert("message");
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(schema))));
+  EXPECT_THAT(schema_store->GetSchema(""), IsOkAndHolds(EqualsProto(schema)));
+
+  // Reset the schema. This should still reset the empty schema, and replace
+  // the existing 2 types.
+  schema =
+      SchemaBuilder()
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("email_v2").SetDatabase(""))
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("message_v2").SetDatabase(""))
+          .Build();
+  result = SchemaStore::SetSchemaResult();
+  result.success = true;
+  result.schema_types_new_by_name.insert("email_v2");
+  result.schema_types_new_by_name.insert("message_v2");
+  result.schema_types_deleted_by_name.insert("email");
+  result.schema_types_deleted_by_name.insert("message");
+  result.schema_types_deleted_by_id.insert(0);
+  result.schema_types_deleted_by_id.insert(1);
+
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"",
+                  /*ignore_errors_and_delete_documents=*/true)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(schema))));
+  EXPECT_THAT(schema_store->GetSchema(""), IsOkAndHolds(EqualsProto(schema)));
+}
+
 TEST_F(SchemaStoreTest, SetSameSchemaOk) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store,
@@ -690,8 +743,7 @@ TEST_F(SchemaStoreTest, SetSameSchemaOk) {
   result.success = true;
   result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -701,8 +753,7 @@ TEST_F(SchemaStoreTest, SetSameSchemaOk) {
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(schema_));
@@ -713,7 +764,6 @@ TEST_F(SchemaStoreTest, SetSameDatabaseSchemaOk) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
@@ -750,17 +800,17 @@ TEST_F(SchemaStoreTest, SetSameDatabaseSchemaOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_email");
   result.schema_types_new_by_name.insert("db2_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
                              schema_store->GetSchema());
@@ -769,11 +819,10 @@ TEST_F(SchemaStoreTest, SetSameDatabaseSchemaOk) {
   // Reset db1 with the same SchemaProto. The schema should be exactly the same.
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  EXPECT_THAT(
-      schema_store->SetSchema(db1_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
-      IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema, this should not have changed
   EXPECT_THAT(schema_store->GetSchema(),
@@ -784,12 +833,11 @@ TEST_F(SchemaStoreTest, SetSameDatabaseSchemaOk) {
               IsOkAndHolds(EqualsProto(db2_schema)));
 }
 
-TEST_F(SchemaStoreTest, SetDatabaseReorderedTypesPreservesSchemaTypeIds) {
+TEST_F(SchemaStoreTest, SetDatabaseReorderedTypesNoChange) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
@@ -841,36 +889,36 @@ TEST_F(SchemaStoreTest, SetDatabaseReorderedTypesPreservesSchemaTypeIds) {
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db2
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_email");
   result.schema_types_new_by_name.insert("db2_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db3
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db3_email");
   result.schema_types_new_by_name.insert("db3_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db3_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db3_schema, /*database=*/"db3",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Verify schema.
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
                              schema_store->GetSchema());
   EXPECT_THAT(*actual_full_schema, EqualsProto(expected_full_schema));
 
-  // Reset db2 with the types reordered. The expected full schema will be
-  // different, but the SchemaTypeIds for db1 and db3 should not change.
-  db2_schema =
+  // Reset db2 with the types reordered. This should not change the existing
+  // schema in any way.
+  SchemaProto reordered_db2_schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
                        .SetType("db2_message")
@@ -878,42 +926,29 @@ TEST_F(SchemaStoreTest, SetDatabaseReorderedTypesPreservesSchemaTypeIds) {
           .AddType(
               SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
           .Build();
-  expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
-          .Build();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  // Only db2's schema type ids should change.
-  result.old_schema_type_ids_changed.insert(2);
-  result.old_schema_type_ids_changed.insert(3);
-  EXPECT_THAT(
-      schema_store->SetSchema(db2_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
-      IsOkAndHolds(EqualsSetSchemaResult(result)));
+
+  libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult> actual_result =
+      schema_store->SetSchema(CreateSetSchemaRequestProto(
+          reordered_db2_schema, /*database=*/"db2",
+          /*ignore_errors_and_delete_documents=*/false));
+  EXPECT_THAT(actual_result, IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(actual_result.ValueOrDie().old_schema_type_ids_changed,
+              IsEmpty());
 
   // Check the schema
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
   EXPECT_THAT(schema_store->GetSchema("db1"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db2"),
-              IsOkAndHolds(EqualsProto(db2_schema)));
+
+  libtextclassifier3::StatusOr<SchemaProto> actual_db2_schema =
+      schema_store->GetSchema("db2");
+  EXPECT_THAT(actual_db2_schema, IsOkAndHolds(EqualsProto(db2_schema)));
+  EXPECT_THAT(actual_db2_schema.ValueOrDie(),
+              Not(EqualsProto(reordered_db2_schema)));
+
   EXPECT_THAT(schema_store->GetSchema("db3"),
               IsOkAndHolds(EqualsProto(db3_schema)));
 }
@@ -923,7 +958,6 @@ TEST_F(SchemaStoreTest, SetDatabaseAddedTypesPreservesSchemaTypeIds) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
@@ -975,27 +1009,27 @@ TEST_F(SchemaStoreTest, SetDatabaseAddedTypesPreservesSchemaTypeIds) {
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db2
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_email");
   result.schema_types_new_by_name.insert("db2_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db3
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db3_email");
   result.schema_types_new_by_name.insert("db3_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db3_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db3_schema, /*database=*/"db3",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Verify schema.
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
@@ -1047,11 +1081,10 @@ TEST_F(SchemaStoreTest, SetDatabaseAddedTypesPreservesSchemaTypeIds) {
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_recipient");
-  EXPECT_THAT(
-      schema_store->SetSchema(db2_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
-      IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema
   EXPECT_THAT(schema_store->GetSchema(),
@@ -1069,7 +1102,6 @@ TEST_F(SchemaStoreTest, SetDatabaseDeletedTypesOk) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
@@ -1103,27 +1135,27 @@ TEST_F(SchemaStoreTest, SetDatabaseDeletedTypesOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db2
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_email");
   result.schema_types_new_by_name.insert("db2_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db3
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db3_email");
   result.schema_types_new_by_name.insert("db3_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db3_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db3_schema, /*database=*/"db3",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema again for db2 and add a type. The added type should be appended
   // to the end of the SchemaProto.
@@ -1141,9 +1173,9 @@ TEST_F(SchemaStoreTest, SetDatabaseDeletedTypesOk) {
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_recipient");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   SchemaProto expected_full_schema =
       SchemaBuilder()
@@ -1208,11 +1240,10 @@ TEST_F(SchemaStoreTest, SetDatabaseDeletedTypesOk) {
   result.old_schema_type_ids_changed.insert(3);  // db2_message
   result.old_schema_type_ids_changed.insert(4);  // db3_email
   result.old_schema_type_ids_changed.insert(5);  // db3_message
-  EXPECT_THAT(
-      schema_store->SetSchema(db2_schema,
-                              /*ignore_errors_and_delete_documents=*/true,
-                              /*allow_circular_schema_definitions=*/false),
-      IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/true)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema
   EXPECT_THAT(schema_store->GetSchema(),
@@ -1225,14 +1256,14 @@ TEST_F(SchemaStoreTest, SetDatabaseDeletedTypesOk) {
               IsOkAndHolds(EqualsProto(db3_schema)));
 }
 
-TEST_F(SchemaStoreTest, SetEmptySchemaInDifferentDatabaseOk) {
+TEST_F(SchemaStoreTest, SetEmptySchemaClearsDatabase) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
+  // Set schema for the first time
   SchemaProto db1_schema =
       SchemaBuilder()
           .AddType(
@@ -1241,37 +1272,117 @@ TEST_F(SchemaStoreTest, SetEmptySchemaInDifferentDatabaseOk) {
                        .SetType("db1_message")
                        .SetDatabase("db1"))
           .Build();
+  SchemaProto db2_schema =
+      SchemaBuilder()
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db2_message")
+                       .SetDatabase("db2"))
+          .Build();
+  SchemaProto db3_schema =
+      SchemaBuilder()
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db3_message")
+                       .SetDatabase("db3"))
+          .Build();
+
+  // Set schema for db1
   SchemaStore::SetSchemaResult result;
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  // Set schema for db2
+  result = SchemaStore::SetSchemaResult();
+  result.success = true;
+  result.schema_types_new_by_name.insert("db2_email");
+  result.schema_types_new_by_name.insert("db2_message");
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
+  // Set schema for db3
+  result = SchemaStore::SetSchemaResult();
+  result.success = true;
+  result.schema_types_new_by_name.insert("db3_email");
+  result.schema_types_new_by_name.insert("db3_message");
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db3_schema, /*database=*/"db3",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  // Verify schema.
+  SchemaProto expected_full_schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db1_email")  // SchemaTypeId 0
+                       .SetDatabase("db1"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db1_message")  // SchemaTypeId 1
+                       .SetDatabase("db1"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db2_email")  // SchemaTypeId 2
+                       .SetDatabase("db2"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db2_message")  // SchemaTypeId 3
+                       .SetDatabase("db2"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db3_email")  // SchemaTypeId 4
+                       .SetDatabase("db3"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db3_message")  // SchemaTypeId 5
+                       .SetDatabase("db3"))
+          .Build();
   EXPECT_THAT(schema_store->GetSchema(),
-              IsOkAndHolds(Pointee(EqualsProto(db1_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
-              IsOkAndHolds(EqualsProto(db1_schema)));
+              IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
 
-  // Set an empty schema in a different database
-  SchemaProto db2_schema;
+  // Set an empty schema for db2. This deletes all types from db2, and changes
+  // the type ids of types from db3 because they appear after db2 in the
+  // original schema.
+  db2_schema = SchemaProto();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  result.schema_types_deleted_by_name.insert("db2_email");
+  result.schema_types_deleted_by_name.insert("db2_message");
+  result.schema_types_deleted_by_id.insert(2);   // db2_email
+  result.schema_types_deleted_by_id.insert(3);   // db2_message
+  result.old_schema_type_ids_changed.insert(4);  // db3_email
+  result.old_schema_type_ids_changed.insert(5);  // db3_message
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/true)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
-  // Check the schema, this should not have changed
-  EXPECT_THAT(schema_store->GetSchema(),
-              IsOkAndHolds(Pointee(EqualsProto(db1_schema))));
+  // Check the schema. Schemas for db1 and db3 should be unchanged.
   EXPECT_THAT(schema_store->GetSchema("db1"),
               IsOkAndHolds(EqualsProto(db1_schema)));
+  EXPECT_THAT(schema_store->GetSchema("db3"),
+              IsOkAndHolds(EqualsProto(db3_schema)));
 
-  // GetSchema for an empty database should return NotFoundError
+  // GetSchema for db2 should return NotFoundError
   EXPECT_THAT(schema_store->GetSchema("db2"),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
+
+  expected_full_schema =
+      SchemaBuilder()
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db1_message")
+                       .SetDatabase("db1"))
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db3_message")
+                       .SetDatabase("db3"))
+          .Build();
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
 }
 
 TEST_F(SchemaStoreTest, SetIncompatibleSchemaOk) {
@@ -1285,8 +1396,7 @@ TEST_F(SchemaStoreTest, SetIncompatibleSchemaOk) {
   result.success = true;
   result.schema_types_new_by_name.insert(schema_.types(0).schema_type());
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -1301,8 +1411,7 @@ TEST_F(SchemaStoreTest, SetIncompatibleSchemaOk) {
   result.schema_types_deleted_by_name.emplace("email");
   result.schema_types_deleted_by_id.emplace(0);
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 }
 
@@ -1311,7 +1420,6 @@ TEST_F(SchemaStoreTest, SetIncompatibleInDifferentDatabaseOk) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
@@ -1348,17 +1456,17 @@ TEST_F(SchemaStoreTest, SetIncompatibleInDifferentDatabaseOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_email");
   result.schema_types_new_by_name.insert("db2_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
                              schema_store->GetSchema());
@@ -1378,11 +1486,10 @@ TEST_F(SchemaStoreTest, SetIncompatibleInDifferentDatabaseOk) {
   result.schema_types_deleted_by_name.insert("db2_message");
   result.schema_types_new_by_name.insert("db2_recipient");
   result.schema_types_deleted_by_id.insert(3);  // db2_message
-  EXPECT_THAT(
-      schema_store->SetSchema(db2_schema_incompatible,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
-      IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema_incompatible, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema, this should not have changed
   EXPECT_THAT(schema_store->GetSchema(),
@@ -1398,7 +1505,6 @@ TEST_F(SchemaStoreTest, SetInvalidInDifferentDatabaseFails) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
@@ -1435,17 +1541,17 @@ TEST_F(SchemaStoreTest, SetInvalidInDifferentDatabaseFails) {
   result.success = true;
   result.schema_types_new_by_name.insert("db1_email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   result.schema_types_new_by_name.insert("db2_email");
   result.schema_types_new_by_name.insert("db2_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
                              schema_store->GetSchema());
@@ -1465,11 +1571,11 @@ TEST_F(SchemaStoreTest, SetInvalidInDifferentDatabaseFails) {
                                                          .AddProperty(prop)
                                                          .AddProperty(prop))
                                             .Build();
-  EXPECT_THAT(
-      schema_store->SetSchema(db2_schema_incompatible,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
-      StatusIs(libtextclassifier3::StatusCode::ALREADY_EXISTS));
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema_incompatible,
+                  /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              StatusIs(libtextclassifier3::StatusCode::ALREADY_EXISTS));
 
   // Check the schema, this should not have changed
   EXPECT_THAT(schema_store->GetSchema(),
@@ -1485,10 +1591,8 @@ TEST_F(SchemaStoreTest, SetSchemaWithMultipleDbFails) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
-  // Set schema for the first time
   SchemaProto combined_schema =
       SchemaBuilder()
           .AddType(
@@ -1502,9 +1606,63 @@ TEST_F(SchemaStoreTest, SetSchemaWithMultipleDbFails) {
                        .SetType("db1_message")
                        .SetDatabase("db1"))
           .Build();
-  EXPECT_THAT(schema_store->SetSchema(
-                  combined_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  combined_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+}
+
+TEST_F(SchemaStoreTest, SetSchemaWithMismatchedDbFails) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaStore> schema_store,
+      SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
+                          feature_flags_.get(),
+                          /*initialize_stats=*/nullptr));
+
+  SchemaProto schema =
+      SchemaBuilder()
+          // This type does not explicitly set its database, so it defaults to
+          // the empty database.
+          .AddType(SchemaTypeConfigBuilder().SetType("db1_email"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db1_message")
+                       .SetDatabase("db1"))
+          .Build();
+
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+
+  schema =
+      SchemaBuilder()
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db1_message")
+                       .SetDatabase("db1"))
+          .Build();
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"db_mismatch",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+
+  schema =
+      SchemaBuilder()
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db1_message")
+                       .SetDatabase("db1"))
+          .AddType(
+              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db2_message")
+                       .SetDatabase("db2"))
+          .Build();
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"",
+                  /*ignore_errors_and_delete_documents=*/false)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -1513,7 +1671,6 @@ TEST_F(SchemaStoreTest, SetSchemaWithDuplicateTypeNameAcrossDifferentDbFails) {
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get(),
-                          /*enable_schema_database=*/true,
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
@@ -1529,9 +1686,9 @@ TEST_F(SchemaStoreTest, SetSchemaWithDuplicateTypeNameAcrossDifferentDbFails) {
   result.success = true;
   result.schema_types_new_by_name.insert("email");
   result.schema_types_new_by_name.insert("db1_message");
-  EXPECT_THAT(schema_store->SetSchema(
-                  db1_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db1_schema, /*database=*/"db1",
+                  /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(db1_schema))));
@@ -1547,9 +1704,9 @@ TEST_F(SchemaStoreTest, SetSchemaWithDuplicateTypeNameAcrossDifferentDbFails) {
                        .SetType("db2_message")
                        .SetDatabase("db2"))
           .Build();
-  EXPECT_THAT(schema_store->SetSchema(
-                  db2_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  db2_schema, /*database=*/"db2",
+                  /*ignore_errors_and_delete_documents=*/false)),
               StatusIs(libtextclassifier3::StatusCode::ALREADY_EXISTS));
 
   // Check schema, this should not have changed
@@ -1574,8 +1731,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithAddedTypeOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("email");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -1591,8 +1747,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithAddedTypeOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("new_type");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(schema));
@@ -1616,8 +1771,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithDeletedTypeOk) {
   result.schema_types_new_by_name.insert("email");
   result.schema_types_new_by_name.insert("message");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -1643,8 +1797,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithDeletedTypeOk) {
 
   // Can't set the incompatible schema
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(incompatible_result)));
 
   SchemaStore::SetSchemaResult force_result;
@@ -1655,8 +1808,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithDeletedTypeOk) {
 
   // Force set the incompatible schema
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/true,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/true),
               IsOkAndHolds(EqualsSetSchemaResult(force_result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(schema));
@@ -1680,34 +1832,50 @@ TEST_F(SchemaStoreTest, SetSchemaWithReorderedTypesOk) {
   result.schema_types_new_by_name.insert("email");
   result.schema_types_new_by_name.insert("message");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(schema));
 
   // Reorder the types
-  schema = SchemaBuilder()
-               .AddType(SchemaTypeConfigBuilder().SetType("message"))
-               .AddType(SchemaTypeConfigBuilder().SetType("email"))
-               .Build();
+  SchemaProto reordered_schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("message"))
+          .AddType(SchemaTypeConfigBuilder().SetType("email"))
+          .Build();
 
-  // Since we assign SchemaTypeIds based on order in the SchemaProto, this will
-  // cause SchemaTypeIds to change
-  result = SchemaStore::SetSchemaResult();
-  result.success = true;
-  result.old_schema_type_ids_changed.emplace(0);  // Old SchemaTypeId of "email"
-  result.old_schema_type_ids_changed.emplace(
-      1);  // Old SchemaTypeId of "message"
+  // Set the compatible schema and verify with GetSchema
+  if (feature_flags_->enable_schema_database()) {
+    // Setting reordered types is a no-op for the new set schema after schema
+    // database is enabled. So everything should be the same as before.
+    result = SchemaStore::SetSchemaResult();
+    result.success = true;
+    EXPECT_THAT(
+        schema_store->SetSchema(reordered_schema,
+                                /*ignore_errors_and_delete_documents=*/false),
+        IsOkAndHolds(EqualsSetSchemaResult(result)));
+
+    ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
+    EXPECT_THAT(*actual_schema, EqualsProto(schema));
+  } else {
+    // Since we assign SchemaTypeIds based on order in the SchemaProto, this
+    // will
+    // cause SchemaTypeIds to change
+    result = SchemaStore::SetSchemaResult();
+    result.success = true;
+    result.old_schema_type_ids_changed.emplace(
+        0);  // Old SchemaTypeId of "email"
+    result.old_schema_type_ids_changed.emplace(
+        1);  // Old SchemaTypeId of "message"
 
-  // Set the compatible schema
-  EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
-              IsOkAndHolds(EqualsSetSchemaResult(result)));
-  ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
-  EXPECT_THAT(*actual_schema, EqualsProto(schema));
+    // Set the compatible schema
+    EXPECT_THAT(schema_store->SetSchema(
+                    schema, /*ignore_errors_and_delete_documents=*/false),
+                IsOkAndHolds(EqualsSetSchemaResult(result)));
+    ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
+    EXPECT_THAT(*actual_schema, EqualsProto(schema));
+  }
 }
 
 TEST_F(SchemaStoreTest, IndexedPropertyChangeRequiresReindexingOk) {
@@ -1731,8 +1899,7 @@ TEST_F(SchemaStoreTest, IndexedPropertyChangeRequiresReindexingOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("email");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -1752,8 +1919,7 @@ TEST_F(SchemaStoreTest, IndexedPropertyChangeRequiresReindexingOk) {
   result.success = true;
   result.schema_types_index_incompatible_by_name.insert("email");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(schema));
@@ -1804,8 +1970,7 @@ TEST_F(SchemaStoreTest, IndexNestedDocumentsChangeRequiresReindexingOk) {
   result.schema_types_new_by_name.insert("person");
   EXPECT_THAT(
       schema_store->SetSchema(no_nested_index_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/false),
       IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -1818,8 +1983,7 @@ TEST_F(SchemaStoreTest, IndexNestedDocumentsChangeRequiresReindexingOk) {
   result.schema_types_index_incompatible_by_name.insert("person");
   EXPECT_THAT(
       schema_store->SetSchema(nested_index_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/false),
       IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(nested_index_schema));
@@ -1831,8 +1995,7 @@ TEST_F(SchemaStoreTest, IndexNestedDocumentsChangeRequiresReindexingOk) {
   result.schema_types_index_incompatible_by_name.insert("person");
   EXPECT_THAT(
       schema_store->SetSchema(no_nested_index_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/false),
       IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(no_nested_index_schema));
@@ -1859,8 +2022,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIncompatibleTypesOk) {
   result.success = true;
   result.schema_types_new_by_name.insert("email");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -1887,8 +2049,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIncompatibleTypesOk) {
 
   // Can't set the incompatible schema
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(incompatible_result)));
 
   SchemaStore::SetSchemaResult force_result;
@@ -1899,8 +2060,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIncompatibleTypesOk) {
 
   // Force set the incompatible schema
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/true,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/true),
               IsOkAndHolds(EqualsSetSchemaResult(force_result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(schema));
@@ -1924,8 +2084,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIncompatibleNestedTypesOk) {
   SchemaProto old_schema =
       SchemaBuilder().AddType(contact_point_repeated_label).Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      old_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      old_schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId old_contact_point_type_id,
                              schema_store->GetSchemaTypeId("ContactPoint"));
 
@@ -1961,8 +2120,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIncompatibleNestedTypesOk) {
   expected_result.schema_types_new_by_name.insert("Person");
   EXPECT_THAT(
       schema_store->SetSchema(new_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/false),
       IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -1973,8 +2131,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIncompatibleNestedTypesOk) {
   expected_result.success = true;
   EXPECT_THAT(
       schema_store->SetSchema(new_schema,
-                              /*ignore_errors_and_delete_documents=*/true,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/true),
       IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(new_schema));
@@ -1999,8 +2156,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIndexIncompatibleNestedTypesOk) {
   SchemaProto old_schema =
       SchemaBuilder().AddType(contact_point_prefix_label).Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      old_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      old_schema, /*ignore_errors_and_delete_documents=*/false));
 
   // 2. Create a type that references the ContactPoint type and make a index
   // backwards incompatible change to ContactPoint
@@ -2032,8 +2188,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithIndexIncompatibleNestedTypesOk) {
   expected_result.schema_types_new_by_name.insert("Person");
   EXPECT_THAT(
       schema_store->SetSchema(new_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/false),
       IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -2058,8 +2213,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithCompatibleNestedTypesOk) {
   SchemaProto old_schema =
       SchemaBuilder().AddType(contact_point_optional_label).Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      old_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      old_schema, /*ignore_errors_and_delete_documents=*/false));
 
   // 2. Create a type that references the ContactPoint type and make a backwards
   // compatible change to ContactPoint
@@ -2091,8 +2245,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithCompatibleNestedTypesOk) {
       "ContactPoint");
   expected_result.schema_types_new_by_name.insert("Person");
   EXPECT_THAT(schema_store->SetSchema(
-                  new_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  new_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -2125,8 +2278,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithAddedIndexableNestedTypeOk) {
   SchemaProto old_schema =
       SchemaBuilder().AddType(contact_point).AddType(person).Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      old_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      old_schema, /*ignore_errors_and_delete_documents=*/false));
 
   // 2. Add another nested document property to "Person" that has type
   //    "ContactPoint"
@@ -2158,8 +2310,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithAddedIndexableNestedTypeOk) {
   expected_result.schema_types_join_incompatible_by_name.insert("Person");
 
   EXPECT_THAT(schema_store->SetSchema(
-                  new_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  new_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -2194,8 +2345,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithAddedJoinableNestedTypeOk) {
   SchemaProto old_schema =
       SchemaBuilder().AddType(contact_point).AddType(person).Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      old_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      old_schema, /*ignore_errors_and_delete_documents=*/false));
 
   // 2. Add another nested document property to "Person" that has type
   //    "ContactPoint", but make it non-indexable
@@ -2224,8 +2374,7 @@ TEST_F(SchemaStoreTest, SetSchemaWithAddedJoinableNestedTypeOk) {
   expected_result.schema_types_join_incompatible_by_name.insert("Person");
 
   EXPECT_THAT(schema_store->SetSchema(
-                  new_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  new_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -2266,8 +2415,7 @@ TEST_F(SchemaStoreTest, SetSchemaByUpdatingScorablePropertyOk) {
   expected_result.success = true;
   expected_result.schema_types_new_by_name.insert("email");
   EXPECT_THAT(schema_store->SetSchema(
-                  old_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  old_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -2282,8 +2430,7 @@ TEST_F(SchemaStoreTest, SetSchemaByUpdatingScorablePropertyOk) {
   new_expected_result.schema_types_changed_fully_compatible_by_name.insert(
       "email");
   EXPECT_THAT(schema_store->SetSchema(
-                  new_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  new_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(new_expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(new_schema));
@@ -2335,8 +2482,7 @@ TEST_F(SchemaStoreTest,
   expected_result.schema_types_new_by_name.insert("email");
   expected_result.schema_types_new_by_name.insert("message");
   EXPECT_THAT(schema_store->SetSchema(
-                  old_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  old_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_schema,
                              schema_store->GetSchema());
@@ -2354,8 +2500,7 @@ TEST_F(SchemaStoreTest,
   new_expected_result.old_schema_type_ids_changed.insert(0);
   new_expected_result.old_schema_type_ids_changed.insert(1);
   EXPECT_THAT(schema_store->SetSchema(
-                  new_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  new_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(new_expected_result)));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
   EXPECT_THAT(*actual_schema, EqualsProto(new_schema));
@@ -2384,8 +2529,7 @@ TEST_F(SchemaStoreTest, GetSchemaTypeId) {
   result.schema_types_new_by_name.insert(first_type);
   result.schema_types_new_by_name.insert(second_type);
   EXPECT_THAT(schema_store->SetSchema(
-                  schema_, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema_, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   EXPECT_THAT(schema_store->GetSchemaTypeId(first_type), IsOkAndHolds(0));
@@ -2413,8 +2557,7 @@ TEST_F(SchemaStoreTest, UpdateChecksumSameBetweenCalls) {
       SchemaBuilder().AddType(SchemaTypeConfigBuilder().SetType("foo")).Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      foo_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      foo_schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 checksum, schema_store->GetChecksum());
   EXPECT_THAT(schema_store->UpdateChecksum(), IsOkAndHolds(checksum));
@@ -2435,8 +2578,7 @@ TEST_F(SchemaStoreTest, UpdateChecksumSameAcrossInstances) {
       SchemaBuilder().AddType(SchemaTypeConfigBuilder().SetType("foo")).Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      foo_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      foo_schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 checksum, schema_store->GetChecksum());
   EXPECT_THAT(schema_store->UpdateChecksum(), IsOkAndHolds(checksum));
@@ -2463,8 +2605,7 @@ TEST_F(SchemaStoreTest, UpdateChecksumChangesOnModification) {
       SchemaBuilder().AddType(SchemaTypeConfigBuilder().SetType("foo")).Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      foo_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      foo_schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 checksum, schema_store->GetChecksum());
   EXPECT_THAT(schema_store->UpdateChecksum(), IsOkAndHolds(checksum));
@@ -2478,8 +2619,7 @@ TEST_F(SchemaStoreTest, UpdateChecksumChangesOnModification) {
           .Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      foo_bar_schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      foo_bar_schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 updated_checksum,
                              schema_store->GetChecksum());
@@ -2508,8 +2648,7 @@ TEST_F(SchemaStoreTest, UpdateChecksumAvoidsRecovery) {
       SchemaBuilder().AddType(SchemaTypeConfigBuilder().SetType("foo")).Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // UpdateChecksum should update the schema store checksum. Therefore, we
   // should not need a recovery on reinitialization.
@@ -2526,8 +2665,7 @@ TEST_F(SchemaStoreTest, UpdateChecksumAvoidsRecovery) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store_two,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
-                          feature_flags_.get(),
-                          /*enable_schema_database=*/false, &initialize_stats));
+                          feature_flags_.get(), &initialize_stats));
   EXPECT_THAT(initialize_stats.schema_store_recovery_cause(),
               Eq(InitializeStatsProto::NONE));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store_two->GetSchema());
@@ -2549,8 +2687,7 @@ TEST_F(SchemaStoreTest, PersistToDiskPreservesAcrossInstances) {
       SchemaBuilder().AddType(SchemaTypeConfigBuilder().SetType("foo")).Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Persisting shouldn't change anything
   ICING_EXPECT_OK(schema_store->PersistToDisk());
@@ -2564,8 +2701,7 @@ TEST_F(SchemaStoreTest, PersistToDiskPreservesAcrossInstances) {
                .AddType(SchemaTypeConfigBuilder().SetType("bar"))
                .Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Should also persist on destruction
   schema_store.reset();
@@ -2575,8 +2711,7 @@ TEST_F(SchemaStoreTest, PersistToDiskPreservesAcrossInstances) {
   ICING_ASSERT_OK_AND_ASSIGN(
       schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
-                          feature_flags_.get(),
-                          /*enable_schema_database=*/false, &initialize_stats));
+                          feature_flags_.get(), &initialize_stats));
   EXPECT_THAT(initialize_stats.schema_store_recovery_cause(),
               Eq(InitializeStatsProto::NONE));
   ICING_ASSERT_OK_AND_ASSIGN(actual_schema, schema_store->GetSchema());
@@ -2615,8 +2750,7 @@ TEST_F(SchemaStoreTest, SchemaStoreStorageInfoProto) {
   result.schema_types_new_by_name.insert("email");
   result.schema_types_new_by_name.insert("fullSectionsType");
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   SchemaStoreStorageInfoProto storage_info = schema_store->GetStorageInfo();
@@ -2635,8 +2769,7 @@ TEST_F(SchemaStoreTest, GetDebugInfo) {
   // Set schema
   ASSERT_THAT(
       schema_store->SetSchema(schema_,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/false),
       IsOkAndHolds(EqualsSetSchemaResult(SchemaStore::SetSchemaResult{
           .success = true,
           .schema_types_new_by_name = {schema_.types(0).schema_type()}})));
@@ -2675,8 +2808,7 @@ TEST_F(SchemaStoreTest, InitializeRegenerateDerivedFilesFailure) {
                              .AddType(SchemaTypeConfigBuilder().SetType("Type"))
                              .Build();
     ICING_ASSERT_OK(schema_store->SetSchema(
-        std::move(schema), /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        std::move(schema), /*ignore_errors_and_delete_documents=*/false));
   }
 
   auto mock_filesystem = std::make_unique<MockFilesystem>();
@@ -2713,8 +2845,7 @@ TEST_F(SchemaStoreTest, SetSchemaRegenerateDerivedFilesFailure) {
                             feature_flags_.get()));
     SchemaProto schema = SchemaBuilder().AddType(type).Build();
     ICING_ASSERT_OK(schema_store->SetSchema(
-        std::move(schema), /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        std::move(schema), /*ignore_errors_and_delete_documents=*/false));
   }
 
   {
@@ -2734,8 +2865,7 @@ TEST_F(SchemaStoreTest, SetSchemaRegenerateDerivedFilesFailure) {
             .Build();
     EXPECT_THAT(
         schema_store->SetSchema(std::move(schema),
-                                /*ignore_errors_and_delete_documents=*/false,
-                                /*allow_circular_schema_definitions=*/false),
+                                /*ignore_errors_and_delete_documents=*/false),
         StatusIs(libtextclassifier3::StatusCode::INTERNAL));
     DocumentProto document =
         DocumentBuilder()
@@ -2799,8 +2929,7 @@ TEST_F(SchemaStoreTest, CanCheckForPropertiesDefinedInSchema) {
           .Build();
 
   EXPECT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId schema_id,
                              schema_store->GetSchemaTypeId("email"));
@@ -2843,8 +2972,7 @@ TEST_F(SchemaStoreTest, GetSchemaTypeIdsWithChildren) {
                            .AddType(type_f)
                            .Build();
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Get schema type id for each type.
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId type_a_id,
@@ -2919,8 +3047,7 @@ TEST_F(SchemaStoreTest, DiamondGetSchemaTypeIdsWithChildren) {
                            .AddType(type_f)
                            .Build();
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Get schema type id for each type.
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId type_a_id,
@@ -2993,8 +3120,7 @@ TEST_F(SchemaStoreTest, IndexableFieldsAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeEmailSchemaId = 0;
 
   // Indexables.
@@ -3035,8 +3161,7 @@ TEST_F(SchemaStoreTest, JoinableFieldsAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeEmailSchemaId = 0;
 
   // Joinables.
@@ -3071,8 +3196,7 @@ TEST_F(SchemaStoreTest, NonIndexableFieldsAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeEmailSchemaId = 0;
 
   // Non-indexables.
@@ -3116,8 +3240,7 @@ TEST_F(SchemaStoreTest, NonExistentFieldsAreUndefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeEmailSchemaId = 0;
 
   // Non-existents.
@@ -3177,8 +3300,7 @@ TEST_F(SchemaStoreTest, NestedIndexableFieldsAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeConversationSchemaId = 1;
 
   // Indexables.
@@ -3236,8 +3358,7 @@ TEST_F(SchemaStoreTest, NestedJoinableFieldsAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeConversationSchemaId = 1;
 
   // Joinables.
@@ -3295,8 +3416,7 @@ TEST_F(SchemaStoreTest, NestedNonIndexableFieldsAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeConversationSchemaId = 1;
 
   // Non-indexables.
@@ -3358,8 +3478,7 @@ TEST_F(SchemaStoreTest, NestedNonExistentFieldsAreUndefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeConversationSchemaId = 1;
 
   // Non-existents.
@@ -3421,8 +3540,7 @@ TEST_F(SchemaStoreTest, IntermediateDocumentPropertiesAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeConversationSchemaId = 1;
 
   // Intermediate documents props.
@@ -3468,8 +3586,7 @@ TEST_F(SchemaStoreTest, CyclePathsAreDefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeASchemaId = 0;
   constexpr SchemaTypeId kTypeBSchemaId = 1;
 
@@ -3539,8 +3656,7 @@ TEST_F(SchemaStoreTest, WrongTypeCyclePathsAreUndefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeASchemaId = 0;
   constexpr SchemaTypeId kTypeBSchemaId = 1;
 
@@ -3613,8 +3729,7 @@ TEST_F(SchemaStoreTest, CyclePathsNonexistentPropertiesAreUndefined) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/true));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   constexpr SchemaTypeId kTypeASchemaId = 0;
   constexpr SchemaTypeId kTypeBSchemaId = 1;
 
@@ -3670,8 +3785,7 @@ TEST_F(SchemaStoreTest, LoadsOverlaySchemaOnInit) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -3742,8 +3856,7 @@ TEST_F(SchemaStoreTest, LoadsBaseSchemaWithNoOverlayOnInit) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -3796,8 +3909,7 @@ TEST_F(SchemaStoreTest, LoadSchemaBackupSchemaMissing) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -3847,8 +3959,7 @@ TEST_F(SchemaStoreTest, LoadSchemaOverlaySchemaMissing) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -3898,8 +4009,7 @@ TEST_F(SchemaStoreTest, LoadSchemaHeaderMissing) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -3948,8 +4058,7 @@ TEST_F(SchemaStoreTest, LoadSchemaNoOverlayHeaderMissing) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -3990,8 +4099,7 @@ TEST_F(SchemaStoreTest, MigrateSchemaCompatibleNoChange) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4034,8 +4142,7 @@ TEST_F(SchemaStoreTest, MigrateSchemaUpgradeNoChange) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4078,8 +4185,7 @@ TEST_F(SchemaStoreTest, MigrateSchemaVersionZeroUpgradeNoChange) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4124,8 +4230,7 @@ TEST_F(SchemaStoreTest,
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4182,8 +4287,7 @@ TEST_F(SchemaStoreTest, MigrateSchemaRollbackKeepsCompatibleOverlaySchema) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4226,8 +4330,7 @@ TEST_F(SchemaStoreTest, MigrateSchemaRollforwardRetainsBaseSchema) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4299,8 +4402,7 @@ TEST_F(SchemaStoreTest, MigrateSchemaRollforwardRetainsOverlaySchema) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4362,8 +4464,7 @@ TEST_F(SchemaStoreTest,
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4417,8 +4518,7 @@ TEST_F(SchemaStoreTest, MigrateSchemaVersionUndeterminedDiscardsOverlaySchema) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema))));
@@ -4507,8 +4607,7 @@ TEST_F(SchemaStoreTest, GetTypeWithBlobProperties) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->ConstructBlobPropertyMap(),
                 IsOkAndHolds(UnorderedElementsAre(
@@ -4579,8 +4678,7 @@ TEST_F(SchemaStoreTest, GetTypeWithMultiLevelBlobProperties) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(
         schema_store->ConstructBlobPropertyMap(),
@@ -4611,8 +4709,7 @@ TEST_F(SchemaStoreTest, GetScorablePropertyIndex_InvalidSchemaTypeId) {
 
   // Set schema
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema_, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema_, /*ignore_errors_and_delete_documents=*/false));
 
   // non-existing schema type id
   EXPECT_THAT(schema_store->GetScorablePropertyIndex(
@@ -4652,8 +4749,7 @@ TEST_F(SchemaStoreTest, GetScorablePropertyIndex_InvalidPropertyName) {
 
   // Set schema
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // non-scorable property
   EXPECT_THAT(schema_store->GetScorablePropertyIndex(
@@ -4675,8 +4771,7 @@ TEST_F(SchemaStoreTest, GetScorablePropertyIndex_Ok) {
 
   // Set schema
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema_, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema_, /*ignore_errors_and_delete_documents=*/false));
 
   EXPECT_THAT(schema_store->GetScorablePropertyIndex(
                   /*schema_type_id=*/0,
@@ -4703,8 +4798,7 @@ TEST_F(SchemaStoreTest, GetOrderedScorablePropertyPaths_InvalidSchemaTypeId) {
 
   // Set schema
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema_, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema_, /*ignore_errors_and_delete_documents=*/false));
 
   EXPECT_THAT(schema_store->GetOrderedScorablePropertyInfo(
                   /*schema_type_id=*/100),
@@ -4747,8 +4841,7 @@ TEST_F(SchemaStoreTest, GetOrderedScorablePropertyPaths_Ok) {
 
   // Set schema
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   EXPECT_THAT(schema_store->GetSchemaTypeId("email"), IsOkAndHolds(0));
   EXPECT_THAT(schema_store->GetSchemaTypeId("message"), IsOkAndHolds(1));
 
@@ -4772,8 +4865,7 @@ TEST_F(SchemaStoreTest, ScorablePropertyManagerUpdatesUponSchemaChange) {
 
   // Sets the initial schema
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema_, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema_, /*ignore_errors_and_delete_documents=*/false));
 
   EXPECT_THAT(schema_store->GetScorablePropertyIndex(
                   /*schema_type_id=*/0,
@@ -4812,8 +4904,7 @@ TEST_F(SchemaStoreTest, ScorablePropertyManagerUpdatesUponSchemaChange) {
 
   // Force updates the schema.
   ICING_ASSERT_OK(schema_store->SetSchema(
-      new_schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      new_schema, /*ignore_errors_and_delete_documents=*/true));
 
   // "timestamp" is no longer a valid property name.
   EXPECT_THAT(schema_store->GetScorablePropertyIndex(
@@ -4867,8 +4958,7 @@ TEST_P(SchemaStoreTestWithParam, MigrateSchemaWithDatabaseMigration) {
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        schema_no_database, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema_no_database, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(schema_no_database))));
@@ -5010,8 +5100,7 @@ TEST_P(SchemaStoreTestWithParam,
         SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                             feature_flags_.get()));
     ICING_ASSERT_OK(schema_store->SetSchema(
-        original_schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        original_schema, /*ignore_errors_and_delete_documents=*/false));
 
     EXPECT_THAT(schema_store->GetSchema(),
                 IsOkAndHolds(Pointee(EqualsProto(original_schema))));
diff --git a/icing/schema/schema-util.cc b/icing/schema/schema-util.cc
index 22ce523..cfc2391 100644
--- a/icing/schema/schema-util.cc
+++ b/icing/schema/schema-util.cc
@@ -689,13 +689,13 @@ SchemaUtil::BuildTransitiveInheritanceGraph(const SchemaProto& schema) {
 }
 
 libtextclassifier3::StatusOr<SchemaUtil::DependentMap> SchemaUtil::Validate(
-    const SchemaProto& schema, const FeatureFlags& feature_flags,
-    bool allow_circular_schema_definitions) {
+    const SchemaProto& schema, const FeatureFlags& feature_flags) {
   // 1. Build the dependent map. This will detect any cycles, non-existent or
   // duplicate types in the schema.
   ICING_ASSIGN_OR_RETURN(
       SchemaUtil::DependentMap dependent_map,
-      BuildTransitiveDependentGraph(schema, allow_circular_schema_definitions));
+      BuildTransitiveDependentGraph(
+          schema, feature_flags.allow_circular_schema_definitions()));
 
   // Tracks PropertyConfigs within a SchemaTypeConfig that we've validated
   // already.
diff --git a/icing/schema/schema-util.h b/icing/schema/schema-util.h
index 27ad3e4..39e6160 100644
--- a/icing/schema/schema-util.h
+++ b/icing/schema/schema-util.h
@@ -15,11 +15,11 @@
 #ifndef ICING_SCHEMA_SCHEMA_UTIL_H_
 #define ICING_SCHEMA_SCHEMA_UTIL_H_
 
-#include <cstdint>
 #include <string>
 #include <string_view>
 #include <unordered_map>
 #include <unordered_set>
+#include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
@@ -186,8 +186,7 @@ class SchemaUtil {
   //   ALREADY_EXISTS for case 1 and 2
   //   INVALID_ARGUMENT for 3-15
   static libtextclassifier3::StatusOr<DependentMap> Validate(
-      const SchemaProto& schema, const FeatureFlags& feature_flags,
-      bool allow_circular_schema_definitions);
+      const SchemaProto& schema, const FeatureFlags& feature_flags);
 
   // Builds a transitive inheritance map.
   //
diff --git a/icing/schema/schema-util_test.cc b/icing/schema/schema-util_test.cc
index 414525e..6758984 100644
--- a/icing/schema/schema-util_test.cc
+++ b/icing/schema/schema-util_test.cc
@@ -14,9 +14,7 @@
 
 #include "icing/schema/schema-util.h"
 
-#include <initializer_list>
 #include <memory>
-#include <string>
 #include <string_view>
 #include <unordered_set>
 #include <utility>
@@ -28,7 +26,6 @@
 #include "icing/proto/schema.pb.h"
 #include "icing/schema-builder.h"
 #include "icing/testing/common-matchers.h"
-#include "icing/testing/test-feature-flags.h"
 
 namespace icing {
 namespace lib {
@@ -50,10 +47,10 @@ constexpr char kEmailType[] = "EmailMessage";
 constexpr char kMessageType[] = "Text";
 constexpr char kPersonType[] = "Person";
 
-class SchemaUtilTest : public ::testing::TestWithParam<bool> {
+class SchemaUtilTest : public ::testing::TestWithParam<FeatureFlags> {
  protected:
   void SetUp() override {
-    feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
+    feature_flags_ = std::make_unique<FeatureFlags>(GetParam());
   }
 
   std::unique_ptr<FeatureFlags> feature_flags_;
@@ -135,9 +132,8 @@ TEST_P(SchemaUtilTest, DependentGraphAlphabeticalOrder) {
                            .AddType(type_e)
                            .AddType(type_f)
                            .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, testing::SizeIs(5));
   EXPECT_THAT(
       d_map["F"],
@@ -244,9 +240,8 @@ TEST_P(SchemaUtilTest, DependentGraphReverseAlphabeticalOrder) {
                            .AddType(type_b)
                            .AddType(type_a)
                            .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, testing::SizeIs(5));
   EXPECT_THAT(
       d_map["F"],
@@ -352,9 +347,8 @@ TEST_P(SchemaUtilTest, DependentGraphMixedOrder) {
                            .AddType(type_b)
                            .AddType(type_d)
                            .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, testing::SizeIs(5));
   EXPECT_THAT(
       d_map["F"],
@@ -407,13 +401,13 @@ TEST_P(SchemaUtilTest, TopLevelCycleIndexableTrueInvalid) {
           .Build();
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
 
 TEST_P(SchemaUtilTest, TopLevelCycleIndexableFalseNotJoinableOK) {
-  if (GetParam() != true) {
+  if (GetParam().allow_circular_schema_definitions() != true) {
     GTEST_SKIP() << "This is an invalid cycle if circular schema definitions "
                     "are not allowed.";
   }
@@ -443,9 +437,8 @@ TEST_P(SchemaUtilTest, TopLevelCycleIndexableFalseNotJoinableOK) {
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
   // Assert Validate status is OK and check dependent map
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(1));
   EXPECT_THAT(d_map["B"],
               UnorderedElementsAre(
@@ -489,13 +482,13 @@ TEST_P(SchemaUtilTest, MultiLevelCycleIndexableTrueInvalid) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs((libtextclassifier3::StatusCode::INVALID_ARGUMENT),
                        HasSubstr("Invalid cycle")));
 }
 
 TEST_P(SchemaUtilTest, MultiLevelCycleIndexableFalseNotJoinableOK) {
-  if (GetParam() != true) {
+  if (GetParam().allow_circular_schema_definitions() != true) {
     GTEST_SKIP() << "This is an invalid cycle if circular schema definitions "
                     "are not allowed.";
   }
@@ -533,12 +526,12 @@ TEST_P(SchemaUtilTest, MultiLevelCycleIndexableFalseNotJoinableOK) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::OK));
 }
 
 TEST_P(SchemaUtilTest, MultiLevelCycleDependentMapOk) {
-  if (GetParam() != true) {
+  if (GetParam().allow_circular_schema_definitions() != true) {
     GTEST_SKIP() << "This is an invalid cycle if circular schema definitions "
                     "are not allowed.";
   }
@@ -579,9 +572,8 @@ TEST_P(SchemaUtilTest, MultiLevelCycleDependentMapOk) {
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
   // Assert Validate status is OK and check dependent map
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(3));
   EXPECT_THAT(
       d_map["A"],
@@ -653,13 +645,13 @@ TEST_P(SchemaUtilTest, NestedCycleIndexableTrueInvalid) {
                            .AddType(type_c)
                            .AddType(type_d)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
 
 TEST_P(SchemaUtilTest, NestedCycleIndexableFalseNotJoinableOK) {
-  if (GetParam() != true) {
+  if (GetParam().allow_circular_schema_definitions() != true) {
     GTEST_SKIP() << "This is an invalid cycle if circular schema definitions "
                     "are not allowed.";
   }
@@ -721,9 +713,8 @@ TEST_P(SchemaUtilTest, NestedCycleIndexableFalseNotJoinableOK) {
                            .AddType(type_d)
                            .Build();
   // Assert Validate status is OK and check dependent map
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(3));
   EXPECT_THAT(d_map["B"],
               UnorderedElementsAre(
@@ -798,7 +789,7 @@ TEST_P(SchemaUtilTest, MultiplePathsAnyPathContainsCycleIsInvalid) {
                            .AddType(type_c)
                            .AddType(type_b)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -868,12 +859,12 @@ TEST_P(SchemaUtilTest, MultipleCycles_anyCycleIndexableTrueInvalid) {
                            .AddType(type_b)
                            .AddType(type_a)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
 TEST_P(SchemaUtilTest, CycleWithSameTypedProps_allPropsIndexableFalseIsOK) {
-  if (GetParam() != true) {
+  if (GetParam().allow_circular_schema_definitions() != true) {
     GTEST_SKIP() << "This is an invalid cycle if circular schema definitions "
                     "are not allowed.";
   }
@@ -909,9 +900,8 @@ TEST_P(SchemaUtilTest, CycleWithSameTypedProps_allPropsIndexableFalseIsOK) {
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
   // Assert Validate status is OK and check dependent map
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(2));
   EXPECT_THAT(
       d_map["A"],
@@ -957,7 +947,7 @@ TEST_P(SchemaUtilTest, CycleWithSameTypedProps_anyPropIndexableTrueIsInvalid) {
           .Build();
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -1005,13 +995,13 @@ TEST_P(SchemaUtilTest, CycleWithJoinablePropertyNotAllowed) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
 
 TEST_P(SchemaUtilTest, NonNestedJoinablePropOutsideCycleOK) {
-  if (GetParam() != true) {
+  if (GetParam().allow_circular_schema_definitions() != true) {
     GTEST_SKIP() << "This is an invalid cycle if circular schema definitions "
                     "are not allowed.";
   }
@@ -1057,9 +1047,8 @@ TEST_P(SchemaUtilTest, NonNestedJoinablePropOutsideCycleOK) {
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
   // Assert Validate status is OK and check dependent map
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(2));
   EXPECT_THAT(d_map["B"],
               UnorderedElementsAre(
@@ -1134,7 +1123,7 @@ TEST_P(SchemaUtilTest, DirectNestedJoinablePropOutsideCycleNotAllowed) {
                            .AddType(type_c)
                            .AddType(type_d)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -1207,7 +1196,7 @@ TEST_P(SchemaUtilTest, TransitiveNestedJoinablePropOutsideCycleNotAllowed) {
                            .AddType(type_d)
                            .AddType(type_e)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -1281,7 +1270,7 @@ TEST_P(SchemaUtilTest,
                            .AddType(type_d)
                            .AddType(type_e)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -1377,7 +1366,7 @@ TEST_P(SchemaUtilTest, ComplexCycleWithJoinablePropertyNotAllowed) {
                            .AddType(type_e)
                            .AddType(type_f)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -1469,13 +1458,13 @@ TEST_P(SchemaUtilTest, ComplexCycleWithIndexableTrueNotAllowed) {
                            .AddType(type_e)
                            .AddType(type_f)
                            .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
 
 TEST_P(SchemaUtilTest, InheritanceAndNestedTypeRelations_noCycle) {
-  if (GetParam() != true) {
+  if (GetParam().allow_circular_schema_definitions() != true) {
     GTEST_SKIP() << "This is an invalid cycle if circular schema definitions "
                     "are not allowed.";
   }
@@ -1543,9 +1532,8 @@ TEST_P(SchemaUtilTest, InheritanceAndNestedTypeRelations_noCycle) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(3));
   // Both A-B and A-C are inheritance relations.
   EXPECT_THAT(d_map["A"],
@@ -1638,7 +1626,7 @@ TEST_P(SchemaUtilTest, InheritanceAndNestedTypeRelations_nestedTypeCycle) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -1704,7 +1692,7 @@ TEST_P(SchemaUtilTest, InheritanceAndNestedTypeRelations_inheritanceCycle) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("inherits from itself")));
 }
@@ -1742,7 +1730,7 @@ TEST_P(SchemaUtilTest, NonExistentType) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -1782,9 +1770,8 @@ TEST_P(SchemaUtilTest, SingleTypeIsBothDirectAndIndirectDependent) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(2));
   EXPECT_THAT(d_map["A"],
               UnorderedElementsAre(
@@ -1810,9 +1797,8 @@ TEST_P(SchemaUtilTest, SimpleInheritance) {
       SchemaTypeConfigBuilder().SetType("B").AddParentType("A").Build();
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(1));
   EXPECT_THAT(d_map["A"], UnorderedElementsAre(Pair("B", IsEmpty())));
 
@@ -1842,9 +1828,8 @@ TEST_P(SchemaUtilTest, SingleInheritanceTypeIsBothDirectAndIndirectChild) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(2));
   EXPECT_THAT(d_map["A"],
               UnorderedElementsAre(Pair("B", IsEmpty()), Pair("C", IsEmpty())));
@@ -1888,9 +1873,8 @@ TEST_P(SchemaUtilTest, ComplexInheritance) {
                            .AddType(type_e)
                            .AddType(type_f)
                            .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(3));
   EXPECT_THAT(d_map["A"],
               UnorderedElementsAre(Pair("B", IsEmpty()), Pair("C", IsEmpty()),
@@ -1927,7 +1911,7 @@ TEST_P(SchemaUtilTest, InheritanceCycle) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -1936,7 +1920,7 @@ TEST_P(SchemaUtilTest, SelfInheritance) {
       SchemaTypeConfigBuilder().SetType("A").AddParentType("A").Build();
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -1952,7 +1936,7 @@ TEST_P(SchemaUtilTest, NonExistentParentType) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -1975,9 +1959,8 @@ TEST_P(SchemaUtilTest, SimpleInheritanceWithNestedType) {
 
   SchemaProto schema =
       SchemaBuilder().AddType(type_a).AddType(type_b).AddType(type_c).Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(2));
   // Nested-type dependency and inheritance dependencies are not transitive.
   EXPECT_THAT(d_map["A"], UnorderedElementsAre(Pair("B", IsEmpty())));
@@ -2048,9 +2031,8 @@ TEST_P(SchemaUtilTest, ComplexInheritanceWithNestedType) {
                            .AddType(type_e)
                            .AddType(type_f)
                            .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(3));
   EXPECT_THAT(
       d_map["A"],
@@ -2092,13 +2074,13 @@ TEST_P(SchemaUtilTest, InheritanceWithNestedTypeCycle) {
       SchemaTypeConfigBuilder().SetType("B").AddParentType("A").Build();
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
 TEST_P(SchemaUtilTest, EmptySchemaProtoIsValid) {
   SchemaProto schema;
-  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_));
 }
 
 TEST_P(SchemaUtilTest, Valid_Nested) {
@@ -2124,7 +2106,7 @@ TEST_P(SchemaUtilTest, Valid_Nested) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
 
-  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_));
 }
 
 TEST_P(SchemaUtilTest, ClearedPropertyConfigsIsValid) {
@@ -2133,13 +2115,13 @@ TEST_P(SchemaUtilTest, ClearedPropertyConfigsIsValid) {
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType(kEmailType))
           .Build();
-  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_));
 }
 
 TEST_P(SchemaUtilTest, ClearedSchemaTypeIsInvalid) {
   SchemaProto schema =
       SchemaBuilder().AddType(SchemaTypeConfigBuilder()).Build();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2147,7 +2129,7 @@ TEST_P(SchemaUtilTest, EmptySchemaTypeIsInvalid) {
   SchemaProto schema =
       SchemaBuilder().AddType(SchemaTypeConfigBuilder().SetType("")).Build();
 
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2157,7 +2139,7 @@ TEST_P(SchemaUtilTest, AnySchemaTypeOk) {
                                "abc123!@#$%^&*()_-+=[{]}|\\;:'\",<.>?"))
                            .Build();
 
-  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_));
 }
 
 TEST_P(SchemaUtilTest, ClearedPropertyNameIsInvalid) {
@@ -2171,7 +2153,7 @@ TEST_P(SchemaUtilTest, ClearedPropertyNameIsInvalid) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
   schema.mutable_types(0)->mutable_properties(0)->clear_property_name();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2186,7 +2168,7 @@ TEST_P(SchemaUtilTest, EmptyPropertyNameIsInvalid) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
 
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2201,7 +2183,7 @@ TEST_P(SchemaUtilTest, NonAlphanumericPropertyNameIsInvalid) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
 
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2216,7 +2198,7 @@ TEST_P(SchemaUtilTest, AlphanumericPropertyNameOk) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
 
-  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK(SchemaUtil::Validate(schema, *feature_flags_));
 }
 
 TEST_P(SchemaUtilTest, DuplicatePropertyNameIsInvalid) {
@@ -2233,7 +2215,7 @@ TEST_P(SchemaUtilTest, DuplicatePropertyNameIsInvalid) {
                                         .SetDataType(TYPE_STRING)
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::ALREADY_EXISTS));
 }
 
@@ -2248,7 +2230,7 @@ TEST_P(SchemaUtilTest, ClearedDataTypeIsInvalid) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
   schema.mutable_types(0)->mutable_properties(0)->clear_data_type();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2264,7 +2246,7 @@ TEST_P(SchemaUtilTest, UnknownDataTypeIsInvalid) {
                           .SetDataType(PropertyConfigProto::DataType::UNKNOWN)
                           .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2279,7 +2261,7 @@ TEST_P(SchemaUtilTest, ClearedCardinalityIsInvalid) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
   schema.mutable_types(0)->mutable_properties(0)->clear_cardinality();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2293,7 +2275,7 @@ TEST_P(SchemaUtilTest, UnknownCardinalityIsInvalid) {
                                         .SetDataType(TYPE_STRING)
                                         .SetCardinality(CARDINALITY_UNKNOWN)))
           .Build();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2307,7 +2289,7 @@ TEST_P(SchemaUtilTest, ClearedPropertySchemaTypeIsInvalid) {
                                         .SetDataType(TYPE_DOCUMENT)
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2324,7 +2306,7 @@ TEST_P(SchemaUtilTest, Invalid_EmptyPropertySchemaType) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
 
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -2341,7 +2323,7 @@ TEST_P(SchemaUtilTest, NoMatchingSchemaTypeIsInvalid) {
                                         .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
 
-  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  ASSERT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Undefined 'schema_type'")));
 }
@@ -4102,9 +4084,8 @@ TEST_P(SchemaUtilTest, SchemasWithConsistentScorableProperties) {
                   .SetScorableType(SCORABLE_TYPE_ENABLED)
                   .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap new_schema_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap new_schema_dependent_map,
+                             SchemaUtil::Validate(new_schema, *feature_flags_));
 
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_schema_dependent_map, *feature_flags_);
@@ -4137,9 +4118,8 @@ TEST_P(SchemaUtilTest,
                   .SetDataType(TYPE_STRING)
                   .SetCardinality(CARDINALITY_REQUIRED)))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap new_schema_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap new_schema_dependent_map,
+                             SchemaUtil::Validate(new_schema, *feature_flags_));
 
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_schema_dependent_map, *feature_flags_);
@@ -4185,9 +4165,8 @@ TEST_P(SchemaUtilTest,
                   .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap new_schema_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap new_schema_dependent_map,
+                             SchemaUtil::Validate(new_schema, *feature_flags_));
 
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_schema_dependent_map, *feature_flags_);
@@ -4220,9 +4199,8 @@ TEST_P(SchemaUtilTest,
                                         .SetScorableType(SCORABLE_TYPE_ENABLED)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap new_schema_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap new_schema_dependent_map,
+                             SchemaUtil::Validate(new_schema, *feature_flags_));
 
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_schema_dependent_map, *feature_flags_);
@@ -4261,9 +4239,8 @@ TEST_P(SchemaUtilTest,
                                         .SetScorableType(SCORABLE_TYPE_DISABLED)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap new_schema_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap new_schema_dependent_map,
+                             SchemaUtil::Validate(new_schema, *feature_flags_));
 
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_schema_dependent_map, *feature_flags_);
@@ -4303,9 +4280,8 @@ TEST_P(SchemaUtilTest,
                                         .SetScorableType(SCORABLE_TYPE_ENABLED)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap new_schema_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap new_schema_dependent_map,
+                             SchemaUtil::Validate(new_schema, *feature_flags_));
 
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_schema_dependent_map, *feature_flags_);
@@ -4360,9 +4336,8 @@ TEST_P(SchemaUtilTest,
                                             /*index_nested_properties=*/true)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap new_schema_dependent_map,
-      SchemaUtil::Validate(new_schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap new_schema_dependent_map,
+                             SchemaUtil::Validate(new_schema, *feature_flags_));
 
   SchemaUtil::SchemaDelta schema_delta = SchemaUtil::ComputeCompatibilityDelta(
       old_schema, new_schema, new_schema_dependent_map, *feature_flags_);
@@ -4382,7 +4357,7 @@ TEST_P(SchemaUtilTest, ValidateStringIndexingConfigShouldHaveTermMatchType) {
           .Build();
 
   // Error if we don't set a term match type
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // Passes once we set a term match type
@@ -4393,8 +4368,7 @@ TEST_P(SchemaUtilTest, ValidateStringIndexingConfigShouldHaveTermMatchType) {
                        .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
                        .SetCardinality(CARDINALITY_REQUIRED)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest, ValidateStringIndexingConfigShouldHaveTokenizer) {
@@ -4408,7 +4382,7 @@ TEST_P(SchemaUtilTest, ValidateStringIndexingConfigShouldHaveTokenizer) {
           .Build();
 
   // Error if we don't set a tokenizer type
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // Passes once we set a tokenizer type
@@ -4419,8 +4393,7 @@ TEST_P(SchemaUtilTest, ValidateStringIndexingConfigShouldHaveTokenizer) {
                        .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
                        .SetCardinality(CARDINALITY_REQUIRED)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest,
@@ -4437,7 +4410,7 @@ TEST_P(SchemaUtilTest,
           .Build();
 
   // Error if data type is not STRING for qualified id joinable value type.
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // Passes once we set STRING as the data type.
@@ -4450,17 +4423,20 @@ TEST_P(SchemaUtilTest,
                                     DELETE_PROPAGATION_TYPE_NONE)
                        .SetCardinality(CARDINALITY_REQUIRED)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest,
        ValidateJoinablePropertyShouldNotHaveRepeatedCardinality) {
   // We need to explicitly override enable_repeated_field_joins to false.
-  feature_flags_ =
-      std::make_unique<FeatureFlags>(/*enable_scorable_properties=*/true,
-                                     /*enable_embedding_quantization=*/true,
-                                     /*enable_repeated_field_joins=*/false);
+  feature_flags_ = std::make_unique<FeatureFlags>(
+      GetParam().allow_circular_schema_definitions(),
+      /*enable_scorable_properties=*/true,
+      /*enable_embedding_quantization=*/true,
+      /*enable_repeated_field_joins=*/false,
+      /*enable_embedding_backup_generation=*/true,
+      /*enable_schema_database=*/true,
+      /*release_backup_schema_file_if_overlay_present=*/true);
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("MyType").AddProperty(
@@ -4473,7 +4449,7 @@ TEST_P(SchemaUtilTest,
           .Build();
 
   // Error if using REPEATED cardinality for joinable property.
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // Passes once we use OPTIONAL cardinality with joinable property.
@@ -4486,8 +4462,7 @@ TEST_P(SchemaUtilTest,
                                     DELETE_PROPAGATION_TYPE_NONE)
                        .SetCardinality(CARDINALITY_OPTIONAL)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 
   // Passes once we use REQUIRED cardinality with joinable property.
   schema = SchemaBuilder()
@@ -4499,8 +4474,7 @@ TEST_P(SchemaUtilTest,
                                     DELETE_PROPAGATION_TYPE_NONE)
                        .SetCardinality(CARDINALITY_REQUIRED)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 
   // Passes once we use REPEATED cardinality with non-joinable property.
   schema = SchemaBuilder()
@@ -4512,16 +4486,19 @@ TEST_P(SchemaUtilTest,
                                     DELETE_PROPAGATION_TYPE_NONE)
                        .SetCardinality(CARDINALITY_REPEATED)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest, ValidateJoinablePropertyCanHaveRepeatedCardinality) {
   // We need to explicitly override enable_repeated_field_joins to true.
-  feature_flags_ =
-      std::make_unique<FeatureFlags>(/*enable_scorable_properties=*/true,
-                                     /*enable_embedding_quantization=*/true,
-                                     /*enable_repeated_field_joins=*/true);
+  feature_flags_ = std::make_unique<FeatureFlags>(
+      GetParam().allow_circular_schema_definitions(),
+      /*enable_scorable_properties=*/true,
+      /*enable_embedding_quantization=*/true,
+      /*enable_repeated_field_joins=*/true,
+      /*enable_embedding_backup_generation=*/true,
+      /*enable_schema_database=*/true,
+      /*release_backup_schema_file_if_overlay_present=*/true);
 
   SchemaProto schema =
       SchemaBuilder()
@@ -4535,8 +4512,7 @@ TEST_P(SchemaUtilTest, ValidateJoinablePropertyCanHaveRepeatedCardinality) {
           .Build();
 
   // Error if using REPEATED cardinality for joinable property.
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest,
@@ -4554,7 +4530,7 @@ TEST_P(SchemaUtilTest,
 
   // Error if enabling delete propagation with non qualified id joinable value
   // type.
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // Passes once we set qualified id joinable value type with delete propagation
@@ -4568,8 +4544,7 @@ TEST_P(SchemaUtilTest,
                                     DELETE_PROPAGATION_TYPE_PROPAGATE_FROM)
                        .SetCardinality(CARDINALITY_REQUIRED)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 
   // Passes once we disable delete propagation.
   schema = SchemaBuilder()
@@ -4581,8 +4556,7 @@ TEST_P(SchemaUtilTest,
                                     DELETE_PROPAGATION_TYPE_NONE)
                        .SetCardinality(CARDINALITY_REQUIRED)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest,
@@ -4612,7 +4586,7 @@ TEST_P(SchemaUtilTest,
                                        /*index_nested_properties=*/false)
                   .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // Passes once we use non-REPEATED cardinality for "C.b", i.e. the dependency
@@ -4639,8 +4613,7 @@ TEST_P(SchemaUtilTest,
                                             /*index_nested_properties=*/false)
                        .SetCardinality(CARDINALITY_OPTIONAL)))
                .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(
@@ -4683,8 +4656,7 @@ TEST_P(
 
   // Passes since nested schema type with REPEATED cardinality doesn't have
   // joinable property.
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest,
@@ -4720,7 +4692,7 @@ TEST_P(SchemaUtilTest,
                                             /*index_nested_properties=*/false)
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // Passes once we use non-REPEATED cardinality for "B.a2", i.e. the dependency
@@ -4754,8 +4726,7 @@ TEST_P(SchemaUtilTest,
                                             /*index_nested_properties=*/false)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest, ValidateNestedJoinablePropertyDiamondRelationship) {
@@ -4806,8 +4777,7 @@ TEST_P(SchemaUtilTest, ValidateNestedJoinablePropertyDiamondRelationship) {
                                             /*index_nested_properties=*/false)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 
   // Fails once we change any of edge to REPEATED cardinality.
   //           B
@@ -4855,7 +4825,7 @@ TEST_P(SchemaUtilTest, ValidateNestedJoinablePropertyDiamondRelationship) {
                                             /*index_nested_properties=*/false)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   //           B
@@ -4903,7 +4873,7 @@ TEST_P(SchemaUtilTest, ValidateNestedJoinablePropertyDiamondRelationship) {
                                             /*index_nested_properties=*/false)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   //           B
@@ -4951,7 +4921,7 @@ TEST_P(SchemaUtilTest, ValidateNestedJoinablePropertyDiamondRelationship) {
                                             /*index_nested_properties=*/false)
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   //           B
@@ -4999,7 +4969,7 @@ TEST_P(SchemaUtilTest, ValidateNestedJoinablePropertyDiamondRelationship) {
                                             /*index_nested_properties=*/false)
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -5034,8 +5004,7 @@ TEST_P(SchemaUtilTest,
       ->mutable_document_indexing_config()
       ->clear_indexable_nested_properties_list();
 
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest,
@@ -5069,8 +5038,7 @@ TEST_P(SchemaUtilTest,
       ->mutable_document_indexing_config()
       ->clear_indexable_nested_properties_list();
 
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest,
@@ -5100,8 +5068,7 @@ TEST_P(SchemaUtilTest,
   outerSchemaType->mutable_properties(0)
       ->mutable_document_indexing_config()
       ->set_index_nested_properties(false);
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest, InvalidDocumentIndexingConfigFields) {
@@ -5133,7 +5100,7 @@ TEST_P(SchemaUtilTest, InvalidDocumentIndexingConfigFields) {
       ->mutable_document_indexing_config()
       ->add_indexable_nested_properties_list("prop");
 
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -5157,8 +5124,7 @@ TEST_P(SchemaUtilTest, MultipleReferencesToSameNestedSchemaOk) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build();
 
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
-              IsOk());
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_), IsOk());
 }
 
 TEST_P(SchemaUtilTest, InvalidSelfReference) {
@@ -5175,7 +5141,7 @@ TEST_P(SchemaUtilTest, InvalidSelfReference) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
 
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -5199,7 +5165,7 @@ TEST_P(SchemaUtilTest, InvalidSelfReferenceEvenWithOtherProperties) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build();
 
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -5231,7 +5197,7 @@ TEST_P(SchemaUtilTest, InvalidInfiniteLoopTwoDegrees) {
           .Build();
 
   // Two degrees of referencing: A -> B -> A
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -5272,7 +5238,7 @@ TEST_P(SchemaUtilTest, InvalidInfiniteLoopThreeDegrees) {
           .Build();
 
   // Three degrees of referencing: A -> B -> C -> A
-  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+  EXPECT_THAT(SchemaUtil::Validate(schema, *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                        HasSubstr("Invalid cycle")));
 }
@@ -5292,7 +5258,7 @@ TEST_P(SchemaUtilTest, ChildMissingOptionalAndRepeatedPropertiesNotOk) {
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
   EXPECT_THAT(
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+      SchemaUtil::Validate(schema, *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Property text is not present in child type")));
 }
@@ -5312,7 +5278,7 @@ TEST_P(SchemaUtilTest, ChildMissingRequiredPropertyNotOk) {
 
   SchemaProto schema = SchemaBuilder().AddType(type_a).AddType(type_b).Build();
   EXPECT_THAT(
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+      SchemaUtil::Validate(schema, *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Property text is not present in child type")));
 }
@@ -5376,9 +5342,8 @@ TEST_P(SchemaUtilTest, ChildCompatiblePropertyOk) {
                            .AddType(person_type)
                            .AddType(artist_type)
                            .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(3));
   EXPECT_THAT(d_map["Message"],
               UnorderedElementsAre(Pair("ArtistMessage", IsEmpty())));
@@ -5444,7 +5409,7 @@ TEST_P(SchemaUtilTest, ChildIncompatibleCardinalityPropertyNotOk) {
                            .AddType(artist_type)
                            .Build();
   EXPECT_THAT(
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+      SchemaUtil::Validate(schema, *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Property person from child type ArtistMessage is not "
                          "compatible to the parent type Message.")));
@@ -5500,7 +5465,7 @@ TEST_P(SchemaUtilTest, ChildIncompatibleDataTypePropertyNotOk) {
                            .AddType(artist_type)
                            .Build();
   EXPECT_THAT(
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+      SchemaUtil::Validate(schema, *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Property text from child type ArtistMessage is not "
                          "compatible to the parent type Message.")));
@@ -5557,7 +5522,7 @@ TEST_P(SchemaUtilTest, ChildIncompatibleDocumentTypePropertyNotOk) {
                            .AddType(artist_type)
                            .Build();
   EXPECT_THAT(
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()),
+      SchemaUtil::Validate(schema, *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Property person from child type ArtistMessage is not "
                          "compatible to the parent type Message.")));
@@ -5614,9 +5579,8 @@ TEST_P(SchemaUtilTest, ChildCompatibleMultipleParentPropertyOk) {
                            .AddType(message_type)
                            .AddType(email_message_type)
                            .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(
-      SchemaUtil::DependentMap d_map,
-      SchemaUtil::Validate(schema, *feature_flags_, GetParam()));
+  ICING_ASSERT_OK_AND_ASSIGN(SchemaUtil::DependentMap d_map,
+                             SchemaUtil::Validate(schema, *feature_flags_));
   EXPECT_THAT(d_map, SizeIs(2));
   EXPECT_THAT(d_map["Email"],
               UnorderedElementsAre(Pair("EmailMessage", IsEmpty())));
@@ -5672,7 +5636,7 @@ TEST_P(SchemaUtilTest, ChildIncompatibleMultipleParentPropertyNotOk) {
                             .AddType(email_message_type1)
                             .Build();
   EXPECT_THAT(
-      SchemaUtil::Validate(schema1, *feature_flags_, GetParam()),
+      SchemaUtil::Validate(schema1, *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr(
                    "Property sender is not present in child type EmailMessage, "
@@ -5701,7 +5665,7 @@ TEST_P(SchemaUtilTest, ChildIncompatibleMultipleParentPropertyNotOk) {
                             .AddType(email_message_type2)
                             .Build();
   EXPECT_THAT(
-      SchemaUtil::Validate(schema2, *feature_flags_, GetParam()),
+      SchemaUtil::Validate(schema2, *feature_flags_),
       StatusIs(
           libtextclassifier3::StatusCode::INVALID_ARGUMENT,
           HasSubstr(
@@ -5720,7 +5684,7 @@ TEST_P(SchemaUtilTest, ValidateScorableType_EnabledForSupportedDataTypes) {
                            .SetDataTypeInt64(NUMERIC_MATCH_RANGE))
           .Build();
   EXPECT_THAT(SchemaUtil::Validate(SchemaBuilder().AddType(type_int64).Build(),
-                                   *feature_flags_, GetParam()),
+                                   *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::OK));
 
   SchemaTypeConfigProto type_double =
@@ -5734,7 +5698,7 @@ TEST_P(SchemaUtilTest, ValidateScorableType_EnabledForSupportedDataTypes) {
           .Build();
 
   EXPECT_THAT(SchemaUtil::Validate(SchemaBuilder().AddType(type_double).Build(),
-                                   *feature_flags_, GetParam()),
+                                   *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::OK));
 
   SchemaTypeConfigProto type_boolean =
@@ -5749,7 +5713,7 @@ TEST_P(SchemaUtilTest, ValidateScorableType_EnabledForSupportedDataTypes) {
 
   EXPECT_THAT(
       SchemaUtil::Validate(SchemaBuilder().AddType(type_boolean).Build(),
-                           *feature_flags_, GetParam()),
+                           *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::OK));
 }
 
@@ -5765,7 +5729,7 @@ TEST_P(SchemaUtilTest, ValidateScorableType_EnabledForUnsupportedDataTypes) {
           .Build();
   EXPECT_THAT(
       SchemaUtil::Validate(SchemaBuilder().AddType(type_a).Build(),
-                           *feature_flags_, GetParam()),
+                           *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Field 'scorable_type' cannot be enabled for data "
                          "type 'STRING' for schema property 'A.c'")));
@@ -5798,7 +5762,7 @@ TEST_P(SchemaUtilTest,
   EXPECT_THAT(
       SchemaUtil::Validate(
           SchemaBuilder().AddType(type_document).AddType(message_type).Build(),
-          *feature_flags_, GetParam()),
+          *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Field 'scorable_type' shouldn't be explicitly "
                          "set for data type DOCUMENT")));
@@ -5831,7 +5795,7 @@ TEST_P(SchemaUtilTest,
   EXPECT_THAT(
       SchemaUtil::Validate(
           SchemaBuilder().AddType(type_document).AddType(message_type).Build(),
-          *feature_flags_, GetParam()),
+          *feature_flags_),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
                HasSubstr("Field 'scorable_type' shouldn't be explicitly "
                          "set for data type DOCUMENT")));
@@ -5848,13 +5812,29 @@ TEST_P(SchemaUtilTest, ValidateScorableType_DisabledForUnsupportedDataTypes) {
                            .SetDataType(TYPE_STRING))
           .Build();
   EXPECT_THAT(SchemaUtil::Validate(SchemaBuilder().AddType(type_b).Build(),
-                                   *feature_flags_, GetParam()),
+                                   *feature_flags_),
               StatusIs(libtextclassifier3::StatusCode::OK));
 }
 
 INSTANTIATE_TEST_SUITE_P(
     SchemaUtilTest, SchemaUtilTest,
-    testing::Values(/*allow_circular_schema_definitions=*/true, false));
+    testing::Values(
+        FeatureFlags(
+            /*enable_circular_schema_definitions=*/false,
+            /*enable_scorable_properties=*/true,
+            /*enable_embedding_quantization=*/true,
+            /*enable_repeated_field_joins=*/true,
+            /*enable_embedding_backup_generation=*/true,
+            /*enable_schema_database=*/true,
+            /*release_backup_schema_file_if_overlay_present=*/true),
+        FeatureFlags(
+            /*enable_circular_schema_definitions=*/true,
+            /*enable_scorable_properties=*/true,
+            /*enable_embedding_quantization=*/true,
+            /*enable_repeated_field_joins=*/true,
+            /*enable_embedding_backup_generation=*/true,
+            /*enable_schema_database=*/true,
+            /*release_backup_schema_file_if_overlay_present=*/true)));
 
 struct IsIndexedPropertyTestParam {
   PropertyConfigProto property_config;
diff --git a/icing/scoring/advanced_scoring/advanced-scorer_test.cc b/icing/scoring/advanced_scoring/advanced-scorer_test.cc
index ccd10c6..386d0c2 100644
--- a/icing/scoring/advanced_scoring/advanced-scorer_test.cc
+++ b/icing/scoring/advanced_scoring/advanced-scorer_test.cc
@@ -167,8 +167,7 @@ class AdvancedScorerTest : public testing::Test {
             .Build();
 
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        test_schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        test_schema, /*ignore_errors_and_delete_documents=*/false));
   }
 
   void TearDown() override {
@@ -1366,10 +1365,10 @@ TEST_F(AdvancedScorerTest,
        MatchedSemanticScoresFunctionScoreExpressionTypeError) {
   EmbeddingQueryResults embedding_query_results;
   embedding_query_results
-      .result_scores[/*query_vector_index=*/0]
+      .result_infos[/*query_vector_index=*/0]
                     [SearchSpecProto::EmbeddingQueryMetricType::COSINE]
                     [/*document_id=*/0]
-      .push_back(/*semantic_score=*/0.1);
+      .AppendScore(/*semantic_score=*/0.1);
 
   libtextclassifier3::StatusOr<std::unique_ptr<AdvancedScorer>> scorer_or =
       AdvancedScorer::Create(
@@ -1467,15 +1466,15 @@ TEST_F(AdvancedScorerTest,
        MatchedSemanticScoresFunctionScoreExpressionNotQueried) {
   EmbeddingQueryResults embedding_query_results;
   embedding_query_results
-      .result_scores[/*query_vector_index=*/0]
+      .result_infos[/*query_vector_index=*/0]
                     [SearchSpecProto::EmbeddingQueryMetricType::COSINE]
                     [/*document_id=*/0]
-      .push_back(/*semantic_score=*/0.1);
+      .AppendScore(/*semantic_score=*/0.1);
   embedding_query_results
-      .result_scores[/*query_vector_index=*/1]
+      .result_infos[/*query_vector_index=*/1]
                     [SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT]
                     [/*document_id=*/1]
-      .push_back(/*semantic_score=*/0.2);
+      .AppendScore(/*semantic_score=*/0.2);
 
   libtextclassifier3::StatusOr<std::unique_ptr<AdvancedScorer>> scorer_or =
       AdvancedScorer::Create(CreateAdvancedScoringSpec(
@@ -1565,9 +1564,9 @@ TEST_F(AdvancedScorerTest,
 }
 
 void AddEntryToEmbeddingQueryScoreMap(
-    EmbeddingQueryResults::EmbeddingQueryScoreMap& score_map,
+    EmbeddingQueryResults::EmbeddingQueryMatchInfoMap& score_map,
     double semantic_score, DocumentId document_id) {
-  score_map[document_id].push_back(semantic_score);
+  score_map[document_id].AppendScore(semantic_score);
 }
 
 TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
@@ -1587,9 +1586,9 @@ TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
   // EUCLIDEAN:
   //   Document 0: 0.7
   //   Document 1: 0.8
-  EmbeddingQueryResults::EmbeddingQueryScoreMap* score_map =
+  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* score_map =
       &embedding_query_results
-           .result_scores[0][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
+           .result_infos[0][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
   AddEntryToEmbeddingQueryScoreMap(*score_map,
                                    /*semantic_score=*/0.1, document_id_0);
   AddEntryToEmbeddingQueryScoreMap(*score_map,
@@ -1598,7 +1597,7 @@ TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
                                    /*semantic_score=*/0.3, document_id_1);
   AddEntryToEmbeddingQueryScoreMap(*score_map,
                                    /*semantic_score=*/0.4, document_id_1);
-  score_map = &embedding_query_results.result_scores
+  score_map = &embedding_query_results.result_infos
                    [0][SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT];
   AddEntryToEmbeddingQueryScoreMap(*score_map,
                                    /*semantic_score=*/0.5, document_id_0);
@@ -1606,7 +1605,7 @@ TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
                                    /*semantic_score=*/0.6, document_id_1);
   score_map =
       &embedding_query_results
-           .result_scores[0]
+           .result_infos[0]
                          [SearchSpecProto::EmbeddingQueryMetricType::EUCLIDEAN];
   AddEntryToEmbeddingQueryScoreMap(*score_map,
                                    /*semantic_score=*/0.7, document_id_0);
@@ -1617,7 +1616,7 @@ TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
   // DOT_PRODUCT:
   //   Document 0: 0.1
   //   Document 1: 0.2
-  score_map = &embedding_query_results.result_scores
+  score_map = &embedding_query_results.result_infos
                    [1][SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT];
   AddEntryToEmbeddingQueryScoreMap(*score_map,
                                    /*semantic_score=*/0.1, document_id_0);
@@ -1719,9 +1718,9 @@ TEST_F(AdvancedScorerTest, ListRelatedFunctions) {
   // - this.matchedSemanticScores(getEmbeddingParameter(1)) returns an empty
   //   list.
   EmbeddingQueryResults embedding_query_results;
-  EmbeddingQueryResults::EmbeddingQueryScoreMap* score_map =
+  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* score_map =
       &embedding_query_results
-           .result_scores[0][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
+           .result_infos[0][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
   AddEntryToEmbeddingQueryScoreMap(*score_map,
                                    /*semantic_score=*/4, document_id_0);
   AddEntryToEmbeddingQueryScoreMap(*score_map,
@@ -1734,7 +1733,7 @@ TEST_F(AdvancedScorerTest, ListRelatedFunctions) {
                                    /*semantic_score=*/3, document_id_0);
   score_map =
       &embedding_query_results
-           .result_scores[1][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
+           .result_infos[1][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
 
   // maxOrDefault({4, 5, 2, 1, 3}, 100) = 5
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1933,62 +1932,144 @@ TEST_F(AdvancedScorerTest, GetScorableProperty_SchemaNotExistInSchemaStore) {
 }
 
 TEST_F(AdvancedScorerTest, GetScorableProperty_PropertyNameNotScorable) {
+  DocumentProto document =
+      DocumentBuilder()
+          .SetKey("namespace", "uri")
+          .SetSchema("person")
+          .SetScore(100)
+          .SetCreationTimestampMs(123)
+          .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
+          .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             document_store_->Put(document));
+  DocHitInfo docHitInfo(put_result.new_document_id);
+
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
       "this.documentScore() + "
-      "sum(getScorableProperty(\"aliasEmail\", \"subject\"))");
-  AddSchemaTypeAliasMap(&scoring_spec, "aliasEmail", {"email"});
+      "sum(getScorableProperty(\"aliasPerson\", \"subject\"))");
+  AddSchemaTypeAliasMap(&scoring_spec, "aliasPerson", {"person"});
   scoring_spec.add_scoring_feature_types_enabled(
       ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
+  double expected_score = 100 + 0;
 
-  EXPECT_THAT(AdvancedScorer::Create(
-                  scoring_spec, /*default_score=*/10,
-                  kDefaultSemanticMetricType, document_store_.get(),
-                  schema_store_.get(), fake_clock_.GetSystemTimeMilliseconds(),
-                  /*join_children_fetcher=*/nullptr,
-                  &empty_embedding_query_results_, feature_flags_.get()),
-              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
-                       HasSubstr("'subject' is not defined as a scorable "
-                                 "property under schema type")));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<AdvancedScorer> scorer,
+      AdvancedScorer::Create(scoring_spec,
+                             /*default_score=*/10, kDefaultSemanticMetricType,
+                             document_store_.get(), schema_store_.get(),
+                             fake_clock_.GetSystemTimeMilliseconds(),
+                             /*join_children_fetcher=*/nullptr,
+                             &empty_embedding_query_results_,
+                             feature_flags_.get()));
+  scorer->PrepareToScore(/*query_term_iterators=*/{});
+  EXPECT_THAT(scorer->GetScore(docHitInfo, /*query_it=*/nullptr),
+              DoubleNear(expected_score, kEps));
 }
 
 TEST_F(AdvancedScorerTest, GetScorableProperty_PropertyNameNotExist) {
+  DocumentProto document =
+      DocumentBuilder()
+          .SetKey("namespace", "uri")
+          .SetSchema("person")
+          .SetScore(100)
+          .SetCreationTimestampMs(123)
+          .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
+          .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             document_store_->Put(document));
+  DocHitInfo docHitInfo(put_result.new_document_id);
+
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
       "this.documentScore() + "
-      "sum(getScorableProperty(\"aliasEmail\", \"non_exist\"))");
-  AddSchemaTypeAliasMap(&scoring_spec, "aliasEmail", {"email"});
+      "sum(getScorableProperty(\"aliasPerson\", \"notExist\"))");
+  AddSchemaTypeAliasMap(&scoring_spec, "aliasPerson", {"person"});
   scoring_spec.add_scoring_feature_types_enabled(
       ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
+  double expected_score = 100 + 0;
 
-  EXPECT_THAT(AdvancedScorer::Create(
-                  scoring_spec, /*default_score=*/10,
-                  kDefaultSemanticMetricType, document_store_.get(),
-                  schema_store_.get(), fake_clock_.GetSystemTimeMilliseconds(),
-                  /*join_children_fetcher=*/nullptr,
-                  &empty_embedding_query_results_, feature_flags_.get()),
-              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
-                       HasSubstr("'non_exist' is not defined as a scorable "
-                                 "property under schema type")));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<AdvancedScorer> scorer,
+      AdvancedScorer::Create(scoring_spec,
+                             /*default_score=*/10, kDefaultSemanticMetricType,
+                             document_store_.get(), schema_store_.get(),
+                             fake_clock_.GetSystemTimeMilliseconds(),
+                             /*join_children_fetcher=*/nullptr,
+                             &empty_embedding_query_results_,
+                             feature_flags_.get()));
+  scorer->PrepareToScore(/*query_term_iterators=*/{});
+  EXPECT_THAT(scorer->GetScore(docHitInfo, /*query_it=*/nullptr),
+              DoubleNear(expected_score, kEps));
 }
 
 TEST_F(AdvancedScorerTest, GetScorableProperty_SomePropertiesNotScorable) {
+  DocumentProto document =
+      DocumentBuilder()
+          .SetKey("namespace", "uri")
+          .SetSchema("person")
+          .SetScore(100)
+          .SetCreationTimestampMs(123)
+          .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
+          .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             document_store_->Put(document));
+  DocHitInfo docHitInfo(put_result.new_document_id);
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
       "this.documentScore() + "
-      "100 * avg(getScorableProperty(\"aliasPerson\", \"isStarred\")) + "
-      "10  * max(getScorableProperty(\"aliasPerson\", \"frequencyScore\")) + "
-      "10  * sum(getScorableProperty(\"aliasPerson\", \"non_exist\"))");
+      "max(getScorableProperty(\"aliasPerson\", \"frequencyScore\")) + "
+      "sum(getScorableProperty(\"aliasPerson\", \"nonExist\"))");
   AddSchemaTypeAliasMap(&scoring_spec, "aliasPerson", {"person"});
   scoring_spec.add_scoring_feature_types_enabled(
       ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
+  double expected_score = 100 + std::max({1.0, 2.0, 3.0}) + 0;
 
-  EXPECT_THAT(AdvancedScorer::Create(
-                  scoring_spec, /*default_score=*/10,
-                  kDefaultSemanticMetricType, document_store_.get(),
-                  schema_store_.get(), fake_clock_.GetSystemTimeMilliseconds(),
-                  /*join_children_fetcher=*/nullptr,
-                  &empty_embedding_query_results_, feature_flags_.get()),
-              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
-                       HasSubstr("'non_exist' is not defined as a scorable "
-                                 "property under schema type")));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<AdvancedScorer> scorer,
+      AdvancedScorer::Create(scoring_spec,
+                             /*default_score=*/10, kDefaultSemanticMetricType,
+                             document_store_.get(), schema_store_.get(),
+                             fake_clock_.GetSystemTimeMilliseconds(),
+                             /*join_children_fetcher=*/nullptr,
+                             &empty_embedding_query_results_,
+                             feature_flags_.get()));
+  scorer->PrepareToScore(/*query_term_iterators=*/{});
+  EXPECT_THAT(scorer->GetScore(docHitInfo, /*query_it=*/nullptr),
+              DoubleNear(expected_score, kEps));
+}
+
+TEST_F(AdvancedScorerTest,
+       GetScorableProperty_InvalidSchemaTypeInTheGetScorablePropertyFunction) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace", "uri")
+                               .SetSchema("email")
+                               .SetScore(100)
+                               .SetCreationTimestampMs(123)
+                               .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             document_store_->Put(document));
+  DocHitInfo docHitInfo(put_result.new_document_id);
+
+  ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
+      "this.documentScore() + "
+      "sum(getScorableProperty(\"aliasPerson\", \"frequencyScore\"))");
+  AddSchemaTypeAliasMap(&scoring_spec, "aliasPerson", {"invalid"});
+  scoring_spec.add_scoring_feature_types_enabled(
+      ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
+  double expected_score = 100 + 0;
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<AdvancedScorer> scorer,
+      AdvancedScorer::Create(
+          scoring_spec, /*default_score=*/10, kDefaultSemanticMetricType,
+          document_store_.get(), schema_store_.get(),
+          fake_clock_.GetSystemTimeMilliseconds(),
+          /*join_children_fetcher=*/nullptr, &empty_embedding_query_results_,
+          feature_flags_.get()));
+  scorer->PrepareToScore(/*query_term_iterators=*/{});
+  EXPECT_THAT(scorer->GetScore(docHitInfo, /*query_it=*/nullptr),
+              DoubleNear(expected_score, kEps));
 }
 
 TEST_F(AdvancedScorerTest,
@@ -2062,6 +2143,83 @@ TEST_F(AdvancedScorerTest,
               DoubleNear(expected_score, kEps));
 }
 
+TEST_F(AdvancedScorerTest,
+       SchemaTypeAliasMap_PropertyNotScorableForSomeSchemaTypes) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(
+              SchemaTypeConfigBuilder()
+                  .SetType("pkg/db1/gmail")
+                  .AddProperty(
+                      PropertyConfigBuilder()
+                          .SetName("frequencyScore")
+                          .SetDataType(PropertyConfigProto::DataType::DOUBLE)
+                          .SetCardinality(CARDINALITY_REPEATED)
+                          .SetScorableType(SCORABLE_TYPE_ENABLED)))
+          .AddType(
+              SchemaTypeConfigBuilder()
+                  .SetType("pkg/db2/gmail")
+                  .AddProperty(
+                      PropertyConfigBuilder()
+                          .SetName("frequencyScore")
+                          .SetDataType(PropertyConfigProto::DataType::DOUBLE)
+                          .SetCardinality(CARDINALITY_REPEATED)))
+          .Build();
+
+  ICING_ASSERT_OK(schema_store_->SetSchema(
+      schema, /*ignore_errors_and_delete_documents=*/true));
+
+  DocumentProto document_from_db1 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("pkg/db1/gmail")
+          .SetScore(100)
+          .SetCreationTimestampMs(123)
+          .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
+          .Build();
+  DocumentProto document_from_db2 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri2")
+          .SetSchema("pkg/db2/gmail")
+          .SetScore(100)
+          .SetCreationTimestampMs(123)
+          .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
+          .Build();
+  double expected_score_doc1 = 100 + (1 + 2 + 3);
+  double expected_score_doc2 = 100 + 0;
+
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store_->Put(document_from_db1));
+  DocHitInfo docHitInfo1(put_result1.new_document_id);
+
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store_->Put(document_from_db2));
+  DocHitInfo docHitInfo2(put_result2.new_document_id);
+
+  ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
+      "this.documentScore() + "
+      "sum(getScorableProperty(\"gmail\", \"frequencyScore\"))");
+  AddSchemaTypeAliasMap(&scoring_spec, "gmail",
+                        {"pkg/db1/gmail", "pkg/db2/gmail"});
+  scoring_spec.add_scoring_feature_types_enabled(
+      ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<AdvancedScorer> scorer,
+      AdvancedScorer::Create(scoring_spec,
+                             /*default_score=*/10, kDefaultSemanticMetricType,
+                             document_store_.get(), schema_store_.get(),
+                             fake_clock_.GetSystemTimeMilliseconds(),
+                             /*join_children_fetcher=*/nullptr,
+                             &empty_embedding_query_results_,
+                             feature_flags_.get()));
+  scorer->PrepareToScore(/*query_term_iterators=*/{});
+  EXPECT_THAT(scorer->GetScore(docHitInfo1, /*query_it=*/nullptr),
+              DoubleNear(expected_score_doc1, kEps));
+  EXPECT_THAT(scorer->GetScore(docHitInfo2, /*query_it=*/nullptr),
+              DoubleNear(expected_score_doc2, kEps));
+}
+
 TEST_F(AdvancedScorerTest, GetScorableProperty_WithDoubleList) {
   DocumentProto document =
       DocumentBuilder()
@@ -2394,8 +2552,7 @@ TEST_F(AdvancedScorerTest, ScoreWithScorableProperty_WithNestedSchemas) {
           .Build();
 
   ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema_proto, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/true));
+      schema_proto, /*ignore_errors_and_delete_documents=*/true));
 
   DocumentProto document =
       DocumentBuilder()
@@ -2500,70 +2657,39 @@ TEST_F(AdvancedScorerTest, ScoreWithScorableProperty_WithNestedSchemas) {
 }
 
 TEST_F(AdvancedScorerTest, SchemaTypeAliasMap_AliasSchemaTypeNotMatched) {
-  ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
-      "this.documentScore() + "
-      "sum(getScorableProperty(\"aliasEmail\", \"frequencyScore\"))");
-  AddSchemaTypeAliasMap(&scoring_spec, "aliasPerson", {"person"});
-  scoring_spec.add_scoring_feature_types_enabled(
-      ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
-
-  EXPECT_THAT(
-      AdvancedScorer::Create(
-          scoring_spec, /*default_score=*/10, kDefaultSemanticMetricType,
-          document_store_.get(), schema_store_.get(),
-          fake_clock_.GetSystemTimeMilliseconds(),
-          /*join_children_fetcher=*/nullptr, &empty_embedding_query_results_,
-          feature_flags_.get()),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
-               HasSubstr("The alias schema type in the score expression is not "
-                         "found in the schema_type_alias_map")));
-}
-
-TEST_F(AdvancedScorerTest,
-       SchemaTypeAliasMap_PropertyNotScorableForSomeSchemaTypes) {
-  SchemaProto schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder()
-                  .SetType("pkg1/db1/message")
-                  .AddProperty(
-                      PropertyConfigBuilder()
-                          .SetName("frequencyScore")
-                          .SetDataType(PropertyConfigProto::DataType::INT64)
-                          .SetCardinality(CARDINALITY_REPEATED)
-                          .SetScorableType(SCORABLE_TYPE_ENABLED)))
-          .AddType(
-              SchemaTypeConfigBuilder()
-                  .SetType("pkg2/db1/message")
-                  .AddProperty(
-                      PropertyConfigBuilder()
-                          .SetName("frequencyScore")
-                          .SetDataType(PropertyConfigProto::DataType::INT64)
-                          .SetCardinality(CARDINALITY_REPEATED)))
+  DocumentProto document =
+      DocumentBuilder()
+          .SetKey("namespace", "uri")
+          .SetSchema("person")
+          .SetScore(100)
+          .SetCreationTimestampMs(123)
+          .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK(schema_store_->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             document_store_->Put(document));
+  DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
       "this.documentScore() + "
-      "sum(getScorableProperty(\"message\", \"frequencyScore\"))");
-  AddSchemaTypeAliasMap(&scoring_spec, "message",
-                        {"pkg1/db1/message", "pkg2/db1/message"});
+      "sum(getScorableProperty(\"notExist\", \"frequencyScore\"))");
+  AddSchemaTypeAliasMap(&scoring_spec, "aliasPerson", {"person"});
   scoring_spec.add_scoring_feature_types_enabled(
       ScoringFeatureType::SCORABLE_PROPERTY_RANKING);
+  double expected_score = 100 + 0;
 
-  EXPECT_THAT(
-      AdvancedScorer::Create(
-          scoring_spec, /*default_score=*/10, kDefaultSemanticMetricType,
-          document_store_.get(), schema_store_.get(),
-          fake_clock_.GetSystemTimeMilliseconds(),
-          /*join_children_fetcher=*/nullptr, &empty_embedding_query_results_,
-          feature_flags_.get()),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
-               HasSubstr("'frequencyScore' is not defined as a scorable "
-                         "property under schema type 1")));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<AdvancedScorer> scorer,
+      AdvancedScorer::Create(scoring_spec,
+                             /*default_score=*/10, kDefaultSemanticMetricType,
+                             document_store_.get(), schema_store_.get(),
+                             fake_clock_.GetSystemTimeMilliseconds(),
+                             /*join_children_fetcher=*/nullptr,
+                             &empty_embedding_query_results_,
+                             feature_flags_.get()));
+  scorer->PrepareToScore(/*query_term_iterators=*/{});
+  EXPECT_THAT(scorer->GetScore(docHitInfo, /*query_it=*/nullptr),
+              DoubleNear(expected_score, kEps));
 }
 
 }  // namespace
diff --git a/icing/scoring/advanced_scoring/score-expression-util_test.cc b/icing/scoring/advanced_scoring/score-expression-util_test.cc
index 29ef915..4e4355b 100644
--- a/icing/scoring/advanced_scoring/score-expression-util_test.cc
+++ b/icing/scoring/advanced_scoring/score-expression-util_test.cc
@@ -95,8 +95,7 @@ class ScoreExpressionUtilTest : public testing::Test {
             .Build();
 
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        std::move(test_schema), /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        std::move(test_schema), /*ignore_errors_and_delete_documents=*/false));
   }
 
   void TearDown() override {
diff --git a/icing/scoring/advanced_scoring/score-expression.cc b/icing/scoring/advanced_scoring/score-expression.cc
index 8804605..445e1f3 100644
--- a/icing/scoring/advanced_scoring/score-expression.cc
+++ b/icing/scoring/advanced_scoring/score-expression.cc
@@ -772,8 +772,8 @@ MatchedSemanticScoresFunctionScoreExpression::Create(
         uint32_t embedding_index,
         embedding_index_arg->EvaluateDouble(DocHitInfo(),
                                             /*query_it=*/nullptr));
-    if (embedding_query_results->GetScoreMap(embedding_index, metric_type) ==
-        nullptr) {
+    if (embedding_query_results->GetMatchInfoMap(embedding_index,
+                                                 metric_type) == nullptr) {
       return absl_ports::InvalidArgumentError(absl_ports::StrCat(
           "The embedding query index ", std::to_string(embedding_index),
           " with metric type ",
@@ -818,42 +818,37 @@ GetScorablePropertyFunctionScoreExpression::GetAndValidateSchemaTypeIds(
     std::string_view alias_schema_type, std::string_view property_path,
     const SchemaTypeAliasMap& schema_type_alias_map,
     const SchemaStore& schema_store) {
+  std::unordered_set<SchemaTypeId> schema_type_ids;
+
   auto alias_map_iter = schema_type_alias_map.find(alias_schema_type.data());
   if (alias_map_iter == schema_type_alias_map.end()) {
-    return absl_ports::InvalidArgumentError(absl_ports::StrCat(
-        "The alias schema type in the score expression is not found in the "
-        "schema_type_alias_map: ",
-        alias_schema_type));
+    return schema_type_ids;
   }
 
-  std::unordered_set<SchemaTypeId> schema_type_ids;
   for (std::string_view schema_type : alias_map_iter->second) {
     // First, verify that the schema type has a valid schema type id in the
     // schema store.
     libtextclassifier3::StatusOr<SchemaTypeId> schema_type_id_or =
         schema_store.GetSchemaTypeId(schema_type);
     if (!schema_type_id_or.ok()) {
-      if (absl_ports::IsNotFound(schema_type_id_or.status())) {
-        // Ignores the schema type if it is not found in the schema store.
-        continue;
-      }
-      return schema_type_id_or.status();
+      // Swallow the error of invalid schema type in the getScorableProperty
+      // function.
+      // Icing will return an empty list of double values in this case.
+      continue;
     }
     SchemaTypeId schema_type_id = schema_type_id_or.ValueOrDie();
 
     // Then, calls GetScorablePropertyIndex() here to validate if the property
-    // path is scorable under the schema type, no need to check the returned
-    // index value.
+    // path is scorable under the schema type.
+    // No error will be thrown if the property path is not scorable under the
+    // schema type. Instead, Icing will return an empty list of double values
+    // in this case.
     libtextclassifier3::StatusOr<std::optional<int>>
         scorable_property_index_or = schema_store.GetScorablePropertyIndex(
             schema_type_id, property_path);
-    if (!scorable_property_index_or.ok()) {
-      return scorable_property_index_or.status();
-    }
-    if (!scorable_property_index_or.ValueOrDie().has_value()) {
-      return absl_ports::InvalidArgumentError(IcingStringUtil::StringPrintf(
-          "'%s' is not defined as a scorable property under schema type %d",
-          property_path.data(), schema_type_id));
+    if (!scorable_property_index_or.ok() ||
+        !scorable_property_index_or.ValueOrDie().has_value()) {
+      continue;
     }
     schema_type_ids.insert(schema_type_id);
   }
@@ -899,6 +894,9 @@ GetScorablePropertyFunctionScoreExpression::EvaluateList(
     return std::vector<double>();
   }
 
+  // By this point, the document to be evaluated is guaranteed to have a
+  // ScorablePropertySetProto, and the property path is guaranteed to be a
+  // scorable property under the schema type.
   std::unique_ptr<ScorablePropertySet> scorable_property_set =
       document_store_.GetScorablePropertySet(hit_info.document_id(),
                                              current_time_ms_);
diff --git a/icing/scoring/advanced_scoring/score-expression.h b/icing/scoring/advanced_scoring/score-expression.h
index b61ac7b..53c5807 100644
--- a/icing/scoring/advanced_scoring/score-expression.h
+++ b/icing/scoring/advanced_scoring/score-expression.h
@@ -550,8 +550,18 @@ class GetScorablePropertyFunctionScoreExpression : public ScoreExpression {
   const DocumentStore& document_store_;
   const SchemaStore& schema_store_;
   int64_t current_time_ms_;
-  // A doc hit is evaluated by this function only if its schema type id is in
-  // this set.
+
+  // A set of schema type ids that have been validated.
+  //
+  // When Parsing the getScorableProperty(schema_type_alias, property_path)
+  // function, Icing first looks up the schema_type_alias_map with the
+  // schema_type_alias, and for each matched schema type, Icing validates that:
+  //   - The schema type is valid in the schema store.
+  //   - The |property_path_| is defined as scorable under the schema type.
+  //
+  // At the query evaluation time, Icing will check each doc's schema type id
+  // against this set. If it is not in the set, then an empty list will be
+  // returned.
   std::unordered_set<SchemaTypeId> schema_type_ids_;
   std::string property_path_;
 };
diff --git a/icing/scoring/priority-queue-scored-document-hits-ranker.h b/icing/scoring/priority-queue-scored-document-hits-ranker.h
index 0798d7d..68cf921 100644
--- a/icing/scoring/priority-queue-scored-document-hits-ranker.h
+++ b/icing/scoring/priority-queue-scored-document-hits-ranker.h
@@ -16,10 +16,12 @@
 #define ICING_SCORING_PRIORITY_QUEUE_SCORED_DOCUMENT_HITS_RANKER_H_
 
 #include <queue>
+#include <unordered_set>
 #include <vector>
 
 #include "icing/scoring/scored-document-hit.h"
 #include "icing/scoring/scored-document-hits-ranker.h"
+#include "icing/store/document-id.h"
 
 namespace icing {
 namespace lib {
@@ -52,6 +54,18 @@ class PriorityQueueScoredDocumentHitsRanker : public ScoredDocumentHitsRanker {
   //   to convert it to JoinedScoredDocumentHit.
   JoinedScoredDocumentHit PopNext() override;
 
+  // Returns DocumentIds of the top K documents according to the ranking policy.
+  // - For ScoredDocumentHit, this returns the DocumentIds of the top K
+  //   documents.
+  // - For JoinedScoredDocumentHit, this returns the DocumentIds of the top K
+  //   parent documents.
+  std::unordered_set<DocumentId> GetTopKDocumentIds(int k) const override;
+
+  // Returns the DocumentIds of the top K child documents for each
+  // JoinedScoredDocumentHit.
+  // - For ScoredDocumentHit, this returns an empty set.
+  std::unordered_set<DocumentId> GetTopKChildDocumentIds(int k) const override;
+
   void TruncateHitsTo(int new_size) override;
 
   int size() const override { return scored_data_pq_.size(); }
@@ -105,6 +119,65 @@ PriorityQueueScoredDocumentHitsRanker<ScoredDataType, Converter>::PopNext() {
   return converter_(std::move(next_scored_data));
 }
 
+template <typename ScoredDataType, typename Converter>
+std::unordered_set<DocumentId> PriorityQueueScoredDocumentHitsRanker<
+    ScoredDataType, Converter>::GetTopKDocumentIds(int k) const {
+  std::unordered_set<DocumentId> top_k_document_ids;
+  if (k <= 0) {
+    return top_k_document_ids;
+  }
+
+  std::priority_queue<ScoredDataType, std::vector<ScoredDataType>, Comparator>
+      pq_copy(scored_data_pq_);
+  for (int i = 0; i < k && !pq_copy.empty(); ++i) {
+    const ScoredDataType& next_scored_data = pq_copy.top();
+    if constexpr (std::is_same_v<ScoredDataType, ScoredDocumentHit>) {
+      top_k_document_ids.insert(next_scored_data.document_id());
+    } else if constexpr (std::is_same_v<ScoredDataType,
+                                        JoinedScoredDocumentHit>) {
+      top_k_document_ids.insert(
+          next_scored_data.parent_scored_document_hit().document_id());
+    } else {
+      // Returns an empty set if the ScoredDataType is not
+      // JoinedScoredDocumentHit or ScoredDocumentHit.
+      return top_k_document_ids;
+    }
+    pq_copy.pop();
+  }
+  return top_k_document_ids;
+}
+
+template <typename ScoredDataType, typename Converter>
+std::unordered_set<DocumentId> PriorityQueueScoredDocumentHitsRanker<
+    ScoredDataType, Converter>::GetTopKChildDocumentIds(int k) const {
+  std::unordered_set<DocumentId> top_k_document_ids;
+  if (k <= 0) {
+    return top_k_document_ids;
+  }
+
+  if constexpr (std::is_same_v<ScoredDataType, ScoredDocumentHit>) {
+    return top_k_document_ids;
+  } else if constexpr (std::is_same_v<ScoredDataType,
+                                      JoinedScoredDocumentHit>) {
+    std::priority_queue<ScoredDataType, std::vector<ScoredDataType>, Comparator>
+        pq_copy(scored_data_pq_);
+    while (!pq_copy.empty()) {
+      const ScoredDataType& next_scored_data = pq_copy.top();
+      const std::vector<ScoredDocumentHit>& child_scored_document_hits =
+          next_scored_data.child_scored_document_hits();
+      for (int i = 0; i < k && i < child_scored_document_hits.size(); ++i) {
+        top_k_document_ids.insert(child_scored_document_hits[i].document_id());
+      }
+      pq_copy.pop();
+    }
+  } else {
+    // Returns an empty set if the ScoredDataType is not JoinedScoredDocumentHit
+    // or ScoredDocumentHit.
+    return top_k_document_ids;
+  }
+  return top_k_document_ids;
+}
+
 template <typename ScoredDataType, typename Converter>
 void PriorityQueueScoredDocumentHitsRanker<
     ScoredDataType, Converter>::TruncateHitsTo(int new_size) {
diff --git a/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc b/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc
index ace2350..19a9ebb 100644
--- a/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc
+++ b/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc
@@ -14,10 +14,12 @@
 
 #include "icing/scoring/priority-queue-scored-document-hits-ranker.h"
 
+#include <utility>
 #include <vector>
 
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/schema/section.h"
 #include "icing/scoring/scored-document-hit.h"
 #include "icing/testing/common-matchers.h"
 
@@ -30,6 +32,7 @@ using ::testing::ElementsAre;
 using ::testing::Eq;
 using ::testing::IsEmpty;
 using ::testing::SizeIs;
+using ::testing::UnorderedElementsAre;
 
 class Converter {
  public:
@@ -50,6 +53,15 @@ std::vector<JoinedScoredDocumentHit> PopAll(
   return hits;
 }
 
+std::vector<JoinedScoredDocumentHit> PopAll(
+    PriorityQueueScoredDocumentHitsRanker<JoinedScoredDocumentHit>& ranker) {
+  std::vector<JoinedScoredDocumentHit> hits;
+  while (!ranker.empty()) {
+    hits.push_back(ranker.PopNext());
+  }
+  return hits;
+}
+
 TEST(PriorityQueueScoredDocumentHitsRankerTest, ShouldGetCorrectSizeAndEmpty) {
   ScoredDocumentHit scored_hit_0(/*document_id=*/0, kSectionIdMaskNone,
                                  /*score=*/1);
@@ -171,6 +183,192 @@ TEST(PriorityQueueScoredDocumentHitsRankerTest,
   EXPECT_THAT(ranker, IsEmpty());
 }
 
+TEST(PriorityQueueScoredDocumentHitsRankerTest,
+     ScoredDocumentHitsGetTopKDocumentIds) {
+  ScoredDocumentHit scored_hit_0(/*document_id=*/0, kSectionIdMaskNone,
+                                 /*score=*/0);
+  ScoredDocumentHit scored_hit_1(/*document_id=*/1, kSectionIdMaskNone,
+                                 /*score=*/1);
+  ScoredDocumentHit scored_hit_2(/*document_id=*/2, kSectionIdMaskNone,
+                                 /*score=*/4);
+  ScoredDocumentHit scored_hit_3(/*document_id=*/3, kSectionIdMaskNone,
+                                 /*score=*/3);
+  ScoredDocumentHit scored_hit_4(/*document_id=*/4, kSectionIdMaskNone,
+                                 /*score=*/2);
+  PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit> ranker(
+      {scored_hit_0, scored_hit_1, scored_hit_2, scored_hit_3, scored_hit_4},
+      /*is_descending=*/true);
+
+  EXPECT_THAT(ranker.GetTopKDocumentIds(2), UnorderedElementsAre(2, 3));
+  EXPECT_THAT(ranker.GetTopKDocumentIds(5),
+              UnorderedElementsAre(4, 2, 3, 1, 0));
+  // k > size
+  EXPECT_THAT(ranker.GetTopKDocumentIds(10),
+              UnorderedElementsAre(4, 2, 3, 1, 0));
+  // 0 and negative values should return empty.
+  EXPECT_THAT(ranker.GetTopKDocumentIds(0), IsEmpty());
+  EXPECT_THAT(ranker.GetTopKDocumentIds(-1), IsEmpty());
+
+  // Check that the ranker is not affected by the call.
+  EXPECT_THAT(ranker, SizeIs(5));
+  std::vector<JoinedScoredDocumentHit> scored_document_hits = PopAll(ranker);
+  EXPECT_THAT(
+      scored_document_hits,
+      ElementsAre(EqualsJoinedScoredDocumentHit(converter(scored_hit_2)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_3)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_4)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_1)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_0))));
+}
+
+TEST(PriorityQueueScoredDocumentHitsRankerTest,
+     JoinedScoredDocumentHitsGetTopKDocumentIds) {
+  ScoredDocumentHit scored_hit_0(/*document_id=*/0, kSectionIdMaskNone,
+                                 /*score=*/0);
+  ScoredDocumentHit scored_hit_1(/*document_id=*/1, kSectionIdMaskNone,
+                                 /*score=*/1);
+  ScoredDocumentHit scored_hit_2(/*document_id=*/2, kSectionIdMaskNone,
+                                 /*score=*/2);
+  ScoredDocumentHit scored_hit_3(/*document_id=*/3, kSectionIdMaskNone,
+                                 /*score=*/3);
+  ScoredDocumentHit scored_hit_4(/*document_id=*/4, kSectionIdMaskNone,
+                                 /*score=*/4);
+  ScoredDocumentHit scored_hit_5(/*document_id=*/5, kSectionIdMaskNone,
+                                 /*score=*/5);
+  ScoredDocumentHit scored_hit_6(/*document_id=*/6, kSectionIdMaskNone,
+                                 /*score=*/6);
+  ScoredDocumentHit scored_hit_7(/*document_id=*/7, kSectionIdMaskNone,
+                                 /*score=*/7);
+
+  JoinedScoredDocumentHit joined_scored_hit_0(
+      /*final_score=*/3, /*parent_scored_document_hit=*/scored_hit_0,
+      /*child_scored_document_hits=*/{scored_hit_1, scored_hit_2});
+  JoinedScoredDocumentHit joined_scored_hit_1(
+      /*final_score=*/4, /*parent_scored_document_hit=*/scored_hit_3,
+      /*child_scored_document_hits=*/{scored_hit_4});
+  JoinedScoredDocumentHit joined_scored_hit_2(
+      /*final_score=*/2, /*parent_scored_document_hit=*/scored_hit_6,
+      /*child_scored_document_hits=*/{scored_hit_5});
+  JoinedScoredDocumentHit joined_scored_hit_3(
+      /*final_score=*/1, /*parent_scored_document_hit=*/scored_hit_7,
+      /*child_scored_document_hits=*/{});
+
+  PriorityQueueScoredDocumentHitsRanker<JoinedScoredDocumentHit> ranker(
+      {joined_scored_hit_0, joined_scored_hit_1, joined_scored_hit_2,
+       joined_scored_hit_3},
+      /*is_descending=*/true);
+
+  EXPECT_THAT(ranker.GetTopKDocumentIds(1), UnorderedElementsAre(3));
+  EXPECT_THAT(ranker.GetTopKDocumentIds(2), UnorderedElementsAre(3, 0));
+  // k > size
+  EXPECT_THAT(ranker.GetTopKDocumentIds(5), UnorderedElementsAre(3, 6, 0, 7));
+  // 0 and negative values should return empty.
+  EXPECT_THAT(ranker.GetTopKDocumentIds(0), IsEmpty());
+  EXPECT_THAT(ranker.GetTopKDocumentIds(-2), IsEmpty());
+
+  // Check that the ranker is not affected by the call.
+  EXPECT_THAT(ranker, SizeIs(4));
+  std::vector<JoinedScoredDocumentHit> scored_document_hits = PopAll(ranker);
+  EXPECT_THAT(scored_document_hits,
+              ElementsAre(EqualsJoinedScoredDocumentHit(joined_scored_hit_1),
+                          EqualsJoinedScoredDocumentHit(joined_scored_hit_0),
+                          EqualsJoinedScoredDocumentHit(joined_scored_hit_2),
+                          EqualsJoinedScoredDocumentHit(joined_scored_hit_3)));
+}
+
+TEST(PriorityQueueScoredDocumentHitsRankerTest,
+     ScoredDocumentHitsGetTopKChildDocumentIds_returnsEmpty) {
+  ScoredDocumentHit scored_hit_0(/*document_id=*/0, kSectionIdMaskNone,
+                                 /*score=*/0);
+  ScoredDocumentHit scored_hit_1(/*document_id=*/1, kSectionIdMaskNone,
+                                 /*score=*/1);
+  ScoredDocumentHit scored_hit_2(/*document_id=*/2, kSectionIdMaskNone,
+                                 /*score=*/4);
+  ScoredDocumentHit scored_hit_3(/*document_id=*/3, kSectionIdMaskNone,
+                                 /*score=*/3);
+  ScoredDocumentHit scored_hit_4(/*document_id=*/4, kSectionIdMaskNone,
+                                 /*score=*/2);
+  PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit> ranker(
+      {scored_hit_0, scored_hit_1, scored_hit_2, scored_hit_3, scored_hit_4},
+      /*is_descending=*/true);
+
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(2), IsEmpty());
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(5), IsEmpty());
+  // k > size
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(10), IsEmpty());
+  // 0 and negative values should return empty.
+  EXPECT_THAT(ranker.GetTopKDocumentIds(0), IsEmpty());
+  EXPECT_THAT(ranker.GetTopKDocumentIds(-1), IsEmpty());
+
+  // Check that the ranker is not affected by the call.
+  EXPECT_THAT(ranker, SizeIs(5));
+  std::vector<JoinedScoredDocumentHit> scored_document_hits = PopAll(ranker);
+  EXPECT_THAT(
+      scored_document_hits,
+      ElementsAre(EqualsJoinedScoredDocumentHit(converter(scored_hit_2)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_3)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_4)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_1)),
+                  EqualsJoinedScoredDocumentHit(converter(scored_hit_0))));
+}
+
+TEST(PriorityQueueScoredDocumentHitsRankerTest,
+     JoinedScoredDocumentHitsGetTopKChildDocumentIds) {
+  ScoredDocumentHit scored_hit_0(/*document_id=*/0, kSectionIdMaskNone,
+                                 /*score=*/0);
+  ScoredDocumentHit scored_hit_1(/*document_id=*/1, kSectionIdMaskNone,
+                                 /*score=*/1);
+  ScoredDocumentHit scored_hit_2(/*document_id=*/2, kSectionIdMaskNone,
+                                 /*score=*/2);
+  ScoredDocumentHit scored_hit_3(/*document_id=*/3, kSectionIdMaskNone,
+                                 /*score=*/3);
+  ScoredDocumentHit scored_hit_4(/*document_id=*/4, kSectionIdMaskNone,
+                                 /*score=*/4);
+  ScoredDocumentHit scored_hit_5(/*document_id=*/5, kSectionIdMaskNone,
+                                 /*score=*/5);
+  ScoredDocumentHit scored_hit_6(/*document_id=*/6, kSectionIdMaskNone,
+                                 /*score=*/6);
+  ScoredDocumentHit scored_hit_7(/*document_id=*/7, kSectionIdMaskNone,
+                                 /*score=*/7);
+
+  JoinedScoredDocumentHit joined_scored_hit_0(
+      /*final_score=*/3, /*parent_scored_document_hit=*/scored_hit_0,
+      /*child_scored_document_hits=*/{scored_hit_1, scored_hit_2});
+  JoinedScoredDocumentHit joined_scored_hit_1(
+      /*final_score=*/4, /*parent_scored_document_hit=*/scored_hit_3,
+      /*child_scored_document_hits=*/{scored_hit_4});
+  JoinedScoredDocumentHit joined_scored_hit_2(
+      /*final_score=*/2, /*parent_scored_document_hit=*/scored_hit_6,
+      /*child_scored_document_hits=*/{scored_hit_5});
+  JoinedScoredDocumentHit joined_scored_hit_3(
+      /*final_score=*/1, /*parent_scored_document_hit=*/scored_hit_7,
+      /*child_scored_document_hits=*/{});
+
+  PriorityQueueScoredDocumentHitsRanker<JoinedScoredDocumentHit> ranker(
+      {joined_scored_hit_0, joined_scored_hit_1, joined_scored_hit_2,
+       joined_scored_hit_3},
+      /*is_descending=*/true);
+
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(1), UnorderedElementsAre(1, 4, 5));
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(2),
+              UnorderedElementsAre(1, 2, 4, 5));
+  // k > size
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(5),
+              UnorderedElementsAre(1, 2, 4, 5));
+  // 0 and negative values should return empty.
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(0), IsEmpty());
+  EXPECT_THAT(ranker.GetTopKChildDocumentIds(-2), IsEmpty());
+
+  // Check that the ranker is not affected by the call.
+  EXPECT_THAT(ranker, SizeIs(4));
+  std::vector<JoinedScoredDocumentHit> scored_document_hits = PopAll(ranker);
+  EXPECT_THAT(scored_document_hits,
+              ElementsAre(EqualsJoinedScoredDocumentHit(joined_scored_hit_1),
+                          EqualsJoinedScoredDocumentHit(joined_scored_hit_0),
+                          EqualsJoinedScoredDocumentHit(joined_scored_hit_2),
+                          EqualsJoinedScoredDocumentHit(joined_scored_hit_3)));
+}
+
 TEST(PriorityQueueScoredDocumentHitsRankerTest, ShouldTruncateToNewSize) {
   ScoredDocumentHit scored_hit_0(/*document_id=*/0, kSectionIdMaskNone,
                                  /*score=*/1);
diff --git a/icing/scoring/score-and-rank_benchmark.cc b/icing/scoring/score-and-rank_benchmark.cc
index 57c02ef..c8f6c00 100644
--- a/icing/scoring/score-and-rank_benchmark.cc
+++ b/icing/scoring/score-and-rank_benchmark.cc
@@ -133,9 +133,9 @@ void BM_ScoreAndRankDocumentHitsByDocumentScore(benchmark::State& state) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK(schema_store->SetSchema(
-      CreateSchemaWithEmailType(), /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+  ICING_ASSERT_OK(
+      schema_store->SetSchema(CreateSchemaWithEmailType(),
+                              /*ignore_errors_and_delete_documents=*/false));
 
   ScoringSpecProto scoring_spec;
   scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::DOCUMENT_SCORE);
@@ -244,9 +244,9 @@ void BM_ScoreAndRankDocumentHitsByCreationTime(benchmark::State& state) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK(schema_store->SetSchema(
-      CreateSchemaWithEmailType(), /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+  ICING_ASSERT_OK(
+      schema_store->SetSchema(CreateSchemaWithEmailType(),
+                              /*ignore_errors_and_delete_documents=*/false));
 
   ScoringSpecProto scoring_spec;
   scoring_spec.set_rank_by(
@@ -358,9 +358,9 @@ void BM_ScoreAndRankDocumentHitsNoScoring(benchmark::State& state) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK(schema_store->SetSchema(
-      CreateSchemaWithEmailType(), /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+  ICING_ASSERT_OK(
+      schema_store->SetSchema(CreateSchemaWithEmailType(),
+                              /*ignore_errors_and_delete_documents=*/false));
 
   ScoringSpecProto scoring_spec;
   scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::NONE);
@@ -466,9 +466,9 @@ void BM_ScoreAndRankDocumentHitsByRelevanceScoring(benchmark::State& state) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK(schema_store->SetSchema(
-      CreateSchemaWithEmailType(), /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+  ICING_ASSERT_OK(
+      schema_store->SetSchema(CreateSchemaWithEmailType(),
+                              /*ignore_errors_and_delete_documents=*/false));
 
   ScoringSpecProto scoring_spec;
   scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::RELEVANCE_SCORE);
diff --git a/icing/scoring/scored-document-hits-ranker.h b/icing/scoring/scored-document-hits-ranker.h
index 9b76ce7..2a7956d 100644
--- a/icing/scoring/scored-document-hits-ranker.h
+++ b/icing/scoring/scored-document-hits-ranker.h
@@ -15,7 +15,10 @@
 #ifndef ICING_SCORING_SCORED_DOCUMENT_HITS_RANKER_H_
 #define ICING_SCORING_SCORED_DOCUMENT_HITS_RANKER_H_
 
+#include <unordered_set>
+
 #include "icing/scoring/scored-document-hit.h"
+#include "icing/store/document-id.h"
 
 namespace icing {
 namespace lib {
@@ -51,6 +54,19 @@ class ScoredDocumentHitsRanker {
   // the remaining ScoredDocumentHits to the given size.
   virtual void TruncateHitsTo(int new_size) = 0;
 
+  // Returns DocumentIds of the top K documents according to the ranking policy.
+  // - For ScoredDocumentHit, this returns the DocumentIds of the top K
+  //   documents.
+  // - For JoinedScoredDocumentHit, this returns the DocumentIds of the top K
+  //   parent documents.
+  virtual std::unordered_set<DocumentId> GetTopKDocumentIds(int k) const = 0;
+
+  // Returns DocumentIds of the top K child documents for each
+  // JoinedScoredDocumentHit.
+  // - For ScoredDocumentHit, this returns an empty set.
+  virtual std::unordered_set<DocumentId> GetTopKChildDocumentIds(
+      int k) const = 0;
+
   virtual int size() const = 0;
 
   virtual bool empty() const = 0;
diff --git a/icing/scoring/scorer_test.cc b/icing/scoring/scorer_test.cc
index a027a94..98ca18e 100644
--- a/icing/scoring/scorer_test.cc
+++ b/icing/scoring/scorer_test.cc
@@ -94,8 +94,7 @@ class ScorerTest : public ::testing::TestWithParam<ScorerTestingMode> {
             .Build();
 
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        test_email_schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        test_email_schema, /*ignore_errors_and_delete_documents=*/false));
   }
 
   void TearDown() override {
diff --git a/icing/scoring/scoring-processor_test.cc b/icing/scoring/scoring-processor_test.cc
index 7949cdf..f2dc84b 100644
--- a/icing/scoring/scoring-processor_test.cc
+++ b/icing/scoring/scoring-processor_test.cc
@@ -115,8 +115,7 @@ class ScoringProcessorTest
                                  .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        test_email_schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        test_email_schema, /*ignore_errors_and_delete_documents=*/false));
   }
 
   void TearDown() override {
diff --git a/icing/scoring/section-weights_test.cc b/icing/scoring/section-weights_test.cc
index c90ca4a..e7d2d92 100644
--- a/icing/scoring/section-weights_test.cc
+++ b/icing/scoring/section-weights_test.cc
@@ -94,8 +94,7 @@ class SectionWeightsTest : public testing::Test {
         SchemaBuilder().AddType(sender_schema).AddType(email_schema).Build();
 
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
   }
 
   void TearDown() override {
diff --git a/icing/store/blob-store.cc b/icing/store/blob-store.cc
index cb26761..eb3b686 100644
--- a/icing/store/blob-store.cc
+++ b/icing/store/blob-store.cc
@@ -18,7 +18,6 @@
 
 #include <algorithm>
 #include <array>
-#include <cerrno>
 #include <cstdint>
 #include <iterator>
 #include <limits>
@@ -44,6 +43,7 @@
 #include "icing/util/logging.h"
 #include "icing/util/sha256.h"
 #include "icing/util/status-macros.h"
+#include "icing/util/status-util.h"
 
 namespace icing {
 namespace lib {
@@ -56,6 +56,8 @@ static constexpr int32_t kReadBufferSize = 8192;
 
 namespace {
 
+using ::icing::lib::status_util::TransformStatus;
+
 std::string MakeBlobInfoProtoLogFileName(const std::string& base_dir) {
   return absl_ports::StrCat(base_dir, "/", kBlobInfoProtoLogFileName);
 }
@@ -64,7 +66,7 @@ std::string MakeBlobFileDir(const std::string& base_dir) {
   return absl_ports::StrCat(base_dir, "/", kBlobFileDir);
 }
 
-std::string MakeBlobFileName(const std::string& base_dir,
+std::string MakeBlobFilePath(const std::string& base_dir,
                              int64_t creation_time_ms) {
   return absl_ports::StrCat(MakeBlobFileDir(base_dir), "/",
                             std::to_string(creation_time_ms));
@@ -108,6 +110,26 @@ LoadBlobHandleToOffsetMapper(
   return blob_handle_to_offset;
 }
 
+BlobProto CreateBlobProtoFromError(const libtextclassifier3::Status& status) {
+  BlobProto blob_proto;
+  TransformStatus(status, blob_proto.mutable_status());
+  return blob_proto;
+}
+
+BlobProto CreateBlobProtoFromFilename(std::string filename) {
+  BlobProto blob_proto;
+  blob_proto.mutable_status()->set_code(StatusProto::OK);
+  blob_proto.set_file_name(std::move(filename));
+  return blob_proto;
+}
+
+BlobProto CreateBlobProtoFromFileDescriptor(int file_descriptor) {
+  BlobProto blob_proto;
+  blob_proto.mutable_status()->set_code(StatusProto::OK);
+  blob_proto.set_file_descriptor(file_descriptor);
+  return blob_proto;
+}
+
 }  // namespace
 
 /* static */ std::string BlobStore::BuildBlobHandleStr(
@@ -118,7 +140,8 @@ LoadBlobHandleToOffsetMapper(
 
 libtextclassifier3::StatusOr<BlobStore> BlobStore::Create(
     const Filesystem* filesystem, std::string base_dir, const Clock* clock,
-    int64_t orphan_blob_time_to_live_ms, int32_t compression_level) {
+    int64_t orphan_blob_time_to_live_ms, int32_t compression_level,
+    bool manage_blob_files) {
   ICING_RETURN_ERROR_IF_NULL(filesystem);
   ICING_RETURN_ERROR_IF_NULL(clock);
 
@@ -158,73 +181,97 @@ libtextclassifier3::StatusOr<BlobStore> BlobStore::Create(
       blob_handle_to_offset,
       LoadBlobHandleToOffsetMapper(log_create_result.proto_log.get()));
 
-  return BlobStore(
-      filesystem, std::move(base_dir), clock, orphan_blob_time_to_live_ms,
-      compression_level, std::move(log_create_result.proto_log),
-      std::move(blob_handle_to_offset), std::move(known_file_names));
+  return BlobStore(filesystem, std::move(base_dir), clock,
+                   orphan_blob_time_to_live_ms, compression_level,
+                   manage_blob_files, std::move(log_create_result.proto_log),
+                   std::move(blob_handle_to_offset),
+                   std::move(known_file_names));
 }
 
-libtextclassifier3::StatusOr<int> BlobStore::OpenWrite(
+BlobProto BlobStore::OpenWrite(
     const PropertyProto::BlobHandleProto& blob_handle) {
-  ICING_RETURN_IF_ERROR(ValidateBlobHandle(blob_handle));
+  ICING_RETURN_EXPRESSION_IF_ERROR(ValidateBlobHandle(blob_handle),
+                                   CreateBlobProtoFromError(_));
   std::string blob_handle_str = BuildBlobHandleStr(blob_handle);
 
   auto blob_info_itr = blob_handle_to_offset_.find(blob_handle_str);
   if (blob_info_itr != blob_handle_to_offset_.end()) {
     ICING_ASSIGN_OR_RETURN(BlobInfoProto blob_info,
-                           blob_info_log_->ReadProto(blob_info_itr->second));
+                           blob_info_log_->ReadProto(blob_info_itr->second),
+                           CreateBlobProtoFromError(_));
     if (blob_info.is_committed()) {
       // The blob is already committed, return error.
-      return absl_ports::AlreadyExistsError(absl_ports::StrCat(
-          "Rewriting the committed blob is not allowed for blob handle: ",
-          blob_handle.digest()));
+      return CreateBlobProtoFromError(
+          absl_ports::AlreadyExistsError(absl_ports::StrCat(
+              "Rewriting the committed blob is not allowed for blob handle: ",
+              blob_handle.digest())));
     }
   }
 
   // Create a new blob info and blob file.
   ICING_ASSIGN_OR_RETURN(BlobInfoProto blob_info,
-                         GetOrCreateBlobInfo(blob_handle_str, blob_handle));
+                         GetOrCreateBlobInfo(blob_handle_str, blob_handle),
+                         CreateBlobProtoFromError(_));
+
+  if (!manage_blob_files_) {
+    return CreateBlobProtoFromFilename(
+        std::to_string(blob_info.creation_time_ms()));
+  }
 
-  std::string file_name =
-      MakeBlobFileName(base_dir_, blob_info.creation_time_ms());
-  int file_descriptor = filesystem_.OpenForWrite(file_name.c_str());
+  std::string file_path =
+      MakeBlobFilePath(base_dir_, blob_info.creation_time_ms());
+  int file_descriptor = filesystem_.OpenForWrite(file_path.c_str());
   if (file_descriptor < 0) {
-    return absl_ports::InternalError(absl_ports::StrCat(
-        "Failed to open blob file for handle: ", blob_handle.digest()));
+    return CreateBlobProtoFromError(
+        absl_ports::InternalError(absl_ports::StrCat(
+            "Failed to open blob file for handle: ", blob_handle.digest())));
   }
-  return file_descriptor;
+  return CreateBlobProtoFromFileDescriptor(file_descriptor);
 }
 
-libtextclassifier3::Status BlobStore::RemoveBlob(
+BlobProto BlobStore::RemoveBlob(
     const PropertyProto::BlobHandleProto& blob_handle) {
-  ICING_RETURN_IF_ERROR(ValidateBlobHandle(blob_handle));
+  ICING_RETURN_EXPRESSION_IF_ERROR(ValidateBlobHandle(blob_handle),
+                                   CreateBlobProtoFromError(_));
   std::string blob_handle_str = BuildBlobHandleStr(blob_handle);
 
   auto blob_info_itr = blob_handle_to_offset_.find(blob_handle_str);
   if (blob_info_itr == blob_handle_to_offset_.end()) {
-    return absl_ports::NotFoundError(absl_ports::StrCat(
-        "Cannot find the blob for handle: ", blob_handle.digest()));
+    return CreateBlobProtoFromError(
+        absl_ports::NotFoundError(absl_ports::StrCat(
+            "Cannot find the blob for handle: ", blob_handle.digest())));
   }
 
   int64_t blob_info_offset = blob_info_itr->second;
   ICING_ASSIGN_OR_RETURN(BlobInfoProto blob_info,
-                         blob_info_log_->ReadProto(blob_info_offset));
+                         blob_info_log_->ReadProto(blob_info_offset),
+                         CreateBlobProtoFromError(_));
 
-  std::string file_name =
-      MakeBlobFileName(base_dir_, blob_info.creation_time_ms());
-  if (!filesystem_.DeleteFile(file_name.c_str())) {
-    return absl_ports::InternalError(absl_ports::StrCat(
-        "Failed to abandon blob file for handle: ", blob_handle.digest()));
-  }
-  ICING_RETURN_IF_ERROR(blob_info_log_->EraseProto(blob_info_offset));
+  ICING_RETURN_EXPRESSION_IF_ERROR(blob_info_log_->EraseProto(blob_info_offset),
+                                   CreateBlobProtoFromError(_));
   blob_handle_to_offset_.erase(blob_info_itr);
-
   has_mutated_ = true;
-  return libtextclassifier3::Status::OK;
+
+  if (!manage_blob_files_) {
+    return CreateBlobProtoFromFilename(
+        std::to_string(blob_info.creation_time_ms()));
+  }
+
+  std::string file_path =
+      MakeBlobFilePath(base_dir_, blob_info.creation_time_ms());
+  if (!filesystem_.DeleteFile(file_path.c_str())) {
+    return CreateBlobProtoFromError(
+        absl_ports::InternalError(absl_ports::StrCat(
+            "Failed to abandon blob file for handle: ", blob_handle.digest())));
+  }
+
+  BlobProto blob_proto;
+  blob_proto.mutable_status()->set_code(StatusProto::OK);
+  return blob_proto;
 }
 
-libtextclassifier3::StatusOr<int> BlobStore::OpenRead(
-    const PropertyProto::BlobHandleProto& blob_handle) {
+libtextclassifier3::StatusOr<BlobInfoProto> BlobStore::GetBlobInfo(
+    const PropertyProto::BlobHandleProto& blob_handle) const {
   ICING_RETURN_IF_ERROR(ValidateBlobHandle(blob_handle));
   std::string blob_handle_str = BuildBlobHandleStr(blob_handle);
   auto itr = blob_handle_to_offset_.find(blob_handle_str);
@@ -232,25 +279,37 @@ libtextclassifier3::StatusOr<int> BlobStore::OpenRead(
     return absl_ports::NotFoundError(absl_ports::StrCat(
         "Cannot find the blob for handle: ", blob_handle.digest()));
   }
-  ICING_ASSIGN_OR_RETURN(BlobInfoProto blob_info,
-                         blob_info_log_->ReadProto(itr->second));
+  return blob_info_log_->ReadProto(itr->second);
+}
+
+BlobProto BlobStore::OpenRead(
+    const PropertyProto::BlobHandleProto& blob_handle) const {
+  ICING_ASSIGN_OR_RETURN(BlobInfoProto blob_info, GetBlobInfo(blob_handle),
+                         CreateBlobProtoFromError(_));
   if (!blob_info.is_committed()) {
     // The blob is not committed, return error.
-    return absl_ports::NotFoundError(absl_ports::StrCat(
-        "Cannot find the blob for handle: ", blob_handle.digest()));
+    return CreateBlobProtoFromError(
+        absl_ports::NotFoundError(absl_ports::StrCat(
+            "Cannot find the blob for handle: ", blob_handle.digest())));
+  }
+
+  if (!manage_blob_files_) {
+    return CreateBlobProtoFromFilename(
+        std::to_string(blob_info.creation_time_ms()));
   }
 
-  std::string file_name =
-      MakeBlobFileName(base_dir_, blob_info.creation_time_ms());
-  int file_descriptor = filesystem_.OpenForRead(file_name.c_str());
+  std::string file_path =
+      MakeBlobFilePath(base_dir_, blob_info.creation_time_ms());
+  int file_descriptor = filesystem_.OpenForRead(file_path.c_str());
   if (file_descriptor < 0) {
-    return absl_ports::InternalError(absl_ports::StrCat(
-        "Failed to open blob file for handle: ", blob_handle.digest()));
+    return CreateBlobProtoFromError(
+        absl_ports::InternalError(absl_ports::StrCat(
+            "Failed to open blob file for handle: ", blob_handle.digest())));
   }
-  return file_descriptor;
+  return CreateBlobProtoFromFileDescriptor(file_descriptor);
 }
 
-libtextclassifier3::Status BlobStore::CommitBlob(
+libtextclassifier3::Status BlobStore::CommitBlobMetadata(
     const PropertyProto::BlobHandleProto& blob_handle) {
   ICING_RETURN_IF_ERROR(ValidateBlobHandle(blob_handle));
 
@@ -272,22 +331,50 @@ libtextclassifier3::Status BlobStore::CommitBlob(
         "The blob is already committed for handle: ", blob_handle.digest()));
   }
 
-  // Read the file and verify the digest.
+  // Update the blob info proto to committed.
+  ICING_RETURN_IF_ERROR(blob_info_log_->EraseProto(pending_blob_info_offset));
+  has_mutated_ = true;
+  blob_info_proto.set_is_committed(true);
+  auto blob_info_offset_or = blob_info_log_->WriteProto(blob_info_proto);
+  if (!blob_info_offset_or.ok()) {
+    ICING_LOG(ERROR) << blob_info_offset_or.status().error_message()
+                     << "Failed to write blob info";
+    return blob_info_offset_or.status();
+  }
+  blob_handle_to_offset_[blob_handle_str] = blob_info_offset_or.ValueOrDie();
+  return libtextclassifier3::Status::OK;
+}
+
+BlobProto BlobStore::CommitBlob(
+    const PropertyProto::BlobHandleProto& blob_handle) {
+  BlobProto blob_proto;
+  blob_proto.mutable_status()->set_code(StatusProto::OK);
+
+  if (!manage_blob_files_) {
+    ICING_RETURN_EXPRESSION_IF_ERROR(CommitBlobMetadata(blob_handle),
+                                     CreateBlobProtoFromError(_))
+    return blob_proto;
+  }
 
-  std::string file_name =
-      MakeBlobFileName(base_dir_, blob_info_proto.creation_time_ms());
+  ICING_ASSIGN_OR_RETURN(BlobInfoProto blob_info, GetBlobInfo(blob_handle),
+                         CreateBlobProtoFromError(_));
+  std::string file_path =
+      MakeBlobFilePath(base_dir_, blob_info.creation_time_ms());
+  // Read the file and verify the digest.
   Sha256 sha256;
   {
-    ScopedFd sfd(filesystem_.OpenForRead(file_name.c_str()));
+    ScopedFd sfd(filesystem_.OpenForRead(file_path.c_str()));
     if (!sfd.is_valid()) {
-      return absl_ports::InternalError(absl_ports::StrCat(
-          "Failed to open blob file for handle: ", blob_handle.digest()));
+      return CreateBlobProtoFromError(
+          absl_ports::InternalError(absl_ports::StrCat(
+              "Failed to open blob file for handle: ", blob_handle.digest())));
     }
 
     int64_t file_size = filesystem_.GetFileSize(sfd.get());
     if (file_size == Filesystem::kBadFileSize) {
-      return absl_ports::InternalError(absl_ports::StrCat(
-          "Failed to get file size for handle: ", blob_handle.digest()));
+      return CreateBlobProtoFromError(
+          absl_ports::InternalError(absl_ports::StrCat(
+              "Failed to get file size for handle: ", blob_handle.digest())));
     }
 
     // Read 8 KiB per iteration
@@ -297,8 +384,9 @@ libtextclassifier3::Status BlobStore::CommitBlob(
       int32_t size_to_read =
           std::min<int32_t>(kReadBufferSize, file_size - prev_total_read_size);
       if (!filesystem_.Read(sfd.get(), buffer, size_to_read)) {
-        return absl_ports::InternalError(absl_ports::StrCat(
-            "Failed to read blob file for handle: ", blob_handle.digest()));
+        return CreateBlobProtoFromError(absl_ports::InternalError(
+            absl_ports::StrCat("Failed to read blob file for handle: ",
+                               blob_handle.digest())));
       }
 
       sha256.Update(buffer, size_to_read);
@@ -309,37 +397,22 @@ libtextclassifier3::Status BlobStore::CommitBlob(
   std::array<uint8_t, 32> hash = std::move(sha256).Finalize();
   const std::string& digest = blob_handle.digest();
 
-  // Close active file descriptor and cached pending blob info for the pending
-  // blob handle before we verify the digest. This is needed anyway. We will add
-  // cached pending blob info back if the digest is valid.
-
-  ICING_RETURN_IF_ERROR(blob_info_log_->EraseProto(pending_blob_info_offset));
-
   if (digest.length() != hash.size() ||
       digest.compare(0, digest.length(),
                      reinterpret_cast<const char*>(hash.data()),
                      hash.size()) != 0) {
     // The blob content doesn't match to the digest. Delete this corrupted blob.
-    if (!filesystem_.DeleteFile(file_name.c_str())) {
-      return absl_ports::InternalError(absl_ports::StrCat(
-          "Failed to delete corrupted blob file for handle: ",
-          blob_handle.digest()));
+    BlobProto remove_blob_result = RemoveBlob(blob_handle);
+    if (remove_blob_result.status().code() != StatusProto::OK) {
+      return remove_blob_result;
     }
-    return absl_ports::InvalidArgumentError(
-        "The blob content doesn't match to the digest.");
-  }
-
-  has_mutated_ = true;
-  blob_info_proto.set_is_committed(true);
-  auto blob_info_offset_or = blob_info_log_->WriteProto(blob_info_proto);
-  if (!blob_info_offset_or.ok()) {
-    ICING_LOG(ERROR) << blob_info_offset_or.status().error_message()
-                     << "Failed to write blob info";
-    return blob_info_offset_or.status();
+    return CreateBlobProtoFromError(absl_ports::InvalidArgumentError(
+        "The blob content doesn't match to the digest."));
   }
-  blob_handle_to_offset_[blob_handle_str] = blob_info_offset_or.ValueOrDie();
-
-  return libtextclassifier3::Status::OK;
+  // Mark the blob as committed.
+  ICING_RETURN_EXPRESSION_IF_ERROR(CommitBlobMetadata(blob_handle),
+                                   CreateBlobProtoFromError(_));
+  return blob_proto;
 }
 
 libtextclassifier3::Status BlobStore::PersistToDisk() {
@@ -387,7 +460,7 @@ libtextclassifier3::StatusOr<BlobInfoProto> BlobStore::GetOrCreateBlobInfo(
 }
 
 std::unordered_set<std::string>
-BlobStore::GetPotentiallyOptimizableBlobHandles() {
+BlobStore::GetPotentiallyOptimizableBlobHandles() const {
   int64_t current_time_ms = clock_.GetSystemTimeMilliseconds();
   if (orphan_blob_time_to_live_ms_ > current_time_ms) {
     // Nothing to optimize, return empty set.
@@ -410,8 +483,11 @@ BlobStore::GetPotentiallyOptimizableBlobHandles() {
   return expired_blob_handles;
 }
 
-libtextclassifier3::Status BlobStore::Optimize(
+libtextclassifier3::StatusOr<std::vector<std::string>> BlobStore::Optimize(
     const std::unordered_set<std::string>& dead_blob_handles) {
+  std::vector<std::string> blob_file_names_to_remove;
+  blob_file_names_to_remove.reserve(dead_blob_handles.size());
+
   // Create the temp blob info log file.
   std::string temp_blob_info_proto_file_name =
       absl_ports::StrCat(MakeBlobInfoProtoLogFileName(base_dir_), "_temp");
@@ -449,11 +525,16 @@ libtextclassifier3::Status BlobStore::Optimize(
     if (dead_blob_handles.find(blob_handle_str) != dead_blob_handles.end()) {
       // Delete all dead blob files.
 
-      std::string file_name =
-          MakeBlobFileName(base_dir_, blob_info_proto.creation_time_ms());
-      if (!filesystem_.DeleteFile(file_name.c_str())) {
-        return absl_ports::InternalError(
-            absl_ports::StrCat("Failed to delete blob file: ", file_name));
+      if (manage_blob_files_) {
+        std::string file_path =
+            MakeBlobFilePath(base_dir_, blob_info_proto.creation_time_ms());
+        if (!filesystem_.DeleteFile(file_path.c_str())) {
+          return absl_ports::InternalError(
+              absl_ports::StrCat("Failed to delete blob file: ", file_path));
+        }
+      } else {
+        blob_file_names_to_remove.push_back(
+            std::to_string(blob_info_proto.creation_time_ms()));
       }
     } else {
       // Write the alive blob info to the new blob info log file.
@@ -487,7 +568,7 @@ libtextclassifier3::Status BlobStore::Optimize(
               compression_level_)));
   blob_info_log_ = std::move(log_create_result.proto_log);
   blob_handle_to_offset_ = std::move(new_blob_handle_to_offset);
-  return libtextclassifier3::Status::OK;
+  return blob_file_names_to_remove;
 }
 
 libtextclassifier3::StatusOr<std::vector<NamespaceBlobStorageInfoProto>>
@@ -509,23 +590,27 @@ BlobStore::GetStorageInfo() const {
     }
     BlobInfoProto blob_info_proto = std::move(blob_info_proto_or).ValueOrDie();
 
-    std::string file_name =
-        MakeBlobFileName(base_dir_, blob_info_proto.creation_time_ms());
-    int64_t file_size = filesystem_.GetFileSize(file_name.c_str());
-    if (file_size == Filesystem::kBadFileSize) {
-      ICING_LOG(WARNING) << "Bad file size for blob file: " << file_name;
-      continue;
-    }
+    std::string file_path =
+        MakeBlobFilePath(base_dir_, blob_info_proto.creation_time_ms());
     std::string name_space = blob_info_proto.blob_handle().namespace_();
-    NamespaceBlobStorageInfoProto namespace_blob_storage_info =
+    NamespaceBlobStorageInfoProto& namespace_blob_storage_info =
         namespace_to_storage_info[name_space];
     namespace_blob_storage_info.set_namespace_(name_space);
-    namespace_blob_storage_info.set_blob_size(
-        namespace_blob_storage_info.blob_size() + file_size);
-    namespace_blob_storage_info.set_num_blobs(
-        namespace_blob_storage_info.num_blobs() + 1);
-    namespace_to_storage_info[name_space] =
-        std::move(namespace_blob_storage_info);
+
+    if (manage_blob_files_) {
+      int64_t file_size = filesystem_.GetFileSize(file_path.c_str());
+      if (file_size == Filesystem::kBadFileSize) {
+        ICING_LOG(WARNING) << "Bad file size for blob file: " << file_path;
+        continue;
+      }
+      namespace_blob_storage_info.set_blob_size(
+          namespace_blob_storage_info.blob_size() + file_size);
+      namespace_blob_storage_info.set_num_blobs(
+          namespace_blob_storage_info.num_blobs() + 1);
+    } else {
+      namespace_blob_storage_info.add_blob_file_names(
+          std::to_string(blob_info_proto.creation_time_ms()));
+    }
   }
 
   // Create the namespace blob storage info for each namespace.
diff --git a/icing/store/blob-store.h b/icing/store/blob-store.h
index fb1a773..77814a3 100644
--- a/icing/store/blob-store.h
+++ b/icing/store/blob-store.h
@@ -16,10 +16,12 @@
 #define ICING_STORE_BLOB_STORE_H_
 
 #include <cstdint>
+#include <memory>
 #include <string>
 #include <unordered_map>
 #include <unordered_set>
 #include <utility>
+#include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
@@ -65,62 +67,80 @@ class BlobStore {
   //   INTERNAL_ERROR on I/O error
   static libtextclassifier3::StatusOr<BlobStore> Create(
       const Filesystem* filesystem, std::string base_dir, const Clock* clock,
-      int64_t orphan_blob_time_to_live_ms, int32_t compression_level);
+      int64_t orphan_blob_time_to_live_ms, int32_t compression_level,
+      bool manage_blob_files);
 
   // Gets or creates a file for write only purpose for the given blob handle.
   // To mark the blob is completed written, CommitBlob must be called. Once
   // CommitBlob is called, the blob is sealed and rewrite is not allowed.
   //
-  // It is the user's responsibility to close the file descriptor after writing
-  // is done and should operate on the file descriptor after commit or remove
-  // it.
+  // If Icing does not manage blob files, this method only creates necessary
+  // metadata for the blob but does not open or manage the file descriptor. The
+  // caller is responsible for opening, writing to, and closing the file using
+  // the returned file name.
+  //
+  // Otherwise, a file descriptor is returned, and it is the user's
+  // responsibility to close the file descriptor after writing is done and
+  // should not operate on the file descriptor after commit or remove it.
   //
   // Returns:
-  //   File descriptor (writable) on success
-  //   INVALID_ARGUMENT_ERROR on invalid blob handle
-  //   FAILED_PRECONDITION_ERROR on blob is already opened for write
-  //   ALREADY_EXISTS_ERROR if the blob has already been committed
-  //   INTERNAL_ERROR on IO error
-  libtextclassifier3::StatusOr<int> OpenWrite(
-      const PropertyProto::BlobHandleProto& blob_handle);
+  //   OK with results on success
+  //   InvalidArgumentError on invalid blob handle
+  //   FailedPreconditionError if the blob is already opened for write
+  //   AlreadyExistsError if the blob is already committed
+  //   InternalError on IO error
+  BlobProto OpenWrite(const PropertyProto::BlobHandleProto& blob_handle);
 
   // Removes a blob file and blob handle from the blob store.
   //
   // This will remove the blob on any state. No matter it's committed or not or
   // it has reference document links or not.
   //
+  // If Icing does not manage blob files, this method only removes the metadata
+  // entry from the blob store, but does not delete the actual blob file. The
+  // caller is responsible for deleting the blob file.
+  //
   // Returns:
-  //   INVALID_ARGUMENT_ERROR on invalid blob handle
-  //   NOT_FOUND_ERROR on blob is not found
-  //   INTERNAL_ERROR on IO error
-  libtextclassifier3::Status RemoveBlob(
-      const PropertyProto::BlobHandleProto& blob_handle);
+  //   OK with results on success
+  //   InvalidArgumentError on invalid blob handle
+  //   NotFoundError if the blob is not found
+  //   InternalError on IO error
+  BlobProto RemoveBlob(const PropertyProto::BlobHandleProto& blob_handle);
 
   // Gets a file for read only purpose for the given blob handle.
-  // Will only succeed for blobs that were committed by calling CommitBlob.
+  // The blob must be committed by calling CommitBlob otherwise it is not
+  // accessible.
   //
-  // It is the user's responsibility to close the file descriptor after reading.
+  // If Icing does not manage blob files, this method only returns the file name
+  // associated with the blob but does not open or manage the file descriptor.
+  // The caller is responsible for opening, reading from, and closing the file
+  // using the returned file name.
+  //
+  // Otherwise, a file descriptor is returned, and it is the user's
+  // responsibility to close the file descriptor after reading.
   //
   // Returns:
-  //   File descriptor (read only) on success
-  //   INVALID_ARGUMENT_ERROR on invalid blob handle
-  //   NOT_FOUND_ERROR on blob is not found or is not committed
-  libtextclassifier3::StatusOr<int> OpenRead(
-      const PropertyProto::BlobHandleProto& blob_handle);
-
-  // Commits the given blob, if the blob is finished wrote via OpenWrite.
-  // Before the blob is committed, it is not visible to any reader via OpenRead.
-  // After the blob is committed, it is not allowed to rewrite or update the
-  // content.
+  //   OK with results on success
+  //   InvalidArgumentError on invalid blob handle
+  //   NotFoundError if the blob is not found or is not committed
+  BlobProto OpenRead(const PropertyProto::BlobHandleProto& blob_handle) const;
+
+  // Commits the given blob when writing of the blob via OpenWrite is complete.
+  // Before the blob is committed, it is not visible to any reader
+  // via OpenRead. After the blob is committed, it is not allowed to rewrite or
+  // update the content.
+  //
+  // If Icing does not manage blob files, this method marks the blob as
+  // committed in the metadata store. The caller is responsible for verifying
+  // the digest of the blob file.
   //
   // Returns:
-  //   OK on the blob is successfully committed.
-  //   ALREADY_EXISTS_ERROR on the blob is already committed, this is no op.
-  //   INVALID_ARGUMENT_ERROR on invalid blob handle or digest is mismatch with
-  //                        file content.
-  //   NOT_FOUND_ERROR on blob is not found.
-  libtextclassifier3::Status CommitBlob(
-      const PropertyProto::BlobHandleProto& blob_handle);
+  //   OK on success
+  //   AlreadyExistsError if the blob is already committed
+  //   InvalidArgumentError on invalid blob handle or if the digest is mismatch
+  //     with file content
+  //   NotFoundError if the blob is not found
+  BlobProto CommitBlob(const PropertyProto::BlobHandleProto& blob_handle);
 
   // Persists the blobs to disk.
   libtextclassifier3::Status PersistToDisk();
@@ -130,7 +150,7 @@ class BlobStore {
   // A blob will be consider as a potentially optimizable blob if it created
   // before the orphan_blob_time_to_live_ms. And the blob should be removed if
   // it has no reference document links to it.
-  std::unordered_set<std::string> GetPotentiallyOptimizableBlobHandles();
+  std::unordered_set<std::string> GetPotentiallyOptimizableBlobHandles() const;
 
   // Optimize the blob store and remove dead blob files.
   //
@@ -140,9 +160,10 @@ class BlobStore {
   //  2: It's mature.
   //
   // Returns:
-  //   OK on success
+  //   The list of expired blob file names to be removed on success. If Icing
+  //   manages blob files, this list will be empty.
   //   INTERNAL_ERROR on IO error
-  libtextclassifier3::Status Optimize(
+  libtextclassifier3::StatusOr<std::vector<std::string>> Optimize(
       const std::unordered_set<std::string>& dead_blob_handles);
 
   // Calculates the StorageInfo for the Blob Store.
@@ -153,10 +174,11 @@ class BlobStore {
   libtextclassifier3::StatusOr<std::vector<NamespaceBlobStorageInfoProto>>
   GetStorageInfo() const;
 
-private:
+ private:
   explicit BlobStore(
       const Filesystem* filesystem, std::string base_dir, const Clock* clock,
       int64_t orphan_blob_time_to_live_ms, int32_t compression_level,
+      bool manage_blob_files,
       std::unique_ptr<PortableFileBackedProtoLog<BlobInfoProto>> blob_info_log,
       std::unordered_map<std::string, int32_t> blob_handle_to_offset,
       std::unordered_set<std::string> known_file_names)
@@ -165,19 +187,27 @@ private:
         clock_(*clock),
         orphan_blob_time_to_live_ms_(orphan_blob_time_to_live_ms),
         compression_level_(compression_level),
+        manage_blob_files_(manage_blob_files),
         blob_info_log_(std::move(blob_info_log)),
         blob_handle_to_offset_(std::move(blob_handle_to_offset)),
         known_file_names_(std::move(known_file_names)) {}
 
+  libtextclassifier3::StatusOr<BlobInfoProto> GetBlobInfo(
+      const PropertyProto::BlobHandleProto& blob_handle) const;
+
   libtextclassifier3::StatusOr<BlobInfoProto> GetOrCreateBlobInfo(
       const std::string& blob_handle_str,
       const PropertyProto::BlobHandleProto& blob_handle);
 
+  libtextclassifier3::Status CommitBlobMetadata(
+      const PropertyProto::BlobHandleProto& blob_handle);
+
   const Filesystem& filesystem_;
   std::string base_dir_;
   const Clock& clock_;
   int64_t orphan_blob_time_to_live_ms_;
   int32_t compression_level_;
+  bool manage_blob_files_;
 
   // The ground truth blob info log file, which is used to read/write/erase
   // BlobInfoProto.
diff --git a/icing/store/document-store.cc b/icing/store/document-store.cc
index 449b005..87a3fa7 100644
--- a/icing/store/document-store.cc
+++ b/icing/store/document-store.cc
@@ -1243,7 +1243,6 @@ DocumentStore::InternalPut(DocumentProto&& document,
     // The old document exists, copy over the usage scores and delete the old
     // document.
     DocumentId old_document_id = old_document_id_or.ValueOrDie();
-    put_result.old_document_id = old_document_id;
 
     ICING_RETURN_IF_ERROR(
         usage_store_->CloneUsageScores(/*from_document_id=*/old_document_id,
@@ -1253,7 +1252,11 @@ DocumentStore::InternalPut(DocumentProto&& document,
     // been deleted previously.
     auto delete_status =
         Delete(old_document_id, clock_.GetSystemTimeMilliseconds());
-    if (!delete_status.ok() && !absl_ports::IsNotFound(delete_status)) {
+    if (delete_status.ok()) {
+      // The old document had existed and was not previously deleted. Return its
+      // document id to mark it as a replacement.
+      put_result.old_document_id = old_document_id;
+    } else if (!absl_ports::IsNotFound(delete_status)) {
       // Real error, pass it up.
       return delete_status;
     }
@@ -1469,9 +1472,8 @@ DocumentStore::GetNonDeletedDocumentFilterData(DocumentId document_id) const {
   if (!filter_data_or.ok()) {
     // This would only happen if document_id is out of range of the
     // filter_cache, meaning we got some invalid document_id. Callers should
-    // already have checked that their document_id is valid or used
-    // DoesDocumentExist(WithStatus). Regardless, return std::nullopt since the
-    // document doesn't exist.
+    // already have checked the status or validated their document_id.
+    // Regardless, return std::nullopt since the document doesn't exist.
     return std::nullopt;
   }
 
@@ -1485,9 +1487,8 @@ bool DocumentStore::IsDeleted(DocumentId document_id) const {
   if (!file_offset_or.ok()) {
     // This would only happen if document_id is out of range of the
     // document_id_mapper, meaning we got some invalid document_id. Callers
-    // should already have checked that their document_id is valid or used
-    // DoesDocumentExist(WithStatus). Regardless, return true since the
-    // document doesn't exist.
+    // should already have checked the status or validated their document_id.
+    // Regardless, return true since the document doesn't exist.
     return true;
   }
   int64_t file_offset = *file_offset_or.ValueOrDie();
@@ -1503,9 +1504,8 @@ DocumentStore::GetNonExpiredDocumentFilterData(DocumentId document_id,
   if (!filter_data_or.ok()) {
     // This would only happen if document_id is out of range of the
     // filter_cache, meaning we got some invalid document_id. Callers should
-    // already have checked that their document_id is valid or used
-    // DoesDocumentExist(WithStatus). Regardless, return std::nullopt since the
-    // document doesn't exist.
+    // already have checked the status or validated their document_id.
+    // Regardless, return std::nullopt since the document doesn't exist.
     return std::nullopt;
   }
   DocumentFilterData document_filter_data = filter_data_or.ValueOrDie();
diff --git a/icing/store/document-store.h b/icing/store/document-store.h
index 7246235..79869a8 100644
--- a/icing/store/document-store.h
+++ b/icing/store/document-store.h
@@ -289,9 +289,10 @@ class DocumentStore {
   // Helper method to find a DocumentId that is associated with the given
   // namespace and uri.
   //
-  // NOTE: The DocumentId may refer to a invalid document (deleted
-  // or expired). Callers can call DoesDocumentExist(document_id) to ensure it
-  // refers to a valid Document.
+  // NOTE: if succeeded, it always returns a valid DocumentId, but this
+  // DocumentId may refer to a invalid document (deleted or expired). Callers
+  // can call GetAliveDocumentFilterData(document_id, current_time_ms) and check
+  // the return value to ensure it refers to an alive Document.
   //
   // Returns:
   //   A DocumentId on success
@@ -303,9 +304,10 @@ class DocumentStore {
   // Helper method to find a DocumentId that is associated with the given
   // NamespaceIdFingerprint.
   //
-  // NOTE: The DocumentId may refer to a invalid document (deleted
-  // or expired). Callers can call DoesDocumentExist(document_id) to ensure it
-  // refers to a valid Document.
+  // NOTE: if succeeded, it always returns a valid DocumentId, but this
+  // DocumentId may refer to a invalid document (deleted or expired). Callers
+  // can call GetAliveDocumentFilterData(document_id, current_time_ms) and check
+  // the return value to ensure it refers to an alive Document.
   //
   // Returns:
   //   A DocumentId on success
@@ -811,32 +813,16 @@ class DocumentStore {
   libtextclassifier3::StatusOr<CorpusAssociatedScoreData>
   GetCorpusAssociatedScoreDataToUpdate(CorpusId corpus_id) const;
 
-  // Check if a document exists. Existence means it hasn't been deleted and it
-  // hasn't expired yet.
-  //
-  // Returns:
-  //   OK if the document exists
-  //   INVALID_ARGUMENT if document_id is less than 0 or greater than the
-  //                    maximum value
-  //   NOT_FOUND if the document doesn't exist (i.e. deleted or expired)
-  //   INTERNAL_ERROR on IO error
-  libtextclassifier3::Status DoesDocumentExistWithStatus(
-      DocumentId document_id) const;
-
-  // Checks if a document has been deleted
+  // Checks if a document has been deleted.
   //
   // This is for internal-use only because we assume that the document_id is
-  // already valid. If you're unsure if the document_id is valid, use
-  // DoesDocumentExist(document_id) instead, which will perform those additional
-  // checks.
+  // already valid.
   bool IsDeleted(DocumentId document_id) const;
 
   // Checks if a document has expired.
   //
   // This is for internal-use only because we assume that the document_id is
-  // already valid. If you're unsure if the document_id is valid, use
-  // DoesDocumentExist(document_id) instead, which will perform those additional
-  // checks.
+  // already valid.
 
   // Returns:
   //   True:DocumentFilterData  if the given document isn't expired.
diff --git a/icing/store/document-store_benchmark.cc b/icing/store/document-store_benchmark.cc
index 08f3e13..3782da0 100644
--- a/icing/store/document-store_benchmark.cc
+++ b/icing/store/document-store_benchmark.cc
@@ -121,8 +121,7 @@ std::unique_ptr<SchemaStore> CreateSchemaStore(
           .ValueOrDie();
 
   auto set_schema_status = schema_store->SetSchema(
-      CreateSchema(), /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false);
+      CreateSchema(), /*ignore_errors_and_delete_documents=*/false);
   if (!set_schema_status.ok()) {
     ICING_LOG(ERROR) << set_schema_status.status().error_message();
   }
diff --git a/icing/store/document-store_test.cc b/icing/store/document-store_test.cc
index 775a4e0..eb50b9b 100644
--- a/icing/store/document-store_test.cc
+++ b/icing/store/document-store_test.cc
@@ -17,12 +17,13 @@
 #include <cstdint>
 #include <limits>
 #include <memory>
-#include <optional>
 #include <string>
 #include <unordered_set>
+#include <utility>
 #include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/text_classifier/lib3/utils/hash/farmhash.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
@@ -33,6 +34,7 @@
 #include "icing/file/filesystem.h"
 #include "icing/file/memory-mapped-file.h"
 #include "icing/file/mock-filesystem.h"
+#include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/portable/equals-proto.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/debug.pb.h"
@@ -61,8 +63,11 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
+#include "icing/util/clock.h"
 #include "icing/util/crc32.h"
+#include "icing/util/data-loss.h"
 #include "icing/util/icu-data-file-helper.h"
+#include "icing/util/logging.h"
 #include "icing/util/scorable_property_set.h"
 #include "unicode/uloc.h"
 
@@ -243,8 +248,7 @@ class DocumentStoreTest
         schema_store_, SchemaStore::Create(&filesystem_, schema_store_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
 
     language_segmenter_factory::SegmenterOptions segmenter_options(ULOC_US);
@@ -817,8 +821,7 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeOk) {
                           feature_flags_.get()));
 
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
@@ -960,8 +963,7 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeRecoversOk) {
                           feature_flags_.get()));
 
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   DocumentId email_document_id;
   DocumentId message_document_id;
@@ -1060,8 +1062,7 @@ TEST_P(DocumentStoreTest, DeletedSchemaTypeFromSchemaStoreRecoversOk) {
                           feature_flags_.get()));
 
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   DocumentId email_document_id;
   DocumentId message_document_id;
@@ -1121,8 +1122,7 @@ TEST_P(DocumentStoreTest, DeletedSchemaTypeFromSchemaStoreRecoversOk) {
           .AddType(SchemaTypeConfigBuilder().SetType("message"))
           .Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      new_schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      new_schema, /*ignore_errors_and_delete_documents=*/true));
 
   // Successfully recover from a corrupt derived file issue.
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -2966,8 +2966,7 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
             .AddType(SchemaTypeConfigBuilder().SetType("message"))
             .Build();
     ICING_EXPECT_OK(schema_store->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
 
     ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId email_schema_type_id,
                                schema_store->GetSchemaTypeId("email"));
@@ -3037,8 +3036,7 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
                            .AddType(SchemaTypeConfigBuilder().SetType("email"))
                            .Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId email_schema_type_id,
                              schema_store->GetSchemaTypeId("email"));
@@ -3100,8 +3098,7 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreUpdatesSchemaTypeIds) {
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId old_email_schema_type_id,
                              schema_store->GetSchemaTypeId("email"));
@@ -3156,16 +3153,16 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreUpdatesSchemaTypeIds) {
               Eq(tc3farmhash::Fingerprint64(message_document.uri())));
   EXPECT_THAT(message_data.schema_type_id(), Eq(old_message_schema_type_id));
 
-  // Rearrange the schema types. Since SchemaTypeId is assigned based on order,
+  // Add a new schema type. Since SchemaTypeId is assigned based on order,
   // this should change the SchemaTypeIds.
   schema = SchemaBuilder()
-               .AddType(SchemaTypeConfigBuilder().SetType("message"))
+               .AddType(SchemaTypeConfigBuilder().SetType("newType"))
                .AddType(SchemaTypeConfigBuilder().SetType("email"))
+               .AddType(SchemaTypeConfigBuilder().SetType("message"))
                .Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId new_email_schema_type_id,
                              schema_store->GetSchemaTypeId("email"));
@@ -3216,8 +3213,7 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreDeletesInvalidDocuments) {
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Add two documents, with and without a subject
   DocumentProto email_without_subject = DocumentBuilder()
@@ -3271,8 +3267,7 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreDeletesInvalidDocuments) {
       PropertyConfigProto::Cardinality::REQUIRED);
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/true,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/true));
 
   ICING_EXPECT_OK(document_store->UpdateSchemaStore(schema_store.get()));
 
@@ -3303,8 +3298,7 @@ TEST_P(DocumentStoreTest,
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Add a "email" and "message" document
   DocumentProto email_document = DocumentBuilder()
@@ -3352,8 +3346,7 @@ TEST_P(DocumentStoreTest,
 
   ICING_EXPECT_OK(
       schema_store->SetSchema(new_schema,
-                              /*ignore_errors_and_delete_documents=*/true,
-                              /*allow_circular_schema_definitions=*/false));
+                              /*ignore_errors_and_delete_documents=*/true));
 
   ICING_EXPECT_OK(document_store->UpdateSchemaStore(schema_store.get()));
 
@@ -3383,8 +3376,7 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreUpdatesSchemaTypeIds) {
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId old_email_schema_type_id,
                              schema_store->GetSchemaTypeId("email"));
@@ -3437,18 +3429,18 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreUpdatesSchemaTypeIds) {
               Eq(tc3farmhash::Fingerprint64(message_document.uri())));
   EXPECT_THAT(message_data.schema_type_id(), Eq(old_message_schema_type_id));
 
-  // Rearrange the schema types. Since SchemaTypeId is assigned based on order,
+  // Add a new schema type. Since SchemaTypeId is assigned based on order,
   // this should change the SchemaTypeIds.
   schema = SchemaBuilder()
-               .AddType(SchemaTypeConfigBuilder().SetType("message"))
+               .AddType(SchemaTypeConfigBuilder().SetType("newType"))
                .AddType(SchemaTypeConfigBuilder().SetType("email"))
+               .AddType(SchemaTypeConfigBuilder().SetType("message"))
                .Build();
 
   ICING_ASSERT_OK_AND_ASSIGN(
       SchemaStore::SetSchemaResult set_schema_result,
       schema_store->SetSchema(schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false));
+                              /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(SchemaTypeId new_email_schema_type_id,
                              schema_store->GetSchemaTypeId("email"));
@@ -3500,8 +3492,7 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreDeletesInvalidDocuments) {
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Add two documents, with and without a subject
   DocumentProto email_without_subject = DocumentBuilder()
@@ -3557,8 +3548,7 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreDeletesInvalidDocuments) {
   ICING_ASSERT_OK_AND_ASSIGN(
       SchemaStore::SetSchemaResult set_schema_result,
       schema_store->SetSchema(schema,
-                              /*ignore_errors_and_delete_documents=*/true,
-                              /*allow_circular_schema_definitions=*/false));
+                              /*ignore_errors_and_delete_documents=*/true));
 
   ICING_EXPECT_OK(document_store->OptimizedUpdateSchemaStore(
       schema_store.get(), set_schema_result));
@@ -3590,8 +3580,7 @@ TEST_P(DocumentStoreTest,
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   // Add a "email" and "message" document
   DocumentProto email_document = DocumentBuilder()
@@ -3640,8 +3629,7 @@ TEST_P(DocumentStoreTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       SchemaStore::SetSchemaResult set_schema_result,
       schema_store->SetSchema(new_schema,
-                              /*ignore_errors_and_delete_documents=*/true,
-                              /*allow_circular_schema_definitions=*/false));
+                              /*ignore_errors_and_delete_documents=*/true));
 
   ICING_EXPECT_OK(document_store->OptimizedUpdateSchemaStore(
       schema_store.get(), set_schema_result));
@@ -4139,6 +4127,68 @@ TEST_P(DocumentStoreTest, UsageScoresShouldPersistOnOptimize) {
   EXPECT_THAT(actual_scores, Eq(expected_scores));
 }
 
+TEST_P(DocumentStoreTest, DeletedDocumentsShouldNotBeReplacements) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> document_store =
+      std::move(create_result.document_store);
+
+  // Add the document.
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store->Put(test_document1_));
+  EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result1.was_replacement());
+  DocumentId document_id = put_result1.new_document_id;
+
+  // Delete the document.
+  ICING_ASSERT_OK(document_store->Delete(
+      document_id, fake_clock_.GetSystemTimeMilliseconds()));
+
+  // Re-add the document.
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store->Put(test_document1_));
+
+  // Because the document was deleted, it should not be a replacement.
+  EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result2.was_replacement());
+  DocumentId updated_document_id = put_result2.new_document_id;
+  ASSERT_THAT(updated_document_id, Not(Eq(document_id)));
+}
+
+TEST_P(DocumentStoreTest, ExpiredDocumentsShouldNotBeReplacements) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> document_store =
+      std::move(create_result.document_store);
+
+  // Add the document.
+  DocumentProto doc1 = test_document1_;
+  doc1.set_ttl_ms(1);
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store->Put(doc1));
+  EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result1.was_replacement());
+  DocumentId document_id = put_result1.new_document_id;
+
+  // Expire the document by advancing the clock by two milliseconds.
+  fake_clock_.SetSystemTimeMilliseconds(
+      fake_clock_.GetSystemTimeMilliseconds() + 2);
+
+  // Re-add the document.
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store->Put(test_document1_));
+
+  // Because the document was expired, it should not be a replacement.
+  EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result2.was_replacement());
+  DocumentId updated_document_id = put_result2.new_document_id;
+  ASSERT_THAT(updated_document_id, Not(Eq(document_id)));
+}
+
 TEST_P(DocumentStoreTest, DetectPartialDataLoss) {
   {
     // Can put and delete fine.
@@ -4448,8 +4498,7 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryUpdatesTypeIds) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
   // The typeid for "email" should be 0.
   ASSERT_THAT(schema_store->GetSchemaTypeId("email"), IsOkAndHolds(0));
@@ -4507,8 +4556,7 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryUpdatesTypeIds) {
           .AddType(email_type_config)
           .Build();
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
   // Adding a new type should cause ids to be reassigned. Ids are assigned in
   // order of appearance so 'alarm' should be 0 and 'email' should be 1.
@@ -4569,8 +4617,7 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryDoesntUpdateTypeIds) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
   // The typeid for "email" should be 0.
   ASSERT_THAT(schema_store->GetSchemaTypeId("email"), IsOkAndHolds(0));
@@ -4628,8 +4675,7 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryDoesntUpdateTypeIds) {
           .AddType(email_type_config)
           .Build();
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
   // Adding a new type should cause ids to be reassigned. Ids are assigned in
   // order of appearance so 'alarm' should be 0 and 'email' should be 1.
@@ -4681,8 +4727,7 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryDeletesInvalidDocument) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   DocumentProto docWithBody =
@@ -4752,8 +4797,7 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryDeletesInvalidDocument) {
           .Build();
   schema = SchemaBuilder().AddType(email_type_config).Build();
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/true,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/true),
               IsOk());
 
   {
@@ -4805,8 +4849,7 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryKeepsInvalidDocument) {
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
                           feature_flags_.get()));
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   DocumentProto docWithBody =
@@ -4876,8 +4919,7 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryKeepsInvalidDocument) {
           .Build();
   schema = SchemaBuilder().AddType(email_type_config).Build();
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/true,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/true),
               IsOk());
 
   {
@@ -4926,8 +4968,7 @@ TEST_P(DocumentStoreTest, MigrateToPortableFileBackedProtoLog) {
                           feature_flags_.get()));
 
   ASSERT_THAT(schema_store->SetSchema(
-                  schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   // Create dst directory that we'll initialize the DocumentStore over.
@@ -5059,8 +5100,7 @@ TEST_P(DocumentStoreTest, GetDebugInfo) {
                           feature_flags_.get()));
 
   ICING_ASSERT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
@@ -5366,11 +5406,74 @@ TEST_P(DocumentStoreTest, SameKeyMapperTypeShouldNotRegenerateDerivedFiles) {
   }
 }
 
+TEST_P(DocumentStoreTest, GetDocumentId_expiredDocument) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      DocumentStore::Create(
+          &filesystem_, document_store_dir_, &fake_clock_, schema_store_.get(),
+          feature_flags_.get(),
+          /*force_recovery_and_revalidate_documents=*/false,
+          GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
+          PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+          /*initialize_stats=*/nullptr));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  fake_clock_.SetSystemTimeMilliseconds(0);
+  DocumentProto foo_document = DocumentBuilder()
+                                   .SetCreationTimestampMs(0)
+                                   .SetTtlMs(1000)
+                                   .SetKey("namespace", "uri")
+                                   .SetSchema("email")
+                                   .SetCreationTimestampMs(0)
+                                   .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             doc_store->Put(foo_document));
+  EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // Adjust the clock to make the document expired. GetDocumentId should still
+  // return the original document id.
+  fake_clock_.SetSystemTimeMilliseconds(2000);
+  EXPECT_THAT(doc_store->GetDocumentId("namespace", "uri"),
+              IsOkAndHolds(document_id));
+}
+
+TEST_P(DocumentStoreTest, GetDocumentId_deletedDocument) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      DocumentStore::Create(
+          &filesystem_, document_store_dir_, &fake_clock_, schema_store_.get(),
+          feature_flags_.get(),
+          /*force_recovery_and_revalidate_documents=*/false,
+          GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
+          PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+          /*initialize_stats=*/nullptr));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  DocumentProto foo_document = DocumentBuilder()
+                                   .SetKey("namespace", "uri")
+                                   .SetSchema("email")
+                                   .SetCreationTimestampMs(0)
+                                   .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             doc_store->Put(foo_document));
+  EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // Delete the document. GetDocumentId should still return the original
+  // document id.
+  ICING_ASSERT_OK(doc_store->Delete(
+      document_id,
+      /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  EXPECT_THAT(doc_store->GetDocumentId("namespace", "uri"),
+              IsOkAndHolds(document_id));
+}
+
 TEST_P(DocumentStoreTest, GetDocumentIdByNamespaceIdFingerprint) {
-  std::string dynamic_trie_uri_mapper_dir =
-      document_store_dir_ + "/key_mapper_dir";
-  std::string persistent_hash_map_uri_mapper_dir =
-      document_store_dir_ + "/uri_mapper";
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       DocumentStore::Create(
@@ -5422,8 +5525,7 @@ TEST_P(DocumentStoreTest, PutDocumentWithNoScorablePropertiesInSchema) {
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
@@ -5514,8 +5616,7 @@ TEST_P(DocumentStoreTest, PutDocumentWithScorablePropertyThenRead) {
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
@@ -5672,8 +5773,7 @@ TEST_P(DocumentStoreTest, ReadScorablePropertyAfterOptimization) {
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
@@ -5788,8 +5888,7 @@ TEST_P(DocumentStoreTest,
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
@@ -5825,8 +5924,7 @@ TEST_P(DocumentStoreTest,
                        .SetCardinality(CARDINALITY_REPEATED)))
                .Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_EXPECT_OK(doc_store->UpdateSchemaStore(schema_store.get()));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaTypeId schema_type_id,
                              schema_store->GetSchemaTypeId("Person"));
@@ -5864,8 +5962,7 @@ TEST_P(DocumentStoreTest,
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
@@ -5903,8 +6000,7 @@ TEST_P(DocumentStoreTest,
                        .SetCardinality(CARDINALITY_REPEATED)))
                .Build();
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_EXPECT_OK(doc_store->UpdateSchemaStore(schema_store.get()));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaTypeId schema_type_id,
                              schema_store->GetSchemaTypeId("Person"));
@@ -5944,8 +6040,7 @@ TEST_P(DocumentStoreTest,
       SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
                           feature_flags_.get()));
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
@@ -5992,8 +6087,7 @@ TEST_P(DocumentStoreTest,
           .Build();
 
   ICING_EXPECT_OK(schema_store->SetSchema(
-      schema, /*ignore_errors_and_delete_documents=*/false,
-      /*allow_circular_schema_definitions=*/false));
+      schema, /*ignore_errors_and_delete_documents=*/false));
   ICING_EXPECT_OK(doc_store->UpdateSchemaStore(schema_store.get()));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaTypeId person_schema_type_id,
                              schema_store->GetSchemaTypeId("Person"));
diff --git a/icing/testing/common-matchers.h b/icing/testing/common-matchers.h
index aaa4f68..d730c83 100644
--- a/icing/testing/common-matchers.h
+++ b/icing/testing/common-matchers.h
@@ -16,16 +16,17 @@
 #define ICING_TESTING_COMMON_MATCHERS_H_
 
 #include <algorithm>
+#include <array>
 #include <cinttypes>
 #include <cmath>
-#include <functional>
 #include <string>
-#include <vector>
+#include <unordered_map>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/status_macros.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/absl_ports/str_cat.h"
 #include "icing/absl_ports/str_join.h"
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/index/hit/hit.h"
@@ -35,15 +36,22 @@
 #include "icing/portable/equals-proto.h"
 #include "icing/proto/search.pb.h"
 #include "icing/proto/status.pb.h"
+#include "icing/result/snippet-context.h"
 #include "icing/schema/joinable-property.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/scorable_property_manager.h"
 #include "icing/schema/section.h"
 #include "icing/scoring/scored-document-hit.h"
+#include "icing/util/character-iterator.h"
 
 namespace icing {
 namespace lib {
 
+using ::testing::DoubleNear;
+using ::testing::Matches;
+
+constexpr float kEps = 1e-6;
+
 // Used to match Token(Token::Type type, std::string_view text)
 MATCHER_P2(EqualsToken, type, text, "") {
   std::string arg_string(arg.text.data(), arg.text.length());
@@ -630,6 +638,15 @@ MATCHER_P(EqualsSearchResultIgnoreStatsAndScores, expected, "") {
                             actual_copy, result_listener);
 }
 
+MATCHER_P4(EqualsCharacterIterator, expected_text, expected_utf8_index,
+           expected_utf16_index, expected_utf32_index, "") {
+  const CharacterIterator& actual = arg;
+  return actual.text() == expected_text &&
+         actual.utf8_index() == expected_utf8_index &&
+         actual.utf16_index() == expected_utf16_index &&
+         actual.utf32_index() == expected_utf32_index;
+}
+
 MATCHER_P(EqualsHit, expected_hit, "") {
   const Hit& actual = arg;
   return actual.value() == expected_hit.value() &&
@@ -642,6 +659,46 @@ MATCHER(EqualsHit, "") {
                             result_listener);
 }
 
+MATCHER_P(EqualsEmbeddingMatchInfoEntry, expected, "") {
+  const SnippetContext::EmbeddingMatchInfoEntry& actual = arg;
+
+  *result_listener << IcingStringUtil::StringPrintf(
+      "Expected: {score=%f, metric_type=%d, position=%d, "
+      "query_vector_index=%d, section_id=%d}, but got: {score=%f, "
+      "metric_type=%d, "
+      "position=%d, query_vector_index=%d, section_id=%d}",
+      expected.score, expected.metric_type, expected.position,
+      expected.query_vector_index, expected.section_id, actual.score,
+      actual.metric_type, actual.position, actual.query_vector_index,
+      expected.section_id);
+
+  return Matches(DoubleNear(expected.score, kEps))(actual.score) &&
+         actual.metric_type == expected.metric_type &&
+         actual.query_vector_index == expected.query_vector_index &&
+         actual.position == expected.position &&
+         actual.section_id == expected.section_id;
+}
+
+MATCHER_P(EqualsEmbeddingMatchSnippetProto, expected, "") {
+  const EmbeddingMatchSnippetProto& actual = arg;
+
+  *result_listener << IcingStringUtil::StringPrintf(
+      "Expected: {semantic_score=%f, embedding_query_vector_index=%d, "
+      "embedding_query_metric_type=%d}, but got: {semantic_score=%f, "
+      "embedding_query_vector_index=%d, embedding_query_metric_type=%d}",
+      expected.semantic_score(), expected.embedding_query_vector_index(),
+      expected.embedding_query_metric_type(), actual.semantic_score(),
+      actual.embedding_query_vector_index(),
+      actual.embedding_query_metric_type());
+
+  return Matches(DoubleNear(expected.semantic_score(), kEps))(
+             actual.semantic_score()) &&
+         actual.embedding_query_vector_index() ==
+             expected.embedding_query_vector_index() &&
+         actual.embedding_query_metric_type() ==
+             expected.embedding_query_metric_type();
+}
+
 // TODO(tjbarron) Remove this once icing has switched to depend on TC3 Status
 #define ICING_STATUS_MACROS_CONCAT_NAME(x, y) \
   ICING_STATUS_MACROS_CONCAT_IMPL(x, y)
diff --git a/icing/testing/test-feature-flags.cc b/icing/testing/test-feature-flags.cc
index c32e95f..3d167b4 100644
--- a/icing/testing/test-feature-flags.cc
+++ b/icing/testing/test-feature-flags.cc
@@ -20,9 +20,13 @@ namespace icing {
 namespace lib {
 
 FeatureFlags GetTestFeatureFlags() {
-  return FeatureFlags(/*enable_scorable_properties=*/true,
+  return FeatureFlags(/*enable_circular_schema_definitions=*/true,
+                      /*enable_scorable_properties=*/true,
                       /*enable_embedding_quantization=*/true,
-                      /*enable_repeated_field_joins=*/true);
+                      /*enable_repeated_field_joins=*/true,
+                      /*enable_embedding_backup_generation=*/true,
+                      /*enable_schema_database=*/true,
+                      /*release_backup_schema_file_if_overlay_present=*/true);
 }
 
 }  // namespace lib
diff --git a/icing/text_classifier/lib3/utils/base/status.cc b/icing/text_classifier/lib3/utils/base/status.cc
index 26af461..9b573f2 100644
--- a/icing/text_classifier/lib3/utils/base/status.cc
+++ b/icing/text_classifier/lib3/utils/base/status.cc
@@ -14,14 +14,17 @@
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 
+#include <string>
+#include <utility>
+
 namespace libtextclassifier3 {
 
 const Status& Status::OK = *new Status(StatusCode::OK, "");
 const Status& Status::UNKNOWN = *new Status(StatusCode::UNKNOWN, "");
 
 Status::Status() : code_(StatusCode::OK) {}
-Status::Status(StatusCode error, const std::string& message)
-    : code_(error), message_(message) {}
+Status::Status(StatusCode error, std::string message)
+    : code_(error), message_(std::move(message)) {}
 
 logging::LoggingStringStream& operator<<(logging::LoggingStringStream& stream,
                                          const Status& status) {
diff --git a/icing/text_classifier/lib3/utils/base/status.h b/icing/text_classifier/lib3/utils/base/status.h
index 7566961..233c2f8 100644
--- a/icing/text_classifier/lib3/utils/base/status.h
+++ b/icing/text_classifier/lib3/utils/base/status.h
@@ -52,7 +52,7 @@ class Status {
   Status();
 
   // Make a Status from the specified error and message.
-  Status(StatusCode error, const std::string& error_message);
+  Status(StatusCode error, std::string error_message);
 
   // Some pre-defined Status objects
   static const Status& OK;
diff --git a/icing/tokenization/combined-tokenizer_test.cc b/icing/tokenization/combined-tokenizer_test.cc
index 04d56fe..520ea47 100644
--- a/icing/tokenization/combined-tokenizer_test.cc
+++ b/icing/tokenization/combined-tokenizer_test.cc
@@ -15,6 +15,7 @@
 #include <algorithm>
 #include <cstdint>
 #include <iterator>
+#include <limits>
 #include <memory>
 #include <string>
 #include <string_view>
@@ -52,6 +53,7 @@
 #include "icing/tokenization/tokenizer-factory.h"
 #include "icing/tokenization/tokenizer.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/status-macros.h"
@@ -128,8 +130,11 @@ class CombinedTokenizerTest : public ::testing::Test {
         lang_segmenter_,
         language_segmenter_factory::Create(std::move(segmenter_options)));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/1000));
+    NormalizerOptions normalizer_options(
+        /*max_term_byte_size=*/std::numeric_limits<int32_t>::max());
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(normalizer_options));
+
     ICING_ASSERT_OK_AND_ASSIGN(
         query_processor_,
         QueryProcessor::Create(
@@ -148,6 +153,7 @@ class CombinedTokenizerTest : public ::testing::Test {
         QueryResults parsed_query,
         query_processor_->ParseSearch(
             search_spec, ScoringSpecProto::RankingStrategy::NONE,
+            /*get_embedding_match_info=*/false,
             /*current_time_ms=*/0, /*search_stats=*/nullptr));
 
     std::vector<std::string> query_terms;
@@ -247,8 +253,7 @@ TEST_F(CombinedTokenizerTest, Negation) {
   const std::string_view kQueryText = "\\-foo \\-bar \\-baz";
   ICING_ASSERT_OK_AND_ASSIGN(std::vector<std::string> query_terms,
                              GetQueryTerms(kQueryText));
-  EXPECT_THAT(query_terms,
-              UnorderedElementsAre("foo", "bar", "baz"));
+  EXPECT_THAT(query_terms, UnorderedElementsAre("foo", "bar", "baz"));
 }
 
 // TODO(b/254874614): Handle colon word breaks in ICU 72+
@@ -277,8 +282,9 @@ TEST_F(CombinedTokenizerTest, ColonsPropertyRestricts) {
       tokenizer_factory::CreateIndexingTokenizer(
           StringIndexingConfig::TokenizerType::PLAIN, lang_segmenter_.get()));
 
-  if (GetIcuTokenizationVersion() >= 72) {
-    // In ICU 72+ and above, ':' are no longer considered word connectors.
+  int icu_version = GetIcuTokenizationVersion();
+  if (icu_version >= 72 && icu_version < 77) {
+    // In ICU 72+ and before 77, ':' are not considered word connectors.
     constexpr std::string_view kText = "foo:bar";
     ICING_ASSERT_OK_AND_ASSIGN(std::vector<Token> indexing_tokens,
                                indexing_tokenizer->TokenizeAll(kText));
@@ -287,7 +293,7 @@ TEST_F(CombinedTokenizerTest, ColonsPropertyRestricts) {
 
     const std::string_view kQueryText = "foo\\:bar";
     ICING_ASSERT_OK_AND_ASSIGN(std::vector<std::string> query_terms,
-                              GetQueryTerms(kQueryText));
+                               GetQueryTerms(kQueryText));
     EXPECT_THAT(query_terms, UnorderedElementsAre("foo", "bar"));
 
     constexpr std::string_view kText2 = "foo:bar:baz";
@@ -297,8 +303,7 @@ TEST_F(CombinedTokenizerTest, ColonsPropertyRestricts) {
     EXPECT_THAT(indexing_terms, ElementsAre("foo", "bar", "baz"));
 
     const std::string_view kQueryText2 = "foo\\:bar\\:baz";
-    ICING_ASSERT_OK_AND_ASSIGN(query_terms,
-                              GetQueryTerms(kQueryText2));
+    ICING_ASSERT_OK_AND_ASSIGN(query_terms, GetQueryTerms(kQueryText2));
     EXPECT_THAT(query_terms, UnorderedElementsAre("foo", "bar", "baz"));
   } else {
     constexpr std::string_view kText = "foo:bar";
diff --git a/icing/tokenization/icu/icu-language-segmenter_test.cc b/icing/tokenization/icu/icu-language-segmenter_test.cc
index 664ccce..cde62f2 100644
--- a/icing/tokenization/icu/icu-language-segmenter_test.cc
+++ b/icing/tokenization/icu/icu-language-segmenter_test.cc
@@ -229,12 +229,19 @@ TEST_P(IcuLanguageSegmenterAllLocalesTest, WordConnector) {
   //   2. '@' became a word connector
   //   3. <numeric><word-connector><numeric> such as "3'14" is now considered as
   //      a single token.
-  if (GetIcuTokenizationVersion() >= 72) {
-    EXPECT_THAT(
-        language_segmenter->GetAllTerms("com:google:android"),
-        IsOkAndHolds(ElementsAre("com", ":", "google", ":", "android")));
+  int icu_version = GetIcuTokenizationVersion();
+  if (icu_version >= 72) {
+    // In ICU 77, the rules for ':' were reverted.
+    if (icu_version >= 77) {
+      EXPECT_THAT(language_segmenter->GetAllTerms("com:google:android"),
+                  IsOkAndHolds(ElementsAre("com:google:android")));
+    } else {
+      EXPECT_THAT(
+          language_segmenter->GetAllTerms("com:google:android"),
+          IsOkAndHolds(ElementsAre("com", ":", "google", ":", "android")));
+    }
     // In ICU 74, the rules for '@' were reverted.
-    if (GetIcuTokenizationVersion() >= 74) {
+    if (icu_version >= 74) {
       EXPECT_THAT(
           language_segmenter->GetAllTerms("com@google@android"),
           IsOkAndHolds(ElementsAre("com", "@", "google", "@", "android")));
diff --git a/icing/tokenization/language-segmenter-factory.h b/icing/tokenization/language-segmenter-factory.h
index ff7b781..5e4879c 100644
--- a/icing/tokenization/language-segmenter-factory.h
+++ b/icing/tokenization/language-segmenter-factory.h
@@ -28,6 +28,8 @@ namespace lib {
 
 namespace language_segmenter_factory {
 
+// TODO: b/332382299 - Avoid using default values in the SegmenterOptions
+// constructor. This can lead to unexpected behavior.
 struct SegmenterOptions {
   explicit SegmenterOptions(std::string locale,
                             const JniCache* jni_cache = nullptr,
diff --git a/icing/tokenization/plain-tokenizer.cc b/icing/tokenization/plain-tokenizer.cc
index d40022b..ec7a783 100644
--- a/icing/tokenization/plain-tokenizer.cc
+++ b/icing/tokenization/plain-tokenizer.cc
@@ -33,7 +33,7 @@ namespace {
 //   1. it's not empty
 //   2. it's not a whitespace
 //   3. it's not a punctuation mark
-//
+//   4. it's not a null terminator
 // TODO(b/141007791): figure out how we'd like to support special characters
 // like "+", "&", "@", "#" in indexing and query tokenizers.
 bool IsValidTerm(std::string_view term) {
@@ -43,7 +43,8 @@ bool IsValidTerm(std::string_view term) {
   // Gets the first unicode character. We can know what the whole term is by
   // checking only the first character.
   return !i18n_utils::IsWhitespaceAt(term, /*position=*/0) &&
-         !i18n_utils::IsPunctuationAt(term, /*position=*/0);
+         !i18n_utils::IsPunctuationAt(term, /*position=*/0) &&
+         !(term[0] == '\0');
 }
 }  // namespace
 
diff --git a/icing/tokenization/plain-tokenizer_test.cc b/icing/tokenization/plain-tokenizer_test.cc
index a0d187d..08d7f3e 100644
--- a/icing/tokenization/plain-tokenizer_test.cc
+++ b/icing/tokenization/plain-tokenizer_test.cc
@@ -14,6 +14,7 @@
 
 #include "icing/tokenization/plain-tokenizer.h"
 
+#include <string>
 #include <string_view>
 
 #include "gmock/gmock.h"
@@ -237,6 +238,32 @@ TEST_F(PlainTokenizerTest, SpecialCharacters) {
                                EqualsToken(Token::Type::REGULAR, "50"))));
 }
 
+TEST_F(PlainTokenizerTest, NullTerminator) {
+  language_segmenter_factory::SegmenterOptions options(ULOC_US,
+                                                       jni_cache_.get());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      auto language_segmenter,
+      language_segmenter_factory::Create(std::move(options)));
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Tokenizer> plain_tokenizer,
+                             tokenizer_factory::CreateIndexingTokenizer(
+                                 StringIndexingConfig::TokenizerType::PLAIN,
+                                 language_segmenter.get()));
+
+  // Plain tokenizer should not produce a token for null terminator.
+  EXPECT_THAT(
+      plain_tokenizer->TokenizeAll(std::string("Hello\0World", 11)),
+      IsOkAndHolds(ElementsAre(EqualsToken(Token::Type::REGULAR, "Hello"),
+                               EqualsToken(Token::Type::REGULAR, "World"))));
+  EXPECT_THAT(
+      plain_tokenizer->TokenizeAll(std::string("Hello\0\0World", 12)),
+      IsOkAndHolds(ElementsAre(EqualsToken(Token::Type::REGULAR, "Hello"),
+                               EqualsToken(Token::Type::REGULAR, "World"))));
+  EXPECT_THAT(
+      plain_tokenizer->TokenizeAll(std::string("Hello\0World\0", 12)),
+      IsOkAndHolds(ElementsAre(EqualsToken(Token::Type::REGULAR, "Hello"),
+                               EqualsToken(Token::Type::REGULAR, "World"))));
+}
+
 TEST_F(PlainTokenizerTest, CJKT) {
   // In plain tokenizer, CJKT characters are handled the same way as non-CJKT
   // characters, just add these tests as sanity checks.
diff --git a/icing/tokenization/reverse_jni/reverse-jni-language-segmenter.cc b/icing/tokenization/reverse_jni/reverse-jni-language-segmenter.cc
index bd80718..e9c2c95 100644
--- a/icing/tokenization/reverse_jni/reverse-jni-language-segmenter.cc
+++ b/icing/tokenization/reverse_jni/reverse-jni-language-segmenter.cc
@@ -256,26 +256,19 @@ class ReverseJniLanguageSegmenterIterator : public LanguageSegmenter::Iterator {
 
  private:
   // Ensures that all members are consistent with the 'Done' state.
-  // In the 'Done' state, both term_start_.utf8_index() and
-  // term_end_exclusive_.utf8_index() will point to the same character, causing
-  // GetTerm() to return an empty string and term_start_.utf16_index() and
-  // term_end_exclusive_.utf16_index() will be marked with the kDone value.
-  // break_iterator_ may be in any state.
+  // In the 'Done' state:
+  // - Both term_start_ and term_end_exclusive_ will be invalid.
+  // - break_iterator_ may be in any state.
   void MarkAsDone() {
-    term_start_ =
-        CharacterIterator(text_, /*utf8_index=*/ReverseJniBreakIterator::kDone,
-                          /*utf16_index=*/ReverseJniBreakIterator::kDone,
-                          /*utf32_index=*/ReverseJniBreakIterator::kDone);
-    term_end_exclusive_ =
-        CharacterIterator(text_, /*utf8_index=*/ReverseJniBreakIterator::kDone,
-                          /*utf16_index=*/ReverseJniBreakIterator::kDone,
-                          /*utf32_index=*/ReverseJniBreakIterator::kDone);
+    // Set the iterators to invalid instances.
+    term_start_ = CharacterIterator();
+    term_end_exclusive_ = CharacterIterator();
   }
   bool IsDone() const {
-    // We could just as easily check the other utf indices or the values in
-    // term_start_ to check for done. There's no particular reason to choose any
-    // one since they should all hold kDone.
-    return term_end_exclusive_.utf16_index() == ReverseJniBreakIterator::kDone;
+    // We could just as easily check if term_end_exclusive_ is invalid. Both
+    // term_start_ and term_end_exclusive_ are invalid when the iterator is
+    // done.
+    return !term_end_exclusive_.is_valid();
   }
 
   // All of ReverseJniBreakIterator's functions return UTF-16 boundaries. So
diff --git a/icing/tokenization/rfc822-tokenizer.cc b/icing/tokenization/rfc822-tokenizer.cc
index 13c58c5..554340a 100644
--- a/icing/tokenization/rfc822-tokenizer.cc
+++ b/icing/tokenization/rfc822-tokenizer.cc
@@ -40,8 +40,8 @@ class Rfc822TokenIterator : public Tokenizer::Iterator {
   // Cursor is the index into the string_view, text_end_ is the length.
   explicit Rfc822TokenIterator(std::string_view text)
       : text_(std::move(text)),
-        iterator_(text, 0, 0, 0),
-        text_end_(text.length()),
+        iterator_(text_),
+        text_end_(text_.length()),
         token_index_(-1) {}
 
   // Advance will move token_index_ past the end of tokens_
diff --git a/icing/tokenization/trigram-tokenizer.cc b/icing/tokenization/trigram-tokenizer.cc
index 4fca591..870a75d 100644
--- a/icing/tokenization/trigram-tokenizer.cc
+++ b/icing/tokenization/trigram-tokenizer.cc
@@ -216,8 +216,7 @@ class TrigramTokenizerIterator : public Tokenizer::Iterator {
   bool Initialize() {
     bool result = true;
 
-    CharacterIterator iterator(text_, /*utf8_index=*/0, /*utf16_index=*/0,
-                               /*utf32_index=*/0);
+    CharacterIterator iterator(text_);
     for (int i = 0; i < kNgramLength; ++i) {
       if (iterator.utf8_index() >= text_.length()) {
         // It means the text is too short (with # of characters < 3) to form a
diff --git a/icing/tokenization/verbatim-tokenizer.cc b/icing/tokenization/verbatim-tokenizer.cc
index 9ca611d..b7745f8 100644
--- a/icing/tokenization/verbatim-tokenizer.cc
+++ b/icing/tokenization/verbatim-tokenizer.cc
@@ -14,9 +14,16 @@
 
 #include "icing/tokenization/verbatim-tokenizer.h"
 
+#include <cstdint>
+#include <memory>
+#include <string_view>
+#include <utility>
 #include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/tokenization/token.h"
+#include "icing/tokenization/tokenizer.h"
 #include "icing/util/character-iterator.h"
 #include "icing/util/status-macros.h"
 
@@ -26,7 +33,7 @@ namespace lib {
 class VerbatimTokenIterator : public Tokenizer::Iterator {
  public:
   explicit VerbatimTokenIterator(std::string_view text)
-      : term_(std::move(text)) {}
+      : term_(std::move(text)), has_advanced_to_end_(false) {}
 
   bool Advance() override {
     if (term_.empty() || has_advanced_to_end_) {
@@ -54,7 +61,7 @@ class VerbatimTokenIterator : public Tokenizer::Iterator {
           "Could not calculate start of empty token.");
     }
 
-    return CharacterIterator(term_, 0, 0, 0);
+    return CharacterIterator(term_);
   }
 
   libtextclassifier3::StatusOr<CharacterIterator> CalculateTokenEndExclusive()
@@ -64,16 +71,11 @@ class VerbatimTokenIterator : public Tokenizer::Iterator {
           "Could not calculate end of empty token.");
     }
 
-    if (token_end_iterator_.utf8_index() >= 0) {
-      return token_end_iterator_;
-    }
-
-    bool moved_to_token_end = token_end_iterator_.MoveToUtf8(term_.length());
-    if (moved_to_token_end) {
-      return token_end_iterator_;
-    } else {
+    CharacterIterator token_end_iterator = GetTokenEndIterator();
+    if (!token_end_iterator.is_valid()) {
       return absl_ports::AbortedError("Could not move to end of token.");
     }
+    return token_end_iterator;
   }
 
   bool ResetToTokenStartingAfter(int32_t utf32_offset) override {
@@ -93,18 +95,7 @@ class VerbatimTokenIterator : public Tokenizer::Iterator {
     // after the end of the token for the reset to be valid. This means the
     // provided utf-32 offset must be equal to or greater than the utf-32 length
     // of the token.
-    if (token_end_iterator_.utf8_index() < 0) {
-      // Moves one index past the end of the term.
-      bool moved_to_token_end = token_end_iterator_.MoveToUtf8(term_.length());
-      if (!moved_to_token_end) {
-        // We're unable to reset as we failed to move to the end of the term.
-        return false;
-      }
-    }
-
-    if (utf32_offset >= token_end_iterator_.utf32_index()) {
-      // Because we are now at the sole verbatim token, we should ensure we can
-      // no longer advance past it.
+    if (utf32_offset >= GetTokenEndIterator().utf32_index()) {
       has_advanced_to_end_ = true;
       return true;
     }
@@ -117,10 +108,34 @@ class VerbatimTokenIterator : public Tokenizer::Iterator {
   }
 
  private:
+  // Returns the end of the token, caching the result if it is not already
+  // cached.
+  //
+  // RETURNS:
+  //   - A valid CharacterIterator instance pointing to end of the token if
+  //     succeeded to move to the end of the token. Also caches the end
+  //     iterator.
+  //   - An invalid character iterator if failed to move to the end of the
+  //     token.
+  CharacterIterator GetTokenEndIterator() const {
+    if (cached_token_end_iterator_.is_valid()) {
+      return cached_token_end_iterator_;
+    }
+
+    CharacterIterator token_end_iterator(term_);
+    if (token_end_iterator.MoveToUtf8(term_.length())) {
+      cached_token_end_iterator_ = std::move(token_end_iterator);
+    }
+
+    return cached_token_end_iterator_;
+  }
+
   std::string_view term_;
-  CharacterIterator token_end_iterator_ = CharacterIterator(term_, -1, -1, -1);
   // Used to determine whether we have advanced on the sole verbatim token
-  bool has_advanced_to_end_ = false;
+  bool has_advanced_to_end_;
+
+  mutable CharacterIterator
+      cached_token_end_iterator_;  // initially invalid. Lazy update.
 };
 
 libtextclassifier3::StatusOr<std::unique_ptr<Tokenizer::Iterator>>
diff --git a/icing/transform/icu/icu-normalizer-factory.cc b/icing/transform/icu/icu-normalizer-factory.cc
index 493aeb5..290fbcc 100644
--- a/icing/transform/icu/icu-normalizer-factory.cc
+++ b/icing/transform/icu/icu-normalizer-factory.cc
@@ -21,6 +21,7 @@
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/canonical_errors.h"
 #include "icing/transform/icu/icu-normalizer.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 
 namespace icing {
@@ -28,20 +29,19 @@ namespace lib {
 
 namespace normalizer_factory {
 
-// Creates an ICU-based  normalizer. max_term_byte_size enforces the max size of
-// text after normalization, text will be truncated if exceeds the max size.
+// Creates an ICU-based normalizer.
 //
 // Returns:
 //   A normalizer on success
-//   INVALID_ARGUMENT if max_term_byte_size <= 0
+//   INVALID_ARGUMENT_ERROR if options.max_term_byte_size <= 0
 //   INTERNAL_ERROR on errors
 libtextclassifier3::StatusOr<std::unique_ptr<Normalizer>> Create(
-    int max_term_byte_size) {
-  if (max_term_byte_size <= 0) {
+    const NormalizerOptions& options) {
+  if (options.max_term_byte_size <= 0) {
     return absl_ports::InvalidArgumentError(
         "max_term_byte_size must be greater than zero.");
   }
-  return IcuNormalizer::Create(max_term_byte_size);
+  return IcuNormalizer::Create(options.max_term_byte_size);
 }
 
 }  // namespace normalizer_factory
diff --git a/icing/transform/icu/icu-normalizer.cc b/icing/transform/icu/icu-normalizer.cc
index 74c240a..4e03bc4 100644
--- a/icing/transform/icu/icu-normalizer.cc
+++ b/icing/transform/icu/icu-normalizer.cc
@@ -254,6 +254,8 @@ IcuNormalizer::TermTransformer::Transform(const std::string_view term) const {
     ICING_LOG(WARNING) << "Failed to normalize UTF8 term: " << term;
     return {std::string(term)};
   }
+  // Resize the buffer to the desired length returned by utrans_transUChars().
+  utf16_term.resize(utf16_term_desired_length);
 
   auto utf8_term_or = i18n_utils::Utf16ToUtf8(utf16_term);
   if (!utf8_term_or.ok()) {
diff --git a/icing/transform/icu/icu-normalizer_benchmark.cc b/icing/transform/icu/icu-normalizer_benchmark.cc
index d3d3074..73b3a12 100644
--- a/icing/transform/icu/icu-normalizer_benchmark.cc
+++ b/icing/transform/icu/icu-normalizer_benchmark.cc
@@ -12,11 +12,15 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+#include <limits>
+#include <memory>
+
 #include "testing/base/public/benchmark.h"
 #include "gmock/gmock.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/test-data.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 
@@ -58,10 +62,10 @@ void BM_NormalizeUppercase(benchmark::State& state) {
         GetTestFilePath("icing/icu.dat")));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create((options)));
 
   std::string input_string(state.range(0), 'A');
   for (auto _ : state) {
@@ -91,10 +95,10 @@ void BM_NormalizeAccent(benchmark::State& state) {
         GetTestFilePath("icing/icu.dat")));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create((options)));
 
   std::string input_string;
   while (input_string.length() < state.range(0)) {
@@ -128,10 +132,10 @@ void BM_NormalizeGreekAccent(benchmark::State& state) {
         GetTestFilePath("icing/icu.dat")));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create((options)));
 
   std::string input_string;
   while (input_string.length() < state.range(0)) {
@@ -165,10 +169,10 @@ void BM_NormalizeHiragana(benchmark::State& state) {
         GetTestFilePath("icing/icu.dat")));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create((options)));
 
   std::string input_string;
   while (input_string.length() < state.range(0)) {
@@ -202,10 +206,10 @@ void BM_UppercaseSubTokenLength(benchmark::State& state) {
         GetTestFilePath("icing/icu.dat")));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create((options)));
 
   std::string input_string(state.range(0), 'A');
   std::string normalized_input_string(state.range(0), 'a');
@@ -237,10 +241,10 @@ void BM_AccentSubTokenLength(benchmark::State& state) {
         GetTestFilePath("icing/icu.dat")));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create((options)));
 
   std::string input_string;
   std::string normalized_input_string;
@@ -277,10 +281,10 @@ void BM_HiraganaSubTokenLength(benchmark::State& state) {
         GetTestFilePath("icing/icu.dat")));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create((options)));
 
   std::string input_string;
   std::string normalized_input_string;
diff --git a/icing/transform/icu/icu-normalizer_test.cc b/icing/transform/icu/icu-normalizer_test.cc
index 7f5af04..499c7c1 100644
--- a/icing/transform/icu/icu-normalizer_test.cc
+++ b/icing/transform/icu/icu-normalizer_test.cc
@@ -13,13 +13,15 @@
 // limitations under the License.
 
 #include <memory>
+#include <string>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/testing/common-matchers.h"
-#include "icing/testing/icu-i18n-test-utils.h"
 #include "icing/testing/test-data.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/icu-data-file-helper.h"
 
@@ -36,22 +38,24 @@ class IcuNormalizerTest : public testing::Test {
         icu_data_file_helper::SetUpIcuDataFile(
             GetTestFilePath("icing/icu.dat")));
 
-    ICING_ASSERT_OK_AND_ASSIGN(normalizer_, normalizer_factory::Create(
-                                                /*max_term_byte_size=*/1024));
+    NormalizerOptions options(/*max_term_byte_size=*/1024);
+    ICING_ASSERT_OK_AND_ASSIGN(normalizer_,
+                               normalizer_factory::Create(options));
   }
 
   std::unique_ptr<Normalizer> normalizer_;
 };
 
 TEST_F(IcuNormalizerTest, Creation) {
-  EXPECT_THAT(normalizer_factory::Create(
-                  /*max_term_byte_size=*/5),
-              IsOk());
-  EXPECT_THAT(normalizer_factory::Create(
-                  /*max_term_byte_size=*/0),
+  NormalizerOptions options1(/*max_term_byte_size=*/5);
+  EXPECT_THAT(normalizer_factory::Create(options1), IsOk());
+
+  NormalizerOptions options2(/*max_term_byte_size=*/0);
+  EXPECT_THAT(normalizer_factory::Create(options2),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-  EXPECT_THAT(normalizer_factory::Create(
-                  /*max_term_byte_size=*/-1),
+
+  NormalizerOptions options3(/*max_term_byte_size=*/-1);
+  EXPECT_THAT(normalizer_factory::Create(options3),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -184,8 +188,9 @@ TEST_F(IcuNormalizerTest, FullWidthCharsToASCII) {
 }
 
 TEST_F(IcuNormalizerTest, IdeographicToASCII) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   EXPECT_THAT(normalizer->NormalizeTerm(""), EqualsNormalizedTerm(",."));
 }
@@ -262,10 +267,20 @@ TEST_F(IcuNormalizerTest, FractionsToASCII) {
   EXPECT_THAT(normalizer_->NormalizeTerm(""), EqualsNormalizedTerm(" 5/6"));
 }
 
+TEST_F(IcuNormalizerTest, CorruptTerm) {
+  std::string_view empty_term = "";
+  EXPECT_THAT(normalizer_->NormalizeTerm(empty_term), EqualsNormalizedTerm(""));
+  std::string_view CGJ_term = "\u034F";
+  EXPECT_THAT(normalizer_->NormalizeTerm(CGJ_term), EqualsNormalizedTerm(""));
+  std::string_view null_term = "\0";
+  EXPECT_THAT(normalizer_->NormalizeTerm(null_term), EqualsNormalizedTerm(""));
+}
+
 TEST_F(IcuNormalizerTest, Truncate) {
   {
+    NormalizerOptions options(/*max_term_byte_size=*/5);
     ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                    /*max_term_byte_size=*/5));
+        options));
 
     // Won't be truncated
     EXPECT_THAT(normalizer->NormalizeTerm("hi"), EqualsNormalizedTerm("hi"));
@@ -287,8 +302,9 @@ TEST_F(IcuNormalizerTest, Truncate) {
   }
 
   {
+    NormalizerOptions options(/*max_term_byte_size=*/2);
     ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                    /*max_term_byte_size=*/2));
+        options));
     // The Japanese character has 3 bytes, truncating it results in an empty
     // string.
     EXPECT_THAT(normalizer->NormalizeTerm(""), EqualsNormalizedTerm(""));
@@ -299,8 +315,9 @@ TEST_F(IcuNormalizerTest, PrefixMatchLength) {
   // Verify that FindNormalizedMatchEndPosition will properly find the length of
   // the prefix match when given a non-normalized term and a normalized term
   // is a prefix of the non-normalized one.
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   // Upper to lower
   std::string term = "MDI";
@@ -377,8 +394,9 @@ TEST_F(IcuNormalizerTest, SharedPrefixMatchLength) {
   // Verify that FindNormalizedMatchEndPosition will properly find the length of
   // the prefix match when given a non-normalized term and a normalized term
   // that share a common prefix.
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   // Upper to lower
   std::string term = "MDI";
diff --git a/icing/transform/map/map-normalizer-factory.cc b/icing/transform/map/map-normalizer-factory.cc
index 3bf84b3..2c0dc8d 100644
--- a/icing/transform/map/map-normalizer-factory.cc
+++ b/icing/transform/map/map-normalizer-factory.cc
@@ -17,29 +17,29 @@
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/canonical_errors.h"
 #include "icing/transform/map/map-normalizer.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
-#include "icing/util/status-macros.h"
 
 namespace icing {
 namespace lib {
 
 namespace normalizer_factory {
 
-// Creates a map-based normalizer. max_term_byte_size enforces the max size of
-// text after normalization, text will be truncated if exceeds the max size.
+// Creates a map-based normalizer.
 //
 // Returns:
 //   A normalizer on success
-//   INVALID_ARGUMENT if max_term_byte_size <= 0
+//   INVALID_ARGUMENT_ERROR if options.max_term_byte_size <= 0
 //   INTERNAL_ERROR on errors
 libtextclassifier3::StatusOr<std::unique_ptr<Normalizer>> Create(
-    int max_term_byte_size) {
-  if (max_term_byte_size <= 0) {
+    const NormalizerOptions& options) {
+  if (options.max_term_byte_size <= 0) {
     return absl_ports::InvalidArgumentError(
-        "max_term_byte_size must be greater than zero.");
+        "normalizer_max_term_byte_size must be greater than zero.");
   }
 
-  return std::make_unique<MapNormalizer>(max_term_byte_size);
+  return std::make_unique<MapNormalizer>(
+      options.max_term_byte_size);
 }
 
 }  // namespace normalizer_factory
diff --git a/icing/transform/map/map-normalizer_benchmark.cc b/icing/transform/map/map-normalizer_benchmark.cc
index 4560329..6d3fb5a 100644
--- a/icing/transform/map/map-normalizer_benchmark.cc
+++ b/icing/transform/map/map-normalizer_benchmark.cc
@@ -12,11 +12,13 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+#include <limits>
 #include <memory>
 
 #include "testing/base/public/benchmark.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 
 // Run on a Linux workstation:
@@ -42,10 +44,10 @@ namespace lib {
 namespace {
 
 void BM_NormalizeUppercase(benchmark::State& state) {
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create(options));
 
   std::string input_string(state.range(0), 'A');
 
@@ -74,10 +76,10 @@ BENCHMARK(BM_NormalizeUppercase)
     ->Arg(4096000);
 
 void BM_NormalizeAccent(benchmark::State& state) {
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create(options));
 
   std::string input_string;
   while (input_string.length() < state.range(0)) {
@@ -109,10 +111,10 @@ BENCHMARK(BM_NormalizeAccent)
     ->Arg(4096000);
 
 void BM_NormalizeHiragana(benchmark::State& state) {
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create(options));
 
   std::string input_string;
   while (input_string.length() < state.range(0)) {
@@ -144,11 +146,10 @@ BENCHMARK(BM_NormalizeHiragana)
     ->Arg(4096000);
 
 void BM_UppercaseSubTokenLength(benchmark::State& state) {
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create(options));
 
   std::string input_string(state.range(0), 'A');
   std::string normalized_input_string(state.range(0), 'a');
@@ -174,10 +175,10 @@ BENCHMARK(BM_UppercaseSubTokenLength)
     ->Arg(4096000);
 
 void BM_AccentSubTokenLength(benchmark::State& state) {
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create(options));
 
   std::string input_string;
   std::string normalized_input_string;
@@ -208,10 +209,10 @@ BENCHMARK(BM_AccentSubTokenLength)
     ->Arg(4096000);
 
 void BM_HiraganaSubTokenLength(benchmark::State& state) {
-  ICING_ASSERT_OK_AND_ASSIGN(
-      std::unique_ptr<Normalizer> normalizer,
-      normalizer_factory::Create(
-          /*max_term_byte_size=*/std::numeric_limits<int>::max()));
+  NormalizerOptions options(
+      /*max_term_byte_size=*/std::numeric_limits<int>::max());
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Normalizer> normalizer,
+                             normalizer_factory::Create(options));
 
   std::string input_string;
   std::string normalized_input_string;
diff --git a/icing/transform/map/map-normalizer_test.cc b/icing/transform/map/map-normalizer_test.cc
index 72b122c..aebfb71 100644
--- a/icing/transform/map/map-normalizer_test.cc
+++ b/icing/transform/map/map-normalizer_test.cc
@@ -16,12 +16,11 @@
 #include <string>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
-#include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/testing/common-matchers.h"
-#include "icing/testing/icu-i18n-test-utils.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/character-iterator.h"
 
@@ -29,24 +28,29 @@ namespace icing {
 namespace lib {
 
 namespace {
+
 using ::testing::Eq;
 
 TEST(MapNormalizerTest, Creation) {
-  EXPECT_THAT(normalizer_factory::Create(
-                  /*max_term_byte_size=*/5),
+  NormalizerOptions options1(/*max_term_byte_size=*/5);
+  EXPECT_THAT(normalizer_factory::Create(options1),
               IsOk());
-  EXPECT_THAT(normalizer_factory::Create(
-                  /*max_term_byte_size=*/0),
+
+  NormalizerOptions options2(/*max_term_byte_size=*/0);
+  EXPECT_THAT(normalizer_factory::Create(options2),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-  EXPECT_THAT(normalizer_factory::Create(
-                  /*max_term_byte_size=*/-1),
+
+  NormalizerOptions options3(/*max_term_byte_size=*/-1);
+
+  EXPECT_THAT(normalizer_factory::Create(options3),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
 // Strings that are already normalized won't change if normalized again.
 TEST(MapNormalizerTest, AlreadyNormalized) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   EXPECT_THAT(normalizer->NormalizeTerm(""), EqualsNormalizedTerm(""));
   EXPECT_THAT(normalizer->NormalizeTerm("hello world"),
@@ -59,8 +63,9 @@ TEST(MapNormalizerTest, AlreadyNormalized) {
 }
 
 TEST(MapNormalizerTest, UppercaseToLowercase) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   EXPECT_THAT(normalizer->NormalizeTerm("MDI"), EqualsNormalizedTerm("mdi"));
   EXPECT_THAT(normalizer->NormalizeTerm("Icing"),
@@ -68,8 +73,9 @@ TEST(MapNormalizerTest, UppercaseToLowercase) {
 }
 
 TEST(MapNormalizerTest, LatinLetterRemoveAccent) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   EXPECT_THAT(normalizer->NormalizeTerm("Zrich"),
               EqualsNormalizedTerm("zurich"));
@@ -127,8 +133,9 @@ TEST(MapNormalizerTest, LatinLetterRemoveAccent) {
 // Accent / diacritic marks won't be removed in non-latin chars, e.g. in
 // Japanese and Greek
 TEST(MapNormalizerTest, NonLatinLetterNotRemoveAccent) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   // Katakana
   EXPECT_THAT(normalizer->NormalizeTerm(""),
@@ -144,8 +151,9 @@ TEST(MapNormalizerTest, NonLatinLetterNotRemoveAccent) {
 }
 
 TEST(MapNormalizerTest, FullWidthCharsToASCII) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   // Full-width punctuation to ASCII punctuation
   EXPECT_THAT(normalizer->NormalizeTerm(""),
@@ -164,15 +172,17 @@ TEST(MapNormalizerTest, FullWidthCharsToASCII) {
 }
 
 TEST(MapNormalizerTest, IdeographicToASCII) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   EXPECT_THAT(normalizer->NormalizeTerm(""), EqualsNormalizedTerm(",."));
 }
 
 TEST(MapNormalizerTest, HiraganaToKatakana) {
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   EXPECT_THAT(normalizer->NormalizeTerm(""),
               EqualsNormalizedTerm(""));
@@ -209,8 +219,9 @@ TEST(MapNormalizerTest, HiraganaToKatakana) {
 
 TEST(MapNormalizerTest, Truncate) {
   {
+    NormalizerOptions options(/*max_term_byte_size=*/5);
     ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                    /*max_term_byte_size=*/5));
+        options));
 
     // Won't be truncated
     EXPECT_THAT(normalizer->NormalizeTerm("hi"), EqualsNormalizedTerm("hi"));
@@ -232,8 +243,9 @@ TEST(MapNormalizerTest, Truncate) {
   }
 
   {
+    NormalizerOptions options(/*max_term_byte_size=*/2);
     ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                    /*max_term_byte_size=*/2));
+        options));
     // The Japanese character has 3 bytes, truncating it results in an empty
     // string.
     EXPECT_THAT(normalizer->NormalizeTerm(""), EqualsNormalizedTerm(""));
@@ -244,8 +256,9 @@ TEST(MapNormalizerTest, PrefixMatchLength) {
   // Verify that FindNormalizedMatchEndPosition will properly find the length of
   // the prefix match when given a non-normalized term and a normalized term
   // is a prefix of the non-normalized one.
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   // Upper to lower
   std::string term = "MDI";
@@ -293,8 +306,9 @@ TEST(MapNormalizerTest, SharedPrefixMatchLength) {
   // Verify that FindNormalizedMatchEndPosition will properly find the length of
   // the prefix match when given a non-normalized term and a normalized term
   // that share a common prefix.
+  NormalizerOptions options(/*max_term_byte_size=*/1000);
   ICING_ASSERT_OK_AND_ASSIGN(auto normalizer, normalizer_factory::Create(
-                                                  /*max_term_byte_size=*/1000));
+      options));
 
   // Upper to lower
   std::string term = "MDI";
diff --git a/icing/transform/normalizer-factory.h b/icing/transform/normalizer-factory.h
index f1f3f62..6a9709c 100644
--- a/icing/transform/normalizer-factory.h
+++ b/icing/transform/normalizer-factory.h
@@ -18,7 +18,7 @@
 #include <memory>
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
-#include "icing/absl_ports/canonical_errors.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 
 namespace icing {
@@ -26,15 +26,14 @@ namespace lib {
 
 namespace normalizer_factory {
 
-// Creates a normalizer. max_term_byte_size enforces the max size of text after
-// normalization, text will be truncated if exceeds the max size.
+// Creates a normalizer.
 //
 // Returns:
 //   A normalizer on success
-//   INVALID_ARGUMENT if max_term_byte_size <= 0
+//   INVALID_ARGUMENT if options.max_term_byte_size <= 0
 //   INTERNAL_ERROR on errors
 libtextclassifier3::StatusOr<std::unique_ptr<Normalizer>> Create(
-    int max_term_byte_size);
+    const NormalizerOptions& options);
 
 }  // namespace normalizer_factory
 
diff --git a/icing/transform/normalizer-options.h b/icing/transform/normalizer-options.h
new file mode 100644
index 0000000..b4f4de2
--- /dev/null
+++ b/icing/transform/normalizer-options.h
@@ -0,0 +1,46 @@
+// Copyright (C) 2024 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_TRANSFORM_NORMALIZER_OPTIONS_H_
+#define ICING_TRANSFORM_NORMALIZER_OPTIONS_H_
+
+namespace icing {
+namespace lib {
+
+// TODO: b/332382299 - Avoid using default values in the NormalizerOptions
+// constructor. This can lead to unexpected behavior.
+struct NormalizerOptions {
+  explicit NormalizerOptions(int max_term_byte_size,
+                             bool enable_icu_normalizer = false)
+      : max_term_byte_size(max_term_byte_size),
+        enable_icu_normalizer(enable_icu_normalizer) {}
+
+  // max_term_byte_size enforces the max size of text after normalization,
+  // text will be truncated if exceeds the max size.
+  int max_term_byte_size;
+
+  // Determines whether to use an ICU based normalizer
+  // in icu-with-map-normalizer-factory or not.
+  // The default value is false, which means that the fallback option of a
+  // map based normalizer will be used.
+  //
+  // This flag is a no-op for all other normalizer factories because they
+  // only support one normalizer type.
+  bool enable_icu_normalizer;
+};
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_TRANSFORM_NORMALIZER_OPTIONS_H_
diff --git a/icing/util/character-iterator.cc b/icing/util/character-iterator.cc
index 3e310e9..8d9cca2 100644
--- a/icing/util/character-iterator.cc
+++ b/icing/util/character-iterator.cc
@@ -36,6 +36,18 @@ int GetUTF8StartPosition(std::string_view text, int current_byte_index) {
 }  // namespace
 
 UChar32 CharacterIterator::GetCurrentChar() const {
+  if (utf8_index_ > text_.length() || utf8_index_ < 0) {
+    return i18n_utils::kInvalidUChar32;
+  }
+
+  if (utf8_index_ == text_.length()) {
+    // This is allowed and it means the iterator is at the end. Since
+    // std::string_view is not guaranteed to be null-terminated, we cannot read
+    // any bytes out of bound.
+    // Therefore, return 0 (null character) directly here.
+    return 0;
+  }
+
   if (cached_current_char_ == i18n_utils::kInvalidUChar32) {
     // Our indices point to the right character, we just need to read that
     // character. No need to worry about an error. If GetUChar32At fails, then
@@ -52,15 +64,21 @@ bool CharacterIterator::MoveToUtf8(int desired_utf8_index) {
 }
 
 bool CharacterIterator::AdvanceToUtf8(int desired_utf8_index) {
-  ResetToStartIfNecessary();
-
-  if (desired_utf8_index > text_.length()) {
-    // Enforce the requirement.
+  // Check the boundary first to ensure we only handle desired_utf8_index in
+  // range [0, text_.length()].
+  //
+  // Note that desired_utf8_index == text_.length() is allowed.
+  if (desired_utf8_index > text_.length() || desired_utf8_index < 0) {
     return false;
   }
+
+  ResetToStartIfNecessary();
+
   // Need to work forwards.
   UChar32 uchar32 = cached_current_char_;
   while (utf8_index_ < desired_utf8_index) {
+    // At this point, utf8_index_ is a valid index in range [0, text_length() -
+    // 1], so we can call GetUChar32At safely.
     uchar32 =
         i18n_utils::GetUChar32At(text_.data(), text_.length(), utf8_index_);
     if (uchar32 == i18n_utils::kInvalidUChar32) {
@@ -77,8 +95,19 @@ bool CharacterIterator::AdvanceToUtf8(int desired_utf8_index) {
     utf16_index_ += i18n_utils::GetUtf16Length(uchar32);
     ++utf32_index_;
   }
-  cached_current_char_ =
-      i18n_utils::GetUChar32At(text_.data(), text_.length(), utf8_index_);
+
+  if (utf8_index_ == text_.length()) {
+    // This is allowed and it means the iterator is at the end. Since
+    // std::string_view is not guaranteed to be null-terminated, we cannot read
+    // any bytes out of bound.
+    // Therefore, return 0 (null character) directly here.
+    cached_current_char_ = 0;
+  } else {
+    // At this point, utf8_index_ is a valid index in range [0, text_length() -
+    // 1], so we can call GetUChar32At safely.
+    cached_current_char_ =
+        i18n_utils::GetUChar32At(text_.data(), text_.length(), utf8_index_);
+  }
   return true;
 }
 
@@ -263,8 +292,12 @@ void CharacterIterator::ResetToStartIfNecessary() {
     utf8_index_ = 0;
     utf16_index_ = 0;
     utf32_index_ = 0;
-    cached_current_char_ =
-        i18n_utils::GetUChar32At(text_.data(), text_.length(), 0);
+    if (!text_.empty()) {
+      cached_current_char_ =
+          i18n_utils::GetUChar32At(text_.data(), text_.length(), 0);
+    } else {
+      cached_current_char_ = i18n_utils::kInvalidUChar32;
+    }
   }
 }
 
diff --git a/icing/util/character-iterator.h b/icing/util/character-iterator.h
index 0960965..391c863 100644
--- a/icing/util/character-iterator.h
+++ b/icing/util/character-iterator.h
@@ -28,18 +28,25 @@ namespace lib {
 class CharacterIterator {
  public:
   explicit CharacterIterator(std::string_view text)
-      : CharacterIterator(text, 0, 0, 0) {}
-
-  CharacterIterator(std::string_view text, int utf8_index, int utf16_index,
-                    int utf32_index)
       : text_(text),
         cached_current_char_(i18n_utils::kInvalidUChar32),
-        utf8_index_(utf8_index),
-        utf16_index_(utf16_index),
-        utf32_index_(utf32_index) {}
+        utf8_index_(0),
+        utf16_index_(0),
+        utf32_index_(0) {}
+
+  CharacterIterator() : utf8_index_(-1), utf16_index_(-1), utf32_index_(-1) {}
 
   // Returns the character that the iterator currently points to.
   // i18n_utils::kInvalidUChar32 if unable to read that character.
+  //
+  // REQUIRES: the instance is not in an undefined state (i.e. all previous
+  //   calls succeeded).
+  //
+  // RETURNS:
+  //   - Null character if the iterator is at the end of the text.
+  //   - The character that the iterator currently points to, if the iterator is
+  //     within the text.
+  //   - i18n_utils::kInvalidUChar32, if unable to decode the character.
   UChar32 GetCurrentChar() const;
 
   // Moves current position to desired_utf8_index.
@@ -48,9 +55,20 @@ class CharacterIterator {
 
   // Advances from current position to the character that includes the specified
   // UTF-8 index.
-  // REQUIRES: desired_utf8_index <= text_.length()
-  // desired_utf8_index is allowed to point one index past the end, but no
-  // further.
+  //
+  // desired_utf8_index should be in range [0, text_.length()]. Note that it is
+  // allowed to point one index past the end (i.e. equals text_.length()), but
+  // no further.
+  //
+  // REQUIRES:
+  //   - The instance is not in an undefined state (i.e. all previous calls
+  //     succeeded).
+  //   - The current position is not ahead of desired_utf8_index, i.e.
+  //     utf8_index() <= desired_utf8_index.
+  //
+  // RETURNS:
+  //   - True if successfully advanced.
+  //   - False otherwise. Also the iterator will be in an undefined state.
   bool AdvanceToUtf8(int desired_utf8_index);
 
   // Rewinds from current position to the character that includes the specified
@@ -86,6 +104,12 @@ class CharacterIterator {
   // REQUIRES: 0 <= desired_utf32_index
   bool RewindToUtf32(int desired_utf32_index);
 
+  bool is_valid() const {
+    return text_.data() != nullptr && utf8_index_ >= 0 && utf16_index_ >= 0 &&
+           utf32_index_ >= 0;
+  }
+
+  std::string_view text() const { return text_; }
   int utf8_index() const { return utf8_index_; }
   int utf16_index() const { return utf16_index_; }
   int utf32_index() const { return utf32_index_; }
diff --git a/icing/util/character-iterator_test.cc b/icing/util/character-iterator_test.cc
index 195a47b..a7ca81c 100644
--- a/icing/util/character-iterator_test.cc
+++ b/icing/util/character-iterator_test.cc
@@ -14,253 +14,340 @@
 
 #include "icing/util/character-iterator.h"
 
+#include <cstring>
+#include <string_view>
+
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/testing/common-matchers.h"
 #include "icing/testing/icu-i18n-test-utils.h"
 
 namespace icing {
 namespace lib {
 
+namespace {
+
 using ::testing::Eq;
 using ::testing::IsFalse;
 using ::testing::IsTrue;
 
+TEST(CharacterIteratorTest, DefaultInstanceShouldBeInvalid) {
+  CharacterIterator iterator;
+  EXPECT_THAT(iterator.is_valid(), IsFalse());
+}
+
+TEST(CharacterIteratorTest, EmptyText) {
+  constexpr std::string_view kText = "Dnde est la biblioteca?";
+  std::string_view empty_text(kText.data(), 0);
+
+  CharacterIterator iterator(empty_text);
+  EXPECT_THAT(iterator.is_valid(), IsTrue());
+  EXPECT_THAT(iterator.GetCurrentChar(), Eq(0));
+}
+
 TEST(CharacterIteratorTest, BasicUtf8) {
   constexpr std::string_view kText = "Dnde est la biblioteca?";
+
   CharacterIterator iterator(kText);
+  EXPECT_THAT(iterator.is_valid(), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
 
   EXPECT_THAT(iterator.AdvanceToUtf8(4), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/3, /*utf16_index=*/2,
-                                   /*utf32_index=*/2)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/3,
+                                      /*expected_utf16_index=*/2,
+                                      /*expected_utf32_index=*/2));
 
   EXPECT_THAT(iterator.AdvanceToUtf8(18), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("b"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/18, /*utf16_index=*/15,
-                                   /*utf32_index=*/15)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/18,
+                                      /*expected_utf16_index=*/15,
+                                      /*expected_utf32_index=*/15));
 
   EXPECT_THAT(iterator.AdvanceToUtf8(28), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("?"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/28, /*utf16_index=*/25,
-                                   /*utf32_index=*/25)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/28,
+                                      /*expected_utf16_index=*/25,
+                                      /*expected_utf32_index=*/25));
 
+  // Advance to the end of the string. This is allowed and we should get null
+  // character.
   EXPECT_THAT(iterator.AdvanceToUtf8(29), IsTrue());
   EXPECT_THAT(iterator.GetCurrentChar(), Eq(0));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/29, /*utf16_index=*/26,
-                                   /*utf32_index=*/26)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/29,
+                                      /*expected_utf16_index=*/26,
+                                      /*expected_utf32_index=*/26));
 
   EXPECT_THAT(iterator.RewindToUtf8(28), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("?"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/28, /*utf16_index=*/25,
-                                   /*utf32_index=*/25)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/28,
+                                      /*expected_utf16_index=*/25,
+                                      /*expected_utf32_index=*/25));
 
   EXPECT_THAT(iterator.RewindToUtf8(18), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("b"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/18, /*utf16_index=*/15,
-                                   /*utf32_index=*/15)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/18,
+                                      /*expected_utf16_index=*/15,
+                                      /*expected_utf32_index=*/15));
 
   EXPECT_THAT(iterator.RewindToUtf8(4), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/3, /*utf16_index=*/2,
-                                   /*utf32_index=*/2)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/3,
+                                      /*expected_utf16_index=*/2,
+                                      /*expected_utf32_index=*/2));
 
   EXPECT_THAT(iterator.RewindToUtf8(0), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/0, /*utf16_index=*/0,
-                                   /*utf32_index=*/0)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/0,
+                                      /*expected_utf16_index=*/0,
+                                      /*expected_utf32_index=*/0));
 }
 
 TEST(CharacterIteratorTest, BasicUtf16) {
   constexpr std::string_view kText = "Dnde est la biblioteca?";
+
   CharacterIterator iterator(kText);
+  EXPECT_THAT(iterator.is_valid(), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
 
   EXPECT_THAT(iterator.AdvanceToUtf16(2), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/3, /*utf16_index=*/2,
-                                   /*utf32_index=*/2)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/3,
+                                      /*expected_utf16_index=*/2,
+                                      /*expected_utf32_index=*/2));
 
   EXPECT_THAT(iterator.AdvanceToUtf16(15), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("b"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/18, /*utf16_index=*/15,
-                                   /*utf32_index=*/15)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/18,
+                                      /*expected_utf16_index=*/15,
+                                      /*expected_utf32_index=*/15));
 
   EXPECT_THAT(iterator.AdvanceToUtf16(25), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("?"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/28, /*utf16_index=*/25,
-                                   /*utf32_index=*/25)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/28,
+                                      /*expected_utf16_index=*/25,
+                                      /*expected_utf32_index=*/25));
 
+  // Advance to the end of the string. This is allowed and we should get null
+  // character.
   EXPECT_THAT(iterator.AdvanceToUtf16(26), IsTrue());
   EXPECT_THAT(iterator.GetCurrentChar(), Eq(0));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/29, /*utf16_index=*/26,
-                                   /*utf32_index=*/26)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/29,
+                                      /*expected_utf16_index=*/26,
+                                      /*expected_utf32_index=*/26));
 
   EXPECT_THAT(iterator.RewindToUtf16(25), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("?"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/28, /*utf16_index=*/25,
-                                   /*utf32_index=*/25)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/28,
+                                      /*expected_utf16_index=*/25,
+                                      /*expected_utf32_index=*/25));
 
   EXPECT_THAT(iterator.RewindToUtf16(15), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("b"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/18, /*utf16_index=*/15,
-                                   /*utf32_index=*/15)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/18,
+                                      /*expected_utf16_index=*/15,
+                                      /*expected_utf32_index=*/15));
 
   EXPECT_THAT(iterator.RewindToUtf16(2), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/3, /*utf16_index=*/2,
-                                   /*utf32_index=*/2)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/3,
+                                      /*expected_utf16_index=*/2,
+                                      /*expected_utf32_index=*/2));
 
-  EXPECT_THAT(iterator.RewindToUtf8(0), IsTrue());
+  EXPECT_THAT(iterator.RewindToUtf16(0), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/0, /*utf16_index=*/0,
-                                   /*utf32_index=*/0)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/0,
+                                      /*expected_utf16_index=*/0,
+                                      /*expected_utf32_index=*/0));
 }
 
 TEST(CharacterIteratorTest, BasicUtf32) {
   constexpr std::string_view kText = "Dnde est la biblioteca?";
+
   CharacterIterator iterator(kText);
+  EXPECT_THAT(iterator.is_valid(), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
 
   EXPECT_THAT(iterator.AdvanceToUtf32(2), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/3, /*utf16_index=*/2,
-                                   /*utf32_index=*/2)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/3,
+                                      /*expected_utf16_index=*/2,
+                                      /*expected_utf32_index=*/2));
 
   EXPECT_THAT(iterator.AdvanceToUtf32(15), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("b"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/18, /*utf16_index=*/15,
-                                   /*utf32_index=*/15)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/18,
+                                      /*expected_utf16_index=*/15,
+                                      /*expected_utf32_index=*/15));
 
   EXPECT_THAT(iterator.AdvanceToUtf32(25), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("?"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/28, /*utf16_index=*/25,
-                                   /*utf32_index=*/25)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/28,
+                                      /*expected_utf16_index=*/25,
+                                      /*expected_utf32_index=*/25));
 
+  // Advance to the end of the string. This is allowed and we should get null
+  // character.
   EXPECT_THAT(iterator.AdvanceToUtf32(26), IsTrue());
   EXPECT_THAT(iterator.GetCurrentChar(), Eq(0));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/29, /*utf16_index=*/26,
-                                   /*utf32_index=*/26)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/29,
+                                      /*expected_utf16_index=*/26,
+                                      /*expected_utf32_index=*/26));
 
   EXPECT_THAT(iterator.RewindToUtf32(25), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("?"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/28, /*utf16_index=*/25,
-                                   /*utf32_index=*/25)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/28,
+                                      /*expected_utf16_index=*/25,
+                                      /*expected_utf32_index=*/25));
 
   EXPECT_THAT(iterator.RewindToUtf32(15), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("b"));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/18, /*utf16_index=*/15,
-                                   /*utf32_index=*/15)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/18,
+                                      /*expected_utf16_index=*/15,
+                                      /*expected_utf32_index=*/15));
 
   EXPECT_THAT(iterator.RewindToUtf32(2), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/3, /*utf16_index=*/2,
-                                   /*utf32_index=*/2)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/3,
+                                      /*expected_utf16_index=*/2,
+                                      /*expected_utf32_index=*/2));
 
   EXPECT_THAT(iterator.RewindToUtf32(0), IsTrue());
   EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq(""));
   EXPECT_THAT(iterator,
-              Eq(CharacterIterator(kText, /*utf8_index=*/0, /*utf16_index=*/0,
-                                   /*utf32_index=*/0)));
+              EqualsCharacterIterator(kText, /*expected_utf8_index=*/0,
+                                      /*expected_utf16_index=*/0,
+                                      /*expected_utf32_index=*/0));
 }
 
 TEST(CharacterIteratorTest, InvalidUtf) {
   // "\255" is an invalid sequence.
   constexpr std::string_view kText = "foo \255 bar";
   CharacterIterator iterator(kText);
+  EXPECT_THAT(iterator.is_valid(), IsTrue());
 
-  // Try to advance to the 'b' in 'bar'. This will fail and leave us pointed at
-  // the invalid sequence '\255'. Get CurrentChar() should return an invalid
-  // character.
+  // Try to advance to the 'b' in 'bar'. This will fail. Also the iterator will
+  // be in an undefined state, so no need to verify the state or
+  // GetCurrentChar().
   EXPECT_THAT(iterator.AdvanceToUtf8(6), IsFalse());
-  EXPECT_THAT(iterator.GetCurrentChar(), Eq(i18n_utils::kInvalidUChar32));
-  CharacterIterator exp_iterator(kText, /*utf8_index=*/4, /*utf16_index=*/4,
-                                 /*utf32_index=*/4);
-  EXPECT_THAT(iterator, Eq(exp_iterator));
-
   EXPECT_THAT(iterator.AdvanceToUtf16(6), IsFalse());
-  EXPECT_THAT(iterator.GetCurrentChar(), Eq(i18n_utils::kInvalidUChar32));
-  EXPECT_THAT(iterator, Eq(exp_iterator));
-
   EXPECT_THAT(iterator.AdvanceToUtf32(6), IsFalse());
-  EXPECT_THAT(iterator.GetCurrentChar(), Eq(i18n_utils::kInvalidUChar32));
-  EXPECT_THAT(iterator, Eq(exp_iterator));
+}
 
-  // Create the iterator with it pointing at the 'b' in 'bar'.
-  iterator = CharacterIterator(kText, /*utf8_index=*/6, /*utf16_index=*/6,
-                               /*utf32_index=*/6);
-  EXPECT_THAT(UCharToString(iterator.GetCurrentChar()), Eq("b"));
+TEST(CharacterIteratorTest, AdvanceToUtf8_emptyText) {
+  // Create an uninitialized buffer.
+  char buf[30];
+
+  // Create a string_view that points to the 10-th byte of the buffer with
+  // length 0.
+  std::string_view text(buf + 10, 0);
+
+  CharacterIterator iter0(text);
+  // Advance to utf8 index 0. This should succeed without memory or
+  // use-of-uninitialized-value errors (tested with "--config=msan").
+  EXPECT_THAT(iter0.AdvanceToUtf8(0), IsTrue());
+  // We should get null character after succeeding.
+  EXPECT_THAT(iter0.GetCurrentChar(), Eq(0));
+
+  // Advance to utf8 indices with positive values. This should fail successfully
+  // without memory or use-of-uninitialized-value errors (tested with
+  // "--config=msan").
+  CharacterIterator iter1(text);
+  EXPECT_THAT(iter1.AdvanceToUtf8(1), IsFalse());
+
+  CharacterIterator iter2(text);
+  EXPECT_THAT(iter2.AdvanceToUtf8(2), IsFalse());
+
+  // Advance to utf8 indices with negative values. This should fail successfully
+  // without memory or use-of-uninitialized-value errors (tested with
+  // "--config=msan").
+  CharacterIterator iter3(text);
+  EXPECT_THAT(iter1.AdvanceToUtf8(-1), IsFalse());
+
+  CharacterIterator iter4(text);
+  EXPECT_THAT(iter2.AdvanceToUtf8(-2), IsFalse());
+}
+
+TEST(CharacterIteratorTest, AdvanceToUtf8_negativeIndex) {
+  constexpr std::string_view kText = "abcdefghijklmnopqrstuvwxyz";
+  // Create a buffer with extra 4 bytes. Copy kText to the last 26 bytes and
+  // intentionally leave the first 4 bytes uninitialized.
+  char buf[30];
+  memcpy(buf + 4, kText.data(), kText.size());
+
+  std::string_view text(buf + 4, kText.size());
+
+  // Advance to negative utf8 indices. This should fail successfully without
+  // memory or use-of-uninitialized-value errors (tested with "--config=msan").
 
-  // Try to advance to the last 'o' in 'foo'. This will fail and leave us
-  // pointed at the ' ' before the invalid sequence '\255'.
-  exp_iterator = CharacterIterator(kText, /*utf8_index=*/5, /*utf16_index=*/5,
-                                   /*utf32_index=*/5);
-  EXPECT_THAT(iterator.RewindToUtf8(2), IsFalse());
-  EXPECT_THAT(iterator.GetCurrentChar(), Eq(' '));
-  EXPECT_THAT(iterator, Eq(exp_iterator));
-
-  EXPECT_THAT(iterator.RewindToUtf16(2), IsFalse());
-  EXPECT_THAT(iterator.GetCurrentChar(), Eq(' '));
-  EXPECT_THAT(iterator, Eq(exp_iterator));
-
-  EXPECT_THAT(iterator.RewindToUtf32(2), IsFalse());
-  EXPECT_THAT(iterator.GetCurrentChar(), Eq(' '));
-  EXPECT_THAT(iterator, Eq(exp_iterator));
+  CharacterIterator iter0(text);
+  EXPECT_THAT(iter0.AdvanceToUtf8(-1), IsFalse());
+
+  CharacterIterator iter1(text);
+  EXPECT_THAT(iter1.AdvanceToUtf8(-2), IsFalse());
 }
 
-TEST(CharacterIteratorTest, MoveToUtfNegativeIndex) {
-  constexpr std::string_view kText = "Dnde est la biblioteca?";
+TEST(CharacterIteratorTest, AdvanceToUtf8_indexEqCharLength) {
+  constexpr std::string_view kText = "abcdefghijklmnopqrstuvwxyz";
+  // Create a buffer with extra 4 bytes. Copy kText to the first 26 bytes and
+  // intentionally leave the last 4 bytes uninitialized.
+  char buf[30];
+  memcpy(buf, kText.data(), kText.size());
+
+  std::string_view text(buf, kText.size());
+
+  CharacterIterator iter0(text);
+  // Advance to utf8 index == kText.size(). This should succeed without memory
+  // or use-of-uninitialized-value errors (tested with "--config=msan").
+  EXPECT_THAT(iter0.AdvanceToUtf8(kText.size()), IsTrue());
+  // We should get null character after succeeding.
+  EXPECT_THAT(iter0.GetCurrentChar(), Eq(0));
+}
+
+TEST(CharacterIteratorTest, AdvanceToUtf8_indexGtCharLength) {
+  constexpr std::string_view kText = "abcdefghijklmnopqrstuvwxyz";
+  // Create a buffer with extra 4 bytes. Copy kText to the first 26 bytes and
+  // intentionally leave the last 4 bytes uninitialized.
+  char buf[30];
+  memcpy(buf, kText.data(), kText.size());
 
-  CharacterIterator iterator_utf8(kText, /*utf8_index=*/-1, /*utf16_index=*/0,
-                             /*utf32_index=*/0);
-  // We should be able to successfully move when the index is negative.
-  EXPECT_THAT(iterator_utf8.MoveToUtf8(0), IsTrue());
-  // The character cache should be reset and contain the first character when
-  // resetting to index 0.
-  EXPECT_THAT(UCharToString(iterator_utf8.GetCurrentChar()), Eq(""));
-  EXPECT_THAT(iterator_utf8.utf8_index(), Eq(0));
-  EXPECT_THAT(iterator_utf8.utf16_index(), Eq(0));
-  EXPECT_THAT(iterator_utf8.utf32_index(), Eq(0));
-
-  CharacterIterator iterator_utf16(kText, /*utf8_index=*/0, /*utf16_index=*/-1,
-                             /*utf32_index=*/0);
-  EXPECT_THAT(iterator_utf16.MoveToUtf16(1), IsTrue());
-  EXPECT_THAT(iterator_utf16.GetCurrentChar(), Eq('D'));
-  EXPECT_THAT(iterator_utf16.utf8_index(), Eq(2));
-  EXPECT_THAT(iterator_utf16.utf16_index(), Eq(1));
-  EXPECT_THAT(iterator_utf16.utf32_index(), Eq(1));
-
-  CharacterIterator iterator_utf32(kText, /*utf8_index=*/0, /*utf16_index=*/0,
-                             /*utf32_index=*/-1);
-  EXPECT_THAT(iterator_utf32.MoveToUtf32(2), IsTrue());
-  EXPECT_THAT(UCharToString(iterator_utf32.GetCurrentChar()), Eq(""));
-  EXPECT_THAT(iterator_utf32.utf8_index(), Eq(3));
-  EXPECT_THAT(iterator_utf32.utf16_index(), Eq(2));
-  EXPECT_THAT(iterator_utf32.utf32_index(), Eq(2));
+  std::string_view text(buf, kText.size());
+
+  // Advance to utf8 index greater than the length of the string. This should
+  // fail successfully without memory or use-of-uninitialized-value errors
+  // (tested with "--config=msan").
+
+  CharacterIterator iter0(text);
+  EXPECT_THAT(iter0.AdvanceToUtf8(kText.size() + 1), IsFalse());
+
+  CharacterIterator iter1(text);
+  EXPECT_THAT(iter0.AdvanceToUtf8(kText.size() + 2), IsFalse());
 }
 
+}  // namespace
+
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/util/crc32.cc b/icing/util/crc32.cc
index d169acf..c182f31 100644
--- a/icing/util/crc32.cc
+++ b/icing/util/crc32.cc
@@ -15,9 +15,12 @@
 #include "icing/util/crc32.h"
 
 #include <cstdint>
+#include <string>
+#include <string_view>
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/canonical_errors.h"
+#include "icing/absl_ports/str_cat.h"
 #include "icing/legacy/core/icing-string-util.h"
 #include "icing/portable/zlib.h"
 
@@ -46,6 +49,15 @@ uint32_t Crc32::Append(const std::string_view str) {
 libtextclassifier3::StatusOr<uint32_t> Crc32::UpdateWithXor(
     const std::string_view xored_str, int full_data_size, int position) {
   // For appending, use Append().
+  if (full_data_size < 0) {
+    return absl_ports::InvalidArgumentError(
+        absl_ports::StrCat("full_data_size must be greater than 0, but was ",
+                           std::to_string(full_data_size)));
+  }
+  if (position < 0) {
+    return absl_ports::InvalidArgumentError(absl_ports::StrCat(
+        "position must be greater than 0, but was ", std::to_string(position)));
+  }
   if (position + xored_str.length() > full_data_size) {
     return absl_ports::InvalidArgumentError(IcingStringUtil::StringPrintf(
         "offset position %d + length %zd > full data size %d", position,
diff --git a/icing/util/crc32_test.cc b/icing/util/crc32_test.cc
index ab8582a..d6f4c46 100644
--- a/icing/util/crc32_test.cc
+++ b/icing/util/crc32_test.cc
@@ -14,8 +14,13 @@
 
 #include "icing/util/crc32.h"
 
+#include <cstddef>
 #include <cstdint>
+#include <cstdlib>
+#include <string>
+#include <string_view>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/portable/zlib.h"
@@ -102,6 +107,19 @@ TEST(Crc32Test, UpdateAtPosition) {
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
+TEST(Crc32Test, InvalidParameters) {
+  Crc32 crc32_test{};
+  EXPECT_THAT(
+      crc32_test.UpdateWithXor("12345", /*full_data_size=*/-1, /*position=*/0),
+      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(
+      crc32_test.UpdateWithXor("12345", /*full_data_size=*/2, /*position=*/-1),
+      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(
+      crc32_test.UpdateWithXor("", /*full_data_size=*/-10, /*position=*/-10),
+      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+}
+
 }  // namespace
 
 }  // namespace lib
diff --git a/icing/util/document-validator_test.cc b/icing/util/document-validator_test.cc
index 2784522..0e366a7 100644
--- a/icing/util/document-validator_test.cc
+++ b/icing/util/document-validator_test.cc
@@ -140,8 +140,7 @@ class DocumentValidatorTest : public ::testing::Test {
         schema_store_, SchemaStore::Create(&filesystem_, schema_dir_,
                                            &fake_clock_, feature_flags_.get()));
     ASSERT_THAT(schema_store_->SetSchema(
-                    schema, /*ignore_errors_and_delete_documents=*/false,
-                    /*allow_circular_schema_definitions=*/false),
+                    schema, /*ignore_errors_and_delete_documents=*/false),
                 IsOk());
 
     document_validator_ =
@@ -496,8 +495,7 @@ TEST_F(DocumentValidatorTest, HandleTypeConfigMapChangesOk) {
       SchemaStore::Create(&filesystem_, custom_schema_dir, &fake_clock_,
                           feature_flags_.get()));
   ASSERT_THAT(schema_store->SetSchema(
-                  email_schema, /*ignore_errors_and_delete_documents=*/false,
-                  /*allow_circular_schema_definitions=*/false),
+                  email_schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
   DocumentValidator document_validator(schema_store.get());
@@ -530,8 +528,7 @@ TEST_F(DocumentValidatorTest, HandleTypeConfigMapChangesOk) {
   // separately
   ASSERT_THAT(
       schema_store->SetSchema(email_and_conversation_schema,
-                              /*ignore_errors_and_delete_documents=*/false,
-                              /*allow_circular_schema_definitions=*/false),
+                              /*ignore_errors_and_delete_documents=*/false),
       IsOk());
 
   ICING_EXPECT_OK(document_validator.Validate(conversation));
diff --git a/icing/util/i18n-utils_test.cc b/icing/util/i18n-utils_test.cc
index a1e8d4e..fd07db9 100644
--- a/icing/util/i18n-utils_test.cc
+++ b/icing/util/i18n-utils_test.cc
@@ -71,6 +71,28 @@ TEST(IcuI18nUtilsTest, IsAlphabeticAt) {
             3);
 }
 
+TEST(IcuI18nUtilsTest, IsWhitespaceAt) {
+  // Test ASCII and non-ASCII whitespaces
+
+  // ASCII whitespaces:
+  EXPECT_TRUE(i18n_utils::IsWhitespaceAt("\u0009",
+                                         /*position=*/0));  // horizontal tab
+  EXPECT_TRUE(i18n_utils::IsWhitespaceAt("\u000a",
+                                         /*position=*/0));  // line feed '\n'
+  EXPECT_TRUE(
+      i18n_utils::IsWhitespaceAt("\u000b", /*position=*/0));  // vertical tab
+  EXPECT_TRUE(
+      i18n_utils::IsWhitespaceAt("\u000c", /*position=*/0));  // form feed
+  EXPECT_TRUE(i18n_utils::IsWhitespaceAt("\u000d",
+                                         /*position=*/0));  // carriage return
+  EXPECT_TRUE(
+      i18n_utils::IsWhitespaceAt("\u0020", /*position=*/0));  // space ' '
+
+  // Non-ASCII whitespaces:
+  EXPECT_TRUE(i18n_utils::IsWhitespaceAt(
+      "\u00a0", /*position=*/0));  // Non-breaking space
+}
+
 TEST(IcuI18nUtilsTest, GetUtf8Length) {
   // Test alphabetic and non-alphabetic ascii characters
   constexpr std::string_view kSomeAscii = "iJ?9";
diff --git a/icing/util/logging.cc b/icing/util/logging.cc
index f60526b..fe14be0 100644
--- a/icing/util/logging.cc
+++ b/icing/util/logging.cc
@@ -64,6 +64,11 @@ constexpr uint32_t CalculateLoggingLevel(LogSeverity::Code severity,
 // The last 16 bits represent the current verbosity.
 std::atomic<uint32_t> global_logging_level = DEFAULT_LOGGING_LEVEL;
 
+// TODO(b/401363381): Remove this once we have a better way to log to
+// /dev/hvc2 in isolated storage.
+// Indicate whether we should force logging to /dev/hvc2 for ICING_LOG.
+std::atomic<bool> global_force_debug_logs = false;
+
 }  // namespace
 
 // Whether we should log according to the current logging level.
@@ -102,11 +107,30 @@ bool SetLoggingLevel(LogSeverity::Code severity, int16_t verbosity) {
   return true;
 }
 
+// TODO(b/401363381): Remove this once we have a better way to log to
+// /dev/hvc2 in isolated storage.
+void SetForceDebugLogging(bool force) {
+  // Using the relaxed order for better performance because we only need to
+  // guarantee the atomicity for this specific statement, without the need to
+  // worry about reordering.
+  global_force_debug_logs.store(force, std::memory_order_relaxed);
+}
+
+// TODO(b/401363381): Remove this once we have a better way to log to
+// /dev/hvc2 in isolated storage.
+bool GetForceDebugLogging() {
+  // Using the relaxed order for better performance because we only need to
+  // guarantee the atomicity for this specific statement, without the need to
+  // worry about reordering.
+  return global_force_debug_logs.load(std::memory_order_relaxed);
+}
+
 LogMessage::LogMessage(LogSeverity::Code severity, uint16_t verbosity,
                        const char *file_name, int line_number)
     : severity_(severity),
       verbosity_(verbosity),
       should_log_(ShouldLog(severity_, verbosity_)),
+      force_debug_logs_(GetForceDebugLogging()),
       stream_(should_log_) {
   if (should_log_) {
     stream_ << JumpToBasename(file_name) << ":" << line_number << ": ";
@@ -115,7 +139,8 @@ LogMessage::LogMessage(LogSeverity::Code severity, uint16_t verbosity,
 
 LogMessage::~LogMessage() {
   if (should_log_) {
-    LowLevelLogging(severity_, kIcingLoggingTag, stream_.message);
+    LowLevelLogging(severity_, kIcingLoggingTag, stream_.message,
+                    force_debug_logs_);
   }
   if (severity_ == LogSeverity::FATAL) {
     std::terminate();  // Will print a stacktrace (stdout or logcat).
diff --git a/icing/util/logging.h b/icing/util/logging.h
index 23280dc..415d055 100644
--- a/icing/util/logging.h
+++ b/icing/util/logging.h
@@ -39,6 +39,16 @@ bool ShouldLog(LogSeverity::Code severity, int16_t verbosity = 0);
 // The function will always return false when verbosity is negative.
 bool SetLoggingLevel(LogSeverity::Code severity, int16_t verbosity = 0);
 
+// TODO(b/401363381): Remove this once we have a better way to log to
+// /dev/hvc2 in isolated storage.
+// Indicate whether we should force logging to /dev/hvc2 for ICING_LOG.
+void SetForceDebugLogging(bool force);
+
+// TODO(b/401363381): Remove this once we have a better way to log to
+// /dev/hvc2 in isolated storage.
+// Get whether or not we should force logging to /dev/hvc2 for ICING_LOG.
+bool GetForceDebugLogging();
+
 // A tiny code footprint string stream for assembling log messages.
 struct LoggingStringStream {
   explicit LoggingStringStream(bool should_log) : should_log_(should_log) {}
@@ -123,6 +133,7 @@ class LogMessage {
   const LogSeverity::Code severity_;
   const uint16_t verbosity_;
   const bool should_log_;
+  const bool force_debug_logs_;
 
   // Stream that "prints" all info into a string (not to a file).  We construct
   // here the entire logging message and next print it in one operation.
diff --git a/icing/util/logging_raw.cc b/icing/util/logging_raw.cc
index 44dd000..09d0308 100644
--- a/icing/util/logging_raw.cc
+++ b/icing/util/logging_raw.cc
@@ -50,7 +50,7 @@ int GetAndroidLogLevel(LogSeverity::Code severity) {
 }  // namespace
 
 void LowLevelLogging(LogSeverity::Code severity, const std::string& tag,
-                     const std::string& message) {
+                     const std::string& message, const bool force_debug_logs) {
   const int android_log_level = GetAndroidLogLevel(severity);
 #if __ANDROID_API__ >= 30
   if (!__android_log_is_loggable(android_log_level, tag.c_str(),
@@ -58,7 +58,28 @@ void LowLevelLogging(LogSeverity::Code severity, const std::string& tag,
     return;
   }
 #endif  // __ANDROID_API__ >= 30
-  __android_log_write(android_log_level, tag.c_str(), message.c_str());
+  // TODO(b/401363381): Remove this once we have a better way to log to
+  // /dev/hvc2 in isolated storage.
+  if (force_debug_logs) {
+    // When isolated icing storage is enabled, the VM debug level determines
+    // whether icing debug logs are delivered. We want the icing debug logs
+    // to always be present. Thus force logging to /dev/hvc2.
+    const char* file_logger_path = "/dev/hvc2";
+    // "e" opens the file with the O_CLOEXEC flag. Icing should not be starting
+    // any other processes, but it is added as a precaution.
+    static FILE* stream = [&file_logger_path]() {
+      FILE* f = fopen(file_logger_path, "ae");
+      if (f != nullptr) {
+        return f;
+      }
+      fprintf(stderr, "Failed to open /dev/hvc2 for logging. "
+                      "Falling back to stderr.\n");
+      return stderr;
+    }();
+    fprintf(stream, "%s: %s\n", tag.c_str(), message.c_str());
+  } else {
+    __android_log_write(android_log_level, tag.c_str(), message.c_str());
+  }
 }
 
 }  // namespace lib
@@ -91,7 +112,7 @@ const char *LogSeverityToString(LogSeverity::Code severity) {
 }  // namespace
 
 void LowLevelLogging(LogSeverity::Code severity, const std::string &tag,
-                     const std::string &message) {
+                     const std::string &message, const bool force_debug_logs) {
   // TODO(b/146903474) Do not log to stderr for logs other than FATAL and ERROR.
   fprintf(stderr, "[%s] %s : %s\n", LogSeverityToString(severity), tag.c_str(),
           message.c_str());
diff --git a/icing/util/logging_raw.h b/icing/util/logging_raw.h
index 99dddb6..438e1a8 100644
--- a/icing/util/logging_raw.h
+++ b/icing/util/logging_raw.h
@@ -26,7 +26,7 @@ namespace lib {
 // severity.  From android/log.h: "the tag normally corresponds to the component
 // that emits the log message, and should be reasonably small".
 void LowLevelLogging(LogSeverity::Code severity, const std::string &tag,
-                     const std::string &message);
+                     const std::string &message, const bool force_debug_logs);
 
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/util/math-util.h b/icing/util/math-util.h
index 22f429f..8aab34e 100644
--- a/icing/util/math-util.h
+++ b/icing/util/math-util.h
@@ -17,6 +17,8 @@
 
 #include <cstdint>
 #include <limits>
+#include <utility>
+#include <vector>
 
 namespace icing {
 namespace lib {
@@ -91,6 +93,38 @@ inline uint32_t NextPowerOf2(uint32_t n) {
   return n;
 }
 
+// Applies a permutation to multiple containers in-place, which permutes
+// elements within the given containers according to the provided permutation
+// vector. permutation[i] specifies the new index for the element originally at
+// index i.
+template <typename... ContainerTypes>
+static void ApplyPermutation(const std::vector<int> &permutation,
+                             ContainerTypes &...values) {
+  std::vector<bool> done(permutation.size());
+  // Apply permutation
+  for (int i = 0; i < permutation.size(); ++i) {
+    if (done[i]) {
+      continue;
+    }
+    done[i] = true;
+    int curr = i;
+    int next = permutation[i];
+    // Since every finite permutation is formed by disjoint cycles, we can
+    // start with the current element, at index i, and swap the element at
+    // this position with whatever element that *should* be here. Then,
+    // continue to swap the original element, at its updated positions, with
+    // the element that should be occupying that position until the original
+    // element has reached *its* correct position. This completes applying the
+    // single cycle in the permutation.
+    while (next != i) {
+      (std::swap(values[curr], values[next]), ...);
+      done[next] = true;
+      curr = next;
+      next = permutation[next];
+    }
+  }
+}
+
 }  // namespace math_util
 
 }  // namespace lib
diff --git a/icing/util/scorable_property_set_test.cc b/icing/util/scorable_property_set_test.cc
index 1dc9f64..ec62520 100644
--- a/icing/util/scorable_property_set_test.cc
+++ b/icing/util/scorable_property_set_test.cc
@@ -152,8 +152,7 @@ class ScorablePropertySetTest : public ::testing::Test {
                                      .SetCardinality(CARDINALITY_REPEATED)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema_proto, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema_proto, /*ignore_errors_and_delete_documents=*/false));
     email_schema_type_id_ =
         schema_store_->GetSchemaTypeId("email").ValueOrDie();
     person_schema_type_id_ =
diff --git a/icing/util/status-macros.h b/icing/util/status-macros.h
index 58ab8b4..d15fa23 100644
--- a/icing/util/status-macros.h
+++ b/icing/util/status-macros.h
@@ -28,6 +28,14 @@
 
 #define ICING_RETURN_IF_ERROR(expr) TC3_RETURN_IF_ERROR(expr)
 
+#define ICING_RETURN_EXPRESSION_IF_ERROR(expr, error_expression)        \
+  if (::libtextclassifier3::StatusAdapter adapter{expr}) {              \
+  } else {                                                              \
+    ::libtextclassifier3::Status _(std::move(adapter).status());        \
+    (void)_; /* error_expression is allowed to not use this variable */ \
+    return (error_expression);                                          \
+  }
+
 #define ICING_ASSIGN_OR_RETURN(...)                            \
   TC_STATUS_MACROS_IMPL_GET_VARIADIC_(                         \
       (__VA_ARGS__, TC_STATUS_MACROS_IMPL_ASSIGN_OR_RETURN_3_, \
diff --git a/icing/util/status-util.h b/icing/util/status-util.h
new file mode 100644
index 0000000..1c6c37e
--- /dev/null
+++ b/icing/util/status-util.h
@@ -0,0 +1,102 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_UTIL_STATUS_UTIL_H_
+#define ICING_UTIL_STATUS_UTIL_H_
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/proto/status.pb.h"
+#include "icing/util/logging.h"
+
+namespace icing {
+namespace lib {
+
+namespace status_util {
+
+inline void TransformStatus(const libtextclassifier3::Status& internal_status,
+                            StatusProto* status_proto) {
+  StatusProto::Code code;
+  if (!internal_status.ok()) {
+    ICING_LOG(WARNING) << "Error: " << internal_status.error_code()
+                       << ", Message: " << internal_status.error_message();
+  }
+  switch (internal_status.CanonicalCode()) {
+    case libtextclassifier3::StatusCode::OK:
+      code = StatusProto::OK;
+      break;
+    case libtextclassifier3::StatusCode::DATA_LOSS:
+      code = StatusProto::WARNING_DATA_LOSS;
+      break;
+    case libtextclassifier3::StatusCode::INVALID_ARGUMENT:
+      code = StatusProto::INVALID_ARGUMENT;
+      break;
+    case libtextclassifier3::StatusCode::NOT_FOUND:
+      code = StatusProto::NOT_FOUND;
+      break;
+    case libtextclassifier3::StatusCode::FAILED_PRECONDITION:
+      code = StatusProto::FAILED_PRECONDITION;
+      break;
+    case libtextclassifier3::StatusCode::ABORTED:
+      code = StatusProto::ABORTED;
+      break;
+    case libtextclassifier3::StatusCode::INTERNAL:
+      // TODO(b/147699081): Cleanup our internal use of INTERNAL since it
+      // doesn't match with what it *should* indicate as described in
+      // go/icing-library-apis.
+      code = StatusProto::INTERNAL;
+      break;
+    case libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED:
+      // TODO(b/147699081): Note that we don't detect all cases of OUT_OF_SPACE
+      // (e.g. if the document log is full). And we use RESOURCE_EXHAUSTED
+      // internally to indicate other resources are exhausted (e.g.
+      // DocHitInfos) - although none of these are exposed through the API.
+      // Consider separating the two cases out more clearly.
+      code = StatusProto::OUT_OF_SPACE;
+      break;
+    case libtextclassifier3::StatusCode::ALREADY_EXISTS:
+      code = StatusProto::ALREADY_EXISTS;
+      break;
+    case libtextclassifier3::StatusCode::CANCELLED:
+      [[fallthrough]];
+    case libtextclassifier3::StatusCode::UNKNOWN:
+      [[fallthrough]];
+    case libtextclassifier3::StatusCode::DEADLINE_EXCEEDED:
+      [[fallthrough]];
+    case libtextclassifier3::StatusCode::PERMISSION_DENIED:
+      [[fallthrough]];
+    case libtextclassifier3::StatusCode::OUT_OF_RANGE:
+      [[fallthrough]];
+    case libtextclassifier3::StatusCode::UNIMPLEMENTED:
+      [[fallthrough]];
+    case libtextclassifier3::StatusCode::UNAVAILABLE:
+      [[fallthrough]];
+    case libtextclassifier3::StatusCode::UNAUTHENTICATED:
+      // Other internal status codes aren't supported externally yet. If it
+      // should be supported, add another switch-case above.
+      ICING_LOG(ERROR) << "Internal status code "
+                       << internal_status.error_code()
+                       << " not supported in the external API";
+      code = StatusProto::UNKNOWN;
+      break;
+  }
+  status_proto->set_code(code);
+  status_proto->set_message(internal_status.error_message());
+}
+
+}  // namespace status_util
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_UTIL_STATUS_UTIL_H_
diff --git a/icing/util/tokenized-document.cc b/icing/util/tokenized-document.cc
index e10fe25..576e0a2 100644
--- a/icing/util/tokenized-document.cc
+++ b/icing/util/tokenized-document.cc
@@ -69,14 +69,20 @@ libtextclassifier3::StatusOr<std::vector<TokenizedSection>> Tokenize(
 TokenizedDocument::Create(const SchemaStore* schema_store,
                           const LanguageSegmenter* language_segmenter,
                           DocumentProto document) {
+  // Since there are many std::string_view objects pointing to the document
+  // proto, we should make sure DocumentProto has a fixed address. The simplest
+  // way is to use a unique_ptr.
+  auto document_ptr = std::make_unique<DocumentProto>(std::move(document));
+
   DocumentValidator validator(schema_store);
-  ICING_RETURN_IF_ERROR(validator.Validate(document));
+  ICING_RETURN_IF_ERROR(validator.Validate(*document_ptr));
 
   ICING_ASSIGN_OR_RETURN(SectionGroup section_group,
-                         schema_store->ExtractSections(document));
+                         schema_store->ExtractSections(*document_ptr));
 
-  ICING_ASSIGN_OR_RETURN(JoinablePropertyGroup joinable_property_group,
-                         schema_store->ExtractJoinableProperties(document));
+  ICING_ASSIGN_OR_RETURN(
+      JoinablePropertyGroup joinable_property_group,
+      schema_store->ExtractJoinableProperties(*document_ptr));
 
   // Tokenize string sections
   ICING_ASSIGN_OR_RETURN(
@@ -84,7 +90,7 @@ TokenizedDocument::Create(const SchemaStore* schema_store,
       Tokenize(schema_store, language_segmenter,
                section_group.string_sections));
 
-  return TokenizedDocument(std::move(document),
+  return TokenizedDocument(std::move(document_ptr),
                            std::move(tokenized_string_sections),
                            std::move(section_group.integer_sections),
                            std::move(section_group.vector_sections),
diff --git a/icing/util/tokenized-document.h b/icing/util/tokenized-document.h
index 0337083..ae92311 100644
--- a/icing/util/tokenized-document.h
+++ b/icing/util/tokenized-document.h
@@ -16,6 +16,7 @@
 #define ICING_STORE_TOKENIZED_DOCUMENT_H_
 
 #include <cstdint>
+#include <memory>
 #include <string_view>
 #include <utility>
 #include <vector>
@@ -46,7 +47,7 @@ class TokenizedDocument {
       const SchemaStore* schema_store,
       const LanguageSegmenter* language_segmenter, DocumentProto document);
 
-  const DocumentProto& document() const { return document_; }
+  const DocumentProto& document() const { return *document_; }
 
   int32_t num_string_tokens() const {
     int32_t num_string_tokens = 0;
@@ -77,7 +78,7 @@ class TokenizedDocument {
  private:
   // Use TokenizedDocument::Create() to instantiate.
   explicit TokenizedDocument(
-      DocumentProto&& document,
+      std::unique_ptr<DocumentProto> document,
       std::vector<TokenizedSection>&& tokenized_string_sections,
       std::vector<Section<int64_t>>&& integer_sections,
       std::vector<Section<PropertyProto::VectorProto>>&& vector_sections,
@@ -88,7 +89,7 @@ class TokenizedDocument {
         vector_sections_(std::move(vector_sections)),
         joinable_property_group_(std::move(joinable_property_group)) {}
 
-  DocumentProto document_;
+  std::unique_ptr<DocumentProto> document_;
   std::vector<TokenizedSection> tokenized_string_sections_;
   std::vector<Section<int64_t>> integer_sections_;
   std::vector<Section<PropertyProto::VectorProto>> vector_sections_;
diff --git a/icing/util/tokenized-document_test.cc b/icing/util/tokenized-document_test.cc
index 2aa92d1..513b8d0 100644
--- a/icing/util/tokenized-document_test.cc
+++ b/icing/util/tokenized-document_test.cc
@@ -213,8 +213,7 @@ class TokenizedDocumentTest : public ::testing::Test {
                                      .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build();
     ICING_ASSERT_OK(schema_store_->SetSchema(
-        schema, /*ignore_errors_and_delete_documents=*/false,
-        /*allow_circular_schema_definitions=*/false));
+        schema, /*ignore_errors_and_delete_documents=*/false));
   }
 
   void TearDown() override {
diff --git a/isolated_storage_service/aidl/Android.bp b/isolated_storage_service/aidl/Android.bp
new file mode 100644
index 0000000..a56e39e
--- /dev/null
+++ b/isolated_storage_service/aidl/Android.bp
@@ -0,0 +1,24 @@
+package {
+    default_applicable_licenses: ["Android-Apache-2.0"],
+}
+
+aidl_interface {
+    name: "com.android.isolated_storage_service.aidl",
+    srcs: ["**/*.aidl"],
+    unstable: true,
+    flags: [
+        "-Werror",
+        "-Wno-mixed-oneway",
+    ],
+    backend: {
+        java: {
+            gen_rpc: true,
+            apex_available: ["com.android.appsearch"],
+        },
+        ndk: {
+            enabled: true,
+            apex_available: ["com.android.appsearch"],
+        },
+    },
+    min_sdk_version: "Tiramisu",
+}
diff --git a/isolated_storage_service/aidl/com/android/isolated_storage_service/IIcingSearchEngine.aidl b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIcingSearchEngine.aidl
new file mode 100644
index 0000000..4017e8f
--- /dev/null
+++ b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIcingSearchEngine.aidl
@@ -0,0 +1,107 @@
+/*
+ * Copyright 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.android.isolated_storage_service;
+
+/**
+ * The AIDL interface for the Icing search engine within the isolated storage service.
+ * These APIs generally map to the available APIs in the Icing search engine library at external/icing/java/src/com/google/android/icing/IcingSearchEngine.java.
+ */
+interface IIcingSearchEngine {
+  @nullable
+  /*InitializeResultProto*/ byte[] initialize(in byte[] icingSearchEngineOptionsProto);
+
+  void close();
+
+  @nullable
+  /*ResetResultProto*/ byte[] reset();
+
+  @nullable
+  /*SetSchemaResultProto*/ byte[] setSchema(in byte[] schemaProto, boolean ignoreErrorsAndDeleteDocuments);
+
+  @nullable
+  /*GetSchemaResultProto*/ byte[] getSchema();
+
+  @nullable
+  /*GetSchemaResultProto*/ byte[] getSchemaForDatabase(String database);
+
+  @nullable
+  /*GetSchemaTypeResultProto*/ byte[] getSchemaType(String schemaType);
+
+  @nullable
+  /*PutResultProto*/ byte[] put(in byte[] documentProto);
+
+  @nullable
+  /*BatchPutResultProto*/ byte[] batchPut(in byte[] putDocumentRequestProto);
+
+  @nullable
+  /*GetResultProto*/ byte[] get(String name_space, String uri, in byte[] getResultSpecProto);
+
+  @nullable
+  /*ReportUsageResultProto*/ byte[] reportUsage(in byte[] usageReportProto);
+
+  @nullable
+  /*GetAllNamespacesResultProto*/ byte[] getAllNamespaces();
+
+  @nullable
+  /*SearchResultProto*/ byte[] search(in byte[] searchSpecProto, in byte[] scoringSpecProto, in byte[] resultSpecProto);
+
+  @nullable
+  /*SearchResultProto*/ byte[] getNextPage(long nextPageToken);
+
+  void invalidateNextPageToken(long nextPageToken);
+
+  @nullable
+  /*BlobProto*/ byte[] openWriteBlob(in byte[] blobHandleProto);
+
+  @nullable
+  /*BlobProto*/ byte[] removeBlob(in byte[] blobHandleProto);
+
+  @nullable
+  /*BlobProto*/ byte[] openReadBlob(in byte[] blobHandleProto);
+
+  @nullable
+  /*BlobProto*/ byte[] commitBlob(in byte[] blobHandleProto);
+
+  @nullable
+  /*DeleteResultProto*/ byte[] deleteDoc(String name_space, String uri);
+
+  @nullable
+  /*SuggestionResponse*/ byte[] searchSuggestions(in byte[] suggestionSpecProto);
+
+  @nullable
+  /*DeleteByNamespaceResultProto*/ byte[] deleteByNamespace(String name_space);
+
+  @nullable
+  /*DeleteBySchemaTypeResultProto*/ byte[] deleteBySchemaType(String schemaType);
+
+  @nullable
+  /*DeleteByQueryResultProto*/ byte[] deleteByQuery(in byte[] searchSpecProto, boolean returnDeletedDocumentInfo);
+
+  @nullable
+  /*PersistToDiskResultProto*/ byte[] persistToDisk(/*PersistType.Code*/ int persistTypeCode);
+
+  @nullable
+  /*OptimizeResultProto*/ byte[] optimize();
+
+  @nullable
+  /*GetOptimizeInfoResultProto*/ byte[] getOptimizeInfo();
+
+  @nullable
+  /*StorageInfoResultProto*/ byte[] getStorageInfo();
+
+  @nullable
+  /*DebugInfoResultProto*/ byte[] getDebugInfo(/*DebugInfoVerbosity.Code*/ int verbosity);
+}
\ No newline at end of file
diff --git a/isolated_storage_service/aidl/com/android/isolated_storage_service/IIsolatedStorageService.aidl b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIsolatedStorageService.aidl
new file mode 100644
index 0000000..2241e0a
--- /dev/null
+++ b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIsolatedStorageService.aidl
@@ -0,0 +1,39 @@
+/*
+ * Copyright 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.android.isolated_storage_service;
+
+import com.android.isolated_storage_service.IIcingSearchEngine;
+
+/**
+ * Isolated Storage Service is a service that runs storage services in an isolated pVM environment.
+ */
+interface IIsolatedStorageService {
+  const long PORT = 1688;
+
+  /**
+   * Quits the VM.
+   */
+  oneway void quit();
+
+  /**
+   * Returns an Icing connection for the given uid. Creates a new Icing connection if one does not
+   * already exist for the given uid.
+   *
+   * @param uid The uid of the caller.
+   * @return An Icing connection for the given uid.
+   */
+  IIcingSearchEngine getOrCreateIcingConnection(int uid);
+}
diff --git a/isolated_storage_service/payload/macros.h b/isolated_storage_service/payload/macros.h
new file mode 100644
index 0000000..dcbad6e
--- /dev/null
+++ b/isolated_storage_service/payload/macros.h
@@ -0,0 +1,46 @@
+#ifndef ISOLATED_STORAGE_SERVICE_MACROS_H_
+#define ISOLATED_STORAGE_SERVICE_MACROS_H_
+
+namespace android::isolated_storage_service {
+
+// Accepts a `std::vector<uint8_t>` and a `proto2::MessageLite&` and
+// deserializes the bytes into the proto. Returns a bad AStatus if the
+// deserialization fails.
+#define DESERIALIZE_OR_RETURN(bytes_in, proto_out)                      \
+  static_assert(std::is_lvalue_reference<decltype((bytes_in))>::value,  \
+                "bytes_in must be an lvalue");                          \
+  static_assert(std::is_lvalue_reference<decltype((proto_out))>::value, \
+                "proto_out must be an lvalue");                         \
+  if (!proto_out.ParseFromArray(bytes_in.data(), bytes_in.size())) {    \
+    return ndk::ScopedAStatus::fromExceptionCodeWithMessage(            \
+        EX_ILLEGAL_ARGUMENT, "Failed to deserialize proto");            \
+  }
+
+// Accepts a `proto2::Message` and a `std::optional<std::vector<uint8_t>>*` and
+// serializes the proto as bytes into the vector. Returns a bad AStatus if the
+// serialization fails.
+#define SERIALIZE_AND_RETURN_ASTATUS(proto_in, bytes_out)               \
+  static_assert(std::is_lvalue_reference<decltype((proto_in))>::value,  \
+                "proto_in must be an lvalue");                          \
+  static_assert(std::is_lvalue_reference<decltype((bytes_out))>::value, \
+                "bytes_out must be an lvalue");                         \
+  *bytes_out = std::vector<uint8_t>(proto_in.ByteSizeLong());           \
+  if (proto_in.SerializeToArray(bytes_out->value().data(),              \
+                                bytes_out->value().size())) {           \
+    return ndk::ScopedAStatus::ok();                                    \
+  } else {                                                              \
+    return ndk::ScopedAStatus::fromExceptionCodeWithMessage(            \
+        EX_ILLEGAL_ARGUMENT, "Failed to serialize proto");              \
+  }
+
+// Accepts a `std::unique_ptr<icing::lib::IcingSearchEngine>` and returns a bad
+// AStatus if the pointer is null.
+#define CHECK_ICING_INIT(icing)                                   \
+  if (!icing) {                                                   \
+    return ndk::ScopedAStatus::fromExceptionCodeWithMessage(      \
+        EX_ILLEGAL_STATE, "Icing connection is not initialized"); \
+  }
+
+}  // namespace android::isolated_storage_service
+
+#endif  // ISOLATED_STORAGE_SERVICE_MACROS_H_
diff --git a/isolated_storage_service/payload/main.cc b/isolated_storage_service/payload/main.cc
new file mode 100644
index 0000000..93820e0
--- /dev/null
+++ b/isolated_storage_service/payload/main.cc
@@ -0,0 +1,444 @@
+#include <android/binder_auto_utils.h>
+#include <android/binder_ibinder.h>
+#include <android/binder_status.h>
+
+#include <cstdint>
+#include <cstdlib>
+#include <memory>
+#include <optional>
+#include <vector>
+
+#include "aidl/com/android/isolated_storage_service/BnIcingSearchEngine.h"
+#include "aidl/com/android/isolated_storage_service/BnIsolatedStorageService.h"
+#include <vm_payload.h>
+#include "icing/icing-search-engine.h"
+#include "icing/proto/blob.pb.h"
+#include "icing/proto/document.pb.h"
+#include "icing/proto/initialize.pb.h"
+#include "icing/proto/schema.pb.h"
+#include "icing/proto/scoring.pb.h"
+#include "icing/proto/search.pb.h"
+#include "icing/proto/status.pb.h"
+#include "icing/proto/storage.pb.h"
+#include "icing/proto/term.pb.h"
+#include "icing/proto/usage.pb.h"
+#include "icing/util/logging.h"
+#include "macros.h"
+
+namespace {
+
+using ::aidl::com::android::isolated_storage_service::BnIcingSearchEngine;
+using ::aidl::com::android::isolated_storage_service::BnIsolatedStorageService;
+using ::icing::lib::BatchPutResultProto;
+using ::icing::lib::BlobProto;
+using ::icing::lib::DebugInfoResultProto;
+using ::icing::lib::DebugInfoVerbosity;
+using ::icing::lib::DeleteByNamespaceResultProto;
+using ::icing::lib::DeleteByQueryResultProto;
+using ::icing::lib::DeleteBySchemaTypeResultProto;
+using ::icing::lib::DeleteResultProto;
+using ::icing::lib::DocumentProto;
+using ::icing::lib::GetAllNamespacesResultProto;
+using ::icing::lib::GetOptimizeInfoResultProto;
+using ::icing::lib::GetResultProto;
+using ::icing::lib::GetResultSpecProto;
+using ::icing::lib::GetSchemaResultProto;
+using ::icing::lib::GetSchemaTypeResultProto;
+using ::icing::lib::IcingSearchEngine;
+using ::icing::lib::IcingSearchEngineOptions;
+using ::icing::lib::InitializeResultProto;
+using ::icing::lib::OptimizeResultProto;
+using ::icing::lib::PersistToDiskResultProto;
+using ::icing::lib::PersistType;
+using ::icing::lib::PutDocumentRequest;
+using ::icing::lib::PutResultProto;
+using ::icing::lib::ReportUsageResultProto;
+using ::icing::lib::ResetResultProto;
+using ::icing::lib::ResultSpecProto;
+using ::icing::lib::SchemaProto;
+using ::icing::lib::ScoringSpecProto;
+using ::icing::lib::SearchResultProto;
+using ::icing::lib::SearchSpecProto;
+using ::icing::lib::SetSchemaResultProto;
+using ::icing::lib::StatusProto;
+using ::icing::lib::StorageInfoResultProto;
+using ::icing::lib::SuggestionResponse;
+using ::icing::lib::SuggestionSpecProto;
+using ::icing::lib::TermMatchType;
+using ::icing::lib::UsageReport;
+using BlobHandleProto = ::icing::lib::PropertyProto::BlobHandleProto;
+using ::icing::lib::INFO;
+using ::ndk::ScopedAStatus;
+
+// This class implements the AIDL interface for the Icing connection.
+class IcingConnectionImpl
+    : public aidl::com::android::isolated_storage_service::BnIcingSearchEngine {
+ public:
+  explicit IcingConnectionImpl(uint32_t uid) : uid_(uid) {}
+
+  ScopedAStatus initialize(
+      const std::vector<uint8_t>& icing_search_engine_options_proto,
+      std::optional<std::vector<uint8_t>>* initialize_result_proto) {
+    IcingSearchEngineOptions options;
+    DESERIALIZE_OR_RETURN(icing_search_engine_options_proto, options);
+    options.set_base_dir(std::string(AVmPayload_getEncryptedStoragePath()) +
+                         "/" + std::to_string(uid_) + "/" + options.base_dir());
+    icing_ = std::make_unique<IcingSearchEngine>(options);
+    InitializeResultProto initialize_result = icing_->Initialize();
+    SERIALIZE_AND_RETURN_ASTATUS(initialize_result, initialize_result_proto);
+  }
+
+  ScopedAStatus close() {
+    CHECK_ICING_INIT(icing_);
+    ICING_LOG(INFO) << "IsolatedStorageService closing Icing connection.";
+    icing_->PersistToDisk(icing::lib::PersistType::FULL);
+    return ScopedAStatus::ok();
+  }
+
+  ScopedAStatus reset(std::optional<std::vector<uint8_t>>* reset_result_proto) {
+    CHECK_ICING_INIT(icing_);
+    ResetResultProto reset_result = icing_->Reset();
+    SERIALIZE_AND_RETURN_ASTATUS(reset_result, reset_result_proto);
+  }
+
+  ScopedAStatus setSchema(
+      const std::vector<uint8_t>& schema_proto,
+      bool ignore_errors_and_delete_documents,
+      std::optional<std::vector<uint8_t>>* set_schema_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    SchemaProto schema;
+    DESERIALIZE_OR_RETURN(schema_proto, schema)
+
+    SetSchemaResultProto set_schema_result =
+        icing_->SetSchema(schema, ignore_errors_and_delete_documents);
+    SERIALIZE_AND_RETURN_ASTATUS(set_schema_result, set_schema_result_proto);
+  }
+
+  ScopedAStatus getSchema(
+      std::optional<std::vector<uint8_t>>* get_schema_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    GetSchemaResultProto schema = icing_->GetSchema();
+    SERIALIZE_AND_RETURN_ASTATUS(schema, get_schema_result_proto);
+  }
+
+  ScopedAStatus getSchemaForDatabase(
+      const std::string& database,
+      std::optional<std::vector<uint8_t>>* get_schema_result_proto) {
+    CHECK_ICING_INIT(icing_);
+    GetSchemaResultProto schema = icing_->GetSchema(database);
+    SERIALIZE_AND_RETURN_ASTATUS(schema, get_schema_result_proto);
+  }
+
+  ScopedAStatus getSchemaType(
+      const std::string& schema_type,
+      std::optional<std::vector<uint8_t>>* get_schema_type_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    GetSchemaTypeResultProto schema_type_result =
+        icing_->GetSchemaType(schema_type);
+    SERIALIZE_AND_RETURN_ASTATUS(schema_type_result,
+                                 get_schema_type_result_proto);
+  }
+
+  ScopedAStatus put(const std::vector<uint8_t>& document_proto,
+                    std::optional<std::vector<uint8_t>>* put_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    DocumentProto document;
+    DESERIALIZE_OR_RETURN(document_proto, document);
+    PutResultProto put_result = icing_->Put(document);
+    *put_result_proto = std::vector<uint8_t>();
+    SERIALIZE_AND_RETURN_ASTATUS(put_result, put_result_proto);
+  }
+
+  ScopedAStatus batchPut(const std::vector<uint8_t>& put_document_request_proto,
+                         std::optional<std::vector<uint8_t>>* batch_put_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    PutDocumentRequest request;
+    DESERIALIZE_OR_RETURN(put_document_request_proto, request);
+
+    BatchPutResultProto result = icing_->BatchPut(std::move(request));
+
+    *batch_put_result_proto = std::vector<uint8_t>();
+    SERIALIZE_AND_RETURN_ASTATUS(result, batch_put_result_proto);
+  }
+
+  ScopedAStatus get(const std::string& name_space, const std::string& uri,
+                    const std::vector<uint8_t>& get_result_spec_proto,
+                    std::optional<std::vector<uint8_t>>* get_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    GetResultSpecProto get_result_spec;
+    DESERIALIZE_OR_RETURN(get_result_spec_proto, get_result_spec);
+
+    GetResultProto get_result = icing_->Get(name_space, uri, get_result_spec);
+    SERIALIZE_AND_RETURN_ASTATUS(get_result, get_result_proto);
+  }
+
+  ScopedAStatus reportUsage(
+      const std::vector<uint8_t>& usage_report_proto,
+      std::optional<std::vector<uint8_t>>* report_usage_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    UsageReport usage_report;
+    DESERIALIZE_OR_RETURN(usage_report_proto, usage_report);
+
+    ReportUsageResultProto report_usage_result =
+        icing_->ReportUsage(usage_report);
+    SERIALIZE_AND_RETURN_ASTATUS(report_usage_result,
+                                 report_usage_result_proto);
+  }
+
+  ScopedAStatus getAllNamespaces(
+      std::optional<std::vector<uint8_t>>* get_all_namespaces_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    GetAllNamespacesResultProto get_all_namespaces_result =
+        icing_->GetAllNamespaces();
+    SERIALIZE_AND_RETURN_ASTATUS(get_all_namespaces_result,
+                                 get_all_namespaces_result_proto);
+  }
+
+  ScopedAStatus search(
+      const std::vector<uint8_t>& search_spec_proto,
+      const std::vector<uint8_t>& scoring_spec_proto,
+      const std::vector<uint8_t>& result_spec_proto,
+      std::optional<std::vector<uint8_t>>* search_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    SearchSpecProto search_spec;
+    DESERIALIZE_OR_RETURN(search_spec_proto, search_spec);
+    ScoringSpecProto scoring_spec;
+    DESERIALIZE_OR_RETURN(scoring_spec_proto, scoring_spec);
+    ResultSpecProto result_spec;
+    DESERIALIZE_OR_RETURN(result_spec_proto, result_spec);
+
+    SearchResultProto search_result =
+        icing_->Search(search_spec, scoring_spec, result_spec);
+    SERIALIZE_AND_RETURN_ASTATUS(search_result, search_result_proto);
+
+    return ScopedAStatus::ok();
+  }
+
+  ScopedAStatus getNextPage(
+      int64_t next_page_token,
+      std::optional<std::vector<uint8_t>>* get_next_page_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    SearchResultProto get_next_page_result =
+        icing_->GetNextPage(next_page_token);
+    SERIALIZE_AND_RETURN_ASTATUS(get_next_page_result,
+                                 get_next_page_result_proto);
+  }
+
+  ScopedAStatus invalidateNextPageToken(int64_t next_page_token) {
+    CHECK_ICING_INIT(icing_);
+
+    icing_->InvalidateNextPageToken(next_page_token);
+    return ScopedAStatus::ok();
+  }
+
+  ScopedAStatus openWriteBlob(const std::vector<uint8_t>& blob_handle_proto,
+                              std::optional<std::vector<uint8_t>>* blob_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    BlobHandleProto blob_handle;
+    DESERIALIZE_OR_RETURN(blob_handle_proto, blob_handle);
+
+    BlobProto open_write_blob_result = icing_->OpenWriteBlob(blob_handle);
+    SERIALIZE_AND_RETURN_ASTATUS(open_write_blob_result, blob_proto);
+  }
+
+  ScopedAStatus removeBlob(const std::vector<uint8_t>& blob_handle_proto,
+                           std::optional<std::vector<uint8_t>>* blob_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    BlobHandleProto blob_handle;
+    DESERIALIZE_OR_RETURN(blob_handle_proto, blob_handle);
+
+    BlobProto remove_blob_result = icing_->RemoveBlob(blob_handle);
+    SERIALIZE_AND_RETURN_ASTATUS(remove_blob_result, blob_proto);
+  }
+
+  ScopedAStatus openReadBlob(const std::vector<uint8_t>& blob_handle_proto,
+                             std::optional<std::vector<uint8_t>>* blob_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    BlobHandleProto blob_handle;
+    DESERIALIZE_OR_RETURN(blob_handle_proto, blob_handle);
+
+    BlobProto open_read_blob_result = icing_->OpenReadBlob(blob_handle);
+    SERIALIZE_AND_RETURN_ASTATUS(open_read_blob_result, blob_proto);
+  }
+
+  ScopedAStatus commitBlob(const std::vector<uint8_t>& blob_handle_proto,
+                           std::optional<std::vector<uint8_t>>* blob_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    BlobHandleProto blob_handle;
+    DESERIALIZE_OR_RETURN(blob_handle_proto, blob_handle);
+
+    BlobProto commit_blob_result = icing_->CommitBlob(blob_handle);
+    SERIALIZE_AND_RETURN_ASTATUS(commit_blob_result, blob_proto);
+  }
+
+  ScopedAStatus deleteDoc(
+      const std::string& name_space, const std::string& uri,
+      std::optional<std::vector<uint8_t>>* delete_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    DeleteResultProto delete_result = icing_->Delete(name_space, uri);
+    SERIALIZE_AND_RETURN_ASTATUS(delete_result, delete_result_proto);
+  }
+
+  ScopedAStatus searchSuggestions(
+      const std::vector<uint8_t>& suggestion_spec_proto,
+      std::optional<std::vector<uint8_t>>* suggestion_response_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    SuggestionSpecProto suggestion_spec;
+    DESERIALIZE_OR_RETURN(suggestion_spec_proto, suggestion_spec);
+
+    SuggestionResponse suggestion_response =
+        icing_->SearchSuggestions(suggestion_spec);
+    SERIALIZE_AND_RETURN_ASTATUS(suggestion_response,
+                                 suggestion_response_proto);
+  }
+
+  ScopedAStatus deleteByNamespace(
+      const std::string& name_space,
+      std::optional<std::vector<uint8_t>>* delete_by_namespace_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    DeleteByNamespaceResultProto delete_by_namespace_result =
+        icing_->DeleteByNamespace(name_space);
+    SERIALIZE_AND_RETURN_ASTATUS(delete_by_namespace_result,
+                                 delete_by_namespace_result_proto);
+  }
+
+  ScopedAStatus deleteBySchemaType(
+      const std::string& schema_type,
+      std::optional<std::vector<uint8_t>>* delete_by_schema_type_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    DeleteBySchemaTypeResultProto delete_by_schema_type_result =
+        icing_->DeleteBySchemaType(schema_type);
+    SERIALIZE_AND_RETURN_ASTATUS(delete_by_schema_type_result,
+                                 delete_by_schema_type_result_proto);
+  }
+
+  ScopedAStatus deleteByQuery(
+      const std::vector<uint8_t>& search_spec_proto,
+      bool return_deleted_document_info,
+      std::optional<std::vector<uint8_t>>* delete_by_query_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    SearchSpecProto search_spec;
+    DESERIALIZE_OR_RETURN(search_spec_proto, search_spec);
+
+    DeleteByQueryResultProto delete_by_query_result =
+        icing_->DeleteByQuery(search_spec, return_deleted_document_info);
+    SERIALIZE_AND_RETURN_ASTATUS(delete_by_query_result,
+                                 delete_by_query_result_proto);
+  }
+
+  ScopedAStatus persistToDisk(
+      int32_t persist_type_code,
+      std::optional<std::vector<uint8_t>>* persist_to_disk_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    PersistToDiskResultProto persist_to_disk_result =
+        icing_->PersistToDisk(PersistType::Code(persist_type_code));
+    SERIALIZE_AND_RETURN_ASTATUS(persist_to_disk_result,
+                                 persist_to_disk_result_proto);
+  }
+
+  ScopedAStatus optimize(
+      std::optional<std::vector<uint8_t>>* optimize_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    OptimizeResultProto optimize_result = icing_->Optimize();
+    SERIALIZE_AND_RETURN_ASTATUS(optimize_result, optimize_result_proto);
+  }
+
+  ScopedAStatus getOptimizeInfo(
+      std::optional<std::vector<uint8_t>>* get_optimize_info_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    GetOptimizeInfoResultProto get_optimize_info_result =
+        icing_->GetOptimizeInfo();
+    SERIALIZE_AND_RETURN_ASTATUS(get_optimize_info_result,
+                                 get_optimize_info_result_proto);
+  }
+
+  ScopedAStatus getStorageInfo(
+      std::optional<std::vector<uint8_t>>* get_storage_info_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    StorageInfoResultProto get_storage_info_result = icing_->GetStorageInfo();
+    SERIALIZE_AND_RETURN_ASTATUS(get_storage_info_result,
+                                 get_storage_info_result_proto);
+  }
+
+  ScopedAStatus getDebugInfo(
+      int32_t verbosity,
+      std::optional<std::vector<uint8_t>>* get_debug_info_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    DebugInfoResultProto get_debug_info_result =
+        icing_->GetDebugInfo(DebugInfoVerbosity::Code(verbosity));
+    SERIALIZE_AND_RETURN_ASTATUS(get_debug_info_result,
+                                 get_debug_info_result_proto);
+  }
+
+ protected:
+  std::unique_ptr<icing::lib::IcingSearchEngine> icing_ = nullptr;
+  uint32_t uid_;
+};
+
+class IsolatedStorageServiceImpl : public BnIsolatedStorageService {
+ public:
+  IsolatedStorageServiceImpl() = default;
+
+ private:
+  ScopedAStatus quit() override {
+    ICING_LOG(INFO) << "Received quit request, exiting";
+    for (const auto& [unused, connection] : icing_connections_) {
+      connection->close();
+    }
+    exit(0);
+  }
+
+  ScopedAStatus getOrCreateIcingConnection(
+      int32_t uid,
+      std::shared_ptr<
+          aidl::com::android::isolated_storage_service::IIcingSearchEngine>*
+          icing_server) override {
+    auto connection = icing_connections_.find(uid);
+    if (connection != icing_connections_.end()) {
+      *icing_server = connection->second;
+      return ScopedAStatus::ok();
+    }
+    icing_connections_[uid] =
+        ndk::SharedRefBase::make<IcingConnectionImpl>(uid);
+    *icing_server = icing_connections_[uid];
+    return ScopedAStatus::ok();
+  }
+
+  std::map<int32_t, std::shared_ptr<IcingConnectionImpl>> icing_connections_;
+};
+}  // namespace
+
+extern "C" int AVmPayload_main() {
+  ICING_LOG(INFO) << "IsolatedStorageService VM Payload starting";
+  auto service = ndk::SharedRefBase::make<IsolatedStorageServiceImpl>();
+  auto callback = []([[maybe_unused]] void* param) {
+    ICING_LOG(INFO) << "IsolatedStorageService VM Payload ready";
+    AVmPayload_notifyPayloadReady();
+  };
+  AVmPayload_runVsockRpcServer(service->asBinder().get(), service->PORT,
+                               callback, /*param=*/nullptr);
+}
diff --git a/java/Android.bp b/java/Android.bp
index 6133230..e727e95 100644
--- a/java/Android.bp
+++ b/java/Android.bp
@@ -30,6 +30,7 @@ java_library {
     ],
     libs: [
         "androidx.annotation_annotation",
+	"jspecify",
     ],
     sdk_version: "current",
     min_sdk_version: "Tiramisu",
diff --git a/java/src/com/google/android/icing/IcingSearchEngine.java b/java/src/com/google/android/icing/IcingSearchEngine.java
index 0dddb2e..fb6d1ef 100644
--- a/java/src/com/google/android/icing/IcingSearchEngine.java
+++ b/java/src/com/google/android/icing/IcingSearchEngine.java
@@ -14,8 +14,8 @@
 
 package com.google.android.icing;
 
-import androidx.annotation.NonNull;
-import androidx.annotation.Nullable;
+import com.google.android.icing.proto.BatchGetResultProto;
+import com.google.android.icing.proto.BatchPutResultProto;
 import com.google.android.icing.proto.BlobProto;
 import com.google.android.icing.proto.DebugInfoResultProto;
 import com.google.android.icing.proto.DebugInfoVerbosity;
@@ -37,6 +37,7 @@ import com.google.android.icing.proto.OptimizeResultProto;
 import com.google.android.icing.proto.PersistToDiskResultProto;
 import com.google.android.icing.proto.PersistType;
 import com.google.android.icing.proto.PropertyProto;
+import com.google.android.icing.proto.PutDocumentRequest;
 import com.google.android.icing.proto.PutResultProto;
 import com.google.android.icing.proto.ReportUsageResultProto;
 import com.google.android.icing.proto.ResetResultProto;
@@ -45,11 +46,14 @@ import com.google.android.icing.proto.SchemaProto;
 import com.google.android.icing.proto.ScoringSpecProto;
 import com.google.android.icing.proto.SearchResultProto;
 import com.google.android.icing.proto.SearchSpecProto;
+import com.google.android.icing.proto.SetSchemaRequestProto;
 import com.google.android.icing.proto.SetSchemaResultProto;
 import com.google.android.icing.proto.StorageInfoResultProto;
 import com.google.android.icing.proto.SuggestionResponse;
 import com.google.android.icing.proto.SuggestionSpecProto;
 import com.google.android.icing.proto.UsageReport;
+import org.jspecify.annotations.NonNull;
+import org.jspecify.annotations.Nullable;
 
 /**
  * Java wrapper to access {@link IcingSearchEngineImpl}.
@@ -79,80 +83,90 @@ public class IcingSearchEngine implements IcingSearchEngineInterface {
     icingSearchEngineImpl.close();
   }
 
-  @NonNull
   @Override
-  public InitializeResultProto initialize() {
+  public @NonNull InitializeResultProto initialize() {
     return IcingSearchEngineUtils.byteArrayToInitializeResultProto(
         icingSearchEngineImpl.initialize());
   }
 
-  @NonNull
   @Override
-  public SetSchemaResultProto setSchema(@NonNull SchemaProto schema) {
-    return setSchema(schema, /*ignoreErrorsAndDeleteDocuments=*/ false);
+  public @NonNull SetSchemaResultProto setSchema(@NonNull SchemaProto schema) {
+    return setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false);
   }
 
-  @NonNull
   @Override
-  public SetSchemaResultProto setSchema(
+  public @NonNull SetSchemaResultProto setSchema(
       @NonNull SchemaProto schema, boolean ignoreErrorsAndDeleteDocuments) {
     return IcingSearchEngineUtils.byteArrayToSetSchemaResultProto(
         icingSearchEngineImpl.setSchema(schema.toByteArray(), ignoreErrorsAndDeleteDocuments));
   }
 
-  @NonNull
   @Override
-  public GetSchemaResultProto getSchema() {
+  public @NonNull SetSchemaResultProto setSchemaWithRequestProto(
+      @NonNull SetSchemaRequestProto setSchemaRequest) {
+    return IcingSearchEngineUtils.byteArrayToSetSchemaResultProto(
+        icingSearchEngineImpl.setSchemaWithRequestProto(setSchemaRequest.toByteArray()));
+  }
+
+  @Override
+  public @NonNull GetSchemaResultProto getSchema() {
     return IcingSearchEngineUtils.byteArrayToGetSchemaResultProto(
         icingSearchEngineImpl.getSchema());
   }
 
-  @NonNull
   @Override
-  public GetSchemaResultProto getSchemaForDatabase(@NonNull String database) {
+  public @NonNull GetSchemaResultProto getSchemaForDatabase(@NonNull String database) {
     return IcingSearchEngineUtils.byteArrayToGetSchemaResultProto(
         icingSearchEngineImpl.getSchemaForDatabase(database));
   }
 
-  @NonNull
   @Override
-  public GetSchemaTypeResultProto getSchemaType(@NonNull String schemaType) {
+  public @NonNull GetSchemaTypeResultProto getSchemaType(@NonNull String schemaType) {
     return IcingSearchEngineUtils.byteArrayToGetSchemaTypeResultProto(
         icingSearchEngineImpl.getSchemaType(schemaType));
   }
 
-  @NonNull
+  // TODO(b/394875109) We can remove this after we make the change in AppSearch, or keep it and make
+  // it call the batch version.
   @Override
-  public PutResultProto put(@NonNull DocumentProto document) {
+  public @NonNull PutResultProto put(@NonNull DocumentProto document) {
     return IcingSearchEngineUtils.byteArrayToPutResultProto(
         icingSearchEngineImpl.put(document.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public GetResultProto get(
+  public @NonNull BatchPutResultProto batchPut(@NonNull PutDocumentRequest documents) {
+    return IcingSearchEngineUtils.byteArrayToBatchPutResultProto(
+        icingSearchEngineImpl.batchPut(documents.toByteArray()));
+  }
+
+  @Override
+  public @NonNull GetResultProto get(
       @NonNull String namespace, @NonNull String uri, @NonNull GetResultSpecProto getResultSpec) {
     return IcingSearchEngineUtils.byteArrayToGetResultProto(
         icingSearchEngineImpl.get(namespace, uri, getResultSpec.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public ReportUsageResultProto reportUsage(@NonNull UsageReport usageReport) {
+  public @NonNull BatchGetResultProto batchGet(@NonNull GetResultSpecProto getResultSpec) {
+    return IcingSearchEngineUtils.byteArrayToBatchGetResultProto(
+        icingSearchEngineImpl.batchGet(getResultSpec.toByteArray()));
+  }
+
+  @Override
+  public @NonNull ReportUsageResultProto reportUsage(@NonNull UsageReport usageReport) {
     return IcingSearchEngineUtils.byteArrayToReportUsageResultProto(
         icingSearchEngineImpl.reportUsage(usageReport.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public GetAllNamespacesResultProto getAllNamespaces() {
+  public @NonNull GetAllNamespacesResultProto getAllNamespaces() {
     return IcingSearchEngineUtils.byteArrayToGetAllNamespacesResultProto(
         icingSearchEngineImpl.getAllNamespaces());
   }
 
-  @NonNull
   @Override
-  public SearchResultProto search(
+  public @NonNull SearchResultProto search(
       @NonNull SearchSpecProto searchSpec,
       @NonNull ScoringSpecProto scoringSpec,
       @NonNull ResultSpecProto resultSpec) {
@@ -161,9 +175,8 @@ public class IcingSearchEngine implements IcingSearchEngineInterface {
             searchSpec.toByteArray(), scoringSpec.toByteArray(), resultSpec.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public SearchResultProto getNextPage(long nextPageToken) {
+  public @NonNull SearchResultProto getNextPage(long nextPageToken) {
     return IcingSearchEngineUtils.byteArrayToSearchResultProto(
         icingSearchEngineImpl.getNextPage(nextPageToken));
   }
@@ -173,113 +186,99 @@ public class IcingSearchEngine implements IcingSearchEngineInterface {
     icingSearchEngineImpl.invalidateNextPageToken(nextPageToken);
   }
 
-  @NonNull
   @Override
-  public BlobProto openWriteBlob(PropertyProto.BlobHandleProto blobHandle) {
+  public @NonNull BlobProto openWriteBlob(PropertyProto.@NonNull BlobHandleProto blobHandle) {
     return IcingSearchEngineUtils.byteArrayToBlobProto(
         icingSearchEngineImpl.openWriteBlob(blobHandle.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public BlobProto removeBlob(PropertyProto.BlobHandleProto blobHandle) {
+  public @NonNull BlobProto removeBlob(PropertyProto.@NonNull BlobHandleProto blobHandle) {
     return IcingSearchEngineUtils.byteArrayToBlobProto(
         icingSearchEngineImpl.removeBlob(blobHandle.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public BlobProto openReadBlob(PropertyProto.BlobHandleProto blobHandle) {
+  public @NonNull BlobProto openReadBlob(PropertyProto.@NonNull BlobHandleProto blobHandle) {
     return IcingSearchEngineUtils.byteArrayToBlobProto(
         icingSearchEngineImpl.openReadBlob(blobHandle.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public BlobProto commitBlob(PropertyProto.BlobHandleProto blobHandle) {
+  public @NonNull BlobProto commitBlob(PropertyProto.@NonNull BlobHandleProto blobHandle) {
     return IcingSearchEngineUtils.byteArrayToBlobProto(
         icingSearchEngineImpl.commitBlob(blobHandle.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public DeleteResultProto delete(@NonNull String namespace, @NonNull String uri) {
+  public @NonNull DeleteResultProto delete(@NonNull String namespace, @NonNull String uri) {
     return IcingSearchEngineUtils.byteArrayToDeleteResultProto(
         icingSearchEngineImpl.delete(namespace, uri));
   }
 
-  @NonNull
   @Override
-  public SuggestionResponse searchSuggestions(@NonNull SuggestionSpecProto suggestionSpec) {
+  public @NonNull SuggestionResponse searchSuggestions(
+      @NonNull SuggestionSpecProto suggestionSpec) {
     return IcingSearchEngineUtils.byteArrayToSuggestionResponse(
         icingSearchEngineImpl.searchSuggestions(suggestionSpec.toByteArray()));
   }
 
-  @NonNull
   @Override
-  public DeleteByNamespaceResultProto deleteByNamespace(@NonNull String namespace) {
+  public @NonNull DeleteByNamespaceResultProto deleteByNamespace(@NonNull String namespace) {
     return IcingSearchEngineUtils.byteArrayToDeleteByNamespaceResultProto(
         icingSearchEngineImpl.deleteByNamespace(namespace));
   }
 
-  @NonNull
   @Override
-  public DeleteBySchemaTypeResultProto deleteBySchemaType(@NonNull String schemaType) {
+  public @NonNull DeleteBySchemaTypeResultProto deleteBySchemaType(@NonNull String schemaType) {
     return IcingSearchEngineUtils.byteArrayToDeleteBySchemaTypeResultProto(
         icingSearchEngineImpl.deleteBySchemaType(schemaType));
   }
 
-  @NonNull
   @Override
-  public DeleteByQueryResultProto deleteByQuery(@NonNull SearchSpecProto searchSpec) {
-    return deleteByQuery(searchSpec, /*returnDeletedDocumentInfo=*/ false);
+  public @NonNull DeleteByQueryResultProto deleteByQuery(@NonNull SearchSpecProto searchSpec) {
+    return deleteByQuery(searchSpec, /* returnDeletedDocumentInfo= */ false);
   }
 
-  @NonNull
   @Override
-  public DeleteByQueryResultProto deleteByQuery(
+  public @NonNull DeleteByQueryResultProto deleteByQuery(
       @NonNull SearchSpecProto searchSpec, boolean returnDeletedDocumentInfo) {
     return IcingSearchEngineUtils.byteArrayToDeleteByQueryResultProto(
         icingSearchEngineImpl.deleteByQuery(searchSpec.toByteArray(), returnDeletedDocumentInfo));
   }
 
-  @NonNull
   @Override
-  public PersistToDiskResultProto persistToDisk(@NonNull PersistType.Code persistTypeCode) {
+  public @NonNull PersistToDiskResultProto persistToDisk(
+      PersistType.@NonNull Code persistTypeCode) {
     return IcingSearchEngineUtils.byteArrayToPersistToDiskResultProto(
         icingSearchEngineImpl.persistToDisk(persistTypeCode.getNumber()));
   }
 
-  @NonNull
   @Override
-  public OptimizeResultProto optimize() {
+  public @NonNull OptimizeResultProto optimize() {
     return IcingSearchEngineUtils.byteArrayToOptimizeResultProto(icingSearchEngineImpl.optimize());
   }
 
-  @NonNull
   @Override
-  public GetOptimizeInfoResultProto getOptimizeInfo() {
+  public @NonNull GetOptimizeInfoResultProto getOptimizeInfo() {
     return IcingSearchEngineUtils.byteArrayToGetOptimizeInfoResultProto(
         icingSearchEngineImpl.getOptimizeInfo());
   }
 
-  @NonNull
   @Override
-  public StorageInfoResultProto getStorageInfo() {
+  public @NonNull StorageInfoResultProto getStorageInfo() {
     return IcingSearchEngineUtils.byteArrayToStorageInfoResultProto(
         icingSearchEngineImpl.getStorageInfo());
   }
 
-  @NonNull
   @Override
-  public DebugInfoResultProto getDebugInfo(DebugInfoVerbosity.Code verbosity) {
+  public @NonNull DebugInfoResultProto getDebugInfo(DebugInfoVerbosity.@NonNull Code verbosity) {
     return IcingSearchEngineUtils.byteArrayToDebugInfoResultProto(
         icingSearchEngineImpl.getDebugInfo(verbosity.getNumber()));
   }
 
-  @NonNull
   @Override
-  public ResetResultProto reset() {
+  public @NonNull ResetResultProto reset() {
     return IcingSearchEngineUtils.byteArrayToResetResultProto(icingSearchEngineImpl.reset());
   }
 
@@ -299,8 +298,7 @@ public class IcingSearchEngine implements IcingSearchEngineInterface {
     return IcingSearchEngineImpl.setLoggingLevel((short) severity.getNumber(), verbosity);
   }
 
-  @Nullable
-  public static String getLoggingTag() {
+  public static @Nullable String getLoggingTag() {
     return IcingSearchEngineImpl.getLoggingTag();
   }
 }
diff --git a/java/src/com/google/android/icing/IcingSearchEngineImpl.java b/java/src/com/google/android/icing/IcingSearchEngineImpl.java
index c06f547..05ae0a3 100644
--- a/java/src/com/google/android/icing/IcingSearchEngineImpl.java
+++ b/java/src/com/google/android/icing/IcingSearchEngineImpl.java
@@ -88,6 +88,12 @@ public class IcingSearchEngineImpl implements Closeable {
     return nativeSetSchema(this, schemaBytes, ignoreErrorsAndDeleteDocuments);
   }
 
+  @Nullable
+  public byte[] setSchemaWithRequestProto(@NonNull byte[] setSchemaRequestBytes) {
+    throwIfClosed();
+    return nativeSetSchemaWithRequestProto(this, setSchemaRequestBytes);
+  }
+
   @Nullable
   public byte[] getSchema() {
     throwIfClosed();
@@ -112,6 +118,12 @@ public class IcingSearchEngineImpl implements Closeable {
     return nativePut(this, documentBytes);
   }
 
+  @Nullable
+  public byte[] batchPut(@NonNull byte[] documentsBytes) {
+    throwIfClosed();
+    return nativeBatchPut(this, documentsBytes);
+  }
+
   @Nullable
   public byte[] get(
       @NonNull String namespace, @NonNull String uri, @NonNull byte[] getResultSpecBytes) {
@@ -119,6 +131,12 @@ public class IcingSearchEngineImpl implements Closeable {
     return nativeGet(this, namespace, uri, getResultSpecBytes);
   }
 
+  @Nullable
+  public byte[] batchGet(@NonNull byte[] getResultSpecBytes) {
+    throwIfClosed();
+    return nativeBatchGet(this, getResultSpecBytes);
+  }
+
   @Nullable
   public byte[] reportUsage(@NonNull byte[] usageReportBytes) {
     throwIfClosed();
@@ -290,6 +308,9 @@ public class IcingSearchEngineImpl implements Closeable {
   private static native byte[] nativeSetSchema(
       IcingSearchEngineImpl instance, byte[] schemaBytes, boolean ignoreErrorsAndDeleteDocuments);
 
+  private static native byte[] nativeSetSchemaWithRequestProto(
+      IcingSearchEngineImpl instance, byte[] setSchemaRequestBytes);
+
   private static native byte[] nativeGetSchema(IcingSearchEngineImpl instance);
 
   private static native byte[] nativeGetSchemaForDatabase(
@@ -300,9 +321,15 @@ public class IcingSearchEngineImpl implements Closeable {
 
   private static native byte[] nativePut(IcingSearchEngineImpl instance, byte[] documentBytes);
 
+  private static native byte[] nativeBatchPut(
+      IcingSearchEngineImpl instance, byte[] documentsBytes);
+
   private static native byte[] nativeGet(
       IcingSearchEngineImpl instance, String namespace, String uri, byte[] getResultSpecBytes);
 
+  private static native byte[] nativeBatchGet(
+      IcingSearchEngineImpl instance, byte[] getResultSpecBytes);
+
   private static native byte[] nativeReportUsage(
       IcingSearchEngineImpl instance, byte[] usageReportBytes);
 
diff --git a/java/src/com/google/android/icing/IcingSearchEngineInterface.java b/java/src/com/google/android/icing/IcingSearchEngineInterface.java
index dcd5c3e..dcf2b60 100644
--- a/java/src/com/google/android/icing/IcingSearchEngineInterface.java
+++ b/java/src/com/google/android/icing/IcingSearchEngineInterface.java
@@ -1,5 +1,7 @@
 package com.google.android.icing;
 
+import com.google.android.icing.proto.BatchGetResultProto;
+import com.google.android.icing.proto.BatchPutResultProto;
 import com.google.android.icing.proto.BlobProto;
 import com.google.android.icing.proto.DebugInfoResultProto;
 import com.google.android.icing.proto.DebugInfoVerbosity;
@@ -19,6 +21,7 @@ import com.google.android.icing.proto.OptimizeResultProto;
 import com.google.android.icing.proto.PersistToDiskResultProto;
 import com.google.android.icing.proto.PersistType;
 import com.google.android.icing.proto.PropertyProto;
+import com.google.android.icing.proto.PutDocumentRequest;
 import com.google.android.icing.proto.PutResultProto;
 import com.google.android.icing.proto.ReportUsageResultProto;
 import com.google.android.icing.proto.ResetResultProto;
@@ -27,6 +30,7 @@ import com.google.android.icing.proto.SchemaProto;
 import com.google.android.icing.proto.ScoringSpecProto;
 import com.google.android.icing.proto.SearchResultProto;
 import com.google.android.icing.proto.SearchSpecProto;
+import com.google.android.icing.proto.SetSchemaRequestProto;
 import com.google.android.icing.proto.SetSchemaResultProto;
 import com.google.android.icing.proto.StorageInfoResultProto;
 import com.google.android.icing.proto.SuggestionResponse;
@@ -43,17 +47,32 @@ public interface IcingSearchEngineInterface extends Closeable {
    */
   InitializeResultProto initialize();
 
-  /** Sets the schema for the icing instance. */
+  /**
+   * Sets the schema for the icing instance.
+   *
+   * <p>Note: This method is deprecated. Please use {@link
+   * #setSchemaWithRequestProto(SetSchemaRequestProto)} instead.
+   */
   SetSchemaResultProto setSchema(SchemaProto schema);
 
   /**
    * Sets the schema for the icing instance.
    *
+   * <p>Note: This method is deprecated. Please use {@link
+   * #setSchemaWithRequestProto(SetSchemaRequestProto)} instead.
+   *
    * @param ignoreErrorsAndDeleteDocuments force to set the schema and delete documents in case of
    *     incompatible schema change.
    */
   SetSchemaResultProto setSchema(SchemaProto schema, boolean ignoreErrorsAndDeleteDocuments);
 
+  /**
+   * Sets the schema for the icing instance.
+   *
+   * @param setSchemaRequest the request proto for setting the schema.
+   */
+  SetSchemaResultProto setSchemaWithRequestProto(SetSchemaRequestProto setSchemaRequest);
+
   /** Gets the schema for the icing instance. */
   GetSchemaResultProto getSchema();
 
@@ -75,6 +94,9 @@ public interface IcingSearchEngineInterface extends Closeable {
   /** Puts the document. */
   PutResultProto put(DocumentProto document);
 
+  /** Puts a number of documents. */
+  BatchPutResultProto batchPut(PutDocumentRequest documents);
+
   /**
    * Gets the document.
    *
@@ -84,6 +106,13 @@ public interface IcingSearchEngineInterface extends Closeable {
    */
   GetResultProto get(String namespace, String uri, GetResultSpecProto getResultSpec);
 
+  /**
+   * Gets a list of documents.
+   *
+   * @param getResultSpec the spec for getting the documents.
+   */
+  BatchGetResultProto batchGet(GetResultSpecProto getResultSpec);
+
   /** Reports usage. */
   ReportUsageResultProto reportUsage(UsageReport usageReport);
 
diff --git a/java/src/com/google/android/icing/IcingSearchEngineUtils.java b/java/src/com/google/android/icing/IcingSearchEngineUtils.java
index 13ded3a..08e7134 100644
--- a/java/src/com/google/android/icing/IcingSearchEngineUtils.java
+++ b/java/src/com/google/android/icing/IcingSearchEngineUtils.java
@@ -17,6 +17,8 @@ package com.google.android.icing;
 import android.util.Log;
 import androidx.annotation.NonNull;
 import androidx.annotation.Nullable;
+import com.google.android.icing.proto.BatchGetResultProto;
+import com.google.android.icing.proto.BatchPutResultProto;
 import com.google.android.icing.proto.BlobProto;
 import com.google.android.icing.proto.DebugInfoResultProto;
 import com.google.android.icing.proto.DeleteByNamespaceResultProto;
@@ -157,6 +159,26 @@ public final class IcingSearchEngineUtils {
     }
   }
 
+  @NonNull
+  public static BatchPutResultProto byteArrayToBatchPutResultProto(
+      @Nullable byte[] putResultsBytes) {
+    if (putResultsBytes == null) {
+      Log.e(TAG, "Received null PutResultProtos from native.");
+      return BatchPutResultProto.newBuilder()
+          .setStatus(StatusProto.newBuilder().setCode(StatusProto.Code.INTERNAL))
+          .build();
+    }
+
+    try {
+      return BatchPutResultProto.parseFrom(putResultsBytes, EXTENSION_REGISTRY_LITE);
+    } catch (InvalidProtocolBufferException e) {
+      Log.e(TAG, "Error parsing PutResultProtos.", e);
+      return BatchPutResultProto.newBuilder()
+          .setStatus(StatusProto.newBuilder().setCode(StatusProto.Code.INTERNAL))
+          .build();
+    }
+  }
+
   @NonNull
   public static GetResultProto byteArrayToGetResultProto(@Nullable byte[] getResultBytes) {
     if (getResultBytes == null) {
@@ -176,6 +198,26 @@ public final class IcingSearchEngineUtils {
     }
   }
 
+  @NonNull
+  public static BatchGetResultProto byteArrayToBatchGetResultProto(
+      @Nullable byte[] batchGetResultBytes) {
+    if (batchGetResultBytes == null) {
+      Log.e(TAG, "Received null BatchGetResultProto from native.");
+      return BatchGetResultProto.newBuilder()
+          .setStatus(StatusProto.newBuilder().setCode(StatusProto.Code.INTERNAL))
+          .build();
+    }
+
+    try {
+      return BatchGetResultProto.parseFrom(batchGetResultBytes, EXTENSION_REGISTRY_LITE);
+    } catch (InvalidProtocolBufferException e) {
+      Log.e(TAG, "Error parsing BatchGetResultProto.", e);
+      return BatchGetResultProto.newBuilder()
+          .setStatus(StatusProto.newBuilder().setCode(StatusProto.Code.INTERNAL))
+          .build();
+    }
+  }
+
   @NonNull
   public static ReportUsageResultProto byteArrayToReportUsageResultProto(
       @Nullable byte[] reportUsageResultBytes) {
diff --git a/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java b/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java
index fb17f44..8d7d8b1 100644
--- a/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java
+++ b/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java
@@ -18,6 +18,8 @@ import static com.google.common.truth.Truth.assertThat;
 import static com.google.common.truth.Truth.assertWithMessage;
 
 import com.google.android.icing.IcingSearchEngine;
+import com.google.android.icing.proto.BatchGetResultProto;
+import com.google.android.icing.proto.BatchPutResultProto;
 import com.google.android.icing.proto.BlobProto;
 import com.google.android.icing.proto.DebugInfoResultProto;
 import com.google.android.icing.proto.DebugInfoVerbosity;
@@ -40,6 +42,7 @@ import com.google.android.icing.proto.PersistToDiskResultProto;
 import com.google.android.icing.proto.PersistType;
 import com.google.android.icing.proto.PropertyConfigProto;
 import com.google.android.icing.proto.PropertyProto;
+import com.google.android.icing.proto.PutDocumentRequest;
 import com.google.android.icing.proto.PutResultProto;
 import com.google.android.icing.proto.ReportUsageResultProto;
 import com.google.android.icing.proto.ResetResultProto;
@@ -49,6 +52,7 @@ import com.google.android.icing.proto.SchemaTypeConfigProto;
 import com.google.android.icing.proto.ScoringSpecProto;
 import com.google.android.icing.proto.SearchResultProto;
 import com.google.android.icing.proto.SearchSpecProto;
+import com.google.android.icing.proto.SetSchemaRequestProto;
 import com.google.android.icing.proto.SetSchemaResultProto;
 import com.google.android.icing.proto.SnippetMatchProto;
 import com.google.android.icing.proto.SnippetProto;
@@ -209,7 +213,8 @@ public final class IcingSearchEngineTest {
     assertThat(getSchemaTypeResultProto.getSchemaTypeConfig()).isEqualTo(emailTypeConfig);
   }
 
-  // TODO(b/337913932) re-enable this test after we preregister this API in jni
+  // TODO: b/383379132 - Re-enable this test once the JNI API is pre-registered and dropped back
+  // into g3.
   @Ignore
   @Test
   public void setAndGetSchemaWithDatabase_ok() throws Exception {
@@ -228,11 +233,23 @@ public final class IcingSearchEngineTest {
     SchemaProto db2Schema =
         SchemaProto.newBuilder().addTypes(createEmailTypeConfigWithDatabase(db2)).build();
 
+    SetSchemaRequestProto requestProto1 =
+        SetSchemaRequestProto.newBuilder()
+            .setSchema(db1Schema)
+            .setDatabase(db1)
+            .setIgnoreErrorsAndDeleteDocuments(false)
+            .build();
     SetSchemaResultProto setSchemaResultProto =
-        icingSearchEngine.setSchema(db1Schema, /* ignoreErrorsAndDeleteDocuments= */ false);
+        icingSearchEngine.setSchemaWithRequestProto(requestProto1);
     assertStatusOk(setSchemaResultProto.getStatus());
-    setSchemaResultProto =
-        icingSearchEngine.setSchema(db2Schema, /* ignoreErrorsAndDeleteDocuments= */ false);
+
+    SetSchemaRequestProto requestProto2 =
+        SetSchemaRequestProto.newBuilder()
+            .setSchema(db2Schema)
+            .setDatabase(db2)
+            .setIgnoreErrorsAndDeleteDocuments(false)
+            .build();
+    setSchemaResultProto = icingSearchEngine.setSchemaWithRequestProto(requestProto2);
     assertStatusOk(setSchemaResultProto.getStatus());
 
     // Get schema for individual databases.
@@ -278,6 +295,264 @@ public final class IcingSearchEngineTest {
     assertThat(getResultProto.getDocument()).isEqualTo(emailDocument);
   }
 
+  @Test
+  public void testBatchPutAndGetDocuments() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+
+    DocumentProto emailDocument1 = createEmailDocument("namespace", "uri1");
+    DocumentProto emailDocument2 = createEmailDocument("namespace", "uri2");
+    PutDocumentRequest putDocumentRequest =
+        PutDocumentRequest.newBuilder()
+            .addDocuments(emailDocument1)
+            .addDocuments(emailDocument2)
+            .build();
+    BatchPutResultProto batchPutResultProto = icingSearchEngine.batchPut(putDocumentRequest);
+
+    assertStatusOk(batchPutResultProto.getStatus());
+    assertThat(batchPutResultProto.getPutResultProtos(0).getUri()).isEqualTo("uri1");
+    assertStatusOk(batchPutResultProto.getPutResultProtos(0).getStatus());
+    assertThat(batchPutResultProto.getPutResultProtos(1).getUri()).isEqualTo("uri2");
+    assertStatusOk(batchPutResultProto.getPutResultProtos(1).getStatus());
+
+    // PersistToDiskResultProto should not be set if persist_type is not set in the
+    // PutDocumentRequest.
+    assertThat(batchPutResultProto.getPersistToDiskResultProto().getStatus().getCode())
+        .isEqualTo(StatusProto.Code.UNKNOWN);
+
+    GetResultSpecProto getResultSpecProto =
+        GetResultSpecProto.newBuilder()
+            .setNamespaceRequested("namespace")
+            .addIds("uri1")
+            .addIds("uri2")
+            .build();
+    BatchGetResultProto batchGetResultProto = icingSearchEngine.batchGet(getResultSpecProto);
+
+    assertStatusOk(batchGetResultProto.getStatus());
+    // Check doc1
+    DocumentProto document = batchGetResultProto.getGetResultProtos(0).getDocument();
+    assertStatusOk(batchGetResultProto.getGetResultProtos(0).getStatus());
+    assertThat(document).isEqualTo(emailDocument1);
+    // Check doc2
+    document = batchGetResultProto.getGetResultProtos(1).getDocument();
+    assertStatusOk(batchGetResultProto.getGetResultProtos(1).getStatus());
+    assertThat(document).isEqualTo(emailDocument2);
+  }
+
+  @Test
+  public void testBatchGetWithEmptyResult() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+
+    DocumentProto emailDocument1 = createEmailDocument("namespace", "uri1");
+    DocumentProto emailDocument2 = createEmailDocument("namespace", "uri2");
+    PutDocumentRequest putDocumentRequest =
+        PutDocumentRequest.newBuilder()
+            .addDocuments(emailDocument1)
+            .addDocuments(emailDocument2)
+            .build();
+    BatchPutResultProto batchPutResultProto = icingSearchEngine.batchPut(putDocumentRequest);
+    assertStatusOk(batchPutResultProto.getStatus());
+
+    // no ids.
+    GetResultSpecProto getResultSpecProto =
+        GetResultSpecProto.newBuilder().setNamespaceRequested("namespace").build();
+    BatchGetResultProto batchGetResultProto = icingSearchEngine.batchGet(getResultSpecProto);
+
+    // Check no doc returned if no ids are specified.
+    assertStatusOk(batchGetResultProto.getStatus());
+    assertThat(batchGetResultProto.getGetResultProtosList()).isEmpty();
+
+    // empty namespace.
+    getResultSpecProto = GetResultSpecProto.newBuilder().addIds("uri1").build();
+    batchGetResultProto = icingSearchEngine.batchGet(getResultSpecProto);
+    assertStatusOk(batchGetResultProto.getStatus());
+    assertThat(batchGetResultProto.getGetResultProtosList()).hasSize(1);
+    assertThat(batchGetResultProto.getGetResultProtos(0).getStatus().getCode())
+        .isEqualTo(StatusProto.Code.NOT_FOUND);
+
+    // different namespace.
+    getResultSpecProto =
+        GetResultSpecProto.newBuilder()
+            .setNamespaceRequested("otherNameSpace")
+            .addIds("uri1")
+            .addIds("uri2")
+            .build();
+    batchGetResultProto = icingSearchEngine.batchGet(getResultSpecProto);
+
+    // Check not found returned if namespace is different.
+    assertStatusOk(batchGetResultProto.getStatus());
+    assertThat(batchGetResultProto.getGetResultProtosList()).hasSize(2);
+    assertThat(batchGetResultProto.getGetResultProtos(0).getStatus().getCode())
+        .isEqualTo(StatusProto.Code.NOT_FOUND);
+    assertThat(batchGetResultProto.getGetResultProtos(1).getStatus().getCode())
+        .isEqualTo(StatusProto.Code.NOT_FOUND);
+  }
+
+  @Test
+  public void testBatchPutWithDuplicatedDocuments() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+
+    // Two docs with same uri.
+    DocumentProto emailDocument1 = createEmailDocument("namespace", "uri");
+    DocumentProto emailDocument2 = createEmailDocument("namespace", "uri");
+    PutDocumentRequest putDocumentRequest =
+        PutDocumentRequest.newBuilder()
+            .addDocuments(emailDocument1)
+            .addDocuments(emailDocument2)
+            .build();
+    BatchPutResultProto batchPutResultProto = icingSearchEngine.batchPut(putDocumentRequest);
+
+    // We should still get two putResults back. That's intended behavior.
+    assertThat(batchPutResultProto.getPutResultProtosList()).hasSize(2);
+    assertThat(batchPutResultProto.getPutResultProtos(0).getUri()).isEqualTo("uri");
+    assertStatusOk(batchPutResultProto.getPutResultProtos(0).getStatus());
+    assertThat(batchPutResultProto.getPutResultProtos(0).getWasReplacement()).isFalse();
+    assertThat(batchPutResultProto.getPutResultProtos(1).getUri()).isEqualTo("uri");
+    assertStatusOk(batchPutResultProto.getPutResultProtos(1).getStatus());
+    assertThat(batchPutResultProto.getPutResultProtos(1).getWasReplacement()).isTrue();
+
+    // PersistToDiskResultProto should not be set if persist_type is not set in the
+    // PutDocumentRequest.
+    assertThat(batchPutResultProto.getPersistToDiskResultProto().getStatus().getCode())
+        .isEqualTo(StatusProto.Code.UNKNOWN);
+  }
+
+  @Test
+  public void testBatchPutWithEmptyRequest() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+
+    PutDocumentRequest putDocumentRequest = PutDocumentRequest.getDefaultInstance();
+    BatchPutResultProto batchPutResultProto = icingSearchEngine.batchPut(putDocumentRequest);
+
+    BatchPutResultProto expected =
+        BatchPutResultProto.newBuilder()
+            .setStatus(StatusProto.newBuilder().setCode(StatusProto.Code.OK))
+            .build();
+    assertThat(batchPutResultProto).isEqualTo(expected);
+
+    // PersistToDiskResultProto should not be set if persist_type is not set in the
+    // PutDocumentRequest.
+    assertThat(batchPutResultProto.getPersistToDiskResultProto().getStatus().getCode())
+        .isEqualTo(StatusProto.Code.UNKNOWN);
+  }
+
+  @Test
+  public void testBatchPutAndGetDocumentsWithError() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+    // Document 1 has no namespace.
+    DocumentProto emailDocument1 = DocumentProto.newBuilder().setUri("uri1").build();
+    DocumentProto emailDocument2 = createEmailDocument("namespace", "uri2");
+    PutDocumentRequest putDocumentRequest =
+        PutDocumentRequest.newBuilder()
+            .addDocuments(emailDocument1)
+            .addDocuments(emailDocument2)
+            .build();
+    BatchPutResultProto batchPutResultProto = icingSearchEngine.batchPut(putDocumentRequest);
+
+    PutResultProto putResult1 = batchPutResultProto.getPutResultProtos(0);
+    // result0 error as namespace is missing.
+    assertThat(putResult1.getUri()).isEqualTo("uri1");
+    assertWithMessage(putResult1.getStatus().getMessage())
+        .that(putResult1.getStatus().getCode())
+        .isEqualTo(StatusProto.Code.INVALID_ARGUMENT);
+    // result1 is ok.
+    assertThat(batchPutResultProto.getPutResultProtos(1).getUri()).isEqualTo("uri2");
+    assertStatusOk(batchPutResultProto.getPutResultProtos(1).getStatus());
+
+    // PersistToDiskResultProto should not be set if persist_type is not set in the
+    // PutDocumentRequest.
+    assertThat(batchPutResultProto.getPersistToDiskResultProto().getStatus().getCode())
+        .isEqualTo(StatusProto.Code.UNKNOWN);
+
+    // Check document 1
+    GetResultProto getResultProto =
+        icingSearchEngine.get("namespace", "uri1", GetResultSpecProto.getDefaultInstance());
+    assertWithMessage(getResultProto.getStatus().getMessage())
+        .that(getResultProto.getStatus().getCode())
+        .isEqualTo(StatusProto.Code.NOT_FOUND);
+    // check document 2
+    getResultProto =
+        icingSearchEngine.get("namespace", "uri2", GetResultSpecProto.getDefaultInstance());
+    assertStatusOk(getResultProto.getStatus());
+    assertThat(getResultProto.getDocument()).isEqualTo(emailDocument2);
+  }
+
+  @Test
+  public void testBatchPutWithPersistToDisk() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+
+    DocumentProto emailDocument1 = createEmailDocument("namespace", "uri1");
+    DocumentProto emailDocument2 = createEmailDocument("namespace", "uri2");
+    PutDocumentRequest putDocumentRequest =
+        PutDocumentRequest.newBuilder()
+            .addDocuments(emailDocument1)
+            .addDocuments(emailDocument2)
+            .setPersistType(PersistType.Code.FULL)
+            .build();
+    BatchPutResultProto batchPutResultProto = icingSearchEngine.batchPut(putDocumentRequest);
+
+    assertThat(batchPutResultProto.getPutResultProtos(0).getUri()).isEqualTo("uri1");
+    assertStatusOk(batchPutResultProto.getPutResultProtos(0).getStatus());
+    assertThat(batchPutResultProto.getPutResultProtos(1).getUri()).isEqualTo("uri2");
+    assertStatusOk(batchPutResultProto.getPutResultProtos(1).getStatus());
+
+    // PersistToDisk should be called if persist_type is set in the PutDocumentRequest.
+    assertStatusOk(batchPutResultProto.getPersistToDiskResultProto().getStatus());
+  }
+
   @Test
   public void testSearch() throws Exception {
     assertStatusOk(icingSearchEngine.initialize().getStatus());
diff --git a/proto/icing/proto/blob.proto b/proto/icing/proto/blob.proto
index 9ff4fc5..b9a8fc2 100644
--- a/proto/icing/proto/blob.proto
+++ b/proto/icing/proto/blob.proto
@@ -23,10 +23,10 @@ option java_package = "com.google.android.icing.proto";
 option java_multiple_files = true;
 option objc_class_prefix = "ICNG";
 
-// Defines the blob operation result proto that user try to read/write/commit a
-// blob to Icing.
+// Defines the blob operation result proto that user try to
+// read/write/commit/remove a blob to Icing.
 //
-// Next tag: 3
+// Next tag: 4
 message BlobProto {
   // Status code can be one of:
   //   OK
@@ -36,8 +36,13 @@ message BlobProto {
   //
   optional StatusProto status = 1;
 
-  // The file decriptor of the blob file from Icing.
+  // If Icing manages blob files, this is the file decriptor of the blob file
+  // from Icing returned by OpenWriteBlob and OpenReadBlob.
   optional int32 file_descriptor = 2;
+
+  // If Icing does not manage blob files, this is the file name of the blob file
+  // from Icing returned by OpenWriteBlob, OpenReadBlob and RemoveBlob.
+  optional string file_name = 3;
 }
 
 // BlobInfo holds information about a blob. It is used to store in the blob
diff --git a/proto/icing/proto/document.proto b/proto/icing/proto/document.proto
index 18ba95f..dfa0943 100644
--- a/proto/icing/proto/document.proto
+++ b/proto/icing/proto/document.proto
@@ -17,12 +17,23 @@ syntax = "proto2";
 package icing.lib;
 
 import "icing/proto/logging.proto";
+import "icing/proto/persist.proto";
 import "icing/proto/status.proto";
 
 option java_package = "com.google.android.icing.proto";
 option java_multiple_files = true;
 option objc_class_prefix = "ICNG";
 
+// Holds a list of DocumentProto.
+// Next tag: 3
+message PutDocumentRequest {
+  repeated DocumentProto documents = 1;
+
+  // The persist type used to call PersistToDisk at the end of the Put request.
+  // If not specified, PersistToDisk will not be called.
+  optional PersistType.Code persist_type = 2;
+}
+
 // Defines a unit of data understood by the IcingSearchEngine.
 // Next tag: 10
 message DocumentProto {
@@ -118,8 +129,24 @@ message PropertyProto {
   repeated BlobHandleProto blob_handle_values = 9;
 }
 
-// Result of a call to IcingSearchEngine.Put
+// Holds a list of PutResultProto.
 // Next tag: 4
+message BatchPutResultProto {
+  // The overall status of doing the batch put. It is independent of the status
+  // of the individual PutResultProtos. E.g. we may still return OK here even if
+  // all the PutResultProto have errors. Or return INTERNAL_ERROR if there is
+  // some issue parsing this proto, even if all documents are indexed
+  // successfully.
+  optional StatusProto status = 3;
+  repeated PutResultProto put_result_protos = 1;
+
+  // The result of calling PersistToDisk at the end of the BatchPut request if
+  // PutDocumentRequest.persist_type is set.
+  optional PersistToDiskResultProto persist_to_disk_result_proto = 2;
+}
+
+// Result of a call to IcingSearchEngine.Put
+// Next tag: 5
 message PutResultProto {
   // Status code can be one of:
   //   OK
@@ -134,6 +161,9 @@ message PutResultProto {
   // go/icing-library-apis.
   optional StatusProto status = 1;
 
+  // The uri of the document that was put.
+  optional string uri = 4;
+
   // Stats of the function call. Inside PutDocumentStatsProto, the function
   // call latency 'latency_ms' will always be populated. The other fields will
   // be accurate only when the status above is OK. See logging.proto for
@@ -145,7 +175,7 @@ message PutResultProto {
 }
 
 // Result of a call to IcingSearchEngine.Get
-// Next tag: 3
+// Next tag: 4
 message GetResultProto {
   // Status code can be one of:
   //   OK
@@ -159,11 +189,25 @@ message GetResultProto {
   // go/icing-library-apis.
   optional StatusProto status = 1;
 
+  // The uri of the document that was retrieved, or failed to be retrieved.
+  // It won't be set now for a single Get call, as the caller knows the uri if
+  // the Get fails.
+  // TODO(b/404275015) We should always set this field in Get once we refactor
+  // the tests.
+  optional string uri = 3;
+
   // Copy of the Document proto with the specified name_space, uri. Modifying
   // this does not affect the Document in IcingSearchEngine.
   optional DocumentProto document = 2;
 }
 
+// Result of a call to IcingSearchEngine.BatchGet
+// Next tag: 3
+message BatchGetResultProto {
+  optional StatusProto status = 1;
+  repeated GetResultProto get_result_protos = 2;
+}
+
 // Result of a call to IcingSearchEngine.GetAllNamespaces
 // Next tag: 3
 message GetAllNamespacesResultProto {
diff --git a/proto/icing/proto/initialize.proto b/proto/icing/proto/initialize.proto
index 35290d0..5977aa9 100644
--- a/proto/icing/proto/initialize.proto
+++ b/proto/icing/proto/initialize.proto
@@ -64,15 +64,15 @@ message IcingSearchEngineFeatureInfoProto {
     // single database field at a time.
     FEATURE_SCHEMA_DATABASE = 5;
 
-    // Feature for flag IcingSearchEngineOptions::
-    // enable_qualified_id_join_index_v3_and_delete_propagate_from.
+    // Feature for flag
+    // IcingSearchEngineOptions::enable_qualified_id_join_index_v3.
     //
-    // This feature covers whether to enable the join index v3 and support
-    // delete propagation PROPAGATE_FROM. Once enabled, join index v3 will be
-    // rebuilt to replace v2, and deleteing a document will also delete its
-    // child document(s) which refer to it via a joinable property with delete
-    // propagation type PROPAGATE_FROM.
-    FEATURE_QUALIFIED_ID_JOIN_INDEX_V3_AND_DELETE_PROPAGATE_FROM = 6;
+    // This feature covers whether to enable the join index v3. Once enabled,
+    // join index v3 will be rebuilt to replace v2.
+    FEATURE_QUALIFIED_ID_JOIN_INDEX_V3 = 6;
+
+    // TODO(b/384947619): decide whether need to add a feature type for delete
+    // propagation.
   }
 
   // Whether the feature requires the document store to be rebuilt.
@@ -109,7 +109,35 @@ message IcingSearchEngineVersionProto {
   repeated IcingSearchEngineFeatureInfoProto enabled_features = 3;
 }
 
-// Next tag: 26
+// This proto is used by the marker file to record information about the last
+// incomplete operation that was performed on Icing.
+// - Usually the marker file is required for a complex operation which is
+//   sensitive to power loss or crash.
+// - The marker file is created before the complex operation and flushed to disk
+//   with essential information. It is deleted after the operation is completed.
+// - If the marker file is present during initialization, then it means the
+//   last operation was not completed due to power loss or crash.
+//
+// Next tag: 2
+message IcingSearchEngineMarkerProto {
+  // Next tag: 3
+  message OperationType {
+    enum Code {
+      // This value should never purposely be used. This is used for backwards
+      // compatibility reasons.
+      UNKNOWN = 0;
+
+      // SetSchema operation.
+      SET_SCHEMA = 1;
+
+      // Optimize operation.
+      OPTIMIZE = 2;
+    }
+  }
+  optional OperationType.Code operation_type = 1;
+}
+
+// Next tag: 35
 message IcingSearchEngineOptions {
   // Directory to persist files for Icing. Required.
   // If Icing was previously initialized with this directory, it will reload
@@ -265,8 +293,8 @@ message IcingSearchEngineOptions {
   // Whether to allow repeated fields to have a joinable value type.
   optional bool enable_repeated_field_joins = 24;
 
-  // Whether to use qualified id join index v3 and enable delete propagation
-  // PROPAGATE_FROM.
+  // DEPRECATED (separate them into 2 flags): whether to use qualified id join
+  // index v3 and enable delete propagation PROPAGATE_FROM.
   //
   // - If set to true, qualified id join index v3 will be created and delete
   //   propagation PROPAGATE_FROM will be enabled.
@@ -277,6 +305,62 @@ message IcingSearchEngineOptions {
   optional bool enable_qualified_id_join_index_v3_and_delete_propagate_from =
       25;
 
+  // The absolute path to the ICU data file.
+  // If set, ICU will be initialized using this data file.
+  optional string icu_data_file_absolute_path = 26;
+
+  // Whether a backup schema and document should be generated for documents with
+  // embedding properties.
+  optional bool enable_embedding_backup_generation = 27;
+
+  // Whether to calculate time since last optimize using last attempted optimize
+  // run time instead of last successful optimize run time.
+  // - If set to true, time since last optimize is calculated using last
+  //   attempted optimize run time, regardless of whether the optimize run was
+  //   successful or not.
+  // - Otherwise, time since last optimize is calculated using last successful
+  //   optimize run time.
+  //
+  // The default value is false.
+  optional bool calculate_time_since_last_attempted_optimize = 28;
+
+  // Whether to use qualified id join index v3.
+  //
+  // If set to true, qualified id join index v3 will be created.
+  // Otherwise, qualified id join index v2 will be created.
+  optional bool enable_qualified_id_join_index_v3 = 29;
+
+  // Whether to enable delete propagation PROPAGATE_FROM.
+  //
+  // If set to true, enable_qualified_id_join_index_v3 must be also true
+  // (otherwise initialization will fail), and delete propagation PROPAGATE_FROM
+  // will be enabled.
+  // Otherwise, delete propagation will be disabled.
+  optional bool enable_delete_propagation_from = 30;
+
+  // Whether to enable soft index restoration.
+  // If set to true, then any error that occurs during index restoration will be
+  // ignored, and the failed document will be deleted.
+  optional bool enable_soft_index_restoration = 31;
+
+  // Whether to enable marker file for optimize API.
+  // If set to true, then a general marker file will be created before any
+  // optimize operation is performed, and deleted after the operation is
+  // completed. This is to ensure that the optimize operation is not interrupted
+  // by power loss or crash.
+  optional bool enable_marker_file_for_optimize = 32;
+
+  // Whether to manage blob files.
+  // If set to true, then Icing will manage blob files and all APIs will return
+  // valid FileDescriptors. If false, then Icing will only manage blob metadata
+  // and will return the names of the files to be created and managed by the
+  // caller.
+  optional bool manage_blob_files = 33 [default = true];
+
+  // Whether to release the backup schema file instance in the schema-store if
+  // the overlay exists.
+  optional bool release_backup_schema_file_if_overlay_present = 34;
+
   reserved 2, 20;
 }
 
diff --git a/proto/icing/proto/internal/optimize.proto b/proto/icing/proto/internal/optimize.proto
index 4ed3d73..0581fb6 100644
--- a/proto/icing/proto/internal/optimize.proto
+++ b/proto/icing/proto/internal/optimize.proto
@@ -22,8 +22,13 @@ option objc_class_prefix = "ICNG";
 
 // A status that is saved internally in Icing to track information about how
 // often Optimize runs.
-// Next tag: 2
+// Next tag: 3
 message OptimizeStatusProto {
-  // The Epoch time at which the last successfuly optimize ran.
+  // The Epoch time at which the last successful optimize was completed.
   optional int64 last_successful_optimize_run_time_ms = 1;
+
+  // The Epoch time at which IcingSearchEngine::Optimize was last called. This
+  // captures the previous optimize run regardless of whether it was successful
+  // or not.
+  optional int64 last_attempted_optimize_run_time_ms = 2;
 }
diff --git a/proto/icing/proto/logging.proto b/proto/icing/proto/logging.proto
index 46e988e..2e620cd 100644
--- a/proto/icing/proto/logging.proto
+++ b/proto/icing/proto/logging.proto
@@ -17,13 +17,14 @@ syntax = "proto2";
 package icing.lib;
 
 import "icing/proto/scoring.proto";
+import "icing/proto/status.proto";
 
 option java_package = "com.google.android.icing.proto";
 option java_multiple_files = true;
 option objc_class_prefix = "ICNG";
 
 // Stats of the top-level function IcingSearchEngine::Initialize().
-// Next tag: 15
+// Next tag: 17
 message InitializeStatsProto {
   // Overall time used for the function call.
   optional int32 latency_ms = 1;
@@ -40,7 +41,8 @@ message InitializeStatsProto {
     // Data in index is inconsistent with ground truth.
     INCONSISTENT_WITH_GROUND_TRUTH = 2;
 
-    // Changes were made to the schema, but possibly not fully applied to the
+    // Changes were made to the schema, but the marker file remains in the
+    // filesystem indicating that changes possibly were not fully applied to the
     // document store and the index - requiring a recovery.
     SCHEMA_CHANGES_OUT_OF_SYNC = 3;
 
@@ -59,6 +61,18 @@ message InitializeStatsProto {
     // Change detected in Icing's feature flags since last initialization that
     // requires recovery.
     FEATURE_FLAG_CHANGED = 8;
+
+    // Changes were made by an incomplete complex operation, which caused marker
+    // file to remain in the filesystem - requiring a recovery.
+    //
+    // Note: Icing is unable to interpret the information from the marker file
+    // due to some reasons, so the OUT_OF_SYNC reason is UNKNOWN.
+    UNKNOWN_OUT_OF_SYNC = 9;
+
+    // Changes were made by optimize, but the marker file remains in the
+    // filesystem indicating that optimize possibly was not fully applied to the
+    // document store and the index - requiring a recovery.
+    OPTIMIZE_OUT_OF_SYNC = 10;
   }
 
   // Possible recovery causes for document store:
@@ -127,6 +141,15 @@ message InitializeStatsProto {
   // - SCHEMA_CHANGES_OUT_OF_SYNC
   // - IO_ERROR
   optional RecoveryCause embedding_index_restoration_cause = 14;
+
+  // Possible status codes for ICU data initialization.
+  // - OK
+  // - INVALID_ARGUMENT
+  // - INTERNAL
+  optional StatusProto initialize_icu_data_status = 15;
+
+  // Number of documents that failed to be reindexed during index restoration.
+  optional int32 num_failed_reindexed_documents = 16;
 }
 
 // Stats of the top-level function IcingSearchEngine::Put().
diff --git a/proto/icing/proto/optimize.proto b/proto/icing/proto/optimize.proto
index 675f980..0ba0a86 100644
--- a/proto/icing/proto/optimize.proto
+++ b/proto/icing/proto/optimize.proto
@@ -23,7 +23,7 @@ option java_multiple_files = true;
 option objc_class_prefix = "ICNG";
 
 // Result of a call to IcingSearchEngine.Optimize
-// Next tag: 3
+// Next tag: 4
 message OptimizeResultProto {
   // Status code can be one of:
   //   OK
@@ -36,6 +36,11 @@ message OptimizeResultProto {
   optional StatusProto status = 1;
 
   optional OptimizeStatsProto optimize_stats = 2;
+
+  // If Icing does not manage blob files, this field will be the list of blob
+  // file names that should be removed. Otherwise, this field will be empty.
+  repeated string blob_file_names_to_remove = 3;
+
   // TODO(b/147699081): Add a field to indicate lost_schema and lost_documents.
   // go/icing-library-apis.
 }
@@ -63,7 +68,7 @@ message GetOptimizeInfoResultProto {
   optional int64 time_since_last_optimize_ms = 4;
 }
 
-// Next tag: 13
+// Next tag: 14
 message OptimizeStatsProto {
   // Overall time used for the function call.
   optional int32 latency_ms = 1;
@@ -92,6 +97,9 @@ message OptimizeStatsProto {
   // The amount of time since the last optimize ran.
   optional int64 time_since_last_optimize_ms = 9;
 
+  // The amount of time since the last successful optimize run.
+  optional int64 time_since_last_successful_optimize_ms = 13;
+
   enum IndexRestorationMode {
     // The index has been translated in place to match the optimized document
     // store.
diff --git a/proto/icing/proto/schema.proto b/proto/icing/proto/schema.proto
index 2a461bf..1f7eb4b 100644
--- a/proto/icing/proto/schema.proto
+++ b/proto/icing/proto/schema.proto
@@ -423,6 +423,37 @@ message SchemaProto {
   repeated SchemaTypeConfigProto types = 1;
 }
 
+// Request for a call to IcingSearchEngine.SetSchema
+// Next tag: 4
+message SetSchemaRequestProto {
+  // REQUIRED: The new schema to set. This will replace the existing schema
+  // stored in IcingSearchEngine.
+  //
+  // schema.types is allowed to be empty. In this case, the SetSchema call will
+  // try to delete all types and indexed documents for the provided database,
+  // which is only allowed if ignore_errors_and_delete_documents=true
+  optional SchemaProto schema = 1;
+
+  // OPTIONAL: The database for the set schema request. Only schema types for
+  // this database will be modified.
+  //
+  // For a valid set schema request, this must match the database fields of
+  // schema.types.
+  //
+  // If unset, the default empty database is assumed for the set schema request.
+  optional string database = 2;
+
+  // OPTIONAL: Whether to ignore errors and delete documents when setting the
+  // schema.
+  //
+  // If true, then Icing will try to set the schema even if it is incompatible.
+  // In that case, documents that are invalidated by the new schema would be
+  // deleted from Icing. This cannot be used to force set an invalid schema.
+  //
+  // The default value is false.
+  optional bool ignore_errors_and_delete_documents = 3;
+}
+
 // Result of a call to IcingSearchEngine.SetSchema
 // Next tag: 9
 message SetSchemaResultProto {
diff --git a/proto/icing/proto/search.proto b/proto/icing/proto/search.proto
index 45e3736..40de819 100644
--- a/proto/icing/proto/search.proto
+++ b/proto/icing/proto/search.proto
@@ -164,6 +164,15 @@ message ResultSpecProto {
     // max_window_utf32_length = 16. "foo bar baz bat rat" with a query of "baz"
     // will return a window of "bar baz bat" which is only 11 bytes long.
     optional int32 max_window_utf32_length = 3;
+
+    // Whether to get match info for embedding semantic search. Embedding match
+    // info is returned in
+    // ResultProto.SnippetProto.EntryProto.EmbeddingMatchSnippetProto and
+    // contains the following information:
+    // - The score of the matched embedding vector.
+    // - The index of the embedding query for this vector match.
+    // - The metric type of the embedding query for this vector match.
+    optional bool get_embedding_match_info = 4;
   }
   optional SnippetSpecProto snippet_spec = 3;
 
@@ -311,12 +320,28 @@ message SnippetMatchProto {
   reserved 1;
 }
 
+// The representation of a single embedding vector match within a DocumentProto
+// property.
+//
+// Next tag: 4
+message EmbeddingMatchSnippetProto {
+  // Semantic score of the matched embedding vector.
+  optional double semantic_score = 1;
+
+  // Index of the embedding query for this vector match.
+  optional int32 embedding_query_vector_index = 2;
+
+  // The metric type of the embedding query for this vector match.
+  optional SearchSpecProto.EmbeddingQueryMetricType.Code
+      embedding_query_metric_type = 3;
+}
+
 // A Proto representing all snippets for a single DocumentProto.
 // Next tag: 2
 message SnippetProto {
   // A pair of property name and all snippet matches that correspond to the
   // property values in the corresponding DocumentProto.
-  // Next tag: 3
+  // Next tag: 4
   message EntryProto {
     // A property path indicating which property in the DocumentProto these
     // snippets correspond to. Property paths will contain 1) property names,
@@ -343,7 +368,14 @@ message SnippetProto {
     // 'attachements[0]').
     optional string property_name = 1;
 
+    // The term-match info for this property. Only populated if the property is
+    // a string.
     repeated SnippetMatchProto snippet_matches = 2;
+
+    // The embedding-match info for this property. Only populated if the
+    // property is an embedding vector and get_embedding_match_info is set to
+    // true in the ResultSpecProto.
+    repeated EmbeddingMatchSnippetProto embedding_matches = 3;
   }
   // Properties that do not appear in entries do not contain any matches.
   repeated EntryProto entries = 1;
@@ -427,12 +459,23 @@ message TypePropertyMask {
   repeated string paths = 2;
 }
 
-// Next tag: 2
+// Next tag: 5
+// TODO(b/394875109): Rename it to GetRequestProto to be consistent with the
+// name in AppSearch.
 message GetResultSpecProto {
+  optional string namespace_requested = 2;
+  repeated string ids = 3;
+
   // How to specify a subset of properties to retrieve. If no type property mask
   // has been specified for a schema type, then *all* properties of that schema
   // type will be retrieved.
   repeated TypePropertyMask type_property_masks = 1;
+
+  // The maximum number of accumulated bytes for the documents to return in the
+  // result. This limit is to prevent the result from being too large, and we
+  // can't send it over VM boundary, which has transaction limit 600KB.
+  optional int32 num_total_document_bytes_to_return = 4
+      [default = 2147483647];  // INT_MAX
 }
 
 // Next tag: 12
diff --git a/proto/icing/proto/storage.proto b/proto/icing/proto/storage.proto
index 266576d..a9eb84a 100644
--- a/proto/icing/proto/storage.proto
+++ b/proto/icing/proto/storage.proto
@@ -163,16 +163,22 @@ message IndexStorageInfoProto {
   optional float min_free_fraction = 8;
 }
 
-// Next tag: 4
+// Next tag: 5
 message NamespaceBlobStorageInfoProto {
-  // The package name of who own the blobs.
+  // The namespace name of who own the blobs.
   optional string namespace = 1;
 
-  // Total size of blobs storage of this package in bytes.
+  // If Icing manages blob files, this field will be the total size of blobs
+  // storage of this namespace in bytes. Otherwise, this field will be unset.
   optional int64 blob_size = 2;
 
-  // Total number of blobs of this package.
+  // If Icing manages blob files, this field will be the total number of blobs
+  // of this namespace. Otherwise, this field will be unset.
   optional int32 num_blobs = 3;
+
+  // If Icing does not manage blob files, this field will be the list of blob
+  // file names in this namespace. Otherwise, this field will be empty.
+  repeated string blob_file_names = 4;
 }
 
 // Next tag: 6
diff --git a/synced_AOSP_CL_number.txt b/synced_AOSP_CL_number.txt
index e32586a..305570d 100644
--- a/synced_AOSP_CL_number.txt
+++ b/synced_AOSP_CL_number.txt
@@ -1 +1 @@
-set(synced_AOSP_CL_number=702081687)
+set(synced_AOSP_CL_number=738860467)
```

