```diff
diff --git a/.coveragerc b/.coveragerc
new file mode 100644
index 0000000..38d01e1
--- /dev/null
+++ b/.coveragerc
@@ -0,0 +1,9 @@
+[report]
+exclude_lines =
+    pragma: no cover
+    def __repr__
+    if TYPE_CHECKING:
+    raise NotImplementedError
+    if __name__ == .__main__.:
+    @abc.abstractmethod
+    except selenium.common.exceptions.WebDriverException as e:
\ No newline at end of file
diff --git a/.gitattributes b/.gitattributes
new file mode 100644
index 0000000..448e9a2
--- /dev/null
+++ b/.gitattributes
@@ -0,0 +1,5 @@
+# Automatically normalize line endings (to LF) for all text-based files.
+* text=auto eol=lf
+# Do not modify line endings for binary files (which are sometimes auto
+# detected as text files by git).
+*.png binary
\ No newline at end of file
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..1dc09ae
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,10 @@
+*.pyc
+.*
+!.vpython3
+__pycache__
+dist
+results
+binary_cache
+.DS_Store
+third_party
+cache
\ No newline at end of file
diff --git a/.gitmodules b/.gitmodules
new file mode 100644
index 0000000..44b3bf8
--- /dev/null
+++ b/.gitmodules
@@ -0,0 +1,6 @@
+[submodule "third_party/tsproxy"]
+	path = third_party/tsproxy
+	url = https://chromium.googlesource.com/external/github.com/catchpoint/WebPageTest.tsproxy
+[submodule "third_party/webpagereplay"]
+	path = third_party/webpagereplay
+	url = https://chromium.googlesource.com/webpagereplay
diff --git a/.pylintrc b/.pylintrc
new file mode 100644
index 0000000..ee2e242
--- /dev/null
+++ b/.pylintrc
@@ -0,0 +1,434 @@
+# This Pylint rcfile contains a best-effort configuration to uphold the
+# best-practices and style described in the Google Python style guide:
+#   https://google.github.io/styleguide/pyguide.html
+#
+# Its canonical open-source location is:
+#   https://google.github.io/styleguide/pylintrc
+
+[MASTER]
+
+# Files or directories to be skipped. They should be base names, not paths.
+ignore=third_party
+
+# Files or directories matching the regex patterns are skipped. The regex
+# matches against base names, not paths.
+ignore-patterns=
+
+# Pickle collected data for later comparisons.
+persistent=no
+
+# List of plugins (as comma separated values of python modules names) to load,
+# usually to register additional checkers.
+load-plugins=
+
+# Use multiple processes to speed up Pylint.
+jobs=4
+
+# Allow loading of arbitrary C extensions. Extensions are imported into the
+# active Python interpreter and may run arbitrary code.
+unsafe-load-any-extension=no
+
+
+[MESSAGES CONTROL]
+
+# Only show warnings with the listed confidence levels. Leave empty to show
+# all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED
+confidence=
+
+# Enable the message, report, category or checker with the given id(s). You can
+# either give multiple identifier separated by comma (,) or put this option
+# multiple time (only on the command line, not in the configuration file where
+# it should appear only once). See also the "--disable" option for examples.
+#enable=
+
+# Disable the message, report, category or checker with the given id(s). You
+# can either give multiple identifiers separated by comma (,) or put this
+# option multiple times (only on the command line, not in the configuration
+# file where it should appear only once).You can also use "--disable=all" to
+# disable everything first and then reenable specific checks. For example, if
+# you want to run only the similarities checker, you can use "--disable=all
+# --enable=similarities". If you want to run only the classes checker, but have
+# no Warning level messages displayed, use"--disable=all --enable=classes
+# --disable=W"
+disable=abstract-method,
+        apply-builtin,
+        arguments-differ,
+        attribute-defined-outside-init,
+        backtick,
+        bad-option-value,
+        basestring-builtin,
+        buffer-builtin,
+        c-extension-no-member,
+        consider-using-enumerate,
+        cmp-builtin,
+        cmp-method,
+        coerce-builtin,
+        coerce-method,
+        delslice-method,
+        div-method,
+        duplicate-code,
+        eq-without-hash,
+        execfile-builtin,
+        file-builtin,
+        filter-builtin-not-iterating,
+        fixme,
+        getslice-method,
+        global-statement,
+        hex-method,
+        idiv-method,
+        implicit-str-concat,
+        import-error,
+        import-self,
+        import-star-module-level,
+        inconsistent-return-statements,
+        input-builtin,
+        intern-builtin,
+        invalid-str-codec,
+        locally-disabled,
+        long-builtin,
+        long-suffix,
+        map-builtin-not-iterating,
+        misplaced-comparison-constant,
+        missing-function-docstring,
+        metaclass-assignment,
+        missing-class-docstring, # added
+        missing-module-docstring, # added
+        next-method-called,
+        next-method-defined,
+        no-absolute-import,
+        no-else-break,
+        no-else-continue,
+        no-else-raise,
+        no-else-return,
+        no-init,  # added
+        no-member,
+        no-name-in-module,
+        no-self-use,
+        nonzero-method,
+        oct-method,
+        old-division,
+        old-ne-operator,
+        old-octal-literal,
+        old-raise-syntax,
+        parameter-unpacking,
+        print-statement,
+        raising-string,
+        range-builtin-not-iterating,
+        raw_input-builtin,
+        rdiv-method,
+        reduce-builtin,
+        relative-import,
+        reload-builtin,
+        round-builtin,
+        setslice-method,
+        signature-differs,
+        standarderror-builtin,
+        suppressed-message,
+        sys-max-int,
+        too-few-public-methods,
+        too-many-ancestors,
+        too-many-arguments,
+        too-many-boolean-expressions,
+        too-many-branches,
+        too-many-instance-attributes,
+        too-many-locals,
+        too-many-nested-blocks,
+        too-many-positional-arguments,
+        too-many-public-methods,
+        too-many-return-statements,
+        too-many-statements,
+        trailing-newlines,
+        unichr-builtin,
+        unicode-builtin,
+        unnecessary-pass,
+        unpacking-in-except,
+        useless-else-on-loop,
+        useless-object-inheritance,
+        useless-suppression,
+        using-cmp-argument,
+        # wrong-import-order,
+        xrange-builtin,
+        zip-builtin-not-iterating,
+
+
+[REPORTS]
+
+# Set the output format. Available formats are text, parseable, colorized, msvs
+# (visual studio) and html. You can also give a reporter class, eg
+# mypackage.mymodule.MyReporterClass.
+output-format=text
+
+# Tells whether to display a full report or only the messages
+reports=no
+
+# Python expression which should return a note less than 10 (10 is the highest
+# note). You have access to the variables errors warning, statement which
+# respectively contain the number of errors / warnings messages and the total
+# number of statements analyzed. This is used by the global evaluation report
+# (RP0004).
+evaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)
+
+# Template used to display messages. This is a python new-style format string
+# used to format the message information. See doc for all details
+#msg-template=
+
+
+[BASIC]
+
+# Good variable names which should always be accepted, separated by a comma
+good-names=main,_
+
+# Bad variable names which should always be refused, separated by a comma
+bad-names=
+
+# Colon-delimited sets of names that determine each other's naming style when
+# the name regexes allow several styles.
+name-group=
+
+# Include a hint for the correct naming format with invalid-name
+include-naming-hint=no
+
+# List of decorators that produce properties, such as abc.abstractproperty. Add
+# to this list to register other decorators that produce valid properties.
+property-classes=abc.abstractproperty,cached_property.cached_property,cached_property.threaded_cached_property,cached_property.cached_property_with_ttl,cached_property.threaded_cached_property_with_ttl
+
+# Regular expression matching correct function names
+function-rgx=^(?:(?P<exempt>setUp|tearDown|setUpModule|tearDownModule)|(?P<camel_case>_?[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_?[a-z][a-z0-9_]*))$
+
+# Regular expression matching correct variable names
+variable-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct constant names
+const-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct attribute names
+attr-rgx=^_{0,2}[a-z][a-z0-9_]*$
+
+# Regular expression matching correct argument names
+argument-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class attribute names
+class-attribute-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$
+
+# Regular expression matching correct inline iteration names
+inlinevar-rgx=^[a-z][a-z0-9_]*$
+
+# Regular expression matching correct class names
+class-rgx=^_?[A-Z][a-zA-Z0-9]*$
+
+# Regular expression matching correct module names
+module-rgx=^(_?[a-z][a-z0-9_]*|__init__|PRESUBMIT)$
+
+# Regular expression matching correct method names
+method-rgx=(?x)^(?:(?P<exempt>_[a-z0-9_]+__|runTest|setUp|tearDown|setUpTestCase|tearDownTestCase|setupSelf|tearDownClass|setUpClass|(test|assert)_*[A-Z0-9][a-zA-Z0-9_]*|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9_]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$
+
+# Regular expression which should only match function or class names that do
+# not require a docstring.
+no-docstring-rgx=(__.*__|main|test.*|.*test|.*Test)$
+
+# Minimum line length for functions/classes that require docstrings, shorter
+# ones are exempt.
+docstring-min-length=10
+
+
+[TYPECHECK]
+
+# List of decorators that produce context managers, such as
+# contextlib.contextmanager. Add to this list to register other decorators that
+# produce valid context managers.
+contextmanager-decorators=contextlib.contextmanager,contextlib2.contextmanager
+
+# Tells whether missing members accessed in mixin class should be ignored. A
+# mixin class is detected if its name ends with "mixin" (case insensitive).
+ignore-mixin-members=yes
+
+# List of module names for which member attributes should not be checked
+# (useful for modules/projects where namespaces are manipulated during runtime
+# and thus existing member attributes cannot be deduced by static analysis. It
+# supports qualified module names, as well as Unix pattern matching.
+ignored-modules=
+
+# List of class names for which member attributes should not be checked (useful
+# for classes with dynamically set attributes). This supports the use of
+# qualified names.
+ignored-classes=optparse.Values,thread._local,_thread._local
+
+# List of members which are set dynamically and missed by pylint inference
+# system, and so shouldn't trigger E1101 when accessed. Python regular
+# expressions are accepted.
+generated-members=
+
+
+[FORMAT]
+
+# Maximum number of characters on a single line.
+max-line-length=80
+
+# TODO(https://github.com/PyCQA/pylint/issues/3352): Direct pylint to exempt
+# lines made too long by directives to pytype.
+
+# Regexp for a line that is allowed to be longer than the limit.
+ignore-long-lines=(?x)(
+  .*https?://\S+>?$|
+  ^\s*(from\s+\S+\s+)?import\s+.+$|
+  .*\spylint:\sdisable=\S+$|
+  .*\spytype:\sdisable=\S+$)
+
+# Allow the body of an if to be on the same line as the test if there is no
+# else.
+single-line-if-stmt=yes
+
+# Maximum number of lines in a module
+max-module-lines=99999
+
+# String used as indentation unit.  The internal Google style guide mandates 2
+# spaces.  Google's externaly-published style guide says 4, consistent with
+# PEP 8.  Here, we use 2 spaces, for conformity with many open-sourced Google
+# projects (like TensorFlow).
+indent-string='  '
+
+# Number of spaces of indent required inside a hanging  or continued line.
+indent-after-paren=4
+
+# Expected format of line ending, e.g. empty (any line ending), LF or CRLF.
+expected-line-ending-format=
+
+
+[MISCELLANEOUS]
+
+# List of note tags to take in consideration, separated by a comma.
+notes=TODO
+
+
+[STRING]
+
+# This flag controls whether inconsistent-quotes generates a warning when the
+# character used as a quote delimiter is used inconsistently within a module.
+check-quote-consistency=yes
+
+
+[VARIABLES]
+
+# Tells whether we should check for unused import in __init__ files.
+init-import=no
+
+# A regular expression matching the name of dummy variables (i.e. expectedly
+# not used).
+dummy-variables-rgx=^\*{0,2}(_$|unused_|dummy_)
+
+# List of additional names supposed to be defined in builtins. Remember that
+# you should avoid to define new builtins when possible.
+additional-builtins=
+
+# List of strings which can identify a callback function by name. A callback
+# name must start or end with one of those strings.
+callbacks=cb_,_cb
+
+# List of qualified module names which can have objects that can redefine
+# builtins.
+redefining-builtins-modules=six,six.moves,past.builtins,future.builtins,functools
+
+
+[LOGGING]
+
+# Logging modules to check that the string format arguments are in logging
+# function parameter format
+logging-modules=logging,absl.logging,tensorflow.io.logging
+
+
+[SIMILARITIES]
+
+# Minimum lines number of a similarity.
+min-similarity-lines=4
+
+# Ignore comments when computing similarities.
+ignore-comments=yes
+
+# Ignore docstrings when computing similarities.
+ignore-docstrings=yes
+
+# Ignore imports when computing similarities.
+ignore-imports=no
+
+
+[SPELLING]
+
+# Spelling dictionary name. Available dictionaries: none. To make it working
+# install python-enchant package.
+spelling-dict=
+
+# List of comma separated words that should not be checked.
+spelling-ignore-words=
+
+# A path to a file that contains private dictionary; one word per line.
+spelling-private-dict-file=
+
+# Tells whether to store unknown words to indicated private dictionary in
+# --spelling-private-dict-file option instead of raising a message.
+spelling-store-unknown-words=no
+
+
+[IMPORTS]
+
+# Deprecated modules which should not be used, separated by a comma
+deprecated-modules=regsub,
+                   TERMIOS,
+                   Bastion,
+                   rexec,
+                   sets
+
+# Create a graph of every (i.e. internal and external) dependencies in the
+# given file (report RP0402 must not be disabled)
+import-graph=
+
+# Create a graph of external dependencies in the given file (report RP0402 must
+# not be disabled)
+ext-import-graph=
+
+# Create a graph of internal dependencies in the given file (report RP0402 must
+# not be disabled)
+int-import-graph=
+
+# Force import order to recognize a module as part of the standard
+# compatibility libraries.
+known-standard-library=
+
+# Force import order to recognize a module as part of a third party library.
+known-third-party=enchant, absl
+
+# Analyse import fallback blocks. This can be used to support both Python 2 and
+# 3 compatible code, which means that the block might have code that exists
+# only in one or another interpreter, leading to false positives when analysed.
+analyse-fallback-blocks=no
+
+
+[CLASSES]
+
+# List of method names used to declare (i.e. assign) instance attributes.
+defining-attr-methods=__init__,
+                      __new__,
+                      setUp
+
+# List of member names, which should be excluded from the protected access
+# warning.
+exclude-protected=_asdict,
+                  _fields,
+                  _replace,
+                  _source,
+                  _make
+
+# List of valid names for the first argument in a class method.
+valid-classmethod-first-arg=cls,
+                            class_
+
+# List of valid names for the first argument in a metaclass class method.
+valid-metaclass-classmethod-first-arg=mcs
+
+
+[EXCEPTIONS]
+
+# Exceptions that will emit a warning when being caught. Defaults to
+# "Exception"
+overgeneral-exceptions=builtins.StandardError,
+                       builtins.Exception,
+                       builtins.BaseException
diff --git a/.style.yapf b/.style.yapf
new file mode 100644
index 0000000..fdd0723
--- /dev/null
+++ b/.style.yapf
@@ -0,0 +1,2 @@
+[style]
+based_on_style = yapf
diff --git a/.vpython3 b/.vpython3
new file mode 100644
index 0000000..03d1a0b
--- /dev/null
+++ b/.vpython3
@@ -0,0 +1,316 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+
+wheel: <
+  name: "infra/python/wheels/pytype/${vpython_platform}"
+  version: "version:2024.1.24"
+  not_match_tag: <
+    platform: "win_amd64"
+  >
+>
+
+wheel: <
+  name: "infra/python/wheels/pytest-py3"
+  version: "version:6.2.2"
+>
+
+# Required by pytest 6.2.2 on Windows only
+wheel: <
+  name: "infra/python/wheels/atomicwrites-py2_py3"
+  version: "version:1.3.0"
+  match_tag: <
+    platform: "win_amd64"
+  >
+>
+
+wheel: <
+  name: "infra/python/wheels/selenium-py3"
+  version: "version:4.10.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/psutil/${vpython_platform}"
+  version: "version:5.8.0.chromium.3"
+>
+
+wheel: <
+  name: "infra/python/wheels/websockets-py3"
+  version: "version:10.3"
+>
+
+wheel: <
+  name: "infra/python/wheels/pyfakefs-py3"
+  version: "version:5.5.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/attrs-py2_py3"
+  version: "version:21.4.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/py-py2_py3"
+  version: "version:1.10.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/pysocks-py3"
+  version: "version:1.7.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/execnet-py3"
+  version: "version:2.0.2"
+>
+
+wheel: <
+  name: "infra/python/wheels/pluggy-py3"
+  version: "version:0.13.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/colorama-py2_py3"
+  version: "version:0.4.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/iniconfig-py3"
+  version: "version:1.1.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/pytest-xdist-py3"
+  version: "version:3.3.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/immutabledict-py3"
+  version: "version:4.1.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/pyyaml-py3"
+  version: "version:5.3.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/typing-inspect-py3"
+  version: "version:0.7.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/mypy-extensions-py3"
+  version: "version:0.4.3"
+>
+
+wheel: <
+  name: "infra/python/wheels/importlab-py3"
+  version: "version:0.8"
+>
+
+wheel: <
+  name: "infra/python/wheels/zstandard/${vpython_platform}"
+  version: "version:0.16.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/networkx-py3"
+  version: "version:2.5"
+>
+
+wheel: <
+  name: "infra/python/wheels/decorator-py3"
+  version: "version:5.0.9"
+>
+
+wheel: <
+  name: "infra/python/wheels/ninja/${vpython_platform}"
+  version: "version:1.10.2.4"
+>
+
+wheel: <
+  name: "infra/python/wheels/libcst/${vpython_platform}"
+  version: "version:1.1.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/typing-extensions-py3"
+  version: "version:4.3.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/jinja2-py3"
+  version: "version:3.1.2"
+>
+
+wheel: <
+  name: "infra/python/wheels/toml-py3"
+  version: "version:0.10.2"
+>
+
+wheel: <
+  name: "infra/python/wheels/packaging-py2_py3"
+  version: "version:16.8"
+>
+
+wheel: <
+  name: "infra/python/wheels/pyparsing-py2_py3"
+  version: "version:2.4.7"
+>
+
+wheel: <
+  name: "infra/python/wheels/six-py2_py3"
+  version: "version:1.10.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/trio-py3"
+  version: "version:0.20.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/trio-websocket-py3"
+  version: "version:0.9.2"
+>
+
+wheel: <
+  name: "infra/python/wheels/urllib3-py2_py3"
+  version: "version:1.26.6"
+>
+
+wheel: <
+  name: "infra/python/wheels/sortedcontainers-py3"
+  version: "version:2.4.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/outcome-py3"
+  version: "version:1.1.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/async-generator-py3"
+  version: "version:1.10"
+>
+
+wheel: <
+  name: "infra/python/wheels/sniffio-py3"
+  version: "version:1.2.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/idna-py2_py3"
+  version: "version:2.10"
+>
+
+wheel: <
+  name: "infra/python/wheels/wsproto-py3"
+  version: "version:1.1.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/h11-py3"
+  version: "version:0.13.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/certifi-py3"
+  version: "version:2023.5.7"
+>
+
+wheel: <
+  name: "infra/python/wheels/pyopenssl-py2_py3"
+  version: "version:19.0.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/cryptography/${vpython_platform}"
+  version: "version:3.3.1.chromium.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/cffi/${vpython_platform}"
+  version: "version:1.14.5.chromium.7"
+>
+
+wheel: <
+  name: "infra/python/wheels/pycparser-py2_py3"
+  version: "version:2.19"
+>
+
+wheel: <
+  name: "infra/python/wheels/ordered-set-py3"
+  version: "version:4.1.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/tabulate-py3"
+  version: "version:0.8.10"
+>
+
+wheel: <
+  name: "infra/python/wheels/hjson-py2_py3"
+  version: "version:3.1.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/pycnite-py3"
+  version: "version:2023.10.11"
+>
+
+wheel: <
+  name: "infra/python/wheels/requests-py3"
+  version: "version:2.31.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/charset_normalizer-py3"
+  version: "version:2.0.4"
+>
+
+wheel: <
+  name: "infra/python/wheels/debugpy/${vpython_platform}"
+  version: "version:1.5.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/markupsafe/${vpython_platform}"
+  version: "version:2.0.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/pydot-py2_py3"
+  version: "version:1.4.2"
+>
+
+wheel: <
+  name: "infra/python/wheels/pandas/${vpython_platform}"
+  version: "version:1.3.2.chromium.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/python-dateutil-py2_py3"
+  version: "version:2.7.3"
+>
+
+wheel: <
+  name: "infra/python/wheels/numpy/${vpython_platform}"
+  version: "version:1.23.5.chromium.4"
+>
+
+wheel: <
+  name: "infra/python/wheels/pytz-py2_py3"
+  version: "version:2024.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/perfetto-py3"
+  version: "version:0.10.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/protobuf-py3"
+  version: "version:4.25.3"
+>
\ No newline at end of file
diff --git a/DEPS b/DEPS
new file mode 100644
index 0000000..9b7174d
--- /dev/null
+++ b/DEPS
@@ -0,0 +1,70 @@
+# This file is used to manage the dependencies. It is
+# used by gclient to determine what version of each dependency to check out, and
+# where.
+#
+# For more information, please refer to the official documentation:
+#   https://sites.google.com/a/chromium.org/dev/developers/how-tos/get-the-code
+#
+# When adding a new dependency, please update the top-level .gitignore file
+# to list the dependency's destination directory.
+#
+# -----------------------------------------------------------------------------
+# Rolling deps
+# -----------------------------------------------------------------------------
+# All repositories in this file are git-based, using Chromium git mirrors where
+# necessary (e.g., a git mirror is used when the source project is SVN-based).
+# To update the revision that Chromium pulls for a given dependency:
+#
+#  # Create and switch to a new branch
+#  git new-branch depsroll
+#  # Run roll-dep (provided by depot_tools) giving the dep's path and optionally
+#  # a regex that will match the line in this file that contains the current
+#  # revision. The script ALWAYS rolls the dependency to the latest revision
+#  # in origin/master. The path for the dep should start with src/.
+#  roll-dep src/third_party/foo_package/src foo_package.git
+#  # You should now have a modified DEPS file; commit and upload as normal
+#  git commit -aspv_he
+#  git cl upload
+#
+# For more on the syntax and semantics of this file, see:
+#   https://bit.ly/chromium-gclient-conditionals
+#
+# which is a bit incomplete but the best documentation we have at the
+# moment.
+
+# We expect all git dependencies specified in this file to be in sync with git
+# submodules (gitlinks).
+git_dependencies = 'SYNC'
+
+use_relative_paths = True
+
+vars = {
+  'chromium_tsproxy_git': 'https://chromium.googlesource.com/external/github.com/catchpoint/WebPageTest.tsproxy.git',
+  'chromium_webpagereplay_git': 'https://chromium.googlesource.com/webpagereplay',
+
+  # This variable is overridden in Chromium's DEPS file.
+  'build_with_chromium': False,
+
+  # Three lines of non-changing comments so that
+  # the commit queue can handle CLs rolling tsproxy
+  # and whatever else without interference from each other.
+  'tsproxy_revision': '7915adec656341bfab173484e1e0ca661eea1627',
+  # Three lines of non-changing comments so that
+  # the commit queue can handle CLs rolling tsproxy
+  # and whatever else without interference from each other.
+  'webpagereplay_revision': '80f08d7a3457ca7f9678e5ae4bda4aefe72bb40e',
+}
+
+# Only these hosts are allowed for dependencies in this DEPS file.
+# If you need to add a new host, contact chrome infrastructure team.
+allowed_hosts = [
+  'chromium.googlesource.com',
+]
+
+deps = {
+  'third_party/tsproxy': Var('chromium_tsproxy_git') + '@' + Var('tsproxy_revision'),
+  'third_party/webpagereplay': {
+    'url': Var('chromium_webpagereplay_git') + '@' + Var('webpagereplay_revision'),
+    'condition': 'not build_with_chromium',
+  }
+}
\ No newline at end of file
diff --git a/LICENSE b/LICENSE
new file mode 100644
index 0000000..b092830
--- /dev/null
+++ b/LICENSE
@@ -0,0 +1,52 @@
+// Copyright 2022 The Chromium Authors. All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are
+// met:
+//
+//    * Redistributions of source code must retain the above copyright
+// notice, this list of conditions and the following disclaimer.
+//    * Redistributions in binary form must reproduce the above
+// copyright notice, this list of conditions and the following disclaimer
+// in the documentation and/or other materials provided with the
+// distribution.
+//    * Neither the name of Google Inc. nor the names of its
+// contributors may be used to endorse or promote products derived from
+// this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+
+Files: flags/known_chrome_flags.py
+# The MIT License (MIT)
+#
+# Copyright (c) 2014 Peter Beverloo
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+#
\ No newline at end of file
diff --git a/METADATA b/METADATA
new file mode 100644
index 0000000..ca222c0
--- /dev/null
+++ b/METADATA
@@ -0,0 +1,16 @@
+name: "crossbench"
+description:
+    "Crossbench is a cross-browser/cross-benchmark runner to extract "
+    "performance numbers."
+
+third_party {
+  identifier {
+    type: "Git"
+    value: "https://chromium.googlesource.com/crossbench"
+    primary_source: true
+    version: "49340d5b69d458f1496edc23064dd9969b2033fa"
+  }
+  version: "49340d5b69d458f1496edc23064dd9969b2033fa"
+  last_upgrade_date { year: 2024 month: 11 day: 11 }
+  license_type: NOTICE
+}
diff --git a/MODULE_LICENSE_CHROME b/MODULE_LICENSE_CHROME
new file mode 100644
index 0000000..e69de29
diff --git a/MODULE_LICENSE_MIT b/MODULE_LICENSE_MIT
new file mode 100644
index 0000000..e69de29
diff --git a/OWNERS b/OWNERS
new file mode 100644
index 0000000..a2a4268
--- /dev/null
+++ b/OWNERS
@@ -0,0 +1,2 @@
+include platform/system/core:main:/janitors/OWNERS
+include platform/system/core:/janitors/OWNERS #{LAST_RESORT_SUGGESTION}
diff --git a/PRESUBMIT.py b/PRESUBMIT.py
new file mode 100644
index 0000000..68ee25e
--- /dev/null
+++ b/PRESUBMIT.py
@@ -0,0 +1,89 @@
+#!/usr/bin/env python3
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import pathlib
+import platform
+import re
+
+USE_PYTHON3 = True
+
+
+def ModifiedFiles(input_api, filename_pattern="*.py"):
+  files = [file.AbsoluteLocalPath() for file in input_api.AffectedFiles()]
+  files_to_check = []
+  for file_path in files:
+    if not input_api.fnmatch.fnmatch(file_path, filename_pattern):
+      continue
+    file_path_pattern = re.escape(
+        input_api.os_path.relpath(file_path, input_api.PresubmitLocalPath()))
+    files_to_check.append(file_path_pattern)
+  return files_to_check
+
+
+def CheckChange(input_api, output_api, on_commit):
+  tests = []
+  results = []
+  testing_env = dict(input_api.environ)
+  testing_path = pathlib.Path(input_api.PresubmitLocalPath())
+  crossbench_test_path = testing_path / "tests" / "crossbench"
+  testing_env["PYTHONPATH"] = input_api.os_path.pathsep.join(
+      map(str, [testing_path, crossbench_test_path]))
+  # ---------------------------------------------------------------------------
+  # Validate the vpython spec
+  if platform.system() in ("Linux", "Darwin"):
+    tests += input_api.canned_checks.CheckVPythonSpec(input_api, output_api)
+  # ---------------------------------------------------------------------------
+  if on_commit:
+    files_to_check = [r"^[^\.]+\.py$"]
+  else:
+    # By default, the pylint canned check lints all Python files together to
+    # check for potential problems between dependencies. This is slow to run
+    # across all of crossbench (>2 min), so only lint affected files.
+    files_to_check = ModifiedFiles(input_api)
+  tests += input_api.canned_checks.GetPylint(
+      input_api,
+      output_api,
+      files_to_check=files_to_check,
+      pylintrc=".pylintrc",
+      version="2.17")
+  # ---------------------------------------------------------------------------
+  # License header checks
+  results += input_api.canned_checks.CheckLicense(input_api, output_api)
+  # ---------------------------------------------------------------------------
+  # Only run test_cli to speed up the presubmit checks
+  if on_commit:
+    dirs_to_check = crossbench_test_path.glob("**")
+    files_to_check = [r".*test_.*\.py$"]
+  else:
+    # Only check a small subset on upload
+    dirs_to_check = [crossbench_test_path / "cli"]
+    files_to_check = [r".*test_cli_fast_.*\.py$"]
+  for dir_to_check in dirs_to_check:
+    # Skip potentially empty dirs
+    if dir_to_check.name == "__pycache__":
+      continue
+    # End-to-end tests require custom setup and are not suited for presubmits.
+    if "end2end" in dir_to_check.parts:
+      continue
+    tests += input_api.canned_checks.GetUnitTestsInDirectory(
+        input_api,
+        output_api,
+        directory=dir_to_check,
+        env=testing_env,
+        files_to_check=files_to_check,
+        skip_shebang_check=True,
+        run_on_python2=False)
+  # ---------------------------------------------------------------------------
+  # Run all test
+  results += input_api.RunTests(tests)
+  return results
+
+
+def CheckChangeOnUpload(input_api, output_api):
+  return CheckChange(input_api, output_api, on_commit=False)
+
+
+def CheckChangeOnCommit(input_api, output_api):
+  return CheckChange(input_api, output_api, on_commit=True)
diff --git a/README.chromium b/README.chromium
new file mode 100644
index 0000000..f119111
--- /dev/null
+++ b/README.chromium
@@ -0,0 +1,13 @@
+Name: CrossBench multi-purpose benchark runner
+Short Name: crossbench
+URL: https://chromium.googlesource.com/crossbench
+Version: N/A
+Revision: DEPS
+License: BSD
+License File: LICENSE
+Security Critical: No
+Shipped: no
+
+Description:
+CrossBench is a cross-browser/cross-benchmark runner to extract performance
+numbers for common press benchmarks and simple page loading.
diff --git a/README.md b/README.md
new file mode 100644
index 0000000..92cc06f
--- /dev/null
+++ b/README.md
@@ -0,0 +1,273 @@
+# Crossbench
+
+Crossbench is a cross-browser/cross-benchmark runner to extract performance
+numbers.
+
+Mailing list: <crossbench@chromium.org>
+
+Issues/Bugs: [Tests > CrossBench](https://bugs.chromium.org/p/chromium/issues/list?q=component%3ATest%3ECrossBench)
+
+Supported Browsers: Chrome/Chromium, Firefox, Safari and Edge.
+
+Supported OS: MacOS, Android, Linux and Windows.
+
+## Basic usage:
+### Chromium Devs (with a full chromium checkout)
+Use the `./cb.py` script directly to run benchmarks (requires chrome's
+[vpython3](https://chromium.googlesource.com/infra/infra/+/main/doc/users/vpython.md))
+
+### Standalone installation
+- Use `pip install crossbench`,
+- or use the "poetry" package manager, see the [development section](#development).
+
+### Running Workloads Examples
+Run the latest [speedometer benchmark](https://browserbench.org/Speedometer/)
+20 times with the system default browser (chrome-stable):
+```bash
+# Run chrome-stable by default:
+./cb.py speedometer --repeat=3
+
+# Compare chrome browser versions and a local chrome build on jetstream:
+./cb.py jetstream --browser=chrome-stable --browser=chrome-m90 --browser=$PATH
+```
+
+Profile individual line items (with pprof on linux):
+```bash
+./cb.py speedometer --probe='profiling' --separate
+```
+
+Use a custom chrome build and only run a subset of the stories:
+```bash
+./cb.py speedometer --browser=$PATH --probe='profiling' --story='jQuery.*'
+```
+
+Profile a website for 17 seconds on Chrome M100 (auto-downloading on macOS and linux):
+```bash
+./cb.py loading --browser=chrome-m100 --probe='profiling' --url=www.cnn.com,17s
+```
+
+Collect perfetto data from loading separate websites on multiple attached
+android devices using the device ID or unique device names
+(see `adb devices -l`):
+
+```bash
+./cb.py loading --probe-config=./config/probe/perfetto/default.config.hjson \
+    --browser='Pixel_4:chrome-stable' --browser='AA00BB11:chrome-stable' \
+    --parallel=platform \
+    --url=https://theverge.com,15s,https://cnn.com,15s  --separate
+```
+
+
+## Main Components
+
+### Browsers
+Crossbench supports running benchmarks on one or multiple browser configurations.
+The main implementation uses selenium for maximum system independence.
+
+You can specify a browser with `--browser=<name>`. You can repeat the
+`--browser` argument to run multiple browser. If you need custom flags for
+multiple browsers use `--browser-config` (or pass simple flags after `--` to
+the browser).
+
+```bash
+./cb.py speedometer --browser=$BROWSER -- --enable-field-trial-config
+```
+#### `--browser` flag on desktop:
+
+| Flag | Description |
+|------|-------------|
+|`--browser=chrome-stable`| Use the installed Chrome stable on the host. Also works with `beta`, `dev` and `canary` versions. |
+|`--browser=edge-stable`| Use the installed Edge stable on the host. Also works with `beta`, `dev` and `canary` versions. |
+|`--browser=safari-stable`| Use the installed Safari stable version on the host. Also works with `technology-preview` |
+|`--browser=firefox-stable`| Use the installed Firefox stable version on the host. Also works with `dev` and `nightly` versions. |
+|`--browser=./out/Release/chrome`| Use a locally compiled chrome version. Any path to a chrome binary will work. |
+|`--browser=chrome-m123`| Download the latest M123 chrome release and install it locally |
+|`--browser=chrome-125.0.6422.112`| Download and install a specific chrome version. |
+|`--browser=chrome-M100...M123`| Download and install a range of 24 different chrome milestones. |
+
+#### `--browser` flag on mobile:
+You can directly run on attached android devices using the device ID or unique device names.
+They need to have [developer mode and usb-debugging enabled](https://developer.android.com/studio/debug/dev-options#Enable-debugging).
+
+| Flag | Description |
+|------|-------------|
+| `--browser=adb:chrome-stable` | Use Chrome stable on a single attached adb device. Note this will fail if there is more than one attached device. |
+|  `--browser=Pixel_7_pro:chrome-canary` | Use Chrome canary on an attached Pixel 7 Pro device. Note this will fail if there is more than one Pixel 7 pro attached.|
+| `--browser=2900FF00BB:chrome-dev` | Use Chrome dev on an attached adb device with the serial id `2900FF00BB`. Use `adb devices -l` to find the serial id.|
+
+#### Browser Config File
+For more complex scenarios you can use a
+[browser.config.hjson](config/doc/browser.config.hjson) file.
+It allows you to specify multiple browser and multiple flag configurations in
+a single file and produce performance numbers with a single invocation.
+
+```bash
+./cb.py speedometer --browser-config=config.hjson
+```
+
+The [example file](config/doc/browser.config.hjson) lists and explains all
+configuration details.
+
+#### Remote WebDriver Interface
+Crossbench also supports benchmarking browsers on remote machines
+running Linux or ChromeOS, via SSH.
+The remote machine is expected to have at least two ports open to the host:
+(a) the SSH port (typically `22`), and
+(b) the WebDriver port (typically `9515`).
+The [remote browser example](config/doc/remote_browser.config.hjson)
+describes the configuration details for both Linux and ChromeOS.
+
+On ChromeOS, Crossbench requires
+[ChromeDriver](https://developer.chrome.com/docs/chromedriver/get-started/chromeos/)
+to interact with Chrome,
+and [Autotest](https://chromium.googlesource.com/chromiumos/third_party/autotest/+/HEAD/docs/user-doc.md)
+for creating ephemeral sessions for testing.
+Both ChromeDriver and Autotest are pre-installed on ChromeOS test images.
+Detailed instructions for flashing Chromebooks with test images are provided at:
+go/arc-setup-dev-mode-dut#usb-cros-test-image.
+
+### Probes
+Probes define a way to extract arbitrary (performance) numbers from a
+host or running browser. This can reach from running simple JS-snippets to
+extract page-specific numbers to system-wide profiling.
+
+Multiple probes can be added with repeated `--probe='XXX'` options.
+You can use the `describe probes` subcommand to list all probes:
+
+```bash
+# List all probes:
+./cb.py describe probes
+
+# List help for an individual probe:
+./cb.py describe probe v8.log
+```
+
+#### Inline Probe Config
+Some probes can be configured, either with inline JSON when using `--probe` or
+in a separate `--probe-config` HJSON file. Use the `describe` command to list
+all options. The inline JSON or HJSON is the same format as used in the separate
+probe config files (see below).
+
+```bash
+# Get probe config details:
+./cb.py describe probe v8.log
+
+# Use inline HJSON to configure a probe:
+./cb.py speedometer --probe='v8.log:{prof:true}'
+```
+
+#### Probe Config File
+For complex probe setups you can use `--probe-config=<file>`.
+The [example file](config/doc/probe.config.hjson) lists and explains all
+configuration details. For the specific probe configuration properties consult
+the `describe` command.
+
+### Benchmarks
+Use the `describe` command to list all benchmark details:
+
+```bash
+# List all benchmark info:
+./cb.py describe benchmarks
+
+# List an individual benchmark info:
+./cb.py describe benchmark speedometer_3.0
+
+# List a benchmark's command line options:
+./cb.py speedometer_3.0 --help
+```
+
+### Stories
+Stories define sequences of browser interactions. This can be simply
+loading a URL and waiting for a given period of time, or in more complex
+scenarios, actively interact with a page and navigate multiple times.
+
+Use `--help` or describe to list all stories for a benchmark:
+
+```bash
+./cb.py speedometer --help
+```
+
+Use `--stories` to list individual story names, or use regular expression
+as filter.
+
+```bash
+./cb.py speedometer --browser=$BROWSER --stories='.*Angular.*'
+```
+
+
+## Development
+
+### Checking Out Code
+Don't just `git clone` the crossbench repo! Use depot_tools to set everything
+up correctly for you.
+
+- Install [Chromium depot_tools](https://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/depot_tools_tutorial.html#_setting_up).
+- Get the crossbench code with all dependencies:
+```
+mkdir code
+cd code
+fetch crossbench
+cd crossbench
+```
+- Don't forget to run `gclient sync` every time you pull new changes from the
+crossbench repo.
+
+### Poetry Setup
+This project uses [poetry](https://python-poetry.org/) deps and package scripts
+to setup the correct environment for testing and debugging.
+
+```bash
+# a) On debian:
+sudo apt-get install python3.10 python3-poetry
+# b) With python 3.9 to 3.11 installed already:
+pip3 install poetry
+```
+
+Check that you have poetry on your path and make sure you have the right
+`$PATH` settings.
+```bash
+poetry --help || echo "Please update your \$PATH to include poetry bin location";
+# Depending on your setup, add one of the following to your $PATH:
+echo "`python3 -m site --user-base`/bin";
+python3 -c "import sysconfig; print(sysconfig.get_path('scripts'))";
+```
+
+Install the necessary dependencies from the lock file using poetry:
+
+```bash
+# Select the python version you want to use (3.9 to 3.10):
+poetry env use 3.10
+poetry install
+
+# For windows you have to skip pytype support:
+poetry env use 3.11
+poetry install --without=dev-pytype
+```
+
+### Crossbench
+For local development / non-chromium installation you should
+use `poetry run cb ...` instead of `./cb.py ...`.
+
+Side-note, beware that poetry eats up an empty `--`:
+
+```bash
+# With cb.py:
+./cb.py speedometer ... -- --custom-chrome-flag ...
+# With poetry:
+poetry run cb speedometer ... -- -- --custom-chrome-flag ...
+```
+
+### Tests
+```
+poetry run pytest
+```
+
+Run detailed test coverage:
+```bash
+poetry run pytest --cov=crossbench --cov-report=html
+```
+
+Run [pytype](https://github.com/google/pytype) type checker:
+```bash
+poetry run pytype -j auto .
+```
diff --git a/WATCHLISTS b/WATCHLISTS
new file mode 100644
index 0000000..9e3d96c
--- /dev/null
+++ b/WATCHLISTS
@@ -0,0 +1,21 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# Watchlist Rules
+# Refer: https://chromium.googlesource.com/chromium/src/+/HEAD/docs/infra/watchlists.md
+
+# IMPORTANT: The regular expression filepath is tested against each path using
+# re.search, so it is not usually necessary to add .*.
+{
+  'WATCHLIST_DEFINITIONS': {
+    'all': {
+      'filepath': '.',
+    },
+  },
+  'WATCHLISTS': {
+    'all': [
+      'cbruni+watch@google.com',
+    ],
+  },
+}
\ No newline at end of file
diff --git a/cb.py b/cb.py
new file mode 100755
index 0000000..8400c32
--- /dev/null
+++ b/cb.py
@@ -0,0 +1,13 @@
+#!/usr/bin/env vpython3
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import sys
+
+from crossbench.cli.cli import CrossBenchCLI
+
+if __name__ == "__main__":
+  argv = sys.argv
+  cli = CrossBenchCLI()
+  cli.run(argv[1:])
diff --git a/cb_btp.py b/cb_btp.py
new file mode 100755
index 0000000..8893f50
--- /dev/null
+++ b/cb_btp.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env vpython3
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import sys
+from crossbench.cli.btp import BTPUtil
+
+if __name__ == "__main__":
+  btp = BTPUtil()
+  btp.run(sys.argv)
diff --git a/chrome-extension-replay/README.md b/chrome-extension-replay/README.md
new file mode 100644
index 0000000..fc943b1
--- /dev/null
+++ b/chrome-extension-replay/README.md
@@ -0,0 +1,11 @@
+# Crossbench Proxy extension: Custom replay button in DevTools > Recorder
+
+This extension is using the [chrome.devtools.recorder API](https://developer.chrome.com/docs/extensions/reference/devtools_recorder/).
+
+To test the extension:
+
+1. Download this directory to your machine: `git clone https://chromium.googlesource.com/crossbench`.
+2. [Load the extension locally](https://developer.chrome.com/docs/extensions/mv3/getstarted/development-basics/#load-unpacked).
+3. Open a new tab and a new DevTools window.
+4. In the **Recorder** panel, create a new recording.
+5. Expand the replay menu and press **crossbench**.
diff --git a/chrome-extension-replay/devtools-recorder/crossbench.css b/chrome-extension-replay/devtools-recorder/crossbench.css
new file mode 100644
index 0000000..1fa30c2
--- /dev/null
+++ b/chrome-extension-replay/devtools-recorder/crossbench.css
@@ -0,0 +1,231 @@
+/*
+// Copyright 2023 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+*/
+
+:root {
+  --bg-color: rgb(220, 232, 254);
+  --input-bg-color: rgb(252, 251, 247);
+  --bg-color-dark: rgb(209, 224, 250);
+  --bg-color-darkest: rgb(177, 195, 227);
+  --section-bg-color: rgb(149, 169, 206);
+  --error-color: rgb(238, 148, 148);
+  --connected-color: rgb(112, 201, 155);
+  --running-color: rgb(173, 231, 146);
+}
+
+html,
+button {
+  font-family: "Gill Sans", sans-serif;
+}
+
+html {
+  background-color: var(--bg-color);
+  color: #333;
+}
+
+html,
+p,
+body {
+  font-size: 13px !important;
+}
+
+a {
+  color: initial;
+}
+
+h1 {
+  font-size: 40px;
+  padding: 0 3px;
+  text-align: center;
+  text-shadow:
+    -2px -2px 0 rgba(255, 255, 255, 0.1),
+    2px -2px 0 rgba(255, 255, 255, 0.1),
+    -2px 2px 0 rgba(255, 255, 255, 0.1),
+    2px 2px 0 rgba(255, 255, 255, 0.1);
+}
+
+h2 {
+  font-size: 20px;
+}
+
+h1,
+h2 {
+  margin-top: 0px;
+  margin-bottom: 6px;
+  font-weight: normal;
+}
+
+section {
+  background-color: var(--section-bg-color);
+  border-radius: 10px;
+  border: 2px rgba(0, 0, 0, 0.1) solid;
+  padding: 5px;
+  margin: 10px;
+  box-shadow: 0px 5px 10px rgba(0, 0, 0, 0.2);
+}
+
+section span {
+  white-space: nowrap;
+}
+
+section .buttons {
+  float: right;
+}
+
+textarea,
+input,
+button {
+  border: 1px rgba(0, 0, 0, 0.3) solid;
+  border-radius: 5px;
+  background-color: var(--input-bg-color);
+}
+
+textarea,
+pre,
+code {
+  font-family: "Roboto Mono", "Monaco", monospace;
+}
+
+textarea {
+  width: 100%;
+  resize: vertical;
+  min-height: 100px;
+  padding: 4px 4px 4px 6px;
+}
+
+button {
+  margin-left: 3px;
+  cursor: pointer;
+  float: right;
+  opacity: 1;
+  padding: 3px 8px;
+  transition: visibility 0s, opacity 0.1s linear;
+}
+
+button:hover {
+  background-color: var(--bg-color-dark);
+}
+
+button:active {
+  background-color: var(--bg-color-darkest);
+}
+
+h2 button {
+  margin: 0px 0 4px 5px;
+}
+
+.info {
+  font-family: "Georgia", serif;
+  font-weight: bold;
+}
+
+.icon {
+  display: inline-block;
+  position: relative;
+  width: 0.537em;
+  height: 13px;
+  margin: -10px 0 -10px 0;
+}
+
+.headerImage {
+  float: right;
+  margin: 25px -20px 0 -80px;
+  filter: drop-shadow(0px 10px 5px rgba(0, 0, 0, 0.2));
+}
+
+h1 img {
+  width: 200px;
+  transform: rotate(-55deg);
+
+}
+
+@media screen and (max-width: 670px) {
+  .headerImage {
+    display: none !important;
+  }
+}
+
+#settingsSection {
+  line-height: 25px;
+  padding-top: 4px;
+  transition: background-color 0.2s linear 0.3s;
+}
+
+.inputGroup {
+  margin-right: 10px;
+}
+
+#settingsSection button {
+  margin-top: 1px;
+}
+
+#settingsSection input {
+  font-family: "Roboto Mono", "Monaco", monospace;
+  margin-top: -1px;
+}
+
+#status {
+  float: right;
+  background-color: var(--section-bg-color);
+  margin-top: 2px !important;
+  text-align: center;
+}
+
+input.error {
+  background-color: var(--error-color);
+}
+
+#runButton,
+#stopButton,
+.running button.help {
+  opacity: 0.1;
+  pointer-events: none;
+}
+
+.connected #connectButton,
+.running #connectButton {
+  opacity: 0.5;
+}
+
+.connected #runButton {
+  opacity: 1;
+  pointer-events: inherit;
+}
+
+.running #stopButton {
+  opacity: 1;
+  pointer-events: inherit;
+}
+
+.connected #settingsSection {
+  background-color: var(--connected-color);
+}
+
+@keyframes status-blink {
+  from {
+    background-color: var(--connected-color);
+  }
+
+  to {
+    background-color: var(--running-color);
+  }
+}
+
+.running #settingsSection,
+.connecting #settingsSection {
+  animation: 1s linear 0.4s infinite alternate status-blink;
+}
+
+.disconnected #settingsSection {
+  background-color: var(--error-color);
+}
+
+#stopButton {
+  background-color: var(--error-color);
+}
+
+#outputStderr {
+  color: rgb(142, 56, 56);
+}
\ No newline at end of file
diff --git a/chrome-extension-replay/devtools-recorder/crossbench.html b/chrome-extension-replay/devtools-recorder/crossbench.html
new file mode 100644
index 0000000..ddf25ce
--- /dev/null
+++ b/chrome-extension-replay/devtools-recorder/crossbench.html
@@ -0,0 +1,119 @@
+<!--
+Copyright 2023 The Chromium Authors
+Use of this source code is governed by a BSD-style license that can be
+found in the LICENSE file.
+-->
+<head>
+  <meta charset="UTF-8">
+  <script async type="module" src="./crossbench.mjs"></script>
+  <link rel="stylesheet" href="./crossbench.css">
+</head>
+
+<body class="connecting">
+  <section>
+    <h1>cross<b>bench</b> Proxy
+      <div class="headerImage">
+        <img src="./knife.png" />
+      </div>
+    </h1>
+    <p>
+      Replay your current recording with <a href="https://chromium.googlesource.com/crossbench">crossbench</a>.
+    <ul>
+      <li>Start a local cross<b>bench</b> server with <code>./cb.py devtools-recorder-proxy</code>.</li>
+      <li>
+        Use the Auth-Token generated by cross<b>bench</b> to connect this extension.
+      </li>
+      <li>
+        Use the command line arguments textarea to specify more options:
+        <ul>
+          <li>Add <code>--browser=...</code> for testing more browsers.</li>
+          <li>Add <code>--probe=...</code> for testing more probes.</li>
+        </ul>
+      </li>
+    </ul>
+    </p>
+  </section>
+
+  <section id="settingsSection">
+    <h2>Connection Settings:
+      <span class="buttons">
+        <button id="connectButton">Connect </button>
+        <input type="text" id="status" name="status" size="12" readonly>
+      </span>
+    </h2>
+    <span class="inputGroup">
+      <label for="host">Host:</label>
+      <input type="text" id="host" name="host" value="localhost" readonly size="9">
+    </span>
+    <span class="inputGroup">
+      <label for="port">Port:</label>
+      <input type="text" id="port" name="port" value="" size="5">
+    </span>
+    <span class="inputGroup">
+      <label for="token">Auth-Token:</label>
+      <input type="text" id="token" name="token" maxlength="32" size="32">
+    </span>
+  </section>
+  <!--
+    TODO: Add dedicated probe output section with links to the files
+    TODO: Add record / replay section
+    TODO: Add merge recording section
+  -->
+  <section id="configSection">
+    <h2>
+      cross<b>bench</b> Command Line Arguments:
+      <span class="buttons">
+        <button id="helpButton" class="help" title="Display crossbench's command-line --help.">
+          CLI Help <i class="info">i</i>
+        </button>
+        <button id="probesHelpButton" class="help" title="Display crossbench's Probe help.">
+          Probes Help <i class="info">i</i>
+        </button>
+        <button id="runButton"
+          title="Run crossbench with the given command-line arguments and current DevTools recording.">
+          Run <span class="icon"></span>
+        </button>
+        <button id="stopButton" title="Stop the current crossbench command.">
+          Stop <span class="icon"></span>
+        </button>
+      </span>
+    </h2>
+    <textarea id="crossbenchCMD"></textarea>
+  </section>
+
+  <section>
+    <h2>
+      cross<b>bench</b> command stdout:
+      <span class="buttons">
+        <button id="copyStdout">
+          Copy 
+        </button>
+      </span>
+    </h2>
+    <textarea id="outputStdout" readonly></textarea>
+  </section>
+
+  <section>
+    <h2>
+      cross<b>bench</b> command stderr:
+      <span class="buttons">
+        <button id="copyStderr">
+          Copy 
+        </button>
+      </span>
+    </h2>
+    <textarea id="outputStderr" readonly></textarea>
+  </section>
+
+  <section id="recordingSection">
+    <h2>
+      DevTools Recorder JSON:
+      <span class="buttons">
+        <button id="copyRecorderJSON">
+          Copy 
+        </button>
+      </span>
+    </h2>
+    <textarea id="recording" readonly></textarea>
+  </section>
+</body>
\ No newline at end of file
diff --git a/chrome-extension-replay/devtools-recorder/crossbench.mjs b/chrome-extension-replay/devtools-recorder/crossbench.mjs
new file mode 100644
index 0000000..9d70ed9
--- /dev/null
+++ b/chrome-extension-replay/devtools-recorder/crossbench.mjs
@@ -0,0 +1,278 @@
+// Copyright 2023 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+class CrossbenchRecorder {
+
+  constructor(host, port, token, onmessage, onerror) {
+    this._host = host;
+    this._port = port;
+    this._token = token;
+    this._onMessageHandler = onmessage;
+    this._onErrorHandler = onerror;
+  }
+
+  async start() {
+    this._webSocket = new WebSocket(`ws://${this._host}:${this._port}`);
+    this._isConnecting = true;
+    this._webSocket.onmessage = this._onmessage.bind(this);
+    this._webSocket.onerror = (e) => this._onErrorHandler(e);
+    this._webSocket.onopen = (e) => this.status();
+  }
+
+  get isConnected() {
+    return this._webSocket && this._webSocket.readyState == WebSocket.OPEN;
+  }
+
+  _onmessage(messageEvent) {
+    const { success, type, payload, error } = JSON.parse(messageEvent.data);
+    this._onMessageHandler(success, type, payload, error);
+  }
+
+  _command(command, args = undefined) {
+    const message = { token: this._token, command: command, args: args };
+    if (!this.isConnected) {
+      throw Error("Invalid websocket state");
+    }
+    this._webSocket.send(JSON.stringify(message));
+  }
+
+  status() {
+    this._command("status");
+  }
+
+  run(cmd, json) {
+    this._command("run", { cmd, json });
+  }
+
+  readline() {
+    this._command("readline");
+  }
+
+  stop() {
+    if (this.isConnected) {
+      this._command("stop");
+    }
+    this._webSocket.close();
+  }
+}
+
+function $(query) {
+  return document.querySelector(query);
+}
+
+class Status {
+  static DISCONNECTED = "disconnected";
+  static CONNECTING = "connecting";
+  static CONNECTED = "connected";
+  static RUNNING = "running";
+}
+
+
+class UI {
+  _crossbench;
+  _recorderJSON;
+  _status = Status.DISCONNECTED;
+  _pingIntervalID;
+
+  constructor() {
+    if (chrome?.runtime?.onMessage) {
+      chrome.runtime.onMessage.addListener(this._onChromeMessage.bind(this));
+    }
+    $("#port").addEventListener("change", this._reconnect.bind(this));
+    $("#token").addEventListener("change", this._reconnect.bind(this));
+    $("#connectButton").onclick = this._reconnect.bind(this);
+    $("#crossbenchCMD").addEventListener("change", this._updateCMD.bind(this));
+    $("#helpButton").onclick = (e) => this._showHelp("loading");
+    $("#probesHelpButton").onclick = (e) => this._showHelp("probes");
+    $("#runButton").onclick = this._run.bind(this);
+    $("#stopButton").onclick = this._stop.bind(this);
+    $("#copyStdout").onclick = () => this._copyOutput("#outputStdout");
+    $("#copyStderr").onclick = () => this._copyOutput("#outputStderr");
+    $("#copyRecorderJSON").onclick = () => this._copyOutput("#copyRecorderJSON");
+
+
+    $("#port").value = localStorage.getItem("crossbenchPort") | 44645;
+    $("#token").value = localStorage.getItem("crossbenchToken");
+    $("#crossbenchCMD").value = localStorage.getItem("crossbenchCMD");
+    this._recorderJSON = JSON.parse(localStorage.getItem("recordingJSON") || "{}");
+    this._reconnect();
+  }
+
+  _updateRecording() {
+    $("#recording").value = JSON.stringify(this._recorderJSON, undefined, "  ");
+  }
+
+  _updateCMD() {
+    const cmd = $("#crossbenchCMD").value;
+    localStorage.setItem("crossbenchCMD", cmd);
+  }
+
+  _run() {
+    if (!this._crossbench) return;
+    if (!this._recorderJSON) return;
+    const cmd = $("#crossbenchCMD").value;
+    this._crossbench.run(cmd, this._recorderJSON);
+    this._clearOutput();
+  }
+
+  _clearOutput() {
+    $("#outputStdout").value = "";
+    $("#outputStderr").value = "";
+  }
+
+  _showHelp(type) {
+    if (this._status !== Status.CONNECTED) return;
+    if (type === "loading") {
+      this._crossbench.run("--help");
+    } else if (type === "probes") {
+      this._crossbench.run("describe probes");
+    } else {
+      console.error("Unknown help type: ", type);
+    }
+  }
+
+  _stop() {
+    this._crossbench.stop();
+  }
+
+  _copyOutput(selector) {
+    navigator.clipboard.writeText($(selector).value);
+  }
+
+  _updateStatus(status) {
+    if (this._status === status) return;
+    document.body.className = status;
+    $("#status").value = status;
+    if (status === Status.DISCONNECTED) {
+      this._stopPinger();
+    } else if (status === Status.CONNECTING) {
+      this._checkStatusTransition(Status.DISCONNECTED, status);
+    } else if (status === Status.CONNECTED) {
+      if (this._status !== Status.RUNNING) {
+        this._checkStatusTransition(Status.CONNECTING, status);
+        this._ensurePinger();
+      }
+    } else if (status === Status.RUNNING) {
+      this._clearOutput();
+      this._checkStatusTransition(Status.CONNECTED, status);
+    } else {
+      console.error("Unknown status: ", status);
+    }
+    this._status = status;
+  }
+
+  _checkStatusTransition(from, to) {
+    if (this._status != from) {
+      console.error(`Invalid status transition ${this._status} => ${to};`);
+    }
+  }
+
+  _stopPinger() {
+    clearInterval(this._pingIntervalID);
+    this._pingIntervalID = undefined;
+  }
+
+  _ensurePinger() {
+    if (!this._crossbench || this._pingIntervalID) return;
+    this._pingIntervalID = setInterval(this._ping.bind(this), 1000);
+  }
+
+  _ping() {
+    if (!this._crossbench || !this._crossbench.isConnected) {
+      this._updateStatus(Status.DISCONNECTED);
+    }
+  }
+
+  _appendOutput({ stdout = "", stderr = "" }) {
+    const stdoutNode = $("#outputStdout");
+    const stderrNode = $("#outputStderr");
+    stdoutNode.value += stdout;
+    stderrNode.value += stderr;
+    stdoutNode.scrollTop = stdoutNode.scrollHeight;
+    stderrNode.scrollTop = stderrNode.scrollHeight;
+  }
+
+  _reconnect() {
+    if (this._crossbench) {
+      this._crossbench.stop();
+    }
+
+    const portNode = $("#port");
+    const tokenNode = $("#token");
+    const port = portNode.value;
+    const token = tokenNode.value;
+
+    let success = true;
+    if (port.length < 4 || !(parseInt(port) > 1024)) {
+      success = false;
+      portNode.className = "error";
+    }
+    if (token.length != 32) {
+      success = false;
+      tokenNode.className = "error";
+    }
+
+    // Try connecting to the local crossbench proxy server:
+    this._clearOutput();
+    this._stopPinger();
+    try {
+      this._crossbench = new CrossbenchRecorder(
+        "localhost", parseInt(port), token,
+        this._onCrossbenchMessage.bind(this),
+        this._onConnectionFail.bind(this));
+      this._crossbench.start();
+      this._updateStatus(Status.CONNECTING);
+    } catch (e) {
+      success = false;
+      portNode.className = "error";
+      tokenNode.className = "error";
+      this._crossbench = undefined;
+      console.error(e);
+      this._updateStatus(Status.DISCONNECTED);
+    }
+    localStorage.setItem("crossbenchPort", port);
+    localStorage.setItem("crossbenchToken", token);
+    if (!success) return;
+    portNode.className = "";
+    tokenNode.className = "";
+  }
+
+  _onConnectionFail(e) {
+    const websocket = e.target;
+    const errorMessage = [
+      `Connection to WebSocket at ${websocket.url} failed.`,
+      "Did you run `./cb.py devtools-recorder-proxy`?"
+    ].join("\n");
+    this._appendOutput({ stderr: errorMessage });
+    this._updateStatus(Status.DISCONNECTED);
+  }
+
+  _onCrossbenchMessage(isSuccess, command, payload, error) {
+    console.log("Response: ", { isSuccess, command, payload, error });
+    if (!isSuccess) {
+      console.error(error);
+      this._appendOutput({ stderr: error });
+      if (error == "AuthenticationError") {
+        this._onAuthenticationError();
+      }
+      return;
+    }
+    if (command == "status") return this._updateStatus(payload);
+    if (command == "output") return this._appendOutput(payload);
+  }
+
+  _onAuthenticationError() {
+    this._updateStatus(Status.DISCONNECTED);
+  }
+
+  _onChromeMessage(request, sender, sendResponse) {
+    if (request === "stop") return this._stop();
+    this._recorderJSON = JSON.parse(request);
+    localStorage.setItem("recordingJSON", request);
+    this._updateRecording();
+  }
+}
+
+globalThis.ui = new UI();
+
diff --git a/chrome-extension-replay/devtools-recorder/knife.png b/chrome-extension-replay/devtools-recorder/knife.png
new file mode 100644
index 0000000..d8b3b11
Binary files /dev/null and b/chrome-extension-replay/devtools-recorder/knife.png differ
diff --git a/chrome-extension-replay/devtools_page.html b/chrome-extension-replay/devtools_page.html
new file mode 100644
index 0000000..7800c9a
--- /dev/null
+++ b/chrome-extension-replay/devtools_page.html
@@ -0,0 +1,6 @@
+<!-- 
+Copyright 2023 The Chromium Authors
+Use of this source code is governed by a BSD-style license that can be
+found in the LICENSE file.
+-->
+<script type="module" src="./devtools_page.mjs"></script>
diff --git a/chrome-extension-replay/devtools_page.mjs b/chrome-extension-replay/devtools_page.mjs
new file mode 100644
index 0000000..62ca2e2
--- /dev/null
+++ b/chrome-extension-replay/devtools_page.mjs
@@ -0,0 +1,25 @@
+// Copyright 2023 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+const kName = "crossbench";
+const view = await chrome.devtools.recorder.createView(kName, 'devtools-recorder/crossbench.html');
+
+let latestRecording;
+
+view.onShown.addListener(() => {
+  chrome.runtime.sendMessage(JSON.stringify(latestRecording));
+});
+
+view.onHidden.addListener(() => {
+  chrome.runtime.sendMessage("stop");
+});
+
+export class RecorderPlugin {
+  replay(recording) {
+    latestRecording = recording;
+    view.show();
+  }
+}
+
+chrome.devtools.recorder.registerRecorderExtensionPlugin(new RecorderPlugin(), kName);
diff --git a/chrome-extension-replay/icon-128.png b/chrome-extension-replay/icon-128.png
new file mode 100644
index 0000000..d831a1c
Binary files /dev/null and b/chrome-extension-replay/icon-128.png differ
diff --git a/chrome-extension-replay/manifest.json b/chrome-extension-replay/manifest.json
new file mode 100644
index 0000000..225a0b1
--- /dev/null
+++ b/chrome-extension-replay/manifest.json
@@ -0,0 +1,15 @@
+{
+  "manifest_version": 3,
+  "version": "0.1.0",
+  "name": "crossbench extension",
+  "description": "DevTools extension for running Recordings in crossbench.",
+  "permissions": [],
+  "devtools_page": "devtools_page.html",
+  "content_security_policy": {
+    "extension_pages": "script-src 'self'; object-src 'self'"
+  },
+  "minimum_chrome_version": "112.0.5569.0",
+  "icons": {
+    "128": "icon-128.png"
+  }
+}
diff --git a/config/benchmark/loadline/README.md b/config/benchmark/loadline/README.md
new file mode 100644
index 0000000..dbe304a
--- /dev/null
+++ b/config/benchmark/loadline/README.md
@@ -0,0 +1,280 @@
+# LoadLine Benchmark
+
+This folder contains configs for the LoadLine benchmark. The goal of the
+benchmark is to facilitate web performance optimization based on a realistic
+workload. The benchmark has two workload variants:
+
+*   General-purpose workload representative of the web usage on mobile phones
+    ("phone");
+
+*   Android Tablet web performance workload ("tablet").
+
+## tl;dr: Running the Benchmark
+
+Run "phone" workload:
+
+```
+./cb.py loadline-phone --browser <browser> --cool-down-threshold moderate
+```
+
+Run "tablet" workload:
+
+```
+./cb.py loadline-tablet --browser <browser> --cool-down-threshold moderate
+```
+
+The browser can be `android:chrome-canary`, `android:chrome-stable` etc. See
+crossbench docs for the full list of options.
+
+Cool down threshold is recommended because by default the benchmark runs 100
+repetitions, which creates a significant load on the device and can lead to
+overheating. This option will insert cooldown periods to ensure that the device
+stays below the given thermal level. Possible values include `light`,
+`moderate`, and `severe`.
+
+Results will be located in `results/latest/`. Notable files in this directory:
+
+*   `loadline_probe.csv`: Final score for the run
+*   `trace_processor/loadline_benchmark_score.csv`: Breakdown of scores per
+    page and repetition
+
+## Benchmark Details
+
+### Background
+
+Web is one of the most important use cases on mobile devices. Page loading speed
+represents a crucial part of user experience, and is not well covered by
+existing benchmarks (Speedometer, Jetstream, MotionMark). Experiments show that
+raw CPU performance does not always result in faster web loading speeds, since
+it's a complex highly parallelized process that stresses a lot of browser and OS
+components and their interactions. Hence the need for a dedicated web loading
+benchmark that will enable us to compare devices, track improvements across OS
+and browser releases.
+
+### Workload
+
+We aimed for two configurations:
+
+*   **Representative mobile Web on Android usage (~5 pages)**
+
+    Aimed at covering loading scenarios representative of real web workloads and
+    user environments on Android mobile phones.
+
+*   **Android Tablet web performance (~5 pages)**
+
+    A set of larger desktop-class workloads intended for tablet/large screen
+    devices running Android.
+
+The biggest challenges we faced in achieving this goal were:
+
+*   **Representativeness**: How do we determine a representative set of web
+    sites given the humongous corpus of websites whose overall distribution is
+    not thoroughly understood.
+*   **Metrics** Existing page load metrics generalize well for O(millions) of
+    page loads across a variety of sites, but are poor fit to judge performance
+    of a specific site
+*   **Noise**: The web evolves. To ensure the benchmark workloads stay
+    consistent over time, we chose to use recorded & replayed workloads.
+    However, page load is very complex and indeterministic so naive replays are
+    often not consistent.
+
+### Site Selection
+
+We did a thorough analysis to ensure we select relevant and representative
+sites. Our aspiration was to understand the distribution of the most important
+CUJs and performance characteristics on the web and use this knowledge to elect
+a small number of representative CUJs, such that their performance
+characteristics maximize coverage of the distribution.
+
+Practically, we evaluated ~50 prominent sites across a number of different
+characteristics (dimensions) via trace-based analysis, cross-checking via field
+data. We clustered similar pages and selected representatives for important
+clusters. In the end, this was a manual selection aided by algorithmic
+clustering/correlation analysis.
+
+We looked at over 20 dimensions for suitability and relevance to our site
+selection, and low correlation between dimensions. Of these, we chose 6 primary
+metrics that we optimized coverage on: Website type, workload size (CPU time),
+DOM/Layout complexity (#nodes), JavaScript heap size, time spent in V8, time
+spent in V8 callbacks into Blink. Secondarily, we included utilization of web
+features and relevant mojo interfaces, e.g. Video, cookies, main/subframe
+communication, input events, frame production, network requests, etc.
+
+In the end we selected 5 sites for each configuration which we plan to extend in
+the future.
+
+#### Mobile
+
+| Page (mobile version)      | CUJ               | Performance characteristics |
+| -------------------------- | ------------------ | -------------------------- |
+| amazon.co.uk <br> (product page) | Shopping           | * average page load, large workload, large DOM/JS (but heavier on DOM) <br> * high on OOPIFs, input, http(s) resources, frame production |
+| cnn.com <br> (article)           | News               | * slow page load, large workload, large DOM/JS (but heavier on JS) <br> * high on iframes, main frame, local storage, cookies, http(s) resources |
+| wikipedia.org <br> (article)     | Reference work     | * fast page load, small workload, large DOM, small JS <br> * high on input <br> * low on iframes, http(s) resources, frame production |
+| globo.com <br> (homepage)        | News / web portal  | * slow page load, large workload, small DOM, large JS <br> * high on iframes, OOPIFs, http(s) resources, frame production, cookies |
+| google.com <br> (results)        | Search             | * fast page load, average workload, average DOM + JS <br> * high on main frame, local storage, video |
+
+#### Tablet
+
+| Page (desktop version)     | CUJ          | Performance characteristics      |
+| -------------------------- | ------------ | -------------------------------- |
+| amazon.co.uk <br> (product page) | Shopping     | * average page load, large workload, large DOM, average JS <br> * high on OOPIFs, http(s) resources, frame production |
+| cnn.com <br> (article)           | News         | * slow page load, large workload, large DOM/JS (but heavier on JS) <br> * high on iframes, local storage, video, frame production, cookies |
+| docs.google.com <br> (document)  | Productivity | * slow page load, large workload, large DOM + JS (heavier on JS) <br> * high on main frame <br> * high on font resources |
+| google.com <br> (results)        | Search       | * fast page load, low workload, low DOM + JS <br> * high on main frame, local storage <br> * low on video |
+| youtube.com<br> (video)         | Media        | * slow page load, very high workload, large DOM, small JS heap, average JS time <br> * high on video |
+
+### Metrics
+
+Measuring page load accurately in generic ways is difficult (e.g. some pages
+require significant work after LCP to become "interactive") and inaccurate
+metrics risk incorrect power/perf trade-off choices. Once we had a selection of
+sites, we looked at each one of them and devised site-specific metrics that
+better reflect when a page is ready to be interacted with.
+
+## Reproducibility / Noise
+
+Page load is a very complex process and is inherently noisy. There is a lot of
+concurrent work happening in the browser and slight timing differences can have
+big impact in the actual workload being executed and thus in the perceived load
+speed.
+
+We took various measures to try to reduce this variability, but there is still
+room to improve and we plan to do this in the next versions of this benchmark.
+
+### Score
+
+We are still actively developing this benchmark and we will try our best to keep
+the score as stable across changes as possible. We will update the benchmark's
+minor version if we introduce changes that have a chance of affecting the score.
+This version is reported in the benchmark output and should be quoted when
+sharing scores.
+
+### Cross-device Comparisons
+
+Workload on two different devices will differ due to variance in application
+tasks, such as the number of frames rendered during load, timers being executed
+more frequently during load, etc.
+
+It is important to stress that page load is a complex workload. As a result, if
+we were to compare scores between two devices A and B, device A having 2x the
+CPU speed compared to device B, then A's score will be less than 2x of B's
+score. This is not an error or an artifact of the measurement, this is a result
+of the adaptable nature of web loading (and / or potential effort of a browser
+trying to get the best user experience from the resources available). The
+benchmark score reflects the actual user-observable loading speed.
+
+### Web Page Replay
+
+To maintain reproducibility, the benchmark uses the
+[web page replay](https://chromium.googlesource.com/catapult/+/HEAD/web_page_replay_go/README.md)
+mechanism. Archives of the web pages are stored in the
+`chrome-partner-telemetry` cloud bucket, so you'll need access to that bucket to
+run the benchmark on recorded pages (you can still run the benchmark on live
+sites if you don't have the access, but there's no guarantee that results will
+be reproducible/comparable).
+
+### Repetitions {#repetitions}
+
+By default, the benchmark runs **100** repetitions, as we have found that this
+brings the noise to an acceptable level. You can override this setting via
+`--repetitions`
+
+### Thermal Throttling
+
+Given the high number of repetitions in the standard configuration, thermal
+throttling can be an issue, especially in more thermally constricted devices. A
+one size fits all solution to this problem is quite hard; even detecting this is
+very device specific. So for the first version of the benchmark, we leave it up
+to the user to determine if the results of the benchmark might be influenced by
+thermal issues. Crossbench has a way of adding a delay between repetitions that
+can be used to mitigate this problem (at the expense of longer running times):
+`--cool-down-time`.
+
+In the future, we want to look at ways to aid users in detecting / mitigating
+thermal throttling (e.g. notify users that thermal throttling happened during
+the test or automatically waiting between repetitions until the device is in a
+good thermal state).
+
+## Configuration
+
+In its standard configuration, the benchmark will run 100 iterations. In
+addition, the WPR server will run on device, rather than on the host, to reduce
+the noise caused by the latency introduced by the host to device connection.
+
+Both these settings can be overridden if needed / desirable.
+([Repetitions](#repetitions), [WPR on host](#host_wpr))
+
+### Run the benchmark on live sites
+
+```
+./cb.py loadline-phone --browser <browser> --network live
+```
+
+*Attention:* This benchmark uses various custom metrics tailored to the
+individual pages. If the pages change, it is not guaranteed that these metrics
+will keep working.
+
+### Record a new WPR archive
+
+Uncomment the `wpr: {},` line in the probe config and run the benchmark on live
+sites (see the command above). The archive will be located in
+`results/latest/archive.wprgo`.
+
+*Attention:* This benchmark uses various custom metrics tailored to the
+individual pages. If the pages change, it is not guaranteed that these metrics
+will keep working.
+
+### Running WPR on the host {#host_wpr}
+
+If you care about running as little overhead as possible on the device, e.g. for
+power measurements, you might consider running the WPR server on the host
+machine instead of the device under test. You can do this by
+
+Adding `run_on_device: false,` to the corresponding network config file
+`config/benchmark/loadline/network_config_phone.hjson` or
+`config/benchmark/loadline/network_config_tablet.hjson`.
+
+Note golang must be available on the host machine. Check
+[go.mod](https://chromium.googlesource.com/catapult/+/HEAD/web_page_replay_go/go.mod)
+for the minimum version.
+
+### Run the benchmark with full set of experimental metrics
+
+Sometimes to investigate a source of a regression, or get deeper insights,
+it may be useful to collect more detailed traces and compute additional metrics.
+This can be done with the following command:
+
+```
+./cb.py loadline-phone --browser <browser>\
+  --probe-config config/benchmark/loadline/probe_config_experimental.hjson
+```
+
+Note that collecting detailed traces incurs significant overhead, so the
+benchmark scores will likely be lower than in the default configuration.
+
+## Common issues
+
+### Problems finding wpr.go
+
+If you see a `Could not find wpr.go binary` error:
+
+*   If you have chromium checked out locally: set `CHROMIUM_SRC` environment
+    variable to the path of your chromium/src folder.
+*   If not (or if you're still getting this error): see the next section.
+
+### Running the benchmark without full chromium checkout
+
+Follow the
+[crossbench development instructions](https://chromium.googlesource.com/crossbench/#development)
+to check out code and run crossbench standalone.
+
+### Problems accessing the cloud bucket
+
+In some cases, you might need to download the web page archive manually. In this
+case, save the archive file corresponding to the version you are running
+(`gs://chrome-partner-telemetry/loading_benchmark/archive_*.wprgo`) locally and
+run the benchmark as follows:
+
+```
+./cb.py loadline-phone --network <path to archive.wprgo>
+```
diff --git a/config/benchmark/loadline/cnn_instrumentation.js b/config/benchmark/loadline/cnn_instrumentation.js
new file mode 100644
index 0000000..981a299
--- /dev/null
+++ b/config/benchmark/loadline/cnn_instrumentation.js
@@ -0,0 +1,37 @@
+// Copyright 2024 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+const button_selector = 'button[id=onetrust-accept-btn-handler]'
+const headline_text_id = 'maincontent'
+
+const button_observer = new MutationObserver(mutations => {
+  const button = document.querySelector(button_selector)
+  if (!button) {
+    return
+  }
+  // This script can run multiple times.
+  if (localStorage.getItem('already_run') === 'already_run') {
+    return
+  }
+  localStorage.setItem('already_run', 'already_run')
+  performance.mark('cookie_banner_shown')
+  button.click()
+})
+
+button_observer.observe(document, {childList: true, subtree: true});
+
+const headline_observer = new MutationObserver(mutations => {
+  performance.mark('update');
+  const headline = document.getElementById(headline_text_id)
+  if (!headline) {
+    return
+  }
+  performance.mark('maincontent.created');
+});
+
+
+if (window.location ==
+    'https://edition.cnn.com/2024/04/21/china/china-spy-agency-public-profile-intl-hnk/index.html') {
+  headline_observer.observe(document, {childList: true, subtree: true});
+}
diff --git a/config/benchmark/loadline/globo_instrumentation.js b/config/benchmark/loadline/globo_instrumentation.js
new file mode 100644
index 0000000..91d49e0
--- /dev/null
+++ b/config/benchmark/loadline/globo_instrumentation.js
@@ -0,0 +1,34 @@
+// Copyright 2024 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+const button_selector = 'button[aria-label=Consent]'
+const banner_selector = 'div[class=fc-consent-root]'
+var banner_observer;
+
+const button_observer = new MutationObserver(mutations => {
+  const button = document.querySelector(button_selector)
+  if (!button) {
+    return
+  }
+  // This script can run multiple times.
+  if (localStorage.getItem('already_run') === 'already_run') {
+    return
+  }
+  localStorage.setItem('already_run', 'already_run')
+  performance.mark('cookie_banner_created')
+  const banner_node = document.querySelector(banner_selector)
+  banner_observer = new MutationObserver(function(e) {
+    e.forEach(function(m) {
+      m.removedNodes.forEach(function(n) {
+        if (n === banner_node) {
+          performance.mark('cookie_banner_gone')
+        }
+      })
+    })
+  });
+  banner_observer.observe(banner_node.parentNode, {childList: true});
+  button.click()
+})
+
+button_observer.observe(document, {childList: true, subtree: true});
diff --git a/config/benchmark/loadline/network_config_phone.hjson b/config/benchmark/loadline/network_config_phone.hjson
new file mode 100644
index 0000000..f5518cd
--- /dev/null
+++ b/config/benchmark/loadline/network_config_phone.hjson
@@ -0,0 +1,6 @@
+{
+  type: "wpr",
+  url: "gs://chrome-partner-telemetry/loading_benchmark/archive_phone.wprgo",
+  persist_server: true,
+  run_on_device: true,
+}
diff --git a/config/benchmark/loadline/network_config_tablet.hjson b/config/benchmark/loadline/network_config_tablet.hjson
new file mode 100644
index 0000000..a26e68c
--- /dev/null
+++ b/config/benchmark/loadline/network_config_tablet.hjson
@@ -0,0 +1,6 @@
+{
+  type: "wpr",
+  url: "gs://chrome-partner-telemetry/loading_benchmark/archive_tablet.wprgo",
+  persist_server: true,
+  run_on_device: true,
+}
diff --git a/config/benchmark/loadline/page_config_phone.hjson b/config/benchmark/loadline/page_config_phone.hjson
new file mode 100644
index 0000000..98b97e1
--- /dev/null
+++ b/config/benchmark/loadline/page_config_phone.hjson
@@ -0,0 +1,33 @@
+{
+  pages: {
+    amazon_product: [
+      {action: "get", url: "https://www.amazon.co.uk/NIVEA-Suncream-Spray-Protect-Moisture/dp/B001B0OJXM"},
+      {action: "wait_for_element", selector: "input[id=sp-cc-accept]", timeout: "3s"},
+      {action: "click", selector: "input[id=sp-cc-accept]"},
+      {action: "wait", duration: "3s"},
+      {action: "get", url: "about:blank"},
+    ],
+    cnn_article: [
+      {action: "inject_new_document_script", script_path: "cnn_instrumentation.js", timeout: "5s"},
+      {action: "get", url: "https://edition.cnn.com/2024/04/21/china/china-spy-agency-public-profile-intl-hnk/index.html"},
+      {action: "wait", duration: "5s"},
+      {action: "get", url: "about:blank"},
+    ],
+    wikipedia_article: [
+      {action: "get", url: "https://en.wikipedia.org/wiki/Taylor_Swift"},
+      {action: "wait", duration: "3s"},
+      {action: "get", url: "about:blank"},
+    ],
+    globo_homepage: [
+      {action: "inject_new_document_script", script_path: "globo_instrumentation.js", timeout: "5s"},
+      {action: "get", url: "https://globo.com"},
+      {action: "wait", duration: "5s"},
+      {action: "get", url: "about:blank"},
+    ],
+    google_search_result: [
+      {action: "get", url: "https://www.google.com/search?q=cats"},
+      {action: "wait", duration: "3s"},
+      {action: "get", url: "about:blank"},
+    ],
+  },
+}
diff --git a/config/benchmark/loadline/page_config_tablet.hjson b/config/benchmark/loadline/page_config_tablet.hjson
new file mode 100644
index 0000000..b20a4c5
--- /dev/null
+++ b/config/benchmark/loadline/page_config_tablet.hjson
@@ -0,0 +1,33 @@
+{
+  pages: {
+    amazon_product: [
+      {action: "get", url: "https://www.amazon.co.uk/NIVEA-Suncream-Spray-Protect-Moisture/dp/B001B0OJXM"},
+      {action: "wait_for_element", selector: "input[id=sp-cc-accept]", timeout: "3s"},
+      {action: "click", selector: "input[id=sp-cc-accept]"},
+      {action: "wait", duration: "3s"},
+      {action: "get", url: "about:blank"},
+    ],
+    cnn_article: [
+      {action: "inject_new_document_script", script_path: "cnn_instrumentation.js", timeout: "5s"},
+      {action: "get", url: "https://edition.cnn.com/2024/04/21/china/china-spy-agency-public-profile-intl-hnk/index.html"},
+      {action: "wait", duration: "10s"},
+      {action: "get", url: "about:blank"},
+    ],
+    google_doc: [
+      {action: "get", url: "https://docs.google.com/document/d/13AWeOGqtSkfpPK7meqE_X-GQQggwx4JJ1vc0YGvKg34/edit#heading=h.gjdgxs"},
+      {action: "wait", duration: "3s"},
+      {action: "get", url: "about:blank"},
+    ],
+    google_search_result: [
+      {action: "get", url: "https://www.google.com/search?q=cats"},
+      {action: "wait", duration: "3s"},
+      {action: "get", url: "about:blank"},
+    ],
+    youtube_video: [
+      {action: "inject_new_document_script", script_path: "youtube_instrumentation.js", timeout: "10s"},
+      {action: "get", url: "https://youtube.com/watch?v=WuS9kPNAXHw"},
+      {action: "wait", duration: "10s"},
+      {action: "get", url: "about:blank"},
+    ],
+  },
+}
diff --git a/config/benchmark/loadline/probe_config.hjson b/config/benchmark/loadline/probe_config.hjson
new file mode 100644
index 0000000..563bbaa
--- /dev/null
+++ b/config/benchmark/loadline/probe_config.hjson
@@ -0,0 +1,44 @@
+{
+  probes: {
+    // Uncomment the following line to record a WPR archive.
+    // wpr: {},
+    trace_processor: {
+      queries: [
+        "loadline/benchmark_score",
+      ],
+      batch: false,
+    },
+    perfetto: {
+      textproto: '''
+        buffers {
+          size_kb: 300000
+          fill_policy: DISCARD
+        }
+        data_sources {
+          config {
+            name: "org.chromium.trace_metadata"
+          }
+        }
+        data_sources {
+          config {
+            name: "track_event"
+            track_event_config {
+              disabled_categories: "*"
+              enabled_categories: "benchmark"
+              enabled_categories: "blink.user_timing"
+              enabled_categories: "devtools.timeline"
+              enabled_categories: "disabled-by-default-devtools.timeline"
+              enabled_categories: "loading"
+              enabled_categories: "v8"
+              enabled_categories: "__metadata"
+              timestamp_unit_multiplier: 1000
+              enable_thread_time_sampling: true
+              filter_debug_annotations: false
+              filter_dynamic_event_names: false
+            }
+          }
+        }
+      '''
+    }
+  }
+}
diff --git a/config/benchmark/loadline/probe_config_experimental.hjson b/config/benchmark/loadline/probe_config_experimental.hjson
new file mode 100644
index 0000000..2bdd8d2
--- /dev/null
+++ b/config/benchmark/loadline/probe_config_experimental.hjson
@@ -0,0 +1,85 @@
+{
+  probes: {
+    trace_processor: {
+      queries: [
+        "loadline/benchmark_score",
+        "loadline/experimental/cpu",
+        "loadline/experimental/dom",
+        "loadline/experimental/interaction_latency",
+        "loadline/experimental/mojo",
+        "loadline/experimental/resources",
+        "loadline/experimental/sequence_manager",
+        "loadline/experimental/tlp",
+        "loadline/experimental/v8",
+        "loadline/experimental/v8_rcs",
+        "loadline/experimental/web_features",
+        "loadline/experimental/worker",
+      ],
+    },
+    perfetto: {
+      textproto: '''
+        buffers {
+          size_kb: 300000
+          fill_policy: DISCARD
+        }
+        data_sources {
+          config {
+            name: "org.chromium.trace_metadata"
+          }
+        }
+        data_sources {
+          config {
+            name: "track_event"
+            chrome_config {
+                trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"benchmark\",\"loading\",\"toplevel\",\"toplevel.flow\",\"devtools.timeline\",\"interactions\",\"v8\",\"v8.execute\",\"blink\",\"blink.user_timing\",\"blink.worker\",\"navigation\",\"gpu\",\"scheduler\",\"disabled-by-default-v8.compile\",\"disabled-by-default-v8.runtime_stats\",\"disabled-by-default-histogram_samples\",\"disabled-by-default-devtools.timeline\"],\"excluded_categories\":[\"*\"],\"histogram_names\":[\"Blink.UseCounter.Features\"]}"
+                privacy_filtering_enabled: false
+                client_priority: USER_INITIATED
+            }
+            track_event_config {
+              disabled_categories: "*"
+              enabled_categories: "benchmark"
+              enabled_categories: "loading"
+              enabled_categories: "toplevel"
+              enabled_categories: "toplevel.flow"
+              enabled_categories: "devtools.timeline"
+              enabled_categories: "interactions"
+              enabled_categories: "v8"
+              enabled_categories: "v8.execute"
+              enabled_categories: "blink"
+              enabled_categories: "blink.user_timing"
+              enabled_categories: "blink.worker"
+              enabled_categories: "navigation"
+              enabled_categories: "gpu"
+              enabled_categories: "scheduler"
+              enabled_categories: "disabled-by-default-v8.compile"
+              enabled_categories: "disabled-by-default-v8.runtime_stats"
+              enabled_categories: "disabled-by-default-histogram_samples"
+              enabled_categories: "disabled-by-default-devtools.timeline"
+              enabled_categories: "__metadata"
+              timestamp_unit_multiplier: 1000
+              enable_thread_time_sampling: true
+              filter_debug_annotations: false
+              filter_dynamic_event_names: false
+            }
+          }
+        }
+        data_sources: {
+            config {
+                name: "linux.ftrace"
+                ftrace_config {
+                    ftrace_events: "sched/sched_switch"
+                    ftrace_events: "power/suspend_resume"
+                    ftrace_events: "sched/sched_wakeup"
+                    ftrace_events: "sched/sched_wakeup_new"
+                    ftrace_events: "sched/sched_waking"
+                    ftrace_events: "sched/sched_process_exit"
+                    ftrace_events: "sched/sched_process_free"
+                    ftrace_events: "task/task_newtask"
+                    ftrace_events: "task/task_rename"
+                }
+            }
+        }
+      '''
+    }
+  }
+}
diff --git a/config/benchmark/loadline/youtube_instrumentation.js b/config/benchmark/loadline/youtube_instrumentation.js
new file mode 100644
index 0000000..bdf96e5
--- /dev/null
+++ b/config/benchmark/loadline/youtube_instrumentation.js
@@ -0,0 +1,37 @@
+// Copyright 2024 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+const button_selector =
+    'div.body.style-scope.ytd-consent-bump-v2-lightbox > div.eom-buttons.style-scope.ytd-consent-bump-v2-lightbox > div:nth-child(1) > ytd-button-renderer:nth-child(1) > yt-button-shape > button'
+const banner_selector =
+    'ytd-consent-bump-v2-lightbox > tp-yt-paper-dialog[id=dialog]'
+
+const button_observer = new MutationObserver(mutations => {
+  const button = document.querySelector(button_selector)
+  if (!button) {
+    return
+  }
+  const banner_node = document.querySelector(banner_selector)
+  if (!banner_node) {
+    return
+  }
+  if (localStorage.getItem('already_run') === 'already_run') {
+    return
+  }
+  localStorage.setItem('already_run', 'already_run')
+  const banner_observer = new MutationObserver(function(e) {
+    for (m of e) {
+      if (m.type == 'attributes' && banner_node.style.display == 'none') {
+        performance.mark('cookie_banner_gone')
+        break
+      }
+    }
+  });
+  banner_observer.observe(
+      banner_node, {attributes: true, attributeFilter: ['style']});
+  performance.mark('cookie_banner_shown')
+  button.click()
+})
+
+button_observer.observe(document, {childList: true, subtree: true});
diff --git a/config/doc/README.md b/config/doc/README.md
new file mode 100644
index 0000000..6f7d6d5
--- /dev/null
+++ b/config/doc/README.md
@@ -0,0 +1,3 @@
+# Config Documentation
+This folder contains example and test configs for different components of
+crossbench. These configs are meant to be used for documentation.
diff --git a/config/doc/browser.config.hjson b/config/doc/browser.config.hjson
new file mode 100644
index 0000000..21d4771
--- /dev/null
+++ b/config/doc/browser.config.hjson
@@ -0,0 +1,126 @@
+{
+  // Contains groups of flags with variants, use by browsers
+  flags: {
+    flag-group-1: {
+      // Create variants (2 x 2 = 4) by creating the product of multiple
+      // flags and values.
+      --js-flags: [
+        null, // null => flag is not set
+        "--max-opt=1",
+        // "--max-opt=2",
+        // "--max-opt=4",
+      ],
+      --enable-fied-trial-config: [
+        null, // null => flag is not set
+        ""    // ""   => flag is set without a value
+      ]
+    },
+    // Define custom flag groups here (referenced by name):
+    chrome-custom: {
+      // Use strings to create arbitrary flag combinations
+      "deafult": "",
+      "experiment_1": "--enable-field-trial-config --disable-features=V8SlowHistograms",
+      "experiment_2": "--enable-field-trial-config --enable-features=V8SlowHistograms",
+    },
+
+    // ------------------------------------------------------------------------
+    // Examples:
+    example-group-1: {
+      // This will result in 2 x 2 = 4 flag configurations that are run:
+      //
+      //  1. no flags (both entries have a `null` variant)
+      //  2. `--js-flags=--no-opt`
+      //  3. `--js-flags=--no-opt --enable-field-trial-config`
+      //  4. `--enable-field-trial-config`
+      --js-flags: [null, "--no-opt"],
+      --enable-field-trial-config: [null, ""]
+    },
+    example-group-2: {
+      // This flag group creates 3 x 2 = 6 varaints:
+      // Use the empty string "" for flags without values
+      "--enable-fied-trial-config": "",
+      // A flag with multiple variants:
+      --js-flags: [
+        null, // variant 1: null == flag is not set
+        "--no-opt --no-ic", // variant 2
+        "--no-sparkplug",   // variant 2
+      ]
+      // Flag with two variants: unset and set
+      "--no-sandbox": [
+        null, // variant 1: null => flag is not set
+        "",   // variant 2: ""   => flag is set without value
+      ]
+    },
+  },
+
+  // --------------------------------------------------------------------------
+  // Contains browser configs
+  browsers: {
+    "chrome-stable-with-flags": {
+      // For "path" you can use a path, browser name, or a versioned browser.
+      // See '--browser' option for all possible values.
+      path: "chrome-stable",
+      # Either the browsers key ("chrome-stable-with-flags") if no label
+      # is specified, otherwise the this label property ("custom-browser-label")
+      # is used.
+      label: "custom-browser-label",
+      flags: [
+        // You can reference multiple flag-groups here, any name added to
+        // the 'flags' dict above can be used here.
+        "flag-group-1",
+        // More flag groups can be added, for instance "chrome-custom", and
+        // you get the product of all flag variants.
+        // You can also directly define fixed flags
+        // "--js-flags=--no-opt",
+      ]
+    }
+  },
+
+  // You can use either comments or other sections to hide configurations
+  // Supported browser names are:
+  // * Chrome:  chrome-stable, chrome-beta, chrome-dev, chrome-canary
+  // * Edge:    edge-stable, edge-beta, edge-dev, edge-canary
+  // * Safari:  safari, safari-tp
+  // * Firefox: firefox-stable, firefox-dev, firefox-nightly
+  browsers-disabled: {
+    "chrome-stable": {
+      browser: "chrome-stable", // or any other name
+      flags: [ /* ... add your flag groups here */ ]
+    },
+    "chromium-mac-local": {
+      path: "~/Documents/chromium/src/out/Release/Chromium.app",
+      // Use custom chromedriver binary for local builds:
+      driver: "~/Documents/chromium/src/out/Release/chromedriver"
+      flags: [ /* ... add your flag groups here */  ]
+    },
+    "chrome-android-canary": {
+      browser: "chrome-canary",
+      driver: "adb", // Just adb for a single device
+      flags: [ /* ... add your flag groups here */  ]
+    },
+    "chrome-android-canary-pixel": {
+      browser: "chrome-canary",
+      driver: {
+        type: "adb",
+        // Use unique name or serial number from `adb devices -l`
+        device_id: "Pixel_7_Pro"
+      }
+      flags: [ /* ... add your flag groups here */  ]
+    },
+    "safari": {
+      browser: "safari",
+    },
+    "safari-tech-preview": {
+      browser: "safari-tp",
+    },
+    "safari-ios": {
+      browser: "safari",
+      driver: {
+        type: "ios",
+        // Use the device UUID, see "xcrun xctrace list devices" for avilable
+        // devices and simulators.
+        device_id: "00001234-AAAA-BBBB-1111-11AA22BB33DD"
+      }
+    }
+  }
+}
diff --git a/config/doc/env.config.hjson b/config/doc/env.config.hjson
new file mode 100644
index 0000000..6d5c1cd
--- /dev/null
+++ b/config/doc/env.config.hjson
@@ -0,0 +1,15 @@
+{
+    // See env.py for more details
+    env: {
+        // null => requirement is ignored
+        disk_min_free_space_gib: null,
+        power_use_battery: false,
+        screen_brightness_percent: 50
+        cpu_max_usage_percent: 99,
+        cpu_min_relative_speed: 1,
+        system_allow_monitoring: false,
+        browser_allow_existing_process: false,
+        browser_is_headless: null,
+        require_probes: null,
+    }
+}
\ No newline at end of file
diff --git a/config/doc/page.config.hjson b/config/doc/page.config.hjson
new file mode 100644
index 0000000..e848193
--- /dev/null
+++ b/config/doc/page.config.hjson
@@ -0,0 +1,114 @@
+{
+    // See loading.py  or `crossbench loading --help` for more details.
+    // Usage:
+    //   crossbench loading --page-config=config.hjson
+  pages: {
+        // Example below will result in:
+        // A Scenario named = Google and will perfom the actions listed synchronisly
+        // Time suffixes accepted:
+        //   milliseconds: ["ms", "millis", "milliseconds"]
+        //   seconds:      ["s", "sec", "second", "seconds"]
+        //   minutes:      ["m", "min", "minute", "minutes"]
+        //   hours:        ["h", "hrs", "hour", "hours"]
+        //
+        // Supported Actions:
+        //  GET: {
+        //      action: "get",
+        //      url: URL,
+        //      duration: DURATION,
+        //      ready_state: [any, interactive, complete],
+        //      target: [self, _blank, _parent, _top],
+        //      timeout: DURATION,
+        //  }
+        //
+        //  CLICK: {
+        //      action: "click",
+        //      selector: [CSS_SELECTOR, XPATH_SELECTOR],
+        //      required: BOOL,
+        //      scroll_into_view: BOOL,
+        //      timeout: DURATION,
+        //  }
+        //
+        //  WAIT: {
+        //      action: "wait",
+        //      duration: DURATION,
+        //  }
+        //
+        //  SCROLL: {
+        //      action: "scroll",
+        //      direction: [up, down],
+        //      distance: NUMBER,
+        //      duration: DURATION,
+        //  }
+        //
+
+    "Google": [
+      {
+        "action": "get",
+        "url": "https://www.google.de/search?q=magic",
+        "duration": "2s"
+      },
+            // Click away the cookie banner:
+      {
+        "action": "click",
+        "required": false,
+        "selector": "xpath///button/div[contains(text(),'akzeptieren')]"
+      },
+      {
+        "action": "click",
+        "required": false,
+        "selector": "xpath///button/div[contains(text(),'Accept')]"
+      },
+      {
+        "action": "scroll",
+        "distance": 2000,
+        "duration": "3s"
+      }
+    ],
+
+    "Amazon": [
+      {
+        "action": "get",
+        "url": "https://www.amazon.com/s?k=v8"
+      },
+      {
+        "action": "wait",
+        "duration": "500ms"
+      },
+      {
+        "action": "scroll",
+        "distance": 2000,
+        "duration": "2s"
+      },
+      {
+        "action": "scroll",
+        "distance": -1000,
+        "duration": "1.5s"
+      }
+    ],
+
+    "Youtube": [
+      {
+        "action": "get",
+        "url": "https://www.youtube.com",
+        "timeout": "20s",
+        "ready-state": "interactive"
+      },
+            // Click away the cookie banner:
+      {
+        "action": "click",
+        "required": false,
+        "selector": "xpath///*/button[contains(@aria-label, 'akzeptieren')]"
+      },
+      {
+        "action": "click",
+        "required": false,
+        "selector": "xpath///*/button[contains(@aria-label, 'Accept')]"
+      },
+      {
+        "action": "scroll",
+        "duration": "1s"
+      }
+    ]
+  }
+}
\ No newline at end of file
diff --git a/config/doc/probe.config.hjson b/config/doc/probe.config.hjson
new file mode 100644
index 0000000..9bf4f23
--- /dev/null
+++ b/config/doc/probe.config.hjson
@@ -0,0 +1,11 @@
+{
+  probes: {
+    // An example config for the v8.log probe:
+    "v8.log": {
+      log_all: false, // use custom V8 logging flags.
+      prof: false, // bool values are JS not Python!
+      profview: false // disable http://v8.dev/tools/head/profview/ data
+      js_flags: ["--log-maps", "--log-function-events"],
+    }
+  }
+}
diff --git a/config/doc/probe/README.md b/config/doc/probe/README.md
new file mode 100644
index 0000000..a4492ca
--- /dev/null
+++ b/config/doc/probe/README.md
@@ -0,0 +1,8 @@
+# Probe Config Documentation
+
+This folder contains example and test configs for different probes.
+
+These configs are meant to be used for documentation and can be copied and
+adapted for personal use.
+
+[config/probe](../../probe) contains directly usable probe configurations.
\ No newline at end of file
diff --git a/config/doc/probe/chrome_histograms.hjson b/config/doc/probe/chrome_histograms.hjson
new file mode 100644
index 0000000..01244b8
--- /dev/null
+++ b/config/doc/probe/chrome_histograms.hjson
@@ -0,0 +1,24 @@
+// This is an example config to be used with the --probe-config switch.
+{
+  probes: {
+    chrome_histograms: {
+      // metrics is a dictionary keyed by UMA histogram name, see
+      // chrome://histograms for histograms logged by a browser. Each histogram
+      // key has an array of metrics to generate. Metrics can be the following:
+      // * "count": the number of samples logged to the histogram.
+      // * "mean": the average value logged to the histogram.
+      // * "p{number}" (e.g. "p50", "p90"): The percentile value of samples
+      //     logged to the histogram. APPROXIMATE.
+      metrics: {
+        // E.g. the following line will create four entries in the results:
+        // * "WebVitals.FirstContentfulPaint3_count"
+        // * "WebVitals.FirstContentfulPaint3_mean"
+        // * "WebVitals.FirstContentfulPaint3_p50"
+        // * "WebVitals.FirstContentfulPaint3_p90"
+        "WebVitals.FirstContentfulPaint3": ["count", "mean", "p50", "p90"],
+        // And another metrics are made from this histogram.
+        "Startup.FirstWebContents.NonEmptyPaint3": ["count", "mean", "p50", "p90"],
+      },
+    },
+  }
+}
\ No newline at end of file
diff --git a/config/doc/probe/dtrace.config.example.d b/config/doc/probe/dtrace.config.example.d
new file mode 100644
index 0000000..460c4ea
--- /dev/null
+++ b/config/doc/probe/dtrace.config.example.d
@@ -0,0 +1,31 @@
+// Copyright 2021 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+// This script profiles the execution of a process and all its children.
+// Execute like this:
+//   sudo dtrace -s profile.d $(pgrep -x "Google Chrome")
+
+// Note on results produced:
+//
+// This script will produce a data file suitable to be converted to a pprof by
+// export_dtrace.py. The flamegraph generated will present time spent on-cpu as
+// a fraction of the total. More time spent on-cpu does not necessarily mean
+// more power consumed. A CPU running at a low frequency will take a long time
+// to execute work but might do it in a more power-efficient way than if it was
+// running at a higher frequency. The same can be said about core selection in
+// a big.LITTLE style architecture.
+
+// Profile with a high frequency that is prime to avoid unfortunate alignement
+// with periods of repeating tasks internal to the process. The frequency was
+// verified as supported by macOS Monterey running on Intel. See
+// illumos.org/books/dtrace/chp-profile.html#chp-profile-5 for details.
+profile-997/(pid == $1 || ppid == $1)/
+{
+  @[ustack(512)] = count();
+}
+
+// Future work:
+// Currently the frequency data is not filled in within the |curcpu| variable
+// on macOS. The |cpu| variable is correctly filled in so applying some notion
+// of per-core type weight will be integrated into this script eventually.
\ No newline at end of file
diff --git a/config/doc/probe/dtrace.config.hjson b/config/doc/probe/dtrace.config.hjson
new file mode 100644
index 0000000..f4fcdd2
--- /dev/null
+++ b/config/doc/probe/dtrace.config.hjson
@@ -0,0 +1,10 @@
+// This is an example config to be used with the --probe-config switch. Set
+// `script_path` to the path of your own DTrace script. The script should
+// generate output through stdout which will be redirected to an output file.
+{
+  probes: {
+    "dtrace": {
+      script_path : "./dtrace.config.example.d",
+    },
+  }
+}
diff --git a/config/doc/probe/frequency.with_wildcard_asterisk.config.hjson b/config/doc/probe/frequency.with_wildcard_asterisk.config.hjson
new file mode 100644
index 0000000..5825fd4
--- /dev/null
+++ b/config/doc/probe/frequency.with_wildcard_asterisk.config.hjson
@@ -0,0 +1,10 @@
+{
+  probes: {
+    frequency: {
+      cpus: {
+        // If a wildcard is used, it should be the one key in the map.
+        *: "max"
+      }
+    }
+  }
+}
diff --git a/config/doc/probe/frequency.with_wildcard_string.config.hjson b/config/doc/probe/frequency.with_wildcard_string.config.hjson
new file mode 100644
index 0000000..e3c2236
--- /dev/null
+++ b/config/doc/probe/frequency.with_wildcard_string.config.hjson
@@ -0,0 +1,7 @@
+{
+  probes: {
+    frequency: {
+      cpus: "max"
+    }
+  }
+}
diff --git a/config/doc/probe/frequency.without_wildcard.config.hjson b/config/doc/probe/frequency.without_wildcard.config.hjson
new file mode 100644
index 0000000..45eefd4
--- /dev/null
+++ b/config/doc/probe/frequency.without_wildcard.config.hjson
@@ -0,0 +1,11 @@
+{
+  probes: {
+    frequency: {
+      cpus: {
+        cpu0: 1111,
+        cpu1: "min",
+        cpu2: "max"
+      }
+    }
+  }
+}
diff --git a/config/doc/probe/js.config.hjson b/config/doc/probe/js.config.hjson
new file mode 100644
index 0000000..c4b0e6f
--- /dev/null
+++ b/config/doc/probe/js.config.hjson
@@ -0,0 +1,15 @@
+// This is an example config to be used with the --probe-config switch.
+{
+  probes: {
+    js: {
+      # You can use "setup" to run some code before any story and set up
+      # some tracking or patch existing JS functions.
+      # setup: "globalThis.customMetrics = { };"
+
+      # This js code should return a simple JS object where the keys are the
+      # metric names and the values are numbers. The data is then automatially
+      # merged over multiple iterations by the probe.
+      js: 'return { "elements":  document.getElementsByTagName("*").length };'
+    },
+  }
+}
diff --git a/config/doc/probe/perfetto.config.hjson b/config/doc/probe/perfetto.config.hjson
new file mode 100644
index 0000000..8816358
--- /dev/null
+++ b/config/doc/probe/perfetto.config.hjson
@@ -0,0 +1,58 @@
+{
+  probes: {
+    perfetto: {
+      // texproto can be directly copied from https://ui.perfetto.dev/#!/record?p=instructions
+      // under the "recording command' settings.
+      textproto: '''
+        buffers: {
+            size_kb: 63488
+            fill_policy: DISCARD
+        }
+        data_sources: {
+            config {
+                name: "org.chromium.trace_event"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+            }
+        }
+        data_sources: {
+            config {
+                name: "track_event"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+                track_event_config {
+                    disabled_categories: "*"
+                    enabled_categories: "disabled-by-default-v8.cpu_profiler"
+                    enabled_categories: "toplevel"
+                    enabled_categories: "toplevel.flow"
+                    enabled_categories: "scheduler"
+                    enabled_categories: "sequence_manager"
+                    enabled_categories: "disabled-by-default-toplevel.flow"
+                    enabled_categories: "__metadata"
+                    timestamp_unit_multiplier: 1000
+                    filter_debug_annotations: false
+                    enable_thread_time_sampling: true
+                    filter_dynamic_event_names: false
+                }
+            }
+        }
+        data_sources: {
+            config {
+                name: "org.chromium.trace_metadata"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+            }
+        }
+      ''',
+    },
+  },
+}
diff --git a/config/doc/probe/trace_processor.config.hjson b/config/doc/probe/trace_processor.config.hjson
new file mode 100644
index 0000000..6e402ca
--- /dev/null
+++ b/config/doc/probe/trace_processor.config.hjson
@@ -0,0 +1,53 @@
+// trace_processor probe example
+{
+  probes: {
+    trace_processor: {
+      queries: ["speedometer_cpu_time"],
+      metrics: ["trace_stats"],
+    },
+    perfetto: {
+      textproto: '''
+        buffers {
+          size_kb: 300000
+          fill_policy: DISCARD
+        }
+        data_sources {
+          config {
+            name: "org.chromium.trace_metadata"
+          }
+        }
+        data_sources {
+          config {
+            name: "track_event"
+            track_event_config {
+              disabled_categories: "*"
+              enabled_categories: "blink.user_timing"
+              enabled_categories: "toplevel"
+              enabled_categories: "__metadata"
+              timestamp_unit_multiplier: 1000
+              enable_thread_time_sampling: true
+              filter_debug_annotations: false
+              filter_dynamic_event_names: false
+            }
+          }
+        }
+        data_sources: {
+          config {
+              name: "linux.ftrace"
+            ftrace_config {
+              ftrace_events: "sched/sched_switch"
+              ftrace_events: "power/suspend_resume"
+              ftrace_events: "sched/sched_wakeup"
+              ftrace_events: "sched/sched_wakeup_new"
+              ftrace_events: "sched/sched_waking"
+              ftrace_events: "sched/sched_process_exit"
+              ftrace_events: "sched/sched_process_free"
+              ftrace_events: "task/task_newtask"
+              ftrace_events: "task/task_rename"
+            }
+          }
+        }
+      '''
+    }
+  }
+}
diff --git a/config/doc/remote_browser.config.hjson b/config/doc/remote_browser.config.hjson
new file mode 100644
index 0000000..4be3717
--- /dev/null
+++ b/config/doc/remote_browser.config.hjson
@@ -0,0 +1,28 @@
+{
+  "browsers": {
+    "linux-ssh-chrome": {
+      "path": "/path/to/google/chrome",
+      "driver": {
+        "type": "ssh",
+        "settings": {
+          "host": "my-linux-machine",
+          "port": 9515,
+          "ssh_port": 22,
+          "ssh_user": "user"
+        }
+      }
+    },
+    "chromeos-ssh-chrome": {
+      "path": "/opt/google/chrome/chrome",
+      "driver": {
+        "type": "chromeos-ssh",
+        "settings": {
+          "host": "my-chromeos-machine",
+          "port": 9515,
+          "ssh_port": 22,
+          "ssh_user": "root"
+        }
+      }
+    }
+  }
+}
diff --git a/config/probe/README.md b/config/probe/README.md
new file mode 100644
index 0000000..891498d
--- /dev/null
+++ b/config/probe/README.md
@@ -0,0 +1,7 @@
+# Probe Configurations
+
+This folder contains example and test configs for individual probes that
+can be directly used.
+
+[config/doc/probe](../doc/probe) contains example configs with
+more detailed documentation.
\ No newline at end of file
diff --git a/config/probe/perfetto/default.config.hjson b/config/probe/perfetto/default.config.hjson
new file mode 100644
index 0000000..938507d
--- /dev/null
+++ b/config/probe/perfetto/default.config.hjson
@@ -0,0 +1,56 @@
+{
+  probes: {
+    perfetto: {
+      textproto: '''
+        buffers: {
+            size_kb: 63488
+            fill_policy: DISCARD
+        }
+        data_sources: {
+            config {
+                name: "org.chromium.trace_event"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+            }
+        }
+        data_sources: {
+            config {
+                name: "track_event"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+                track_event_config {
+                    disabled_categories: "*"
+                    enabled_categories: "disabled-by-default-v8.cpu_profiler"
+                    enabled_categories: "toplevel"
+                    enabled_categories: "toplevel.flow"
+                    enabled_categories: "scheduler"
+                    enabled_categories: "sequence_manager"
+                    enabled_categories: "disabled-by-default-toplevel.flow"
+                    enabled_categories: "__metadata"
+                    timestamp_unit_multiplier: 1000
+                    filter_debug_annotations: false
+                    enable_thread_time_sampling: true
+                    filter_dynamic_event_names: false
+                }
+            }
+        }
+        data_sources: {
+            config {
+                name: "org.chromium.trace_metadata"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+            }
+        }
+      ''',
+    },
+  },
+}
diff --git a/config/probe/trace_processor/default.config.hjson b/config/probe/trace_processor/default.config.hjson
new file mode 100644
index 0000000..6e402ca
--- /dev/null
+++ b/config/probe/trace_processor/default.config.hjson
@@ -0,0 +1,53 @@
+// trace_processor probe example
+{
+  probes: {
+    trace_processor: {
+      queries: ["speedometer_cpu_time"],
+      metrics: ["trace_stats"],
+    },
+    perfetto: {
+      textproto: '''
+        buffers {
+          size_kb: 300000
+          fill_policy: DISCARD
+        }
+        data_sources {
+          config {
+            name: "org.chromium.trace_metadata"
+          }
+        }
+        data_sources {
+          config {
+            name: "track_event"
+            track_event_config {
+              disabled_categories: "*"
+              enabled_categories: "blink.user_timing"
+              enabled_categories: "toplevel"
+              enabled_categories: "__metadata"
+              timestamp_unit_multiplier: 1000
+              enable_thread_time_sampling: true
+              filter_debug_annotations: false
+              filter_dynamic_event_names: false
+            }
+          }
+        }
+        data_sources: {
+          config {
+              name: "linux.ftrace"
+            ftrace_config {
+              ftrace_events: "sched/sched_switch"
+              ftrace_events: "power/suspend_resume"
+              ftrace_events: "sched/sched_wakeup"
+              ftrace_events: "sched/sched_wakeup_new"
+              ftrace_events: "sched/sched_waking"
+              ftrace_events: "sched/sched_process_exit"
+              ftrace_events: "sched/sched_process_free"
+              ftrace_events: "task/task_newtask"
+              ftrace_events: "task/task_rename"
+            }
+          }
+        }
+      '''
+    }
+  }
+}
diff --git a/config/team/README.md b/config/team/README.md
new file mode 100644
index 0000000..2dd654c
--- /dev/null
+++ b/config/team/README.md
@@ -0,0 +1 @@
+This folder contains team-specific configs that are used on a regular basis.
\ No newline at end of file
diff --git a/config/team/catan/power_sampler.config.hjson b/config/team/catan/power_sampler.config.hjson
new file mode 100644
index 0000000..31049b9
--- /dev/null
+++ b/config/team/catan/power_sampler.config.hjson
@@ -0,0 +1,41 @@
+{
+  // This file will NOT be submited in final version. Used to test
+  // flags/config/parsing. The idea is this file can be share to quickly set up
+  // and recreate config to benchmark
+  browsers: {
+    "chrome-stable": {
+      path: "chrome-stable",
+      flags: [
+        // You can pass a user-data-dir path to the --user-data-dir flag.
+        // Usefull in scenarios where the users wants to use an existent
+        // user-data-dir instead of creating a new temporary directory.
+        --user-data-dir="PATH/SOMETHING/SOMETHING",
+        //--start-fullscreen=true,
+        --start-maximized=true,
+        --center-mouse=true
+      ]
+    }
+  },
+  env: {
+    "disk_min_free_space_gib": null,
+    "power_use_battery": true,
+    "screen_brightness_percent": 60,
+    "cpu_max_usage_percent": 98,
+    "cpu_min_relative_speed": 1,
+    "system_allow_monitoring": false,
+    "browser_allow_existing_process": false,
+    "browser_is_headless": false,
+    "require_probes": true,
+    "system_forbidden_process_names": "",
+    "screen_allow_autobrightness": false,
+  },
+  probes: {
+    "powersampler": {
+      bin_path: "/Users/aattar/chromium/src/out/Release/power_sampler",
+      // Use sampling_interval=0 to use '--sample-on-notification' instead of
+      // specifying an explicit sampling_interval
+      sampling_interval: 0,
+      wait_for_battery: false,
+    },
+  }
+}
diff --git a/config/team/coreloading/probe_config.hjson b/config/team/coreloading/probe_config.hjson
new file mode 100644
index 0000000..233cbad
--- /dev/null
+++ b/config/team/coreloading/probe_config.hjson
@@ -0,0 +1,64 @@
+{
+  probes: {
+    trace_processor: {
+      queries: ["search_latency"]
+    },
+    perfetto: {
+      textproto: '''
+        buffers {
+          size_kb: 300000
+          fill_policy: DISCARD
+        }
+        data_sources {
+          config {
+            name: "org.chromium.trace_metadata"
+          }
+        }
+        data_sources {
+          config {
+            name: "track_event"
+            track_event_config {
+              enabled_categories: "*"
+              enabled_categories: "benchmark"
+              enabled_categories: "__metadata"
+              enabled_categories: "disabled-by-default-loading"
+              enabled_categories: "disabled-by-default-network"
+              enabled_categories: "disabled-by-default-net"
+              enabled_categories: "disabled-by-default-toplevel.flow"
+              enabled_categories: "disabled-by-default-ipc.flow"
+            }
+          }
+        }
+        data_sources: {
+          config {
+            name: "linux.ftrace"
+            ftrace_config {
+              ftrace_events: "sched/sched_switch"
+              ftrace_events: "power/suspend_resume"
+              ftrace_events: "sched/sched_wakeup"
+              ftrace_events: "sched/sched_wakeup_new"
+              ftrace_events: "sched/sched_waking"
+              ftrace_events: "sched/sched_process_exit"
+              ftrace_events: "sched/sched_process_free"
+              ftrace_events: "task/task_newtask"
+              ftrace_events: "task/task_rename"
+            }
+          }
+        }
+        data_sources: {
+          config {
+            name: "linux.perf"
+            perf_event_config {
+              timebase {
+                frequency: 100
+                timestamp_clock: PERF_CLOCK_BOOTTIME
+              }
+              callstack_sampling {
+              }
+            }
+          }
+        }
+      '''
+    }
+  }
+}
diff --git a/config/team/coreloading/serp.page_config.hjson b/config/team/coreloading/serp.page_config.hjson
new file mode 100644
index 0000000..214f4c5
--- /dev/null
+++ b/config/team/coreloading/serp.page_config.hjson
@@ -0,0 +1,16 @@
+{
+  pages: {
+    "Google": [
+      {
+        "action": "get",
+        "url": "https://www.google.com/search?q=puppies",
+        "duration": "4s"
+      },
+      {
+        "action": "get",
+        "url": "about:blank",
+        "duration": "1s"
+      },
+    ],
+  }
+}
diff --git a/config/team/v8/perfetto.probe.config.hjson b/config/team/v8/perfetto.probe.config.hjson
new file mode 100644
index 0000000..938507d
--- /dev/null
+++ b/config/team/v8/perfetto.probe.config.hjson
@@ -0,0 +1,56 @@
+{
+  probes: {
+    perfetto: {
+      textproto: '''
+        buffers: {
+            size_kb: 63488
+            fill_policy: DISCARD
+        }
+        data_sources: {
+            config {
+                name: "org.chromium.trace_event"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+            }
+        }
+        data_sources: {
+            config {
+                name: "track_event"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+                track_event_config {
+                    disabled_categories: "*"
+                    enabled_categories: "disabled-by-default-v8.cpu_profiler"
+                    enabled_categories: "toplevel"
+                    enabled_categories: "toplevel.flow"
+                    enabled_categories: "scheduler"
+                    enabled_categories: "sequence_manager"
+                    enabled_categories: "disabled-by-default-toplevel.flow"
+                    enabled_categories: "__metadata"
+                    timestamp_unit_multiplier: 1000
+                    filter_debug_annotations: false
+                    enable_thread_time_sampling: true
+                    filter_dynamic_event_names: false
+                }
+            }
+        }
+        data_sources: {
+            config {
+                name: "org.chromium.trace_metadata"
+                chrome_config {
+                    trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"disabled-by-default-v8.cpu_profiler\",\"toplevel\",\"toplevel.flow\",\"scheduler\",\"sequence_manager\",\"disabled-by-default-toplevel.flow\"],\"excluded_categories\":[\"*\"],\"memory_dump_config\":{}}"
+                    privacy_filtering_enabled: false
+                    client_priority: USER_INITIATED
+                }
+            }
+        }
+      ''',
+    },
+  },
+}
diff --git a/config/team/woa/android_input_page_config.hjson b/config/team/woa/android_input_page_config.hjson
new file mode 100644
index 0000000..ad9bcc0
--- /dev/null
+++ b/config/team/woa/android_input_page_config.hjson
@@ -0,0 +1,13 @@
+// Run with --action-runner=android
+{
+  pages: {
+    CNN: [
+      {action: "get", url: "https://edition.cnn.com"},
+      {action: "wait", duration: '5s'},
+      {action: "click", source: "touch", selector: "button[id=onetrust-accept-btn-handler]"},
+      {action: "wait", duration: '5s'},
+      {action: "swipe", duration: '1s', startx: 500, starty: 1800, endx: 500, endy: 800},
+      {action: "wait", duration: '5s'},
+    ],
+  },
+}
diff --git a/config/team/woa/templates/android_chrome_v8_stack_samples.hjson b/config/team/woa/templates/android_chrome_v8_stack_samples.hjson
new file mode 100644
index 0000000..04aa8bf
--- /dev/null
+++ b/config/team/woa/templates/android_chrome_v8_stack_samples.hjson
@@ -0,0 +1,35 @@
+// Minimum config required to collect Chrome and V8 stack samples on Android.
+// V8 Jitted code will be symbolized but to symbolize chrome you will need to
+// use Perfetto's symbolization tools.
+{
+  browsers: {
+    chrome: {
+      browser: "chrome-stable",
+      flags: [
+        "--js-flags=--interpreted_frames_native_stack,--perfetto_code_logger"
+      ]
+      driver: {
+        type: "adb",
+      }}}
+  env: {}
+  probes: {
+    trace_processor: {
+    }
+    perfetto: {
+      textproto: '''
+buffers {
+  size_kb: 500000
+  fill_policy: DISCARD
+}
+data_sources {
+  config {
+    name: "dev.v8.code"
+  }}
+'''
+    }
+    profiling: {
+      target: "renderer_main_only"
+      pprof: false
+      events: ['cpu-cycles']
+      count: 1000000
+    }}}
diff --git a/config/team/woa/templates/pmu_counters.hjson b/config/team/woa/templates/pmu_counters.hjson
new file mode 100644
index 0000000..953d222
--- /dev/null
+++ b/config/team/woa/templates/pmu_counters.hjson
@@ -0,0 +1,53 @@
+// Example config for collecting PMU counters for Chrome on Android.
+{
+  browsers: {
+    chrome: {
+      browser: "chrome-stable",
+      driver: {
+        type: "adb",
+      }
+    },
+  }
+  env: {
+  },
+  probes: {
+    trace_processor: {},
+    perfetto: {
+    // These Chrome tracing categories allow us to associate PMU counters with events.
+      textproto: '''
+buffers {
+  size_kb: 300000
+  fill_policy: DISCARD
+}
+data_sources: {
+  config {
+    name: "track_event"
+    track_event_config {
+      disabled_categories: "*"
+      enabled_categories: "blink.user_timing"
+    }
+  }
+}
+data_sources {
+  config {
+    name: "org.chromium.trace_metadata"
+  }
+}
+'''
+    }
+    profiling: {
+      // Profile the renderer main thread only.
+      target: "renderer_main_only"
+      pprof: false
+      events: ['cpu-cycles']
+      count: 500000
+      call_graph_mode: 'no_call_graph'
+      // Pin the big core, this could be a different CPU on your device.
+      cpu: [7]
+      pin_renderer_main_core: 7
+      add_counters: [
+        'raw-inst-retired',
+      ]
+    }
+  }
+}
diff --git a/crossbench/__init__.py b/crossbench/__init__.py
new file mode 100644
index 0000000..941488b
--- /dev/null
+++ b/crossbench/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+__version__ = "1.0.5"
diff --git a/crossbench/action_runner/__init__.py b/crossbench/action_runner/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/action_runner/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/action_runner/action/__init__.py b/crossbench/action_runner/action/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/action_runner/action/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/action_runner/action/action.py b/crossbench/action_runner/action/action.py
new file mode 100644
index 0000000..b20ca8c
--- /dev/null
+++ b/crossbench/action_runner/action/action.py
@@ -0,0 +1,116 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+from typing import TYPE_CHECKING, Any, Dict, Type, TypeVar
+
+from crossbench import exception
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.config import ConfigObject, ConfigParser
+from crossbench.parse import DurationParser, NumberParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class ActionTypeConfigParser(ConfigParser):
+  """Custom ConfigParser for ActionType that works on
+  Action Configs. This way we can pop the 'value' or 'type' key from the
+  config dict."""
+
+  def __init__(self):
+    super().__init__("ActionType parser", ActionType)
+    self.add_argument(
+        "action",
+        aliases=("type",),
+        type=ObjectParser.non_empty_str,
+        required=True)
+
+  def new_instance_from_kwargs(self, kwargs: Dict[str, Any]) -> ActionType:
+    return ActionType(kwargs["action"])
+
+
+_ACTION_TYPE_CONFIG_PARSER = ActionTypeConfigParser()
+
+ACTION_TIMEOUT = dt.timedelta(seconds=20)
+
+ActionT = TypeVar("ActionT", bound="Action")
+
+# Lazily initialized Action class lookup.
+ACTIONS: Dict[ActionType, Type[Action]] = {}
+
+
+class Action(ConfigObject, metaclass=abc.ABCMeta):
+  TYPE: ActionType = ActionType.GET
+
+  @classmethod
+  def parse_str(cls, value: str) -> Action:
+    return ACTIONS[ActionType.GET].parse_str(value)
+
+  @classmethod
+  def parse_dict(cls: Type[ActionT], config: Dict[str, Any]) -> ActionT:
+    action_type: ActionType = _ACTION_TYPE_CONFIG_PARSER.parse(config)
+    action_cls: Type[ActionT] = ACTIONS[action_type]
+    with exception.annotate_argparsing(
+        f"Parsing Action details  ...{{ action: \"{action_type}\", ...}}:"):
+      action = action_cls.config_parser().parse(config)
+    assert isinstance(action, cls), f"Expected {cls} but got {type(action)}"
+    return action
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = ConfigParser(f"{cls.__name__} parser", cls)
+    parser.add_argument(
+        "index", type=NumberParser.positive_zero_int, required=False, default=0)
+    parser.add_argument(
+        "timeout",
+        type=DurationParser.positive_duration,
+        default=ACTION_TIMEOUT)
+    return parser
+
+  def __init__(self, timeout: dt.timedelta = ACTION_TIMEOUT, index: int = 0):
+    self._timeout: dt.timedelta = timeout
+    self._index = index
+    self.validate()
+
+  @property
+  def index(self) -> int:
+    return self._index
+
+  @property
+  def duration(self) -> dt.timedelta:
+    return dt.timedelta(milliseconds=10)
+
+  @property
+  def timeout(self) -> dt.timedelta:
+    return self._timeout
+
+  @property
+  def has_timeout(self) -> bool:
+    return self._timeout != dt.timedelta.max
+
+  @abc.abstractmethod
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    pass
+
+  def validate(self) -> None:
+    if self._timeout.total_seconds() < 0:
+      raise ValueError(
+          f"{self}.timeout should be positive, but got {self.timeout}")
+
+  def to_json(self) -> JsonDict:
+    return {"type": str(self.TYPE), "timeout": self.timeout.total_seconds()}
+
+  def __str__(self) -> str:
+    return type(self).__name__
+
+  def __eq__(self, other: object) -> bool:
+    if isinstance(other, Action):
+      return self.to_json() == other.to_json()
+    return False
diff --git a/crossbench/action_runner/action/action_type.py b/crossbench/action_runner/action/action_type.py
new file mode 100644
index 0000000..5e2dc48
--- /dev/null
+++ b/crossbench/action_runner/action/action_type.py
@@ -0,0 +1,32 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+
+from crossbench.config import ConfigEnum
+
+
+@enum.unique
+class ActionType(ConfigEnum):
+  GET = ("get", "Open a URL")
+  JS = ("js", "Run a custom script")
+  WAIT = ("wait", "Wait for a given time")
+  SCROLL = ("scroll", "Scroll on page")
+  CLICK = ("click", "Click on element or at specified coordinates")
+  SWIPE = ("swipe", "Swipe on screen")
+  TEXT_INPUT = ("text_input", "Type printable characters at a"
+                "specified speed.")
+  WAIT_FOR_ELEMENT = ("wait_for_element",
+                      "Wait until element appears on the page")
+  INJECT_NEW_DOCUMENT_SCRIPT = ("inject_new_document_script", (
+      "Evaluates given script in every frame upon creation "
+      "(before loading frame's scripts). "
+      "Only supported in chromium-based browsers."))
+  SCREENSHOT = ("screenshot", "Take a screenshot")
+  SWITCH_TAB = ("switch_tab", "Switch the tab that actions are sent to")
+  WAIT_FOR_READY_STATE = ("wait_for_ready_state",
+                          "Wait for a specific document.readyState")
+  DUMP_HTML = ("dump_html", "Dump the current document's HTML")
diff --git a/crossbench/action_runner/action/all.py b/crossbench/action_runner/action/all.py
new file mode 100644
index 0000000..7a143f6
--- /dev/null
+++ b/crossbench/action_runner/action/all.py
@@ -0,0 +1,45 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple, Type
+
+from crossbench.action_runner.action.action import ACTIONS, Action
+from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.dump_html import DumpHtmlAction
+from crossbench.action_runner.action.get import GetAction
+from crossbench.action_runner.action.inject_new_document_script import \
+    InjectNewDocumentScriptAction
+from crossbench.action_runner.action.js import JsAction
+from crossbench.action_runner.action.screenshot import ScreenshotAction
+from crossbench.action_runner.action.scroll import ScrollAction
+from crossbench.action_runner.action.swipe import SwipeAction
+from crossbench.action_runner.action.switch_tab import SwitchTabAction
+from crossbench.action_runner.action.text_input import TextInputAction
+from crossbench.action_runner.action.wait import WaitAction
+from crossbench.action_runner.action.wait_for_element import \
+    WaitForElementAction
+from crossbench.action_runner.action.wait_for_ready_state import \
+    WaitForReadyStateAction
+
+ACTIONS_TUPLE: Tuple[Type[Action], ...] = (
+    ClickAction,
+    DumpHtmlAction,
+    GetAction,
+    InjectNewDocumentScriptAction,
+    JsAction,
+    ScreenshotAction,
+    ScrollAction,
+    SwipeAction,
+    SwitchTabAction,
+    TextInputAction,
+    WaitAction,
+    WaitForElementAction,
+    WaitForReadyStateAction,
+)
+for action_cls in ACTIONS_TUPLE:
+  ACTIONS[action_cls.TYPE] = action_cls
+
+assert len(ACTIONS_TUPLE) == len(ACTIONS), "Non unique Action.TYPE present"
diff --git a/crossbench/action_runner/action/base_duration.py b/crossbench/action_runner/action/base_duration.py
new file mode 100644
index 0000000..89d9e16
--- /dev/null
+++ b/crossbench/action_runner/action/base_duration.py
@@ -0,0 +1,56 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Type
+
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
+                                                    ActionT)
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.parse import DurationParser
+
+if TYPE_CHECKING:
+  from crossbench.config import ConfigParser
+  from crossbench.types import JsonDict
+
+
+class BaseDurationAction(Action):
+
+  def __init__(self,
+               duration: dt.timedelta,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._duration: dt.timedelta = duration
+    super().__init__(timeout, index)
+
+  @property
+  def duration(self) -> dt.timedelta:
+    return self._duration
+
+  def validate(self) -> None:
+    super().validate()
+    self.validate_duration()
+
+  def validate_duration(self) -> None:
+    if self.duration.total_seconds() <= 0:
+      raise ValueError(
+          f"{self}.duration should be positive, but got {self.duration}")
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["duration"] = self.duration.total_seconds()
+    return details
+
+
+class DurationAction(BaseDurationAction):
+  TYPE: ActionType = ActionType.WAIT
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "duration", type=DurationParser.positive_duration, required=True)
+    return parser
diff --git a/crossbench/action_runner/action/base_input_source.py b/crossbench/action_runner/action/base_input_source.py
new file mode 100644
index 0000000..5636c70
--- /dev/null
+++ b/crossbench/action_runner/action/base_input_source.py
@@ -0,0 +1,57 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+from typing import TYPE_CHECKING, Tuple, Type
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.base_duration import BaseDurationAction
+from crossbench.benchmarks.loading.input_source import InputSource
+
+if TYPE_CHECKING:
+  from crossbench.config import ConfigParser
+  from crossbench.types import JsonDict
+
+
+class InputSourceAction(BaseDurationAction, metaclass=abc.ABCMeta):
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "source", type=InputSource.parse, default=InputSource.JS)
+    return parser
+
+  def __init__(self,
+               source: InputSource,
+               duration: dt.timedelta,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._input_source = source
+    super().__init__(duration, timeout, index)
+
+  @property
+  def input_source(self) -> InputSource:
+    return self._input_source
+
+  def validate(self) -> None:
+    super().validate()
+    self.validate_input_source()
+
+  def validate_input_source(self) -> None:
+    if self.input_source not in self.supported_input_sources():
+      raise ValueError(
+          f"Unsupported input source for {self.__class__.__name__}")
+
+  @abc.abstractmethod
+  def supported_input_sources(self) -> Tuple[InputSource, ...]:
+    pass
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["source"] = self.input_source
+    return details
diff --git a/crossbench/action_runner/action/click.py b/crossbench/action_runner/action/click.py
new file mode 100644
index 0000000..f23a3db
--- /dev/null
+++ b/crossbench/action_runner/action/click.py
@@ -0,0 +1,116 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Optional, Tuple, Type
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.base_input_source import InputSourceAction
+from crossbench.benchmarks.loading.input_source import InputSource
+from crossbench.benchmarks.loading.point import Point
+from crossbench.parse import DurationParser, NumberParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class ClickAction(InputSourceAction):
+  TYPE: ActionType = ActionType.CLICK
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument("selector", type=ObjectParser.non_empty_str)
+    parser.add_argument("required", type=ObjectParser.bool, default=False)
+    parser.add_argument(
+        "scroll_into_view", type=ObjectParser.bool, default=False)
+    parser.add_argument("x", type=NumberParser.positive_zero_int)
+    parser.add_argument("y", type=NumberParser.positive_zero_int)
+    parser.add_argument(
+        "duration",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta())
+    return parser
+
+  def __init__(self,
+               source: InputSource,
+               duration: dt.timedelta = dt.timedelta(),
+               selector: Optional[str] = None,
+               required: bool = False,
+               scroll_into_view: bool = False,
+               x: Optional[int] = None,
+               y: Optional[int] = None,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0):
+    # TODO: convert to custom selector object.
+    self._selector = selector
+    self._required: bool = required
+    self._scroll_into_view: bool = scroll_into_view
+    self._coordinates: Optional[Point] = None
+    if x is not None and y is not None:
+      self._coordinates = Point(x, y)
+    super().__init__(source, duration, timeout, index)
+
+  @property
+  def selector(self) -> Optional[str]:
+    return self._selector
+
+  @property
+  def required(self) -> bool:
+    return self._required
+
+  @property
+  def scroll_into_view(self) -> bool:
+    return self._scroll_into_view
+
+  @property
+  def coordinates(self) -> Optional[Point]:
+    return self._coordinates
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.click(run, self)
+
+  def validate(self) -> None:
+    super().validate()
+
+    if self._selector and self._coordinates:
+      raise ValueError("Only one is allowed: either selector or coordinates")
+
+    if not self._selector and not self._coordinates:
+      raise ValueError("Either selector or coordinates are required")
+
+    if self._input_source is InputSource.JS and self._coordinates:
+      raise ValueError("X,Y Coordinates cannot be used with JS click source.")
+
+    if self._required and self._coordinates:
+      raise ValueError("'required' is not compatible with coordinates")
+
+    if self._scroll_into_view and self._coordinates:
+      raise ValueError("'scroll_into_view' is not compatible with coordinates")
+
+  def validate_duration(self) -> None:
+    # A click action is allowed to have a zero duration.
+    return
+
+  def supported_input_sources(self) -> Tuple[InputSource, ...]:
+    return (InputSource.JS, InputSource.TOUCH, InputSource.MOUSE)
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+
+    if self._selector:
+      details["selector"] = self._selector
+      details["required"] = self._required
+      details["scroll_into_view"] = self._scroll_into_view
+    else:
+      assert self._coordinates
+      details["x"] = self._coordinates.x
+      details["y"] = self._coordinates.y
+    return details
diff --git a/crossbench/action_runner/action/dump_html.py b/crossbench/action_runner/action/dump_html.py
new file mode 100644
index 0000000..f1916e4
--- /dev/null
+++ b/crossbench/action_runner/action/dump_html.py
@@ -0,0 +1,21 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench.action_runner.action.action import Action
+from crossbench.action_runner.action.action_type import ActionType
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.runner.run import Run
+
+
+class DumpHtmlAction(Action):
+  TYPE: ActionType = ActionType.DUMP_HTML
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.dump_html(run, self)
diff --git a/crossbench/action_runner/action/enums.py b/crossbench/action_runner/action/enums.py
new file mode 100644
index 0000000..e376552
--- /dev/null
+++ b/crossbench/action_runner/action/enums.py
@@ -0,0 +1,48 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+
+from crossbench.config import ConfigEnum
+
+
+@enum.unique
+class ButtonClick(ConfigEnum):
+  LEFT = ("left", "Press left mouse button")
+  RIGHT = ("right", "Press right mouse button")
+  MIDDLE = ("middle", "Press middle mouse button")
+
+
+@enum.unique
+class ReadyState(ConfigEnum):
+  """See https://developer.mozilla.org/en-US/docs/Web/API/Document/readyState"""
+  # Non-blocking:
+  ANY = ("any", "Ignore ready state")
+  # Blocking (on dom event):
+  LOADING = ("loading", "The document is still loading.")
+  INTERACTIVE = ("interactive", "The document has finished loading "
+                 "but sub-resources might still be loading")
+  COMPLETE = ("complete",
+              "The document and all sub-resources have finished loading.")
+
+
+@enum.unique
+class WindowTarget(ConfigEnum):
+  """See https://developer.mozilla.org/en-US/docs/Web/API/Window/open"""
+  # TODO: pull this out to the browsers and use this enum instead of the strings
+  # in the browser show_url implementations.
+  SELF = ("_self", "The current browsing context. (Default)")
+  BLANK = ("_blank", "Usually a new tab, but users can configure browsers "
+           "to open a new window instead.")
+  PARENT = ("_parent", "The parent browsing context of the current one. "
+            "If no parent, behaves as _self.")
+  TOP = ("_top", "The topmost browsing context "
+         "(the 'highest' context that's an ancestor of the current one). "
+         "If no ancestors, behaves as _self.")
+  # The following options are Crossbench specific and are not understoon by the
+  # underlying call to window.open() in JS.
+  NEW_TAB = ("_new_tab", "A new tab.")
+  NEW_WINDOW = ("_new_window", "A new window.")
diff --git a/crossbench/action_runner/action/get.py b/crossbench/action_runner/action/get.py
new file mode 100644
index 0000000..409289e
--- /dev/null
+++ b/crossbench/action_runner/action/get.py
@@ -0,0 +1,91 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Type
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.base_duration import BaseDurationAction
+from crossbench.action_runner.action.enums import ReadyState, WindowTarget
+from crossbench.parse import DurationParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class GetAction(BaseDurationAction):
+  TYPE: ActionType = ActionType.GET
+
+  @classmethod
+  def parse_str(cls, value: str) -> GetAction:
+    return cls(url=ObjectParser.parse_fuzzy_url_str(value))
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "url", type=ObjectParser.parse_fuzzy_url_str, required=True)
+    parser.add_argument(
+        "duration",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta())
+    parser.add_argument(
+        "ready_state", type=ReadyState.parse, default=ReadyState.ANY)
+    parser.add_argument(
+        "target", type=WindowTarget.parse, default=WindowTarget.SELF)
+    return parser
+
+  def __init__(self,
+               url: str,
+               duration: dt.timedelta = dt.timedelta(),
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               ready_state: ReadyState = ReadyState.ANY,
+               target: WindowTarget = WindowTarget.SELF,
+               index: int = 0):
+    if not url:
+      raise ValueError(f"{self}.url is missing")
+    self._url: str = url
+    self._ready_state = ready_state
+    self._target = target
+    super().__init__(duration, timeout, index)
+
+  def validate_duration(self) -> None:
+    if self.ready_state != ReadyState.ANY:
+      if self.duration != dt.timedelta():
+        raise ValueError(
+            f"Expected empty duration with ReadyState {self.ready_state} "
+            f"but got: {self.duration}")
+      self._duration = dt.timedelta()
+
+  @property
+  def url(self) -> str:
+    return self._url
+
+  @property
+  def ready_state(self) -> ReadyState:
+    return self._ready_state
+
+  @property
+  def duration(self) -> dt.timedelta:
+    return self._duration
+
+  @property
+  def target(self) -> WindowTarget:
+    return self._target
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.get(run, self)
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["url"] = self.url
+    details["ready_state"] = str(self.ready_state)
+    details["target"] = str(self.target)
+    return details
diff --git a/crossbench/action_runner/action/inject_new_document_script.py b/crossbench/action_runner/action/inject_new_document_script.py
new file mode 100644
index 0000000..d9ec008
--- /dev/null
+++ b/crossbench/action_runner/action/inject_new_document_script.py
@@ -0,0 +1,21 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.js import JsAction
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.runner.run import Run
+
+
+class InjectNewDocumentScriptAction(JsAction):
+  TYPE: ActionType = ActionType.INJECT_NEW_DOCUMENT_SCRIPT
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.inject_new_document_script(run, self)
diff --git a/crossbench/action_runner/action/js.py b/crossbench/action_runner/action/js.py
new file mode 100644
index 0000000..9bfbbde
--- /dev/null
+++ b/crossbench/action_runner/action/js.py
@@ -0,0 +1,94 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+from typing import TYPE_CHECKING, Any, Dict, Optional, Type
+
+from crossbench import exception
+from crossbench import path as pth
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
+                                                    ActionT)
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.parse import ObjectParser, PathParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+def parse_replacement_dict(value: Any) -> Dict[str, str]:
+  dict_value = ObjectParser.dict(value)
+  for replace_key, replace_value in dict_value.items():
+    with exception.annotate_argparsing(
+        f"Parsing ...[{repr(replace_key)}] = {repr(value)}"):
+      ObjectParser.non_empty_str(replace_key, "replacement key")
+      ObjectParser.any_str(replace_value, "replacement value")
+  return dict_value
+
+
+class JsAction(Action):
+  TYPE: ActionType = ActionType.JS
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument("script", type=ObjectParser.non_empty_str)
+    parser.add_argument(
+        "script_path", aliases=("path",), type=PathParser.existing_file_path)
+    parser.add_argument(
+        "replacements", aliases=("replace",), type=parse_replacement_dict)
+    return parser
+
+  def __init__(self,
+               script: Optional[str],
+               script_path: Optional[pth.LocalPath],
+               replacements: Optional[Dict[str, str]] = None,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._original_script = script
+    self._script_path = script_path
+    self._script = ""
+    if bool(script) == bool(script_path):
+      raise ValueError(
+          f"One of {self}.script or {self}.script_path, but not both, "
+          "have to specified. ")
+    if script:
+      self._script = script
+    elif script_path:
+      self._script = script_path.read_text()
+      logging.debug("Loading script from %s: %s", script_path, script)
+      # TODO: Support argument injection into shared file script.
+    self._replacements = replacements
+    if replacements:
+      for key, value in replacements.items():
+        self._script = self._script.replace(key, value)
+    super().__init__(timeout, index)
+
+  @property
+  def script(self) -> str:
+    return self._script
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.js(run, self)
+
+  def validate(self) -> None:
+    super().validate()
+    if not self.script:
+      raise ValueError(
+          f"{self}.script is missing or the provided script file is empty.")
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    if self._original_script:
+      details["script"] = self._original_script
+    if self._script_path:
+      details["script_path"] = str(self._script_path)
+    if self._replacements:
+      details["replacements"] = self._replacements
+    return details
diff --git a/crossbench/action_runner/action/screenshot.py b/crossbench/action_runner/action/screenshot.py
new file mode 100644
index 0000000..ffa4757
--- /dev/null
+++ b/crossbench/action_runner/action/screenshot.py
@@ -0,0 +1,21 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench.action_runner.action.action import Action
+from crossbench.action_runner.action.action_type import ActionType
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.runner.run import Run
+
+
+class ScreenshotAction(Action):
+  TYPE: ActionType = ActionType.SCREENSHOT
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.screenshot(run, self)
diff --git a/crossbench/action_runner/action/scroll.py b/crossbench/action_runner/action/scroll.py
new file mode 100644
index 0000000..60ba47e
--- /dev/null
+++ b/crossbench/action_runner/action/scroll.py
@@ -0,0 +1,83 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Optional, Tuple, Type
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.base_input_source import InputSourceAction
+from crossbench.benchmarks.loading.input_source import InputSource
+from crossbench.parse import DurationParser, NumberParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class ScrollAction(InputSourceAction):
+  TYPE: ActionType = ActionType.SCROLL
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument("distance", type=NumberParser.any_float, default=500)
+    parser.add_argument(
+        "duration",
+        type=DurationParser.positive_duration,
+        default=dt.timedelta(seconds=1))
+    parser.add_argument("selector", type=ObjectParser.non_empty_str)
+    parser.add_argument("required", type=ObjectParser.bool, default=False)
+    return parser
+
+  def __init__(self,
+               source: InputSource,
+               distance: float = 500.0,
+               duration: dt.timedelta = dt.timedelta(seconds=1),
+               selector: Optional[str] = None,
+               required: bool = False,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._distance = distance
+
+    # TODO: convert to custom selector object.
+    self._selector = selector
+    self._required = required
+    super().__init__(source, duration, timeout, index)
+
+  @property
+  def distance(self) -> float:
+    return self._distance
+
+  @property
+  def selector(self) -> Optional[str]:
+    return self._selector
+
+  @property
+  def required(self) -> bool:
+    return self._required
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.scroll(run, self)
+
+  def validate(self) -> None:
+    super().validate()
+    if not self.distance:
+      raise ValueError(f"{self}.distance is not provided")
+
+    if self.required and not self.selector:
+      raise ValueError(
+          "'required' can only be used when a selector is specified")
+
+  def supported_input_sources(self) -> Tuple[InputSource, ...]:
+    return (InputSource.JS, InputSource.TOUCH)
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["distance"] = str(self.distance)
+    return details
diff --git a/crossbench/action_runner/action/swipe.py b/crossbench/action_runner/action/swipe.py
new file mode 100644
index 0000000..80cf110
--- /dev/null
+++ b/crossbench/action_runner/action/swipe.py
@@ -0,0 +1,83 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Type
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.base_duration import DurationAction
+from crossbench.parse import NumberParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class SwipeAction(DurationAction):
+  TYPE: ActionType = ActionType.SWIPE
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "start_x",
+        aliases=("startx",),
+        type=NumberParser.any_int,
+        required=True)
+    parser.add_argument(
+        "start_y",
+        aliases=("starty",),
+        type=NumberParser.any_int,
+        required=True)
+    parser.add_argument(
+        "end_x", aliases=("endx",), type=NumberParser.any_int, required=True)
+    parser.add_argument(
+        "end_y", aliases=("endy",), type=NumberParser.any_int, required=True)
+    return parser
+
+  def __init__(self,
+               start_x: int,
+               start_y: int,
+               end_x: int,
+               end_y: int,
+               duration: dt.timedelta = dt.timedelta(seconds=1),
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._start_x: int = start_x
+    self._start_y: int = start_y
+    self._end_x: int = end_x
+    self._end_y: int = end_y
+    super().__init__(duration, timeout, index)
+
+  @property
+  def start_x(self) -> int:
+    return self._start_x
+
+  @property
+  def start_y(self) -> int:
+    return self._start_y
+
+  @property
+  def end_x(self) -> int:
+    return self._end_x
+
+  @property
+  def end_y(self) -> int:
+    return self._end_y
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.swipe(run, self)
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["start_x"] = self._start_x
+    details["start_y"] = self._start_y
+    details["end_x"] = self._end_x
+    details["end_y"] = self._end_y
+    return details
diff --git a/crossbench/action_runner/action/switch_tab.py b/crossbench/action_runner/action/switch_tab.py
new file mode 100644
index 0000000..cf4dbfe
--- /dev/null
+++ b/crossbench/action_runner/action/switch_tab.py
@@ -0,0 +1,74 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import re
+from typing import TYPE_CHECKING, Optional, Type
+
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
+                                                    ActionT)
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.parse import NumberParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class SwitchTabAction(Action):
+  TYPE: ActionType = ActionType.SWITCH_TAB
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "tab_index",
+        type=NumberParser.any_int,
+        help=(
+            "The index of the tab to switch to. Tabs are indexed in creation "
+            "order. Negative values are allowed, e.g. -1 is the most recently "
+            "opened tab."))
+    parser.add_argument("title", type=ObjectParser.regexp)
+    parser.add_argument("url", type=ObjectParser.regexp)
+    return parser
+
+  def __init__(self,
+               tab_index: Optional[int] = None,
+               title: Optional[re.Pattern] = None,
+               url: Optional[re.Pattern] = None,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._title = title
+    self._url = url
+    self._tab_index = tab_index
+    super().__init__(timeout, index)
+
+  @property
+  def title(self) -> Optional[re.Pattern]:
+    return self._title
+
+  @property
+  def url(self) -> Optional[re.Pattern]:
+    return self._url
+
+  @property
+  def tab_index(self) -> Optional[int]:
+    return self._tab_index
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.switch_tab(run, self)
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    if self._tab_index:
+      details["tab_index"] = self._tab_index
+    if self._title:
+      details["title"] = str(self._title.pattern)
+    if self._url:
+      details["url"] = str(self._url.pattern)
+    return details
diff --git a/crossbench/action_runner/action/text_input.py b/crossbench/action_runner/action/text_input.py
new file mode 100644
index 0000000..9b013b7
--- /dev/null
+++ b/crossbench/action_runner/action/text_input.py
@@ -0,0 +1,67 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Tuple, Type
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.base_input_source import InputSourceAction
+from crossbench.benchmarks.loading.input_source import InputSource
+from crossbench.parse import DurationParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class TextInputAction(InputSourceAction):
+  TYPE: ActionType = ActionType.TEXT_INPUT
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument("text", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "duration",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta())
+    return parser
+
+  def __init__(self,
+               source: InputSource,
+               duration: dt.timedelta,
+               text: str,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._text: str = text
+    super().__init__(source, duration, timeout, index)
+
+  @property
+  def text(self) -> str:
+    return self._text
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.text_input(run, self)
+
+  def validate(self) -> None:
+    super().validate()
+    if not self._text:
+      raise ValueError(f"{self}.text is missing.")
+
+  def validate_duration(self) -> None:
+    # A text input action is allowed to have a zero duration.
+    return
+
+  def supported_input_sources(self) -> Tuple[InputSource, ...]:
+    return (InputSource.JS, InputSource.KEYBOARD)
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["text"] = self._text
+    return details
diff --git a/crossbench/action_runner/action/wait.py b/crossbench/action_runner/action/wait.py
new file mode 100644
index 0000000..af7c5f5
--- /dev/null
+++ b/crossbench/action_runner/action/wait.py
@@ -0,0 +1,21 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.base_duration import DurationAction
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.runner.run import Run
+
+
+class WaitAction(DurationAction):
+  TYPE: ActionType = ActionType.WAIT
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.wait(run, self)
diff --git a/crossbench/action_runner/action/wait_for_element.py b/crossbench/action_runner/action/wait_for_element.py
new file mode 100644
index 0000000..a50ede4
--- /dev/null
+++ b/crossbench/action_runner/action/wait_for_element.py
@@ -0,0 +1,54 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Type
+
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
+                                                    ActionT)
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.parse import ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class WaitForElementAction(Action):
+  TYPE: ActionType = ActionType.WAIT_FOR_ELEMENT
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "selector", type=ObjectParser.non_empty_str, required=True)
+    return parser
+
+  def __init__(self,
+               selector: str,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0):
+    self._selector = selector
+    super().__init__(timeout, index)
+
+  @property
+  def selector(self) -> str:
+    return self._selector
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.wait_for_element(run, self)
+
+  def validate(self) -> None:
+    super().validate()
+    if not self.selector:
+      raise ValueError(f"{self}.selector is missing.")
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["selector"] = self.selector
+    return details
diff --git a/crossbench/action_runner/action/wait_for_ready_state.py b/crossbench/action_runner/action/wait_for_ready_state.py
new file mode 100644
index 0000000..c5e00a9
--- /dev/null
+++ b/crossbench/action_runner/action/wait_for_ready_state.py
@@ -0,0 +1,49 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Type
+
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
+                                                    ActionT)
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.enums import ReadyState
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class WaitForReadyStateAction(Action):
+  TYPE: ActionType = ActionType.WAIT_FOR_READY_STATE
+
+  @classmethod
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "ready_state", type=ReadyState.parse, default=ReadyState.COMPLETE)
+    return parser
+
+  def __init__(self,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               ready_state: ReadyState = ReadyState.COMPLETE,
+               index: int = 0):
+    self._ready_state = ready_state
+    super().__init__(timeout, index)
+
+  @property
+  def ready_state(self) -> ReadyState:
+    return self._ready_state
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.wait_for_ready_state(run, self)
+
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    details["ready_state"] = str(self.ready_state)
+    return details
diff --git a/crossbench/action_runner/action_runner_listener.py b/crossbench/action_runner/action_runner_listener.py
new file mode 100644
index 0000000..d208d4a
--- /dev/null
+++ b/crossbench/action_runner/action_runner_listener.py
@@ -0,0 +1,23 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+
+
+class ActionRunnerListener:
+  """Default empty ActionRunnerListener implementation."""
+
+  def handle_error(self, run: Run, e: Exception) -> None:
+    pass
+
+  def handle_page_run(self, run: Run) -> None:
+    pass
+
+  def handle_new_tab(self, run: Run) -> None:
+    pass
diff --git a/crossbench/action_runner/android_input_action_runner.py b/crossbench/action_runner/android_input_action_runner.py
new file mode 100644
index 0000000..40402e4
--- /dev/null
+++ b/crossbench/action_runner/android_input_action_runner.py
@@ -0,0 +1,302 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+import re
+from typing import List, Optional
+
+from crossbench.action_runner.action import all as i_action
+from crossbench.action_runner.base import InputSourceNotImplementedError
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.display_rectangle import DisplayRectangle
+from crossbench.action_runner.element_not_found_error import \
+    ElementNotFoundError
+from crossbench.benchmarks.loading.point import Point
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.runner.actions import Actions
+from crossbench.runner.run import Run
+
+
+class ViewportInfo:
+
+  def __init__(self,
+               raw_chrome_window_bounds: DisplayRectangle,
+               window_inner_height: int,
+               window_inner_width: int,
+               element_rect: Optional[DisplayRectangle] = None) -> None:
+    self._element_rect: Optional[DisplayRectangle] = None
+
+    # On android, clank does not report the correct window.devicePixelRatio
+    # when a page is zoomed.
+    # Zoom can happen automatically on load with pages that force a certain
+    # viewport width (such as speedometer), so calculate the ratio manually.
+    # Note: this calculation assumes there are no system borders on the side of
+    # the chrome window.
+    self._actual_pixel_ratio: float = float(raw_chrome_window_bounds.width /
+                                            window_inner_width)
+
+    window_inner_height = int(
+        round(self.actual_pixel_ratio * window_inner_height))
+    window_inner_width = int(
+        round(self.actual_pixel_ratio * window_inner_width))
+
+    # On Android there may be a system added border from the top of the app view
+    # that is included in the mAppBounds rectangle dimensions. Calculate the
+    # height of this border using the difference between the height reported by
+    # chrome and the height reported by android.
+    top_border_height = raw_chrome_window_bounds.height - window_inner_height
+
+    self._chrome_window: DisplayRectangle = DisplayRectangle(
+        Point(raw_chrome_window_bounds.origin.x,
+              raw_chrome_window_bounds.origin.y + top_border_height),
+        raw_chrome_window_bounds.width,
+        raw_chrome_window_bounds.height - top_border_height)
+
+    if element_rect:
+      self._element_rect = (element_rect * self.actual_pixel_ratio).shift_by(
+          self._chrome_window)
+
+  @property
+  def chrome_window(self) -> DisplayRectangle:
+    return self._chrome_window
+
+  @property
+  def actual_pixel_ratio(self) -> float:
+    return self._actual_pixel_ratio
+
+  def element_rect(self) -> Optional[DisplayRectangle]:
+    return self._element_rect
+
+  def element_center(self) -> Optional[Point]:
+    if not self._element_rect:
+      return None
+    return self._element_rect.middle
+
+  def css_to_native_distance(self, distance: float) -> float:
+    return distance * self.actual_pixel_ratio
+
+
+class AndroidInputActionRunner(BasicActionRunner):
+
+  # Represents the position of the chrome main window relative to the entire
+  # screen as reported by Android window manager.
+  _raw_chrome_window_bounds: Optional[DisplayRectangle] = None
+
+  @property
+  def raw_chrome_window_bounds(self) -> DisplayRectangle:
+    assert self._raw_chrome_window_bounds, "Uninitialized chrome window bounds"
+    return self._raw_chrome_window_bounds
+
+  _BOUNDS_RE = re.compile(
+      r"mAppBounds=Rect\((?P<left>\d+), (?P<top>\d+) - (?P<right>\d+),"
+      r" (?P<bottom>\d+)\)")
+
+  _GET_JS_VALUES = """
+const found_element = arguments[0] && element;
+if(found_element && arguments[1]) element.scrollIntoView();
+rect = found_element ? element.getBoundingClientRect() : new DOMRect();
+return [
+  found_element,
+  window.innerHeight,
+  window.innerWidth,
+  rect.left,
+  rect.top,
+  rect.width,
+  rect.height
+];"""
+
+  def scroll_touch(self, run: Run, action: i_action.ScrollAction) -> None:
+    with run.actions("ScrollAction", measure=False) as actions:
+
+      viewport_info = self._get_viewport_info(run, actions, action.selector)
+
+      # The scroll distance is specified in terms of css pixels so adjust to the
+      # native pixel density.
+      total_scroll_distance = (
+          viewport_info.css_to_native_distance(action.distance))
+
+      # Default to scrolling within the entire chrome window.
+      scroll_area: DisplayRectangle = viewport_info.chrome_window
+
+      if action.selector:
+        if element_rect := viewport_info.element_rect():
+          scroll_area = element_rect
+        else:
+          if action.required:
+            raise ElementNotFoundError(action.selector)
+          return
+
+      scrollable_top = scroll_area.top
+      scrollable_bottom = scroll_area.bottom
+
+      max_swipe_distance = scrollable_bottom - scrollable_top
+
+      remaining_distance = abs(total_scroll_distance)
+
+      while remaining_distance > 0:
+
+        current_distance = min(max_swipe_distance, remaining_distance)
+
+        # The duration for this swipe should be only a fraction of the total
+        # duration since the entire distance may not be covered in one swipe.
+        current_duration = (current_distance /
+                            abs(total_scroll_distance)) * action.duration
+
+        # If scrolling down, the swipe should start at the bottom and end above.
+        y_start = scrollable_bottom
+        y_end = scrollable_bottom - current_distance
+
+        # If scrolling up, the swipe should start at the top and end below.
+        if total_scroll_distance < 0:
+          y_start = scrollable_top
+          y_end = scrollable_top + current_distance
+
+        self._swipe_impl(run, round(scroll_area.mid_x), round(y_start),
+                         round(scroll_area.mid_x), round(y_end),
+                         current_duration)
+
+        remaining_distance -= current_distance
+
+  def click_touch(self, run: Run, action: i_action.ClickAction) -> None:
+    self._click_impl(run, action, False)
+
+  def click_mouse(self, run: Run, action: i_action.ClickAction) -> None:
+    self._click_impl(run, action, True)
+
+  def swipe(self, run: Run, action: i_action.SwipeAction) -> None:
+    with run.actions("SwipeAction", measure=False):
+      self._swipe_impl(run, action.start_x, action.start_y, action.end_x,
+                       action.end_y, action.duration)
+
+  def text_input_keyboard(self, run: Run,
+                          action: i_action.TextInputAction) -> None:
+    self._rate_limit_keystrokes(run, action, self._type_characters)
+
+  def _click_impl(self, run: Run, action: i_action.ClickAction,
+                  use_mouse: bool) -> None:
+    if action.duration > dt.timedelta():
+      raise InputSourceNotImplementedError(self, action, action.input_source,
+                                           "Non-zero duration not implemented")
+
+    with run.actions("ClickAction", measure=False) as actions:
+
+      coordinates = action.coordinates
+
+      if action.selector:
+        viewport_info = self._get_viewport_info(run, actions, action.selector,
+                                                action.scroll_into_view)
+
+        rect = viewport_info.element_rect()
+        if not rect:
+          logging.warning("No clickable element_rect found for %s",
+                          action.selector)
+          if action.required:
+            raise ElementNotFoundError(action.selector)
+          return
+
+        coordinates = Point(rect.mid_x, rect.mid_y)
+
+      cmd: List[str] = ["input"]
+
+      if use_mouse:
+        cmd.append("mouse")
+
+      cmd.extend(["tap", str(coordinates.x), str(coordinates.y)])
+
+      run.browser_platform.sh(*cmd)
+
+  def _swipe_impl(self, run: Run, start_x: int, start_y: int, end_x: int,
+                  end_y: int, duration: dt.timedelta) -> None:
+
+    duration_millis = round(duration // dt.timedelta(milliseconds=1))
+
+    run.browser_platform.sh("input", "swipe", str(start_x), str(start_y),
+                            str(end_x), str(end_y), str(duration_millis))
+
+  def _get_viewport_info(self,
+                         run: Run,
+                         actions: Actions,
+                         selector: Optional[str] = None,
+                         scroll_into_view: bool = False) -> ViewportInfo:
+
+    script = ""
+
+    if selector:
+      selector, script = self.get_selector_script(selector)
+
+    script += self._GET_JS_VALUES
+
+    (found_element, inner_height, inner_width, left, top, width,
+     height) = actions.js(
+         script, arguments=[selector, scroll_into_view])
+
+    # If the chrome window position has not yet been found,
+    # initialize it now.
+    # Note: this assumes the chrome app will not be moved or resized during
+    # the test.
+    if not self._raw_chrome_window_bounds:
+      self._raw_chrome_window_bounds = self._find_chrome_window_size(run)
+
+    element_rect: Optional[DisplayRectangle] = None
+    if found_element:
+      element_rect = DisplayRectangle(Point(left, top), width, height)
+
+    return ViewportInfo(self.raw_chrome_window_bounds, inner_height,
+                        inner_width, element_rect)
+
+
+  # Returns the name of the browser's main window as reported by android's
+  # window manager.
+  def _get_browser_window_name(self,
+                               browser_attributes: BrowserAttributes) -> str:
+    if browser_attributes.is_chrome:
+      return "chrome.Main"
+
+    raise RuntimeError("Unsupported browser for android action runner.")
+
+  def _find_chrome_window_size(self, run: Run) -> DisplayRectangle:
+    # Find the chrome app window position by dumping the android app window
+    # list.
+    #
+    # Chrome's main view is always called 'chrome.Main' and is followed by the
+    # configuration for that window.
+    #
+    # The mAppBounds config of the chrome.Main window contains the dimensions
+    # for the visible part of the current chrome window formatted like this for
+    # a 800 height by 480 width window:
+    #
+    # mAppBounds=Rect(0, 0 - 480, 800)
+    browser_main_window_name = self._get_browser_window_name(
+        run.browser.attributes)
+
+    raw_window_config = run.browser_platform.sh_stdout(
+        "dumpsys",
+        "window",
+        "windows",
+        "|",
+        "grep",
+        "-E",
+        "-A100",
+        browser_main_window_name,
+    )
+    match = self._BOUNDS_RE.search(raw_window_config)
+    if not match:
+      raise RuntimeError("Could not find chrome window bounds")
+
+    width = int(match["right"]) - int(match["left"])
+    height = int(match["bottom"]) - int(match["top"])
+
+    return DisplayRectangle(
+        Point(int(match["left"]), int(match["top"])), width, height)
+
+  def _type_characters(self, run: Run, _: Actions, characters: str) -> None:
+    # TODO(kalutes) handle special characters and other whitespaces like '\t'
+
+    # The 'input text' command cannot handle spaces directly. Replace space
+    # characters with the encoding '%s'.
+    characters = characters.replace(" ", "%s")
+    run.browser_platform.sh("input", "keyboard", "text", characters)
diff --git a/crossbench/action_runner/base.py b/crossbench/action_runner/base.py
new file mode 100644
index 0000000..0c58708
--- /dev/null
+++ b/crossbench/action_runner/base.py
@@ -0,0 +1,256 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Iterable, Optional
+
+from crossbench import exception
+from crossbench.action_runner.action_runner_listener import \
+    ActionRunnerListener
+from crossbench.benchmarks.loading.input_source import InputSource
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.action import all as i_action
+  from crossbench.benchmarks.loading.config.pages import ActionBlock
+  from crossbench.benchmarks.loading.page.base import Page
+  from crossbench.benchmarks.loading.page.combined import CombinedPage
+  from crossbench.benchmarks.loading.page.interactive import InteractivePage
+  from crossbench.benchmarks.loading.tab_controller import TabController
+  from crossbench.path import LocalPath
+  from crossbench.runner.run import Run
+
+
+class ActionNotImplementedError(NotImplementedError):
+
+  def __init__(self,
+               runner: ActionRunner,
+               action: i_action.Action,
+               msg_context: str = "") -> None:
+    self.runner = runner
+    self.action = action
+
+    if msg_context:
+      msg_context = ". Context: " + msg_context
+
+    message = (f"{str(action.TYPE).capitalize()}-action "
+               f"not implemented in {type(runner).__name__}{msg_context}")
+    super().__init__(message)
+
+
+class InputSourceNotImplementedError(ActionNotImplementedError):
+
+  def __init__(self,
+               runner: ActionRunner,
+               action: i_action.Action,
+               input_source: InputSource,
+               msg_context: str = "") -> None:
+
+    if msg_context:
+      msg_context = ". Context: " + msg_context
+
+    input_source_message = (f"Source: '{input_source}'"
+                            f"not implemented{msg_context}")
+
+    super().__init__(runner, action, input_source_message)
+
+
+class ActionRunner:
+
+  def __init__(self):
+    self._listener = ActionRunnerListener()
+
+  def set_listener(self, listener):
+    self._listener = listener
+
+  # TODO: Don't share state across runs
+  _info_stack: Optional[exception.TInfoStack]
+
+  # info_stack is a unique identifier for the currently running or most recently
+  # run action.
+  @property
+  def info_stack(self) -> exception.TInfoStack:
+    if not self._info_stack:
+      raise RuntimeError("info_stack can not be called before run_blocks")
+    return self._info_stack
+
+  def run_blocks(self, run: Run, page: InteractivePage,
+                 blocks: Iterable[ActionBlock]) -> None:
+    for block in blocks:
+      block.run_with(self, run, page)
+
+  def run_block(self, run, block: ActionBlock) -> None:
+    block_index = block.index
+    # TODO: Instead maybe just pass context down.
+    # Or pass unique path to every action __init__
+    with exception.annotate(f"Running block {block_index}: {block.label}"):
+      for action_index, action in enumerate(block, start=1):
+        self._info_stack = (f"block_{block_index}", f"action_{action_index}")
+        action.run_with(run, self)
+
+  def wait(self, run: Run, action: i_action.WaitAction) -> None:
+    with run.actions("WaitAction", measure=False) as actions:
+      actions.wait(action.duration)
+
+  def js(self, run: Run, action: i_action.JsAction) -> None:
+    with run.actions("JS", measure=False) as actions:
+      actions.js(action.script, action.timeout)
+
+  def click(self, run: Run, action: i_action.ClickAction) -> None:
+    input_source = action.input_source
+    if input_source is InputSource.JS:
+      self.click_js(run, action)
+    elif input_source is InputSource.TOUCH:
+      self.click_touch(run, action)
+    elif input_source is InputSource.MOUSE:
+      self.click_mouse(run, action)
+    else:
+      raise RuntimeError(f"Unsupported input source: '{input_source}'")
+
+  def scroll(self, run: Run, action: i_action.ScrollAction) -> None:
+    input_source = action.input_source
+    if input_source is InputSource.JS:
+      self.scroll_js(run, action)
+    elif input_source is InputSource.TOUCH:
+      self.scroll_touch(run, action)
+    elif input_source is InputSource.MOUSE:
+      self.scroll_mouse(run, action)
+    else:
+      raise RuntimeError(f"Unsupported input source: '{input_source}'")
+
+  def get(self, run: Run, action: i_action.GetAction) -> None:
+    raise ActionNotImplementedError(self, action)
+
+  def text_input(self, run: Run, action: i_action.TextInputAction) -> None:
+    input_source = action.input_source
+    if input_source is InputSource.JS:
+      self.text_input_js(run, action)
+    elif input_source is InputSource.KEYBOARD:
+      self.text_input_keyboard(run, action)
+    else:
+      raise RuntimeError(f"Unsupported input source: '{input_source}'")
+
+  def click_js(self, run: Run, action: i_action.ClickAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def click_touch(self, run: Run, action: i_action.ClickAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def click_mouse(self, run: Run, action: i_action.ClickAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def scroll_js(self, run: Run, action: i_action.ScrollAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def scroll_touch(self, run: Run, action: i_action.ScrollAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def scroll_mouse(self, run: Run, action: i_action.ScrollAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def text_input_js(self, run: Run, action: i_action.TextInputAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def text_input_keyboard(self, run: Run,
+                          action: i_action.TextInputAction) -> None:
+    raise InputSourceNotImplementedError(self, action, action.input_source)
+
+  def swipe(self, run: Run, action: i_action.SwipeAction) -> None:
+    raise ActionNotImplementedError(self, action)
+
+  def wait_for_element(self, run: Run,
+                       action: i_action.WaitForElementAction) -> None:
+    raise ActionNotImplementedError(self, action)
+
+  def wait_for_ready_state(self, run: Run,
+                           action: i_action.WaitForReadyStateAction) -> None:
+    raise ActionNotImplementedError(self, action)
+
+  def inject_new_document_script(
+      self, run: Run, action: i_action.InjectNewDocumentScriptAction) -> None:
+    raise ActionNotImplementedError(self, action)
+
+  def screenshot_impl(self, run: Run, suffix: str) -> None:
+    del run, suffix
+    raise NotImplementedError("screenshot_impl not implemented")
+
+  def screenshot(self, run: Run, action: i_action.ScreenshotAction) -> None:
+    del action
+    with run.actions("Screenshot", measure=False):
+      self.screenshot_impl(run, "screenshot")
+
+  def dump_html_impl(self, run: Run, suffix: str) -> None:
+    del run, suffix
+    raise NotImplementedError("dump_html_impl not implemented")
+
+  def dump_html(self, run: Run, action: i_action.DumpHtmlAction) -> None:
+    del action
+    with run.actions("Dump HTML", measure=False):
+      self.dump_html_impl(run, "dump")
+
+  def _maybe_navigate_to_about_blank(self, run: Run, page: Page) -> None:
+    if duration := page.about_blank_duration:
+      run.browser.show_url("about:blank")
+      run.runner.wait(duration)
+
+  def run_page_multiple_tabs(self, run: Run, tabs: TabController,
+                             pages: Iterable[Page]):
+    # TODO: refactor possible logics to TabController.
+    browser = run.browser
+    for _ in tabs:
+      try:
+        for i, page in enumerate(pages):
+          # Create a new tab for the multiple_tab case.
+          if i > 0:
+            browser.switch_to_new_tab()
+            self._listener.handle_new_tab(run)
+          page.run_with(run, self, False)
+          self._listener.handle_page_run(run)
+        browser.switch_to_new_tab()
+        self._listener.handle_new_tab(run)
+      except Exception as e:
+        self._listener.handle_error(run, e)
+        raise
+
+  def run_combined_page(self, run: Run, page: CombinedPage,
+                        multiple_tabs: bool):
+    if multiple_tabs:
+      self.run_page_multiple_tabs(run, page.tabs, page.pages)
+    else:
+      for sub_page in page.pages:
+        sub_page.run_with(run, self, False)
+
+  def run_interactive_page_once(self, run: Run, page: InteractivePage):
+    try:
+      self.run_blocks(run, page, page.blocks)
+      self._maybe_navigate_to_about_blank(run, page)
+    except Exception:
+      page.create_failure_artifacts(run)
+      raise
+
+  def run_interactive_page(self, run: Run, page: InteractivePage,
+                           multiple_tabs: bool):
+    if multiple_tabs:
+      self.run_page_multiple_tabs(run, page.tabs, [page])
+    else:
+      self.run_interactive_page_once(run, page)
+
+  def run_setup(self, run: Run, page: InteractivePage, setup: ActionBlock):
+    try:
+      with exception.annotate("setup"):
+        setup.run_with(self, run, page)
+    except Exception:
+      page.create_failure_artifacts(run, "setup-failure")
+      raise
+
+  def run_login(self, run: Run, page: InteractivePage, login: ActionBlock):
+    try:
+      with exception.annotate("login"):
+        login.run_with(self, run, page)
+    except Exception:
+      page.create_failure_artifacts(run, "login-failure")
+      raise
+
+  def switch_tab(self, run: Run, action: i_action.SwitchTabAction):
+    raise ActionNotImplementedError(self, action)
diff --git a/crossbench/action_runner/basic_action_runner.py b/crossbench/action_runner/basic_action_runner.py
new file mode 100644
index 0000000..225a353
--- /dev/null
+++ b/crossbench/action_runner/basic_action_runner.py
@@ -0,0 +1,265 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+import time
+from typing import TYPE_CHECKING, Callable, Tuple
+
+from crossbench.action_runner.action import all as i_action
+from crossbench.action_runner.action.enums import ReadyState
+from crossbench.action_runner.base import (ActionRunner,
+                                           InputSourceNotImplementedError)
+from crossbench.action_runner.element_not_found_error import \
+    ElementNotFoundError
+from crossbench.probes.dump_html import DumpHtmlProbe, DumpHtmlProbeContext
+from crossbench.probes.screenshot import ScreenshotProbe, ScreenshotProbeContext
+
+if TYPE_CHECKING:
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.run import Run
+
+
+class BasicActionRunner(ActionRunner):
+  XPATH_SELECT_ELEMENT = """
+      let element = document.evaluate(arguments[0], document).iterateNext();
+  """
+
+  CSS_SELECT_ELEMENT = """
+      let element = document.querySelector(arguments[0]);
+  """
+
+  CHECK_ELEMENT_EXISTS = """
+      if (!element) return false;
+  """
+
+  ELEMENT_SCROLL_INTO_VIEW = """
+      element.scrollIntoView();
+  """
+
+  ELEMENT_CLICK = """
+      element.click();
+  """
+
+  RETURN_SUCCESS = """
+      return true;
+  """
+
+  SELECT_WINDOW = """
+      let element = window;
+  """
+
+  SCROLL_ELEMENT_TO = """
+      element.scrollTo({top:arguments[1], behavior:'smooth'});
+  """
+
+  GET_CURRENT_SCROLL_POSITION = """
+      if (!element) return [false, 0];
+      return [true, element[arguments[1]]];
+  """
+
+  def get_selector_script(self,
+                          selector: str,
+                          check_element_exists=False,
+                          scroll_into_view=False,
+                          click=False,
+                          return_on_success=False) -> Tuple[str, str]:
+    # TODO: support more selector types
+
+    script: str = ""
+
+    prefix = "xpath/"
+    if selector.startswith(prefix):
+      selector = selector[len(prefix):]
+      script = self.XPATH_SELECT_ELEMENT
+    else:
+      script = self.CSS_SELECT_ELEMENT
+
+    if check_element_exists:
+      script += self.CHECK_ELEMENT_EXISTS
+
+    if scroll_into_view:
+      script += self.ELEMENT_SCROLL_INTO_VIEW
+
+    if click:
+      script += self.ELEMENT_CLICK
+
+    if return_on_success:
+      script += self.RETURN_SUCCESS
+
+    return selector, script
+
+  def _wait_for_ready_state(self, actions: Actions, ready_state: ReadyState,
+                            timeout: dt.timedelta) -> None:
+    # Make sure we also finish if readyState jumps directly
+    # from "loading" to "complete"
+    actions.wait_js_condition(
+        f"""
+          let state = document.readyState;
+          return state === '{ready_state}' || state === "complete";
+        """, 0.2, timeout.total_seconds())
+
+  def get(self, run: Run, action: i_action.GetAction) -> None:
+    # TODO: potentially refactor the timing and logging out to the base class.
+    start_time = time.time()
+    expected_end_time = start_time + action.duration.total_seconds()
+
+    with run.actions(f"Get {action.url}", measure=False) as actions:
+      actions.show_url(action.url, str(action.target))
+
+      if action.ready_state != ReadyState.ANY:
+        self._wait_for_ready_state(actions, action.ready_state, action.timeout)
+        return
+      # Wait for the given duration from the start of the action.
+      wait_time_seconds = expected_end_time - time.time()
+      if wait_time_seconds > 0:
+        actions.wait(wait_time_seconds)
+      elif action.duration:
+        run_duration = dt.timedelta(seconds=time.time() - start_time)
+        logging.info("%s took longer (%s) than expected action duration (%s).",
+                     action, run_duration, action.duration)
+
+  def click_js(self, run: Run, action: i_action.ClickAction) -> None:
+
+    if action.duration > dt.timedelta():
+      raise InputSourceNotImplementedError(self, action, action.input_source,
+                                           "Non-zero duration not implemented")
+    selector = action.selector
+    if not selector:
+      raise RuntimeError("Missing selector")
+
+    selector, script = self.get_selector_script(
+        selector,
+        check_element_exists=True,
+        scroll_into_view=action.scroll_into_view,
+        click=True,
+        return_on_success=True)
+
+    with run.actions("ClickAction", measure=False) as actions:
+      if not actions.js(script, arguments=[selector]) and action.required:
+        raise ElementNotFoundError(selector)
+
+  def scroll_js(self, run: Run, action: i_action.ScrollAction) -> None:
+    with run.actions("ScrollAction", measure=False) as actions:
+      selector = ""
+      selector_script = self.SELECT_WINDOW
+
+      if action.selector:
+        selector, selector_script = self.get_selector_script(action.selector)
+
+      current_scroll_position_script = (
+          selector_script + self.GET_CURRENT_SCROLL_POSITION)
+
+      found_element, initial_scroll_y = actions.js(
+          current_scroll_position_script,
+          arguments=[selector,
+                     self._get_scroll_field(bool(action.selector))])
+
+      if not found_element:
+        if action.required:
+          raise ElementNotFoundError(selector)
+        return
+
+      do_scroll_script = selector_script + self.SCROLL_ELEMENT_TO
+
+      duration_s = action.duration.total_seconds()
+      distance = action.distance
+
+      start_time = time.time()
+      # TODO: use the chrome.gpuBenchmarking.smoothScrollBy extension
+      # if available.
+      while True:
+        time_delta = time.time() - start_time
+        if time_delta >= duration_s:
+          break
+        scroll_y = initial_scroll_y + time_delta / duration_s * distance
+        actions.js(do_scroll_script, arguments=[selector, scroll_y])
+        actions.wait(0.2)
+      scroll_y = initial_scroll_y + distance
+      actions.js(do_scroll_script, arguments=[selector, scroll_y])
+
+  def wait_for_element(self, run: Run,
+                       action: i_action.WaitForElementAction) -> None:
+    with run.actions("WaitForElementAction", measure=False) as actions:
+      actions.wait_js_condition(
+          f"return !!document.querySelector({repr(action.selector)})", 0.2,
+          action.timeout)
+
+  def wait_for_ready_state(self, run: Run,
+                           action: i_action.WaitForReadyStateAction) -> None:
+    with run.actions(
+        f"Wait for ready state {action.ready_state}", measure=False) as actions:
+      self._wait_for_ready_state(actions, action.ready_state, action.timeout)
+
+  def inject_new_document_script(
+      self, run: Run, action: i_action.InjectNewDocumentScriptAction) -> None:
+    run.browser.run_script_on_new_document(action.script)
+
+  def switch_tab(self, run: Run, action: i_action.SwitchTabAction) -> None:
+    with run.actions("SwitchTabAction", measure=False):
+      run.browser.switch_tab(action.title, action.url, action.tab_index,
+                             action.timeout)
+
+  def _get_scroll_field(self, has_selector: bool) -> str:
+    if has_selector:
+      return "scrollTop"
+    return "scrollY"
+
+  def _rate_limit_keystrokes(
+      self, run: Run, action: i_action.TextInputAction,
+      do_type_function: Callable[[Run, Actions, str], None]) -> None:
+    character_delay_s = (action.duration / len(action.text)).total_seconds()
+
+    start_time = time.time()
+
+    action_expected_end_time = start_time + action.duration.total_seconds()
+
+    with run.actions("TextInput", measure=False) as actions:
+
+      # When no duration is specified, input the entire text at once.
+      if action.duration == dt.timedelta():
+        do_type_function(run, actions, action.text)
+        return
+
+      character_expected_end_time = start_time
+
+      for character in action.text:
+        character_expected_end_time += character_delay_s
+
+        do_type_function(run, actions, character)
+
+        expected_end_delta = character_expected_end_time - time.time()
+
+        if expected_end_delta > 0:
+          actions.wait(expected_end_delta)
+
+      overrun_time = time.time() - action_expected_end_time
+
+      # There will always be a slight overrun due to the overhead of the final
+      # actions.wait() call, but that is acceptable. Check if the overrun was
+      # significant.
+      if overrun_time > 0.01:
+        logging.warning(
+            "text_input action is behind schedule! Consider extending this "
+            "action's duration otherwise the action may timeout.")
+
+  def screenshot_impl(self, run: Run, suffix: str) -> None:
+    ctx = run.find_probe_context(ScreenshotProbe)
+    if not ctx:
+      logging.warning("No screenshot probe for screenshot on %s",
+                      repr(self.info_stack))
+      return
+    assert isinstance(ctx, ScreenshotProbeContext)
+    ctx.screenshot("_".join(self.info_stack) + f"_{suffix}")
+
+  def dump_html_impl(self, run: Run, suffix: str) -> None:
+    ctx = run.find_probe_context(DumpHtmlProbe)
+    if not ctx:
+      logging.warning("No dump_html probe for dump on %s",
+                      repr(self.info_stack))
+      return
+    assert isinstance(ctx, DumpHtmlProbeContext)
+    ctx.dump_html("_".join(self.info_stack) + f"_{suffix}")
diff --git a/crossbench/action_runner/chromeos_input_action_runner.py b/crossbench/action_runner/chromeos_input_action_runner.py
new file mode 100644
index 0000000..f445a61
--- /dev/null
+++ b/crossbench/action_runner/chromeos_input_action_runner.py
@@ -0,0 +1,471 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+import datetime as dt
+import shlex
+import subprocess
+from typing import TYPE_CHECKING
+
+import crossbench.path as pth
+from crossbench.action_runner.action import all as i_action
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.display_rectangle import DisplayRectangle
+from crossbench.action_runner.element_not_found_error import \
+    ElementNotFoundError
+from crossbench.benchmarks.loading.point import Point
+from crossbench.parse import NumberParser
+
+if TYPE_CHECKING:
+  from typing import Optional, Tuple, Type
+
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.run import Run
+
+SCRIPTS_DIR = pth.LocalPath(__file__).parent / "chromeos_scripts"
+
+
+class ChromeOSViewportInfo:
+
+  def __init__(self, device_pixel_ratio, window_outer_width, window_inner_width,
+               window_inner_height, screen_width, screen_height,
+               screen_avail_width, screen_avail_height, window_offset_x,
+               window_offset_y,
+               element_rect: Optional[DisplayRectangle]) -> None:
+
+    # The actual screen width and height in pixels.
+    # Corrects for any zoom/scaling factors.
+    # 80 is a common factor of most display pixel widths, so use it as a common
+    # factor to ensure integer division.
+    screen_width_pixels = round(
+        screen_width * device_pixel_ratio /
+        (window_outer_width / window_inner_width) / 80) * 80
+
+    # 60 is a common factor of most display pixel heights, so use it as a common
+    # factor to ensure integer division.
+    screen_height_pixels = round(
+        screen_height * device_pixel_ratio /
+        (window_outer_width / window_inner_width) / 60) * 60
+
+    self._actual_pixel_ratio = screen_width_pixels / screen_avail_width
+
+    screen_avail_width = round(self.css_to_native_distance(screen_avail_width))
+    screen_avail_height = round(
+        self.css_to_native_distance(screen_avail_height))
+
+    window_inner_width = round(self.css_to_native_distance(window_inner_width))
+    window_inner_height = round(
+        self.css_to_native_distance(window_inner_height))
+
+    window_offset_x = round(self.css_to_native_distance(window_offset_x))
+
+    window_offset_y = round(self.css_to_native_distance(window_offset_y))
+    window_offset_y += (screen_avail_height - window_inner_height)
+
+    visible_width = min(window_inner_width,
+                        screen_avail_width - window_offset_x)
+    visible_height = min(window_inner_height,
+                         round(screen_avail_height - window_offset_y))
+
+    self._native_screen = DisplayRectangle(
+        Point(0, 0), screen_width_pixels, screen_height_pixels)
+
+    self._browser_viewable = DisplayRectangle(
+        Point(window_offset_x, window_offset_y), visible_width, visible_height)
+
+    self._element_rect: Optional[DisplayRectangle] = None
+    if element_rect:
+      self._element_rect = self._dom_rect_to_native_rect(element_rect)
+
+  @property
+  def browser_viewable(self) -> DisplayRectangle:
+    return self._browser_viewable
+
+  @property
+  def native_screen(self) -> DisplayRectangle:
+    return self._native_screen
+
+  @property
+  def element_rect(self) -> Optional[DisplayRectangle]:
+    return self._element_rect
+
+  def _dom_rect_to_native_rect(self,
+                               dom_rect: DisplayRectangle) -> DisplayRectangle:
+    browser_viewable = self.browser_viewable
+    correct_ratio_rect = dom_rect * self._actual_pixel_ratio
+
+    adjusted_left = correct_ratio_rect.left + browser_viewable.left
+    adjusted_top = correct_ratio_rect.top + browser_viewable.top
+    adjusted_width = min(correct_ratio_rect.width,
+                         self._native_screen.width - correct_ratio_rect.left)
+    adjusted_height = min(correct_ratio_rect.height,
+                          self._native_screen.height - correct_ratio_rect.top)
+
+    return DisplayRectangle(
+        Point(adjusted_left, adjusted_top), adjusted_width, adjusted_height)
+
+  def css_to_native_distance(self, distance: float) -> float:
+    return distance * self._actual_pixel_ratio
+
+
+@dataclasses.dataclass(frozen=True)
+# Stores the configuration of the touchscreen device for the Chromebook.
+class TouchDevice:
+  # The path of the device.
+  device_path: str
+  # The maximum X value for a touch input.
+  x_max: int
+  # The maximum Y value for a touch input.
+  y_max: int
+
+  @classmethod
+  def parse_str(cls: Type[TouchDevice], config: str) -> TouchDevice:
+    # The first line of output is always 'Performing autotest_lib import'
+    # Followed by the output we care about.
+    touch_device_values = config.splitlines()[1].split(" ")
+
+    return TouchDevice(touch_device_values[0],
+                       NumberParser.positive_zero_int(touch_device_values[1]),
+                       NumberParser.positive_zero_int(touch_device_values[2]))
+
+  def __str__(self) -> str:
+    return f"{self.device_path} {self.x_max} {self.y_max}"
+
+  def is_valid_tap_position(self, position: Point) -> bool:
+    return (0 <= position.x and position.x <= self.x_max and 0 <= position.y and
+            position.y <= self.y_max)
+
+
+@dataclasses.dataclass(frozen=True)
+class ChromeOSTouchEvent:
+  touch_device: TouchDevice
+
+  # The viewport in which the start and end positions lie.
+  viewport: DisplayRectangle
+  # The start position in terms of the device's screen resolution
+  start_position: Point
+  # The end position in terms of the device's screen resolution
+  end_position: Optional[Point] = None
+
+  duration: dt.timedelta = dt.timedelta()
+
+  # Touch event data recorded with evemu-record on a dedede.
+  # This has been tested to work on dedede, brya, and volteer.
+  # Some devices, however, may use a different x-y orientation
+  # (such as kukui in landscape mode) and are not currently supported.
+  _TAP_DOWN = """E: <time> 0003 0039 0
+E: <time> 0003 0035 <x>
+E: <time> 0003 0036 <y>
+E: <time> 0001 014a 1
+E: <time> 0003 0000 <x>
+E: <time> 0003 0001 <y>
+E: <time> 0000 0000 0
+"""
+
+  _TAP_POSITION = """E: <time> 0003 0035 <x>
+E: <time> 0003 0036 <y>
+E: <time> 0003 0000 <x>
+E: <time> 0003 0001 <y>
+E: <time> 0000 0000 0
+"""
+
+  _TAP_UP = """E: <time> 0003 0039 -1
+E: <time> 0001 014a 0
+E: <time> 0000 0000 0
+"""
+
+  # For swipes, simulate the touch panel updating the position 60 times a
+  # second.
+  # This was chosen arbitrarily, but should balance a realistic swipe action
+  # with the size of the playback file that needs to be pushed to the device.
+  _TOUCH_UPDATE_HERTZ = 60
+
+  def __str__(self) -> str:
+    # Not sure why, but evemu-playback does not like it when the event time
+    # starts at 0.X
+    current_event_time_seconds: float = 1.0
+    playback_script: str = ""
+
+    start_position: Point = self._rereference_to_touch_coordinates(
+        self.viewport, self.start_position)
+
+    playback_script += self._format_script_block(self._TAP_DOWN,
+                                                 current_event_time_seconds,
+                                                 start_position)
+
+    # Shortcut for long taps
+    if not self.end_position:
+      current_event_time_seconds += self.duration.total_seconds()
+      playback_script += self._format_script_block(self._TAP_UP,
+                                                   current_event_time_seconds,
+                                                   start_position)
+      return playback_script
+
+    end_position: Point = self._rereference_to_touch_coordinates(
+        self.viewport, self.end_position)
+
+    num_position_updates: int = round(self.duration.total_seconds() *
+                                      self._TOUCH_UPDATE_HERTZ)
+    assert num_position_updates > 0, "Choose a longer scroll duration."
+
+    increment_distance_x = (end_position.x -
+                            start_position.x) / num_position_updates
+    increment_distance_y = (end_position.y -
+                            start_position.y) / num_position_updates
+
+    current_position_x = start_position.x
+    current_position_y = start_position.y
+
+    for _ in range(num_position_updates):
+      current_event_time_seconds += 1.0 / self._TOUCH_UPDATE_HERTZ
+      current_position_x += increment_distance_x
+      current_position_y += increment_distance_y
+      playback_script += self._format_script_block(
+          self._TAP_POSITION, current_event_time_seconds,
+          Point(round(current_position_x), round(current_position_y)))
+
+    playback_script += self._format_script_block(self._TAP_UP,
+                                                 current_event_time_seconds,
+                                                 end_position)
+    return playback_script
+
+  def _rereference(self, original: int, original_max: int, new_max: int) -> int:
+    return round(float(original / original_max) * new_max)
+
+  def _rereference_to_touch_coordinates(self,
+                                        original_viewport: DisplayRectangle,
+                                        point: Point) -> Point:
+    x = self._rereference(point.x, original_viewport.width,
+                          self.touch_device.x_max)
+    y = self._rereference(point.y, original_viewport.height,
+                          self.touch_device.y_max)
+
+    return Point(x, y)
+
+  def _format_script_block(self, script_block: str, time: float,
+                           position: Point) -> str:
+    if not self.touch_device.is_valid_tap_position(position):
+      raise ValueError(f"Cannot tap on out of bounds position: {position}")
+
+    return script_block.replace("<x>", str(round(position.x))).replace(
+        "<y>", str(round(position.y))).replace("<time>", f"{time:.6f}")
+
+
+class ChromeOSInputActionRunner(BasicActionRunner):
+
+  def __init__(self):
+    super().__init__()
+    self._touch_device: Optional[TouchDevice] = None
+    self._remote_tmp_file = ""
+
+  def click_touch(self, run: Run, action: i_action.ClickAction) -> None:
+    if self._touch_device is None:
+      self._touch_device = self._setup_touch_device(run)
+
+    with run.actions("ClickAction", measure=False) as actions:
+
+      click_location, viewport = self._get_click_location(actions, action)
+
+      if not click_location:
+        return
+
+      self._execute_touch_playback(
+          run,
+          ChromeOSTouchEvent(
+              self._touch_device,
+              viewport.native_screen,
+              click_location,
+              end_position=None,
+              duration=action.duration))
+
+  def click_mouse(self, run: Run, action: i_action.ClickAction) -> None:
+    with run.actions("ClickAction", measure=False) as actions:
+
+      click_location, viewport = self._get_click_location(actions, action)
+
+      if not click_location:
+        return
+
+      browser_platform = run.browser_platform
+      self._remote_tmp_file = browser_platform.mktemp()
+      script = (SCRIPTS_DIR / "mouse.py").read_text()
+      browser_platform.set_file_contents(self._remote_tmp_file, script)
+
+      run.browser_platform.sh("python3", self._remote_tmp_file,
+                              str(viewport.native_screen.width),
+                              str(viewport.native_screen.height),
+                              str(action.duration.total_seconds()),
+                              str(click_location.x), str(click_location.y))
+
+  def scroll_touch(self, run: Run, action: i_action.ScrollAction) -> None:
+    if self._touch_device is None:
+      self._touch_device = self._setup_touch_device(run)
+
+    with run.actions("ScrollAction", measure=False) as actions:
+
+      viewport_info: ChromeOSViewportInfo = self._get_viewport_info(
+          actions, action.selector, False)
+
+      scroll_area: DisplayRectangle = viewport_info.browser_viewable
+
+      total_scroll_distance = viewport_info.css_to_native_distance(
+          action.distance)
+
+      if action.selector:
+        if not viewport_info.element_rect:
+          if action.required:
+            raise ElementNotFoundError(action.selector)
+          return
+        scroll_area = viewport_info.element_rect
+
+      max_swipe_distance = scroll_area.bottom - scroll_area.top
+
+      remaining_distance = abs(total_scroll_distance)
+
+      while remaining_distance > 0:
+
+        current_distance = min(max_swipe_distance, remaining_distance)
+
+        # The duration for this swipe should be only a fraction of the total
+        # duration since the entire distance may not be covered in one swipe.
+        current_duration = (current_distance /
+                            abs(total_scroll_distance)) * action.duration
+
+        if total_scroll_distance > 0:
+          # If scrolling down, the swipe should start at the bottom and end
+          # above.
+          y_start = scroll_area.bottom
+          y_end = scroll_area.bottom - current_distance
+
+        else:
+          # If scrolling up, the swipe should start at the top and end below.
+          y_start = scroll_area.top
+          y_end = scroll_area.top + current_distance
+
+        self._execute_touch_playback(
+            run,
+            ChromeOSTouchEvent(
+                self._touch_device,
+                viewport_info.native_screen,
+                Point(scroll_area.middle.x, y_start),
+                end_position=Point(scroll_area.middle.x, y_end),
+                duration=current_duration))
+
+        remaining_distance -= current_distance
+
+  def text_input_keyboard(self, run: Run,
+                          action: i_action.TextInputAction) -> None:
+    browser_platform = run.browser_platform
+    self._remote_tmp_file = browser_platform.mktemp()
+    script = (SCRIPTS_DIR / "text_input.py").read_text()
+    browser_platform.set_file_contents(self._remote_tmp_file, script)
+
+    try:
+      typing_process = browser_platform.popen(
+          "python3", self._remote_tmp_file, bufsize=0, stdin=subprocess.PIPE)
+
+      self._rate_limit_keystrokes(
+          run, action, lambda run, actions, text: typing_process.stdin.write(
+              text.encode("utf-8")))
+    finally:
+      typing_process.stdin.close()
+      typing_process.wait(timeout=action.timeout.total_seconds())
+
+  def _get_click_location(
+      self, actions: Actions, action: i_action.ClickAction
+  ) -> Tuple[Optional[Point], ChromeOSViewportInfo]:
+    viewport_info: ChromeOSViewportInfo = self._get_viewport_info(
+        actions, action.selector, action.scroll_into_view)
+
+    if action.selector:
+      element_rect = viewport_info.element_rect
+      if not element_rect:
+        if action.required:
+          raise ElementNotFoundError(action.selector)
+        return (None, viewport_info)
+      click_location: Point = element_rect.middle
+    else:
+      click_location = action.coordinates
+
+    assert click_location, "Invalid click location click action."
+
+    return (click_location, viewport_info)
+
+  def _get_viewport_info(self,
+                         actions: Actions,
+                         selector: Optional[str],
+                         scroll_into_view=False) -> ChromeOSViewportInfo:
+
+    script = ""
+    if selector:
+      selector, script = self.get_selector_script(selector)
+
+    script += (SCRIPTS_DIR / "get_window_positions.js").read_text()
+
+    (found_element, pixel_ratio, outer_width, inner_width, inner_height,
+     screen_width, screen_height, avail_width, avail_height, screen_x, screen_y,
+     element_left, element_top, element_width, element_height) = actions.js(
+         script, arguments=[selector, scroll_into_view])
+
+    element_rect: Optional[DisplayRectangle] = None
+
+    if found_element:
+      element_rect = DisplayRectangle(
+          Point(element_left, element_top), element_width, element_height)
+
+    viewport_info: ChromeOSViewportInfo = ChromeOSViewportInfo(
+        device_pixel_ratio=pixel_ratio,
+        window_outer_width=outer_width,
+        window_inner_width=inner_width,
+        window_inner_height=inner_height,
+        screen_width=screen_width,
+        screen_height=screen_height,
+        screen_avail_width=avail_width,
+        screen_avail_height=avail_height,
+        window_offset_x=screen_x,
+        window_offset_y=screen_y,
+        element_rect=element_rect)
+
+    return viewport_info
+
+  def _query_touch_device(self, run: Run) -> str:
+    try:
+      with (SCRIPTS_DIR / "query_touch_device.py").open() as file:
+        return run.browser_platform.sh_stdout("python3", "-", stdin=file)
+    except Exception as e:
+      raise RuntimeError(
+          "Failed to query touchscreen information from device.") from e
+
+  def _setup_touch_device(self, run: Run) -> TouchDevice:
+    self._remote_tmp_file = run.browser_platform.mktemp()
+
+    touch_device_output = self._query_touch_device(run)
+
+    return TouchDevice.parse_str(touch_device_output)
+
+  def _execute_touch_playback(self, run: Run,
+                              touch_event: ChromeOSTouchEvent) -> None:
+    # Ideally the touch event data could just be sent to |input| of evemu-play,
+    # but after a lot of testing, evemu-play *only* behaves when input is
+    # redirected from a file such as with:
+    # 'evemu-play touch-device < input-file.txt'
+    # Using a pipe to redirect the input *does not work*:
+    # 'cat input-file.txt | evemu-play touch-device'
+
+    # Because of this weird behavior, create a temp file on the device first
+    # that contains the touch events.
+
+    touch_event_cmds = str(touch_event)
+
+    run.browser_platform.set_file_contents(self._remote_tmp_file,
+                                           touch_event_cmds)
+
+    # Then run evemu-play with the input redirected from the temp file.
+    run.browser_platform.sh(
+        f"evemu-play --insert-slot0 "
+        f"{shlex.quote(self._touch_device.device_path)} < "
+        f"{self._remote_tmp_file}",
+        shell=True)
diff --git a/crossbench/action_runner/chromeos_scripts/get_window_positions.js b/crossbench/action_runner/chromeos_scripts/get_window_positions.js
new file mode 100644
index 0000000..7864d19
--- /dev/null
+++ b/crossbench/action_runner/chromeos_scripts/get_window_positions.js
@@ -0,0 +1,31 @@
+// Copyright 2024 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+// <INSERT SELECTOR LOGIC HERE>
+
+if (arguments[0] && element && arguments[1]) element.scrollIntoView();
+
+if (arguments[0] && element) {
+  element_rect = element.getBoundingClientRect();
+} else {
+  element_rect = new DOMRect();
+}
+
+return [
+  arguments[0] && element,
+  window.devicePixelRatio,
+  window.outerWidth,
+  window.innerWidth,
+  window.innerHeight,
+  screen.width,
+  screen.height,
+  screen.availWidth,
+  screen.availHeight,
+  screenX,
+  screenY,
+  element_rect.left,
+  element_rect.top,
+  element_rect.width,
+  element_rect.height
+];
\ No newline at end of file
diff --git a/crossbench/action_runner/chromeos_scripts/mouse.py b/crossbench/action_runner/chromeos_scripts/mouse.py
new file mode 100644
index 0000000..78b7fb9
--- /dev/null
+++ b/crossbench/action_runner/chromeos_scripts/mouse.py
@@ -0,0 +1,37 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# pytype: skip-file
+
+# This script is to be run directly on a ChromeOS device to emulate a mouse and
+# then move to and click a location.
+
+import sys
+import time
+import uinput
+
+screen_width = int(sys.argv[1])
+screen_height = int(sys.argv[2])
+click_duration = float(sys.argv[3])
+x = int(sys.argv[4])
+y = int(sys.argv[5])
+
+events = (
+    uinput.ABS_X + (0, screen_width, 0, 0),
+    uinput.ABS_Y + (0, screen_height, 0, 0),
+    uinput.BTN_LEFT,
+    uinput.BTN_RIGHT,
+)
+
+with uinput.Device(events) as device:
+  # The system needs a bit of time before it can start processing events from
+  # the newly registered device.
+  time.sleep(0.1)
+
+  device.emit(uinput.ABS_X, x, syn=False)
+  device.emit(uinput.ABS_Y, y)
+
+  device.emit(uinput.BTN_LEFT, 1)
+  time.sleep(click_duration)
+  device.emit(uinput.BTN_LEFT, 0)
diff --git a/crossbench/action_runner/chromeos_scripts/query_touch_device.py b/crossbench/action_runner/chromeos_scripts/query_touch_device.py
new file mode 100644
index 0000000..8a27986
--- /dev/null
+++ b/crossbench/action_runner/chromeos_scripts/query_touch_device.py
@@ -0,0 +1,28 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# pytype: skip-file
+
+# This script is to be run directly on a ChromeOS device to query and return
+# the touch device information.
+
+import logging
+import sys
+
+sys.path.append("/usr/local/autotest/bin")
+
+# pylint: disable=wrong-import-position
+import common  # pylint: disable=unused-import
+from autotest_lib.client.bin.input import input_device
+from autotest_lib.client.cros.input_playback import input_playback
+
+logging.disable(logging.ERROR)
+
+playback = input_playback.InputPlayback()
+playback.find_connected_inputs()
+touchscreen_node = playback.devices["touchscreen"].node
+touchscreen = input_device.InputDevice(touchscreen_node)
+
+# This output is parsed by crossbench:
+print(touchscreen_node, touchscreen.get_x_max(), touchscreen.get_y_max())
diff --git a/crossbench/action_runner/chromeos_scripts/text_input.py b/crossbench/action_runner/chromeos_scripts/text_input.py
new file mode 100644
index 0000000..94d9f49
--- /dev/null
+++ b/crossbench/action_runner/chromeos_scripts/text_input.py
@@ -0,0 +1,20 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# pytype: skip-file
+
+# This script is to be run directly on a ChromeOS device to redirect characters
+# read from stdin to be typed on an emulated keyboard device.
+
+import sys
+
+import uinput.cros_keys
+
+while True:
+  char = sys.stdin.read(1)
+
+  if not char:
+    break
+
+  uinput.cros_keys.type_chars(char)
diff --git a/crossbench/action_runner/config.py b/crossbench/action_runner/config.py
new file mode 100644
index 0000000..fc69e9b
--- /dev/null
+++ b/crossbench/action_runner/config.py
@@ -0,0 +1,34 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+from typing import Any
+
+from crossbench.action_runner.android_input_action_runner import \
+    AndroidInputActionRunner
+from crossbench.action_runner.base import ActionRunner
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.chromeos_input_action_runner import \
+    ChromeOSInputActionRunner
+
+
+# TODO: migrate to full config.ConfigObject
+class ActionRunnerConfig:
+
+  @classmethod
+  def parse(cls, value: Any) -> ActionRunner:
+    if isinstance(value, ActionRunner):
+      return value
+    if value == "basic":
+      return BasicActionRunner()
+    if value == "android":
+      return AndroidInputActionRunner()
+    if value == "chromeos":
+      return ChromeOSInputActionRunner()
+    raise argparse.ArgumentTypeError(
+      f"Invalid choice '{value}', allowed values are 'basic', 'android', "
+      "'chromeos'"
+    )
diff --git a/crossbench/action_runner/display_rectangle.py b/crossbench/action_runner/display_rectangle.py
new file mode 100644
index 0000000..4518e8d
--- /dev/null
+++ b/crossbench/action_runner/display_rectangle.py
@@ -0,0 +1,67 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+
+from typing_extensions import Self
+
+from crossbench.benchmarks.loading.point import Point
+
+
+@dataclasses.dataclass(frozen=False)
+# Represents a rectangular section of the device's display.
+class DisplayRectangle:
+  # The top left corner of the rectangle.
+  origin: Point
+  # The width in pixels of the rectangle.
+  width: int
+  # The height in pixels of the rectangle.
+  height: int
+
+  # Stretches or squishes the rectangle by |factor|
+  def __mul__(self, factor: float) -> DisplayRectangle:
+    return DisplayRectangle(
+        Point(round(self.origin.x * factor), round(self.origin.y * factor)),
+        round(self.width * factor), round(self.height * factor))
+
+  __rmul__ = __mul__
+
+  def __bool__(self) -> bool:
+    return self.width != 0 and self.height != 0
+
+  # Translates the rectangle into |other|
+  def shift_by(self, other: Self) -> DisplayRectangle:
+    return DisplayRectangle(
+        Point(self.origin.x + other.origin.x, self.origin.y + other.origin.y),
+        self.width, self.height)
+
+  @property
+  def left(self) -> int:
+    return self.origin.x
+
+  @property
+  def right(self) -> int:
+    return self.origin.x + self.width
+
+  @property
+  def top(self) -> int:
+    return self.origin.y
+
+  @property
+  def bottom(self) -> int:
+    return self.origin.y + self.height
+
+  @property
+  def mid_x(self) -> int:
+    return round(self.origin.x + (self.width / 2))
+
+  @property
+  def mid_y(self) -> int:
+    return round(self.origin.y + (self.height / 2))
+
+  @property
+  def middle(self) -> Point:
+    return Point(self.mid_x, self.mid_y)
diff --git a/crossbench/action_runner/element_not_found_error.py b/crossbench/action_runner/element_not_found_error.py
new file mode 100644
index 0000000..3022026
--- /dev/null
+++ b/crossbench/action_runner/element_not_found_error.py
@@ -0,0 +1,10 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+
+class ElementNotFoundError(RuntimeError):
+
+  def __init__(self, selector: str) -> None:
+    message = f"Could not find matching DOM element: {repr(selector)}"
+    super().__init__(message)
diff --git a/crossbench/benchmarks/__init__.py b/crossbench/benchmarks/__init__.py
new file mode 100644
index 0000000..d271f03
--- /dev/null
+++ b/crossbench/benchmarks/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/benchmarks/all.py b/crossbench/benchmarks/all.py
new file mode 100644
index 0000000..01d14cf
--- /dev/null
+++ b/crossbench/benchmarks/all.py
@@ -0,0 +1,23 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+# pylint: disable=unused-import
+
+from __future__ import annotations
+
+from crossbench.benchmarks.jetstream import (JetStream20Benchmark,
+                                             JetStream21Benchmark,
+                                             JetStream22Benchmark,
+                                             JetStream30Benchmark)
+from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+from crossbench.benchmarks.loading.loadline_presets import (
+    LoadLinePhoneBenchmark, LoadLineTabletBenchmark)
+from crossbench.benchmarks.manual import ManualBenchmark
+from crossbench.benchmarks.memory.memory_benchmark import MemoryBenchmark
+from crossbench.benchmarks.motionmark import (MotionMark10Benchmark,
+                                              MotionMark11Benchmark,
+                                              MotionMark12Benchmark,
+                                              MotionMark13Benchmark)
+from crossbench.benchmarks.speedometer import (Speedometer20Benchmark,
+                                               Speedometer21Benchmark,
+                                               Speedometer30Benchmark)
diff --git a/crossbench/benchmarks/base.py b/crossbench/benchmarks/base.py
new file mode 100644
index 0000000..ad753ae
--- /dev/null
+++ b/crossbench/benchmarks/base.py
@@ -0,0 +1,509 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+import logging
+import re
+from typing import (TYPE_CHECKING, Any, Dict, Generic, List, Optional, Sequence,
+                    Tuple, Type, TypeVar, cast)
+
+from ordered_set import OrderedSet
+
+from crossbench import helper
+from crossbench.cli.parser import CrossBenchArgumentParser
+from crossbench.flags.base import Flags
+from crossbench.parse import ObjectParser
+from crossbench.stories.press_benchmark import PressBenchmarkStory
+from crossbench.stories.story import Story
+
+if TYPE_CHECKING:
+  from crossbench import path as pth
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.runner.runner import Runner
+
+
+class BenchmarkProbeMixin:
+  NAME: str = ""
+  IS_GENERAL_PURPOSE: bool = False
+
+  def __init__(self, *args, **kwargs):
+    self._benchmark = kwargs.pop("benchmark")
+    assert isinstance(self._benchmark, Benchmark)
+    super().__init__(*args, **kwargs)
+
+  @property
+  def benchmark(self) -> Benchmark:
+    return self._benchmark
+
+
+class Benchmark(abc.ABC):
+  NAME: str = ""
+  DEFAULT_STORY_CLS: Type[Story] = Story
+  PROBES: Tuple[Type[BenchmarkProbeMixin], ...] = ()
+  DEFAULT_REPETITIONS: int = 1
+
+  @classmethod
+  def cli_help(cls) -> str:
+    assert cls.__doc__, (f"Benchmark class {cls} must provide a doc string.")
+    # Return the first non-empty line
+    return cls.__doc__.strip().splitlines()[0]
+
+  @classmethod
+  def cli_description(cls) -> str:
+    assert cls.__doc__
+    return cls.__doc__.strip()
+
+  @classmethod
+  def cli_epilog(cls) -> str:
+    return ""
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return tuple()
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers, aliases: Sequence[str] = ()) -> CrossBenchArgumentParser:
+    parser = subparsers.add_parser(
+        cls.NAME,
+        formatter_class=argparse.RawDescriptionHelpFormatter,
+        help=cls.cli_help(),
+        description=cls.cli_description(),
+        epilog=cls.cli_epilog(),
+        aliases=aliases)
+    assert isinstance(parser, CrossBenchArgumentParser)
+    return parser
+
+  @classmethod
+  def describe(cls) -> Dict[str, Any]:
+    return {
+        "name": cls.NAME,
+        "description": "\n".join(helper.wrap_lines(cls.cli_description(), 70)),
+        "stories": [],
+        "probes-default": {
+            probe_cls.NAME:
+                "\n".join(
+                    list(
+                        helper.wrap_lines((probe_cls.__doc__ or "").strip(),
+                                          70))) for probe_cls in cls.PROBES
+        }
+    }
+
+  @classmethod
+  def default_probe_config_path(cls) -> Optional[pth.LocalPath]:
+    return None
+
+  @classmethod
+  def default_network_config_path(cls) -> Optional[pth.LocalPath]:
+    return None
+
+  @classmethod
+  def extra_flags(cls, browser_attributes: BrowserAttributes) -> Flags:
+    del browser_attributes
+    return Flags()
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    del args
+    return {}
+
+  @classmethod
+  def from_cli_args(cls, args: argparse.Namespace) -> Benchmark:
+    kwargs = cls.kwargs_from_cli(args)
+    return cls(**kwargs)
+
+  def __init__(self, stories: Sequence[Story]) -> None:
+    assert self.NAME is not None, f"{self} has no .NAME property"
+    assert self.DEFAULT_STORY_CLS != Story, (
+        f"{self} has no .DEFAULT_STORY_CLS property")
+    self.stories: List[Story] = self._validate_stories(stories)
+
+  def _validate_stories(self, stories: Sequence[Story]) -> List[Story]:
+    assert stories, "No stories provided"
+    for story in stories:
+      assert isinstance(story, self.DEFAULT_STORY_CLS), (
+          f"story={story} should be a subclass/the same "
+          f"class as {self.DEFAULT_STORY_CLS}")
+    return list(stories)
+
+  def setup(self, runner: Runner) -> None:
+    del runner
+
+
+StoryT = TypeVar("StoryT", bound=Story)
+
+
+class StoryFilter(Generic[StoryT], metaclass=abc.ABCMeta):
+  CAN_COMBINE_STORIES: bool = True
+
+  @classmethod
+  def add_cli_parser(
+      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser.add_argument(
+        "--stories",
+        "--story",
+        dest="stories",
+        default="default",
+        help="Comma-separated list of story names. "
+        "Use 'all' for selecting all available stories. "
+        "Use 'default' for the standard selection of stories.")
+    if cls.CAN_COMBINE_STORIES:
+      is_combined_group = parser.add_mutually_exclusive_group()
+      is_combined_group.add_argument(
+          "--combined",
+          dest="separate",
+          default=False,
+          action="store_false",
+          help="Run each story in the same session. (default)")
+      is_combined_group.add_argument(
+          "--separate",
+          action="store_true",
+          help="Run each story in a fresh browser.")
+
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    return {"patterns": args.stories.split(",")}
+
+  @classmethod
+  def from_cli_args(cls, story_cls: Type[StoryT],
+                    args: argparse.Namespace) -> StoryFilter[StoryT]:
+    kwargs = cls.kwargs_from_cli(args)
+    return cls(story_cls, **kwargs)
+
+  def __init__(self,
+               story_cls: Type[StoryT],
+               patterns: Sequence[str],
+               separate: bool = False) -> None:
+    self.story_cls: Type[StoryT] = story_cls
+    assert issubclass(
+        story_cls, Story), (f"Subclass of {Story} expected, found {story_cls}")
+    # Using order-preserving dict instead of set
+    self._known_names: Dict[str,
+                            None] = dict.fromkeys(story_cls.all_story_names())
+    self.stories: Sequence[StoryT] = []
+    # TODO: only use one method.
+    self.process_all(patterns)
+    self.stories = self.create_stories(separate)
+
+  @abc.abstractmethod
+  def process_all(self, patterns: Sequence[str]) -> None:
+    pass
+
+  @abc.abstractmethod
+  def create_stories(self, separate: bool) -> Sequence[StoryT]:
+    pass
+
+
+class SubStoryBenchmark(Benchmark, metaclass=abc.ABCMeta):
+  STORY_FILTER_CLS: Type[StoryFilter] = StoryFilter
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers, aliases: Sequence[str] = ()) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    return parser
+
+  @classmethod
+  def cli_description(cls) -> str:
+    desc = super().cli_description()
+    desc += "\n\n"
+    desc += ("Stories (alternatively use the 'describe benchmark "
+             f"{cls.NAME}' command):\n")
+    desc += ", ".join(cls.all_story_names())
+    desc += "\n\n"
+    desc += "Filtering (for --stories): "
+    assert cls.STORY_FILTER_CLS.__doc__, (
+        f"{cls.STORY_FILTER_CLS} has no doc string.")
+    desc += cls.STORY_FILTER_CLS.__doc__.strip()
+
+    return desc
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["stories"] = cls.stories_from_cli_args(args)
+    return kwargs
+
+  @classmethod
+  def stories_from_cli_args(cls, args: argparse.Namespace) -> Sequence[Story]:
+    return cls.STORY_FILTER_CLS.from_cli_args(cls.DEFAULT_STORY_CLS,
+                                              args).stories
+
+  @classmethod
+  def describe(cls) -> Dict[str, Any]:
+    data = super().describe()
+    data["stories"] = cls.all_story_names()
+    return data
+
+  @classmethod
+  def all_story_names(cls) -> Sequence[str]:
+    return sorted(cls.DEFAULT_STORY_CLS.all_story_names())
+
+
+PressBenchmarkStoryT = TypeVar(
+    "PressBenchmarkStoryT", bound=PressBenchmarkStory)
+
+
+class PressBenchmarkStoryFilter(StoryFilter[PressBenchmarkStoryT],
+                                Generic[PressBenchmarkStoryT]):
+  """
+  Filter stories by name or regexp.
+
+  Syntax:
+    "all"     Include all stories (defaults to story_names).
+    "name"    Include story with the given name.
+    "-name"   Exclude story with the given name'
+    "foo.*"   Include stories whose name matches the regexp.
+    "-foo.*"  Exclude stories whose name matches the regexp.
+
+  These patterns can be combined:
+    [".*", "-foo", "-bar"] Includes all except the "foo" and "bar" story
+  """
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["separate"] = args.separate
+    kwargs["url"] = args.custom_benchmark_url
+    return kwargs
+
+  def __init__(self,
+               story_cls: Type[PressBenchmarkStoryT],
+               patterns: Sequence[str],
+               separate: bool = False,
+               url: Optional[str] = None):
+    self.url: Optional[str] = url
+    self._selected_names: OrderedSet[str] = OrderedSet()
+    super().__init__(story_cls, patterns, separate)
+    assert issubclass(self.story_cls, PressBenchmarkStory)
+    for name in self._known_names:
+      assert name, "Invalid empty story name"
+      assert not name.startswith("-"), (
+          f"Known story names cannot start with '-', but got '{name}'.")
+      assert not name == "all", "Known story name cannot match 'all'."
+
+  def process_all(self, patterns: Sequence[str]) -> None:
+    if not isinstance(patterns, (list, tuple)):
+      raise ValueError("Expected Sequence of story name or patterns "
+                       f"but got '{type(patterns)}'.")
+    for pattern in patterns:
+      self.process_pattern(pattern)
+
+  def process_pattern(self, pattern: str) -> None:
+    if pattern.startswith("-"):
+      self.remove(pattern[1:])
+    else:
+      self.add(pattern)
+
+  def add(self, pattern: str) -> None:
+    self._check_processed_pattern(pattern)
+    regexp = self._pattern_to_regexp(pattern)
+    self._add_matching(regexp, pattern)
+
+  def remove(self, pattern: str) -> None:
+    self._check_processed_pattern(pattern)
+    regexp = self._pattern_to_regexp(pattern)
+    self._remove_matching(regexp, pattern)
+
+  def _pattern_to_regexp(self, pattern: str) -> re.Pattern:
+    if pattern == "all":
+      return re.compile(".*")
+    if pattern == "default":
+      default_story_names = self.story_cls.default_story_names()
+      if default_story_names == self.story_cls.all_story_names():
+        return re.compile(".*")
+      joined_names = "|".join(re.escape(name) for name in default_story_names)
+      return re.compile(f"^({joined_names})$")
+    if pattern in self._known_names:
+      return re.compile(re.escape(pattern))
+    return re.compile(pattern)
+
+  def _check_processed_pattern(self, pattern: str) -> None:
+    if not pattern:
+      raise ValueError("Empty pattern is not allowed")
+    if pattern == "-":
+      raise ValueError(f"Empty remove pattern not allowed: '{pattern}'")
+    if pattern[0] == "-":
+      raise ValueError(f"Unprocessed negative pattern not allowed: '{pattern}'")
+
+  def _add_matching(self, regexp: re.Pattern, original_pattern: str) -> None:
+    substories = self._regexp_match(regexp, original_pattern)
+    self._selected_names.update(substories)
+
+  def _remove_matching(self, regexp: re.Pattern, original_pattern: str) -> None:
+    substories = self._regexp_match(regexp, original_pattern)
+    for substory in substories:
+      try:
+        self._selected_names.remove(substory)
+      except KeyError as e:
+        raise ValueError(
+            "Removing Story failed: "
+            f"name='{substory}' extracted by pattern='{original_pattern}'"
+            "is not in the filtered story list") from e
+
+  def _regexp_match(self, regexp: re.Pattern,
+                    original_pattern: str) -> List[str]:
+    substories = [
+        substory for substory in self._known_names if regexp.fullmatch(substory)
+    ]
+    if not substories:
+      logging.warning(
+          "No matching stories, using case-insensitive fallback regexp.")
+      iregexp: re.Pattern = re.compile(regexp.pattern, flags=re.IGNORECASE)
+      substories = [
+          substory for substory in self._known_names
+          if iregexp.fullmatch(substory)
+      ]
+    if not substories:
+      raise ValueError(f"'{original_pattern}' didn't match any stories.")
+    if len(substories) == len(self._known_names) and self._selected_names:
+      raise ValueError(f"'{original_pattern}' matched all and overrode all"
+                       "previously filtered story names.")
+    return substories
+
+  def create_stories(self, separate: bool) -> Sequence[PressBenchmarkStoryT]:
+    logging.info("SELECTED STORIES: %s",
+                 str(list(map(str, self._selected_names))))
+    names = list(self._selected_names)
+    return self.create_stories_from_names(names, separate)
+
+  def create_stories_from_names(
+      self, names: List[str], separate: bool) -> Sequence[PressBenchmarkStoryT]:
+    return self.story_cls.from_names(names, separate=separate, url=self.url)
+
+
+class PressBenchmark(SubStoryBenchmark):
+  STORY_FILTER_CLS = PressBenchmarkStoryFilter
+  DEFAULT_STORY_CLS: Type[PressBenchmarkStory] = PressBenchmarkStory
+
+  @classmethod
+  @abc.abstractmethod
+  def short_base_name(cls) -> str:
+    raise NotImplementedError()
+
+  @classmethod
+  @abc.abstractmethod
+  def base_name(cls) -> str:
+    raise NotImplementedError()
+
+  @classmethod
+  @abc.abstractmethod
+  def version(cls) -> Tuple[int, ...]:
+    raise NotImplementedError()
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    version = [str(v) for v in cls.version()]
+    assert version, "Expected non-empty version tuple."
+    version_names = []
+    dot_version = ".".join(version)
+    for name in (cls.short_base_name(), cls.base_name()):
+      assert name, "Expected non-empty base name."
+      version_names.append(f"{name}{dot_version}")
+      version_names.append(f"{name}_{dot_version}")
+    return tuple(version_names)
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers, aliases: Sequence[str] = ()) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    # TODO: Move story-related args to dedicated PressBenchmarkStoryFilter class
+    benchmark_url_group = parser.add_mutually_exclusive_group()
+    live_url = cls.DEFAULT_STORY_CLS.URL
+    local_url = cls.DEFAULT_STORY_CLS.URL_LOCAL
+    official_url = cls.DEFAULT_STORY_CLS.URL_OFFICIAL
+    benchmark_url_group.add_argument(
+        "--live",
+        "--live-url",
+        "--browser-ben",
+        dest="custom_benchmark_url",
+        const=None,
+        action="store_const",
+        help=(f"Use chrome live benchmark url ({live_url}) "
+              "on https://browserben.ch."))
+    benchmark_url_group.add_argument(
+        "--official",
+        "--official-url",
+        dest="custom_benchmark_url",
+        const=official_url,
+        action="store_const",
+        help=(f"Use officially hosted live/online benchmark url "
+              f"({official_url})."))
+    benchmark_url_group.add_argument(
+        "--local",
+        "--local-url",
+        "--url",
+        "--custom-benchmark-url",
+        type=ObjectParser.httpx_url_str,
+        nargs="?",
+        dest="custom_benchmark_url",
+        const=local_url,
+        help=(f"Use custom or locally (default={local_url}) "
+              "hosted benchmark url."))
+    cls.STORY_FILTER_CLS.add_cli_parser(parser)
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["custom_url"] = args.custom_benchmark_url
+    return kwargs
+
+  @classmethod
+  def describe(cls) -> Dict[str, Any]:
+    data = super().describe()
+    assert issubclass(cls.DEFAULT_STORY_CLS, PressBenchmarkStory)
+    data["url"] = cls.DEFAULT_STORY_CLS.URL
+    data["url-official"] = cls.DEFAULT_STORY_CLS.URL_OFFICIAL
+    data["url-local"] = cls.DEFAULT_STORY_CLS.URL_LOCAL
+    return data
+
+  def __init__(self,
+               stories: Sequence[Story],
+               custom_url: Optional[str] = None):
+    super().__init__(stories)
+    self.custom_url = custom_url
+    if custom_url:
+      for story in stories:
+        press_story = cast(PressBenchmarkStory, story)
+        assert press_story.url == custom_url
+
+  def setup(self, runner: Runner) -> None:
+    super().setup(runner)
+    self.validate_url(runner)
+
+  def validate_url(self, runner: Runner) -> None:
+    if self.custom_url:
+      if runner.has_any_live_network():
+        self._validate_custom_url(runner, self.custom_url)
+      return
+    first_story = cast(PressBenchmarkStory, self.stories[0])
+    url = first_story.url
+    if not runner.has_all_live_network() and not url:
+      # For non-live networks we create a matching URL
+      return
+    if not url:
+      raise ValueError("Invalid empty url")
+    if all(runner.env.validate_url(url, p) for p in runner.platforms):
+      return
+    msg = [
+        f"Could not reach live benchmark URL: '{url}'."
+        f"Please make sure you're connected to the internet."
+    ]
+    local_url = first_story.URL_LOCAL
+    if local_url:
+      msg.append(
+          f"Alternatively use --local for the default local URL: {local_url}")
+    raise ValueError("\n".join(msg))
+
+  def _validate_custom_url(self, runner: Runner, url: str) -> None:
+    if not all(runner.env.validate_url(url, p) for p in runner.platforms):
+      raise ValueError(
+          f"Could not reach custom benchmark URL: '{self.custom_url}'. "
+          f"Please make sure your local web server is running.")
diff --git a/crossbench/benchmarks/jetstream/__init__.py b/crossbench/benchmarks/jetstream/__init__.py
new file mode 100644
index 0000000..229e21f
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/__init__.py
@@ -0,0 +1,10 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.benchmarks.jetstream.jetstream_2_0 import JetStream20Benchmark
+from crossbench.benchmarks.jetstream.jetstream_2_1 import JetStream21Benchmark
+from crossbench.benchmarks.jetstream.jetstream_2_2 import JetStream22Benchmark
+from crossbench.benchmarks.jetstream.jetstream_3_0 import JetStream30Benchmark
diff --git a/crossbench/benchmarks/jetstream/jetstream.py b/crossbench/benchmarks/jetstream/jetstream.py
new file mode 100644
index 0000000..dad96fb
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/jetstream.py
@@ -0,0 +1,199 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import json
+import logging
+from collections import defaultdict
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    cast)
+
+from crossbench.benchmarks.base import BenchmarkProbeMixin, PressBenchmark
+from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.metric import (CSVFormatter, Metric, MetricsMerger,
+                                      geomean)
+from crossbench.probes.results import ProbeResult, ProbeResultDict
+
+if TYPE_CHECKING:
+  import argparse
+
+  from crossbench.cli.parser import CrossBenchArgumentParser
+  from crossbench.path import LocalPath
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.stories.story import Story
+  from crossbench.types import Json
+
+
+class JetStreamProbe(
+    BenchmarkProbeMixin, JsonResultProbe, metaclass=abc.ABCMeta):
+  """
+  JetStream-specific Probe.
+  Extracts all JetStream times and scores.
+  """
+  FLATTEN: bool = False
+  JS: str = """
+  let results = Object.create(null);
+  let benchmarks = []
+  for (let benchmark of JetStream.benchmarks) {
+    const data = { score: benchmark.score };
+    if ("worst4" in benchmark) {
+      data.firstIteration = benchmark.firstIteration;
+      data.average = benchmark.average;
+      data.worst4 = benchmark.worst4;
+    } else if ("runTime" in benchmark) {
+      data.runTime = benchmark.runTime;
+      data.startupTime = benchmark.startupTime;
+    } else if ("mainRun" in benchmark) {
+      data.mainRun = benchmark.mainRun;
+      data.stdlib = benchmark.stdlib;
+    }
+    results[benchmark.plan.name] = data;
+    benchmarks.push(benchmark);
+  };
+  return results;
+"""
+
+  @property
+  def jetstream(self) -> JetStreamBenchmark:
+    return cast(JetStreamBenchmark, self.benchmark)
+
+  def to_json(self, actions: Actions) -> Dict[str, float]:
+    data = actions.js(self.JS)
+    assert len(data) > 0, "No benchmark data generated"
+    return data
+
+  def process_json_data(self, json_data: Dict[str, Any]) -> Dict[str, Any]:
+    assert "Total" not in json_data, (
+        "JSON result data already contains a ['Total'] entry.")
+    json_data["Total"] = self._compute_total_metrics(json_data)
+    return json_data
+
+  def _compute_total_metrics(self, json_data: Dict[str,
+                                                   Any]) -> Dict[str, float]:
+    # Manually add all total scores
+    accumulated_metrics = defaultdict(list)
+    for _, metrics in json_data.items():
+      for metric, value in metrics.items():
+        accumulated_metrics[metric].append(value)
+    total: Dict[str, float] = {}
+    for metric, values in accumulated_metrics.items():
+      total[metric] = geomean(values)
+    return total
+
+  def log_run_result(self, run: Run) -> None:
+    self._log_result(run.results, single_result=True)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    self._log_result(group.results, single_result=False)
+
+  def _log_result(self, result_dict: ProbeResultDict,
+                  single_result: bool) -> None:
+    if self not in result_dict:
+      return
+    results_json: LocalPath = result_dict[self].json
+    logging.info("-" * 80)
+    logging.critical("JetStream results:")
+    if not single_result:
+      logging.critical("  %s", result_dict[self].csv)
+    logging.info("- " * 40)
+
+    with results_json.open(encoding="utf-8") as f:
+      data = json.load(f)
+      if single_result:
+        logging.critical("Score %s", data["Total"]["score"])
+      else:
+        self._log_result_metrics(data)
+
+  def _extract_result_metrics_table(self, metrics: Dict[str, Any],
+                                    table: Dict[str, List[str]]) -> None:
+    for metric_key, metric_value in metrics.items():
+      if not self._is_valid_metric_key(metric_key):
+        continue
+      table[metric_key].append(
+          Metric.format(metric_value["average"], metric_value["stddev"]))
+      # Separate runs don't produce a score
+    if "Total/score" in metrics:
+      metric_value = metrics["Total/score"]
+      table["Score"].append(
+          Metric.format(metric_value["average"], metric_value["stddev"]))
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        story_group.results[self].json
+        for story_group in group.repetitions_groups)
+    return self.write_group_result(group, merged, JetStreamCSVFormatter)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self.merge_browsers_json_list(group).merge(
+        self.merge_browsers_csv_list(group))
+
+  def _is_valid_metric_key(self, metric_key: str) -> bool:
+    parts = metric_key.split("/")
+    if len(parts) != 2:
+      return False
+    if self.jetstream.detailed_metrics:
+      return True
+    return parts[0] != "Total" and parts[1] == "score"
+
+class JetStreamCSVFormatter(CSVFormatter):
+
+  def format_items(self, data: Dict[str, Json],
+                   sort: bool) -> Sequence[Tuple[str, Json]]:
+    items = list(data.items())
+    if sort:
+      items.sort()
+    # Copy all /score items to the top:
+    total_key = "Total/score"
+    score_items = []
+    for key, value in items:
+      if key != total_key and key.endswith("/score"):
+        score_items.append((key, value))
+    total_item = [(total_key, data[total_key])]
+    return total_item + score_items + items
+
+
+class JetStreamBenchmark(PressBenchmark, metaclass=abc.ABCMeta):
+
+  @classmethod
+  def short_base_name(cls) -> str:
+    return "js"
+
+  @classmethod
+  def base_name(cls) -> str:
+    return "jetstream"
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
+  ) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    parser.add_argument(
+        "--detailed-metrics",
+        "--details",
+        default=False,
+        action="store_true",
+        help="Report more detailed internal metrics.")
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["detailed_metrics"] = args.detailed_metrics
+    return kwargs
+
+  def __init__(self,
+               stories: Sequence[Story],
+               custom_url: Optional[str] = None,
+               detailed_metrics: bool = False):
+    self._detailed_metrics = detailed_metrics
+    super().__init__(stories, custom_url)
+
+  @property
+  def detailed_metrics(self) -> bool:
+    return self._detailed_metrics
diff --git a/crossbench/benchmarks/jetstream/jetstream_2.py b/crossbench/benchmarks/jetstream/jetstream_2.py
new file mode 100644
index 0000000..fec1625
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/jetstream_2.py
@@ -0,0 +1,137 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+from typing import TYPE_CHECKING, Tuple, Type
+
+from crossbench.benchmarks.jetstream.jetstream import (JetStreamBenchmark,
+                                                       JetStreamProbe)
+from crossbench.stories.press_benchmark import PressBenchmarkStory
+
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+
+
+class JetStream2Probe(JetStreamProbe, metaclass=abc.ABCMeta):
+  """
+  JetStream2-specific Probe.
+  Extracts all JetStream2 times and scores.
+  """
+
+
+class JetStream2Story(PressBenchmarkStory, metaclass=abc.ABCMeta):
+  URL_LOCAL: str = "http://localhost:8000/"
+  SUBSTORIES: Tuple[str, ...] = (
+      "WSL",
+      "UniPoker",
+      "uglify-js-wtb",
+      "typescript",
+      "tsf-wasm",
+      "tagcloud-SP",
+      "string-unpack-code-SP",
+      "stanford-crypto-sha256",
+      "stanford-crypto-pbkdf2",
+      "stanford-crypto-aes",
+      "splay",
+      "segmentation",
+      "richards-wasm",
+      "richards",
+      "regexp",
+      "regex-dna-SP",
+      "raytrace",
+      "quicksort-wasm",
+      "prepack-wtb",
+      "pdfjs",
+      "OfflineAssembler",
+      "octane-zlib",
+      "octane-code-load",
+      "navier-stokes",
+      "n-body-SP",
+      "multi-inspector-code-load",
+      "ML",
+      "mandreel",
+      "lebab-wtb",
+      "json-stringify-inspector",
+      "json-parse-inspector",
+      "jshint-wtb",
+      "HashSet-wasm",
+      "hash-map",
+      "gcc-loops-wasm",
+      "gbemu",
+      "gaussian-blur",
+      "float-mm.c",
+      "FlightPlanner",
+      "first-inspector-code-load",
+      "espree-wtb",
+      "earley-boyer",
+      "delta-blue",
+      "date-format-xparb-SP",
+      "date-format-tofte-SP",
+      "crypto-sha1-SP",
+      "crypto-md5-SP",
+      "crypto-aes-SP",
+      "crypto",
+      "coffeescript-wtb",
+      "chai-wtb",
+      "cdjs",
+      "Box2D",
+      "bomb-workers",
+      "Basic",
+      "base64-SP",
+      "babylon-wtb",
+      "Babylon",
+      "async-fs",
+      "Air",
+      "ai-astar",
+      "acorn-wtb",
+      "3d-raytrace-SP",
+      "3d-cube-SP",
+  )
+
+  @property
+  def substory_duration(self) -> dt.timedelta:
+    return dt.timedelta(seconds=2)
+
+  def setup(self, run: Run) -> None:
+    with run.actions("Setup") as actions:
+      actions.show_url(self.get_run_url(run))
+      if self._substories != self.SUBSTORIES:
+        actions.wait_js_condition(("return JetStream && JetStream.benchmarks "
+                                   "&& JetStream.benchmarks.length > 0;"), 0.1,
+                                  10)
+        actions.js(
+            """
+        let benchmarks = arguments[0];
+        JetStream.benchmarks = JetStream.benchmarks.filter(
+            benchmark => benchmarks.includes(benchmark.name));
+        """,
+            arguments=[self._substories])
+      actions.wait_js_condition(
+          """
+        return document.querySelectorAll("#results>.benchmark").length > 0;
+      """, 1, self.duration + dt.timedelta(seconds=30))
+
+  def run(self, run: Run) -> None:
+    with run.actions("Running") as actions:
+      actions.js("JetStream.start()")
+      actions.wait(self.fast_duration)
+    with run.actions("Waiting for completion") as actions:
+      actions.wait_js_condition(
+          """
+        let summaryElement = document.getElementById("result-summary");
+        return (summaryElement.classList.contains("done"));
+        """,
+          0.5,
+          self.slow_duration,
+          delay=self.substory_duration)
+
+
+ProbeClsTupleT = Tuple[Type[JetStream2Probe], ...]
+
+
+class JetStream2Benchmark(JetStreamBenchmark):
+  pass
diff --git a/crossbench/benchmarks/jetstream/jetstream_2_0.py b/crossbench/benchmarks/jetstream/jetstream_2_0.py
new file mode 100644
index 0000000..f98287c
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/jetstream_2_0.py
@@ -0,0 +1,38 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
+                                                         JetStream2Probe,
+                                                         JetStream2Story,
+                                                         ProbeClsTupleT)
+
+
+class JetStream20Probe(JetStream2Probe):
+  __doc__ = JetStream2Probe.__doc__
+  NAME: str = "jetstream_2.0"
+
+
+class JetStream20Story(JetStream2Story):
+  __doc__ = JetStream2Story.__doc__
+  NAME: str = "jetstream_2.0"
+  URL: str = "https://chromium-workloads.web.app/jetstream/v2.0/"
+  URL_OFFICIAL: str = "https://browserbench.org/JetStream2.0/"
+
+
+class JetStream20Benchmark(JetStream2Benchmark):
+  """
+  Benchmark runner for JetStream 2.0.
+  """
+
+  NAME: str = "jetstream_2.0"
+  DEFAULT_STORY_CLS = JetStream20Story
+  PROBES: ProbeClsTupleT = (JetStream20Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (2, 0)
diff --git a/crossbench/benchmarks/jetstream/jetstream_2_1.py b/crossbench/benchmarks/jetstream/jetstream_2_1.py
new file mode 100644
index 0000000..df63804
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/jetstream_2_1.py
@@ -0,0 +1,38 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
+                                                         JetStream2Probe,
+                                                         JetStream2Story,
+                                                         ProbeClsTupleT)
+
+
+class JetStream21Probe(JetStream2Probe):
+  __doc__ = JetStream2Probe.__doc__
+  NAME: str = "jetstream_2.1"
+
+
+class JetStream21Story(JetStream2Story):
+  __doc__ = JetStream2Story.__doc__
+  NAME: str = "jetstream_2.1"
+  URL: str = "https://chromium-workloads.web.app/jetstream/v2.1/"
+  URL_OFFICIAL: str = "https://browserbench.org/JetStream2.1/"
+
+
+class JetStream21Benchmark(JetStream2Benchmark):
+  """
+  Benchmark runner for JetStream 2.1.
+  """
+
+  NAME: str = "jetstream_2.1"
+  DEFAULT_STORY_CLS = JetStream21Story
+  PROBES: ProbeClsTupleT = (JetStream21Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (2, 1)
diff --git a/crossbench/benchmarks/jetstream/jetstream_2_2.py b/crossbench/benchmarks/jetstream/jetstream_2_2.py
new file mode 100644
index 0000000..902daf3
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/jetstream_2_2.py
@@ -0,0 +1,42 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
+                                                         JetStream2Probe,
+                                                         JetStream2Story,
+                                                         ProbeClsTupleT)
+
+
+class JetStream22Probe(JetStream2Probe):
+  __doc__ = JetStream2Probe.__doc__
+  NAME: str = "jetstream_2.2"
+
+
+class JetStream22Story(JetStream2Story):
+  __doc__ = JetStream2Story.__doc__
+  NAME: str = "jetstream_2.2"
+  URL: str = "https://chromium-workloads.web.app/jetstream/v2.2/"
+  URL_OFFICIAL: str = "https://browserbench.org/JetStream2.2/"
+
+
+class JetStream22Benchmark(JetStream2Benchmark):
+  """
+  Benchmark runner for JetStream 2.2.
+  """
+
+  NAME: str = "jetstream_2.2"
+  DEFAULT_STORY_CLS = JetStream22Story
+  PROBES: ProbeClsTupleT = (JetStream22Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (2, 2)
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("js", "jetstream", "js2", "jetstream_2") + super().aliases()
diff --git a/crossbench/benchmarks/jetstream/jetstream_3.py b/crossbench/benchmarks/jetstream/jetstream_3.py
new file mode 100644
index 0000000..0750f74
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/jetstream_3.py
@@ -0,0 +1,33 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+from typing import Tuple, Type
+
+from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
+                                                         JetStream2Probe,
+                                                         JetStream2Story)
+
+
+# TODO: introduce JetStreamProbe
+class JetStream3Probe(JetStream2Probe, metaclass=abc.ABCMeta):
+  """
+  JetStream3-specific Probe.
+  Extracts all JetStream 3 times and scores.
+  """
+
+
+# TODO: introduce JetStreamStory
+class JetStream3Story(JetStream2Story, metaclass=abc.ABCMeta):
+  SUBSTORIES: Tuple[str, ...] = ()
+
+
+ProbeClsTupleT = Tuple[Type[JetStream3Probe], ...]
+
+
+# TODO: introduce JetStreamBenchmark
+class JetStream3Benchmark(JetStream2Benchmark):
+  pass
diff --git a/crossbench/benchmarks/jetstream/jetstream_3_0.py b/crossbench/benchmarks/jetstream/jetstream_3_0.py
new file mode 100644
index 0000000..67fdf62
--- /dev/null
+++ b/crossbench/benchmarks/jetstream/jetstream_3_0.py
@@ -0,0 +1,127 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.jetstream.jetstream_3 import (JetStream3Benchmark,
+                                                         JetStream3Probe,
+                                                         JetStream3Story,
+                                                         ProbeClsTupleT)
+
+
+class JetStream30Probe(JetStream3Probe):
+  __doc__ = JetStream3Probe.__doc__
+  NAME: str = "jetstream_3.0"
+
+
+class JetStream30Story(JetStream3Story):
+  __doc__ = JetStream3Story.__doc__
+  NAME: str = "jetstream_3.0"
+  URL: str = "https://chromium-workloads.web.app/jetstream/v3.0/"
+  URL_OFFICIAL: str = "https://browserbench.org/JetStream3.0/"
+  SUBSTORIES: Tuple[str, ...] = (
+      "WSL",
+      "UniPoker",
+      "uglify-js-wtb",
+      "typescript",
+      "tsf-wasm",
+      "tfjs-wasm-simd",
+      "tfjs-wasm",
+      "tagcloud-SP",
+      "sync-fs",
+      "string-unpack-code-SP",
+      "stanford-crypto-sha256",
+      "stanford-crypto-pbkdf2",
+      "stanford-crypto-aes",
+      "splay",
+      "segmentation",
+      "richards-wasm",
+      "richards",
+      "regexp",
+      "regex-dna-SP",
+      "raytrace-public-class-fields",
+      "raytrace-private-class-fields",
+      "raytrace",
+      "quicksort-wasm",
+      "proxy-vue",
+      "proxy-mobx",
+      "prepack-wtb",
+      "pdfjs",
+      "OfflineAssembler",
+      "octane-zlib",
+      "octane-code-load",
+      "navier-stokes",
+      "n-body-SP",
+      "multi-inspector-code-load",
+      "ML",
+      "mandreel",
+      "lebab-wtb",
+      "lazy-collections",
+      "json-stringify-inspector",
+      "json-parse-inspector",
+      "jshint-wtb",
+      "js-tokens",
+      "HashSet-wasm",
+      "hash-map",
+      "gcc-loops-wasm",
+      "gbemu",
+      "gaussian-blur",
+      "float-mm.c",
+      "FlightPlanner",
+      "first-inspector-code-load",
+      "espree-wtb",
+      "earley-boyer",
+      "doxbee-promise",
+      "doxbee-async",
+      "delta-blue",
+      "date-format-xparb-SP",
+      "date-format-tofte-SP",
+      "crypto-sha1-SP",
+      "crypto-md5-SP",
+      "crypto-aes-SP",
+      "crypto",
+      "coffeescript-wtb",
+      "chai-wtb",
+      "cdjs",
+      "Box2D",
+      "bomb-workers",
+      "bigint-paillier",
+      "bigint-noble-secp256k1",
+      "bigint-noble-ed25519",
+      "bigint-noble-bls12-381",
+      "bigint-bigdenary",
+      "Basic",
+      "base64-SP",
+      "babylon-wtb",
+      "Babylon",
+      "async-fs",
+      "argon2-wasm-simd",
+      "argon2-wasm",
+      "Air",
+      "ai-astar",
+      "acorn-wtb",
+      "8bitbench-wasm",
+      "3d-raytrace-SP",
+      "3d-cube-SP",
+  )
+
+
+class JetStream30Benchmark(JetStream3Benchmark):
+  """
+  Benchmark runner for JetStream 3.0.
+  """
+
+  NAME: str = "jetstream_3.0"
+  DEFAULT_STORY_CLS = JetStream30Story
+  PROBES: ProbeClsTupleT = (JetStream30Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (3, 0)
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("js3", "jetstream_3") + super().aliases()
diff --git a/crossbench/benchmarks/loading/__init__.py b/crossbench/benchmarks/loading/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/benchmarks/loading/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/benchmarks/loading/config/__init__.py b/crossbench/benchmarks/loading/config/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/benchmarks/loading/config/blocks.py b/crossbench/benchmarks/loading/config/blocks.py
new file mode 100644
index 0000000..f78d9f7
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/blocks.py
@@ -0,0 +1,238 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import datetime as dt
+from typing import (TYPE_CHECKING, Any, Dict, Final, Iterator, List, Optional,
+                    Sequence, Tuple, Type, cast)
+
+from crossbench import exception
+from crossbench.action_runner.action.action import Action
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.all import ACTIONS_TUPLE
+from crossbench.action_runner.action.get import GetAction
+from crossbench.config import ConfigError, ConfigObject, ConfigParser
+from crossbench.parse import NumberParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.benchmarks.loading.page.interactive import InteractivePage
+  from crossbench.runner.run import Run
+
+assert ACTIONS_TUPLE, "import failed"
+
+LOGIN_LABEL: Final[str] = "login"
+
+
+@dataclasses.dataclass(frozen=True)
+class ActionBlock(ConfigObject):
+  label: str = "default"
+  index: int = 0
+  actions: Tuple[Action, ...] = tuple()
+
+  @classmethod
+  def parse_str(cls: Type[ActionBlock], value: str) -> ActionBlock:
+    raise NotImplementedError("Cannot create action blocks from strings")
+
+  @classmethod
+  def parse_other(cls: Type[ActionBlock], value: Any, **kwargs) -> ActionBlock:
+    if isinstance(value, (tuple, list)):
+      return cls.parse_sequence(value, **kwargs)
+    return super().parse_other(value, **kwargs)
+
+  @classmethod
+  def parse_dict(  # pylint: disable=arguments-differ
+      cls: Type,
+      config: Dict[str, Any],
+      label: Optional[str] = None,
+      index: Optional[int] = None):
+    return cls.config_parser().parse(config, label=label, index=index)
+
+  @classmethod
+  def config_parser(cls: Type[ActionBlock]) -> ConfigParser[ActionBlock]:
+    parser = ConfigParser(f"{cls.__name__} parser", cls)
+    parser.add_argument("label", type=cls._parse_block_label, default="default")
+    parser.add_argument(
+        "index", type=NumberParser.positive_zero_int, default=0, required=False)
+    # TODO: enable passing index
+    parser.add_argument("actions", type=Action, required=True, is_list=True)
+    return parser
+
+  @classmethod
+  def parse_sequence(cls: Type[ActionBlock],
+                     config: Sequence[Dict[str, Any]],
+                     label: Optional[str] = None,
+                     index: Optional[int] = None) -> ActionBlock:
+    with exception.annotate_argparsing(
+        "Parsing default block action sequence:"):
+      return cls.parse_dict({"actions": config}, label=label, index=index)
+
+  @classmethod
+  def _parse_block_label(cls, value: Any) -> Optional[str]:
+    if not value:
+      return None
+    label = ObjectParser.non_empty_str(value)
+    if label == LOGIN_LABEL:
+      raise ConfigError(
+          f"Block label {repr(label)} is reserved for login blocks")
+    return value
+
+  def validate(self) -> None:
+    super().validate()
+    self.validate_actions()
+
+  def validate_actions(self) -> None:
+    ObjectParser.non_empty_sequence(self.actions, "actions")
+    # TODO: enable validating action indices
+    # for index, action in enumerate(self.actions):
+    #   if index != action.index:
+    #     raise ValueError(
+    #         f"action[{index}].index should be {index}, "
+    #         f"but got {action.index}")
+    if not self.actions:
+      raise argparse.ArgumentTypeError("Invalid block without actions")
+
+  def run_with(self, runner: ActionRunner, run: Run,
+               page: InteractivePage) -> None:
+    del page
+    runner.run_block(run, self)
+
+  def to_json(self) -> Dict[str, Any]:
+    return {
+        "label": self.label,
+        "actions": [action.to_json() for action in self.actions]
+    }
+
+  @property
+  def duration(self) -> dt.timedelta:
+    total_duration = dt.timedelta()
+    for action in self.actions:
+      if duration := action.duration:
+        total_duration += duration
+    return total_duration
+
+  @property
+  def is_login(self) -> bool:
+    return False
+
+  def __iter__(self) -> Iterator[Action]:
+    yield from self.actions
+
+  def __len__(self) -> int:
+    return len(self.actions)
+
+  @property
+  def first_url(self) -> str:
+    for action in self.actions:
+      if action.TYPE == ActionType.GET:
+        return cast(GetAction, action).url
+    raise RuntimeError("No GET action with an URL found.")
+
+
+@dataclasses.dataclass(frozen=True)
+class ActionBlockListConfig(ConfigObject):
+  blocks: Tuple[ActionBlock, ...] = tuple()
+
+  def to_argument_value(self) -> Tuple[ActionBlock, ...]:
+    return self.blocks
+
+  @classmethod
+  def parse_other(cls: Type[ActionBlockListConfig],
+                  value: Any) -> ActionBlockListConfig:
+    if isinstance(value, (tuple, list)):
+      return cls.parse_sequence(value)
+    return super().parse_other(value)
+
+  @classmethod
+  def parse_sequence(cls: Type[ActionBlockListConfig],
+                     config: Sequence[Dict[str, Any]]) -> ActionBlockListConfig:
+    """Parse either a sequence of blocks or a sequence of actions for an
+    implicit default block.
+
+    Blocks:
+    [{ "label": "block 1", "actions": [...]}, ... ]
+    [ "block 1": [{ "action": ...}, ...], "block 2": [ ... ] ]
+
+    Default block actions:
+    [{ "action": "get", ...}, { "action": ...}, ...]
+    """
+    config = ObjectParser.non_empty_sequence(config, "actions")
+    info = "action block"
+    if cls._is_default_block_actions(config):
+      info = "default actions"
+      config = [{"actions": config}]
+    if not cls._is_block_sequence_config(config):
+      raise ValueError(
+          "Invalid data: Expected a list of either blocks or actions.")
+
+    def block_config_data_gen():
+      for index, block_config in enumerate(config):
+        with exception.annotate_argparsing(f"Parsing {info} ...[{index}]"):
+          block_config = ObjectParser.dict(block_config, f"blocks[{index}]")
+          label = block_config.get("label")
+          yield index, label, block_config
+
+    return cls._parse_blocks(block_config_data_gen())
+
+  @classmethod
+  def _is_block_sequence_config(cls, config: Sequence[Dict[str, Any]]) -> bool:
+    return "label" in config[0] or "actions" in config[0]
+
+  @classmethod
+  def _is_default_block_actions(cls, config: Sequence[Dict[str, Any]]) -> bool:
+    sample = config[0]
+    return isinstance(sample, str) or "action" in sample
+
+  @classmethod
+  def parse_dict(cls: Type[ActionBlockListConfig],
+                 config: Dict[str, Any]) -> ActionBlockListConfig:
+    config = ObjectParser.non_empty_dict(config, "blocks")
+
+    def block_config_data_gen():
+      for index, (label, block_data) in enumerate(config.items()):
+        with exception.annotate_argparsing(
+            f"Parsing action block  ...[{label}]"):
+          yield index, label, block_data
+
+    return cls._parse_blocks(block_config_data_gen())
+
+  @classmethod
+  def _parse_blocks(cls, block_config_data_gen) -> ActionBlockListConfig:
+    blocks: List[ActionBlock] = []
+    for index, label, block_data in block_config_data_gen:
+      block = cls._parse_block(index, label, block_data)
+      blocks.append(block)
+    return cls(tuple(blocks))
+
+  @classmethod
+  def _parse_block(cls, index: int, label: str, block_data: Any) -> ActionBlock:
+    if isinstance(block_data, dict):
+      # Early warning for better usability.
+      if inner_label := block_data.get("label"):
+        if inner_label != label:
+          raise ConfigError(
+              "ActionBlock inside a dict cannot have a 'label' property, "
+              f"but got label={repr(inner_label)}")
+    return ActionBlock.parse(block_data, label=label, index=index)
+
+  @classmethod
+  def parse_str(cls, value: str) -> ActionBlockListConfig:
+    raise NotImplementedError("Cannot create action blocks from strings")
+
+  def validate(self) -> None:
+    super().validate()
+    if not self.blocks:
+      raise ValueError("Missing action blocks.")
+    ObjectParser.non_empty_sequence(self.blocks, "blocks")
+    found_get = False
+    for index, block in enumerate(self.blocks):
+      if index != block.index:
+        raise ValueError(
+            f"blocks[{index}].index should be {index}, but got {block.index}")
+      found_get |= any(action.TYPE == ActionType.GET for action in block)
+    if not found_get:
+      raise ValueError("Expected at least one get action in one of the blocks.")
diff --git a/crossbench/benchmarks/loading/config/login/__init__.py b/crossbench/benchmarks/loading/config/login/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/login/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/benchmarks/loading/config/login/base.py b/crossbench/benchmarks/loading/config/login/base.py
new file mode 100644
index 0000000..041219b
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/login/base.py
@@ -0,0 +1,61 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+from typing import TYPE_CHECKING, Final
+
+from crossbench.benchmarks.loading.config.blocks import ActionBlock
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.loading.page.interactive import InteractivePage
+  from crossbench.cli.config.secrets import Secret, SecretType
+  from crossbench.runner.run import Run
+
+
+class BaseLoginBlock(ActionBlock):
+  LABEL: Final[str] = "login"
+
+  def validate(self) -> None:
+    super().validate()
+    assert self.index == 0, (
+        f"Login block has to be the first, but got {self.index}")
+
+  @property
+  def is_login(self) -> bool:
+    return True
+
+  def get_secret(
+      self,
+      run: Run,
+      page: InteractivePage,
+      type: SecretType  # pylint: disable=redefined-builtin
+  ) -> Secret:
+    logging.debug("Looking up secrets {%s} for page %s", type, page)
+    if secret := page.secrets.get(type):
+      return secret
+    if secret := run.browser.secrets.get(type):
+      return secret
+    raise LookupError(f"Could not find any secret for {repr(str(type))} "
+                      f"on {page} or on {run.browser}")
+
+  def is_logged_in(self,
+                   run: Run,
+                   secret: Secret,
+                   strict: bool = False) -> bool:
+    return run.browser.is_logged_in(secret, strict)
+
+
+class PresetLoginBlock(BaseLoginBlock):
+
+  def validate_actions(self) -> None:
+    """Skip validation, since PresetLoginBlocks have an unknown number
+    of actions."""
+
+  def __len__(self) -> int:
+    """LoginBlocks will have at least one action. Given they're not known
+    upfront we set this to 1. This also ensures that bool(login_block) is
+    True."""
+    return 1
diff --git a/crossbench/benchmarks/loading/config/login/custom.py b/crossbench/benchmarks/loading/config/login/custom.py
new file mode 100644
index 0000000..96a9d50
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/login/custom.py
@@ -0,0 +1,20 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+
+from crossbench.benchmarks.loading.config.login.base import BaseLoginBlock
+from crossbench.benchmarks.loading.config.login.login_type import (LOGIN_LOOKUP,
+                                                                   LoginType)
+
+
+@dataclasses.dataclass(frozen=True)
+class LoginBlock(BaseLoginBlock):
+
+  @classmethod
+  def parse_str(cls, value: str) -> BaseLoginBlock:
+    login_type = LoginType.parse(value)
+    return LOGIN_LOOKUP[login_type]()
diff --git a/crossbench/benchmarks/loading/config/login/google.py b/crossbench/benchmarks/loading/config/login/google.py
new file mode 100644
index 0000000..aced045
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/login/google.py
@@ -0,0 +1,75 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench.benchmarks.loading.config.login.base import PresetLoginBlock
+from crossbench.cli.config.secret_type import SecretType
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.benchmarks.loading.page.interactive import InteractivePage
+  from crossbench.cli.config.secrets import Secret
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.run import Run
+
+GOOGLE_LOGIN_URL: str = (
+    "https://accounts.google.com/Logout?"
+    "continue=https%3A%2F%2Faccounts.google.com%2Fv3%2Fsignin%2Fidentifier%3F"
+    "flowName%3DGlifWebSignIn%26flowEntry%3DServiceLogin")
+
+TRUSTED_EMAIL_CHECK: str = (
+    "return document.getElementById('verifycontactNext') != null")
+
+
+class GoogleLogin(PresetLoginBlock):
+  """Google-specific login steps."""
+
+  def _submit_login_field(self, action: Actions, aria_label: str,
+                          input_val: str, button_name: str) -> None:
+    action.wait_js_condition(
+        ("return "
+         f"document.querySelector(\"[aria-label='{aria_label}']\") != null &&"
+         f"document.getElementById({repr(button_name)}) != null;"), 0.2, 10)
+    action.js("const inputField ="
+              f" document.querySelector(\"[aria-label='{aria_label}']\");"
+              f"inputField.value = {repr(input_val)};"
+              f"document.getElementById({repr(button_name)}).click();")
+
+  def run_with(self, runner: ActionRunner, run: Run,
+               page: InteractivePage) -> None:
+    secret: Secret = self.get_secret(run, page, SecretType.GOOGLE)
+
+    if self.is_logged_in(run, secret, strict=True):
+      return
+
+    with run.actions("Login", measure=False) as action:
+      action.show_url(GOOGLE_LOGIN_URL)
+      self._submit_login_field(action, "Email or phone", secret.username,
+                               "identifierNext")
+      action.wait_js_condition(
+          "return document.getElementById('verifycontactNext') || "
+          "document.getElementById('passwordNext') != null;", 0.2, 10)
+      if action.js(TRUSTED_EMAIL_CHECK):
+        self._test_account_login(action, secret)
+      else:
+        self._standard_login(action, secret)
+
+  def _standard_login(self, action, secret):
+    self._submit_login_field(action, "Enter your password", secret.password,
+                             "passwordNext")
+    action.wait_js_condition(
+        "return document.URL.startsWith('https://myaccount.google.com');", 0.2,
+        10)
+
+  def _test_account_login(self, action, secret):
+    self._submit_login_field(action, "Enter trusted contact\\s email",
+                             secret.password, "verifycontactNext")
+    # TODO: handle account passkey setup, for now each test account needs a
+    # one time manual interaction.
+    action.wait_js_condition(
+        "return document.URL.startsWith('https://myaccount.google.com')", 0.2,
+        60)
diff --git a/crossbench/benchmarks/loading/config/login/login_type.py b/crossbench/benchmarks/loading/config/login/login_type.py
new file mode 100644
index 0000000..c5713f8
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/login/login_type.py
@@ -0,0 +1,24 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+from typing import TYPE_CHECKING, Dict, Type
+
+from crossbench.benchmarks.loading.config.login.google import GoogleLogin
+from crossbench.config import ConfigEnum
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.loading.config.login.base import BaseLoginBlock
+
+
+@enum.unique
+class LoginType(ConfigEnum):
+  GOOGLE = ("google", "Login for google properties")
+
+
+LOGIN_LOOKUP: Dict[LoginType, Type[BaseLoginBlock]] = {
+    LoginType.GOOGLE: GoogleLogin
+}
diff --git a/crossbench/benchmarks/loading/config/page.py b/crossbench/benchmarks/loading/config/page.py
new file mode 100644
index 0000000..7d5771f
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/page.py
@@ -0,0 +1,142 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+import datetime as dt
+from typing import (TYPE_CHECKING, Any, Dict, Iterator, Optional, Sequence,
+                    Tuple, Type, cast)
+from urllib import parse as urlparse
+
+from crossbench import path as pth
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.get import GetAction
+from crossbench.benchmarks.loading.config.blocks import (ActionBlock,
+                                                         ActionBlockListConfig)
+from crossbench.benchmarks.loading.config.login.custom import LoginBlock
+from crossbench.benchmarks.loading.page.live import PAGES
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.config import ConfigObject, ConfigParser
+from crossbench.parse import DurationParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.action.action import Action
+
+
+@dataclasses.dataclass(frozen=True)
+class PageConfig(ConfigObject):
+  label: Optional[str] = None
+  playback: Optional[PlaybackController] = None
+  secrets: SecretsConfig = SecretsConfig()
+  login: Optional[LoginBlock] = None
+  setup: Optional[ActionBlock] = None
+  blocks: Tuple[ActionBlock, ...] = tuple()
+
+  @classmethod
+  def parse_other(cls: Type[PageConfig], value: Any, **kwargs) -> PageConfig:
+    if isinstance(value, (list, tuple)):
+      return cls.parse_sequence(value, **kwargs)
+    return super().parse_other(value)
+
+  @classmethod
+  def parse_str(  # pylint: disable=arguments-differ
+      cls: Type[PageConfig],
+      value: str,
+      label: Optional[str] = None) -> PageConfig:
+    """
+    Simple comma-separated string with optional duration:
+      value = URL,[DURATION]
+    """
+    parts = value.rsplit(",", maxsplit=1)
+    duration = dt.timedelta()
+    raw_url: str = parts[0]
+    if raw_url in PAGES:
+      url = PAGES[raw_url].url
+      label = label or raw_url
+    else:
+      url = ObjectParser.parse_fuzzy_url_str(raw_url)
+    if len(parts) == 2:
+      duration = DurationParser.positive_duration(parts[1])
+    return cls.from_url(label, url, duration)
+
+  @classmethod
+  def parse_sequence(cls: Type[PageConfig],
+                     value: Sequence[Any],
+                     label: Optional[str] = None,
+                     secrets: Optional[SecretsConfig] = None) -> PageConfig:
+    value = ObjectParser.non_empty_sequence(value, "story actions or blocks")
+    blocks = ActionBlockListConfig.parse_sequence(value)
+    if label is not None:
+      label = ObjectParser.non_empty_str(label, "label")
+    secrets = secrets or SecretsConfig()
+    return cls(label, secrets=secrets, blocks=blocks.blocks)
+
+  @classmethod
+  def parse_dict(  # pylint: disable=arguments-differ
+      cls: Type[PageConfig],
+      config: Dict[str, Any],
+      label: Optional[str] = None,
+      secrets: Optional[SecretsConfig] = None) -> PageConfig:
+    config = ObjectParser.non_empty_dict(config, "story actions or blocks")
+    page_config = cls.config_parser().parse(
+        config, label=label, secrets=secrets)
+    return page_config
+
+  @classmethod
+  def config_parser(cls: Type[PageConfig]) -> ConfigParser[PageConfig]:
+    parser = ConfigParser(f"{cls.__name__} parser", cls)
+    parser.add_argument("label", type=ObjectParser.non_empty_str)
+    parser.add_argument("playback", type=PlaybackController.parse)
+    parser.add_argument("secrets", type=SecretsConfig, default=SecretsConfig())
+    parser.add_argument("login", type=LoginBlock)
+    parser.add_argument("setup", type=ActionBlock)
+    parser.add_argument(
+        "blocks",
+        aliases=("actions", "url", "urls"),
+        type=ActionBlockListConfig)
+    return parser
+
+  @classmethod
+  def from_url(cls,
+               label: Optional[str],
+               url: str,
+               duration: dt.timedelta = dt.timedelta()) -> PageConfig:
+    actions = (GetAction(url, duration=duration),)
+    blocks = (ActionBlock(actions=actions),)
+    return PageConfig(label=label, blocks=blocks)
+
+  def actions(self) -> Iterator[Action]:
+    for block in self.blocks:
+      yield from block
+
+  @property
+  def duration(self) -> dt.timedelta:
+    return sum((action.duration for action in self.actions()), dt.timedelta())
+
+  @property
+  def any_label(self) -> str:
+    return self.label or self.url_label
+
+  @property
+  def url_label(self) -> str:
+    url = urlparse.urlparse(self.first_url)
+    if url.scheme == "about":
+      return url.path
+    if url.scheme == "file":
+      return pth.LocalPath(url.path).name
+    if hostname := url.hostname:
+      if hostname.startswith("www."):
+        return hostname[len("www."):]
+      return hostname
+    return str(url)
+
+  @property
+  def first_url(self) -> str:
+    for action in self.actions():
+      if action.TYPE == ActionType.GET:
+        return cast(GetAction, action).url
+    raise RuntimeError("No GET action with an URL found.")
diff --git a/crossbench/benchmarks/loading/config/pages.py b/crossbench/benchmarks/loading/config/pages.py
new file mode 100644
index 0000000..0b072ac
--- /dev/null
+++ b/crossbench/benchmarks/loading/config/pages.py
@@ -0,0 +1,265 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import datetime as dt
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    Type)
+
+from crossbench import exception
+from crossbench import path as pth
+from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.enums import ReadyState
+from crossbench.action_runner.action.get import GetAction
+from crossbench.action_runner.action.wait import WaitAction
+from crossbench.benchmarks.loading.config.blocks import ActionBlock
+from crossbench.benchmarks.loading.config.page import PageConfig
+from crossbench.benchmarks.loading.input_source import InputSource
+from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.config import ConfigObject
+from crossbench.parse import DurationParseError, DurationParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.action.action import Action
+
+
+@dataclasses.dataclass(frozen=True)
+class PagesConfig(ConfigObject):
+  pages: Tuple[PageConfig, ...] = ()
+  secrets: Optional[SecretsConfig] = None
+
+  def validate(self) -> None:
+    super().validate()
+    for index, page in enumerate(self.pages):
+      assert isinstance(page, PageConfig), (
+          f"pages[{index}] is not a PageConfig but {type(page).__name__}")
+
+  @classmethod
+  def parse_str(cls, value: str) -> PagesConfig:
+    """
+    Simple comma-separate config:
+    value = URL, [DURATION], ...
+    """
+    values: List[str] = []
+    previous_part: Optional[str] = None
+    for part in value.strip().split(","):
+      part = ObjectParser.non_empty_str(part, "url or duration")
+      try:
+        DurationParser.positive_duration(part)
+        if not previous_part:
+          raise argparse.ArgumentTypeError(
+              "Duration can only follow after url. "
+              f"Current value: {repr(part)}")
+        values[-1] = f"{previous_part},{part}"
+        previous_part = None
+      except DurationParseError:
+        previous_part = part
+        values.append(part)
+    return cls.parse_sequence(values)
+
+  @classmethod
+  def parse_unknown_path(cls, path: pth.LocalPath, **kwargs) -> PagesConfig:
+    # Make sure we get errors for invalid files.
+    return cls.parse_config_path(path, **kwargs)
+
+  @classmethod
+  def parse_other(cls, value: Any, **kwargs) -> PagesConfig:
+    if isinstance(value, (list, tuple)):
+      return cls.parse_sequence(value, **kwargs)
+    return super().parse_other(value, **kwargs)
+
+  @classmethod
+  def parse_sequence(cls, values: Sequence[str]) -> PagesConfig:
+    """
+    Variant a): List of comma-separate URLs
+      [ "URL,[DURATION]", ... ]
+    """
+    # TODO: support parsing a list of PageConfig dicts
+    if not values:
+      raise argparse.ArgumentTypeError("Got empty page list.")
+    pages: List[PageConfig] = []
+    for index, single_line_config in enumerate(values):
+      with exception.annotate_argparsing(
+          f"Parsing pages[{index}]: {repr(single_line_config)}"):
+        pages.append(PageConfig.parse_str(single_line_config))
+    return PagesConfig(pages=tuple(pages))
+
+  @classmethod
+  def parse_dict(cls, config: Dict) -> PagesConfig:
+    """
+    Variant a):
+      { "pages": { "LABEL": PAGE_CONFIG }, "secrets": { ... } }
+    """
+    with exception.annotate_argparsing("Parsing stories"):
+      if "pages" not in config:
+        raise argparse.ArgumentTypeError(
+            "Config does not provide a 'pages' dict.")
+      secrets: Optional[SecretsConfig] = None
+      if secrets_data := config.get("secrets"):
+        secrets = SecretsConfig.parse(secrets_data)
+      pages_config = ObjectParser.non_empty_dict(config["pages"], "pages")
+      with exception.annotate_argparsing("Parsing config 'pages'"):
+        pages = cls._parse_pages(pages_config, secrets)
+        return PagesConfig(pages, secrets)
+    raise exception.UnreachableError()
+
+  @classmethod
+  def _parse_pages(
+      cls,
+      data: Dict[str, Any],
+      secrets: Optional[SecretsConfig] = None) -> Tuple[PageConfig, ...]:
+    pages = []
+    for name, page_config in data.items():
+      with exception.annotate_argparsing(f"Parsing story ...['{name}']"):
+        # TODO: fix secrets on the inner page and on the outer pages config
+        page = PageConfig.parse(page_config, label=name, secrets=secrets)
+        pages.append(page)
+    return tuple(pages)
+
+
+class DevToolsRecorderPagesConfig(PagesConfig):
+
+  @classmethod
+  def parse_str(cls: Type[PagesConfig], value: str) -> PagesConfig:
+    raise NotImplementedError()
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> DevToolsRecorderPagesConfig:
+    config = ObjectParser.non_empty_dict(config)
+    with exception.annotate_argparsing("Loading DevTools recording file"):
+      title = ObjectParser.non_empty_str(config["title"], "title")
+      actions = cls._parse_steps(config["steps"])
+      # Use default block
+      blocks = (ActionBlock(actions=actions),)
+      pages = (PageConfig(label=title, blocks=blocks),)
+      return DevToolsRecorderPagesConfig(pages)
+    raise exception.UnreachableError()
+
+  @classmethod
+  def _parse_steps(cls, steps: List[Dict[str, Any]]) -> Tuple[Action, ...]:
+    actions: List[Action] = []
+    for step in steps:
+      if maybe_actions := cls.parse_step(step):
+        actions.extend(maybe_actions)
+        # TODO(cbruni): make this configurable
+        actions.append(WaitAction(duration=dt.timedelta(seconds=1)))
+    return tuple(actions)
+
+  @classmethod
+  def parse_step(cls, step: Dict[str, Any]) -> List[Action]:
+    step_type: str = step["type"]
+    default_timeout = dt.timedelta(seconds=10)
+    if step_type == "navigate":
+      return [cls._parse_navigate_step(step, default_timeout)]
+    if step_type == "click":
+      return [cls._parse_click_step(step, default_timeout)]
+    if step_type == "setViewport":
+      # Resizing is ignored for now.
+      return []
+    raise ValueError(f"Unsupported step: {step_type}")
+
+  @classmethod
+  def _parse_navigate_step(cls, step: Dict[str, Any],
+                           default_timeout: dt.timedelta) -> Action:
+    del default_timeout
+    return GetAction(  # type: ignore
+        step["url"], ready_state=ReadyState.COMPLETE)
+
+  @classmethod
+  def _parse_click_step(cls, step: Dict[str, Any],
+                        default_timeout: dt.timedelta) -> Action:
+    selector = cls._parse_selectors(step["selectors"])
+    return ClickAction(
+        InputSource.JS,
+        selector=selector,
+        scroll_into_view=True,
+        timeout=default_timeout)
+
+  @classmethod
+  def _parse_selectors(cls, selectors: List[List[str]]) -> str:
+    xpath: Optional[str] = None
+    aria: Optional[str] = None
+    text: Optional[str] = None
+    css: Optional[str] = None
+    # Detect all single-element selectors first.
+    for selector_list in selectors:
+      if len(selector_list) != 1:
+        continue
+      selector_candidate = selector_list[0]
+      if not aria and selector_candidate.startswith("aria/"):
+        aria = selector_candidate
+      elif not xpath and selector_candidate.startswith("xpath//"):
+        xpath = selector_candidate
+      elif not text and selector_candidate.startswith("css/"):
+        css = selector_candidate
+      elif not text and selector_candidate.startswith("text/"):
+        text = selector_candidate
+      elif not text and selector_candidate.startswith("pierce/"):
+        # not supported yet.
+        pass
+      else:
+        css = f"css/{selector_candidate}"
+
+    if xpath:
+      assert xpath.startswith("xpath/")
+      return xpath
+    if css:
+      _, css = css.split("css/", maxsplit=1)
+      return css
+    if aria:
+      _, aria = aria.split("aria/", maxsplit=1)
+      return f"[aria-label={repr(aria)}]"
+    if text:
+      _, text = text.split("text/", maxsplit=1)
+      return f"xpath///*[text()={repr(text)}]"
+
+    raise ValueError("Need at least one single element xpath or aria "
+                     "selector for click action")
+
+
+class ListPagesConfig(PagesConfig):
+
+  VALID_EXTENSIONS: Tuple[str, ...] = (".txt", ".list")
+
+  @classmethod
+  def parse_str(cls, value: str) -> PagesConfig:
+    raise argparse.ArgumentTypeError(
+        f"URL list file {repr(value)} does not exist.")
+
+  @classmethod
+  def parse_path(cls, path: pth.LocalPath, **kwargs) -> PagesConfig:
+    assert not kwargs, f"{cls.__name__} does not support extra kwargs"
+    pages: List[PageConfig] = []
+    with exception.annotate_argparsing(f"Loading Pages list file: {path.name}"):
+      line: int = 0
+      with path.open() as f:
+        for single_line_config in f.readlines():
+          with exception.annotate_argparsing(f"Parsing line {line}"):
+            line += 1
+            single_line_config = single_line_config.strip()
+            if not single_line_config:
+              logging.warning("Skipping empty line %s", line)
+              continue
+            pages.append(PageConfig.parse(single_line_config))
+    return PagesConfig(pages=tuple(pages))
+
+  @classmethod
+  def parse_dict(cls, config: Dict) -> PagesConfig:
+    config = ObjectParser.non_empty_dict(config, "pages")
+    with exception.annotate_argparsing("Parsing scenarios / pages"):
+      if "pages" not in config:
+        raise argparse.ArgumentTypeError(
+            "Config does not provide a 'pages' dict.")
+      pages = config["pages"]
+      if isinstance(pages, str):
+        pages = [pages]
+      if not isinstance(pages, (list, tuple)):
+        raise argparse.ArgumentTypeError(
+            f"Expected list/tuple for pages, but got {type(pages)}")
+      return cls.parse_sequence(pages)
+    raise exception.UnreachableError()
diff --git a/crossbench/benchmarks/loading/input_source.py b/crossbench/benchmarks/loading/input_source.py
new file mode 100644
index 0000000..1720234
--- /dev/null
+++ b/crossbench/benchmarks/loading/input_source.py
@@ -0,0 +1,15 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import enum
+
+from crossbench.config import ConfigEnum
+
+
+@enum.unique
+class InputSource(ConfigEnum):
+  JS = ("js", "Inject a script into the webpage to simulate the action.")
+  TOUCH = ("touch", "Use the touchscreen to perform the action")
+  MOUSE = ("mouse", "Use the mouse to perform the action")
+  KEYBOARD = ("keyboard", "Use the keyboard to perform the action")
diff --git a/crossbench/benchmarks/loading/loading_benchmark.py b/crossbench/benchmarks/loading/loading_benchmark.py
new file mode 100644
index 0000000..52c3c43
--- /dev/null
+++ b/crossbench/benchmarks/loading/loading_benchmark.py
@@ -0,0 +1,352 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    Type)
+
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.config import ActionRunnerConfig
+from crossbench.benchmarks.base import StoryFilter, SubStoryBenchmark
+from crossbench.benchmarks.loading.config.pages import (
+    DevToolsRecorderPagesConfig, ListPagesConfig, PageConfig, PagesConfig)
+from crossbench.benchmarks.loading.page.base import DEFAULT_DURATION, Page
+from crossbench.benchmarks.loading.page.combined import CombinedPage
+from crossbench.benchmarks.loading.page.interactive import InteractivePage
+from crossbench.benchmarks.loading.page.live import (PAGE_LIST,
+                                                     PAGE_LIST_SMALL, PAGES,
+                                                     LivePage)
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.benchmarks.loading.tab_controller import TabController
+from crossbench.parse import DurationParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.cli.parser import CrossBenchArgumentParser
+  from crossbench.stories.story import Story
+
+
+class LoadingPageFilter(StoryFilter[Page]):
+  """
+  Filter / create loading stories
+
+  Syntax:
+    "name"            Include LivePage with the given name from predefined list.
+    "name", 10        Include predefined page with given 10s timeout.
+    "http://..."      Include custom page at the given URL with a default
+                      timeout of 15 seconds.
+    "http://...", 12  Include custom page at the given URL with a 12s timeout
+
+  These patterns can be combined:
+    ["http://foo.com", 5, "http://bar.co.jp", "amazon"]
+  """
+  stories: Sequence[Page]
+
+  @classmethod
+  def add_cli_parser(
+      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser = super().add_cli_parser(parser)
+    cls.add_page_config_parser(parser)
+    tab_group = parser.add_mutually_exclusive_group()
+    tab_group.add_argument(
+        "--single-tab",
+        dest="tabs",
+        const=TabController.single(),
+        default=TabController.default(),
+        action="store_const",
+        help="Open given urls in a single tab.")
+    tab_group.add_argument(
+        "--multiple-tab",
+        dest="tabs",
+        nargs="?",
+        type=TabController.parse,
+        const=TabController.multiple(),
+        help="Open given urls in separate tabs "
+        "(optional value for number of tabs for each url).")
+    tab_group.add_argument(
+        "--infinite-tab",
+        dest="tabs",
+        const=TabController.forever(),
+        action="store_const",
+        help="Open given urls in separate tabs infinitely.")
+
+    playback_group = parser.add_mutually_exclusive_group()
+    playback_group.add_argument(
+        "--playback",
+        "--cycle",
+        type=PlaybackController.parse,
+        default=PlaybackController.default(),
+        help="Set limit on looping through/repeating the selected stories. "
+        "Default is once."
+        "Valid values are: 'once', 'forever', number, time. "
+        "Cycle 10 times: '--playback=10x'. "
+        "Repeat for 1.5 hours: '--playback=1.5h'.")
+    playback_group.add_argument(
+        "--forever",
+        dest="playback",
+        const=PlaybackController.forever(),
+        action="store_const",
+        help="Equivalent to --playback=infinity")
+
+    parser.add_argument(
+        "--about-blank-duration",
+        "--about-blank",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help="If non-zero, navigate to about:blank after every page.")
+
+    block_modifier_group = parser.add_argument_group("Action Block Options")
+    block_modifier_group.add_argument(
+        "--skip-login",
+        dest="run_login",
+        default=True,
+        action="store_const",
+        const=False,
+        help="Skip the login block, useful for replaying "
+        "archive that filtered already all login requests "
+        "to hide potential secrets. "
+        "The login block is run by default.")
+    block_modifier_group.add_argument(
+        "--skip-setup",
+        dest="run_setup",
+        default=True,
+        action="store_const",
+        const=False,
+        help="Skip the setup block, useful for replaying "
+        "archive that filtered already all login requests "
+        "to hide potential secrets. "
+        "The setup block is run by default.")
+
+    return parser
+
+  @classmethod
+  def add_page_config_parser(cls, parser) -> None:
+    page_config_group = parser.add_mutually_exclusive_group()
+    # TODO: move --stories into mutually exclusive group as well
+    page_config_group.add_argument(
+        "--urls",
+        "--url",
+        dest="urls",
+        help="List of urls and durations to load: url,seconds,...")
+    page_config_group.add_argument(
+        "--page-config",
+        "--pages-config",
+        dest="pages_config",
+        type=PagesConfig.parse,
+        help="Stories we want to perform in the benchmark run following a"
+        "specified scenario. For a reference on how to build scenarios and"
+        "possible actions check config/doc/pages.config.hjson")
+    page_config_group.add_argument(
+        "--url-file",
+        "--urls-file",
+        dest="pages_config",
+        type=ListPagesConfig.parse,
+        help=("List of urls and durations in a line-by-line file. "
+              "Each line has the same format as --url for a single Page."))
+    page_config_group.add_argument(
+        "--devtools-recorder",
+        dest="pages_config",
+        type=DevToolsRecorderPagesConfig.parse,
+        help="Run a single story from a serialized DevTools recorder session. "
+        "See https://developer.chrome.com/docs/devtools/recorder/ "
+        "for more details.")
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["separate"] = args.separate
+    kwargs["args"] = args
+    return kwargs
+
+  def __init__(self,
+               story_cls: Type[Page],
+               patterns: Sequence[str],
+               args: argparse.Namespace,
+               separate: bool = True) -> None:
+    self._args: argparse.Namespace = args
+    super().__init__(story_cls, patterns, separate)
+
+  def process_all(self, patterns: Sequence[str]) -> None:
+    name_or_url_list = patterns
+    if len(name_or_url_list) == 1:
+      if name_or_url_list[0] == "all":
+        self.stories = self.all_stories()
+        return
+      if name_or_url_list[0] == "default":
+        self.stories = self.default_stories()
+        return
+    # Let the PageConfig handle the arg splitting again:
+    config = PagesConfig.parse(",".join(patterns))
+    self.stories = self.stories_from_config(self._args, config)
+
+  @classmethod
+  def all_stories(cls) -> Tuple[Page, ...]:
+    return tuple(PAGE_LIST)
+
+  @classmethod
+  def default_stories(cls) -> Tuple[Page, ...]:
+    return PAGE_LIST_SMALL
+
+  @classmethod
+  def stories_from_config(cls, args: argparse.Namespace,
+                          config: PagesConfig) -> Sequence[Page]:
+    labels = set(page_config.label for page_config in config.pages)
+    use_labels = len(labels) == len(config.pages)
+
+    stories: List[Page] = []
+    for page_config in config.pages:
+      stories.append(cls._story_from_config(args, page_config, use_labels))
+
+    if use_labels:
+      # Double check that the urls are unique
+      urls = set(page_config.first_url for page_config in config.pages)
+      if len(urls) != len(config.pages):
+        raise argparse.ArgumentTypeError(
+            "Got non-unique story labels and urls.")
+    return stories
+
+  @classmethod
+  def _story_from_config(cls, args: argparse.Namespace, config: PageConfig,
+                         use_labels: bool) -> Page:
+    playback: PlaybackController = args.playback
+    tabs: TabController = args.tabs
+    if config.playback:
+      # TODO: support custom config playback
+      playback = config.playback
+    duration: dt.timedelta = config.duration
+    if config.label in PAGES:
+      page = PAGES[config.label]
+      duration = duration or page.duration
+      return LivePage(page.name, page.url, duration, playback, tabs,
+                      args.about_blank_duration)
+
+    label: str = config.any_label if use_labels else config.first_url
+    duration = duration or DEFAULT_DURATION
+
+    if not config.blocks:
+      return LivePage(label, config.first_url, duration, playback, tabs,
+                      args.about_blank_duration)
+    return InteractivePage(label, config.blocks, config.setup, config.login,
+                           config.secrets.as_dict(), playback, tabs,
+                           args.about_blank_duration, args.run_login,
+                           args.run_setup)
+
+  def create_stories(self, separate: bool) -> Sequence[Page]:
+    logging.info("SELECTED STORIES: %s", str(list(map(str, self.stories))))
+    if not separate and len(self.stories) > 1:
+      combined_name = "_".join(page.name for page in self.stories)
+      self.stories = (CombinedPage(self.stories, combined_name,
+                                   self._args.playback, self._args.tabs),)
+    return self.stories
+
+
+class PageLoadBenchmark(SubStoryBenchmark):
+  """
+  Benchmark runner for loading pages.
+
+  Use --urls/--stories to either choose from an existing set of pages, or direct
+  URLs. After each page you can also specify a custom wait/load duration in
+  seconds. Multiple URLs/page names can be provided as a comma-separated list.
+
+  Use --separate to load each page individually.
+
+  Example:
+    --urls=amazon
+    --urls=http://cnn.com,10s
+    --urls=http://twitter.com,5s,http://cnn.com,10s
+  """
+  NAME = "loading"
+  DEFAULT_STORY_CLS = Page
+  STORY_FILTER_CLS = LoadingPageFilter
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
+  ) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    cls.STORY_FILTER_CLS.add_cli_parser(parser)
+
+    parser.add_argument(
+        "--action-runner",
+        type=ActionRunnerConfig.parse,
+        help="Set the action runner for interactive pages.")
+    return parser
+
+  @classmethod
+  def requires_separate(cls, args: argparse.Namespace) -> bool:
+    return args.separate
+
+  @classmethod
+  def stories_from_cli_args(cls, args: argparse.Namespace) -> Sequence[Story]:
+    has_default_stories: bool = args.stories and args.stories == "default"
+    if config := cls.get_pages_config(args):
+      # TODO: make stories and page_config mutually exclusive.
+      if not has_default_stories:
+        raise argparse.ArgumentTypeError(
+            f"Cannot specify --stories={repr(args.stories)} "
+            "with any other page config option.")
+      pages = LoadingPageFilter.stories_from_config(args, config)
+      if cls.requires_separate(args):
+        return pages
+      if len(pages) == 1:
+        return pages
+      return (CombinedPage(pages, "Page Scenarios - Combined", args.playback,
+                           args.tabs),)
+
+    if args.urls:
+      # TODO: make urls and stories mutually exclusive.
+      if not has_default_stories:
+        raise argparse.ArgumentTypeError(
+            "Cannot specify --urls and --stories at the same time.")
+      args.stories = args.urls
+
+    # Fall back to story filter class.
+    return super().stories_from_cli_args(args)
+
+  @classmethod
+  def get_pages_config(cls, args: argparse.Namespace) -> Optional[PagesConfig]:
+    if global_config := args.config:
+      # TODO: migrate --config to an already parsed hjson/json dict
+      config_file = global_config
+      config_data = ObjectParser.hjson_file(config_file)
+      if pages_config_dict := config_data.get("pages"):
+        if args.pages_config:
+          raise argparse.ArgumentTypeError(
+              "Conflicting arguments: "
+              "either specify a --config file without a 'pages' property "
+              "or remove the --page-config argument.")
+        # TODO: PagesConfig.parse_dict should be able to parse the inner dict.
+        return PagesConfig.parse_dict({"pages": pages_config_dict})
+    return args.pages_config
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("load", "ld")
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["action_runner"] = args.action_runner
+    return kwargs
+
+  @classmethod
+  def all_story_names(cls) -> Sequence[str]:
+    return sorted(LivePage.all_story_names())
+
+  def __init__(self,
+               stories: Sequence[Page],
+               action_runner: Optional[ActionRunner] = None) -> None:
+    self._action_runner = action_runner or BasicActionRunner()
+    for story in stories:
+      assert isinstance(story, Page)
+    super().__init__(stories)
+
+  @property
+  def action_runner(self) -> ActionRunner:
+    return self._action_runner
diff --git a/crossbench/benchmarks/loading/loadline_presets.py b/crossbench/benchmarks/loading/loadline_presets.py
new file mode 100644
index 0000000..4f335a4
--- /dev/null
+++ b/crossbench/benchmarks/loading/loadline_presets.py
@@ -0,0 +1,196 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+import logging
+from typing import TYPE_CHECKING, Optional, Sequence, Tuple
+
+import numpy as np
+import pandas as pd
+from tabulate import tabulate
+
+from crossbench import config
+from crossbench import path as pth
+from crossbench.benchmarks.base import BenchmarkProbeMixin
+from crossbench.benchmarks.loading.config.pages import PagesConfig
+from crossbench.benchmarks.loading.loading_benchmark import (LoadingPageFilter,
+                                                             PageLoadBenchmark)
+from crossbench.flags.base import Flags
+from crossbench.probes.perfetto.trace_processor.trace_processor import \
+    TraceProcessorProbe
+from crossbench.probes.probe import Probe, ProbeContext
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.loading.page.base import Page
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.runner import Run
+
+CONFIG_DIR = config.config_dir()
+LOADLINE_DIR = CONFIG_DIR / "benchmark" / "loadline"
+
+# We should increase the minor version number every time there are any changes
+# that might affect the benchmark score.
+VERSION_STRING = "1.1.0"
+
+
+class LoadLinePageFilter(LoadingPageFilter):
+  """LoadLine benchmark for phone/tablet."""
+  CAN_COMBINE_STORIES: bool = False
+
+  @classmethod
+  def add_page_config_parser(cls, parser: argparse.ArgumentParser) -> None:
+    pass
+
+  @classmethod
+  def default_stories(cls) -> Tuple[Page, ...]:
+    return cls.all_stories()
+
+  @classmethod
+  def all_stories(cls) -> Tuple[Page, ...]:
+    return ()
+
+
+class LoadLineProbe(BenchmarkProbeMixin, Probe):
+  IS_GENERAL_PURPOSE = False
+  NAME = "loadline_probe"
+
+  def get_context(self, run: Run) -> Optional[LoadLineProbeContext]:
+    return LoadLineProbeContext(self, run)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    logging.info("-" * 80)
+    logging.critical("LoadLine Benchmark (%s)", VERSION_STRING)
+    logging.critical("LoadLine results:")
+    logging.info("- " * 40)
+    logging.critical(
+        tabulate(
+            pd.read_csv(
+                group.get_local_probe_result_path(self).with_suffix(".csv")),
+            headers="keys",
+            tablefmt="plain"))
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    csv_file = group.get_local_probe_result_path(self).with_suffix(".csv")
+    self._compute_score(group).to_csv(csv_file)
+    return ProbeResult(csv=(csv_file,))
+
+  def _compute_score(self, group: BrowsersRunGroup) -> pd.DataFrame:
+    all_results = group.results.get_by_name(TraceProcessorProbe.NAME).csv_list
+    loadline_result: Optional[pth.LocalPath] = None
+    for result in all_results:
+      # Look for the "loadline/benchmark_score" trace processor query result.
+      if result.name == "loadline_benchmark_score.csv":
+        loadline_result = result
+        break
+    assert loadline_result is not None, "LoadLine: query result not found"
+
+    df = pd.read_csv(loadline_result)
+    df = df.groupby(["cb_browser",
+                     "cb_story"])["score"].mean().reset_index().pivot(
+                         columns=["cb_story"],
+                         index=["cb_browser"],
+                         values=["score"])
+    df = df.droplevel(0, axis=1)
+    df["TOTAL_SCORE"] = np.exp(np.log(df).mean(axis=1))
+    df.index.rename("browser", inplace=True)
+    return df.reindex(
+        columns=(["TOTAL_SCORE"] +
+                 sorted(list(c for c in df.columns if c != "TOTAL_SCORE"))))
+
+
+class LoadLineProbeContext(ProbeContext[LoadLineProbe]):
+
+  def start(self) -> None:
+    pass
+
+  def start_story_run(self) -> None:
+    self.browser.performance_mark(
+        f"LoadLine/{self.probe.benchmark.NAME}/{self.run.story.name}")
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    return EmptyProbeResult()
+
+
+class LoadLineBenchmark(PageLoadBenchmark, metaclass=abc.ABCMeta):
+  STORY_FILTER_CLS = LoadLinePageFilter
+  PROBES = (LoadLineProbe,)
+  DEFAULT_REPETITIONS = 100
+
+  @classmethod
+  def requires_separate(cls, args: argparse.Namespace) -> bool:
+    # Perfetto metrics used in the benchmark require a separate Perfetto
+    # session for each run.
+    return True
+
+  @classmethod
+  def default_probe_config_path(cls) -> pth.LocalPath:
+    return pth.LocalPath(LOADLINE_DIR) / "probe_config.hjson"
+
+  @classmethod
+  @abc.abstractmethod
+  def default_network_config_path(cls) -> pth.LocalPath:
+    pass
+
+  @classmethod
+  @abc.abstractmethod
+  def default_pages_config_path(cls) -> pth.LocalPath:
+    pass
+
+  @classmethod
+  def get_pages_config(
+      cls, args: Optional[argparse.Namespace] = None) -> PagesConfig:
+    return PagesConfig.parse(cls.default_pages_config_path())
+
+  @classmethod
+  def all_story_names(cls) -> Sequence[str]:
+    return tuple(page.any_label for page in cls.get_pages_config().pages)
+
+
+class LoadLineTabletBenchmark(LoadLineBenchmark):
+  """LoadLine benchmark for tablet.
+  """
+  NAME = "loadline-tablet"
+
+  @classmethod
+  def default_pages_config_path(cls) -> pth.LocalPath:
+    return pth.LocalPath(LOADLINE_DIR) / "page_config_tablet.hjson"
+
+  @classmethod
+  def default_network_config_path(cls) -> pth.LocalPath:
+    return pth.LocalPath(LOADLINE_DIR) / "network_config_tablet.hjson"
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("loading-tablet", "load-tablet", "ld-tablet")
+
+  @classmethod
+  def extra_flags(cls, browser_attributes: BrowserAttributes) -> Flags:
+    assert browser_attributes.is_chromium_based
+    return Flags(["--request-desktop-sites"])
+
+
+class LoadLinePhoneBenchmark(LoadLineBenchmark):
+  """LoadLine benchmark for phones.
+  """
+  NAME = "loadline-phone"
+
+  @classmethod
+  def default_pages_config_path(cls) -> pth.LocalPath:
+    return pth.LocalPath(LOADLINE_DIR) / "page_config_phone.hjson"
+
+  @classmethod
+  def default_network_config_path(cls) -> pth.LocalPath:
+    return pth.LocalPath(LOADLINE_DIR) / "network_config_phone.hjson"
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("loading-phone", "load-phone", "ld-phone")
diff --git a/crossbench/benchmarks/loading/page/__init__.py b/crossbench/benchmarks/loading/page/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/benchmarks/loading/page/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/benchmarks/loading/page/base.py b/crossbench/benchmarks/loading/page/base.py
new file mode 100644
index 0000000..62e80bd
--- /dev/null
+++ b/crossbench/benchmarks/loading/page/base.py
@@ -0,0 +1,75 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+from typing import TYPE_CHECKING, List, Tuple, cast
+
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.benchmarks.loading.tab_controller import TabController
+from crossbench.stories.story import Story
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+  from crossbench.runner.run import Run
+
+DEFAULT_DURATION_SECONDS = 15
+DEFAULT_DURATION = dt.timedelta(seconds=DEFAULT_DURATION_SECONDS)
+
+# This is initialized in interactive.py to avoid circular dependencies
+PAGE_LIST: List[Page] = []
+
+class Page(Story, metaclass=abc.ABCMeta):
+
+  @classmethod
+  def all_story_names(cls) -> Tuple[str, ...]:
+    assert PAGE_LIST, "Missing predefined page list"
+    # TODO: move all story names magic to the dedicated StoryFilter.
+    # Use module instead of direct import to avoid import cycle
+    return tuple(page.name for page in PAGE_LIST)
+
+  def __init__(self,
+               name: str,
+               duration: dt.timedelta = DEFAULT_DURATION,
+               playback: PlaybackController = PlaybackController.default(),
+               tabs: TabController = TabController.default(),
+               about_blank_duration: dt.timedelta = dt.timedelta()):
+    self._playback: PlaybackController = playback
+    self._tabs: TabController = tabs
+    self._about_blank_duration = about_blank_duration
+    super().__init__(name, duration)
+
+  @property
+  def about_blank_duration(self) -> dt.timedelta:
+    return self._about_blank_duration
+
+  def set_parent(self, parent: Page) -> None:
+    # TODO: support nested playback controllers.
+    self._playback = PlaybackController.default()
+    self._tabs = TabController.default()
+    del parent
+
+  @abc.abstractmethod
+  def run_with(self, run: Run, action_runner: ActionRunner,
+               multiple_tabs: bool) -> None:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def first_url(self) -> str:
+    pass
+
+  @property
+  def tabs(self) -> TabController:
+    return self._tabs
+
+
+def get_action_runner(run: Run) -> ActionRunner:
+  # TODO: make sure we have a single instance per Run
+  benchmark = cast("PageLoadBenchmark", run.benchmark)
+  return benchmark.action_runner
diff --git a/crossbench/benchmarks/loading/page/combined.py b/crossbench/benchmarks/loading/page/combined.py
new file mode 100644
index 0000000..dee19e2
--- /dev/null
+++ b/crossbench/benchmarks/loading/page/combined.py
@@ -0,0 +1,70 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Iterable
+
+from crossbench.benchmarks.loading.page.base import Page, get_action_runner
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.benchmarks.loading.tab_controller import TabController
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class CombinedPage(Page):
+
+  def __init__(self,
+               pages: Iterable[Page],
+               name: str = "combined",
+               playback: PlaybackController = PlaybackController.default(),
+               tabs: TabController = TabController.default(),
+               about_blank_duration: dt.timedelta = dt.timedelta()):
+    self._pages = tuple(pages)
+    assert self._pages, "No sub-pages provided for CombinedPage"
+    assert len(self._pages) >= 1, "Combined Page needs at least one page"
+    self._tabs = tabs
+
+    duration = dt.timedelta()
+    for page in self._pages:
+      page.set_parent(self)
+      duration += page.duration
+    super().__init__(name, duration, playback, tabs, about_blank_duration)
+    self.url = None
+
+  @property
+  def tabs(self) -> TabController:
+    return self._tabs
+
+  @property
+  def pages(self) -> Iterable[Page]:
+    return self._pages
+
+  @property
+  def first_url(self) -> str:
+    return self._pages[0].first_url
+
+  def details_json(self) -> JsonDict:
+    result = super().details_json()
+    result["pages"] = list(page.details_json() for page in self._pages)
+    return result
+
+  def run(self, run: Run) -> None:
+    action_runner = get_action_runner(run)
+    multiple_tabs = self.tabs.multiple_tabs
+    for _ in self._playback:
+      action_runner.run_combined_page(run, self, multiple_tabs)
+
+  def run_with(self, run: Run, action_runner: ActionRunner,
+               multiple_tabs: bool) -> None:
+    action_runner.run_combined_page(run, self, multiple_tabs)
+
+  def __str__(self) -> str:
+    combined_name = ",".join(page.name for page in self._pages)
+    return f"CombinedPage({combined_name})"
diff --git a/crossbench/benchmarks/loading/page/interactive.py b/crossbench/benchmarks/loading/page/interactive.py
new file mode 100644
index 0000000..85f3f0c
--- /dev/null
+++ b/crossbench/benchmarks/loading/page/interactive.py
@@ -0,0 +1,121 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+from typing import TYPE_CHECKING, Optional, Tuple, cast
+
+from immutabledict import immutabledict
+
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.get import GetAction
+from crossbench.benchmarks.loading.page.base import Page, get_action_runner
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.benchmarks.loading.tab_controller import TabController
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.benchmarks.loading.config.blocks import ActionBlock
+  from crossbench.benchmarks.loading.config.login.custom import LoginBlock
+  from crossbench.cli.config.secrets import SecretsDict
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class InteractivePage(Page):
+
+  def __init__(self,
+               name: str,
+               blocks: Tuple[ActionBlock, ...],
+               setup: Optional[ActionBlock] = None,
+               login: Optional[LoginBlock] = None,
+               secrets: Optional[SecretsDict] = None,
+               playback: PlaybackController = PlaybackController.default(),
+               tabs: TabController = TabController.default(),
+               about_blank_duration: dt.timedelta = dt.timedelta(),
+               run_login: bool = True,
+               run_setup: bool = True):
+    assert name, "missing name"
+    self._name: str = name
+    assert isinstance(blocks, tuple)
+    self._blocks: Tuple[ActionBlock, ...] = blocks
+    assert self._blocks, "Must have at least 1 valid action"
+    assert not any(block.is_login for block in blocks), (
+        "No login blocks allowed as normal action block")
+    self._setup_block = setup
+    self._login_block = login
+    self._secrets: SecretsDict = secrets or immutabledict()
+    self._run_login = run_login
+    self._run_setup = run_setup
+    duration = self._get_duration()
+    super().__init__(self._name, duration, playback, tabs, about_blank_duration)
+
+  @property
+  def login_block(self) -> Optional[ActionBlock]:
+    return self._login_block
+
+  @property
+  def setup_block(self) -> Optional[ActionBlock]:
+    return self._setup_block
+
+  @property
+  def blocks(self) -> Tuple[ActionBlock, ...]:
+    return self._blocks
+
+  @property
+  def secrets(self) -> SecretsDict:
+    return self._secrets
+
+  @property
+  def first_url(self) -> str:
+    for block in self.blocks:
+      for action in block:
+        if action.TYPE == ActionType.GET:
+          return cast(GetAction, action).url
+    raise RuntimeError("No GET action with an URL found.")
+
+  def create_failure_artifacts(self,
+                               run: Run,
+                               message: str = "failure") -> None:
+    action_runner = get_action_runner(run)
+    try:
+      action_runner.screenshot_impl(run, message)
+    except Exception as e:  # pylint: disable=broad-except
+      logging.error("Failed to take a failure screenshot: %s", str(e))
+
+    try:
+      action_runner.dump_html_impl(run, message)
+    except Exception as e:  # pylint: disable=broad-except
+      logging.error("Failed to dump HTML on failure: %s", str(e))
+
+  def setup(self, run: Run) -> None:
+    action_runner = get_action_runner(run)
+    if self._run_login and (login_block := self.login_block):
+      action_runner.run_login(run, self, login_block)
+    if self._run_setup and (setup_block := self.setup_block):
+      action_runner.run_setup(run, self, setup_block)
+
+  def run(self, run: Run) -> None:
+    action_runner = get_action_runner(run)
+    multiple_tabs = self.tabs.multiple_tabs
+    for _ in self._playback:
+      action_runner.run_interactive_page(run, self, multiple_tabs)
+
+  def run_with(self, run: Run, action_runner: ActionRunner,
+               multiple_tabs: bool) -> None:
+    action_runner.run_interactive_page(run, self, multiple_tabs)
+
+  def details_json(self) -> JsonDict:
+    result = super().details_json()
+    result["actions"] = list(block.to_json() for block in self._blocks)
+    return result
+
+  def _get_duration(self) -> dt.timedelta:
+    duration = dt.timedelta()
+    for block in self._blocks:
+      duration += block.duration
+    return duration
diff --git a/crossbench/benchmarks/loading/page/live.py b/crossbench/benchmarks/loading/page/live.py
new file mode 100644
index 0000000..72c36b4
--- /dev/null
+++ b/crossbench/benchmarks/loading/page/live.py
@@ -0,0 +1,96 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Dict, Tuple
+
+from crossbench.action_runner.action.get import GetAction
+from crossbench.benchmarks.loading.config.blocks import ActionBlock
+from crossbench.benchmarks.loading.page.base import DEFAULT_DURATION, PAGE_LIST
+from crossbench.benchmarks.loading.page.interactive import InteractivePage
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.benchmarks.loading.tab_controller import TabController
+
+if TYPE_CHECKING:
+  from crossbench.types import JsonDict
+
+
+class LivePage(InteractivePage):
+
+  @classmethod
+  def all_story_names(cls) -> Tuple[str, ...]:
+    return tuple(page.name for page in PAGE_LIST)
+
+  def __init__(
+      self,
+      name: str,
+      url: str,
+      duration: dt.timedelta = DEFAULT_DURATION,
+      playback: PlaybackController = PlaybackController.default(),
+      tabs: TabController = TabController.default(),
+      about_blank_duration: dt.timedelta = dt.timedelta()
+  ) -> None:
+    assert url, "Invalid page url"
+    self.url: str = url
+    blocks = (ActionBlock(actions=(GetAction(self.url, duration),)),)
+    super().__init__(
+        name,
+        blocks=blocks,
+        playback=playback,
+        tabs=tabs,
+        about_blank_duration=about_blank_duration)
+
+  def details_json(self) -> JsonDict:
+    result = super().details_json()
+    result["url"] = str(self.url)
+    return result
+
+  @property
+  def first_url(self) -> str:
+    return self.url
+
+  def __str__(self) -> str:
+    return f"Page(name={self.name}, url={self.url})"
+
+
+LIVE_PAGES = ((LivePage("blank", "about:blank", dt.timedelta(seconds=1)),
+               LivePage("amazon", "https://www.amazon.de/s?k=heizkissen",
+                        dt.timedelta(seconds=5)),
+               LivePage("bing",
+                        "https://www.bing.com/images/search?q=not+a+squirrel",
+                        dt.timedelta(seconds=5)),
+               LivePage("caf", "http://www.caf.fr", dt.timedelta(seconds=6)),
+               LivePage("cnn", "https://cnn.com/", dt.timedelta(seconds=7)),
+               LivePage("ecma262",
+                        "https://tc39.es/ecma262/#sec-numbers-and-dates",
+                        dt.timedelta(seconds=10)),
+               LivePage("expedia", "https://www.expedia.com/",
+                        dt.timedelta(seconds=7)),
+               LivePage("facebook", "https://facebook.com/shakira",
+                        dt.timedelta(seconds=8)),
+               LivePage("maps", "https://goo.gl/maps/TEZde4y4Hc6r2oNN8",
+                        dt.timedelta(seconds=10)),
+               LivePage("microsoft", "https://microsoft.com/",
+                        dt.timedelta(seconds=6)),
+               LivePage("provincial", "http://www.provincial.com",
+                        dt.timedelta(seconds=6)),
+               LivePage("sueddeutsche",
+                        "https://www.sueddeutsche.de/wirtschaft",
+                        dt.timedelta(seconds=8)),
+               LivePage("theverge", "https://www.theverge.com/",
+                        dt.timedelta(seconds=10)),
+               LivePage("timesofindia", "https://timesofindia.indiatimes.com/",
+                        dt.timedelta(seconds=8)),
+               LivePage("twitter", "https://twitter.com/wernertwertzog?lang=en",
+                        dt.timedelta(seconds=6))))
+
+assert not PAGE_LIST, "PAGE_LIST was already initialized."
+PAGE_LIST.extend(LIVE_PAGES)
+
+PAGES: Dict[str, LivePage] = {page.name: page for page in LIVE_PAGES}
+PAGE_LIST_SMALL = (PAGES["facebook"], PAGES["maps"], PAGES["timesofindia"],
+                   PAGES["cnn"])
diff --git a/crossbench/benchmarks/loading/playback_controller.py b/crossbench/benchmarks/loading/playback_controller.py
new file mode 100644
index 0000000..6552cf2
--- /dev/null
+++ b/crossbench/benchmarks/loading/playback_controller.py
@@ -0,0 +1,88 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+import dataclasses
+import datetime as dt
+from typing import Iterator
+
+from crossbench.parse import DurationParser, NumberParser
+
+
+class PlaybackController(abc.ABC):
+
+  @classmethod
+  def parse(cls, value: str) -> PlaybackController:
+    if not value or value == "once":
+      return cls.once()
+    if value in ("inf", "infinity", "forever"):
+      return cls.forever()
+    if value[-1].isnumeric():
+      raise argparse.ArgumentTypeError(
+          f"Missing unit suffix: '{value}'\n"
+          "Use 'x' for repetitions or time unit 's', 'm', 'h'")
+    if value[-1] == "x":
+      loops = NumberParser.positive_int(value[:-1], "Repeat-count")
+      return cls.repeat(loops)
+    duration = DurationParser.positive_duration(value)
+    return cls.timeout(duration)
+
+  @classmethod
+  def default(cls) -> PlaybackController:
+    return cls.once()
+
+  @classmethod
+  def once(cls) -> RepeatPlaybackController:
+    return RepeatPlaybackController(1)
+
+  @classmethod
+  def repeat(cls, count: int) -> RepeatPlaybackController:
+    return RepeatPlaybackController(count)
+
+  @classmethod
+  def forever(cls) -> PlaybackController:
+    return ForeverPlaybackController()
+
+  @classmethod
+  def timeout(cls, duration: dt.timedelta) -> TimeoutPlaybackController:
+    return TimeoutPlaybackController(duration)
+
+  @abc.abstractmethod
+  def __iter__(self) -> Iterator[None]:
+    pass
+
+
+@dataclasses.dataclass(frozen=True)
+class ForeverPlaybackController(PlaybackController):
+
+  def __iter__(self) -> Iterator[None]:
+    while True:
+      yield None
+
+
+@dataclasses.dataclass(frozen=True)
+class TimeoutPlaybackController(PlaybackController):
+  duration : dt.timedelta
+
+  def __iter__(self) -> Iterator[None]:
+    end = dt.datetime.now() + self.duration
+    while True:
+      yield None
+      if dt.datetime.now() > end:
+        return
+
+
+@dataclasses.dataclass(frozen=True)
+class RepeatPlaybackController(PlaybackController):
+  count : int
+
+  def __post_init__(self):
+    NumberParser.positive_int(self.count, " page playback count")
+
+  def __iter__(self) -> Iterator[None]:
+    for _ in range(self.count):
+      yield None
diff --git a/crossbench/benchmarks/loading/point.py b/crossbench/benchmarks/loading/point.py
new file mode 100644
index 0000000..d56b9ac
--- /dev/null
+++ b/crossbench/benchmarks/loading/point.py
@@ -0,0 +1,14 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import dataclasses
+
+
+@dataclasses.dataclass(frozen=True)
+# Represents a single point on a screen.
+class Point:
+  # The offset in pixels from the left edge of the screen.
+  x: int
+  # The offset in pixels from the top edge of the screen.
+  y: int
diff --git a/crossbench/benchmarks/loading/tab_controller.py b/crossbench/benchmarks/loading/tab_controller.py
new file mode 100644
index 0000000..4aee2ba
--- /dev/null
+++ b/crossbench/benchmarks/loading/tab_controller.py
@@ -0,0 +1,104 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import dataclasses
+from typing import Any, Dict, Iterator
+
+from crossbench.config import ConfigObject
+from crossbench.parse import NumberParser
+
+
+class TabController(ConfigObject):
+  multiple_tabs: bool
+  is_forever: bool
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> TabController:
+    raise NotImplementedError("Cannot create tab controller from dict")
+
+  @classmethod
+  def parse_str(cls, value: str) -> TabController:
+    if not value or value == "single":
+      return cls.single()
+    if value in ("inf", "infinity"):
+      return cls.forever()
+    loops = NumberParser.positive_int(value, "Repeat-count")
+    return cls.repeat(loops)
+
+  @classmethod
+  def default(cls) -> TabController:
+    return cls.single()
+
+  @classmethod
+  def single(cls) -> TabController:
+    return SingleTabController()
+
+  @classmethod
+  def multiple(cls) -> TabController:
+    return RepeatTabController(1)
+
+  @classmethod
+  def repeat(cls, count: int) -> RepeatTabController:
+    return RepeatTabController(count)
+
+  @classmethod
+  def forever(cls) -> TabController:
+    return ForeverTabController()
+
+  @abc.abstractmethod
+  def __iter__(self) -> Iterator[None]:
+    pass
+
+
+@dataclasses.dataclass(frozen=True)
+class SingleTabController(TabController):
+  """
+  Open given urls in one tab sequentially.
+  """
+  multiple_tabs: bool = False
+  is_forever: bool = False
+
+  def __iter__(self) -> Iterator[None]:
+    yield None
+
+
+@dataclasses.dataclass(frozen=True)
+class ForeverTabController(TabController):
+  """
+  Open given urls in separate tabs and repeat infinitely until
+  one of the tabs gets discarded.
+
+  Example 1: if url='cnn', it keeps opening new tabs loading cnn.
+
+  Example 2: if urls='amazon,cnn', it keeps opening
+  amazon,cnn,amazon,cnn,amazon,cnn,.... ....
+  """
+  multiple_tabs: bool = True
+  is_forever: bool = True
+
+  def __iter__(self) -> Iterator[None]:
+    while True:
+      yield None
+
+
+@dataclasses.dataclass(frozen=True)
+class RepeatTabController(TabController):
+  """
+  Open given urls in separate tabs and repeat for `count` times.
+
+  Example 1: if url='cnn', count=3, it will open 3 tabs: cnn,cnn,cnn.
+
+  Example 2: if urls='amazon,cnn', count=3, it will open 6 tabs:
+  amazon,cnn,amazon,cnn,amazon,cnn
+  """
+  count: int
+  multiple_tabs: bool = True
+  is_forever: bool = False
+
+  def __iter__(self) -> Iterator[None]:
+    for _ in range(self.count):
+      yield None
diff --git a/crossbench/benchmarks/manual/__init__.py b/crossbench/benchmarks/manual/__init__.py
new file mode 100644
index 0000000..3ac0e1c
--- /dev/null
+++ b/crossbench/benchmarks/manual/__init__.py
@@ -0,0 +1,7 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.benchmarks.manual.manual_benchmark import ManualBenchmark
diff --git a/crossbench/benchmarks/manual/manual_benchmark.py b/crossbench/benchmarks/manual/manual_benchmark.py
new file mode 100644
index 0000000..23e0671
--- /dev/null
+++ b/crossbench/benchmarks/manual/manual_benchmark.py
@@ -0,0 +1,116 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import logging
+from typing import TYPE_CHECKING, Any, Dict, Optional, Sequence, Tuple
+
+from crossbench import helper
+from crossbench.benchmarks.base import Benchmark
+from crossbench.cli.ui import timer
+from crossbench.parse import DurationParser
+from crossbench.stories.story import Story
+
+if TYPE_CHECKING:
+  import argparse
+
+  from crossbench.cli.parser import CrossBenchArgumentParser
+  from crossbench.runner.run import Run
+
+
+class ManualStory(Story, metaclass=abc.ABCMeta):
+
+  STORY_NAME = "manual"
+
+  def __init__(self, start_after: Optional[dt.timedelta],
+               run_for: Optional[dt.timedelta]):
+    self._start_after = start_after
+    self._run_for = run_for
+    duration = ((start_after or dt.timedelta()) +
+                (run_for or dt.timedelta(seconds=30)))
+    super().__init__(self.STORY_NAME, duration)
+
+  def setup(self, run: Run) -> None:
+    if self._start_after is None:
+      logging.info("-" * 80)
+      logging.critical("Press enter to start:")
+      input()
+    elif self._start_after.total_seconds():
+      logging.critical("-" * 80)
+      logging.critical(
+          "The browser has launched. Measurement will start in %s" +
+          " (or press enter to start immediately)", self._start_after)
+      helper.input_with_timeout(timeout=self._start_after)
+    logging.info("Starting Manual Benchmark...")
+
+  def run(self, run: Run) -> None:
+    with timer():
+      logging.info("-" * 80)
+      self._wait_for_input()
+      # Empty line to preserve timer output.
+      print()
+      logging.info("Stopping Manual Benchmark...")
+
+  def _wait_for_input(self) -> None:
+    if self._run_for is None:
+      logging.critical("Press enter to stop:")
+      try:
+        input()
+      except KeyboardInterrupt:
+        pass
+    else:
+      logging.critical(
+          "Measurement has started. The browser will close in %s" +
+          " (or press enter to close immediately)", self._run_for)
+      helper.input_with_timeout(timeout=self._run_for)
+
+
+  @classmethod
+  def all_story_names(cls) -> Tuple[str, ...]:
+    return (ManualStory.STORY_NAME,)
+
+
+class ManualBenchmark(Benchmark, metaclass=abc.ABCMeta):
+  """
+  Benchmark runner for the manual mode.
+
+  Just launches the browser and lets the user perform the desired interactions.
+  Optionally waits for |start_after| seconds, then runs measurements for
+  |run_for| seconds, then closes the browser.
+  """
+  NAME = "manual"
+  DEFAULT_STORY_CLS = ManualStory
+
+  def __init__(self, start_after: Optional[dt.timedelta],
+               run_for: Optional[dt.timedelta]) -> None:
+    super().__init__([ManualStory(start_after=start_after, run_for=run_for)])
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
+  ) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    parser.add_argument(
+        "--start-after",
+        help="How long to wait until measurement starts",
+        required=False,
+        type=DurationParser.positive_or_zero_duration)
+    parser.add_argument(
+        "--run-for",
+        "--stop-after",
+        "--duration",
+        help="How long to run measurement for",
+        required=False,
+        type=DurationParser.positive_duration)
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["start_after"] = args.start_after
+    kwargs["run_for"] = args.run_for
+    return kwargs
diff --git a/crossbench/benchmarks/memory/__init__.py b/crossbench/benchmarks/memory/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/benchmarks/memory/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/benchmarks/memory/memory_benchmark.py b/crossbench/benchmarks/memory/memory_benchmark.py
new file mode 100644
index 0000000..227b594
--- /dev/null
+++ b/crossbench/benchmarks/memory/memory_benchmark.py
@@ -0,0 +1,347 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import json
+import logging
+from typing import TYPE_CHECKING, Any, Dict, Optional, Sequence, Tuple, Type
+
+import selenium.common.exceptions
+import urllib3.exceptions
+
+from crossbench import helper
+from crossbench.action_runner.action_runner_listener import \
+    ActionRunnerListener
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.benchmarks.base import (BenchmarkProbeMixin, StoryFilter,
+                                        SubStoryBenchmark)
+from crossbench.benchmarks.loading.page.base import Page
+from crossbench.benchmarks.loading.page.live import LivePage
+from crossbench.benchmarks.loading.tab_controller import TabController
+from crossbench.parse import NumberParser
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
+from crossbench.probes.metric import MetricsMerger
+from crossbench.probes.results import ProbeResult, ProbeResultDict
+from crossbench.runner.exception import StopStoryException
+
+if TYPE_CHECKING:
+  import argparse
+
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.cli.parser import CrossBenchArgumentParser
+  from crossbench.path import LocalPath
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+
+
+class MemoryProbe(BenchmarkProbeMixin, JsonResultProbe):
+  """
+  Memory-specific Probe.
+  Extracts the number of alive tabs.
+  """
+  NAME: str = "memory_probe"
+
+  def get_context(self, run: Run) -> MemoryProbeContext:
+    return MemoryProbeContext(self, run)
+
+  def to_json(self, actions: Actions) -> Dict[str, float]:
+    raise NotImplementedError(
+        "should not be called, data comes from memory probe context")
+
+  def log_run_result(self, run: Run) -> None:
+    self._log_result(run.results, single_result=True)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    self._log_result(group.results, single_result=False)
+
+  def _log_result(self, result_dict: ProbeResultDict,
+                  single_result: bool) -> None:
+
+    if self not in result_dict:
+      return
+    results_json: LocalPath = result_dict[self].json
+    logging.info("-" * 80)
+    logging.critical("Memory results (num of alive tabs):")
+    if not single_result:
+      logging.critical("  %s", result_dict[self].csv)
+    logging.info("- " * 40)
+
+    with results_json.open(encoding="utf-8") as f:
+      data = json.load(f)
+      if single_result:
+        logging.critical("Score %s", data["alive_tab_count"])
+      else:
+        self._log_result_metrics(data)
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        repetitions_group.results[self].json
+        for repetitions_group in group.repetitions_groups)
+    return self.write_group_result(group, merged)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self.merge_browsers_json_list(group).merge(
+        self.merge_browsers_csv_list(group))
+
+
+class MemoryProbeContext(ActionRunnerListener,
+                         JsonResultProbeContext[MemoryProbe]):
+
+  def __init__(self, probe: MemoryProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    cur_benchmark = probe.benchmark
+    if not isinstance(cur_benchmark, MemoryBenchmark):
+      raise TypeError("The probe only works for MemoryBenchmark")
+    cur_benchmark.action_runner.set_listener(self)
+    self._skippable_tab_count = cur_benchmark._skippable_tab_count
+    # Records the navigation_start_time time for each window handle.
+    self._navigation_time_ms: Dict[str, float] = {}
+    self._tab_count: int = 1
+
+  def start(self) -> None:
+    pass
+
+  def to_json(self, actions: Actions) -> Dict[str, int]:
+    return {"alive_tab_count": self._tab_count - 1}
+
+  def _increment_tab_count(self):
+    self._tab_count += 1
+
+  def _record_navigation_time(self, run: Run) -> None:
+    """
+    Record NavigationStart time for each handle.
+    """
+    with run.actions("_record_navigation_time", measure=False) as action:
+      cur_handle: str = action.current_window_id()
+      navigation_start_time = action.js(
+          "return window.performance.timing.navigationStart")
+      logging.debug("Browser: %s. Navigation starttime for handle %s is %s.",
+                    run.browser.unique_name, cur_handle, navigation_start_time)
+      self._navigation_time_ms[cur_handle] = navigation_start_time
+
+  def _check_liveness(self, run: Run) -> None:
+    """
+    Navigate each opened tab, and check if the navigation start time
+    has changed. If so, then it means that page has been discarded
+    and reloaded.
+    """
+    with run.actions("_check_liveness", measure=False) as action:
+      for handle, handle_navigation_time_ms in self._navigation_time_ms.items():
+        logging.debug("Browser: %s. Liveness checking for handle: %s",
+                      run.browser, handle)
+        action.switch_window(handle)
+        action.wait(1)
+        navigation_start_time = action.js(
+            "return window.performance.timing.navigationStart")
+        if navigation_start_time != handle_navigation_time_ms:
+          logging.info(
+              "Browser: %s. The max num of tabs we can keep alive concurrently "
+              "is: %s ", run.browser, self._tab_count - 1)
+          raise StopStoryException("Found a page that has been reloaded.")
+
+  def _check_error_msg(self, e: Exception):
+    if isinstance(e, selenium.common.exceptions.WebDriverException
+                 ) and "page crash" in str(e):
+      return True
+    if isinstance(e, selenium.common.exceptions.TimeoutException):
+      return True
+    if isinstance(e, urllib3.exceptions.ReadTimeoutError):
+      return True
+    # Error msg from `Could not execute JS` due to page crash.
+    if isinstance(e, ValueError) and "page crash" in str(e):
+      return True
+    return False
+
+  def handle_error(self, run: Run, e: Exception) -> None:
+    """
+    If there is a page crash error or a http request time out
+    for the stress liveness test, directly exit the benchmark
+    and report the max alive tab count.
+    """
+    if self._check_error_msg(e):
+      logging.info(
+          "Browser: %s. The max num of tabs we can keep alive concurrently "
+          "is: %s ", run.browser, self._tab_count - 1)
+      raise StopStoryException(f"Found a Tab Crash/Timeout: {e}")
+
+  def handle_page_run(self, run: Run) -> None:
+    self._record_navigation_time(run)
+    if self._tab_count > self._skippable_tab_count:
+      self._check_liveness(run)
+
+  def handle_new_tab(self, run: Run) -> None:
+    self._increment_tab_count()
+
+
+class MemoryBenchmarkStoryFilter(StoryFilter[Page]):
+  """
+  Create memory story
+  Specify alloc-count, block-size, compressiblity,
+  prefill-constnat, random style to decide the
+  memory workload.
+  """
+  stories: Sequence[Page]
+  URL = "https://chromium-workloads.web.app/web-tests/main/synthetic/memory"
+
+  @classmethod
+  def add_cli_parser(
+      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser = super().add_cli_parser(parser)
+    parser.add_argument(
+        "--alloc-count",
+        type=NumberParser.positive_int,
+        default=1,
+        help="The number of block to allocate.")
+    parser.add_argument(
+        "--block-size",
+        type=NumberParser.positive_int,
+        default=128,
+        help="The size of each block (MB).")
+    parser.add_argument(
+        "--compressibility",
+        type=NumberParser.positive_zero_int,
+        default=0,
+        help="The compressibility (0-100)")
+    parser.add_argument(
+        "--prefill-constant",
+        type=NumberParser.any_int,
+        default=1,
+        help="Prefill memory buffer with given constant (-1-127)."
+        "Default is 1."
+        "-1 represents no prefilling.")
+    parser.add_argument(
+        "--random-per-buffer",
+        dest="random_per_page",
+        action="store_false",
+        help="With the flag, it will generate the memory workload "
+        "with random per buffer level. Without the flag,"
+        "it will generate the memory workload with random"
+        "per page level.")
+
+    tab_group = parser.add_mutually_exclusive_group()
+    tab_group.add_argument(
+        "--tabs",
+        type=TabController.parse,
+        default=TabController.default(),
+        help="Open memory workload in single/multiple/infinity tabs. "
+        "Default is single."
+        "Valid values are: 'single', 'inf', 'infinity', number")
+    tab_group.add_argument(
+        "--single-tab",
+        dest="tabs",
+        const=TabController.single(),
+        default=TabController.default(),
+        action="store_const",
+        help="Open memory workload in a single tab."
+        "Equivalent to --tabs=single")
+    tab_group.add_argument(
+        "--infinite-tab",
+        dest="tabs",
+        const=TabController.forever(),
+        action="store_const",
+        help="Open memory workload in separate tabs infinitely."
+        "Equivalent to --tabs=infinity")
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["args"] = args
+    return kwargs
+
+  def __init__(self,
+               story_cls: Type[Page],
+               patterns: Sequence[str],
+               args: argparse.Namespace,
+               separate: bool = False) -> None:
+    self._args: argparse.Namespace = args
+
+    super().__init__(story_cls, patterns, separate)
+
+  def process_all(self, patterns: Sequence[str]) -> None:
+    self.stories = self.stories_from_cli_args(self._args)
+
+  @classmethod
+  def stories_from_cli_args(cls, args: argparse.Namespace) -> Sequence[Page]:
+    url_params = {
+        "alloc": str(args.alloc_count),
+        "blocksize": str(args.block_size),
+        "compress": str(args.compressibility),
+        "prefill": str(args.prefill_constant),
+    }
+    if not args.random_per_page:
+      url_params["randomperpage"] = "false"
+    url = helper.update_url_query(cls.URL, url_params)
+    stories: Sequence[Page] = []
+    page = LivePage("memory", url, dt.timedelta(seconds=2), tabs=args.tabs)
+    stories = [page]
+    return stories
+
+  def create_stories(self, separate: bool) -> Sequence[Page]:
+    logging.info("SELECTED STORIES: %s", ", ".join(map(str, self.stories)))
+    return self.stories
+
+
+class MemoryBenchmark(SubStoryBenchmark):
+  """
+  Benchmark runner for memory stress test.
+  """
+
+  NAME = "memory"
+  DEFAULT_STORY_CLS = Page
+  STORY_FILTER_CLS = MemoryBenchmarkStoryFilter
+  PROBES: Tuple[Type[MemoryProbe], ...] = (MemoryProbe,)
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
+  ) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    cls.STORY_FILTER_CLS.add_cli_parser(parser)
+    parser.add_argument(
+        "--skippable-tab-count",
+        type=NumberParser.positive_int,
+        default=0,
+        help="The number of tabs that can be skipped for liveness checking.")
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["skippable_tab_count"] = args.skippable_tab_count
+    return kwargs
+
+  @classmethod
+  def stories_from_cli_args(cls, args: argparse.Namespace) -> Sequence[Page]:
+    super().stories_from_cli_args(args)
+    stories = MemoryBenchmarkStoryFilter.stories_from_cli_args(args)
+    return stories
+
+  @classmethod
+  def all_story_names(cls) -> Tuple[str, ...]:
+    return ()
+
+  def __init__(self,
+               stories: Sequence[Page],
+               skippable_tab_count: int = 0,
+               action_runner: Optional[ActionRunner] = None) -> None:
+    self._action_runner = action_runner or BasicActionRunner()
+    for story in stories:
+      assert isinstance(story, Page)
+    super().__init__(stories)
+    self._skippable_tab_count = skippable_tab_count
+
+  @classmethod
+  def describe(cls) -> Dict[str, Any]:
+    data = super().describe()
+    data["url"] = cls.STORY_FILTER_CLS.URL
+    return data
+
+  @property
+  def action_runner(self) -> ActionRunner:
+    return self._action_runner
diff --git a/crossbench/benchmarks/motionmark/__init__.py b/crossbench/benchmarks/motionmark/__init__.py
new file mode 100644
index 0000000..16bcede
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/__init__.py
@@ -0,0 +1,23 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.benchmarks.motionmark.motionmark_1_0 import \
+    MotionMark10Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_1 import \
+    MotionMark11Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_2 import \
+    MotionMark12Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_3 import \
+    MotionMark13Benchmark
+
+benchmark_classes = (MotionMark10Benchmark, MotionMark11Benchmark,
+                     MotionMark12Benchmark, MotionMark13Benchmark)
+
+_versions = set()
+for benchmark_cls in benchmark_classes:
+  assert benchmark_cls.version() not in _versions, (
+      f"Got duplicated benchmark version for {benchmark_cls}")
+  _versions.add(benchmark_cls.version())
diff --git a/crossbench/benchmarks/motionmark/base.py b/crossbench/benchmarks/motionmark/base.py
new file mode 100644
index 0000000..2b7d7af
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/base.py
@@ -0,0 +1,18 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.benchmarks.base import PressBenchmark
+
+
+class MotionMarkBenchmark(PressBenchmark):
+
+  @classmethod
+  def short_base_name(cls) -> str:
+    return "mm"
+
+  @classmethod
+  def base_name(cls) -> str:
+    return "motionmark"
diff --git a/crossbench/benchmarks/motionmark/motionmark_1.py b/crossbench/benchmarks/motionmark/motionmark_1.py
new file mode 100644
index 0000000..d547047
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/motionmark_1.py
@@ -0,0 +1,286 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import itertools
+import json
+import logging
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple
+
+from crossbench.benchmarks.base import BenchmarkProbeMixin
+from crossbench.benchmarks.motionmark.base import MotionMarkBenchmark
+from crossbench.helper import update_url_query
+from crossbench.probes.helper import Flatten
+from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.metric import Metric, MetricsMerger
+from crossbench.probes.results import ProbeResult, ProbeResultDict
+from crossbench.stories.press_benchmark import PressBenchmarkStory
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.types import Json
+
+
+def _clean_up_path_segments(path: Tuple[str, ...]) -> Optional[str]:
+  name = path[-1]
+  if name.startswith("segment") or name == "data":
+    return None
+  if path[:2] == ("testsResults", "MotionMark"):
+    path = path[2:]
+  return "/".join(path)
+
+
+class MotionMark1Probe(BenchmarkProbeMixin, JsonResultProbe, abc.ABC):
+  """
+  MotionMark-specific Probe.
+  Extracts all MotionMark times and scores.
+  """
+  JS = """
+    return window.benchmarkRunnerClient.results.results;
+  """
+
+  def to_json(self, actions: Actions) -> Json:
+    return actions.js(self.JS)
+
+  def flatten_json_data(self, json_data: List) -> Json:
+    assert isinstance(json_data, list) and len(json_data) == 1, (
+        "Motion12MarkProbe requires a results list.")
+    return Flatten(json_data[0], key_fn=_clean_up_path_segments).data
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        story_group.results[self].json
+        for story_group in group.repetitions_groups)
+    return self.write_group_result(group, merged)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self.merge_browsers_json_list(group).merge(
+        self.merge_browsers_csv_list(group))
+
+  def log_run_result(self, run: Run) -> None:
+    self._log_result(run.results, single_result=True)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    self._log_result(group.results, single_result=False)
+
+  def _log_result(self, result_dict: ProbeResultDict,
+                  single_result: bool) -> None:
+    if self not in result_dict:
+      return
+    results_json: LocalPath = result_dict[self].json
+    logging.info("-" * 80)
+    logging.critical("Motionmark results:")
+    if not single_result:
+      logging.critical("  %s", result_dict[self].csv)
+    logging.info("- " * 40)
+
+    with results_json.open(encoding="utf-8") as f:
+      data = json.load(f)
+      if single_result:
+        score = data.get("score") or data["Score"]
+        logging.critical("Score %s", score)
+      else:
+        self._log_result_metrics(data)
+
+  def _extract_result_metrics_table(self, metrics: Dict[str, Any],
+                                    table: Dict[str, List[str]]) -> None:
+    for metric_key, metric in metrics.items():
+      if not self._valid_metric_key(metric_key):
+        continue
+      table[metric_key].append(
+          Metric.format(metric["average"], metric["stddev"]))
+    # Separate runs don't produce a score
+    if total_metric := metrics.get("score") or metrics.get("Score"):
+      table["Score"].append(
+          Metric.format(total_metric["average"], total_metric["stddev"]))
+
+  def _valid_metric_key(self, metric_key: str) -> bool:
+    parts = metric_key.split("/")
+    return len(parts) == 2 or parts[-1] == "score"
+
+
+class MotionMark1Story(PressBenchmarkStory):
+  URL_LOCAL: str = "http://localhost:8000/"
+  ALL_STORIES = {
+      "MotionMark": (
+          "Multiply",
+          "Canvas Arcs",
+          "Leaves",
+          "Paths",
+          "Canvas Lines",
+          "Images",
+          "Design",
+          "Suits",
+      ),
+      "HTML suite": (
+          "CSS bouncing circles",
+          "CSS bouncing clipped rects",
+          "CSS bouncing gradient circles",
+          "CSS bouncing blend circles",
+          "CSS bouncing filter circles",
+          # "CSS bouncing SVG images",
+          "CSS bouncing tagged images",
+          "Focus 2.0",
+          "DOM particles, SVG masks",
+          # "Composited Transforms",
+      ),
+      "Canvas suite": (
+          "canvas bouncing clipped rects",
+          "canvas bouncing gradient circles",
+          # "canvas bouncing SVG images",
+          # "canvas bouncing PNG images",
+          "Stroke shapes",
+          "Fill shapes",
+          "Canvas put/get image data",
+      ),
+      "SVG suite": (
+          "SVG bouncing circles",
+          "SVG bouncing clipped rects",
+          "SVG bouncing gradient circles",
+          # "SVG bouncing SVG images",
+          # "SVG bouncing PNG images",
+      ),
+      "Leaves suite": (
+          "Translate-only Leaves",
+          "Translate + Scale Leaves",
+          "Translate + Opacity Leaves",
+      ),
+      "Multiply suite": (
+          "Multiply: CSS opacity only",
+          "Multiply: CSS display only",
+          "Multiply: CSS visibility only",
+      ),
+      "Text suite": (
+          "Design: Latin only (12 items)",
+          "Design: CJK only (12 items)",
+          "Design: RTL and complex scripts only (12 items)",
+          "Design: Latin only (6 items)",
+          "Design: CJK only (6 items)",
+          "Design: RTL and complex scripts only (6 items)",
+      ),
+      "Suits suite": (
+          "Suits: clip only",
+          "Suits: shape only",
+          "Suits: clip, shape, rotation",
+          "Suits: clip, shape, gradient",
+          "Suits: static",
+      ),
+      "3D Graphics": (
+          "Triangles (WebGL)",
+          # "Triangles (WebGPU)",
+      ),
+      "Basic canvas path suite": (
+          "Canvas line segments, butt caps",
+          "Canvas line segments, round caps",
+          "Canvas line segments, square caps",
+          "Canvas line path, bevel join",
+          "Canvas line path, round join",
+          "Canvas line path, miter join",
+          "Canvas line path with dash pattern",
+          "Canvas quadratic segments",
+          "Canvas quadratic path",
+          "Canvas bezier segments",
+          "Canvas bezier path",
+          "Canvas arcTo segments",
+          "Canvas arc segments",
+          "Canvas rects",
+          "Canvas ellipses",
+          "Canvas line path, fill",
+          "Canvas quadratic path, fill",
+          "Canvas bezier path, fill",
+          "Canvas arcTo segments, fill",
+          "Canvas arc segments, fill",
+          "Canvas rects, fill",
+          "Canvas ellipses, fill",
+      )
+  }
+  SUBSTORIES = tuple(itertools.chain.from_iterable(ALL_STORIES.values()))
+  READY_TIMEOUT: dt.timedelta = dt.timedelta(seconds=10)
+  DEVELOPER_READY_JS: str = (
+      "return document.querySelector('tree > li') !== undefined;")
+  # The default page is ready immediately.
+  READY_JS: str = "return true;"
+
+  @classmethod
+  def default_story_names(cls) -> Tuple[str, ...]:
+    return cls.ALL_STORIES["MotionMark"]
+
+  @property
+  def substory_duration(self) -> dt.timedelta:
+    return dt.timedelta(seconds=35)
+
+  @property
+  def url_params(self) -> Dict[str, str]:
+    return {}
+
+  def prepare_test_url(self) -> str:
+    if (url_params := self.url_params) or not self.has_default_substories:
+      updated_url = update_url_query(f"{self.url}/developer.html", url_params)
+      logging.info("CUSTOM URL: %s", updated_url)
+      return updated_url
+    return self.url
+
+  def setup(self, run: Run) -> None:
+    test_url = self.prepare_test_url()
+    use_developer_url = test_url != self.url
+    with run.actions("Setup") as actions:
+      actions.show_url(test_url)
+      self._setup_wait_until_ready(actions, use_developer_url)
+      if use_developer_url:
+        self._setup_filter_stories(actions)
+
+  def _setup_wait_until_ready(self, actions: Actions,
+                              use_developer_url: bool) -> None:
+    if use_developer_url:
+      wait_js = self.DEVELOPER_READY_JS
+    else:
+      wait_js = self.READY_JS
+    actions.wait_js_condition(wait_js, 0.2, self.READY_TIMEOUT)
+
+  def _setup_filter_stories(self, actions: Actions) -> None:
+    num_enabled = actions.js(
+        """
+      let benchmarks = arguments[0];
+      const list = document.querySelectorAll(".tree li");
+      let counter = 0;
+      for (const row of list) {
+        const name = row.querySelector("label.tree-label").textContent.trim();
+        let checked = benchmarks.includes(name);
+        const labels = row.querySelectorAll("input[type=checkbox]");
+        for (const label of labels) {
+          if (checked) {
+            label.click()
+            counter++;
+          }
+        }
+      }
+      return counter
+      """,
+        arguments=[self._substories])
+    assert num_enabled > 0, "No tests were enabled"
+    actions.wait(0.1)
+
+  def run(self, run: Run) -> None:
+    with run.actions("Running") as actions:
+      actions.js("window.benchmarkController.startBenchmark()")
+      actions.wait(self.fast_duration)
+    with run.actions("Waiting for completion") as actions:
+      actions.wait_js_condition(
+          """
+          return window.benchmarkRunnerClient.results._results != undefined
+          """,
+          0.5,
+          self.slow_duration,
+          delay=self.substory_duration / 4)
+
+
+class MotionMark1Benchmark(MotionMarkBenchmark):
+  pass
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_0.py b/crossbench/benchmarks/motionmark/motionmark_1_0.py
new file mode 100644
index 0000000..f244ee1
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/motionmark_1_0.py
@@ -0,0 +1,38 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
+                                                           MotionMark1Probe,
+                                                           MotionMark1Story)
+
+
+class MotionMark10Probe(MotionMark1Probe):
+  __doc__ = MotionMark1Probe.__doc__
+  NAME = "motionmark_1.0"
+
+
+class MotionMark10Story(MotionMark1Story):
+  NAME = "motionmark_1.0"
+  URL: str = "https://chromium-workloads.web.app/motionmark/v1.0/MotionMark/"
+  URL_OFFICIAL: str = "https://browserbench.org/MotionMark1.0/"
+
+
+class MotionMark10Benchmark(MotionMark1Benchmark):
+  """
+  Benchmark runner for MotionMark 1.0.
+
+  See https://browserbench.org/MotionMark1.0/ for more details.
+  """
+
+  NAME = "motionmark_1.0"
+  DEFAULT_STORY_CLS = MotionMark10Story
+  PROBES = (MotionMark10Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (1, 0)
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_1.py b/crossbench/benchmarks/motionmark/motionmark_1_1.py
new file mode 100644
index 0000000..a7beff9
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/motionmark_1_1.py
@@ -0,0 +1,38 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
+                                                           MotionMark1Probe,
+                                                           MotionMark1Story)
+
+
+class MotionMark11Probe(MotionMark1Probe):
+  __doc__ = MotionMark1Probe.__doc__
+  NAME = "motionmark_1.1"
+
+
+class MotionMark11Story(MotionMark1Story):
+  NAME = "motionmark_1.1"
+  URL: str = "https://chromium-workloads.web.app/motionmark/v1.1/MotionMark/"
+  URL_OFFICIAL: str = "https://browserbench.org/MotionMark1.1/"
+
+
+class MotionMark11Benchmark(MotionMark1Benchmark):
+  """
+  Benchmark runner for MotionMark 1.1.
+
+  See https://browserbench.org/MotionMark1.1/ for more details.
+  """
+
+  NAME = "motionmark_1.1"
+  DEFAULT_STORY_CLS = MotionMark11Story
+  PROBES = (MotionMark11Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (1, 1)
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_2.py b/crossbench/benchmarks/motionmark/motionmark_1_2.py
new file mode 100644
index 0000000..da80803
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/motionmark_1_2.py
@@ -0,0 +1,38 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
+                                                           MotionMark1Probe,
+                                                           MotionMark1Story)
+
+
+class MotionMark12Probe(MotionMark1Probe):
+  __doc__ = MotionMark1Probe.__doc__
+  NAME = "motionmark_1.2"
+
+
+class MotionMark12Story(MotionMark1Story):
+  NAME = "motionmark_1.2"
+  URL: str = "https://chromium-workloads.web.app/motionmark/v1.2/MotionMark/"
+  URL_OFFICIAL: str = "https://browserbench.org/MotionMark1.2/"
+
+
+class MotionMark12Benchmark(MotionMark1Benchmark):
+  """
+  Benchmark runner for MotionMark 1.2.
+
+  See https://browserbench.org/MotionMark1.2/ for more details.
+  """
+
+  NAME = "motionmark_1.2"
+  DEFAULT_STORY_CLS = MotionMark12Story
+  PROBES = (MotionMark12Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (1, 2)
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_3.py b/crossbench/benchmarks/motionmark/motionmark_1_3.py
new file mode 100644
index 0000000..6428343
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/motionmark_1_3.py
@@ -0,0 +1,45 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import Tuple
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
+                                                           MotionMark1Probe,
+                                                           MotionMark1Story)
+
+
+class MotionMark13Probe(MotionMark1Probe):
+  __doc__ = MotionMark1Probe.__doc__
+  NAME = "motionmark_1.3"
+
+
+class MotionMark13Story(MotionMark1Story):
+  NAME = "motionmark_1.3"
+  URL: str = "https://chromium-workloads.web.app/motionmark/v1.3/MotionMark/"
+  URL_OFFICIAL: str = "https://browserbench.org/MotionMark1.3/"
+  READY_TIMEOUT: dt.timedelta = dt.timedelta(seconds=12)
+  DEVELOPER_READY_JS: str = (
+      "return !(document.querySelector('#frame-rate-detection span'));")
+  READY_JS: str = (
+      "return !!("
+      "   document.querySelector('#frame-rate-label')?.textContent?.trim());")
+
+
+class MotionMark13Benchmark(MotionMark1Benchmark):
+  """
+  Benchmark runner for MotionMark 1.3.
+
+  See https://browserbench.org/MotionMark1.3/ for more details.
+  """
+
+  NAME = "motionmark_1.3"
+  DEFAULT_STORY_CLS = MotionMark13Story
+  PROBES = (MotionMark13Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (1, 3)
diff --git a/crossbench/benchmarks/speedometer/__init__.py b/crossbench/benchmarks/speedometer/__init__.py
new file mode 100644
index 0000000..90688c3
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/__init__.py
@@ -0,0 +1,22 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.benchmarks.speedometer.speedometer_2_0 import \
+    Speedometer20Benchmark
+from crossbench.benchmarks.speedometer.speedometer_2_1 import \
+    Speedometer21Benchmark
+from crossbench.benchmarks.speedometer.speedometer_3_0 import \
+    Speedometer30Benchmark
+
+benchmark_classes = [
+    Speedometer20Benchmark, Speedometer21Benchmark, Speedometer30Benchmark
+]
+
+_versions = set()
+for benchmark_cls in benchmark_classes:
+  assert benchmark_cls.version() not in _versions, (
+      f"Got duplicated benchmark version for {benchmark_cls}")
+  _versions.add(benchmark_cls.version())
diff --git a/crossbench/benchmarks/speedometer/speedometer.py b/crossbench/benchmarks/speedometer/speedometer.py
new file mode 100644
index 0000000..8359aec
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer.py
@@ -0,0 +1,269 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import json
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    Type)
+
+from crossbench import helper
+from crossbench.benchmarks.base import (BenchmarkProbeMixin, PressBenchmark,
+                                        PressBenchmarkStoryFilter)
+from crossbench.parse import NumberParser
+from crossbench.probes.helper import Flatten
+from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.metric import Metric, MetricsMerger
+from crossbench.probes.results import ProbeResult, ProbeResultDict
+from crossbench.stories.press_benchmark import PressBenchmarkStory
+
+if TYPE_CHECKING:
+  import argparse
+
+  from crossbench.path import LocalPath
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.types import Json
+
+
+def _probe_remove_tests_segments(path: Tuple[str, ...]) -> str:
+  return "/".join(segment for segment in path if segment != "tests")
+
+
+class SpeedometerProbe(
+    BenchmarkProbeMixin, JsonResultProbe, metaclass=abc.ABCMeta):
+  """
+  Speedometer-specific probe (compatible with v2.X and v3.X).
+  Extracts all speedometer times and scores.
+  """
+  JS: str = "return window.suiteValues;"
+  SORT_KEYS: bool = False
+
+  def to_json(self, actions: Actions) -> Json:
+    return actions.js(self.JS)
+
+  def flatten_json_data(self, json_data: Any) -> Json:
+    # json_data may contain multiple iterations, merge those first
+    assert isinstance(json_data, list), f"Expected list got {type(json_data)}"
+    merged = MetricsMerger(
+        json_data, key_fn=_probe_remove_tests_segments).to_json(
+            value_fn=lambda values: values.geomean, sort=self.SORT_KEYS)
+    return Flatten(merged, sort=self.SORT_KEYS).data
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        repetitions_group.results[self].json
+        for repetitions_group in group.repetitions_groups)
+    return self.write_group_result(group, merged)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self.merge_browsers_json_list(group).merge(
+        self.merge_browsers_csv_list(group))
+
+  def log_run_result(self, run: Run) -> None:
+    self._log_result(run.results, single_result=True)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    self._log_result(group.results, single_result=False)
+
+  def _log_result(self, result_dict: ProbeResultDict,
+                  single_result: bool) -> None:
+    if self not in result_dict:
+      return
+    results_json: LocalPath = result_dict[self].json
+    logging.info("-" * 80)
+    logging.critical("Speedometer results:")
+    if not single_result:
+      logging.critical("  %s", result_dict[self].csv)
+    logging.info("- " * 40)
+
+    with results_json.open(encoding="utf-8") as f:
+      data = json.load(f)
+      if single_result:
+        score = data.get("score") or data["Score"]
+        logging.critical("Score %s", score)
+      else:
+        self._log_result_metrics(data)
+
+  def _extract_result_metrics_table(self, metrics: Dict[str, Any],
+                                    table: Dict[str, List[str]]) -> None:
+    for metric_key, metric in metrics.items():
+      if not self._is_valid_metric_key(metric_key):
+        continue
+      table[metric_key].append(
+          Metric.format(metric["average"], metric["stddev"]))
+
+  @abc.abstractmethod
+  def _is_valid_metric_key(self, metric_key: str) -> bool:
+    pass
+
+
+
+class SpeedometerStory(PressBenchmarkStory, metaclass=abc.ABCMeta):
+  URL_LOCAL: str = "http://localhost:8000/"
+  DEFAULT_ITERATIONS: int = 10
+
+  def __init__(self,
+               substories: Sequence[str] = (),
+               iterations: Optional[int] = None,
+               url: Optional[str] = None):
+    self._iterations: int = iterations or self.DEFAULT_ITERATIONS
+    assert self.iterations >= 1, f"Invalid iterations count: '{iterations}'."
+    super().__init__(url=url, substories=substories)
+
+  @property
+  def iterations(self) -> int:
+    return self._iterations
+
+  @property
+  def substory_duration(self) -> dt.timedelta:
+    return self.iterations * self.single_substory_duration
+
+  @property
+  def single_substory_duration(self) -> dt.timedelta:
+    return dt.timedelta(seconds=0.4)
+
+  @property
+  def slow_duration(self) -> dt.timedelta:
+    """Max duration that covers run-times on slow machines and/or
+    debug-mode browsers.
+    Making this number too large might cause needless wait times on broken
+    browsers/benchmarks.
+    """
+    return dt.timedelta(seconds=60 * 20) + self.duration * 10
+
+  @property
+  def url_params(self) -> Dict[str, str]:
+    if self.iterations == self.DEFAULT_ITERATIONS:
+      return {}
+    return {"iterationCount": str(self.iterations)}
+
+  def setup(self, run: Run) -> None:
+    updated_url = self.get_run_url(run)
+    with run.actions("Setup") as actions:
+      actions.show_url(updated_url)
+      actions.wait_js_condition("return window.Suites !== undefined;", 0.5, 10)
+      self._setup_substories(actions)
+      self._setup_benchmark_client(actions)
+      actions.wait(0.5)
+
+  def get_run_url(self, run: Run) -> str:
+    url = super().get_run_url(run)
+    url = helper.update_url_query(url, self.url_params)
+    if url != self.url:
+      logging.info("CUSTOM URL: %s", url)
+    return url
+
+  def _setup_substories(self, actions: Actions) -> None:
+    if self._substories == self.SUBSTORIES:
+      return
+    actions.js(
+        """
+        let substories = arguments[0];
+        Suites.forEach((suite) => {
+          suite.disabled = substories.indexOf(suite.name) === -1;
+        });""",
+        arguments=[self._substories])
+
+  def _setup_benchmark_client(self, actions: Actions) -> None:
+    actions.js("""
+      window.testDone = false;
+      window.suiteValues = [];
+      const client = window.benchmarkClient;
+      const clientCopy = {
+        didRunSuites: client.didRunSuites,
+        didFinishLastIteration: client.didFinishLastIteration,
+      };
+      client.didRunSuites = function(measuredValues, ...arguments) {
+          clientCopy.didRunSuites.call(this, measuredValues, ...arguments);
+          window.suiteValues.push(measuredValues);
+      };
+      client.didFinishLastIteration = function(...arguments) {
+          clientCopy.didFinishLastIteration.call(this, ...arguments);
+          window.testDone = true;
+      };""")
+
+  def run(self, run: Run) -> None:
+    with run.actions("Running") as actions:
+      actions.js("""
+          if (window.startTest) {
+            window.startTest();
+          } else {
+            // Interactive Runner fallback / old 3.0 fallback.
+            let startButton = document.getElementById("runSuites") ||
+                document.querySelector("start-tests-button") ||
+                document.querySelector(".buttons button");
+            startButton.click();
+          }
+          """)
+      actions.wait(self.fast_duration)
+    with run.actions("Waiting for completion") as actions:
+      actions.wait_js_condition(
+          "return window.testDone",
+          0.5,
+          self.slow_duration,
+          delay=self.substory_duration)
+
+
+ProbeClsTupleT = Tuple[Type[SpeedometerProbe], ...]
+
+
+class SpeedometerBenchmarkStoryFilter(PressBenchmarkStoryFilter):
+  __doc__ = PressBenchmarkStoryFilter.__doc__
+
+  @classmethod
+  def add_cli_parser(
+      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser = super().add_cli_parser(parser)
+    parser.add_argument(
+        "--iterations",
+        "--iteration-count",
+        default=SpeedometerStory.DEFAULT_ITERATIONS,
+        type=NumberParser.positive_int,
+        help="Number of iterations each Speedometer subtest is run "
+        "within the same session. \n"
+        "Note: --repetitions restarts the whole benchmark, --iterations runs "
+        "the same test tests n-times within the same session without the setup "
+        "overhead of starting up a whole new browser.")
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["iterations"] = args.iterations
+    return kwargs
+
+  def __init__(self,
+               story_cls: Type[SpeedometerStory],
+               patterns: Sequence[str],
+               separate: bool = False,
+               url: Optional[str] = None,
+               iterations: Optional[int] = None):
+    self.iterations = iterations
+    assert issubclass(story_cls, SpeedometerStory)
+    super().__init__(story_cls, patterns, separate, url)
+
+  def create_stories_from_names(self, names: List[str],
+                                separate: bool) -> Sequence[SpeedometerStory]:
+    return self.story_cls.from_names(
+        names, separate=separate, url=self.url, iterations=self.iterations)
+
+
+class SpeedometerBenchmark(PressBenchmark, metaclass=abc.ABCMeta):
+
+  DEFAULT_STORY_CLS = SpeedometerStory
+  STORY_FILTER_CLS = SpeedometerBenchmarkStoryFilter
+
+  @classmethod
+  def short_base_name(cls) -> str:
+    return "sp"
+
+  @classmethod
+  def base_name(cls) -> str:
+    return "speedometer"
diff --git a/crossbench/benchmarks/speedometer/speedometer_2.py b/crossbench/benchmarks/speedometer/speedometer_2.py
new file mode 100644
index 0000000..3610fef
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer_2.py
@@ -0,0 +1,66 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+from typing import TYPE_CHECKING, Any, Tuple
+
+from crossbench import helper
+from crossbench.benchmarks.speedometer.speedometer import (SpeedometerProbe,
+                                                           SpeedometerStory)
+
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+
+
+class Speedometer2Probe(SpeedometerProbe):
+
+  def _is_valid_metric_key(self, metric_key: str) -> bool:
+    parts = metric_key.split("/")
+    if len(parts) == 2:
+      return True
+    if len(parts) == 1:
+      return parts[0] in ("Geomean", "Score")
+    return parts[-1] == "total"
+
+  def process_json_data(self, json_data) -> Any:
+    # Move aggregate scores to the end
+    for iteration_data in json_data:
+      iteration_data["Mean"] = iteration_data.pop("mean")
+      iteration_data["Total"] = iteration_data.pop("total")
+      iteration_data["Geomean"] = iteration_data.pop("geomean")
+      iteration_data["Score"] = iteration_data.pop("score")
+    return json_data
+
+
+class Speedometer2Story(SpeedometerStory):
+  __doc__ = SpeedometerStory.__doc__
+  SUBSTORIES: Tuple[str, ...] = (
+      "VanillaJS-TodoMVC",
+      "Vanilla-ES2015-TodoMVC",
+      "Vanilla-ES2015-Babel-Webpack-TodoMVC",
+      "React-TodoMVC",
+      "React-Redux-TodoMVC",
+      "EmberJS-TodoMVC",
+      "EmberJS-Debug-TodoMVC",
+      "BackboneJS-TodoMVC",
+      "AngularJS-TodoMVC",
+      "Angular2-TypeScript-TodoMVC",
+      "VueJS-TodoMVC",
+      "jQuery-TodoMVC",
+      "Preact-TodoMVC",
+      "Inferno-TodoMVC",
+      "Elm-TodoMVC",
+      "Flight-TodoMVC",
+  )
+
+  def log_run_test_url(self, run: Run) -> None:
+    test_url = f"{self.URL}/InteractiveRunner.html"
+    params = self.url_params
+    if len(self.substories) == 1:
+      params["suite"] = self.substories[0]
+    params["startAutomatically"] = "true"
+    official_test_url = helper.update_url_query(test_url, params)
+    logging.info("STORY PUBLIC TEST URL: %s", official_test_url)
diff --git a/crossbench/benchmarks/speedometer/speedometer_2_0.py b/crossbench/benchmarks/speedometer/speedometer_2_0.py
new file mode 100644
index 0000000..4a6c220
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer_2_0.py
@@ -0,0 +1,35 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.speedometer.speedometer import (ProbeClsTupleT,
+                                                           SpeedometerBenchmark)
+from crossbench.benchmarks.speedometer.speedometer_2 import (Speedometer2Probe,
+                                                             Speedometer2Story)
+
+
+class Speedometer20Probe(Speedometer2Probe):
+  NAME: str = "speedometer_2.0"
+
+
+class Speedometer20Story(Speedometer2Story):
+  NAME: str = "speedometer_2.0"
+  URL: str = "https://chromium-workloads.web.app/speedometer/v2.0/"
+  URL_OFFICIAL: str = "https://browserbench.org/Speedometer2.0/"
+
+
+class Speedometer20Benchmark(SpeedometerBenchmark):
+  """
+  Benchmark runner for Speedometer 2.0
+  """
+  NAME: str = "speedometer_2.0"
+  DEFAULT_STORY_CLS = Speedometer20Story
+  PROBES: ProbeClsTupleT = (Speedometer20Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (2, 0)
diff --git a/crossbench/benchmarks/speedometer/speedometer_2_1.py b/crossbench/benchmarks/speedometer/speedometer_2_1.py
new file mode 100644
index 0000000..fbf4c98
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer_2_1.py
@@ -0,0 +1,39 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple
+
+from crossbench.benchmarks.speedometer.speedometer import (ProbeClsTupleT,
+                                                           SpeedometerBenchmark)
+from crossbench.benchmarks.speedometer.speedometer_2 import (Speedometer2Probe,
+                                                             Speedometer2Story)
+
+
+class Speedometer21Probe(Speedometer2Probe):
+  NAME: str = "speedometer_2.1"
+
+
+class Speedometer21Story(Speedometer2Story):
+  NAME: str = "speedometer_2.1"
+  URL: str = "https://chromium-workloads.web.app/speedometer/v2.1/"
+  URL_OFFICIAL: str = "https://browserbench.org/Speedometer2.1/"
+
+
+class Speedometer21Benchmark(SpeedometerBenchmark):
+  """
+  Benchmark runner for Speedometer 2.1
+  """
+  NAME: str = "speedometer_2.1"
+  DEFAULT_STORY_CLS = Speedometer21Story
+  PROBES: ProbeClsTupleT = (Speedometer21Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (2, 1)
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("sp", "speedometer", "sp2", "speedometer2") + super().aliases()
diff --git a/crossbench/benchmarks/speedometer/speedometer_3_0.py b/crossbench/benchmarks/speedometer/speedometer_3_0.py
new file mode 100644
index 0000000..cfc4bcc
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer_3_0.py
@@ -0,0 +1,458 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import enum
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    Type, Union, cast)
+
+from crossbench import compat, helper
+from crossbench.benchmarks.speedometer.speedometer import (
+    ProbeClsTupleT, SpeedometerBenchmark, SpeedometerBenchmarkStoryFilter,
+    SpeedometerProbe, SpeedometerStory)
+from crossbench.browsers import viewport as vp
+from crossbench.parse import DurationParser, NumberParser
+from crossbench.stories.story import Story
+
+if TYPE_CHECKING:
+  from crossbench.cli.parser import CrossBenchArgumentParser
+  from crossbench.runner.run import Run
+  ShuffleSeedT = Optional[Union[str, int]]
+  from crossbench.runner.actions import Actions
+  from crossbench.types import Json
+
+
+class Speedometer30Probe(SpeedometerProbe):
+  """
+  Speedometer3-specific probe (compatible with v3.0).
+  Extracts all speedometer times and scores.
+  """
+  NAME: str = "speedometer_3.0"
+  JS: str = "return window.benchmarkClient.metrics"
+
+  @property
+  def speedometer(self) -> Speedometer30Benchmark:
+    return cast(Speedometer30Benchmark, self.benchmark)
+
+  def to_json(self, actions: Actions) -> Json:
+    return actions.js(self.JS)
+
+  def process_json_data(self, json_data) -> Any:
+    # Move aggregate scores to the end
+    aggregate_keys = []
+    for metric_key in json_data.keys():
+      if metric_key.startswith("Iteration-"):
+        aggregate_keys.append(metric_key)
+    aggregate_keys.extend(["Geomean", "Score"])
+    for metric_key in aggregate_keys:
+      json_data[metric_key] = json_data.pop(metric_key)
+    return json_data
+
+  def flatten_json_data(self, json_data: Any) -> Json:
+    result: Dict[str, float] = {}
+    assert isinstance(json_data, dict), f"Expected dict, got {type(json_data)}"
+    for name, metric in json_data.items():
+      result[name] = metric["mean"]
+    return result
+
+  def _is_valid_metric_key(self, metric_key: str) -> bool:
+    parts = metric_key.split("/")
+    if len(parts) != 1:
+      return False
+    if self.speedometer.detailed_metrics:
+      return True
+    if metric_key.startswith("Iteration-"):
+      return False
+    if metric_key == "Geomean":
+      return False
+    return True
+
+
+@enum.unique
+class MeasurementMethod(compat.StrEnumWithHelp):
+  RAF = ("raf", "requestAnimationFrame-based measurement")
+  TIMER = ("timer", "setTimeout-based measurement")
+
+
+def to_ms(duration: dt.timedelta) -> int:
+  return int(round(duration.total_seconds() * 1000))
+
+
+def parse_shuffle_seed(value: Optional[Any]) -> ShuffleSeedT:
+  if value in (None, "off", "generate"):
+    return value
+  if isinstance(value, int):
+    return value
+  return NumberParser.any_int(value, "shuffle-seed")
+
+
+# Generated by running this JS snippet and updating the bools:
+#  JSON.stringify(
+#    Suites.reduce((data, e) => {
+#        data[e.name]={ tags:e.tags, enabled:!e.disabled};
+#        return data}, {}))
+#  .replaceAll(":true", ":True")
+#  .replaceAll(":false", ":False");
+SPEEDOMETER_3_STORY_DATA = {
+    "TodoMVC-JavaScript-ES5": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-JavaScript-ES5-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-JavaScript-ES6-Webpack": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-JavaScript-ES6-Webpack-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-WebComponents": {
+        "tags": ["all", "default", "todomvc", "webcomponents"],
+        "enabled": True
+    },
+    "TodoMVC-WebComponents-Complex-DOM": {
+        "tags": ["all", "todomvc", "webcomponents", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-React": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-React-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-React-Redux": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-React-Redux-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-Backbone": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-Backbone-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-Angular": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-Angular-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-Vue": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-Vue-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex", "complex-default"],
+        "enabled": False
+    },
+    "TodoMVC-jQuery": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-jQuery-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-Preact": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-Preact-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-Svelte": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-Svelte-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-Lit": {
+        "tags": ["all", "todomvc", "webcomponents"],
+        "enabled": False
+    },
+    "TodoMVC-Lit-Complex-DOM": {
+        "tags": [
+            "all", "default", "todomvc", "webcomponents", "complex",
+            "complex-default"
+        ],
+        "enabled": True
+    },
+    "NewsSite-Next": {
+        "tags": ["all", "default", "newssite", "language"],
+        "enabled": True
+    },
+    "NewsSite-Nuxt": {
+        "tags": ["all", "default", "newssite"],
+        "enabled": True
+    },
+    "Editor-CodeMirror": {
+        "tags": ["all", "default", "editor"],
+        "enabled": True
+    },
+    "Editor-TipTap": {
+        "tags": ["all", "default", "editor"],
+        "enabled": True
+    },
+    "Charts-observable-plot": {
+        "tags": ["all", "default", "chart"],
+        "enabled": True
+    },
+    "Charts-chartjs": {
+        "tags": ["all", "default", "chart"],
+        "enabled": True
+    },
+    "React-Stockcharts-SVG": {
+        "tags": ["all", "default", "chart", "svg"],
+        "enabled": True
+    },
+    "Perf-Dashboard": {
+        "tags": ["all", "default", "chart", "webcomponents"],
+        "enabled": True
+    }
+}
+
+
+class Speedometer30Story(SpeedometerStory):
+  __doc__ = SpeedometerStory.__doc__
+  NAME: str = "speedometer_3.0"
+  URL: str = "https://chromium-workloads.web.app/speedometer/v3.0/"
+  URL_OFFICIAL: str = "https://browserbench.org/Speedometer3.0/"
+  URL_LOCAL: str = "http://127.0.0.1:7000"
+  SUBSTORIES: Tuple[str, ...] = tuple(SPEEDOMETER_3_STORY_DATA.keys())
+
+  @classmethod
+  def default_story_names(cls) -> Tuple[str, ...]:
+    return tuple(
+        tuple(name for name, data in SPEEDOMETER_3_STORY_DATA.items()
+              if data["enabled"]))
+
+  def __init__(self,
+               substories: Sequence[str] = (),
+               iterations: Optional[int] = None,
+               sync_wait: Optional[dt.timedelta] = None,
+               sync_warmup: Optional[dt.timedelta] = None,
+               measurement_method: Optional[MeasurementMethod] = None,
+               viewport: Optional[vp.Viewport] = None,
+               shuffle_seed: ShuffleSeedT = None,
+               url: Optional[str] = None):
+    self._sync_wait = DurationParser.positive_or_zero_duration(
+        sync_wait or dt.timedelta(0), "sync_wait")
+    self._sync_warmup = DurationParser.positive_or_zero_duration(
+        sync_warmup or dt.timedelta(0), "sync_warmup")
+    self._measurement_method: MeasurementMethod = (
+        measurement_method or MeasurementMethod.RAF)
+    self._viewport = None
+    if viewport:
+      self._viewport = vp.Viewport.parse_sized(viewport)
+    self._shuffle_seed: ShuffleSeedT = parse_shuffle_seed(shuffle_seed)
+    super().__init__(url=url, substories=substories, iterations=iterations)
+
+  @property
+  def single_substory_duration(self) -> dt.timedelta:
+    return dt.timedelta(seconds=0.25)
+
+  @property
+  def sync_wait(self) -> dt.timedelta:
+    return self._sync_wait
+
+  @property
+  def sync_warmup(self) -> dt.timedelta:
+    return self._sync_warmup
+
+  @property
+  def measurement_method(self) -> MeasurementMethod:
+    return self._measurement_method
+
+  @property
+  def viewport(self) -> Optional[vp.Viewport]:
+    return self._viewport
+
+  @property
+  def shuffle_seed(self) -> ShuffleSeedT:
+    return self._shuffle_seed
+
+  @property
+  def url_params(self) -> Dict[str, str]:
+    url_params = super().url_params
+    if sync_wait := self.sync_wait:
+      url_params["waitBeforeSync"] = str(to_ms(sync_wait))
+    if sync_warmup := self.sync_warmup:
+      url_params["warmupBeforeSync"] = str(to_ms(sync_warmup))
+    if self.measurement_method != MeasurementMethod.RAF:
+      url_params["measurementMethod"] = str(self.measurement_method)
+    if viewport := self.viewport:
+      url_params["viewport"] = f"{viewport.width}x{viewport.height}"
+    if self.shuffle_seed is not None:
+      url_params["shuffleSeed"] = str(self.shuffle_seed)
+    return url_params
+
+  def log_run_test_url(self, run: Run) -> None:
+    del run
+    params = self.url_params
+    params["suites"] = ",".join(self.substories)
+    params["developerMode"] = "true"
+    params["startAutomatically"] = "true"
+    official_test_url = helper.update_url_query(self.URL, params)
+    logging.info("STORY PUBLIC TEST URL: %s", official_test_url)
+
+
+class Speedometer3BenchmarkStoryFilter(SpeedometerBenchmarkStoryFilter):
+  __doc__ = SpeedometerBenchmarkStoryFilter.__doc__
+
+  @classmethod
+  def add_cli_parser(
+      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser = super().add_cli_parser(parser)
+    parser.add_argument(
+        "--sync-wait",
+        default=dt.timedelta(0),
+        type=DurationParser.positive_or_zero_duration,
+        help="Add a custom wait timeout before each sync step.")
+    parser.add_argument(
+        "--sync-warmup",
+        default=dt.timedelta(0),
+        type=DurationParser.positive_or_zero_duration,
+        help="Run a warmup loop for the given duration before each sync step.")
+
+    measurement_method_group = parser.add_argument_group(
+        "Measurement Method Option")
+    measurement_method_group = parser.add_mutually_exclusive_group()
+    measurement_method_group.add_argument(
+        "--raf",
+        dest="measurement_method",
+        default=MeasurementMethod.RAF,
+        const=MeasurementMethod.RAF,
+        action="store_const",
+        help=("Use the default requestAnimationFrame-based approach "
+              "for async time measurement."))
+    measurement_method_group.add_argument(
+        "--timer",
+        dest="measurement_method",
+        const=MeasurementMethod.TIMER,
+        action="store_const",
+        help=("Use the 'classical' setTimeout-based approach "
+              "for async time measurement. "
+              "This might omit measuring some async work."))
+
+    parser.add_argument(
+        "--story-viewport",
+        type=vp.Viewport.parse_sized,
+        help="Specify the speedometer workload viewport size.")
+    parser.add_argument(
+        "--shuffle-seed",
+        type=parse_shuffle_seed,
+        help=("Set a shuffle seed to run the stories in a"
+              "non-default order."))
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["iterations"] = args.iterations
+    kwargs["measurement_method"] = args.measurement_method
+    kwargs["sync_wait"] = args.sync_wait
+    kwargs["sync_warmup"] = args.sync_warmup
+    kwargs["viewport"] = args.story_viewport
+    kwargs["shuffle_seed"] = args.shuffle_seed
+    return kwargs
+
+  def __init__(self,
+               story_cls: Type[SpeedometerStory],
+               patterns: Sequence[str],
+               separate: bool = False,
+               url: Optional[str] = None,
+               iterations: Optional[int] = None,
+               measurement_method: Optional[MeasurementMethod] = None,
+               sync_wait: Optional[dt.timedelta] = None,
+               sync_warmup: Optional[dt.timedelta] = None,
+               viewport: Optional[vp.Viewport] = None,
+               shuffle_seed: ShuffleSeedT = None):
+    self.measurement_method = measurement_method
+    self.sync_wait = sync_wait
+    self.sync_warmup = sync_warmup
+    self.viewport = viewport
+    self.shuffle_seed: ShuffleSeedT = shuffle_seed
+    assert issubclass(story_cls, Speedometer30Story)
+    super().__init__(story_cls, patterns, separate, url, iterations=iterations)
+
+  def create_stories_from_names(self, names: List[str],
+                                separate: bool) -> Sequence[SpeedometerStory]:
+    return self.story_cls.from_names(
+        names,
+        separate=separate,
+        url=self.url,
+        iterations=self.iterations,
+        measurement_method=self.measurement_method,
+        sync_wait=self.sync_wait,
+        sync_warmup=self.sync_warmup,
+        viewport=self.viewport,
+        shuffle_seed=self.shuffle_seed)
+
+
+class Speedometer30Benchmark(SpeedometerBenchmark):
+  """
+  Benchmark runner for Speedometer 3.0
+  """
+  NAME: str = "speedometer_3.0"
+  DEFAULT_STORY_CLS = Speedometer30Story
+  STORY_FILTER_CLS = Speedometer3BenchmarkStoryFilter
+  PROBES: ProbeClsTupleT = (Speedometer30Probe,)
+
+  @classmethod
+  def version(cls) -> Tuple[int, ...]:
+    return (3, 0)
+
+  @classmethod
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("sp3", "speedometer_3") + super().aliases()
+
+  @classmethod
+  def add_cli_parser(
+      cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
+  ) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    parser.add_argument(
+        "--detailed-metrics",
+        "--details",
+        default=False,
+        action="store_true",
+        help="Report more detailed internal metrics.")
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["detailed_metrics"] = args.detailed_metrics
+    return kwargs
+
+  def __init__(self,
+               stories: Sequence[Story],
+               custom_url: Optional[str] = None,
+               detailed_metrics: bool = False):
+    self._detailed_metrics = detailed_metrics
+    super().__init__(stories, custom_url)
+
+  @property
+  def detailed_metrics(self) -> bool:
+    return self._detailed_metrics
diff --git a/crossbench/browsers/__init__.py b/crossbench/browsers/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/browsers/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/browsers/all.py b/crossbench/browsers/all.py
new file mode 100644
index 0000000..d436a34
--- /dev/null
+++ b/crossbench/browsers/all.py
@@ -0,0 +1,27 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+# pylint: disable=unused-import
+
+from __future__ import annotations
+
+from crossbench.browsers.chrome.applescript import ChromeAppleScript
+from crossbench.browsers.chrome.chrome import Chrome
+from crossbench.browsers.chrome.webdriver import (ChromeWebDriver,
+                                                  ChromeWebDriverAndroid,
+                                                  ChromeWebDriverChromeOsSsh,
+                                                  ChromeWebDriverSsh,
+                                                  LocalChromeWebDriverAndroid)
+from crossbench.browsers.chromium.applescript import ChromiumAppleScript
+from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.browsers.chromium.webdriver import (
+    ChromiumWebDriver, ChromiumWebDriverAndroid, ChromiumWebDriverChromeOsSsh,
+    ChromiumWebDriverSsh, LocalChromiumWebDriverAndroid)
+from crossbench.browsers.edge.edge import Edge
+from crossbench.browsers.edge.webdriver import EdgeWebDriver
+from crossbench.browsers.firefox.firefox import Firefox
+from crossbench.browsers.firefox.webdriver import FirefoxWebDriver
+from crossbench.browsers.safari.applescript import SafariAppleScript
+from crossbench.browsers.safari.safari import Safari
+from crossbench.browsers.safari.webdriver import (SafariWebDriver,
+                                                  SafariWebdriverIOS)
diff --git a/crossbench/browsers/applescript.py b/crossbench/browsers/applescript.py
new file mode 100644
index 0000000..ae4d302
--- /dev/null
+++ b/crossbench/browsers/applescript.py
@@ -0,0 +1,196 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import json
+import logging
+import os
+import subprocess
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple
+
+import psutil
+
+from crossbench import helper, plt
+from crossbench.browsers.browser import Browser
+from crossbench.env import HostEnvironment, ValidationError
+
+if TYPE_CHECKING:
+  import datetime as dt
+
+  from crossbench.path import AnyPath
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class AppleScript:
+
+  @classmethod
+  def with_args(cls, app_path: AnyPath, apple_script: str,
+                **kwargs) -> Tuple[str, List[str]]:
+    variables = []
+    replacements = {}
+    args: List[str] = []
+    for variable, value in kwargs.items():
+      args.append(value)
+      unique_variable = f"cb_input_{variable}"
+      replacements[variable] = unique_variable
+      variables.append(f"set {unique_variable} to (item {len(args)} of argv)")
+    variables_str = "\n".join(variables)
+    formatted_script = apple_script.strip() % replacements
+    wrapper = f"""
+      {variables_str}
+      tell application "{app_path}"
+        {formatted_script}
+      end tell
+    """
+    return wrapper.strip(), args
+
+  @classmethod
+  def js_script_with_args(cls, script: str, args: Sequence[object]) -> str:
+    """Create a script that returns [JSON.stringify(result), true] on success,
+    and [exception.toString(), false] when failing."""
+    args_str: str = json.dumps(args)
+    script = """JSON.stringify((function exceptionWrapper(){
+        try {
+          return [(function(...arguments){%(script)s}).apply(window, %(args_str)s), true]
+        } catch(e) {
+          return [e + "", false]
+        }
+      })())""" % {
+        "script": script,
+        "args_str": args_str
+    }
+    return script.strip()
+
+  class JavaScriptFromAppleScriptException(ValueError):
+    pass
+
+
+def try_get_parent_app_name(platform: plt.Platform) -> str:
+  if platform.is_remote:
+    return ""
+  launched_apps: Dict[str, str] = {}
+  try:
+    for line in platform.sh_stdout("launchctl", "list").splitlines():
+      parts = line.split()
+      if len(parts) == 3:
+        pid, _, label = parts
+        # Input:  "application.com.google.Chrome.46262139.72133274"
+        # Output: "Chrome"
+        label_parts = label.split(".")
+        if len(label_parts) <= 3:
+          continue
+        launched_apps[pid] = label_parts[3]
+  except Exception as e:  # pylint: disable=broad-except
+    logging.debug("Could not list all parents: %s", e)
+    return ""
+  if not launched_apps:
+    logging.debug("Could not find any apps")
+    return ""
+  try:
+    for parent in psutil.Process(os.getpid()).parents():
+      if label := launched_apps.get(str(parent.pid), ""):
+        return label
+  except Exception as e:  # pylint: disable=broad-except
+    logging.debug("Could not find parent parent app process: %s", e)
+  return ""
+
+
+SYSTEM_EVENTS_CHECK = (
+    'tell application "System Events" to log (count of windows)')
+
+class AppleScriptBrowser(Browser, metaclass=abc.ABCMeta):
+  APPLE_SCRIPT_ALLOW_JS_MENU: str = ""
+  APPLE_SCRIPT_JS_COMMAND: str = ""
+  APPLE_SCRIPT_SET_URL: str = ""
+
+  _browser_process: subprocess.Popen
+
+  def _exec_apple_script(self, apple_script: str, **kwargs) -> Any:
+    assert self.platform.is_macos, (
+        f"Sorry, f{self.__class__} is only supported on MacOS for now")
+    wrapper_script, args = AppleScript.with_args(self.app_path, apple_script,
+                                                 **kwargs)
+    return self.platform.exec_apple_script(wrapper_script, *args)
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    super().validate_env(env)
+    self._check_system_events_allowed(env)
+
+  def start(self, session: BrowserSessionRunGroup) -> None:
+    assert not self._is_running
+    # Start process directly
+    startup_flags = self._get_browser_flags_for_session(session)
+    self._log_browser_start(startup_flags)
+    self._browser_process = self.platform.popen(
+        self.path, *startup_flags, shell=False)
+    if self._browser_process.poll():
+      raise ValueError("Could not start browser process.")
+    self._pid = self._browser_process.pid
+    self.platform.sleep(3)
+    self._exec_apple_script("activate")
+    self._setup_window()
+    self._check_js_from_apple_script_allowed(session.env)
+
+  def _check_system_events_allowed(self, env: HostEnvironment) -> None:
+    try:
+      self._exec_apple_script(SYSTEM_EVENTS_CHECK)
+    except plt.SubprocessError as e:
+      logging.error("Not allowed to run AppleScript and send System Events!")
+      logging.debug("    SubprocessError: %s", e)
+      app_name = try_get_parent_app_name(self.platform) or "parent"
+      env.handle_warning(
+          f"Enable the 'System Events' permission for the {app_name} App. \n"
+          "  See 'System Settings' > 'Privacy & Security' > 'Automation'.\n")
+    try:
+      self._exec_apple_script(SYSTEM_EVENTS_CHECK)
+    except plt.SubprocessError as e:
+      raise ValidationError(
+          " Not allowed to run AppleScript and send System Events!") from e
+
+  def _check_js_from_apple_script_allowed(self, env: HostEnvironment) -> None:
+    try:
+      self.js("return 1")
+    except plt.SubprocessError as e:
+      logging.error("Browser does not allow JS from AppleScript!")
+      logging.debug("    SubprocessError: %s", e)
+      env.handle_warning("Enable JavaScript from Apple Script Events: "
+                         f"'{self.APPLE_SCRIPT_ALLOW_JS_MENU}'")
+    try:
+      self.js("return 1;")
+    except plt.SubprocessError as e:
+      raise ValidationError(
+          " JavaScript from Apple Script Events was not enabled") from e
+    self._is_running = True
+
+  @abc.abstractmethod
+  def _setup_window(self) -> None:
+    pass
+
+  def js(
+      self,
+      script: str,
+      timeout: Optional[dt.timedelta] = None,
+      arguments: Sequence[object] = ()
+  ) -> Any:
+    del timeout
+    js_script = AppleScript.js_script_with_args(script, arguments)
+    json_result: str = self._exec_apple_script(
+        self.APPLE_SCRIPT_JS_COMMAND.strip(), js_script=js_script).rstrip()
+    result, is_success = json.loads(json_result)
+    if not is_success:
+      raise AppleScript.JavaScriptFromAppleScriptException(result)
+    return result
+
+  def show_url(self, url: str, target: Optional[str] = None) -> None:
+    if target not in (None, "_self"):
+      raise NotImplementedError(
+          f"AppleScriptBrowser show_url does not support target {target}")
+    self._exec_apple_script(self.APPLE_SCRIPT_SET_URL, url=url)
+    self.platform.sleep(0.5)
+
+  def quit(self) -> None:
+    self._exec_apple_script("quit")
+    helper.wait_and_kill(self._browser_process)
diff --git a/crossbench/browsers/attributes.py b/crossbench/browsers/attributes.py
new file mode 100644
index 0000000..d899a95
--- /dev/null
+++ b/crossbench/browsers/attributes.py
@@ -0,0 +1,53 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+
+
+class BrowserAttributes(enum.IntFlag):
+  SAFARI = enum.auto()
+  FIREFOX = enum.auto()
+  CHROMIUM = enum.auto()
+  CHROME = enum.auto()
+  EDGE = enum.auto()
+
+  CHROMIUM_BASED = enum.auto()
+
+  WEBDRIVER = enum.auto()
+  APPLESCRIPT = enum.auto()
+
+  MOBILE = enum.auto()
+  DESKTOP = enum.auto()
+
+  REMOTE = enum.auto()
+
+  @property
+  def is_chromium_based(self) -> bool:
+    return bool(self.CHROMIUM_BASED & self)
+
+  @property
+  def is_chrome(self) -> bool:
+    return bool(self & self.CHROME)
+
+  @property
+  def is_safari(self) -> bool:
+    return bool(self & self.SAFARI)
+
+  @property
+  def is_edge(self) -> bool:
+    return bool(self & self.EDGE)
+
+  @property
+  def is_firefox(self) -> bool:
+    return bool(self & self.FIREFOX)
+
+  @property
+  def is_remote(self) -> bool:
+    return bool(self & self.REMOTE)
+
+  @property
+  def is_local(self) -> bool:
+    return not self.is_remote
diff --git a/crossbench/browsers/browser.py b/crossbench/browsers/browser.py
new file mode 100644
index 0000000..42075f8
--- /dev/null
+++ b/crossbench/browsers/browser.py
@@ -0,0 +1,403 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import logging
+import os
+import shlex
+from typing import TYPE_CHECKING, Any, Iterable, Optional, Sequence, Tuple
+
+from ordered_set import OrderedSet
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.settings import Settings
+from crossbench.flags.base import Flags, FlagsData, FlagsT
+
+if TYPE_CHECKING:
+  import re
+
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.browsers.splash_screen import SplashScreen
+  from crossbench.browsers.viewport import Viewport
+  from crossbench.cli.config.secrets import Secret, SecretsDict
+  from crossbench.env import HostEnvironment
+  from crossbench.flags.chrome import ChromeFeatures
+  from crossbench.flags.js_flags import JSFlags
+  from crossbench.network.base import Network
+  from crossbench.probes.probe import Probe
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+  from crossbench.types import JsonDict
+
+
+class Browser(abc.ABC):
+
+  @classmethod
+  def default_flags(cls, initial_data: FlagsData = None) -> Flags:
+    return Flags(initial_data)
+
+  def __init__(self,
+               label: str,
+               path: Optional[pth.AnyPath] = None,
+               settings: Optional[Settings] = None):
+    self._settings = settings or Settings()
+    self._platform = self._settings.platform
+    self.label: str = label
+    self._unique_name: str = ""
+    self.app_name: str = self.type_name
+    self.version: str = "custom"
+    self.major_version: int = 0
+    self.app_path: pth.AnyPath = pth.AnyPath()
+    self.path = pth.AnyPath()
+    self._setup_path(path)
+    self._is_running: bool = False
+    self._pid: Optional[int] = None
+    self._probes: OrderedSet[Probe] = OrderedSet()
+    self._flags: Flags = self._setup_flags(self._settings)
+    self.log_file: Optional[pth.AnyPath] = None
+    self.cache_dir: Optional[pth.AnyPath] = self._settings.cache_dir
+    self.clear_cache_dir: bool = True
+    self._setup_cache_dir(self._settings)
+
+  def _setup_path(self, path: Optional[pth.AnyPath] = None) -> None:
+    if not path:
+      # TODO: separate class for remote browser (selenium) without an explicit
+      # binary path.
+      self.unique_name = f"{self.type_name}_{self.label}".lower()
+      return
+    self.path = self._resolve_binary(path)
+    # TODO clean up
+    if not self.platform.is_android:
+      assert self.path.is_absolute()
+    self.version = self._extract_version()
+    self.major_version = int(self.version.split(".")[0])
+    self.unique_name = f"{self.type_name}_v{self.major_version}_{self.label}"
+
+  def _setup_flags(self, settings: Settings) -> Flags:
+    assert not self._settings.js_flags, (
+        f"{self} doesn't support custom js_flags")
+    return self.default_flags(settings.flags)
+
+  def _setup_cache_dir(self, settings: Settings) -> None:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def type_name(self) -> str:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def attributes(self) -> BrowserAttributes:
+    pass
+
+  @property
+  def platform(self) -> plt.Platform:
+    return self._platform
+
+  @property
+  def host_platform(self) -> plt.Platform:
+    return self._platform.host_platform
+
+  @property
+  def unique_name(self) -> str:
+    return self._unique_name
+
+  @unique_name.setter
+  def unique_name(self, name: str) -> None:
+    assert name
+    # Replace any potentially unsafe chars in the name
+    self._unique_name = pth.safe_filename(name).lower()
+
+  @property
+  def network(self) -> Network:
+    return self._settings.network
+
+  @property
+  def secrets(self) -> SecretsDict:
+    return self._settings.secrets
+
+  @property
+  def splash_screen(self) -> SplashScreen:
+    return self._settings.splash_screen
+
+  @property
+  def viewport(self) -> Viewport:
+    return self._settings.viewport
+
+  @viewport.setter
+  def viewport(self, value: Viewport) -> None:
+    self._settings.viewport = value
+
+  @property
+  def wipe_system_user_data(self) -> bool:
+    return self._settings.wipe_system_user_data
+
+  @property
+  def http_request_timeout(self) -> dt.timedelta:
+    return self._settings.http_request_timeout
+
+  @property
+  def probes(self) -> Iterable[Probe]:
+    return iter(self._probes)
+
+  @property
+  def flags(self) -> Flags:
+    return self._flags
+
+  @property
+  def features(self) -> ChromeFeatures:
+    raise NotImplementedError(f"Unsupported feature flags on {self}.")
+
+  @property
+  def js_flags(self) -> JSFlags:
+    raise NotImplementedError(f"Unsupported feature flags on {self}.")
+
+  def user_agent(self) -> str:
+    return str(self.js("return window.navigator.userAgent"))
+
+  @property
+  def pid(self) -> Optional[int]:
+    return self._pid
+
+  @property
+  def is_running_process(self) -> Optional[bool]:
+    # TODO: activate this method again
+    if self.pid is None:
+      return None
+    info = self.platform.process_info(self.pid)
+    if info is None:
+      return None
+    if status := info.get("status"):
+      return status in ("running", "sleeping")
+    # TODO(cbruni): fix posix process_info for remote platforms where
+    # we don't get the status back.
+    return False
+
+  @property
+  def is_running(self) -> bool:
+    return self._is_running
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    """Called before starting a browser / browser session to perform
+    a pre-run checklist."""
+
+  @property
+  def is_local(self) -> bool:
+    return self.platform.is_local
+
+  @property
+  def is_remote(self) -> bool:
+    return self.platform.is_remote
+
+  def set_log_file(self, path: pth.AnyPath) -> None:
+    self.log_file = path
+
+  @property
+  def stdout_log_file(self) -> pth.AnyPath:
+    assert self.log_file
+    return self.log_file.with_suffix(".stdout.log")
+
+  def _resolve_binary(self, path: pth.AnyPath) -> pth.AnyPath:
+    path = self.platform.absolute(path)
+    assert self.platform.exists(path), f"Binary at path={path} does not exist."
+    self.app_path = path
+    self.app_name = self.app_path.stem
+    if self.platform.is_macos:
+      path = self._resolve_macos_binary(path)
+    assert self.platform.is_file(path), (
+        f"Binary at path={path} is not a file.")
+    return path
+
+  def _resolve_macos_binary(self, path: pth.AnyPath) -> pth.AnyPath:
+    assert self.platform.is_macos
+    candidate = self.platform.search_binary(path)
+    if not candidate or not self.platform.is_file(candidate):
+      raise ValueError(f"Could not find browser executable in {path}")
+    return candidate
+
+  def attach_probe(self, probe: Probe) -> None:
+    if probe in self._probes:
+      raise ValueError(f"Cannot attach same probe twice: {probe}")
+    self._probes.add(probe)
+    probe.attach(self)
+
+  def details_json(self) -> JsonDict:
+    return {
+        "label": self.label,
+        "browser": self.type_name,
+        "unique_name": self.unique_name,
+        "app_name": self.app_name,
+        "version": self.version,
+        "flags": tuple(self.flags),
+        "js_flags": tuple(),
+        "path": os.fspath(self.path),
+        "clear_cache_dir": self.clear_cache_dir,
+        "major_version": self.major_version,
+        "log": {}
+    }
+
+  def validate_binary(self) -> None:
+    """ Helper method is called from the Runner before any Runs / Sessions
+    have started."""
+
+  def setup_binary(self) -> None:
+    """ This helper is called in the setup steps of each Session.
+    This can be used to install a custom binary on remote devices. """
+
+  def setup(self, session: BrowserSessionRunGroup) -> None:
+    assert not self._is_running, (
+        "Previously used browser was not correctly stopped.")
+    self.clear_cache()
+    self.start(session)
+    assert self._is_running
+
+  def is_logged_in(self, secret: Secret, strict: bool = False) -> bool:
+    """Determines whether the browser is already logged in with the given
+    credentials.
+
+    Args:
+      secret: The credentials to check.
+      strict: Whether or not to raise an error if login is impossible
+
+    Returns:
+      True if and only if the browser is already logged in with the account
+
+    Raises:
+      RuntimeError: If strict, when logging in with the given cridentials is
+      not possible.
+    """
+    del secret
+    del strict
+    return False
+
+  @abc.abstractmethod
+  def _extract_version(self) -> str:
+    pass
+
+  def clear_cache(self) -> None:
+    if self.clear_cache_dir and self.cache_dir:
+      self.platform.rm(self.cache_dir, missing_ok=True, dir=True)
+      self.platform.mkdir(self.cache_dir, parents=True)
+
+  @abc.abstractmethod
+  def start(self, session: BrowserSessionRunGroup) -> None:
+    pass
+
+  def _log_browser_start(self,
+                         args: Tuple[str, ...],
+                         driver_path: Optional[pth.AnyPath] = None) -> None:
+    logging.info("STARTING BROWSER Binary:  %s", self.path)
+    logging.info("STARTING BROWSER Version: %s", self.version)
+    if driver_path:
+      logging.info("STARTING BROWSER Driver:  %s", driver_path)
+    logging.info("STARTING BROWSER Network: %s", self.network)
+    logging.info("STARTING BROWSER Probes:  %s",
+                 ", ".join(p.NAME for p in self.probes))
+    logging.info("STARTING BROWSER Flags:   %s", shlex.join(args))
+
+  def _get_browser_flags_for_session(
+      self, session: BrowserSessionRunGroup) -> Tuple[str, ...]:
+    flags_copy: Flags = self.flags.copy()
+    flags_copy.update(session.extra_flags)
+    flags_copy.update(self.network.extra_flags(self.attributes))
+    flags_copy = self._filter_flags_for_run(flags_copy)
+    return tuple(flags_copy)
+
+  def _filter_flags_for_run(self, flags: FlagsT) -> FlagsT:
+    return flags
+
+  def quit(self) -> None:
+    assert self._is_running, "Browser is already stopped"
+    try:
+      self.force_quit()
+    finally:
+      self._pid = None
+
+  def force_quit(self) -> None:
+    if not self._is_running:
+      return
+    logging.info("Browser.force_quit()")
+    if self.platform.is_macos:
+      self.platform.exec_apple_script(f"""
+  tell application "{self.app_path}"
+    quit
+  end tell
+      """)
+    elif self._pid:
+      self.platform.terminate(self._pid)
+    self._is_running = False
+
+  @abc.abstractmethod
+  def js(
+      self,
+      script: str,
+      timeout: Optional[dt.timedelta] = None,
+      arguments: Sequence[object] = ()
+  ) -> Any:
+    pass
+
+  def run_script_on_new_document(self, script: str) -> None:
+    del script
+    raise NotImplementedError(
+        f"New document script injection is not supported by {self}")
+
+  def current_window_id(self) -> str:
+    raise NotImplementedError(f"current_window_id is not implemented by {self}")
+
+  def switch_window(self, window_id: str) -> None:
+    del window_id
+    raise NotImplementedError(f"switch_window is not implemented by {self}")
+
+  def switch_tab(
+      self,
+      title: Optional[re.Pattern] = None,
+      url: Optional[re.Pattern] = None,
+      tab_index: Optional[int] = None,
+      timeout: dt.timedelta = dt.timedelta(seconds=0)
+  ) -> None:
+    del title
+    del url
+    del tab_index
+    del timeout
+    raise NotImplementedError(f"Switching tabs is not supported by {self}")
+
+  @abc.abstractmethod
+  def show_url(self, url: str, target: Optional[str] = None) -> None:
+    pass
+
+  def switch_to_new_tab(self) -> None:
+    raise NotImplementedError(f"New tab is not supported by {self}")
+
+  def screenshot(self, path: pth.LocalPath) -> None:
+    # TODO: implement screenshot on browser and platform.
+    raise NotImplementedError(f"Taking screenshots is not supported by {self}")
+
+  def _sync_viewport_flag(self, flags: Flags, flag: str,
+                          is_requested_by_viewport: bool,
+                          replacement: Viewport) -> None:
+    if is_requested_by_viewport:
+      flags.set(flag)
+    elif flag in flags:
+      if self.viewport.is_default:
+        self.viewport = replacement
+      else:
+        raise ValueError(
+            f"{flag} conflicts with requested --viewport={self.viewport}")
+
+  def __str__(self) -> str:
+    platform_prefix = ""
+    if self.platform.is_remote:
+      platform_prefix = str(self.platform)
+    return f"{platform_prefix}{self.type_name.capitalize()}:{self.label}"
+
+  def __hash__(self) -> int:
+    # Poor-man's hash, browsers should be unique.
+    return hash(id(self))
+
+  def performance_mark(self, name: str):
+    self.js("performance.mark(arguments[0]);", arguments=[name])
diff --git a/crossbench/browsers/browser_helper.py b/crossbench/browsers/browser_helper.py
new file mode 100644
index 0000000..a70b507
--- /dev/null
+++ b/crossbench/browsers/browser_helper.py
@@ -0,0 +1,19 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import Optional
+
+_FLAG_TO_PATH_RE = re.compile(r"[-/\\:.]")
+
+
+def convert_flags_to_label(*flags: str, index: Optional[int] = None) -> str:
+  label = "default"
+  if flags:
+    label = _FLAG_TO_PATH_RE.sub("_", "_".join(flags).replace("--", ""))
+  if index is None:
+    return label
+  return f"{str(index).rjust(2,'0')}_{label}"
diff --git a/crossbench/browsers/chrome/__init__.py b/crossbench/browsers/chrome/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/browsers/chrome/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/browsers/chrome/applescript.py b/crossbench/browsers/chrome/applescript.py
new file mode 100644
index 0000000..b1e4a1c
--- /dev/null
+++ b/crossbench/browsers/chrome/applescript.py
@@ -0,0 +1,33 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from selenium import webdriver
+from selenium.webdriver.chrome.options import Options as ChromeOptions
+from selenium.webdriver.chrome.service import Service as ChromeService
+
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chrome.helper import ChromePathMixin
+from crossbench.browsers.chromium.applescript import ChromiumAppleScript
+
+if TYPE_CHECKING:
+  from selenium.webdriver.chromium.webdriver import ChromiumDriver
+
+
+class ChromeAppleScript(ChromePathMixin, ChromiumAppleScript):
+
+  WEB_DRIVER_OPTIONS = ChromeOptions
+  WEB_DRIVER_SERVICE = ChromeService
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return (BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
+            | BrowserAttributes.APPLESCRIPT)
+
+  def _create_driver(self, options: ChromeOptions,
+                     service: ChromeService) -> ChromiumDriver:
+    return webdriver.Chrome(options=options, service=service)
diff --git a/crossbench/browsers/chrome/chrome.py b/crossbench/browsers/chrome/chrome.py
new file mode 100644
index 0000000..c8c44c2
--- /dev/null
+++ b/crossbench/browsers/chrome/chrome.py
@@ -0,0 +1,16 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chrome.helper import ChromePathMixin
+from crossbench.browsers.chromium.chromium import Chromium
+
+
+class Chrome(ChromePathMixin, Chromium):
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
diff --git a/crossbench/browsers/chrome/downloader.py b/crossbench/browsers/chrome/downloader.py
new file mode 100644
index 0000000..8aa9332
--- /dev/null
+++ b/crossbench/browsers/chrome/downloader.py
@@ -0,0 +1,526 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+import json
+import logging
+import tempfile
+import zipfile
+from typing import (TYPE_CHECKING, Dict, Final, Iterable, List, Optional, Tuple,
+                    Type, Union, cast)
+
+from crossbench import helper
+from crossbench import path as pth
+from crossbench.browsers.chrome.version import ChromeVersion
+from crossbench.browsers.downloader import (DMGArchiveHelper, Downloader,
+                                            IncompatibleVersionError,
+                                            RPMArchiveHelper)
+from crossbench.browsers.version import BrowserVersion, BrowserVersionChannel
+from crossbench.plt.android_adb import AndroidAdbPlatform
+from crossbench.plt.base import SubprocessError
+
+if TYPE_CHECKING:
+  from crossbench.plt.android_adb import Adb
+  from crossbench.plt.base import Platform
+
+
+class ChromeDownloader(Downloader):
+  STORAGE_URL: str = "gs://chrome-signed/desktop-5c0tCh/"
+  VERSION_URL = (
+      "https://versionhistory.googleapis.com/v1/"
+      "chrome/platforms/{platform}/channels/{channel}/versions?filter={filter}")
+  VERSION_URL_PLATFORM_LOOKUP: Dict[Tuple[str, str], str] = {
+      ("win", "ia32"): "win",
+      ("win", "x64"): "win64",
+      ("linux", "x64"): "linux",
+      ("macos", "x64"): "mac",
+      ("macos", "arm64"): "mac_arm64",
+      ("android", "arm64"): "android",
+  }
+
+  def __init__(self, *args, **kwargs):
+    self._gsutil: Optional[pth.AnyPath] = None
+    super().__init__(*args, **kwargs)
+
+  @classmethod
+  def is_valid_version(cls, path_or_identifier: str):
+    return ChromeVersion.is_valid_unique(path_or_identifier)
+
+  @classmethod
+  def _is_valid(cls, path_or_identifier: pth.AnyPathLike,
+                browser_platform: Platform) -> bool:
+    if cls.is_valid_version(str(path_or_identifier)):
+      return True
+    path = browser_platform.path(path_or_identifier)
+    return (browser_platform.exists(path) and
+            path.name.endswith(cls.ARCHIVE_SUFFIX))
+
+  @classmethod
+  def _get_loader_cls(cls,
+                      browser_platform: Platform) -> Type[ChromeDownloader]:
+    if browser_platform.is_macos:
+      return ChromeDownloaderMacOS
+    if browser_platform.is_linux:
+      return ChromeDownloaderLinux
+    if browser_platform.is_win:
+      return ChromeDownloaderWin
+    if browser_platform.is_android:
+      return ChromeDownloaderAndroid
+    raise ValueError(
+        "Downloading chrome is only supported on linux and macOS, "
+        f"but not on {browser_platform.name} {browser_platform.machine}")
+
+  def _pre_check(self) -> None:
+    super()._pre_check()
+    if not self._requested_version:
+      return
+    self._gsutil = self.host_platform.which("gsutil")
+    if not self._gsutil:
+      raise ValueError(
+          f"Cannot download chrome version {self._requested_version}: "
+          "please install gsutil.\n"
+          "- https://cloud.google.com/storage/docs/gsutil_install\n"
+          "- Run 'gcloud auth login' to get access to the archives "
+          "(googlers only).")
+
+  @property
+  def gsutil(self) -> pth.AnyPath:
+    assert self._gsutil, "gsutil not be found."
+    return self._gsutil
+
+  def _requested_version_validation(self) -> None:
+    pass
+
+  def _parse_version(self, version_identifier: str) -> BrowserVersion:
+    return ChromeVersion.parse_unique(version_identifier)
+
+  def _find_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
+    # Quick probe for complete versions
+    if self._requested_version.is_complete:
+      return self._find_exact_archive_url()
+    return self._find_milestone_archive_url()
+
+  def _find_milestone_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
+    milestone: int = self._requested_version.major
+    platform = self.VERSION_URL_PLATFORM_LOOKUP.get(self._browser_platform.key)
+    if not platform:
+      raise ValueError(f"Unsupported platform {self._browser_platform}")
+    # Version ordering is: stable < beta < dev < canary < canary_asan
+    # See https://developer.chrome.com/docs/web-platform/versionhistory/reference#filter
+    channel_filter = "channel<=canary"
+    requested_channel = BrowserVersionChannel.ANY
+    if self._requested_version.has_channel:
+      requested_channel = self._requested_version.channel
+      channel_filter = f"channel={self._requested_version.channel_name}"
+
+    url = self.VERSION_URL.format(
+        platform=platform,
+        channel="all",
+        filter=f"version>={milestone},version<{milestone+1},{channel_filter}&")
+    logging.debug("LIST ALL VERSIONS for M%s: %s", milestone, url)
+    version_urls: List[Tuple[BrowserVersion, str]] = []
+    try:
+      with helper.urlopen(url) as response:
+        raw_infos = json.loads(response.read().decode("utf-8"))["versions"]
+        version_urls = [
+            self._create_version_url(
+                ChromeVersion(
+                    map(int, info["version"].split(".")), requested_channel))
+            for info in raw_infos
+        ]
+    except Exception as e:
+      raise ValueError(
+          f"Could not find version {self._requested_version} "
+          f"for {self._browser_platform.name} {self._browser_platform.machine} "
+      ) from e
+    logging.debug("FILTERING %d CANDIDATES", len(version_urls))
+    return self._filter_candidate_urls(version_urls)
+
+  def _create_version_url(
+      self, version: BrowserVersion) -> Tuple[BrowserVersion, str]:
+    # TODO: respect channel
+    assert version.has_complete_parts
+    return (version,
+            f"{self.STORAGE_URL}{version.parts_str}/{self._platform_name}/")
+
+  def _find_exact_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
+    # TODO: respect channel
+    version, test_url = self._create_version_url(self._requested_version)
+    logging.debug("LIST VERSIONS for M%s: %s", self._requested_version,
+                  test_url)
+    return self._filter_candidate_urls([(version, test_url)])
+
+  def _filter_candidate_urls(
+      self, versions_urls: List[Tuple[BrowserVersion, str]]
+  ) -> Tuple[BrowserVersion, Optional[str]]:
+    versions_urls.sort(key=lambda x: x[1], reverse=True)
+    # Iterate from new to old version and and the first one that is older or
+    # equal than the requested version.
+    for version, url in versions_urls:
+      if not self._requested_version.contains(version):
+        logging.debug("Skipping download candidate: %s %s", version, url)
+        continue
+      for archive_version, archive_url in self._archive_urls(url, version):
+        try:
+          result = self.host_platform.sh_stdout(self.gsutil, "ls", archive_url)
+        except SubprocessError as e:
+          logging.debug("gsutil failed: %s", e)
+          continue
+        if result:
+          return archive_version, archive_url
+    return self._requested_version, None
+
+  def _download_archive(self, archive_url: str, tmp_dir: pth.LocalPath) -> None:
+    self.host_platform.sh(self.gsutil, "cp", archive_url, tmp_dir)
+    archive_candidates = list(tmp_dir.glob("*"))
+    assert len(archive_candidates) == 1, (
+        f"Download tmp dir contains more than one file: {tmp_dir}: "
+        f"{archive_candidates}")
+    candidate = archive_candidates[0]
+    assert not self._archive_path.exists(), (
+        f"Archive was already downloaded: {self._archive_path}")
+    candidate.replace(self._archive_path)
+
+
+class ChromeDownloaderLinux(ChromeDownloader):
+  ARCHIVE_SUFFIX: str = ".rpm"
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: pth.AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return cls._is_valid(path_or_identifier, browser_platform)
+
+  def __init__(self, version_identifier: Union[str, pth.LocalPath],
+               browser_type: str, platform_name: str,
+               browser_platform: Platform):
+    assert not browser_type
+    if browser_platform.is_linux and browser_platform.is_x64:
+      platform_name = "linux64"
+    else:
+      raise ValueError("Unsupported linux architecture for downloading chrome: "
+                       f"got={browser_platform.machine} supported=linux.x64")
+    super().__init__(version_identifier, "chrome", platform_name,
+                     browser_platform)
+
+  def _installed_app_path(self) -> pth.LocalPath:
+    dir_name = "chrome-unstable"
+    if self._requested_version.is_stable or self._requested_version.is_unknown:
+      dir_name = "chrome"
+    if self._requested_version.is_beta:
+      dir_name = "chrome-beta"
+    return self._extracted_path() / "opt/google" / dir_name / "chrome"
+
+  def _archive_urls(
+      self, folder_url: str,
+      version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
+    parts_str = version.parts_str
+    parts = version.parts
+    stable = (ChromeVersion.stable(parts),
+              f"{folder_url}google-chrome-stable-{parts_str}-1.x86_64.rpm")
+    if version.is_stable:
+      return (stable,)
+    beta = (ChromeVersion.beta(parts),
+            f"{folder_url}google-chrome-beta-{parts_str}-1.x86_64.rpm")
+    if version.is_beta:
+      return (beta,)
+    dev = (ChromeVersion.alpha(parts),
+           f"{folder_url}google-chrome-unstable-{parts_str}-1.x86_64.rpm")
+    if version.is_alpha:
+      return (dev,)
+    if version.is_pre_alpha:
+      raise ValueError(f"Canary not supported on linux: {version}")
+    return (stable, beta, dev)
+
+  def _install_archive(self, archive_path: pth.LocalPath) -> None:
+    extracted_path = self._extracted_path()
+    RPMArchiveHelper.extract(self.host_platform, archive_path, extracted_path)
+    assert extracted_path.exists()
+
+
+class ChromeDownloaderMacOS(ChromeDownloader):
+  ARCHIVE_SUFFIX: str = ".dmg"
+  MIN_MAC_ARM64_MILESTONE: Final[int] = 87
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: pth.AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return cls._is_valid(path_or_identifier, browser_platform)
+
+  def __init__(self, version_identifier: Union[str, pth.LocalPath],
+               browser_type: str, platform_name: str,
+               browser_platform: Platform):
+    assert not browser_type
+    assert browser_platform.is_macos, f"{type(self)} can only be used on macOS"
+    platform_name = "mac-universal"
+    super().__init__(version_identifier, "chrome", platform_name,
+                     browser_platform)
+
+  def _requested_version_validation(self) -> None:
+    assert self._browser_platform.is_macos
+    major_version: int = self._requested_version.major
+    if (self._browser_platform.is_arm64 and
+        (major_version < self.MIN_MAC_ARM64_MILESTONE)):
+      raise ValueError(
+          "Native Mac arm64/m1 Chrome version is available with M87, "
+          f"but requested M{major_version}.")
+
+  def _download_archive(self, archive_url: str, tmp_dir: pth.LocalPath) -> None:
+    assert self._browser_platform.is_macos
+    if self._browser_platform.is_arm64 and (self._requested_version.major
+                                            < self.MIN_MAC_ARM64_MILESTONE):
+      raise ValueError(
+          "Chrome Arm64 Apple Silicon is only available starting with M87, "
+          f"but requested {self._requested_version} is too old.")
+    super()._download_archive(archive_url, tmp_dir)
+
+  def _archive_urls(
+      self, folder_url: str,
+      version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
+    # TODO: respect channel
+    version_str: str = version.parts_str
+    parts = version.parts
+    stable = (ChromeVersion.stable(parts),
+              f"{folder_url}GoogleChrome-{version_str}.dmg")
+    if version.is_stable:
+      return (stable,)
+    beta = (ChromeVersion.beta(parts),
+            f"{folder_url}GoogleChromeBeta-{version_str}.dmg")
+    if version.is_beta:
+      return (beta,)
+    dev = (ChromeVersion.alpha(parts),
+           f"{folder_url}GoogleChromeDev-{version_str}.dmg")
+    if version.is_alpha:
+      return (dev,)
+    canary = (ChromeVersion.pre_alpha(parts),
+              f"{folder_url}GoogleChromeCanary-{version_str}.dmg")
+    if version.is_pre_alpha:
+      return (canary,)
+    return (stable, beta, dev, canary)
+
+  def _extracted_path(self) -> pth.LocalPath:
+    # TODO: support local vs remote
+    return self._installed_app_path()
+
+  def _installed_app_path(self) -> pth.LocalPath:
+    return self._out_dir / f"Google Chrome {self._requested_version}.app"
+
+  def _install_archive(self, archive_path: pth.LocalPath) -> None:
+    extracted_path = self._extracted_path()
+    if archive_path.suffix == ".dmg":
+      DMGArchiveHelper.extract(self.host_platform, archive_path, extracted_path)
+    else:
+      raise ValueError(f"Unknown archive type: {archive_path}")
+    assert extracted_path.exists()
+
+
+class ChromeDownloaderAndroid(ChromeDownloader):
+  """The android downloader for Chrome pulls .apks and the
+  corresponding .apk library and installs both on the attached device."""
+  ARCHIVE_SUFFIX: str = ".apks"
+  LIBRARY_ARCHIVE_SUFFIX: str = ".lib.apk"
+  STORAGE_URL: str = "gs://chrome-signed/android-B0urB0N/"
+
+  MIN_HIGH_ARM_64_MILESTONE: Final[int] = 104
+  ARM_32_BUILD: Final[str] = "arm"
+  ARM_64_BUILD: Final[str] = "arm_64"
+  ARM_64_HIGH_BUILD: Final[str] = "high-arm_64"
+
+  CHANNEL_PACKAGE_LOOKUP: Dict[str, Tuple[str, BrowserVersionChannel]] = {
+      "Beta": (
+          "com.chrome.beta",
+          BrowserVersionChannel.BETA,
+      ),
+      "Dev": ("com.chrome.dev", BrowserVersionChannel.ALPHA),
+      "Canary": ("com.chrome.canary", BrowserVersionChannel.PRE_ALPHA),
+      # Let's check stable last to avoid overriding the default installation
+      # if possible.
+      "Stable": ("com.android.chrome", BrowserVersionChannel.STABLE),
+  }
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: pth.AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return cls._is_valid(path_or_identifier, browser_platform)
+
+  def __init__(self, version_identifier: Union[str, pth.LocalPath],
+               browser_type: str, platform_name: str,
+               browser_platform: Platform):
+    assert not browser_type
+    assert browser_platform.is_android, (
+        f"{type(self)} can only be used on Android")
+    # TODO: support more CPU types
+    assert browser_platform.is_arm64, f"{type(self)} only supports arm64"
+    # TODO: support low-end arm_64 and high-arm_64 at the same time.
+    platform_name = "high-arm_64"
+    super().__init__(version_identifier, "chrome", platform_name,
+                     browser_platform)
+
+  @property
+  def adb(self) -> Adb:
+    return cast(AndroidAdbPlatform, self._browser_platform).adb
+
+  def _pre_check(self) -> None:
+    super()._pre_check()
+    assert self._browser_platform.is_android, (
+        f"Expected android but got {self._browser_platform}")
+
+  def _requested_version_validation(self) -> None:
+    assert self._browser_platform.is_android
+    # TODO: support custom android builds
+    if self._requested_version.major < self.MIN_HIGH_ARM_64_MILESTONE:
+      self._platform_name = self.ARM_64_BUILD
+    else:
+      self._platform_name = self.ARM_64_HIGH_BUILD
+
+  def _installed_app_version(self, app_path: pth.LocalPath) -> BrowserVersion:
+    raw_version = self._browser_platform.app_version(app_path)
+    channel = BrowserVersionChannel.STABLE
+    for value in self.CHANNEL_PACKAGE_LOOKUP.values():
+      (package_name, package_channel) = value
+      if app_path.name == package_name:
+        channel = package_channel
+        break
+    return ChromeVersion.parse(raw_version, channel)
+
+  def _archive_urls(
+      self, folder_url: str,
+      version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
+    prefix: str = f"{folder_url}"
+    urls: List[Tuple[BrowserVersion, str]] = []
+    # TODO: pass in correct sdk_level
+    package = self._get_chrome_package(100)
+    # TODO: respect version channel
+    for channel_name, (_, channel) in self.CHANNEL_PACKAGE_LOOKUP.items():
+      channel_version = ChromeVersion(version.parts, channel)
+      version_url = (channel_version,
+                     f"{prefix}{package}{channel_name}{self.ARCHIVE_SUFFIX}")
+      if version.matches_channel(channel_version.channel):
+        return (version_url,)
+      urls.append(version_url)
+    return tuple(urls)
+
+  def _get_chrome_package(self, sdk_level: int) -> str:
+    del sdk_level
+    # TODO support older SDKs at some point
+    # if sdk_level < 19:
+    #   raise RuntimeError(
+    #       f"Clank can only be installed on >= 19, not {sdk_level}")
+    # if sdk_level < 21:
+    #   return "Chrome"
+    # if sdk_level < 24:
+    #   return "ChromeModern"
+    # if sdk_level < 29:
+    #   return "Monochrome"
+    return "TrichromeChromeGoogle6432"
+
+  def _extracted_path(self) -> pth.LocalPath:
+    return self._archive_path
+
+  def _installed_app_path(self) -> pth.LocalPath:
+    for channel, (package_name, _) in self.CHANNEL_PACKAGE_LOOKUP.items():
+      if channel in self._archive_url:
+        logging.debug("Using package: %s", package_name)
+        return pth.LocalPath(package_name)
+    package_name, _ = self.CHANNEL_PACKAGE_LOOKUP["Stable"]
+    return pth.LocalPath(package_name)
+
+  def _find_matching_installed_version(self) -> Optional[pth.LocalPath]:
+    # TODO: we should use aapt and read the package name directly from
+    # the apk: `aapt dump badging <path-to-apk> | grep package:\ name`
+    # Iterate over all chrome versions and find any matching release
+    installed_packages = self.adb.packages()
+    for value in self.CHANNEL_PACKAGE_LOOKUP.values():
+      (package_name, package_channel) = value
+      if not self._requested_version.matches_channel(package_channel):
+        continue
+      if package_name not in installed_packages:
+        continue
+      try:
+        package = pth.LocalPath(package_name)
+        self._validate_installed(package)
+        return package
+      except IncompatibleVersionError as e:
+        logging.debug("Ignoring installed package %s: %s", package_name, e)
+    return None
+
+  def _download_archive(self, archive_url: str, tmp_dir: pth.LocalPath) -> None:
+    super()._download_archive(archive_url, tmp_dir)
+    if "TrichromeChromeGoogle" not in archive_url:
+      return
+    # Download TrichromeLibrary.apk needed by TrichromeChromeGoogle.apks
+    with self._prepare_lib_archive_download(archive_url) as (lib_archive_url,
+                                                             lib_tmp_dir):
+      super()._download_archive(lib_archive_url, lib_tmp_dir)
+
+  @contextlib.contextmanager
+  def _prepare_lib_archive_download(self, archive_url: str):
+    # Also download the trichrome library (such a mess)
+    main_archive_path = self._archive_path
+    lib_archive_path = main_archive_path.with_suffix(
+        self.LIBRARY_ARCHIVE_SUFFIX)
+    if lib_archive_path.exists():
+      return
+    self._archive_path = lib_archive_path
+    lib_url = archive_url.replace("TrichromeChromeGoogle",
+                                  "TrichromeLibraryGoogle")
+    lib_url = lib_url.replace(self.ARCHIVE_SUFFIX, ".apk")
+    with tempfile.TemporaryDirectory(prefix="cb_download_") as tmp_dir_name:
+      lib_tmp_dir = pth.LocalPath(tmp_dir_name)
+      yield lib_url, lib_tmp_dir
+    self._archive_path = main_archive_path
+
+  def _install_archive(self, archive_path: pth.LocalPath) -> None:
+    # TODO: move browser installation to browser startup to allow
+    # multiple versions on android in a single crossbench invocation
+    package = str(self._installed_app_path())
+    self.adb.uninstall(package, missing_ok=True)
+    lib_archive_path = archive_path.with_suffix(self.LIBRARY_ARCHIVE_SUFFIX)
+    if lib_archive_path.exists():
+      self.adb.install(lib_archive_path, allow_downgrade=True, modules="_ALL_")
+    self.adb.install(archive_path, allow_downgrade=True, modules="_ALL_")
+
+
+class ChromeDownloaderWin(ChromeDownloader):
+  ARCHIVE_SUFFIX: str = ".zip"
+  ARCHIVE_STEM: str = "chrome-win64-clang"
+  STORAGE_URL: str = "gs://chrome-unsigned/desktop-5c0tCh/"
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: pth.AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return cls._is_valid(path_or_identifier, browser_platform)
+
+  def __init__(self, version_identifier: Union[str, pth.LocalPath],
+               browser_type: str, platform_name: str,
+               browser_platform: Platform):
+    assert not browser_type
+    assert browser_platform.is_win, f"{type(self)} can only be used on windows"
+    platform_name = "win64-clang"
+    super().__init__(version_identifier, "chrome", platform_name,
+                     browser_platform)
+
+  def _archive_urls(
+      self, folder_url: str,
+      version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
+    parts = version.parts
+    stable = (ChromeVersion.stable(parts),
+              f"{folder_url}{self.ARCHIVE_STEM}.zip")
+    return (stable,)
+
+  def _extracted_path(self) -> pth.LocalPath:
+    # TODO: support local vs remote
+    return self._out_dir / f"Google Chrome {self._requested_version}"
+
+  def _installed_app_path(self) -> pth.LocalPath:
+    return self._extracted_path() / "chrome.exe"
+
+  def _install_archive(self, archive_path: pth.LocalPath) -> None:
+    extracted_path = self._extracted_path()
+    tmp_path = self.host_platform.mkdtemp()
+    with zipfile.ZipFile(archive_path, "r") as zip_file:
+      zip_file.extractall(tmp_path)
+    self.host_platform.rename(tmp_path / self.ARCHIVE_STEM, extracted_path)
+    assert self.host_platform.is_dir(extracted_path), "Could not extract"
diff --git a/crossbench/browsers/chrome/helper.py b/crossbench/browsers/chrome/helper.py
new file mode 100644
index 0000000..ed5dd4f
--- /dev/null
+++ b/crossbench/browsers/chrome/helper.py
@@ -0,0 +1,54 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench import plt
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath
+
+
+class ChromePathMixin:
+
+  @classmethod
+  def default_path(cls, platform: plt.Platform) -> AnyPath:
+    return cls.stable_path(platform)
+
+  @classmethod
+  def stable_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Chrome Stable",
+        macos=["Google Chrome.app"],
+        linux=["google-chrome", "chrome"],
+        win=["Google/Chrome/Application/chrome.exe"])
+
+  @classmethod
+  def beta_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Chrome Beta",
+        macos=["Google Chrome Beta.app"],
+        linux=["google-chrome-beta"],
+        win=["Google/Chrome Beta/Application/chrome.exe"])
+
+  @classmethod
+  def dev_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Chrome Dev",
+        macos=["Google Chrome Dev.app"],
+        linux=["google-chrome-unstable"],
+        win=["Google/Chrome Dev/Application/chrome.exe"])
+
+  @classmethod
+  def canary_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Chrome Canary",
+        macos=["Google Chrome Canary.app"],
+        win=["Google/Chrome SxS/Application/chrome.exe"])
+
+  @property
+  def type_name(self) -> str:
+    return "chrome"
diff --git a/crossbench/browsers/chrome/version.py b/crossbench/browsers/chrome/version.py
new file mode 100644
index 0000000..4f01cd4
--- /dev/null
+++ b/crossbench/browsers/chrome/version.py
@@ -0,0 +1,32 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import Optional
+
+from crossbench.browsers.chromium.version import ChromiumVersion
+
+
+class ChromeVersion(ChromiumVersion):
+
+  _PREFIX_RE = re.compile(
+      r"(?:google )?chr(?:ome)?[- ]?"
+      rf"(?:{ChromiumVersion._CHANNEL_RE.pattern})?[- ]?m?", re.I)
+
+  @classmethod
+  def _validate_prefix(cls, prefix: Optional[str]) -> bool:
+    if not prefix:
+      return True
+    prefix = prefix.lower()
+    if prefix.strip() == "m":
+      return True
+    return bool(cls._PREFIX_RE.fullmatch(prefix))
+
+  @classmethod
+  def _validate_suffix(cls, suffix: Optional[str]) -> bool:
+    if suffix and "(Official Build)" in suffix:
+      return True
+    return super()._validate_suffix(suffix)
diff --git a/crossbench/browsers/chrome/webdriver.py b/crossbench/browsers/chrome/webdriver.py
new file mode 100644
index 0000000..14bb37d
--- /dev/null
+++ b/crossbench/browsers/chrome/webdriver.py
@@ -0,0 +1,75 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+from typing import TYPE_CHECKING, List
+
+import selenium.common.exceptions
+from selenium import webdriver
+from selenium.webdriver.chrome.options import Options as ChromeOptions
+from selenium.webdriver.chrome.service import Service as ChromeService
+
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chrome.helper import ChromePathMixin
+from crossbench.browsers.chromium.webdriver import (
+    ChromiumWebDriver, ChromiumWebDriverAndroid, ChromiumWebDriverChromeOsSsh,
+    ChromiumWebDriverSsh, LocalChromiumWebDriverAndroid,
+    build_chromedriver_instructions)
+from crossbench.browsers.webdriver import DriverException
+
+if TYPE_CHECKING:
+  from selenium.webdriver.chromium.options import ChromiumOptions
+  from selenium.webdriver.chromium.service import ChromiumService
+  from selenium.webdriver.chromium.webdriver import ChromiumDriver
+
+
+class ChromeWebDriver(ChromePathMixin, ChromiumWebDriver):
+
+  WEB_DRIVER_OPTIONS = ChromeOptions
+  WEB_DRIVER_SERVICE = ChromeService
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return (BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
+            | BrowserAttributes.WEBDRIVER)
+
+  def _create_driver(self, options: ChromiumOptions,
+                     service: ChromiumService) -> ChromiumDriver:
+    assert isinstance(options, ChromeOptions)
+    assert isinstance(service, ChromeService)
+    try:
+      return webdriver.Chrome(options=options, service=service)
+    except selenium.common.exceptions.WebDriverException as e:
+      msg: List[str] = [f"Could not start WebDriver: {e.msg}"]
+      if self.platform.is_android:
+        msg += [
+            f"Possibly missing chrome settings on {self.platform}.",
+            "Please make sure to allow chrome-flags on "
+            "non-rooted android devices:",
+            "chrome://flags#enable-command-line-on-non-rooted-devices",
+        ]
+      if self.is_locally_compiled():
+        msg.append(build_chromedriver_instructions(self.app_path.parent))
+      msg_str = "\n".join(msg)
+      logging.error(msg_str)
+      raise DriverException(msg_str) from e
+
+
+class ChromeWebDriverAndroid(ChromiumWebDriverAndroid, ChromeWebDriver):
+  pass
+
+
+class LocalChromeWebDriverAndroid(LocalChromiumWebDriverAndroid,
+                                  ChromeWebDriver):
+  pass
+
+
+class ChromeWebDriverSsh(ChromiumWebDriverSsh, ChromeWebDriver):
+  pass
+
+
+class ChromeWebDriverChromeOsSsh(ChromiumWebDriverChromeOsSsh, ChromeWebDriver):
+  pass
diff --git a/crossbench/browsers/chromium/__init__.py b/crossbench/browsers/chromium/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/browsers/chromium/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/browsers/chromium/applescript.py b/crossbench/browsers/chromium/applescript.py
new file mode 100644
index 0000000..ece4eae
--- /dev/null
+++ b/crossbench/browsers/chromium/applescript.py
@@ -0,0 +1,29 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.browsers.applescript import AppleScriptBrowser
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chromium.chromium import Chromium
+
+
+# TODO: fix https://source.chromium.org/chromium/chromium/src/+/main:chrome/browser/ui/browser_commands_mac.mm;drc=ddf482c0cf47fc8e47e5cfc5c112e2313e066cb8;bpv=1;bpt=1;l=38
+# TODO: Auto-set: prefs::kAllowJavascriptAppleEvents
+# TODO: add --enable-automation flag
+class ChromiumAppleScript(Chromium, AppleScriptBrowser):
+  APPLE_SCRIPT_ALLOW_JS_MENU: str = (
+      "View > Developer > Allow JavaScript from Apple Events")
+  APPLE_SCRIPT_JS_COMMAND: str = (
+      "tell the active tab of front window to execute javascript %(js_script)s")
+  APPLE_SCRIPT_SET_URL: str = (
+      "set URL of the active tab of front window to %(url)s")
+
+  def _setup_window(self) -> None:
+    pass
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return (BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
+            | BrowserAttributes.APPLESCRIPT)
diff --git a/crossbench/browsers/chromium/chromium.py b/crossbench/browsers/chromium/chromium.py
new file mode 100644
index 0000000..e01bf17
--- /dev/null
+++ b/crossbench/browsers/chromium/chromium.py
@@ -0,0 +1,256 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import logging
+import re
+from typing import TYPE_CHECKING, Optional, TextIO, Tuple, cast
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.browser import Browser
+from crossbench.browsers.browser_helper import convert_flags_to_label
+from crossbench.browsers.viewport import Viewport
+from crossbench.flags.chrome import ChromeFeatures, ChromeFlags
+from crossbench.types import JsonDict
+
+if TYPE_CHECKING:
+  from crossbench.browsers.settings import Settings
+  from crossbench.flags.base import Flags, FlagsData
+  from crossbench.flags.js_flags import JSFlags
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class Chromium(Browser):
+  MIN_HEADLESS_NEW_VERSION: int = 112
+  DEFAULT_FLAGS: Tuple[str, ...] = (
+      "--no-default-browser-check",
+      "--disable-component-update",
+      "--disable-sync",
+      "--disable-extensions",
+      "--no-first-run",
+      # This could be enabled via feature-flags as well.
+      "--disable-search-engine-choice-screen",
+  )
+  FLAGS_FOR_DISABLING_BACKGROUND_INTERVENTIONS: Tuple[str, ...] = (
+      "--disable-background-timer-throttling",
+      "--disable-renderer-backgrounding",
+  )
+  # All flags that might affect how finch / field-trials are loaded.
+  FIELD_TRIAL_FLAGS: Tuple[str, ...] = (
+      "--force-fieldtrials",
+      "--variations-server-url",
+      "--variations-insecure-server-url",
+      "--variations-test-seed-path",
+      "--enable-field-trial-config",
+      "--disable-variations-safe-mode",
+  )
+  NO_EXPERIMENTS_FLAGS: Tuple[str, ...] = (
+      "--no-experiments",
+      "--enable-benchmarking",
+      "--disable-field-trial-config",
+  )
+
+  @classmethod
+  def default_path(cls, platform: plt.Platform) -> pth.AnyPath:
+    return platform.search_app_or_executable(
+        "Chromium",
+        macos=["Chromium.app"],
+        linux=["google-chromium", "chromium"],
+        win=["Google/Chromium/Application/chromium.exe"])
+
+  @classmethod
+  def default_flags(cls, initial_data: FlagsData = None) -> ChromeFlags:
+    return ChromeFlags(initial_data)
+
+  def __init__(self,
+               label: str,
+               path: pth.AnyPath,
+               settings: Optional[Settings] = None):
+    super().__init__(label, path, settings=settings)
+    self._stdout_log_file: Optional[TextIO] = None
+    assert isinstance(self._flags, ChromeFlags)
+
+  def _setup_flags(self, settings: Settings) -> ChromeFlags:
+    flags: Flags = settings.flags
+    js_flags: Flags = settings.js_flags
+    self._flags = self.default_flags(self.DEFAULT_FLAGS)
+    self._flags.update(flags)
+
+    if "--allow-background-interventions" in self._flags.data:
+      # The --allow-background-interventions flag should have no value.
+      assert self._flags.get("--allow-background-interventions") is None
+    else:
+      self._flags.update(self.FLAGS_FOR_DISABLING_BACKGROUND_INTERVENTIONS)
+
+    # Explicitly disable field-trials by default on all chrome flavours:
+    # By default field-trials are enabled on non-Chrome branded builds, but
+    # are auto-enabled on everything else. This gives very confusing results
+    # when comparing local builds to official binaries.
+    field_trial_flags = [
+        flag for flag in self.FIELD_TRIAL_FLAGS if flag in self._flags
+    ]
+    if not field_trial_flags:
+      logging.info("Disabling experiments/finch/field-trials for %s", self)
+      for flag in self.NO_EXPERIMENTS_FLAGS:
+        self._flags.set(flag)
+    else:
+      logging.warning("Running with field-trials or finch experiments.")
+      no_finch_flags = [
+          flag for flag in self.NO_EXPERIMENTS_FLAGS if flag in self._flags
+      ]
+      if no_finch_flags:
+        raise argparse.ArgumentTypeError(
+            "Conflicting flag groups set: "
+            f"{field_trial_flags} vs {no_finch_flags}.\n"
+            "Cannot enable and disable finch / field-trials at the same time.")
+
+    self.js_flags.update(js_flags)
+    self._maybe_disable_gpu_compositing()
+    return self._flags
+
+  def _maybe_disable_gpu_compositing(self) -> None:
+    # Chrome Remote Desktop provide no GPU and older chrome versions
+    # don't handle this well.
+    if self.major_version > 92 or ("CHROME_REMOTE_DESKTOP_SESSION"
+                                   not in self.platform.environ):
+      return
+    self.flags.set("--disable-gpu-compositing")
+    self.flags.set("--no-sandbox")
+
+  def _setup_cache_dir(self, settings: Settings) -> None:
+    cache_dir = settings.cache_dir
+    if cache_dir is None:
+      maybe_cache_dir = self._flags.get("--user-data-dir", None)
+      if maybe_cache_dir:
+        cache_dir = pth.AnyPath(maybe_cache_dir)
+    if cache_dir is None:
+      self.cache_dir = self.platform.mkdtemp(prefix=self.type_name)
+      self.clear_cache_dir = True
+    else:
+      self.cache_dir = cache_dir
+      self.clear_cache_dir = False
+
+  def _extract_version(self) -> str:
+    assert self.path
+    version_string = self.platform.app_version(self.path)
+    # Sample output: "Chromium 90.0.4430.212 dev" => "90.0.4430.212"
+    matches = re.findall(r"[\d\.]+", version_string)
+    if not matches:
+      raise ValueError(
+          f"Could not extract version number from '{version_string}' "
+          f"for '{self.path}'")
+    return str(matches[0])
+
+  @property
+  def type_name(self) -> str:
+    return "chromium"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
+
+  @property
+  def is_headless(self) -> bool:
+    return "--headless" in self._flags
+
+  @property
+  def chrome_log_file(self) -> pth.AnyPath:
+    assert self.log_file
+    return self.log_file.with_suffix(f".{self.type_name}.log")
+
+  @property
+  def flags(self) -> ChromeFlags:
+    return cast(ChromeFlags, self._flags)
+
+  @property
+  def js_flags(self) -> JSFlags:
+    return cast(ChromeFlags, self._flags).js_flags
+
+  @property
+  def features(self) -> ChromeFeatures:
+    return cast(ChromeFlags, self._flags).features
+
+  def details_json(self) -> JsonDict:
+    details: JsonDict = super().details_json()
+    if self.log_file:
+      log = cast(JsonDict, details["log"])
+      log[self.type_name] = str(self.chrome_log_file)
+      log["stdout"] = str(self.stdout_log_file)
+    details["js_flags"] = tuple(self.js_flags)
+    return details
+
+  def _get_browser_flags_for_session(
+      self, session: BrowserSessionRunGroup) -> Tuple[str, ...]:
+    js_flags_copy = self.js_flags.copy()
+    js_flags_copy.update(session.extra_js_flags)
+
+    flags_copy = self.flags.copy()
+    flags_copy.update(session.extra_flags)
+    flags_copy.update(self.network.extra_flags(self.attributes))
+    self._handle_viewport_flags(flags_copy)
+
+    if len(js_flags_copy):
+      flags_copy["--js-flags"] = str(js_flags_copy)
+    if user_data_dir := self.flags.get("--user-data-dir"):
+      assert user_data_dir == str(
+          self.cache_dir), (f"--user-data-dir path: {user_data_dir} was passed "
+                            f"but does not match cache-dir: {self.cache_dir}")
+    if self.cache_dir:
+      flags_copy["--user-data-dir"] = str(self.cache_dir)
+    if self.log_file:
+      flags_copy.set("--enable-logging")
+      flags_copy["--log-file"] = str(self.chrome_log_file)
+
+    flags_copy = self._filter_flags_for_run(flags_copy)
+
+    return tuple(flags_copy)
+
+  def _handle_viewport_flags(self, flags: Flags) -> None:
+    self._sync_viewport_flag(flags, "--start-fullscreen",
+                             self.viewport.is_fullscreen, Viewport.FULLSCREEN)
+    self._sync_viewport_flag(flags, "--start-maximized",
+                             self.viewport.is_maximized, Viewport.MAXIMIZED)
+    self._sync_viewport_flag(flags, "--headless", self.viewport.is_headless,
+                             Viewport.HEADLESS)
+    # M112 added --headless=new as replacement for --headless
+    if "--headless" in flags and (self.major_version >=
+                                  self.MIN_HEADLESS_NEW_VERSION):
+      if flags["--headless"] is None:
+        logging.info("Replacing --headless with --headless=new")
+        flags.set("--headless", "new", override=True)
+
+    if self.viewport.is_default:
+      update_viewport = False
+      width, height = self.viewport.size
+      x, y = self.viewport.position
+      if "--window-size" in flags:
+        update_viewport = True
+        width, height = map(int, flags["--window-size"].split(","))
+      if "--window-position" in flags:
+        update_viewport = True
+        x, y = map(int, flags["--window-position"].split(","))
+      if update_viewport:
+        self.viewport = Viewport(width, height, x, y)
+    if self.viewport.has_size:
+      flags["--window-size"] = f"{self.viewport.width},{self.viewport.height}"
+      flags["--window-position"] = f"{self.viewport.x},{self.viewport.y}"
+    else:
+      for flag in ("--window-position", "--window-size"):
+        if flag in flags:
+          flag_value = flags[flag]
+          raise ValueError(f"Viewport {self.viewport} conflicts with flag "
+                           f"{flag}={flag_value}")
+
+  def get_label_from_flags(self) -> str:
+    return convert_flags_to_label(*self.flags, *self.js_flags)
+
+  def quit(self) -> None:
+    super().quit()
+    if self._stdout_log_file:
+      self._stdout_log_file.close()
+      self._stdout_log_file = None
diff --git a/crossbench/browsers/chromium/version.py b/crossbench/browsers/chromium/version.py
new file mode 100644
index 0000000..17e268f
--- /dev/null
+++ b/crossbench/browsers/chromium/version.py
@@ -0,0 +1,184 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import Dict, Final, Optional, Tuple
+
+from crossbench.browsers.version import (BrowserVersion, BrowserVersionChannel,
+                                         PartialBrowserVersionError)
+
+
+class ChromiumVersion(BrowserVersion):
+  _PARTS_LEN: Final[int] = 4
+  _VERSION_RE = re.compile(
+      r"(?P<prefix>[^\d]*)"
+      r"(?P<version>\d{2,3}(\.(\d{1,4}|X)){0,3})? ?"
+      r"(?P<suffix>.*)", re.I)
+  _VALID_SUFFIX_MATCH = re.compile(r"[^.\d]+", re.I)
+  _CHANNEL_LOOKUP: Dict[str, BrowserVersionChannel] = {
+      "any": BrowserVersionChannel.ANY,
+      "extended": BrowserVersionChannel.LTS,
+      "stable": BrowserVersionChannel.STABLE,
+      "beta": BrowserVersionChannel.BETA,
+      "dev": BrowserVersionChannel.ALPHA,
+      "canary": BrowserVersionChannel.PRE_ALPHA,
+  }
+  _CHANNEL_NAME_LOOKUP: Dict[BrowserVersionChannel, str] = {
+      channel: name for name, channel in _CHANNEL_LOOKUP.items()
+  }
+  _CHANNEL_RE = re.compile("|".join(_CHANNEL_LOOKUP.keys()), re.I)
+
+  @classmethod
+  def _parse(
+      cls,
+      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
+    matches = cls._VERSION_RE.fullmatch(full_version.strip(),)
+    if not matches:
+      raise cls.parse_error("Could not extract version number.", full_version)
+    channel_str = cls._parse_channel(full_version)
+    version_str = matches["version"]
+    if not version_str and not channel_str:
+      raise cls.parse_error("Got empty version match.", full_version)
+    prefix = matches["prefix"]
+    if not cls._validate_prefix(prefix):
+      raise cls.parse_error(f"Wrong prefix {repr(prefix)}", full_version)
+    suffix = matches["suffix"]
+    if not cls._validate_suffix(suffix):
+      raise cls.parse_error(f"Wrong suffix {repr(suffix)}", full_version)
+
+    if not version_str:
+      return cls._channel_version(channel_str, full_version)
+    return cls._numbered_version(version_str, full_version)
+
+  @classmethod
+  def _parse_channel(cls, full_version: str) -> str:
+    if matches := cls._CHANNEL_RE.search(full_version):
+      return matches[0]
+    return ""
+
+  @classmethod
+  def _channel_version(
+      cls, channel_str: str,
+      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
+    channel = cls._parse_exact_channel(channel_str, full_version)
+    version_str = ""
+    return tuple(), channel, version_str
+
+  @classmethod
+  def _numbered_version(
+      cls, version_str: str,
+      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
+    channel: BrowserVersionChannel = cls._parse_default_channel(full_version)
+
+    parts_str = version_str.split(".")
+    if len(parts_str) > cls._PARTS_LEN:
+      raise cls.parse_error(f"Too many version parts {parts_str}", full_version)
+    if len(parts_str) != 1 and len(parts_str) != cls._PARTS_LEN:
+      raise cls.parse_error(
+          f"Incomplete chrome version number, need {cls._PARTS_LEN} parts",
+          full_version)
+    # Remove .X from the input version.
+    while parts_str[-1] == "X":
+      parts_str.pop()
+    try:
+      parts = tuple(map(int, parts_str))
+    except ValueError as e:
+      raise cls.parse_error(
+          f"Could not parse version parts {repr(version_str)}",
+          full_version) from e
+    if not parts_str:
+      raise cls.parse_error("Need at least one version number part.",
+                            full_version)
+    if len(parts_str) == 1:
+      version_str = f"M{parts_str[0]}"
+    else:
+      padding = ("X",) * (cls._PARTS_LEN - len(parts))
+      version_str = ".".join(map(str, parts + padding))
+    return parts, channel, version_str
+
+  @classmethod
+  def _validate_prefix(cls, prefix: Optional[str]) -> bool:
+    if not prefix:
+      return True
+    prefix = prefix.lower()
+    if prefix.strip() == "m":
+      return True
+    return "chromium " in prefix or "chromium-" in prefix
+
+  @classmethod
+  def _parse_exact_channel(cls, channel_str: str,
+                           full_version: str) -> BrowserVersionChannel:
+    if channel := cls._CHANNEL_LOOKUP.get(channel_str.lower()):
+      return channel
+    raise cls.parse_error(f"Unknown channel {repr(channel_str)}", full_version)
+
+  @classmethod
+  def _parse_default_channel(cls, full_version: str) -> BrowserVersionChannel:
+    version_lower: str = full_version.lower()
+    for channel_name, channel_obj in cls._CHANNEL_LOOKUP.items():
+      if channel_name in version_lower:
+        return channel_obj
+    return BrowserVersionChannel.STABLE
+
+  @classmethod
+  def _validate_suffix(cls, suffix: Optional[str]) -> bool:
+    if not suffix:
+      return True
+    return bool(cls._VALID_SUFFIX_MATCH.fullmatch(suffix))
+
+  @property
+  def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
+    return (self.comparable_parts(self._PARTS_LEN), self._channel)
+
+  @property
+  def has_complete_parts(self) -> bool:
+    return len(self.parts) == 4
+
+  @property
+  def build(self) -> int:
+    if len(self._parts) <= 2:
+      raise PartialBrowserVersionError()
+    return self._parts[2]
+
+  @property
+  def patch(self) -> int:
+    if len(self._parts) <= 3:
+      raise PartialBrowserVersionError()
+    return self._parts[3]
+
+  @property
+  def is_dev(self) -> bool:
+    return self.is_alpha
+
+  @property
+  def is_canary(self) -> bool:
+    return self.is_pre_alpha
+
+  def _channel_name(self, channel: BrowserVersionChannel) -> str:
+    if name := self._CHANNEL_NAME_LOOKUP[channel]:
+      return name
+    raise ValueError(f"Unsupported channel: {channel}")
+
+
+class ChromeDriverVersion(ChromiumVersion):
+  _EMPTY_COMMIT_HASH: Final = "0000000000000000000000000000000000000000"
+
+  @classmethod
+  def _validate_prefix(cls, prefix: Optional[str]) -> bool:
+    if not prefix:
+      return False
+    return prefix.lower() in ("chromedriver ", "chromedriver-")
+
+  @classmethod
+  def _parse_default_channel(cls, full_version: str) -> BrowserVersionChannel:
+    if cls._EMPTY_COMMIT_HASH in full_version:
+      return BrowserVersionChannel.PRE_ALPHA
+    return BrowserVersionChannel.STABLE
+
+  @classmethod
+  def _validate_suffix(cls, suffix: Optional[str]) -> bool:
+    # TODO: extract commit hash / branch info from newer versions
+    return True
diff --git a/crossbench/browsers/chromium/webdriver.py b/crossbench/browsers/chromium/webdriver.py
new file mode 100644
index 0000000..c49745b
--- /dev/null
+++ b/crossbench/browsers/chromium/webdriver.py
@@ -0,0 +1,868 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import atexit
+import datetime as dt
+import json
+import logging
+import os
+import re
+import shutil
+import stat
+import tempfile
+import urllib.error
+import zipfile
+from typing import (TYPE_CHECKING, Any, Dict, Final, Iterable, List, Optional,
+                    Sequence, Tuple, Type, cast)
+
+import hjson
+from immutabledict import immutabledict
+from selenium.webdriver.chromium.options import ChromiumOptions
+from selenium.webdriver.chromium.service import ChromiumService
+from selenium.webdriver.chromium.webdriver import ChromiumDriver
+from selenium.webdriver.remote.webdriver import WebDriver as RemoteWebDriver
+
+from crossbench import exception, helper
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.browsers.chromium.version import (ChromeDriverVersion,
+                                                  ChromiumVersion)
+from crossbench.browsers.webdriver import WebDriverBrowser
+from crossbench.cli.config.secret_type import SecretType
+from crossbench.flags.chrome import ChromeFlags
+from crossbench.plt.android_adb import AndroidAdbPlatform
+from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
+from crossbench.plt.linux_ssh import LinuxSshPlatform
+
+if TYPE_CHECKING:
+  from selenium import webdriver
+
+  from crossbench.browsers.settings import Settings
+  from crossbench.cli.config.secrets import Secret
+  from crossbench.flags.base import FlagsT
+  from crossbench.plt.base import Platform
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class ChromiumWebDriver(WebDriverBrowser, Chromium, metaclass=abc.ABCMeta):
+
+  WEB_DRIVER_OPTIONS: Type[ChromiumOptions] = ChromiumOptions
+  WEB_DRIVER_SERVICE: Type[ChromiumService] = ChromiumService
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return (BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
+            | BrowserAttributes.WEBDRIVER)
+
+  def use_local_chromedriver(self) -> bool:
+    return self.major_version == 0 or self.is_locally_compiled()
+
+  def is_locally_compiled(self) -> bool:
+    return pth.LocalPath(self.app_path.parent / "args.gn").exists()
+
+  def _execute_cdp_cmd(self, driver: webdriver.Remote, cmd: str,
+                       cmd_args: dict):
+    return driver.execute("executeCdpCommand", {
+        "cmd": cmd,
+        "params": cmd_args
+    })["value"]
+
+  def _find_driver(self) -> pth.AnyPath:
+    if self._driver_path:
+      return self._driver_path
+    finder = ChromeDriverFinder(self)
+    assert self.app_path
+    if self.use_local_chromedriver():
+      return finder.find_local_build()
+    try:
+      return finder.download()
+    except DriverNotFoundError as original_download_error:
+      logging.debug(
+          "Could not download chromedriver, "
+          "falling back to finding local build: %s", original_download_error)
+      try:
+        return finder.find_local_build()
+      except DriverNotFoundError as e:
+        logging.debug("Could not find fallback chromedriver: %s", e)
+        raise original_download_error from e
+      # to make an old pytype version happy
+      return pth.LocalPath()
+
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: pth.AnyPath) -> webdriver.Remote:
+    return self._start_chromedriver(session, driver_path)
+
+  def _start_chromedriver(self, session: BrowserSessionRunGroup,
+                          driver_path: pth.AnyPath) -> ChromiumDriver:
+    assert not self._is_running
+    assert self.log_file
+    args = self._get_browser_flags_for_session(session)
+    options = self._create_options(session, args)
+
+    self._log_browser_start(args, driver_path)
+    service_args: List[str] = []
+    log_path: Optional[str] = None
+    if self._settings.driver_logging:
+      service_args += ["--verbose"]
+      log_path = os.fspath(self.driver_log_file)
+    # pytype: disable=wrong-keyword-args
+    service = self.WEB_DRIVER_SERVICE(
+        executable_path=os.fspath(driver_path),
+        log_path=log_path,
+        service_args=service_args)
+    # TODO: support remote platforms
+    service.log_file = pth.LocalPath(self.stdout_log_file).open(  # pylint: disable=consider-using-with
+        "w", encoding="utf-8")
+    driver = self._create_driver(options, service)
+    # pytype: enable=wrong-keyword-args
+    # Prevent debugging overhead.
+    self._execute_cdp_cmd(driver, "Runtime.setMaxCallStackSizeToCapture",
+                          {"size": 0})
+    return driver
+
+  def _create_options(self, session: BrowserSessionRunGroup,
+                      args: Sequence[str]) -> ChromiumOptions:
+    assert not self._is_running
+    options: ChromiumOptions = self.WEB_DRIVER_OPTIONS()
+    options.set_capability("browserVersion", str(self.major_version))
+    # Don't wait for document-ready.
+    options.set_capability("pageLoadStrategy", "eager")
+    for arg in args:
+      options.add_argument(arg)
+    options.binary_location = os.fspath(self.path)
+    session.setup_selenium_options(options)
+    return options
+
+  @abc.abstractmethod
+  def _create_driver(self, options: ChromiumOptions,
+                     service: ChromiumService) -> ChromiumDriver:
+    pass
+
+  def _validate_driver_version(self) -> None:
+    assert self._driver_path, "No driver available"
+    error_message = None
+    if self.is_local and is_build_dir(
+        self.platform.local_path(self.app_path.parent)):
+      error_message = self._validate_locally_built_driver(
+          self.platform.local_path(self._driver_path))
+    else:
+      error_message = self._validate_any_driver_version(self._driver_path)
+    if error_message:
+      raise RuntimeError("\n".join(error_message))
+
+  def _validate_locally_built_driver(
+      self, driver_path: pth.LocalPath) -> Optional[Iterable[str]]:
+    # TODO: migrate to version object on the browser
+    browser_version = ChromiumVersion.parse(self.version)
+    driver_version = ChromeDriverVersion.parse(
+        self.platform.app_version(driver_path))
+    if browser_version.parts == driver_version.parts:
+      return None
+    return (f"Chromedriver version mismatch: driver={driver_version.parts_str} "
+            f"browser={browser_version.parts_str} ({self}).",
+            build_chromedriver_instructions(driver_path.parent))
+
+  def _validate_any_driver_version(
+      self, driver_path: pth.AnyPath) -> Optional[Iterable[str]]:
+    raw_version_str = self.host_platform.sh_stdout(driver_path, "--version")
+    driver_version = ChromeDriverVersion.parse(raw_version_str)
+    if driver_version.major == self.major_version:
+      return None
+    return (f"Chromedriver version mismatch: driver={driver_version} "
+            f"browser={self.version} ({self})",)
+
+  def run_script_on_new_document(self, script: str) -> None:
+    self._execute_cdp_cmd(self._private_driver,
+                          "Page.addScriptToEvaluateOnNewDocument",
+                          {"source": script})
+
+  def current_window_id(self) -> str:
+    return str(self._private_driver.current_window_handle)
+
+  def switch_window(self, window_id: str) -> None:
+    self._private_driver.switch_to.window(window_id)
+
+  def switch_tab(
+      self,
+      title: Optional[re.Pattern] = None,
+      url: Optional[re.Pattern] = None,
+      tab_index: Optional[int] = None,
+      timeout: dt.timedelta = dt.timedelta(seconds=0)
+  ) -> None:
+    driver = self._private_driver
+    original_handle = driver.current_window_handle
+    for _ in helper.wait_with_backoff(timeout, self.platform):
+      # Search through other handles starting from current_window_handle + 1
+      try:
+        i = driver.window_handles.index(original_handle)
+      except ValueError as e:
+        raise RuntimeError("Original starting tab no longer exists") from e
+
+      if tab_index is not None:
+        handles = [driver.window_handles[tab_index]]
+      else:
+        handles = driver.window_handles[i + 1:] + driver.window_handles[:i]
+
+      for handle in handles:
+        driver.switch_to.window(handle)
+        if title is not None:
+          if title.match(driver.title) is None:
+            continue
+        if url is not None:
+          if url.match(driver.current_url) is None:
+            continue
+        return
+    error = "No new tab found"
+    if title is not None:
+      error += f" with title matching {repr(title.pattern)}"
+    if url is not None:
+      error += f" with url matching {repr(url.pattern)}"
+    if tab_index is not None:
+      error += f" with tab_index matching {tab_index}"
+    raise RuntimeError(error)
+
+  def start_profiling(self) -> None:
+    assert isinstance(self._private_driver, ChromiumDriver)
+    # TODO: reuse the TraceProbe categories,
+    self._execute_cdp_cmd(
+        self._private_driver, "Tracing.start", {
+            "transferMode":
+                "ReturnAsStream",
+            "includedCategories": [
+                "devtools.timeline",
+                "v8.execute",
+                "disabled-by-default-devtools.timeline",
+                "disabled-by-default-devtools.timeline.frame",
+                "toplevel",
+                "blink.console",
+                "blink.user_timing",
+                "latencyInfo",
+                "disabled-by-default-devtools.timeline.stack",
+                "disabled-by-default-v8.cpu_profiler",
+            ],
+        })
+
+  def stop_profiling(self) -> Any:
+    assert isinstance(self._private_driver, ChromiumDriver)
+    data = self._execute_cdp_cmd(self._private_driver,
+                                 "Tracing.tracingComplete", {})
+    # TODO: use webdriver bidi to get the async Tracing.end event.
+    # self._execute_cdp_cmd(self._driver, "Tracing.end", {})
+    return data
+
+
+# Android is high-tech and reads chrome flags from an app-specific file.
+# TODO: extend support to more than just chrome.
+_FLAG_ROOT: pth.AnyPosixPath = pth.AnyPosixPath("/data/local/tmp/")
+FLAGS_WEBLAYER: pth.AnyPosixPath = _FLAG_ROOT / "weblayer-command-line"
+FLAGS_WEBVIEW: pth.AnyPosixPath = _FLAG_ROOT / "webview-command-line"
+FLAGS_CONTENT_SHELL: pth.AnyPosixPath = (
+    _FLAG_ROOT / "content-shell-command-line")
+FLAGS_CHROME: pth.AnyPosixPath = _FLAG_ROOT / "chrome-command-line"
+
+
+class ChromiumWebDriverAndroid(ChromiumWebDriver):
+
+  def __init__(self,
+               label: str,
+               path: Optional[pth.AnyPath] = None,
+               settings: Optional[Settings] = None):
+    assert settings, "Android browser needs custom settings and platform"
+    self._chrome_command_line_path: pth.AnyPath = FLAGS_CHROME
+    self._previous_command_line_contents: Optional[str] = None
+    super().__init__(label, path, settings)
+    self._android_package: str = self._lookup_android_package(self.path)
+    if not self._android_package:
+      raise RuntimeError("Could not find matching adb package for "
+                         f"{self.path} on {self.platform}")
+
+  def _lookup_android_package(self, path: pth.AnyPath) -> str:
+    return self.platform.app_path_to_package(path)
+
+  @property
+  def android_package(self) -> str:
+    return self._android_package
+
+  @property
+  def platform(self) -> AndroidAdbPlatform:
+    assert isinstance(
+        self._platform,
+        AndroidAdbPlatform), (f"Invalid platform: {self._platform}")
+    return cast(AndroidAdbPlatform, self._platform)
+
+  def _resolve_binary(self, path: pth.AnyPath) -> pth.AnyPath:
+    return path
+
+  # TODO: implement setting a clean profile on android
+  _UNSUPPORTED_FLAGS: Tuple[str, ...] = (
+      "--user-data-dir",
+      "--disable-sync",
+      "--window-size",
+      "--window-position",
+  )
+
+  def _filter_flags_for_run(self, flags: FlagsT) -> FlagsT:
+    assert isinstance(flags, ChromeFlags)
+    chrome_flags = cast(ChromeFlags, flags)
+    for flag in self._UNSUPPORTED_FLAGS:
+      if flag not in chrome_flags:
+        continue
+      flag_value = chrome_flags.pop(flag, None)
+      logging.debug("Chrome Android: Removed unsupported flag: %s=%s", flag,
+                    flag_value)
+    return chrome_flags
+
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: pth.AnyPath) -> webdriver.Remote:
+    self.adb_force_stop()
+    if session.browser.wipe_system_user_data:
+      self.adb_force_clear()
+      self.platform.adb.grant_notification_permissions(self.android_package)
+    self._backup_chrome_flags()
+    atexit.register(self._restore_chrome_flags)
+    return self._start_chromedriver(session, driver_path)
+
+  def _backup_chrome_flags(self) -> None:
+    assert self._previous_command_line_contents is None
+    self._previous_command_line_contents = self._read_device_flags()
+
+  def _read_device_flags(self) -> Optional[str]:
+    if not self.platform.exists(self._chrome_command_line_path):
+      return None
+    return self.platform.cat(self._chrome_command_line_path)
+
+  def adb_force_stop(self) -> None:
+    self.platform.adb.force_stop(self.android_package)
+
+  def adb_force_clear(self) -> None:
+    self.platform.adb.force_clear(self.android_package)
+
+  def force_quit(self) -> None:
+    try:
+      try:
+        super().force_quit()
+      finally:
+        self.adb_force_stop()
+    finally:
+      self._restore_chrome_flags()
+
+  def _restore_chrome_flags(self) -> None:
+    atexit.unregister(self._restore_chrome_flags)
+    current_flags = self._read_device_flags()
+    if current_flags != self._previous_command_line_contents:
+      logging.warning("%s: flags file changed during run", self)
+      logging.debug("before: %s", self._previous_command_line_contents)
+      logging.debug("current: %s", current_flags)
+    if self._previous_command_line_contents is None:
+      logging.debug("%s: deleting chrome flags file: %s", self,
+                    self._chrome_command_line_path)
+      self.platform.rm(self._chrome_command_line_path, missing_ok=True)
+    else:
+      logging.debug("%s: restoring previous flags file contents in %s", self,
+                    self._chrome_command_line_path)
+      self.platform.set_file_contents(self._chrome_command_line_path,
+                                      self._previous_command_line_contents)
+    self._previous_command_line_contents = None
+
+  def _create_options(self, session: BrowserSessionRunGroup,
+                      args: Sequence[str]) -> ChromiumOptions:
+    options: ChromiumOptions = super()._create_options(session, args)
+    options.binary_location = ""
+    options.add_experimental_option("androidPackage", self.android_package)
+    options.add_experimental_option("androidDeviceSerial",
+                                    self.platform.adb.serial_id)
+    return options
+
+  def setup_binary(self) -> None:
+    super().setup_binary()
+    self.platform.adb.grant_notification_permissions(self.android_package)
+
+
+class LocalChromiumWebDriverAndroid(ChromiumWebDriverAndroid):
+  """
+  Custom version that uses a locally built bundle wrapper.
+  https://chromium.googlesource.com/chromium/src/+/HEAD/docs/android_build_instructions.md
+  """
+
+  @classmethod
+  def is_apk_helper(cls, path: Optional[pth.AnyPath]) -> bool:
+    if not path or len(path.parts) == 1:
+      return False
+    return path.name.endswith("_apk")
+
+  def __init__(self,
+               label: str,
+               path: Optional[pth.AnyPath] = None,
+               settings: Optional[Settings] = None):
+    if self.is_apk_helper(path):
+      raise ValueError(
+          "Locally built chrome version needs package, got empty path")
+    assert settings, "Android browser needs custom settings and platform"
+    self._package_info: immutabledict[str, Any] = self._parse_package_info(
+        settings.platform, path)
+    super().__init__(label, path, settings)
+
+  def _lookup_android_package(self, path: pth.AnyPath) -> str:
+    return self._package_info["Package name"]
+
+  def _extract_version(self) -> str:
+    return self._package_info["versionName"]
+
+  def _parse_package_info(self, platform: plt.Platform,
+                          path: pth.AnyPath) -> immutabledict[str, Any]:
+    output = platform.host_platform.sh_stdout(
+        path, "package-info").rstrip().splitlines()
+    package_info = {}
+    for line in output:
+      key, value = line.split(": ")
+      package_info[key] = hjson.loads(value)
+    return immutabledict(package_info)
+
+  def setup_binary(self) -> None:
+    super().setup_binary()
+    self.host_platform.sh_stdout(self.path, "install",
+                                 f"--device={self.platform.serial_id}")
+
+
+class ChromiumWebDriverSsh(ChromiumWebDriver):
+
+  @property
+  def platform(self) -> LinuxSshPlatform:
+    assert isinstance(self._platform,
+                      LinuxSshPlatform), (f"Invalid platform: {self._platform}")
+    return cast(LinuxSshPlatform, self._platform)
+
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: pth.AnyPath) -> RemoteWebDriver:
+    del driver_path
+    args = self._get_browser_flags_for_session(session)
+    options = self._create_options(session, args)
+    platform = self.platform
+    host = platform.host
+    port = platform.port
+    driver = RemoteWebDriver(f"http://{host}:{port}", options=options)
+    return driver
+
+
+class ChromiumWebDriverChromeOsSsh(ChromiumWebDriver):
+
+  @property
+  def platform(self) -> ChromeOsSshPlatform:
+    assert isinstance(
+        self._platform,
+        ChromeOsSshPlatform), (f"Invalid platform: {self._platform}")
+    return cast(ChromeOsSshPlatform, self._platform)
+
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: pth.AnyPath) -> RemoteWebDriver:
+    del driver_path
+    platform = self.platform
+    host = platform.host
+    port = platform.port
+    args = self._get_browser_flags_for_session(session)
+    # TODO(spadhi): correctly handle flags:
+    #   1. decide which flags to pass to chrome vs chromedriver
+    #   2. investigate irrelevant / unsupported flags on ChromeOS
+    #   3. filter out and pass the chrome flags to the debugging session below
+    #   4. pass the remaining flags to RemoteWebDriver options
+    google_login = session.browser.secrets.get(SecretType.GOOGLE)
+    if google_login:
+      dbg_port = platform.create_debugging_session(
+          username=google_login.username, password=google_login.password)
+    else:
+      dbg_port = platform.create_debugging_session()
+    options = self._create_options(session, args)
+    options.add_experimental_option("debuggerAddress", f"127.0.0.1:{dbg_port}")
+    driver = RemoteWebDriver(f"http://{host}:{port}", options=options)
+    return driver
+
+  # On ChromeOS, the system profile is the same as the browser profile.
+  def is_logged_in(self, secret: Secret, strict: bool = False) -> bool:
+    if secret.type != SecretType.GOOGLE:
+      return False
+    if secret.username == self.platform.username:
+      return True
+    if not strict:
+      return False
+    raise RuntimeError("Login of non-primary Google accounts not supported")
+
+
+class DriverNotFoundError(ValueError):
+  pass
+
+
+def build_chromedriver_instructions(build_dir: pth.AnyPath) -> str:
+  return ("Please build 'chromedriver' manually for local builds:\n"
+          f"    autoninja -C {build_dir} chromedriver")
+
+
+def is_build_dir(path: pth.LocalPath,
+                 platform: plt.Platform = plt.PLATFORM) -> bool:
+  return platform.is_file(path / "args.gn")
+
+
+class ChromeDriverFinder:
+  driver_path: pth.LocalPath
+
+  def __init__(self, browser: ChromiumWebDriver):
+    self.browser = browser
+    self.platform: Platform = browser.platform
+    self.host_platform: Platform = browser.platform.host_platform
+    extension: str = ""
+    if self.host_platform.is_win:
+      extension = ".exe"
+    cache_dir = self.host_platform.local_cache_dir("driver")
+    self.driver_path: pth.LocalPath = (
+        cache_dir / f"chromedriver-{self.browser.major_version}{extension}")
+    self._validate_browser()
+
+  def _validate_browser(self) -> None:
+    browser_platform = self.browser.platform
+    if browser_platform.is_local:
+      return
+    # Some remote platforms rely on a local chromedriver
+    if (browser_platform.is_android or browser_platform.is_remote_ssh):
+      return
+    raise RuntimeError("Cannot download chromedriver for remote browser yet")
+
+  def find_local_build(self) -> pth.LocalPath:
+    assert self.browser.app_path
+    # assume it's a local build
+    lookup_dir = pth.LocalPath(self.browser.app_path.parent)
+    driver_path = lookup_dir / "chromedriver"
+    if self.platform.is_win:
+      driver_path = driver_path.with_suffix(".exe")
+    if self.platform.is_file(driver_path):
+      return driver_path
+    error_message: List[str] = [f"Driver '{driver_path}' does not exist."]
+    if is_build_dir(lookup_dir, self.platform):
+      error_message += [build_chromedriver_instructions(lookup_dir)]
+    else:
+      error_message += ["Please manually provide a chromedriver binary."]
+    raise DriverNotFoundError("\n".join(error_message))
+
+  def download(self) -> pth.LocalPath:
+    if not self.platform.is_file(self.driver_path):
+      with exception.annotate(
+          f"Downloading chromedriver for {self.browser.version}"):
+        self._download()
+    return self.driver_path
+
+  def _download(self) -> None:
+    milestone = self.browser.major_version
+    logging.info("CHROMEDRIVER Downloading from %s v%s", self.browser.type_name,
+                 milestone)
+    url: Optional[str] = None
+    listing_url: Optional[str] = None
+    if milestone >= self.CFT_MIN_MILESTONE:
+      listing_url, url = self._get_cft_url(milestone)
+    if not url:
+      listing_url, url = self._get_pre_115_stable_url(milestone)
+      if not url:
+        listing_url, url = self._get_canary_url()
+
+    if not url:
+      raise DriverNotFoundError(
+          "Please manually compile/download chromedriver for "
+          f"{self.browser.type_name} {self.browser.version}")
+
+    logging.info("CHROMEDRIVER Downloading M%s: %s", milestone, listing_url or
+                 url)
+    with tempfile.TemporaryDirectory() as tmp_dir:
+      if ".zip" not in url:
+        maybe_driver = pth.LocalPath(tmp_dir) / "chromedriver"
+        self.host_platform.download_to(url, maybe_driver)
+      else:
+        zip_file = pth.LocalPath(tmp_dir) / "download.zip"
+        self.host_platform.download_to(url, zip_file)
+        with zipfile.ZipFile(zip_file, "r") as zip_ref:
+          zip_ref.extractall(zip_file.parent)
+        zip_file.unlink()
+        maybe_driver = None
+        candidates: List[pth.LocalPath] = [
+            path for path in zip_file.parent.glob("**/*")
+            if path.is_file() and "chromedriver" in path.name
+        ]
+        # Find exact match first:
+        maybe_drivers: List[pth.LocalPath] = [
+            path for path in candidates if path.stem == "chromedriver"
+        ]
+        # Backup less strict matching:
+        maybe_drivers += candidates
+        if len(maybe_drivers) > 0:
+          maybe_driver = maybe_drivers[0]
+      if not maybe_driver or not maybe_driver.is_file():
+        raise DriverNotFoundError(
+            f"Extracted driver at {maybe_driver} does not exist.")
+      self.driver_path.parent.mkdir(parents=True, exist_ok=True)
+      shutil.move(os.fspath(maybe_driver), os.fspath(self.driver_path))
+      self.driver_path.chmod(self.driver_path.stat().st_mode | stat.S_IEXEC)
+
+  # Using CFT as abbreviation for Chrome For Testing here.
+  CFT_MIN_MILESTONE = 115
+  CFT_BASE_URL: str = "https://googlechromelabs.github.io/chrome-for-testing"
+  CFT_VERSION_URL: str = f"{CFT_BASE_URL}/{{version}}.json"
+  CFT_LATEST_URL: str = f"{CFT_BASE_URL}/LATEST_RELEASE_{{major}}"
+
+  CFT_PLATFORM: Final[Dict[Tuple[str, str], str]] = {
+      ("linux", "x64"): "linux64",
+      ("macos", "x64"): "mac-x64",
+      ("macos", "arm64"): "mac-arm64",
+      ("win", "ia32"): "win32",
+      ("win", "x64"): "win64"
+  }
+
+  def _get_cft_url(self, milestone: int) -> Tuple[str, Optional[str]]:
+    logging.debug("ChromeDriverFinder: Looking up chrome-for-testing version.")
+    platform_name: Optional[str] = self.CFT_PLATFORM.get(self.host_platform.key)
+    if not platform_name:
+      raise DriverNotFoundError(
+          f"Unsupported platform {self.host_platform.key} for chromedriver.")
+    listing_url, version_data = self._get_cft_version_data(milestone)
+    download_url: Optional[str] = None
+    if version_data:
+      download_url = self._get_cft_driver_download_url(version_data,
+                                                       platform_name)
+    return (listing_url, download_url)
+
+  def _get_cft_version_data(self, milestone: int) -> Tuple[str, Optional[Dict]]:
+    logging.debug("ChromeDriverFinder: Trying direct download url")
+    listing_url, data = self._get_cft_precise_version_data(self.browser.version)
+    if data:
+      return listing_url, data
+    logging.debug(
+        "ChromeDriverFinder: Invalid precise version url %s, "
+        "using M%s", listing_url, milestone)
+    return self._get_ctf_milestone_data(milestone)
+
+  def _get_cft_precise_version_data(self,
+                                    version: str) -> Tuple[str, Optional[Dict]]:
+    version_url = self.CFT_VERSION_URL.format(version=version)
+    try:
+      with helper.urlopen(version_url) as response:
+        version_data = json.loads(response.read().decode("utf-8"))
+        return (version_url, version_data)
+    except urllib.error.HTTPError as e:
+      logging.debug("ChromeDriverFinder: "
+                    "Precise version download failed %s", e)
+      return (version_url, None)
+
+  def _get_ctf_milestone_data(self,
+                              milestone: int) -> Tuple[str, Optional[Dict]]:
+    latest_version_url = self.CFT_LATEST_URL.format(major=milestone)
+    try:
+      with helper.urlopen(latest_version_url) as response:
+        alternative_version = response.read().decode("utf-8").strip()
+        logging.debug(
+            "ChromeDriverFinder: Using alternative version %s "
+            "for M%s", alternative_version, milestone)
+        return self._get_cft_precise_version_data(alternative_version)
+    except urllib.error.HTTPError:
+      return (self.CFT_BASE_URL, None)
+
+  def _get_cft_driver_download_url(self, version_data,
+                                   platform_name) -> Optional[str]:
+    if all_downloads := version_data.get("downloads"):
+      driver_downloads: Dict = all_downloads.get("chromedriver", [])
+      for download in driver_downloads:
+        if isinstance(download, dict) and download["platform"] == platform_name:
+          return download["url"]
+    return None
+
+  PRE_115_STABLE_URL: str = "http://chromedriver.storage.googleapis.com"
+
+  def _get_pre_115_stable_url(self,
+                              milestone: int) -> Tuple[str, Optional[str]]:
+    logging.debug(
+        "ChromeDriverFinder: "
+        "Looking upe old-style stable version M%s", milestone)
+    assert milestone < self.CFT_MIN_MILESTONE
+    listing_url = f"{self.PRE_115_STABLE_URL}/index.html"
+    driver_version: Optional[str] = self._get_pre_115_driver_version(milestone)
+    if not driver_version:
+      return listing_url, None
+    if self.host_platform.is_linux:
+      arch_suffix = "linux64"
+    elif self.host_platform.is_macos:
+      arch_suffix = "mac64"
+      if self.host_platform.is_arm64:
+        # The uploaded chromedriver archives changed the naming scheme after
+        # chrome version 106.0.5249.21 for Arm64 (previously m1):
+        #   before: chromedriver_mac64_m1.zip
+        #   after:  chromedriver_mac_arm64.zip
+        last_old_naming_version = (106, 0, 5249, 21)
+        version_tuple = tuple(map(int, driver_version.split(".")))
+        if version_tuple <= last_old_naming_version:
+          arch_suffix = "mac64_m1"
+        else:
+          arch_suffix = "mac_arm64"
+    elif self.host_platform.is_win:
+      arch_suffix = "win32"
+    else:
+      raise DriverNotFoundError("Unsupported chromedriver platform")
+    url = (f"{self.PRE_115_STABLE_URL}/{driver_version}/"
+           f"chromedriver_{arch_suffix}.zip")
+    return listing_url, url
+
+  def _get_pre_115_driver_version(self, milestone) -> Optional[str]:
+    if milestone < 70:
+      return self._get_pre_70_driver_version(milestone)
+    url = f"{self.PRE_115_STABLE_URL}/LATEST_RELEASE_{milestone}"
+    try:
+      with helper.urlopen(url) as response:
+        return response.read().decode("utf-8")
+    except urllib.error.HTTPError as e:
+      if e.code != 404:
+        raise DriverNotFoundError(f"Could not query {url}") from e
+      logging.debug("ChromeDriverFinder: Could not load latest release url %s",
+                    e)
+    return None
+
+  def _get_pre_70_driver_version(self, milestone) -> Optional[str]:
+    with helper.urlopen(
+        f"{self.PRE_115_STABLE_URL}/2.46/notes.txt") as response:
+      lines = response.read().decode("utf-8").splitlines()
+    for i, line in enumerate(lines):
+      if not line.startswith("---"):
+        continue
+      [min_version, max_version] = map(int, re.findall(r"\d+", lines[i + 1]))
+      if min_version <= milestone <= max_version:
+        match = re.search(r"\d\.\d+", line)
+        if not match:
+          raise DriverNotFoundError(f"Could not parse version number: {line}")
+        return match.group(0)
+    return None
+
+  CHROMIUM_DASH_URL: str = "https://chromiumdash.appspot.com/fetch_releases"
+  CHROMIUM_LISTING_URL: str = (
+      "https://www.googleapis.com/storage/v1/b/chromium-browser-snapshots/o/")
+  CHROMIUM_DASH_PARAMS: Dict[Tuple[str, str], Dict] = {
+      ("linux", "x64"): {
+          "dash_platform": "linux",
+          "dash_channel": "dev",
+          "dash_limit": 10,
+      },
+      ("macos", "x64"): {
+          "dash_platform": "mac",
+      },
+      ("macos", "arm64"): {
+          "dash_platform": "mac",
+      },
+      ("win", "ia32"): {
+          "dash_platform": "win",
+      },
+      ("win", "x64"): {
+          "dash_platform": "win64",
+      },
+  }
+  CHROMIUM_LISTING_PREFIX: Dict[Tuple[str, str], str] = {
+      ("linux", "x64"): "Linux_x64",
+      ("macos", "x64"): "Mac",
+      ("macos", "arm64"): "Mac_Arm",
+      ("win", "ia32"): "Win",
+      ("win", "x64"): "Win_x64",
+  }
+
+  def _get_canary_url(self) -> Tuple[str, Optional[str]]:
+    logging.debug(
+        "ChromeDriverFinder: Try downloading the chromedriver canary version")
+    properties = self.CHROMIUM_DASH_PARAMS.get(self.host_platform.key)
+    if not properties:
+      raise DriverNotFoundError(
+          f"Unsupported platform={self.platform}, key={self.host_platform.key}")
+    dash_platform = properties["dash_platform"]
+    dash_channel = properties.get("dash_channel", "canary")
+    # Limit should be > len(canary_versions) so we also get potentially
+    # the latest dev version (only beta / stable have official driver binaries).
+    dash_limit = properties.get("dash_limit", 100)
+    url = helper.update_url_query(
+        self.CHROMIUM_DASH_URL, {
+            "platform": dash_platform,
+            "channel": dash_channel,
+            "milestone": str(self.browser.major_version),
+            "num": str(dash_limit),
+        })
+    chromium_base_position = 0
+    with helper.urlopen(url) as response:
+      version_infos = list(json.loads(response.read().decode("utf-8")))
+      if not version_infos:
+        raise DriverNotFoundError("Could not find latest version info for "
+                                  f"platform={self.host_platform}")
+      for version_info in version_infos:
+        if version_info["version"] == self.browser.version:
+          chromium_base_position = int(
+              version_info["chromium_main_branch_position"])
+          break
+
+    if not chromium_base_position and version_infos:
+      fallback_version_info = None
+      # Try matching latest milestone
+      for version_info in version_infos:
+        if version_info["milestone"] == self.browser.major_version:
+          fallback_version_info = version_info
+          break
+
+      if not fallback_version_info:
+        # Android has a slightly different release cycle than the desktop
+        # versions. Assume that the latest canary version is good enough
+        fallback_version_info = version_infos[0]
+      chromium_base_position = int(
+          fallback_version_info["chromium_main_branch_position"])
+      logging.warning(
+          "Falling back to latest (not precisely matching) "
+          "canary chromedriver %s (expected %s)",
+          fallback_version_info["version"], self.browser.version)
+
+    if not chromium_base_position:
+      raise DriverNotFoundError("Could not find matching canary chromedriver "
+                                f"for {self.browser.version}")
+    # Use prefixes to limit listing results and increase chances of finding
+    # a matching version
+    listing_prefix = self.CHROMIUM_LISTING_PREFIX.get(self.host_platform.key)
+    if not listing_prefix:
+      raise NotImplementedError(
+          f"Unsupported chromedriver platform {self.host_platform}")
+    base_prefix = str(chromium_base_position)[:4]
+    listing_url = helper.update_url_query(self.CHROMIUM_LISTING_URL, {
+        "prefix": f"{listing_prefix}/{base_prefix}",
+        "maxResults": "10000"
+    })
+    with helper.urlopen(listing_url) as response:
+      listing = json.loads(response.read().decode("utf-8"))
+
+    versions = []
+    logging.debug("Filtering %s candidate URLs.", len(listing["items"]))
+    for version in listing["items"]:
+      if "name" not in version:
+        continue
+      if "mediaLink" not in version:
+        continue
+      name = version["name"]
+      if "chromedriver" not in name:
+        continue
+      parts = name.split("/")
+      if "chromedriver" not in parts[-1] or len(parts) < 3:
+        continue
+      base = parts[1]
+      try:
+        int(base)
+      except ValueError:
+        # Ignore base if it is not an int
+        continue
+      versions.append((int(base), version["mediaLink"]))
+    versions.sort()
+    logging.debug("Found candidates: %s", versions)
+    logging.debug("chromium_base_position=%s", chromium_base_position)
+
+    for i in range(len(versions)):
+      base, url = versions[i]
+      if base > chromium_base_position:
+        base, url = versions[i - 1]
+        return listing_url, url
+    return listing_url, None
diff --git a/crossbench/browsers/downloader.py b/crossbench/browsers/downloader.py
new file mode 100644
index 0000000..acc309b
--- /dev/null
+++ b/crossbench/browsers/downloader.py
@@ -0,0 +1,330 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import logging
+import os
+import plistlib
+import re
+import shutil
+import sys
+import tempfile
+from typing import TYPE_CHECKING, Final, Iterable, Optional, Tuple, Type, Union
+
+from crossbench import path as pth
+from crossbench.browsers.version import BrowserVersion, UnknownBrowserVersion
+from crossbench.helper import Spinner
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import Platform
+
+
+class IncompatibleVersionError(ValueError):
+  pass
+
+
+class Downloader(abc.ABC):
+  ARCHIVE_SUFFIX: str = ""
+  ANY_MARKER: Final = 9999
+  APP_VERSION_RE = re.compile(r"(?P<version>[\d\.ab]+)")
+
+  @classmethod
+  @abc.abstractmethod
+  def _get_loader_cls(cls, browser_platform: Platform) -> Type[Downloader]:
+    pass
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: pth.AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return cls._get_loader_cls(browser_platform).is_valid(
+        path_or_identifier, browser_platform)
+
+  @classmethod
+  @abc.abstractmethod
+  def is_valid_version(cls, path_or_identifier: str):
+    pass
+
+  @classmethod
+  def load(cls, archive_path_or_version_identifier: Union[str, pth.LocalPath],
+           browser_platform: Platform) -> pth.LocalPath:
+    logging.debug("Downloading chrome %s binary for %s",
+                  archive_path_or_version_identifier, browser_platform)
+    loader_cls: Type[Downloader] = cls._get_loader_cls(browser_platform)
+    loader: Downloader = loader_cls(archive_path_or_version_identifier, "", "",
+                                    browser_platform)
+    return loader.app_path
+
+  def __init__(self, archive_path_or_version_identifier: Union[str,
+                                                               pth.LocalPath],
+               browser_type: str, platform_name: str,
+               browser_platform: Platform):
+    assert browser_type, "Missing browser_type"
+    self._browser_type = browser_type
+    self._browser_platform = browser_platform
+    self._platform_name = platform_name
+    assert platform_name, "Missing platform_name"
+    self._archive_url: str = ""
+    self._archive_path: pth.LocalPath = pth.LocalPath()
+    self._out_dir: pth.LocalPath = (
+        self.host_platform.local_cache_dir("browser_bin"))
+    self._archive_dir: pth.LocalPath = (
+        self.host_platform.local_cache_dir("browser_archive"))
+    self._archive_dir.mkdir(parents=True, exist_ok=True)
+    self._app_path: pth.LocalPath = pth.LocalPath()
+    self._requested_version: BrowserVersion = UnknownBrowserVersion()
+    with Spinner():
+      self._app_path = self.find(archive_path_or_version_identifier)
+    self._validate()
+
+  def find(
+      self, archive_path_or_version_identifier: Union[str, pth.LocalPath]
+  ) -> pth.LocalPath:
+    version_value = os.fspath(archive_path_or_version_identifier)
+    if self.is_valid_version(version_value):
+      self._requested_version = self._parse_version(version_value)
+      self._pre_check()
+      sys.stdout.write(f"   BROWSER: Looking for {self._requested_version}\r")
+      return self._load_from_version()
+
+    self._archive_path = pth.LocalPath(archive_path_or_version_identifier)
+    self._pre_check()
+    if not archive_path_or_version_identifier or (
+        not self._archive_path.exists()):
+      raise ValueError(
+          f"{self._browser_type} archive does not exist: {self._archive_path}")
+    return self._load_from_archive()
+
+  def _validate(self) -> None:
+    assert self._app_path != pth.LocalPath(), "Did not set app_path"
+    assert self._is_app_installed(self._app_path), (
+        f"Could not extract {self._browser_type}  binary: {self._app_path}")
+    logging.debug("Extracted app: %s", self._app_path)
+
+  @property
+  def app_path(self) -> pth.LocalPath:
+    assert self._is_app_installed(self._app_path), "Could not download browser"
+    return self._app_path
+
+  @property
+  def host_platform(self) -> Platform:
+    return self._browser_platform.host_platform
+
+  def _pre_check(self) -> None:
+    pass
+
+  def _is_app_installed(self, app_path: pth.LocalPath) -> bool:
+    return self._browser_platform.search_app(app_path) is not None
+
+  def _find_matching_installed_version(self) -> Optional[pth.LocalPath]:
+    app_path: pth.LocalPath = self._installed_app_path()
+    if self._is_app_installed(app_path):
+      return app_path
+    return None
+
+  def _create_archive_path(self, version: BrowserVersion) -> pth.LocalPath:
+    version_name = str(version).replace(" ", "_")
+    return self._archive_dir / (f"{version_name}{self.ARCHIVE_SUFFIX}")
+
+  def _load_from_version(self) -> pth.LocalPath:
+    self._archive_path = self._create_archive_path(self._requested_version)
+    if app_path := self._find_matching_installed_version():
+      if cached_version := self._validate_installed(app_path):
+        logging.info("CACHED BROWSER: %s %s", cached_version, self._app_path)
+        return app_path
+    self._requested_version_validation()
+    if not self._try_download_version_archive():
+      logging.info("CACHED DOWNLOAD: %s", self._archive_path)
+    self._install_archive(self._archive_path)
+    return self._installed_app_path()
+
+  def _try_download_version_archive(self):
+    if self._archive_path.exists():
+      return False
+    archive_version, archive_url = self._find_archive_url()
+    if not archive_url:
+      raise ValueError(
+          f"Could not find matching version for {self._requested_version}")
+    self._archive_url = archive_url
+    self._archive_path = self._create_archive_path(archive_version)
+    if self._archive_path.exists():
+      return False
+    logging.info("DOWNLOADING %s", self._archive_url)
+    with tempfile.TemporaryDirectory(prefix="cb_download_") as tmp_dir_name:
+      tmp_dir = pth.LocalPath(tmp_dir_name)
+      self._download_archive(self._archive_url, tmp_dir)
+    return True
+
+  @abc.abstractmethod
+  def _requested_version_validation(self) -> None:
+    pass
+
+  def _load_from_archive(self) -> pth.LocalPath:
+    assert not self._requested_version.is_complete
+    assert self._archive_path.exists()
+    logging.info("EXTRACTING ARCHIVE: %s", self._archive_path)
+    original_out_dir = self._out_dir
+    with tempfile.TemporaryDirectory(
+        prefix="cb_extract_", dir=original_out_dir) as tmpdir:
+      # Extract input archive to temp dir for version extraction.
+      self._out_dir = pth.LocalPath(tmpdir)
+      temp_extracted_path = self._extract_unknown_version_archive()
+      self._out_dir = original_out_dir
+      # Install temporary extracted version
+      versioned_path = self._extracted_path()
+      app_path = self._installed_app_path()
+      if self._is_app_installed(app_path):
+        cached_version = self._validate_installed(app_path)
+        logging.info("CACHED BROWSER: %s %s", cached_version, app_path)
+      else:
+        assert not versioned_path.exists()
+        temp_extracted_path.rename(versioned_path)
+    return app_path
+
+  def _extract_unknown_version_archive(self) -> pth.LocalPath:
+    tmp_app_path: pth.LocalPath = self._installed_app_path()
+    temp_extracted_path = self._extracted_path()
+    self._install_archive(self._archive_path)
+    logging.debug("Parsing browser version: %s", tmp_app_path)
+    assert self._is_app_installed(tmp_app_path), (
+        f"Extraction failed, app does not exist: {tmp_app_path}")
+    full_version_string = self._browser_platform.app_version(tmp_app_path)
+    self._requested_version = self._parse_version(full_version_string)
+    assert self._requested_version.is_complete
+    return temp_extracted_path
+
+
+  @abc.abstractmethod
+  def _parse_version(self, version_identifier: str) -> BrowserVersion:
+    pass
+
+  def _extracted_path(self) -> pth.LocalPath:
+    # TODO: support local vs remote
+    return self._out_dir / str(self._requested_version).replace(" ", "_")
+
+  @abc.abstractmethod
+  def _installed_app_path(self) -> pth.LocalPath:
+    pass
+
+  def _installed_app_version(self, app_path: pth.LocalPath) -> BrowserVersion:
+    raw_version = self._browser_platform.app_version(app_path)
+    return self._parse_version(raw_version)
+
+  def _validate_installed(self, app_path: pth.LocalPath) -> BrowserVersion:
+    cached_version: BrowserVersion = self._installed_app_version(app_path)
+    msg: str = ""
+    expected_version_str: str = str(self._requested_version)
+    if self._requested_version.is_complete:
+      if self._requested_version.contains(cached_version):
+        return cached_version
+      msg = (f"Previously downloaded browser at {app_path} "
+             "might have been auto-updated.\n")
+    else:
+      requested_milestone: int = self._requested_version.major
+      logging.debug("Validating installed milestone %s", requested_milestone)
+      latest_milestone_version, _ = self._find_archive_url()
+      if cached_version == latest_milestone_version:
+        return cached_version
+      msg = (f"Previously downloaded browser at {app_path} "
+             f"does not match latest milestone {requested_milestone} "
+             f"version: {latest_milestone_version}.\n")
+      expected_version_str = (
+          f"{self._requested_version}/{latest_milestone_version}")
+    msg += ("Please delete the old version and re-install/-download it.\n"
+            f"Expected: {expected_version_str} Got: {cached_version}")
+    logging.debug(msg)
+    raise IncompatibleVersionError(msg)
+
+  @abc.abstractmethod
+  def _find_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
+    pass
+
+  @abc.abstractmethod
+  def _archive_urls(
+      self, folder_url: str,
+      version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
+    pass
+
+  @abc.abstractmethod
+  def _download_archive(self, archive_url: str, tmp_dir: pth.LocalPath) -> None:
+    pass
+
+  @abc.abstractmethod
+  def _install_archive(self, archive_path: pth.LocalPath) -> None:
+    pass
+
+
+class ArchiveHelper(abc.ABC):
+
+  @classmethod
+  @abc.abstractmethod
+  def extract(cls, platform: Platform, archive_path: pth.LocalPath,
+              dest_path: pth.LocalPath) -> pth.LocalPath:
+    pass
+
+
+class RPMArchiveHelper(ArchiveHelper):
+
+  @classmethod
+  def extract(cls, platform: Platform, archive_path: pth.LocalPath,
+              dest_path: pth.LocalPath) -> pth.LocalPath:
+    assert platform.which("rpm2cpio"), (
+        "Need rpm2cpio to extract downloaded .rpm archive")
+    assert platform.which("cpio"), (
+        "Need cpio to extract downloaded .rpm archive")
+    cpio_file = archive_path.with_suffix(".cpio")
+    assert not cpio_file.exists()
+    archive_path.parent.mkdir(parents=True, exist_ok=True)
+    with cpio_file.open("w") as f:
+      platform.sh("rpm2cpio", archive_path, stdout=f)
+    assert cpio_file.is_file(), f"Could not extract archive: {archive_path}"
+    assert not dest_path.exists()
+    with cpio_file.open() as f:
+      platform.sh(
+          "cpio",
+          "--extract",
+          f"--directory={dest_path}",
+          "--make-directories",
+          stdin=f)
+    cpio_file.unlink()
+    if not dest_path.exists():
+      raise ValueError(f"Could not extract archive to {dest_path}")
+    return dest_path
+
+
+class DMGArchiveHelper:
+
+  @classmethod
+  def extract(cls, platform: Platform, archive_path: pth.LocalPath,
+              dest_path: pth.LocalPath) -> pth.LocalPath:
+    assert platform.is_macos, "DMG are only supported on macOS."
+    assert not platform.is_remote, "Remote platform not supported yet"
+    result = platform.sh_stdout("hdiutil", "attach", "-plist",
+                                archive_path).strip()
+    data = plistlib.loads(str.encode(result))
+    dmg_path: Optional[pth.LocalPath] = None
+    for item in data["system-entities"]:
+      mount_point = item.get("mount-point", None)
+      if mount_point:
+        dmg_path = pth.LocalPath(mount_point)
+        if dmg_path.exists():
+          break
+    if not dmg_path:
+      raise ValueError("Could not mount downloaded disk image")
+    apps = list(dmg_path.glob("*.app"))
+    assert len(apps) == 1, "Mounted disk image contains more than 1 app"
+    app = apps[0]
+    try:
+      logging.info("COPYING BROWSER src=%s dst=%s", app, dest_path)
+      shutil.copytree(
+          os.fspath(app),
+          os.fspath(dest_path),
+          symlinks=True,
+          dirs_exist_ok=False)
+    finally:
+      platform.sh("hdiutil", "detach", dmg_path)
+    if not dest_path.exists():
+      raise ValueError(f"Could not extract archive to {dest_path}")
+    return dest_path
diff --git a/crossbench/browsers/edge/__init__.py b/crossbench/browsers/edge/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/browsers/edge/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/browsers/edge/edge.py b/crossbench/browsers/edge/edge.py
new file mode 100644
index 0000000..ba88aee
--- /dev/null
+++ b/crossbench/browsers/edge/edge.py
@@ -0,0 +1,68 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench import plt
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chromium.chromium import Chromium
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath
+
+
+class EdgePathMixin:
+  @classmethod
+  def default_path(cls, platform: plt.Platform) -> AnyPath:
+    return cls.stable_path(platform)
+
+  @classmethod
+  def stable_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Stable",
+        macos=["Microsoft Edge.app"],
+        linux=["microsoft-edge"],
+        win=["Microsoft/Edge/Application/msedge.exe"])
+
+  @classmethod
+  def beta_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Beta",
+        macos=["Microsoft Edge Beta.app"],
+        linux=["microsoft-edge-beta"],
+        win=["Microsoft/Edge Beta/Application/msedge.exe"])
+
+  @classmethod
+  def dev_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Dev",
+        macos=["Microsoft Edge Dev.app"],
+        linux=["microsoft-edge-dev"],
+        win=["Microsoft/Edge Dev/Application/msedge.exe"])
+
+  @classmethod
+  def canary_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Canary",
+        macos=["Microsoft Edge Canary.app"],
+        linux=[],
+        win=["Microsoft/Edge SxS/Application/msedge.exe"])
+
+  @property
+  def type_name(self) -> str:
+    return "edge"
+
+
+class Edge(EdgePathMixin, Chromium):
+  DEFAULT_FLAGS = (
+      "--enable-benchmarking",
+      "--disable-extensions",
+      "--no-first-run",
+  )
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.EDGE | BrowserAttributes.CHROMIUM_BASED
diff --git a/crossbench/browsers/edge/webdriver.py b/crossbench/browsers/edge/webdriver.py
new file mode 100644
index 0000000..c0f4c70
--- /dev/null
+++ b/crossbench/browsers/edge/webdriver.py
@@ -0,0 +1,105 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+import os
+import shutil
+import stat
+import tempfile
+from typing import TYPE_CHECKING
+
+from selenium import webdriver
+from selenium.webdriver.edge.options import Options as EdgeOptions
+from selenium.webdriver.edge.service import Service as EdgeService
+
+import crossbench
+import crossbench.exception
+from crossbench import path as pth
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chromium.webdriver import ChromiumWebDriver
+from crossbench.browsers.edge.edge import EdgePathMixin
+
+if TYPE_CHECKING:
+  from selenium.webdriver.chromium.webdriver import ChromiumDriver
+
+  from crossbench import plt
+
+
+class EdgeWebDriver(EdgePathMixin, ChromiumWebDriver):
+
+  WEB_DRIVER_OPTIONS = EdgeOptions
+  WEB_DRIVER_SERVICE = EdgeService
+
+  @property
+  def type_name(self) -> str:
+    return "edge"
+
+  def _find_driver(self) -> pth.AnyPath:
+    finder = EdgeWebDriverDownloader(self)
+    return finder.download()
+
+  def _create_driver(self, options: EdgeOptions,
+                     service: EdgeService) -> ChromiumDriver:
+    return webdriver.Edge(options=options, service=service)
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return (BrowserAttributes.EDGE | BrowserAttributes.CHROMIUM_BASED
+            | BrowserAttributes.WEBDRIVER)
+
+
+class EdgeWebDriverDownloader:
+  BASE_URL = "https://msedgedriver.azureedge.net"
+
+  def __init__(self, browser: EdgeWebDriver) -> None:
+    self.browser = browser
+    self.platform: plt.Platform = browser.platform
+    assert self.browser.is_local, (
+        "Cannot download chromedriver for remote browser yet")
+    self.extension: str = ""
+    if self.platform.is_win:
+      self.extension = ".exe"
+    cache_dir = self.platform.host_platform.local_cache_dir("driver")
+    self.driver_path: pth.LocalPath = (
+        cache_dir / f"edgedriver-{self.browser.major_version}{self.extension}")
+
+  def download(self) -> pth.LocalPath:
+    if not self.driver_path.exists():
+      with crossbench.exception.annotate(
+          f"Downloading edgedriver for {self.browser.version}"):
+        self._download()
+    return self.driver_path
+
+  def _download(self) -> None:
+    arch = self._arch_identifier()
+    archive_name = f"edgedriver_{arch}.zip"
+    url = self.BASE_URL + f"/{self.browser.version}/{archive_name}"
+    logging.info("EDGEDRIVER downloading %s: %s", self.browser.version, url)
+    with tempfile.TemporaryDirectory() as tmp_dir:
+      archive_file = pth.LocalPath(tmp_dir) / archive_name
+      self.platform.download_to(url, archive_file)
+      unpack_dir = pth.LocalPath(tmp_dir) / "extracted"
+      shutil.unpack_archive(os.fspath(archive_file), os.fspath(unpack_dir))
+      driver = unpack_dir / f"msedgedriver{self.extension}"
+      assert driver.is_file(), (f"Extracted driver at {driver} does not exist.")
+      shutil.move(os.fspath(driver), os.fspath(self.driver_path))
+      self.driver_path.chmod(self.driver_path.stat().st_mode | stat.S_IEXEC)
+
+  def _arch_identifier(self) -> str:
+    if self.platform.is_linux:
+      assert self.platform.is_x64, "edgedriver is only available on linux x64"
+      return "linux64"
+    if self.platform.is_macos:
+      if self.platform.is_arm64:
+        return "mac64_m1"
+      if self.platform.is_x64:
+        return "mac64"
+    elif self.platform.is_win:
+      if self.platform.is_x64:
+        return "win64"
+      if self.platform.is_ia32:
+        return "win32"
+    raise ValueError(f"Unsupported edgedriver platform {self.platform}")
diff --git a/crossbench/browsers/firefox/__init__.py b/crossbench/browsers/firefox/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/browsers/firefox/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/browsers/firefox/downloader.py b/crossbench/browsers/firefox/downloader.py
new file mode 100644
index 0000000..c66868d
--- /dev/null
+++ b/crossbench/browsers/firefox/downloader.py
@@ -0,0 +1,183 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import urllib.parse
+from typing import (TYPE_CHECKING, Dict, Final, Iterable, Optional, Tuple, Type,
+                    Union)
+
+from crossbench.browsers.downloader import DMGArchiveHelper, Downloader
+from crossbench.browsers.firefox.version import FirefoxVersion
+
+if TYPE_CHECKING:
+  from crossbench.browsers.version import BrowserVersion
+  from crossbench.path import AnyPathLike, LocalPath
+  from crossbench.plt.base import Platform
+
+
+_PLATFORM_NAME_LOOKUP: Final[Dict[Tuple[str, str], str]] = {
+    ("win", "ia32"): "win32",
+    ("win", "x64"): "win64",
+    ("win", "arm64"): "win-aarch64",
+    ("linux", "x64"): "linux-x86-64",
+    ("linux", "ia32"): "linux-i686",
+    ("macos", "x64"): "mac",
+    ("macos", "arm64"): "mac"
+}
+
+
+class FirefoxDownloader(Downloader):
+  # TODO: support nightly versions as well
+  STORAGE_URL: str = "https://ftp.mozilla.org/pub/firefox/releases/"
+
+  @classmethod
+  def _get_loader_cls(cls,
+                      browser_platform: Platform) -> Type[FirefoxDownloader]:
+    if browser_platform.is_macos:
+      return FirefoxDownloaderMacOS
+    if browser_platform.is_linux:
+      return FirefoxDownloaderLinux
+    if browser_platform.is_win:
+      return FirefoxDownloaderWin
+    raise ValueError("Downloading Firefox is not supported "
+                     f"{browser_platform.name} {browser_platform.machine}")
+
+  @classmethod
+  def is_valid_version(cls, path_or_identifier: str) -> bool:
+    return FirefoxVersion.is_valid_unique(path_or_identifier)
+
+  @classmethod
+  def _is_valid(cls, path_or_identifier: AnyPathLike,
+                browser_platform: Platform) -> bool:
+    if cls.is_valid_version(str(path_or_identifier)):
+      return True
+    path = browser_platform.path(path_or_identifier)
+    return (browser_platform.exists(path) and
+            path.name.endswith(cls.ARCHIVE_SUFFIX))
+
+  def __init__(self, version_identifier: Union[str,
+                                               LocalPath], browser_type: str,
+               platform_name: str, browser_platform: Platform):
+    assert not browser_type
+    assert not platform_name
+    firefox_platform_name = _PLATFORM_NAME_LOOKUP.get(browser_platform.key)
+    if not firefox_platform_name:
+      raise ValueError(
+          "Unsupported macOS architecture for downloading Firefox: "
+          f"got={browser_platform.machine}")
+    super().__init__(version_identifier, "firefox", firefox_platform_name,
+                     browser_platform)
+
+  def _parse_version(self, version_identifier: str) -> BrowserVersion:
+    return FirefoxVersion.parse(version_identifier)
+
+  def _requested_version_validation(self) -> None:
+    pass
+
+  def _find_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
+    # Quick probe for complete versions
+    if self._requested_version.is_complete:
+      return self._find_exact_archive_url()
+    raise NotImplementedError("Only full-release versions supported.")
+
+  def _find_exact_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
+    folder_url = (
+        f"{self.STORAGE_URL}{self._requested_version.parts_str}/mac/en-GB")
+    return tuple(self._archive_urls(folder_url, self._requested_version))[0]
+
+  def _download_archive(self, archive_url: str, tmp_dir: LocalPath) -> None:
+    self._browser_platform.download_to(
+        archive_url, tmp_dir / f"archive.{self.ARCHIVE_SUFFIX}")
+    archive_candidates = list(tmp_dir.glob("*"))
+    assert len(archive_candidates) == 1, (
+        f"Download tmp dir contains more than one file: {tmp_dir}"
+        f"{archive_candidates}")
+    candidate = archive_candidates[0]
+    assert not self._archive_path.exists(), (
+        f"Archive was already downloaded: {self._archive_path}")
+    candidate.replace(self._archive_path)
+
+  @abc.abstractmethod
+  def _install_archive(self, archive_path: LocalPath) -> None:
+    pass
+
+
+class FirefoxDownloaderLinux(FirefoxDownloader):
+  ARCHIVE_SUFFIX: str = ".tar.bz2"
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return cls._is_valid(path_or_identifier, browser_platform)
+
+  def _installed_app_path(self) -> LocalPath:
+    # TODO: support local vs remote
+    return self._extracted_path() / "firefox-bin"
+
+  def _archive_urls(
+      self, folder_url: str,
+      version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
+    return ((version, f"{folder_url}/firefox-{version.parts_str}.tar.bz2"),)
+
+  def _install_archive(self, archive_path: LocalPath) -> None:
+    raise NotImplementedError("Missing linux support")
+
+
+class FirefoxDownloaderMacOS(FirefoxDownloader):
+  ARCHIVE_SUFFIX: str = ".dmg"
+  MIN_MAC_ARM64_MILESTONE: Final[int] = 84
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return cls._is_valid(path_or_identifier, browser_platform)
+
+  def _requested_version_validation(self) -> None:
+    major_version: int = self._requested_version.major
+    if (self._browser_platform.is_macos and self._browser_platform.is_arm64 and
+        major_version < self.MIN_MAC_ARM64_MILESTONE):
+      raise ValueError(
+          "Native Mac arm64/m1 Firefox version is available with v84, "
+          f"but requested {major_version}.")
+
+  def _download_archive(self, archive_url: str, tmp_dir: LocalPath) -> None:
+    assert self._browser_platform.is_macos
+    if self._browser_platform.is_arm64 and (self._requested_version
+                                            < self.MIN_MAC_ARM64_MILESTONE):
+      raise ValueError(
+          "Firefox Arm64 Apple Silicon is only available starting with "
+          f"{self.MIN_MAC_ARM64_MILESTONE}, "
+          f"but requested {self._requested_version} is too old.")
+    super()._download_archive(archive_url, tmp_dir)
+
+  def _archive_urls(
+      self, folder_url: str,
+      version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
+    archive_name = urllib.parse.quote(f"Firefox {version.parts_str}.dmg")
+    return ((version, f"{folder_url}/{archive_name}"),)
+
+  def _extracted_path(self) -> LocalPath:
+    # TODO: support local vs remote
+    return self._installed_app_path()
+
+  def _installed_app_path(self) -> LocalPath:
+    return self._out_dir / f"Firefox {self._requested_version}.app"
+
+  def _install_archive(self, archive_path: LocalPath) -> None:
+    extracted_path = self._extracted_path()
+    DMGArchiveHelper.extract(self.host_platform, archive_path, extracted_path)
+    assert extracted_path.exists()
+
+
+class FirefoxDownloaderWin(FirefoxDownloader):
+
+  @classmethod
+  def is_valid(cls, path_or_identifier: AnyPathLike,
+               browser_platform: Platform) -> bool:
+    return False
+
+  def _install_archive(self, archive_path: LocalPath) -> None:
+    raise NotImplementedError("Missing windows support")
diff --git a/crossbench/browsers/firefox/firefox.py b/crossbench/browsers/firefox/firefox.py
new file mode 100644
index 0000000..9665986
--- /dev/null
+++ b/crossbench/browsers/firefox/firefox.py
@@ -0,0 +1,119 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import TYPE_CHECKING, Tuple
+
+from crossbench import plt
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.browser import Browser
+from crossbench.browsers.viewport import Viewport
+from crossbench.browsers.webdriver import WebDriverBrowser
+
+if TYPE_CHECKING:
+  from crossbench.browsers.settings import Settings
+  from crossbench.flags.base import Flags
+  from crossbench.path import AnyPath
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class Firefox(Browser):
+
+  @classmethod
+  def default_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Firefox",
+        macos=["Firefox.app"],
+        linux=["firefox"],
+        win=["Mozilla Firefox/firefox.exe"])
+
+  @classmethod
+  def developer_edition_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Firefox Developer Edition",
+        macos=["Firefox Developer Edition.app"],
+        linux=["firefox-developer-edition"],
+        win=["Firefox Developer Edition/firefox.exe"])
+
+  @classmethod
+  def nightly_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Firefox Nightly",
+        macos=["Firefox Nightly.app"],
+        linux=["firefox-nightly", "firefox-trunk"],
+        win=["Firefox Nightly/firefox.exe"])
+
+  def _setup_cache_dir(self, settings: Settings) -> None:
+    cache_dir = settings.cache_dir
+    if cache_dir:
+      self.cache_dir = cache_dir
+      self.clear_cache_dir = False
+    else:
+      self.cache_dir: AnyPath = settings.platform.mkdtemp(prefix="firefox")
+      self.clear_cache_dir = True
+
+  @property
+  def type_name(self) -> str:
+    return "firefox"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.FIREFOX
+
+  def _extract_version(self) -> str:
+    assert self.path
+    version_string = self.platform.app_version(self.path)
+    # "Firefox 107.0" => "107.0"
+    return str(re.findall(r"[\d\.]+", version_string)[0])
+
+  def _get_browser_flags_for_session(
+      self, session: BrowserSessionRunGroup) -> Tuple[str, ...]:
+    flags_copy = self.flags.copy()
+    flags_copy.update(session.extra_flags)
+    flags_copy.update(self.network.extra_flags(self.attributes))
+    self._handle_viewport_flags(flags_copy)
+    if self.log_file:
+      flags_copy["--MOZ_LOG_FILE"] = str(self.log_file)
+    return tuple(flags_copy)
+
+  def _handle_viewport_flags(self, flags: Flags) -> None:
+    new_width, new_height = 0, 0
+    if self.viewport.has_size:
+      new_width, new_height = self.viewport.size
+    update_size = False
+    if "--width" in flags:
+      if self.viewport.is_default:
+        new_width = int(flags["--width"])
+        update_size = True
+      else:
+        assert self.viewport.width == int(flags["--width"])
+    if "--height" in flags:
+      if self.viewport.is_default:
+        new_height = int(flags["--height"])
+        update_size = True
+      else:
+        assert self.viewport.height == int(flags["--height"])
+    if update_size:
+      assert self.viewport.is_default
+      self.viewport = Viewport(new_width, new_height)
+    elif self.viewport.has_size:
+      flags["--width"] = str(self.viewport.width)
+      flags["--height"] = str(self.viewport.height)
+
+    self._sync_viewport_flag(flags, "--kiosk", self.viewport.is_fullscreen,
+                             Viewport.FULLSCREEN)
+    self._sync_viewport_flag(flags, "--headless", self.viewport.is_headless,
+                             Viewport.HEADLESS)
+
+    if self.viewport.has_size and not self.viewport.is_default:
+      if not isinstance(self,
+                        WebDriverBrowser) and self.viewport.size != (0, 0):
+        raise ValueError(f"Browser {self} cannot handle viewport position: "
+                         f"{self.viewport.position}")
+    else:
+      if not isinstance(self, WebDriverBrowser):
+        raise ValueError(
+            f"Browser {self} cannot handle viewport mode: {self.viewport}")
diff --git a/crossbench/browsers/firefox/version.py b/crossbench/browsers/firefox/version.py
new file mode 100644
index 0000000..aead212
--- /dev/null
+++ b/crossbench/browsers/firefox/version.py
@@ -0,0 +1,82 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import Dict, Final, Optional, Tuple
+
+from crossbench.browsers.version import BrowserVersion, BrowserVersionChannel
+
+
+class FirefoxVersion(BrowserVersion):
+  _PARTS_LEN: Final[int] = 4
+  _PREFIX_RE = re.compile(r"(mozilla )?(ff|firefox)[ -]?", re.I)
+  _VERSION_RE = re.compile(r"(?P<prefix>[^\d]*)"
+                           r"(?P<version>"
+                           r"(?P<parts>\d+\.\d+(?P<channel>[ab.])\d+)"
+                           r") ?(?P<channel_long>esr|any)?")
+  _SPLIT_RE = re.compile(r"[ab.]")
+  _CHANNEL_LOOKUP: Dict[str, BrowserVersionChannel] = {
+      "esr": BrowserVersionChannel.LTS,
+      ".": BrowserVersionChannel.STABLE,
+      # IRL Firefox version numbers do not distinct beta from stable, so we
+      # remap Firefox Dev => beta.
+      "b": BrowserVersionChannel.BETA,
+      "a": BrowserVersionChannel.ALPHA,
+      "any": BrowserVersionChannel.ANY,
+  }
+
+  @classmethod
+  def _parse(
+      cls,
+      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
+    matches = cls._VERSION_RE.fullmatch(full_version.strip())
+    if not matches:
+      raise cls.parse_error("Could not extract version number", full_version)
+    prefix = matches["prefix"]
+    if not cls._validate_prefix(prefix):
+      raise cls.parse_error(f"Wrong prefix {repr(prefix)}", full_version)
+    version_str = matches["version"]
+    version_parts = matches["parts"]
+    assert version_parts and version_str
+    if matches["channel_long"] and matches["channel"] != ".":
+      raise cls.parse_error("Invalid ESR/Any channel version", full_version)
+    browser_channel = cls._parse_channel(matches)
+    parts = tuple(map(int, cls._SPLIT_RE.split(version_parts)))
+    if len(parts) != 3:
+      raise cls.parse_error("Invalid number of version number parts",
+                            full_version)
+    return parts, browser_channel, version_str
+
+  @classmethod
+  def _parse_channel(cls, matches) -> BrowserVersionChannel:
+    channel_str: str = (matches["channel_long"] or matches["channel"] or
+                        "stable").lower()
+    return cls._CHANNEL_LOOKUP[channel_str]
+
+  @classmethod
+  def _validate_prefix(cls, prefix: Optional[str]) -> bool:
+    if not prefix:
+      return True
+    return bool(cls._PREFIX_RE.match(prefix))
+
+  def _channel_name(self, channel: BrowserVersionChannel) -> str:
+    if channel == BrowserVersionChannel.LTS:
+      return "esr"
+    if channel == BrowserVersionChannel.STABLE:
+      return "stable"
+    if channel == BrowserVersionChannel.BETA:
+      return "dev"
+    if channel == BrowserVersionChannel.ALPHA:
+      return "nightly"
+    raise ValueError(f"Unsupported channel: {channel}")
+
+  @property
+  def has_complete_parts(self) -> bool:
+    return len(self.parts) == 3
+
+  @property
+  def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
+    return (self.comparable_parts(self._PARTS_LEN), self._channel)
diff --git a/crossbench/browsers/firefox/webdriver.py b/crossbench/browsers/firefox/webdriver.py
new file mode 100644
index 0000000..15da878
--- /dev/null
+++ b/crossbench/browsers/firefox/webdriver.py
@@ -0,0 +1,192 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+import logging
+import os
+import shutil
+import stat
+import tempfile
+from typing import TYPE_CHECKING, Dict, List, Optional, Tuple
+
+from selenium import webdriver
+from selenium.webdriver.firefox.firefox_profile import FirefoxProfile
+from selenium.webdriver.firefox.options import Options as FirefoxOptions
+from selenium.webdriver.firefox.service import Service as FirefoxService
+
+from crossbench import exception, helper
+from crossbench import path as pth
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.firefox.firefox import Firefox
+from crossbench.browsers.webdriver import WebDriverBrowser
+
+if TYPE_CHECKING:
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class FirefoxWebDriver(WebDriverBrowser, Firefox):
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.FIREFOX | BrowserAttributes.WEBDRIVER
+
+  def _find_driver(self) -> pth.AnyPath:
+    finder = FirefoxDriverFinder(self)
+    return finder.download()
+
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: pth.AnyPath) -> webdriver.Remote:
+    return self._start_firefox_driver(session, driver_path)
+
+  def _start_firefox_driver(self, session: BrowserSessionRunGroup,
+                            driver_path: pth.AnyPath) -> webdriver.Firefox:
+    assert not self._is_running
+    assert self.log_file
+    options = FirefoxOptions()
+    options.set_capability("browserVersion", str(self.major_version))
+    # Don't wait for document-ready.
+    options.set_capability("pageLoadStrategy", "eager")
+    args = self._get_browser_flags_for_session(session)
+    for arg in args:
+      options.add_argument(arg)
+    options.binary_location = os.fspath(self.path)
+    session.setup_selenium_options(options)
+    if self.cache_dir:
+      # TODO: support remote platforms
+      options.profile = FirefoxProfile(self.cache_dir)
+    self._log_browser_start(args, driver_path)
+    service_args: List[str] = []
+    log_path: Optional[str] = None
+    if self._settings.driver_logging:
+      service_args += ["--log", "debug"]
+      log_path = os.fspath(self.driver_log_file)
+    # Explicitly copy the env vars for FirefoxBrowserProfilerProbeContext
+    env_copy = dict(self.platform.environ)
+    service = FirefoxService(
+        executable_path=os.fspath(driver_path),
+        log_path=log_path,
+        service_args=service_args,
+        env=env_copy)
+    # TODO support remote platforms:
+    service.log_file = self.host_platform.local_path(self.stdout_log_file).open(
+        "w", encoding="utf-8")
+    driver = webdriver.Firefox(options=options, service=service)
+    return driver
+
+  def _validate_driver_version(self) -> None:
+    # TODO
+    # version = self.platform.sh_stdout(self._driver_path, "--version")
+    pass
+
+
+class FirefoxDriverFinder:
+  RELEASES_URL = "https://api.github.com/repos/mozilla/geckodriver/releases"
+
+  def __init__(self, browser: FirefoxWebDriver):
+    self.browser = browser
+    self.platform = browser.platform
+    self.extension = ""
+    if self.platform.is_win:
+      self.extension = ".exe"
+    cache_dir = self.platform.host_platform.local_cache_dir("driver")
+    self.driver_path = (
+        cache_dir / f"geckodriver-{self.browser.major_version}{self.extension}")
+
+  def download(self) -> pth.LocalPath:
+    if not self.driver_path.exists():
+      with exception.annotate(
+          f"Downloading geckodriver for {self.browser.version}"):
+        self._download()
+    return self.driver_path
+
+  def _download(self) -> None:
+    url, archive_type = self._find_driver_download_url()
+    with tempfile.TemporaryDirectory() as tmp_dir:
+      tar_file = pth.LocalPath(tmp_dir) / f"download.{archive_type}"
+      self.platform.download_to(url, tar_file)
+      unpack_dir = pth.LocalPath(tmp_dir) / "extracted"
+      shutil.unpack_archive(os.fspath(tar_file), os.fspath(unpack_dir))
+      driver = unpack_dir / f"geckodriver{self.extension}"
+      assert driver.is_file(), (f"Extracted driver at {driver} does not exist.")
+      self.driver_path.parent.mkdir(parents=True, exist_ok=True)
+      shutil.move(os.fspath(driver), os.fspath(self.driver_path))
+      self.driver_path.chmod(self.driver_path.stat().st_mode | stat.S_IEXEC)
+
+  def _find_driver_download_url(self) -> Tuple[str, str]:
+    driver_version = self._get_driver_version()
+    all_releases = self._load_releases()
+    matching_release = {}
+    for version, version_release in all_releases.items():
+      if version <= driver_version:
+        matching_release = version_release
+        break
+    if not matching_release:
+      raise ValueError("No matching geckodriver version found")
+    arch = self._arch_identifier()
+    version = matching_release["tag_name"]
+    archive_type = "tar.gz"
+    if self.platform.is_win:
+      archive_type = "zip"
+    driver_asset_name = f"geckodriver-{version}-{arch}.{archive_type}"
+    url = ""
+    for asset in matching_release["assets"]:
+      if asset["name"] == driver_asset_name:
+        url = asset["browser_download_url"]
+        break
+    if not url:
+      raise ValueError(
+          f"Could not find geckodriver {version} for platform {arch}")
+    logging.info("GECKODRIVER downloading %s: %s", version, url)
+    return url, archive_type
+
+  def _get_driver_version(self) -> Tuple[int, int, int]:
+    version = self.browser.major_version
+    # See https://firefox-source-docs.mozilla.org/testing/geckodriver/Support.html
+    if version < 52:
+      raise ValueError(f"Firefox {version} is too old for geckodriver.")
+    if version < 53:
+      return (0, 18, 0)
+    if version < 57:
+      return (0, 20, 1)
+    if version < 60:
+      return (0, 25, 0)
+    if version < 78:
+      return (0, 30, 0)
+    if version < 91:
+      return (0, 31, 0)
+    return (9999, 9999, 9999)
+
+  def _load_releases(self) -> Dict[Tuple[int, ...], Dict]:
+    with helper.urlopen(self.RELEASES_URL) as response:
+      releases = json.loads(response.read().decode("utf-8"))
+    assert isinstance(releases, list)
+    versions = {}
+    for release in releases:
+      # "v0.10.2" => "0.10.2"
+      version = release["tag_name"][1:]
+      # "0.10.2" => (0, 10, 2)
+      version = tuple(int(i) for i in version.split("."))
+      assert version not in versions
+      versions[version] = release
+    return dict(sorted(versions.items(), reverse=True))
+
+  def _arch_identifier(self) -> str:
+    if self.platform.is_linux:
+      arch = "linux"
+    elif self.platform.is_macos:
+      arch = "macos"
+    elif self.platform.is_win:
+      arch = "win"
+    else:
+      raise ValueError(f"Unsupported geckodriver platform {self.platform}")
+    if not self.platform.is_macos:
+      if self.platform.is_x64:
+        arch += "64"
+      elif self.platform.is_ia32:
+        arch += "32"
+    if self.platform.is_arm64:
+      arch += "-aarch64"
+    return arch
diff --git a/crossbench/browsers/safari/__init__.py b/crossbench/browsers/safari/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/browsers/safari/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/browsers/safari/applescript.py b/crossbench/browsers/safari/applescript.py
new file mode 100644
index 0000000..9697657
--- /dev/null
+++ b/crossbench/browsers/safari/applescript.py
@@ -0,0 +1,54 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.browsers.applescript import AppleScriptBrowser
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.safari.safari import Safari
+
+
+class SafariAppleScript(Safari, AppleScriptBrowser):
+  APPLE_SCRIPT_ALLOW_JS_MENU: str = (
+      "Develop > Allow JavaScript from Apple Events")
+  APPLE_SCRIPT_JS_COMMAND: str = (
+      "tell current tab of front window to do javascript %(js_script)s")
+  APPLE_SCRIPT_SET_URL: str = (
+      "set URL of the current tab of front window to %(url)s")
+
+  def _setup_window(self) -> None:
+    self._exec_apple_script(f"""
+      tell application "System Events"
+          click menu item "New Private Window" of menu "File" of menu bar 1 of process "{self.bundle_name}"
+      end tell
+      set URL of current tab of front window to ""
+    """)
+    self.platform.sleep(0.5)
+    if self.viewport.is_fullscreen:
+      self._exec_apple_script("""
+        tell application "System Events"
+          keystroke "f" using {command down, control down}
+        end tell""")
+    elif self.viewport.is_maximized:
+      self._exec_apple_script("""
+        tell application "System Events"
+          keystroke "m"
+        end tell""")
+    else:
+      bounds = (f"{self.viewport.x},{self.viewport.y},"
+                f"{self.viewport.width},{self.viewport.height}")
+      self._exec_apple_script("set the bounds of the first window to {%s}" %
+                              bounds)
+
+  def quit(self) -> None:
+    super().quit()
+    # Safari doesn't react to "quit" when using the full app path.
+    self.platform.exec_apple_script(f"""
+        tell application "{self.bundle_name}"
+          quit
+        end tell""")
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.SAFARI | BrowserAttributes.APPLESCRIPT
diff --git a/crossbench/browsers/safari/safari.py b/crossbench/browsers/safari/safari.py
new file mode 100644
index 0000000..906becd
--- /dev/null
+++ b/crossbench/browsers/safari/safari.py
@@ -0,0 +1,94 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+from typing import TYPE_CHECKING, Optional
+
+from crossbench import compat
+from crossbench import path as pth
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.browser import Browser
+
+if TYPE_CHECKING:
+  from crossbench import plt
+  from crossbench.browsers.settings import Settings
+
+
+SAFARIDRIVER_PATH = pth.AnyPosixPath("/usr/bin/safaridriver")
+
+
+def find_safaridriver(bin_path: pth.AnyPath,
+                      platform: plt.Platform) -> pth.AnyPath:
+  assert platform.is_file(bin_path), f"Invalid binary path: {bin_path}"
+  driver_path = bin_path.parent / "safaridriver"
+  if platform.exists(driver_path):
+    return driver_path
+  # The system-default Safari version doesn't come with the driver
+  assert compat.is_relative_to(bin_path, Safari.default_path(platform)), (
+      f"Expected default Safari.app binary but got {bin_path}")
+  return SAFARIDRIVER_PATH
+
+
+class Safari(Browser):
+
+  @classmethod
+  def default_path(cls, platform: plt.Platform) -> pth.AnyPath:
+    return platform.path("/Applications/Safari.app")
+
+  @classmethod
+  def technology_preview_path(cls, platform: plt.Platform) -> pth.AnyPath:
+    return platform.path("/Applications/Safari Technology Preview.app")
+
+  def __init__(self,
+               label: str,
+               path: pth.AnyPath,
+               settings: Optional[Settings] = None):
+    super().__init__(label, path, settings=settings)
+    assert self.platform.is_macos, "Safari only works on MacOS"
+    self.bundle_name: str = ""
+
+  def _setup_path(self, path: Optional[pth.AnyPath] = None) -> None:
+    super()._setup_path(path)
+    assert self.path
+    self.bundle_name = self.path.stem.replace(" ", "")
+
+  def _setup_cache_dir(self, settings: Settings) -> None:
+    assert settings.cache_dir is None, (
+        "Cannot set custom cache dir for Safari")
+    assert self.bundle_name, "Missing bundle_name"
+    self.cache_dir = self.platform.home() / (
+        f"Library/Containers/com.apple.{self.bundle_name}/Data/Library/Caches")
+
+  @property
+  def type_name(self) -> str:
+    return "safari"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.SAFARI
+
+  def clear_cache(self) -> None:
+    self._clear_cache()
+
+  def _clear_cache(self) -> None:
+    logging.info("CLEAR CACHE: %s", self)
+    self.platform.exec_apple_script(f"""
+      tell application "{self.app_path}" to activate
+      tell application "System Events"
+          keystroke "e" using {{command down, option down}}
+      end tell""")
+
+  def _extract_version(self) -> str:
+    # Use the shipped safaridriver to get the more detailed version
+    # TODO: support remote platform
+    driver_version = self.platform.app_version(
+        find_safaridriver(self.path, self.platform))
+    # Input: "Included with Safari 16.6 (18615.3.6.11.1)"
+    # Output: " (18615.3.6.11.1)"
+    driver_version = " (" + driver_version.split(" (", maxsplit=1)[1]
+    assert self.path
+    app_path = self.path.parents[2]
+    return self.platform.app_version(app_path) + driver_version
diff --git a/crossbench/browsers/safari/version.py b/crossbench/browsers/safari/version.py
new file mode 100644
index 0000000..776ac9e
--- /dev/null
+++ b/crossbench/browsers/safari/version.py
@@ -0,0 +1,77 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import Final, Tuple
+
+from crossbench.browsers.version import BrowserVersion, BrowserVersionChannel
+
+
+class SafariVersion(BrowserVersion):
+  _MIN_PARTS_LEN: Final[int] = 4
+  _VERSION_RE = re.compile(
+      r"(?P<major_minor>\d+\.\d+)"
+      r"[^(]+ "
+      r"\((?P<version>(Release (?P<release>\d+), )?(?P<parts>([\d.]+)+))\)"
+      r".*", re.I)
+
+  @classmethod
+  def _parse(
+      cls,
+      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
+    matches = cls._VERSION_RE.fullmatch(full_version.strip())
+    if not matches:
+      raise cls.parse_error("Could not extract version number", full_version)
+    version_str = matches["version"]
+    parts_str = matches["parts"]
+    major_minor_str = matches["major_minor"]
+    assert version_str and parts_str and major_minor_str
+    channel = cls._parse_channel(full_version)
+    major, minor = tuple(map(int, major_minor_str.split(".")))
+    release = 0
+    if release_str := matches["release"]:
+      release = int(release_str)
+    try:
+      parts = tuple(map(int, parts_str.split(".")))
+    except ValueError as e:
+      raise cls.parse_error("Could not parse version number parts.",
+                            full_version) from e
+    if len(parts) < cls._MIN_PARTS_LEN:
+      raise cls.parse_error("Invalid number of version number parts",
+                            full_version)
+    parts = (major, minor, release) + parts
+    return parts, channel, f"{major_minor_str} ({version_str})"
+
+  @classmethod
+  def _parse_channel(cls, full_version: str) -> BrowserVersionChannel:
+    if "Safari Technology Preview" in full_version:
+      return BrowserVersionChannel.BETA
+    if " any" in full_version.lower():
+      return BrowserVersionChannel.ANY
+    return BrowserVersionChannel.STABLE
+
+  @property
+  def has_complete_parts(self) -> bool:
+    return len(self.parts) >= self._MIN_PARTS_LEN
+
+  @property
+  def is_tech_preview(self) -> bool:
+    return self.channel == BrowserVersionChannel.BETA
+
+  @property
+  def release(self) -> int:
+    return self._parts[2]
+
+  def _channel_name(self, channel: BrowserVersionChannel) -> str:
+    if channel == BrowserVersionChannel.STABLE:
+      return "stable"
+    if channel == BrowserVersionChannel.BETA:
+      return "technology preview"
+    raise ValueError(f"Unsupported channel: {channel}")
+
+  @property
+  def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
+    return (self.comparable_parts(self._MIN_PARTS_LEN), self._channel)
diff --git a/crossbench/browsers/safari/webdriver.py b/crossbench/browsers/safari/webdriver.py
new file mode 100644
index 0000000..0e8d312
--- /dev/null
+++ b/crossbench/browsers/safari/webdriver.py
@@ -0,0 +1,198 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+import os
+from typing import TYPE_CHECKING, Any, Dict, Optional, Set, Type
+
+from selenium import webdriver
+from selenium.webdriver.safari.options import Options as SafariOptions
+from selenium.webdriver.safari.service import Service as SafariService
+
+from crossbench import exception, helper
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.safari.safari import Safari, find_safaridriver
+from crossbench.browsers.webdriver import DriverException, WebDriverBrowser
+
+if TYPE_CHECKING:
+  from crossbench.browsers.settings import Settings
+  from crossbench.path import AnyPath
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class SafariWebDriver(WebDriverBrowser, Safari):
+
+  MAX_STARTUP_TIMEOUT = dt.timedelta(seconds=10)
+
+  def __init__(self,
+               label: str,
+               path: AnyPath,
+               settings: Optional[Settings] = None):
+    super().__init__(label, path, settings)
+    assert self.platform.is_macos
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.SAFARI | BrowserAttributes.WEBDRIVER
+
+  def clear_cache(self) -> None:
+    # skip the default caching, and only do it after launching the browser
+    # via selenium.
+    pass
+
+  def _find_driver(self) -> AnyPath:
+    # TODO: support remote platform
+    assert self.platform.is_local, "Remote platform is not supported yet"
+    return self.host_platform.local_path(
+        find_safaridriver(self.path, self.platform))
+
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: AnyPath) -> webdriver.Remote:
+    return self._start_safari_driver(session, driver_path)
+
+  def _start_safari_driver(self, session: BrowserSessionRunGroup,
+                           driver_path: AnyPath) -> webdriver.Safari:
+    assert not self._is_running
+    logging.info("STARTING BROWSER: browser: %s driver: %s", self.path,
+                 driver_path)
+
+    options: SafariOptions = self._get_driver_options(session)
+    session.setup_selenium_options(options)
+    self._force_clear_cache(session)
+
+    service = SafariService(executable_path=os.fspath(driver_path))
+    driver_kwargs = {"service": service, "options": options}
+
+    if webdriver.__version__ == "4.1.0":
+      # Manually inject desired options for older selenium versions
+      # (currently fixed version from vpython3).
+      self._legacy_settings(options, driver_kwargs)
+
+    with helper.Spinner():
+      driver = self._start_driver_with_retries(driver_kwargs)
+
+    assert driver.session_id, "Could not start webdriver"
+    logs: AnyPath = (
+        self.platform.home() / "Library/Logs/com.apple.WebDriver" /
+        driver.session_id)
+    all_logs = list(self.platform.glob(logs, "safaridriver*"))
+    if all_logs:
+      self.log_file = all_logs[0]
+      assert self.platform.is_file(self.log_file)
+    return driver
+
+  # TODO(cbruni): implement iOS platform
+  def _start_driver_with_retries(
+      self, driver_kwargs: Dict[str, Any]) -> webdriver.Safari:
+    # safaridriver for iOS / technology preview seems to be brittle.
+    # Let's give it several chances to start up.
+    seen_exceptions: Set[Type[Exception]] = set()
+    retries = 0
+    for _ in helper.WaitRange(
+        min=2, timeout=self.MAX_STARTUP_TIMEOUT).wait_with_backoff():
+      try:
+        return webdriver.Safari(**driver_kwargs)
+      except Exception as e:  # pylint: disable=broad-except
+        retries += 1
+        exception_type = type(e)
+        logging.warning("SafariWebDriver: startup failed (%s), retrying...",
+                        exception_type)
+        logging.debug("SafariWebDriver: startup error %s", e)
+        # After 2 retries we don't accept the same error twice.
+        if retries >= 2 and exception_type in seen_exceptions:
+          raise DriverException("Could not start SafariWebDriver") from e
+        seen_exceptions.add(type(e))
+    raise DriverException("Could not start SafariWebDriver")
+
+  def _legacy_settings(self, options, driver_kwargs) -> None:
+    logging.debug("SafariDriver: using legacy capabilities")
+    options.binary_location = str(self.path)
+    driver_kwargs["desired_capabilities"] = options.to_capabilities()
+
+  def _force_clear_cache(self, session: BrowserSessionRunGroup) -> None:
+    del session
+    with exception.annotate("Clearing Browser Cache"):
+      self._clear_cache()
+      self.platform.exec_apple_script(f"""
+        tell application "{self.app_path}" to quit """)
+
+  def _get_driver_options(self,
+                          session: BrowserSessionRunGroup) -> SafariOptions:
+    options = SafariOptions()
+    # Don't wait for document-ready.
+    options.set_capability("pageLoadStrategy", "eager")
+
+    args = self._get_browser_flags_for_session(session)
+    for arg in args:
+      options.add_argument(arg)
+
+    if self._settings.driver_logging:
+      options.set_capability("safari:diagnose", "true")
+    if "Technology Preview" in self.app_name:
+      options.set_capability("browserName", "Safari Technology Preview")
+      options.use_technology_preview = True
+    return options
+
+  def _validate_driver_version(self) -> None:
+    # The bundled driver is always ok
+    assert self._driver_path
+    for parent in self._driver_path.parents:
+      if parent == self.path.parent:
+        return
+    version = self.platform.sh_stdout(self._driver_path, "--version")
+    assert str(self.major_version) in version, (
+        f"safaridriver={self._driver_path} version='{version}' "
+        f" doesn't match safari version={self.major_version}")
+
+  def _setup_window(self) -> None:
+    super()._setup_window()
+    self.platform.exec_apple_script(f"""
+        tell application "{self.app_name}"
+          activate
+        end tell""")
+
+  def quit(self) -> None:
+    super().quit()
+    # Safari needs some additional push to quit properly
+    self.platform.exec_apple_script(f"""
+        tell application "{self.app_name}"
+          quit
+        end tell""")
+
+
+class SafariWebdriverIOS(SafariWebDriver):
+  MAX_STARTUP_TIMEOUT = dt.timedelta(seconds=15)
+
+  def _get_driver_options(self,
+                          session: BrowserSessionRunGroup) -> SafariOptions:
+    options = super()._get_driver_options(session)
+    desired_cap = {
+        # "browserName": "Safari",
+        # "browserVersion": "17.0.3", # iOS version
+        # "safari:deviceType": "iPhone",
+        # "safari:deviceName": "XXX's iPhone",
+        # "safari:deviceUDID": "...",
+        "platformName": "iOS",
+        "safari:initialUrl": "about:blank",
+        "safari:openLinksInBackground": True,
+        "safari:allowPopups": True,
+    }
+    for key, value in desired_cap.items():
+      options.set_capability(key, value)
+    return options
+
+  def _setup_window(self) -> None:
+    pass
+
+  def _force_clear_cache(self, session: BrowserSessionRunGroup) -> None:
+    pass
+
+  def quit(self) -> None:
+    self._private_driver.close()
+    self.platform.sleep(1.0)
+    self._private_driver.quit()
+    self.force_quit()
diff --git a/crossbench/browsers/settings.py b/crossbench/browsers/settings.py
new file mode 100644
index 0000000..09cca3c
--- /dev/null
+++ b/crossbench/browsers/settings.py
@@ -0,0 +1,124 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Optional
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.splash_screen import SplashScreen
+from crossbench.browsers.viewport import Viewport
+from crossbench.flags.base import Flags, FlagsData
+from crossbench.flags.chrome import ChromeFlags
+from crossbench.network.live import LiveNetwork
+
+if TYPE_CHECKING:
+  from crossbench.cli.config.secrets import Secret, SecretsDict, SecretType
+  from crossbench.network.base import Network
+
+
+class Settings:
+  """Container object for browser agnostic settings."""
+
+  def __init__(self,
+               flags: Optional[FlagsData] = None,
+               js_flags: Optional[FlagsData] = None,
+               cache_dir: Optional[pth.AnyPath] = None,
+               network: Optional[Network] = None,
+               driver_path: Optional[pth.AnyPath] = None,
+               viewport: Optional[Viewport] = None,
+               splash_screen: Optional[SplashScreen] = None,
+               platform: Optional[plt.Platform] = None,
+               secrets: Optional[SecretsDict] = None,
+               driver_logging: bool = False,
+               wipe_system_user_data: bool = False,
+               http_request_timeout: dt.timedelta = dt.timedelta()):
+    self._flags = self._convert_flags(flags, "flags")
+    self._js_flags = self._extract_js_flags(self._flags, js_flags)
+    self._cache_dir = cache_dir
+    self._platform = platform or plt.PLATFORM
+    self._driver_path = driver_path
+    self._network: Network = network or LiveNetwork()
+    self._viewport: Viewport = viewport or Viewport.DEFAULT
+    self._splash_screen: SplashScreen = splash_screen or SplashScreen.DEFAULT
+    self._secrets: SecretsDict = secrets or {}
+    self._driver_logging = driver_logging
+    self._wipe_system_user_data = wipe_system_user_data
+    self._http_request_timeout = http_request_timeout
+
+  def _extract_js_flags(self, flags: Flags,
+                        js_flags: Optional[FlagsData]) -> Flags:
+    if isinstance(flags, ChromeFlags):
+      chrome_js_flags = flags.js_flags
+      if not js_flags:
+        return chrome_js_flags
+      if chrome_js_flags:
+        raise ValueError(
+            f"Ambiguous js-flags: flags.js_flags={repr(chrome_js_flags)}, "
+            f"js_flags={repr(js_flags)}")
+    return self._convert_flags(js_flags, "--js-flags")
+
+  def _convert_flags(self, flags: Optional[FlagsData], label: str) -> Flags:
+    if isinstance(flags, str):
+      raise ValueError(f"{label} should be a list, but got: {repr(flags)}")
+    if not flags:
+      return Flags()
+    if isinstance(flags, Flags):
+      return flags
+    return Flags(flags)
+
+  @property
+  def driver_logging(self) -> bool:
+    return self._driver_logging
+
+  @property
+  def flags(self) -> Flags:
+    return self._flags
+
+  @property
+  def js_flags(self) -> Flags:
+    return self._js_flags
+
+  @property
+  def cache_dir(self) -> Optional[pth.AnyPath]:
+    return self._cache_dir
+
+  @property
+  def driver_path(self) -> Optional[pth.AnyPath]:
+    return self._driver_path
+
+  @property
+  def platform(self) -> plt.Platform:
+    return self._platform
+
+  @property
+  def network(self) -> Network:
+    return self._network
+
+  @property
+  def secrets(self) -> SecretsDict:
+    return self._secrets
+
+  @property
+  def splash_screen(self) -> SplashScreen:
+    return self._splash_screen
+
+  @property
+  def wipe_system_user_data(self) -> bool:
+    return self._wipe_system_user_data
+
+  @property
+  def http_request_timeout(self) -> dt.timedelta:
+    return self._http_request_timeout
+
+  @property
+  def viewport(self) -> Viewport:
+    return self._viewport
+
+  @viewport.setter
+  def viewport(self, value: Viewport) -> None:
+    assert self._viewport.is_default
+    self._viewport = value
diff --git a/crossbench/browsers/splash_screen.py b/crossbench/browsers/splash_screen.py
new file mode 100644
index 0000000..c96c64e
--- /dev/null
+++ b/crossbench/browsers/splash_screen.py
@@ -0,0 +1,143 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import html
+import urllib.parse
+from argparse import ArgumentTypeError
+from typing import TYPE_CHECKING, Any, Dict
+
+from crossbench import path as pth
+
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+
+
+class SplashScreen:
+  NONE: SplashScreen
+  MINIMAL: SplashScreen
+  DETAILED: SplashScreen
+  DEFAULT: SplashScreen
+
+  @classmethod
+  def parse(cls, value: str) -> SplashScreen:
+    if not value or value == "default":
+      return cls.DEFAULT
+    if value in ("none", "skip"):
+      return cls.NONE
+    if value == "minimal":
+      return cls.MINIMAL
+    if value == "detailed":
+      return cls.DETAILED
+    if value.startswith("http:") or value.startswith("https:"):
+      return URLSplashScreen(value)
+    maybe_path = pth.LocalPath(value)
+    if maybe_path.exists():
+      return URLSplashScreen(maybe_path.absolute().as_uri())
+    raise ArgumentTypeError(f"Unknown splashscreen: {value}")
+
+  def run(self, run: Run) -> None:
+    pass
+
+
+_BLANK_PAGE_HTML = "<html></html>"
+_BLANK_PAGE_DATA_URL = (
+    f"data:text/html;charset=utf-8,{urllib.parse.quote(_BLANK_PAGE_HTML)}")
+
+
+class BaseURLSplashScreen(SplashScreen, metaclass=abc.ABCMeta):
+
+  def __init__(self, timeout: float = 2) -> None:
+    super().__init__()
+    self._timeout = timeout
+
+  def run(self, run: Run) -> None:
+    with run.actions("SplashScreen") as action:
+      action.show_url(self.get_url(run))
+      action.wait(self._timeout)
+      action.show_url(_BLANK_PAGE_DATA_URL)
+
+  @abc.abstractmethod
+  def get_url(self, run: Run) -> str:
+    pass
+
+
+class DetailedSplashScreen(BaseURLSplashScreen):
+
+  def get_url(self, run: Run) -> str:
+    browser = run.browser
+    title = html.escape(browser.app_name.title())
+    version = html.escape(browser.version)
+    run_type = "Run"
+    bg_color = "#000"
+    if run.is_warmup:
+      title = f"Warmup: {title}"
+      run_type = "Warmup Run"
+      bg_color = "#444"
+    page = "".join((
+        "<html><head>"
+        f"<title>{run_type} Details</title>",
+        "<style>",
+        "html{"
+        "font-family:sans-serif;",
+        f"background-color:{bg_color};",
+        "color:#fff",
+        "}",
+        "dl{display:grid;grid-template-columns:max-content auto}",
+        "dt{grid-column-start:1}",
+        "dd{grid-column-start:2;font-family:monospace}",
+        "</style>",
+        "</head><body>",
+        f"<h1>{title} {version}</h1>",
+        self._render_browser_details(run),
+        self._render_run_details(run),
+        "</body></html>",
+    ))
+    data_url = f"data:text/html;charset=utf-8,{urllib.parse.quote(page)}"
+    return data_url
+
+  def _render_properties(self, title: str, properties: Dict[str, Any]) -> str:
+    section = f"<h2>{html.escape(title)}</h2><dl>"
+    for property_name, value in properties.items():
+      section += f"<dt>{html.escape(property_name)}</dt>"
+      section += f"<dd>{html.escape(str(value))}</dd>"
+    section += "</dl>"
+    return section
+
+  def _render_browser_details(self, run: Run) -> str:
+    browser = run.browser
+    properties = {"User Agent": browser.user_agent(), **browser.details_json()}
+    return self._render_properties("Browser Details", properties)
+
+  def _render_run_details(self, run: Run) -> str:
+    return self._render_properties("Run Details", run.details_json())
+
+
+class MinimalSplashScreen(DetailedSplashScreen):
+
+  def _render_browser_details(self, run: Run) -> str:
+    properties = {"User Agent": run.browser.user_agent()}
+    return self._render_properties("Browser Details", properties)
+
+
+class URLSplashScreen(BaseURLSplashScreen):
+
+  def __init__(self, url: str, timeout: float = 2) -> None:
+    super().__init__(timeout)
+    self._url = url
+
+  def get_url(self, run: Run) -> str:
+    return self._url
+
+  @property
+  def url(self) -> str:
+    return self._url
+
+
+SplashScreen.NONE = SplashScreen()
+SplashScreen.MINIMAL = MinimalSplashScreen()
+SplashScreen.DETAILED = DetailedSplashScreen()
+SplashScreen.DEFAULT = SplashScreen.DETAILED
diff --git a/crossbench/browsers/version.py b/crossbench/browsers/version.py
new file mode 100644
index 0000000..6a17d8c
--- /dev/null
+++ b/crossbench/browsers/version.py
@@ -0,0 +1,337 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import dataclasses
+import enum
+import functools
+import re
+from typing import Any, Final, Iterable, Optional, Tuple, Type, TypeVar
+
+
+@dataclasses.dataclass
+class _BrowserVersionChannelMixin:
+  label: str
+  index: int
+
+
+@functools.total_ordering
+class BrowserVersionChannel(_BrowserVersionChannelMixin, enum.Enum):
+  # Explicit channel enums:
+  LTS = ("lts", 0)
+  STABLE = ("stable", 1)
+  BETA = ("beta", 2)
+  ALPHA = ("alpha", 3)
+  PRE_ALPHA = ("pre-alpha", 4)
+  # Use as sentinel if the channel can be ignored:
+  ANY = ("any", 5)
+
+  def __str__(self) -> str:
+    return self.label
+
+  def __lt__(self, other: Any) -> bool:
+    if not isinstance(other, BrowserVersionChannel):
+      raise TypeError("BrowserVersionChannel can not be compared to {other}")
+    return self.index < other.index
+
+  def __hash__(self) -> int:
+    return hash(self.name)
+
+  def matches(self, other: BrowserVersionChannel) -> bool:
+    if BrowserVersionChannel.ANY in (self, other):
+      return True
+    return self == other
+
+
+class BrowserVersionParseError(ValueError):
+
+  def __init__(self, name: str, msg: str, version: str):
+    self._version = version
+    super().__init__(f"Invalid {name} {repr(version)}: {msg}")
+
+
+class PartialBrowserVersionError(ValueError):
+  pass
+
+
+class BrowserVersionNoChannelError(ValueError):
+  pass
+
+
+BrowserVersionT = TypeVar("BrowserVersionT", bound="BrowserVersion")
+
+_VERSION_DIGITS_ONLY_RE = re.compile(r"\d+(\.\d+)*")
+
+
+@functools.total_ordering
+class BrowserVersion(abc.ABC):
+
+  _MAX_PART_VALUE: Final[int] = 0xFFFF
+
+  _parts: Tuple[int, ...]
+  _channel: BrowserVersionChannel
+  _version_str: str
+
+  @classmethod
+  def parse_unique(cls: Type[BrowserVersionT], value: str) -> BrowserVersionT:
+    """Parse a unique version identifier for a browser.
+    Unlike the parse() method, this should only parse input values that can
+    be unambiguously associated with a specific BrowserVersion."""
+    if _VERSION_DIGITS_ONLY_RE.fullmatch(str(value)):
+      raise cls.parse_error(
+          "Ambiguous version, missing browser specific prefix or suffix", value)
+    return cls.parse(value)
+
+  @classmethod
+  def parse(cls: Type[BrowserVersionT],
+            value: str,
+            channel: Optional[BrowserVersionChannel] = None) -> BrowserVersionT:
+    (parts, parsed_channel, version_str) = cls._parse(value)
+    parts = cls._validate_parts(parts, value)
+    return cls(parts, channel or parsed_channel, version_str)
+
+  @classmethod
+  def _validate_parts(cls, parts: Iterable[int], value: str) -> Tuple[int, ...]:
+    if parts is None:
+      raise cls.parse_error("Invalid version format", value)
+    parts_tpl = tuple(parts)
+    for part in parts_tpl:
+      if part < 0:
+        raise cls.parse_error("Version parts must be positive", value)
+    return parts_tpl
+
+  @classmethod
+  def is_valid_unique(cls, value: str) -> bool:
+    try:
+      cls.parse_unique(value)
+      return True
+    except BrowserVersionParseError:
+      return False
+
+  @classmethod
+  @abc.abstractmethod
+  def _parse(
+      cls,
+      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
+    pass
+
+  @classmethod
+  def parse_error(cls, msg: str, version: str) -> BrowserVersionParseError:
+    return BrowserVersionParseError(cls.__name__, msg, version)
+
+  @classmethod
+  def any(cls: Type[BrowserVersionT],
+          parts: Iterable[int],
+          version_str: str = "") -> BrowserVersionT:
+    return cls(parts, BrowserVersionChannel.ANY, version_str)
+
+  @classmethod
+  def lts(cls: Type[BrowserVersionT],
+          parts: Iterable[int],
+          version_str: str = "") -> BrowserVersionT:
+    return cls(parts, BrowserVersionChannel.LTS, version_str)
+
+  @classmethod
+  def stable(cls: Type[BrowserVersionT],
+             parts: Iterable[int],
+             version_str: str = "") -> BrowserVersionT:
+    return cls(parts, BrowserVersionChannel.STABLE, version_str)
+
+  @classmethod
+  def beta(cls: Type[BrowserVersionT],
+           parts: Iterable[int],
+           version_str: str = "") -> BrowserVersionT:
+    return cls(parts, BrowserVersionChannel.BETA, version_str)
+
+  @classmethod
+  def alpha(cls: Type[BrowserVersionT],
+            parts: Iterable[int],
+            version_str: str = "") -> BrowserVersionT:
+    return cls(parts, BrowserVersionChannel.ALPHA, version_str)
+
+  @classmethod
+  def pre_alpha(cls: Type[BrowserVersionT],
+                parts: Iterable[int],
+                version_str: str = "") -> BrowserVersionT:
+    return cls(parts, BrowserVersionChannel.PRE_ALPHA, version_str)
+
+  def __init__(self,
+               parts: Iterable[int],
+               channel: BrowserVersionChannel = BrowserVersionChannel.STABLE,
+               version_str: str = "") -> None:
+    self._parts = self._validate_parts(parts, version_str or repr(parts))
+    self._channel = channel
+    self._version_str = version_str
+
+  @property
+  def parts(self) -> Tuple[int, ...]:
+    return self._parts
+
+  @property
+  def version_str(self) -> str:
+    return self._version_str
+
+  @property
+  def parts_str(self) -> str:
+    return ".".join(map(str, self._parts))
+
+  def comparable_parts(self, padded_len) -> Tuple[int, ...]:
+    if self.is_complete:
+      return self._parts
+    padding = (self._MAX_PART_VALUE,) * (padded_len - len(self._parts))
+    return self._parts + padding
+
+  @property
+  def is_complete(self) -> bool:
+    return self.has_complete_parts and self.has_channel
+
+  @property
+  @abc.abstractmethod
+  def has_complete_parts(self) -> bool:
+    pass
+
+  @property
+  def is_unknown(self) -> bool:
+    # Only True for UnknownBrowserVersion
+    return False
+
+  @property
+  def is_channel_version(self) -> bool:
+    return not self._parts and self.has_channel
+
+  @property
+  def major(self) -> int:
+    if not self._parts:
+      raise PartialBrowserVersionError()
+    return self._parts[0]
+
+  @property
+  def minor(self) -> int:
+    if len(self._parts) <= 1:
+      raise PartialBrowserVersionError()
+    return self._parts[1]
+
+  @property
+  def channel(self) -> BrowserVersionChannel:
+    if not self.has_channel:
+      raise BrowserVersionNoChannelError(
+          f"BrowserVersion {self} has no channel")
+    return self._channel
+
+  def matches_channel(self, channel: BrowserVersionChannel) -> bool:
+    return self._channel.matches(channel)
+
+  @property
+  def has_channel(self) -> bool:
+    return self._channel is not BrowserVersionChannel.ANY
+
+  @property
+  def is_lts(self) -> bool:
+    return self._channel == BrowserVersionChannel.LTS
+
+  @property
+  def is_stable(self) -> bool:
+    return self._channel == BrowserVersionChannel.STABLE
+
+  @property
+  def is_beta(self) -> bool:
+    return self._channel == BrowserVersionChannel.BETA
+
+  @property
+  def is_alpha(self) -> bool:
+    return self._channel == BrowserVersionChannel.ALPHA
+
+  @property
+  def is_pre_alpha(self) -> bool:
+    return self._channel == BrowserVersionChannel.PRE_ALPHA
+
+  @property
+  def channel_name(self) -> str:
+    if not self.has_channel:
+      return "any"
+    return self._channel_name(self._channel)
+
+  @abc.abstractmethod
+  def _channel_name(self, channel: BrowserVersionChannel) -> str:
+    pass
+
+  @property
+  def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
+    return (self._parts, self._channel)
+
+  def __str__(self) -> str:
+    if not self._version_str:
+      if not self._parts:
+        return self.channel_name
+      return f"{self.parts_str} {self.channel_name}"
+    return f"{self._version_str} {self.channel_name}"
+
+  def __repr__(self) -> str:
+    return (
+        f"{self.__class__.__name__}"
+        f"({self.parts_str}, {self.channel_name}, {repr(self._version_str)})")
+
+  def __eq__(self, other: Any) -> bool:
+    if not isinstance(other, type(self)):
+      return False
+    return self.key == other.key
+
+  def __le__(self, other: Any) -> bool:
+    if not isinstance(other, type(self)):
+      raise TypeError("Cannot compare versions from different browsers: "
+                      f"{self} vs. {other}.")
+    if self.is_channel_version and other.is_channel_version:
+      return self._channel <= other._channel
+    if self.is_channel_version:
+      raise ValueError(f"Cannot compare channel {self} against {other}")
+    if other.is_channel_version:
+      raise ValueError(f"Cannot compare {self} against channel {other}")
+    return self.key <= other.key
+
+  def contains(self, other: BrowserVersion) -> bool:
+    if not isinstance(other, type(self)):
+      raise TypeError("Cannot compare versions from different browsers: "
+                      f"{self} vs. {other}.")
+    if self == other:
+      return True
+    if self.has_channel and other.has_channel:
+      if self.channel != other.channel:
+        return False
+    # A less precise version (e.g. channel or partial version) can never be
+    # part of a more complete version.
+    other_parts = other.parts
+    common_part_len = min(len(self._parts), len(other_parts))
+    if common_part_len < len(self._parts):
+      return False
+    return self._parts[:common_part_len] == other_parts[:common_part_len]
+
+
+class UnknownBrowserVersion(BrowserVersion):
+  """Sentinel helper object for initializing version variables before
+  knowing which exact browser/version is used."""
+
+  def __init__(self,
+               parts: Tuple[int, ...] = (),
+               channel: BrowserVersionChannel = BrowserVersionChannel.ANY,
+               version_str: str = "unknown") -> None:
+    super().__init__(parts, BrowserVersionChannel.ANY, version_str)
+
+  @classmethod
+  def _parse(
+      cls,
+      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
+    raise RuntimeError("UnknownBrowserVersion does not support parsing")
+
+  def _channel_name(self, channel: BrowserVersionChannel) -> str:
+    return "unknown"
+
+  @property
+  def has_complete_parts(self) -> bool:
+    return False
+
+  @property
+  def is_unknown(self) -> bool:
+    return True
diff --git a/crossbench/browsers/viewport.py b/crossbench/browsers/viewport.py
new file mode 100644
index 0000000..d846a12
--- /dev/null
+++ b/crossbench/browsers/viewport.py
@@ -0,0 +1,181 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+from argparse import ArgumentTypeError
+from typing import Any, Tuple
+
+from crossbench import compat
+
+
+@enum.unique
+class ViewportMode(compat.StrEnum):
+  SIZE = "size"
+  MAXIMIZED = "maximized"
+  FULLSCREEN = "fullscreen"
+  HEADLESS = "headless"
+
+
+class Viewport:
+  DEFAULT: Viewport
+  MAXIMIZED: Viewport
+  FULLSCREEN: Viewport
+  HEADLESS: Viewport
+
+  @classmethod
+  def parse_sized(cls, value: Any) -> Viewport:
+    if isinstance(value, Viewport):
+      viewport = value
+    elif isinstance(value, str):
+      viewport = cls.parse(value)
+    else:
+      raise ArgumentTypeError(f"Expected str, but got '{type(value)}': {value}")
+    if not viewport.has_size:
+      raise ArgumentTypeError("Expected viewport with explicit size, "
+                              f"but got {viewport}")
+    return viewport
+
+  @classmethod
+  def parse(cls, value: str) -> Viewport:
+    if not value:
+      return cls.DEFAULT
+    if value in ("m", "max", "maximised", ViewportMode.MAXIMIZED):
+      return cls.MAXIMIZED
+    if value in ("f", "full", ViewportMode.FULLSCREEN):
+      return cls.FULLSCREEN
+    if value == ViewportMode.HEADLESS:
+      return cls.HEADLESS
+    size, _, position = value.partition(",")
+    width, _, height = size.partition("x")
+    if not height:
+      raise ArgumentTypeError(f"Missing viewport height in input: {value}")
+    x = str(cls.DEFAULT.x)
+    y = str(cls.DEFAULT.y)
+    if position:
+      x, _, y = position.partition("x")
+      if not y:
+        raise ArgumentTypeError(
+            f"Missing viewport y position in input: {value}")
+    return Viewport(int(width), int(height), int(x), int(y))
+
+  def __init__(self,
+               width: int = 1500,
+               height: int = 1000,
+               x: int = 10,
+               y: int = 50,
+               mode: ViewportMode = ViewportMode.SIZE):
+    self._width = width
+    self._height = height
+    self._x = x
+    self._y = y
+    self._mode = mode
+    self._validate()
+
+  def _validate(self) -> None:
+    if self._mode == ViewportMode.SIZE:
+      if self._width <= 0:
+        raise ArgumentTypeError(f"width must be > 0, but got {self._width}")
+      if self._height <= 0:
+        raise ArgumentTypeError(f"height must be > 0, but got {self._height}")
+      if self._x < 0:
+        raise ArgumentTypeError(f"x must be >= 0, but got {self._x}")
+      if self._y < 0:
+        raise ArgumentTypeError(f"y must be >= 0, but got {self._y}")
+    else:
+      if self._width != 0:
+        raise ArgumentTypeError(
+            "Non-zero width only allowed with ViewportMode.SIZE")
+      if self._height != 0:
+        raise ArgumentTypeError(
+            "Non-zero height only allowed with ViewportMode.SIZE")
+      if self._x != 0:
+        raise ArgumentTypeError(
+            "Non-zero x only allowed with ViewportMode.SIZE")
+      if self._y != 0:
+        raise ArgumentTypeError(
+            "Non-zero y only allowed with ViewportMode.SIZE")
+
+  @property
+  def is_default(self) -> bool:
+    return self is Viewport.DEFAULT
+
+  @property
+  def is_maximized(self) -> bool:
+    return self._mode == ViewportMode.MAXIMIZED
+
+  @property
+  def is_fullscreen(self) -> bool:
+    return self._mode == ViewportMode.FULLSCREEN
+
+  @property
+  def is_headless(self) -> bool:
+    return self._mode == ViewportMode.HEADLESS
+
+  @property
+  def has_size(self) -> bool:
+    return self._mode == ViewportMode.SIZE
+
+  @property
+  def position(self) -> Tuple[int, int]:
+    assert self.has_size, f"Viewport has no explicit size: {self._mode}"
+    return (self._x, self._y)
+
+  @property
+  def size(self) -> Tuple[int, int]:
+    assert self.has_size, f"Viewport has no explicit size: {self._mode}"
+    return (self._width, self._height)
+
+  @property
+  def width(self) -> int:
+    assert self.has_size, f"Viewport has no explicit size: {self._mode}"
+    return self._width
+
+  @property
+  def height(self) -> int:
+    assert self.has_size, f"Viewport has no explicit size: {self._mode}"
+    return self._height
+
+  @property
+  def x(self) -> int:
+    assert self.has_size, f"Viewport has no explicit size: {self._mode}"
+    return self._x
+
+  @property
+  def y(self) -> int:
+    assert self.has_size, f"Viewport has no explicit size: {self._mode}"
+    return self._y
+
+  @property
+  def mode(self) -> ViewportMode:
+    return self._mode
+
+  @property
+  def key(self) -> Tuple[Tuple, ...]:
+    return (
+        ("mode", str(self.mode)),
+        ("x", self._x),
+        ("y", self._y),
+        ("width", self._width),
+        ("height", self._height),
+    )
+
+  def __str__(self) -> str:
+    if self.has_size:
+      return f"Viewport({self.width}x{self.height},{self.x}x{self.y})"
+    return f"Viewport({self.mode})"
+
+  def __eq__(self, other) -> bool:
+    if not isinstance(other, Viewport):
+      return False
+    if self is other:
+      return True
+    return self.key == other.key
+
+
+Viewport.DEFAULT = Viewport()
+Viewport.MAXIMIZED = Viewport(0, 0, 0, 0, ViewportMode.MAXIMIZED)
+Viewport.FULLSCREEN = Viewport(0, 0, 0, 0, ViewportMode.FULLSCREEN)
+Viewport.HEADLESS = Viewport(0, 0, 0, 0, ViewportMode.HEADLESS)
diff --git a/crossbench/browsers/webdriver.py b/crossbench/browsers/webdriver.py
new file mode 100644
index 0000000..bc1d35a
--- /dev/null
+++ b/crossbench/browsers/webdriver.py
@@ -0,0 +1,329 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import atexit
+import logging
+import os
+import time
+import traceback
+from typing import TYPE_CHECKING, Any, List, Optional, Sequence, cast
+
+import selenium.common.exceptions
+import urllib3
+from selenium import webdriver
+from selenium.webdriver.remote.remote_connection import RemoteConnection
+
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.browser import Browser
+from crossbench.types import JsonDict
+
+if TYPE_CHECKING:
+  import datetime as dt
+
+  from selenium.webdriver.common.timeouts import Timeouts
+
+  from crossbench.browsers.settings import Settings
+  from crossbench.env import HostEnvironment
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class DriverException(RuntimeError):
+  """Wrapper for more readable error messages than the default
+  WebDriver exceptions."""
+
+  def __init__(self, msg: str, browser: Optional[Browser] = None) -> None:
+    self._browser = browser
+    self._msg = msg
+    super().__init__(msg)
+
+  def __str__(self) -> str:
+    browser_prefix = ""
+    if self._browser:
+      browser_prefix = f"browser={self._browser}: "
+    return f"{browser_prefix}{self._msg}"
+
+
+class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
+  _private_driver: webdriver.Remote
+  _driver_path: Optional[AnyPath]
+  _driver_pid: int
+  _pid: int
+  log_file: Optional[LocalPath]
+
+  def __init__(self,
+               label: str,
+               path: Optional[AnyPath] = None,
+               settings: Optional[Settings] = None):
+    super().__init__(label, path, settings)
+    self._driver_path = self._settings.driver_path
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.WEBDRIVER
+
+  @property
+  def driver_log_file(self) -> LocalPath:
+    log_file = self.log_file
+    assert log_file
+    return log_file.with_suffix(".driver.log")
+
+  def validate_binary(self) -> None:
+    super().validate_binary()
+    self._driver_path = self.platform.absolute(self._find_driver())
+    # TODO: support remote chromedriver as well
+    assert self.host_platform.exists(self._driver_path), (
+        f"Webdriver path '{self._driver_path}' does not exist")
+
+  @abc.abstractmethod
+  def _find_driver(self) -> AnyPath:
+    pass
+
+  @abc.abstractmethod
+  def _validate_driver_version(self) -> None:
+    pass
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    super().validate_env(env)
+    self._validate_driver_version()
+
+  def start(self, session: BrowserSessionRunGroup) -> None:
+    assert self._driver_path
+    if timeout := self.http_request_timeout:
+      logging.debug("Setting http request timeout to %s", timeout)
+      RemoteConnection.set_timeout(timeout.total_seconds())
+    try:
+      self._private_driver = self._start_driver(session, self._driver_path)
+    except selenium.common.exceptions.SessionNotCreatedException as e:
+      msg = e.msg or "Could not create Webdriver session."
+      raise DriverException(msg, self) from e
+    self._is_running = True
+    atexit.register(self.force_quit)
+    self._find_driver_pid()
+    self._set_driver_timeouts(session)
+    self._setup_window()
+
+  def _find_driver_pid(self) -> None:
+    service = getattr(self._private_driver, "service", None)
+    if not service:
+      return
+    self._driver_pid = service.process.pid
+    candidates: List[int] = []
+    for child in self.platform.process_children(self._driver_pid):
+      if str(child["exe"]) == str(self.path):
+        candidates.append(child["pid"])
+    if len(candidates) == 1:
+      self._pid = candidates[0]
+    else:
+      logging.debug(
+          "Could not find unique browser process for webdriver: %s, got %s",
+          self, candidates)
+
+  def _set_driver_timeouts(self, session: BrowserSessionRunGroup) -> None:
+    """Adjust the global webdriver timeouts if the runner has custom timeout
+    unit values.
+    If timing.has_no_timeout each value is set to SAFE_MAX_TIMEOUT_TIMEDELTA."""
+    timing = session.timing
+    if not timing.timeout_unit:
+      return
+    if timing.has_no_timeout:
+      logging.info("Disabling webdriver timeouts")
+    else:
+      factor = timing.timeout_unit.total_seconds()
+      if factor != 1.0:
+        logging.info("Increasing webdriver timeouts by %fx", factor)
+    timeouts: Timeouts = self._private_driver.timeouts
+    if implicit_wait := getattr(timeouts, "implicit_wait", None):
+      timeouts.implicit_wait = timing.timeout_timedelta(
+          implicit_wait).total_seconds()
+    if script := getattr(timeouts, "script", None):
+      timeouts.script = timing.timeout_timedelta(script).total_seconds()
+    if page_load := getattr(timeouts, "page_load", None):
+      timeouts.page_load = timing.timeout_timedelta(page_load).total_seconds()
+    self._private_driver.timeouts = timeouts
+
+  def _setup_window(self) -> None:
+    # Force main window to foreground.
+    self._private_driver.switch_to.window(
+        self._private_driver.current_window_handle)
+    if self.viewport.is_headless:
+      return
+    if self.viewport.is_fullscreen:
+      self._private_driver.fullscreen_window()
+    elif self.viewport.is_maximized:
+      self._private_driver.maximize_window()
+    else:
+      self._private_driver.set_window_position(self.viewport.x, self.viewport.y)
+      self._private_driver.set_window_size(self.viewport.width,
+                                           self.viewport.height)
+
+  @abc.abstractmethod
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: AnyPath) -> webdriver.Remote:
+    pass
+
+  def details_json(self) -> JsonDict:
+    details: JsonDict = super().details_json()
+    log = cast(JsonDict, details["log"])
+    if self.log_file:
+      log["driver"] = os.fspath(self.driver_log_file)
+    return details
+
+  def show_url(self, url: str, target: Optional[str] = None) -> None:
+    logging.debug("WebDriverBrowser.show_url(%s, %s)", url, target)
+    try:
+      if target in ("_self", None):
+        handles = self._private_driver.window_handles
+        assert handles, "Browser has no more opened windows."
+        self._private_driver.switch_to.window(handles[-1])
+      elif target == "_new_tab":
+        self._private_driver.switch_to.new_window("tab")
+      elif target == "_new_window":
+        self._private_driver.switch_to.new_window("window")
+      else:
+        raise RuntimeError(f"unexpected target {target}")
+      self._private_driver.get(url)
+    except selenium.common.exceptions.WebDriverException as e:
+      if msg := e.msg:
+        self._wrap_webdriver_exception(e, msg, url)
+      raise
+
+  def switch_to_new_tab(self) -> None:
+    self._private_driver.switch_to.new_window("tab")
+
+  def screenshot(self, path: LocalPath) -> None:
+    if not self._private_driver.get_screenshot_as_file(path.as_posix()):
+      raise DriverException(
+          f"Browser failed to get_screenshot_as_file to file '{path}'", self)
+
+  def _wrap_webdriver_exception(
+      self, e: selenium.common.exceptions.WebDriverException, msg: str,
+      url: str) -> None:
+    if "net::ERR_CONNECTION_REFUSED" in msg:
+      raise DriverException(
+          f"Browser failed to load URL={url}. The URL is likely unreachable.",
+          self) from e
+    if "net::ERR_INTERNET_DISCONNECTED" in msg:
+      raise DriverException(
+          f"Browser failed to load URL={url}. "
+          f"The device is not connected to the internet.", self) from e
+
+  def js(
+      self,
+      script: str,
+      timeout: Optional[dt.timedelta] = None,
+      arguments: Sequence[object] = ()
+  ) -> Any:
+    logging.debug("WebDriverBrowser.js() timeout=%s, script: %s", timeout,
+                  script)
+    assert self._is_running
+    try:
+      if timeout is not None:
+        assert timeout.total_seconds() > 0, (
+            f"timeout must be a positive number, got: {timeout}")
+        self._private_driver.set_script_timeout(timeout.total_seconds())
+      return self._private_driver.execute_script(script, *arguments)
+    except selenium.common.exceptions.WebDriverException as e:
+      # pylint: disable=raise-missing-from
+      raise ValueError(f"Could not execute JS: {e.msg}")
+
+  def close_all_tabs(self) -> None:
+    try:
+      all_handles = self._private_driver.window_handles
+      for handle in all_handles:
+        self._private_driver.switch_to.window(handle)
+        self._private_driver.close()
+    except (selenium.common.exceptions.InvalidSessionIdException,
+            urllib3.exceptions.MaxRetryError) as e:
+      logging.debug("%s: Got errors while closing all tabs: {%s}", self, e)
+
+  def quit(self) -> None:
+    assert self._is_running
+    self.close_all_tabs()
+    self.force_quit()
+
+  def force_quit(self) -> None:
+    if getattr(self, "_private_driver", None) is None or not self._is_running:
+      return
+    atexit.unregister(self.force_quit)
+    logging.debug("WebDriverBrowser.force_quit()")
+    try:
+      try:
+        # Close the current window.
+        self._private_driver.close()
+        time.sleep(0.1)
+      except selenium.common.exceptions.NoSuchWindowException:
+        # No window is good.
+        pass
+      except selenium.common.exceptions.InvalidSessionIdException:
+        # Closing the last tab will close the session as well.
+        return
+      try:
+        self._private_driver.quit()
+      except selenium.common.exceptions.InvalidSessionIdException:
+        return
+      # Sometimes a second quit is needed, ignore any warnings there
+      try:
+        self._private_driver.quit()
+      except Exception as e:  # pylint: disable=broad-except
+        logging.debug("Driver raised exception on quit: %s\n%s", e,
+                      traceback.format_exc())
+      return
+    except Exception as e:  # pylint: disable=broad-except
+      logging.debug("Could not quit browser: %s\n%s", e, traceback.format_exc())
+    finally:
+      self._is_running = False
+
+
+class RemoteWebDriver(WebDriverBrowser, Browser):
+  """Represent a remote WebDriver that has already been started"""
+
+  def __init__(self, label: str, driver: webdriver.Remote) -> None:
+    super().__init__(label=label, path=None)
+    self._private_driver = driver
+    self.version: str = driver.capabilities["browserVersion"]
+    self.major_version: int = int(self.version.split(".")[0])
+
+  @property
+  def type_name(self) -> str:
+    return "remote"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.WEBDRIVER | BrowserAttributes.REMOTE
+
+  def _validate_driver_version(self) -> None:
+    pass
+
+  def _extract_version(self) -> str:
+    raise NotImplementedError()
+
+  def _find_driver(self) -> LocalPath:
+    raise NotImplementedError()
+
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: AnyPath) -> webdriver.Remote:
+    raise NotImplementedError()
+
+  def setup_binary(self) -> None:
+    pass
+
+  def start(self, session: BrowserSessionRunGroup) -> None:
+    # Driver has already been started. We just need to mark it as running.
+    self._is_running = True
+    if self.viewport.is_fullscreen:
+      self._private_driver.fullscreen_window()
+    elif self.viewport.is_maximized:
+      self._private_driver.maximize_window()
+    else:
+      self._private_driver.set_window_position(self.viewport.x, self.viewport.y)
+      self._private_driver.set_window_size(self.viewport.width,
+                                           self.viewport.height)
+
+  def quit(self) -> None:
+    # External code that started the driver is responsible for shutting it down.
+    self._is_running = False
diff --git a/crossbench/cbb/__init__.py b/crossbench/cbb/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/cbb/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/cbb/cbb_adapter.py b/crossbench/cbb/cbb_adapter.py
new file mode 100644
index 0000000..83c6b93
--- /dev/null
+++ b/crossbench/cbb/cbb_adapter.py
@@ -0,0 +1,153 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+"""
+An adapter class for CBB to interact with the crossbench runner.
+The goal is to abstract out the crossbench runner interface details and
+provide an integration point for CBB.
+
+Any breaking changes in the function definitions here need to be coordinated
+with corresponding changes in CBB in google3
+"""
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, List, Optional, Type
+
+from selenium import webdriver
+
+import crossbench.benchmarks.all as benchmarks
+import crossbench.browsers.browser
+import crossbench.browsers.webdriver as cb_webdriver
+import crossbench.env
+import crossbench.runner.runner
+from crossbench import path as pth
+from crossbench.runner.run import Run
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import PressBenchmark
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+  from crossbench.stories.press_benchmark import PressBenchmarkStory
+  from crossbench.stories.story import Story
+
+press_benchmarks: List[Type[PressBenchmark]] = [
+    benchmarks.Speedometer20Benchmark,
+    benchmarks.Speedometer21Benchmark,
+    benchmarks.Speedometer30Benchmark,
+    benchmarks.MotionMark12Benchmark,
+    benchmarks.MotionMark13Benchmark,
+    benchmarks.JetStream20Benchmark,
+    benchmarks.JetStream21Benchmark,
+    benchmarks.JetStream22Benchmark,
+    benchmarks.JetStream30Benchmark,
+]
+
+press_benchmarks_dict = {cls.NAME: cls for cls in press_benchmarks}
+
+
+def get_pressbenchmark_cls(
+    benchmark_name: str) -> Optional[Type[PressBenchmark]]:
+  """Returns the class of the specified pressbenchmark.
+
+  Args:
+    benchmark_name: Name of the benchmark.
+
+  Returns:
+    An instance of the benchmark implementation
+  """
+  return press_benchmarks_dict.get(benchmark_name)
+
+
+def get_pressbenchmark_story_cls(
+    benchmark_name: str) -> Optional[Type[PressBenchmarkStory]]:
+  """Returns the class of the specified pressbenchmark story.
+
+  Args:
+    benchmark_name: Name of the benchmark.
+
+  Returns:
+    An instance of the benchmark default story
+  """
+
+  benchmark_cls = get_pressbenchmark_cls(benchmark_name)
+  if benchmark_cls is not None:
+    return benchmark_cls.DEFAULT_STORY_CLS
+
+  return None
+
+
+def create_remote_webdriver(driver: webdriver.Remote
+                           ) -> cb_webdriver.RemoteWebDriver:
+  """Creates a remote webdriver instance for the driver.
+
+  Args:
+    driver: Remote web driver instance.
+  """
+
+  browser = cb_webdriver.RemoteWebDriver("default", driver)
+  browser.version = driver.capabilities["browserVersion"]
+  return browser
+
+
+def get_probe_result_file(benchmark_name: str,
+                          browser: crossbench.browsers.browser.Browser,
+                          output_dir: pth.LocalPathLike,
+                          probe_name: Optional[str] = None) -> Optional[str]:
+  """Returns the path to the probe result file.
+
+  Args:
+    benchmark_name: Name of the benchmark.
+    browser: Browser instance.
+    output_dir: Path to the directory where the output of the benchmark
+                execution was written.
+    probe_name: Optional name of the probe for the result file. If not
+                specified, the first probe from the default benchmark story
+                will be used."""
+  output_dir_path = pth.LocalPath(output_dir)
+  if probe_name is None:
+    if benchmark_name not in press_benchmarks_dict:
+      return None
+    benchmark_cls = press_benchmarks_dict[benchmark_name]
+    probe_cls = benchmark_cls.PROBES[0]
+    probe_name = probe_cls.NAME
+
+  result_file: pth.LocalPath = (
+      output_dir_path / browser.unique_name / "stories" / f"{probe_name}.json")
+  return str(result_file)
+
+
+class CbbRunner(crossbench.runner.runner.Runner):
+
+  def create_run(self, browser_session: BrowserSessionRunGroup, story: Story,
+                 repetition: int, is_warmup: bool, temperature: str, index: int,
+                 name: str, timeout: dt.timedelta, throw: bool) -> Run:
+    return CbbRun(self, browser_session, story, repetition, is_warmup,
+                  temperature, index, name, timeout, throw)
+
+
+class CbbRun(Run):
+
+  def _create_session_dir(self) -> None:
+    # Don't create symlink loops and skip this step
+    pass
+
+
+def run_benchmark(output_folder: pth.LocalPathLike,
+                  browser_list: List[crossbench.browsers.browser.Browser],
+                  benchmark: PressBenchmark) -> None:
+  """Runs the benchmark using crossbench runner.
+
+  Args:
+    output_folder: Path to the directory where the output of the benchmark
+                  execution will be written.
+    browser_list: List of browsers to run the benchmark on.
+    benchmark: The Benchmark instance to run.
+  """
+  runner = CbbRunner(
+      out_dir=pth.LocalPath(output_folder),
+      browsers=browser_list,
+      benchmark=benchmark,
+      env_validation_mode=crossbench.env.ValidationMode.SKIP)
+
+  runner.run()
diff --git a/crossbench/cli/__init__.py b/crossbench/cli/__init__.py
new file mode 100644
index 0000000..67eefa2
--- /dev/null
+++ b/crossbench/cli/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/cli/btp.py b/crossbench/cli/btp.py
new file mode 100644
index 0000000..5d6e22c
--- /dev/null
+++ b/crossbench/cli/btp.py
@@ -0,0 +1,111 @@
+#!/usr/bin/env vpython3
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import logging
+from typing import Dict, Optional, Sequence
+
+from perfetto.batch_trace_processor.api import (BatchTraceProcessor,
+                                                BatchTraceProcessorConfig,
+                                                FailureHandling)
+from perfetto.trace_processor.api import TraceProcessorConfig
+from perfetto.trace_uri_resolver.resolver import TraceUriResolver
+
+from crossbench import path as pth
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.cli.parser import CrossBenchArgumentParser
+from crossbench.parse import PathParser
+from crossbench.probes.perfetto.trace_processor.trace_processor import (
+    _MODULES_DIR, _QUERIES_DIR, TraceProcessorProbe)
+
+ROOT_DIR = pth.LocalPath(__file__).parents[2]
+DEFAULT_RESULT_DIR = ROOT_DIR / "results" / "latest"
+DEFAULT_CONFIG_PATH = (
+    ROOT_DIR / "config" / "benchmark" / "loadline" / "probe_config.hjson")
+
+class MergedTraceUriResolver(TraceUriResolver):
+  def __init__(self, result_path: pth.LocalPath):
+
+    def metadata(path) -> Dict[str, str]:
+      parts = str(path).split("/")
+      return {
+          "cb_browser": parts[-7],
+          "cb_story": parts[-5],
+          "cb_run": parts[-4],
+          "cb_temperature": parts[-3],
+      }
+
+    listdir = list(result_path.glob("*/stories/**/merged_trace.zip"))
+
+    self._resolved = [
+        TraceUriResolver.Result(trace=str(path), metadata=metadata(path))
+        for path in listdir]
+
+  def resolve(self):
+    return self._resolved
+
+class BTPUtil:
+  def __init__(self):
+    self.parser = CrossBenchArgumentParser(
+      description=("Runs trace processor queries in a batch mode on existing "
+                   "benchmark results, without re-running the benchmark "
+                   "itself."),
+      formatter_class=argparse.ArgumentDefaultsHelpFormatter)
+    self.parser.add_argument(
+        "--result-dir",
+        type=PathParser.existing_path,
+        default=DEFAULT_RESULT_DIR,
+        help="Path to the benchmark result directory.")
+    self.parser.add_argument(
+        "--probe-config",
+        type=PathParser.existing_file_path,
+        default=DEFAULT_CONFIG_PATH,
+        help="Path to the trace_processor probe config.")
+    self.parser.add_argument(
+        "--output-dir",
+        type=pth.LocalPath,
+        default=ROOT_DIR,
+        help="Path to the directory where output files will be placed.")
+    self.parser.add_argument(
+        "--extra-query",
+        type=str,
+        default=[],
+        action="append",
+        help=("Name of the query to compute (the query must be present in the "
+              "trace_processor/queries/ dir). Repeat for multiple queries."))
+
+  def run(self, argv: Sequence[str]):
+    args = self.parser.parse_args(argv)
+
+    probe_config = ProbeListConfig.parse_path(args.probe_config)
+    tp: Optional[TraceProcessorProbe] = None
+    for probe in probe_config.probes:
+      if isinstance(probe, TraceProcessorProbe):
+        tp = probe
+    assert tp is not None
+
+    tp_config = TraceProcessorConfig(
+        bin_path=str(tp.trace_processor_bin),
+        extra_flags=["--add-sql-module", _MODULES_DIR])
+    btp_conf = BatchTraceProcessorConfig(
+      tp_config=tp_config,
+      load_failure_handling=FailureHandling.INCREMENT_STAT,
+      execute_failure_handling=FailureHandling.INCREMENT_STAT)
+
+    with BatchTraceProcessor(
+      traces=MergedTraceUriResolver(args.result_dir), config=btp_conf) as btp:
+      queries = list(tp.queries) + args.extra_query
+      for query in queries:
+        query_path = _QUERIES_DIR / f"{query}.sql"
+        csv_file = args.output_dir / f"{pth.safe_filename(query)}.csv"
+        btp.query_and_flatten(query_path.read_text()).to_csv(
+          path_or_buf=csv_file, index=False)
+        print(f"Query result written into {csv_file}")
+
+    stats = btp.stats()
+    if stats.load_failures + stats.execute_failures > 0:
+      logging.error("Failures registered during BTP run: "
+                  "%s load failures, %s execution failures.",
+                  stats.load_failures, stats.execute_failures)
diff --git a/crossbench/cli/cli.py b/crossbench/cli/cli.py
new file mode 100644
index 0000000..92c9230
--- /dev/null
+++ b/crossbench/cli/cli.py
@@ -0,0 +1,1155 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import json
+import logging
+import sys
+import textwrap
+import traceback
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    Type, Union)
+
+import tabulate as tbl
+
+import crossbench.benchmarks.all as benchmarks
+from crossbench import __version__
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.benchmarks.base import Benchmark
+from crossbench.browsers import splash_screen, viewport
+from crossbench.cli import ui
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.cli.config.env import (parse_env_config_file,
+                                       parse_inline_env_config)
+from crossbench.cli.config.network import NetworkConfig
+from crossbench.cli.config.probe import (PROBE_LOOKUP, ProbeConfig,
+                                         ProbeListConfig)
+from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.cli.parser import CrossBenchArgumentParser
+from crossbench.cli.subcommand.devtools_recorder_proxy.default import \
+    CrossbenchDevToolsRecorderProxy
+from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
+                            ValidationMode)
+from crossbench.parse import (DurationParser, LateArgumentError, ObjectParser,
+                              PathParser)
+from crossbench.probes.all import GENERAL_PURPOSE_PROBES, DebuggerProbe
+from crossbench.probes.internal import ErrorsProbe
+from crossbench.probes.thermal_monitor import ThermalStatus
+from crossbench.runner.runner import Runner
+from crossbench.runner.timing import Timing
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.probes.probe import Probe
+  from crossbench.runner.run import Run
+  BenchmarkClsT = Type[Benchmark]
+  BrowserLookupTableT = Dict[str, Tuple[Type[Browser], pth.LocalPath]]
+
+
+class CrossBenchArgumentError(argparse.ArgumentError):
+  """Custom class that also prints the argument.help if available.
+  """
+
+  def __init__(self, argument: Any, message: str) -> None:
+    self.help: str = ""
+    super().__init__(argument, message)
+    if self.argument_name:
+      self.help = getattr(argument, "help", "")
+
+  def __str__(self) -> str:
+    formatted = super().__str__()
+    if not self.help:
+      return formatted
+    return (f"argument error {self.argument_name}:\n\n"
+            f"Help {self.argument_name}:\n{self.help}\n\n"
+            f"{formatted}")
+
+
+argparse.ArgumentError = CrossBenchArgumentError
+
+
+class EnableDebuggingAction(argparse.Action):
+  """Custom action to set both --throw and -vvv."""
+
+  def __call__(self,
+               parser: argparse.ArgumentParser,
+               namespace: argparse.Namespace,
+               values: Union[str, Sequence[Any], None],
+               option_string: Optional[str] = None) -> None:
+    setattr(namespace, "throw", True)
+    setattr(namespace, "verbosity", 3)
+    setattr(namespace, "driver_logging", True)
+
+
+class EnableFastAction(argparse.Action):
+  """Custom action to enable fast test runs"""
+
+  def __call__(self,
+               parser: argparse.ArgumentParser,
+               namespace: argparse.Namespace,
+               values: Union[str, Sequence[Any], None],
+               option_string: Optional[str] = None) -> None:
+    setattr(namespace, "cool_down_time", dt.timedelta())
+    setattr(namespace, "splash_screen", splash_screen.SplashScreen.NONE)
+    setattr(namespace, "env_validation", ValidationMode.SKIP)
+
+
+class AppendDebuggerProbeAction(argparse.Action):
+  """Custom action to set multiple args when --gdb or --lldb are set:
+  - Add a DebuggerProbe config.
+  - Increase --timeout-unit to a large value to keep debug session alive for a
+    longer time.
+  """
+
+  def __call__(self,
+               parser: argparse.ArgumentParser,
+               namespace: argparse.Namespace,
+               values: Union[str, Sequence[Any], None],
+               option_string: Optional[str] = None) -> None:
+    probes: List[ProbeConfig] = getattr(namespace, self.dest, [])
+    probe_settings = {"debugger": "gdb"}
+    if option_string and "lldb" in option_string:
+      probe_settings["debugger"] = "lldb"
+    probes.append(ProbeConfig(DebuggerProbe, probe_settings))
+    if not getattr(namespace, "timeout_unit", None):
+      # Set a very large --timeout-unit to allow for very slow debugging without
+      # causing timeouts (for instance when waiting on a breakpoint).
+      setattr(namespace, "timeout_unit", dt.timedelta.max)
+
+
+class MainCrossBenchArgumentParser(CrossBenchArgumentParser):
+
+  def print_help(self, file=None) -> None:
+    super().print_help(file=file)
+    self.print_probes(file=file)
+
+  def print_probes(self, file=None) -> None:
+    lines = [
+        "Probes can be added and configured for each benchmark.",
+        f"Use `{sys.argv[0]} describe probe $PROBE` for the full help.",
+        "",
+        "Usage: --probe=v8.log --probe=video ...",
+        "Usage: --probe=v8.log:{log_all:false} ...",
+        "Usage: --probe-config=configs/probe/perfetto/default.config.hjson",
+        "",
+    ]
+    table = []
+    for probe_cls in GENERAL_PURPOSE_PROBES:
+      table.append((probe_cls.NAME, probe_cls.summary_text()))
+    lines.append(tbl.tabulate(table, tablefmt="plain"))
+    contents = "\n".join(lines)
+    file = file or sys.stdout
+    file.write("\n")
+    file.write("Available Probes for all Benchmarks:\n")
+    file.write(textwrap.indent(contents, "    "))
+    file.write("\n")
+
+
+class CrossBenchCLI:
+  BENCHMARKS: Tuple[BenchmarkClsT, ...] = (
+      benchmarks.JetStream20Benchmark,
+      benchmarks.JetStream21Benchmark,
+      benchmarks.JetStream22Benchmark,
+      benchmarks.JetStream30Benchmark,
+      benchmarks.LoadLinePhoneBenchmark,
+      benchmarks.LoadLineTabletBenchmark,
+      benchmarks.ManualBenchmark,
+      benchmarks.MotionMark10Benchmark,
+      benchmarks.MotionMark11Benchmark,
+      benchmarks.MotionMark12Benchmark,
+      benchmarks.MotionMark13Benchmark,
+      benchmarks.PageLoadBenchmark,
+      benchmarks.Speedometer20Benchmark,
+      benchmarks.Speedometer21Benchmark,
+      benchmarks.Speedometer30Benchmark,
+      benchmarks.MemoryBenchmark,
+  )
+
+  RUNNER_CLS: Type[Runner] = Runner
+
+  def __init__(self, enable_logging: bool = True) -> None:
+    self._enable_logging = enable_logging
+    self._console_handler: Optional[logging.StreamHandler] = None
+    self._subparsers: Dict[BenchmarkClsT, CrossBenchArgumentParser] = {}
+    self.parser = MainCrossBenchArgumentParser(
+        description=("A cross browser and cross benchmark runner "
+                     "with configurable measurement probes."))
+    self.describe_parser = CrossBenchArgumentParser()
+    self.recorder_parser = CrossBenchArgumentParser()
+    self.args = argparse.Namespace()
+    self._setup_parser()
+    self._setup_subparser()
+
+  def _setup_parser(self) -> None:
+    self._add_verbosity_argument(self.parser)
+    # Disable colors by default when piped to a file.
+    has_color = hasattr(sys.stdout, "isatty") and sys.stdout.isatty()
+    self.parser.add_argument(
+        "--no-color",
+        dest="color",
+        action="store_false",
+        default=has_color,
+        help="Disable colored output")
+    self.parser.add_argument(
+        "--version", action="version", version=f"%(prog)s {__version__}")
+
+  def _add_verbosity_argument(self, parser: argparse.ArgumentParser) -> None:
+    debug_group = parser.add_argument_group("Verbosity / Debugging Options")
+    verbosity_group = debug_group.add_mutually_exclusive_group()
+    verbosity_group.add_argument(
+        "--quiet",
+        "-q",
+        dest="verbosity",
+        default=0,
+        action="store_const",
+        const=-1,
+        help="Disable most output printing.")
+    verbosity_group.add_argument(
+        "--verbose",
+        "-v",
+        dest="verbosity",
+        action="count",
+        default=0,
+        help=("Increase output verbosity. "
+              "Repeat for more verbose output (0..2)."))
+    debug_group.add_argument(
+        "--driver-logging",
+        "--verbose-driver",
+        action="store_true",
+        default=False,
+        help=("Enable verbose webdriver logging. "
+              "Disabled by default, automatically enable with --debug"))
+    debug_group.add_argument(
+        "--throw",
+        action="store_true",
+        default=False,
+        help=("Directly throw exceptions instead. "
+              "Note that this prevents merging of probe results if only "
+              "a subset of the runs failed."))
+    debug_group.add_argument(
+        "--debug",
+        action=EnableDebuggingAction,
+        nargs=0,
+        help="Enable debug output, equivalent to --throw -vvv")
+
+    debugger_group = debug_group.add_mutually_exclusive_group()
+    debugger_group.add_argument(
+        "--gdb",
+        action=AppendDebuggerProbeAction,
+        nargs=0,
+        dest="probe",
+        help=("Launch chrome with gdb or lldb attached to all processes. "
+              " See 'describe probe debugger' for more options."))
+    debugger_group.add_argument(
+        "--lldb",
+        action=AppendDebuggerProbeAction,
+        nargs=0,
+        dest="probe",
+        help=("Launch chrome with lldb attached to all processes."
+              " See 'describe probe debugger' for more options."))
+
+  def _setup_subparser(self) -> None:
+    self.subparsers = self.parser.add_subparsers(
+        title="Subcommands",
+        dest="subcommand",
+        required=True,
+        parser_class=CrossBenchArgumentParser)
+    for benchmark_cls in self.BENCHMARKS:
+      self._setup_benchmark_subparser(benchmark_cls)
+    self._setup_help_subparser()
+    self._setup_describe_subparser()
+    self._setup_recorder_subparser()
+
+  def _setup_recorder_subparser(self) -> None:
+    self.recorder_parser = CrossbenchDevToolsRecorderProxy.add_subcommand(
+        self.subparsers)
+    assert isinstance(self.recorder_parser, CrossBenchArgumentParser)
+    self._add_verbosity_argument(self.recorder_parser)
+
+  def _setup_describe_subparser(self) -> None:
+    self.describe_parser = self.subparsers.add_parser(
+        "describe", aliases=["desc"], help="Print all benchmarks and stories")
+    assert isinstance(self.describe_parser, CrossBenchArgumentParser)
+    self.describe_parser.add_argument(
+        "category",
+        nargs="?",
+        choices=["all", "benchmark", "benchmarks", "probe", "probes"],
+        default="all",
+        help="Limit output to the given category, defaults to 'all'")
+    self.describe_parser.add_argument(
+        "filter",
+        nargs="?",
+        help=("Only display the given item from the provided category. "
+              "By default all items are displayed. "
+              "Example: describe probes v8.log"))
+    self.describe_parser.add_argument(
+        "--json",
+        default=False,
+        action="store_true",
+        help="Print the data as json data")
+    self.describe_parser.set_defaults(subcommand_fn=self.describe_subcommand)
+    self._add_verbosity_argument(self.describe_parser)
+
+  def _setup_help_subparser(self) -> None:
+    # Just for completeness we want to support "--help" and "help"
+    help_parser = self.subparsers.add_parser(
+        "help", help="Print the top-level, same as --help")
+    help_parser.set_defaults(subcommand_fn=self.help_subcommand)
+    version_parser = self.subparsers.add_parser(
+        "version",
+        help="Show program's version number and exit, same as --version")
+    version_parser.set_defaults(subcommand_fn=self.version_subcommand)
+    assert isinstance(self.describe_parser, CrossBenchArgumentParser)
+    self._add_verbosity_argument(self.describe_parser)
+
+  def describe_subcommand(self, args: argparse.Namespace) -> None:
+    benchmarks_data: Dict[str, Any] = {}
+    for benchmark_cls in self.BENCHMARKS:
+      aliases: Tuple[str, ...] = benchmark_cls.aliases()
+      if args.filter:
+        if benchmark_cls.NAME != args.filter and args.filter not in aliases:
+          continue
+      benchmark_info = benchmark_cls.describe()
+      benchmark_info["aliases"] = aliases or "None"
+      benchmark_info["help"] = f"See `{benchmark_cls.NAME} --help`"
+      benchmarks_data[benchmark_cls.NAME] = benchmark_info
+    data: Dict[str, Dict[str, Any]] = {
+        "benchmarks": benchmarks_data,
+        "probes": {
+            str(probe_cls.NAME): probe_cls.help_text()
+            for probe_cls in GENERAL_PURPOSE_PROBES
+            if not args.filter or probe_cls.NAME == args.filter
+        }
+    }
+    if args.json:
+      if args.category in ("probe", "probes"):
+        data = data["probes"]
+        if not data:
+          self.error(f"No matching probe found: '{args.filter}'")
+      elif args.category in ("benchmark", "benchmarks"):
+        data = data["benchmarks"]
+        if not data:
+          self.error(f"No matching benchmark found: '{args.filter}'")
+      else:
+        assert args.category == "all"
+        if not data["benchmarks"] and not data["probes"]:
+          self.error(f"No matching benchmarks or probes found: '{args.filter}'")
+      print(json.dumps(data, indent=2))
+      return
+    # Create tabular format
+    printed_any = False
+    if args.category in ("all", "benchmark", "benchmarks"):
+      table: List[List[Optional[str]]] = [["Benchmark", "Property", "Value"]]
+      for benchmark_name, values in data["benchmarks"].items():
+        table.append([
+            benchmark_name,
+        ])
+        for name, value in values.items():
+          if isinstance(value, (tuple, list)):
+            value = "\n".join(value)
+          elif isinstance(value, dict):
+            if not value.items():
+              value = "[]"
+            else:
+              kwargs = {"maxcolwidths": 60}
+              value = tbl.tabulate(value.items(), tablefmt="plain", **kwargs)
+          table.append([None, name, value])
+      if len(table) <= 1:
+        if args.category != "all":
+          self.error(f"No matching benchmark found: '{args.filter}'")
+      else:
+        printed_any = True
+        print(tbl.tabulate(table, tablefmt="grid"))
+
+    if args.category in ("all", "probe", "probes"):
+      table = [["Probe", "Help"]]
+      for probe_name, probe_desc in data["probes"].items():
+        table.append([probe_name, probe_desc])
+      if len(table) <= 1:
+        if args.category != "all":
+          self.error(f"No matching probe found: '{args.filter}'")
+      else:
+        printed_any = True
+        print(tbl.tabulate(table, tablefmt="grid"))
+
+    if not printed_any:
+      self.error(f"No matching benchmarks or probes found: '{args.filter}'")
+
+  def help_subcommand(self, args: argparse.Namespace) -> None:
+    del args
+    self.parser.print_help()
+    sys.exit(0)
+
+  def version_subcommand(self, args: argparse.Namespace) -> None:
+    del args
+    print(f"{sys.argv[0]} {__version__}")
+    sys.exit(0)
+
+  def _setup_benchmark_subparser(self, benchmark_cls: Type[Benchmark]) -> None:
+    subparser = benchmark_cls.add_cli_parser(self.subparsers,
+                                             benchmark_cls.aliases())
+    self.RUNNER_CLS.add_cli_parser(benchmark_cls, subparser)
+    assert isinstance(subparser, argparse.ArgumentParser), (
+        f"Benchmark class {benchmark_cls}.add_cli_parser did not return "
+        f"an ArgumentParser: {subparser}")
+    self._subparsers[benchmark_cls] = subparser
+
+    runner_group = subparser.add_argument_group("Runner Options", "")
+    runner_group.add_argument(
+        "--cache-dir",
+        type=pth.LocalPath,
+        default=None,
+        help=("Used for caching browser binaries and archives. "
+              "Defaults to binary_cache"))
+
+    cooldown_group = runner_group.add_mutually_exclusive_group()
+    cooldown_group.add_argument(
+        "--cool-down-threshold",
+        type=ThermalStatus.parse,
+        help=("Pause execution when the device reaches this thermal status. "
+              "Exucution resumes once the status drops below the threshold. "
+              "Only available on Android."))
+    cooldown_group.add_argument(
+        "--cool-down-time",
+        "--cool-down",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(seconds=2),
+        help=("Wait between repetitions for a fixed amount of time. "
+              f"Format: {DurationParser.help()}"))
+    cooldown_group.add_argument(
+        "--no-cool-down",
+        action="store_const",
+        dest="cool_down_time",
+        const=dt.timedelta(seconds=0),
+        help=("Disable cool-down between runs (might cause CPU throttling), "
+              "equivalent to --cool-down=0."))
+    cooldown_group.add_argument(
+        "--fast",
+        action=EnableFastAction,
+        nargs=0,
+        help=("Switch to a fast run mode "
+              "which might yield unstable performance results. "
+              "Equivalent to --cool-down=0 --no-splash --env-validation=skip."))
+
+    runner_group.add_argument(
+        "--time-unit",
+        type=DurationParser.any_duration,
+        default=dt.timedelta(seconds=1),
+        help=("Absolute duration of 1 time unit in the runner. "
+              "Increase this for slow builds or machines. "
+              f"Format: {DurationParser.help()}"))
+    runner_group.add_argument(
+        "--timeout-unit",
+        type=DurationParser.any_duration,
+        default=dt.timedelta(),
+        help=("Absolute duration of 1 time unit for timeouts in the runner. "
+              "Unlike --time-unit, this does only apply for timeouts, "
+              "as opposed to say initial wait times or sleeps."
+              f"Format: {DurationParser.help()}"))
+    runner_group.add_argument(
+        "--run-timeout",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Sets the same timeout per run on all browsers. "
+              "Runs will be aborted after the given timeout. "
+              f"Format: {DurationParser.help()}"))
+    runner_group.add_argument(
+        "--start-delay",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Delay before running the core workload, "
+              "after a story's/workload's setup, "
+              "and after starting the browser."))
+    runner_group.add_argument(
+        "--stop-delay",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Delay after running the core workload, "
+              "before story's/workload's teardown, "
+              "and before quitting the browser."))
+
+    network_group = subparser.add_argument_group("Network Options", "")
+    network_settings_group = network_group.add_mutually_exclusive_group()
+    network_settings_group.add_argument(
+        "--network",
+        type=NetworkConfig.parse,
+        help=("Either an inline network config or an file path to full "
+              "network config hjson file (see --network-config)."))
+    network_settings_group.add_argument(
+        "--network-config",
+        metavar="DIR",
+        type=NetworkConfig.parse_config_path,
+        help=NetworkConfig.help())
+    network_settings_group.add_argument(
+        "--local-file-server",
+        "--local-fileserver",
+        "--file-server",
+        "--fileserver",
+        type=NetworkConfig.parse_local,
+        metavar="DIR",
+        dest="network",
+        help="Start a local http file server at the given directory.")
+    network_settings_group.add_argument(
+        "--wpr",
+        "--web-page-replay",
+        type=NetworkConfig.parse_wpr,
+        metavar="WPR_ARCHIVE",
+        dest="network",
+        help=("Use wpr.archive to replay network requests "
+              "via a local proxy server. "
+              "Archives can be recorded with --probe=wpr. "
+              "WPR_ARCHIVE can be a local file or a gs:// google storage url."))
+
+    env_group = subparser.add_argument_group("Environment Options", "")
+    env_settings_group = env_group.add_mutually_exclusive_group()
+    env_settings_group.add_argument(
+        "--env",
+        type=parse_inline_env_config,
+        help=("Set default runner environment settings. "
+              f"Possible values: {', '.join(HostEnvironment.CONFIGS)}"
+              "or an inline hjson configuration (see --env-config). "
+              "Mutually exclusive with --env-config"))
+    env_settings_group.add_argument(
+        "--env-config",
+        type=parse_env_config_file,
+        help=("Path to an env.config.hjson file that specifies detailed "
+              "runner environment settings and requirements. "
+              "See config/env.config.hjson for more details."
+              "Mutually exclusive with --env"))
+
+    env_group.add_argument(
+        "--env-validation",
+        default=ValidationMode.PROMPT,
+        type=ValidationMode,
+        help=(
+            "Set how runner env is validated (see als --env-config/--env):\n" +
+            ValidationMode.help_text(indent=2)))
+    env_group.add_argument(
+        "--dry-run",
+        action="store_true",
+        default=False,
+        help="Don't run any browsers or probes")
+
+    browser_group = subparser.add_argument_group(
+        "Browser Options", "Any other browser option can be passed "
+        "after the '--' arguments separator.")
+    browser_config_group = browser_group.add_mutually_exclusive_group()
+    browser_config_group.add_argument(
+        "--browser",
+        "-b",
+        type=BrowserConfig.parse_with_range,
+        action="extend",
+        default=[],
+        help=(
+            "Browser binary, defaults to 'chrome-stable'."
+            "Use this to test a simple browser variant. "
+            "Use [chrome, chrome-stable, chrome-dev, chrome-canary, "
+            "safari, safari-tp, "
+            "firefox, firefox-stable, firefox-dev, firefox-nightly, "
+            "edge, edge-stable, edge-beta, edge-dev, edge-canary] "
+            "for system default browsers or a full path. \n"
+            "* Use --browser=chrome-M107 to download the latest version for a "
+            "specific milestone\n"
+            "* Use ... to test milestone ranges --browser=chr-M100...M125"
+            "* Use --browser=chrome-100.0.4896.168 to download a specific "
+            "chrome version (macOS and linux for googlers and chrome only). \n"
+            "* Use --browser=path/to/archive.dmg on macOS or "
+            "--browser=path/to/archive.rpm on linux "
+            "for locally cached versions (chrome only).\n"
+            "* Use --browser=\"${ADB_SERIAL}:chrome\" "
+            "(e.g. --browser='0a388e93:chrome') for specific "
+            "android devices or --browser='adb:chrome' if only once device is "
+            "attached.\n"
+            "Repeat for adding multiple browsers. "
+            "The browser result dir's name is "
+            "'${BROWSER}_${PLATFORM}_${INDEX}' "
+            "$INDEX corresponds to the order on the command line."
+            "Cannot be used together with --browser-config"))
+    browser_config_group.add_argument(
+        "--browser-config",
+        type=PathParser.hjson_file_path,
+        help=("Browser configuration.json file. "
+              "Use this to run multiple browsers and/or multiple "
+              "flag configurations. "
+              "See config/doc/browser.config.hjson on how to set up a complex "
+              "configuration file. "
+              "Cannot be used together with --browser."))
+    browser_group.add_argument(
+        "--driver-path",
+        type=PathParser.file_path,
+        help=("Use the same custom driver path for all specified browsers. "
+              "Version mismatches might cause crashes."))
+    browser_group.add_argument(
+        "--config",
+        type=PathParser.hjson_file_path,
+        help=("Specify a common config for --probe-config, --browser-config, "
+              "--network-config and --env-config."))
+    browser_group.add_argument(
+        "--secrets",
+        dest="secrets",
+        type=SecretsConfig.parse,
+        default=SecretsConfig(),
+        help="Path to file containing login secrets")
+
+    browser_group.add_argument(
+        "--wipe-system-user-data",
+        dest="wipe_system_user_data",
+        default=False,
+        action="store_true",
+        help="Clear user data at the beginning of the test "
+        "(be careful using it).")
+    browser_group.add_argument(
+        "--http-request-timeout",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Set the timeout of http request. "
+              f"Format: {DurationParser.help()}. "
+              "When not specified, there will be no timeout."))
+
+    splashscreen_group = browser_group.add_mutually_exclusive_group()
+    splashscreen_group.add_argument(
+        "--splash-screen",
+        "--splashscreen",
+        "--splash",
+        type=splash_screen.SplashScreen.parse,
+        default=splash_screen.SplashScreen.DETAILED,
+        help=("Set the splashscreen shown before each run. "
+              "Choices: 'default', 'none', 'minimal', 'detailed,' or "
+              "a path or a URL."))
+    splashscreen_group.add_argument(
+        "--no-splash",
+        "--nosplash",
+        dest="splash_screen",
+        const=splash_screen.SplashScreen.NONE,
+        action="store_const",
+        help="Shortcut for --splash-screen=none")
+
+    viewport_group = browser_group.add_mutually_exclusive_group()
+    # pytype: disable=missing-parameter
+    viewport_group.add_argument(
+        "--viewport",
+        default=viewport.Viewport.DEFAULT,
+        type=viewport.Viewport.parse,
+        help=("Set the browser window position."
+              "Options: size and position, "
+              f"{', '.join(str(e) for e in viewport.ViewportMode)}. "
+              "Examples: --viewport=1550x300 --viewport=fullscreen. "
+              f"Default: {viewport.Viewport.DEFAULT}"))
+    # pytype: enable=missing-parameter
+    viewport_group.add_argument(
+        "--headless",
+        dest="viewport",
+        const=viewport.Viewport.HEADLESS,
+        action="store_const",
+        help=("Start the browser in headless if supported. "
+              "Equivalent to --viewport=headless."))
+
+    chrome_args = subparser.add_argument_group(
+        "Browsers Options: Chrome/Chromium",
+        "For convenience these arguments are directly are forwarded "
+        "directly to chrome. ")
+    chrome_args.add_argument(
+        "--js-flags", dest="js_flags", action="append", default=[])
+
+    doc_str = "See chrome's base/feature_list.h source file for more details"
+    chrome_args.add_argument(
+        "--enable-features",
+        help="Comma-separated list of enabled chrome features. " + doc_str,
+        default="")
+    chrome_args.add_argument(
+        "--disable-features",
+        help="Command-separated list of disabled chrome features. " + doc_str,
+        default="")
+
+    field_trial_group = chrome_args.add_mutually_exclusive_group()
+    field_trial_group.add_argument(
+        "--enable-field-trial-config",
+        "--enable-field-trials",
+        default=None,
+        action="store_true",
+        help=("Use chrome's field-trial configs, "
+              "disabled by default by crossbench"))
+    field_trial_group.add_argument(
+        "--disable-field-trial-config",
+        "--disable-field-trials",
+        dest="enable_field_trial_config",
+        action="store_false",
+        help=("Explicitly disable field-trial configs."
+              "Off by default on official builds, "
+              "and disabled by default by crossbench."))
+
+    probe_group = subparser.add_argument_group("Probe Options", "")
+    probe_config_group = probe_group.add_mutually_exclusive_group()
+    probe_config_group.add_argument(
+        "--probe",
+        action="append",
+        type=ProbeConfig.parse,
+        default=[],
+        help=(
+            "Enable general purpose probes to measure data on all cb.stories. "
+            "This argument can be specified multiple times to add more probes. "
+            "Use inline hjson (e.g. --probe=\"$NAME{$CONFIG}\") "
+            "to configure probes. "
+            "Individual probe configs can be specified in files as well: "
+            "--probe='path/to/config.hjson'."
+            "Use 'describe probes' or 'describe probe $NAME' for probe "
+            "configuration details."
+            "Cannot be used together with --probe-config."
+            f"\n\nChoices: {', '.join(PROBE_LOOKUP.keys())}"))
+    probe_config_group.add_argument(
+        "--probe-config",
+        type=PathParser.hjson_file_path,
+        default=benchmark_cls.default_probe_config_path(),
+        help=("Browser configuration.json file. "
+              "Use this config file to specify more complex Probe settings."
+              "See config/doc/probe.config.hjson on how to set up a complex "
+              "configuration file. "
+              "Cannot be used together with --probe."))
+    subparser.set_defaults(
+        subcommand_fn=self.benchmark_subcommand, benchmark_cls=benchmark_cls)
+    self._add_verbosity_argument(subparser)
+    subparser.add_argument("other_browser_args", nargs="*")
+
+  def benchmark_subcommand(self, args: argparse.Namespace) -> None:
+    benchmark = None
+    runner = None
+    if args.cache_dir:
+      plt.PLATFORM.set_cache_dir(args.cache_dir)
+    self._benchmark_subcommand_helper(args)
+    try:
+      self._benchmark_subcommand_process_args(args)
+      benchmark = self._get_benchmark(args)
+      with plt.PLATFORM.TemporaryDirectory(prefix="crossbench") as tmp_dirname:
+        if args.dry_run:
+          args.out_dir = pth.LocalPath(tmp_dirname) / "results"
+        args.browser = self._get_browsers(args)
+        probes = self._get_probes(args)
+        env_config = self._get_env_config(args)
+        env_validation_mode = self._get_env_validation_mode(args)
+        timing = self._get_timing(args)
+        runner = self._get_runner(args, benchmark, env_config,
+                                  env_validation_mode, timing)
+
+        # We prevent running multiple stories in repetition OR if multiple
+        # browsers are open when 'power' probes are used since it might distort
+        # the data.
+        if len(args.browser) > 1 or args.repetitions > 1:
+          probe_names = [probe.name for probe in probes if probe.BATTERY_ONLY]
+          if probe_names:
+            names_str = ",".join(probe_names)
+            raise argparse.ArgumentTypeError(
+                f"Cannot use [{names_str}] probe(s) "
+                "with repeat > 1 and/or with multiple browsers. We need to "
+                "always start at the same battery level, and by running "
+                "stories on multiple browsers or multiples time will create "
+                "erroneous data.")
+
+        for probe in probes:
+          runner.attach_probe(probe, matching_browser_only=True)
+
+        self._run_benchmark(args, runner)
+    except KeyboardInterrupt:
+      sys.exit(2)
+    except LateArgumentError as e:
+      if args.throw:
+        raise
+      self.handle_late_argument_error(e)
+    except Exception as e:  # pylint: disable=broad-except
+      if args.throw:
+        raise
+      self._log_benchmark_subcommand_failure(benchmark, runner, e)
+      sys.exit(3)
+
+  def _benchmark_subcommand_helper(self, args: argparse.Namespace) -> None:
+    """Handle common subcommand mistakes that are not easily implementable
+    with argparse.
+    run: => just run the benchmark
+    help => use --help
+    describe => use describe benchmark NAME
+    """
+    if not args.other_browser_args:
+      return
+    maybe_command = args.other_browser_args[0]
+    if maybe_command == "run":
+      args.other_browser_args.pop()
+      return
+    if maybe_command == "help":
+      self._subparsers[args.benchmark_cls].print_help()
+      sys.exit(0)
+    if maybe_command == "describe":
+      logging.warning("See `describe benchmark %s` for more options",
+                      args.benchmark_cls.NAME)
+      # Patch args to simulate: describe benchmark BENCHMARK_NAME
+      args.category = "benchmarks"
+      args.filter = args.benchmark_cls.NAME
+      args.json = False
+      self.describe_subcommand(args)
+      sys.exit(0)
+
+  def _process_network_args(self, args) -> None:
+    # The order of preference of flags is as follows:
+    # Explicitly specified network config > explicitly specified network >
+    # benchmark-specific network config > default network.
+    if network_config := args.network_config:
+      args.network = network_config
+    elif args.network:
+      pass
+    elif network_config := args.benchmark_cls.default_network_config_path():
+      args.network = network_config
+    else:
+      args.network = NetworkConfig.default()
+
+  def _benchmark_subcommand_process_args(self, args) -> None:
+    if args.config:
+      self._process_config_args(args)
+    else:
+      # We keep separate *_config args so we can throw in case they conflict
+      # with --config. Since we don't use argparse's dest, we have to manually
+      # copy the args.*_config back.
+      self._process_network_args(args)
+
+  def _process_config_args(self, args) -> None:
+    if args.env_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --env-config")
+    if args.network_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --network-config")
+    if args.browser_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --browser-config")
+    if args.probe_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --probe-config")
+
+    config_file = args.config
+    config_data = ObjectParser.hjson_file(config_file)
+    found_any_config = False
+
+    if config_data.get("env"):
+      args.env_config = parse_env_config_file(config_file)
+      found_any_config = True
+    else:
+      logging.warning("Skipping env config: no 'env' property in %s",
+                      config_file)
+
+    if network_config_data := config_data.get("network"):
+      # TODO: migrate all --config helper to this format
+      args.network = NetworkConfig.parse(network_config_data)
+      found_any_config = True
+    else:
+      logging.warning("Skipping network config: no 'network' property in %s",
+                      config_file)
+    if not args.network:
+      args.network = NetworkConfig.default()
+
+    if config_data.get("browsers"):
+      args.browser_config = config_file
+      found_any_config = True
+    else:
+      logging.warning("Skipping browsers config: No 'browsers' property in %s",
+                      config_file)
+
+    if config_data.get("probes"):
+      args.probe_config = config_file
+      found_any_config = True
+    else:
+      logging.warning("Skipping probes config: no 'probes' property in %s",
+                      config_file)
+
+    if not found_any_config:
+      raise argparse.ArgumentTypeError(
+          f"--config: config file has no config properties {config_file}")
+
+  def _log_benchmark_subcommand_failure(self, benchmark: Optional[Benchmark],
+                                        runner: Optional[Runner],
+                                        e: Exception) -> None:
+    logging.debug(e)
+    logging.error("")
+    logging.error("#" * 80)
+    logging.error("SUBCOMMAND UNSUCCESSFUL got %s:", e.__class__.__name__)
+    logging.error("-" * 80)
+    self._log_benchmark_subcommand_exception(e)
+    logging.error("-" * 80)
+    if benchmark:
+      logging.error("Running '%s' was not successful:", benchmark.NAME)
+    logging.error(
+        "- Use --debug for very verbose output (equivalent to --throw -vvv)")
+    if runner and runner.runs:
+      self._log_runner_debug_hints(runner)
+    else:
+      logging.error("- Check %s.json detailed backtraces", ErrorsProbe.NAME)
+    logging.error("#" * 80)
+    sys.exit(3)
+
+  def _log_benchmark_subcommand_exception(self, e: Exception) -> None:
+    message = str(e)
+    if message:
+      logging.error(message)
+      return
+    if isinstance(e, AssertionError):
+      self._log_assertion_error_statement(e)
+
+  def _log_assertion_error_statement(self, e: AssertionError) -> None:
+    _, exception, tb = sys.exc_info()
+    if exception is not e:
+      return
+    tb_info = traceback.extract_tb(tb)
+    filename, line, _, text = tb_info[-1]
+    logging.info("%s:%s: %s", filename, line, text)
+
+  def _log_runner_debug_hints(self, runner: Runner) -> None:
+    failed_runs = [run for run in runner.runs if not run.is_success]
+    if not failed_runs:
+      return
+    candidates: List[pth.LocalPath] = [
+        *runner.out_dir.glob(f"{ErrorsProbe.NAME}*"),
+    ]
+    for failed_run in failed_runs:
+      candidates.extend(failed_run.out_dir.glob(f"{ErrorsProbe.NAME}*"))
+      candidates.extend(failed_run.out_dir.glob("*.log"))
+
+    failed_run = failed_runs[0]
+    logging.error("- Check log outputs (1 of %d failed runs):",
+                  len(failed_runs))
+    limit = 3
+    for log_file in candidates[:limit]:
+      try:
+        log_file = log_file.relative_to(pth.LocalPath.cwd())
+      except Exception as e:  # pylint: disable=broad-except
+        logging.debug("Could not create relative log_file: %s", e)
+      logging.error("  - %s", log_file)
+    if (pending := len(candidates) - limit) > 0:
+      logging.error("  - ... and %d more interesting %s.json or *.log files",
+                    pending, ErrorsProbe.NAME)
+
+  def _run_benchmark(self, args: argparse.Namespace, runner: Runner) -> None:
+    try:
+      runner.run(is_dry_run=args.dry_run)
+      logging.info("")
+      self._log_results(args, runner, is_success=runner.is_success)
+    except:  # pylint: disable=broad-except
+      self._log_results(args, runner, is_success=False)
+      raise
+    finally:
+      self._update_symlinks(args, runner)
+
+  def _update_symlinks(self, args: argparse.Namespace, runner: Runner) -> None:
+    if not args.create_symlinks:
+      logging.debug("Symlink disabled by command line option")
+      return
+    if plt.PLATFORM.is_win:
+      logging.debug("Skipping session_dir symlink on windows.")
+      return
+    if not args.out_dir and runner.out_dir.exists():
+      self._update_default_results_symlinks(runner)
+      self._create_runs_results_symlinks(runner)
+
+  def _update_default_results_symlinks(self, runner: Runner) -> None:
+    results_root = runner.out_dir.parent
+    latest_link = results_root / "latest"
+    if latest_link.is_symlink():
+      latest_link.unlink()
+    if not latest_link.exists():
+      latest_link.symlink_to(
+          runner.out_dir.relative_to(results_root), target_is_directory=True)
+    else:
+      logging.error("Could not create %s", latest_link)
+
+  def _create_runs_results_symlinks(self, runner: Runner) -> None:
+    results_root = runner.out_dir.parent
+    runs: Tuple[Run, ...] = runner.all_runs
+    if not runs:
+      logging.debug("Skip creating result symlinks in '%s': no runs produced.",
+                    results_root)
+      return
+    out_dir = runner.out_dir
+    first_run_dir = out_dir / "first_run"
+    last_run_dir = out_dir / "last_run"
+    if first_run_dir.exists():
+      logging.error("Cannot create first_run symlink: %s", first_run_dir)
+    else:
+      first_run_dir.symlink_to(runs[0].out_dir.relative_to(out_dir))
+    if last_run_dir.exists():
+      logging.error("Cannot create last_run symlink: %s", last_run_dir)
+    else:
+      last_run_dir.symlink_to(runs[-1].out_dir.relative_to(out_dir))
+
+    runs_dir = out_dir / "runs"
+    runs_dir.mkdir()
+    for run in runs:
+      if not run.out_dir.exists():
+        continue
+      relative = pth.LocalPath("..") / run.out_dir.relative_to(out_dir)
+      (runs_dir / str(run.index)).symlink_to(relative)
+
+    sessions_dir = out_dir / "sessions"
+    sessions_dir.mkdir()
+    for session in set(run.browser_session for run in runs):
+      relative = pth.LocalPath("..") / session.path.relative_to(out_dir)
+      (sessions_dir / str(session.index)).symlink_to(relative)
+
+  def _log_results(self, args: argparse.Namespace, runner: Runner,
+                   is_success: bool) -> None:
+    logging.info("=" * 80)
+    if is_success:
+      logging.critical("RESULTS: %s", runner.out_dir)
+    else:
+      logging.critical("RESULTS (maybe incomplete/broken): %s", runner.out_dir)
+    logging.info("=" * 80)
+    if not runner.has_browser_group:
+      logging.debug("No browser group in %s", runner)
+      return
+    browser_group = runner.browser_group
+    for probe in runner.probes:
+      try:
+        probe.log_browsers_result(browser_group)
+      except Exception as e:  # pylint: disable=broad-except
+        if args.throw:
+          raise
+        logging.warning("log_result_summary failed: %s", e)
+
+  def _get_browsers(self, args: argparse.Namespace) -> Sequence[Browser]:
+    # TODO: move browser instance create to separate method.
+    # TODO: move --browser-config parsing to BrowserVariantsConfig
+    args.browser_config = BrowserVariantsConfig.from_cli_args(args)
+    return args.browser_config.variants
+
+  def _get_probes(self, args: argparse.Namespace) -> Sequence[Probe]:
+    # TODO: move probe creation to separate method
+    # TODO: move --probe-config parsing to ProbeListConfig
+    args.probe_config = ProbeListConfig.from_cli_args(args)
+    return args.probe_config.probes
+
+  def _get_benchmark(self, args: argparse.Namespace) -> Benchmark:
+    benchmark_cls = self._get_benchmark_cls(args)
+    assert (issubclass(benchmark_cls, Benchmark)), (
+        f"benchmark_cls={benchmark_cls} is not subclass of Runner")
+    return benchmark_cls.from_cli_args(args)
+
+  def _get_benchmark_cls(self, args: argparse.Namespace) -> Type[Benchmark]:
+    return args.benchmark_cls
+
+  def _get_env_validation_mode(self,
+                               args: argparse.Namespace) -> ValidationMode:
+    return args.env_validation
+
+  def _get_env_config(self, args: argparse.Namespace) -> HostEnvironmentConfig:
+    # TODO: move env_config to args.env and use ConfigObject
+    if args.env:
+      return args.env
+    if args.env_config:
+      return args.env_config
+    return HostEnvironmentConfig()
+
+  def _get_timing(self, args: argparse.Namespace) -> Timing:
+    timeout_unit: dt.timedelta = args.timeout_unit or args.time_unit
+    return Timing(args.cool_down_time, args.time_unit, timeout_unit,
+                  args.run_timeout, args.start_delay, args.stop_delay)
+
+  def _get_runner(self, args: argparse.Namespace, benchmark: Benchmark,
+                  env_config: HostEnvironmentConfig,
+                  env_validation_mode: ValidationMode,
+                  timing: Timing) -> Runner:
+    runner_kwargs = self.RUNNER_CLS.kwargs_from_cli(args)
+    return self.RUNNER_CLS(
+        benchmark=benchmark,
+        env_config=env_config,
+        env_validation_mode=env_validation_mode,
+        timing=timing,
+        **runner_kwargs)
+
+  def run(self, argv: Sequence[str]) -> None:
+    self._init_logging(argv)
+    unprocessed_argv: List[str] = []
+    try:
+      # Manually check for unprocessed_argv to print nicer error messages.
+      self.args, unprocessed_argv = self.parser.parse_known_args(argv)
+    except argparse.ArgumentError as e:
+      # args is not set at this point, as parsing might have failed before
+      # handling --throw or --debug.
+      if "--throw" in argv or "--debug" in argv:
+        raise e
+      self.error(str(e))
+    if unprocessed_argv:
+      self.error(f"unrecognized arguments: {unprocessed_argv}\n"
+                 f"Use `{self.parser.prog} {self.args.subcommand} --help` "
+                 "for more details.")
+    # Properly initialize logging after having parsed all args
+    self._setup_logging()
+    try:
+      self.args.subcommand_fn(self.args)
+    finally:
+      self._teardown_logging()
+
+  def handle_late_argument_error(self, e: LateArgumentError) -> None:
+    self.error(f"error argument {e.flag}: {e.message}")
+
+  def error(self, message: str) -> None:
+    parser: CrossBenchArgumentParser = self.parser
+    # Try to use the subparser to print nicer usage help on errors.
+    # ArgumentParser tends to default to the toplevel parser instead of the
+    # current subcommand, which in turn prints the wrong usage text.
+    subcommand: str = getattr(self.args, "subcommand", "")
+    if subcommand == "describe":
+      parser = self.describe_parser
+    else:
+      maybe_benchmark_cls = getattr(self.args, "benchmark_cls", None)
+      if maybe_benchmark_cls:
+        parser = self._subparsers[maybe_benchmark_cls]
+    if subcommand:
+      parser.fail(f"{subcommand}: {message}")
+    else:
+      parser.fail(message)
+
+  def _init_logging(self, argv: Sequence[str]) -> None:
+    assert self._console_handler is None
+    if not self._enable_logging:
+      logging.getLogger().setLevel(logging.CRITICAL)
+      return
+    self._console_handler = logging.StreamHandler(sys.stderr)
+    self._console_handler.addFilter(logging.Filter("root"))
+    self._console_handler.setLevel(logging.INFO)
+    logging.getLogger().setLevel(logging.INFO)
+    logging.getLogger().addHandler(self._console_handler)
+
+    # Manually extract values to allow logging for failing arguments.
+    if "-v" in argv or "-vv" in argv or "-vvv" in argv:
+      self._console_handler.setLevel(logging.DEBUG)
+      logging.getLogger().setLevel(logging.DEBUG)
+    # TODO: move to ui helpers
+    ui.COLOR_LOGGING = "--no-color" not in argv
+    if ui.COLOR_LOGGING:
+      self._console_handler.setFormatter(ui.ColoredLogFormatter())
+
+  def _setup_logging(self) -> None:
+    if not self._enable_logging:
+      return
+    assert self._console_handler
+    if self.args.verbosity == -1:
+      self._console_handler.setLevel(logging.ERROR)
+    elif self.args.verbosity == 0:
+      self._console_handler.setLevel(logging.INFO)
+    elif self.args.verbosity >= 1:
+      self._console_handler.setLevel(logging.DEBUG)
+      logging.getLogger().setLevel(logging.DEBUG)
+    ui.COLOR_LOGGING = self.args.color
+    if ui.COLOR_LOGGING:
+      self._console_handler.setFormatter(ui.ColoredLogFormatter())
+    else:
+      self._console_handler.setFormatter(None)
+
+  def _teardown_logging(self) -> None:
+    if not self._enable_logging:
+      assert self._console_handler is None
+      return
+    assert self._console_handler
+    self._console_handler.flush()
+    logging.getLogger().removeHandler(self._console_handler)
+    self._console_handler = None
diff --git a/crossbench/cli/config/__init__.py b/crossbench/cli/config/__init__.py
new file mode 100644
index 0000000..67eefa2
--- /dev/null
+++ b/crossbench/cli/config/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/cli/config/browser.py b/crossbench/cli/config/browser.py
new file mode 100644
index 0000000..8a9225d
--- /dev/null
+++ b/crossbench/cli/config/browser.py
@@ -0,0 +1,315 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import logging
+import os
+import re
+from typing import Any, Dict, Optional, TextIO, Tuple, cast
+
+import hjson
+
+import crossbench.browsers.all as browsers
+from crossbench import exception
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.chrome.downloader import ChromeDownloader
+from crossbench.browsers.firefox.downloader import FirefoxDownloader
+from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
+from crossbench.cli.config.network import NetworkConfig, NetworkSpeedPreset
+from crossbench.config import ConfigObject, ConfigParser
+from crossbench.parse import NumberParser, PathParser
+
+SUPPORTED_BROWSER = ("chromium", "chrome", "safari", "edge", "firefox")
+
+# Split inputs like:
+# - "/out/x64.release/chrome"
+# - "/out/x64.release/chrome:4G"
+# - "C:\out\x64.release\chrome"
+# - "C:\out\x64.release\chrome:4G"
+# - "applescript:/out/x64.release/chrome"
+# - "applescript:/out/x64.release/chrome:4G"
+# - "selenium:C:\out\x64.release\chrome"
+# - "selenium:C:\out\x64.release\chrome:4G"
+NETWORK_PRESETS: str = "|".join(
+    re.escape(preset.value) for preset in NetworkSpeedPreset)  # pytype: disable=missing-parameter
+SHORT_FORM_RE = re.compile(r"((?P<driver>\w{3,}):)??"
+                           r"(?P<path>([A-Z]:[/\\])?[^:]+)"
+                           f"(:(?P<network>{NETWORK_PRESETS}))?")
+ANDROID_PACKAGE_RE = re.compile(r"[a-z]+(\.[a-z]+){2,}")
+VERSION_FOR_RANGE_RE = re.compile(r"(?P<prefix>[^\d]*)(?P<milestone>\d+)")
+
+
+@dataclasses.dataclass(frozen=True)
+class BrowserConfig(ConfigObject):
+  browser: pth.AnyPathLike
+  driver: DriverConfig = DriverConfig.default()
+  # Make network optional since --network provides a global default and we do
+  # want to have the option to explicitly specify the default network in a
+  # browser config.
+  network: Optional[NetworkConfig] = None
+
+  def __post_init__(self) -> None:
+    if not self.browser:
+      raise ValueError(f"{type(self).__name__}.browser cannot be None.")
+    if not self.driver:
+      raise ValueError(f"{type(self).__name__}.driver cannot be None.")
+
+  @classmethod
+  def default(cls) -> BrowserConfig:
+    return cls(
+        browsers.Chrome.stable_path(plt.PLATFORM), DriverConfig.default())
+
+  @classmethod
+  def parse_str(cls, value: str) -> BrowserConfig:
+    if not value:
+      raise argparse.ArgumentTypeError("Cannot parse empty string")
+    network: Optional[NetworkConfig] = None
+    driver = DriverConfig.default()
+    path: Optional[pth.AnyPathLike] = None
+    if ":" not in value or cls.value_has_path_prefix(value):
+      # Variant 1: $PATH_OR_IDENTIFIER
+      path = cls._parse_path_or_identifier(value)
+    elif value[0] != "{":
+      # Variant 2: ${DRIVER_TYPE}:${PATH_OR_IDENTIFIER}:${NETWORK}
+      driver, path, network = cls._parse_inline_short_form(value)
+    else:
+      # Variant 3: Full inline hjson
+      return cls.parse_inline_hjson(value)
+    assert path, "Invalid path"
+    return cls(path, driver, network)
+
+  @classmethod
+  def parse_with_range(cls, value: Any) -> Tuple[BrowserConfig, ...]:
+    if isinstance(value, str):
+      return cls._parse_with_range(value)
+    return (cls.parse(value),)
+
+  @classmethod
+  def _parse_with_range(cls, value: str) -> Tuple[BrowserConfig, ...]:
+    if not value:
+      raise argparse.ArgumentTypeError("Cannot parse empty string")
+    parts = value.split("...", maxsplit=1)
+    start_version: str = parts.pop(0)
+    if not parts:
+      return (cls.parse(start_version),)
+    limit_version = parts[0]
+
+    start_match = VERSION_FOR_RANGE_RE.fullmatch(start_version)
+    if not start_match:
+      raise argparse.ArgumentTypeError(
+          f"Start of a browser range {repr(value)} must end in digits, "
+          f"but got {repr(start_version)}")
+    limit_match = VERSION_FOR_RANGE_RE.fullmatch(limit_version)
+    if not limit_match:
+      raise argparse.ArgumentTypeError(
+          f"Upper limit of a browser range {repr(value)} must end in digits, "
+          f"but got {repr(limit_version)}")
+
+    start_prefix = start_match["prefix"]
+    limit_prefix = limit_match["prefix"]
+    if limit_prefix and not start_prefix.endswith(limit_prefix):
+      raise argparse.ArgumentTypeError(
+          f"Browser version range start prefix {repr(start_prefix)} must match "
+          f"limit prefix {repr(limit_prefix)}: {repr(value)}")
+
+    start_milestone: int = NumberParser.positive_int(
+        start_match["milestone"], "browser version range start milestone")
+    limit_milestone: int = NumberParser.positive_int(
+        limit_match["milestone"], "browser version range limit milestone")
+    if start_milestone > limit_milestone:
+      raise argparse.ArgumentTypeError(
+          f"Browser version limit must be larger than start: {repr(value)}")
+
+    count = limit_milestone - start_milestone
+    logging.info("Creating %d intermediate browser versions from %s", count,
+                 value)
+    versions = []
+    for milestone in range(start_milestone, limit_milestone + 1):
+      version_str = f"{start_prefix}{milestone}"
+      versions.append(cls.parse(version_str))
+    return tuple(versions)
+
+  @classmethod
+  def _parse_path_or_identifier(
+      cls,
+      maybe_path_or_identifier: str,
+      driver_type: Optional[BrowserDriverType] = None,
+      driver: Optional[DriverConfig] = None) -> pth.AnyPathLike:
+    if not maybe_path_or_identifier:
+      raise argparse.ArgumentTypeError("Got empty browser identifier.")
+    if not driver_type:
+      if driver:
+        driver_type = driver.type
+      else:
+        driver_type = BrowserDriverType.default()
+    identifier = maybe_path_or_identifier.lower()
+    path = None
+    if "/" in maybe_path_or_identifier or "\\" in maybe_path_or_identifier:
+      if cls._is_downloadable_identifier(maybe_path_or_identifier):
+        return maybe_path_or_identifier
+      # Assume a path since short-names never contain back-/slashes.
+      if driver_type.is_remote:
+        path = PathParser.path(maybe_path_or_identifier)
+      else:
+        path = PathParser.existing_path(maybe_path_or_identifier)
+    else:
+      if ":" in maybe_path_or_identifier:
+        raise argparse.ArgumentTypeError(
+            "Got unexpected short-form string "
+            f"{repr(maybe_path_or_identifier)}. \n"
+            "  - Use a complex browser config with separate "
+            "'browser' and 'driver' attributes, or\n"
+            "  - Use the short-form directly on the parent config attribute: \n"
+            f"   {{my-browser: '{maybe_path_or_identifier}'}}")
+      if maybe_path := cls._try_parse_short_name(identifier, driver_type):
+        return maybe_path
+      if cls._is_downloadable_identifier(maybe_path_or_identifier):
+        return maybe_path_or_identifier
+      if driver_type == BrowserDriverType.ANDROID:
+        if ANDROID_PACKAGE_RE.fullmatch(maybe_path_or_identifier):
+          return pth.AnyPosixPath(maybe_path_or_identifier)
+    if not path:
+      path = pth.try_resolve_existing_path(maybe_path_or_identifier)
+      if not path:
+        raise argparse.ArgumentTypeError(
+            f"Unknown browser path or short name: '{maybe_path_or_identifier}'")
+    if cls.is_supported_browser_path(path):
+      return path
+    raise argparse.ArgumentTypeError(f"Unsupported browser path='{path}'")
+
+  @classmethod
+  def _is_downloadable_identifier(cls, maybe_path_or_identifier: str) -> bool:
+    # TODO: handle remote platforms.
+    platform = plt.PLATFORM
+    if ChromeDownloader.is_valid(maybe_path_or_identifier, platform):
+      return True
+    if FirefoxDownloader.is_valid(maybe_path_or_identifier, platform):
+      return True
+    return False
+
+  @classmethod
+  def _try_parse_short_name(
+      cls, identifier: str,
+      driver_type: BrowserDriverType) -> Optional[pth.AnyPath]:
+    # We're not using a dict-based lookup here, since not all browsers are
+    # available on all platforms
+    # TODO: handle remote platforms.
+    platform = plt.PLATFORM
+    if identifier in ("chrome", "chrome-stable", "chr-stable", "chr"):
+      if driver_type == BrowserDriverType.ANDROID:
+        return pth.AnyPosixPath("com.android.chrome")
+      return browsers.Chrome.stable_path(platform)
+    if identifier in ("chrome-app"):
+      if driver_type == BrowserDriverType.ANDROID:
+        return pth.AnyPosixPath("com.google.android.apps.chrome")
+    if identifier in ("chrome-beta", "chr-beta"):
+      if driver_type == BrowserDriverType.ANDROID:
+        return pth.AnyPosixPath("com.chrome.beta")
+      return browsers.Chrome.beta_path(platform)
+    if identifier in ("chrome-dev", "chr-dev"):
+      if driver_type == BrowserDriverType.ANDROID:
+        return pth.AnyPosixPath("com.chrome.dev")
+      return browsers.Chrome.dev_path(platform)
+    if identifier in ("chrome-canary", "chr-canary"):
+      if driver_type == BrowserDriverType.ANDROID:
+        return pth.AnyPosixPath("com.chrome.canary")
+      return browsers.Chrome.canary_path(platform)
+    if identifier == "chromium":
+      if driver_type == BrowserDriverType.ANDROID:
+        return pth.AnyPosixPath("org.chromium.chrome")
+      return browsers.Chromium.default_path(platform)
+    if identifier in ("edge", "edge-stable"):
+      return browsers.Edge.stable_path(platform)
+    if identifier == "edge-beta":
+      return browsers.Edge.beta_path(platform)
+    if identifier == "edge-dev":
+      return browsers.Edge.dev_path(platform)
+    if identifier == "edge-canary":
+      return browsers.Edge.canary_path(platform)
+    if identifier in ("safari", "sf", "safari-stable", "sf-stable"):
+      return browsers.Safari.default_path(platform)
+    if identifier in ("safari-technology-preview", "safari-tp", "sf-tp", "tp"):
+      return browsers.Safari.technology_preview_path(platform)
+    if identifier in ("firefox", "firefox-stable", "ff", "ff-stable"):
+      return browsers.Firefox.default_path(platform)
+    if identifier in ("firefox-dev", "firefox-developer-edition", "ff-dev"):
+      return browsers.Firefox.developer_edition_path(platform)
+    if identifier in ("firefox-nightly", "ff-nightly", "ff-trunk"):
+      return browsers.Firefox.nightly_path(platform)
+    return None
+
+  @classmethod
+  def is_supported_browser_path(cls, path: pth.AnyPath) -> bool:
+    path_str = os.fspath(path).lower()
+    for short_name in SUPPORTED_BROWSER:
+      if short_name in path_str:
+        return True
+    return False
+
+  @classmethod
+  def _parse_inline_short_form(
+      cls, value: str
+  ) -> Tuple[DriverConfig, pth.AnyPathLike, Optional[NetworkConfig]]:
+    assert ":" in value
+    match = SHORT_FORM_RE.fullmatch(value)
+    if not match:
+      raise argparse.ArgumentTypeError(
+          f"Invalid browser short form: '{value}' \n"
+          "A browser path/identifier and "
+          "at least a driver or network preset have to be present")
+    driver_identifier = match.group("driver")
+    path_or_identifier = match.group("path")
+    network_identifier = match.group("network")
+    if not path_or_identifier:
+      raise argparse.ArgumentTypeError(
+          "Browser short form: missing path or browser identifier.")
+    driver = DriverConfig.default()
+    if driver_identifier is not None:
+      driver = cast(DriverConfig, DriverConfig.parse(match.group("driver")))
+    path: pth.AnyPathLike = cls._parse_path_or_identifier(
+        path_or_identifier, driver.type)
+    network = None
+    if network_identifier is not None:
+      network = NetworkConfig.parse_str(network_identifier)
+    return (driver, path, network)
+
+  @classmethod
+  def parse_text_io(cls, f: TextIO) -> BrowserConfig:
+    with exception.annotate(f"Loading browser config file: {f.name}"):
+      config = {}
+      with exception.annotate("Parsing hjson"):
+        config = hjson.load(f)
+      with exception.annotate(f"Parsing config file: {f.name}"):
+        return cls.parse_dict(config)
+    raise argparse.ArgumentTypeError(f"Could not parse : '{f.name}'")
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> BrowserConfig:
+    return cls.config_parser().parse(config)
+
+  @classmethod
+  def config_parser(cls) -> ConfigParser[BrowserConfig]:
+    parser = ConfigParser("BrowserConfig parser", cls)
+    parser.add_argument(
+        "browser",
+        aliases=("path",),
+        type=cls._parse_path_or_identifier,
+        required=True,
+        depends_on=("driver",))
+    parser.add_argument(
+        "driver", type=DriverConfig, default=DriverConfig.default())
+    parser.add_argument("network", required=False, type=NetworkConfig)
+    return parser
+
+  @property
+  def path(self) -> pth.AnyPath:
+    assert isinstance(self.browser, pth.AnyPath)
+    return self.browser
+
+  def get_platform(self) -> plt.Platform:
+    return self.driver.get_platform()
diff --git a/crossbench/cli/config/browser_variants.py b/crossbench/cli/config/browser_variants.py
new file mode 100644
index 0000000..1bd007e
--- /dev/null
+++ b/crossbench/cli/config/browser_variants.py
@@ -0,0 +1,755 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import contextlib
+import dataclasses
+import functools
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, Final, Iterator, List, Optional,
+                    Sequence, Set, TextIO, Tuple, Type, Union, cast)
+
+import hjson
+from immutabledict import immutabledict
+from ordered_set import OrderedSet
+
+import crossbench.browsers.all as browsers
+from crossbench import exception
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.browser_helper import convert_flags_to_label
+from crossbench.browsers.chrome.downloader import ChromeDownloader
+from crossbench.browsers.firefox.downloader import FirefoxDownloader
+from crossbench.browsers.settings import Settings
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.driver import BrowserDriverType
+from crossbench.cli.config.network import NetworkConfig
+from crossbench.config import ConfigError, ConfigObject
+from crossbench.flags.base import Flags
+from crossbench.flags.chrome import ChromeFlags
+from crossbench.network.base import Network
+from crossbench.parse import LateArgumentError, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  FlagGroupItemT = Optional[Tuple[str, Optional[str]]]
+  BrowserLookupTableT = Dict[str, Tuple[Type[Browser], "BrowserConfig"]]
+
+
+@contextlib.contextmanager
+def late_argument_type_error_wrapper(flag: str) -> Iterator[None]:
+  """Converts raised ValueError and ArgumentTypeError to LateArgumentError
+  that are associated with the given flag.
+  """
+  try:
+    yield
+  except Exception as e:
+    raise LateArgumentError(flag, str(e)) from e
+
+
+def _flags_to_label(flags: Flags) -> str:
+  return convert_flags_to_label(*flags)
+
+
+FlagItemT = Tuple[str, Optional[str]]
+FlagVariantsDictT = Dict[str, List[str]]
+
+DEFAULT_LABEL: Final[str] = "default"
+
+
+@dataclasses.dataclass(frozen=True)
+class FlagsVariantConfig:
+  label: str
+  index: int = 0
+  flags: Flags = dataclasses.field(default_factory=lambda: Flags().freeze())
+
+  @classmethod
+  def parse(cls, name: str, index: int, data: Any) -> FlagsVariantConfig:
+    return cls(name, index, Flags.parse(data).freeze())
+
+  def merge_copy(self,
+                 other: FlagsVariantConfig,
+                 label: Optional[str] = None,
+                 index: int = -1) -> FlagsVariantConfig:
+    index = self.index if index < 0 else index
+    new_label = label or f"{self.label}_{other.label}"
+    return FlagsVariantConfig(new_label, index,
+                              self.flags.merge_copy(other.flags).freeze())
+
+  def __hash__(self) -> int:
+    return hash(self.flags)
+
+  def __eq__(self, other: Any) -> bool:
+    if not isinstance(other, FlagsVariantConfig):
+      return False
+    return self.flags == other.flags
+
+
+try:
+  FlagsGroupConfigTuple = tuple[FlagsVariantConfig, ...]
+except:  # pylint: disable=bare-except
+  # Python 3.8 fallback
+  FlagsGroupConfigTuple = tuple
+
+
+class FlagsGroupConfig(FlagsGroupConfigTuple):
+  """
+  Config container for a list of FlagsVariantConfig:
+  FlagsGroupConfig(
+    FlagsVariantConfig("default"),
+    FlagsVariantConfig("max_opt_1", "--js-flags='--max-opt=1'),
+    FlagsVariantConfig("max_opt_2", "--js-flags='--max-opt=2'),
+    ...
+  )
+  """
+
+  @classmethod
+  def parse(cls, data: Any) -> FlagsGroupConfig:
+    if data is None:
+      return FlagsGroupConfig()
+    if isinstance(data, str):
+      return cls.parse_str(data)
+    if isinstance(data, dict):
+      return cls.parse_dict(data)
+    if isinstance(data, (list, tuple)):
+      return cls.parse_sequence(data)
+    raise ConfigError(f"Invalid type {type(data)}: {repr(data)}")
+
+  @classmethod
+  def parse_dict(cls, config: Dict) -> FlagsGroupConfig:
+    if not config:
+      return FlagsGroupConfig()
+    all_flag_keys = all(key.startswith("-") for key in config.keys())
+    all_str_values = all(isinstance(value, str) for value in config.values())
+    if not all_flag_keys:
+      return cls.parse_dict_with_labels(config)
+    if all_str_values:
+      return cls.parse_dict_simple(config)
+    return cls._parse_variants_dict(config)
+
+  @classmethod
+  def parse_dict_with_labels(cls, config: Dict) -> FlagsGroupConfig:
+    variants: OrderedSet[FlagsVariantConfig] = OrderedSet()
+    logging.debug("Using custom flag group labels")
+    for label, value in config.items():
+      with exception.annotate_argparsing(
+          f"Parsing flag variant ...[{repr(label)}]:"):
+        variant = FlagsVariantConfig.parse(label, len(variants), value)
+        if variant in variants:
+          raise ConfigError(f"Duplicate flag variant: {value}")
+        variants.add(variant)
+    return FlagsGroupConfig(tuple(variants))
+
+  @classmethod
+  def parse_dict_simple(cls, config: Dict) -> FlagsGroupConfig:
+    logging.debug("Using single flag group dict")
+    variants = (FlagsVariantConfig.parse(DEFAULT_LABEL, 0, config),)
+    return FlagsGroupConfig(variants)
+
+  @classmethod
+  def _parse_variants_dict(cls, data: Dict[str, Any]) -> FlagsGroupConfig:
+    # data == {
+    #  "--flag": None,
+    #  "--flag-b": "custom flag value",
+    #  "--flag-c": (None, "value 2", "value 3"),
+    # }
+    cls._validate_variants_dict(data)
+    per_flag_groups: List[FlagsGroupConfig] = []
+    for flag_name, flag_data in data.items():
+      per_flag_groups.append(cls._dict_variant_to_group(flag_name, flag_data))
+
+    variants = per_flag_groups[0]
+    for next_variant in per_flag_groups[1:]:
+      variants = variants.product(next_variant)
+    return variants
+
+  @classmethod
+  def _validate_variants_dict(cls, data: Dict[str, Any]) -> None:
+    flags = Flags()
+    for flag_name, flag_value in data.items():
+      with exception.annotate_argparsing(
+          f"Parsing flag variant ...[{flag_name}]:"):
+        flags.set(flag_name)
+        if flag_value is None:
+          continue
+        if not isinstance(flag_value, (str, list, tuple)):
+          raise ConfigError(
+              f"Invalid flag variant value (None, str or sequence): "
+              f"{flag_name}={repr(flag_value)}")
+        if isinstance(flag_value, (list, tuple)):
+          ObjectParser.unique_sequence(
+              flag_value, f"flag {repr(flag_name)} variant values", ConfigError)
+
+  @classmethod
+  def _dict_variant_to_group(cls, flag_name: str,
+                             data: Any) -> FlagsGroupConfig:
+    if data is None:
+      return cls.parse_str(flag_name)
+    if isinstance(data, str):
+      data_str: str = data.strip()
+      if not data_str:
+        return cls.parse_str(flag_name)
+      data = (data_str,)
+    assert isinstance(data, (list, tuple)), "Invalid flag variant type"
+    flags: OrderedSet[Optional[Flags]] = OrderedSet()
+    for variant in data:
+      if variant is None:
+        flag = None
+      elif not variant.strip():
+        flag = Flags((flag_name,))
+      else:
+        cls._validate_variant_flag(flag_name, variant)
+        flag = Flags({flag_name: variant})
+      if flag in flags:
+        raise ConfigError("Same flag variant was specified more than once: "
+                          f"{repr(flag)} for entry {repr(flag_name)}")
+      flags.add(flag)
+    return cls.parse_sequence(flags)
+
+  @classmethod
+  def _validate_variant_flag(cls, flag_name: str, flag_value: Any) -> None:
+    if flag_value == "None,":
+      raise ConfigError("Please use null (from json) instead of "
+                        f"None (from python) for flag {repr(flag_name)}")
+
+  @classmethod
+  def parse_sequence(cls, data: Sequence) -> FlagsGroupConfig:
+    variants: List[FlagsVariantConfig] = []
+    duplicates: Set[str] = set()
+    for flag_data in data:
+      if not flag_data:
+        flags = Flags()
+      else:
+        flags = Flags.parse(flag_data)
+      if flag_data in duplicates:
+        raise ConfigError(f"Duplicate variant: {flags}")
+      duplicates.add(flag_data)
+      variants.append(
+          FlagsVariantConfig(_flags_to_label(flags), len(variants), flags))
+    return FlagsGroupConfig(tuple(variants))
+
+  @classmethod
+  def parse_str(cls, value: str) -> FlagsGroupConfig:
+    if not value.strip():
+      return FlagsGroupConfig()
+    variants = (FlagsVariantConfig.parse(DEFAULT_LABEL, 0, value),)
+    return FlagsGroupConfig(variants)
+
+  def product(self, *args: FlagsGroupConfig) -> FlagsGroupConfig:
+    return functools.reduce(lambda a, b: a.inner_product(b), args, self)
+
+  def inner_product(self, other: FlagsGroupConfig) -> FlagsGroupConfig:
+    """Create a new FlagsGroupConfig as the combination of
+    self.variants x other.variants"""
+    new_variants: List[FlagsVariantConfig] = []
+    new_labels: Set[str] = set()
+    if not other:
+      return self
+    if not self:
+      return other
+    for variant in self:
+      for variant_other in other:
+        new_label = self._unique_product_label(new_labels, variant,
+                                               variant_other)
+        new_labels.add(new_label)
+        new_variant: FlagsVariantConfig = variant.merge_copy(
+            variant_other, index=len(new_variants), label=new_label)
+        new_variants.append(new_variant)
+
+    return FlagsGroupConfig(tuple(new_variants))
+
+  def _unique_product_label(self, label_set: Set[str],
+                            variant_a: FlagsVariantConfig,
+                            variant_b: FlagsVariantConfig) -> str:
+    default = f"{variant_a.label}_{variant_b.label}"
+    if variant_a.label == DEFAULT_LABEL:
+      default = variant_b.label
+    if variant_b.label == DEFAULT_LABEL:
+      default = variant_a.label
+    label = default
+    if not variant_a.flags:
+      label = variant_b.label
+    if not variant_b.flags:
+      label = variant_a.label
+    if label not in label_set:
+      return label
+    if default not in label_set:
+      return default
+    return f"{default}_{len(label_set)}"
+
+
+class FlagsConfig(ConfigObject, immutabledict[str, FlagsGroupConfig]):
+
+  @classmethod
+  def parse_str(cls, value: str) -> FlagsConfig:
+    if not value:
+      raise ConfigError("Cannot parse empty string")
+    return cls({"default": FlagsGroupConfig.parse_str(value)})
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> FlagsConfig:
+    groups: Dict[str, FlagsGroupConfig] = {}
+    for group_name, group_data in config.items():
+      with exception.annotate(f"Parsing flag-group: flags[{repr(group_name)}]"):
+        groups[group_name] = FlagsGroupConfig.parse(group_data)
+    return cls(groups)
+
+
+class BrowserVariantsConfig:
+
+  @classmethod
+  def from_cli_args(cls, args: argparse.Namespace) -> BrowserVariantsConfig:
+    browser_config = BrowserVariantsConfig()
+    if args.browser_config:
+      with late_argument_type_error_wrapper("--browser-config"):
+        path = args.browser_config.expanduser()
+        with path.open(encoding="utf-8") as f:
+          browser_config.parse_text_io(f, args)
+    else:
+      with late_argument_type_error_wrapper("--browser"):
+        browser_config.parse_args(args)
+    return browser_config
+
+  def __init__(self,
+               raw_config_data: Optional[Dict[str, Any]] = None,
+               browser_lookup_override: Optional[BrowserLookupTableT] = None,
+               args: Optional[argparse.Namespace] = None):
+    self.flags_config: FlagsConfig = FlagsConfig()
+    self._variants: List[Browser] = []
+    self._unique_names: Set[str] = set()
+    self._browser_lookup_override = browser_lookup_override or {}
+    if raw_config_data:
+      assert args, "args object needed when loading from dict."
+      self.parse_dict(raw_config_data, args)
+
+  @property
+  def variants(self) -> List[Browser]:
+    assert self._variants
+    return self._variants
+
+  def parse_text_io(self, f: TextIO, args: argparse.Namespace) -> None:
+    with exception.annotate(f"Loading browser config file: {f.name}"):
+      config = {}
+      with exception.annotate("Parsing hjson"):
+        config = hjson.load(f)
+      with exception.annotate(f"Parsing config file: {f.name}"):
+        self.parse_dict(config, args)
+
+  def parse_dict(self, config: Dict[str, Any],
+                 args: argparse.Namespace) -> None:
+    with exception.annotate(
+        f"Parsing {type(self).__name__} dict", throw_cls=ConfigError):
+      if "flags" in config:
+        with exception.annotate("Parsing config['flags']"):
+          self.flags_config = FlagsConfig.parse(config["flags"])
+      if "browsers" not in config:
+        raise ConfigError("Config does not provide a 'browsers' dict.")
+      if not config["browsers"]:
+        raise ConfigError("Config contains empty 'browsers' dict.")
+      with exception.annotate("Parsing config['browsers']"):
+        self._parse_browsers(config["browsers"], args)
+
+  def parse_args(self, args: argparse.Namespace) -> None:
+    browser_list: List[BrowserConfig] = args.browser or [
+        BrowserConfig.default()
+    ]
+    assert isinstance(browser_list, list)
+    browser_list = ObjectParser.unique_sequence(browser_list,
+                                                "--browser arguments")
+    for i, browser in enumerate(browser_list):
+      with exception.annotate(f"Append browser {i}"):
+        self._append_browser(args, browser)
+    self._verify_browser_flags(args)
+    self._ensure_unique_browser_names()
+
+  def _parse_browsers(self, data: Dict[str, Any],
+                      args: argparse.Namespace) -> None:
+    for name, browser_config in data.items():
+      with exception.annotate(f"Parsing browsers[{repr(name)}]"):
+        self._parse_browser(name, browser_config, args)
+    self._ensure_unique_browser_names()
+
+  def _parse_browser(self, name: str, raw_browser_data: Any,
+                     args: argparse.Namespace) -> None:
+    if isinstance(raw_browser_data, (dict, str)):
+      return self._parse_browser_dict(name, raw_browser_data, args)
+    raise argparse.ArgumentTypeError(
+        f"Expected str or dict, got {type(raw_browser_data).__name__}: "
+        f"{repr(raw_browser_data)}")
+
+  def _parse_browser_dict(self, name: str,
+                          raw_browser_data: Union[str, Dict[str, Any]],
+                          args: argparse.Namespace) -> None:
+    path_or_identifier: Optional[str] = None
+    if isinstance(raw_browser_data, dict):
+      path_or_identifier = raw_browser_data.get("path")
+    else:
+      path_or_identifier = raw_browser_data
+    browser_cls: Type[Browser]
+    if path_or_identifier and (path_or_identifier
+                               in self._browser_lookup_override):
+      browser_cls, browser_config = self._browser_lookup_override[
+          path_or_identifier]
+    else:
+      browser_config = self._maybe_downloaded_binary(
+          cast(BrowserConfig, BrowserConfig.parse(raw_browser_data)))
+      browser_cls = self.get_browser_cls(browser_config)
+    if not browser_config.driver.type.is_remote and (not pth.LocalPath(
+        browser_config.path).exists()):
+      raise ConfigError(
+          f"browsers[{repr(name)}].path='{browser_config.path}' does not exist."
+      )
+    flag_variants: FlagsGroupConfig = self._get_browser_variants(
+        name, raw_browser_data)
+    self._log_browser_variants(name, flag_variants)
+    browser_platform = self._get_browser_platform(browser_config)
+    labels_lookup = self._create_unique_variant_labels(name, raw_browser_data,
+                                                       flag_variants)
+    for variant in flag_variants:
+      label = labels_lookup[variant]
+      browser_flags = browser_cls.default_flags(variant.flags)
+      with exception.annotate_argparsing("Creating network config"):
+        network_config = browser_config.network or args.network
+        network = self._get_browser_network(network_config, browser_platform)
+      # TODO: move the browser instantiation to a separate step and only
+      # create BrowserConfig objects first.
+      # pytype: disable=not-instantiable
+      settings = Settings(
+          flags=browser_flags,
+          network=network,
+          driver_path=args.driver_path or browser_config.driver.path,
+          # TODO: support all args in the browser.config file
+          viewport=args.viewport,
+          splash_screen=args.splash_screen,
+          platform=browser_platform,
+          secrets=args.secrets.as_dict(),
+          driver_logging=args.driver_logging,
+          wipe_system_user_data=args.wipe_system_user_data,
+          http_request_timeout=args.http_request_timeout)
+      browser_instance = browser_cls(
+          label=label, path=browser_config.path, settings=settings)
+      # pytype: enable=not-instantiable
+      self._variants.append(browser_instance)
+
+  def _flags_to_label(self, name: str, flags: Flags) -> str:
+    return f"{name}_{_flags_to_label(flags)}"
+
+  def _create_unique_variant_labels(self, name: str,
+                                    raw_browser_data: Union[str, Dict[str,
+                                                                      Any]],
+                                    flag_variants: FlagsGroupConfig) -> Dict:
+    labels_lookup: Dict[FlagsVariantConfig, str] = {}
+    group_labels = set(variant.label for variant in flag_variants)
+    use_unique_variant_label = len(group_labels) == len(flag_variants)
+
+    for variant in flag_variants:
+      label = name
+      if isinstance(raw_browser_data, dict):
+        label = raw_browser_data.get("label", name)
+      if len(flag_variants) > 1:
+        if use_unique_variant_label:
+          label = f"{name}_{variant.label}"
+        else:
+          # TODO: This case might not happen anymore
+          label = self._flags_to_label(name, variant.flags)
+      if not self._check_unique_label(label):
+        raise ConfigError(f"browsers[{repr(name)}] has non-unique label: "
+                          f"{repr(label)}")
+      labels_lookup[variant] = label
+    return labels_lookup
+
+  def _check_unique_label(self, label: str) -> bool:
+    if label in self._unique_names:
+      return False
+    self._unique_names.add(label)
+    return True
+
+  def _get_browser_variants(
+      self, browser_name: str,
+      raw_browser_data: Union[str, Dict[str, Any]]) -> FlagsGroupConfig:
+    default_variant = FlagsVariantConfig(DEFAULT_LABEL)
+    flag_variants = FlagsGroupConfig((default_variant,))
+    if not isinstance(raw_browser_data, dict):
+      return flag_variants
+    flag_groups: List[FlagsGroupConfig] = []
+    with exception.annotate(f"Parsing browsers[{repr(browser_name)}].flags"):
+      flag_groups = self._parse_browser_flags(browser_name, raw_browser_data)
+    with exception.annotate(
+        f"Expand browsers[{repr(browser_name)}].flags into full variants"):
+      flag_variants = flag_variants.product(*flag_groups)
+    return flag_variants
+
+  def _parse_browser_flags(self, browser_name: str,
+                           data: Dict[str, Any]) -> List[FlagsGroupConfig]:
+    flag_group_names = data.get("flags", [])
+    if isinstance(flag_group_names, str):
+      flag_group_names = [flag_group_names]
+    self._validate_flags(browser_name, flag_group_names)
+    inline_flags = Flags()
+    flag_groups: List[FlagsGroupConfig] = []
+    for flag_group_name in flag_group_names:
+      if flag_group_name.startswith("--"):
+        inline_flags.update(Flags.parse(flag_group_name))
+      else:
+        maybe_flag_group = self.flags_config.get(flag_group_name, None)
+        if maybe_flag_group is None:
+          raise ConfigError(
+              f"group={repr(flag_group_name)} "
+              f"for browser={repr(browser_name)} does not exist.\n"
+              f"Choices are: {list(self.flags_config.keys())}")
+        flag_groups.append(maybe_flag_group)
+    if inline_flags:
+      flag_data = {"inline": inline_flags}
+      flag_groups.append(FlagsGroupConfig.parse_dict(flag_data))
+    return flag_groups
+
+  def _validate_flags(self, browser_name: str, flag_group_names: List[str]):
+    if isinstance(flag_group_names, str):
+      flag_group_names = [flag_group_names]
+    if not isinstance(flag_group_names, list):
+      raise ConfigError(
+          f"'flags' is not a list for browser={repr(browser_name)}")
+    seen_flag_group_names: Set[str] = set()
+    for flag_group_name in flag_group_names:
+      if flag_group_name in seen_flag_group_names:
+        raise ConfigError(f"Duplicate group name {repr(flag_group_name)} "
+                          f"for browser={repr(browser_name)}")
+
+  def _log_browser_variants(self, name: str,
+                            flag_variants: FlagsGroupConfig) -> None:
+    logging.info("SELECTED BROWSER: '%s' with %s flag variants:", name,
+                 len(flag_variants))
+    for i, variant in enumerate(flag_variants):
+      logging.info("   %s: %s", i, variant.flags)
+
+  def get_browser_cls(self, browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    path: pth.AnyPath = browser_config.path
+    assert not isinstance(path, str), "Invalid path"
+    if not BrowserConfig.is_supported_browser_path(path):
+      raise argparse.ArgumentTypeError(f"Unsupported browser path='{path}'")
+    path_str = str(browser_config.path).lower()
+    if "safari" in path_str:
+      return self._get_safari_browser_cls(browser_config)
+    if "chrome" in path_str:
+      return self._get_chrome_browser_cls(browser_config)
+    if "chromium" in path_str:
+      return self._get_chromium_browser_cls(browser_config)
+    if "firefox" in path_str:
+      if driver == BrowserDriverType.WEB_DRIVER:
+        return browsers.FirefoxWebDriver
+    if "edge" in path_str:
+      return browsers.EdgeWebDriver
+    raise argparse.ArgumentTypeError(f"Unsupported browser path='{path}'")
+
+  def _get_safari_browser_cls(self,
+                              browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    if driver == BrowserDriverType.IOS:
+      return browsers.SafariWebdriverIOS
+    if driver == BrowserDriverType.WEB_DRIVER:
+      return browsers.SafariWebDriver
+    if driver == BrowserDriverType.APPLE_SCRIPT:
+      return browsers.SafariAppleScript
+    raise argparse.ArgumentTypeError(f"Unsupported Safari driver: {driver}")
+
+  def _get_chrome_browser_cls(self,
+                              browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    if driver == BrowserDriverType.WEB_DRIVER:
+      return browsers.ChromeWebDriver
+    if driver == BrowserDriverType.APPLE_SCRIPT:
+      return browsers.ChromeAppleScript
+    if driver == BrowserDriverType.ANDROID:
+      if browsers.LocalChromeWebDriverAndroid.is_apk_helper(
+          browser_config.path):
+        return browsers.LocalChromeWebDriverAndroid
+      return browsers.ChromeWebDriverAndroid
+    if driver == BrowserDriverType.LINUX_SSH:
+      return browsers.ChromeWebDriverSsh
+    if driver == BrowserDriverType.CHROMEOS_SSH:
+      return browsers.ChromeWebDriverChromeOsSsh
+    raise argparse.ArgumentTypeError(f"Unsupported Chrome driver: {driver}")
+
+  def _get_chromium_browser_cls(self,
+                                browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    # TODO: technically this should be ChromiumWebDriver
+    if driver == BrowserDriverType.WEB_DRIVER:
+      return browsers.ChromiumWebDriver
+    if driver == BrowserDriverType.APPLE_SCRIPT:
+      return browsers.ChromiumAppleScript
+    if driver == BrowserDriverType.ANDROID:
+      if browsers.LocalChromiumWebDriverAndroid.is_apk_helper(
+          browser_config.path):
+        return browsers.LocalChromiumWebDriverAndroid
+      return browsers.ChromiumWebDriverAndroid
+    if driver == BrowserDriverType.LINUX_SSH:
+      return browsers.ChromiumWebDriverSsh
+    if driver == BrowserDriverType.CHROMEOS_SSH:
+      return browsers.ChromiumWebDriverChromeOsSsh
+    raise argparse.ArgumentTypeError(f"Unsupported chromium driver: {driver}")
+
+  def _get_browser_platform(self,
+                            browser_config: BrowserConfig) -> plt.Platform:
+    return browser_config.get_platform()
+
+  def _ensure_unique_browser_names(self) -> None:
+    if self._has_unique_variant_names():
+      return
+    # Expand to full version names
+    for browser in self._variants:
+      browser.unique_name = (
+          f"{browser.type_name}_{browser.version}_{browser.label}")
+    if self._has_unique_variant_names():
+      return
+    logging.info("Got unique browser names and versions, "
+                 "please use --browser-config for more meaningful names")
+    # Last resort, add index
+    for index, browser in enumerate(self._variants):
+      browser.unique_name += f"_{index}"
+    assert self._has_unique_variant_names()
+
+  def _has_unique_variant_names(self) -> bool:
+    names = [browser.unique_name for browser in self._variants]
+    unique_names = set(names)
+    return len(unique_names) == len(names)
+
+  def _extract_chrome_flags(self,
+                            args: argparse.Namespace) -> List[ChromeFlags]:
+    initial_flags = ChromeFlags()
+
+    if args.enable_features:
+      initial_flags["--enable-features"] = args.enable_features
+    if args.disable_features:
+      initial_flags["--disable-features"] = args.disable_features
+    if args.enable_field_trial_config is True:
+      initial_flags.set("--enable-field-trial-config")
+    if args.enable_field_trial_config is False:
+      initial_flags.set("--disable-field-trial-config")
+
+    flags_sets = [initial_flags]
+    if not args.js_flags:
+      return flags_sets
+
+    def copy_and_set_js_flags(flags: ChromeFlags,
+                              js_flags_str: str) -> ChromeFlags:
+      flags = flags.copy()
+      for js_flag in js_flags_str.split(","):
+        js_flag_name, js_flag_value = Flags.split(js_flag.lstrip())
+        flags.js_flags.set(js_flag_name, js_flag_value)
+      return flags
+
+    flags_sets = [
+        copy_and_set_js_flags(flags, js_flags_str)
+        for flags in flags_sets
+        for js_flags_str in args.js_flags
+    ]
+    return flags_sets
+
+  def _verify_browser_flags(self, args: argparse.Namespace) -> None:
+    for chrome_flags in self._extract_chrome_flags(args):
+      for flag_name, value in chrome_flags.items():
+        if not value:
+          continue
+        for browser in self._variants:
+          if not browser.attributes.is_chromium_based:
+            raise argparse.ArgumentTypeError(
+                f"Used chrome/chromium-specific flags {flag_name} "
+                f"for non-chrome {browser.unique_name}.\n"
+                "Use --browser-config for complex variants.")
+    browser_types = set(browser.type_name for browser in self._variants)
+    if len(browser_types) == 1:
+      return
+    if args.driver_path:
+      raise argparse.ArgumentTypeError(
+          f"Cannot use custom --driver-path='{args.driver_path}' "
+          f"for multiple browser {browser_types}.")
+    if args.other_browser_args:
+      raise argparse.ArgumentTypeError(
+          f"Multiple browser types {browser_types} "
+          "cannot be used with common extra browser flags: "
+          f"{args.other_browser_args}.\n"
+          "Use --browser-config for complex variants.")
+
+  def _maybe_downloaded_binary(self,
+                               browser_config: BrowserConfig) -> BrowserConfig:
+    path_or_identifier = browser_config.browser
+    if isinstance(path_or_identifier, pth.AnyPath):
+      return browser_config
+    browser_platform = self._get_browser_platform(browser_config)
+    if ChromeDownloader.is_valid(path_or_identifier, browser_platform):
+      downloaded = ChromeDownloader.load(path_or_identifier, browser_platform)
+    elif FirefoxDownloader.is_valid(path_or_identifier, browser_platform):
+      downloaded = FirefoxDownloader.load(path_or_identifier, browser_platform)
+    else:
+      raise ValueError(
+          f"No version-download support for browser: {path_or_identifier}")
+    return BrowserConfig(downloaded, browser_config.driver)
+
+  def _append_browser(self, args: argparse.Namespace,
+                      browser_config: BrowserConfig) -> None:
+    assert browser_config, "Expected non-empty BrowserConfig."
+    browser_config = self._maybe_downloaded_binary(browser_config)
+    browser_cls: Type[Browser] = self.get_browser_cls(browser_config)
+    path: pth.AnyPath = browser_config.path
+    flags_sets = [browser_cls.default_flags()]
+
+    if browser_config.driver.is_local and not pth.LocalPath(path).exists():
+      raise argparse.ArgumentTypeError(f"Browser binary does not exist: {path}")
+
+    if issubclass(browser_cls, browsers.Chromium):
+      assert all(isinstance(flags, ChromeFlags) for flags in flags_sets)
+
+      extra_flag_sets = self._extract_chrome_flags(args)
+      flags_sets = [
+          flags.merge_copy(extra_flags)
+          for flags in flags_sets
+          for extra_flags in extra_flag_sets
+      ]
+
+    for flag_str in args.other_browser_args:
+      flag_name, flag_value = Flags.split(flag_str)
+      for flags in flags_sets:
+        flags.set(flag_name, flag_value)
+
+    browser_platform = self._get_browser_platform(browser_config)
+    with exception.annotate_argparsing("Creating network config"):
+      network_config = browser_config.network or args.network
+      network = self._get_browser_network(network_config, browser_platform)
+
+    name = f"{browser_platform}_{len(self._unique_names)}"
+    for flags in flags_sets:
+      label = name
+      if len(flags_sets) > 1:
+        label = self._flags_to_label(label, flags)
+      assert self._check_unique_label(label), f"Non-unique label: {label}"
+      settings = Settings(
+          flags=flags,
+          network=network,
+          driver_path=args.driver_path or browser_config.driver.path,
+          viewport=args.viewport,
+          splash_screen=args.splash_screen,
+          platform=browser_platform,
+          secrets=args.secrets.as_dict(),
+          driver_logging=args.driver_logging,
+          wipe_system_user_data=args.wipe_system_user_data,
+          http_request_timeout=args.http_request_timeout)
+
+      browser_instance = browser_cls(  # pytype: disable=not-instantiable # pylint: disable=abstract-class-instantiated
+          label=label,
+          path=path,
+          settings=settings)
+      logging.info("SELECTED BROWSER: name=%s path='%s' ",
+                   browser_instance.unique_name, path)
+      self._variants.append(browser_instance)
+
+  def _get_browser_network(self, network_config: Union[pth.LocalPath,
+                                                       NetworkConfig],
+                           browser_platform: plt.Platform) -> Network:
+    if not isinstance(network_config, NetworkConfig):
+      network_config = NetworkConfig.parse(network_config)
+    return network_config.create(browser_platform)
diff --git a/crossbench/cli/config/driver.py b/crossbench/cli/config/driver.py
new file mode 100644
index 0000000..6496a63
--- /dev/null
+++ b/crossbench/cli/config/driver.py
@@ -0,0 +1,361 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import enum
+import logging
+import re
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, cast
+
+from immutabledict import immutabledict
+
+from crossbench import compat
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.config import ConfigObject, ConfigParser
+from crossbench.parse import NumberParser, ObjectParser, PathParser
+from crossbench.plt.android_adb import Adb, AndroidAdbPlatform, adb_devices
+from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
+from crossbench.plt.ios import ios_devices
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath, LocalPath
+
+
+@enum.unique
+class BrowserDriverType(compat.StrEnumWithHelp):
+  WEB_DRIVER = ("WebDriver", "Use Selenium with webdriver, for local runs.")
+  APPLE_SCRIPT = ("AppleScript", "Use AppleScript, for local macOS runs only")
+  ANDROID = ("Android",
+             "Use Webdriver for android. Allows to specify additional settings")
+  IOS = ("iOS", "Placeholder, unsupported at the moment")
+  LINUX_SSH = ("Remote Linux",
+               "Use remote webdriver and execute commands via SSH")
+  CHROMEOS_SSH = ("Remote ChromeOS",
+                  "Use remote ChromeDriver and execute commands via SSH")
+
+  @classmethod
+  def default(cls) -> BrowserDriverType:
+    return cls.WEB_DRIVER
+
+  @classmethod
+  def parse(cls, value: Any) -> BrowserDriverType:
+    if isinstance(value, cls):
+      return value
+    if value == "":
+      return BrowserDriverType.default()
+    value = ObjectParser.non_empty_str(value, "driver_type")
+    identifier = value.lower()
+    if identifier in ("selenium", "webdriver"):
+      return BrowserDriverType.WEB_DRIVER
+    if identifier in ("applescript", "osa"):
+      return BrowserDriverType.APPLE_SCRIPT
+    if identifier in ("android", "adb"):
+      return BrowserDriverType.ANDROID
+    if identifier in ("iphone", "ios"):
+      return BrowserDriverType.IOS
+    if identifier == "ssh":
+      return BrowserDriverType.LINUX_SSH
+    if identifier == "chromeos-ssh":
+      return BrowserDriverType.CHROMEOS_SSH
+    raise argparse.ArgumentTypeError(f"Unknown driver type: {repr(value)}")
+
+  @property
+  def is_remote(self):
+    if self.name in ("ANDROID", "CHROMEOS_SSH", "LINUX_SSH"):
+      return True
+    return False
+
+  @property
+  def is_local(self):
+    return not self.is_remote
+
+
+class AmbiguousDriverIdentifier(argparse.ArgumentTypeError):
+  pass
+
+
+IOS_UUID_RE = re.compile(r"[0-9A-Z]+-[0-9A-Z-]+")
+
+
+@dataclasses.dataclass(frozen=True)
+class DriverConfig(ConfigObject):
+  type: BrowserDriverType = BrowserDriverType.default()
+  path: Optional[AnyPath] = None
+  device_id: Optional[str] = None
+  adb_bin: Optional[AnyPath] = None
+  settings: Optional[immutabledict] = None
+
+  @classmethod
+  def default(cls) -> DriverConfig:
+    return cls(BrowserDriverType.default())
+
+  @classmethod
+  def parse_str(cls, value: str) -> DriverConfig:
+    if not value:
+      raise argparse.ArgumentTypeError("Cannot parse empty string")
+    # Variant 1: $PATH
+    path: Optional[LocalPath] = pth.try_resolve_existing_path(value)
+    driver_type: BrowserDriverType = BrowserDriverType.default()
+    if path:
+      if path.stat().st_size == 0:
+        raise argparse.ArgumentTypeError(f"Driver path is empty file: {path}")
+    else:
+      if cls.value_has_path_prefix(value):
+        raise argparse.ArgumentTypeError(
+            f"Driver path does not exist: {repr(value)}")
+      if value[0] == "{":
+        # Variant 1: full hjson config
+        return cls.parse_inline_hjson(value)
+      # Variant 2: $DRIVER_TYPE
+      try:
+        driver_type = BrowserDriverType.parse(value)
+      except argparse.ArgumentTypeError as original_error:
+        try:
+          return cls.parse_short_settings(value, plt.PLATFORM)
+        except AmbiguousDriverIdentifier:  # pylint: disable=try-except-raise
+          raise
+        except ValueError as e:
+          logging.debug("Parsing short inline driver config failed: %s", e)
+          raise original_error from e
+    return DriverConfig(driver_type, path)
+
+  @classmethod
+  def parse_short_settings(cls, value: str,
+                           platform: plt.Platform) -> DriverConfig:
+    """Check for short versions and multiple candidates"""
+    logging.debug("Looking for driver candidates: %s", value)
+    candidate: Optional[DriverConfig]
+    if candidate := cls.try_parse_adb_settings(value, platform):
+      return candidate
+    if platform.is_macos:
+      if candidate := cls.try_parse_ios_settings(value, platform):
+        return candidate
+    # TODO: add more custom parsing here
+    raise ValueError("Unknown setting")
+
+  @classmethod
+  def try_parse_adb_settings(cls, value: str,
+                             platform: plt.Platform) -> Optional[DriverConfig]:
+    candidate_serials: List[str] = []
+    pattern: re.Pattern = cls.compile_search_pattern(value)
+    for serial, info in adb_devices(platform).items():
+      if pattern.fullmatch(serial):
+        candidate_serials.append(serial)
+        continue
+      print(info)
+      for key, info_value in info.items():
+        if (pattern.fullmatch(f"{key}:{info_value}") or
+            pattern.fullmatch(info_value)):
+          candidate_serials.append(serial)
+          break
+    if len(candidate_serials) > 1:
+      raise AmbiguousDriverIdentifier(
+          "Found more than one adb devices matching "
+          f"'{value}': {candidate_serials}")
+    if len(candidate_serials) == 0:
+      logging.debug("No matching adb devices found.")
+      return None
+    assert len(candidate_serials) == 1
+    return DriverConfig(
+        BrowserDriverType.ANDROID, device_id=candidate_serials[0])
+
+  @classmethod
+  def try_parse_ios_settings(cls, value: str,
+                             platform: plt.Platform) -> Optional[DriverConfig]:
+    candidate_serials: List[str] = []
+    pattern: re.Pattern = cls.compile_search_pattern(value)
+    for uuid, device_info in ios_devices(platform).items():
+      if pattern.fullmatch(uuid):
+        candidate_serials.append(uuid)
+        continue
+      if pattern.fullmatch(device_info.name):
+        candidate_serials.append(uuid)
+        continue
+    if len(candidate_serials) > 1:
+      raise AmbiguousDriverIdentifier(
+          "Found more than one ios devices matching "
+          f"'{value}': {candidate_serials}")
+    if len(candidate_serials) == 0:
+      logging.debug("No matching ios devices found.")
+      return None
+    assert len(candidate_serials) == 1
+    return DriverConfig(BrowserDriverType.IOS, device_id=candidate_serials[0])
+
+  @classmethod
+  def compile_search_pattern(cls, maybe_pattern: str) -> re.Pattern:
+    try:
+      return re.compile(maybe_pattern)
+    except Exception as e:  # pylint: disable=broad-except
+      logging.debug(
+          "Falling back to full string match for "
+          "invalid regexp search pattern: %s %s", maybe_pattern, e)
+      return re.compile(re.escape(maybe_pattern))
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> DriverConfig:
+    return cls.config_parser().parse(config)
+
+  @classmethod
+  def config_parser(cls) -> ConfigParser[DriverConfig]:
+    parser = ConfigParser("DriverConfig parser", cls)
+    parser.add_argument(
+        "type",
+        type=BrowserDriverType.parse,
+        default=BrowserDriverType.default())
+    # TODO: likely distinguish between local and remote driver path
+    parser.add_argument(
+        "path",
+        type=PathParser.binary_path,
+        required=False,
+        help="Path to the driver executable")
+    parser.add_argument(
+        "settings",
+        type=immutabledict,
+        help="Additional driver-dependent settings.")
+    parser.add_argument(
+        "device_id",
+        type=driver_device_id,
+        depends_on=("settings",),
+        help="Device ID / Serial ID / Unique device name")
+    parser.add_argument(
+        "adb_bin",
+        type=PathParser.binary_path,
+        required=False,
+        help="Path to the adb binary, only valid for Android.")
+    return parser
+
+  def __post_init__(self):
+    if not self.type:
+      raise ValueError(f"{type(self).__name__}.type cannot be None.")
+    try:
+      hash(self.settings)
+    except ValueError as e:
+      raise ValueError(
+          f"settings must be hashable but got: {self.settings}") from e
+    self.validate()
+
+  @property
+  def is_remote(self) -> bool:
+    return self.type.is_remote
+
+  @property
+  def is_local(self) -> bool:
+    return self.type.is_local
+
+  def validate(self) -> None:
+    if self.type == BrowserDriverType.ANDROID:
+      self.validate_android()
+    elif self.adb_bin:
+      raise argparse.ArgumentTypeError("adb_path is only valid for Android.")
+    if self.type == BrowserDriverType.IOS:
+      self.validate_ios()
+    if self.type == BrowserDriverType.CHROMEOS_SSH:
+      # Unlike the validation functions above for iOS and Android,
+      # which validate the "host" to which the device is connected,
+      # the ChromeOS validation function validates the "client".
+      # Consider moving this logic elsewhere in the future.
+      self.validate_chromeos()
+
+  def validate_android(self) -> None:
+    platform = plt.PLATFORM
+    devices = adb_devices(platform, self.adb_bin)
+    names = list(devices.keys())
+    if not devices:
+      raise argparse.ArgumentTypeError("No ADB devices attached.")
+    if not self.device_id:
+      if len(devices) == 1:
+        # Default device "adb" (no settings) with exactly one device is ok.
+        return
+      raise AmbiguousDriverIdentifier(
+          f"{len(devices)} ADB devices connected: {names}. "
+          "Please explicitly specify a device ID.")
+    if self.device_id not in devices:
+      raise argparse.ArgumentTypeError(
+          f"Could not find ADB device with device_id={repr(self.device_id)}. "
+          f"Choices are {names}.")
+    if self.adb_bin:
+      PathParser.binary_path(self.adb_bin, platform=platform)
+
+  def validate_chromeos(self) -> None:
+    platform = self.get_platform()
+    assert isinstance(platform, ChromeOsSshPlatform), \
+           f"Invalid platform: {platform}"
+    platform = cast(ChromeOsSshPlatform, platform)
+    if not platform.exists(platform.AUTOLOGIN_PATH):
+      raise ValueError(f"Could not find `autotest` on {platform.host}."
+                       "Please ensure that it is running a test image:"
+                       "go/arc-setup-dev-mode-dut#usb-cros-test-image")
+
+  def validate_ios(self) -> None:
+    devices: Dict[str, Any] = ios_devices(plt.PLATFORM)
+    if not devices:
+      raise argparse.ArgumentTypeError("No iOS devices attached.")
+    names = list(map(str, devices))
+    if not self.device_id:
+      if len(devices) == 1:
+        # Default device "ios" (no settings) with exactly one device is ok.
+        return
+      raise AmbiguousDriverIdentifier(
+          f"{len(devices)} ios devices connected: {names}. "
+          "Please explicitly specify a device UUID.")
+    if self.device_id not in devices:
+      raise argparse.ArgumentTypeError(
+          f"Could not find ios device with device_id={repr(self.device_id)}. "
+          f"Choices are {names}.")
+
+  def get_platform(self) -> plt.Platform:
+    if self.type == BrowserDriverType.ANDROID:
+      return self.get_adb_platform()
+    if self.type == BrowserDriverType.IOS:
+      # TODO(cbruni): use `xcrun xctrace list devices` to find the UDID
+      # for attached simulators or devices. Currently only a single device
+      # is supported
+      pass
+    if self.type in (BrowserDriverType.LINUX_SSH,
+                     BrowserDriverType.CHROMEOS_SSH):
+      return self.get_ssh_platform()
+    return plt.PLATFORM
+
+  def get_ssh_platform(self) -> plt.Platform:
+    assert self.settings
+    host = ObjectParser.non_empty_str(self.settings.get("host"), "host")
+    port = NumberParser.port_number(self.settings.get("port"), "port")
+    ssh_port = NumberParser.port_number(
+        self.settings.get("ssh_port"), "ssh port")
+    ssh_user = ObjectParser.non_empty_str(
+        self.settings.get("ssh_user"), "ssh user")
+    if self.type == BrowserDriverType.CHROMEOS_SSH:
+      return ChromeOsSshPlatform(
+          plt.PLATFORM,
+          host=host,
+          port=port,
+          ssh_port=ssh_port,
+          ssh_user=ssh_user)
+    return plt.LinuxSshPlatform(
+        plt.PLATFORM,
+        host=host,
+        port=port,
+        ssh_port=ssh_port,
+        ssh_user=ssh_user)
+
+  def get_adb_platform(self) -> plt.Platform:
+    adb = Adb(plt.PLATFORM, self.device_id, self.adb_bin)
+    return AndroidAdbPlatform(plt.PLATFORM, self.device_id, adb)
+
+def driver_device_id(device_id: Optional[str],
+                     settings: Optional[immutabledict]) -> Optional[str]:
+  if not settings:
+    return device_id
+  settings_device_id = settings.get("device_id")
+  if not device_id:
+    return settings_device_id
+  if settings_device_id != device_id:
+    raise TypeError("Conflicting both driver['settings']['device_id'] "
+                    "and driver['device_id']: "
+                    f"{repr(settings_device_id)} vs {repr(device_id)}")
+  return device_id
diff --git a/crossbench/cli/config/env.py b/crossbench/cli/config/env.py
new file mode 100644
index 0000000..8ed4aa0
--- /dev/null
+++ b/crossbench/cli/config/env.py
@@ -0,0 +1,50 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+from typing import TYPE_CHECKING
+
+import hjson
+
+from crossbench.env import HostEnvironment, HostEnvironmentConfig
+from crossbench.parse import ObjectParser, PathParser
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+
+
+def parse_inline_env_config(value: str) -> HostEnvironmentConfig:
+  if value in HostEnvironment.CONFIGS:
+    return HostEnvironment.CONFIGS[value]
+  if value[0] != "{":
+    raise argparse.ArgumentTypeError(
+        f"Invalid env config name: '{value}'. "
+        f"choices = {list(HostEnvironment.CONFIGS.keys())}")
+  # Assume hjson data
+  kwargs = None
+  msg = ""
+  try:
+    kwargs = ObjectParser.inline_hjson(value)
+    return HostEnvironmentConfig(**kwargs)
+  except Exception as e:
+    msg = f"\n{e}"
+    raise argparse.ArgumentTypeError(
+        f"Invalid inline config string: {value}{msg}") from e
+
+
+def parse_env_config_file(value: str) -> HostEnvironmentConfig:
+  config_path: LocalPath = PathParser.file_path(value)
+  try:
+    with config_path.open(encoding="utf-8") as f:
+      data = hjson.load(f)
+    if "env" not in data:
+      raise argparse.ArgumentTypeError("No 'env' property found")
+    kwargs = data["env"]
+    return HostEnvironmentConfig(**kwargs)
+  except Exception as e:
+    msg = f"\n{e}"
+    raise argparse.ArgumentTypeError(
+        f"Invalid env config file: {value}{msg}") from e
diff --git a/crossbench/cli/config/network.py b/crossbench/cli/config/network.py
new file mode 100644
index 0000000..f116f66
--- /dev/null
+++ b/crossbench/cli/config/network.py
@@ -0,0 +1,310 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import enum
+from typing import TYPE_CHECKING, Any, Dict, Optional
+
+from crossbench import exception
+from crossbench.config import ConfigEnum, ConfigObject, ConfigParser
+from crossbench.network.live import LiveNetwork
+from crossbench.network.local_file_server import LocalFileNetwork
+from crossbench.network.replay.wpr import (GS_PREFIX, LocalWprReplayNetwork,
+                                           RemoteWprReplayNetwork)
+from crossbench.network.traffic_shaping import ts_proxy
+from crossbench.network.traffic_shaping.live import NoTrafficShaper
+from crossbench.parse import NumberParser, PathParser
+
+if TYPE_CHECKING:
+  from crossbench import path as pth
+  from crossbench.network.base import Network
+  from crossbench.network.traffic_shaping.base import TrafficShaper
+  from crossbench.plt.base import Platform
+
+# We're using 'type' here a lot, let's skip the warnings from pylint.
+# pylint: disable=redefined-builtin
+
+
+@enum.unique
+class NetworkType(ConfigEnum):
+  LIVE = ("live", "Live network.")
+  WPR = ("wpr", "Replayed network from a wpr.go archive.")
+  LOCAL = ("local", "Serve content from a local http file server.")
+
+
+def _settings_str(name: str) -> str:
+  settings = ts_proxy.TRAFFIC_SETTINGS[name]
+  return (f"rtt={settings['rtt_ms']}ms, "
+          f"in={settings['in_kbps']} kbps,"
+          f"out={settings['out_kbps']} kbps")
+
+
+@enum.unique
+class NetworkSpeedPreset(ConfigEnum):
+  """Presets that match ts_proxy settings."""
+  LIVE = ("live", "Untroubled default network settings")
+  MOBILE_3G_SLOW = ("3G-slow",
+                    f"Slow 3G network settings: {_settings_str('3G-slow')}")
+  MOBILE_3G_REGULAR = (
+      "3G-regular",
+      f"Regular 3G network settings: {_settings_str('3G-regular')}")
+  MOBILE_3G_FAST = ("3G-fast",
+                    f"Slow 3G network settings: {_settings_str('3G-fast')}")
+  MOBILE_4G = ("4G", f"Regular 4G network settings: {_settings_str('4G')}")
+
+
+@dataclasses.dataclass(frozen=True)
+class NetworkSpeedConfig(ConfigObject):
+  ts_proxy: Optional[pth.AnyPath] = None
+  rtt_ms: Optional[int] = None
+  in_kbps: Optional[int] = None
+  out_kbps: Optional[int] = None
+  window: Optional[int] = None
+
+  @classmethod
+  def default(cls) -> NetworkSpeedConfig:
+    return NetworkSpeedConfig()
+
+  @classmethod
+  def parse(cls, value: Any, **kwargs) -> NetworkSpeedConfig:
+    if isinstance(value, NetworkSpeedPreset):
+      return cls.parse_preset(value)
+    return super().parse(value, **kwargs)
+
+  @classmethod
+  def parse_str(cls, value: str) -> NetworkSpeedConfig:
+    if not value:
+      raise argparse.ArgumentTypeError("Cannot parse empty string")
+    if value == "default":
+      return cls.default()
+    preset = NetworkSpeedPreset.parse(value)
+    return cls.parse_preset(preset)
+
+  @classmethod
+  def parse_preset(cls, preset: NetworkSpeedPreset) -> NetworkSpeedConfig:
+    if preset == NetworkSpeedPreset.LIVE:
+      return cls.default()
+    preset_kwargs = ts_proxy.TRAFFIC_SETTINGS[str(preset)]
+    return cls(**preset_kwargs)
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> NetworkSpeedConfig:
+    return cls.config_parser().parse(config)
+
+  @classmethod
+  def config_parser(cls) -> ConfigParser[NetworkSpeedConfig]:
+    parser = ConfigParser(
+        "NetworkSpeedConfig parser", cls, default=NetworkSpeedConfig.default())
+    parser.add_argument(
+        "ts_proxy", type=PathParser.existing_file_path, required=False)
+    # See tsproxy.py --help
+    parser.add_argument(
+        "rtt_ms",
+        type=NumberParser.positive_int,
+        help="Round Trip Time Latency (in ms).")
+    parser.add_argument(
+        "in_kbps",
+        type=NumberParser.positive_int,
+        help="Download Bandwidth (in 1000 bits/s - Kbps).")
+    parser.add_argument(
+        "out_kbps",
+        type=NumberParser.positive_int,
+        help="Upload Bandwidth (in 1000 bits/s - Kbps).")
+    parser.add_argument(
+        "window",
+        default=10,
+        type=NumberParser.positive_int,
+        help="Emulated TCP initial congestion window (defaults to 10).")
+    return parser
+
+  @classmethod
+  def help(cls) -> str:
+    return cls.config_parser().help
+
+  @property
+  def is_live(self):
+    return self == self.default()
+
+
+@dataclasses.dataclass(frozen=True)
+class NetworkConfig(ConfigObject):
+  type: NetworkType = NetworkType.LIVE
+  speed: NetworkSpeedConfig = NetworkSpeedConfig.default()
+  path: Optional[pth.LocalPath] = None
+  url: Optional[str] = None
+  wpr_go_bin: Optional[pth.LocalPath] = None
+  persist_server: bool = False
+  run_on_device: bool = False
+
+  ARCHIVE_EXTENSIONS = (".archive", ".wprgo")
+  VALID_EXTENSIONS = ConfigObject.VALID_EXTENSIONS + ARCHIVE_EXTENSIONS
+
+  @classmethod
+  def default(cls, type: Optional[NetworkType] = None) -> NetworkConfig:
+    return NetworkConfig(type=type or NetworkType.LIVE)
+
+  @classmethod
+  def config_parser(cls) -> ConfigParser[NetworkConfig]:
+    parser = ConfigParser(
+        "NetworkConfig parser", cls, default=NetworkConfig.default())
+    parser.add_argument("type", type=NetworkType, default=NetworkType.LIVE)
+    parser.add_argument(
+        "speed", type=NetworkSpeedConfig, default=NetworkSpeedConfig.default())
+    parser.add_argument("path", type=PathParser.existing_path, required=False)
+    parser.add_argument("url", type=str, required=False)
+    parser.add_argument(
+        "wpr_go_bin",
+        type=PathParser.existing_file_path,
+        required=False,
+        help=("Location of the wpr.go binary or source, "
+              "used for WPR replay network. "
+              "If not specified, a default lookup in known locations is used."))
+    parser.add_argument("persist_server", type=bool, default=False)
+    parser.add_argument("run_on_device", type=bool, default=False)
+    return parser
+
+  @classmethod
+  def help(cls) -> str:
+    return cls.config_parser().help
+
+  @classmethod
+  def parse_wpr(cls, value: Any) -> NetworkConfig:
+    config: NetworkConfig = cls.parse(value)
+    if config.type != NetworkType.WPR:
+      raise argparse.ArgumentTypeError(f"Expected wpr, but got {config.type}")
+    return config
+
+  @classmethod
+  def parse_local(cls, value: Any) -> NetworkConfig:
+    config = cls.parse(value, type=NetworkType.LOCAL)
+    if config.type != NetworkType.LOCAL:
+      raise argparse.ArgumentTypeError(
+          f"Expected local file server, but got {config.type}. ")
+    return config
+
+  @classmethod
+  def parse_str(  # pylint: disable=arguments-differ
+      cls,
+      value: str,
+      type: Optional[NetworkType] = None) -> NetworkConfig:
+    if not value:
+      raise argparse.ArgumentTypeError("Network: Cannot parse empty string")
+    if value == "default":
+      return cls.default(type)
+    if value[0] == "{":
+      return cls.parse_inline_hjson(value, type=type)
+    # TODO(346197734): Move to load_url once available.
+    if value.startswith(GS_PREFIX):
+      if type and type is not NetworkType.WPR:
+        raise argparse.ArgumentTypeError(
+            f"Network type mismatch, expected WPR, got {type}")
+      return cls.parse_wpr_archive_url(value)
+    if type and type is not NetworkType.LIVE:
+      raise argparse.ArgumentTypeError(
+          f"Network type mismatch expected LIVE, got {type}")
+    return cls.parse_live(value)
+
+  @classmethod
+  def parse_live(cls, value: Any) -> NetworkConfig:
+    with exception.annotate_argparsing("Live network with speed config"):
+      speed = NetworkSpeedConfig.parse(value)
+      return cls(NetworkType.LIVE, speed)
+    raise exception.UnreachableError()
+
+  @classmethod
+  def is_valid_path(cls, path: pth.LocalPath) -> bool:
+    if path.suffix in cls.ARCHIVE_EXTENSIONS:
+      return True
+    # for local file server
+    if path.is_dir():
+      return True
+    return super().is_valid_path(path)
+
+  @classmethod
+  def parse_path(cls, path: pth.LocalPath, **kwargs) -> NetworkConfig:
+    if path.suffix in cls.ARCHIVE_EXTENSIONS:
+      return cls.parse_wpr_archive_path(path)
+    if path.is_dir():
+      return NetworkConfig(NetworkType.LOCAL, path=path)
+    return super().parse_path(path, **kwargs)
+
+  @classmethod
+  def parse_wpr_archive_path(cls, path: pth.LocalPath) -> NetworkConfig:
+    path = PathParser.non_empty_file_path(path, "wpr.go archive")
+    return NetworkConfig(type=NetworkType.WPR, path=path)
+
+  @classmethod
+  def parse_wpr_archive_url(cls, url: str) -> NetworkConfig:
+    return NetworkConfig(type=NetworkType.WPR, url=url)
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> NetworkConfig:
+    return cls.config_parser().parse(config, **kwargs)
+
+  def validate(self) -> None:
+    if not self.type:
+      raise argparse.ArgumentTypeError("Missing NetworkConfig.type.")
+    if not self.speed and isinstance(self.speed, NetworkSpeedConfig):
+      raise argparse.ArgumentTypeError("Missing NetworkConfig.speed.")
+    if self.type == NetworkType.LIVE:
+      if self.path:
+        raise argparse.ArgumentTypeError(
+            "NetworkConfig path cannot be used with type=live")
+    elif self.type is NetworkType.WPR:
+      if not self.path and not self.url:
+        raise argparse.ArgumentTypeError(
+            "NetworkConfig with type=replay requires "
+            "a valid wpr.go archive path or download url.")
+      if self.path and self.url:
+        raise argparse.ArgumentTypeError(
+            "NetworkConfig with type=replay requires "
+            "either archive path or download url but not both.")
+    elif self.type is NetworkType.LOCAL:
+      if not self.path:
+        raise argparse.ArgumentTypeError(
+            "NetworkConfig with type=local requires "
+            "a valid local dir path to serve files.")
+      PathParser.non_empty_dir_path(self.path, "local-serve dir")
+    if self.wpr_go_bin and self.type is not NetworkType.WPR:
+      raise argparse.ArgumentTypeError(
+          "wpr_go_bin can only be used for the WPR replay network")
+    if self.persist_server and self.type is not NetworkType.WPR:
+      # TODO: support file server as well
+      raise argparse.ArgumentTypeError(
+          "persist_server can only be used for the WPR replay network")
+    if self.run_on_device and self.type is not NetworkType.WPR:
+      raise argparse.ArgumentTypeError(
+          "run_on_device can only be used for the WPR replay network")
+
+  def create(self, browser_platform: Platform) -> Network:
+    with exception.annotate_argparsing(
+        f"Setting up {self.type} network for {browser_platform}"):
+      traffic_shaper = self._create_traffic_shaper(browser_platform)
+      if self.type is NetworkType.LIVE:
+        return LiveNetwork(traffic_shaper, browser_platform)
+      if self.type is NetworkType.LOCAL:
+        assert self.path
+        return LocalFileNetwork(self.path, self.url, traffic_shaper,
+                                browser_platform)
+      if self.type is NetworkType.WPR:
+        if self.run_on_device and browser_platform.is_remote:
+          if not browser_platform.is_android:
+            raise ValueError("run_on_device only supported on Android")
+          return RemoteWprReplayNetwork(
+              self.url or str(self.path), traffic_shaper, self.wpr_go_bin,
+              browser_platform, self.persist_server)
+        return LocalWprReplayNetwork(
+            self.url or str(self.path), traffic_shaper, self.wpr_go_bin,
+            browser_platform, self.persist_server)
+    raise ValueError(f"Unknown network type {self.type}")
+
+  def _create_traffic_shaper(self, browser_platform: Platform) -> TrafficShaper:
+    if self.speed.is_live:
+      return NoTrafficShaper(browser_platform)
+    return ts_proxy.TsProxyTrafficShaper(browser_platform, self.speed.ts_proxy,
+                                         self.speed.rtt_ms, self.speed.in_kbps,
+                                         self.speed.out_kbps, self.speed.window)
diff --git a/crossbench/cli/config/probe.py b/crossbench/cli/config/probe.py
new file mode 100644
index 0000000..e000e90
--- /dev/null
+++ b/crossbench/cli/config/probe.py
@@ -0,0 +1,151 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import re
+from typing import (TYPE_CHECKING, Any, Dict, Final, Iterable, List, Optional,
+                    Sequence, Type)
+
+from crossbench import exception
+from crossbench.config import ConfigError, ConfigObject
+from crossbench.parse import ObjectParser
+from crossbench.probes.all import GENERAL_PURPOSE_PROBES
+
+if TYPE_CHECKING:
+  from crossbench.probes.probe import Probe
+
+
+class ProbeConfigError(ConfigError):
+  pass
+
+
+PROBE_LOOKUP: Dict[str, Type[Probe]] = {
+    cls.NAME: cls for cls in GENERAL_PURPOSE_PROBES
+}
+
+_PROBE_CONFIG_RE: Final[re.Pattern] = re.compile(
+    r"(?P<probe_name>[\w.]+)(:?(?P<config>\{.*\}))?", re.MULTILINE | re.DOTALL)
+
+
+@dataclasses.dataclass(frozen=True)
+class ProbeConfig(ConfigObject):
+  cls: Type[Probe]
+  config: Dict[str, Any] = dataclasses.field(default_factory=dict)
+
+  def __post_init__(self) -> None:
+    if not self.cls:
+      raise ValueError(f"{type(self).__name__}.cls cannot be None.")
+    if self.config is None:
+      raise ValueError(f"{type(self).__name__}.config cannot be None.")
+
+  @classmethod
+  def parse_str(cls, value: str) -> ProbeConfig:
+    # 1. variant: known probe
+    if value in PROBE_LOOKUP:
+      return cls(PROBE_LOOKUP[value])
+    if cls.value_has_path_prefix(value):
+      # ConfigObject.parse handles .hjson paths already, additional paths are
+      # not supported in ProbeConfig.loads.
+      raise ProbeConfigError(f"Probe config path does not exist: {value}")
+    # 2. variant, inline hjson: "name:{hjson}"
+    match = _PROBE_CONFIG_RE.fullmatch(value)
+    if match is None:
+      raise ProbeConfigError(f"Could not parse probe argument: {value}")
+    config = {"name": match["probe_name"]}
+    if config_str := match["config"]:
+      inline_config = ObjectParser.inline_hjson(config_str)
+      if "name" in inline_config:
+        raise ProbeConfigError("Inline hjson cannot redefine 'name'.")
+      config.update(inline_config)
+    return cls.parse_dict(config)
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> ProbeConfig:
+    probe_name = ObjectParser.non_empty_str(config.pop("name"), "name")
+    return cls.parse_probe_dict(probe_name, config)
+
+  @classmethod
+  def parse_probe_dict(cls, probe_name: str, config: Dict[str,
+                                                          Any]) -> ProbeConfig:
+    if probe_cls := PROBE_LOOKUP.get(probe_name):
+      return cls(probe_cls, config)
+    raise cls._unknown_probe_error(probe_name)
+
+  @classmethod
+  def _unknown_probe_error(cls, probe_name: str) -> ProbeConfigError:
+    additional_msg = ""
+    if ":" in probe_name or "}" in probe_name:
+      additional_msg = "\n    Likely missing quotes for --probe argument"
+    msg = f"    Options are: {list(PROBE_LOOKUP.keys())}{additional_msg}"
+    return ProbeConfigError(f"Unknown probe name: '{probe_name}'\n{msg}")
+
+  @property
+  def name(self) -> str:
+    return self.cls.NAME
+
+
+class ProbeListConfig(ConfigObject):
+
+  @classmethod
+  def from_cli_args(cls, args: argparse.Namespace) -> ProbeListConfig:
+    with exception.annotate_argparsing():
+      if args.probe_config:
+        return cls.parse_path(args.probe_config)
+      return cls(args.probe)
+
+  @classmethod
+  def parse_other(cls: Type[ProbeListConfig], value: Any) -> ProbeListConfig:
+    if isinstance(value, (tuple, list)):
+      return cls.parse_sequence(value)
+    return super().parse_other(value)
+
+  @classmethod
+  def parse_sequence(cls: Type[ProbeListConfig],
+                     config: Sequence[Dict[str, Any]]) -> ProbeListConfig:
+    probe_configs: List[ProbeConfig] = []
+    for index, probe_config in enumerate(config):
+      probe_config = ObjectParser.dict(probe_config, f"probes[{index}]")
+      probe_configs.append(ProbeConfig.parse_dict(probe_config))
+    return cls(probe_configs)
+
+  @classmethod
+  def parse_dict(cls: Type[ProbeListConfig],
+                 config: Dict[str, Any]) -> ProbeListConfig:
+    # Support global configs with {"probes": ...}
+    if "probes" in config:
+      config = config["probes"]
+      if isinstance(config, (tuple, list)):
+        return cls.parse_sequence(config)
+    elif "browsers" in config or "flags" in config:
+      raise ProbeConfigError("Missing 'probes' property in global config.")
+    config = ObjectParser.dict(config, "probes")
+    probe_configs: List[ProbeConfig] = []
+    for probe_name, config_data in config.items():
+      with exception.annotate(f"Parsing probe config probes['{probe_name}']"):
+        probe_configs.append(
+            ProbeConfig.parse_probe_dict(probe_name, config_data))
+    return cls(probe_configs)
+
+  @classmethod
+  def parse_str(cls, value: str) -> ProbeListConfig:
+    raise NotImplementedError()
+
+  def __init__(self, probes: Optional[Iterable[ProbeConfig]] = None):
+    self._probes: List[Probe] = []
+    if not probes:
+      return
+    for probe_config in probes:
+      with exception.annotate(f"Parsing --probe={probe_config.name}"):
+        self._add_probe(probe_config)
+
+  @property
+  def probes(self) -> List[Probe]:
+    return self._probes
+
+  def _add_probe(self, probe_config: ProbeConfig) -> None:
+    probe: Probe = probe_config.cls.from_config(probe_config.config)
+    self._probes.append(probe)
diff --git a/crossbench/cli/config/secret_type.py b/crossbench/cli/config/secret_type.py
new file mode 100644
index 0000000..940700a
--- /dev/null
+++ b/crossbench/cli/config/secret_type.py
@@ -0,0 +1,14 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+
+from crossbench.config import ConfigEnum
+
+
+@enum.unique
+class SecretType(ConfigEnum):
+  GOOGLE = ("google", "Google account name and password")
diff --git a/crossbench/cli/config/secrets.py b/crossbench/cli/config/secrets.py
new file mode 100644
index 0000000..7d2318a
--- /dev/null
+++ b/crossbench/cli/config/secrets.py
@@ -0,0 +1,78 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+from typing import Dict, Type
+
+from immutabledict import immutabledict
+
+from crossbench import exception
+from crossbench.cli.config.secret_type import SecretType
+from crossbench.config import ConfigObject, ConfigParser
+from crossbench.parse import ObjectParser
+
+SecretsDict = immutabledict[SecretType, "Secret"]
+
+
+@dataclasses.dataclass(frozen=True)
+class SecretsConfig(ConfigObject):
+  secrets: SecretsDict = dataclasses.field(default_factory=immutabledict)
+
+  @classmethod
+  def parse_str(cls, value: str) -> SecretsConfig:
+    if value[0] == "{":
+      return cls.parse_inline_hjson(value)
+    # TODO: maybe support passwd style string format
+    raise NotImplementedError("Cannot create secrets from string")
+
+  @classmethod
+  def parse_dict(cls, config: Dict) -> SecretsConfig:
+    secrets = {}
+    for type_str, secret_data in config.items():
+      secret_type = SecretType.parse(type_str)
+      with exception.annotate_argparsing("Parsing Secret details:"):
+        secret = Secret.parse_dict(secret_data, type=secret_type)
+      assert isinstance(secret,
+                        Secret), f"Expected {cls} but got {type(secret)}"
+      assert secret_type not in secrets, f"Duplicate entry for {type_str}"
+      secrets[secret_type] = secret
+    return SecretsConfig(immutabledict(secrets))
+
+  def as_dict(self) -> SecretsDict:
+    return self.secrets
+
+
+@dataclasses.dataclass(frozen=True)
+class Secret(ConfigObject):
+  type: SecretType
+  username: str
+  password: str
+
+  @classmethod
+  def config_parser(cls: Type[Secret]) -> ConfigParser[Secret]:
+    parser = ConfigParser(f"{cls.__name__} parser", cls)
+    parser.add_argument("type", type=SecretType, required=True)
+    parser.add_argument(
+        "username",
+        aliases=("user", "usr", "account"),
+        type=ObjectParser.non_empty_str,
+        required=True)
+    parser.add_argument(
+        "password",
+        aliases=("pass", "pw"),
+        type=ObjectParser.any_str,
+        required=True)
+    return parser
+
+  @classmethod
+  def parse_dict(  # pylint: disable=arguments-differ
+      cls, config: Dict, **kwargs) -> Secret:
+    return cls.config_parser().parse(config, **kwargs)
+
+  @classmethod
+  def parse_str(cls, value: str):
+    # TODO: maybe support passwd style string format
+    raise NotImplementedError("Cannot support")
diff --git a/crossbench/cli/parser.py b/crossbench/cli/parser.py
new file mode 100644
index 0000000..107a1ed
--- /dev/null
+++ b/crossbench/cli/parser.py
@@ -0,0 +1,54 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import logging
+import sys
+
+import colorama
+
+from crossbench.cli import ui
+
+
+# Needed to gap the diff between 3.8 and 3.9 default args that change throwing
+# behavior.
+class _BaseCrossBenchArgumentParser(argparse.ArgumentParser):
+
+  def fail(self, message) -> None:
+    super().error(message)
+
+  def exit(self, status=0, message=None) -> None:
+    if message:
+      if status == 0:
+        logging.info(message)
+      else:
+        # Hack to get red colored output
+        if ui.COLOR_LOGGING:
+          print(str(colorama.Fore.RED))
+        logging.critical(message)
+        if ui.COLOR_LOGGING:
+          print(str(colorama.Style.RESET_ALL))
+    sys.exit(status)
+
+
+if sys.version_info < (3, 9, 0):
+
+  class CrossBenchArgumentParser(_BaseCrossBenchArgumentParser):
+
+    def error(self, message) -> None:
+      # Let the CrossBenchCLI handle all errors and simplify testing.
+      exception = sys.exc_info()[1]
+      if isinstance(exception, BaseException):
+        raise exception
+      raise argparse.ArgumentError(None, message)
+
+else:
+
+  class CrossBenchArgumentParser(_BaseCrossBenchArgumentParser):
+
+    def __init__(self, *args, **kwargs) -> None:
+      kwargs["exit_on_error"] = False
+      super().__init__(*args, **kwargs)
diff --git a/crossbench/cli/subcommand/__init__.py b/crossbench/cli/subcommand/__init__.py
new file mode 100644
index 0000000..e9d2bfa
--- /dev/null
+++ b/crossbench/cli/subcommand/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/cli/subcommand/devtools_recorder_proxy/__init__.py b/crossbench/cli/subcommand/devtools_recorder_proxy/__init__.py
new file mode 100644
index 0000000..e9d2bfa
--- /dev/null
+++ b/crossbench/cli/subcommand/devtools_recorder_proxy/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/cli/subcommand/devtools_recorder_proxy/default.py b/crossbench/cli/subcommand/devtools_recorder_proxy/default.py
new file mode 100644
index 0000000..ba6c428
--- /dev/null
+++ b/crossbench/cli/subcommand/devtools_recorder_proxy/default.py
@@ -0,0 +1,258 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import asyncio
+import enum
+import json
+import logging
+import os
+import secrets
+import shlex
+import sys
+import tempfile
+from typing import TYPE_CHECKING, Any, Coroutine, Dict, Optional, Tuple
+
+import websockets
+from websockets.server import WebSocketServerProtocol
+
+from crossbench import compat, helper
+from crossbench import path as pth
+from crossbench.helper.state import BaseState, StateMachine
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import ListCmdArgs
+  from crossbench.types import JsonDict
+
+
+CROSSBENCH_ROOT: pth.LocalPath = pth.LocalPath(__file__).parents[4]
+
+
+@enum.unique
+class State(BaseState):
+  CONNECTED = enum.auto()
+  RUNNING = enum.auto()
+
+
+@enum.unique
+class Response(compat.StrEnum):
+  STATUS = "status"
+  OUTPUT = "output"
+
+
+class AuthenticationError(ValueError):
+  pass
+
+
+class CrossbenchDevToolsRecorderProxy:
+  DEFAULT_PORT = 44645
+
+  @classmethod
+  def add_subcommand(cls, subparsers) -> argparse.ArgumentParser:
+    parser = subparsers.add_parser(
+        "devtools-recorder-proxy",
+        aliases=["devtools"],
+        help=("Starts a local server to communicate with the "
+              "DevTools Recorder extension."))
+    parser.set_defaults(subcommand_fn=cls._subcommand)
+    parser.add_argument(
+        "--disable-token-authentication",
+        dest="use_auth_token",
+        default=True,
+        action="store_false",
+        help=("Disable token-based authentication. "
+              "Unsafe, only use for local development."))
+    return parser
+
+  @classmethod
+  def _subcommand(cls, args: argparse.Namespace) -> None:
+    instance: CrossbenchDevToolsRecorderProxy = cls(
+        use_auth_token=args.use_auth_token)
+    instance.run()
+
+  _websocket: WebSocketServerProtocol
+
+  def __init__(self, use_auth_token: bool = True) -> None:
+    self._token: str = secrets.token_hex(16)
+    self._use_auth_token: bool = use_auth_token
+    self._print_cmd_output: bool = False
+    self._port: int = self.DEFAULT_PORT
+    self._state = StateMachine(State.CONNECTED)
+    self._crossbench_task: Optional[asyncio.Task] = None
+    self._crossbench_process = None
+    self._tmp_json = pth.LocalPath(
+        tempfile.mkdtemp("crossbench_proxy")) / "devtools_recorder.json"
+
+  def run(self) -> None:
+    asyncio.run(self.run_server())
+
+  async def run_server(self) -> None:
+    try:
+      serve = websockets.serve(self.handler, "localhost", self.DEFAULT_PORT)
+    except Exception as e:  # pylint: disable=broad-except
+      logging.exception(e)
+      serve = websockets.serve(self.handler, "localhost")
+    async with serve as server:
+      self._port = server.sockets[0].getsockname()[1]
+      logging.info("#" * 80)
+      logging.info("#" * 80)
+      logging.info("# Crossbench DevTools Recorder Replay Server Started")
+      logging.info("#")
+      if self._port != self.DEFAULT_PORT:
+        logging.warning("# Non-default port!")
+      logging.info("# PORT:  %s", self._port)
+      if not self._use_auth_token:
+        logging.warning("# Token authentication has been disabled!")
+      logging.info("# TOKEN: %s", self._token)
+      logging.info("#")
+      logging.info("#" * 80)
+      logging.info("#" * 80)
+      await asyncio.Future()  # run forever
+
+  async def handler(self, websocket: WebSocketServerProtocol) -> None:
+    self._websocket = websocket
+    async for message in websocket:
+      await self._send_message(self._handle_message(message))
+
+  async def _send_message(
+      self, coroutine: Coroutine[Any, Any, Optional[Tuple[Response,
+                                                          Any]]]) -> None:
+    response: JsonDict = {"success": False, "payload": None, "error": None}
+    try:
+      result: Optional[Tuple[Response, Any]] = await coroutine
+      response["success"] = True
+      if result:
+        response_type, payload = result
+        response["payload"] = payload
+        response["type"] = response_type.value
+    except Exception as e:  # pylint: disable=broad-except
+      logging.exception(e)
+      response["error"] = str(type(e).__name__)
+    try:
+      response_json = json.dumps(response)
+    except Exception as e:  # pylint: disable=broad-except
+      logging.exception(e)
+      response["success"] = False
+      response["error"] = "Failed to encode message"
+      response["payload"] = None
+      response_json = json.dumps(response)
+    logging.debug("SEND Response: %s", response_json)
+    await self._websocket.send(response_json)
+
+  async def _handle_message(self, message) -> Optional[Tuple[Response, Any]]:
+    logging.debug("RECEIVE Message: %s", message)
+    try:
+      payload: Dict[str, Any] = json.loads(message)
+    except json.JSONDecodeError as e:
+      logging.error("Could not parse JSON response: %s", e)
+      raise e
+    if self._use_auth_token:
+      payload_token = payload["token"]
+      if payload_token != self._token:
+        logging.error("Invalid request token: %s", payload_token)
+        raise AuthenticationError("Invalid Token")
+    command = payload["command"]
+    args = payload.get("args", None)
+    if command == "run":
+      return await self._run_command(args)
+    if command == "stop":
+      return await self._stop_command()
+    if command == "status":
+      return await self._status_command()
+    logging.error("Unknown command: %s", command)
+    return None
+
+  async def _stop_command(self) -> Tuple[Response, str]:
+    if self._crossbench_process:
+      logging.info("# CROSSBENCH COMMAND: KILL")
+      helper.wait_and_kill(self._crossbench_process)
+    self._state.transition(State.CONNECTED, State.CONNECTED, to=State.CONNECTED)
+    return await self._status_command()
+
+  async def _run_command(self, args) -> Tuple[Response, str]:
+    self._state.transition(State.CONNECTED, to=State.RUNNING)
+    assert self._crossbench_process is None
+    cb_path = CROSSBENCH_ROOT / "cb.py"
+    os.environ["PYTHONUNBUFFERED"] = "1"
+    cmd: ListCmdArgs = []
+    if args.get("cmd") == "--help":
+      cmd = ["load", "--help"]
+      self._print_cmd_output = False
+    elif args.get("cmd") == "describe probes":
+      cmd = ["describe", "probes"]
+      self._print_cmd_output = False
+    else:
+      self._print_cmd_output = True
+      with self._tmp_json.open("w", encoding="utf-8") as f:
+        json.dump(args["json"], f)
+      assert self._tmp_json.exists(), f"{self._tmp_json} does not exist."
+      assert cb_path.exists(), f"{cb_path} does not exist."
+      cmd = [
+          "load", "--env-validation=warn", "--verbose",
+          f"--devtools-recorder={self._tmp_json.absolute()}",
+          *shlex.split(args.get("cmd"))
+      ]
+    logging.info("CROSSBENCH COMMAND: %s", cmd)
+    self._crossbench_process = await asyncio.create_subprocess_exec(
+        cb_path.absolute(),
+        *cmd,
+        stdout=asyncio.subprocess.PIPE,
+        stderr=asyncio.subprocess.PIPE)
+    self._crossbench_task = asyncio.create_task(self._wait_for_crossbench())
+    return await self._status_command()
+
+  async def _send_output(
+      self, stdout_str: Optional[str],
+      stderr_str: Optional[str]) -> Optional[Tuple[Response, Dict[str, str]]]:
+    if self._state != State.RUNNING:
+      return None
+    if self._print_cmd_output:
+      sys.stdout.write(stdout_str or "")
+      sys.stderr.write(stderr_str or "")
+    return Response.OUTPUT, {
+        "stdout": stdout_str or "",
+        "stderr": stderr_str or "",
+    }
+
+  async def _wait_for_crossbench(self) -> None:
+    assert self._crossbench_process
+    stdout_sender = asyncio.create_task(
+        self._send_stdout_incrementally(self._crossbench_process.stdout))
+    stderr_sender = asyncio.create_task(
+        self._send_stderr_incrementally(self._crossbench_process.stderr))
+    # TODO: Figure out why waiting on sending the output hangs when the
+    # crossbench subprocess ends with exit!=0
+    await asyncio.wait([stdout_sender, stderr_sender])
+    stdout, stderr = await self._crossbench_process.communicate()
+    await self._send_message(
+        self._send_output(stdout.decode("utf-8"), stderr.decode("utf-8")))
+    returncode = self._crossbench_process.returncode
+    self._state.transition(State.RUNNING, to=State.CONNECTED)
+    self._crossbench_task = None
+    self._crossbench_process = None
+    await self._send_message(self._status_command())
+    logging.info("# CROSSBENCH COMMAND DONE: returncode=%s", returncode)
+
+  _OUTPUT_BUFFER_SIZE = 128
+
+  async def _send_stdout_incrementally(self, stdout) -> None:
+    while self._crossbench_process:
+      stdout_data = await stdout.read(self._OUTPUT_BUFFER_SIZE)
+      if not stdout_data:
+        return
+      stdout_str = stdout_data.decode("utf-8")
+      await self._send_message(self._send_output(stdout_str, None))
+
+  async def _send_stderr_incrementally(self, stderr) -> None:
+    while self._crossbench_process:
+      stderr_data = await stderr.read(self._OUTPUT_BUFFER_SIZE)
+      if not stderr_data:
+        return
+      stderr_str = stderr_data.decode("utf-8")
+      await self._send_message(self._send_output(None, stderr_str))
+
+  async def _status_command(self) -> Tuple[Response, str]:
+    return Response.STATUS, str(self._state.name)
diff --git a/crossbench/cli/subcommand/devtools_recorder_proxy/empty.py b/crossbench/cli/subcommand/devtools_recorder_proxy/empty.py
new file mode 100644
index 0000000..421c590
--- /dev/null
+++ b/crossbench/cli/subcommand/devtools_recorder_proxy/empty.py
@@ -0,0 +1,19 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+
+
+class CrossbenchDevToolsRecorderProxy:
+  """Empty dummy implementation that can be used in case async is not
+  supported."""
+
+  @classmethod
+  def add_subcommand(cls, subparsers) -> argparse.ArgumentParser:
+    return subparsers.add_parser(
+        "devtools-recorder-proxy",
+        aliases=["devtools"],
+        help="Unsupported operation")
diff --git a/crossbench/cli/ui.py b/crossbench/cli/ui.py
new file mode 100644
index 0000000..b3ecc6b
--- /dev/null
+++ b/crossbench/cli/ui.py
@@ -0,0 +1,59 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import contextlib
+import datetime as dt
+import logging
+import sys
+from typing import Iterator
+
+import colorama
+
+from crossbench import helper
+
+colorama.init()
+
+COLOR_LOGGING: bool = True
+
+
+class ColoredLogFormatter(logging.Formatter):
+
+  FORMAT = "%(message)s"
+
+  FORMATS = {
+      logging.DEBUG:
+          FORMAT,
+      logging.INFO:
+          str(colorama.Fore.GREEN) + FORMAT + str(colorama.Fore.RESET),
+      logging.WARNING:
+          str(colorama.Fore.YELLOW) + FORMAT + str(colorama.Fore.RESET),
+      logging.ERROR:
+          str(colorama.Fore.RED) + FORMAT + str(colorama.Fore.RESET),
+      logging.CRITICAL:
+          str(colorama.Style.BRIGHT) + FORMAT + str(colorama.Style.RESET_ALL),
+  }
+
+  def format(self, record: logging.LogRecord) -> str:
+    log_fmt = self.FORMATS.get(record.levelno)
+    formatter = logging.Formatter(log_fmt)
+    return formatter.format(record)
+
+  def formatException(self, ei) -> str:
+    return ""
+
+  def formatStack(self, stack_info) -> str:
+    return ""
+
+
+@contextlib.contextmanager
+def timer(msg: str = "Elapsed Time") -> Iterator[None]:
+  start_time = dt.datetime.now()
+
+  def print_timer():
+    delta = dt.datetime.now() - start_time
+    indent = colorama.Cursor.FORWARD() * 3
+    sys.stdout.write(f"{indent}{msg}: {delta}\r")
+
+  with helper.RepeatTimer(interval=0.25, function=print_timer):
+    yield
diff --git a/crossbench/compat.py b/crossbench/compat.py
new file mode 100644
index 0000000..25fb4d3
--- /dev/null
+++ b/crossbench/compat.py
@@ -0,0 +1,80 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+""" A collection of helpers that rely on non-crossbench code."""
+
+from __future__ import annotations
+
+import enum
+import os
+import sys
+import textwrap
+from typing import List, NamedTuple, Optional, Tuple, Type, TypeVar, cast
+
+import tabulate
+
+from crossbench import path as pth
+
+if sys.version_info >= (3, 11):
+  from enum import StrEnum  # pylint: disable=unused-import
+else:
+
+  class StrEnum(str, enum.Enum):
+
+    def __str__(self) -> str:
+      return str(self.value)
+
+
+if sys.version_info >= (3, 9):
+
+  def is_relative_to(path_a: pth.AnyPath, path_b: pth.AnyPath) -> bool:
+    return path_a.is_relative_to(path_b)
+
+  def readlink(path: pth.LocalPath) -> pth.LocalPath:
+    return path.readlink()
+else:
+
+  def is_relative_to(path_a: pth.AnyPath, path_b: pth.AnyPath) -> bool:
+    try:
+      path_a.relative_to(path_b)
+      return True
+    except ValueError:
+      return False
+
+  def readlink(path: pth.LocalPath) -> pth.LocalPath:
+    return pth.LocalPath(os.readlink(path))
+
+
+class StrHelpDataMixin(NamedTuple):
+  value: str
+  help: str
+
+
+StrEnumWithHelpT = TypeVar("StrEnumWithHelpT", bound="StrEnumWithHelp")
+
+class StrEnumWithHelp(StrHelpDataMixin, enum.Enum):
+
+  @classmethod
+  def _missing_(cls: Type[StrEnumWithHelpT],
+                value) -> Optional[StrEnumWithHelpT]:
+    value = str(value).lower()
+    for member in cls:
+      if member.value == value:
+        return member
+    return None
+
+  @classmethod
+  def help_text_items(cls) -> List[Tuple[str, str]]:
+    return [
+        (repr(instance.value), instance.help) for instance in cls  # pytype: disable=missing-parameter
+    ]
+
+  @classmethod
+  def help_text(cls, indent: int = 0) -> str:
+    text: str = tabulate.tabulate(cls.help_text_items(), tablefmt="plain")
+    if indent:
+      return textwrap.indent(text, " " * indent)
+    return text
+
+  def __str__(self) -> str:
+    return cast(str, self.value)
diff --git a/crossbench/config.py b/crossbench/config.py
new file mode 100644
index 0000000..0c3a067
--- /dev/null
+++ b/crossbench/config.py
@@ -0,0 +1,707 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+import collections
+import collections.abc
+import enum
+import inspect
+import logging
+import textwrap
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, Generic,
+                    Iterable, List, Optional, Set, Tuple, Type, TypeVar, Union,
+                    cast)
+from urllib.parse import urlparse
+
+import tabulate
+
+# Use indirection to support pyfakefs
+from crossbench import compat, exception, helper
+from crossbench import path as pth
+from crossbench.helper import ChangeCWD
+from crossbench.parse import ObjectParser, PathParser
+
+if TYPE_CHECKING:
+  ArgParserType = Union[Callable[..., Any], Type]
+
+
+class ConfigError(argparse.ArgumentTypeError):
+  pass
+
+
+NOT_SET: Final[object] = object()
+
+
+class _ConfigArgParser:
+  """
+  Parser for a single config arg.
+  """
+
+  def __init__(  # pylint: disable=redefined-builtin
+      self,
+      parser: ConfigParser,
+      name: str,
+      type: Optional[ArgParserType],
+      default: Any = NOT_SET,
+      choices: Optional[frozenset[Any]] = None,
+      aliases: Iterable[str] = tuple(),
+      help: Optional[str] = None,
+      is_list: bool = False,
+      required: bool = False,
+      depends_on: Optional[Iterable[str]] = None):
+    self.parser: ConfigParser = parser
+    self.name: str = name
+    self.aliases = tuple(aliases)
+    self._validate_aliases()
+    self.type: Optional[ArgParserType] = type
+    self.required: bool = required
+    self.help: Optional[str] = help
+    self.is_list: bool = is_list
+    type_is_class = inspect.isclass(type)
+    self.type_is_class: bool = type_is_class
+    self.is_enum: bool = type_is_class and issubclass(type, enum.Enum)
+    self.config_object_type: Optional[Type[ConfigObject]] = None
+    if type_is_class and issubclass(type, ConfigObject):
+      self.config_object_type = type
+    self.depends_on = frozenset(depends_on) if depends_on else frozenset()
+    self.choices: Optional[frozenset] = self._validate_choices(choices)
+    if self.type:
+      self._validate_callable()
+    self.default = self._validate_default(default)
+    self._validate_depends_on(depends_on)
+
+  def _validate_callable(self) -> None:
+    assert self.type, "Expected not-None type"
+    if not callable(self.type):
+      raise TypeError(
+          f"Expected type to be a class or a callable, but got: {self.type}")
+    if self.config_object_type:
+      # Config objects and depends_on are handled specially.
+      return
+
+    signature = None
+    if getattr(self.type, "__module__") != "builtins":
+      try:
+        signature = inspect.signature(self.type)
+      except ValueError as e:
+        logging.debug("Could not get signature for %s: %s", self.type, e)
+
+    if not signature:
+      if not self.depends_on:
+        return
+      raise TypeError(
+          f"Type for config '{self.name}' should take at least 2 arguments "
+          f"to support depends_on, but got builtin: {self.type}")
+
+    if len(signature.parameters) == 0:
+      raise TypeError(
+          f"Type for config '{self.name}' should take at least 1 argument, "
+          f"but got: {self.type}")
+    if self.depends_on and len(signature.parameters) <= 1:
+      raise TypeError(
+          f"Type for config '{self.name}' should take at least 2 arguments "
+          f"to support depends_on, but got: {self.type}")
+
+  def _validate_aliases(self) -> None:
+    unique = set(self.aliases)
+    if self.name in unique:
+      raise ValueError(f"Config name '{self.name}' cannot be part "
+                       f"of the aliases='{self.aliases}'")
+    ObjectParser.unique_sequence(self.aliases, "aliases", ValueError)
+
+  def _validate_choices(
+      self, choices: Optional[frozenset[Any]]) -> Optional[frozenset]:
+    if self.is_enum:
+      return self._validate_enum_choices(choices)
+    if choices is None:
+      return None
+    choices_list = list(choices)
+    assert choices_list, f"Got empty choices: {choices}"
+    frozen_choices = frozenset(choices_list)
+    if len(frozen_choices) != len(choices_list):
+      raise ValueError("Choices must be unique, but got: {choices}")
+    return frozen_choices
+
+  def _validate_enum_choices(
+      self, choices: Optional[frozenset[Any]]) -> Optional[frozenset]:
+    assert self.is_enum
+    assert self.type
+    enum_type: Type[enum.Enum] = cast(Type[enum.Enum], self.type)
+    if choices is None:
+      return frozenset(enum for enum in enum_type)
+    for choice in choices:
+      assert isinstance(
+          choice,
+          enum_type), (f"Enum choices must be {enum_type}, but got: {choice}")
+    return frozenset(choices)
+
+  def _validate_default(self, default: Any) -> Any:
+    if default is NOT_SET:
+      return None
+    if default is None and self.required:
+      raise ValueError(
+          f"ConfigArg name={self.name}: use required=False without "
+          "a 'default' argument when default is None")
+    if self.required:
+      raise ValueError("Required argument should have an empty default value, "
+                       f"but got default={repr(default)}")
+    if self.is_enum:
+      return self._validate_enum_default(default)
+    # TODO: Remove once pytype can handle self.type
+    maybe_class: Optional[ArgParserType] = self.type
+    if self.is_list:
+      self._validate_list_default(default, maybe_class)
+    elif maybe_class and inspect.isclass(maybe_class):
+      self._validate_class_default(default, maybe_class)
+    return default
+
+  def _validate_class_default(self, default: Any, class_type: Type) -> None:
+    if not isinstance(default, class_type):
+      raise ValueError(f"Expected default value of type={class_type.__name__}, "
+                       f"but got type={type(default).__name__}: {default}")
+
+  def _validate_list_default(self, default: Any,
+                             maybe_class: Optional[ArgParserType]) -> None:
+    if not isinstance(default, collections.abc.Sequence):
+      raise ValueError(f"List default must be a sequence, but got: {default}")
+    if isinstance(default, str):
+      raise ValueError(
+          f"List default should not be a string, but got: {repr(default)}")
+    if inspect.isclass(maybe_class):
+      for default_item in default:
+        if not isinstance(default_item, maybe_class):
+          raise ValueError(
+              f"Expected default list item of type={self.type}, "
+              f"but got type={type(default_item).__name__}: {default_item}")
+
+  def _validate_enum_default(self, default: Any) -> None:
+    enum_type: Type[enum.Enum] = cast(Type[enum.Enum], self.type)
+    if self.is_list:
+      default_list = default
+    else:
+      default_list = (default,)
+    for default_item in default_list:
+      assert isinstance(default_item, enum_type), (
+          f"Default must be a {enum_type} enum, but got: {default}")
+    return default
+
+  def _validate_depends_on(self, depends_on: Optional[Iterable[str]]) -> None:
+    if not depends_on:
+      return
+    if not self._is_iterable_non_str(depends_on):
+      raise TypeError(f"Expected depends_on to be a collection of str, "
+                      f"but got {type(depends_on).__name__}: "
+                      f"{repr(depends_on)}")
+    for i, value in enumerate(depends_on):
+      if not isinstance(value, str):
+        raise TypeError(f"Expected depends_on[{i}] to be a str, but got "
+                        f"{type(value).__name__}: {repr(value)}")
+    if not self.type:
+      raise ValueError(f"Argument '{self.name}' without a type "
+                       "cannot have argument dependencies.")
+    if self.is_enum:
+      raise ValueError(f"Enum '{self.name}' cannot have argument dependencies")
+
+  def _is_iterable_non_str(self, value: Any) -> bool:
+    if isinstance(value, str):
+      return False
+    return isinstance(value, collections.abc.Iterable)
+
+  @property
+  def cls(self) -> Type:
+    return self.parser.cls
+
+  @property
+  def cls_name(self) -> str:
+    return self.cls.__name__
+
+  @property
+  def help_text(self) -> str:
+    items: List[Tuple[str, str]] = []
+    if self.type is None:
+      if self.is_list:
+        items.append(("type", "list"))
+    else:
+      if self.is_list:
+        items.append(("type", f"List[{self.type.__qualname__}]"))
+      else:
+        items.append(("type", str(self.type.__qualname__)))
+
+    if self.required:
+      items.append(("required", ""))
+    elif self.default is None:
+      items.append(("default", "not set"))
+    else:
+      if self.is_list:
+        if not self.default:
+          items.append(("default", "[]"))
+        else:
+          items.append(("default", ",".join(map(str, self.default))))
+      else:
+        items.append(("default", str(self.default)))
+    if self.is_enum:
+      items.extend(self._enum_help_text())
+    elif self.choices:
+      items.append(self._choices_help_text(self.choices))
+
+    text = tabulate.tabulate(items, tablefmt="presto")
+    if self.help:
+      return f"{self.help}\n{text}"
+    return text
+
+  def _choices_help_text(self, choices: Iterable) -> Tuple[str, str]:
+    return ("choices", ", ".join(map(str, choices)))
+
+  def _enum_help_text(self) -> List[Tuple[str, str]]:
+    if self.type and hasattr(self.type, "help_text_items"):
+      # See compat.StrEnumWithHelp
+      return [("choices", ""), *self.type.help_text_items()]
+    assert self.choices
+    return [self._choices_help_text(choice.value for choice in self.choices)]
+
+  def parse(self, config_data: Dict[str, Any],
+            depending_kwargs: Dict[str, Any]) -> Any:
+    data = None
+    if self.name in config_data:
+      data = config_data.pop(self.name)
+    elif self.aliases:
+      data = self._pop_alias(config_data)
+
+    if data is None:
+      if self.required and self.default is None:
+        raise ValueError(
+            f"{self.cls_name}: "
+            f"No value provided for required config option '{self.name}'")
+      data = self.default
+      if depending_kwargs:
+        self._validate_depending_kwargs(depending_kwargs)
+    else:
+      self._validate_depending_kwargs(depending_kwargs)
+      self._validate_no_aliases(config_data)
+    if data is None and not depending_kwargs:
+      return None
+    if self.is_list:
+      return self.parse_list_data(data, depending_kwargs)
+    return self.parse_data(data, depending_kwargs)
+
+  def _pop_alias(self, config_data) -> Optional[Any]:
+    value: Optional[Any] = None
+    found: bool = False
+    for alias in self.aliases:
+      if alias not in config_data:
+        continue
+      if found:
+        raise ValueError(f"Ambiguous arguments, got alias for {self.name} "
+                         "specified more than once.")
+      value = config_data.pop(alias, None)
+      found = True
+    return value
+
+  def _validate_depending_kwargs(self, depending_kwargs: Dict[str,
+                                                              Any]) -> None:
+    if not self.depends_on and depending_kwargs:
+      raise ValueError(f"{self.name} has no depending arguments, "
+                       f"but got: {depending_kwargs}")
+    for arg_name in self.depends_on:
+      if arg_name not in depending_kwargs:
+        raise ValueError(
+            f"{arg_name}.depends_on['{arg_name}'] was not provided.")
+
+  def _validate_no_aliases(self, config_data) -> None:
+    for alias in self.aliases:
+      if alias in config_data:
+        raise ValueError(
+            f"{self.cls_name}: ",
+            f"Got conflicting argument, '{self.name}' and '{alias}' "
+            "cannot be specified together.")
+
+  def _validate_type_without_depending_kwargs(
+      self, depending_kwargs: Dict[str, Any]) -> None:
+    if depending_kwargs:
+      raise ValueError(
+          f"{str(self.type)} does not accept "
+          f"additional depending arguments, but got: {depending_kwargs}")
+
+  def parse_list_data(self, data: Any,
+                      depending_kwargs: Dict[str, Any]) -> List[Any]:
+    if isinstance(data, str):
+      data = data.split(",")
+    if not isinstance(data, (list, tuple)):
+      raise ValueError(f"{self.cls_name}.{self.name}: "
+                       f"Expected sequence got {type(data).__name__}")
+    return [self.parse_data(value, depending_kwargs) for value in data]
+
+  def parse_data(self, data: Any, depending_kwargs: Dict[str, Any]) -> Any:
+    if self.is_enum:
+      self._validate_type_without_depending_kwargs(depending_kwargs)
+      return self.parse_enum_data(data)
+    if self.choices and data not in self.choices:
+      raise ValueError(f"{self.cls_name}.{self.name}: "
+                       f"Invalid choice '{data}', choices are {self.choices}")
+    if self.type is None:
+      self._validate_type_without_depending_kwargs(depending_kwargs)
+      return data
+    if self.type is bool:
+      self._validate_type_without_depending_kwargs(depending_kwargs)
+      if not isinstance(data, bool):
+        raise ValueError(
+            f"{self.cls_name}.{self.name}: Expected bool, but got {data}")
+    elif self.type in (float, int):
+      self._validate_type_without_depending_kwargs(depending_kwargs)
+      if not isinstance(data, (float, int)):
+        raise ValueError(
+            f"{self.cls_name}.{self.name}: Expected number, got {data}")
+    if self.config_object_type:
+      # TODO: support custom depending kwargs with ConfigObject
+      self._validate_type_without_depending_kwargs(depending_kwargs)
+      return self.parse_config_object(data)
+    return self.type(data, **depending_kwargs)
+
+  def parse_config_object(self, data) -> Any:
+    config_object: ConfigObject = self.config_object_type.parse(data)
+    return config_object.to_argument_value()
+
+  def parse_enum_data(self, data: Any) -> enum.Enum:
+    assert self.is_enum
+    assert self.choices
+    assert self.type
+    assert isinstance(self.type, type), "type for enum has to be a Class."
+    if issubclass(self.type, ConfigEnum):
+      return self.type.parse(data)
+    assert issubclass(self.type, enum.Enum)
+    return ObjectParser.enum(self.name, self.type, data, self.choices)
+
+
+
+
+ConfigEnumT = TypeVar("ConfigEnumT", bound="ConfigEnum")
+
+
+class ConfigEnum(compat.StrEnumWithHelp):
+
+  @classmethod
+  def parse(cls: Type[ConfigEnumT], value: Any) -> ConfigEnumT:
+    return ObjectParser.enum(cls.__name__, cls, value, cls)
+
+
+ConfigObjectT = TypeVar("ConfigObjectT", bound="ConfigObject")
+
+class ConfigObject(abc.ABC):
+  """A ConfigObject is a placeholder object with parsed values from
+  a ConfigParser.
+  - It is used to do complex input validation when the final instantiated
+    objects contain other nested config-parsed objects,
+  - It is then used to create a real instance of an object.
+  """
+  VALID_EXTENSIONS: Tuple[str, ...] = (".hjson", ".json")
+
+  @classmethod
+  def value_has_path_prefix(cls, value: str) -> bool:
+    return PathParser.PATH_PREFIX.match(value) is not None
+
+  def __post_init__(self) -> None:
+    self.validate()
+
+  def validate(self) -> None:
+    """Override to perform validation of config properties that cannot be
+    checked individually (aka depend on each other).
+    """
+
+  def to_argument_value(self) -> Any:
+    """ Called to convert a ConfigObject to the value stored in ConfigParser
+     result. """
+    return self
+
+  @classmethod
+  def parse(cls: Type[ConfigObjectT], value: Any, **kwargs) -> ConfigObjectT:
+    # Quick return for default values used by parsers.
+    if isinstance(value, cls):
+      return value
+    # Make sure we wrap any exception in a argparse.ArgumentTypeError)
+    with exception.annotate_argparsing(f"Parsing {cls.__name__}"):
+      return cls._parse(value, **kwargs)
+    raise exception.UnreachableError()
+
+  @classmethod
+  def _parse(cls: Type[ConfigObjectT], value: Any, **kwargs) -> ConfigObjectT:
+    if isinstance(value, dict):
+      return cls.parse_dict(value, **kwargs)
+    if not value:
+      raise ConfigError(f"{cls.__name__}: Empty config value")
+    if isinstance(value, pth.LocalPath):
+      return cls.parse_path(value, **kwargs)
+    if isinstance(value, str):
+      if urlparse(value).scheme:
+        # TODO(346197734): use parse_url here
+        return cls.parse_str(value, **kwargs)
+      try:
+        maybe_path = pth.LocalPath(value).expanduser()
+        if cls.is_valid_path(maybe_path):
+          return cls.parse_path(maybe_path, **kwargs)
+        if cls.value_has_path_prefix(value):
+          return cls.parse_unknown_path(maybe_path, **kwargs)
+      except OSError:
+        pass
+      return cls.parse_str(value, **kwargs)
+    return cls.parse_other(value, **kwargs)
+
+  @classmethod
+  def parse_other(cls: Type[ConfigObjectT], value: Any) -> ConfigObjectT:
+    raise ConfigError(
+        f"Invalid config input type {type(value).__name__}: {value}")
+
+  @classmethod
+  @abc.abstractmethod
+  def parse_str(cls: Type[ConfigObjectT], value: str) -> ConfigObjectT:
+    """Custom implementation for parsing config values that are
+    not handled by the default .parse(...) method."""
+    raise NotImplementedError()
+
+  @classmethod
+  def is_valid_path(cls, path: pth.LocalPath) -> bool:
+    if not path.is_file():
+      return False
+    return path.suffix in cls.VALID_EXTENSIONS
+
+  @classmethod
+  def parse_unknown_path(cls: Type[ConfigObjectT], path: pth.LocalPath,
+                         **kwargs) -> ConfigObjectT:
+    # TODO: this should be redirected to parse_config_path
+    return cls.parse_str(str(path), **kwargs)
+
+  @classmethod
+  def parse_path(cls: Type[ConfigObjectT], path: pth.LocalPath,
+                 **kwargs) -> ConfigObjectT:
+    return cls.parse_config_path(path, **kwargs)
+
+  @classmethod
+  def parse_inline_hjson(cls: Type[ConfigObjectT], value: str,
+                         **kwargs) -> ConfigObjectT:
+    with exception.annotate(f"Parsing inline {cls.__name__}"):
+      data = ObjectParser.inline_hjson(value)
+      return cls.parse_dict(data, **kwargs)
+    raise exception.UnreachableError()
+
+  @classmethod
+  def parse_config_path(cls: Type[ConfigObjectT], path: pth.LocalPathLike,
+                        **kwargs) -> ConfigObjectT:
+    with exception.annotate_argparsing(f"Parsing {cls.__name__} file: {path}"):
+      file_path = PathParser.existing_file_path(path)
+      data = ObjectParser.dict_hjson_file(file_path)
+      with ChangeCWD(file_path.parent):
+        return cls.parse_dict(data, **kwargs)
+    raise exception.UnreachableError()
+
+  @classmethod
+  @abc.abstractmethod
+  def parse_dict(cls: Type[ConfigObjectT], config: Dict[str,
+                                                        Any]) -> ConfigObjectT:
+    raise NotImplementedError()
+
+
+class _ConfigKwargsParser:
+
+  def __init__(self, parser: ConfigParser, config_data: Dict[str, Any]):
+    self._parser = parser
+    self._kwargs: Dict[str, Any] = {}
+    self._processed_args: Set[str] = set()
+    self._config_data = config_data
+    self._parse()
+
+  def _parse(self) -> None:
+    for arg_parser in self._parser.arg_parsers:
+      if arg_parser.name in self._processed_args:
+        # Already previously handled by some depending_on argument.
+        continue
+      self._parse_arg(arg_parser)
+
+  def _parse_arg(self, arg_parser: _ConfigArgParser) -> None:
+    arg_name: str = arg_parser.name
+    if arg_name in self._processed_args:
+      raise ValueError(
+          f"Recursive argument dependency on '{arg_name}' cannot be resolved.")
+    self._processed_args.add(arg_name)
+    with exception.annotate(f"Parsing ...['{arg_name}']:"):
+      depending_kwargs = self._maybe_parse_depending_args(arg_parser)
+      self._kwargs[arg_name] = arg_parser.parse(self._config_data,
+                                                depending_kwargs)
+
+  def _maybe_parse_depending_args(
+      self, arg_parser: _ConfigArgParser) -> Dict[str, Any]:
+    depending_args: Dict[str, Any] = {}
+    if not arg_parser.depends_on:
+      return depending_args
+    with exception.annotate(f"Parsing ...['{arg_parser.name}'].depends_on:"):
+      for depending_arg_name in arg_parser.depends_on:
+        depending_args[depending_arg_name] = self._parse_depending_arg(
+            depending_arg_name)
+    return depending_args
+
+  def _parse_depending_arg(self, arg_name: str) -> Any:
+    if arg_name in self._kwargs:
+      return self._kwargs[arg_name]
+    with exception.annotate(f"Parsing ...['{arg_name}']:"):
+      self._parse_arg(self._parser.get_argument(arg_name))
+      assert arg_name in self._kwargs, (
+          f"Failure when parsing depending {arg_name}")
+    return self._kwargs[arg_name]
+
+  def as_dict(self) -> Dict[str, Any]:
+    return dict(self._kwargs)
+
+
+ConfigResultObjectT = TypeVar("ConfigResultObjectT", bound="object")
+
+class ConfigParser(Generic[ConfigResultObjectT]):
+
+  def __init__(self,
+               title: str,
+               cls: Type[ConfigResultObjectT],
+               default: Optional[ConfigResultObjectT] = None,
+               allow_unused_config_data: bool = True) -> None:
+    self.title = title
+    assert title, "No title provided"
+    self._cls = cls
+    if default:
+      if not isinstance(default, cls):
+        raise TypeError(
+            f"Default value '{default}' is not an instance of {cls.__name__}")
+    self._default = default
+    self._args: Dict[str, _ConfigArgParser] = {}
+    self._arg_names: Set[str] = set()
+    self._allow_unused_config_data = allow_unused_config_data
+
+  @property
+  def default(self) -> Optional[ConfigResultObjectT]:
+    return self._default
+
+  def add_argument(  # pylint: disable=redefined-builtin
+      self,
+      name: str,
+      type: Optional[ArgParserType],
+      default: Optional[Any] = NOT_SET,
+      choices: Optional[Iterable[Any]] = None,
+      aliases: Tuple[str, ...] = tuple(),
+      help: Optional[str] = None,
+      is_list: bool = False,
+      required: bool = False,
+      depends_on: Optional[Iterable[str]] = None) -> None:
+    if name in self._arg_names:
+      raise ValueError(f"Duplicate argument: {name}")
+    arg = self._args[name] = _ConfigArgParser(self, name, type, default,
+                                              choices, aliases, help, is_list,
+                                              required, depends_on)
+    self._arg_names.add(name)
+    for alias in arg.aliases:
+      if alias in self._arg_names:
+        raise ValueError(f"Argument alias ({alias}) from {name}"
+                         " was previously added as argument.")
+      self._arg_names.add(alias)
+
+  def get_argument(self, arg_name: str) -> _ConfigArgParser:
+    return self._args[arg_name]
+
+  def kwargs_from_config(self, config_data: Dict[str, Any],
+                         **extra_kwargs) -> Dict[str, Any]:
+    with exception.annotate_argparsing(
+        f"Parsing {self._cls.__name__} extra config kwargs:"):
+      config_data = self._prepare_config_data(config_data, **extra_kwargs)
+    with exception.annotate_argparsing(
+        f"Parsing {self._cls.__name__} config dict:"):
+      kwargs = _ConfigKwargsParser(self, config_data)
+      if config_data:
+        self._handle_unused_config_data(config_data)
+      return kwargs.as_dict()
+    raise exception.UnreachableError()
+
+  def parse(self, config_data: Dict[str, Any], **kwargs) -> ConfigResultObjectT:
+    if self._default and config_data == {} and not kwargs:
+      return self._default
+    kwargs = self.kwargs_from_config(config_data, **kwargs)
+    return self.new_instance_from_kwargs(kwargs)
+
+  def _prepare_config_data(self, config_data: Dict[str, Any],
+                           **extra_kwargs) -> Dict[str, Any]:
+    config_data = dict(config_data)
+    for extra_key, extra_data in extra_kwargs.items():
+      if extra_data is None:
+        continue
+      if extra_key in config_data and extra_data is not config_data[extra_key]:
+        raise ValueError(
+            f"Extra config data {repr(extra_key)}={repr(extra_data)} "
+            "was already present in "
+            f"config_data[..]={repr(config_data[extra_key])}")
+      config_data[extra_key] = extra_data
+    return config_data
+
+  def new_instance_from_kwargs(self, kwargs: Dict[str,
+                                                  Any]) -> ConfigResultObjectT:
+    return self._cls(**kwargs)
+
+  def _handle_unused_config_data(self, unused_config_data: Dict[str,
+                                                                Any]) -> None:
+    logging.debug("Got unused properties: %s", unused_config_data.keys())
+    if not self._allow_unused_config_data:
+      unused_keys = ", ".join(map(repr, unused_config_data.keys()))
+      raise argparse.ArgumentTypeError(
+          f"Config for {self._cls.__name__} contains unused properties: "
+          f"{unused_keys}")
+
+  @property
+  def arg_parsers(self) -> Tuple[_ConfigArgParser, ...]:
+    return tuple(self._args.values())
+
+  @property
+  def cls(self) -> Type:
+    return self._cls
+
+  @property
+  def doc(self) -> str:
+    if not self._cls.__doc__:
+      return ""
+    return self._cls.__doc__.strip()
+
+  @property
+  def help(self) -> str:
+    return str(self)
+
+  @property
+  def summary(self) -> str:
+    return self.doc.splitlines()[0]
+
+  def __str__(self) -> str:
+    parts: List[str] = []
+    doc_string = self.doc
+    width = 80
+    if doc_string:
+      parts.append("\n".join(textwrap.wrap(doc_string, width=width)))
+      parts.append("")
+    if not self._args:
+      if parts:
+        return parts[0]
+      return ""
+    parts.append(f"{self.title} Configuration:")
+    parts.append("")
+    for arg in self._args.values():
+      parts.append(f"{arg.name}:")
+      parts.extend(helper.wrap_lines(arg.help_text, width=width, indent="  "))
+      parts.append("")
+    return "\n".join(parts)
+
+
+def is_google_env() -> bool:
+  return "/google3/" in __file__
+
+
+def root_dir() -> pth.LocalPath:
+  if is_google_env():
+    return pth.LocalPath(__file__).parents[0]
+  return pth.LocalPath(__file__).parents[1]
+
+
+def config_dir() -> pth.LocalPath:
+  return root_dir() / "config"
diff --git a/crossbench/decor/__init__.py b/crossbench/decor/__init__.py
new file mode 100644
index 0000000..67eefa2
--- /dev/null
+++ b/crossbench/decor/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/decor/base.py b/crossbench/decor/base.py
new file mode 100644
index 0000000..727778f
--- /dev/null
+++ b/crossbench/decor/base.py
@@ -0,0 +1,186 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import enum
+from typing import Dict, Generic, Optional, Set, Type, TypeVar
+
+from crossbench import plt
+from crossbench.config import ConfigParser
+from crossbench.helper.state import BaseState, StateMachine
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+
+DecoratorT = TypeVar("DecoratorT", bound="Decorator")
+DecoratorTargetT = TypeVar("DecoratorTargetT")
+
+
+class DecoratorConfigParser(ConfigParser[DecoratorT]):
+
+  def __init__(self, probe_cls: Type[DecoratorT]) -> None:
+    super().__init__(
+        probe_cls.__name__, probe_cls, allow_unused_config_data=False)
+    self._probe_cls = probe_cls
+
+
+class Decorator(abc.ABC, Generic[DecoratorTargetT]):
+  """ Abstract base class for RunDecorator and SessionDecorator that can
+  temporarily modify Runs or BrowserSessions.
+  """
+
+  NAME: str = ""
+
+  @classmethod
+  def config_parser(cls) -> DecoratorConfigParser:
+    return DecoratorConfigParser(cls)
+
+  @classmethod
+  def from_config(cls: Type[DecoratorT], config_data: Dict) -> DecoratorT:
+    return cls.config_parser().parse(config_data)
+
+  @classmethod
+  def help_text(cls) -> str:
+    return str(cls.config_parser())
+
+  def __init__(self) -> None:
+    assert self.name is not None, f"{type(self).__name__} must have a name"
+    self._targets: Set[DecoratorTargetT] = set()
+
+  def __str__(self) -> str:
+    return type(self).__name__
+
+  @property
+  def host_platform(self) -> plt.Platform:
+    return plt.PLATFORM
+
+  @property
+  def name(self) -> str:
+    return self.NAME
+
+  @abc.abstractmethod
+  def context(
+      self: DecoratorT,
+      target: DecoratorTargetT,
+  ) -> DecoratorContext[DecoratorT, DecoratorTargetT]:
+    pass
+
+
+class DecoratorContext(abc.ABC, Generic[DecoratorT, DecoratorTargetT]):
+  """
+  The active python context-manager for a Decorator with a life-time interface
+  to manage measurement, services or resources.
+
+  +- setup()
+  |  Unmeasured scope, browser might not be active yet.
+  |
+  | +- start()
+  | |  Browser active / measured section.
+  | +- stop()
+  |
+  *- teardown()
+  """
+
+  @enum.unique
+  class _State(BaseState):
+    READY = enum.auto()
+    STARTING = enum.auto()
+    RUNNING = enum.auto()
+    SUCCESS = enum.auto()
+    FAILURE = enum.auto()
+
+  def __init__(self, decorator: DecoratorT, target: DecoratorTargetT) -> None:
+    self._decorator = decorator
+    self._target = target
+    self._state = StateMachine(self._State.READY)
+    self._is_success: bool = False
+    self._start_time: Optional[dt.datetime] = None
+    self._stop_time: Optional[dt.datetime] = None
+    self._label = f"{type(self).__name__} {self.name}"
+
+  @property
+  def name(self) -> str:
+    return self._decorator.name
+
+  @property
+  def label(self) -> str:
+    return self._label
+
+  @property
+  def start_time(self) -> dt.datetime:
+    """
+    Returns a unified start time that is the same for all active Decorators.
+    This can be used to account for startup delays caused by other Decorators.
+    """
+    assert self._start_time
+    return self._start_time
+
+  @property
+  def duration(self) -> dt.timedelta:
+    assert self._start_time and self._stop_time
+    return self._stop_time - self._start_time
+
+  @property
+  def is_success(self) -> bool:
+    return self._is_success
+
+  def set_start_time(self, start_datetime: dt.datetime) -> None:
+    # Used to set a uniform start time across all active DecoratorContexts.
+    assert self._start_time is None
+    self._start_time = start_datetime
+
+  def __enter__(self) -> None:
+    self._state.transition(self._State.READY, to=self._State.STARTING)
+    with self._target.exception_handler(f"{self._label} start"):
+      try:
+        self.start()
+        self._state.transition(self._State.STARTING, to=self._State.RUNNING)
+      except:
+        self._state.transition(self._State.STARTING, to=self._State.FAILURE)
+        raise
+
+  def __exit__(self, exc_type, exc_value, traceback) -> None:
+    self._state.expect(self._State.RUNNING, self._State.FAILURE)
+    with self._target.exception_handler(f"{self._label} stop"):
+      try:
+        self.stop()
+        if self._state == self._State.RUNNING:
+          self._state.transition(self._State.RUNNING, to=self._State.SUCCESS)
+      except:
+        self._state.transition(to=self._State.FAILURE)
+        raise
+      finally:
+        self._stop_time = dt.datetime.now()
+
+  def setup(self) -> None:
+    """
+    Called before starting the target.
+    Not on the critical path, can be used for heavy computation.
+    """
+
+  def start(self) -> None:
+    """
+    Called immediately before starting the given target, after the browser
+    started.
+    This method should have as little overhead as possible.
+    If possible, delegate heavy computation to the "setup" method.
+    """
+
+  def stop(self) -> None:
+    """
+    Called immediately after finishing the given Target with the browser still
+    running.
+    This method should have as little overhead as possible.
+    If possible, delegate heavy computation to the "teardown" method.
+    """
+
+  def teardown(self) -> ProbeResult:
+    """
+    Non time-critical, called after stopping all Decorators and after stopping
+    the target.
+    Heavy post-processing can be performed here without affect the result of
+    other DecoratorContexts.
+    """
+    return EmptyProbeResult()
diff --git a/crossbench/decor/run/__init__.py b/crossbench/decor/run/__init__.py
new file mode 100644
index 0000000..67eefa2
--- /dev/null
+++ b/crossbench/decor/run/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/decor/run/run_decorator.py b/crossbench/decor/run/run_decorator.py
new file mode 100644
index 0000000..e26bfb1
--- /dev/null
+++ b/crossbench/decor/run/run_decorator.py
@@ -0,0 +1,32 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+from typing import Set, TypeVar
+
+from crossbench.runner.run import Run
+
+from crossbench.decor import base
+
+RunDecoratorT = TypeVar("RunDecoratorT", bound="RunDecorator")
+
+
+class RunDecorator(base.Decorator[Run]):
+
+  def runs(self) -> Set[Run]:
+    return self._targets
+
+  @abc.abstractmethod
+  def get_context(self: RunDecoratorT,
+                  target: Run) -> RunDecoratorContext[RunDecoratorT]:
+    pass
+
+
+class RunDecoratorContext(base.DecoratorContext[RunDecoratorT, Run]):
+
+  @property
+  def run(self) -> Run:
+    return self._target
diff --git a/crossbench/decor/session/__init__.py b/crossbench/decor/session/__init__.py
new file mode 100644
index 0000000..67eefa2
--- /dev/null
+++ b/crossbench/decor/session/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/decor/session/session_decorator.py b/crossbench/decor/session/session_decorator.py
new file mode 100644
index 0000000..196ebb3
--- /dev/null
+++ b/crossbench/decor/session/session_decorator.py
@@ -0,0 +1,33 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+from typing import Set, TypeVar
+
+from crossbench.decor import base
+from crossbench.runner.groups.session import BrowserSessionRunGroup
+from crossbench.runner.run import Run
+
+SessionDecoratorT = TypeVar("SessionDecoratorT", bound="SessionDecorator")
+
+
+class SessionDecorator(base.Decorator[Run]):
+
+  def runs(self) -> Set[Run]:
+    return self._targets
+
+  @abc.abstractmethod
+  def get_context(self: SessionDecoratorT,
+                  target: Run) -> SessionDecoratorContext[SessionDecoratorT]:
+    pass
+
+
+class SessionDecoratorContext(base.DecoratorContext[SessionDecoratorT,
+                                                    BrowserSessionRunGroup]):
+
+  @property
+  def browser_session(self) -> BrowserSessionRunGroup:
+    return self._target
diff --git a/crossbench/env.py b/crossbench/env.py
new file mode 100644
index 0000000..f6e04b92
--- /dev/null
+++ b/crossbench/env.py
@@ -0,0 +1,564 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+import datetime as dt
+import enum
+import logging
+import os
+import urllib.request
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterable, List,
+                    Optional, Tuple, Union)
+from urllib.parse import urlparse
+
+import colorama
+
+from crossbench import compat, helper, plt
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.path import LocalPath
+  from crossbench.plt.base import CmdArg, Platform
+  from crossbench.probes.probe import Probe
+
+
+def merge_bool(name: str, left: Optional[bool],
+               right: Optional[bool]) -> Optional[bool]:
+  if left is None:
+    return right
+  if right is None:
+    return left
+  if left != right:
+    raise ValueError(f"Conflicting merge values for {name}: "
+                     f"{left} vs. {right}")
+  return left
+
+
+Number = Union[float, int]
+
+
+def merge_number_max(name: str, left: Optional[Number],
+                     right: Optional[Number]) -> Optional[Number]:
+  del name
+  if left is None:
+    return right
+  if right is None:
+    return left
+  return max(left, right)
+
+
+def merge_number_min(name: str, left: Optional[Number],
+                     right: Optional[Number]) -> Optional[Number]:
+  del name
+  if left is None:
+    return right
+  if right is None:
+    return left
+  return min(left, right)
+
+
+def merge_str_list(name: str, left: Optional[List[str]],
+                   right: Optional[List[str]]) -> Optional[List[str]]:
+  del name
+  if left is None:
+    return right
+  if right is None:
+    return left
+  return left + right
+
+
+@dataclasses.dataclass(frozen=True)
+class HostEnvironmentConfig:
+  IGNORE = None
+
+  disk_min_free_space_gib: Optional[float] = IGNORE
+  power_use_battery: Optional[bool] = IGNORE
+  screen_brightness_percent: Optional[int] = IGNORE
+  cpu_max_usage_percent: Optional[float] = IGNORE
+  cpu_min_relative_speed: Optional[float] = IGNORE
+  system_allow_monitoring: Optional[bool] = IGNORE
+  browser_allow_existing_process: Optional[bool] = IGNORE
+  browser_allow_background: Optional[bool] = IGNORE
+  browser_is_headless: Optional[bool] = IGNORE
+  require_probes: Optional[bool] = IGNORE
+  system_forbidden_process_names: Optional[List[str]] = IGNORE
+  screen_allow_autobrightness: Optional[bool] = IGNORE
+
+  def merge(self, other: HostEnvironmentConfig) -> HostEnvironmentConfig:
+    mergers: Dict[str, Callable[[str, Any, Any], Any]] = {
+        "disk_min_free_space_gib": merge_number_max,
+        "power_use_battery": merge_bool,
+        "screen_brightness_percent": merge_number_max,
+        "cpu_max_usage_percent": merge_number_min,
+        "cpu_min_relative_speed": merge_number_max,
+        "system_allow_monitoring": merge_bool,
+        "browser_allow_existing_process": merge_bool,
+        "browser_allow_background": merge_bool,
+        "browser_is_headless": merge_bool,
+        "require_probes": merge_bool,
+        "system_forbidden_process_names": merge_str_list,
+        "screen_allow_autobrightness": merge_bool,
+    }
+    kwargs = {}
+    for name, merger in mergers.items():
+      self_value = getattr(self, name)
+      other_value = getattr(other, name)
+      kwargs[name] = merger(name, self_value, other_value)
+    return HostEnvironmentConfig(**kwargs)
+
+
+@enum.unique
+class ValidationMode(compat.StrEnumWithHelp):
+  THROW = ("throw", "Strict mode, throw and abort on env issues")
+  PROMPT = ("prompt", "Prompt to accept potential env issues")
+  WARN = ("warn", "Only display a warning for env issue")
+  SKIP = ("skip", "Don't perform any env validation")
+
+
+class ValidationError(Exception):
+  pass
+
+
+_config_default = HostEnvironmentConfig()
+_config_strict = HostEnvironmentConfig(
+    cpu_max_usage_percent=98,
+    cpu_min_relative_speed=1,
+    system_allow_monitoring=False,
+    browser_allow_existing_process=False,
+    require_probes=True,
+)
+_config_battery = _config_strict.merge(
+    HostEnvironmentConfig(power_use_battery=True))
+_config_power = _config_strict.merge(
+    HostEnvironmentConfig(power_use_battery=False))
+_config_catan = _config_strict.merge(
+    HostEnvironmentConfig(
+        screen_brightness_percent=65,
+        system_forbidden_process_names=["terminal", "iterm2"],
+        screen_allow_autobrightness=False))
+
+STALE_RESULT_ICONS = {
+    75: "",
+    100: "",
+    125: "",
+    150: "",
+    200: "",
+    250: "",
+    500: "",
+    1000: "",
+}
+
+
+class HostEnvironment:
+  """
+  HostEnvironment can check and enforce certain settings on a host
+  where we run benchmarks.
+
+  Modes:
+    skip:     Do not perform any checks
+    warn:     Only warn about mismatching host conditions
+    enforce:  Tries to auto-enforce conditions and warns about others.
+    prompt:   Interactive mode to skip over certain conditions
+    fail:     Fast-fail on mismatch
+  """
+
+  CONFIGS = {
+      "default": _config_default,
+      "strict": _config_strict,
+      "battery": _config_battery,
+      "power": _config_power,
+      "catan": _config_catan,
+  }
+
+  def __init__(self,
+               platform: Platform,
+               out_dir: LocalPath,
+               browsers: Iterable[Browser],
+               probes: Iterable[Probe],
+               repetitions: int,
+               config: Optional[HostEnvironmentConfig] = None,
+               validation_mode: ValidationMode = ValidationMode.THROW):
+    self._wait_until = dt.datetime.now()
+    self._config = config or HostEnvironmentConfig()
+    self._out_dir = out_dir
+    self._browsers = tuple(browsers)
+    self._probes = tuple(probes)
+    self._repetitions = repetitions
+    self._platform = platform
+    self._validation_mode = validation_mode
+
+  @property
+  def platform(self) -> Platform:
+    return self._platform
+
+  @property
+  def repetitions(self) -> int:
+    return self._repetitions
+
+  @property
+  def browsers(self) -> Tuple[Browser, ...]:
+    return self._browsers
+
+  @property
+  def config(self) -> HostEnvironmentConfig:
+    return self._config
+
+  @property
+  def validation_mode(self) -> ValidationMode:
+    return self._validation_mode
+
+  def _add_min_delay(self, seconds: float) -> None:
+    end_time = dt.datetime.now() + dt.timedelta(seconds=seconds)
+    self._wait_until = max(self._wait_until, end_time)
+
+  def _wait_min_time(self) -> None:
+    delta = self._wait_until - dt.datetime.now()
+    if delta > dt.timedelta(0):
+      self._platform.sleep(delta)
+
+  def handle_validation_warning(self, message: str) -> None:
+    message = f"Runner/Host environment requests cannot be fulfilled: {message}"
+    self.handle_warning(message)
+
+  def handle_warning(self,
+                     message: str,
+                     allow_interactive: bool = True) -> None:
+    """Process a warning, depending on the requested mode, this will
+    - throw an error,
+    - log a warning,
+    - prompts for continue [Yn], or
+    - skips (and just debug logs) a warning.
+    If returned True (in the prompt mode) the env validation may continue.
+    """
+    if self._validation_mode == ValidationMode.SKIP:
+      logging.debug("Ignoring %s", message)
+      return
+    if self._validation_mode == ValidationMode.WARN:
+      logging.warning(message)
+      return
+    if self._validation_mode == ValidationMode.PROMPT:
+      if allow_interactive:
+        result = input(f"{colorama.Fore.RED}{message} Continue?"
+                       f"{colorama.Fore.RESET} [Yn]")
+        # Accept <enter> as default input to continue.
+        if result.lower() != "n":
+          return
+    elif self._validation_mode != ValidationMode.THROW:
+      raise ValueError(
+          f"Unknown environment validation mode={self._validation_mode}")
+    raise ValidationError(message)
+
+  def validate_url(self,
+                   url: str,
+                   platform: plt.Platform = plt.PLATFORM) -> bool:
+    if self._validation_mode == ValidationMode.SKIP:
+      return True
+    result = urlparse(url)
+    if result.scheme == "file":
+      return platform.exists(result.path)
+    if platform.is_remote and result.hostname in ("localhost", "127.0.0.1"):
+      # TODO: support remote URL verification, for now we just assume that
+      # checking a live site is ok.
+      return True
+    try:
+      if not all([result.scheme in ["http", "https"], result.netloc]):
+        return False
+      if self._validation_mode != ValidationMode.PROMPT:
+        return True
+      with urllib.request.urlopen(url, timeout=5) as request:
+        if request.getcode() == 200:
+          return True
+        logging.debug("Could not load URL '%s', got %s", url, request)
+    except urllib.error.URLError as e:
+      logging.debug("Could not parse URL '%s' got error: %s", url, e)
+    return False
+
+  def _check_system_monitoring(self) -> None:
+    # TODO(cbruni): refactor to use list_... and disable_system_monitoring api
+    if self._platform.is_macos:
+      self._check_crowdstrike()
+
+  def _check_crowdstrike(self) -> None:
+    """Crowdstrike security monitoring (for googlers go/crowdstrike-falcon) can
+    have quite terrible overhead for each file-access. Disable it to reduce
+    flakiness. """
+    is_disabled = False
+    force_disable = self._config.system_allow_monitoring is False
+    try:
+      # TODO(cbruni): refactor to use list_... and disable_system_monitoring api
+      is_disabled = self._platform.check_system_monitoring(force_disable)
+      if force_disable:
+        # Add cool-down period, crowdstrike caused CPU usage spikes
+        self._add_min_delay(5)
+    except plt.SubprocessError as e:
+      self.handle_validation_warning(
+          "Could not disable go/crowdstrike-falcon monitor which can cause"
+          f" high background CPU usage: {e}")
+      return
+    if not is_disabled:
+      self.handle_validation_warning(
+          "Crowdstrike monitoring is running, "
+          "which can impact startup performance drastically.\n"
+          "Use the following command to disable it manually:\n"
+          "sudo /Applications/Falcon.app/Contents/Resources/falconctl unload\n")
+
+  def _check_disk_space(self) -> None:
+    limit = self._config.disk_min_free_space_gib
+    if limit is HostEnvironmentConfig.IGNORE:
+      return
+    # Check the remaining disk space on the FS where we write the results.
+    usage = self._platform.disk_usage(self._out_dir)
+    free_gib = round(usage.free / 1024 / 1024 / 1024, 2)
+    if free_gib < limit:
+      self.handle_validation_warning(
+          f"Only {free_gib}GiB disk space left, expected at least {limit}GiB.")
+
+  def _check_power(self) -> None:
+    use_battery = self._config.power_use_battery
+    if use_battery is HostEnvironmentConfig.IGNORE:
+      return
+    battery_probes = []
+    # Certain probes may require battery power:
+    for probe in self._probes:
+      if probe.BATTERY_ONLY:
+        battery_probes.append(probe)
+    if not use_battery and battery_probes:
+      probes_str = ",".join(probe.name for probe in battery_probes)
+      self.handle_validation_warning(
+          "Requested battery_power=False, "
+          f"but probes={probes_str} require battery power.")
+    sys_use_battery = self._platform.is_battery_powered
+    if sys_use_battery != use_battery:
+      self.handle_validation_warning(
+          f"Expected battery_power={use_battery}, "
+          f"but the system reported battery_power={sys_use_battery}")
+
+  def _check_cpu_usage(self) -> None:
+    max_cpu_usage = self._config.cpu_max_usage_percent
+    if max_cpu_usage is HostEnvironmentConfig.IGNORE:
+      return
+    cpu_usage_percent = round(100 * self._platform.cpu_usage(), 1)
+    if cpu_usage_percent > max_cpu_usage:
+      self.handle_validation_warning(
+          f"CPU usage={cpu_usage_percent}% is higher than "
+          f"requested max={max_cpu_usage}%.")
+
+  def _check_cpu_temperature(self) -> None:
+    min_relative_speed = self._config.cpu_min_relative_speed
+    if min_relative_speed is HostEnvironmentConfig.IGNORE:
+      return
+    cpu_speed = self._platform.get_relative_cpu_speed()
+    if cpu_speed < min_relative_speed:
+      self.handle_validation_warning(
+          "CPU thermal throttling is active. "
+          f"Relative speed is {cpu_speed}, "
+          f"but expected at least {min_relative_speed}.")
+
+  def _check_forbidden_system_process(self) -> None:
+    # Verify that no terminals are running.
+    # They introduce too much overhead. (As measured with powermetrics)
+    system_forbidden_process_names = self._config.system_forbidden_process_names
+    if system_forbidden_process_names is HostEnvironmentConfig.IGNORE:
+      return
+    process_found = self._platform.process_running(
+        system_forbidden_process_names)
+    if process_found:
+      self.handle_validation_warning(
+          f"Process:{process_found} found."
+          "Make sure not to have a terminal opened. Use SSH.")
+
+  def _check_screen_autobrightness(self) -> None:
+    auto_brightness = self._config.screen_allow_autobrightness
+    if auto_brightness is not False:
+      return
+    if self._platform.check_autobrightness():
+      self.handle_validation_warning(
+          "Auto-brightness was found to be ON. "
+          "Deactivate it in 'System Preferences/Displays'")
+
+  def _check_cpu_power_mode(self) -> bool:
+    # TODO Implement checks for performance mode
+    return True
+
+  def _check_running_binaries(self) -> None:
+    if self._config.browser_allow_existing_process:
+      return
+    grouped_browsers: Dict[plt.Platform, List[Browser]] = helper.group_by(
+        self.browsers, key=lambda browser: browser.platform)
+    for platform, browsers in grouped_browsers.items():
+      self._check_running_binaries_on_platform(platform, browsers)
+
+  def _check_running_binaries_on_platform(
+      self, platform: plt.Platform, platform_browsers: List[Browser]) -> None:
+    browser_binaries: Dict[str, List[Browser]] = helper.group_by(
+        platform_browsers, key=lambda browser: os.fspath(browser.path))
+    own_pid = os.getpid()
+    for proc_info in platform.processes(["cmdline", "exe", "pid", "name"]):
+      if not browser_binaries:
+        return
+      # Skip over this python script which might have the binary path as
+      # part of the command line invocation.
+      if proc_info["pid"] == own_pid:
+        continue
+      cmdline = " ".join(proc_info.get("cmdline") or "")
+      exe = proc_info.get("exe") or proc_info.get("name")
+      if not exe:
+        continue
+      # Windows uses some intermediate processes that contains the binary name
+      # on the command line.
+      if (platform.is_win and
+          proc_info.get("name") in ("cmd.exe", "vpython3.exe")):
+        continue
+      for binary, browsers in list(browser_binaries.items()):
+        # Add a white-space to get less false-positives
+        if f"{binary} " not in cmdline and binary != exe:
+          continue
+        # Use the first in the group
+        browser: Browser = browsers[0]
+        logging.debug("Binary=%s Platform=%s", binary, platform)
+        logging.debug("PS status output:")
+        logging.debug("proc(pid=%s, name=%s, cmd=%s)", proc_info["pid"],
+                      proc_info["name"], cmdline)
+        self.handle_validation_warning(
+            f"{browser.app_name} {browser.version} "
+            f"seems to be already running on {platform}.")
+        # Avoid re-checking the same binary once we've allowed it to be running.
+        del browser_binaries[binary]
+
+  def _check_screen_brightness(self) -> None:
+    brightness = self._config.screen_brightness_percent
+    if brightness is HostEnvironmentConfig.IGNORE:
+      return
+    assert 0 <= brightness <= 100, f"Invalid brightness={brightness}"
+    self._platform.set_main_display_brightness(brightness)
+    current = self._platform.get_main_display_brightness()
+    if current != brightness:
+      self.handle_validation_warning(
+          f"Requested main display brightness={brightness}%, "
+          "but got {brightness}%")
+
+  def _check_headless(self) -> None:
+    # TODO: migrate to full viewport support
+    requested_headless = self._config.browser_is_headless
+    if requested_headless is HostEnvironmentConfig.IGNORE:
+      return
+    if self._platform.is_linux and not requested_headless:
+      # Check that the system can run browsers with a UI.
+      if not self._platform.has_display:
+        self.handle_validation_warning(
+            "Requested browser_is_headless=False, "
+            "but no DISPLAY is available to run with a UI.")
+    # Check that browsers are running in the requested display mode:
+    for browser in self.browsers:
+      if browser.viewport.is_headless != requested_headless:
+        self.handle_validation_warning(
+            f"Requested browser_is_headless={requested_headless},"
+            f"but browser {browser.unique_name} has conflicting "
+            f"headless={browser.viewport.is_headless}.")
+
+  def _check_probes(self) -> None:
+    for probe in self._probes:
+      try:
+        probe.validate_env(self)
+      except Exception as e:
+        raise ValidationError(
+            f"Probe='{probe.NAME}' validation failed: {e}") from e
+    require_probes = self._config.require_probes
+    if require_probes is HostEnvironmentConfig.IGNORE:
+      return
+    if self._config.require_probes and not self._probes:
+      self.handle_validation_warning("No probes specified.")
+
+  def _check_results_dir(self) -> None:
+    results_dir = self._out_dir.parent
+    if not results_dir.exists():
+      return
+    results = [path for path in results_dir.iterdir() if path.is_dir()]
+    num_results = len(results)
+    if num_results < 20:
+      return
+    message = (f"Found {num_results} existing crossbench results. "
+               f"Consider cleaning stale results in '{results_dir}'")
+    for count, icon in reversed(STALE_RESULT_ICONS.items()):
+      if num_results > count:
+        message = f"{icon} {message}"
+        break
+    if num_results > 50:
+      logging.error(message)
+    else:
+      logging.warning(message)
+
+  def _check_macos_terminal(self) -> None:
+    if not self._platform.is_macos or (
+        self._platform.environ.get("TERM_PROGRAM") != "Apple_Terminal"):
+      return
+    any_not_headless = any(
+        not browser.viewport.is_headless for browser in self.browsers)
+    if any_not_headless:
+      self.handle_validation_warning(
+          "Terminal.app does not launch apps in the foreground.\n"
+          "Please use iTerm.app for a better experience.")
+
+  def check_browser_focused(self, browser: Browser) -> None:
+    if (self._config.browser_allow_background or not browser.pid or
+        browser.viewport.is_headless):
+      return
+    info = browser.platform.foreground_process()
+    if not info:
+      return
+    if info["pid"] != browser.pid:
+      self.handle_warning(
+          f"Browser(name={browser.unique_name} pid={browser.pid})) "
+          "was not in the foreground at the end of the benchmark. "
+          "Background apps and tabs can be heavily throttled.",
+          allow_interactive=False)
+
+  def setup(self) -> None:
+    self.validate()
+
+  def validate(self) -> None:
+    logging.info("-" * 80)
+    if self._validation_mode == ValidationMode.SKIP:
+      logging.info("VALIDATE ENVIRONMENT: SKIP")
+      return
+    message = "VALIDATE ENVIRONMENT"
+    if self._validation_mode != ValidationMode.WARN:
+      message += " (--env-validation=warn for soft warnings)"
+    message += ": %s"
+    logging.info(message, self._validation_mode.name)
+    self._check_system_monitoring()
+    self._check_power()
+    self._check_disk_space()
+    self._check_cpu_usage()
+    self._check_cpu_temperature()
+    self._check_cpu_power_mode()
+    self._check_running_binaries()
+    self._check_screen_brightness()
+    self._check_headless()
+    self._check_results_dir()
+    self._check_probes()
+    self._wait_min_time()
+    self._check_forbidden_system_process()
+    self._check_screen_autobrightness()
+    self._check_macos_terminal()
+
+  def check_installed(self,
+                      binaries: Iterable[str],
+                      message: str = "Missing binaries: {}") -> None:
+    assert not isinstance(binaries, str), "Expected iterable of strings."
+    missing_binaries = list(
+        binary for binary in binaries if not self._platform.which(binary))
+    if missing_binaries:
+      self.handle_validation_warning(message.format(missing_binaries))
+
+  def check_sh_success(self,
+                       *args: CmdArg,
+                       message: str = "Could not execute: {}") -> None:
+    assert args, "Missing sh arguments"
+    try:
+      assert self._platform.sh_stdout(*args, quiet=True)
+    except plt.SubprocessError as e:
+      self.handle_validation_warning(message.format(e))
diff --git a/crossbench/exception.py b/crossbench/exception.py
new file mode 100644
index 0000000..ed36dc3
--- /dev/null
+++ b/crossbench/exception.py
@@ -0,0 +1,347 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import contextlib
+import logging
+import sys
+import traceback as tb
+from dataclasses import dataclass
+from types import TracebackType
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Type
+
+from crossbench import helper
+from crossbench.types import JsonList
+
+if TYPE_CHECKING:
+  from crossbench.types import JsonDict
+
+TInfoStack = Tuple[str, ...]
+
+TExceptionTypes = Tuple[Type[BaseException], ...]
+
+
+@dataclass
+class Entry:
+  traceback: List[str]
+  exception: BaseException
+  info_stack: TInfoStack
+
+
+class MultiException(ValueError):
+  """Default exception thrown by ExceptionAnnotator.assert_success.
+  It holds on to the ExceptionAnnotator and its previously captured exceptions
+  are automatically added to active ExceptionAnnotator in an
+  ExceptionAnnotationScope."""
+
+  def __init__(self, message: str, exceptions: ExceptionAnnotator):
+    super().__init__(message)
+    self.exceptions = exceptions
+
+  def __len__(self) -> int:
+    return len(self.exceptions)
+
+  def matching(self, *args: Type[BaseException]) -> List[BaseException]:
+    return self.exceptions.matching(*args)
+
+  @property
+  def annotator(self) -> ExceptionAnnotator:
+    return self.exceptions
+
+
+class ExceptionAnnotationScope:
+  """Used in a with-scope to annotate exceptions with a TInfoStack.
+
+  Used via the capture/annotate/info helper methods on
+  ExceptionAnnotator.
+  """
+
+  def __init__(
+      self,
+      annotator: ExceptionAnnotator,
+      exception_types: TExceptionTypes,
+      ignore_exception_types: TExceptionTypes,
+      entries: Tuple[str, ...],
+      throw_cls: Optional[Type[BaseException]] = None,
+  ) -> None:
+    logging.debug("ExceptionAnnotationScope: %s", entries)
+    self._annotator = annotator
+    self._exception_types = exception_types
+    self._ignore_exception_types = ignore_exception_types + (
+        StopIteration, GeneratorExit, StopAsyncIteration)
+    self._ignore_exception_types = ignore_exception_types
+    self._added_info_stack_entries = entries
+    self._throw_cls: Optional[Type[BaseException]] = throw_cls
+    self._previous_info_stack: TInfoStack = ()
+
+  def __enter__(self) -> ExceptionAnnotationScope:
+    self._annotator._pending_exceptions.clear()
+    self._previous_info_stack = self._annotator.info_stack
+    self._annotator._info_stack = self._previous_info_stack + (
+        self._added_info_stack_entries)
+    return self
+
+  def __exit__(self, exception_type: Optional[Type[BaseException]],
+               exception_value: Optional[BaseException],
+               traceback: Optional[TracebackType]) -> bool:
+    if not exception_value or not exception_type:
+      self._annotator._info_stack = self._previous_info_stack
+      # False => exception not handled
+      return False
+    if issubclass(exception_type, self._ignore_exception_types) and (
+        not issubclass(exception_type, MultiException)):
+      self._annotator._info_stack = self._previous_info_stack
+      # False => exception not handled, directly forward
+      return False
+    logging.debug("Intermediate Exception: %s:%s", exception_type,
+                  exception_value)
+    if self._exception_types and exception_type and (
+        issubclass(exception_type, MultiException) or
+        issubclass(exception_type, self._exception_types)):
+      # Handle matching exceptions directly here and prevent further
+      # exception handling by returning True.
+      self._annotator.append(exception_value)
+      self._annotator._info_stack = self._previous_info_stack
+      if self._throw_cls:
+        self._annotator.assert_success(
+            exception_cls=self._throw_cls,
+            log=False,
+        )
+      return True
+    if exception_value not in self._annotator._pending_exceptions:
+      self._annotator._pending_exceptions[
+          exception_value] = self._annotator.info_stack
+    # False => exception not handled
+    return False
+
+class ExceptionAnnotator:
+  """Collects exceptions with full backtraces and user-provided info stacks.
+
+  Additional stack information is constructed from active
+  ExceptionAnnotationScopes.
+  """
+
+  def __init__(self,
+               throw: bool = False,
+               throw_cls: Optional[Type[BaseException]] = None) -> None:
+    self._exceptions: List[Entry] = []
+    self.throw: bool = throw
+    self._throw_cls: Optional[Type[BaseException]] = throw_cls
+    # The info_stack adds additional meta information to handle exceptions.
+    # Unlike the source-based backtrace, this can contain dynamic information
+    # for easier debugging.
+    self._info_stack: TInfoStack = ()
+    # Associates raised exception with the info_stack at that time for later
+    # use in the `handle` method.
+    # This is cleared whenever we enter a  new ExceptionAnnotationScope.
+    self._pending_exceptions: Dict[BaseException, TInfoStack] = {}
+
+  @property
+  def is_success(self) -> bool:
+    return len(self._exceptions) == 0
+
+  @property
+  def info_stack(self) -> TInfoStack:
+    return self._info_stack
+
+  @property
+  def exceptions(self) -> List[Entry]:
+    return self._exceptions
+
+  def __getitem__(self, key: Any) -> Entry:
+    if not isinstance(key, int):
+      raise TypeError(f"Expected int key, but got: {key}")
+    return self._exceptions[key]
+
+  def __len__(self) -> int:
+    return len(self._exceptions)
+
+  def matching(self, *args: Type[BaseException]) -> List[BaseException]:
+    result = []
+    for entry in self._exceptions:
+      exception = entry.exception
+      if isinstance(exception, *args):
+        result.append(exception)
+    return result
+
+  def assert_success(self,
+                     message: Optional[str] = None,
+                     exception_cls: Type[BaseException] = MultiException,
+                     log: bool = True) -> None:
+    if self.is_success:
+      return
+    if log:
+      self.log()
+    if message is None:
+      message = "{}"
+    message = message.format(self)
+    if issubclass(exception_cls, MultiException):
+      exception = exception_cls(message, self)
+      raise exception
+    raise exception_cls(message)
+
+  def info(self, *stack_entries: str) -> ExceptionAnnotationScope:
+    """Only sets info stack entries, exceptions are passed-through."""
+    return ExceptionAnnotationScope(self, tuple(), tuple(), stack_entries)
+
+  def capture(
+      self,
+      *stack_entries: str,
+      exceptions: TExceptionTypes = (Exception,),
+      ignore: TExceptionTypes = tuple(),
+  ) -> ExceptionAnnotationScope:
+    """Sets info stack entries and captures exceptions.
+    - Does not rethrow captured exceptions
+    - Does not directly throw a MultiExceptions, unless assert_success()
+      is called. """
+    return ExceptionAnnotationScope(self, exceptions, ignore, stack_entries,
+                                    self._throw_cls)
+
+  @contextlib.contextmanager
+  def annotate(self,
+               *stack_entries,
+               exceptions: TExceptionTypes = (Exception,),
+               ignore: TExceptionTypes = tuple()):
+    """Sets info stack entries and rethrows an annotated
+      MultiException by default ."""
+    with self.capture(*stack_entries, exceptions=exceptions, ignore=ignore):
+      yield self
+    self.assert_success()
+
+  def extend(self, annotator: ExceptionAnnotator,
+             is_nested: bool = False) -> None:
+    if is_nested:
+      self._extend_with_prepended_stack_info(annotator)
+    else:
+      self._exceptions.extend(annotator.exceptions)
+
+  def _extend_with_prepended_stack_info(self,
+                                        annotator: ExceptionAnnotator) -> None:
+    if annotator == self:
+      return
+    for entry in annotator.exceptions:
+      merged_info_stack = self.info_stack + entry.info_stack
+      merged_entry = Entry(entry.traceback, entry.exception, merged_info_stack)
+      self._exceptions.append(merged_entry)
+
+  def append(self, exception: BaseException) -> None:
+    traceback_str = tb.format_exc()
+    logging.debug("Intermediate Exception %s:%s", type(exception), exception)
+    logging.debug(traceback_str)
+    traceback: List[str] = traceback_str.splitlines()
+    if isinstance(exception, KeyboardInterrupt):
+      # Fast exit on KeyboardInterrupts for a better user experience.
+      sys.exit(0)
+    if isinstance(exception, MultiException):
+      # Directly add exceptions from nested annotators.
+      self.extend(exception.exceptions, is_nested=True)
+    else:
+      stack = self.info_stack
+      if exception in self._pending_exceptions:
+        stack = self._pending_exceptions[exception]
+      self._exceptions.append(Entry(traceback, exception, stack))
+    if self.throw:
+      raise  # pylint: disable=misplaced-bare-raise
+
+  def log(self) -> None:
+    if self.is_success:
+      return
+    logging.error("=" * 80)
+    logging.error("ERRORS occurred (1/%d):", len(self._exceptions))
+    logging.error("=" * 80)
+    for entry in self._exceptions:
+      logging.debug(entry.exception)
+      logging.debug("\n".join(entry.traceback))
+      logging.debug("-" * 80)
+    is_first_entry = True
+    grouped_entries: Dict[TInfoStack, List[Entry]] = helper.group_by(
+        self._exceptions, key=lambda entry: entry.info_stack, sort_key=None)
+    for info_stack, entries in grouped_entries.items():
+      logging_level = logging.ERROR if is_first_entry else logging.DEBUG
+      is_first_entry = False
+      if info_stack:
+        info = "Info: "
+        joiner = "\n" + (" " * (len(info) - 2)) + "> "
+        message = f"{info}{joiner.join(info_stack)}"
+        logging.log(logging_level, message)
+      for entry in entries:
+        logging.log(logging_level, "- " * 40)
+        logging.log(logging_level, "Type: %s:",
+                    helper.type_name(type(entry.exception)))
+        logging.log(logging_level, "      %s", self.format_exception(entry))
+        logging_level = logging.DEBUG
+      logging.log(logging_level, "-" * 80)
+
+  def error_messages(self) -> List[str]:
+    return [self.format_exception(entry) for entry in self._exceptions]
+
+  def to_json(self) -> JsonList:
+    return [{
+        "info_stack": entry.info_stack,
+        "type": helper.type_name(type(entry.exception)),
+        "title": self.format_exception(entry),
+        "trace": entry.traceback
+    } for entry in self._exceptions]
+
+  def format_exception(self, entry: Entry) -> str:
+    msg = str(entry.exception).strip()
+    # Try to print the source line for empty AssertionError
+    if not msg and isinstance(entry.exception, AssertionError):
+      return entry.traceback[-2].strip()
+    return msg
+
+  def __str__(self) -> str:
+    if len(self._exceptions) == 1:
+      entry = self._exceptions[0]
+      stack = "\n\t".join(entry.info_stack)
+      return f"{stack}: {entry.exception}"
+
+    return "\n".join(
+        f"{entry.info_stack}: {entry.exception}" for entry in self._exceptions)
+
+
+# Expose simpler name
+Annotator = ExceptionAnnotator
+
+def annotate(
+    *stack_entries: str,
+    exceptions: TExceptionTypes = (Exception,),
+    ignore: TExceptionTypes = tuple(),
+    throw_cls: Optional[Type[BaseException]] = MultiException
+) -> ExceptionAnnotationScope:
+  """Use to annotate an exception.
+  By default this will throw a MultiException which can keep track of
+  more annotations."""
+  return ExceptionAnnotator(throw_cls=throw_cls).capture(
+      *stack_entries, exceptions=exceptions, ignore=ignore)
+
+
+class ArgumentTypeMultiException(MultiException, argparse.ArgumentTypeError):
+  pass
+
+
+def annotate_argparsing(*stack_entries: str,
+                        exceptions: TExceptionTypes = (Exception,)):
+  """Use this to annotate argument parsing-related code blocks to get more
+  readable annotated exception back.
+  - Wraps multiple exception in an ArgumentTypeMultiException
+  - Single ArgumentTypeError are raised directly
+  """
+  return annotate(
+      *stack_entries,
+      exceptions=exceptions,
+      throw_cls=ArgumentTypeMultiException)
+
+
+class UnreachableError(RuntimeError):
+  """Used for making checker tools happy in places where it's not directly
+  obvious that we always return, for instance due to using one of the above
+  exception annotations that could in theory mute exceptions and create an
+  additional return path.
+  """
+
+  def __init__(self) -> None:
+    super().__init__("Unreachable Code")
diff --git a/crossbench/flags/__init__.py b/crossbench/flags/__init__.py
new file mode 100644
index 0000000..e9d2bfa
--- /dev/null
+++ b/crossbench/flags/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/flags/base.py b/crossbench/flags/base.py
new file mode 100644
index 0000000..2759c9b
--- /dev/null
+++ b/crossbench/flags/base.py
@@ -0,0 +1,260 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import collections
+import re
+from typing import (Any, Dict, Iterable, Iterator, List, Optional, Tuple, Type,
+                    TypeVar, Union)
+
+
+class FrozenFlagsError(RuntimeError):
+  pass
+
+
+FreezableT = TypeVar("FreezableT", bound="Freezable")
+
+
+class Freezable:
+
+  def __init__(self, *args, **kwargs) -> None:
+    self._frozen = False
+    super().__init__(*args, **kwargs)
+
+  def __hash__(self):
+    self.freeze()
+    return hash(str(self))
+
+  @property
+  def is_frozen(self) -> bool:
+    return self._frozen
+
+  def freeze(self: FreezableT) -> FreezableT:
+    self._frozen = True
+    return self
+
+  def assert_not_frozen(self, msg: Optional[str] = None) -> None:
+    if not self._frozen:
+      return
+    if not msg:
+      msg = f"Cannot modify frozen {type(self).__name__}"
+    raise FrozenFlagsError(msg)
+
+
+BasicFlagsT = TypeVar("BasicFlagsT", bound="BasicFlags")
+
+
+FlagsData = Optional[Union[Dict[str, str], "Flags",
+                           Iterable[Union[Tuple[str, Optional[str]], str]]]]
+
+
+class BasicFlags(Freezable, collections.UserDict):
+  """Basic implementation for command line flags (similar to Dic[str, str].
+
+  This class is mostly used to make sure command-line flags for browsers
+  don't end up having contradicting values.
+  """
+
+  _WHITE_SPACE_RE = re.compile(r"\s+")
+  _BASIC_FLAG_NAME_RE = re.compile(r"(--?)[^\s=-][^\s=]*")
+  # Handles space-separated flags: --foo="1" --bar  --baz='2'  --boo=3
+  _VALUE_PATTERN = (r"('(?P<value_single_quotes>[^']*)')|"
+                    r"(\"(?P<value_double_quotes>[^\"]*)\")|"
+                    r"(?P<value_no_quotes>[^'\" ]+)")
+  _END_OR_SEPARATOR_PATTERN = r"(\s*\s\s*|$)"
+  _PARSE_RE = re.compile(fr"(?P<name>{_BASIC_FLAG_NAME_RE.pattern})"
+                         fr"((?P<equal>=)({_VALUE_PATTERN})?)?"
+                         fr"{_END_OR_SEPARATOR_PATTERN}")
+
+  @classmethod
+  def split(cls, flag_str: str) -> Tuple[str, Optional[str]]:
+    if "=" in flag_str:
+      flag_name, flag_value = flag_str.split("=", maxsplit=1)
+      return (flag_name, flag_value)
+    return (flag_str, None)
+
+  @classmethod
+  def parse(cls: Type[BasicFlagsT], data: Any) -> BasicFlagsT:
+    if isinstance(data, cls):
+      return data
+    if isinstance(data, str):
+      return cls.parse_str(data)
+    return cls(data)
+
+  @classmethod
+  def parse_str(cls: Type[BasicFlagsT], raw_flags: str) -> BasicFlagsT:
+    return cls._parse_str(raw_flags)
+
+  @classmethod
+  def _parse_str(cls: Type[BasicFlagsT],
+                 raw_flags: str,
+                 msg: str = "flag") -> BasicFlagsT:
+    raw_flags = raw_flags.strip()
+    if not raw_flags:
+      return cls()
+    flag_parts: List[Tuple[str, Optional[str]]] = []
+    current_end: Optional[int] = None
+    for match in cls._PARSE_RE.finditer(raw_flags):
+      if current_end is None:
+        if match.start() != 0:
+          part = raw_flags[:match.start()]
+          raise ValueError(f"Invalid {msg} part at pos=0: {repr(part)}")
+      else:
+        if current_end != match.start():
+          raise ValueError(f"Invalid {msg}: could not consume all data")
+      current_end = match.end()
+
+      groups = match.groupdict()
+      maybe_flag_name: Optional[str] = groups.get("name")
+      if not maybe_flag_name:
+        raise ValueError(f"Invalid {msg}: {repr(raw_flags)}")
+      # Re-assign since pytype doesn't remove the Optional.
+      flag_name: str = maybe_flag_name
+      flag_value: Optional[str] = (
+          groups.get("value_single_quotes") or
+          groups.get("value_double_quotes") or groups.get("value_no_quotes"))
+      if groups.get("equal") and not flag_value:
+        raise ValueError(f"Invalid {msg}: missing value for {repr(flag_name)}")
+      assert flag_name
+      flag_parts.append((flag_name, flag_value))
+
+    if current_end != len(raw_flags):
+      part = raw_flags[current_end:]
+      raise ValueError(
+          f"Invalid {msg} part at pos={current_end or 0}: {repr(part)}")
+    return cls(flag_parts)
+
+  def __init__(self, initial_data: FlagsData = None) -> None:
+    super().__init__(initial_data)
+
+  def __setitem__(self, flag_name: str, flag_value: Optional[str]) -> None:
+    return self.set(flag_name, flag_value)
+
+  def set(self,
+          flag_name: str,
+          flag_value: Optional[str] = None,
+          override: bool = False) -> None:
+    self._set(flag_name, flag_value, override)
+
+  def _set(self,
+           flag_name: str,
+           flag_value: Optional[str] = None,
+           override: bool = False) -> None:
+    self.assert_not_frozen()
+    self._validate_flag_name(flag_name)
+    if flag_value:
+      self._validate_flag_value(flag_name, flag_value)
+    self._validate_override(flag_name, flag_value, override)
+    self.data[flag_name] = flag_value
+
+  def _validate_flag_name(self, flag_name: str) -> None:
+    if not flag_name:
+      raise ValueError("Cannot set empty flag")
+    if self._WHITE_SPACE_RE.search(flag_name):
+      raise ValueError(
+          f"Flag name cannot contain whitespaces: {repr(flag_name)}")
+    if "=" in flag_name:
+      raise ValueError(
+          f"Flag name contains '=': {repr(flag_name)}, please split")
+    if flag_name[0] != "-":
+      raise ValueError(
+          f"Flag name must begin with a '-', but got {repr(flag_name)}")
+    if not self._BASIC_FLAG_NAME_RE.fullmatch(flag_name):
+      raise ValueError(
+          f"Flag name contains invalid characters: {repr(flag_name)}")
+
+  def _validate_flag_value(self, flag_name: str, flag_value: str) -> None:
+    assert flag_value, "Got invalid empty flag_value."
+    if not isinstance(flag_value, str):
+      raise TypeError(
+          f"Expected None or string flag-value for flag {flag_name}, "
+          f"but got: {repr(flag_value)}")
+
+  def _validate_override(self, flag_name: str, flag_value: Optional[str],
+                         override: bool) -> None:
+    if override or flag_name not in self:
+      return
+    old_value = self[flag_name]
+    if flag_value != old_value:
+      raise ValueError(f"Flag {flag_name}={repr(flag_value)} was already set "
+                       f"with a different previous value: {repr(old_value)}")
+
+  # pylint: disable=arguments-differ
+  def update(self,
+             initial_data: FlagsData = None,
+             override: bool = False) -> None:
+    # pylint: disable=arguments-differ
+    if initial_data is None:
+      return
+    if isinstance(initial_data, (Flags, dict)):
+      for flag_name, flag_value in initial_data.items():
+        self.set(flag_name, flag_value, override)
+    else:
+      for flag_name_or_items in initial_data:
+        if isinstance(flag_name_or_items, str):
+          self.set(flag_name_or_items, None, override)
+        else:
+          flag_name, flag_value = flag_name_or_items
+          self.set(flag_name, flag_value, override)
+
+  def merge(self, other: FlagsData) -> None:
+    self.update(other)
+
+  def copy(self: BasicFlagsT) -> BasicFlagsT:
+    return self.__class__(self)
+
+  def merge_copy(self, other: FlagsData):
+    ret = self.copy()
+    ret.merge(other)
+    return ret
+
+  def _describe(self, flag_name: str) -> str:
+    value = self.get(flag_name)
+    if value is None:
+      return flag_name
+    return f"{flag_name}={value}"
+
+  def items(self) -> Iterable[Tuple[str, Optional[str]]]:
+    return self.data.items()
+
+  def to_dict(self) -> Dict[str, Optional[str]]:
+    return dict(self.items())
+
+  def __iter__(self) -> Iterator[str]:
+    for k, v in self.items():
+      if v is None:
+        yield k
+      else:
+        yield f"{k}={v}"
+
+  def __bool__(self) -> bool:
+    return bool(self.data)
+
+  def __repr__(self) -> str:
+    dict_repr = repr(self.to_dict())
+    return f"{type(self).__name__}({dict_repr})"
+
+  def __str__(self) -> str:
+    return " ".join(self)
+
+
+class Flags(BasicFlags):
+  """
+  Subclass with slightly stricter flag name checking.
+  Most command-line programs adhere to this.
+  """
+  _FLAG_NAME_RE = re.compile(r"(--?)[a-zA-Z0-9][a-zA-Z0-9_-]*")
+  _PARSE_RE = re.compile(fr"(?P<name>{_FLAG_NAME_RE.pattern})"
+                         fr"((?P<equal>=)({BasicFlags._VALUE_PATTERN})?)?"
+                         fr"{BasicFlags._END_OR_SEPARATOR_PATTERN}")
+
+  def _validate_flag_name(self, flag_name: str) -> None:
+    super()._validate_flag_name(flag_name)
+    if not self._FLAG_NAME_RE.fullmatch(flag_name):
+      raise ValueError(
+          f"Flag name contains invalid characters: {repr(flag_name)}")
+
+
+FlagsT = TypeVar("FlagsT", bound=Flags)
diff --git a/crossbench/flags/chrome.py b/crossbench/flags/chrome.py
new file mode 100644
index 0000000..2d11e61
--- /dev/null
+++ b/crossbench/flags/chrome.py
@@ -0,0 +1,316 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import logging
+from typing import Dict, Iterable, Iterator, Optional, Tuple
+
+from ordered_set import OrderedSet
+
+from crossbench import path as pth
+from crossbench.flags.base import Flags, FlagsData, Freezable
+from crossbench.flags.js_flags import JSFlags
+from crossbench.flags.known_js_flags import KNOWN_JS_FLAGS
+
+
+class ChromeFlags(Flags):
+  """Specialized Flags for Chrome/Chromium-based browser.
+
+  This has special treatment for --js-flags and the feature flags:
+  --enable-features/--disable-features
+  --enable-blink-features/--disable-blink-features
+  """
+  _JS_FLAG = "--js-flags"
+
+  def __init__(self, initial_data: FlagsData = None) -> None:
+    self._features = ChromeFeatures()
+    self._blink_features = ChromeBlinkFeatures()
+    self._js_flags = JSFlags()
+    super().__init__(initial_data)
+
+  def freeze(self) -> ChromeFlags:
+    super().freeze()
+    self._js_flags.freeze()
+    self._features.freeze()
+    self._blink_features.freeze()
+    return self
+
+  def __getitem__(self, key):
+    if key == self._JS_FLAG and self._js_flags:
+      return self._js_flags
+    if key == ChromeFeatures.ENABLE_FLAG and self._features.enabled:
+      return self._features.enabled_str()
+    if key == ChromeFeatures.DISABLE_FLAG and self._features.disabled:
+      return self._features.disabled_str()
+    if key == ChromeBlinkFeatures.ENABLE_FLAG and self._blink_features.enabled:
+      return self._blink_features.enabled_str()
+    if (key == ChromeBlinkFeatures.DISABLE_FLAG and
+        self._blink_features.disabled):
+      return self._blink_features.disabled_str()
+    return super().__getitem__(key)
+
+  def _set(self,
+           flag_name: str,
+           flag_value: Optional[str] = None,
+           override: bool = False) -> None:
+    self.assert_not_frozen()
+    # pylint: disable=signature-differs
+    if flag_name == ChromeFeatures.ENABLE_FLAG:
+      if flag_value is None:
+        raise ValueError(f"{ChromeFeatures.ENABLE_FLAG} cannot be None")
+      for feature in flag_value.split(","):
+        self._features.enable(feature)
+    elif flag_name == ChromeFeatures.DISABLE_FLAG:
+      if flag_value is None:
+        raise ValueError(f"{ChromeFeatures.DISABLE_FLAG} cannot be None")
+      for feature in flag_value.split(","):
+        self._features.disable(feature)
+    elif flag_name == ChromeBlinkFeatures.ENABLE_FLAG:
+      if flag_value is None:
+        raise ValueError(f"{ChromeBlinkFeatures.ENABLE_FLAG} cannot be None")
+      for feature in flag_value.split(","):
+        self._blink_features.enable(feature)
+    elif flag_name == ChromeBlinkFeatures.DISABLE_FLAG:
+      if flag_value is None:
+        raise ValueError(f"{ChromeBlinkFeatures.DISABLE_FLAG} cannot be None")
+      for feature in flag_value.split(","):
+        self._blink_features.disable(feature)
+    elif flag_name == self._JS_FLAG:
+      if flag_value is None:
+        raise ValueError(f"{self._JS_FLAG} cannot be None")
+      self._set_js_flag(flag_value, override)
+    else:
+      flag_value = self._verify_flag(flag_name, flag_value)
+      super()._set(flag_name, flag_value, override)
+
+  def _set_js_flag(self, raw_js_flags: str, override: bool) -> None:
+    new_js_flags = JSFlags(self._js_flags)
+    for js_flag_name, js_flag_value in JSFlags.parse(raw_js_flags).items():
+      new_js_flags.set(js_flag_name, js_flag_value, override=override)
+    self._js_flags.update(new_js_flags)
+
+  def _verify_flag(self, name: str, value: Optional[str]) -> Optional[str]:
+    if candidate := self._find_misspelled_flag(name):
+      logging.error(
+          "Potentially misspelled flag: '%s'. "
+          "Did you mean to use %s ?", name, candidate)
+    if candidate := self._find_js_flag(name):
+      js_flags = JSFlags()
+      js_flags.set(candidate, value)
+      logging.error(
+          "Got potential V8 flag that should be used as "
+          "--js-flags=%s", js_flags)
+    if name == "--user-data-dir":
+      if not value or not value.strip():
+        raise ValueError("--user-data-dir cannot be the empty string.")
+      # TODO: support remote platforms
+      expanded_dir = str(pth.LocalPath(value).expanduser())
+      if expanded_dir != value:
+        logging.warning(
+            "Chrome Flags: auto-expanding --user-data-dir from '%s' to '%s'",
+            value, expanded_dir)
+      return expanded_dir
+    return value
+
+  def _find_misspelled_flag(self, name: str) -> Optional[str]:
+    if name in ("--enable-feature", "--enabled-feature", "--enabled-features"):
+      return "--enable-features"
+    if name in ("--disable-feature", "--disabled-feature",
+                "--disabled-features"):
+      return "--disable-features"
+    if name in ("--enable-blink-feature", "--enabled-blink-feature",
+                "--enabled-blink-features"):
+      return "--enable-blink-features"
+    if name in ("--disable-blink-feature", "--disabled-blink-feature",
+                "--disabled-blink-features"):
+      return "--disable-blink-features"
+    return None
+
+  def _find_js_flag(self, name: str) -> Optional[str]:
+    normalized_name = name
+    if name.startswith("--no-"):
+      normalized_name = f"--{name[5:]}"
+    elif name.startswith("--no"):
+      normalized_name = f"--{name[4:]}"
+    if normalized_name in KNOWN_JS_FLAGS:
+      return name
+    return None
+
+  @property
+  def features(self) -> ChromeFeatures:
+    return self._features
+
+  @property
+  def blink_features(self) -> ChromeBlinkFeatures:
+    return self._blink_features
+
+  @property
+  def js_flags(self) -> JSFlags:
+    return self._js_flags
+
+  def merge(self, other: FlagsData) -> None:
+    if not isinstance(other, ChromeFlags):
+      other = ChromeFlags(other)
+    self.features.merge(other.features)
+    self.blink_features.merge(other.blink_features)
+    self.js_flags.merge(other.js_flags)
+    for name, value in other.base_items():
+      self.set(name, value)
+
+  def base_items(self) -> Iterable[Tuple[str, Optional[str]]]:
+    yield from super().items()
+
+  def items(self) -> Iterable[Tuple[str, Optional[str]]]:
+    yield from self.base_items()
+    if self._js_flags:
+      yield (self._JS_FLAG, str(self.js_flags))
+    yield from self.features.items()
+    yield from self.blink_features.items()
+
+  def __bool__(self) -> bool:
+    return bool(self.data) or bool(self._js_flags) or bool(
+        self._features) or bool(self._blink_features)
+
+
+class ChromeBaseFeatures(Freezable, abc.ABC):
+  ENABLE_FLAG: str = ""
+  DISABLE_FLAG: str = ""
+
+  def __init__(self) -> None:
+    super().__init__()
+    self._enabled: Dict[str, Optional[str]] = {}
+    self._disabled: OrderedSet[str] = OrderedSet()
+
+  @property
+  def is_empty(self) -> bool:
+    return len(self._enabled) == 0 and len(self._disabled) == 0
+
+  @property
+  def enabled(self) -> Dict[str, Optional[str]]:
+    return dict(self._enabled)
+
+  @property
+  def disabled(self) -> OrderedSet[str]:
+    return OrderedSet(self._disabled)
+
+  def _parse_feature(self, feature: str) -> Tuple[str, Optional[str]]:
+    if not feature:
+      raise ValueError("Cannot parse empty feature")
+    if "," in feature:
+      raise ValueError(f"{repr(feature)} contains multiple features. "
+                       "Please split them first.")
+    return self._parse_feature_parts(feature)
+
+  @abc.abstractmethod
+  def _parse_feature_parts(self, feature: str) -> Tuple[str, Optional[str]]:
+    pass
+
+  def enable(self, feature: str) -> None:
+    name, value = self._parse_feature(feature)
+    self._enable(name, value)
+
+  def _enable(self, name: str, value: Optional[str]) -> None:
+    self.assert_not_frozen()
+    if name in self._disabled:
+      raise ValueError(
+          f"Cannot enable previously disabled feature={repr(name)}")
+    if name in self._enabled:
+      prev_value = self._enabled[name]
+      if value != prev_value:
+        raise ValueError("Cannot set conflicting values "
+                         f"({repr(prev_value)}, vs. {repr(value)}) "
+                         f"for the same feature={repr(name)}")
+    else:
+      self._enabled[name] = value
+
+  def disable(self, feature: str) -> None:
+    self.assert_not_frozen()
+    name, _ = self._parse_feature(feature)
+    if name in self._enabled:
+      raise ValueError(
+          f"Cannot disable previously enabled feature={repr(name)}")
+    self._disabled.add(name)
+
+  def update(self, other: ChromeBaseFeatures) -> None:
+    if not isinstance(other, type(self)):
+      raise TypeError(f"Cannot merge {type(self)} with {type(other)}")
+    for disabled in other.disabled:
+      self.disable(disabled)
+    for name, value in other.enabled.items():
+      self._enable(name, value)
+
+  def merge(self, other: ChromeBaseFeatures) -> None:
+    self.update(other)
+
+  def items(self) -> Iterable[Tuple[str, str]]:
+    if self._enabled:
+      yield (self.ENABLE_FLAG, self.enabled_str())
+    if self._disabled:
+      yield (self.DISABLE_FLAG, self.disabled_str())
+
+  def enabled_str(self) -> str:
+    return ",".join(
+        k if v is None else f"{k}{v}" for k, v in self._enabled.items())
+
+  def disabled_str(self) -> str:
+    return ",".join(self._disabled)
+
+  def __iter__(self) -> Iterator[str]:
+    for flag_name, features_str in self.items():
+      yield f"{flag_name}={features_str}"
+
+  def __bool__(self):
+    return bool(self._enabled) or bool(self._disabled)
+
+  def __str__(self) -> str:
+    return " ".join(self)
+
+
+class ChromeFeatures(ChromeBaseFeatures):
+  """
+  Chrome Features set, throws if features are enabled and disabled at the same
+  time.
+  Examples:
+    --disable-features="MyFeature1"
+    --enable-features="MyFeature1,MyFeature2"
+    --enable-features="MyFeature1:k1/v1/k2/v2,MyFeature2"
+    --enable-features="MyFeature3<Trial2:k1/v1/k2/v2"
+  """
+
+  ENABLE_FLAG: str = "--enable-features"
+  DISABLE_FLAG: str = "--disable-features"
+
+  def _parse_feature_parts(self, feature: str) -> Tuple[str, Optional[str]]:
+    parts = feature.split("<")
+    if len(parts) == 2:
+      return (parts[0], "<" + parts[1])
+    if len(parts) != 1:
+      raise ValueError(f"Invalid number of feature parts: {repr(parts)}")
+    parts = feature.split(":")
+    if len(parts) == 2:
+      return (parts[0], ":" + parts[1])
+    if len(parts) != 1:
+      raise ValueError(f"Invalid number of feature parts: {repr(parts)}")
+    return (feature, None)
+
+
+class ChromeBlinkFeatures(ChromeBaseFeatures):
+  """
+  Chrome Features set, throws if features are enabled and disabled at the same
+  time.
+  Examples:
+    --disable-blink-features="MyFeature1"
+    --enable-blink-features="MyFeature1,MyFeature2"
+  """
+
+  ENABLE_FLAG: str = "--enable-blink-features"
+  DISABLE_FLAG: str = "--disable-blink-features"
+
+  def _parse_feature_parts(self, feature: str) -> Tuple[str, Optional[str]]:
+    if "<" in feature or ":" in feature:
+      raise ValueError("blink features do not have params, "
+                       f"but found param separator in {repr(feature)}")
+    return (feature, None)
diff --git a/crossbench/flags/js_flags.py b/crossbench/flags/js_flags.py
new file mode 100644
index 0000000..f76196f
--- /dev/null
+++ b/crossbench/flags/js_flags.py
@@ -0,0 +1,99 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import Optional
+
+from crossbench.flags.base import Flags
+
+
+class JSFlags(Flags):
+  """Custom flags implementation for V8 flags (--js-flags in chrome)
+
+  Additionally to the base Flag implementation it asserts that bool flags
+  with the --no-.../--no... prefix are not contradicting each other.
+  """
+  _NO_PREFIX = "--no"
+  _NAME_RE = re.compile(r"--[a-zA-Z_][a-zA-Z0-9_-]+")
+
+  # We allow two forms:
+  # - space separated: --foo="1" --bar  --baz='2'  --boo=3
+  # - comma separated: --foo="1",--bar ,--baz='2', --boo=3
+  _VALUE_PATTERN = (r"('(?P<value_single_quotes>[^',]+)')|"
+                    r"(\"(?P<value_double_quotes>[^\",]+)\")|"
+                    r"(?P<value_no_quotes>[^'\", =]+)")
+  _END_OR_SEPARATOR_PATTERN = r"(\s*[,\s]\s*|$)"
+  _PARSE_RE = re.compile(fr"(?P<name>{_NAME_RE.pattern})"
+                         fr"((?P<equal>=)({_VALUE_PATTERN})?)?"
+                         fr"{_END_OR_SEPARATOR_PATTERN}")
+
+  @classmethod
+  def parse_str(cls, raw_flags: str) -> JSFlags:
+    return cls._parse_str(raw_flags, "--js-flags")
+
+  def copy(self) -> JSFlags:
+    return self.__class__(self)
+
+  def _set(self,
+           flag_name: str,
+           flag_value: Optional[str] = None,
+           override: bool = False) -> None:
+    self._validate_js_flag_name(flag_name)
+    if flag_value is not None:
+      self._validate_js_flag_value(flag_name, flag_value)
+    self._check_negated_flag(flag_name, override)
+    super()._set(flag_name, flag_value, override)
+
+  def _validate_js_flag_value(self, flag_name: str, flag_value: str) -> None:
+    if not isinstance(flag_value, str):
+      raise TypeError("JSFlag value must be str, "
+                      f"but got {type(flag_value)}: {repr(flag_value)}")
+    if "," in flag_value:
+      raise ValueError(
+          "--js-flags: Comma in V8 flag value, flag escaping for chrome's "
+          f"--js-flags might not work: {flag_name}={repr(flag_value)}")
+    if self._WHITE_SPACE_RE.search(flag_value):
+      raise ValueError("--js-flags: V8 flag-values cannot contain whitespaces:"
+                       f"{flag_name}={repr(flag_value)}")
+
+  def _validate_js_flag_name(self, flag_name: str) -> None:
+    if not flag_name.startswith("--"):
+      raise ValueError("--js-flags: Only long-form flag names allowed, "
+                       f"but got {repr(flag_name)}")
+    if not self._NAME_RE.fullmatch(flag_name):
+      raise ValueError(f"--js-flags: Invalid flag name {repr(flag_name)}. \n"
+                       "Check invalid characters in the V8 flag name?")
+
+  def _check_negated_flag(self, flag_name: str, override: bool) -> None:
+    if flag_name.startswith(self._NO_PREFIX):
+      enabled = flag_name[len(self._NO_PREFIX):]
+      # Check for --no-foo form
+      if enabled.startswith("-"):
+        enabled = enabled[1:]
+      enabled = "--" + enabled
+      if override:
+        del self[enabled]
+      elif enabled in self:
+        raise ValueError(
+            f"Conflicting flag {flag_name}, "
+            f"it has already been enabled by {repr(self._describe(enabled))}")
+    else:
+      # --foo => --no-foo
+      disabled = f"--no-{flag_name[2:]}"
+      if disabled not in self:
+        # Try compact version: --foo => --nofoo
+        disabled = f"--no{flag_name[2:]}"
+        if disabled not in self:
+          return
+      if override:
+        del self[disabled]
+      else:
+        raise ValueError(f"Conflicting flag {flag_name}, "
+                         "it has previously been disabled by "
+                         f"{repr(self._describe(flag_name))}")
+
+  def __str__(self) -> str:
+    return ",".join(self)
diff --git a/crossbench/flags/known_chrome_flags.py b/crossbench/flags/known_chrome_flags.py
new file mode 100644
index 0000000..38fdc89
--- /dev/null
+++ b/crossbench/flags/known_chrome_flags.py
@@ -0,0 +1,1598 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Final
+
+# Based on external code:
+# https://github.com/beverloo/peter.sh/tree/master/services
+# https://peter.sh/experiments/chromium-command-line-switches/
+#
+# The MIT License (MIT)
+#
+# Copyright (c) 2014 Peter Beverloo
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+#
+KNOWN_CHROME_FLAGS: Final[frozenset[str]] = frozenset({
+    "--accept-empty-variations-seed-signature",
+    "--accept-lang",
+    "--accept-resource-provider",
+    "--adaboost",
+    "--add-gpu-appcontainer-caps",
+    "--add-xr-appcontainer-caps",
+    "--additional-private-state-token-key-commitments",
+    "--aggressive-cache-discard",
+    "--all",
+    "--all-renderers",
+    "--allarticles",
+    "--allow-command-line-plugins",
+    "--allow-cross-origin-auth-prompt",
+    "--allow-empty-passwords-in-tests",
+    "--allow-external-pages",
+    "--allow-failed-policy-fetch-for-test",
+    "--allow-file-access-from-files",
+    "--allow-future-manifest-version",
+    "--allow-http-background-page",
+    "--allow-http-screen-capture",
+    "--allow-insecure-localhost",
+    "--allow-legacy-extension-manifests",
+    "--allow-loopback-in-peer-connection",
+    "--allow-nacl-crxfs-api",
+    "--allow-nacl-file-handle-api",
+    "--allow-nacl-socket-api",
+    "--allow-os-install",
+    "--allow-pre-commit-input",
+    "--allow-ra-in-dev-mode",
+    "--allow-running-insecure-content",
+    "--allow-sandbox-debugging",
+    "--allow-silent-push",
+    "--allow-third-party-modules",
+    "--allow-video-codecs",
+    "--allowlisted-extension-id",
+    "--almanac-api-url",
+    "--alsa-amp-device-name",
+    "--alsa-amp-element-name",
+    "--alsa-check-close-timeout",
+    "--alsa-enable-upsampling",
+    "--alsa-fixed-output-sample-rate",
+    "--alsa-input-device",
+    "--alsa-mute-device-name",
+    "--alsa-mute-element-name",
+    "--alsa-output-avail-min",
+    "--alsa-output-buffer-size",
+    "--alsa-output-device",
+    "--alsa-output-period-size",
+    "--alsa-output-start-threshold",
+    "--alsa-volume-device-name",
+    "--alsa-volume-element-name",
+    "--also-emit-success-logs",
+    "--always-enable-hdcp",
+    "--always-use-complex-text",
+    "--alwaystrue",
+    "--angle",
+    "--animated-image-resume",
+    "--animation-duration-scale",
+    "--app",
+    "--app-auto-launched",
+    "--app-id",
+    "--app-launch-url-for-shortcuts-menu-item",
+    "--app-mode-auth-code",
+    "--app-mode-oauth-token",
+    "--app-mode-oem-manifest",
+    "--app-run-on-os-login-mode",
+    "--app-shell-allow-roaming",
+    "--app-shell-host-window-size",
+    "--app-shell-preferred-network",
+    "--apple",
+    "--apps-gallery-download-url",
+    "--apps-gallery-update-url",
+    "--apps-gallery-url",
+    "--apps-keep-chrome-alive-in-tests",
+    "--arc-availability",
+    "--arc-available",
+    "--arc-block-keymint",
+    "--arc-data-cleanup-on-start",
+    "--arc-disable-app-sync",
+    "--arc-disable-dexopt-cache",
+    "--arc-disable-download-provider",
+    "--arc-disable-gms-core-cache",
+    "--arc-disable-locale-sync",
+    "--arc-disable-media-store-maintenance",
+    "--arc-disable-play-auto-install",
+    "--arc-disable-tts-cache",
+    "--arc-erofs",
+    "--arc-force-mount-android-volumes-in-files",
+    "--arc-force-show-optin-ui",
+    "--arc-generate-play-auto-install",
+    "--arc-host-ureadahead-mode",
+    "--arc-install-event-chrome-log-for-tests",
+    "--arc-packages-cache-mode",
+    "--arc-play-store-auto-update",
+    "--arc-scale",
+    "--arc-start-mode",
+    "--arc-tos-host-for-tests",
+    "--arc-use-dev-caches",
+    "--arcore",
+    "--arcvm-ureadahead-mode",
+    "--arcvm-use-hugepages",
+    "--as-browser",
+    "--ash-allow-default-shelf-pin-layout-ignoring-sync",
+    "--ash-clear-fast-ink-buffer",
+    "--ash-constrain-pointer-to-root",
+    "--ash-contextual-nudges-interval",
+    "--ash-contextual-nudges-reset-shown-count",
+    "--ash-debug-shortcuts",
+    "--ash-dev-shortcuts",
+    "--ash-disable-touch-exploration-mode",
+    "--ash-enable-magnifier-key-scroller",
+    "--ash-enable-palette-on-all-displays",
+    "--ash-enable-software-mirroring",
+    "--ash-enable-unified-desktop",
+    "--ash-hide-notifications-for-factory",
+    "--ash-host-window-bounds",
+    "--ash-no-nudges",
+    "--ash-power-button-position",
+    "--ash-side-volume-button-position",
+    "--ash-touch-hud",
+    "--attestation-server",
+    "--attribution-reporting-debug-mode",
+    "--audio",
+    "--audio-buffer-size",
+    "--audio-capturer-with-echo-cancellation",
+    "--audio-codecs-from-edid",
+    "--audio-output-channels",
+    "--audio-output-sample-rate",
+    "--audio-process-high-priority",
+    "--aue-reached-for-update-required-test",
+    "--aura-legacy-power-button",
+    "--auth-server-allowlist",
+    "--auth-spnego-account-type",
+    "--auto",
+    "--auto-accept-camera-and-microphone-capture",
+    "--auto-accept-this-tab-capture",
+    "--auto-grant-captured-surface-control-prompt",
+    "--auto-open-devtools-for-tabs",
+    "--auto-reject-this-tab-capture",
+    "--auto-select-desktop-capture-source",
+    "--auto-select-tab-capture-source-by-title",
+    "--auto-select-window-capture-source-by-title",
+    "--autofill-api-key",
+    "--autofill-server-url",
+    "--autofill-upload-throttling-period-in-days",
+    "--autoplay-policy",
+    "--back-gesture-horizontal-threshold",
+    "--background-tracing-output-path",
+    "--bgra",
+    "--biod-fake",
+    "--birch-is-morning",
+    "--blink-settings",
+    "--block-new-web-contents",
+    "--bootstrap",
+    "--borealis-launch-options",
+    "--bottom-gesture-start-height",
+    "--bound-session-cookie-rotation-delay",
+    "--bound-session-cookie-rotation-result",
+    "--browser",
+    "--browser-data-backward-migration-for-user",
+    "--browser-data-backward-migration-mode",
+    "--browser-data-migration-for-user",
+    "--browser-data-migration-mode",
+    "--browser-startup-dialog",
+    "--browser-subprocess-path",
+    "--browser-test",
+    "--browser-ui-tests-verify-pixels",
+    "--bwsi",
+    "--bypass-app-banner-engagement-checks",
+    "--bypass-installable-message-throttle-for-testing",
+    "--campaigns-test-tag",
+    "--campbell-key",
+    "--canvas-2d-layers",
+    "--cardboard",
+    "--cast-app-background-color",
+    "--cast-developer-certificate-path",
+    "--cast-initial-screen-height",
+    "--cast-initial-screen-width",
+    "--cast-log-device-cert-chain",
+    "--cast-mirroring-target-playout-delay",
+    "--cast-mojo-broker-path",
+    "--cast-streaming-force-disable-hardware-h264",
+    "--cast-streaming-force-disable-hardware-vp8",
+    "--cast-streaming-force-disable-hardware-vp9",
+    "--cast-streaming-force-enable-hardware-h264",
+    "--cast-streaming-force-enable-hardware-vp8",
+    "--cast-streaming-force-enable-hardware-vp9",
+    "--cc-layer-tree-test-long-timeout",
+    "--cc-layer-tree-test-no-timeout",
+    "--cc-scroll-animation-duration-in-seconds",
+    "--cdm",
+    "--cdm-data-directory",
+    "--cdm-data-quota-bytes",
+    "--cellular-first",
+    "--change-stack-guard-on-fork",
+    "--character",
+    "--check-accessibility-permission",
+    "--check-damage-early",
+    "--check-for-update-interval",
+    "--check-permission",
+    "--check-screen-recording-permission",
+    "--child-wallpaper-large",
+    "--child-wallpaper-small",
+    "--cipher-suite-blacklist",
+    "--clamshell",
+    "--class",
+    "--clear-key-cdm-path-for-testing",
+    "--clear-token-service",
+    "--compensate-for-unstable-pinch-zoom",
+    "--compile-shader-always-succeeds",
+    "--component-updater",
+    "--component-updater-trust-tokens-component-path",
+    "--conch-key",
+    "--conditional-focus-window-ms",
+    "--connectivity-check-url",
+    "--conservative",
+    "--container-app-preinstall-activation-time-threshold",
+    "--content-shell-devtools-tab-target",
+    "--content-shell-hide-toolbar",
+    "--content-shell-host-window-size",
+    "--context-provider",
+    "--controller",
+    "--coral-feature-key",
+    "--cors-exempt-headers",
+    "--crash-dumps-dir",
+    "--crash-loop-before",
+    "--crash-on-failure",
+    "--crash-on-hang-threads",
+    "--crash-server-pipe-handle",
+    "--crash-server-url",
+    "--crash-test",
+    "--crashpad-handler",
+    "--crashpad-handler-pid",
+    "--create-browser-on-startup-for-tests",
+    "--credits",
+    "--cros-bundled-widevine",
+    "--cros-component-updated-widevine-hint-file",
+    "--cros-disks-fake",
+    "--cros-postlogin-data-fd",
+    "--cros-postlogin-log-file",
+    "--cros-region",
+    "--cros-startup-data-fd",
+    "--crosh-command",
+    "--cryptauth-http-host",
+    "--cryptauth-v2-devicesync-http-host",
+    "--cryptauth-v2-enrollment-http-host",
+    "--cryptohome-ignore-cleanup-ownership-for-testing",
+    "--cryptohome-recovery-service-base-url",
+    "--cryptohome-recovery-use-test-env",
+    "--cryptohome-use-authsession",
+    "--cryptohome-use-old-encryption-for-testing",
+    "--custom-android-messages-domain",
+    "--custom-devtools-frontend",
+    "--custom_summary",
+    "--d3d-support",
+    "--d3d11",
+    "--d3d11-null",
+    "--d3d11on12",
+    "--d3d9",
+    "--daemon",
+    "--dark-mode-settings",
+    "--data-quota-bytes",
+    "--data-url-in-svg-use-enabled",
+    "--dawn",
+    "--dawn-d3d11",
+    "--dawn-d3d12",
+    "--dawn-metal",
+    "--dawn-swiftshader",
+    "--dawn-vulkan",
+    "--dbus-stub",
+    "--deadline-to-synchronize-surfaces",
+    "--debug-blindauth",
+    "--debug-devtools",
+    "--debug-packed-apps",
+    "--debug-print",
+    "--default",
+    "--default-background-color",
+    "--default-country-code",
+    "--default-tile-height",
+    "--default-tile-width",
+    "--default-trace-buffer-size-limit-in-kb",
+    "--default-wallpaper-is-oem",
+    "--default-wallpaper-large",
+    "--default-wallpaper-small",
+    "--defer-external-display-timeout",
+    "--defer-feature-list",
+    "--demo-app-test-tag",
+    "--demo-mode-enrolling-username",
+    "--demo-mode-force-arc-offline-provision",
+    "--demo-mode-highlights-extension",
+    "--demo-mode-screensaver-extension",
+    "--demo-mode-swa-content-directory",
+    "--deny-permission-prompts",
+    "--derelict-detection-timeout",
+    "--derelict-idle-timeout",
+    "--desktop",
+    "--desktop-window-1080p",
+    "--deterministic-mode",
+    "--dev",
+    "--device-management-url",
+    "--device-scale-factor",
+    "--devtools-code-coverage",
+    "--devtools-flags",
+    "--diagnostics",
+    "--diagnostics-format",
+    "--diagnostics-recovery",
+    "--direct-composition-video-swap-chain-format",
+    "--direction",
+    "--disable",
+    "--disable-2d-canvas-clip-aa",
+    "--disable-2d-canvas-image-chromium",
+    "--disable-3d-apis",
+    "--disable-accelerated-2d-canvas",
+    "--disable-accelerated-mjpeg-decode",
+    "--disable-accelerated-video-decode",
+    "--disable-accelerated-video-encode",
+    "--disable-adpf",
+    "--disable-android-native-fence-sync-for-testing",
+    "--disable-angle-features",
+    "--disable-app-content-verification",
+    "--disable-arc-cpu-restriction",
+    "--disable-arc-opt-in-verification",
+    "--disable-audio-input",
+    "--disable-audio-output",
+    "--disable-auto-maximize-for-tests",
+    "--disable-auto-reload",
+    "--disable-auto-wpt-origin-isolation",
+    "--disable-back-forward-cache",
+    "--disable-background-media-suspend",
+    "--disable-background-networking",
+    "--disable-background-timer-throttling",
+    "--disable-backgrounding-occluded-windows",
+    "--disable-backing-store-limit",
+    "--disable-best-effort-tasks",
+    "--disable-blink-features",
+    "--disable-breakpad",
+    "--disable-cancel-all-touches",
+    "--disable-canvas-aa",
+    "--disable-checker-imaging",
+    "--disable-checking-optimization-guide-user-permissions",
+    "--disable-chrome-tracing-computation",
+    "--disable-component-extensions-with-background-pages",
+    "--disable-component-update",
+    "--disable-composited-antialiasing",
+    "--disable-cookie-encryption",
+    "--disable-crash-reporter",
+    "--disable-crashpad-forwarding",
+    "--disable-databases",
+    "--disable-dawn-features",
+    "--disable-default-apps",
+    "--disable-demo-mode",
+    "--disable-dev-shm-usage",
+    "--disable-device-disabling",
+    "--disable-dinosaur-easter-egg",
+    "--disable-disallow-lacros",
+    "--disable-domain-blocking-for-3d-apis",
+    "--disable-domain-reliability",
+    "--disable-drive-fs-for-testing",
+    "--disable-explicit-dma-fences",
+    "--disable-extensions",
+    "--disable-extensions-except",
+    "--disable-extensions-file-access-check",
+    "--disable-extensions-http-throttling",
+    "--disable-features",
+    "--disable-fetching-hints-at-navigation-start",
+    "--disable-field-trial-config",
+    "--disable-file-system",
+    "--disable-fine-grained-time-zone-detection",
+    "--disable-first-run-ui",
+    "--disable-font-subpixel-positioning",
+    "--disable-frame-rate-limit",
+    "--disable-gaia-services",
+    "--disable-gesture-requirement-for-presentation",
+    "--disable-gl-drawing-for-tests",
+    "--disable-gl-error-limit",
+    "--disable-gl-extensions",
+    "--disable-glsl-translator",
+    "--disable-gpu",
+    "--disable-gpu-compositing",
+    "--disable-gpu-driver-bug-workarounds",
+    "--disable-gpu-early-init",
+    "--disable-gpu-memory-buffer-compositor-resources",
+    "--disable-gpu-memory-buffer-video-frames",
+    "--disable-gpu-process-crash-limit",
+    "--disable-gpu-process-for-dx12-info-collection",
+    "--disable-gpu-program-cache",
+    "--disable-gpu-rasterization",
+    "--disable-gpu-sandbox",
+    "--disable-gpu-shader-disk-cache",
+    "--disable-gpu-vsync",
+    "--disable-gpu-watchdog",
+    "--disable-hang-monitor",
+    "--disable-headless-mode",
+    "--disable-hid-blocklist",
+    "--disable-hid-detection-on-oobe",
+    "--disable-highres-timer",
+    "--disable-histogram-customizer",
+    "--disable-image-animation-resync",
+    "--disable-in-process-stack-traces",
+    "--disable-input-event-activation-protection",
+    "--disable-ios-password-suggestions",
+    "--disable-ip-privacy-proxy",
+    "--disable-ipc-flooding-protection",
+    "--disable-javascript-harmony-shipping",
+    "--disable-kill-after-bad-ipc",
+    "--disable-lacros-keep-alive",
+    "--disable-layer-tree-host-memory-pressure",
+    "--disable-lazy-loading",
+    "--disable-lcd-text",
+    "--disable-legacy-window",
+    "--disable-libassistant-logfile",
+    "--disable-local-storage",
+    "--disable-logging",
+    "--disable-logging-redirect",
+    "--disable-login-animations",
+    "--disable-login-lacros-opening",
+    "--disable-login-screen-apps",
+    "--disable-low-end-device-mode",
+    "--disable-low-latency-dxva",
+    "--disable-low-res-tiling",
+    "--disable-machine-cert-request",
+    "--disable-main-frame-before-activation",
+    "--disable-media-session-api",
+    "--disable-metal-shader-cache",
+    "--disable-mipmap-generation",
+    "--disable-modal-animations",
+    "--disable-model-download-verification",
+    "--disable-mojo-broker",
+    "--disable-mojo-renderer",
+    "--disable-nacl",
+    "--disable-namespace-sandbox",
+    "--disable-new-content-rendering-timeout",
+    "--disable-notifications",
+    "--disable-nv12-dxgi-video",
+    "--disable-oobe-chromevox-hint-timer-for-testing",
+    "--disable-oobe-network-screen-skipping-for-testing",
+    "--disable-oopr-debug-crash-dump",
+    "--disable-origin-trial-controlled-blink-features",
+    "--disable-overscroll-edge-effect",
+    "--disable-partial-raster",
+    "--disable-partitioned-cookies",
+    "--disable-pdf-tagging",
+    "--disable-pepper-3d",
+    "--disable-per-user-timezone",
+    "--disable-permissions-api",
+    "--disable-pinch",
+    "--disable-pnacl-crash-throttling",
+    "--disable-policy-key-verification",
+    "--disable-popup-blocking",
+    "--disable-prefer-compositing-to-lcd-text",
+    "--disable-presentation-api",
+    "--disable-print-preview",
+    "--disable-prompt-on-repost",
+    "--disable-pull-to-refresh-effect",
+    "--disable-pushstate-throttle",
+    "--disable-reading-from-canvas",
+    "--disable-remote-fonts",
+    "--disable-remote-playback-api",
+    "--disable-renderer-accessibility",
+    "--disable-renderer-backgrounding",
+    "--disable-resource-scheduler",
+    "--disable-rgba-4444-textures",
+    "--disable-rollback-option",
+    "--disable-rtc-smoothness-algorithm",
+    "--disable-screen-orientation-lock",
+    "--disable-scroll-to-text-fragment",
+    "--disable-search-engine-choice-screen",
+    "--disable-seccomp-filter-sandbox",
+    "--disable-setuid-sandbox",
+    "--disable-shader-name-hashing",
+    "--disable-shared-workers",
+    "--disable-signin-frame-client-certs",
+    "--disable-site-isolation-for-policy",
+    "--disable-site-isolation-trials",
+    "--disable-skia-graphite",
+    "--disable-skia-runtime-opts",
+    "--disable-smooth-scrolling",
+    "--disable-software-compositing-fallback",
+    "--disable-software-rasterizer",
+    "--disable-speech-api",
+    "--disable-speech-synthesis-api",
+    "--disable-stack-profiler",
+    "--disable-system-font-check",
+    "--disable-third-party-keyboard-workaround",
+    "--disable-threaded-animation",
+    "--disable-threaded-compositing",
+    "--disable-timeouts-for-profiling",
+    "--disable-touch-drag-drop",
+    "--disable-usb-keyboard-detect",
+    "--disable-v8-idle-tasks",
+    "--disable-variations-safe-mode",
+    "--disable-variations-seed-fetch-throttling",
+    "--disable-video-capture-use-gpu-memory-buffer",
+    "--disable-virtual-keyboard",
+    "--disable-volume-adjust-sound",
+    "--disable-vsync-for-tests",
+    "--disable-vulkan-fallback-to-gl-for-testing",
+    "--disable-vulkan-for-tests",
+    "--disable-vulkan-surface",
+    "--disable-wayland-ime",
+    "--disable-web-security",
+    "--disable-webgl",
+    "--disable-webgl-image-chromium",
+    "--disable-webgl2",
+    "--disable-webrtc-encryption",
+    "--disable-yuv-image-decoding",
+    "--disable-zero-browsers-open-for-tests",
+    "--disable-zero-copy",
+    "--disable-zero-copy-dxgi-video",
+    "--disabled",
+    "--disallow-lacros",
+    "--disallow-non-exact-resource-reuse",
+    "--disallow-policy-block-dev-mode",
+    "--discoverability",
+    "--disk-cache-dir",
+    "--disk-cache-size",
+    "--display",
+    "--display-properties",
+    "--dmg-device",
+    "--document-user-activation-required",
+    "--dom-automation",
+    "--double-buffer-compositing",
+    "--draw-quad-split-limit",
+    "--draw-view-bounds-rects",
+    "--drm-virtual-connector-is-external",
+    "--dump-blink-runtime-call-stats",
+    "--dump-browser-histograms",
+    "--dump-dom",
+    "--dumpstate-path",
+    "--edge-touch-filtering",
+    "--egl",
+    "--elevate",
+    "--embedded-extension-options",
+    "--enable",
+    "--enable-accelerated-2d-canvas",
+    "--enable-adaptive-selection-handle-orientation",
+    "--enable-aggressive-domstorage-flushing",
+    "--enable-angle-features",
+    "--enable-arc",
+    "--enable-arcvm",
+    "--enable-arcvm-rt-vcpu",
+    "--enable-ash-debug-browser",
+    "--enable-audio-debug-recordings-from-extension",
+    "--enable-auto-reload",
+    "--enable-automation",
+    "--enable-background-thread-pool",
+    "--enable-background-tracing",
+    "--enable-begin-frame-control",
+    "--enable-benchmarking",
+    "--enable-bfcache",
+    "--enable-ble-advertising-in-apps",
+    "--enable-blink-features",
+    "--enable-blink-test-features",
+    "--enable-bookmark-undo",
+    "--enable-caret-browsing",
+    "--enable-cast-receiver",
+    "--enable-cast-streaming-receiver",
+    "--enable-chrome-browser-cloud-management",
+    "--enable-cloud-print-proxy",
+    "--enable-consumer-kiosk",
+    "--enable-content-directories",
+    "--enable-crash-reporter",
+    "--enable-crash-reporter-for-testing",
+    "--enable-crx-hash-check",
+    "--enable-dawn-backend-validation",
+    "--enable-dawn-features",
+    "--enable-dim-shelf",
+    "--enable-dinosaur-easter-egg-alt-images",
+    "--enable-direct-composition-video-overlays",
+    "--enable-discover-feed",
+    "--enable-distillability-service",
+    "--enable-dom-distiller",
+    "--enable-domain-reliability",
+    "--enable-download-warning-improvements",
+    "--enable-encryption-selection",
+    "--enable-exclusive-audio",
+    "--enable-experimental-accessibility-autoclick",
+    "--enable-experimental-accessibility-labels-debugging",
+    "--enable-experimental-accessibility-language-detection",
+    "--enable-experimental-accessibility-language-detection-dynamic",
+    "--enable-experimental-accessibility-manifest-v3",
+    "--enable-experimental-accessibility-switch-access-text",
+    "--enable-experimental-cookie-features",
+    "--enable-experimental-extension-apis",
+    "--enable-experimental-web-platform-features",
+    "--enable-experimental-webassembly-features",
+    "--enable-extension-activity-log-testing",
+    "--enable-extension-activity-logging",
+    "--enable-extension-assets-sharing",
+    "--enable-features",
+    "--enable-field-trial-config",
+    "--enable-finch-seed-delta-compression",
+    "--enable-font-antialiasing",
+    "--enable-gamepad-button-axis-events",
+    "--enable-gpu",
+    "--enable-gpu-benchmarking",
+    "--enable-gpu-blocked-time",
+    "--enable-gpu-client-logging",
+    "--enable-gpu-client-tracing",
+    "--enable-gpu-command-logging",
+    "--enable-gpu-debugging",
+    "--enable-gpu-driver-debug-logging",
+    "--enable-gpu-main-time-keeper-metrics",
+    "--enable-gpu-memory-buffer-compositor-resources",
+    "--enable-gpu-memory-buffer-video-frames",
+    "--enable-gpu-rasterization",
+    "--enable-gpu-service-logging",
+    "--enable-gpu-service-tracing",
+    "--enable-hangout-services-extension-for-testing",
+    "--enable-hardware-overlays",
+    "--enable-houdini",
+    "--enable-houdini-dlc",
+    "--enable-houdini64",
+    "--enable-idle-tracing",
+    "--enable-input",
+    "--enable-ios-handoff-to-other-devices",
+    "--enable-isolated-web-apps-in-renderer",
+    "--enable-lcd-text",
+    "--enable-leak-detection",
+    "--enable-leak-detection-heap-snapshot",
+    "--enable-legacy-background-tracing",
+    "--enable-live-caption-pref-for-testing",
+    "--enable-local-file-accesses",
+    "--enable-logging",
+    "--enable-longpress-drag-selection",
+    "--enable-low-end-device-mode",
+    "--enable-low-res-tiling",
+    "--enable-magnifier-debug-draw-rect",
+    "--enable-main-frame-before-activation",
+    "--enable-model-quality-dogfood-logging",
+    "--enable-nacl",
+    "--enable-nacl-debug",
+    "--enable-native-gpu-memory-buffers",
+    "--enable-natural-scroll-default",
+    "--enable-ndk-translation",
+    "--enable-ndk-translation64",
+    "--enable-net-benchmarking",
+    "--enable-network-information-downlink-max",
+    "--enable-new-app-menu-icon",
+    "--enable-ntp-search-engine-country-detection",
+    "--enable-oobe-chromevox-hint-timer-for-dev-mode",
+    "--enable-oobe-test-api",
+    "--enable-optimization-guide-debug-logs",
+    "--enable-page-content-annotations-logging",
+    "--enable-pepper-testing",
+    "--enable-pixel-output-in-tests",
+    "--enable-plugin-placeholder-testing",
+    "--enable-potentially-annoying-security-features",
+    "--enable-precise-memory-info",
+    "--enable-prefer-compositing-to-lcd-text",
+    "--enable-primary-node-access-for-vkms-testing",
+    "--enable-privacy-sandbox-ads-apis",
+    "--enable-profile-shortcut-manager",
+    "--enable-promo-manager-fullscreen-promos",
+    "--enable-protected-video-buffers",
+    "--enable-raster-side-dark-mode-for-images",
+    "--enable-requisition-edits",
+    "--enable-resources-file-sharing",
+    "--enable-rgba-4444-textures",
+    "--enable-sandbox-logging",
+    "--enable-scaling-clipped-images",
+    "--enable-service-binary-launcher",
+    "--enable-service-manager-tracing",
+    "--enable-sgi-video-sync",
+    "--enable-share-button-unbranded",
+    "--enable-skia-benchmarking",
+    "--enable-skia-graphite",
+    "--enable-smooth-scrolling",
+    "--enable-spatial-navigation",
+    "--enable-speech-dispatcher",
+    "--enable-spotlight-actions",
+    "--enable-stats-collection-bindings",
+    "--enable-strict-mixed-content-checking",
+    "--enable-strict-powerful-feature-restrictions",
+    "--enable-swap-buffers-with-bounds",
+    "--enable-tablet-form-factor",
+    "--enable-third-party-keyboard-workaround",
+    "--enable-threaded-texture-mailboxes",
+    "--enable-top-drag-gesture",
+    "--enable-touch-calibration-setting",
+    "--enable-touch-drag-drop",
+    "--enable-touchpad-three-finger-click",
+    "--enable-touchview",
+    "--enable-trace-app-source",
+    "--enable-tracing",
+    "--enable-tracing-format",
+    "--enable-tracing-fraction",
+    "--enable-tracing-output",
+    "--enable-ui-devtools",
+    "--enable-unsafe-extension-debugging",
+    "--enable-unsafe-webgpu",
+    "--enable-upgrade-signin-promo",
+    "--enable-user-metrics",
+    "--enable-usermedia-screen-capturing",
+    "--enable-utempter",
+    "--enable-viewport",
+    "--enable-virtual-keyboard",
+    "--enable-vtune-support",
+    "--enable-vulkan-protected-memory",
+    "--enable-wayland-ime",
+    "--enable-wayland-server",
+    "--enable-web-auth-deprecated-mojo-testing-api",
+    "--enable-webgl-developer-extensions",
+    "--enable-webgl-draft-extensions",
+    "--enable-webgl-image-chromium",
+    "--enable-webgpu-developer-features",
+    "--enable-webrtc-srtp-encrypted-headers",
+    "--enable-widevine",
+    "--enable-zero-copy",
+    "--enabled",
+    "--encode-binary",
+    "--encrypted-reporting-url",
+    "--enforce",
+    "--enforce-gl-minimums",
+    "--enforce-webrtc-ip-permission-check",
+    "--enforce_strict",
+    "--ensure-forced-color-profile",
+    "--enterprise-disable-arc",
+    "--enterprise-enable-forced-re-enrollment",
+    "--enterprise-enable-forced-re-enrollment-on-flex",
+    "--enterprise-enable-initial-enrollment",
+    "--enterprise-enable-unified-state-determination",
+    "--enterprise-enable-zero-touch-enrollment",
+    "--enterprise-enrollment-initial-modulus",
+    "--enterprise-enrollment-modulus-limit",
+    "--enterprise-force-manual-enrollment-in-test-builds",
+    "--eol-ignore-profile-creation-time",
+    "--eol-reset-dismissed-prefs",
+    "--evaluate-type",
+    "--evaluate_capability",
+    "--explicitly-allowed-ports",
+    "--export-uma-logs-to-file",
+    "--expose-internals-for-testing",
+    "--extension-apps-block-for-app-service-in-ash",
+    "--extension-apps-run-in-ash-and-lacros",
+    "--extension-apps-run-in-ash-only",
+    "--extension-content-verification",
+    "--extension-force-channel",
+    "--extension-install-event-chrome-log-for-tests",
+    "--extension-process",
+    "--extension-updater-test-request",
+    "--extensions-install-verification",
+    "--extensions-not-webstore",
+    "--extensions-on-chrome-urls",
+    "--extensions-run-in-ash-and-lacros",
+    "--extensions-run-in-ash-only",
+    "--external-metrics-collection-interval",
+    "--extra-search-query-params",
+    "--extra-web-apps-dir",
+    "--fail-audio-stream-creation",
+    "--fake-arc-recommended-apps-for-testing",
+    "--fake-drivefs-launcher-chroot-path",
+    "--fake-drivefs-launcher-socket-path",
+    "--fake-oobe-configuration-file",
+    "--fake-variations-channel",
+    "--false",
+    "--feedback-server",
+    "--field-trial-handle",
+    "--file-storage-server-upload-url",
+    "--file-url-path-alias",
+    "--file_chooser",
+    "--finch-seed-expiration-age",
+    "--finch-seed-ignore-pending-download",
+    "--finch-seed-min-download-period",
+    "--finch-seed-min-update-period",
+    "--finch-seed-no-charging-requirement",
+    "--fingerprint-sensor-location",
+    "--first-exec-after-boot",
+    "--flag-switches-begin",
+    "--flag-switches-end",
+    "--font-cache-shared-handle",
+    "--font-render-hinting",
+    "--force-app-mode",
+    "--force-assistant-onboarding",
+    "--force-birch-fetch",
+    "--force-birch-release-notes",
+    "--force-browser-crash-on-gpu-crash",
+    "--force-browser-data-migration-for-testing",
+    "--force-caption-style",
+    "--force-color-profile",
+    "--force-cryptohome-recovery-for-testing",
+    "--force-dark-mode",
+    "--force-dev-mode-highlighting",
+    "--force-device-ownership",
+    "--force-device-scale-factor",
+    "--force-device-switcher-experience",
+    "--force-devtools-available",
+    "--force-disable-variation-ids",
+    "--force-effective-connection-type",
+    "--force-enable-metrics-reporting",
+    "--force-enable-night-mode",
+    "--force-enable-stylus-tools",
+    "--force-fieldtrial-params",
+    "--force-fieldtrials",
+    "--force-first-run",
+    "--force-first-run-ui",
+    "--force-fre-default-browser-step",
+    "--force-gpu-mem-available-mb",
+    "--force-gpu-mem-discardable-limit-mb",
+    "--force-happiness-tracking-system",
+    "--force-headless-for-tests",
+    "--force-high-contrast",
+    "--force-hwid-check-result-for-test",
+    "--force-lacros-launch-at-login-screen-for-testing",
+    "--force-launch-browser",
+    "--force-login-manager-in-tests",
+    "--force-max-texture-size",
+    "--force-media-resolution-height",
+    "--force-media-resolution-width",
+    "--force-mojo-renderer",
+    "--force-msbb-setting-on-for-ukm",
+    "--force-online-connection-state-for-indicator",
+    "--force-permission-policy-unload-default-enabled",
+    "--force-pnacl-subzero",
+    "--force-prefers-no-reduced-motion",
+    "--force-prefers-reduced-motion",
+    "--force-presentation-receiver-for-testing",
+    "--force-protected-video-output-buffers",
+    "--force-raster-color-profile",
+    "--force-refresh-rate-throttle",
+    "--force-renderer-accessibility",
+    "--force-search-engine-choice-screen",
+    "--force-separate-egl-display-for-webgl-testing",
+    "--force-show-cursor",
+    "--force-show-release-track",
+    "--force-show-update-menu-badge",
+    "--force-status-area-collapsible",
+    "--force-tablet-mode",
+    "--force-tablet-power-button",
+    "--force-text-direction",
+    "--force-ui-direction",
+    "--force-update-menu-type",
+    "--force-update-remote-url",
+    "--force-variation-ids",
+    "--force-video-overlays",
+    "--force-wave-audio",
+    "--force-webgpu-compat",
+    "--force-webrtc-ip-handling-policy",
+    "--force-webxr-runtime",
+    "--force-whats-new",
+    "--forest-feature-key",
+    "--form-factor",
+    "--full-memory-crash-report",
+    "--gaia-config",
+    "--gaia-config-contents",
+    "--gaia-url",
+    "--gamepad-polling-interval",
+    "--gcm-checkin-url",
+    "--gcm-mcs-endpoint",
+    "--gcm-registration-url",
+    "--generate-accessibility-test-expectations",
+    "--generate-pdf-document-outline",
+    "--get-access-token-for-test",
+    "--gl",
+    "--gl-egl",
+    "--gl-null",
+    "--gl-shader-interm-output",
+    "--gles",
+    "--gles-egl",
+    "--gles-null",
+    "--google-api-key",
+    "--google-apis-url",
+    "--google-base-url",
+    "--google-doodle-url",
+    "--google-url",
+    "--gpu",
+    "--gpu-blocklist-test-group",
+    "--gpu-device-id",
+    "--gpu-disk-cache-size-kb",
+    "--gpu-driver-bug-list-test-group",
+    "--gpu-driver-version",
+    "--gpu-launcher",
+    "--gpu-no-context-lost",
+    "--gpu-preferences",
+    "--gpu-process",
+    "--gpu-program-cache-size-kb",
+    "--gpu-rasterization-msaa-sample-count",
+    "--gpu-revision",
+    "--gpu-sandbox-allow-sysv-shm",
+    "--gpu-sandbox-failures-fatal",
+    "--gpu-sandbox-start-early",
+    "--gpu-startup-dialog",
+    "--gpu-sub-system-id",
+    "--gpu-vendor-id",
+    "--gpu-watchdog-timeout-seconds",
+    "--gpu2-startup-dialog",
+    "--graphics-buffer-count",
+    "--growth-campaigns",
+    "--growth-campaigns-path",
+    "--guest",
+    "--guest-wallpaper-large",
+    "--guest-wallpaper-small",
+    "--h",
+    "--hardware-video-decode-framerate",
+    "--hardware_video_decoding",
+    "--hardware_video_encoding",
+    "--has-chromeos-keyboard",
+    "--has-hps",
+    "--has-internal-stylus",
+    "--has-number-pad",
+    "--headless",
+    "--hermes-fake",
+    "--hidden-network-migration-age",
+    "--hidden-network-migration-interval",
+    "--hide-crash-restore-bubble",
+    "--hide-icons",
+    "--hide-scrollbars",
+    "--highlight-all-webviews",
+    "--highlight-non-lcd-text-layers",
+    "--homedir",
+    "--homepage",
+    "--host",
+    "--host-package-label",
+    "--host-package-name",
+    "--host-resolver-rules",
+    "--host-version-code",
+    "--icon_reader",
+    "--ignore-arcvm-dev-conf",
+    "--ignore-autocomplete-off-autofill",
+    "--ignore-certificate-errors-spki-list",
+    "--ignore-google-port-numbers",
+    "--ignore-gpu-blocklist",
+    "--ignore-profile-directory-if-not-exists",
+    "--ignore-unknown-auth-factors",
+    "--ignore-user-profile-mapping-for-tests",
+    "--ime",
+    "--in-process-broker",
+    "--in-process-gpu",
+    "--incognito",
+    "--init-isolate-as-foreground",
+    "--initial-preferences-file",
+    "--initialize-client-hints-storage",
+    "--input",
+    "--inspector-protocol-log",
+    "--install-autogenerated-theme",
+    "--install-chrome-app",
+    "--install-isolated-web-app-from-file",
+    "--install-isolated-web-app-from-url",
+    "--install-log-fast-upload-for-tests",
+    "--instant-process",
+    "--ip-address-space-overrides",
+    "--ipc-connection-timeout",
+    "--ipc-dump-directory",
+    "--ipc-fuzzer-testcase",
+    "--isolate-origins",
+    "--isolated-context-origins",
+    "--isolation-by-default",
+    "--javascript-harmony",
+    "--js-flags",
+    "--keep-alive-for-test",
+    "--kiosk",
+    "--kiosk-printing",
+    "--kiosk-splash-screen-min-time-seconds",
+    "--lacros-availability-ignore",
+    "--lacros-chrome-additional-args",
+    "--lacros-chrome-additional-args-file",
+    "--lacros-chrome-additional-env",
+    "--lacros-chrome-path",
+    "--lacros-mojo-socket-for-testing",
+    "--lacros-selection-policy-ignore",
+    "--lang",
+    "--last-launched-app",
+    "--launch-rma",
+    "--launch-time-ticks",
+    "--layer",
+    "--libassistant",
+    "--list-apps",
+    "--list-audio-devices",
+    "--llvm-profile-file",
+    "--load-and-launch-app",
+    "--load-apps",
+    "--load-extension",
+    "--load-guest-mode-test-extension",
+    "--load-signin-profile-test-extension",
+    "--loading-predictor-allow-local-request-for-testing",
+    "--localhost",
+    "--log-best-effort-tasks",
+    "--log-file",
+    "--log-gpu-control-list-decisions",
+    "--log-level",
+    "--log-missing-unload-ack",
+    "--log-net-log",
+    "--log-on-ui-double-background-blur",
+    "--login-manager",
+    "--login-profile",
+    "--login-user",
+    "--lso-url",
+    "--ltr",
+    "--mahi-feature-key",
+    "--make-chrome-default",
+    "--make-default-browser",
+    "--managed-mode",
+    "--managed-user-id",
+    "--mangle-localized-strings",
+    "--manual",
+    "--market-url-for-testing",
+    "--marketing-opt-in-url",
+    "--max-active-webgl-contexts",
+    "--max-decoded-image-size-mb",
+    "--max-gum-fps",
+    "--max-output-volume-dba1m",
+    "--max-untiled-layer-height",
+    "--max-untiled-layer-width",
+    "--max-web-media-player-count",
+    "--mem-pressure-system-reserved-kb",
+    "--memlog",
+    "--memlog-sampling-rate",
+    "--memlog-stack-mode",
+    "--message-loop-type-ui",
+    "--metal",
+    "--metal-null",
+    "--metrics-client-id",
+    "--metrics-recording-only",
+    "--metrics-shmem-handle",
+    "--metrics-upload-interval",
+    "--mf_cdm",
+    "--min-height-for-gpu-raster-tile",
+    "--min-video-decoder-output-buffer-size",
+    "--minimal",
+    "--mirroring",
+    "--mixed",
+    "--mixer-enable-dynamic-channel-count",
+    "--mixer-service-endpoint",
+    "--mixer-service-port",
+    "--mixer-source-audio-ready-threshold-ms",
+    "--mixer-source-input-queue-ms",
+    "--mock",
+    "--mock-cert-verifier-default-result-for-testing",
+    "--model-quality-service-api-key",
+    "--model-quality-service-url",
+    "--modifier-split-feature-key",
+    "--mojo-core-library-path",
+    "--mojo-is-broker",
+    "--mojo-local-storage",
+    "--mojo-pipe-token",
+    "--monitoring-destination-id",
+    "--mse-audio-buffer-size-limit-mb",
+    "--mse-video-buffer-size-limit-mb",
+    "--mute-audio",
+    "--nacl-debug-mask",
+    "--nacl-gdb",
+    "--nacl-gdb-script",
+    "--nacl-loader",
+    "--native",
+    "--native-messaging-connect-extension",
+    "--native-messaging-connect-host",
+    "--native-messaging-connect-id",
+    "--native-with-thread-names",
+    "--nearby-share-certificate-validity-period-hours",
+    "--nearby-share-device-id",
+    "--nearby-share-num-private-certificates",
+    "--nearby-share-verbose-logging",
+    "--nearbysharing-http-host",
+    "--net-log",
+    "--net-log-capture-mode",
+    "--net-log-max-size-mb",
+    "--netifs-to-ignore",
+    "--network",
+    "--network-quiet-timeout",
+    "--new-window",
+    "--no-default-browser-check",
+    "--no-delay-for-dx12-vulkan-info-collection",
+    "--no-experiments",
+    "--no-first-run",
+    "--no-mojo",
+    "--no-network-profile-warning",
+    "--no-pdf-header-footer",
+    "--no-pings",
+    "--no-pre-read-main-dll",
+    "--no-proxy-server",
+    "--no-sandbox",
+    "--no-service-autorun",
+    "--no-startup-window",
+    "--no-subproc-heap-profiling",
+    "--no-system-proxy-config-service",
+    "--no-unsandboxed-zygote",
+    "--no-user-gesture-required",
+    "--no-xr-runtime",
+    "--no-xshm",
+    "--no-zygote",
+    "--no-zygote-sandbox",
+    "--noerrdialogs",
+    "--none",
+    "--none_and_elevated",
+    "--note-taking-app-ids",
+    "--notification-inline-reply",
+    "--notification-launch-id",
+    "--null",
+    "--num-raster-threads",
+    "--nv12",
+    "--oauth-account-manager-url",
+    "--oauth2-client-id",
+    "--oauth2-client-secret",
+    "--offer-in-settings",
+    "--offscreen-document-testing",
+    "--on-the-fly-mhtml-hash-computation",
+    "--on_device_model_execution",
+    "--ondevice-validation-request-override",
+    "--ondevice-validation-write-to-file",
+    "--ondevice_handwriting",
+    "--oobe-eula-url-for-tests",
+    "--oobe-force-tablet-first-run",
+    "--oobe-large-screen-special-scaling",
+    "--oobe-print-frontend-load-timings",
+    "--oobe-screenshot-dir",
+    "--oobe-show-accessibility-button-on-marketing-opt-in-for-testing",
+    "--oobe-skip-new-user-check-for-testing",
+    "--oobe-skip-postlogin",
+    "--oobe-skip-to-login",
+    "--oobe-timer-interval",
+    "--oobe-timezone-override-for-tests",
+    "--oobe-trigger-sync-timeout-for-tests",
+    "--opengraph",
+    "--openxr",
+    "--optimization-guide-fetch-hints-override",
+    "--optimization-guide-fetch-hints-override-timer",
+    "--optimization-guide-model-execution-validate",
+    "--optimization-guide-model-override",
+    "--optimization-guide-model-validate",
+    "--optimization-guide-ondevice-model-adaptations-override",
+    "--optimization-guide-ondevice-model-execution-override",
+    "--optimization-guide-service-api-key",
+    "--optimization-guide-service-get-hints-url",
+    "--optimization-guide-service-get-models-url",
+    "--optimization-guide-service-model-execution-url",
+    "--optimization_guide_hints_override",
+    "--orientation-sensors",
+    "--origin-trial-disabled-features",
+    "--origin-trial-disabled-tokens",
+    "--origin-trial-public-key",
+    "--output",
+    "--override-enabled-cdm-interface-version",
+    "--override-hardware-secure-codecs-for-testing",
+    "--override-language-detection",
+    "--override-metrics-upload-url",
+    "--override-use-software-gl-for-tests",
+    "--overview-button-for-tests",
+    "--ozone-dump-file",
+    "--ozone-override-screen-size",
+    "--ozone-platform",
+    "--ozone-platform-hint",
+    "--pack-extension",
+    "--pack-extension-key",
+    "--package-name",
+    "--package-version-name",
+    "--page-content-annotations-validation-batch-size",
+    "--page-content-annotations-validation-content-visibility",
+    "--page-content-annotations-validation-startup-delay-seconds",
+    "--page-content-annotations-validation-write-to-file",
+    "--parent-window",
+    "--passthrough",
+    "--password-store",
+    "--pdf-renderer",
+    "--pdf_conversion",
+    "--pen-devices",
+    "--perf-test-print-uma-means",
+    "--perfetto-disable-interning",
+    "--performance",
+    "--picker-feature-key",
+    "--playready-key-system",
+    "--policy",
+    "--policy-verification-key",
+    "--ppapi",
+    "--ppapi-antialiased-text-enabled",
+    "--ppapi-in-process",
+    "--ppapi-plugin-launcher",
+    "--ppapi-startup-dialog",
+    "--ppapi-subpixel-rendering-setting",
+    "--pre-crashpad-crash-test",
+    "--prediction-service-mock-likelihood",
+    "--preinstalled-web-apps-dir",
+    "--prevent-kiosk-autolaunch-for-testing",
+    "--prevent-resizing-contents-for-testing",
+    "--previous-app",
+    "--print-to-pdf",
+    "--print_backend",
+    "--print_compositor",
+    "--printing-ppd-channel",
+    "--privacy-policy-host-for-tests",
+    "--private-aggregation-developer-mode",
+    "--privet-ipv6-only",
+    "--process-per-site",
+    "--process-per-tab",
+    "--product-version",
+    "--production",
+    "--profile-base-name",
+    "--profile-directory",
+    "--profile-email",
+    "--profile-management-attributes",
+    "--profile-requires-policy",
+    "--profiling-at-start",
+    "--profiling-file",
+    "--profiling-flush",
+    "--protected-audiences-consented-debug-token",
+    "--proxy-auto-detect",
+    "--proxy-bypass-list",
+    "--proxy-pac-url",
+    "--proxy-server",
+    "--proxy_resolver_win",
+    "--pseudo",
+    "--public-accounts-saml-acl-url",
+    "--pull-to-refresh",
+    "--purge-model-and-features-store",
+    "--purge-optimization-guide-store",
+    "--pwa-launcher-version",
+    "--qs-add-fake-bluetooth-devices",
+    "--qs-add-fake-cast-devices",
+    "--qs-show-locale-tile",
+    "--query-tiles-country-code",
+    "--query-tiles-enable-trending",
+    "--query-tiles-instant-background-task",
+    "--query-tiles-rank-tiles",
+    "--query-tiles-single-tier",
+    "--quota-change-event-interval",
+    "--raise-timer-frequency",
+    "--rdp_desktop_session",
+    "--reader-mode-feedback",
+    "--reader-mode-heuristics",
+    "--realtime-reporting-url",
+    "--redirect-libassistant-logging",
+    "--reduce-accept-language",
+    "--reduce-user-agent-minor-version",
+    "--reduce-user-agent-platform-oscpu",
+    "--register-max-dark-suspend-delay",
+    "--register-pepper-plugins",
+    "--regulatory-label-dir",
+    "--relauncher",
+    "--remote-allow-origins",
+    "--remote-debug-mode",
+    "--remote-debugging-address",
+    "--remote-debugging-io-pipes",
+    "--remote-debugging-pipe",
+    "--remote-debugging-port",
+    "--remote-debugging-socket-name",
+    "--remote-debugging-targets",
+    "--remote-reboot-command-timeout-in-seconds-for-testing",
+    "--renderer",
+    "--renderer-client-id",
+    "--renderer-cmd-prefix",
+    "--renderer-process-limit",
+    "--renderer-sampling",
+    "--renderer-startup-dialog",
+    "--renderer-wait-for-java-debugger",
+    "--renderpass",
+    "--report-vp9-as-an-unsupported-mime-type",
+    "--request-desktop-sites",
+    "--require-wlan",
+    "--reset-browsing-instance-between-tests",
+    "--reset-variation-state",
+    "--restart",
+    "--restore-key-on-lock-screen",
+    "--restore-last-session",
+    "--restrict-gamepad-access",
+    "--reven-branding",
+    "--rlz-ping-delay",
+    "--rma-not-allowed",
+    "--rtl",
+    "--run-all-compositor-stages-before-draw",
+    "--run-manual",
+    "--run-web-tests",
+    "--safe-mode",
+    "--safebrowsing-enable-enhanced-protection",
+    "--safebrowsing-manual-download-blacklist",
+    "--saml-password-change-url",
+    "--sandbox-ipc",
+    "--save-page-as-mhtml",
+    "--scheduled-reboot-grace-period-in-seconds-for-testing",
+    "--scheduler-boost-urgent",
+    "--scheduler-configuration",
+    "--scheduler-configuration-default",
+    "--screen-capture-audio-default-unchecked",
+    "--screen-config",
+    "--screen_ai",
+    "--screenshot",
+    "--seal-key",
+    "--search-engine-choice-country",
+    "--search-provider-logo-url",
+    "--secondary-display-layout",
+    "--secure-connect-api-url",
+    "--service",
+    "--service-name",
+    "--service-request-attachment-name",
+    "--service-sandbox-type",
+    "--service_with_jit",
+    "--set-extension-throttle-test-params",
+    "--setup",
+    "--shader-cache-path",
+    "--shared-array-buffer-allowed-origins",
+    "--shared-array-buffer-unrestricted-access-allowed",
+    "--shared-files",
+    "--shelf-hotseat",
+    "--shill-stub",
+    "--short-merge-session-timeout-for-test",
+    "--short-reporting-delay",
+    "--show-aggregated-damage",
+    "--show-autofill-signatures",
+    "--show-autofill-type-predictions",
+    "--show-component-extension-options",
+    "--show-composited-layer-borders",
+    "--show-dc-layer-debug-borders",
+    "--show-fps-counter",
+    "--show-icons",
+    "--show-layer-animation-bounds",
+    "--show-layout-shift-regions",
+    "--show-login-dev-overlay",
+    "--show-mac-overlay-borders",
+    "--show-oobe-dev-overlay",
+    "--show-oobe-quick-start-debugger",
+    "--show-overdraw-feedback",
+    "--show-paint-rects",
+    "--show-property-changed-rects",
+    "--show-screenspace-rects",
+    "--show-surface-damage-rects",
+    "--show-taps",
+    "--signed-out-ntp-modules",
+    "--silent-debugger-extension-api",
+    "--silent-launch",
+    "--simulate-browsing-data-lifetime",
+    "--simulate-critical-update",
+    "--simulate-elevated-recovery",
+    "--simulate-idle-timeout",
+    "--simulate-outdated",
+    "--simulate-outdated-no-au",
+    "--simulate-update-error-code",
+    "--simulate-update-hresult",
+    "--simulate-upgrade",
+    "--single-process",
+    "--site-per-process",
+    "--skia-font-cache-limit-mb",
+    "--skia-graphite-backend",
+    "--skia-resource-cache-limit-mb",
+    "--skip-force-online-signin-for-testing",
+    "--skip-local-upm-gms-core-version-check-for-testing",
+    "--skip-multidevice-screen",
+    "--skip-reorder-nudge-show-threshold-duration",
+    "--slow-down-compositing-scale-factor",
+    "--slow-down-raster-scale-factor",
+    "--sms-test-messages",
+    "--source-shortcut",
+    "--speech_recognition",
+    "--ssl-key-log-file",
+    "--ssl-version-max",
+    "--ssl-version-min",
+    "--stabilize-time-dependent-view-for-tests",
+    "--stable-release-mode",
+    "--staging",
+    "--start-fullscreen",
+    "--start-maximized",
+    "--start-stack-profiler",
+    "--storage-pressure-notification-interval",
+    "--stub",
+    "--subproc-heap-profiling",
+    "--supports-clamshell-auto-rotation",
+    "--suppress-message-center-popups",
+    "--surface",
+    "--swiftshader",
+    "--swiftshader-webgl",
+    "--sys-info-file-path",
+    "--system-aec-enabled",
+    "--system-developer-mode",
+    "--system-font-family",
+    "--system-gesture-start-height",
+    "--system-gesture-start-width",
+    "--system-log-upload-frequency",
+    "--telemetry-extension-dir",
+    "--test-child-process",
+    "--test-encryption-migration-ui",
+    "--test-gl-lib",
+    "--test-memory-log-delay-in-minutes",
+    "--test-name",
+    "--test-register-standard-scheme",
+    "--test-third-party-cookie-phaseout",
+    "--test-type",
+    "--test-wallpaper-server",
+    "--tether-host-scans-ignore-wired-connections",
+    "--tether-stub",
+    "--text-contrast",
+    "--text-gamma",
+    "--third-party-doodle-url",
+    "--time-before-onboarding-survey-in-seconds-for-testing",
+    "--time-ticks-at-unix-epoch",
+    "--timeout",
+    "--tint-composited-content",
+    "--tint-composited-content-modulate",
+    "--tls1.2",
+    "--tls1.3",
+    "--top-chrome-touch-ui",
+    "--top-controls-hide-threshold",
+    "--top-controls-show-threshold",
+    "--touch-devices",
+    "--touch-events",
+    "--touch-selection-strategy",
+    "--touch-slop-distance",
+    "--touch_view",
+    "--touchscreen-usable-while-screen-off",
+    "--tpm-is-dynamic",
+    "--trace-config-file",
+    "--trace-smb-size",
+    "--trace-startup",
+    "--trace-startup-duration",
+    "--trace-startup-enable-privacy-filtering",
+    "--trace-startup-file",
+    "--trace-startup-format",
+    "--trace-startup-owner",
+    "--trace-startup-record-mode",
+    "--trace-to-console",
+    "--trace-to-file",
+    "--trace-to-file-name",
+    "--translate-ranker-model-url",
+    "--translate-script-url",
+    "--translate-security-origin",
+    "--true",
+    "--trusted-download-sources",
+    "--try-supported-channel-layouts",
+    "--tts",
+    "--type",
+    "--ui-disable-partial-swap",
+    "--ui-disable-zero-copy",
+    "--ui-enable-rgba-4444-textures",
+    "--ui-enable-zero-copy",
+    "--ui-show-composited-layer-borders",
+    "--ui-show-fps-counter",
+    "--ui-show-layer-animation-bounds",
+    "--ui-show-paint-rects",
+    "--ui-show-property-changed-rects",
+    "--ui-show-screenspace-rects",
+    "--ui-show-surface-damage-rects",
+    "--ui-slow-animations",
+    "--ui-toolkit",
+    "--ukm-server-url",
+    "--uma-insecure-server-url",
+    "--uma-server-url",
+    "--unfiltered-bluetooth-devices",
+    "--uninstall",
+    "--uninstall-app-id",
+    "--unlimited-storage",
+    "--unsafely-allow-protected-media-identifier-for-domain",
+    "--unsafely-disable-devtools-self-xss-warnings",
+    "--unsafely-treat-insecure-origin-as-secure",
+    "--url_forwarder_configurator",
+    "--use-adapter-luid",
+    "--use-angle",
+    "--use-cast-browser-pref-config",
+    "--use-cmd-decoder",
+    "--use-context-snapshot",
+    "--use-cras",
+    "--use-fake-codec-for-peer-connection",
+    "--use-fake-cras-audio-client-for-dbus",
+    "--use-fake-device-for-media-stream",
+    "--use-fake-mahi-manager",
+    "--use-fake-mjpeg-decode-accelerator",
+    "--use-fake-ui-for-digital-identity",
+    "--use-fake-ui-for-fedcm",
+    "--use-fake-ui-for-media-stream",
+    "--use-file-for-fake-audio-capture",
+    "--use-file-for-fake-video-capture",
+    "--use-first-display-as-internal",
+    "--use-first-party-set",
+    "--use-gl",
+    "--use-gpu-in-tests",
+    "--use-heap-profiling-proto-writer",
+    "--use-legacy-metrics-service",
+    "--use-mobile-user-agent",
+    "--use-mock-cert-verifier-for-testing",
+    "--use-mock-keychain",
+    "--use-myfiles-in-user-data-dir-for-testing",
+    "--use-redist-dml",
+    "--use-related-website-set",
+    "--use-skia-font-manager",
+    "--use-system-clipboard",
+    "--use-system-default-printer",
+    "--use-system-proxy-resolver",
+    "--use-va-dev-keys",
+    "--use-vulkan",
+    "--use-wayland-explicit-grab",
+    "--user-agent",
+    "--user-agent-product",
+    "--user-data-dir",
+    "--user-data-migrated",
+    "--user-gesture-required",
+    "--utility",
+    "--utility-and-browser",
+    "--utility-cmd-prefix",
+    "--utility-sampling",
+    "--utility-startup-dialog",
+    "--utility-sub-type",
+    "--v",
+    "--v8-cache-options",
+    "--validate-crx",
+    "--validate-input-event-stream",
+    "--validating",
+    "--variations-insecure-server-url",
+    "--variations-override-country",
+    "--variations-seed-fetch-interval",
+    "--variations-seed-version",
+    "--variations-server-url",
+    "--variations-test-seed-path",
+    "--verbose-logging-in-nacl",
+    "--version",
+    "--video-capture-use-gpu-memory-buffer",
+    "--video-image-texture-target",
+    "--video-threads",
+    "--video_capture",
+    "--view-stack-traces",
+    "--virtual-time-budget",
+    "--viz-demo-use-gpu",
+    "--vmodule",
+    "--vsync-interval",
+    "--vulkan",
+    "--vulkan-heap-memory-limit-mb",
+    "--vulkan-null",
+    "--vulkan-sync-cpu-memory-limit-mb",
+    "--wait-for-debugger",
+    "--wait-for-debugger-children",
+    "--wait-for-debugger-on-navigation",
+    "--wait-for-debugger-webui",
+    "--wallet-service-use-sandbox",
+    "--waveout-buffers",
+    "--web-otp-backend",
+    "--web-otp-backend-auto",
+    "--web-otp-backend-sms-verification",
+    "--web-otp-backend-user-consent",
+    "--web-ui-data-source-path-for-testing",
+    "--webapk-server-url",
+    "--webauthn-gpm-pin-reset-reauth-url",
+    "--webauthn-permit-enterprise-attestation",
+    "--webauthn-remote-desktop-support",
+    "--webauthn-remote-proxied-requests-allowed-additional-origin",
+    "--webgl-antialiasing-mode",
+    "--webgl-msaa-sample-count",
+    "--webrtc-event-log-proactive-pruning-delta",
+    "--webrtc-event-log-upload-delay-ms",
+    "--webrtc-event-log-upload-no-suppression",
+    "--webrtc-event-logging",
+    "--webrtc-ip-handling-policy",
+    "--webview-disable-safebrowsing-support",
+    "--webview-draw-functor-uses-vulkan",
+    "--webview-enable-modern-cookie-same-site",
+    "--webview-enable-trust-tokens-component",
+    "--webview-fenced-frames",
+    "--webview-force-crash-java",
+    "--webview-force-crash-native",
+    "--webview-force-disable-3pcs",
+    "--webview-fps-component",
+    "--webview-log-js-console-messages",
+    "--webview-safebrowsing-block-all-resources",
+    "--webview-sandboxed-renderer",
+    "--webview-selective-image-inversion-darkening",
+    "--webview-tpcd-metadata-component",
+    "--webview-use-separate-resource-context",
+    "--webview-verbose-logging",
+    "--win-jumplist-action",
+    "--window-name",
+    "--window-position",
+    "--window-size",
+    "--window-workspace",
+    "--winhttp-proxy-resolver",
+    "--wm-window-animations-disabled",
+    "--xr_compositing",
+    "--xsession_chooser",
+    "--yuy2",
+    "--zygote",
+})
diff --git a/crossbench/flags/known_js_flags.py b/crossbench/flags/known_js_flags.py
new file mode 100644
index 0000000..4fc1244
--- /dev/null
+++ b/crossbench/flags/known_js_flags.py
@@ -0,0 +1,794 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Final
+
+# Extracted by:
+# - Run `d8 --print-flag-value`
+# - Strip "--no-" prefixes
+# - Sort list
+KNOWN_JS_FLAGS: Final[frozenset[str]] = frozenset({
+    "--abort-on-bad-builtin-profile-data",
+    "--abort-on-contradictory-flags",
+    "--abort-on-far-code-range",
+    "--abort-on-uncaught-exception",
+    "--adjust-os-scheduling-parameters",
+    "--allocation-buffer-parking",
+    "--allocation-site-pretenuring",
+    "--allocation-site-tracking",
+    "--allow-natives-for-differential-fuzzing",
+    "--allow-natives-syntax",
+    "--allow-overwriting-for-next-flag",
+    "--allow-unsafe-function-constructor",
+    "--always-osr",
+    "--always-osr-from-maglev",
+    "--always-sparkplug",
+    "--always-turbofan",
+    "--always-use-string-forwarding-table",
+    "--analyze-environment-liveness",
+    "--arm-arch",
+    "--asm-wasm-lazy-compilation",
+    "--assert-types",
+    "--async-stack-traces",
+    "--baseline-batch-compilation",
+    "--baseline-batch-compilation-threshold",
+    "--battery-saver-mode",
+    "--better-code-range-allocation",
+    "--builtin-subclassing",
+    "--builtins-in-stack-traces",
+    "--bytecode-old-age",
+    "--bytecode-old-time",
+    "--cache-prototype-transitions",
+    "--check-handle-count",
+    "--clear-exceptions-on-js-entry",
+    "--clear-free-memory",
+    "--code-comments",
+    "--code-stats",
+    "--compact",
+    "--compact-code-space",
+    "--compact-code-space-with-stack",
+    "--compact-on-every-full-gc",
+    "--compact-with-stack",
+    "--compilation-cache",
+    "--compile-hints-magic",
+    "--concurrent-array-buffer-sweeping",
+    "--concurrent-cache-deserialization",
+    "--concurrent-maglev-high-priority-threads",
+    "--concurrent-maglev-max-threads",
+    "--concurrent-marking",
+    "--concurrent-marking-high-priority-threads",
+    "--concurrent-marking-max-worker-num",
+    "--concurrent-minor-ms-marking",
+    "--concurrent-osr",
+    "--concurrent-recompilation",
+    "--concurrent-recompilation-delay",
+    "--concurrent-recompilation-queue-length",
+    "--concurrent-sparkplug",
+    "--concurrent-sparkplug-high-priority-threads",
+    "--concurrent-sparkplug-max-threads",
+    "--concurrent-sweeping",
+    "--concurrent-turbofan-max-threads",
+    "--conservative-stack-scanning",
+    "--correctness-fuzzer-suppressions",
+    "--cppgc-young-generation",
+    "--cppheap-concurrent-marking",
+    "--cppheap-incremental-marking",
+    "--cpu-profiler-sampling-interval",
+    "--csa-trap-on-node",
+    "--debug-code",
+    "--default-to-experimental-regexp-engine",
+    "--deopt-every-n-times",
+    "--deopt-to-baseline",
+    "--detailed-error-stack-trace",
+    "--detailed-line-info",
+    "--detect-ineffective-gcs-near-heap-limit",
+    "--dict-property-const-tracking",
+    "--direct-handle",
+    "--direct-local",
+    "--disable-abortjs",
+    "--disable-old-api-accessors",
+    "--disable-write-barriers",
+    "--disallow-code-generation-from-strings",
+    "--dump-allocations-digest-at-alloc",
+    "--dump-builtins-hashes-to-file",
+    "--dump-wasm-module",
+    "--dump-wasm-module-path",
+    "--efficiency-mode-delay-turbofan",
+    "--efficiency-mode-disable-turbofan",
+    "--efficiency-mode-for-tiering-heuristics",
+    "--efficiency-mode",
+    "--embedded-src",
+    "--embedded-variant",
+    "--embedder-instance-types",
+    "--enable-32dregs",
+    "--enable-allocation-folding",
+    "--enable-armv7",
+    "--enable-armv8",
+    "--enable-avx",
+    "--enable-avx2",
+    "--enable-bmi1",
+    "--enable-bmi2",
+    "--enable-etw-stack-walking",
+    "--enable-experimental-regexp-engine",
+    "--enable-experimental-regexp-engine-on-excessive-backtracks",
+    "--enable-fma3",
+    "--enable-lazy-source-positions",
+    "--enable-lzcnt",
+    "--enable-neon",
+    "--enable-popcnt",
+    "--enable-regexp-unaligned-accesses",
+    "--enable-sahf",
+    "--enable-sealed-frozen-elements-kind",
+    "--enable-sharedarraybuffer-per-context",
+    "--enable-slow-asserts",
+    "--enable-source-at-csa-bind",
+    "--enable-sse3",
+    "--enable-sse4-1",
+    "--enable-sse4-2",
+    "--enable-ssse3",
+    "--enable-sudiv",
+    "--enable-testing-opcode-in-wasm",
+    "--enable-third-party-heap",
+    "--enable-unconditional-write-barriers",
+    "--enable-vfp3",
+    "--enable-wasm-arm64-generic-wrapper",
+    "--ephemeron-fixpoint-iterations",
+    "--exit-on-contradictory-flags",
+    "--experimental",
+    "--experimental-flush-embedded-blob-icache",
+    "--experimental-stack-trace-frames",
+    "--experimental-value-unavailable",
+    "--experimental-wasm-assume-ref-cast-succeeds",
+    "--experimental-wasm-branch-hinting",
+    "--experimental-wasm-compilation-hints",
+    "--experimental-wasm-exnref",
+    "--experimental-wasm-gc",
+    "--experimental-wasm-imported-strings",
+    "--experimental-wasm-inlining",
+    "--experimental-wasm-instruction-tracing",
+    "--experimental-wasm-js-inlining",
+    "--experimental-wasm-memory64",
+    "--experimental-wasm-multi-memory",
+    "--experimental-wasm-pgo-from-file",
+    "--experimental-wasm-pgo-to-file",
+    "--experimental-wasm-ref-cast-nop",
+    "--experimental-wasm-skip-bounds-checks",
+    "--experimental-wasm-skip-null-checks",
+    "--experimental-wasm-stack-switching",
+    "--experimental-wasm-stringref",
+    "--experimental-wasm-type-reflection",
+    "--experimental-wasm-typed-funcref",
+    "--expose-async-hooks",
+    "--expose-cputracemark-as",
+    "--expose-externalize-string",
+    "--expose-gc",
+    "--expose-gc-as",
+    "--expose-ignition-statistics",
+    "--expose-inspector-scripts",
+    "--expose-statistics",
+    "--expose-trigger-failure",
+    "--expose-wasm",
+    "--external-reference-stats",
+    "--fast-map-update",
+    "--fast-properties-soft-limit",
+    "--feedback-normalization",
+    "--fixed-array-bounds-checks",
+    "--flush-baseline-code",
+    "--flush-bytecode",
+    "--flush-code-based-on-tab-visibility",
+    "--flush-code-based-on-time",
+    "--force-emit-interrupt-budget-checks",
+    "--force-long-branches",
+    "--force-marking-deque-overflows",
+    "--force-slow-path",
+    "--freeze-flags-after-init",
+    "--future",
+    "--fuzzer-gc-analysis",
+    "--fuzzer-random-seed",
+    "--fuzzing",
+    "--gc-experiment-less-compaction",
+    "--gc-fake-mmap",
+    "--gc-global",
+    "--gc-interval",
+    "--gc-memory-reducer-start-delay-ms",
+    "--gc-stats",
+    "--gc-verbose",
+    "--gdbjit",
+    "--gdbjit-dump",
+    "--gdbjit-dump-filter",
+    "--gdbjit-full",
+    "--hard-abort",
+    "--harmony",
+    "--harmony-array-from-async",
+    "--harmony-array-grouping",
+    "--harmony-import-assertions",
+    "--harmony-import-attributes",
+    "--harmony-intl-best-fit-matcher",
+    "--harmony-intl-duration-format",
+    "--harmony-intl-locale-info-func",
+    "--harmony-iterator-helpers",
+    "--harmony-json-parse-with-source",
+    "--harmony-rab-gsab",
+    "--harmony-rab-gsab-transfer",
+    "--harmony-regexp-unicode-sets",
+    "--harmony-remove-intl-locale-info-getters",
+    "--harmony-set-methods",
+    "--harmony-shadow-realm",
+    "--harmony-shipping",
+    "--harmony-struct",
+    "--harmony-temporal",
+    "--harmony-weak-refs-with-cleanup-some",
+    "--hash-seed",
+    "--heap-growing-percent",
+    "--heap-profiler-show-hidden-objects",
+    "--heap-profiler-trace-objects",
+    "--heap-profiler-use-embedder-graph",
+    "--heap-snapshot-on-oom",
+    "--heap-snapshot-string-limit",
+    "--heap-snapshot-verify",
+    "--histogram-interval",
+    "--hole-fuzzing",
+    "--huge-max-old-generation-size",
+    "--icu-timezone-data",
+    "--ignition-elide-noneffectful-bytecodes",
+    "--ignition-elide-redundant-tdz-checks",
+    "--ignition-filter-expression-positions",
+    "--ignition-reo",
+    "--ignition-share-named-property-feedback",
+    "--incremental-marking",
+    "--incremental-marking-bailout-when-ahead-of-schedule",
+    "--incremental-marking-hard-trigger",
+    "--incremental-marking-soft-trigger",
+    "--incremental-marking-task",
+    "--incremental-marking-task-delay-ms",
+    "--initial-heap-size",
+    "--initial-old-space-size",
+    "--initial-shared-heap-size",
+    "--inline-new",
+    "--intel-jcc-erratum-mitigation",
+    "--internalize-on-the-fly",
+    "--interpreted-frames-native-stack",
+    "--invocation-count-for-early-optimization",
+    "--invocation-count-for-feedback-allocation",
+    "--invocation-count-for-maglev",
+    "--invocation-count-for-maglev-osr",
+    "--invocation-count-for-osr",
+    "--invocation-count-for-turbofan",
+    "--jit-fuzzing",
+    "--jitless",
+    "--js-explicit-resource-management",
+    "--js-promise-withresolvers",
+    "--js-regexp-modifiers",
+    "--js-shipping",
+    "--js-staging",
+    "--lazy",
+    "--lazy-compile-dispatcher",
+    "--lazy-compile-dispatcher-max-threads",
+    "--lazy-eval",
+    "--lazy-feedback-allocation",
+    "--lazy-new-space-shrinking",
+    "--lazy-streaming",
+    "--liftoff",
+    "--liftoff-only",
+    "--lite-mode",
+    "--ll-prof",
+    "--local-off-stack-check",
+    "--log",
+    "--log-all",
+    "--log-code",
+    "--log-code-disassemble",
+    "--log-colour",
+    "--log-deopt",
+    "--log-feedback-vector",
+    "--log-function-events",
+    "--log-ic",
+    "--log-internal-timer-events",
+    "--log-maps",
+    "--log-maps-details",
+    "--log-or-trace-osr",
+    "--log-source-code",
+    "--log-source-position",
+    "--log-timer-events",
+    "--logfile",
+    "--logfile-per-isolate",
+    "--maglev",
+    "--maglev-assert",
+    "--maglev-assert-stack-size",
+    "--maglev-break-on-entry",
+    "--maglev-build-code-on-background",
+    "--maglev-cse",
+    "--maglev-deopt-data-on-background",
+    "--maglev-destroy-on-background",
+    "--maglev-filter",
+    "--maglev-function-context-specialization",
+    "--maglev-future",
+    "--maglev-hoist-osr-value-phi-untagging",
+    "--maglev-inline-api-calls",
+    "--maglev-inlining",
+    "--maglev-loop-peeling",
+    "--maglev-loop-peeling-max-size",
+    "--maglev-loop-peeling-only-trivial",
+    "--maglev-osr",
+    "--maglev-overwrite-budget",
+    "--maglev-overwrite-osr-budget",
+    "--maglev-print-feedback",
+    "--maglev-reuse-stack-slots",
+    "--maglev-speculative-hoist-phi-untagging",
+    "--maglev-stats",
+    "--maglev-stats-nvp",
+    "--maglev-untagged-phis",
+    "--manual-evacuation-candidates-selection",
+    "--map-counters",
+    "--max-fast-properties",
+    "--max-heap-size",
+    "--max-inlined-bytecode-size",
+    "--max-inlined-bytecode-size-absolute",
+    "--max-inlined-bytecode-size-cumulative",
+    "--max-inlined-bytecode-size-small",
+    "--max-lazy",
+    "--max-maglev-hard-inline-depth",
+    "--max-maglev-inline-depth",
+    "--max-maglev-inlined-bytecode-size-cumulative",
+    "--max-maglev-inlined-bytecode-size-small",
+    "--max-maglev-inlined-bytecode-size",
+    "--max-old-space-size",
+    "--max-opt",
+    "--max-optimized-bytecode-size",
+    "--max-semi-space-size",
+    "--max-serializer-nesting",
+    "--max-shared-heap-size",
+    "--max-stack-trace-source-length",
+    "--max-valid-polymorphic-map-count",
+    "--max-wasm-functions",
+    "--mcpu",
+    "--mega-dom-ic",
+    "--memory-balancer",
+    "--memory-balancer-c-value",
+    "--memory-protection-keys",
+    "--memory-reducer",
+    "--memory-reducer-for-small-heaps",
+    "--memory-reducer-gc-count",
+    "--memory-reducer-single-gc",
+    "--merge-background-deserialized-script-with-compilation-cache",
+    "--min-inlining-frequency",
+    "--min-maglev-inlining-frequency",
+    "--min-semi-space-size",
+    "--minimum-invocations-after-ic-update",
+    "--minimum-invocations-before-optimization",
+    "--minor-gc-task",
+    "--minor-gc-task-trigger",
+    "--minor-ms",
+    "--minor-ms-concurrent-marking-trigger",
+    "--minor-ms-max-new-space-capacity-mb",
+    "--minor-ms-max-page-age",
+    "--minor-ms-min-lab-size-kb",
+    "--minor-ms-min-new-space-capacity-for-concurrent-marking-mb",
+    "--minor-ms-page-promotion-max-lab-threshold",
+    "--minor-ms-page-promotion-threshold",
+    "--minor-ms-shortcut-strings",
+    "--minor-ms-trace-fragmentation",
+    "--mock-arraybuffer-allocator",
+    "--mock-arraybuffer-allocator-limit",
+    "--move-object-start",
+    "--native-code-counters",
+    "--omit-default-ctors",
+    "--opt",
+    "--optimize-for-size",
+    "--optimize-gc-for-battery",
+    "--optimize-on-next-call-optimizes-to-maglev",
+    "--osr-from-maglev",
+    "--osr-to-tierup",
+    "--page-promotion",
+    "--page-promotion-threshold",
+    "--parallel-compaction",
+    "--parallel-compile-tasks-for-eager-toplevel",
+    "--parallel-compile-tasks-for-lazy",
+    "--parallel-marking",
+    "--parallel-pointer-update",
+    "--parallel-scavenge",
+    "--parallel-weak-ref-clearing",
+    "--parse-only",
+    "--partial-constant-pool",
+    "--perf-basic-prof",
+    "--perf-basic-prof-only-functions",
+    "--perf-basic-prof-path",
+    "--perf-prof",
+    "--perf-prof-annotate-wasm",
+    "--perf-prof-delete-file",
+    "--perf-prof-path",
+    "--perf-prof-unwinding-info",
+    "--polymorphic-inlining",
+    "--predictable",
+    "--predictable-gc-schedule",
+    "--prepare-always-turbofan",
+    "--print-all-code",
+    "--print-all-exceptions",
+    "--print-ast",
+    "--print-break-location",
+    "--print-builtin-code",
+    "--print-builtin-code-filter",
+    "--print-builtin-size",
+    "--print-bytecode",
+    "--print-bytecode-filter",
+    "--print-code",
+    "--print-code-verbose",
+    "--print-deopt-stress",
+    "--print-flag-values",
+    "--print-global-handles",
+    "--print-handles",
+    "--print-maglev-code",
+    "--print-maglev-deopt-verbose",
+    "--print-maglev-graph",
+    "--print-maglev-graphs",
+    "--print-opt-code",
+    "--print-opt-code-filter",
+    "--print-opt-source",
+    "--print-regexp-bytecode",
+    "--print-regexp-code",
+    "--print-scopes",
+    "--print-wasm-code",
+    "--print-wasm-code-function-index",
+    "--print-wasm-stub-code",
+    "--prof",
+    "--prof-browser-mode",
+    "--prof-cpp",
+    "--prof-sampling-interval",
+    "--profile-deserialization",
+    "--profile-guided-optimization",
+    "--profile-guided-optimization-for-empty-feedback-vector",
+    "--profile-heap-snapshot",
+    "--random-gc-interval",
+    "--random-seed",
+    "--randomize-all-allocations",
+    "--rcs",
+    "--rcs-cpu-time",
+    "--reclaim-unmodified-wrappers",
+    "--redirect-code-traces",
+    "--redirect-code-traces-to",
+    "--regexp-backtracks-before-fallback",
+    "--regexp-interpret-all",
+    "--regexp-optimization",
+    "--regexp-peephole-optimization",
+    "--regexp-possessive-quantifier",
+    "--regexp-tier-up",
+    "--regexp-tier-up-ticks",
+    "--rehash-snapshot",
+    "--reorder-builtins",
+    "--reserve-inline-budget-scale-factor",
+    "--retain-maps-for-n-gc",
+    "--runtime-call-stats",
+    "--sampling-heap-profiler-suppress-randomness",
+    "--scavenge-separate-stack-scanning",
+    "--scavenger-max-new-space-capacity-mb",
+    "--script-streaming",
+    "--semi-space-growth-factor",
+    "--separate-gc-phases",
+    "--serialization-statistics",
+    "--shared-string-table",
+    "--short-builtin-calls",
+    "--shortcut-strings-with-stack",
+    "--sim-abort-on-bad-auth",
+    "--sim-arm64-optional-features",
+    "--single-generation",
+    "--single-threaded",
+    "--single-threaded-gc",
+    "--single-threaded-gc-in-background",
+    "--slow-histograms",
+    "--soft-abort",
+    "--sparkplug",
+    "--sparkplug-filter",
+    "--sparkplug-needs-short-builtins",
+    "--stack-size",
+    "--stack-trace-limit",
+    "--stack-trace-on-illegal",
+    "--startup-blob",
+    "--startup-src",
+    "--stress-background-compile",
+    "--stress-compaction",
+    "--stress-compaction-random",
+    "--stress-concurrent-allocation",
+    "--stress-concurrent-inlining",
+    "--stress-concurrent-inlining-attach-code",
+    "--stress-flush-code",
+    "--stress-gc-during-compilation",
+    "--stress-incremental-marking",
+    "--stress-inline",
+    "--stress-lazy-compilation",
+    "--stress-lazy-source-positions",
+    "--stress-maglev",
+    "--stress-marking",
+    "--stress-per-context-marking-worklist",
+    "--stress-runs",
+    "--stress-sampling-allocation-profiler",
+    "--stress-scavenge",
+    "--stress-snapshot",
+    "--stress-turbo-late-spilling",
+    "--stress-validate-asm",
+    "--stress-wasm-code-gc",
+    "--strict-termination-checks",
+    "--string-slices",
+    "--super-ic",
+    "--suppress-asm-messages",
+    "--switch-table-min-cases",
+    "--switch-table-spread-threshold",
+    "--target-arch",
+    "--target-is-simulator",
+    "--target-os",
+    "--test-small-max-function-context-stub-size",
+    "--testing-bool-flag",
+    "--testing-d8-test-runner",
+    "--testing-float-flag",
+    "--testing-int-flag",
+    "--testing-maybe-bool-flag",
+    "--testing-prng-seed",
+    "--testing-string-flag",
+    "--text-is-readable",
+    "--trace",
+    "--trace-all-uses",
+    "--trace-allocation-stack-interval",
+    "--trace-asm-parser",
+    "--trace-asm-scanner",
+    "--trace-asm-time",
+    "--trace-backing-store",
+    "--trace-baseline",
+    "--trace-baseline-batch-compilation",
+    "--trace-block-coverage",
+    "--trace-code-range-allocation",
+    "--trace-compilation-dependencies",
+    "--trace-compiler-dispatcher",
+    "--trace-concurrent-marking",
+    "--trace-concurrent-recompilation",
+    "--trace-contexts",
+    "--trace-creation-allocation-sites",
+    "--trace-deopt",
+    "--trace-deopt-verbose",
+    "--trace-detached-contexts",
+    "--trace-duplicate-threshold-kb",
+    "--trace-elements-transitions",
+    "--trace-environment-liveness",
+    "--trace-evacuation",
+    "--trace-evacuation-candidates",
+    "--trace-experimental-regexp-engine",
+    "--trace-file-names",
+    "--trace-flush-code",
+    "--trace-for-in-enumerate",
+    "--trace-fragmentation",
+    "--trace-fragmentation-verbose",
+    "--trace-gc",
+    "--trace-gc-freelists",
+    "--trace-gc-freelists-verbose",
+    "--trace-gc-heap-layout",
+    "--trace-gc-heap-layout-ignore-minor-gc",
+    "--trace-gc-ignore-scavenger",
+    "--trace-gc-nvp",
+    "--trace-gc-object-stats",
+    "--trace-gc-verbose",
+    "--trace-generalization",
+    "--trace-heap-broker",
+    "--trace-heap-broker-memory",
+    "--trace-heap-broker-verbose",
+    "--trace-idle-notification",
+    "--trace-idle-notification-verbose",
+    "--trace-ignition-codegen",
+    "--trace-ignition-dispatches-output-file",
+    "--trace-incremental-marking",
+    "--trace-isolates",
+    "--trace-lazy",
+    "--trace-liftoff",
+    "--trace-maglev-graph-building",
+    "--trace-maglev-inlining",
+    "--trace-maglev-inlining-verbose",
+    "--trace-maglev-phi-untagging",
+    "--trace-maglev-regalloc",
+    "--trace-memory-balancer",
+    "--trace-memory-reducer",
+    "--trace-migration",
+    "--trace-minor-ms-parallel-marking",
+    "--trace-module-status",
+    "--trace-mutator-utilization",
+    "--trace-normalization",
+    "--trace-opt",
+    "--trace-opt-stats",
+    "--trace-opt-verbose",
+    "--trace-osr",
+    "--trace-page-promotions",
+    "--trace-parallel-scavenge",
+    "--trace-pending-allocations",
+    "--trace-pretenuring",
+    "--trace-pretenuring-statistics",
+    "--trace-protector-invalidation",
+    "--trace-prototype-users",
+    "--trace-rail",
+    "--trace-read-only-promotion",
+    "--trace-read-only-promotion-verbose",
+    "--trace-regexp-assembler",
+    "--trace-regexp-bytecodes",
+    "--trace-regexp-graph",
+    "--trace-regexp-parser",
+    "--trace-regexp-peephole-optimization",
+    "--trace-regexp-tier-up",
+    "--trace-representation",
+    "--trace-serializer",
+    "--trace-side-effect-free-debug-evaluate",
+    "--trace-store-elimination",
+    "--trace-stress-marking",
+    "--trace-stress-scavenge",
+    "--trace-temporal",
+    "--trace-track-allocation-sites",
+    "--trace-turbo",
+    "--trace-turbo-alloc",
+    "--trace-turbo-ceq",
+    "--trace-turbo-cfg-file",
+    "--trace-turbo-escape",
+    "--trace-turbo-file-prefix",
+    "--trace-turbo-filter",
+    "--trace-turbo-graph",
+    "--trace-turbo-inlining",
+    "--trace-turbo-jt",
+    "--trace-turbo-load-elimination",
+    "--trace-turbo-loop",
+    "--trace-turbo-path",
+    "--trace-turbo-reduction",
+    "--trace-turbo-scheduled",
+    "--trace-turbo-scheduler",
+    "--trace-turbo-stack-accesses",
+    "--trace-turbo-trimming",
+    "--trace-turbo-types",
+    "--trace-unmapper",
+    "--trace-verify-csa",
+    "--trace-wasm",
+    "--trace-wasm-code-gc",
+    "--trace-wasm-compilation-times",
+    "--trace-wasm-compiler",
+    "--trace-wasm-decoder",
+    "--trace-wasm-inlining",
+    "--trace-wasm-instances",
+    "--trace-wasm-lazy-compilation",
+    "--trace-wasm-loop-peeling",
+    "--trace-wasm-memory",
+    "--trace-wasm-native-heap",
+    "--trace-wasm-offheap-memory",
+    "--trace-wasm-serialization",
+    "--trace-wasm-stack-switching",
+    "--trace-wasm-streaming",
+    "--trace-wasm-typer",
+    "--trace-zone-stats",
+    "--trace-zone-type-stats",
+    "--track-detached-contexts",
+    "--track-field-types",
+    "--track-gc-object-stats",
+    "--track-retaining-path",
+    "--transition-strings-during-gc-with-stack",
+    "--trap-on-abort",
+    "--turbo-allocation-folding",
+    "--turbo-cf-optimization",
+    "--turbo-collect-feedback-in-generic-lowering",
+    "--turbo-compress-frame-translations",
+    "--turbo-escape",
+    "--turbo-fast-api-calls",
+    "--turbo-filter",
+    "--turbo-inline-array-builtins",
+    "--turbo-inline-js-wasm-calls",
+    "--turbo-inlining",
+    "--turbo-instruction-scheduling",
+    "--turbo-jt",
+    "--turbo-load-elimination",
+    "--turbo-log-builtins-count-input",
+    "--turbo-loop-peeling",
+    "--turbo-loop-rotation",
+    "--turbo-loop-variable",
+    "--turbo-move-optimization",
+    "--turbo-optimize-apply",
+    "--turbo-optimize-math-minmax",
+    "--turbo-profiling",
+    "--turbo-profiling-input",
+    "--turbo-profiling-output",
+    "--turbo-profiling-verbose",
+    "--turbo-rab-gsab",
+    "--turbo-rewrite-far-jumps",
+    "--turbo-splitting",
+    "--turbo-stats",
+    "--turbo-stats-nvp",
+    "--turbo-stats-wasm",
+    "--turbo-store-elimination",
+    "--turbo-stress-instruction-scheduling",
+    "--turbo-string-builder",
+    "--turbo-typer-hardening",
+    "--turbo-verify",
+    "--turbo-verify-allocation",
+    "--turbo-verify-machine-graph",
+    "--turbo-wasm-address-reassociation",
+    "--turbofan",
+    "--turboshaft",
+    "--turboshaft-assert-types",
+    "--turboshaft-csa",
+    "--turboshaft-enable-debug-features",
+    "--turboshaft-from-maglev",
+    "--turboshaft-frontend",
+    "--turboshaft-future",
+    "--turboshaft-instruction-selection",
+    "--turboshaft-load-elimination",
+    "--turboshaft-loop-peeling",
+    "--turboshaft-loop-unrolling",
+    "--turboshaft-machine-lowering-opt",
+    "--turboshaft-opt-bisect-break",
+    "--turboshaft-opt-bisect-limit",
+    "--turboshaft-trace-emitted",
+    "--turboshaft-trace-reduction",
+    "--turboshaft-trace-typing",
+    "--turboshaft-typed-optimizations",
+    "--turboshaft-verify-reductions",
+    "--turboshaft-wasm",
+    "--turboshaft-wasm-instruction-selection-experimental",
+    "--turboshaft-wasm-instruction-selection-staged",
+    "--turboshaft-wasm-load-elimination",
+    "--unbox-double-arrays",
+    "--use-external-strings",
+    "--use-ic",
+    "--use-idle-notification",
+    "--use-libm-trig-functions",
+    "--use-marking-progress-bar",
+    "--use-osr",
+    "--use-strict",
+    "--v8-os-page-size",
+    "--validate-asm",
+    "--verify-csa",
+    "--verify-heap",
+    "--verify-heap-skip-remembered-set",
+    "--verify-predictable",
+    "--verify-simplified-lowering",
+    "--verify-snapshot-checksum",
+    "--vtune-prof-annotate-wasm",
+    "--warn-about-builtin-profile-data",
+    "--wasm-async-compilation",
+    "--wasm-bounds-checks",
+    "--wasm-caching-hard-threshold",
+    "--wasm-caching-threshold",
+    "--wasm-caching-timeout-ms",
+    "--wasm-code-gc",
+    "--wasm-debug-mask-for-testing",
+    "--wasm-disassembly-max-mb",
+    "--wasm-dynamic-tiering",
+    "--wasm-enforce-bounds-checks",
+    "--wasm-fuzzer-gen-test",
+    "--wasm-generic-wrapper",
+    "--wasm-inlining-budget",
+    "--wasm-inlining-factor",
+    "--wasm-inlining-max-size",
+    "--wasm-inlining-min-budget",
+    "--wasm-js-js-generic-wrapper",
+    "--wasm-lazy-compilation",
+    "--wasm-lazy-validation",
+    "--wasm-loop-peeling",
+    "--wasm-loop-peeling-max-size",
+    "--wasm-loop-unrolling",
+    "--wasm-math-intrinsics",
+    "--wasm-max-code-space-size-mb",
+    "--wasm-max-committed-code-mb",
+    "--wasm-max-initial-code-space-reservation",
+    "--wasm-max-mem-pages",
+    "--wasm-max-module-size",
+    "--wasm-max-table-size",
+    "--wasm-memory64-trap-handling",
+    "--wasm-native-module-cache-enabled",
+    "--wasm-num-compilation-tasks",
+    "--wasm-opt",
+    "--wasm-simd-ssse3-codegen",
+    "--wasm-stack-checks",
+    "--wasm-stack-switching-stack-size",
+    "--wasm-staging",
+    "--wasm-test-streaming",
+    "--wasm-tier-mask-for-testing",
+    "--wasm-tier-up",
+    "--wasm-tier-up-filter",
+    "--wasm-tiering-budget",
+    "--wasm-to-js-generic-wrapper",
+    "--wasm-trace-native",
+    "--wasm-turboshaft-mask-for-testing",
+    "--wasm-wrapper-tiering-budget",
+    "--win64-unwinding-info",
+    "--zone-stats-tolerance",
+})
diff --git a/crossbench/helper/__init__.py b/crossbench/helper/__init__.py
new file mode 100644
index 0000000..d8dfe43
--- /dev/null
+++ b/crossbench/helper/__init__.py
@@ -0,0 +1,439 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import datetime as dt
+import logging
+import os
+import shlex
+import sys
+import textwrap
+import threading
+import time
+import urllib
+import urllib.error
+import urllib.parse as urlparse
+import urllib.request
+from subprocess import Popen, TimeoutExpired
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, Iterable,
+                    Iterator, List, Optional, Tuple, Type, TypeVar, Union)
+
+from crossbench import plt
+
+if TYPE_CHECKING:
+  import signal
+
+  from crossbench.path import AnyPath, LocalPath
+
+  InputT = TypeVar("InputT")
+  KeyT = TypeVar("KeyT")
+  GroupT = TypeVar("GroupT")
+  PathT = TypeVar("PathT", bound=AnyPath)
+
+assert hasattr(shlex,
+               "join"), ("Please update to python v3.8 that has shlex.join")
+
+
+
+def group_by(collection: Iterable[InputT],
+             key: Callable[[InputT], KeyT],
+             value: Optional[Callable[[InputT], Any]] = None,
+             group: Optional[Callable[[KeyT], GroupT]] = None,
+             sort_key: Optional[Callable[[Tuple[KeyT, GroupT]], Any]] = str
+            ) -> Dict[KeyT, GroupT]:
+  """
+  Works similar to itertools.groupby but does a global, SQL-style grouping
+  instead of a line-by-line basis like uniq.
+
+  key:   a function that returns the grouping key for a group
+  group: a function that accepts a group_key and returns a group object that
+    has an append() method.
+  """
+  assert key, "No key function provided"
+  key_fn = key
+  value_fn = value or (lambda item: item)
+  group_fn: Callable[[KeyT], GroupT] = group or (lambda key: [])
+  groups: Dict[KeyT, GroupT] = {}
+  for input_item in collection:
+    group_key: KeyT = key_fn(input_item)
+    group_item = value_fn(input_item)
+    if group_key not in groups:
+      new_group: GroupT = group_fn(group_key)
+      groups[group_key] = new_group
+      new_group.append(group_item)
+    else:
+      groups[group_key].append(group_item)
+  if sort_key:
+    # sort keys as well for more predictable behavior
+    return dict(sorted(groups.items(), key=sort_key))
+  return dict(groups.items())
+
+
+def sort_by_file_size(files: Iterable[PathT],
+                      platform: plt.Platform = plt.PLATFORM) -> List[PathT]:
+  return sorted(files, key=lambda f: (platform.file_size(f), f.name))
+
+
+SIZE_UNITS: Final[Tuple[str, ...]] = ("B", "KiB", "MiB", "GiB", "TiB")
+
+
+def get_file_size(file: AnyPath,
+                  digits: int = 2,
+                  platform: plt.Platform = plt.PLATFORM) -> str:
+  size: float = float(platform.file_size(file))
+  unit_index = 0
+  divisor = 1024.0
+  while (unit_index < len(SIZE_UNITS)) and size >= divisor:
+    unit_index += 1
+    size /= divisor
+  return f"{size:.{digits}f} {SIZE_UNITS[unit_index]}"
+
+# =============================================================================
+
+
+def urlopen(url: str, timeout: Union[int, float] = 10):
+  try:
+    logging.debug("Opening url: %s", url)
+    return urllib.request.urlopen(url, timeout=timeout)
+  except (urllib.error.HTTPError, urllib.error.URLError) as e:
+    logging.info("Could not load url=%s", url)
+    raise e
+
+
+# =============================================================================
+
+
+class ChangeCWD:
+
+  def __init__(self, destination: LocalPath) -> None:
+    self.new_dir = destination
+    self.prev_dir: Optional[str] = None
+
+  def __enter__(self) -> None:
+    self.prev_dir = os.getcwd()
+    os.chdir(self.new_dir)
+    logging.debug("CWD=%s", self.new_dir)
+
+  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+    assert self.prev_dir, "ChangeCWD was not entered correctly."
+    os.chdir(self.prev_dir)
+
+
+class SystemSleepPreventer:
+  """
+  Prevent the system from going to sleep while running the benchmark.
+  """
+
+  def __init__(self) -> None:
+    self._process: Optional[Popen] = None
+
+  def __enter__(self) -> None:
+    if plt.PLATFORM.is_macos:
+      self._process = plt.PLATFORM.popen("caffeinate", "-imdsu")
+      atexit.register(self.stop_process)
+    # TODO: Add linux support
+
+  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+    self.stop_process()
+
+  def stop_process(self) -> None:
+    if self._process:
+      self._process.kill()
+      self._process = None
+
+
+class TimeScope:
+  """
+  Measures and logs the time spend during the lifetime of the TimeScope.
+  """
+
+  def __init__(self, message: str, level: int = 3) -> None:
+    self._message = message
+    self._level = level
+    self._start: Optional[dt.datetime] = None
+    self._duration: dt.timedelta = dt.timedelta()
+
+  @property
+  def message(self) -> str:
+    return self._message
+
+  @property
+  def duration(self) -> dt.timedelta:
+    return self._duration
+
+  def __enter__(self) -> TimeScope:
+    self._start = dt.datetime.now()
+    return self
+
+  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+    assert self._start
+    self._duration = dt.datetime.now() - self._start
+    logging.log(self._level, "%s duration=%s", self._message, self._duration)
+
+
+def as_timedelta(value: Union[int, float, dt.timedelta]) -> dt.timedelta:
+  if isinstance(value, dt.timedelta):
+    return value
+  return dt.timedelta(seconds=value)
+
+
+class WaitRange:
+  """
+  Create wait/sleep ranges with the given parameters:
+
+  If present we start with the initial delay, and then exponentially
+  increase the sleep/wait time by the given factor, until we reach the max
+  sleep time.
+
+  | delay | min | min * factor | ... | min * factor ** N | max | ... | max |
+  | ----------------------------- timeout ---------------------------------|
+
+  The timeout puts an upper bound to the total sleep time when using
+  wait_with_backoff().
+  """
+  min: dt.timedelta
+  max: dt.timedelta
+  initial_sleep: dt.timedelta
+  max_iterations: Optional[int]
+
+  def __init__(
+      self,
+      min: Union[int, float, dt.timedelta] = 0.1,  # pylint: disable=redefined-builtin
+      timeout: Union[int, float, dt.timedelta] = 10,
+      factor: float = 1.01,
+      max: Optional[Union[int, float, dt.timedelta]] = None,  # pylint: disable=redefined-builtin
+      max_iterations: Optional[int] = None,
+      delay: Union[int, float, dt.timedelta] = 0) -> None:
+    self.min = as_timedelta(min)
+    assert self.min.total_seconds() > 0
+    if not max:
+      self.max = self.min * 10
+    else:
+      self.max = as_timedelta(max)
+    assert self.min <= self.max
+    assert 1.0 < factor
+    self.factor = factor
+    self.timeout = as_timedelta(timeout)
+    assert 0 < self.timeout.total_seconds()
+    self.delay = as_timedelta(delay)
+    assert self.delay <= self.timeout
+    assert max_iterations is None or max_iterations > 0
+    self.max_iterations = max_iterations
+
+  def __iter__(self) -> Iterator[dt.timedelta]:
+    i = 0
+    if self.delay:
+      yield self.delay
+    current_sleep = self.min
+    while self.max_iterations is None or i < self.max_iterations:
+      yield current_sleep
+      current_sleep = min(current_sleep * self.factor, self.max)
+      i += 1
+
+  def wait_with_backoff(
+      self,
+      platform: plt.Platform = plt.PLATFORM) -> Iterator[Tuple[float, float]]:
+    start = dt.datetime.now()
+    timeout = self.timeout
+    for sleep_for in self:
+      duration = dt.datetime.now() - start
+      if duration > self.timeout:
+        raise TimeoutError(f"Waited for {duration}")
+      time_left = timeout - duration
+      yield duration.total_seconds(), time_left.total_seconds()
+      platform.sleep(sleep_for.total_seconds())
+
+
+def wait_with_backoff(
+    wait_range: Union[int, float, dt.timedelta, WaitRange],
+    platform: plt.Platform = plt.PLATFORM) -> Iterator[Tuple[float, float]]:
+  if not isinstance(wait_range, WaitRange):
+    wait_range = WaitRange(timeout=wait_range)
+  return wait_range.wait_with_backoff(platform)
+
+
+class DurationMeasureContext:
+
+  def __init__(self, durations: Durations, name: str) -> None:
+    self._start_time = dt.datetime.utcfromtimestamp(0)
+    self._durations = durations
+    self._name = name
+
+  def __enter__(self) -> DurationMeasureContext:
+    self._start_time = dt.datetime.now()
+    return self
+
+  def __exit__(self, exc_type, exc_value, traceback) -> None:
+    assert self._start_time
+    delta = dt.datetime.now() - self._start_time
+    self._durations[self._name] = delta
+
+
+class Durations:
+  """
+  Helper object to track durations.
+  """
+
+  def __init__(self) -> None:
+    self._durations: Dict[str, dt.timedelta] = {}
+
+  def __getitem__(self, name: str) -> dt.timedelta:
+    return self._durations[name]
+
+  def __setitem__(self, name: str, duration: dt.timedelta) -> None:
+    assert name not in self._durations, f"Cannot set '{name}' duration twice!"
+    self._durations[name] = duration
+
+  def __len__(self) -> int:
+    return len(self._durations)
+
+  def measure(self, name: str) -> DurationMeasureContext:
+    assert name not in self._durations, (
+        f"Cannot measure '{name}' duration twice!")
+    return DurationMeasureContext(self, name)
+
+  def to_json(self) -> Dict[str, float]:
+    return {
+        name: self._durations[name].total_seconds()
+        for name in sorted(self._durations.keys())
+    }
+
+
+def wrap_lines(body: str, width: int = 80, indent: str = "") -> Iterable[str]:
+  for line in body.splitlines():
+    if len(line) <= width:
+      yield f"{indent}{line}"
+      continue
+    for split in textwrap.wrap(line, width):
+      yield f"{indent}{split}"
+
+
+def type_name(t: Type) -> str:
+  module = t.__module__
+  if not module:
+    return t.__qualname__
+  return f"{module}.{t.__qualname__}"
+
+
+class Spinner:
+  CURSORS = ""
+
+  def __init__(self, sleep: float = 0.5) -> None:
+    self._is_running = False
+    self._sleep_time = sleep
+
+  def __enter__(self) -> None:
+    # Only enable the spinner if the output is an interactive terminal.
+    is_atty = hasattr(sys.stdout, "isatty") and sys.stdout.isatty()
+    if is_atty:
+      self._is_running = True
+      threading.Thread(target=self._spin).start()
+
+  def __exit__(self, exc_type, exc_value, traceback) -> None:
+    if self._is_running:
+      self._is_running = False
+      self._sleep()
+
+  def _cursors(self) -> Iterable[str]:
+    while True:
+      yield from Spinner.CURSORS
+
+  def _spin(self) -> None:
+    stdout = sys.stdout
+    for cursor in self._cursors():
+      if not self._is_running:
+        return
+      # Print the current wait-cursor and send a carriage return to move to the
+      # start of the line.
+      stdout.write(f" {cursor}\r")
+      stdout.flush()
+      self._sleep()
+
+  def _sleep(self) -> None:
+    time.sleep(self._sleep_time)
+
+
+
+def update_url_query(url: str, query_params: Dict[str, str]) -> str:
+  parsed_url = urlparse.urlparse(url)
+  query = dict(urlparse.parse_qsl(parsed_url.query))
+  query.update(query_params)
+  parsed_url = parsed_url._replace(query=urlparse.urlencode(query, doseq=True))
+  return parsed_url.geturl()
+
+
+def wait_and_kill(process: Popen,
+                  timeout=1,
+                  signal: Optional[signal.Signals] = None) -> None:
+  """Graceful process termination:
+  1. Send signal if provided,
+  2. wait for the given time,
+  3. terminate(),
+  4. Last stage: kill process.
+  """
+  logging.debug("wait_and_kill: %s", process)
+  try:
+    wait_and_terminate(process, timeout, signal)
+  finally:
+    try:
+      process.kill()
+    except ProcessLookupError:
+      pass
+
+
+def wait_and_terminate(process,
+                       timeout=1,
+                       signal: Optional[signal.Signals] = None) -> None:
+  if process.poll() is not None:
+    return
+  logging.debug("Terminating process: %s", process)
+  try:
+    if signal:
+      process.send_signal(signal)
+    process.wait(timeout)
+    return
+  except TimeoutExpired as e:
+    logging.debug("Got timeout while waiting "
+                  "for process shutdown (%s): %s", process, e)
+  except Exception as e:  # pylint: disable=broad-except
+    logging.debug("Ignoring exception during process termination: %s", e)
+  finally:
+    try:
+      process.terminate()
+    except ProcessLookupError:
+      pass
+
+
+class RepeatTimer(threading.Timer):
+
+  def run(self) -> None:
+    while not self.finished.wait(self.interval):
+      self.function(*self.args, **self.kwargs)
+
+  def __enter__(self, *args, **kwargs):
+    self.start()
+
+  def __exit__(self, *args, **kwargs):
+    self.cancel()
+
+
+def input_with_timeout(timeout=dt.timedelta(seconds=10), default=None):
+  result_container = [default]
+  wait = threading.Thread(
+      target=_input, args=[
+          result_container,
+      ])
+  wait.daemon = True
+  wait.start()
+  wait.join(timeout=timeout.total_seconds())
+  return result_container[0]
+
+
+def _input(results_container):
+  try:
+    results_container[0] = input()
+  except KeyboardInterrupt:
+    pass
diff --git a/crossbench/helper/path_finder.py b/crossbench/helper/path_finder.py
new file mode 100644
index 0000000..9e0f92b
--- /dev/null
+++ b/crossbench/helper/path_finder.py
@@ -0,0 +1,321 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import logging
+from typing import TYPE_CHECKING, Iterator, Optional, Tuple
+
+from crossbench import path as pth
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import Platform
+
+
+class BaseToolFinder(abc.ABC):
+
+  def __init__(
+      self, platform: Platform, candidates: Tuple[pth.AnyPath,
+                                                  ...] = tuple()) -> None:
+    self._platform = platform
+    self._candidates = candidates + self.default_candidates()
+    self._path: Optional[pth.AnyPath] = self._find_path()
+    if self._path:
+      assert self.is_valid_path(self._path)
+
+  @property
+  def platform(self) -> Platform:
+    return self._platform
+
+  @property
+  def path(self) -> Optional[pth.AnyPath]:
+    return self._path
+
+  @property
+  def candidates(self) -> Tuple[pth.AnyPath, ...]:
+    return self._candidates
+
+  def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
+    return tuple()
+
+  def _find_path(self) -> Optional[pth.AnyPath]:
+    # Try potential build location
+    for candidate_path in self._candidates:
+      if self.is_valid_path(candidate_path):
+        return candidate_path
+    return None
+
+  @abc.abstractmethod
+  def is_valid_path(self, candidate: pth.AnyPath) -> bool:
+    pass
+
+
+def default_chromium_candidates(platform: Platform) -> Tuple[pth.AnyPath, ...]:
+  """Returns a generous list of potential locations of a chromium checkout."""
+  candidates = []
+  if chromium_src := platform.environ.get("CHROMIUM_SRC"):
+    candidates.append(platform.path(chromium_src))
+  if platform.is_local:
+    candidates.append(chromium_src_relative_local_path())
+  if platform.is_android:
+    return tuple(candidates)
+  home_dir = platform.home()
+  candidates += [
+      # Guessing default locations
+      home_dir / "Documents/chromium/src",
+      home_dir / "chromium/src",
+      platform.path("C:/src/chromium/src"),
+      home_dir / "Documents/chrome/src",
+      home_dir / "chrome/src",
+      platform.path("C:/src/chrome/src"),
+  ]
+  return tuple(candidates)
+
+
+def chromium_src_relative_local_path():
+  """Gets the local relative path of `chromium/src`.
+
+  Assuming the cli.py path is `third_party/crossbench/crossbench/cli/cli.py`.
+  """
+  return pth.LocalPath(__file__).parents[4]
+
+
+def is_chromium_checkout_dir(platform: Platform, dir_path: pth.AnyPath) -> bool:
+  return (platform.is_dir(dir_path / "v8") and
+          platform.is_dir(dir_path / "chrome") and
+          platform.is_dir(dir_path / ".git"))
+
+
+class ChromiumCheckoutFinder(BaseToolFinder):
+  """Finds a chromium src checkout at either given locations or at
+  some preset known checkout locations."""
+
+  def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
+    return default_chromium_candidates(self.platform)
+
+  def is_valid_path(self, candidate: pth.AnyPath) -> bool:
+    return is_chromium_checkout_dir(self.platform, candidate)
+
+
+class ChromiumBuildBinaryFinder(BaseToolFinder):
+  """Finds a custom-built binary in either a given out/BUILD dir or
+  tries to find it in build dirs in common known chromium checkout locations."""
+
+  def __init__(
+      self,
+      platform: Platform,
+      binary_name: str,
+      candidates: Tuple[pth.AnyPath, ...] = tuple()) -> None:
+    self._binary_name = binary_name
+    super().__init__(platform, candidates)
+
+  @property
+  def binary_name(self) -> str:
+    return self._binary_name
+
+  def _iterate_candidate_bin_paths(self) -> Iterator[pth.AnyPath]:
+    for candidate_dir in self._candidates:
+      yield candidate_dir / self._binary_name
+
+    for candidate in default_chromium_candidates(self.platform):
+      candidate_out = candidate / "out"
+      if not self.platform.is_dir(candidate_out):
+        continue
+      # TODO: support remote glob
+      for build in ("Release", "release", "rel", "Optdebug", "optdebug", "opt"):
+        yield candidate_out / build / self._binary_name
+
+  def _find_path(self) -> Optional[pth.AnyPath]:
+    for candidate in self._iterate_candidate_bin_paths():
+      if self.is_valid_path(candidate):
+        return candidate
+    return None
+
+  def is_valid_path(self, candidate: pth.AnyPath) -> bool:
+    assert candidate.name == self._binary_name
+    if not self.platform.is_file(candidate):
+      return False
+    # .../chromium/src/out/Release/BINARY => .../chromium/src/
+    # Don't use parents[] access to stop at the root.
+    maybe_checkout_dir = candidate.parent.parent.parent
+    return is_chromium_checkout_dir(self._platform, maybe_checkout_dir)
+
+
+class V8CheckoutFinder(BaseToolFinder):
+
+  def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
+    if self.platform.is_android:
+      return ()
+    home_dir = self._platform.home()
+    return (
+        # V8 Checkouts
+        home_dir / "Documents/v8/v8",
+        home_dir / "v8/v8",
+        self._platform.path("C:/src/v8/v8"),
+        # Raw V8 checkouts
+        home_dir / "Documents/v8",
+        home_dir / "v8",
+        self._platform.path("C:/src/v8/"),
+    )
+
+  def _find_path(self) -> Optional[pth.AnyPath]:
+    if v8_checkout := super()._find_path():
+      return v8_checkout
+    if chromium_checkout := ChromiumCheckoutFinder(self._platform).path:
+      return chromium_checkout / "v8"
+    maybe_d8_path = self.platform.environ.get("D8_PATH")
+    if not maybe_d8_path:
+      return None
+    for candidate_dir in self.platform.path(maybe_d8_path).parents:
+      if self.is_valid_path(candidate_dir):
+        return candidate_dir
+    return None
+
+  def is_valid_path(self, candidate: pth.AnyPath) -> bool:
+    v8_header_file = candidate / "include/v8.h"
+    return (self.platform.is_file(v8_header_file) and
+            (self.platform.is_dir(candidate / ".git")))
+
+
+class V8ToolsFinder:
+  """Helper class to find d8 binaries and the tick-processor.
+  If no explicit d8 and checkout path are given, $D8_PATH and common v8 and
+  chromium installation directories are checked."""
+
+  def __init__(self,
+               platform: Platform,
+               d8_binary: Optional[pth.AnyPath] = None,
+               v8_checkout: Optional[pth.AnyPath] = None) -> None:
+    self.platform = platform
+    self.d8_binary: Optional[pth.AnyPath] = d8_binary
+    self.v8_checkout: Optional[pth.AnyPath] = None
+    if v8_checkout:
+      self.v8_checkout = v8_checkout
+    else:
+      self.v8_checkout = V8CheckoutFinder(self.platform).path
+    self.tick_processor: Optional[pth.AnyPath] = None
+    self.d8_binary = self._find_d8()
+    if self.d8_binary:
+      self.tick_processor = self._find_v8_tick_processor()
+    logging.debug("V8ToolsFinder found d8_binary='%s' tick_processor='%s'",
+                  self.d8_binary, self.tick_processor)
+
+  def _find_d8(self) -> Optional[pth.AnyPath]:
+    if self.d8_binary and self.platform.is_file(self.d8_binary):
+      return self.d8_binary
+    environ = self.platform.environ
+    if "D8_PATH" in environ:
+      candidate = self.platform.path(environ["D8_PATH"]) / "d8"
+      if self.platform.is_file(candidate):
+        return candidate
+      candidate = self.platform.path(environ["D8_PATH"])
+      if self.platform.is_file(candidate):
+        return candidate
+    # Try potential build location
+    for candidate_dir in V8CheckoutFinder(self.platform).candidates:
+      for build_type in ("release", "optdebug", "Default", "Release"):
+        candidates = list(
+            self.platform.glob(candidate_dir, f"out/*{build_type}/d8"))
+        if not candidates:
+          continue
+        d8_candidate = candidates[0]
+        if self.platform.is_file(d8_candidate):
+          return d8_candidate
+    return None
+
+  def _find_v8_tick_processor(self) -> Optional[pth.AnyPath]:
+    if self.platform.is_linux:
+      tick_processor = "tools/linux-tick-processor"
+    elif self.platform.is_macos:
+      tick_processor = "tools/mac-tick-processor"
+    elif self.platform.is_win:
+      tick_processor = "tools/windows-tick-processor.bat"
+    else:
+      logging.debug(
+          "Not looking for the v8 tick-processor on unsupported platform: %s",
+          self.platform)
+      return None
+    if self.v8_checkout and self.platform.is_dir(self.v8_checkout):
+      candidate = self.v8_checkout / tick_processor
+      assert self.platform.is_file(candidate), (
+          f"Provided v8_checkout has no '{tick_processor}' at {candidate}")
+    assert self.d8_binary
+    # Try inferring the V8 checkout from a built d8:
+    # .../foo/v8/v8/out/x64.release/d8
+    candidate = self.d8_binary.parents[2] / tick_processor
+    if self.platform.is_file(candidate):
+      return candidate
+    if self.v8_checkout:
+      candidate = self.v8_checkout / tick_processor
+      if self.platform.is_file(candidate):
+        return candidate
+    return None
+
+
+class BaseChromiumBinaryToolFinder(BaseToolFinder):
+
+  def is_valid_path(self, candidate: pth.AnyPath) -> bool:
+    return self._platform.is_file(candidate)
+
+  @classmethod
+  def chrome_path(cls) -> pth.AnyPath:
+    raise NotImplementedError()
+
+  def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
+    relative_path = chromium_src_relative_local_path() / self.chrome_path()
+    if maybe_chrome := ChromiumCheckoutFinder(self._platform).path:
+      return (relative_path, maybe_chrome / self.chrome_path(),)
+    return (relative_path,)
+
+
+class TraceconvFinder(BaseChromiumBinaryToolFinder):
+
+  @classmethod
+  def chrome_path(cls) -> pth.AnyPath:
+    return pth.AnyPath("third_party/perfetto/tools/traceconv")
+
+
+class TraceProcessorFinder(BaseChromiumBinaryToolFinder):
+
+  @classmethod
+  def chrome_path(cls) -> pth.AnyPath:
+    return pth.AnyPath("third_party/perfetto/tools/trace_processor")
+
+
+CROSSBENCH_DIR = pth.LocalPath(__file__).parents[2]
+
+
+class BaseCrossbenchBinaryToolFinder(BaseChromiumBinaryToolFinder):
+
+  def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
+    candidates = super().default_candidates()
+    return (CROSSBENCH_DIR / self.crossbench_path(),) + candidates
+
+  @classmethod
+  @abc.abstractmethod
+  def crossbench_path(cls) -> pth.AnyPath:
+    pass
+
+
+class WprGoToolFinder(BaseCrossbenchBinaryToolFinder):
+
+  @classmethod
+  def chrome_path(cls) -> pth.AnyPath:
+    return pth.AnyPath("third_party/catapult/web_page_replay_go/src/wpr.go")
+
+  @classmethod
+  def crossbench_path(cls) -> pth.AnyPath:
+    return pth.AnyPath("third_party/webpagereplay/src/wpr.go")
+
+
+class TsProxyFinder(BaseCrossbenchBinaryToolFinder):
+
+  @classmethod
+  def chrome_path(cls) -> pth.AnyPath:
+    return pth.AnyPath("third_party/catapult/third_party/tsproxy/tsproxy.py")
+
+  @classmethod
+  def crossbench_path(cls) -> pth.AnyPath:
+    return pth.AnyPath("third_party/tsproxy/tsproxy.py")
diff --git a/crossbench/helper/state.py b/crossbench/helper/state.py
new file mode 100644
index 0000000..eb962e1
--- /dev/null
+++ b/crossbench/helper/state.py
@@ -0,0 +1,86 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+from typing import Any, Generic, Iterable, Tuple, TypeVar
+
+
+class UnexpectedStateError(RuntimeError):
+
+  def __init__(self, state: BaseState, expected: Iterable[BaseState]) -> None:
+    self._state = state
+    self._expected = tuple(expected)
+    names = ", ".join(tuple(s.name for s in expected))
+    super().__init__(f"Unexpected state got={state.name} expected=({names})")
+
+  @property
+  def state(self) -> BaseState:
+    return self._state
+
+  @property
+  def expected(self) -> Tuple[BaseState, ...]:
+    return self._expected
+
+
+class BaseState(enum.IntEnum):
+  """Base class for StateMachine states."""
+
+
+@enum.unique
+class State(BaseState):
+  """Default state implementation."""
+  INITIAL = enum.auto()
+  SETUP = enum.auto()
+  READY = enum.auto()
+  RUN = enum.auto()
+  DONE = enum.auto()
+
+
+StateT = TypeVar("StateT", bound="BaseState")
+
+
+class StateMachine(Generic[StateT]):
+
+  def __init__(self, default: StateT) -> None:
+    self._state: StateT = default
+
+  @property
+  def state(self) -> StateT:
+    return self._state
+
+  @property
+  def name(self) -> str:
+    return self._state.name
+
+  def __eq__(self, other: Any) -> bool:
+    if self is other:
+      return True
+    if isinstance(other, StateMachine):
+      return self._state is other._state
+    if isinstance(other, type(self._state)):
+      return self._state is other
+    return False
+
+  def transition(self, *args: StateT, to: StateT) -> None:
+    self.expect(*args)
+    self._state = to
+
+  def expect(self, *args: StateT) -> None:
+    if self._state not in args:
+      raise UnexpectedStateError(self._state, args)
+
+  def expect_before(self, state: StateT) -> None:
+    if self._state >= state:
+      valid_states = (s for s in type(self._state) if s < state)
+      raise UnexpectedStateError(self._state, valid_states)
+
+  def expect_at_least(self, state: StateT) -> None:
+    if self._state < state:
+      valid_states = (s for s in type(self._state) if s >= state)
+      raise UnexpectedStateError(self._state, valid_states)
+
+  def __str__(self) -> str:
+    return f"{self._state}"
diff --git a/crossbench/network/__init__.py b/crossbench/network/__init__.py
new file mode 100644
index 0000000..67eefa2
--- /dev/null
+++ b/crossbench/network/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/network/base.py b/crossbench/network/base.py
new file mode 100644
index 0000000..73aab25
--- /dev/null
+++ b/crossbench/network/base.py
@@ -0,0 +1,90 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+from typing import TYPE_CHECKING, Iterator, Optional
+
+from crossbench import plt
+from crossbench.network.traffic_shaping.live import NoTrafficShaper
+
+if TYPE_CHECKING:
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.flags.base import Flags
+  from crossbench.network.traffic_shaping.base import TrafficShaper
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class Network(abc.ABC):
+
+  def __init__(self,
+               traffic_shaper: Optional[TrafficShaper] = None,
+               browser_platform: plt.Platform = plt.PLATFORM) -> None:
+    self._traffic_shaper = traffic_shaper or NoTrafficShaper(browser_platform)
+    self._browser_platform = browser_platform
+    self._host_platform = browser_platform.host_platform
+    self._is_running: bool = False
+
+  @property
+  def traffic_shaper(self) -> TrafficShaper:
+    return self._traffic_shaper
+
+  @property
+  def browser_platform(self) -> plt.Platform:
+    return self._browser_platform
+
+  @property
+  def host_platform(self) -> plt.Platform:
+    return self._host_platform
+
+  @property
+  def is_running(self) -> bool:
+    return self._is_running
+
+  @property
+  def is_live(self) -> bool:
+    """Return True if the network is the default live/direct connection, as
+    opposed to a replay network or local file server."""
+    return False
+
+  @property
+  def is_wpr(self) -> bool:
+    """Return True if the network is the replay network."""
+    return False
+
+  @property
+  def is_local_file_server(self) -> bool:
+    """Return True if the network is the local file server network."""
+    return False
+
+  @property
+  def http_port(self) -> Optional[int]:
+    """HTTP port for non-live server-based networks."""
+    return None
+
+  @property
+  def https_port(self) -> Optional[int]:
+    """HTTPS port for non-live server-based networks."""
+    return None
+
+  @property
+  def host(self) -> Optional[str]:
+    """Host for non-live server-based networks."""
+    return None
+
+  def extra_flags(self, browser_attributes: BrowserAttributes) -> Flags:
+    assert self.is_running, "Network is not running."
+    return self.traffic_shaper.extra_flags(browser_attributes)
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+    del session
+    assert not self._is_running, "Cannot start network more than once."
+    self._is_running = True
+    try:
+      yield self
+    finally:
+      self._is_running = False
diff --git a/crossbench/network/live.py b/crossbench/network/live.py
new file mode 100644
index 0000000..3c5eeb7
--- /dev/null
+++ b/crossbench/network/live.py
@@ -0,0 +1,31 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+from typing import TYPE_CHECKING, Iterator
+
+from crossbench.network.base import Network
+
+if TYPE_CHECKING:
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+
+class LiveNetwork(Network):
+
+  @property
+  def is_live(self) -> bool:
+    return True
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+    with super().open(session):
+      with self._traffic_shaper.open(self, session):
+        # TODO: implement
+        yield self
+
+  def __str__(self) -> str:
+    return f"LIVE(speed={self.traffic_shaper})"
diff --git a/crossbench/network/local_file_server.py b/crossbench/network/local_file_server.py
new file mode 100644
index 0000000..f40cdda
--- /dev/null
+++ b/crossbench/network/local_file_server.py
@@ -0,0 +1,200 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+import email.parser
+import http.server
+import json
+import logging
+import os
+import threading
+from typing import (TYPE_CHECKING, Final, Iterator, Mapping, Optional, Tuple,
+                    Type)
+
+from immutabledict import immutabledict
+
+from crossbench import plt
+from crossbench.network.base import Network
+from crossbench.parse import ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.network.traffic_shaping.base import TrafficShaper
+  from crossbench.path import LocalPath
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+DEFAULT_HOST = "localhost"
+DEFAULT_PORT = 8000
+# List of known headers that are served by the default HTTPServer and might
+# be accidentally overridden by provided extra headers.
+CONFLICTING_EXTRA_HEADERS: Final[frozenset[str]] = frozenset(
+    map(lambda header: header.lower(),
+        ("Content-Type", "Content-Length", "Last-Modified", "Server", "Date",
+         "Connection", "Location")))
+
+
+class CustomHeadersRequestHandler(http.server.SimpleHTTPRequestHandler):
+
+  @classmethod
+  def bind(
+      cls: Type[CustomHeadersRequestHandler],
+      server_dir: LocalPath,
+      extra_headers: Mapping[str, str],
+  ) -> Type[http.server.SimpleHTTPRequestHandler]:
+    # Use a temporary class to bind arguments.
+    class BoundDirectoryRequestHandler(cls):
+
+      def __init__(self, *args, **kwargs):
+        super().__init__(
+            *args,
+            directory=os.fspath(server_dir),
+            extra_headers=extra_headers,
+            **kwargs)
+
+    return BoundDirectoryRequestHandler
+
+  def __init__(self,
+               *args,
+               directory: Optional[str] = None,
+               extra_headers: Optional[Mapping[str, str]] = None,
+               **kwargs):
+    self._extra_headers: immutabledict[str, str] = (
+        immutabledict(extra_headers) if extra_headers else immutabledict())
+    super().__init__(*args, directory=directory, **kwargs)
+
+  def end_headers(self):
+    if self._extra_headers:
+      self._send_custom_headers()
+    super().end_headers()
+
+  def _send_custom_headers(self):
+    for key, value in self._extra_headers.items():
+      self.send_header(key, value)
+
+
+class LocalFileNetwork(Network):
+
+  def __init__(self,
+               path: LocalPath,
+               url: Optional[str],
+               traffic_shaper: Optional[TrafficShaper] = None,
+               browser_platform: plt.Platform = plt.PLATFORM):
+    super().__init__(traffic_shaper, browser_platform)
+    self._path = path
+    self._host, self._port = self._parse_url(url)
+    # TODO: support custom headers via command line
+    self._extra_headers: immutabledict[str, str] = self._try_parse_headers()
+    if self._extra_headers:
+      self._validate_extra_headers()
+
+  @property
+  def is_local_file_server(self) -> bool:
+    return True
+
+  @property
+  def path(self) -> LocalPath:
+    return self._path
+
+  def _parse_url(self, url: Optional[str]) -> Tuple[str, int]:
+    host: str = DEFAULT_HOST
+    port: int = DEFAULT_PORT
+    if not url:
+      return host, port
+    parsed_url = ObjectParser.url(url)
+    if parsed_url.hostname:
+      host = parsed_url.hostname
+    if parsed_url.port is not None:
+      port = parsed_url.port
+    return host, port
+
+  def _try_parse_headers(self) -> immutabledict[str, str]:
+    for name in ("HEADERS", "HEADERS.txt"):
+      header_file = self._path / name
+      if header_file.exists():
+        return self._read_headers_file(header_file)
+    return immutabledict()
+
+  def _read_headers_file(self,
+                         header_file: LocalPath) -> immutabledict[str, str]:
+    with header_file.open("rb") as f:
+      # Reuse python's email message library to parse headers
+      message = email.parser.BytesParser().parsebytes(f.read())
+      return immutabledict(message)
+
+  def _validate_extra_headers(self):
+    for key, value in self._extra_headers.items():
+      if key.lower() in CONFLICTING_EXTRA_HEADERS:
+        logging.error(
+            "BROWSER Network: Extra header overrides server defaults: '%s: %s'",
+            key, value)
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+    with super().open(session):
+      with self._open_local_file_server():
+        # TODO: properly hook up traffic shaper for the local http server
+        with self._traffic_shaper.open(self, session):
+          with self._forward_ports(session):
+            yield self
+
+  @contextlib.contextmanager
+  def _open_local_file_server(self):
+    # TODO: write request log file to session results folder.
+    # TODO: support  https server using SSLContext.wrap_socket(httpd.socket)
+    request_handler_cls = CustomHeadersRequestHandler.bind(
+        self._path, self._extra_headers)
+    server = http.server.ThreadingHTTPServer((self._host, self._port),
+                                             request_handler_cls)
+    with self._server_thread(server):
+      logging.info("%s custom host=%s, port=%s",
+                   type(self).__name__, self.host, self.http_port)
+      yield
+
+  @contextlib.contextmanager
+  def _server_thread(self, server: http.server.HTTPServer) -> Iterator[None]:
+    with server:
+      server_thread = threading.Thread(target=server.serve_forever)
+      server_thread.daemon = True
+      server_thread.start()
+      self._port = server.server_port
+      try:
+        yield
+      finally:
+        server.shutdown()
+        server_thread.join()
+
+  @contextlib.contextmanager
+  def _forward_ports(self, session: BrowserSessionRunGroup) -> Iterator:
+    browser_platform = session.browser_platform
+    if browser_platform.is_remote:
+      logging.info("REMOTE PORT FORWARDING: %s <= %s", self.host_platform,
+                   browser_platform)
+      # TODO: create port-forwarder service that is shut down properly.
+      # TODO: make ports configurable
+      browser_platform.reverse_port_forward(self._port, self._port)
+    yield
+    if browser_platform.is_remote:
+      browser_platform.stop_reverse_port_forward(self._port)
+
+  @property
+  def http_port(self) -> Optional[int]:
+    return self._port
+
+  @property
+  def https_port(self) -> Optional[int]:
+    # TODO: support https locally
+    return None
+
+  @property
+  def host(self) -> Optional[str]:
+    return self._host
+
+  def __str__(self) -> str:
+    extra_headers_str = ""
+    if self._extra_headers:
+      formatted_headers = json.dumps(dict(self._extra_headers))
+      extra_headers_str = f" extra_headers={formatted_headers}"
+    return ("LOCAL(path={self._path}, "
+            f"speed={self.traffic_shaper}{extra_headers_str})")
diff --git a/crossbench/network/replay/__init__.py b/crossbench/network/replay/__init__.py
new file mode 100644
index 0000000..e9d2bfa
--- /dev/null
+++ b/crossbench/network/replay/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/network/replay/base.py b/crossbench/network/replay/base.py
new file mode 100644
index 0000000..eff23f4
--- /dev/null
+++ b/crossbench/network/replay/base.py
@@ -0,0 +1,85 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+import logging
+import re
+from typing import TYPE_CHECKING, Iterator, Optional, Union
+from urllib.parse import urlparse
+
+from crossbench import exception
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.helper import Spinner
+from crossbench.network.base import Network
+from crossbench.parse import PathParser
+
+if TYPE_CHECKING:
+  from crossbench.network.traffic_shaping.base import TrafficShaper
+  from crossbench.path import LocalPath
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+GS_PREFIX = "gs://"
+GSUTIL_LS_MD5_RE = re.compile(r"Hash \(md5\):\s*([A-Za-z0-9+/]+)=*")
+
+
+class ReplayNetwork(Network):
+  """ A network implementation that can be used to replay requests
+  from a an archive."""
+
+  def __init__(self,
+               archive: Union[pth.LocalPath, str],
+               traffic_shaper: Optional[TrafficShaper] = None,
+               browser_platform: plt.Platform = plt.PLATFORM):
+    super().__init__(traffic_shaper, browser_platform)
+    self._archive_path = self._ensure_archive(archive)
+
+  @property
+  def is_wpr(self) -> bool:
+    return True
+
+  @property
+  def archive_path(self) -> LocalPath:
+    return self._archive_path
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+    with super().open(session):
+      with self._open_replay_server(session):
+        with self._traffic_shaper.open(self, session):
+          yield self
+
+  @contextlib.contextmanager
+  def _open_replay_server(self, session: BrowserSessionRunGroup):
+    del session
+    yield
+
+  def _generate_filename(self, url: str) -> str:
+    metadata = self.host_platform.sh_stdout("gsutil", "ls", "-L", url)
+    if md5_search := GSUTIL_LS_MD5_RE.search(metadata):
+      md5 = md5_search.group(1)
+      safe_md5 = pth.safe_filename(md5)
+      url_path = pth.AnyPosixPath(urlparse(url).path)
+      return f"{url_path.stem}_{safe_md5}{url_path.suffix}"
+    raise RuntimeError(f"Could not find md5 hash in gsutil output: {metadata}")
+
+  def _download_gcloud_archive(self, url: str) -> LocalPath:
+    with exception.annotate(f"Downloading {url}"), Spinner():
+      local_path = (
+          self.host_platform.local_cache_dir("wpr") /
+          self._generate_filename(url))
+      if local_path.is_file():
+        logging.info("Found cached WPR archive: %s", local_path)
+        return local_path
+      logging.info("Downloading WPR archive from %s to %s", url, local_path)
+      self.host_platform.sh("gsutil", "cp", url, local_path)
+    return local_path
+
+  def _ensure_archive(self, archive: Union[pth.LocalPath, str]) -> LocalPath:
+    if isinstance(archive, str) and archive.startswith(GS_PREFIX):
+      return self._download_gcloud_archive(url=archive)
+    return PathParser.existing_file_path(archive).resolve()
diff --git a/crossbench/network/replay/web_page_replay.py b/crossbench/network/replay/web_page_replay.py
new file mode 100644
index 0000000..a414a84
--- /dev/null
+++ b/crossbench/network/replay/web_page_replay.py
@@ -0,0 +1,365 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import atexit
+import logging
+import os
+import re
+import shlex
+import subprocess
+import time
+from typing import Iterable, Optional, TextIO, Tuple
+
+from crossbench import helper
+from crossbench.helper.path_finder import WprGoToolFinder
+from crossbench.parse import NumberParser, PathParser
+from crossbench.path import AnyPath, LocalPath
+from crossbench.plt import PLATFORM, Platform, TupleCmdArgs
+
+_WPR_PORT_RE = re.compile(r".*Starting server on "
+                          r"(?P<protocol>http|https)://"
+                          r"(?P<host>[^:]+):"
+                          r"(?P<port>\d+)")
+
+
+class WprStartupError(RuntimeError):
+  pass
+
+
+class WprBase(abc.ABC):
+  NAME: str = ""
+
+  _key_file: AnyPath
+  _cert_file: AnyPath
+
+  def __init__(self,
+               archive_path: AnyPath,
+               bin_path: AnyPath,
+               http_port: int = 0,
+               https_port: int = 0,
+               host: str = "127.0.0.1",
+               inject_scripts: Optional[Iterable[AnyPath]] = None,
+               key_file: Optional[AnyPath] = None,
+               cert_file: Optional[AnyPath] = None,
+               log_path: Optional[LocalPath] = None,
+               platform: Platform = PLATFORM):
+    self._platform: Platform = platform
+    self._process: Optional[subprocess.Popen] = None
+    self._log_path: Optional[LocalPath] = None
+    if log_path:
+      self._log_path = PathParser.not_existing_path(log_path)
+    self._log_file: Optional[TextIO] = None
+    self._bin_path = bin_path
+    self._go_cmd: TupleCmdArgs = ()
+    self._local_http_port: int = 0
+    self._local_https_port: int = 0
+
+    wpr_root: LocalPath
+    if self._bin_path.suffix == ".go":
+      # `go` binary is required to run a Go source file (`wpr.go`).
+      assert self._platform.is_local
+      if local_go := self._platform.which("go"):
+        self._go_cmd = (local_go, "run", self._bin_path)
+      else:
+        raise ValueError(f"'go' binary not available on {self._platform}")
+      wpr_root = self._platform.local_path(self._bin_path.parents[1])
+    else:
+      # Assuming the binary path is precompiled and executable.
+      self._go_cmd = (self._bin_path,)
+      if self._platform.is_local:
+        if local_wpr_go := WprGoToolFinder(self._platform).path:
+          wpr_root = self._platform.local_path(local_wpr_go.parents[1])
+        else:
+          raise ValueError(
+              f"Could not find web_page_replay_go on {self._platform}")
+      else:
+        assert key_file is not None
+        assert cert_file is not None
+        assert inject_scripts is not None
+
+    self._archive_path = self._validate_archive_path(archive_path)
+    (self._http_port,
+     self._https_port) = self._validate_ports(http_port, https_port)
+    self._num_parsed_ports: int = 0
+    self._host: str = host
+    if self._platform.is_remote:
+      assert self._host == "127.0.0.1"
+
+    if key_file:
+      self._key_file = key_file
+    else:
+      self._key_file = wpr_root / "ecdsa_key.pem"
+    if not self._platform.is_file(self._key_file):
+      raise ValueError(f"Could not find ecdsa_key.pem file: {self._key_file}")
+
+    if cert_file:
+      self._cert_file = cert_file
+    else:
+      self._cert_file = wpr_root / "ecdsa_cert.pem"
+    if not self._platform.is_file(self._cert_file):
+      raise ValueError(f"Could not find ecdsa_cert.pem file: {self._cert_file}")
+
+    if inject_scripts is None:
+      inject_scripts = [wpr_root / "deterministic.js"]
+    for script in inject_scripts:
+      if "," in str(script):
+        raise ValueError(f"Injected script path cannot contain ',': {script}")
+      if not self._platform.is_file(script):
+        raise ValueError(f"Injected script does not exist: {script}")
+    self._inject_scripts: Tuple[AnyPath, ...] = tuple(inject_scripts)
+
+  def _validate_ports(self, http_port: int, https_port: int) -> Tuple[int, int]:
+    if http_port == 0:
+      logging.debug("WPR: using auto-port for http")
+    else:
+      http_port = NumberParser.port_number(http_port, "wpr http port")
+    if https_port == 0:
+      logging.debug("WPR: using auto-port for https")
+    else:
+      https_port = NumberParser.port_number(https_port, "wpr https port")
+    if http_port and http_port == https_port:
+      raise ValueError("http_port must be different from https_port, "
+                       f"but got twice: {http_port}")
+    return (http_port, https_port)
+
+  @abc.abstractmethod
+  def _validate_archive_path(self, path: AnyPath) -> AnyPath:
+    pass
+
+  @property
+  def http_port(self) -> int:
+    return self._http_port
+
+  @property
+  def https_port(self) -> int:
+    return self._https_port
+
+  @property
+  def host(self) -> str:
+    return self._host
+
+  @property
+  def cert_file(self) -> AnyPath:
+    return self._cert_file
+
+  @property
+  @abc.abstractmethod
+  def cmd(self) -> TupleCmdArgs:
+    pass
+
+  @property
+  def base_cmd_flags(self) -> TupleCmdArgs:
+    cmd: TupleCmdArgs = (
+        f"--http_port={self._http_port}",
+        f"--https_port={self._https_port}",
+        f"--https_key_file={self._key_file}",
+        f"--https_cert_file={self._cert_file}",
+    )
+    if self._inject_scripts is not None:
+      injected_scripts = ",".join(
+          os.fspath(path) for path in self._inject_scripts)
+      cmd += (f"--inject_scripts={injected_scripts}",)
+    return cmd
+
+  def start(self) -> None:
+    try:
+      self._start_wpr()
+      atexit.register(self.stop)
+      logging.info("WPR: waiting for startup...")
+      self._wait_for_startup()
+      logging.info("WPR: Started wpr.go %s: DONE (http_port=%s, http_port=%s)",
+                   self.NAME, self.http_port, self.https_port)
+    except BaseException as e:
+      if isinstance(e, Exception):
+        logging.debug("WPR got startup errors: %s %s", type(e), e)
+      force_shutdown = isinstance(e, WprStartupError)
+      self.stop(force_shutdown)
+      self._handle_startup_error()
+      raise
+
+  def _start_wpr(self) -> None:
+    go_cmd: TupleCmdArgs = self._go_cmd + self.cmd
+    logging.info("STARTING WPR on %s: %s", self._platform,
+                 shlex.join(map(str, go_cmd)))
+    self._num_parsed_ports = 0
+    if self._log_path:
+      self._log_file = self._log_path.open("w", encoding="utf-8")  # pylint: disable=consider-using-with
+    work_dir = (
+        self._bin_path.parent if self._platform.is_local else LocalPath.cwd())
+    with helper.ChangeCWD(work_dir):
+      logging.debug("Logging to %s", self._log_path)
+      self._process = self._platform.popen(
+          *go_cmd, stdout=self._log_file, stderr=self._log_file)
+    if not self._process:
+      raise WprStartupError(f"Could not start {type(self).__name__}")
+
+  def _handle_startup_error(self):
+    logging.error("WPR: Could not start %s", type(self).__name__)
+    if not self._log_path or not self._log_path.exists():
+      return
+    logging.error("WPR: Check log files %s", self._log_path)
+    try:
+      with self._log_path.open("r", encoding="utf-8") as f:
+        log_lines = list(f.readlines())
+        logging.error("  %s", "  ".join(log_lines[-4:]))
+    except Exception as e:  # pylint: disable=broad-except
+      logging.debug("Got exception while reading wpr log file: %s", e)
+
+  def _forward_ports(self) -> None:
+    if self._platform.is_remote:
+      self._local_http_port = self._platform.port_forward(0, self._http_port)
+      self._local_https_port = self._platform.port_forward(0, self._https_port)
+
+  def _stop_forward_ports(self) -> None:
+    if self._platform.is_remote:
+      self._platform.stop_port_forward(self._local_http_port)
+      self._platform.stop_port_forward(self._local_https_port)
+
+  def _wait_for_startup(self) -> None:
+    assert self._process, "process not started"
+    assert self._log_path, "missing log_path"
+    assert self._num_parsed_ports == 0, "WPR did not shut down correctly."
+    time.sleep(1)
+    with self._log_path.open("r", encoding="utf-8") as log_file:
+      while self._process.poll() is None:
+        line = log_file.readline()
+        if not line:
+          time.sleep(0.1)
+          continue
+        if self._parse_wpr_log_line(line):
+          break
+    if self._process.poll():
+      self._raise_startup_failure()
+
+    self._forward_ports()
+    time.sleep(0.1)
+    try:
+      with self._open_wpr_cmd_url("generate-200") as r:
+        if r.status == 200:
+          return
+    except Exception as e:  # pylint: disable=broad-except
+      logging.debug("Could not query wpr server: %s", e)
+    self._raise_startup_failure()
+
+  def _raise_startup_failure(self) -> None:
+    raise WprStartupError("Could not start wpr.go.\n"
+                          f"See log for more details: {self._log_path}")
+
+  def _parse_wpr_log_line(self, line: str) -> bool:
+    if "Failed to start server on" in line:
+      logging.error(line)
+      raise WprStartupError(
+          f"Could not start wpr.go server, address in use: {line}")
+    line = line.strip()
+    if match := _WPR_PORT_RE.match(line):
+      protocol = match["protocol"].lower()
+      port = int(match["port"])
+      if protocol == "http":
+        self._http_port = port
+        self._num_parsed_ports += 1
+      elif protocol == "https":
+        self._https_port = port
+        self._num_parsed_ports += 1
+      else:
+        logging.error("WPR: got invalid protocol: %s", line)
+      self._host = match["host"]
+      if not self._host:
+        raise WprStartupError(f"WPR: could not parse host from: {line}")
+
+    if self._num_parsed_ports == 2 and self._http_port and self._https_port:
+      logging.debug("WPR: https_port=%s http_port=%s", self._https_port,
+                    self._http_port)
+      return True
+    return False
+
+  def _open_wpr_cmd_url(self, cmd: str):
+    http_port = (
+        self._local_http_port if self._platform.is_remote else self._http_port)
+    test_url = f"http://{self._host}:{http_port}/web-page-replay-{cmd}"
+    return helper.urlopen(test_url, timeout=1)
+
+  def stop(self, force_shutdown: bool = False) -> None:
+    if self._process and not force_shutdown:
+      self._shut_down()
+    if self._log_file:
+      self._log_file.close()
+      self._log_file = None
+    if self._process:
+      helper.wait_and_kill(self._process, timeout=1)
+    self._process = None
+    self._stop_forward_ports()
+
+  def _shut_down(self) -> None:
+    logging.info("WPR: shutting down recorder.")
+    try:
+      with self._open_wpr_cmd_url("command-exit"):
+        pass
+    except IOError:
+      # The above request always fails because WPR closes the connection
+      # without response.
+      pass
+
+
+class WprRecorder(WprBase):
+  NAME: str = "recorder"
+
+  @property
+  def cert_file(self) -> LocalPath:
+    return self._platform.local_path(self._cert_file)
+
+  @property
+  def cmd(self) -> TupleCmdArgs:
+    return ("record",) + super().base_cmd_flags + (str(self._archive_path),)
+
+  def _validate_archive_path(self, path: AnyPath) -> LocalPath:
+    return PathParser.not_existing_path(path, "Wpr.go result archive")
+
+  def clear(self) -> None:
+    """Start a new recording by clearing out all existing recorded requests."""
+    self._open_wpr_cmd_url("command-clear")
+
+
+class WprReplayServer(WprBase):
+  NAME: str = "replay"
+
+  def __init__(self,
+               archive_path: AnyPath,
+               bin_path: AnyPath,
+               http_port: int = 0,
+               https_port: int = 0,
+               host: str = "127.0.0.1",
+               inject_scripts: Optional[Iterable[AnyPath]] = None,
+               key_file: Optional[AnyPath] = None,
+               cert_file: Optional[AnyPath] = None,
+               rules_file: Optional[AnyPath] = None,
+               log_path: Optional[LocalPath] = None,
+               fuzzy_url_matching: bool = True,
+               serve_chronologically: bool = True,
+               platform: Platform = PLATFORM):
+    super().__init__(archive_path, bin_path, http_port, https_port, host,
+                     inject_scripts, key_file, cert_file, log_path, platform)
+    self._rules_file: Optional[AnyPath] = None
+    if rules_file:
+      self._rules_file = PathParser.non_empty_file_path(rules_file)
+    self._fuzzy_url_matching: bool = fuzzy_url_matching
+    self._serve_chronologically: bool = serve_chronologically
+
+  def _validate_archive_path(self, path: AnyPath) -> AnyPath:
+    assert self._platform.is_file(path)
+    return path
+
+  @property
+  def cmd(self) -> TupleCmdArgs:
+    cmd = ("replay",) + super().base_cmd_flags
+    if self._rules_file:
+      cmd += (f"--rules_file={self._rules_file }",)
+    if not self._fuzzy_url_matching:
+      cmd += ("--disable_fuzzy_url_matching",)
+    if self._serve_chronologically:
+      cmd += ("--serve_response_in_chronological_sequence",)
+    cmd += (str(self._archive_path),)
+    return cmd
diff --git a/crossbench/network/replay/wpr.py b/crossbench/network/replay/wpr.py
new file mode 100644
index 0000000..9da1826
--- /dev/null
+++ b/crossbench/network/replay/wpr.py
@@ -0,0 +1,261 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+import hashlib
+import logging
+from typing import TYPE_CHECKING, Iterator, List, Optional, Union
+
+from crossbench.flags.base import Flags
+from crossbench.helper.path_finder import WprGoToolFinder
+from crossbench.network.replay.base import GS_PREFIX, ReplayNetwork
+from crossbench.network.replay.web_page_replay import WprReplayServer
+from crossbench.parse import PathParser
+from crossbench.plt import PLATFORM, Platform
+from crossbench.plt.arch import MachineArch
+
+if TYPE_CHECKING:
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.network.base import TrafficShaper
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+# use value for pylint
+assert GS_PREFIX
+
+BASE_URL = "gs://chromium-telemetry/binary_dependencies"
+
+WPR_PREBUILT_ARCH_MAP = {
+    MachineArch.ARM_64: {
+        "url": f"{BASE_URL}/wpr_go_129a66a1378dfcbb815596f66ca680728f77da36",
+        "file_hash": "129a66a1378dfcbb815596f66ca680728f77da36",
+    },
+    MachineArch.ARM_32: {
+        "url": f"{BASE_URL}/wpr_go_92ff5bdb9370b36d2844c2f018e2b7d9c3b8ed39",
+        "file_hash": "92ff5bdb9370b36d2844c2f018e2b7d9c3b8ed39",
+    },
+    MachineArch.X64: {
+        "url": f"{BASE_URL}/wpr_go_6caa467dc6bef92e1c34256f539f8ed8f26a2fe1",
+        "file_hash": "6caa467dc6bef92e1c34256f539f8ed8f26a2fe1",
+    },
+}
+
+
+def check_hash(file_path: LocalPath, file_hash: str) -> bool:
+  if not file_path.exists():
+    return False
+  sha1 = hashlib.sha1()
+  sha1.update(file_path.read_bytes())
+  return sha1.hexdigest() == file_hash
+
+
+class WprReplayNetwork(ReplayNetwork):
+
+  def __init__(self,
+               archive: Union[LocalPath, str],
+               traffic_shaper: Optional[TrafficShaper] = None,
+               wpr_go_bin: Optional[LocalPath] = None,
+               browser_platform: Platform = PLATFORM,
+               persist_server: bool = False):
+    super().__init__(archive, traffic_shaper, browser_platform)
+    self._server: Optional[WprReplayServer] = None
+    self._tmp_dir: Optional[AnyPath] = None
+    self._persist_server = persist_server
+    self._ensure_wpr_go(wpr_go_bin)
+
+  def extra_flags(self, browser_attributes: BrowserAttributes) -> Flags:
+    assert self.is_running, "Extra network flags are not valid"
+    assert self._server
+    if not browser_attributes.is_chromium_based:
+      raise ValueError(
+          "Only chromium-based browsers are supported for wpr replay.")
+    # TODO: make ports configurable.
+    extra_flags = super().extra_flags(browser_attributes)
+    # TODO: read this from wpr_public_hash.txt like in the recorder probe
+    extra_flags["--ignore-certificate-errors-spki-list"] = (
+        "PhrPvGIaAMmd29hj8BCZOq096yj7uMpRNHpn5PDxI6I=,"
+        "2HcXCSKKJS0lEXLQEWhpHUfGuojiU0tiT5gOF9LP6IQ=")
+    if self._traffic_shaper.is_live:
+      # Only remap ports if we're not using the SOCKS proxy from the traffic
+      # shaper.
+      extra_flags["--host-resolver-rules"] = (
+          f"MAP *:80 {self.host}:{self.http_port},"
+          f"MAP *:443 {self.host}:{self.https_port},"
+          "EXCLUDE localhost")
+
+    return extra_flags
+
+  @abc.abstractmethod
+  def _ensure_wpr_go(self, wpr_go_bin: Optional[LocalPath] = None):
+    pass
+
+  @abc.abstractmethod
+  def _create_server(self, log_dir: LocalPath) -> WprReplayServer:
+    pass
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+    with super().open(session):
+      yield self
+
+  def _ensure_server_started(self, session: BrowserSessionRunGroup):
+    log_dir = session.browser_dir if self._persist_server else session.out_dir
+    if not self._server or not self._persist_server:
+      self._server = self._create_server(log_dir)
+      logging.debug("Starting WPR server")
+      self._server.start()
+    else:
+      # TODO: reset wpr server state for reuse
+      logging.debug("WPR server already started")
+
+  @contextlib.contextmanager
+  def _open_replay_server(self, session: BrowserSessionRunGroup):
+    self._ensure_server_started(session)
+
+    try:
+      yield self
+    finally:
+      if not self._persist_server:
+        self._server.stop()
+
+  @property
+  def http_port(self) -> int:
+    assert self._server, "WPR is not running"
+    return self._server.http_port
+
+  @property
+  def https_port(self) -> int:
+    assert self._server, "WPR is not running"
+    return self._server.https_port
+
+  @property
+  def host(self) -> str:
+    assert self._server, "WPR is not running"
+    return self._server.host
+
+  def __str__(self) -> str:
+    return f"WPR(archive={self.archive_path}, speed={self.traffic_shaper})"
+
+
+class LocalWprReplayNetwork(WprReplayNetwork):
+
+  def _ensure_wpr_go(self, wpr_go_bin: Optional[LocalPath] = None):
+    if not wpr_go_bin:
+      if local_wpr_go := WprGoToolFinder(self.host_platform).path:
+        wpr_go_bin = self.host_platform.local_path(local_wpr_go)
+    if not wpr_go_bin:
+      raise RuntimeError(
+          f"Could not find wpr.go binary on {self.host_platform}")
+    if wpr_go_bin.suffix == ".go" and not self.host_platform.which("go"):
+      raise ValueError(f"'go' binary not found on {self.host_platform}")
+    self._wpr_go_bin: LocalPath = self.host_platform.local_path(
+        PathParser.binary_path(wpr_go_bin, "wpr.go source"))
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+    with super().open(session):
+      with self._forward_ports(session):
+        yield self
+
+  @contextlib.contextmanager
+  def _forward_ports(self, session: BrowserSessionRunGroup) -> Iterator:
+    browser_platform = session.browser_platform
+    if not self._traffic_shaper.is_live or not browser_platform.is_remote:
+      yield
+      return
+    http_port = self.http_port
+    https_port = self.https_port
+    logging.info("REMOTE PORT FORWARDING: %s <= %s", self.host_platform,
+                 browser_platform)
+    # TODO: create port-forwarder service that is shut down properly.
+    # TODO: make ports configurable
+    browser_platform.reverse_port_forward(http_port, http_port)
+    browser_platform.reverse_port_forward(https_port, https_port)
+    yield
+    browser_platform.stop_reverse_port_forward(http_port)
+    browser_platform.stop_reverse_port_forward(https_port)
+
+  def _create_server(self, log_dir: LocalPath) -> WprReplayServer:
+    return WprReplayServer(
+        self.archive_path,
+        self._wpr_go_bin,
+        log_path=log_dir / "network.wpr.log",
+        platform=self.host_platform)
+
+
+class RemoteWprReplayNetwork(WprReplayNetwork):
+
+  def _ensure_wpr_go(self, wpr_go_bin: Optional[LocalPath] = None):
+    assert self.browser_platform.is_android
+    if wpr_go_bin:
+      if wpr_go_bin.suffix == ".go":
+        raise ValueError(f"Can't run .go files on {self.browser_platform}")
+    else:
+      wpr_go_bin = self._download_prebuilt_wpr()
+    self._wpr_go_bin: LocalPath = self.host_platform.local_path(
+        PathParser.binary_path(wpr_go_bin, "wpr.go binary"))
+
+  def _download_prebuilt_wpr(self) -> LocalPath:
+    wpr_info = WPR_PREBUILT_ARCH_MAP[self.browser_platform.machine]
+    local_wpr_go_bin = (
+        self.host_platform.local_cache_dir("wpr") /
+        str(self.browser_platform.machine) / "wpr_go")
+    if not check_hash(local_wpr_go_bin, wpr_info["file_hash"]):
+      self.host_platform.sh("gsutil", "cp", wpr_info["url"], local_wpr_go_bin)
+    assert check_hash(local_wpr_go_bin, wpr_info["file_hash"])
+
+    return local_wpr_go_bin
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+    with self._remote_temp_dir(session):
+      with super().open(session):
+        yield self
+
+  @contextlib.contextmanager
+  def _remote_temp_dir(self, session: BrowserSessionRunGroup) -> Iterator:
+    with session.browser_platform.TemporaryDirectory() as tmp_dir:
+      self._tmp_dir = tmp_dir
+      yield
+      self._tmp_dir = None
+
+  def _push_file(self, path: LocalPath) -> AnyPath:
+    assert self._tmp_dir is not None
+    remote_path = self._tmp_dir / path.name
+    self.browser_platform.push(path, remote_path)
+    return remote_path
+
+  def _push_required_files(self) -> List[AnyPath]:
+    host_platform = self.host_platform
+    if local_wpr_go := WprGoToolFinder(host_platform).path:
+      wpr_root = self.host_platform.path(local_wpr_go.parents[1])
+    else:
+      raise RuntimeError(f"Could not fine local wpr.go on {host_platform}")
+
+    all_files = [self._archive_path,
+                 wpr_root / "ecdsa_key.pem",
+                 wpr_root / "ecdsa_cert.pem",
+                 wpr_root / "deterministic.js"]
+    remote_files = [self._push_file(f) for f in all_files]
+
+    remote_wpr_go_bin = self._push_file(self._wpr_go_bin)
+    self.browser_platform.sh("chmod", "+x", remote_wpr_go_bin)
+
+    return [remote_wpr_go_bin] + remote_files
+
+  def _create_server(self, log_dir: LocalPath) -> WprReplayServer:
+    wpr_go_bin, archive, key_file, cert_file, inject_script =\
+        self._push_required_files()
+    return WprReplayServer(
+        archive_path=archive,
+        bin_path=wpr_go_bin,
+        key_file=key_file,
+        cert_file=cert_file,
+        inject_scripts=[inject_script],
+        log_path=log_dir / "network.wpr.log",
+        platform=self.browser_platform)
diff --git a/crossbench/network/traffic_shaping/__init__.py b/crossbench/network/traffic_shaping/__init__.py
new file mode 100644
index 0000000..e9d2bfa
--- /dev/null
+++ b/crossbench/network/traffic_shaping/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/network/traffic_shaping/base.py b/crossbench/network/traffic_shaping/base.py
new file mode 100644
index 0000000..75c9b4a
--- /dev/null
+++ b/crossbench/network/traffic_shaping/base.py
@@ -0,0 +1,56 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+from typing import TYPE_CHECKING, Iterator
+
+from crossbench.flags.base import Flags
+
+if TYPE_CHECKING:
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.network.base import Network
+  from crossbench.plt.base import Platform
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class TrafficShaper(abc.ABC):
+
+  def __init__(self, browser_platform: Platform):
+    self._browser_platform = browser_platform
+    self._is_running = False
+
+  @property
+  def browser_platform(self) -> Platform:
+    return self._browser_platform
+
+  @property
+  def host_platform(self) -> Platform:
+    return self._browser_platform.host_platform
+
+  @property
+  def is_live(self) -> bool:
+    return False
+
+  @property
+  def is_running(self) -> bool:
+    return self._is_running
+
+  def extra_flags(self, browser_attributes: BrowserAttributes) -> Flags:
+    del browser_attributes
+    assert self.is_running, "TrafficShaper is not running."
+    return Flags()
+
+  @contextlib.contextmanager
+  def open(self, network: Network,
+           session: BrowserSessionRunGroup) -> Iterator[TrafficShaper]:
+    del network, session
+    assert not self._is_running, "Cannot start network more than once."
+    self._is_running = True
+    try:
+      yield self
+    finally:
+      self._is_running = False
diff --git a/crossbench/network/traffic_shaping/live.py b/crossbench/network/traffic_shaping/live.py
new file mode 100644
index 0000000..dd0e491
--- /dev/null
+++ b/crossbench/network/traffic_shaping/live.py
@@ -0,0 +1,17 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.network.traffic_shaping.base import TrafficShaper
+
+
+class NoTrafficShaper(TrafficShaper):
+
+  @property
+  def is_live(self) -> bool:
+    return True
+
+  def __str__(self) -> str:
+    return "full"
diff --git a/crossbench/network/traffic_shaping/ts_proxy.py b/crossbench/network/traffic_shaping/ts_proxy.py
new file mode 100644
index 0000000..664f616
--- /dev/null
+++ b/crossbench/network/traffic_shaping/ts_proxy.py
@@ -0,0 +1,462 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# Modified from chrome's catapult project.
+
+from __future__ import annotations
+
+import atexit
+import contextlib
+import locale
+import logging
+import os
+import re
+import shlex
+import signal
+import subprocess
+import sys
+from typing import IO, TYPE_CHECKING, Iterator, List, Optional, Union
+
+from crossbench import helper
+from crossbench.flags.base import Flags
+from crossbench.helper.path_finder import TsProxyFinder
+from crossbench.network.traffic_shaping.base import TrafficShaper
+from crossbench.parse import NumberParser, PathParser
+
+if TYPE_CHECKING:
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.network.base import Network
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.plt.base import ListCmdArgs, Platform
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+fcntl = None
+try:
+  import fcntl
+except ModuleNotFoundError as not_found:
+  logging.debug("No fcntl support %s", not_found)
+
+
+
+class TsProxyServerError(Exception):
+  """Catch-all exception for tsProxy Server."""
+
+
+_PORT_RE = re.compile(r"Started Socks5 proxy server on "
+                      r"(?P<host>[^:]*):"
+                      r"(?P<port>\d+)")
+DEFAULT_TIMEOUT = 5
+
+
+def parse_ts_socks_proxy_port(output_line):
+  if match := _PORT_RE.match(output_line):
+    return int(match.group("port"))
+  return None
+
+
+# TODO: improve and double check
+TRAFFIC_SETTINGS = {
+    "3G-slow": {
+        "rtt_ms": 400,
+        "in_kbps": 400,
+        "out_kbps": 400,
+    },
+    "3G-regular": {
+        "rtt_ms": 300,
+        "in_kbps": 1600,
+        "out_kbps": 768,
+    },
+    "3G-fast": {
+        "rtt_ms": 150,
+        "in_kbps": 1600,
+        "out_kbps": 768,
+    },
+    "4G": {
+        "rtt_ms": 170,
+        "in_kbps": 9000,
+        "out_kbps": 9000,
+    },
+}
+
+
+class TsProxyServer:
+  """
+  TsProxy provides basic latency, download and upload traffic shaping. This
+  class provides a programming API to the tsproxy script in
+  catapult/third_party/tsproxy/tsproxy.py
+
+  This class can be used as a context manager.
+  """
+
+  def __init__(self,
+               ts_proxy_path: LocalPath,
+               host: Optional[str] = None,
+               socks_proxy_port: Optional[int] = None,
+               http_port: Optional[int] = None,
+               https_port: Optional[int] = None,
+               rtt_ms: Optional[int] = None,
+               in_kbps: Optional[int] = None,
+               out_kbps: Optional[int] = None,
+               window: Optional[int] = None,
+               verbose: bool = True):
+    self._proc: Optional[TsProxyProcess] = None
+    self._ts_proxy_path = PathParser.existing_file_path(ts_proxy_path)
+    self._socks_proxy_port = socks_proxy_port
+    self._host = host
+    self._http_port = http_port
+    self._https_port = https_port
+    self._rtt_ms = rtt_ms
+    self._in_kbps = in_kbps
+    self._out_kbps = out_kbps
+    self._window = window
+    self._verbose = verbose
+    self.verify_ports(http_port, https_port)
+
+  @classmethod
+  def verify_ports(cls,
+                   http_port: Optional[int] = None,
+                   https_port: Optional[int] = None) -> None:
+    if https_port and not bool(http_port):
+      raise ValueError(f"Got https_port={https_port} without a http port")
+    if http_port is not None and http_port == https_port:
+      raise ValueError("http_port and https_port must be different, "
+                       f"got {https_port} twice.")
+    if http_port is not None:
+      NumberParser.port_number(http_port, "http_port")
+    if https_port is not None:
+      NumberParser.port_number(https_port, "https_port")
+
+  @property
+  def is_running(self) -> bool:
+    return self._proc is not None
+
+  def set_traffic_settings(self,
+                           rtt_ms: Optional[int] = None,
+                           in_kbps: Optional[int] = None,
+                           out_kbps: Optional[int] = None,
+                           window: Optional[int] = None,
+                           timeout=DEFAULT_TIMEOUT) -> None:
+    assert self._proc, "ts_proxy is not running."
+    self._proc.set_traffic_settings(rtt_ms, in_kbps, out_kbps, window, timeout)
+
+  @property
+  def socks_proxy_port(self) -> int:
+    assert self._proc, "ts_proxy is not running."
+    return self._proc.socks_proxy_port
+
+  @property
+  def ts_proxy_path(self) -> LocalPath:
+    return self._ts_proxy_path
+
+  @property
+  def rtt_ms(self) -> Optional[int]:
+    return self._rtt_ms
+
+  @property
+  def in_kbps(self) -> Optional[int]:
+    return self._in_kbps
+
+  @property
+  def out_kbps(self) -> Optional[int]:
+    return self._out_kbps
+
+  @property
+  def window(self) -> Optional[int]:
+    return self._window
+
+  def start(self) -> None:
+    assert not self._proc, "ts_proxy is already running."
+    self._proc = TsProxyProcess(self._ts_proxy_path, self._host,
+                                self._socks_proxy_port, self._http_port,
+                                self._https_port, self._rtt_ms, self._in_kbps,
+                                self._out_kbps, self._window, self._verbose)
+    atexit.register(self.stop)
+
+  def stop(self) -> Optional[str]:
+    if not self._proc:
+      logging.debug("TsProxy: Attempting to stop server that is not running.")
+      return None
+    assert self._proc
+    err = self._proc.stop()
+    self._proc = None
+    return err
+
+  def __enter__(self):
+    self.start()
+    return self
+
+  def __exit__(self, unused_exc_type, unused_exc_val, unused_exc_tb):
+    self.stop()
+
+
+class TsProxyProcess:
+  """Separate wrapper around the ts_proxy to simplify pytype testing."""
+
+  def __init__(self,
+               ts_proxy_path: LocalPath,
+               host: Optional[str] = None,
+               socks_proxy_port: Optional[int] = None,
+               http_port: Optional[int] = None,
+               https_port: Optional[int] = None,
+               rtt_ms: Optional[int] = None,
+               in_kbps: Optional[int] = None,
+               out_kbps: Optional[int] = None,
+               window: Optional[int] = None,
+               verbose: bool = False,
+               timeout: Union[int, float] = DEFAULT_TIMEOUT) -> None:
+    """Start TsProxy server and verify that it started."""
+    cmd: ListCmdArgs = [
+        sys.executable,
+        ts_proxy_path,
+    ]
+    self._socks_proxy_port: Optional[int] = socks_proxy_port
+    self._initial_socks_proxy_port: Optional[int] = socks_proxy_port
+    if not socks_proxy_port:
+      # Use port 0 so tsproxy picks a random available port.
+      cmd.append("--port=0")
+    else:
+      cmd.append(f"--port={socks_proxy_port}")
+    if verbose:
+      cmd.append("--verbose")
+    self._in_kbps: Optional[int] = in_kbps
+    if in_kbps:
+      cmd.append(f"--inkbps={in_kbps}")
+    self._out_kbps: Optional[int] = out_kbps
+    if out_kbps:
+      cmd.append(f"--outkbps={out_kbps}")
+    self._window: Optional[int] = window
+    if window:
+      cmd.append(f"--window={window}")
+    self._rtt_ms: Optional[int] = rtt_ms
+    if rtt_ms:
+      cmd.append(f"--rtt={rtt_ms}")
+    self._host: Optional[str] = host
+    if host:
+      cmd.append(f"--desthost={host}")
+    self._http_port: Optional[int] = http_port
+    self._https_port: Optional[int] = https_port
+    TsProxyServer.verify_ports(http_port, https_port)
+    mapports = []
+    if https_port:
+      mapports.append(f"443:{https_port}")
+    if http_port:
+      mapports.append(f"*:{http_port}")
+    cmd.append(f"--mapports={','.join(mapports)}")
+    logging.info("TsProxy: commandline: %s", shlex.join(map(str, cmd)))
+    self._verify_default_encoding()
+    # In python3 universal_newlines forces subprocess to encode/decode,
+    # allowing per-line buffering.
+    proc = subprocess.Popen(  # pylint: disable=consider-using-with
+        cmd,
+        stdout=subprocess.PIPE,
+        stdin=subprocess.PIPE,
+        # stderr=subprocess.PIPE,
+        bufsize=1,
+        universal_newlines=True)
+    assert proc and proc.stdout and proc.stdin, "Could not start ts_proxy"
+    self._proc = proc
+    if stdout := proc.stdout:
+      self._stdout: IO[str] = stdout
+    else:
+      raise RuntimeError("Missing stdout")
+    if stdin := proc.stdin:
+      self._stdin: IO[str] = stdin
+    else:
+      raise RuntimeError("Missing stdin")
+    if fcntl:  # pylint: disable=using-constant-test
+      self._setup_non_blocking_io()
+    self._wait_for_startup(timeout)
+
+  def _setup_non_blocking_io(self) -> None:
+    logging.debug("TsProxy: fcntl is supported, trying to set "
+                  "non blocking I/O for the ts_proxy process")
+    fd = self._stdout.fileno()
+    fl = fcntl.fcntl(fd, fcntl.F_GETFL)
+    fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)  # pylint: disable=no-member
+
+  @property
+  def socks_proxy_port(self) -> int:
+    if self._socks_proxy_port is None:
+      raise RuntimeError("ts_proxy didn't start")
+    return self._socks_proxy_port
+
+  def _verify_default_encoding(self) -> None:
+    # In python3 subprocess handles encoding/decoding; this warns if it won't
+    # be UTF-8.
+    encoding = locale.getpreferredencoding()
+    if encoding != "UTF-8":
+      logging.warning("Decoding will use %s instead of UTF-8", encoding)
+
+  def _wait_for_startup(self, timeout: Union[int, float]) -> None:
+    for _ in helper.wait_with_backoff(timeout):
+      if self._has_started():
+        logging.info("TsProxy: port=%i", self._socks_proxy_port)
+        return
+    if err := self.stop():
+      logging.error("TsProxy: Error stopping WPR server:\n%s", err)
+    raise TsProxyServerError(
+        f"Starting tsproxy timed out after {timeout} seconds")
+
+  def _has_started(self) -> bool:
+    if self._proc.poll() is not None:
+      return False
+    self._stdout.flush()
+    output_line = self._read_line_ts_proxy_stdout(timeout=5)
+    if not output_line:
+      return False
+    logging.debug("TsProxy: output: %s", output_line)
+    port = parse_ts_socks_proxy_port(output_line)
+    self._socks_proxy_port = NumberParser.port_number(port, "socks_proxy_port")
+    return True
+
+  def _read_line_ts_proxy_stdout(self, timeout: Union[int, float]) -> str:
+    for _ in helper.wait_with_backoff(timeout):
+      try:
+        return self._stdout.readline().strip()
+      except IOError as io_error:
+        logging.debug("TsProxy: Error while reading tsproxy line: %s", io_error)
+    return ""
+
+  def _send_command(self,
+                    command: str,
+                    timeout: Union[int, float] = DEFAULT_TIMEOUT) -> None:
+    logging.debug("TsProxy: Sending command to ts_proxy_server: %s", command)
+    self._stdin.write(f"{command}\n")
+    command_output = self._wait_for_status_response(timeout)
+    success = "OK" in command_output
+    logging.log(logging.DEBUG if success else logging.ERROR,
+                "TsProxy: output:\n%s", "\n".join(command_output))
+    if not success:
+      raise TsProxyServerError(f"Failed to execute command: {command}")
+
+  def _wait_for_status_response(self, timeout: Union[int, float]) -> List[str]:
+    logging.debug("TsProxy: waiting for status response")
+    command_output = []
+    for _ in helper.wait_with_backoff(timeout):
+      self._stdin.flush()
+      self._stdout.flush()
+      last_output = self._read_line_ts_proxy_stdout(timeout)
+      command_output.append(last_output)
+      if last_output in ("OK", "ERROR"):
+        break
+    return command_output
+
+  def set_traffic_settings(self,
+                           rtt_ms: Optional[int] = None,
+                           in_kbps: Optional[int] = None,
+                           out_kbps: Optional[int] = None,
+                           window: Optional[int] = None,
+                           timeout=DEFAULT_TIMEOUT) -> None:
+    if rtt_ms is not None and self._rtt_ms != rtt_ms:
+      assert rtt_ms >= 0, f"Invalid rtt value: {rtt_ms}"
+      self._send_command(f"set rtt {rtt_ms}", timeout)
+      self._rtt_ms = rtt_ms
+
+    if in_kbps is not None and self._in_kbps != in_kbps:
+      assert in_kbps >= 0, f"Invalid in_kbps value: {in_kbps}"
+      self._send_command(f"set inkbps {in_kbps}", timeout)
+      self._in_kbps = in_kbps
+
+    if out_kbps is not None and self._out_kbps != out_kbps:
+      assert out_kbps >= 0, f"Invalid out_kbps value: {out_kbps}"
+      self._send_command(f"set outkbps {out_kbps}", timeout)
+      self._out_kbps = out_kbps
+
+    if window is not None and self._window != window:
+      assert window >= 0, f"Invalid window value: {window}"
+      self._send_command(f"set window {window}", timeout)
+      self._window = window
+
+  def stop(self) -> Optional[str]:
+    self._send_command("exit")
+    helper.wait_and_kill(self._proc, signal=signal.SIGINT)
+    _, err = self._proc.communicate()
+    self._socks_proxy_port = self._initial_socks_proxy_port
+    return err
+
+
+class TsProxyTrafficShaper(TrafficShaper):
+
+  def __init__(self,
+               browser_platform: Platform,
+               ts_proxy_path: Optional[AnyPath] = None,
+               rtt_ms: Optional[int] = None,
+               in_kbps: Optional[int] = None,
+               out_kbps: Optional[int] = None,
+               window: Optional[int] = None):
+    super().__init__(browser_platform)
+    if not ts_proxy_path:
+      if maybe_ts_proxy_path := TsProxyFinder(self.host_platform).path:
+        ts_proxy_path = self.host_platform.local_path(maybe_ts_proxy_path)
+    if not ts_proxy_path:
+      raise RuntimeError(
+          f"Could not find ts_proxy script on {self.host_platform}")
+    # Early instantiation to validate inputs.
+    self._ts_proxy = TsProxyServer(
+        self.host_platform.local_path(ts_proxy_path),
+        rtt_ms=rtt_ms,
+        in_kbps=in_kbps,
+        out_kbps=out_kbps,
+        window=window)
+    # TODO: support custom name
+    self._name = "tsproxy"
+
+  @property
+  def ts_proxy(self) -> TsProxyServer:
+    return self._ts_proxy
+
+  @contextlib.contextmanager
+  def open(self, network: Network,
+           session: BrowserSessionRunGroup) -> Iterator[TrafficShaper]:
+    if not network.is_live:
+      self._ts_proxy = self._create_remapping_ts_proxy(network)
+
+    with super().open(network, session):
+      logging.debug("Starting TS Proxy")
+      with self._ts_proxy:
+        with self._forward_ports(network, session):
+          yield self
+
+  def _create_remapping_ts_proxy(self, network) -> TsProxyServer:
+    return TsProxyServer(
+        self._ts_proxy.ts_proxy_path,
+        rtt_ms=self._ts_proxy.rtt_ms,
+        in_kbps=self._ts_proxy.in_kbps,
+        out_kbps=self._ts_proxy.out_kbps,
+        window=self._ts_proxy.window,
+        host=network.host,
+        http_port=network.http_port,
+        https_port=network.https_port)
+
+  @contextlib.contextmanager
+  def _forward_ports(self, network: Network,
+                     session: BrowserSessionRunGroup) -> Iterator:
+    del network
+    browser_platform = session.browser_platform
+    ts_proxy_port = self._ts_proxy.socks_proxy_port
+    # TODO; remap network port for remote browsers or when ports are occupied
+    # already.
+    if browser_platform.is_remote:
+      browser_platform.reverse_port_forward(ts_proxy_port, ts_proxy_port)
+    yield
+    if browser_platform.is_remote:
+      browser_platform.stop_reverse_port_forward(ts_proxy_port)
+
+  def extra_flags(self, browser_attributes: BrowserAttributes) -> Flags:
+    if not browser_attributes.is_chromium_based:
+      raise ValueError(
+          "Only chromium-based browsers are supported with ts_proxy.")
+    # TODO: support port forwarding to remote device
+    assert browser_attributes.is_local, "Only local browsers supported for now"
+    assert self.is_running, "TrafficShaper is not running."
+    assert self._ts_proxy.socks_proxy_port, "ts_proxy is not running"
+    return Flags({
+        "--proxy-server":
+            f"socks://127.0.0.1:{self._ts_proxy.socks_proxy_port}",
+        "--proxy-bypass-list":
+            "<-loopback>"
+    })
+
+  def __str__(self) -> str:
+    return self._name
diff --git a/crossbench/parse.py b/crossbench/parse.py
new file mode 100644
index 0000000..827f8ca
--- /dev/null
+++ b/crossbench/parse.py
@@ -0,0 +1,642 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import enum
+import json
+import logging
+import math
+import re
+import shlex
+from typing import (Any, Dict, Final, Iterable, List, Optional, Sequence, Type,
+                    TypeVar, Union, cast)
+from urllib import parse as urlparse
+
+import hjson
+
+from crossbench import path as pth
+from crossbench import plt
+
+
+def type_str(value: Any) -> str:
+  return type(value).__name__
+
+
+class PathParser:
+
+  PATH_PREFIX = re.compile(r"^(?:"
+                           r"(?:\.\.?|~)?|"
+                           r"[a-zA-Z]:"
+                           r")(\\|/)[^\\/]")
+
+  @classmethod
+  def path(cls, value: pth.AnyPathLike, name: str = "value") -> pth.LocalPath:
+    value = ObjectParser.not_none(value, "path")
+    if not value:
+      raise argparse.ArgumentTypeError("Invalid empty path.")
+    try:
+      path = pth.LocalPath(value).expanduser()
+    except RuntimeError as e:
+      raise argparse.ArgumentTypeError(
+          f"Invalid Path {name} {repr(value)}': {e}") from e
+    return path
+
+  @classmethod
+  def existing_file_path(cls,
+                         value: pth.AnyPathLike,
+                         name: str = "value") -> pth.LocalPath:
+    path = cls.existing_path(value, name)
+    if not path.is_file():
+      raise argparse.ArgumentTypeError(
+          f"{name} is not a file: {repr(str(path))}")
+    return path
+
+  @classmethod
+  def non_empty_file_path(cls,
+                          value: pth.AnyPathLike,
+                          name: str = "value") -> pth.LocalPath:
+    path: pth.LocalPath = cls.existing_file_path(value, name)
+    if path.stat().st_size == 0:
+      raise argparse.ArgumentTypeError(
+          f"{name} is an empty file: {repr(str(path))}")
+    return path
+
+  @classmethod
+  def file_path(cls,
+                value: pth.AnyPathLike,
+                name: str = "value") -> pth.LocalPath:
+    return cls.non_empty_file_path(value, name)
+
+  @classmethod
+  def dir_path(cls,
+               value: pth.AnyPathLike,
+               name: str = "value") -> pth.LocalPath:
+    path = cls.existing_path(value, name)
+    if not path.is_dir():
+      raise argparse.ArgumentTypeError(
+          f"{name} is not a folder: '{repr(str(path))}'")
+    return path
+
+  @classmethod
+  def non_empty_dir_path(cls,
+                         value: pth.AnyPathLike,
+                         name: str = "value") -> pth.LocalPath:
+    dir_path = cls.dir_path(value, name)
+    for _ in dir_path.iterdir():
+      return dir_path
+    raise argparse.ArgumentTypeError(
+        f"{name} dir must be non empty: {repr(str(dir_path))}")
+
+  @classmethod
+  def existing_path(cls,
+                    value: pth.AnyPathLike,
+                    name: str = "value") -> pth.LocalPath:
+    path = cls.path(value)
+    if not path.exists():
+      raise argparse.ArgumentTypeError(
+          f"{name} path does not exist: {repr(str(path))}")
+    return path
+
+  @classmethod
+  def not_existing_path(cls,
+                        value: pth.AnyPathLike,
+                        name: str = "value") -> pth.LocalPath:
+    path = cls.path(value)
+    if path.exists():
+      raise argparse.ArgumentTypeError(
+          f"{name} path already exists: {repr(str(path))}")
+    return path
+
+  @classmethod
+  def binary_path(cls,
+                  value: Optional[pth.AnyPathLike],
+                  name: str = "binary",
+                  platform: Optional[plt.Platform] = None) -> pth.AnyPath:
+    platform = platform or plt.PLATFORM
+    maybe_path = platform.path(ObjectParser.not_none(value, name))
+    if platform.is_file(maybe_path):
+      return maybe_path
+    maybe_bin = platform.search_binary(maybe_path)
+    if not maybe_bin:
+      raise argparse.ArgumentTypeError(f"Unknown binary: {value}")
+    return maybe_bin
+
+  @classmethod
+  def any_path(cls,
+               value: Optional[pth.AnyPathLike],
+               name: str = "value") -> pth.AnyPath:
+    """Parse a path than can be on a local or remote file system."""
+    some_value: pth.AnyPathLike = ObjectParser.not_none(value, name)
+    if not some_value:
+      raise argparse.ArgumentTypeError(f"Expected non empty path {name}.")
+    return pth.AnyPath(some_value)
+
+  @classmethod
+  def local_binary_path(cls,
+                        value: Optional[pth.AnyPathLike],
+                        name: str = "binary") -> pth.LocalPath:
+    return cast(pth.LocalPath, cls.binary_path(value, name))
+
+  @classmethod
+  def json_file_path(cls, value: pth.AnyPathLike) -> pth.LocalPath:
+    path = cls.file_path(value)
+    with path.open(encoding="utf-8") as f:
+      try:
+        json.load(f)
+      except ValueError as e:
+        message = _extract_decoding_error(f"Invalid json file '{path}':", path,
+                                          e)
+        raise argparse.ArgumentTypeError(message) from e
+    return path
+
+  @classmethod
+  def hjson_file_path(cls, value: pth.AnyPathLike) -> pth.LocalPath:
+    path = cls.file_path(value)
+    with path.open(encoding="utf-8") as f:
+      try:
+        hjson.load(f)
+      except ValueError as e:
+        message = _extract_decoding_error("Invalid hjson file '{path}':", path,
+                                          e)
+        raise argparse.ArgumentTypeError(message) from e
+    return path
+
+
+EnumT = TypeVar("EnumT", bound=enum.Enum)
+NotNoneT = TypeVar("NotNoneT", bound=Any)
+SequenceT = TypeVar("SequenceT", bound=Sequence)
+
+
+class ObjectParser:
+
+  @classmethod
+  def enum(cls, label: str, enum_cls: Type[EnumT], data: Any,
+           choices: Union[Type[EnumT], Iterable[EnumT]]) -> EnumT:
+    try:
+      # Try direct conversion, relying on the Enum._missing_ hook:
+      enum_value = enum_cls(data)
+      assert isinstance(enum_value, enum.Enum)
+      assert isinstance(enum_value, enum_cls)
+      return enum_value
+    except Exception as e:  # pylint: disable=broad-except
+      logging.debug("Could not auto-convert data '%s' to enum %s: %s", data,
+                    enum_cls, e)
+
+    for enum_instance in choices:
+      if data in (enum_instance, enum_instance.value):
+        return enum_instance
+    choices_str: str = ", ".join(repr(item.value) for item in choices)  # pytype: disable=missing-parameter
+    raise argparse.ArgumentTypeError(f"Unknown {label}: {repr(data)}.\n"
+                                     f"Choices are {choices_str}.")
+
+  @classmethod
+  def inline_hjson(cls, value: Any) -> Any:
+    value_str = cls.non_empty_str(value, "hjson")
+    if value_str[0] != "{" or value_str[-1] != "}":
+      raise argparse.ArgumentTypeError(
+          "Invalid inline hjson, missing braces: '{value_str}'")
+    try:
+      return hjson.loads(value_str)
+    except ValueError as e:
+      message = _extract_decoding_error("Could not decode inline hjson",
+                                        value_str, e)
+      if "eof" in message:
+        message += "\n   Likely missing quotes."
+      raise argparse.ArgumentTypeError(message) from e
+
+  @classmethod
+  def json_file(cls, value: pth.AnyPathLike) -> Any:
+    path = PathParser.file_path(value)
+    with path.open(encoding="utf-8") as f:
+      try:
+        return json.load(f)
+      except ValueError as e:
+        message = _extract_decoding_error(f"Invalid json file '{path}':", path,
+                                          e)
+        raise argparse.ArgumentTypeError(message) from e
+
+  @classmethod
+  def hjson_file(cls, value: pth.AnyPathLike) -> Any:
+    path = PathParser.file_path(value)
+    with path.open(encoding="utf-8") as f:
+      try:
+        return hjson.load(f)
+      except ValueError as e:
+        message = _extract_decoding_error("Invalid hjson file '{path}':", path,
+                                          e)
+        raise argparse.ArgumentTypeError(message) from e
+
+  @classmethod
+  def non_empty_hjson_file(cls, value: pth.AnyPathLike) -> Any:
+    data = cls.hjson_file(value)
+    if not data:
+      raise argparse.ArgumentTypeError(
+          "Expected hjson file with non-empty data, "
+          f"but got: {hjson.dumps(data)}")
+    return data
+
+  @classmethod
+  def dict_hjson_file(cls, value: pth.AnyPathLike) -> Any:
+    data = cls.non_empty_hjson_file(value)
+    if not isinstance(data, dict):
+      raise argparse.ArgumentTypeError(
+          "Expected object in hjson config '{value}', "
+          f"but got {type_str(data)}: {repr(data)}")
+    return data
+
+  @classmethod
+  def dict(cls, value: Any, name: str = "value") -> Dict:
+    if isinstance(value, dict):
+      return value
+    raise argparse.ArgumentTypeError(
+        f"Expected dict, but {name} is {type_str(value)}: {repr(value)}")
+
+  @classmethod
+  def non_empty_dict(cls, value: Any, name: str = "value") -> Dict:
+    dict_value = cls.dict(value)
+    if not dict_value:
+      raise argparse.ArgumentTypeError(
+          f"Expected {name} to be a non-empty dict.")
+    return dict_value
+
+  @classmethod
+  def sequence(cls, value: Any, name: str = "value") -> Sequence[Any]:
+    if isinstance(value, (list, tuple)):
+      return value
+    raise argparse.ArgumentTypeError(
+        f"Expected sequence, but {name} is {type_str(value)}: {repr(value)}")
+
+  @classmethod
+  def non_empty_sequence(cls, value: Any, name: str = "value") -> Sequence[Any]:
+    sequence_value = cls.sequence(value)
+    if not sequence_value:
+      raise argparse.ArgumentTypeError(
+          f"Expected {name} to be a non-empty sequence.")
+    return sequence_value
+
+  @classmethod
+  def any_str(cls, value: Any, name: str = "value") -> str:
+    value = cls.not_none(value, name)
+    if isinstance(value, str):
+      return value
+    raise argparse.ArgumentTypeError(
+        f"Expected str, but got {type_str(value)}: {value}")
+
+  @classmethod
+  def non_empty_str(cls, value: Any, name: str = "value") -> str:
+    value = cls.any_str(value, name)
+    if not isinstance(value, str):
+      raise argparse.ArgumentTypeError(
+          f"Expected non-empty string {name}, "
+          f"but got {type_str(value)}: {repr(value)}")
+    if not value:
+      raise argparse.ArgumentTypeError(f"Non-empty string {name} expected.")
+    return value
+
+  @classmethod
+  def url_str(cls,
+              value: str,
+              name: str = "url",
+              schemes: Optional[Sequence[str]] = None) -> str:
+    cls.url(value, name, schemes)
+    return value
+
+  @classmethod
+  def httpx_url_str(cls, value: Any, name: str = "url") -> str:
+    cls.url(value, name, schemes=("http", "https"))
+    return value
+
+  @classmethod
+  def base_url(cls, value: str, name: str = "url") -> urlparse.ParseResult:
+    url_str: str = cls.non_empty_str(value, name)
+    try:
+      return urlparse.urlparse(url_str)
+    except ValueError as e:
+      raise argparse.ArgumentTypeError(
+          f"Invalid {name}: {repr(value)}, {e}") from e
+
+  PORT_URL_PATH_RE = re.compile(r"^[0-9]+(?:/|$)")
+
+  @classmethod
+  def parse_fuzzy_url_str(cls,
+                          value: str,
+                          name: str = "url",
+                          schemes: Sequence[str] = ("http", "https", "about",
+                                                    "file"),
+                          default_scheme: str = "https") -> str:
+    parsed = cls.parse_fuzzy_url(value, name, schemes, default_scheme)
+    return urlparse.urlunparse(parsed)
+
+  @classmethod
+  def parse_fuzzy_url(cls,
+                      value: str,
+                      name: str = "url",
+                      schemes: Sequence[str] = ("http", "https", "about",
+                                                "file"),
+                      default_scheme: str = "https") -> urlparse.ParseResult:
+    assert default_scheme, "missing default scheme value"
+    value = cls.non_empty_str(value, name)
+    if PathParser.PATH_PREFIX.match(value):
+      value = f"file://{value}"
+    else:
+      parsed = cls.base_url(value)
+      if not parsed.scheme:
+        value = f"{default_scheme}://{value}"
+      # Check if this was a url without a scheme but with ports, which gets
+      # "wrongly" parsed and the host ends up in result.scheme and port and path
+      # are merged into result.path.
+      if parsed.scheme not in schemes and not parsed.netloc:
+        if cls.PORT_URL_PATH_RE.match(parsed.path):
+          # foo.com:8080/test => https://foo.com:8080/test
+          value = f"{default_scheme}://{value}"
+      schemes = tuple(schemes) + (default_scheme,)
+    return cls.url(value, name, schemes)
+
+  @classmethod
+  def url(cls,
+          value: str,
+          name: str = "url",
+          schemes: Optional[Sequence[str]] = None) -> urlparse.ParseResult:
+    parsed = cls.base_url(value)
+    try:
+      scheme = parsed.scheme
+      if schemes and scheme not in schemes:
+        schemes_str = ",".join(map(repr, schemes))
+        raise argparse.ArgumentTypeError(
+            f"Invalid {name}: Expected scheme to be one of {schemes_str}, "
+            f"but got {repr(parsed.scheme)} for url {repr(value)}")
+      if port := parsed.port:
+        _ = NumberParser.port_number(port, f"{name} port")
+      if scheme in ("file", "about"):
+        return parsed
+      hostname = parsed.hostname
+      if not hostname:
+        raise argparse.ArgumentTypeError(
+            f"Missing hostname in {name}: {repr(value)}")
+      if " " in hostname:
+        raise argparse.ArgumentTypeError(
+            f"Hostname in {name} contains invalid space: {repr(value)}")
+    except ValueError as e:
+      # Some ParseResult properties trigger errors, wrap all of them
+      raise argparse.ArgumentTypeError(
+          f"Invalid {name}: {repr(value)}, {e}") from e
+    return parsed
+
+  @classmethod
+  def bool(cls, value: Any, name: str = "value") -> bool:
+    if isinstance(value, bool):
+      return value
+    value = str(value).lower()
+    if value == "true":
+      return True
+    if value == "false":
+      return False
+    raise argparse.ArgumentTypeError(
+        f"Expected bool {name} but got {type_str(value)}: {repr(value)}")
+
+
+  @classmethod
+  def not_none(cls, value: Optional[NotNoneT], name: str = "value") -> NotNoneT:
+    if value is None:
+      raise argparse.ArgumentTypeError(f"Expected {name} to be not None.")
+    return value
+
+  @classmethod
+  def sh_cmd(cls, value: Any) -> List[str]:
+    value = cls.not_none(value, "shell cmd")
+    if not value:
+      raise argparse.ArgumentTypeError(
+          f"Expected non-empty shell cmd, but got: {value}")
+    if isinstance(value, (list, tuple)):
+      for i, part in enumerate(value):
+        cls.non_empty_str(part, f"cmd[{i}]")
+      return list(value)
+    if not isinstance(value, str):
+      raise argparse.ArgumentTypeError(
+          f"Expected string or list, but got {type_str(value)}: {value}")
+    try:
+      return shlex.split(value)
+    except ValueError as e:
+      raise argparse.ArgumentTypeError(f"Invalid shell cmd: {value} ") from e
+
+  @classmethod
+  def unique_sequence(
+      cls,
+      value: SequenceT,
+      name: str = "sequence",
+      error_cls: Type[Exception] = argparse.ArgumentTypeError) -> SequenceT:
+    unique = set()
+    duplicates = set()
+    for item in value:
+      if item in unique:
+        duplicates.add(item)
+      else:
+        unique.add(item)
+    if not duplicates:
+      return value
+    raise error_cls(f"Unexpected duplicates in {name}: {repr(duplicates)}")
+
+  @classmethod
+  def regexp(cls, value: Any, name: str = "regexp") -> re.Pattern:
+    try:
+      return re.compile(cls.any_str(value, name))
+    except re.error as e:
+      raise argparse.ArgumentTypeError(f"Invalid regexp {name}: {value}") from e
+
+
+_MAX_LEN = 70
+
+
+def _extract_decoding_error(message: str, value: pth.AnyPathLike,
+                            e: ValueError) -> str:
+  lineno = getattr(e, "lineno", -1) - 1
+  colno = getattr(e, "colno", -1) - 1
+  if lineno < 0 or colno < 0:
+    if isinstance(value, pth.LocalPath):
+      return f"{message}\n    {str(e)}"
+    return f"{message}: {value}\n    {str(e)}"
+  if isinstance(value, pth.AnyPath):
+    with pth.LocalPath(value).open(encoding="utf-8") as f:
+      line = f.readlines()[lineno]
+  else:
+    line = value.splitlines()[lineno]
+  if len(line) > _MAX_LEN:
+    # Only show line around error:
+    start = colno - _MAX_LEN // 2
+    end = colno + _MAX_LEN // 2
+    prefix = "..."
+    suffix = "..."
+    if start < 0:
+      start = 0
+      end = _MAX_LEN
+      prefix = ""
+    elif end > len(line):
+      end = len(line)
+      start = len(line) - _MAX_LEN
+      suffix = ""
+    colno -= start
+    line = prefix + line[start:end] + suffix
+    marker_space = (" " * len(prefix)) + (" " * colno)
+  else:
+    marker_space = " " * colno
+  marker = "__"
+  # Adjust line to be aligned with marker size
+  line = (" " * (len(marker) // 2)) + line
+  return f"{message}\n    {line}\n    {marker_space}{marker}\n({str(e)})"
+
+
+class NumberParser:
+
+  @classmethod
+  def any_float(cls, value: Any, name: str = "float") -> float:
+    try:
+      return float(value)
+    except ValueError as e:
+      raise argparse.ArgumentTypeError(f"Invalid {name}: {repr(value)}") from e
+
+  @classmethod
+  def positive_zero_float(cls, value: Any, name: str = "float") -> float:
+    value_f = cls.any_float(value, name)
+    if not math.isfinite(value_f) or value_f < 0:
+      raise argparse.ArgumentTypeError(
+          f"Expected {name} >= 0, but got: {value_f}")
+    return value_f
+
+  @classmethod
+  def any_int(cls, value: Any, name: str = "value") -> int:
+    try:
+      return int(value)
+    except ValueError as e:
+      raise argparse.ArgumentTypeError(
+          f"Invalid integer {name}: {repr(value)}") from e
+
+  @classmethod
+  def positive_zero_int(cls, value: Any, name: str = "value") -> int:
+    value_i = cls.any_int(value, name)
+    if value_i < 0:
+      raise argparse.ArgumentTypeError(
+          f"Expected integer {name} >= 0, but got: {value_i}")
+    return value_i
+
+  @classmethod
+  def positive_int(cls, value: Any, name: str = "value") -> int:
+    value_i = cls.any_int(value, name)
+    if not math.isfinite(value_i) or value_i <= 0:
+      raise argparse.ArgumentTypeError(
+          f"Expected integer {name} > 0, but got: {value_i}")
+    return value_i
+
+  @classmethod
+  def port_number(cls, value: Any, name: str = "port") -> int:
+    port = cls.any_int(value, name)
+    if 1 <= port <= 65535:
+      return port
+    raise argparse.ArgumentTypeError(
+        f"Invalid Port: expected 1 <= {name} <= 65535, but got: {repr(port)}")
+
+
+class LateArgumentError(argparse.ArgumentTypeError):
+  """Signals argument parse errors after parser.parse_args().
+  This is used to map errors back to the original argument, much like
+  argparse.ArgumentError does internally. However, since this happens after
+  the internal argument parsing we need this custom implementation to print
+  more descriptive error messages.
+  """
+
+  def __init__(self, flag: str, message: str) -> None:
+    super().__init__(message)
+    self.flag = flag
+    self.message = message
+
+
+class DurationParseError(argparse.ArgumentTypeError):
+  pass
+
+
+class DurationParser:
+
+  @classmethod
+  def help(cls) -> str:
+    return "'12.5' == '12.5s',  units=['ms', 's', 'm', 'h']"
+
+  _DURATION_RE: Final[re.Pattern] = re.compile(
+      r"(?P<value>(-?\d+(\.\d+)?)) ?(?P<unit>[a-z]+)?")
+
+  @classmethod
+  def _to_timedelta(cls, value: float, suffix: str) -> dt.timedelta:
+    if suffix in {"ms", "millis", "milliseconds"}:
+      return dt.timedelta(milliseconds=value)
+    if suffix in {"s", "sec", "secs", "second", "seconds"}:
+      return dt.timedelta(seconds=value)
+    if suffix in {"m", "min", "mins", "minute", "minutes"}:
+      return dt.timedelta(minutes=value)
+    if suffix in {"h", "hrs", "hour", "hours"}:
+      return dt.timedelta(hours=value)
+    raise DurationParseError(f"Error: {suffix} is not supported for duration. "
+                             "Make sure to use a supported time unit/suffix")
+
+  @classmethod
+  def positive_duration(cls,
+                        time_value: Any,
+                        name: str = "duration") -> dt.timedelta:
+    duration: dt.timedelta = cls.any_duration(time_value)
+    if duration.total_seconds() <= 0:
+      raise DurationParseError(f"Expected non-zero {name}, but got {duration}")
+    return duration
+
+  @classmethod
+  def positive_or_zero_duration(cls,
+                                time_value: Any,
+                                name: str = "duration") -> dt.timedelta:
+    duration: dt.timedelta = cls.any_duration(time_value, name)
+    if duration.total_seconds() < 0:
+      raise DurationParseError(f"Expected positive {name}, but got {duration}")
+    return duration
+
+  @classmethod
+  def any_duration(cls,
+                   time_value: Any,
+                   name: str = "duration") -> dt.timedelta:
+    """
+    This function will parse the measurement and the value from string value.
+
+    For example:
+    5s => dt.timedelta(seconds=5)
+    5m => 5*60 = dt.timedelta(minutes=5)
+
+    """
+    if isinstance(time_value, dt.timedelta):
+      return time_value
+    if isinstance(time_value, (int, float)):
+      return dt.timedelta(seconds=time_value)
+    if not time_value:
+      raise DurationParseError(f"Expected non-empty {name} value.")
+    if not isinstance(time_value, str):
+      raise DurationParseError(
+          f"Unexpected {type_str(time_value)} for {name}: {time_value}")
+
+    match = cls._DURATION_RE.fullmatch(time_value)
+    if match is None:
+      raise DurationParseError(f"Unknown {name} format: '{time_value}'")
+
+    value = match.group("value")
+    if not value:
+      raise DurationParseError(
+          f"Error: {name} value not found."
+          f"Make sure to include a valid {name} value: '{time_value}'")
+    time_unit = match.group("unit")
+    try:
+      time_value = float(value)
+    except ValueError as e:
+      raise DurationParseError(f"{name} must be a valid number, {e}") from e
+    if not math.isfinite(time_value):
+      raise DurationParseError(f"{name} must be finite, but got: {time_value}")
+
+    if not time_unit:
+      # If no time unit provided we assume it is in seconds.
+      return dt.timedelta(seconds=time_value)
+    return cls._to_timedelta(time_value, time_unit)
diff --git a/crossbench/path.py b/crossbench/path.py
new file mode 100644
index 0000000..6b8e1b7
--- /dev/null
+++ b/crossbench/path.py
@@ -0,0 +1,44 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import pathlib
+import re
+import unicodedata
+from typing import Optional, Union
+
+# A path that can refer to files on a remote platform with potentially
+# a different Path flavour (e.g. Win vs Posix).
+AnyPath = pathlib.PurePath
+AnyPosixPath = pathlib.PurePosixPath
+AnyWindowsPath = pathlib.PureWindowsPath
+
+AnyPathLike = Union[str, AnyPath]
+
+# A path that only ever refers to files on the local host / runner platform.
+# Not that Path inherits from PurePath, and thus we can use a LocalPath in
+# all places a RemotePath is expected.
+LocalPath = pathlib.Path
+LocalPosixPath = pathlib.PosixPath
+
+LocalPathLike = Union[str, LocalPath]
+
+_UNSAFE_FILENAME_CHARS_RE = re.compile(r"[^a-zA-Z0-9+\-_.]")
+
+
+def safe_filename(name: str) -> str:
+  normalized_name = unicodedata.normalize("NFKD", name)
+  ascii_name = normalized_name.encode("ascii", "ignore").decode("ascii")
+  return _UNSAFE_FILENAME_CHARS_RE.sub("_", ascii_name)
+
+
+def try_resolve_existing_path(value: str) -> Optional[LocalPath]:
+  if not value:
+    return None
+  maybe_path = LocalPath(value)
+  if maybe_path.exists():
+    return maybe_path
+  maybe_path = maybe_path.expanduser()
+  if maybe_path.exists():
+    return maybe_path
+  return None
diff --git a/crossbench/plt/__init__.py b/crossbench/plt/__init__.py
new file mode 100644
index 0000000..953acdf
--- /dev/null
+++ b/crossbench/plt/__init__.py
@@ -0,0 +1,28 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import sys
+from typing import Final
+
+from crossbench.plt.arch import MachineArch
+from crossbench.plt.base import Platform, SubprocessError, TupleCmdArgs
+from crossbench.plt.linux import LinuxPlatform
+from crossbench.plt.linux_ssh import LinuxSshPlatform
+from crossbench.plt.macos import MacOSPlatform
+from crossbench.plt.win import WinPlatform
+
+
+def _get_default() -> Platform:
+  if sys.platform == "linux":
+    return LinuxPlatform()
+  if sys.platform == "darwin":
+    return MacOSPlatform()
+  if sys.platform == "win32":
+    return WinPlatform()
+  raise NotImplementedError(f"Unsupported platform: {sys.platform}")
+
+
+PLATFORM: Final[Platform] = _get_default()
diff --git a/crossbench/plt/android_adb.py b/crossbench/plt/android_adb.py
new file mode 100644
index 0000000..b66ad2c
--- /dev/null
+++ b/crossbench/plt/android_adb.py
@@ -0,0 +1,694 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import functools
+import logging
+import re
+import shlex
+import subprocess
+from typing import TYPE_CHECKING, Any, Dict, List, Mapping, Optional, Tuple
+
+from crossbench import path as pth
+from crossbench.parse import PathParser
+from crossbench.plt.arch import MachineArch
+from crossbench.plt.posix import RemotePosixPlatform
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import CmdArg, ListCmdArgs, Platform
+  from crossbench.types import JsonDict
+
+
+def _find_adb_bin(platform: Platform) -> pth.AnyPath:
+  adb_bin = platform.search_platform_binary(
+      name="adb",
+      macos=["adb", "~/Library/Android/sdk/platform-tools/adb"],
+      linux=["adb"],
+      win=["adb.exe", "Android/sdk/platform-tools/adb.exe"])
+  if adb_bin:
+    return adb_bin
+  raise ValueError(
+      "Could not find adb binary."
+      "See https://developer.android.com/tools/adb fore more details.")
+
+
+def adb_devices(
+    platform: Platform,
+    adb_bin: Optional[pth.AnyPath] = None) -> Dict[str, Dict[str, str]]:
+  adb_bin = adb_bin or _find_adb_bin(platform)
+  output = platform.sh_stdout(adb_bin, "devices", "-l")
+  raw_lines = output.strip().splitlines()[1:]
+  result: Dict[str, Dict[str, str]] = {}
+  for line in raw_lines:
+    serial_id, details = line.split(" ", maxsplit=1)
+    result[serial_id.strip()] = _parse_adb_device_info(details.strip())
+  return result
+
+
+def _parse_adb_device_info(value: str) -> Dict[str, str]:
+  parts = value.split(" ")
+  assert parts[0], "device"
+  return dict(part.split(":") for part in parts[1:])
+
+
+class Adb:
+
+  _serial_id: str
+  _device_info: Dict[str, str]
+  _adb_bin: pth.AnyPath
+
+  def __init__(self,
+               host_platform: Platform,
+               device_identifier: Optional[str] = None,
+               adb_bin: Optional[pth.AnyPath] = None) -> None:
+    self._host_platform = host_platform
+    if adb_bin:
+      self._adb_bin = PathParser.binary_path(adb_bin, platform=host_platform)
+    else:
+      self._adb_bin = _find_adb_bin(host_platform)
+    self.start_server()
+    self._serial_id, self._device_info = self._find_serial_id(device_identifier)
+    logging.debug("ADB Selected device: %s %s", self._serial_id,
+                  self._device_info)
+    assert self._serial_id
+
+  def _find_serial_id(
+      self,
+      device_identifier: Optional[str] = None) -> Tuple[str, Dict[str, str]]:
+    devices = self.devices()
+    if not devices:
+      raise ValueError("adb could not find any attached devices."
+                       "Connect your device and use 'adb devices' to list all.")
+    if device_identifier is None:
+      if len(devices) != 1:
+        raise ValueError(
+            f"Too many adb devices attached, please specify one of: {devices}")
+      device_identifier = list(devices.keys())[0]
+    if not device_identifier:
+      raise ValueError(f"Invalid device identifier: {repr(device_identifier)}")
+    if device_identifier in devices:
+      return device_identifier, devices[device_identifier]
+    matches: List[str] = []
+    under_name = device_identifier.replace(" ", "_")
+    for key, device_info in devices.items():
+      for _, info_value in device_info.items():
+        if device_identifier in info_value or (under_name in info_value):
+          matches.append(key)
+    if not matches:
+      raise ValueError(
+          f"Could not find adb device matching: '{device_identifier}'")
+    if len(matches) > 1:
+      raise ValueError(
+          f"Found {len(matches)} adb devices matching: '{device_identifier}'.\n"
+          f"Choices: {matches}")
+    return matches[0], devices[matches[0]]
+
+  def __str__(self) -> str:
+    info = f"info='{self._device_info}'"
+    if model := self._device_info.get("model"):
+      info = f"model={repr(model)}"
+    return f"adb(device_id={repr(self._serial_id)}, {info})"
+
+  def has_root(self) -> bool:
+    return self.shell_stdout("id").startswith("uid=0(root)")
+
+  def path(self, path: pth.AnyPathLike) -> pth.AnyPath:
+    return pth.AnyPosixPath(path)
+
+  @property
+  def serial_id(self) -> str:
+    return self._serial_id
+
+  @functools.cached_property
+  def build_version(self) -> int:
+    return int(self.getprop("ro.build.version.release"))
+
+  @property
+  def device_info(self) -> Dict[str, str]:
+    return self._device_info
+
+  def popen(self,
+            *args: CmdArg,
+            bufsize=-1,
+            shell: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False) -> subprocess.Popen:
+    del shell
+    assert not env, "ADB does not support setting env vars."
+    if not quiet:
+      logging.debug("SHELL: %s", shlex.join(map(str, args)))
+    adb_cmd: ListCmdArgs = [self._adb_bin, "-s", self._serial_id, "shell"]
+    adb_cmd.extend(args)
+    return self._host_platform.popen(
+        *adb_cmd, bufsize=bufsize, stdout=stdout, stderr=stderr, stdin=stdin)
+
+  def _adb(self,
+           *args: CmdArg,
+           shell: bool = False,
+           capture_output: bool = False,
+           stdout=None,
+           stderr=None,
+           stdin=None,
+           env: Optional[Mapping[str, str]] = None,
+           quiet: bool = False,
+           check: bool = True,
+           use_serial_id: bool = True) -> subprocess.CompletedProcess:
+    del shell
+    adb_cmd: ListCmdArgs = []
+    if use_serial_id:
+      adb_cmd = [self._adb_bin, "-s", self._serial_id]
+    else:
+      adb_cmd = [self._adb_bin]
+    adb_cmd.extend(args)
+    return self._host_platform.sh(
+        *adb_cmd,
+        capture_output=capture_output,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet,
+        check=check)
+
+  def _adb_stdout(self,
+                  *args: CmdArg,
+                  quiet: bool = False,
+                  stdin=None,
+                  encoding: str = "utf-8",
+                  use_serial_id: bool = True,
+                  check: bool = True) -> str:
+    result = self._adb_stdout_bytes(
+        *args,
+        quiet=quiet,
+        stdin=stdin,
+        use_serial_id=use_serial_id,
+        check=check)
+    return result.decode(encoding)
+
+  def _adb_stdout_bytes(self,
+                        *args: CmdArg,
+                        quiet: bool = False,
+                        stdin=None,
+                        use_serial_id: bool = True,
+                        check: bool = True) -> bytes:
+    adb_cmd: ListCmdArgs = []
+    if use_serial_id:
+      adb_cmd = [self._adb_bin, "-s", self._serial_id]
+    else:
+      adb_cmd = [self._adb_bin]
+    adb_cmd.extend(args)
+    return self._host_platform.sh_stdout_bytes(
+        *adb_cmd, quiet=quiet, check=check, stdin=stdin)
+
+  def shell_stdout(self,
+                   *args: CmdArg,
+                   quiet: bool = False,
+                   encoding: str = "utf-8",
+                   stdin=None,
+                   env: Optional[Mapping[str, str]] = None,
+                   check: bool = True) -> str:
+    result = self.shell_stdout_bytes(
+        *args, quiet=quiet, stdin=stdin, env=env, check=check)
+    return result.decode(encoding)
+
+  def shell_stdout_bytes(self,
+                         *args: CmdArg,
+                         quiet: bool = False,
+                         stdin=None,
+                         env: Optional[Mapping[str, str]] = None,
+                         check: bool = True) -> bytes:
+    # -e: choose escape character, or "none"; default '~'
+    # -n: don't read from stdin
+    # -T: disable pty allocation
+    # -t: allocate a pty if on a tty (-tt: force pty allocation)
+    # -x: disable remote exit codes and stdout/stderr separation
+    if env:
+      raise ValueError("ADB shell only supports an empty env for now.")
+    #Need to escape spaces in args for adb shell
+    str_args = map(lambda x: str(x).replace(" ", "\\ "), args)
+    return self._adb_stdout_bytes(
+        "shell", *str_args, stdin=stdin, quiet=quiet, check=check)
+
+  def shell(self,
+            *args: CmdArg,
+            shell: bool = False,
+            capture_output: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False,
+            check: bool = True) -> subprocess.CompletedProcess:
+    # See shell_stdout for more `adb shell` options.
+    adb_cmd: ListCmdArgs = ["shell", *args]
+    return self._adb(
+        *adb_cmd,
+        shell=shell,
+        capture_output=capture_output,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet,
+        check=check)
+
+  def start_server(self) -> None:
+    self._adb_stdout("start-server", use_serial_id=False)
+
+  def stop_server(self) -> None:
+    self.kill_server()
+
+  def kill_server(self) -> None:
+    self._adb_stdout("kill-server", use_serial_id=False)
+
+  def devices(self) -> Dict[str, Dict[str, str]]:
+    return adb_devices(self._host_platform, self._adb_bin)
+
+  def forward(self, local: int, remote: int, protocol: str = "tcp") -> int:
+    stdout = self._adb_stdout(
+        "forward", f"{protocol}:{local}", f"{protocol}:{remote}")
+    return int(stdout)
+
+  def forward_remove(self, local: int, protocol: str = "tcp") -> None:
+    self._adb("forward", "--remove", f"{protocol}:{local}")
+
+  def reverse(self, remote: int, local: int, protocol: str = "tcp") -> int:
+    stdout = self._adb_stdout(
+        "reverse", f"{protocol}:{remote}", f"{protocol}:{local}")
+    return int(stdout)
+
+  def reverse_remove(self, remote: int, protocol: str = "tcp") -> None:
+    self._adb("reverse", "--remove", f"{protocol}:{remote}")
+
+  def pull(self, device_src_path: pth.AnyPath,
+           local_dest_path: pth.LocalPath) -> None:
+    self._adb("pull", self.path(device_src_path), local_dest_path)
+
+  def push(self, local_src_path: pth.LocalPath,
+           device_dest_path: pth.AnyPath) -> None:
+    self._adb("push", local_src_path, self.path(device_dest_path))
+
+  def cmd(self,
+          *args: str,
+          quiet: bool = False,
+          encoding: str = "utf-8") -> str:
+    cmd: ListCmdArgs = ["cmd", *args]
+    return self.shell_stdout(*cmd, quiet=quiet, encoding=encoding)
+
+  def dumpsys(self,
+              *args: str,
+              quiet: bool = False,
+              encoding: str = "utf-8") -> str:
+    cmd: ListCmdArgs = ["dumpsys", *args]
+    return self.shell_stdout(*cmd, quiet=quiet, encoding=encoding)
+
+  def getprop(self,
+              *args: str,
+              quiet: bool = False,
+              encoding: str = "utf-8") -> str:
+    cmd: ListCmdArgs = ["getprop", *args]
+    return self.shell_stdout(*cmd, quiet=quiet, encoding=encoding).strip()
+
+  def services(self, quiet: bool = False, encoding: str = "utf-8") -> List[str]:
+    lines = list(
+        self.cmd("-l", quiet=quiet, encoding=encoding).strip().splitlines())
+    lines = lines[1:]
+    lines.sort()
+    return [line.strip() for line in lines]
+
+  def packages(self, quiet: bool = False, encoding: str = "utf-8") -> List[str]:
+    # adb shell cmd package list packages
+    raw_list = self.cmd(
+        "package", "list", "packages", quiet=quiet,
+        encoding=encoding).strip().splitlines()
+    packages = [package.split(":", maxsplit=2)[1] for package in raw_list]
+    packages.sort()
+    return packages
+
+  def force_stop(self, package_name: str) -> None:
+    if not package_name:
+      raise ValueError("Got empty package name")
+    self.shell("am", "force-stop", package_name)
+
+  def force_clear(self, package_name: str) -> None:
+    if not package_name:
+      raise ValueError("Got empty package name")
+    cmd: ListCmdArgs = ["pm", "clear"]
+    if self.build_version >= 14:
+      user = self.cmd("user", "get-main-user").strip()
+      cmd.extend(["--user", user])
+    cmd.extend([package_name])
+    self.shell(*cmd)
+
+  def install(self,
+              bundle: pth.LocalPath,
+              allow_downgrade: bool = False,
+              modules: Optional[str] = None) -> None:
+    if bundle.suffix == ".apks":
+      self.install_apks(bundle, allow_downgrade, modules)
+    if bundle.suffix == ".apk":
+      self.install_apk(bundle, allow_downgrade)
+
+  def install_apk(self,
+                  apk: pth.LocalPath,
+                  allow_downgrade: bool = False) -> None:
+    if not apk.exists():
+      raise ValueError(f"APK {apk} does not exist.")
+    args = ["install"]
+    if allow_downgrade:
+      args.append("-d")
+    args.append(str(apk))
+    self._adb(*args)
+
+  def install_apks(self,
+                   apks: pth.LocalPath,
+                   allow_downgrade: bool = False,
+                   modules: Optional[str] = None) -> None:
+    if not apks.exists():
+      raise ValueError(f"APK {apks} does not exist.")
+    cmd = [
+        "bundletool",
+        "install-apks",
+        f"--apks={apks}",
+        f"--device-id={self._serial_id}",
+    ]
+    if allow_downgrade:
+      cmd.append("--allow-downgrade")
+    if modules:
+      cmd.append(f"--modules={modules}")
+    self._host_platform.sh(*cmd)
+
+  def uninstall(self, package_name: str, missing_ok: bool = False) -> None:
+    if not package_name:
+      raise ValueError("Got empty package name")
+    try:
+      self._adb("uninstall", package_name)
+    except Exception as e:  # pylint: disable=broad-except
+      if missing_ok:
+        logging.debug("Could not uninstall %s: %s", package_name, e)
+      else:
+        raise
+
+  def grant_notification_permissions(self, package_name: str) -> None:
+    if self.build_version < 13:
+      # Notification permission setting is needed for Android 13 and above.
+      # https://developer.android.com/develop/ui/views/notifications/notification-permission  # pylint: disable=line-too-long
+      return
+    if not package_name:
+      raise ValueError("Got empty package name")
+    cmd: ListCmdArgs = ["pm", "grant"]
+    if self.build_version >= 14:
+      user = self.cmd("user", "get-main-user").strip()
+      cmd.extend(["--user", user])
+    cmd.extend([package_name, "android.permission.POST_NOTIFICATIONS"])
+    self.shell(*cmd)
+
+
+class AndroidAdbPlatform(RemotePosixPlatform):
+
+  def __init__(self,
+               host_platform: Platform,
+               device_identifier: Optional[str] = None,
+               adb: Optional[Adb] = None) -> None:
+    super().__init__(host_platform)
+    self._system_details: Optional[Dict[str, Any]] = None
+    self._cpu_details: Optional[Dict[str, Any]] = None
+    assert not host_platform.is_remote, (
+        "adb on remote platform is not supported yet")
+    self._adb = adb or Adb(host_platform, device_identifier)
+
+  @property
+  def is_android(self) -> bool:
+    return True
+
+  @property
+  def name(self) -> str:
+    return "android"
+
+  @functools.cached_property
+  def version(self) -> str:  #pylint: disable=invalid-overridden-method
+    return str(self.adb.build_version)
+
+  @functools.cached_property
+  def device(self) -> str:  #pylint: disable=invalid-overridden-method
+    return self.adb.getprop("ro.product.model")
+
+  @property
+  def serial_id(self):
+    return self._adb.serial_id
+
+  @functools.cached_property
+  def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
+    variant = self.adb.getprop("dalvik.vm.isa.arm.variant")
+    platform = self.adb.getprop("ro.board.platform")
+    cpu_str = f"{variant} {platform}"
+    if cores_info := self._get_cpu_cores_info():
+      cpu_str = f"{cpu_str} {cores_info}"
+    return cpu_str
+
+  @property
+  def adb(self) -> Adb:
+    return self._adb
+
+  _MACHINE_ARCH_LOOKUP = {
+      "arm64-v8a": MachineArch.ARM_64,
+      "armeabi-v7a": MachineArch.ARM_32,
+      "x86": MachineArch.IA32,
+      "x86_64": MachineArch.X64,
+  }
+
+  @functools.cached_property
+  def machine(self) -> MachineArch:  #pylint: disable=invalid-overridden-method
+    cpu_abi = self.adb.getprop("ro.product.cpu.abi")
+    arch = self._MACHINE_ARCH_LOOKUP.get(cpu_abi, None)
+    if not arch:
+      raise ValueError(f"Unknown android CPU ABI: {cpu_abi}")
+    return arch
+
+  def app_path_to_package(self, app_path: pth.AnyPathLike) -> str:
+    path = self.path(app_path)
+    if len(path.parts) > 1:
+      raise ValueError(f"Invalid android package name: '{path}'")
+    package: str = path.parts[0]
+    packages = self.adb.packages()
+    if package not in packages:
+      raise ValueError(f"Package '{package}' is not installed on {self._adb}")
+    return package
+
+  def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    app_or_bin_path = self.path(app_or_bin)
+    if not app_or_bin_path.parts:
+      raise ValueError("Got empty path")
+    if result_path := self.which(app_or_bin_path):
+      return result_path
+    if str(app_or_bin) in self.adb.packages():
+      return app_or_bin_path
+    return None
+
+  def home(self) -> pth.AnyPath:
+    raise RuntimeError("Cannot access home dir on (non-rooted) android device")
+
+  _VERSION_NAME_RE = re.compile(r"versionName=(?P<version>.+)")
+
+  def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
+    # adb shell dumpsys package com.chrome.canary | grep versionName -C2
+    package = self.app_path_to_package(app_or_bin)
+    package_info = self.adb.dumpsys("package", str(package))
+    match_result = self._VERSION_NAME_RE.search(package_info)
+    if match_result is None:
+      raise ValueError(
+          f"Could not find version for '{package}': {package_info}")
+    return match_result.group("version")
+
+  def process_children(self,
+                       parent_pid: int,
+                       recursive: bool = False) -> List[Dict[str, Any]]:
+    # TODO: implement
+    return []
+
+  def foreground_process(self) -> Optional[Dict[str, Any]]:
+    # adb shell dumpsys activity activities
+    # TODO: implement
+    return None
+
+  def get_relative_cpu_speed(self) -> float:
+    # TODO figure out
+    return 1.0
+
+  def python_details(self) -> JsonDict:
+    # Python is not available on android.
+    return {}
+
+  def os_details(self) -> JsonDict:
+    # TODO: add more info
+    return {"version": self.version}
+
+  def check_autobrightness(self) -> bool:
+    # adb shell dumpsys display
+    # TODO: implement.
+    return True
+
+  _BRIGHTNESS_RE = re.compile(
+      r"mLatestFloatBrightness=(?P<brightness>[0-9]+\.[0-9]+)")
+
+  def get_main_display_brightness(self) -> int:
+    display_info: str = self.adb.shell_stdout("dumpsys", "display")
+    match_result = self._BRIGHTNESS_RE.search(display_info)
+    if match_result is None:
+      raise ValueError("Could not parse adb display brightness.")
+    return int(float(match_result.group("brightness")) * 100)
+
+  @property
+  def default_tmp_dir(self) -> pth.AnyPath:
+    return self.path("/data/local/tmp/")
+
+  def sh(self,
+         *args: CmdArg,
+         shell: bool = False,
+         capture_output: bool = False,
+         stdout=None,
+         stderr=None,
+         stdin=None,
+         env: Optional[Mapping[str, str]] = None,
+         quiet: bool = False,
+         check: bool = False) -> subprocess.CompletedProcess:
+    return self.adb.shell(
+        *args,
+        shell=shell,
+        capture_output=capture_output,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet,
+        check=check)
+
+  def sh_stdout_bytes(self,
+                      *args: CmdArg,
+                      shell: bool = False,
+                      quiet: bool = False,
+                      stdin=None,
+                      env: Optional[Mapping[str, str]] = None,
+                      check: bool = True) -> bytes:
+    # The shell option is not supported on adb.
+    del shell
+    return self.adb.shell_stdout_bytes(
+        *args, stdin=stdin, env=env, quiet=quiet, check=check)
+
+  def popen(self,
+            *args: CmdArg,
+            bufsize=-1,
+            shell: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False) -> subprocess.Popen:
+    return self.adb.popen(
+        *args,
+        bufsize=bufsize,
+        shell=shell,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet)
+
+  def port_forward(self, local_port: int, remote_port: int) -> int:
+    return self.adb.forward(local_port, remote_port, protocol="tcp")
+
+  def stop_port_forward(self, local_port: int) -> None:
+    self.adb.forward_remove(local_port, protocol="tcp")
+
+  def reverse_port_forward(self, remote_port: int, local_port: int) -> int:
+    return self.adb.reverse(remote_port, local_port, protocol="tcp")
+
+  def stop_reverse_port_forward(self, remote_port: int) -> None:
+    self.adb.reverse_remove(remote_port, protocol="tcp")
+
+  def pull(self, from_path: pth.AnyPath,
+           to_path: pth.LocalPath) -> pth.LocalPath:
+    device_path = self.path(from_path)
+    if not self.exists(device_path):
+      raise ValueError(f"Source file '{from_path}' does not exist on {self}")
+    local_host_path = self.host_path(to_path)
+    local_host_path.parent.mkdir(parents=True, exist_ok=True)
+    self.adb.pull(device_path, local_host_path)
+    return to_path
+
+  def push(self, from_path: pth.LocalPath, to_path: pth.AnyPath) -> pth.AnyPath:
+    to_path = self.path(to_path)
+    self.adb.push(self.host_path(from_path), to_path)
+    return to_path
+
+  def processes(self,
+                attrs: Optional[List[str]] = None) -> List[Dict[str, Any]]:
+    lines = self.sh_stdout("ps", "-A", "-o", "PID,NAME").splitlines()
+    if len(lines) == 1:
+      return []
+
+    res: List[Dict[str, Any]] = []
+    for line in lines[1:]:
+      tokens = line.strip().split(maxsplit=1)
+      assert len(tokens) == 2, f"Got invalid process tokens: {tokens}"
+      res.append({"pid": int(tokens[0]), "name": tokens[1]})
+    return res
+
+  def cpu_details(self) -> Dict[str, Any]:
+    if self._cpu_details:
+      return self._cpu_details
+    # TODO: Implement properly (i.e. remove all n/a values)
+    self._cpu_details = {
+        "info": self.cpu,
+        "physical cores": "n/a",
+        "logical cores": "n/a",
+        "usage": "n/a",
+        "total usage": "n/a",
+        "system load": "n/a",
+        "max frequency": "n/a",
+        "min frequency": "n/a",
+        "current frequency": "n/a",
+    }
+    return self._cpu_details
+
+  _GETPROP_RE = re.compile(r"^\[(?P<key>[^\]]+)\]: \[(?P<value>[^\]]+)\]$")
+
+  def _getprop_system_details(self) -> Dict[str, Any]:
+    details = super().system_details()
+    properties: Dict[str, str] = {}
+    for line in self.adb.shell_stdout("getprop").strip().splitlines():
+      result = self._GETPROP_RE.fullmatch(line)
+      if result:
+        properties[result.group("key")] = result.group("value")
+    details["android"] = properties
+    return details
+
+  def system_details(self) -> Dict[str, Any]:
+    if self._system_details:
+      return self._system_details
+
+    # TODO: Implement properly (i.e. remove all n/a values)
+    self._system_details = {
+        "machine": self.sh_stdout("uname", "-m").split()[0],
+        "os": {
+            "system": self.sh_stdout("uname", "-s").split()[0],
+            "release": self.sh_stdout("uname", "-r").split()[0],
+            "version": self.sh_stdout("uname", "-v").split()[0],
+            "platform": "n/a",
+        },
+        "python": {
+            "version": "n/a",
+            "bits": "n/a",
+        },
+        "CPU": self.cpu_details(),
+        "Android": self._getprop_system_details(),
+    }
+    return self._system_details
+
+  def screenshot(self, result_path: pth.AnyPath) -> None:
+    self.sh("screencap", "-p", result_path)
diff --git a/crossbench/plt/arch.py b/crossbench/plt/arch.py
new file mode 100644
index 0000000..0162e6b
--- /dev/null
+++ b/crossbench/plt/arch.py
@@ -0,0 +1,38 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+
+
+class MachineArch(enum.Enum):
+  IA32 = ("ia32", "intel", 32)
+  X64 = ("x64", "intel", 64)
+  ARM_32 = ("arm32", "arm", 32)
+  ARM_64 = ("arm64", "arm", 64)
+
+  def __init__(self, name: str, arch: str, bits: int) -> None:
+    self.identifier = name
+    self.arch = arch
+    self.bits = bits
+
+  @property
+  def is_arm(self) -> bool:
+    return self.arch == "arm"
+
+  @property
+  def is_intel(self) -> bool:
+    return self.arch == "intel"
+
+  @property
+  def is_32bit(self) -> bool:
+    return self.bits == 32
+
+  @property
+  def is_64bit(self) -> bool:
+    return self.bits == 64
+
+  def __str__(self) -> str:
+    return self.identifier
diff --git a/crossbench/plt/base.py b/crossbench/plt/base.py
new file mode 100644
index 0000000..f10eb71
--- /dev/null
+++ b/crossbench/plt/base.py
@@ -0,0 +1,833 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import collections.abc
+import contextlib
+import datetime as dt
+import functools
+import inspect
+import logging
+import os
+import pathlib
+import platform as py_platform
+import shlex
+import shutil
+import subprocess
+import sys
+import tempfile
+import time
+import urllib.error
+import urllib.parse
+import urllib.request
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, Generator,
+                    Iterable, Iterator, List, Mapping, Optional, Sequence,
+                    Tuple, Union)
+
+import psutil
+
+from crossbench import path as pth
+from crossbench.plt.arch import MachineArch
+from crossbench.plt.bin import Binary
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+  from crossbench.types import JsonDict
+
+
+CmdArg = pth.AnyPathLike
+ListCmdArgs = List[CmdArg]
+TupleCmdArgs = Tuple[CmdArg, ...]
+CmdArgs = Union[ListCmdArgs, TupleCmdArgs]
+
+
+class Environ(collections.abc.MutableMapping, metaclass=abc.ABCMeta):
+  pass
+
+
+class LocalEnviron(Environ):
+
+  def __init__(self) -> None:
+    self._environ = os.environ
+
+  def __getitem__(self, key: str) -> str:
+    return self._environ.__getitem__(key)
+
+  def __setitem__(self, key: str, item: str) -> None:
+    self._environ.__setitem__(key, item)
+
+  def __delitem__(self, key: str) -> None:
+    self._environ.__delitem__(key)
+
+  def __iter__(self) -> Iterator[str]:
+    return self._environ.__iter__()
+
+  def __len__(self) -> int:
+    return self._environ.__len__()
+
+
+class SubprocessError(subprocess.CalledProcessError):
+  """ Custom version that also prints stderr for debugging"""
+
+  def __init__(self, platform: Platform, process) -> None:
+    self.platform = platform
+    super().__init__(process.returncode, shlex.join(map(str, process.args)),
+                     process.stdout, process.stderr)
+
+  def __str__(self) -> str:
+    super_str = super().__str__()
+    if not self.stderr:
+      return f"{self.platform}: {super_str}"
+    return f"{self.platform}: {super_str}\nstderr:{self.stderr.decode()}"
+
+
+_IGNORED_PROCESS_EXCEPTIONS: Final = (psutil.NoSuchProcess, psutil.AccessDenied,
+                                      psutil.ZombieProcess)
+
+DEFAULT_CACHE_DIR = pth.LocalPath(__file__).parents[2] / "cache"
+
+class Platform(abc.ABC):
+  # pylint: disable=locally-disabled, redefined-builtin
+
+  def __init__(self) -> None:
+    self._binary_lookup_override: Dict[str, pth.AnyPath] = {}
+    self._cache_dir: Optional[pth.AnyPath] = None
+    if self.is_local:
+      self._cache_dir = DEFAULT_CACHE_DIR
+
+  def assert_is_local(self) -> None:
+    if self.is_local:
+      return
+    caller = "assert_is_local"
+    caller = inspect.stack()[1].function
+    raise RuntimeError(f"{type(self).__name__}.{caller}(...) is not supported "
+                       "on remote platform")
+
+  @property
+  @abc.abstractmethod
+  def name(self) -> str:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def version(self) -> str:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def device(self) -> str:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def cpu(self) -> str:
+    pass
+
+  @property
+  def full_version(self) -> str:
+    return f"{self.name} {self.version} {self.machine}"
+
+  def __str__(self) -> str:
+    return ".".join(self.key) + (".remote" if self.is_remote else ".local")
+
+  @property
+  def is_remote(self) -> bool:
+    return False
+
+  @property
+  def is_local(self) -> bool:
+    return not self.is_remote
+
+  @property
+  def host_platform(self) -> Platform:
+    return self
+
+  @functools.cached_property
+  def machine(self) -> MachineArch:
+    raw = self._raw_machine_arch()
+    if raw in ("i386", "i686", "x86", "ia32"):
+      return MachineArch.IA32
+    if raw in ("x86_64", "AMD64"):
+      return MachineArch.X64
+    if raw in ("arm64", "aarch64"):
+      return MachineArch.ARM_64
+    if raw in ("arm"):
+      return MachineArch.ARM_32
+    raise NotImplementedError(f"Unsupported machine type: {raw}")
+
+  def _raw_machine_arch(self) -> str:
+    self.assert_is_local()
+    return py_platform.machine()
+
+  @property
+  def is_ia32(self) -> bool:
+    return self.machine == MachineArch.IA32
+
+  @property
+  def is_x64(self) -> bool:
+    return self.machine == MachineArch.X64
+
+  @property
+  def is_arm64(self) -> bool:
+    return self.machine == MachineArch.ARM_64
+
+  @property
+  def key(self) -> Tuple[str, str]:
+    return (self.name, str(self.machine))
+
+  @property
+  def is_macos(self) -> bool:
+    return False
+
+  @property
+  def is_linux(self) -> bool:
+    return False
+
+  @property
+  def is_android(self) -> bool:
+    return False
+
+  @property
+  def is_chromeos(self) -> bool:
+    return False
+
+  @property
+  def is_posix(self) -> bool:
+    return self.is_macos or self.is_linux or self.is_android
+
+  @property
+  def is_win(self) -> bool:
+    return False
+
+  @property
+  def is_remote_ssh(self) -> bool:
+    return False
+
+  @property
+  def environ(self) -> Environ:
+    self.assert_is_local()
+    return LocalEnviron()
+
+  @property
+  def is_battery_powered(self) -> bool:
+    self.assert_is_local()
+    if not psutil.sensors_battery:
+      return False
+    status = psutil.sensors_battery()
+    if not status:
+      return False
+    return not status.power_plugged
+
+  def _search_executable(
+      self,
+      name: str,
+      macos: Sequence[str],
+      win: Sequence[str],
+      linux: Sequence[str],
+      lookup_callable: Callable[[pth.AnyPath], Optional[pth.AnyPath]],
+  ) -> pth.AnyPath:
+    executables: Sequence[str] = []
+    if self.is_macos:
+      executables = macos
+    elif self.is_win:
+      executables = win
+    elif self.is_linux:
+      executables = linux
+    if not executables:
+      raise ValueError(f"Executable {name} not supported on {self}")
+    for name_or_path in executables:
+      path = self.local_path(name_or_path).expanduser()
+      binary = lookup_callable(path)
+      if binary and self.exists(binary):
+        return binary
+    raise ValueError(f"Executable {name} not found on {self}")
+
+  def search_app_or_executable(
+      self,
+      name: str,
+      macos: Sequence[str] = (),
+      win: Sequence[str] = (),
+      linux: Sequence[str] = ()
+  ) -> pth.AnyPath:
+    return self._search_executable(name, macos, win, linux, self.search_app)
+
+  def search_platform_binary(
+      self,
+      name: str,
+      macos: Sequence[str] = (),
+      win: Sequence[str] = (),
+      linux: Sequence[str] = ()
+  ) -> pth.AnyPath:
+    return self._search_executable(name, macos, win, linux, self.search_binary)
+
+  def search_app(self, app_or_bin: pth.AnyPath) -> Optional[pth.AnyPath]:
+    """Look up a application bundle (macos) or binary (all other platforms) in
+    the common search paths.
+    """
+    return self.search_binary(app_or_bin)
+
+  @abc.abstractmethod
+  def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    """Look up a binary in the common search paths based of a path or a single
+    segment path with just the binary name.
+    Returns the location of the binary (and not the .app bundle on macOS).
+    """
+
+  @abc.abstractmethod
+  def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
+    pass
+
+  @property
+  def has_display(self) -> bool:
+    """Return a bool whether the platform has an active display.
+    This can be false on linux without $DISPLAY, true an all other platforms."""
+    return True
+
+  def sleep(self, seconds: Union[int, float, dt.timedelta]) -> None:
+    if isinstance(seconds, dt.timedelta):
+      seconds = seconds.total_seconds()
+    if seconds == 0:
+      return
+    logging.debug("WAIT %ss", seconds)
+    time.sleep(seconds)
+
+  def which(self, binary_name: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    if not binary_name:
+      raise ValueError("Got empty path")
+    self.assert_is_local()
+    if override := self.lookup_binary_override(binary_name):
+      return override
+    if result := shutil.which(os.fspath(binary_name)):
+      return self.path(result)
+    return None
+
+  def lookup_binary_override(
+      self, binary_name: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    return self._binary_lookup_override.get(os.fspath(binary_name))
+
+  def set_binary_lookup_override(self, binary_name: pth.AnyPathLike,
+                                 new_path: Optional[pth.AnyPath]):
+    name = os.fspath(binary_name)
+    if new_path is None:
+      prev_result = self._binary_lookup_override.pop(name, None)
+      if prev_result is None:
+        logging.debug(
+            "Could not remove binary override for %s as it was never set",
+            binary_name)
+      return
+    if self.search_binary(new_path) is None:
+      raise ValueError(f"Suggested binary override for {repr(name)} "
+                       f"does not exist: {new_path}")
+    self._binary_lookup_override[name] = new_path
+
+  @contextlib.contextmanager
+  def override_binary(self, binary: Union[pth.AnyPathLike, Binary],
+                      result: Optional[pth.AnyPath]):
+    binary_name: pth.AnyPathLike = ""
+    if isinstance(binary, Binary):
+      if override := binary.platform_path(self):
+        binary_name = override[0]
+      else:
+        raise RuntimeError("Cannot override binary:"
+                           f" {binary} is not supported supported on {self}")
+    else:
+      binary_name = binary
+    prev_override = self.lookup_binary_override(binary_name)
+    self.set_binary_lookup_override(binary_name, result)
+    try:
+      yield
+    finally:
+      self.set_binary_lookup_override(binary_name, prev_override)
+
+  def processes(self,
+                attrs: Optional[List[str]] = None) -> List[Dict[str, Any]]:
+    # TODO(cbruni): support remote platforms
+    assert self.is_local, "Only local platform supported"
+    return self._collect_process_dict(psutil.process_iter(attrs=attrs))
+
+  def process_running(self, process_name_list: List[str]) -> Optional[str]:
+    self.assert_is_local()
+    # TODO(cbruni): support remote platforms
+    for proc in psutil.process_iter(attrs=["name"]):
+      try:
+        if proc.name().lower() in process_name_list:
+          return proc.name()
+      except _IGNORED_PROCESS_EXCEPTIONS:
+        pass
+    return None
+
+  def process_children(self,
+                       parent_pid: int,
+                       recursive: bool = False) -> List[Dict[str, Any]]:
+    self.assert_is_local()
+    # TODO(cbruni): support remote platforms
+    try:
+      process = psutil.Process(parent_pid)
+    except _IGNORED_PROCESS_EXCEPTIONS:
+      return []
+    return self._collect_process_dict(process.children(recursive=recursive))
+
+  def _collect_process_dict(
+      self, process_iterator: Iterable[psutil.Process]) -> List[Dict[str, Any]]:
+    process_info_list: List[Dict[str, Any]] = []
+    for process in process_iterator:
+      try:
+        process_info_list.append(process.as_dict())
+      except _IGNORED_PROCESS_EXCEPTIONS:
+        pass
+    return process_info_list
+
+  def process_info(self, pid: int) -> Optional[Dict[str, Any]]:
+    self.assert_is_local()
+    # TODO(cbruni): support remote platforms
+    try:
+      return psutil.Process(pid).as_dict()
+    except _IGNORED_PROCESS_EXCEPTIONS:
+      return None
+
+  def foreground_process(self) -> Optional[Dict[str, Any]]:
+    return None
+
+  def terminate(self, proc_pid: int) -> None:
+    self.assert_is_local()
+    # TODO(cbruni): support remote platforms
+    process = psutil.Process(proc_pid)
+    for proc in process.children(recursive=True):
+      proc.terminate()
+    process.terminate()
+
+  @property
+  def default_tmp_dir(self) -> pth.AnyPath:
+    self.assert_is_local()
+    return self.path(tempfile.gettempdir())
+
+  def port_forward(self, local_port: int, remote_port: int) -> int:
+    if remote_port != local_port:
+      raise ValueError("Cannot forward a remote port on a local platform.")
+    self.assert_is_local()
+    return local_port
+
+  def stop_port_forward(self, local_port: int) -> None:
+    del local_port
+    self.assert_is_local()
+
+  def reverse_port_forward(self, remote_port: int, local_port: int) -> int:
+    if remote_port != local_port:
+      raise ValueError("Cannot forward a remote port on a local platform.")
+    self.assert_is_local()
+    return remote_port
+
+  def stop_reverse_port_forward(self, remote_port: int) -> None:
+    del remote_port
+    self.assert_is_local()
+
+  def local_cache_dir(self, name: Optional[str] = None) -> pth.LocalPath:
+    return self.local_path(self.cache_dir(name))
+
+  def cache_dir(self, name: Optional[str] = None) -> pth.AnyPath:
+    assert self._cache_dir, "missing cache dir"
+    if not name:
+      dir = self._cache_dir
+    else:
+      dir = self._cache_dir / pth.safe_filename(name)
+    self.mkdir(dir, parents=True, exist_ok=True)
+    return dir
+
+  def set_cache_dir(self, path: pth.AnyPath) -> None:
+    self._cache_dir = path
+    self.mkdir(path, parents=True, exist_ok=True)
+
+  def cat(self, file: pth.AnyPathLike, encoding: str = "utf-8") -> str:
+    """Meow! I return the file contents as a str."""
+    with self.local_path(file).open(encoding=encoding) as f:
+      return f.read()
+
+  def cat_bytes(self, file: pth.AnyPathLike) -> bytes:
+    """Hiss! I return the file contents as bytes."""
+    with self.local_path(file).open("rb") as f:
+      return f.read()
+
+  def get_file_contents(self,
+                        file: pth.AnyPathLike,
+                        encoding: str = "utf-8") -> str:
+    return self.cat(file, encoding)
+
+  def set_file_contents(self,
+                        file: pth.AnyPathLike,
+                        data: str,
+                        encoding: str = "utf-8") -> None:
+    with self.local_path(file).open("w", encoding=encoding) as f:
+      f.write(data)
+
+  def pull(self, from_path: pth.AnyPath,
+           to_path: pth.LocalPath) -> pth.LocalPath:
+    """ Download / Copy a (remote) file to the local filesystem.
+    By default this is just a copy operation on the local filesystem.
+    """
+    self.assert_is_local()
+    return self.local_path(self.copy_file(from_path, to_path))
+
+  def push(self, from_path: pth.LocalPath, to_path: pth.AnyPath) -> pth.AnyPath:
+    """ Copy a local file to this (remote) platform.
+    By default this is just a copy operation on the local filesystem.
+    """
+    self.assert_is_local()
+    return self.copy_file(from_path, to_path)
+
+  def copy(self, from_path: pth.AnyPath, to_path: pth.AnyPath) -> pth.AnyPath:
+    """ Convenience implementation for copying local files and dirs """
+    if not self.exists(from_path):
+      raise ValueError(f"Cannot copy non-existing source path: {from_path}")
+    if self.is_dir(from_path):
+      return self.copy_dir(from_path, to_path)
+    return self.copy_file(from_path, to_path)
+
+  def copy_dir(self, from_path: pth.AnyPathLike,
+               to_path: pth.AnyPathLike) -> pth.AnyPath:
+    from_path = self.local_path(from_path)
+    to_path = self.local_path(to_path)
+    self.mkdir(to_path.parent, parents=True, exist_ok=True)
+    shutil.copytree(os.fspath(from_path), os.fspath(to_path))
+    return to_path
+
+  def copy_file(self, from_path: pth.AnyPathLike,
+                to_path: pth.AnyPathLike) -> pth.AnyPath:
+    from_path = self.local_path(from_path)
+    to_path = self.local_path(to_path)
+    self.mkdir(to_path.parent, parents=True, exist_ok=True)
+    shutil.copy2(os.fspath(from_path), os.fspath(to_path))
+    return to_path
+
+  def rm(self,
+         path: pth.AnyPathLike,
+         dir: bool = False,
+         missing_ok: bool = False) -> None:
+    """Remove a single file on this platform."""
+    path = self.local_path(path)
+    if dir:
+      if missing_ok and not self.exists(path):
+        return
+      shutil.rmtree(os.fspath(path))
+    else:
+      path.unlink(missing_ok)
+
+  def rename(self, src_path: pth.AnyPathLike,
+             dst_path: pth.AnyPathLike) -> pth.AnyPath:
+    """Remove a single file on this platform."""
+    return self.local_path(src_path).rename(dst_path)
+
+  def symlink_or_copy(self, src: pth.AnyPathLike,
+                      dst: pth.AnyPathLike) -> pth.AnyPath:
+    """Windows does not support symlinking without admin support.
+    Copy files on windows (see WinPlatform) but symlink everywhere else."""
+    assert not self.is_win, "Unsupported operation 'symlink_or_copy' on windows"
+    dst_path = self.local_path(dst)
+    dst_path.symlink_to(self.path(src))
+    return dst_path
+
+  def path(self, path: pth.AnyPathLike) -> pth.AnyPath:
+    """"Used to convert any paths and strings to a platform specific
+    remote path.
+    For instance a remote ADB platform on windows returns posix paths:
+      posix_path = adb_remote_platform.patch(windows_path)
+    This is used when passing out platform specific paths to remote shell
+    commands.
+    """
+    return self.local_path(path)
+
+  def local_path(self, path: pth.AnyPathLike) -> pth.LocalPath:
+    self.assert_is_local()
+    return pth.LocalPath(path)
+
+  def absolute(self, path: pth.AnyPathLike) -> pth.AnyPath:
+    """Convert an arbitrary path to a platform-specific absolute path"""
+    platform_path: pth.AnyPath = self.path(path)
+    if platform_path.is_absolute():
+      return platform_path
+    if self.is_local:
+      return self.local_path(platform_path).absolute()
+    raise RuntimeError(
+        f"Converting relative to absolute paths is not supported on {self}")
+
+  def home(self) -> pth.AnyPath:
+    return pathlib.Path.home()
+
+  def touch(self, path: pth.AnyPathLike) -> None:
+    self.local_path(path).touch(exist_ok=True)
+
+  def mkdir(self,
+            path: pth.AnyPathLike,
+            parents: bool = True,
+            exist_ok: bool = True) -> None:
+    self.local_path(path).mkdir(parents=parents, exist_ok=exist_ok)
+
+  @contextlib.contextmanager
+  def NamedTemporaryFile(  # pylint: disable=invalid-name
+      self,
+      prefix: Optional[str] = None,
+      dir: Optional[pth.AnyPathLike] = None):
+    tmp_file: LocalPath = self.host_platform.local_path(
+        self.host_platform.mktemp(prefix, dir))
+    try:
+      yield tmp_file
+    finally:
+      self.rm(tmp_file, missing_ok=True)
+
+  def mkdtemp(self,
+              prefix: Optional[str] = None,
+              dir: Optional[pth.AnyPathLike] = None) -> pth.AnyPath:
+    self.assert_is_local()
+    return self.path(tempfile.mkdtemp(prefix=prefix, dir=dir))
+
+  def mktemp(self,
+             prefix: Optional[str] = None,
+             dir: Optional[pth.AnyPathLike] = None) -> pth.AnyPath:
+    self.assert_is_local()
+    fd, name = tempfile.mkstemp(prefix=prefix, dir=dir)
+    os.close(fd)
+    return self.path(name)
+
+  @contextlib.contextmanager
+  def TemporaryDirectory(  # pylint: disable=invalid-name
+      self,
+      prefix: Optional[str] = None,
+      dir: Optional[pth.AnyPathLike] = None):
+    tmp_dir = self.mkdtemp(prefix, dir)
+    try:
+      yield tmp_dir
+    finally:
+      self.rm(tmp_dir, dir=True, missing_ok=True)
+
+  def exists(self, path: pth.AnyPathLike) -> bool:
+    return self.local_path(path).exists()
+
+  def is_file(self, path: pth.AnyPathLike) -> bool:
+    return self.local_path(path).is_file()
+
+  def is_dir(self, path: pth.AnyPathLike) -> bool:
+    return self.local_path(path).is_dir()
+
+  def iterdir(self,
+              path: pth.AnyPathLike) -> Generator[pth.AnyPath, None, None]:
+    return self.local_path(path).iterdir()
+
+  def glob(self, path: pth.AnyPathLike,
+           pattern: str) -> Generator[pth.AnyPath, None, None]:
+    # TODO: support remotely
+    return self.local_path(path).glob(pattern)
+
+  def file_size(self, path: pth.AnyPathLike) -> int:
+    # TODO: support remotely
+    return self.local_path(path).stat().st_size
+
+  def sh_stdout(self,
+                *args: CmdArg,
+                shell: bool = False,
+                quiet: bool = False,
+                encoding: str = "utf-8",
+                stdin=None,
+                env: Optional[Mapping[str, str]] = None,
+                check: bool = True) -> str:
+    result = self.sh_stdout_bytes(
+        *args, shell=shell, quiet=quiet, stdin=stdin, env=env, check=check)
+    return result.decode(encoding)
+
+  def sh_stdout_bytes(self,
+                      *args: CmdArg,
+                      shell: bool = False,
+                      quiet: bool = False,
+                      stdin=None,
+                      env: Optional[Mapping[str, str]] = None,
+                      check: bool = True) -> bytes:
+    completed_process = self.sh(
+        *args,
+        shell=shell,
+        capture_output=True,
+        quiet=quiet,
+        stdin=stdin,
+        env=env,
+        check=check)
+    return completed_process.stdout
+
+  def popen(self,
+            *args: CmdArg,
+            bufsize=-1,
+            shell: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False) -> subprocess.Popen:
+    self.assert_is_local()
+    if not quiet:
+      logging.debug("SHELL: %s", shlex.join(map(str, args)))
+      logging.debug("CWD: %s", os.getcwd())
+    return subprocess.Popen(
+        args=args,
+        bufsize=bufsize,
+        shell=shell,
+        stdin=stdin,
+        stderr=stderr,
+        stdout=stdout,
+        env=env)
+
+  def sh(self,
+         *args: CmdArg,
+         shell: bool = False,
+         capture_output: bool = False,
+         stdout=None,
+         stderr=None,
+         stdin=None,
+         env: Optional[Mapping[str, str]] = None,
+         quiet: bool = False,
+         check: bool = True) -> subprocess.CompletedProcess:
+    self.assert_is_local()
+    if not quiet:
+      logging.debug("SHELL: %s", shlex.join(map(str, args)))
+      logging.debug("CWD: %s", os.getcwd())
+    process = subprocess.run(
+        args=args,
+        shell=shell,
+        stdin=stdin,
+        stdout=stdout,
+        stderr=stderr,
+        env=env,
+        capture_output=capture_output,
+        check=False)
+    if check and process.returncode != 0:
+      raise SubprocessError(self, process)
+    return process
+
+  def exec_apple_script(self, script: str, *args: str) -> str:
+    del script, args
+    raise NotImplementedError("AppleScript is only available on MacOS")
+
+  def log(self, *messages: Any, level: int = 2) -> None:
+    message_str = " ".join(map(str, messages))
+    if level == 3:
+      level = logging.DEBUG
+    if level == 2:
+      level = logging.INFO
+    if level == 1:
+      level = logging.WARNING
+    if level == 0:
+      level = logging.ERROR
+    logging.log(level, message_str)
+
+  # TODO(cbruni): split into separate list_system_monitoring and
+  # disable_system_monitoring methods
+  def check_system_monitoring(self, disable: bool = False) -> bool:
+    # pylint: disable=unused-argument
+    return True
+
+  def get_relative_cpu_speed(self) -> float:
+    return 1
+
+  def is_thermal_throttled(self) -> bool:
+    return self.get_relative_cpu_speed() < 1
+
+  def disk_usage(self, path: pth.AnyPathLike) -> psutil._common.sdiskusage:
+    return psutil.disk_usage(str(self.local_path(path)))
+
+  def cpu_usage(self) -> float:
+    self.assert_is_local()
+    return 1 - psutil.cpu_times_percent().idle / 100
+
+  def cpu_details(self) -> Dict[str, Any]:
+    self.assert_is_local()
+    details = {
+        "physical cores":
+            psutil.cpu_count(logical=False),
+        "logical cores":
+            psutil.cpu_count(logical=True),
+        "usage":
+            psutil.cpu_percent(  # pytype: disable=attribute-error
+                percpu=True, interval=0.1),
+        "total usage":
+            psutil.cpu_percent(),
+        "system load":
+            psutil.getloadavg(),
+        "info":
+            self.cpu,
+    }
+    try:
+      cpu_freq = psutil.cpu_freq()
+    except FileNotFoundError as e:
+      logging.debug("psutil.cpu_freq() failed (normal on macOS M1): %s", e)
+      return details
+    details.update({
+        "max frequency": f"{cpu_freq.max:.2f}Mhz",
+        "min frequency": f"{cpu_freq.min:.2f}Mhz",
+        "current frequency": f"{cpu_freq.current:.2f}Mhz",
+    })
+    return details
+
+  def system_details(self) -> Dict[str, Any]:
+    return {
+        "machine": str(self.machine),
+        "os": self.os_details(),
+        "python": self.python_details(),
+        "CPU": self.cpu_details(),
+    }
+
+  def os_details(self) -> JsonDict:
+    self.assert_is_local()
+    return {
+        "system": py_platform.system(),
+        "release": py_platform.release(),
+        "version": py_platform.version(),
+        "platform": py_platform.platform(),
+    }
+
+  def python_details(self) -> JsonDict:
+    self.assert_is_local()
+    return {
+        "version": py_platform.python_version(),
+        "bits": 64 if sys.maxsize > 2**32 else 32,
+    }
+
+  def download_to(self, url: str, path: pth.LocalPath) -> pth.LocalPath:
+    self.assert_is_local()
+    logging.debug("DOWNLOAD: %s\n       TO: %s", url, path)
+    assert not path.exists(), f"Download destination {path} exists already."
+    try:
+      urllib.request.urlretrieve(url, path)
+    except (urllib.error.HTTPError, urllib.error.URLError) as e:
+      raise OSError(f"Could not load {url}") from e
+    assert path.exists(), (
+        f"Downloading {url} failed. Downloaded file {path} doesn't exist.")
+    return path
+
+  def concat_files(self,
+                   inputs: Iterable[pth.LocalPath],
+                   output: pth.LocalPath,
+                   prefix: str = "") -> pth.LocalPath:
+    self.assert_is_local()
+    with output.open("w", encoding="utf-8") as output_f:
+      if prefix:
+        output_f.write(prefix)
+      for input_file in inputs:
+        assert input_file.is_file()
+        with input_file.open(encoding="utf-8") as input_f:
+          shutil.copyfileobj(input_f, output_f)
+    return output
+
+  def set_main_display_brightness(self, brightness_level: int) -> None:
+    raise NotImplementedError(
+        "'set_main_display_brightness' is only available on MacOS for now")
+
+  def get_main_display_brightness(self) -> int:
+    raise NotImplementedError(
+        "'get_main_display_brightness' is only available on MacOS for now")
+
+  def check_autobrightness(self) -> bool:
+    raise NotImplementedError(
+        "'check_autobrightness' is only available on MacOS for now")
+
+  def screenshot(self, result_path: pth.AnyPath) -> None:
+    # TODO: support screen coordinates
+    raise NotImplementedError(
+        "'screenshot' is only available on MacOS for now")
diff --git a/crossbench/plt/bin.py b/crossbench/plt/bin.py
new file mode 100644
index 0000000..12a0da6
--- /dev/null
+++ b/crossbench/plt/bin.py
@@ -0,0 +1,214 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import functools
+from typing import TYPE_CHECKING, Iterable, Optional, Tuple, Union
+
+from crossbench import path as pth
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import Platform
+
+
+class BinaryNotFoundError(RuntimeError):
+
+  def __init__(self, binary: Binary, platform: Platform):
+    self.binary = binary
+    self.platform = platform
+    super().__init__(self._create_message())
+
+  def _create_message(self) -> str:
+    return (f"Could not find binary '{self.binary}' on {self.platform}. "
+            f"Please install {self.binary.name} or use the "
+            f"--bin-{self.binary.name} "
+            "command line flag to manually specify a path.")
+
+
+class UnsupportedPlatformError(BinaryNotFoundError):
+
+  def __init__(self, binary: Binary, platform: Platform, expected: str):
+    self.expected_platform_name: str = expected
+    super().__init__(binary, platform)
+
+  def _create_message(self) -> str:
+    return (f"Could not find binary '{self.binary}' on {self.platform}. "
+            f"Only supported on {self.expected_platform_name}")
+
+
+BinaryLookup = Union[pth.AnyPathLike, Iterable[pth.AnyPathLike]]
+
+
+class Binary:
+  """A binary abstraction for multiple platforms.
+  Use this implementation to define binaries that exist on multiple platforms.
+  For platform-specific binaries use subclasses of Binary."""
+
+  def __init__(self,
+               name: str,
+               default: Optional[BinaryLookup] = None,
+               posix: Optional[BinaryLookup] = None,
+               linux: Optional[BinaryLookup] = None,
+               android: Optional[BinaryLookup] = None,
+               macos: Optional[BinaryLookup] = None,
+               win: Optional[BinaryLookup] = None) -> None:
+    self._name = name
+    self._default = self._convert(default)
+    self._posix = self._convert(posix)
+    self._linux = self._convert(linux)
+    self._android = self._convert(android)
+    self._macos = self._convert(macos)
+    self._win = self._convert(win)
+    self._validate_win()
+    if not any((default, posix, linux, android, macos, win)):
+      raise ValueError("At least one platform binary must be provided")
+
+  def _convert(self,
+               paths: Optional[BinaryLookup] = None) -> Tuple[pth.AnyPath, ...]:
+    if paths is None:
+      return tuple()
+    if isinstance(paths, str):
+      path: str = paths
+      if not path:
+        raise ValueError("Got unexpected empty string as binary path")
+      paths = [path]
+    elif isinstance(paths, pth.AnyPath):
+      paths = [paths]
+    return tuple(pth.AnyPath(path) for path in paths)
+
+  def _validate_win(self) -> None:
+    for path in self._win:
+      if path.suffix != ".exe":
+        raise ValueError(f"Windows binary {path} should have '.exe' suffix")
+
+  @property
+  def name(self) -> str:
+    return self._name
+
+  def __str__(self) -> str:
+    return self._name
+
+  @functools.lru_cache(maxsize=None)  # pylint: disable=method-cache-max-size-none
+  def resolve_cached(self, platform: Platform) -> pth.AnyPath:
+    return self.resolve(platform)
+
+  def resolve(self, platform: Platform) -> pth.AnyPath:
+    self._validate_platform(platform)
+    for binary in self.platform_path(platform):
+      binary_path = platform.path(binary)
+      if result := platform.search_binary(binary_path):
+        return result
+    raise BinaryNotFoundError(self, platform)
+
+  def platform_path(self, platform: Platform) -> Tuple[pth.AnyPath, ...]:
+    if self._linux and platform.is_linux:
+      return self._linux
+    if self._android and platform.is_android:
+      return self._android
+    if self._macos and platform.is_macos:
+      return self._macos
+    if self._posix and platform.is_posix:
+      return self._posix
+    if platform.is_win:
+      if self._win:
+        return self._win
+      if self._default:
+        return self._win_default()
+    return self._default
+
+  def _win_default(self) -> Tuple[pth.AnyPath, ...]:
+    return tuple(
+        default if default.suffix == ".exe" else default.with_suffix(".exe")
+        for default in self._default)
+
+  def _validate_platform(self, platform: Platform) -> None:
+    pass
+
+
+class PosixBinary(Binary):
+
+  def __init__(self, name: pth.AnyPathLike):
+    super().__init__(pth.AnyPosixPath(name).name, posix=name)
+
+  def _validate_platform(self, platform: Platform) -> None:
+    if not platform.is_posix:
+      raise UnsupportedPlatformError(self, platform, "posix")
+
+
+class MacOsBinary(Binary):
+
+  def __init__(self, name: pth.AnyPathLike):
+    super().__init__(pth.AnyPosixPath(name).name, macos=name)
+
+  def _validate_platform(self, platform: Platform) -> None:
+    if not platform.is_macos:
+      raise UnsupportedPlatformError(self, platform, "macos")
+
+
+class LinuxBinary(Binary):
+
+  def __init__(self, name: pth.AnyPathLike):
+    super().__init__(pth.AnyPosixPath(name).name, linux=name)
+
+  def _validate_platform(self, platform: Platform) -> None:
+    if not platform.is_posix:
+      raise UnsupportedPlatformError(self, platform, "linux")
+
+
+class AndroidBinary(Binary):
+
+  def __init__(self, name: pth.AnyPathLike):
+    super().__init__(pth.AnyPosixPath(name).name, android=name)
+
+  def _validate_platform(self, platform: Platform) -> None:
+    if not platform.is_android:
+      raise UnsupportedPlatformError(self, platform, "android")
+
+
+class WinBinary(Binary):
+
+  def __init__(self, name: pth.AnyPathLike):
+    super().__init__(pth.AnyWindowsPath(name).name, win=name)
+
+  def _validate_platform(self, platform: Platform) -> None:
+    if not platform.is_win:
+      raise UnsupportedPlatformError(self, platform, "windows")
+
+
+class Binaries:
+  CPIO = LinuxBinary("cpio")
+  FFMPEG = Binary("ffmpeg", posix="ffmpeg")
+  GCERTSTATUS = Binary("gcertstatus", posix="gcertstatus")
+  GO = Binary("go", posix="go")
+  GSUTIL = Binary("gsutil", posix="gsutil")
+  LSCPU = LinuxBinary("lscpu")
+  MONTAGE = Binary("montage", posix="montage")
+  ON_AC_POWER = LinuxBinary("on_ac_power")
+  PERF = LinuxBinary("perf")
+  PPROF = LinuxBinary("pprof")
+  PYTHON3 = Binary("python3", default="python3", win="python3.exe")
+  RPM2CPIO = LinuxBinary("rpm2cpio")
+  SIMPLEPERF = AndroidBinary("simpleperf")
+  XCTRACE = MacOsBinary("xctrace")
+
+
+class Browsers:
+  SAFARI = MacOsBinary("Safari.app")
+  SAFARI_TECH_PREVIEW = MacOsBinary("Safari Technology Preview.app")
+  FIREFOX_STABLE = Binary(
+      "firefox stable",
+      macos="Firefox.app",
+      linux="firefox",
+      win="Mozilla Firefox/firefox.exe")
+  FIREFOX_DEV = Binary(
+      "firefox developer edition",
+      macos="Firefox Developer Edition.app",
+      linux="firefox-developer-edition",
+      win="Firefox Developer Edition/firefox.exe")
+  FIREFOX_NIGHTLY = Binary(
+      "Firefox nightly",
+      macos="Firefox Nightly.app",
+      linux=["firefox-nightly", "firefox-trunk"],
+      win="Firefox Nightly/firefox.exe")
diff --git a/crossbench/plt/chromeos_ssh.py b/crossbench/plt/chromeos_ssh.py
new file mode 100644
index 0000000..3aa0414
--- /dev/null
+++ b/crossbench/plt/chromeos_ssh.py
@@ -0,0 +1,60 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.plt.linux_ssh import LinuxSshPlatform
+
+if TYPE_CHECKING:
+  from typing import Optional
+
+  from crossbench.flags.chrome import ChromeFlags
+  from crossbench.plt.base import ListCmdArgs
+
+
+class ChromeOsSshPlatform(LinuxSshPlatform):
+
+  AUTOLOGIN_PATH = pth.AnyPosixPath("/usr/local/autotest/bin/autologin.py")
+  DEVTOOLS_PORT_PATH = pth.AnyPosixPath("/home/chronos/DevToolsActivePort")
+
+  def __init__(self, *args, **kwargs):
+    self._username: Optional[str] = None
+    super().__init__(*args, **kwargs)
+
+  @property
+  def name(self) -> str:
+    return "chromeos_ssh"
+
+  @property
+  def username(self) -> Optional[str]:
+    return self._username
+
+  @property
+  def is_chromeos(self) -> bool:
+    return True
+
+  def create_debugging_session(self,
+                               browser_flags: Optional[ChromeFlags] = None,
+                               username: Optional[str] = None,
+                               password: Optional[str] = None) -> int:
+    try:
+      args: ListCmdArgs = [self.AUTOLOGIN_PATH]
+      if username and password:
+        self._username = username
+        args.extend(("-u", username, "-p", password))
+      if browser_flags:
+        args.append("--")
+        args.extend(browser_flags)
+      self.sh(*args)
+    except plt.SubprocessError as e:
+      raise RuntimeError("Autologin failed.") from e
+    try:
+      dbg_port = self.cat(self.DEVTOOLS_PORT_PATH).splitlines()[0].strip()
+    except plt.SubprocessError as e:
+      raise RuntimeError("Could not read remote debugging port.") from e
+    return int(dbg_port)
diff --git a/crossbench/plt/ios.py b/crossbench/plt/ios.py
new file mode 100644
index 0000000..f76d4dd
--- /dev/null
+++ b/crossbench/plt/ios.py
@@ -0,0 +1,46 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from dataclasses import dataclass
+from typing import TYPE_CHECKING, Dict
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import Platform
+
+pattern = re.compile(
+    r"(?P<name>[^\(\)]) \((?P<version>[0-9\.]+)\) \((?P<uuid>[0-9A-Z-]+)\)")
+
+
+@dataclass(frozen=True)
+class IOSDevice:
+  name: str
+  version: str
+  uuid: str
+
+  def __str__(self) -> str:
+    return f"{self.name} ({self.version}) ({self.uuid})"
+
+
+def ios_devices(platform: Platform,
+                show_all: bool = False) -> Dict[str, IOSDevice]:
+  output = platform.sh_stdout("xcrun", "xctrace", "list", "devices")
+  category_index = 0
+  results: Dict[str, IOSDevice] = {}
+  for line in output.splitlines():
+    if line.startswith("== "):
+      category_index += 1
+      continue
+    if category_index > 1 and not show_all:
+      return results
+
+    for match in pattern.finditer(line):
+      device = IOSDevice(
+          match.group("name"), match.group("version"), match.group("uuid"))
+      if device.uuid in results:
+        raise ValueError("Invalid UUID")
+      results[device.uuid] = device
+  return results
diff --git a/crossbench/plt/linux.py b/crossbench/plt/linux.py
new file mode 100644
index 0000000..2b41e8b
--- /dev/null
+++ b/crossbench/plt/linux.py
@@ -0,0 +1,101 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import functools
+import os
+from typing import Any, Dict, Optional, Tuple
+
+from crossbench import path as pth
+from crossbench.plt.base import SubprocessError
+from crossbench.plt.posix import PosixPlatform
+from crossbench.plt.remote import RemotePlatformMixin
+
+
+class LinuxPlatform(PosixPlatform):
+  SEARCH_PATHS: Tuple[pth.AnyPath, ...] = (
+      pth.AnyPosixPath("."),
+      pth.AnyPosixPath("/usr/local/sbin"),
+      pth.AnyPosixPath("/usr/local/bin"),
+      pth.AnyPosixPath("/usr/sbin"),
+      pth.AnyPosixPath("/usr/bin"),
+      pth.AnyPosixPath("/sbin"),
+      pth.AnyPosixPath("/bin"),
+      pth.AnyPosixPath("/opt/google"),
+  )
+
+  @property
+  def is_linux(self) -> bool:
+    return True
+
+  @property
+  def name(self) -> str:
+    return "linux"
+
+  def check_system_monitoring(self, disable: bool = False) -> bool:
+    return True
+
+  @functools.cached_property
+  def device(self) -> str:  #pylint: disable=invalid-overridden-method
+    try:
+      id_dir = self.path("/sys/devices/virtual/dmi/id")
+      vendor = self.cat(id_dir / "sys_vendor").strip()
+      product = self.cat(id_dir / "product_name").strip()
+      return f"{vendor} {product}"
+    except (FileNotFoundError, SubprocessError):
+      return "UNKNOWN"
+
+  @functools.cached_property
+  def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
+    cpu_str = "UNKNOWN"
+    for line in self.cat(self.path("/proc/cpuinfo")).splitlines():
+      if line.startswith("model name"):
+        _, cpu_str = line.split(":", maxsplit=2)
+        break
+    if cores_info := self._get_cpu_cores_info():
+      cpu_str = f"{cpu_str} {cores_info}"
+    return cpu_str
+
+  @property
+  def has_display(self) -> bool:
+    return "DISPLAY" in os.environ
+
+  @property
+  def is_battery_powered(self) -> bool:
+    if self.is_local:
+      return super().is_battery_powered
+    if self.which("on_ac_power"):
+      return self.sh("on_ac_power", check=False).returncode == 1
+    return False
+
+  def system_details(self) -> Dict[str, Any]:
+    details = super().system_details()
+    for info_bin in ("lscpu", "inxi"):
+      if self.which(info_bin):
+        details[info_bin] = self.sh_stdout(info_bin)
+    return details
+
+  def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    app_or_bin_path: pth.AnyPath = self.path(app_or_bin)
+    if not app_or_bin_path.parts:
+      raise ValueError("Got empty path")
+    if result_path := self.which(app_or_bin_path):
+      if not self.exists(result_path):
+        raise RuntimeError(f"{result_path} does not exist.")
+      return result_path
+    for path in self.SEARCH_PATHS:
+      # Recreate Path object for easier pyfakefs testing
+      result_path = self.path(path) / app_or_bin_path
+      if self.exists(result_path):
+        return result_path
+    return None
+
+  def screenshot(self, result_path: pth.AnyPath) -> None:
+    # TODO: maybe use imagemagick's 'import' as more portable alternative
+    self.sh("gnome-screenshot", "--file", result_path)
+
+
+class RemoteLinuxPlatform(RemotePlatformMixin, LinuxPlatform):
+  pass
diff --git a/crossbench/plt/linux_ssh.py b/crossbench/plt/linux_ssh.py
new file mode 100644
index 0000000..55fdf48
--- /dev/null
+++ b/crossbench/plt/linux_ssh.py
@@ -0,0 +1,144 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import shlex
+import subprocess
+from typing import TYPE_CHECKING, Any, Dict, List, Mapping, Optional
+
+from crossbench.plt.arch import MachineArch
+from crossbench.plt.linux import RemoteLinuxPlatform
+from crossbench.plt.ssh import SshPlatformMixin
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.plt.base import CmdArg, CmdArgs, ListCmdArgs, Platform
+
+
+class LinuxSshPlatform(SshPlatformMixin, RemoteLinuxPlatform):
+
+  def __init__(self, host_platform: Platform, host: str, port: int,
+               ssh_port: int, ssh_user: str) -> None:
+    super().__init__(host_platform)
+    self._machine: Optional[MachineArch] = None
+    self._system_details: Optional[Dict[str, Any]] = None
+    self._cpu_details: Optional[Dict[str, Any]] = None
+    # TODO: move ssh-related code to SshPlatformMixin
+    self._host = host
+    self._port = port
+    self._ssh_port = ssh_port
+    self._ssh_user = ssh_user
+
+  @property
+  def name(self) -> str:
+    return "linux_ssh"
+
+  @property
+  def host(self) -> str:
+    return self._host
+
+  @property
+  def port(self) -> int:
+    return self._port
+
+  @property
+  def ssh_user(self) -> str:
+    return self._ssh_user
+
+  @property
+  def ssh_port(self) -> int:
+    return self._ssh_port
+
+  def _build_ssh_cmd(self, *args: CmdArg, shell=False) -> ListCmdArgs:
+    ssh_cmd: ListCmdArgs = [
+        "ssh", "-p", f"{self._ssh_port}", f"{self._ssh_user}@{self._host}"
+    ]
+    if shell:
+      ssh_cmd.append(*args)
+    else:
+      ssh_cmd.append(shlex.join(map(str, args)))
+    return ssh_cmd
+
+  def sh_stdout_bytes(self,
+                      *args: CmdArg,
+                      shell: bool = False,
+                      quiet: bool = False,
+                      stdin=None,
+                      env: Optional[Mapping[str, str]] = None,
+                      check: bool = True) -> bytes:
+    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
+    return self._host_platform.sh_stdout_bytes(
+        *ssh_cmd, quiet=quiet, stdin=stdin, env=env, check=check)
+
+  def sh(self,
+         *args: CmdArg,
+         shell: bool = False,
+         capture_output: bool = False,
+         stdout=None,
+         stderr=None,
+         stdin=None,
+         env: Optional[Mapping[str, str]] = None,
+         quiet: bool = False,
+         check: bool = True) -> subprocess.CompletedProcess:
+    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
+    return self._host_platform.sh(
+        *ssh_cmd,
+        capture_output=capture_output,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet,
+        check=check)
+
+  def popen(self,
+            *args: CmdArg,
+            bufsize=-1,
+            shell: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False) -> subprocess.Popen:
+    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
+    return self._host_platform.popen(
+        *ssh_cmd,
+        bufsize=bufsize,
+        shell=shell,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet)
+
+  def processes(self,
+                attrs: Optional[List[str]] = None) -> List[Dict[str, Any]]:
+    # TODO: Define a more generic method in PosixPlatform, possibly with
+    # an overridable function to generate ps command line.
+    lines = self.sh_stdout("ps", "-A", "-o", "pid,cmd").splitlines()
+    if len(lines) == 1:
+      return []
+
+    res: List[Dict[str, Any]] = []
+    for line in lines[1:]:
+      pid, name = line.split(maxsplit=1)
+      res.append({"pid": int(pid), "name": name})
+    return res
+
+  def push(self, from_path: LocalPath, to_path: AnyPath) -> AnyPath:
+    scp_cmd: CmdArgs = [
+        "scp", "-P", f"{self._ssh_port}", f"{from_path}",
+        f"{self._ssh_user}@{self._host}:{to_path}"
+    ]
+    self._host_platform.sh_stdout(*scp_cmd)
+    return to_path
+
+  def pull(self, from_path: AnyPath, to_path: LocalPath) -> LocalPath:
+    scp_cmd: CmdArgs = [
+        "scp", "-P", f"{self._ssh_port}",
+        f"{self._ssh_user}@{self._host}:{from_path}", f"{to_path}"
+    ]
+    self._host_platform.sh_stdout(*scp_cmd)
+    return to_path
diff --git a/crossbench/plt/macos.py b/crossbench/plt/macos.py
new file mode 100644
index 0000000..77e01ff
--- /dev/null
+++ b/crossbench/plt/macos.py
@@ -0,0 +1,345 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import ctypes
+import functools
+import json
+import logging
+import plistlib
+import re
+import traceback as tb
+from subprocess import SubprocessError
+from typing import Any, Dict, Optional, Tuple
+
+import psutil
+
+from crossbench import path as pth
+from crossbench.plt.posix import PosixPlatform
+
+
+class MacOSPlatform(PosixPlatform):
+  SEARCH_PATHS: Tuple[pth.AnyPath, ...] = (
+      pth.AnyPosixPath("."),
+      pth.AnyPosixPath("/Applications"),
+      # TODO: support remote platforms
+      pth.LocalPath.home() / "Applications",
+  )
+
+  LSAPPINFO_IN_FRONT_LINE_RE = r".*\(in front\)\s*"
+  LSAPPINFO_PID_LINE_RE = r"\s*pid = ([0-9]+).*"
+
+  @property
+  def is_macos(self) -> bool:
+    return True
+
+  @property
+  def name(self) -> str:
+    return "macos"
+
+  @functools.cached_property
+  def version(self) -> str:
+    return self.sh_stdout("sw_vers", "-productVersion").strip()
+
+  @functools.cached_property
+  def device(self) -> str:  #pylint: disable=invalid-overridden-method
+    return self.sh_stdout("sysctl", "hw.model").strip().split(maxsplit=1)[1]
+
+  @functools.cached_property
+  def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
+    brand = self.sh_stdout("sysctl", "-n", "machdep.cpu.brand_string").strip()
+    cores_info = self._get_cpu_cores_info()
+    return f"{brand} {cores_info}"
+
+  def _get_cpu_cores_info(self):
+    cores = self.sh_stdout("sysctl", "-n", "machdep.cpu.core_count").strip()
+    return f"{cores} cores"
+
+  @property
+  def is_battery_powered(self) -> bool:
+    if self.is_local:
+      return super().is_battery_powered
+    return "Battery Power" in self.sh_stdout("pmset", "-g", "batt")
+
+  def _find_app_binary_path(self, app_path: pth.AnyPath) -> pth.AnyPath:
+    assert app_path.suffix == ".app", f"Expected .app but got {app_path}"
+    bin_path = app_path / "Contents" / "MacOS" / app_path.stem
+    if self.exists(bin_path):
+      return bin_path
+    if not self.exists(bin_path.parent):
+      raise ValueError(f"Binary does not exist: {bin_path}")
+    self.assert_is_local()
+    binaries = [
+        path for path in self.iterdir(bin_path.parent) if self.is_file(path)
+    ]
+    if len(binaries) == 1:
+      return binaries[0]
+    # Fallback to read plist
+    plist_path = app_path / "Contents" / "Info.plist"
+    if not self.is_file(plist_path):
+      raise ValueError(f"Could not find Info.plist in app bundle: {app_path}")
+    # TODO: support remote platform
+    with self.local_path(plist_path).open("rb") as f:
+      plist = plistlib.load(f)
+    bin_path = (
+        app_path / "Contents" / "MacOS" /
+        plist.get("CFBundleExecutable", app_path.stem))
+    if self.is_file(bin_path):
+      return bin_path
+    if not binaries:
+      raise ValueError(f"No binaries found in {app_path}")
+    raise ValueError(f"Invalid number of binaries found: {binaries}")
+
+  def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    app_or_bin_path: pth.AnyPath = self.path(app_or_bin)
+    if not app_or_bin_path.parts:
+      raise ValueError("Got empty path")
+    is_app = app_or_bin_path.suffix == ".app"
+    if not is_app:
+      # Look up basic binaries with `which` if possible.
+      if result_path := self.which(app_or_bin_path):
+        assert self.exists(result_path), f"{result_path} does not exist."
+        return result_path
+    if app_path := self.lookup_binary_override(app_or_bin_path):
+      if app_path := self._validate_search_binary_candidate(is_app, app_path):
+        return app_path
+    for search_path in self.SEARCH_PATHS:
+      # Recreate Path object for easier pyfakefs testing
+      result_path = self.path(search_path) / app_or_bin_path
+      if app_path := self._validate_search_binary_candidate(
+          is_app, result_path):
+        return app_path
+    return None
+
+  def _validate_search_binary_candidate(
+      self, is_app: bool, result_path: pth.AnyPath) -> Optional[pth.AnyPath]:
+    if not is_app:
+      if self.is_file(result_path):
+        return result_path
+      return None
+    if not self.is_dir(result_path):
+      return None
+    result_path = self._find_app_binary_path(result_path)
+    if self.exists(result_path):
+      return result_path
+    return None
+
+  def search_app(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    app_or_bin_path: pth.AnyPath = self.path(app_or_bin)
+    if not app_or_bin_path.parts:
+      raise ValueError("Got empty path")
+    self.assert_is_local()
+    if app_or_bin_path.suffix != ".app":
+      raise ValueError("Expected app name with '.app' suffix, "
+                       f"but got: '{app_or_bin_path.name}'")
+    binary = self.search_binary(app_or_bin_path)
+    if not binary:
+      return None
+    # input: /Applications/Safari.app/Contents/MacOS/Safari
+    # output: /Applications/Safari.app
+    app_path = binary.parents[2]
+    assert app_path.suffix == ".app", f"Expected .app but got {app_path}"
+    assert self.is_dir(app_path)
+    return app_path
+
+  def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
+    app_or_bin = self.path(app_or_bin)
+    if not self.exists(app_or_bin):
+      raise ValueError(f"Binary {app_or_bin} does not exist.")
+
+    app_path = None
+    for current in (app_or_bin, *app_or_bin.parents):
+      if current.suffix == ".app" and current.stem == app_or_bin.stem:
+        app_path = current
+        break
+    if not app_path:
+      # Most likely just a cli tool"
+      return self.sh_stdout(app_or_bin, "--version").strip()
+    info_plist = app_path / "Contents/Info.plist"
+    if self.exists(info_plist):
+      plist = plistlib.loads(self.cat_bytes(info_plist))
+      if version_string := plist.get("CFBundleShortVersionString"):
+        return version_string
+
+    # Backup solution use the binary (not the .app bundle) with --version.
+    maybe_bin_path: Optional[pth.AnyPath] = app_or_bin
+    if app_or_bin.suffix == ".app":
+      maybe_bin_path = self.search_binary(app_or_bin)
+    if not maybe_bin_path:
+      raise ValueError(f"Could not extract app version: {app_or_bin}")
+    try:
+      return self.sh_stdout(maybe_bin_path, "--version").strip()
+    except SubprocessError as e:
+      raise ValueError(f"Could not extract app version: {app_or_bin}") from e
+
+  def exec_apple_script(self, script: str, *args: str) -> str:
+    if args:
+      script = f"""on run argv
+        {script.strip()}
+      end run"""
+    return self.sh_stdout("/usr/bin/osascript", "-e", script, *args)
+
+  def foreground_process(self) -> Optional[Dict[str, Any]]:
+    foreground_process_info = self.sh_stdout("lsappinfo", "front").strip()
+    if not foreground_process_info:
+      return None
+    foreground_info = self.sh_stdout("lsappinfo", "info", "-only", "pid",
+                                     foreground_process_info).strip()
+    foreground_info_split = foreground_info.split("=")
+
+    pid = None
+
+    if len(foreground_info_split) == 2:
+      pid = foreground_info_split[1]
+    else:
+      # On macOS 14.0 Beta, "lsappinfo info" returns an empty result. Fall back
+      # to parsing the output of "lsappinfo list" to obtain the front app's
+      # info.
+      app_list = self.sh_stdout("lsappinfo", "list")
+      found_front_app = False
+      for app_list_line in app_list.splitlines():
+        if re.match(self.LSAPPINFO_IN_FRONT_LINE_RE, app_list_line):
+          found_front_app = True
+        elif found_front_app:
+          match = re.match(self.LSAPPINFO_PID_LINE_RE, app_list_line)
+          if match:
+            pid = match.group(1)
+            break
+
+    if pid and pid.isdigit():
+      return psutil.Process(int(pid)).as_dict()
+
+    return None
+
+  def get_relative_cpu_speed(self) -> float:
+    try:
+      lines = self.sh_stdout("pmset", "-g", "therm").split()
+      for index, line in enumerate(lines):
+        if line == "CPU_Speed_Limit":
+          return int(lines[index + 2]) / 100.0
+    except SubprocessError:
+      pass
+    logging.debug("Could not get relative CPU speed: %s", tb.format_exc())
+    return 1
+
+  def system_details(self) -> Dict[str, Any]:
+    details = super().system_details()
+    details.update({
+        "system_profiler":
+            self.sh_stdout("system_profiler", "SPHardwareDataType"),
+        "sysctl_machdep_cpu":
+            self.sh_stdout("sysctl", "machdep.cpu"),
+        "sysctl_hw":
+            self.sh_stdout("sysctl", "hw"),
+    })
+    return details
+
+  def check_system_monitoring(self, disable: bool = False) -> bool:
+    return self.check_crowdstrike(disable)
+
+  def check_autobrightness(self) -> bool:
+    output = self.sh_stdout("system_profiler", "SPDisplaysDataType",
+                            "-json").strip()
+    data = json.loads(output)
+    if spdisplays_data := data.get("SPDisplaysDataType"):
+      for data in spdisplays_data:
+        if spdisplays_ndrvs := data.get("spdisplays_ndrvs"):
+          for display in spdisplays_ndrvs:
+            if auto_brightness := display.get("spdisplays_ambient_brightness"):
+              return auto_brightness == "spdisplays_yes"
+        raise ValueError(
+            "Could not find 'spdisplays_ndrvs' from SPDisplaysDataType")
+    raise ValueError("Could not get 'SPDisplaysDataType' form system profiler")
+
+  def check_crowdstrike(self, disable: bool = False) -> bool:
+    falconctl = self.path(
+        "/Applications/Falcon.app/Contents/Resources/falconctl")
+    if not self.exists(falconctl):
+      logging.debug("You're fine, falconctl or %s are not installed.",
+                    falconctl)
+      return True
+    if not disable:
+      for process in self.processes(attrs=["exe"]):
+        exe = process["exe"]
+        if exe and exe.endswith("/com.crowdstrike.falcon.Agent"):
+          return False
+      return True
+    try:
+      logging.warning("Checking falcon sensor status:")
+      status = self.sh_stdout("sudo", falconctl, "stats", "agent_info")
+    except SubprocessError as e:
+      logging.debug("Could not probe falconctl, assuming it's not running: %s",
+                    e)
+      return True
+    if "operational: true" not in status:
+      # Early return if not running, no need to disable the sensor.
+      return True
+    # Try disabling the process
+    logging.warning("Disabling crowdstrike monitoring:")
+    self.sh("sudo", falconctl, "unload")
+    return True
+
+  def _get_display_service(self) -> Tuple[ctypes.CDLL, Any]:
+    assert self.is_local, "Operation not supported on remote platforms"
+    core_graphics = ctypes.CDLL(
+        "/System/Library/Frameworks/CoreGraphics.framework/CoreGraphics")
+    main_display = core_graphics.CGMainDisplayID()
+    display_services = ctypes.CDLL(
+        "/System/Library/PrivateFrameworks/DisplayServices.framework"
+        "/DisplayServices")
+    display_services.DisplayServicesSetBrightness.argtypes = [
+        ctypes.c_int, ctypes.c_float
+    ]
+    display_services.DisplayServicesGetBrightness.argtypes = [
+        ctypes.c_int, ctypes.POINTER(ctypes.c_float)
+    ]
+    return display_services, main_display
+
+  def set_main_display_brightness(self, brightness_level: int) -> None:
+    """Sets the main display brightness at the specified percentage by
+    brightness_level.
+
+    This function imitates the open-source "brightness" tool at
+    https://github.com/nriley/brightness.
+    Since the benchmark doesn't care about older MacOSen, multiple displays
+    or other complications that tool has to consider, setting the brightness
+    level boils down to calling this function for the main display.
+
+    Args:
+      brightness_level: Percentage at which we want to set screen brightness.
+
+    Raises:
+      AssertionError: An error occurred when we tried to set the brightness
+    """
+    display_services, main_display = self._get_display_service()
+    ret = display_services.DisplayServicesSetBrightness(main_display,
+                                                        brightness_level / 100)
+    assert ret == 0
+
+  def get_main_display_brightness(self) -> int:
+    """Gets the current brightness level of the main display .
+
+    This function imitates the open-source "brightness" tool at
+    https://github.com/nriley/brightness.
+    Since the benchmark doesn't care about older MacOSen, multiple displays
+    or other complications that tool has to consider, setting the brightness
+    level boils down to calling this function for the main display.
+
+    Returns:
+      An int of the current percentage value of the main screen brightness
+
+    Raises:
+      AssertionError: An error occurred when we tried to set the brightness
+    """
+
+    display_services, main_display = self._get_display_service()
+    display_brightness = ctypes.c_float()  # pylint: disable=no-value-for-parameter
+    ret = display_services.DisplayServicesGetBrightness(
+        main_display, ctypes.byref(display_brightness))
+    assert ret == 0
+    return round(display_brightness.value * 100)
+
+  def screenshot(self, result_path: pth.AnyPath) -> None:
+    self.sh("screencapture", "-x", result_path)
diff --git a/crossbench/plt/posix.py b/crossbench/plt/posix.py
new file mode 100644
index 0000000..317a703
--- /dev/null
+++ b/crossbench/plt/posix.py
@@ -0,0 +1,337 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import functools
+import logging
+import re
+from typing import TYPE_CHECKING, Any, Dict, Generator, Iterator, Optional
+
+from crossbench import path as pth
+from crossbench.plt.base import Environ, ListCmdArgs, Platform, SubprocessError
+from crossbench.plt.remote import RemotePlatformMixin
+
+if TYPE_CHECKING:
+  from crossbench.types import JsonDict
+
+
+class PosixPlatform(Platform, metaclass=abc.ABCMeta):
+  # pylint: disable=locally-disabled, redefined-builtin
+
+  def __init__(self) -> None:
+    super().__init__()
+    self._default_tmp_dir: pth.AnyPath = pth.AnyPosixPath("")
+
+  @functools.cached_property
+  def version(self) -> str:  #pylint: disable=invalid-overridden-method
+    return self.sh_stdout("uname", "-r").strip()
+
+  def _raw_machine_arch(self):
+    if self.is_local:
+      return super()._raw_machine_arch()
+    return self.sh_stdout("uname", "-m").strip()
+
+  def _get_cpu_cores_info(self) -> str:
+    try:
+      max_cores_file = self.path("/sys/devices/system/cpu/possible")
+      _, max_core = self.cat(max_cores_file).strip().split("-", maxsplit=1)
+      cores = int(max_core) + 1
+      return f"{cores} cores"
+    except Exception as e:  # pylint: disable=broad-except
+      logging.debug("Failed to get detailed CPU stats: %s", e)
+      return ""
+
+  _GET_CPONF_PROC_RE: re.Pattern = re.compile(
+      r".*PROCESSORS_CONF[^0-9]+(?P<cores>[0-9]+)")
+
+  def cpu_details(self) -> Dict[str, Any]:
+    if self.is_local:
+      return super().cpu_details()
+    cores = -1
+    if self.which("nproc"):
+      cores = int(self.sh_stdout("nproc"))
+    elif self.which("getconf"):
+      result = self._GET_CPONF_PROC_RE.search(self.sh_stdout("getconf", "-a"))
+      if result:
+        cores = int(result["cores"])
+    return {
+        "physical cores": cores,
+        "info": self.cpu,
+    }
+
+  def os_details(self) -> JsonDict:
+    if self.is_local:
+      return super().os_details()
+    return {
+        "system": self.sh_stdout("uname").strip(),
+        "release": self.sh_stdout("uname", "-r").strip(),
+        "version": self.sh_stdout("uname", "-v").strip(),
+        "platform": self.sh_stdout("uname", "-a").strip(),
+    }
+
+  _PY_VERSION: str = "import sys; print(64 if sys.maxsize > 2**32 else 32)"
+
+  def python_details(self) -> JsonDict:
+    if self.is_local:
+      return super().python_details()
+    if not self.which("python3"):
+      return {"version": "unknown", "bits": 64}
+    return {
+        "version": self.sh_stdout("python3", "--version").strip(),
+        "bits": int(self.sh_stdout("python3", "-c", self._PY_VERSION).strip())
+    }
+
+  def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
+    app_or_bin = self.path(app_or_bin)
+    if not self.exists(app_or_bin):
+      raise ValueError(f"Binary {app_or_bin} does not exist.")
+    return self.sh_stdout(app_or_bin, "--version")
+
+  @property
+  def default_tmp_dir(self) -> pth.AnyPath:
+    if self._default_tmp_dir.parts:
+      return self._default_tmp_dir
+    if self.is_local:
+      self._default_tmp_dir = self.path(super().default_tmp_dir)
+      return self._default_tmp_dir
+    env = self.environ
+
+    for tmp_var in ("TMPDIR", "TEMP", "TMP"):
+      if tmp_var not in env:
+        continue
+      tmp_path = self.path(env[tmp_var])
+      if self.is_dir(tmp_path):
+        self._default_tmp_dir = tmp_path
+        return tmp_path
+    self._default_tmp_dir = self.path("/tmp")
+    assert self.is_dir(self._default_tmp_dir), (
+        f"Fallback tmp dir does not exist: {self._default_tmp_dir}")
+    return self._default_tmp_dir
+
+  def path(self, path: pth.AnyPathLike) -> pth.AnyPath:
+    if self.is_local:
+      return pth.LocalPosixPath(path)
+    return pth.AnyPosixPath(path)
+
+  def which(self, binary_name: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    if self.is_local:
+      return super().which(binary_name)
+    if not binary_name:
+      raise ValueError("Got empty path")
+    if override := self.lookup_binary_override(binary_name):
+      return override
+    try:
+      if maybe_path := self.sh_stdout("which", self.path(binary_name)).strip():
+        maybe_bin = self.path(maybe_path)
+        if self.exists(maybe_bin):
+          return maybe_bin
+    except SubprocessError:
+      pass
+    return None
+
+  def cat(self, file: pth.AnyPathLike, encoding: str = "utf-8") -> str:
+    if self.is_local:
+      return super().cat(file, encoding)
+    return self.sh_stdout("cat", self.path(file), encoding=encoding)
+
+  def cat_bytes(self, file: pth.AnyPathLike) -> bytes:
+    if self.is_local:
+      return super().cat_bytes(file)
+    return self.sh_stdout_bytes("cat", self.path(file))
+
+  def rm(self,
+         path: pth.AnyPathLike,
+         dir: bool = False,
+         missing_ok: bool = False) -> None:
+    if self.is_local:
+      super().rm(path, dir, missing_ok)
+      return
+    if missing_ok and not self.exists(path):
+      return
+    if dir:
+      self.sh("rm", "-rf", self.path(path))
+    else:
+      self.sh("rm", self.path(path))
+
+  def rename(self, src_path: pth.AnyPathLike,
+             dst_path: pth.AnyPathLike) -> pth.AnyPath:
+    if self.is_local:
+      return super().rename(src_path, dst_path)
+    dst_path = self.path(dst_path)
+    self.sh("mv", self.path(src_path), dst_path)
+    return dst_path
+
+  def home(self) -> pth.AnyPath:
+    if self.is_local:
+      return super().home()
+    return self.path(self.sh_stdout("printenv", "HOME").strip())
+
+  def touch(self, path: pth.AnyPathLike) -> None:
+    if self.is_local:
+      super().touch(path)
+    else:
+      self.sh("touch", self.path(path))
+
+  def mkdir(self,
+            path: pth.AnyPathLike,
+            parents: bool = True,
+            exist_ok: bool = True) -> None:
+    if self.is_local:
+      super().mkdir(path, parents, exist_ok)
+    elif parents or exist_ok:
+      self.sh("mkdir", "-p", self.path(path))
+    else:
+      self.sh("mkdir", "-p", self.path(path))
+
+  def mkdtemp(self,
+              prefix: Optional[str] = None,
+              dir: Optional[pth.AnyPathLike] = None) -> pth.AnyPath:
+    if self.is_local:
+      return super().mkdtemp(prefix, dir)
+    return self._mktemp_sh(is_dir=True, prefix=prefix, dir=dir)
+
+  def mktemp(self,
+             prefix: Optional[str] = None,
+             dir: Optional[pth.AnyPathLike] = None) -> pth.AnyPath:
+    if self.is_local:
+      return super().mktemp(prefix, dir)
+    return self._mktemp_sh(is_dir=False, prefix=prefix, dir=dir)
+
+  def _mktemp_sh(self, is_dir: bool, prefix: Optional[str],
+                 dir: Optional[pth.AnyPathLike]) -> pth.AnyPath:
+    if not dir:
+      dir = self.default_tmp_dir
+    template = self.path(dir) / f"{prefix}.XXXXXXXXXXX"
+    args: ListCmdArgs = ["mktemp"]
+    if is_dir:
+      args.append("-d")
+    args.append(str(template))
+    result = self.sh_stdout(*args)
+    return self.path(result.strip())
+
+  def copy_dir(self, from_path: pth.AnyPathLike,
+               to_path: pth.AnyPathLike) -> pth.AnyPath:
+    if self.is_local:
+      return super().copy_dir(from_path, to_path)
+    from_path = self.path(from_path)
+    to_path = self.path(to_path)
+    if not self.exists(from_path):
+      raise ValueError(f"Cannot copy non-existing source path: {from_path}")
+    self.mkdir(to_path.parent, parents=True, exist_ok=True)
+    self.sh("cp", "-R", from_path, to_path)
+    return to_path
+
+  def copy_file(self, from_path: pth.AnyPathLike,
+                to_path: pth.AnyPathLike) -> pth.AnyPath:
+    if self.is_local:
+      return super().copy_file(from_path, to_path)
+    from_path = self.path(from_path)
+    to_path = self.path(to_path)
+    if not self.exists(from_path):
+      raise ValueError(f"Cannot copy non-existing source path: {from_path}")
+    self.mkdir(to_path.parent, parents=True, exist_ok=True)
+    self.sh("cp", from_path, to_path)
+    return to_path
+
+  def set_file_contents(self,
+                        file: pth.AnyPathLike,
+                        data: str,
+                        encoding: str = "utf-8") -> None:
+    if self.is_local:
+      super().set_file_contents(file, data, encoding)
+      return
+    # TODO: implement stdin bypass for small content
+    dest_file = self.path(file)
+    with self.host_platform.NamedTemporaryFile("push.data") as tmp_file:
+      self.host_platform.set_file_contents(tmp_file, data, encoding=encoding)
+      self.push(tmp_file, dest_file)
+
+  def exists(self, path: pth.AnyPathLike) -> bool:
+    if self.is_local:
+      return super().exists(path)
+    return self.sh("[", "-e", self.path(path), "]", check=False).returncode == 0
+
+  def is_file(self, path: pth.AnyPathLike) -> bool:
+    if self.is_local:
+      return super().is_file(path)
+    return self.sh("[", "-f", self.path(path), "]", check=False).returncode == 0
+
+  def is_dir(self, path: pth.AnyPathLike) -> bool:
+    if self.is_local:
+      return super().is_dir(path)
+    return self.sh("[", "-d", self.path(path), "]", check=False).returncode == 0
+
+  def iterdir(self,
+              path: pth.AnyPathLike) -> Generator[pth.AnyPath, None, None]:
+    if self.is_local:
+      yield from super().iterdir(path)
+      return
+
+    remote_path = self.path(path)
+    if not self.is_dir(remote_path):
+      raise NotADirectoryError(f"Not a directory: {remote_path}")
+
+    for name in self.sh_stdout("ls", "-1",
+                               remote_path).rstrip("\n").split("\n"):
+      yield remote_path / name
+
+  def terminate(self, proc_pid: int) -> None:
+    self.sh("kill", "-s", "TERM", str(proc_pid))
+
+  def process_info(self, pid: int) -> Optional[Dict[str, Any]]:
+    if self.is_local:
+      return super().process_info(pid)
+    try:
+      lines = self.sh_stdout("ps", "-o", "comm", "-p", str(pid)).splitlines()
+      if len(lines) <= 1:
+        return None
+      assert len(lines) == 2, lines
+      tokens = lines[1].split()
+      assert len(tokens) == 1
+      return {"comm": tokens[0]}
+    except SubprocessError:
+      return None
+
+  @property
+  def environ(self) -> Environ:
+    if self.is_local:
+      return super().environ
+    return RemotePosixEnviron(self)
+
+
+class RemotePosixEnviron(Environ):
+
+  def __init__(self, platform: PosixPlatform) -> None:
+    self._platform = platform
+    self._environ = {}
+    for line in self._platform.sh_stdout("env").splitlines():
+      parts = line.split("=", maxsplit=1)
+      if len(parts) == 2:
+        key, value = parts
+        self._environ[key] = value
+      else:
+        assert len(parts) == 1
+        key = parts[0]
+        self._environ[key] = ""
+
+  def __getitem__(self, key: str) -> str:
+    return self._environ.__getitem__(key)
+
+  def __setitem__(self, key: str, item: str) -> None:
+    raise NotImplementedError("Unsupported")
+
+  def __delitem__(self, key: str) -> None:
+    raise NotImplementedError("Unsupported")
+
+  def __iter__(self) -> Iterator[str]:
+    return self._environ.__iter__()
+
+  def __len__(self) -> int:
+    return self._environ.__len__()
+
+
+class RemotePosixPlatform(RemotePlatformMixin, PosixPlatform):
+  pass
diff --git a/crossbench/plt/remote.py b/crossbench/plt/remote.py
new file mode 100644
index 0000000..0ba913c
--- /dev/null
+++ b/crossbench/plt/remote.py
@@ -0,0 +1,29 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPathLike, LocalPath
+  from crossbench.plt.base import Platform
+
+
+class RemotePlatformMixin:
+
+  def __init__(self, host_platform: Platform):
+    super().__init__()
+    self._host_platform: Platform = host_platform
+
+  @property
+  def is_remote(self) -> bool:
+    return True
+
+  @property
+  def host_platform(self) -> Platform:
+    return self._host_platform
+
+  def host_path(self, path: AnyPathLike) -> LocalPath:
+    return self._host_platform.local_path(path)
diff --git a/crossbench/plt/ssh.py b/crossbench/plt/ssh.py
new file mode 100644
index 0000000..4ca568d
--- /dev/null
+++ b/crossbench/plt/ssh.py
@@ -0,0 +1,22 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import CmdArg, ListCmdArgs
+
+
+class SshPlatformMixin(abc.ABC):
+
+  @property
+  def is_remote_ssh(self) -> bool:
+    return True
+
+  @abc.abstractmethod
+  def _build_ssh_cmd(self, *args: CmdArg, shell=False) -> ListCmdArgs:
+    pass
diff --git a/crossbench/plt/win.py b/crossbench/plt/win.py
new file mode 100644
index 0000000..415d2da
--- /dev/null
+++ b/crossbench/plt/win.py
@@ -0,0 +1,91 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import functools
+import logging
+import os
+import shutil
+from typing import Optional
+
+from crossbench import path as pth
+from crossbench.plt.base import Platform
+
+
+class WinPlatform(Platform):
+  # TODO: support remote platforms
+  SEARCH_PATHS = (
+      pth.LocalPath("."),
+      pth.LocalPath(os.path.expandvars("%ProgramFiles%")),
+      pth.LocalPath(os.path.expandvars("%ProgramFiles(x86)%")),
+      pth.LocalPath(os.path.expandvars("%APPDATA%")),
+      pth.LocalPath(os.path.expandvars("%LOCALAPPDATA%")),
+  )
+
+  @property
+  def is_win(self) -> bool:
+    return True
+
+  @property
+  def name(self) -> str:
+    return "win"
+
+  @property
+  def device(self) -> str:
+    # TODO: implement
+    return ""
+
+  @functools.cached_property
+  def version(self) -> str:  #pylint: disable=invalid-overridden-method
+    return self.sh_stdout("cmd", "/c", "ver").strip()
+
+  @functools.cached_property
+  def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
+    return self.sh_stdout("wmic", "cpu", "get",
+                          "name").strip().splitlines()[2].strip()
+
+  def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
+    self.assert_is_local()
+    app_or_bin_path: pth.AnyPath = self.path(app_or_bin)
+    if not app_or_bin_path.parts:
+      raise ValueError("Got empty path")
+    if app_or_bin_path.suffix.lower() not in (".exe", ".bat"):
+      raise ValueError("Expected executable path with '.exe' or '.bat' suffix, "
+                       f"but got: '{app_or_bin_path.name}'")
+    if result_path := self.which(app_or_bin):
+      assert self.exists(result_path), f"{result_path} does not exist."
+      return result_path
+    for path in self.SEARCH_PATHS:
+      # Recreate Path object for easier pyfakefs testing
+      result_path = self.path(path) / app_or_bin
+      if self.exists(result_path):
+        return result_path
+    return None
+
+  def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
+    app_or_bin = self.path(app_or_bin)
+    if not self.exists(app_or_bin):
+      raise ValueError(f"Binary {app_or_bin} does not exist.")
+    if version := self.sh_stdout(
+        "powershell", "-command",
+        f"(Get-Item '{app_or_bin}').VersionInfo.ProductVersion").strip():
+      return version
+    try:
+      # Fall back to command-line tools.
+      if version := self.sh_stdout(app_or_bin, "--version").strip():
+        return version
+    except Exception as e:  # pylint: disable=broad-exception-caught
+      logging.debug("Failed to extract binary tool version: %s", e)
+    raise ValueError(f"Could not extract version for {app_or_bin}")
+
+
+  def symlink_or_copy(self, src: pth.AnyPathLike,
+                      dst: pth.AnyPathLike) -> pth.AnyPath:
+    """Windows does not support symlinking without admin support.
+    Copy files on windows but symlink everywhere else (see base Platform)."""
+    self.assert_is_local()
+    dst_path = self.path(dst)
+    shutil.copy(os.fspath(self.path(src)), os.fspath(dst_path))
+    return dst_path
diff --git a/crossbench/probes/__init__.py b/crossbench/probes/__init__.py
new file mode 100644
index 0000000..d271f03
--- /dev/null
+++ b/crossbench/probes/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/all.py b/crossbench/probes/all.py
new file mode 100644
index 0000000..a61798d
--- /dev/null
+++ b/crossbench/probes/all.py
@@ -0,0 +1,105 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Tuple, Type
+
+from crossbench.probes.android_logcat import AndroidLogcatProbe
+from crossbench.probes.chrome_histograms import ChromeHistogramsProbe
+from crossbench.probes.debugger import DebuggerProbe
+from crossbench.probes.dtrace import DTraceProbe
+from crossbench.probes.dump_html import DumpHtmlProbe
+from crossbench.probes.frequency import FrequencyProbe
+from crossbench.probes.helper import INTERNAL_NAME_PREFIX
+from crossbench.probes.internal import (DurationsProbe, ErrorsProbe,
+                                        InternalProbe, LogProbe,
+                                        ResultsSummaryProbe, SystemDetailsProbe)
+from crossbench.probes.js import JSProbe
+from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.perfetto.perfetto import PerfettoProbe
+from crossbench.probes.perfetto.trace_processor.trace_processor import \
+    TraceProcessorProbe
+from crossbench.probes.perfetto.tracing import TracingProbe
+from crossbench.probes.performance_entries import PerformanceEntriesProbe
+from crossbench.probes.polling import ShellPollingProbe
+from crossbench.probes.power_sampler import PowerSamplerProbe
+from crossbench.probes.powermetrics import PowerMetricsProbe
+from crossbench.probes.probe import Probe
+from crossbench.probes.profiling.browser_profiling import BrowserProfilingProbe
+from crossbench.probes.profiling.system_profiling import ProfilingProbe
+from crossbench.probes.screenshot import ScreenshotProbe
+from crossbench.probes.shell import ShellProbe
+from crossbench.probes.system_stats import SystemStatsProbe
+from crossbench.probes.thermal_monitor import ThermalMonitorProbe
+from crossbench.probes.v8.builtins_pgo import V8BuiltinsPGOProbe
+from crossbench.probes.v8.log import V8LogProbe
+from crossbench.probes.v8.rcs import V8RCSProbe
+from crossbench.probes.v8.turbolizer import V8TurbolizerProbe
+from crossbench.probes.video import VideoProbe
+from crossbench.probes.web_page_replay.recorder import WebPageReplayProbe
+
+ABSTRACT_PROBES: Tuple[Type[Probe], ...] = (Probe, JsonResultProbe)
+
+# Probes that are not user-configurable
+# Order matters, not alpha-sorted:
+# Internal probes depend on each other, for instance the ResultsSummaryProbe
+# reads the values of the other internal probes and thus needs to be the first
+# to be initialized and the last to be teared down to write out a summary
+# result of all the other probes.
+INTERNAL_PROBES: Tuple[Type[InternalProbe], ...] = (
+    ResultsSummaryProbe,
+    DurationsProbe,
+    ErrorsProbe,
+    LogProbe,
+    SystemDetailsProbe,
+    ThermalMonitorProbe,
+)
+# ResultsSummaryProbe should always be processed last, and thus must be the
+# first probe to be added to any browser.
+assert INTERNAL_PROBES[0] == ResultsSummaryProbe
+assert INTERNAL_PROBES[1] == DurationsProbe
+
+# Probes that can be used on arbitrary stories and may be user configurable.
+GENERAL_PURPOSE_PROBES: Tuple[Type[Probe], ...] = (
+    AndroidLogcatProbe,
+    BrowserProfilingProbe,
+    ChromeHistogramsProbe,
+    DTraceProbe,
+    DebuggerProbe,
+    DumpHtmlProbe,
+    FrequencyProbe,
+    JSProbe,
+    PerfettoProbe,
+    PerformanceEntriesProbe,
+    PowerMetricsProbe,
+    PowerSamplerProbe,
+    ProfilingProbe,
+    ScreenshotProbe,
+    ShellPollingProbe,
+    ShellProbe,
+    SystemStatsProbe,
+    TraceProcessorProbe,
+    TracingProbe,
+    V8BuiltinsPGOProbe,
+    V8LogProbe,
+    V8RCSProbe,
+    V8TurbolizerProbe,
+    VideoProbe,
+    WebPageReplayProbe,
+)
+
+for probe_cls in GENERAL_PURPOSE_PROBES:
+  assert probe_cls.IS_GENERAL_PURPOSE, (
+      f"Probe {probe_cls} should be marked for GENERAL_PURPOSE")
+  assert probe_cls.NAME
+  assert not probe_cls.NAME.startswith(INTERNAL_NAME_PREFIX), (
+      f"General purpose {probe_cls}.NAME cannot start with 'cb.'")
+
+for probe_cls in INTERNAL_PROBES:
+  assert not probe_cls.IS_GENERAL_PURPOSE, (
+      f"Internal Probe {probe_cls} should not marked for GENERAL_PURPOSE")
+  assert probe_cls.NAME
+  assert probe_cls.NAME.startswith(INTERNAL_NAME_PREFIX), (
+      f"Internal {probe_cls}.NAME must start with 'cb.'")
diff --git a/crossbench/probes/android_logcat.py b/crossbench/probes/android_logcat.py
new file mode 100644
index 0000000..ed1a259
--- /dev/null
+++ b/crossbench/probes/android_logcat.py
@@ -0,0 +1,96 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Iterable, Optional, Tuple, cast
+
+from crossbench.plt.android_adb import AndroidAdbPlatform
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeIncompatibleBrowser)
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.runner.run import Run
+
+
+class AndroidLogcatProbe(Probe):
+  """
+  Android-only probe to collect logcat traces.
+  """
+  NAME = "logcat"
+  RESULT_LOCATION = ResultLocation.LOCAL
+
+  IS_GENERAL_PURPOSE = True
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "filterspec",
+        type=str,
+        is_list=True,
+        default=tuple(),
+        help="Filter specifications are a series of <tag>[:priority]")
+    return parser
+
+  def __init__(self, filterspec: Iterable[str]):
+    super().__init__()
+    self._filterspec = tuple(filterspec)
+
+  @property
+  def filterspec(self) -> Tuple[str, ...]:
+    return self._filterspec
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    if not browser.platform.is_android:
+      raise ProbeIncompatibleBrowser(self, browser, "Only supported on android")
+
+  def get_context(self, run: Run) -> AndroidLogcatProbeContext:
+    return AndroidLogcatProbeContext(self, run)
+
+
+class AndroidLogcatProbeContext(ProbeContext[AndroidLogcatProbe]):
+
+  def __init__(self, probe: AndroidLogcatProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._logcat_start_time: Optional[str] = None
+
+  def _get_browser_platform_time(self) -> str:
+    return self.browser_platform.sh_stdout("date",
+                                           "+%Y-%m-%d %H:%M:%S").rstrip()
+
+  def _log_to_logcat(self, msg: str):
+    self.browser_platform.sh("log", "-t", "crossbench", msg)
+
+  @property
+  def browser_platform(self) -> AndroidAdbPlatform:
+    browser_platform = super().browser_platform
+    assert isinstance(browser_platform, AndroidAdbPlatform)
+    return cast(AndroidAdbPlatform, browser_platform)
+
+  def start(self) -> None:
+    self._logcat_start_time = self._get_browser_platform_time()
+    self._log_to_logcat("logcat probe start")
+
+  def stop(self) -> None:
+    self._log_to_logcat("logcat probe end")
+
+  def teardown(self) -> ProbeResult:
+    assert self._logcat_start_time
+    file = self.local_result_path.with_suffix(".txt")
+    with file.open("w", encoding="utf-8") as f:
+      self.host_platform.sh(
+          "adb",
+          "logcat",
+          "-t",
+          self._logcat_start_time + ".000",
+          *self.probe.filterspec,
+          stdout=f)
+
+    return LocalProbeResult(trace=(file,))
diff --git a/crossbench/probes/chrome_histograms.py b/crossbench/probes/chrome_histograms.py
new file mode 100644
index 0000000..8a8587e
--- /dev/null
+++ b/crossbench/probes/chrome_histograms.py
@@ -0,0 +1,372 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+import dataclasses
+import functools
+import logging
+import re
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence
+
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.browser import Browser
+from crossbench.env import HostEnvironment
+from crossbench.parse import ObjectParser
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
+from crossbench.probes.probe import ProbeConfigParser
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.run import Run
+  from crossbench.types import Json
+
+
+class ChromeHistogramMetric(abc.ABC):
+  """
+  Stores enough information to log a single metric from a diff between two UMA
+  histograms.
+  """
+
+  def __init__(self, name: str, histogram_name: str) -> None:
+    super().__init__()
+    self._name = name
+    self._histogram_name = histogram_name
+
+  @property
+  def name(self) -> str:
+    return self._name
+
+  @property
+  def histogram_name(self) -> str:
+    return self._histogram_name
+
+  @abc.abstractmethod
+  def compute(self, delta: ChromeHistogramSample,
+              baseline: ChromeHistogramSample) -> float:
+    pass
+
+
+class ChromeHistogramCountMetric(ChromeHistogramMetric):
+
+  def __init__(self, histogram_name: str):
+    super().__init__(f"{histogram_name}_count", histogram_name)
+
+  def compute(self, delta: ChromeHistogramSample,
+              baseline: ChromeHistogramSample) -> float:
+    return delta.diff_count(baseline)
+
+
+class ChromeHistogramMeanMetric(ChromeHistogramMetric):
+
+  def __init__(self, histogram_name: str):
+    super().__init__(f"{histogram_name}_mean", histogram_name)
+
+  def compute(self, delta: ChromeHistogramSample,
+              baseline: ChromeHistogramSample) -> float:
+    return delta.diff_mean(baseline)
+
+
+class ChromeHistogramPercentileMetric(ChromeHistogramMetric):
+
+  def __init__(self, histogram_name: str, percentile: int):
+    super().__init__(f"{histogram_name}_p{percentile}", histogram_name)
+    self._percentile = percentile
+
+  def compute(self, delta: ChromeHistogramSample,
+              baseline: ChromeHistogramSample) -> float:
+    return delta.diff_percentile(baseline, self._percentile)
+
+
+PERCENTILE_METRIC_RE = re.compile(r"^p(\d+)$")
+
+
+def parse_histogram_metrics(value: Any,
+                            name: str = "value"
+                           ) -> Sequence[ChromeHistogramMetric]:
+  result: List[ChromeHistogramMetric] = []
+  d = ObjectParser.dict(value, name)
+  for k, v in d.items():
+    histogram_name = ObjectParser.any_str(k, f"{name} name")
+    metrics = ObjectParser.non_empty_sequence(
+        v, f"{name} {histogram_name} metrics")
+    for x in metrics:
+      metric = ObjectParser.any_str(x)
+      if metric == "count":
+        result.append(ChromeHistogramCountMetric(histogram_name))
+      elif metric == "mean":
+        result.append(ChromeHistogramMeanMetric(histogram_name))
+      else:
+        m = re.match(PERCENTILE_METRIC_RE, metric)
+        if not m:
+          raise argparse.ArgumentTypeError(
+              f"{name} {histogram_name} {metric} is not a valid metric")
+        percentile = int(m[1])
+        if percentile < 0 or percentile > 100:
+          raise argparse.ArgumentTypeError(
+              f"{name} {histogram_name} {metric} is not a valid percentile")
+        result.append(
+            ChromeHistogramPercentileMetric(histogram_name, percentile))
+  return result
+
+
+class ChromeHistogramsProbe(JsonResultProbe):
+  """
+  Probe that collects UMA histogram metrics from Chrome.
+  """
+  NAME = "chrome_histograms"
+  RESULT_LOCATION = ResultLocation.LOCAL
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "metrics",
+        required=True,
+        type=parse_histogram_metrics,
+        help=("Required dictionary of Chrome UMA histogram metric names. "
+              "Histograms are recorded before and after a test and any "
+              "differences logged."))
+    return parser
+
+  def __init__(self, metrics: Sequence[ChromeHistogramMetric]) -> None:
+    super().__init__()
+    self._metrics = metrics
+
+  @property
+  def metrics(self) -> Sequence[ChromeHistogramMetric]:
+    return self._metrics
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    self.expect_browser(browser, BrowserAttributes.CHROMIUM_BASED)
+
+  def to_json(self, actions: Actions) -> Json:
+    raise NotImplementedError("should not be called, data comes from context")
+
+  def get_context(self, run: Run) -> ChromeHistogramsProbeContext:
+    return ChromeHistogramsProbeContext(self, run)
+
+
+@dataclasses.dataclass
+class ChromeHistogramBucket:
+  min: int
+  max: int
+  count: int
+
+
+ChromeHistogramBuckets = List[ChromeHistogramBucket]
+
+
+class ChromeHistogramSample:
+  """
+  Stores the contents of one UMA histogram and provides helpers to generate
+  metrics based on the difference between two samples.
+  """
+
+  # Generated by https://source.chromium.org/chromium/chromium/src/+/main:base/metrics/sample_vector.cc;l=520;drc=de573334f8fa97f9a7c99577611302736d2490b6
+  # Example histogram body lines (with whitespace shortened):
+  # "1326111536  -------------------O                              (19 = 63.3%)"
+  # "114   ---O                                              (3 = 3.1%) {92.7%}"
+  # "12  ... "
+  # "1000..."
+  _BUCKET_RE = re.compile(
+      r"^(-?\d+) *(?:(?:-*O "  # Bucket min and ASCII bar
+      r"+\((\d+) = \d+\.\d%\)(?: \{\d+\.\d%\}"  # Count and optional sum %
+      r")?)|(?:\.\.\. ))$"  # Or a "..." line
+  )
+
+  # Generated by https://source.chromium.org/chromium/chromium/src/+/main:base/metrics/sample_vector.cc;l=538;drc=de573334f8fa97f9a7c99577611302736d2490b6
+  # Example histogram header lines:
+  # "Histogram: UKM.InitSequence recorded 1 samples, mean = 1.0 (flags = 0x41)"
+  # "Histogram: WebUI.CreatedForUrl recorded 30 samples (flags = 0x41)"
+  _HEADER_RE = re.compile(r"^Histogram: +.* recorded (\d+) samples"
+                          r"(?:, mean = (-?\d+\.\d+))?"
+                          r" \(flags = (0x[0-9A-Fa-f]+)\)$")
+
+  @classmethod
+  def from_json(cls, histogram_dict: Dict) -> ChromeHistogramSample:
+    name = ObjectParser.any_str(histogram_dict["name"], "histogram name")
+    header = ObjectParser.any_str(histogram_dict["header"], "histogram header")
+    body = ObjectParser.any_str(histogram_dict["body"], "histogram body")
+
+    m = re.match(cls._HEADER_RE, header)
+    if not m:
+      raise argparse.ArgumentTypeError(
+          f"{name} histogram header has invalid data: {header}")
+    count = int(m.group(1))
+    mean = float(m.group(2)) if m.group(2) is not None else None
+    flags = int(m.group(3), 16)
+
+    bucket_counts: Dict[int, int] = {}
+    bucket_maxes: Dict[int, int] = {}
+    prev_min: Optional[int] = None
+    for i, line in enumerate(body.splitlines(), start=1):
+      m = re.match(cls._BUCKET_RE, line)
+      if not m:
+        raise argparse.ArgumentTypeError(
+            f"{name} histogram body line {i} has invalid data: {line}")
+
+      bucket_min = int(m.group(1))
+
+      # Previous bucket's max is this bucket's min.
+      if prev_min is not None:
+        bucket_maxes[prev_min] = bucket_min
+      prev_min = bucket_min
+
+      if bucket_count_str := m.group(2):
+        bucket_count = int(bucket_count_str)
+        if bucket_count > 0:
+          bucket_counts[bucket_min] = bucket_count
+    return ChromeHistogramSample(name, count, mean, flags, bucket_counts,
+                                 bucket_maxes)
+
+  def __init__(self,
+               name: str,
+               count: int = 0,
+               mean: Optional[float] = 0,
+               flags: int = 0,
+               bucket_counts: Optional[Dict[int, int]] = None,
+               bucket_maxes: Optional[Dict[int, int]] = None):
+    self._name = name
+    self._count = count
+    self._mean = mean
+    self._flags = flags
+    self._bucket_counts = bucket_counts or {}
+    self._bucket_maxes = bucket_maxes or {}
+    bucket_sum = sum(self._bucket_counts.values())
+    if count != bucket_sum:
+      raise ValueError(f"Histogram {name} has {count} total samples, "
+                       f"but buckets add to {bucket_sum}")
+
+  @property
+  def mean(self) -> Optional[float]:
+    return self._mean
+
+  @property
+  def count(self) -> int:
+    return self._count
+
+  def bucket_max(self, bucket_min: int) -> Optional[int]:
+    return self._bucket_maxes.get(bucket_min)
+
+  def bucket_count(self, bucket_min: int) -> int:
+    return self._bucket_counts.get(bucket_min, 0)
+
+  def diff_buckets(self,
+                   baseline: ChromeHistogramSample) -> ChromeHistogramBuckets:
+    buckets: ChromeHistogramBuckets = []
+    for bucket_min, bucket_count in self._bucket_counts.items():
+      bucket_count = bucket_count - baseline.bucket_count(bucket_min)
+      bucket_max: Optional[int] = self._bucket_maxes.get(bucket_min)
+      buckets.append(
+          ChromeHistogramBucket(bucket_min, bucket_max, bucket_count))
+    return buckets
+
+  def diff_percentile(self, baseline: ChromeHistogramSample,
+                      percentile: int) -> float:
+    if percentile < 0 or percentile > 100:
+      raise ValueError(f"{percentile} is not a valid percentile")
+    buckets = self.diff_buckets(baseline)
+    count = functools.reduce(lambda s, b: b.count + s, buckets, 0)
+    if count == 0:
+      raise ValueError(
+          f"{self._name} can not compute percentile without any samples")
+    target = count * percentile / 100
+    for bucket in buckets:
+      if target <= bucket.count:
+        if bucket.max is None:
+          return bucket.min
+        # Assume all samples are evenly distributed within the bucket.
+        # NB: 0 <= target <= bucket_count
+        t = target / (bucket.count + 1)
+        return bucket.min * (1 - t) + bucket.max * t
+      target -= bucket.count
+    raise ValueError("overflowed histogram buckets looking for percentile")
+
+  def diff_mean(self, baseline: ChromeHistogramSample) -> float:
+    count = self._count - baseline.count
+    if count <= 0:
+      raise ValueError(f"{self._name} can not compute mean without any samples")
+    if self._mean is None or baseline.mean is None:
+      raise ValueError(
+          f"{self._name} has no mean reported, is it an enum histogram?")
+
+    return (self._mean * self._count - baseline.mean * baseline.count) / count
+
+  def diff_count(self, baseline: ChromeHistogramSample) -> int:
+    return self._count - baseline.count
+
+  @property
+  def name(self) -> str:
+    return self._name
+
+
+class ChromeHistogramsProbeContext(JsonResultProbeContext[ChromeHistogramsProbe]
+                                  ):
+
+  # JS code that overrides the chrome.send response handler and requests
+  # histograms.
+  HISTOGRAM_SEND = """
+function webUIResponse(id, isSuccess, response) {
+  if (id === "crossbench_histograms_1") {
+    window.crossbench_histograms = response;
+  }
+}
+window.cr.webUIResponse = webUIResponse;
+chrome.send("requestHistograms", ["crossbench_histograms_1", "", true]);
+"""
+
+  # JS code that checks if there is a histogram response.
+  HISTOGRAM_WAIT = "return !!window.crossbench_histograms"
+
+  # JS code that returns the histograms response.
+  HISTOGRAM_DATA = "return window.crossbench_histograms"
+
+  def __init__(self, probe: ChromeHistogramsProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._baseline: Optional[Dict[str, ChromeHistogramSample]] = None
+    self._delta: Optional[Dict[str, ChromeHistogramSample]] = None
+
+  def dump_histograms(self, name: str) -> Dict[str, ChromeHistogramSample]:
+    with self.run.actions(
+        f"Probe({self.probe.name}) dump histograms {name}") as actions:
+      actions.show_url("chrome://histograms")
+      actions.js(self.HISTOGRAM_SEND)
+      actions.wait_js_condition(self.HISTOGRAM_WAIT, 0.1, 10.0)
+      data = actions.js(self.HISTOGRAM_DATA)
+      histogram_list = ObjectParser.sequence(data)
+      histograms: Dict[str, ChromeHistogramSample] = {}
+      for histogram_dict in histogram_list:
+        histogram = ChromeHistogramSample.from_json(
+            ObjectParser.dict(histogram_dict))
+        histograms[histogram.name] = histogram
+      return histograms
+
+  def start(self) -> None:
+    self._baseline = self.dump_histograms("start")
+    super().start()
+
+  def stop(self) -> None:
+    self._delta = self.dump_histograms("stop")
+    super().stop()
+
+  def to_json(self, actions: Actions) -> Json:
+    del actions
+    assert self._baseline, "Did not extract start histograms"
+    assert self._delta, "Did not extract end histograms"
+    json = {}
+    for metric in self.probe.metrics:
+      baseline = self._baseline.get(
+          metric.histogram_name, ChromeHistogramSample(metric.histogram_name))
+      delta = self._delta.get(metric.histogram_name,
+                              ChromeHistogramSample(metric.histogram_name))
+      try:
+        json[metric.name] = metric.compute(delta, baseline)
+      except Exception as e:  # pylint: disable=broad-exception-caught
+        logging.warning("Failed to log metric %s: %s", metric.name, e)
+    return json
diff --git a/crossbench/probes/chromium_probe.py b/crossbench/probes/chromium_probe.py
new file mode 100644
index 0000000..a672657
--- /dev/null
+++ b/crossbench/probes/chromium_probe.py
@@ -0,0 +1,21 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.probes.probe import Probe
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+
+
+class ChromiumProbe(Probe):
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    self.expect_browser(browser, BrowserAttributes.CHROMIUM_BASED)
diff --git a/crossbench/probes/cpu_frequency_map.py b/crossbench/probes/cpu_frequency_map.py
new file mode 100644
index 0000000..b402302
--- /dev/null
+++ b/crossbench/probes/cpu_frequency_map.py
@@ -0,0 +1,161 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from abc import ABCMeta, abstractmethod
+import argparse
+import re
+from typing import Any, Dict, Hashable, List, Pattern, TYPE_CHECKING, Type, Union
+
+from immutabledict import immutabledict
+
+from crossbench import exception
+from crossbench import path as pth
+from crossbench.compat import StrEnum
+from crossbench.config import ConfigObject
+from crossbench.parse import NumberParser, ObjectParser
+if TYPE_CHECKING:
+  from crossbench.plt.base import Platform
+
+# Directory exposing info & controls for the frequency of all CPUs.
+_CPUS_DIR: pth.AnyPosixPath = pth.AnyPosixPath("/sys/devices/system/cpu")
+
+# Used to specify behavior for all CPUs.
+_WILDCARD_CONFIG_KEY = "*"
+
+# Matches the CPU names exposed by the system in _CPUS_DIR.
+_CPU_NAME_REGEX: Pattern[str] = re.compile("cpu[0-9]+$")
+
+
+class _ExtremeFrequency(StrEnum):
+  MAX = "max"
+  MIN = "min"
+
+
+if TYPE_CHECKING:
+  FrequencyType = Union[_ExtremeFrequency, int]
+
+
+class CPUFrequencyMap(ConfigObject, metaclass=ABCMeta):
+
+  @abstractmethod
+  def get_target_frequencies(
+      self, platform: Platform) -> immutabledict[pth.AnyPosixPath, int]:
+    raise NotImplementedError()
+
+  @property
+  @abstractmethod
+  def key(self) -> Hashable:
+    raise NotImplementedError()
+
+  @classmethod
+  def parse_dict(cls: Type[CPUFrequencyMap],
+                 config: Dict[str, Any]) -> CPUFrequencyMap:
+    if _WILDCARD_CONFIG_KEY in config:
+      return WildcardCPUFrequencyMap(config)
+
+    return ExplicitCPUFrequencyMap(config)
+
+  @classmethod
+  def parse_str(cls: Type[CPUFrequencyMap], value: str) -> CPUFrequencyMap:
+    return CPUFrequencyMap.parse_dict({_WILDCARD_CONFIG_KEY: value})
+
+  @classmethod
+  def _parse_frequency(cls, value: Any) -> FrequencyType:
+    if value == _ExtremeFrequency.MIN:
+      return _ExtremeFrequency.MIN
+
+    if value == _ExtremeFrequency.MAX:
+      return _ExtremeFrequency.MAX
+
+    try:
+      return NumberParser.positive_zero_int(value)
+    except argparse.ArgumentTypeError as e:
+      raise argparse.ArgumentTypeError(
+          f"Invalid value in CPU frequency map: {value}. Should "
+          "have been one of \"max\"|\"min\"|<int>|\"<int>\"") from e
+
+  def _get_target_frequency(self, platform: Platform, cpu_name: str,
+                            frequency: FrequencyType) -> int:
+    if not platform.exists(_CPUS_DIR):
+      # TODO(crbug.com/372862708): If different devices indeed use different
+      # dirs, consider making this configurable in the jSON.
+      raise FileNotFoundError(
+          f"{_CPUS_DIR} not found. Either {platform} does not support setting "
+          "CPU frequency or the CPUs are exposed in another path and that "
+          "requires extra support.")
+
+    cpu_dir: pth.AnyPosixPath = self._get_cpu_dir(cpu_name)
+    if not platform.is_dir(cpu_dir):
+      raise ValueError(f"Invalid CPU name: {cpu_name}.")
+
+    available_frequencies: List[int] = [
+        NumberParser.positive_zero_int(f)
+        for f in platform.cat(cpu_dir / "scaling_available_frequencies").rstrip(
+            "\n").rstrip(" ").split(" ")
+    ]
+    if frequency == _ExtremeFrequency.MIN:
+      return min(available_frequencies)
+    if frequency == _ExtremeFrequency.MAX:
+      return max(available_frequencies)
+    if frequency in available_frequencies:
+      assert isinstance(frequency, int)
+      return frequency
+    raise ValueError(f"Target frequency {frequency} for {cpu_name} "
+                     f"not allowed in {platform}. Available frequencies: "
+                     f"{available_frequencies}")
+
+  def _get_cpu_dir(self, cpu_name: str) -> pth.AnyPosixPath:
+    # Create new AnyPosixPath so pyfakefs is happy in tests.
+    return pth.AnyPosixPath(_CPUS_DIR / cpu_name / "cpufreq")
+
+
+class WildcardCPUFrequencyMap(CPUFrequencyMap):
+
+  def __init__(self, frequencies: Dict):
+    if len(frequencies) != 1:
+      raise argparse.ArgumentTypeError(
+          f"A wildcard ({_WILDCARD_CONFIG_KEY}) in "
+          "the CPU frequency map should be the only key.")
+
+    self._target_frequency = CPUFrequencyMap._parse_frequency(
+        list(frequencies.values())[0])
+
+  def get_target_frequencies(
+      self, platform: Platform) -> immutabledict[pth.AnyPosixPath, int]:
+    return immutabledict({
+        self._get_cpu_dir(p.name):
+            self._get_target_frequency(platform, p.name, self._target_frequency)
+        for p in platform.iterdir(_CPUS_DIR)
+        if _CPU_NAME_REGEX.match(p.name)
+    })
+
+  @property
+  def key(self) -> Hashable:
+    return self._target_frequency
+
+
+class ExplicitCPUFrequencyMap(CPUFrequencyMap):
+
+  def __init__(self, frequencies: Dict):
+    typed_map: Dict[str, FrequencyType] = {}
+    for k, v in frequencies.items():
+      with exception.annotate_argparsing(f"Parsing cpu frequency: {k}, {v}"):
+        typed_map[ObjectParser.non_empty_str(k)] = (
+            CPUFrequencyMap._parse_frequency(v))
+    self._frequencies: immutabledict[str, Union[_ExtremeFrequency,
+                                                int]] = immutabledict(typed_map)
+
+  def get_target_frequencies(
+      self, platform: Platform) -> immutabledict[pth.AnyPosixPath, int]:
+    return immutabledict({
+        self._get_cpu_dir(cpu_name):
+            self._get_target_frequency(platform, cpu_name, config_frequeny)
+        for cpu_name, config_frequeny in self._frequencies.items()
+    })
+
+  @property
+  def key(self) -> Hashable:
+    return self._frequencies
diff --git a/crossbench/probes/debugger.py b/crossbench/probes/debugger.py
new file mode 100644
index 0000000..e7d0063
--- /dev/null
+++ b/crossbench/probes/debugger.py
@@ -0,0 +1,162 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import shlex
+from typing import TYPE_CHECKING, Dict, Iterable
+
+from crossbench import plt
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.parse import PathParser
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeKeyT, ProbeValidationError)
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.path import LocalPath
+  from crossbench.runner.run import Run
+
+_DEBUGGER_LOOKUP: Dict[str, str] = {
+    "macos": "lldb",
+    "linux": "gdb",
+}
+
+DEFAULT_GEOMETRY = "80x70"
+
+
+class DebuggerProbe(Probe):
+  """
+  Probe debugging chrome's renderer process.
+  """
+  NAME = "debugger"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  IS_GENERAL_PURPOSE = True
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "debugger",
+        type=PathParser.binary_path,
+        default=_DEBUGGER_LOOKUP.get(plt.PLATFORM.name,
+                                     "debugger probe not supported"),
+        help="Set a custom debugger binary. "
+        "Currently only gdb and lldb are supported.")
+    parser.add_argument(
+        "auto_run",
+        type=bool,
+        default=True,
+        help="Automatically start the renderer process in the debugger.")
+    parser.add_argument(
+        "spare_renderer_process",
+        type=bool,
+        default=False,
+        help=("Chrome-only: Enable/Disable spare renderer processes via \n"
+              "--enable-/--disable-features=SpareRendererForSitePerProcess.\n"
+              "Spare renderers are disabled by default when profiling "
+              "for fewer uninteresting processes."))
+    parser.add_argument(
+        "geometry",
+        type=str,
+        default=DEFAULT_GEOMETRY,
+        help="Geometry of the terminal (xterm) used to display the debugger.")
+    parser.add_argument(
+        "args",
+        type=str,
+        default=tuple(),
+        is_list=True,
+        help="Additional args that are passed to the debugger.")
+    return parser
+
+  def __init__(
+      self,
+      debugger: LocalPath,
+      auto_run: bool = True,
+      spare_renderer_process: bool = False,
+      geometry: str = DEFAULT_GEOMETRY,
+      args: Iterable[str] = ()) -> None:
+    super().__init__()
+    self._debugger_bin = debugger
+    self._debugger_args = args
+    self._auto_run = auto_run
+    self._geometry = geometry
+    self._spare_renderer_process = spare_renderer_process
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("debugger", str(self._debugger_bin)),
+        ("debugger_args", tuple(self._debugger_args)),
+        ("auto_run", self._auto_run),
+        ("geometry", str(self._geometry)),
+        ("spare_renderer_process", self._spare_renderer_process),
+    )
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    self.expect_browser(browser, BrowserAttributes.CHROMIUM_BASED)
+    # TODO: support more platforms
+    if not (browser.platform.is_macos or browser.platform.is_linux):
+      raise ValueError(f"Only supported on linux and macOS, but got {browser}")
+    if browser.platform.is_remote:
+      raise ProbeValidationError(self, "Does not run on remote platforms.")
+    # TODO: support more terminals.
+    if not browser.platform.which("xterm"):
+      raise ProbeValidationError(self, "Please install xterm on your system.")
+
+  def attach(self, browser: Browser) -> None:
+    super().attach(browser)
+    assert browser.attributes.is_chromium_based
+    flags = browser.flags
+    flags.set("--no-sandbox")
+    flags.set("--disable-hang-monitor")
+    flags["--renderer-cmd-prefix"] = self.renderer_cmd_prefix()
+    if not self._spare_renderer_process:
+      browser.features.disable("SpareRendererForSitePerProcess")
+
+  def renderer_cmd_prefix(self) -> str:
+    # TODO: support more terminals.
+    debugger_cmd = [
+        "xterm",
+        "-title",
+        "renderer",
+        "-geometry",
+        self._geometry,
+        "-e",
+        str(self._debugger_bin),
+    ]
+    if self._debugger_bin.name == "lldb":
+      if self._auto_run:
+        debugger_cmd += ["-o", "run"]
+      if self._debugger_args:
+        debugger_cmd.extend(self._debugger_args)
+      debugger_cmd += ["--"]
+    else:
+      assert self._debugger_bin.name == "gdb", (
+          f"Unsupported debugger: {self._debugger_bin}")
+      if self._auto_run:
+        debugger_cmd += ["-ex", "run"]
+      if self._debugger_args:
+        debugger_cmd.extend(self._debugger_args)
+      debugger_cmd += ["--args"]
+    return shlex.join(debugger_cmd)
+
+  def get_context(self, run: Run) -> DebuggerContext:
+    return DebuggerContext(self, run)
+
+
+class DebuggerContext(ProbeContext[DebuggerProbe]):
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    return EmptyProbeResult()
diff --git a/crossbench/probes/dtrace.py b/crossbench/probes/dtrace.py
new file mode 100644
index 0000000..ccd76d7
--- /dev/null
+++ b/crossbench/probes/dtrace.py
@@ -0,0 +1,149 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import subprocess
+from typing import TYPE_CHECKING, Optional, TextIO
+
+from crossbench.parse import PathParser
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeKeyT, ProbeValidationError)
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.path import LocalPath
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+
+
+class DTraceProbe(Probe):
+  """
+  Probe to collect data using DTrace.
+  """
+
+  NAME = "dtrace"
+  RESULT_LOCATION = ResultLocation.BROWSER
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument("script_path", type=PathParser.non_empty_file_path)
+    return parser
+
+  def __init__(self, script_path: LocalPath):
+    super().__init__()
+    self._script_path = script_path.resolve()
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (("script_path", str(self.script_path)),)
+
+  @property
+  def script_path(self) -> LocalPath:
+    return self._script_path
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    self.expect_macos(browser)
+
+    # Check that it is possible to execute "sudo dtrace" without prompting for a
+    # password. The best way to do this is to actually run the command and check
+    # the return value of `sudo`.
+    #
+    # Under normal usage, DTrace expects an input script file and returns "2"
+    # when it is missing. To force a return value of zero, without actually
+    # providing a valid script file, the "-l -P $dtrace_probe_name" argument is
+    # used, which tells DTrace to simply print all DTrace probes (do not confuse
+    # with crossbench probes) whose name matches $dtrace_probe_name. This will
+    # ensure the command either succeeds or fails fast. Use a non-existent probe
+    # name to reduce output size
+    dtrace_probe_name = "nonexistantprobename"
+    # Execute and check the returncode, while ignoring output.
+    try:
+      browser.platform.sh(
+          "sudo",
+          "-n",
+          "dtrace",
+          "-l",
+          "-P",
+          dtrace_probe_name,
+          stdout=subprocess.DEVNULL,
+          stderr=subprocess.STDOUT)
+    except subprocess.CalledProcessError as e:
+      raise ProbeValidationError(
+          self, "Cannot execute 'sudo dtrace'. "
+          "This probe will fail to start.") from e
+
+  def get_context(self, run: Run) -> DTraceProbeContext:
+    return DTraceProbeContext(self, run)
+
+
+class DTraceProbeContext(ProbeContext[DTraceProbe]):
+
+  def __init__(self, probe: DTraceProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._script_path: LocalPath = probe.script_path
+    self._output_path: LocalPath = (
+        self.local_result_path.with_suffix(".output.txt"))
+    self._log_path: LocalPath = self.local_result_path.with_suffix(".log")
+    self._dtrace_process: Optional[subprocess.Popen] = None
+    self._log_file: Optional[TextIO] = None
+    atexit.register(self.stop_dtrace_process)
+
+  def start(self) -> None:
+    self._log_file = self._log_path.open("w", encoding="utf-8")
+    # TODO: copy over script to remote machine
+    assert self.browser_platform.is_local, "Remote dtrace not supported yet"
+    self._dtrace_process = self.browser_platform.popen(
+        "sudo",
+        "-n",
+        "dtrace",
+        "-p",
+        str(self.browser_pid),
+        "-o",
+        self._output_path,
+        "-s",
+        self._script_path,
+        stdout=self._log_file,
+        stderr=self._log_file,
+    )
+    assert self._dtrace_process is not None, ("Could not start DTrace")
+
+  def stop(self) -> None:
+    if not self._dtrace_process:
+      return
+    # DTrace will close by itself once the browser exits.
+    returncode = self._dtrace_process.poll()
+    if returncode is not None:
+      # Print an error message if DTrace was already closed.
+      if returncode == 0:
+        raise RuntimeError("DTrace exited early without errors.")
+      raise RuntimeError(f"DTrace exited early with error {returncode}.\n"
+                         f"Check {self._log_path} for the program's log.")
+
+  def teardown(self) -> ProbeResult:
+    self.stop_dtrace_process()
+    assert self._log_file, "Did not open log file."
+    self._log_file.close()
+    return self.browser_result(file=(self._output_path,))
+
+  def stop_dtrace_process(self) -> None:
+    if self._dtrace_process:
+      try:
+        # Wait for the process to terminate normally.
+        returncode = self._dtrace_process.wait(timeout=5)
+        if returncode != 0:
+          raise RuntimeError(f"DTrace exited with error {returncode}.\n"
+                             f"Check {self._log_path} for the program's log.")
+      except subprocess.TimeoutExpired:
+        # DTrace took too long to terminate. Send SIGKILL.
+        # Note: Not using .kill() because the process was started with sudo so
+        # it would raise an PermissionError exception.
+        subprocess.run(
+            ["sudo", "-n", "kill", "-SIGKILL", f"{self._dtrace_process.pid}"],
+            check=True)
diff --git a/crossbench/probes/dump_html.py b/crossbench/probes/dump_html.py
new file mode 100644
index 0000000..69ba7b8
--- /dev/null
+++ b/crossbench/probes/dump_html.py
@@ -0,0 +1,77 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+
+import os
+from typing import List, Optional
+
+from crossbench.path import AnyPath
+from crossbench.probes.probe import Probe, ProbeConfigParser
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+from crossbench.runner.groups.browsers import BrowsersRunGroup
+from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+from crossbench.runner.run import Run
+
+
+class DumpHtmlProbe(Probe):
+  """
+  General-purpose Probe that collects HTML dumps.
+  """
+  NAME = "dump_html"
+  RESULT_LOCATION = ResultLocation.LOCAL
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    # TODO: support stop dumps
+    return parser
+
+  def get_context(self, run: Run) -> DumpHtmlProbeContext:
+    return DumpHtmlProbeContext(self, run)
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    # TODO: implement
+    return EmptyProbeResult()
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    # TODO: implement
+    return EmptyProbeResult()
+
+
+class DumpHtmlProbeContext(ProbeContext[DumpHtmlProbe]):
+
+  def __init__(self, probe: DumpHtmlProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._results: List[AnyPath] = []
+
+  def get_default_result_path(self) -> AnyPath:
+    dump_dir = super().get_default_result_path()
+    os.mkdir(dump_dir)
+    return dump_dir
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def dump_html(self, label: Optional[str] = None) -> None:
+    if not label:
+      label = str(dt.datetime.now().strftime("%Y-%m-%d_%H%M%S"))
+    path = self.result_path / f"{label}.html"
+    html = self.browser.js("return document.children[0].outerHTML",
+                           dt.timedelta(seconds=10))
+    with open(path, "w", encoding="utf-8") as dump_file:
+      dump_file.write(html)
+    self._results.append(path)
+
+  def teardown(self) -> ProbeResult:
+    if not self.browser_platform.is_dir(self.result_path):
+      return EmptyProbeResult()
+    return self.browser_result(file=tuple(self._results))
diff --git a/crossbench/probes/env_modifier.py b/crossbench/probes/env_modifier.py
new file mode 100644
index 0000000..4df77da
--- /dev/null
+++ b/crossbench/probes/env_modifier.py
@@ -0,0 +1,15 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from crossbench.probes.probe import Probe
+
+
+class EnvModifier(Probe):
+  """
+  A class that modifies the running environment without actually producing
+  data like a Probe.
+
+  TODO(crbug.com/374017625): Add more logic here, and maybe not inherit from
+  Probe.
+  """
diff --git a/crossbench/probes/frequency.py b/crossbench/probes/frequency.py
new file mode 100644
index 0000000..64e1c4e
--- /dev/null
+++ b/crossbench/probes/frequency.py
@@ -0,0 +1,147 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import dataclasses
+from typing import List
+
+from immutabledict import immutabledict
+
+from crossbench import path as pth
+from crossbench.browsers.browser import Browser
+from crossbench.probes.cpu_frequency_map import CPUFrequencyMap
+from crossbench.env import HostEnvironment
+from crossbench.probes.env_modifier import EnvModifier
+from crossbench.probes.probe import (ProbeConfigParser, ProbeContext, ProbeKeyT)
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+from crossbench.runner.run import Run
+
+
+class FrequencyProbe(EnvModifier):
+  """
+  Probe to pin a frequency for certain parts of the system, e.g. CPUs and
+  memory on platforms with SysFS (Linux and Android). As of 10/2024, only CPUs
+  are supported. The probe can be configured as follows:
+
+  // Probe config HJSON.
+  frequency: {
+    cpus: {
+      cpu0: 1111,
+      cpu1: "min", // Will use the minimum allowed frequency.
+      cpu2: "max"  // Will use the maximum allowed frequency.
+    }
+  }
+
+  Generally, the system only allows a certain set of frequency values (for CPUs
+  the values can be found in [1]). Using an invalid value in the probe config
+  will cause a runtime error, but also print the list of valid values. Numerical
+  values can be specified as both integers (1111) and strings ("1111").
+
+  Wildcards are supported in 2 ways:
+
+  frequency: {
+    cpus: "max"
+  }
+
+
+  frequency: {
+    cpus: {
+      // When * is used, there should be no other keys in the map.
+      *: "max"
+    }
+  }
+
+  Note that when running with different platforms (e.g.
+  --browser=android:chrome-stable --browser=linux:chrome-stable), "*", "min"
+  and "max" might mean different things for each platform.
+
+  [1] https://docs.kernel.org/admin-guide/pm/cpufreq.html#:~:text=scaling_available_frequencies
+  """
+
+  NAME = "frequency"
+
+  IS_GENERAL_PURPOSE = True
+  PRODUCES_DATA = False
+
+  def __init__(self, cpus: CPUFrequencyMap):
+    super().__init__()
+    self._cpu_frequency_map: CPUFrequencyMap = cpus
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "cpus",
+        type=CPUFrequencyMap,
+        default=CPUFrequencyMap.parse({}),
+        help="CPU frequency map, see FrequencyProbe docs")
+    return parser
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (("cpus", self._cpu_frequency_map.key),)
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    # As long as a valid platform map can be derived, all is good.
+    self._cpu_frequency_map.get_target_frequencies(browser.platform)
+
+  @property
+  def cpu_frequency_map(self) -> CPUFrequencyMap:
+    return self._cpu_frequency_map
+
+  def get_context(self, run: Run):
+    return FrequencyProbeContext(self, run)
+
+
+@dataclasses.dataclass(frozen=True)
+class _FrequencyState:
+  dir: pth.AnyPosixPath
+  min: str
+  max: str
+
+
+class FrequencyProbeContext(ProbeContext[FrequencyProbe]):
+
+  _MIN_FREQUENCY_FILE: str = "scaling_min_freq"
+  _MAX_FREQUENCY_FILE: str = "scaling_max_freq"
+
+
+  def __init__(self, probe: FrequencyProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._previous_frequencies: List[_FrequencyState] = []
+
+  def start(self) -> None:
+    target_cpu_frequencies: immutabledict[pth.AnyPosixPath, int] = (
+        self.probe.cpu_frequency_map.get_target_frequencies(
+            self.browser_platform))
+    for cpu_dir in target_cpu_frequencies.keys():
+      self._previous_frequencies.append(
+          _FrequencyState(
+              dir=cpu_dir,
+              min=self.browser_platform.cat(cpu_dir / self._MIN_FREQUENCY_FILE),
+              max=self.browser_platform.cat(cpu_dir /
+                                            self._MAX_FREQUENCY_FILE)))
+
+    try:
+      for cpu_dir, frequency in target_cpu_frequencies.items():
+        self.browser_platform.set_file_contents(
+            cpu_dir / self._MIN_FREQUENCY_FILE, f"{frequency}\n")
+        self.browser_platform.set_file_contents(
+            cpu_dir / self._MAX_FREQUENCY_FILE, f"{frequency}\n")
+    except Exception:
+      self._restore_frequencies()
+      raise
+
+  def stop(self) -> None:
+    self._restore_frequencies()
+
+  def _restore_frequencies(self) -> None:
+    for state in self._previous_frequencies:
+      self.browser_platform.set_file_contents(
+          state.dir / self._MIN_FREQUENCY_FILE, state.min)
+      self.browser_platform.set_file_contents(
+          state.dir / self._MAX_FREQUENCY_FILE, state.max)
+
+  def teardown(self) -> ProbeResult:
+    return EmptyProbeResult()
diff --git a/crossbench/probes/helper.py b/crossbench/probes/helper.py
new file mode 100644
index 0000000..2830c07
--- /dev/null
+++ b/crossbench/probes/helper.py
@@ -0,0 +1,247 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import csv
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, List, Optional,
+                    Sequence, Set, Tuple)
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+
+INTERNAL_NAME_PREFIX: Final[str] = "cb."
+
+KeyFnType = Callable[[Tuple[str, ...]], Optional[str]]
+
+
+def _default_flatten_key_fn(path: Tuple[str, ...]) -> str:
+  return "/".join(path)
+
+
+class Flatten:
+  """
+  Creates a sorted flat list of (key-path, Metric) from hierarchical data.
+
+  input = {"a" : {"aa1":1, "aa2":2}, "b": 12 }
+  Flatten(input).data == {
+    "a/aa1":  1,
+    "a/aa2":  2,
+    "b":     12,
+  }
+  """
+  _key_fn: KeyFnType
+  _accumulator: Dict[str, Any]
+
+  def __init__(self,
+               *args: Dict,
+               key_fn: Optional[KeyFnType] = None,
+               sort: bool = True) -> None:
+    """_summary_
+
+    Args:
+        *args (optional): Optional hierarchical data to be flattened
+        key_fn (optional): Maps property paths (Tuple[str,...]) to strings used
+          as final result keys, or None to skip property paths.
+    """
+    self._accumulator = {}
+    self._key_fn = key_fn or _default_flatten_key_fn
+    self._sort = sort
+    self.append(*args)
+
+  @property
+  def data(self) -> Dict[str, Any]:
+    if not self._sort:
+      return dict(self._accumulator)
+    items = sorted(self._accumulator.items(), key=lambda item: item[0])
+    return dict(items)
+
+  def append(self, *args: Dict, ignore_toplevel: bool = False) -> None:
+    toplevel_path: Tuple[str, ...] = tuple()
+    for merged_data in args:
+      self._flatten(toplevel_path, merged_data, ignore_toplevel)
+
+  def _is_leaf_item(self, item: Any) -> bool:
+    if isinstance(item, (str, float, int, list)):
+      return True
+    if "values" in item and isinstance(item["values"], list):
+      return True
+    return False
+
+  def _flatten(self,
+               parent_path: Tuple[str, ...],
+               data,
+               ignore_toplevel: bool = False) -> None:
+    for name, item in data.items():
+      if item is None:
+        continue
+      path = parent_path + (name,)
+      if self._is_leaf_item(item):
+        if ignore_toplevel and parent_path == ():
+          continue
+        key = self._key_fn(path)
+        if key is None:
+          continue
+        assert isinstance(key, str)
+        if key in self._accumulator:
+          raise ValueError(f"Duplicate key='{key}' path={path}")
+        self._accumulator[key] = item
+      else:
+        self._flatten(path, item)
+
+
+def _ljust_row(sequence: List, n: int, fill_value: Any = None) -> List:
+  return sequence + ([fill_value] * (n - len(sequence)))
+
+
+def merge_csv(csv_list: Sequence[LocalPath],
+              headers: Optional[List[str]] = None,
+              row_header_len: int = 1,
+              delimiter: str = "\t") -> List[List[Any]]:
+  """
+  Merge multiple CSV files.
+  File 1:
+    Header,     Col Header 1.1, Col Header  1.2
+    ...
+    Row Header, Data 1.1,       Data 1.2
+
+  File 2:
+    Header,     Col Header 2.1,
+    ...
+    Row Header, Data 2.1,
+
+  The first Col has to contain the same data:
+
+  Merged:
+    Header,     Col Header 1.1, Col Header 1.2,  Col Header 2.1,
+    ...
+    Row Header, Data 1.1,       Data 1.2,        Data 2.1,
+
+
+  If no column header is available, filename_as_header=True can be used.
+
+  Merged with file name header:
+            , File 1,           , File 2,
+  Row Header, Data 1.1, Data 1.2, Data 2.1, Data 2.2
+  """
+  table: List[List[Any]] = []
+  # Initial row-headers from the first csv file.
+  known_row_headers: Set[Tuple[str, ...]] = set()
+  row_header_len = _merge_csv_prepare_row_headers(table, known_row_headers,
+                                                  csv_list[0], row_header_len,
+                                                  delimiter)
+
+  # Fill in the header column taken from the first file
+  if headers:
+    table_headers = [None] * row_header_len
+  else:
+    table_headers = []
+
+  table_row_len = row_header_len
+  for csv_file in csv_list:
+    with csv_file.open(encoding="utf-8") as f:
+      csv_data = list(csv.reader(f, delimiter=delimiter))
+    table_row_len = _merge_csv_append(csv_data, table, table_headers,
+                                      row_header_len, headers,
+                                      known_row_headers, table_row_len)
+
+  if table_headers:
+    return [table_headers] + table
+  return table
+
+
+def _merge_csv_prepare_row_headers(table: List[List[Any]],
+                                   known_row_headers: Set[Tuple[str, ...]],
+                                   csv_file: LocalPath, row_header_len: int,
+                                   delimiter: str):
+  with csv_file.open(encoding="utf-8") as first_file:
+    for csv_row in csv.reader(first_file, delimiter=delimiter):
+      if row_header_len == -1:
+        row_header_len = _detect_row_header_len(csv_row)
+      assert csv_row, "Mergeable CSV files must have row names."
+      row_headers = csv_row[:row_header_len]
+      table.append(row_headers)
+      csv_row_header_key = tuple(row_headers)
+      known_row_headers.add(csv_row_header_key)
+  return row_header_len
+
+
+def _detect_row_header_len(row: List[str]) -> int:
+  # Input: ["header", "", "", "value 1", "value 2"]
+  #                        ^
+  # Output: 3
+  for i, value in enumerate(row):
+    if i == 0 or value == "":
+      continue
+    return i
+  return 1
+
+def _merge_csv_append(csv_data: List[List[Any]], table: List[List[Any]],
+                      table_headers, row_header_len: int, headers,
+                      known_row_headers, table_row_len):
+  # Find the max row width in added csv_data.
+  max_csv_row_len = max(len(row) for row in csv_data) - row_header_len
+  if table:
+    table_row_len = len(table[0]) + max_csv_row_len
+  else:
+    table_row_len = max_csv_row_len
+
+  if headers:
+    col_header = [headers.pop(0)]
+    table_headers.extend(_ljust_row(col_header, max_csv_row_len))
+
+  # Pre-computed potential padding lists.
+  skipped_table_row_padding = [None] * max_csv_row_len
+  new_row_padding = [None] * (table_row_len - row_header_len - max_csv_row_len)
+
+  table_index = 0
+  for csv_row in csv_data:
+    csv_row_header = tuple(csv_row[:row_header_len])
+    csv_padded_row = _ljust_row(csv_row[row_header_len:], max_csv_row_len)
+
+    if table_index >= len(table):
+      # Append all additional rows to the end of the table.
+      new_row = list(csv_row_header) + new_row_padding + csv_padded_row
+      table.append(new_row)
+      table_index += 1
+      continue
+
+    table_row = table[table_index]
+    table_row_header = tuple(table_row[:row_header_len])
+
+    if table_row_header == csv_row_header:
+      # Simple case, row-headers are matching the current table.
+      table_row.extend(csv_padded_row)
+      table_index += 1
+      continue
+
+    csv_row_header_key = tuple(csv_row_header)
+
+    # csv_data does not contain the current table_row_header, continue
+    # to find a proper insertion point:
+    # - if the know the row-header exists, loop until we find the matching one,
+    # - otherwise insert before the next row, whose row-header would be
+    #   after csv_row_header when using alpha-compare
+    try_insert_alpha_sorted = csv_row_header_key not in known_row_headers
+    while True:
+      table_row = table[table_index]
+      table_row_header = tuple(table_row[:row_header_len])
+      if table_row_header == csv_row_header:
+        table_row.extend(csv_padded_row)
+        break
+      if try_insert_alpha_sorted and csv_row_header_key < table_row_header:
+        new_row = list(csv_row_header) + new_row_padding + csv_padded_row
+        # Try maintaining alpha-sorting by inserting before the next row.
+        table.insert(table_index, new_row)
+        known_row_headers.add(csv_row_header_key)
+        break
+      table_row.extend(skipped_table_row_padding)
+      table_index += 1
+      if table_index >= len(table):
+        # Append all additional rows to the end of the table.
+        new_row = list(csv_row_header) + new_row_padding + csv_padded_row
+        table.append(new_row)
+        break
+    table_index += 1
+  return table_row_len
diff --git a/crossbench/probes/internal.py b/crossbench/probes/internal.py
new file mode 100644
index 0000000..644d8ee
--- /dev/null
+++ b/crossbench/probes/internal.py
@@ -0,0 +1,275 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+import logging
+from typing import TYPE_CHECKING, Iterable, Optional
+
+from crossbench.probes import probe
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
+from crossbench.probes.metric import MetricsMerger
+from crossbench.probes.results import (EmptyProbeResult, ProbeResult,
+                                       ProbeResultDict)
+
+if TYPE_CHECKING:
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.types import Json, JsonDict, JsonList
+
+
+class InternalProbe(probe.Probe):
+  IS_GENERAL_PURPOSE = False
+
+  @property
+  def is_internal(self) -> bool:
+    return True
+
+
+class InternalJsonResultProbe(JsonResultProbe, InternalProbe):
+  IS_GENERAL_PURPOSE = False
+  FLATTEN = False
+
+  def get_context(self, run: Run) -> InternalJsonResultProbeContext:
+    return InternalJsonResultProbeContext(self, run)
+
+
+class InternalJsonResultProbeContext(
+    JsonResultProbeContext[InternalJsonResultProbe]):
+
+  def stop(self) -> None:
+    # Only extract data in the late teardown phase.
+    pass
+
+  def teardown(self) -> ProbeResult:
+    self._json_data = self.extract_json(self.run)  # pylint: disable=no-member
+    return super().teardown()
+
+
+class LogProbe(InternalProbe):
+  """
+  Runner-internal meta-probe: Collects the python logging data from the runner
+  itself.
+  """
+  NAME = "cb.log"
+
+  def get_context(self, run: Run) -> LogProbeContext:
+    return LogProbeContext(self, run)
+
+
+class LogProbeContext(probe.ProbeContext[LogProbe]):
+
+  def __init__(self, probe_instance: LogProbe, run: Run) -> None:
+    super().__init__(probe_instance, run)
+    self._log_handler: Optional[logging.Handler] = None
+
+  def setup(self) -> None:
+    log_formatter = logging.Formatter(
+        "%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s] "
+        "[%(name)s]  %(message)s")
+    self._log_handler = logging.FileHandler(self.result_path)
+    self._log_handler.setFormatter(log_formatter)
+    self._log_handler.setLevel(logging.DEBUG)
+    logging.getLogger().addHandler(self._log_handler)
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    assert self._log_handler
+    logging.getLogger().removeHandler(self._log_handler)
+    self._log_handler = None
+    return ProbeResult(file=(self.local_result_path,))
+
+
+class SystemDetailsProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects the browser's system/platform details.
+  """
+  NAME = "cb.system.details"
+
+  def to_json(self, actions: Actions) -> Json:
+    return actions.run.browser_platform.system_details()
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    return EmptyProbeResult()
+
+
+class ErrorsProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects all errors from running stories and/or
+  from merging probe data.
+  """
+  NAME = "cb.errors"
+
+  def to_json(self, actions: Actions) -> Json:
+    return actions.run.exceptions.to_json()
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    return self._merge_group(group, (run.results for run in group.runs))
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    return self._merge_group(
+        group, (rep_group.results for rep_group in group.repetitions_groups))
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self._merge_group(
+        group, (story_group.results for story_group in group.story_groups))
+
+  def _merge_group(self, group,
+                   results_iter: Iterable[ProbeResultDict]) -> ProbeResult:
+    merged_errors = []
+
+    for results in results_iter:
+      result = results[self]
+      if not result:
+        continue
+      source_file = result.json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        repetition_errors = json.load(f)
+        assert isinstance(repetition_errors, list)
+        merged_errors.extend(repetition_errors)
+
+    group_errors = group.exceptions.to_json()
+    assert isinstance(group_errors, list)
+    merged_errors.extend(group_errors)
+
+    if not merged_errors:
+      return EmptyProbeResult()
+
+    return self.write_group_result(group, merged_errors)
+
+
+class DurationsProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects timing information for various components
+  of the runner (and the times spent in individual stories as well).
+  """
+  NAME = "cb.durations"
+
+  def to_json(self, actions: Actions) -> Json:
+    return actions.run.durations.to_json()
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        (repetitions_group.results[self].json
+         for repetitions_group in group.repetitions_groups),
+        merge_duplicate_paths=True)
+    return self.write_group_result(group, merged, csv_formatter=None)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        (story_group.results[self].json for story_group in group.story_groups),
+        merge_duplicate_paths=True)
+    return self.write_group_result(group, merged, csv_formatter=None)
+
+
+class ResultsSummaryProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects a summary results.json with all the Run
+  information, including all paths to the results of all attached Probes.
+  """
+  NAME = "cb.results"
+  # Given that this is  a meta-Probe that summarizes the data from other
+  # probes we exclude it from the default results lists.
+  PRODUCES_DATA = False
+
+  @property
+  def is_attached(self) -> bool:
+    return True
+
+  def to_json(self, actions: Actions) -> JsonDict:
+    return actions.run.details_json()
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    repetitions: JsonList = []
+    browser: Optional[JsonDict] = None
+
+    for run in group.runs:
+      source_file = run.results[self].json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        repetition_data = json.load(f)
+      if browser is None:
+        browser = repetition_data["browser"]
+        del browser["log"]
+      repetitions.append({
+          "cwd": repetition_data["cwd"],
+          "probes": repetition_data["probes"],
+          "success": repetition_data["success"],
+          "errors": repetition_data["errors"],
+      })
+
+    merged_data: JsonDict = {
+        "cwd": str(group.path),
+        "story": group.story.details_json(),
+        "browser": browser,
+        "group": group.info,
+        "repetitions": repetitions,
+        "probes": group.results.to_json(),
+        "success": group.is_success,
+        "errors": group.exceptions.error_messages(),
+    }
+    return self.write_group_result(group, merged_data, csv_formatter=None)
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    stories: JsonDict = {}
+    browser = None
+
+    for repetitions_group in group.repetitions_groups:
+      source_file = repetitions_group.results[self].json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        merged_story_data = json.load(f)
+      if browser is None:
+        browser = merged_story_data["browser"]
+      story_info = merged_story_data["story"]
+      stories[story_info["name"]] = {
+          "cwd": merged_story_data["cwd"],
+          "duration": story_info["duration"],
+          "probes": merged_story_data["probes"],
+          "errors": merged_story_data["errors"],
+      }
+
+    merged_data: JsonDict = {
+        "cwd": str(group.path),
+        "browser": browser,
+        "stories": stories,
+        "group": group.info,
+        "probes": group.results.to_json(),
+        "success": group.is_success,
+        "errors": group.exceptions.error_messages(),
+    }
+    return self.write_group_result(group, merged_data, csv_formatter=None)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    browsers: JsonDict = {}
+    for story_group in group.story_groups:
+      source_file = story_group.results[self].json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        merged_browser_data = json.load(f)
+      browser_info = merged_browser_data["browser"]
+      browsers[browser_info["unique_name"]] = {
+          "cwd": merged_browser_data["cwd"],
+          "probes": merged_browser_data["probes"],
+          "errors": merged_browser_data["errors"],
+      }
+
+    merged_data: JsonDict = {
+        "cwd": str(group.path),
+        "browsers": browsers,
+        "probes": group.results.to_json(),
+        "success": group.is_success,
+        "errors": group.exceptions.error_messages(),
+    }
+    return self.write_group_result(group, merged_data, csv_formatter=None)
diff --git a/crossbench/probes/js.py b/crossbench/probes/js.py
new file mode 100644
index 0000000..858dcaa
--- /dev/null
+++ b/crossbench/probes/js.py
@@ -0,0 +1,99 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Optional
+
+from crossbench.parse import ObjectParser
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
+from crossbench.probes.metric import MetricsMerger
+from crossbench.probes.probe import ProbeConfigParser, ProbeKeyT
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.types import Json
+
+
+def parse_javascript(value: str) -> str:
+  # TODO: maybe add more sanity checks
+  return ObjectParser.non_empty_str(value, name="javascript")
+
+
+class JSProbe(JsonResultProbe):
+  """
+  Probe for extracting arbitrary metrics using custom javascript code.
+  """
+  NAME = "js"
+  RESULT_LOCATION = ResultLocation.LOCAL
+  IS_GENERAL_PURPOSE = True
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "setup",
+        type=parse_javascript,
+        help=(
+            "Optional JavaScript code that is run immediately before a story. "
+            "This can be used for setting up some JS tracking code or patch "
+            "existing code for custom metric tracking."))
+    parser.add_argument(
+        "js",
+        type=parse_javascript,
+        required=True,
+        help=("Required JavaScript code that is run immediately after "
+              "a story has finished. The code must return a JS object with "
+              "(nested) metric values (numbers)."))
+    return parser
+
+  def __init__(self, js: str, setup: Optional[str] = None) -> None:
+    super().__init__()
+    self._setup_js = setup
+    self._metric_js = js
+
+  @property
+  def setup_js(self) -> Optional[str]:
+    return self._setup_js
+
+  @property
+  def metric_js(self) -> str:
+    return self._metric_js
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("setup_js", self._setup_js),
+        ("metric_js", self._metric_js),
+    )
+
+  def to_json(self, actions: Actions) -> Json:
+    data = actions.js(self._metric_js)
+    return ObjectParser.non_empty_dict(data, "JS metric data")
+
+  def get_context(self, run: Run) -> JSProbeContext:
+    return JSProbeContext(self, run)
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        story_group.results[self].json
+        for story_group in group.repetitions_groups)
+    return self.write_group_result(group, merged)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self.merge_browsers_json_list(group).merge(
+        self.merge_browsers_csv_list(group))
+
+
+class JSProbeContext(JsonResultProbeContext[JSProbe]):
+
+  def start(self) -> None:
+    if setup_js := self.probe.setup_js:
+      with self.run.actions(f"Probe({self.probe.name}) setup") as actions:
+        actions.js(setup_js)
diff --git a/crossbench/probes/json.py b/crossbench/probes/json.py
new file mode 100644
index 0000000..a367c55
--- /dev/null
+++ b/crossbench/probes/json.py
@@ -0,0 +1,253 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import csv
+import json
+import logging
+from collections import defaultdict
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Generic, List, Optional,
+                    Type, TypeVar, Union)
+
+from tabulate import tabulate
+
+from crossbench.probes import helper
+from crossbench.probes.metric import (CSVFormatter, MetricsMerger,
+                                      metric_geomean)
+from crossbench.probes.probe import Probe, ProbeContext, ProbeMissingDataError
+from crossbench.probes.results import (EmptyProbeResult, LocalProbeResult,
+                                       ProbeResult)
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.base import RunGroup
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.types import Json
+
+class JsonResultProbe(Probe, metaclass=abc.ABCMeta):
+  """
+  Abstract Probe that stores a Json result extracted by the `to_json` method
+
+  Tje `to_json` is provided by subclasses. A typical examples includes just
+  running a JS script on the page.
+  Multiple Json result files for RepetitionsRunGroups are merged with the
+  MetricsMerger. Custom merging for other RunGroups can be defined in the
+  subclass.
+  """
+
+  FLATTEN = True
+  SORT_KEYS = True
+
+  @property
+  def result_path_name(self) -> str:
+    return f"{self.name}.json"
+
+  @abc.abstractmethod
+  def to_json(self, actions: Actions) -> Json:
+    """
+    Override in subclasses.
+    Returns json-serializable data.
+    """
+    return None
+
+  def flatten_json_data(self, json_data: Any) -> Json:
+    return helper.Flatten(json_data).data
+
+  def process_json_data(self, json_data) -> Any:
+    return json_data
+
+  def get_context(self, run: Run) -> JsonResultProbeContext:
+    return JsonResultProbeContext(self, run)
+
+  def merge_repetitions(
+      self,
+      group: RepetitionsRunGroup,
+  ) -> ProbeResult:
+    merger = MetricsMerger()
+    for run in group.runs:
+      if self not in run.results:
+        raise ProbeMissingDataError(
+            f"Probe {self.NAME} produced no data to merge.")
+      source_file = run.results[self].json
+      assert source_file.is_file(), (
+          f"{source_file} from {run} is not a file or doesn't exist.")
+      with source_file.open(encoding="utf-8") as f:
+        merger.add(json.load(f))
+    return self.write_group_result(group, merger, csv_formatter=CSVFormatter)
+
+  def merge_browsers_json_list(self, group: BrowsersRunGroup) -> ProbeResult:
+    merged_json: Dict[str, Dict[str, Any]] = {}
+    for story_group in group.story_groups:
+      browser_result: Dict[str, Any] = {}
+      merged_json[story_group.browser.unique_name] = browser_result
+      browser_result["info"] = story_group.info
+      browser_json_path = story_group.results[self].json
+      assert browser_json_path.is_file(), (
+          f"{browser_json_path} from {story_group} "
+          "is not a file or doesn't exist.")
+      with browser_json_path.open(encoding="utf-8") as f:
+        browser_result["data"] = json.load(f)
+    merged_json_path = group.get_local_probe_result_path(self)
+    assert not merged_json_path.exists(), (
+        f"Cannot override existing Json result: {merged_json_path}")
+    with merged_json_path.open("w", encoding="utf-8") as f:
+      json.dump(merged_json, f, indent=2)
+      # TODO(375390958): figure out why files aren't fully written to
+      # pyfakefs here.
+      f.write("\n")
+    return LocalProbeResult(json=(merged_json_path,))
+
+  def merge_browsers_csv_list(self, group: BrowsersRunGroup) -> ProbeResult:
+    csv_file_list: List[LocalPath] = []
+    for story_group in group.story_groups:
+      csv_file_list.append(story_group.results[self].csv)
+    merged_table = helper.merge_csv(csv_file_list, row_header_len=-1)
+    merged_json_path = group.get_local_probe_result_path(self, exists_ok=True)
+    merged_csv_path = merged_json_path.with_suffix(".csv")
+    assert not merged_csv_path.exists(), (
+        f"Cannot override existing CSV result: {merged_csv_path}")
+    with merged_csv_path.open("w", newline="", encoding="utf-8") as f:
+      csv.writer(f, delimiter="\t").writerows(merged_table)
+    return LocalProbeResult(csv=(merged_csv_path,))
+
+  def write_group_result(
+      self,
+      group: RunGroup,
+      merged_data: Union[Dict, List, MetricsMerger],
+      csv_formatter: Optional[Type[CSVFormatter]] = CSVFormatter,
+      value_fn: Callable[[Any], Any] = metric_geomean) -> ProbeResult:
+    merged_json_path = group.get_local_probe_result_path(self)
+    with merged_json_path.open("w", encoding="utf-8") as f:
+      if isinstance(merged_data, (dict, list)):
+        json.dump(merged_data, f, indent=2)
+      else:
+        json.dump(merged_data.to_json(sort=self.SORT_KEYS), f, indent=2)
+      # TODO(375390958): figure out why files aren't fully written to
+      # pyfakefs here.
+      f.write("\n")
+    if not csv_formatter:
+      return LocalProbeResult(json=(merged_json_path,))
+    if not isinstance(merged_data, MetricsMerger):
+      raise ValueError("write_csv is only supported for MetricsMerger, "
+                       f"but found {type(merged_data)}'.")
+    return self.write_group_csv_result(group, merged_data, merged_json_path,
+                                       csv_formatter, value_fn)
+
+  def write_group_csv_result(self, group: RunGroup, merged_data: MetricsMerger,
+                             merged_json_path: LocalPath,
+                             csv_formatter: Type[CSVFormatter],
+                             value_fn: Callable[[Any], Any]) -> ProbeResult:
+    merged_csv_path = merged_json_path.with_suffix(".csv")
+    assert not merged_csv_path.exists(), (
+        f"Cannot override existing CSV result: {merged_csv_path}")
+    # Create a CSV table:
+    # 0 | info label 0,                                          info_value 0
+    #     ...                                                    ...
+    # N | info label N,                                          info_value N
+    # 0 | metric 0 full path, metric path[0] ... metric path[N], metric 0 value
+    #     ...                                                    ...
+    # M | metric M full path, ...                                metric M value
+    headers = []
+    for label, info_value in group.info.items():
+      headers.append((label, info_value))
+    csv_data = csv_formatter(
+        merged_data, value_fn, headers=headers, sort=self.SORT_KEYS).table
+    with merged_csv_path.open("w", newline="", encoding="utf-8") as f:
+      writer = csv.writer(f, delimiter="\t")
+      writer.writerows(csv_data)
+    return LocalProbeResult(json=(merged_json_path,), csv=(merged_csv_path,))
+
+  LOG_SUMMARY_KEYS = ("label", "browser", "version", "os", "device", "cpu",
+                      "runs", "failed runs")
+
+  def _log_result_metrics(self, data: Dict) -> None:
+    table: Dict[str, List[str]] = defaultdict(list)
+    for browser_result in data.values():
+      for info_key in self.LOG_SUMMARY_KEYS:
+        table[info_key].append(browser_result["info"][info_key])
+      data = browser_result["data"]
+      self._extract_result_metrics_table(data, table)
+    flattened: List[List[str]] = list(
+        [label] + values for label, values in table.items())
+    logging.critical(tabulate(flattened, tablefmt="plain"))
+
+  def _extract_result_metrics_table(self, metrics: Dict[str, Any],
+                                    table: Dict[str, List[str]]) -> None:
+    """Add individual metrics to the table in here.
+    Typically you only add score and total values for each benchmark or
+    benchmark item."""
+    del metrics
+    del table
+
+
+JsonResultProbeT = TypeVar("JsonResultProbeT", bound="JsonResultProbe")
+
+
+class JsonResultProbeContext(ProbeContext[JsonResultProbeT],
+                             Generic[JsonResultProbeT]):
+
+  def __init__(self, probe: JsonResultProbeT, run: Run) -> None:
+    super().__init__(probe, run)
+    self._json_data: Json = None
+
+  @property
+  def probe(self) -> JsonResultProbeT:
+    return super().probe
+
+  def to_json(self, actions: Actions) -> Json:
+    return self.probe.to_json(actions)
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    self._json_data = self.extract_json(self.run)
+
+  def teardown(self) -> ProbeResult:
+    if self._json_data is None:
+      return EmptyProbeResult()
+    self._json_data = self.process_json_data(self._json_data)
+    return self.write_json(self.run, self._json_data)
+
+  def extract_json(self, run: Run) -> Json:
+    with run.actions(f"Extracting Probe({self.probe.name})") as actions:
+      json_data = self.to_json(actions)
+      assert json_data is not None, (
+          f"Probe({self.probe.name}) produced no data")
+      return json_data
+
+  def write_json(self, run: Run, json_data: Json) -> ProbeResult:
+    flattened_file = None
+    with run.actions(f"Writing Probe({self.probe.name})"):
+      assert json_data is not None, (
+          f"Probe({self.probe.name}) produced no Json data.")
+      raw_file = self.local_result_path
+      if self.probe.FLATTEN:
+        raw_file = raw_file.with_suffix(".json.nested")
+        flattened_file = self.local_result_path
+        flat_json_data = self.flatten_json_data(json_data)
+        with flattened_file.open("w", encoding="utf-8") as f:
+          json.dump(flat_json_data, f, indent=2)
+          # TODO(375390958): figure out why files aren't fully written to
+          # pyfakefs here.
+          f.write("\n")
+      with raw_file.open("w", encoding="utf-8") as f:
+        json.dump(json_data, f, indent=2)
+        # TODO(375390958): figure out why files aren't fully written to
+        # pyfakefs here.
+        f.write("\n")
+    if flattened_file:
+      return LocalProbeResult(json=(flattened_file,), file=(raw_file,))
+    return LocalProbeResult(json=(raw_file,))
+
+  def process_json_data(self, json_data: Json) -> Json:
+    return self.probe.process_json_data(json_data)
+
+  def flatten_json_data(self, json_data: Any) -> Json:
+    return self.probe.flatten_json_data(json_data)
diff --git a/crossbench/probes/metric.py b/crossbench/probes/metric.py
new file mode 100644
index 0000000..68ae045
--- /dev/null
+++ b/crossbench/probes/metric.py
@@ -0,0 +1,359 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+import logging
+import math
+from math import floor, log10
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Hashable, Iterable,
+                    List, Optional, Sequence, Set, Tuple, Union)
+
+from crossbench.probes import helper
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+  from crossbench.types import Json, JsonDict
+
+
+
+def is_number(value: Any) -> bool:
+  return isinstance(value, (int, float))
+
+
+class Metric:
+  """
+  Metric provides simple statistical getters if the collected values are
+  ints or floats only.
+  """
+
+  @classmethod
+  def format(cls,
+             value: Union[float, int],
+             stddev: Optional[float] = None) -> str:
+    """Format value and stdev to only expose significant + 1 digits.
+    Example outputs:
+      100  10%
+      100.1  1.2%
+      100.12  0.12%
+      100.123  0.012%
+      100.1235  0.0012%
+    """
+    if not stddev:
+      return str(value)
+    stddev = float(stddev)
+    stddev_significant_digit = int(floor(log10(abs(stddev))))
+    value_width = max(0, 1 - stddev_significant_digit)
+    percent = stddev / value * 100
+    percent_significant_digit = int(floor(log10(abs(percent))))
+    percent_width = max(0, 1 - percent_significant_digit)
+    return f"{value:.{value_width}f}  {percent:.{percent_width}f}%"
+
+  @classmethod
+  def from_json(cls, json_data: JsonDict) -> Metric:
+    values = json_data["values"]
+    assert isinstance(values, list)
+    return cls(values)
+
+  def __init__(self, values: Optional[List] = None) -> None:
+    self.values = values or []
+    self._is_numeric: bool = all(map(is_number, self.values))
+
+  def __len__(self) -> int:
+    return len(self.values)
+
+  @property
+  def is_numeric(self) -> bool:
+    return self._is_numeric
+
+  @property
+  def min(self) -> float:
+    assert self._is_numeric
+    return min(self.values)
+
+  @property
+  def max(self) -> float:
+    assert self._is_numeric
+    return max(self.values)
+
+  @property
+  def sum(self) -> float:
+    assert self._is_numeric
+    return sum(self.values)
+
+  @property
+  def average(self) -> float:
+    assert self._is_numeric
+    return sum(self.values) / len(self.values)
+
+  @property
+  def geomean(self) -> float:
+    assert self._is_numeric
+    return geomean(self.values)
+
+  @property
+  def stddev(self) -> float:
+    assert self._is_numeric
+    # We're ignoring here any actual distribution of the data and use this as a
+    # rough estimate of the quality of the data
+    average = self.average
+    variance = 0.0
+    for value in self.values:
+      variance += (average - value)**2
+    variance /= len(self.values)
+    return math.sqrt(variance)
+
+  def append(self, value: Any) -> None:
+    self.values.append(value)
+    self._is_numeric = self._is_numeric and is_number(value)
+
+  def to_json(self) -> JsonDict:
+    json_data: JsonDict = {"values": self.values}
+    if not self.values:
+      return json_data
+    if self.is_numeric:
+      json_data["min"] = self.min
+      average = json_data["average"] = self.average
+      json_data["geomean"] = self.geomean
+      json_data["max"] = self.max
+      json_data["sum"] = self.sum
+      stddev = json_data["stddev"] = self.stddev
+      if average == 0:
+        json_data["stddevPercent"] = 0
+      else:
+        json_data["stddevPercent"] = (stddev / average) * 100
+      return json_data
+    # Try to simplify repeated non-numeric values
+    if not isinstance(self.values[0], Hashable):
+      return json_data
+    if len(set(self.values)) == 1:
+      return self.values[0]
+    return json_data
+
+
+def geomean(values: Iterable[Union[int, float]]) -> float:
+  product: float = 1
+  length: int = 0
+  for value in values:
+    product *= value
+    length += 1
+  return product**(1 / length)
+
+
+def metric_geomean(metric: Metric) -> float:
+  return metric.geomean
+
+
+class MetricsMerger:
+  """
+  Merges hierarchical data into 1-level aggregated data;
+
+  Input:
+  data_1 ={
+    "a": {
+      "aa": 1.1,
+      "ab": 2
+    }
+    "b": 2.1
+  }
+  data_2 = {
+    "a": {
+      "aa": 1.2
+    }
+    "b": 2.2,
+    "c": 2
+  }
+
+  The merged data maps str => Metric():
+
+  MetricsMerger(data_1, data_2).data == {
+    "a/aa": Metric(1.1, 1.2)
+    "a/ab": Metric(2)
+    "b":    Metric(2.1, 2.2)
+    "c":    Metric(2)
+  }
+  """
+
+  @classmethod
+  def merge_json_list(cls,
+                      files: Iterable[LocalPath],
+                      key_fn: Optional[helper.KeyFnType] = None,
+                      merge_duplicate_paths: bool = False) -> MetricsMerger:
+    merger = cls(key_fn=key_fn)
+    for file in files:
+      with file.open(encoding="utf-8") as f:
+        merger.merge_values(
+            json.load(f), merge_duplicate_paths=merge_duplicate_paths)
+    return merger
+
+  def __init__(self,
+               *args: Union[Dict, List[Dict]],
+               key_fn: Optional[helper.KeyFnType] = None):
+    """Create a new MetricsMerger
+
+    Args:
+        *args (optional): Optional hierarchical data to be merged.
+        key_fn (optional): Maps property paths (Tuple[str,...]) to strings used
+          as keys to group/merge values, or None to skip property paths.
+    """
+    self._data: Dict[str, Metric] = {}
+    self._key_fn: helper.KeyFnType = key_fn or helper._default_flatten_key_fn
+    self._ignored_keys: Set[str] = set()
+    for data in args:
+      self.add(data)
+
+  @property
+  def data(self) -> Dict[str, Metric]:
+    return self._data
+
+  def merge_values(self,
+                   data: Dict[str, Dict],
+                   prefix_path: Tuple[str, ...] = (),
+                   merge_duplicate_paths: bool = False) -> None:
+    """Merge a previously json-serialized MetricsMerger object"""
+    for property_name, item in data.items():
+      path = prefix_path + (property_name,)
+      key = self._key_fn(path)
+      if key is None or key in self._ignored_keys:
+        continue
+      if key in self._data:
+        if merge_duplicate_paths:
+          values = self._data[key]
+          for value in item["values"]:
+            values.append(value)
+        else:
+          logging.debug(
+              "Removing Metric with the same key-path='%s', key='%s"
+              "from multiple files.", path, key)
+          del self._data[key]
+          self._ignored_keys.add(key)
+      else:
+        self._data[key] = Metric.from_json(item)
+
+  def add(self, data: Union[Dict, List[Dict]]) -> None:
+    """ Merge "arbitrary" hierarchical data that ends up having primitive leafs.
+    Anything that is not a dict is considered a leaf node.
+    """
+    if isinstance(data, list):
+      # Assume that top-level lists are repetitions of the same data
+      for item in data:
+        self._merge(item)
+    else:
+      self._merge(data)
+
+  def _merge(
+      self, data: Union[Dict,
+                        List[Dict]], parent_path: Tuple[str, ...] = ()) -> None:
+    assert isinstance(data, dict)
+    for property_name, value in data.items():
+      path = parent_path + (property_name,)
+      key: Optional[str] = self._key_fn(path)
+      if key is None:
+        continue
+      if isinstance(value, dict):
+        self._merge(value, path)
+      else:
+        if key in self._data:
+          values = self._data[key]
+        else:
+          values = self._data[key] = Metric()
+        if isinstance(value, list):
+          for v in value:
+            values.append(v)
+        else:
+          values.append(value)
+
+  def to_json(self,
+              value_fn: Optional[Callable[[Any], Json]] = None,
+              sort: bool = True) -> JsonDict:
+    items = []
+    for key, value in self._data.items():
+      assert isinstance(value, Metric)
+      if value_fn is None:
+        json_value: Json = value.to_json()
+      else:
+        json_value = value_fn(value)
+      items.append((key, json_value))
+    if sort:
+      # Make sure the data is always in the same order, independent of the input
+      # order
+      items.sort()
+    return dict(items)
+
+
+class CSVFormatter:
+  """
+  Headers: [
+    ["label_1", "value_1"],
+    ["label_2", "value_2"],
+  ]
+  Input: {
+      "A_1/B_1/Async": 1,
+      "A_1/B_2/Sync": 2,
+      "A_1/Total": 3,
+      "Total": 3,
+    }
+  Output: [
+    ["label_1",      "",      "",      "",      "value_1],
+    ["label_2",      "",      "",      "",      "value_2],
+    ["A_1/B1/Async", "A1",    "B1",    "Async", 1],
+    ["A_1/B2/Sync",  "A1",    "B2",    "Sync",  2],
+    ["A_1/Total",    "A1",    "Total", "",      3],
+    ["Total"         "Total", "",      "",      3],
+  ]
+  """
+
+  def __init__(self,
+               metrics: MetricsMerger,
+               value_fn: Optional[Callable[[Any], Any]] = None,
+               headers: Sequence[Tuple[Any, ...]] = (),
+               include_parts: bool = True,
+               sort: bool = True):
+    self._table: List[Sequence[Any]] = []
+    converted = metrics.to_json(value_fn, sort)
+    items = self.format_items(converted, sort=sort)
+    max_path_depth: int = self.extract_max_depth(items, include_parts)
+    self.append_headers(headers, max_path_depth)
+    self.append_body(items, include_parts, max_path_depth)
+
+  def extract_max_depth(self, items: Sequence[Tuple[str, Json]],
+                        include_parts: bool) -> int:
+    max_path_depth = 0
+    if include_parts:
+      for path, _ in items:
+        max_path_depth = max(max_path_depth, path.count("/"))
+    max_path_depth += 1
+    return max_path_depth
+
+  def append_headers(self, headers, max_path_depth: int) -> None:
+    header_padding = ("",) * max_path_depth
+    for header in headers:
+      assert isinstance(header, tuple), (
+          f"Additional CSV headers must be tuples, got {type(header)}: "
+          f"{header}")
+      row = header[:1] + header_padding + header[1:]
+      self._table.append(row)
+
+  def append_body(self, items: Sequence[Tuple[str, Json]], include_parts: bool,
+                  max_path_depth: int) -> None:
+    for path, value in items:
+      if include_parts:
+        parts = tuple(path.split("/"))
+        buffer = ("",) * (max_path_depth - len(parts))
+        row = (path,) + parts + buffer + (value,)
+      else:
+        row = (path, value)
+      self._table.append(row)
+
+  def format_items(self, data: Dict[str, Json],
+                   sort: bool) -> Sequence[Tuple[str, Json]]:
+    items = tuple(data.items())
+    if not sort:
+      return items
+    return sorted(items)
+
+  @property
+  def table(self) -> List[Sequence[Any]]:
+    return self._table
diff --git a/crossbench/probes/perfetto/__init__.py b/crossbench/probes/perfetto/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/probes/perfetto/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/probes/perfetto/perfetto.py b/crossbench/probes/perfetto/perfetto.py
new file mode 100644
index 0000000..4a4177a
--- /dev/null
+++ b/crossbench/probes/perfetto/perfetto.py
@@ -0,0 +1,240 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import logging
+import subprocess
+from typing import TYPE_CHECKING, Iterable, Optional, cast
+
+from crossbench import helper
+from crossbench import path as pth
+from crossbench.parse import PathParser
+from crossbench.plt.android_adb import AndroidAdbPlatform
+from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeIncompatibleBrowser, ProbeKeyT)
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.run import Run
+
+_PERFETTO_CONFIG_REMOTE_DIR_ANDROID = pth.AnyPath(
+    "/data/misc/perfetto-configs/")
+_PERFETTO_TRACE_REMOTE_DIR_ANDROID = pth.AnyPath("/data/misc/perfetto-traces/")
+
+_PERFETTO_REMOTE_DIR_CROS = pth.AnyPath("/usr/local/tmp")
+
+class PerfettoProbe(Probe):
+  """
+  A probe to collect Perfetto system traces that can be viewed on
+  https://ui.perfetto.dev/. The probe supports Android and ChromeOS targets.
+
+  Recommended way to use:
+  1. Go to https://ui.perfetto.dev/, click "Record new trace" and set up your
+     preferred tracing options.
+  2. Click "Recording command" and copy the textproto config part of the
+     command.
+  3. Paste it into the textproto field of the probe config. An example probe
+     config can be found at config/doc/probe/perfetto.config.hjson.
+  4. Specify the config via the --probe-config command-line flag.
+
+  After the run, the trace will be found among the results as
+  "perfetto.trace.pb.gz".
+  """
+  NAME = "perfetto"
+  RESULT_LOCATION = ResultLocation.BROWSER
+
+  IS_GENERAL_PURPOSE = True
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "textproto",
+        type=str,
+        help=("Serialized perfetto configuration. "
+              "See probe instructions for more details"))
+    parser.add_argument(
+        "perfetto_bin",
+        type=PathParser.any_path,
+        default="perfetto",
+        help="Perfetto binary on the browser device")
+    return parser
+
+  def __init__(self, textproto: str, perfetto_bin: pth.AnyPath):
+    super().__init__()
+    if not textproto:
+      raise ValueError("Please specify a tracing config")
+    self._textproto = textproto
+    if not perfetto_bin:
+      raise ValueError("Please specify a perfetto binary.")
+    self._perfetto_bin = perfetto_bin
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("textproto", self.textproto),
+        ("perfetto_bin", str(self.perfetto_bin)),
+    )
+
+  @property
+  def textproto(self) -> str:
+    return self._textproto
+
+  @property
+  def perfetto_bin(self) -> pth.AnyPath:
+    return self._perfetto_bin
+
+  @property
+  def result_path_name(self) -> str:
+    return "perfetto.trace.pb"
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    if not (browser.platform.is_android or browser.platform.is_chromeos):
+      raise ProbeIncompatibleBrowser(self, browser,
+                                     "Only supported on android or ChromeOS")
+
+  def attach(self, browser: Browser) -> None:
+    assert browser.attributes.is_chromium_based
+    browser.features.enable("EnablePerfettoSystemTracing")
+    super().attach(browser)
+
+  def log_run_result(self, run: Run) -> None:
+    self._log_results([run])
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    self._log_results(group.runs)
+
+  def _log_results(self, runs: Iterable[Run]) -> None:
+    logging.info("-" * 80)
+    logging.critical("Perfetto trace results:")
+    for run in runs:
+      result_file = run.results[self].file
+      logging.critical("  - %s : %s", result_file,
+                       helper.get_file_size(result_file))
+
+  def get_context(self, run: Run) -> PerfettoProbeContext:
+    # TODO: support more platforms
+    if run.browser_platform.is_chromeos:
+      return ChromeOsPerfettoProbeContext(self, run)
+    return AndroidPerfettoProbeContext(self, run)
+
+
+class PerfettoProbeContext(ProbeContext[PerfettoProbe], metaclass=abc.ABCMeta):
+  def __init__(self, probe: PerfettoProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._host_config_file: pth.LocalPath = (
+        run.out_dir / "perfetto_config.textproto")
+    self._pid: Optional[int] = None
+
+
+  def setup(self) -> None:
+    assert self._pid is None
+    for p in self.browser_platform.processes():
+      if p["name"] == "perfetto":
+        logging.warning("PERFETTO: killing existing session pid: %s", p["pid"])
+        self.browser_platform.terminate(p["pid"])
+
+    if not self.browser_platform.which(self.probe.perfetto_bin):
+      raise ValueError(
+          f"perfetto bin '{self.probe.perfetto_bin}' cannot be found "
+          f"on {self.browser_platform}")
+
+    self.host_platform.set_file_contents(self._host_config_file,
+                                         self.probe.textproto)
+    self.browser_platform.push(self._host_config_file,
+                               self.get_browser_config_path())
+
+  @abc.abstractmethod
+  def get_browser_config_path(self) -> pth.AnyPath:
+    pass
+
+  @abc.abstractmethod
+  def get_default_result_path(self) -> pth.AnyPath:
+    pass
+
+  def start(self) -> None:
+    logging.info("PERFETTO: starting")
+    proc = self.browser_platform.sh(
+        self.probe.perfetto_bin,
+        "--background",
+        "--config",
+        self.get_browser_config_path(),
+        "--txt",
+        "--out",
+        self.result_path,
+        capture_output=True)
+    if proc.returncode > 0:
+      logging.error("perfetto command failed with stderr: %s", proc.stderr)
+      raise subprocess.CalledProcessError(proc.returncode, proc.args,
+                                          proc.stdout, proc.stderr)
+
+    self._pid = int(proc.stdout.decode("utf-8").rstrip())
+    self.browser.performance_mark("crossbench-probe-perfetto-start")
+
+  def stop(self) -> None:
+    self.browser.performance_mark("crossbench-probe-perfetto-stop")
+    logging.info("PERFETTO: stopping")
+    if not self._pid:
+      raise RuntimeError("Perfetto was not started")
+    # TODO(cbruni): replace with wait_and_terminate
+    self.browser_platform.terminate(self._pid)
+    try:
+      for _ in helper.WaitRange(1, 30).wait_with_backoff():
+        if not self.browser_platform.process_info(self._pid):
+          break
+    except TimeoutError:
+      logging.error("perfetto process did not stop after 30s. "
+                    "The trace might be incomplete.")
+    self._pid = None
+
+  def teardown(self) -> ProbeResult:
+    # Copy files:
+    browser_result = self.browser_result(file=[self.result_path])
+    local_result_file = browser_result.file
+    assert local_result_file.is_file(), (
+        f"Could not copy perfetto results: {local_result_file}")
+
+    self.host_platform.sh("gzip", local_result_file)
+    local_result_file = local_result_file.with_suffix(
+        f"{local_result_file.suffix}.gz")
+
+    return LocalProbeResult(trace=(local_result_file,))
+
+
+class AndroidPerfettoProbeContext(PerfettoProbeContext):
+
+  def get_browser_config_path(self) -> pth.AnyPath:
+    return _PERFETTO_CONFIG_REMOTE_DIR_ANDROID / "perfetto_config.textproto"
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    return _PERFETTO_TRACE_REMOTE_DIR_ANDROID / "perfetto.trace.pb"
+
+  @property
+  def browser_platform(self) -> AndroidAdbPlatform:
+    browser_platform = super().browser_platform
+    assert isinstance(browser_platform, AndroidAdbPlatform)
+    return cast(AndroidAdbPlatform, browser_platform)
+
+
+class ChromeOsPerfettoProbeContext(PerfettoProbeContext):
+
+  @property
+  def browser_platform(self) -> ChromeOsSshPlatform:
+    browser_platform = super().browser_platform
+    isinstance(browser_platform, ChromeOsSshPlatform)
+    return cast(ChromeOsSshPlatform, browser_platform)
+
+  def get_browser_config_path(self) -> pth.AnyPath:
+    return _PERFETTO_REMOTE_DIR_CROS / "perfetto_config.textproto"
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    return _PERFETTO_REMOTE_DIR_CROS / "perfetto.trace.pb"
diff --git a/crossbench/probes/perfetto/trace_processor/__init__.py b/crossbench/probes/perfetto/trace_processor/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/chrome_tlp.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/chrome_tlp.sql
new file mode 100644
index 0000000..003242f
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/chrome_tlp.sql
@@ -0,0 +1,44 @@
+-- TODO(carlscab): All this is still in experimental stage. Your use at your own
+-- risk. We intend to move all these to the Perfetto stdlib once we have a
+-- stable and convenient API
+SELECT RUN_METRIC('chrome/chrome_processes.sql');
+
+CREATE VIEW ext_chrome_tlp_slice
+AS
+WITH
+  chrome_thread_view AS (
+    SELECT
+      utid,
+      1 AS is_chrome_thread
+    FROM
+      chrome_process
+    JOIN chrome_thread
+      USING (upid)
+  ),
+  base AS (
+    SELECT
+      SCHED_SLICE.*,
+      COALESCE(is_chrome_thread, 0) AS is_chrome_thread
+    FROM SCHED_SLICE
+    LEFT JOIN chrome_thread_view
+      USING (utid)
+    WHERE dur > 0 AND utid <> 0
+  ),
+  events AS (
+    SELECT ts, 1 AS tlp, IIF(is_chrome_thread, 1, 0) AS chrome_tlp FROM base
+    UNION ALL
+    SELECT ts + dur AS ts, -1 AS tlp, IIF(is_chrome_thread, -1, 0) AS chrome_tlp
+    FROM base
+  ),
+  cum AS (
+    SELECT
+      ts,
+      LEAD(ts) OVER (win) - ts AS dur,
+      SUM(tlp) OVER (win) AS tlp,
+      SUM(chrome_tlp) OVER (win) AS chrome_tlp
+    FROM events
+    WINDOW win AS (ORDER BY ts ASC)
+  )
+SELECT ts, dur, tlp, chrome_tlp
+FROM cum
+WHERE dur IS NOT NULL AND dur > 0;
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/first_presentation_time.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/first_presentation_time.sql
new file mode 100644
index 0000000..64e2bcf
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/first_presentation_time.sql
@@ -0,0 +1,44 @@
+-- Trace categories needed:
+--   * benchmark
+--   * blink.user_timing
+--   * loading
+--   * devtools.timeline
+--   * disabled-by-default-devtools.timeline
+--   * v8
+CREATE OR REPLACE PERFETTO FUNCTION get_next_presentation_time(ts INT)
+RETURNS INT
+AS
+WITH
+  candidate_presentation_time AS (
+    SELECT a.ts + a.dur AS ts
+    FROM slice s, ancestor_slice(s.id) a
+    WHERE
+      s.name = 'Commit'
+      AND a.name = 'PipelineReporter'
+      AND s.depth - 1 = a.depth
+      AND s.ts > $ts
+    ORDER BY s.ts
+    LIMIT 1
+  )
+SELECT ts
+FROM slice
+WHERE
+  name = 'Display::FrameDisplayed'
+  AND ts >= (SELECT ts FROM candidate_presentation_time)
+ORDER BY ts
+LIMIT 1;
+
+CREATE OR REPLACE PERFETTO FUNCTION get_first_presentation_time_for_event(
+  name STRING)
+RETURNS INT
+AS
+WITH
+  event AS (
+    SELECT ts
+    FROM slice
+    WHERE name = $name AND cat = 'blink.user_timing'
+    ORDER BY ts
+    LIMIT 1
+  )
+SELECT get_next_presentation_time(ts)
+FROM event;
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loading_interesting_intervals.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loading_interesting_intervals.sql
new file mode 100644
index 0000000..d1f45ca
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loading_interesting_intervals.sql
@@ -0,0 +1,144 @@
+INCLUDE PERFETTO MODULE chrome.page_loads;
+INCLUDE PERFETTO MODULE sched.thread_level_parallelism;
+
+DROP VIEW IF EXISTS interesting_interval_with_overlaps;
+
+CREATE VIEW interesting_interval_with_overlaps
+AS
+WITH
+  offset(i, len) AS (VALUES(0, 1), (1, 2), (2, 3), (3, 5)),
+  INTERVAL AS (
+    SELECT
+      id AS page_load_id,
+      navigation_start_ts AS ts,
+      navigation_start_ts,
+      0 AS lcp_offset,
+      lcp AS dur,
+      0 AS i,
+      0 AS len
+    FROM chrome_page_loads
+    WHERE lcp IS NOT NULL
+    UNION ALL
+    SELECT
+      page_load_id,
+      ts + dur AS ts,
+      navigation_start_ts,
+      lcp_offset + offset.len AS lcp_offset,
+      offset.len * 1000 * 1000 * 1000 AS dur,
+      i + 1,
+      offset.len
+    FROM INTERVAL, offset
+    USING (i)
+  ),
+  data AS (
+    SELECT
+      ROW_NUMBER() OVER (ORDER BY page_load_id, len) AS interval_id,
+      *,
+      ts + dur AS END
+    FROM INTERVAL
+  ),
+  overlap AS (
+    SELECT
+      *,
+      (
+        SELECT MIN(other.interval_id)
+        FROM data AS other
+        WHERE
+          interval.interval_id
+            <> other.interval_id
+            AND other.ts < interval.end
+            AND interval.ts < other.end
+      ) AS first_overlap_interval_id
+    FROM data AS INTERVAL
+    ORDER BY 1, 2 ASC
+  )
+SELECT
+  interval_id,
+  page_load_id,
+  IIF(len <> 0, PRINTF('lcp+%02d-lcp+%02d', lcp_offset - len, lcp_offset), 'NAV_START-lcp')
+    AS interval_name,
+  first_overlap_interval_id,
+  ts,
+  navigation_start_ts,
+  dur,
+    END
+FROM overlap;
+
+DROP VIEW IF EXISTS interesting_interval;
+
+CREATE VIEW interesting_interval
+AS
+SELECT
+  *
+FROM interesting_interval_with_overlaps
+WHERE page_load_id = (SELECT MAX(page_load_id) FROM interesting_interval_with_overlaps);
+
+DROP VIEW IF EXISTS interesting_slice_span_in;
+
+CREATE VIEW interesting_slice_span_in
+AS
+SELECT *, dur AS original_dur
+FROM slice;
+
+DROP TABLE IF EXISTS interesting_slice_span_internal;
+
+CREATE VIRTUAL TABLE interesting_slice_span_internal
+USING
+  SPAN_JOIN(interesting_slice_span_in PARTITIONED track_id, interesting_interval);
+
+DROP VIEW IF EXISTS interesting_slice_span;
+
+CREATE VIEW interesting_slice_span
+AS
+SELECT
+  interval_id,
+  ts,
+  dur AS span_dur,
+  original_dur,
+  name,
+  arg_set_id,
+  IIF(original_dur = 0, 1, 1.0 * dur / original_dur) AS span_ratio,
+  IIF(original_dur = 0, 0.0, 1.0 * thread_dur * dur / original_dur) AS thread_span_dur,
+  track_id
+FROM interesting_slice_span_internal;
+
+DROP VIEW IF EXISTS interesting_slice_start_in;
+
+CREATE VIEW interesting_slice_start_in
+AS
+SELECT ts, 0 AS dur, dur AS original_dur, name, arg_set_id, track_id
+FROM slice;
+
+DROP TABLE IF EXISTS interesting_slice_start_span;
+
+CREATE VIRTUAL TABLE interesting_slice_start_span
+USING
+  SPAN_JOIN(interesting_slice_start_in, interesting_interval);
+
+DROP VIEW IF EXISTS interesting_slice_start;
+
+CREATE VIEW interesting_slice_start
+AS
+SELECT interval_id, ts, original_dur, name, arg_set_id, track_id
+FROM interesting_slice_start_span;
+
+DROP VIEW IF EXISTS interesting_slice_end_in;
+
+CREATE VIEW interesting_slice_end_in
+AS
+SELECT ts + dur AS ts, 0 AS dur, ts AS original_ts, dur AS original_dur, name, arg_set_id, track_id
+FROM slice
+ORDER BY ts ASC;
+
+DROP TABLE IF EXISTS interesting_slice_end_span;
+
+CREATE VIRTUAL TABLE interesting_slice_end_span
+USING
+  SPAN_JOIN(interesting_slice_end_in, interesting_interval);
+
+DROP VIEW IF EXISTS interesting_slice_end;
+
+CREATE VIEW interesting_slice_end
+AS
+SELECT interval_id, ts AS end_ts, original_ts, original_dur, name, arg_set_id, track_id
+FROM interesting_slice_end_span;
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_amazon_product.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_amazon_product.sql
new file mode 100644
index 0000000..ec16695
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_amazon_product.sql
@@ -0,0 +1,23 @@
+INCLUDE PERFETTO MODULE ext.first_presentation_time;
+INCLUDE PERFETTO MODULE ext.navigation_start;
+
+-- This metric returns the time it takes for the "main" JS script to finish the
+-- execution - this is when the page becomes interactive.
+CREATE OR REPLACE PERFETTO FUNCTION loadline_amazon_product_score()
+RETURNS FLOAT
+AS
+WITH
+  js_ready AS (
+    SELECT MAX(ts) AS js_ready
+    FROM slice
+    WHERE
+      name = 'v8.run'
+      AND EXTRACT_ARG(arg_set_id, 'debug.fileName')
+        = 'https://www.amazon.co.uk/NIVEA-Suncream-Spray-Protect-Moisture/dp/B001B0OJXM'
+  )
+SELECT
+  -- Multiply by 60 to make the score per minutes rather than per second.
+  60e9 / (
+    get_next_presentation_time(
+      (SELECT * FROM js_ready))
+    - first_navigation_start());
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_benchmark.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_benchmark.sql
new file mode 100644
index 0000000..444deba
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_benchmark.sql
@@ -0,0 +1,33 @@
+INCLUDE PERFETTO MODULE ext.loadline_amazon_product;
+INCLUDE PERFETTO MODULE ext.loadline_cnn_article;
+INCLUDE PERFETTO MODULE ext.loadline_globo_homepage;
+INCLUDE PERFETTO MODULE ext.loadline_google_doc;
+INCLUDE PERFETTO MODULE ext.loadline_google_search_result;
+INCLUDE PERFETTO MODULE ext.loadline_wikipedia_article;
+INCLUDE PERFETTO MODULE ext.loadline_youtube_video;
+
+CREATE OR REPLACE PERFETTO FUNCTION loadline_get_name()
+RETURNS STRING
+AS
+SELECT DISTINCT substr(name, length('LoadLine/') + 1)
+FROM slice
+WHERE category = 'blink.user_timing' AND name GLOB 'LoadLine/*'
+LIMIT 1;
+
+CREATE OR REPLACE PERFETTO FUNCTION loadline_benchmark_score()
+RETURNS FLOAT
+AS
+SELECT
+  CASE loadline_get_name()
+    WHEN 'loadline-phone/amazon_product' THEN loadline_amazon_product_score()
+    WHEN 'loadline-tablet/amazon_product' THEN loadline_amazon_product_score()
+    WHEN 'loadline-phone/cnn_article' THEN loadline_phone_cnn_article_score()
+    WHEN 'loadline-tablet/cnn_article' THEN loadline_tablet_cnn_article_score()
+    WHEN 'loadline-phone/globo_homepage' THEN loadline_globo_homepage_score()
+    WHEN 'loadline-tablet/google_doc' THEN loadline_google_doc_score()
+    WHEN 'loadline-phone/google_search_result' THEN loadline_google_search_result_score()
+    WHEN 'loadline-tablet/google_search_result' THEN loadline_google_search_result_score()
+    WHEN 'loadline-phone/wikipedia_article' THEN loadline_wikipedia_article_score()
+    WHEN 'loadline-tablet/youtube_video' THEN loadline_youtube_video_score()
+    ELSE NULL
+    END AS score;
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_cnn_article.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_cnn_article.sql
new file mode 100644
index 0000000..1be9e2d
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_cnn_article.sql
@@ -0,0 +1,39 @@
+INCLUDE PERFETTO MODULE ext.first_presentation_time;
+INCLUDE PERFETTO MODULE ext.navigation_start;
+
+-- This metric returns the time the headline text element takes to show up.
+CREATE OR REPLACE PERFETTO FUNCTION loadline_phone_cnn_article_score()
+RETURNS FLOAT
+AS
+SELECT
+  -- Multiply by 60 to make the score per minutes rather than per second.
+  60e9 / (
+    get_first_presentation_time_for_event('maincontent.created')
+    - first_navigation_start());
+
+-- This metric returns the time the headline text element takes to show up
+-- after the second (which is also the last) page load.
+-- The first page load is "incomplete" - it shows the cookie banner and
+-- doesn't load some of the content like ads. We click on the cookie
+-- banner, triggering the second ("complete") page load.
+CREATE OR REPLACE PERFETTO FUNCTION loadline_tablet_cnn_article_score()
+RETURNS FLOAT
+AS
+WITH
+  last_navigation_maincontent_created AS (
+    SELECT ts
+    FROM slice
+    WHERE
+      name = 'maincontent.created'
+      AND cat = 'blink.user_timing'
+      AND ts > last_navigation_start()
+    ORDER BY ts
+    LIMIT 1
+  )
+SELECT
+  -- Multiply by 60 to make the score per minutes rather than per second.
+  60e9
+  / (
+    get_next_presentation_time(
+      (SELECT ts FROM last_navigation_maincontent_created))
+    - last_navigation_start());
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_globo_homepage.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_globo_homepage.sql
new file mode 100644
index 0000000..60477c0
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_globo_homepage.sql
@@ -0,0 +1,12 @@
+INCLUDE PERFETTO MODULE ext.first_presentation_time;
+INCLUDE PERFETTO MODULE ext.navigation_start;
+
+-- This metric returns the time the cookie banner takes to disappear.
+CREATE OR REPLACE PERFETTO FUNCTION loadline_globo_homepage_score()
+RETURNS FLOAT
+AS
+SELECT
+  -- Multiply by 60 to make the score per minutes rather than per second.
+  60e9 / (
+    get_first_presentation_time_for_event('cookie_banner_gone')
+    - first_navigation_start());
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_google_doc.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_google_doc.sql
new file mode 100644
index 0000000..e234f5f
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_google_doc.sql
@@ -0,0 +1,10 @@
+-- LCP
+CREATE OR REPLACE PERFETTO FUNCTION loadline_google_doc_score()
+RETURNS FLOAT
+AS
+-- Multiply by 60 to make the score per minutes rather than per second.
+SELECT 60e9 / dur
+FROM slice
+WHERE name = 'PageLoadMetrics.NavigationToLargestContentfulPaint'
+ORDER BY ts
+LIMIT 1;
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_google_search_result.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_google_search_result.sql
new file mode 100644
index 0000000..ed59ce0
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_google_search_result.sql
@@ -0,0 +1,10 @@
+-- LCP
+CREATE OR REPLACE PERFETTO FUNCTION loadline_google_search_result_score()
+RETURNS FLOAT
+AS
+-- Multiply by 60 to make the score per minutes rather than per second.
+SELECT 60e9 / dur
+FROM slice
+WHERE name = 'PageLoadMetrics.NavigationToLargestContentfulPaint'
+ORDER BY ts
+LIMIT 1;
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_wikipedia_article.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_wikipedia_article.sql
new file mode 100644
index 0000000..6ce8d3a
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_wikipedia_article.sql
@@ -0,0 +1,48 @@
+INCLUDE PERFETTO MODULE ext.first_presentation_time;
+INCLUDE PERFETTO MODULE ext.navigation_start;
+
+-- This metric returns the timestamp of the last important event (including
+-- image paint, JS script runs etc.) since the beginning of the page load.
+CREATE OR REPLACE PERFETTO FUNCTION loadline_wikipedia_article_score()
+RETURNS FLOAT
+AS
+WITH
+  script_run AS (
+    SELECT MAX(ts + dur) AS script_run
+    FROM slice
+    WHERE
+      name = 'v8.run'
+      AND EXTRACT_ARG(arg_set_id, 'debug.fileName')
+        GLOB '*ext.cx.entrypoints.languagesearcher.init*'
+  ),
+  img_load AS (
+    SELECT ts
+    FROM slice
+    WHERE
+      name = 'PaintImage'
+      AND EXTRACT_ARG(arg_set_id, 'debug.data.url')
+        GLOB '*Taylor_Swift_at_the_2023_MTV_Video_Music_Awards*'
+  ),
+  img_next_af AS (
+    SELECT id
+    FROM slice, img_load
+    WHERE
+      name = 'AnimationFrame'
+      AND slice.ts > img_load.ts
+    ORDER BY slice.ts
+    LIMIT 1
+  ),
+  img_presentation AS (
+    SELECT MAX(ts) AS img_presentation
+    FROM img_next_af, DIRECTLY_CONNECTED_FLOW(img_next_af.id) AS flow, slice
+    WHERE slice.id = flow.slice_in
+  ),
+  last_event AS (
+    SELECT
+      MAX(
+        (SELECT * FROM img_presentation), (SELECT * FROM script_run))
+  )
+SELECT
+  -- Multiply by 60 to make the score per minutes rather than per second.
+  60e9 / (
+    (SELECT * FROM last_event) - first_navigation_start());
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_youtube_video.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_youtube_video.sql
new file mode 100644
index 0000000..3a17478
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_youtube_video.sql
@@ -0,0 +1,11 @@
+INCLUDE PERFETTO MODULE ext.first_presentation_time;
+INCLUDE PERFETTO MODULE ext.navigation_start;
+
+-- This metric returns the time the cookie banner takes to disappear.
+CREATE OR REPLACE PERFETTO FUNCTION loadline_youtube_video_score()
+RETURNS FLOAT
+AS
+SELECT
+  -- Multiply by 60 to make the score per minutes rather than per second.
+  60e9
+  / (get_first_presentation_time_for_event('cookie_banner_gone') - first_navigation_start());
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/navigation_start.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/navigation_start.sql
new file mode 100644
index 0000000..4f5e5ba
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/navigation_start.sql
@@ -0,0 +1,13 @@
+CREATE OR REPLACE PERFETTO FUNCTION first_navigation_start()
+RETURNS INT
+AS
+SELECT MIN(ts) AS navigation_start
+FROM slice
+WHERE name = 'PageLoadMetrics.NavigationToLargestContentfulPaint';
+
+CREATE OR REPLACE PERFETTO FUNCTION last_navigation_start()
+RETURNS INT
+AS
+SELECT MAX(ts) AS last_navigation_start
+FROM slice
+WHERE name = 'PageLoadMetrics.NavigationToLargestContentfulPaint';
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/speedometer.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/speedometer.sql
new file mode 100644
index 0000000..d9acb34
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/speedometer.sql
@@ -0,0 +1,120 @@
+-- TODO(carlscab): All this is still in experimental stage. Your use at your own
+-- risk. We intend to move all these to the Perfetto stdlib once we have a
+-- stable and convenient API
+SELECT IMPORT('chrome.speedometer');
+
+CREATE VIEW internal_ext_benchmark_slice_mark
+AS
+WITH
+  timing_slices AS (
+    SELECT *
+    FROM slice
+    WHERE category = 'blink.user_timing'
+  )
+    SELECT
+      track_id,
+      ts,
+      substr(name, 28) AS suite_name,
+      1 AS is_start
+    FROM timing_slices
+    WHERE name GLOB 'benchmark-test_suite-start-*'
+    UNION ALL
+    SELECT
+      track_id,
+      ts,
+      substr(name, 26) AS suite_name,
+      0 AS is_start
+    FROM timing_slices
+    WHERE name GLOB 'benchmark-test_suite-end-*';
+
+CREATE VIEW internal_ext_benchmark_slice
+AS
+WITH
+  next AS (
+    SELECT
+      track_id,
+      ts,
+      suite_name,
+      is_start,
+      LEAD(suite_name) OVER (win) AS next_suite_name,
+      LEAD(is_start) OVER (win) AS next_is_start,
+      LEAD(ts) OVER (win) AS next_ts
+    FROM internal_ext_benchmark_slice_mark
+    WINDOW win AS (PARTITION BY track_id ORDER BY ts ASC)
+  )
+SELECT
+  ts,
+  CAST(next_ts - ts AS INT) AS dur,
+  ROW_NUMBER()
+    OVER (PARTITION BY track_id, suite_name ORDER BY ts ASC) AS iteration,
+  suite_name
+FROM next
+WHERE is_start AND NOT next_is_start AND suite_name = next_suite_name;
+
+CREATE TABLE ext_benchmark_slice
+AS
+WITH
+  speedometer AS (
+    SELECT
+      iteration,
+      suite_name,
+      test_name,
+      measure_type AS measure,
+      ts,
+      dur
+    FROM
+      chrome_speedometer_measure
+  ),
+  other AS (
+    SELECT
+      iteration,
+      suite_name,
+      suite_name AS test_name,
+      suite_name AS measure,
+      ts,
+      dur
+    FROM
+      internal_ext_benchmark_slice
+  ),
+  merged AS (
+    -- TODO: Do something if we find rows for both tables (eg. take only speedometer ones?)
+    SELECT * FROM other
+    UNION ALL
+    SELECT * FROM speedometer
+  )
+SELECT
+  ROW_NUMBER() OVER () AS benchmark_slice_id,
+  iteration,
+  suite_name,
+  test_name,
+  measure,
+  ts,
+  dur
+FROM merged;
+
+CREATE
+  UNIQUE INDEX ext_benchmark_slice_indx
+ON ext_benchmark_slice(benchmark_slice_id);
+
+SELECT
+  CREATE_FUNCTION(
+    'EXT_BENCHMARK_RENDER_MAIN_UTID()',
+    'INT',
+    "
+      WITH
+      union_track AS (
+        SELECT track_id
+        FROM slice
+        WHERE id IN (SELECT slice_id FROM chrome_speedometer_measure)
+        UNION ALL
+        SELECT track_id
+        FROM internal_ext_benchmark_slice_mark
+      ), benchmark_track AS (
+        SELECT DISTINCT track_id
+        FROM union_track
+      )
+    SELECT utid
+    FROM thread_track
+    WHERE
+      id IN (SELECT * FROM benchmark_track)
+        ");
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/speedometer_scheduling.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/speedometer_scheduling.sql
new file mode 100644
index 0000000..63d856c
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/speedometer_scheduling.sql
@@ -0,0 +1,111 @@
+-- TODO(carlscab): All this is still in experimental stage. Your use at your own
+-- risk. We intend to move all these to the Perfetto stdlib once we have a
+-- stable and convenient API
+SELECT IMPORT('ext.chrome_tlp');
+SELECT RUN_METRIC('chrome/chrome_processes.sql');
+
+CREATE VIEW internal_ext_benchmark_scheduling_benchmark_slice
+AS
+SELECT iteration, suite_name, ts, dur FROM ext_benchmark_slice;
+
+CREATE VIRTUAL TABLE internal_ext_benchmark_scheduling_sched_slice
+USING
+  SPAN_JOIN(internal_ext_benchmark_scheduling_benchmark_slice, sched_slice);
+
+CREATE VIEW ext_benchmark_scheduling_thread_cpu_time
+AS
+WITH
+  base AS (
+    SELECT
+      iteration,
+      suite_name,
+      utid,
+      cpu,
+      SUM(DUR) / 1e9 AS cpu_time
+    FROM internal_ext_benchmark_scheduling_sched_slice
+    WHERE utid <> 0 AND dur > 0
+    GROUP BY 1, 2, 3
+  ),
+  chrome_thread_view AS (
+    SELECT
+      utid,
+      1 AS is_chrome_thread,
+      process_type AS chrome_process_type,
+      canonical_name AS chrome_thread_name
+    FROM
+      chrome_process
+    JOIN chrome_thread
+      USING (upid)
+  )
+SELECT
+  base.*,
+  thread.name AS thread_name,
+  process.name AS process_name,
+  COALESCE(is_chrome_thread, 0) AS is_chrome_thread,
+  chrome_process_type,
+  chrome_thread_name
+FROM
+  base
+JOIN thread
+  USING (utid)
+JOIN process
+  USING (upid)
+LEFT JOIN chrome_thread_view
+  USING (utid);
+
+CREATE VIRTUAL TABLE ext_benchmark_scheduling_tpl_slice
+USING
+  SPAN_JOIN(ext_benchmark_slice, ext_chrome_tlp_slice);
+
+CREATE VIEW ext_benchmark_scheduling_tlp_by_test
+AS
+WITH
+  base AS (
+    SELECT
+      iteration,
+      suite_name,
+      tlp * SUM(dur) AS weighted_tlp,
+      chrome_tlp * SUM(dur) AS weighted_chrome_tlp,
+      SUM(dur) AS total_cpu_time
+    FROM ext_benchmark_scheduling_tpl_slice
+    GROUP BY iteration, suite_name, tlp, chrome_tlp
+  ),
+  by_iter_test AS (
+    SELECT
+      iteration,
+      suite_name,
+      1.0 * SUM(weighted_tlp) / SUM(total_cpu_time) AS avg_tlp,
+      1.0 * SUM(weighted_chrome_tlp) / SUM(total_cpu_time) AS avg_chrome_tlp
+    FROM base
+    GROUP BY iteration, suite_name
+  ),
+  median_base AS (
+    SELECT
+      suite_name,
+      avg_tlp,
+      avg_chrome_tlp,
+      ROW_NUMBER()
+        OVER (PARTITION BY suite_name ORDER BY avg_tlp ASC) n_avg_tlp,
+      ROW_NUMBER()
+        OVER (PARTITION BY suite_name ORDER BY avg_chrome_tlp ASC)
+          n_avg_chrome_tlp,
+      COUNT() OVER (PARTITION BY suite_name) n_total
+    FROM by_iter_test
+  ),
+  tlp AS (
+    SELECT
+      suite_name,
+      AVG(avg_tlp) AS median_avg_tlp
+    FROM median_base
+    WHERE (n_avg_tlp - 1) IN ((n_total / 2), ((n_total - 1) / 2))
+    GROUP BY suite_name
+  ),
+  chrome_tlp AS (
+    SELECT
+      suite_name,
+      AVG(avg_chrome_tlp) AS median_avg_chrome_tlp
+    FROM median_base
+    WHERE (n_avg_chrome_tlp - 1) IN (n_total / 2, (n_total - 1) / 2)
+    GROUP BY suite_name
+  )
+SELECT * FROM tlp JOIN chrome_tlp USING (suite_name);
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/benchmark_score.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/benchmark_score.sql
new file mode 100644
index 0000000..f01bfec
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/benchmark_score.sql
@@ -0,0 +1,3 @@
+INCLUDE PERFETTO MODULE ext.loadline_benchmark;
+
+SELECT loadline_benchmark_score() as score;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/cpu.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/cpu.sql
new file mode 100644
index 0000000..6b6c142
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/cpu.sql
@@ -0,0 +1,50 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS sched_slice_type_in;
+
+CREATE VIEW sched_slice_type_in
+AS
+SELECT
+  sched_slice.*,
+  CASE
+    WHEN thread.name = 'CrRendererMain' THEN 'CrRendererMain'
+    WHEN thread.name GLOB 'ThreadPool*' THEN 'ThreadPool'
+    WHEN thread.name GLOB '*IOThread' THEN 'IOThread'
+    WHEN thread.name = 'NetworkService' THEN 'NetworkService'
+    WHEN thread.name = 'Compositor' THEN 'Compositor'
+    WHEN thread.name = 'VizCompositorThread' THEN 'VizCompositorThread'
+    WHEN EXTRACT_ARG(arg_set_id, 'chrome.process_type') IS NOT NULL
+      THEN 'Other_' || EXTRACT_ARG(arg_set_id, 'chrome.process_type')
+    WHEN thread.name GLOB 'binder*' THEN 'binder'
+    WHEN thread.name GLOB 'surfaceflinger*' THEN 'surfaceflinger'
+    WHEN thread.name = 'HeapTaskDaemon' THEN 'HeapTaskDaemon'
+    ELSE 'Other'
+    END AS thread_type
+FROM sched_slice
+LEFT JOIN thread
+  USING (utid)
+LEFT JOIN process
+  USING (upid)
+WHERE
+  utid <> 0;
+
+DROP TABLE IF EXISTS sched_slice_type_span;
+
+CREATE VIRTUAL TABLE sched_slice_type_span
+USING
+  SPAN_JOIN(interesting_interval, sched_slice_type_in PARTITIONED cpu);
+
+DROP VIEW IF EXISTS cpu_metric;
+
+CREATE VIEW cpu_metric
+AS
+SELECT
+  thread_type,
+  interval_id,
+  "thread_time" AS metric_name,
+  "cpu_sec" AS unit,
+  sum(dur) / 1e9 AS value
+FROM sched_slice_type_span
+GROUP BY thread_type, interval_id;
+
+SELECT * FROM cpu_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/dom.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/dom.sql
new file mode 100644
index 0000000..1f82143
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/dom.sql
@@ -0,0 +1,35 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS dom_metric;
+
+CREATE VIEW dom_metric
+AS
+WITH
+  data AS (
+    SELECT
+      interval_id,
+      'dom_' || substr(key, 12) AS metric_name,
+      MAX(coalesce(int_value, real_value)) AS value
+    FROM interesting_slice_span, args
+    USING (arg_Set_id)
+    WHERE name = 'UpdateCounters'
+    GROUP BY 1, 2, track_id
+  )
+SELECT
+  interval_id,
+  metric_name,
+  CASE
+    WHEN metric_name LIKE "%HeapSize%" THEN 'bytes'
+    ELSE 'count'
+    END AS unit,
+  sum(value) AS value
+FROM data
+GROUP BY 1, 2
+UNION ALL
+SELECT
+  interval_id, 'created_frames' AS metric, 'count' AS unit, COUNT(*) AS value
+FROM interesting_slice_start
+WHERE name = 'ContentRendererClient::RenderFrameCreated'
+GROUP BY interval_id;
+
+SELECT * FROM dom_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/interaction_latency.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/interaction_latency.sql
new file mode 100644
index 0000000..d15dff7
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/interaction_latency.sql
@@ -0,0 +1,16 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS interaction_latency_metric;
+
+CREATE VIEW interaction_latency_metric
+AS
+SELECT
+  interval_id,
+  "average_interaction_latency" AS metric_name,
+  "usec" AS unit,
+  avg(original_dur) / 1e3 AS value
+FROM interesting_slice_start
+WHERE name = 'Responsiveness.Renderer.UserInteraction'
+GROUP BY interval_id;
+
+SELECT * FROM interaction_latency_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/mojo.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/mojo.sql
new file mode 100644
index 0000000..248b3c9
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/mojo.sql
@@ -0,0 +1,4385 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP TABLE IF EXISTS mojo_ipc_hash;
+
+CREATE TABLE mojo_ipc_hash(ipc_hash, method_name);
+
+-- Extracted from go/ipc-hashes
+INSERT INTO mojo_ipc_hash
+VALUES
+  (4139214343, 'AppWindowReady'),
+  (447688467, 'CloseMessagePort'),
+  (689156000, 'ContentScriptsExecuting'),
+  (24923085, 'DecrementLazyKeepaliveCount'),
+  (3636815736, 'EventAck'),
+  (213183823, 'EventAckWorker'),
+  (3678980726, 'GetMessageBundle'),
+  (3216452244, 'IncrementLazyKeepaliveCount'),
+  (2834998395, 'OpenChannelToExtension'),
+  (2514655244, 'OpenChannelToNativeApp'),
+  (3050465354, 'OpenChannelToTab'),
+  (2824804248, 'OpenMessagePort'),
+  (2122641674, 'PostMessage'),
+  (607208504, 'ResponsePending'),
+  (907568712, 'UpdateDraggableRegions'),
+  (1562051102, 'WakeEventPage'),
+  (1434243914, 'DeliverMessage'),
+  (149545958, 'DispatchOnConnect'),
+  (2060554611, 'DispatchOnDisconnect'),
+  (943173601, 'ResponseWorker'),
+  (3290552071, 'ValidateMessagePort'),
+  (3057830961, 'WakeEventPageResponse'),
+  (3348806589, 'GetMethods'),
+  (3100937146, 'HasMethod'),
+  (2397413004, 'InvokeMethod'),
+  (1871672798, 'ObjectWrapperDeleted'),
+  (403863263, 'AddNamedObject'),
+  (2990216602, 'RemoveNamedObject'),
+  (1831369248, 'AddSink'),
+  (651547359, 'CastToSink'),
+  (2501284510, 'CreatePageHandler'),
+  (3744046794, 'Create'),
+  (2241750424, 'ClearStorage'),
+  (2829058747, 'GetReports'),
+  (77632887, 'SendReports'),
+  (2756232191, 'OnReportHandled'),
+  (2035563130, 'OnRequestStorageModified'),
+  (882367664, 'ContentsSizeChanged'),
+  (1986918424, 'ShouldOverrideUrlLoading'),
+  (2621454548, 'UpdateHitTestData'),
+  (477118550, 'DocumentHasImage'),
+  (3685839186, 'HitTest'),
+  (3965050451, 'ResetScrollAndScaleState'),
+  (3414439200, 'SetInitialPageScale'),
+  (414659097, 'SetTextZoomFactor'),
+  (1150145755, 'SmoothScroll'),
+  (3677353702, 'ClearCache'),
+  (690274105, 'SetJsOnlineProperty'),
+  (812305071, 'SubFrameCreated'),
+  (4070584065, 'AddApp'),
+  (2584449395, 'CreateAppShortcut'),
+  (4123771448, 'CreatePageHandler'),
+  (609007913, 'GetApps'),
+  (1040181985, 'GetDeprecationLinkString'),
+  (1102964631, 'InstallAppLocally'),
+  (2594301838, 'LaunchApp'),
+  (3829188940, 'LaunchDeprecatedAppDialog'),
+  (439435222, 'SetRunOnOsLoginMode'),
+  (605244941, 'SetUserDisplayMode'),
+  (1062755670, 'ShowAppSettings'),
+  (1983847769, 'UninstallApp'),
+  (3665440250, 'RemoveApp'),
+  (3099428455, 'CreatePageHandler'),
+  (327610607, 'GetApp'),
+  (3945959279, 'GetApps'),
+  (1801468987, 'GetExtensionAppPermissionMessages'),
+  (3410112755, 'GetOverlappingPreferredApps'),
+  (1952190172, 'GetSubAppToParentMap'),
+  (650164118, 'OpenNativeSettings'),
+  (1792908078, 'OpenStorePage'),
+  (2433159959, 'SetFileHandlingEnabled'),
+  (3034749631, 'SetPermission'),
+  (3279070118, 'SetPinned'),
+  (3752258594, 'SetPreferredApp'),
+  (673524906, 'SetResizeLocked'),
+  (2530894500, 'SetRunOnOsLoginMode'),
+  (1068350492, 'SetWindowMode'),
+  (3039923658, 'ShowDefaultAppAssociationsUi'),
+  (2393963, 'Uninstall'),
+  (4091878904, 'UpdateAppSize'),
+  (3372482987, 'OnAppAdded'),
+  (3707537145, 'OnAppChanged'),
+  (3862875033, 'OnAppRemoved'),
+  (3652552946, 'Create'),
+  (964779851, 'ClearStorage'),
+  (2271077329, 'GetActiveSources'),
+  (2727490368, 'GetReports'),
+  (1712408550, 'IsAttributionReportingEnabled'),
+  (523930970, 'SendReports'),
+  (2108345975, 'OnDebugReportSent'),
+  (1797651465, 'OnOsRegistration'),
+  (1501390658, 'OnReportDropped'),
+  (1829151322, 'OnReportsChanged'),
+  (1420017007, 'OnReportSent'),
+  (4053189647, 'OnSourceHandled'),
+  (1780837444, 'OnSourcesChanged'),
+  (3544543535, 'OnTriggerHandled'),
+  (1453491609, 'Clone'),
+  (479807854, 'OnNetworkRequestComplete'),
+  (1177920270, 'OnNetworkResponseReceived'),
+  (3989247091, 'OnNetworkSendRequest'),
+  (1012939762, 'Append'),
+  (2647921849, 'Clear'),
+  (1437496952, 'Delete'),
+  (448815918, 'Set'),
+  (2032031855, 'LoadBidderWorklet'),
+  (1554059152, 'LoadSellerWorklet'),
+  (3227766475, 'BeginGenerateBid'),
+  (1668316631, 'ConnectDevToolsAgent'),
+  (1652379601, 'ReportWin'),
+  (1953337607, 'SendPendingSignalsRequests'),
+  (1102893283, 'OnBiddingSignalsReceived'),
+  (2449070808, 'OnGenerateBidComplete'),
+  (3411004988, 'FinishGenerateBid'),
+  (1816607364, 'OnScoreAdComplete'),
+  (448533354, 'ConnectDevToolsAgent'),
+  (937287835, 'ReportResult'),
+  (4147710202, 'ScoreAd'),
+  (1855406955, 'SendPendingSignalsRequests'),
+  (539108923, 'BindDebugRecording'),
+  (2478167668, 'BindDeviceNotifier'),
+  (230717533, 'BindLogFactoryManager'),
+  (3446618299, 'BindStreamFactory'),
+  (2942700047, 'BindSystemInfo'),
+  (2117376844, 'BindTestingApi'),
+  (3329191524, 'Enable'),
+  (2873166613, 'CreateAecdumpFile'),
+  (3954522854, 'CreateWavFile'),
+  (4028561747, 'DevicesChanged'),
+  (2298535271, 'RegisterListener'),
+  (1122069497, 'SetLogFactory'),
+  (1128612797, 'GetAssociatedOutputDeviceID'),
+  (1080971286, 'GetInputDeviceDescriptions'),
+  (1396036112, 'GetInputDeviceInfo'),
+  (116236800, 'GetInputStreamParameters'),
+  (1585601219, 'GetOutputDeviceDescriptions'),
+  (3714115289, 'GetOutputStreamParameters'),
+  (79738686, 'HasInputDevices'),
+  (1897921720, 'HasOutputDevices'),
+  (258865295, 'Crash'),
+  (1509335311, 'AcceptDataListSuggestion'),
+  (1817889349, 'ApplyAutofillAction'),
+  (1791061111, 'ClearPreviewedForm'),
+  (2961946132, 'ClearSection'),
+  (3376067677, 'EnableHeavyFormDataScraping'),
+  (2801889515, 'FieldTypePredictionsAvailable'),
+  (1668485679, 'FillFieldWithValue'),
+  (3068978537, 'GetPotentialLastFourCombinationsForStandaloneCvc'),
+  (2950221060, 'PreviewFieldWithValue'),
+  (2484979956, 'PreviewPasswordGenerationSuggestion'),
+  (960584076, 'PreviewPasswordSuggestion'),
+  (1029544468, 'SetFieldsEligibleForManualFilling'),
+  (1359403708, 'SetFocusRequiresScroll'),
+  (912402724, 'SetQueryPasswordSuggestion'),
+  (2772381820, 'SetSecureContextRequired'),
+  (3857021084, 'SetSuggestionAvailability'),
+  (448375680, 'SetUserGestureRequired'),
+  (1914251799, 'TriggerFormExtraction'),
+  (4272213797, 'TriggerFormExtractionWithResponse'),
+  (2715941115, 'TriggerSuggestions'),
+  (2932065087, 'AskForValuesToFill'),
+  (1510807901, 'DidEndTextFieldEditing'),
+  (4206636325, 'DidFillAutofillFormData'),
+  (1600138603, 'FocusNoLongerOnForm'),
+  (476735032, 'FocusOnFormField'),
+  (1921329928, 'FormsSeen'),
+  (3423774328, 'FormSubmitted'),
+  (3590408314, 'HidePopup'),
+  (1978533792, 'JavaScriptChangedAutofilledValue'),
+  (801946681, 'SelectControlDidChange'),
+  (1577900962, 'SelectOrSelectListFieldOptionsDidChange'),
+  (1273243201, 'SetFormToBeProbablySubmitted'),
+  (3634056912, 'TextFieldDidChange'),
+  (1044727827, 'TextFieldDidScroll'),
+  (2995255543, 'AnnotateFieldsWithParsingResult'),
+  (3017457078, 'FillIntoFocusedField'),
+  (4009684833, 'FillPasswordSuggestion'),
+  (555060626, 'InformNoSavedCredentials'),
+  (1342828496, 'KeyboardReplacingSurfaceClosed'),
+  (2662325712, 'SetLoggingState'),
+  (584049104, 'SetPasswordFillData'),
+  (546224467, 'TriggerFormSubmission'),
+  (3090342337, 'FoundFormEligibleForGeneration'),
+  (2642735855, 'GeneratedPasswordAccepted'),
+  (2352996220, 'TriggeredGeneratePassword'),
+  (3362044037, 'AutomaticGenerationAvailable'),
+  (1407699520, 'FrameWasScrolled'),
+  (1941124540, 'GenerationElementLostFocus'),
+  (1640592403, 'PasswordGenerationRejectedByTyping'),
+  (75848029, 'PasswordNoLongerGenerated'),
+  (81879285, 'PresaveGeneratedPassword'),
+  (2535743579, 'ShowPasswordEditingPopup'),
+  (516229426, 'CheckSafeBrowsingReputation'),
+  (802697699, 'DynamicFormSubmission'),
+  (231101043, 'FocusedInputChanged'),
+  (3007098802, 'InformAboutUserInput'),
+  (360524695, 'LogFirstFillingResult'),
+  (2511147236, 'PasswordFormCleared'),
+  (3502110191, 'PasswordFormsParsed'),
+  (3845128847, 'PasswordFormsRendered'),
+  (1623397234, 'PasswordFormSubmitted'),
+  (1924029995, 'RecordSavePasswordProgress'),
+  (3858287711, 'ShowKeyboardReplacingSurface'),
+  (3279576685, 'ShowPasswordSuggestions'),
+  (41431047, 'UserModifiedNonPasswordField'),
+  (1112823114, 'UserModifiedPasswordField'),
+  (3420265114, 'BindAccessibilityServiceClient'),
+  (842332863, 'BindAutomation'),
+  (1579576003, 'DispatchAccessibilityEvents'),
+  (2582012746, 'DispatchAccessibilityLocationChange'),
+  (1804596894, 'DispatchActionResult'),
+  (2065545498, 'DispatchTreeDestroyedEvent'),
+  (118609964, 'Abort'),
+  (1147176139, 'ResolvedAdditionalBids'),
+  (1119143914, 'ResolvedAuctionAdResponsePromise'),
+  (1185534379, 'ResolvedBuyerCurrenciesPromise'),
+  (1634767472, 'ResolvedBuyerTimeoutsPromise'),
+  (1131699575, 'ResolvedDirectFromSellerSignalsHeaderAdSlotPromise'),
+  (397932888, 'ResolvedDirectFromSellerSignalsPromise'),
+  (3735139681, 'ResolvedPerBuyerSignalsPromise'),
+  (3550470193, 'ResolvedPromiseParam'),
+  (1426258187, 'ClearOriginJoinedInterestGroups'),
+  (3208915402, 'CreateAdRequest'),
+  (1460448285, 'CreateAuctionNonce'),
+  (2433833441, 'DeprecatedGetURLFromURN'),
+  (801941963, 'DeprecatedReplaceInURN'),
+  (1671468910, 'FinalizeAd'),
+  (2452736245, 'GetInterestGroupAdAuctionData'),
+  (2663603700, 'JoinInterestGroup'),
+  (2248901951, 'LeaveInterestGroup'),
+  (1256564601, 'LeaveInterestGroupForDocument'),
+  (429106311, 'RunAdAuction'),
+  (158347888, 'UpdateAdInterestGroups'),
+  (1098423048, 'Start'),
+  (4186193084, 'Stop'),
+  (2043676684, 'Add'),
+  (3141764576, 'OnPointerDown'),
+  (2243014997, 'OnPointerHover'),
+  (3604479184, 'ProcessPointerEventUsingMLModel'),
+  (1603037466, 'ReportAnchorElementClick'),
+  (3362748136, 'ReportAnchorElementPointerDataOnHoverTimerFired'),
+  (773450032, 'ReportAnchorElementPointerDown'),
+  (862404615, 'ReportAnchorElementPointerOut'),
+  (196769556, 'ReportAnchorElementPointerOver'),
+  (1848815724, 'ReportAnchorElementsEnteredViewport'),
+  (797316778, 'ReportAnchorElementsLeftViewport'),
+  (2923531833, 'ReportNewAnchorElements'),
+  (2893707992, 'FetchAllFontFiles'),
+  (4001990792, 'GetUniqueNameLookupTable'),
+  (3023312356, 'MatchLocalFontByUniqueName'),
+  (2843604854, 'CreateAgent'),
+  (1012633109, 'CreateAgentFromSelection'),
+  (52357849, 'DidFinishAttachment'),
+  (1598482979, 'ScrollIntoView'),
+  (2184573768, 'BannerPromptRequest'),
+  (1168554204, 'BannerAccepted'),
+  (3203895697, 'BannerDismissed'),
+  (217455996, 'DisplayAppBanner'),
+  (2648115757, 'GetAssociatedInterface'),
+  (540764622, 'OsSourceDataAvailable'),
+  (4073326900, 'OsTriggerDataAvailable'),
+  (2231624699, 'SourceDataAvailable'),
+  (1364109667, 'TriggerDataAvailable'),
+  (3406138542, 'RegisterDataHost'),
+  (1937637715, 'RegisterNavigationDataHost'),
+  (683112779, 'AudioContextAudiblePlaybackStarted'),
+  (402968186, 'AudioContextAudiblePlaybackStopped'),
+  (1568012167, 'Cancel'),
+  (2055326841, 'GetAssertion'),
+  (9905980, 'IsConditionalMediationAvailable'),
+  (3422915789, 'IsUserVerifyingPlatformAuthenticatorAvailable'),
+  (2388237970, 'MakeCredential'),
+  (2398659990, 'AddAutoplayFlags'),
+  (2422720384, 'DidChangeBackForwardCacheDisablingFeatures'),
+  (966385357, 'EvictFromBackForwardCache'),
+  (4157298551, 'OnProgress'),
+  (672626915, 'OnRecordsUnavailable'),
+  (718888284, 'OnRequestCompleted'),
+  (3207410849, 'Abort'),
+  (510454755, 'AddRegistrationObserver'),
+  (3327105683, 'MatchRequests'),
+  (143939606, 'UpdateUI'),
+  (1512600029, 'Fetch'),
+  (1322983752, 'GetDeveloperIds'),
+  (3424784169, 'GetIconDisplaySize'),
+  (861943950, 'GetRegistration'),
+  (1161047510, 'ClearBadge'),
+  (1474878266, 'SetBadge'),
+  (1744196816, 'AsDataPipeGetter'),
+  (1552173152, 'CaptureSnapshot'),
+  (945495644, 'Clone'),
+  (2153063981, 'GetInternalUUID'),
+  (4215467121, 'Load'),
+  (2692393822, 'ReadAll'),
+  (1739567007, 'OnCalculatedSize'),
+  (2407174870, 'OnComplete'),
+  (63985040, 'ReadRange'),
+  (180643611, 'ReadSideData'),
+  (1390436099, 'GetBlobFromUUID'),
+  (683086128, 'Register'),
+  (3328575691, 'RegisterFromStream'),
+  (87787854, 'URLStoreForOrigin'),
+  (3390388383, 'Register'),
+  (771983348, 'Resolve'),
+  (4132311605, 'ResolveAsURLLoaderFactory'),
+  (1075469817, 'ResolveForNavigation'),
+  (4232328359, 'Revoke'),
+  (90072839, 'Clone'),
+  (1298096740, 'GetToken'),
+  (3848569215, 'OnMessage'),
+  (3978713840, 'ConnectToChannel'),
+  (2708892102, 'GetInterface'),
+  (654971201, 'GetBrowsingTopics'),
+  (440737833, 'Durability'),
+  (3210344025, 'Estimate'),
+  (1755568463, 'Expires'),
+  (1981046388, 'GetCaches'),
+  (1056279585, 'GetDirectory'),
+  (1284382596, 'GetIdbFactory'),
+  (954753343, 'GetLockManager'),
+  (3651932954, 'Persist'),
+  (3289416977, 'Persisted'),
+  (2006852476, 'SetExpires'),
+  (1537138520, 'DeleteBucket'),
+  (2643021953, 'GetBucketForDevtools'),
+  (1577147780, 'Keys'),
+  (1332473502, 'OpenBucket'),
+  (3207855066, 'RequestAsFile'),
+  (3802958950, 'RequestAsReply'),
+  (387443881, 'RequestAsStream'),
+  (854503807, 'Batch'),
+  (2884635435, 'GetAllMatchedEntries'),
+  (3175175008, 'Keys'),
+  (2639580817, 'Match'),
+  (2122836777, 'MatchAll'),
+  (3488927137, 'WriteSideData'),
+  (1685241191, 'Delete'),
+  (242271745, 'Has'),
+  (1708541760, 'Keys'),
+  (3265023444, 'Match'),
+  (731473071, 'Open'),
+  (2291270536, 'CommitWrite'),
+  (2797992449, 'GetSequenceNumber'),
+  (3851156433, 'IsFormatAvailable'),
+  (3141344637, 'ReadAvailableCustomAndStandardFormats'),
+  (2241770181, 'ReadAvailableTypes'),
+  (3045087283, 'ReadCustomData'),
+  (3931027179, 'ReadFiles'),
+  (2028456694, 'ReadHtml'),
+  (1321860405, 'ReadPng'),
+  (1648042014, 'ReadRtf'),
+  (2034789337, 'ReadSvg'),
+  (1299166912, 'ReadText'),
+  (4137969997, 'ReadUnsanitizedCustomFormat'),
+  (1247157510, 'WriteBookmark'),
+  (1431630508, 'WriteCustomData'),
+  (1026641503, 'WriteHtml'),
+  (2392680450, 'WriteImage'),
+  (3263019123, 'WriteSmartPasteMarker'),
+  (560242170, 'WriteSvg'),
+  (568101751, 'WriteText'),
+  (2448870436, 'WriteUnsanitizedCustomFormat'),
+  (714862438, 'Signal'),
+  (3822268249, 'ClearCodeCacheEntry'),
+  (1172210283, 'DidGenerateCacheableMetadata'),
+  (1424299661, 'DidGenerateCacheableMetadataInCacheStorage'),
+  (1986840253, 'FetchCachedCode'),
+  (2938447185, 'DidChooseColor'),
+  (1196717144, 'OpenColorChooser'),
+  (2394880463, 'SetSelectedColor'),
+  (1850824813, 'Select'),
+  (1748022034, 'Add'),
+  (3120080845, 'CheckOfflineCapability'),
+  (3175047028, 'Delete'),
+  (1919453258, 'GetDescriptions'),
+  (1828439017, 'GetIconSizes'),
+  (2523171767, 'NotifyContentWithCertificateErrorsDisplayed'),
+  (3397959574, 'NotifyContentWithCertificateErrorsRan'),
+  (2389982963, 'NotifyInsecureContentRan'),
+  (1081042954, 'ContextMenuClosed'),
+  (624468196, 'CustomContextMenuAction'),
+  (1563433034, 'Clone'),
+  (12963134, 'UpdateController'),
+  (3046423650, 'DispatchFetchEventForSubresource'),
+  (2214845249, 'GetValue'),
+  (1219551573, 'AddSubscriptions'),
+  (1576518907, 'GetSubscriptions'),
+  (1940741999, 'RemoveSubscriptions'),
+  (976884604, 'SetSharedMemory'),
+  (980305126, 'Get'),
+  (350882676, 'PreventSilentAccess'),
+  (3734610900, 'Store'),
+  (1049712311, 'CloseDateTimeDialog'),
+  (1383065388, 'OpenDateTimeDialog'),
+  (3816092340, 'OnScriptLoadStarted'),
+  (3914538632, 'OnScriptLoadStartFailed'),
+  (4071249698, 'OnWorkerHostCreated'),
+  (1727955250, 'CreateWorkerHost'),
+  (240079176, 'CreateWorkerHostAndStartScriptLoad'),
+  (2762177554, 'GetAnnotatedAssetId'),
+  (1990836220, 'GetAnnotatedLocation'),
+  (2477252353, 'GetDirectoryId'),
+  (2677494376, 'GetHostname'),
+  (3831149923, 'GetSerialNumber'),
+  (1537682673, 'AttachDevToolsSession'),
+  (1640702093, 'GetUniqueFormControlId'),
+  (3650225621, 'ChildTargetCreated'),
+  (4067800784, 'MainThreadDebuggerPaused'),
+  (2666088996, 'MainThreadDebuggerResumed'),
+  (1070896521, 'InspectElement'),
+  (1456486475, 'ReportChildTargets'),
+  (4017293133, 'DispatchEmbedderMessage'),
+  (3655758907, 'SetupDevToolsExtensionAPI'),
+  (637389578, 'SetupDevToolsFrontend'),
+  (3321254228, 'DispatchProtocolCommand'),
+  (2788778580, 'DispatchProtocolNotification'),
+  (3275898187, 'DispatchProtocolResponse'),
+  (3117163400, 'OpenBoundUDPSocket'),
+  (1026205467, 'OpenConnectedUDPSocket'),
+  (1879059861, 'OpenTCPServerSocket'),
+  (3110619152, 'OpenTCPSocket'),
+  (3742154351, 'ProvideTemporaryFile'),
+  (1195629255, 'SetSafeArea'),
+  (2123045895, 'NotifyViewportFitChanged'),
+  (149975614, 'GetEntities'),
+  (4055338689, 'BindSessionStorageArea'),
+  (1933009532, 'BindSessionStorageNamespace'),
+  (1688677112, 'ResetStorageAreaAndNamespaceConnections'),
+  (156935928, 'OpenLocalStorage'),
+  (1192778526, 'BindDomStorage'),
+  (1767400724, 'BindSurfaceEmbedder'),
+  (2642559667, 'ConnectToEmbedder'),
+  (1608097400, 'CreateBundledCompositorFrameSink'),
+  (3172042742, 'CreateCompositorFrameSink'),
+  (3411914827, 'CreateSimpleCompositorFrameSink'),
+  (2829865084, 'RegisterEmbeddedFrameSink'),
+  (1509173862, 'RegisterEmbeddedFrameSinkBundle'),
+  (1921489216, 'RegisterFrameSinkHierarchy'),
+  (1233217199, 'UnregisterFrameSinkHierarchy'),
+  (2908177361, 'StartWorker'),
+  (3326269416, 'StopWorker'),
+  (747332556, 'CountFeature'),
+  (2924640957, 'OnReadyForInspection'),
+  (3757511470, 'OnReportConsoleMessage'),
+  (988869152, 'OnReportException'),
+  (3109171515, 'OnScriptEvaluationStart'),
+  (316124689, 'OnScriptLoaded'),
+  (2634768507, 'OnStarted'),
+  (4277067972, 'OnStopped'),
+  (1915798960, 'RequestTermination'),
+  (3925252471, 'GetEnvironmentIntegrity'),
+  (474053833, 'Choose'),
+  (3801112123, 'Register'),
+  (1905284698, 'CancelTokenRequest'),
+  (2198102842, 'CloseModalDialogView'),
+  (1980281316, 'LogoutRps'),
+  (3319118181, 'PreventSilentAccess'),
+  (3030650445, 'RegisterIdP'),
+  (3617225905, 'RequestToken'),
+  (1510300857, 'RequestUserInfo'),
+  (287324458, 'ResolveTokenRequest'),
+  (686094846, 'SetIdpSigninStatus'),
+  (418981594, 'UnregisterIdP'),
+  (2276214579, 'DidChangeFramePolicy'),
+  (2537588906, 'Navigate'),
+  (2466936525, 'Cancel'),
+  (4048827221, 'Clone'),
+  (2813620865, 'CreateLoader'),
+  (2674940655, 'SendNow'),
+  (1680019597, 'RegisterBlob'),
+  (3941685087, 'RegisterBlobSync'),
+  (328524945, 'EnumerateChosenDirectory'),
+  (3044585416, 'OpenFileChooser'),
+  (2136689312, 'Close'),
+  (3375563530, 'OnContentsModified'),
+  (3681340503, 'RequestCapacityChange'),
+  (2089745181, 'Clone'),
+  (572120852, 'GetInternalId'),
+  (3793612906, 'DidReadDirectory'),
+  (1485409182, 'GetCloudIdentifiers'),
+  (1028352376, 'GetDirectory'),
+  (2600955370, 'GetEntries'),
+  (2332497090, 'GetFile'),
+  (4043927714, 'GetPermissionStatus'),
+  (2048195421, 'GetUniqueId'),
+  (3174215947, 'Move'),
+  (3979016786, 'Remove'),
+  (2197879302, 'RemoveEntry'),
+  (1418983274, 'Rename'),
+  (1604347600, 'RequestPermission'),
+  (360603306, 'Resolve'),
+  (1602329283, 'Transfer'),
+  (1139664486, 'GetLength'),
+  (3280540327, 'Read'),
+  (3657412815, 'SetLength'),
+  (1912430087, 'Write'),
+  (84851551, 'AsBlob'),
+  (3930674372, 'CreateFileWriter'),
+  (2482459889, 'GetCloudIdentifiers'),
+  (3176367909, 'GetPermissionStatus'),
+  (3299702324, 'GetUniqueId'),
+  (1451232191, 'IsSameEntry'),
+  (2431685622, 'Move'),
+  (2570114296, 'OpenAccessHandle'),
+  (520093867, 'Remove'),
+  (21251198, 'Rename'),
+  (4147705669, 'RequestPermission'),
+  (2795909371, 'Transfer'),
+  (692214232, 'Abort'),
+  (490282388, 'Close'),
+  (3692463845, 'Truncate'),
+  (686631158, 'Write'),
+  (1537678874, 'BindObserverHost'),
+  (680029041, 'ChooseEntries'),
+  (1283442158, 'GetDirectoryHandleFromToken'),
+  (2454997216, 'GetEntryFromDataTransferToken'),
+  (2928527070, 'GetFileHandleFromToken'),
+  (3789364397, 'GetSandboxedFileSystem'),
+  (2064889945, 'Observe'),
+  (3545382217, 'Unobserve'),
+  (3202380274, 'OnFileChanges'),
+  (3435862342, 'Clone'),
+  (3030428334, 'GetInternalID'),
+  (1341459348, 'Cancel'),
+  (1086831084, 'Copy'),
+  (1279046914, 'Create'),
+  (3791055456, 'CreateSnapshotFile'),
+  (4042304678, 'Exists'),
+  (4124601274, 'GetPlatformPath'),
+  (4204014645, 'Move'),
+  (1277545397, 'Open'),
+  (1183593904, 'ReadDirectory'),
+  (3023558473, 'ReadDirectorySync'),
+  (3306235880, 'ReadMetadata'),
+  (3617764644, 'RegisterBlob'),
+  (46060430, 'Remove'),
+  (553802553, 'ResolveURL'),
+  (3860731505, 'Truncate'),
+  (1074434083, 'TruncateSync'),
+  (2081543769, 'Write'),
+  (4073759750, 'WriteSync'),
+  (1969836462, 'DidWrite'),
+  (555233909, 'ErrorOccurred'),
+  (2218369982, 'ResultsRetrieved'),
+  (3193809849, 'GetFileInfo'),
+  (4100119161, 'ActivateNearestFindResult'),
+  (1108647106, 'ClearActiveFindMatch'),
+  (2146968669, 'SetActiveMatch'),
+  (3801798051, 'SetNumberOfMatches'),
+  (4203334972, 'Find'),
+  (1311638811, 'FindMatchRects'),
+  (1370170483, 'GetNearestFindResult'),
+  (728590801, 'SetClient'),
+  (1423830763, 'StopFinding'),
+  (1256577392, 'EnumerateLocalFonts'),
+  (1927715657, 'GetUniqueNameLookupTable'),
+  (1437211059, 'GetUniqueNameLookupTableIfAvailable'),
+  (4009262341, 'BindInputTargetClient'),
+  (2306470062, 'BindWidgetCompositor'),
+  (3718348490, 'DisableDeviceEmulation'),
+  (1079232586, 'DragSourceEndedAt'),
+  (3065440662, 'DragSourceSystemDragEnded'),
+  (2638032261, 'DragTargetDragEnter'),
+  (3482009839, 'DragTargetDragLeave'),
+  (1225947884, 'DragTargetDragOver'),
+  (543914017, 'DragTargetDrop'),
+  (1418263384, 'EnableDeviceEmulation'),
+  (3528132268, 'AnimateDoubleTapZoomInMainFrame'),
+  (484695543, 'AutoscrollEnd'),
+  (2439838982, 'AutoscrollFling'),
+  (1300077942, 'AutoscrollStart'),
+  (3410956171, 'IntrinsicSizingInfoChanged'),
+  (819120956, 'SetHasTouchEventConsumers'),
+  (703387435, 'ZoomToFindInPageRectInMainFrame'),
+  (1460799893, 'AddImeTextSpansToExistingText'),
+  (2687647592, 'AdjustSelectionByCharacterOffset'),
+  (2003475068, 'CenterSelection'),
+  (945976073, 'ClearImeTextSpansByType'),
+  (2914572085, 'CollapseSelection'),
+  (4140689611, 'Copy'),
+  (3410992162, 'CopyToFindPboard'),
+  (2958435604, 'Cut'),
+  (2581691669, 'Delete'),
+  (1276460431, 'DeleteSurroundingText'),
+  (90726989, 'DeleteSurroundingTextInCodePoints'),
+  (146481515, 'ExecuteEditCommand'),
+  (307217861, 'ExtendSelectionAndDelete'),
+  (853098545, 'ExtendSelectionAndReplace'),
+  (227031634, 'HandleStylusWritingGestureAction'),
+  (2577385542, 'MoveCaret'),
+  (3789859106, 'MoveRangeSelectionExtent'),
+  (548110250, 'Paste'),
+  (2892028588, 'PasteAndMatchStyle'),
+  (2734083268, 'Redo'),
+  (1200309639, 'Replace'),
+  (528618447, 'ReplaceMisspelling'),
+  (225468182, 'ScrollFocusedEditableNodeIntoView'),
+  (3338226080, 'SelectAll'),
+  (3342590527, 'SelectAroundCaret'),
+  (2062346498, 'SelectRange'),
+  (3838021608, 'SetCompositionFromExistingText'),
+  (1961100789, 'SetEditableSelectionOffsets'),
+  (1340897012, 'Undo'),
+  (1892434623, 'WaitForPageScaleAnimationForTesting'),
+  (2740338960, 'OnStartStylusWriting'),
+  (603318547, 'SetActive'),
+  (3409087346, 'SetBackgroundOpaque'),
+  (2405007921, 'SetInheritedEffectiveTouchActionForSubFrame'),
+  (3683329670, 'SetIsInertForSubFrame'),
+  (2644542400, 'SetTextDirection'),
+  (1544016022, 'SetViewportIntersection'),
+  (1302162758, 'ShowContextMenu'),
+  (1791212314, 'UpdateRenderThrottlingStatusForSubFrame'),
+  (3621319526, 'RequestFullscreenVideoElement'),
+  (79068364, 'CreateGeolocation'),
+  (1920592710, 'Are3DAPIsBlockedForUrl'),
+  (2890541480, 'Connect'),
+  (3637540962, 'Forget'),
+  (3367917160, 'GetDevices'),
+  (2777538087, 'RegisterClient'),
+  (3598814318, 'RequestDevice'),
+  (813020890, 'DispatchBeforeUnload'),
+  (1765855090, 'OpenDictionary'),
+  (2163630174, 'Advance'),
+  (2446256965, 'Continue'),
+  (2538106252, 'Prefetch'),
+  (2217477716, 'PrefetchReset'),
+  (2452456527, 'Abort'),
+  (1902297148, 'Abort'),
+  (3675134814, 'Complete'),
+  (1626451721, 'ForcedClose'),
+  (2942309124, 'VersionChange'),
+  (2251575755, 'Clear'),
+  (2835498260, 'Close'),
+  (4073294306, 'Count'),
+  (3322525714, 'CreateIndex'),
+  (3263056097, 'CreateTransaction'),
+  (2226967637, 'DeleteIndex'),
+  (2918827080, 'DeleteRange'),
+  (1248941106, 'DidBecomeInactive'),
+  (420685851, 'Get'),
+  (2542496193, 'GetAll'),
+  (1010181228, 'OnError'),
+  (1501344461, 'ReceiveKeys'),
+  (1246421956, 'ReceiveValues'),
+  (137473483, 'GetKeyGeneratorCurrentNumber'),
+  (2739634069, 'OpenCursor'),
+  (2638319399, 'RenameIndex'),
+  (2415999371, 'RenameObjectStore'),
+  (2016507220, 'SetIndexesReady'),
+  (3628930200, 'SetIndexKeys'),
+  (3602441157, 'VersionChangeIgnored'),
+  (2394464146, 'Blocked'),
+  (1390541783, 'DeleteSuccess'),
+  (354043987, 'Error'),
+  (1933059289, 'OpenSuccess'),
+  (2001473866, 'UpgradeNeeded'),
+  (121616465, 'DeleteDatabase'),
+  (3511616394, 'GetDatabaseInfo'),
+  (1569400293, 'Open'),
+  (2234756584, 'Commit'),
+  (213127992, 'CreateObjectStore'),
+  (98371715, 'DeleteObjectStore'),
+  (3937939719, 'Put'),
+  (3146914094, 'AddMonitor'),
+  (1814745066, 'Update'),
+  (1850754588, 'DownloadImage'),
+  (3749133001, 'Release'),
+  (3009066898, 'OnInstall'),
+  (155815797, 'FilterInstalledApps'),
+  (2974731687, 'IssueKeepAliveHandle'),
+  (2396508011, 'CancelKeyboardLock'),
+  (2590079781, 'GetKeyboardLayoutMap'),
+  (2220103604, 'RequestKeyboardLock'),
+  (4243627632, 'NotifyFetchedFont'),
+  (2604521134, 'SetLcpElementLocator'),
+  (525123972, 'SetLcpInfluencerScriptUrls'),
+  (975040017, 'PerformLeakDetection'),
+  (1641339048, 'AddInspectorIssue'),
+  (3347972133, 'AddMessageToConsole'),
+  (1286444995, 'AddResourceTimingEntryForFailedSubframeNavigation'),
+  (2373179499, 'AdvanceFocusForIME'),
+  (95920899, 'AdvanceFocusInFrame'),
+  (855280385, 'BeforeUnload'),
+  (4026737823, 'BindDevToolsAgent'),
+  (2474265815, 'BindReportingObserver'),
+  (1046583454, 'CheckCompleted'),
+  (1488852653, 'ClearFocusedElement'),
+  (416256009, 'Collapse'),
+  (2111449033, 'CopyImageAt'),
+  (2701936063, 'DidUpdateFramePolicy'),
+  (1404750877, 'EnableViewSourceMode'),
+  (4013798249, 'ExtractSmartClipData'),
+  (1060462906, 'Focus'),
+  (3660613642, 'GetCanonicalUrlForSharing'),
+  (3649461695, 'GetOpenGraphMetadata'),
+  (3989015596, 'GetSavableResourceLinks'),
+  (2895575539, 'GetTextSurroundingSelection'),
+  (2656329020, 'HandleRendererDebugURL'),
+  (2195569282, 'AdoptPortal'),
+  (1511296613, 'BubbleLogicalScrollInParentFrame'),
+  (2027272724, 'CapturePaintPreviewOfSubframe'),
+  (4129771255, 'CreateFencedFrame'),
+  (1598629729, 'CreateNewPopupWidget'),
+  (1268887206, 'CreatePortal'),
+  (3124232810, 'Detach'),
+  (412443934, 'DidAddMessageToConsole'),
+  (2270712626, 'DidBlockNavigation'),
+  (2105860095, 'DidCallFocus'),
+  (1997205994, 'DidChangeBackgroundColor'),
+  (2177860990, 'DidChangeFrameOwnerProperties'),
+  (1977289357, 'DidChangeFramePolicy'),
+  (1466699684, 'DidChangeIframeAttributes'),
+  (3716466459, 'DidChangeLoadProgress'),
+  (4264983514, 'DidChangeOpener'),
+  (1656053608, 'DidChangeSrcDoc'),
+  (3877630179, 'DidChangeThemeColor'),
+  (636932619, 'DidConsumeHistoryUserActivation'),
+  (3070179262, 'DidContainInsecureFormAction'),
+  (1023753144, 'DidDispatchDOMContentLoadedEvent'),
+  (3874227723, 'DidDisplayInsecureContent'),
+  (1353731132, 'DidFailLoadWithError'),
+  (3395298888, 'DidFinishLoad'),
+  (352076130, 'DidFocusFrame'),
+  (300723280, 'DidInferColorScheme'),
+  (286853256, 'DidLoadResourceFromMemoryCache'),
+  (2086664397, 'DispatchLoad'),
+  (3162150329, 'DocumentOnLoadCompleted'),
+  (2668061873, 'DownloadURL'),
+  (4101742307, 'EnforceInsecureNavigationsSet'),
+  (316282272, 'EnforceInsecureRequestPolicy'),
+  (3689362720, 'EnterFullscreen'),
+  (3462377740, 'ExitFullscreen'),
+  (568487315, 'FocusedElementChanged'),
+  (1983984653, 'ForwardResourceTimingToParent'),
+  (3721282066, 'FrameSizeChanged'),
+  (2264370461, 'FullscreenStateChanged'),
+  (574640235, 'GetKeepAliveHandleFactory'),
+  (3158527243, 'GoToEntryAtOffset'),
+  (3500964934, 'HadStickyUserActivationBeforeNavigationChanged'),
+  (1214137507, 'HandleAccessibilityFindInPageResult'),
+  (973335421, 'HandleAccessibilityFindInPageTermination'),
+  (3837109250, 'MainDocumentElementAvailable'),
+  (1080993489, 'Maximize'),
+  (60674564, 'Minimize'),
+  (2913689884, 'NavigateEventHandlerPresenceChanged'),
+  (2493116149, 'NavigateToNavigationApiKey'),
+  (2382205651, 'OnViewTransitionOptInChanged'),
+  (3704208140, 'ReceivedDelegatedCapability'),
+  (1837282257, 'RegisterProtocolHandler'),
+  (3867543164, 'Restore'),
+  (1743292217, 'RunBeforeUnloadConfirm'),
+  (2062010071, 'RunModalAlertDialog'),
+  (686885315, 'RunModalConfirmDialog'),
+  (3345654858, 'RunModalPromptDialog'),
+  (988912345, 'ScrollRectToVisibleInParentFrame'),
+  (4096061682, 'SendFencedFrameReportingBeacon'),
+  (1911643833, 'SendFencedFrameReportingBeaconToCustomURL'),
+  (4205136864, 'SendLegacyTechEvent'),
+  (3106886237, 'SendPrivateAggregationRequestsForFencedFrameEvent'),
+  (3773165937, 'SetCloseListener'),
+  (1683118313, 'SetFencedFrameAutomaticBeaconReportEventData'),
+  (3328612082, 'SetNeedsOcclusionTracking'),
+  (2650326712, 'SetVirtualKeyboardMode'),
+  (601373591, 'ShowContextMenu'),
+  (1185475949, 'ShowPopupMenu'),
+  (3237065063, 'StartDragging'),
+  (2552468173, 'StartLoadingForAsyncNavigationApiCommit'),
+  (1724615644, 'SuddenTerminationDisablerChanged'),
+  (2544331498, 'TextSelectionChanged'),
+  (1611596475, 'UnregisterProtocolHandler'),
+  (431437509, 'UpdateFaviconURL'),
+  (487718473, 'UpdateTitle'),
+  (132910108, 'UpdateUserActivationState'),
+  (495838918, 'VisibilityChanged'),
+  (3069490054, 'JavaScriptExecuteRequest'),
+  (4281001592, 'JavaScriptExecuteRequestForTests'),
+  (312551809, 'JavaScriptExecuteRequestInIsolatedWorld'),
+  (995534453, 'JavaScriptMethodExecuteRequest'),
+  (2059989329, 'MediaPlayerActionAt'),
+  (2197051003, 'MixedContentFound'),
+  (648199905, 'NotifyNavigationApiOfDisposedEntries'),
+  (3413058168, 'NotifyUserActivation'),
+  (1227721423, 'NotifyVirtualKeyboardOverlayRect'),
+  (16922313, 'PluginActionAt'),
+  (2698044462, 'PostMessageEvent'),
+  (1153580355, 'RenderFallbackContent'),
+  (3667045029, 'ReportBlinkFeatureUsage'),
+  (4197040946, 'ReportContentSecurityPolicyViolation'),
+  (3877491537, 'RequestFullscreenDocumentElement'),
+  (1373889775, 'SaveImageAt'),
+  (3715767689, 'SendInterventionReport'),
+  (2816293776, 'SetFrameOwnerProperties'),
+  (891228425, 'SetNavigationApiHistoryEntriesForRestore'),
+  (2872017935, 'SnapshotDocumentForViewTransition'),
+  (1768411298, 'StopLoading'),
+  (1043339546, 'SwapInImmediately'),
+  (3731538737, 'TraverseCancelled'),
+  (353070023, 'UpdateOpener'),
+  (2187871927, 'AnimateDoubleTapZoom'),
+  (737441730, 'ClosePage'),
+  (1447921580, 'EnablePreferredSizeChangedMode'),
+  (4033724355, 'ForwardMessageFromHost'),
+  (2159574362, 'GetFullPageSize'),
+  (2992279710, 'ContentsPreferredSizeChanged'),
+  (2621113203, 'DidAccessInitialMainDocument'),
+  (453132784, 'DidFirstVisuallyNonEmptyPaint'),
+  (191148950, 'FocusPage'),
+  (3094627400, 'RequestClose'),
+  (2936437485, 'ScaleFactorChanged'),
+  (330720987, 'SetWindowRect'),
+  (1203769624, 'ShowCreatedWindow'),
+  (575260254, 'TakeFocus'),
+  (2681895571, 'TextAutosizerPageInfoChanged'),
+  (2220333980, 'UpdateTargetURL'),
+  (2181181670, 'InstallCoopAccessMonitor'),
+  (897566684, 'OnPortalActivated'),
+  (2777621222, 'SetInitialFocus'),
+  (79986184, 'SetScaleFactor'),
+  (3872843018, 'SetV8CompileHints'),
+  (2603884585, 'UpdateBrowserControlsState'),
+  (3380320160, 'ZoomToFindInPageRect'),
+  (1838620424, 'QueryState'),
+  (3864692387, 'RequestLock'),
+  (225610022, 'Failed'),
+  (914188852, 'Granted'),
+  (54528767, 'GetKeys'),
+  (2523509377, 'SetData'),
+  (1496794323, 'OnConfigurationChanged'),
+  (95000504, 'GetManagedConfiguration'),
+  (2543878351, 'SubscribeToManagedConfiguration'),
+  (469016085, 'ParseManifestFromString'),
+  (3247973346, 'RequestManifest'),
+  (3346246644, 'RequestManifestDebugInfo'),
+  (3143404307, 'ManifestUrlChanged'),
+  (176945773, 'AddMediaDevicesListener'),
+  (231348809, 'CloseFocusWindowOfOpportunity'),
+  (1333724593, 'EnumerateDevices'),
+  (2641306874, 'GetAllVideoInputDeviceFormats'),
+  (1154548641, 'GetAudioInputCapabilities'),
+  (413562229, 'GetAvailableVideoInputDeviceFormats'),
+  (3223436002, 'GetVideoInputCapabilities'),
+  (636613945, 'ProduceCropId'),
+  (3269016905, 'SetCaptureHandleConfig'),
+  (2135513457, 'OnDevicesChanged'),
+  (1553022464, 'DidReceiveAction'),
+  (2338673210, 'DisableAction'),
+  (1568474206, 'EnableAction'),
+  (3352514807, 'SetCameraState'),
+  (3785821957, 'SetClient'),
+  (3230019410, 'SetMetadata'),
+  (657275323, 'SetMicrophoneState'),
+  (2659244105, 'SetPlaybackState'),
+  (862978405, 'SetPositionState'),
+  (397308935, 'OnDeviceCaptureConfigurationChange'),
+  (2113660574, 'OnDeviceCaptureHandleChange'),
+  (2512699880, 'OnDeviceChanged'),
+  (2669507425, 'OnDeviceRequestStateChange'),
+  (711194380, 'OnDeviceStopped'),
+  (1655929766, 'CancelRequest'),
+  (1470263475, 'CloseDevice'),
+  (2550476426, 'Crop'),
+  (3656397049, 'FocusCapturedSurface'),
+  (3607174806, 'GenerateStreams'),
+  (2601793791, 'GetOpenDevice'),
+  (3894297263, 'KeepDeviceAliveForTransfer'),
+  (951606455, 'OnStreamStarted'),
+  (225044872, 'OpenDevice'),
+  (1194659003, 'SetCapturingLinkSecured'),
+  (2609115435, 'StopStreamDevice'),
+  (2335170910, 'AddTrack'),
+  (2963412838, 'RemoveTrack'),
+  (1209000629, 'SetProcFiles'),
+  (3269624406, 'GetMimeTypeFromExtension'),
+  (1108994056, 'MaybeStartOutermostMainFrameNavigation'),
+  (3108247901, 'OnClick'),
+  (1114875965, 'OnClose'),
+  (3786604185, 'OnShow'),
+  (1459109111, 'Cancel'),
+  (4049716657, 'Start'),
+  (3979237728, 'CloseNonPersistentNotification'),
+  (1213429649, 'ClosePersistentNotification'),
+  (2960622344, 'DisplayNonPersistentNotification'),
+  (295085159, 'DisplayPersistentNotification'),
+  (2712916095, 'GetNotifications'),
+  (2534607082, 'GetPermissionStatus'),
+  (341483141, 'DidResolveRegistration'),
+  (3592915575, 'GetRegistrations'),
+  (1720988842, 'Register'),
+  (1325345435, 'OnHighMemoryUsage'),
+  (3087162418, 'StartDetection'),
+  (3887826643, 'ApplyFeatureDiffForOriginTrial'),
+  (3584624643, 'EnablePersistentTrial'),
+  (1179601572, 'ActivatePrerenderedPage'),
+  (3122947388, 'AudioStateChanged'),
+  (73667072, 'CreateRemoteMainFrame'),
+  (3789602807, 'SetHistoryOffsetAndLength'),
+  (21142420, 'SetInsidePortal'),
+  (3727082240, 'SetPageBaseBackgroundColor'),
+  (2723506334, 'SetPageLifecycleState'),
+  (3433443499, 'UpdatePageBrowsingContextGroup'),
+  (68279521, 'UpdateRendererPreferences'),
+  (1682824955, 'UpdateWebPreferences'),
+  (4237436327, 'GetCurrentState'),
+  (3211493794, 'GetLegacyStats'),
+  (3287052705, 'GetStandardStats'),
+  (349954390, 'OnSpeedLimitChange'),
+  (1999251242, 'OnSuspend'),
+  (3738280094, 'OnThermalStateChange'),
+  (3808327193, 'StartEventLog'),
+  (411935255, 'StopEventLog'),
+  (3966529989, 'AddLegacyStats'),
+  (1760322164, 'AddPeerConnection'),
+  (827745587, 'AddStandardStats'),
+  (2263470652, 'GetDisplayMedia'),
+  (3765103796, 'GetDisplayMediaFailure'),
+  (712762820, 'GetDisplayMediaSuccess'),
+  (1903091103, 'GetUserMedia'),
+  (444894877, 'GetUserMediaFailure'),
+  (3604258791, 'GetUserMediaSuccess'),
+  (2047301243, 'OnPeerConnectionSessionIdSet'),
+  (3839202339, 'RemovePeerConnection'),
+  (1145450558, 'UpdatePeerConnection'),
+  (877703137, 'WebRtcEventLogWrite'),
+  (3000201473, 'Deactivate'),
+  (1792715724, 'CreateBeacon'),
+  (2426484616, 'SendNow'),
+  (3289106177, 'SetRequestData'),
+  (2243183213, 'SetRequestURL'),
+  (2652290861, 'GetRegistrations'),
+  (615507611, 'Register'),
+  (1291489406, 'Unregister'),
+  (3367719800, 'OnPermissionStatusChange'),
+  (955270278, 'AddPermissionObserver'),
+  (772438597, 'HasPermission'),
+  (4157278739, 'NotifyEventListener'),
+  (1516149202, 'RequestPageEmbeddedPermission'),
+  (322855744, 'RequestPermission'),
+  (3428229935, 'RequestPermissions'),
+  (2829473024, 'RevokePermission'),
+  (2776888455, 'StartSession'),
+  (3338071954, 'OnStopped'),
+  (2649113675, 'OnWindowSizeChanged'),
+  (2000079949, 'Stop'),
+  (434165052, 'Update'),
+  (4290632471, 'GetPlugins'),
+  (3420030960, 'RequestMouseLockChange'),
+  (3287532569, 'AddContentSecurityPolicies'),
+  (3821171500, 'IssueKeepAliveHandle'),
+  (3608477859, 'SetReferrerPolicy'),
+  (3228750645, 'DidAcceptIndices'),
+  (1146914189, 'DidCancel'),
+  (952593085, 'RequestClosePopup'),
+  (3985409599, 'SetPopupBounds'),
+  (4215946667, 'ShowPopup'),
+  (4157349688, 'Activate'),
+  (2011597841, 'DispatchLoadEvent'),
+  (1679990044, 'ForwardMessageFromGuest'),
+  (1292311517, 'PostMessageToHost'),
+  (2017262908, 'Navigate'),
+  (4130021214, 'PostMessageToGuest'),
+  (788042074, 'DidChangeState'),
+  (2490957761, 'DidClose'),
+  (3338623290, 'OnMessage'),
+  (2747912511, 'OnConnectionClosed'),
+  (3225431288, 'OnConnectionStateChanged'),
+  (1480465971, 'OnDefaultPresentationStarted'),
+  (2695908223, 'OnScreenAvailabilityUpdated'),
+  (3616630562, 'OnReceiverConnectionAvailable'),
+  (2615768842, 'CloseConnection'),
+  (3202951471, 'ListenForScreenAvailability'),
+  (1521640530, 'ReconnectPresentation'),
+  (2513276506, 'SetController'),
+  (4065112428, 'SetDefaultPresentationUrls'),
+  (1483576025, 'SetReceiver'),
+  (3960791612, 'StartPresentation'),
+  (1547551816, 'StopListeningForScreenAvailability'),
+  (128144289, 'Terminate'),
+  (1017207428, 'ContributeToHistogram'),
+  (2700674047, 'EnableDebugMode'),
+  (1748156846, 'OnProgress'),
+  (1572488881, 'GetSubscription'),
+  (2025841810, 'Subscribe'),
+  (4047421659, 'Unsubscribe'),
+  (463057040, 'OnQuotaChange'),
+  (41108358, 'AddChangeListener'),
+  (3482855944, 'QueryStorageUsageAndQuota'),
+  (1371607226, 'DidReceiveSnapshotFile'),
+  (2152872386, 'AddResourceTimingFromChild'),
+  (3668051875, 'BubbleLogicalScroll'),
+  (241372468, 'ChildProcessGone'),
+  (936193611, 'Collapse'),
+  (4221826357, 'CreateRemoteChild'),
+  (2163428749, 'CreateRemoteChildren'),
+  (1293455874, 'DetachAndDispose'),
+  (2837190596, 'DidSetFramePolicyHeaders'),
+  (3808879027, 'DidStartLoading'),
+  (868126304, 'DidStopLoading'),
+  (603220111, 'DidUpdateFramePolicy'),
+  (75331146, 'DidUpdateVisualProperties'),
+  (3143401549, 'DisableAutoResize'),
+  (2648661715, 'DispatchLoadEventForFrameOwner'),
+  (3092380122, 'EnableAutoResize'),
+  (3335777437, 'EnforceInsecureNavigationsSet'),
+  (2563262293, 'EnforceInsecureRequestPolicy'),
+  (3312715238, 'Focus'),
+  (3081540893, 'AdvanceFocus'),
+  (3979837433, 'CapturePaintPreviewOfCrossProcessSubframe'),
+  (695874450, 'CheckCompleted'),
+  (2579933166, 'Detach'),
+  (1821452097, 'DidChangeOpener'),
+  (152822277, 'DidFocusFrame'),
+  (3953362377, 'OpenURL'),
+  (3816696370, 'PrintCrossProcessSubframe'),
+  (389662449, 'RouteMessageEvent'),
+  (505382698, 'SetInheritedEffectiveTouchAction'),
+  (3279529702, 'SetIsInert'),
+  (637930071, 'SynchronizeVisualProperties'),
+  (1301309822, 'UpdateRenderThrottlingStatus'),
+  (1391967000, 'UpdateViewportIntersection'),
+  (2122411306, 'VisibilityChanged'),
+  (3674740809, 'IntrinsicSizingInfoOfChildChanged'),
+  (3327329459, 'RenderFallbackContent'),
+  (2973859169, 'ScrollRectToVisible'),
+  (3984360368, 'SetEmbeddingToken'),
+  (890487506, 'SetFrameOwnerProperties'),
+  (3155154303, 'SetFrameSinkId'),
+  (1242265569, 'SetHadStickyUserActivationBeforeNavigation'),
+  (1273083243, 'SetNeedsOcclusionTracking'),
+  (1871171689, 'SetPageFocus'),
+  (1656520838, 'SetReplicatedIsAdFrame'),
+  (3321229720, 'SetReplicatedName'),
+  (602195852, 'SetReplicatedOrigin'),
+  (3788938025, 'UpdateOpener'),
+  (3908972418, 'UpdateUserActivationState'),
+  (88125000, 'WillEnterFullscreen'),
+  (1499718673, 'FocusPage'),
+  (794400878, 'RouteCloseEvent'),
+  (3120758554, 'TakeFocus'),
+  (3856635293, 'UpdateTargetURL'),
+  (1959406370, 'UpdateTextAutosizerPageInfo'),
+  (714124344, 'AddNamedObject'),
+  (4149828782, 'CreateRemoteObjectGateway'),
+  (1152389987, 'RemoveNamedObject'),
+  (2146197017, 'GetMethods'),
+  (1081205770, 'HasMethod'),
+  (1680282036, 'AcquireObject'),
+  (2133530465, 'GetObject'),
+  (2833211915, 'ReleaseObject'),
+  (3101779779, 'InvokeMethod'),
+  (2602173225, 'NotifyReleasedObject'),
+  (3572379997, 'FatalError'),
+  (3627980428, 'HitTest'),
+  (4114284947, 'HandleAXEvents'),
+  (4021165875, 'HandleAXLocationChanges'),
+  (1712633939, 'PerformAction'),
+  (3197596847, 'Reset'),
+  (1333527917, 'SetMode'),
+  (2604988818, 'AssociateInputAndOutputForAec'),
+  (2581329109, 'StreamCreated'),
+  (797334233, 'CreateStream'),
+  (2578331814, 'RequestDeviceAuthorization'),
+  (606571783, 'NotifyUpdate'),
+  (3116815768, 'Notify'),
+  (766899964, 'QueueCspViolationReport'),
+  (4126530200, 'QueueDeprecationReport'),
+  (108927376, 'QueueDocumentPolicyViolationReport'),
+  (4096607811, 'QueueInterventionReport'),
+  (1598669232, 'QueuePermissionsPolicyViolationReport'),
+  (3034853792, 'Contains'),
+  (737465942, 'Clone'),
+  (2876181821, 'NotifyResourceLoadCanceled'),
+  (1260868577, 'NotifyResourceLoadCompleted'),
+  (1840825812, 'NotifyResourceRedirectReceived'),
+  (3648353257, 'NotifyResourceResponseReceived'),
+  (3703601544, 'NotifyResourceTransferSizeUpdated'),
+  (3672508382, 'NotifyUpdateUserGestureCarryoverInfo'),
+  (3584146607, 'OnPortAdded'),
+  (1701093372, 'OnPortRemoved'),
+  (3335954763, 'ForgetPort'),
+  (638785786, 'GetPorts'),
+  (3345260649, 'OpenPort'),
+  (3267275199, 'RequestPort'),
+  (1593970610, 'SetClient'),
+  (1254159214, 'AddKeepAlive'),
+  (2561484433, 'AddMessageToConsole'),
+  (2526628869, 'ClearKeepAlive'),
+  (3876015860, 'CountFeature'),
+  (738617888, 'CloneContainerHost'),
+  (3633360884, 'EnsureControllerServiceWorker'),
+  (571096038, 'EnsureFileAccess'),
+  (1767760242, 'GetRegistration'),
+  (1958744305, 'GetRegistrationForReady'),
+  (3629909817, 'GetRegistrations'),
+  (3491257268, 'HintToUpdateServiceWorker'),
+  (1915472522, 'OnExecutionReady'),
+  (826296802, 'Register'),
+  (1101041475, 'PostMessageToClient'),
+  (2128963182, 'SetController'),
+  (2901383386, 'DispatchAbortPaymentEvent'),
+  (3717148884, 'DispatchActivateEvent'),
+  (1442630276, 'DispatchBackgroundFetchAbortEvent'),
+  (1563298104, 'DispatchBackgroundFetchClickEvent'),
+  (3733124, 'DispatchBackgroundFetchFailEvent'),
+  (2417245393, 'DispatchBackgroundFetchSuccessEvent'),
+  (4206780042, 'DispatchCanMakePaymentEvent'),
+  (1076925115, 'DispatchContentDeleteEvent'),
+  (2008147060, 'DispatchCookieChangeEvent'),
+  (54712779, 'DispatchExtendableMessageEvent'),
+  (1261547922, 'DispatchFetchEventForMainResource'),
+  (1574225043, 'DispatchInstallEvent'),
+  (3086109091, 'DispatchNotificationClickEvent'),
+  (2314165714, 'DispatchNotificationCloseEvent'),
+  (2692624690, 'DispatchPaymentRequestEvent'),
+  (2325567305, 'DispatchPeriodicSyncEvent'),
+  (688915152, 'DispatchPushEvent'),
+  (3265027550, 'DispatchPushSubscriptionChangeEvent'),
+  (3997282242, 'DispatchSyncEvent'),
+  (2550257636, 'ExecuteScriptForTest'),
+  (3277259609, 'OnFallback'),
+  (2668917436, 'OnResponse'),
+  (377818102, 'OnResponseStream'),
+  (3407735805, 'ClaimClients'),
+  (139511129, 'ClearCachedMetadata'),
+  (2590694527, 'FocusClient'),
+  (2762138837, 'GetClient'),
+  (3117238646, 'GetClients'),
+  (1438644110, 'NavigateClient'),
+  (2528637812, 'OpenNewTab'),
+  (1061983509, 'OpenPaymentHandlerWindow'),
+  (2816753317, 'PostMessageToClient'),
+  (594747315, 'RegisterRouter'),
+  (1327894839, 'SetCachedMetadata'),
+  (4123227516, 'SkipWaiting'),
+  (4119585511, 'InitializeGlobalScope'),
+  (3273180580, 'RequestInstalledScript'),
+  (1848381855, 'TransferInstalledScript'),
+  (3620150749, 'PostMessageToServiceWorker'),
+  (1408244899, 'TerminateForTesting'),
+  (148150019, 'StateChanged'),
+  (2898455796, 'Ping'),
+  (2656054538, 'EnableNavigationPreload'),
+  (3431529225, 'GetNavigationPreloadState'),
+  (2208422565, 'SetNavigationPreloadHeader'),
+  (4022300523, 'Unregister'),
+  (897653742, 'Update'),
+  (2422564710, 'SetServiceWorkerObjects'),
+  (4181430137, 'SetUpdateViaCache'),
+  (2729686083, 'UpdateFound'),
+  (2235301144, 'OnStatusChanged'),
+  (2234980761, 'SetIdleDelay'),
+  (1541058465, 'OnAborted'),
+  (48518876, 'OnCompleted'),
+  (3061818020, 'OnControllerChanged'),
+  (3754723197, 'CloneWorkerClientRegistry'),
+  (3214051659, 'RegisterWorkerClient'),
+  (3176181858, 'Clone'),
+  (3743121224, 'AddModuleOnWorklet'),
+  (2337624007, 'RunOperationOnWorklet'),
+  (240216117, 'RunURLSelectionOperationOnWorklet'),
+  (1385876513, 'SharedStorageAppend'),
+  (3850957701, 'SharedStorageClear'),
+  (944029769, 'SharedStorageDelete'),
+  (1210328326, 'SharedStorageSet'),
+  (278086905, 'DidReadEntries'),
+  (667212575, 'AddModule'),
+  (2446870329, 'ConsoleLog'),
+  (2937548451, 'RecordUseCounters'),
+  (1650731660, 'SharedStorageAppend'),
+  (315855754, 'SharedStorageClear'),
+  (1716602782, 'SharedStorageDelete'),
+  (1546454759, 'SharedStorageEntries'),
+  (195607425, 'SharedStorageGet'),
+  (931473904, 'SharedStorageKeys'),
+  (2661167058, 'SharedStorageLength'),
+  (2276073090, 'SharedStorageRemainingBudget'),
+  (2396482081, 'SharedStorageSet'),
+  (1346195380, 'Initialize'),
+  (184606513, 'RunOperation'),
+  (98289539, 'RunURLSelectionOperation'),
+  (1216331209, 'OnConnected'),
+  (443282202, 'OnCreated'),
+  (747458921, 'OnFeatureUsed'),
+  (3405768449, 'OnScriptLoadFailed'),
+  (3745172681, 'Connect'),
+  (3571558593, 'Connect'),
+  (2388257055, 'CreateSharedWorker'),
+  (1681898925, 'OnConnected'),
+  (157659230, 'OnContextClosed'),
+  (2534282855, 'OnFeatureUsed'),
+  (1221681048, 'OnReadyForInspection'),
+  (2369494032, 'OnScriptLoadFailed'),
+  (2033104311, 'Terminate'),
+  (1549211034, 'Share'),
+  (521681587, 'CreateContext'),
+  (3873790966, 'EnableNoVarySearchSupport'),
+  (761722924, 'InitiatePreview'),
+  (3911116378, 'UpdateSpeculationCandidates'),
+  (3090679934, 'Abort'),
+  (1791621766, 'AudioEnded'),
+  (3761045855, 'AudioStarted'),
+  (600447390, 'Ended'),
+  (1876086567, 'ErrorOccurred'),
+  (778308224, 'ResultRetrieved'),
+  (3168656963, 'SoundEnded'),
+  (2827242026, 'SoundStarted'),
+  (4124268224, 'Started'),
+  (2471639692, 'StopCapture'),
+  (2380514912, 'Start'),
+  (1882367376, 'AddVoiceListObserver'),
+  (254664603, 'Cancel'),
+  (3003058739, 'OnEncounteredSentenceBoundary'),
+  (2551325986, 'OnEncounteredSpeakingError'),
+  (1526144725, 'OnEncounteredWordBoundary'),
+  (1272875513, 'OnFinishedSpeaking'),
+  (3708689039, 'OnPausedSpeaking'),
+  (2214797370, 'OnResumedSpeaking'),
+  (3560988076, 'OnStartedSpeaking'),
+  (2705368144, 'Pause'),
+  (3992079558, 'Resume'),
+  (2153052633, 'Speak'),
+  (2993498785, 'OnSetVoiceList'),
+  (3484441540, 'AddObserver'),
+  (3027504960, 'Delete'),
+  (1852524270, 'DeleteAll'),
+  (2961565216, 'Get'),
+  (750467104, 'GetAll'),
+  (2239563386, 'AllDeleted'),
+  (2196903550, 'KeyChanged'),
+  (3201092315, 'KeyChangeFailed'),
+  (362758420, 'KeyDeleted'),
+  (688460913, 'ShouldSendOldValueOnMutations'),
+  (692843433, 'Put'),
+  (3069037057, 'Add'),
+  (3355538669, 'List'),
+  (4286984679, 'Remove'),
+  (1989153118, 'UpdateSubresourceLoaderFactories'),
+  (660956826, 'SetLocalSurfaceId'),
+  (3282697690, 'BeginFrame'),
+  (4276627319, 'BeginFrameResponse'),
+  (1874508037, 'ReturnFrame'),
+  (2304880354, 'DemandDrawHw'),
+  (1330930130, 'DemandDrawHwAsync'),
+  (3437848961, 'DemandDrawSw'),
+  (988005029, 'LayerTreeFrameSinkCreated'),
+  (3232147200, 'SetNeedsBeginFrames'),
+  (114385298, 'UpdateState'),
+  (1400942178, 'OnCompositorFrameTransitionDirectiveProcessed'),
+  (2220017166, 'ReclaimResources'),
+  (382754661, 'SetBeginFrameSourcePaused'),
+  (2777016630, 'SetMemoryPolicy'),
+  (291775800, 'SetScroll'),
+  (319312147, 'SetSharedMemory'),
+  (1742476724, 'WillSkipDraw'),
+  (11668875, 'ZeroSharedMemory'),
+  (1235565425, 'ZoomBy'),
+  (3743768165, 'Cancel'),
+  (1831801334, 'ExtractFirstFragmentRect'),
+  (3655986418, 'ExtractTextFragmentsMatches'),
+  (1553940656, 'GetExistingSelectors'),
+  (1881798200, 'RemoveFragments'),
+  (2008682365, 'RequestSelector'),
+  (2485033496, 'ApplySpellCheckSuggestion'),
+  (3197739717, 'ApplyTextSuggestion'),
+  (2792583152, 'DeleteActiveSuggestionRange'),
+  (111207054, 'OnNewWordAddedToDictionary'),
+  (2051168203, 'OnSuggestionMenuClosed'),
+  (3652112370, 'SuggestionMenuTimeoutCallback'),
+  (427805855, 'ShowSpellCheckSuggestionMenu'),
+  (3376932650, 'ShowTextSuggestionMenu'),
+  (2811247687, 'StartSuggestionMenuTimer'),
+  (3738228, 'ShowUnhandledTapUIIfNeeded'),
+  (794206605, 'GetV8MemoryUsage'),
+  (45049298, 'GetWakeLock'),
+  (2251642264, 'AdvertisingEvent'),
+  (13631854, 'RemoteCharacteristicValueChanged'),
+  (2370525562, 'GATTServerDisconnected'),
+  (2920030046, 'ForgetDevice'),
+  (2195080055, 'GetAvailability'),
+  (648282006, 'GetDevices'),
+  (3363699642, 'RemoteCharacteristicGetDescriptors'),
+  (2063556475, 'RemoteCharacteristicReadValue'),
+  (2370252784, 'RemoteCharacteristicStartNotifications'),
+  (3377364072, 'RemoteCharacteristicStopNotifications'),
+  (3528035123, 'RemoteCharacteristicWriteValue'),
+  (3682612238, 'RemoteDescriptorReadValue'),
+  (2429318859, 'RemoteDescriptorWriteValue'),
+  (3331701147, 'RemoteServerConnect'),
+  (2493819763, 'RemoteServerDisconnect'),
+  (2714552070, 'RemoteServerGetPrimaryServices'),
+  (1656485698, 'RemoteServiceGetCharacteristics'),
+  (2853404712, 'RequestDevice'),
+  (961921046, 'RequestScanningStart'),
+  (646497529, 'WatchAdvertisementsForDevice'),
+  (833122768, 'CloseImmediately'),
+  (2010599, 'Closed'),
+  (990961569, 'DeleteFile'),
+  (3270888487, 'GetFileAttributes'),
+  (3792454827, 'GetSpaceAvailable'),
+  (3419561255, 'HandleSqliteError'),
+  (1857533463, 'Modified'),
+  (4174444980, 'Opened'),
+  (2091632017, 'OpenFile'),
+  (3477267319, 'SetFileSize'),
+  (4268959521, 'UpdateSize'),
+  (1168008582, 'EnqueueLaunchParams'),
+  (2253088464, 'SetLaunchFiles'),
+  (2774731974, 'Abort'),
+  (44738278, 'Receive'),
+  (3474666471, 'GetSensor'),
+  (3264651654, 'Connect'),
+  (1572220289, 'Connect'),
+  (3647675238, 'ForgetDevice'),
+  (1696098914, 'GetDevice'),
+  (3299144182, 'GetDevices'),
+  (3071194690, 'GetPermission'),
+  (2991924418, 'SetClient'),
+  (1066626682, 'CancelSuccessfulPresentationTimeRequest'),
+  (2100861819, 'VisualStateRequest'),
+  (3071017789, 'ForceRedraw'),
+  (4145032502, 'GetWidgetInputHandler'),
+  (1947789679, 'ClearKeyboardTriggeredTooltip'),
+  (3261706746, 'CreateFrameSink'),
+  (3974701891, 'RegisterRenderFrameMetadataObserver'),
+  (2031882786, 'SelectionBoundsChanged'),
+  (3997379630, 'SetCursor'),
+  (1656336707, 'TextInputStateChanged'),
+  (1659532370, 'UpdateTooltipFromKeyboard'),
+  (561237502, 'UpdateTooltipUnderCursor'),
+  (3004620900, 'AttachSynchronousCompositor'),
+  (1967831211, 'CursorVisibilityChanged'),
+  (3392143105, 'DispatchEvent'),
+  (1243813610, 'DispatchNonBlockingEvent'),
+  (26334691, 'GetFrameWidgetInputHandler'),
+  (2072395166, 'DidOverscroll'),
+  (3510320680, 'DidStartScrollingViewport'),
+  (144065915, 'ImeCancelComposition'),
+  (2038153618, 'ImeCompositionRangeChanged'),
+  (3570301518, 'RequestMouseLock'),
+  (863314648, 'SetMouseCapture'),
+  (3614483554, 'SetPanAction'),
+  (3194432587, 'SetTouchActionFromMain'),
+  (2812731741, 'ImeCommitText'),
+  (2083286522, 'ImeFinishComposingText'),
+  (574795215, 'ImeSetComposition'),
+  (4224435266, 'MouseCaptureLost'),
+  (3276815969, 'RequestCompositionUpdates'),
+  (2245426734, 'RequestTextInputStateUpdate'),
+  (4122999759, 'SetEditCommandsForNextKeyEvent'),
+  (2021270504, 'SetFocus'),
+  (717422451, 'UpdateBrowserControlsState'),
+  (2143954133, 'WaitForInputProcessed'),
+  (1900553858, 'RequestSuccessfulPresentationTimeForNextFrame'),
+  (3534864496, 'UpdateScreenRects'),
+  (1337806005, 'UpdateVisualProperties'),
+  (3860104672, 'WasHidden'),
+  (345544528, 'WasShown'),
+  (2330302519, 'AllowCacheStorage'),
+  (3970323247, 'AllowIndexedDB'),
+  (36423147, 'AllowWebLocks'),
+  (3596196853, 'RequestFileSystemAccessSync'),
+  (2385265063, 'OnReadyForInspection'),
+  (3011890969, 'DeleteAllCookies'),
+  (39086581, 'GetAllCookies'),
+  (1029754173, 'GetNamedCookie'),
+  (3660205316, 'ConfirmIdpLogin'),
+  (1948050136, 'DismissFedCmDialog'),
+  (805736236, 'GetDialogType'),
+  (1731985001, 'GetFedCmDialogTitle'),
+  (641052068, 'SelectFedCmAccount'),
+  (3640931389, 'SetPermission'),
+  (3879830353, 'SetStorageAccess'),
+  (2268684725, 'AddRegistration'),
+  (2210034840, 'ClearRegistrations'),
+  (1943638370, 'GetLargeBlob'),
+  (2052768131, 'GetRegistrations'),
+  (2814683867, 'GetUniqueId'),
+  (243883457, 'ClearAuthenticators'),
+  (3015269554, 'CreateAuthenticator'),
+  (466143869, 'GetAuthenticators'),
+  (2075340135, 'RemoveAuthenticator'),
+  (2202207003, 'RemoveRegistration'),
+  (13468183, 'SetLargeBlob'),
+  (3980555316, 'SetUserVerified'),
+  (3696127651, 'AddObserver'),
+  (306311098, 'ConnectToDevice'),
+  (3562233939, 'ConnectToServiceInsecurely'),
+  (1680217417, 'CreateRfcommServiceInsecurely'),
+  (3615137913, 'GetDevices'),
+  (2201263443, 'GetInfo'),
+  (3298763675, 'DeviceAdded'),
+  (1876999384, 'DeviceChanged'),
+  (1027506730, 'DeviceRemoved'),
+  (3830892397, 'DiscoverableChanged'),
+  (61224607, 'DiscoveringChanged'),
+  (1691324308, 'PoweredChanged'),
+  (1151469774, 'PresentChanged'),
+  (2907115915, 'RegisterAdvertisement'),
+  (3806185335, 'SetDiscoverable'),
+  (3359004733, 'SetName'),
+  (1850530477, 'StartDiscoverySession'),
+  (549398888, 'Unregister'),
+  (2717117910, 'Disconnect'),
+  (2632654565, 'GetCharacteristics'),
+  (656515940, 'GetDescriptors'),
+  (2135795645, 'GetInfo'),
+  (2733581301, 'GetServices'),
+  (2495068666, 'ReadValueForCharacteristic'),
+  (3192495363, 'ReadValueForDescriptor'),
+  (2920727828, 'WriteValueForCharacteristic'),
+  (1577496703, 'WriteValueForDescriptor'),
+  (4181075452, 'IsActive'),
+  (3496875565, 'Stop'),
+  (664524157, 'Accept'),
+  (3957505903, 'Disconnect'),
+  (2565151847, 'Disconnect'),
+  (4200548098, 'CanExecuteCommand'),
+  (699682519, 'ExecuteCommand'),
+  (2693802977, 'CreateBrowserCommandHandler'),
+  (3020663646, 'ClassifyHosts'),
+  (1719254526, 'GetBrowsingTopicsConfiguration'),
+  (1477428597, 'GetBrowsingTopicsState'),
+  (2989102472, 'GetModelInfo'),
+  (623545927, 'OnAddToCart'),
+  (3681310940, 'OnCartExtraction'),
+  (3125344055, 'OnCartProductUpdated'),
+  (3596291909, 'OnFormSubmit'),
+  (2637553920, 'OnNavigation'),
+  (310066140, 'OnPurchase'),
+  (74897635, 'OnVisitCart'),
+  (3501676606, 'OnVisitCheckout'),
+  (2614784724, 'OnWillSendRequest'),
+  (4263706938, 'OnFrameSubmissionForTesting'),
+  (330497194, 'OnRenderFrameMetadataChanged'),
+  (1674000535, 'OnRootScrollOffsetChanged'),
+  (2041784233, 'ReportAllFrameSubmissionsForTesting'),
+  (1114151312, 'UpdateRootScrollOffsetUpdateFrequency'),
+  (1586811590, 'Complete'),
+  (4158821004, 'OnCertVerifierChanged'),
+  (1268740058, 'EnableNetworkAccess'),
+  (763350490, 'GetChromeRootStoreInfo'),
+  (1430862953, 'GetNewCertVerifier'),
+  (215141431, 'SetUseChromeRootStore'),
+  (2349700793, 'UpdateChromeRootStore'),
+  (2234398638, 'UpdateCRLSet'),
+  (1357369109, 'SetConfig'),
+  (2241335299, 'Verify'),
+  (2152332429, 'CreateURLLoaderFactory'),
+  (1618108660, 'GetCartFeatureEnabled'),
+  (852387410, 'GetDiscountConsentCardVisible'),
+  (3187360719, 'GetDiscountEnabled'),
+  (1868058595, 'GetDiscountToggleVisible'),
+  (3428697347, 'GetDiscountURL'),
+  (3367681255, 'GetMerchantCarts'),
+  (206223077, 'GetWarmWelcomeVisible'),
+  (2017203634, 'HideCart'),
+  (4116109535, 'HideCartModule'),
+  (1618688174, 'OnDiscountConsentAcknowledged'),
+  (1035249304, 'OnDiscountConsentContinued'),
+  (1749411320, 'OnDiscountConsentDismissed'),
+  (461032250, 'PrepareForNavigation'),
+  (274510379, 'RemoveCart'),
+  (3886086246, 'RestoreHiddenCart'),
+  (2293017033, 'RestoreHiddenCartModule'),
+  (2854461565, 'RestoreRemovedCart'),
+  (3944170933, 'SetDiscountEnabled'),
+  (2016265841, 'ShowNativeConsentDialog'),
+  (545120542, 'LaunchDownloadsPage'),
+  (3144155539, 'LaunchItem'),
+  (530676351, 'List'),
+  (1375075076, 'ListVisibilityChanged'),
+  (4260817035, 'OnRequestBlockedOnCookie'),
+  (1884977486, 'ExecuteWebUIJavaScript'),
+  (4151613932, 'GetMediaFeedURL'),
+  (3723198297, 'LoadBlockedPlugins'),
+  (336418005, 'RequestImageForContextNode'),
+  (1398161367, 'RequestReloadImageForContextNode'),
+  (1618188791, 'SetCCTClientHeader'),
+  (2009562238, 'SetWindowFeatures'),
+  (2042344497, 'BindSafeDocumentAnalyzer'),
+  (3990901566, 'UpdateDraggableRegions'),
+  (3679883431, 'BindSafeArchiveAnalyzer'),
+  (3172479172, 'BindSingleFileTarFileExtractor'),
+  (197465858, 'BindSingleFileTarXzFileExtractor'),
+  (441070976, 'SetConsentResult'),
+  (3814250275, 'Read'),
+  (3053438790, 'CheckMediaFile'),
+  (2055561787, 'ExtractVideoFrame'),
+  (4272726666, 'CreateMediaParser'),
+  (2604865276, 'GetCpuInfo'),
+  (2954792392, 'ParseMediaMetadata'),
+  (4291148555, 'IsMetricsAndCrashReportingEnabled'),
+  (3074467275, 'ClearCache'),
+  (2471697699, 'ClearHostResolverCache'),
+  (3076777468, 'ClearPredictorCache'),
+  (2946982208, 'CloseCurrentConnections'),
+  (1578086606, 'DownloadPageLater'),
+  (1922133340, 'SetIsShowingDownloadButtonInErrorPage'),
+  (1355258984, 'DNSProbeStatus'),
+  (3759856278, 'SetCanShowNetworkDiagnosticsDialog'),
+  (2719821937, 'RunNetworkDiagnostics'),
+  (1044927529, 'GetHighScore'),
+  (16722078, 'ResetHighScore'),
+  (1647031923, 'UpdateHighScore'),
+  (3998179440, 'CancelSchedule'),
+  (463663370, 'TrySchedule'),
+  (3500997903, 'PageHasOpenSearchDescriptionDocument'),
+  (92443502, 'BlockedUnauthorizedPlugin'),
+  (3564894020, 'CouldNotLoadPlugin'),
+  (2316687860, 'OpenPDF'),
+  (291138800, 'GetPluginInfo'),
+  (1145758560, 'CancelImport'),
+  (2605778447, 'OnAutofillFormDataImportGroup'),
+  (1370586091, 'OnAutofillFormDataImportStart'),
+  (1381747765, 'OnBookmarksImportGroup'),
+  (3493912625, 'OnBookmarksImportStart'),
+  (2659825258, 'OnFaviconsImportGroup'),
+  (2739380618, 'OnFaviconsImportStart'),
+  (1265596970, 'OnHistoryImportGroup'),
+  (1127849048, 'OnHistoryImportStart'),
+  (1031932495, 'OnHomePageImportReady'),
+  (2233156343, 'OnImportFinished'),
+  (2082058006, 'OnImportItemFinished'),
+  (495541424, 'OnImportItemStart'),
+  (3121239373, 'OnImportStart'),
+  (3852779880, 'OnKeywordsImportReady'),
+  (1365296214, 'OnPasswordFormImportReady'),
+  (2883571138, 'ReportImportItemFinished'),
+  (2117005612, 'StartImport'),
+  (907204574, 'Complete'),
+  (4243959911, 'Progress'),
+  (3899173013, 'Verify'),
+  (2685350375, 'Write'),
+  (4139654510, 'SetConfiguration'),
+  (935783404, 'SetInitialConfiguration'),
+  (2451641637, 'AnalyzeDmgFile'),
+  (2300893401, 'AnalyzeRarFile'),
+  (1204598225, 'AnalyzeSevenZipFile'),
+  (4006532212, 'AnalyzeZipFile'),
+  (1789703273, 'AnalyzeDocument'),
+  (2591663768, 'AddSandboxStatusExtension'),
+  (363631391, 'Extract'),
+  (620717997, 'OnProgress'),
+  (1628102677, 'RequestTemporaryFile'),
+  (4194669742, 'AddTrustedRecoveryMethod'),
+  (2629009301, 'SetEncryptionKeys'),
+  (1259723297, 'Start'),
+  (3336841814, 'Stop'),
+  (1426628094, 'OnAddMessages'),
+  (2254751396, 'OnStopped'),
+  (3125677706, 'SetPage'),
+  (2090682118, 'OnColorProviderChanged'),
+  (3931120147, 'CreateCommerceInternalsHandler'),
+  (4003470166, 'GetIsShoppingListEligible'),
+  (1599866331, 'GetShoppingListEligibleDetails'),
+  (2548835176, 'ResetPriceTrackingEmailPref'),
+  (697768916, 'OnShoppingListEligibilityChanged'),
+  (869238063, 'GetModelWithMetadata'),
+  (3829205714, 'StartVisualClassification'),
+  (324516861, 'HandleClassification'),
+  (109467462, 'Compose'),
+  (2138905782, 'CreateComposeDialogPageHandler'),
+  (1604581172, 'DeleteDeviceTrustKey'),
+  (2953928564, 'GetDeviceTrustState'),
+  (1944585054, 'DidCaptureContent'),
+  (3848103955, 'DidRemoveContent'),
+  (1162218896, 'DidUpdateContent'),
+  (213316439, 'StartCapture'),
+  (1269272182, 'StopCapture'),
+  (1800131012, 'BindAssociatedInterfaces'),
+  (3024260328, 'CreateFrame'),
+  (1445777638, 'CreateSharedStorageWorkletService'),
+  (2395027597, 'CreateView'),
+  (1591457016, 'DidUnloadRenderFrame'),
+  (3650055636, 'CreateFetcher'),
+  (3557682388, 'GetChildNonPersistentHistogramData'),
+  (749929237, 'Ping'),
+  (1868925865, 'BindReceiver'),
+  (2366374525, 'BindServiceInterface'),
+  (2217312508, 'CrashHungProcess'),
+  (4260818236, 'EnableSystemTracingService'),
+  (2148062898, 'GetBackgroundTracingAgentProvider'),
+  (3455726814, 'BindHostReceiver'),
+  (38682745, 'Ping'),
+  (2057503294, 'OnMemoryPressure'),
+  (610831209, 'ProcessShutdown'),
+  (4064069290, 'RunServiceDeprecated'),
+  (2957456809, 'SetIPCLoggingEnabled'),
+  (4228370015, 'SetPseudonymizationSalt'),
+  (3214620380, 'DomOperationResponse'),
+  (1232936871, 'FieldTrialActivated'),
+  (2675102258, 'AllowBindings'),
+  (29781743, 'BindWebUI'),
+  (833262988, 'EnableMojoJsBindings'),
+  (3595148643, 'EnableMojoJsBindingsWithBroker'),
+  (1066724405, 'CommitSameDocumentNavigation'),
+  (964865743, 'Delete'),
+  (1021273536, 'GetInterfaceProvider'),
+  (3050707559, 'GetSerializedHtmlWithLocalLinks'),
+  (2168461044, 'BeginNavigation'),
+  (2541191182, 'CancelInitialHistoryLoad'),
+  (2324894379, 'CreateChildFrame'),
+  (4230710627, 'CreateNewWindow'),
+  (1839937984, 'DidChangeName'),
+  (3561497419, 'DidCommitProvisionalLoad'),
+  (1421450774, 'DidCommitSameDocumentNavigation'),
+  (237773912, 'DidOpenDocumentInputStream'),
+  (368650583, 'DidStopLoading'),
+  (3961459168, 'OpenURL'),
+  (3826696652, 'ResourceLoadComplete'),
+  (171518470, 'SubresourceResponseStarted'),
+  (4063347880, 'UpdateEncoding'),
+  (1222769559, 'UpdateState'),
+  (3251878308, 'UpdateUserGestureCarryoverInfo'),
+  (1446037504, 'DidReceiveData'),
+  (1340551184, 'Done'),
+  (2951578828, 'SetResourceCache'),
+  (2459512505, 'SetWantErrorMessageStackTrace'),
+  (1396534067, 'SnapshotAccessibilityTree'),
+  (3145516344, 'UndoCommitNavigation'),
+  (3824597090, 'Unload'),
+  (11031178, 'UpdateSubresourceLoaderFactories'),
+  (995030857, 'QueueSyntheticPinch'),
+  (1503910747, 'QueueSyntheticPointerAction'),
+  (3488394949, 'QueueSyntheticSmoothDrag'),
+  (3325623609, 'QueueSyntheticSmoothScroll'),
+  (3270838334, 'QueueSyntheticTap'),
+  (770685969, 'Log'),
+  (1283418924, 'SerializeAsMHTML'),
+  (4248032555, 'CommitFailedNavigation'),
+  (479951742, 'CommitNavigation'),
+  (281273569, 'RendererCancellationWindowEnded'),
+  (1022424039, 'BindHungDetectorHost'),
+  (4094004645, 'DidCreateInProcessInstance'),
+  (4076804396, 'DidCreateOutOfProcessPepperInstance'),
+  (750946714, 'DidDeleteInProcessInstance'),
+  (3755121482, 'DidDeleteOutOfProcessPepperInstance'),
+  (1505138876, 'GetPluginInfo'),
+  (931728988, 'InstanceCreated'),
+  (865493725, 'OpenChannelToPepperPlugin'),
+  (3848387775, 'PluginHung'),
+  (1030045633, 'InstanceCrashed'),
+  (3389422967, 'StartsPlayback'),
+  (2029097079, 'StopsPlayback'),
+  (3623910651, 'SetVolume'),
+  (2862178891, 'CreateAgentSchedulingGroup'),
+  (4160781454, 'CreateAssociatedAgentSchedulingGroup'),
+  (4163569192, 'GetBrowserHistogram'),
+  (1738910966, 'RecordUserMetricsAction'),
+  (4020738024, 'SetPrivateMemoryFootprint'),
+  (724468159, 'SuddenTerminationChanged'),
+  (4145300713, 'InitializeRenderer'),
+  (2626704207, 'OnNetworkConnectionChanged'),
+  (3883196013, 'OnNetworkQualityChanged'),
+  (2045907380, 'OnSystemColorsChanged'),
+  (551632307, 'PurgePluginListCache'),
+  (4111473604, 'PurgeResourceCache'),
+  (1348577397, 'SetAttributionReportingSupport'),
+  (2897230957, 'SetIsCrossOriginIsolated'),
+  (36268348, 'SetIsIsolatedContext'),
+  (1173734277, 'SetIsLockedToSite'),
+  (2129435451, 'SetIsWebSecurityDisabled'),
+  (1780788289, 'SetProcessState'),
+  (3985399801, 'SetWebKitSharedTimersSuspended'),
+  (1584504577, 'UpdateScrollbarTheme'),
+  (154366262, 'UpdateSystemColorInfo'),
+  (1192743551, 'SetFieldTrialGroup'),
+  (3311293094, 'SetVariationsHeaders'),
+  (456797143, 'GenerateFrameRoutingID'),
+  (3194717971, 'GenerateRoutingID'),
+  (1233167068, 'HasGpuProcess'),
+  (2708420869, 'GetUsageData'),
+  (1292736357, 'GetRoute'),
+  (3305746320, 'SetThreadType'),
+  (2717060071, 'Send'),
+  (267625557, 'SetProperty'),
+  (7386572, 'SendRendererContentSettingRules'),
+  (948672453, 'SetAllowRunningInsecureContent'),
+  (2048689944, 'SetDisabledMixedContentUpgrades'),
+  (4198238010, 'AllowStorageAccess'),
+  (516019696, 'Clone'),
+  (901723924, 'OnContentBlocked'),
+  (259560719, 'ExtractCurrentSearchResults'),
+  (1930806540, 'SetColorSchemeMode'),
+  (2771695149, 'CreateCustomizeColorSchemeModeHandler'),
+  (2170946036, 'InitializeColorSchemeMode'),
+  (1494207252, 'SetColorSchemeMode'),
+  (3705179111, 'SetTheme'),
+  (2183909049, 'ApplyAutogeneratedTheme'),
+  (1828253429, 'ApplyChromeTheme'),
+  (3021706506, 'ApplyDefaultTheme'),
+  (1778948159, 'ConfirmThemeChanges'),
+  (1629389841, 'CreateCustomizeThemesHandler'),
+  (421061399, 'GetChromeThemes'),
+  (1441434396, 'InitializeTheme'),
+  (2346949600, 'RevertThemeChanges'),
+  (1644985483, 'Parse'),
+  (3219642052, 'BindCborParser'),
+  (3514101731, 'BindGzipper'),
+  (116952783, 'BindImageDecoder'),
+  (2036514685, 'BindJsonParser'),
+  (1783075176, 'BindStructuredHeadersParser'),
+  (351941065, 'BindWebBundleParserFactory'),
+  (437510789, 'BindXmlParser'),
+  (2521159218, 'Compress'),
+  (2089798862, 'Deflate'),
+  (2349318536, 'Inflate'),
+  (3048224210, 'Uncompress'),
+  (1551142738, 'DecodeAnimation'),
+  (3761349538, 'DecodeImage'),
+  (1226249912, 'Parse'),
+  (4099995678, 'ParseItem'),
+  (218871102, 'ParseList'),
+  (66681333, 'Parse'),
+  (3655126896, 'QueryNextStatus'),
+  (2841949730, 'OnPostureChanged'),
+  (4009108873, 'AddListenerAndGetCurrentPosture'),
+  (2560952351, 'AddListenerAndGetCurrentViewportSegments'),
+  (1099561799, 'BindBatteryMonitor'),
+  (3075407629, 'BindDevicePostureProvider'),
+  (447428518, 'BindFingerprint'),
+  (1772530237, 'BindGeolocationConfig'),
+  (1138913142, 'BindGeolocationContext'),
+  (2295045455, 'BindGeolocationControl'),
+  (2353062512, 'BindGeolocationInternals'),
+  (1723552464, 'BindHidManager'),
+  (3573704442, 'BindInputDeviceManager'),
+  (4252971410, 'BindNFCProvider'),
+  (3372813913, 'BindPowerMonitor'),
+  (252701415, 'BindPressureManager'),
+  (392739481, 'BindPublicIpAddressGeolocationProvider'),
+  (3336098540, 'BindScreenOrientationListener'),
+  (3226714375, 'BindSensorProvider'),
+  (1363023761, 'BindSerialPortManager'),
+  (3068539119, 'BindTimeZoneMonitor'),
+  (3897530558, 'BindUsbDeviceManager'),
+  (4267752794, 'BindUsbDeviceManagerTest'),
+  (529182057, 'BindVibrationManager'),
+  (2920995311, 'BindWakeLockProvider'),
+  (2234288935, 'OnViewportSegmentsChanged'),
+  (359791932, 'AddFingerprintObserver'),
+  (4131582997, 'CancelCurrentEnrollSession'),
+  (744169966, 'DestroyAllRecords'),
+  (2424528319, 'EndCurrentAuthSession'),
+  (2451986783, 'GetRecordsForUser'),
+  (571881221, 'OnAuthScanDone'),
+  (407231767, 'OnEnrollScanDone'),
+  (2532473150, 'OnRestarted'),
+  (776397828, 'OnSessionFailed'),
+  (133446222, 'OnStatusChanged'),
+  (2607371529, 'RemoveRecord'),
+  (2321469495, 'RequestRecordLabel'),
+  (1190667780, 'RequestType'),
+  (3120703743, 'SetRecordLabel'),
+  (2543705443, 'StartAuthSession'),
+  (3102694574, 'StartEnrollSession'),
+  (641492788, 'PlayVibrationEffectOnce'),
+  (2253144197, 'ResetVibrationActuator'),
+  (980651430, 'GamepadStartPolling'),
+  (2088927805, 'GamepadStopPolling'),
+  (1342812900, 'SetObserver'),
+  (1854698556, 'GamepadChanged'),
+  (3632929595, 'GamepadConnected'),
+  (3556595425, 'GamepadDisconnected'),
+  (1801029936, 'IsHighAccuracyLocationBeingCaptured'),
+  (3616780394, 'BindGeolocation'),
+  (3556475679, 'ClearOverride'),
+  (3847887934, 'OnPermissionRevoked'),
+  (709827508, 'SetOverride'),
+  (3095262811, 'UserDidOptIntoLocationServices'),
+  (731323602, 'AddInternalsObserver'),
+  (3591352031, 'OnDiagnosticsChanged'),
+  (760473965, 'OnNetworkLocationReceived'),
+  (1777813570, 'OnNetworkLocationRequested'),
+  (938391927, 'QueryNextPosition'),
+  (2267047447, 'SetHighAccuracy'),
+  (604892254, 'OnInputReport'),
+  (3570293564, 'GetFeatureReport'),
+  (3916777298, 'Read'),
+  (1305949685, 'SendFeatureReport'),
+  (3243843986, 'Write'),
+  (614048806, 'AddReceiver'),
+  (3924674658, 'DeviceAdded'),
+  (2945965082, 'DeviceChanged'),
+  (3332088839, 'DeviceRemoved'),
+  (495916650, 'Connect'),
+  (1461917890, 'GetDevices'),
+  (729388026, 'GetDevicesAndSetClient'),
+  (2527180014, 'RequestNextOverlayPose'),
+  (1159871865, 'RequestNotificationOnWebXrSubmitted'),
+  (648449490, 'SetOverlayAndWebXRVisibility'),
+  (2652474384, 'SubmitOverlayTexture'),
+  (3310843241, 'InputDeviceAdded'),
+  (826807111, 'InputDeviceRemoved'),
+  (1619930814, 'GetDevices'),
+  (2605117925, 'GetDevicesAndSetClient'),
+  (931778104, 'OnDeviceAdded'),
+  (3159766452, 'OnDeviceRemoved'),
+  (805428607, 'OnDevicesEnumerated'),
+  (1332642608, 'RequestDevices'),
+  (3878048224, 'CancelMakeReadOnly'),
+  (142023615, 'CancelPush'),
+  (411778394, 'CancelWatch'),
+  (3455151912, 'OnError'),
+  (3183751638, 'OnWatch'),
+  (4228140092, 'MakeReadOnly'),
+  (4074618365, 'GetNFCForHost'),
+  (830000168, 'ResumeNFCOperations'),
+  (1742137057, 'SuspendNFCOperations'),
+  (2421772240, 'Push'),
+  (959009931, 'SetClient'),
+  (4146495355, 'Watch'),
+  (1428246654, 'AddClient'),
+  (1112072386, 'PowerStateChange'),
+  (86821538, 'Resume'),
+  (1805655255, 'Suspend'),
+  (2709720546, 'OnPressureUpdated'),
+  (725920781, 'AddClient'),
+  (1953274376, 'CreateGeolocation'),
+  (1261094670, 'IsAutoRotateEnabledByUser'),
+  (302510942, 'LockOrientation'),
+  (2385841336, 'UnlockOrientation'),
+  (315573001, 'AddConfiguration'),
+  (2656829796, 'RaiseError'),
+  (4257769474, 'SensorReadingChanged'),
+  (2354771619, 'ConfigureReadingChangeNotifications'),
+  (443244855, 'GetDefaultConfiguration'),
+  (586357532, 'GetSensor'),
+  (282934222, 'RemoveConfiguration'),
+  (570506941, 'Resume'),
+  (3902313697, 'Suspend'),
+  (930954762, 'OnReadError'),
+  (2434483464, 'OnSendError'),
+  (1586245494, 'Close'),
+  (691839582, 'ConfigurePort'),
+  (514040075, 'Drain'),
+  (4222372059, 'Flush'),
+  (65225007, 'GetControlSignals'),
+  (3120118557, 'GetPortInfo'),
+  (997682656, 'OnPortAdded'),
+  (1189966685, 'OnPortRemoved'),
+  (3681474306, 'GetDevices'),
+  (2938580348, 'OpenPort'),
+  (3754890435, 'SetClient'),
+  (1465146034, 'SetControlSignals'),
+  (35097741, 'StartReading'),
+  (1127906653, 'StartWriting'),
+  (2976674589, 'BeginTransaction'),
+  (719182294, 'Control'),
+  (151180532, 'Disconnect'),
+  (311974170, 'GetAttrib'),
+  (2669678412, 'SetAttrib'),
+  (1683676688, 'Status'),
+  (185582897, 'Transmit'),
+  (178411750, 'Cancel'),
+  (3119051335, 'Connect'),
+  (3510971747, 'CreateContext'),
+  (1471035691, 'GetStatusChange'),
+  (4266598856, 'ListReaders'),
+  (2804061711, 'EndTransaction'),
+  (1344416814, 'AddClient'),
+  (1069725941, 'OnTimeZoneChange'),
+  (2460675659, 'ClaimInterface'),
+  (1983927106, 'ClearHalt'),
+  (2418616563, 'OnDeviceClosed'),
+  (3895606962, 'OnDeviceOpened'),
+  (1739186981, 'Close'),
+  (2672813764, 'ControlTransferIn'),
+  (3616249362, 'ControlTransferOut'),
+  (4282733530, 'GenericTransferIn'),
+  (475136140, 'GenericTransferOut'),
+  (1734214769, 'IsochronousTransferIn'),
+  (3419736742, 'IsochronousTransferOut'),
+  (401400857, 'OnDeviceAdded'),
+  (2289904268, 'OnDeviceRemoved'),
+  (3789973177, 'EnumerateDevicesAndSetClient'),
+  (2725635365, 'GetDevice'),
+  (3620535997, 'GetDevices'),
+  (145469870, 'GetSecurityKeyDevice'),
+  (1225910844, 'RefreshDeviceInfo'),
+  (1687364557, 'SetClient'),
+  (1323142320, 'AddDeviceForTesting'),
+  (3294661434, 'GetTestDevices'),
+  (4171178999, 'RemoveDeviceForTesting'),
+  (912557170, 'Open'),
+  (3534429309, 'ReleaseInterface'),
+  (3853327763, 'Reset'),
+  (605470422, 'SetConfiguration'),
+  (1503826080, 'SetInterfaceAlternateSetting'),
+  (1416883652, 'Cancel'),
+  (2104345512, 'Vibrate'),
+  (485523681, 'OnDeviceChanged'),
+  (1500435910, 'ExitPresent'),
+  (2828418294, 'MakeXrCompatible'),
+  (3676701444, 'RequestSession'),
+  (2694056759, 'SetClient'),
+  (2329361771, 'SetFramesThrottled'),
+  (485791784, 'SupportsSession'),
+  (2633758669, 'AddClient'),
+  (4074679465, 'CancelWakeLock'),
+  (1989247908, 'ChangeType'),
+  (2874593729, 'GetWakeLock'),
+  (28517028, 'HasWakeLockForTests'),
+  (396924288, 'OnWakeLockDeactivated'),
+  (3758454743, 'GetActiveWakeLocksForTests'),
+  (3650512528, 'GetWakeLockContextForID'),
+  (1983646260, 'GetWakeLockWithoutContext'),
+  (2867620013, 'NotifyOnWakeLockDeactivation'),
+  (1989854977, 'RequestWakeLock'),
+  (600224384, 'CreateImmersiveOverlay'),
+  (1247369541, 'BindRuntimeProvider'),
+  (765853139, 'BindTestHook'),
+  (1487326756, 'BindGpu'),
+  (2682044441, 'CreateAnchor'),
+  (631445810, 'CreatePlaneAnchor'),
+  (1923243215, 'DetachAnchor'),
+  (1233050972, 'SubscribeToHitTest'),
+  (49143999, 'SubscribeToHitTestForTransientInput'),
+  (1486129100, 'UnsubscribeFromHitTest'),
+  (3523673031, 'GetEnvironmentIntegrationProvider'),
+  (932697300, 'GetFrameData'),
+  (420760444, 'OnSubmitFrameGpuFence'),
+  (330038611, 'OnSubmitFrameRendered'),
+  (1477205040, 'OnSubmitFrameTransferred'),
+  (1504224274, 'SubmitFrame'),
+  (1832502649, 'SubmitFrameDrawnIntoTexture'),
+  (2510679337, 'SubmitFrameMissing'),
+  (2545115414, 'UpdateLayerBounds'),
+  (369485515, 'OnExitPresent'),
+  (2386004008, 'OnVisibilityStateChanged'),
+  (300589321, 'ListenToDeviceChanges'),
+  (2317961020, 'RequestSession'),
+  (3564122865, 'ShutdownSession'),
+  (194200805, 'OnExitPresent'),
+  (2221038980, 'OnVisibilityStateChanged'),
+  (2967272873, 'SetFrameDataRestricted'),
+  (3943529457, 'ReportFeatureUsed'),
+  (2199703930, 'GetFileSystemSignals'),
+  (1665725794, 'SetTestHook'),
+  (12255592, 'TerminateDeviceServiceProcessForTesting'),
+  (3256127185, 'OnFrameSubmitted'),
+  (2388594455, 'WaitGetCanCreateSession'),
+  (2859675996, 'WaitGetControllerData'),
+  (1870559690, 'WaitGetControllerRoleForTrackedDeviceIndex'),
+  (1992315058, 'WaitGetDeviceConfig'),
+  (2505182268, 'WaitGetEventData'),
+  (3354588923, 'WaitGetMagicWindowPose'),
+  (1379863252, 'WaitGetPresentingPose'),
+  (3977214267, 'WaitGetTrackedDeviceClass'),
+  (1061321392, 'AllocateLockedDiscardableSharedMemory'),
+  (1324000231, 'DeletedDiscardableSharedMemory'),
+  (2430011185, 'Discard'),
+  (3302910068, 'DiscardById'),
+  (2790742027, 'GetTabDiscardsInfo'),
+  (4111565375, 'LoadById'),
+  (368731846, 'SetAutoDiscardable'),
+  (2592784341, 'ToggleBatterySaverMode'),
+  (2480720151, 'FavIconDataAvailable'),
+  (505243338, 'FrameChanged'),
+  (3577761826, 'FrameCreated'),
+  (3033628638, 'NodeDeleted'),
+  (770149276, 'PageChanged'),
+  (107013136, 'PageCreated'),
+  (1282931926, 'ProcessChanged'),
+  (3958386104, 'ProcessCreated'),
+  (968950034, 'WorkerChanged'),
+  (250113796, 'WorkerCreated'),
+  (2038170263, 'RequestNodeDescriptions'),
+  (1166592162, 'SubscribeToChanges'),
+  (3093970831, 'GetSiteDataArray'),
+  (4176714600, 'GetSiteDataDatabaseSize'),
+  (3094238197, 'NotifyIsDistillable'),
+  (3381897377, 'HandleDistillerOpenSettingsCall'),
+  (1842565763, 'HandleStoreFontFamilyPref'),
+  (3486215259, 'HandleStoreFontScalingPref'),
+  (2585651518, 'HandleStoreThemePref'),
+  (600615489, 'OnStreamCompleted'),
+  (3750401207, 'ClearAll'),
+  (2844718556, 'BypassDeepScanRequiringGesture'),
+  (436018308, 'Cancel'),
+  (2837389968, 'ClearAll'),
+  (3710162856, 'DeepScan'),
+  (1342498329, 'DiscardDangerous'),
+  (3408712846, 'Drag'),
+  (3320009552, 'CreatePageHandler'),
+  (3147240924, 'GetDownloads'),
+  (4206877282, 'OpenDownloadsFolderRequiringGesture'),
+  (4085588869, 'OpenDuringScanningRequiringGesture'),
+  (2196313146, 'OpenFileRequiringGesture'),
+  (1705412396, 'Pause'),
+  (2454363052, 'Remove'),
+  (3197326857, 'Resume'),
+  (1480572509, 'RetryDownload'),
+  (1480058184, 'ReviewDangerousRequiringGesture'),
+  (2331390013, 'SaveDangerousRequiringGesture'),
+  (1454376667, 'Show'),
+  (1874079038, 'Undo'),
+  (3955664538, 'InsertItems'),
+  (3467705843, 'RemoveItem'),
+  (3274871134, 'UpdateItem'),
+  (3756799782, 'DismissModule'),
+  (1125052081, 'GetFiles'),
+  (2510871706, 'RestoreModule'),
+  (3045273418, 'SetShowBeforeUnloadDialog'),
+  (4042289901, 'GetStreamInfo'),
+  (3738399688, 'SetPdfPluginAttributes'),
+  (1994542102, 'SetVisuallyDeemphasized'),
+  (408414188, 'DispatchEvent'),
+  (2413957877, 'AddFilteredListenerForMainThread'),
+  (2792606600, 'AddFilteredListenerForServiceWorker'),
+  (2040500791, 'AddLazyListenerForMainThread'),
+  (3909589491, 'AddLazyListenerForServiceWorker'),
+  (962350887, 'AddListenerForMainThread'),
+  (3695771120, 'AddListenerForServiceWorker'),
+  (1130483708, 'RemoveFilteredListenerForMainThread'),
+  (1374855521, 'RemoveFilteredListenerForServiceWorker'),
+  (3802055526, 'RemoveLazyListenerForMainThread'),
+  (816442196, 'RemoveLazyListenerForServiceWorker'),
+  (191067119, 'RemoveListenerForMainThread'),
+  (1991229207, 'RemoveListenerForServiceWorker'),
+  (2499343587, 'CanExecuteContentScript'),
+  (2351688121, 'ReadyToCreateMimeHandlerView'),
+  (473502255, 'AppWindowClosed'),
+  (3118400856, 'ExecuteCode'),
+  (4022461315, 'ExecuteDeclarativeScript'),
+  (2548788961, 'DetailedConsoleMessageAdded'),
+  (1605255791, 'GetAppInstallState'),
+  (295817213, 'Request'),
+  (747850497, 'RequestScriptInjectionPermission'),
+  (1771584634, 'ResponseAck'),
+  (625017081, 'WatchedPageChange'),
+  (3987002718, 'MessageInvoke'),
+  (148732931, 'NotifyRenderViewType'),
+  (835207248, 'SetFrameName'),
+  (2009809424, 'SetSpatialNavigationEnabled'),
+  (2733193119, 'SetTabId'),
+  (2784421122, 'UpdateBrowserWindowId'),
+  (2866756967, 'CreateBeforeUnloadControl'),
+  (2317310547, 'DestroyFrameContainer'),
+  (1305049987, 'DidLoad'),
+  (1210362517, 'SetInternalId'),
+  (3496579554, 'ActivateExtension'),
+  (2342205158, 'BindAutomation'),
+  (4198518229, 'CancelSuspendExtension'),
+  (2799885401, 'ClearTabSpecificPermissions'),
+  (1221240915, 'AddAPIActionToActivityLog'),
+  (689112112, 'AddDOMActionToActivityLog'),
+  (2618948969, 'AddEventToActivityLog'),
+  (1598388920, 'LoadExtensions'),
+  (1845802813, 'SetActivityLoggingEnabled'),
+  (1033568805, 'SetDeveloperMode'),
+  (857522690, 'SetScriptingAllowlist'),
+  (736505961, 'SetSessionInfo'),
+  (1054945688, 'SetSystemFont'),
+  (4196620597, 'SetWebViewPartitionID'),
+  (1080728518, 'ShouldSuspend'),
+  (1972146295, 'SuspendExtension'),
+  (245511152, 'TransferBlobs'),
+  (154547172, 'UnloadExtension'),
+  (3248732535, 'UpdateDefaultPolicyHostRestrictions'),
+  (3056808755, 'UpdatePermissions'),
+  (433460920, 'UpdateTabSpecificPermissions'),
+  (1392530241, 'UpdateUserHostRestrictions'),
+  (2739061531, 'UpdateUserScripts'),
+  (2990968432, 'UpdateUserScriptWorld'),
+  (2571609726, 'WatchPages'),
+  (3250267877, 'DidInitializeServiceWorkerContext'),
+  (1768400391, 'DidStartServiceWorkerContext'),
+  (2731667968, 'DidStopServiceWorkerContext'),
+  (225666397, 'RequestWorker'),
+  (1612971226, 'WorkerResponseAck'),
+  (2439311859, 'GetFeedHistograms'),
+  (3213383178, 'GetFeedProcessScopeDump'),
+  (3776503310, 'GetGeneralProperties'),
+  (4045054245, 'GetLastFetchProperties'),
+  (1548721884, 'OverrideDiscoverApiEndpoint'),
+  (967082479, 'OverrideFeedHost'),
+  (65934220, 'OverrideFeedStreamData'),
+  (3246848548, 'RefreshFollowingFeed'),
+  (627018916, 'RefreshForYouFeed'),
+  (3898087331, 'RefreshWebFeedSuggestions'),
+  (1786434176, 'SetFollowingFeedOrder'),
+  (1071388388, 'SetUseFeedQueryRequests'),
+  (2331857666, 'SetWebFeedFollowIntroDebugEnabled'),
+  (174256033, 'DoSomething'),
+  (2775366517, 'CreateFeedSidePanelHandler'),
+  (3010389019, 'OnEventOccurred'),
+  (1553485392, 'GetRssLinks'),
+  (4059924950, 'Clone'),
+  (1288378092, 'Delete'),
+  (738615691, 'Exists'),
+  (2400577248, 'Flush'),
+  (252619776, 'IsWritable'),
+  (744976458, 'OpenDirectory'),
+  (1187105197, 'OpenFileHandle'),
+  (2943525555, 'OpenFileHandles'),
+  (1725193664, 'Read'),
+  (3781515427, 'ReadEntireFile'),
+  (3304141131, 'Rename'),
+  (1856201265, 'Replace'),
+  (4207949954, 'StatFile'),
+  (265904693, 'WriteFile'),
+  (3121004742, 'FallbackFontForCharacter'),
+  (890833383, 'FontRenderStyleForStrike'),
+  (2708291200, 'MatchFamilyName'),
+  (1428546636, 'MatchFontByPostscriptNameOrFullFontName'),
+  (1980297402, 'MatchFontWithFallback'),
+  (1370794319, 'OpenStream'),
+  (862807200, 'GetData'),
+  (3940508946, 'ResetPrediction'),
+  (1937254861, 'StoreDelegatedInkPoint'),
+  (802347656, 'OnDevicesUpdated'),
+  (2558526748, 'SelectDevice'),
+  (3534673829, 'OnMediaUIClosed'),
+  (646269849, 'OnMediaUIOpened'),
+  (2132934937, 'OnMediaUIUpdated'),
+  (2715852390, 'OnPickerDismissed'),
+  (1563216298, 'AddObserver'),
+  (1891494379, 'CreateItem'),
+  (3562554298, 'DeleteItem'),
+  (1079139078, 'HideItem'),
+  (1133451438, 'HideMediaUI'),
+  (3069298207, 'OnArtworkImageChanged'),
+  (3850102959, 'OnFaviconImageChanged'),
+  (2099921224, 'OnMetadataChanged'),
+  (4127988527, 'ShowItem'),
+  (385010331, 'GetDeviceListHostForPresentation'),
+  (2272568128, 'GetDeviceListHostForSession'),
+  (3371878838, 'SetDevicePickerProvider'),
+  (3343213500, 'CopyGpuMemoryBuffer'),
+  (1909913537, 'CreateGpuMemoryBuffer'),
+  (2732482547, 'DestroyGpuMemoryBuffer'),
+  (1599461848, 'OnConsoleMessage'),
+  (1214367160, 'OnDestroyed'),
+  (1557888098, 'OnGpuSwitched'),
+  (285658306, 'OnReturnData'),
+  (1549261169, 'OnSignalAck'),
+  (3078295824, 'CreateGpuFenceFromHandle'),
+  (915837384, 'GetGpuFenceHandle'),
+  (1411889528, 'RegisterTransferBuffer'),
+  (3663796760, 'SetGetBuffer'),
+  (3374007320, 'SignalQuery'),
+  (496676249, 'SignalSyncToken'),
+  (776859791, 'CrashForTesting'),
+  (3793643893, 'CreateCommandBuffer'),
+  (2074917023, 'CreateGpuMemoryBuffer'),
+  (1638454825, 'CreateStreamTexture'),
+  (1470751736, 'DestroyCommandBuffer'),
+  (1232300672, 'Flush'),
+  (2382432867, 'FlushDeferredRequests'),
+  (1738877302, 'GetChannelToken'),
+  (1674249383, 'GetGpuMemoryBufferHandleInfo'),
+  (2934077149, 'ScheduleImageDecode'),
+  (2845246355, 'TerminateForTesting'),
+  (63357587, 'WaitForGetOffsetInRange'),
+  (56036244, 'WaitForTokenInRange'),
+  (1327539129, 'OnFrameAvailable'),
+  (3212179374, 'OnFrameWithInfoAvailable'),
+  (99027882, 'ForwardForSurfaceRequest'),
+  (2287277479, 'StartListening'),
+  (1083987858, 'UpdateRotatedVisibleSize'),
+  (143545376, 'AttachToEmbedderFrame'),
+  (1135586962, 'ViewCreated'),
+  (1530660785, 'ViewGarbageCollected'),
+  (2235316673, 'CreateHandwritingRecognizer'),
+  (336638801, 'QueryHandwritingRecognizer'),
+  (460428423, 'GetPrediction'),
+  (2285420817, 'AddHeapProfileToTrace'),
+  (634243561, 'RetrieveHeapProfile'),
+  (104831040, 'StartProfiling'),
+  (3486890969, 'AddProfilingClient'),
+  (347120755, 'GetProfiledPids'),
+  (3545945286, 'ExternalHelpBubbleUpdated'),
+  (2963975638, 'HideHelpBubble'),
+  (4041105594, 'ShowHelpBubble'),
+  (217453686, 'ToggleFocusForAccessibility'),
+  (1511972789, 'CreateHelpBubbleHandler'),
+  (1481342547, 'HelpBubbleAnchorActivated'),
+  (145124618, 'HelpBubbleAnchorCustomEvent'),
+  (245911679, 'HelpBubbleAnchorVisibilityChanged'),
+  (173353192, 'HelpBubbleButtonPressed'),
+  (1770673643, 'HelpBubbleClosed'),
+  (1977469167, 'CreatePageHandler'),
+  (3532816917, 'GetContextClustersJson'),
+  (337460372, 'PrintKeywordBagStateToLogMessages'),
+  (4178541307, 'OnLogMessageAdded'),
+  (2497669847, 'HideVisits'),
+  (3713293501, 'LoadMoreClusters'),
+  (1428226743, 'OpenHistoryCluster'),
+  (197689920, 'OpenVisitUrlsInTabGroup'),
+  (695001224, 'RecordClusterAction'),
+  (1925567435, 'RecordRelatedSearchAction'),
+  (622361747, 'RecordToggledVisibility'),
+  (209724965, 'RecordVisitAction'),
+  (1417577244, 'RemoveVisits'),
+  (2853898723, 'SetPage'),
+  (3350309949, 'ShowContextMenuForSearchbox'),
+  (1822764294, 'ShowContextMenuForURL'),
+  (3424503136, 'ShowSidePanelUI'),
+  (4160353853, 'StartQueryClusters'),
+  (4070408445, 'ToggleVisibility'),
+  (3696553083, 'OnClusterImageUpdated'),
+  (3356053668, 'OnClustersQueryResult'),
+  (1314677785, 'OnHistoryDeleted'),
+  (2319450223, 'OnQueryChangedByUser'),
+  (1880091352, 'OnVisitsHidden'),
+  (2288446205, 'OnVisitsRemoved'),
+  (4034121598, 'AnnotateImage'),
+  (3215404563, 'BindAnnotator'),
+  (1920435265, 'GetJpgImageData'),
+  (888598897, 'GetAssociatedInterface'),
+  (3591105100, 'Receive'),
+  (2618344252, 'SetPeerPid'),
+  (3661240620, 'OnPostMessage'),
+  (879072433, 'AddDocumentStartScript'),
+  (1277098034, 'RemoveDocumentStartScript'),
+  (4167072037, 'SetJsObjects'),
+  (3689306572, 'PostMessage'),
+  (910245701, 'SetBrowserToJsMessaging'),
+  (925746911, 'DetermineLanguage'),
+  (3080734051, 'GetMediaHistoryOriginRows'),
+  (233592862, 'GetMediaHistoryPlaybackRows'),
+  (3745783772, 'GetMediaHistoryPlaybackSessionRows'),
+  (1562021466, 'GetMediaHistoryStats'),
+  (1652997358, 'BeginObservation'),
+  (2182055135, 'CancelObservation'),
+  (3510675173, 'CompleteObservation'),
+  (2852432199, 'PredictDistribution'),
+  (1179835749, 'UpdateDefaultTarget'),
+  (1302073027, 'OnDestroyed'),
+  (3344052416, 'OnPowerEfficientState'),
+  (2044982096, 'OnSurfaceReady'),
+  (774949715, 'OnSynchronouslyDestroyed'),
+  (2392288623, 'CreateOverlay'),
+  (1749449909, 'ScheduleLayout'),
+  (1236322389, 'OnBufferDecoded'),
+  (801922913, 'OnWaiting'),
+  (308416720, 'Construct'),
+  (3873809553, 'Decode'),
+  (3360488017, 'Initialize'),
+  (3340123396, 'Reset'),
+  (2503587690, 'SetDataSource'),
+  (1830422711, 'OnEncodedBufferReady'),
+  (3427048405, 'Encode'),
+  (3338756082, 'Flush'),
+  (3587542380, 'Initialize'),
+  (668869111, 'OnError'),
+  (2705461071, 'OnMutedStateChanged'),
+  (3434392174, 'DidStartRecording'),
+  (23518161, 'Record'),
+  (1548933448, 'SetVolume'),
+  (2955032066, 'CreateAudioLog'),
+  (4066113149, 'OnClosed'),
+  (4125750970, 'OnCreated'),
+  (3336396858, 'OnError'),
+  (2284225729, 'OnLogMessage'),
+  (3681802569, 'OnProcessingStateChanged'),
+  (1654898889, 'OnSetVolume'),
+  (1303627419, 'OnStarted'),
+  (1331851838, 'OnStopped'),
+  (2176907348, 'Flush'),
+  (1847502073, 'DidChangeAudibleState'),
+  (2478879532, 'DidStartPlaying'),
+  (340998298, 'DidStopPlaying'),
+  (998987717, 'Pause'),
+  (938846683, 'Play'),
+  (2764318625, 'Acquire'),
+  (2423027165, 'Created'),
+  (4062036040, 'SetVolume'),
+  (1055483429, 'GetStats'),
+  (3686923580, 'SetPreferredNumCaptureChannels'),
+  (3705813965, 'Start'),
+  (2863455693, 'Stop'),
+  (1246421755, 'BindAudioSourceFetcher'),
+  (2002950911, 'AssociateInputAndOutputForAec'),
+  (957170192, 'BindMuter'),
+  (2436327863, 'CreateInputStream'),
+  (610976099, 'CreateLoopbackStream'),
+  (4111525908, 'CreateOutputStream'),
+  (3438622217, 'ChallengePlatform'),
+  (370936224, 'GetStorageId'),
+  (2721688709, 'CreateCdm'),
+  (4119374754, 'Read'),
+  (3121433321, 'Write'),
+  (2410290410, 'GetService'),
+  (3361977005, 'CreateCdmFactory'),
+  (1243506778, 'Open'),
+  (361844729, 'OnSessionClosed'),
+  (4276413440, 'OnSessionExpirationUpdate'),
+  (3817614555, 'OnSessionKeysChange'),
+  (2990026963, 'OnSessionMessage'),
+  (616210159, 'CloseSession'),
+  (2248987837, 'CreateSessionAndGenerateRequest'),
+  (1544782561, 'GetStatusForPolicy'),
+  (1126869200, 'LoadSession'),
+  (2506944705, 'RemoveSession'),
+  (1443602195, 'SetClient'),
+  (3940869788, 'SetServerCertificate'),
+  (3278490227, 'UpdateSession'),
+  (2826629764, 'CancelDecrypt'),
+  (1860194801, 'Decrypt'),
+  (319288141, 'DecryptAndDecodeAudio'),
+  (378922185, 'DecryptAndDecodeVideo'),
+  (3921514621, 'DeinitializeDecoder'),
+  (843049037, 'Initialize'),
+  (2220531158, 'InitializeAudioDecoder'),
+  (2126670146, 'InitializeVideoDecoder'),
+  (3244249871, 'ResetDecoder'),
+  (4028187046, 'EnableBitstreamConverter'),
+  (1328339636, 'Initialize'),
+  (1889824314, 'Read'),
+  (1995074790, 'OnRemotePlayStateChange'),
+  (1236699519, 'BindEmbedderReceiver'),
+  (3173767151, 'CreateCdmStorage'),
+  (3087935906, 'CreateProvisionFetcher'),
+  (1617871964, 'GetCdmOrigin'),
+  (7947917, 'GetPhotoState'),
+  (2502512110, 'SetPhotoOptions'),
+  (1620559098, 'TakePhoto'),
+  (41012726, 'CreateAudioDecoder'),
+  (3073501626, 'CreateAudioEncoder'),
+  (2953447619, 'CreateCdm'),
+  (1265365485, 'CreateDefaultRenderer'),
+  (2749144772, 'CreateFlingingRenderer'),
+  (2348943477, 'CreateMediaPlayerRenderer'),
+  (1103022925, 'CreateVideoDecoder'),
+  (3421751543, 'AddObserver'),
+  (3642067279, 'OnKeySystemSupportUpdated'),
+  (2902758954, 'Initialize'),
+  (2395613503, 'LoadPersistentSession'),
+  (1366309514, 'OnProvisioned'),
+  (2612827237, 'RemovePersistentSession'),
+  (3456368177, 'SavePersistentSession'),
+  (4198852638, 'GetMediaEngagementConfig'),
+  (1418382632, 'GetMediaEngagementScoreDetails'),
+  (3220051067, 'MediaFoundationRendererCreated'),
+  (18907213, 'AddLogRecord'),
+  (3821203330, 'AcquireLearningTaskController'),
+  (4059741957, 'AcquirePlaybackEventsRecorder'),
+  (1746853385, 'AcquireVideoDecodeStatsRecorder'),
+  (3775197799, 'AcquireWatchTimeRecorder'),
+  (1931616923, 'Initialize'),
+  (3728500910, 'OnError'),
+  (3757124879, 'OnFallback'),
+  (1708318282, 'SetAudioPipelineInfo'),
+  (1539073966, 'SetContainerName'),
+  (451680262, 'SetHasAudio'),
+  (2312389250, 'SetHasPlayed'),
+  (1794118553, 'SetHasVideo'),
+  (1967513281, 'SetHaveEnough'),
+  (153845470, 'SetIsEME'),
+  (838719633, 'SetIsHardwareSecure'),
+  (4030789783, 'SetKeySystem'),
+  (2795536959, 'SetRendererType'),
+  (88728170, 'SetTimeToFirstFrame'),
+  (763703158, 'SetTimeToMetadata'),
+  (18950887, 'SetTimeToPlayReady'),
+  (2910530295, 'SetVideoPipelineInfo'),
+  (655863005, 'OnMediaPlayerAdded'),
+  (613826211, 'GetHasPlayedBefore'),
+  (3212262087, 'OnAudioOutputSinkChanged'),
+  (1426313906, 'OnAudioOutputSinkChangingDisabled'),
+  (1015860044, 'OnMediaEffectivelyFullscreenChanged'),
+  (3891915806, 'OnMediaMetadataChanged'),
+  (2514300882, 'OnMediaPaused'),
+  (4104312479, 'OnMediaPlaying'),
+  (2796198850, 'OnMediaPositionStateChanged'),
+  (2709838661, 'OnMediaSizeChanged'),
+  (3072835551, 'OnMutedStatusChanged'),
+  (1734067640, 'OnPictureInPictureAvailabilityChanged'),
+  (408294722, 'OnRemotePlaybackMetadataChange'),
+  (4253316885, 'OnUseAudioServiceChanged'),
+  (2390706361, 'OnDurationChange'),
+  (4110657008, 'OnVideoSizeChange'),
+  (1624145427, 'InitiateScopedSurfaceRequest'),
+  (2668843207, 'RequestEnterPictureInPicture'),
+  (1702994486, 'RequestMediaRemoting'),
+  (2947474637, 'RequestMute'),
+  (4204744887, 'RequestPause'),
+  (1975289943, 'RequestPlay'),
+  (3656484875, 'RequestSeekBackward'),
+  (121475934, 'RequestSeekForward'),
+  (99133545, 'RequestSeekTo'),
+  (4267887368, 'SetAudioSinkId'),
+  (3202076778, 'SetPersistentState'),
+  (3185987706, 'SetPowerExperimentState'),
+  (1123494835, 'SetVolumeMultiplier'),
+  (2214130774, 'SuspendForFrameClosed'),
+  (2991131778, 'CreateInterfaceFactory'),
+  (599660242, 'EnableProtection'),
+  (4294715778, 'QueryStatus'),
+  (3406640036, 'OnBuffering'),
+  (2703097927, 'OnBufferingComplete'),
+  (3788334801, 'OnEnded'),
+  (1934235793, 'OnError'),
+  (4207096483, 'OnNaturalSizeChanged'),
+  (3302238494, 'OnPaused'),
+  (2021483220, 'OnPipelineStatistics'),
+  (1308623203, 'OnPlaying'),
+  (2299731827, 'OnSeeking'),
+  (213030468, 'Retrieve'),
+  (3593668013, 'OnFlushUntil'),
+  (1907966512, 'OnRemotingSinkReady'),
+  (286800438, 'OnVideoNaturalSizeChange'),
+  (3329533216, 'SendMessageToSource'),
+  (358584271, 'StartDataStreams'),
+  (3994633958, 'EstimateTransmissionCapacity'),
+  (3003494157, 'Create'),
+  (1097646649, 'SendMessageToSink'),
+  (1582142032, 'Start'),
+  (3296699291, 'StartDataStreams'),
+  (2159724905, 'StartWithPermissionAlreadyGranted'),
+  (89592214, 'Stop'),
+  (3390251468, 'FlushUntil'),
+  (2246525113, 'InitializeDataPipe'),
+  (3370501815, 'ReceiveFrame'),
+  (535357877, 'CancelInFlightData'),
+  (2608865209, 'SendFrame'),
+  (2064981471, 'OnMessageFromSource'),
+  (2800765533, 'OnMessageFromSink'),
+  (1542333592, 'OnSinkAvailable'),
+  (220543656, 'OnSinkGone'),
+  (2778626197, 'OnStarted'),
+  (3419078009, 'OnStartFailed'),
+  (2717559106, 'OnStopped'),
+  (2222238986, 'OnAudioConfigChange'),
+  (1088905104, 'OnBufferingStateChange'),
+  (3598021346, 'OnEnded'),
+  (234205203, 'OnError'),
+  (3183276895, 'OnStatisticsUpdate'),
+  (3013266561, 'OnTimeUpdate'),
+  (1640316518, 'OnVideoConfigChange'),
+  (3218976703, 'OnVideoNaturalSizeChange'),
+  (1565748409, 'OnVideoOpacityChange'),
+  (1282997171, 'OnWaiting'),
+  (3879649374, 'Flush'),
+  (2251844103, 'Initialize'),
+  (610479010, 'SetCdm'),
+  (2532768787, 'SetPlaybackRate'),
+  (4151938487, 'SetVolume'),
+  (2864559248, 'StartPlayingFrom'),
+  (950969783, 'SpeechRecognitionAvailabilityChanged'),
+  (4147254206, 'SpeechRecognitionLanguageChanged'),
+  (556248261, 'SpeechRecognitionMaskOffensiveWordsChanged'),
+  (529593358, 'BindRecognizerToRemoteClient'),
+  (824153974, 'BindSpeechRecognitionBrowserObserver'),
+  (1461767028, 'BindRecognizer'),
+  (1732816429, 'OnLanguageIdentificationEvent'),
+  (4202158879, 'OnSpeechRecognitionError'),
+  (716684352, 'OnSpeechRecognitionRecognitionEvent'),
+  (1883500597, 'OnSpeechRecognitionStopped'),
+  (947997866, 'MarkDone'),
+  (619887875, 'OnLanguageChanged'),
+  (1895389479, 'OnMaskOffensiveWordsChanged'),
+  (1029612792, 'SendAudioToSpeechRecognitionService'),
+  (2178033636, 'BindAudioSourceSpeechRecognitionContext'),
+  (194200966, 'BindSpeechRecognitionContext'),
+  (3743166392, 'SetSodaConfigPaths'),
+  (2123347161, 'SetSodaParams'),
+  (1227806656, 'SetSodaPaths'),
+  (4148280426, 'Activate'),
+  (3605859735, 'OnFullscreenToggled'),
+  (4252945901, 'OnSessionEnded'),
+  (111852965, 'GetBounds'),
+  (4178441837, 'GetDeviceFormatsInUse'),
+  (742898717, 'GetDeviceSupportedFormats'),
+  (3168319083, 'OnLog'),
+  (3065474077, 'Pause'),
+  (3025439006, 'ReleaseBuffer'),
+  (331362724, 'RequestRefreshFrame'),
+  (3632480199, 'Resume'),
+  (629565662, 'Start'),
+  (3003110806, 'Stop'),
+  (3531815180, 'OnBufferDestroyed'),
+  (3277667023, 'OnBufferReady'),
+  (2056553189, 'OnFrameDropped'),
+  (1094597525, 'OnNewBuffer'),
+  (3178109552, 'OnNewCropVersion'),
+  (224531295, 'OnStateChanged'),
+  (2852445893, 'GetPerfInfo'),
+  (811476277, 'OnVideoFrameDecoded'),
+  (3989133922, 'OnWaiting'),
+  (3195496331, 'RequestOverlayInfo'),
+  (3966690077, 'Construct'),
+  (2275364407, 'Decode'),
+  (1374192714, 'GetSupportedConfigs'),
+  (2377917806, 'Initialize'),
+  (487614472, 'OnOverlayInfoChanged'),
+  (4092198463, 'Reset'),
+  (1174478229, 'StartNewRecord'),
+  (1805797775, 'UpdateRecord'),
+  (1180068465, 'BitstreamBufferReady'),
+  (3990074865, 'NotifyEncoderInfoChange'),
+  (1065579103, 'NotifyErrorStatus'),
+  (2589602645, 'RequireBitstreamBuffers'),
+  (2022540360, 'Encode'),
+  (66741606, 'Flush'),
+  (1635088743, 'Initialize'),
+  (4068032134, 'IsFlushSupported'),
+  (2423145408, 'CreateVideoEncodeAccelerator'),
+  (8250813, 'CreateVideoEncodeAcceleratorProvider'),
+  (1724269046, 'GetVideoEncodeAcceleratorSupportedProfiles'),
+  (719970494, 'RequestEncodingParametersChangeWithBitrate'),
+  (1785397180, 'RequestEncodingParametersChangeWithLayers'),
+  (2650905640, 'UseOutputBitstreamBuffer'),
+  (1628011719, 'Complete'),
+  (1331684035, 'Initialize'),
+  (2967676110, 'SetEncodedFrameCount'),
+  (743920211, 'SetError'),
+  (2065520615, 'ReleaseVideoFrame'),
+  (665238367, 'FinalizeWatchTime'),
+  (3383040664, 'OnCurrentTimestampChanged'),
+  (329943447, 'OnDurationChanged'),
+  (492838439, 'OnError'),
+  (756408215, 'RecordWatchTime'),
+  (4054007301, 'SetAutoplayInitiated'),
+  (3176975280, 'UpdateSecondaryProperties'),
+  (2865342277, 'UpdateUnderflowCount'),
+  (728074860, 'UpdateUnderflowDuration'),
+  (2833506327, 'UpdateVideoDecodeStats'),
+  (1911290156, 'GetPerfInfo'),
+  (1618785642, 'UpdateRecord'),
+  (3625593424, 'BindReceiver'),
+  (3468042691, 'OnMirroringStats'),
+  (1395757940, 'ShouldFetchMirroringStats'),
+  (3264546489, 'BindReceiver'),
+  (1631133627, 'LogError'),
+  (1985223252, 'LogInfo'),
+  (3158475680, 'LogWarning'),
+  (2936925025, 'NextTrack'),
+  (4154689239, 'Pause'),
+  (3868607630, 'Play'),
+  (905157495, 'PreviousTrack'),
+  (3283797426, 'Seek'),
+  (2682287693, 'SetMute'),
+  (3667070738, 'SetVolume'),
+  (3731251261, 'CreateMediaRouteController'),
+  (2623801077, 'CreateRoute'),
+  (3800123701, 'DetachRoute'),
+  (1113133780, 'DiscoverSinksNow'),
+  (4143604246, 'EnableMdnsDiscovery'),
+  (662292501, 'GetState'),
+  (157469502, 'JoinRoute'),
+  (900665356, 'SendRouteBinaryMessage'),
+  (713502766, 'SendRouteMessage'),
+  (1724549195, 'StartListeningForRouteMessages'),
+  (3036338907, 'StartObservingMediaRoutes'),
+  (990498517, 'StartObservingMediaSinks'),
+  (3933221270, 'StopListeningForRouteMessages'),
+  (630093455, 'StopObservingMediaSinks'),
+  (2731730882, 'TerminateRoute'),
+  (2324555292, 'ClearTopIssueForSink'),
+  (1814774774, 'GetDebugger'),
+  (3912273633, 'GetLogger'),
+  (2842857190, 'GetLogsAsString'),
+  (18080070, 'GetMediaSinkServiceStatus'),
+  (4238527416, 'OnIssue'),
+  (577016353, 'OnPresentationConnectionClosed'),
+  (501384143, 'OnPresentationConnectionStateChanged'),
+  (3196243012, 'OnRouteMessagesReceived'),
+  (1251512299, 'OnRoutesUpdated'),
+  (4230625936, 'OnSinksReceived'),
+  (629020924, 'RegisterMediaRouteProvider'),
+  (3264341803, 'OnMediaStatusUpdated'),
+  (1199776015, 'AddObserver'),
+  (1394339488, 'AddSourceObserver'),
+  (2732908400, 'GetDebugInfoForRequest'),
+  (3919643475, 'GetFocusRequests'),
+  (2925143710, 'GetSourceFocusRequests'),
+  (2884765754, 'RequestAudioFocus'),
+  (580092605, 'RequestGroupedAudioFocus'),
+  (2207112270, 'RequestIdReleased'),
+  (3714237097, 'SetEnforcementMode'),
+  (1631841556, 'SetSource'),
+  (708181324, 'OnFocusGained'),
+  (3308702422, 'OnFocusLost'),
+  (1884218714, 'OnRequestIdReleased'),
+  (3057438177, 'AbandonAudioFocus'),
+  (3871551116, 'MediaSessionInfoChanged'),
+  (1834204102, 'RequestAudioFocus'),
+  (1329150649, 'AddObserver'),
+  (74828749, 'EnterAutoPictureInPicture'),
+  (590969678, 'EnterPictureInPicture'),
+  (3040330368, 'ExitPictureInPicture'),
+  (2465154499, 'HangUp'),
+  (3926971399, 'MediaControllerImageChanged'),
+  (3788729072, 'CreateActiveMediaController'),
+  (3180303870, 'CreateMediaControllerForSession'),
+  (240250789, 'SuspendAllSessions'),
+  (300977356, 'NextTrack'),
+  (1034062117, 'ObserveImages'),
+  (3593328791, 'MediaSessionActionsChanged'),
+  (3354403732, 'MediaSessionChanged'),
+  (1778845725, 'MediaSessionInfoChanged'),
+  (1390401610, 'MediaSessionMetadataChanged'),
+  (1611146669, 'MediaSessionPositionChanged'),
+  (760907013, 'PreviousTrack'),
+  (359726049, 'Raise'),
+  (1159105410, 'RequestMediaRemoting'),
+  (4188765703, 'Resume'),
+  (3429711743, 'ScrubTo'),
+  (4169085873, 'Seek'),
+  (1266671969, 'SeekTo'),
+  (3498529358, 'SetAudioSinkId'),
+  (4195039493, 'SetMute'),
+  (944285553, 'Stop'),
+  (2716074775, 'Suspend'),
+  (3556541051, 'ToggleCamera'),
+  (2432427759, 'ToggleMicrophone'),
+  (2276738615, 'ToggleSuspendResume'),
+  (109080725, 'AddObserver'),
+  (3159162590, 'EnterAutoPictureInPicture'),
+  (3163134625, 'EnterPictureInPicture'),
+  (2896287999, 'ExitPictureInPicture'),
+  (3160578282, 'GetDebugInfo'),
+  (2331697758, 'GetMediaImageBitmap'),
+  (2517689556, 'GetMediaSessionInfo'),
+  (573352236, 'HangUp'),
+  (944226855, 'NextSlide'),
+  (444074291, 'NextTrack'),
+  (4278894421, 'MediaSessionActionsChanged'),
+  (3966185760, 'MediaSessionImagesChanged'),
+  (2742425409, 'MediaSessionInfoChanged'),
+  (169447862, 'MediaSessionMetadataChanged'),
+  (2531464749, 'MediaSessionPositionChanged'),
+  (1616097043, 'PreviousSlide'),
+  (3245210150, 'PreviousTrack'),
+  (694596715, 'Raise'),
+  (3652505358, 'RequestMediaRemoting'),
+  (2944612889, 'Resume'),
+  (1881914354, 'ScrubTo'),
+  (148081793, 'Seek'),
+  (321827022, 'SeekTo'),
+  (1085554238, 'SetAudioSinkId'),
+  (3717229028, 'SetMute'),
+  (1969654077, 'SkipAd'),
+  (3227927227, 'StartDucking'),
+  (1900102916, 'Stop'),
+  (3496656162, 'StopDucking'),
+  (2603352555, 'Suspend'),
+  (3729527520, 'ToggleCamera'),
+  (1851324363, 'ToggleMicrophone'),
+  (3658060291, 'EventCallback'),
+  (4214186852, 'AddLogRecord'),
+  (1458175438, 'AllocateSecureBuffer'),
+  (3884036376, 'GetHwConfigData'),
+  (3720302051, 'GetHwKeyData'),
+  (2924777564, 'GetScreenResolutions'),
+  (684575523, 'RegisterEventCallback'),
+  (2246474061, 'Construct'),
+  (2065722489, 'Decode'),
+  (2771590047, 'CreateStableVideoDecoder'),
+  (415061393, 'InitializeStableVideoDecoderFactory'),
+  (2037357689, 'GetSupportedConfigs'),
+  (747219933, 'Initialize'),
+  (2150830758, 'Reset'),
+  (3820221268, 'OnVideoFrameDecoded'),
+  (101425544, 'OnWaiting'),
+  (1554601952, 'ReleaseVideoFrame'),
+  (4148973985, 'RequestChromeMemoryDump'),
+  (2083992172, 'RequestOSMemoryDump'),
+  (3189782928, 'RegisterCoordinatorClient'),
+  (3317452956, 'RequestGlobalMemoryDump'),
+  (546291156, 'RequestGlobalMemoryDumpAndAppendToTrace'),
+  (247628240, 'RequestGlobalMemoryDumpForPid'),
+  (3726691382, 'RequestPrivateMemoryFootprint'),
+  (1455993618, 'DumpProcessesForTracing'),
+  (2942663956, 'GetVmRegionsForHeapProfiler'),
+  (283351454, 'Collect'),
+  (1241215316, 'SetSample'),
+  (4096910119, 'AcquireSingleSampleMetric'),
+  (1002255857, 'OnClearMark'),
+  (1587140796, 'OnGetMark'),
+  (3625313319, 'OnPageRemoteCreated'),
+  (655963861, 'OnUmaReportTime'),
+  (511892518, 'OnClearMark'),
+  (1485118528, 'OnGetMark'),
+  (3003479844, 'AcknowledgeSentData'),
+  (863112999, 'AddInputPort'),
+  (737947277, 'AddOutputPort'),
+  (1791287230, 'DataReceived'),
+  (3734749213, 'SessionStarted'),
+  (2441775373, 'SetInputPortState'),
+  (4059486837, 'SetOutputPortState'),
+  (709203188, 'StartSession'),
+  (3405038297, 'SendData'),
+  (3463117243, 'StreamCreated'),
+  (2477052053, 'OnMessage'),
+  (736510040, 'GetMirroringStats'),
+  (1027215560, 'Start'),
+  (1349933684, 'SwitchMirroringSourceTab'),
+  (2135127019, 'BindGpu'),
+  (3748970050, 'ConnectToRemotingSource'),
+  (641268869, 'CreateAudioStream'),
+  (3006910964, 'GetNetworkContext'),
+  (3674575874, 'GetVideoCaptureHost'),
+  (320856345, 'GetVideoEncoderMetricsProvider'),
+  (3970376057, 'DidStart'),
+  (636065240, 'DidStop'),
+  (2450691050, 'LogErrorMessage'),
+  (1764895871, 'LogInfoMessage'),
+  (3458807772, 'OnError'),
+  (1302431677, 'OnRemotingStateChanged'),
+  (3622233931, 'OnSourceChanged'),
+  (2771316908, 'CreateModelLoader'),
+  (2469915697, 'Compute'),
+  (1692954132, 'Load'),
+  (3253860162, 'Bind'),
+  (2483680572, 'GetDebugInfo'),
+  (2084911167, 'CheckSystemPermissions'),
+  (1545305211, 'GetAdapter'),
+  (519466199, 'GetDebugLogsChangeHandler'),
+  (2624960057, 'RequestLocationServices'),
+  (1862682292, 'RequestSystemPermissions'),
+  (1967868588, 'ChangeDebugLogsState'),
+  (3026583887, 'BindInternalsInterface'),
+  (1817729242, 'HandleAnswerImageData'),
+  (31102778, 'HandleNewAutocompleteQuery'),
+  (3926115208, 'HandleNewAutocompleteResponse'),
+  (2016351793, 'SetClientPage'),
+  (2176796246, 'StartOmniboxQuery'),
+  (1452728385, 'GetAllWebContentsInfo'),
+  (1481865813, 'GetGloballyIsolatedOrigins'),
+  (326129746, 'GetIsolationMode'),
+  (2783623311, 'GetProcessCountInfo'),
+  (2677900731, 'GetUserTriggeredIsolatedOrigins'),
+  (3413449071, 'GetWebTriggeredIsolatedOrigins'),
+  (500403580, 'HandlePasswordReset'),
+  (3848003527, 'BindTestInterface'),
+  (3710987817, 'BindUsbDeviceManagerInterface'),
+  (1033670626, 'GetFeaturePromos'),
+  (1453624711, 'GetTutorials'),
+  (1120842225, 'ShowFeaturePromo'),
+  (3120117050, 'StartTutorial'),
+  (73237463, 'GetDebugInfoAsJsonString'),
+  (1524320959, 'InstallIsolatedWebAppFromDevProxy'),
+  (708957778, 'SelectFileAndInstallIsolatedWebAppFromDevBundle'),
+  (1556845181, 'AddMostVisitedTile'),
+  (1471268374, 'CancelPrerender'),
+  (4058982845, 'DeleteMostVisitedTile'),
+  (2526512057, 'CreatePageHandler'),
+  (3603751528, 'OnMostVisitedTileNavigation'),
+  (4099761488, 'OnMostVisitedTilesRendered'),
+  (332664241, 'PrerenderMostVisitedTile'),
+  (3014937623, 'ReorderMostVisitedTile'),
+  (313378791, 'RestoreMostVisitedDefaults'),
+  (1432012754, 'UndoMostVisitedTileAction'),
+  (3227098105, 'UpdateMostVisitedInfo'),
+  (2784306573, 'UpdateMostVisitedTile'),
+  (2753194597, 'SetMostVisitedInfo'),
+  (796475135, 'ProvideExitControl'),
+  (3284462637, 'ReportExitStatus'),
+  (1434423270, 'ReportLoadStatus'),
+  (3491588818, 'Preconnect'),
+  (827471616, 'PrefetchDNS'),
+  (912978577, 'Clone'),
+  (3745913413, 'OnAcceptCHFrameReceived'),
+  (1470830642, 'OnAuthCredentials'),
+  (1466349638, 'GetSize'),
+  (2074753498, 'StartReading'),
+  (1904150679, 'CancelRequest'),
+  (271956909, 'ContinueWithCertificate'),
+  (3702509694, 'ContinueWithoutCertificate'),
+  (3148955620, 'Clone'),
+  (2964420114, 'OnCookiesAccessed'),
+  (2066419482, 'OnCookieChange'),
+  (659283967, 'AddCookieChangeListener'),
+  (853220684, 'AddGlobalChangeListener'),
+  (400708006, 'AllowFileSchemeCookies'),
+  (877150279, 'BlockThirdPartyCookies'),
+  (3365713786, 'BlockTruncatedCookies'),
+  (3253784451, 'CloneInterface'),
+  (2967220758, 'DeleteCanonicalCookie'),
+  (1271710531, 'DeleteCookies'),
+  (610347512, 'DeleteSessionOnlyCookies'),
+  (3950263405, 'FlushCookieStore'),
+  (2430195333, 'GetAllCookies'),
+  (3618388499, 'GetAllCookiesWithAccessSemantics'),
+  (2943020078, 'GetCookieList'),
+  (94178623, 'SetCanonicalCookie'),
+  (1826824685, 'SetContentSettings'),
+  (219436638, 'SetForceKeepSessionState'),
+  (2104272135, 'SetMitigationsEnabledFor3pcd'),
+  (3533789458, 'Clone'),
+  (1188150421, 'QueueCorpViolationReport'),
+  (3571604225, 'QueueAccessReport'),
+  (3974577689, 'ClearBadProxiesCache'),
+  (1315987915, 'MarkProxiesAsBad'),
+  (3880196169, 'OnCustomProxyConfigUpdated'),
+  (3454086310, 'OnFallback'),
+  (458218614, 'OnTunnelHeadersReceived'),
+  (1991273356, 'Clone'),
+  (1815419388, 'Read'),
+  (3093371228, 'Clone'),
+  (1955313548, 'OnCorbError'),
+  (2816441187, 'OnCorsError'),
+  (3496107222, 'OnCorsPreflightRequest'),
+  (2823514911, 'OnCorsPreflightRequestCompleted'),
+  (2144103571, 'OnCorsPreflightResponse'),
+  (1805828749, 'OnPrivateNetworkRequest'),
+  (976381151, 'OnRawRequest'),
+  (4102824253, 'OnRawResponse'),
+  (3139992114, 'OnSubresourceWebBundleInnerResponse'),
+  (1053922146, 'OnSubresourceWebBundleInnerResponseError'),
+  (1653891817, 'OnSubresourceWebBundleMetadata'),
+  (2998906895, 'OnSubresourceWebBundleMetadataError'),
+  (3934023672, 'OnTrustTokenOperationDone'),
+  (4044697222, 'OnDnsConfigChanged'),
+  (2099320524, 'RequestNotifications'),
+  (504737166, 'GetNext'),
+  (2271683572, 'NotifyReady'),
+  (200666637, 'SetEnabled'),
+  (3808425690, 'OnBeforeGssapiLibraryLoad'),
+  (1879222671, 'MdnsListen'),
+  (1473987205, 'ResolveHost'),
+  (3714536213, 'CleanupDirectory'),
+  (1700630323, 'CreateDirectory'),
+  (829650938, 'DeleteFile'),
+  (2219936204, 'DirectoryExists'),
+  (2085406015, 'EnumerateFiles'),
+  (3222287818, 'Create'),
+  (1023575270, 'GetFileInfo'),
+  (3194918586, 'OpenFile'),
+  (3053508744, 'PathExists'),
+  (1589281113, 'RenameFile'),
+  (1559964273, 'GetProxyList'),
+  (622444951, 'TryGetAuthTokens'),
+  (3681260770, 'OnAddressResult'),
+  (875997784, 'OnHostnameResult'),
+  (811607081, 'OnTextResult'),
+  (1749827903, 'OnUnhandledResult'),
+  (402836750, 'CreateNameForAddress'),
+  (1172427023, 'RemoveNameForAddress'),
+  (1639210587, 'Start'),
+  (1104747109, 'Stop'),
+  (1154840901, 'AddEntry'),
+  (3629161244, 'UpdateCaptureModes'),
+  (4086020099, 'BindNetworkInterfaceChangeListener'),
+  (4152690700, 'OnInitialConnectionType'),
+  (3156818821, 'OnNetworkChanged'),
+  (2380256014, 'OnNetworkChanged'),
+  (2978964956, 'RequestNotifications'),
+  (4069184646, 'AddAuthCacheEntry'),
+  (4123512141, 'AddDomainReliabilityContextForTesting'),
+  (1342519561, 'AddHSTS'),
+  (2264299471, 'AddReportingApiObserver'),
+  (3778615856, 'ClearBadProxiesCache'),
+  (1691402476, 'ClearCorsPreflightCache'),
+  (1407196666, 'ClearDomainReliability'),
+  (710250334, 'ClearHostCache'),
+  (2868431362, 'ClearHttpAuthCache'),
+  (3956354993, 'ClearHttpCache'),
+  (4120055798, 'ClearNetworkErrorLogging'),
+  (809893901, 'ClearNetworkingHistoryBetween'),
+  (1022492016, 'ClearReportingCacheClients'),
+  (694932452, 'ClearReportingCacheReports'),
+  (193816603, 'ClearSharedDictionaryCache'),
+  (1942801938, 'ClearSharedDictionaryCacheForIsolationKey'),
+  (2969278959, 'ClearTrustTokenData'),
+  (1973451749, 'ClearTrustTokenSessionOnlyData'),
+  (3783402827, 'OnCanSendDomainReliabilityUpload'),
+  (2038161998, 'OnCanSendReportingReports'),
+  (1498002981, 'OnCanSendSCTAuditingReport'),
+  (4009146748, 'OnFileUploadRequested'),
+  (3388656613, 'OnGenerateHttpNegotiateAuthToken'),
+  (768567649, 'OnNewSCTAuditingReportSent'),
+  (292891116, 'CloseAllConnections'),
+  (2956635927, 'CloseIdleConnections'),
+  (3027925827, 'ComputeHttpCacheSize'),
+  (507809468, 'CreateHostResolver'),
+  (4281272197, 'CreateMdnsResponder'),
+  (3613131009, 'CreateNetLogExporter'),
+  (4181723504, 'CreateP2PSocketManager'),
+  (4116839010, 'CreateProxyResolvingSocketFactory'),
+  (138345098, 'CreateRestrictedUDPSocket'),
+  (1209488328, 'CreateTCPBoundSocket'),
+  (700182790, 'CreateTCPConnectedSocket'),
+  (2857972326, 'CreateTCPServerSocket'),
+  (1025418275, 'CreateUDPSocket'),
+  (4202500781, 'CreateURLLoaderFactory'),
+  (1818711516, 'CreateWebSocket'),
+  (3223096269, 'CreateWebTransport'),
+  (3176345828, 'DeleteDynamicDataForHost'),
+  (91471566, 'DeleteStoredTrustTokens'),
+  (1761609508, 'EnableStaticKeyPinningForTesting'),
+  (3565928430, 'FlushCachedClientCertIfNeeded'),
+  (3212672758, 'ForceDomainReliabilityUploadsForTesting'),
+  (4005525437, 'ForceReloadProxyConfig'),
+  (2948734142, 'GetCookieManager'),
+  (465729219, 'GetHSTSState'),
+  (546155654, 'GetRestrictedCookieManager'),
+  (3258687483, 'GetSharedDictionaryInfo'),
+  (4105109898, 'GetSharedDictionaryOriginsBetween'),
+  (2823303413, 'GetSharedDictionaryUsageInfo'),
+  (1511942248, 'GetStoredTrustTokenCounts'),
+  (3722620149, 'GetTrustTokenQueryAnswerer'),
+  (3434680930, 'GetViaObliviousHttp'),
+  (632300895, 'InvalidateIpProtectionConfigCacheTryAgainAfterTime'),
+  (2307702409, 'IsHSTSActiveForHost'),
+  (438245471, 'LoadHttpAuthCacheProxyEntries'),
+  (2556214070, 'LookUpProxyForURL'),
+  (4041395715, 'LookupServerBasicAuthCredentials'),
+  (1797934280, 'NotifyExternalCacheHit'),
+  (809612192, 'PreconnectSockets'),
+  (983006111, 'QueueReport'),
+  (3141390153, 'QueueSignedExchangeReport'),
+  (2731691928, 'ResetURLLoaderFactories'),
+  (3015928373, 'ResolveHost'),
+  (1005394704, 'ResourceSchedulerClientVisibilityChanged'),
+  (1348486267, 'SaveHttpAuthCacheProxyEntries'),
+  (1410961087, 'SendReportsAndRemoveSource'),
+  (4281048925, 'SetAcceptLanguage'),
+  (3915639374, 'SetBlockTrustTokens'),
+  (2802113820, 'SetClient'),
+  (4075882966, 'SetCookieDeprecationLabel'),
+  (205327495, 'SetCorsNonWildcardRequestHeadersSupport'),
+  (2591268583, 'SetCorsOriginAccessListsForOrigin'),
+  (4189653657, 'SetCTLogListAlwaysTimelyForTesting'),
+  (3448548843, 'SetCTPolicy'),
+  (506906837, 'SetDocumentReportingEndpoints'),
+  (121187834, 'SetEnableReferrers'),
+  (665888864, 'SetNetworkConditions'),
+  (1191657667, 'SetSCTAuditingMode'),
+  (465963532, 'SetSharedDictionaryCacheMaxSize'),
+  (4086182401, 'SetSplitAuthCacheByNetworkAnonymizationKey'),
+  (1456228997, 'VerifyCertForSignedExchange'),
+  (193082988, 'VerifyCertificateForTesting'),
+  (819577940, 'VerifyIpProtectionConfigGetterForTesting'),
+  (3043965578, 'OnNetworkInterfacesChanged'),
+  (183036424, 'OnNetworkQualityChanged'),
+  (1695949770, 'RequestNotifications'),
+  (2168292788, 'AttachNetLogProxy'),
+  (1135029020, 'BindTestInterfaceForTesting'),
+  (283949586, 'ClearSCTAuditingCache'),
+  (796681483, 'ConfigureHttpAuthPrefs'),
+  (2830839659, 'ConfigureSCTAuditing'),
+  (1507596219, 'ConfigureStubHostResolver'),
+  (125529834, 'CreateNetworkContext'),
+  (644756601, 'DisableQuic'),
+  (4229922202, 'DumpWithoutCrashing'),
+  (1011753108, 'EnableDataUseUpdates'),
+  (2303800476, 'GetDnsConfigChangeManager'),
+  (2940198739, 'GetNetworkChangeManager'),
+  (4216876629, 'GetNetworkList'),
+  (3934124839, 'GetNetworkQualityEstimatorManager'),
+  (121963099, 'OnApplicationStateChange'),
+  (1696651083, 'OnClientCertStoreChanged'),
+  (664134871, 'OnMemoryPressure'),
+  (2497675816, 'OnPeerToPeerConnectionsCountChange'),
+  (2011791722, 'OnTrustStoreChanged'),
+  (1419877769, 'ParseHeaders'),
+  (3567810134, 'SetCtEnforcementEnabled'),
+  (2168484115, 'SetEncryptionKey'),
+  (1912590501, 'SetEnvironment'),
+  (4138098604, 'SetExplicitlyAllowedPorts'),
+  (781514888, 'SetFirstPartySets'),
+  (1241368289, 'SetGssapiLibraryLoadObserver'),
+  (2651178912, 'SetMaxConnectionsPerProxy'),
+  (3104265949, 'SetParams'),
+  (2429828600, 'SetRawHeadersAccess'),
+  (2782845133, 'SetSSLKeyLogFile'),
+  (3340924024, 'SetTrustTokenKeyCommitments'),
+  (1110067975, 'SetUpHttpAuth'),
+  (1292047489, 'StartNetLog'),
+  (4206713481, 'ActivateFieldTrial'),
+  (1547648982, 'AddRules'),
+  (3018276558, 'CrashOnGetCookieList'),
+  (3968232667, 'CrashOnResolveHost'),
+  (890636685, 'CreateSimpleCache'),
+  (842204835, 'EnumerateFiles'),
+  (3617370064, 'ForceNetworkQualityEstimatorReportWifiAsSlow2G'),
+  (4107354918, 'GetAddressMapCacheLinux'),
+  (1532167534, 'GetEnvironmentVariableValue'),
+  (1242583150, 'GetLatestMemoryPressureLevel'),
+  (593876485, 'GetPeerToPeerConnectionsCountChange'),
+  (3342620320, 'Log'),
+  (1713229159, 'MakeRequestToServer'),
+  (282611978, 'MockCertVerifierAddResultForCertAndHost'),
+  (1322509988, 'MockCertVerifierSetDefaultResult'),
+  (2387429777, 'OpenFile'),
+  (931071167, 'ReplaceSystemDnsConfig'),
+  (1402529848, 'ResolveOwnHostnameWithSystemDns'),
+  (1535389215, 'SetAllowNetworkAccessToHostResolutions'),
+  (3911778623, 'SetRequireCT'),
+  (3156376201, 'SetSCTAuditingRetryDelay'),
+  (4076961248, 'SetTestDohConfig'),
+  (2998179079, 'SetTransportSecurityStateSource'),
+  (1270529292, 'SimulateCrash'),
+  (3667450740, 'SimulateNetworkChange'),
+  (1867175086, 'SimulateNetworkQualityChange'),
+  (1497266165, 'UpdateCtKnownPopularSCTs'),
+  (2698849953, 'UpdateCtLogList'),
+  (476699818, 'UpdateKeyPinsList'),
+  (2786904923, 'UpdateMaskedDomainList'),
+  (3242928275, 'OnCompleted'),
+  (491638245, 'NetworkListChanged'),
+  (1185763128, 'DataReceived'),
+  (1002528683, 'SendBatchComplete'),
+  (1803811683, 'SendComplete'),
+  (3932347331, 'SocketCreated'),
+  (488545597, 'CreateSocket'),
+  (3443602192, 'GetHostAddress'),
+  (217586235, 'GetHostAddressWithFamily'),
+  (2170074153, 'StartNetworkNotifications'),
+  (1619392202, 'Send'),
+  (2976344178, 'SendBatch'),
+  (1900732933, 'SetOption'),
+  (228519617, 'DumpPacket'),
+  (654598286, 'InvalidSocketPortRangeRequested'),
+  (4239043367, 'PauseNetworkChangeNotifications'),
+  (4250055442, 'ResumeNetworkChangeNotifications'),
+  (2639852738, 'StartRtpDump'),
+  (2321227156, 'StopRtpDump'),
+  (2160424497, 'FlushProxyConfig'),
+  (984780041, 'OnProxyConfigUpdated'),
+  (2347231843, 'OnLazyProxyConfigPoll'),
+  (2959974125, 'OnPACScriptError'),
+  (1362184243, 'OnRequestMaybeFailedDueToProxySettings'),
+  (2691760440, 'OnProxyLookupComplete'),
+  (2273109288, 'CreateProxyResolvingSocket'),
+  (243937692, 'UpgradeToTLS'),
+  (1669644223, 'OnEndpointsUpdatedForOrigin'),
+  (3425261103, 'OnReportAdded'),
+  (3890429369, 'OnReportUpdated'),
+  (1884657456, 'OnComplete'),
+  (2097936687, 'OnHostnameResults'),
+  (1996546839, 'OnTextResults'),
+  (2397696341, 'Cancel'),
+  (1871343451, 'AddChangeListener'),
+  (1387096055, 'CookiesEnabledFor'),
+  (3125137012, 'GetAllForUrl'),
+  (2375907603, 'GetCookiesString'),
+  (2262328379, 'SetCanonicalCookie'),
+  (1399101471, 'SetCookieFromString'),
+  (648145183, 'ReceiveMore'),
+  (1968967495, 'Send'),
+  (237040138, 'SendTo'),
+  (3232715809, 'Clone'),
+  (1209257064, 'OnSharedDictionaryAccessed'),
+  (2407194672, 'CreateEntry'),
+  (2014710212, 'Detach'),
+  (3080045764, 'DoomAllEntries'),
+  (3529501525, 'DoomEntry'),
+  (3805245175, 'Close'),
+  (4072547506, 'GetNext'),
+  (3761769639, 'ReadData'),
+  (788605465, 'ReadSparseData'),
+  (1677548894, 'WriteData'),
+  (2231970841, 'WriteSparseData'),
+  (2241398545, 'EnumerateEntries'),
+  (4057082814, 'OpenEntry'),
+  (2239811681, 'CreateTcpSocket'),
+  (1662452987, 'CreateUdpSocket'),
+  (1272043854, 'OnReadError'),
+  (3069027041, 'OnWriteError'),
+  (3915451231, 'OnSSLConfigUpdated'),
+  (2524736507, 'Sign'),
+  (2028440811, 'Resolve'),
+  (1444811867, 'Connect'),
+  (1482320419, 'Listen'),
+  (2318136597, 'SetKeepAlive'),
+  (3051125951, 'SetNoDelay'),
+  (1565075340, 'SetReceiveBufferSize'),
+  (3895354544, 'SetSendBufferSize'),
+  (1542319541, 'UpgradeToTLS'),
+  (2101992554, 'Accept'),
+  (1048844037, 'OnBeforeSendHeaders'),
+  (1579511721, 'OnHeadersReceived'),
+  (3852477826, 'OnLoaderCreated'),
+  (519050630, 'OnLoaderForCorsPreflightCreated'),
+  (824794696, 'Clone'),
+  (2467677475, 'OnTrustTokensAccessed'),
+  (2948083941, 'HasRedemptionRecord'),
+  (3508165695, 'HasTrustTokens'),
+  (3357065968, 'Bind'),
+  (157503757, 'Close'),
+  (710059718, 'Connect'),
+  (1320306039, 'JoinGroup'),
+  (996323912, 'LeaveGroup'),
+  (3124227593, 'OnReceived'),
+  (1661871782, 'ReceiveMore'),
+  (2488854261, 'ReceiveMoreWithBufferSize'),
+  (3480076194, 'Send'),
+  (3554663442, 'SendTo'),
+  (2247428946, 'SetBroadcast'),
+  (3595071532, 'SetReceiveBufferSize'),
+  (3954658870, 'SetSendBufferSize'),
+  (2503424824, 'OnComplete'),
+  (1778869307, 'OnReceiveEarlyHints'),
+  (2012636717, 'OnReceiveRedirect'),
+  (374770486, 'OnReceiveResponse'),
+  (3734484340, 'OnTransferSizeUpdated'),
+  (231973177, 'OnUploadProgress'),
+  (4026588969, 'Clone'),
+  (2397174083, 'CreateLoaderAndStart'),
+  (3412901938, 'FollowRedirect'),
+  (4220276451, 'Clone'),
+  (3786859165, 'OnAuthRequired'),
+  (909581951, 'OnCertificateRequested'),
+  (3526348422, 'OnClearSiteData'),
+  (3598259070, 'OnDataUseUpdate'),
+  (2791424369, 'OnLoadingStateUpdate'),
+  (1066168046, 'OnPrivateNetworkAccessPermissionRequired'),
+  (2043295568, 'OnSharedStorageHeaderReceived'),
+  (1442731778, 'OnSSLCertificateError'),
+  (861902108, 'PauseReadingBodyFromNet'),
+  (19891547, 'ResumeReadingBodyFromNet'),
+  (1109260469, 'SetPriority'),
+  (2062307250, 'Clone'),
+  (2557626952, 'OnWebBundleError'),
+  (1785959928, 'OnWebBundleLoadFinished'),
+  (1177921054, 'OnAuthRequired'),
+  (1674730323, 'OnClosingHandshake'),
+  (4223139020, 'OnDataFrame'),
+  (2003897453, 'OnDropChannel'),
+  (3064348090, 'OnConnectionEstablished'),
+  (2162527540, 'OnFailure'),
+  (3320874585, 'OnOpeningHandshakeStarted'),
+  (4190234944, 'SendMessage'),
+  (1743388136, 'StartClosingHandshake'),
+  (239562914, 'StartReceiving'),
+  (535612045, 'AbortStream'),
+  (4225716318, 'AcceptBidirectionalStream'),
+  (62171957, 'AcceptUnidirectionalStream'),
+  (3723037610, 'OnClosed'),
+  (2319506695, 'OnDatagramReceived'),
+  (3322145243, 'OnIncomingStreamClosed'),
+  (2293757315, 'OnOutgoingStreamClosed'),
+  (3560274410, 'OnReceivedResetStream'),
+  (3304457397, 'OnReceivedStopSending'),
+  (2458869320, 'Close'),
+  (1614513152, 'CreateStream'),
+  (2766555408, 'GetStats'),
+  (2772495661, 'OnConnectionEstablished'),
+  (3754141468, 'OnHandshakeFailed'),
+  (2524799198, 'SendDatagram'),
+  (370241504, 'SendFin'),
+  (2323259501, 'SetOutgoingDatagramExpirationDuration'),
+  (3883426631, 'StopSending'),
+  (1746564750, 'BlocklistPromo'),
+  (1579467667, 'ChooseLocalCustomBackground'),
+  (1587592508, 'ConfirmBackgroundChanges'),
+  (1996867908, 'CreatePageHandler'),
+  (2803937010, 'GetBackgroundCollections'),
+  (1867556499, 'GetBackgroundImages'),
+  (4112950821, 'GetDoodle'),
+  (550266603, 'GetModulesIdNames'),
+  (2316963419, 'GetModulesOrder'),
+  (847266683, 'GetMostVisitedSettings'),
+  (2590311703, 'IncrementCustomizeChromeButtonOpenCount'),
+  (428669685, 'IncrementModulesShownCount'),
+  (1175083592, 'LogModulesFreOptInStatus'),
+  (3483331438, 'MaybeShowCustomizeChromeFeaturePromo'),
+  (1545672178, 'OnAppRendered'),
+  (1314709032, 'OnCustomizeDialogAction'),
+  (1158385861, 'OnDismissModule'),
+  (349961044, 'OnDoodleImageClicked'),
+  (1568997659, 'OnDoodleImageRendered'),
+  (2656790132, 'OnDoodleShared'),
+  (3021088099, 'OnModulesLoadedWithData'),
+  (1747153580, 'OnOneGoogleBarRendered'),
+  (2092530033, 'OnPromoLinkClicked'),
+  (2394374609, 'OnPromoRendered'),
+  (3274908130, 'OnRestoreModule'),
+  (3054278185, 'RevertBackgroundChanges'),
+  (2274737521, 'SetBackgroundImage'),
+  (4189031839, 'SetCustomizeChromeSidePanelVisible'),
+  (3254558513, 'SetDailyRefreshCollectionId'),
+  (153054764, 'SetModuleDisabled'),
+  (3322987676, 'SetModulesFreVisible'),
+  (2611173287, 'SetModulesOrder'),
+  (1171576305, 'SetModulesVisible'),
+  (3458693753, 'SetMostVisitedSettings'),
+  (2172222551, 'SetNoBackgroundImage'),
+  (3711293034, 'UndoBlocklistPromo'),
+  (2756907054, 'UpdateDisabledModules'),
+  (1015599281, 'UpdateModulesFreVisibility'),
+  (3639623891, 'UpdatePromoData'),
+  (3193541545, 'SetCustomizeChromeSidePanelVisibility'),
+  (2129307663, 'SetDisabledModules'),
+  (4166549113, 'SetModulesFreVisibility'),
+  (2808970795, 'SetPromo'),
+  (818186828, 'SetTheme'),
+  (1604223332, 'ShowWebstoreToast'),
+  (680431220, 'CreatePageHandler'),
+  (1146450006, 'UpdateTheme'),
+  (2434366913, 'SetTheme'),
+  (593784705, 'ArticleOpened'),
+  (3736600852, 'GetFollowingFeedArticles'),
+  (2317704497, 'DismissCluster'),
+  (1014594964, 'GetCartForCluster'),
+  (2266751708, 'GetClusters'),
+  (4098040761, 'GetDiscountsForCluster'),
+  (3284449666, 'OpenUrlsInTabGroup'),
+  (919935248, 'RecordClick'),
+  (122336746, 'RecordDisabled'),
+  (1637109534, 'RecordLayoutTypeShown'),
+  (349270721, 'ShowJourneysSidePanel'),
+  (3723126674, 'GetCartForCluster'),
+  (470720061, 'GetClusters'),
+  (1040789337, 'GetDiscountsForCluster'),
+  (593655863, 'RecordClick'),
+  (4223632453, 'RecordLayoutTypeShown'),
+  (2351459183, 'ShowJourneysSidePanel'),
+  (2760014518, 'UpdateClusterVisitsInteractionState'),
+  (3328712537, 'CanShowModule'),
+  (331692678, 'DismissModule'),
+  (2382645938, 'ProcessModuleClick'),
+  (1514255016, 'RestoreModule'),
+  (645446120, 'NotifyMhtmlPageLoadAttempted'),
+  (1320802191, 'AutocompleteResultChanged'),
+  (1442360981, 'DeleteAutocompleteMatch'),
+  (1068651238, 'ExecuteAction'),
+  (1470593827, 'OnFocusChanged'),
+  (2962381074, 'OnNavigationLikely'),
+  (1684210230, 'OpenAutocompleteMatch'),
+  (3546575125, 'QueryAutocomplete'),
+  (3796138415, 'SetPage'),
+  (561751794, 'StopAutocomplete'),
+  (3677371177, 'ToggleSuggestionGroupIdVisibility'),
+  (3222530455, 'UpdateSelection'),
+  (1564818562, 'Execute'),
+  (3544758983, 'LoadModel'),
+  (2514235156, 'OnComplete'),
+  (3053935915, 'OnResponse'),
+  (965124771, 'CreatePageHandler'),
+  (1450009923, 'RequestDownloadedModelsInfo'),
+  (1170896972, 'OnLogMessageAdded'),
+  (2510325862, 'OnChunksEnd'),
+  (2659500149, 'OnTextDumpChunk'),
+  (1660354845, 'RequestPageTextDump'),
+  (3050702584, 'GetPageImageUrl'),
+  (1702483874, 'SetUpSharedMemoryForSmoothness'),
+  (1589948206, 'UpdateTiming'),
+  (534813988, 'BeginMainFrameComposite'),
+  (2092611066, 'BeginSeparatedFrameComposite'),
+  (3176740475, 'BitmapForMainFrame'),
+  (3817615947, 'BitmapForSeparatedFrame'),
+  (3208590864, 'CreateCompositor'),
+  (3367917806, 'ListCompositors'),
+  (3769235365, 'OnMemoryPressure'),
+  (764082256, 'SetDiscardableSharedMemoryManager'),
+  (3870203092, 'SetRootFrameUrl'),
+  (3186574148, 'CapturePaintPreview'),
+  (809638857, 'ParseCSV'),
+  (4099024750, 'PatchFileBsdiff'),
+  (3287052147, 'PatchFileCourgette'),
+  (84502586, 'PatchFilePuffPatch'),
+  (40814688, 'Consume'),
+  (1288932699, 'CreateDigitalGoods'),
+  (1234004052, 'GetDetails'),
+  (3004087112, 'ListPurchaseHistory'),
+  (2116739347, 'ListPurchases'),
+  (2468495791, 'StorePaymentCredential'),
+  (2956845549, 'ChangePaymentMethod'),
+  (1960000276, 'ChangeShippingAddress'),
+  (1873419592, 'ChangeShippingOption'),
+  (1101098608, 'OnResponseForAbortPayment'),
+  (3659520223, 'OnResponseForCanMakePayment'),
+  (2366009053, 'OnResponseForPaymentRequest'),
+  (3065142326, 'ClearPaymentInstruments'),
+  (2235626593, 'DeletePaymentInstrument'),
+  (1799351088, 'EnableDelegations'),
+  (446626229, 'GetPaymentInstrument'),
+  (4234827433, 'HasPaymentInstrument'),
+  (82289547, 'Init'),
+  (3148747019, 'KeysOfPaymentInstruments'),
+  (739020111, 'SetPaymentInstrument'),
+  (811917069, 'SetUserHint'),
+  (3277574740, 'Abort'),
+  (2730887948, 'CanMakePayment'),
+  (3404623177, 'AllowConnectToSource'),
+  (646072910, 'OnAbort'),
+  (1837619362, 'OnCanMakePayment'),
+  (2185291149, 'OnComplete'),
+  (362133181, 'OnError'),
+  (2937848103, 'OnHasEnrolledInstrument'),
+  (1399112732, 'OnPayerDetailChange'),
+  (3356810592, 'OnPaymentMethodChange'),
+  (1705884419, 'OnPaymentResponse'),
+  (1540667498, 'OnShippingAddressChange'),
+  (1924371915, 'OnShippingOptionChange'),
+  (3128752639, 'WarnNoFavicon'),
+  (1445722019, 'Complete'),
+  (1709199342, 'HasEnrolledInstrument'),
+  (4011452359, 'Init'),
+  (3538382764, 'OnPaymentDetailsNotUpdated'),
+  (3108310162, 'Retry'),
+  (1764662995, 'Show'),
+  (2551807249, 'UpdateWith'),
+  (703304332, 'MoveRangeSelectionExtent'),
+  (1740268825, 'SetCaretPosition'),
+  (3638483333, 'SetSelectionBounds'),
+  (3377959030, 'HasUnsupportedFeature'),
+  (2102108332, 'SaveUrlAs'),
+  (201653861, 'SelectionChanged'),
+  (2421353523, 'SetListener'),
+  (1164914142, 'SetPluginCanSave'),
+  (505086706, 'UpdateContentRestrictions'),
+  (545793916, 'OnFirstContentfulPaint'),
+  (1758040487, 'OnNonPersistentNotificationCreated'),
+  (3492801403, 'OnWebMemoryMeasurementRequested'),
+  (1659929831, 'SetHadFormInteraction'),
+  (3986466885, 'SetHadUserEdits'),
+  (3832956231, 'SetHasNonEmptyBeforeUnload'),
+  (1712430367, 'SetIsAdFrame'),
+  (4214016382, 'SetLifecycleState'),
+  (174705920, 'SetNetworkAlmostIdle'),
+  (772520097, 'FireBackgroundTracingTrigger'),
+  (3218139293, 'OnRemoteIframeAttached'),
+  (2124820806, 'OnRemoteIframeDetached'),
+  (3973739995, 'OnV8ContextCreated'),
+  (742935319, 'OnV8ContextDestroyed'),
+  (3776459967, 'OnV8ContextDetached'),
+  (4171320225, 'SetMainThreadTaskLoadIsLow'),
+  (1674236446, 'DismissModule'),
+  (1716653274, 'GetMemories'),
+  (2955177791, 'GetOptInTitleText'),
+  (1953749537, 'OnMemoryOpen'),
+  (358388472, 'OnUserOptIn'),
+  (1316646080, 'RestoreModule'),
+  (189509225, 'ShouldShowOptInScreen'),
+  (1133999686, 'ShouldShowSoftOptOutButton'),
+  (3267928446, 'SoftOptOut'),
+  (1316941709, 'OnResetOnLoad'),
+  (2959711655, 'OnAtomicPreferenceValidation'),
+  (3427431453, 'OnSplitPreferenceValidation'),
+  (3172989671, 'CancelPrerenderForNoStatePrefetch'),
+  (988521287, 'CancelPrerenderForUnsupportedScheme'),
+  (925854505, 'SetIsPrerendering'),
+  (2899626403, 'NupDocumentConvert'),
+  (2270984947, 'NupPageConvert'),
+  (155199771, 'SetUseSkiaRendererPolicy'),
+  (1655216438, 'SetWebContentsURL'),
+  (1124528700, 'Convert'),
+  (478152588, 'SetUseSkiaRendererPolicy'),
+  (1794221037, 'Cancel'),
+  (4258171967, 'DocumentDone'),
+  (1674396103, 'EnumeratePrinters'),
+  (2511856344, 'EstablishPrintingContext'),
+  (872801000, 'FetchCapabilities'),
+  (709162509, 'GetDefaultPrinterName'),
+  (1753803451, 'Init'),
+  (3173534402, 'Poke'),
+  (2367674252, 'RenderPrintedDocument'),
+  (2908193355, 'StartPrinting'),
+  (4265680110, 'UpdatePrintSettings'),
+  (1335427619, 'UseDefaultSettings'),
+  (2172621334, 'AddSubframeContent'),
+  (2112913572, 'CompleteDocumentToPdf'),
+  (3364059889, 'CompositeDocumentToPdf'),
+  (4179337949, 'CompositePageToPdf'),
+  (86192027, 'NotifyUnavailableSubframe'),
+  (2851583638, 'PrepareForDocumentToPdf'),
+  (29330238, 'SetAccessibilityTree'),
+  (563602988, 'SetUserAgent'),
+  (3742606342, 'SetWebContentsURL'),
+  (4141743926, 'BindPdfNupConverter'),
+  (2935349743, 'BindPdfToPwgRasterConverter'),
+  (3155401641, 'CheckForCancel'),
+  (3245244372, 'DidGetPrintedPagesCount'),
+  (3807390546, 'DidPrintDocument'),
+  (3938784764, 'DidShowPrintDialog'),
+  (108342388, 'GetDefaultPrintSettings'),
+  (978836631, 'IsPrintingEnabled'),
+  (729843971, 'PrintingFailed'),
+  (2101903466, 'RequestPrintPreview'),
+  (560890216, 'ScriptedPrint'),
+  (2621591845, 'SetAccessibilityTree'),
+  (623780099, 'SetupScriptedPrintPreview'),
+  (2667387452, 'ShowScriptedPrintPreview'),
+  (2375707650, 'UpdatePrintSettings'),
+  (3424087580, 'DidGetDefaultPageLayout'),
+  (2878929156, 'DidPrepareDocumentForPreview'),
+  (2091278719, 'DidPreviewPage'),
+  (3251160967, 'DidStartPreview'),
+  (4165947465, 'MetafileReadyForPrinting'),
+  (3290204383, 'PrinterSettingsInvalid'),
+  (1493210943, 'PrintPreviewCancelled'),
+  (2147837003, 'PrintPreviewFailed'),
+  (1860442981, 'SetOptionsFromDocument'),
+  (1063873110, 'ConnectToPdfRenderer'),
+  (90521197, 'InitiatePrintPreview'),
+  (96980383, 'OnPrintPreviewDialogClosed'),
+  (1651161920, 'PrintForSystemDialog'),
+  (3152990719, 'PrintFrameContent'),
+  (3158797774, 'PrintingDone'),
+  (2751195900, 'PrintNodeUnderContextMenu'),
+  (1829006056, 'PrintPreview'),
+  (4267312213, 'PrintRequestedPages'),
+  (632684883, 'PrintWithParams'),
+  (1937721984, 'SetPrintPreviewUI'),
+  (2108256247, 'SnapshotForContentAnalysis'),
+  (1165438097, 'BindBackend'),
+  (2600459349, 'BindBackend'),
+  (1092318502, 'ReportResult'),
+  (1028618809, 'CreateResolver'),
+  (2899276603, 'Alert'),
+  (4152006869, 'OnError'),
+  (4274336804, 'ReportResult'),
+  (2262871693, 'ResolveDns'),
+  (3928665252, 'GetProxyForUrl'),
+  (1575006882, 'Alert'),
+  (1179960025, 'OnError'),
+  (3484071026, 'ReportResult'),
+  (3458112734, 'ResolveDns'),
+  (2875287417, 'GenerateQRCode'),
+  (1048113121, 'QuarantineFile'),
+  (1695765607, 'AccessibilityEventReceived'),
+  (2562524490, 'CreateUntrustedPageHandler'),
+  (1126739717, 'OnCollapseSelection'),
+  (2868332992, 'OnColorChange'),
+  (2542868492, 'OnCopy'),
+  (2688187407, 'OnFontChange'),
+  (3566535138, 'OnFontSizeChange'),
+  (3094545564, 'OnHighlightGranularityChanged'),
+  (2346843265, 'OnLetterSpaceChange'),
+  (531399677, 'OnLineSpaceChange'),
+  (3129597932, 'OnLinkClicked'),
+  (2010672477, 'OnSelectionChange'),
+  (3191579487, 'OnSpeechRateChange'),
+  (636222964, 'OnActiveAXTreeIDChanged'),
+  (3963585172, 'OnAXTreeDestroyed'),
+  (10292851, 'OnSettingsRestoredFromPrefs'),
+  (2613051921, 'OnThemeChanged'),
+  (3982457278, 'ScreenAIServiceReady'),
+  (558420874, 'SetDefaultLanguageCode'),
+  (310005044, 'CurrentPageActionButtonStateChanged'),
+  (2641245398, 'AddCurrentTab'),
+  (2715730258, 'CloseUI'),
+  (278742505, 'CreatePageHandler'),
+  (942162059, 'GetReadLaterEntries'),
+  (3263396732, 'MarkCurrentTabAsRead'),
+  (122920452, 'OpenURL'),
+  (1538215185, 'RemoveEntry'),
+  (4248419571, 'ShowContextMenuForURL'),
+  (2037974439, 'ShowUI'),
+  (4201892525, 'UpdateCurrentPageActionButtonState'),
+  (3435734535, 'UpdateReadStatus'),
+  (2727672577, 'ItemsChanged'),
+  (3076904250, 'DismissTask'),
+  (1559048586, 'GetPrimaryTask'),
+  (3442611666, 'OnRecipeClicked'),
+  (4038732537, 'OnRelatedSearchClicked'),
+  (1703965510, 'RestoreTask'),
+  (1507702115, 'Clone'),
+  (612047425, 'SendWebRequestData'),
+  (3181512135, 'StartPhishingDetection'),
+  (3875402137, 'StartImageEmbedding'),
+  (2741803500, 'ClearScorer'),
+  (117899716, 'SetImageEmbeddingAndPhishingFlatBufferModel'),
+  (3940828042, 'SetPhishingFlatBufferModel'),
+  (3283442638, 'SetTestObserver'),
+  (1845994476, 'PhishingModelUpdated'),
+  (2187947849, 'Clone'),
+  (1095838433, 'CreateCheckerAndCheck'),
+  (2287367719, 'CheckUrl'),
+  (490701328, 'GetThreatDOMDetails'),
+  (3187063712, 'OnCompleteCheck'),
+  (1833396734, 'BindMainContentExtractor'),
+  (4215170427, 'BindAnnotator'),
+  (16035055, 'BindAnnotatorClient'),
+  (3030600069, 'ExtractMainContent'),
+  (3913652830, 'HandleAXTreeUpdate'),
+  (2791697893, 'ExtractSemanticLayout'),
+  (2124545187, 'PerformOcrAndReturnAnnotation'),
+  (1936146161, 'PerformOcrAndReturnAXTreeUpdate'),
+  (23526225, 'InitializeMainContentExtraction'),
+  (3071847983, 'InitializeOCR'),
+  (3788817823, 'DisplayDialog'),
+  (2091583406, 'CreatePageHandler'),
+  (1977757950, 'HandleSearchEngineChoiceSelected'),
+  (1346667505, 'FocusChanged'),
+  (612808177, 'MostVisitedInfoChanged'),
+  (673981471, 'SetInputInProgress'),
+  (2335443599, 'SetPageSequenceNumber'),
+  (3298864706, 'ThemeChanged'),
+  (2537286677, 'Connect'),
+  (3013035414, 'DeleteMostVisitedItem'),
+  (4080960028, 'FocusOmnibox'),
+  (4054166271, 'UndoAllMostVisitedDeletions'),
+  (2975980382, 'UndoMostVisitedDeletion'),
+  (491366215, 'DontProceed'),
+  (976070289, 'DontReport'),
+  (4229536220, 'DoReport'),
+  (3316496180, 'OpenDateSettings'),
+  (2184047664, 'OpenDiagnostic'),
+  (895866819, 'OpenEnhancedProtectionSettings'),
+  (190557553, 'OpenHelpCenter'),
+  (304515587, 'OpenLogin'),
+  (1602660732, 'OpenReportingPrivacy'),
+  (2068708377, 'OpenWhitepaper'),
+  (1385679323, 'Proceed'),
+  (4176864089, 'Reload'),
+  (3277199973, 'ReportPhishingError'),
+  (3771247223, 'ShowMoreSection'),
+  (3793499909, 'ExecuteModel'),
+  (2645381816, 'CreatePageHandler'),
+  (859618120, 'GetServiceStatus'),
+  (1433745826, 'OverwriteResult'),
+  (4125874951, 'SetSelected'),
+  (4050096717, 'OnClientInfoAvailable'),
+  (2383624216, 'OnServiceStatusChanged'),
+  (1296474288, 'BindInterface'),
+  (853225858, 'Clone'),
+  (943541783, 'QueryService'),
+  (4245309870, 'RegisterServiceInstance'),
+  (3447648729, 'WarmService'),
+  (607834802, 'GetInterface'),
+  (2758622000, 'SetPID'),
+  (3151986638, 'RequestQuit'),
+  (3753264550, 'CreatePackagedServiceInstance'),
+  (1177687027, 'AddListener'),
+  (3112920986, 'OnInit'),
+  (2843144799, 'OnServiceCreated'),
+  (2205510077, 'OnServiceFailedToStart'),
+  (3826290106, 'OnServicePIDReceived'),
+  (1398231960, 'OnServiceStarted'),
+  (1838051678, 'OnServiceStopped'),
+  (423149410, 'OnBindInterface'),
+  (4157805402, 'OnStart'),
+  (2474822998, 'Detect'),
+  (572048935, 'CreateBarcodeDetection'),
+  (4266489258, 'EnumerateSupportedFormats'),
+  (4216497584, 'Detect'),
+  (2405491222, 'CreateFaceDetection'),
+  (3633195464, 'BindBarcodeDetectionProvider'),
+  (3405847291, 'BindFaceDetectionProvider'),
+  (3939300232, 'BindTextDetection'),
+  (2616974355, 'Detect'),
+  (2710953988, 'OnProductBookmarkMoved'),
+  (660076124, 'OperationFailedForBookmark'),
+  (2730867766, 'PriceTrackedForBookmark'),
+  (3468130573, 'PriceUntrackedForBookmark'),
+  (330155062, 'CreateShoppingListHandler'),
+  (132056828, 'GetAllPriceTrackedBookmarkProductInfo'),
+  (2412314039, 'GetAllShoppingBookmarkProductInfo'),
+  (4042722319, 'GetParentBookmarkFolderNameForCurrentUrl'),
+  (1877419179, 'GetPriceInsightsInfoForCurrentUrl'),
+  (1588309292, 'GetPriceTrackingStatusForCurrentUrl'),
+  (2489443213, 'GetProductInfoForCurrentUrl'),
+  (542331243, 'GetShoppingCollectionBookmarkFolderId'),
+  (562308977, 'IsShoppingListEligible'),
+  (1342998570, 'OpenUrlInNewTab'),
+  (3696871690, 'SetPriceTrackingStatusForCurrentUrl'),
+  (3542314429, 'ShowBookmarkEditorForCurrentUrl'),
+  (836436386, 'ShowFeedback'),
+  (3426010847, 'ShowInsightsSidePanelUI'),
+  (3117117499, 'TrackPriceForBookmark'),
+  (1669863470, 'UntrackPriceForBookmark'),
+  (117396543, 'BookmarkCurrentTabInFolder'),
+  (2097705110, 'ExecuteAddToBookmarksBarCommand'),
+  (3400740786, 'ExecuteDeleteCommand'),
+  (1505475037, 'ExecuteOpenInIncognitoWindowCommand'),
+  (917356780, 'ExecuteOpenInNewTabCommand'),
+  (2174250779, 'ExecuteOpenInNewTabGroupCommand'),
+  (3717208808, 'ExecuteOpenInNewWindowCommand'),
+  (3601905786, 'ExecuteRemoveFromBookmarksBarCommand'),
+  (136213923, 'CreateBookmarksPageHandler'),
+  (2190726306, 'OpenBookmark'),
+  (1908766139, 'SetSortOrder'),
+  (2429803809, 'SetViewType'),
+  (1524706891, 'ShowContextMenu'),
+  (2239504673, 'ShowUI'),
+  (813281373, 'CreateCompanionPageHandler'),
+  (2121977516, 'OnCqCandidatesAvailable'),
+  (1638382912, 'OnCqJumptagClicked'),
+  (3146997962, 'OnExpsOptInStatusAvailable'),
+  (815496181, 'OnLoadingState'),
+  (1100556757, 'OnOpenInNewTabButtonURLChanged'),
+  (2843227961, 'OnPhFeedback'),
+  (1256720961, 'OnPromoAction'),
+  (2490908140, 'OnRegionSearchClicked'),
+  (546701623, 'OpenUrlInBrowser'),
+  (3117445620, 'RecordUiSurfaceClicked'),
+  (2991145324, 'RecordUiSurfaceShown'),
+  (2984019944, 'RefreshCompanionPage'),
+  (3731340641, 'ShowUI'),
+  (3588356821, 'LoadCompanionPage'),
+  (1310352458, 'NotifyLinkOpen'),
+  (3079821461, 'OnCqFindTextResultsAvailable'),
+  (274092370, 'OnDeviceVisualClassificationResult'),
+  (1418240035, 'OnImageQuery'),
+  (2850319811, 'OnNavigationError'),
+  (3687596506, 'UpdateCompanionPage'),
+  (295567606, 'ChooseLocalCustomBackground'),
+  (1289995268, 'CreatePageHandler'),
+  (2328140328, 'GetBackgroundCollections'),
+  (2005324196, 'GetBackgroundImages'),
+  (4247441957, 'GetDescriptors'),
+  (497476978, 'OpenChromeWebStore'),
+  (4106038800, 'OpenThirdPartyThemePage'),
+  (169505478, 'RemoveBackgroundImage'),
+  (167166673, 'SearchWallpaper'),
+  (451885433, 'SetBackgroundImage'),
+  (592326296, 'SetDailyRefreshCollectionId'),
+  (1846653199, 'SetDefaultColor'),
+  (2116796107, 'SetFollowDeviceTheme'),
+  (612663034, 'SetModuleDisabled'),
+  (3569059480, 'SetModulesVisible'),
+  (2885678948, 'SetMostVisitedSettings'),
+  (2960922034, 'UpdateModulesSettings'),
+  (865029338, 'UpdateMostVisitedSettings'),
+  (1019336926, 'UpdateScrollToSection'),
+  (1114916821, 'UpdateTheme'),
+  (3964732216, 'ScrollToSection'),
+  (1041987429, 'SetModulesSettings'),
+  (758433262, 'SetMostVisitedSettings'),
+  (2992790069, 'SetTheme'),
+  (4270382421, 'CreatePerformancePageHandler'),
+  (1103833200, 'CurrentTabUrlChanged'),
+  (1463384603, 'DeleteNote'),
+  (4143899146, 'DeleteNotesForUrl'),
+  (2413791855, 'CreatePageHandler'),
+  (64843321, 'GetNoteOverviews'),
+  (3515501146, 'GetNotesForCurrentTab'),
+  (348273487, 'HasNotesInAnyPages'),
+  (3867332818, 'NewNoteFinished'),
+  (766978367, 'NoteOverviewSelected'),
+  (3148856968, 'OpenInIncognitoWindow'),
+  (3732724168, 'OpenInNewTab'),
+  (4006422571, 'OpenInNewWindow'),
+  (295541206, 'SetSortOrder'),
+  (773732178, 'ShowUI'),
+  (138539718, 'UpdateNote'),
+  (847607115, 'NotesChanged'),
+  (1536698819, 'SortByNewestPrefChanged'),
+  (3769067945, 'StartNoteCreation'),
+  (3419999300, 'GetSiteEngagementDetails'),
+  (1421478435, 'SetSiteEngagementBaseScoreForUrl'),
+  (3994569335, 'CustomDictionaryChanged'),
+  (2107541360, 'Initialize'),
+  (3071370002, 'CallSpellingService'),
+  (3779747400, 'CheckSpelling'),
+  (1261703913, 'DisconnectSessionBridge'),
+  (810875827, 'FillSuggestionList'),
+  (2205246458, 'NotifyChecked'),
+  (360449165, 'RequestDictionary'),
+  (331690682, 'RequestTextCheck'),
+  (3612134528, 'Read'),
+  (2883876688, 'ReadSideData'),
+  (2936382345, 'Clone'),
+  (1751683883, 'RegisterFromDataItem'),
+  (1460830545, 'RegisterFromMemory'),
+  (918692566, 'WriteBlobToFile'),
+  (3122069357, 'AddObserver'),
+  (2665245739, 'AddReceiver'),
+  (249779574, 'ApplyPolicyUpdates'),
+  (3605823237, 'DeleteForStorageKey'),
+  (2520911266, 'GetAllStorageKeysInfo'),
+  (684693673, 'OnCacheContentChanged'),
+  (2547731182, 'OnCacheListChanged'),
+  (2104640769, 'Clone'),
+  (3728200337, 'CreateDirectory'),
+  (4286109068, 'DeleteFile'),
+  (1103176414, 'DeletePathRecursively'),
+  (3106978048, 'GetEntries'),
+  (2266187572, 'GetFileInfo'),
+  (3240171614, 'GetMaximumPathComponentLength'),
+  (939458606, 'GetPathAccess'),
+  (2765875948, 'LockFile'),
+  (229847589, 'OpenFile'),
+  (3832008737, 'PathExists'),
+  (1132519039, 'RenameFile'),
+  (2203359154, 'SetOpenedFileLength'),
+  (3209169546, 'WriteFileAtomically'),
+  (1120759936, 'Release'),
+  (3806793448, 'Clone'),
+  (2638665468, 'DeserializeHandle'),
+  (2791913083, 'SerializeHandle'),
+  (544003270, 'DownloadBucketData'),
+  (1470774979, 'ForceClose'),
+  (3333135163, 'GetAllBucketsAcrossAllStorageKeys'),
+  (2808565553, 'DisallowInactiveClient'),
+  (1783961091, 'AddObserver'),
+  (1420110709, 'ApplyPolicyUpdates'),
+  (3811527834, 'BindIndexedDB'),
+  (4111529449, 'BindTestInterface'),
+  (741516115, 'DeleteForStorageKey'),
+  (256226543, 'DownloadBucketData'),
+  (2689134690, 'ForceClose'),
+  (2494229310, 'GetAllBucketsDetails'),
+  (3536357852, 'GetConnectionCount'),
+  (2648083412, 'GetUsage'),
+  (1553722402, 'SetForceKeepSessionState'),
+  (4071979625, 'BindMockFailureSingletonForTesting'),
+  (3331034945, 'CompactBackingStoreForTesting'),
+  (4083506781, 'ForceInitializeFromFilesForTesting'),
+  (453441748, 'ForceSchemaDowngradeForTesting'),
+  (954059770, 'GetBaseDataPathForTesting'),
+  (1004585338, 'GetBlobCountForTesting'),
+  (971454839, 'GetDatabaseKeysForTesting'),
+  (1987878844, 'GetFilePathForTesting'),
+  (2939259485, 'GetNextBlobNumberForTesting'),
+  (3509954011, 'GetPathForBlobForTesting'),
+  (3559127864, 'HasV2SchemaCorruptionForTesting'),
+  (3408671134, 'ResetCachesForTesting'),
+  (4180561908, 'WriteToIndexedDBForTesting'),
+  (973838763, 'OnIndexedDBContentChanged'),
+  (903630399, 'OnIndexedDBListChanged'),
+  (770053353, 'ApplyPolicyUpdates'),
+  (3243358266, 'BindStorageArea'),
+  (928689101, 'CleanUpStorage'),
+  (1500028720, 'DeleteStorage'),
+  (3224253673, 'Flush'),
+  (1550208571, 'ForceKeepSessionState'),
+  (192462296, 'GetUsage'),
+  (2435333465, 'PurgeMemory'),
+  (1626732664, 'FailOperation'),
+  (795176948, 'BindLocalStorageControl'),
+  (421591947, 'BindOriginContext'),
+  (3098393670, 'BindServiceWorkerStorageControl'),
+  (1667309494, 'BindSessionStorageControl'),
+  (3189753532, 'DeleteBucketData'),
+  (1543861700, 'GetBucketUsage'),
+  (3761517054, 'GetStorageKeysForType'),
+  (3574721651, 'PerformStorageCleanup'),
+  (2489930612, 'GetDiskAvailabilityAndTempPoolSize'),
+  (1153747246, 'GetGlobalUsageForInternals'),
+  (2775942055, 'GetStatistics'),
+  (1438672772, 'IsSimulateStoragePressureAvailable'),
+  (679974687, 'RetrieveBucketsTable'),
+  (1177801303, 'SimulateStoragePressure'),
+  (373866699, 'OnCreateOrUpdateBucket'),
+  (2154372539, 'OnDeleteBucket'),
+  (3304877294, 'WriteMetadata'),
+  (3592736145, 'PrepareReadData'),
+  (3679074493, 'ReadData'),
+  (3262105699, 'ReadResponseHead'),
+  (3470504599, 'WriteData'),
+  (1141737354, 'WriteResponseHead'),
+  (812354185, 'ApplyPolicyUpdates'),
+  (457822060, 'ClearUserData'),
+  (242249281, 'ClearUserDataByKeyPrefixes'),
+  (2865457709, 'ClearUserDataForAllRegistrationsByKeyPrefix'),
+  (562923033, 'CreateResourceMetadataWriter'),
+  (2733290810, 'CreateResourceReader'),
+  (3424350648, 'CreateResourceWriter'),
+  (923321490, 'Delete'),
+  (2973257536, 'DeleteRegistration'),
+  (3075594260, 'Disable'),
+  (3234395557, 'DoomUncommittedResources'),
+  (1048611517, 'FindRegistrationForClientUrl'),
+  (290523284, 'FindRegistrationForId'),
+  (2439838707, 'FindRegistrationForScope'),
+  (2522616582, 'GetAllRegistrationsDeprecated'),
+  (3464077199, 'GetNewRegistrationId'),
+  (2417417071, 'GetNewResourceId'),
+  (4175798098, 'GetNewVersionId'),
+  (3336235321, 'GetPurgeableResourceIdsForTest'),
+  (3893347314, 'GetPurgingResourceIdsForLiveVersionForTest'),
+  (501738571, 'GetPurgingResourceIdsForTest'),
+  (925298523, 'GetRegisteredStorageKeys'),
+  (1783616662, 'GetRegistrationsForStorageKey'),
+  (3335081475, 'GetUncommittedResourceIdsForTest'),
+  (3499350716, 'GetUsageForStorageKey'),
+  (2094445486, 'GetUserData'),
+  (1084148838, 'GetUserDataByKeyPrefix'),
+  (579428968, 'GetUserDataForAllRegistrations'),
+  (2655916495, 'GetUserDataForAllRegistrationsByKeyPrefix'),
+  (3743330318, 'GetUserKeysAndDataByKeyPrefix'),
+  (1760093014, 'PerformStorageCleanup'),
+  (3740810883, 'Recover'),
+  (1277474203, 'SetPurgingCompleteCallbackForTest'),
+  (611273669, 'StoreRegistration'),
+  (512992416, 'StoreUncommittedResourceId'),
+  (2590934960, 'StoreUserData'),
+  (3918662723, 'UpdateFetchHandlerType'),
+  (1795062665, 'UpdateLastUpdateCheckTime'),
+  (1739813691, 'UpdateNavigationPreloadEnabled'),
+  (1925157736, 'UpdateNavigationPreloadHeader'),
+  (2685920552, 'UpdateResourceSha256Checksums'),
+  (1027987773, 'UpdateToActiveState'),
+  (2928478137, 'BindNamespace'),
+  (4218322511, 'BindStorageArea'),
+  (2790551519, 'CleanUpStorage'),
+  (187642727, 'CloneNamespace'),
+  (618253076, 'CreateNamespace'),
+  (2237893792, 'DeleteNamespace'),
+  (2861042027, 'DeleteStorage'),
+  (2106177501, 'Flush'),
+  (812983233, 'GetUsage'),
+  (3289852865, 'PurgeMemory'),
+  (542991274, 'ScavengeUnusedNamespaces'),
+  (383466206, 'BindPartition'),
+  (2315367181, 'BindTestApi'),
+  (669808064, 'EnableAggressiveDomStorageFlushing'),
+  (1314164899, 'SetDataDirectory'),
+  (231421941, 'ActivateForNextCommittedLoad'),
+  (3601385976, 'AdScriptDidCreateFencedFrame'),
+  (3118262848, 'DidDisallowFirstSubresource'),
+  (1985742603, 'FrameIsAd'),
+  (2876038201, 'FrameWasCreatedByAdScript'),
+  (3122616860, 'OnAdsViolationTriggered'),
+  (1876708822, 'SetDocumentLoadStatistics'),
+  (4074661662, 'SetRulesetForProcess'),
+  (3731102674, 'HardcodeResponse'),
+  (1093520376, 'SetPage'),
+  (4160944138, 'OnSuggestRequestCompleted'),
+  (4231384495, 'OnSuggestRequestCreated'),
+  (1233680417, 'OnSuggestRequestStarted'),
+  (4104165781, 'GoBack'),
+  (1149860522, 'RequestUrlAccessLocal'),
+  (406379833, 'RequestUrlAccessRemote'),
+  (265479742, 'CloseTab'),
+  (3022661207, 'CreatePageHandler'),
+  (254947418, 'GetProfileData'),
+  (1152769914, 'OpenRecentlyClosedEntry'),
+  (2720551010, 'RequestTabOrganization'),
+  (249043039, 'SaveRecentlyClosedExpandedPref'),
+  (3668969010, 'ShowUI'),
+  (1412245215, 'SwitchToTab'),
+  (284473697, 'TabsChanged'),
+  (3497850197, 'TabsRemoved'),
+  (1883215918, 'TabUpdated'),
+  (995452707, 'ContextMenuClosed'),
+  (1968347798, 'ActivateTab'),
+  (2398850642, 'CloseContainer'),
+  (3940986388, 'CloseTab'),
+  (3873382283, 'CreatePageHandler'),
+  (2417789000, 'GetGroupVisualData'),
+  (2822955849, 'GetLayout'),
+  (544702901, 'GetTabs'),
+  (234490089, 'GroupTab'),
+  (4286872344, 'MoveGroup'),
+  (3897315017, 'MoveTab'),
+  (892602101, 'ReportTabActivationDuration'),
+  (3318128384, 'ReportTabCreationDuration'),
+  (1398034242, 'ReportTabDataReceivedDuration'),
+  (2659156567, 'SetThumbnailTracked'),
+  (489844777, 'ShowBackgroundContextMenu'),
+  (3616915654, 'ShowEditDialogForGroup'),
+  (1261636232, 'ShowTabContextMenu'),
+  (1305768566, 'UngroupTab'),
+  (937200005, 'LayoutChanged'),
+  (1215301448, 'LongPress'),
+  (2484877656, 'ReceivedKeyboardFocus'),
+  (1703663376, 'ShowContextMenu'),
+  (4067688112, 'TabActiveChanged'),
+  (129149700, 'TabCloseCancelled'),
+  (813965639, 'TabCreated'),
+  (3876181084, 'TabGroupClosed'),
+  (2278955311, 'TabGroupMoved'),
+  (2376084975, 'TabGroupStateChanged'),
+  (2418197263, 'TabGroupVisualsChanged'),
+  (397046958, 'TabMoved'),
+  (728881089, 'TabRemoved'),
+  (2174026760, 'TabReplaced'),
+  (565491418, 'TabThumbnailUpdated'),
+  (4094192498, 'TabUpdated'),
+  (758622449, 'ThemeChanged'),
+  (233750065, 'SetTheme'),
+  (3981051312, 'CreateThemeColorPickerHandler'),
+  (239220930, 'GetChromeColors'),
+  (1269281134, 'RemoveBackgroundImage'),
+  (1668636249, 'SetDefaultColor'),
+  (3376430986, 'SetGreyDefaultColor'),
+  (879229899, 'SetSeedColor'),
+  (102293738, 'SetSeedColorFromHue'),
+  (2860616290, 'UpdateTheme'),
+  (2485692809, 'DeleteAllTraces'),
+  (1771037757, 'DeleteSingleTrace'),
+  (726756454, 'DownloadTrace'),
+  (2945943736, 'GetAllTraceReports'),
+  (3629348098, 'UserUploadSingleTrace'),
+  (4270277780, 'CreatePageHandler'),
+  (2743780483, 'ClearUMACallback'),
+  (1914842064, 'OnInitialized'),
+  (3910369060, 'OnTriggerBackgroundTrace'),
+  (2376398837, 'Create'),
+  (4171116130, 'SetUMACallback'),
+  (1322355286, 'EnableTracing'),
+  (3821615380, 'ConnectToProducerHost'),
+  (1884113734, 'ClearIncrementalState'),
+  (3404648402, 'Flush'),
+  (2964700609, 'OnTracingStart'),
+  (1377057286, 'StartDataSource'),
+  (3526922743, 'StopDataSource'),
+  (2180696659, 'CommitData'),
+  (1567334432, 'RegisterDataSource'),
+  (3013694824, 'RegisterTraceWriter'),
+  (331808460, 'UnregisterTraceWriter'),
+  (2029855293, 'OpenProducerSocket'),
+  (2621133919, 'ConnectToTracingService'),
+  (2713683366, 'AddClient'),
+  (77590241, 'BindConsumerHost'),
+  (1509401225, 'Initialize'),
+  (1108668766, 'OnTracingDisabled'),
+  (1158953003, 'OnTracingEnabled'),
+  (221202494, 'ChangeTraceConfig'),
+  (4038560164, 'DisableTracing'),
+  (586408553, 'DisableTracingAndEmitJson'),
+  (1661368664, 'ReadBuffers'),
+  (167101205, 'RequestBufferUsage'),
+  (1436894345, 'GetLanguageDetectionModel'),
+  (2100873752, 'RegisterPage'),
+  (2929122631, 'RevertTranslation'),
+  (2580454734, 'TranslateFrame'),
+  (3583525221, 'GetProperty'),
+  (2146196869, 'ListDevices'),
+  (3286139892, 'ListProperties'),
+  (1099515772, 'SetProperty'),
+  (3920469653, 'Initialize'),
+  (1056359488, 'OnPresentation'),
+  (2553971524, 'OnSubmission'),
+  (585201032, 'CommitOverlays'),
+  (3049077189, 'CreateDmabufBasedBuffer'),
+  (1212929378, 'CreateShmBasedBuffer'),
+  (3801292086, 'CreateSinglePixelBuffer'),
+  (2997202887, 'CreateSolidColorBuffer'),
+  (2550846531, 'DestroyBuffer'),
+  (3362633907, 'SetWaylandBufferManagerGpu'),
+  (142806477, 'Submit'),
+  (4251523639, 'SetParameters'),
+  (800289624, 'CreateUkmRecorder'),
+  (1330960522, 'AddEntry'),
+  (29591844, 'UpdateSourceURL'),
+  (770478239, 'ShouldUnzipFile'),
+  (449594740, 'OnProgress'),
+  (3906131485, 'DetectEncoding'),
+  (3473602471, 'GetExtractedInfo'),
+  (4023636610, 'Unzip'),
+  (2309310900, 'GetPhotoState'),
+  (1431011178, 'MaybeSuspend'),
+  (56362179, 'ProcessFeedback'),
+  (2277534784, 'RequestRefreshFrame'),
+  (3419370163, 'Resume'),
+  (3429015350, 'OnDevicesChanged'),
+  (1709134853, 'SetPhotoOptions'),
+  (611931685, 'Start'),
+  (3926263322, 'TakePhoto'),
+  (464532978, 'OnBufferRetired'),
+  (3094230371, 'OnFrameAccessHandlerReady'),
+  (3027328573, 'OnFrameReadyInBuffer'),
+  (3255969508, 'OnNewGpuMemoryBufferHandle'),
+  (1692870763, 'OnBufferRetired'),
+  (2621079165, 'OnNewBuffer'),
+  (1905054890, 'Activate'),
+  (89347029, 'Close'),
+  (2997832278, 'GetPhotoState'),
+  (3163244296, 'ProcessFeedback'),
+  (843559777, 'Resume'),
+  (3044553452, 'SetPhotoOptions'),
+  (270110299, 'Suspend'),
+  (26264479, 'TakePhoto'),
+  (1685796424, 'OnFrameReadyInBuffer'),
+  (4057877345, 'RequestFrameBuffer'),
+  (1075247717, 'Crash'),
+  (1578357967, 'OnBufferRetired'),
+  (4165815590, 'OnFrameAccessHandlerReady'),
+  (1194188522, 'OnFrameReadyInBuffer'),
+  (2525353118, 'OnNewMailboxHolderBufferHandle'),
+  (2652765737, 'BindControlsForTesting'),
+  (1725600148, 'ConnectToVideoSourceProvider'),
+  (960348194, 'OnConfigurationChanged'),
+  (2129685475, 'AddObserver'),
+  (659804863, 'GetConfiguration'),
+  (141295053, 'SetConfiguration'),
+  (1661129286, 'OnFinishedConsumingBuffer'),
+  (1652500193, 'OnBufferRetired'),
+  (2038145533, 'OnCaptureConfigurationChanged'),
+  (3789824940, 'OnError'),
+  (1422537559, 'OnFrameAccessHandlerReady'),
+  (1865024339, 'OnFrameDropped'),
+  (320244199, 'OnFrameReadyInBuffer'),
+  (2768221364, 'OnFrameWithEmptyRegionCapture'),
+  (98763253, 'OnLog'),
+  (1907120964, 'OnNewBuffer'),
+  (3153384193, 'OnNewCropVersion'),
+  (2655133419, 'OnStarted'),
+  (3970011098, 'OnStartedUsingGpuDecode'),
+  (4168708326, 'OnStopped'),
+  (3690374846, 'CreatePushSubscription'),
+  (4225179877, 'AddSharedMemoryVirtualDevice'),
+  (3669909670, 'AddTextureVirtualDevice'),
+  (2317125463, 'Close'),
+  (2533442523, 'GetSourceInfos'),
+  (3242420511, 'GetVideoSource'),
+  (3017220371, 'RegisterDevicesChangedObserver'),
+  (1353203498, 'RegisterVirtualDevicesChangedObserver'),
+  (2792362269, 'RegisterVideoEffectsManager'),
+  (1476780830, 'AddVisitedLinks'),
+  (3339905516, 'ResetVisitedLinks'),
+  (1212529690, 'UpdateVisitedLinks'),
+  (2365631060, 'OnStandaloneBeginFrame'),
+  (2717964073, 'AddCompositingModeWatcher'),
+  (3290647081, 'CompositingModeFallbackToSoftware'),
+  (2707448288, 'BindLayerContext'),
+  (713406245, 'DidReceiveCompositorFrameAck'),
+  (3114070324, 'OnBeginFrame'),
+  (50871626, 'OnBeginFramePausedChanged'),
+  (3087826834, 'OnCompositorFrameTransitionDirectiveProcessed'),
+  (2504664826, 'ReclaimResources'),
+  (1696003947, 'DidAllocateSharedBitmap'),
+  (3766451482, 'DidDeleteSharedBitmap'),
+  (3089589715, 'DidNotProduceFrame'),
+  (3552565381, 'InitializeCompositorFrameSinkType'),
+  (516038020, 'SetAutoNeedsBeginFrame'),
+  (1654984935, 'SetNeedsBeginFrame'),
+  (2419025018, 'SetThreadIds'),
+  (978715407, 'SetWantsAnimateOnlyBeginFrames'),
+  (3508370506, 'SetWantsBeginFrameAcks'),
+  (1797539858, 'SubmitCompositorFrame'),
+  (347160666, 'SubmitCompositorFrameSync'),
+  (3270490113, 'SendResult'),
+  (1206845944, 'DidCompleteSwapWithNewSize'),
+  (1343668400, 'DidCompleteSwapWithSize'),
+  (1065001730, 'OnContextCreationResult'),
+  (4283806957, 'SetPreferredRefreshRate'),
+  (2140720235, 'SetWideColorEnabled'),
+  (2110170589, 'AddVSyncParameterObserver'),
+  (4110172676, 'ForceImmediateDrawAndSwapIfPossible'),
+  (3734041415, 'PreserveChildSurfaceControls'),
+  (4118009111, 'Resize'),
+  (158950973, 'SetDelegatedInkPointRenderer'),
+  (582496174, 'SetDisplayColorMatrix'),
+  (542635046, 'SetDisplayColorSpaces'),
+  (668347700, 'SetDisplayVisible'),
+  (2315758523, 'SetDisplayVSyncParameters'),
+  (361783844, 'SetMaxVrrInterval'),
+  (744999618, 'SetOutputIsSecure'),
+  (2164991562, 'SetStandaloneBeginFrameObserver'),
+  (3462131719, 'SetSupportedRefreshRates'),
+  (2269903183, 'SetSwapCompletionCallbackEnabled'),
+  (2540550679, 'SetVSyncPaused'),
+  (2806047995, 'UpdateRefreshRate'),
+  (3227545229, 'IssueExternalBeginFrame'),
+  (134332553, 'FlushNotifications'),
+  (3346943791, 'OnBeginFramePausedChanged'),
+  (2231383998, 'OnCompositorFrameTransitionDirectiveProcessed'),
+  (1812075750, 'DidAllocateSharedBitmap'),
+  (1796158583, 'InitializeCompositorFrameSinkType'),
+  (1584032579, 'SetNeedsBeginFrame'),
+  (638707167, 'SetThreadIds'),
+  (4047538051, 'Submit'),
+  (1392378602, 'AddVideoDetectorObserver'),
+  (111580641, 'CacheBackBuffer'),
+  (1534747569, 'OnAggregatedHitTestRegionListUpdated'),
+  (2694988951, 'OnFirstSurfaceActivation'),
+  (532012934, 'OnFrameTokenChanged'),
+  (3339073283, 'CreateCompositorFrameSink'),
+  (3291280578, 'CreateFrameSinkBundle'),
+  (2998502914, 'CreateRootCompositorFrameSink'),
+  (1293663699, 'CreateVideoCapturer'),
+  (1741400875, 'DestroyCompositorFrameSink'),
+  (2353002391, 'EvictBackBuffer'),
+  (1181536863, 'EvictSurfaces'),
+  (905910854, 'InvalidateFrameSinkId'),
+  (2505019909, 'RegisterFrameSinkHierarchy'),
+  (540319294, 'RegisterFrameSinkId'),
+  (1287673356, 'RequestCopyOfOutput'),
+  (1778103049, 'SetFrameSinkDebugLabel'),
+  (671054398, 'StartFrameCountingForTest'),
+  (2526832472, 'StartThrottlingAllFrameSinks'),
+  (2622430390, 'StopFrameCountingForTest'),
+  (1373707747, 'StopThrottlingAllFrameSinks'),
+  (2907592395, 'Throttle'),
+  (1630150791, 'UnregisterFrameSinkHierarchy'),
+  (1152427829, 'UpdateDebugRendererSettings'),
+  (3333791077, 'SetBounds'),
+  (3755455144, 'SetImageAndBounds'),
+  (788104206, 'ChangeTarget'),
+  (1184903699, 'CreateOverlay'),
+  (4098504588, 'RequestRefreshFrame'),
+  (175618446, 'SetAutoThrottlingEnabled'),
+  (2851312518, 'SetFormat'),
+  (1734092316, 'SetMinCapturePeriod'),
+  (4184346730, 'SetMinSizeChangePeriod'),
+  (790533729, 'SetResolutionConstraints'),
+  (2504488549, 'Start'),
+  (3098717306, 'Stop'),
+  (3272901181, 'Done'),
+  (1390560585, 'ProvideFeedback'),
+  (1585099510, 'OnFrameCaptured'),
+  (54884120, 'OnFrameWithEmptyRegionCapture'),
+  (757116579, 'OnLog'),
+  (1065098373, 'OnNewCropVersion'),
+  (1253064494, 'OnStopped'),
+  (1044755569, 'CreateClientGpuMemoryBufferFactory'),
+  (3712695328, 'CreateGpuMemoryBufferFactory'),
+  (3190802209, 'CreateVideoEncodeAcceleratorProvider'),
+  (3487411075, 'EstablishGpuChannel'),
+  (4264056690, 'DidCreateContextSuccessfully'),
+  (2261948180, 'DidCreateOffscreenContext'),
+  (3609887574, 'DidDestroyAllChannels'),
+  (749646116, 'DidDestroyChannel'),
+  (3584884912, 'DidDestroyOffscreenContext'),
+  (1421156420, 'DidFailInitialize'),
+  (2521933190, 'DidInitialize'),
+  (4203949973, 'DidLoseContext'),
+  (3800880659, 'DidUpdateGPUInfo'),
+  (3242863442, 'DisableGpuCompositing'),
+  (2149738577, 'GetIsolationKey'),
+  (1228387173, 'RecordLogMessage'),
+  (1292371055, 'StoreBlobToDisk'),
+  (2185532637, 'CopyGpuMemoryBuffer'),
+  (2289352354, 'CreateGpuMemoryBuffer'),
+  (2324953988, 'DestroyGpuMemoryBuffer'),
+  (1201405379, 'BindClientGmbInterface'),
+  (3964066509, 'BindWebNNContextProvider'),
+  (1537854555, 'CloseChannel'),
+  (2495631854, 'CopyGpuMemoryBuffer'),
+  (2423729286, 'Crash'),
+  (1196671941, 'CreateGpuMemoryBuffer'),
+  (2270160688, 'CreateVideoEncodeAcceleratorProvider'),
+  (233391335, 'DestroyAllChannels'),
+  (2786938706, 'DestroyGpuMemoryBuffer'),
+  (4035597164, 'DisplayAdded'),
+  (1269448151, 'DisplayMetricsChanged'),
+  (2133247170, 'DisplayRemoved'),
+  (1707191269, 'EstablishGpuChannel'),
+  (4260156116, 'GetDawnInfo'),
+  (3002350734, 'GetPeakMemoryUsage'),
+  (2188457759, 'GetVideoMemoryUsageStats'),
+  (2523781471, 'GpuSwitched'),
+  (3955825446, 'Hang'),
+  (2609565448, 'LoadedBlob'),
+  (3493737943, 'OnBackgroundCleanup'),
+  (1884766844, 'OnBackgrounded'),
+  (3410099514, 'OnDiskCacheHandleDestoyed'),
+  (2287770334, 'OnForegrounded'),
+  (2511119447, 'OnMemoryPressure'),
+  (3341479994, 'SetChannelClientPid'),
+  (2975339890, 'SetChannelDiskCacheHandle'),
+  (956579994, 'StartPeakMemoryMonitor'),
+  (617515799, 'ThrowJavaException'),
+  (4281484097, 'WakeUpGpu'),
+  (1835611593, 'FrameSinkIdAt'),
+  (785851047, 'OnRequestCommitForFrame'),
+  (3175862253, 'Commit'),
+  (3388727046, 'SetTargetLocalSurfaceId'),
+  (1118574166, 'SetVisible'),
+  (3807393789, 'Draw'),
+  (1031710566, 'OnAllocatedSharedMemory'),
+  (4284455547, 'Release'),
+  (599316834, 'OnVideoActivityEnded'),
+  (675484779, 'OnVideoActivityStarted'),
+  (3299984662, 'LogFrame'),
+  (3820868381, 'CreateFrameSinkManager'),
+  (324218130, 'CreateGpuService'),
+  (2107471541, 'FilterDebugStream'),
+  (791775997, 'SetHostProcessId'),
+  (435554984, 'StartDebugStream'),
+  (1108658665, 'StopDebugStream'),
+  (1985830557, 'OnUpdateVSyncParameters'),
+  (3297537290, 'ParseWebAppOriginAssociation'),
+  (2308158392, 'GetWebPageMetadata'),
+  (2380044859, 'ClearCache'),
+  (1534025918, 'CreateGraph'),
+  (1216028690, 'CreateWebNNContext'),
+  (3700539943, 'Compute'),
+  (3753417770, 'Close'),
+  (1827191881, 'IsRandomAccessContext'),
+  (1829894592, 'Length'),
+  (475147151, 'Read'),
+  (3292100721, 'Close'),
+  (421140152, 'BindFileDataSource'),
+  (490773084, 'GetParserForDataSource'),
+  (3022326894, 'ParseIntegrityBlock'),
+  (2413391439, 'ParseMetadata'),
+  (1063256464, 'ParseResponse'),
+  (4162104867, 'GetActiveRuntimes'),
+  (583651156, 'GetDeviceInfo'),
+  (3767960474, 'SubscribeToEvents'),
+  (298806224, 'LogXrRuntimeAdded'),
+  (3871204958, 'LogXrRuntimeRemoved'),
+  (1744629979, 'LogXrSessionRejected'),
+  (2587538796, 'LogXrSessionRequested'),
+  (2648824707, 'LogXrSessionStarted'),
+  (4106291989, 'LogXrSessionStopped'),
+  (3257827393, 'GetReadonlyPnaclFD'),
+  (189266238, 'LaunchNaCl'),
+  (2493980426, 'MissingArchError'),
+  (3816661981, 'NaClCreateTemporaryFile'),
+  (1827118346, 'NaClDebugEnabledForURL'),
+  (2627181932, 'NaClGetNumProcessors'),
+  (2301773727, 'NexeTempFileRequest'),
+  (1520436140, 'OpenNaClExecutable'),
+  (758635942, 'ReportTranslationFinished'),
+  (3559583707, 'DebugStubPortSelected'),
+  (974800768, 'PpapiChannelsCreated'),
+  (2661914408, 'AddPrefetchedResource'),
+  (761610407, 'AttachDebugExceptionHandler'),
+  (1809029411, 'QueryKnownToValidate'),
+  (3372734512, 'ResolveFileToken'),
+  (669433170, 'ResolveFileTokenReply'),
+  (792459192, 'SetKnownToValidate'),
+  (3502693610, 'Start'),
+  (3349102147, 'NexeTempFileReply'),
+  (115210396, 'AttachToPendingHost'),
+  (2892195420, 'ChannelCreated'),
+  (859828756, 'CreateResourceHostsFromHost'),
+  (721600275, 'CreateResourceHostsFromHostReply'),
+  (2466856245, 'InProcessResourceCall'),
+  (733814426, 'LogWithSource'),
+  (254389137, 'OpenResource'),
+  (3134025041, 'Create'),
+  (4035869130, 'StartOrStop'),
+  (2999923984, 'Create'),
+  (1137083249, 'AddRefResource'),
+  (2917411600, 'ReleaseResource'),
+  (2239102386, 'AsyncFlush'),
+  (3722894934, 'Create'),
+  (3592687800, 'CreateTransferBuffer'),
+  (2274536714, 'DestroyTransferBuffer'),
+  (584071741, 'EnsureWorkVisible'),
+  (3625276845, 'Resize'),
+  (55992442, 'ResolveAndDetachFramebuffer'),
+  (3517514264, 'SetGetBuffer'),
+  (2631204680, 'SwapBuffers'),
+  (1978839658, 'WaitForGetOffsetInRange'),
+  (3215642061, 'WaitForTokenInRange'),
+  (451650319, 'CreatePlatform'),
+  (917589725, 'CreateSimple'),
+  (3925410423, 'BindGraphics'),
+  (2097098386, 'CancelCompositionText'),
+  (2665815867, 'ClearInputEvents'),
+  (969354986, 'DocumentCanAccessDocument'),
+  (1561313519, 'DocumentCanRequest'),
+  (3136397048, 'ExecuteScript'),
+  (4160849198, 'GetAudioHardwareOutputBufferSize'),
+  (1586736956, 'GetAudioHardwareOutputSampleRate'),
+  (248132507, 'GetDefaultCharSet'),
+  (2221063094, 'GetDocumentURL'),
+  (209684956, 'GetOwnerElementObject'),
+  (445839673, 'GetPluginInstanceURL'),
+  (3080990218, 'GetPluginReferrerURL'),
+  (33196016, 'GetScreenSize'),
+  (1794714966, 'GetWindowObject'),
+  (4098846847, 'IsFullFrame'),
+  (3923158956, 'LockMouse'),
+  (126814075, 'PostMessage'),
+  (1114074215, 'RequestInputEvents'),
+  (1286223657, 'ResolveRelativeToDocument'),
+  (1124272340, 'SetCursor'),
+  (3131712123, 'SetFullscreen'),
+  (3510729160, 'SetTextInputType'),
+  (112108394, 'UnlockMouse'),
+  (712008392, 'UpdateCaretPosition'),
+  (1252758564, 'UpdateSurroundingText'),
+  (3468816333, 'GetLiveObjectsForInstance'),
+  (1385596787, 'ReadImageData'),
+  (124069155, 'SetMinimumArrayBufferSizeForShmem'),
+  (2125744475, 'SimulateInputEvent'),
+  (1037179738, 'AddRefObject'),
+  (920324834, 'CallDeprecated'),
+  (3587765713, 'Construct'),
+  (1548954672, 'CreateObjectDeprecated'),
+  (717350681, 'DeleteProperty'),
+  (2442301854, 'EnumerateProperties'),
+  (3661301269, 'GetProperty'),
+  (4282023271, 'HasMethodDeprecated'),
+  (1659952851, 'HasProperty'),
+  (988557772, 'IsInstanceOfDeprecated'),
+  (2542093581, 'ReleaseObject'),
+  (4280509663, 'SetPropertyDeprecated'),
+  (1028828577, 'AssignPictureBuffers'),
+  (1777414875, 'Create'),
+  (4251629445, 'Decode'),
+  (3562505503, 'Destroy'),
+  (1654039353, 'Flush'),
+  (3987303578, 'Reset'),
+  (3996615960, 'ReusePictureBuffer'),
+  (389653201, 'ResourceCall'),
+  (3480231979, 'ResourceCreated'),
+  (3849183607, 'ResourceDestroyed'),
+  (4280880872, 'ResourceSyncCall'),
+  (62279235, 'CreateSharedMemory'),
+  (29267529, 'StartupInitializationComplete'),
+  (685064852, 'CreateChannel'),
+  (2973675606, 'InitializeNaClDispatcher'),
+  (233694040, 'LoadPlugin'),
+  (3217280728, 'PnaclTranslatorCompileChunk'),
+  (2665052240, 'PnaclTranslatorCompileEnd'),
+  (625263382, 'PnaclTranslatorCompileInit'),
+  (1709803022, 'PnaclTranslatorLink'),
+  (44261960, 'NotifyAudioStreamCreated'),
+  (1744536867, 'SwapBuffersACK'),
+  (3659760475, 'NotifyUnusedImageData'),
+  (2952049889, 'MouseLockComplete'),
+  (1483635848, 'EndOfBitstreamACK'),
+  (684937880, 'FlushACK'),
+  (1133730204, 'ResetACK'),
+  (1334228998, 'Call'),
+  (3677730140, 'Construct'),
+  (3360069140, 'Deallocate'),
+  (3539354244, 'EnumerateProperties'),
+  (1261483682, 'GetProperty'),
+  (1784946360, 'HasMethod'),
+  (337732267, 'HasProperty'),
+  (1549780111, 'SetProperty'),
+  (2095455942, 'ContextLost'),
+  (166548113, 'HandleFilteredInputEvent'),
+  (3548359980, 'HandleInputEvent'),
+  (1609871213, 'DidChangeFocus'),
+  (1534441462, 'DidChangeView'),
+  (2995133311, 'DidCreate'),
+  (1089948162, 'DidDestroy'),
+  (340472842, 'HandleDocumentLoad'),
+  (2867160296, 'GetInstanceObject'),
+  (2275538399, 'HandleBlockingMessage'),
+  (3386551988, 'HandleMessage'),
+  (4150213489, 'MouseLockLost'),
+  (665129779, 'Begin'),
+  (2910806542, 'End'),
+  (103088570, 'IsScalingDisabled'),
+  (3454569422, 'PrintPages'),
+  (1772360703, 'QuerySupportedFormats'),
+  (995053992, 'RequestSurroundingText'),
+  (3096414596, 'DismissPictureBuffer'),
+  (3670943749, 'NotifyError'),
+  (4048340455, 'PictureReady'),
+  (869731839, 'ProvidePictureBuffers'),
+  (167173222, 'ReserveInstanceId'),
+  (2885368392, 'SetNetworkState'),
+  (1756852224, 'SetPreferences'),
+  (1981698804, 'SupportsInterface'),
+  (1081205815, 'ResourceReply');
+
+DROP INDEX IF EXISTS mojo_ipc_hash_idx;
+
+CREATE
+  UNIQUE INDEX mojo_ipc_hash_idx
+ON mojo_ipc_hash(ipc_hash);
+
+DROP VIEW IF EXISTS mojo_in;
+
+CREATE VIEW mojo_in
+AS
+WITH
+  mojo_receive AS (
+    SELECT id, ts, arg_set_id, "message" AS type
+    FROM
+      slice
+    WHERE
+      name = "Receive mojo message" AND category GLOB '*toplevel*'
+    UNION ALL
+    SELECT id, ts, arg_set_id, "message" AS type
+    FROM
+      slice
+    WHERE
+      name = "Receive mojo reply" AND category GLOB '*toplevel*'
+  )
+SELECT
+  coalesce(send.ts, recv.ts) AS ts,
+  0 AS dur,
+  EXTRACT_ARG(recv.arg_set_id, "chrome_mojo_event_info.mojo_interface_tag") AS interface_name,
+  EXTRACT_ARG(recv.arg_set_id, "chrome_mojo_event_info.ipc_hash") AS ipc_hash,
+  recv.type
+FROM
+  mojo_receive AS recv
+LEFT JOIN
+  flow
+  ON flow.slice_in = recv.id
+LEFT JOIN
+  slice AS send
+  ON flow.slice_out = send.id
+WHERE send.name = "Send mojo message";
+
+DROP TABLE IF EXISTS mojo_span;
+
+CREATE VIRTUAL TABLE mojo_span
+USING
+  SPAN_JOIN(mojo_in, interesting_interval);
+
+DROP VIEW IF EXISTS mojo_metric;
+
+CREATE VIEW mojo_metric
+AS
+SELECT interval_id, interface_name, method_name, type, ipc_hash, COUNT(*) AS count
+FROM mojo_span
+LEFT JOIN mojo_ipc_hash
+  USING (ipc_hash)
+GROUP BY interval_id, interface_name, method_name, type, ipc_hash;
+
+SELECT * FROM mojo_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/resources.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/resources.sql
new file mode 100644
index 0000000..2ae2ce0
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/resources.sql
@@ -0,0 +1,71 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS resource_metric;
+
+CREATE VIEW resource_metric
+AS
+WITH
+  request AS (
+    SELECT
+      EXTRACT_ARG(arg_set_id, 'debug.data.requestId') AS id,
+      EXTRACT_ARG(arg_set_id, 'debug.data.url') AS url,
+      ts
+    FROM slice
+    WHERE name = 'ResourceSendRequest'
+  ),
+  response AS (
+    SELECT
+      EXTRACT_ARG(arg_set_id, 'debug.data.requestId') AS id,
+      EXTRACT_ARG(arg_set_id, 'debug.data.mimeType') AS mime,
+      ts
+    FROM slice
+    WHERE name = 'ResourceReceiveResponse'
+  ),
+  finish AS (
+    SELECT
+      EXTRACT_ARG(arg_set_id, 'debug.data.requestId') AS id,
+      EXTRACT_ARG(arg_set_id, 'debug.data.decodedBodyLength') AS len,
+      EXTRACT_ARG(arg_set_id, 'debug.data.encodedDataLength') AS data_len,
+      ts
+    FROM slice
+    WHERE name = 'ResourceFinish'
+  ),
+  resource AS (
+    SELECT
+      request.ts,
+      finish.ts - request.ts AS dur,
+      finish.ts - response.ts AS download_dur,
+      len,
+      CASE
+        WHEN url LIKE "data:%" THEN length(url)
+        ELSE data_len
+      END AS data_len,
+      mime,
+      CASE
+        WHEN mime LIKE '%css%' THEN 'css'
+        WHEN mime LIKE '%htm%' THEN 'html'
+        WHEN mime LIKE '%html%' THEN 'html'
+        WHEN mime LIKE '%json%' THEN 'json'
+        WHEN mime LIKE '%font%' THEN 'font'
+        WHEN mime LIKE '%audio%' THEN 'audio'
+        WHEN mime LIKE '%video%' THEN 'video'
+        WHEN mime LIKE '%image%' THEN 'image'
+        WHEN mime LIKE 'application/wasm' THEN 'javascript'
+        WHEN mime LIKE '%javascript%' THEN 'javascript'
+        WHEN mime LIKE '%ecmascript%' THEN 'javascript'
+        WHEN mime LIKE '%xml%' THEN 'xml'
+        ELSE 'other'
+      END AS mime_category,
+      CASE
+        WHEN length(url) > 100 THEN SUBSTR(url, 1, 90) || '<TRUNCATED>'
+        ELSE url
+      END AS url
+    FROM request, response
+    USING (id),
+    finish USING (id)
+  )
+SELECT interval_id, resource.*, resource.ts - navigation_start_ts AS nav_rel_ts
+FROM resource, interesting_interval
+ON resource.ts BETWEEN interesting_interval.ts AND interesting_interval.end - 1;
+
+SELECT * FROM resource_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/sequence_manager.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/sequence_manager.sql
new file mode 100644
index 0000000..eeb8e85
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/sequence_manager.sql
@@ -0,0 +1,22 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS sequence_manager_metric;
+
+CREATE VIEW sequence_manager_metric
+AS
+SELECT interval_id, COUNT(*) AS value, 'tasks_started' AS metric_name, 'count' AS unit
+FROM interesting_slice_start
+WHERE name = 'ThreadControllerImpl::RunTask'
+GROUP BY interval_id
+UNION ALL
+SELECT interval_id, COUNT(*) AS value, 'tasks_posted' AS metric_name, 'count' AS unit
+FROM interesting_slice_start
+WHERE name = 'SequenceManager PostTask'
+GROUP BY interval_id
+UNION ALL
+SELECT interval_id, COUNT(*) AS value, 'tasks_completed' AS metric_name, 'count' AS unit
+FROM interesting_slice_end
+WHERE name = 'ThreadControllerImpl::RunTask'
+GROUP BY interval_id;
+
+SELECT * FROM sequence_manager_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/tlp.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/tlp.sql
new file mode 100644
index 0000000..1069aee
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/tlp.sql
@@ -0,0 +1,37 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS tlp_span_in;
+
+CREATE VIEW tlp_span_in
+AS
+WITH
+  data AS (
+    SELECT ts, LEAD(ts) OVER (ORDER BY ts ASC) - ts AS dur, active_cpu_count
+    FROM sched_active_cpu_count
+  )
+SELECT * FROM data WHERE dur IS NOT NULL;
+
+DROP TABLE IF EXISTS tlp_span;
+
+CREATE VIRTUAL TABLE tlp_span
+USING
+  SPAN_JOIN(tlp_span_in, interesting_interval);
+
+DROP VIEW IF EXISTS tlp_metric;
+
+CREATE VIEW tlp_metric
+AS
+WITH
+  collapse AS (
+    SELECT
+      interval_id,
+      dur,
+      IIF(active_cpu_count < 6, '' || active_cpu_count, '6+') AS tlp
+    FROM tlp_span
+  ),
+  data AS (
+    SELECT interval_id, SUM(dur) / 1e9 AS value, tlp FROM collapse GROUP BY interval_id, tlp
+  )
+SELECT interval_id, 'tlp_' || tlp AS metric_name, 'sec' AS unit, value FROM data;
+
+SELECT * FROM tlp_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/v8.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/v8.sql
new file mode 100644
index 0000000..503ca5a
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/v8.sql
@@ -0,0 +1,77 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS metric;
+
+CREATE VIEW metric
+AS
+SELECT
+  interval_id,
+  'v8_optimize' AS metric_name,
+  'cpu_sec' AS unit,
+  SUM(thread_span_dur) / 1e9 AS value
+FROM interesting_slice_span
+WHERE
+  name IN (
+    'V8.OptimizeBackground',
+    'V8.OptimizeCode',
+    'V8.InstallOptimizedFunctions',
+    'V8.FinalizeMaglevConcurrentCompilation')
+GROUP BY interval_id
+UNION ALL
+SELECT
+  interval_id,
+  'v8_parse' AS metric_name,
+  'cpu_sec' AS unit,
+  sum(coalesce(thread_span_dur, 0)) / 1e9 AS value
+FROM interesting_slice_span
+WHERE
+  name IN (
+    'V8.ParseFunction',
+    'V8.ParseProgram',
+    'v8.parseOnBackground')  -- we're double counting batch baseline compoilation here
+GROUP BY interval_id
+UNION ALL
+SELECT
+  interval_id,
+  'v8_compile' AS metric_name,
+  'cpu_sec' AS unit,
+  sum(coalesce(thread_span_dur, 0)) / 1e9 AS value
+FROM interesting_slice_span
+WHERE
+  name IN (
+    'V8.CompileIgnition',
+    'V8.CompileIgnitionFinalization',
+    'V8.FinalizeBaselineConcurrentCompilation')
+  OR (  -- hack until we have a proper baseline compilation slice
+    name = 'ThreadPool_RunTask'
+    AND EXTRACT_ARG(arg_set_id, 'task.posted_from.function_name') = "ConcurrentBaselineCompiler")
+GROUP BY interval_id
+UNION ALL
+SELECT
+  interval_id,
+  'style_and_layout' AS metric_name,
+  'cpu_sec' AS unit,
+  SUM(thread_span_dur) / 1e9 AS value
+FROM interesting_slice_span
+WHERE name = 'Blink.ForcedStyleAndLayout.UpdateTime' OR name = 'LocalFrameView::RunStyleAndLayoutLifecyclePhases'
+GROUP BY interval_id
+UNION ALL
+SELECT
+  interval_id,
+  'blink_parse_style' AS name,
+  'cpu_sec' AS unit,
+  SUM(thread_span_dur) / 1e9 AS parse_style
+FROM interesting_slice_span
+WHERE name = 'Blink.ParseStyleSheet.UpdateTime'
+GROUP BY interval_id
+UNION ALL
+SELECT
+  interval_id,
+  'gpu_command_flush' AS metric_name,
+  'cpu_sec' AS unit,
+  SUM(thread_span_dur) / 1e9 AS value
+FROM interesting_slice_span
+WHERE name = 'CommandBufferStub::OnAsyncFlush'
+GROUP BY interval_id;
+
+SELECT * FROM metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/v8_rcs.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/v8_rcs.sql
new file mode 100644
index 0000000..0f29709
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/v8_rcs.sql
@@ -0,0 +1,88 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS v8_rcs_metric;
+
+CREATE VIEW v8_rcs_metric
+AS
+WITH
+  dur AS (
+    SELECT
+      interval_id,
+      replace(substr(key, 26), '[1]', '') AS name,
+      sum(int_value * span_ratio) AS dur
+    FROM interesting_slice_span, args
+    USING (arg_set_id)
+    WHERE key LIKE 'debug.runtime-call-stats%[1]'
+    GROUP BY 1, 2
+  ),
+  count AS (
+    SELECT
+      interval_id,
+      replace(substr(key, 26), '[0]', '') AS name,
+      sum(int_value * span_ratio) AS count
+    FROM interesting_slice_span, args
+    USING (arg_set_id)
+    WHERE key LIKE 'debug.runtime-call-stats%[0]'
+    GROUP BY 1, 2
+  ),
+  data AS (
+    SELECT
+      interval_id,
+      CASE
+        WHEN name LIKE '%Total%' THEN 'total'
+        WHEN name LIKE '%RegExp%' THEN 'regexp'
+        WHEN name LIKE '%IC^_%' ESCAPE '^' THEN 'ic'
+        WHEN name LIKE '%IC%Miss' THEN 'ic'
+        WHEN name LIKE 'IC' THEN 'ic'
+        WHEN name LIKE 'Json%' THEN 'json'
+        WHEN name LIKE '%Optimize%Background%' THEN 'optimize_background'
+        WHEN name LIKE '%Optimize%Concurrent%' THEN 'optimize_background'
+        WHEN name LIKE 'StackGuard%' THEN 'optimize'
+        WHEN name LIKE 'Optimize%' THEN 'optimize'
+        WHEN name LIKE 'Deoptimize%' THEN 'optimize'
+        WHEN name LIKE 'Recompile%' THEN 'optimize'
+        WHEN name LIKE '%TierUp%' THEN 'optimize'
+        WHEN name LIKE '%BudgetInterrupt%' THEN 'optimize'
+        WHEN name LIKE 'Compile%Optimized%' THEN 'optimize'
+        WHEN name LIKE '%Compile%Background%' THEN 'compile_background'
+        WHEN name LIKE 'Compile%' THEN 'compile'
+        WHEN name LIKE '%^_Compile%' ESCAPE '^' THEN 'compile'
+        WHEN name LIKE '%CompileLazy%' THEN 'compile'
+        WHEN name LIKE '%Parse%Background%' THEN 'parse_background'
+        WHEN name LIKE 'Parse%' THEN 'parse'
+        WHEN name LIKE 'PreParse%' THEN 'parse'
+        WHEN name LIKE '%GetMoreDataCallback%' THEN 'network_data'
+        WHEN name LIKE '%Callback%' THEN 'callback'
+        WHEN name LIKE "%Blink C\+\+%" THEN 'callback'
+        WHEN name LIKE '%API%' THEN 'api'
+        WHEN name LIKE 'GC^_Custom^_%'  ESCAPE '^' THEN 'gc_custom'
+        WHEN name LIKE 'GC^_%BACKGROUND%' ESCAPE '^' THEN 'gc_background'
+        WHEN name LIKE 'GC^_%Background%' ESCAPE '^' THEN 'gc_background'
+        WHEN name LIKE 'GC^_%AllocateInTargetSpace' ESCAPE '^' THEN 'gc'
+        WHEN name LIKE 'GC_%' ESCAPE '^' THEN 'gc'
+        WHEN name LIKE 'JS^_Execution' ESCAPE '^' THEN 'javascript'
+        WHEN name LIKE 'JavaScript' THEN 'javascript'
+        WHEN name LIKE '%Blink^_%' ESCAPE '^' THEN 'blink'
+        ELSE 'runtime'
+        END AS metric,
+      SUM(dur) AS dur,
+      SUM(count) AS count
+    FROM dur, count
+    USING (interval_id, name)
+    GROUP BY interval_id, metric
+  )
+SELECT
+  interval_id,
+  'v8_rcs_' || metric || '_dur' AS metric_name,
+  'sec' AS unit,
+  dur / 1e6 AS value
+FROM data
+UNION ALL
+SELECT
+  interval_id,
+  'v8_rcs_' || metric || '_count' AS metric_name,
+  'count' AS unit,
+  count AS value
+FROM data;
+
+SELECT * FROM v8_rcs_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/web_features.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/web_features.sql
new file mode 100644
index 0000000..d2d07c9
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/web_features.sql
@@ -0,0 +1,4916 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP TABLE IF EXISTS web_feature_name;
+
+CREATE TABLE web_feature_name(web_feature_id, name);
+
+-- Source: third_party/blink/public/mojom/use_counter/metrics/web_feature.mojom
+INSERT INTO web_feature_name
+VALUES
+  (0, 'OBSOLETE_PageDestruction'),
+  (1, 'LegacyNotifications'),
+  (2, 'MultipartMainResource'),
+  (3, 'PrefixedIndexedDB'),
+  (4, 'WorkerStart'),
+  (5, 'SharedWorkerStart'),
+  (6, 'LegacyWebAudio'),
+  (7, 'WebAudioStart'),
+  (8, 'PrefixedContentSecurityPolicy'),
+  (9, 'UnprefixedIndexedDB'),
+  (10, 'OpenWebDatabase'),
+  (11, 'LegacyHTMLNotifications'),
+  (12, 'LegacyTextNotifications'),
+  (13, 'UnprefixedRequestAnimationFrame'),
+  (14, 'PrefixedRequestAnimationFrame'),
+  (15, 'ContentSecurityPolicy'),
+  (16, 'ContentSecurityPolicyReportOnly'),
+  (17, 'PrefixedContentSecurityPolicyReportOnly'),
+  (18, 'PrefixedTransitionEndEvent'),
+  (19, 'UnprefixedTransitionEndEvent'),
+  (20, 'PrefixedAndUnprefixedTransitionEndEvent'),
+  (21, 'AutoFocusAttribute'),
+  (22, 'DeprecatedAutoSaveAttribute'),
+  (23, 'DataListElement'),
+  (24, 'FormAttribute'),
+  (25, 'IncrementalAttribute'),
+  (26, 'InputTypeColor'),
+  (27, 'InputTypeDate'),
+  (28, 'InputTypeDateTime'),
+  (29, 'InputTypeDateTimeFallback'),
+  (30, 'InputTypeDateTimeLocal'),
+  (31, 'InputTypeEmail'),
+  (32, 'InputTypeMonth'),
+  (33, 'InputTypeNumber'),
+  (34, 'InputTypeRange'),
+  (35, 'InputTypeSearch'),
+  (36, 'InputTypeTel'),
+  (37, 'InputTypeTime'),
+  (38, 'InputTypeURL'),
+  (39, 'InputTypeWeek'),
+  (40, 'InputTypeWeekFallback'),
+  (41, 'ListAttribute'),
+  (42, 'MaxAttribute'),
+  (43, 'MinAttribute'),
+  (44, 'PatternAttribute'),
+  (45, 'PlaceholderAttribute'),
+  (46, 'PrecisionAttribute'),
+  (47, 'PrefixedDirectoryAttribute'),
+  (48, 'PrefixedSpeechAttribute'),
+  (49, 'RequiredAttribute'),
+  (50, 'ResultsAttribute'),
+  (51, 'StepAttribute'),
+  (52, 'PageVisits'),
+  (53, 'HTMLMarqueeElement'),
+  (54, 'Unused: CSSOverflowMarquee'),
+  (55, 'Reflection'),
+  (56, 'CursorVisibility'),
+  (57, 'OBSOLETE_PrefixedStorageInfo'),
+  (58, 'XFrameOptions'),
+  (59, 'XFrameOptionsSameOrigin'),
+  (60, 'XFrameOptionsSameOriginWithBadAncestorChain'),
+  (61, 'DeprecatedFlexboxWebContent'),
+  (62, 'DeprecatedFlexboxChrome'),
+  (63, 'DeprecatedFlexboxChromeExtension'),
+  (64, 'SVGTRefElement'),
+  (65, 'UnprefixedPerformanceTimeline'),
+  (66, 'PrefixedPerformanceTimeline'),
+  (67, 'UnprefixedUserTiming'),
+  (68, 'PrefixedUserTiming'),
+  (69, 'WindowEvent'),
+  (70, 'ContentSecurityPolicyWithBaseElement'),
+  (71, 'PrefixedMediaAddKey'),
+  (72, 'PrefixedMediaGenerateKeyRequest'),
+  (73, 'WebAudioLooping'),
+  (74, 'DocumentClear'),
+  (75, 'PrefixedTransitionMediaFeature'),
+  (76, 'SVGFontElement'),
+  (77, 'XMLDocument'),
+  (78, 'XSLProcessingInstruction'),
+  (79, 'XSLTProcessor'),
+  (80, 'SVGSwitchElement'),
+  (81, 'PrefixedDocumentRegister'),
+  (82, 'HTMLShadowElementOlderShadowRoot'),
+  (83, 'DocumentAll'),
+  (84, 'FormElement'),
+  (85, 'DemotedFormElement'),
+  (86, 'CaptureAttributeAsEnum'),
+  (87, 'ShadowDOMPrefixedPseudo'),
+  (88, 'ShadowDOMPrefixedCreateShadowRoot'),
+  (89, 'ShadowDOMPrefixedShadowRoot'),
+  (90, 'SVGAnimationElement'),
+  (91, 'KeyboardEventKeyLocation'),
+  (92, 'CaptureEvents'),
+  (93, 'ReleaseEvents'),
+  (94, 'CSSDisplayRunIn'),
+  (95, 'CSSDisplayCompact'),
+  (96, 'LineClamp'),
+  (97, 'SubFrameBeforeUnloadRegistered'),
+  (98, 'SubFrameBeforeUnloadFired'),
+  (99, 'CSSPseudoElementPrefixedDistributed'),
+  (100, 'TextReplaceWholeText'),
+  (101, 'PrefixedShadowRootConstructor'),
+  (102, 'ConsoleMarkTimeline'),
+  (103, 'CSSPseudoElementUserAgentCustomPseudo'),
+  (104, 'DocumentTypeEntities'),
+  (105, 'DocumentTypeInternalSubset'),
+  (106, 'DocumentTypeNotations'),
+  (107, 'ElementGetAttributeNode'),
+  (108, 'ElementSetAttributeNode'),
+  (109, 'ElementRemoveAttributeNode'),
+  (110, 'ElementGetAttributeNodeNS'),
+  (111, 'DocumentCreateAttribute'),
+  (112, 'DocumentCreateAttributeNS'),
+  (113, 'DocumentCreateCDATASection'),
+  (114, 'DocumentInputEncoding'),
+  (115, 'DocumentXMLEncoding'),
+  (116, 'DocumentXMLStandalone'),
+  (117, 'DocumentXMLVersion'),
+  (118, 'NodeIsSameNode'),
+  (119, 'NodeIsSupported'),
+  (120, 'NodeNamespaceURI'),
+  (121, 'NodePrefix'),
+  (122, 'NodeLocalName'),
+  (123, 'NavigatorProductSub'),
+  (124, 'NavigatorVendor'),
+  (125, 'NavigatorVendorSub'),
+  (126, 'FileError'),
+  (127, 'DocumentCharset'),
+  (128, 'PrefixedAnimationEndEvent'),
+  (129, 'UnprefixedAnimationEndEvent'),
+  (130, 'PrefixedAndUnprefixedAnimationEndEvent'),
+  (131, 'PrefixedAnimationStartEvent'),
+  (132, 'UnprefixedAnimationStartEvent'),
+  (133, 'PrefixedAndUnprefixedAnimationStartEvent'),
+  (134, 'PrefixedAnimationIterationEvent'),
+  (135, 'UnprefixedAnimationIterationEvent'),
+  (136, 'PrefixedAndUnprefixedAnimationIterationEvent'),
+  (137, 'EventReturnValue'),
+  (138, 'SVGSVGElement'),
+  (139, 'SVGAnimateColorElement'),
+  (140, 'InsertAdjacentText'),
+  (141, 'InsertAdjacentElement'),
+  (142, 'HasAttributes'),
+  (143, 'DOMSubtreeModifiedEvent'),
+  (144, 'DOMNodeInsertedEvent'),
+  (145, 'DOMNodeRemovedEvent'),
+  (146, 'DOMNodeRemovedFromDocumentEvent'),
+  (147, 'DOMNodeInsertedIntoDocumentEvent'),
+  (148, 'DOMCharacterDataModifiedEvent'),
+  (149, 'DocumentAllTags'),
+  (150, 'OBSOLETE_DocumentAllLegacyCall'),
+  (151, 'HTMLAppletElementLegacyCall'),
+  (152, 'HTMLEmbedElementLegacyCall'),
+  (153, 'HTMLObjectElementLegacyCall'),
+  (154, 'BeforeLoadEvent'),
+  (155, 'GetMatchedCSSRules'),
+  (156, 'SVGFontInCSS'),
+  (157, 'ScrollTopBodyNotQuirksMode'),
+  (158, 'ScrollLeftBodyNotQuirksMode'),
+  (159, 'AttributeIsId'),
+  (160, 'AttributeOwnerElement'),
+  (161, 'AttributeSetPrefix'),
+  (162, 'AttributeSpecified'),
+  (163, 'BeforeLoadEventInIsolatedWorld'),
+  (164, 'PrefixedAudioDecodedByteCount'),
+  (165, 'PrefixedVideoDecodedByteCount'),
+  (166, 'PrefixedVideoSupportsFullscreen'),
+  (167, 'PrefixedVideoDisplayingFullscreen'),
+  (168, 'PrefixedVideoEnterFullscreen'),
+  (169, 'PrefixedVideoExitFullscreen'),
+  (170, 'PrefixedVideoEnterFullScreen'),
+  (171, 'PrefixedVideoExitFullScreen'),
+  (172, 'PrefixedVideoDecodedFrameCount'),
+  (173, 'PrefixedVideoDroppedFrameCount'),
+  (174, 'SourceElementCandidate'),
+  (175, 'SourceElementNonMatchingMedia'),
+  (176, 'PrefixedElementRequestFullscreen'),
+  (177, 'PrefixedElementRequestFullScreen'),
+  (178, 'BarPropLocationbar'),
+  (179, 'BarPropMenubar'),
+  (180, 'BarPropPersonalbar'),
+  (181, 'BarPropScrollbars'),
+  (182, 'BarPropStatusbar'),
+  (183, 'BarPropToolbar'),
+  (184, 'InputTypeEmailMultiple'),
+  (185, 'InputTypeEmailMaxLength'),
+  (186, 'InputTypeEmailMultipleMaxLength'),
+  (187, 'TextTrackCueConstructor'),
+  (188, 'CSSStyleDeclarationPropertyName'),
+  (189, 'CSSStyleDeclarationFloatPropertyName'),
+  (190, 'InputTypeText'),
+  (191, 'InputTypeTextMaxLength'),
+  (192, 'InputTypePassword'),
+  (193, 'InputTypePasswordMaxLength'),
+  (194, 'SVGInstanceRoot'),
+  (195, 'ShowModalDialog'),
+  (196, 'PrefixedPageVisibility'),
+  (197, 'HTMLFrameElementLocation'),
+  (198, 'CSSStyleSheetInsertRuleOptionalArg'),
+  (199, 'CSSWebkitRegionAtRule'),
+  (200, 'DocumentBeforeUnloadRegistered'),
+  (201, 'DocumentBeforeUnloadFired'),
+  (202, 'DocumentUnloadRegistered'),
+  (203, 'DocumentUnloadFired'),
+  (204, 'SVGLocatableNearestViewportElement'),
+  (205, 'SVGLocatableFarthestViewportElement'),
+  (206, 'IsIndexElement'),
+  (207, 'HTMLHeadElementProfile'),
+  (208, 'OverflowChangedEvent'),
+  (209, 'SVGPointMatrixTransform'),
+  (210, 'HTMLHtmlElementManifest'),
+  (211, 'DOMFocusInOutEvent'),
+  (212, 'FileGetLastModifiedDate'),
+  (213, 'HTMLElementInnerText'),
+  (214, 'HTMLElementOuterText'),
+  (215, 'ReplaceDocumentViaJavaScriptURL'),
+  (216, 'ElementSetAttributeNodeNS'),
+  (217, 'ElementPrefixedMatchesSelector'),
+  (218, 'DOMImplementationCreateCSSStyleSheet'),
+  (219, 'CSSStyleSheetRules'),
+  (220, 'CSSStyleSheetAddRule'),
+  (221, 'CSSStyleSheetRemoveRule'),
+  (222, 'InitMessageEvent'),
+  (223, 'PrefixedInitMessageEvent'),
+  (224, 'ElementSetPrefix'),
+  (225, 'CSSStyleDeclarationGetPropertyCSSValue'),
+  (226, 'SVGElementGetPresentationAttribute'),
+  (227, 'REMOVEDAttrUsedAsNodeParameter'),
+  (228, 'REMOVEDAttrUsedAsNodeReceiver'),
+  (229, 'PrefixedMediaCancelKeyRequest'),
+  (230, 'DOMImplementationHasFeature'),
+  (231, 'DOMImplementationHasFeatureReturnFalse'),
+  (232, 'CanPlayTypeKeySystem'),
+  (233, 'PrefixedDevicePixelRatioMediaFeature'),
+  (234, 'PrefixedMaxDevicePixelRatioMediaFeature'),
+  (235, 'PrefixedMinDevicePixelRatioMediaFeature'),
+  (236, 'PrefixedTransform2dMediaFeature'),
+  (237, 'PrefixedTransform3dMediaFeature'),
+  (238, 'PrefixedAnimationMediaFeature'),
+  (239, 'PrefixedViewModeMediaFeature'),
+  (240, 'PrefixedStorageQuota'),
+  (241, 'ContentSecurityPolicyReportOnlyInMeta'),
+  (242, 'PrefixedMediaSourceOpen'),
+  (243, 'ResetReferrerPolicy'),
+  (244, 'CaseInsensitiveAttrSelectorMatch'),
+  (245, 'CaptureAttributeAsBoolean'),
+  (246, 'FormNameAccessForImageElement'),
+  (247, 'FormNameAccessForPastNamesMap'),
+  (248, 'FormAssociationByParser'),
+  (249, 'HTMLSourceElementMedia'),
+  (250, 'SVGSVGElementInDocument'),
+  (251, 'SVGDocumentRootElement'),
+  (252, 'DocumentCreateEventOptionalArgument'),
+  (253, 'MediaErrorEncrypted'),
+  (254, 'EventSourceURL'),
+  (255, 'WebSocketURL'),
+  (256, 'UnsafeEvalBlocksCSSOM'),
+  (257, 'WorkerSubjectToCSP'),
+  (258, 'WorkerAllowedByChildBlockedByScript'),
+  (259, 'HTMLMediaElementControllerNotNull'),
+  (260, 'DeprecatedWebKitGradient'),
+  (261, 'DeprecatedWebKitLinearGradient'),
+  (262, 'DeprecatedWebKitRepeatingLinearGradient'),
+  (263, 'DeprecatedWebKitRadialGradient'),
+  (264, 'DeprecatedWebKitRepeatingRadialGradient'),
+  (265, 'PrefixedGetImageDataHD'),
+  (266, 'PrefixedPutImageDataHD'),
+  (267, 'PrefixedImageSmoothingEnabled (obsolete)'),
+  (268, 'UnprefixedImageSmoothingEnabled'),
+  (269, 'ShadowRootApplyAuthorStyles'),
+  (270, 'PromiseConstructor'),
+  (271, 'PromiseCast'),
+  (272, 'PromiseReject'),
+  (273, 'PromiseResolve'),
+  (274, 'TextAutosizing'),
+  (275, 'TextAutosizingLayout'),
+  (276, 'HTMLAnchorElementPingAttribute'),
+  (277, 'JavascriptExhaustedMemory'),
+  (278, 'InsertAdjacentHTML'),
+  (279, 'SVGClassName'),
+  (280, 'HTMLAppletElement'),
+  (281, 'HTMLMediaElementSeekToFragmentStart'),
+  (282, 'HTMLMediaElementPauseAtFragmentEnd'),
+  (283, 'OBSOLETE_PrefixedWindowURL'),
+  (284, 'PrefixedWorkerURL'),
+  (285, 'WindowOrientation'),
+  (286, 'DOMStringListContains'),
+  (287, 'DocumentCaptureEvents'),
+  (288, 'DocumentReleaseEvents'),
+  (289, 'WindowCaptureEvents'),
+  (290, 'WindowReleaseEvents'),
+  (291, 'PrefixedGamepad'),
+  (292, 'ElementAnimateKeyframeListEffectObjectTiming'),
+  (293, 'ElementAnimateKeyframeListEffectDoubleTiming'),
+  (294, 'ElementAnimateKeyframeListEffectNoTiming'),
+  (295, 'DocumentXPathCreateExpression'),
+  (296, 'DocumentXPathCreateNSResolver'),
+  (297, 'DocumentXPathEvaluate'),
+  (298, 'AttrGetValue'),
+  (299, 'AttrSetValue'),
+  (300, 'AnimationConstructorKeyframeListEffectObjectTiming'),
+  (301, 'AnimationConstructorKeyframeListEffectDoubleTiming'),
+  (302, 'AnimationConstructorKeyframeListEffectNoTiming'),
+  (303, 'AttrSetValueWithElement'),
+  (304, 'PrefixedCancelAnimationFrame'),
+  (305, 'PrefixedCancelRequestAnimationFrame'),
+  (306, 'NamedNodeMapGetNamedItem'),
+  (307, 'NamedNodeMapSetNamedItem'),
+  (308, 'NamedNodeMapRemoveNamedItem'),
+  (309, 'NamedNodeMapItem'),
+  (310, 'NamedNodeMapGetNamedItemNS'),
+  (311, 'NamedNodeMapSetNamedItemNS'),
+  (312, 'NamedNodeMapRemoveNamedItemNS'),
+  (313, 'OpenWebDatabaseInWorker'),
+  (314, 'OpenWebDatabaseSyncInWorker'),
+  (315, 'PrefixedAllowFullscreenAttribute'),
+  (316, 'XHRProgressEventPosition'),
+  (317, 'XHRProgressEventTotalSize'),
+  (318, 'PrefixedDocumentIsFullscreen'),
+  (319, 'PrefixedDocumentFullScreenKeyboardInputAllowed'),
+  (320, 'PrefixedDocumentCurrentFullScreenElement'),
+  (321, 'PrefixedDocumentCancelFullScreen'),
+  (322, 'PrefixedDocumentFullscreenEnabled'),
+  (323, 'PrefixedDocumentFullscreenElement'),
+  (324, 'PrefixedDocumentExitFullscreen'),
+  (325, 'SVGForeignObjectElement'),
+  (326, 'PrefixedElementRequestPointerLock'),
+  (327, 'SelectionSetPosition'),
+  (328, 'AnimationFinishEvent'),
+  (329, 'SVGSVGElementInXMLDocument'),
+  (330, 'CanvasRenderingContext2DSetAlpha'),
+  (331, 'CanvasRenderingContext2DSetCompositeOperation'),
+  (332, 'CanvasRenderingContext2DSetLineWidth'),
+  (333, 'CanvasRenderingContext2DSetLineCap'),
+  (334, 'CanvasRenderingContext2DSetLineJoin'),
+  (335, 'CanvasRenderingContext2DSetMiterLimit'),
+  (336, 'CanvasRenderingContext2DClearShadow'),
+  (337, 'CanvasRenderingContext2DSetStrokeColor'),
+  (338, 'CanvasRenderingContext2DSetFillColor'),
+  (339, 'CanvasRenderingContext2DDrawImageFromRect'),
+  (340, 'CanvasRenderingContext2DSetShadow'),
+  (341, 'PrefixedPerformanceClearResourceTimings'),
+  (342, 'PrefixedPerformanceSetResourceTimingBufferSize'),
+  (343, 'EventSrcElement'),
+  (344, 'EventCancelBubble'),
+  (345, 'OBSOLETE_EventPath'),
+  (346, 'EventClipboardData'),
+  (347, 'NodeIteratorDetach'),
+  (348, 'AttrNodeValue'),
+  (349, 'AttrTextContent'),
+  (350, 'EventGetReturnValueTrue'),
+  (351, 'EventGetReturnValueFalse'),
+  (352, 'EventSetReturnValueTrue'),
+  (353, 'EventSetReturnValueFalse'),
+  (354, 'NodeIteratorExpandEntityReferences'),
+  (355, 'TreeWalkerExpandEntityReferences'),
+  (356, 'WindowOffscreenBuffering'),
+  (357, 'WindowDefaultStatus'),
+  (358, 'WindowDefaultstatus'),
+  (359, 'PrefixedConvertPointFromPageToNode'),
+  (360, 'PrefixedConvertPointFromNodeToPage'),
+  (361, 'PrefixedTransitionEventConstructor'),
+  (362, 'PrefixedMutationObserverConstructor'),
+  (363, 'PrefixedIDBCursorConstructor'),
+  (364, 'PrefixedIDBDatabaseConstructor'),
+  (365, 'PrefixedIDBFactoryConstructor'),
+  (366, 'PrefixedIDBIndexConstructor'),
+  (367, 'PrefixedIDBKeyRangeConstructor'),
+  (368, 'PrefixedIDBObjectStoreConstructor'),
+  (369, 'PrefixedIDBRequestConstructor'),
+  (370, 'PrefixedIDBTransactionConstructor'),
+  (371, 'NotificationPermission'),
+  (372, 'RangeDetach'),
+  (373, 'DocumentImportNodeOptionalArgument'),
+  (374, 'HTMLTableElementVspace'),
+  (375, 'HTMLTableElementHspace'),
+  (376, 'PrefixedDocumentExitPointerLock'),
+  (377, 'PrefixedDocumentPointerLockElement'),
+  (378, 'PrefixedTouchRadiusX'),
+  (379, 'PrefixedTouchRadiusY'),
+  (380, 'PrefixedTouchRotationAngle'),
+  (381, 'PrefixedTouchForce'),
+  (382, 'PrefixedMouseEventMovementX'),
+  (383, 'PrefixedMouseEventMovementY'),
+  (384, 'PrefixedWheelEventDirectionInvertedFromDevice'),
+  (385, 'PrefixedWheelEventInit'),
+  (386, 'PrefixedFileRelativePath'),
+  (387, 'DocumentCaretRangeFromPoint'),
+  (388, 'DocumentGetCSSCanvasContext'),
+  (389, 'ElementScrollIntoViewIfNeeded'),
+  (390, 'ElementScrollByLines'),
+  (391, 'ElementScrollByPages'),
+  (392, 'RangeCompareNode'),
+  (393, 'RangeExpand'),
+  (394, 'HTMLFrameElementWidth'),
+  (395, 'HTMLFrameElementHeight'),
+  (396, 'HTMLImageElementX'),
+  (397, 'HTMLImageElementY'),
+  (398, 'HTMLOptionsCollectionRemoveElement'),
+  (399, 'HTMLPreElementWrap'),
+  (400, 'SelectionBaseNode'),
+  (401, 'SelectionBaseOffset'),
+  (402, 'SelectionExtentNode'),
+  (403, 'SelectionExtentOffset'),
+  (404, 'SelectionType'),
+  (405, 'SelectionModify'),
+  (406, 'SelectionSetBaseAndExtent'),
+  (407, 'SelectionEmpty'),
+  (408, 'SVGFEMorphologyElementSetRadius'),
+  (409, 'VTTCue'),
+  (410, 'VTTCueRender'),
+  (411, 'VTTCueRenderVertical'),
+  (412, 'VTTCueRenderSnapToLinesFalse'),
+  (413, 'VTTCueRenderLineNotAuto'),
+  (414, 'VTTCueRenderPositionNot50'),
+  (415, 'VTTCueRenderSizeNot100'),
+  (416, 'VTTCueRenderAlignNotCenter'),
+  (417, 'ElementRequestPointerLock'),
+  (418, 'VTTCueRenderRtl'),
+  (419, 'PostMessageFromSecureToInsecure'),
+  (420, 'PostMessageFromInsecureToSecure'),
+  (421, 'DocumentExitPointerLock'),
+  (422, 'DocumentPointerLockElement'),
+  (423, 'MixedContentFont'),
+  (424, 'PrefixedCursorZoomIn'),
+  (425, 'PrefixedCursorZoomOut'),
+  (426, 'CSSCharsetRuleEncoding'),
+  (427, 'DocumentSetCharset'),
+  (428, 'DocumentDefaultCharset'),
+  (429, 'TextEncoderConstructor'),
+  (430, 'TextEncoderEncode'),
+  (431, 'TextDecoderConstructor'),
+  (432, 'TextDecoderDecode'),
+  (433, 'FocusInOutEvent'),
+  (434, 'MouseEventMovementX'),
+  (435, 'MouseEventMovementY'),
+  (436, 'MixedContentTextTrack'),
+  (437, 'MixedContentRaw'),
+  (438, 'MixedContentImage (old)'),
+  (439, 'MixedContentMedia'),
+  (440, 'DocumentFonts'),
+  (441, 'MixedContentFormsSubmitted'),
+  (442, 'FormsSubmitted'),
+  (443, 'TextInputEventOnInputObsolete'),
+  (444, 'TextInputEventOnTextAreaObsolete'),
+  (445, 'TextInputEventOnContentEditableObsolete'),
+  (446, 'TextInputEventOnNotNodeObsolete'),
+  (447, 'WebkitBeforeTextInsertedOnInputObsolete'),
+  (448, 'WebkitBeforeTextInsertedOnTextAreaObsolete'),
+  (449, 'WebkitBeforeTextInsertedOnContentEditableObsolete'),
+  (450, 'WebkitBeforeTextInsertedOnNotNodeObsolete'),
+  (451, 'WebkitEditableContentChangedOnInputObsolete'),
+  (452, 'WebkitEditableContentChangedOnTextAreaObsolete'),
+  (453, 'WebkitEditableContentChangedOnContentEditableObsolete'),
+  (454, 'WebkitEditableContentChangedOnNotNodeObsolete'),
+  (455, 'OBSOLETE_HTMLImports'),
+  (456, 'OBSOLETE_ElementCreateShadowRoot'),
+  (457, 'OBSOLETE_DocumentRegisterElement'),
+  (458, 'EditingAppleInterchangeNewline'),
+  (459, 'EditingAppleConvertedSpace'),
+  (460, 'EditingApplePasteAsQuotation'),
+  (461, 'EditingAppleStyleSpanClass'),
+  (462, 'EditingAppleTabSpanClass'),
+  (463, 'OBSOLETE_HTMLImportsAsyncAttribute'),
+  (464, 'FontFaceSetReady'),
+  (465, 'XMLHttpRequestSynchronous'),
+  (466, 'CSSSelectorPseudoUnresolved'),
+  (467, 'OBSOLETE_CSSSelectorPseudoShadow'),
+  (468, 'OBSOLETE_CSSSelectorPseudoContent'),
+  (469, 'CSSSelectorPseudoHost'),
+  (470, 'CSSSelectorPseudoHostContext'),
+  (471, 'OBSOLETE_CSSDeepCombinator'),
+  (472, 'SyncXHRWithCredentials'),
+  (473, 'UseAsm'),
+  (474, 'KeyEventNotAllowedInFullScreen'),
+  (475, 'DOMWindowOpen'),
+  (476, 'DOMWindowOpenFeatures'),
+  (477, 'LegacyFullScreenErrorExemption'),
+  (478, 'MediaStreamTrackGetSources'),
+  (479, 'AspectRatioFlexItem'),
+  (480, 'DetailsElement'),
+  (481, 'DialogElement'),
+  (482, 'MapElement'),
+  (483, 'MeterElement'),
+  (484, 'ProgressElement'),
+  (485, 'VideoFullscreenAllowedExemption'),
+  (488, 'WebKitPoint'),
+  (489, 'HTMLPreElementWidth'),
+  (490, 'OBSOLETE_PrefixedHTMLElementDropzone'),
+  (491, 'WheelEventWheelDeltaX'),
+  (492, 'WheelEventWheelDeltaY'),
+  (493, 'WheelEventWheelDelta'),
+  (494, 'SendBeacon'),
+  (495, 'SendBeaconQuotaExceeded'),
+  (501, 'SVGSMILElementInDocument'),
+  (502, 'MouseEventOffsetX'),
+  (503, 'MouseEventOffsetY'),
+  (504, 'MouseEventX'),
+  (505, 'MouseEventY'),
+  (506, 'MouseEventFromElement'),
+  (507, 'MouseEventToElement'),
+  (508, 'RequestFileSystem'),
+  (509, 'RequestFileSystemWorker'),
+  (510, 'RequestFileSystemSyncWorker'),
+  (511, 'UIEventLayerX'),
+  (512, 'UIEventLayerY'),
+  (513, 'UIEventPageX'),
+  (514, 'UIEventPageY'),
+  (515, 'BgPropertiesFixed'),
+  (516, 'HTMLImageElementComposite'),
+  (517, 'DevToolsConsoleTimeline'),
+  (518, 'DevToolsConsoleProfile'),
+  (519, 'SVGStyleElementTitle'),
+  (520, 'PictureSourceSrc'),
+  (521, 'Picture'),
+  (522, 'Sizes'),
+  (523, 'SrcsetXDescriptor'),
+  (524, 'SrcsetWDescriptor'),
+  (525, 'SelectionContainsNode'),
+  (526, 'MediaStreamEnded'),
+  (527, 'MixedContentPrivateIPInPublicWebsitePassive'),
+  (528, 'MixedContentPrivateIPInPublicWebsiteActive'),
+  (529, 'XMLExternalResourceLoad'),
+  (530, 'MixedContentPrivateHostnameInPublicHostname'),
+  (531, 'OBSOLETE_LegacyProtocolEmbeddedAsSubresource'),
+  (532, 'RequestedSubresourceWithEmbeddedCredentials'),
+  (533, 'NotificationCreated'),
+  (534, 'NotificationClosed'),
+  (535, 'NotificationPermissionRequested'),
+  (536, 'MediaStreamLabel'),
+  (537, 'MediaStreamStop'),
+  (538, 'ConsoleTimeline'),
+  (539, 'ConsoleTimelineEnd'),
+  (540, 'SRIElementWithMatchingIntegrityAttribute'),
+  (541, 'SRIElementWithNonMatchingIntegrityAttribute'),
+  (542, 'SRIElementWithUnparsableIntegrityAttribute'),
+  (543, 'SRIElementWithIntegrityAttributeAndInsecureOrigin'),
+  (544, 'SRIElementWithIntegrityAttributeAndInsecureResource'),
+  (545, 'V8Animation_StartTime_AttributeGetter'),
+  (546, 'V8Animation_StartTime_AttributeSetter'),
+  (547, 'V8Animation_CurrentTime_AttributeGetter'),
+  (548, 'V8Animation_CurrentTime_AttributeSetter'),
+  (549, 'V8Animation_PlaybackRate_AttributeGetter'),
+  (550, 'V8Animation_PlaybackRate_AttributeSetter'),
+  (551, 'V8Animation_PlayState_AttributeGetter'),
+  (552, 'V8Animation_Finish_Method'),
+  (553, 'V8Animation_Play_Method'),
+  (554, 'V8Animation_Pause_Method'),
+  (555, 'V8Animation_Reverse_Method'),
+  (556, 'BreakIterator'),
+  (557, 'ScreenOrientationAngle'),
+  (558, 'ScreenOrientationType'),
+  (559, 'ScreenOrientationLock'),
+  (560, 'ScreenOrientationUnlock'),
+  (561, 'GeolocationSecureOrigin'),
+  (562, 'GeolocationInsecureOrigin'),
+  (563, 'NotificationSecureOrigin'),
+  (564, 'NotificationInsecureOrigin'),
+  (565, 'NotificationShowEvent'),
+  (566, 'CSSXGetComputedStyleQueries'),
+  (567, 'SVG1DOM'),
+  (568, 'SVGPathSegDOM'),
+  (569, 'SVGTransformListConsolidate'),
+  (570, 'SVGAnimatedTransformListBaseVal'),
+  (571, 'QuotedAnimationName'),
+  (572, 'QuotedKeyframesRule'),
+  (573, 'SrcsetDroppedCandidate'),
+  (574, 'WindowPostMessage'),
+  (575, 'WindowPostMessageWithLegacyTargetOriginArgument'),
+  (576, 'RenderRuby'),
+  (577, 'CanvasRenderingContext2DCompositeOperationDarker'),
+  (578, 'ScriptElementWithInvalidTypeHasSrc'),
+  (579, 'TimelineStart'),
+  (580, 'ElementBaseURIFromXMLBase'),
+  (581, 'XMLHttpRequestSynchronousInNonWorkerOutsideBeforeUnload'),
+  (582, 'CSSSelectorPseudoScrollbar'),
+  (583, 'CSSSelectorPseudoScrollbarButton'),
+  (584, 'CSSSelectorPseudoScrollbarThumb'),
+  (585, 'CSSSelectorPseudoScrollbarTrack'),
+  (586, 'CSSSelectorPseudoScrollbarTrackPiece'),
+  (587, 'LangAttribute'),
+  (588, 'LangAttributeOnHTML'),
+  (589, 'LangAttributeOnBody'),
+  (590, 'LangAttributeDoesNotMatchToUILocale'),
+  (591, 'InputTypeSubmit'),
+  (592, 'InputTypeSubmitWithValue'),
+  (593, 'SetReferrerPolicy'),
+  (594, 'DOMImplementationHasFeatureReturnFalseInternal'),
+  (595, 'MouseEventWhich'),
+  (596, 'UIEventCharCode'),
+  (597, 'UIEventKeyCode'),
+  (598, 'UIEventWhich'),
+  (599, 'TextWholeText'),
+  (600, 'AttrChildAccess'),
+  (601, 'AttrChildChange'),
+  (602, 'DocumentGetOverrideStyle'),
+  (603, 'NotificationCloseEvent'),
+  (604, 'CSSKeyframesRuleAppendRule'),
+  (605, 'CSSKeyframesRuleInsertRule'),
+  (606, 'StyleMedia'),
+  (607, 'StyleMediaType'),
+  (608, 'StyleMediaMatchMedium'),
+  (609, 'MixedContentPresent'),
+  (610, 'MixedContentBlockable'),
+  (611, 'MixedContentAudio'),
+  (612, 'MixedContentDownload'),
+  (613, 'MixedContentFavicon'),
+  (614, 'MixedContentImage'),
+  (615, 'MixedContentInternal'),
+  (616, 'MixedContentPlugin'),
+  (617, 'MixedContentPrefetch'),
+  (618, 'MixedContentVideo'),
+  (619, 'CORSCredentialedNullOriginAccessAllowed'),
+  (620, 'AudioListenerDopplerFactor'),
+  (621, 'AudioListenerSpeedOfSound'),
+  (622, 'AudioListenerSetVelocity'),
+  (623, 'ShadowRootGetElementsByClassName'),
+  (624, 'ShadowRootGetElementsByTagName'),
+  (625, 'ShadowRootGetElementsByTagNameNS'),
+  (626, 'SVGSMILAnimationInImage'),
+  (627, 'CSSSelectorPseudoFullScreenDocument'),
+  (628, 'CSSSelectorPseudoFullScreenAncestor'),
+  (629, 'CSSSelectorPseudoFullScreen'),
+  (630, 'WebKitCSSMatrix'),
+  (631, 'AudioContextCreateAnalyser'),
+  (632, 'AudioContextCreateBiquadFilter'),
+  (633, 'AudioContextCreateBufferSource'),
+  (634, 'AudioContextCreateChannelMerger'),
+  (635, 'AudioContextCreateChannelSplitter'),
+  (636, 'AudioContextCreateConvolver'),
+  (637, 'AudioContextCreateDelay'),
+  (638, 'AudioContextCreateDynamicsCompressor'),
+  (639, 'AudioContextCreateGain'),
+  (640, 'AudioContextCreateMediaElementSource'),
+  (641, 'AudioContextCreateMediaStreamDestination'),
+  (642, 'AudioContextCreateMediaStreamSource'),
+  (643, 'AudioContextCreateOscillator'),
+  (644, 'AudioContextCreatePanner'),
+  (645, 'AudioContextCreatePeriodicWave'),
+  (646, 'AudioContextCreateScriptProcessor'),
+  (647, 'AudioContextCreateStereoPanner'),
+  (648, 'AudioContextCreateWaveShaper'),
+  (649, 'AudioContextDecodeAudioData'),
+  (650, 'AudioContextResume'),
+  (651, 'AudioContextSuspend'),
+  (652, 'OBSOLETE_AudioContext'),
+  (653, 'OBSOLETE_OfflineAudioContext'),
+  (654, 'OBSOLETE_PrefixedAudioContext'),
+  (655, 'OBSOLETE_PrefixedOfflineAudioContext'),
+  (656, 'AddEventListenerNoArguments'),
+  (657, 'AddEventListenerOneArgument'),
+  (658, 'RemoveEventListenerNoArguments'),
+  (659, 'RemoveEventListenerOneArgument'),
+  (660, 'SRIElementWithNonMatchingIntegrityType'),
+  (661, 'MixedContentInNonHTTPSFrameThatRestrictsMixedContent'),
+  (662, 'MixedContentInSecureFrameThatDoesNotRestrictMixedContent'),
+  (663, 'MixedContentWebSocket'),
+  (664, 'SyntheticKeyframesInCompositedCSSAnimation'),
+  (665, 'MixedContentFormPresent'),
+  (666, 'GetUserMediaInsecureOrigin'),
+  (667, 'GetUserMediaSecureOrigin'),
+  (668, 'OBSOLETE_DeviceMotionInsecureOrigin'),
+  (669, 'DeviceMotionSecureOrigin'),
+  (670, 'OBSOLETE_DeviceOrientationInsecureOrigin'),
+  (671, 'DeviceOrientationSecureOrigin'),
+  (672, 'SandboxViaIFrame'),
+  (673, 'SandboxViaCSP'),
+  (674, 'BlockedSniffingImageToScript'),
+  (675, 'Fetch'),
+  (676, 'FetchBodyStream'),
+  (677, 'XMLHttpRequestAsynchronous'),
+  (678, 'AudioBufferSourceBufferOnce'),
+  (679, 'WhiteSpacePreFromXMLSpace'),
+  (680, 'WhiteSpaceNowrapFromXMLSpace'),
+  (681, 'SVGElementXmlbase'),
+  (682, 'SVGElementXmllang'),
+  (683, 'SVGElementXmlspace'),
+  (684, 'WindowMoveResizeMissingArguments'),
+  (685, 'SVGSVGElementForceRedraw'),
+  (686, 'SVGSVGElementSuspendRedraw'),
+  (687, 'SVGSVGElementUnsuspendRedraw'),
+  (688, 'SVGSVGElementUnsuspendRedrawAll'),
+  (689, 'AudioContextClose'),
+  (690, 'ServiceWorkerClientPostMessage'),
+  (691, 'CSSZoomNotEqualToOne'),
+  (692, 'SVGGraphicsElementGetTransformToElement'),
+  (693, 'ServiceWorkerClientsGetAll'),
+  (694, 'ClientRectListItem'),
+  (695, 'WindowClientInformation'),
+  (696, 'WindowFind'),
+  (697, 'WindowScreenLeft'),
+  (698, 'WindowScreenTop'),
+  (699, 'V8Animation_Cancel_Method'),
+  (700, 'V8Animation_Onfinish_AttributeGetter'),
+  (701, 'V8Animation_Onfinish_AttributeSetter'),
+  (702, 'ElementOffsetParent'),
+  (703, 'ElementOffsetTop'),
+  (704, 'ElementOffsetLeft'),
+  (705, 'ElementOffsetWidth'),
+  (706, 'ElementOffsetHeight'),
+  (707, 'V8Window_WebKitAnimationEvent_ConstructorGetter'),
+  (708, 'V8Window_WebKitAnimationEvent_AttributeSetter'),
+  (709, 'ResourceLoadedAfterRedirectWithCSP'),
+  (710, 'CryptoGetRandomValues'),
+  (711, 'SubtleCryptoEncrypt'),
+  (712, 'SubtleCryptoDecrypt'),
+  (713, 'SubtleCryptoSign'),
+  (714, 'SubtleCryptoVerify'),
+  (715, 'SubtleCryptoDigest'),
+  (716, 'SubtleCryptoGenerateKey'),
+  (717, 'SubtleCryptoImportKey'),
+  (718, 'SubtleCryptoExportKey'),
+  (719, 'SubtleCryptoDeriveBits'),
+  (720, 'SubtleCryptoDeriveKey'),
+  (721, 'SubtleCryptoWrapKey'),
+  (722, 'SubtleCryptoUnwrapKey'),
+  (723, 'CryptoAlgorithmAesCbc'),
+  (724, 'CryptoAlgorithmHmac'),
+  (725, 'CryptoAlgorithmRsaSsaPkcs1v1_5'),
+  (726, 'CryptoAlgorithmSha1'),
+  (727, 'CryptoAlgorithmSha256'),
+  (728, 'CryptoAlgorithmSha384'),
+  (729, 'CryptoAlgorithmSha512'),
+  (730, 'CryptoAlgorithmAesGcm'),
+  (731, 'CryptoAlgorithmRsaOaep'),
+  (732, 'CryptoAlgorithmAesCtr'),
+  (733, 'CryptoAlgorithmAesKw'),
+  (734, 'CryptoAlgorithmRsaPss'),
+  (735, 'CryptoAlgorithmEcdsa'),
+  (736, 'CryptoAlgorithmEcdh'),
+  (737, 'CryptoAlgorithmHkdf'),
+  (738, 'CryptoAlgorithmPbkdf2'),
+  (739, 'DocumentSetDomain'),
+  (740, 'UpgradeInsecureRequestsEnabled'),
+  (741, 'OBSOLETE_UpgradeInsecureRequestsUpgradedRequest'),
+  (742, 'DocumentDesignMode'),
+  (743, 'GlobalCacheStorage'),
+  (744, 'NetInfo'),
+  (745, 'BackgroundSync'),
+  (746, 'TabStopProperty'),
+  (747, 'TabStopAttribute'),
+  (748, 'OBSOLETE_LegacyConst'),
+  (749, 'SVGFilterRes'),
+  (750, 'V8Permissions_Query_Method'),
+  (751, 'LegacyCSSValueIntrinsic'),
+  (752, 'LegacyCSSValueMinIntrinsic'),
+  (753, 'WebkitCanvas'),
+  (754, 'V8HTMLInputElement_Autocapitalize_AttributeGetter'),
+  (755, 'V8HTMLInputElement_Autocapitalize_AttributeSetter'),
+  (756, 'V8HTMLTextAreaElement_Autocapitalize_AttributeGetter'),
+  (757, 'V8HTMLTextAreaElement_Autocapitalize_AttributeSetter'),
+  (758, 'SVGHrefBaseVal'),
+  (759, 'SVGHrefAnimVal'),
+  (760, 'V8CSSRuleList_Item_Method'),
+  (761, 'V8MediaList_Item_Method'),
+  (762, 'V8StyleSheetList_Item_Method'),
+  (763, 'StyleSheetListAnonymousNamedGetter'),
+  (764, 'AutocapitalizeAttribute'),
+  (765, 'FullscreenSecureOrigin'),
+  (766, 'FullscreenInsecureOrigin'),
+  (767, 'DialogInSandboxedContext'),
+  (768, 'SVGSMILAnimationInImageRegardlessOfCache'),
+  (769, 'PushSubscriptionId'),
+  (770, 'EncryptedMediaSecureOrigin'),
+  (771, 'EncryptedMediaInsecureOrigin'),
+  (772, 'PerformanceFrameTiming'),
+  (773, 'V8Element_Animate_Method'),
+  (774, 'V8SVGSVGElement_PixelUnitToMillimeterX_AttributeGetter'),
+  (775, 'V8SVGSVGElement_PixelUnitToMillimeterY_AttributeGetter'),
+  (776, 'V8SVGSVGElement_ScreenPixelToMillimeterX_AttributeGetter'),
+  (777, 'V8SVGSVGElement_ScreenPixelToMillimeterY_AttributeGetter'),
+  (778, 'V8SVGSVGElement_GetElementById_Method'),
+  (779, 'ElementCreateShadowRootMultiple'),
+  (780, 'V8MessageChannel_Constructor'),
+  (781, 'V8MessagePort_PostMessage_Method'),
+  (782, 'V8MessagePort_Start_Method'),
+  (783, 'V8MessagePort_Close_Method'),
+  (784, 'MessagePortsTransferred'),
+  (785, 'CSSKeyframesRuleAnonymousIndexedGetter'),
+  (786, 'V8Screen_AvailLeft_AttributeGetter'),
+  (787, 'V8Screen_AvailTop_AttributeGetter'),
+  (788, 'ObjectObserve'),
+  (789, 'V8SVGAnimationElement_HasExtension_Method'),
+  (790, 'V8SVGCursorElement_HasExtension_Method'),
+  (791, 'V8SVGFEConvolveMatrixElement_PreserveAlpha_AttributeGetter'),
+  (792, 'V8SVGFilterElement_FilterResX_AttributeGetter'),
+  (793, 'V8SVGFilterElement_FilterResY_AttributeGetter'),
+  (794, 'V8SVGFilterElement_SetFilterRes_Method'),
+  (795, 'V8SVGGraphicsElement_HasExtension_Method'),
+  (796, 'V8SVGMaskElement_HasExtension_Method'),
+  (797, 'V8SVGPatternElement_HasExtension_Method'),
+  (798, 'V8SVGStyleElement_Disabled_AttributeGetter'),
+  (799, 'V8SVGStyleElement_Disabled_AttributeSetter'),
+  (800, 'ElementCreateShadowRootMultipleWithUserAgentShadowRoot'),
+  (801, 'InputTypeFileSecureOrigin'),
+  (802, 'InputTypeFileInsecureOrigin'),
+  (803, 'V8HashChangeEvent_InitHashChangeEvent_Method'),
+  (804, 'ElementAttachShadow'),
+  (805, 'V8KeyboardEvent_KeyIdentifier_AttributeGetter'),
+  (806, 'V8SecurityPolicyViolationEvent_DocumentURI_AttributeGetter'),
+  (807, 'V8SecurityPolicyViolationEvent_BlockedURI_AttributeGetter'),
+  (808, 'V8SecurityPolicyViolationEvent_StatusCode_AttributeGetter'),
+  (809, 'HTMLLinkElementDisabled'),
+  (810, 'V8HTMLLinkElement_Disabled_AttributeGetter'),
+  (811, 'V8HTMLLinkElement_Disabled_AttributeSetter'),
+  (812, 'V8HTMLStyleElement_Disabled_AttributeGetter'),
+  (813, 'V8HTMLStyleElement_Disabled_AttributeSetter'),
+  (814, 'V8FileReader_ReadAsBinaryString_Method'),
+  (815, 'V8FileReaderSync_ReadAsBinaryString_Method'),
+  (816, 'V8DOMError_Constructor'),
+  (817, 'V8DOMError_Name_AttributeGetter'),
+  (818, 'V8DOMError_Message_AttributeGetter'),
+  (819, 'V8FileReader_Error_AttributeGetter'),
+  (820, 'V8IDBRequest_Error_AttributeGetter'),
+  (821, 'V8IDBTransaction_Error_AttributeGetter'),
+  (822, 'V8DOMStringList_Item_Method'),
+  (823, 'V8Location_AncestorOrigins_AttributeGetter'),
+  (824, 'V8IDBDatabase_ObjectStoreNames_AttributeGetter'),
+  (825, 'V8IDBObjectStore_IndexNames_AttributeGetter'),
+  (826, 'V8IDBTransaction_ObjectStoreNames_AttributeGetter'),
+  (827, 'V8Navigator_GetStorageUpdates_Method'),
+  (828, 'V8TextTrackCueList_Item_Method'),
+  (829, 'V8TextTrackList_Item_Method'),
+  (830, 'TextInputFired'),
+  (831, 'V8TextEvent_Data_AttributeGetter'),
+  (832, 'V8TextEvent_InitTextEvent_Method'),
+  (833, 'V8SVGSVGElement_UseCurrentView_AttributeGetter'),
+  (834, 'V8SVGSVGElement_CurrentView_AttributeGetter'),
+  (835, 'ClientHintsDPR_DEPRECATED'),
+  (836, 'ClientHintsResourceWidth_DEPRECATED'),
+  (837, 'ClientHintsViewportWidth_DEPRECATED'),
+  (838, 'SRIElementIntegrityAttributeButIneligible'),
+  (839, 'FormDataAppendFile'),
+  (840, 'FormDataAppendFileWithFilename'),
+  (841, 'FormDataAppendBlob'),
+  (842, 'FormDataAppendBlobWithFilename'),
+  (843, 'FormDataAppendNull'),
+  (844, 'HTMLDocumentCreateAttributeNameNotLowercase'),
+  (845, 'NonHTMLElementSetAttributeNodeFromHTMLDocumentNameNotLowercase'),
+  (846, 'DOMStringList_Item_AttributeGetter_IndexedDB'),
+  (847, 'DOMStringList_Item_AttributeGetter_Location'),
+  (848, 'DOMStringList_Contains_Method_IndexedDB'),
+  (849, 'DOMStringList_Contains_Method_Location'),
+  (850, 'NavigatorVibrate'),
+  (851, 'NavigatorVibrateSubFrame'),
+  (852, 'PermissionStatusStatus'),
+  (853, 'V8XPathEvaluator_Constructor'),
+  (854, 'V8XPathEvaluator_CreateExpression_Method'),
+  (855, 'V8XPathEvaluator_CreateNSResolver_Method'),
+  (856, 'V8XPathEvaluator_Evaluate_Method'),
+  (857, 'RequestMIDIAccess_ObscuredByFootprinting'),
+  (858, 'V8MouseEvent_LayerX_AttributeGetter'),
+  (859, 'V8MouseEvent_LayerY_AttributeGetter'),
+  (860, 'InnerTextWithShadowTree'),
+  (861, 'SelectionToStringWithShadowTree'),
+  (862, 'WindowFindWithShadowTree'),
+  (863, 'V8CompositionEvent_InitCompositionEvent_Method'),
+  (864, 'V8CustomEvent_InitCustomEvent_Method'),
+  (865, 'V8DeviceMotionEvent_InitDeviceMotionEvent_Method'),
+  (866, 'V8DeviceOrientationEvent_InitDeviceOrientationEvent_Method'),
+  (867, 'V8Event_InitEvent_Method'),
+  (868, 'V8KeyboardEvent_InitKeyboardEvent_Method'),
+  (869, 'V8MouseEvent_InitMouseEvent_Method'),
+  (870, 'V8MutationEvent_InitMutationEvent_Method'),
+  (871, 'V8StorageEvent_InitStorageEvent_Method'),
+  (872, 'V8TouchEvent_InitTouchEvent_Method'),
+  (873, 'V8UIEvent_InitUIEvent_Method'),
+  (874, 'V8Document_CreateTouch_Method'),
+  (875, 'V8HTMLFrameElement_GetSVGDocument_Method'),
+  (876, 'RequestFileSystemNonWebbyOrigin'),
+  (877, 'V8Console_Memory_AttributeGetter'),
+  (878, 'V8Console_Memory_AttributeSetter'),
+  (879, 'V8MemoryInfo_TotalJSHeapSize_AttributeGetter'),
+  (880, 'V8MemoryInfo_UsedJSHeapSize_AttributeGetter'),
+  (881, 'V8MemoryInfo_JSHeapSizeLimit_AttributeGetter'),
+  (882, 'V8Performance_Timing_AttributeGetter'),
+  (883, 'V8Performance_Navigation_AttributeGetter'),
+  (884, 'V8Performance_Memory_AttributeGetter'),
+  (885, 'V8SharedWorker_WorkerStart_AttributeGetter'),
+  (886, 'OBSOLETE_HTMLKeygenElement'),
+  (887, 'V8SVGElement_OffsetParent_AttributeGetter'),
+  (888, 'V8SVGElement_OffsetTop_AttributeGetter'),
+  (889, 'V8SVGElement_OffsetLeft_AttributeGetter'),
+  (890, 'V8SVGElement_OffsetWidth_AttributeGetter'),
+  (891, 'V8SVGElement_OffsetHeight_AttributeGetter'),
+  (892, 'HTMLMediaElementPreloadNone'),
+  (893, 'HTMLMediaElementPreloadMetadata'),
+  (894, 'HTMLMediaElementPreloadAuto'),
+  (895, 'HTMLMediaElementPreloadDefault'),
+  (896, 'MixedContentBlockableAllowed'),
+  (897, 'PseudoBeforeAfterForInputElement'),
+  (898, 'V8Permissions_Revoke_Method'),
+  (899, 'LinkRelDnsPrefetch'),
+  (900, 'LinkRelPreconnect'),
+  (901, 'LinkRelPreload'),
+  (902, 'LinkHeaderDnsPrefetch'),
+  (903, 'LinkHeaderPreconnect'),
+  (904, 'ClientHintsMetaHTTPEquivAcceptCH'),
+  (905, 'HTMLElementDeprecatedWidth'),
+  (906, 'ClientHintsContentDPR'),
+  (907, 'ElementAttachShadowOpen'),
+  (908, 'ElementAttachShadowClosed'),
+  (909, 'AudioParamSetValueAtTime'),
+  (910, 'AudioParamLinearRampToValueAtTime'),
+  (911, 'AudioParamExponentialRampToValueAtTime'),
+  (912, 'AudioParamSetTargetAtTime'),
+  (913, 'AudioParamSetValueCurveAtTime'),
+  (914, 'AudioParamCancelScheduledValues'),
+  (915, 'V8Permissions_Request_Method'),
+  (916, 'LinkRelSubresource'),
+  (917, 'LinkRelPrefetch'),
+  (918, 'LinkRelPrerender'),
+  (919, 'LinkRelNext'),
+  (920, 'PrefixedPerformanceResourceTimingBufferFull'),
+  (921, 'CSSValuePrefixedMinContent'),
+  (922, 'CSSValuePrefixedMaxContent'),
+  (923, 'CSSValuePrefixedFitContent'),
+  (924, 'CSSValuePrefixedFillAvailable'),
+  (925, 'FetchAPIRequestContext'),
+  (926, 'PresentationDefaultRequest'),
+  (927, 'PresentationAvailabilityChangeEventListener'),
+  (928, 'PresentationRequestConstructor'),
+  (929, 'PresentationRequestStart'),
+  (930, 'PresentationRequestReconnect'),
+  (931, 'PresentationRequestGetAvailability'),
+  (932, 'PresentationRequestConnectionAvailableEventListener'),
+  (933, 'PresentationConnectionTerminate'),
+  (934, 'PresentationConnectionSend'),
+  (935, 'PresentationConnectionStateChangeEventListener'),
+  (936, 'PresentationConnectionMessageEventListener'),
+  (937, 'CSSAnimationsStackedNeutralKeyframe'),
+  (938, 'ReadingCheckedInClickHandler'),
+  (939, 'FlexboxIntrinsicSizeAlgorithmIsDifferent'),
+  (940, 'OBSOLETE_HTMLImportsHasStyleSheets'),
+  (941, 'WebkitTextInClipProperty'),
+  (942, 'WebkitTextInColorProperty'),
+  (943, 'HeaderValueNotMatchingRFC7230'),
+  (944, 'ClipPathOfPositionedElement'),
+  (945, 'ClipCssOfPositionedElement'),
+  (946, 'NetInfoType'),
+  (947, 'NetInfoDownlinkMax'),
+  (948, 'NetInfoOnChange'),
+  (949, 'NetInfoOnTypeChange'),
+  (950, 'V8Window_Alert_Method'),
+  (951, 'V8Window_Confirm_Method'),
+  (952, 'V8Window_Prompt_Method'),
+  (953, 'V8Window_Print_Method'),
+  (954, 'V8Window_RequestIdleCallback_Method'),
+  (955, 'FlexboxPercentagePaddingVertical'),
+  (956, 'FlexboxPercentageMarginVertical'),
+  (957, 'BackspaceNavigatedBack'),
+  (958, 'BackspaceNavigatedBackAfterFormInteraction'),
+  (959, 'CSPSourceWildcardWouldMatchExactHost'),
+  (960, 'CredentialManagerGet'),
+  (961, 'CredentialManagerGetMediationOptional'),
+  (962, 'CredentialManagerGetMediationSilent'),
+  (963, 'CredentialManagerStore'),
+  (964, 'CredentialManagerRequireUserMediation (obsolete as of M64)'),
+  (965, 'RequestAutocomplete'),
+  (966, 'BlockableMixedContentInSubframeBlocked'),
+  (967, 'AddEventListenerThirdArgumentIsObject'),
+  (968, 'RemoveEventListenerThirdArgumentIsObject'),
+  (969, 'CSSAtRuleCharset'),
+  (970, 'CSSAtRuleFontFace'),
+  (971, 'CSSAtRuleImport'),
+  (972, 'CSSAtRuleKeyframes'),
+  (973, 'CSSAtRuleMedia'),
+  (974, 'CSSAtRuleNamespace'),
+  (975, 'CSSAtRulePage'),
+  (976, 'CSSAtRuleSupports'),
+  (977, 'CSSAtRuleViewport'),
+  (978, 'CSSAtRuleWebkitKeyframes'),
+  (979, 'V8HTMLFieldSetElement_Elements_AttributeGetter'),
+  (980, 'HTMLMediaElementPreloadForcedNone'),
+  (981, 'OBSOLETE_ExternalAddSearchProvider'),
+  (982, 'OBSOLETE_ExternalIsSearchProviderInstalled'),
+  (983, 'V8Permissions_RequestAll_Method'),
+  (984, 'BluetoothDeviceInstanceId'),
+  (985, 'HTMLLabelElementFormIDLAttribute'),
+  (986, 'HTMLLabelElementFormContentAttribute'),
+  (987, 'OBSOLETE_DeviceOrientationAbsoluteInsecureOrigin'),
+  (988, 'DeviceOrientationAbsoluteSecureOrigin'),
+  (989, 'FontFaceConstructor'),
+  (990, 'ServiceWorkerControlledPage'),
+  (991, 'MeterElementWithContinuousCapacityAppearance'),
+  (992, 'MeterElementWithDiscreteCapacityAppearance'),
+  (993, 'MeterElementWithMeterAppearance'),
+  (994, 'MeterElementWithNoneAppearance'),
+  (995, 'MeterElementWithRatingAppearance'),
+  (996, 'MeterElementWithRelevancyAppearance'),
+  (997, 'SelectionAnchorNode'),
+  (998, 'SelectionAnchorOffset'),
+  (999, 'SelectionFocusNode'),
+  (1000, 'SelectionFocusOffset'),
+  (1001, 'SelectionIsCollapsed'),
+  (1002, 'SelectionRangeCount'),
+  (1003, 'SelectionGetRangeAt'),
+  (1004, 'SelectionAddRange'),
+  (1005, 'SelectionRemoveAllRanges'),
+  (1006, 'SelectionCollapse'),
+  (1007, 'SelectionCollapseToStart'),
+  (1008, 'SelectionCollapseToEnd'),
+  (1009, 'SelectionExtend'),
+  (1010, 'SelectionSelectAllChildren'),
+  (1011, 'SelectionDeleteDromDocument'),
+  (1012, 'SelectionDOMString'),
+  (1013, 'InputTypeRangeVerticalAppearance'),
+  (1014, 'CSSFilterReference'),
+  (1015, 'CSSFilterGrayscale'),
+  (1016, 'CSSFilterSepia'),
+  (1017, 'CSSFilterSaturate'),
+  (1018, 'CSSFilterHueRotate'),
+  (1019, 'CSSFilterInvert'),
+  (1020, 'CSSFilterOpacity'),
+  (1021, 'CSSFilterBrightness'),
+  (1022, 'CSSFilterContrast'),
+  (1023, 'CSSFilterBlur'),
+  (1024, 'CSSFilterDropShadow'),
+  (1025, 'BackgroundSyncRegister'),
+  (1026, 'BorderImageWithBorderStyleNone'),
+  (1027, 'ExecCommandOnInputOrTextarea'),
+  (1028, 'V8History_ScrollRestoration_AttributeGetter'),
+  (1029, 'V8History_ScrollRestoration_AttributeSetter'),
+  (1030, 'SVG1DOMFilter'),
+  (1031, 'OfflineAudioContextStartRendering'),
+  (1032, 'OfflineAudioContextSuspend'),
+  (1033, 'OfflineAudioContextResume'),
+  (1034, 'AttrCloneNode'),
+  (1035, 'SVG1DOMPaintServer'),
+  (1036, 'SVGSVGElementFragmentSVGView'),
+  (1037, 'SVGSVGElementFragmentSVGViewElement'),
+  (1038, 'PresentationConnectionClose'),
+  (1039, 'SVG1DOMShape'),
+  (1040, 'SVG1DOMText'),
+  (1041, 'RTCPeerConnectionConstructorConstraints'),
+  (1042, 'RTCPeerConnectionConstructorCompliant'),
+  (1043, 'RTCPeerConnectionCreateOfferLegacyNoFailureCallback'),
+  (1044, 'RTCPeerConnectionCreateOfferLegacyFailureCallback'),
+  (1045, 'RTCPeerConnectionCreateOfferLegacyConstraints'),
+  (1046, 'OBSOLETE_RTCPeerConnectionCreateOfferLegacyOfferOptions'),
+  (1047, 'RTCPeerConnectionCreateOfferLegacyCompliant'),
+  (1048, 'RTCPeerConnectionCreateAnswerLegacyNoFailureCallback'),
+  (1049, 'RTCPeerConnectionCreateAnswerLegacyFailureCallback'),
+  (1050, 'OBSOLETE_RTCPeerConnectionCreateAnswerLegacyConstraints'),
+  (1051, 'RTCPeerConnectionCreateAnswerLegacyCompliant'),
+  (1052, 'RTCPeerConnectionSetLocalDescriptionLegacyNoSuccessCallback'),
+  (1053, 'RTCPeerConnectionSetLocalDescriptionLegacyNoFailureCallback'),
+  (1054, 'RTCPeerConnectionSetLocalDescriptionLegacyCompliant'),
+  (1055, 'RTCPeerConnectionSetRemoteDescriptionLegacyNoSuccessCallback'),
+  (1056, 'RTCPeerConnectionSetRemoteDescriptionLegacyNoFailureCallback'),
+  (1057, 'RTCPeerConnectionSetRemoteDescriptionLegacyCompliant'),
+  (1058, 'RTCPeerConnectionGetStatsLegacyNonCompliant'),
+  (1059, 'NodeFilterIsFunction'),
+  (1060, 'NodeFilterIsObject'),
+  (1061, 'TextEncoderUTF16'),
+  (1062, 'CSSSelectorInternalPseudoListBox'),
+  (1063, 'CSSSelectorInternalMediaControlsCastButton'),
+  (1064, 'CSSSelectorInternalMediaControlsOverlayCastButton'),
+  (1065, 'CSSSelectorInternalPseudoSpatialNavigationFocus'),
+  (1066, 'SameOriginTextScript'),
+  (1067, 'SameOriginApplicationScript'),
+  (1068, 'SameOriginOtherScript'),
+  (1069, 'CrossOriginTextScript'),
+  (1070, 'CrossOriginApplicationScript'),
+  (1071, 'CrossOriginOtherScript'),
+  (1072, 'SVG1DOMSVGTests'),
+  (1073, 'V8SVGViewElement_ViewTarget_AttributeGetter'),
+  (1074, 'DisableRemotePlaybackAttribute'),
+  (1075, 'V8SloppyMode'),
+  (1076, 'V8StrictMode'),
+  (1077, 'OBSOLETE_V8StrongMode'),
+  (1078, 'AudioNodeConnectToAudioNode'),
+  (1079, 'AudioNodeConnectToAudioParam'),
+  (1080, 'AudioNodeDisconnectFromAudioNode'),
+  (1081, 'AudioNodeDisconnectFromAudioParam'),
+  (1082, 'V8CSSFontFaceRule_Style_AttributeGetter'),
+  (1083, 'SelectionCollapseNull'),
+  (1084, 'SelectionSetBaseAndExtentNull'),
+  (1085, 'V8SVGSVGElement_CreateSVGNumber_Method'),
+  (1086, 'V8SVGSVGElement_CreateSVGLength_Method'),
+  (1087, 'V8SVGSVGElement_CreateSVGAngle_Method'),
+  (1088, 'V8SVGSVGElement_CreateSVGPoint_Method'),
+  (1089, 'V8SVGSVGElement_CreateSVGMatrix_Method'),
+  (1090, 'V8SVGSVGElement_CreateSVGRect_Method'),
+  (1091, 'V8SVGSVGElement_CreateSVGTransform_Method'),
+  (1092, 'V8SVGSVGElement_CreateSVGTransformFromMatrix_Method'),
+  (1093, 'FormNameAccessForNonDescendantImageElement'),
+  (1094, 'FormControlsCollectionNameAccessForImageElement'),
+  (1095, 'V8SVGSVGElement_Viewport_AttributeGetter'),
+  (1096, 'V8RegExpPrototypeStickyGetter'),
+  (1097, 'V8RegExpPrototypeToString'),
+  (1098, 'V8InputDeviceCapabilities_FiresTouchEvents_AttributeGetter'),
+  (1099, 'DataElement'),
+  (1100, 'TimeElement'),
+  (1101, 'SVG1DOMUriReference'),
+  (1102, 'SVG1DOMZoomAndPan'),
+  (1103, 'V8SVGGraphicsElement_Transform_AttributeGetter'),
+  (1104, 'MenuItemElement'),
+  (1105, 'MenuItemCloseTag'),
+  (1106, 'SVG1DOMMarkerElement'),
+  (1107, 'SVG1DOMUseElement'),
+  (1108, 'SVG1DOMMaskElement'),
+  (1109, 'V8SVGAElement_Target_AttributeGetter'),
+  (1110, 'V8SVGClipPathElement_ClipPathUnits_AttributeGetter'),
+  (1111, 'SVG1DOMFitToViewBox'),
+  (1112, 'SVG1DOMCursorElement'),
+  (1113, 'V8SVGPathElement_PathLength_AttributeGetter'),
+  (1114, 'SVG1DOMSVGElement'),
+  (1115, 'SVG1DOMImageElement'),
+  (1116, 'SVG1DOMForeignObjectElement'),
+  (1117, 'AudioContextCreateIIRFilter'),
+  (1118, 'CSSSelectorPseudoSlotted'),
+  (1119, 'MediaDevicesEnumerateDevices'),
+  (1120, 'NonSecureSharedWorkerAccessedFromSecureContext'),
+  (1121, 'SecureSharedWorkerAccessedFromNonSecureContext'),
+  (1122, 'NonCSSStyleSheetType'),
+  (1123, 'EventComposedPath'),
+  (1124, 'LinkHeaderPreload'),
+  (1125, 'MouseWheelEvent'),
+  (1126, 'WheelEvent'),
+  (1127, 'MouseWheelAndWheelEvent'),
+  (1128, 'BodyScrollsInAdditionToViewport'),
+  (1129, 'DocumentDesignModeEnabeld'),
+  (1130, 'ContentEditableTrue'),
+  (1131, 'ContentEditableTrueOnHTML'),
+  (1132, 'ContentEditablePlainTextOnly'),
+  (1133, 'V8RegExpPrototypeUnicodeGetter'),
+  (1134, 'OBSOLETE_V8IntlV8Parse'),
+  (1135, 'OBSOLETE_V8IntlPattern'),
+  (1136, 'OBSOLETE_V8IntlResolved'),
+  (1137, 'OBSOLETE_V8PromiseChain'),
+  (1138, 'OBSOLETE_V8PromiseAccept'),
+  (1139, 'OBSOLETE_V8PromiseDefer'),
+  (1140, 'EventComposed'),
+  (1141, 'GeolocationInsecureOriginIframe'),
+  (1142, 'GeolocationSecureOriginIframe'),
+  (1143, 'RequestMIDIAccessIframe_ObscuredByFootprinting'),
+  (1144, 'GetUserMediaInsecureOriginIframe'),
+  (1145, 'GetUserMediaSecureOriginIframe'),
+  (1146, 'ElementRequestPointerLockIframe'),
+  (1147, 'NotificationAPIInsecureOriginIframe'),
+  (1148, 'NotificationAPISecureOriginIframe'),
+  (1149, 'WebSocket'),
+  (1150, 'MediaStreamConstraintsNameValue'),
+  (1151, 'OBSOLETE_MediaStreamConstraintsFromDictionary'),
+  (1152, 'MediaStreamConstraintsConformant'),
+  (1153, 'CSSSelectorIndirectAdjacent'),
+  (1154, 'NodeRootNode (obsolete)'),
+  (
+    1155,
+    'obsolete: BluetoothDeviceConnectGATT (use              WebBluetoothRemoteServerConnect)'),
+  (1156, 'CreateImageBitmap'),
+  (1157, 'PresentationConnectionConnectEventListener'),
+  (1158, 'PresentationConnectionCloseEventListener'),
+  (1159, 'PresentationConnectionTerminateEventListener'),
+  (1160, 'DocumentCreateEventFontFaceSetLoadEvent'),
+  (1161, 'DocumentCreateEventMediaQueryListEvent'),
+  (1162, 'DocumentCreateEventAnimationEvent'),
+  (1163, 'DocumentCreateEventAnimationPlayerEvent'),
+  (1164, 'DocumentCreateEventApplicationCacheErrorEvent'),
+  (1165, 'DocumentCreateEventAutocompleteErrorEvent'),
+  (1166, 'DocumentCreateEventBeforeUnloadEvent'),
+  (1167, 'DocumentCreateEventClipboardEvent'),
+  (1168, 'DocumentCreateEventCompositionEvent'),
+  (1169, 'DocumentCreateEventDragEvent'),
+  (1170, 'DocumentCreateEventErrorEvent'),
+  (1171, 'DocumentCreateEventFocusEvent'),
+  (1172, 'DocumentCreateEventHashChangeEvent'),
+  (1173, 'DocumentCreateEventMutationEvent'),
+  (1174, 'DocumentCreateEventPageTransitionEvent'),
+  (1175, 'DocumentCreateEventPointerEvent'),
+  (1176, 'DocumentCreateEventPopStateEvent'),
+  (1177, 'DocumentCreateEventProgressEvent'),
+  (1178, 'DocumentCreateEventPromiseRejectionEvent'),
+  (1179, 'DocumentCreateEventRelatedEvent'),
+  (1180, 'DocumentCreateEventResourceProgressEvent'),
+  (1181, 'DocumentCreateEventSecurityPolicyViolationEvent'),
+  (1182, 'DocumentCreateEventTextEvent'),
+  (1183, 'DocumentCreateEventTransitionEvent'),
+  (1184, 'DocumentCreateEventWheelEvent'),
+  (1185, 'DocumentCreateEventMediaKeyEvent'),
+  (1186, 'DocumentCreateEventTrackEvent'),
+  (1187, 'OBSOLETE_DocumentCreateEventWebKitAnimationEvent'),
+  (1188, 'DocumentCreateEventMutationEvents'),
+  (1189, 'DocumentCreateEventOrientationEvent'),
+  (1190, 'DocumentCreateEventSVGEvents'),
+  (1191, 'OBSOLETE_DocumentCreateEventWebKitTransitionEvent'),
+  (1192, 'DocumentCreateEventBeforeInstallPromptEvent'),
+  (1193, 'DocumentCreateEventSyncEvent'),
+  (1194, 'DocumentCreateEventDeviceLightEvent'),
+  (1195, 'DocumentCreateEventDeviceMotionEvent'),
+  (1196, 'DocumentCreateEventDeviceOrientationEvent'),
+  (1197, 'DocumentCreateEventMediaEncryptedEvent'),
+  (1198, 'DocumentCreateEventMediaKeyMessageEvent'),
+  (1199, 'DocumentCreateEventGamepadEvent'),
+  (1200, 'DocumentCreateEventGeofencingEvent'),
+  (1201, 'DocumentCreateEventIDBVersionChangeEvent'),
+  (1202, 'DocumentCreateEventBlobEvent'),
+  (1203, 'DocumentCreateEventMediaStreamEvent'),
+  (1204, 'DocumentCreateEventMediaStreamTrackEvent'),
+  (1205, 'DocumentCreateEventRTCDTMFToneChangeEvent'),
+  (1206, 'DocumentCreateEventRTCDataChannelEvent'),
+  (1207, 'DocumentCreateEventRTCIceCandidateEvent'),
+  (1208, 'DocumentCreateEventServicePortConnectEvent'),
+  (1209, 'DocumentCreateEventNotificationEvent'),
+  (1210, 'DocumentCreateEventPresentationConnectionAvailableEvent'),
+  (1211, 'DocumentCreateEventPresentationConnectionCloseEvent'),
+  (1212, 'DocumentCreateEventPushEvent'),
+  (1213, 'DocumentCreateEventExtendableEvent'),
+  (1214, 'DocumentCreateEventExtendableMessageEvent'),
+  (1215, 'DocumentCreateEventFetchEvent'),
+  (1216, 'DocumentCreateEventInstallEvent'),
+  (1217, 'DocumentCreateEventServiceWorkerMessageEvent'),
+  (1218, 'DocumentCreateEventSpeechRecognitionError'),
+  (1219, 'DocumentCreateEventSpeechRecognitionEvent'),
+  (1220, 'DocumentCreateEventSpeechSynthesisEvent'),
+  (1221, 'DocumentCreateEventStorageEvent'),
+  (1222, 'DocumentCreateEventAudioProcessingEvent'),
+  (1223, 'DocumentCreateEventOfflineAudioCompletionEvent'),
+  (1224, 'DocumentCreateEventWebGLContextEvent'),
+  (1225, 'DocumentCreateEventMIDIConnectionEvent'),
+  (1226, 'DocumentCreateEventMIDIMessageEvent'),
+  (1227, 'DocumentCreateEventCloseEvent'),
+  (1228, 'DocumentCreateEventKeyboardEvents'),
+  (1229, 'HTMLMediaElement'),
+  (1230, 'HTMLMediaElementInDocument'),
+  (1231, 'HTMLMediaElementControlsAttribute'),
+  (1232, 'SVGZoomEvent'),
+  (1233, 'V8Animation_Oncancel_AttributeGetter'),
+  (1234, 'V8Animation_Oncancel_AttributeSetter'),
+  (1235, 'V8HTMLCommentInExternalScript'),
+  (1236, 'V8HTMLComment'),
+  (1237, 'V8SloppyModeBlockScopedFunctionRedefinition'),
+  (1238, 'V8ForInInitializer'),
+  (1239, 'V8Animation_Id_AttributeGetter'),
+  (1240, 'V8Animation_Id_AttributeSetter'),
+  (1241, 'MediaStreamOnEnded'),
+  (1242, 'DocumentCreateEventInputEvent'),
+  (1243, 'WebAnimationHyphenatedProperty'),
+  (1244, 'FormControlsCollectionReturnsRadioNodeListForFieldSet'),
+  (1245, 'OBSOLETE_ApplicationCacheManifestSelectInsecureOrigin'),
+  (1246, 'OBSOLETE_ApplicationCacheManifestSelectSecureOrigin'),
+  (1247, 'OBSOLETE_ApplicationCacheAPIInsecureOrigin'),
+  (1248, 'OBSOLETE_ApplicationCacheAPISecureOrigin'),
+  (1249, 'CSSAtRuleApply'),
+  (1250, 'CSSSelectorPseudoAny'),
+  (1251, 'PannerNodeSetVelocity'),
+  (1252, 'OBSOLETE_DocumentAllItemNoArguments'),
+  (1253, 'OBSOLETE_DocumentAllItemNamed'),
+  (1254, 'OBSOLETE_DocumentAllItemIndexed'),
+  (1255, 'OBSOLETE_DocumentAllItemIndexedWithNonNumber'),
+  (1256, 'OBSOLETE_DocumentAllLegacyCallNoArguments'),
+  (1257, 'OBSOLETE_DocumentAllLegacyCallNamed'),
+  (1258, 'OBSOLETE_DocumentAllLegacyCallIndexed'),
+  (1259, 'OBSOLETE_DocumentAllLegacyCallIndexedWithNonNumber'),
+  (1260, 'OBSOLETE_DocumentAllLegacyCallTwoArguments'),
+  (1261, 'HTMLLabelElementFormIsDifferentFromControlForm'),
+  (1262, 'HTMLLabelElementHasNoControlAndFormIsAncestor'),
+  (1263, 'HTMLLabelElementControlForNonFormAssociatedElement'),
+  (1264, 'PatternAttributeUnicodeFlagIsIncompatible'),
+  (1265, 'HTMLMediaElementLoadNetworkEmptyNotPaused'),
+  (1266, 'EventRelatedTargetScoped'),
+  (1267, 'V8Window_WebkitSpeechGrammar_ConstructorGetter'),
+  (1268, 'V8Window_WebkitSpeechGrammarList_ConstructorGetter'),
+  (1269, 'V8Window_WebkitSpeechRecognition_ConstructorGetter'),
+  (1270, 'V8Window_WebkitSpeechRecognitionError_ConstructorGetter'),
+  (1271, 'V8Window_WebkitSpeechRecognitionEvent_ConstructorGetter'),
+  (1272, 'V8Window_SpeechSynthesis_AttributeGetter'),
+  (1273, 'V8IDBFactory_WebkitGetDatabaseNames_Method'),
+  (1274, 'ImageDocument'),
+  (1275, 'ScriptPassesCSPDynamic'),
+  (1276, 'ScriptPassesCSPNonce'),
+  (1277, 'CSPWithStrictDynamic'),
+  (1278, 'ScrollAnchored'),
+  (1279, 'AddEventListenerFourArguments'),
+  (1280, 'RemoveEventListenerFourArguments'),
+  (1281, 'InvalidReportUriDirectiveInMetaCSP'),
+  (1282, 'InvalidSandboxDirectiveInMetaCSP'),
+  (1283, 'InvalidFrameAncestorsDirectiveInMetaCSP'),
+  (1284, 'TouchDragUserGestureUsed'),
+  (1285, 'TouchDragUserGestureUsedCrossOrigin'),
+  (1286, 'DocumentCreateEventForeignFetchEvent'),
+  (1287, 'SVGCalcModeDiscrete'),
+  (1288, 'SVGCalcModeLinear'),
+  (1289, 'SVGCalcModePaced'),
+  (1290, 'SVGCalcModeSpline'),
+  (1291, 'FormSubmissionStarted'),
+  (1292, 'FormValidationStarted'),
+  (1293, 'FormValidationAbortedSubmission'),
+  (1294, 'FormValidationShowedMessage'),
+  (1297, 'V8Document_Images_AttributeGetter'),
+  (1298, 'V8Document_Embeds_AttributeGetter'),
+  (1299, 'V8Document_Plugins_AttributeGetter'),
+  (1300, 'V8Document_Links_AttributeGetter'),
+  (1301, 'V8Document_Forms_AttributeGetter'),
+  (1302, 'V8Document_Scripts_AttributeGetter'),
+  (1303, 'V8Document_Anchors_AttributeGetter'),
+  (1304, 'V8Document_Applets_AttributeGetter'),
+  (1305, 'OBSOLETE_XMLHttpRequestCrossOriginWithCredentials'),
+  (1306, 'MediaStreamTrackRemote'),
+  (1307, 'V8Node_IsConnected_AttributeGetter'),
+  (1308, 'ShadowRootDelegatesFocus'),
+  (1309, 'OBSOLETE_MixedShadowRootV0AndV1'),
+  (1310, 'ImageDocumentInFrame'),
+  (1311, 'MediaDocument'),
+  (1312, 'MediaDocumentInFrame'),
+  (1313, 'PluginDocument'),
+  (1314, 'PluginDocumentInFrame'),
+  (1315, 'SinkDocument'),
+  (1316, 'SinkDocumentInFrame'),
+  (1317, 'TextDocument'),
+  (1318, 'TextDocumentInFrame'),
+  (1319, 'ViewSourceDocument'),
+  (1320, 'FileAPINativeLineEndings'),
+  (1321, 'PointerEventAttributeCount'),
+  (1322, 'CompositedReplication'),
+  (1323, 'EncryptedMediaAllSelectedContentTypesHaveCodecs'),
+  (1324, 'EncryptedMediaAllSelectedContentTypesMissingCodecs'),
+  (1325, 'V8DataTransferItem_WebkitGetAsEntry_Method'),
+  (1326, 'V8HTMLInputElement_WebkitEntries_AttributeGetter'),
+  (1327, 'Entry_Filesystem_AttributeGetter_IsolatedFileSystem'),
+  (1328, 'Entry_GetMetadata_Method_IsolatedFileSystem'),
+  (1329, 'Entry_MoveTo_Method_IsolatedFileSystem'),
+  (1330, 'Entry_CopyTo_Method_IsolatedFileSystem'),
+  (1331, 'Entry_Remove_Method_IsolatedFileSystem'),
+  (1332, 'Entry_GetParent_Method_IsolatedFileSystem'),
+  (1333, 'Entry_ToURL_Method_IsolatedFileSystem'),
+  (1334, 'During_Microtask_Alert'),
+  (1335, 'During_Microtask_Confirm'),
+  (1336, 'During_Microtask_Print'),
+  (1337, 'During_Microtask_Prompt'),
+  (1338, 'During_Microtask_SyncXHR'),
+  (1339, 'URLMethodCreateObjectURLServiceWorker'),
+  (1340, 'URLMethodRevokeObjectURLServiceWorker'),
+  (1341, 'DocumentCreateEventPaymentRequestUpdateEvent'),
+  (1342, 'CredentialManagerGetReturnedCredential'),
+  (1343, 'GeolocationInsecureOriginDeprecatedNotRemoved'),
+  (1344, 'GeolocationInsecureOriginIframeDeprecatedNotRemoved'),
+  (1345, 'ProgressElementWithNoneAppearance'),
+  (1346, 'ProgressElementWithProgressBarAppearance'),
+  (1347, 'PointerEventAddListenerCount'),
+  (1351, 'CSSValueAppearanceNone'),
+  (1352, 'CSSValueAppearanceNotNone'),
+  (1353, 'CSSValueAppearanceOthers'),
+  (1354, 'CSSValueAppearanceButton'),
+  (1355, 'OBSOLETE_CSSValueAppearanceCaret'),
+  (1356, 'CSSValueAppearanceCheckbox'),
+  (1357, 'CSSValueAppearanceMenulist'),
+  (1358, 'CSSValueAppearanceMenulistButton'),
+  (1359, 'CSSValueAppearanceListbox'),
+  (1360, 'CSSValueAppearanceRadio'),
+  (1361, 'CSSValueAppearanceSearchField'),
+  (1362, 'CSSValueAppearanceTextField'),
+  (1363, 'AudioContextCreatePannerAutomated'),
+  (1364, 'PannerNodeSetPosition'),
+  (1365, 'PannerNodeSetOrientation'),
+  (1366, 'AudioListenerSetPosition'),
+  (1367, 'AudioListenerSetOrientation'),
+  (1368, 'IntersectionObserver_Constructor'),
+  (1369, 'DurableStoragePersist'),
+  (1370, 'DurableStoragePersisted'),
+  (1371, 'DurableStorageEstimate'),
+  (1372, 'UntrustedEventDefaultHandled'),
+  (1373, 'FixedRasterScaleBlurryContent'),
+  (1374, 'FixedRasterScalePotentialPerformanceRegression'),
+  (1375, 'OBSOLETE_CSSDeepCombinatorAndShadow'),
+  (1376, 'OpacityWithPreserve3DQuirk'),
+  (1377, 'CSSSelectorPseudoReadOnly'),
+  (1378, 'CSSSelectorPseudoReadWrite'),
+  (1379, 'UnloadHandler_Navigation'),
+  (1380, 'TouchStartUserGestureUtilized'),
+  (1381, 'TouchMoveUserGestureUtilized'),
+  (1382, 'TouchEndDuringScrollUserGestureUtilized'),
+  (1383, 'CSSSelectorPseudoDefined'),
+  (1384, 'RTCPeerConnectionAddIceCandidatePromise'),
+  (1385, 'RTCPeerConnectionAddIceCandidateLegacy'),
+  (1386, 'RTCIceCandidateDefaultSdpMLineIndex'),
+  (1387, 'DocumentCreateEventSensorErrorEvent'),
+  (1388, 'DocumentCreateEventSensorReadingEvent'),
+  (1389, 'MediaStreamConstraintsOldAndNew'),
+  (1390, 'OBSOLETE_V8ArrayProtectorDirtied'),
+  (1391, 'V8ArraySpeciesModified'),
+  (1392, 'V8ArrayPrototypeConstructorModified'),
+  (1393, 'OBSOLETE_V8ArrayInstanceProtoModified'),
+  (1394, 'V8ArrayInstanceConstructorModified'),
+  (1395, 'OBSOLETE_V8LegacyFunctionDeclaration'),
+  (1396, 'OBSOLETE_V8RegExpPrototypeSourceGetter'),
+  (1397, 'OBSOLETE_V8RegExpPrototypeOldFlagGetter'),
+  (1398, 'V8DecimalWithLeadingZeroInStrictMode'),
+  (1399, 'OBSOLETE_FormSubmissionNotInDocumentTree'),
+  (1400, 'GetUserMediaPrefixed'),
+  (1401, 'GetUserMediaLegacy'),
+  (1402, 'GetUserMediaPromise'),
+  (1403, 'CSSFilterFunctionNoArguments'),
+  (1404, 'V8LegacyDateParser'),
+  (1405, 'OpenSearchInsecureOriginInsecureTarget'),
+  (1406, 'OpenSearchInsecureOriginSecureTarget'),
+  (1407, 'OpenSearchSecureOriginInsecureTarget'),
+  (1408, 'OpenSearchSecureOriginSecureTarget'),
+  (1409, 'RegisterProtocolHandlerSecureOrigin'),
+  (1410, 'RegisterProtocolHandlerInsecureOrigin'),
+  (1411, 'CrossOriginWindowAlert'),
+  (1412, 'CrossOriginWindowConfirm'),
+  (1413, 'OBSOLETE_CrossOriginWindowPrompt'),
+  (1414, 'CrossOriginWindowPrint'),
+  (1415, 'MediaStreamOnActive'),
+  (1416, 'MediaStreamOnInactive'),
+  (1417, 'AddEventListenerPassiveTrue'),
+  (1418, 'AddEventListenerPassiveFalse'),
+  (1419, 'CSPReferrerDirective'),
+  (1420, 'OBSOLETE_DocumentOpen'),
+  (1421, 'ElementRequestPointerLockInShadow'),
+  (1422, 'ShadowRootPointerLockElement'),
+  (1423, 'OBSOLETE_DocumentPointerLockElementInV0Shadow'),
+  (1424, 'TextAreaMaxLength'),
+  (1425, 'TextAreaMinLength'),
+  (1426, 'TopNavigationFromSubFrame'),
+  (1427, 'PrefixedElementRequestFullscreenInShadow'),
+  (1428, 'MediaSourceAbortRemove'),
+  (1429, 'MediaSourceDurationTruncatingBuffered'),
+  (1430, 'AudioContextCrossOriginIframe'),
+  (1431, 'PointerEventSetCapture'),
+  (1432, 'PointerEventDispatch'),
+  (1433, 'MIDIMessageEventReceivedTime'),
+  (1434, 'OBSOLETE_SummaryElementWithDisplayBlockAuthorRule'),
+  (1435, 'V8MediaStream_Active_AttributeGetter'),
+  (1436, 'BeforeInstallPromptEvent'),
+  (1437, 'BeforeInstallPromptEventUserChoice'),
+  (1438, 'BeforeInstallPromptEventPreventDefault'),
+  (1439, 'BeforeInstallPromptEventPrompt'),
+  (1440, 'ExecCommandAltersHTMLStructure'),
+  (1441, 'SecureContextCheckPassed'),
+  (1442, 'SecureContextCheckFailed'),
+  (1443, 'SecureContextCheckForSandboxedOriginPassed'),
+  (1444, 'SecureContextCheckForSandboxedOriginFailed'),
+  (1445, 'V8DefineGetterOrSetterWouldThrow'),
+  (1446, 'V8FunctionConstructorReturnedUndefined'),
+  (1447, 'V8BroadcastChannel_Constructor'),
+  (1448, 'V8BroadcastChannel_PostMessage_Method'),
+  (1449, 'V8BroadcastChannel_Close_Method'),
+  (1450, 'TouchStartFired'),
+  (1451, 'MouseDownFired'),
+  (1452, 'PointerDownFired'),
+  (1453, 'PointerDownFiredForTouch'),
+  (1454, 'PointerEventDispatchPointerDown'),
+  (1455, 'SVGSMILBeginOrEndEventValue'),
+  (1456, 'SVGSMILBeginOrEndSyncbaseValue'),
+  (1457, 'SVGSMILElementInsertedAfterLoad'),
+  (1458, 'V8VisualViewport_OffsetLeft_AttributeGetter'),
+  (1459, 'V8VisualViewport_OffsetTop_AttributeGetter'),
+  (1460, 'V8VisualViewport_PageLeft_AttributeGetter'),
+  (1461, 'V8VisualViewport_PageTop_AttributeGetter'),
+  (1462, 'V8VisualViewport_Width_AttributeGetter'),
+  (1463, 'V8VisualViewport_Height_AttributeGetter'),
+  (1464, 'V8VisualViewport_Scale_AttributeGetter'),
+  (1465, 'VisualViewportScrollFired'),
+  (1466, 'VisualViewportResizeFired'),
+  (1467, 'NodeGetRootNode'),
+  (1468, 'SlotChangeEventAddListener'),
+  (1469, 'OBSOLETE_CSSValueAppearanceButtonRendered'),
+  (1470, 'OBSOLETE_CSSValueAppearanceButtonForAnchor'),
+  (1471, 'CSSValueAppearanceButtonForButton'),
+  (1472, 'CSSValueAppearanceButtonForOtherButtons'),
+  (1473, 'OBSOLETE_CSSValueAppearanceTextFieldRendered'),
+  (1474, 'CSSValueAppearanceTextFieldForSearch'),
+  (1475, 'CSSValueAppearanceTextFieldForTextField'),
+  (1476, 'RTCPeerConnectionGetStats'),
+  (1477, 'SVGSMILAnimationAppliedEffect'),
+  (1478, 'PerformanceResourceTimingSizes'),
+  (1479, 'EventSourceDocument'),
+  (1480, 'EventSourceWorker'),
+  (1481, 'SingleOriginInTimingAllowOrigin'),
+  (1482, 'MultipleOriginsInTimingAllowOrigin'),
+  (1483, 'StarInTimingAllowOrigin'),
+  (1484, 'SVGSMILAdditiveAnimation'),
+  (1485, 'OBSOLETE_SendBeaconWithNonSimpleContentType'),
+  (1486, 'ChromeLoadTimesRequestTime'),
+  (1487, 'ChromeLoadTimesStartLoadTime'),
+  (1488, 'ChromeLoadTimesCommitLoadTime'),
+  (1489, 'ChromeLoadTimesFinishDocumentLoadTime'),
+  (1490, 'ChromeLoadTimesFinishLoadTime'),
+  (1491, 'ChromeLoadTimesFirstPaintTime'),
+  (1492, 'ChromeLoadTimesFirstPaintAfterLoadTime'),
+  (1493, 'ChromeLoadTimesNavigationType'),
+  (1494, 'ChromeLoadTimesWasFetchedViaSpdy'),
+  (1495, 'ChromeLoadTimesWasNpnNegotiated'),
+  (1496, 'ChromeLoadTimesNpnNegotiatedProtocol'),
+  (1497, 'ChromeLoadTimesWasAlternateProtocolAvailable'),
+  (1498, 'ChromeLoadTimesConnectionInfo'),
+  (1499, 'ChromeLoadTimesUnknown'),
+  (1500, 'SVGViewElement'),
+  (1501, 'WebShareShare'),
+  (1502, 'AuxclickAddListenerCount'),
+  (1503, 'HTMLCanvasElement'),
+  (1504, 'SVGSMILAnimationElementTiming'),
+  (1505, 'SVGSMILBeginEndAnimationElement'),
+  (1506, 'SVGSMILPausing'),
+  (1507, 'SVGSMILCurrentTime'),
+  (1508, 'HTMLBodyElementOnSelectionChangeAttribute'),
+  (1509, 'OBSOLETE_ForeignFetchInterception'),
+  (1510, 'MapNameMatchingStrict'),
+  (1511, 'MapNameMatchingASCIICaseless'),
+  (1512, 'MapNameMatchingUnicodeLower'),
+  (1513, 'RadioNameMatchingStrict'),
+  (1514, 'RadioNameMatchingASCIICaseless'),
+  (1515, 'RadioNameMatchingCaseFolding'),
+  (1516, 'NavigatorPointerEnabled'),
+  (1517, 'OBSOLETE_InputSelectionGettersThrow'),
+  (1518, 'DocumentCreateEventVRDisplayEvent'),
+  (1519, 'UsbGetDevices'),
+  (1520, 'UsbRequestDevice'),
+  (1521, 'UsbDeviceOpen'),
+  (1522, 'UsbDeviceClose'),
+  (1523, 'UsbDeviceSelectConfiguration'),
+  (1524, 'UsbDeviceClaimInterface'),
+  (1525, 'UsbDeviceReleaseInterface'),
+  (1526, 'UsbDeviceSelectAlternateInterface'),
+  (1527, 'UsbDeviceControlTransferIn'),
+  (1528, 'UsbDeviceControlTransferOut'),
+  (1529, 'UsbDeviceClearHalt'),
+  (1530, 'UsbDeviceTransferIn'),
+  (1531, 'UsbDeviceTransferOut'),
+  (1532, 'UsbDeviceIsochronousTransferIn'),
+  (1533, 'UsbDeviceIsochronousTransferOut'),
+  (1534, 'UsbDeviceReset'),
+  (1535, 'PointerEnterLeaveFired'),
+  (1536, 'PointerOverOutFired'),
+  (1537, 'PointerEnterLeaveFiredWhileCaptured'),
+  (1538, 'PointerOverOutFiredWhileCaptured'),
+  (1539, 'DraggableAttribute'),
+  (1540, 'CleanScriptElementWithNonce'),
+  (1541, 'PotentiallyInjectedScriptElementWithNonce'),
+  (1542, 'PendingStylesheetAddedAfterBodyStarted'),
+  (1543, 'UntrustedMouseDownEventDispatchedToSelect'),
+  (1544, 'BlockedSniffingAudioToScript'),
+  (1545, 'BlockedSniffingVideoToScript'),
+  (1546, 'BlockedSniffingCSVToScript'),
+  (1547, 'MetaSetCookie'),
+  (1548, 'MetaRefresh'),
+  (1549, 'MetaSetCookieWhenCSPBlocksInlineScript'),
+  (1550, 'MetaRefreshWhenCSPBlocksInlineScript'),
+  (1551, 'MiddleClickAutoscrollStart'),
+  (1552, 'ClipCssOfFixedPositionElement'),
+  (1553, 'RTCPeerConnectionCreateOfferOptionsOfferToReceive'),
+  (1554, 'DragAndDropScrollStart'),
+  (1555, 'PresentationConnectionListConnectionAvailableEventListener'),
+  (1556, 'WebAudioAutoplayCrossOriginIframe'),
+  (1557, 'ScriptInvalidTypeOrLanguage'),
+  (1558, 'VRGetDisplays'),
+  (1559, 'VRPresent (Obsolete)'),
+  (1560, 'VRDeprecatedGetPose'),
+  (1561, 'WebAudioAnalyserNode'),
+  (1562, 'WebAudioAudioBuffer'),
+  (1563, 'WebAudioAudioBufferSourceNode'),
+  (1564, 'WebAudioBiquadFilterNode'),
+  (1565, 'WebAudioChannelMergerNode'),
+  (1566, 'WebAudioChannelSplitterNode'),
+  (1567, 'WebAudioConvolverNode'),
+  (1568, 'WebAudioDelayNode'),
+  (1569, 'WebAudioDynamicsCompressorNode'),
+  (1570, 'WebAudioGainNode'),
+  (1571, 'WebAudioIIRFilterNode'),
+  (1572, 'WebAudioMediaElementAudioSourceNode'),
+  (1573, 'WebAudioOscillatorNode'),
+  (1574, 'WebAudioPannerNode'),
+  (1575, 'WebAudioPeriodicWave'),
+  (1576, 'WebAudioStereoPannerNode'),
+  (1577, 'WebAudioWaveShaperNode'),
+  (1578, 'CSSZoomReset'),
+  (1579, 'CSSZoomDocument'),
+  (1580, 'PaymentAddressCareOf'),
+  (1581, 'XSSAuditorBlockedScript'),
+  (1582, 'XSSAuditorBlockedEntirePage'),
+  (1583, 'XSSAuditorDisabled'),
+  (1584, 'XSSAuditorEnabledFilter'),
+  (1585, 'XSSAuditorEnabledBlock'),
+  (1586, 'XSSAuditorInvalid'),
+  (1587, 'SVGCursorElement'),
+  (1588, 'SVGCursorElementHasClient'),
+  (1589, 'TextInputEventOnInput'),
+  (1590, 'TextInputEventOnTextArea'),
+  (1591, 'TextInputEventOnContentEditable'),
+  (1592, 'TextInputEventOnNotNode'),
+  (1593, 'WebkitBeforeTextInsertedOnInput'),
+  (1594, 'WebkitBeforeTextInsertedOnTextArea'),
+  (1595, 'WebkitBeforeTextInsertedOnContentEditable'),
+  (1596, 'WebkitBeforeTextInsertedOnNotNode'),
+  (1597, 'WebkitEditableContentChangedOnInput'),
+  (1598, 'WebkitEditableContentChangedOnTextArea'),
+  (1599, 'WebkitEditableContentChangedOnContentEditable'),
+  (1600, 'WebkitEditableContentChangedOnNotNode'),
+  (1601, 'V8NavigatorUserMediaError_ConstraintName_AttributeGetter'),
+  (1602, 'V8HTMLMediaElement_SrcObject_AttributeGetter'),
+  (1603, 'V8HTMLMediaElement_SrcObject_AttributeSetter'),
+  (1604, 'CreateObjectURLBlob'),
+  (1605, 'CreateObjectURLMediaSource'),
+  (1606, 'CreateObjectURLMediaStream'),
+  (1607, 'DocumentCreateTouchWindowNull'),
+  (1608, 'DocumentCreateTouchWindowWrongType'),
+  (1609, 'DocumentCreateTouchTargetNull'),
+  (1610, 'DocumentCreateTouchTargetWrongType'),
+  (1611, 'DocumentCreateTouchLessThanSevenArguments'),
+  (1612, 'DocumentCreateTouchMoreThanSevenArguments'),
+  (1613, 'EncryptedMediaCapabilityProvided'),
+  (1614, 'EncryptedMediaCapabilityNotProvided'),
+  (1615, 'LongTaskObserver'),
+  (1616, 'CSSMotionInEffect'),
+  (1617, 'CSSOffsetInEffect'),
+  (1618, 'VRGetDisplaysInsecureOrigin'),
+  (1619, 'VRRequestPresent'),
+  (1620, 'VRRequestPresentInsecureOrigin'),
+  (1621, 'VRDeprecatedFieldOfView'),
+  (1622, 'VideoInCanvas'),
+  (1623, 'HiddenAutoplayedVideoInCanvas'),
+  (1624, 'OffscreenCanvas'),
+  (1625, 'GamepadPose'),
+  (1626, 'GamepadHand'),
+  (1627, 'GamepadDisplayId'),
+  (1628, 'GamepadButtonTouched'),
+  (1629, 'GamepadPoseHasOrientation'),
+  (1630, 'GamepadPoseHasPosition'),
+  (1631, 'GamepadPosePosition'),
+  (1632, 'GamepadPoseLinearVelocity'),
+  (1633, 'GamepadPoseLinearAcceleration'),
+  (1634, 'GamepadPoseOrientation'),
+  (1635, 'GamepadPoseAngularVelocity'),
+  (1636, 'GamepadPoseAngularAcceleration'),
+  (1637, 'DeprecatedBluetoothDeviceUUIDsAttribute'),
+  (1638, 'V8RTCDataChannel_MaxRetransmitTime_AttributeGetter'),
+  (1639, 'V8RTCDataChannel_MaxRetransmits_AttributeGetter'),
+  (1640, 'V8RTCDataChannel_Reliable_AttributeGetter'),
+  (1641, 'V8RTCPeerConnection_AddStream_Method'),
+  (1642, 'V8RTCPeerConnection_CreateDTMFSender_Method'),
+  (1643, 'V8RTCPeerConnection_GetLocalStreams_Method'),
+  (1644, 'V8RTCPeerConnection_GetRemoteStreams_Method'),
+  (1645, 'V8RTCPeerConnection_GetStreamById_Method'),
+  (1646, 'V8RTCPeerConnection_RemoveStream_Method'),
+  (1647, 'V8RTCPeerConnection_UpdateIce_Method'),
+  (1648, 'RTCPeerConnectionCreateDataChannelMaxRetransmitTime'),
+  (1649, 'RTCPeerConnectionCreateDataChannelMaxRetransmits'),
+  (1650, 'AudioContextCreateConstantSource'),
+  (1651, 'WebAudioConstantSourceNode'),
+  (1652, 'OBSOLETE_LoopbackEmbeddedInSecureContext'),
+  (1653, 'OBSOLETE_LoopbackEmbeddedInNonSecureContext'),
+  (1654, 'BlinkMacSystemFont'),
+  (1655, 'RTCConfigurationIceTransportsNone'),
+  (1656, 'RTCIceServerURL'),
+  (1657, 'RTCIceServerURLs'),
+  (1658, 'OffscreenCanvasTransferToImageBitmap2D'),
+  (1659, 'OffscreenCanvasTransferToImageBitmapWebGL'),
+  (1660, 'OffscreenCanvasCommit2D'),
+  (1661, 'OffscreenCanvasCommitWebGL'),
+  (1662, 'RTCConfigurationIceTransportPolicy'),
+  (1663, 'RTCConfigurationIceTransportPolicyNone'),
+  (1664, 'RTCConfigurationIceTransports'),
+  (1665, 'OBSOLETE_DocumentFullscreenElementInV0Shadow'),
+  (1666, 'ScriptWithCSPBypassingSchemeParserInserted'),
+  (1667, 'ScriptWithCSPBypassingSchemeNotParserInserted'),
+  (1668, 'DocumentCreateElement2ndArgStringHandling'),
+  (1669, 'V8MediaRecorder_Start_Method'),
+  (1670, 'WebBluetoothRequestDevice'),
+  (1671, 'UnitlessPerspectiveInPerspectiveProperty'),
+  (1672, 'UnitlessPerspectiveInTransformProperty'),
+  (1673, 'V8RTCSessionDescription_Type_AttributeGetter'),
+  (1674, 'V8RTCSessionDescription_Type_AttributeSetter'),
+  (1675, 'V8RTCSessionDescription_Sdp_AttributeGetter'),
+  (1676, 'V8RTCSessionDescription_Sdp_AttributeSetter'),
+  (1677, 'RTCSessionDescriptionInitNoType'),
+  (1678, 'RTCSessionDescriptionInitNoSdp'),
+  (1679, 'HTMLMediaElementPreloadForcedMetadata'),
+  (1680, 'GenericSensorStart'),
+  (1681, 'GenericSensorStop'),
+  (1682, 'TouchEventPreventedNoTouchAction'),
+  (1683, 'TouchEventPreventedForcedDocumentPassiveNoTouchAction'),
+  (1684, 'V8Event_StopPropagation_Method'),
+  (1685, 'V8Event_StopImmediatePropagation_Method'),
+  (1686, 'ImageCaptureConstructor'),
+  (1687, 'V8Document_RootScroller_AttributeGetter'),
+  (1688, 'V8Document_RootScroller_AttributeSetter'),
+  (1689, 'CustomElementRegistryDefine'),
+  (1690, 'LinkHeaderServiceWorker'),
+  (1691, 'CSSShadowPiercingDescendantCombinator'),
+  (1692, 'CSSFlexibleBox'),
+  (1693, 'CSSGridLayout'),
+  (1694, 'V8BarcodeDetector_Detect_Method'),
+  (1695, 'V8FaceDetector_Detect_Method'),
+  (1696, 'FullscreenAllowedByOrientationChange'),
+  (1697, 'ServiceWorkerRespondToNavigationRequestWithRedirectedResponse'),
+  (1698, 'V8AudioContext_Constructor'),
+  (1699, 'V8OfflineAudioContext_Constructor'),
+  (1700, 'AppInstalledEventAddListener'),
+  (1701, 'AudioContextGetOutputTimestamp'),
+  (1702, 'V8MediaStreamAudioDestinationNode_Constructor'),
+  (1703, 'V8AnalyserNode_Constructor'),
+  (1704, 'V8AudioBuffer_Constructor'),
+  (1705, 'V8AudioBufferSourceNode_Constructor'),
+  (1706, 'V8AudioProcessingEvent_Constructor'),
+  (1707, 'V8BiquadFilterNode_Constructor'),
+  (1708, 'V8ChannelMergerNode_Constructor'),
+  (1709, 'V8ChannelSplitterNode_Constructor'),
+  (1710, 'V8ConstantSourceNode_Constructor'),
+  (1711, 'V8ConvolverNode_Constructor'),
+  (1712, 'V8DelayNode_Constructor'),
+  (1713, 'V8DynamicsCompressorNode_Constructor'),
+  (1714, 'V8GainNode_Constructor'),
+  (1715, 'V8IIRFilterNode_Constructor'),
+  (1716, 'V8MediaElementAudioSourceNode_Constructor'),
+  (1717, 'V8MediaStreamAudioSourceNode_Constructor'),
+  (1718, 'V8OfflineAudioCompletionEvent_Constructor'),
+  (1719, 'V8OscillatorNode_Constructor'),
+  (1720, 'V8PannerNode_Constructor'),
+  (1721, 'V8PeriodicWave_Constructor'),
+  (1722, 'V8StereoPannerNode_Constructor'),
+  (1723, 'V8WaveShaperNode_Constructor'),
+  (1724, 'V8Headers_GetAll_Method'),
+  (1725, 'NavigatorVibrateEngagementNone'),
+  (1726, 'NavigatorVibrateEngagementMinimal'),
+  (1727, 'NavigatorVibrateEngagementLow'),
+  (1728, 'NavigatorVibrateEngagementMedium'),
+  (1729, 'NavigatorVibrateEngagementHigh'),
+  (1730, 'NavigatorVibrateEngagementMax'),
+  (1731, 'AlertEngagementNone'),
+  (1732, 'AlertEngagementMinimal'),
+  (1733, 'AlertEngagementLow'),
+  (1734, 'AlertEngagementMedium'),
+  (1735, 'AlertEngagementHigh'),
+  (1736, 'AlertEngagementMax'),
+  (1737, 'ConfirmEngagementNone'),
+  (1738, 'ConfirmEngagementMinimal'),
+  (1739, 'ConfirmEngagementLow'),
+  (1740, 'ConfirmEngagementMedium'),
+  (1741, 'ConfirmEngagementHigh'),
+  (1742, 'ConfirmEngagementMax'),
+  (1743, 'PromptEngagementNone'),
+  (1744, 'PromptEngagementMinimal'),
+  (1745, 'PromptEngagementLow'),
+  (1746, 'PromptEngagementMedium'),
+  (1747, 'PromptEngagementHigh'),
+  (1748, 'PromptEngagementMax'),
+  (1749, 'TopNavInSandbox'),
+  (1750, 'TopNavInSandboxWithoutGesture'),
+  (1751, 'TopNavInSandboxWithPerm'),
+  (1752, 'TopNavInSandboxWithPermButNoGesture'),
+  (1753, 'ReferrerPolicyHeader'),
+  (1754, 'HTMLAnchorElementReferrerPolicyAttribute'),
+  (1755, 'HTMLIFrameElementReferrerPolicyAttribute'),
+  (1756, 'HTMLImageElementReferrerPolicyAttribute'),
+  (1757, 'HTMLLinkElementReferrerPolicyAttribute'),
+  (1758, 'BaseElement'),
+  (1759, 'BaseWithCrossOriginHref'),
+  (1760, 'BaseWithDataHref'),
+  (1761, 'BaseWithNewlinesInTarget'),
+  (1762, 'BaseWithOpenBracketInTarget'),
+  (1763, 'OBSOLETE_BaseWouldBeBlockedByDefaultSrc'),
+  (1764, 'V8AssigmentExpressionLHSIsCallInSloppy'),
+  (1765, 'V8AssigmentExpressionLHSIsCallInStrict'),
+  (1766, 'V8PromiseConstructorReturnedUndefined'),
+  (1767, 'FormSubmittedWithUnclosedFormControl'),
+  (1768, 'DocumentCompleteURLHTTPContainingNewline'),
+  (1769, 'DocumentCompleteURLHTTPContainingLessThan'),
+  (1770, 'DocumentCompleteURLHTTPContainingNewlineAndLessThan'),
+  (1771, 'DocumentCompleteURLNonHTTPContainingNewline'),
+  (1772, 'CSSSelectorInternalMediaControlsTextTrackList'),
+  (1773, 'CSSSelectorInternalMediaControlsTextTrackListItem'),
+  (1774, 'CSSSelectorInternalMediaControlsTextTrackListItemInput'),
+  (1775, 'CSSSelectorInternalMediaControlsTextTrackListKindCaptions'),
+  (1776, 'CSSSelectorInternalMediaControlsTextTrackListKindSubtitles'),
+  (1777, 'ScrollbarUseVerticalScrollbarButton'),
+  (1778, 'ScrollbarUseVerticalScrollbarThumb'),
+  (1779, 'ScrollbarUseVerticalScrollbarTrack'),
+  (1780, 'ScrollbarUseHorizontalScrollbarButton'),
+  (1781, 'ScrollbarUseHorizontalScrollbarThumb'),
+  (1782, 'ScrollbarUseHorizontalScrollbarTrack'),
+  (1783, 'HTMLTableCellElementColspan'),
+  (1784, 'OBSOLETE_HTMLTableCellElementColspanGreaterThan1000'),
+  (1785, 'OBSOLETE_HTMLTableCellElementColspanGreaterThan8190'),
+  (1786, 'OBSOLETE_SelectionAddRangeIntersect'),
+  (1787, 'PostMessageFromInsecureToSecureToplevel'),
+  (1788, 'V8MediaSession_Metadata_AttributeGetter'),
+  (1789, 'V8MediaSession_Metadata_AttributeSetter'),
+  (1790, 'V8MediaSession_PlaybackState_AttributeGetter'),
+  (1791, 'V8MediaSession_PlaybackState_AttributeSetter'),
+  (1792, 'V8MediaSession_SetActionHandler_Method'),
+  (1793, 'OBSOLETE_WebNFCPush'),
+  (1794, 'OBSOLETE_WebNFCCancelPush'),
+  (1795, 'OBSOLETE_WebNFCWatch'),
+  (1796, 'OBSOLETE_WebNFCCancelWatch'),
+  (1797, 'AudioParamCancelAndHoldAtTime'),
+  (1798, 'CSSValueUserModifyReadOnly'),
+  (1799, 'CSSValueUserModifyReadWrite'),
+  (1800, 'CSSValueUserModifyReadWritePlaintextOnly'),
+  (1801, 'V8TextDetector_Detect_Method'),
+  (1802, 'CSSValueOnDemand'),
+  (1803, 'ServiceWorkerNavigationPreload'),
+  (1804, 'FullscreenRequestWithPendingElement'),
+  (1805, 'HTMLIFrameElementAllowfullscreenAttributeSetAfterContentLoad'),
+  (1806, 'PointerEventSetCaptureOutsideDispatch'),
+  (1807, 'NotificationPermissionRequestedInsecureOrigin'),
+  (1808, 'V8DeprecatedStorageInfo_QueryUsageAndQuota_Method'),
+  (1809, 'V8DeprecatedStorageInfo_RequestQuota_Method'),
+  (1810, 'V8DeprecatedStorageQuota_QueryUsageAndQuota_Method'),
+  (1811, 'V8DeprecatedStorageQuota_RequestQuota_Method'),
+  (1812, 'V8FileReaderSync_Constructor'),
+  (1815, 'V8HTMLVideoElement_Poster_AttributeGetter'),
+  (1816, 'V8HTMLVideoElement_Poster_AttributeSetter'),
+  (1817, 'NotificationPermissionRequestedIframe'),
+  (1818, 'FileReaderSyncInServiceWorker'),
+  (1819, 'PresentationReceiverInsecureOrigin'),
+  (1820, 'PresentationReceiverSecureOrigin'),
+  (1821, 'PresentationRequestInsecureOrigin'),
+  (1822, 'PresentationRequestSecureOrigin'),
+  (1823, 'RtcpMuxPolicyNegotiate'),
+  (1824, 'DOMClobberedVariableAccessed'),
+  (1825, 'HTMLDocumentCreateProcessingInstruction'),
+  (1826, 'FetchResponseConstructionWithStream'),
+  (1827, 'LocationOrigin'),
+  (1828, 'DocumentOrigin'),
+  (1829, 'SubtleCryptoOnlyStrictSecureContextCheckFailed'),
+  (1830, 'Canvas2DFilter'),
+  (1831, 'Canvas2DImageSmoothingQuality'),
+  (1832, 'CanvasToBlob'),
+  (1833, 'CanvasToDataURL'),
+  (1834, 'OffscreenCanvasConvertToBlob'),
+  (1835, 'SVGInCanvas2D'),
+  (1836, 'SVGInWebGL'),
+  (1837, 'SelectionFuncionsChangeFocus'),
+  (1838, 'HTMLObjectElementGetter'),
+  (1839, 'HTMLObjectElementSetter'),
+  (1840, 'HTMLEmbedElementGetter'),
+  (1841, 'HTMLEmbedElementSetter'),
+  (1842, 'TransformUsesBoxSizeOnSVG'),
+  (1843, 'ScrollByKeyboardArrowKeys'),
+  (1844, 'ScrollByKeyboardPageUpDownKeys'),
+  (1845, 'ScrollByKeyboardHomeEndKeys'),
+  (1846, 'ScrollByKeyboardSpacebarKey'),
+  (1847, 'ScrollByTouch'),
+  (1848, 'ScrollByWheel'),
+  (1849, 'ScheduledActionIgnored'),
+  (1850, 'GetCanvas2DContextAttributes'),
+  (1851, 'V8HTMLInputElement_Capture_AttributeGetter'),
+  (1852, 'V8HTMLInputElement_Capture_AttributeSetter'),
+  (1853, 'HTMLMediaElementControlsListAttribute'),
+  (1854, 'HTMLMediaElementControlsListNoDownload'),
+  (1855, 'HTMLMediaElementControlsListNoFullscreen'),
+  (1856, 'HTMLMediaElementControlsListNoRemotePlayback'),
+  (1857, 'PointerEventClickRetargetCausedByCapture'),
+  (1858, 'VRDisplayIsConnected'),
+  (1859, 'VRDisplayResetPose'),
+  (1860, 'VRDisplayCapabilitiesHasOrientation'),
+  (1861, 'VRDisplayDisplayName'),
+  (1862, 'VREyeParametersOffset'),
+  (1863, 'VRPoseLinearVelocity'),
+  (1864, 'VRPoseLinearAcceleration'),
+  (1865, 'VRPoseAngularVelocity'),
+  (1866, 'VRPoseAngularAcceleration'),
+  (1867, 'CSSOverflowPaged'),
+  (1868, 'ChildSrcAllowedWorkerThatScriptSrcBlocked'),
+  (1869, 'OBSOLETE_HTMLTableElementPresentationAttributeBackground'),
+  (1870, 'V8Navigator_GetInstalledRelatedApps_Method'),
+  (1871, 'NamedAccessOnWindow_ChildBrowsingContext'),
+  (1872, 'NamedAccessOnWindow_ChildBrowsingContext_CrossOriginNameMismatch'),
+  (1873, 'V0CustomElementsRegisterHTMLCustomTag'),
+  (1874, 'V0CustomElementsRegisterHTMLTypeExtension'),
+  (1875, 'V0CustomElementsRegisterSVGElement'),
+  (1876, 'OBSOLETE_V0CustomElementsRegisterEmbedderElement'),
+  (1877, 'V0CustomElementsCreateCustomTagElement'),
+  (1878, 'V0CustomElementsCreateTypeExtensionElement'),
+  (1879, 'V0CustomElementsConstruct'),
+  (1880, 'V8IDBObserver_Observe_Method'),
+  (1881, 'V8IDBObserver_Unobserve_Method'),
+  (1882, 'WebBluetoothRemoteCharacteristicGetDescriptor'),
+  (1883, 'WebBluetoothRemoteCharacteristicGetDescriptors'),
+  (1884, 'WebBluetoothRemoteCharacteristicReadValue'),
+  (1885, 'WebBluetoothRemoteCharacteristicWriteValue'),
+  (1886, 'WebBluetoothRemoteCharacteristicStartNotifications'),
+  (1887, 'WebBluetoothRemoteCharacteristicStopNotifications'),
+  (1888, 'WebBluetoothRemoteDescriptorReadValue'),
+  (1889, 'WebBluetoothRemoteDescriptorWriteValue'),
+  (1890, 'WebBluetoothRemoteServerConnect'),
+  (1891, 'WebBluetoothRemoteServerDisconnect'),
+  (1892, 'WebBluetoothRemoteServerGetPrimaryService'),
+  (1893, 'WebBluetoothRemoteServerGetPrimaryServices'),
+  (1894, 'WebBluetoothRemoteServiceGetCharacteristic'),
+  (1895, 'WebBluetoothRemoteServiceGetCharacteristics'),
+  (1896, 'OBSOLETE_HTMLContentElement'),
+  (1897, 'OBSOLETE_HTMLShadowElement'),
+  (1898, 'HTMLSlotElement'),
+  (1899, 'AccelerometerConstructor'),
+  (1900, 'AbsoluteOrientationSensorConstructor'),
+  (1901, 'AmbientLightSensorConstructor'),
+  (1902, 'GenericSensorOnActivate'),
+  (1903, 'GenericSensorOnChange'),
+  (1904, 'GenericSensorOnError'),
+  (1905, 'GenericSensorActivated'),
+  (1906, 'GyroscopeConstructor'),
+  (1907, 'MagnetometerConstructor'),
+  (1908, 'OrientationSensorPopulateMatrix'),
+  (1909, 'WindowOpenWithInvalidURL'),
+  (1910, 'CrossOriginMainFrameNulledNameAccessed'),
+  (1911, 'MenuItemElementIconAttribute'),
+  (1912, 'WebkitCSSMatrixSetMatrixValue'),
+  (1913, 'WebkitCSSMatrixConstructFromString'),
+  (1914, 'CanRequestURLHTTPContainingNewline'),
+  (1915, 'CanRequestURLNonHTTPContainingNewline'),
+  (1916, 'GetGamepads'),
+  (1917, 'V8SVGPathElement_GetPathSegAtLength_Method'),
+  (1918, 'MediaStreamConstraintsAudio'),
+  (1919, 'MediaStreamConstraintsAudioUnconstrained'),
+  (1920, 'MediaStreamConstraintsVideo'),
+  (1921, 'MediaStreamConstraintsVideoUnconstrained'),
+  (1922, 'MediaStreamConstraintsWidth'),
+  (1923, 'MediaStreamConstraintsHeight'),
+  (1924, 'MediaStreamConstraintsAspectRatio'),
+  (1925, 'MediaStreamConstraintsFrameRate'),
+  (1926, 'MediaStreamConstraintsFacingMode'),
+  (1927, 'MediaStreamConstraintsVolume'),
+  (1928, 'MediaStreamConstraintsSampleRate'),
+  (1929, 'MediaStreamConstraintsSampleSize'),
+  (1930, 'MediaStreamConstraintsEchoCancellation'),
+  (1931, 'MediaStreamConstraintsLatency'),
+  (1932, 'MediaStreamConstraintsChannelCount'),
+  (1933, 'MediaStreamConstraintsDeviceIdAudio'),
+  (1934, 'MediaStreamConstraintsDeviceIdVideo'),
+  (1935, 'MediaStreamConstraintsDisableLocalEcho'),
+  (1936, 'MediaStreamConstraintsGroupIdAudio'),
+  (1937, 'MediaStreamConstraintsGroupIdVideo'),
+  (1938, 'OBSOLETE_MediaStreamConstraintsVideoKind'),
+  (1939, 'OBSOLETE_MediaStreamConstraintsDepthNear'),
+  (1940, 'OBSOLETE_MediaStreamConstraintsDepthFar'),
+  (1941, 'OBSOLETE_MediaStreamConstraintsFocalLengthX'),
+  (1942, 'OBSOLETE_MediaStreamConstraintsFocalLengthY'),
+  (1943, 'MediaStreamConstraintsMediaStreamSourceAudio'),
+  (1944, 'MediaStreamConstraintsMediaStreamSourceVideo'),
+  (1945, 'MediaStreamConstraintsRenderToAssociatedSink'),
+  (1946, 'MediaStreamConstraintsHotwordEnabled'),
+  (1947, 'MediaStreamConstraintsGoogEchoCancellation'),
+  (1948, 'MediaStreamConstraintsGoogExperimentalEchoCancellation'),
+  (1949, 'MediaStreamConstraintsGoogAutoGainControl'),
+  (1950, 'MediaStreamConstraintsGoogExperimentalAutoGainControl'),
+  (1951, 'MediaStreamConstraintsGoogNoiseSuppression'),
+  (1952, 'MediaStreamConstraintsGoogHighpassFilter'),
+  (1953, 'MediaStreamConstraintsGoogTypingNoiseDetection'),
+  (1954, 'MediaStreamConstraintsGoogExperimentalNoiseSuppression'),
+  (1955, 'MediaStreamConstraintsGoogBeamforming'),
+  (1956, 'MediaStreamConstraintsGoogArrayGeometry'),
+  (1957, 'MediaStreamConstraintsGoogAudioMirroring'),
+  (1958, 'MediaStreamConstraintsGoogDAEchoCancellation'),
+  (1959, 'MediaStreamConstraintsGoogNoiseReduction'),
+  (1960, 'MediaStreamConstraintsGoogPowerLineFrequency'),
+  (1961, 'ViewportFixedPositionUnderFilter'),
+  (1962, 'RequestMIDIAccessWithSysExOption_ObscuredByFootprinting'),
+  (1963, 'RequestMIDIAccessIframeWithSysExOption_ObscuredByFootprinting'),
+  (1964, 'GamepadAxes'),
+  (1965, 'GamepadButtons'),
+  (1966, 'VibrateWithoutUserGesture'),
+  (1967, 'OBSOLETE_DispatchMouseEventOnDisabledFormControl'),
+  (1968, 'ElementNameDOMInvalidHTMLParserValid'),
+  (1969, 'ElementNameDOMValidHTMLParserInvalid'),
+  (1970, 'GATTServerDisconnectedEvent'),
+  (1971, 'AnchorClickDispatchForNonConnectedNode'),
+  (1972, 'HTMLParseErrorNestedForm'),
+  (1973, 'FontShapingNotDefGlyphObserved'),
+  (1974, 'PostMessageOutgoingWouldBeBlockedByConnectSrc'),
+  (1975, 'PostMessageIncomingWouldBeBlockedByConnectSrc'),
+  (1977, 'CrossOriginPropertyAccess'),
+  (1978, 'CrossOriginPropertyAccessFromOpener'),
+  (1979, 'CredentialManagerCreate'),
+  (1980, 'OBSOLETE_WebDatabaseCreateDropFTS3Table'),
+  (1981, 'FieldEditInSecureContext'),
+  (1982, 'FieldEditInNonSecureContext'),
+  (
+    1983,
+    'CredentialManagerCredentialRequestOptionsUnmediated (obsolete as              of M64)'),
+  (1984, 'CredentialManagerGetMediationRequired'),
+  (1985, 'CredentialManagerIdName (obsolete as of M64)'),
+  (1986, 'CredentialManagerPasswordName (obsolete as of M64)'),
+  (1987, 'CredentialManagerAdditionalData (obsolete as of M64)'),
+  (1988, 'CredentialManagerCustomFetch (obsolete as of M64)'),
+  (1989, 'NetInfoRtt'),
+  (1990, 'NetInfoDownlink'),
+  (1991, 'OBSOLETE_ShapeDetection_BarcodeDetectorConstructor'),
+  (1992, 'OBSOLETE_ShapeDetection_FaceDetectorConstructor'),
+  (1993, 'OBSOLETE_ShapeDetection_TextDetectorConstructor'),
+  (
+    1994,
+    'CredentialManagerCredentialRequestOptionsOnlyUnmediated              (obsolete as of M64)'),
+  (1995, 'OBSOLETE_InertAttribute'),
+  (1996, 'PluginInstanceAccessFromIsolatedWorld'),
+  (1997, 'PluginInstanceAccessFromMainWorld'),
+  (1998, 'RequestFullscreenForDialogElement'),
+  (1999, 'RequestFullscreenForDialogElementInTopLayer'),
+  (2000, 'ShowModalForElementInFullscreenStack'),
+  (2001, 'ThreeValuedPositionBackground'),
+  (2002, 'ThreeValuedPositionBasicShape'),
+  (2003, 'ThreeValuedPositionGradient'),
+  (2004, 'ThreeValuedPositionObjectPosition'),
+  (2005, 'ThreeValuedPositionPerspectiveOrigin'),
+  (2006, 'UnitlessZeroAngleCustomProperty'),
+  (2007, 'UnitlessZeroAngleFilter'),
+  (2008, 'UnitlessZeroAngleGradient'),
+  (2009, 'UnitlessZeroAngleOffsetRotate'),
+  (2010, 'UnitlessZeroAngleTransform'),
+  (2011, 'OBSOLETE_HTMLOListElementStartGetterReversedWithoutStartAttribute'),
+  (2012, 'CredentialManagerPreventSilentAccess'),
+  (2013, 'NetInfoEffectiveType'),
+  (2014, 'V8SpeechRecognition_Start_Method'),
+  (2015, 'TableRowDirectionDifferentFromTable'),
+  (2016, 'TableSectionDirectionDifferentFromTable'),
+  (2017, 'ClientHintsDeviceMemory_DEPRECATED'),
+  (2018, 'CSSRegisterProperty'),
+  (2019, 'RelativeOrientationSensorConstructor'),
+  (2020, 'OBSOLETE_kSmoothScrollJSInterventionActivated'),
+  (2021, 'BudgetAPIGetCost'),
+  (2022, 'BudgetAPIGetBudget'),
+  (2023, 'CrossOriginMainFrameNulledNonEmptyNameAccessed'),
+  (2024, 'DeprecatedTimingFunctionStepMiddle'),
+  (2025, 'DocumentDomainSetWithNonDefaultPort'),
+  (2026, 'DocumentDomainSetWithDefaultPort'),
+  (2027, 'FeaturePolicyHeader'),
+  (2028, 'FeaturePolicyAllowAttribute'),
+  (2029, 'MIDIPortOpen'),
+  (2030, 'MIDIOutputSend'),
+  (2031, 'MIDIMessageEvent'),
+  (2032, 'FetchEventIsReload'),
+  (2033, 'ServiceWorkerClientFrameType'),
+  (2034, 'QuirksModeDocument'),
+  (2035, 'LimitedQuirksModeDocument'),
+  (2036, 'EncryptedMediaCrossOriginIframe'),
+  (2037, 'CSSSelectorWebkitMediaControls'),
+  (2038, 'CSSSelectorWebkitMediaControlsOverlayEnclosure'),
+  (2039, 'CSSSelectorWebkitMediaControlsOverlayPlayButton'),
+  (2040, 'CSSSelectorWebkitMediaControlsEnclosure'),
+  (2041, 'CSSSelectorWebkitMediaControlsPanel'),
+  (2042, 'CSSSelectorWebkitMediaControlsPlayButton'),
+  (2043, 'CSSSelectorWebkitMediaControlsCurrentTimeDisplay'),
+  (2044, 'CSSSelectorWebkitMediaControlsTimeRemainingDisplay'),
+  (2045, 'CSSSelectorWebkitMediaControlsTimeline'),
+  (2046, 'CSSSelectorWebkitMediaControlsTimelineContainer'),
+  (2047, 'CSSSelectorWebkitMediaControlsMuteButton'),
+  (2048, 'CSSSelectorWebkitMediaControlsVolumeSlider'),
+  (2049, 'CSSSelectorWebkitMediaControlsFullscreenButton'),
+  (2050, 'CSSSelectorWebkitMediaControlsToggleClosedCaptionsButton'),
+  (2051, 'LinearAccelerationSensorConstructor'),
+  (2052, 'ReportUriMultipleEndpoints'),
+  (2053, 'ReportUriSingleEndpoint'),
+  (2054, 'OBSOLETE_V8ConstructorNonUndefinedPrimitiveReturn'),
+  (2055, 'EncryptedMediaDisallowedByFeaturePolicyInCrossOriginIframe'),
+  (2056, 'GeolocationDisallowedByFeaturePolicyInCrossOriginIframe'),
+  (2057, 'GetUserMediaMicDisallowedByFeaturePolicyInCrossOriginIframe'),
+  (2058, 'GetUserMediaCameraDisallowedByFeaturePolicyInCrossOriginIframe'),
+  (2059, 'RequestMIDIAccessDisallowedByFeaturePolicyInCrossOriginIframe'),
+  (2060, 'MediaSourceKeyframeTimeGreaterThanDependant'),
+  (2061, 'MediaSourceMuxedSequenceMode'),
+  (2062, 'PrepareModuleScript'),
+  (2063, 'PresentationRequestStartSecureOrigin'),
+  (2064, 'PresentationRequestStartInsecureOrigin'),
+  (2065, 'PersistentClientHintHeader'),
+  (2066, 'StyleSheetListNonNullAnonymousNamedGetter'),
+  (2067, 'OBSOLETE_OffMainThreadFetch'),
+  (2068, 'OBSOLETE_HTMLOptionsCollectionNamedGetterReturnsNodeList'),
+  (2069, 'ARIAActiveDescendantAttribute'),
+  (2070, 'ARIAAtomicAttribute'),
+  (2071, 'ARIAAutocompleteAttribute'),
+  (2072, 'ARIABusyAttribute'),
+  (2073, 'ARIACheckedAttribute'),
+  (2074, 'ARIAColCountAttribute'),
+  (2075, 'ARIAColIndexAttribute'),
+  (2076, 'ARIAColSpanAttribute'),
+  (2077, 'ARIAControlsAttribute'),
+  (2078, 'ARIACurrentAttribute'),
+  (2079, 'ARIADescribedByAttribute'),
+  (2080, 'ARIADetailsAttribute'),
+  (2081, 'ARIADisabledAttribute'),
+  (2082, 'ARIADropEffectAttribute'),
+  (2083, 'ARIAErrorMessageAttribute'),
+  (2084, 'ARIAExpandedAttribute'),
+  (2085, 'ARIAFlowToAttribute'),
+  (2086, 'ARIAGrabbedAttribute'),
+  (2087, 'ARIAHasPopupAttribute'),
+  (2088, 'OBSOLETE_ARIAHelpAttribute'),
+  (2089, 'ARIAHiddenAttribute'),
+  (2090, 'ARIAInvalidAttribute'),
+  (2091, 'ARIAKeyShortcutsAttribute'),
+  (2092, 'ARIALabelAttribute'),
+  (2093, 'ARIALabeledByAttribute'),
+  (2094, 'ARIALabelledByAttribute'),
+  (2095, 'ARIALevelAttribute'),
+  (2096, 'ARIALiveAttribute'),
+  (2097, 'ARIAModalAttribute'),
+  (2098, 'ARIAMultilineAttribute'),
+  (2099, 'ARIAMultiselectableAttribute'),
+  (2100, 'ARIAOrientationAttribute'),
+  (2101, 'ARIAOwnsAttribute'),
+  (2102, 'ARIAPlaceholderAttribute'),
+  (2103, 'ARIAPosInSetAttribute'),
+  (2104, 'ARIAPressedAttribute'),
+  (2105, 'ARIAReadOnlyAttribute'),
+  (2106, 'ARIARelevantAttribute'),
+  (2107, 'ARIARequiredAttribute'),
+  (2108, 'ARIARoleDescriptionAttribute'),
+  (2109, 'ARIARowCountAttribute'),
+  (2110, 'ARIARowIndexAttribute'),
+  (2111, 'ARIARowSpanAttribute'),
+  (2112, 'ARIASelectedAttribute'),
+  (2113, 'ARIASetSizeAttribute'),
+  (2114, 'ARIASortAttribute'),
+  (2115, 'ARIAValueMaxAttribute'),
+  (2116, 'ARIAValueMinAttribute'),
+  (2117, 'ARIAValueNowAttribute'),
+  (2118, 'ARIAValueTextAttribute'),
+  (2119, 'OBSOLETE_V8LabeledExpressionStatement'),
+  (2120, 'PaymentRequestSupportedMethodsArray'),
+  (2121, 'NavigatorDeviceMemory'),
+  (2122, 'FixedWidthTableDistributionChanged'),
+  (2123, 'WebkitBoxLayout'),
+  (2124, 'WebkitBoxLayoutHorizontal'),
+  (2125, 'WebkitBoxLayoutVertical'),
+  (2126, 'WebkitBoxAlignNotInitial'),
+  (2127, 'WebkitBoxDirectionNotInitial'),
+  (2128, 'WebkitBoxLinesNotInitial'),
+  (2129, 'WebkitBoxPackNotInitial'),
+  (2130, 'WebkitBoxChildFlexNotInitial'),
+  (2131, 'WebkitBoxChildFlexGroupNotInitial'),
+  (2132, 'WebkitBoxChildOrdinalGroupNotInitial'),
+  (2133, 'WebkitBoxNotDefaultOrder'),
+  (2134, 'WebkitBoxNoChildren'),
+  (2135, 'WebkitBoxOneChild'),
+  (2136, 'WebkitBoxOneChildIsLayoutBlockFlowInline'),
+  (2137, 'WebkitBoxManyChildren'),
+  (2138, 'WebkitBoxLineClamp'),
+  (2139, 'WebkitBoxLineClampPercentage'),
+  (2140, 'WebkitBoxLineClampNoChildren'),
+  (2141, 'WebkitBoxLineClampOneChild'),
+  (2142, 'WebkitBoxLineClampOneChildIsLayoutBlockFlowInline'),
+  (2143, 'WebkitBoxLineClampManyChildren'),
+  (2144, 'WebkitBoxLineClampDoesSomething'),
+  (2145, 'FeaturePolicyAllowAttributeDeprecatedSyntax'),
+  (2146, 'SuppressHistoryEntryWithoutUserGesture'),
+  (2147, 'OBSOLETE_ImageInputTypeFormDataWithNonEmptyValue'),
+  (2148, 'WebAudioDezipperGainNodeGain'),
+  (2149, 'WebAudioDezipperStereoPannerNodePan'),
+  (2150, 'WebAudioDezipperDelayNodeDelayTime'),
+  (2151, 'WebAudioDezipperOscillatorNodeFrequency'),
+  (2152, 'WebAudioDezipperOscillatorNodeDetune'),
+  (2153, 'WebAudioDezipperBiquadFilterNodeFrequency'),
+  (2154, 'WebAudioDezipperBiquadFilterNodeDetune'),
+  (2155, 'WebAudioDezipperBiquadFilterNodeQ'),
+  (2156, 'WebAudioDezipperBiquadFilterNodeGain'),
+  (2157, 'PerformanceServerTiming'),
+  (2158, 'FileReaderResultBeforeCompletion'),
+  (2159, 'SyncXhrInPageDismissal'),
+  (2160, 'AsyncXhrInPageDismissal'),
+  (2161, 'V8LineOrParagraphSeparatorAsLineTerminator (obsolete)'),
+  (2162, 'AnimationSetPlaybackRateCompensatorySeek'),
+  (2163, 'OBSOLETE_DeepCombinatorInStaticProfile'),
+  (2164, 'OBSOLETE_PseudoShadowInStaticProfile'),
+  (2165, 'SchemeBypassesCSP'),
+  (2166, 'InnerSchemeBypassesCSP'),
+  (2167, 'SameOriginApplicationOctetStream'),
+  (2168, 'SameOriginApplicationXml'),
+  (2169, 'SameOriginTextHtml'),
+  (2170, 'SameOriginTextPlain'),
+  (2171, 'SameOriginTextXml'),
+  (2172, 'CrossOriginApplicationOctetStream'),
+  (2173, 'CrossOriginApplicationXml'),
+  (2174, 'CrossOriginTextHtml'),
+  (2175, 'CrossOriginTextPlain'),
+  (2176, 'CrossOriginTextXml'),
+  (2177, 'OBSOLETE_SameOriginWorkerApplicationOctetStream'),
+  (2178, 'OBSOLETE_SameOriginWorkerApplicationXml'),
+  (2179, 'OBSOLETE_SameOriginWorkerTextHtml'),
+  (2180, 'OBSOLETE_SameOriginWorkerTextPlain'),
+  (2181, 'OBSOLETE_SameOriginWorkerTextXml'),
+  (2182, 'OBSOLETE_CrossOriginWorkerApplicationOctetStream'),
+  (2183, 'OBSOLETE_CrossOriginWorkerApplicationXml'),
+  (2184, 'OBSOLETE_CrossOriginWorkerTextHtml'),
+  (2185, 'OBSOLETE_CrossOriginWorkerTextPlain'),
+  (2186, 'OBSOLETE_CrossOriginWorkerTextXml'),
+  (2187, 'OBSOLETE_ImageCaptureSetOptions'),
+  (2188, 'PerformanceObserverForWindow'),
+  (2189, 'PerformanceObserverForWorker'),
+  (2190, 'PaintTimingObserved'),
+  (2191, 'PaintTimingRequested'),
+  (2192, 'HTMLMediaElementMediaPlaybackRateOutOfRange'),
+  (2193, 'CSSFilterFunctionNegativeBrightness'),
+  (2194, 'CookieSet'),
+  (2195, 'CookieGet'),
+  (2196, 'GeolocationDisabledByFeaturePolicy'),
+  (2197, 'EncryptedMediaDisabledByFeaturePolicy'),
+  (2198, 'BatteryStatusGetBattery'),
+  (2199, 'OBSOLETE_BatteryStatusInsecureOrigin'),
+  (2200, 'BatteryStatusCrossOrigin'),
+  (2201, 'BatteryStatusSameOriginABA'),
+  (2202, 'WebAudioValueSetterIsSetValue (Obsolete)'),
+  (2203, 'HasIDClassTagAttribute'),
+  (2204, 'HasBeforeOrAfterPseudoElement'),
+  (2205, 'ShapeOutsideMaybeAffectedInlineSize'),
+  (2206, 'ShapeOutsideMaybeAffectedInlinePosition'),
+  (2207, 'GamepadVibrationActuator'),
+  (2208, 'MicrophoneDisabledByFeaturePolicyEstimate'),
+  (2209, 'CameraDisabledByFeaturePolicyEstimate'),
+  (2210, 'MidiDisabledByFeaturePolicy'),
+  (2211, 'DocumentGetPreferredStylesheetSet'),
+  (2212, 'DocumentGetSelectedStylesheetSet'),
+  (2213, 'DocumentSetSelectedStylesheetSet'),
+  (2214, 'GeolocationGetCurrentPosition'),
+  (2215, 'GeolocationWatchPosition'),
+  (2216, 'OBSOLETE_DataUriHasOctothorpe'),
+  (2217, 'NetInfoSaveData'),
+  (2218, 'V8Element_GetClientRects_Method'),
+  (2219, 'V8Element_GetBoundingClientRect_Method'),
+  (2220, 'V8Range_GetClientRects_Method'),
+  (2221, 'V8Range_GetBoundingClientRect_Method'),
+  (2222, 'V8ErrorCaptureStackTrace'),
+  (2223, 'V8ErrorPrepareStackTrace'),
+  (2224, 'V8ErrorStackTraceLimit'),
+  (2225, 'PaintWorklet'),
+  (2226, 'DocumentPageHideRegistered'),
+  (2227, 'DocumentPageHideFired'),
+  (2228, 'DocumentPageShowRegistered'),
+  (2229, 'DocumentPageShowFired'),
+  (2230, 'ReplaceCharsetInXHR'),
+  (2231, 'OBSOLETE_RespondToSameOriginRequestWithCrossOriginResponse'),
+  (2232, 'LinkRelModulePreload'),
+  (2236, 'CSPWithUnsafeEval'),
+  (2237, 'WebAssemblyInstantiation'),
+  (2238, 'V8IndexAccessor'),
+  (2239, 'V8MediaCapabilities_DecodingInfo_Method'),
+  (2240, 'V8MediaCapabilities_EncodingInfo_Method'),
+  (2241, 'V8MediaCapabilitiesInfo_Supported_AttributeGetter'),
+  (2242, 'V8MediaCapabilitiesInfo_Smooth_AttributeGetter'),
+  (2243, 'V8MediaCapabilitiesInfo_PowerEfficient_AttributeGetter'),
+  (2244, 'OBSOLETE_WindowEventInV0ShadowTree'),
+  (2245, 'OBSOLETE_HTMLAnchorElementDownloadInSandboxWithUserGesture'),
+  (2246, 'OBSOLETE_HTMLAnchorElementDownloadInSandboxWithoutUserGesture'),
+  (2247, 'WindowOpenRealmMismatch'),
+  (2248, 'GridRowTrackPercentIndefiniteHeight'),
+  (2249, 'VRGetDisplaysSupportsPresent'),
+  (2250, 'DuplicatedAttribute'),
+  (2251, 'DuplicatedAttributeForExecutedScript'),
+  (2252, 'V8RTCPeerConnection_GetSenders_Method'),
+  (2253, 'V8RTCPeerConnection_GetReceivers_Method'),
+  (2254, 'V8RTCPeerConnection_AddTrack_Method'),
+  (2255, 'V8RTCPeerConnection_RemoveTrack_Method'),
+  (2256, 'LocalCSSFile'),
+  (2257, 'LocalCSSFileExtensionRejected'),
+  (2258, 'UserMediaDisableHardwareNoiseSuppression'),
+  (2259, 'CertificateTransparencyRequiredErrorOnResourceLoad'),
+  (2260, 'CSSSelectorPseudoWebkitAnyLink'),
+  (2261, 'AudioWorkletAddModule'),
+  (2262, 'AudioWorkletGlobalScopeRegisterProcessor'),
+  (2263, 'AudioWorkletNodeConstructor'),
+  (2264, 'HTMLMediaElementEmptyLoadWithFutureData'),
+  (2265, 'CSSValueDisplayContents'),
+  (2266, 'CSSSelectorPseudoAnyLink'),
+  (2267, 'FileAccessedCache'),
+  (2268, 'FileAccessedCookies'),
+  (2269, 'FileAccessedDatabase'),
+  (2270, 'FileAccessedFileSystem'),
+  (2271, 'FileAccessedLocalStorage'),
+  (2272, 'FileAccessedLocks'),
+  (2273, 'FileAccessedServiceWorker'),
+  (2274, 'FileAccessedSessionStorage'),
+  (2275, 'FileAccessedSharedWorker'),
+  (2276, 'V8MediaKeys_GetStatusForPolicy_Method'),
+  (2277, 'V8DeoptimizerDisableSpeculation'),
+  (2278, 'CSSSelectorCue'),
+  (2279, 'CSSSelectorWebkitCalendarPickerIndicator'),
+  (2280, 'CSSSelectorWebkitClearButton'),
+  (2281, 'CSSSelectorWebkitColorSwatch'),
+  (2282, 'CSSSelectorWebkitColorSwatchWrapper'),
+  (2283, 'CSSSelectorWebkitDateAndTimeValue'),
+  (2284, 'CSSSelectorWebkitDatetimeEdit'),
+  (2285, 'CSSSelectorWebkitDatetimeEditAmpmField'),
+  (2286, 'CSSSelectorWebkitDatetimeEditDayField'),
+  (2287, 'CSSSelectorWebkitDatetimeEditFieldsWrapper'),
+  (2288, 'CSSSelectorWebkitDatetimeEditHourField'),
+  (2289, 'CSSSelectorWebkitDatetimeEditMillisecondField'),
+  (2290, 'CSSSelectorWebkitDatetimeEditMinuteField'),
+  (2291, 'CSSSelectorWebkitDatetimeEditMonthField'),
+  (2292, 'CSSSelectorWebkitDatetimeEditSecondField'),
+  (2293, 'CSSSelectorWebkitDatetimeEditText'),
+  (2294, 'CSSSelectorWebkitDatetimeEditWeekField'),
+  (2295, 'CSSSelectorWebkitDatetimeEditYearField'),
+  (2296, 'OBSOLETE_CSSSelectorWebkitDetailsMarker'),
+  (2297, 'CSSSelectorWebkitFileUploadButton'),
+  (2298, 'CSSSelectorWebkitInnerSpinButton'),
+  (2299, 'CSSSelectorWebkitInputPlaceholder'),
+  (2300, 'CSSSelectorWebkitMediaSliderContainer'),
+  (2301, 'CSSSelectorWebkitMediaSliderThumb'),
+  (2302, 'CSSSelectorWebkitMediaTextTrackContainer'),
+  (2303, 'CSSSelectorWebkitMediaTextTrackDisplay'),
+  (2304, 'CSSSelectorWebkitMediaTextTrackRegion'),
+  (2305, 'CSSSelectorWebkitMediaTextTrackRegionContainer'),
+  (2306, 'CSSSelectorWebkitMeterBar'),
+  (2307, 'CSSSelectorWebkitMeterEvenLessGoodValue'),
+  (2308, 'CSSSelectorWebkitMeterInnerElement'),
+  (2309, 'CSSSelectorWebkitMeterOptimumValue'),
+  (2310, 'CSSSelectorWebkitMeterSuboptimumValue'),
+  (2311, 'CSSSelectorWebkitProgressBar'),
+  (2312, 'CSSSelectorWebkitProgressInnerElement'),
+  (2313, 'CSSSelectorWebkitProgressValue'),
+  (2314, 'CSSSelectorWebkitSearchCancelButton'),
+  (2315, 'CSSSelectorWebkitSliderContainer'),
+  (2316, 'CSSSelectorWebkitSliderRunnableTrack'),
+  (2317, 'CSSSelectorWebkitSliderThumb'),
+  (2318, 'CSSSelectorWebkitTextfieldDecorationContainer'),
+  (2319, 'CSSSelectorWebkitUnknownPseudo'),
+  (2320, 'FilterAsContainingBlockMayChangeOutput'),
+  (2321, 'OBSOLETE_DispatchMouseUpDownEventOnDisabledFormControl'),
+  (2322, 'CSSSelectorPseudoIs'),
+  (2323, 'V8RTCRtpSender_ReplaceTrack_Method'),
+  (2324, 'InputTypeFileSecureOriginOpenChooser'),
+  (2325, 'InputTypeFileInsecureOriginOpenChooser'),
+  (2326, 'BasicShapeEllipseNoRadius'),
+  (2327, 'OBSOLETE_BasicShapeEllipseOneRadius'),
+  (2328, 'BasicShapeEllipseTwoRadius'),
+  (2329, 'TemporalInputTypeChooserByTrustedClick'),
+  (2330, 'TemporalInputTypeChooserByUntrustedClick'),
+  (2331, 'TemporalInputTypeIgnoreUntrustedClick'),
+  (2332, 'ColorInputTypeChooserByTrustedClick'),
+  (2333, 'ColorInputTypeChooserByUntrustedClick'),
+  (2334, 'CSSTypedOMStylePropertyMap'),
+  (2335, 'OBSOLETE_ScrollToFragmentRequested'),
+  (2336, 'OBSOLETE_ScrollToFragmentSucceedWithRaw'),
+  (2337, 'OBSOLETE_ScrollToFragmentSucceedWithASCII'),
+  (2338, 'OBSOLETE_ScrollToFragmentSucceedWithUTF8'),
+  (2339, 'OBSOLETE_ScrollToFragmentSucceedWithIsomorphic'),
+  (2340, 'OBSOLETE_ScrollToFragmentSucceedWithMixed'),
+  (2341, 'OBSOLETE_ScrollToFragmentFailWithASCII'),
+  (2342, 'OBSOLETE_ScrollToFragmentFailWithUTF8'),
+  (2343, 'OBSOLETE_ScrollToFragmentFailWithIsomorphic'),
+  (2344, 'OBSOLETE_ScrollToFragmentFailWithMixed'),
+  (2345, 'OBSOLETE_ScrollToFragmentFailWithInvalidEncoding'),
+  (2346, 'RTCPeerConnectionWithActiveCsp'),
+  (2347, 'ImageDecodingAttribute'),
+  (2348, 'ImageDecodeAPI'),
+  (2349, 'V8HTMLElement_Autocapitalize_AttributeGetter'),
+  (2350, 'V8HTMLElement_Autocapitalize_AttributeSetter'),
+  (2351, 'CSSLegacyAlignment'),
+  (2352, 'SRISignatureCheck'),
+  (2353, 'SRISignatureSuccess'),
+  (2354, 'CSSBasicShape'),
+  (2355, 'CSSGradient'),
+  (2356, 'CSSPaintFunction'),
+  (2357, 'WebkitCrossFade'),
+  (2358, 'DisablePictureInPictureAttribute'),
+  (
+    2359,
+    'OBSOLETE_CertificateTransparencyNonCompliantSubresourceInMainFrame'),
+  (2360, 'OBSOLETE_CertificateTransparencyNonCompliantResourceInSubframe'),
+  (2361, 'V8AbortController_Constructor'),
+  (2362, 'ReplaceCharsetInXHRIgnoringCase'),
+  (2363, 'HTMLIFrameElementGestureMedia'),
+  (2364, 'WorkletAddModule'),
+  (2365, 'AnimationWorkletRegisterAnimator'),
+  (2366, 'WorkletAnimationConstructor'),
+  (2367, 'ScrollTimelineConstructor'),
+  (2368, 'V8Document_CreateTouchList_Method'),
+  (2369, 'AsyncClipboardAPIRead'),
+  (2370, 'AsyncClipboardAPIWrite'),
+  (2371, 'AsyncClipboardAPIReadText'),
+  (2372, 'AsyncClipboardAPIWriteText'),
+  (2373, 'OpenerNavigationWithoutGesture'),
+  (2374, 'OBSOLETE_GetComputedStyleWebkitAppearance'),
+  (2375, 'V8LockManager_Request_Method'),
+  (2376, 'V8LockManager_Query_Method'),
+  (2377, 'UserMediaEnableExperimentalHardwareEchoCancellation'),
+  (2378, 'V8RTCDTMFSender_Track_AttributeGetter'),
+  (2379, 'V8RTCDTMFSender_Duration_AttributeGetter'),
+  (2380, 'V8RTCDTMFSender_InterToneGap_AttributeGetter'),
+  (2381, 'V8RTCRtpSender_Dtmf_AttributeGetter'),
+  (2382, 'RTCConstraintEnableDtlsSrtpTrue'),
+  (2383, 'RTCConstraintEnableDtlsSrtpFalse'),
+  (2384, 'DeprecatedRtcPeerConnectionId'),
+  (2385, 'V8PaintWorkletGlobalScope_RegisterPaint_Method'),
+  (2386, 'V8PaintWorkletGlobalScope_DevicePixelRatio_AttributeGetter'),
+  (2387, 'CSSSelectorPseudoFocus'),
+  (2388, 'CSSSelectorPseudoFocusVisible'),
+  (2389, 'DistrustedLegacySymantecSubresource'),
+  (2390, 'VRDisplayGetFrameData'),
+  (2391, 'XMLHttpRequestResponseXML'),
+  (2392, 'MessagePortTransferClosedPort'),
+  (2393, 'RTCLocalSdpModification'),
+  (2394, 'KeyboardApiLock'),
+  (2395, 'KeyboardApiUnlock'),
+  (2396, 'PPAPIURLRequestStreamToFile'),
+  (2397, 'PaymentHandler'),
+  (2398, 'PaymentRequestShowWithoutGesture'),
+  (2399, 'ReadableStreamConstructor'),
+  (2400, 'WritableStreamConstructor'),
+  (2401, 'TransformStreamConstructor'),
+  (2402, 'NegativeBackgroundSize'),
+  (2403, 'NegativeMaskSize'),
+  (2404, 'ClientHintsRtt_DEPRECATED'),
+  (2405, 'ClientHintsDownlink_DEPRECATED'),
+  (2406, 'ClientHintsEct_DEPRECATED'),
+  (2407, 'CrossOriginHTMLIFrameElementContentDocument'),
+  (2408, 'CrossOriginHTMLIFrameElementGetSVGDocument'),
+  (2409, 'CrossOriginHTMLEmbedElementGetSVGDocument'),
+  (2410, 'CrossOriginHTMLFrameElementContentDocument'),
+  (2411, 'CrossOriginHTMLObjectElementContentDocument'),
+  (2412, 'CrossOriginHTMLObjectElementGetSVGDocument'),
+  (2413, 'NavigatorXR'),
+  (2414, 'XRRequestDevice'),
+  (2415, 'XRRequestSession'),
+  (2416, 'XRSupportsSession'),
+  (2417, 'XRSessionGetInputSources'),
+  (2418, 'CSSResizeAuto'),
+  (2419, 'PrefixedCursorGrab'),
+  (2420, 'PrefixedCursorGrabbing'),
+  (2421, 'CredentialManagerCreatePublicKeyCredential'),
+  (2422, 'CredentialManagerGetPublicKeyCredential'),
+  (2423, 'CredentialManagerMakePublicKeyCredentialSuccess'),
+  (2424, 'CredentialManagerGetPublicKeyCredentialSuccess'),
+  (2425, 'ShapeOutsideContentBox'),
+  (2426, 'ShapeOutsidePaddingBox'),
+  (2427, 'ShapeOutsideBorderBox'),
+  (2428, 'ShapeOutsideMarginBox'),
+  (2429, 'PerformanceTimeline'),
+  (2430, 'UserTiming'),
+  (2431, 'CSSSelectorPseudoWhere'),
+  (2432, 'KeyboardApiGetLayoutMap'),
+  (2433, 'WebRtcVaapiHWVP8Encoding'),
+  (2434, 'PerformanceResourceTimingInitiatorType'),
+  (2435, 'PaymentRequestInvalidCurrencyCode'),
+  (2436, 'V8ArraySortNoElementsProtector'),
+  (2437, 'OBSOLETE_V8ArrayPrototypeSortJSArrayModifiedPrototype'),
+  (2438, 'V8Document_PictureInPictureEnabled_AttributeGetter'),
+  (2439, 'V8Document_PictureInPictureElement_AttributeGetter'),
+  (2440, 'V8Document_ExitPictureInPicture_Method'),
+  (2441, 'V8ShadowRoot_PictureInPictureElement_AttributeGetter'),
+  (2442, 'V8HTMLVideoElement_DisablePictureInPicture_AttributeGetter'),
+  (2443, 'V8HTMLVideoElement_DisablePictureInPicture_AttributeSetter'),
+  (2444, 'V8HTMLVideoElement_RequestPictureInPicture_Method'),
+  (2445, 'EnterPictureInPictureEventListener'),
+  (2446, 'LeavePictureInPictureEventListener'),
+  (2447, 'V8PictureInPictureWindow_Height_AttributeGetter'),
+  (2448, 'V8PictureInPictureWindow_Width_AttributeGetter'),
+  (2449, 'PictureInPictureWindowResizeEventListener'),
+  (2450, 'V8CookieStore_Delete_Method'),
+  (2451, 'V8CookieStore_Get_Method'),
+  (2452, 'V8CookieStore_GetAll_Method'),
+  (2453, 'V8CookieStore_GetChangeSubscriptions_Method'),
+  (2454, 'V8CookieStore_Has_Method'),
+  (2455, 'V8CookieStore_Set_Method'),
+  (2456, 'V8CookieStore_SubscribeToChanges_Method'),
+  (2457, 'V8CookieChangeEvent_Changed_AttributeGetter'),
+  (2458, 'V8CookieChangeEvent_Deleted_AttributeGetter'),
+  (2459, 'V8ExtendableCookieChangeEvent_Changed_AttributeGetter'),
+  (2460, 'V8ExtendableCookieChangeEvent_Deleted_AttributeGetter'),
+  (2461, 'ShapeOutsideContentBoxDifferentFromMarginBox'),
+  (2462, 'ShapeOutsidePaddingBoxDifferentFromMarginBox'),
+  (2463, 'DeprecatedCSSContainLayoutPositionedDescendants'),
+  (2465, 'CanvasConvertToBlob'),
+  (2466, 'PolymerV1Detected'),
+  (2467, 'PolymerV2Detected'),
+  (2468, 'PerformanceEventTimingBuffer'),
+  (2469, 'PerformanceEventTimingConstructor'),
+  (2470, 'ReverseIterateDOMStorage'),
+  (2471, 'TextToSpeech_Speak'),
+  (2472, 'TextToSpeech_SpeakCrossOrigin'),
+  (2473, 'TextToSpeech_SpeakDisallowedByAutoplay'),
+  (2474, 'StaleWhileRevalidateEnabled'),
+  (2475, 'MediaElementSourceOnOfflineContext'),
+  (2476, 'OBSOLETE_MediaStreamDestinationOnOfflineContext'),
+  (2477, 'OBSOLETE_MediaStreamSourceOnOfflineContext'),
+  (2478, 'RTCDataChannelInitMaxRetransmitTime'),
+  (2479, 'RTCPeerConnectionCreateDataChannelMaxPacketLifeTime'),
+  (2480, 'V8SpeechGrammarList_AddFromUri_Method'),
+  (2481, 'V8SpeechRecognitionEvent_Interpretation_AttributeGetter'),
+  (2482, 'V8SpeechRecognitionEvent_Emma_AttributeGetter'),
+  (2483, 'V8SpeechSynthesis_Speak_Method'),
+  (2484, 'LegacySymantecCertMainFrameResource'),
+  (2485, 'LegacySymantecCertInSubresource'),
+  (2486, 'LegacySymantecCertInSubframeMainResource'),
+  (2487, 'EventTimingExplicitlyRequested'),
+  (2488, 'CSSEnvironmentVariable'),
+  (2489, 'CSSEnvironmentVariable_SafeAreaInsetTop'),
+  (2490, 'CSSEnvironmentVariable_SafeAreaInsetLeft'),
+  (2491, 'CSSEnvironmentVariable_SafeAreaInsetBottom'),
+  (2492, 'CSSEnvironmentVariable_SafeAreaInsetRight'),
+  (2493, 'MediaControlsDisplayCutoutGesture'),
+  (2494, 'DocumentOpenTwoArgs'),
+  (2495, 'DocumentOpenTwoArgsWithReplace'),
+  (2496, 'DocumentOpenThreeArgs'),
+  (2497, 'V8FunctionTokenOffsetTooLongForToString'),
+  (2498, 'ServiceWorkerImportScriptNotInstalled'),
+  (2499, 'NestedDedicatedWorker'),
+  (2500, 'OBSOLETE_ClientHintsMetaAcceptCHLifetime'),
+  (2501, 'OBSOLETE_DOMNodeRemovedEventDelayed'),
+  (2502, 'OBSOLETE_DOMNodeRemovedEventHandlerAccessDetachingNode'),
+  (2503, 'OBSOLETE_DOMNodeRemovedEventListenedAtNonTarget'),
+  (2504, 'OBSOLETE_DOMNodeRemovedFromDocumentEventDelayed'),
+  (
+    2505,
+    'OBSOLETE_DOMNodeRemovedFromDocumentEventHandlerAccessDetachingNode'),
+  (2506, 'OBSOLETE_DOMNodeRemovedFromDocumentEventListenedAtNonTarget'),
+  (2507, 'CSSFillAvailableLogicalWidth'),
+  (2508, 'CSSFillAvailableLogicalHeight'),
+  (2509, 'PopupOpenWhileFileChooserOpened'),
+  (2510, 'CookieStoreAPI'),
+  (2511, 'FeaturePolicyJSAPI'),
+  (2512, 'V8RTCPeerConnection_GetTransceivers_Method'),
+  (2513, 'V8RTCPeerConnection_AddTransceiver_Method'),
+  (2514, 'V8RTCRtpTransceiver_Direction_AttributeGetter'),
+  (2515, 'V8RTCRtpTransceiver_Direction_AttributeSetter'),
+  (2516, 'HTMLLinkElementDisabledByParser'),
+  (2517, 'RequestIsHistoryNavigation'),
+  (2518, 'AddDocumentLevelPassiveTrueWheelEventListener'),
+  (2519, 'AddDocumentLevelPassiveFalseWheelEventListener'),
+  (2520, 'AddDocumentLevelPassiveDefaultWheelEventListener'),
+  (2521, 'DocumentLevelPassiveDefaultEventListenerPreventedWheel'),
+  (2522, 'OBSOLETE_ShapeDetectionAPI'),
+  (2523, 'V8SourceBuffer_ChangeType_Method'),
+  (2524, 'PPAPIWebSocket'),
+  (2525, 'V8MediaStreamTrack_ContentHint_AttributeGetter'),
+  (2526, 'V8MediaStreamTrack_ContentHint_AttributeSetter'),
+  (2527, 'V8IDBFactory_Open_Method'),
+  (2528, 'EvaluateScriptMovedBetweenDocuments'),
+  (2529, 'ReportingObserver'),
+  (2530, 'DeprecationReport'),
+  (2531, 'InterventionReport'),
+  (2532, 'V8WasmSharedMemory'),
+  (2533, 'V8WasmThreadOpcodes'),
+  (2534, 'CacheStorageAddAllSuccessWithDuplicate'),
+  (2535, 'OBSOLETE_LegendDelegateFocusOrAccessKey'),
+  (2536, 'FeaturePolicyReport'),
+  (2537, 'V8Window_WebkitRTCPeerConnection_ConstructorGetter'),
+  (2538, 'V8Window_WebkitMediaStream_ConstructorGetter'),
+  (2539, 'TextEncoderStreamConstructor'),
+  (2540, 'TextDecoderStreamConstructor'),
+  (2541, 'SignedExchangeInnerResponse'),
+  (2542, 'PaymentAddressLanguageCode'),
+  (2543, 'DocumentDomainBlockedCrossOriginAccess'),
+  (2544, 'DocumentDomainEnabledCrossOriginAccess'),
+  (2545, 'SerialGetPorts'),
+  (2546, 'SerialRequestPort'),
+  (2547, 'SerialPortOpen'),
+  (2548, 'SerialPortClose'),
+  (2549, 'BackgroundFetchManagerFetch'),
+  (2550, 'BackgroundFetchManagerGet'),
+  (2551, 'BackgroundFetchManagerGetIds'),
+  (2552, 'BackgroundFetchRegistrationAbort'),
+  (2553, 'BackgroundFetchRegistrationMatch'),
+  (2554, 'BackgroundFetchRegistrationMatchAll'),
+  (2555, 'V8AtomicsNotify'),
+  (2556, 'V8AtomicsWake'),
+  (2557, 'FormDisabledAttributePresent'),
+  (2558, 'FormDisabledAttributePresentAndSubmit'),
+  (2559, 'CSSValueAppearanceCheckboxRendered'),
+  (2560, 'OBSOLETE_CSSValueAppearanceCheckboxForOthersRendered'),
+  (2561, 'CSSValueAppearanceRadioRendered'),
+  (2562, 'OBSOLETE_CSSValueAppearanceRadioForOthersRendered'),
+  (2563, 'CSSValueAppearanceInnerSpinButtonRendered'),
+  (2564, 'OBSOLETE_CSSValueAppearanceInnerSpinButtonForOthersRendered'),
+  (2565, 'CSSValueAppearanceMenuListRendered'),
+  (2566, 'OBSOLETE_CSSValueAppearanceMenuListForOthersRendered'),
+  (2567, 'CSSValueAppearanceProgressBarRendered'),
+  (2568, 'CSSValueAppearanceSliderHorizontalRendered'),
+  (2569, 'OBSOLETE_CSSValueAppearanceSliderHorizontalForOthersRendered'),
+  (2570, 'CSSValueAppearanceSliderVerticalRendered'),
+  (2571, 'OBSOLETE_CSSValueAppearanceSliderVerticalForOthersRendered'),
+  (2572, 'CSSValueAppearanceSliderThumbHorizontalRendered'),
+  (2573, 'OBSOLETE_CSSValueAppearanceSliderThumbHorizontalForOthersRendered'),
+  (2574, 'CSSValueAppearanceSliderThumbVerticalRendered'),
+  (2575, 'OBSOLETE_CSSValueAppearanceSliderThumbVerticalForOthersRendered'),
+  (2576, 'CSSValueAppearanceSearchFieldRendered'),
+  (2577, 'OBSOLETE_CSSValueAppearanceSearchFieldForOthersRendered'),
+  (2578, 'CSSValueAppearanceSearchCancelRendered'),
+  (2579, 'OBSOLETE_CSSValueAppearanceSearchCancelForOthersRendered'),
+  (2580, 'CSSValueAppearanceTextAreaRendered'),
+  (2581, 'OBSOLETE_CSSValueAppearanceTextAreaForOthersRendered'),
+  (2582, 'CSSValueAppearanceMenuListButtonRendered'),
+  (2583, 'OBSOLETE_CSSValueAppearanceMenuListButtonForOthersRendered'),
+  (2584, 'CSSValueAppearancePushButtonRendered'),
+  (2585, 'OBSOLETE_CSSValueAppearancePushButtonForOthersRendered'),
+  (2586, 'CSSValueAppearanceSquareButtonRendered'),
+  (2587, 'OBSOLETE_CSSValueAppearanceSquareButtonForOthersRendered'),
+  (2588, 'OBSOLETE_GetComputedStyleForWebkitAppearanceExcludeDevTools'),
+  (2589, 'CursorImageLE32x32'),
+  (2590, 'CursorImageGT32x32'),
+  (2591, 'OBSOLETE_RTCPeerConnectionComplexPlanBSdpUsingDefaultSdpSemantics'),
+  (2592, 'ResizeObserver_Constructor'),
+  (2593, 'Collator'),
+  (2594, 'NumberFormat'),
+  (2595, 'DateTimeFormat'),
+  (2596, 'PluralRules'),
+  (2597, 'RelativeTimeFormat'),
+  (2598, 'Locale'),
+  (2599, 'ListFormat'),
+  (2600, 'Segmenter'),
+  (2601, 'StringLocaleCompare'),
+  (2602, 'OBSOLETE_StringToLocaleUpperCase'),
+  (2603, 'StringToLocaleLowerCase'),
+  (2604, 'NumberToLocaleString'),
+  (2605, 'DateToLocaleString'),
+  (2606, 'DateToLocaleDateString'),
+  (2607, 'DateToLocaleTimeString'),
+  (2608, 'MalformedCSP'),
+  (2609, 'V8AttemptOverrideReadOnlyOnPrototypeSloppy'),
+  (2610, 'V8AttemptOverrideReadOnlyOnPrototypeStrict'),
+  (2611, 'HTMLCanvasElementLowLatency'),
+  (2612, 'OBSOLETE_V8OptimizedFunctionWithOneShotBytecode'),
+  (2613, 'SVGGeometryPropertyHasNonZeroUnitlessValue'),
+  (2614, 'CSSValueAppearanceNoImplementationSkipBorder'),
+  (2615, 'InstantiateModuleScript'),
+  (2616, 'DynamicImportModuleScript'),
+  (2617, 'HistoryPushState'),
+  (2618, 'HistoryReplaceState'),
+  (2619, 'GetDisplayMedia'),
+  (2620, 'CursorImageGT64x64'),
+  (2621, 'AdClick'),
+  (2622, 'UpdateWithoutShippingOptionOnShippingAddressChange'),
+  (2623, 'UpdateWithoutShippingOptionOnShippingOptionChange'),
+  (2624, 'CSSSelectorEmptyWhitespaceOnlyFail'),
+  (2625, 'ActivatedImplicitRootScroller'),
+  (2626, 'CSSUnknownNamespacePrefixInSelector'),
+  (2627, 'PageLifeCycleFreeze'),
+  (2628, 'OBSOLETE_DefaultInCustomIdent'),
+  (2629, 'HTMLAnchorElementHrefTranslateAttribute'),
+  (2630, 'WebKitUserModifyEffective'),
+  (2631, 'PlainTextEditingEffective'),
+  (2632, 'OBSOLETE_NavigationDownloadInSandboxWithUserGesture'),
+  (2633, 'OBSOLETE_NavigationDownloadInSandboxWithoutUserGesture'),
+  (2634, 'OBSOLETE_LegacyTLSVersionInMainFrameResource'),
+  (2635, 'OBSOLETE_LegacyTLSVersionInSubresource'),
+  (2636, 'OBSOLETE_LegacyTLSVersionInSubframeMainResource'),
+  (2637, 'RTCMaxAudioBufferSize'),
+  (2638, 'WebKitUserModifyReadWriteEffective'),
+  (2639, 'WebKitUserModifyReadOnlyEffective'),
+  (2640, 'WebKitUserModifyPlainTextEffective'),
+  (2641, 'CSSAtRuleFontFeatureValues'),
+  (2642, 'FlexboxSingleLineAlignContent'),
+  (2643, 'SignedExchangeInnerResponseInMainFrame'),
+  (2644, 'SignedExchangeInnerResponseInSubFrame'),
+  (2645, 'OBSOLETE_CSSSelectorNotWithValidList'),
+  (2646, 'OBSOLETE_CSSSelectorNotWithInvalidList'),
+  (2647, 'OBSOLETE_CSSSelectorNotWithPartiallyValidList'),
+  (2648, 'V8IDBFactory_Databases_Method'),
+  (2649, 'OpenerNavigationDownloadCrossOrigin'),
+  (2650, 'V8RegExpMatchIsTrueishOnNonJSRegExp'),
+  (2651, 'V8RegExpMatchIsFalseishOnJSRegExp'),
+  (2652, 'OBSOLETE_DownloadInAdFrameWithUserGesture'),
+  (2653, 'DownloadInAdFrameWithoutUserGesture'),
+  (2654, 'NavigatorAppVersion'),
+  (2655, 'NavigatorDoNotTrack'),
+  (2656, 'NavigatorHardwareConcurrency'),
+  (2657, 'NavigatorLanguage'),
+  (2658, 'NavigatorLanguages'),
+  (2659, 'NavigatorMaxTouchPoints'),
+  (2660, 'NavigatorMimeTypes'),
+  (2661, 'NavigatorPlatform'),
+  (2662, 'NavigatorPlugins'),
+  (2663, 'NavigatorUserAgent'),
+  (2664, 'WebBluetoothRequestScan'),
+  (2665, 'V8SVGGeometryElement_IsPointInFill_Method'),
+  (2666, 'V8SVGGeometryElement_IsPointInStroke_Method'),
+  (2667, 'V8SVGGeometryElement_GetTotalLength_Method'),
+  (2668, 'V8SVGGeometryElement_GetPointAtLength_Method'),
+  (2669, 'OffscreenCanvasTransferToImageBitmap'),
+  (2670, 'OffscreenCanvasIsPointInPath'),
+  (2671, 'OffscreenCanvasIsPointInStroke'),
+  (2672, 'OffscreenCanvasMeasureText'),
+  (2673, 'OffscreenCanvasGetImageData'),
+  (2674, 'V8SVGTextContentElement_GetComputedTextLength_Method'),
+  (2675, 'V8SVGTextContentElement_GetEndPositionOfChar_Method'),
+  (2676, 'V8SVGTextContentElement_GetExtentOfChar_Method'),
+  (2677, 'V8SVGTextContentElement_GetStartPositionOfChar_Method'),
+  (2678, 'V8SVGTextContentElement_GetSubStringLength_Method'),
+  (2679, 'V8BatteryManager_ChargingTime_AttributeGetter'),
+  (2680, 'V8BatteryManager_Charging_AttributeGetter'),
+  (2681, 'V8BatteryManager_DischargingTime_AttributeGetter'),
+  (2682, 'V8BatteryManager_Level_AttributeGetter'),
+  (2683, 'V8PaintRenderingContext2D_IsPointInPath_Method'),
+  (2684, 'V8PaintRenderingContext2D_IsPointInStroke_Method'),
+  (2685, 'V8PaymentRequest_CanMakePayment_Method'),
+  (2686, 'V8AnalyserNode_GetByteFrequencyData_Method'),
+  (2687, 'V8AnalyserNode_GetByteTimeDomainData_Method'),
+  (2688, 'V8AnalyserNode_GetFloatFrequencyData_Method'),
+  (2689, 'V8AnalyserNode_GetFloatTimeDomainData_Method'),
+  (2690, 'V8AudioBuffer_CopyFromChannel_Method'),
+  (2691, 'V8AudioBuffer_GetChannelData_Method'),
+  (2692, 'WebGLDebugRendererInfo'),
+  (2693, 'V8WebGL2ComputeRenderingContext_GetExtension_Method'),
+  (2694, 'V8WebGL2ComputeRenderingContext_GetSupportedExtensions_Method'),
+  (2695, 'V8WebGL2RenderingContext_GetExtension_Method'),
+  (2696, 'V8WebGL2RenderingContext_GetSupportedExtensions_Method'),
+  (2697, 'V8WebGLRenderingContext_GetExtension_Method'),
+  (2698, 'V8WebGLRenderingContext_GetSupportedExtensions_Method'),
+  (2699, 'V8Screen_AvailHeight_AttributeGetter'),
+  (2700, 'V8Screen_AvailWidth_AttributeGetter'),
+  (2701, 'V8Screen_ColorDepth_AttributeGetter'),
+  (2702, 'V8Screen_Height_AttributeGetter'),
+  (2703, 'V8Screen_PixelDepth_AttributeGetter'),
+  (2704, 'V8Screen_Width_AttributeGetter'),
+  (2705, 'WindowInnerWidth'),
+  (2706, 'WindowInnerHeight'),
+  (2707, 'V8Window_MatchMedia_Method'),
+  (2708, 'WindowScrollX'),
+  (2709, 'WindowScrollY'),
+  (2710, 'WindowPageXOffset'),
+  (2711, 'WindowPageYOffset'),
+  (2712, 'WindowScreenX'),
+  (2713, 'WindowScreenY'),
+  (2714, 'WindowOuterHeight'),
+  (2715, 'WindowOuterWidth'),
+  (2716, 'WindowDevicePixelRatio'),
+  (2717, 'CanvasCaptureStream'),
+  (2718, 'V8HTMLMediaElement_CanPlayType_Method'),
+  (2719, 'HistoryLength'),
+  (2720, 'FeaturePolicyReportOnlyHeader'),
+  (2721, 'V8PaymentRequest_HasEnrolledInstrument_Method'),
+  (2722, 'TrustedTypesEnabled'),
+  (2723, 'TrustedTypesCreatePolicy'),
+  (2724, 'TrustedTypesDefaultPolicyCreated'),
+  (2725, 'TrustedTypesAssignmentError'),
+  (2726, 'BadgeSet'),
+  (2727, 'BadgeClear'),
+  (2728, 'ElementTimingExplicitlyRequested'),
+  (2729, 'V8HTMLMediaElement_CaptureStream_Method'),
+  (2730, 'QuirkyLineBoxBackgroundSize'),
+  (2731, 'DirectlyCompositedImage'),
+  (2732, 'ForbiddenSyncXhrInPageDismissal'),
+  (2733, 'OBSOLETE_V8HTMLVideoElement_AutoPictureInPicture_AttributeGetter'),
+  (2734, 'OBSOLETE_V8HTMLVideoElement_AutoPictureInPicture_AttributeSetter'),
+  (2735, 'OBSOLETE_AutoPictureInPictureAttribute'),
+  (2736, 'OBSOLETE_RTCAudioJitterBufferRtxHandling'),
+  (2737, 'WebShareCanShare'),
+  (2738, 'PriorityHints'),
+  (2739, 'TextAutosizedCrossSiteIframe'),
+  (2740, 'OBSOLETE_V8RTCQuicTransport_Constructor'),
+  (2741, 'OBSOLETE_V8RTCQuicTransport_Transport_AttributeGetter'),
+  (2742, 'OBSOLETE_V8RTCQuicTransport_State_AttributeGetter'),
+  (2743, 'OBSOLETE_V8RTCQuicTransport_GetKey_Method'),
+  (2744, 'OBSOLETE_V8RTCQuicTransport_GetStats_Method'),
+  (2745, 'OBSOLETE_V8RTCQuicTransport_Connect_Method'),
+  (2746, 'OBSOLETE_V8RTCQuicTransport_Listen_Method'),
+  (2747, 'OBSOLETE_V8RTCQuicTransport_Stop_Method'),
+  (2748, 'OBSOLETE_V8RTCQuicTransport_CreateStream_Method'),
+  (2749, 'V8RTCIceTransport_Constructor'),
+  (2750, 'V8RTCIceTransport_Role_AttributeGetter'),
+  (2751, 'V8RTCIceTransport_State_AttributeGetter'),
+  (2752, 'V8RTCIceTransport_GatheringState_AttributeGetter'),
+  (2753, 'V8RTCIceTransport_GetLocalCandidates_Method'),
+  (2754, 'V8RTCIceTransport_GetRemoteCandidates_Method'),
+  (2755, 'V8RTCIceTransport_GetSelectedCandidatePair_Method'),
+  (2756, 'V8RTCIceTransport_GetLocalParameters_Method'),
+  (2757, 'V8RTCIceTransport_GetRemoteParameters_Method'),
+  (2758, 'OBSOLETE_V8RTCQuicStream_Transport_AttributeGetter'),
+  (2759, 'OBSOLETE_V8RTCQuicStream_State_AttributeGetter'),
+  (2760, 'OBSOLETE_V8RTCQuicStream_ReadBufferedAmount_AttributeGetter'),
+  (2761, 'OBSOLETE_V8RTCQuicStream_MaxReadBufferedAmount_AttributeGetter'),
+  (2762, 'OBSOLETE_V8RTCQuicStream_WriteBufferedAmount_AttributeGetter'),
+  (2763, 'OBSOLETE_V8RTCQuicStream_MaxWriteBufferedAmount_AttributeGetter'),
+  (2764, 'OBSOLETE_V8RTCQuicStream_ReadInto_Method'),
+  (2765, 'OBSOLETE_V8RTCQuicStream_Write_Method'),
+  (2766, 'OBSOLETE_V8RTCQuicStream_Reset_Method'),
+  (2767, 'OBSOLETE_V8RTCQuicStream_WaitForWriteBufferedAmountBelow_Method'),
+  (2768, 'OBSOLETE_V8RTCQuicStream_WaitForReadable_Method'),
+  (2769, 'HTMLTemplateElement'),
+  (2770, 'NoSysexWebMIDIWithoutPermission'),
+  (2771, 'NoSysexWebMIDIOnInsecureOrigin'),
+  (2772, 'OBSOLETE_ApplicationCacheInstalledButNoManifest'),
+  (2773, 'PerMethodCanMakePaymentQuota'),
+  (2774, 'OBSOLETE_CSSValueAppearanceButtonForNonButtonRendered'),
+  (2775, 'OBSOLETE_CSSValueAppearanceButtonForOthersRendered'),
+  (2776, 'OBSOLETE_CustomCursorIntersectsViewport'),
+  (2777, 'OBSOLETE_ClientHintsLang'),
+  (2778, 'LinkRelPreloadImageSrcset'),
+  (2779, 'V8HTMLMediaElement_Remote_AttributeGetter'),
+  (2780, 'V8RemotePlayback_WatchAvailability_Method'),
+  (2781, 'V8RemotePlayback_Prompt_Method'),
+  (2782, 'LayoutShiftExplicitlyRequested'),
+  (2783, 'MediaSessionSkipAd'),
+  (2784, 'AdFrameSizeIntervention'),
+  (2785, 'V8UserActivation_HasBeenActive_AttributeGetter'),
+  (2786, 'V8UserActivation_IsActive_AttributeGetter'),
+  (2787, 'TextEncoderEncodeInto'),
+  (2788, 'InvalidBasicCardMethodData'),
+  (2789, 'ClientHintsUA'),
+  (2790, 'ClientHintsUAArch'),
+  (2791, 'ClientHintsUAPlatform'),
+  (2792, 'ClientHintsUAModel'),
+  (2793, 'AnimationFrameCancelledWithinFrame'),
+  (2794, 'SchedulingIsInputPending'),
+  (2795, 'V8StringNormalize'),
+  (2796, 'OBSOLETE_CSSValueAppearanceButtonBevel'),
+  (2797, 'OBSOLETE_CSSValueAppearanceListitem'),
+  (2798, 'OBSOLETE_CSSValueAppearanceMediaControlsBackground'),
+  (2799, 'OBSOLETE_CSSValueAppearanceMediaControlsFullscreenBackground'),
+  (2800, 'OBSOLETE_CSSValueAppearanceMediaCurrentTimeDisplay'),
+  (2801, 'OBSOLETE_CSSValueAppearanceMediaEnterFullscreenButton'),
+  (2802, 'OBSOLETE_CSSValueAppearanceMediaExitFullscreenButton'),
+  (2803, 'OBSOLETE_CSSValueAppearanceMediaMuteButton'),
+  (2804, 'OBSOLETE_CSSValueAppearanceMediaOverlayPlayButton'),
+  (2805, 'OBSOLETE_CSSValueAppearanceMediaPlayButton'),
+  (2806, 'OBSOLETE_CSSValueAppearanceMediaTimeRemainingDisplay'),
+  (2807, 'OBSOLETE_CSSValueAppearanceMediaToggleClosedCaptionsButton'),
+  (2808, 'OBSOLETE_CSSValueAppearanceMediaVolumeSliderContainer'),
+  (2809, 'OBSOLETE_CSSValueAppearanceMenulistTextfield'),
+  (2810, 'OBSOLETE_CSSValueAppearanceMenulistText'),
+  (2811, 'OBSOLETE_CSSValueAppearanceProgressBarValue'),
+  (2812, 'OBSOLETE_U2FCryptotokenRegister'),
+  (2813, 'OBSOLETE_U2FCryptotokenSign'),
+  (2814, 'CSSValueAppearanceInnerSpinButton'),
+  (2815, 'CSSValueAppearanceMeter'),
+  (2816, 'CSSValueAppearanceProgressBar'),
+  (2817, 'OBSOLETE_CSSValueAppearanceProgressBarForOthersRendered'),
+  (2818, 'CSSValueAppearancePushButton'),
+  (2819, 'CSSValueAppearanceSquareButton'),
+  (2820, 'CSSValueAppearanceSearchCancel'),
+  (2821, 'CSSValueAppearanceTextarea'),
+  (2822, 'OBSOLETE_CSSValueAppearanceTextFieldForOthersRendered'),
+  (2823, 'CSSValueAppearanceTextFieldForTemporalRendered'),
+  (2824, 'OBSOLETE_BuiltInModuleKvStorage'),
+  (2825, 'OBSOLETE_BuiltInModuleVirtualScroller'),
+  (2826, 'OBSOLETE_AdClickNavigation'),
+  (2827, 'RTCStatsRelativePacketArrivalDelay'),
+  (2829, 'CSSSelectorHostContextInSnapshotProfile'),
+  (2830, 'CSSSelectorHostContextInLiveProfile'),
+  (2831, 'ImportMap'),
+  (2832, 'RefreshHeader'),
+  (2833, 'SearchEventFired'),
+  (2834, 'IdleDetectionStart'),
+  (2835, 'TargetCurrent'),
+  (2836, 'SandboxBackForwardStaysWithinSubtree'),
+  (2837, 'SandboxBackForwardAffectsFramesOutsideSubtree'),
+  (2838, 'DownloadPrePolicyCheck'),
+  (2839, 'DownloadPostPolicyCheck'),
+  (2840, 'OBSOLETE_DownloadInSandboxWithoutUserGesture'),
+  (2841, 'ReadableStreamGetReader'),
+  (2842, 'ReadableStreamPipeThrough'),
+  (2843, 'ReadableStreamPipeTo'),
+  (2844, 'CSSStyleSheetReplace'),
+  (2845, 'CSSStyleSheetReplaceSync'),
+  (2846, 'AdoptedStyleSheets'),
+  (2847, 'OBSOLETE_HTMLImportsOnReverseOriginTrials'),
+  (2848, 'OBSOLETE_ElementCreateShadowRootOnReverseOriginTrials'),
+  (2849, 'OBSOLETE_DocumentRegisterElementOnReverseOriginTrials'),
+  (2850, 'InputTypeRadio'),
+  (2851, 'InputTypeCheckbox'),
+  (2852, 'InputTypeImage'),
+  (2853, 'InputTypeButton'),
+  (2854, 'InputTypeHidden'),
+  (2855, 'InputTypeReset'),
+  (2856, 'SelectElementSingle'),
+  (2857, 'SelectElementMultiple'),
+  (2858, 'V8Animation_Effect_AttributeGetter'),
+  (2859, 'V8Animation_Effect_AttributeSetter'),
+  (2860, 'HidDeviceClose'),
+  (2861, 'HidDeviceOpen'),
+  (2862, 'HidDeviceReceiveFeatureReport'),
+  (2863, 'HidDeviceSendFeatureReport'),
+  (2864, 'HidDeviceSendReport'),
+  (2865, 'HidGetDevices'),
+  (2866, 'HidRequestDevice'),
+  (2867, 'OBSOLETE_V8RTCQuicTransport_MaxDatagramLength_AttributeGetter'),
+  (2868, 'OBSOLETE_V8RTCQuicTransport_ReadyToSendDatagram_Method'),
+  (2869, 'OBSOLETE_V8RTCQuicTransport_SendDatagram_Method'),
+  (2870, 'OBSOLETE_V8RTCQuicTransport_ReceiveDatagrams_Method'),
+  (2871, 'CSSValueContainStyle'),
+  (2872, 'WebShareSuccessfulContainingFiles'),
+  (2873, 'WebShareSuccessfulWithoutFiles'),
+  (2874, 'WebShareUnsuccessfulContainingFiles'),
+  (2875, 'WebShareUnsuccessfulWithoutFiles'),
+  (2876, 'VerticalScrollbarThumbScrollingWithMouse'),
+  (2877, 'VerticalScrollbarThumbScrollingWithTouch'),
+  (2878, 'HorizontalScrollbarThumbScrollingWithMouse'),
+  (2879, 'HorizontalScrollbarThumbScrollingWithTouch'),
+  (2880, 'WebOTP'),
+  (2881, 'V8Animation_Pending_AttributeGetter'),
+  (2882, 'FocusWithoutUserActivationNotSandboxedNotAdFrame'),
+  (2883, 'FocusWithoutUserActivationNotSandboxedAdFrame'),
+  (2884, 'FocusWithoutUserActivationSandboxedNotAdFrame'),
+  (2885, 'FocusWithoutUserActivationSandboxedAdFrame'),
+  (2886, 'V8RTCRtpReceiver_JitterBufferDelayHint_AttributeGetter'),
+  (2887, 'V8RTCRtpReceiver_JitterBufferDelayHint_AttributeSetter'),
+  (2888, 'MediaCapabilitiesDecodingInfoWithKeySystemConfig'),
+  (2889, 'OBSOLETE_RevertInCustomIdent'),
+  (2890, 'UnoptimizedImagePolicies'),
+  (2891, 'VTTCueParser'),
+  (2892, 'MediaElementTextTrackContainer'),
+  (2893, 'MediaElementTextTrackList'),
+  (2894, 'PaymentRequestInitialized'),
+  (2895, 'PaymentRequestShow'),
+  (2896, 'PaymentRequestShippingAddressChange'),
+  (2897, 'PaymentRequestShippingOptionChange'),
+  (2898, 'PaymentRequestPaymentMethodChange'),
+  (2899, 'V8Animation_UpdatePlaybackRate_Method'),
+  (2900, 'TwoValuedOverflow'),
+  (2901, 'TextFragmentAnchor'),
+  (2902, 'TextFragmentAnchorMatchFound'),
+  (2903, 'NonPassiveTouchEventListener'),
+  (2904, 'PassiveTouchEventListener'),
+  (2905, 'OBSOLETE_CSSValueAppearanceSearchCancelForOthers2Rendered'),
+  (2906, 'WebXrFramebufferScale'),
+  (2907, 'WebXrIgnoreDepthValues'),
+  (2908, 'WebXrSessionCreated'),
+  (2909, 'V8XRReferenceSpace_GetOffsetReferenceSpace_Method'),
+  (2910, 'V8XRInputSource_Gamepad_AttributeGetter'),
+  (2911, 'V8XRSession_End_Method'),
+  (2912, 'V8XRWebGLLayer_Constructor'),
+  (2913, 'FetchKeepalive'),
+  (2914, 'CSSTransitionCancelledByRemovingStyle'),
+  (2915, 'V8RTCRtpSender_SetStreams_Method'),
+  (2916, 'CookieNoSameSite'),
+  (2917, 'CookieInsecureAndSameSiteNone'),
+  (2918, 'UnsizedMediaPolicy'),
+  (2919, 'ScrollByPrecisionTouchPad'),
+  (2920, 'PinchZoom'),
+  (2921, 'OBSOLETE_BuiltInModuleSwitchImported'),
+  (2922, 'FeaturePolicyCommaSeparatedDeclarations'),
+  (2923, 'FeaturePolicySemicolonSeparatedDeclarations'),
+  (2924, 'V8CallSiteAPIGetFunctionSloppyCall'),
+  (2925, 'V8CallSiteAPIGetThisSloppyCall'),
+  (2926, 'OBSOLETE_BuiltInModuleToast'),
+  (2927, 'LargestContentfulPaintExplicitlyRequested'),
+  (2928, 'PageFreezeOptIn'),
+  (2929, 'PageFreezeOptOut'),
+  (2930, 'PeriodicBackgroundSync'),
+  (2931, 'PeriodicBackgroundSyncRegister'),
+  (2932, 'LazyLoadFrameLoadingAttributeEager'),
+  (2933, 'LazyLoadFrameLoadingAttributeLazy'),
+  (2934, 'LazyLoadImageLoadingAttributeEager'),
+  (2935, 'LazyLoadImageLoadingAttributeLazy'),
+  (2936, 'LazyLoadImageMissingDimensionsForLazy'),
+  (2937, 'PeriodicBackgroundSyncGetTags'),
+  (2938, 'PeriodicBackgroundSyncUnregister'),
+  (2939, 'CreateObjectURLMediaSourceFromWorker'),
+  (2940, 'CSSAtRuleProperty'),
+  (2941, 'ServiceWorkerInterceptedRequestFromOriginDirtyStyleSheet'),
+  (2942, 'WebkitMarginBeforeCollapseDiscard'),
+  (2943, 'WebkitMarginBeforeCollapseSeparate'),
+  (2944, 'WebkitMarginBeforeCollapseSeparateMaybeDoesSomething'),
+  (2945, 'WebkitMarginAfterCollapseDiscard'),
+  (2946, 'WebkitMarginAfterCollapseSeparate'),
+  (2947, 'WebkitMarginAfterCollapseSeparateMaybeDoesSomething'),
+  (2949, 'CredentialManagerGetWithUVM'),
+  (2951, 'CredentialManagerGetSuccessWithUVM'),
+  (2952, 'DiscardInputEventToMovingIframe'),
+  (2953, 'SignedExchangeSubresourcePrefetch'),
+  (2954, 'BasicCardType'),
+  (2955, 'ExecutedJavaScriptURL'),
+  (2956, 'LinkPrefetchLoadEvent'),
+  (2957, 'LinkPrefetchErrorEvent'),
+  (2958, 'FontSizeWebkitXxxLarge'),
+  (2959, 'V8Database_ChangeVersion_Method'),
+  (2960, 'V8Database_Transaction_Method'),
+  (2961, 'V8Database_ReadTransaction_Method'),
+  (2962, 'V8SQLTransaction_ExecuteSql_Method'),
+  (
+    2963,
+    'OBSOLETE_CSSValueAppearanceButtonForBootstrapLooseSelectorRendered'),
+  (2964, 'OBSOLETE_CSSValueAppearanceButtonForOthers2Rendered'),
+  (2965, 'OBSOLETE_CSSValueAppearanceButtonForSelectRendered'),
+  (2966, 'OBSOLETE_CSSValueAppearanceListboxForOthersRendered'),
+  (2967, 'OBSOLETE_CSSValueAppearanceMeterForOthersRendered'),
+  (2968, 'SVGSMILDiscardElementParsed'),
+  (2969, 'SVGSMILDiscardElementTriggered'),
+  (2971, 'V8PointerEvent_GetPredictedEvents_Method'),
+  (2972, 'OBSOLETE_ScrollSnapOnViewportBreaks'),
+  (2973, 'OBSOLETE_ScrollPaddingOnViewportBreaks'),
+  (2974, 'DownloadInAdFrame'),
+  (2975, 'DownloadInSandbox'),
+  (2976, 'DownloadWithoutUserGesture'),
+  (2977, 'AutoplayDynamicDelegation'),
+  (2978, 'ToggleEventHandlerDuringParsing'),
+  (2979, 'FragmentDoubleHash'),
+  (2980, 'V8RegExpMatchAllWithNonGlobalRegExp (obsolete)'),
+  (2981, 'OBSOLETE_CSSValueOverflowXOverlay'),
+  (2982, 'OBSOLETE_CSSValueOverflowYOverlay'),
+  (2983, 'ContentIndexAdd'),
+  (2984, 'ContentIndexDelete'),
+  (2985, 'ContentIndexGet'),
+  (2986, 'V8SpeechGrammar_Constructor'),
+  (2987, 'V8SpeechGrammarList_AddFromString_Method'),
+  (2988, 'V8SpeechGrammarList_Constructor'),
+  (2989, 'V8SpeechGrammarList_Item_Method'),
+  (2990, 'V8SpeechRecognition_Constructor'),
+  (2991, 'V8SpeechRecognition_Grammars_AttributeGetter'),
+  (2992, 'V8SpeechRecognition_Grammars_AttributeSetter'),
+  (2993, 'ContactsManagerSelect'),
+  (2994, 'V8MediaSession_SetPositionState_Method'),
+  (2995, 'CSSValueOverflowOverlay'),
+  (2996, 'RequestedFileSystemTemporary'),
+  (2997, 'RequestedFileSystemPersistent'),
+  (2998, 'ElementWithLeftwardOrUpwardOverflowDirection_ScrollLeftOrTop'),
+  (
+    2999,
+    'ElementWithLeftwardOrUpwardOverflowDirection_ScrollLeftOrTopSetPositive'),
+  (3000, 'XMLHttpRequestSynchronousInMainFrame'),
+  (3001, 'XMLHttpRequestSynchronousInCrossOriginSubframe'),
+  (3002, 'XMLHttpRequestSynchronousInSameOriginSubframe'),
+  (3003, 'XMLHttpRequestSynchronousInWorker'),
+  (3004, 'PerformanceObserverBufferedFlag'),
+  (3005, 'WakeLockAcquireScreenLock'),
+  (3006, 'WakeLockAcquireSystemLock'),
+  (3007, 'ThirdPartyServiceWorker'),
+  (3008, 'JSSelfProfiling'),
+  (3009, 'HTMLFrameSetElement'),
+  (3010, 'MediaCapabilitiesFramerateRatio'),
+  (3011, 'MediaCapabilitiesFramerateNumber'),
+  (3012, 'FetchRedirectError'),
+  (3013, 'FetchRedirectManual'),
+  (3014, 'FetchCacheReload'),
+  (3015, 'V8Window_ChooseFileSystemEntries_Method'),
+  (3016, 'V8FileSystemDirectoryHandle_GetSystemDirectory_Method'),
+  (3017, 'NotificationShowTrigger'),
+  (3018, 'WebSocketStreamConstructor'),
+  (3019, 'DOMStorageRead'),
+  (3020, 'DOMStorageWrite'),
+  (3021, 'CacheStorageRead'),
+  (3022, 'CacheStorageWrite'),
+  (3023, 'IndexedDBRead'),
+  (3024, 'IndexedDBWrite'),
+  (3025, 'DeprecatedFileSystemRead'),
+  (3026, 'DeprecatedFileSystemWrite'),
+  (3027, 'PointerLockUnadjustedMovement'),
+  (3028, 'CreateObjectBlob'),
+  (3029, 'QuotaRead'),
+  (3030, 'DelegateFocus'),
+  (3031, 'OBSOLETE_DelegateFocusNotFirstInFlatTree'),
+  (3032, 'ThirdPartySharedWorker'),
+  (3033, 'ThirdPartyBroadcastChannel'),
+  (3034, 'MediaSourceGroupEndTimestampDecreaseWithinMediaSegment'),
+  (3035, 'TextFragmentAnchorTapToDismiss'),
+  (3036, 'XRIsSessionSupported'),
+  (3037, 'ScrollbarUseScrollbarButtonReversedDirection'),
+  (3038, 'CSSSelectorPseudoScrollbarButtonReversedDirection'),
+  (3039, 'OBSOLETE_FragmentHasTildeAmpersandTilde'),
+  (3040, 'OBSOLETE_FragmentHasColonTildeColon'),
+  (3041, 'OBSOLETE_FragmentHasTildeAtTilde'),
+  (3042, 'OBSOLETE_FragmentHasAmpersandDelimiterQuestion'),
+  (3043, 'InvalidFragmentDirective'),
+  (3044, 'ContactsManagerGetProperties'),
+  (3045, 'EvaluateScriptMovedBetweenElementDocuments'),
+  (3046, 'PluginElementLoadedDocument'),
+  (3047, 'PluginElementLoadedImage'),
+  (3048, 'PluginElementLoadedExternal'),
+  (3049, 'RenderSubtreeAttribute'),
+  (3050, 'ARIAAnnotations'),
+  (3051, 'IntersectionObserverV2'),
+  (3052, 'HeavyAdIntervention'),
+  (3053, 'UserTimingL3'),
+  (3054, 'GetGamepadsFromCrossOriginSubframe'),
+  (3055, 'GetGamepadsFromInsecureContext'),
+  (3056, 'OriginCleanImageBitmapSerialization'),
+  (3057, 'NonOriginCleanImageBitmapSerialization'),
+  (3058, 'OriginCleanImageBitmapTransfer'),
+  (3059, 'NonOriginCleanImageBitmapTransfer'),
+  (3060, 'CompressionStreamConstructor'),
+  (3061, 'DecompressionStreamConstructor'),
+  (3062, 'V8RTCRtpReceiver_PlayoutDelayHint_AttributeGetter'),
+  (3063, 'V8RTCRtpReceiver_PlayoutDelayHint_AttributeSetter'),
+  (3064, 'V8RegExpExecCalledOnSlowRegExp'),
+  (3065, 'V8RegExpReplaceCalledOnSlowRegExp'),
+  (3066, 'HasMarkerPseudoElement'),
+  (3067, 'WindowMove'),
+  (3068, 'WindowResize'),
+  (3069, 'MovedOrResizedPopup'),
+  (3070, 'MovedOrResizedPopup2sAfterCreation'),
+  (3071, 'DOMWindowOpenPositioningFeatures'),
+  (3072, 'MouseEventScreenX'),
+  (3073, 'MouseEventScreenY'),
+  (3074, 'CredentialManagerIsUserVerifyingPlatformAuthenticatorAvailable'),
+  (3075, 'ObsoleteWebrtcTlsVersion'),
+  (3076, 'UpgradeInsecureRequestsUpgradedRequestBlockable'),
+  (3077, 'UpgradeInsecureRequestsUpgradedRequestOptionallyBlockable'),
+  (3078, 'UpgradeInsecureRequestsUpgradedRequestWebsocket'),
+  (3079, 'UpgradeInsecureRequestsUpgradedRequestForm'),
+  (3080, 'UpgradeInsecureRequestsUpgradedRequestUnknown'),
+  (3081, 'HasGlyphRelativeUnits'),
+  (3082, 'CountQueuingStrategyConstructor'),
+  (3083, 'ByteLengthQueuingStrategyConstructor'),
+  (3084, 'ClassicDedicatedWorker'),
+  (3085, 'ModuleDedicatedWorker'),
+  (3086, 'FetchBodyStreamInServiceWorker'),
+  (3087, 'FetchBodyStreamOutsideServiceWorker'),
+  (3088, 'GetComputedStyleOutsideFlatTree'),
+  (3089, 'ARIADescriptionAttribute'),
+  (3090, 'StrictMimeTypeChecksWouldBlockWorker'),
+  (3091, 'ResourceTimingTaintedOriginFlagFail'),
+  (3092, 'RegisterProtocolHandlerSameOriginAsTop'),
+  (3093, 'RegisterProtocolHandlerCrossOriginSubframe'),
+  (3094, 'WebNfcNdefReaderScan'),
+  (3095, 'WebNfcNdefWriterWrite'),
+  (3096, 'HTMLPortalElement'),
+  (3097, 'V8HTMLPortalElement_Activate_Method'),
+  (3098, 'V8HTMLPortalElement_PostMessage_Method'),
+  (3099, 'V8Window_PortalHost_AttributeGetter'),
+  (3100, 'V8PortalHost_PostMessage_Method'),
+  (3101, 'V8PortalActivateEvent_Data_AttributeGetter'),
+  (3102, 'V8PortalActivateEvent_AdoptPredecessor_Method'),
+  (3103, 'LinkRelPrefetchForSignedExchanges'),
+  (3104, 'MessageEventSharedArrayBufferSameOrigin'),
+  (3105, 'MessageEventSharedArrayBufferSameAgentCluster'),
+  (3106, 'MessageEventSharedArrayBufferDifferentAgentCluster'),
+  (3107, 'CacheStorageCodeCacheHint'),
+  (3108, 'V8Metadata_ModificationTime_AttributeGetter'),
+  (3109, 'V8RTCLegacyStatsReport_Timestamp_AttributeGetter'),
+  (3110, 'InputElementValueAsDateGetter'),
+  (3111, 'InputElementValueAsDateSetter'),
+  (3112, 'HTMLMetaElementReferrerPolicy'),
+  (3113, 'NonWebbyMixedContent'),
+  (3114, 'V8SharedArrayBufferConstructed'),
+  (3115, 'ScrollSnapCausesScrollOnInitialLayout'),
+  (3116, 'ClientHintsUAMobile'),
+  (3117, 'V8VideoPlaybackQuality_CorruptedVideoFrames_AttributeGetter'),
+  (3118, 'LongTaskBufferFull'),
+  (3119, 'HTMLMetaElementMonetization'),
+  (3120, 'HTMLLinkElementMonetization'),
+  (3121, 'OBSOLETE_InputTypeCheckboxRenderedNonSquare'),
+  (3122, 'OBSOLETE_InputTypeRadioRenderedNonSquare'),
+  (3123, 'WebkitBoxPackJustifyDoesSomething'),
+  (3124, 'WebkitBoxPackCenterDoesSomething'),
+  (3125, 'WebkitBoxPackEndDoesSomething'),
+  (3126, 'V8KeyframeEffect_Constructor'),
+  (3127, 'OBSOLETE_WebNfcAPI'),
+  (3128, 'HostCandidateAttributeGetter'),
+  (3129, 'CSPWithReasonableObjectRestrictions'),
+  (3130, 'CSPWithReasonableBaseRestrictions'),
+  (3131, 'CSPWithReasonableScriptRestrictions'),
+  (3132, 'CSPWithReasonableRestrictions'),
+  (3133, 'CSPROWithReasonableObjectRestrictions'),
+  (3134, 'CSPROWithReasonableBaseRestrictions'),
+  (3135, 'CSPROWithReasonableScriptRestrictions'),
+  (3136, 'CSPROWithReasonableRestrictions'),
+  (3137, 'CSPWithBetterThanReasonableRestrictions'),
+  (3138, 'CSPROWithBetterThanReasonableRestrictions'),
+  (3139, 'MeasureMemory'),
+  (3140, 'V8Animation_ReplaceState_AttributeGetter'),
+  (3141, 'V8Animation_Persist_Method'),
+  (3142, 'TaskControllerConstructor'),
+  (3143, 'TaskControllerSetPriority'),
+  (3144, 'TaskSignalPriority'),
+  (3145, 'SchedulerPostTask'),
+  (3146, 'V8Animation_Onremove_AttributeGetter'),
+  (3147, 'V8Animation_Onremove_AttributeSetter'),
+  (3148, 'ClassicSharedWorker'),
+  (3149, 'ModuleSharedWorker'),
+  (3150, 'V8Animation_CommitStyles_Method'),
+  (3151, 'SameOriginIframeWindowAlert'),
+  (3152, 'SameOriginIframeWindowConfirm'),
+  (3153, 'SameOriginIframeWindowPrompt'),
+  (3154, 'SameOriginIframeWindowPrint'),
+  (3155, 'LargeStickyAd'),
+  (3156, 'ObsoleteOverlayInterstitialAd'),
+  (3157, 'CSSComparisonFunctions'),
+  (3158, 'OBSOLETE_FeaturePolicyProposalWouldChangeBehaviour'),
+  (3159, 'RTCLocalSdpModificationSimulcast'),
+  (3160, 'TrustedTypesEnabledEnforcing'),
+  (3161, 'TrustedTypesEnabledReportOnly'),
+  (3162, 'TrustedTypesAllowDuplicates'),
+  (3163, 'V8ArrayPrototypeHasElements'),
+  (3164, 'V8ObjectPrototypeHasElements'),
+  (3165, 'DisallowDocumentAccess'),
+  (3166, 'XRSessionRequestHitTestSource'),
+  (3167, 'XRSessionRequestHitTestSourceForTransientInput'),
+  (3168, 'XRDOMOverlay'),
+  (3169, 'OBSOLETE_CssStyleSheetReplaceWithImport'),
+  (3170, 'CryptoAlgorithmEd25519'),
+  (3171, 'CryptoAlgorithmX25519'),
+  (3172, 'DisplayNames'),
+  (3173, 'NumberFormatStyleUnit'),
+  (3174, 'DateTimeFormatRange'),
+  (3175, 'DateTimeFormatDateTimeStyle'),
+  (3176, 'BreakIteratorTypeWord'),
+  (3177, 'BreakIteratorTypeLine'),
+  (3178, 'V8FileSystemDirectoryHandle_Resolve_Method'),
+  (3179, 'V8FileSystemHandle_IsSameEntry_Method'),
+  (3180, 'OBSOLETE_V8RTCRtpSender_CreateEncodedAudioStreams_Method'),
+  (3181, 'OBSOLETE_V8RTCRtpSender_CreateEncodedVideoStreams_Method'),
+  (3182, 'OBSOLETE_V8RTCRtpReceiver_CreateEncodedAudioStreams_Method'),
+  (3183, 'OBSOLETE_V8RTCRtpReceiver_CreateEncodedVideoStreams_Method'),
+  (3184, 'QuicTransport'),
+  (3185, 'QuicTransportStreamApis'),
+  (3186, 'QuicTransportDatagramApis'),
+  (3187, 'V8Document_GetAnimations_Method'),
+  (3188, 'V8ShadowRoot_GetAnimations_Method'),
+  (3189, 'ClientHintsUAFullVersion'),
+  (3190, 'OBSOLETE_SchedulerCurrentTaskSignal'),
+  (3191, 'ThirdPartyFileSystem'),
+  (3192, 'ThirdPartyIndexedDb'),
+  (3193, 'ThirdPartyCacheStorage'),
+  (3194, 'ThirdPartyLocalStorage'),
+  (3195, 'ThirdPartySessionStorage'),
+  (3196, 'DeclarativeShadowRoot'),
+  (3197, 'CrossOriginOpenerPolicySameOrigin'),
+  (3198, 'CrossOriginOpenerPolicySameOriginAllowPopups'),
+  (3199, 'CrossOriginEmbedderPolicyRequireCorp'),
+  (3200, 'CoopAndCoepIsolated'),
+  (3201, 'OBSOLETE_WrongBaselineOfButtonElement'),
+  (3202, 'V8Document_HasTrustToken_Method'),
+  (3203, 'ForceLoadAtTop'),
+  (3204, 'OBSOLETE_LegacyLayoutByButton'),
+  (3205, 'OBSOLETE_LegacyLayoutByDeprecatedFlexBox'),
+  (3206, 'OBSOLETE_LegacyLayoutByDetailsMarker'),
+  (3207, 'OBSOLETE_LegacyLayoutByEditing'),
+  (3208, 'OBSOLETE_LegacyLayoutByFieldSet'),
+  (3209, 'OBSOLETE_LegacyLayoutByFileUploadControl'),
+  (3210, 'OBSOLETE_LegacyLayoutByFlexBox'),
+  (3211, 'OBSOLETE_LegacyLayoutByFrameSet'),
+  (3212, 'OBSOLETE_LegacyLayoutByGrid'),
+  (3213, 'OBSOLETE_LegacyLayoutByMenuList'),
+  (3214, 'OBSOLETE_LegacyLayoutByMultiCol'),
+  (3215, 'OBSOLETE_LegacyLayoutByPrinting'),
+  (3216, 'OBSOLETE_LegacyLayoutByRuby'),
+  (3217, 'OBSOLETE_LegacyLayoutBySVG'),
+  (3218, 'OBSOLETE_LegacyLayoutBySlider'),
+  (3219, 'OBSOLETE_LegacyLayoutByTable'),
+  (3220, 'OBSOLETE_LegacyLayoutByTextCombine'),
+  (3221, 'OBSOLETE_LegacyLayoutByTextControl'),
+  (3222, 'OBSOLETE_LegacyLayoutByVTTCue'),
+  (3223, 'OBSOLETE_LegacyLayoutByWebkitBoxWithoutVerticalLineClamp'),
+  (3224, 'OBSOLETE_LegacyLayoutByTableFlexGridBlockInNGFragmentationContext'),
+  (3225, 'DocumentPolicyHeader'),
+  (3226, 'DocumentPolicyReportOnlyHeader'),
+  (3227, 'RequireDocumentPolicyHeader'),
+  (3228, 'DocumentPolicyIframePolicyAttribute'),
+  (3229, 'DocumentPolicyCausedPageUnload'),
+  (3230, 'RequiredDocumentPolicy'),
+  (3231, 'PerformanceObserverEntryTypesAndBuffered'),
+  (3232, 'PerformanceObserverTypeError'),
+  (3233, 'ImageCaptureWhiteBalanceMode'),
+  (3234, 'ImageCaptureExposureMode'),
+  (3235, 'ImageCaptureFocusMode'),
+  (3236, 'ImageCapturePointsOfInterest'),
+  (3237, 'ImageCaptureExposureCompensation'),
+  (3238, 'ImageCaptureExposureTime'),
+  (3239, 'ImageCaptureColorTemperature'),
+  (3240, 'ImageCaptureIso'),
+  (3241, 'ImageCaptureBrightness'),
+  (3242, 'ImageCaptureContrast'),
+  (3243, 'ImageCaptureSaturation'),
+  (3244, 'ImageCaptureSharpness'),
+  (3245, 'ImageCaptureFocusDistance'),
+  (3246, 'ImageCapturePan'),
+  (3247, 'ImageCaptureTilt'),
+  (3248, 'ImageCaptureZoom'),
+  (3249, 'ImageCaptureTorch'),
+  (3250, 'XRFrameCreateAnchor'),
+  (3251, 'XRHitTestResultCreateAnchor'),
+  (3252, 'CSSKeywordRevert'),
+  (3253, 'OverlayPopupAd'),
+  (3254, 'EventTimingFirstInputExplicitlyRequested'),
+  (3255, 'CustomScrollbarPercentThickness'),
+  (3256, 'CustomScrollbarPartPercentLength'),
+  (3257, 'V8InvalidatedArrayBufferDetachingProtector'),
+  (3258, 'V8InvalidatedArrayConstructorProtector'),
+  (3259, 'V8InvalidatedArrayIteratorLookupChainProtector'),
+  (3260, 'V8InvalidatedArraySpeciesLookupChainProtector'),
+  (3261, 'V8InvalidatedIsConcatSpreadableLookupChainProtector'),
+  (3262, 'V8InvalidatedMapIteratorLookupChainProtector'),
+  (3263, 'V8InvalidatedNoElementsProtector'),
+  (3264, 'V8InvalidatedPromiseHookProtector'),
+  (3265, 'V8InvalidatedPromiseResolveLookupChainProtector'),
+  (3266, 'V8InvalidatedPromiseSpeciesLookupChainProtector'),
+  (3267, 'V8InvalidatedPromiseThenLookupChainProtector'),
+  (3268, 'V8InvalidatedRegExpSpeciesLookupChainProtector'),
+  (3269, 'V8InvalidatedSetIteratorLookupChainProtector'),
+  (3270, 'V8InvalidatedStringIteratorLookupChainProtector'),
+  (3271, 'V8InvalidatedStringLengthOverflowLookupChainProtector'),
+  (3272, 'V8InvalidatedTypedArraySpeciesLookupChainProtector'),
+  (3273, 'ClientHintsUAPlatformVersion'),
+  (3274, 'IFrameCSPAttribute'),
+  (3275, 'NavigatorCookieEnabled'),
+  (3276, 'TrustTokenFetch'),
+  (3277, 'TrustTokenXhr'),
+  (3278, 'TrustTokenIframe'),
+  (3279, 'TrustedTypesPolicyCreated'),
+  (3280, 'V8HTMLVideoElement_RequestVideoFrameCallback_Method'),
+  (3281, 'V8HTMLVideoElement_CancelVideoFrameCallback_Method'),
+  (3282, 'OBSOLETE_RubyElementWithDisplayBlock'),
+  (3283, 'OBSOLETE_LocationFragmentDirectiveAccessed'),
+  (3284, 'CanvasRenderingContext'),
+  (3285, 'SchemefulSameSiteContextDowngrade'),
+  (3286, 'OriginAgentClusterHeader'),
+  (3287, 'V8WasmSimdOpcodes'),
+  (3288, 'GridRowGapPercent'),
+  (3289, 'GridRowGapPercentIndefinite'),
+  (3290, 'FlexRowGapPercent'),
+  (3291, 'FlexRowGapPercentIndefinite'),
+  (3292, 'V8RTCRtpSender_CreateEncodedStreams_Method'),
+  (3293, 'V8RTCRtpReceiver_CreateEncodedStreams_Method'),
+  (3294, 'OBSOLETEForceEncodedAudioInsertableStreams'),
+  (3295, 'OBSOLETEForceEncodedVideoInsertableStreams'),
+  (3296, 'TransformStyleContainingBlockComputedUsedMismatch'),
+  (3297, 'OBSOLETE_AdditionalGroupingPropertiesForCompat'),
+  (3298, 'PopupDoesNotExceedOwnerWindowBounds'),
+  (3299, 'PopupExceedsOwnerWindowBounds'),
+  (3300, 'PopupExceedsOwnerWindowBoundsForIframe'),
+  (3301, 'PopupGestureTapExceedsOwnerWindowBounds'),
+  (3302, 'PopupMouseDownExceedsOwnerWindowBounds'),
+  (3303, 'PopupMouseWheelExceedsOwnerWindowBounds'),
+  (3304, 'V8VarRedeclaredCatchBinding'),
+  (3305, 'WebBluetoothRemoteCharacteristicWriteValueWithResponse'),
+  (3306, 'WebBluetoothRemoteCharacteristicWriteValueWithoutResponse'),
+  (3307, 'FlexGapSpecified'),
+  (3308, 'FlexGapPositive'),
+  (3309, 'PluginInstanceAccessSuccessful'),
+  (3310, 'StorageAccessAPI_HasStorageAccess_Method'),
+  (3311, 'StorageAccessAPI_requestStorageAccess_Method'),
+  (3312, 'WebBluetoothWatchAdvertisements'),
+  (3313, 'RubyTextWithNonDefaultTextAlign'),
+  (3314, 'HTMLMetaElementReferrerPolicyOutsideHead'),
+  (3315, 'HTMLMetaElementReferrerPolicyMultipleTokens'),
+  (3318, 'DynamicImportModuleScriptRelativeClassicSameOrigin'),
+  (3319, 'DynamicImportModuleScriptRelativeClassicCrossOrigin'),
+  (3320, 'OBSOLETE_V8WasmBulkMemory'),
+  (3321, 'V8WasmRefTypes'),
+  (3322, 'OBSOLETE_V8WasmMultiValue'),
+  (3323, 'HiddenBackfaceWithPossible3D'),
+  (3324, 'HiddenBackfaceWithPreserve3D'),
+  (3325, 'CSSAtRuleScrollTimeline'),
+  (3326, 'FetchUploadStreaming'),
+  (3327, 'WebkitLineClampWithoutWebkitBox'),
+  (3328, 'WebBluetoothGetDevices'),
+  (3329, 'DialogWithNonZeroScrollOffset'),
+  (3330, 'DialogHeightLargerThanViewport'),
+  (3331, 'OverlayPopup'),
+  (3332, 'ContentVisibilityAuto'),
+  (3333, 'ContentVisibilityHidden'),
+  (3334, 'ContentVisibilityHiddenMatchable'),
+  (3335, 'InlineOverflowAutoWithInlineEndPadding'),
+  (3336, 'InlineOverflowScrollWithInlineEndPadding'),
+  (3337, 'OBSOLETE_CSSSelectorPseudoWebKitDetailsMarker'),
+  (3338, 'SerialPortGetInfo'),
+  (3339, 'FileSystemPickerMethod'),
+  (3340, 'V8Window_ShowOpenFilePicker_Method'),
+  (3341, 'V8Window_ShowSaveFilePicker_Method'),
+  (3342, 'V8Window_ShowDirectoryPicker_Method'),
+  (3343, 'V8Window_GetOriginPrivateDirectory_Method'),
+  (3344, 'OBSOLETE_RTCConstraintEnableRtpDataChannelsTrue'),
+  (3345, 'OBSOLETE_RTCConstraintEnableRtpDataChannelsFalse'),
+  (3346, 'FileSystemAccessDragAndDrop'),
+  (3347, 'RTCAdaptivePtime'),
+  (3348, 'HTMLMetaElementReferrerPolicyMultipleTokensAffectingRequest'),
+  (3349, 'NavigationTimingL2'),
+  (3350, 'ResourceTiming'),
+  (3351, 'V8PointerEvent_AzimuthAngle_AttributeGetter'),
+  (3352, 'V8PointerEvent_AltitudeAngle_AttributeGetter'),
+  (3353, 'CrossBrowsingContextGroupMainFrameNulledNonEmptyNameAccessed'),
+  (3354, 'PositionSticky'),
+  (3355, 'OBSOLETE_CommaSeparatorInAllowAttribute'),
+  (3359, 'MainFrameCSPViaHTTP'),
+  (3360, 'MainFrameCSPViaMeta'),
+  (3361, 'OBSOLETE_MainFrameCSPViaOriginPolicy'),
+  (3362, 'HtmlClipboardApiRead'),
+  (3363, 'HtmlClipboardApiWrite'),
+  (3364, 'OBSOLETE_CSSSystemColorComputeToSelf'),
+  (3365, 'AttributionReportingAPIAll'),
+  (3366, 'OBSOLETE_ImpressionRegistration'),
+  (3367, 'OBSOLETE_ConversionRegistration'),
+  (3368, 'WebSharePolicyAllow'),
+  (3369, 'WebSharePolicyDisallow'),
+  (3370, 'FormAssociatedCustomElement'),
+  (3371, 'WindowClosed'),
+  (3372, 'WrongBaselineOfMultiLineButton'),
+  (3373, 'WrongBaselineOfEmptyLineButton'),
+  (3374, 'V8RTCRtpTransceiver_Stopped_AttributeGetter'),
+  (3375, 'V8RTCRtpTransceiver_Stop_Method'),
+  (3376, 'SecurePaymentConfirmation'),
+  (3377, 'OBSOLETE_CSSInvalidVariableUnset'),
+  (3378, 'ElementInternalsShadowRoot'),
+  (3379, 'UserDataFieldFilled_PredictedTypeMatch'),
+  (3380, 'EmailFieldFilled_PredictedTypeMatch'),
+  (3381, 'PhoneFieldFilled_PredictedTypeMatch'),
+  (3382, 'EmailFieldFilled_PatternMatch'),
+  (3383, 'OBSOLETE_LastLetterSpacingAffectsRendering'),
+  (3384, 'V8FontData_GetTables_Method'),
+  (3385, 'V8FontData_Blob_Method'),
+  (3386, 'OBSOLETE_V8FontManager_Query_Method'),
+  (3387, 'AudioContextBaseLatency'),
+  (3388, 'V8Window_GetScreenDetails_Method'),
+  (3389, 'OBSOLETE_V8Window_IsMultiScreen_Method'),
+  (3390, 'OBSOLETE_V8Window_Onscreenschange_AttributeGetter'),
+  (3391, 'OBSOLETE_V8Window_Onscreenschange_AttributeSetter'),
+  (3392, 'DOMWindowOpenPositioningFeaturesCrossScreen'),
+  (3393, 'DOMWindowSetWindowRectCrossScreen'),
+  (3394, 'FullscreenCrossScreen'),
+  (3395, 'OBSOLETE_BatterySavingsMeta'),
+  (3396, 'DigitalGoodsGetDigitalGoodsService'),
+  (3397, 'DigitalGoodsGetDetails'),
+  (3398, 'DigitalGoodsAcknowledge'),
+  (3399, 'MediaRecorder_MimeType'),
+  (3400, 'MediaRecorder_VideoBitsPerSecond'),
+  (3401, 'MediaRecorder_AudioBitsPerSecond'),
+  (3402, 'OBSOLETE_BluetoothRemoteGATTCharacteristic_Uuid'),
+  (3403, 'OBSOLETE_BluetoothRemoteGATTDescriptor_Uuid'),
+  (3404, 'OBSOLETE_BluetoothRemoteGATTService_Uuid'),
+  (3405, 'GPUAdapter_Name'),
+  (3406, 'OBSOLETE_WindowScreenInternal'),
+  (3407, 'OBSOLETE_WindowScreenPrimary'),
+  (3408, 'ThirdPartyCookieRead'),
+  (3409, 'ThirdPartyCookieWrite'),
+  (3410, 'RTCLegacyRtpDataChannelNegotiated'),
+  (3411, 'CrossSitePostMessage'),
+  (3412, 'SchemelesslySameSitePostMessage'),
+  (3413, 'SchemefulSameSitePostMessage'),
+  (3414, 'UnspecifiedTargetOriginPostMessage'),
+  (3415, 'SchemelesslySameSitePostMessageSecureToInsecure'),
+  (3416, 'SchemelesslySameSitePostMessageInsecureToSecure'),
+  (3417, 'OBSOLETE_BCPBroadcast'),
+  (3418, 'OBSOLETE_BCPRead'),
+  (3419, 'OBSOLETE_BCPWriteWithoutResponse'),
+  (3420, 'OBSOLETE_BCPWrite'),
+  (3421, 'OBSOLETE_BCPNotify'),
+  (3422, 'OBSOLETE_BCPIndicate'),
+  (3423, 'OBSOLETE_BCPAuthenticatedSignedWrites'),
+  (3424, 'OBSOLETE_BCPReliableWrite'),
+  (3425, 'OBSOLETE_BCPWritableAuxiliaries'),
+  (3426, 'TextAlignSpecifiedToLegend'),
+  (3427, 'V8Document_FragmentDirective_AttributeGetter'),
+  (3428, 'V8StorageManager_GetDirectory_Method'),
+  (3429, 'BeforematchHandlerRegistered'),
+  (3430, 'BluetoothAdvertisingEventName'),
+  (3431, 'BluetoothAdvertisingEventAppearance'),
+  (3432, 'BluetoothAdvertisingEventTxPower'),
+  (3433, 'CrossOriginOpenerPolicyReporting'),
+  (3434, 'GamepadId'),
+  (3435, 'ElementAttachInternals'),
+  (3436, 'BluetoothDeviceName'),
+  (3437, 'RTCIceCandidateAddress'),
+  (3438, 'RTCIceCandidateCandidate'),
+  (3439, 'RTCIceCandidatePort'),
+  (3440, 'RTCIceCandidateRelatedAddress'),
+  (3441, 'RTCIceCandidateRelatedPort'),
+  (3442, 'SlotAssignNode'),
+  (3443, 'PluginName'),
+  (3444, 'PluginFilename'),
+  (3445, 'PluginDescription'),
+  (3446, 'OBSOLETE_SubresourceWebBundles'),
+  (3447, 'RTCPeerConnectionSetRemoteDescriptionPromise'),
+  (3448, 'RTCPeerConnectionSetLocalDescriptionPromise'),
+  (3449, 'RTCPeerConnectionCreateOfferPromise'),
+  (3450, 'RTCPeerConnectionCreateAnswerPromise'),
+  (3451, 'RTCPeerConnectionSetRemoteDescription'),
+  (3452, 'RTCPeerConnectionSetLocalDescription'),
+  (3453, 'RTCPeerConnectionCreateOffer'),
+  (3454, 'RTCPeerConnectionCreateAnswer'),
+  (3455, 'V8AuthenticatorAttestationResponse_GetTransports_Method'),
+  (3456, 'WebCodecsAudioDecoder'),
+  (3457, 'WebCodecsVideoDecoder'),
+  (3458, 'WebCodecsVideoEncoder'),
+  (3459, 'WebCodecsVideoTrackReader'),
+  (3460, 'WebCodecsImageDecoder'),
+  (3461, 'BackForwardCacheExperimentHTTPHeader'),
+  (3462, 'V8Navigator_OpenTCPSocket_Method'),
+  (3463, 'V8Navigator_OpenUDPSocket_Method'),
+  (3464, 'WebCodecs'),
+  (3465, 'CredentialManagerCrossOriginPublicKeyGetRequest'),
+  (3466, 'CSSContainStrictWithoutContentVisibility'),
+  (3467, 'CSSContainAllWithoutContentVisibility'),
+  (3468, 'TimerInstallFromBeforeUnload'),
+  (3469, 'TimerInstallFromUnload'),
+  (3470, 'OBSOLETE_ElementAttachInternalsBeforeConstructor'),
+  (3471, 'SMILElementHasRepeatNEventListener'),
+  (3472, 'WebTransport'),
+  (3473, 'OBSOLETE_WebkitPrerenderStartEventFired'),
+  (3474, 'OBSOLETE_WebkitPrerenderStopEventFired'),
+  (3475, 'OBSOLETE_WebkitPrerenderLoadEventFired'),
+  (3476, 'OBSOLETE_WebkitPrerenderDOMContentLoadedEventFired'),
+  (3477, 'IdleDetectionPermissionRequested'),
+  (3478, 'IdentifiabilityStudyReserved3478'),
+  (3479, 'SpeechSynthesis_GetVoices_Method'),
+  (3480, 'IdentifiabilityStudyReserved3480'),
+  (3481, 'V8Navigator_JavaEnabled_Method'),
+  (3482, 'IdentifiabilityStudyReserved3482'),
+  (3483, 'IdentifiabilityStudyReserved3483'),
+  (3484, 'IdentifiabilityStudyReserved3484'),
+  (3485, 'IdentifiabilityStudyReserved3485'),
+  (3486, 'IdentifiabilityStudyReserved3486'),
+  (3487, 'IdentifiabilityStudyReserved3487'),
+  (3488, 'IdentifiabilityStudyReserved3488'),
+  (3489, 'IdentifiabilityStudyReserved3489'),
+  (3490, 'IdentifiabilityStudyReserved3490'),
+  (3491, 'IdentifiabilityStudyReserved3491'),
+  (3492, 'IdentifiabilityStudyReserved3492'),
+  (3493, 'IdentifiabilityStudyReserved3493'),
+  (3494, 'IdentifiabilityStudyReserved3494'),
+  (3495, 'IdentifiabilityStudyReserved3495'),
+  (3496, 'IdentifiabilityStudyReserved3496'),
+  (3497, 'IdentifiabilityStudyReserved3497'),
+  (3498, 'IdentifiabilityStudyReserved3498'),
+  (3499, 'V8BackgroundFetchRegistration_FailureReason_AttributeGetter'),
+  (3500, 'V8Document_ElementFromPoint_Method'),
+  (3501, 'V8Document_ElementsFromPoint_Method'),
+  (3502, 'V8ShadowRoot_ElementFromPoint_Method'),
+  (3503, 'V8ShadowRoot_ElementsFromPoint_Method'),
+  (3504, 'OBSOLETE_WindowScreenTouchSupport'),
+  (3505, 'IdentifiabilityStudyReserved3505'),
+  (3506, 'IdentifiabilityStudyReserved3506'),
+  (3507, 'V8PushManager_SupportedContentEncodings_AttributeGetter'),
+  (3508, 'IdentifiabilityStudyReserved3508'),
+  (3509, 'V8RTCRtpReceiver_GetCapabilities_Method'),
+  (3510, 'V8RTCRtpSender_GetCapabilities_Method'),
+  (3511, 'IdentifiabilityStudyReserved3511'),
+  (3512, 'IdentifiabilityStudyReserved3512'),
+  (3513, 'IdentifiabilityStudyReserved3513'),
+  (3514, 'IdentifiabilityStudyReserved3514'),
+  (3515, 'IdentifiabilityStudyReserved3515'),
+  (3516, 'IdentifiabilityStudyReserved3516'),
+  (3517, 'IdentifiabilityStudyReserved3517'),
+  (3518, 'IdentifiabilityStudyReserved3518'),
+  (3519, 'IdentifiabilityStudyReserved3519'),
+  (3520, 'IdentifiabilityStudyReserved3520'),
+  (3521, 'IdentifiabilityStudyReserved3521'),
+  (3522, 'IdentifiabilityStudyReserved3522'),
+  (3523, 'IdentifiabilityStudyReserved3523'),
+  (3524, 'IdentifiabilityStudyReserved3524'),
+  (3525, 'IdentifiabilityStudyReserved3525'),
+  (3526, 'IdentifiabilityStudyReserved3526'),
+  (3527, 'IdentifiabilityStudyReserved3527'),
+  (3528, 'IdentifiabilityStudyReserved3528'),
+  (3529, 'IdentifiabilityStudyReserved3529'),
+  (3530, 'IdentifiabilityStudyReserved3530'),
+  (3531, 'IdentifiabilityStudyReserved3531'),
+  (3532, 'IdentifiabilityStudyReserved3532'),
+  (3533, 'IdentifiabilityStudyReserved3533'),
+  (3534, 'IdentifiabilityStudyReserved3534'),
+  (3535, 'IdentifiabilityStudyReserved3535'),
+  (3536, 'IdentifiabilityStudyReserved3536'),
+  (3537, 'IdentifiabilityStudyReserved3537'),
+  (3538, 'IdentifiabilityStudyReserved3538'),
+  (3539, 'IdentifiabilityStudyReserved3539'),
+  (3540, 'IdentifiabilityStudyReserved3540'),
+  (3541, 'V8WheelEvent_DeltaMode_AttributeGetter'),
+  (3542, 'V8Touch_Force_AttributeGetter'),
+  (3543, 'WebGLRenderingContextMakeXRCompatible'),
+  (3544, 'V8WebGLCompressedTextureASTC_GetSupportedProfiles_Method'),
+  (3545, 'HTMLCanvasGetContext'),
+  (3546, 'V8BeforeInstallPromptEvent_Platforms_AttributeGetter'),
+  (3547, 'IdentifiabilityStudyReserved3547'),
+  (3548, 'IdentifiabilityStudyReserved3548'),
+  (3549, 'IdentifiabilityStudyReserved3549'),
+  (3550, 'IdentifiabilityStudyReserved3550'),
+  (3551, 'IdentifiabilityStudyReserved3551'),
+  (3552, 'IdentifiabilityStudyReserved3552'),
+  (3553, 'IdentifiabilityStudyReserved3553'),
+  (3554, 'IdentifiabilityStudyReserved3554'),
+  (3555, 'IdentifiabilityStudyReserved3555'),
+  (3556, 'IdentifiabilityStudyReserved3556'),
+  (3557, 'IdentifiabilityStudyReserved3557'),
+  (3558, 'IdentifiabilityStudyReserved3558'),
+  (3559, 'IdentifiabilityStudyReserved3559'),
+  (3560, 'IdentifiabilityStudyReserved3560'),
+  (3561, 'IdentifiabilityStudyReserved3561'),
+  (3562, 'IdentifiabilityStudyReserved3562'),
+  (3563, 'IdentifiabilityStudyReserved3563'),
+  (3564, 'IdentifiabilityStudyReserved3564'),
+  (3565, 'IdentifiabilityStudyReserved3565'),
+  (3566, 'V8BaseAudioContext_SampleRate_AttributeGetter'),
+  (3567, 'OBSOLETE_WindowScreenId'),
+  (3568, 'WebGLRenderingContextGetParameter'),
+  (3569, 'WebGLRenderingContextGetRenderbufferParameter'),
+  (3570, 'WebGLRenderingContextGetShaderPrecisionFormat'),
+  (3571, 'WebGL2RenderingContextGetInternalFormatParameter'),
+  (3572, 'IdentifiabilityStudyReserved3572'),
+  (3573, 'IdentifiabilityStudyReserved3573'),
+  (3574, 'IdentifiabilityStudyReserved3574'),
+  (3575, 'IdentifiabilityStudyReserved3575'),
+  (3576, 'IdentifiabilityStudyReserved3576'),
+  (3577, 'IdentifiabilityStudyReserved3577'),
+  (3578, 'CascadedCSSZoomNotEqualToOne'),
+  (3579, 'ForcedDarkMode'),
+  (3580, 'PreferredColorSchemeDark'),
+  (3581, 'PreferredColorSchemeDarkSetting'),
+  (3582, 'IdentifiabilityMediaDevicesEnumerateDevices'),
+  (3583, 'IdentifiabilityStudyReserved3583'),
+  (3584, 'IdentifiabilityStudyReserved3584'),
+  (3585, 'IdentifiabilityStudyReserved3585'),
+  (3586, 'IdentifiabilityStudyReserved3586'),
+  (3587, 'IdentifiabilityStudyReserved3587'),
+  (3588, 'IdentifiabilityStudyReserved3588'),
+  (3589, 'IdentifiabilityStudyReserved3589'),
+  (3590, 'IdentifiabilityStudyReserved3590'),
+  (3591, 'IdentifiabilityStudyReserved3591'),
+  (3592, 'IdentifiabilityStudyReserved3592'),
+  (3593, 'IdentifiabilityStudyReserved3593'),
+  (3594, 'IdentifiabilityStudyReserved3594'),
+  (3595, 'IdentifiabilityStudyReserved3595'),
+  (3596, 'IdentifiabilityStudyReserved3596'),
+  (3597, 'IdentifiabilityStudyReserved3597'),
+  (3598, 'IdentifiabilityStudyReserved3598'),
+  (3599, 'IdentifiabilityStudyReserved3599'),
+  (3600, 'IdentifiabilityStudyReserved3600'),
+  (3601, 'IdentifiabilityStudyReserved3601'),
+  (3602, 'IdentifiabilityStudyReserved3602'),
+  (3603, 'IdentifiabilityStudyReserved3603'),
+  (3604, 'IdentifiabilityStudyReserved3604'),
+  (3605, 'IdentifiabilityStudyReserved3605'),
+  (3606, 'IdentifiabilityStudyReserved3606'),
+  (3607, 'IdentifiabilityStudyReserved3607'),
+  (3608, 'IdentifiabilityStudyReserved3608'),
+  (3609, 'IdentifiabilityStudyReserved3609'),
+  (3610, 'BarcodeDetector_GetSupportedFormats'),
+  (3611, 'IdentifiabilityStudyReserved3611'),
+  (3612, 'IdentifiabilityStudyReserved3612'),
+  (3613, 'IdentifiabilityStudyReserved3613'),
+  (3614, 'IdentifiabilityStudyReserved3614'),
+  (3615, 'IdentifiabilityStudyReserved3615'),
+  (3616, 'IdentifiabilityStudyReserved3616'),
+  (3617, 'IdentifiabilityStudyReserved3617'),
+  (3618, 'IdentifiabilityStudyReserved3618'),
+  (3619, 'IdentifiabilityStudyReserved3619'),
+  (3620, 'IdentifiabilityStudyReserved3620'),
+  (3621, 'IdentifiabilityStudyReserved3621'),
+  (3622, 'IdentifiabilityStudyReserved3622'),
+  (3623, 'IdentifiabilityStudyReserved3623'),
+  (3624, 'IdentifiabilityStudyReserved3624'),
+  (3625, 'IdentifiabilityStudyReserved3625'),
+  (3626, 'IdentifiabilityStudyReserved3626'),
+  (3627, 'IdentifiabilityStudyReserved3627'),
+  (3628, 'IdentifiabilityStudyReserved3628'),
+  (3629, 'IdentifiabilityStudyReserved3629'),
+  (3630, 'IdentifiabilityStudyReserved3630'),
+  (3631, 'IdentifiabilityStudyReserved3631'),
+  (3632, 'IdentifiabilityStudyReserved3632'),
+  (3633, 'IdentifiabilityStudyReserved3633'),
+  (3634, 'IdentifiabilityStudyReserved3634'),
+  (3635, 'IdentifiabilityStudyReserved3635'),
+  (3636, 'IdentifiabilityStudyReserved3636'),
+  (3637, 'IdentifiabilityStudyReserved3637'),
+  (3638, 'IdentifiabilityStudyReserved3638'),
+  (3639, 'IdentifiabilityStudyReserved3639'),
+  (3640, 'IdentifiabilityStudyReserved3640'),
+  (3641, 'IdentifiabilityStudyReserved3641'),
+  (3642, 'IdentifiabilityStudyReserved3642'),
+  (3643, 'IdentifiabilityStudyReserved3643'),
+  (3644, 'IdentifiabilityStudyReserved3644'),
+  (3645, 'IdentifiabilityStudyReserved3645'),
+  (3646, 'IdentifiabilityStudyReserved3646'),
+  (3647, 'IdentifiabilityStudyReserved3647'),
+  (3648, 'IdentifiabilityStudyReserved3648'),
+  (3649, 'IdentifiabilityStudyReserved3649'),
+  (3650, 'IdentifiabilityStudyReserved3650'),
+  (3651, 'IdentifiabilityStudyReserved3651'),
+  (3652, 'IdentifiabilityStudyReserved3652'),
+  (3653, 'IdentifiabilityStudyReserved3653'),
+  (3654, 'IdentifiabilityStudyReserved3654'),
+  (3655, 'IdentifiabilityStudyReserved3655'),
+  (3656, 'IdentifiabilityStudyReserved3656'),
+  (3657, 'IdentifiabilityStudyReserved3657'),
+  (3658, 'IdentifiabilityStudyReserved3658'),
+  (3659, 'IdentifiabilityStudyReserved3659'),
+  (3660, 'IdentifiabilityStudyReserved3660'),
+  (3661, 'IdentifiabilityStudyReserved3661'),
+  (3662, 'IdentifiabilityStudyReserved3662'),
+  (3663, 'IdentifiabilityStudyReserved3663'),
+  (3664, 'IdentifiabilityStudyReserved3664'),
+  (3665, 'IdentifiabilityStudyReserved3665'),
+  (3666, 'IdentifiabilityStudyReserved3666'),
+  (3667, 'IdentifiabilityStudyReserved3667'),
+  (3668, 'IdentifiabilityStudyReserved3668'),
+  (3669, 'IdentifiabilityStudyReserved3669'),
+  (3670, 'IdentifiabilityStudyReserved3670'),
+  (3671, 'IdentifiabilityStudyReserved3671'),
+  (3672, 'IdentifiabilityStudyReserved3672'),
+  (3673, 'IdentifiabilityStudyReserved3673'),
+  (3674, 'IdentifiabilityStudyReserved3674'),
+  (3675, 'IdentifiabilityStudyReserved3675'),
+  (3676, 'IdentifiabilityStudyReserved3676'),
+  (3677, 'IdentifiabilityStudyReserved3677'),
+  (3678, 'IdentifiabilityStudyReserved3678'),
+  (3679, 'IdentifiabilityStudyReserved3679'),
+  (3680, 'IdentifiabilityStudyReserved3680'),
+  (3681, 'IdentifiabilityStudyReserved3681'),
+  (3682, 'UndeferrableThirdPartySubresourceRequestWithCookie'),
+  (3683, 'XRDepthSensing'),
+  (3684, 'XRFrameGetDepthInformation'),
+  (3685, 'XRCPUDepthInformationGetDepth'),
+  (3686, 'XRCPUDepthInformationDataAttribute'),
+  (3687, 'OBSOLETE_InterestCohortAPI_interestCohort_Method'),
+  (3688, 'OBSOLETE_AddressSpaceLocalEmbeddedInPrivateSecureContext'),
+  (3689, 'OBSOLETE_AddressSpaceLocalEmbeddedInPrivateNonSecureContext'),
+  (3690, 'OBSOLETE_AddressSpaceLocalEmbeddedInPublicSecureContext'),
+  (3691, 'OBSOLETE_AddressSpaceLocalEmbeddedInPublicNonSecureContext'),
+  (3692, 'OBSOLETE_AddressSpaceLocalEmbeddedInUnknownSecureContext'),
+  (3693, 'OBSOLETE_AddressSpaceLocalEmbeddedInUnknownNonSecureContext'),
+  (3694, 'OBSOLETE_AddressSpacePrivateEmbeddedInPublicSecureContext'),
+  (3695, 'OBSOLETE_AddressSpacePrivateEmbeddedInPublicNonSecureContext'),
+  (3696, 'OBSOLETE_AddressSpacePrivateEmbeddedInUnknownSecureContext'),
+  (3697, 'OBSOLETE_AddressSpacePrivateEmbeddedInUnknownNonSecureContext'),
+  (3698, 'ThirdPartyAccess'),
+  (3699, 'ThirdPartyActivation'),
+  (3700, 'ThirdPartyAccessAndActivation'),
+  (3701, 'FullscreenAllowedByScreensChange'),
+  (3702, 'NewLayoutOverflowDifferentBlock'),
+  (3703, 'NewLayoutOverflowDifferentFlex'),
+  (3704, 'NewLayoutOverflowDifferentAndAlreadyScrollsBlock'),
+  (3705, 'NewLayoutOverflowDifferentAndAlreadyScrollsFlex'),
+  (3706, 'UnicodeBidiPlainText'),
+  (3707, 'ColorSchemeDarkSupportedOnRoot'),
+  (3708, 'WebBluetoothGetAvailability'),
+  (3709, 'DigitalGoodsListPurchases'),
+  (3710, 'CompositedSVG'),
+  (3711, 'BarcodeDetectorDetect'),
+  (3712, 'FaceDetectorDetect'),
+  (3713, 'TextDetectorDetect'),
+  (3714, 'OBSOLETE_LocalStorageFirstUsedBeforeFcp'),
+  (3715, 'OBSOLETE_LocalStorageFirstUsedAfterFcp'),
+  (3716, 'OBSOLETE_CSSPseudoHostCompoundList'),
+  (3717, 'OBSOLETE_CSSPseudoHostContextCompoundList'),
+  (3718, 'OBSOLETE_CSSPseudoHostDynamicSpecificity'),
+  (3719, 'OBSOLETE_GetCurrentBrowsingContextMedia'),
+  (3720, 'MouseEventRelativePositionForInlineElement'),
+  (3721, 'V8SharedArrayBufferConstructedWithoutIsolation'),
+  (3722, 'V8HTMLVideoElement_GetVideoPlaybackQuality_Method'),
+  (3723, 'XRWebGLBindingGetReflectionCubeMap'),
+  (3724, 'XRFrameGetLightEstimate'),
+  (3725, 'V8HTMLDialogElement_Show_Method'),
+  (3726, 'V8HTMLDialogElement_ShowModal_Method'),
+  (3727, 'AdFrameDetected'),
+  (3728, 'MediaStreamTrackGenerator'),
+  (3729, 'MediaStreamTrackProcessor'),
+  (3730, 'AddEventListenerWithAbortSignal'),
+  (3731, 'XRSessionRequestLightProbe'),
+  (3732, 'BeforematchRevealedHiddenMatchable'),
+  (3733, 'AddSourceBufferUsingConfig'),
+  (3734, 'ChangeTypeUsingConfig'),
+  (3735, 'V8SourceBuffer_AppendEncodedChunks_Method'),
+  (3736, 'OversrollBehaviorOnViewportBreaks'),
+  (3737, 'SameOriginJsonTypeForScript'),
+  (3738, 'CrossOriginJsonTypeForScript'),
+  (3739, 'SameOriginStrictNosniffWouldBlock'),
+  (3740, 'CrossOriginStrictNosniffWouldBlock'),
+  (3741, 'CSSSelectorPseudoDir'),
+  (3742, 'CrossOriginSubframeWithoutEmbeddingControl'),
+  (3743, 'ReadableStreamWithByteSource'),
+  (3744, 'ReadableStreamBYOBReader'),
+  (3745, 'EmbedElementWithoutTypeSrcChanged_Deleted'),
+  (3746, 'SamePartyCookieAttribute'),
+  (3747, 'SamePartyCookieExclusionOverruledSameSite'),
+  (3748, 'SamePartyCookieInclusionOverruledSameSite'),
+  (3749, 'EmbedElementWithoutTypeSrcChanged'),
+  (3750, 'PaymentHandlerStandardizedPaymentMethodIdentifier'),
+  (3751, 'WebCodecsAudioEncoder'),
+  (3752, 'EmbeddedCrossOriginFrameWithoutFrameAncestorsOrXFO'),
+  (3753, 'AddressSpacePrivateSecureContextEmbeddedLocal'),
+  (3754, 'AddressSpacePrivateNonSecureContextEmbeddedLocal'),
+  (3755, 'AddressSpacePublicSecureContextEmbeddedLocal'),
+  (3756, 'AddressSpacePublicNonSecureContextEmbeddedLocal'),
+  (3757, 'AddressSpacePublicSecureContextEmbeddedPrivate'),
+  (3758, 'AddressSpacePublicNonSecureContextEmbeddedPrivate'),
+  (3759, 'AddressSpaceUnknownSecureContextEmbeddedLocal'),
+  (3760, 'AddressSpaceUnknownNonSecureContextEmbeddedLocal'),
+  (3761, 'AddressSpaceUnknownSecureContextEmbeddedPrivate'),
+  (3762, 'AddressSpaceUnknownNonSecureContextEmbeddedPrivate'),
+  (3763, 'AddressSpacePrivateSecureContextNavigatedToLocal'),
+  (3764, 'AddressSpacePrivateNonSecureContextNavigatedToLocal'),
+  (3765, 'AddressSpacePublicSecureContextNavigatedToLocal'),
+  (3766, 'AddressSpacePublicNonSecureContextNavigatedToLocal'),
+  (3767, 'AddressSpacePublicSecureContextNavigatedToPrivate'),
+  (3768, 'AddressSpacePublicNonSecureContextNavigatedToPrivate'),
+  (3769, 'AddressSpaceUnknownSecureContextNavigatedToLocal'),
+  (3770, 'AddressSpaceUnknownNonSecureContextNavigatedToLocal'),
+  (3771, 'AddressSpaceUnknownSecureContextNavigatedToPrivate'),
+  (3772, 'AddressSpaceUnknownNonSecureContextNavigatedToPrivate'),
+  (3773, 'OBSOLETE_RTCPeerConnectionSdpSemanticsPlanB'),
+  (3774, 'FetchRespondWithNoResponseWithUsedRequestBody'),
+  (3775, 'V8TCPSocket_Close_Method'),
+  (3776, 'V8TCPSocket_Readable_AttributeGetter'),
+  (3777, 'V8TCPSocket_Writable_AttributeGetter'),
+  (3778, 'V8TCPSocket_RemoteAddress_AttributeGetter'),
+  (3779, 'V8TCPSocket_RemotePort_AttributeGetter'),
+  (3780, 'CSSSelectorTargetText'),
+  (3781, 'OBSOLETE_PopoverAttribute'),
+  (3782, 'OBSOLETE_V8HTMLPopupElement_Show_Method'),
+  (3783, 'OBSOLETE_V8HTMLPopupElement_Hide_Method'),
+  (3784, 'OBSOLETE_WindowOpenWithAdditionalBoolParameter'),
+  (3785, 'OBSOLETE_RTCPeerConnectionConstructedWithPlanB'),
+  (3786, 'OBSOLETE_RTCPeerConnectionConstructedWithUnifiedPlan'),
+  (3787, 'OBSOLETE_RTCPeerConnectionUsingComplexPlanB'),
+  (3788, 'OBSOLETE_RTCPeerConnectionUsingComplexUnifiedPlan'),
+  (3789, 'WindowScreenIsExtended'),
+  (3790, 'WindowScreenChange'),
+  (3791, 'XRWebGLDepthInformationTextureAttribute'),
+  (3792, 'XRWebGLBindingGetDepthInformation'),
+  (3793, 'OBSOLETE_SessionStorageFirstUsedBeforeFcp'),
+  (3794, 'OBSOLETE_SessionStorageFirstUsedAfterFcp'),
+  (3795, 'GravitySensorConstructor'),
+  (3796, 'ElementInternalsStates'),
+  (3797, 'WebPImage'),
+  (3798, 'AVIFImage'),
+  (3799, 'SVGTextEdited'),
+  (3800, 'V8WasmExceptionHandling'),
+  (3803, 'OverflowClipAlongEitherAxis'),
+  (3804, 'CreateJSONModuleScript'),
+  (3805, 'CreateCSSModuleScript'),
+  (3806, 'InsertHTMLCommandOnInput'),
+  (3807, 'InsertHTMLCommandOnTextarea'),
+  (3808, 'InsertHTMLCommandOnReadWritePlainText'),
+  (3809, 'CSSAtRuleCounterStyle'),
+  (3810, 'CanvasUseColorSpace'),
+  (3811, 'SelectListElement'),
+  (3812, 'OBSOLETE_RTCPeerConnectionSdpSemanticsPlanBWithReverseOriginTrial'),
+  (3813, 'WebAppManifestCaptureLinks'),
+  (3814, 'SanitizerAPICreated'),
+  (3815, 'SanitizerAPIDefaultConfiguration'),
+  (3816, 'OBSOLETE_SanitizerAPIToString'),
+  (3817, 'SanitizerAPIToFragment'),
+  (3818, 'SanitizerAPIActionTaken'),
+  (3819, 'SanitizerAPIFromString'),
+  (3820, 'SanitizerAPIFromDocument'),
+  (3821, 'SanitizerAPIFromFragment'),
+  (3822, 'OBSOLETE_StorageFoundationOpen'),
+  (3823, 'OBSOLETE_StorageFoundationRead'),
+  (3824, 'OBSOLETE_StorageFoundationReadSync'),
+  (3825, 'OBSOLETE_StorageFoundationWrite'),
+  (3826, 'OBSOLETE_StorageFoundationWriteSync'),
+  (3827, 'OBSOLETE_StorageFoundationFlush'),
+  (3828, 'OBSOLETE_StorageFoundationFlushSync'),
+  (3829, 'UnrestrictedSharedArrayBuffer'),
+  (3830, 'FeaturePolicyJSAPIAllowsFeatureIFrame'),
+  (3831, 'FeaturePolicyJSAPIAllowsFeatureDocument'),
+  (3832, 'FeaturePolicyJSAPIAllowsFeatureOriginIFrame'),
+  (3833, 'FeaturePolicyJSAPIAllowsFeatureOriginDocument'),
+  (3834, 'FeaturePolicyJSAPIAllowedFeaturesIFrame'),
+  (3835, 'FeaturePolicyJSAPIAllowedFeaturesDocument'),
+  (3836, 'FeaturePolicyJSAPIFeaturesIFrame'),
+  (3837, 'FeaturePolicyJSAPIFeaturesDocument'),
+  (3838, 'FeaturePolicyJSAPIGetAllowlistIFrame'),
+  (3839, 'FeaturePolicyJSAPIGetAllowlistDocument'),
+  (3840, 'OBSOLETE_V8Screens_Onchange_AttributeGetter'),
+  (3841, 'OBSOLETE_V8Screens_Onchange_AttributeSetter'),
+  (3842, 'V8ScreenDetailed_Left_AttributeGetter'),
+  (3843, 'V8ScreenDetailed_Top_AttributeGetter'),
+  (3844, 'V8ScreenDetailed_IsPrimary_AttributeGetter'),
+  (3845, 'V8ScreenDetailed_IsInternal_AttributeGetter'),
+  (3846, 'V8ScreenDetailed_DevicePixelRatio_AttributeGetter'),
+  (3847, 'V8ScreenDetailed_Id_AttributeGetter'),
+  (3848, 'V8ScreenDetailed_PointerTypes_AttributeGetter'),
+  (3849, 'V8ScreenDetailed_Label_AttributeGetter'),
+  (3850, 'PermissionsPolicyHeader'),
+  (3851, 'WebAppManifestUrlHandlers'),
+  (3852, 'LaxAllowingUnsafeCookies'),
+  (3853, 'V8MediaSession_SetMicrophoneActive_Method'),
+  (3854, 'V8MediaSession_SetCameraActive_Method'),
+  (3855, 'V8Navigator_JoinAdInterestGroup_Method'),
+  (3856, 'V8Navigator_LeaveAdInterestGroup_Method'),
+  (3857, 'V8Navigator_RunAdAuction_Method'),
+  (3858, 'XHRJSONEncodingDetection'),
+  (3859, 'WorkerControlledByServiceWorkerOutOfScope'),
+  (3860, 'XRPlaneDetection'),
+  (3861, 'XRFrameDetectedPlanes'),
+  (3862, 'XRImageTracking'),
+  (3863, 'XRSessionGetTrackedImageScores'),
+  (3864, 'XRFrameGetImageTrackingResults'),
+  (3865, 'OBSOLETE_OpenWebDatabaseThirdPartyContext'),
+  (3866, 'PointerId'),
+  (3867, 'Transform3dScene'),
+  (3868, 'PrefersColorSchemeMediaFeature'),
+  (3869, 'PrefersContrastMediaFeature'),
+  (3870, 'ForcedColorsMediaFeature'),
+  (3871, 'PaymentRequestCSPViolation'),
+  (3872, 'WorkerControlledByServiceWorkerWithFetchEventHandlerOutOfScope'),
+  (3873, 'AuthorizationCoveredByWildcard'),
+  (3874, 'ElementGetInnerHTML'),
+  (3875, 'FileHandlingLaunch'),
+  (3876, 'SameOriginDocumentsWithDifferentCOOPStatus'),
+  (3877, 'HTMLMediaElementSetSinkId'),
+  (3878, 'PrefixedStorageQuotaThirdPartyContext'),
+  (3879, 'RequestedFileSystemPersistentThirdPartyContext'),
+  (3880, 'PrefixedStorageInfoThirdPartyContext'),
+  (3881, 'CrossOriginEmbedderPolicyCredentialless'),
+  (3882, 'PostMessageFromSecureToSecure'),
+  (3883, 'PostMessageFromInsecureToInsecure'),
+  (3884, 'WebAppManifestProtocolHandlers'),
+  (3885, 'RTCPeerConnectionOfferAllowExtmapMixedFalse'),
+  (3886, 'OBSOLETE_NewCanvas2DAPI'),
+  (3887, 'OBSOLETE_ServiceWorkerSubresourceFilterBypassedRequest'),
+  (3888, 'WebGPURequestAdapter'),
+  (3889, 'CSSFilterColorMatrix'),
+  (3890, 'HTMLFencedFrameElement'),
+  (3891, 'CSSFilterLuminanceToAlpha'),
+  (3892, 'HandwritingRecognitionCreateRecognizer'),
+  (3893, 'OBSOLETE_HandwritingRecognitionQuerySupport'),
+  (3894, 'HandwritingRecognitionStartDrawing'),
+  (3895, 'HandwritingRecognitionGetPrediction'),
+  (3896, 'WebBluetoothManufacturerDataFilter'),
+  (3897, 'SanitizerAPIGetConfig'),
+  (3898, 'SanitizerAPIGetDefaultConfig'),
+  (3899, 'PressureObserver_Constructor'),
+  (3900, 'PressureObserver_Observe'),
+  (3901, 'OBSOLETE_ComputePressureObserver_Stop'),
+  (3902, 'WebAppWindowControlsOverlay'),
+  (3903, 'PaymentRequestShowWithoutGestureOrToken'),
+  (3904, 'V8Navigator_UpdateAdInterestGroups_Method'),
+  (3905, 'V8ScreenDetails_Onscreenschange_AttributeGetter'),
+  (3906, 'V8ScreenDetails_Onscreenschange_AttributeSetter'),
+  (3907, 'V8ScreenDetails_Oncurrentscreenchange_AttributeGetter'),
+  (3908, 'V8ScreenDetails_Oncurrentscreenchange_AttributeSetter'),
+  (3909, 'RTCOfferAnswerOptionsVoiceActivityDetection'),
+  (3910, 'MultiColAndListItem'),
+  (3911, 'CaptureHandle'),
+  (3912, 'SVGText'),
+  (3913, 'GetBBoxForText'),
+  (3914, 'SVGTextHangingFromPath'),
+  (3915, 'ClientHintsPrefersColorScheme'),
+  (3916, 'OverscrollBehaviorWillBeFixed'),
+  (3917, 'ControlledWorkerWillBeUncontrolled'),
+  (3918, 'OBSOLETE_kARIATouchpassthroughAttribute'),
+  (3919, 'ARIAVirtualcontentAttribute'),
+  (3920, 'OBSOLETE_kAccessibilityTouchPassthroughSet'),
+  (3921, 'TextFragmentBlockedByForceLoadAtTop'),
+  (3922, 'OBSOLETE_UrnDocumentAccessedCookies'),
+  (3923, 'FontFaceAscentOverride'),
+  (3924, 'FontFaceDescentOverride'),
+  (3925, 'FontFaceLineGapOverride'),
+  (3926, 'FontFaceSizeAdjust'),
+  (3927, 'HiddenBackfaceWith3D'),
+  (3928, 'MainFrameNonSecurePrivateAddressSpace'),
+  (3930, 'HTMLMediaElementControlsListNoPlaybackRate'),
+  (3931, 'OBSOLETE_DocumentTransition'),
+  (3932, 'SpeculationRules'),
+  (3933, 'V8AbortSignal_Abort_Method'),
+  (3934, 'SelectionBackgroundColorInversion'),
+  (3935, 'OBSOLETE_RTCPeerConnectionPlanBThrewAnException'),
+  (3936, 'HTMLRootContained'),
+  (3937, 'HTMLBodyContained'),
+  (3938, 'XRFrameGetJointPose'),
+  (3939, 'XRFrameFillJointRadii'),
+  (3940, 'XRFrameFillPoses'),
+  (3941, 'OBSOLETE_kWindowOpenNewPopupBehaviorMismatch'),
+  (3942, 'ExplicitPointerCaptureClickTargetDiff'),
+  (3943, 'ControlledNonBlobURLWorkerWillBeUncontrolled'),
+  (3944, 'MediaMetaThemeColor'),
+  (3945, 'ClientHintsUABitness'),
+  (3946, 'DifferentPerspectiveCBOrParent'),
+  (3947, 'WebkitImageSet'),
+  (3948, 'RTCPeerConnectionWithBlockingCsp'),
+  (3949, 'SanitizerAPISanitizeFor'),
+  (3950, 'SanitizerAPIElementSetSanitized'),
+  (3951, 'TextShadowInHighlightPseudo'),
+  (3952, 'TextShadowNotNoneInHighlightPseudo'),
+  (3953, 'SameSiteNoneRequired'),
+  (3954, 'SameSiteNoneIncludedBySamePartyTopResource'),
+  (3955, 'SameSiteNoneIncludedBySamePartyAncestors'),
+  (3956, 'SameSiteNoneIncludedBySameSiteLax'),
+  (3957, 'SameSiteNoneIncludedBySameSiteStrict'),
+  (3958, 'PrivateNetworkAccessNonSecureContextsAllowedDeprecationTrial'),
+  (3959, 'V8URLPattern_Constructor'),
+  (3960, 'V8URLPattern_Test_Method'),
+  (3961, 'V8URLPattern_Exec_Method'),
+  (3962, 'SameSiteCookieInclusionChangedByCrossSiteRedirect'),
+  (3963, 'BlobStoreAccessAcrossAgentClustersInResolveAsURLLoaderFactory'),
+  (3964, 'BlobStoreAccessAcrossAgentClustersInResolveForNavigation'),
+  (3965, 'TapDelayEnabled'),
+  (3966, 'V8URLPattern_CompareComponent_Method'),
+  (3967, 'EarlyHintsPreload'),
+  (3968, 'ClientHintsUAReduced'),
+  (3969, 'SpeculationRulesPrerender'),
+  (3970, 'OBSOLETE_ExecCommandWithTrustedTypes'),
+  (3971, 'OBSOLETE_CSSSelectorPseudoHasInSnapshotProfile'),
+  (3972, 'OBSOLETE_CSSSelectorPseudoHasInLiveProfile'),
+  (3973, 'NavigatorPdfViewerEnabled'),
+  (3974, 'CanvasRenderingContext2DContextLostEvent'),
+  (3975, 'CanvasRenderingContext2DContextRestoredEvent'),
+  (3976, 'ClientHintsViewportHeight'),
+  (3977, 'V8NavigatorManagedData_GetDirectoryId_Method'),
+  (3978, 'V8NavigatorManagedData_GetHostname_Method'),
+  (3979, 'V8NavigatorManagedData_GetSerialNumber_Method'),
+  (3980, 'V8NavigatorManagedData_GetAnnotatedAssetId_Method'),
+  (3981, 'V8NavigatorManagedData_GetAnnotatedLocation_Method'),
+  (3982, 'UserDataFieldFilledPreviously'),
+  (3983, 'TableCollapsedBorderDifferentToVisual'),
+  (3984, 'HighlightAPIRegisterHighlight'),
+  (3985, 'OBSOLETE_ReadOrWriteWebDatabaseThirdPartyContext'),
+  (3986, 'OBSOLETE_FontSelectorCSSFontFamilyWebKitPrefixPictograph'),
+  (3987, 'OBSOLETE_FontSelectorCSSFontFamilyWebKitPrefixStandard'),
+  (3988, 'FontSelectorCSSFontFamilyWebKitPrefixBody'),
+  (3989, 'FontBuilderCSSFontFamilyWebKitPrefixBody'),
+  (3990, 'CapabilityDelegationOfPaymentRequest'),
+  (3991, 'ConditionalFocus_Deleted'),
+  (3992, 'CredentialManagerGetLegacyFederatedCredential'),
+  (3993, 'CredentialManagerGetPasswordCredential'),
+  (3994, 'CredentialManagerStoreFederatedCredential'),
+  (3995, 'CredentialManagerStorePasswordCredential'),
+  (3996, 'CredentialManagerCreateFederatedCredential'),
+  (3997, 'CredentialManagerCreatePasswordCredential'),
+  (3998, 'CanvasRenderingContext2DRoundRect'),
+  (3999, 'NewLayoutOverflowDifferentBlockWithNonEmptyInflowBounds'),
+  (4000, 'CanvasRenderingContext2DReset'),
+  (4001, 'CanvasRenderingContext2DLetterSpacing'),
+  (4002, 'CanvasRenderingContext2DWordSpacing'),
+  (4003, 'CanvasRenderingContext2DFontVariantCaps'),
+  (4004, 'CanvasRenderingContext2DFontKerning'),
+  (4005, 'CanvasRenderingContext2DFontStretch'),
+  (4006, 'CanvasRenderingContext2DTextRendering'),
+  (4007, 'CSSCascadeLayers'),
+  (4008, 'CanvasRenderingContext2DConicGradient'),
+  (4009, 'CanvasRenderingContext2DCanvasFilter'),
+  (4010, 'OBSOLETE_HTMLParamElementURLParameter'),
+  (4011, 'V8HTMLScriptElement_Supports_Method'),
+  (4012, 'HandwritingRecognitionQueryRecognizer'),
+  (4013, 'V8FileSystemFileHandle_CreateSyncAccessHandle_Method'),
+  (4014, 'V8FileSystemSyncAccessHandle_Read_Method'),
+  (4015, 'V8FileSystemSyncAccessHandle_Write_Method'),
+  (4016, 'V8FileSystemSyncAccessHandle_Close_Method'),
+  (4017, 'V8FileSystemSyncAccessHandle_Flush_Method'),
+  (4018, 'V8FileSystemSyncAccessHandle_GetSize_Method'),
+  (4019, 'V8FileSystemSyncAccessHandle_Truncate_Method'),
+  (4020, 'V8SharedArrayBufferConstructedInExtensionWithoutIsolation'),
+  (4021, 'MediaSourceExtensionsForWebCodecs'),
+  (4023, 'PaymentRequestResponse'),
+  (4024, 'PaymentRequestComplete'),
+  (4025, 'HTMLCanvasElement_2D'),
+  (4026, 'HTMLCanvasElement_WebGL'),
+  (4027, 'HTMLCanvasElement_WebGL2'),
+  (4028, 'HTMLCanvasElement_BitmapRenderer'),
+  (4029, 'HTMLCanvasElement_WebGPU'),
+  (4030, 'OffscreenCanvas_2D'),
+  (4031, 'OffscreenCanvas_WebGL'),
+  (4032, 'OffscreenCanvas_WebGL2'),
+  (4033, 'OffscreenCanvas_BitmapRenderer'),
+  (4034, 'OffscreenCanvas_WebGPU'),
+  (4035, 'CanvasRenderingContext2DHasOverdraw'),
+  (4036, 'DigitalGoodsConsume'),
+  (4037, 'DigitalGoodsListPurchaseHistory'),
+  (4038, 'WebShareContainingFiles'),
+  (4039, 'WebShareContainingTitle'),
+  (4040, 'WebShareContainingText'),
+  (4041, 'WebShareContainingUrl'),
+  (4042, 'CoepNoneSharedWorker'),
+  (4043, 'CoepRequireCorpSharedWorker'),
+  (4044, 'CoepCredentiallessSharedWorker'),
+  (4045, 'PaymentRequestBasicCard'),
+  (4046, 'ClientHintsDeviceMemory'),
+  (4047, 'ClientHintsDPR'),
+  (4048, 'ClientHintsResourceWidth'),
+  (4049, 'ClientHintsViewportWidth'),
+  (4050, 'InlineBoxIgnoringContinuation'),
+  (4051, 'OBSOLETE_OffsetWidthOrHeightIgnoringContinuation'),
+  (4052, 'ConditionalFocus'),
+  (4053, 'V8Navigator_CreateAdRequest_Method'),
+  (4054, 'V8Navigator_FinalizeAd_Method'),
+  (4055, 'RegionCapture'),
+  (4056, 'AppHistory'),
+  (4057, 'FlexboxAlignSingleLineDifference'),
+  (4058, 'ExternalProtocolBlockedBySandbox'),
+  (4059, 'OBSOLETE_WebAssemblyDynamicTiering'),
+  (4060, 'OBSOLETE_DeferredShapingTallerIfc'),
+  (4061, 'ReadOrWriteWebDatabase'),
+  (4062, 'AutoDarkMode'),
+  (4063, 'HttpRefreshWhenScriptingDisabled'),
+  (4064, 'V8FragmentDirective_Items_AttributeGetter'),
+  (4065, 'V8FragmentDirective_CreateSelectorDirective_Method'),
+  (4066, 'CSSTransitionBlockedByAnimation'),
+  (4067, 'WebAppManifestHasComments'),
+  (4068, 'AutoExpandedDetailsForFindInPage'),
+  (4069, 'AutoExpandedDetailsForScrollToTextFragment'),
+  (4070, 'OBSOLETE_WebCodecsVideoFrameDefaultTimestamp'),
+  (4071, 'WebCodecsVideoFrameFromImage'),
+  (4072, 'WebCodecsVideoFrameFromBuffer'),
+  (4073, 'OBSOLETE_OpenWebDatabaseInsecureContext'),
+  (4074, 'ScriptWebBundle'),
+  (4075, 'RunAdAuction'),
+  (4076, 'JoinAdInterestGroup'),
+  (4077, 'FileSystemUrlNavigation'),
+  (4078, 'V8Navigator_AdAuctionComponents_Method'),
+  (4079, 'ClientHintsUAFullVersionList'),
+  (4080, 'WebAppManifestLaunchHandler'),
+  (4081, 'OBSOLETE_ClientHintsMetaNameAcceptCH'),
+  (4082, 'OBSOLETE_CSSMatchMediaUnknown'),
+  (4083, 'OBSOLETE_CSSMediaListUnknown'),
+  (4084, 'OBSOLETE_CSSOMMediaConditionUnknown'),
+  (4085, 'DocumentDomainSettingWithoutOriginAgentClusterHeader'),
+  (4086, 'CrossOriginEmbedderPolicyCredentiallessReportOnly'),
+  (4087, 'CrossOriginEmbedderPolicyRequireCorpReportOnly'),
+  (4088, 'CoopAndCoepIsolatedReportOnly'),
+  (4089, 'CrossOriginOpenerPolicySameOriginAllowPopupsReportOnly'),
+  (4090, 'CrossOriginOpenerPolicySameOriginReportOnly'),
+  (4091, 'ImageLoadAtDismissalEvent'),
+  (4092, 'OBSOLETE_PrivateNetworkAccessIgnoredPreflightError'),
+  (4093, 'AbortPaymentRespondWithTrue'),
+  (4094, 'AllowPaymentRequestAttributeHasEffect'),
+  (4095, 'V8PaymentResponse_Retry_Method'),
+  (4096, 'WebAppManifestUserPreferences'),
+  (4097, 'V8HTMLInputElement_ShowPicker_Method'),
+  (4098, 'LayerXYWithMediaTarget'),
+  (4099, 'LayerXYWithCanvasTarget'),
+  (4100, 'LayerXYWithFrameTarget'),
+  (4101, 'LayerXYWithSVGTarget'),
+  (4102, 'HTMLObjectElementFallback'),
+  (4103, 'SecureContextIncorrectForWorker'),
+  (4104, 'V8UDPSocket_Close_Method'),
+  (4105, 'HTMLInputElementSimulatedClick'),
+  (4106, 'RTCLocalSdpModificationIceUfragPwd'),
+  (4107, 'WebNfcNdefMakeReadOnly'),
+  (4108, 'V8Navigator_DeprecatedURNToURL_Method'),
+  (4109, 'OBSOLETE_WebAppManifestHandleLinks'),
+  (4110, 'OBSOLETE_HTMLParamElementURLParameterInUsePdf'),
+  (4111, 'OBSOLETE_HTMLParamElementURLParameterInUseNonPdf'),
+  (4112, 'WebTransportServerCertificateHashes'),
+  (4113, 'HiddenAttribute'),
+  (4114, 'HiddenUntilFoundAttribute'),
+  (4115, 'WindowProxyCrossOriginAccessBlur'),
+  (4116, 'WindowProxyCrossOriginAccessClose'),
+  (4117, 'WindowProxyCrossOriginAccessClosed'),
+  (4118, 'WindowProxyCrossOriginAccessFocus'),
+  (4119, 'WindowProxyCrossOriginAccessFrames'),
+  (4120, 'WindowProxyCrossOriginAccessIndexedGetter'),
+  (4121, 'WindowProxyCrossOriginAccessLength'),
+  (4122, 'WindowProxyCrossOriginAccessLocation'),
+  (4123, 'WindowProxyCrossOriginAccessNamedGetter'),
+  (4124, 'WindowProxyCrossOriginAccessOpener'),
+  (4125, 'WindowProxyCrossOriginAccessParent'),
+  (4126, 'WindowProxyCrossOriginAccessPostMessage'),
+  (4127, 'WindowProxyCrossOriginAccessSelf'),
+  (4128, 'WindowProxyCrossOriginAccessTop'),
+  (4129, 'WindowProxyCrossOriginAccessWindow'),
+  (4130, 'WindowProxyCrossOriginAccessFromOtherPageBlur'),
+  (4131, 'WindowProxyCrossOriginAccessFromOtherPageClose'),
+  (4132, 'WindowProxyCrossOriginAccessFromOtherPageClosed'),
+  (4133, 'WindowProxyCrossOriginAccessFromOtherPageFocus'),
+  (4134, 'WindowProxyCrossOriginAccessFromOtherPageFrames'),
+  (4135, 'WindowProxyCrossOriginAccessFromOtherPageIndexedGetter'),
+  (4136, 'WindowProxyCrossOriginAccessFromOtherPageLength'),
+  (4137, 'WindowProxyCrossOriginAccessFromOtherPageLocation'),
+  (4138, 'WindowProxyCrossOriginAccessFromOtherPageNamedGetter'),
+  (4139, 'WindowProxyCrossOriginAccessFromOtherPageOpener'),
+  (4140, 'WindowProxyCrossOriginAccessFromOtherPageParent'),
+  (4141, 'WindowProxyCrossOriginAccessFromOtherPagePostMessage'),
+  (4142, 'WindowProxyCrossOriginAccessFromOtherPageSelf'),
+  (4143, 'WindowProxyCrossOriginAccessFromOtherPageTop'),
+  (4144, 'WindowProxyCrossOriginAccessFromOtherPageWindow'),
+  (4145, 'PrivateNetworkAccessFetchedWorkerScript'),
+  (4146, 'FrameNameContainsBrace'),
+  (4147, 'FrameNameContainsNewline'),
+  (4148, 'AbortSignalThrowIfAborted'),
+  (4149, 'ClientHintsUAFull'),
+  (4150, 'PrivateNetworkAccessWithinWorker'),
+  (4151, 'ClientHintsUAWoW64'),
+  (4152, 'FetchSetCookieInRequestGuardedHeaders'),
+  (4153, 'OBSOLETE_V8Window_RequestPictureInPictureWindow_Method'),
+  (4154, 'V8UDPSocket_LocalPort_AttributeGetter'),
+  (4155, 'V8UDPSocket_Readable_AttributeGetter'),
+  (4156, 'V8UDPSocket_RemoteAddress_AttributeGetter'),
+  (4157, 'V8UDPSocket_RemotePort_AttributeGetter'),
+  (4158, 'V8UDPSocket_Writable_AttributeGetter'),
+  (4159, 'AbortSignalTimeout'),
+  (4160, 'OBSOLETE_ClientHintsPartitionedCookies'),
+  (4161, 'V8Document_Prerendering_AttributeGetter'),
+  (4162, 'V8Document_Onprerenderingchange_AttributeGetter'),
+  (4163, 'V8Document_Onprerenderingchange_AttributeSetter'),
+  (4164, 'CSSAtRuleFontPaletteValues'),
+  (4165, 'CSSAtRuleContainer'),
+  (4166, 'FedCm'),
+  (4167, 'FetchEventSourceLastEventIdCorsUnSafe'),
+  (4168, 'WrongBaselineOfMultiLineButtonWithNonSpace'),
+  (4169, 'BlobStoreAccessAcrossTopLevelSite'),
+  (4170, 'BlobStoreAccessUnknownTopLevelSite'),
+  (4171, 'CrossOriginAccessBasedOnDocumentDomain'),
+  (4172, 'CookieWithTruncatingChar'),
+  (4173, 'VideoTrackGenerator'),
+  (4174, 'MediaCapabilitiesDecodingInfoWebrtc'),
+  (4175, 'MediaCapabilitiesEncodingInfoWebrtc'),
+  (4176, 'UsbDeviceForget'),
+  (4177, 'PartitionedCookies'),
+  (4178, 'SecureContextIncorrectForSharedWorker'),
+  (4179, 'V8FunctionPrototypeArguments'),
+  (4180, 'V8FunctionPrototypeCaller'),
+  (4181, 'BluetoothDeviceForget'),
+  (4182, 'TopicsAPI_BrowsingTopics_Method'),
+  (4183, 'BlockingAttributeRenderToken'),
+  (4184, 'PressureObserver_Unobserve'),
+  (4185, 'PressureObserver_Disconnect'),
+  (4186, 'PressureObserver_TakeRecords'),
+  (4187, 'PrivacySandboxAdsAPIs'),
+  (4188, 'Fledge'),
+  (4189, 'ElementShowPopover'),
+  (4190, 'ElementHidePopover'),
+  (4191, 'ValidPopoverAttribute'),
+  (4192, 'DeprecationExample'),
+  (4193, 'RTCLocalSdpModificationOpusStereo'),
+  (4194, 'NavigatorUAData_Mobile'),
+  (4195, 'NavigatorUAData_Platform'),
+  (4196, 'NavigatorUAData_Brands'),
+  (4197, 'OldConstraintsParsed'),
+  (4198, 'OBSOLETE_OldConstraintNotReported'),
+  (4199, 'OBSOLETE_OldConstraintRejected'),
+  (4200, 'OBSOLETE_OldConstraintIgnored'),
+  (4201, 'ExplicitOverflowVisibleOnReplacedElement'),
+  (4202, 'ExplicitOverflowVisibleOnReplacedElementWithObjectProp'),
+  (4203, 'PrivateNetworkAccessNullIpAddress'),
+  (4204, 'OBSOLETE_LegacyConstraintGoogScreencastMinBitrate'),
+  (4205, 'OBSOLETE_RTCPeerConnectionLegacyCreateWithMediaConstraints'),
+  (4206, 'ClientHintsSaveData'),
+  (4207, 'OBSOLETE_LegacyConstraintGoogIPv6'),
+  (4208, 'OBSOLETE_LegacyConstraintGoogSuspendBelowMinBitrate'),
+  (4209, 'OBSOLETE_LegacyConstraintGoogCpuOveruseDetection'),
+  (4210, 'AudioContextOutputLatency'),
+  (4211, 'V8Window_QueryLocalFonts_Method'),
+  (4212, 'CSSAtRuleScope'),
+  (4213, 'OBSOLETE_DeferredShapingDisabledByPositioned'),
+  (4214, 'CapabilityDelegationOfFullscreenRequest'),
+  (4215, 'SerialPortForget'),
+  (4216, 'CookieHasNotBeenRefreshedIn201To300Days'),
+  (4217, 'CookieHasNotBeenRefreshedIn301To350Days'),
+  (4218, 'CookieHasNotBeenRefreshedIn351To400Days'),
+  (4219, 'AnonymousIframe'),
+  (4220, 'OBSOLETE_GestureScrollStart'),
+  (4221, 'OBSOLETE_GestureScrollUpdate'),
+  (4222, 'OBSOLETE_GestureScrollEnd'),
+  (4223, 'ArrayBufferTooBigForWebAPI'),
+  (4224, 'FedCmDisconnect'),
+  (4225, 'OBSOLETE_FedCmLogout'),
+  (4226, 'OBSOLETE_FedCmLogoutRps'),
+  (4227, 'V8Navigator_DeprecatedReplaceInURN_Method'),
+  (4228, 'WebAppBorderless'),
+  (4229, 'PaymentInstruments'),
+  (4230, 'V8PaymentInstruments_Clear_Method'),
+  (4231, 'V8PaymentInstruments_Delete_Method'),
+  (4232, 'V8PaymentInstruments_Get_Method'),
+  (4233, 'V8PaymentInstruments_Has_Method'),
+  (4234, 'V8PaymentInstruments_Keys_Method'),
+  (4235, 'V8PaymentInstruments_Set_Method'),
+  (4236, 'PerformanceMeasureFindExistingName'),
+  (4237, 'FlexboxNewAbsPos'),
+  (4238, 'ScriptSchedulingType_Defer'),
+  (4239, 'ScriptSchedulingType_ParserBlocking'),
+  (4240, 'ScriptSchedulingType_ParserBlockingInline'),
+  (4241, 'ScriptSchedulingType_InOrder'),
+  (4242, 'ScriptSchedulingType_Async'),
+  (4243, 'Focusgroup'),
+  (4244, 'V8HTMLElement_Focusgroup_AttributeGetter'),
+  (4245, 'V8HTMLElement_Focusgroup_AttributeSetter'),
+  (4246, 'V8MathMLElement_Focusgroup_AttributeGetter'),
+  (4247, 'V8MathMLElement_Focusgroup_AttributeSetter'),
+  (4248, 'V8SVGElement_Focusgroup_AttributeGetter'),
+  (4249, 'V8SVGElement_Focusgroup_AttributeSetter'),
+  (4250, 'CSSLegacyPerspectiveOrigin'),
+  (4251, 'CSSLegacyTransformOrigin'),
+  (4252, 'CSSLegacyBorderImage'),
+  (4253, 'CSSLegacyBorderImageWidth'),
+  (4254, 'CrossOriginOpenerPolicyRestrictProperties'),
+  (4255, 'CrossOriginOpenerPolicyRestrictPropertiesReportOnly'),
+  (4256, 'EventTimingInteractionId'),
+  (4257, 'SecurePaymentConfirmationOptOut'),
+  (4258, 'OBSOLETE_AnyPopoverAttribute'),
+  (4259, 'OBSOLETE_DeferredShapingWorked'),
+  (4260, 'OBSOLETE_DeferredShapingReshapedByForceLayout'),
+  (4261, 'MediaSourceGetHandle'),
+  (4262, 'IdentityInCanMakePaymentEvent'),
+  (4263, 'SharedStorageAPI_SharedStorage_DOMReference'),
+  (4264, 'SharedStorageAPI_AddModule_Method'),
+  (4265, 'SharedStorageAPI_Set_Method'),
+  (4266, 'SharedStorageAPI_Append_Method'),
+  (4267, 'SharedStorageAPI_Delete_Method'),
+  (4268, 'SharedStorageAPI_Clear_Method'),
+  (4269, 'SharedStorageAPI_SelectURL_Method'),
+  (4270, 'SharedStorageAPI_Run_Method'),
+  (4271, 'ViewTimelineConstructor'),
+  (4272, 'H1UserAgentFontSizeInSectionApplied'),
+  (4273, 'OBSOLETE_kV8PendingBeacon_Constructor'),
+  (4274, 'V8PendingBeacon_Url_AttributeGetter'),
+  (4275, 'OBSOLETE_kV8PendingBeacon_Url_AttributeSetter'),
+  (4276, 'V8PendingBeacon_Method_AttributeGetter'),
+  (4277, 'OBSOLETE_kV8PendingBeacon_Method_AttributeSetter'),
+  (4278, 'OBSOLETE_kV8PendingBeacon_PageHideTimeout_AttributeGetter'),
+  (4279, 'OBSOLETE_kV8PendingBeacon_PageHideTimeout_AttributeSetter'),
+  (4280, 'OBSOLETE_kV8PendingBeacon_State_AttributeGetter'),
+  (4281, 'V8PendingBeacon_Deactivate_Method'),
+  (4282, 'OBSOLETE_kV8PendingBeacon_SetData_Method'),
+  (4283, 'V8PendingBeacon_SendNow_Method'),
+  (4284, 'TabSharingBarSwitchToCapturer'),
+  (4285, 'TabSharingBarSwitchToCapturee'),
+  (4286, 'AutomaticLazyAds'),
+  (4287, 'AutomaticLazyEmbeds'),
+  (4288, 'OBSOLETE_TouchActionChangedAtPointerDown'),
+  (4289, 'DeviceOrientationPermissionRequested'),
+  (4290, 'DeviceOrientationUsedWithoutPermissionRequest'),
+  (4291, 'DeviceMotionPermissionRequested'),
+  (4292, 'DeviceMotionUsedWithoutPermissionRequest'),
+  (4293, 'PrivateNetworkAccessPermissionPrompt'),
+  (4294, 'PseudoBeforeAfterForDateTimeInputElement'),
+  (4295, 'OBSOLETE_kV8PendingBeacon_IsPending_AttributeGetter'),
+  (4296, 'ParentOfDisabledFormControlRespondsToMouseEvents'),
+  (4297, 'UnhandledExceptionCountInMainThread'),
+  (4298, 'UnhandledExceptionCountInWorker'),
+  (4299, 'OBSOLETE_WebCodecsImageDecoderPremultiplyAlphaDeprecation'),
+  (4300, 'CookieDomainNonASCII'),
+  (4301, 'ClientHintsMetaEquivDelegateCH'),
+  (4302, 'OBSOLETE_ExpectCTHeader'),
+  (4303, 'OBSOLETE_kNavigateEventTransitionWhile'),
+  (4304, 'OBSOLETE_kNavigateEventRestoreScroll'),
+  (4305, 'SendBeaconWithArrayBuffer'),
+  (4306, 'SendBeaconWithArrayBufferView'),
+  (4307, 'SendBeaconWithBlob'),
+  (4308, 'SendBeaconWithFormData'),
+  (4309, 'SendBeaconWithURLSearchParams'),
+  (4310, 'SendBeaconWithUSVString'),
+  (4311, 'ReplacedElementPaintedWithOverflow'),
+  (4312, 'ImageAd'),
+  (4313, 'LinkRelPrefetchAsDocumentSameOrigin'),
+  (4314, 'LinkRelPrefetchAsDocumentCrossOrigin'),
+  (4315, 'PersistentQuotaType'),
+  (4316, 'CrossOriginScrollIntoView'),
+  (4317, 'LinkRelCanonical'),
+  (4318, 'CredentialManagerIsConditionalMediationAvailable'),
+  (4319, 'V8PendingBeacon_Pending_AttributeGetter'),
+  (4320, 'V8PendingBeacon_BackgroundTimeout_AttributeGetter'),
+  (4321, 'V8PendingBeacon_BackgroundTimeout_AttributeSetter'),
+  (4322, 'V8PendingBeacon_Timeout_AttributeGetter'),
+  (4323, 'V8PendingBeacon_Timeout_AttributeSetter'),
+  (4324, 'V8PendingGetBeacon_Constructor'),
+  (4325, 'V8PendingGetBeacon_SetURL_Method'),
+  (4326, 'V8PendingPostBeacon_Constructor'),
+  (4327, 'V8PendingPostBeacon_SetData_Method'),
+  (4328, 'ContentVisibilityAutoStateChangeHandlerRegistered'),
+  (4329, 'ReplacedElementPaintedWithLargeOverflow'),
+  (4330, 'FlexboxAbsPosJustifyContent'),
+  (4331, 'MultipleFetchHandlersInServiceWorker'),
+  (4332, 'StorageAccessAPI_requestStorageAccessFor_Method'),
+  (4333, 'PrivateAggregationApiAll'),
+  (4334, 'PrivateAggregationApiFledge'),
+  (4335, 'PrivateAggregationApiSharedStorage'),
+  (4336, 'OBSOLETE_DeferredShaping2ReshapedByComputedStyle'),
+  (4337, 'OBSOLETE_DeferredShaping2ReshapedByDomContentLoaded'),
+  (4338, 'OBSOLETE_DeferredShaping2ReshapedByFcp'),
+  (4339, 'OBSOLETE_DeferredShaping2DisabledByFragmentAnchor'),
+  (4340, 'OBSOLETE_DeferredShaping2ReshapedByFocus'),
+  (4341, 'OBSOLETE_DeferredShaping2ReshapedByGeometry'),
+  (4342, 'OBSOLETE_DeferredShaping2ReshapedByInspector'),
+  (4343, 'OBSOLETE_DeferredShaping2ReshapedByPrinting'),
+  (4344, 'OBSOLETE_DeferredShaping2ReshapedByScrolling'),
+  (4345, 'LCPCandidateImageFromOriginDirtyStyle'),
+  (4346, 'V8TurboFanOsrCompileStarted'),
+  (4347, 'V8Document_HasRedemptionRecord_Method'),
+  (4348, 'OBSOLETE_DeferredShaping2ReshapedByLastResort'),
+  (4349, 'AudioContextSinkId'),
+  (4350, 'AudioContextSetSinkId'),
+  (4351, 'ViewportDependentLazyLoadedImageWithSizesAttribute'),
+  (4352, 'XRWebGLBindingGetCameraImage'),
+  (4353, 'SelectiveInOrderScript'),
+  (4354, 'V8AsyncStackTaggingCreateTaskCall'),
+  (4355, 'WebkitBoxWithoutWebkitLineClamp'),
+  (4356, 'DataUrlInSvgUse'),
+  (4357, 'WebAuthnConditionalUiGet'),
+  (4358, 'WebAuthnConditionalUiGetSuccess'),
+  (4359, 'WebAuthnRkRequiredCreationSuccess'),
+  (4360, 'DestructiveDocumentWriteAfterModuleScript'),
+  (4361, 'OBSOLETE_CSSAtSupportsDropInvalidWhileForgivingParsing'),
+  (4362, 'PermissionsPolicyUnload'),
+  (4363, 'ServiceWorkerSkippedForSubresourceLoad'),
+  (4364, 'ClientHintsPrefersReducedMotion'),
+  (4365, 'OBSOLETE_WakeLockAcquireScreenLockWithoutActivation'),
+  (4366, 'InteractiveWidgetOverlaysContent'),
+  (4367, 'InteractiveWidgetResizesContent'),
+  (4368, 'InteractiveWidgetResizesVisual'),
+  (4369, 'SerivceWorkerFallbackMainResource'),
+  (4370, 'OBSOLETE_GetDisplayMediaWithoutUserActivation'),
+  (4371, 'BackForwardCacheNotRestoredReasons'),
+  (4372, 'CSSNesting'),
+  (4373, 'SandboxIneffectiveAllowOriginAllowScript'),
+  (4374, 'DocumentOpenDifferentWindow'),
+  (4375, 'DocumentOpenMutateSandbox'),
+  (4376, 'EligibleForImageLoadingPrioritizationFix'),
+  (4377, 'ExecutedNonTrivialJavaScriptURL'),
+  (4378, 'StorageBucketsOpen'),
+  (4379, 'PerformanceEntryBufferSwaps'),
+  (4380, 'ClearPerformanceEntries'),
+  (4381, 'ViewportDependentLazyLoadedImageWithoutSizesAttribute'),
+  (4382, 'V8MediaStreamTrack_ApplyConstraints_Method'),
+  (4383, 'ViewTransition'),
+  (4384, 'ElementTogglePopover'),
+  (4385, 'OBSOLETE_LayoutMediaInlineChildren'),
+  (4386, 'ReduceAcceptLanguage'),
+  (4387, 'OBSOLETE_UuidInPackageUrlNavigation'),
+  (4388, 'CSSValueAppearanceMediaSliderRendered'),
+  (4389, 'CSSValueAppearanceMediaSliderThumbRendered'),
+  (4390, 'CSSValueAppearanceMediaVolumeSliderRendered'),
+  (4391, 'CSSValueAppearanceMediaVolumeSliderThumbRendered'),
+  (4392, 'V8PerformanceResourceTiming_DeliveryType_AttributeGetter'),
+  (4393, 'DocumentLoaderDeliveryTypeNavigationalPrefetch'),
+  (4394, 'SpeculationRulesHeader'),
+  (4395, 'SpeculationRulesDocumentRules'),
+  (4396, 'FedCmIframe'),
+  (4397, 'V8DocumentPictureInPicture_RequestWindow_Method'),
+  (4398, 'V8DocumentPictureInPicture_Window_AttributeGetter'),
+  (4399, 'V8DocumentPictureInPictureEvent_Window_AttributeGetter'),
+  (4400, 'DocumentPictureInPictureEnterEvent'),
+  (4401, 'SoftNavigationHeuristics'),
+  (4402, 'MathMLMathElement'),
+  (4403, 'MathMLMathElementInDocument'),
+  (4404, 'CSSAtRuleStylistic'),
+  (4405, 'CSSAtRuleStyleset'),
+  (4406, 'CSSAtRuleCharacterVariant'),
+  (4407, 'CSSAtRuleSwash'),
+  (4408, 'CSSAtRuleOrnaments'),
+  (4409, 'CSSAtRuleAnnotation'),
+  (4410, 'ServiceWorkerBypassFetchHandlerForMainResource'),
+  (4411, 'V8Document_HasPrivateToken_Method'),
+  (4412, 'ServiceWorkerSkippedForEmptyFetchHandler'),
+  (4413, 'ImageSet'),
+  (4414, 'WindowCloseHistoryLengthOne'),
+  (4415, 'OBSOLETE_CreateNSResolverWithNonElements'),
+  (4416, 'CSSValueAppearanceNonStandard'),
+  (4417, 'OBSOLETE_CSSGetComputedAnimationDelayZero'),
+  (4418, 'GetEffectTimingDelayZero'),
+  (4419, 'Scrollend'),
+  (4420, 'DOMWindowOpenCrossOriginIframe'),
+  (4421, 'StreamingDeclarativeShadowDOM'),
+  (4422, 'OBSOLETE_DialogCloseWatcherCancelSkipped'),
+  (4423, 'OBSOLETE_DialogCloseWatcherCancelSkippedAndDefaultPrevented'),
+  (4424, 'OBSOLETE_DialogCloseWatcherCloseSignalClosedMultiple'),
+  (4425, 'NoVarySearch'),
+  (4426, 'FedCmUserInfo'),
+  (4427, 'IDNA2008DeviationCharacterInHostnameOfSubresource'),
+  (4428, 'IDNA2008DeviationCharacterInHostnameOfIFrame'),
+  (4429, 'WindowOpenPopupOnMobile'),
+  (4430, 'WindowOpenedAsPopupOnMobile'),
+  (4431, 'PrivateNetworkAccessIgnoredCrossOriginPreflightError'),
+  (4432, 'PrivateNetworkAccessIgnoredCrossSitePreflightError'),
+  (4433, 'LinkRelPrerenderSameOrigin'),
+  (4434, 'LinkRelPrerenderSameSiteCrossOrigin'),
+  (4435, 'LinkRelPrerenderCrossSite'),
+  (4436, 'CSSBackgroundClipBorder'),
+  (4437, 'CSSBackgroundClipContent'),
+  (4438, 'CSSBackgroundClipPadding'),
+  (
+    4439,
+    'DisableThirdPartySessionStoragePartitioningAfterGeneralPartitioning'),
+  (4440, 'OBSOLETE_kCSSPseudoHasContainsMixOfValidAndInvalid'),
+  (4441, 'OBSOLETE_kCSSPseudoIsWhereContainsMixOfValidAndInvalid'),
+  (4442, 'PrivateNetworkAccessFetchedSubFrame'),
+  (4443, 'PrivateNetworkAccessFetchedTopFrame'),
+  (4444, 'DisableThirdPartyStoragePartitioning'),
+  (4445, 'ServiceWorkerFetchHandlerAddedAfterInitialization'),
+  (4446, 'ObsoleteCreateImageBitmapImageOrientationNone'),
+  (4447, 'WindowManagementPermissionDescriptorUsed'),
+  (4448, 'WindowPlacementPermissionDescriptorUsed'),
+  (4449, 'WindowManagementPermissionPolicyParsed'),
+  (4450, 'WindowPlacementPermissionPolicyParsed'),
+  (4451, 'ContentDispositionInSvgUse'),
+  (4452, 'SameDocumentCrossOriginInitiator'),
+  (4453, 'ServiceWorkerFetchHandlerModifiedAfterInitialization'),
+  (4454, 'OptionLabelInQuirksMode'),
+  (4455, 'ParseFromStringIncludeShadows'),
+  (4456, 'WebAppManifestScopeExtensions'),
+  (4457, 'ServiceWorkerBypassFetchHandlerForMainResourceByOriginTrial'),
+  (4458, 'OBSOLETE_V8RegExpUnicodeSetIncompatibilitiesWithUnicodeMode'),
+  (4459, 'FedCmAutoReauthn'),
+  (4460, 'TopicsAPIFetch'),
+  (4461, 'OBSOLETE_TopicsAPIXhr'),
+  (4462, 'ParseFromString'),
+  (
+    4463,
+    'OBSOLETE_HTMLPatternRegExpUnicodeSetIncompatibilitiesWithUnicodeMode'),
+  (4464, 'PopoverTypeAuto'),
+  (4465, 'PopoverTypeManual'),
+  (4466, 'PopoverTypeInvalid'),
+  (4467, 'CSSAnchorPositioning'),
+  (4468, 'ServiceWorkerEventHandlerAddedAfterInitialization'),
+  (4469, 'ServiceWorkerEventHandlerModifiedAfterInitialization'),
+  (4470, 'AuthorizationCrossOrigin'),
+  (4471, 'CSSColorMixFunction'),
+  (4472, 'CSSColorColorSpecifiedSpace'),
+  (4473, 'CSSColorLabOklab'),
+  (4474, 'CSSColorLchOklch'),
+  (4475, 'OBSOLETE_CreateNSResolverWithNonElements2'),
+  (4476, 'GetDisplayMediaWithPreferCurrentTabTrue'),
+  (4477, 'FencedFrameConfigAttribute'),
+  (4478, 'URLSearchParams_Has_Delete_MultipleArguments'),
+  (4479, 'PaymentHandlerMinimalHeaderUX'),
+  (4480, 'PopoverTypeHint'),
+  (4481, 'OBSOLETE_WebGPUWebCodecs'),
+  (4482, 'RTCPeerConnectionLegacyGetStatsTrial'),
+  (4483, 'ExecutedEmptyJavaScriptURLFromFrame'),
+  (4484, 'ExecutedJavaScriptURLFromFrame'),
+  (4485, 'ServiceWorkerBypassFetchHandlerForSubResource'),
+  (4486, 'CSSAtRuleStartingStyle'),
+  (4487, 'PrivateAggregationApiFledgeExtensions'),
+  (4488, 'DeprecatedInterestGroupDailyUpdateUrl'),
+  (4489, 'CSSColorGradientColorSpace'),
+  (4490, 'DanglingMarkupInWindowName'),
+  (4491, 'DanglingMarkupInWindowNameNotEndsWithNewLineOrGT'),
+  (4492, 'DanglingMarkupInWindowNameNotEndsWithGT'),
+  (4493, 'DanglingMarkupInTarget'),
+  (4494, 'DanglingMarkupInTargetNotEndsWithGT'),
+  (4495, 'DanglingMarkupInTargetNotEndsWithNewLineOrGT'),
+  (4496, 'AttributionFencedFrameReportingBeacon'),
+  (4497, 'IframeBrowsingTopicsAttribute'),
+  (4498, 'SpeculationRulesSelectorMatches'),
+  (4499, 'SpeculationRulesExplicitEagerness'),
+  (4500, 'SpeculationRulesEagernessConservative'),
+  (4501, 'SpeculationRulesEagernessModerate'),
+  (4502, 'SpeculationRulesEagernessEager'),
+  (4503, 'OBSOLETE_URLSetPortCheckOverflow'),
+  (4504, 'V8Animation_RangeStart_AttributeGetter'),
+  (4505, 'V8Animation_RangeStart_AttributeSetter'),
+  (4506, 'V8Animation_RangeEnd_AttributeGetter'),
+  (4507, 'V8Animation_RangeEnd_AttributeSetter'),
+  (4508, 'V8StorageBucket_Persist_Method'),
+  (4509, 'V8StorageBucket_Persisted_Method'),
+  (4510, 'V8StorageBucket_Estimate_Method'),
+  (4511, 'V8StorageBucket_Durability_Method'),
+  (4512, 'V8StorageBucket_SetExpires_Method'),
+  (4513, 'V8StorageBucket_Expires_Method'),
+  (4514, 'V8StorageBucket_IndexedDB_AttributeGetter'),
+  (4515, 'V8StorageBucket_Locks_AttributeGetter'),
+  (4516, 'V8StorageBucket_Caches_AttributeGetter'),
+  (4517, 'V8StorageBucket_GetDirectory_Method'),
+  (4518, 'V8StorageBucketManager_Keys_Method'),
+  (4519, 'V8StorageBucketManager_Delete_Method'),
+  (4520, 'NavigatorUAData_GetHighEntropyValues'),
+  (4521, 'SchedulerYield'),
+  (4522, 'HtmlClipboardApiUnsanitizedRead'),
+  (4523, 'HtmlClipboardApiUnsanitizedWrite'),
+  (4524, 'AsyncClipboardAPIUnsanitizedRead'),
+  (4525, 'WindowOpenFullscreenRequested'),
+  (4526, 'FullscreenAllowedByWindowOpen'),
+  (4527, 'AttributeValueContainsLtOrGt'),
+  (4528, 'V8ImportAssertionDeprecatedSyntax'),
+  (4529, 'ImageCaptureBackgroundBlur'),
+  (4530, 'PrivateNetworkAccessPreflightError'),
+  (4531, 'PrivateNetworkAccessPreflightSuccess'),
+  (4532, 'PrivateNetworkAccessPreflightWarning'),
+  (4533, 'CSSGetComputedAnimationDurationZero'),
+  (4534, 'CSSGetComputedWebkitFontSmoothingAnimationDurationZero'),
+  (4535, 'DocumentOpenAliasedOriginDocumentDomain'),
+  (4536, 'GamepadTouchEvents'),
+  (4537, 'GamepadTouchTouchId'),
+  (4538, 'GamepadTouchSurfaceId'),
+  (4539, 'GamepadTouchPosition'),
+  (4540, 'GamepadTouchSurfaceDimension'),
+  (4541, 'SandboxViaFencedFrame'),
+  (4542, 'VisibilityStateObserver'),
+  (4543, 'V8CompileHintsMagicAll'),
+  (4544, 'OBSOLETE_TextWrapBalance'),
+  (4545, 'OBSOLETE_TextWrapBalanceFail'),
+  (4546, 'AttributionReportingCrossAppWeb'),
+  (4547, 'SecurePaymentConfirmationActivationlessShow'),
+  (4548, 'ServiceWorkerBypassFetchHandlerForAllWithRaceNetworkRequest'),
+  (4549, 'FlexIntrinsicSizesCacheMiss'),
+  (4550, 'CSSStyleContainerQuery'),
+  (4551, 'CSSValueAppearanceMediaSlider'),
+  (4552, 'CSSValueAppearanceMediaSliderthumb'),
+  (4553, 'CSSValueAppearanceMediaVolumeSlider'),
+  (4554, 'CSSValueAppearanceMediaVolumeSliderthumb'),
+  (4555, 'CSSValueAppearanceSliderHorizontal'),
+  (4556, 'CSSValueAppearanceSliderVertical'),
+  (4557, 'CSSValueAppearanceSliderthumbHorizontal'),
+  (4558, 'CSSValueAppearanceSliderthumbVertical'),
+  (
+    4559,
+    'ServiceWorkerBypassFetchHandlerForAllWithRaceNetworkRequestByOriginTrial'),
+  (
+    4560,
+    'OBSOLETE_EventTimingPaintedPresentationPromiseResolvedWithEarlierPromiseUnresolved'),
+  (4561, 'LinkRelPreloadAsFont'),
+  (4562, 'CrossWindowAccessToBrowserGeneratedDocument'),
+  (4563, 'SpeculationRulesNoVarySearchHint'),
+  (4564, 'FileSystemAccessMoveRename'),
+  (4565, 'FileSystemAccessMoveReparent'),
+  (4566, 'FileSystemAccessMoveReparentAndRename'),
+  (4567, 'V8FileSystemDirectoryHandle_RemoveEntry_Method'),
+  (4568, 'V8FileSystemFileHandle_CreateWritable_Method'),
+  (4569, 'V8FileSystemFileHandle_GetFile_Method'),
+  (4570, 'V8FileSystemHandle_GetUniqueId_Method'),
+  (4571, 'V8FileSystemHandle_Remove_Method'),
+  (4572, 'PerformanceNavigateSystemEntropy'),
+  (4573, 'V8InvalidatedNumberStringNotRegexpLikeProtector'),
+  (4574, 'CriticalCHRestartNavigationTiming'),
+  (4575, 'TopLevelDocumentWithEmbeddedCredentials'),
+  (4576, 'V8Navigator_GetInterestGroupAdAuctionData_Method'),
+  (4577, 'LongAnimationFrameObserver'),
+  (4578, 'LongAnimationFrameRequested'),
+  (4579, 'FedCmLoginHint'),
+  (4580, 'FedCmRpContext'),
+  (4581, 'EventTimingArtificialPointerupOrClick'),
+  (4582, 'AbortSignalAny'),
+  (4583, 'FedCmIdpSigninStatusApi'),
+  (4584, 'FedCmIdpSigninStatusJsApi'),
+  (4585, 'ExecCommand'),
+  (4586, 'WebGPUQueueSubmit'),
+  (4587, 'WebGPUCanvasContextGetCurrentTexture'),
+  (4588, 'EditContext'),
+  (4589, 'ServiceWorkerStaticRouter_RegisterRouter'),
+  (4590, 'ServiceWorkerStaticRouter_Evaluate'),
+  (4591, 'ClientHintsUAFormFactor'),
+  (4592, 'URLSearchParamsHasFnBehaviourDiverged'),
+  (4593, 'URLSearchParamsDeleteFnBehaviourDiverged'),
+  (4594, 'OBSOLETE_TextWrapPretty'),
+  (4595, 'OBSOLETE_TextWrapPrettyFail'),
+  (4596, 'ContainerQueryEvalUnknown'),
+  (4597, 'OBSOLETE_EventTimingPresentationPromiseResolvedAfterReport'),
+  (4598, 'GetCoalescedEventsInInsecureContext'),
+  (4599, 'CSPEESameOriginBlanketEnforcement'),
+  (4601, 'SharedDictionaryUsed'),
+  (4602, 'SharedDictionaryUsedForNavigation'),
+  (4603, 'SharedDictionaryUsedForMainFrameNavigation'),
+  (4604, 'SharedDictionaryUsedForSubFrameNavigation'),
+  (4605, 'SharedDictionaryUsedForSubresource'),
+  (4606, 'PriceChangeConfirmation'),
+  (4607, 'PaymentRequestActivationlessShow'),
+  (4608, 'WebAppTabbed'),
+  (4609, 'FetchLater'),
+  (4610, 'URLPatternReliantOnImplicitURLComponentsInString'),
+  (4611, 'URLPatternReliantOnLaterComponentFromBaseURL'),
+  (4612, 'V8Navigator_CreateAuctionNonce_Method'),
+  (4613, 'CrossOriginWindowFrameElement'),
+  (4614, 'QuirksModeAboutBlankDocument'),
+  (4615, 'V8WasmMemory64'),
+  (4616, 'V8WasmMultiMemory'),
+  (4617, 'V8WasmGC'),
+  (4618, 'OBSOLETE_ORBBlockWithoutAnyEventHandler'),
+  (4619, 'OBSOLETE_ORBBlockWithOnErrorButWithoutOnLoadEventHandler'),
+  (4620, 'OBSOLETE_ORBBlockWithOnLoadButWithoutOnErrorEventHandler'),
+  (4621, 'OBSOLETE_ORBBlockWithOnLoadAndOnErrorEventHandler'),
+  (4622, 'OBSOLETE_ORBBlockWithAnyEventHandler'),
+  (4623, 'V8RTCEncodedVideoFrame_SetMetadata_Method'),
+  (4624, 'V8RTCEncodedVideoFrame_SetTimestamp_Method'),
+  (4625, 'V8RTCEncodedAudioFrame_SetTimestamp_Method'),
+  (4626, 'CSSAtRuleViewTransition'),
+  (4627, 'SharedDictionaryUsedWithSharedBrotli'),
+  (4628, 'SharedDictionaryUsedWithSharedZstd'),
+  (4629, 'ZstdContentEncoding'),
+  (4630, 'GetAllScreensMedia'),
+  (4631, 'InputEventToRecentlyMovedIframeMistakenlyDiscarded'),
+  (4632, 'CSSRelativeColor'),
+  (4633, 'XPathMissingVariableParsed'),
+  (4634, 'XPathMissingVariableEvaluated'),
+  (4635, 'ClientHintsPrefersReducedTransparency'),
+  (4636, 'ElementCapture'),
+  (4637, 'SharedStorageAPI_Fetch_Attribute'),
+  (4638, 'SharedStorageAPI_Image_Attribute'),
+  (4639, 'SharedStorageAPI_Iframe_Attribute'),
+  (4640, 'VirtualKeyboardShow'),
+  (4641, 'VirtualKeyboardHide'),
+  (4642, 'VirtualKeyboardOverlayPolicy'),
+  (4643, 'ScrollSnapNestedSnapAreas'),
+  (4644, 'ScrollSnapCoveringSnapArea'),
+  (4645, 'V8RTCEncodedAudioFrame_SetMetadata_Method'),
+  (4646, 'V8FetchLaterResult_Activated_AttributeGetter'),
+  (4647, 'V8Window_FetchLater_Method'),
+  (4648, 'FetchLaterInvokeStateDeferred'),
+  (4649, 'FetchLaterInvokeStateScheduled'),
+  (4650, 'FetchLaterInvokeStateTerminated'),
+  (4651, 'FetchLaterInvokeStateAborted'),
+  (4652, 'FetchLaterInvokeStateActivated'),
+  (4653, 'FetchLaterErrorUnknownBodyLength'),
+  (4654, 'FetchLaterErrorQuotaExceeded'),
+  (4655, 'V8FileSystemHandle_GetCloudIdentifiers_Method'),
+  (4656, 'PrivateAggregationApiEnableDebugMode'),
+  (4657, 'LineBreakPhrase'),
+  (4658, 'OBSOLETE_AttributionReportingUnderscorePrefixedFilterKey'),
+  (4659, 'PercentOrCalcStickyUsedOffset'),
+  (4660, 'PercentOrCalcRelativeUsedOffset'),
+  (4661, 'AutoRelativeUsedOffset'),
+  (4662, 'ViewportFitContain'),
+  (4663, 'ViewportFitCover'),
+  (4664, 'ViewportFitCoverOrSafeAreaInsetBottom'),
+  (4665, 'OutOfFlowJustifySelfNoInsets'),
+  (4666, 'OutOfFlowJustifySelfSingleInset'),
+  (4667, 'OutOfFlowJustifySelfBothInsets'),
+  (4668, 'OutOfFlowAlignSelfNoInsets'),
+  (4669, 'OutOfFlowAlignSelfSingleInset'),
+  (4670, 'OutOfFlowAlignSelfBothInsets'),
+  (4671, 'V8WebAssemblyJSStringBuiltins'),
+  (4672, 'ObservableConstructor'),
+  (4673, 'TextWrapBalance'),
+  (4674, 'TextWrapPretty'),
+  (4675, 'V8PointerEvent_DeviceId_AttributeGetter'),
+  (4676, 'SourceMappingUrlMagicCommentAtSign'),
+  (4677, 'HTMLDetailsElementNameAttribute'),
+  (4678, 'HTMLDetailsElementNameAttributeClosesSelf'),
+  (4679, 'HTMLDetailsElementNameAttributeClosesOther'),
+  (4680, 'CSSSubgridLayout'),
+  (4681, 'V8TemporalObject'),
+  (4682, 'ChromeCSIUnknown'),
+  (4683, 'ChromeCSIOnloadT'),
+  (4684, 'ChromeCSIPageT'),
+  (4685, 'ChromeCSIStartE'),
+  (4686, 'ChromeCSITran'),
+  (4687, 'ParseHTMLUnsafe'),
+  (4688, 'SetHTMLUnsafe'),
+  (4689, 'WebAssemblyModuleCompilation'),
+  (4690, 'V8MediaStreamTrack_Stats_AttributeGetter'),
+  (4691, 'ElementCheckVisibility'),
+  (4692, 'V8ClipboardItem_Supports_Method'),
+  (4693, 'ThirdPartyCookieAccessBlockByExperiment'),
+  (4694, 'CspWouldBlockIfWildcardDoesNotMatchWs'),
+  (4695, 'CspWouldBlockIfWildcardDoesNotMatchFtp'),
+  (4696, 'StorageAccessAPI_requestStorageAccess_BeyondCookies'),
+  (4697, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_all'),
+  (
+    4698,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_sessionStorage'),
+  (
+    4699,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_sessionStorage_Use'),
+  (4700, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_localStorage'),
+  (
+    4701,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_localStorage_Use'),
+  (4702, 'ElementCheckVisibilityOptionCheckVisibilityCSS'),
+  (4703, 'ElementCheckVisibilityOptionCheckOpacity'),
+  (4704, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_indexedDB'),
+  (4705, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_indexedDB_Use'),
+  (4706, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_locks'),
+  (4707, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_locks_Use'),
+  (4708, 'OBSOLETE_RubyElementWithDisplayBlockAndRt'),
+  (4709, 'CSSDeclarationAfterNestedRule'),
+  (4710, 'ThirdPartyCookieAdAccessBlockByExperiment'),
+  (4711, 'ServiceWorkerStaticRouter_AddRoutes'),
+  (4712, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_caches'),
+  (4713, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_caches_Use'),
+  (4714, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_getDirectory'),
+  (
+    4715,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_getDirectory_Use'),
+  (4716, 'ElementCheckVisibilityOptionContentVisibilityAuto'),
+  (4717, 'ElementCheckVisibilityOptionOpacityProperty'),
+  (4718, 'ElementCheckVisibilityOptionVisibilityProperty'),
+  (4719, 'AdClickMainFrameNavigation'),
+  (4720, 'LinkRelPrivacyPolicy'),
+  (4721, 'LinkRelTermsOfService'),
+  (4722, 'WebAppManifestIdField'),
+  (4723, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_estimate'),
+  (4724, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_estimate_Use'),
+  (
+    4725,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_createObjectURL'),
+  (
+    4726,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_createObjectURL_Use'),
+  (
+    4727,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_revokeObjectURL'),
+  (
+    4728,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_revokeObjectURL_Use'),
+  (
+    4729,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_BroadcastChannel'),
+  (
+    4730,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_BroadcastChannel_Use'),
+  (4731, 'ThirdPartyCookieDeprecation_AllowByExplicitSetting'),
+  (4732, 'ThirdPartyCookieDeprecation_AllowByGlobalSetting'),
+  (4733, 'ThirdPartyCookieDeprecation_AllowBy3PCDMetadata'),
+  (4734, 'ThirdPartyCookieDeprecation_AllowBy3PCD'),
+  (4735, 'ThirdPartyCookieDeprecation_AllowBy3PCDHeuristics'),
+  (4736, 'ThirdPartyCookieDeprecation_AllowByStorageAccess'),
+  (4737, 'ThirdPartyCookieDeprecation_AllowByTopLevelStorageAccess'),
+  (4738, 'IframeAdAuctionHeadersAttribute'),
+  (4739, 'AutoSpeculationRulesOptedOut'),
+  (4740, 'OverrideFlashEmbedwithHTML'),
+  (4741, 'LinkRelOpener'),
+  (4742, 'LinkRelOpenerTargetingSameFrame'),
+  (4743, 'CSSSelectorPseudoHas'),
+  (4744, 'WakeLockAcquireScreenLockWithoutStickyActivation'),
+  (4745, 'SubtleCryptoDeriveBitsZeroLength'),
+  (4746, 'SubtleCryptoDeriveBitsTruncation'),
+  (4747, 'TextDirectiveInShadowDOM'),
+  (4748, 'OBSOLETE_PseudoFirstLetterOnRt'),
+  (4749, 'OBSOLETE_PseudoFirstLineOnRt'),
+  (4750, 'AutoSizesLazy'),
+  (4751, 'AutoSizesNonLazy'),
+  (4752, 'OBSOLETE_TrustedTypesIntrospection'),
+  (4753, 'TrustedTypesIsCheck'),
+  (4754, 'MouseDragOnCancelledMouseMove'),
+  (4755, 'FedCmDomainHint'),
+  (4756, 'LCPImageWasLazy'),
+  (4757, 'EventTargetOnObservable'),
+  (4758, 'CredentialManagerCrossOriginPublicKeyCreateRequest'),
+  (4759, 'ViewTransitionNameAuto'),
+  (4760, 'V8WasmJavaScriptPromiseIntegration'),
+  (4761, 'WindowMinimize'),
+  (4762, 'WindowMaximize'),
+  (4763, 'WindowRestore'),
+  (4764, 'WindowSetResizable'),
+  (4765, 'V8WasmReturnCall'),
+  (4766, 'V8WasmExtendedConst'),
+  (4767, 'V8WasmRelaxedSimd'),
+  (4768, 'V8WasmTypeReflection'),
+  (4769, 'V8WasmExnRef'),
+  (4770, 'V8WasmTypedFuncRef'),
+  (4771, 'HTMLButtonInSelect'),
+  (4772, 'HTMLDatalistInSelect'),
+  (4773, 'EffectiveAlignContentForBlock'),
+  (4774, 'EffectiveAlignContentForTableCell'),
+  (4775, 'UserFeatureNgOptimizedImage'),
+  (4776, 'CSSAtRulePageMargin'),
+  (
+    4777,
+    'ThirdPartyCookieDeprecation_AllowByEnterprisePolicyCookieAllowedForUrls'),
+  (4778, 'UserFeatureNgAfterRender'),
+  (4779, 'UserFeatureNgHydration'),
+  (4780, 'CapturedSurfaceControl'),
+  (4781, 'ElementGetHTML'),
+  (4782, 'ElementAttachSerializableShadow'),
+  (4783, 'CSSBareDeclarationShift'),
+  (4784, 'CSSNestedGroupRuleSpecificity'),
+  (4785, 'CSSRuleWithSignalingChildModified'),
+  (4786, 'UserFeatureNextThirdPartiesGA'),
+  (4787, 'UserFeatureNextThirdPartiesGTM'),
+  (4788, 'UserFeatureNextThirdPartiesYouTubeEmbed'),
+  (4789, 'UserFeatureNextThirdPartiesGoogleMapsEmbed'),
+  (4790, 'StorageAccessAPI_hasUnpartitionedCookieAccess'),
+  (4791, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_cookies'),
+  (4792, 'VisualViewportScrollEndFired'),
+  (4793, 'AttributionReportingCrossAppWebSupportHeader'),
+  (4794, 'V8Element_AriaActiveDescendantElement_AttributeGetter'),
+  (4795, 'V8Element_AriaActiveDescendantElement_AttributeSetter'),
+  (4796, 'V8Element_AriaControlsElements_AttributeGetter'),
+  (4797, 'V8Element_AriaControlsElements_AttributeSetter'),
+  (4798, 'V8Element_AriaDescribedByElements_AttributeGetter'),
+  (4799, 'V8Element_AriaDescribedByElements_AttributeSetter'),
+  (4800, 'V8Element_AriaDetailsElements_AttributeGetter'),
+  (4801, 'V8Element_AriaDetailsElements_AttributeSetter'),
+  (4802, 'V8Element_AriaErrorMessageElements_AttributeGetter'),
+  (4803, 'V8Element_AriaErrorMessageElements_AttributeSetter'),
+  (4804, 'V8Element_AriaFlowToElements_AttributeGetter'),
+  (4805, 'V8Element_AriaFlowToElements_AttributeSetter'),
+  (4806, 'V8Element_AriaLabelledByElements_AttributeGetter'),
+  (4807, 'V8Element_AriaLabelledByElements_AttributeSetter'),
+  (4808, 'V8Element_AriaOwnsElements_AttributeGetter'),
+  (4809, 'V8Element_AriaOwnsElements_AttributeSetter'),
+  (4810, 'V8ElementInternals_AriaActiveDescendantElement_AttributeGetter'),
+  (4811, 'V8ElementInternals_AriaActiveDescendantElement_AttributeSetter'),
+  (4812, 'V8ElementInternals_AriaControlsElements_AttributeGetter'),
+  (4813, 'V8ElementInternals_AriaControlsElements_AttributeSetter'),
+  (4814, 'V8ElementInternals_AriaDescribedByElements_AttributeGetter'),
+  (4815, 'V8ElementInternals_AriaDescribedByElements_AttributeSetter'),
+  (4816, 'V8ElementInternals_AriaDetailsElements_AttributeGetter'),
+  (4817, 'V8ElementInternals_AriaDetailsElements_AttributeSetter'),
+  (4818, 'V8ElementInternals_AriaErrorMessageElements_AttributeGetter'),
+  (4819, 'V8ElementInternals_AriaErrorMessageElements_AttributeSetter'),
+  (4820, 'V8ElementInternals_AriaFlowToElements_AttributeGetter'),
+  (4821, 'V8ElementInternals_AriaFlowToElements_AttributeSetter'),
+  (4822, 'V8ElementInternals_AriaLabelledByElements_AttributeGetter'),
+  (4823, 'V8ElementInternals_AriaLabelledByElements_AttributeSetter'),
+  (4824, 'V8ElementInternals_AriaOwnsElements_AttributeGetter'),
+  (4825, 'V8ElementInternals_AriaOwnsElements_AttributeSetter'),
+  (4826, 'IdentityDigitalCredentials'),
+  (4827, 'CSSSelectorPseudoState'),
+  (4828, 'SpeculationRulesPrefetch'),
+  (4829, 'SpeculationRulesAuthorPrefetchRule'),
+  (4830, 'SpeculationRulesAuthorPrerenderRule'),
+  (4831, 'SpeculationRulesBrowserPrefetchRule'),
+  (4832, 'SpeculationRulesBrowserPrerenderRule'),
+  (4833, 'FirstPartySharedWorkerSameSiteCookiesNone'),
+  (4834, 'CSSCustomStateDeprecatedSyntax'),
+  (4835, 'FullscreenAllowedByContentSetting'),
+  (4836, 'SharedStorageAPI_CreateWorklet_Method'),
+  (4837, 'Canvas2DLayers'),
+  (4838, 'UserFeatureNuxtImage'),
+  (4839, 'UserFeatureNuxtPicture'),
+  (4840, 'UserFeatureNuxtThirdPartiesGA'),
+  (4841, 'UserFeatureNuxtThirdPartiesGTM'),
+  (4842, 'UserFeatureNuxtThirdPartiesYouTubeEmbed'),
+  (4843, 'UserFeatureNuxtThirdPartiesGoogleMaps'),
+  (4844, 'SelectParserDroppedTag'),
+  (4845, 'InputTypeRangeHorizontalLtr'),
+  (4846, 'InputTypeRangeHorizontalRtl'),
+  (4847, 'InputTypeRangeVerticalLtr'),
+  (4848, 'InputTypeRangeVerticalRtl'),
+  (4849, 'MeterElementHorizontalLtr'),
+  (4850, 'MeterElementHorizontalRtl'),
+  (4851, 'MeterElementVerticalLtr'),
+  (4852, 'MeterElementVerticalRtl'),
+  (4853, 'ProgressElementHorizontalLtr'),
+  (4854, 'ProgressElementHorizontalRtl'),
+  (4855, 'ProgressElementVerticalLtr'),
+  (4856, 'ProgressElementVerticalRtl'),
+  (4857, 'StorageAccessAPI_requestStorageAccess_BeyondCookies_SharedWorker'),
+  (
+    4858,
+    'StorageAccessAPI_requestStorageAccess_BeyondCookies_SharedWorker_Use'),
+  (4859, 'V8PointerEvent_GetCoalescedEvents_Method'),
+  (4861, 'CSSFunctions'),
+  (4862, 'CSSPageRule'),
+  (4863, 'V8RTCRtpReceiver_JitterBufferTarget_AttributeGetter'),
+  (4864, 'V8RTCRtpReceiver_JitterBufferTarget_AttributeSetter'),
+  (4865, 'TrustedTypesIntrospectionAttributeType'),
+  (4866, 'TrustedTypesIntrospectionPropertyType'),
+  (4867, 'TrustedTypesIntrospectionTypeMapping'),
+  (4868, 'IndexedDBFileLastModifiedDate');
+
+DROP INDEX IF EXISTS web_feature_name_idx;
+
+CREATE
+  UNIQUE INDEX web_feature_name_idx
+ON web_feature_name(web_feature_id);
+
+DROP VIEW IF EXISTS web_feature_metric;
+
+CREATE VIEW web_feature_metric
+AS
+WITH
+  sample AS (
+    SELECT interval_id, EXTRACT_ARG(arg_set_id, 'chrome_histogram_sample.sample') AS web_feature_id
+    FROM interesting_slice_span
+    WHERE
+      name = 'HistogramSample'
+      AND EXTRACT_ARG(arg_set_id, 'chrome_histogram_sample.name')
+        = 'Blink.UseCounter.Features'
+  )
+SELECT interval_id, name
+FROM web_feature_name, sample
+USING (web_feature_id)
+GROUP BY interval_id, name;
+
+SELECT * FROM web_feature_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/worker.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/worker.sql
new file mode 100644
index 0000000..1563705
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/experimental/worker.sql
@@ -0,0 +1,32 @@
+INCLUDE PERFETTO MODULE ext.loading_interesting_intervals;
+
+DROP VIEW IF EXISTS worker_metric;
+
+CREATE VIEW worker_metric
+AS
+WITH
+  data AS (
+    SELECT interval_id, thread.name AS thread_name
+    FROM interesting_slice_start, thread_track
+    ON track_id = thread_track.id,
+    thread
+    USING (utid)
+    WHERE interesting_slice_start.name = 'WorkerThread::InitializeWorkerContext'
+  )
+SELECT
+  interval_id,
+  'web_worker_count' AS metric_name,
+  'count' AS unit,
+  COUNT(*) AS value
+FROM data
+WHERE thread_name LIKE 'DedicatedWorker%'
+UNION ALL
+SELECT
+  interval_id,
+  'service_worker_count' AS metric_name,
+  'count' AS unit,
+  COUNT(*) AS value
+FROM data
+WHERE thread_name LIKE 'ServiceWorker%';
+
+SELECT * FROM worker_metric;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/search_latency.sql b/crossbench/probes/perfetto/trace_processor/queries/search_latency.sql
new file mode 100644
index 0000000..36efac1
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/search_latency.sql
@@ -0,0 +1 @@
+SELECT name,dur FROM slices WHERE name LIKE "GWS%";
diff --git a/crossbench/probes/perfetto/trace_processor/queries/speedometer_cpu_time.sql b/crossbench/probes/perfetto/trace_processor/queries/speedometer_cpu_time.sql
new file mode 100644
index 0000000..8cec645
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/speedometer_cpu_time.sql
@@ -0,0 +1,4 @@
+INCLUDE PERFETTO MODULE ext.speedometer;
+INCLUDE PERFETTO MODULE ext.speedometer_scheduling;
+
+SELECT * FROM ext_benchmark_scheduling_thread_cpu_time;
diff --git a/crossbench/probes/perfetto/trace_processor/trace_processor.py b/crossbench/probes/perfetto/trace_processor/trace_processor.py
new file mode 100644
index 0000000..63f0d84
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/trace_processor.py
@@ -0,0 +1,344 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import collections
+import json
+import logging
+import zipfile
+from typing import TYPE_CHECKING, Dict, Iterable, List, Optional, Tuple, Union
+
+import pandas as pd
+from google.protobuf.json_format import MessageToJson
+from perfetto.batch_trace_processor.api import (BatchTraceProcessor,
+                                                BatchTraceProcessorConfig)
+from perfetto.trace_processor.api import TraceProcessor, TraceProcessorConfig
+from perfetto.trace_uri_resolver.path import PathUriResolver
+from perfetto.trace_uri_resolver.registry import ResolverRegistry
+from perfetto.trace_uri_resolver.resolver import TraceUriResolver
+
+from crossbench import path as pth
+from crossbench.parse import PathParser
+from crossbench.probes.metric import MetricsMerger
+from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeContext
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.env import HostEnvironment
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+_QUERIES_DIR = pth.LocalPath(__file__).parent / "queries"
+_MODULES_DIR = pth.LocalPath(__file__).parent / "modules/ext"
+
+
+class CrossbenchTraceUriResolver(TraceUriResolver):
+  PREFIX = "crossbench"
+
+  def __init__(self, traces: Union[Iterable[Run], TraceProcessorProbeContext]):
+
+    def metadata(run: Run) -> Dict[str, str]:
+      return {
+          "cb_browser": run.browser.unique_name,
+          "cb_story": run.story.name,
+          "cb_temperature": run.temperature,
+          "cb_run": str(run.repetition)
+      }
+
+    if isinstance(traces, TraceProcessorProbeContext):
+      self._resolved = [
+          TraceUriResolver.Result(
+              trace=str(traces.merged_trace_path.absolute()),
+              metadata=metadata(traces.run))
+      ]
+    else:
+      self._resolved = [
+          TraceUriResolver.Result(
+              trace=str(
+                  run.results.get_by_name(
+                      TraceProcessorProbe.NAME).trace.absolute()),
+              metadata=metadata(run)) for run in traces
+      ]
+
+  def resolve(self) -> List["TraceUriResolver.Result"]:
+    return self._resolved
+
+
+class TraceProcessorProbe(Probe):
+  """
+  Trace processor probe.
+  """
+
+  NAME = "trace_processor"
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "batch",
+        type=bool,
+        required=False,
+        default=False,
+        help="Run queries in batch mode when all the test runs are done. This "
+        "can considerably reduce the run time at the expense of higher "
+        "memory usage (all traces will be loaded into memory at the same "
+        "time)")
+    parser.add_argument(
+        "metrics",
+        type=str,
+        is_list=True,
+        default=tuple(),
+        help="Name of metric to be run (can be any metric from Perfetto)")
+    parser.add_argument(
+        "queries",
+        type=str,
+        is_list=True,
+        default=tuple(),
+        help="Name of query to be run (under probes/trace_processor/queries)")
+    parser.add_argument(
+        "trace_processor_bin",
+        type=PathParser.local_binary_path,
+        required=False,
+        help="Path to the trace_processor binary")
+    return parser
+
+  def __init__(self,
+               batch: bool,
+               metrics: Iterable[str],
+               queries: Iterable[str],
+               trace_processor_bin: Optional[pth.LocalPath] = None):
+    super().__init__()
+    self._batch = batch
+    self._metrics = tuple(metrics)
+    self._queries = tuple(queries)
+    self._trace_processor_bin: Optional[pth.LocalPath] = None
+    if trace_processor_bin:
+      self._trace_processor_bin = PathParser.local_binary_path(
+          trace_processor_bin, "trace_processor")
+
+  @property
+  def batch(self) -> bool:
+    return self._batch
+
+  @property
+  def metrics(self) -> Tuple[str, ...]:
+    return self._metrics
+
+  @property
+  def queries(self) -> Tuple[str, ...]:
+    return self._queries
+
+  @property
+  def has_work(self) -> bool:
+    return len(self._queries) != 0 or len(self._metrics) != 0
+
+  @property
+  def needs_tp_run(self) -> bool:
+    return (not self.batch) and self.has_work
+
+  @property
+  def needs_btp_run(self) -> bool:
+    return self._batch and self.has_work
+
+  @property
+  def trace_processor_bin(self) -> Optional[pth.LocalPath]:
+    return self._trace_processor_bin
+
+  @property
+  def tp_config(self) -> TraceProcessorConfig:
+    extra_flags = [
+        "--add-sql-module",
+        _MODULES_DIR,
+    ]
+
+    return TraceProcessorConfig(
+        bin_path=self.trace_processor_bin,
+        resolver_registry=ResolverRegistry(
+            resolvers=[CrossbenchTraceUriResolver, PathUriResolver]),
+        extra_flags=extra_flags)
+
+  def get_context(self, run: Run) -> TraceProcessorProbeContext:
+    return TraceProcessorProbeContext(self, run)
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    super().validate_env(env)
+    self._check_sql()
+
+  def _check_sql(self) -> None:
+    """
+    Runs all metrics and queries on an empty trace. This will ensure that they
+    are correctly defined in trace processor.
+    """
+    with TraceProcessor(trace="/dev/null", config=self.tp_config) as tp:
+      for metric in self.metrics:
+        tp.metric([metric])
+      for query in self.queries:
+        query_path = _QUERIES_DIR / f"{query}.sql"
+        tp.query(query_path.read_text())
+
+  def _add_cb_columns(self, df: pd.DataFrame, run: Run) -> pd.DataFrame:
+    df["cb_browser"] = run.browser.unique_name
+    df["cb_story"] = run.story.name
+    df["cb_temperature"] = run.temperature
+    df["cb_run"] = run.repetition
+    return df
+
+  def _aggregate_results_by_query(
+      self, runs: Iterable[Run]) -> Dict[str, pd.DataFrame]:
+    res: Dict[str, pd.DataFrame] = {}
+    for run in runs:
+      for file in run.results.get(self).csv_list:
+        df = pd.read_csv(file)
+        df = self._add_cb_columns(df, run)
+        if file.stem in res:
+          res[file.stem] = pd.concat([res[file.stem], df])
+        else:
+          res[file.stem] = df
+
+    return res
+
+  def _merge_json(self, runs: Iterable[Run]) -> Dict[str, JsonDict]:
+    merged_metrics: Dict[str,
+                         MetricsMerger] = collections.defaultdict(MetricsMerger)
+    for run in runs:
+      for file_path in run.results[self].json_list:
+        with file_path.open() as json_file:
+          merged_metrics[file_path.stem].add(json.load(json_file))
+
+    return {
+        metric_name: merged.to_json()
+        for metric_name, merged in merged_metrics.items()
+    }
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    if self.needs_btp_run:
+      return self._run_btp(group)
+
+    return self._merge_browser_files(group)
+
+  def _merge_browser_files(self, group: BrowsersRunGroup) -> LocalProbeResult:
+    group_dir = group.get_local_probe_result_path(self)
+    group_dir.mkdir()
+    csv_files = []
+    json_files = []
+    for query, df in self._aggregate_results_by_query(group.runs).items():
+      csv_file = group_dir / f"{pth.safe_filename(query)}.csv"
+      df.to_csv(path_or_buf=csv_file, index=False)
+      csv_files.append(csv_file)
+    for metric, data in self._merge_json(group.runs).items():
+      json_file = group_dir / f"{pth.safe_filename(metric)}.json"
+      with json_file.open("x") as f:
+        json.dump(data, f, indent=4)
+        # TODO(375390958): figure out why files aren't fully written to
+        # pyfakefs here.
+        f.write("\n")
+      json_files.append(json_file)
+    return LocalProbeResult(csv=csv_files, json=json_files)
+
+  def _run_btp(self, group: BrowsersRunGroup) -> LocalProbeResult:
+    group_dir = group.get_local_probe_result_path(self)
+    group_dir.mkdir()
+    btp_config = BatchTraceProcessorConfig(tp_config=self.tp_config)
+
+    with BatchTraceProcessor(
+        traces=CrossbenchTraceUriResolver(group.runs),
+        config=btp_config) as btp:
+
+      def run_query(query: str):
+        query_path = _QUERIES_DIR / f"{query}.sql"
+        csv_file = group_dir / f"{pth.safe_filename(query)}.csv"
+        btp.query_and_flatten(query_path.read_text()).to_csv(
+            path_or_buf=csv_file, index=False)
+        return csv_file
+
+      csv_files = list(map(run_query, self.queries))
+
+      def run_metric(metric: str):
+        json_file = group_dir / f"{pth.safe_filename(metric)}.json"
+        protos = btp.metric([metric])
+        with json_file.open("x") as f:
+          for p in protos:
+            f.write(MessageToJson(p))
+        return json_file
+
+      json_files = list(map(run_metric, self.metrics))
+
+    return LocalProbeResult(csv=csv_files, json=json_files)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    logging.info("-" * 80)
+    logging.critical("TraceProcessor merged traces:")
+    for run in group.runs:
+      logging.critical("  - %s", run.results[self].trace)
+
+
+class TraceProcessorProbeContext(ProbeContext[TraceProcessorProbe]):
+
+  def __init__(self, probe: TraceProcessorProbe, run: Run) -> None:
+    super().__init__(probe, run)
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    result_dir = super().get_default_result_path()
+    self.host_platform.mkdir(result_dir)
+    return result_dir
+
+  def setup(self) -> None:
+    pass
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    return self._merge_trace_files().merge(self._maybe_run_tp())
+
+  def _merge_trace_files(self) -> LocalProbeResult:
+    with self.run.actions("TRACE_PROCESSOR: Merging trace files", verbose=True):
+      with zipfile.ZipFile(self.merged_trace_path, "w") as zip_file:
+        for f in self.run.results.all_traces():
+          zip_file.write(f, arcname=f.relative_to(self.run.out_dir))
+    return LocalProbeResult(trace=(self.merged_trace_path,))
+
+  def _maybe_run_tp(self):
+    if not self.probe.needs_tp_run:
+      return LocalProbeResult()
+
+    with TraceProcessor(
+        trace=CrossbenchTraceUriResolver(self),
+        config=self.probe.tp_config) as tp:
+      return self._run_queries(tp).merge(self._run_metrics(tp))
+
+  def _run_queries(self, tp: TraceProcessor) -> LocalProbeResult:
+
+    def run_query(query: str):
+      query_path = _QUERIES_DIR / f"{query}.sql"
+      csv_file = self.local_result_path / f"{pth.safe_filename(query)}.csv"
+      tp.query(query_path.read_text()).as_pandas_dataframe().to_csv(
+          path_or_buf=csv_file, index=False)
+      return csv_file
+
+    with self.run.actions("TRACE_PROCESSOR: Running queries", verbose=True):
+      files = tuple(map(run_query, self.probe.queries))
+      return LocalProbeResult(csv=files)
+
+  def _run_metrics(self, tp: TraceProcessor) -> LocalProbeResult:
+
+    def run_metric(metric: str):
+      json_file = self.local_result_path / f"{pth.safe_filename(metric)}.json"
+      proto = tp.metric([metric])
+      with json_file.open("x") as f:
+        f.write(MessageToJson(proto))
+      return json_file
+
+    with self.run.actions("TRACE_PROCESSOR: Running metrics", verbose=True):
+      files = tuple(map(run_metric, self.probe.metrics))
+      return LocalProbeResult(json=files)
+
+  @property
+  def merged_trace_path(self):
+    return self.local_result_path / "merged_trace.zip"
diff --git a/crossbench/probes/perfetto/tracing.py b/crossbench/probes/perfetto/tracing.py
new file mode 100644
index 0000000..a86a1f1
--- /dev/null
+++ b/crossbench/probes/perfetto/tracing.py
@@ -0,0 +1,323 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import enum
+import logging
+import sys
+from typing import TYPE_CHECKING, Dict, Optional, Sequence, Set
+
+from crossbench import path as pth
+from crossbench.config import ConfigEnum
+from crossbench.helper.path_finder import TraceconvFinder
+from crossbench.parse import NumberParser, ObjectParser, PathParser
+from crossbench.probes.chromium_probe import ChromiumProbe
+from crossbench.probes.probe import ProbeConfigParser, ProbeContext, ProbeKeyT
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.plt.base import ListCmdArgs
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+
+# TODO: go over these again and clean the categories.
+MINIMAL_CONFIG = frozenset((
+    "blink.user_timing",
+    "toplevel",
+    "v8",
+    "v8.execute",
+))
+DEVTOOLS_TRACE_CONFIG = frozenset((
+    "blink.console",
+    "blink.user_timing",
+    "devtools.timeline",
+    "disabled-by-default-devtools.screenshot",
+    "disabled-by-default-devtools.timeline",
+    "disabled-by-default-devtools.timeline.frame",
+    "disabled-by-default-devtools.timeline.layers",
+    "disabled-by-default-devtools.timeline.picture",
+    "disabled-by-default-devtools.timeline.stack",
+    "disabled-by-default-lighthouse",
+    "disabled-by-default-v8.compile",
+    "disabled-by-default-v8.cpu_profiler",
+    "disabled-by-default-v8.cpu_profiler.hires"
+    "latencyInfo",
+    "toplevel",
+    "v8.execute",
+))
+V8_TRACE_CONFIG = frozenset((
+    "blink",
+    "blink.user_timing",
+    "browser",
+    "cc",
+    "disabled-by-default-ipc.flow",
+    "disabled-by-default-power",
+    "disabled-by-default-v8.compile",
+    "disabled-by-default-v8.cpu_profiler",
+    "disabled-by-default-v8.cpu_profiler.hires",
+    "disabled-by-default-v8.gc",
+    "disabled-by-default-v8.inspector",
+    "disabled-by-default-v8.runtime",
+    "disabled-by-default-v8.runtime_stats",
+    "disabled-by-default-v8.runtime_stats_sampling",
+    "disabled-by-default-v8.stack_trace",
+    "disabled-by-default-v8.turbofan",
+    "disabled-by-default-v8.wasm.detailed",
+    "disabled-by-default-v8.wasm.turbofan",
+    "gpu",
+    "io",
+    "ipc",
+    "latency",
+    "latencyInfo",
+    "loading",
+    "log",
+    "mojom",
+    "navigation",
+    "net",
+    "netlog",
+    "toplevel",
+    "toplevel.flow",
+    "v8",
+    "v8.execute",
+    "wayland",
+))
+V8_GC_STATS_TRACE_CONFIG = V8_TRACE_CONFIG | frozenset(
+    ("disabled-by-default-v8.gc_stats",))
+
+TRACE_PRESETS: Dict[str, frozenset[str]] = {
+    "minimal": MINIMAL_CONFIG,
+    "devtools": DEVTOOLS_TRACE_CONFIG,
+    "v8": V8_TRACE_CONFIG,
+    "v8-gc-stats": V8_GC_STATS_TRACE_CONFIG,
+}
+
+
+@enum.unique
+class RecordMode(ConfigEnum):
+  CONTINUOUSLY = ("record-continuously",
+                  "Record until the trace buffer is full.")
+  UNTIL_FULL = ("record-until-full", "Record until the user ends the trace. "
+                "The trace buffer is a fixed size and we use it as "
+                "a ring buffer during recording.")
+  AS_MUCH_AS_POSSIBLE = ("record-as-much-as-possible",
+                         "Record until the trace buffer is full, "
+                         "but with a huge buffer size.")
+  TRACE_TO_CONSOLE = ("trace-to-console",
+                      "Echo to console. Events are discarded.")
+
+
+@enum.unique
+class RecordFormat(ConfigEnum):
+  JSON = ("json", "Old about://tracing compatible file format.")
+  PROTO = ("proto", "New https://ui.perfetto.dev/ compatible format")
+
+
+def parse_trace_config_file_path(value: str) -> pth.LocalPath:
+  data = ObjectParser.json_file(value)
+  if "trace_config" not in data:
+    raise argparse.ArgumentTypeError("Missing 'trace_config' property.")
+  NumberParser.positive_int(
+      data.get("startup_duration", "0"), "for 'startup_duration'")
+  if "result_file" in data:
+    raise argparse.ArgumentTypeError(
+        "Explicit 'result_file' is not allowed with crossbench. "
+        "--probe=tracing sets a results location automatically.")
+  config = data["trace_config"]
+  if "included_categories" not in config and (
+      "excluded_categories" not in config) and ("memory_dump_config"
+                                                not in config):
+    raise argparse.ArgumentTypeError(
+        "Empty trace config: no trace categories or memory dumps configured.")
+  RecordMode.parse(config.get("record_mode", RecordMode.CONTINUOUSLY))
+  return pth.LocalPath(value)
+
+
+ANDROID_TRACE_CONFIG_PATH = pth.AnyPosixPath(
+    "/data/local/chrome-trace-config.json")
+
+
+class TracingProbe(ChromiumProbe):
+  """
+  Chromium-only Probe to collect tracing / perfetto data that can be used by
+  chrome://tracing or https://ui.perfetto.dev/.
+
+  Currently WIP
+  """
+  NAME = "tracing"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  CHROMIUM_FLAGS = ("--enable-perfetto",)
+
+  HELP_URL = "https://bit.ly/chrome-about-tracing"
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "preset",
+        type=str,
+        default="minimal",
+        choices=TRACE_PRESETS.keys(),
+        help=("Use predefined trace categories, "
+              f"see source {__file__} for more details."))
+    parser.add_argument(
+        "categories",
+        is_list=True,
+        default=[],
+        type=str,
+        help=f"A list of trace categories to enable.\n{cls.HELP_URL}")
+    parser.add_argument(
+        "trace_config",
+        type=parse_trace_config_file_path,
+        help=("Sets Chromium's --trace-config-file to the given json config.\n"
+              "https://bit.ly/chromium-memory-startup-tracing "))
+    parser.add_argument(
+        "startup_duration",
+        default=0,
+        type=NumberParser.positive_zero_int,
+        help=("Stop recording tracing after a given number of seconds. "
+              "Use 0 (default) for unlimited recording time."))
+    parser.add_argument(
+        "record_mode",
+        default=RecordMode.CONTINUOUSLY,
+        type=RecordMode,
+        help="")
+    parser.add_argument(
+        "record_format",
+        default=RecordFormat.PROTO,
+        type=RecordFormat,
+        help=("Choose between 'json' or the default 'proto' format. "
+              "Perfetto proto output is converted automatically to the "
+              "legacy json format."))
+    parser.add_argument(
+        "traceconv",
+        default=None,
+        type=PathParser.file_path,
+        help=(
+            "Path to the 'traceconv.py' helper on the runner platofrm "
+            "to convert '.proto' traces to legacy '.json'. "
+            "If not specified, tries to find it in a v8 or chromium checkout."))
+    return parser
+
+  def __init__(self,
+               preset: Optional[str] = None,
+               categories: Optional[Sequence[str]] = None,
+               trace_config: Optional[pth.LocalPath] = None,
+               startup_duration: int = 0,
+               record_mode: RecordMode = RecordMode.CONTINUOUSLY,
+               record_format: RecordFormat = RecordFormat.PROTO,
+               traceconv: Optional[pth.LocalPath] = None) -> None:
+    super().__init__()
+    self._trace_config: Optional[pth.LocalPath] = trace_config
+    self._categories: Set[str] = set(categories or MINIMAL_CONFIG)
+    self._preset: Optional[str] = preset
+    if preset:
+      self._categories.update(TRACE_PRESETS[preset])
+    if self._trace_config:
+      if self._categories != set(MINIMAL_CONFIG):
+        raise argparse.ArgumentTypeError(
+            "TracingProbe requires either a list of "
+            "trace categories or a trace_config file.")
+      self._categories = set()
+
+    self._startup_duration: int = startup_duration
+    self._record_mode: RecordMode = record_mode
+    self._record_format: RecordFormat = record_format
+    self._traceconv: Optional[pth.LocalPath] = traceconv
+    if not traceconv and self._record_format == RecordFormat.PROTO:
+      self._find_traceconv()
+
+  def _find_traceconv(self) -> None:
+    if traceconv := TraceconvFinder(self.host_platform).path:
+      self._traceconv = self.host_platform.local_path(traceconv)
+      logging.debug("Using default traceconv: %s", traceconv)
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (("preset", self._preset),
+                          ("categories", tuple(self._categories)),
+                          ("startup_duration", self._startup_duration),
+                          ("record_mode", str(self._record_mode)),
+                          ("record_format", str(self._record_format)),
+                          ("traceconv", str(self._traceconv)))
+
+  @property
+  def result_path_name(self) -> str:
+    return f"trace.{self._record_format.value}"  # pylint: disable=no-member
+
+  @property
+  def traceconv(self) -> Optional[pth.LocalPath]:
+    return self._traceconv
+
+  @property
+  def record_format(self) -> RecordFormat:
+    return self._record_format
+
+  def attach(self, browser: Browser) -> None:
+    assert browser.attributes.is_chromium_based
+    flags = browser.flags
+    flags.update(self.CHROMIUM_FLAGS)
+    # Force proto file so we can convert it to legacy json as well.
+    flags["--trace-startup-format"] = str(self._record_format)
+    # pylint: disable=no-member
+    flags["--trace-startup-duration"] = str(self._startup_duration)
+    if self._trace_config:
+      # TODO: use ANDROID_TRACE_CONFIG_PATH
+      assert not browser.platform.is_android, (
+          "Trace config files not supported on android yet")
+      flags["--trace-config-file"] = str(self._trace_config.absolute())
+    else:
+      flags["--trace-startup-record-mode"] = str(self._record_mode)
+      assert self._categories, "No trace categories provided."
+      flags["--enable-tracing"] = ",".join(self._categories)
+    super().attach(browser)
+
+  def get_context(self, run: Run) -> TracingProbeContext:
+    return TracingProbeContext(self, run)
+
+
+class TracingProbeContext(ProbeContext[TracingProbe]):
+  _traceconv: Optional[pth.AnyPath]
+  _record_format: RecordFormat
+
+  def setup(self) -> None:
+    self.session.extra_flags["--trace-startup-file"] = str(self.result_path)
+    self._record_format = self.probe.record_format
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    if self._record_format == RecordFormat.JSON:
+      return self.browser_result(json=(self.result_path,))
+    traceconv: Optional[pth.LocalPath] = self.probe.traceconv
+    result = self.browser_result(proto=(self.result_path,))
+    if not traceconv:
+      logging.info(
+          "No traceconv binary: skipping converting proto to legacy traces")
+      return result
+    proto_file = result.get("proto")
+    try:
+      legacy_json_file = self._convert_to_json(traceconv, proto_file)
+      return self.local_result(proto=(proto_file,), json=(legacy_json_file,))
+    except Exception as e:  # pylint: disable=broad-exception-caught
+      logging.error("traceconv failure, defaulting to .proto file: %s", e)
+      return self.local_result(proto=(proto_file,))
+
+  def _convert_to_json(self, traceconv: pth.LocalPath,
+                       local_proto: pth.LocalPath) -> pth.LocalPath:
+    logging.info("Converting to legacy .json trace on local machine: %s",
+                 self.result_path)
+    json_trace_file = local_proto.with_suffix(".json")
+    cmd: ListCmdArgs = [traceconv, "json", self.result_path, json_trace_file]
+    if not self.host_platform.is_posix:
+      python_executable = sys.argv[0]
+      cmd = [python_executable] + cmd
+    self.host_platform.sh(*cmd)
+    return json_trace_file
diff --git a/crossbench/probes/performance_entries.py b/crossbench/probes/performance_entries.py
new file mode 100644
index 0000000..5bd841b
--- /dev/null
+++ b/crossbench/probes/performance_entries.py
@@ -0,0 +1,81 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+from __future__ import annotations
+
+import logging
+from typing import TYPE_CHECKING
+
+from crossbench.probes import metric
+from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.probe import ProbeIncompatibleBrowser
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.types import Json
+
+
+class PerformanceEntriesProbe(JsonResultProbe):
+  """
+  Extract all JavaScript PerformanceEntry [1] from a website.
+  Website owners can define more entries via `performance.mark()`.
+
+  [1] https://developer.mozilla.org/en-US/docs/Web/API/PerformanceEntry
+  """
+  NAME = "performance.entries"
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    if not hasattr(browser, "js"):
+      raise ProbeIncompatibleBrowser(self, browser,
+                                     "Needs browser with JS-execution support")
+
+  def to_json(self, actions: Actions) -> Json:
+    return actions.js("""
+      let data = { __proto__: null, paint: {}, mark: {} };
+      for (let entryType of Object.keys(data)) {
+        for (let entry of performance.getEntriesByType(entryType)) {
+           const typeData = data[entryType];
+           let values = typeData[entry.name];
+           if (values === undefined) {
+             values = typeData[entry.name] = { startTime: [], duration: [] };
+           }
+           for (let metricName of Object.keys(values)) {
+            values[metricName].push(entry[metricName]);
+          }
+        }
+      }
+      data.navigation = {};
+      const navigationTiming = performance.getEntriesByType("navigation")[0];
+      for (let name in navigationTiming) {
+        const value = navigationTiming[name];
+        if (typeof value !== "number") continue;
+        data.navigation[name] = value;
+      }
+      return data;
+      """)
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    stories = list(group.stories)
+    if len(stories) > 1:
+      logging.warning(
+          "%s: Merging performance.entries from %d possibly unrelated pages %s",
+          group.browser.unique_name, len(stories),
+          ", ".join(story.name for story in stories))
+    merged = metric.MetricsMerger.merge_json_list(
+        (story_group.results[self].json
+         for story_group in group.repetitions_groups),
+        merge_duplicate_paths=True)
+    return self.write_group_result(group, merged)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    # TODO: recreate the CSV from the merged JSON files since we might not
+    # get the same values in all browsers.
+    # TODO: Add merged browser data with separate stories.
+    return self.merge_browsers_json_list(group).merge(
+        self.merge_browsers_csv_list(group))
diff --git a/crossbench/probes/polling.py b/crossbench/probes/polling.py
new file mode 100644
index 0000000..c8ea934
--- /dev/null
+++ b/crossbench/probes/polling.py
@@ -0,0 +1,155 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import logging
+import threading
+import time
+from typing import TYPE_CHECKING, Iterable
+
+from crossbench.parse import DurationParser, ObjectParser
+from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeKeyT
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench import plt
+  from crossbench.env import HostEnvironment
+  from crossbench.path import LocalPath
+  from crossbench.plt.base import CmdArg, TupleCmdArgs
+  from crossbench.runner.run import Run
+
+class PollingProbe(Probe, metaclass=abc.ABCMeta):
+  """
+  Abstract probe to periodically collect the results of any bash cmd.
+  """
+  NAME = "polling"
+  IS_GENERAL_PURPOSE = False
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "interval",
+        type=DurationParser.positive_duration,
+        default=dt.timedelta(seconds=1),
+        help="Run the cmd at this interval and produce separate results.")
+    return parser
+
+  def __init__(
+      self,
+      cmd: Iterable[CmdArg],
+      interval: dt.timedelta = dt.timedelta(seconds=1)
+  ) -> None:
+    super().__init__()
+    self._cmd: TupleCmdArgs = tuple(cmd)
+    self._interval = interval
+    if interval.total_seconds() < 0.1:
+      raise ValueError(f"Polling interval must be >= 0.1s, but got: {interval}")
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (("cmd", tuple(self.cmd)),
+                          ("interval", self.interval.total_seconds()))
+
+  @property
+  def interval(self) -> dt.timedelta:
+    return self._interval
+
+  @property
+  def cmd(self) -> TupleCmdArgs:
+    return self._cmd
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    super().validate_env(env)
+    if env.repetitions != 1:
+      env.handle_warning(f"Probe={self.NAME} cannot merge data over multiple "
+                         f"repetitions={env.repetitions}.")
+
+  def get_context(self, run: Run) -> PollingProbeContext:
+    return PollingProbeContext(self, run)
+
+
+class ShellPollingProbe(PollingProbe):
+  """
+  General-purpose probe to periodically collect the stdout of a given bash cmd.
+  """
+
+  IS_GENERAL_PURPOSE = True
+  NAME = "poll"
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "cmd",
+        type=ObjectParser.sh_cmd,
+        required=True,
+        help="Write stdout of this CMD as a result.")
+    return parser
+
+
+class PollingProbeContext(ProbeContext[PollingProbe]):
+  _poller: CMDPoller
+
+  def __init__(self, probe: PollingProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._poller = CMDPoller(self.browser_platform, self.probe.cmd,
+                             self.probe.interval, self.local_result_path)
+
+  def setup(self) -> None:
+    self.local_result_path.mkdir()
+
+  def start(self) -> None:
+    self._poller.start()
+
+  def stop(self) -> None:
+    self._poller.stop()
+
+  def teardown(self) -> ProbeResult:
+    return LocalProbeResult(file=(self.local_result_path,))
+
+
+class CMDPoller(threading.Thread):
+
+  def __init__(self, platform: plt.Platform, cmd: Iterable[CmdArg],
+               interval: dt.timedelta, path: LocalPath):
+    super().__init__()
+    self._platform = platform
+    self._cmd: TupleCmdArgs = tuple(cmd)
+    self._path: LocalPath = path
+    if interval < dt.timedelta(seconds=0.1):
+      raise ValueError("Poller interval should be >= 0.1s for accuracy, "
+                       f"but got {interval}s")
+    self._interval_seconds = interval.total_seconds()
+    self._event = threading.Event()
+
+  def stop(self) -> None:
+    self._event.set()
+    self.join()
+
+  def run(self) -> None:
+    start_time = time.monotonic_ns()
+    while not self._event.is_set():
+      poll_start = dt.datetime.now()
+
+      data = self._platform.sh_stdout(*self._cmd)
+      datetime_str = poll_start.strftime("%Y-%m-%d_%H%M%S_%f")
+      out_file = self._path / f"{datetime_str}.txt"
+      with out_file.open("w", encoding="utf-8") as f:
+        f.write(data)
+
+      poll_end = dt.datetime.now()
+      diff = (poll_end - poll_start).total_seconds()
+      if diff > self._interval_seconds:
+        logging.warning("Poller command took longer than expected %fs: %s",
+                        self._interval_seconds, self._cmd)
+
+      # Calculate wait_time against fixed start time to avoid drifting.
+      total_time = (time.monotonic_ns() - start_time) / 10.0**9
+      wait_time = self._interval_seconds - (total_time % self._interval_seconds)
+      self._event.wait(wait_time)
diff --git a/crossbench/probes/power_sampler.py b/crossbench/probes/power_sampler.py
new file mode 100644
index 0000000..5f4cc07
--- /dev/null
+++ b/crossbench/probes/power_sampler.py
@@ -0,0 +1,256 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import csv
+import datetime as dt
+import enum
+import logging
+import subprocess
+from typing import TYPE_CHECKING, Optional, Sequence, Tuple
+
+from crossbench import compat, helper
+from crossbench.helper.path_finder import ChromiumBuildBinaryFinder
+from crossbench.parse import DurationParser, PathParser
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeKeyT, ProbeValidationError)
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.path import AnyPath
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+
+
+@enum.unique
+class SamplerType(compat.StrEnumWithHelp):
+  MAIN_DISPLAY = ("main_display",
+                  "Samples the backlight level of the main display.")
+  BATTERY = ("battery", "Provides data retrieved from the IOPMPowerSource.")
+  SMC = ("smc", ("Samples power usage from various hardware components "
+                 "from the System Management Controller (SMC)"))
+  M1 = ("m1", "Samples the temperature of M1 P-Cores and E-Cores.")
+  USER_IDLE_LEVEL = (
+      "user_idle_level",
+      "Samples the machdep.user_idle_level sysctl value if it exists")
+  RESOURCE_COALITION = ("resource_coalition", (
+      "Provides resource usage data for a group of tasks that are part of a "
+      "'resource coalition', including those that have died."))
+
+
+class PowerSamplerProbe(Probe):
+  """
+  Probe for chrome's power_sampler helper binary to collect MacOS specific
+  battery and system usage metrics.
+  Note that the battery monitor only gets a value infrequently (> 30s), thus
+  this probe mostly makes sense for long-running benchmarks.
+  """
+
+  NAME = "powersampler"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  BATTERY_ONLY: bool = True
+  SAMPLERS: Tuple[SamplerType,
+                  ...] = (SamplerType.SMC, SamplerType.USER_IDLE_LEVEL,
+                          SamplerType.MAIN_DISPLAY)
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument("bin_path", type=PathParser.binary_path)
+    parser.add_argument(
+        "sampling_interval",
+        type=DurationParser.positive_duration,
+        default=dt.timedelta(seconds=10))
+    parser.add_argument(
+        "samplers", type=SamplerType, default=cls.SAMPLERS, is_list=True)
+    parser.add_argument(
+        "wait_for_battery",
+        type=bool,
+        default=True,
+        help="Wait for the first non-100% battery measurement before "
+        "running the benchmark to ensure accurate readings.")
+    return parser
+
+  def __init__(self,
+               bin_path: Optional[AnyPath] = None,
+               sampling_interval: dt.timedelta = dt.timedelta(),
+               samplers: Sequence[SamplerType] = SAMPLERS,
+               wait_for_battery: bool = True):
+    super().__init__()
+    self._bin_path: Optional[AnyPath] = bin_path
+    if not self._bin_path:
+      logging.debug("No default power_sampler binary provided.")
+    self._sampling_interval = sampling_interval
+    if sampling_interval.total_seconds() < 0:
+      raise ValueError(f"Invalid sampling_interval={sampling_interval}")
+    assert SamplerType.BATTERY not in samplers
+    self._samplers = tuple(samplers)
+    self._wait_for_battery = wait_for_battery
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("bin_path", str(self.bin_path)),
+        ("sampling_interval", self.sampling_interval.total_seconds()),
+        ("samplers", tuple(map(str, self.samplers))),
+        ("wait_for_battery", self.wait_for_battery),
+    )
+
+  @property
+  def bin_path(self) -> Optional[AnyPath]:
+    return self._bin_path
+
+  @property
+  def sampling_interval(self) -> dt.timedelta:
+    return self._sampling_interval
+
+  @property
+  def samplers(self) -> Tuple[SamplerType, ...]:
+    return self._samplers
+
+  @property
+  def wait_for_battery(self) -> bool:
+    return self._wait_for_battery
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    self.expect_macos(browser)
+    if not browser.platform.is_battery_powered:
+      env.handle_warning("Power Sampler only works on battery power, "
+                         f"but Browser {browser} is connected to power.")
+    # TODO() warn when external monitors are connected
+    # TODO() warn about open terminals
+    self.find_power_sampler_bin(browser)
+
+  def find_power_sampler_bin(self, browser: Browser) -> AnyPath:
+    browser_platform = browser.platform
+    maybe_path = self.bin_path
+    if maybe_path and browser_platform.is_file(maybe_path):
+      return maybe_path
+    #  .../chrome/src/out/x64.Release/App.path
+    # Don't use parents[] access to stop at the root.
+    maybe_build_dir: AnyPath = browser.app_path.parent
+    finder = ChromiumBuildBinaryFinder(browser_platform, "power_sampler",
+                                       (maybe_build_dir,))
+    if maybe_path := finder.path:
+      if browser_platform.is_file(maybe_path):
+        logging.info("Using fallback power_sampler: %s", maybe_path)
+        return maybe_path
+    raise self.missing_power_sampler_error(browser_platform, maybe_build_dir)
+
+  def missing_power_sampler_error(self, browser_platform, maybe_build_dir):
+    is_build_dir = browser_platform.is_file(maybe_build_dir / "args.gn")
+    if not is_build_dir:
+      maybe_build_dir = browser_platform.path(
+          "path/to/chromium/src/out/Release")
+    error_message = [
+        "Could not find custom chromium power_sampler helper binary.",
+        "Please build 'power_sampler manually for local builds'",
+        f"autoninja -C {maybe_build_dir} power_sampler"
+    ]
+    return ProbeValidationError(self, "\n".join(error_message))
+
+  def get_context(self, run: Run) -> PowerSamplerProbeContext:
+    return PowerSamplerProbeContext(self, run)
+
+
+class PowerSamplerProbeContext(ProbeContext[PowerSamplerProbe]):
+
+  def __init__(self, probe: PowerSamplerProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._bin_path: AnyPath = probe.find_power_sampler_bin(self.browser)
+    self._active_user_process: Optional[subprocess.Popen] = None
+    self._power_process: Optional[subprocess.Popen] = None
+    self._power_battery_process: Optional[subprocess.Popen] = None
+    self._power_output: AnyPath = self.result_path.with_suffix(".power.json")
+    self._power_battery_output: AnyPath = self.result_path.with_suffix(
+        ".power_battery.json")
+
+  def setup(self) -> None:
+    self._active_user_process = self.browser_platform.popen(
+        self._bin_path,
+        "--no-samplers",
+        "--simulate-user-active",
+        stdout=subprocess.DEVNULL)
+    if self._active_user_process.poll():
+      raise ValueError("Could not start active user background sampler")
+    atexit.register(self.stop_processes)
+    if self.probe.wait_for_battery:
+      self._wait_for_battery_not_full(self.run)
+
+  def start(self) -> None:
+    assert self._active_user_process
+    if sampling_interval := self.probe.sampling_interval.total_seconds():
+      self._power_process = self.browser_platform.popen(
+          self._bin_path,
+          f"--sample-interval={int(sampling_interval)}",
+          f"--samplers={','.join(map(str, self.probe.samplers))}",
+          f"--json-output-file={self._power_output}",
+          f"--resource-coalition-pid={self.browser_pid}",
+          stdout=subprocess.DEVNULL)
+      if self._power_process.poll():
+        raise ValueError("Could not start power sampler")
+    self._power_battery_process = self.browser_platform.popen(
+        self._bin_path,
+        "--sample-on-notification",
+        f"--samplers={','.join(map(str, self.probe.samplers))+',battery'}",
+        f"--json-output-file={self._power_battery_output}",
+        f"--resource-coalition-pid={self.browser_pid}",
+        stdout=subprocess.DEVNULL)
+    if self._power_battery_process.poll():
+      raise ValueError("Could not start power and battery sampler")
+
+  def stop(self) -> None:
+    if self._power_process:
+      self._power_process.terminate()
+    if self._power_battery_process:
+      self._power_battery_process.terminate()
+
+  def teardown(self) -> ProbeResult:
+    self.stop_processes()
+    if self.probe.sampling_interval:
+      return self.browser_result(
+          json=[self._power_output, self._power_battery_output])
+    return self.browser_result(json=[self._power_battery_output])
+
+  def stop_processes(self) -> None:
+    if self._power_process:
+      helper.wait_and_kill(self._power_process)
+      self._power_process = None
+    if self._power_battery_process:
+      helper.wait_and_kill(self._power_battery_process)
+      self._power_battery_process = None
+    if self._active_user_process:
+      helper.wait_and_kill(self._active_user_process)
+      self._active_user_process = None
+
+  def _wait_for_battery_not_full(self, run: Run) -> None:
+    """
+    Empirical evidence has shown that right after a full battery charge, the
+    current capacity stays equal to the maximum capacity for several minutes,
+    despite the fact that power is definitely consumed. To ensure that power
+    consumption estimates from battery level are meaningful, wait until the
+    battery is no longer reporting being fully charged before crossbench.
+    """
+    del run
+    logging.info("POWER SAMPLER: Waiting for non-100% battery or "
+                 "initial sample to synchronize")
+    while True:
+      assert self.browser_platform.is_battery_powered, (
+          "Cannot wait for draining if power is connected.")
+
+      power_sampler_output = self.browser_platform.sh_stdout(
+          self._bin_path, "--sample-on-notification", "--samplers=battery",
+          "--sample-count=1")
+
+      for row in csv.DictReader(power_sampler_output.splitlines()):
+        max_capacity = float(row["battery_max_capacity(Ah)"])
+        current_capacity = float(row["battery_current_capacity(Ah)"])
+        percent = 100 * current_capacity / max_capacity
+        logging.debug("POWER SAMPLER: Battery level is %.2f%%", percent)
+        if max_capacity != current_capacity:
+          return
diff --git a/crossbench/probes/powermetrics.py b/crossbench/probes/powermetrics.py
new file mode 100644
index 0000000..23f4446
--- /dev/null
+++ b/crossbench/probes/powermetrics.py
@@ -0,0 +1,131 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import datetime as dt
+import enum
+import subprocess
+from typing import TYPE_CHECKING, Optional, Sequence, Tuple
+
+from crossbench import compat, helper
+from crossbench.parse import DurationParser
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeKeyT)
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.path import AnyPath
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+
+
+@enum.unique
+class SamplerType(compat.StrEnumWithHelp):
+  BATTERY = ("battery", "Battery level")
+  CPU_POWER = ("cpu_power",
+               "CPU power and per-core frequency and idle residency")
+  DISK = ("disk", "Number of read/write ops/bytes")
+  GPU_POWER = ("gpu_power",
+               "GPU power consumption, frequency and active residency")
+  INTERRUPTS = ("interrupts", "Per-core interrupt count")
+  NETWORK = ("network", "Number of in/out packets/bytes")
+  TASKS = ("tasks", "Per-task stats including CPU usage and wakeups")
+  THERMAL = ("thermal", "Thermal pressure state")
+
+
+class PowerMetricsProbe(Probe):
+  """
+  Probe to collect data using macOS's powermetrics command-line tool.
+  """
+
+  NAME = "powermetrics"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  SAMPLERS: Tuple[SamplerType,
+                  ...] = (SamplerType.BATTERY, SamplerType.CPU_POWER,
+                          SamplerType.DISK, SamplerType.GPU_POWER,
+                          SamplerType.INTERRUPTS, SamplerType.NETWORK,
+                          SamplerType.TASKS, SamplerType.THERMAL)
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "sampling_interval",
+        type=DurationParser.positive_duration,
+        default=1000)
+    parser.add_argument(
+        "samplers", type=SamplerType, default=cls.SAMPLERS, is_list=True)
+    return parser
+
+  def __init__(self,
+               sampling_interval: dt.timedelta = dt.timedelta(),
+               samplers: Sequence[SamplerType] = SAMPLERS):
+    super().__init__()
+    self._sampling_interval = sampling_interval
+    if sampling_interval.total_seconds() < 0:
+      raise ValueError(f"Invalid sampling_interval={sampling_interval}")
+    self._samplers = tuple(samplers)
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("sampling_interval", self.sampling_interval.total_seconds()),
+        ("samplers", tuple(map(str, self.samplers))),
+    )
+
+  @property
+  def sampling_interval(self) -> dt.timedelta:
+    return self._sampling_interval
+
+  @property
+  def samplers(self) -> Tuple[SamplerType, ...]:
+    return self._samplers
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    self.expect_macos(browser)
+
+  def get_context(self, run: Run) -> PowerMetricsProbeContext:
+    return PowerMetricsProbeContext(self, run)
+
+
+class PowerMetricsProbeContext(ProbeContext[PowerMetricsProbe]):
+
+  def __init__(self, probe: PowerMetricsProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._power_metrics_process: Optional[subprocess.Popen] = None
+    self._output_plist_file: AnyPath = self.result_path.with_suffix(".plist")
+
+  def start(self) -> None:
+    self._power_metrics_process = self.browser_platform.popen(
+        "sudo",
+        "powermetrics",
+        "-f",
+        "plist",
+        f"--samplers={','.join(map(str, self.probe.samplers))}",
+        "-i",
+        f"{int(self.probe.sampling_interval.total_seconds())}",
+        "--output-file",
+        self._output_plist_file,
+        stdout=subprocess.DEVNULL)
+    if self._power_metrics_process.poll():
+      raise ValueError("Could not start powermetrics")
+    atexit.register(self.stop_process)
+
+  def stop(self) -> None:
+    if self._power_metrics_process:
+      self._power_metrics_process.terminate()
+
+  def teardown(self) -> ProbeResult:
+    self.stop_process()
+    return self.browser_result(file=(self._output_plist_file,))
+
+  def stop_process(self) -> None:
+    if self._power_metrics_process:
+      helper.wait_and_kill(self._power_metrics_process)
+      self._power_metrics_process = None
diff --git a/crossbench/probes/probe.py b/crossbench/probes/probe.py
new file mode 100644
index 0000000..7b5e483
--- /dev/null
+++ b/crossbench/probes/probe.py
@@ -0,0 +1,254 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+from typing import (TYPE_CHECKING, Dict, Hashable, Optional, Set, Tuple, Type,
+                    TypeVar)
+
+from crossbench import plt
+from crossbench.config import ConfigParser
+from crossbench.probes.probe_context import ProbeContext, ProbeSessionContext
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.cache_temperatures import \
+      CacheTemperaturesRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+
+
+ProbeT = TypeVar("ProbeT", bound="Probe")
+
+
+class ProbeConfigParser(ConfigParser[ProbeT]):
+
+  def __init__(self, probe_cls: Type[ProbeT]) -> None:
+    super().__init__("Probe", probe_cls, allow_unused_config_data=False)
+    self._probe_cls: Type[ProbeT] = probe_cls
+
+  @property
+  def probe_cls(self) -> Type[ProbeT]:
+    return self._probe_cls
+
+
+class ProbeMissingDataError(ValueError):
+  pass
+
+
+class ProbeValidationError(ValueError):
+
+  def __init__(self, probe: Probe, message: str) -> None:
+    self.probe = probe
+    super().__init__(f"Probe({probe.NAME}): {message}")
+
+
+class ProbeIncompatibleBrowser(ProbeValidationError):
+
+  def __init__(self,
+               probe: Probe,
+               browser: Browser,
+               message: str = "Incompatible browser") -> None:
+    super().__init__(probe, f"{message}, got {browser.attributes}")
+
+
+ProbeKeyT = Tuple[Tuple[str, Hashable], ...]
+
+
+class Probe(abc.ABC):
+  """
+  Abstract Probe class.
+
+  Probes are responsible for extracting performance numbers from websites
+  / stories.
+
+  Probe interface:
+  - scope(): Return a custom ProbeContext (see below)
+  - validate_browser(): Customize to display warnings before using Probes with
+    incompatible settings / browsers.
+  The Probe object can the customize how to merge probe (performance) date at
+  multiple levels:
+  - multiple repetitions of the same story
+  - merged repetitions from multiple stories (same browser)
+  - Probe data from all Runs
+
+  Probes use a ProbeContext that is active during a story-Run.
+  The ProbeContext class defines a customizable interface
+  - setup(): Used for high-overhead Probe initialization
+  - start(): Low-overhead start-to-measure signal
+  - stop():  Low-overhead stop-to-measure signal
+  - teardown(): Used for high-overhead Probe cleanup
+
+  """
+  NAME: str = ""
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    return ProbeConfigParser(cls)
+
+  @classmethod
+  def from_config(cls: Type[ProbeT], config_data: Dict) -> ProbeT:
+    return cls.config_parser().parse(config_data)
+
+  @classmethod
+  def help_text(cls) -> str:
+    return cls.config_parser().help
+
+  @classmethod
+  def summary_text(cls) -> str:
+    return cls.config_parser().summary
+
+  # Set to False if the Probe cannot be used with arbitrary Stories or Pages
+  IS_GENERAL_PURPOSE: bool = True
+  PRODUCES_DATA: bool = True
+  # Set the default probe result location, used to figure out whether result
+  # files need to be transferred from a remote machine.
+  RESULT_LOCATION = ResultLocation.LOCAL
+  # Set to True if the probe only works on battery power with single runs
+  BATTERY_ONLY: bool = False
+
+  def __init__(self) -> None:
+    assert self.name is not None, "A Probe must define a name"
+    self._browsers: Set[Browser] = set()
+
+  def __str__(self) -> str:
+    return type(self).__name__
+
+  def __eq__(self, other) -> bool:
+    if self is other:
+      return True
+    if type(self) is not type(other):
+      return False
+    return self.key == other.key
+
+  @property
+  def is_internal(self) -> bool:
+    """Returns True for subclasses of InternalProbe that are not
+    directly user-accessible."""
+    return False
+
+  @property
+  def key(self) -> ProbeKeyT:
+    """Return a sort key."""
+    return (("name", self.name),)
+
+  def __hash__(self) -> int:
+    return hash(self.key)
+
+  @property
+  def host_platform(self) -> plt.Platform:
+    return plt.PLATFORM
+
+  @property
+  def name(self) -> str:
+    return self.NAME
+
+  @property
+  def result_path_name(self) -> str:
+    return self.name
+
+  @property
+  def is_attached(self) -> bool:
+    return len(self._browsers) > 0
+
+  def attach(self, browser: Browser) -> None:
+    assert browser not in self._browsers, (
+        f"Probe={self.name} is attached multiple times to the same browser")
+    self._browsers.add(browser)
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    """
+    Part of the Checklist, make sure everything is set up correctly for a probe
+    to run.
+    Browser-only validation is handled in validate_browser(...).
+    """
+    # Ensure that the proper super methods for setting up a probe were
+    # called.
+    assert self.is_attached, (
+        f"Probe {self.name} is not properly attached to a browser")
+    for browser in self._browsers:
+      self.validate_browser(env, browser)
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    """
+    Validate that browser is compatible with this Probe.
+    - Raise ProbeValidationError for hard-errors,
+    - Use env.handle_warning for soft errors where we expect recoverable errors
+      or only partially broken results.
+    """
+    del env, browser
+
+  def expect_browser(self,
+                     browser: Browser,
+                     attributes: BrowserAttributes,
+                     message: Optional[str] = None) -> None:
+    if attributes in browser.attributes:
+      return
+    if not message:
+      message = f"Incompatible browser, expected {attributes}"
+    raise ProbeIncompatibleBrowser(self, browser, message)
+
+  def expect_macos(self, browser: Browser) -> None:
+    if not browser.platform.is_macos:
+      raise ProbeIncompatibleBrowser(self, browser, "Only supported on macOS")
+
+  def merge_cache_temperatures(self,
+                               group: CacheTemperaturesRunGroup) -> ProbeResult:
+    """
+    For merging probe data from multiple browser cache temperatures with the
+    same repetition, story and browser.
+    """
+    # Return the first result by default.
+    return tuple(group.runs)[0].results[self]
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    """
+    For merging probe data from multiple repetitions of the same story.
+    """
+    del group
+    return EmptyProbeResult()
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    """
+    For merging multiple stories for the same browser.
+    """
+    del group
+    return EmptyProbeResult()
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    """
+    For merging all probe data (from multiple stories and browsers.)
+    """
+    del group
+    return EmptyProbeResult()
+
+  @abc.abstractmethod
+  def get_context(self: ProbeT, run: Run) -> Optional[ProbeContext[ProbeT]]:
+    pass
+
+  def get_session_context(
+      self: ProbeT,
+      session: BrowserSessionRunGroup) -> Optional[ProbeSessionContext[ProbeT]]:
+    del session
+
+  def log_run_result(self, run: Run) -> None:
+    """
+    Override to print a short summary of the collected results after a run
+    completes.
+    """
+    del run
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    """
+    Override to print a short summary of all the collected results.
+    """
+    del group
diff --git a/crossbench/probes/probe_context.py b/crossbench/probes/probe_context.py
new file mode 100644
index 0000000..d1ccca5
--- /dev/null
+++ b/crossbench/probes/probe_context.py
@@ -0,0 +1,300 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+import datetime as dt
+from typing import (TYPE_CHECKING, Generic, Iterable, Iterator, Optional,
+                    TypeVar)
+
+from crossbench import plt
+from crossbench.probes.results import (BrowserProbeResult, EmptyProbeResult,
+                                       LocalProbeResult, ProbeResult)
+
+if TYPE_CHECKING:
+  from selenium.webdriver.common.options import BaseOptions
+
+  from crossbench.browsers.browser import Browser
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.probes.probe import Probe
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+  from crossbench.runner.result_origin import ResultOrigin
+  from crossbench.runner.run import Run
+  from crossbench.runner.runner import Runner
+
+# Redefine here to avoid circular imports
+ProbeT = TypeVar("ProbeT", bound="Probe")
+
+
+class BaseProbeContext(Generic[ProbeT], metaclass=abc.ABCMeta):
+  """
+    Base class for an activation of a probe where active data collection
+    happens. See specific subclasses for implementations that can be used
+    for data collection during runs or whole sessions.
+    Override in Probe subclasses to implement actual performance data
+    collection.
+    - The data should be written to self.result_path.
+    - A file / list / dict of result file Paths should be returned by the
+      override teardown() method
+  """
+
+  def __init__(self, probe: ProbeT, result_origin: ResultOrigin) -> None:
+    self._probe: ProbeT = probe
+    self._result_origin = result_origin
+    self._is_active: bool = False
+    self._is_success: bool = False
+    self._start_time: Optional[dt.datetime] = None
+    self._stop_time: Optional[dt.datetime] = None
+
+  def set_start_time(self, start_datetime: dt.datetime) -> None:
+    assert self._start_time is None
+    self._start_time = start_datetime
+
+  @contextlib.contextmanager
+  def open(self) -> Iterator[None]:
+    assert self._start_time
+    assert not self._is_active
+    assert not self._is_success
+
+    with self.result_origin.exception_handler(f"Probe {self.name} start"):
+      self._is_active = True
+      self.start()
+
+    try:
+      yield
+    finally:
+      with self.result_origin.exception_handler(f"Probe {self.name} stop"):
+        self.stop()
+        self._is_success = True
+        assert self._stop_time is None
+      self._stop_time = dt.datetime.now()
+
+  @property
+  def probe(self) -> ProbeT:
+    return self._probe
+
+  @property
+  def result_origin(self) -> ResultOrigin:
+    return self._result_origin
+
+  @property
+  def browser_platform(self) -> plt.Platform:
+    return self.browser.platform
+
+  @property
+  def host_platform(self) -> plt.Platform:
+    return self.browser.host_platform
+
+  @property
+  @abc.abstractmethod
+  def browser(self) -> Browser:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def runner(self) -> Runner:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def session(self) -> BrowserSessionRunGroup:
+    pass
+
+  @property
+  def start_time(self) -> dt.datetime:
+    """
+    Returns a unified start time that is the same for all probe contexts
+    within a run. This can be used to account for startup delays caused by other
+    Probes.
+    """
+    assert self._start_time
+    return self._start_time
+
+  @property
+  def duration(self) -> dt.timedelta:
+    assert self._start_time and self._stop_time
+    return self._stop_time - self._start_time
+
+  @property
+  def is_success(self) -> bool:
+    return self._is_success
+
+  @property
+  @abc.abstractmethod
+  def result_path(self) -> AnyPath:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def local_result_path(self) -> LocalPath:
+    pass
+
+  @property
+  def name(self) -> str:
+    return self.probe.name
+
+  @property
+  def browser_pid(self) -> int:
+    maybe_pid = self.browser.pid
+    assert maybe_pid, "Browser is not runner or does not provide a pid."
+    return maybe_pid
+
+  def browser_result(self,
+                     url: Optional[Iterable[str]] = None,
+                     file: Optional[Iterable[AnyPath]] = None,
+                     **kwargs: Iterable[AnyPath]) -> BrowserProbeResult:
+    """Helper to create BrowserProbeResult that might be stored on a remote
+    browser/device and need to be copied over to the local machine."""
+    return BrowserProbeResult(self.result_origin, url=url, file=file, **kwargs)
+
+  def local_result(self,
+                   url: Optional[Iterable[str]] = None,
+                   file: Optional[Iterable[LocalPath]] = None,
+                   **kwargs: Iterable[LocalPath]) -> LocalProbeResult:
+    """Helper to create LocalProbeResult."""
+    return LocalProbeResult(url=url, file=file, **kwargs)
+
+  def setup(self) -> None:
+    """
+    Called before starting the browser, typically used to set run-specific
+    browser flags.
+    """
+
+  @abc.abstractmethod
+  def start(self) -> None:
+    pass
+
+  @abc.abstractmethod
+  def stop(self) -> None:
+    pass
+
+  @abc.abstractmethod
+  def teardown(self) -> ProbeResult:
+    pass
+
+
+class ProbeContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
+  """
+  A scope during which a probe is actively collecting data during a Run.
+  See BaseProbeContext additional usage.
+  """
+
+  def __init__(self, probe: ProbeT, run: Run) -> None:
+    super().__init__(probe, run)
+    self._run: Run = run
+    self._default_result_path: AnyPath = self.get_default_result_path()
+
+  def get_default_result_path(self) -> AnyPath:
+    return self._run.get_default_probe_result_path(self._probe)
+
+  @property
+  def run(self) -> Run:
+    return self._run
+
+  @property
+  def result_origin(self) -> ResultOrigin:
+    return self._run
+
+  @property
+  def session(self) -> BrowserSessionRunGroup:
+    return self._run.session
+
+  @property
+  def browser(self) -> Browser:
+    return self._run.browser
+
+  @property
+  def runner(self) -> Runner:
+    return self._run.runner
+
+  @property
+  def result_path(self) -> AnyPath:
+    return self._default_result_path
+
+  @property
+  def local_result_path(self) -> LocalPath:
+    return self.host_platform.local_path(self.result_path)
+
+  def setup_selenium_options(self, options: BaseOptions) -> None:
+    """
+    Custom hook to change selenium options before starting the browser.
+    """
+    # TODO: move to SessionContext
+    del options
+
+  @abc.abstractmethod
+  def start(self) -> None:
+    """
+    Called immediately before starting the given Run, after the browser started.
+    This method should have as little overhead as possible. If possible,
+    delegate heavy computation to the "SetUp" method.
+    """
+
+  def start_story_run(self) -> None:
+    """
+    Called before running a Story's core workload (Story.run)
+    and after running Story.setup.
+    """
+
+  def stop_story_run(self) -> None:
+    """
+    Called after running a Story's core workload (Story.run) and before running
+    Story.teardown.
+    """
+
+  @abc.abstractmethod
+  def stop(self) -> None:
+    """
+    Called immediately after finishing the given Run with the browser still
+    running.
+    This method should have as little overhead as possible. If possible,
+    delegate heavy computation to the "teardown" method.
+    """
+    return None
+
+  @abc.abstractmethod
+  def teardown(self) -> ProbeResult:
+    """
+    Called after stopping all probes and shutting down the browser.
+    Returns
+    - None if no data was collected
+    - If Data was collected:
+      - Either a path (or list of paths) to results file
+      - Directly a primitive json-serializable object containing the data
+    """
+    return EmptyProbeResult()
+
+
+class ProbeSessionContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
+  """
+  A scope during which a probe is actively collecting data during an active
+  browser session, which might span several runs.
+  See BaseProbeContext additional usage.
+  """
+
+  def __init__(self, probe: ProbeT, session: BrowserSessionRunGroup) -> None:
+    super().__init__(probe, session)
+    self._session: BrowserSessionRunGroup = session
+    self._default_result_path: AnyPath = self.get_default_result_path()
+
+  def get_default_result_path(self) -> AnyPath:
+    return self._session.get_default_probe_result_path(self._probe)
+
+  @property
+  def session(self) -> BrowserSessionRunGroup:
+    return self._session
+
+  @property
+  def result_origin(self) -> ResultOrigin:
+    return self._session
+
+  @property
+  def browser(self) -> Browser:
+    return self._session.browser
+
+  @property
+  def result_path(self) -> AnyPath:
+    return self._default_result_path
diff --git a/crossbench/probes/profiling/__init__.py b/crossbench/probes/profiling/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/probes/profiling/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/probes/profiling/browser_profiling.py b/crossbench/probes/profiling/browser_profiling.py
new file mode 100644
index 0000000..d807bc7
--- /dev/null
+++ b/crossbench/probes/profiling/browser_profiling.py
@@ -0,0 +1,248 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import enum
+import json
+from typing import TYPE_CHECKING, List, Optional, cast
+
+from selenium.webdriver.safari.options import Options as SafariOptions
+
+from crossbench import compat
+from crossbench.browsers.chromium.webdriver import ChromiumWebDriver
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeIncompatibleBrowser, ProbeKeyT,
+                                     ProbeValidationError)
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from selenium.webdriver.common.options import BaseOptions
+
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.path import AnyPath
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+
+
+@enum.unique
+class MozProfilerStartupFeatures(compat.StrEnumWithHelp):
+  """Options for MOZ_PROFILER_STARTUP_FEATURES env var.
+    Extracted via MOZ_PROFILER_HELP=1 ./firefox-nightly-en/firefox
+    """
+  JAVA = ("java", "Profile Java code, Android only")
+  JS = ("js", "Get the JS engine to expose the JS stack to the profiler")
+  LEAF = ("leaf", "Include the C++ leaf node if not stackwalking")
+  MAINTHREADIO = ("mainthreadio", "Add main thread file I/O")
+  FILEIO = ("fileio",
+            "Add file I/O from all profiled threads, implies mainthreadio")
+  FILEIOALL = ("fileioall", "Add file I/O from all threads, implies fileio")
+  NOIOSTACKS = ("noiostacks",
+                "File I/O markers do not capture stacks, to reduce overhead")
+  SCREENSHOTS = ("screenshots",
+                 "Take a snapshot of the window on every composition")
+  SEQSTYLE = ("seqstyle", "Disable parallel traversal in styling")
+  STACKWALK = ("stackwalk",
+               "Walk the C++ stack, not available on all platforms")
+  TASKTRACER = ("tasktracer", "Start profiling with feature TaskTracer")
+  THREADS = ("threads", "Profile the registered secondary threads")
+  JSTRACER = ("jstracer", "Enable tracing of the JavaScript engine")
+  JSALLOCATIONS = ("jsallocations",
+                   "Have the JavaScript engine track allocations")
+  NOSTACKSAMPLING = (
+      "nostacksampling",
+      "Disable all stack sampling: Cancels 'js', 'leaf', 'stackwalk' and labels"
+  )
+  PREFERENCEREADS = ("preferencereads", "Track when preferences are read")
+  NATIVEALLOCATIONS = (
+      "nativeallocations",
+      "Collect the stacks from a smaller subset of all native allocations, "
+      "biasing towards collecting larger allocations")
+  IPCMESSAGES = ("ipcmessages",
+                 "Have the IPC layer track cross-process messages")
+  AUDIOCALLBACKTRACING = ("audiocallbacktracing", "Audio callback tracing")
+  CPU = ("cpu", "CPU utilization")
+
+
+@enum.unique
+class FirefoxProfilerEnvVars(compat.StrEnum):
+  # If set to any value other than '' or '0'/'N'/'n', starts the
+  # profiler immediately on start-up.
+  STARTUP = "MOZ_PROFILER_STARTUP"
+  # Contains a comma-separated list of MozProfilerStartupFeatures.
+  STARTUP_FEATURES = "MOZ_PROFILER_STARTUP_FEATURES"
+  # If set, the profiler saves a profile to the named file on shutdown.
+  SHUTDOWN = "MOZ_PROFILER_SHUTDOWN"
+
+
+class BrowserProfilingProbe(Probe):
+  """
+  Browser profiling for generating in-browser performance profiles:
+  - Firefox https://profiler.firefox.com/
+  - Chrome: https://developer.chrome.com/docs/devtools/
+  - Safari: Timelines https://developer.apple.com/safari/tools
+  """
+  NAME = "browser-profiling"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  IS_GENERAL_PURPOSE = True
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "moz_profiler_startup_features",
+        type=MozProfilerStartupFeatures,
+        is_list=True,
+        default=[])
+    return parser
+
+  def __init__(self,
+               moz_profiler_startup_features: Optional[
+                   List[MozProfilerStartupFeatures]] = None):
+    super().__init__()
+    self._moz_profiler_startup_features: List[
+        MozProfilerStartupFeatures] = moz_profiler_startup_features or []
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("moz_profiler_startup_features",
+         tuple(map(str, self.moz_profiler_startup_features))),)
+
+  @property
+  def moz_profiler_startup_features(self) -> List[MozProfilerStartupFeatures]:
+    return self._moz_profiler_startup_features
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    if browser.platform.is_remote:
+      raise ProbeValidationError(
+          self, f"Only works on local browser, but got {browser}.")
+    attributes = browser.attributes
+    if attributes.is_chromium_based or attributes.is_safari:
+      return
+    if attributes.is_firefox:
+      browser_env = browser.platform.environ
+      for env_var in list(FirefoxProfilerEnvVars):
+        if env_var.value in browser_env:
+          env.handle_warning(
+              f"Probe({self}) conflicts with existing "
+              f"env[{env_var.value}]={browser_env[env_var.value]}")
+    raise ProbeIncompatibleBrowser(self, browser)
+
+  def get_context(self, run: Run) -> BrowserProfilingProbeContext:
+    attributes = run.browser.attributes
+    if attributes.is_chromium_based:
+      return ChromiumWebDriverBrowserProfilerProbeContext(self, run)
+    if attributes.is_firefox:
+      return FirefoxBrowserProfilerProbeContext(self, run)
+    if attributes.is_safari:
+      return SafariWebdriverBrowserProfilerProbeContext(self, run)
+    raise NotImplementedError(
+        f"Probe({self}): Unsupported browser: {run.browser}")
+
+
+class BrowserProfilingProbeContext(
+    ProbeContext[BrowserProfilingProbe], metaclass=abc.ABCMeta):
+
+  def setup(self) -> None:
+    pass
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+
+class ChromiumWebDriverBrowserProfilerProbeContext(BrowserProfilingProbeContext
+                                                  ):
+
+  def get_default_result_path(self) -> AnyPath:
+    return (super().get_default_result_path().parent /
+            f"{self.browser.type_name}.profile.json")
+
+  @property
+  def chromium(self) -> ChromiumWebDriver:
+    return cast(ChromiumWebDriver, self.browser)
+
+  def start(self) -> None:
+    self.chromium.start_profiling()
+
+  def stop(self) -> None:
+    with self.run.actions(f"Probe({self.probe}): extract DevTools profile."):
+      profile = self.chromium.stop_profiling()
+      local_result_path = self.local_result_path
+      with local_result_path.open("w", encoding="utf-8") as f:
+        json.dump(profile, f)
+        # TODO(375390958): figure out why files aren't fully written to
+        # pyfakefs here.
+        f.write("\n")
+
+  def teardown(self) -> ProbeResult:
+    return self.browser_result(json=[self.result_path])
+
+
+class FirefoxBrowserProfilerProbeContext(BrowserProfilingProbeContext):
+
+  def get_default_result_path(self) -> AnyPath:
+    return super().get_default_result_path().parent / "firefox.profile.json"
+
+  def setup(self) -> None:
+    env = self.browser.platform.environ
+    env[FirefoxProfilerEnvVars.STARTUP] = "y"
+    if self.probe.moz_profiler_startup_features:
+      env[FirefoxProfilerEnvVars.STARTUP_FEATURES] = ",".join(
+          str(feature) for feature in self.probe.moz_profiler_startup_features)
+    env[FirefoxProfilerEnvVars.SHUTDOWN] = str(self.result_path)
+
+  def teardown(self) -> ProbeResult:
+    env = self.browser.platform.environ
+    del env[FirefoxProfilerEnvVars.STARTUP]
+    del env[FirefoxProfilerEnvVars.STARTUP_FEATURES]
+    del env[FirefoxProfilerEnvVars.SHUTDOWN]
+    return self.browser_result(json=[self.result_path])
+
+
+class SafariWebdriverBrowserProfilerProbeContext(BrowserProfilingProbeContext):
+
+  def get_default_result_path(self) -> AnyPath:
+    return super().get_default_result_path().parent / "safari.timeline.json"
+
+  def setup_selenium_options(self, options: BaseOptions) -> None:
+    assert isinstance(options, SafariOptions)
+    cast(SafariOptions, options).automatic_profiling = True
+
+  def stop(self) -> None:
+    # TODO: Update this mess when Safari supports a command-line option
+    # to download the profile.
+    # Manually safe the profile using apple script to navigate the safari UI
+    # Stop profiling.
+    self.browser_platform.exec_apple_script("""
+      tell application "System Events"
+        keystroke "T" using {command down, option down, shift down}
+      end tell""")
+    # TODO: explicitly focus the developer pane
+    # Focus the Developer Tools split pane and use CMD-S to save the profile.
+    self.browser_platform.exec_apple_script(f"""
+      tell application "System Events"
+        keystroke "S" using command down
+        tell window "Save As"
+          delay 0.5
+          keystroke "g" using {{command down, shift down}}
+          delay 0.5
+          # Send DELETE key input to clear the current text input.
+          key code 51
+          keystroke "{self.result_path}"
+          delay 0.5
+          keystroke return
+          delay 0.5
+          keystroke return
+        end tell
+      end tell""")
+
+  def teardown(self) -> ProbeResult:
+    return self.browser_result(json=[self.result_path])
diff --git a/crossbench/probes/profiling/linux-perf-chrome-renderer-cmd.sh b/crossbench/probes/profiling/linux-perf-chrome-renderer-cmd.sh
new file mode 100755
index 0000000..571479a
--- /dev/null
+++ b/crossbench/probes/profiling/linux-perf-chrome-renderer-cmd.sh
@@ -0,0 +1,103 @@
+#!/usr/bin/env bash
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+PERF_DATA_DIR="."
+PERF_DATA_PREFIX="chrome_renderer"
+PERF_CLOCKID="mono"
+PERF_CALL_GRAPH="fp"
+PERF_FREQ_DEFAULT=10000
+PERF_FREQ=""
+PERF_COUNT=""
+PERF_RAW_ARGS=""
+RENDERER_ID="0"
+
+for i in "$@"; do
+  case $i in
+    -h|--help)
+cat <<EOF
+Usage: path/to/chrome --renderer-cmd-prefix='$0 [OPTION]' [CHROME OPTIONS]
+This script is mostly used in conjuction with linux_perf.py to run linux-perf
+for each renderer process.
+It generates perf.data files that can be read by pprof or linux-perf.
+
+File naming: \$OUT_DIR/\$PREFIX_\$PARENT_PID_\$RENDERER_ID.perf.data
+
+Options:
+  --perf-data-dir=OUT_DIR    Change the location where perf.data is written.
+                             Default: '${PERF_DATA_DIR}'
+  --perf-data-prefix=PREFIX  Set a custom prefix for all generated
+                             perf.data files.
+                             Default: '${PERF_DATA_PREFIX}'
+
+Pass-though Options:
+  --perf-count=SAMPLE_DELTA    Forwards options to 'perf record --count'
+                               Default: not used
+  --perf-freq=FREQUENCY        Forwards options to 'perf record --freq'
+                               Default: ${PERF_FREQ_DEFAULT}
+  --perf-clockid=CLOCK_TYPE    Forwards options to 'perf record --clockid'
+                               Default: '${PERF_CLOCKID}'
+  --perf-call-graph=MODE       Forwards options to 'perf record --call-graph'
+                               Default: '${PERF_CALL_GRAPH}'
+  --perf-args=ARGS             Forwards raw options to 'perf record \$ARGS'
+                               Default: not used
+EOF
+      exit
+      ;;
+    --perf-data-dir=*)
+      PERF_DATA_DIR="${i#*=}"
+      shift
+    ;;
+    --perf-data-prefix=*)
+      PERF_DATA_PREFIX="${i#*=}"
+      shift
+    ;;
+    --perf-freq=*)
+      PERF_FREQ="${i#*=}"
+      shift
+    ;;
+    --perf-count=*)
+      PERF_COUNT="${i#*=}"
+      shift
+    ;;
+    --perf-call-graph*)
+      PERF_CALL_GRAPH="${i#*=}"
+      shift
+    ;;
+    --perf-clockid*)
+      PERF_CLOCKID="${i#*=}"
+      shift
+    ;;
+    --perf-args*)
+      PERF_RAW_ARGS="${i#*=}"
+      shift
+    ;;
+    --renderer-client-id=*)
+      # Don't shift this option since it is passed in (and used by) chrome.
+      RENDERER_ID="${i#*=}"
+    ;;
+    *)
+      ;;
+  esac
+done
+
+SAMPLE_TRIGGER=""
+if [ -n "${PERF_COUNT}" ]; then
+  SAMPLE_TRIGGER+="--count=${PERF_COUNT}"
+elif [ -n "${PERF_FREQ}" ]; then
+  SAMPLE_TRIGGER+=" --freq=${PERF_FREQ}"
+else
+  SAMPLE_TRIGGER="--freq=${PERF_FREQ_DEFAULT}"
+fi
+
+# Make sure `perf record` doesn't create `.debug/` in the home directory.
+export JITDUMPDIR="${PERF_DATA_DIR}";
+PERF_OUTPUT="${PERF_DATA_DIR}/${PERF_DATA_PREFIX}_${PPID}_${RENDERER_ID}.perf.data";
+perf record \
+  --call-graph=${PERF_CALL_GRAPH} \
+  --clockid=${PERF_CLOCKID} \
+  ${SAMPLE_TRIGGER} \
+  ${PERF_RAW_ARGS} \
+  --output="${PERF_OUTPUT}" \
+  -- $@
diff --git a/crossbench/probes/profiling/system_profiling.py b/crossbench/probes/profiling/system_profiling.py
new file mode 100644
index 0000000..40b0194
--- /dev/null
+++ b/crossbench/probes/profiling/system_profiling.py
@@ -0,0 +1,1047 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import atexit
+import enum
+import io
+import json
+import logging
+import multiprocessing
+import shlex
+import signal
+import subprocess
+import time
+from functools import cached_property
+from typing import (TYPE_CHECKING, Any, Dict, Final, Iterable, List, Optional,
+                    Sequence, Tuple, Union, cast)
+
+from crossbench import helper
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chrome.version import ChromeVersion
+from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.compat import StrEnumWithHelp
+from crossbench.parse import NumberParser, ObjectParser
+from crossbench.plt.base import ListCmdArgs
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeIncompatibleBrowser, ProbeKeyT)
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.v8.log import V8LogProbe
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.run import Run
+
+
+@enum.unique
+class CleanupMode(StrEnumWithHelp):
+
+  @classmethod
+  def _missing_(cls, value) -> Optional[CleanupMode]:
+    if value is True:
+      return CleanupMode.ALWAYS
+    if value is False:
+      return CleanupMode.NEVER
+    return super()._missing_(value)
+
+  ALWAYS = ("always", "Always clean up temp files")
+  AUTO = ("auto", "Best-guess auto-cleanup")
+  NEVER = ("never", "Always clean up temp files")
+
+
+@enum.unique
+class TargetMode(StrEnumWithHelp):
+  RENDERER_MAIN_ONLY = ("renderer_main_only",
+                        "Profile Renderer Main thread only")
+  RENDERER_PROCESS_ONLY = ("renderer_process_only",
+                           "Profile Renderer process only")
+  BROWSER_APP_ONLY = ("browser_app_only",
+                      "Profile all processes of the Browser App only")
+  SYSTEM_WIDE = ("system_wide", "Run system-wide profiling")
+
+
+@enum.unique
+class CallGraphMode(StrEnumWithHelp):
+  # Refer to the documentation below for more details and comparison
+  # between these options:
+  # https://android.googlesource.com/platform/system/extras/+/master/simpleperf/doc/README.md.
+  NO_CALL_GRAPH = ("no_call_graph", "Do not record a call graph")
+  DWARF = ("dwarf", "Run DWARF-based unwinding unwinding")
+  FRAME_POINTER = ("frame_pointer", "Run frame pointer unwinding")
+
+
+V8_INTERPRETED_FRAMES_FLAG = "--interpreted-frames-native-stack"
+
+RENDERER_CMD_PATH: Final[pth.LocalPath] = pth.LocalPath(
+    __file__).parent / "linux-perf-chrome-renderer-cmd.sh"
+
+
+def perf_frequency(value: Any) -> Union[str, int]:
+  if value == "max":
+    return "max"
+  return NumberParser.positive_int(value, "frequency")
+
+
+class ProfilingProbe(Probe):
+  """
+  General-purpose sampling profiling probe.
+
+  Implementation:
+  - Uses linux-perf on linux platforms (per browser/renderer process)
+  - Uses xctrace on MacOS (currently only system-wide)
+  - Uses simpleperf on Android (renderer-only, browser-only, or system-wide)
+
+  For linux-based Chromium browsers it also injects JS stack samples with names
+  from V8. For Googlers it additionally can auto-upload symbolized profiles to
+  pprof.
+  """
+  NAME = "profiling"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  IS_GENERAL_PURPOSE = True
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "js",
+        type=bool,
+        default=True,
+        help=("Chrome-on-Linux-only: expose JS function names to the native "
+              "profiler"))
+    parser.add_argument(
+        "browser_process",
+        type=bool,
+        default=False,
+        help=("Chrome-on-Linux-only: also profile the browser process, "
+              "(as opposed to only renderer processes)"))
+    parser.add_argument(
+        "spare_renderer_process",
+        type=bool,
+        default=False,
+        help=("Chrome-only: Enable/Disable spare renderer processes via \n"
+              "--enable-/--disable-features=SpareRendererForSitePerProcess.\n"
+              "Spare renderers are disabled by default when profiling "
+              "for fewer uninteresting processes."))
+    parser.add_argument(
+        "v8_interpreted_frames",
+        type=bool,
+        default=True,
+        help=(
+            f"Chrome-only: Sets the {V8_INTERPRETED_FRAMES_FLAG} flag for "
+            "V8, which exposes interpreted frames as native frames. "
+            "Note that this comes at an additional performance and memory cost."
+        ))
+    parser.add_argument(
+        "pprof",
+        type=bool,
+        default=True,
+        help="linux-only: process collected samples with pprof.")
+    parser.add_argument(
+        "cleanup",
+        type=CleanupMode,
+        default=CleanupMode.AUTO,
+        help="Automatically clean up any temp files "
+        "(perf.data.jitted and temporary .so files on linux "
+        "cleaned up automatically if pprof is set to True)")
+    # Android/simpleperf-specific arguments.
+    parser.add_argument(
+        "target",
+        type=TargetMode,
+        default=TargetMode.BROWSER_APP_ONLY,
+        help=("Chrome-on-Android-only: "
+              "Profile either Renderer main/process only, "
+              "or all processes of the Browser App, or system-wide. "
+              "If Renderer main/process profiling is selected, "
+              "profiling begins **after** browser has started "
+              "and the benchmark story has been setup."))
+    parser.add_argument(
+        "pin_renderer_main_core",
+        type=NumberParser.positive_zero_int,
+        default=None,
+        help=("Chrome-on-Android-only: "
+              "Whether to pin the renderer main thread to a given core"))
+    parser.add_argument(
+        "call_graph_mode",
+        aliases=("call-graph",),
+        type=CallGraphMode,
+        default=CallGraphMode.FRAME_POINTER,
+        help=("Android/Linux-only: Specify whether to record a call graph, "
+              "and, if yes, which kind of stack unwinding to run."))
+    # Advanced Android/simpleperf/linux-perf-specific arguments.
+    # Generally, the defaults should suffice.
+    parser.add_argument(
+        "frequency",
+        aliases=("freq",),
+        type=perf_frequency,
+        default=None,
+        help=("Android/Linux-only: Event sampling frequency "
+              "(record at most `frequency` samples every second). "
+              "Please refer to '--freq' in the simpleperf/linux perf "
+              "documentation for more details."))
+    parser.add_argument(
+        "count",
+        type=NumberParser.positive_int,
+        default=None,
+        help=("Android/Linux-only: Event sampling period "
+              "(record one sample every `count` events). "
+              "Please refer to '--count' in the simpleperf/linux perf "
+              "documentation for more details."))
+    parser.add_argument(
+        "clockid",
+        type=ObjectParser.non_empty_str,
+        default=None,
+        help=("Android/Linux-only: Defines the clock id used in perf events. "
+              "Please refer to '--clockid' in the simpleperf/linux perf "
+              "documentation for more details. Defaults to 'mono'."))
+    parser.add_argument(
+        "cpu",
+        type=NumberParser.positive_zero_int,
+        is_list=True,
+        default=tuple(),
+        help=("Android/Linux-only: Sample only on the selected cpus, "
+              "specified as a list of 0-indexed cpu indices. "
+              "Please refer to '--cpu' in the simpleperf/linux-perf "
+              "documentation for more details."))
+    parser.add_argument(
+        "events",
+        type=str,
+        is_list=True,
+        default=tuple(),
+        help=("Android/Linux-only-only: Events to record. "
+              "Please refer to the '-e' simpleperf/linux-perf "
+              "documentation for more details."))
+    parser.add_argument(
+        "grouped_events",
+        type=str,
+        is_list=True,
+        default=tuple(),
+        help=("Android-only: Events to record as a single group. "
+              "These events are monitored as a group, "
+              "and scheduled in and out together. "
+              "Please refer to simpleperf documentation for `--group` "
+              "for more details."))
+    parser.add_argument(
+        "add_counters",
+        type=str,
+        is_list=True,
+        default=tuple(),
+        help=("Android-only: Add additional event counts in samples. NOTE: If "
+              "`add_counter` is used, `--no-inherit` is implicitly set, since "
+              "this is required by simpleperf. Please refer to simpleperf "
+              "documentation for `--add-counter` and `--no-inherit` for more "
+              "details."))
+    return parser
+
+  def __init__(self,
+               js: bool = True,
+               v8_interpreted_frames: bool = True,
+               pprof: bool = True,
+               cleanup: CleanupMode = CleanupMode.AUTO,
+               browser_process: bool = False,
+               spare_renderer_process: bool = False,
+               target: TargetMode = TargetMode.BROWSER_APP_ONLY,
+               pin_renderer_main_core: Optional[int] = None,
+               call_graph_mode: CallGraphMode = CallGraphMode.FRAME_POINTER,
+               frequency: Optional[Union[int, str]] = None,
+               clockid: Optional[str] = None,
+               count: Optional[int] = None,
+               cpu: Sequence[int] = (),
+               events: Sequence[str] = (),
+               grouped_events: Sequence[str] = (),
+               add_counters: Sequence[str] = ()):
+    super().__init__()
+    self._sample_js: bool = js
+    self._sample_browser_process: bool = browser_process
+    self._spare_renderer_process: bool = spare_renderer_process
+    self._run_pprof: bool = pprof
+    self._cleanup_mode = cleanup
+    self._expose_v8_interpreted_frames: bool = v8_interpreted_frames
+    if v8_interpreted_frames:
+      assert js, "Cannot expose V8 interpreted frames without js profiling."
+    self._target: TargetMode = target
+    self._pin_renderer_main_core: Optional[int] = pin_renderer_main_core
+    self._call_graph_mode: CallGraphMode = call_graph_mode
+    self._start_profiling_after_setup: bool = target in (
+        TargetMode.RENDERER_MAIN_ONLY,
+        TargetMode.RENDERER_PROCESS_ONLY) or pin_renderer_main_core is not None
+    self._frequency: Optional[Union[int, str]] = frequency
+    self._clockid: Optional[str] = clockid
+    self._count: Optional[int] = count
+    self._cpu: Tuple[int, ...] = tuple(cpu)
+    self._events: Tuple[str, ...] = tuple(events)
+    self._grouped_events: Tuple[str, ...] = tuple(grouped_events)
+    self._add_counters: Tuple[str, ...] = tuple(add_counters)
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("js", self._sample_js),
+        ("v8_interpreted_frames", self._expose_v8_interpreted_frames),
+        ("pprof", self._run_pprof),
+        ("cleanup", self._cleanup_mode),
+        ("browser_process", self._sample_browser_process),
+        ("spare_renderer_process", self._spare_renderer_process),
+        ("target", str(self._target)),
+        ("pin_renderer_main_core", self._pin_renderer_main_core),
+        ("call_graph_mode", str(self._call_graph_mode)),
+        ("start_profiling_after_setup", self._start_profiling_after_setup),
+        ("frequency", self._frequency),
+        ("count", self._count),
+        ("cpu", self._cpu),
+        ("events", self._events),
+        ("grouped_events", self._grouped_events),
+        ("add_counters", self._add_counters),
+    )
+
+  @property
+  def sample_js(self) -> bool:
+    return self._sample_js
+
+  @property
+  def sample_browser_process(self) -> bool:
+    return self._sample_browser_process
+
+  @property
+  def run_pprof(self) -> bool:
+    return self._run_pprof
+
+  @property
+  def cleanup_mode(self) -> CleanupMode:
+    return self._cleanup_mode
+
+  @property
+  def target(self) -> TargetMode:
+    return self._target
+
+  @property
+  def pin_renderer_main_core(self) -> Optional[int]:
+    return self._pin_renderer_main_core
+
+  @property
+  def call_graph_mode(self) -> CallGraphMode:
+    return self._call_graph_mode
+
+  @property
+  def start_profiling_after_setup(self) -> bool:
+    return self._start_profiling_after_setup
+
+  @property
+  def frequency(self) -> Optional[Union[int, str]]:
+    return self._frequency
+
+  @property
+  def clockid(self) -> Optional[str]:
+    return self._clockid
+
+  @property
+  def count(self) -> Optional[int]:
+    return self._count
+
+  @property
+  def cpu(self) -> Tuple[int, ...]:
+    return self._cpu
+
+  @property
+  def events(self) -> Tuple[str, ...]:
+    return self._events
+
+  @property
+  def grouped_events(self) -> Tuple[str, ...]:
+    return self._grouped_events
+
+  @property
+  def add_counters(self) -> Tuple[str, ...]:
+    return self._add_counters
+
+  def attach(self, browser: Browser) -> None:
+    super().attach(browser)
+    if browser.platform.is_linux or browser.platform.is_android:
+      assert browser.attributes.is_chromium_based, (
+          f"Expected Chromium-based browser, found {type(browser)}.")
+    if browser.attributes.is_chromium_based:
+      chromium = cast(Chromium, browser)
+      if not self._spare_renderer_process:
+        chromium.features.disable("SpareRendererForSitePerProcess")
+      self._attach(chromium)
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    browser_platform = browser.platform
+    if browser_platform.is_linux:
+      self._validate_linux(env, browser)
+    elif browser_platform.is_macos:
+      self._validate_macos(env, browser)
+    elif browser_platform.is_android:
+      self._validate_android(env, browser)
+    else:
+      raise ProbeIncompatibleBrowser(self, browser)
+    if self.run_pprof:
+      self._validate_pprof(env, browser)
+    # Check that certain Android-only options are
+    # not provided by on other platforms.
+    if not browser_platform.is_android and not browser_platform.is_linux:
+      self._validate_perf_settings(browser)
+    if not browser_platform.is_android:
+      self._validate_non_android_perf_settings(browser)
+
+  def _validate_perf_settings(self, browser) -> None:
+    unsupported_settings = (
+        ("frequency", self._frequency),
+        ("count", self._count),
+        ("cpu", self._cpu),
+        ("events", self._events),
+    )
+    self._validate_unsupported_settings(browser, unsupported_settings,
+                                        "Android and Linux")
+
+  def _validate_non_android_perf_settings(self, browser) -> None:
+    unsupported_settings = (
+        ("grouped_events", self._grouped_events),
+        ("add_counters", self._add_counters),
+    )
+    self._validate_unsupported_settings(browser, unsupported_settings,
+                                        "Android")
+
+  def _validate_unsupported_settings(self, browser,
+                                     unsupported_settings: Iterable[Tuple[str,
+                                                                          Any]],
+                                     platforms) -> None:
+    for name, value in unsupported_settings:
+      if value:
+        raise ProbeIncompatibleBrowser(
+            self, browser,
+            f"{repr(name)} is currently only supported on {platforms}")
+
+  def _validate_linux(self, env: HostEnvironment, browser: Browser) -> None:
+    env.check_installed(binaries=["pprof"])
+    assert browser.platform.which("perf"), "Please install linux-perf"
+
+  def _validate_macos(self, env: HostEnvironment, browser: Browser) -> None:
+    assert browser.platform.which(
+        "xctrace"), "Please install Xcode to use xctrace"
+    # Only Linux-perf and Android-simpleperf results can be merged
+    if env.repetitions > 1:
+      env.handle_warning(f"Probe={self.NAME} cannot merge data over multiple "
+                         f"repetitions={env.repetitions}.")
+
+  def _assert_is_chrome_with_extension(self, browser: Browser) -> None:
+    assert (
+        BrowserAttributes.CHROME in browser.attributes and
+        browser.major_version >= 124), (
+            "For RENDERER_MAIN_ONLY/RENDERER_PROCESS_ONLY profiling, "
+            "browser version >= M124 https://crrev.com/c/5374765 is required.")
+
+  def _requires_chrome_with_extension(self) -> bool:
+    return self._target in (TargetMode.RENDERER_MAIN_ONLY,
+                            TargetMode.RENDERER_PROCESS_ONLY
+                           ) or self._pin_renderer_main_core is not None
+
+  def _validate_android(self, env: HostEnvironment, browser: Browser) -> None:
+    del env
+    if self._requires_chrome_with_extension():
+      self._assert_is_chrome_with_extension(browser)
+    assert browser.platform.which("simpleperf"), "simpleperf is not available"
+
+  def _validate_pprof(self, env: HostEnvironment, browser: Browser) -> None:
+    assert self._run_pprof
+    host_platform = browser.host_platform
+    self._run_pprof = host_platform.which("gcert") is not None
+    if not self.run_pprof:
+      logging.warning(
+          "Disabled automatic pprof uploading for non-googler machine.")
+      return
+    if browser.platform.is_macos:
+      # Converting xctrace to pprof is not supported on macos
+      return
+    try:
+      if gcertstatus := browser.platform.which("gcertstatus"):
+        browser.platform.sh(gcertstatus)
+        return
+      env.handle_warning("Could not find gcertstatus")
+    except plt.SubprocessError:
+      env.handle_warning("Please run gcert for generating pprof results")
+
+  def _attach(self, browser: Chromium) -> None:
+    if self._sample_js:
+      if browser.platform.is_linux:
+        browser.js_flags.set("--perf-prof")
+      if self._expose_v8_interpreted_frames:
+        browser.js_flags.set(V8_INTERPRETED_FRAMES_FLAG)
+    if browser.platform.is_linux and browser.platform.is_local:
+      self._set_renderer_cmd_prefix(browser)
+    # Disable sandbox to write profiling data
+    browser.flags.set("--no-sandbox")
+
+  def _set_renderer_cmd_prefix(self, browser):
+    assert not browser.platform.is_remote, (
+        "Copying renderer command prefix to remote platform is "
+        "not implemented yet")
+    assert RENDERER_CMD_PATH.is_file(), f"Didn't find {RENDERER_CMD_PATH}"
+    cmd_prefix = [str(RENDERER_CMD_PATH), f"--perf-data-dir={self.NAME}"]
+    if freq := self.frequency:
+      cmd_prefix.append(f"--perf-freq={freq}")
+    if count := self.count:
+      cmd_prefix.append(f"--perf-count={count}")
+    if self.call_graph_mode != CallGraphMode.FRAME_POINTER:
+      cmd_prefix.append(f"--perf-call-graph={self.call_graph_mode}")
+    if clockid := self.clockid:
+      cmd_prefix.append(f"--perf-clockid={clockid}")
+    custom_perf_args = []
+    if cpu := self.cpu:
+      cpu_str = ",".join(map(str, cpu))
+      custom_perf_args.append(f"--cpu={cpu_str}")
+    if events := self.events:
+      events_str = ",".join(events)
+      custom_perf_args.append(f"--event={events_str}")
+    if custom_perf_args:
+      cmd_prefix.append(f"--perf-args={shlex.join(custom_perf_args)}")
+    browser.flags["--renderer-cmd-prefix"] = shlex.join(cmd_prefix)
+
+  def log_run_result(self, run: Run) -> None:
+    self._log_results([run])
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    self._log_results(group.runs)
+
+  def _log_results(self, runs: Iterable[Run]) -> None:
+    filtered_runs = list(run for run in runs if self in run.results)
+    if not filtered_runs:
+      return
+    logging.info("-" * 80)
+    logging.critical("Profiling results:")
+    self._log_results_overview(filtered_runs)
+    logging.info("- " * 40)
+    for i, run in enumerate(filtered_runs):
+      self._log_run_result_summary(run, i)
+
+  def _log_results_overview(self, filtered_runs):
+    if len(filtered_runs) <= 1:
+      return
+    if any(run.browser_platform.is_macos for run in filtered_runs):
+      logging.info("  *.trace:     'open $FILE'")
+    if any(run.browser_platform.is_linux or run.browser_platform.is_android
+           for run in filtered_runs):
+      logging.info("  *.perf.data: 'perf report -i $FILE'")
+
+  def _log_run_result_summary(self, run: Run, i: int) -> None:
+    if self not in run.results:
+      return
+    urls = run.results[self].url_list
+    perf_files = run.results[self].file_list
+    if not urls and not perf_files:
+      return
+    logging.info("Run %d: %s", i + 1, run.name)
+    if urls:
+      logging.critical("    %s", urls[-1])
+    if not perf_files:
+      return
+    largest_perf_file = perf_files[-1]
+    logging.critical("    %s : %s", largest_perf_file,
+                     helper.get_file_size(largest_perf_file))
+    if len(perf_files) <= 1:
+      return
+    glob = "*.perf.data"
+    if run.browser_platform.is_macos:
+      glob = "*.trace"
+    logging.info("    %s/%s: %d more files", largest_perf_file.parent, glob,
+                 len(perf_files))
+
+  def get_context(self, run: Run) -> ProfilingContext:
+    if run.browser_platform.is_linux:
+      return LinuxProfilingContext(self, run)
+    if run.browser_platform.is_macos:
+      return MacOSProfilingContext(self, run)
+    if run.browser_platform.is_android:
+      return AndroidProfilingContext(self, run)
+    raise NotImplementedError("Invalid platform")
+
+
+class ProfilingContext(ProbeContext[ProfilingProbe], metaclass=abc.ABCMeta):
+
+  def setup_v8_log_path(self) -> None:
+    if any(isinstance(probe, V8LogProbe) for probe in self.run.probes):
+      return
+    # Try to get a bit a cleaner output folder by redirecting v8 logging output
+    # to v8.log.
+    v8_log_dir = self.result_path.parent / V8LogProbe.NAME / "v8.log"
+    self.browser_platform.mkdir(v8_log_dir)
+    self.session.extra_js_flags["--logfile"] = str(v8_log_dir)
+
+
+class MacOSProfilingContext(ProfilingContext):
+  _process: Optional[subprocess.Popen]
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    return super().get_default_result_path().parent / "profile.trace"
+
+  def start(self) -> None:
+    self._process = self.browser_platform.popen("xctrace", "record",
+                                                "--template", "Time Profiler",
+                                                "--all-processes", "--output",
+                                                self.result_path)
+    # xctrace takes some time to start up
+    time.sleep(3)
+    if self._process.poll():
+      raise ValueError("Could not start xctrace")
+    atexit.register(self.stop_process)
+
+  def stop(self) -> None:
+    # Needs to be SIGINT for xctrace, terminate won't work.
+    assert self._process
+    self._process.send_signal(signal.SIGINT)
+
+  def teardown(self) -> ProbeResult:
+    self.stop_process()
+    return self.browser_result(file=(self.result_path,))
+
+  def stop_process(self) -> None:
+    if self._process:
+      logging.info("  Waiting for xctrace profiles (slow)...")
+      with helper.Spinner():
+        helper.wait_and_kill(self._process, signal=signal.SIGINT, timeout=60)
+      self._process = None
+    atexit.unregister(self.stop_process)
+
+
+V8_PERF_PROF_PATH_FLAG_MIN_VERSION = ChromeVersion((118, 0, 5993, 48))
+PERF_DATA_PATTERN = "*.perf.data"
+JIT_DUMP_PATTERN = "jit-*.dump"
+
+
+class LinuxProfilingContext(ProfilingContext):
+  TEMP_FILE_PATTERNS = (
+      "*.perf.data.jitted",
+      "jitted-*.so",
+      JIT_DUMP_PATTERN,
+  )
+
+  def __init__(self, probe: ProfilingProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._perf_process: Optional[subprocess.Popen] = None
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    result_dir = super().get_default_result_path()
+    self.browser_platform.mkdir(result_dir)
+    return result_dir
+
+  @property
+  def has_perf_prof_path(self) -> bool:
+    # TODO: replace with full version comparison
+    return self.browser.major_version > V8_PERF_PROF_PATH_FLAG_MIN_VERSION.major
+
+  def setup(self) -> None:
+    self.setup_v8_log_path()
+    if self.has_perf_prof_path:
+      self.session.extra_js_flags["--perf-prof-path"] = str(self.result_path)
+
+  def start(self) -> None:
+    if not self.probe.sample_browser_process:
+      return
+    if self.run.browser.pid is None:
+      logging.warning("Cannot sample browser process")
+      return
+    perf_data_file: pth.AnyPath = self.result_path / "browser.perf.data"
+    # TODO: not fully working yet
+    self._perf_process = self.browser_platform.popen(
+        "perf", "record", f"--call-graph={self.probe.call_graph_mode or 'fp'}",
+        f"--freq={self.probe.frequency or 'max'}",
+        f"--clockid={self.probe.clockid or 'mono'}",
+        f"--output={perf_data_file}", f"--pid={self.run.browser.pid}")
+    if self._perf_process.poll():
+      raise ValueError("Could not start linux profiler")
+    atexit.register(self.stop_process)
+
+  def stop(self) -> None:
+    self.stop_process()
+
+  def stop_process(self) -> None:
+    if self._perf_process:
+      helper.wait_and_kill(self._perf_process)
+      self._perf_process = None
+
+  def teardown(self) -> ProbeResult:
+    # Waiting for linux-perf to flush all perf data
+    if self.probe.sample_browser_process:
+      logging.debug("Waiting for browser process to stop")
+      time.sleep(3)
+    if self.probe.sample_browser_process:
+      logging.info("Browser process did not stop after 3s. "
+                   "You might get partial profiles")
+    time.sleep(2)
+
+    perf_files: List[pth.AnyPath] = helper.sort_by_file_size(
+        list(self.browser_platform.glob(self.result_path, PERF_DATA_PATTERN)),
+        self.browser_platform)
+    raw_perf_files = perf_files
+    urls: List[str] = []
+    try:
+      if self.probe.sample_js:
+        perf_files = self._inject_v8_symbols(self.run, perf_files)
+      if self.probe.run_pprof:
+        urls = self._export_to_pprof(self.run, perf_files)
+    finally:
+      self._clean_up_temp_files(self.run)
+    if self.probe.run_pprof:
+      logging.debug("Profiling results: %s", urls)
+      return self.browser_result(url=urls, file=raw_perf_files)
+    if self.browser_platform.which("pprof"):
+      logging.info("Run pprof over all (or single) perf data files "
+                   "for interactive analysis:")
+      logging.info("   pprof --http=localhost:1984 %s",
+                   " ".join(map(str, perf_files)))
+    return self.browser_result(trace=perf_files)
+
+  def _inject_v8_symbols(self, run: Run,
+                         perf_files: List[pth.AnyPath]) -> List[pth.AnyPath]:
+    with run.actions(
+        f"Probe {self.probe.name}: "
+        f"Injecting V8 symbols into {len(perf_files)} profiles",
+        verbose=True), helper.Spinner():
+      # Filter out empty files
+      perf_files = [
+          file for file in perf_files
+          if self.browser_platform.file_size(file) > 0
+      ]
+      if self.browser_platform.is_remote:
+        # Use loop, as we cannot easily serialize the remote platform.
+        perf_jitted_files = [
+            linux_perf_probe_inject_v8_symbols(file, self.browser_platform)
+            for file in perf_files
+        ]
+      else:
+        assert self.browser_platform == plt.PLATFORM
+        with multiprocessing.Pool() as pool:
+          perf_jitted_files = list(
+              pool.imap(linux_perf_probe_inject_v8_symbols, perf_files))
+      return [file for file in perf_jitted_files if file is not None]
+
+  def _export_to_pprof(self, run: Run,
+                       perf_files: List[pth.AnyPath]) -> List[str]:
+    assert self.probe.run_pprof
+    run_details_json = json.dumps(run.get_browser_details_json())
+    with run.actions(
+        f"Probe {self.probe.name}: "
+        f"exporting {len(perf_files)} profiles to pprof (slow)",
+        verbose=True), helper.Spinner():
+      self.browser_platform.sh(
+          "gcertstatus >&/dev/null || "
+          "(echo 'Authenticating with gcert:'; gcert)",
+          shell=True)
+      size = len(perf_files)
+      items = zip(perf_files, [run_details_json] * size)
+      urls: List[str] = []
+      if self.browser_platform.is_remote:
+        # Use loop, as we cannot easily serialize the remote platform.
+        for perf_data_file, run_details in items:
+          url = linux_perf_probe_pprof(perf_data_file, run_details,
+                                       self.browser_platform)
+          if url:
+            urls.append(url)
+      else:
+        assert self.browser_platform == plt.PLATFORM
+        with multiprocessing.Pool() as pool:
+          urls = [
+              url for url in pool.starmap(linux_perf_probe_pprof, items) if url
+          ]
+      try:
+        if perf_files:
+          # TODO: Add "combined" profile again
+          pass
+      except Exception as e:  # pylint: disable=broad-except
+        logging.debug("Failed to run pprof: %s", e)
+      return urls
+
+  def _clean_up_temp_files(self, run: Run) -> None:
+    if self.probe.cleanup_mode == CleanupMode.NEVER:
+      logging.debug("%s: skipping cleanup", self.probe)
+      return
+    if self.probe.cleanup_mode == CleanupMode.AUTO:
+      if not self.probe.run_pprof:
+        logging.debug("%s: skipping auto cleanup without pprof upload",
+                      self.probe)
+        return
+    for pattern in self.TEMP_FILE_PATTERNS:
+      for file in run.out_dir.glob(pattern):
+        file.unlink()
+
+
+def prepare_linux_perf_env(platform: plt.Platform,
+                           cwd: pth.AnyPath) -> Dict[str, str]:
+  env: Dict[str, str] = dict(platform.environ)
+  env["JITDUMPDIR"] = str(platform.absolute(cwd))
+  return env
+
+
+KB = 1024
+
+
+def linux_perf_probe_inject_v8_symbols(
+    perf_data_file: pth.AnyPath,
+    platform: Optional[plt.Platform] = None) -> Optional[pth.AnyPath]:
+  platform = platform or plt.PLATFORM
+  assert platform.is_file(perf_data_file)
+  output_file = perf_data_file.with_suffix(".data.jitted")
+  assert not platform.exists(output_file)
+  env = prepare_linux_perf_env(platform, perf_data_file.parent)
+  try:
+    # TODO: use remote chdir
+    platform.sh(
+        "perf",
+        "inject",
+        "--jit",
+        f"--input={perf_data_file}",
+        f"--output={output_file}",
+        env=env)
+  except plt.SubprocessError as e:
+    if platform.file_size(perf_data_file) > 200 * KB:
+      logging.warning("Failed processing: %s\n%s", perf_data_file, e)
+    else:
+      # TODO: investigate why almost all small perf.data files fail
+      logging.debug("Failed processing small profile (likely empty): %s\n%s",
+                    perf_data_file, e)
+  if not platform.exists(output_file):
+    return None
+  return output_file
+
+
+def linux_perf_probe_pprof(
+    perf_data_file: pth.AnyPath,
+    run_details: str,
+    platform: Optional[plt.Platform] = None) -> Optional[str]:
+  size = helper.get_file_size(perf_data_file)
+  platform = platform or plt.PLATFORM
+  env = prepare_linux_perf_env(platform, perf_data_file.parent)
+  url = ""
+  try:
+    url = platform.sh_stdout(
+        "pprof",
+        "-flame",
+        f"-add_comment={run_details}",
+        perf_data_file,
+        env=env,
+    ).strip()
+  except plt.SubprocessError as e:
+    # Occasionally small .jitted files fail, likely due perf inject silently
+    # failing?
+    raw_perf_data_file = perf_data_file.with_suffix("")
+    if (perf_data_file.suffix == ".jitted" and
+        platform.exists(raw_perf_data_file)):
+      logging.debug(
+          "pprof best-effort: falling back to standard perf data "
+          "without js symbols: %s \n"
+          "Got failures for %s: %s", raw_perf_data_file, perf_data_file.name, e)
+      try:
+        perf_data_file = raw_perf_data_file
+        url = platform.sh_stdout(
+            "pprof",
+            "-flame",
+            f"-add_comment={run_details}",
+            raw_perf_data_file,
+        ).strip()
+      except plt.SubprocessError as e2:
+        logging.debug("pprof -flame failed: %s", e2)
+    if not url:
+      logging.warning("Failed processing: %s\n%s", perf_data_file, e)
+      return None
+  if perf_data_file.suffix == ".jitted":
+    logging.info("PPROF (with js-symbols):")
+  else:
+    logging.info("PPROF (no js-symbols):")
+  logging.info("  linux-perf:   %s %s", perf_data_file.name, size)
+  logging.info("  pprof result: %s", url)
+  return url
+
+
+class AndroidProfilingContext(ProfilingContext):
+
+  def __init__(self, probe: ProfilingProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._simpleperf_process: Optional[subprocess.Popen] = None
+    self._story_ready = False
+
+  @cached_property
+  def _renderer_pid_tid(self) -> Tuple[int, int]:
+    assert self._story_ready, (
+        "Fetching renderer PID/TID before the story is loaded could lead to "
+        "the wrong PID/TID being used. This should never happen TM!")
+    renderer_pid: Optional[int] = None
+    renderer_main_tid: Optional[int] = None
+    with self.run.actions("Get Renderer PID/TID") as actions:
+      renderer_pid = actions.js(
+          "return chrome?.benchmarking?.getRendererPid?.();")
+      renderer_main_tid = actions.js(
+          "return chrome?.benchmarking?.getRendererMainTid?.();")
+    if renderer_pid is None or renderer_main_tid is None:
+      error_message = (
+          "Unable to get Renderer PID/TID from browser. "
+          "Is the browser binary a sufficiently new version? "
+          "For RENDERER_MAIN_ONLY/RENDERER_PROCESS_ONLY profiling, at least "
+          "https://chromium-review.googlesource.com/c/chromium/src/+/5374765 "
+          "is required.")
+      logging.error(error_message)
+      raise ValueError(error_message)
+    return renderer_pid, renderer_main_tid
+
+  def _generate_command_line(self) -> ListCmdArgs:
+    renderer_pid: Optional[int] = None
+    renderer_main_tid: Optional[int] = None
+    if self.probe.target in (TargetMode.RENDERER_MAIN_ONLY,
+                             TargetMode.RENDERER_PROCESS_ONLY):
+      renderer_pid, renderer_main_tid = self._renderer_pid_tid
+    return generate_simpleperf_command_line(
+        self.probe.target,
+        str(self.run.browser.path),
+        renderer_pid,
+        renderer_main_tid,
+        self.probe.call_graph_mode,
+        self.probe.frequency,
+        self.probe.count,
+        self.probe.cpu,
+        self.probe.events,
+        self.probe.grouped_events,
+        self.probe.add_counters,
+        self.result_path,
+    )
+
+  def _start_simpleperf(self) -> None:
+    command_line = self._generate_command_line()
+    logging.info("Starting simpleperf with command line: %s.", command_line)
+    self._simpleperf_process = self.browser_platform.popen(
+        *command_line, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
+    # Wait a bit for simpleperf to start and (potentially) terminate on error.
+    time.sleep(1)
+    if self._simpleperf_process.poll():
+      error_msg: str = ""
+      if stdout := self._simpleperf_process.stdout:
+        if isinstance(stdout, io.BufferedReader):
+          error_msg = stdout.read().decode("utf-8")
+          logging.error(error_msg)
+      raise ValueError(f"Unable to start simpleperf. {error_msg}")
+    atexit.register(self.stop_process)
+    self.browser.performance_mark("crossbench-probe-profiling-start")
+
+  def _get_simpleperf_pids(self) -> List[int]:
+    simpleperf_pids = []
+    for process in self.browser_platform.processes():
+      if process["name"] == "simpleperf":
+        simpleperf_pids.append(process["pid"])
+    return simpleperf_pids
+
+  def _stop_existing_simpleperf(self) -> None:
+    for simpleperf_pid in self._get_simpleperf_pids():
+      logging.warning("Terminating existing simpleperf process: %d.",
+                      simpleperf_pid)
+      self.browser_platform.terminate(simpleperf_pid)
+
+  def _cpu_mask(self, cpus: Iterable) -> str:
+    assert max(cpus) < 32, "Cpu index too high"
+    mask = 0
+    for cpu in cpus:
+      mask |= (1 << cpu)
+    return f"{mask:x}"
+
+  def _pin_renderer_main_core(self, cpu: int):
+    _, renderer_main_tid = self._renderer_pid_tid
+    self.browser_platform.sh("taskset", "-p", self._cpu_mask([cpu]),
+                             str(renderer_main_tid))
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    return super().get_default_result_path().parent / "simpleperf.perf.data"
+
+  def setup(self) -> None:
+    assert self.browser.platform.is_android, (
+        f"Expected Android platform, found {type(self.browser.platform)}.")
+    assert self.browser.attributes.is_chromium_based, (
+        f"Expected Chromium-based browser, found {type(self.browser)}.")
+    if (self.browser.platform.is_android and
+        self.browser.attributes.is_chromium_based):
+      chromium = cast(Chromium, self.browser)
+      # Set `--enable-benchmarking` explicitly for
+      # retrieving Renderer PID, if needed.
+      chromium.flags.set("--enable-benchmarking")
+    self._stop_existing_simpleperf()
+
+  def start(self) -> None:
+    if not self.probe.start_profiling_after_setup:
+      self._start_simpleperf()
+
+  def start_story_run(self) -> None:
+    self._story_ready = True
+    if self.probe.pin_renderer_main_core is not None:
+      self._pin_renderer_main_core(self.probe.pin_renderer_main_core)
+
+    if self.probe.start_profiling_after_setup:
+      self._start_simpleperf()
+
+  def stop(self) -> None:
+    self.stop_process()
+
+  def stop_process(self) -> None:
+    if self._simpleperf_process:
+      helper.wait_and_kill(
+          self._simpleperf_process, timeout=30, signal=signal.SIGINT)
+      self._simpleperf_process = None
+      self.browser.performance_mark("crossbench-probe-profiling-stop")
+
+  def teardown(self) -> ProbeResult:
+    return self.browser_result(trace=[self.result_path])
+
+
+def generate_simpleperf_command_line(
+    target: TargetMode,
+    app_name: str,
+    renderer_pid: Optional[int],
+    renderer_main_tid: Optional[int],
+    call_graph_mode: CallGraphMode,
+    frequency: Optional[Union[int, str]],
+    count: Optional[int],
+    cpus: Tuple[int, ...],
+    events: Tuple[str, ...],
+    grouped_events: Tuple[str, ...],
+    add_counters: Tuple[str, ...],
+    output_path: pth.AnyPath,
+) -> ListCmdArgs:
+  command_line: ListCmdArgs = ["simpleperf", "record"]
+  if target == TargetMode.RENDERER_MAIN_ONLY:
+    assert renderer_main_tid is not None
+    command_line.extend(["-t", str(renderer_main_tid)])
+  elif target == TargetMode.RENDERER_PROCESS_ONLY:
+    assert renderer_pid is not None
+    command_line.extend(["-p", str(renderer_pid)])
+  elif target == TargetMode.BROWSER_APP_ONLY:
+    command_line.extend(["--app", app_name])
+  else:  # TargetMode.SYSTEM_WIDE
+    command_line.append("-a")
+  if call_graph_mode == CallGraphMode.FRAME_POINTER:
+    command_line.extend(["--call-graph", "fp"])
+  elif call_graph_mode == CallGraphMode.DWARF:
+    # Use "--post-unwind=yes" while unwinding with DWARF, to reduce
+    # unwinding overhead during profiling.
+    command_line.extend(["--call-graph", "dwarf", "--post-unwind=yes"])
+  else:
+    assert call_graph_mode == CallGraphMode.NO_CALL_GRAPH, (
+        f"Invalid call_graph_mode: {call_graph_mode}")
+  if frequency is not None:
+    command_line.extend(["-f", str(frequency)])
+  if count is not None:
+    command_line.extend(["-c", str(count)])
+  if cpus:
+    command_line.extend(["--cpu", ",".join(map(str, cpus))])
+  # Events and counters need to be provided after `-f` and `-c`.
+  if events:
+    command_line.extend(["-e", ",".join(events)])
+  if grouped_events:
+    command_line.extend(["--group", ",".join(grouped_events)])
+  if add_counters:
+    command_line.extend(["--add-counter", ",".join(add_counters)])
+    # `--no-inherit` is required by simpleperf when `--add-counter` is used.
+    command_line.append("--no-inherit")
+  command_line.extend(["-o", output_path])
+  return command_line
diff --git a/crossbench/probes/result_location.py b/crossbench/probes/result_location.py
new file mode 100644
index 0000000..9e0806b
--- /dev/null
+++ b/crossbench/probes/result_location.py
@@ -0,0 +1,19 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+
+from crossbench import compat
+
+
+@enum.unique
+class ResultLocation(compat.StrEnumWithHelp):
+  LOCAL = ("local",
+           "Probe always produces results on the runner's local platform.")
+  BROWSER = ("browser",
+             ("Probe produces results on the browser's platform. "
+              "This can be either remote (for instance android browser) "
+              "or local (default system browser)."))
diff --git a/crossbench/probes/results.py b/crossbench/probes/results.py
new file mode 100644
index 0000000..7550d9f
--- /dev/null
+++ b/crossbench/probes/results.py
@@ -0,0 +1,332 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Tuple,
+                    cast)
+
+from immutabledict import immutabledict
+from ordered_set import OrderedSet
+
+from crossbench import path as pth
+from crossbench.parse import ObjectParser
+from crossbench.probes.helper import INTERNAL_NAME_PREFIX
+
+if TYPE_CHECKING:
+  from crossbench.probes.probe import Probe
+  from crossbench.runner.result_origin import ResultOrigin
+  from crossbench.types import JsonDict
+
+
+class DuplicateProbeResult(ValueError):
+  pass
+
+
+class ProbeResult(abc.ABC):
+  """
+  Collection of result files for a given Probe. These can be URLs or any file.
+
+  We distinguish between two types of files, files that can be fed to Perfetto
+  TraceProcessor (trace) and any other file (file). Trace files will be fed to
+  the trace_processor probe if present.
+  """
+
+  def __init__(self,
+               url: Optional[Iterable[str]] = None,
+               file: Optional[Iterable[pth.LocalPath]] = None,
+               trace: Optional[Iterable[pth.LocalPath]] = None,
+               **kwargs: Iterable[pth.LocalPath]):
+    self._url_list: Tuple[str, ...] = ()
+    if url:
+      self._url_list = ObjectParser.unique_sequence(
+          tuple(url), "urls", DuplicateProbeResult)
+    self._trace_list: Tuple[pth.LocalPath, ...] = ()
+    if trace:
+      self._trace_list = ObjectParser.unique_sequence(
+          tuple(trace), "traces", DuplicateProbeResult)
+    tmp_files: Dict[str, OrderedSet[pth.LocalPath]] = {}
+    if file:
+      self._extend(tmp_files, file, suffix=None, allow_duplicates=False)
+    for suffix, files in kwargs.items():
+      self._extend(tmp_files, files, suffix=suffix, allow_duplicates=False)
+
+    # Do last and allow duplicated
+    self._extend(
+        tmp_files, self._trace_list, suffix=None, allow_duplicates=True)
+    self._files: immutabledict[str, Tuple[pth.LocalPath, ...]] = immutabledict({
+        suffix: tuple(files) for suffix, files in tmp_files.items()
+    })
+    # TODO: Add Metric object for keeping metrics in-memory instead of reloading
+    # them from serialized JSON files for merging.
+    self._values = None
+    self._validate()
+
+  def _append(self,
+              tmp_files: Dict[str, OrderedSet[pth.LocalPath]],
+              file: pth.LocalPath,
+              suffix: Optional[str] = None,
+              allow_duplicates: bool = False) -> None:
+    file_suffix_name = file.suffix[1:]
+    if not suffix:
+      suffix = file_suffix_name
+    elif file_suffix_name != suffix:
+      raise ValueError(
+          f"Expected '.{suffix}' suffix, but got {repr(file.suffix)} "
+          f"for {file}")
+    if files_with_suffix := tmp_files.get(suffix):
+      if file not in files_with_suffix:
+        files_with_suffix.add(file)
+      elif not allow_duplicates:
+        raise DuplicateProbeResult(
+            f"Cannot append file twice to ProbeResult: {file}")
+    else:
+      tmp_files[suffix] = OrderedSet((file,))
+
+  def _extend(self,
+              tmp_files: Dict[str, OrderedSet[pth.LocalPath]],
+              files: Iterable[pth.LocalPath],
+              suffix: Optional[str] = None,
+              allow_duplicates=False) -> None:
+    for file in files:
+      self._append(
+          tmp_files, file, suffix=suffix, allow_duplicates=allow_duplicates)
+
+  def get(self, suffix: str) -> pth.LocalPath:
+    if files_with_suffix := self._files.get(suffix):
+      if len(files_with_suffix) != 1:
+        raise ValueError(f"Expected exactly one file with suffix {suffix}, "
+                         f"but got {files_with_suffix}")
+      return files_with_suffix[0]
+    raise ValueError(f"No files with suffix '.{suffix}'. "
+                     f"Options are {tuple(self._files.keys())}")
+
+  def get_all(self, suffix: str) -> List[pth.LocalPath]:
+    if files_with_suffix := self._files.get(suffix):
+      return list(files_with_suffix)
+    return []
+
+  @property
+  def is_empty(self) -> bool:
+    return not self._url_list and not self._files
+
+  @property
+  def is_remote(self) -> bool:
+    return False
+
+  def __bool__(self) -> bool:
+    return not self.is_empty
+
+  def __eq__(self, other: Any) -> bool:
+    if not isinstance(other, ProbeResult):
+      return False
+    if self is other:
+      return True
+    if self._files != other._files:
+      return False
+    return self._url_list == other._url_list
+
+  def merge(self, other: ProbeResult) -> ProbeResult:
+    if self.is_empty:
+      return other
+    if other.is_empty:
+      return self
+    return LocalProbeResult(
+        url=self.url_list + other.url_list,
+        file=self.file_list + other.file_list,
+        trace=self.trace_list + other.trace_list)
+
+  def _validate(self) -> None:
+    for path in self.all_files():
+      if not path.exists():
+        raise ValueError(f"ProbeResult path does not exist: {path}")
+
+  def to_json(self) -> JsonDict:
+    result: JsonDict = {}
+    if self._url_list:
+      result["url"] = self._url_list
+    for suffix, files in self._files.items():
+      result[suffix] = list(map(str, files))
+    return result
+
+  @property
+  def has_files(self) -> bool:
+    return bool(self._files)
+
+  def all_files(self) -> Iterable[pth.LocalPath]:
+    for files in self._files.values():
+      yield from files
+
+  @property
+  def url(self) -> str:
+    if len(self._url_list) != 1:
+      raise ValueError("ProbeResult has multiple URLs.")
+    return self._url_list[0]
+
+  @property
+  def url_list(self) -> List[str]:
+    return list(self._url_list)
+
+  @property
+  def file(self) -> pth.LocalPath:
+    if sum(len(files) for files in self._files.values()) > 1:
+      raise ValueError("ProbeResult has more than one file.")
+    for files in self._files.values():
+      return files[0]
+    raise ValueError("ProbeResult has no files.")
+
+  @property
+  def file_list(self) -> List[pth.LocalPath]:
+    return list(self.all_files())
+
+  @property
+  def trace(self) -> pth.LocalPath:
+    if len(self._trace_list) != 1:
+      raise ValueError("ProbeResult has multiple traces.")
+    return self._trace_list[0]
+
+  @property
+  def trace_list(self) -> List[pth.LocalPath]:
+    return list(self._trace_list)
+
+  @property
+  def json(self) -> pth.LocalPath:
+    return self.get("json")
+
+  @property
+  def json_list(self) -> List[pth.LocalPath]:
+    return self.get_all("json")
+
+  @property
+  def csv(self) -> pth.LocalPath:
+    return self.get("csv")
+
+  @property
+  def csv_list(self) -> List[pth.LocalPath]:
+    return self.get_all("csv")
+
+
+class EmptyProbeResult(ProbeResult):
+
+  def __init__(self) -> None:
+    super().__init__()
+
+  def __bool__(self) -> bool:
+    return False
+
+
+class LocalProbeResult(ProbeResult):
+  """LocalProbeResult can be used for files that are always available on the
+  runner/local machine."""
+
+
+class BrowserProbeResult(ProbeResult):
+  """BrowserProbeResult are stored on the device where the browser runs.
+  Result files will be automatically transferred to the local run's results
+  folder.
+  """
+
+  def __init__(self,
+               result_origin: ResultOrigin,
+               url: Optional[Iterable[str]] = None,
+               file: Optional[Iterable[pth.AnyPath]] = None,
+               **kwargs: Iterable[pth.AnyPath]):
+    self._browser_file = file
+    local_file: Optional[Iterable[pth.LocalPath]] = None
+    local_kwargs: Dict[str, Iterable[pth.LocalPath]] = {}
+    self._is_remote = result_origin.is_remote
+    if self._is_remote:
+      if file:
+        local_file = self._copy_files(result_origin, file)
+      for suffix_name, files in kwargs.items():
+        local_kwargs[suffix_name] = self._copy_files(result_origin, files)
+    else:
+      # Keep local files as is.
+      local_file = cast(Iterable[pth.LocalPath], file)
+      local_kwargs = cast(Dict[str, Iterable[pth.LocalPath]], kwargs)
+
+    super().__init__(url, local_file, **local_kwargs)
+
+  @property
+  def is_remote(self) -> bool:
+    return self._is_remote
+
+  def _copy_files(self, result_origin: ResultOrigin,
+                  paths: Iterable[pth.AnyPath]) -> Iterable[pth.LocalPath]:
+    assert paths, "Got no remote paths to copy."
+    # Copy result files from remote tmp dir to local results dir
+    browser_platform = result_origin.browser_platform
+    remote_tmp_dir = result_origin.browser_tmp_dir
+    out_dir = result_origin.out_dir
+    local_result_paths: List[pth.LocalPath] = []
+    for remote_path in paths:
+      try:
+        relative_path = remote_path.relative_to(remote_tmp_dir)
+      except ValueError:
+        logging.debug(
+            "Browser result is not in browser tmp dir: "
+            "only using the name of '%s'", remote_path)
+        relative_path = result_origin.host_platform.local_path(remote_path.name)
+      local_result_path = out_dir / relative_path
+      browser_platform.pull(remote_path, local_result_path)
+      assert local_result_path.exists(), "Failed to copy result file."
+      local_result_paths.append(local_result_path)
+    return local_result_paths
+
+
+class ProbeResultDict:
+  """
+  Maps Probes to their result files Paths.
+  """
+
+  def __init__(self, path: pth.AnyPath) -> None:
+    self._path = path
+    self._dict: Dict[str, ProbeResult] = {}
+
+  def __setitem__(self, probe: Probe, result: ProbeResult) -> None:
+    assert isinstance(result, ProbeResult)
+    self._dict[probe.name] = result
+
+  def __getitem__(self, probe: Probe) -> ProbeResult:
+    name = probe.name
+    if name not in self._dict:
+      raise KeyError(f"No results for probe='{name}'")
+    return self._dict[name]
+
+  def __contains__(self, probe: Probe) -> bool:
+    return probe.name in self._dict
+
+  def __bool__(self) -> bool:
+    return bool(self._dict)
+
+  def __len__(self) -> int:
+    return len(self._dict)
+
+  def get(self, probe: Probe, default: Any = None) -> ProbeResult:
+    return self._dict.get(probe.name, default)
+
+  def get_by_name(self, name: str, default: Any = None) -> ProbeResult:
+    # Debug helper only.
+    # Use bracket `results[probe]` or `results.get(probe)` instead.
+    return self._dict.get(name, default)
+
+  def to_json(self) -> JsonDict:
+    data: JsonDict = {}
+    for probe_name, results in self._dict.items():
+      if isinstance(results, (pth.AnyPath, str)):
+        data[probe_name] = str(results)
+      else:
+        if results.is_empty:
+          if not probe_name.startswith(INTERNAL_NAME_PREFIX):
+            logging.debug("probe=%s did not produce any data.", probe_name)
+          data[probe_name] = None
+        else:
+          data[probe_name] = results.to_json()
+    return data
+
+  def all_traces(self) -> Iterable[pth.LocalPath]:
+    for probe_result in self._dict.values():
+      yield from probe_result.trace_list
diff --git a/crossbench/probes/screenshot.py b/crossbench/probes/screenshot.py
new file mode 100644
index 0000000..7726dd4
--- /dev/null
+++ b/crossbench/probes/screenshot.py
@@ -0,0 +1,96 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, List, Optional
+
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeMissingDataError)
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Viewport
+  from crossbench.env import HostEnvironment
+  from crossbench.path import AnyPath
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.run import Run
+
+
+class ScreenshotProbe(Probe):
+  """
+  General-purpose Probe that collects screenshots.
+  """
+  NAME = "screenshot"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  IMAGE_FORMAT = "png"
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    # TODO: support interval-based screenshots
+    return parser
+
+  def _pre_check_viewport_size(self, env: HostEnvironment) -> None:
+    for browser in env.browsers:
+      viewport: Viewport = browser.viewport
+      if viewport.is_headless:
+        env.handle_warning(
+            f"Cannot take screenshots for headless browser: {browser}")
+      if viewport.x < 10 or viewport.y < 50:
+        env.handle_warning(
+            f"Viewport for '{browser}' might include toolbar: {viewport}")
+
+  def get_context(self, run: Run) -> ScreenshotProbeContext:
+    return ScreenshotProbeContext(self, run)
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    # TODO: implement
+    return EmptyProbeResult()
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    # TODO: implement
+    return EmptyProbeResult()
+
+
+class ScreenshotProbeContext(ProbeContext[ScreenshotProbe]):
+
+  def __init__(self, probe: ScreenshotProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._results: List[AnyPath] = []
+
+  def get_default_result_path(self) -> AnyPath:
+    screenshot_dir = super().get_default_result_path()
+    self.browser_platform.mkdir(screenshot_dir)
+    return screenshot_dir
+
+  def start(self) -> None:
+    self.screenshot("start")
+
+  def start_story_run(self) -> None:
+    self.screenshot("start_story")
+
+  def stop_story_run(self) -> None:
+    self.screenshot("stop_story")
+
+  def stop(self) -> None:
+    self.screenshot("stop")
+
+  def screenshot(self, label: Optional[str] = None) -> None:
+    # TODO: support screen coordinates
+    if not label:
+      label = str(dt.datetime.now().strftime("%Y-%m-%d_%H%M%S"))
+    path = self.result_path / f"{label}.{ScreenshotProbe.IMAGE_FORMAT}"
+    # TODO: use the browser's implementation first which might be more portable
+    self.browser_platform.screenshot(path)
+    self._results.append(path)
+
+  def teardown(self) -> ProbeResult:
+    if not self.browser_platform.is_dir(self.result_path):
+      raise ProbeMissingDataError(
+          f"No screen shot found at: {self.result_path}")
+    return self.browser_result(file=tuple(self._results))
diff --git a/crossbench/probes/shell.py b/crossbench/probes/shell.py
new file mode 100644
index 0000000..83a89ea
--- /dev/null
+++ b/crossbench/probes/shell.py
@@ -0,0 +1,175 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Iterable, List, Optional
+
+from crossbench.parse import ObjectParser
+from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeKeyT
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench import path as pth
+  from crossbench.env import HostEnvironment
+  from crossbench.plt.base import CmdArg, TupleCmdArgs
+  from crossbench.runner.run import Run
+
+
+class ShellProbe(Probe):
+  """
+  Run an arbitrary shell command on the browser platform and store the
+  stdout and stderr of the command as a result file.
+  """
+  NAME = "shell"
+  IS_GENERAL_PURPOSE = True
+  RESULT_LOCATION = ResultLocation.LOCAL
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "setup_cmd",
+        aliases=("setup",),
+        type=ObjectParser.sh_cmd,
+        required=False,
+        help="CMD is run before the browser is started.")
+    parser.add_argument(
+        "start_cmd",
+        type=ObjectParser.sh_cmd,
+        aliases=("start",),
+        required=False,
+        help=("CMD is run right before each story is started "
+              "and the browser is already running."))
+    parser.add_argument(
+        "start_story_run_cmd",
+        aliases=("start-story",),
+        type=ObjectParser.sh_cmd,
+        required=False,
+        help=("CMD is run right before the measurement phase "
+              "of a story is started."))
+    parser.add_argument(
+        "stop_story_run_cmd",
+        aliases=("stop-story",),
+        type=ObjectParser.sh_cmd,
+        required=False,
+        help=("CMD is run right after the measurement phase "
+              "of a story has ended."))
+    parser.add_argument(
+        "stop_cmd",
+        aliases=("cmd", "stop"),
+        type=ObjectParser.sh_cmd,
+        required=True,
+        help=("CMD is run right after the workload ended and the browser "
+              "is still running."))
+    parser.add_argument(
+        "teardown_cmd",
+        aliases=("teardown",),
+        type=ObjectParser.sh_cmd,
+        required=False,
+        help="CMD is run after the browser is stopped.")
+    return parser
+
+  def __init__(self,
+               setup_cmd: Optional[Iterable[CmdArg]] = None,
+               start_cmd: Optional[Iterable[CmdArg]] = None,
+               start_story_run_cmd: Optional[Iterable[CmdArg]] = None,
+               stop_story_run_cmd: Optional[Iterable[CmdArg]] = None,
+               stop_cmd: Optional[Iterable[CmdArg]] = None,
+               teardown_cmd: Optional[Iterable[CmdArg]] = None) -> None:
+    super().__init__()
+    self._setup_cmd: TupleCmdArgs = tuple(setup_cmd) if setup_cmd else ()
+    self._start_cmd: TupleCmdArgs = tuple(start_cmd) if start_cmd else ()
+    self._start_story_run_cmd: TupleCmdArgs = (
+        tuple(start_story_run_cmd) if start_story_run_cmd else ())
+    self._stop_story_run_cmd: TupleCmdArgs = (
+        tuple(stop_story_run_cmd) if stop_story_run_cmd else ())
+    self._stop_cmd: TupleCmdArgs = tuple(stop_cmd) if stop_cmd else ()
+    self._teardown_cmd: TupleCmdArgs = (
+        tuple(teardown_cmd) if teardown_cmd else ())
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("setup_cmd", tuple(map(str, self.stop_cmd))),
+        ("start_cmd", tuple(map(str, self.start_cmd))),
+        ("start_story_run_cmd", tuple(map(str, self.start_story_run_cmd))),
+        ("stop_story_run_cmd", tuple(map(str, self.stop_story_run_cmd))),
+        ("stop_cmd", tuple(map(str, self.stop_cmd))),
+        ("teardown_cmd", tuple(map(str, self.teardown_cmd))),
+    )
+
+  @property
+  def setup_cmd(self) -> TupleCmdArgs:
+    return self._setup_cmd
+
+  @property
+  def start_cmd(self) -> TupleCmdArgs:
+    return self._start_cmd
+
+  @property
+  def start_story_run_cmd(self) -> TupleCmdArgs:
+    return self._start_story_run_cmd
+
+  @property
+  def stop_story_run_cmd(self) -> TupleCmdArgs:
+    return self._stop_story_run_cmd
+
+  @property
+  def stop_cmd(self) -> TupleCmdArgs:
+    return self._stop_cmd
+
+  @property
+  def teardown_cmd(self) -> TupleCmdArgs:
+    return self._teardown_cmd
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    super().validate_env(env)
+    if env.repetitions != 1:
+      env.handle_warning(f"Probe={self.NAME} cannot merge data over multiple "
+                         f"repetitions={env.repetitions}.")
+
+  def get_context(self, run: Run) -> ShellProbeContext:
+    return ShellProbeContext(self, run)
+
+
+class ShellProbeContext(ProbeContext[ShellProbe]):
+
+  def __init__(self, probe: ShellProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._result_files: List[pth.LocalPath] = []
+
+  def _maybe_run_cmd(self, name: str, cmd: TupleCmdArgs) -> None:
+    if not cmd:
+      return
+    stdout_path = self.local_result_path / f"{name}.stdout.txt"
+    self.host_platform.touch(stdout_path)
+    self._result_files.append(stdout_path)
+    stderr_path = self.local_result_path / f"{name}.stderr.txt"
+    self.host_platform.touch(stderr_path)
+    self._result_files.append(stderr_path)
+    with stdout_path.open("w") as stdout, stderr_path.open("w") as stderr:
+      self.browser_platform.sh(*cmd, shell=True, stdout=stdout, stderr=stderr)
+
+  def setup(self) -> None:
+    self.host_platform.mkdir(self.local_result_path)
+    self._maybe_run_cmd("setup", self.probe.setup_cmd)
+
+  def start(self) -> None:
+    self._maybe_run_cmd("start", self.probe.start_cmd)
+
+  def start_story_run(self) -> None:
+    self._maybe_run_cmd("start_story_run", self.probe.start_story_run_cmd)
+
+  def stop_story_run(self) -> None:
+    self._maybe_run_cmd("stop_story_run", self.probe.stop_story_run_cmd)
+
+  def stop(self) -> None:
+    self._maybe_run_cmd("stop", self.probe.stop_cmd)
+
+  def teardown(self) -> ProbeResult:
+    self._maybe_run_cmd("teardown", self.probe.teardown_cmd)
+    return LocalProbeResult(file=tuple(self._result_files))
diff --git a/crossbench/probes/system_stats.py b/crossbench/probes/system_stats.py
new file mode 100644
index 0000000..74b470f
--- /dev/null
+++ b/crossbench/probes/system_stats.py
@@ -0,0 +1,34 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING
+
+from crossbench.probes.polling import PollingProbe
+from crossbench.probes.probe import ProbeValidationError
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+
+
+class SystemStatsProbe(PollingProbe):
+  """
+  General-purpose probe to periodically collect system-wide CPU and memory
+  stats on unix systems.
+  """
+  NAME = "system.stats"
+  CMD = ("ps", "-a", "-e", "-o", "pcpu,pmem,args", "-r")
+  IS_GENERAL_PURPOSE = True
+
+  def __init__(
+      self, interval: dt.timedelta = dt.timedelta(seconds=0.1)) -> None:
+    super().__init__(self.CMD, interval)
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    if not (browser.platform.is_linux or browser.platform.is_macos):
+      raise ProbeValidationError(self, "Only supported on macOS and linux.")
diff --git a/crossbench/probes/thermal_monitor.py b/crossbench/probes/thermal_monitor.py
new file mode 100644
index 0000000..6e9fa6e
--- /dev/null
+++ b/crossbench/probes/thermal_monitor.py
@@ -0,0 +1,239 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import json
+import logging
+import re
+from enum import IntEnum
+from typing import TYPE_CHECKING, Iterable, Optional
+
+from crossbench import helper
+from crossbench.probes.internal import (InternalJsonResultProbe,
+                                        InternalJsonResultProbeContext)
+from crossbench.probes.probe import ProbeIncompatibleBrowser
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import EmptyProbeResult, LocalProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.probes.results import ProbeResult, ProbeResultDict
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.types import Json
+
+THERMAL_STATUS_RE = re.compile(r"Thermal Status: (?P<status>\d+)")
+COOLDOWN_WAIT_RANGE = helper.WaitRange(
+    min=dt.timedelta(seconds=1), timeout=dt.timedelta(minutes=5))
+
+
+class ThermalStatus(IntEnum):
+  UNAVAILABLE = -1
+  NONE = 0
+  LIGHT = 1
+  MODERATE = 2
+  SEVERE = 3
+  CRITICAL = 4
+  EMERGENCY = 5
+  SHUTDOWN = 6
+
+  @classmethod
+  def parse(cls, value: str) -> ThermalStatus:
+    try:
+      return ThermalStatus(int(value))
+    except ValueError:
+      pass
+
+    for member in ThermalStatus:
+      if value.upper().endswith(member.name):
+        return member
+
+    raise ValueError(f"Invalid ThermalStatus: {repr(value)}")
+
+
+class ThermalMonitorProbe(InternalJsonResultProbe):
+  """
+  Internal probe to monitor device thermal status.
+  """
+  NAME = "cb.thermal_monitor"
+  RESULT_LOCATION = ResultLocation.LOCAL
+
+  def __init__(self,
+               cool_down_time: dt.timedelta = dt.timedelta(),
+               threshold: Optional[ThermalStatus] = None):
+    super().__init__()
+    self._threshold: Optional[ThermalStatus] = threshold
+    self._cool_down_time: Optional[dt.timedelta] = cool_down_time
+    if threshold is not None and threshold <= 0:
+      raise ValueError("Threshold must be positive")
+
+  @property
+  def result_path_name(self) -> str:
+    return "cb.thermal_monitor.json"
+
+  @property
+  def threshold(self) -> Optional[ThermalStatus]:
+    return self._threshold
+
+  @property
+  def cool_down_time(self) -> dt.timedelta:
+    return self._cool_down_time
+
+  def to_json(self, actions: Actions) -> Json:
+    raise NotImplementedError("Should not be called, data comes from context")
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    if self.threshold is not None and not browser.platform.is_android:
+      raise ProbeIncompatibleBrowser(
+          self, browser, "Thermal thresholds only supported on android")
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    return self._merge_group(group, (run.results for run in group.runs))
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    return self._merge_group(
+        group, (rep_group.results for rep_group in group.repetitions_groups))
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self._merge_group(
+        group, (story_group.results for story_group in group.story_groups))
+
+  def _merge_group(self, group,
+                   results_iter: Iterable[ProbeResultDict]) -> ProbeResult:
+    group_max_status: ThermalStatus = ThermalStatus.UNAVAILABLE
+    has_results: bool = False
+    for results in results_iter:
+      result = results[self]
+      if not result:
+        continue
+      with result.json.open(encoding="utf-8") as f:
+        thermals = json.load(f)
+        if "max_observed_status" not in thermals:
+          continue
+        repetition_max_status = ThermalStatus(thermals["max_observed_status"])
+        group_max_status = max(group_max_status, repetition_max_status)
+        has_results = True
+
+    if not has_results:
+      return EmptyProbeResult()
+
+    merged_path = group.get_local_probe_result_path(self)
+    with merged_path.open("w", encoding="utf-8") as f:
+      json.dump({"max_observed_status": group_max_status}, f, indent=2)
+      # TODO(375390958): figure out why files aren't fully written to
+      # pyfakefs here.
+      f.write("\n")
+
+    return LocalProbeResult(json=(merged_path,))
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    if self not in group.results:
+      return
+    result = group.results[self]
+    if not result:
+      return
+
+    with result.json.open(encoding="utf-8") as f:
+      thermals = json.load(f)
+      max_observed_status = ThermalStatus(thermals["max_observed_status"])
+
+    if max_observed_status == ThermalStatus.LIGHT:
+      logging.info("-" * 80)
+      logging.error("Light thermal throttling detected during execution, "
+                    "scores may be affected.")
+    elif max_observed_status > ThermalStatus.LIGHT:
+      logging.info("-" * 80)
+      logging.error("Significant thermal throttling detected during execution, "
+                    "scores are not representative of the device performance.")
+
+  def get_context(self, run: Run) -> ThermalMonitorProbeContext:
+    if run.browser.platform.is_android:
+      return AndroidThermalMonitorProbeContext(self, run)
+    return ThermalMonitorProbeContext(self, run)
+
+
+class ThermalMonitorProbeContext(InternalJsonResultProbeContext):
+
+  def __init__(self, probe: ThermalMonitorProbe, run: Run) -> None:
+    super().__init__(probe, run)
+
+  @property
+  def probe(self) -> ThermalMonitorProbe:
+    return self._probe
+
+  def setup(self) -> None:
+    self.run.runner.wait(self.probe.cool_down_time, absolute_time=True)
+
+    if not self.browser_platform.is_thermal_throttled():
+      return
+    logging.info("COOLDOWN")
+    for _ in COOLDOWN_WAIT_RANGE.wait_with_backoff():
+      if not self.browser_platform.is_thermal_throttled():
+        break
+      logging.info("COOLDOWN: still hot, waiting some more")
+
+  def to_json(self, actions: Actions) -> Json:
+    del actions
+    return {}
+
+
+class AndroidThermalMonitorProbeContext(ThermalMonitorProbeContext):
+
+  def __init__(self, probe: ThermalMonitorProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._max_observed_status: ThermalStatus = ThermalStatus.UNAVAILABLE
+
+  def _get_thermal_status(self) -> ThermalStatus:
+    stdout = self.browser_platform.sh_stdout("dumpsys", "thermalservice")
+    if match := THERMAL_STATUS_RE.search(stdout):
+      return ThermalStatus(int(match["status"]))
+    return ThermalStatus.UNAVAILABLE
+
+  def _wait_if_necessary(self, probe_threshold: ThermalStatus) -> None:
+    current_status = self._get_thermal_status()
+    if current_status < probe_threshold:
+      return
+
+    logging.info("Thermal throttling status too high: %s", current_status.name)
+    logging.info("COOLDOWN")
+    try:
+      for _ in COOLDOWN_WAIT_RANGE.wait_with_backoff():
+        current_status = self._get_thermal_status()
+        logging.debug("Thermal status: %s", current_status.name)
+        if current_status < probe_threshold:
+          logging.info("COOLDOWN: complete")
+          break
+    except TimeoutError:
+      logging.error("COOLDOWN: device is still too hot after waiting for %s",
+                    COOLDOWN_WAIT_RANGE.timeout)
+
+  def setup(self) -> None:
+    if self.probe.threshold is not None:
+      self._wait_if_necessary(self.probe.threshold)
+    else:
+      super().setup()
+
+    current_status = self._get_thermal_status()
+    self._max_observed_status = max(self._max_observed_status, current_status)
+    logging.debug("Thermal throttling before run: %s", current_status.name)
+
+  def teardown(self) -> ProbeResult:
+    current_status = self._get_thermal_status()
+    self._max_observed_status = max(self._max_observed_status, current_status)
+    logging.debug("Thermal throttling after run: %s", current_status.name)
+    # TODO(crbug.com/374737038): After crbug.com/374737038 is done, raise an
+    # exception here if max status was at threshold or higher. This will
+    # register the run as a failure to process it correctly later.
+    return super().teardown()
+
+  def to_json(self, actions: Actions) -> Json:
+    del actions
+    return {"max_observed_status": self._max_observed_status.value}
diff --git a/crossbench/probes/v8/__init__.py b/crossbench/probes/v8/__init__.py
new file mode 100644
index 0000000..3ea02f9
--- /dev/null
+++ b/crossbench/probes/v8/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/probes/v8/builtins_pgo.py b/crossbench/probes/v8/builtins_pgo.py
new file mode 100644
index 0000000..3d95cf1
--- /dev/null
+++ b/crossbench/probes/v8/builtins_pgo.py
@@ -0,0 +1,73 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Optional
+
+from crossbench.probes.chromium_probe import ChromiumProbe
+from crossbench.probes.probe import ProbeContext
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+
+
+class V8BuiltinsPGOProbe(ChromiumProbe):
+  """
+  Chromium-only Probe to extract V8 builtins PGO data.
+  The resulting data is used to optimize Torque and CSA builtins.
+  """
+  NAME = "v8.builtins.pgo"
+
+  def attach(self, browser: Browser) -> None:
+    assert browser.attributes.is_chromium_based, (
+        "Expected Chromium-based browser.")
+    super().attach(browser)
+    browser.js_flags.set("--allow-natives-syntax")
+
+  def get_context(self, run: Run) -> V8BuiltinsPGOProbeContext:
+    return V8BuiltinsPGOProbeContext(self, run)
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    merged_result_path = group.get_local_probe_result_path(self)
+    result_files = (run.results[self].file for run in group.runs)
+    result_file = self.host_platform.concat_files(
+        inputs=result_files, output=merged_result_path)
+    return LocalProbeResult(file=(result_file,))
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged_result_path = group.get_local_probe_result_path(self)
+    result_files = (g.results[self].file for g in group.repetitions_groups)
+    result_file = self.host_platform.concat_files(
+        inputs=result_files, output=merged_result_path)
+    return LocalProbeResult(file=(result_file,))
+
+
+class V8BuiltinsPGOProbeContext(ProbeContext[V8BuiltinsPGOProbe]):
+  _pgo_counters: Optional[str] = None
+
+  def setup(self) -> None:
+    pass
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    with self.run.actions("Extract Builtins PGO DATA") as actions:
+      self._pgo_counters = actions.js(
+          "return %GetAndResetTurboProfilingData();")
+
+  def teardown(self) -> ProbeResult:
+    assert self._pgo_counters is not None and self._pgo_counters, (
+        "Chrome didn't produce any V8 builtins PGO data. "
+        "Please make sure to set the v8_enable_builtins_profiling=true "
+        "gn args.")
+    pgo_file = self.local_result_path
+    with pgo_file.open("a") as f:
+      f.write(self._pgo_counters)
+    return LocalProbeResult(file=(pgo_file,))
diff --git a/crossbench/probes/v8/log.py b/crossbench/probes/v8/log.py
new file mode 100644
index 0000000..dad3adb
--- /dev/null
+++ b/crossbench/probes/v8/log.py
@@ -0,0 +1,267 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+import multiprocessing
+import os
+import re
+import subprocess
+from typing import TYPE_CHECKING, Iterable, List, Optional, cast
+
+from crossbench import compat, helper, plt
+from crossbench.browsers.browser import Browser
+from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.flags.js_flags import JSFlags
+from crossbench.helper.path_finder import V8ToolsFinder
+from crossbench.parse import PathParser
+from crossbench.probes.chromium_probe import ChromiumProbe
+from crossbench.probes.probe import ProbeConfigParser, ProbeContext, ProbeKeyT
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.env import HostEnvironment
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.run import Run
+
+_PROF_FLAG = "--prof"
+_LOG_ALL_FLAG = "--log-all"
+
+
+class V8LogProbe(ChromiumProbe):
+  """
+  Chromium-only probe that produces a v8.log file with detailed internal V8
+  performance and logging information.
+  This file can be used by tools hosted on http://v8.dev/tools.
+  If prof == true, this probe will try to generate profview.json files for
+  http://v8.dev/tools/head/profview. See de d8_binary and v8_checkout
+  config-properties for more details.
+  """
+  NAME = "v8.log"
+  RESULT_LOCATION = ResultLocation.BROWSER
+
+  _FLAG_RE = re.compile("^--(prof|log-|no-log-).*$")
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "log_all",
+        type=bool,
+        default=True,
+        help="Enable all v8 logging (equivalent to --log-all)")
+    parser.add_argument(
+        "prof",
+        type=bool,
+        default=True,
+        help="Enable v8-profiling (equivalent to --prof)")
+    parser.add_argument(
+        "profview",
+        type=bool,
+        default=True,
+        help=("Enable v8-profiling and generate profview.json files for "
+              "http://v8.dev/tools/head/profview"))
+    parser.add_argument(
+        "js_flags",
+        type=str,
+        default=[],
+        is_list=True,
+        help="Manually pass --log-.* flags to V8")
+    parser.add_argument(
+        "d8_binary",
+        type=PathParser.file_path,
+        help="Path to a D8 binary for extended log processing."
+        "If not specified the $D8_PATH env variable is used and/or "
+        "default build locations are tried.")
+    parser.add_argument(
+        "v8_checkout",
+        type=PathParser.dir_path,
+        help="Path to a V8 checkout for extended log processing."
+        "If not specified it is auto inferred from either the provided"
+        "d8_binary or standard installation locations.")
+    return parser
+
+  def __init__(
+      self,
+      log_all: bool = True,
+      prof: bool = True,
+      profview: bool = True,
+      js_flags: Optional[Iterable[str]] = None,
+      # TODO: support remote platform
+      d8_binary: Optional[LocalPath] = None,
+      v8_checkout: Optional[LocalPath] = None) -> None:
+    super().__init__()
+    self._profview: bool = profview
+    self._js_flags = JSFlags()
+    self._d8_binary: Optional[LocalPath] = d8_binary
+    self._v8_checkout: Optional[LocalPath] = v8_checkout
+    assert isinstance(log_all,
+                      bool), (f"Expected bool value, got log_all={log_all}")
+    assert isinstance(prof, bool), f"Expected bool value, got log_all={prof}"
+    if log_all:
+      self._js_flags.set(_LOG_ALL_FLAG)
+    elif prof:
+      self._js_flags.set(_PROF_FLAG)
+    elif profview:
+      raise ValueError(f"{self}: Need prof:true with profview:true")
+    js_flags = js_flags or []
+    for flag in js_flags:
+      if self._FLAG_RE.match(flag):
+        self._js_flags.set(flag)
+      else:
+        raise ValueError(f"{self}: Non-v8.log-related flag detected: {flag}")
+    if len(self._js_flags) == 0:
+      raise ValueError(f"{self}: V8LogProbe has no effect")
+
+  @property
+  def key(self) -> ProbeKeyT:
+    return super().key + (
+        ("profview", self._profview),
+        ("js_flags", str(self.js_flags)),
+        ("d8_binary", str(self._d8_binary)),
+        ("v8_checkout", str(self._v8_checkout)),
+    )
+
+  @property
+  def js_flags(self) -> JSFlags:
+    return self._js_flags.copy()
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    super().validate_env(env)
+    if env.repetitions != 1:
+      env.handle_warning(f"Probe({self.NAME}) cannot merge data over multiple "
+                         f"repetitions={env.repetitions}.")
+
+  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
+    super().validate_browser(env, browser)
+    # --prof sometimes causes issues on enterprise chrome on linux.
+    if _PROF_FLAG not in self._js_flags:
+      return
+    if not browser.platform.is_linux or browser.major_version <= 106:
+      return
+    for search_path in cast(plt.LinuxPlatform, browser.platform).SEARCH_PATHS:
+      if compat.is_relative_to(browser.path, search_path):
+        logging.error(
+            "Probe with V8 --prof might not work with enterprise profiles")
+
+  def attach(self, browser: Browser) -> None:
+    super().attach(browser)
+    assert isinstance(browser, Chromium)
+
+    browser = cast(Chromium, browser)
+    browser.flags.set("--no-sandbox")
+    browser.js_flags.update(self._js_flags)
+
+  def process_log_files(self, log_files: List[AnyPath]) -> List[AnyPath]:
+    if not self._profview:
+      return []
+    platform = self.host_platform
+    finder = V8ToolsFinder(platform, self._d8_binary, self._v8_checkout)
+    if not finder.d8_binary or not finder.tick_processor or not log_files:
+      logging.warning("Did not find $D8_PATH for profview processing.")
+      return []
+    logging.info(
+        "PROBE v8.log: generating profview json data "
+        "for %d v8.log files. (slow)", len(log_files))
+    logging.debug("v8.log files: %s", log_files)
+    if platform.is_remote:
+      # TODO: fix, currently unused
+      # Use loop, as we cannot easily serialize the remote platform.
+      return [
+          _process_profview_json(finder.d8_binary, finder.tick_processor,
+                                 log_file) for log_file in log_files
+      ]
+    assert platform == plt.PLATFORM
+    with multiprocessing.Pool(processes=4) as pool:
+      return list(
+          pool.starmap(_process_profview_json,
+                       [(finder.d8_binary, finder.tick_processor, log_file)
+                        for log_file in log_files]))
+
+  def get_context(self, run: Run) -> V8LogProbeContext:
+    return V8LogProbeContext(self, run)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    runs: List[Run] = list(run for run in group.runs if self in run.results)
+    if not runs:
+      return
+    logging.info("-" * 80)
+    logging.critical("v8.log results:")
+    logging.info("  *.v8.log:        https://v8.dev/tools/head/system-analyzer")
+    logging.info("  *.profview.json: https://v8.dev/tools/head/profview")
+    logging.info("- " * 40)
+    # Iterate over all runs again, to get proper indices:
+    for i, run in enumerate(group.runs):
+      if self not in run.results:
+        continue
+      log_files = run.results[self].file_list
+      if not log_files:
+        continue
+      logging.info("Run %d: %s", i + 1, run.name)
+      largest_log_file = log_files[-1]
+      logging.critical("    %s : %s", largest_log_file,
+                       helper.get_file_size(largest_log_file))
+      if len(log_files) > 1:
+        logging.info("    %s/.*v8.log: %d files", largest_log_file.parent,
+                     len(log_files))
+      profview_files = run.results[self].json_list
+      if not profview_files:
+        continue
+      largest_profview_file = profview_files[-1]
+      logging.critical("    %s : %s", largest_profview_file,
+                       helper.get_file_size(largest_profview_file))
+      if len(profview_files) > 1:
+        logging.info("    %s/*.profview.json: %d more files",
+                     largest_profview_file.parent, len(profview_files))
+
+
+class V8LogProbeContext(ProbeContext[V8LogProbe]):
+
+  def get_default_result_path(self) -> AnyPath:
+    log_dir = super().get_default_result_path()
+    self.browser_platform.mkdir(log_dir)
+    return log_dir / self.probe.result_path_name
+
+  def setup(self) -> None:
+    self.session.extra_js_flags["--logfile"] = str(self.result_path)
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    log_dir = self.result_path.parent
+    log_files = helper.sort_by_file_size(
+        self.browser_platform.glob(log_dir, "*-v8.log"), self.browser_platform)
+    # Only convert a v8.log file with profile ticks.
+    json_list: List[AnyPath] = []
+    maybe_js_flags = getattr(self.browser, "js_flags", {})
+    if _PROF_FLAG in maybe_js_flags or _LOG_ALL_FLAG in maybe_js_flags:
+      with helper.Spinner():
+        json_list = self.probe.process_log_files(log_files)
+    return self.browser_result(file=tuple(log_files), json=json_list)
+
+
+def _process_profview_json(d8_binary: AnyPath, tick_processor: AnyPath,
+                           log_file: AnyPath) -> AnyPath:
+  env = os.environ.copy()
+  # TODO: support remote platforms
+  platform = plt.PLATFORM
+  # The tick-processor scripts expect D8_PATH to point to the parent dir.
+  env["D8_PATH"] = str(platform.local_path(d8_binary).parent.resolve())
+  result_json = log_file.with_suffix(".profview.json")
+  with platform.local_path(result_json).open("w", encoding="utf-8") as f:
+    platform.sh(
+        tick_processor,
+        "--preprocess",
+        log_file,
+        env=env,
+        stdout=f,
+        stderr=subprocess.PIPE)
+  return result_json
diff --git a/crossbench/probes/v8/rcs.py b/crossbench/probes/v8/rcs.py
new file mode 100644
index 0000000..9a07a7e
--- /dev/null
+++ b/crossbench/probes/v8/rcs.py
@@ -0,0 +1,134 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import collections
+import logging
+from typing import TYPE_CHECKING, Optional, Union, cast
+
+from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.probes.chromium_probe import ChromiumProbe
+from crossbench.probes.probe import ProbeContext, ProbeMissingDataError
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.path import LocalPath
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import (
+      CacheTemperatureRepetitionsRunGroup, RepetitionsRunGroup)
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+
+
+class V8RCSProbe(ChromiumProbe):
+  """
+  Chromium-only Probe to extract runtime-call-stats data that can be used
+  to analyze precise counters and time spent in various VM components in V8:
+  https://v8.dev/tools/head/callstats.html
+  """
+  NAME = "v8.rcs"
+
+  def attach(self, browser: Browser) -> None:
+    assert isinstance(browser, Chromium), "Expected Chromium-based browser."
+    super().attach(browser)
+    chromium = cast(Chromium, browser)
+    chromium.js_flags.update(("--runtime-call-stats", "--allow-natives-syntax"))
+
+  def get_context(self, run: Run) -> V8RCSProbeContext:
+    return V8RCSProbeContext(self, run)
+
+  def concat_group_files(self,
+                         group: Union[RepetitionsRunGroup,
+                                      CacheTemperatureRepetitionsRunGroup],
+                         file_name: str) -> LocalPath:
+    result_dir = group.get_local_probe_result_dir(self)
+    result_files = (run.results[self].file for run in group.runs)
+    result_file = self.host_platform.concat_files(
+        inputs=result_files,
+        output=result_dir / file_name,
+        prefix=f"\n== Page: {group.story.name}\n")
+    return result_file
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    all_file = self.concat_group_files(group, "all.rcs.txt")
+    result_files = [all_file]
+    for temperature_group in group.cache_temperature_repetitions_groups:
+      temperature_file_name = f"{temperature_group.cache_temperature}.rcs.txt"
+      group_file = self.concat_group_files(temperature_group,
+                                           temperature_file_name)
+      result_files.append(group_file)
+    result_dir = group.get_local_probe_result_dir(self)
+    self.host_platform.symlink_or_copy(all_file,
+                                       result_dir.with_suffix(".rcs.txt"))
+    return LocalProbeResult(file=tuple(result_files))
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    name_groups = collections.defaultdict(list)
+    for repetition_group in group.repetitions_groups:
+      for result_file in repetition_group.results[self].file_list:
+        name_groups[result_file.name].append(result_file)
+
+    result_dir = group.get_local_probe_result_dir(self)
+    result_files = []
+    for name, files in name_groups.items():
+      result_files.append(
+          self.host_platform.concat_files(
+              inputs=files, output=result_dir / name))
+    src_file = result_dir / "all.rcs.txt"
+    self.host_platform.symlink_or_copy(src_file,
+                                       result_dir.with_suffix(".rcs.txt"))
+    return LocalProbeResult(file=(src_file,))
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    # We put all the fils by in a toplevel v8.rcs folder
+    result_dir = group.get_local_probe_result_dir(self)
+    files = []
+    for story_group in group.story_groups:
+      story_group_file = story_group.results[self].file
+      # Be permissive and skip failed probes
+      if not story_group_file.exists():
+        logging.info("Probe %s: skipping non-existing results file: %s",
+                     self.NAME, story_group_file)
+        continue
+      dest_file = result_dir / f"{story_group.browser.unique_name}.rcs.txt"
+      self.host_platform.symlink_or_copy(story_group_file, dest_file)
+      files.append(dest_file)
+    return LocalProbeResult(file=files)
+
+  def log_browsers_result(self, group: BrowsersRunGroup) -> None:
+    if self not in group.results:
+      return
+    logging.info("-" * 80)
+    logging.critical(
+        "V8 RCS results: open on  http://v8.dev/tools/head/callstats.html")
+    for file in group.results[self].get_all("txt"):
+      logging.critical("    %s", file)
+    logging.info("- " * 40)
+
+
+class V8RCSProbeContext(ProbeContext[V8RCSProbe]):
+  _rcs_table: Optional[str] = None
+
+  def setup(self) -> None:
+    pass
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    with self.run.actions("Extract RCS") as actions:
+      self._rcs_table = actions.js("return %GetAndResetRuntimeCallStats();")
+
+  def teardown(self) -> ProbeResult:
+    if not self._rcs_table:
+      raise ProbeMissingDataError(
+          "Chrome didn't produce any RCS data. "
+          "Use Chrome Canary or make sure to enable the "
+          "v8_enable_runtime_call_stats compile-time flag.")
+    rcs_file = self.local_result_path.with_suffix(".rcs.txt")
+    with rcs_file.open("a") as f:
+      f.write(self._rcs_table)
+    return LocalProbeResult(file=(rcs_file,))
diff --git a/crossbench/probes/v8/turbolizer.py b/crossbench/probes/v8/turbolizer.py
new file mode 100644
index 0000000..102effa
--- /dev/null
+++ b/crossbench/probes/v8/turbolizer.py
@@ -0,0 +1,73 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, cast
+
+from crossbench import helper
+from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.probes.chromium_probe import ChromiumProbe
+from crossbench.probes.probe import ProbeContext
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import (BrowserProbeResult, LocalProbeResult,
+                                       ProbeResult)
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.path import AnyPath
+  from crossbench.runner.run import Run
+
+
+class V8TurbolizerProbe(ChromiumProbe):
+  """
+  Chromium-only Probe for extracting detailed turbofan graphs.
+  Note: This probe can have significant overhead.
+  Tool: https://v8.dev/tools/head/turbolizer
+  """
+  NAME = "v8.turbolizer"
+  RESULT_LOCATION = ResultLocation.BROWSER
+
+  def attach(self, browser: Browser) -> None:
+    super().attach(browser)
+    assert isinstance(browser, Chromium)
+    chromium = cast(Chromium, browser)
+    chromium.flags.set("--no-sandbox")
+    chromium.js_flags.set("--trace-turbo")
+
+  def get_context(self, run: Run) -> V8TurbolizerProbeContext:
+    return V8TurbolizerProbeContext(self, run)
+
+
+class V8TurbolizerProbeContext(ProbeContext[V8TurbolizerProbe]):
+
+  @property
+  def results_dir(self) -> AnyPath:
+    # Put v8.turbolizer files into separate dirs in case we have
+    # multiple isolates
+    turbolizer_log_dir = super().result_path
+    self.browser_platform.mkdir(turbolizer_log_dir, exist_ok=True)
+    return turbolizer_log_dir
+
+  def setup(self) -> None:
+    js_flags = self.session.extra_js_flags
+    js_flags["--trace-turbo-path"] = str(self.results_dir)
+    js_flags["--trace-turbo-cfg-file"] = str(self.results_dir / "cfg.graph")
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    log_dir = self.local_result_path.parent
+    # Copy the files from a potentially remote browser to a the local result
+    # dir.
+    result: BrowserProbeResult = self.browser_result(file=(log_dir,))
+    local_log_dir = result.file
+    assert local_log_dir.is_dir()
+    # Sort files locally after transferring them.
+    log_files = helper.sort_by_file_size(local_log_dir.glob("*"))
+    return LocalProbeResult(file=log_files)
diff --git a/crossbench/probes/video.py b/crossbench/probes/video.py
new file mode 100644
index 0000000..e6d1c6b
--- /dev/null
+++ b/crossbench/probes/video.py
@@ -0,0 +1,362 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import logging
+import os
+import signal
+import subprocess
+import tempfile
+from typing import TYPE_CHECKING, Dict, List, Optional, TextIO, Tuple, Union
+
+from crossbench import helper
+from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+                                     ProbeMissingDataError)
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import (EmptyProbeResult, LocalProbeResult,
+                                       ProbeResult)
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Viewport
+  from crossbench.env import HostEnvironment
+  from crossbench.path import LocalPath
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.stories.story import Story
+
+
+class VideoProbe(Probe):
+  """
+  General-purpose Probe that collects screen-recordings.
+
+  It can also produce a timestrip png and creates merged versions of these files
+  for visually comparing various browsers / variants / cb.stories
+  """
+  NAME = "video"
+  RESULT_LOCATION = ResultLocation.BROWSER
+  VIDEO_QUALITY = ["-vcodec", "libx264", "-crf", "20"]
+  IMAGE_FORMAT = "png"
+  TIMESTRIP_FILE_SUFFIX = f".timestrip.{IMAGE_FORMAT}"
+  FRAMERATE = 60
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "generate_timestrip",
+        aliases=("timestrip",),
+        type=bool,
+        default=True,
+        help="Produce a timestrip png")
+    parser.add_argument(
+        "merge_runs",
+        type=bool,
+        default=True,
+        help="Merge videos from multiple runs")
+    return parser
+
+  def __init__(self,
+               generate_timestrip: bool = True,
+               merge_runs: bool = True) -> None:
+    super().__init__()
+    self._duration = None
+    self._generate_timestrip = generate_timestrip
+    self._merge_runs = merge_runs
+
+  @property
+  def result_path_name(self) -> str:
+    return f"{self.name}.mp4"
+
+  @property
+  def generate_timestrip(self) -> bool:
+    return self._generate_timestrip
+
+  @property
+  def merge_runs(self) -> bool:
+    return self._merge_runs
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    super().validate_env(env)
+    if env.repetitions > 10:
+      env.handle_warning(
+          f"Probe={self.NAME} might not be able to merge so many "
+          f"repetitions={env.repetitions}.")
+    env.check_installed(
+        binaries=("ffmpeg",), message="Missing binaries for video probe: {}")
+    # Check that ffmpeg can be executed
+    env.check_sh_success("ffmpeg", "-version")
+    env.check_installed(
+        binaries=("montage",),
+        message="Missing 'montage' binary, please install imagemagick.")
+    # Check that montage can be executed
+    env.check_sh_success("montage", "--version")
+    self._pre_check_viewport_size(env)
+
+  def _pre_check_viewport_size(self, env: HostEnvironment) -> None:
+    first_viewport: Viewport = env.browsers[0].viewport
+    for browser in env.browsers:
+      viewport: Viewport = browser.viewport
+      if viewport.is_headless:
+        env.handle_warning(
+            f"Cannot record video for headless browser: {browser}")
+      # TODO: support fullscreen / maximised
+      if not viewport.has_size:
+        env.handle_warning(
+            "Can only record video for browsers with explicit viewport sizes, "
+            f"but got {viewport} for {browser}.")
+      if viewport.x < 10 or viewport.y < 50:
+        env.handle_warning(
+            f"Viewport for '{browser}' might include toolbar: {viewport}")
+      if viewport != first_viewport:
+        env.handle_warning(
+            "Video recording requires same viewport size for all browsers.\n"
+            f"Viewport size for {browser} is {viewport}, "
+            f"which differs from first viewport {first_viewport}. ")
+
+  def get_context(self, run: Run) -> VideoProbeContext:
+    return VideoProbeContext(self, run)
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    if not self.merge_runs:
+      return LocalProbeResult()
+    runs = tuple(group.runs)
+    if len(runs) == 1:
+      # In the simple case just copy the files
+      run_files = runs[0].results[self].file_list
+      group_files = [group.path / f.name for f in run_files]
+      for src, dest in zip(run_files, group_files):
+        self.host_platform.copy(src, dest)
+      return LocalProbeResult(file=group_files)
+
+    video_file = group.get_local_probe_result_path(self)
+    group_files = [video_file]
+    logging.info("VIDEO merge page repetitions")
+    browser = group.browser
+    video_file_inputs: List[Union[str, LocalPath]] = []
+    for run in runs:
+      video_file_inputs += ["-i", run.results[self].file_list[0]]
+    draw_text = ("fontfile='/Library/Fonts/Arial.ttf':"
+                 f"text='{browser.app_name} {browser.label}':"
+                 "fontsize=h/15:"
+                 "y=h-line_h-10:x=10:"
+                 "box=1:boxborderw=20:boxcolor=white")
+    self.host_platform.sh(
+        "ffmpeg", "-hide_banner", \
+        *video_file_inputs, \
+        "-filter_complex",
+        f"hstack=inputs={len(runs)},"
+        f"drawtext={draw_text},"
+        "scale=3000:-2", *self.VIDEO_QUALITY, video_file)
+
+    if self._generate_timestrip:
+      timeline_strip_file = video_file.with_suffix(self.TIMESTRIP_FILE_SUFFIX)
+      logging.info("TIMESTRIP merge page repetitions")
+      timeline_strips = (run.results[self].file_list[1] for run in runs)
+      self.host_platform.sh("montage", *timeline_strips, "-tile", "1x",
+                            "-gravity", "NorthWest", "-geometry", "x100",
+                            timeline_strip_file)
+      group_files.append(timeline_strip_file)
+
+    return LocalProbeResult(file=group_files)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    """Merge story videos from multiple browser/configurations"""
+    if not self.merge_runs:
+      return LocalProbeResult()
+    groups = list(group.repetitions_groups)
+    if len(groups) <= 1:
+      return EmptyProbeResult()
+    grouped: Dict[Story, List[RepetitionsRunGroup]] = helper.group_by(
+        groups, key=lambda repetitions_group: repetitions_group.story)
+
+    result_dir = group.get_local_probe_result_path(self)
+    result_dir = result_dir / result_dir.stem
+    result_dir.mkdir(parents=True)
+    return LocalProbeResult(
+        file=(self._merge_stories_for_browser(result_dir, story,
+                                              repetitions_groups)
+              for story, repetitions_groups in grouped.items()))
+
+  def _merge_stories_for_browser(
+      self, result_dir: LocalPath, story: Story,
+      repetitions_groups: List[RepetitionsRunGroup]) -> LocalPath:
+    story = repetitions_groups[0].story
+    result_path = result_dir / f"{story.name}_combined.mp4"
+
+    if len(repetitions_groups) == 1:
+      # In the simple case just copy files
+      input_file = repetitions_groups[0].results[self].file_list[0]
+      self.host_platform.copy(input_file, result_path)
+      return result_path
+
+    input_files: List[str] = []
+    for repetitions_group in repetitions_groups:
+      result_files = repetitions_group.results[self].file_list
+      input_files += ["-i", os.fspath(result_files[0])]
+    try:
+      self.host_platform.sh("ffmpeg", "-hide_banner", *input_files,
+                            "-filter_complex",
+                            f"vstack=inputs={len(repetitions_groups)}",
+                            *self.VIDEO_QUALITY, result_path)
+    except Exception as e:
+      logging.error("Merging multiple browser video failed. "
+                    "Different screen orientations are not supported yet.")
+      logging.debug("Browser video merging failed: %e", e)
+      raise e
+    return result_path
+
+
+class VideoProbeContext(ProbeContext[VideoProbe]):
+  IMAGE_FORMAT = "png"
+  FFMPEG_TIMELINE_TEXT = (
+      "drawtext="
+      "fontfile=/Library/Fonts/Arial.ttf:"
+      "text='%{eif\\:t\\:d}.%{eif\\:t*100-floor(t)*100\\:d}s':"
+      "fontsize=h/16:"
+      "y=h-line_h-5:x=5:"
+      "box=1:boxborderw=15:boxcolor=white")
+
+  def __init__(self, probe: VideoProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._record_process: Optional[subprocess.Popen] = None
+    self._recorder_log_file: Optional[TextIO] = None
+
+  def start(self) -> None:
+    browser = self.run.browser
+    cmd = self._record_cmd(browser.viewport)
+    logging.debug("Screen recorder cmd: %s", cmd)
+    if self.browser_platform.is_remote:
+      self._recorder_log_file = None
+    else:
+      self._recorder_log_file = self.local_result_path.with_suffix(
+          ".recorder.log").open(
+              "w", encoding="utf-8")
+    self._record_process = self.browser_platform.popen(
+        *cmd,
+        stdin=subprocess.PIPE,
+        stderr=subprocess.STDOUT,
+        stdout=self._recorder_log_file)
+    if self._record_process.poll():
+      raise ValueError("Could not start screen recorder")
+    atexit.register(self.stop_process)
+    # TODO: Add common start-story-delay on runner for these cases.
+    self.host_platform.sleep(1)
+
+  def _record_cmd(self, viewport: Viewport) -> Tuple[str, ...]:
+    if self.browser_platform.is_linux:
+      env_display = os.environ.get("DISPLAY", ":0.0")
+      return ("ffmpeg", "-hide_banner", "-video_size",
+              f"{viewport.width}x{viewport.height}", "-f", "x11grab",
+              "-framerate", str(self.probe.FRAMERATE), "-i",
+              f"{env_display}+{viewport.x},{viewport.y}", str(self.result_path))
+    if self.browser_platform.is_macos:
+      return ("/usr/sbin/screencapture", "-v",
+              f"-R{viewport.x},{viewport.y},{viewport.width},{viewport.height}",
+              str(self.result_path))
+    if self.browser_platform.is_android:
+      return ("screenrecord", str(self.result_path))
+    raise ValueError("Invalid platform")
+
+  def stop(self) -> None:
+    assert self._record_process, "screencapture stopped early."
+    if self.browser_platform.is_macos:
+      assert not self._record_process.poll(), (
+          "screencapture stopped early. "
+          "Please ensure that the parent application has screen recording "
+          "permissions")
+      # The mac screencapture stops on the first (arbitrary) input.
+      self._record_process.communicate(input=b"stop")
+    elif self.browser_platform.is_android:
+      self._record_process.send_signal(signal.SIGINT)
+    else:
+      self._record_process.terminate()
+
+  def teardown(self) -> ProbeResult:
+    assert self._record_process, "Screen recorder stopped early."
+    if self._recorder_log_file:
+      self._recorder_log_file.close()
+    self.stop_process()
+    if not self.browser_platform.is_file(self.result_path):
+      raise ProbeMissingDataError(
+          f"No screen recording video found at: {self.result_path}")
+    # Copy files
+    browser_result = self.browser_result(file=(self.result_path,))
+    self._default_result_path = browser_result.file
+    assert self.host_platform.exists(self.result_path)
+
+    if not self.probe.generate_timestrip:
+      return LocalProbeResult(file=(self.local_result_path,))
+
+    with tempfile.TemporaryDirectory() as tmp_dir:
+      self._convert_to_constant_framerate()
+      timestrip_file = self._create_time_strip(
+          self.host_platform.local_path(tmp_dir))
+    return LocalProbeResult(file=(self.local_result_path, timestrip_file))
+
+  def stop_process(self) -> None:
+    if self._record_process:
+      helper.wait_and_kill(self._record_process, timeout=5)
+      self._record_process = None
+
+  def _convert_to_constant_framerate(self):
+    # On some platforms (android for certain) we get VFR videos which confuse
+    # the next video extraction / conversion steps.
+    vrf_video_result = (
+        self.local_result_path.parent / f"vfr_{self.result_path.name}")
+    self.local_result_path.rename(vrf_video_result)
+    self.host_platform.sh(
+        "ffmpeg", "-hide_banner", \
+        "-fflags", "+igndts", \
+        "-i", vrf_video_result, \
+        "-filter:v", "fps=60", \
+        "-fps_mode:v", "cfr",
+        # Use the decoder timebase.
+        "-copytb", "0", \
+        *self.probe.VIDEO_QUALITY,
+        self.result_path
+    )
+    if not self.local_result_path.exists() or self.local_result_path.stat(
+    ).st_size == 0:
+      vrf_video_result.rename(self.result_path)
+      logging.error("Could not generate constant FPS video: %s",
+                    self.result_path)
+    else:
+      vrf_video_result.unlink()
+
+  def _create_time_strip(self, tmpdir: LocalPath) -> LocalPath:
+    logging.info("TIMESTRIP")
+    progress_dir = tmpdir / "progress"
+    progress_dir.mkdir(parents=True, exist_ok=True)
+    timeline_dir = tmpdir / "timeline"
+    timeline_dir.mkdir(exist_ok=True)
+    # Try detect scene changes / steps
+    self.host_platform.sh(
+        "ffmpeg", "-hide_banner", "-i", self.result_path, \
+        "-filter_complex", "scale=3000:-2,"
+        "select='gt(scene\\,0.011)'," + self.FFMPEG_TIMELINE_TEXT, \
+        "-fps_mode", "cfr", \
+        "-framerate", str(self.probe.FRAMERATE), \
+          f"{progress_dir}/%02d.{self.IMAGE_FORMAT}")
+    # Extract at regular intervals of 100ms, assuming 60fps input
+    every_nth_frame = self.probe.FRAMERATE / 20
+    safe_duration = 10
+    safe_duration = 2
+    self.host_platform.sh(
+        "ffmpeg", "-hide_banner", \
+        "-i", self.result_path, \
+        "-filter_complex",
+        f"trim=duration={safe_duration},"
+        "scale=3000:-2,"
+        f"select=not(mod(n\\,{every_nth_frame}))," + self.FFMPEG_TIMELINE_TEXT,
+        f"{timeline_dir}/%02d.{self.IMAGE_FORMAT}")
+
+    timeline_strip_file = self.local_result_path.with_suffix(
+        self.probe.TIMESTRIP_FILE_SUFFIX)
+    self.runner.platform.sh("montage", f"{timeline_dir}/*.{self.IMAGE_FORMAT}",
+                            "-tile", "x1", "-gravity", "NorthWest", "-geometry",
+                            "x100", timeline_strip_file)
+    return timeline_strip_file
diff --git a/crossbench/probes/web_page_replay/__init__.py b/crossbench/probes/web_page_replay/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/probes/web_page_replay/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/probes/web_page_replay/recorder.py b/crossbench/probes/web_page_replay/recorder.py
new file mode 100644
index 0000000..5183531
--- /dev/null
+++ b/crossbench/probes/web_page_replay/recorder.py
@@ -0,0 +1,231 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import shutil
+from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Union
+
+from immutabledict import immutabledict
+
+from crossbench import helper, plt
+from crossbench.helper.path_finder import WprGoToolFinder
+from crossbench.network.replay.web_page_replay import WprRecorder
+from crossbench.parse import PathParser
+from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeContext
+from crossbench.probes.results import (EmptyProbeResult, LocalProbeResult,
+                                       ProbeResult)
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.path import LocalPath
+  from crossbench.runner.groups.base import RunGroup
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+
+
+
+class WebPageReplayProbe(Probe):
+  """
+  Probe to collect browser requests to wpr.go archive which then can be
+  replayed using a local proxy server.
+
+  Chrome telemetry's wpr.go:
+  https://chromium.googlesource.com/catapult/+/HEAD/web_page_replay_go/README.md
+  """
+
+  NAME = "wpr"
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument("http_port", type=int, default=8080, required=False)
+    parser.add_argument("https_port", type=int, default=8081, required=False)
+    parser.add_argument(
+        "wpr_go_bin", type=PathParser.binary_path, required=False)
+    parser.add_argument(
+        "key_file", type=PathParser.existing_file_path, required=False)
+    parser.add_argument(
+        "cert_file", type=PathParser.existing_file_path, required=False)
+    parser.add_argument(
+        "inject_scripts",
+        is_list=True,
+        type=PathParser.existing_file_path,
+        required=False)
+    parser.add_argument(
+        "use_test_root_certificate", type=bool, default=False, required=False)
+    parser.add_argument(
+        "record_setup",
+        type=bool,
+        default=True,
+        help="Also include the requests that are part of "
+        "the setup / login steps, "
+        "which might include passwords.")
+    return parser
+
+  def __init__(self,
+               http_port: int = 0,
+               https_port: int = 0,
+               wpr_go_bin: Optional[LocalPath] = None,
+               inject_scripts: Optional[Iterable[LocalPath]] = None,
+               key_file: Optional[LocalPath] = None,
+               cert_file: Optional[LocalPath] = None,
+               use_test_root_certificate: bool = False,
+               record_setup: bool = True):
+    super().__init__()
+    host_platform = plt.PLATFORM
+    if not wpr_go_bin:
+      if local_wpr_path := WprGoToolFinder(host_platform).path:
+        wpr_go_bin = host_platform.local_path(local_wpr_path)
+    if not wpr_go_bin:
+      raise RuntimeError(f"Could not find wpr.go on {host_platform}")
+    self._wpr_go_bin: LocalPath = host_platform.local_path(
+        PathParser.binary_path(wpr_go_bin, "wpr.go"))
+
+    self._recorder_kwargs: immutabledict[str, Any] = immutabledict(
+        bin_path=wpr_go_bin,
+        http_port=http_port,
+        https_port=https_port,
+        inject_scripts=inject_scripts,
+        key_file=key_file,
+        cert_file=cert_file,
+    )
+
+    self._https_port = https_port
+    self._http_port = http_port
+    self._use_test_root_certificate = use_test_root_certificate
+    self._record_setup = record_setup
+
+  @property
+  def https_port(self) -> int:
+    return self._https_port
+
+  @property
+  def http_port(self) -> int:
+    return self._http_port
+
+  @property
+  def recorder_kwargs(self) -> immutabledict:
+    return self._recorder_kwargs
+
+  @property
+  def use_test_root_certificate(self) -> bool:
+    return self._use_test_root_certificate
+
+  @property
+  def record_setup(self) -> bool:
+    return self._record_setup
+
+  @property
+  def result_path_name(self) -> str:
+    return "archive.wprgo"
+
+  def is_compatible(self, browser: Browser) -> bool:
+    return browser.attributes.is_chromium_based and browser.platform.is_local
+
+  def get_context(self, run: Run) -> WprRecorderProbeContext:
+    return WprRecorderProbeContext(self, run)
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    results = [run.results[self].file for run in group.runs]
+    return self.merge_group(results, group)
+
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    results = [
+        subgroup.results[self].file for subgroup in group.repetitions_groups
+    ]
+    return self.merge_group(results, group)
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    results = [subgroup.results[self].file for subgroup in group.story_groups]
+    return self.merge_group(results, group)
+
+  def merge_group(self, results: List[LocalPath],
+                  group: RunGroup) -> ProbeResult:
+    result_file = group.get_local_probe_result_path(self)
+    if not results:
+      return EmptyProbeResult()
+    first_wprgo = results.pop(0)
+    # TODO migrate to platform
+    shutil.copy(first_wprgo, result_file)
+    for repetition_file in results:
+      self.httparchive_merge(repetition_file, result_file)
+    return ProbeResult(file=[result_file])
+
+  def httparchive_merge(self, input_archive: LocalPath,
+                        output_archive: LocalPath) -> None:
+    cmd: List[Union[str, LocalPath]] = [
+        "go",
+        "run",
+        self._wpr_go_bin.parent / "httparchive.go",
+        "merge",
+        output_archive,
+        input_archive,
+        output_archive,
+    ]
+    with helper.ChangeCWD(self._wpr_go_bin.parent):
+      self.host_platform.sh(*cmd)
+
+
+class WprRecorderProbeContext(ProbeContext[WebPageReplayProbe]):
+
+  def __init__(self, probe: WebPageReplayProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._wprgo_log: LocalPath = self.local_result_path.with_name(
+        "wpr_record.log")
+    self._host: str = "127.0.0.1"
+    kwargs = dict(self.probe.recorder_kwargs)
+    kwargs.update({
+        "platform": run.host_platform,
+        "log_path": self._wprgo_log,
+        "archive_path": self.result_path,
+    })
+    self._recorder = WprRecorder(**kwargs)
+    self._browser_platform = run.browser_platform
+
+  def setup(self) -> None:
+    self._recorder.start()
+    self._setup_extra_flags()
+    self._setup_port_forwarding()
+
+  def _setup_extra_flags(self) -> None:
+    if not self.probe.use_test_root_certificate:
+      cert_hash_file = self._recorder.cert_file.parent / "wpr_public_hash.txt"
+      if not cert_hash_file.is_file():
+        raise ValueError(
+            f"Could not read public key hash file: {cert_hash_file}")
+      cert_skip_list = ",".join(cert_hash_file.read_text().strip().splitlines())
+      self.session.extra_flags[
+          "--ignore-certificate-errors-spki-list"] = cert_skip_list
+    # TODO: support ts_proxy traffic shaping
+    # session.extra_flags["--proxy-server"] =  (
+    #   "socks://{self._ts_proxy_host}:{self._ts_proxy_port}")
+    # session.extra_flags["--proxy-bypass-list"] = "<-loopback>"
+    self.session.extra_flags["--host-resolver-rules"] = (
+        f"MAP *:80 {self._host}:{self._recorder.http_port},"
+        f"MAP *:443 {self._host}:{self._recorder.https_port},"
+        "EXCLUDE localhost")
+    # TODO: add replay support, see:
+    # https://crsrc.org/c/third_party/catapult/telemetry/telemetry/internal/backends/chrome/chrome_startup_args.py
+
+  def _setup_port_forwarding(self) -> None:
+    if self._browser_platform.is_remote:
+      self._browser_platform.reverse_port_forward(self._recorder.http_port,
+                                                  self._recorder.http_port)
+      self._browser_platform.reverse_port_forward(self._recorder.https_port,
+                                                  self._recorder.https_port)
+
+  def start(self) -> None:
+    if not self.probe.record_setup:
+      assert self._recorder
+      self._recorder.clear()
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    self._recorder.stop()
+    return LocalProbeResult(file=(self.local_result_path,))
diff --git a/crossbench/runner/__init__.py b/crossbench/runner/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/runner/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/runner/actions.py b/crossbench/runner/actions.py
new file mode 100644
index 0000000..f7bff62
--- /dev/null
+++ b/crossbench/runner/actions.py
@@ -0,0 +1,138 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+import sys
+from typing import TYPE_CHECKING, Any, Optional, Sequence, Union
+
+from crossbench import helper
+
+if TYPE_CHECKING:
+  from crossbench import plt
+  from crossbench.browsers.browser import Browser
+  from crossbench.exception import ExceptionAnnotationScope
+  from crossbench.runner.run import Run
+  from crossbench.runner.runner import Runner
+  from crossbench.runner.timing import Timing
+
+
+class Actions(helper.TimeScope):
+
+  _max_end_datetime: dt.datetime
+
+  def __init__(self,
+               message: str,
+               run: Run,
+               runner: Optional[Runner] = None,
+               browser: Optional[Browser] = None,
+               verbose: bool = False,
+               measure: bool = True,
+               timeout: dt.timedelta = dt.timedelta()):
+    assert message, "Actions need a name"
+    super().__init__(message)
+    self._exception_annotation: ExceptionAnnotationScope = run.exceptions.info(
+        f"Action: {message}")
+    self._run: Run = run
+    self._browser: Browser = browser or run.browser
+    self._runner: Runner = runner or run.runner
+    self._is_active: bool = False
+    self._verbose: bool = verbose
+    self._measure = measure
+    if timeout:
+      self._max_end_datetime = min(dt.datetime.now() + timeout,
+                                   run.max_end_datetime())
+    else:
+      self._max_end_datetime = run.max_end_datetime()
+
+  @property
+  def timing(self) -> Timing:
+    return self._runner.timing
+
+  @property
+  def run(self) -> Run:
+    return self._run
+
+  @property
+  def platform(self) -> plt.Platform:
+    return self._run.browser_platform
+
+  def __enter__(self) -> Actions:
+    self._exception_annotation.__enter__()
+    super().__enter__()
+    self._is_active = True
+    logging.debug("Action begin: %s", self._message)
+    if self._verbose:
+      logging.info(self._message.ljust(30))
+    else:
+      # Print message that doesn't overlap with helper.Spinner
+      sys.stdout.write(f"   {self._message.ljust(30)}\r")
+    return self
+
+  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+    self._is_active = False
+    self._exception_annotation.__exit__(exc_type, exc_value, exc_traceback)
+    super().__exit__(exc_type, exc_value, exc_traceback)
+    logging.debug("Action end: %s", self._message)
+    if self._measure:
+      self.run.durations[f"actions-duration {self.message}"] = self.duration
+
+  def _assert_is_active(self) -> None:
+    assert self._is_active, "Actions have to be used in a with scope"
+
+  def current_window_id(self) -> str:
+    return self._browser.current_window_id()
+
+  def switch_window(self, window_id: str) -> None:
+    self._browser.switch_window(window_id)
+
+  def js(self,
+         js_code: str,
+         timeout: Union[int, float, dt.timedelta] = 10,
+         arguments: Sequence[object] = (),
+         **kwargs) -> Any:
+    self._assert_is_active()
+    assert js_code, "js_code must be a valid JS script"
+    if kwargs:
+      js_code = js_code.format(**kwargs)
+    delta = self.timing.timeout_timedelta(timeout)
+    return self._browser.js(js_code, delta, arguments=arguments)
+
+  def wait_js_condition(self,
+                        js_code: str,
+                        min_wait: Union[dt.timedelta, float],
+                        timeout: Union[dt.timedelta, float],
+                        delay: Union[dt.timedelta, float] = 0) -> None:
+    wait_range = helper.WaitRange(
+        min=self.timing.timedelta(min_wait),
+        timeout=self.timing.timeout_timedelta(timeout),
+        delay=delay)
+    assert "return" in js_code, (
+        f"Missing return statement in js-wait code: {js_code}")
+    for _, time_left in wait_range.wait_with_backoff():
+      time_units = self.timing.units(time_left)
+      result = self.js(js_code, timeout=time_units, absolute_time=True)
+      if result:
+        return
+      assert result is False, (
+          f"js_code did not return a bool, but got: {result}\n"
+          f"js-code: {js_code}")
+
+  def show_url(self, url: str, target: Optional[str] = None) -> None:
+    self._assert_is_active()
+    if target and target in ("_blank", "_parent", "_top"):
+      # TODO: use target in the driver instead.
+      self.js(f"window.open('{url}','{target}');")
+    else:
+      if target not in (None, "_self", "_new_tab", "_new_window"):
+        raise ValueError(f"Invalid target: {target}")
+      self._browser.show_url(url, target=target)
+
+  def wait(
+      self, seconds: Union[dt.timedelta,
+                           float] = dt.timedelta(seconds=1)) -> None:
+    self._assert_is_active()
+    self.platform.sleep(seconds)
diff --git a/crossbench/runner/exception.py b/crossbench/runner/exception.py
new file mode 100644
index 0000000..add0b0e
--- /dev/null
+++ b/crossbench/runner/exception.py
@@ -0,0 +1,6 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+class StopStoryException(Exception):
+  """Exceptions thrown that resulted in the termination of the story."""
diff --git a/crossbench/runner/groups/__init__.py b/crossbench/runner/groups/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/runner/groups/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/runner/groups/base.py b/crossbench/runner/groups/base.py
new file mode 100644
index 0000000..f97a143
--- /dev/null
+++ b/crossbench/runner/groups/base.py
@@ -0,0 +1,106 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+from typing import TYPE_CHECKING, Iterable, Optional
+
+from crossbench import exception
+from crossbench.probes.results import ProbeResult, ProbeResultDict
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+  from crossbench.probes.probe import Probe
+  from crossbench.runner.run import Run
+  from crossbench.runner.runner import Runner
+  from crossbench.types import JsonDict
+
+
+class RunGroup(abc.ABC):
+
+  def __init__(self, throw: bool = False) -> None:
+    self._exceptions = exception.Annotator(throw)
+    self._path: Optional[LocalPath] = None
+    self._merged_probe_results: Optional[ProbeResultDict] = None
+
+  def _set_path(self, path: LocalPath) -> None:
+    assert self._path is None
+    self._path = path
+    self._merged_probe_results = ProbeResultDict(path)
+
+  @property
+  def results(self) -> ProbeResultDict:
+    assert self._merged_probe_results is not None
+    return self._merged_probe_results
+
+  @property
+  def path(self) -> LocalPath:
+    assert self._path
+    return self._path
+
+  @property
+  def throw(self) -> bool:
+    return self._exceptions.throw
+
+  @property
+  def exceptions(self) -> exception.Annotator:
+    return self._exceptions
+
+  @property
+  def is_success(self) -> bool:
+    return self._exceptions.is_success
+
+  @property
+  @abc.abstractmethod
+  def info_stack(self) -> exception.TInfoStack:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def runs(self) -> Iterable[Run]:
+    pass
+
+  @property
+  def failed_runs(self) -> Iterable[Run]:
+    for run in self.runs:
+      if not run.is_success:
+        yield run
+
+  @property
+  def info(self) -> JsonDict:
+    return {
+        "runs": len(tuple(self.runs)),
+        "failed runs": len(tuple(self.failed_runs))
+    }
+
+  def get_local_probe_result_path(self,
+                                  probe: Probe,
+                                  exists_ok: bool = False) -> LocalPath:
+    new_file = self.path / probe.result_path_name
+    if not exists_ok:
+      assert not new_file.exists(), (
+          f"Merged file {new_file} for {self.__class__} exists already.")
+    return new_file
+
+  def get_local_probe_result_dir(self,
+                                 probe: Probe,
+                                 exists_ok: bool = True) -> LocalPath:
+    path = self.get_local_probe_result_path(probe, exists_ok)
+    path.mkdir(parents=True, exist_ok=exists_ok)
+    return path
+
+  def merge(self, probes: Iterable[Probe]) -> None:
+    assert self._merged_probe_results is not None
+    with self._exceptions.info(*self.info_stack):
+      for probe in reversed(tuple(probes)):
+        with self._exceptions.capture(f"Probe {probe.name} merge results"):
+          results = self._merge_probe_results(probe)
+          if results is None:
+            continue
+          self._merged_probe_results[probe] = results
+
+  @abc.abstractmethod
+  def _merge_probe_results(self, probe: Probe) -> ProbeResult:
+    pass
diff --git a/crossbench/runner/groups/browsers.py b/crossbench/runner/groups/browsers.py
new file mode 100644
index 0000000..355d8e1
--- /dev/null
+++ b/crossbench/runner/groups/browsers.py
@@ -0,0 +1,55 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Iterable
+
+from crossbench.runner.groups.base import RunGroup
+
+if TYPE_CHECKING:
+  from crossbench import exception
+  from crossbench.browsers.browser import Browser
+  from crossbench.probes.probe import Probe
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.runner.run import Run
+
+
+class BrowsersRunGroup(RunGroup):
+
+  def __init__(self, story_groups: Iterable[StoriesRunGroup],
+               throw: bool) -> None:
+    super().__init__(throw)
+    self._story_groups = tuple(story_groups)
+    if not story_groups:
+      raise ValueError("No story groups provided")
+    self._set_path(self._story_groups[0].path.parents[1])
+
+  @property
+  def story_groups(self) -> Iterable[StoriesRunGroup]:
+    return self._story_groups
+
+  @property
+  def browsers(self) -> Iterable[Browser]:
+    for story_group in self._story_groups:
+      yield story_group.browser
+
+  @property
+  def repetitions_groups(self) -> Iterable[RepetitionsRunGroup]:
+    for story_group in self._story_groups:
+      yield from story_group.repetitions_groups
+
+  @property
+  def runs(self) -> Iterable[Run]:
+    for group in self._story_groups:
+      yield from group.runs
+
+  @property
+  def info_stack(self) -> exception.TInfoStack:
+    return ("Merging results from multiple browsers",)
+
+  def _merge_probe_results(self, probe: Probe) -> ProbeResult:
+    return probe.merge_browsers(self)
diff --git a/crossbench/runner/groups/cache_temperatures.py b/crossbench/runner/groups/cache_temperatures.py
new file mode 100644
index 0000000..2e7e223
--- /dev/null
+++ b/crossbench/runner/groups/cache_temperatures.py
@@ -0,0 +1,97 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Iterable, List, Optional, Tuple
+
+from crossbench import helper
+from crossbench.runner.groups.base import RunGroup
+
+if TYPE_CHECKING:
+  from crossbench import exception
+  from crossbench.browsers.browser import Browser
+  from crossbench.probes.probe import Probe
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+  from crossbench.runner.runner import Runner
+  from crossbench.stories.story import Story
+  from crossbench.types import JsonDict
+
+
+class CacheTemperaturesRunGroup(RunGroup):
+  """
+  A group of Run objects with different cache temperatures for the same Story
+  with same browser and same repetition.
+  """
+
+  @classmethod
+  def groups(cls,
+             runs: Iterable[Run],
+             throw: bool = False) -> Tuple[CacheTemperaturesRunGroup, ...]:
+    return tuple(
+        helper.group_by(
+            runs,
+            key=lambda run: (run.story, run.browser, run.repetition),
+            group=lambda _: cls(throw),
+            sort_key=None).values())
+
+  def __init__(self, throw: bool = False):
+    super().__init__(throw)
+    self._runs: List[Run] = []
+    self._story: Optional[Story] = None
+    self._browser: Optional[Browser] = None
+    self._repetition = -1
+    self._cache_temperature = ""
+
+  def append(self, run: Run) -> None:
+    if self._path is None:
+      self._set_path(run.group_dir)
+      self._story = run.story
+      self._browser = run.browser
+      self._repetition = run.repetition
+    assert self._story == run.story
+    assert self._path == run.group_dir
+    assert self._browser == run.browser
+    assert self._repetition == run.repetition
+    self._runs.append(run)
+
+  @property
+  def runs(self) -> Iterable[Run]:
+    return iter(self._runs)
+
+  @property
+  def repetition(self) -> int:
+    return self._repetition
+
+  @property
+  def story(self) -> Story:
+    assert self._story
+    return self._story
+
+  @property
+  def browser(self) -> Browser:
+    assert self._browser
+    return self._browser
+
+  @property
+  def info_stack(self) -> exception.TInfoStack:
+    return (
+        "Merging results from multiple cache temperatures",
+        f"browser={self.browser.unique_name}",
+        f"story={self.story}",
+        f"repetition={self.repetition}",
+    )
+
+  @property
+  def info(self) -> JsonDict:
+    info = {
+        "story": str(self.story),
+        "repetition": self.repetition,
+    }
+    info.update(super().info)
+    return info
+
+  def _merge_probe_results(self, probe: Probe) -> ProbeResult:
+    return probe.merge_cache_temperatures(self)
diff --git a/crossbench/runner/groups/repetitions.py b/crossbench/runner/groups/repetitions.py
new file mode 100644
index 0000000..d262588
--- /dev/null
+++ b/crossbench/runner/groups/repetitions.py
@@ -0,0 +1,166 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Dict, Iterable, List, Optional, Tuple
+
+from crossbench import helper
+from crossbench.path import LocalPath
+from crossbench.runner.groups.base import RunGroup
+
+if TYPE_CHECKING:
+  from crossbench import exception
+  from crossbench.browsers.browser import Browser
+  from crossbench.probes.probe import Probe
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.groups.cache_temperatures import \
+      CacheTemperaturesRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.stories.story import Story
+  from crossbench.types import JsonDict
+
+
+class RepetitionsRunGroup(RunGroup):
+  """
+  A group of Run objects that are different repetitions for the same Story
+  and the same browser, including all cache temperatures.
+  """
+
+  @classmethod
+  def groups(cls,
+             run_groups: Iterable[CacheTemperaturesRunGroup],
+             throw: bool = False) -> Tuple[RepetitionsRunGroup, ...]:
+    return tuple(
+        helper.group_by(
+            run_groups,
+            key=lambda group: (group.browser, group.story),
+            group=lambda _: cls(throw),
+            sort_key=None).values())
+
+  def __init__(self, throw: bool = False):
+    super().__init__(throw)
+    self._cache_temperatures_groups: List[CacheTemperaturesRunGroup] = []
+    self._cache_temperature_repetitions_groups: Dict[
+        str, CacheTemperatureRepetitionsRunGroup] = {}
+    self._story: Optional[Story] = None
+    self._browser: Optional[Browser] = None
+
+  def append(self, group: CacheTemperaturesRunGroup) -> None:
+    if self._path is None:
+      self._set_path(group.path.parent)
+      self._story = group.story
+      self._browser = group.browser
+    assert self._story == group.story
+    assert self._path == group.path.parent
+    assert self._browser == group.browser
+    self._cache_temperatures_groups.append(group)
+    for run in group.runs:
+      self._append_run(run)
+
+  def _append_run(self, run: Run) -> None:
+    temperature = run.temperature
+    group = self._cache_temperature_repetitions_groups.get(temperature)
+    if not group:
+      group = CacheTemperatureRepetitionsRunGroup(self, self.throw)
+      self._cache_temperature_repetitions_groups[temperature] = group
+    group.append(run)
+
+  @property
+  def story(self) -> Story:
+    assert self._story
+    return self._story
+
+  @property
+  def browser(self) -> Browser:
+    assert self._browser
+    return self._browser
+
+  @property
+  def cache_temperatures_groups(self) -> List[CacheTemperaturesRunGroup]:
+    return self._cache_temperatures_groups
+
+  @property
+  def cache_temperature_repetitions_groups(
+      self) -> List[CacheTemperatureRepetitionsRunGroup]:
+    return list(self._cache_temperature_repetitions_groups.values())
+
+  @property
+  def runs(self) -> Iterable[Run]:
+    for group in self._cache_temperatures_groups:
+      yield from group.runs
+
+  @property
+  def info_stack(self) -> exception.TInfoStack:
+    return ("Merging results from multiple repetitions",
+            f"browser={self.browser.unique_name}", f"story={self.story}")
+
+  @property
+  def info(self) -> JsonDict:
+    info: JsonDict = {"story": str(self.story)}
+    info.update(super().info)
+    return info
+
+  def _merge_probe_results(self, probe: Probe) -> ProbeResult:
+    return probe.merge_repetitions(self)
+
+
+class CacheTemperatureRepetitionsRunGroup(RunGroup):
+  """
+  A group of Run objects that are different repetitions for the same Story
+  and the same browser and the same cache temperatures.
+  """
+
+  def __init__(self,
+               repetitions_group: RepetitionsRunGroup,
+               throw: bool = False):
+    super().__init__(throw)
+    self._repetitions_group = repetitions_group
+    self._set_path(repetitions_group.path)
+    self._cache_temperature: str = ""
+    self._runs: List[Run] = []
+
+  @property
+  def repetitions_group(self) -> RepetitionsRunGroup:
+    return self._repetitions_group
+
+  @property
+  def story(self) -> Story:
+    return self._repetitions_group.story
+
+  @property
+  def browser(self) -> Browser:
+    return self._repetitions_group.browser
+
+  @property
+  def path(self) -> LocalPath:
+    return self._repetitions_group.path
+
+  @property
+  def cache_temperature(self) -> str:
+    return self._cache_temperature
+
+  @property
+  def runs(self) -> Iterable[Run]:
+    return iter(self._runs)
+
+  @property
+  def info_stack(self) -> exception.TInfoStack:
+    info_stack = self.repetitions_group.info_stack
+    info_stack += (f"cache_temperature={self.cache_temperature}",)
+    return info_stack
+
+  @property
+  def info(self) -> JsonDict:
+    info = self._repetitions_group.info
+    return info
+
+  def append(self, run: Run) -> None:
+    if not self._cache_temperature:
+      self._cache_temperature = run.temperature
+    assert self._cache_temperature == run.temperature
+    self._runs.append(run)
+
+  def _merge_probe_results(self, probe: Probe) -> ProbeResult:
+    raise NotImplementedError("Unsupported")
diff --git a/crossbench/runner/groups/session.py b/crossbench/runner/groups/session.py
new file mode 100644
index 0000000..b3e9a4e
--- /dev/null
+++ b/crossbench/runner/groups/session.py
@@ -0,0 +1,376 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+import enum
+import logging
+from typing import TYPE_CHECKING, Iterable, Iterator, List, Optional, Tuple
+
+from crossbench.exception import TInfoStack
+from crossbench.flags.base import Flags
+from crossbench.flags.js_flags import JSFlags
+from crossbench.helper import ChangeCWD, Durations
+from crossbench.helper.state import BaseState, StateMachine
+from crossbench.probes.probe_context import ProbeSessionContext
+from crossbench.probes.results import EmptyProbeResult, ProbeResultDict
+from crossbench.runner.groups.base import RunGroup
+from crossbench.runner.probe_context_manager import ProbeContextManager
+from crossbench.runner.result_origin import ResultOrigin
+
+if TYPE_CHECKING:
+  from selenium.webdriver.common.options import ArgOptions
+
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.network.base import Network
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.probes.probe import Probe
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+  from crossbench.runner.timing import Timing
+  from crossbench.types import JsonDict
+
+
+@enum.unique
+class State(BaseState):
+  BUILDING = enum.auto()
+  READY = enum.auto()
+  SETUP = enum.auto()
+  STARTING = enum.auto()
+  RUNNING = enum.auto()
+  STOPPING = enum.auto()
+  DONE = enum.auto()
+
+
+class BrowserSessionRunGroup(RunGroup, ResultOrigin):
+  """
+  Groups Run objects together that are run within the same browser session.
+  At the beginning of a new session the caches are cleared and the
+  browser is (re-)started.
+  """
+
+  def __init__(self, env: HostEnvironment, probes: Iterable[Probe],
+               browser: Browser, extra_flags: Flags, index: int,
+               root_dir: LocalPath, create_symlinks: bool, throw: bool) -> None:
+    super().__init__(throw)
+    self._state: StateMachine[State] = StateMachine(State.BUILDING)
+    self._env = env
+    self._create_symlinks = create_symlinks
+    self._probes: Tuple[Probe, ...] = tuple(probes)
+    self._durations = Durations()
+    self._browser = browser
+    self._network: Network = browser.network
+    self._index: int = index
+    self._runs: List[Run] = []
+    self._root_dir: LocalPath = root_dir
+    self._browser_tmp_dir: Optional[AnyPath] = None
+    self._extra_js_flags = JSFlags()
+    self._extra_flags = extra_flags
+    # Temporary objects, reset after all runs are ready (see set_ready).
+    self._probe_results = ProbeResultDict(root_dir)
+    self._probe_context_manager = ProbeSessionContextManager(
+        self, self._probe_results)
+
+  def append(self, run: Run) -> None:
+    self._state.expect(State.BUILDING)
+    assert run.browser_session == self
+    assert run.browser is self._browser
+    # TODO: assert that the runs have compatible flags (likely we're only
+    # allowing changes in the cache temperature)
+    # TODO: Add session/run switch for probe results
+    self._runs.append(run)
+
+  def set_ready(self) -> None:
+    self._state.transition(State.BUILDING, to=State.READY)
+    self._validate()
+    self._set_path(self._get_session_dir())
+    self._probe_results = ProbeResultDict(self.path)
+    self._probe_context_manager = ProbeSessionContextManager(
+        self, self._probe_results)
+
+  def _validate(self) -> None:
+    if not self._runs:
+      raise ValueError("BrowserSessionRunGroup must be non-empty.")
+    self.browser.validate_env(self.env)
+    for run in self.runs:
+      run.validate_env(self.env)
+    self._validate_same_browser_probes()
+
+  def _validate_same_browser_probes(self) -> None:
+    first_run = self._runs[0]
+    first_probes = tuple(first_run.probes)
+    for index, run in enumerate(self.runs):
+      if first_run.browser is not run.browser:
+        raise ValueError("A browser session can only contain "
+                         "Runs with the same Browser.\n"
+                         f"runs[0].browser == {first_run.browser} vs. "
+                         f"runs[{index}].browser == {run.browser}")
+      if first_probes != tuple(run.probes):
+        raise ValueError("Got conflicting Probes within a browser session.\n"
+                         "All runs must have the same probes within a session.")
+
+  @property
+  def raw_session_dir(self) -> LocalPath:
+    return (self.root_dir / self.browser.unique_name / "sessions" /
+            str(self.index))
+
+  @property
+  def is_single_run(self) -> bool:
+    return len(self._runs) == 1
+
+  @property
+  def first_run(self) -> Run:
+    return self._runs[0]
+
+  def _get_session_dir(self) -> LocalPath:
+    self._state.expect_at_least(State.READY)
+    if self.is_single_run:
+      return self.first_run.out_dir
+    if not self._runs:
+      raise ValueError("Cannot have empty browser session")
+    return self.raw_session_dir
+
+  @property
+  def out_dir(self) -> LocalPath:
+    return self._get_session_dir()
+
+  @property
+  def browser_dir(self) -> LocalPath:
+    return self.root_dir / self.browser.unique_name
+
+  @property
+  def durations(self) -> Durations:
+    return self._durations
+
+  @property
+  def env(self) -> HostEnvironment:
+    return self._env
+
+  @property
+  def probes(self) -> Iterable[Probe]:
+    return iter(self._probes)
+
+  @property
+  def network(self) -> Network:
+    return self._network
+
+  @property
+  def browser(self) -> Browser:
+    return self._browser
+
+  @property
+  def index(self) -> int:
+    return self._index
+
+  @property
+  def is_running(self) -> bool:
+    return self._state == State.RUNNING
+
+  @property
+  def root_dir(self) -> LocalPath:
+    return self._root_dir
+
+  @property
+  def runs(self) -> Iterable[Run]:
+    return iter(self._runs)
+
+  @property
+  def timing(self) -> Timing:
+    return self._runs[0].timing
+
+  @property
+  def extra_js_flags(self) -> JSFlags:
+    self._state.expect_before(State.RUNNING)
+    return self._extra_js_flags
+
+  @property
+  def extra_flags(self) -> Flags:
+    self._state.expect_before(State.RUNNING)
+    return self._extra_flags
+
+  def add_flag_details(self, details_json: JsonDict) -> None:
+    assert isinstance(details_json["js_flags"], tuple)
+    details_json["js_flags"] += tuple(self._extra_js_flags)
+    assert isinstance(details_json["flags"], tuple)
+    details_json["flags"] += tuple(self._extra_flags)
+
+  def setup_selenium_options(self, options: ArgOptions):
+    # Using only the first run, since all runs need to have the same probes.
+    self.first_run.setup_selenium_options(options)
+
+  @property
+  def info_stack(self) -> TInfoStack:
+    return ("Merging results from multiple browser sessions",
+            f"browser={self.browser.unique_name}", f"session={self.index}")
+
+  @property
+  def info(self) -> JsonDict:
+    info_dict = super().info
+    info_dict.update({"index": self.index})
+    return info_dict
+
+  def __str__(self) -> str:
+    return f"Session({self.browser}, {self.index})"
+
+  @property
+  def browser_tmp_dir(self) -> AnyPath:
+    if not self._browser_tmp_dir:
+      prefix = f"cb_browser_session_{self.index}"
+      self._browser_tmp_dir = self.browser_platform.mkdtemp(prefix)
+    return self._browser_tmp_dir
+
+  def merge(self, probes: Iterable[Probe]) -> None:
+    # TODO: implement merging of session probes
+    pass
+
+  def _merge_probe_results(self, probe: Probe) -> ProbeResult:
+    return EmptyProbeResult()
+
+  @contextlib.contextmanager
+  def open(self, is_dry_run: bool = False) -> Iterator[bool]:
+    self._state.transition(State.READY, to=State.SETUP)
+    yielded = False
+    with self.exceptions.capture():
+      self._setup_session_dir()
+      self._setup_browser()
+      with ChangeCWD(self.path):
+        with self._open(is_dry_run):
+          yielded = True
+          yield self.is_success
+    # Contextmanager always needs to yield, even in the case of early
+    # exceptions, the caller is responsible for skipping the body.
+    if not yielded:
+      assert not self.is_success
+      yield False
+
+  @contextlib.contextmanager
+  def _open(self, is_dry_run: bool) -> Iterator[None]:
+    self._state.expect(State.SETUP)
+    with self.measure("browser-session-setup"):
+      self._setup(is_dry_run)
+    try:
+      with self._start_network(), self._start_probes(is_dry_run):
+        self._start(is_dry_run)
+        try:
+          self._state.expect(State.RUNNING)
+          yield
+        except Exception as e:
+          logging.debug(
+              "BrowserSessionRunGroup: got unexpected inner exception: %s", e)
+          raise e
+    finally:
+      self._teardown(is_dry_run)
+
+  def _setup(self, is_dry_run: bool) -> None:
+    self._state.expect(State.SETUP)
+    self._probe_context_manager.setup(self.probes, is_dry_run)
+    # TODO: handle session vs run probe.
+    for run in self.runs:
+      with self._exceptions.annotate(f"Setting up {run}"):
+        label = "RUN"
+        if run.is_warmup:
+          label = "WARMUP RUN"
+        logging.info("Preparing SESSION %s, %s %s", self.index, label,
+                     run.index)
+        run.setup(is_dry_run)
+
+  def _setup_browser(self) -> None:
+    self._state.expect(State.SETUP)
+    self.browser.setup_binary()
+
+  def _setup_session_dir(self) -> None:
+    self._state.expect(State.SETUP)
+    with self.measure("browser-session-setup-dir"):
+      self.path.mkdir(parents=True, exist_ok=True)
+      if not self._create_symlinks:
+        logging.debug("Symlink disabled by command line option")
+        return
+      if self.host_platform.is_win:
+        logging.debug("Skipping session_dir symlink on windows.")
+        return
+      if self.is_single_run:
+        # If there is a single run per session we reuse the run-dir.
+        self.raw_session_dir.parent.mkdir(parents=True, exist_ok=True)
+        self.raw_session_dir.symlink_to(self.path)
+
+  @contextlib.contextmanager
+  def _start_network(self):
+    logging.debug("Starting network: %s", self.network)
+    with self._exceptions.annotate(f"Starting Network: {self.network}"):
+      with self.network.open(self):
+        yield
+
+  @contextlib.contextmanager
+  def _start_probes(self, is_dry_run: bool):
+    with self._exceptions.annotate("Starting Session Probes"):
+      with self._probe_context_manager.open(is_dry_run):
+        yield
+
+  def _start(self, is_dry_run: bool) -> None:
+    self._state.transition(State.SETUP, to=State.STARTING)
+    with self.measure("browser-session-start"):
+      with self._exceptions.annotate(f"Starting Browser: {self.browser}"):
+        self._start_browser(is_dry_run)
+        self._state.transition(State.STARTING, to=State.RUNNING)
+
+  def _start_browser(self, is_dry_run: bool) -> None:
+    self._state.expect(State.STARTING)
+    assert self.network.is_running, "Network isn't running yet"
+    if is_dry_run:
+      logging.info("BROWSER: %s", self.browser.path)
+      return
+    assert self._probe_context_manager.is_running
+    browser_log_file = self.path / "browser.log"
+    assert not browser_log_file.exists(), (
+        f"Default browser log file {browser_log_file} already exists.")
+    self._browser.set_log_file(browser_log_file)
+
+    with self.measure("browser-setup"):
+      try:
+        # pytype somehow gets the package path wrong here, disabling for now.
+        self._browser.setup(self)
+      except Exception as e:
+        logging.debug("Browser setup failed: %s", e)
+        # Clean up half-setup browser instances
+        self._browser.force_quit()
+        raise
+
+  def _teardown(self, is_dry_run: bool) -> None:
+    self._state.transition(
+        State.SETUP, State.STARTING, State.RUNNING, to=State.STOPPING)
+    with self.measure("browser-session-teardown"):
+      try:
+        self._stop_browser(is_dry_run)
+      finally:
+        self._state.transition(State.STOPPING, to=State.DONE)
+    self._probe_context_manager.teardown(is_dry_run)
+
+  def _stop_browser(self, is_dry_run: bool) -> None:
+    self._state.expect(State.STOPPING)
+    # TODO: move complete implementation here
+    # This can happen if a browser / probe setup error occurs and we're
+    # in a unclean state.
+    if self.browser.is_running:
+      self._runs[-1]._teardown_browser(is_dry_run)  # pylint: disable=protected-access
+
+  # TODO: remove once cleanly implemented
+  def is_first_run(self, run: Run) -> bool:
+    return self.first_run is run
+
+  # TODO: remove once cleanly implemented
+  def is_last_run(self, run: Run) -> bool:
+    return self._runs[-1] is run
+
+
+class ProbeSessionContextManager(ProbeContextManager[BrowserSessionRunGroup,
+                                                     ProbeSessionContext]):
+
+  def __init__(self, session: BrowserSessionRunGroup,
+               probe_results: ProbeResultDict):
+    super().__init__(session, probe_results)
+
+  def get_probe_context(self, probe: Probe) -> Optional[ProbeSessionContext]:
+    return probe.get_session_context(self._origin)
diff --git a/crossbench/runner/groups/stories.py b/crossbench/runner/groups/stories.py
new file mode 100644
index 0000000..97b0a74
--- /dev/null
+++ b/crossbench/runner/groups/stories.py
@@ -0,0 +1,102 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Iterable, List, Optional, Tuple
+
+from crossbench import helper
+from crossbench.runner.groups.base import RunGroup
+
+if TYPE_CHECKING:
+  from crossbench import exception
+  from crossbench.browsers.browser import Browser
+  from crossbench.probes.probe import Probe
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.groups.cache_temperatures import \
+      CacheTemperaturesRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.stories.story import Story
+  from crossbench.types import JsonDict
+
+
+class StoriesRunGroup(RunGroup):
+  """
+  A group of RepetitionsRunGroup for the same browser.
+  """
+
+  def __init__(self, throw: bool = False) -> None:
+    super().__init__(throw)
+    self._repetitions_groups: List[RepetitionsRunGroup] = []
+    self._browser: Optional[Browser] = None
+
+  @classmethod
+  def groups(cls,
+             run_groups: Iterable[RepetitionsRunGroup],
+             throw: bool = False) -> Tuple[StoriesRunGroup, ...]:
+    return tuple(
+        helper.group_by(
+            run_groups,
+            key=lambda run_group: run_group.browser,
+            group=lambda _: cls(throw),
+            sort_key=None).values())
+
+  def append(self, group: RepetitionsRunGroup) -> None:
+    if self._path is None:
+      self._set_path(group.path.parent)
+      self._browser = group.browser
+    assert self._path == group.path.parent
+    assert self._browser == group.browser
+    self._repetitions_groups.append(group)
+
+  @property
+  def repetitions_groups(self) -> List[RepetitionsRunGroup]:
+    return self._repetitions_groups
+
+  @property
+  def cache_temperatures_groups(self) -> Iterable[CacheTemperaturesRunGroup]:
+    for group in self._repetitions_groups:
+      yield from group.cache_temperatures_groups
+
+  @property
+  def runs(self) -> Iterable[Run]:
+    for group in self._repetitions_groups:
+      yield from group.runs
+
+  @property
+  def browser(self) -> Browser:
+    assert self._browser
+    return self._browser
+
+  @property
+  def stories(self) -> Iterable[Story]:
+    return (group.story for group in self._repetitions_groups)
+
+  @property
+  def info_stack(self) -> exception.TInfoStack:
+    return (
+        "Merging results from multiple stories",
+        f"browser={self.browser.unique_name}",
+    )
+
+  @property
+  def info(self) -> JsonDict:
+    info = {
+        "label": self.browser.label,
+        "browser": self.browser.app_name.title(),
+        "version": self.browser.version,
+        "os": self.browser.platform.full_version,
+        "device": self.browser.platform.device,
+        "cpu": self.browser.platform.cpu,
+        "binary": str(self.browser.path),
+        "flags": str(self.browser.flags),
+        "runs": len(tuple(self.runs)),
+        "failed runs": len(tuple(self.failed_runs))
+    }
+    info.update(super().info)
+    return info
+
+  def _merge_probe_results(self, probe: Probe) -> ProbeResult:
+    return probe.merge_stories(self)
diff --git a/crossbench/runner/groups/thread.py b/crossbench/runner/groups/thread.py
new file mode 100644
index 0000000..aa9ff66
--- /dev/null
+++ b/crossbench/runner/groups/thread.py
@@ -0,0 +1,133 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+import threading
+from typing import TYPE_CHECKING, Iterable, Tuple
+
+from ordered_set import OrderedSet
+
+from crossbench import exception
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+  from crossbench.runner.run import Run
+  from crossbench.runner.runner import Runner
+
+
+class RunThreadGroup(threading.Thread):
+  """The main interface to start Runs.
+  - Typically only a single RunThreadGroup is used.
+  - If runs are executed in parallel, multiple RunThreadGroup are used
+  """
+
+  def __init__(self, runs: Iterable[Run], index=0, throw: bool = False) -> None:
+    super().__init__()
+    self._index = index
+    self._exceptions = exception.Annotator(throw)
+    self._runs = tuple(runs)
+    assert self._runs, "Got unexpected empty runs list"
+    self._runner: Runner = self._runs[0].runner
+    self._total_run_count = len(self._runner.runs)
+    self._browser_sessions: OrderedSet[BrowserSessionRunGroup] = OrderedSet(
+        run.browser_session for run in self._runs)
+    self.is_dry_run: bool = False
+    self._verify_contains_all_browser_session_runs()
+    self._verify_same_runner()
+    if not self._browser_sessions:
+      raise ValueError("No browser sessions / runs")
+
+  def _verify_contains_all_browser_session_runs(self) -> None:
+    runs_set = set(self._runs)
+    for browser_session in self._browser_sessions:
+      for session_run in browser_session.runs:
+        assert session_run in runs_set, (
+            f"BrowserSession {browser_session} is not allowed to have "
+            f"{session_run} in another RunThreadGroup.")
+
+  def _verify_same_runner(self) -> None:
+    for run in self._runs:
+      assert run.runner is self._runner, "All Runs must have the same Runner."
+
+  @property
+  def index(self) -> int:
+    return self._index
+
+  @property
+  def runner(self) -> Runner:
+    return self._runner
+
+  @property
+  def runs(self) -> Tuple[Run, ...]:
+    return tuple(self._runs)
+
+  @property
+  def browser_sessions(self) -> Tuple[BrowserSessionRunGroup, ...]:
+    return tuple(self._browser_sessions)
+
+  @property
+  def browsers(self) -> Iterable[Browser]:
+    for browser_session in self._browser_sessions:
+      yield browser_session.browser
+
+  @property
+  def exceptions(self) -> exception.Annotator:
+    return self._exceptions
+
+  @property
+  def is_success(self) -> bool:
+    return self._exceptions.is_success
+
+  def _log_run(self, run: Run):
+    logging.info("=" * 80)
+    label = ""
+    if run.is_warmup:
+      label = " | WARMUP, ignoring results"
+    logging.info("RUN %s/%s%s", run.index + 1, self._total_run_count, label)
+    logging.info("  %s", run.name)
+    logging.info("=" * 80)
+
+  def run(self) -> None:
+    for browser_session in self._browser_sessions:
+      self._run_browser_session(browser_session)
+      if not browser_session.is_success:
+        self._exceptions.extend(browser_session.exceptions)
+    self.runner.exceptions.extend(self._exceptions)
+
+  def _run_browser_session(self,
+                           browser_session: BrowserSessionRunGroup) -> None:
+    if browser_session.is_single_run:
+      self._log_run(browser_session.first_run)
+    else:
+      logging.info("=" * 80)
+    with browser_session.open() as is_success:
+      if not is_success:
+        self._handle_session_startup_failure(browser_session)
+      else:
+        for run in browser_session.runs:
+          self._run_browser_session_run(browser_session, run)
+
+  def _handle_session_startup_failure(
+      self, browser_session: BrowserSessionRunGroup) -> None:
+    runs = tuple(browser_session.runs)
+    logging.info("%s: Skipping %s runs due to browser session setup errors.",
+                 self, len(runs))
+    for run in runs:
+      run.exceptions.extend(browser_session.exceptions)
+
+  def _run_browser_session_run(self, browser_session: BrowserSessionRunGroup,
+                               run: Run) -> None:
+    if not browser_session.is_single_run:
+      self._log_run(run)
+    if not run.is_success:
+      logging.info("%s: Skipping %s due to setup errors.", self, run)
+    else:
+      run.run(self.is_dry_run)
+    if run.is_success:
+      run.log_results()
+    else:
+      browser_session.exceptions.extend(run.exceptions)
diff --git a/crossbench/runner/probe_context_manager.py b/crossbench/runner/probe_context_manager.py
new file mode 100644
index 0000000..67b2fa0
--- /dev/null
+++ b/crossbench/runner/probe_context_manager.py
@@ -0,0 +1,162 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+import datetime as dt
+import logging
+from typing import (TYPE_CHECKING, Dict, Generic, Iterable, List, Optional,
+                    Tuple, Type, TypeVar)
+
+from crossbench.helper.state import State, StateMachine
+from crossbench.probes.probe_context import BaseProbeContext, ProbeContext
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+from crossbench.runner.result_origin import ResultOrigin
+
+if TYPE_CHECKING:
+  from crossbench.probes.probe import Probe, ProbeT
+  from crossbench.probes.results import ProbeResultDict
+
+ResultOriginT = TypeVar("ResultOriginT", bound=ResultOrigin)
+ProbeContextT = TypeVar("ProbeContextT", bound=BaseProbeContext)
+
+
+class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
+
+  def __init__(self, result_origin: ResultOriginT,
+               probe_results: ProbeResultDict):
+    self._state = StateMachine(State.INITIAL)
+    self._origin = result_origin
+    self._probe_results = probe_results
+    self._probe_contexts: Dict[Type[Probe], ProbeContextT] = {}
+    # TODO: either prefix timers or use custom duration
+    self._durations = result_origin.durations
+    self._exceptions = result_origin.exceptions
+
+  @property
+  def is_ready(self) -> bool:
+    return self._state == State.READY
+
+  @property
+  def is_running(self) -> bool:
+    return self._state == State.RUN
+
+  def measure(self, name):
+    return self._origin.measure(name)
+
+  @contextlib.contextmanager
+  def capture(self, label: str, measure: bool = False):
+    with self._exceptions.capture(label):
+      if not measure:
+        yield
+      else:
+        with self._origin.durations.measure(label):
+          yield
+
+  @property
+  def is_success(self) -> bool:
+    return self._exceptions.is_success
+
+  def setup(self, probes: Iterable[Probe], is_dry_run: bool):
+    self._state.transition(State.INITIAL, to=State.SETUP)
+    if not is_dry_run:
+      if not self._setup_probes(tuple(probes), is_dry_run):
+        return
+    self._state.transition(State.SETUP, to=State.READY)
+
+  def _setup_probes(self, probes: Tuple[Probe, ...], is_dry_run: bool) -> bool:
+    with self.capture("probes-setup", measure=True):
+      self._validate_probes(probes)
+      self._create_contexts(probes)
+      self._setup_contexts()
+    if not self.is_success:
+      self._handle_setup_error(is_dry_run)
+    return self.is_success
+
+  def _validate_probes(self, probes: Tuple[Probe, ...]):
+    assert not self._probe_contexts, "Wrong probe context initialization order"
+    probe_set = set()
+    for probe in probes:
+      assert probe not in probe_set, (f"Got duplicate probe name={probe.name}")
+      probe_set.add(probe)
+      assert probe.is_attached, (
+          f"Probe {probe.name} is not properly attached to a browser")
+
+  def _create_contexts(self, probes: Tuple[Probe, ...]):
+    for probe in probes:
+      if probe.PRODUCES_DATA:
+        self._probe_results[probe] = EmptyProbeResult()
+      with self.capture(f"{probe.name} get_context"):
+        if probe_context := self.get_probe_context(probe):
+          probe_cls = type(probe)
+          assert probe_cls not in self._probe_contexts
+          self._probe_contexts[probe_cls] = probe_context
+
+  def _setup_contexts(self):
+    for probe_context in self._probe_contexts.values():
+      with self.capture(f"probes-setup {probe_context.name}"):
+        probe_context.setup()
+
+  def _handle_setup_error(self, is_dry_run: bool) -> None:
+    self._state.transition(State.SETUP, to=State.DONE)
+    logging.debug("Handling setup error")
+    assert not self.is_success
+    # Special handling for crucial runner probes
+    internal_probe_contexts = [
+        context for context in self._probe_contexts.values()
+        if context.probe.is_internal
+    ]
+    self._teardown(internal_probe_contexts, is_dry_run, setup_error=True)
+
+  @contextlib.contextmanager
+  def open(self, is_dry_run: bool):
+    self._state.transition(State.READY, to=State.RUN)
+    probe_start_time = dt.datetime.now()
+    combined_contexts = contextlib.ExitStack()
+
+    for probe_context in self._probe_contexts.values():
+      probe_context.set_start_time(probe_start_time)
+      if not is_dry_run:
+        combined_contexts.enter_context(probe_context.open())
+
+    with combined_contexts:
+      self._durations["probes-start"] = dt.datetime.now() - probe_start_time
+      yield self
+
+  def teardown(self, is_dry_run: bool, setup_error: bool = False) -> None:
+    self._state.transition(State.READY, State.RUN, to=State.DONE)
+    with self.measure("probes-teardown"):
+      self._teardown(
+          list(self._probe_contexts.values()), is_dry_run, setup_error)
+      self._probe_contexts = {}
+
+  def _teardown(self,
+                probe_contexts: List[ProbeContextT],
+                is_dry_run: bool,
+                setup_error: bool = False) -> None:
+    if setup_error:
+      assert self._probe_contexts, "Invalid state"
+    self._state.expect(State.DONE)
+    logging.debug("PROBE SCOPE TEARDOWN")
+    if is_dry_run:
+      return
+    for probe_context in reversed(probe_contexts):
+      with self.capture(f"Probe {probe_context.name} teardown", measure=True):
+        assert probe_context.result_origin == self._origin
+        probe_results: ProbeResult = probe_context.teardown()
+        probe = probe_context.probe
+        if probe_results.is_empty:
+          logging.warning("Probe did not extract any data. probe=%s in %s",
+                          probe, self._origin)
+        self._probe_results[probe] = probe_results
+
+  @abc.abstractmethod
+  def get_probe_context(self, probe: Probe) -> Optional[ProbeContextT]:
+    pass
+
+  def find_probe_context(self,
+                         cls: Type[ProbeT]) -> Optional[ProbeContext[ProbeT]]:
+    return self._probe_contexts.get(cls)
diff --git a/crossbench/runner/result_origin.py b/crossbench/runner/result_origin.py
new file mode 100644
index 0000000..698a1f4
--- /dev/null
+++ b/crossbench/runner/result_origin.py
@@ -0,0 +1,124 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+import logging
+from collections.abc import Generator
+from typing import TYPE_CHECKING, Iterable, Tuple
+
+from crossbench import plt
+from crossbench.helper import DurationMeasureContext, Durations
+from crossbench.probes.result_location import ResultLocation
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.exception import (Annotator, ExceptionAnnotationScope,
+                                    TExceptionTypes)
+  from crossbench.path import AnyPath, LocalPath
+  from crossbench.probes.probe import Probe
+  from crossbench.runner.runner import Runner
+
+
+class ResultOrigin(abc.ABC):
+  """Base class for Run and BrowserSession, both places where
+  probe results can be placed."""
+
+  @property
+  def is_local(self) -> bool:
+    return self.browser_platform.is_local
+
+  @property
+  def is_remote(self) -> bool:
+    return self.browser_platform.is_remote
+
+  @property
+  @abc.abstractmethod
+  def browser_tmp_dir(self) -> AnyPath:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def out_dir(self) -> LocalPath:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def exceptions(self) -> Annotator:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def durations(self) -> Durations:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def browser(self) -> Browser:
+    pass
+
+  @property
+  def runner(self) -> Runner:
+    raise NotImplementedError(
+        f"Cannot access on runner on {type(self).__name__}")
+
+  @property
+  def host_platform(self) -> plt.Platform:
+    return self.browser.host_platform
+
+  @property
+  def browser_platform(self) -> plt.Platform:
+    return self.browser.platform
+
+  @property
+  def probes(self) -> Iterable[Probe]:
+    # TODO: migrate away from using runner
+    return self.runner.probes
+
+  @contextlib.contextmanager
+  def measure(
+      self, label: str
+  ) -> Generator[Tuple[ExceptionAnnotationScope, DurationMeasureContext], None,
+                 None]:
+    # Return a combined context manager that adds an named exception info
+    # and measures the time during the with-scope.
+    with self.exceptions.info(label) as stack, self.durations.measure(
+        label) as timer:
+      yield (stack, timer)
+
+  def exception_info(self, *stack_entries: str) -> ExceptionAnnotationScope:
+    return self.exceptions.info(*stack_entries)
+
+  def exception_handler(
+      self, *stack_entries: str, exceptions: TExceptionTypes = (Exception,)
+  ) -> ExceptionAnnotationScope:
+    return self.exceptions.capture(*stack_entries, exceptions=exceptions)
+
+  def get_default_probe_result_path(self, probe: Probe) -> AnyPath:
+    """Return a local or remote/browser-based result path depending on the
+    Probe default RESULT_LOCATION."""
+    if probe.RESULT_LOCATION == ResultLocation.BROWSER:
+      return self.get_browser_probe_result_path(probe)
+    if probe.RESULT_LOCATION == ResultLocation.LOCAL:
+      return self.get_local_probe_result_path(probe)
+    raise ValueError(f"Invalid probe.RESULT_LOCATION {probe.RESULT_LOCATION} "
+                     f"for probe {probe}")
+
+  @abc.abstractmethod
+  def get_local_probe_result_path(self, probe: Probe) -> LocalPath:
+    pass
+
+  def get_browser_probe_result_path(self, probe: Probe) -> AnyPath:
+    local_path = self.get_local_probe_result_path(probe)
+    if self.is_local:
+      return local_path
+    # Create a temp file relative to the remote browser tmp dir.
+    relative_path = local_path.relative_to(self.out_dir)
+    path = self.browser_tmp_dir / relative_path
+    logging.debug("Creating remote result dir=%s on platform=%s", path.parent,
+                  self.browser_platform)
+    self.browser_platform.mkdir(path.parent)
+    return path
diff --git a/crossbench/runner/run.py b/crossbench/runner/run.py
new file mode 100644
index 0000000..7a82f8c
--- /dev/null
+++ b/crossbench/runner/run.py
@@ -0,0 +1,425 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import enum
+import logging
+from typing import TYPE_CHECKING, Optional, Type
+
+from crossbench import compat
+from crossbench import path as pth
+from crossbench.exception import Annotator, TInfoStack
+from crossbench.helper import ChangeCWD, Durations, Spinner
+from crossbench.helper.state import State, StateMachine
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.results import ProbeResultDict
+from crossbench.runner.actions import Actions
+from crossbench.runner.exception import StopStoryException
+from crossbench.runner.probe_context_manager import ProbeContextManager
+from crossbench.runner.result_origin import ResultOrigin
+from crossbench.runner.timing import Timing
+
+if TYPE_CHECKING:
+  from selenium.webdriver.common.options import ArgOptions
+
+  from crossbench.benchmarks.base import Benchmark
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.probes.probe import Probe, ProbeT
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+  from crossbench.runner.probe_context_manager import ProbeContextT
+  from crossbench.runner.runner import Runner
+  from crossbench.stories.story import Story
+  from crossbench.types import JsonDict
+
+
+@enum.unique
+class Temperature(compat.StrEnumWithHelp):
+  COLD = ("cold", "first run")
+  WARM = ("warm", "second run")
+  HOT = ("hot", "third run")
+
+
+class Run(ResultOrigin):
+
+  def __init__(self,
+               runner: Runner,
+               browser_session: BrowserSessionRunGroup,
+               story: Story,
+               repetition: int,
+               is_warmup: bool,
+               temperature: str,
+               index: int,
+               name: Optional[str] = None,
+               timeout: dt.timedelta = dt.timedelta(),
+               throw: bool = False):
+    self._state = StateMachine(State.INITIAL)
+    self._runner = runner
+    self._browser_session = browser_session
+    self._browser: Browser = browser_session.browser
+    browser_session.append(self)
+    self._story = story
+    assert repetition >= 0
+    self._repetition = repetition
+    self._is_warmup = is_warmup
+    assert temperature, "Missing cache-temperature value."
+    self._temperature = temperature
+    assert index >= 0
+    self._index = index
+    self._name = name
+    self._out_dir = self._get_out_dir().absolute()
+    self._probe_results = ProbeResultDict(self._out_dir)
+    self._durations = Durations()
+    self._start_datetime = dt.datetime.utcfromtimestamp(0)
+    self._timeout = timeout
+    self._exceptions = Annotator(throw)
+    self._browser_tmp_dir: Optional[pth.AnyPath] = None
+    self._probe_context_manager = ProbeRunContextManager(
+        self, self._probe_results)
+
+  def __str__(self) -> str:
+    return f"Run({self.name}, {self._state}, {self.browser})"
+
+  def _get_out_dir(self) -> pth.LocalPath:
+    return (self._browser_session.browser_dir / "stories" /
+            pth.safe_filename(self.story.name) / str(self.repetition_name) /
+            str(self._temperature))
+
+  @property
+  def group_dir(self) -> pth.LocalPath:
+    return self.out_dir.parent
+
+  def actions(self,
+              name: str,
+              verbose: bool = False,
+              measure: bool = True) -> Actions:
+    return Actions(name, self, verbose=verbose, measure=measure)
+
+  @property
+  def info_stack(self) -> TInfoStack:
+    return (
+        f"Run({self.name})",
+        (f"browser={self.browser.type_name} label={self.browser.label} "
+         f"binary={self.browser.path}"),
+        f"story={self.story}",
+        f"repetition={self.repetition_name}",
+    )
+
+  def details_json(self) -> JsonDict:
+    return {
+        "cwd": str(self.out_dir),
+        "name": self.name,
+        "story": self.story.details_json(),
+        "browser": self.get_browser_details_json(),
+        "run": {
+            "name": self.name,
+            "index": self.index,
+            "repetition": self.repetition,
+            "temperature": self.temperature,
+            "isWarmup": self.is_warmup,
+        },
+        "session": {
+            "index": self.browser_session.index,
+            "cwd": str(self.browser_session.path)
+        },
+        "probes": self.results.to_json(),
+        "timing": {
+            "startDateTime": str(self.start_datetime),
+            "duration": self.story.duration.total_seconds(),
+            "durations": self.durations.to_json(),
+            "timeout": self.timeout.total_seconds(),
+            "global": self.timing.to_json(),
+        },
+        "success": self.is_success,
+        "errors": self.exceptions.error_messages()
+    }
+
+  @property
+  def temperature(self) -> str:
+    return self._temperature
+
+  @property
+  def timing(self) -> Timing:
+    return self.runner.timing
+
+  @property
+  def durations(self) -> Durations:
+    return self._durations
+
+  @property
+  def start_datetime(self) -> dt.datetime:
+    return self._start_datetime
+
+  def max_end_datetime(self) -> dt.datetime:
+    if not self._timeout:
+      return dt.datetime.max
+    return self._start_datetime + self._timeout
+
+  @property
+  def timeout(self) -> dt.timedelta:
+    return self._timeout
+
+  @property
+  def repetition_name(self) -> str:
+    if self.is_warmup:
+      return f"warmup_{self.repetition}"
+    return str(self.repetition)
+
+  @property
+  def repetition(self) -> int:
+    return self._repetition
+
+  @property
+  def is_warmup(self) -> bool:
+    return self._is_warmup
+
+  @property
+  def index(self) -> int:
+    return self._index
+
+  @property
+  def runner(self) -> Runner:
+    return self._runner
+
+  @property
+  def benchmark(self) -> Benchmark:
+    return self._runner.benchmark
+
+  @property
+  def browser_session(self) -> BrowserSessionRunGroup:
+    return self._browser_session
+
+  @property
+  def browser(self) -> Browser:
+    return self._browser
+
+  @property
+  def environment(self) -> HostEnvironment:
+    # TODO: replace with custom BrowserEnvironment
+    return self.runner.env
+
+  @property
+  def out_dir(self) -> pth.LocalPath:
+    """A local directory where all result files are gathered.
+    Results from browsers on remote platforms are transferred to this dir
+    as well."""
+    return self._out_dir
+
+  @property
+  def browser_tmp_dir(self) -> pth.AnyPath:
+    """Returns a path to a tmp dir on the browser platform."""
+    if not self._browser_tmp_dir:
+      prefix = "cb_run_results"
+      self._browser_tmp_dir = self.browser_platform.mkdtemp(prefix)
+    return self._browser_tmp_dir
+
+  @property
+  def results(self) -> ProbeResultDict:
+    return self._probe_results
+
+  @property
+  def story(self) -> Story:
+    return self._story
+
+  @property
+  def name(self) -> Optional[str]:
+    return self._name
+
+  @property
+  def exceptions(self) -> Annotator:
+    return self._exceptions
+
+  @property
+  def is_success(self) -> bool:
+    return self._exceptions.is_success
+
+  @property
+  def session(self) -> BrowserSessionRunGroup:
+    return self._browser_session
+
+  def get_browser_details_json(self) -> JsonDict:
+    details_json = self.browser.details_json()
+    self.session.add_flag_details(details_json)
+    return details_json
+
+  def get_local_probe_result_path(self, probe: Probe) -> pth.LocalPath:
+    file = self._out_dir / probe.result_path_name
+    assert not file.exists(), f"Probe results file exists already. file={file}"
+    return file
+
+  def validate_env(self, env: HostEnvironment) -> None:
+    """Called before starting a browser / browser session to perform
+    a pre-run checklist."""
+
+  def setup(self, is_dry_run: bool) -> None:
+    self._state.transition(State.INITIAL, to=State.SETUP)
+    self._setup_dirs()
+    with ChangeCWD(self._out_dir), self.exception_info(*self.info_stack):
+      self._probe_context_manager.setup(self.probes, is_dry_run)
+    self._log_setup()
+
+  def setup_selenium_options(self, options: ArgOptions):
+    # TODO: move explicitly to session.
+    self._probe_context_manager.setup_selenium_options(options)
+
+  def _setup_dirs(self) -> None:
+    self._start_datetime = dt.datetime.now()
+    logging.debug("Creating Run(%s) out dir: %s", self, self._out_dir)
+    self._out_dir.mkdir(parents=True, exist_ok=True)
+    if not self.runner.create_symlinks:
+      logging.debug("Symlinks disabled by command line option")
+      return
+    self._create_runs_dir()
+    self._create_session_dir()
+
+  def _create_runs_dir(self) -> None:
+    browser_dir = self.browser_session.browser_dir
+    runs_dir = browser_dir / "runs"
+    runs_dir.mkdir(parents=True, exist_ok=True)
+    # Source: BROWSER / "runs" / RUN
+    # Target: BROWSER / "stories" / STORY / REPETITION / CACHE_TEMP
+    run_dir = runs_dir / str(self.index)
+    relative_out_dir = (
+        pth.LocalPath("../") / self.out_dir.relative_to(browser_dir))
+    run_dir.symlink_to(relative_out_dir, target_is_directory=True)
+
+  def _create_session_dir(self) -> None:
+    session_run_dir = self._out_dir / "session"
+    assert not session_run_dir.exists(), (
+        f"Cannot setup session dir twice: {session_run_dir}")
+    if self.host_platform.is_win:
+      logging.debug("Skipping session_dir symlink on windows.")
+      return
+    # Source: BROWSER / "stories" / STORY / REPETITION / CACHE_TEMP / "session"
+    # Target: BROWSER / "sessions" / SESSION
+    relative_session_dir = (
+        pth.LocalPath("../../../..") /
+        self.browser_session.path.relative_to(self.out_dir.parents[3]))
+    session_run_dir.symlink_to(relative_session_dir, target_is_directory=True)
+
+  def _log_setup(self) -> None:
+    logging.debug("SETUP")
+    logging.info(
+        "PROBES: %s",
+        ", ".join(probe.NAME for probe in self.probes if not probe.is_internal))
+    logging.debug("PROBES ALL: %s",
+                  ", ".join(probe.NAME for probe in self.probes))
+    self.story.log_run_details(self)
+    logging.info("RUN DIR: %s", self._out_dir)
+    logging.debug("CWD %s", self._out_dir)
+
+  def run(self, is_dry_run: bool) -> None:
+    self._state.transition(State.SETUP, to=State.READY)
+    self._start_datetime = dt.datetime.now()
+    with ChangeCWD(self._out_dir), self.exception_info(*self.info_stack):
+      assert self._probe_context_manager.is_ready
+      try:
+        self._run(is_dry_run)
+      except Exception as e:  # pylint: disable=broad-except
+        self._exceptions.append(e)
+      finally:
+        self.teardown(is_dry_run)
+
+  def _run(self, is_dry_run: bool) -> None:
+    self._state.transition(State.READY, to=State.RUN)
+    self.browser.splash_screen.run(self)
+    with self._probe_context_manager.open(is_dry_run):
+      logging.info("RUNNING STORY")
+      self._state.expect(State.RUN)
+      try:
+        with self.measure("run"), Spinner(), self.exceptions.capture():
+          if not is_dry_run:
+            self._run_story()
+      except TimeoutError as e:
+        # Handle TimeoutError earlier since they might be caused by
+        # throttled down non-foreground browser.
+        self._exceptions.append(e)
+      if self.is_success:
+        with self.exceptions.capture():
+          self.environment.check_browser_focused(self.browser)
+
+  def _run_story(self) -> None:
+    self._run_story_setup()
+    try:
+      self._story.run(self)
+    except StopStoryException as e:
+      logging.debug("Stop story: %s", e)
+    finally:
+      self._run_story_teardown()
+
+  def _run_story_setup(self) -> None:
+    with self.measure("story-setup"):
+      self._story.setup(self)
+    self._probe_context_manager.start_story()
+
+  def _run_story_teardown(self) -> None:
+    self._probe_context_manager.stop_story()
+    with self.measure("story-tear-down"):
+      self._story.teardown(self)
+
+  def teardown(self, is_dry_run: bool) -> None:
+    self._state.transition(State.RUN, to=State.DONE)
+    self._teardown_browser(is_dry_run)
+    self._probe_context_manager.teardown(is_dry_run)
+    if not is_dry_run:
+      self._rm_browser_tmp_dir()
+
+  def _teardown_browser(self, is_dry_run: bool) -> None:
+    if is_dry_run:
+      return
+    if not self.browser_session.is_last_run(self):
+      logging.debug("Skipping browser teardown (not last in session): %s", self)
+      return
+    if self._browser.is_running is False:
+      logging.warning("Browser is no longer running (crashed or closed).")
+      return
+    with self.measure("browser-teardown"), self._exceptions.capture(
+        "Quit browser"):
+      try:
+        self._browser.quit()
+      except Exception as e:  # pylint: disable=broad-except
+        logging.warning("Error quitting browser: %s", e)
+        return
+
+  def _rm_browser_tmp_dir(self) -> None:
+    if not self._browser_tmp_dir:
+      return
+    self.browser_platform.rm(self._browser_tmp_dir, dir=True)
+
+  def log_results(self) -> None:
+    for probe in self.probes:
+      probe.log_run_result(self)
+
+  def find_probe_context(self,
+                         cls: Type[ProbeT]) -> Optional[ProbeContext[ProbeT]]:
+    return self._probe_context_manager.find_probe_context(cls)
+
+
+class ProbeRunContextManager(ProbeContextManager[Run, ProbeContext]):
+
+  def __init__(self, run: Run, probe_results: ProbeResultDict):
+    super().__init__(run, probe_results)
+
+  def get_probe_context(self, probe: Probe) -> Optional[ProbeContext]:
+    return probe.get_context(self._origin)
+
+  def setup_selenium_options(self, options: ArgOptions):
+    for probe_context in self._probe_contexts.values():
+      probe_context.setup_selenium_options(options)
+
+  def start_story(self) -> None:
+    with self.measure("probes-start_story_run"):
+      for probe_context in self._probe_contexts.values():
+        with self._origin.exception_handler(
+            f"Probe {probe_context.name} start_story_run"):
+          probe_context.start_story_run()
+
+  def stop_story(self) -> None:
+    with self.measure("probes-stop_story_run"):
+      for probe_context in self._probe_contexts.values():
+        with self._origin.exception_handler(
+            f"Probe {probe_context.name} stop_story_run"):
+          probe_context.stop_story_run()
diff --git a/crossbench/runner/runner.py b/crossbench/runner/runner.py
new file mode 100644
index 0000000..01e1d38
--- /dev/null
+++ b/crossbench/runner/runner.py
@@ -0,0 +1,598 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import enum
+import inspect
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Optional,
+                    Sequence, Set, Tuple, Type, Union)
+
+from crossbench import compat, exception, helper
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.benchmarks.base import BenchmarkProbeMixin
+from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
+                            ValidationMode)
+from crossbench.helper.state import BaseState, StateMachine
+from crossbench.parse import NumberParser, ObjectParser
+from crossbench.probes import all as all_probes
+from crossbench.probes.internal import ResultsSummaryProbe
+from crossbench.probes.perfetto.trace_processor.trace_processor import \
+    TraceProcessorProbe
+from crossbench.probes.probe import Probe, ProbeIncompatibleBrowser
+from crossbench.probes.thermal_monitor import ThermalStatus
+from crossbench.runner.groups.browsers import BrowsersRunGroup
+from crossbench.runner.groups.cache_temperatures import \
+    CacheTemperaturesRunGroup
+from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+from crossbench.runner.groups.session import BrowserSessionRunGroup
+from crossbench.runner.groups.stories import StoriesRunGroup
+from crossbench.runner.groups.thread import RunThreadGroup
+from crossbench.runner.run import Run
+from crossbench.runner.timing import Timing
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import Benchmark
+  from crossbench.browsers.browser import Browser
+  from crossbench.stories.story import Story
+
+
+
+class RunnerException(exception.MultiException):
+  pass
+
+
+@enum.unique
+class ThreadMode(compat.StrEnumWithHelp):
+  NONE = ("none", (
+      "Execute all browser-sessions sequentially, default. "
+      "Low interference risk, use for worry-free time-critical measurements."))
+  PLATFORM = ("platform", (
+      "Execute browser-sessions from each platform in parallel threads. "
+      "Might cause some interference with probes that do heavy "
+      "post-processing."))
+  BROWSER = ("browser", (
+      "Execute browser-sessions from each browser in parallel thread. "
+      "High interference risk, don't use for time-critical measurements."))
+  SESSION = ("session", (
+      "Execute run from each browser-session in a parallel thread. "
+      "High interference risk, don't use for time-critical measurements."))
+
+  def group(self, runs: List[Run]) -> List[RunThreadGroup]:
+    if self == ThreadMode.NONE:
+      return [RunThreadGroup(runs)]
+    groups: Dict[Any, List[Run]] = {}
+    if self == ThreadMode.SESSION:
+      groups = helper.group_by(
+          runs, lambda run: run.browser_session, sort_key=None)
+    elif self == ThreadMode.PLATFORM:
+      groups = helper.group_by(
+          runs, lambda run: run.browser_platform, sort_key=None)
+    elif self == ThreadMode.BROWSER:
+      groups = helper.group_by(runs, lambda run: run.browser, sort_key=None)
+    else:
+      raise ValueError(f"Unexpected thread mode: {self}")
+    return [
+        RunThreadGroup(runs, index=index)
+        for index, runs in enumerate(groups.values())
+    ]
+
+
+@enum.unique
+class RunnerState(BaseState):
+  INITIAL = enum.auto()
+  SETUP = enum.auto()
+  RUNNING = enum.auto()
+  TEARDOWN = enum.auto()
+
+class Runner:
+
+  @classmethod
+  def get_out_dir(cls,
+                  cwd: pth.LocalPath,
+                  suffix: str = "",
+                  test: bool = False) -> pth.LocalPath:
+    if test:
+      return cwd / "results" / "test"
+    if suffix:
+      suffix = "_" + suffix
+    return (cwd / "results" /
+            f"{dt.datetime.now().strftime('%Y-%m-%d_%H%M%S')}{suffix}")
+
+  @classmethod
+  def add_cli_parser(
+      cls, benchmark_cls: Type[Benchmark],
+      parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser.add_argument(
+        "--repetitions",
+        "--repeat",
+        "--invocations",
+        "-r",
+        default=benchmark_cls.DEFAULT_REPETITIONS,
+        type=NumberParser.positive_int,
+        help=("Number of times each benchmark story is repeated. "
+              f"Defaults to {benchmark_cls.DEFAULT_REPETITIONS}. "
+              "Metrics are aggregated over multiple repetitions"))
+    parser.add_argument(
+        "--warmup-repetitions",
+        "--warmups",
+        default=0,
+        type=NumberParser.positive_zero_int,
+        help=("Number of times each benchmark story is repeated for warmup. "
+              "Defaults to 0. "
+              "Metrics for warmup-repetitions are discarded."))
+    parser.add_argument(
+        "--cache-temperatures",
+        default=["default"],
+        const=["cold", "warm", "hot"],
+        action="store_const",
+        help=("Repeat each run with different cache temperatures without "
+              "closing the browser in between."))
+
+    parser.add_argument(
+        "--thread-mode",
+        "--parallel",
+        default=ThreadMode.NONE,
+        type=ThreadMode,
+        help=("Change how Runs are executed.\n" +
+              ThreadMode.help_text(indent=2)))
+
+    out_dir_group = parser.add_argument_group("Output Directory Options")
+    out_dir_group.add_argument(
+        "--no-symlinks",
+        "--nosymlinks",
+        dest="create_symlinks",
+        action="store_false",
+        default=True,
+        help="Do not create symlinks in the output directory.")
+
+    out_dir_xor_group = out_dir_group.add_mutually_exclusive_group()
+    out_dir_xor_group.add_argument(
+        "--out-dir",
+        "--output-directory",
+        "-o",
+        type=pth.LocalPath,
+        help=("Results will be stored in this directory. "
+              "Defaults to results/${DATE}_${LABEL}"))
+    out_dir_xor_group.add_argument(
+        "--label",
+        "--name",
+        type=ObjectParser.non_empty_str,
+        default=benchmark_cls.NAME,
+        help=("Add a name to the default output directory. "
+              "Defaults to the benchmark name"))
+    return parser
+
+  @classmethod
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    if args.out_dir:
+      out_dir = args.out_dir
+    else:
+      label = args.label
+      assert label
+      root_dir = pth.LocalPath(__file__).parents[2]
+      out_dir = cls.get_out_dir(root_dir, label)
+    return {
+        "out_dir": out_dir,
+        "browsers": args.browser,
+        "repetitions": args.repetitions,
+        "warmup_repetitions": args.warmup_repetitions,
+        "cache_temperatures": args.cache_temperatures,
+        "thread_mode": args.thread_mode,
+        "throw": args.throw,
+        "create_symlinks": args.create_symlinks,
+        "cool_down_threshold": args.cool_down_threshold,
+    }
+
+  def __init__(self,
+               out_dir: pth.LocalPath,
+               browsers: Sequence[Browser],
+               benchmark: Benchmark,
+               additional_probes: Iterable[Probe] = (),
+               platform: plt.Platform = plt.PLATFORM,
+               env_config: Optional[HostEnvironmentConfig] = None,
+               env_validation_mode: ValidationMode = ValidationMode.THROW,
+               repetitions: int = 1,
+               warmup_repetitions: int = 0,
+               cache_temperatures: Iterable[str] = ("default",),
+               timing: Timing = Timing(),
+               cool_down_threshold: Optional[ThermalStatus] = None,
+               thread_mode: ThreadMode = ThreadMode.NONE,
+               throw: bool = False,
+               create_symlinks: bool = True):
+    self._state = StateMachine(RunnerState.INITIAL)
+    self.out_dir = out_dir.absolute()
+    assert not self.out_dir.exists(), f"out_dir={self.out_dir} exists already"
+    self.out_dir.mkdir(parents=True)
+    self._timing = timing
+    self._cool_down_threshold: Optional[ThermalStatus] = cool_down_threshold
+    self._browsers: Tuple[Browser, ...] = tuple(browsers)
+    self._validate_browser_labels()
+    self._benchmark = benchmark
+    self._stories = tuple(benchmark.stories)
+    self._repetitions = NumberParser.positive_int(repetitions, "repetitions")
+    self._warmup_repetitions = NumberParser.positive_zero_int(
+        warmup_repetitions, "warmup repetitions")
+    self._cache_temperatures: Tuple[str, ...] = tuple(cache_temperatures)
+    self._probes: List[Probe] = []
+    self._default_probes: List[Probe] = []
+    # Contains both measure and warmup runs:
+    self._all_runs: List[Run] = []
+    self._measured_runs: List[Run] = []
+    self._thread_mode = thread_mode
+    self._exceptions = exception.Annotator(throw)
+    self._platform = platform
+    self._env = HostEnvironment(self.platform, self.out_dir, self.browsers,
+                                self.probes, self.repetitions, env_config,
+                                env_validation_mode)
+    self._attach_default_probes(additional_probes)
+    self._prepare_benchmark()
+    self._cache_temperatures_groups: Tuple[CacheTemperaturesRunGroup, ...] = ()
+    self._repetitions_groups: Tuple[RepetitionsRunGroup, ...] = ()
+    self._story_groups: Tuple[StoriesRunGroup, ...] = ()
+    self._browser_group: Optional[BrowsersRunGroup] = None
+    self._create_symlinks: bool = create_symlinks
+
+  def _prepare_benchmark(self) -> None:
+    benchmark_probe_cls: Type[BenchmarkProbeMixin]
+    for benchmark_probe_cls in self._benchmark.PROBES:
+      assert inspect.isclass(benchmark_probe_cls), (
+          f"{self._benchmark}.PROBES must contain classes only, "
+          f"but got {type(benchmark_probe_cls)}")
+      assert issubclass(
+          benchmark_probe_cls,
+          Probe), (f"Expected Probe class but got {type(benchmark_probe_cls)}")
+      assert issubclass(benchmark_probe_cls, BenchmarkProbeMixin), (
+          f"{benchmark_probe_cls} should be BenchmarkProbeMixin "
+          f"for {type(self._benchmark)}.PROBES")
+      assert benchmark_probe_cls.NAME, (
+          f"Expected probe.NAME for {benchmark_probe_cls}")
+      self.attach_probe(benchmark_probe_cls(benchmark=self._benchmark))
+
+  def _validate_browser_labels(self) -> None:
+    assert self.browsers, "No browsers provided"
+    browser_unique_names = [browser.unique_name for browser in self.browsers]
+    ObjectParser.unique_sequence(browser_unique_names, "browser names")
+
+  def _attach_default_probes(self, probe_list: Iterable[Probe]) -> None:
+    assert len(self._probes) == 0
+    assert len(self._default_probes) == 0
+    for probe_cls in all_probes.INTERNAL_PROBES:
+      if probe_cls == all_probes.ThermalMonitorProbe:
+        thermal_monitor_probe = all_probes.ThermalMonitorProbe(
+            cool_down_time=self._timing.cool_down_time,
+            threshold=self._cool_down_threshold)
+        self._attach_default_probe(thermal_monitor_probe)
+      else:
+        default_probe: Probe = probe_cls()  # pytype: disable=not-instantiable
+        self._attach_default_probe(default_probe)
+
+    for index, probe in enumerate(probe_list):
+      assert (not isinstance(probe, TraceProcessorProbe) or index == 0), (
+          f"TraceProcessorProbe must be first in the list to be able "
+          f"to process other probes data. Found it at index: {index}")
+      self.attach_probe(probe)
+    # Results probe must be first in the list, and thus last to be processed
+    # so all other probes have data by the time we write the results summary.
+    assert isinstance(self._probes[0], ResultsSummaryProbe)
+
+  def _attach_default_probe(self, probe: Probe) -> None:
+    self.attach_probe(probe)
+    self._default_probes.append(probe)
+
+  def attach_probe(self,
+                   probe: Probe,
+                   matching_browser_only: bool = False) -> Probe:
+    if probe in self._probes:
+      raise ValueError(f"Cannot add the same probe twice: {probe.NAME}")
+    probe_was_used = False
+    for browser in self.browsers:
+      try:
+        probe.validate_browser(self.env, browser)
+        browser.attach_probe(probe)
+        probe_was_used = True
+      except ProbeIncompatibleBrowser as e:
+        if matching_browser_only:
+          logging.error("Skipping incompatible probe=%s for browser=%s:",
+                        probe.name, browser.unique_name)
+          logging.error("    %s", e)
+          continue
+        raise
+    if probe_was_used:
+      self._probes.append(probe)
+    return probe
+
+  @property
+  def timing(self) -> Timing:
+    return self._timing
+
+  @property
+  def cache_temperatures(self) -> Tuple[str, ...]:
+    return self._cache_temperatures
+
+  @property
+  def browsers(self) -> Tuple[Browser, ...]:
+    return self._browsers
+
+  @property
+  def stories(self) -> Tuple[Story, ...]:
+    return self._stories
+
+  @property
+  def probes(self) -> Iterable[Probe]:
+    return iter(self._probes)
+
+  @property
+  def default_probes(self) -> Iterable[Probe]:
+    return iter(self._default_probes)
+
+  @property
+  def benchmark(self) -> Benchmark:
+    return self._benchmark
+
+  @property
+  def repetitions(self) -> int:
+    return self._repetitions
+
+  @property
+  def warmup_repetitions(self) -> int:
+    return self._warmup_repetitions
+
+  @property
+  def create_symlinks(self) -> bool:
+    return self._create_symlinks
+
+  @property
+  def exceptions(self) -> exception.Annotator:
+    return self._exceptions
+
+  @property
+  def is_success(self) -> bool:
+    return len(self._measured_runs) > 0 and self._exceptions.is_success
+
+  @property
+  def platform(self) -> plt.Platform:
+    return self._platform
+
+  @property
+  def env(self) -> HostEnvironment:
+    return self._env
+
+  @property
+  def platforms(self) -> Set[plt.Platform]:
+    return set(browser.platform for browser in self.browsers)
+
+  @property
+  def all_runs(self) -> Tuple[Run, ...]:
+    return tuple(self._all_runs)
+
+  @property
+  def runs(self) -> Tuple[Run, ...]:
+    return tuple(self._measured_runs)
+
+  @property
+  def cache_temperatures_groups(self) -> Tuple[CacheTemperaturesRunGroup, ...]:
+    assert self._cache_temperatures_groups, (
+        f"No CacheTemperatureRunGroup in {self}")
+    return self._cache_temperatures_groups
+
+  @property
+  def repetitions_groups(self) -> Tuple[RepetitionsRunGroup, ...]:
+    assert self._repetitions_groups, f"No RepetitionsRunGroup in {self}"
+    return self._repetitions_groups
+
+  @property
+  def story_groups(self) -> Tuple[StoriesRunGroup, ...]:
+    assert self._story_groups, f"No StoriesRunGroup in {self}"
+    return self._story_groups
+
+  @property
+  def browser_group(self) -> BrowsersRunGroup:
+    assert self._browser_group, f"No BrowsersRunGroup in {self}"
+    return self._browser_group
+
+  @property
+  def has_browser_group(self) -> bool:
+    return self._browser_group is not None
+
+  def wait(self,
+           time: Union[int, float, dt.timedelta],
+           absolute_time: bool = False) -> None:
+    if not time:
+      return
+    if not absolute_time:
+      delta = self.timing.timedelta(time)
+    else:
+      if isinstance(time, (int, float)):
+        delta = dt.timedelta(seconds=time)
+      else:
+        delta = time
+    self._platform.sleep(delta)
+
+  def run(self, is_dry_run: bool = False) -> None:
+    self._state.expect(RunnerState.INITIAL)
+    with helper.SystemSleepPreventer():
+      with self._exceptions.annotate("Preparing"):
+        self._setup()
+      with self._exceptions.annotate("Running"):
+        self._run(is_dry_run)
+
+    if self._exceptions.throw:
+      # Ensure that we bail out on the first exception.
+      self.assert_successful_sessions_and_runs()
+    if not is_dry_run:
+      self._teardown()
+    self.assert_successful_sessions_and_runs()
+
+  def _setup(self) -> None:
+    self._state.transition(RunnerState.INITIAL, to=RunnerState.SETUP)
+    logging.info("-" * 80)
+    logging.info("SETUP")
+    logging.info("-" * 80)
+    assert self.repetitions > 0, (
+        f"Invalid repetitions count: {self.repetitions}")
+    assert self.browsers, "No browsers provided: self.browsers is empty"
+    assert self.stories, "No stories provided: self.stories is empty"
+    self._validate_browsers()
+    self._exceptions.assert_success()
+    with self._exceptions.annotate("Preparing Runs"):
+      self._all_runs = list(self.get_runs())
+      assert self._all_runs, f"{type(self)}.get_runs() produced no runs"
+      logging.info("DISCOVERED %d RUN(S)", len(self._all_runs))
+      self._measured_runs = [run for run in self._all_runs if not run.is_warmup]
+    with self._exceptions.capture("Preparing Environment"):
+      self._env.setup()
+    with self._exceptions.annotate(
+        f"Preparing Benchmark: {self._benchmark.NAME}"):
+      self._benchmark.setup(self)
+
+  def _validate_browsers(self) -> None:
+    logging.info("PREPARING %d BROWSER(S)", len(self.browsers))
+    for browser in self.browsers:
+      with self._exceptions.capture(
+          f"Preparing browser type={browser.type_name} "
+          f"unique_name={browser.unique_name}"):
+        self._validate_browser(browser)
+
+  def _validate_browser(self, browser: Browser) -> None:
+    browser.validate_binary()
+    for probe in browser.probes:
+      assert probe in self._probes, (
+          f"Browser {browser} probe {probe} not in Runner.probes. "
+          "Use Runner.attach_probe()")
+
+  def has_any_live_network(self) -> bool:
+    return any(browser.network.is_live for browser in self.browsers)
+
+  def has_all_live_network(self) -> bool:
+    return all(browser.network.is_live for browser in self.browsers)
+
+  def get_runs(self) -> Iterable[Run]:
+    index = 0
+    session_index = 0
+    throw = self._exceptions.throw
+    total_repetitions = self.repetitions + self.warmup_repetitions
+    for repetition in range(total_repetitions):
+      is_warmup: bool = repetition < self.warmup_repetitions
+      for story in self.stories:
+        for browser in self.browsers:
+          # TODO: implement browser-session start/stop
+          extra_benchmark_flags = self.benchmark.extra_flags(browser.attributes)
+          browser_session = BrowserSessionRunGroup(self.env, self.probes,
+                                                   browser,
+                                                   extra_benchmark_flags,
+                                                   session_index, self.out_dir,
+                                                   self.create_symlinks, throw)
+          session_index += 1
+          for t_index, temperature in enumerate(self.cache_temperatures):
+            name_parts = [f"story={story.name}"]
+            if total_repetitions > 1:
+              name_parts.append(f"repetition={repetition}")
+            if len(self.cache_temperatures) > 1:
+              name_parts.append(f"temperature={temperature_icon(temperature)}")
+            name_parts.append(f"index={index}")
+            yield self.create_run(
+                browser_session,
+                story,
+                repetition,
+                is_warmup,
+                f"{t_index}_{temperature}",
+                index,
+                name=", ".join(name_parts),
+                timeout=self.timing.run_timeout,
+                throw=throw)
+            index += 1
+          browser_session.set_ready()
+
+  def create_run(self, browser_session: BrowserSessionRunGroup, story: Story,
+                 repetition: int, is_warmup: bool, temperature: str, index: int,
+                 name: str, timeout: dt.timedelta, throw: bool) -> Run:
+    return Run(self, browser_session, story, repetition, is_warmup, temperature,
+               index, name, timeout, throw)
+
+  def assert_successful_sessions_and_runs(self) -> None:
+    failed_runs = list(run for run in self.runs if not run.is_success)
+    self._exceptions.assert_success(
+        f"Runs Failed: {len(failed_runs)}/{len(tuple(self.runs))} runs failed.",
+        RunnerException)
+
+  def _get_thread_groups(self) -> List[RunThreadGroup]:
+    # Also include warmup runs here.
+    return self._thread_mode.group(self._all_runs)
+
+  def _run(self, is_dry_run: bool = False) -> None:
+    self._state.transition(RunnerState.SETUP, to=RunnerState.RUNNING)
+    thread_groups: List[RunThreadGroup] = []
+    with self._exceptions.info("Creating thread groups for all Runs"):
+      thread_groups = self._get_thread_groups()
+
+    group_count = len(thread_groups)
+    if group_count == 1:
+      self._run_single_threaded(thread_groups[0])
+      return
+
+    with self._exceptions.annotate(f"Starting {group_count} thread groups."):
+      for thread_group in thread_groups:
+        thread_group.is_dry_run = is_dry_run
+        thread_group.start()
+    with self._exceptions.annotate(
+        "Waiting for all thread groups to complete."):
+      for thread_group in thread_groups:
+        thread_group.join()
+
+  def _run_single_threaded(self, thread_group: RunThreadGroup) -> None:
+    # Special case single thread groups
+    with self._exceptions.annotate("Running single thread group"):
+      thread_group.run()
+
+  def _teardown(self) -> None:
+    self._state.transition(RunnerState.RUNNING, to=RunnerState.TEARDOWN)
+    logging.info("=" * 80)
+    logging.info("RUNS COMPLETED")
+    logging.info("-" * 80)
+    logging.info("MERGING PROBE DATA")
+
+    throw = self._exceptions.throw
+
+    logging.debug("MERGING PROBE DATA: cache temperatures")
+    self._cache_temperatures_groups = CacheTemperaturesRunGroup.groups(
+        self._measured_runs, throw)
+    for cache_temp_group in self._cache_temperatures_groups:
+      cache_temp_group.merge(self.probes)
+      self._exceptions.extend(cache_temp_group.exceptions, is_nested=True)
+
+    logging.debug("MERGING PROBE DATA: repetitions")
+    self._repetitions_groups = RepetitionsRunGroup.groups(
+        self._cache_temperatures_groups, throw)
+    for repetition_group in self._repetitions_groups:
+      repetition_group.merge(self.probes)
+      self._exceptions.extend(repetition_group.exceptions, is_nested=True)
+
+    logging.debug("MERGING PROBE DATA: stories")
+    self._story_groups = StoriesRunGroup.groups(self._repetitions_groups, throw)
+    for story_group in self._story_groups:
+      story_group.merge(self.probes)
+      self._exceptions.extend(story_group.exceptions, is_nested=True)
+
+    logging.debug("MERGING PROBE DATA: browsers")
+    self._browser_group = BrowsersRunGroup(self._story_groups, throw)
+    self._browser_group.merge(self.probes)
+    self._exceptions.extend(self._browser_group.exceptions, is_nested=True)
+
+
+TEMPERATURE_ICONS = {
+    "cold": "",
+    "warm": "",
+    "hot": "",
+}
+
+
+def temperature_icon(temperature: str) -> str:
+  if icon := TEMPERATURE_ICONS.get(temperature):
+    return icon
+  return temperature
diff --git a/crossbench/runner/timing.py b/crossbench/runner/timing.py
new file mode 100644
index 0000000..f1239ba
--- /dev/null
+++ b/crossbench/runner/timing.py
@@ -0,0 +1,93 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+import datetime as dt
+from typing import Dict, Union
+
+# Arbitrary very large number that doesn't break any browser driver protocol.
+# chromedriver likely uses an uint32 ms internally, 2**30ms == 12days.
+SAFE_MAX_TIMEOUT_TIMEDELTA = dt.timedelta(milliseconds=2**30)
+
+
+@dataclasses.dataclass(frozen=True)
+class Timing:
+  cool_down_time: dt.timedelta = dt.timedelta(seconds=1)
+  # General purpose time unit.
+  unit: dt.timedelta = dt.timedelta(seconds=1)
+  # Used for upper bound / timeout limits independently.
+  timeout_unit: dt.timedelta = dt.timedelta()
+  run_timeout: dt.timedelta = dt.timedelta()
+  # Wait time after starting the browser and before running a workload.
+  start_delay: dt.timedelta = dt.timedelta()
+  # Wait time after running a workload and before stopping a browser.
+  stop_delay: dt.timedelta = dt.timedelta()
+
+  def __post_init__(self) -> None:
+    if self.cool_down_time.total_seconds() < 0:
+      raise ValueError(
+          f"Timing.cool_down_time must be >= 0, but got: {self.cool_down_time}")
+    if self.unit.total_seconds() <= 0:
+      raise ValueError(f"Timing.unit must be > 0, but got {self.unit}")
+    if self.timeout_unit:
+      if self.timeout_unit.total_seconds() <= 0:
+        raise ValueError(
+            f"Timing.timeout_unit must be > 0, but got {self.timeout_unit}")
+      if self.timeout_unit < self.unit:
+        raise ValueError(f"Timing.unit must be <= Timing.timeout_unit: "
+                         f"{self.unit} vs. {self.timeout_unit}")
+    if self.run_timeout.total_seconds() < 0:
+      raise ValueError(
+          f"Timing.run_timeout, must be >= 0, but got {self.run_timeout}")
+
+  def units(self, time: Union[float, int, dt.timedelta]) -> float:
+    if isinstance(time, dt.timedelta):
+      seconds = time.total_seconds()
+    else:
+      seconds = time
+    if seconds < 0:
+      raise ValueError(f"Unexpected negative time: {seconds}s")
+    return seconds / self.unit.total_seconds()
+
+  def _convert_to_seconds(
+      self, time_units: Union[float, int, dt.timedelta]) -> Union[float, int]:
+    if isinstance(time_units, dt.timedelta):
+      seconds = time_units.total_seconds()
+    else:
+      seconds = time_units
+    assert isinstance(seconds, (float, int))
+    if seconds < 0:
+      raise ValueError(f"Time-units must be >= 0, but got {seconds}")
+    return seconds
+
+  def timedelta(self, time_units: Union[float, int,
+                                        dt.timedelta]) -> dt.timedelta:
+    seconds_f = self._convert_to_seconds(time_units)
+    return self._to_safe_range(seconds_f * self.unit)
+
+  def timeout_timedelta(
+      self, time_units: Union[float, int, dt.timedelta]) -> dt.timedelta:
+    if self.has_no_timeout:
+      return SAFE_MAX_TIMEOUT_TIMEDELTA
+    seconds_f = self._convert_to_seconds(time_units)
+    return self._to_safe_range(seconds_f * (self.timeout_unit or self.unit))
+
+  def _to_safe_range(self, result: dt.timedelta) -> dt.timedelta:
+    if result > SAFE_MAX_TIMEOUT_TIMEDELTA:
+      return SAFE_MAX_TIMEOUT_TIMEDELTA
+    return result
+
+  @property
+  def has_no_timeout(self) -> bool:
+    return self.timeout_unit == dt.timedelta.max
+
+  def to_json(self) -> Dict[str, float]:
+    return {
+        "coolDownTime": self.cool_down_time.total_seconds(),
+        "unit": self.unit.total_seconds(),
+        "timeoutUnit": self.timeout_unit.total_seconds(),
+        "runTimeout": self.run_timeout.total_seconds(),
+    }
diff --git a/crossbench/scripts.py b/crossbench/scripts.py
new file mode 100644
index 0000000..dfc3cae
--- /dev/null
+++ b/crossbench/scripts.py
@@ -0,0 +1,22 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import sys
+
+from crossbench.cli.btp import BTPUtil
+from crossbench.cli.cli import CrossBenchCLI
+
+
+def crossbench(argv=None) -> None:
+  if not argv:
+    argv = sys.argv
+  cli = CrossBenchCLI()
+  cli.run(argv[1:])
+
+
+def cb_btp(argv=None) -> None:
+  if not argv:
+    argv = sys.argv
+  btp = BTPUtil()
+  btp.run(argv[1:])
diff --git a/crossbench/stories/__init__.py b/crossbench/stories/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/crossbench/stories/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/stories/press_benchmark.py b/crossbench/stories/press_benchmark.py
new file mode 100644
index 0000000..cc4a862
--- /dev/null
+++ b/crossbench/stories/press_benchmark.py
@@ -0,0 +1,179 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import logging
+from typing import List, Optional, Sequence, Tuple, Type, TypeVar
+
+from crossbench.parse import ObjectParser
+from crossbench.runner.run import Run
+from crossbench.stories.story import Story
+
+PressBenchmarkStoryT = TypeVar(
+    "PressBenchmarkStoryT", bound="PressBenchmarkStory")
+
+
+class PressBenchmarkStory(Story, metaclass=abc.ABCMeta):
+  NAME: str = ""
+  URL: str = ""
+  URL_OFFICIAL: str = ""
+  URL_LOCAL: str = ""
+  SUBSTORIES: Tuple[str, ...] = ()
+
+  @classmethod
+  def all_story_names(cls) -> Tuple[str, ...]:
+    assert cls.SUBSTORIES
+    return cls.SUBSTORIES
+
+  @classmethod
+  def default_story_names(cls) -> Tuple[str, ...]:
+    """Override this method to use a subset of all_story_names as default
+    selection if no story names are provided."""
+    return cls.all_story_names()
+
+  @classmethod
+  def all(cls: Type[PressBenchmarkStoryT],
+          separate: bool = False,
+          url: Optional[str] = None,
+          **kwargs) -> List[PressBenchmarkStoryT]:
+    return cls.from_names(cls.all_story_names(), separate, url, **kwargs)
+
+  @classmethod
+  def default(cls: Type[PressBenchmarkStoryT],
+              separate: bool = False,
+              url: Optional[str] = None,
+              **kwargs) -> List[PressBenchmarkStoryT]:
+    return cls.from_names(cls.default_story_names(), separate, url, **kwargs)
+
+  @classmethod
+  def from_names(cls: Type[PressBenchmarkStoryT],
+                 substories: Sequence[str],
+                 separate: bool = False,
+                 url: Optional[str] = None,
+                 **kwargs) -> List[PressBenchmarkStoryT]:
+    if not substories:
+      raise ValueError("No substories provided")
+    if separate:
+      return [
+          cls(  # pytype: disable=not-instantiable
+              url=url,
+              substories=[substory],
+              **kwargs) for substory in substories
+      ]
+    return [
+        cls(  # pytype: disable=not-instantiable
+            url=url,
+            substories=substories,
+            **kwargs)
+    ]
+
+  def __init__(self,
+               *args,
+               substories: Sequence[str] = (),
+               duration: Optional[float] = None,
+               url: Optional[str] = None,
+               **kwargs) -> None:
+    cls = self.__class__
+    assert self.SUBSTORIES, f"{cls}.SUBSTORIES is not set."
+    assert self.NAME is not None, f"{cls}.NAME is not set."
+    self._verify_url(self.URL, "URL")
+    self._verify_url(self.URL_OFFICIAL, "URL_OFFICIAL")
+    self._verify_url(self.URL_LOCAL, "URL_LOCAL")
+    assert substories, f"No substories provided for {cls}"
+    self._substories: Sequence[str] = substories
+    self._verify_substories()
+    kwargs["name"] = self._get_unique_name()
+    kwargs["duration"] = duration or self._get_initial_duration()
+    super().__init__(*args, **kwargs)
+    # If the _custom_url is empty, we generate a matching URL when the
+    # local file server is used.
+    self._custom_url: Optional[str] = url
+
+  def _get_unique_name(self) -> str:
+    substories_set = set(self._substories)
+    if substories_set == set(self.default_story_names()):
+      return self.NAME
+    if substories_set == set(self.all_story_names()):
+      name = "all"
+    else:
+      name = "_".join(self._substories)
+    if len(name) > 220:
+      # Crop the name and add some random hash bits
+      name = name[:220] + hex(hash(name))[2:10]
+    return name
+
+  def _get_initial_duration(self) -> dt.timedelta:
+    # Fixed delay for startup costs
+    startup_delay = dt.timedelta(seconds=2)
+    # Add some slack due to different story lengths
+    story_factor = 0.5 + 1.1 * len(self._substories)
+    return startup_delay + (story_factor * self.substory_duration)
+
+  def get_run_url(self, run: Run) -> str:
+    if self._custom_url:
+      # TODO: check that we have a live network / url host matches network host
+      return self._custom_url
+    network = run.browser_session.network
+    # Create a matching URL for a local file server.
+    if network.is_local_file_server and network.http_port:
+      return f"http://{network.host}:{network.http_port}"
+    # Return default URL in case of live network.
+    return self.url
+
+  @property
+  def substories(self) -> List[str]:
+    return list(self._substories)
+
+  @property
+  def has_default_substories(self) -> bool:
+    return tuple(self.substories) == self.default_story_names()
+
+  @property
+  def fast_duration(self) -> dt.timedelta:
+    """Expected benchmark duration on fast machines.
+    Keep this low enough to not have to wait needlessly at the end of a
+    benchmark.
+    """
+    return self.duration / 3
+
+  @property
+  def slow_duration(self) -> dt.timedelta:
+    """Max duration that covers run-times on slow machines and/or
+    debug-mode browsers.
+    Making this number too large might cause needless wait times on broken
+    browsers/benchmarks.
+    """
+    return dt.timedelta(seconds=15) + self.duration * 5
+
+  @property
+  @abc.abstractmethod
+  def substory_duration(self) -> dt.timedelta:
+    pass
+
+  @property
+  def url(self) -> str:
+    return self._custom_url or self.URL
+
+  def _verify_url(self, url: str, property_name: str) -> None:
+    cls = self.__class__
+    assert url is not None, f"{cls}.{property_name} is not set."
+
+  def _verify_substories(self) -> None:
+    ObjectParser.unique_sequence(self._substories, "substories", ValueError)
+    if self._substories == self.SUBSTORIES:
+      return
+    for substory in self._substories:
+      assert substory in self.SUBSTORIES, (f"Unknown {self.NAME} substory %s" %
+                                           substory)
+
+  def log_run_details(self, run: Run) -> None:
+    super().log_run_details(run)
+    self.log_run_test_url(run)
+
+  def log_run_test_url(self, run: Run):
+    del run
+    logging.info("STORY PUBLIC TEST URL: %s", self.URL)
diff --git a/crossbench/stories/story.py b/crossbench/stories/story.py
new file mode 100644
index 0000000..affeedc
--- /dev/null
+++ b/crossbench/stories/story.py
@@ -0,0 +1,70 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import logging
+from typing import TYPE_CHECKING, Sequence
+
+from crossbench.path import safe_filename
+
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
+
+
+class Story(abc.ABC):
+  @classmethod
+  @abc.abstractmethod
+  def all_story_names(cls) -> Sequence[str]:
+    pass
+
+  def __init__(self,
+               name: str,
+               duration: dt.timedelta = dt.timedelta(seconds=15)):
+    assert name, "Invalid page name"
+    self._name = safe_filename(name)
+    self._duration = duration
+    if self._duration:
+      assert self._duration.total_seconds() > 0, (
+          f"Duration must be non-empty, but got: {duration}")
+
+  @property
+  def name(self) -> str:
+    return self._name
+
+  @property
+  def duration(self) -> dt.timedelta:
+    return self._duration
+
+  def details_json(self) -> JsonDict:
+    return {"name": self.name, "duration": self.duration.total_seconds()}
+
+  def log_run_details(self, run: Run) -> None:
+    logging.info("STORY:          %s", self)
+    timing = run.timing
+    logging.info("STORY DURATION: expected=%s timeout=%s",
+                 timing.timedelta(self.duration),
+                 timing.timeout_timedelta(self.duration))
+
+  def setup(self, run: Run) -> None:
+    """Setup work for a story that is not part of the main workload should
+    be put in this method. Probes can skip measuring this section.
+    i.e selecting substories to run.
+    """
+
+  @abc.abstractmethod
+  def run(self, run: Run) -> None:
+    """The main workload of a story that is measured by all Probes.
+    """
+
+  def teardown(self, run: Run) -> None:
+    """Cleanup work for a story that is not part of the main workload should
+    be put in this method. Probes can skip measuring this section.
+    """
+
+  def __str__(self) -> str:
+    return f"Story(name={self.name})"
diff --git a/crossbench/types.py b/crossbench/types.py
new file mode 100644
index 0000000..0b6b13b
--- /dev/null
+++ b/crossbench/types.py
@@ -0,0 +1,12 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Dict, List, Tuple, Union
+
+Json = Union["JsonDict", "JsonList", "JsonTuple", str, int, float, bool, None]
+JsonDict = Dict[str, Json]
+JsonList = List[Json]
+JsonTuple = Tuple[Json, ...]
diff --git a/docs/contributing.md b/docs/contributing.md
new file mode 100644
index 0000000..dfee376
--- /dev/null
+++ b/docs/contributing.md
@@ -0,0 +1,28 @@
+# How to Contribute
+
+We'd love to accept your patches and contributions to this project. There are
+just a few small guidelines you need to follow.
+
+## Contributor License Agreement
+
+Contributions to this project must be accompanied by a Contributor License
+Agreement. You (or your employer) retain the copyright to your contribution;
+this simply gives us permission to use and redistribute your contributions as
+part of the project. Head over to <https://cla.developers.google.com/> to see
+your current agreements on file or to sign a new one.
+
+You generally only need to submit a CLA once, so if you've already submitted one
+(even if it was for a different project), you probably don't need to do it
+again.
+
+## Code Reviews
+
+All submissions, including submissions by project members, require review. We
+use Gerrit for this purpose. Consult
+[Gerrit Help](https://gerrit-review.googlesource.com/Documentation/intro-gerrit-walkthrough.html)
+for more information on using gerrit.
+
+## Community Guidelines
+
+This project follows [Google's Open Source Community
+Guidelines](https://opensource.google/conduct/).
diff --git a/mypy.ini b/mypy.ini
new file mode 100644
index 0000000..0206027
--- /dev/null
+++ b/mypy.ini
@@ -0,0 +1,2 @@
+[mypy]
+disable_error_code = import
\ No newline at end of file
diff --git a/poetry.lock b/poetry.lock
new file mode 100644
index 0000000..cb63945
--- /dev/null
+++ b/poetry.lock
@@ -0,0 +1,1522 @@
+# This file is automatically @generated by Poetry 1.5.1 and should not be changed by hand.
+
+[[package]]
+name = "astroid"
+version = "3.3.5"
+description = "An abstract syntax tree for Python with inference support."
+optional = false
+python-versions = ">=3.9.0"
+files = [
+    {file = "astroid-3.3.5-py3-none-any.whl", hash = "sha256:a9d1c946ada25098d790e079ba2a1b112157278f3fb7e718ae6a9252f5835dc8"},
+    {file = "astroid-3.3.5.tar.gz", hash = "sha256:5cfc40ae9f68311075d27ef68a4841bdc5cc7f6cf86671b49f00607d30188e2d"},
+]
+
+[package.dependencies]
+typing-extensions = {version = ">=4.0.0", markers = "python_version < \"3.11\""}
+
+[[package]]
+name = "attrs"
+version = "24.2.0"
+description = "Classes Without Boilerplate"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "attrs-24.2.0-py3-none-any.whl", hash = "sha256:81921eb96de3191c8258c199618104dd27ac608d9366f5e35d011eae1867ede2"},
+    {file = "attrs-24.2.0.tar.gz", hash = "sha256:5cfb1b9148b5b086569baec03f20d7b6bf3bcacc9a42bebf87ffaaca362f6346"},
+]
+
+[package.extras]
+benchmark = ["cloudpickle", "hypothesis", "mypy (>=1.11.1)", "pympler", "pytest (>=4.3.0)", "pytest-codspeed", "pytest-mypy-plugins", "pytest-xdist[psutil]"]
+cov = ["cloudpickle", "coverage[toml] (>=5.3)", "hypothesis", "mypy (>=1.11.1)", "pympler", "pytest (>=4.3.0)", "pytest-mypy-plugins", "pytest-xdist[psutil]"]
+dev = ["cloudpickle", "hypothesis", "mypy (>=1.11.1)", "pre-commit", "pympler", "pytest (>=4.3.0)", "pytest-mypy-plugins", "pytest-xdist[psutil]"]
+docs = ["cogapp", "furo", "myst-parser", "sphinx", "sphinx-notfound-page", "sphinxcontrib-towncrier", "towncrier (<24.7)"]
+tests = ["cloudpickle", "hypothesis", "mypy (>=1.11.1)", "pympler", "pytest (>=4.3.0)", "pytest-mypy-plugins", "pytest-xdist[psutil]"]
+tests-mypy = ["mypy (>=1.11.1)", "pytest-mypy-plugins"]
+
+[[package]]
+name = "certifi"
+version = "2024.8.30"
+description = "Python package for providing Mozilla's CA Bundle."
+optional = false
+python-versions = ">=3.6"
+files = [
+    {file = "certifi-2024.8.30-py3-none-any.whl", hash = "sha256:922820b53db7a7257ffbda3f597266d435245903d80737e34f8a45ff3e3230d8"},
+    {file = "certifi-2024.8.30.tar.gz", hash = "sha256:bec941d2aa8195e248a60b31ff9f0558284cf01a52591ceda73ea9afffd69fd9"},
+]
+
+[[package]]
+name = "cffi"
+version = "1.17.1"
+description = "Foreign Function Interface for Python calling C code."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "cffi-1.17.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:df8b1c11f177bc2313ec4b2d46baec87a5f3e71fc8b45dab2ee7cae86d9aba14"},
+    {file = "cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:8f2cdc858323644ab277e9bb925ad72ae0e67f69e804f4898c070998d50b1a67"},
+    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:edae79245293e15384b51f88b00613ba9f7198016a5948b5dddf4917d4d26382"},
+    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:45398b671ac6d70e67da8e4224a065cec6a93541bb7aebe1b198a61b58c7b702"},
+    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ad9413ccdeda48c5afdae7e4fa2192157e991ff761e7ab8fdd8926f40b160cc3"},
+    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5da5719280082ac6bd9aa7becb3938dc9f9cbd57fac7d2871717b1feb0902ab6"},
+    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2bb1a08b8008b281856e5971307cc386a8e9c5b625ac297e853d36da6efe9c17"},
+    {file = "cffi-1.17.1-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:045d61c734659cc045141be4bae381a41d89b741f795af1dd018bfb532fd0df8"},
+    {file = "cffi-1.17.1-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:6883e737d7d9e4899a8a695e00ec36bd4e5e4f18fabe0aca0efe0a4b44cdb13e"},
+    {file = "cffi-1.17.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:6b8b4a92e1c65048ff98cfe1f735ef8f1ceb72e3d5f0c25fdb12087a23da22be"},
+    {file = "cffi-1.17.1-cp310-cp310-win32.whl", hash = "sha256:c9c3d058ebabb74db66e431095118094d06abf53284d9c81f27300d0e0d8bc7c"},
+    {file = "cffi-1.17.1-cp310-cp310-win_amd64.whl", hash = "sha256:0f048dcf80db46f0098ccac01132761580d28e28bc0f78ae0d58048063317e15"},
+    {file = "cffi-1.17.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:a45e3c6913c5b87b3ff120dcdc03f6131fa0065027d0ed7ee6190736a74cd401"},
+    {file = "cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:30c5e0cb5ae493c04c8b42916e52ca38079f1b235c2f8ae5f4527b963c401caf"},
+    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f75c7ab1f9e4aca5414ed4d8e5c0e303a34f4421f8a0d47a4d019ceff0ab6af4"},
+    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a1ed2dd2972641495a3ec98445e09766f077aee98a1c896dcb4ad0d303628e41"},
+    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:46bf43160c1a35f7ec506d254e5c890f3c03648a4dbac12d624e4490a7046cd1"},
+    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a24ed04c8ffd54b0729c07cee15a81d964e6fee0e3d4d342a27b020d22959dc6"},
+    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:610faea79c43e44c71e1ec53a554553fa22321b65fae24889706c0a84d4ad86d"},
+    {file = "cffi-1.17.1-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:a9b15d491f3ad5d692e11f6b71f7857e7835eb677955c00cc0aefcd0669adaf6"},
+    {file = "cffi-1.17.1-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:de2ea4b5833625383e464549fec1bc395c1bdeeb5f25c4a3a82b5a8c756ec22f"},
+    {file = "cffi-1.17.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:fc48c783f9c87e60831201f2cce7f3b2e4846bf4d8728eabe54d60700b318a0b"},
+    {file = "cffi-1.17.1-cp311-cp311-win32.whl", hash = "sha256:85a950a4ac9c359340d5963966e3e0a94a676bd6245a4b55bc43949eee26a655"},
+    {file = "cffi-1.17.1-cp311-cp311-win_amd64.whl", hash = "sha256:caaf0640ef5f5517f49bc275eca1406b0ffa6aa184892812030f04c2abf589a0"},
+    {file = "cffi-1.17.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:805b4371bf7197c329fcb3ead37e710d1bca9da5d583f5073b799d5c5bd1eee4"},
+    {file = "cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:733e99bc2df47476e3848417c5a4540522f234dfd4ef3ab7fafdf555b082ec0c"},
+    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1257bdabf294dceb59f5e70c64a3e2f462c30c7ad68092d01bbbfb1c16b1ba36"},
+    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:da95af8214998d77a98cc14e3a3bd00aa191526343078b530ceb0bd710fb48a5"},
+    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d63afe322132c194cf832bfec0dc69a99fb9bb6bbd550f161a49e9e855cc78ff"},
+    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f79fc4fc25f1c8698ff97788206bb3c2598949bfe0fef03d299eb1b5356ada99"},
+    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b62ce867176a75d03a665bad002af8e6d54644fad99a3c70905c543130e39d93"},
+    {file = "cffi-1.17.1-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:386c8bf53c502fff58903061338ce4f4950cbdcb23e2902d86c0f722b786bbe3"},
+    {file = "cffi-1.17.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:4ceb10419a9adf4460ea14cfd6bc43d08701f0835e979bf821052f1805850fe8"},
+    {file = "cffi-1.17.1-cp312-cp312-win32.whl", hash = "sha256:a08d7e755f8ed21095a310a693525137cfe756ce62d066e53f502a83dc550f65"},
+    {file = "cffi-1.17.1-cp312-cp312-win_amd64.whl", hash = "sha256:51392eae71afec0d0c8fb1a53b204dbb3bcabcb3c9b807eedf3e1e6ccf2de903"},
+    {file = "cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f3a2b4222ce6b60e2e8b337bb9596923045681d71e5a082783484d845390938e"},
+    {file = "cffi-1.17.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:0984a4925a435b1da406122d4d7968dd861c1385afe3b45ba82b750f229811e2"},
+    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d01b12eeeb4427d3110de311e1774046ad344f5b1a7403101878976ecd7a10f3"},
+    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:706510fe141c86a69c8ddc029c7910003a17353970cff3b904ff0686a5927683"},
+    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:de55b766c7aa2e2a3092c51e0483d700341182f08e67c63630d5b6f200bb28e5"},
+    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c59d6e989d07460165cc5ad3c61f9fd8f1b4796eacbd81cee78957842b834af4"},
+    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dd398dbc6773384a17fe0d3e7eeb8d1a21c2200473ee6806bb5e6a8e62bb73dd"},
+    {file = "cffi-1.17.1-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:3edc8d958eb099c634dace3c7e16560ae474aa3803a5df240542b305d14e14ed"},
+    {file = "cffi-1.17.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:72e72408cad3d5419375fc87d289076ee319835bdfa2caad331e377589aebba9"},
+    {file = "cffi-1.17.1-cp313-cp313-win32.whl", hash = "sha256:e03eab0a8677fa80d646b5ddece1cbeaf556c313dcfac435ba11f107ba117b5d"},
+    {file = "cffi-1.17.1-cp313-cp313-win_amd64.whl", hash = "sha256:f6a16c31041f09ead72d69f583767292f750d24913dadacf5756b966aacb3f1a"},
+    {file = "cffi-1.17.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:636062ea65bd0195bc012fea9321aca499c0504409f413dc88af450b57ffd03b"},
+    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c7eac2ef9b63c79431bc4b25f1cd649d7f061a28808cbc6c47b534bd789ef964"},
+    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e221cf152cff04059d011ee126477f0d9588303eb57e88923578ace7baad17f9"},
+    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:31000ec67d4221a71bd3f67df918b1f88f676f1c3b535a7eb473255fdc0b83fc"},
+    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6f17be4345073b0a7b8ea599688f692ac3ef23ce28e5df79c04de519dbc4912c"},
+    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0e2b1fac190ae3ebfe37b979cc1ce69c81f4e4fe5746bb401dca63a9062cdaf1"},
+    {file = "cffi-1.17.1-cp38-cp38-win32.whl", hash = "sha256:7596d6620d3fa590f677e9ee430df2958d2d6d6de2feeae5b20e82c00b76fbf8"},
+    {file = "cffi-1.17.1-cp38-cp38-win_amd64.whl", hash = "sha256:78122be759c3f8a014ce010908ae03364d00a1f81ab5c7f4a7a5120607ea56e1"},
+    {file = "cffi-1.17.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:b2ab587605f4ba0bf81dc0cb08a41bd1c0a5906bd59243d56bad7668a6fc6c16"},
+    {file = "cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:28b16024becceed8c6dfbc75629e27788d8a3f9030691a1dbf9821a128b22c36"},
+    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1d599671f396c4723d016dbddb72fe8e0397082b0a77a4fab8028923bec050e8"},
+    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ca74b8dbe6e8e8263c0ffd60277de77dcee6c837a3d0881d8c1ead7268c9e576"},
+    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f7f5baafcc48261359e14bcd6d9bff6d4b28d9103847c9e136694cb0501aef87"},
+    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:98e3969bcff97cae1b2def8ba499ea3d6f31ddfdb7635374834cf89a1a08ecf0"},
+    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cdf5ce3acdfd1661132f2a9c19cac174758dc2352bfe37d98aa7512c6b7178b3"},
+    {file = "cffi-1.17.1-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:9755e4345d1ec879e3849e62222a18c7174d65a6a92d5b346b1863912168b595"},
+    {file = "cffi-1.17.1-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:f1e22e8c4419538cb197e4dd60acc919d7696e5ef98ee4da4e01d3f8cfa4cc5a"},
+    {file = "cffi-1.17.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:c03e868a0b3bc35839ba98e74211ed2b05d2119be4e8a0f224fba9384f1fe02e"},
+    {file = "cffi-1.17.1-cp39-cp39-win32.whl", hash = "sha256:e31ae45bc2e29f6b2abd0de1cc3b9d5205aa847cafaecb8af1476a609a2f6eb7"},
+    {file = "cffi-1.17.1-cp39-cp39-win_amd64.whl", hash = "sha256:d016c76bdd850f3c626af19b0542c9677ba156e4ee4fccfdd7848803533ef662"},
+    {file = "cffi-1.17.1.tar.gz", hash = "sha256:1c39c6016c32bc48dd54561950ebd6836e1670f2ae46128f67cf49e789c52824"},
+]
+
+[package.dependencies]
+pycparser = "*"
+
+[[package]]
+name = "colorama"
+version = "0.4.6"
+description = "Cross-platform colored terminal text."
+optional = false
+python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7"
+files = [
+    {file = "colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6"},
+    {file = "colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44"},
+]
+
+[[package]]
+name = "coverage"
+version = "7.6.4"
+description = "Code coverage measurement for Python"
+optional = false
+python-versions = ">=3.9"
+files = [
+    {file = "coverage-7.6.4-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:5f8ae553cba74085db385d489c7a792ad66f7f9ba2ee85bfa508aeb84cf0ba07"},
+    {file = "coverage-7.6.4-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:8165b796df0bd42e10527a3f493c592ba494f16ef3c8b531288e3d0d72c1f6f0"},
+    {file = "coverage-7.6.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c7c8b95bf47db6d19096a5e052ffca0a05f335bc63cef281a6e8fe864d450a72"},
+    {file = "coverage-7.6.4-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:8ed9281d1b52628e81393f5eaee24a45cbd64965f41857559c2b7ff19385df51"},
+    {file = "coverage-7.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0809082ee480bb8f7416507538243c8863ac74fd8a5d2485c46f0f7499f2b491"},
+    {file = "coverage-7.6.4-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:d541423cdd416b78626b55f123412fcf979d22a2c39fce251b350de38c15c15b"},
+    {file = "coverage-7.6.4-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:58809e238a8a12a625c70450b48e8767cff9eb67c62e6154a642b21ddf79baea"},
+    {file = "coverage-7.6.4-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:c9b8e184898ed014884ca84c70562b4a82cbc63b044d366fedc68bc2b2f3394a"},
+    {file = "coverage-7.6.4-cp310-cp310-win32.whl", hash = "sha256:6bd818b7ea14bc6e1f06e241e8234508b21edf1b242d49831831a9450e2f35fa"},
+    {file = "coverage-7.6.4-cp310-cp310-win_amd64.whl", hash = "sha256:06babbb8f4e74b063dbaeb74ad68dfce9186c595a15f11f5d5683f748fa1d172"},
+    {file = "coverage-7.6.4-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:73d2b73584446e66ee633eaad1a56aad577c077f46c35ca3283cd687b7715b0b"},
+    {file = "coverage-7.6.4-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:51b44306032045b383a7a8a2c13878de375117946d68dcb54308111f39775a25"},
+    {file = "coverage-7.6.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0b3fb02fe73bed561fa12d279a417b432e5b50fe03e8d663d61b3d5990f29546"},
+    {file = "coverage-7.6.4-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ed8fe9189d2beb6edc14d3ad19800626e1d9f2d975e436f84e19efb7fa19469b"},
+    {file = "coverage-7.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b369ead6527d025a0fe7bd3864e46dbee3aa8f652d48df6174f8d0bac9e26e0e"},
+    {file = "coverage-7.6.4-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:ade3ca1e5f0ff46b678b66201f7ff477e8fa11fb537f3b55c3f0568fbfe6e718"},
+    {file = "coverage-7.6.4-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:27fb4a050aaf18772db513091c9c13f6cb94ed40eacdef8dad8411d92d9992db"},
+    {file = "coverage-7.6.4-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:4f704f0998911abf728a7783799444fcbbe8261c4a6c166f667937ae6a8aa522"},
+    {file = "coverage-7.6.4-cp311-cp311-win32.whl", hash = "sha256:29155cd511ee058e260db648b6182c419422a0d2e9a4fa44501898cf918866cf"},
+    {file = "coverage-7.6.4-cp311-cp311-win_amd64.whl", hash = "sha256:8902dd6a30173d4ef09954bfcb24b5d7b5190cf14a43170e386979651e09ba19"},
+    {file = "coverage-7.6.4-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:12394842a3a8affa3ba62b0d4ab7e9e210c5e366fbac3e8b2a68636fb19892c2"},
+    {file = "coverage-7.6.4-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:2b6b4c83d8e8ea79f27ab80778c19bc037759aea298da4b56621f4474ffeb117"},
+    {file = "coverage-7.6.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1d5b8007f81b88696d06f7df0cb9af0d3b835fe0c8dbf489bad70b45f0e45613"},
+    {file = "coverage-7.6.4-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b57b768feb866f44eeed9f46975f3d6406380275c5ddfe22f531a2bf187eda27"},
+    {file = "coverage-7.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5915fcdec0e54ee229926868e9b08586376cae1f5faa9bbaf8faf3561b393d52"},
+    {file = "coverage-7.6.4-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:0b58c672d14f16ed92a48db984612f5ce3836ae7d72cdd161001cc54512571f2"},
+    {file = "coverage-7.6.4-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:2fdef0d83a2d08d69b1f2210a93c416d54e14d9eb398f6ab2f0a209433db19e1"},
+    {file = "coverage-7.6.4-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:8cf717ee42012be8c0cb205dbbf18ffa9003c4cbf4ad078db47b95e10748eec5"},
+    {file = "coverage-7.6.4-cp312-cp312-win32.whl", hash = "sha256:7bb92c539a624cf86296dd0c68cd5cc286c9eef2d0c3b8b192b604ce9de20a17"},
+    {file = "coverage-7.6.4-cp312-cp312-win_amd64.whl", hash = "sha256:1032e178b76a4e2b5b32e19d0fd0abbce4b58e77a1ca695820d10e491fa32b08"},
+    {file = "coverage-7.6.4-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:023bf8ee3ec6d35af9c1c6ccc1d18fa69afa1cb29eaac57cb064dbb262a517f9"},
+    {file = "coverage-7.6.4-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:b0ac3d42cb51c4b12df9c5f0dd2f13a4f24f01943627120ec4d293c9181219ba"},
+    {file = "coverage-7.6.4-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f8fe4984b431f8621ca53d9380901f62bfb54ff759a1348cd140490ada7b693c"},
+    {file = "coverage-7.6.4-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:5fbd612f8a091954a0c8dd4c0b571b973487277d26476f8480bfa4b2a65b5d06"},
+    {file = "coverage-7.6.4-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dacbc52de979f2823a819571f2e3a350a7e36b8cb7484cdb1e289bceaf35305f"},
+    {file = "coverage-7.6.4-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:dab4d16dfef34b185032580e2f2f89253d302facba093d5fa9dbe04f569c4f4b"},
+    {file = "coverage-7.6.4-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:862264b12ebb65ad8d863d51f17758b1684560b66ab02770d4f0baf2ff75da21"},
+    {file = "coverage-7.6.4-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:5beb1ee382ad32afe424097de57134175fea3faf847b9af002cc7895be4e2a5a"},
+    {file = "coverage-7.6.4-cp313-cp313-win32.whl", hash = "sha256:bf20494da9653f6410213424f5f8ad0ed885e01f7e8e59811f572bdb20b8972e"},
+    {file = "coverage-7.6.4-cp313-cp313-win_amd64.whl", hash = "sha256:182e6cd5c040cec0a1c8d415a87b67ed01193ed9ad458ee427741c7d8513d963"},
+    {file = "coverage-7.6.4-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:a181e99301a0ae128493a24cfe5cfb5b488c4e0bf2f8702091473d033494d04f"},
+    {file = "coverage-7.6.4-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:df57bdbeffe694e7842092c5e2e0bc80fff7f43379d465f932ef36f027179806"},
+    {file = "coverage-7.6.4-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0bcd1069e710600e8e4cf27f65c90c7843fa8edfb4520fb0ccb88894cad08b11"},
+    {file = "coverage-7.6.4-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:99b41d18e6b2a48ba949418db48159d7a2e81c5cc290fc934b7d2380515bd0e3"},
+    {file = "coverage-7.6.4-cp313-cp313t-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a6b1e54712ba3474f34b7ef7a41e65bd9037ad47916ccb1cc78769bae324c01a"},
+    {file = "coverage-7.6.4-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:53d202fd109416ce011578f321460795abfe10bb901b883cafd9b3ef851bacfc"},
+    {file = "coverage-7.6.4-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:c48167910a8f644671de9f2083a23630fbf7a1cb70ce939440cd3328e0919f70"},
+    {file = "coverage-7.6.4-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:cc8ff50b50ce532de2fa7a7daae9dd12f0a699bfcd47f20945364e5c31799fef"},
+    {file = "coverage-7.6.4-cp313-cp313t-win32.whl", hash = "sha256:b8d3a03d9bfcaf5b0141d07a88456bb6a4c3ce55c080712fec8418ef3610230e"},
+    {file = "coverage-7.6.4-cp313-cp313t-win_amd64.whl", hash = "sha256:f3ddf056d3ebcf6ce47bdaf56142af51bb7fad09e4af310241e9db7a3a8022e1"},
+    {file = "coverage-7.6.4-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:9cb7fa111d21a6b55cbf633039f7bc2749e74932e3aa7cb7333f675a58a58bf3"},
+    {file = "coverage-7.6.4-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:11a223a14e91a4693d2d0755c7a043db43d96a7450b4f356d506c2562c48642c"},
+    {file = "coverage-7.6.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a413a096c4cbac202433c850ee43fa326d2e871b24554da8327b01632673a076"},
+    {file = "coverage-7.6.4-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:00a1d69c112ff5149cabe60d2e2ee948752c975d95f1e1096742e6077affd376"},
+    {file = "coverage-7.6.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1f76846299ba5c54d12c91d776d9605ae33f8ae2b9d1d3c3703cf2db1a67f2c0"},
+    {file = "coverage-7.6.4-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:fe439416eb6380de434886b00c859304338f8b19f6f54811984f3420a2e03858"},
+    {file = "coverage-7.6.4-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:0294ca37f1ba500667b1aef631e48d875ced93ad5e06fa665a3295bdd1d95111"},
+    {file = "coverage-7.6.4-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:6f01ba56b1c0e9d149f9ac85a2f999724895229eb36bd997b61e62999e9b0901"},
+    {file = "coverage-7.6.4-cp39-cp39-win32.whl", hash = "sha256:bc66f0bf1d7730a17430a50163bb264ba9ded56739112368ba985ddaa9c3bd09"},
+    {file = "coverage-7.6.4-cp39-cp39-win_amd64.whl", hash = "sha256:c481b47f6b5845064c65a7bc78bc0860e635a9b055af0df46fdf1c58cebf8e8f"},
+    {file = "coverage-7.6.4-pp39.pp310-none-any.whl", hash = "sha256:3c65d37f3a9ebb703e710befdc489a38683a5b152242664b973a7b7b22348a4e"},
+    {file = "coverage-7.6.4.tar.gz", hash = "sha256:29fc0f17b1d3fea332f8001d4558f8214af7f1d87a345f3a133c901d60347c73"},
+]
+
+[package.dependencies]
+tomli = {version = "*", optional = true, markers = "python_full_version <= \"3.11.0a6\" and extra == \"toml\""}
+
+[package.extras]
+toml = ["tomli"]
+
+[[package]]
+name = "debugpy"
+version = "1.8.7"
+description = "An implementation of the Debug Adapter Protocol for Python"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "debugpy-1.8.7-cp310-cp310-macosx_14_0_x86_64.whl", hash = "sha256:95fe04a573b8b22896c404365e03f4eda0ce0ba135b7667a1e57bd079793b96b"},
+    {file = "debugpy-1.8.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:628a11f4b295ffb4141d8242a9bb52b77ad4a63a2ad19217a93be0f77f2c28c9"},
+    {file = "debugpy-1.8.7-cp310-cp310-win32.whl", hash = "sha256:85ce9c1d0eebf622f86cc68618ad64bf66c4fc3197d88f74bb695a416837dd55"},
+    {file = "debugpy-1.8.7-cp310-cp310-win_amd64.whl", hash = "sha256:29e1571c276d643757ea126d014abda081eb5ea4c851628b33de0c2b6245b037"},
+    {file = "debugpy-1.8.7-cp311-cp311-macosx_14_0_universal2.whl", hash = "sha256:caf528ff9e7308b74a1749c183d6808ffbedbb9fb6af78b033c28974d9b8831f"},
+    {file = "debugpy-1.8.7-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cba1d078cf2e1e0b8402e6bda528bf8fda7ccd158c3dba6c012b7897747c41a0"},
+    {file = "debugpy-1.8.7-cp311-cp311-win32.whl", hash = "sha256:171899588bcd412151e593bd40d9907133a7622cd6ecdbdb75f89d1551df13c2"},
+    {file = "debugpy-1.8.7-cp311-cp311-win_amd64.whl", hash = "sha256:6e1c4ffb0c79f66e89dfd97944f335880f0d50ad29525dc792785384923e2211"},
+    {file = "debugpy-1.8.7-cp312-cp312-macosx_14_0_universal2.whl", hash = "sha256:4d27d842311353ede0ad572600c62e4bcd74f458ee01ab0dd3a1a4457e7e3706"},
+    {file = "debugpy-1.8.7-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:703c1fd62ae0356e194f3e7b7a92acd931f71fe81c4b3be2c17a7b8a4b546ec2"},
+    {file = "debugpy-1.8.7-cp312-cp312-win32.whl", hash = "sha256:2f729228430ef191c1e4df72a75ac94e9bf77413ce5f3f900018712c9da0aaca"},
+    {file = "debugpy-1.8.7-cp312-cp312-win_amd64.whl", hash = "sha256:45c30aaefb3e1975e8a0258f5bbd26cd40cde9bfe71e9e5a7ac82e79bad64e39"},
+    {file = "debugpy-1.8.7-cp313-cp313-macosx_14_0_universal2.whl", hash = "sha256:d050a1ec7e925f514f0f6594a1e522580317da31fbda1af71d1530d6ea1f2b40"},
+    {file = "debugpy-1.8.7-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f2f4349a28e3228a42958f8ddaa6333d6f8282d5edaea456070e48609c5983b7"},
+    {file = "debugpy-1.8.7-cp313-cp313-win32.whl", hash = "sha256:11ad72eb9ddb436afb8337891a986302e14944f0f755fd94e90d0d71e9100bba"},
+    {file = "debugpy-1.8.7-cp313-cp313-win_amd64.whl", hash = "sha256:2efb84d6789352d7950b03d7f866e6d180284bc02c7e12cb37b489b7083d81aa"},
+    {file = "debugpy-1.8.7-cp38-cp38-macosx_14_0_x86_64.whl", hash = "sha256:4b908291a1d051ef3331484de8e959ef3e66f12b5e610c203b5b75d2725613a7"},
+    {file = "debugpy-1.8.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:da8df5b89a41f1fd31503b179d0a84a5fdb752dddd5b5388dbd1ae23cda31ce9"},
+    {file = "debugpy-1.8.7-cp38-cp38-win32.whl", hash = "sha256:b12515e04720e9e5c2216cc7086d0edadf25d7ab7e3564ec8b4521cf111b4f8c"},
+    {file = "debugpy-1.8.7-cp38-cp38-win_amd64.whl", hash = "sha256:93176e7672551cb5281577cdb62c63aadc87ec036f0c6a486f0ded337c504596"},
+    {file = "debugpy-1.8.7-cp39-cp39-macosx_14_0_x86_64.whl", hash = "sha256:90d93e4f2db442f8222dec5ec55ccfc8005821028982f1968ebf551d32b28907"},
+    {file = "debugpy-1.8.7-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b6db2a370e2700557a976eaadb16243ec9c91bd46f1b3bb15376d7aaa7632c81"},
+    {file = "debugpy-1.8.7-cp39-cp39-win32.whl", hash = "sha256:a6cf2510740e0c0b4a40330640e4b454f928c7b99b0c9dbf48b11efba08a8cda"},
+    {file = "debugpy-1.8.7-cp39-cp39-win_amd64.whl", hash = "sha256:6a9d9d6d31846d8e34f52987ee0f1a904c7baa4912bf4843ab39dadf9b8f3e0d"},
+    {file = "debugpy-1.8.7-py2.py3-none-any.whl", hash = "sha256:57b00de1c8d2c84a61b90880f7e5b6deaf4c312ecbde3a0e8912f2a56c4ac9ae"},
+    {file = "debugpy-1.8.7.zip", hash = "sha256:18b8f731ed3e2e1df8e9cdaa23fb1fc9c24e570cd0081625308ec51c82efe42e"},
+]
+
+[[package]]
+name = "dill"
+version = "0.3.9"
+description = "serialize all of Python"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "dill-0.3.9-py3-none-any.whl", hash = "sha256:468dff3b89520b474c0397703366b7b95eebe6303f108adf9b19da1f702be87a"},
+    {file = "dill-0.3.9.tar.gz", hash = "sha256:81aa267dddf68cbfe8029c42ca9ec6a4ab3b22371d1c450abc54422577b4512c"},
+]
+
+[package.extras]
+graph = ["objgraph (>=1.7.2)"]
+profile = ["gprof2dot (>=2022.7.29)"]
+
+[[package]]
+name = "exceptiongroup"
+version = "1.2.2"
+description = "Backport of PEP 654 (exception groups)"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "exceptiongroup-1.2.2-py3-none-any.whl", hash = "sha256:3111b9d131c238bec2f8f516e123e14ba243563fb135d3fe885990585aa7795b"},
+    {file = "exceptiongroup-1.2.2.tar.gz", hash = "sha256:47c2edf7c6738fafb49fd34290706d1a1a2f4d1c6df275526b62cbb4aa5393cc"},
+]
+
+[package.extras]
+test = ["pytest (>=6)"]
+
+[[package]]
+name = "execnet"
+version = "2.1.1"
+description = "execnet: rapid multi-Python deployment"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "execnet-2.1.1-py3-none-any.whl", hash = "sha256:26dee51f1b80cebd6d0ca8e74dd8745419761d3bef34163928cbebbdc4749fdc"},
+    {file = "execnet-2.1.1.tar.gz", hash = "sha256:5189b52c6121c24feae288166ab41b32549c7e2348652736540b9e6e7d4e72e3"},
+]
+
+[package.extras]
+testing = ["hatch", "pre-commit", "pytest", "tox"]
+
+[[package]]
+name = "gprof2dot"
+version = "2024.6.6"
+description = "Generate a dot graph from the output of several profilers."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "gprof2dot-2024.6.6-py2.py3-none-any.whl", hash = "sha256:45b14ad7ce64e299c8f526881007b9eb2c6b75505d5613e96e66ee4d5ab33696"},
+    {file = "gprof2dot-2024.6.6.tar.gz", hash = "sha256:fa1420c60025a9eb7734f65225b4da02a10fc6dd741b37fa129bc6b41951e5ab"},
+]
+
+[[package]]
+name = "h11"
+version = "0.14.0"
+description = "A pure-Python, bring-your-own-I/O implementation of HTTP/1.1"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "h11-0.14.0-py3-none-any.whl", hash = "sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761"},
+    {file = "h11-0.14.0.tar.gz", hash = "sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d"},
+]
+
+[[package]]
+name = "hjson"
+version = "3.1.0"
+description = "Hjson, a user interface for JSON."
+optional = false
+python-versions = "*"
+files = [
+    {file = "hjson-3.1.0-py3-none-any.whl", hash = "sha256:65713cdcf13214fb554eb8b4ef803419733f4f5e551047c9b711098ab7186b89"},
+    {file = "hjson-3.1.0.tar.gz", hash = "sha256:55af475a27cf83a7969c808399d7bccdec8fb836a07ddbd574587593b9cdcf75"},
+]
+
+[[package]]
+name = "idna"
+version = "3.10"
+description = "Internationalized Domain Names in Applications (IDNA)"
+optional = false
+python-versions = ">=3.6"
+files = [
+    {file = "idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3"},
+    {file = "idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9"},
+]
+
+[package.extras]
+all = ["flake8 (>=7.1.1)", "mypy (>=1.11.2)", "pytest (>=8.3.2)", "ruff (>=0.6.2)"]
+
+[[package]]
+name = "immutabledict"
+version = "4.2.0"
+description = "Immutable wrapper around dictionaries (a fork of frozendict)"
+optional = false
+python-versions = ">=3.8,<4.0"
+files = [
+    {file = "immutabledict-4.2.0-py3-none-any.whl", hash = "sha256:d728b2c2410d698d95e6200237feb50a695584d20289ad3379a439aa3d90baba"},
+    {file = "immutabledict-4.2.0.tar.gz", hash = "sha256:e003fd81aad2377a5a758bf7e1086cf3b70b63e9a5cc2f46bce8d0a2b4727c5f"},
+]
+
+[[package]]
+name = "importlab"
+version = "0.8.1"
+description = "A library to calculate python dependency graphs."
+optional = false
+python-versions = ">=3.6.0"
+files = [
+    {file = "importlab-0.8.1-py2.py3-none-any.whl", hash = "sha256:124cfa00e8a34fefe8aac1a5e94f56c781b178c9eb61a1d3f60f7e03b77338d3"},
+    {file = "importlab-0.8.1.tar.gz", hash = "sha256:b3893853b1f6eb027da509c3b40e6787e95dd66b4b66f1b3613aad77556e1465"},
+]
+
+[package.dependencies]
+networkx = ">=2"
+
+[[package]]
+name = "iniconfig"
+version = "2.0.0"
+description = "brain-dead simple config-ini parsing"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "iniconfig-2.0.0-py3-none-any.whl", hash = "sha256:b6a85871a79d2e3b22d2d1b94ac2824226a63c6b741c88f7ae975f18b6778374"},
+    {file = "iniconfig-2.0.0.tar.gz", hash = "sha256:2d91e135bf72d31a410b17c16da610a82cb55f6b0477d1a902134b24a455b8b3"},
+]
+
+[[package]]
+name = "isort"
+version = "5.13.2"
+description = "A Python utility / library to sort Python imports."
+optional = false
+python-versions = ">=3.8.0"
+files = [
+    {file = "isort-5.13.2-py3-none-any.whl", hash = "sha256:8ca5e72a8d85860d5a3fa69b8745237f2939afe12dbf656afbcb47fe72d947a6"},
+    {file = "isort-5.13.2.tar.gz", hash = "sha256:48fdfcb9face5d58a4f6dde2e72a1fb8dcaf8ab26f95ab49fab84c2ddefb0109"},
+]
+
+[package.extras]
+colors = ["colorama (>=0.4.6)"]
+
+[[package]]
+name = "jinja2"
+version = "3.1.4"
+description = "A very fast and expressive template engine."
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "jinja2-3.1.4-py3-none-any.whl", hash = "sha256:bc5dd2abb727a5319567b7a813e6a2e7318c39f4f487cfe6c89c6f9c7d25197d"},
+    {file = "jinja2-3.1.4.tar.gz", hash = "sha256:4a3aee7acbbe7303aede8e9648d13b8bf88a429282aa6122a993f0ac800cb369"},
+]
+
+[package.dependencies]
+MarkupSafe = ">=2.0"
+
+[package.extras]
+i18n = ["Babel (>=2.7)"]
+
+[[package]]
+name = "libcst"
+version = "1.5.0"
+description = "A concrete syntax tree with AST-like properties for Python 3.0 through 3.13 programs."
+optional = false
+python-versions = ">=3.9"
+files = [
+    {file = "libcst-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:23d0e07fd3ed11480f8993a1e99d58a45f914a711b14f858b8db08ae861a8a34"},
+    {file = "libcst-1.5.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:d92c5ae2e2dc9356ad7e3d05077d9b7e5065423e45788fd86729c88729e45c6e"},
+    {file = "libcst-1.5.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:96adc45e96476350df6b8a5ddbb1e1d6a83a7eb3f13087e52eb7cd2f9b65bcc7"},
+    {file = "libcst-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2d5978fd60c66794bb60d037b2e6427ea52d032636e84afce32b0f04e1cf500a"},
+    {file = "libcst-1.5.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d6502aeb11412afc759036160c686be1107eb5a4466db56b207c786b9b4da7c4"},
+    {file = "libcst-1.5.0-cp310-cp310-win_amd64.whl", hash = "sha256:9cccfc0a78e110c0d0a9d2c6fdeb29feb5274c9157508a8baef7edf352420f6d"},
+    {file = "libcst-1.5.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:585b3aa705b3767d717d2100935d8ef557275ecdd3fac81c3e28db0959efb0ea"},
+    {file = "libcst-1.5.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:8935dd3393e30c2f97344866a4cb14efe560200e232166a8db1de7865c2ef8b2"},
+    {file = "libcst-1.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fc80ea16c7d44e38f193e4d4ef7ff1e0ba72d8e60e8b61ac6f4c87f070a118bd"},
+    {file = "libcst-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:02be4aab728261bb76d16e77c9a457884cebb60d09c8edee844de43b0e08aff7"},
+    {file = "libcst-1.5.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a8fcd78be4d9ce3c36d0c5d0bdd384e0c7d5f72970a9e4ebd56070141972b4ad"},
+    {file = "libcst-1.5.0-cp311-cp311-win_amd64.whl", hash = "sha256:52b6aadfe54e3ae52c3b815eaaa17ba4da9ff010d5e8adf6a70697872886dd10"},
+    {file = "libcst-1.5.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:83bc5fbe34d33597af1d5ea113dcb9b5dd5afe5a5f4316bac4293464d5e3971a"},
+    {file = "libcst-1.5.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:5f10124bf99a0b075eae136ef0ce06204e5f6b8da4596a9c4853a0663e80ddf3"},
+    {file = "libcst-1.5.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:48e581af6127c5af4c9f483e5986d94f0c6b2366967ee134f0a8eba0aa4c8c12"},
+    {file = "libcst-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7dba93cca0a5c6d771ed444c44d21ce8ea9b277af7036cea3743677aba9fbbb8"},
+    {file = "libcst-1.5.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:80b5c4d87721a7bab265c202575809b810815ab81d5e2e7a5d4417a087975840"},
+    {file = "libcst-1.5.0-cp312-cp312-win_amd64.whl", hash = "sha256:b48bf71d52c1e891a0948465a94d9817b5fc1ec1a09603566af90585f3b11948"},
+    {file = "libcst-1.5.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:88520b6dea59eaea0cae80f77c0a632604a82c5b2d23dedb4b5b34035cbf1615"},
+    {file = "libcst-1.5.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:208ea92d80b2eeed8cbc879d5f39f241582a5d56b916b1b65ed2be2f878a2425"},
+    {file = "libcst-1.5.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d4592872aaf5b7fa5c2727a7d73c0985261f1b3fe7eff51f4fd5b8174f30b4e2"},
+    {file = "libcst-1.5.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d2788b2b5838b78fe15df8e9fa6b6903195ea49b2d2ba43e8f423f6c90e4b69f"},
+    {file = "libcst-1.5.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b5b5bcd3a9ba92840f27ad34eaa038acbee195ec337da39536c0a2efbbf28efd"},
+    {file = "libcst-1.5.0-cp313-cp313-win_amd64.whl", hash = "sha256:4d6acb0bdee1e55b44c6215c59755ec4693ac01e74bb1fde04c37358b378835d"},
+    {file = "libcst-1.5.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:6453b5a8755a6eee3ad67ee246f13a8eac9827d2cfc8e4a269e8bf0393db74bc"},
+    {file = "libcst-1.5.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:40748361f4ea66ab6cdd82f8501c82c29808317ac7a3bd132074efd5fd9bfae2"},
+    {file = "libcst-1.5.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4f71aed85932c2ea92058fd9bbd99a6478bd69eada041c3726b4f4c9af1f564e"},
+    {file = "libcst-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b60b09abcc2848ab52d479c3a9b71b606d91a941e3779616efd083bb87dbe8ad"},
+    {file = "libcst-1.5.0-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6fb324ed20f3a725d152df5dba8d80f7e126d9c93cced581bf118a5fc18c1065"},
+    {file = "libcst-1.5.0-cp39-cp39-win_amd64.whl", hash = "sha256:99e7c52150a135d66716b03e00c7b1859a44336dc2a2bf8f9acc164494308531"},
+    {file = "libcst-1.5.0.tar.gz", hash = "sha256:8478abf21ae3861a073e898d80b822bd56e578886331b33129ba77fec05b8c24"},
+]
+
+[package.dependencies]
+pyyaml = ">=5.2"
+
+[package.extras]
+dev = ["Sphinx (>=5.1.1)", "black (==24.8.0)", "build (>=0.10.0)", "coverage[toml] (>=4.5.4)", "fixit (==2.1.0)", "flake8 (==7.1.1)", "hypothesis (>=4.36.0)", "hypothesmith (>=0.0.4)", "jinja2 (==3.1.4)", "jupyter (>=1.0.0)", "maturin (>=1.7.0,<1.8)", "nbsphinx (>=0.4.2)", "prompt-toolkit (>=2.0.9)", "pyre-check (==0.9.18)", "setuptools-rust (>=1.5.2)", "setuptools-scm (>=6.0.1)", "slotscheck (>=0.7.1)", "sphinx-rtd-theme (>=0.4.3)", "ufmt (==2.7.3)", "usort (==1.0.8.post1)"]
+
+[[package]]
+name = "markupsafe"
+version = "3.0.2"
+description = "Safely add untrusted strings to HTML/XML markup."
+optional = false
+python-versions = ">=3.9"
+files = [
+    {file = "MarkupSafe-3.0.2-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:7e94c425039cde14257288fd61dcfb01963e658efbc0ff54f5306b06054700f8"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:9e2d922824181480953426608b81967de705c3cef4d1af983af849d7bd619158"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:38a9ef736c01fccdd6600705b09dc574584b89bea478200c5fbf112a6b0d5579"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bbcb445fa71794da8f178f0f6d66789a28d7319071af7a496d4d507ed566270d"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:57cb5a3cf367aeb1d316576250f65edec5bb3be939e9247ae594b4bcbc317dfb"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:3809ede931876f5b2ec92eef964286840ed3540dadf803dd570c3b7e13141a3b"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:e07c3764494e3776c602c1e78e298937c3315ccc9043ead7e685b7f2b8d47b3c"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:b424c77b206d63d500bcb69fa55ed8d0e6a3774056bdc4839fc9298a7edca171"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-win32.whl", hash = "sha256:fcabf5ff6eea076f859677f5f0b6b5c1a51e70a376b0579e0eadef8db48c6b50"},
+    {file = "MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl", hash = "sha256:6af100e168aa82a50e186c82875a5893c5597a0c1ccdb0d8b40240b1f28b969a"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:9025b4018f3a1314059769c7bf15441064b2207cb3f065e6ea1e7359cb46db9d"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:93335ca3812df2f366e80509ae119189886b0f3c2b81325d39efdb84a1e2ae93"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2cb8438c3cbb25e220c2ab33bb226559e7afb3baec11c4f218ffa7308603c832"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a123e330ef0853c6e822384873bef7507557d8e4a082961e1defa947aa59ba84"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1e084f686b92e5b83186b07e8a17fc09e38fff551f3602b249881fec658d3eca"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:d8213e09c917a951de9d09ecee036d5c7d36cb6cb7dbaece4c71a60d79fb9798"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:5b02fb34468b6aaa40dfc198d813a641e3a63b98c2b05a16b9f80b7ec314185e"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:0bff5e0ae4ef2e1ae4fdf2dfd5b76c75e5c2fa4132d05fc1b0dabcd20c7e28c4"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-win32.whl", hash = "sha256:6c89876f41da747c8d3677a2b540fb32ef5715f97b66eeb0c6b66f5e3ef6f59d"},
+    {file = "MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl", hash = "sha256:70a87b411535ccad5ef2f1df5136506a10775d267e197e4cf531ced10537bd6b"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:9778bd8ab0a994ebf6f84c2b949e65736d5575320a17ae8984a77fab08db94cf"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:846ade7b71e3536c4e56b386c2a47adf5741d2d8b94ec9dc3e92e5e1ee1e2225"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1c99d261bd2d5f6b59325c92c73df481e05e57f19837bdca8413b9eac4bd8028"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e17c96c14e19278594aa4841ec148115f9c7615a47382ecb6b82bd8fea3ab0c8"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:88416bd1e65dcea10bc7569faacb2c20ce071dd1f87539ca2ab364bf6231393c"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:2181e67807fc2fa785d0592dc2d6206c019b9502410671cc905d132a92866557"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:52305740fe773d09cffb16f8ed0427942901f00adedac82ec8b67752f58a1b22"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:ad10d3ded218f1039f11a75f8091880239651b52e9bb592ca27de44eed242a48"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-win32.whl", hash = "sha256:0f4ca02bea9a23221c0182836703cbf8930c5e9454bacce27e767509fa286a30"},
+    {file = "MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl", hash = "sha256:8e06879fc22a25ca47312fbe7c8264eb0b662f6db27cb2d3bbbc74b1df4b9b87"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:ba9527cdd4c926ed0760bc301f6728ef34d841f405abf9d4f959c478421e4efd"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:f8b3d067f2e40fe93e1ccdd6b2e1d16c43140e76f02fb1319a05cf2b79d99430"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:569511d3b58c8791ab4c2e1285575265991e6d8f8700c7be0e88f86cb0672094"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:15ab75ef81add55874e7ab7055e9c397312385bd9ced94920f2802310c930396"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f3818cb119498c0678015754eba762e0d61e5b52d34c8b13d770f0719f7b1d79"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:cdb82a876c47801bb54a690c5ae105a46b392ac6099881cdfb9f6e95e4014c6a"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:cabc348d87e913db6ab4aa100f01b08f481097838bdddf7c7a84b7575b7309ca"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:444dcda765c8a838eaae23112db52f1efaf750daddb2d9ca300bcae1039adc5c"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-win32.whl", hash = "sha256:bcf3e58998965654fdaff38e58584d8937aa3096ab5354d493c77d1fdd66d7a1"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:e6a2a455bd412959b57a172ce6328d2dd1f01cb2135efda2e4576e8a23fa3b0f"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:b5a6b3ada725cea8a5e634536b1b01c30bcdcd7f9c6fff4151548d5bf6b3a36c"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:a904af0a6162c73e3edcb969eeeb53a63ceeb5d8cf642fade7d39e7963a22ddb"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4aa4e5faecf353ed117801a068ebab7b7e09ffb6e1d5e412dc852e0da018126c"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c0ef13eaeee5b615fb07c9a7dadb38eac06a0608b41570d8ade51c56539e509d"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d16a81a06776313e817c951135cf7340a3e91e8c1ff2fac444cfd75fffa04afe"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:6381026f158fdb7c72a168278597a5e3a5222e83ea18f543112b2662a9b699c5"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:3d79d162e7be8f996986c064d1c7c817f6df3a77fe3d6859f6f9e7be4b8c213a"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:131a3c7689c85f5ad20f9f6fb1b866f402c445b220c19fe4308c0b147ccd2ad9"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-win32.whl", hash = "sha256:ba8062ed2cf21c07a9e295d5b8a2a5ce678b913b45fdf68c32d95d6c1291e0b6"},
+    {file = "MarkupSafe-3.0.2-cp313-cp313t-win_amd64.whl", hash = "sha256:e444a31f8db13eb18ada366ab3cf45fd4b31e4db1236a4448f68778c1d1a5a2f"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:eaa0a10b7f72326f1372a713e73c3f739b524b3af41feb43e4921cb529f5929a"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:48032821bbdf20f5799ff537c7ac3d1fba0ba032cfc06194faffa8cda8b560ff"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1a9d3f5f0901fdec14d8d2f66ef7d035f2157240a433441719ac9a3fba440b13"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:88b49a3b9ff31e19998750c38e030fc7bb937398b1f78cfa599aaef92d693144"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:cfad01eed2c2e0c01fd0ecd2ef42c492f7f93902e39a42fc9ee1692961443a29"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:1225beacc926f536dc82e45f8a4d68502949dc67eea90eab715dea3a21c1b5f0"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:3169b1eefae027567d1ce6ee7cae382c57fe26e82775f460f0b2778beaad66c0"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:eb7972a85c54febfb25b5c4b4f3af4dcc731994c7da0d8a0b4a6eb0640e1d178"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-win32.whl", hash = "sha256:8c4e8c3ce11e1f92f6536ff07154f9d49677ebaaafc32db9db4620bc11ed480f"},
+    {file = "MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl", hash = "sha256:6e296a513ca3d94054c2c881cc913116e90fd030ad1c656b3869762b754f5f8a"},
+    {file = "markupsafe-3.0.2.tar.gz", hash = "sha256:ee55d3edf80167e48ea11a923c7386f4669df67d7994554387f84e7d8b0a2bf0"},
+]
+
+[[package]]
+name = "mccabe"
+version = "0.7.0"
+description = "McCabe checker, plugin for flake8"
+optional = false
+python-versions = ">=3.6"
+files = [
+    {file = "mccabe-0.7.0-py2.py3-none-any.whl", hash = "sha256:6c2d30ab6be0e4a46919781807b4f0d834ebdd6c6e3dca0bda5a15f863427b6e"},
+    {file = "mccabe-0.7.0.tar.gz", hash = "sha256:348e0240c33b60bbdf4e523192ef919f28cb2c3d7d5c7794f74009290f236325"},
+]
+
+[[package]]
+name = "msgspec"
+version = "0.18.6"
+description = "A fast serialization and validation library, with builtin support for JSON, MessagePack, YAML, and TOML."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "msgspec-0.18.6-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:77f30b0234eceeff0f651119b9821ce80949b4d667ad38f3bfed0d0ebf9d6d8f"},
+    {file = "msgspec-0.18.6-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:1a76b60e501b3932782a9da039bd1cd552b7d8dec54ce38332b87136c64852dd"},
+    {file = "msgspec-0.18.6-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:06acbd6edf175bee0e36295d6b0302c6de3aaf61246b46f9549ca0041a9d7177"},
+    {file = "msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:40a4df891676d9c28a67c2cc39947c33de516335680d1316a89e8f7218660410"},
+    {file = "msgspec-0.18.6-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:a6896f4cd5b4b7d688018805520769a8446df911eb93b421c6c68155cdf9dd5a"},
+    {file = "msgspec-0.18.6-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:3ac4dd63fd5309dd42a8c8c36c1563531069152be7819518be0a9d03be9788e4"},
+    {file = "msgspec-0.18.6-cp310-cp310-win_amd64.whl", hash = "sha256:fda4c357145cf0b760000c4ad597e19b53adf01382b711f281720a10a0fe72b7"},
+    {file = "msgspec-0.18.6-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:e77e56ffe2701e83a96e35770c6adb655ffc074d530018d1b584a8e635b4f36f"},
+    {file = "msgspec-0.18.6-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:d5351afb216b743df4b6b147691523697ff3a2fc5f3d54f771e91219f5c23aaa"},
+    {file = "msgspec-0.18.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c3232fabacef86fe8323cecbe99abbc5c02f7698e3f5f2e248e3480b66a3596b"},
+    {file = "msgspec-0.18.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e3b524df6ea9998bbc99ea6ee4d0276a101bcc1aa8d14887bb823914d9f60d07"},
+    {file = "msgspec-0.18.6-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:37f67c1d81272131895bb20d388dd8d341390acd0e192a55ab02d4d6468b434c"},
+    {file = "msgspec-0.18.6-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:d0feb7a03d971c1c0353de1a8fe30bb6579c2dc5ccf29b5f7c7ab01172010492"},
+    {file = "msgspec-0.18.6-cp311-cp311-win_amd64.whl", hash = "sha256:41cf758d3f40428c235c0f27bc6f322d43063bc32da7b9643e3f805c21ed57b4"},
+    {file = "msgspec-0.18.6-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:d86f5071fe33e19500920333c11e2267a31942d18fed4d9de5bc2fbab267d28c"},
+    {file = "msgspec-0.18.6-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:ce13981bfa06f5eb126a3a5a38b1976bddb49a36e4f46d8e6edecf33ccf11df1"},
+    {file = "msgspec-0.18.6-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e97dec6932ad5e3ee1e3c14718638ba333befc45e0661caa57033cd4cc489466"},
+    {file = "msgspec-0.18.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ad237100393f637b297926cae1868b0d500f764ccd2f0623a380e2bcfb2809ca"},
+    {file = "msgspec-0.18.6-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:db1d8626748fa5d29bbd15da58b2d73af25b10aa98abf85aab8028119188ed57"},
+    {file = "msgspec-0.18.6-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:d70cb3d00d9f4de14d0b31d38dfe60c88ae16f3182988246a9861259c6722af6"},
+    {file = "msgspec-0.18.6-cp312-cp312-win_amd64.whl", hash = "sha256:1003c20bfe9c6114cc16ea5db9c5466e49fae3d7f5e2e59cb70693190ad34da0"},
+    {file = "msgspec-0.18.6-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:f7d9faed6dfff654a9ca7d9b0068456517f63dbc3aa704a527f493b9200b210a"},
+    {file = "msgspec-0.18.6-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:9da21f804c1a1471f26d32b5d9bc0480450ea77fbb8d9db431463ab64aaac2cf"},
+    {file = "msgspec-0.18.6-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:46eb2f6b22b0e61c137e65795b97dc515860bf6ec761d8fb65fdb62aa094ba61"},
+    {file = "msgspec-0.18.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c8355b55c80ac3e04885d72db515817d9fbb0def3bab936bba104e99ad22cf46"},
+    {file = "msgspec-0.18.6-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:9080eb12b8f59e177bd1eb5c21e24dd2ba2fa88a1dbc9a98e05ad7779b54c681"},
+    {file = "msgspec-0.18.6-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:cc001cf39becf8d2dcd3f413a4797c55009b3a3cdbf78a8bf5a7ca8fdb76032c"},
+    {file = "msgspec-0.18.6-cp38-cp38-win_amd64.whl", hash = "sha256:fac5834e14ac4da1fca373753e0c4ec9c8069d1fe5f534fa5208453b6065d5be"},
+    {file = "msgspec-0.18.6-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:974d3520fcc6b824a6dedbdf2b411df31a73e6e7414301abac62e6b8d03791b4"},
+    {file = "msgspec-0.18.6-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:fd62e5818731a66aaa8e9b0a1e5543dc979a46278da01e85c3c9a1a4f047ef7e"},
+    {file = "msgspec-0.18.6-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7481355a1adcf1f08dedd9311193c674ffb8bf7b79314b4314752b89a2cf7f1c"},
+    {file = "msgspec-0.18.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6aa85198f8f154cf35d6f979998f6dadd3dc46a8a8c714632f53f5d65b315c07"},
+    {file = "msgspec-0.18.6-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:0e24539b25c85c8f0597274f11061c102ad6b0c56af053373ba4629772b407be"},
+    {file = "msgspec-0.18.6-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:c61ee4d3be03ea9cd089f7c8e36158786cd06e51fbb62529276452bbf2d52ece"},
+    {file = "msgspec-0.18.6-cp39-cp39-win_amd64.whl", hash = "sha256:b5c390b0b0b7da879520d4ae26044d74aeee5144f83087eb7842ba59c02bc090"},
+    {file = "msgspec-0.18.6.tar.gz", hash = "sha256:a59fc3b4fcdb972d09138cb516dbde600c99d07c38fd9372a6ef500d2d031b4e"},
+]
+
+[package.extras]
+dev = ["attrs", "coverage", "furo", "gcovr", "ipython", "msgpack", "mypy", "pre-commit", "pyright", "pytest", "pyyaml", "sphinx", "sphinx-copybutton", "sphinx-design", "tomli", "tomli-w"]
+doc = ["furo", "ipython", "sphinx", "sphinx-copybutton", "sphinx-design"]
+test = ["attrs", "msgpack", "mypy", "pyright", "pytest", "pyyaml", "tomli", "tomli-w"]
+toml = ["tomli", "tomli-w"]
+yaml = ["pyyaml"]
+
+[[package]]
+name = "mypy"
+version = "1.12.1"
+description = "Optional static typing for Python"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "mypy-1.12.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:3d7d4371829184e22fda4015278fbfdef0327a4b955a483012bd2d423a788801"},
+    {file = "mypy-1.12.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:f59f1dfbf497d473201356966e353ef09d4daec48caeacc0254db8ef633a28a5"},
+    {file = "mypy-1.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:b947097fae68004b8328c55161ac9db7d3566abfef72d9d41b47a021c2fba6b1"},
+    {file = "mypy-1.12.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:96af62050971c5241afb4701c15189ea9507db89ad07794a4ee7b4e092dc0627"},
+    {file = "mypy-1.12.1-cp310-cp310-win_amd64.whl", hash = "sha256:d90da248f4c2dba6c44ddcfea94bb361e491962f05f41990ff24dbd09969ce20"},
+    {file = "mypy-1.12.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:1230048fec1380faf240be6385e709c8570604d2d27ec6ca7e573e3bc09c3735"},
+    {file = "mypy-1.12.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:02dcfe270c6ea13338210908f8cadc8d31af0f04cee8ca996438fe6a97b4ec66"},
+    {file = "mypy-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:a5a437c9102a6a252d9e3a63edc191a3aed5f2fcb786d614722ee3f4472e33f6"},
+    {file = "mypy-1.12.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:186e0c8346efc027ee1f9acf5ca734425fc4f7dc2b60144f0fbe27cc19dc7931"},
+    {file = "mypy-1.12.1-cp311-cp311-win_amd64.whl", hash = "sha256:673ba1140a478b50e6d265c03391702fa11a5c5aff3f54d69a62a48da32cb811"},
+    {file = "mypy-1.12.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:9fb83a7be97c498176fb7486cafbb81decccaef1ac339d837c377b0ce3743a7f"},
+    {file = "mypy-1.12.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:389e307e333879c571029d5b93932cf838b811d3f5395ed1ad05086b52148fb0"},
+    {file = "mypy-1.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:94b2048a95a21f7a9ebc9fbd075a4fcd310410d078aa0228dbbad7f71335e042"},
+    {file = "mypy-1.12.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:4ee5932370ccf7ebf83f79d1c157a5929d7ea36313027b0d70a488493dc1b179"},
+    {file = "mypy-1.12.1-cp312-cp312-win_amd64.whl", hash = "sha256:19bf51f87a295e7ab2894f1d8167622b063492d754e69c3c2fed6563268cb42a"},
+    {file = "mypy-1.12.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:d34167d43613ffb1d6c6cdc0cc043bb106cac0aa5d6a4171f77ab92a3c758bcc"},
+    {file = "mypy-1.12.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:427878aa54f2e2c5d8db31fa9010c599ed9f994b3b49e64ae9cd9990c40bd635"},
+    {file = "mypy-1.12.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:5fcde63ea2c9f69d6be859a1e6dd35955e87fa81de95bc240143cf00de1f7f81"},
+    {file = "mypy-1.12.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:d54d840f6c052929f4a3d2aab2066af0f45a020b085fe0e40d4583db52aab4e4"},
+    {file = "mypy-1.12.1-cp313-cp313-win_amd64.whl", hash = "sha256:20db6eb1ca3d1de8ece00033b12f793f1ea9da767334b7e8c626a4872090cf02"},
+    {file = "mypy-1.12.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:b16fe09f9c741d85a2e3b14a5257a27a4f4886c171d562bc5a5e90d8591906b8"},
+    {file = "mypy-1.12.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:0dcc1e843d58f444fce19da4cce5bd35c282d4bde232acdeca8279523087088a"},
+    {file = "mypy-1.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:e10ba7de5c616e44ad21005fa13450cd0de7caaa303a626147d45307492e4f2d"},
+    {file = "mypy-1.12.1-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:0e6fe449223fa59fbee351db32283838a8fee8059e0028e9e6494a03802b4004"},
+    {file = "mypy-1.12.1-cp38-cp38-win_amd64.whl", hash = "sha256:dc6e2a2195a290a7fd5bac3e60b586d77fc88e986eba7feced8b778c373f9afe"},
+    {file = "mypy-1.12.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:de5b2a8988b4e1269a98beaf0e7cc71b510d050dce80c343b53b4955fff45f19"},
+    {file = "mypy-1.12.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:843826966f1d65925e8b50d2b483065c51fc16dc5d72647e0236aae51dc8d77e"},
+    {file = "mypy-1.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:9fe20f89da41a95e14c34b1ddb09c80262edcc295ad891f22cc4b60013e8f78d"},
+    {file = "mypy-1.12.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:8135ffec02121a75f75dc97c81af7c14aa4ae0dda277132cfcd6abcd21551bfd"},
+    {file = "mypy-1.12.1-cp39-cp39-win_amd64.whl", hash = "sha256:a7b76fa83260824300cc4834a3ab93180db19876bce59af921467fd03e692810"},
+    {file = "mypy-1.12.1-py3-none-any.whl", hash = "sha256:ce561a09e3bb9863ab77edf29ae3a50e65685ad74bba1431278185b7e5d5486e"},
+    {file = "mypy-1.12.1.tar.gz", hash = "sha256:f5b3936f7a6d0e8280c9bdef94c7ce4847f5cdfc258fbb2c29a8c1711e8bb96d"},
+]
+
+[package.dependencies]
+mypy-extensions = ">=1.0.0"
+tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
+typing-extensions = ">=4.6.0"
+
+[package.extras]
+dmypy = ["psutil (>=4.0)"]
+install-types = ["pip"]
+mypyc = ["setuptools (>=50)"]
+reports = ["lxml"]
+
+[[package]]
+name = "mypy-extensions"
+version = "1.0.0"
+description = "Type system extensions for programs checked with the mypy type checker."
+optional = false
+python-versions = ">=3.5"
+files = [
+    {file = "mypy_extensions-1.0.0-py3-none-any.whl", hash = "sha256:4392f6c0eb8a5668a69e23d168ffa70f0be9ccfd32b5cc2d26a34ae5b844552d"},
+    {file = "mypy_extensions-1.0.0.tar.gz", hash = "sha256:75dbf8955dc00442a438fc4d0666508a9a97b6bd41aa2f0ffe9d2f2725af0782"},
+]
+
+[[package]]
+name = "networkx"
+version = "3.1"
+description = "Python package for creating and manipulating graphs and networks"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "networkx-3.1-py3-none-any.whl", hash = "sha256:4f33f68cb2afcf86f28a45f43efc27a9386b535d567d2127f8f61d51dec58d36"},
+    {file = "networkx-3.1.tar.gz", hash = "sha256:de346335408f84de0eada6ff9fafafff9bcda11f0a0dfaa931133debb146ab61"},
+]
+
+[package.extras]
+default = ["matplotlib (>=3.4)", "numpy (>=1.20)", "pandas (>=1.3)", "scipy (>=1.8)"]
+developer = ["mypy (>=1.1)", "pre-commit (>=3.2)"]
+doc = ["nb2plots (>=0.6)", "numpydoc (>=1.5)", "pillow (>=9.4)", "pydata-sphinx-theme (>=0.13)", "sphinx (>=6.1)", "sphinx-gallery (>=0.12)", "texext (>=0.6.7)"]
+extra = ["lxml (>=4.6)", "pydot (>=1.4.2)", "pygraphviz (>=1.10)", "sympy (>=1.10)"]
+test = ["codecov (>=2.1)", "pytest (>=7.2)", "pytest-cov (>=4.0)"]
+
+[[package]]
+name = "ninja"
+version = "1.11.1.1"
+description = "Ninja is a small build system with a focus on speed"
+optional = false
+python-versions = "*"
+files = [
+    {file = "ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl", hash = "sha256:376889c76d87b95b5719fdd61dd7db193aa7fd4432e5d52d2e44e4c497bdbbee"},
+    {file = "ninja-1.11.1.1-py2.py3-none-manylinux1_i686.manylinux_2_5_i686.whl", hash = "sha256:ecf80cf5afd09f14dcceff28cb3f11dc90fb97c999c89307aea435889cb66877"},
+    {file = "ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl", hash = "sha256:84502ec98f02a037a169c4b0d5d86075eaf6afc55e1879003d6cab51ced2ea4b"},
+    {file = "ninja-1.11.1.1-py2.py3-none-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:73b93c14046447c7c5cc892433d4fae65d6364bec6685411cb97a8bcf815f93a"},
+    {file = "ninja-1.11.1.1-py2.py3-none-manylinux2014_ppc64le.manylinux_2_17_ppc64le.whl", hash = "sha256:18302d96a5467ea98b68e1cae1ae4b4fb2b2a56a82b955193c637557c7273dbd"},
+    {file = "ninja-1.11.1.1-py2.py3-none-manylinux2014_s390x.manylinux_2_17_s390x.whl", hash = "sha256:aad34a70ef15b12519946c5633344bc775a7656d789d9ed5fdb0d456383716ef"},
+    {file = "ninja-1.11.1.1-py2.py3-none-musllinux_1_1_aarch64.whl", hash = "sha256:d491fc8d89cdcb416107c349ad1e3a735d4c4af5e1cb8f5f727baca6350fdaea"},
+    {file = "ninja-1.11.1.1-py2.py3-none-musllinux_1_1_i686.whl", hash = "sha256:7563ce1d9fe6ed5af0b8dd9ab4a214bf4ff1f2f6fd6dc29f480981f0f8b8b249"},
+    {file = "ninja-1.11.1.1-py2.py3-none-musllinux_1_1_ppc64le.whl", hash = "sha256:9df724344202b83018abb45cb1efc22efd337a1496514e7e6b3b59655be85205"},
+    {file = "ninja-1.11.1.1-py2.py3-none-musllinux_1_1_s390x.whl", hash = "sha256:3e0f9be5bb20d74d58c66cc1c414c3e6aeb45c35b0d0e41e8d739c2c0d57784f"},
+    {file = "ninja-1.11.1.1-py2.py3-none-musllinux_1_1_x86_64.whl", hash = "sha256:76482ba746a2618eecf89d5253c0d1e4f1da1270d41e9f54dfbd91831b0f6885"},
+    {file = "ninja-1.11.1.1-py2.py3-none-win32.whl", hash = "sha256:fa2ba9d74acfdfbfbcf06fad1b8282de8a7a8c481d9dee45c859a8c93fcc1082"},
+    {file = "ninja-1.11.1.1-py2.py3-none-win_amd64.whl", hash = "sha256:95da904130bfa02ea74ff9c0116b4ad266174fafb1c707aa50212bc7859aebf1"},
+    {file = "ninja-1.11.1.1-py2.py3-none-win_arm64.whl", hash = "sha256:185e0641bde601e53841525c4196278e9aaf4463758da6dd1e752c0a0f54136a"},
+    {file = "ninja-1.11.1.1.tar.gz", hash = "sha256:9d793b08dd857e38d0b6ffe9e6b7145d7c485a42dcfea04905ca0cdb6017cc3c"},
+]
+
+[package.extras]
+test = ["codecov (>=2.0.5)", "coverage (>=4.2)", "flake8 (>=3.0.4)", "pytest (>=4.5.0)", "pytest-cov (>=2.7.1)", "pytest-runner (>=5.1)", "pytest-virtualenv (>=1.7.0)", "virtualenv (>=15.0.3)"]
+
+[[package]]
+name = "numpy"
+version = "1.26.4"
+description = "Fundamental package for array computing in Python"
+optional = false
+python-versions = ">=3.9"
+files = [
+    {file = "numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:9ff0f4f29c51e2803569d7a51c2304de5554655a60c5d776e35b4a41413830d0"},
+    {file = "numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:2e4ee3380d6de9c9ec04745830fd9e2eccb3e6cf790d39d7b98ffd19b0dd754a"},
+    {file = "numpy-1.26.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d209d8969599b27ad20994c8e41936ee0964e6da07478d6c35016bc386b66ad4"},
+    {file = "numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ffa75af20b44f8dba823498024771d5ac50620e6915abac414251bd971b4529f"},
+    {file = "numpy-1.26.4-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:62b8e4b1e28009ef2846b4c7852046736bab361f7aeadeb6a5b89ebec3c7055a"},
+    {file = "numpy-1.26.4-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:a4abb4f9001ad2858e7ac189089c42178fcce737e4169dc61321660f1a96c7d2"},
+    {file = "numpy-1.26.4-cp310-cp310-win32.whl", hash = "sha256:bfe25acf8b437eb2a8b2d49d443800a5f18508cd811fea3181723922a8a82b07"},
+    {file = "numpy-1.26.4-cp310-cp310-win_amd64.whl", hash = "sha256:b97fe8060236edf3662adfc2c633f56a08ae30560c56310562cb4f95500022d5"},
+    {file = "numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:4c66707fabe114439db9068ee468c26bbdf909cac0fb58686a42a24de1760c71"},
+    {file = "numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:edd8b5fe47dab091176d21bb6de568acdd906d1887a4584a15a9a96a1dca06ef"},
+    {file = "numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7ab55401287bfec946ced39700c053796e7cc0e3acbef09993a9ad2adba6ca6e"},
+    {file = "numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:666dbfb6ec68962c033a450943ded891bed2d54e6755e35e5835d63f4f6931d5"},
+    {file = "numpy-1.26.4-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:96ff0b2ad353d8f990b63294c8986f1ec3cb19d749234014f4e7eb0112ceba5a"},
+    {file = "numpy-1.26.4-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:60dedbb91afcbfdc9bc0b1f3f402804070deed7392c23eb7a7f07fa857868e8a"},
+    {file = "numpy-1.26.4-cp311-cp311-win32.whl", hash = "sha256:1af303d6b2210eb850fcf03064d364652b7120803a0b872f5211f5234b399f20"},
+    {file = "numpy-1.26.4-cp311-cp311-win_amd64.whl", hash = "sha256:cd25bcecc4974d09257ffcd1f098ee778f7834c3ad767fe5db785be9a4aa9cb2"},
+    {file = "numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:b3ce300f3644fb06443ee2222c2201dd3a89ea6040541412b8fa189341847218"},
+    {file = "numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:03a8c78d01d9781b28a6989f6fa1bb2c4f2d51201cf99d3dd875df6fbd96b23b"},
+    {file = "numpy-1.26.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9fad7dcb1aac3c7f0584a5a8133e3a43eeb2fe127f47e3632d43d677c66c102b"},
+    {file = "numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:675d61ffbfa78604709862923189bad94014bef562cc35cf61d3a07bba02a7ed"},
+    {file = "numpy-1.26.4-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:ab47dbe5cc8210f55aa58e4805fe224dac469cde56b9f731a4c098b91917159a"},
+    {file = "numpy-1.26.4-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:1dda2e7b4ec9dd512f84935c5f126c8bd8b9f2fc001e9f54af255e8c5f16b0e0"},
+    {file = "numpy-1.26.4-cp312-cp312-win32.whl", hash = "sha256:50193e430acfc1346175fcbdaa28ffec49947a06918b7b92130744e81e640110"},
+    {file = "numpy-1.26.4-cp312-cp312-win_amd64.whl", hash = "sha256:08beddf13648eb95f8d867350f6a018a4be2e5ad54c8d8caed89ebca558b2818"},
+    {file = "numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:7349ab0fa0c429c82442a27a9673fc802ffdb7c7775fad780226cb234965e53c"},
+    {file = "numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:52b8b60467cd7dd1e9ed082188b4e6bb35aa5cdd01777621a1658910745b90be"},
+    {file = "numpy-1.26.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d5241e0a80d808d70546c697135da2c613f30e28251ff8307eb72ba696945764"},
+    {file = "numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f870204a840a60da0b12273ef34f7051e98c3b5961b61b0c2c1be6dfd64fbcd3"},
+    {file = "numpy-1.26.4-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:679b0076f67ecc0138fd2ede3a8fd196dddc2ad3254069bcb9faf9a79b1cebcd"},
+    {file = "numpy-1.26.4-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:47711010ad8555514b434df65f7d7b076bb8261df1ca9bb78f53d3b2db02e95c"},
+    {file = "numpy-1.26.4-cp39-cp39-win32.whl", hash = "sha256:a354325ee03388678242a4d7ebcd08b5c727033fcff3b2f536aea978e15ee9e6"},
+    {file = "numpy-1.26.4-cp39-cp39-win_amd64.whl", hash = "sha256:3373d5d70a5fe74a2c1bb6d2cfd9609ecf686d47a2d7b1d37a8f3b6bf6003aea"},
+    {file = "numpy-1.26.4-pp39-pypy39_pp73-macosx_10_9_x86_64.whl", hash = "sha256:afedb719a9dcfc7eaf2287b839d8198e06dcd4cb5d276a3df279231138e83d30"},
+    {file = "numpy-1.26.4-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:95a7476c59002f2f6c590b9b7b998306fba6a5aa646b1e22ddfeaf8f78c3a29c"},
+    {file = "numpy-1.26.4-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:7e50d0a0cc3189f9cb0aeb3a6a6af18c16f59f004b866cd2be1c14b36134a4a0"},
+    {file = "numpy-1.26.4.tar.gz", hash = "sha256:2a02aba9ed12e4ac4eb3ea9421c420301a0c6460d9830d74a9df87efa4912010"},
+]
+
+[[package]]
+name = "ordered-set"
+version = "4.1.0"
+description = "An OrderedSet is a custom MutableSet that remembers its order, so that every"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "ordered-set-4.1.0.tar.gz", hash = "sha256:694a8e44c87657c59292ede72891eb91d34131f6531463aab3009191c77364a8"},
+    {file = "ordered_set-4.1.0-py3-none-any.whl", hash = "sha256:046e1132c71fcf3330438a539928932caf51ddbc582496833e23de611de14562"},
+]
+
+[package.extras]
+dev = ["black", "mypy", "pytest"]
+
+[[package]]
+name = "outcome"
+version = "1.3.0.post0"
+description = "Capture the outcome of Python function calls."
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "outcome-1.3.0.post0-py2.py3-none-any.whl", hash = "sha256:e771c5ce06d1415e356078d3bdd68523f284b4ce5419828922b6871e65eda82b"},
+    {file = "outcome-1.3.0.post0.tar.gz", hash = "sha256:9dcf02e65f2971b80047b377468e72a268e15c0af3cf1238e6ff14f7f91143b8"},
+]
+
+[package.dependencies]
+attrs = ">=19.2.0"
+
+[[package]]
+name = "packaging"
+version = "24.1"
+description = "Core utilities for Python packages"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "packaging-24.1-py3-none-any.whl", hash = "sha256:5b8f2217dbdbd2f7f384c41c628544e6d52f2d0f53c6d0c3ea61aa5d1d7ff124"},
+    {file = "packaging-24.1.tar.gz", hash = "sha256:026ed72c8ed3fcce5bf8950572258698927fd1dbda10a5e981cdf0ac37f4f002"},
+]
+
+[[package]]
+name = "pandas"
+version = "1.3.5"
+description = "Powerful data structures for data analysis, time series, and statistics"
+optional = false
+python-versions = ">=3.7.1"
+files = [
+    {file = "pandas-1.3.5-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:62d5b5ce965bae78f12c1c0df0d387899dd4211ec0bdc52822373f13a3a022b9"},
+    {file = "pandas-1.3.5-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:adfeb11be2d54f275142c8ba9bf67acee771b7186a5745249c7d5a06c670136b"},
+    {file = "pandas-1.3.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:60a8c055d58873ad81cae290d974d13dd479b82cbb975c3e1fa2cf1920715296"},
+    {file = "pandas-1.3.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fd541ab09e1f80a2a1760032d665f6e032d8e44055d602d65eeea6e6e85498cb"},
+    {file = "pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2651d75b9a167cc8cc572cf787ab512d16e316ae00ba81874b560586fa1325e0"},
+    {file = "pandas-1.3.5-cp310-cp310-win_amd64.whl", hash = "sha256:aaf183a615ad790801fa3cf2fa450e5b6d23a54684fe386f7e3208f8b9bfbef6"},
+    {file = "pandas-1.3.5-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:344295811e67f8200de2390093aeb3c8309f5648951b684d8db7eee7d1c81fb7"},
+    {file = "pandas-1.3.5-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:552020bf83b7f9033b57cbae65589c01e7ef1544416122da0c79140c93288f56"},
+    {file = "pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5cce0c6bbeb266b0e39e35176ee615ce3585233092f685b6a82362523e59e5b4"},
+    {file = "pandas-1.3.5-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:7d28a3c65463fd0d0ba8bbb7696b23073efee0510783340a44b08f5e96ffce0c"},
+    {file = "pandas-1.3.5-cp37-cp37m-win32.whl", hash = "sha256:a62949c626dd0ef7de11de34b44c6475db76995c2064e2d99c6498c3dba7fe58"},
+    {file = "pandas-1.3.5-cp37-cp37m-win_amd64.whl", hash = "sha256:8025750767e138320b15ca16d70d5cdc1886e8f9cc56652d89735c016cd8aea6"},
+    {file = "pandas-1.3.5-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:fe95bae4e2d579812865db2212bb733144e34d0c6785c0685329e5b60fcb85dd"},
+    {file = "pandas-1.3.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5f261553a1e9c65b7a310302b9dbac31cf0049a51695c14ebe04e4bfd4a96f02"},
+    {file = "pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8b6dbec5f3e6d5dc80dcfee250e0a2a652b3f28663492f7dab9a24416a48ac39"},
+    {file = "pandas-1.3.5-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d3bc49af96cd6285030a64779de5b3688633a07eb75c124b0747134a63f4c05f"},
+    {file = "pandas-1.3.5-cp38-cp38-win32.whl", hash = "sha256:b6b87b2fb39e6383ca28e2829cddef1d9fc9e27e55ad91ca9c435572cdba51bf"},
+    {file = "pandas-1.3.5-cp38-cp38-win_amd64.whl", hash = "sha256:a395692046fd8ce1edb4c6295c35184ae0c2bbe787ecbe384251da609e27edcb"},
+    {file = "pandas-1.3.5-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:bd971a3f08b745a75a86c00b97f3007c2ea175951286cdda6abe543e687e5f2f"},
+    {file = "pandas-1.3.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:37f06b59e5bc05711a518aa10beaec10942188dccb48918bb5ae602ccbc9f1a0"},
+    {file = "pandas-1.3.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2c21778a688d3712d35710501f8001cdbf96eb70a7c587a3d5613573299fdca6"},
+    {file = "pandas-1.3.5-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:3345343206546545bc26a05b4602b6a24385b5ec7c75cb6059599e3d56831da2"},
+    {file = "pandas-1.3.5-cp39-cp39-win32.whl", hash = "sha256:c69406a2808ba6cf580c2255bcf260b3f214d2664a3a4197d0e640f573b46fd3"},
+    {file = "pandas-1.3.5-cp39-cp39-win_amd64.whl", hash = "sha256:32e1a26d5ade11b547721a72f9bfc4bd113396947606e00d5b4a5b79b3dcb006"},
+    {file = "pandas-1.3.5.tar.gz", hash = "sha256:1e4285f5de1012de20ca46b188ccf33521bff61ba5c5ebd78b4fb28e5416a9f1"},
+]
+
+[package.dependencies]
+numpy = [
+    {version = ">=1.17.3", markers = "(platform_machine != \"aarch64\" and platform_machine != \"arm64\") and python_version < \"3.10\""},
+    {version = ">=1.19.2", markers = "platform_machine == \"aarch64\" and python_version < \"3.10\""},
+    {version = ">=1.20.0", markers = "platform_machine == \"arm64\" and python_version < \"3.10\""},
+    {version = ">=1.21.0", markers = "python_version >= \"3.10\""},
+]
+python-dateutil = ">=2.7.3"
+pytz = ">=2017.3"
+
+[package.extras]
+test = ["hypothesis (>=3.58)", "pytest (>=6.0)", "pytest-xdist"]
+
+[[package]]
+name = "perfetto"
+version = "0.10.0"
+description = "Python API for Perfetto's Trace Processor"
+optional = false
+python-versions = "*"
+files = [
+    {file = "perfetto-0.10.0.tar.gz", hash = "sha256:d6ead832a9aea2da26562977f0403e6fbefb70920041eb08791cfaf6689579c3"},
+]
+
+[package.dependencies]
+protobuf = "*"
+
+[[package]]
+name = "platformdirs"
+version = "4.3.6"
+description = "A small Python package for determining appropriate platform-specific dirs, e.g. a `user data dir`."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "platformdirs-4.3.6-py3-none-any.whl", hash = "sha256:73e575e1408ab8103900836b97580d5307456908a03e92031bab39e4554cc3fb"},
+    {file = "platformdirs-4.3.6.tar.gz", hash = "sha256:357fb2acbc885b0419afd3ce3ed34564c13c9b95c89360cd9563f73aa5e2b907"},
+]
+
+[package.extras]
+docs = ["furo (>=2024.8.6)", "proselint (>=0.14)", "sphinx (>=8.0.2)", "sphinx-autodoc-typehints (>=2.4)"]
+test = ["appdirs (==1.4.4)", "covdefaults (>=2.3)", "pytest (>=8.3.2)", "pytest-cov (>=5)", "pytest-mock (>=3.14)"]
+type = ["mypy (>=1.11.2)"]
+
+[[package]]
+name = "pluggy"
+version = "1.5.0"
+description = "plugin and hook calling mechanisms for python"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pluggy-1.5.0-py3-none-any.whl", hash = "sha256:44e1ad92c8ca002de6377e165f3e0f1be63266ab4d554740532335b9d75ea669"},
+    {file = "pluggy-1.5.0.tar.gz", hash = "sha256:2cffa88e94fdc978c4c574f15f9e59b7f4201d439195c3715ca9e2486f1d0cf1"},
+]
+
+[package.extras]
+dev = ["pre-commit", "tox"]
+testing = ["pytest", "pytest-benchmark"]
+
+[[package]]
+name = "protobuf"
+version = "4.25.5"
+description = ""
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "protobuf-4.25.5-cp310-abi3-win32.whl", hash = "sha256:5e61fd921603f58d2f5acb2806a929b4675f8874ff5f330b7d6f7e2e784bbcd8"},
+    {file = "protobuf-4.25.5-cp310-abi3-win_amd64.whl", hash = "sha256:4be0571adcbe712b282a330c6e89eae24281344429ae95c6d85e79e84780f5ea"},
+    {file = "protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl", hash = "sha256:b2fde3d805354df675ea4c7c6338c1aecd254dfc9925e88c6d31a2bcb97eb173"},
+    {file = "protobuf-4.25.5-cp37-abi3-manylinux2014_aarch64.whl", hash = "sha256:919ad92d9b0310070f8356c24b855c98df2b8bd207ebc1c0c6fcc9ab1e007f3d"},
+    {file = "protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl", hash = "sha256:fe14e16c22be926d3abfcb500e60cab068baf10b542b8c858fa27e098123e331"},
+    {file = "protobuf-4.25.5-cp38-cp38-win32.whl", hash = "sha256:98d8d8aa50de6a2747efd9cceba361c9034050ecce3e09136f90de37ddba66e1"},
+    {file = "protobuf-4.25.5-cp38-cp38-win_amd64.whl", hash = "sha256:b0234dd5a03049e4ddd94b93400b67803c823cfc405689688f59b34e0742381a"},
+    {file = "protobuf-4.25.5-cp39-cp39-win32.whl", hash = "sha256:abe32aad8561aa7cc94fc7ba4fdef646e576983edb94a73381b03c53728a626f"},
+    {file = "protobuf-4.25.5-cp39-cp39-win_amd64.whl", hash = "sha256:7a183f592dc80aa7c8da7ad9e55091c4ffc9497b3054452d629bb85fa27c2a45"},
+    {file = "protobuf-4.25.5-py3-none-any.whl", hash = "sha256:0aebecb809cae990f8129ada5ca273d9d670b76d9bfc9b1809f0a9c02b7dbf41"},
+    {file = "protobuf-4.25.5.tar.gz", hash = "sha256:7f8249476b4a9473645db7f8ab42b02fe1488cbe5fb72fddd445e0665afd8584"},
+]
+
+[[package]]
+name = "psutil"
+version = "5.9.8"
+description = "Cross-platform lib for process and system monitoring in Python."
+optional = false
+python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*"
+files = [
+    {file = "psutil-5.9.8-cp27-cp27m-macosx_10_9_x86_64.whl", hash = "sha256:26bd09967ae00920df88e0352a91cff1a78f8d69b3ecabbfe733610c0af486c8"},
+    {file = "psutil-5.9.8-cp27-cp27m-manylinux2010_i686.whl", hash = "sha256:05806de88103b25903dff19bb6692bd2e714ccf9e668d050d144012055cbca73"},
+    {file = "psutil-5.9.8-cp27-cp27m-manylinux2010_x86_64.whl", hash = "sha256:611052c4bc70432ec770d5d54f64206aa7203a101ec273a0cd82418c86503bb7"},
+    {file = "psutil-5.9.8-cp27-cp27mu-manylinux2010_i686.whl", hash = "sha256:50187900d73c1381ba1454cf40308c2bf6f34268518b3f36a9b663ca87e65e36"},
+    {file = "psutil-5.9.8-cp27-cp27mu-manylinux2010_x86_64.whl", hash = "sha256:02615ed8c5ea222323408ceba16c60e99c3f91639b07da6373fb7e6539abc56d"},
+    {file = "psutil-5.9.8-cp27-none-win32.whl", hash = "sha256:36f435891adb138ed3c9e58c6af3e2e6ca9ac2f365efe1f9cfef2794e6c93b4e"},
+    {file = "psutil-5.9.8-cp27-none-win_amd64.whl", hash = "sha256:bd1184ceb3f87651a67b2708d4c3338e9b10c5df903f2e3776b62303b26cb631"},
+    {file = "psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl", hash = "sha256:aee678c8720623dc456fa20659af736241f575d79429a0e5e9cf88ae0605cc81"},
+    {file = "psutil-5.9.8-cp36-abi3-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:8cb6403ce6d8e047495a701dc7c5bd788add903f8986d523e3e20b98b733e421"},
+    {file = "psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d06016f7f8625a1825ba3732081d77c94589dca78b7a3fc072194851e88461a4"},
+    {file = "psutil-5.9.8-cp36-cp36m-win32.whl", hash = "sha256:7d79560ad97af658a0f6adfef8b834b53f64746d45b403f225b85c5c2c140eee"},
+    {file = "psutil-5.9.8-cp36-cp36m-win_amd64.whl", hash = "sha256:27cc40c3493bb10de1be4b3f07cae4c010ce715290a5be22b98493509c6299e2"},
+    {file = "psutil-5.9.8-cp37-abi3-win32.whl", hash = "sha256:bc56c2a1b0d15aa3eaa5a60c9f3f8e3e565303b465dbf57a1b730e7a2b9844e0"},
+    {file = "psutil-5.9.8-cp37-abi3-win_amd64.whl", hash = "sha256:8db4c1b57507eef143a15a6884ca10f7c73876cdf5d51e713151c1236a0e68cf"},
+    {file = "psutil-5.9.8-cp38-abi3-macosx_11_0_arm64.whl", hash = "sha256:d16bbddf0693323b8c6123dd804100241da461e41d6e332fb0ba6058f630f8c8"},
+    {file = "psutil-5.9.8.tar.gz", hash = "sha256:6be126e3225486dff286a8fb9a06246a5253f4c7c53b475ea5f5ac934e64194c"},
+]
+
+[package.extras]
+test = ["enum34", "ipaddress", "mock", "pywin32", "wmi"]
+
+[[package]]
+name = "pycnite"
+version = "2024.7.31"
+description = "Python bytecode utilities"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pycnite-2024.7.31-py3-none-any.whl", hash = "sha256:9ff9c09d35056435b867e14ebf79626ca94b6017923a0bf9935377fa90d4cbb3"},
+    {file = "pycnite-2024.7.31.tar.gz", hash = "sha256:5125f1c95aef4a23b9bec3b32fae76873dcd46324fa68e39c10fa852ecdea340"},
+]
+
+[[package]]
+name = "pycparser"
+version = "2.22"
+description = "C parser in Python"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pycparser-2.22-py3-none-any.whl", hash = "sha256:c3702b6d3dd8c7abc1afa565d7e63d53a1d0bd86cdc24edd75470f4de499cfcc"},
+    {file = "pycparser-2.22.tar.gz", hash = "sha256:491c8be9c040f5390f5bf44a5b07752bd07f56edf992381b05c701439eec10f6"},
+]
+
+[[package]]
+name = "pydot"
+version = "3.0.2"
+description = "Python interface to Graphviz's Dot"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pydot-3.0.2-py3-none-any.whl", hash = "sha256:99cedaa55d04abb0b2bc56d9981a6da781053dd5ac75c428e8dd53db53f90b14"},
+    {file = "pydot-3.0.2.tar.gz", hash = "sha256:9180da540b51b3aa09fbf81140b3edfbe2315d778e8589a7d0a4a69c41332bae"},
+]
+
+[package.dependencies]
+pyparsing = ">=3.0.9"
+
+[package.extras]
+dev = ["chardet", "parameterized", "ruff"]
+release = ["zest.releaser[recommended]"]
+tests = ["chardet", "parameterized", "pytest", "pytest-cov", "pytest-xdist[psutil]", "ruff", "tox"]
+
+[[package]]
+name = "pyfakefs"
+version = "5.7.1"
+description = "pyfakefs implements a fake file system that mocks the Python file system modules."
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "pyfakefs-5.7.1-py3-none-any.whl", hash = "sha256:6503ffe7f401701cf974b502311f926da2b0657a72244a6ba36e985ceb3dd783"},
+    {file = "pyfakefs-5.7.1.tar.gz", hash = "sha256:24774c632f3b67ea26fd56b08115ba7c339d5cd65655410bca8572d73a1ae9a4"},
+]
+
+[[package]]
+name = "pylint"
+version = "3.3.1"
+description = "python code static checker"
+optional = false
+python-versions = ">=3.9.0"
+files = [
+    {file = "pylint-3.3.1-py3-none-any.whl", hash = "sha256:2f846a466dd023513240bc140ad2dd73bfc080a5d85a710afdb728c420a5a2b9"},
+    {file = "pylint-3.3.1.tar.gz", hash = "sha256:9f3dcc87b1203e612b78d91a896407787e708b3f189b5fa0b307712d49ff0c6e"},
+]
+
+[package.dependencies]
+astroid = ">=3.3.4,<=3.4.0-dev0"
+colorama = {version = ">=0.4.5", markers = "sys_platform == \"win32\""}
+dill = [
+    {version = ">=0.2", markers = "python_version < \"3.11\""},
+    {version = ">=0.3.6", markers = "python_version >= \"3.11\""},
+]
+isort = ">=4.2.5,<5.13.0 || >5.13.0,<6"
+mccabe = ">=0.6,<0.8"
+platformdirs = ">=2.2.0"
+tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
+tomlkit = ">=0.10.1"
+typing-extensions = {version = ">=3.10.0", markers = "python_version < \"3.10\""}
+
+[package.extras]
+spelling = ["pyenchant (>=3.2,<4.0)"]
+testutils = ["gitpython (>3)"]
+
+[[package]]
+name = "pyparsing"
+version = "3.2.0"
+description = "pyparsing module - Classes and methods to define and execute parsing grammars"
+optional = false
+python-versions = ">=3.9"
+files = [
+    {file = "pyparsing-3.2.0-py3-none-any.whl", hash = "sha256:93d9577b88da0bbea8cc8334ee8b918ed014968fd2ec383e868fb8afb1ccef84"},
+    {file = "pyparsing-3.2.0.tar.gz", hash = "sha256:cbf74e27246d595d9a74b186b810f6fbb86726dbf3b9532efb343f6d7294fe9c"},
+]
+
+[package.extras]
+diagrams = ["jinja2", "railroad-diagrams"]
+
+[[package]]
+name = "pysocks"
+version = "1.7.1"
+description = "A Python SOCKS client module. See https://github.com/Anorov/PySocks for more information."
+optional = false
+python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"
+files = [
+    {file = "PySocks-1.7.1-py27-none-any.whl", hash = "sha256:08e69f092cc6dbe92a0fdd16eeb9b9ffbc13cadfe5ca4c7bd92ffb078b293299"},
+    {file = "PySocks-1.7.1-py3-none-any.whl", hash = "sha256:2725bd0a9925919b9b51739eea5f9e2bae91e83288108a9ad338b2e3a4435ee5"},
+    {file = "PySocks-1.7.1.tar.gz", hash = "sha256:3f8804571ebe159c380ac6de37643bb4685970655d3bba243530d6558b799aa0"},
+]
+
+[[package]]
+name = "pytest"
+version = "7.4.4"
+description = "pytest: simple powerful testing with Python"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "pytest-7.4.4-py3-none-any.whl", hash = "sha256:b090cdf5ed60bf4c45261be03239c2c1c22df034fbffe691abe93cd80cea01d8"},
+    {file = "pytest-7.4.4.tar.gz", hash = "sha256:2cf0005922c6ace4a3e2ec8b4080eb0d9753fdc93107415332f50ce9e7994280"},
+]
+
+[package.dependencies]
+colorama = {version = "*", markers = "sys_platform == \"win32\""}
+exceptiongroup = {version = ">=1.0.0rc8", markers = "python_version < \"3.11\""}
+iniconfig = "*"
+packaging = "*"
+pluggy = ">=0.12,<2.0"
+tomli = {version = ">=1.0.0", markers = "python_version < \"3.11\""}
+
+[package.extras]
+testing = ["argcomplete", "attrs (>=19.2.0)", "hypothesis (>=3.56)", "mock", "nose", "pygments (>=2.7.2)", "requests", "setuptools", "xmlschema"]
+
+[[package]]
+name = "pytest-cov"
+version = "4.1.0"
+description = "Pytest plugin for measuring coverage."
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "pytest-cov-4.1.0.tar.gz", hash = "sha256:3904b13dfbfec47f003b8e77fd5b589cd11904a21ddf1ab38a64f204d6a10ef6"},
+    {file = "pytest_cov-4.1.0-py3-none-any.whl", hash = "sha256:6ba70b9e97e69fcc3fb45bfeab2d0a138fb65c4d0d6a41ef33983ad114be8c3a"},
+]
+
+[package.dependencies]
+coverage = {version = ">=5.2.1", extras = ["toml"]}
+pytest = ">=4.6"
+
+[package.extras]
+testing = ["fields", "hunter", "process-tests", "pytest-xdist", "six", "virtualenv"]
+
+[[package]]
+name = "pytest-profiling"
+version = "1.7.0"
+description = "Profiling plugin for py.test"
+optional = false
+python-versions = "*"
+files = [
+    {file = "pytest-profiling-1.7.0.tar.gz", hash = "sha256:93938f147662225d2b8bd5af89587b979652426a8a6ffd7e73ec4a23e24b7f29"},
+    {file = "pytest_profiling-1.7.0-py2.py3-none-any.whl", hash = "sha256:999cc9ac94f2e528e3f5d43465da277429984a1c237ae9818f8cfd0b06acb019"},
+]
+
+[package.dependencies]
+gprof2dot = "*"
+pytest = "*"
+six = "*"
+
+[package.extras]
+tests = ["pytest-virtualenv"]
+
+[[package]]
+name = "pytest-subtests"
+version = "0.11.0"
+description = "unittest subTest() support and subtests fixture"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "pytest-subtests-0.11.0.tar.gz", hash = "sha256:51865c88457545f51fb72011942f0a3c6901ee9e24cbfb6d1b9dc1348bafbe37"},
+    {file = "pytest_subtests-0.11.0-py3-none-any.whl", hash = "sha256:453389984952eec85ab0ce0c4f026337153df79587048271c7fd0f49119c07e4"},
+]
+
+[package.dependencies]
+attrs = ">=19.2.0"
+pytest = ">=7.0"
+
+[[package]]
+name = "pytest-xdist"
+version = "3.6.1"
+description = "pytest xdist plugin for distributed testing, most importantly across multiple CPUs"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pytest_xdist-3.6.1-py3-none-any.whl", hash = "sha256:9ed4adfb68a016610848639bb7e02c9352d5d9f03d04809919e2dafc3be4cca7"},
+    {file = "pytest_xdist-3.6.1.tar.gz", hash = "sha256:ead156a4db231eec769737f57668ef58a2084a34b2e55c4a8fa20d861107300d"},
+]
+
+[package.dependencies]
+execnet = ">=2.1"
+pytest = ">=7.0.0"
+
+[package.extras]
+psutil = ["psutil (>=3.0)"]
+setproctitle = ["setproctitle"]
+testing = ["filelock"]
+
+[[package]]
+name = "python-dateutil"
+version = "2.7.3"
+description = "Extensions to the standard Python datetime module"
+optional = false
+python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*"
+files = [
+    {file = "python-dateutil-2.7.3.tar.gz", hash = "sha256:e27001de32f627c22380a688bcc43ce83504a7bc5da472209b4c70f02829f0b8"},
+    {file = "python_dateutil-2.7.3-py2.py3-none-any.whl", hash = "sha256:1adb80e7a782c12e52ef9a8182bebeb73f1d7e24e374397af06fb4956c8dc5c0"},
+]
+
+[package.dependencies]
+six = ">=1.5"
+
+[[package]]
+name = "pytype"
+version = "2024.9.13"
+description = "Python type inferencer"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pytype-2024.9.13-cp310-cp310-macosx_12_0_x86_64.whl", hash = "sha256:52c0005d220b27f9c933e4077de700c4e8171abce0c2af72f4c6263a85ff5bce"},
+    {file = "pytype-2024.9.13-cp310-cp310-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:2d5dc847c2fe98bac044f956e2fc9f074f09704b64436522b81ede7dd5fa3653"},
+    {file = "pytype-2024.9.13-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:529f19141c6170d96a38909df430ca52e6904eaef851ad2690cf632f17d2c195"},
+    {file = "pytype-2024.9.13-cp311-cp311-macosx_10_14_universal2.whl", hash = "sha256:38f3eddf05d8530ef16d3d7c2da2556148b9975fc7c3405ac3073022e1a7434b"},
+    {file = "pytype-2024.9.13-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:1b530eae5ab421a2dc9c4ef53f68629c5a622545150ae9702dbb811f56852a63"},
+    {file = "pytype-2024.9.13-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:eb9eaaaf6c33e2716fdce1cf4166d3e5099372d8898b69ab7673225928096456"},
+    {file = "pytype-2024.9.13-cp312-cp312-macosx_10_14_universal2.whl", hash = "sha256:53b767d85f374c7483c8b2849dceb811a15fcb01520e245dd82bd7c0e2befefb"},
+    {file = "pytype-2024.9.13-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:176a5bbc0cb0882918a0b48818b95df2c15811e3a8391da089ffc5b33fea7013"},
+    {file = "pytype-2024.9.13-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:7bdaf1eaaf17a13741f67686c2d4c94c30279cd682c7e4cf535e41fc911b0e59"},
+    {file = "pytype-2024.9.13-cp38-cp38-macosx_12_0_x86_64.whl", hash = "sha256:425011cc45fba8c83af796155049f9db89d11e8aedbfb21bc1c99408f4a2c4e3"},
+    {file = "pytype-2024.9.13-cp38-cp38-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:6e500727967b843488c1978114778162ef00fee9be49dfa5b4758dcbbcc55dd9"},
+    {file = "pytype-2024.9.13-cp38-cp38-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:b9b40beab6ef04fc260d86a8ef47b25d1b525dbc4cfbcb73151fd74210c176df"},
+    {file = "pytype-2024.9.13-cp39-cp39-macosx_12_0_x86_64.whl", hash = "sha256:b5fdc24b60938ee846dfbdf08b5ea96e934e7d69c34eb1f8fb7707083d177f0e"},
+    {file = "pytype-2024.9.13-cp39-cp39-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:8dcfd509118c2d7e0787e72832b45e30037af1c29dfcb733a7e8014f58337287"},
+    {file = "pytype-2024.9.13-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:9df731062dc18518a46135c4825ad966e1a275ffc0723dd62f9771b420889da0"},
+    {file = "pytype-2024.9.13.tar.gz", hash = "sha256:941046ca0f1c43b79162bb51836fef0ba6608012d99f6833148c249f22216f26"},
+]
+
+[package.dependencies]
+attrs = ">=21.4.0"
+immutabledict = ">=4.1.0"
+importlab = ">=0.8"
+jinja2 = ">=3.1.2"
+libcst = ">=1.0.1"
+msgspec = ">=0.18.6"
+networkx = "<3.2"
+ninja = ">=1.10.0.post2"
+pycnite = ">=2024.07.31"
+pydot = ">=1.4.2"
+tabulate = ">=0.8.10"
+toml = ">=0.10.2"
+typing-extensions = ">=4.3.0"
+
+[[package]]
+name = "pytz"
+version = "2024.2"
+description = "World timezone definitions, modern and historical"
+optional = false
+python-versions = "*"
+files = [
+    {file = "pytz-2024.2-py2.py3-none-any.whl", hash = "sha256:31c7c1817eb7fae7ca4b8c7ee50c72f93aa2dd863de768e1ef4245d426aa0725"},
+    {file = "pytz-2024.2.tar.gz", hash = "sha256:2aa355083c50a0f93fa581709deac0c9ad65cca8a9e9beac660adcbd493c798a"},
+]
+
+[[package]]
+name = "pyyaml"
+version = "6.0.2"
+description = "YAML parser and emitter for Python"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:0a9a2848a5b7feac301353437eb7d5957887edbf81d56e903999a75a3d743086"},
+    {file = "PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:29717114e51c84ddfba879543fb232a6ed60086602313ca38cce623c1d62cfbf"},
+    {file = "PyYAML-6.0.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8824b5a04a04a047e72eea5cec3bc266db09e35de6bdfe34c9436ac5ee27d237"},
+    {file = "PyYAML-6.0.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:7c36280e6fb8385e520936c3cb3b8042851904eba0e58d277dca80a5cfed590b"},
+    {file = "PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ec031d5d2feb36d1d1a24380e4db6d43695f3748343d99434e6f5f9156aaa2ed"},
+    {file = "PyYAML-6.0.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:936d68689298c36b53b29f23c6dbb74de12b4ac12ca6cfe0e047bedceea56180"},
+    {file = "PyYAML-6.0.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:23502f431948090f597378482b4812b0caae32c22213aecf3b55325e049a6c68"},
+    {file = "PyYAML-6.0.2-cp310-cp310-win32.whl", hash = "sha256:2e99c6826ffa974fe6e27cdb5ed0021786b03fc98e5ee3c5bfe1fd5015f42b99"},
+    {file = "PyYAML-6.0.2-cp310-cp310-win_amd64.whl", hash = "sha256:a4d3091415f010369ae4ed1fc6b79def9416358877534caf6a0fdd2146c87a3e"},
+    {file = "PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:cc1c1159b3d456576af7a3e4d1ba7e6924cb39de8f67111c735f6fc832082774"},
+    {file = "PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:1e2120ef853f59c7419231f3bf4e7021f1b936f6ebd222406c3b60212205d2ee"},
+    {file = "PyYAML-6.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5d225db5a45f21e78dd9358e58a98702a0302f2659a3c6cd320564b75b86f47c"},
+    {file = "PyYAML-6.0.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5ac9328ec4831237bec75defaf839f7d4564be1e6b25ac710bd1a96321cc8317"},
+    {file = "PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3ad2a3decf9aaba3d29c8f537ac4b243e36bef957511b4766cb0057d32b0be85"},
+    {file = "PyYAML-6.0.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:ff3824dc5261f50c9b0dfb3be22b4567a6f938ccce4587b38952d85fd9e9afe4"},
+    {file = "PyYAML-6.0.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:797b4f722ffa07cc8d62053e4cff1486fa6dc094105d13fea7b1de7d8bf71c9e"},
+    {file = "PyYAML-6.0.2-cp311-cp311-win32.whl", hash = "sha256:11d8f3dd2b9c1207dcaf2ee0bbbfd5991f571186ec9cc78427ba5bd32afae4b5"},
+    {file = "PyYAML-6.0.2-cp311-cp311-win_amd64.whl", hash = "sha256:e10ce637b18caea04431ce14fabcf5c64a1c61ec9c56b071a4b7ca131ca52d44"},
+    {file = "PyYAML-6.0.2-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:c70c95198c015b85feafc136515252a261a84561b7b1d51e3384e0655ddf25ab"},
+    {file = "PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:ce826d6ef20b1bc864f0a68340c8b3287705cae2f8b4b1d932177dcc76721725"},
+    {file = "PyYAML-6.0.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1f71ea527786de97d1a0cc0eacd1defc0985dcf6b3f17bb77dcfc8c34bec4dc5"},
+    {file = "PyYAML-6.0.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:9b22676e8097e9e22e36d6b7bda33190d0d400f345f23d4065d48f4ca7ae0425"},
+    {file = "PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:80bab7bfc629882493af4aa31a4cfa43a4c57c83813253626916b8c7ada83476"},
+    {file = "PyYAML-6.0.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:0833f8694549e586547b576dcfaba4a6b55b9e96098b36cdc7ebefe667dfed48"},
+    {file = "PyYAML-6.0.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:8b9c7197f7cb2738065c481a0461e50ad02f18c78cd75775628afb4d7137fb3b"},
+    {file = "PyYAML-6.0.2-cp312-cp312-win32.whl", hash = "sha256:ef6107725bd54b262d6dedcc2af448a266975032bc85ef0172c5f059da6325b4"},
+    {file = "PyYAML-6.0.2-cp312-cp312-win_amd64.whl", hash = "sha256:7e7401d0de89a9a855c839bc697c079a4af81cf878373abd7dc625847d25cbd8"},
+    {file = "PyYAML-6.0.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:efdca5630322a10774e8e98e1af481aad470dd62c3170801852d752aa7a783ba"},
+    {file = "PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:50187695423ffe49e2deacb8cd10510bc361faac997de9efef88badc3bb9e2d1"},
+    {file = "PyYAML-6.0.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0ffe8360bab4910ef1b9e87fb812d8bc0a308b0d0eef8c8f44e0254ab3b07133"},
+    {file = "PyYAML-6.0.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:17e311b6c678207928d649faa7cb0d7b4c26a0ba73d41e99c4fff6b6c3276484"},
+    {file = "PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:70b189594dbe54f75ab3a1acec5f1e3faa7e8cf2f1e08d9b561cb41b845f69d5"},
+    {file = "PyYAML-6.0.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:41e4e3953a79407c794916fa277a82531dd93aad34e29c2a514c2c0c5fe971cc"},
+    {file = "PyYAML-6.0.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:68ccc6023a3400877818152ad9a1033e3db8625d899c72eacb5a668902e4d652"},
+    {file = "PyYAML-6.0.2-cp313-cp313-win32.whl", hash = "sha256:bc2fa7c6b47d6bc618dd7fb02ef6fdedb1090ec036abab80d4681424b84c1183"},
+    {file = "PyYAML-6.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:8388ee1976c416731879ac16da0aff3f63b286ffdd57cdeb95f3f2e085687563"},
+    {file = "PyYAML-6.0.2-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:24471b829b3bf607e04e88d79542a9d48bb037c2267d7927a874e6c205ca7e9a"},
+    {file = "PyYAML-6.0.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d7fded462629cfa4b685c5416b949ebad6cec74af5e2d42905d41e257e0869f5"},
+    {file = "PyYAML-6.0.2-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:d84a1718ee396f54f3a086ea0a66d8e552b2ab2017ef8b420e92edbc841c352d"},
+    {file = "PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9056c1ecd25795207ad294bcf39f2db3d845767be0ea6e6a34d856f006006083"},
+    {file = "PyYAML-6.0.2-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:82d09873e40955485746739bcb8b4586983670466c23382c19cffecbf1fd8706"},
+    {file = "PyYAML-6.0.2-cp38-cp38-win32.whl", hash = "sha256:43fa96a3ca0d6b1812e01ced1044a003533c47f6ee8aca31724f78e93ccc089a"},
+    {file = "PyYAML-6.0.2-cp38-cp38-win_amd64.whl", hash = "sha256:01179a4a8559ab5de078078f37e5c1a30d76bb88519906844fd7bdea1b7729ff"},
+    {file = "PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:688ba32a1cffef67fd2e9398a2efebaea461578b0923624778664cc1c914db5d"},
+    {file = "PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a8786accb172bd8afb8be14490a16625cbc387036876ab6ba70912730faf8e1f"},
+    {file = "PyYAML-6.0.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d8e03406cac8513435335dbab54c0d385e4a49e4945d2909a581c83647ca0290"},
+    {file = "PyYAML-6.0.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f753120cb8181e736c57ef7636e83f31b9c0d1722c516f7e86cf15b7aa57ff12"},
+    {file = "PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3b1fdb9dc17f5a7677423d508ab4f243a726dea51fa5e70992e59a7411c89d19"},
+    {file = "PyYAML-6.0.2-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:0b69e4ce7a131fe56b7e4d770c67429700908fc0752af059838b1cfb41960e4e"},
+    {file = "PyYAML-6.0.2-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:a9f8c2e67970f13b16084e04f134610fd1d374bf477b17ec1599185cf611d725"},
+    {file = "PyYAML-6.0.2-cp39-cp39-win32.whl", hash = "sha256:6395c297d42274772abc367baaa79683958044e5d3835486c16da75d2a694631"},
+    {file = "PyYAML-6.0.2-cp39-cp39-win_amd64.whl", hash = "sha256:39693e1f8320ae4f43943590b49779ffb98acb81f788220ea932a6b6c51004d8"},
+    {file = "pyyaml-6.0.2.tar.gz", hash = "sha256:d584d9ec91ad65861cc08d42e834324ef890a082e591037abe114850ff7bbc3e"},
+]
+
+[[package]]
+name = "selenium"
+version = "4.25.0"
+description = "Official Python bindings for Selenium WebDriver"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "selenium-4.25.0-py3-none-any.whl", hash = "sha256:3798d2d12b4a570bc5790163ba57fef10b2afee958bf1d80f2a3cf07c4141f33"},
+    {file = "selenium-4.25.0.tar.gz", hash = "sha256:95d08d3b82fb353f3c474895154516604c7f0e6a9a565ae6498ef36c9bac6921"},
+]
+
+[package.dependencies]
+certifi = ">=2021.10.8"
+trio = ">=0.17,<1.0"
+trio-websocket = ">=0.9,<1.0"
+typing_extensions = ">=4.9,<5.0"
+urllib3 = {version = ">=1.26,<3", extras = ["socks"]}
+websocket-client = ">=1.8,<2.0"
+
+[[package]]
+name = "six"
+version = "1.16.0"
+description = "Python 2 and 3 compatibility utilities"
+optional = false
+python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*"
+files = [
+    {file = "six-1.16.0-py2.py3-none-any.whl", hash = "sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254"},
+    {file = "six-1.16.0.tar.gz", hash = "sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926"},
+]
+
+[[package]]
+name = "sniffio"
+version = "1.3.1"
+description = "Sniff out which async library your code is running under"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "sniffio-1.3.1-py3-none-any.whl", hash = "sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2"},
+    {file = "sniffio-1.3.1.tar.gz", hash = "sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc"},
+]
+
+[[package]]
+name = "sortedcontainers"
+version = "2.4.0"
+description = "Sorted Containers -- Sorted List, Sorted Dict, Sorted Set"
+optional = false
+python-versions = "*"
+files = [
+    {file = "sortedcontainers-2.4.0-py2.py3-none-any.whl", hash = "sha256:a163dcaede0f1c021485e957a39245190e74249897e2ae4b2aa38595db237ee0"},
+    {file = "sortedcontainers-2.4.0.tar.gz", hash = "sha256:25caa5a06cc30b6b83d11423433f65d1f9d76c4c6a0c90e3379eaa43b9bfdb88"},
+]
+
+[[package]]
+name = "tabulate"
+version = "0.8.10"
+description = "Pretty-print tabular data"
+optional = false
+python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"
+files = [
+    {file = "tabulate-0.8.10-py3-none-any.whl", hash = "sha256:0ba055423dbaa164b9e456abe7920c5e8ed33fcc16f6d1b2f2d152c8e1e8b4fc"},
+    {file = "tabulate-0.8.10.tar.gz", hash = "sha256:6c57f3f3dd7ac2782770155f3adb2db0b1a269637e42f27599925e64b114f519"},
+]
+
+[package.extras]
+widechars = ["wcwidth"]
+
+[[package]]
+name = "toml"
+version = "0.10.2"
+description = "Python Library for Tom's Obvious, Minimal Language"
+optional = false
+python-versions = ">=2.6, !=3.0.*, !=3.1.*, !=3.2.*"
+files = [
+    {file = "toml-0.10.2-py2.py3-none-any.whl", hash = "sha256:806143ae5bfb6a3c6e736a764057db0e6a0e05e338b5630894a5f779cabb4f9b"},
+    {file = "toml-0.10.2.tar.gz", hash = "sha256:b3bda1d108d5dd99f4a20d24d9c348e91c4db7ab1b749200bded2f839ccbe68f"},
+]
+
+[[package]]
+name = "tomli"
+version = "2.0.2"
+description = "A lil' TOML parser"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "tomli-2.0.2-py3-none-any.whl", hash = "sha256:2ebe24485c53d303f690b0ec092806a085f07af5a5aa1464f3931eec36caaa38"},
+    {file = "tomli-2.0.2.tar.gz", hash = "sha256:d46d457a85337051c36524bc5349dd91b1877838e2979ac5ced3e710ed8a60ed"},
+]
+
+[[package]]
+name = "tomlkit"
+version = "0.13.2"
+description = "Style preserving TOML library"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "tomlkit-0.13.2-py3-none-any.whl", hash = "sha256:7a974427f6e119197f670fbbbeae7bef749a6c14e793db934baefc1b5f03efde"},
+    {file = "tomlkit-0.13.2.tar.gz", hash = "sha256:fff5fe59a87295b278abd31bec92c15d9bc4a06885ab12bcea52c71119392e79"},
+]
+
+[[package]]
+name = "trio"
+version = "0.27.0"
+description = "A friendly Python library for async concurrency and I/O"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "trio-0.27.0-py3-none-any.whl", hash = "sha256:68eabbcf8f457d925df62da780eff15ff5dc68fd6b367e2dde59f7aaf2a0b884"},
+    {file = "trio-0.27.0.tar.gz", hash = "sha256:1dcc95ab1726b2da054afea8fd761af74bad79bd52381b84eae408e983c76831"},
+]
+
+[package.dependencies]
+attrs = ">=23.2.0"
+cffi = {version = ">=1.14", markers = "os_name == \"nt\" and implementation_name != \"pypy\""}
+exceptiongroup = {version = "*", markers = "python_version < \"3.11\""}
+idna = "*"
+outcome = "*"
+sniffio = ">=1.3.0"
+sortedcontainers = "*"
+
+[[package]]
+name = "trio-websocket"
+version = "0.11.1"
+description = "WebSocket library for Trio"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "trio-websocket-0.11.1.tar.gz", hash = "sha256:18c11793647703c158b1f6e62de638acada927344d534e3c7628eedcb746839f"},
+    {file = "trio_websocket-0.11.1-py3-none-any.whl", hash = "sha256:520d046b0d030cf970b8b2b2e00c4c2245b3807853ecd44214acd33d74581638"},
+]
+
+[package.dependencies]
+exceptiongroup = {version = "*", markers = "python_version < \"3.11\""}
+trio = ">=0.11"
+wsproto = ">=0.14"
+
+[[package]]
+name = "typing-extensions"
+version = "4.12.2"
+description = "Backported and Experimental Type Hints for Python 3.8+"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "typing_extensions-4.12.2-py3-none-any.whl", hash = "sha256:04e5ca0351e0f3f85c6853954072df659d0d13fac324d0072316b67d7794700d"},
+    {file = "typing_extensions-4.12.2.tar.gz", hash = "sha256:1a7ead55c7e559dd4dee8856e3a88b41225abfe1ce8df57b7c13915fe121ffb8"},
+]
+
+[[package]]
+name = "urllib3"
+version = "2.2.3"
+description = "HTTP library with thread-safe connection pooling, file post, and more."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "urllib3-2.2.3-py3-none-any.whl", hash = "sha256:ca899ca043dcb1bafa3e262d73aa25c465bfb49e0bd9dd5d59f1d0acba2f8fac"},
+    {file = "urllib3-2.2.3.tar.gz", hash = "sha256:e7d814a81dad81e6caf2ec9fdedb284ecc9c73076b62654547cc64ccdcae26e9"},
+]
+
+[package.dependencies]
+pysocks = {version = ">=1.5.6,<1.5.7 || >1.5.7,<2.0", optional = true, markers = "extra == \"socks\""}
+
+[package.extras]
+brotli = ["brotli (>=1.0.9)", "brotlicffi (>=0.8.0)"]
+h2 = ["h2 (>=4,<5)"]
+socks = ["pysocks (>=1.5.6,!=1.5.7,<2.0)"]
+zstd = ["zstandard (>=0.18.0)"]
+
+[[package]]
+name = "websocket-client"
+version = "1.8.0"
+description = "WebSocket client for Python with low level API options"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "websocket_client-1.8.0-py3-none-any.whl", hash = "sha256:17b44cc997f5c498e809b22cdf2d9c7a9e71c02c8cc2b6c56e7c2d1239bfa526"},
+    {file = "websocket_client-1.8.0.tar.gz", hash = "sha256:3239df9f44da632f96012472805d40a23281a991027ce11d2f45a6f24ac4c3da"},
+]
+
+[package.extras]
+docs = ["Sphinx (>=6.0)", "myst-parser (>=2.0.0)", "sphinx-rtd-theme (>=1.1.0)"]
+optional = ["python-socks", "wsaccel"]
+test = ["websockets"]
+
+[[package]]
+name = "websockets"
+version = "11.0.3"
+description = "An implementation of the WebSocket Protocol (RFC 6455 & 7692)"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "websockets-11.0.3-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:3ccc8a0c387629aec40f2fc9fdcb4b9d5431954f934da3eaf16cdc94f67dbfac"},
+    {file = "websockets-11.0.3-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:d67ac60a307f760c6e65dad586f556dde58e683fab03323221a4e530ead6f74d"},
+    {file = "websockets-11.0.3-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:84d27a4832cc1a0ee07cdcf2b0629a8a72db73f4cf6de6f0904f6661227f256f"},
+    {file = "websockets-11.0.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ffd7dcaf744f25f82190856bc26ed81721508fc5cbf2a330751e135ff1283564"},
+    {file = "websockets-11.0.3-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:7622a89d696fc87af8e8d280d9b421db5133ef5b29d3f7a1ce9f1a7bf7fcfa11"},
+    {file = "websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bceab846bac555aff6427d060f2fcfff71042dba6f5fca7dc4f75cac815e57ca"},
+    {file = "websockets-11.0.3-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:54c6e5b3d3a8936a4ab6870d46bdd6ec500ad62bde9e44462c32d18f1e9a8e54"},
+    {file = "websockets-11.0.3-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:41f696ba95cd92dc047e46b41b26dd24518384749ed0d99bea0a941ca87404c4"},
+    {file = "websockets-11.0.3-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:86d2a77fd490ae3ff6fae1c6ceaecad063d3cc2320b44377efdde79880e11526"},
+    {file = "websockets-11.0.3-cp310-cp310-win32.whl", hash = "sha256:2d903ad4419f5b472de90cd2d40384573b25da71e33519a67797de17ef849b69"},
+    {file = "websockets-11.0.3-cp310-cp310-win_amd64.whl", hash = "sha256:1d2256283fa4b7f4c7d7d3e84dc2ece74d341bce57d5b9bf385df109c2a1a82f"},
+    {file = "websockets-11.0.3-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:e848f46a58b9fcf3d06061d17be388caf70ea5b8cc3466251963c8345e13f7eb"},
+    {file = "websockets-11.0.3-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:aa5003845cdd21ac0dc6c9bf661c5beddd01116f6eb9eb3c8e272353d45b3288"},
+    {file = "websockets-11.0.3-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:b58cbf0697721120866820b89f93659abc31c1e876bf20d0b3d03cef14faf84d"},
+    {file = "websockets-11.0.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:660e2d9068d2bedc0912af508f30bbeb505bbbf9774d98def45f68278cea20d3"},
+    {file = "websockets-11.0.3-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c1f0524f203e3bd35149f12157438f406eff2e4fb30f71221c8a5eceb3617b6b"},
+    {file = "websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:def07915168ac8f7853812cc593c71185a16216e9e4fa886358a17ed0fd9fcf6"},
+    {file = "websockets-11.0.3-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:b30c6590146e53149f04e85a6e4fcae068df4289e31e4aee1fdf56a0dead8f97"},
+    {file = "websockets-11.0.3-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:619d9f06372b3a42bc29d0cd0354c9bb9fb39c2cbc1a9c5025b4538738dbffaf"},
+    {file = "websockets-11.0.3-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:01f5567d9cf6f502d655151645d4e8b72b453413d3819d2b6f1185abc23e82dd"},
+    {file = "websockets-11.0.3-cp311-cp311-win32.whl", hash = "sha256:e1459677e5d12be8bbc7584c35b992eea142911a6236a3278b9b5ce3326f282c"},
+    {file = "websockets-11.0.3-cp311-cp311-win_amd64.whl", hash = "sha256:e7837cb169eca3b3ae94cc5787c4fed99eef74c0ab9506756eea335e0d6f3ed8"},
+    {file = "websockets-11.0.3-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:9f59a3c656fef341a99e3d63189852be7084c0e54b75734cde571182c087b152"},
+    {file = "websockets-11.0.3-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2529338a6ff0eb0b50c7be33dc3d0e456381157a31eefc561771ee431134a97f"},
+    {file = "websockets-11.0.3-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:34fd59a4ac42dff6d4681d8843217137f6bc85ed29722f2f7222bd619d15e95b"},
+    {file = "websockets-11.0.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:332d126167ddddec94597c2365537baf9ff62dfcc9db4266f263d455f2f031cb"},
+    {file = "websockets-11.0.3-cp37-cp37m-musllinux_1_1_aarch64.whl", hash = "sha256:6505c1b31274723ccaf5f515c1824a4ad2f0d191cec942666b3d0f3aa4cb4007"},
+    {file = "websockets-11.0.3-cp37-cp37m-musllinux_1_1_i686.whl", hash = "sha256:f467ba0050b7de85016b43f5a22b46383ef004c4f672148a8abf32bc999a87f0"},
+    {file = "websockets-11.0.3-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:9d9acd80072abcc98bd2c86c3c9cd4ac2347b5a5a0cae7ed5c0ee5675f86d9af"},
+    {file = "websockets-11.0.3-cp37-cp37m-win32.whl", hash = "sha256:e590228200fcfc7e9109509e4d9125eace2042fd52b595dd22bbc34bb282307f"},
+    {file = "websockets-11.0.3-cp37-cp37m-win_amd64.whl", hash = "sha256:b16fff62b45eccb9c7abb18e60e7e446998093cdcb50fed33134b9b6878836de"},
+    {file = "websockets-11.0.3-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:fb06eea71a00a7af0ae6aefbb932fb8a7df3cb390cc217d51a9ad7343de1b8d0"},
+    {file = "websockets-11.0.3-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:8a34e13a62a59c871064dfd8ffb150867e54291e46d4a7cf11d02c94a5275bae"},
+    {file = "websockets-11.0.3-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:4841ed00f1026dfbced6fca7d963c4e7043aa832648671b5138008dc5a8f6d99"},
+    {file = "websockets-11.0.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1a073fc9ab1c8aff37c99f11f1641e16da517770e31a37265d2755282a5d28aa"},
+    {file = "websockets-11.0.3-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:68b977f21ce443d6d378dbd5ca38621755f2063d6fdb3335bda981d552cfff86"},
+    {file = "websockets-11.0.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e1a99a7a71631f0efe727c10edfba09ea6bee4166a6f9c19aafb6c0b5917d09c"},
+    {file = "websockets-11.0.3-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:bee9fcb41db2a23bed96c6b6ead6489702c12334ea20a297aa095ce6d31370d0"},
+    {file = "websockets-11.0.3-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:4b253869ea05a5a073ebfdcb5cb3b0266a57c3764cf6fe114e4cd90f4bfa5f5e"},
+    {file = "websockets-11.0.3-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:1553cb82942b2a74dd9b15a018dce645d4e68674de2ca31ff13ebc2d9f283788"},
+    {file = "websockets-11.0.3-cp38-cp38-win32.whl", hash = "sha256:f61bdb1df43dc9c131791fbc2355535f9024b9a04398d3bd0684fc16ab07df74"},
+    {file = "websockets-11.0.3-cp38-cp38-win_amd64.whl", hash = "sha256:03aae4edc0b1c68498f41a6772d80ac7c1e33c06c6ffa2ac1c27a07653e79d6f"},
+    {file = "websockets-11.0.3-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:777354ee16f02f643a4c7f2b3eff8027a33c9861edc691a2003531f5da4f6bc8"},
+    {file = "websockets-11.0.3-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:8c82f11964f010053e13daafdc7154ce7385ecc538989a354ccc7067fd7028fd"},
+    {file = "websockets-11.0.3-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:3580dd9c1ad0701169e4d6fc41e878ffe05e6bdcaf3c412f9d559389d0c9e016"},
+    {file = "websockets-11.0.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6f1a3f10f836fab6ca6efa97bb952300b20ae56b409414ca85bff2ad241d2a61"},
+    {file = "websockets-11.0.3-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:df41b9bc27c2c25b486bae7cf42fccdc52ff181c8c387bfd026624a491c2671b"},
+    {file = "websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:279e5de4671e79a9ac877427f4ac4ce93751b8823f276b681d04b2156713b9dd"},
+    {file = "websockets-11.0.3-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:1fdf26fa8a6a592f8f9235285b8affa72748dc12e964a5518c6c5e8f916716f7"},
+    {file = "websockets-11.0.3-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:69269f3a0b472e91125b503d3c0b3566bda26da0a3261c49f0027eb6075086d1"},
+    {file = "websockets-11.0.3-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:97b52894d948d2f6ea480171a27122d77af14ced35f62e5c892ca2fae9344311"},
+    {file = "websockets-11.0.3-cp39-cp39-win32.whl", hash = "sha256:c7f3cb904cce8e1be667c7e6fef4516b98d1a6a0635a58a57528d577ac18a128"},
+    {file = "websockets-11.0.3-cp39-cp39-win_amd64.whl", hash = "sha256:c792ea4eabc0159535608fc5658a74d1a81020eb35195dd63214dcf07556f67e"},
+    {file = "websockets-11.0.3-pp37-pypy37_pp73-macosx_10_9_x86_64.whl", hash = "sha256:f2e58f2c36cc52d41f2659e4c0cbf7353e28c8c9e63e30d8c6d3494dc9fdedcf"},
+    {file = "websockets-11.0.3-pp37-pypy37_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:de36fe9c02995c7e6ae6efe2e205816f5f00c22fd1fbf343d4d18c3d5ceac2f5"},
+    {file = "websockets-11.0.3-pp37-pypy37_pp73-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0ac56b661e60edd453585f4bd68eb6a29ae25b5184fd5ba51e97652580458998"},
+    {file = "websockets-11.0.3-pp37-pypy37_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e052b8467dd07d4943936009f46ae5ce7b908ddcac3fda581656b1b19c083d9b"},
+    {file = "websockets-11.0.3-pp37-pypy37_pp73-win_amd64.whl", hash = "sha256:42cc5452a54a8e46a032521d7365da775823e21bfba2895fb7b77633cce031bb"},
+    {file = "websockets-11.0.3-pp38-pypy38_pp73-macosx_10_9_x86_64.whl", hash = "sha256:e6316827e3e79b7b8e7d8e3b08f4e331af91a48e794d5d8b099928b6f0b85f20"},
+    {file = "websockets-11.0.3-pp38-pypy38_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8531fdcad636d82c517b26a448dcfe62f720e1922b33c81ce695d0edb91eb931"},
+    {file = "websockets-11.0.3-pp38-pypy38_pp73-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c114e8da9b475739dde229fd3bc6b05a6537a88a578358bc8eb29b4030fac9c9"},
+    {file = "websockets-11.0.3-pp38-pypy38_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e063b1865974611313a3849d43f2c3f5368093691349cf3c7c8f8f75ad7cb280"},
+    {file = "websockets-11.0.3-pp38-pypy38_pp73-win_amd64.whl", hash = "sha256:92b2065d642bf8c0a82d59e59053dd2fdde64d4ed44efe4870fa816c1232647b"},
+    {file = "websockets-11.0.3-pp39-pypy39_pp73-macosx_10_9_x86_64.whl", hash = "sha256:0ee68fe502f9031f19d495dae2c268830df2760c0524cbac5d759921ba8c8e82"},
+    {file = "websockets-11.0.3-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:dcacf2c7a6c3a84e720d1bb2b543c675bf6c40e460300b628bab1b1efc7c034c"},
+    {file = "websockets-11.0.3-pp39-pypy39_pp73-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b67c6f5e5a401fc56394f191f00f9b3811fe843ee93f4a70df3c389d1adf857d"},
+    {file = "websockets-11.0.3-pp39-pypy39_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1d5023a4b6a5b183dc838808087033ec5df77580485fc533e7dab2567851b0a4"},
+    {file = "websockets-11.0.3-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:ed058398f55163a79bb9f06a90ef9ccc063b204bb346c4de78efc5d15abfe602"},
+    {file = "websockets-11.0.3-py3-none-any.whl", hash = "sha256:6681ba9e7f8f3b19440921e99efbb40fc89f26cd71bf539e45d8c8a25c976dc6"},
+    {file = "websockets-11.0.3.tar.gz", hash = "sha256:88fc51d9a26b10fc331be344f1781224a375b78488fc343620184e95a4b27016"},
+]
+
+[[package]]
+name = "wsproto"
+version = "1.2.0"
+description = "WebSockets state-machine based protocol implementation"
+optional = false
+python-versions = ">=3.7.0"
+files = [
+    {file = "wsproto-1.2.0-py3-none-any.whl", hash = "sha256:b9acddd652b585d75b20477888c56642fdade28bdfd3579aa24a4d2c037dd736"},
+    {file = "wsproto-1.2.0.tar.gz", hash = "sha256:ad565f26ecb92588a3e43bc3d96164de84cd9902482b130d0ddbaa9664a85065"},
+]
+
+[package.dependencies]
+h11 = ">=0.9.0,<1"
+
+[metadata]
+lock-version = "2.0"
+python-versions = ">=3.9,<3.12"
+content-hash = "6bafb9b450faac0435cb5cd5a0a01441346b9f5e89e2abc4d1ca74e0767e98a6"
diff --git a/pyproject.toml b/pyproject.toml
new file mode 100644
index 0000000..1258d40
--- /dev/null
+++ b/pyproject.toml
@@ -0,0 +1,70 @@
+[tool.poetry]
+name = "crossbench"
+version = "1.0.5"
+authors = [ "Camillo Bruni <cbruni@chromium.org>" ]
+description = "A cross-browser, cross-system web benchmark runner"
+readme = "README.md"
+license = "BSD-3-Clause"
+classifiers = [
+    "Programming Language :: Python :: 3",
+    "License :: OSI Approved :: BSD License",
+    "Operating System :: OS Independent",
+]
+
+[tool.poetry.urls]
+"Homepage" = "http://crossben.ch"
+"Bug Tracker" = "http://bugs.crossben.ch"
+"Source" = "http://source.crossben.ch"
+"User Mailing list" = "http://mail.crossben.ch"
+
+[tool.poetry_bumpversion.file."crossbench/__init__.py"]
+
+[tool.poetry.dependencies]
+colorama = "^0.4.6"
+hjson = "^3.1.0"
+immutabledict = "^4.1.0"
+numpy = "^1.23.5"
+ordered-set = "^4.1.0"
+pandas = "^1.1.3"
+perfetto = "^0.10.0"
+protobuf = "^4.25.3"
+psutil = "^5.9.1"
+python = ">=3.9,<3.12"
+python-dateutil = "2.7.3"
+pytz = "^2024.1"
+selenium = "^4.1.0"
+tabulate = "^0.8.10"
+websockets = "^11.0.3"
+
+[tool.poetry.scripts]
+crossbench = 'crossbench.scripts:crossbench'
+cb = 'crossbench.scripts:crossbench'
+cb_btp = 'crossbench.scripts:cb_btp'
+
+[tool.poetry.group.dev.dependencies]
+debugpy = "^1.6.3"
+isort = "^5.10.1"
+pyfakefs = "^5.2.2"
+pylint = "^3.0"
+pytest = "^7.4.2"
+pytest-cov = "^4.0.0"
+pytest-xdist = "^3.3.1"
+pytest-subtests = "^0.11.0"
+mypy = "^1.8"
+pytest-profiling = "^1.7.0"
+
+[tool.poetry.group.dev-pytype.dependencies]
+python = ">=3.9,<3.12"
+pytype = { version = "^2024.1.24", markers = "sys_platform != 'win32'" }
+
+[build-system]
+requires = ["poetry_core>=1.1.5"]
+build-backend = "poetry.core.masonry.api"
+
+[tool.pytest.ini_options]
+addopts = "--ignore=tests/cbb -n auto --dist=loadgroup"
+log_cli = 1
+log_cli_level = "DEBUG"
+testpaths = [
+    "tests",
+]
diff --git a/pytest.ini b/pytest.ini
new file mode 100644
index 0000000..e4911c4
--- /dev/null
+++ b/pytest.ini
@@ -0,0 +1,6 @@
+[pytest]
+log_cli = True
+log_cli_level = DEBUG
+addopts = --ignore=tests/cbb -n 4 --dist=loadgroup -rs
+testpaths =
+    tests
diff --git a/tests/__init__.py b/tests/__init__.py
new file mode 100644
index 0000000..3ea02f9
--- /dev/null
+++ b/tests/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/cbb/__init__.py b/tests/cbb/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/cbb/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/cbb/cbb_runner.py b/tests/cbb/cbb_runner.py
new file mode 100644
index 0000000..e86ef16
--- /dev/null
+++ b/tests/cbb/cbb_runner.py
@@ -0,0 +1,20 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# TODO: remove after landing infra change.
+
+import pathlib
+import sys
+
+import pytest
+
+repo_dir = pathlib.Path(__file__).absolute().parents[2]
+if repo_dir not in sys.path:
+  sys.path.insert(0, str(repo_dir))
+
+if __name__ == "__main__":
+  test_file = (
+      pathlib.Path(__file__).absolute().parents[1] / "end2end" / "cbb" /
+      "test_cbb.py")
+  sys.exit(pytest.main([str(test_file)]))
diff --git a/tests/crossbench/__init__.py b/tests/crossbench/__init__.py
new file mode 100644
index 0000000..3ea02f9
--- /dev/null
+++ b/tests/crossbench/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/action_runner/action_runner_test_case.py b/tests/crossbench/action_runner/action_runner_test_case.py
new file mode 100644
index 0000000..04bb917
--- /dev/null
+++ b/tests/crossbench/action_runner/action_runner_test_case.py
@@ -0,0 +1,19 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class ActionRunnerTestCase(CrossbenchFakeFsTestCase):
+
+  def tearDown(self):
+    expected_sh_cmds = self.platform.expected_sh_cmds
+    if expected_sh_cmds is not None:
+      self.assertListEqual(expected_sh_cmds, [],
+                           "Got additional unused shell cmds.")
+
+    expected_js = self.browser.expected_js
+    if expected_js is not None:
+      self.assertListEqual(expected_js, [],
+                           "Got additional unused expected JS.")
diff --git a/tests/crossbench/base.py b/tests/crossbench/base.py
new file mode 100644
index 0000000..0fb85f4
--- /dev/null
+++ b/tests/crossbench/base.py
@@ -0,0 +1,191 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+import datetime as dt
+import io
+import logging
+import pathlib
+from typing import Final, List, Optional, Sequence, Tuple
+from unittest import mock
+
+from pyfakefs import fake_filesystem_unittest
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.mock_helper import MockCLI, MockPlatform
+
+import crossbench
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.benchmarks.loading.loadline_presets import \
+    LoadLineTabletBenchmark
+from crossbench.browsers.browser import Browser
+from crossbench.browsers.settings import Settings
+from crossbench.cli.cli import CrossBenchCLI
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.cli.config.network import NetworkConfig
+from crossbench.cli.config.secrets import SecretsConfig
+
+
+class CrossbenchFakeFsTestCase(
+    fake_filesystem_unittest.TestCase, metaclass=abc.ABCMeta):
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.setUpPyfakefs(modules_to_reload=[crossbench, mock_browser, pth])
+    # gettext is used extensively in argparse
+    gettext_patcher = mock.patch(
+        "gettext.dgettext", side_effect=lambda domain, message: message)
+    gettext_patcher.start()
+    self.addCleanup(gettext_patcher.stop)
+
+    sleep_patcher = mock.patch("time.sleep", return_value=None)
+    sleep_patcher.start()
+    self.addCleanup(sleep_patcher.stop)
+
+  def create_file(self,
+                  path_str: str,
+                  contents: Optional[str] = None) -> pathlib.Path:
+    path = pathlib.Path(path_str)
+    self.fs.create_file(path, contents=contents)
+    return path
+
+
+class BaseCrossbenchTestCase(CrossbenchFakeFsTestCase, metaclass=abc.ABCMeta):
+
+  def filter_splashscreen_urls(self, urls: Sequence[str]) -> List[str]:
+    return [url for url in urls if not url.startswith("data:")]
+
+  def setUp(self) -> None:
+    # Instantiate MockPlatform before setting up fake_filesystem so we can
+    # still interact with the original, real plt.Platform object for extracting
+    # basic system information.
+    self.platform = MockPlatform()  # pytype: disable=not-instantiable
+    super().setUp()
+    self._default_log_level = logging.getLogger().getEffectiveLevel()
+    logging.getLogger().setLevel(logging.CRITICAL)
+    for mock_browser_cls in mock_browser.ALL:
+      mock_browser_cls.setup_fs(self.fs)
+      self.assertTrue(mock_browser_cls.mock_app_path().exists())
+    self.out_dir = pathlib.Path("/tmp/results/test")
+    self.out_dir.parent.mkdir(parents=True)
+    self.fs.add_real_directory(
+        LoadLineTabletBenchmark.default_network_config_path().parent,
+        lazy_read=not test_helper.is_google_env())
+    if test_helper.is_google_env():
+      self.fs.add_real_directory("/build/cas")
+    self.browsers: List[mock_browser.MockBrowser] = [
+        mock_browser.MockChromeDev(
+            "dev", settings=Settings(platform=self.platform)),
+        mock_browser.MockChromeStable(
+            "stable", settings=Settings(platform=self.platform))
+    ]
+    mock_platform_patcher = mock.patch.object(plt, "PLATFORM", self.platform)
+    mock_platform_patcher.start()
+    self.addCleanup(mock_platform_patcher.stop)
+    for browser in self.browsers:
+      self.assertListEqual(browser.expected_js, [])
+    self.mock_args = mock.Mock(
+        wraps=False,
+        driver_path=None,
+        network_config=None,
+        browser_config=None,
+        viewport=None,
+        splash_screen=None,
+        secrets=SecretsConfig(),
+        wipe_system_user_data=False,
+        http_request_timeout=dt.timedelta(),
+        cache_dir=pathlib.Path("test_cache_dir"),
+        enable_features=None,
+        disable_features=None,
+        js_flags=None,
+        enable_field_trial_config=False,
+        network=NetworkConfig.default(),
+        probe=[],
+        other_browser_args=[],
+        driver_logging=False)
+
+  def tearDown(self) -> None:
+    logging.getLogger().setLevel(self._default_log_level)
+    self.assertListEqual(self.platform.sh_results, [])
+    super().tearDown()
+
+
+class SysExitTestException(Exception):
+
+  def __init__(self, exit_code=0):
+    super().__init__("sys.exit")
+    self.exit_code = exit_code
+
+
+class BaseCliTestCase(BaseCrossbenchTestCase):
+
+  SPLASH_URLS_LEN: Final[int] = 2
+
+  def setUp(self) -> None:
+    super().setUp()
+
+    # tabulate and textwrap can be slow for tests, let's mock them out.
+    def mock_tabulate(table, *args, **kwargs):
+      del args, kwargs
+      return str(table)
+
+    patcher = mock.patch("tabulate.tabulate", side_effect=mock_tabulate)
+    self.addCleanup(patcher.stop)
+    patcher.start()
+
+    def mock_wrap(text, *args, **kwargs):
+      del args, kwargs
+      return [text]
+
+    patcher = mock.patch("textwrap.wrap", side_effect=mock_wrap)
+    self.addCleanup(patcher.stop)
+    patcher.start()
+
+  def run_cli_output(self,
+                     *args,
+                     raises=None,
+                     enable_logging: bool = True) -> Tuple[MockCLI, str, str]:
+    with mock.patch(
+        "sys.stdout", new_callable=io.StringIO) as mock_stdout, mock.patch(
+            "sys.stderr", new_callable=io.StringIO) as mock_stderr:
+      cli = self.run_cli(*args, raises=raises, enable_logging=enable_logging)
+    stdout = mock_stdout.getvalue()
+    stderr = mock_stderr.getvalue()
+    # Make sure we don't accidentally reuse the buffers across run_cli calls.
+    mock_stdout.close()
+    mock_stderr.close()
+    return cli, stdout, stderr
+
+  def run_cli(self,
+              *args,
+              raises=None,
+              enable_logging: bool = False) -> MockCLI:
+    cli = MockCLI(platform=self.platform, enable_logging=enable_logging)
+    with mock.patch(
+        "sys.exit", side_effect=SysExitTestException), mock.patch.object(
+            plt, "PLATFORM", self.platform):
+      if raises:
+        with self.assertRaises(raises):
+          cli.run(args)
+      else:
+        cli.run(args)
+    return cli
+
+  def mock_chrome_stable(self):
+    return mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        return_value=mock_browser.MockChromeStable)
+
+  @contextlib.contextmanager
+  def patch_get_browser(self, return_value: Optional[Sequence[Browser]] = None):
+    if not return_value:
+      return_value = self.browsers
+    with mock.patch.object(
+        CrossBenchCLI, "_get_browsers", return_value=return_value):
+      yield
diff --git a/tests/crossbench/benchmarks/__init__.py b/tests/crossbench/benchmarks/__init__.py
new file mode 100644
index 0000000..3ea02f9
--- /dev/null
+++ b/tests/crossbench/benchmarks/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/benchmarks/helper.py b/tests/crossbench/benchmarks/helper.py
new file mode 100644
index 0000000..638480e
--- /dev/null
+++ b/tests/crossbench/benchmarks/helper.py
@@ -0,0 +1,163 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import abc
+from typing import Sequence, Type
+
+from crossbench.benchmarks import base as benchmark
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class BaseBenchmarkTestCase(BaseCrossbenchTestCase, metaclass=abc.ABCMeta):
+
+  @property
+  @abc.abstractmethod
+  def benchmark_cls(self):
+    pass
+
+  @property
+  def story_cls(self):
+    return self.benchmark_cls.DEFAULT_STORY_CLS
+
+  def setUp(self):
+    super().setUp()
+    self.assertTrue(
+        issubclass(self.benchmark_cls, benchmark.Benchmark),
+        f"Expected Benchmark subclass, but got: BENCHMARK={self.benchmark_cls}")
+
+  def test_describe(self):
+    self.assertIsInstance(self.benchmark_cls.describe(), dict)
+
+
+class SubStoryTestCase(BaseBenchmarkTestCase, metaclass=abc.ABCMeta):
+
+  @property
+  def story_filter_cls(self) -> Type[benchmark.StoryFilter]:
+    return self.benchmark_cls.STORY_FILTER_CLS
+
+  def story_filter(self, patterns: Sequence[str],
+                   **kwargs) -> benchmark.StoryFilter:
+    return self.story_filter_cls(  # pytype: disable=not-instantiable
+        story_cls=self.story_cls,
+        patterns=patterns,
+        **kwargs)
+
+  def test_instantiate_no_stories(self):
+    with self.assertRaises(AssertionError):
+      self.benchmark_cls(stories=[])
+    with self.assertRaises(AssertionError):
+      self.benchmark_cls(stories="")
+    with self.assertRaises(AssertionError):
+      self.benchmark_cls(stories=["", ""])
+
+  def test_stories_creation(self):
+    for name in self.story_cls.all_story_names():
+      stories = self.story_filter([name]).stories
+      self.assertTrue(len(stories) == 1)
+      story = stories[0]
+      self.assertIsInstance(story, self.story_cls)
+      self.assertIsInstance(story.details_json(), dict)
+      self.assertTrue(len(str(story)) > 0)
+
+  def test_instantiate_single_story(self):
+    any_story_name = self.story_cls.all_story_names()[0]
+    any_story = self.story_filter([any_story_name]).stories[0]
+    # Instantiate with single story,
+    with self.assertRaises(Exception):
+      self.benchmark_cls(any_story)
+    # with single story array
+    self.benchmark_cls([any_story])
+    with self.assertRaises(AssertionError):
+      # Accidentally nested array.
+      self.benchmark_cls([[any_story]])
+
+  def test_instantiate_all_stories(self):
+    stories = self.story_filter(self.story_cls.all_story_names()).stories
+    self.benchmark_cls(stories)
+
+
+class PressBaseBenchmarkTestCase(SubStoryTestCase, metaclass=abc.ABCMeta):
+
+  def test_invalid_story_names(self):
+    # Only StoryFilter can filter stories by regexp
+    with self.assertRaises(Exception):
+      self.story_cls.from_names(".*", separate=True)
+    with self.assertRaises(Exception):
+      self.story_cls.from_names([".*"], separate=True)
+    with self.assertRaises(Exception):
+      self.story_cls.from_names([".*", "name does not exist"], separate=True)
+    with self.assertRaises(Exception):
+      self.story_cls.from_names([""], separate=True)
+
+  def test_all(self):
+    all_stories = [story.name for story in self.story_cls.all(separate=True)]
+    all_regexp = [
+        story.name for story in self.story_filter([".*"], separate=True).stories
+    ]
+    all_string = [
+        story.name
+        for story in self.story_filter(["all"], separate=True).stories
+    ]
+    self.assertListEqual(all_stories, all_regexp)
+    self.assertListEqual(all_stories, all_string)
+
+  def test_default(self):
+    default_stories = [
+        story.name for story in self.story_cls.default(separate=True)
+    ]
+    default_string = [
+        story.name
+        for story in self.story_filter(["default"], separate=True).stories
+    ]
+    self.assertListEqual(default_stories, default_string)
+
+  def test_remove(self):
+    assert len(self.story_cls.all_story_names()) > 1
+    story_name = self.story_cls.all_story_names()[0]
+    all_stories = [story.name for story in self.story_cls.all(separate=True)]
+    filtered_stories = [
+        story.name for story in self.story_filter([".*", f"-{story_name}"],
+                                                  separate=True).stories
+    ]
+    self.assertEqual(len(filtered_stories) + 1, len(all_stories))
+    for name in filtered_stories:
+      self.assertIn(name, all_stories)
+
+  def test_remove_invalid(self):
+    assert len(self.story_cls.all_story_names()) > 1
+    story_name = self.story_cls.all_story_names()[0]
+    with self.assertRaises(ValueError):
+      self.story_filter(["-"])
+    with self.assertRaises(ValueError):
+      self.story_filter(["--"])
+    with self.assertRaises(ValueError):
+      self.story_filter(["-.*"])
+    with self.assertRaises(ValueError):
+      self.story_filter(["-all"])
+    with self.assertRaises(ValueError):
+      self.story_filter(["-does not exist name"])
+    with self.assertRaises(ValueError):
+      self.story_filter([f"-{story_name}"])
+
+  def test_invalid_remove_all(self):
+    assert len(self.story_cls.all_story_names()) > 1
+    story_name = self.story_cls.all_story_names()[0]
+    with self.assertRaises(ValueError):
+      self.story_filter([story_name, f"-{story_name}"])
+    with self.assertRaises(ValueError):
+      self.story_filter([story_name, "-[^ ]+"])
+
+  def test_invalid_add_all(self):
+    assert len(self.story_cls.all_story_names()) > 1
+    story_name = self.story_cls.all_story_names()[0]
+    with self.assertRaises(ValueError):
+      # Add all stories again after filtering out some
+      self.story_filter([".*", f"-{story_name}", ".*|[^ ]+"])
+
+  def test_remove_non_existent(self):
+    assert len(self.story_cls.all_story_names()) > 1
+    story_name = self.story_cls.all_story_names()[0]
+    other_story_name = self.story_cls.all_story_names()[1]
+    with self.assertRaises(ValueError):
+      self.story_filter([other_story_name, f"-{story_name}"])
diff --git a/tests/crossbench/benchmarks/jetstream_helper.py b/tests/crossbench/benchmarks/jetstream_helper.py
new file mode 100644
index 0000000..579ec26
--- /dev/null
+++ b/tests/crossbench/benchmarks/jetstream_helper.py
@@ -0,0 +1,140 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import abc
+import copy
+import csv
+from typing import Optional, Type
+from unittest import mock
+
+from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
+                                                         JetStream2Probe,
+                                                         JetStream2Story)
+from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
+                            ValidationMode)
+from crossbench.runner.runner import Runner
+from tests.crossbench.benchmarks import helper
+
+
+class JetStream2BaseTestCase(
+    helper.PressBaseBenchmarkTestCase, metaclass=abc.ABCMeta):
+
+  @property
+  @abc.abstractmethod
+  def benchmark_cls(self) -> Type[JetStream2Benchmark]:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def story_cls(self) -> Type[JetStream2Story]:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def probe_cls(self) -> Type[JetStream2Probe]:
+    pass
+
+  def test_run_throw(self):
+    self._test_run(throw=True)
+
+  def test_run_default(self):
+    self._test_run()
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(self.story_cls.URL, urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+  def test_run_custom_url(self):
+    custom_url = "http://test.example.com/jetstream"
+    self._test_run(custom_url)
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(custom_url, urls)
+      self.assertNotIn(self.story_cls.URL, urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+  def _test_run(self, custom_url: Optional[str] = None, throw: bool = False):
+    repetitions = 3
+    stories = self.story_cls.from_names(["WSL"], url=custom_url)
+    example_story_data = {
+        "firstIteration": 1,
+        "average": 0.1,
+        "worst4": 1.1,
+        "score": 1
+    }
+    # The order should match Runner.get_runs
+    for _ in range(repetitions):
+      for _ in stories:
+        jetstream_probe_results = {
+            story.name: example_story_data for story in stories
+        }
+        for browser in self.browsers:
+          # Page is ready
+          browser.expect_js(result=True)
+          # filter benchmarks
+          browser.expect_js()
+          # UI is updated and ready,
+          browser.expect_js(result=True)
+          # Start running benchmark
+          browser.expect_js()
+          # Wait until done
+          browser.expect_js(result=True)
+          browser.expect_js(result=jetstream_probe_results)
+    for browser in self.browsers:
+      browser.expected_js = copy.deepcopy(browser.expected_js)
+
+    benchmark = self.benchmark_cls(stories, custom_url=custom_url)  # pytype: disable=not-instantiable
+    self.assertTrue(len(benchmark.describe()) > 0)
+    runner = Runner(
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        env_config=HostEnvironmentConfig(),
+        env_validation_mode=ValidationMode.SKIP,
+        platform=self.platform,
+        repetitions=repetitions,
+        throw=throw)
+    with mock.patch.object(
+        HostEnvironment, "validate_url", return_value=True) as cm:
+      runner.run()
+    cm.assert_called_once()
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertEqual(len(urls), repetitions)
+      self.assertTrue(browser.was_js_invoked(self.probe_cls.JS))
+
+    csv_file = self.out_dir / f"{self.probe_cls.NAME}.csv"
+    with csv_file.open(encoding="utf-8") as f:
+      csv_data = list(csv.DictReader(f, delimiter="\t"))
+    self.assertListEqual(
+        list(csv_data[0].keys()), ["label", "", "dev", "stable"])
+    self.assertDictEqual(
+        csv_data[1],
+        {
+            "label": "version",
+            "dev": "102.22.33.44",
+            "stable": "100.22.33.44",
+            # One padding element
+            "": ""
+        })
+
+    with self.assertLogs(level="INFO") as cm:
+      for probe in runner.probes:
+        for run in runner.runs:
+          probe.log_run_result(run)
+    output = "\n".join(cm.output)
+    self.assertIn("JetStream results", output)
+
+    with self.assertLogs(level="INFO") as cm:
+      for probe in runner.probes:
+        probe.log_browsers_result(runner.browser_group)
+    output = "\n".join(cm.output)
+    self.assertIn("JetStream results", output)
+    self.assertIn("102.22.33.44", output)
+    self.assertIn("100.22.33.44", output)
+
+
+# TODO: introduce JetStreamBaseTestCase
+class JetStream3BaseTestCase(JetStream2BaseTestCase, metaclass=abc.ABCMeta):
+  pass
diff --git a/tests/crossbench/benchmarks/loading/__init__.py b/tests/crossbench/benchmarks/loading/__init__.py
new file mode 100644
index 0000000..e9d2bfa
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/tests/crossbench/benchmarks/loading/action_runner/__init__.py b/tests/crossbench/benchmarks/loading/action_runner/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/action_runner/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_action_runner_config.py b/tests/crossbench/benchmarks/loading/action_runner/test_action_runner_config.py
new file mode 100644
index 0000000..ebd3448
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_action_runner_config.py
@@ -0,0 +1,41 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import unittest
+
+from crossbench.action_runner.android_input_action_runner import \
+    AndroidInputActionRunner
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.chromeos_input_action_runner import \
+    ChromeOSInputActionRunner
+from crossbench.action_runner.config import ActionRunnerConfig
+from tests import test_helper
+
+
+class ActionRunnerConfigTest(unittest.TestCase):
+
+  def test_parse_invalid(self):
+    for invalid in ["bas", "adnroid", "chroms"]:
+      with self.subTest(pattern=invalid):
+        with self.assertRaises((argparse.ArgumentTypeError, ValueError)):
+          ActionRunnerConfig.parse(invalid)
+
+  def test_parse_basic(self):
+    action_runner = ActionRunnerConfig.parse("basic")
+    self.assertIsInstance(action_runner, BasicActionRunner)
+
+  def test_parse_android(self):
+    action_runner = ActionRunnerConfig.parse("android")
+    self.assertIsInstance(action_runner, AndroidInputActionRunner)
+
+  def test_parse_chromeos(self):
+    action_runner = ActionRunnerConfig.parse("chromeos")
+    self.assertIsInstance(action_runner, ChromeOSInputActionRunner)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_android_input_action_runner.py b/tests/crossbench/benchmarks/loading/action_runner/test_android_input_action_runner.py
new file mode 100644
index 0000000..b1acc4c
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_android_input_action_runner.py
@@ -0,0 +1,411 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import datetime as dt
+import pathlib
+import unittest
+from typing import Optional, Tuple
+
+from crossbench.action_runner.action.action import Action
+from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.scroll import ScrollAction
+from crossbench.action_runner.action.swipe import SwipeAction
+from crossbench.action_runner.action.text_input import TextInputAction
+from crossbench.action_runner.android_input_action_runner import (
+    AndroidInputActionRunner, ViewportInfo)
+from crossbench.action_runner.base import InputSourceNotImplementedError
+from crossbench.action_runner.display_rectangle import DisplayRectangle
+from crossbench.action_runner.element_not_found_error import \
+    ElementNotFoundError
+from crossbench.benchmarks.loading.input_source import InputSource
+from crossbench.benchmarks.loading.point import Point
+from crossbench.browsers.settings import Settings
+from crossbench.flags.base import Flags
+from crossbench.runner.groups.session import BrowserSessionRunGroup
+from tests import test_helper
+from tests.crossbench.action_runner.action_runner_test_case import ActionRunnerTestCase
+from tests.crossbench.mock_browser import JsInvocation, MockChromeAndroidStable
+from tests.crossbench.mock_helper import (AndroidAdbMockPlatform,
+                                          LinuxMockPlatform, MockAdb)
+from tests.crossbench.runner.helper import MockRun, MockRunner
+
+
+class ViewportInfoTestCase(unittest.TestCase):
+
+  def test_calculate_coordinates_no_element_still_returns_chrome_window(self):
+    config: ViewportInfo = ViewportInfo(
+        raw_chrome_window_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        window_inner_height=100,
+        window_inner_width=100)
+
+    self.assertTrue(config.chrome_window)
+    self.assertFalse(config.element_rect())
+    self.assertFalse(config.element_center())
+
+  def test_calculate_coordinates_top_system_border_accounted_for(self):
+    config: ViewportInfo = ViewportInfo(
+        raw_chrome_window_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        window_inner_height=90,
+        window_inner_width=100)
+
+    self.assertEqual(config.chrome_window.origin.x, 0)
+    self.assertEqual(config.chrome_window.width, 100)
+    self.assertEqual(config.chrome_window.origin.y, 10)
+    self.assertEqual(config.chrome_window.height, 90)
+
+  def test_calculate_coordinates_chrome_higher_pixel_ratio_calculated_correctly(
+      self):
+    config: ViewportInfo = ViewportInfo(
+        raw_chrome_window_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        window_inner_height=400,
+        window_inner_width=400,
+        element_rect=DisplayRectangle(Point(196, 196), 8, 8))
+
+    element_center = config.element_center()
+    self.assertTrue(element_center)
+    self.assertEqual(element_center.x, 50)
+    self.assertEqual(element_center.y, 50)
+
+    self.assertEqual(config.css_to_native_distance(60), 15)
+
+  def test_calculate_coordinates_chrome_lower_pixel_ratio_calculated_correctly(
+      self):
+    config: ViewportInfo = ViewportInfo(
+        raw_chrome_window_bounds=DisplayRectangle(Point(0, 0), 600, 600),
+        window_inner_height=200,
+        window_inner_width=200,
+        element_rect=DisplayRectangle(Point(99, 99), 2, 2))
+
+    element_center = config.element_center()
+    self.assertTrue(element_center)
+    self.assertEqual(element_center.x, 300)
+    self.assertEqual(element_center.y, 300)
+
+    self.assertEqual(config.css_to_native_distance(60), 180)
+
+  def test_calculate_coordinates_chrome_window_offset_accounted_for(self):
+    config: ViewportInfo = ViewportInfo(
+        raw_chrome_window_bounds=DisplayRectangle(Point(100, 200), 100, 100),
+        window_inner_height=100,
+        window_inner_width=100,
+        element_rect=DisplayRectangle(Point(49, 49), 2, 2))
+
+    element_center = config.element_center()
+    self.assertTrue(element_center)
+    self.assertEqual(element_center.x, 150)
+    self.assertEqual(element_center.y, 250)
+
+  def test_calculate_coordinates_element_center_calculated_correctly(self):
+    config: ViewportInfo = ViewportInfo(
+        raw_chrome_window_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        window_inner_height=100,
+        window_inner_width=100,
+        element_rect=DisplayRectangle(Point(10, 20), 80, 70))
+
+    element_center = config.element_center()
+    self.assertTrue(element_center)
+    self.assertEqual(element_center.x, 50)
+    self.assertEqual(element_center.y, 55)
+
+
+class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
+  __test__ = True
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.host_platform = LinuxMockPlatform()
+    self.host_platform.expect_sh(
+        "/usr/bin/adb",
+        "devices",
+        "-l",
+        result=("List of attached devices\n"
+                "1.1.1.1 device product:mock model:mock"))
+    self.platform = AndroidAdbMockPlatform(
+        self.host_platform, adb=MockAdb(self.host_platform))
+    self.browser = MockChromeAndroidStable(
+        "mock browser", settings=Settings(platform=self.platform))
+    self.runner = MockRunner()
+    self.root_dir = pathlib.Path()
+    self.session = BrowserSessionRunGroup(self.runner.env,
+                                          self.runner.probes, self.browser,
+                                          Flags(), 1, self.root_dir, True, True)
+    self.mock_run = MockRun(self.runner, self.session, "run 1")
+    self.action_runner = AndroidInputActionRunner()
+
+  def run_action(self, action: Action) -> None:
+    action.run_with(self.mock_run, self.action_runner)
+
+  def expect_action_setup(
+      self,
+      found_element: bool = True,
+      js_args: Optional[Tuple[str, bool]] = None,
+      app_bounds: DisplayRectangle = DisplayRectangle(Point(0, 0), 10, 10),
+      window_inner_height: Optional[int] = None,
+      window_inner_width: Optional[int] = None,
+      element_bounds: DisplayRectangle = DisplayRectangle(Point(0, 0), 0, 0)):
+    self.platform.expect_sh(
+        "dumpsys",
+        "window",
+        "windows",
+        "|",
+        "grep",
+        "-E",
+        "-A100",
+        "chrome.Main",
+        result=(f"mAppBounds=Rect({app_bounds.left}, "
+                f"{app_bounds.top} - {app_bounds.right}, {app_bounds.bottom})"))
+
+    if not window_inner_height:
+      window_inner_height = app_bounds.height
+
+    if not window_inner_width:
+      window_inner_width = app_bounds.width
+
+    # element bounding rect
+    self.browser.expect_js(
+        JsInvocation(
+            result=[
+                # Found element
+                found_element,
+                # window.innerHeight
+                window_inner_height,
+                # window.innerWidth
+                window_inner_width,
+                # rect.left
+                element_bounds.left,
+                # rect.top
+                element_bounds.top,
+                # rect.width
+                element_bounds.width,
+                # rect.height
+                element_bounds.height,
+            ],
+            arguments=js_args))
+
+  def test_swipe(self):
+    self.platform.expect_sh("input", "swipe", "0", "1", "2", "3", "3000")
+    swipe_action = SwipeAction(0, 1, 2, 3, dt.timedelta(milliseconds=3000))
+    self.run_action(swipe_action)
+
+  def test_text_input_zero_duration(self):
+    self.platform.expect_sh("input", "keyboard", "text", "Some%ssample%stext")
+
+    text_input_action = TextInputAction(InputSource.KEYBOARD, dt.timedelta(),
+                                        "Some sample text")
+
+    self.run_action(text_input_action)
+
+  def test_text_input_non_zero_duration(self):
+    text_input_action = TextInputAction(InputSource.KEYBOARD,
+                                        dt.timedelta(seconds=1), "aaa")
+
+    for _ in range(3):
+      self.platform.expect_sh("input", "keyboard", "text", "a")
+
+    self.run_action(text_input_action)
+
+  def test_click_touch_coordinates(self):
+    click_action = ClickAction(InputSource.TOUCH, x=100, y=200)
+
+    self.platform.expect_sh("input", "tap", "100", "200")
+
+    self.run_action(click_action)
+
+  def test_click_mouse_coordinates(self):
+    click_action = ClickAction(InputSource.MOUSE, x=100, y=200)
+
+    self.platform.expect_sh("input", "mouse", "tap", "100", "200")
+
+    self.run_action(click_action)
+
+  def test_click_mouse_non_zero_duration_fails(self):
+    click_action = ClickAction(
+        InputSource.MOUSE, duration=dt.timedelta(seconds=1), x=0, y=0)
+
+    with self.assertRaises(InputSourceNotImplementedError) as cm:
+      self.run_action(click_action)
+    self.assertIn("Non-zero", str(cm.exception))
+
+  def test_click_touch_non_zero_duration_fails(self):
+    click_action = ClickAction(
+        InputSource.TOUCH, duration=dt.timedelta(seconds=1), x=0, y=0)
+
+    with self.assertRaises(InputSourceNotImplementedError) as cm:
+      self.run_action(click_action)
+    self.assertIn("Non-zero", str(cm.exception))
+
+  def test_click_selector_passes_selector_string(self):
+    click_action = ClickAction(
+        InputSource.TOUCH, selector="div[]", required=False)
+
+    self.expect_action_setup(found_element=False, js_args=["div[]", False])
+
+    self.run_action(click_action)
+
+  def test_click_selector_scroll_into_viwe_passes_scroll_true(self):
+    click_action = ClickAction(
+        InputSource.TOUCH,
+        selector="div[]",
+        required=False,
+        scroll_into_view=True)
+
+    self.expect_action_setup(found_element=False, js_args=["div[]", True])
+
+    self.run_action(click_action)
+
+  def test_click_selector_non_existant_element_raises(self):
+    click_action = ClickAction(
+        InputSource.TOUCH, selector="div[]", required=True)
+
+    self.expect_action_setup(found_element=False)
+
+    with self.assertRaises(ElementNotFoundError) as cm:
+      self.run_action(click_action)
+    self.assertIn("matching DOM", str(cm.exception))
+
+  def test_click_touch_selector_non_required_element_success(self):
+    click_action = ClickAction(
+        InputSource.TOUCH, selector="div[]", required=False)
+
+    self.expect_action_setup(found_element=False)
+
+    self.run_action(click_action)
+
+  def test_click_mouse_selector_non_required_element_success(self):
+    click_action = ClickAction(
+        InputSource.MOUSE, selector="div[]", required=False)
+
+    self.expect_action_setup(found_element=False)
+
+    self.run_action(click_action)
+
+  def test_click_touch_selector_success(self):
+    click_action = ClickAction(
+        InputSource.TOUCH, selector="div[]", required=True)
+
+    self.expect_action_setup(
+        found_element=True,
+        app_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        element_bounds=DisplayRectangle(Point(20, 40), 10, 10))
+
+    self.platform.expect_sh("input", "tap", "25", "45")
+
+    self.run_action(click_action)
+
+  def test_click_mouse_selector_success(self):
+    click_action = ClickAction(
+        InputSource.MOUSE, selector="div[]", required=True)
+
+    self.expect_action_setup(
+        found_element=True,
+        app_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        element_bounds=DisplayRectangle(Point(20, 40), 10, 10))
+
+    self.platform.expect_sh("input", "mouse", "tap", "25", "45")
+
+    self.run_action(click_action)
+
+  def test_scroll_selector_non_required_element_success(self):
+    scroll_action = ScrollAction(
+        InputSource.TOUCH, distance=100, selector="div[]", required=False)
+
+    self.expect_action_setup(found_element=False)
+
+    self.run_action(scroll_action)
+
+  def test_scroll_touch_selector_non_existant_element_raises(self):
+    scroll_action = ScrollAction(
+        InputSource.TOUCH, distance=100, selector="div[]", required=True)
+
+    self.expect_action_setup(found_element=False)
+
+    with self.assertRaises(ElementNotFoundError) as cm:
+      self.run_action(scroll_action)
+    self.assertIn("matching DOM", str(cm.exception))
+
+  def test_scroll_distance_converted_to_css_pixels(self):
+    scroll_action = ScrollAction(InputSource.TOUCH, distance=100)
+
+    self.expect_action_setup(
+        found_element=False,
+        app_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        window_inner_height=200,
+        window_inner_width=200)
+
+    self.platform.expect_sh("input", "swipe", "50", "100", "50", "50", "1000")
+
+    self.run_action(scroll_action)
+
+  def test_scroll_positive_direction(self):
+    scroll_action = ScrollAction(InputSource.TOUCH, distance=1)
+
+    self.expect_action_setup(
+        found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 10, 10))
+
+    self.platform.expect_sh("input", "swipe", "5", "10", "5", "9", "1000")
+
+    self.run_action(scroll_action)
+
+  def test_scroll_negative_direction(self):
+    scroll_action = ScrollAction(InputSource.TOUCH, distance=-1)
+
+    self.expect_action_setup(
+        found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 10, 10))
+
+    self.platform.expect_sh("input", "swipe", "5", "0", "5", "1", "1000")
+
+    self.run_action(scroll_action)
+
+  def test_scroll_window_scrolls_window_bounds(self):
+    scroll_action = ScrollAction(InputSource.TOUCH, distance=100)
+
+    self.expect_action_setup(
+        found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 100, 100))
+
+    self.platform.expect_sh("input", "swipe", "50", "100", "50", "0", "1000")
+
+    self.run_action(scroll_action)
+
+  def test_scroll_element_scrolls_element_bounds(self):
+    scroll_action = ScrollAction(
+        InputSource.TOUCH, distance=10, selector="div[]", required=True)
+
+    self.expect_action_setup(
+        found_element=True,
+        app_bounds=DisplayRectangle(Point(0, 0), 100, 100),
+        element_bounds=DisplayRectangle(Point(10, 10), 80, 80))
+
+    self.platform.expect_sh("input", "swipe", "50", "90", "50", "80", "1000")
+
+    self.run_action(scroll_action)
+
+  def test_scroll_touch_duration_single_scroll(self):
+    scroll_action = ScrollAction(
+        InputSource.TOUCH,
+        distance=100,
+        duration=dt.timedelta(milliseconds=3000))
+
+    self.expect_action_setup(
+        found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 100, 100))
+
+    self.platform.expect_sh("input", "swipe", "50", "100", "50", "0", "3000")
+
+    self.run_action(scroll_action)
+
+  def test_scroll_is_chunked(self):
+    scroll_action = ScrollAction(InputSource.TOUCH, distance=999)
+
+    self.expect_action_setup(
+        found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 100, 100))
+
+    for _ in range(9):
+      self.platform.expect_sh("input", "swipe", "50", "100", "50", "0", "100")
+
+    self.platform.expect_sh("input", "swipe", "50", "100", "50", "1", "99")
+
+    self.run_action(scroll_action)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_chromeos_input_action_runner.py b/tests/crossbench/benchmarks/loading/action_runner/test_chromeos_input_action_runner.py
new file mode 100644
index 0000000..96482de
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_chromeos_input_action_runner.py
@@ -0,0 +1,729 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import datetime as dt
+import pathlib
+import unittest
+from typing import Optional
+
+from crossbench.action_runner.action.action import Action
+from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.scroll import ScrollAction
+from crossbench.action_runner.chromeos_input_action_runner import (
+    SCRIPTS_DIR, ChromeOSInputActionRunner, ChromeOSTouchEvent,
+    ChromeOSViewportInfo, TouchDevice)
+from crossbench.action_runner.display_rectangle import DisplayRectangle
+from crossbench.action_runner.element_not_found_error import \
+    ElementNotFoundError
+from crossbench.benchmarks.loading.input_source import InputSource
+from crossbench.benchmarks.loading.point import Point
+from crossbench.browsers.settings import Settings
+from crossbench.flags.base import Flags
+from crossbench.runner.groups.session import BrowserSessionRunGroup
+from tests import test_helper
+from tests.crossbench.action_runner.action_runner_test_case import ActionRunnerTestCase
+from tests.crossbench.mock_browser import JsInvocation, MockChromeStable
+from tests.crossbench.mock_helper import (ChromeOsSshMockPlatform,
+                                          LinuxMockPlatform)
+from tests.crossbench.runner.helper import MockRun, MockRunner
+
+
+class ChromeOSTouchEventTestCase(unittest.TestCase):
+
+  _FAKE_TOUCH_DEVICE: TouchDevice = TouchDevice("/dev/input/event0", 200, 100)
+
+  def test_zero_duration_tap(self):
+    expected_playback: str = """E: 1.000000 0003 0039 0
+E: 1.000000 0003 0035 200
+E: 1.000000 0003 0036 100
+E: 1.000000 0001 014a 1
+E: 1.000000 0003 0000 200
+E: 1.000000 0003 0001 100
+E: 1.000000 0000 0000 0
+E: 1.000000 0003 0039 -1
+E: 1.000000 0001 014a 0
+E: 1.000000 0000 0000 0
+"""
+
+    tap_event: ChromeOSTouchEvent = ChromeOSTouchEvent(
+        self._FAKE_TOUCH_DEVICE, DisplayRectangle(Point(0, 0), 200, 100),
+        Point(200, 100))
+
+    playback = str(tap_event)
+
+    self.assertEqual(playback, expected_playback)
+
+  def test_long_tap(self):
+    expected_playback: str = """E: 1.000000 0003 0039 0
+E: 1.000000 0003 0035 200
+E: 1.000000 0003 0036 100
+E: 1.000000 0001 014a 1
+E: 1.000000 0003 0000 200
+E: 1.000000 0003 0001 100
+E: 1.000000 0000 0000 0
+E: 5.000000 0003 0039 -1
+E: 5.000000 0001 014a 0
+E: 5.000000 0000 0000 0
+"""
+
+    tap_event: ChromeOSTouchEvent = ChromeOSTouchEvent(
+        self._FAKE_TOUCH_DEVICE, DisplayRectangle(Point(0, 0), 200, 100),
+        Point(200, 100), None, dt.timedelta(seconds=4))
+
+    playback = str(tap_event)
+
+    self.assertEqual(playback, expected_playback)
+
+  def test_out_of_bounds_tap_raises(self):
+    tap_event: ChromeOSTouchEvent = ChromeOSTouchEvent(
+        self._FAKE_TOUCH_DEVICE, DisplayRectangle(Point(0, 0), 200, 100),
+        Point(201, 101))
+
+    with self.assertRaisesRegex(ValueError, "out of bounds"):
+      str(tap_event)
+
+  def test_reference_coordinates(self):
+    tap_event: ChromeOSTouchEvent = ChromeOSTouchEvent(
+        self._FAKE_TOUCH_DEVICE, DisplayRectangle(Point(0, 0), 600, 300),
+        Point(53, 53))
+
+    expected_playback: str = """E: 1.000000 0003 0039 0
+E: 1.000000 0003 0035 18
+E: 1.000000 0003 0036 18
+E: 1.000000 0001 014a 1
+E: 1.000000 0003 0000 18
+E: 1.000000 0003 0001 18
+E: 1.000000 0000 0000 0
+E: 1.000000 0003 0039 -1
+E: 1.000000 0001 014a 0
+E: 1.000000 0000 0000 0
+"""
+    playback = str(tap_event)
+    self.assertEqual(playback, expected_playback)
+
+  def test_minimum_swipe(self):
+    expected_playback: str = """E: 1.000000 0003 0039 0
+E: 1.000000 0003 0035 100
+E: 1.000000 0003 0036 50
+E: 1.000000 0001 014a 1
+E: 1.000000 0003 0000 100
+E: 1.000000 0003 0001 50
+E: 1.000000 0000 0000 0
+E: 1.016667 0003 0035 200
+E: 1.016667 0003 0036 100
+E: 1.016667 0003 0000 200
+E: 1.016667 0003 0001 100
+E: 1.016667 0000 0000 0
+E: 1.016667 0003 0039 -1
+E: 1.016667 0001 014a 0
+E: 1.016667 0000 0000 0
+"""
+
+    swipe_event: ChromeOSTouchEvent = ChromeOSTouchEvent(
+        self._FAKE_TOUCH_DEVICE, DisplayRectangle(Point(0, 0), 200, 100),
+        Point(100, 50), Point(200, 100), dt.timedelta(seconds=0.016))
+
+    playback = str(swipe_event)
+
+    self.assertEqual(playback, expected_playback)
+
+  def test_multi_step_swipe(self):
+    expected_playback: str = """E: 1.000000 0003 0039 0
+E: 1.000000 0003 0035 100
+E: 1.000000 0003 0036 50
+E: 1.000000 0001 014a 1
+E: 1.000000 0003 0000 100
+E: 1.000000 0003 0001 50
+E: 1.000000 0000 0000 0
+E: 1.016667 0003 0035 110
+E: 1.016667 0003 0036 60
+E: 1.016667 0003 0000 110
+E: 1.016667 0003 0001 60
+E: 1.016667 0000 0000 0
+E: 1.033333 0003 0035 120
+E: 1.033333 0003 0036 70
+E: 1.033333 0003 0000 120
+E: 1.033333 0003 0001 70
+E: 1.033333 0000 0000 0
+E: 1.050000 0003 0035 130
+E: 1.050000 0003 0036 80
+E: 1.050000 0003 0000 130
+E: 1.050000 0003 0001 80
+E: 1.050000 0000 0000 0
+E: 1.066667 0003 0035 140
+E: 1.066667 0003 0036 90
+E: 1.066667 0003 0000 140
+E: 1.066667 0003 0001 90
+E: 1.066667 0000 0000 0
+E: 1.066667 0003 0039 -1
+E: 1.066667 0001 014a 0
+E: 1.066667 0000 0000 0
+"""
+
+    swipe_event: ChromeOSTouchEvent = ChromeOSTouchEvent(
+        self._FAKE_TOUCH_DEVICE, DisplayRectangle(Point(0, 0), 200, 100),
+        Point(100, 50), Point(140, 90), dt.timedelta(seconds=0.064))
+
+    playback = str(swipe_event)
+
+    self.assertEqual(playback, expected_playback)
+
+
+class ChromeOSViewportInfoTestCase(unittest.TestCase):
+
+  def test_element_rect_no_element(self) -> None:
+    viewport_info = ChromeOSViewportInfo(
+        device_pixel_ratio=1,
+        window_outer_width=1920,
+        window_inner_width=1920,
+        window_inner_height=1080,
+        screen_width=1920,
+        screen_height=1080,
+        screen_avail_width=1920,
+        screen_avail_height=1080,
+        window_offset_x=0,
+        window_offset_y=0,
+        element_rect=None)
+
+    self.assertFalse(viewport_info.element_rect)
+
+  _NO_RATIO_NO_OFFSET = ChromeOSViewportInfo(
+      device_pixel_ratio=1,
+      window_outer_width=1920,
+      window_inner_width=1920,
+      window_inner_height=1080,
+      screen_width=1920,
+      screen_height=1080,
+      screen_avail_width=1920,
+      screen_avail_height=1080,
+      window_offset_x=0,
+      window_offset_y=0,
+      element_rect=DisplayRectangle(Point(1, 2), 3, 4))
+
+  def test_browser_viewable_no_ratios_no_offset(self) -> None:
+    self.assertEqual(self._NO_RATIO_NO_OFFSET.browser_viewable,
+                     DisplayRectangle(Point(0, 0), 1920, 1080))
+
+  def test_css_to_native_no_ratio(self) -> None:
+    self.assertEqual(
+        self._NO_RATIO_NO_OFFSET.css_to_native_distance(1234), 1234)
+
+  def test_element_rect_no_ratio_no_offset(self) -> None:
+    self.assertEqual(self._NO_RATIO_NO_OFFSET.element_rect,
+                     DisplayRectangle(Point(1, 2), 3, 4))
+
+  _DOUBLE_RATIO_NO_OFFSET = ChromeOSViewportInfo(
+      device_pixel_ratio=2,
+      window_outer_width=1920,
+      window_inner_width=1920,
+      window_inner_height=1080,
+      screen_width=1920,
+      screen_height=1080,
+      screen_avail_width=1920,
+      screen_avail_height=1080,
+      window_offset_x=0,
+      window_offset_y=0,
+      element_rect=DisplayRectangle(Point(1, 2), 3, 4))
+
+  def test_css_to_native_double_ratio(self) -> None:
+    viewport_info = self._DOUBLE_RATIO_NO_OFFSET
+
+    self.assertEqual(viewport_info.css_to_native_distance(100), 200)
+
+  def test_browser_viewable_double_ratio(self) -> None:
+    viewport_info = self._DOUBLE_RATIO_NO_OFFSET
+
+    self.assertEqual(viewport_info.browser_viewable,
+                     DisplayRectangle(Point(0, 0), 3840, 2160))
+
+  def test_element_rect_double_ratio(self) -> None:
+    viewport_info = self._DOUBLE_RATIO_NO_OFFSET
+
+    self.assertEqual(viewport_info.element_rect,
+                     DisplayRectangle(Point(2, 4), 6, 8))
+
+  def test_browser_viewable_no_ratios_with_browser_window_offset(self) -> None:
+    viewport_info = ChromeOSViewportInfo(
+        device_pixel_ratio=1,
+        window_outer_width=1920,
+        window_inner_width=1920,
+        window_inner_height=1080,
+        screen_width=1920,
+        screen_height=1080,
+        screen_avail_width=1920,
+        screen_avail_height=1080,
+        window_offset_x=10,
+        window_offset_y=20,
+        element_rect=None)
+
+    self.assertEqual(viewport_info.browser_viewable,
+                     DisplayRectangle(Point(10, 20), 1910, 1060))
+
+  def test_element_rect_no_ratios_with_browser_window_offset(self) -> None:
+    viewport_info = ChromeOSViewportInfo(
+        device_pixel_ratio=1,
+        window_outer_width=1920,
+        window_inner_width=1920,
+        window_inner_height=1080,
+        screen_width=1920,
+        screen_height=1080,
+        screen_avail_width=1920,
+        screen_avail_height=1080,
+        window_offset_x=10,
+        window_offset_y=20,
+        element_rect=DisplayRectangle(Point(1, 2), 3, 4))
+
+    self.assertEqual(viewport_info.element_rect,
+                     DisplayRectangle(Point(11, 22), 3, 4))
+
+  def test_element_rect_no_ratios_with_browser_window_offset_2(self) -> None:
+    viewport_info = ChromeOSViewportInfo(
+        device_pixel_ratio=1,
+        window_outer_width=1920,
+        window_inner_width=1920,
+        window_inner_height=900,
+        screen_width=1920,
+        screen_height=1080,
+        screen_avail_width=1920,
+        screen_avail_height=1080,
+        window_offset_x=10,
+        window_offset_y=20,
+        element_rect=None)
+
+    self.assertEqual(viewport_info.browser_viewable,
+                     DisplayRectangle(Point(10, 200), 1910, 880))
+
+  def test_element_rect_no_ratios_with_browser_window_offset_3(self) -> None:
+    viewport_info = ChromeOSViewportInfo(
+        device_pixel_ratio=1,
+        window_outer_width=1920,
+        window_inner_width=1920,
+        window_inner_height=900,
+        screen_width=1920,
+        screen_height=1080,
+        screen_avail_width=1920,
+        screen_avail_height=1080,
+        window_offset_x=10,
+        window_offset_y=20,
+        element_rect=DisplayRectangle(Point(1, 2), 3, 4))
+
+    self.assertEqual(viewport_info.element_rect,
+                     DisplayRectangle(Point(11, 202), 3, 4))
+
+
+class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
+  _FAKE_TOUCH_DEVICE: TouchDevice = TouchDevice("/dev/input/event0", 1920, 1080)
+
+  _NO_ELEMENT_JS_RESULT: JsInvocation = JsInvocation(result=[
+      False,  # Found element
+      1,  # pixel ratio
+      1920,  # window outer width
+      1920,  # window inner width
+      1080,  # window inner height
+      1920,  # screen width
+      1080,  # screen height
+      1920,  # screen avail width
+      1080,  # screen avail height
+      0,  # screenX
+      0,  # screenY
+      0,  # element left
+      0,  # element top
+      0,  # element width
+      0,  # element height
+  ])
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.host_platform = LinuxMockPlatform()
+    self.platform = ChromeOsSshMockPlatform(
+        host_platform=self.host_platform,
+        host="1.1.1.1",
+        port="1234",
+        ssh_port="22",
+        ssh_user="root")
+
+    self.platform.expect_sh("[", "-e", "/usr/bin/google-chrome", "]", result="")
+    self.platform.expect_sh("[", "-f", "/usr/bin/google-chrome", "]", result="")
+
+    self.browser = MockChromeStable(
+        "mock browser", settings=Settings(platform=self.platform))
+    self.runner = MockRunner()
+    self.root_dir = pathlib.Path()
+    self.session = BrowserSessionRunGroup(self.runner.env,
+                                          self.runner.probes, self.browser,
+                                          Flags(), 1, self.root_dir, True, True)
+    self.run = MockRun(self.runner, self.session, "run 1")
+
+    self.action_runner = ChromeOSInputActionRunner()
+
+  def run_action(self, action: Action) -> None:
+    action.run_with(self.run, self.action_runner)
+
+  def expect_touch_setup(self, expected_js: JsInvocation, touch_count: int = 1):
+
+    path = SCRIPTS_DIR / "query_touch_device.py"
+    self.fs.create_file(path, contents="query_touch_device")
+
+    self.platform.expect_sh("env")
+    self.platform.expect_sh("[", "-d", "/tmp", "]")
+    self.platform.expect_sh("mktemp", "/tmp/None.XXXXXXXXXXX")
+
+    path = SCRIPTS_DIR / "get_window_positions.js"
+    self.fs.create_file(path, contents="get_window_positions")
+
+    # Query touch device response
+    self.platform.expect_sh(
+        "python3",
+        "-",
+        result=f"Performing autotest_lib import\n{self._FAKE_TOUCH_DEVICE}")
+
+    self.browser.expect_js(expected_js=expected_js)
+
+    for _ in range(touch_count):
+      self.platform.expect_sh("evemu-play --insert-slot0 /dev/input/event0 < .")
+
+  def expect_mouse_click(
+      self,
+      expected_js: JsInvocation,
+      clicked_coordinates: Optional[Point],
+      click_duration: dt.timedelta = dt.timedelta(seconds=0)):
+
+    path = SCRIPTS_DIR / "get_window_positions.js"
+    self.fs.create_file(path, contents="get_window_positions")
+
+    self.browser.expect_js(expected_js=expected_js)
+
+    path = SCRIPTS_DIR / "mouse.py"
+    self.fs.create_file(path, contents="mouse")
+
+    if clicked_coordinates:
+      self.platform.expect_sh("env")
+      self.platform.expect_sh("[", "-d", "/tmp", "]")
+      self.platform.expect_sh("mktemp", "/tmp/None.XXXXXXXXXXX")
+      self.platform.expect_sh("python3", ".", "1920", "1080",
+                              click_duration.total_seconds(),
+                              clicked_coordinates.x, clicked_coordinates.y)
+
+  def assert_coordinates_touched(
+      self,
+      start_coordinates: Point,
+      end_coordinates: Optional[Point] = None,
+      duration: dt.timedelta = dt.timedelta()
+  ) -> None:
+
+    expected_event: ChromeOSTouchEvent = ChromeOSTouchEvent(
+        self._FAKE_TOUCH_DEVICE, DisplayRectangle(Point(0, 0), 1920, 1080),
+        start_coordinates, end_coordinates, duration)
+
+    pushed_files = self.platform.file_contents
+    self.assertEqual(len(pushed_files), 1)
+
+    actual_playback_history = list(pushed_files.values())[0]
+
+    actual_playback = actual_playback_history.pop(0)
+
+    self.assertEqual(actual_playback, str(expected_event))
+
+  def test_click_touch_coordinates(self):
+    click_action = ClickAction(InputSource.TOUCH, x=50, y=50)
+
+    self.expect_touch_setup(expected_js=self._NO_ELEMENT_JS_RESULT)
+
+    self.run_action(click_action)
+
+    self.assert_coordinates_touched(Point(50, 50))
+
+  def test_click_mouse_coordinates(self):
+    click_action = ClickAction(InputSource.MOUSE, x=50, y=50)
+
+    self.expect_mouse_click(
+        expected_js=self._NO_ELEMENT_JS_RESULT,
+        clicked_coordinates=Point(50, 50))
+
+    self.run_action(click_action)
+
+  def test_click_touch_coordinates_duration(self):
+    click_duration = dt.timedelta(seconds=100)
+
+    click_action = ClickAction(
+        InputSource.TOUCH, x=50, y=50, duration=click_duration)
+
+    self.expect_touch_setup(expected_js=self._NO_ELEMENT_JS_RESULT)
+
+    self.run_action(click_action)
+
+    self.assert_coordinates_touched(Point(50, 50), duration=click_duration)
+
+  def test_click_mouse_coordinates_duration(self):
+    click_duration = dt.timedelta(seconds=100)
+
+    click_action = ClickAction(
+        InputSource.MOUSE, x=50, y=50, duration=click_duration)
+
+    self.expect_mouse_click(
+        expected_js=self._NO_ELEMENT_JS_RESULT,
+        clicked_coordinates=Point(50, 50),
+        click_duration=click_duration)
+
+    self.run_action(click_action)
+
+  def test_click_touch_selector_non_existent_element_raises(self):
+    click_action = ClickAction(
+        InputSource.TOUCH, selector="div[]", required=True)
+
+    self.expect_touch_setup(
+        touch_count=0, expected_js=self._NO_ELEMENT_JS_RESULT)
+
+    with self.assertRaisesRegex(ElementNotFoundError, "matching DOM"):
+      self.run_action(click_action)
+
+  def test_click_mouse_selector_non_existent_element_raises(self):
+    click_action = ClickAction(
+        InputSource.MOUSE, selector="div[]", required=True)
+
+    self.expect_mouse_click(
+        expected_js=self._NO_ELEMENT_JS_RESULT, clicked_coordinates=None)
+
+    with self.assertRaisesRegex(ElementNotFoundError, "matching DOM"):
+      self.run_action(click_action)
+
+  def test_click_touch_selector_non_required_element_success(self):
+    click_action = ClickAction(
+        InputSource.TOUCH, selector="div[]", required=False)
+
+    self.expect_touch_setup(
+        touch_count=0, expected_js=self._NO_ELEMENT_JS_RESULT)
+
+    self.run_action(click_action)
+
+  def test_click_mouse_selector_non_required_element_success(self):
+    click_action = ClickAction(
+        InputSource.MOUSE, selector="div[]", required=False)
+
+    self.expect_mouse_click(
+        expected_js=self._NO_ELEMENT_JS_RESULT, clicked_coordinates=None)
+
+    self.run_action(click_action)
+
+  def test_click_touch_selector_success(self):
+
+    click_action = ClickAction(
+        InputSource.TOUCH, selector="div[]", required=True)
+
+    self.expect_touch_setup(
+        expected_js=JsInvocation(result=[
+            True,  # Found element
+            1,  # pixel ratio
+            1920,  # window outer width
+            1920,  # window inner width
+            1080,  # window inner height
+            1920,  # screen width
+            1080,  # screen height
+            1920,  # screen avail width
+            1080,  # screen avail height
+            0,  # screenX
+            0,  # screenY
+            5,  # element left
+            6,  # element top
+            7,  # element width
+            8,  # element height
+        ]))
+
+    self.run_action(click_action)
+
+    self.assert_coordinates_touched(Point(8, 10))
+
+  def test_click_mouse_selector_success(self):
+
+    click_action = ClickAction(
+        InputSource.MOUSE, selector="div[]", required=True)
+
+    self.expect_mouse_click(
+        expected_js=JsInvocation(result=[
+            True,  # Found element
+            1,  # pixel ratio
+            1920,  # window outer width
+            1920,  # window inner width
+            1080,  # window inner height
+            1920,  # screen width
+            1080,  # screen height
+            1920,  # screen avail width
+            1080,  # screen avail height
+            0,  # screenX
+            0,  # screenY
+            5,  # element left
+            6,  # element top
+            7,  # element width
+            8,  # element height
+        ]),
+        clicked_coordinates=Point(8, 10))
+
+    self.run_action(click_action)
+
+  def test_scroll_touch_window_success(self):
+
+    scroll_duration: dt.timedelta = dt.timedelta(seconds=2)
+
+    scroll_action = ScrollAction(
+        InputSource.TOUCH, distance=100, duration=scroll_duration)
+
+    self.expect_touch_setup(
+        expected_js=JsInvocation(result=[
+            False,  # Found element
+            1,  # pixel ratio
+            1920,  # window outer width
+            1920,  # window inner width
+            1080,  # window inner height
+            1920,  # screen width
+            1080,  # screen height
+            1920,  # screen avail width
+            1080,  # screen avail height
+            0,  # screenX
+            0,  # screenY
+            0,  # element left
+            0,  # element top
+            0,  # element width
+            0,  # element height
+        ]))
+
+    self.run_action(scroll_action)
+
+    self.assert_coordinates_touched(
+        Point(960, 1080), Point(960, 980), scroll_duration)
+
+  def test_scroll_touch_window_multi_step_success(self):
+
+    scroll_duration: dt.timedelta = dt.timedelta(seconds=2)
+
+    scroll_action = ScrollAction(
+        InputSource.TOUCH, distance=2000, duration=scroll_duration)
+
+    self.expect_touch_setup(
+        expected_js=JsInvocation(result=[
+            False,  # Found element
+            1,  # pixel ratio
+            1920,  # window outer width
+            1920,  # window inner width
+            1080,  # window inner height
+            1920,  # screen width
+            1080,  # screen height
+            1920,  # screen avail width
+            1080,  # screen avail height
+            0,  # screenX
+            0,  # screenY
+            0,  # element left
+            0,  # element top
+            0,  # element width
+            0,  # element height
+        ]),
+        touch_count=2)
+
+    self.run_action(scroll_action)
+
+    self.assert_coordinates_touched(
+        Point(960, 1080), Point(960, 0), scroll_duration * (1080 / 2000))
+    self.assert_coordinates_touched(
+        Point(960, 1080), Point(960, 160), scroll_duration * (920 / 2000))
+
+  def test_scroll_touch_selector_required_not_found_raises(self):
+    scroll_action = ScrollAction(
+        InputSource.TOUCH,
+        distance=100,
+        duration=dt.timedelta(seconds=2),
+        selector="div[]",
+        required=True)
+
+    self.expect_touch_setup(
+        expected_js=JsInvocation(result=[
+            False,  # Found element
+            1,  # pixel ratio
+            1920,  # window outer width
+            1920,  # window inner width
+            1080,  # window inner height
+            1920,  # screen width
+            1080,  # screen height
+            1920,  # screen avail width
+            1080,  # screen avail height
+            0,  # screenX
+            0,  # screenY
+            0,  # element left
+            0,  # element top
+            0,  # element width
+            0,  # element height
+        ]),
+        touch_count=0)
+
+    with self.assertRaisesRegex(ElementNotFoundError, "matching DOM"):
+      self.run_action(scroll_action)
+
+  def test_scroll_touch_selector_not_found_does_nothing(self):
+    scroll_action = ScrollAction(
+        InputSource.TOUCH,
+        distance=100,
+        duration=dt.timedelta(seconds=2),
+        selector="div[]",
+        required=False)
+
+    self.expect_touch_setup(
+        expected_js=JsInvocation(result=[
+            False,  # Found element
+            1,  # pixel ratio
+            1920,  # window outer width
+            1920,  # window inner width
+            1080,  # window inner height
+            1920,  # screen width
+            1080,  # screen height
+            1920,  # screen avail width
+            1080,  # screen avail height
+            0,  # screenX
+            0,  # screenY
+            0,  # element left
+            0,  # element top
+            0,  # element width
+            0,  # element height
+        ]),
+        touch_count=0)
+
+    self.run_action(scroll_action)
+
+    pushed_files = self.platform.file_contents
+    self.assertEqual(len(pushed_files), 0)
+
+  def test_scroll_touch_selector_success(self):
+    scroll_duration: dt.timedelta = dt.timedelta(seconds=0.5)
+
+    scroll_action = ScrollAction(
+        InputSource.TOUCH,
+        distance=100,
+        duration=scroll_duration,
+        selector="div[]",
+        required=True)
+
+    self.expect_touch_setup(
+        expected_js=JsInvocation(result=[
+            True,  # Found element
+            1,  # pixel ratio
+            1920,  # window outer width
+            1920,  # window inner width
+            1080,  # window inner height
+            1920,  # screen width
+            1080,  # screen height
+            1920,  # screen avail width
+            1080,  # screen avail height
+            0,  # screenX
+            0,  # screenY
+            10,  # element left
+            20,  # element top
+            50,  # element width
+            600,  # element height
+        ]))
+
+    self.run_action(scroll_action)
+
+    self.assert_coordinates_touched(
+        Point(35, 620), Point(35, 520), scroll_duration)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_display_rectangle.py b/tests/crossbench/benchmarks/loading/action_runner/test_display_rectangle.py
new file mode 100644
index 0000000..06079a9
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_display_rectangle.py
@@ -0,0 +1,53 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import unittest
+
+from crossbench.action_runner.display_rectangle import DisplayRectangle
+from crossbench.benchmarks.loading.point import Point
+
+
+class DisplayRectangleTestCase(unittest.TestCase):
+
+  def test_display_rectangle_mul(self):
+    rect: DisplayRectangle = DisplayRectangle(Point(1, 2), 3, 4)
+
+    rect = rect * 5
+
+    self.assertEqual(rect.origin.x, 5)
+    self.assertEqual(rect.origin.y, 10)
+    self.assertEqual(rect.width, 15)
+    self.assertEqual(rect.height, 20)
+
+  def test_display_rectangle_shift_by(self):
+    rect: DisplayRectangle = DisplayRectangle(Point(1, 2), 3, 4)
+    rect2: DisplayRectangle = DisplayRectangle(Point(10, 20), 30, 40)
+
+    rect = rect.shift_by(rect2)
+
+    self.assertEqual(rect.origin.x, 11)
+    self.assertEqual(rect.origin.y, 22)
+    self.assertEqual(rect.width, 3)
+    self.assertEqual(rect.height, 4)
+
+  def test_display_rectangle_mid_x(self):
+    rect: DisplayRectangle = DisplayRectangle(Point(1, 2), 6, 8)
+
+    self.assertEqual(rect.mid_x, 4)
+
+  def test_display_rectangle_mid_y(self):
+    rect: DisplayRectangle = DisplayRectangle(Point(1, 2), 6, 8)
+
+    self.assertEqual(rect.mid_y, 6)
+
+  def test_display_rectangle_middle(self):
+    rect: DisplayRectangle = DisplayRectangle(Point(1, 2), 6, 8)
+
+    self.assertEqual(rect.middle, Point(4, 6))
+
+  def test_display_rectangle_truthy(self):
+    self.assertFalse(DisplayRectangle(Point(1, 2), 0, 0))
+    self.assertFalse(DisplayRectangle(Point(5, 6), 0, 1))
+    self.assertFalse(DisplayRectangle(Point(3, 4), 1, 0))
+    self.assertTrue(DisplayRectangle(Point(1, 2), 1, 1))
diff --git a/tests/crossbench/benchmarks/loading/config/test_blocks.py b/tests/crossbench/benchmarks/loading/config/test_blocks.py
new file mode 100644
index 0000000..31d1e6a
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/config/test_blocks.py
@@ -0,0 +1,100 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import unittest
+
+from crossbench.action_runner.action.get import GetAction
+from crossbench.benchmarks.loading.config.blocks import ActionBlock
+from crossbench.benchmarks.loading.config.login.custom import LoginBlock
+from crossbench.benchmarks.loading.config.login.google import GoogleLogin
+from tests import test_helper
+
+
+class ActionBlockTestCase(unittest.TestCase):
+
+  def test_create_empty_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ActionBlock()
+
+  def test_single_action(self):
+    action = GetAction("http://test.com", duration=dt.timedelta(seconds=3))
+    block = ActionBlock(actions=(action,))
+    self.assertTrue(bool(block))
+    self.assertFalse(block.is_login)
+    self.assertEqual(len(block), 1)
+    self.assertTupleEqual(tuple(block), (action,))
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+    block = ActionBlock.parse(block.to_json())
+    self.assertTrue(bool(block))
+    self.assertFalse(block.is_login)
+    self.assertEqual(len(block), 1)
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+  def test_multi_action(self):
+    action_2 = GetAction("http://test.com/0", duration=dt.timedelta(seconds=1))
+    action_1 = GetAction("http://test.com/1", duration=dt.timedelta(seconds=2))
+    block = ActionBlock(actions=(action_1, action_2))
+    self.assertTrue(bool(block))
+    self.assertFalse(block.is_login)
+    self.assertEqual(len(block), 2)
+    self.assertTupleEqual(tuple(block), (action_1, action_2))
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+    block = ActionBlock.parse(block.to_json())
+    self.assertTrue(bool(block))
+    self.assertFalse(block.is_login)
+    self.assertEqual(len(block), 2)
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+
+class LoginBlockTestCase(unittest.TestCase):
+
+  def test_single_action(self):
+    action = GetAction("http://test.com", duration=dt.timedelta(seconds=3))
+    block = LoginBlock(actions=(action,))
+    self.assertTrue(bool(block))
+    self.assertTrue(block.is_login)
+    self.assertEqual(len(block), 1)
+    self.assertTupleEqual(tuple(block), (action,))
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+    block = LoginBlock.parse(block.to_json())
+    self.assertTrue(bool(block))
+    self.assertTrue(block.is_login)
+    self.assertEqual(len(block), 1)
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+  def test_multi_action(self):
+    action_2 = GetAction("http://test.com/0", duration=dt.timedelta(seconds=1))
+    action_1 = GetAction("http://test.com/1", duration=dt.timedelta(seconds=2))
+    block = LoginBlock(actions=(action_1, action_2))
+    self.assertTrue(bool(block))
+    self.assertTrue(block.is_login)
+    self.assertEqual(len(block), 2)
+    self.assertTupleEqual(tuple(block), (action_1, action_2))
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+    block = LoginBlock.parse(block.to_json())
+    self.assertTrue(bool(block))
+    self.assertTrue(block.is_login)
+    self.assertEqual(len(block), 2)
+    self.assertEqual(block.duration, dt.timedelta(seconds=3))
+
+
+class PresetLoginBlockTestCase(unittest.TestCase):
+
+  def test_google_login_block(self):
+    block = GoogleLogin()
+    self.assertTrue(bool(block))
+    self.assertTrue(block.is_login)
+    self.assertEqual(len(block), 1)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/config/test_example_configs.py b/tests/crossbench/benchmarks/loading/config/test_example_configs.py
new file mode 100644
index 0000000..e3c65e6
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/config/test_example_configs.py
@@ -0,0 +1,93 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import hjson
+
+from crossbench.benchmarks.loading.config.pages import PagesConfig
+from crossbench.helper import ChangeCWD
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class TestExamplePageConfig(CrossbenchFakeFsTestCase):
+
+  CNN_JS_INSTRUMENTATION_PATH = (
+      test_helper.config_dir() / "benchmark/loadline/cnn_instrumentation.js")
+
+  GLOBO_JS_INSTRUMENTATION_PATH = (
+      test_helper.config_dir() / "benchmark/loadline/globo_instrumentation.js")
+
+  YT_JS_INSTRUMENTATION_PATH = (
+      test_helper.config_dir() /
+      "benchmark/loadline/youtube_instrumentation.js")
+
+  def test_parse_example_page_config_file(self):
+    example_config_file = test_helper.config_dir() / "doc/page.config.hjson"
+    self.fs.add_real_file(example_config_file)
+    file_config = PagesConfig.parse(example_config_file)
+    with example_config_file.open(encoding="utf-8") as f:
+      data = hjson.load(f)
+    dict_config = PagesConfig.parse_dict(data)
+    self.assertTrue(dict_config.pages)
+    self.assertTrue(file_config.pages)
+    for page in dict_config.pages:
+      self.assertEqual(len(page.blocks), 1)
+      self.assertGreater(len(page.blocks[0].actions), 1)
+
+  def test_parse_android_page_config_file(self):
+    example_config_file = (
+        test_helper.config_dir() / "team/woa/android_input_page_config.hjson")
+    self.fs.add_real_file(example_config_file)
+    file_config = PagesConfig.parse(example_config_file)
+    with example_config_file.open(encoding="utf-8") as f:
+      data = hjson.load(f)
+    dict_config = PagesConfig.parse_dict(data)
+    self.assertTrue(dict_config.pages)
+    self.assertTrue(file_config.pages)
+    for page in dict_config.pages:
+      self.assertEqual(len(page.blocks), 1)
+      self.assertGreater(len(page.blocks[0].actions), 1)
+
+  def test_parse_loadline_page_config_phone(self):
+    self.fs.add_real_file(self.CNN_JS_INSTRUMENTATION_PATH)
+    self.fs.add_real_file(self.GLOBO_JS_INSTRUMENTATION_PATH)
+
+    config_file = (
+        test_helper.config_dir() / "benchmark/loadline/page_config_phone.hjson")
+    self.fs.add_real_file(config_file)
+    file_config = PagesConfig.parse(config_file)
+    with config_file.open(encoding="utf-8") as f:
+      data = hjson.load(f)
+    with ChangeCWD(test_helper.config_dir() / "benchmark/loadline"):
+      dict_config = PagesConfig.parse_dict(data)
+    self.assertTrue(dict_config.pages)
+    self.assertTrue(file_config.pages)
+    for page in dict_config.pages:
+      self.assertEqual(len(page.blocks), 1)
+      self.assertGreater(len(page.blocks[0].actions), 1)
+
+  def test_parse_loadline_page_config_tablet(self):
+    self.fs.add_real_file(self.CNN_JS_INSTRUMENTATION_PATH)
+    self.fs.add_real_file(self.YT_JS_INSTRUMENTATION_PATH)
+
+    config_file = (
+        test_helper.config_dir() /
+        "benchmark/loadline/page_config_tablet.hjson")
+    self.fs.add_real_file(config_file)
+    file_config = PagesConfig.parse(config_file)
+    with config_file.open(encoding="utf-8") as f:
+      data = hjson.load(f)
+    with ChangeCWD(test_helper.config_dir() / "benchmark/loadline"):
+      dict_config = PagesConfig.parse_dict(data)
+    self.assertTrue(dict_config.pages)
+    self.assertTrue(file_config.pages)
+    for page in dict_config.pages:
+      self.assertEqual(len(page.blocks), 1)
+      self.assertGreater(len(page.blocks[0].actions), 1)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/config/test_login.py b/tests/crossbench/benchmarks/loading/config/test_login.py
new file mode 100644
index 0000000..6ab145c
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/config/test_login.py
@@ -0,0 +1,106 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import pathlib
+from unittest import mock
+
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.benchmarks.loading.config.pages import PagesConfig
+from crossbench.benchmarks.loading.loading_benchmark import LoadingPageFilter
+from crossbench.browsers.settings import Settings
+from crossbench.cli.config.secrets import Secret
+from crossbench.cli.config.secret_type import SecretType
+from crossbench.flags.base import Flags
+from crossbench.runner.groups.session import BrowserSessionRunGroup
+from tests import test_helper
+from tests.crossbench.action_runner.action_runner_test_case import ActionRunnerTestCase
+from tests.crossbench.mock_browser import MockChromeStable
+from tests.crossbench.mock_helper import (ChromeOsSshMockPlatform,
+                                          LinuxMockPlatform)
+from tests.crossbench.runner.helper import MockRun, MockRunner
+
+
+class ChromeOSLoginTestCase(ActionRunnerTestCase):
+  _CONFIG_DATA = {
+      "secrets": {
+          "google": {
+              "username": "test",
+              "password": "s3cr3t"
+          }
+      },
+      "pages": {
+          "Google Story": {
+              "login": "google",
+              "actions": [{
+                  "action": "get",
+                  "url": "https://www.google.com"
+              },]
+          }
+      }
+  }
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.host_platform = LinuxMockPlatform()
+    self.platform = ChromeOsSshMockPlatform(
+        host_platform=self.host_platform,
+        host="1.1.1.1",
+        port="1234",
+        ssh_port="22",
+        ssh_user="root")
+
+    self.platform.expect_sh("[", "-e", "/usr/bin/google-chrome", "]", result="")
+    self.platform.expect_sh("[", "-f", "/usr/bin/google-chrome", "]", result="")
+
+    self.browser = MockChromeStable(
+        "mock browser", settings=Settings(platform=self.platform))
+    self.runner = MockRunner()
+    self.root_dir = pathlib.Path()
+    self.session = BrowserSessionRunGroup(self.runner.env,
+                                          self.runner.probes, self.browser,
+                                          Flags(), 1, self.root_dir, True, True)
+    self.run = MockRun(self.runner, self.session, "run 1")
+
+    self.action_runner = BasicActionRunner()
+    self.mock_args = mock.Mock()
+
+  def expect_google_login(self):
+    self.browser.expect_js(result=True)
+    self.browser.expect_js(result=True)
+    self.browser.expect_js(result=True)
+    self.browser.expect_js(result=True)
+    self.browser.expect_js(result=True)
+    self.browser.expect_js(result=True)
+    self.browser.expect_js(result=True)
+
+  def test_google_account(self):
+    config = PagesConfig.parse(self._CONFIG_DATA)
+    page = LoadingPageFilter.stories_from_config(self.mock_args, config)
+
+    self.expect_google_login()
+
+    config.pages[0].login.run_with(self.action_runner, self.run, page[0])
+
+  def test_logged_in_google_account(self):
+    config = PagesConfig.parse(self._CONFIG_DATA)
+    page = LoadingPageFilter.stories_from_config(self.mock_args, config)
+
+    self.browser.expect_is_logged_in(
+        Secret(SecretType.GOOGLE, "test", "s3cr3t"))
+
+    config.pages[0].login.run_with(self.action_runner, self.run, page[0])
+
+  def test_logged_in_non_google_account(self):
+    config = PagesConfig.parse(self._CONFIG_DATA)
+    page = LoadingPageFilter.stories_from_config(self.mock_args, config)
+
+    self.browser.expect_is_logged_in(Secret(None, "test", "s3cr3t"))
+
+    self.expect_google_login()
+
+    config.pages[0].login.run_with(self.action_runner, self.run, page[0])
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/config/test_page.py b/tests/crossbench/benchmarks/loading/config/test_page.py
new file mode 100644
index 0000000..68e519c
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/config/test_page.py
@@ -0,0 +1,229 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import unittest
+
+from crossbench.benchmarks.loading.config.login.google import GoogleLogin
+from crossbench.benchmarks.loading.config.page import PageConfig
+from tests import test_helper
+
+
+class PageConfigTestsCase(unittest.TestCase):
+
+  def test_parse_empty(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PageConfig.parse("")
+    self.assertIn("empty", str(cm.exception).lower())
+
+  def test_parse_unknown_type(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PageConfig.parse(self)
+    self.assertIn("type", str(cm.exception))
+
+  def test_parse_blank(self):
+    config = PageConfig.parse("about:blank")
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "blank")
+    self.assertEqual(config.first_url, "about:blank")
+
+  def test_parse_file(self):
+    config = PageConfig.parse("file://foo/bar/custom.html")
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "custom.html")
+    self.assertEqual(config.first_url, "file://foo/bar/custom.html")
+
+  def test_parse_url(self):
+    config = PageConfig.parse("http://www.a.com")
+    self.assertEqual(config.first_url, "http://www.a.com")
+    self.assertEqual(config.duration, dt.timedelta())
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "a.com")
+
+  def test_parse_url_ftp_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = PageConfig.parse("ftp://www.a.com")
+    self.assertIn("ftp", str(cm.exception))
+
+  def test_parse_invalid_url(self):
+    for invalid in ("ssh://test.com/bar", "", "http://invalid host/"):
+      with self.subTest(url=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          PageConfig.parse(invalid)
+
+  def test_parse_url_no_protocol(self):
+    config = PageConfig.parse("www.a.com")
+    self.assertEqual(config.duration, dt.timedelta())
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "a.com")
+
+  def test_parse_url_numbers(self):
+    config = PageConfig.parse("123.a.com")
+    self.assertEqual(config.first_url, "https://123.a.com")
+    self.assertEqual(config.duration, dt.timedelta())
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "123.a.com")
+
+  def test_parse_with_duration(self):
+    config = PageConfig.parse("http://news.b.com,123s")
+    self.assertEqual(config.first_url, "http://news.b.com")
+    self.assertEqual(config.duration.total_seconds(), 123)
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "news.b.com")
+
+  def test_parse_invalid_multiple_urls(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PageConfig.parse("111.a.com,222.b.com")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PageConfig.parse("111s,222.b.com")
+
+  def test_parse_multiple_comma(self):
+    # duration splitting should happen in the caller
+    config = PageConfig.parse("www.b.com/foo?bar=a,b,c,d,123s")
+    self.assertEqual(config.first_url, "https://www.b.com/foo?bar=a,b,c,d")
+    self.assertEqual(config.duration.total_seconds(), 123)
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "b.com")
+
+  def test_parse_invalid(self):
+    for invalid in ("", {}, [], None):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          PageConfig.parse(invalid)
+
+  def test_parse_sequence_urls(self):
+    config_urls = [
+        "http://test.com/0",
+        "http://test.com/0,123s",
+    ]
+    config_1 = PageConfig.parse(config_urls)
+    self.assertIsNone(config_1.login)
+    self.assertIsNone(config_1.label)
+    self.assertEqual(config_1.any_label, "test.com")
+    self.assertEqual(config_1.first_url, "http://test.com/0")
+    self.assertEqual(len(config_1.blocks), 1)
+    self.assertEqual(len(tuple(config_1.actions())), 2)
+    self.assertEqual(config_1.blocks[0].actions[0].url, "http://test.com/0")
+    self.assertEqual(config_1.blocks[0].actions[1].url,
+                     "http://test.com/0,123s")
+
+    config_data = {"urls": config_urls}
+    config_2 = PageConfig.parse(config_data)
+    self.assertEqual(config_1, config_2)
+    config_data = {"actions": config_urls}
+    config_3 = PageConfig.parse(config_data)
+    self.assertEqual(config_1, config_3)
+    self.assertEqual(config_2, config_3)
+
+  def test_parse_sequence_preset_urls(self):
+    # Known url names only work at PageConfig level at this point.
+    config_urls = [
+        "cnn",
+    ]
+    config = PageConfig.parse(config_urls)
+    self.assertIsNone(config.login)
+    self.assertIsNone(config.setup)
+    self.assertIsNone(config.label)
+    self.assertEqual(config.any_label, "cnn")
+    self.assertEqual(config.first_url, "https://cnn")
+    self.assertEqual(len(config.blocks), 1)
+
+  def test_parse_actions_no_get(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PageConfig.parse([{"action": "click", "selector": "#foo"}])
+    self.assertIn("get", str(cm.exception))
+
+  def test_parse_action_sequence(self):
+    config = PageConfig.parse([{
+        "action": "get",
+        "url": "http://test.com/click"
+    }, {
+        "action": "click",
+        "selector": "#foo"
+    }])
+    self.assertEqual(config.first_url, "http://test.com/click")
+    self.assertIsNone(config.login)
+    self.assertIsNone(config.setup)
+    self.assertEqual(len(tuple(config.actions())), 2)
+
+  def test_parse_actions_dict(self):
+    config_data = {
+        "actions": [{
+            "action": "get",
+            "url": "http://test.com/click"
+        }, {
+            "action": "click",
+            "selector": "#foo"
+        }]
+    }
+    config_1 = PageConfig.parse(config_data)
+    self.assertIsNone(config_1.login)
+    self.assertIsNone(config_1.setup)
+    self.assertEqual(config_1.first_url, "http://test.com/click")
+    self.assertEqual(len(tuple(config_1.actions())), 2)
+
+    config_data = {"blocks": config_data["actions"]}
+    config_2 = PageConfig.parse(config_data)
+    self.assertEqual(config_1, config_2)
+
+  def test_parse_login_block(self):
+    config_data = {
+        "login": [{
+            "action": "get",
+            "url": "http://test.com/login"
+        }, {
+            "action": "click",
+            "selector": "#foo"
+        }],
+        "urls": ["http://test.com/charts",]
+    }
+    config = PageConfig.parse(config_data)
+    login = config.login
+    self.assertTrue(login.is_login)
+    self.assertIsNone(config.setup)
+    self.assertFalse(config.blocks[0].is_login)
+    self.assertEqual(config.first_url, "http://test.com/charts")
+    self.assertEqual(len(config.blocks), 1)
+    self.assertEqual(len(tuple(config.actions())), 1)
+    self.assertEqual(len(login), 2)
+    self.assertEqual(login.actions[0].url, "http://test.com/login")
+
+  def test_parse_setup_block(self):
+    config_data = {
+        "login": ["http://test.com/login"],
+        "setup": [{
+            "action": "get",
+            "url": "http://test.com/setup"
+        }, {
+            "action": "click",
+            "selector": "#foo"
+        }],
+        "actions": ["http://test.com/charts",]
+    }
+    config = PageConfig.parse(config_data)
+    self.assertEqual(len(config.login), 1)
+    self.assertEqual(len(config.setup), 2)
+    self.assertEqual(len(config.blocks), 1)
+    self.assertEqual(config.login.first_url, "http://test.com/login")
+    self.assertEqual(config.setup.first_url, "http://test.com/setup")
+    self.assertEqual(config.blocks[0].first_url, "http://test.com/charts")
+
+  def test_parse_login_block_preset(self):
+    config_data = {"login": "google", "urls": ["http://test.com/charts",]}
+    config = PageConfig.parse(config_data)
+    login = config.login
+    self.assertTrue(login.is_login)
+    self.assertIsInstance(login, GoogleLogin)
+    self.assertIsNone(config.setup)
+    self.assertFalse(config.blocks[0].is_login)
+    self.assertEqual(config.first_url, "http://test.com/charts")
+    self.assertEqual(len(config.blocks), 1)
+    self.assertEqual(len(tuple(config.actions())), 1)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/config/test_pages.py b/tests/crossbench/benchmarks/loading/config/test_pages.py
new file mode 100644
index 0000000..ebdffcd
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/config/test_pages.py
@@ -0,0 +1,601 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import json
+import pathlib
+import unittest
+from typing import Sequence
+
+import hjson
+
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.click import ClickAction
+from crossbench.benchmarks.loading.config.login.google import GoogleLogin
+from crossbench.benchmarks.loading.config.page import PageConfig
+from crossbench.benchmarks.loading.config.pages import (
+    DevToolsRecorderPagesConfig, ListPagesConfig, PagesConfig)
+from crossbench.cli.config.secret_type import SecretType
+from crossbench.cli.config.secrets import Secret, SecretsConfig
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class PagesConfigTestCase(CrossbenchFakeFsTestCase):
+
+  def test_parse_unknown_type(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse(self)
+    self.assertIn("type", str(cm.exception))
+
+  def test_parse_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse("123s,")
+    self.assertIn("Duration", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse(",")
+    self.assertIn("empty", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse("http://foo.com,,")
+    self.assertIn("empty", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse("http://foo.com,123s,")
+    self.assertIn("empty", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse("http://foo.com,123s,123s")
+    self.assertIn("Duration", str(cm.exception))
+
+  def test_parse_single(self):
+    config = PagesConfig.parse("http://a.com")
+    self.assertEqual(len(config.pages), 1)
+    page_config = config.pages[0]
+    self.assertEqual(page_config.first_url, "http://a.com")
+
+  def test_parse_single_with_duration(self):
+    config = PagesConfig.parse("http://a.com,123s")
+    self.assertEqual(len(config.pages), 1)
+    page_config = config.pages[0]
+    self.assertEqual(page_config.first_url, "http://a.com")
+    self.assertEqual(page_config.duration.total_seconds(), 123)
+
+  def test_parse_multiple(self):
+    config = PagesConfig.parse("http://a.com,http://b.com")
+    self.assertEqual(len(config.pages), 2)
+    page_config_0, page_config_1 = config.pages
+    self.assertEqual(page_config_0.first_url, "http://a.com")
+    self.assertEqual(page_config_1.first_url, "http://b.com")
+
+  def test_parse_multiple_short_domain(self):
+    config = PagesConfig.parse("a.com,b.com")
+    self.assertEqual(len(config.pages), 2)
+    page_config_0, page_config_1 = config.pages
+    self.assertEqual(page_config_0.first_url, "https://a.com")
+    self.assertEqual(page_config_1.first_url, "https://b.com")
+
+  def test_parse_multiple_numeric_domain(self):
+    config = PagesConfig.parse("111.a.com,222.b.com")
+    self.assertEqual(len(config.pages), 2)
+    page_config_0, page_config_1 = config.pages
+    self.assertEqual(page_config_0.first_url, "https://111.a.com")
+    self.assertEqual(page_config_1.first_url, "https://222.b.com")
+
+  def test_parse_multiple_numeric_domain_with_duration(self):
+    config = PagesConfig.parse("111.a.com,12s,222.b.com,23s")
+    self.assertEqual(len(config.pages), 2)
+    page_config_0, page_config_1 = config.pages
+    self.assertEqual(page_config_0.first_url, "https://111.a.com")
+    self.assertEqual(page_config_1.first_url, "https://222.b.com")
+    self.assertEqual(page_config_0.duration.total_seconds(), 12)
+    self.assertEqual(page_config_1.duration.total_seconds(), 23)
+
+  def test_parse_multiple_with_duration(self):
+    config = PagesConfig.parse("http://a.com,123s,http://b.com")
+    self.assertEqual(len(config.pages), 2)
+    page_config_0, page_config_1 = config.pages
+    self.assertEqual(page_config_0.first_url, "http://a.com")
+    self.assertEqual(page_config_1.first_url, "http://b.com")
+    self.assertEqual(page_config_0.duration.total_seconds(), 123)
+    self.assertEqual(page_config_1.duration, dt.timedelta())
+
+  def test_parse_multiple_with_duration_end(self):
+    config = PagesConfig.parse("http://a.com,http://b.com,123s")
+    self.assertEqual(len(config.pages), 2)
+    page_config_0, page_config_1 = config.pages
+    self.assertEqual(page_config_0.first_url, "http://a.com")
+    self.assertEqual(page_config_1.first_url, "http://b.com")
+    self.assertEqual(page_config_0.duration, dt.timedelta())
+    self.assertEqual(page_config_1.duration.total_seconds(), 123)
+
+  def test_parse_multiple_with_duration_all(self):
+    config = PagesConfig.parse("http://a.com,1s,http://b.com,123s")
+    self.assertEqual(len(config.pages), 2)
+    page_config_0, page_config_1 = config.pages
+    self.assertEqual(page_config_0.first_url, "http://a.com")
+    self.assertEqual(page_config_1.first_url, "http://b.com")
+    self.assertEqual(page_config_0.duration.total_seconds(), 1)
+    self.assertEqual(page_config_1.duration.total_seconds(), 123)
+
+  def test_parse_sequence(self):
+    config_list = PagesConfig.parse(["http://a.com,1s", "http://b.com,123s"])
+    config_str = PagesConfig.parse("http://a.com,1s,http://b.com,123s")
+    self.assertEqual(config_list, config_str)
+
+    config_list = PagesConfig.parse(["http://a.com", "http://b.com"])
+    config_str = PagesConfig.parse("http://a.com,http://b.com")
+    self.assertEqual(config_list, config_str)
+
+  def test_parse_empty_actions(self):
+    config_data = {"pages": {"Google Story": []}}
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse(config_data)
+    self.assertIn("empty", str(cm.exception).lower())
+    config_data = {"pages": {"Google Story": {}}}
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse(config_data)
+    self.assertIn("empty", str(cm.exception).lower())
+
+  def test_parse_empty_missing_get_action(self):
+    config_data = {
+        "pages": {
+            "Google Story": [{
+                "action": "wait",
+                "duration": 5
+            }]
+        }
+    }
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse(config_data)
+    self.assertIn("get", str(cm.exception).lower())
+
+  def test_example(self):
+    config_data = {
+        "pages": {
+            "Google Story": [
+                {
+                    "action": "get",
+                    "url": "https://www.google.com"
+                },
+                {
+                    "action": "wait",
+                    "duration": 5
+                },
+                {
+                    "action": "scroll",
+                    "direction": "down",
+                    "duration": 3
+                },
+            ],
+        }
+    }
+    config = PagesConfig.parse(config_data)
+    self.assert_single_google_story(config.pages)
+    self.assertIsNone(config.pages[0].login)
+    # Loading the same config from a file should result in the same actions.
+    file = pathlib.Path("page.config.hjson")
+    assert not file.exists()
+    with file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+    pages = PagesConfig.parse(str(file)).pages
+    self.assert_single_google_story(pages)
+    self.assertIsNone(config.pages[0].login)
+
+  def test_example_with_login(self):
+    config_data = {
+        "pages": {
+            "Google Story": {
+                "login": [{
+                    "action": "get",
+                    "url": "https://www.google.com/login"
+                },],
+                "actions": [
+                    {
+                        "action": "get",
+                        "url": "https://www.google.com"
+                    },
+                    {
+                        "action": "wait",
+                        "duration": 5
+                    },
+                    {
+                        "action": "scroll",
+                        "direction": "down",
+                        "duration": 3
+                    },
+                ]
+            },
+        }
+    }
+    config = PagesConfig.parse(config_data)
+    self.assert_single_google_story(config.pages)
+    login = config.pages[0].login
+    self.assertEqual(len(login.actions), 1)
+    self.assertEqual(login.actions[0].url, "https://www.google.com/login")
+
+  def test_example_with_login_preset(self):
+    config_data = {
+        "pages": {
+            "Google Story": {
+                "login":
+                    "google",
+                "actions": [
+                    {
+                        "action": "get",
+                        "url": "https://www.google.com"
+                    },
+                    {
+                        "action": "wait",
+                        "duration": 5
+                    },
+                    {
+                        "action": "scroll",
+                        "direction": "down",
+                        "duration": 3
+                    },
+                ]
+            },
+        }
+    }
+    config = PagesConfig.parse(config_data)
+    self.assert_single_google_story(config.pages)
+    page = config.pages[0]
+    self.assertIsInstance(page.login, GoogleLogin)
+    self.assertIsNone(page.setup)
+
+  def assert_single_google_story(self, pages: Sequence[PageConfig]):
+    self.assertTrue(len(pages), 1)
+    page = pages[0]
+    self.assertEqual(page.label, "Google Story")
+    self.assertEqual(page.first_url, "https://www.google.com")
+    self.assertEqual(len(page.blocks), 1)
+    block = page.blocks[0]
+    self.assertListEqual([str(action.TYPE) for action in block],
+                         ["get", "wait", "scroll"])
+
+  def test_secrets(self):
+    config_data = {
+        "secrets": {
+            "google": {
+                "username": "test",
+                "password": "s3cr3t"
+            }
+        },
+        "pages": {
+            "Google Story": ["http://google.com"],
+        }
+    }
+    pages = PagesConfig.parse(config_data)
+    secret = Secret(SecretType.GOOGLE, "test", "s3cr3t")
+    self.assertEqual(pages.secrets, SecretsConfig({secret.type: secret}))
+    self.assertEqual(pages.pages[0].first_url, "http://google.com")
+
+  def test_no_scenarios(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PagesConfig.parse_dict({})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PagesConfig.parse_dict({"pages": {}})
+
+  def test_scenario_invalid_actions(self):
+    invalid_actions = [None, "", [], {}, "invalid string", 12]
+    invalid_actions = ["invalid string", 12]
+    for invalid_action in invalid_actions:
+      config_dict = {"pages": {"name": invalid_action}}
+      with self.subTest(invalid_action=invalid_action):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          PagesConfig.parse_dict(config_dict)
+
+  def test_missing_action(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PagesConfig.parse_dict(
+          {"pages": {
+              "TEST": [{
+                  "action___": "wait",
+                  "duration": 5.0
+              }]
+          }})
+    self.assertIn("Invalid data:", str(cm.exception))
+
+  def test_invalid_action(self):
+    invalid_actions = [None, "", [], {}, "unknown action name", 12]
+    for invalid_action in invalid_actions:
+      config_dict = {
+          "pages": {
+              "TEST": [{
+                  "action": invalid_action,
+                  "duration": 5.0
+              }]
+          }
+      }
+      with self.subTest(invalid_action=invalid_action):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          PagesConfig.parse_dict(config_dict)
+
+  def test_missing_get_action_scenario(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PagesConfig.parse_dict(
+          {"pages": {
+              "TEST": [{
+                  "action": "wait",
+                  "duration": 5.0
+              }]
+          }})
+
+  def test_get_action_durations(self):
+    durations = [
+        ("5", 5),
+        ("5.5", 5.5),
+        (6, 6),
+        (6.1, 6.1),
+        ("5.5", 5.5),
+        ("170ms", 0.17),
+        ("170milliseconds", 0.17),
+        ("170.4ms", 0.1704),
+        ("170.4 millis", 0.1704),
+        ("8s", 8),
+        ("8.1s", 8.1),
+        ("8.1seconds", 8.1),
+        ("1 second", 1),
+        ("1.1 seconds", 1.1),
+        ("9m", 9 * 60),
+        ("9.5m", 9.5 * 60),
+        ("9.5 minutes", 9.5 * 60),
+        ("9.5 mins", 9.5 * 60),
+        ("1 minute", 60),
+        ("1 min", 60),
+        ("1h", 3600),
+        ("1 h", 3600),
+        ("1 hour", 3600),
+        ("0.5h", 1800),
+        ("0.5 hours", 1800),
+    ]
+    for input_value, duration in durations:
+      with self.subTest(duration=duration):
+        page_config = PagesConfig.parse_dict({
+            "pages": {
+                "TEST": [
+                    {
+                        "action": "get",
+                        "url": "google.com"
+                    },
+                    {
+                        "action": "wait",
+                        "duration": input_value
+                    },
+                ]
+            }
+        })
+        self.assertEqual(len(page_config.pages), 1)
+        page = page_config.pages[0]
+        self.assertEqual(len(page.blocks), 1)
+        actions = page.blocks[0].actions
+        self.assertEqual(len(actions), 2)
+        self.assertEqual(actions[1].duration, dt.timedelta(seconds=duration))
+
+  def test_action_invalid_duration(self):
+    invalid_durations = [
+        "1.1.1", None, "", -1, "-1", "-1ms", "1msss", "1ss", "2hh", "asdfasd",
+        "---", "1.1.1", "1_123ms", "1'200h", (), [], {}, "-1h"
+    ]
+    for invalid_duration in invalid_durations:
+      with self.subTest(duration=invalid_duration), self.assertRaises(
+          (AssertionError, ValueError, argparse.ArgumentTypeError)):
+        PagesConfig.parse_dict({
+            "pages": {
+                "TEST": [
+                    {
+                        "action": "get",
+                        "url": "google.com"
+                    },
+                    {
+                        "action": "wait",
+                        "duration": invalid_duration
+                    },
+                ]
+            }
+        })
+
+
+DEVTOOLS_RECORDER_EXAMPLE = {
+    "title":
+        "cnn load",
+    "steps": [
+        {
+            "type": "setViewport",
+            "width": 1628,
+            "height": 397,
+            "deviceScaleFactor": 1,
+            "isMobile": False,
+            "hasTouch": False,
+            "isLandscape": False
+        },
+        {
+            "type":
+                "navigate",
+            "url":
+                "https://edition.cnn.com/",
+            "assertedEvents": [{
+                "type": "navigation",
+                "url": "https://edition.cnn.com/",
+                "title": ""
+            }]
+        },
+        {
+            "type": "click",
+            "target": "main",
+            "selectors": [["aria/Opinion"],
+                          [
+                              "#pageHeader > div > div > "
+                              "div.header__container div:nth-of-type(5) > a"
+                          ],
+                          [
+                              "xpath///*[@id=\"pageHeader\"]/"
+                              "div/div/div[1]/div[1]/nav/div/div[5]/a"
+                          ],
+                          [
+                              "pierce/#pageHeader > div > div > "
+                              "div.header__container div:nth-of-type(5) > a"
+                          ]],
+            "offsetY": 17,
+            "offsetX": 22.515625
+        },
+    ]
+}
+
+
+class DevToolsRecorderPageConfigTestCase(CrossbenchFakeFsTestCase):
+
+  def test_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DevToolsRecorderPagesConfig.parse({})
+    self.assertIn("empty", str(cm.exception))
+
+  def test_missing_title(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DevToolsRecorderPagesConfig.parse({"foo": {}})
+    self.assertIn("title", str(cm.exception))
+
+  def test_basic_config(self):
+    config = DevToolsRecorderPagesConfig.parse(DEVTOOLS_RECORDER_EXAMPLE)
+    self.assertEqual(len(config.pages), 1)
+    page = config.pages[0]
+    self.assertEqual(page.label, "cnn load")
+    self.assertEqual(page.first_url, "https://edition.cnn.com/")
+    self.assertEqual(len(page.blocks), 1)
+    self.assertGreater(len(page.blocks[0].actions), 1)
+
+  def test_basic_config_from_file(self):
+    config_path = pathlib.Path("devtools.config.json")
+    with config_path.open("w", encoding="utf-8") as f:
+      json.dump(DEVTOOLS_RECORDER_EXAMPLE, f)
+    config_file = DevToolsRecorderPagesConfig.parse(config_path)
+    config_dict = DevToolsRecorderPagesConfig.parse(DEVTOOLS_RECORDER_EXAMPLE)
+    self.assertEqual(config_file, config_dict)
+
+  def test_parse_click_step(self):
+    config = {
+        "type": "click",
+        "target": "main",
+        "selectors": [["aria/Search Google"],],
+    }
+    actions = DevToolsRecorderPagesConfig.parse_step(config)
+    self.assertEqual(len(actions), 1)
+    action = actions[0]
+    self.assertEqual(action.TYPE, ActionType.CLICK)
+    assert isinstance(action, ClickAction)
+    self.assertEqual(action.selector, "[aria-label='Search Google']")
+
+    config["selectors"] = [["aria/SIMPLE"], ["#rso > div:nth-of-type(3) h3"],
+                           ["xpath///*[@id=\"rso\"]"],
+                           ["pierce/#rso > div:nth-of-type(3) h3"],
+                           ["text/SIMPLE"]]
+    action = DevToolsRecorderPagesConfig.parse_step(config)[0]
+    assert isinstance(action, ClickAction)
+    self.assertEqual(action.selector, "xpath///*[@id=\"rso\"]")
+
+    config["selectors"] = [
+        ["aria/SIMPLE"],
+        ["css/#rso > div:nth-of-type(3) h3"],
+    ]
+    action = DevToolsRecorderPagesConfig.parse_step(config)[0]
+    assert isinstance(action, ClickAction)
+    self.assertEqual(action.selector, "#rso > div:nth-of-type(3) h3")
+
+    config["selectors"] = [
+        ["#rso > div:nth-of-type(3) h3"],
+    ]
+    action = DevToolsRecorderPagesConfig.parse_step(config)[0]
+    assert isinstance(action, ClickAction)
+    self.assertEqual(action.selector, "#rso > div:nth-of-type(3) h3")
+
+    config["selectors"] = [
+        ["aria/SIMPLE", "area/OTHER"],
+        ["#rso > div:nth-of-type(3) h3"],
+    ]
+    action = DevToolsRecorderPagesConfig.parse_step(config)[0]
+    assert isinstance(action, ClickAction)
+    self.assertEqual(action.selector, "#rso > div:nth-of-type(3) h3")
+
+    config["selectors"] = [
+        ["text/Content"],
+    ]
+    action = DevToolsRecorderPagesConfig.parse_step(config)[0]
+    assert isinstance(action, ClickAction)
+    self.assertEqual(action.selector, "xpath///*[text()='Content']")
+
+
+class ListPageConfigTestCase(CrossbenchFakeFsTestCase):
+
+  def test_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ListPagesConfig.parse({})
+    self.assertIn("empty", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ListPagesConfig.parse({"foo": {}})
+    self.assertIn("pages", str(cm.exception))
+
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ListPagesConfig.parse_dict({"pages": None})
+    self.assertIn("None", str(cm.exception))
+
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ListPagesConfig.parse_dict({"pages": []})
+    self.assertIn("empty", str(cm.exception))
+
+  def test_direct_string_single(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ListPagesConfig.parse("http://foo.bar.com,23s")
+    self.assertIn("http://foo.bar.com,23s", str(cm.exception))
+
+  def test_direct_string_single_dict(self):
+    config_dict = ListPagesConfig.parse({"pages": "http://foo.bar.com,23s"})
+    config_str = PagesConfig(
+        pages=(PageConfig.parse("http://foo.bar.com,23s"),))
+    self.assertEqual(config_dict, config_str)
+
+  @unittest.skip("Combined pages per line not supported yet")
+  def test_direct_string_multiple(self):
+    config = ListPagesConfig.parse_dict(
+        {"pages": "http://a.com,12s,http://b.com,13s"})
+    self.assertEqual(len(config.pages), 2)
+    story_1, story_2 = config.pages
+    self.assertEqual(story_1.first_url, "http://a.com")
+    self.assertEqual(story_2.first_url, "http://b.com")
+    self.assertEqual(story_1.duration.total_seconds(), 12)
+    self.assertEqual(story_2.duration.total_seconds(), 13)
+
+  def test_list(self):
+    page_configs = ["http://a.com,12s", "http://b.com,13s"]
+    config_str = PagesConfig.parse("http://a.com,12s,http://b.com,13s")
+    config_dict_list = ListPagesConfig.parse({"pages": page_configs})
+    config_list = ListPagesConfig.parse(page_configs)
+    self.assertEqual(config_str, config_dict_list)
+    self.assertEqual(config_str, config_list)
+
+  def test_parse_file(self):
+    page_configs = ["http://a.com,12s", "http://b.com,13s"]
+    config_file = pathlib.Path("page_list.txt")
+    with config_file.open("w", encoding="utf-8") as f:
+      f.write("\n".join(page_configs))
+    config_file = ListPagesConfig.parse(config_file)
+    config_list = ListPagesConfig.parse(page_configs)
+    self.assertEqual(config_file, config_list)
+
+  def test_parse_file_empty_lines(self):
+    page_configs = ["http://a.com,12s", "http://b.com,13s"]
+    config_file = pathlib.Path("page_list.txt")
+    with config_file.open("w", encoding="utf-8") as f:
+      f.write("\n")
+      f.write(page_configs[0])
+      f.write("\n\n")
+      f.write(page_configs[1])
+      f.write("\n\n")
+    config_file = ListPagesConfig.parse(config_file)
+    config_list = ListPagesConfig.parse(page_configs)
+    self.assertEqual(config_file, config_list)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/test_action.py b/tests/crossbench/benchmarks/loading/test_action.py
new file mode 100644
index 0000000..cf4beb3
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/test_action.py
@@ -0,0 +1,772 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.enums import ReadyState, WindowTarget
+from crossbench.action_runner.action.get import GetAction
+from crossbench.action_runner.action.inject_new_document_script import \
+    InjectNewDocumentScriptAction
+from crossbench.action_runner.action.js import JsAction
+from crossbench.action_runner.action.scroll import ScrollAction
+from crossbench.action_runner.action.swipe import SwipeAction
+from crossbench.action_runner.action.switch_tab import SwitchTabAction
+from crossbench.action_runner.action.text_input import TextInputAction
+from crossbench.action_runner.action.wait import WaitAction
+from crossbench.action_runner.action.wait_for_element import \
+    WaitForElementAction
+from crossbench.action_runner.action.wait_for_ready_state import \
+    WaitForReadyStateAction
+from crossbench.benchmarks.loading.input_source import InputSource
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class ActionTestCase(CrossbenchFakeFsTestCase):
+
+  def test_parse_get_default(self):
+    config_dict = {"action": "get", "url": "http://crossben.ch"}
+    action = GetAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.GET)
+    self.assertEqual(action.url, "http://crossben.ch")
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.duration, dt.timedelta())
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = GetAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_get_all(self):
+    config_dict = {
+        "action": "get",
+        "url": "http://crossben.ch",
+        "duration": "12s",
+        "timeout": "34s",
+        "ready_state": "any",
+        "target": "_top"
+    }
+    action = GetAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.GET)
+    self.assertEqual(action.url, "http://crossben.ch")
+    self.assertEqual(action.timeout, dt.timedelta(seconds=34))
+    self.assertEqual(action.duration, dt.timedelta(seconds=12))
+    self.assertEqual(action.ready_state, ReadyState.ANY)
+    self.assertEqual(action.target, WindowTarget.TOP)
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = GetAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_get_new_tab(self):
+    config_dict = {
+        "action": "get",
+        "url": "http://crossben.ch",
+        "target": "_new_tab"
+    }
+    action = GetAction.parse_dict(config_dict)
+    self.assertEqual(action.target, WindowTarget.NEW_TAB)
+    action.validate()
+
+    action_2 = GetAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_get_new_window(self):
+    config_dict = {
+        "action": "get",
+        "url": "http://crossben.ch",
+        "target": "_new_window"
+    }
+    action = GetAction.parse_dict(config_dict)
+    self.assertEqual(action.target, WindowTarget.NEW_WINDOW)
+    action.validate()
+
+    action_2 = GetAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_get_invalid_url(self):
+    with self.assertRaises(ValueError) as cm:
+      GetAction.parse_dict({
+          "action": "get",
+          "url": "",
+      })
+    self.assertIn("url", str(cm.exception))
+
+  def test_parse_get_invalid_duration(self):
+    with self.assertRaises(ValueError) as cm:
+      GetAction.parse_dict({
+          "action": "get",
+          "url": "http://crossben.ch",
+          "duration": "-12s"
+      })
+    self.assertIn("duration", str(cm.exception))
+
+  def test_parse_get_invalid_duration_for_ready_state(self):
+    with self.assertRaises(ValueError):
+      GetAction.parse_dict({
+          "action": "get",
+          "url": "http://crossben.ch",
+          "ready_state": "interactive",
+          "duration": "12s"
+      })
+
+  def test_parse_wait_default(self):
+    config_dict = {"action": "wait", "duration": "12s"}
+    action = WaitAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.WAIT)
+    self.assertEqual(action.duration, dt.timedelta(seconds=12))
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = WaitAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_wait_missing_duration(self):
+    with self.assertRaises(ValueError) as cm:
+      WaitAction.parse_dict({"action": "wait"})
+    self.assertIn("duration", str(cm.exception))
+
+  def test_parse_scroll_default(self):
+    config_dict = {"action": "scroll"}
+    action = ScrollAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.SCROLL)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.duration, dt.timedelta(seconds=1))
+    self.assertEqual(action.distance, 500)
+    self.assertEqual(action.input_source, InputSource.JS)
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = ScrollAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_scroll_all(self):
+    config_dict = {
+        "action": "scroll",
+        "distance": "123",
+        "timeout": "12s",
+        "duration": "34s",
+        "source": "js",
+        "selector": "#button",
+        "required": "true"
+    }
+    action = ScrollAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.SCROLL)
+    self.assertEqual(action.timeout, dt.timedelta(seconds=12))
+    self.assertEqual(action.duration, dt.timedelta(seconds=34))
+    self.assertEqual(action.distance, 123)
+    self.assertEqual(action.input_source, InputSource.JS)
+    self.assertTrue(action.required)
+    self.assertEqual(action.selector, "#button")
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = ScrollAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_scroll_invalid_source(self):
+    config_dict = {
+        "action": "scroll",
+        "source": "invalid source",
+    }
+
+    with self.assertRaises(ValueError) as cm:
+      ScrollAction.parse_dict(config_dict)
+
+    self.assertIn("source", str(cm.exception))
+
+  def test_parse_scroll_valid_but_unsupported_source(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "scroll",
+          "source": "keyboard",
+      })
+    self.assertIn("source", str(cm.exception))
+
+  def test_parse_scroll_required_missing_selector(self):
+    config_dict = {
+        "action": "scroll",
+        "required": "true",
+    }
+
+    with self.assertRaises(ValueError) as cm:
+      ScrollAction.parse_dict(config_dict)
+
+    self.assertIn("required", str(cm.exception))
+
+  def test_scroll_invalid_distance(self):
+    with self.assertRaises(ValueError) as cm:
+      ScrollAction.parse_dict({"action": "scroll", "distance": ""})
+    self.assertIn("distance", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      ScrollAction.parse_dict({"action": "scroll", "distance": "0"})
+    self.assertIn("distance", str(cm.exception))
+
+  def test_parse_click_minimal_selector(self):
+    config_dict = {"action": "click", "selector": "#button"}
+    action = ClickAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.CLICK)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.input_source, InputSource.JS)
+    self.assertEqual(action.selector, "#button")
+    self.assertFalse(action.required)
+    self.assertFalse(action.scroll_into_view)
+    self.assertIsNone(action.coordinates)
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = ClickAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_click_minimal_coordinates(self):
+    config_dict = {"action": "click", "source": "touch", "x": 1, "y": 2}
+    action = ClickAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.CLICK)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.input_source, InputSource.TOUCH)
+    self.assertIsNone(action.selector)
+    self.assertFalse(action.required)
+    self.assertFalse(action.scroll_into_view)
+    self.assertEqual(action.coordinates.x, 1)
+    self.assertEqual(action.coordinates.y, 2)
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = ClickAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_click_selector_all(self):
+    config_dict = {
+        "action": "click",
+        "source": "js",
+        "selector": "#button",
+        "required": True,
+        "scroll_into_view": True,
+        "timeout": "12s"
+    }
+    action = ClickAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.CLICK)
+    self.assertEqual(action.timeout, dt.timedelta(seconds=12))
+    self.assertEqual(action.input_source, InputSource.JS)
+    self.assertEqual(action.selector, "#button")
+    self.assertTrue(action.required)
+    self.assertTrue(action.scroll_into_view)
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = ClickAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_click_invalid_source(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "click",
+          "source": "invalid_source",
+          "selector": "#button"
+      })
+    self.assertIn("source", str(cm.exception))
+
+  def test_parse_click_valid_but_unsupported_source(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "click",
+          "source": "keyboard",
+          "selector": "#button"
+      })
+    self.assertIn("source", str(cm.exception))
+
+  def test_parse_click_invalid_selector(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({"action": "click", "selector": ""})
+    self.assertIn("selector", str(cm.exception))
+
+  def test_parse_click_selector_and_coordinates(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "click",
+          "source": "TOUCH",
+          "selector": "#button",
+          "x": 0,
+          "y": 0
+      })
+    self.assertIn("either selector or coordinates", str(cm.exception))
+
+  def test_parse_click_incomplete_coordinates(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({"action": "click", "source": "TOUCH", "x": 0})
+    self.assertIn("Either selector or coordinates", str(cm.exception))
+
+  def test_parse_click_coordinates_with_required(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "click",
+          "source": "TOUCH",
+          "x": 0,
+          "y": 0,
+          "required": "true"
+      })
+    self.assertIn("required", str(cm.exception))
+
+  def test_parse_click_coordinates_with_scroll(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "click",
+          "source": "TOUCH",
+          "x": 0,
+          "y": 0,
+          "scroll_into_view": "true"
+      })
+    self.assertIn("scroll_into_view", str(cm.exception))
+
+  def test_parse_click_coordinates_with_js(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "click",
+          "source": "JS",
+          "x": 0,
+          "y": 0
+      })
+    self.assertIn("JS", str(cm.exception))
+
+  def test_parse_click_missing_coordinates_and_selector(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({"action": "click", "source": "TOUCH"})
+    self.assertIn("Either selector or coordinates", str(cm.exception))
+
+  def test_parse_swipe(self):
+    config_dict = {
+        "action": "swipe",
+        "startx": 100,
+        "starty": 200,
+        "endx": 110,
+        "endy": 220,
+        "duration": "12s"
+    }
+    action = SwipeAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.SWIPE)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.duration, dt.timedelta(seconds=12))
+    self.assertEqual(action.start_x, 100)
+    self.assertEqual(action.start_y, 200)
+    self.assertEqual(action.end_x, 110)
+    self.assertEqual(action.end_y, 220)
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = SwipeAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_text_input_minimal(self):
+    config_dict = {
+        "action": "text_input",
+        "duration": "10s",
+        "text": "some text"
+    }
+    action = TextInputAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.TEXT_INPUT)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.input_source, InputSource.JS)
+    self.assertEqual(action.text, "some text")
+    self.assertEqual(action.duration, dt.timedelta(seconds=10))
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = TextInputAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_text_input_non_default_source(self):
+    config_dict = {
+        "action": "text_input",
+        "duration": "1s",
+        "source": "keyboard",
+        "text": "some text",
+    }
+    action = TextInputAction.parse_dict(config_dict)
+
+    self.assertEqual(action.input_source, InputSource.KEYBOARD)
+
+  def test_parse_text_input_invalid_source(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "text_input",
+          "duration": "1s",
+          "source": "invalid_source",
+          "text": "some text",
+      })
+    self.assertIn("source", str(cm.exception))
+
+  def test_parse_text_input_valid_but_unsupported_source(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "text_input",
+          "duration": "1s",
+          "source": "mouse",
+          "text": "some text",
+      })
+    self.assertIn("source", str(cm.exception))
+
+  def test_parse_text_input_negative_duration(self):
+    config_dict = {
+        "action": "text_input",
+        "text": "some text",
+        "duration": "-1s"
+    }
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict(config_dict)
+    self.assertIn("duration", str(cm.exception))
+
+  def test_parse_text_input_missing_text(self):
+    config_dict = {"action": "text_input", "duration": "1s"}
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict(config_dict)
+    self.assertIn("text", str(cm.exception))
+
+  def test_parse_wait_for_element(self):
+    config_dict = {
+        "action": "wait_for_element",
+        "selector": "#button",
+    }
+    action = WaitForElementAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.WAIT_FOR_ELEMENT)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.selector, "#button")
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = WaitForElementAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_wait_for_element_timeout(self):
+    config_dict = {
+        "action": "wait_for_element",
+        "selector": "#button",
+        "timeout": "12s"
+    }
+    action = WaitForElementAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.WAIT_FOR_ELEMENT)
+    self.assertEqual(action.timeout, dt.timedelta(seconds=12))
+    self.assertEqual(action.selector, "#button")
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = WaitForElementAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_js_script(self):
+    config_dict = {
+        "action": "js",
+        "script": "alert(1)",
+    }
+    action = JsAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.JS)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.script, "alert(1)")
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = JsAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_js_script_path(self):
+    path = self.create_file("/foo/bar.js", contents="alert(2)")
+    config_dict = {
+        "action": "js",
+        "script_path": str(path),
+    }
+    action = JsAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.JS)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.script, "alert(2)")
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = JsAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_js_script_path_with_replacements(self):
+    path = self.create_file("/foo/bar.js", contents="alert($ALERT$)")
+    config_dict = {
+        "action": "js",
+        "script_path": str(path),
+        "replace": {
+            "$ALERT$": "'something'"
+        }
+    }
+    action = JsAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.JS)
+    self.assertEqual(action.script, "alert('something')")
+    action.validate()
+
+    action_2 = JsAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_js_script_invalid(self):
+    config_dict = {
+        "action": "js",
+        "script": "",
+    }
+    with self.assertRaises(ValueError) as cm:
+      JsAction.parse_dict(config_dict)
+    self.assertIn("script", str(cm.exception))
+
+
+  def test_js_script_invalid_path(self):
+    config_dict = {
+        "action": "js",
+        "script_path": "",
+    }
+    with self.assertRaises(ValueError) as cm:
+      JsAction.parse_dict(config_dict)
+    self.assertIn("script_path", str(cm.exception))
+
+    config_dict = {
+        "action": "js",
+        "script_path": "/does/not/exist.js",
+    }
+    with self.assertRaises(ValueError) as cm:
+      JsAction.parse_dict(config_dict)
+    self.assertIn("script_path", str(cm.exception))
+
+
+  def test_js_script_invalid_script_xor_path(self):
+    path = self.create_file("/foo/bar.js", contents="alert(2)")
+    config_dict = {
+        "action": "js",
+        "script": "alert(1)",
+        "script_path": str(path),
+    }
+    with self.assertRaises(ValueError) as cm:
+      JsAction.parse_dict(config_dict)
+    self.assertIn("script_path", str(cm.exception))
+
+
+  def test_js_script_invalid_replacements(self):
+    path = self.create_file("/foo/bar.js", contents="alert(2)")
+    config_dict = {
+        "action": "js",
+        "script_path": str(path),
+        "replacements": {
+            1: 1,
+            "one": 1,
+        }
+    }
+    with self.assertRaises(ValueError) as cm:
+      JsAction.parse_dict(config_dict)
+    self.assertIn("replacements", str(cm.exception))
+
+
+  def test_inject_new_document_script_script(self):
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script": "alert(1)",
+    }
+    action = InjectNewDocumentScriptAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.INJECT_NEW_DOCUMENT_SCRIPT)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.script, "alert(1)")
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = InjectNewDocumentScriptAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_inject_new_document_script_script_path(self):
+    path = self.create_file("/foo/bar.js", contents="alert(2)")
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script_path": str(path),
+    }
+    action = InjectNewDocumentScriptAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.INJECT_NEW_DOCUMENT_SCRIPT)
+    self.assertEqual(action.timeout, ACTION_TIMEOUT)
+    self.assertEqual(action.script, "alert(2)")
+    self.assertTrue(action.has_timeout)
+    action.validate()
+
+    action_2 = InjectNewDocumentScriptAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_inject_new_document_script_path_with_replacements(self):
+    path = self.create_file("/foo/bar.js", contents="alert($ALERT$)")
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script_path": str(path),
+        "replace": {
+            "$ALERT$": "'something'"
+        }
+    }
+    action = InjectNewDocumentScriptAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.INJECT_NEW_DOCUMENT_SCRIPT)
+    self.assertEqual(action.script, "alert('something')")
+    action.validate()
+
+    action_2 = InjectNewDocumentScriptAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_inject_new_document_script_invalid(self):
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script": "",
+    }
+    with self.assertRaises(ValueError) as cm:
+      InjectNewDocumentScriptAction.parse_dict(config_dict)
+    self.assertIn("script", str(cm.exception))
+
+
+  def test_inject_new_document_script_invalid_path(self):
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script_path": "",
+    }
+    with self.assertRaises(ValueError) as cm:
+      InjectNewDocumentScriptAction.parse_dict(config_dict)
+    self.assertIn("script_path", str(cm.exception))
+
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script_path": "/does/not/exist.js",
+    }
+    with self.assertRaises(ValueError) as cm:
+      InjectNewDocumentScriptAction.parse_dict(config_dict)
+    self.assertIn("script_path", str(cm.exception))
+
+
+  def test_inject_new_document_script_invalid_script_xor_path(self):
+    path = self.create_file("/foo/bar.js", contents="alert(2)")
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script": "alert(1)",
+        "script_path": str(path),
+    }
+    with self.assertRaises(ValueError) as cm:
+      InjectNewDocumentScriptAction.parse_dict(config_dict)
+    self.assertIn("script_path", str(cm.exception))
+
+
+  def test_inject_new_document_script_invalid_replacements(self):
+    path = self.create_file("/foo/bar.js", contents="alert(2)")
+    config_dict = {
+        "action": "inject_new_document_script",
+        "script_path": str(path),
+        "replacements": {
+            1: 1,
+            "one": 1,
+        }
+    }
+    with self.assertRaises(ValueError) as cm:
+      InjectNewDocumentScriptAction.parse_dict(config_dict)
+    self.assertIn("replacements", str(cm.exception))
+
+
+  def test_parse_switch_tab_all_args(self):
+    config_dict = {
+        "action": "switch_tab",
+        "tab_index": 17,
+        "title": "^Example.*",
+        "url": "http(s)?://example.com"
+    }
+    action = SwitchTabAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.SWITCH_TAB)
+    self.assertEqual(action.tab_index, 17)
+    self.assertEqual(action.title.pattern, "^Example.*")
+    self.assertEqual(action.url.pattern, "http(s)?://example.com")
+    action.validate()
+
+    action_2 = SwitchTabAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_switch_tab_no_args(self):
+    config_dict = {
+        "action": "switch_tab",
+    }
+    action = SwitchTabAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.SWITCH_TAB)
+    self.assertEqual(action.tab_index, None)
+    self.assertEqual(action.title, None)
+    self.assertEqual(action.url, None)
+    action.validate()
+
+    action_2 = SwitchTabAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_wait_for_ready_state(self):
+    config_dict = {
+        "action": "wait_for_ready_state",
+    }
+    action = WaitForReadyStateAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.WAIT_FOR_READY_STATE)
+    self.assertEqual(action.ready_state, ReadyState.COMPLETE)
+    action.validate()
+
+    action_2 = WaitForReadyStateAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_wait_for_ready_state_interactive(self):
+    config_dict = {
+        "action": "wait_for_ready_state",
+        "ready_state": "interactive",
+    }
+    action = WaitForReadyStateAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.WAIT_FOR_READY_STATE)
+    self.assertEqual(action.ready_state, ReadyState.INTERACTIVE)
+    action.validate()
+
+    action_2 = WaitForReadyStateAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/test_loading.py b/tests/crossbench/benchmarks/loading/test_loading.py
new file mode 100644
index 0000000..117ddf5
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/test_loading.py
@@ -0,0 +1,713 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# pytype: disable=attribute-error
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import json
+import pathlib
+import re
+import unittest
+from typing import List, Sequence, cast
+from unittest import mock
+
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.base import ActionRunner
+from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.benchmarks.loading.config.blocks import ActionBlockListConfig
+from crossbench.benchmarks.loading.config.login.google import GOOGLE_LOGIN_URL
+from crossbench.benchmarks.loading.loading_benchmark import (LoadingPageFilter,
+                                                             PageLoadBenchmark)
+from crossbench.benchmarks.loading.page.combined import CombinedPage
+from crossbench.benchmarks.loading.page.interactive import InteractivePage
+from crossbench.benchmarks.loading.page.live import (PAGE_LIST, PAGE_LIST_SMALL,
+                                                     LivePage)
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.benchmarks.loading.tab_controller import TabController
+from crossbench.browsers.settings import Settings
+from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.runner.runner import Runner
+from tests import test_helper
+from tests.crossbench.base import BaseCliTestCase
+from tests.crossbench.benchmarks import helper
+from tests.crossbench.mock_browser import JsInvocation
+
+
+class TestPageLoadBenchmark(helper.SubStoryTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return PageLoadBenchmark
+
+  def story_filter(  # pylint: disable=arguments-differ
+      self,
+      patterns: Sequence[str],
+      separate: bool = True,
+      playback: PlaybackController = PlaybackController.default(),
+      tabs: TabController = TabController.default(),
+      action_runner: ActionRunner = BasicActionRunner(),
+      about_blank_duration: dt.timedelta = dt.timedelta(),
+      run_login: bool = True,
+      run_setup: bool = True) -> LoadingPageFilter:
+    args = argparse.Namespace(
+        about_blank_duration=about_blank_duration,
+        playback=playback,
+        tabs=tabs,
+        action_runner=action_runner,
+        run_login=run_login,
+        run_setup=run_setup)
+    return cast(LoadingPageFilter,
+                super().story_filter(patterns, args=args, separate=separate))
+
+  def test_page_list(self):
+    self.assertTrue(PAGE_LIST)
+    self.assertTrue(PAGE_LIST_SMALL)
+    for page in PAGE_LIST:
+      self.assertIsInstance(page, InteractivePage)
+    for page in PAGE_LIST_SMALL:
+      self.assertIsInstance(page, InteractivePage)
+
+  def test_all_stories(self):
+    stories = self.story_filter(["all"]).stories
+    self.assertGreater(len(stories), 1)
+    for story in stories:
+      self.assertIsInstance(story, LivePage)
+    names = set(story.name for story in stories)
+    self.assertEqual(len(names), len(stories))
+    self.assertEqual(names, set(page.name for page in PAGE_LIST))
+
+  def test_default_stories(self):
+    stories = self.story_filter(["default"]).stories
+    self.assertGreater(len(stories), 1)
+    for story in stories:
+      self.assertIsInstance(story, LivePage)
+    names = set(story.name for story in stories)
+    self.assertEqual(len(names), len(stories))
+    self.assertEqual(names, set(page.name for page in PAGE_LIST_SMALL))
+
+  def test_combined_stories(self):
+    stories = self.story_filter(["all"], separate=False).stories
+    self.assertEqual(len(stories), 1)
+    combined = stories[0]
+    self.assertIsInstance(combined, CombinedPage)
+
+  def test_filter_by_name(self):
+    for preset_page in PAGE_LIST:
+      stories = self.story_filter([preset_page.name]).stories
+      self.assertListEqual([p.url for p in stories], [preset_page.url])
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      self.story_filter([])
+    self.assertIn("empty", str(cm.exception).lower())
+
+  def test_filter_by_name_with_duration(self):
+    pages = PAGE_LIST
+    filtered_pages = self.story_filter([pages[0].name, pages[1].name,
+                                        "1001"]).stories
+    self.assertListEqual([p.url for p in filtered_pages],
+                         [pages[0].url, pages[1].url])
+    self.assertEqual(filtered_pages[0].duration, pages[0].duration)
+    self.assertEqual(filtered_pages[1].duration, dt.timedelta(seconds=1001))
+
+  def test_page_by_url(self):
+    url1 = "http://example.com/test1"
+    url2 = "http://example.com/test2"
+    stories = self.story_filter([url1, url2]).stories
+    self.assertEqual(len(stories), 2)
+    self.assertEqual(stories[0].first_url, url1)
+    self.assertEqual(stories[1].first_url, url2)
+
+  def test_page_by_url_www(self):
+    url1 = "www.example.com/test1"
+    url2 = "www.example.com/test2"
+    stories = self.story_filter([url1, url2]).stories
+    self.assertEqual(len(stories), 2)
+    self.assertEqual(stories[0].first_url, f"https://{url1}")
+    self.assertEqual(stories[1].first_url, f"https://{url2}")
+
+  def test_page_by_url_combined(self):
+    url1 = "http://example.com/test1"
+    url2 = "http://example.com/test2"
+    stories = self.story_filter([url1, url2], separate=False).stories
+    self.assertEqual(len(stories), 1)
+    combined = stories[0]
+    self.assertIsInstance(combined, CombinedPage)
+
+  def test_run_combined(self):
+    stories = [CombinedPage(PAGE_LIST)]
+    self._test_run(stories)
+    self._assert_urls_loaded([story.url for story in PAGE_LIST])
+
+  def test_run_default(self):
+    stories = PAGE_LIST
+    self._test_run(stories)
+    self._assert_urls_loaded([story.url for story in stories])
+
+  def test_run_throw(self):
+    stories = PAGE_LIST
+    self._test_run(stories)
+    self._assert_urls_loaded([story.url for story in stories])
+
+  def test_run_repeat_with_about_blank(self):
+    url1 = "https://www.example.com/test1"
+    url2 = "https://www.example.com/test2"
+    stories = self.story_filter(
+        [url1, url2],
+        separate=False,
+        about_blank_duration=dt.timedelta(seconds=1)).stories
+    self._test_run(stories)
+    urls = [url1, "about:blank", url2, "about:blank"]
+    self._assert_urls_loaded(urls)
+
+  def test_run_repeat_with_about_blank_separate(self):
+    url1 = "https://www.example.com/test1"
+    url2 = "https://www.example.com/test2"
+    stories = self.story_filter(
+        [url1, url2],
+        separate=True,
+        about_blank_duration=dt.timedelta(seconds=1)).stories
+    self._test_run(stories)
+    urls = [url1, "about:blank", url2, "about:blank"]
+    self._assert_urls_loaded(urls)
+
+  def test_run_repeat(self):
+    url1 = "https://www.example.com/test1"
+    url2 = "https://www.example.com/test2"
+    stories = self.story_filter([url1, url2],
+                                separate=False,
+                                playback=PlaybackController.repeat(3)).stories
+    self._test_run(stories)
+    urls = [url1, url2] * 3
+    self._assert_urls_loaded(urls)
+
+  def test_run_repeat_separate(self):
+    url1 = "https://www.example.com/test1"
+    url2 = "https://www.example.com/test2"
+    stories = self.story_filter([url1, url2],
+                                separate=True,
+                                playback=PlaybackController.repeat(3)).stories
+    self._test_run(stories)
+    urls = [url1] * 3 + [url2] * 3
+    self._assert_urls_loaded(urls)
+
+  def _test_run(self, stories, throw: bool = False):
+    benchmark = self.benchmark_cls(stories)
+    self.assertTrue(len(benchmark.describe()) > 0)
+    runner = Runner(
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        env_config=HostEnvironmentConfig(),
+        env_validation_mode=ValidationMode.SKIP,
+        platform=self.platform,
+        throw=throw)
+    runner.run()
+    self.assertTrue(runner.is_success)
+    self.assertTrue(self.browsers[0].did_run)
+    self.assertTrue(self.browsers[1].did_run)
+
+  def _assert_urls_loaded(self, story_urls):
+    browser_1_urls = self.filter_splashscreen_urls(self.browsers[0].url_list)
+    self.assertEqual(browser_1_urls, story_urls)
+    browser_2_urls = self.filter_splashscreen_urls(self.browsers[1].url_list)
+    self.assertEqual(browser_2_urls, story_urls)
+
+
+class LoadingBenchmarkCliTestCase(BaseCliTestCase):
+
+  def test_invalid_duplicate_urls_stories(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      with self.patch_get_browser():
+        url = "http://test.com"
+        self.run_cli("loading", "run", f"--urls={url}", f"--stories={url}",
+                     "--env-validation=skip", "--throw")
+    self.assertIn("--urls", str(cm.exception))
+    self.assertIn("--stories", str(cm.exception))
+
+  def test_invalid_duplicate_urls_config(self):
+    with self.assertRaises(argparse.ArgumentError) as cm:
+      with self.patch_get_browser():
+        self.run_cli("loading", "run", "--urls=https://test.com",
+                     "--page-config=config.hjson", "--env-validation=skip",
+                     "--throw")
+    self.assertIn("--urls", str(cm.exception))
+    self.assertIn("--page-config", str(cm.exception))
+
+  def test_invalid_duplicate_stories_config(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      with self.patch_get_browser():
+        self.run_cli("loading", "run", "--stories=https://test.com",
+                     "--page-config=config.hjson", "--env-validation=skip",
+                     "--throw")
+    self.assertIn("--stories", str(cm.exception))
+    self.assertIn("page config", str(cm.exception).lower())
+
+  def test_conflicting_global_config(self):
+    config_data = {
+        "browsers": {
+            "chrome": "chrome-stable"
+        },
+        "pages": {
+            "google_search_result": [{
+                "action": "get",
+                "url": "https://www.google.com/search?q=cats"
+            },]
+        }
+    }
+    config_file = pathlib.Path("config.hjson")
+    with config_file.open("w", encoding="utf-8") as f:
+      json.dump(config_data, f)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      with self.patch_get_browser():
+        self.run_cli("loading", "run", "--stories=https://test.com",
+                     "--config=config.hjson", "--page-config=config.hjson",
+                     "--env-validation=skip", "--throw")
+    error_message = str(cm.exception).lower()
+    self.assertIn("conflict", error_message)
+    self.assertIn("--config", error_message)
+    self.assertIn("--page-config", error_message)
+
+  def test_page_list_file(self):
+    config = pathlib.Path("test/pages.txt")
+    self.fs.create_file(config)
+    url_1 = "http://one.test.com"
+    url_2 = "http://two.test.com"
+    with config.open("w", encoding="utf-8") as f:
+      f.write("\n".join((url_1, url_2)))
+    with self.patch_get_browser():
+      self.run_cli("loading", "run", f"--urls-file={config}",
+                   "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url_1, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def test_page_list_file_separate(self):
+    config = pathlib.Path("test/pages.txt")
+    self.fs.create_file(config)
+    url_1 = "http://one.test.com"
+    url_2 = "http://two.test.com"
+    with config.open("w", encoding="utf-8") as f:
+      f.write("\n".join((url_1, url_2)))
+    with self.patch_get_browser():
+      self.run_cli("loading", "run", f"--urls-file={config}",
+                   "--env-validation=skip", "--separate", "--throw")
+      for browser in self.browsers:
+        self.assertEqual(len(browser.url_list), (self.SPLASH_URLS_LEN + 1) * 2)
+        self.assertEqual(url_1, browser.url_list[self.SPLASH_URLS_LEN])
+        self.assertEqual(url_2, browser.url_list[self.SPLASH_URLS_LEN * 2 + 1])
+
+  def test_urls_single(self):
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", "run", f"--urls={url}", "--env-validation=skip",
+                   "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def test_urls_multiple(self):
+    with self.patch_get_browser():
+      url_1 = "http://one.test.com"
+      url_2 = "http://two.test.com"
+      self.run_cli("loading", "run", f"--urls={url_1},{url_2}",
+                   "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url_1, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def test_urls_multiple_separate(self):
+    with self.patch_get_browser():
+      url_1 = "http://one.test.com"
+      url_2 = "http://two.test.com"
+      self.run_cli("loading", "run", f"--urls={url_1},{url_2}",
+                   "--env-validation=skip", "--separate", "--throw")
+      for browser in self.browsers:
+        self.assertEqual(len(browser.url_list), (self.SPLASH_URLS_LEN + 1) * 2)
+        self.assertEqual(url_1, browser.url_list[self.SPLASH_URLS_LEN])
+        self.assertEqual(url_2, browser.url_list[self.SPLASH_URLS_LEN * 2 + 1])
+
+  def test_repeat_playback(self):
+    with self.patch_get_browser():
+      url_1 = "http://one.test.com"
+      url_2 = "http://two.test.com"
+      self.run_cli("loading", "run", f"--urls={url_1},{url_2}", "--playback=2x",
+                   "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url_1, url_2, url_1, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def test_repeat_playback_separate(self):
+    with self.patch_get_browser():
+      url_1 = "http://one.test.com"
+      url_2 = "http://two.test.com"
+      self.run_cli("loading", "run", f"--urls={url_1},{url_2}", "--playback=2x",
+                   "--separate", "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertEqual(len(browser.url_list), (self.SPLASH_URLS_LEN + 2) * 2)
+        self.assertListEqual(
+            [url_1, url_1],
+            browser.url_list[self.SPLASH_URLS_LEN:self.SPLASH_URLS_LEN + 2])
+        self.assertListEqual([url_2, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN * 2 + 2:])
+
+  def simple_pages_config(self):
+    url_1 = "http://one.test.com"
+    url_2 = "http://two.test.com"
+    config = {
+        "pages": {
+            "test_one": [{
+                "action": "get",
+                "url": url_1
+            }, {
+                "action": "get",
+                "url": url_2
+            }]
+        }
+    }
+    return url_1, url_2, config
+
+  def test_actions_config(self):
+    url_1, url_2, config = self.simple_pages_config()
+    config_file = pathlib.Path("test/page_config.json")
+    self.fs.create_file(config_file, contents=json.dumps(config))
+    with self.patch_get_browser():
+      self.run_cli("loading", "run", f"--page-config={config_file}",
+                   "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url_1, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def setup_expected_google_login_js(self):
+    expected_scripts: List[JsInvocation] = [
+        JsInvocation(True, re.compile(r".*Email or phone.*")),
+        JsInvocation(None, re.compile(r".*user@test.com.*")),
+        JsInvocation(True, re.compile(r".*passwordNext.*")),
+        JsInvocation(False, re.compile(r".*verifycontactNext.*")),
+        JsInvocation(True, re.compile(r".*Enter your password.*")),
+        JsInvocation(True, re.compile(r".*s3cr3t.*")),
+        JsInvocation(True, re.compile(r".*https://myaccount.google.com.*")),
+    ]
+    for browser in self.browsers:
+      for script in expected_scripts:
+        browser.expect_js(script)
+
+  def simple_pages_with_login_config(self):
+    url_1 = "http://one.test.com"
+    url_2 = "http://two.test.com"
+    config = {
+        "pages": {
+            "test_one": {
+                "login":
+                    "google",
+                "actions": [{
+                    "action": "get",
+                    "url": url_1
+                }, {
+                    "action": "get",
+                    "url": url_2
+                }]
+            }
+        }
+    }
+    return url_1, url_2, config
+
+  def test_actions_config_with_login_preset(self):
+    url_1, url_2, config = self.simple_pages_with_login_config()
+    config.update({
+        "secrets": {
+            "google": {
+                "username": "user@test.com",
+                "password": "s3cr3t"
+            }
+        },
+    })
+    config_file = pathlib.Path("test/page_config.json")
+    self.fs.create_file(config_file, contents=json.dumps(config))
+    self.setup_expected_google_login_js()
+    with self.patch_get_browser():
+      self.run_cli("loading", "run", f"--page-config={config_file}",
+                   "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([GOOGLE_LOGIN_URL, url_1, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def test_actions_config_with_login_preset_global_secrets(self):
+    url_1, url_2, config = self.simple_pages_with_login_config()
+    config_file = pathlib.Path("test/page_config.json")
+    self.fs.create_file(config_file, contents=json.dumps(config))
+    secrets_data = {
+        "google": {
+            "username": "user@test.com",
+            "password": "s3cr3t"
+        }
+    }
+    secrets_dict = SecretsConfig.parse(secrets_data).as_dict()
+    self.setup_expected_google_login_js()
+    with self.patch_get_browser():
+      with mock.patch.object(
+          Settings, "secrets",
+          new_callable=mock.PropertyMock) as mock_get_secrets:
+        mock_get_secrets.return_value = secrets_dict
+        self.run_cli("loading", "run", f"--page-config={config_file}",
+                     "--env-validation=skip", "--throw",
+                     f"--secrets={json.dumps(secrets_data)}")
+      for browser in self.browsers:
+        self.assertListEqual([GOOGLE_LOGIN_URL, url_1, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def test_actions_config_with_login_preset_missing_secrets(self):
+    _, _, config = self.simple_pages_with_login_config()
+    config_file = pathlib.Path("test/page_config.json")
+    self.fs.create_file(config_file, contents=json.dumps(config))
+    self.setup_expected_google_login_js()
+    with self.patch_get_browser():
+      with self.assertRaises(Exception) as cm:
+        self.run_cli("loading", "run", f"--page-config={config_file}",
+                     "--env-validation=skip", "--throw")
+      self.assertIn("google", str(cm.exception))
+
+  def test_global_config_actions_config(self):
+    url_1 = "http://one.test.com"
+    url_2 = "http://two.test.com"
+    global_config_file = pathlib.Path("config.hjson")
+    global_config_data = {
+        # Dummy entry, not actually used by the test
+        "browsers": {
+            "chrome": "chrome-stable"
+        },
+        "pages": {
+            "test_one": [{
+                "action": "get",
+                "url": url_1
+            }, {
+                "action": "get",
+                "url": url_2
+            }]
+        }
+    }
+    with global_config_file.open("w", encoding="utf-8") as f:
+      json.dump(global_config_data, f)
+    with self.patch_get_browser():
+      self.run_cli("loading", "run", f"--config={global_config_file}",
+                   "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url_1, url_2],
+                             browser.url_list[self.SPLASH_URLS_LEN:])
+
+
+class ActionBlockListConfigTestCase(unittest.TestCase):
+
+  def test_parse_invalid(self):
+    for invalid in ("", (), {}, 1):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          ActionBlockListConfig.parse(invalid)
+
+  def test_parse_default_action_list(self):
+    config = ActionBlockListConfig.parse([{
+        "action": "get",
+        "url": "http://test.com",
+        "duration": "12.5s",
+    }])
+    self.assertEqual(len(config.blocks), 1)
+    block = config.blocks[0]
+    self.assertEqual(block.label, "default")
+    self.assertEqual(len(block.actions), 1)
+    self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+    self.assertEqual(block.duration, dt.timedelta(seconds=12.5))
+
+  def test_parse_default_action_list_2(self):
+    config = ActionBlockListConfig.parse([{
+        "action": "get",
+        "url": "http://test.com",
+        "duration": "12.5s",
+    }, {
+        "action": "wait",
+        "duration": "100s",
+    }])
+    self.assertEqual(len(config.blocks), 1)
+    block = config.blocks[0]
+    self.assertEqual(block.label, "default")
+    self.assertEqual(len(block.actions), 2)
+    self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+    self.assertEqual(block.actions[1].TYPE, ActionType.WAIT)
+    self.assertEqual(block.duration, dt.timedelta(seconds=112.5))
+
+  def test_parse_single_block_action_list(self):
+    config = ActionBlockListConfig.parse([{
+        "label": "block 1",
+        "actions": [{
+            "action": "get",
+            "url": "http://test.com"
+        }]
+    }])
+    self.assertEqual(len(config.blocks), 1)
+    block = config.blocks[0]
+    self.assertEqual(block.label, "block 1")
+    self.assertEqual(len(block.actions), 1)
+    self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+
+  def test_parse_multi_block_action_list(self):
+    config = ActionBlockListConfig.parse([{
+        "label":
+            "block 0",
+        "actions": [{
+            "action": "get",
+            "url": "http://test.com/0",
+            "duration": "10s",
+        }]
+    }, {
+        "label":
+            "block 1",
+        "actions": [{
+            "action": "get",
+            "url": "http://test.com/1",
+            "duration": "11s",
+        }]
+    }])
+    self.assertEqual(len(config.blocks), 2)
+    for index, block in enumerate(config.blocks):
+      self.assertEqual(block.label, f"block {index}")
+      self.assertEqual(len(block.actions), 1)
+      self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+      self.assertEqual(block.actions[0].url, f"http://test.com/{index}")
+      self.assertEqual(block.duration, dt.timedelta(seconds=10 + index))
+
+  def test_parse_single_block_dict(self):
+    config = ActionBlockListConfig.parse(
+        {"block 1": {
+            "actions": [{
+                "action": "get",
+                "url": "http://test.com"
+            }]
+        }})
+    self.assertEqual(len(config.blocks), 1)
+    block = config.blocks[0]
+    self.assertEqual(block.label, "block 1")
+    self.assertEqual(len(block.actions), 1)
+    self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+
+  def test_parse_block_dict_action_list_2(self):
+    config = ActionBlockListConfig.parse({
+        "block 1": [{
+            "action": "get",
+            "url": "http://test.com"
+        }, {
+            "action": "wait",
+            "duration": "2s"
+        }]
+    })
+    self.assertEqual(len(config.blocks), 1)
+    block = config.blocks[0]
+    self.assertEqual(block.label, "block 1")
+    self.assertEqual(len(block.actions), 2)
+    self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+    self.assertEqual(block.actions[1].TYPE, ActionType.WAIT)
+
+  def test_parse_single_block_multi_action_dict(self):
+    config = ActionBlockListConfig.parse({
+        "block 1": {
+            "actions": [{
+                "action": "get",
+                "url": "http://test.com/0",
+                "duration": "1s",
+            }, {
+                "action": "get",
+                "url": "http://test.com/1",
+                "duration": "20s",
+            }]
+        }
+    })
+    self.assertEqual(len(config.blocks), 1)
+    block = config.blocks[0]
+    self.assertEqual(block.label, "block 1")
+    self.assertEqual(block.duration, dt.timedelta(seconds=21))
+    self.assertEqual(len(block.actions), 2)
+    for index, action in enumerate(block.actions):
+      self.assertEqual(action.TYPE, ActionType.GET)
+      self.assertEqual(action.url, f"http://test.com/{index}")
+
+  def test_parse_multi_block_actions_dict(self):
+    config = ActionBlockListConfig.parse({
+        "block 0": {
+            "actions": [{
+                "action": "get",
+                "url": "http://test.com/0"
+            }]
+        },
+        "block 1": {
+            "actions": [{
+                "action": "get",
+                "url": "http://test.com/1"
+            }]
+        }
+    })
+    self.assertEqual(len(config.blocks), 2)
+    for index, block in enumerate(config.blocks):
+      self.assertEqual(block.label, f"block {index}")
+      self.assertEqual(len(block.actions), 1)
+      self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+      self.assertEqual(block.actions[0].url, f"http://test.com/{index}")
+
+  def test_parse_multi_block_actions_list(self):
+    config = ActionBlockListConfig.parse({
+        "block 0": [{
+            "action": "get",
+            "url": "http://test.com/0"
+        }],
+        "block 1": [{
+            "action": "get",
+            "url": "http://test.com/1"
+        }]
+    })
+    self.assertEqual(len(config.blocks), 2)
+    for index, block in enumerate(config.blocks):
+      self.assertEqual(block.label, f"block {index}")
+      self.assertEqual(len(block.actions), 1)
+      self.assertEqual(block.actions[0].TYPE, ActionType.GET)
+      self.assertEqual(block.actions[0].url, f"http://test.com/{index}")
+
+  def test_parse_dict_label_conflict(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ActionBlockListConfig.parse({
+          "block 1": {
+              "label": "block 2",
+              "actions": [{
+                  "action": "get",
+                  "url": "http://test.com"
+              }]
+          }
+      })
+    self.assertIn("block 2", str(cm.exception))
+
+  def test_parse_invalid_dict_missing_actions(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ActionBlockListConfig.parse({"block 1": {}})
+    self.assertIn("actions", str(cm.exception))
+
+  def test_parse_invalid_dict_empty_actions(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ActionBlockListConfig.parse({"block 1": {"actions": []}})
+    self.assertIn("actions", str(cm.exception))
+
+  def test_parse_logins(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = ActionBlockListConfig.parse({
+          "login": [{
+              "action": "get",
+              "url": "http://test.com/login"
+          }],
+          "block 0": [{
+              "action": "get",
+              "url": "http://test.com/1"
+          }]
+      })
+    self.assertIn("login", str(cm.exception))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/test_playback_controller.py b/tests/crossbench/benchmarks/loading/test_playback_controller.py
new file mode 100644
index 0000000..ae6d65c
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/test_playback_controller.py
@@ -0,0 +1,110 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import unittest
+
+from crossbench.benchmarks.loading.playback_controller import (
+    ForeverPlaybackController, PlaybackController, RepeatPlaybackController,
+    TimeoutPlaybackController)
+from tests import test_helper
+
+
+class PlaybackControllerTestCase(unittest.TestCase):
+
+  def test_parse_invalid(self):
+    for invalid in [
+        "11", "something", "1.5x", "4.3.h", "4.5.x", "-1x", "-1.4x", "-2h",
+        "-2.1h", "1h30", "infx", "infh", "nanh", "nanx", "0s", "0"
+    ]:
+      with self.subTest(pattern=invalid):
+        with self.assertRaises((argparse.ArgumentTypeError, ValueError)):
+          PlaybackController.parse(invalid)
+
+  def test_invalid_repeat(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PlaybackController.repeat(-1)
+
+  def test_parse_repeat(self):
+    playback = PlaybackController.parse("once")
+    self.assertIsInstance(playback, RepeatPlaybackController)
+    assert isinstance(playback, RepeatPlaybackController)
+    self.assertEqual(playback.count, 1)
+    self.assertEqual(len(list(playback)), 1)
+
+    playback = PlaybackController.parse("1x")
+    self.assertIsInstance(playback, RepeatPlaybackController)
+    assert isinstance(playback, RepeatPlaybackController)
+    self.assertEqual(playback.count, 1)
+    self.assertEqual(len(list(playback)), 1)
+
+    playback = PlaybackController.parse("11x")
+    self.assertIsInstance(playback, RepeatPlaybackController)
+    assert isinstance(playback, RepeatPlaybackController)
+    self.assertEqual(playback.count, 11)
+    self.assertEqual(len(list(playback)), 11)
+
+  def test_parse_forever(self):
+    playback = PlaybackController.parse("forever")
+    self.assertIsInstance(playback, ForeverPlaybackController)
+    playback = PlaybackController.parse("inf")
+    self.assertIsInstance(playback, ForeverPlaybackController)
+    playback = PlaybackController.parse("infinity")
+    self.assertIsInstance(playback, ForeverPlaybackController)
+
+  def test_parse_duration(self):
+    playback = PlaybackController.parse("5s")
+    self.assertIsInstance(playback, TimeoutPlaybackController)
+    assert isinstance(playback, TimeoutPlaybackController)
+    self.assertEqual(playback.duration, dt.timedelta(seconds=5))
+
+    playback = PlaybackController.parse("5m")
+    self.assertIsInstance(playback, TimeoutPlaybackController)
+    assert isinstance(playback, TimeoutPlaybackController)
+    self.assertEqual(playback.duration, dt.timedelta(minutes=5))
+
+    playback = PlaybackController.parse("5.5m")
+    self.assertIsInstance(playback, TimeoutPlaybackController)
+    assert isinstance(playback, TimeoutPlaybackController)
+    self.assertEqual(playback.duration, dt.timedelta(minutes=5.5))
+
+    playback = PlaybackController.parse("5.5m")
+    self.assertIsInstance(playback, TimeoutPlaybackController)
+    assert isinstance(playback, TimeoutPlaybackController)
+    self.assertEqual(playback.duration, dt.timedelta(minutes=5.5))
+
+  def test_once(self):
+    iterations = sum(1 for _ in PlaybackController.once())
+    self.assertEqual(iterations, 1)
+    iterations = sum(1 for _ in PlaybackController.default())
+    self.assertEqual(iterations, 1)
+
+  def test_repeat(self):
+    iterations = sum(1 for _ in PlaybackController.repeat(1))
+    self.assertEqual(iterations, 1)
+    iterations = sum(1 for _ in PlaybackController.repeat(11))
+    self.assertEqual(iterations, 11)
+
+  def test_timeout(self):
+    # Even 0-duration playback should run once
+    iterations = sum(1 for _ in PlaybackController.timeout(dt.timedelta()))
+    self.assertEqual(iterations, 1)
+    iterations = sum(
+        1 for _ in PlaybackController.timeout(dt.timedelta(milliseconds=0.1)))
+    self.assertGreaterEqual(iterations, 1)
+
+  def test_forever(self):
+    count = 0
+    for _ in PlaybackController.forever():
+      # Just run for some large-ish amount of iterations to get code coverage.
+      count += 1
+      if count > 100:
+        break
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/test_tab_controller.py b/tests/crossbench/benchmarks/loading/test_tab_controller.py
new file mode 100644
index 0000000..68151ea
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/test_tab_controller.py
@@ -0,0 +1,63 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import unittest
+
+from crossbench.benchmarks.loading.tab_controller import (TabController,
+                                                          SingleTabController,
+                                                          RepeatTabController,
+                                                          ForeverTabController)
+from tests import test_helper
+
+
+class TabControllerTestCase(unittest.TestCase):
+
+  def test_parse_invalid(self):
+    for invalid in ["sing", "mult", "mlt", "x5"]:
+      with self.subTest(pattern=invalid):
+        with self.assertRaises((argparse.ArgumentTypeError, ValueError)):
+          TabController.parse(invalid)
+
+  def test_parse_repeat(self):
+    tab = TabController.parse("3")
+    self.assertIsInstance(tab, RepeatTabController)
+    assert isinstance(tab, RepeatTabController)
+    self.assertEqual(tab.count, 3)
+    self.assertEqual(len(list(tab)), 3)
+    self.assertTrue(tab.multiple_tabs)
+    self.assertFalse(tab.is_forever)
+
+  def test_parse_single(self):
+    tab = TabController.parse("single")
+    self.assertIsInstance(tab, SingleTabController)
+    self.assertFalse(tab.multiple_tabs)
+    self.assertFalse(tab.is_forever)
+    self.assertEqual(len(list(tab)), 1)
+
+  def test_parse_inf(self):
+    tab = TabController.parse("inf")
+    self.assertIsInstance(tab, ForeverTabController)
+    tab = TabController.parse("infinity")
+    self.assertIsInstance(tab, ForeverTabController)
+
+  def test_repeat(self):
+    iterations = sum(1 for _ in TabController.repeat(1))
+    self.assertEqual(iterations, 1)
+    iterations = sum(1 for _ in TabController.repeat(10))
+    self.assertEqual(iterations, 10)
+
+  def test_forever(self):
+    count = 0
+    for _ in TabController.forever():
+      count += 1
+      if count > 100:
+        break
+    self.assertEqual(count, 101)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/speedometer_helper.py b/tests/crossbench/benchmarks/speedometer_helper.py
new file mode 100644
index 0000000..efa0120
--- /dev/null
+++ b/tests/crossbench/benchmarks/speedometer_helper.py
@@ -0,0 +1,370 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import abc
+import argparse
+import copy
+import csv
+import json
+from dataclasses import dataclass
+from typing import Dict, List, Optional, Sequence, Type
+from unittest import mock
+
+from crossbench.benchmarks.speedometer.speedometer import (SpeedometerBenchmark,
+                                                           SpeedometerProbe,
+                                                           SpeedometerStory)
+from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.runner.runner import Runner
+from tests.crossbench.benchmarks import helper
+
+
+class SpeedometerBaseTestCase(
+    helper.PressBaseBenchmarkTestCase, metaclass=abc.ABCMeta):
+
+  @property
+  @abc.abstractmethod
+  def benchmark_cls(self) -> Type[SpeedometerBenchmark]:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def story_cls(self) -> Type[SpeedometerStory]:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def probe_cls(self) -> Type[SpeedometerProbe]:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def name(self) -> str:
+    pass
+
+  @property
+  def name_all(self) -> str:
+    # Override if default() != all() stories.
+    return self.name
+
+  @dataclass
+  class Namespace(argparse.Namespace):
+    stories = "all"
+    iterations: int = 10
+    separate: bool = False
+    custom_benchmark_url: Optional[str] = None
+
+  def test_iterations_kwargs(self):
+    args = self.Namespace()
+    self.benchmark_cls.from_cli_args(args)
+    with self.assertRaises(TypeError):
+      args.iterations = "-10"  # pytype: disable=annotation-type-mismatch
+      self.benchmark_cls.from_cli_args(args)
+    with self.assertRaises(TypeError):
+      args.iterations = "1234"  # pytype: disable=annotation-type-mismatch
+      benchmark = self.benchmark_cls.from_cli_args(args)
+    args.iterations = 1234
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.iterations, 1234)
+
+  def test_story_filtering_cli_args_all_separate(self):
+    stories = self.story_cls.all(separate=True)
+    args = self.Namespace()
+    args.stories = "all"
+    args.separate = True
+    stories_all = self.benchmark_cls.stories_from_cli_args(args)
+    self.assertListEqual(
+        [story.name for story in stories],
+        [story.name for story in stories_all],
+    )
+
+  def test_story_filtering_cli_args_all(self):
+    stories = self.story_cls.all(separate=False)
+    args = self.Namespace()
+    args.stories = "all"
+    args.custom_benchmark_url = self.story_cls.URL_LOCAL
+    args.separate = False
+    args.iterations = 503
+    stories_all = self.benchmark_cls.stories_from_cli_args(args)
+    self.assertEqual(len(stories), 1)
+    self.assertEqual(len(stories_all), 1)
+    story = stories[0]
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.name, self.name_all)
+    story = stories_all[0]
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.name, self.name_all)
+    self.assertEqual(story.url, self.story_cls.URL_LOCAL)
+    self.assertEqual(story.iterations, 503)
+
+    args.custom_benchmark_url = None
+    args.separate = False
+    args.iterations = 701
+    stories_all = self.benchmark_cls.stories_from_cli_args(args)
+    self.assertEqual(len(stories_all), 1)
+    story = stories_all[0]
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.name, self.name_all)
+    self.assertEqual(story.url, self.story_cls.URL)
+    self.assertEqual(story.iterations, 701)
+
+  def test_story_filtering(self):
+    with self.assertRaises(ValueError):
+      self.story_cls.from_names([])
+    stories = self.story_cls.default(separate=False)
+    self.assertEqual(len(stories), 1)
+
+    with self.assertRaises(ValueError):
+      self.story_cls.from_names([], separate=True)
+    stories = self.story_cls.default(separate=True)
+    self.assertEqual(len(stories), len(self.story_cls.default_story_names()))
+
+  def test_story_filtering_regexp_invalid(self):
+    with self.assertRaises(ValueError):
+      _ = self.story_filter(".*", separate=True).stories
+
+  def test_story_filtering_regexp(self):
+    stories = self.story_cls.all(separate=True)
+    stories_b = self.story_filter([".*"], separate=True).stories
+    self.assertListEqual(
+        [story.name for story in stories],
+        [story.name for story in stories_b],
+    )
+
+  def _test_run(self,
+                story_names: Optional[Sequence[str]] = None,
+                separate: bool = False,
+                iterations: int = 2,
+                repetitions: int = 3,
+                warmup_repetitions: int = 0,
+                custom_url: Optional[str] = None,
+                throw: bool = True) -> Runner:
+    if story_names is None:
+      default_story_name = self.story_cls.SUBSTORIES[0]
+      self.assertTrue(default_story_name)
+      story_names = [default_story_name]
+    stories = self.story_cls.from_names(
+        story_names, separate=separate, url=custom_url, iterations=iterations)
+
+    # The order should match Runner.get_runs
+    for _ in range(warmup_repetitions + repetitions):
+      for story in stories:
+        speedometer_probe_results = self._generate_test_probe_results(
+            iterations, story)
+
+        for browser in self.browsers:
+          # Page is ready
+          browser.expect_js(result=True)
+          # _setup_substories
+          browser.expect_js()
+          # _setup_benchmark_client
+          browser.expect_js()
+          # _run_stories
+          browser.expect_js()
+          # Wait until done
+          browser.expect_js(result=True)
+          browser.expect_js(result=speedometer_probe_results)
+    for browser in self.browsers:
+      browser.expected_js = copy.deepcopy(browser.expected_js)
+
+    benchmark = self.benchmark_cls(stories, custom_url=custom_url)  # pytype: disable=not-instantiable
+    self.assertTrue(len(benchmark.describe()) > 0)
+    runner = Runner(
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        env_config=HostEnvironmentConfig(),
+        env_validation_mode=ValidationMode.SKIP,
+        platform=self.platform,
+        repetitions=repetitions,
+        warmup_repetitions=warmup_repetitions,
+        throw=throw)
+    with mock.patch.object(self.benchmark_cls, "validate_url") as cm:
+      runner.run()
+    cm.assert_called_once()
+    return runner
+
+  @abc.abstractmethod
+  def _generate_test_probe_results(self, iterations, story):
+    pass
+
+  def _verify_results(
+      self,
+      runner: Runner,
+      expected_num_urls: Optional[int] = None) -> List[Dict[str, str]]:
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      if expected_num_urls is not None:
+        self.assertEqual(len(urls), expected_num_urls)
+      self.assertTrue(browser.was_js_invoked(self.probe_cls.JS))
+      self.assertListEqual(browser.expected_js, [])
+
+    with self.assertLogs(level="INFO") as cm:
+      for probe in runner.probes:
+        for run in runner.runs:
+          probe.log_run_result(run)
+    output = "\n".join(cm.output)
+    self.assertIn("Speedometer results", output)
+
+    with self.assertLogs(level="INFO") as cm:
+      for probe in runner.probes:
+        probe.log_browsers_result(runner.browser_group)
+    output = "\n".join(cm.output)
+    self.assertIn("Speedometer results", output)
+    self.assertIn("102.22.33.44", output)
+    self.assertIn("100.22.33.44", output)
+
+    csv_files = list(runner.out_dir.glob("speedometer*.csv"))
+    self.assertEqual(len(csv_files), 1)
+    csv_file = self.out_dir / f"{self.probe_cls.NAME}.csv"
+    rows: List[Dict[str, str]] = [{}]
+    with csv_file.open(encoding="utf-8") as f:
+      reader = csv.DictReader(f, delimiter="\t")
+      rows = list(reader)
+    self.assertListEqual(list(rows[0].keys()), ["label", "", "dev", "stable"])
+    self.assertDictEqual(
+        rows[1],
+        {
+            "label": "version",
+            "dev": "102.22.33.44",
+            "stable": "100.22.33.44",
+            # Padding element after "label":
+            "": ""
+        })
+    return rows
+
+  def test_run_throw(self):
+    runner = self._test_run(throw=True)
+    self._verify_results(runner)
+
+  def test_run_default(self):
+    runner = self._test_run(iterations=10)
+    self._verify_results(runner)
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(self.story_cls.URL, urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+  def test_run_warmups(self):
+    runner = self._test_run(iterations=10, warmup_repetitions=1)
+    self._verify_results(runner)
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(self.story_cls.URL, urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+  def test_run_custom_url(self):
+    custom_url = "http://test.example.com/speedometer"
+    runner = self._test_run(custom_url=custom_url, iterations=10)
+    self._verify_results(runner)
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(custom_url, urls)
+      self.assertNotIn(self.story_cls.URL, urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+  def test_run_custom_iterations(self):
+    runner = self._test_run(iterations=7)
+    self._verify_results(runner)
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(f"{self.story_cls.URL}?iterationCount=7", urls)
+      self.assertNotIn(self.story_cls.URL, urls)
+      self.assertNotIn(f"{self.story_cls.URL_LOCAL}?iterationCount=7", urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+  def _verify_results_stories(self, rows, story_names, label_suffix):
+    labels = [row["label"] for row in rows]
+    story_name_str = "_".join(story_names)
+    self.assertNotIn(f"{self.benchmark_cls.NAME}_{story_name_str}", labels)
+    for story_name in story_names:
+      self.assertIn(f"{story_name}{label_suffix}", labels)
+
+  def _run_combined(self, story_names: Sequence[str], label_suffix: str = ""):
+    runner = self._test_run(story_names=story_names, separate=False)
+    rows = self._verify_results(runner, expected_num_urls=3)
+    self._verify_results_stories(rows, story_names, label_suffix)
+
+  def _run_separate(self, story_names: Sequence[str], label_suffix: str = ""):
+    runner = self._test_run(story_names=story_names, separate=True)
+    rows = self._verify_results(runner, expected_num_urls=6)
+    self._verify_results_stories(rows, story_names, label_suffix)
+
+  def test_run_combined(self):
+    self._run_combined(["VanillaJS-TodoMVC", "Elm-TodoMVC"])
+
+  def test_run_separate(self):
+    self._run_separate(["VanillaJS-TodoMVC", "Elm-TodoMVC"])
+
+
+class Speedometer2BaseTestCase(SpeedometerBaseTestCase, metaclass=abc.ABCMeta):
+  EXAMPLE_STORY_DATA = {
+      "tests": {
+          "Adding100Items": {
+              "tests": {
+                  "Sync": 74.6000000089407,
+                  "Async": 6.299999997019768
+              },
+              "total": 80.90000000596046
+          },
+          "CompletingAllItems": {
+              "tests": {
+                  "Sync": 22.600000008940697,
+                  "Async": 5.899999991059303
+              },
+              "total": 28.5
+          },
+          "DeletingItems": {
+              "tests": {
+                  "Sync": 11.800000011920929,
+                  "Async": 0.19999998807907104
+              },
+              "total": 12
+          }
+      },
+      "total": 121.40000000596046
+  }
+
+  def _generate_test_probe_results(self, iterations, story):
+    return [{
+        "tests": {
+            substory_name: copy.deepcopy(self.EXAMPLE_STORY_DATA)
+            for substory_name in story.substories
+        },
+        "total": 1000,
+        "mean": 2000,
+        "geomean": 3000,
+        "score": 10
+    }
+            for _ in range(iterations)]
+
+  def test_s2_probe_results(self):
+    story_names = ("VanillaJS-TodoMVC", "React-TodoMVC")
+    self.browsers = [self.browsers[0]]
+    runner = self._test_run(
+        story_names=story_names, separate=False, repetitions=2)
+    run_1, run_2 = runner.runs
+    probe_file = f"{self.probe_cls.NAME}.json"
+    with (run_1.out_dir / probe_file).open() as f:
+      data_1 = json.load(f)
+    with (run_2.out_dir / probe_file).open() as f:
+      data_2 = json.load(f)
+    keys_1 = tuple(data_1.keys())
+    keys_2 = tuple(data_2.keys())
+    self.assertTupleEqual(keys_1, keys_2)
+    # Make sure the aggregate metrics are at the end
+    self.assertTupleEqual(keys_1[-2:], ("Geomean", "Score"))
+
+    with (runner.story_groups[0].path / probe_file).open() as f:
+      stories_data = json.load(f)
+    self.assertTupleEqual(tuple(stories_data.keys())[-2:], ("Geomean", "Score"))
+
+  def test_run_combined(self):
+    self._run_combined(["VanillaJS-TodoMVC", "Elm-TodoMVC"],
+                       label_suffix="/total")
+
+  def test_run_separate(self):
+    self._run_separate(["VanillaJS-TodoMVC", "Elm-TodoMVC"],
+                       label_suffix="/total")
diff --git a/tests/crossbench/benchmarks/test_all.py b/tests/crossbench/benchmarks/test_all.py
new file mode 100644
index 0000000..67595d0
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_all.py
@@ -0,0 +1,86 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import unittest
+
+from ordered_set import OrderedSet
+
+from crossbench.benchmarks.jetstream.jetstream_2_0 import JetStream20Benchmark
+from crossbench.benchmarks.jetstream.jetstream_2_1 import JetStream21Benchmark
+from crossbench.benchmarks.jetstream.jetstream_2_2 import JetStream22Benchmark
+from crossbench.benchmarks.jetstream.jetstream_3_0 import JetStream30Benchmark
+from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+from crossbench.benchmarks.loading.loadline_presets import (
+    LoadLinePhoneBenchmark, LoadLineTabletBenchmark)
+from crossbench.benchmarks.manual.manual_benchmark import ManualBenchmark
+from crossbench.benchmarks.memory.memory_benchmark import MemoryBenchmark
+from crossbench.benchmarks.motionmark.motionmark_1_0 import \
+    MotionMark10Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_1 import \
+    MotionMark11Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_2 import \
+    MotionMark12Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_3 import \
+    MotionMark13Benchmark
+from crossbench.benchmarks.speedometer.speedometer_2_0 import \
+    Speedometer20Benchmark
+from crossbench.benchmarks.speedometer.speedometer_2_1 import \
+    Speedometer21Benchmark
+from crossbench.benchmarks.speedometer.speedometer_3_0 import \
+    Speedometer30Benchmark
+from tests import test_helper
+
+ALL = (
+    JetStream20Benchmark,
+    JetStream21Benchmark,
+    JetStream22Benchmark,
+    JetStream30Benchmark,
+    LoadLinePhoneBenchmark,
+    LoadLineTabletBenchmark,
+    ManualBenchmark,
+    MotionMark10Benchmark,
+    MotionMark11Benchmark,
+    MotionMark12Benchmark,
+    MotionMark13Benchmark,
+    PageLoadBenchmark,
+    Speedometer20Benchmark,
+    Speedometer21Benchmark,
+    Speedometer30Benchmark,
+    MemoryBenchmark,
+)
+
+
+class AllBenchmarksTestCase(unittest.TestCase):
+
+  def test_unique_classes(self):
+    self.assertTupleEqual(ALL, tuple(OrderedSet(ALL)))
+
+  def test_aliases(self):
+    seen_names = OrderedSet()
+    seen_aliases = OrderedSet()
+    for benchmark_cls in ALL:
+      with self.subTest(benchmark_cls=benchmark_cls):
+        self.assertNotIn(benchmark_cls.NAME, seen_names)
+        seen_names.add(benchmark_cls.NAME)
+        for alias in benchmark_cls.aliases():
+          self.assertNotIn(alias, seen_aliases)
+          seen_aliases.add(alias)
+
+  def test_story_classes(self):
+    seen_story_classes = OrderedSet()
+    for benchmark_cls in ALL:
+      if benchmark_cls is MemoryBenchmark:
+        continue
+      if issubclass(benchmark_cls,
+                    PageLoadBenchmark) and (benchmark_cls
+                                            is not PageLoadBenchmark):
+        continue
+      self.assertNotIn(benchmark_cls.DEFAULT_STORY_CLS, seen_story_classes)
+      seen_story_classes.add(benchmark_cls.DEFAULT_STORY_CLS)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/test_benchmark.py b/tests/crossbench/benchmarks/test_benchmark.py
new file mode 100644
index 0000000..5d2427c
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_benchmark.py
@@ -0,0 +1,77 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import datetime as dt
+import unittest
+
+from crossbench.benchmarks.base import PressBenchmarkStoryFilter
+from crossbench.runner.run import Run
+from crossbench.stories.press_benchmark import PressBenchmarkStory
+from tests import test_helper
+
+
+class MockStory(PressBenchmarkStory):
+  NAME = "MockStory"
+  URL = "http://test.com"
+  SUBSTORIES = (
+      "Story-1",
+      "Story-2",
+      "Story-3",
+      "Story-4",
+  )
+
+  @property
+  def substory_duration(self) -> dt.timedelta:
+    return dt.timedelta(seconds=0.1)
+
+  def run(self, run: Run) -> None:
+    pass
+
+
+class PressBenchmarkStoryFilterTestCase(unittest.TestCase):
+
+  def test_empty(self):
+    with self.assertRaises(ValueError):
+      _ = PressBenchmarkStoryFilter(MockStory, [])
+
+  def test_all(self):
+    stories = PressBenchmarkStoryFilter(MockStory, ["all"]).stories
+    self.assertEqual(len(stories), 1)
+    story: MockStory = stories[0]
+    self.assertSequenceEqual(story.substories, MockStory.SUBSTORIES)
+
+  def test_all_separate(self):
+    stories = PressBenchmarkStoryFilter(
+        MockStory, ["all"], separate=True).stories
+    self.assertSequenceEqual([story.substories[0] for story in stories],
+                             MockStory.SUBSTORIES)
+    for story in stories:
+      self.assertTrue(len(story.substories), 1)
+
+  def test_match_regexp_none(self):
+    with self.assertRaises(ValueError) as cm:
+      _ = PressBenchmarkStoryFilter(MockStory, ["Story"]).stories
+    self.assertIn("Story", str(cm.exception))
+
+  def test_match_regexp_some(self):
+    stories = PressBenchmarkStoryFilter(MockStory, [".*-3"]).stories
+    self.assertEqual(len(stories), 1)
+    story: MockStory = stories[0]
+    self.assertSequenceEqual(story.substories, ["Story-3"])
+
+  def test_match_regexp_all(self):
+    stories = PressBenchmarkStoryFilter(MockStory, ["Story.*"]).stories
+    self.assertEqual(len(stories), 1)
+    story: MockStory = stories[0]
+    self.assertSequenceEqual(story.substories, MockStory.SUBSTORIES)
+
+  def test_match_regexp_all_wrong_case(self):
+    stories = PressBenchmarkStoryFilter(MockStory, ["StOrY.*"]).stories
+    self.assertEqual(len(stories), 1)
+    story: MockStory = stories[0]
+    self.assertSequenceEqual(story.substories, MockStory.SUBSTORIES)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/test_jetstream.py b/tests/crossbench/benchmarks/test_jetstream.py
new file mode 100644
index 0000000..8841ba1
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_jetstream.py
@@ -0,0 +1,141 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import unittest
+
+from crossbench.benchmarks.jetstream.jetstream import JetStreamCSVFormatter
+from crossbench.benchmarks.jetstream.jetstream_2_0 import (JetStream20Benchmark,
+                                                           JetStream20Probe,
+                                                           JetStream20Story)
+from crossbench.benchmarks.jetstream.jetstream_2_1 import (JetStream21Benchmark,
+                                                           JetStream21Probe,
+                                                           JetStream21Story)
+from crossbench.benchmarks.jetstream.jetstream_2_2 import (JetStream22Benchmark,
+                                                           JetStream22Probe,
+                                                           JetStream22Story)
+from crossbench.benchmarks.jetstream.jetstream_3_0 import (JetStream30Benchmark,
+                                                           JetStream30Probe,
+                                                           JetStream30Story)
+from crossbench.probes.metric import MetricsMerger
+from tests import test_helper
+# Only import module to avoid exposing the abstract test classes to the runner.
+from tests.crossbench.benchmarks import jetstream_helper
+
+
+class JetStreamCSVFormatterTestCase(unittest.TestCase):
+
+  def test_format_sorted(self):
+    metrics = MetricsMerger({
+        "Total/average": 10,
+        "Total/score": 20,
+        "cdjs/average": 30,
+        "cdjs/score": 40,
+    })
+    table = JetStreamCSVFormatter(metrics, lambda metric: metric.geomean).table
+    self.assertSequenceEqual(table, [
+        ("Total/score", "Total", "score", 20.0),
+        ("cdjs/score", "cdjs", "score", 40.0),
+        ("Total/average", "Total", "average", 10.0),
+        ("Total/score", "Total", "score", 20.0),
+        ("cdjs/average", "cdjs", "average", 30.0),
+        ("cdjs/score", "cdjs", "score", 40.0),
+    ])
+
+  def test_format_unsorted(self):
+    metrics = MetricsMerger({
+        "cdjs/average": 30,
+        "cdjs/score": 40,
+        "Total/average": 10,
+        "Total/score": 20,
+    })
+    table = JetStreamCSVFormatter(
+        metrics, lambda metric: metric.geomean, sort=False).table
+    self.assertSequenceEqual(table, [
+        ("Total/score", "Total", "score", 20.0),
+        ("cdjs/score", "cdjs", "score", 40.0),
+        ("cdjs/average", "cdjs", "average", 30.0),
+        ("cdjs/score", "cdjs", "score", 40.0),
+        ("Total/average", "Total", "average", 10.0),
+        ("Total/score", "Total", "score", 20.0),
+    ])
+
+
+class JetStream20TestCase(jetstream_helper.JetStream2BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return JetStream20Benchmark
+
+  @property
+  def story_cls(self):
+    return JetStream20Story
+
+  @property
+  def probe_cls(self):
+    return JetStream20Probe
+
+  @property
+  def name(self):
+    return "jetstream_2.0"
+
+
+class JetStream21TestCase(jetstream_helper.JetStream2BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return JetStream21Benchmark
+
+  @property
+  def story_cls(self):
+    return JetStream21Story
+
+  @property
+  def probe_cls(self):
+    return JetStream21Probe
+
+  @property
+  def name(self):
+    return "jetstream_2.1"
+
+
+class JetStream22TestCase(jetstream_helper.JetStream2BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return JetStream22Benchmark
+
+  @property
+  def story_cls(self):
+    return JetStream22Story
+
+  @property
+  def probe_cls(self):
+    return JetStream22Probe
+
+  @property
+  def name(self):
+    return "jetstream_2.2"
+
+
+class JetStream30TestCase(jetstream_helper.JetStream3BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return JetStream30Benchmark
+
+  @property
+  def story_cls(self):
+    return JetStream30Story
+
+  @property
+  def probe_cls(self):
+    return JetStream30Probe
+
+  @property
+  def name(self):
+    return "jetstream_3.0"
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/test_manual.py b/tests/crossbench/benchmarks/test_manual.py
new file mode 100644
index 0000000..97ffbf1
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_manual.py
@@ -0,0 +1,78 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import Optional
+from unittest import mock
+
+from crossbench.benchmarks.manual.manual_benchmark import ManualBenchmark
+from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.runner.runner import Runner
+from tests import test_helper
+from tests.crossbench.benchmarks.helper import BaseBenchmarkTestCase
+
+
+class TestManualBenchmark(BaseBenchmarkTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return ManualBenchmark
+
+  def test_run_default(self):
+    with mock.patch("builtins.input", lambda *args: "y"):
+      self._test_run()
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      # No automatic URLS.
+      self.assertFalse(urls)
+
+  def test_run_auto_start(self):
+    with mock.patch("builtins.input", lambda *args: "y"):
+      self._test_run(start_after=dt.timedelta(seconds=0.2))
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      # No automatic URLS.
+      self.assertFalse(urls)
+
+  def test_run_custom_duration(self):
+    with mock.patch("builtins.input", lambda *args: "y"):
+      self._test_run(run_for=dt.timedelta(seconds=0.2))
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      # No automatic URLS.
+      self.assertFalse(urls)
+
+  def _test_run(self,
+                start_after: Optional[dt.timedelta] = None,
+                run_for: Optional[dt.timedelta] = None):
+    repetitions = 3
+    benchmark = ManualBenchmark(start_after, run_for)  # pytype: disable=not-instantiable
+    self.assertTrue(len(benchmark.describe()) > 0)
+    runner = Runner(
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        env_config=HostEnvironmentConfig(),
+        env_validation_mode=ValidationMode.SKIP,
+        platform=self.platform,
+        repetitions=repetitions,
+        throw=True)
+
+    with self.assertLogs(level="INFO") as cm:
+      runner.run()
+    output = "\n".join(cm.output)
+    self.assertIn("Starting Manual Benchmark", output)
+
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      # No automatic URLS.
+      self.assertFalse(urls)
+
+
+del BaseBenchmarkTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/test_memory.py b/tests/crossbench/benchmarks/test_memory.py
new file mode 100644
index 0000000..20e25ff
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_memory.py
@@ -0,0 +1,130 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import copy
+import csv
+
+from crossbench.benchmarks.loading.page.live import LivePage
+from crossbench.benchmarks.loading.tab_controller import TabController
+from crossbench.benchmarks.memory.memory_benchmark import (
+    MemoryBenchmark, MemoryBenchmarkStoryFilter, MemoryProbe)
+from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.runner.runner import Runner
+from tests import test_helper
+from tests.crossbench.benchmarks import helper
+
+
+class MemoryBenchmarkTestCase(helper.BaseBenchmarkTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return MemoryBenchmark
+
+  @property
+  def story_cls(self):
+    return MemoryBenchmarkStoryFilter
+
+  @property
+  def probe_cls(self):
+    return MemoryProbe
+
+  def _create_stories(self, tab_count):
+    args = argparse.Namespace(
+        alloc_count=8,
+        prefill_constant=8,
+        compressibility=50,
+        random_per_page=False,
+        block_size=128,
+        tabs=TabController.repeat(tab_count))
+    stories = self.story_cls.stories_from_cli_args(args=args)
+    return stories
+
+  def test_story(self):
+    stories = self._create_stories(tab_count=2)
+    self.assertEqual(len(stories), 1)
+    story = stories[0]
+    self.assertIsInstance(story, LivePage)
+    expected_url = ("https://chromium-workloads.web.app/web-tests/main/"
+                    "synthetic/memory?alloc=8&blocksize=128&compress=50"
+                    "&prefill=8&randomperpage=false")
+    self.assertEqual(story.first_url, expected_url)
+    names = set(story.name for story in stories)
+    self.assertEqual(len(names), len(stories))
+
+  def test_run_throw(self):
+    self._test_run(throw=True)
+
+  def test_run_default(self):
+    self._test_run()
+
+  def _test_run(self, throw: bool = False):
+    tab_count = 2
+    repetitions = 2
+    stories = self._create_stories(tab_count=tab_count)
+    for _ in range(repetitions):
+      for _ in stories:
+        for browser in self.browsers:
+          # Record navigation time
+          browser.expect_js(result="1000")
+          browser.expect_js(result="1001")
+    for browser in self.browsers:
+      browser.expected_js = copy.deepcopy(browser.expected_js)
+
+    benchmark = self.benchmark_cls(stories, skippable_tab_count=2)
+    self.assertTrue(len(benchmark.describe()) > 0)
+    runner = Runner(
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        env_config=HostEnvironmentConfig(),
+        env_validation_mode=ValidationMode.SKIP,
+        platform=self.platform,
+        repetitions=repetitions,
+        throw=throw)
+
+    runner.run()
+    assert runner.is_success
+    story_urls = [story.first_url for story in stories]
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertEqual(len(urls), repetitions * tab_count)
+      self.assertEqual(story_urls * repetitions * tab_count, urls)
+      self.assertEqual(len(browser.tab_list) - 1, repetitions * tab_count)
+      self.assertEqual(browser.tab_list, [0, 1, 2, 3, 4])
+
+    with (self.out_dir /
+          f"{self.probe_cls.NAME}.csv").open(encoding="utf-8") as f:
+      csv_data = list(csv.DictReader(f, delimiter="\t"))
+    self.assertListEqual(
+        list(csv_data[0].keys()), ["label", "", "dev", "stable"])
+    self.assertDictEqual(
+        csv_data[1],
+        {
+            "label": "version",
+            "dev": "102.22.33.44",
+            "stable": "100.22.33.44",
+            # One padding element (after "label"):
+            "": "",
+        })
+
+    with self.assertLogs(level="INFO") as cm:
+      for probe in runner.probes:
+        for run in runner.runs:
+          probe.log_run_result(run)
+    output = "\n".join(cm.output)
+    self.assertIn("Memory results", output)
+    self.assertIn(f"Score {tab_count}", output)
+
+    with self.assertLogs(level="INFO") as cm:
+      for probe in runner.probes:
+        probe.log_browsers_result(runner.browser_group)
+    output = "\n".join(cm.output)
+    self.assertIn("Memory results", output)
+    self.assertIn("102.22.33.44", output)
+    self.assertIn("100.22.33.44", output)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/test_motionmark.py b/tests/crossbench/benchmarks/test_motionmark.py
new file mode 100644
index 0000000..5ce3f8b
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_motionmark.py
@@ -0,0 +1,207 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import abc
+import copy
+import csv
+from typing import Optional, Type
+from unittest import mock
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
+                                                           MotionMark1Probe,
+                                                           MotionMark1Story)
+from crossbench.benchmarks.motionmark.motionmark_1_2 import (
+    MotionMark12Benchmark, MotionMark12Probe, MotionMark12Story)
+from crossbench.benchmarks.motionmark.motionmark_1_3 import (
+    MotionMark13Benchmark, MotionMark13Probe, MotionMark13Story)
+from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
+                            ValidationMode)
+from crossbench.runner.runner import Runner
+from tests import test_helper
+from tests.crossbench.benchmarks import helper
+
+
+class MotionMark1BaseTestCase(
+    helper.PressBaseBenchmarkTestCase, metaclass=abc.ABCMeta):
+
+  @property
+  @abc.abstractmethod
+  def benchmark_cls(self) -> Type[MotionMark1Benchmark]:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def story_cls(self) -> Type[MotionMark1Story]:
+    pass
+
+  @property
+  @abc.abstractmethod
+  def probe_cls(self) -> Type[MotionMark1Probe]:
+    pass
+
+
+  EXAMPLE_PROBE_DATA = [{
+      "testsResults": {
+          "MotionMark": {
+              "Multiply": {
+                  "complexity": {
+                      "complexity":
+                          1169.7666313745012,
+                      "stdev":
+                          2.6693101402239985,
+                      "bootstrap": {
+                          "confidenceLow": 1154.0859381321234,
+                          "confidenceHigh": 1210.464520355893,
+                          "median": 1180.8987652049277,
+                          "mean": 1163.0061487765158,
+                          "confidencePercentage": 0.8
+                      },
+                      "segment1": [[1, 16.666666666666668],
+                                   [1, 16.666666666666668]],
+                      "segment2": [[1, 6.728874992470971],
+                                   [3105, 13.858528114770454]]
+                  },
+                  "controller": {
+                      "score": 1168.106104032434,
+                      "average": 1168.106104032434,
+                      "stdev": 37.027504395081785,
+                      "percent": 3.1698750881669624
+                  },
+                  "score": 1180.8987652049277,
+                  "scoreLowerBound": 1154.0859381321234,
+                  "scoreUpperBound": 1210.464520355893
+              }
+          }
+      },
+      "score": 1180.8987652049277,
+      "scoreLowerBound": 1154.0859381321234,
+      "scoreUpperBound": 1210.464520355893
+  }]
+
+  def test_all_stories(self):
+    stories = self.story_filter(["all"], separate=True).stories
+    self.assertGreater(len(stories), 1)
+    for story in stories:
+      self.assertIsInstance(story, self.story_cls)
+    names = set(story.name for story in stories)
+    self.assertEqual(len(names), len(stories))
+    self.assertEqual(len(names), len(self.story_cls.SUBSTORIES))
+
+  def test_default_stories(self):
+    stories = self.story_filter(["default"], separate=True).stories
+    self.assertGreater(len(stories), 1)
+    for story in stories:
+      self.assertIsInstance(story, self.story_cls)
+    names = set(story.name for story in stories)
+    self.assertEqual(len(names), len(stories))
+    self.assertEqual(len(names), len(self.story_cls.ALL_STORIES["MotionMark"]))
+
+  def test_run_throw(self):
+    self._test_run(throw=True)
+
+  def test_run_default(self):
+    self._test_run()
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(f"{self.story_cls.URL}/developer.html", urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+      self.assertNotIn(f"{self.story_cls.URL_LOCAL}/developer.html", urls)
+
+  def test_run_custom_url(self):
+    custom_url = "http://test.example.com/motionmark"
+    self._test_run(custom_url)
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(f"{custom_url}/developer.html", urls)
+      self.assertNotIn(self.story_cls.URL, urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+  def _test_run(self, custom_url: Optional[str] = None, throw: bool = False):
+    stories = self.story_cls.from_names(["Multiply"], url=custom_url)
+    repetitions = 3
+    # The order should match Runner.get_runs
+    for _ in range(repetitions):
+      for _ in stories:
+        for browser in self.browsers:
+          # Page is ready
+          browser.expect_js(result=True)
+          # NOF enabled benchmarks
+          browser.expect_js(result=1)
+          # Start running benchmark
+          browser.expect_js()
+          # Wait until done
+          browser.expect_js(result=True)
+          browser.expect_js(result=self.EXAMPLE_PROBE_DATA)
+    for browser in self.browsers:
+      browser.expected_js = copy.deepcopy(browser.expected_js)
+    benchmark = self.benchmark_cls(stories, custom_url=custom_url)
+    self.assertTrue(len(benchmark.describe()) > 0)
+    runner = Runner(
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        env_config=HostEnvironmentConfig(),
+        env_validation_mode=ValidationMode.SKIP,
+        platform=self.platform,
+        repetitions=repetitions,
+        throw=throw)
+    with mock.patch.object(
+        HostEnvironment, "validate_url", return_value=True) as cm:
+      runner.run()
+    cm.assert_called_once()
+    assert runner.is_success
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertEqual(len(urls), repetitions)
+      self.assertTrue(browser.was_js_invoked(self.probe_cls.JS))
+    with (self.out_dir /
+          f"{self.probe_cls.NAME}.csv").open(encoding="utf-8") as f:
+      csv_data = list(csv.DictReader(f, delimiter="\t"))
+    self.assertListEqual(
+        list(csv_data[0].keys()), ["label", "", "dev", "stable"])
+    self.assertDictEqual(
+        csv_data[1],
+        {
+            "label": "version",
+            "dev": "102.22.33.44",
+            "stable": "100.22.33.44",
+            # One padding element (after "label"):
+            "": "",
+        })
+
+
+class MotionMark12TestCase(MotionMark1BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return MotionMark12Benchmark
+
+  @property
+  def story_cls(self):
+    return MotionMark12Story
+
+  @property
+  def probe_cls(self):
+    return MotionMark12Probe
+
+
+class MotionMark13TestCase(MotionMark1BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return MotionMark13Benchmark
+
+  @property
+  def story_cls(self):
+    return MotionMark13Story
+
+  @property
+  def probe_cls(self):
+    return MotionMark13Probe
+
+
+del MotionMark1BaseTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/test_speedometer.py b/tests/crossbench/benchmarks/test_speedometer.py
new file mode 100644
index 0000000..5c41f86
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_speedometer.py
@@ -0,0 +1,255 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import datetime as dt
+import json
+from dataclasses import dataclass
+
+from crossbench.benchmarks.speedometer.speedometer_2_0 import (
+    Speedometer20Benchmark, Speedometer20Probe, Speedometer20Story)
+from crossbench.benchmarks.speedometer.speedometer_2_1 import (
+    Speedometer21Benchmark, Speedometer21Probe, Speedometer21Story)
+from crossbench.benchmarks.speedometer.speedometer_3_0 import (
+    MeasurementMethod, Speedometer30Benchmark, Speedometer30Probe,
+    Speedometer30Story)
+from crossbench.browsers.viewport import Viewport
+from tests import test_helper
+from tests.crossbench.benchmarks.speedometer_helper import (
+    Speedometer2BaseTestCase, SpeedometerBaseTestCase)
+
+
+class Speedometer20TestCase(Speedometer2BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return Speedometer20Benchmark
+
+  @property
+  def story_cls(self):
+    return Speedometer20Story
+
+  @property
+  def probe_cls(self):
+    return Speedometer20Probe
+
+  @property
+  def name(self):
+    return "speedometer_2.0"
+
+  def test_default_all(self):
+    default_story_names = [
+        story.name for story in self.story_cls.default(separate=True)
+    ]
+    all_story_names = [
+        story.name for story in self.story_cls.all(separate=True)
+    ]
+    self.assertListEqual(default_story_names, all_story_names)
+
+
+class Speedometer21TestCase(Speedometer2BaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return Speedometer21Benchmark
+
+  @property
+  def story_cls(self):
+    return Speedometer21Story
+
+  @property
+  def probe_cls(self):
+    return Speedometer21Probe
+
+  @property
+  def name(self):
+    return "speedometer_2.1"
+
+
+class Speedometer30TestCase(SpeedometerBaseTestCase):
+
+  @property
+  def benchmark_cls(self):
+    return Speedometer30Benchmark
+
+  @property
+  def story_cls(self):
+    return Speedometer30Story
+
+  @property
+  def probe_cls(self):
+    return Speedometer30Probe
+
+  @property
+  def name(self):
+    return "speedometer_3.0"
+
+  @property
+  def name_all(self):
+    return "all"
+
+  @dataclass
+  class Namespace(SpeedometerBaseTestCase.Namespace):
+    sync_wait = dt.timedelta(0)
+    sync_warmup = dt.timedelta(0)
+    measurement_method = MeasurementMethod.RAF
+    story_viewport = None
+    shuffle_seed = None
+    detailed_metrics = False
+
+  EXAMPLE_STORY_DATA = {}
+
+  def _generate_s3_metrics(self, name, values):
+    return {
+        "children": [],
+        "delta": 0,
+        "geomean": 39.20000000298023,
+        "max": 39.20000000298023,
+        "mean": 39.20000000298023,
+        "min": 39.20000000298023,
+        "name": name,
+        "percentDelta": 0,
+        "sum": 39.20000000298023,
+        "unit": "ms",
+        "values": values
+    }
+
+  def _generate_test_probe_results(self, iterations, story):
+    values = [21.3] * iterations
+    probe_result = {
+        "Geomean": self._generate_s3_metrics("Geomean", values),
+        "Score": self._generate_s3_metrics("Score", values),
+    }
+    for iteration in range(iterations):
+      key = f"Iteration-{iteration}-Total"
+      probe_result[key] = self._generate_s3_metrics(key, values)
+
+    for substory_name in story.substories:
+      probe_result[substory_name] = self._generate_s3_metrics(
+          substory_name, values)
+    return probe_result
+
+  def test_run_combined(self):
+    self._run_combined(["TodoMVC-JavaScript-ES5", "TodoMVC-Backbone"])
+
+  def test_run_separate(self):
+    self._run_separate(["TodoMVC-JavaScript-ES5", "TodoMVC-Backbone"])
+
+  def test_s3_probe_results(self):
+    story_names = ("TodoMVC-JavaScript-ES5", "TodoMVC-Backbone")
+    self.browsers = [self.browsers[0]]
+    runner = self._test_run(
+        story_names=story_names, separate=False, repetitions=2)
+    self.assertEqual(len(runner.runs), 2)
+    run_1 = runner.runs[0]
+    run_2 = runner.runs[1]
+    probe_file = f"{self.probe_cls.NAME}.json"
+    with (run_1.out_dir / probe_file).open() as f:
+      data_1 = json.load(f)
+    with (run_2.out_dir / probe_file).open() as f:
+      data_2 = json.load(f)
+    keys_1 = tuple(data_1.keys())
+    keys_2 = tuple(data_2.keys())
+    self.assertTupleEqual(keys_1, keys_2)
+    # Make sure the aggregate metrics are at the end
+    expected_keys = story_names + ("Iteration-0-Total", "Iteration-1-Total",
+                                   "Geomean", "Score")
+    self.assertTupleEqual(keys_1, expected_keys)
+
+    with (runner.story_groups[0].path / probe_file).open() as f:
+      stories_data = json.load(f)
+    self.assertTupleEqual(tuple(stories_data.keys()), expected_keys)
+
+  def test_measurement_method_kwargs(self):
+    args = self.Namespace()
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.measurement_method, MeasurementMethod.RAF)
+
+    args.measurement_method = MeasurementMethod.TIMER
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.measurement_method, MeasurementMethod.TIMER)
+      self.assertDictEqual(story.url_params, {"measurementMethod": "timer"})
+
+  def test_sync_wait_kwargs(self):
+    args = self.Namespace()
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.sync_wait, dt.timedelta(0))
+
+    with self.assertRaises(argparse.ArgumentTypeError):
+      args.sync_wait = dt.timedelta(seconds=-123.4)
+      self.benchmark_cls.from_cli_args(args)
+
+    args.sync_wait = dt.timedelta(seconds=123.4)
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.sync_wait, dt.timedelta(seconds=123.4))
+      self.assertDictEqual(story.url_params, {"waitBeforeSync": "123400"})
+
+  def test_sync_warmup_kwargs(self):
+    args = self.Namespace()
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.sync_warmup, dt.timedelta(0))
+
+    with self.assertRaises(argparse.ArgumentTypeError):
+      args.sync_warmup = dt.timedelta(seconds=-123.4)
+      self.benchmark_cls.from_cli_args(args)
+
+    args.sync_warmup = dt.timedelta(seconds=123.4)
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.sync_warmup, dt.timedelta(seconds=123.4))
+      self.assertDictEqual(story.url_params, {"warmupBeforeSync": "123400"})
+
+  def test_viewport_kwargs(self):
+    args = self.Namespace()
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.viewport, None)
+
+    with self.assertRaises(argparse.ArgumentTypeError):
+      args.story_viewport = Viewport.FULLSCREEN
+      self.benchmark_cls.from_cli_args(args)
+
+    args.story_viewport = Viewport(999, 888)
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.viewport, Viewport(999, 888))
+      self.assertDictEqual(story.url_params, {"viewport": "999x888"})
+
+  def test_shuffle_seed_kwargs(self):
+    args = self.Namespace()
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.shuffle_seed, None)
+
+    with self.assertRaises(argparse.ArgumentTypeError):
+      args.shuffle_seed = "some invalid value"
+      self.benchmark_cls.from_cli_args(args)
+
+    args.shuffle_seed = 1234
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    for story in benchmark.stories:
+      assert isinstance(story, self.story_cls)
+      self.assertEqual(story.shuffle_seed, 1234)
+      self.assertDictEqual(story.url_params, {"shuffleSeed": "1234"})
+
+#  Don't expose abstract BaseTestCase to test runner
+del SpeedometerBaseTestCase
+del Speedometer2BaseTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/__init__.py b/tests/crossbench/browsers/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/browsers/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/browsers/chrome/__init__.py b/tests/crossbench/browsers/chrome/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/browsers/chrome/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/browsers/chrome/test_chrome.py b/tests/crossbench/browsers/chrome/test_chrome.py
new file mode 100644
index 0000000..6b38409
--- /dev/null
+++ b/tests/crossbench/browsers/chrome/test_chrome.py
@@ -0,0 +1,80 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+from crossbench import path as pth
+from crossbench.browsers.chrome.webdriver import (ChromeWebDriver,
+                                                  LocalChromeWebDriverAndroid)
+from crossbench.browsers.settings import Settings
+
+
+class ChromeWebDriverForTesting(ChromeWebDriver):
+
+  def _extract_version(self) -> str:
+    return mock_browser.MockChromeStable.VERSION
+
+
+class ChromeWebdriverTestCase(BaseCrossbenchTestCase):
+
+  def test_conflicting_finch_flags(self) -> None:
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ChromeWebDriverForTesting(
+          label="browser-label",
+          path=mock_browser.MockChromeStable.mock_app_path(),
+          settings=Settings(
+              js_flags=[],
+              flags=[
+                  "--disable-field-trial-config", "--enable-field-trial-config"
+              ],
+              platform=self.platform))
+    msg = str(cm.exception)
+    self.assertIn("--enable-field-trial-config", msg)
+    self.assertIn("--disable-field-trial-config", msg)
+
+  def test_auto_disabling_field_trials(self):
+    browser = ChromeWebDriverForTesting(
+        label="browser-label",
+        path=mock_browser.MockChromeStable.mock_app_path(),
+        settings=Settings(platform=self.platform))
+    self.assertIn("--disable-field-trial-config", browser.flags)
+
+    browser_field_trial = ChromeWebDriverForTesting(
+        label="browser-label",
+        path=mock_browser.MockChromeStable.mock_app_path(),
+        settings=Settings(
+            flags=["--force-fieldtrials"], platform=self.platform))
+    self.assertIn("--force-fieldtrials", browser_field_trial.flags)
+    self.assertNotIn("--disable-field-trial-config", browser_field_trial.flags)
+
+  def test_auto_disabling_field_trials_all(self):
+    for field_trial_flag in ChromeWebDriver.FIELD_TRIAL_FLAGS:
+      browser = ChromeWebDriverForTesting(
+          label="browser-label",
+          path=mock_browser.MockChromeStable.mock_app_path(),
+          settings=Settings(flags=[field_trial_flag], platform=self.platform))
+      flags = browser.flags
+      for no_experiment_flag in ChromeWebDriver.NO_EXPERIMENTS_FLAGS:
+        self.assertNotIn(no_experiment_flag, flags)
+
+
+class LocalChromeWebDriverAndroidTestCase(BaseCrossbenchTestCase):
+
+  def test_is_apk_helper(self):
+    self.assertTrue(
+        LocalChromeWebDriverAndroid.is_apk_helper(
+            pth.AnyPath("/home/user/Documents/chrome/src/"
+                        "out/arm64.apk/bin/chrome_public_apk")))
+    self.assertFalse(LocalChromeWebDriverAndroid.is_apk_helper(None))
+    self.assertFalse(
+        LocalChromeWebDriverAndroid.is_apk_helper(
+            pth.AnyPath("org.chromium.chrome")))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/chrome/test_downloader.py b/tests/crossbench/browsers/chrome/test_downloader.py
new file mode 100644
index 0000000..5a852c0
--- /dev/null
+++ b/tests/crossbench/browsers/chrome/test_downloader.py
@@ -0,0 +1,145 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import pathlib
+
+from crossbench.browsers.chrome.downloader import (ChromeDownloader,
+                                                   ChromeDownloaderLinux,
+                                                   ChromeDownloaderMacOS,
+                                                   ChromeDownloaderWin)
+from tests import test_helper
+from tests.crossbench.browsers.downloader_helper import \
+    AbstractDownloaderTestCase
+
+
+class AbstractChromeDownloaderTestCase(
+    AbstractDownloaderTestCase, metaclass=abc.ABCMeta):
+  __test__ = False
+
+  def test_wrong_versions(self) -> None:
+    with self.assertRaises(ValueError):
+      ChromeDownloader.load("", self.platform)
+    with self.assertRaises(ValueError):
+      ChromeDownloader.load("M", self.platform)
+    with self.assertRaises(ValueError):
+      ChromeDownloader.load("M-100", self.platform)
+    with self.assertRaises(ValueError):
+      ChromeDownloader.load("M100.1.2.3.4.5", self.platform)
+    with self.assertRaises(ValueError):
+      ChromeDownloader.load("100.1.2.3.4.5", self.platform)
+
+  def test_empty_path(self) -> None:
+    with self.assertRaises(ValueError):
+      ChromeDownloader.load(pathlib.Path("custom"), self.platform)
+
+  def test_load_valid_non_googler(self) -> None:
+    self.platform.which = lambda x: None
+    with self.assertRaises(ValueError):
+      ChromeDownloader.load("chrome-111.0.5563.110", self.platform)
+
+  def test_is_valid_strings(self) -> None:
+    self.assertFalse(ChromeDownloader.is_valid("", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("mM45", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("M4", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("M1234", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("M123.4", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("M123 ", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("M12 ", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("145", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("45", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("i145", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("i45", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("chr-i145", self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("chr-i45", self.platform))
+
+    self.assertTrue(ChromeDownloader.is_valid("M45", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("m45", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chrome-m45", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chrome-45", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chr-m45", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chr-45", self.platform))
+
+    self.assertTrue(ChromeDownloader.is_valid("M100", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("m100", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chrome-m100", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chrome-100", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chr-m100", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("chr-100", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("Google Chrome m100", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("Google Chrome 100", self.platform))
+
+    self.assertFalse(
+        ChromeDownloader.is_valid("M100.1.2.123.9999", self.platform))
+    self.assertTrue(ChromeDownloader.is_valid("M111.0.5563.110", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("Google Chrome M111.0.5563.110",
+                                  self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("Google Chrome Canary M111.0.5563.110",
+                                  self.platform))
+    self.assertFalse(ChromeDownloader.is_valid("111.0.5563.110", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("Google Chrome 111.0.5563.110",
+                                  self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("Google Chrome Canary111.0.5563.110",
+                                  self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("chrome-11.0.5563.110", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("chrome-M11.0.5563.110", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("chr-11.0.5563.110", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("chrome-111.0.5563.110", self.platform))
+    self.assertTrue(
+        ChromeDownloader.is_valid("chr-111.0.5563.110", self.platform))
+
+  def test_is_valid_path(self) -> None:
+    self.assertFalse(
+        ChromeDownloader.is_valid(pathlib.Path("custom"), self.platform))
+    path = pathlib.Path("download/archive.foo")
+    self.fs.create_file(path)
+    self.assertFalse(ChromeDownloader.is_valid(path, self.platform))
+
+
+class BasicChromeDownloaderTestCaseLinux(AbstractChromeDownloaderTestCase):
+  __test__ = True
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.platform.is_linux = True
+
+  def test_is_valid_archive(self) -> None:
+    path = pathlib.Path("download/archive.rpm")
+    self.fs.create_file(path)
+    self.assertTrue(ChromeDownloader.is_valid(path, self.platform))
+    self.assertTrue(ChromeDownloaderLinux.is_valid(path, self.platform))
+    self.assertFalse(ChromeDownloaderMacOS.is_valid(path, self.platform))
+    self.assertFalse(ChromeDownloaderWin.is_valid(path, self.platform))
+
+
+class BasicChromeDownloaderTestCaseMacOS(AbstractChromeDownloaderTestCase):
+  __test__ = True
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.platform.is_macos = True
+
+  def test_is_valid_archive(self) -> None:
+    path = pathlib.Path("download/archive.dmg")
+    self.fs.create_file(path)
+    self.assertTrue(ChromeDownloader.is_valid(path, self.platform))
+    self.assertTrue(ChromeDownloaderMacOS.is_valid(path, self.platform))
+    self.assertFalse(ChromeDownloaderLinux.is_valid(path, self.platform))
+    self.assertFalse(ChromeDownloaderWin.is_valid(path, self.platform))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/chromium/__init__.py b/tests/crossbench/browsers/chromium/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/browsers/chromium/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/browsers/chromium/test_chromium.py b/tests/crossbench/browsers/chromium/test_chromium.py
new file mode 100644
index 0000000..a1c10cf
--- /dev/null
+++ b/tests/crossbench/browsers/chromium/test_chromium.py
@@ -0,0 +1,27 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from tests import test_helper
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+from crossbench import path as pth
+from crossbench.browsers.chromium.webdriver import \
+    LocalChromiumWebDriverAndroid
+
+
+class LocalChromeWebDriverAndroidTestCase(BaseCrossbenchTestCase):
+
+  def test_is_apk_helper(self):
+    self.assertTrue(
+        LocalChromiumWebDriverAndroid.is_apk_helper(
+            pth.AnyPath("/home/user/Documents/chrome/src/"
+                        "out/arm64.apk/bin/chrome_public_apk")))
+    self.assertFalse(LocalChromiumWebDriverAndroid.is_apk_helper(None))
+    self.assertFalse(
+        LocalChromiumWebDriverAndroid.is_apk_helper(
+            pth.AnyPath("org.chromium.chrome")))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/downloader_helper.py b/tests/crossbench/browsers/downloader_helper.py
new file mode 100644
index 0000000..26951fe
--- /dev/null
+++ b/tests/crossbench/browsers/downloader_helper.py
@@ -0,0 +1,30 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import pathlib
+from unittest import mock
+
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class AbstractDownloaderTestCase(BaseCrossbenchTestCase, metaclass=abc.ABCMeta):
+  __test__ = False
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.platform = mock.Mock(
+        is_remote=False,
+        is_linux=False,
+        is_macos=False,
+        exists=self.fs.exists,
+        sh_results=[],
+        path=pathlib.Path)
+    self.platform.search_app = lambda x: x
+    self.platform.which = pathlib.Path
+    self.platform.host_platform = self.platform
+    self.cache_dir = pathlib.Path("crossbench/binary_cache")
+    self.fs.create_dir(self.cache_dir)
diff --git a/tests/crossbench/browsers/firefox/__init__.py b/tests/crossbench/browsers/firefox/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/browsers/firefox/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/browsers/firefox/test_downloader.py b/tests/crossbench/browsers/firefox/test_downloader.py
new file mode 100644
index 0000000..ce138a6
--- /dev/null
+++ b/tests/crossbench/browsers/firefox/test_downloader.py
@@ -0,0 +1,105 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import pathlib
+
+from crossbench.browsers.firefox.downloader import (FirefoxDownloader,
+                                                    FirefoxDownloaderLinux,
+                                                    FirefoxDownloaderMacOS,
+                                                    FirefoxDownloaderWin)
+from tests import test_helper
+from tests.crossbench.browsers.downloader_helper import \
+    AbstractDownloaderTestCase
+
+
+class AbstractFirefoxDownloaderTestCase(
+    AbstractDownloaderTestCase, metaclass=abc.ABCMeta):
+  __test__ = False
+
+  def test_wrong_versions(self) -> None:
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load("", self.platform)
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load("ff", self.platform)
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load("firefox", self.platform)
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load("124-0.2", self.platform)
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load("124-0.2", self.platform)
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load("124.0ab2", self.platform)
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load("124.0.2.3.5", self.platform)
+
+  def test_valid_versions_stable(self):
+    self.assertFalse(FirefoxDownloader.is_valid("124.0.2", self.platform))
+    self.assertTrue(FirefoxDownloader.is_valid("ff-124.0.2", self.platform))
+    self.assertTrue(
+        FirefoxDownloader.is_valid("firefox-124.0.2", self.platform))
+
+  def test_valid_versions_beta(self):
+    self.assertTrue(FirefoxDownloader.is_valid("104.0b9", self.platform))
+    self.assertTrue(FirefoxDownloader.is_valid("ff-104.0b9", self.platform))
+    self.assertTrue(
+        FirefoxDownloader.is_valid("firefox-104.0b9", self.platform))
+
+    self.assertFalse(FirefoxDownloader.is_valid("104.0ab9", self.platform))
+    self.assertFalse(FirefoxDownloader.is_valid("ff-104.0ab9", self.platform))
+    self.assertFalse(
+        FirefoxDownloader.is_valid("firefox-104.0ab9", self.platform))
+
+  def test_valid_versions_esr(self):
+    self.assertTrue(FirefoxDownloader.is_valid("115.0.3esr", self.platform))
+    self.assertTrue(FirefoxDownloader.is_valid("ff-115.0.3esr", self.platform))
+    self.assertTrue(
+        FirefoxDownloader.is_valid("firefox-115.0.3esr", self.platform))
+
+    self.assertFalse(FirefoxDownloader.is_valid("115.0a3esr", self.platform))
+    self.assertFalse(FirefoxDownloader.is_valid("ff-115.0a3esr", self.platform))
+    self.assertFalse(
+        FirefoxDownloader.is_valid("firefox-115.0a3esr", self.platform))
+
+  def test_empty_path(self) -> None:
+    with self.assertRaises(ValueError):
+      FirefoxDownloader.load(pathlib.Path("custom"), self.platform)
+
+
+class BasicFirefoxDownloaderLinuxTestCase(AbstractFirefoxDownloaderTestCase):
+  __test__ = True
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.platform.is_linux = True
+
+  def test_is_valid_archive(self) -> None:
+    path = pathlib.Path("download/archive.tar.bz2")
+    self.fs.create_file(path)
+    self.assertTrue(FirefoxDownloader.is_valid(path, self.platform))
+    self.assertTrue(FirefoxDownloaderLinux.is_valid(path, self.platform))
+    self.assertFalse(FirefoxDownloaderMacOS.is_valid(path, self.platform))
+    self.assertFalse(FirefoxDownloaderWin.is_valid(path, self.platform))
+
+
+class BasicFirefoxDownloaderMacOSTestCase(AbstractFirefoxDownloaderTestCase):
+  __test__ = True
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.platform.is_macos = True
+
+  def test_is_valid_archive(self) -> None:
+    path = pathlib.Path("download/archive.dmg")
+    self.fs.create_file(path)
+    self.assertTrue(FirefoxDownloader.is_valid(path, self.platform))
+    self.assertFalse(FirefoxDownloaderLinux.is_valid(path, self.platform))
+    self.assertTrue(FirefoxDownloaderMacOS.is_valid(path, self.platform))
+    self.assertFalse(FirefoxDownloaderWin.is_valid(path, self.platform))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/test_attributes.py b/tests/crossbench/browsers/test_attributes.py
new file mode 100644
index 0000000..ff861d9
--- /dev/null
+++ b/tests/crossbench/browsers/test_attributes.py
@@ -0,0 +1,59 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import unittest
+
+from crossbench.browsers.attributes import BrowserAttributes
+from tests import test_helper
+
+
+class BrowserAttributesTestCase(unittest.TestCase):
+
+  def test_is_chromium_based(self):
+    custom_chrome = (
+        BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED)
+    self.assertTrue(custom_chrome)
+    self.assertFalse(custom_chrome & BrowserAttributes.SAFARI)
+    self.assertTrue(custom_chrome & BrowserAttributes.CHROMIUM_BASED)
+    self.assertIs(custom_chrome & BrowserAttributes.CHROMIUM_BASED,
+                  BrowserAttributes.CHROMIUM_BASED)
+    self.assertTrue(custom_chrome.is_chromium_based)
+
+  def test_is_chrome(self):
+    for value in BrowserAttributes:
+      self.assertEqual(value.is_chrome, value is BrowserAttributes.CHROME)
+    custom = BrowserAttributes.CHROME | BrowserAttributes.WEBDRIVER
+    self.assertTrue(custom.is_chrome)
+    self.assertTrue(BrowserAttributes.CHROME.is_chrome)
+    self.assertFalse(BrowserAttributes.SAFARI.is_chrome)
+
+  def test_is_safari(self):
+    for value in BrowserAttributes:
+      self.assertEqual(value.is_safari, value is BrowserAttributes.SAFARI)
+    custom = BrowserAttributes.SAFARI | BrowserAttributes.WEBDRIVER
+    self.assertTrue(custom.is_safari)
+    self.assertTrue(BrowserAttributes.SAFARI.is_safari)
+    self.assertFalse(BrowserAttributes.CHROME.is_safari)
+
+  def test_is_edge(self):
+    for value in BrowserAttributes:
+      self.assertEqual(value.is_edge, value is BrowserAttributes.EDGE)
+    custom = BrowserAttributes.EDGE | BrowserAttributes.WEBDRIVER
+    self.assertTrue(custom.is_edge)
+    self.assertTrue(BrowserAttributes.EDGE.is_edge)
+    self.assertFalse(BrowserAttributes.CHROME.is_edge)
+
+  def test_is_firefox(self):
+    for value in BrowserAttributes:
+      self.assertEqual(value.is_firefox, value is BrowserAttributes.FIREFOX)
+    custom = BrowserAttributes.FIREFOX | BrowserAttributes.WEBDRIVER
+    self.assertTrue(custom.is_firefox)
+    self.assertTrue(BrowserAttributes.FIREFOX.is_firefox)
+    self.assertFalse(BrowserAttributes.CHROME.is_firefox)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/test_settings.py b/tests/crossbench/browsers/test_settings.py
new file mode 100644
index 0000000..2b9ef8a
--- /dev/null
+++ b/tests/crossbench/browsers/test_settings.py
@@ -0,0 +1,90 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import unittest
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.settings import Settings
+from crossbench.browsers.splash_screen import SplashScreen
+from crossbench.browsers.viewport import Viewport
+from crossbench.flags.base import Flags
+from crossbench.flags.chrome import ChromeFlags
+from crossbench.flags.js_flags import JSFlags
+
+
+class SettingsTestCase(unittest.TestCase):
+
+  def test_defaults(self):
+    settings = Settings()
+    self.assertEqual(settings.flags, Flags())
+    self.assertEqual(settings.js_flags, Flags())
+    self.assertIsNone(settings.cache_dir)
+    self.assertEqual(settings.viewport, Viewport.DEFAULT)
+    self.assertIsNone(settings.driver_path)
+    self.assertEqual(settings.splash_screen, SplashScreen.DEFAULT)
+    self.assertTrue(settings.network.is_live)
+    self.assertEqual(settings.platform, plt.PLATFORM)
+
+  def test_custom(self):
+    flags = Flags({"--one": "1", "--two": "2"}).freeze()
+    js_flags = Flags({"--js-one": "js-1", "--js-two": "js-2"}).freeze()
+    settings = Settings(
+        flags,
+        js_flags,
+        cache_dir=pth.LocalPath("cache"),
+        viewport=Viewport.FULLSCREEN,
+        driver_path=pth.LocalPath("driver"),
+        splash_screen=SplashScreen.DETAILED,
+    )
+    self.assertEqual(settings.flags, flags)
+    self.assertEqual(settings.js_flags, js_flags)
+    self.assertEqual(settings.cache_dir, pth.LocalPath("cache"))
+    self.assertEqual(settings.viewport, Viewport.FULLSCREEN)
+    self.assertEqual(settings.driver_path, pth.LocalPath("driver"))
+    self.assertEqual(settings.splash_screen, SplashScreen.DETAILED)
+    self.assertTrue(settings.network.is_live)
+
+  def test_js_flags_alone(self):
+    js_flags = Flags({"--js-one": "js-1", "--js-two": "js-2"}).freeze()
+    settings = Settings(js_flags=js_flags)
+    self.assertEqual(settings.flags, Flags())
+    self.assertEqual(settings.js_flags, js_flags)
+
+  def test_chrome_flags(self):
+    flags = ChromeFlags({"--one": "1", "--two": "2"}).freeze()
+    settings = Settings(flags)
+    self.assertEqual(settings.flags, flags)
+    self.assertIsInstance(settings.flags, ChromeFlags)
+    self.assertEqual(settings.js_flags, JSFlags())
+    self.assertIsInstance(settings.js_flags, JSFlags)
+
+  def test_chrome_flags_js_flags(self):
+    flags = ChromeFlags({
+        "--one": "1",
+        "--two": "2",
+        "--js-flags": "--js-one=js-1"
+    }).freeze()
+    settings = Settings(flags)
+    self.assertEqual(settings.flags, flags)
+    self.assertIsInstance(settings.flags, ChromeFlags)
+    self.assertEqual(settings.js_flags, JSFlags({"--js-one": "js-1"}))
+    self.assertIsInstance(settings.js_flags, JSFlags)
+
+  def test_chrome_flags_separate_js_flags(self):
+    flags = ChromeFlags({"--one": "1", "--two": "2"}).freeze()
+    js_flags = Flags({"--js-one": "js-1", "--js-two": "js-2"}).freeze()
+    settings = Settings(flags, js_flags)
+    self.assertEqual(settings.flags, flags)
+    self.assertIsInstance(settings.flags, ChromeFlags)
+    self.assertEqual(settings.js_flags, js_flags)
+    self.assertIsInstance(settings.js_flags, Flags)
+
+  def test_ambiguous_js_flags(self):
+    flags = ChromeFlags({"--one": "1", "--js-flags": "--js-one=js-1"}).freeze()
+    with self.assertRaises(ValueError) as cm:
+      _ = Settings(flags, js_flags=Flags({"--js-two": "js-2"}))
+    self.assertIn("js-flags", str(cm.exception))
diff --git a/tests/crossbench/browsers/test_splash_screen.py b/tests/crossbench/browsers/test_splash_screen.py
new file mode 100644
index 0000000..eed4854
--- /dev/null
+++ b/tests/crossbench/browsers/test_splash_screen.py
@@ -0,0 +1,40 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import unittest
+from argparse import ArgumentTypeError
+
+from crossbench.browsers.splash_screen import SplashScreen, URLSplashScreen
+from tests import test_helper
+
+
+class SplashScreenTestCase(unittest.TestCase):
+
+  def test_prase_invalid(self):
+    for invalid in ("a", "1", "{}"):
+      with self.assertRaises(ArgumentTypeError):
+        SplashScreen.parse(invalid)
+
+  def test_parse_default(self):
+    self.assertEqual(SplashScreen.parse(""), SplashScreen.DEFAULT)
+    self.assertEqual(SplashScreen.parse("default"), SplashScreen.DEFAULT)
+
+  def test_parse_named(self):
+    self.assertEqual(SplashScreen.parse("none"), SplashScreen.NONE)
+    self.assertEqual(SplashScreen.parse("minimal"), SplashScreen.MINIMAL)
+    self.assertEqual(SplashScreen.parse("detailed"), SplashScreen.DETAILED)
+
+  def test_parse_url(self):
+    splash = SplashScreen.parse("http://splash.com")
+    self.assertIsInstance(splash, URLSplashScreen)
+    self.assertEqual(splash.url, "http://splash.com")
+
+  def test_parse_file(self):
+    splash = SplashScreen.parse(__file__)
+    self.assertIsInstance(splash, URLSplashScreen)
+    self.assertIn("file://", splash.url)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/test_version.py b/tests/crossbench/browsers/test_version.py
new file mode 100644
index 0000000..40e74cd
--- /dev/null
+++ b/tests/crossbench/browsers/test_version.py
@@ -0,0 +1,941 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import unittest
+from typing import cast
+
+from crossbench.browsers.chrome.version import ChromeVersion
+from crossbench.browsers.chromium.version import (ChromeDriverVersion,
+                                                  ChromiumVersion)
+from crossbench.browsers.firefox.version import FirefoxVersion
+from crossbench.browsers.safari.version import SafariVersion
+from crossbench.browsers.version import (BrowserVersion, BrowserVersionChannel,
+                                         BrowserVersionParseError,
+                                         PartialBrowserVersionError,
+                                         UnknownBrowserVersion)
+from tests import test_helper
+
+
+class BrowserVersionChannelTestCase(unittest.TestCase):
+
+  def test_unique(self):
+    channels = set()
+    names = set()
+    indices = set()
+    for channel in BrowserVersionChannel:
+      self.assertNotIn(channel, channels)
+      self.assertNotIn(channel.name, names)
+      self.assertNotIn(channel.index, indices)
+      channels.add(channel)
+      names.add(channel.name)
+      indices.add(channel.index)
+
+  def test_name(self):
+    self.assertEqual(BrowserVersionChannel.STABLE.label, "stable")
+    self.assertEqual(str(BrowserVersionChannel.STABLE), "stable")
+
+  def test_compare(self):
+    self.assertLess(BrowserVersionChannel.LTS, BrowserVersionChannel.STABLE)
+    self.assertLess(BrowserVersionChannel.STABLE, BrowserVersionChannel.BETA)
+    self.assertLess(BrowserVersionChannel.BETA, BrowserVersionChannel.ALPHA)
+    self.assertLess(BrowserVersionChannel.ALPHA,
+                    BrowserVersionChannel.PRE_ALPHA)
+    self.assertLessEqual(BrowserVersionChannel.PRE_ALPHA,
+                         BrowserVersionChannel.PRE_ALPHA)
+
+  def test_equal(self):
+    self.assertEqual(BrowserVersionChannel.PRE_ALPHA,
+                     BrowserVersionChannel.PRE_ALPHA)
+
+  def test_sorting(self):
+    unsorted = [
+        BrowserVersionChannel.ALPHA, BrowserVersionChannel.PRE_ALPHA,
+        BrowserVersionChannel.STABLE, BrowserVersionChannel.BETA,
+        BrowserVersionChannel.LTS, BrowserVersionChannel.ANY
+    ]
+    self.assertListEqual(
+        sorted(unsorted), [
+            BrowserVersionChannel.LTS, BrowserVersionChannel.STABLE,
+            BrowserVersionChannel.BETA, BrowserVersionChannel.ALPHA,
+            BrowserVersionChannel.PRE_ALPHA, BrowserVersionChannel.ANY
+        ])
+
+  def test_compare_invalid(self):
+    with self.assertRaises(TypeError):
+      _ = BrowserVersionChannel.LTS < "some value"
+
+  def test_matches_any(self):
+    base = BrowserVersionChannel.ANY
+    self.assertTrue(base.matches(BrowserVersionChannel.ANY))
+    self.assertTrue(base.matches(BrowserVersionChannel.LTS))
+    self.assertTrue(base.matches(BrowserVersionChannel.STABLE))
+    self.assertTrue(base.matches(BrowserVersionChannel.BETA))
+    self.assertTrue(base.matches(BrowserVersionChannel.ALPHA))
+    self.assertTrue(base.matches(BrowserVersionChannel.PRE_ALPHA))
+
+  def test_matches_other(self):
+    test_channels = (BrowserVersionChannel.LTS, BrowserVersionChannel.STABLE,
+                     BrowserVersionChannel.BETA, BrowserVersionChannel.ALPHA,
+                     BrowserVersionChannel.PRE_ALPHA)
+    for channel in test_channels:
+      self.assertTrue(channel.matches(BrowserVersionChannel.ANY))
+      self.assertTrue(channel.matches(channel))
+      for other in test_channels:
+        if other != channel:
+          self.assertFalse(channel.matches(other))
+
+  def test_matches_lts(self):
+    base = BrowserVersionChannel.LTS
+    self.assertTrue(base.matches(BrowserVersionChannel.ANY))
+    self.assertTrue(base.matches(BrowserVersionChannel.LTS))
+    self.assertFalse(base.matches(BrowserVersionChannel.STABLE))
+    self.assertFalse(base.matches(BrowserVersionChannel.BETA))
+    self.assertFalse(base.matches(BrowserVersionChannel.ALPHA))
+    self.assertFalse(base.matches(BrowserVersionChannel.PRE_ALPHA))
+
+
+class _BrowserVersionTestCase(unittest.TestCase, metaclass=abc.ABCMeta):
+  ANY_VERSION_STR: str = ""
+  LTS_VERSION_STR: str = ""
+  STABLE_VERSION_STR: str = ""
+  BETA_VERSION_STR: str = ""
+  ALPHA_VERSION_STR: str = ""
+  PRE_ALPHA_VERSION_STR: str = ""
+  VERSION_CLS = BrowserVersion
+
+  @abc.abstractmethod
+  def parse(self, value: str) -> BrowserVersion:
+    pass
+
+  def _parse_helper(self, value: str):
+    self.assertTrue(value)
+    version: BrowserVersion = self.parse(value)
+    self.assertGreater(version.major, 0)
+    self.assertGreaterEqual(version.minor, 0)
+    return version
+
+  def test_parse_any(self):
+    if self.ANY_VERSION_STR == "":
+      self.skipTest(
+          f"{type(self).__name__}: 'any'-channel version not supported")
+    version: BrowserVersion = self._parse_helper(self.ANY_VERSION_STR)
+    self.assertTrue(str(version))
+    self.assertFalse(version.has_channel)
+    with self.assertRaises(ValueError):
+      _ = version.channel
+    self.assertFalse(version.is_complete)
+    self.assertTrue(version.has_complete_parts)
+    self.assertFalse(version.is_lts)
+    self.assertFalse(version.is_stable)
+    self.assertFalse(version.is_beta)
+    self.assertFalse(version.is_alpha)
+    self.assertFalse(version.is_pre_alpha)
+    self.assertEqual(version.channel_name, "any")
+    self.assertTrue(version.key)
+    _ = hash(version.key)
+    self.assertEqual(version, self.VERSION_CLS.any(version.parts))
+
+  def test_parse_lts(self):
+    if self.LTS_VERSION_STR == "":
+      self.skipTest(f"{type(self).__name__}: lts version not supported")
+    version: BrowserVersion = self._parse_helper(self.LTS_VERSION_STR)
+    self.assertEqual(version.channel, BrowserVersionChannel.LTS)
+    self.assertTrue(version.is_complete)
+    self.assertTrue(version.has_complete_parts)
+    self.assertTrue(version.is_lts)
+    self.assertFalse(version.is_stable)
+    self.assertFalse(version.is_beta)
+    self.assertFalse(version.is_alpha)
+    self.assertFalse(version.is_pre_alpha)
+    self.assertTrue(version.has_channel)
+    self.assertTrue(version.channel_name)
+    self.assertTrue(version.key)
+    _ = hash(version.key)
+    self.assertEqual(version, self.VERSION_CLS.lts(version.parts))
+
+
+  def test_parse_stable(self):
+    version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
+    self.assertEqual(version.channel, BrowserVersionChannel.STABLE)
+    self.assertTrue(str(version))
+    self.assertTrue(version.is_complete)
+    self.assertTrue(version.has_complete_parts)
+    self.assertFalse(version.is_lts)
+    self.assertTrue(version.is_stable)
+    self.assertFalse(version.is_beta)
+    self.assertFalse(version.is_alpha)
+    self.assertFalse(version.is_pre_alpha)
+    self.assertTrue(version.has_channel)
+    self.assertTrue(version.channel_name)
+    self.assertTrue(version.key)
+    _ = hash(version.key)
+    self.assertEqual(version, self.VERSION_CLS.stable(version.parts))
+
+  def test_parse_beta(self):
+    if not self.BETA_VERSION_STR:
+      self.skipTest(f"{type(self).__name__}: beta version not supported.")
+    version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
+    self.assertEqual(version.channel, BrowserVersionChannel.BETA)
+    self.assertTrue(str(version))
+    self.assertTrue(version.is_complete)
+    self.assertTrue(version.has_complete_parts)
+    self.assertFalse(version.is_lts)
+    self.assertFalse(version.is_stable)
+    self.assertTrue(version.is_beta)
+    self.assertFalse(version.is_alpha)
+    self.assertFalse(version.is_pre_alpha)
+    self.assertTrue(version.has_channel)
+    self.assertTrue(version.channel_name)
+    self.assertTrue(version.key)
+    _ = hash(version.key)
+    self.assertEqual(version, self.VERSION_CLS.beta(version.parts))
+
+  def test_parse_alpha(self):
+    if self.ALPHA_VERSION_STR == "":
+      self.skipTest(f"{type(self).__name__}: alpha version not supported")
+    version: BrowserVersion = self._parse_helper(self.ALPHA_VERSION_STR)
+    self.assertEqual(version.channel, BrowserVersionChannel.ALPHA)
+    self.assertTrue(str(version))
+    self.assertTrue(version.is_complete)
+    self.assertTrue(version.has_complete_parts)
+    self.assertFalse(version.is_lts)
+    self.assertFalse(version.is_stable)
+    self.assertFalse(version.is_beta)
+    self.assertTrue(version.is_alpha)
+    self.assertFalse(version.is_pre_alpha)
+    self.assertTrue(version.has_channel)
+    self.assertTrue(version.channel_name)
+    self.assertTrue(version.key)
+    _ = hash(version.key)
+    self.assertEqual(version, self.VERSION_CLS.alpha(version.parts))
+
+  def test_parse_pre_alpha(self):
+    if self.PRE_ALPHA_VERSION_STR == "":
+      self.skipTest(f"{type(self).__name__}: nightly version not supported")
+    version: BrowserVersion = self._parse_helper(self.PRE_ALPHA_VERSION_STR)
+    self.assertEqual(version.channel, BrowserVersionChannel.PRE_ALPHA)
+    self.assertTrue(str(version))
+    self.assertTrue(version.is_complete)
+    self.assertTrue(version.has_complete_parts)
+    self.assertFalse(version.is_lts)
+    self.assertFalse(version.is_stable)
+    self.assertFalse(version.is_beta)
+    self.assertFalse(version.is_alpha)
+    self.assertTrue(version.is_pre_alpha)
+    self.assertTrue(version.has_channel)
+    self.assertTrue(version.channel_name)
+    self.assertTrue(version.key)
+    _ = hash(version.key)
+    self.assertEqual(version, self.VERSION_CLS.pre_alpha(version.parts))
+
+  def test_equal_stable(self):
+    version_a = self.parse(self.STABLE_VERSION_STR)
+    version_b = self.parse(self.STABLE_VERSION_STR)
+    self.assertEqual(version_a, version_a)
+    self.assertEqual(version_a, version_b)
+    self.assertEqual(version_b, version_a)
+
+  def test_no_equal_stable_beta(self):
+    if not self.BETA_VERSION_STR:
+      self.skipTest(f"{type(self).__name__} :beta version not supported.")
+    version_stable = self.parse(self.STABLE_VERSION_STR)
+    version_beta = self.parse(self.BETA_VERSION_STR)
+    self.assertNotEqual(version_stable, version_beta)
+    self.assertNotEqual(version_beta, version_stable)
+
+  def test_stable_lt_beta(self):
+    if not self.BETA_VERSION_STR:
+      self.skipTest(f"{type(self).__name__}: beta version not supported.")
+    version_stable = self.parse(self.STABLE_VERSION_STR)
+    version_beta = self.parse(self.BETA_VERSION_STR)
+    # pylint: disable=comparison-with-itself
+    self.assertFalse(version_stable > version_stable)
+    self.assertFalse(version_stable < version_stable)
+    self.assertTrue(version_stable >= version_stable)
+    self.assertTrue(version_stable <= version_stable)
+    self.assertLess(version_stable, version_beta)
+    self.assertGreater(version_beta, version_stable)
+
+  def test_invalid(self):
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("no numbers here")
+
+  def test_contains_basic(self):
+    if not self.BETA_VERSION_STR:
+      self.skipTest(f"{type(self).__name__}: beta version not supported.")
+    version_stable = self.parse(self.STABLE_VERSION_STR)
+    version_beta = self.parse(self.BETA_VERSION_STR)
+    self.assertFalse(version_beta.contains(version_stable))
+    self.assertFalse(version_stable.contains(version_beta))
+    self.assertTrue(version_beta.contains(version_beta))
+    self.assertTrue(version_stable.contains(version_stable))
+
+
+class ChromiumVersionTestCase(_BrowserVersionTestCase):
+  ANY_VERSION_STR = ""
+  LTS_VERSION_STR = ""
+  STABLE_VERSION_STR = "Google Chromium 115.0.5790.114"
+  BETA_VERSION_STR = ""
+  ALPHA_VERSION_STR = ""
+  PRE_ALPHA_VERSION_STR = ""
+  VERSION_CLS = ChromiumVersion
+
+  def parse(self, value: str) -> ChromiumVersion:
+    return ChromiumVersion.parse(value)
+
+  def test_parse_invalid(self):
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium 115.0.5790.114.0.0.")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium 115.0.5790..114")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium 115.a.5790.114")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium 115 115.1.5790.114")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium ")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chrome 115.1.5790.114")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chrome 115")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chrome M115")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chr M115")
+
+  def test_init_invalid(self):
+    with self.assertRaises(BrowserVersionParseError):
+      ChromiumVersion(None)
+    with self.assertRaises(BrowserVersionParseError):
+      ChromiumVersion((-1, -2))
+
+  def test_equal(self):
+    self.assertEqual(self.parse("Chromium 125"), self.parse("125 Stable"))
+    self.assertNotEqual(self.parse("Chromium 125"), self.parse("120 Stable"))
+    self.assertEqual(self.parse("Chromium 120 Dev"), self.parse("120 Dev"))
+
+  def test_parse_full(self):
+    version = self.parse("Chromium 125.1.6416.3")
+    self.assertTrue(version.is_stable)
+    self.assertTrue(version.is_complete)
+    self.assertTrue(version.has_complete_parts)
+    self.assertEqual(str(version), "125.1.6416.3 stable")
+    self.assertEqual(version.major, 125)
+    self.assertEqual(version.minor, 1)
+    self.assertEqual(version.build, 6416)
+    self.assertEqual(version.patch, 3)
+    self.assertEqual(version.parts_str, "125.1.6416.3")
+
+  def parse_full_variants(self):
+    self.assertEqual(
+        self.parse("Chromium 125.1.6416.3"), self.parse("125.1.6416.3"))
+    self.assertEqual(
+        self.parse("Chromium 125.1.6416.3"), self.parse("M125.1.6416.3"))
+    self.assertEqual(
+        self.parse("Chromium 125.1.6416.3"), self.parse("m125.1.6416.3"))
+    self.assertEqual(
+        self.parse("Chromium 125.1.6416.3"), self.parse("125.1.6416.3 Stable"))
+    self.assertEqual(
+        self.parse("Chromium 125.1.6416.3"), self.parse("125.1.6416.3 stable"))
+
+  def test_parse_milestone_variants(self):
+    self.assertEqual(self.parse("Chromium 125"), self.parse("Chromium M125"))
+    self.assertEqual(self.parse("Chromium 125"), self.parse("M125"))
+    self.assertEqual(self.parse("Chromium 125"), self.parse("m125"))
+    self.assertEqual(self.parse("Chromium 125"), self.parse("125"))
+    self.assertEqual(self.parse("Chromium 125"), self.parse("125 Stable"))
+    self.assertEqual(self.parse("Chromium 125"), self.parse("125 stable"))
+
+  def test_parse_partial_milestone(self):
+    version = self.parse("Chromium 125")
+    self.assertTrue(version.is_stable)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertEqual(str(version), "M125 stable")
+    self.assertEqual(version.major, 125)
+    self.assertEqual(version.parts_str, "125")
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.minor
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.build
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.patch
+
+  def test_parse_partial_minor(self):
+    version = self.parse("Chromium 125.3.X.X")
+    self.assertTrue(version.is_stable)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertEqual(str(version), "125.3.X.X stable")
+    self.assertEqual(version.major, 125)
+    self.assertEqual(version.minor, 3)
+    self.assertEqual(version.parts_str, "125.3")
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.build
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.patch
+
+  def test_parse_partial_build(self):
+    version = self.parse("Chromium 125.3.1234.X")
+    self.assertTrue(version.is_stable)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertEqual(str(version), "125.3.1234.X stable")
+    self.assertEqual(version.major, 125)
+    self.assertEqual(version.minor, 3)
+    self.assertEqual(version.build, 1234)
+    self.assertEqual(version.parts_str, "125.3.1234")
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.patch
+
+
+class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
+  ANY_VERSION_STR = "Google Chrome 115.0.5790.114 Any"
+  LTS_VERSION_STR = ""
+  STABLE_VERSION_STR = "Google Chrome 115.0.5790.114"
+  BETA_VERSION_STR = "Google Chrome 116.0.5845.50 beta"
+  ALPHA_VERSION_STR = "Google Chrome 117.0.5911.2 dev"
+  PRE_ALPHA_VERSION_STR = "Google Chrome 117.0.5921.0 canary"
+  VERSION_CLS = ChromeVersion
+
+  def parse(self, value: str) -> ChromeVersion:
+    return ChromeVersion.parse(value)
+
+  def test_parse_invalid(self):
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Google Chrome 115.0.5790.114.0.0.")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Google Chrome 115.0.5790..114")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Google Chrome 115.a.5790.114")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chrome ")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chrome 121 121")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium 115.1.5790.114")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium 115")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium X.X.X.X")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chromium M115")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("M1")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("1")
+    with self.assertRaises(BrowserVersionParseError):
+      ChromeVersion.parse_unique("1")
+    _ = self.parse("123")
+    with self.assertRaises(BrowserVersionParseError):
+      ChromeVersion.parse_unique("123")
+
+  def test_parse_variants(self):
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("Chrome 115.0.5790.114"))
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("M115.0.5790.114"))
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("chr 115.0.5790.114"))
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("chrome 115.0.5790.114"))
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("chr-115.0.5790.114"))
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("chrome-115.0.5790.114"))
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("chr m115.0.5790.114"))
+    self.assertEqual(
+        self.parse("Google Chrome 115.0.5790.114"),
+        self.parse("chrome m115.0.5790.114"))
+
+  def test_parse_channel(self):
+    self.assertEqual(
+        self.parse(self.BETA_VERSION_STR),
+        self.parse("Google Chrome Beta 116.0.5845.50"))
+    self.assertEqual(
+        self.parse(self.ALPHA_VERSION_STR),
+        self.parse("Google Chrome DEv 117.0.5911.2"))
+    self.assertEqual(
+        self.parse(self.PRE_ALPHA_VERSION_STR),
+        self.parse("Google Chrome Canary 117.0.5921.0"))
+
+  def test_str(self):
+    self.assertEqual(
+        str(self.parse(self.STABLE_VERSION_STR)), "115.0.5790.114 stable")
+    self.assertEqual(
+        str(self.parse(self.BETA_VERSION_STR)), "116.0.5845.50 beta")
+    self.assertEqual(
+        str(self.parse(self.ALPHA_VERSION_STR)), "117.0.5911.2 dev")
+    self.assertEqual(
+        str(self.parse(self.PRE_ALPHA_VERSION_STR)), "117.0.5921.0 canary")
+
+  def test_parse_stable_chrome(self):
+    version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
+    self.assertEqual(version.major, 115)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "stable")
+    chrome_version = cast(ChromiumVersion, version)
+    self.assertEqual(chrome_version.build, 5790)
+    self.assertEqual(chrome_version.patch, 114)
+    self.assertFalse(chrome_version.is_dev)
+    self.assertFalse(chrome_version.is_canary)
+    stable_version = ChromeVersion.stable(version.parts)
+    self.assertEqual(stable_version, version)
+
+  def test_parse_beta_chrome(self):
+    version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
+    self.assertEqual(version.major, 116)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "beta")
+    chrome_version = cast(ChromiumVersion, version)
+    self.assertEqual(chrome_version.build, 5845)
+    self.assertEqual(chrome_version.patch, 50)
+    self.assertFalse(chrome_version.is_dev)
+    self.assertFalse(chrome_version.is_canary)
+    beta_version = ChromeVersion.beta(version.parts)
+    self.assertEqual(beta_version, version)
+
+  def test_parse_alpha_chrome(self):
+    version: BrowserVersion = self._parse_helper(self.ALPHA_VERSION_STR)
+    self.assertEqual(version.major, 117)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "dev")
+    chrome_version = cast(ChromiumVersion, version)
+    self.assertEqual(chrome_version.build, 5911)
+    self.assertEqual(chrome_version.patch, 2)
+    self.assertTrue(chrome_version.is_dev)
+    self.assertFalse(chrome_version.is_canary)
+    alpha_version = ChromeVersion.alpha(version.parts)
+    self.assertEqual(alpha_version, version)
+
+  def test_parse_pre_alpha_chrome(self):
+    version: BrowserVersion = self._parse_helper(self.PRE_ALPHA_VERSION_STR)
+    self.assertEqual(version.major, 117)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "canary")
+    chrome_version = cast(ChromiumVersion, version)
+    self.assertEqual(chrome_version.build, 5921)
+    self.assertEqual(chrome_version.patch, 0)
+    self.assertFalse(chrome_version.is_dev)
+    self.assertTrue(chrome_version.is_canary)
+    pre_alpha_version = ChromeVersion.pre_alpha(version.parts)
+    self.assertEqual(pre_alpha_version, version)
+
+  def test_parse_partial_milestone(self):
+    version = self.parse("Chrome 125")
+    self.assertTrue(version.is_stable)
+    self.assertTrue(version.has_channel)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertEqual(str(version), "M125 stable")
+    self.assertEqual(version.major, 125)
+    self.assertEqual(version.parts_str, "125")
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.minor
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.build
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.patch
+
+  def test_parse_partial_minor(self):
+    version = self.parse("Chrome 125.3.X.X")
+    self.assertTrue(version.is_stable)
+    self.assertTrue(version.has_channel)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertEqual(str(version), "125.3.X.X stable")
+    self.assertEqual(version.major, 125)
+    self.assertEqual(version.minor, 3)
+    self.assertEqual(version.parts_str, "125.3")
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.build
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.patch
+
+  def test_parse_partial_build(self):
+    version = self.parse("Chrome 125.3.1234.X")
+    self.assertTrue(version.is_stable)
+    self.assertTrue(version.has_channel)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertEqual(str(version), "125.3.1234.X stable")
+    self.assertEqual(version.major, 125)
+    self.assertEqual(version.minor, 3)
+    self.assertEqual(version.build, 1234)
+    self.assertEqual(version.parts_str, "125.3.1234")
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.patch
+
+  def test_parse_partial_channel(self):
+    version = self.parse("Chrome Stable")
+    self.assertTrue(version.is_stable)
+    self.assertTrue(version.has_channel)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertEqual(str(version), "stable")
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.major
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.minor
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.build
+    with self.assertRaises(PartialBrowserVersionError):
+      _ = version.patch
+
+  def test_parse_partial_channels(self):
+    version = self.parse("Chrome Extended")
+    self.assertTrue(version.is_lts)
+    version = self.parse("Chrome Stable")
+    self.assertTrue(version.is_stable)
+    version = self.parse("Chrome Beta")
+    self.assertTrue(version.is_beta)
+    version = self.parse("Chrome Dev")
+    self.assertTrue(version.is_alpha)
+    version = self.parse("Chrome Canary")
+    self.assertTrue(version.is_pre_alpha)
+
+  def test_compare_channel(self):
+    canary_version = self.parse(self.PRE_ALPHA_VERSION_STR)
+    dev_channel = self.parse("Chrome Dev")
+    stable_channel = self.parse("Chrome Stable")
+    dev_version = self.parse(self.ALPHA_VERSION_STR)
+    with self.assertRaises(ValueError):
+      _ = canary_version <= dev_channel
+    with self.assertRaises(ValueError):
+      _ = stable_channel <= dev_version
+    self.assertLess(stable_channel, dev_channel)
+    self.assertEqual(stable_channel, stable_channel)
+    self.assertEqual(dev_channel, dev_channel)
+
+  def test_compare_version_different_channels(self):
+    any_125_version = self.parse("Chrome 125.3.1234.60 any")
+    extended_125_version = self.parse("Chrome 125.3.1234.60 extended")
+    beta_125_version = self.parse("Chrome 125.3.1234.60 beta")
+    stable_125_version = self.parse("Chrome 125.3.1234.60 stable")
+    beta_120_version = self.parse("Chrome 120.3.1234.60 beta")
+    stable_120_version = self.parse("Chrome 120.3.1234.60 stable")
+    self.assertFalse(any_125_version.has_channel)
+    self.assertTrue(extended_125_version.is_lts)
+    self.assertTrue(stable_125_version.is_stable)
+    self.assertTrue(beta_125_version.is_beta)
+    self.assertTrue(stable_120_version.is_stable)
+    self.assertTrue(beta_120_version.is_beta)
+
+    self.assertLess(extended_125_version, beta_125_version)
+    self.assertLess(stable_125_version, beta_125_version)
+    self.assertLess(beta_120_version, beta_125_version)
+
+    self.assertLess(beta_120_version, extended_125_version)
+    self.assertLess(beta_120_version, stable_125_version)
+
+    self.assertLess(stable_120_version, beta_125_version)
+    self.assertLess(stable_120_version, extended_125_version)
+    self.assertLess(stable_120_version, stable_125_version)
+    self.assertLess(stable_120_version, beta_120_version)
+
+    self.assertNotEqual(stable_125_version, extended_125_version)
+    self.assertNotEqual(stable_125_version, beta_125_version)
+    self.assertNotEqual(stable_125_version, stable_120_version)
+    self.assertNotEqual(extended_125_version, beta_125_version)
+    self.assertNotEqual(extended_125_version, stable_120_version)
+
+  def test_parse_full_version_macos(self):
+    version = self.parse("125.0.6422.60 (Official Build) (arm64) ")
+    self.assertTrue(version.is_stable)
+    self.assertTrue(version.parts, (125, 0, 6422, 60))
+    version = self.parse("127.0.6490.1 (Official Build) canary (arm64) ")
+    self.assertTrue(version.is_pre_alpha)
+    self.assertTrue(version.parts, (127, 0, 6490, 1))
+
+  def test_parse_full_version_linux(self):
+    version = self.parse("125.0.6422.60 (Official Build) (64-bit) ")
+    self.assertTrue(version.is_stable)
+    self.assertTrue(version.parts, (125, 0, 6422, 60))
+    version = self.parse("126.0.6478.7 (Official Build) beta (64-bit) ")
+    self.assertTrue(version.is_beta)
+    self.assertTrue(version.parts, (126, 0, 6478, 7))
+
+  def test_contains_channel(self):
+    any_125_milestone = self.parse("Chrome M125 any")
+    beta_125_version = self.parse("Chrome 125.3.1234.60 beta")
+    stable_125_version = self.parse("Chrome 125.3.1234.60 stable")
+    channel_stable = self.parse("Chrome Stable")
+    channel_beta = self.parse("Chrome Beta")
+    milestone_125_stable = self.parse("Chrome M125 Stable")
+    milestone_125_beta = self.parse("Chrome M125 beta")
+
+    self.assertFalse(any_125_milestone.has_channel)
+    self.assertTrue(beta_125_version.has_channel)
+
+    self.assertTrue(any_125_milestone.contains(stable_125_version))
+    self.assertTrue(channel_stable.contains(stable_125_version))
+    self.assertFalse(channel_beta.contains(stable_125_version))
+    self.assertTrue(milestone_125_stable.contains(stable_125_version))
+    self.assertFalse(milestone_125_beta.contains(stable_125_version))
+
+    self.assertTrue(any_125_milestone.contains(beta_125_version))
+    self.assertFalse(channel_stable.contains(beta_125_version))
+    self.assertTrue(channel_beta.contains(beta_125_version))
+    self.assertFalse(milestone_125_stable.contains(beta_125_version))
+    self.assertTrue(milestone_125_beta.contains(beta_125_version))
+
+    self.assertTrue(any_125_milestone.contains(milestone_125_stable))
+    self.assertTrue(channel_stable.contains(milestone_125_stable))
+    self.assertFalse(channel_beta.contains(milestone_125_stable))
+    self.assertTrue(channel_stable.contains(milestone_125_stable))
+    self.assertFalse(channel_beta.contains(milestone_125_stable))
+
+    self.assertTrue(milestone_125_stable.contains(any_125_milestone))
+    self.assertTrue(channel_stable.contains(any_125_milestone))
+    self.assertTrue(channel_beta.contains(any_125_milestone))
+    self.assertTrue(channel_stable.contains(any_125_milestone))
+    self.assertTrue(channel_beta.contains(any_125_milestone))
+
+    self.assertFalse(any_125_milestone.contains(channel_beta))
+    self.assertFalse(beta_125_version.contains(channel_beta))
+    self.assertFalse(stable_125_version.contains(channel_beta))
+    self.assertFalse(channel_stable.contains(channel_beta))
+    self.assertTrue(channel_beta.contains(channel_beta))
+    self.assertFalse(milestone_125_stable.contains(channel_beta))
+    self.assertFalse(milestone_125_beta.contains(channel_beta))
+
+
+class ChromeDriverBrowserVersionTestCase(_BrowserVersionTestCase):
+  ANY_VERSION_STR = ""
+  LTS_VERSION_STR = ""
+  STABLE_VERSION_STR = ("ChromeDriver 115.0.5790.114 "
+                        "(386bc09e8f4f2e025eddae123f36f6263096ae49-"
+                        "refs/branch-heads/5735@{#1052})")
+  BETA_VERSION_STR = ""
+  ALPHA_VERSION_STR = ""
+  PRE_ALPHA_VERSION_STR = ("ChromeDriver 126.0.6424.0 "
+                           "(0000000000000000000000000000000000000000-"
+                           "0000000000000000000000000000000000000000)")
+  VERSION_CLS = ChromeDriverVersion
+
+  def parse(self, value: str) -> BrowserVersion:
+    return ChromeDriverVersion.parse(value)
+
+
+class FirefoxVersionTestCase(_BrowserVersionTestCase):
+  ANY_VERSION_STR = "Mozilla Firefox 114.0.1 any"
+  LTS_VERSION_STR = "Mozilla Firefox 114.0.1esr"
+  STABLE_VERSION_STR = "Mozilla Firefox 115.0.3"
+  # IRL Firefox version numbers do not distinct beta from stable. so we
+  # remap Firefox Dev => beta.
+  BETA_VERSION_STR = "Mozilla Firefox 116.0b4"
+  ALPHA_VERSION_STR = "Mozilla Firefox 117.0a1"
+  PRE_ALPHA_VERSION_STR = ""
+  VERSION_CLS = FirefoxVersion
+
+  def parse(self, value: str) -> BrowserVersion:
+    return FirefoxVersion.parse(value)
+
+  def test_parse_invalid(self):
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116.0b4esr")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116.0X4")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116.0a4b5")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116.10.0.1")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116.0a1.2")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116.10.0a")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116.10.1.0a")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Mozilla Firefox 116..0a")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Chrome 116.0a1")
+
+  def test_parse_lts_firefox(self):
+    version: BrowserVersion = self._parse_helper(self.LTS_VERSION_STR)
+    self.assertEqual(version.major, 114)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "esr")
+    self.assertTrue(version.is_lts)
+    version = self._parse_helper("115.8.0esr")
+    self.assertEqual(version.major, 115)
+    self.assertEqual(version.minor, 8)
+    self.assertEqual(version.channel_name, "esr")
+    self.assertTrue(version.is_lts)
+
+  def test_parse_stable_firefox(self):
+    version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
+    self.assertEqual(version.major, 115)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "stable")
+
+  def test_parse_beta_firefox(self):
+    version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
+    self.assertEqual(version.major, 116)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "dev")
+
+  def test_parse_alpha_firefox(self):
+    version: BrowserVersion = self._parse_helper(self.ALPHA_VERSION_STR)
+    self.assertEqual(version.major, 117)
+    self.assertEqual(version.minor, 0)
+    self.assertEqual(version.channel_name, "nightly")
+
+  def test_str(self):
+    self.assertEqual(str(self.parse(self.LTS_VERSION_STR)), "114.0.1 esr")
+    self.assertEqual(str(self.parse(self.STABLE_VERSION_STR)), "115.0.3 stable")
+    self.assertEqual(str(self.parse(self.BETA_VERSION_STR)), "116.0b4 dev")
+    self.assertEqual(str(self.parse(self.ALPHA_VERSION_STR)), "117.0a1 nightly")
+
+
+class SafariBrowserVersionTestCase(_BrowserVersionTestCase):
+  ANY_VERSION_STR = "16.6 Included with Safari 16.6 (18615.3.12.11.2) Any"
+  LTS_VERSION_STR = ""
+  # Additionally use the `safaridriver --version``
+  STABLE_VERSION_STR = "16.6 Included with Safari 16.6 (18615.3.12.11.2)"
+  BETA_VERSION_STR = ("17.0 Included with Safari Technology Preview "
+                      "(Release 175, 18617.1.1.2)")
+  ALPHA_VERSION_STR = ""
+  PRE_ALPHA_VERSION_STR = ""
+  VERSION_CLS = SafariVersion
+
+  def parse(self, value: str) -> BrowserVersion:
+    return SafariVersion.parse(value)
+
+  def test_parse_invalid(self):
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("(Release 175, 18617.1.1.2)")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("16.7 (Release 175, 18617.1.1.2)")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("16.7 XXX (Release, 18617.1.1.2)")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("16.6 XXX (18615.3...12.11.2)")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("16.6 XXX (18615.3)")
+
+  def test_parse_stable_safari(self):
+    version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
+    self.assertEqual(version.major, 16)
+    self.assertEqual(version.minor, 6)
+    safari_version = cast(SafariVersion, version)
+    self.assertFalse(safari_version.is_tech_preview)
+    self.assertEqual(safari_version.release, 0)
+    self.assertEqual(version.channel_name, "stable")
+
+  def test_parse_beta_safari(self):
+    version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
+    self.assertEqual(version.major, 17)
+    self.assertEqual(version.minor, 0)
+    safari_version = cast(SafariVersion, version)
+    self.assertTrue(safari_version.is_tech_preview)
+    self.assertEqual(safari_version.release, 175)
+    self.assertEqual(version.channel_name, "technology preview")
+
+  def test_str(self):
+    self.assertEqual(
+        str(self.parse(self.STABLE_VERSION_STR)),
+        "16.6 (18615.3.12.11.2) stable")
+    self.assertEqual(
+        str(self.parse(self.BETA_VERSION_STR)),
+        "17.0 (Release 175, 18617.1.1.2) technology preview")
+
+
+class BrowserVersionTestCase(unittest.TestCase):
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.sf_version = SafariVersion.parse(
+        "16.6 Included with Safari 16.6 (18615.3.12.11.2)")
+    self.chr_version = ChromeVersion.parse("Google Chrome 117.0.5911.2 dev")
+
+  def test_cross_browser_compare(self):
+    self.assertFalse(self.sf_version == self.chr_version)
+    with self.assertRaises(TypeError):
+      _ = self.sf_version <= self.chr_version
+    with self.assertRaises(TypeError):
+      _ = self.chr_version <= self.sf_version
+
+  def check_not_valid_unique(self, value: str):
+    self.assertFalse(ChromeVersion.is_valid_unique(value))
+    self.assertFalse(FirefoxVersion.is_valid_unique(value))
+    self.assertFalse(SafariVersion.is_valid_unique(value))
+
+  def test_not_valid_unique(self):
+    self.check_not_valid_unique("123")
+    self.check_not_valid_unique("123.1")
+    self.check_not_valid_unique("123.1.3")
+    self.check_not_valid_unique("123.1.3.2")
+
+  def check_is_valid_unique(self, value: str):
+    valid = (ChromeVersion.is_valid_unique(value),
+             FirefoxVersion.is_valid_unique(value),
+             SafariVersion.is_valid_unique(value))
+    self.assertEqual(sum(valid), 1)
+
+  def test_is_valid_unique(self):
+    for prefix in ("chr", "chr-", "chr", "chrome", "chrome-"):
+      with self.subTest(prefix=prefix):
+        self.check_is_valid_unique(f"{prefix}123")
+        self.check_is_valid_unique(f"{prefix}123.1.3.2")
+      self.check_is_valid_unique("123.1b3")
+      self.check_is_valid_unique("ff-123.1.3")
+      self.check_is_valid_unique("firefox-123.1a3")
+      self.check_is_valid_unique("ff-123.1b3")
+
+  def test_contains_invalid(self):
+    with self.assertRaises(TypeError):
+      self.sf_version.contains(self.chr_version)
+    with self.assertRaises(TypeError):
+      self.chr_version.contains(self.sf_version)
+
+
+class UnknownBrowserVersionTestCase(unittest.TestCase):
+
+  def test_init(self):
+    with self.assertRaises(RuntimeError):
+      UnknownBrowserVersion.parse("")
+
+  def test_attributes(self):
+    version = UnknownBrowserVersion()
+    self.assertFalse(version.has_channel)
+    self.assertFalse(version.is_complete)
+    self.assertFalse(version.has_complete_parts)
+    self.assertFalse(version.is_stable)
+    self.assertFalse(version.is_beta)
+    self.assertFalse(version.is_alpha)
+    self.assertFalse(version.is_pre_alpha)
+    self.assertEqual(version.parts, ())
+
+  def test_compare(self):
+    version = UnknownBrowserVersion()
+    chr_version = ChromeVersion.parse("Google Chrome 117.0.5911.2 dev")
+    self.assertFalse(version == chr_version)
+    with self.assertRaises(TypeError):
+      _ = version <= chr_version
+    with self.assertRaises(TypeError):
+      _ = chr_version <= version
+
+
+# Hide the abstract base test class from all test runner
+del _BrowserVersionTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/test_viewport.py b/tests/crossbench/browsers/test_viewport.py
new file mode 100644
index 0000000..d059ed2
--- /dev/null
+++ b/tests/crossbench/browsers/test_viewport.py
@@ -0,0 +1,171 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import unittest
+from argparse import ArgumentTypeError
+
+from crossbench.browsers.viewport import Viewport, ViewportMode
+from tests import test_helper
+
+
+class ViewportTestCase(unittest.TestCase):
+
+  def test_is_default(self):
+    self.assertTrue(Viewport.DEFAULT.is_default)
+    self.assertFalse(Viewport.FULLSCREEN.is_default)
+    self.assertFalse(Viewport.MAXIMIZED.is_default)
+    self.assertFalse(Viewport.HEADLESS.is_default)
+    self.assertFalse(Viewport().is_default)
+
+  def test_has_size(self):
+    self.assertTrue(Viewport.DEFAULT.has_size)
+    self.assertFalse(Viewport.FULLSCREEN.has_size)
+    self.assertFalse(Viewport.MAXIMIZED.has_size)
+    self.assertFalse(Viewport.HEADLESS.has_size)
+    self.assertTrue(Viewport().has_size)
+
+  def test_is_maximized(self):
+    self.assertFalse(Viewport.DEFAULT.is_maximized)
+    self.assertFalse(Viewport.FULLSCREEN.is_maximized)
+    self.assertTrue(Viewport.MAXIMIZED.is_maximized)
+    self.assertFalse(Viewport.HEADLESS.is_maximized)
+    self.assertFalse(Viewport().is_maximized)
+
+  def test_is_fullscreen(self):
+    self.assertFalse(Viewport.DEFAULT.is_fullscreen)
+    self.assertTrue(Viewport.FULLSCREEN.is_fullscreen)
+    self.assertFalse(Viewport.MAXIMIZED.is_fullscreen)
+    self.assertFalse(Viewport.HEADLESS.is_fullscreen)
+    self.assertFalse(Viewport().is_fullscreen)
+
+  def test_is_headless(self):
+    self.assertFalse(Viewport.DEFAULT.is_headless)
+    self.assertFalse(Viewport.FULLSCREEN.is_headless)
+    self.assertFalse(Viewport.MAXIMIZED.is_headless)
+    self.assertTrue(Viewport.HEADLESS.is_headless)
+    self.assertFalse(Viewport().is_headless)
+
+  def test_mode(self):
+    self.assertEqual(Viewport.DEFAULT.mode, ViewportMode.SIZE)
+    self.assertEqual(Viewport.FULLSCREEN.mode, ViewportMode.FULLSCREEN)
+    self.assertEqual(Viewport.MAXIMIZED.mode, ViewportMode.MAXIMIZED)
+    self.assertEqual(Viewport.HEADLESS.mode, ViewportMode.HEADLESS)
+    self.assertEqual(Viewport().mode, ViewportMode.SIZE)
+
+  NON_SIZED_DEFAULTS = (Viewport.FULLSCREEN, Viewport.MAXIMIZED,
+                        Viewport.HEADLESS)
+
+  def test_position(self):
+    for invalid in self.NON_SIZED_DEFAULTS:
+      with self.assertRaises(AssertionError):
+        _ = invalid.position
+    self.assertTupleEqual(Viewport.DEFAULT.position, (10, 50))
+    self.assertTupleEqual(Viewport(x=100, y=200).position, (100, 200))
+
+  def test_size(self):
+    for invalid in self.NON_SIZED_DEFAULTS:
+      with self.assertRaises(AssertionError):
+        _ = invalid.size
+    self.assertTupleEqual(Viewport.DEFAULT.size, (1500, 1000))
+    self.assertTupleEqual(Viewport(100, 200).size, (100, 200))
+
+  def test_width(self):
+    for invalid in self.NON_SIZED_DEFAULTS:
+      with self.assertRaises(AssertionError):
+        _ = invalid.width
+    self.assertEqual(Viewport.DEFAULT.width, 1500)
+    self.assertEqual(Viewport(100, 200).width, 100)
+
+  def test_height(self):
+    for invalid in self.NON_SIZED_DEFAULTS:
+      with self.assertRaises(AssertionError):
+        _ = invalid.height
+    self.assertEqual(Viewport.DEFAULT.height, 1000)
+    self.assertEqual(Viewport(100, 200).height, 200)
+
+  def test_x(self):
+    for invalid in self.NON_SIZED_DEFAULTS:
+      with self.assertRaises(AssertionError):
+        _ = invalid.x
+    self.assertEqual(Viewport.DEFAULT.x, 10)
+    self.assertEqual(Viewport(x=100, y=200).x, 100)
+
+  def test_y(self):
+    for invalid in self.NON_SIZED_DEFAULTS:
+      with self.assertRaises(AssertionError):
+        _ = invalid.y
+    self.assertEqual(Viewport.DEFAULT.y, 50)
+    self.assertEqual(Viewport(x=100, y=200).y, 200)
+
+  def test_parse_invalid(self):
+    invalid_inputs = ("-", "-100x", "100x", "100xXX", "100x-100", "-100x100",
+                      "asdf", "100x100,,", "100x100,a", "100x100,100",
+                      "100x100,100x", "100x100,-100", "100x100,100x-100",
+                      "100x100,-100x100")
+    for invalid in invalid_inputs:
+      with self.subTest(value=invalid):
+        with self.assertRaises((ValueError, ArgumentTypeError)):
+          Viewport.parse(invalid)
+
+  def test_parse_placeholders(self):
+    for value in ("m", "max", "maximised", "maximized"):
+      self.assertTrue(Viewport.parse(value).is_maximized)
+    for value in ("f", "full", "fullscreen"):
+      self.assertTrue(Viewport.parse(value).is_fullscreen)
+    self.assertTrue(Viewport.parse("headless").is_headless)
+    self.assertTrue(Viewport.parse("").is_default)
+
+  def test_non_size_wrong_params(self):
+    with self.assertRaises(ArgumentTypeError):
+      Viewport(width=100, height=0, x=0, y=0, mode=ViewportMode.MAXIMIZED)
+    with self.assertRaises(ArgumentTypeError):
+      Viewport(width=0, height=100, x=0, y=0, mode=ViewportMode.MAXIMIZED)
+    with self.assertRaises(ArgumentTypeError):
+      Viewport(width=0, height=0, x=100, y=0, mode=ViewportMode.MAXIMIZED)
+    with self.assertRaises(ArgumentTypeError):
+      Viewport(width=0, height=0, x=0, y=100, mode=ViewportMode.MAXIMIZED)
+
+  def test_parse(self):
+    viewport: Viewport = Viewport.parse("100x200")
+    self.assertTupleEqual(viewport.size, (100, 200))
+    self.assertTupleEqual(viewport.position, Viewport.DEFAULT.position)
+    viewport = Viewport.parse("100x200,22x33")
+    self.assertTupleEqual(viewport.size, (100, 200))
+    self.assertTupleEqual(viewport.position, (22, 33))
+
+  def test_parse_sized_invalid(self):
+    for invalid in (None, 1, tuple()):
+      with self.assertRaises(ArgumentTypeError):
+        Viewport.parse_sized(invalid)
+
+  def test_parse_sized_invalid_no_size(self):
+    for invalid in ("fullscreen", Viewport.FULLSCREEN, "headless",
+                    Viewport.HEADLESS):
+      with self.assertRaises(ArgumentTypeError) as cm:
+        Viewport.parse_sized(invalid)
+      self.assertIn("explicit size", str(cm.exception))
+
+  def test_parse_sized(self):
+    sized = Viewport.parse_sized("500x500,11x22")
+    self.assertEqual(sized, Viewport(500, 500, 11, 22))
+    sized = Viewport.parse_sized(Viewport.DEFAULT)
+    self.assertIs(sized, Viewport.DEFAULT)
+
+  def test_str(self):
+    self.assertEqual(
+        str(Viewport.parse("100x200,22x33")), "Viewport(100x200,22x33)")
+    self.assertEqual(str(Viewport.MAXIMIZED), "Viewport(maximized)")
+
+  def test_equal(self):
+    self.assertFalse(Viewport.DEFAULT == "other")
+    self.assertTrue(Viewport.DEFAULT == Viewport.DEFAULT)
+    self.assertFalse(Viewport.DEFAULT != Viewport.DEFAULT)
+    self.assertTrue(Viewport.MAXIMIZED == Viewport.MAXIMIZED)
+    self.assertFalse(Viewport.DEFAULT == Viewport.MAXIMIZED)
+    self.assertTrue(
+        Viewport.parse("100x200,22x33"), Viewport.parse("100x200,22x33"))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/__init__.py b/tests/crossbench/cli/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/cli/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/cli/config/__init__.py b/tests/crossbench/cli/config/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/cli/config/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/cli/config/base.py b/tests/crossbench/cli/config/base.py
new file mode 100644
index 0000000..ce17d6f
--- /dev/null
+++ b/tests/crossbench/cli/config/base.py
@@ -0,0 +1,66 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Type
+from unittest import mock
+
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+from crossbench import path as pth
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+
+XCTRACE_DEVICES_OUTPUT = """
+== Devices ==
+a-macbookpro3 (00001234-AAAA-BBBB-0000-11AA22BB33DD)
+An iPhone (17.1.2) (00001111-11AA22BB33DD)
+An iPhone Pro (17.1.1) (00002222-11AA22BB33DD)
+
+== Devices Offline ==
+An iPhone Pro Max (17.1.0) (00003333-11AA22BB33DD)
+
+== Simulators ==
+iPad (10th generation) (17.0.1) (00001234-AAAA-BBBB-1111-11AA22BB33DD)
+iPad (9th generation) Simulator (15.5) (00001234-AAAA-BBBB-2222-11AA22BB33DD
+"""
+XCTRACE_DEVICES_SINGLE_OUTPUT = """
+== Devices ==
+a-macbookpro3 (00001234-AAAA-BBBB-0000-11AA22BB33DD)
+An iPhone (17.1.2) (00001111-11AA22BB33DD)
+
+== Devices Offline ==
+An iPhone Pro (17.1.1) (00002222-11AA22BB33DD)
+
+== Simulators ==
+iPad (10th generation) (17.0.1) (00001234-AAAA-BBBB-1111-11AA22BB33DD)
+iPad (9th generation) Simulator (15.5) (00001234-AAAA-BBBB-2222-11AA22BB33DD
+"""
+
+ADB_DEVICES_SINGLE_OUTPUT = (
+    "List of devices attached\n"
+    "emulator-5556 device product:sdk_google_phone_x86_64 "
+    "model:Android_SDK_built_for_x86_64 device:generic_x86_64\n")
+
+ADB_DEVICES_OUTPUT = (
+    f"{ADB_DEVICES_SINGLE_OUTPUT}"
+    "emulator-5554 device product:sdk_google_phone_x86 "
+    "model:Android_SDK_built_for_x86 device:generic_x86\n"
+    "0a388e93      device usb:1-1 product:razor model:Nexus_7 device:flo\n")
+
+
+class BaseConfigTestCase(BaseCrossbenchTestCase):
+
+  def setUp(self) -> None:
+    super().setUp()
+    adb_patcher = mock.patch(
+        "crossbench.plt.android_adb._find_adb_bin",
+        return_value=pth.LocalPath("adb"))
+    adb_patcher.start()
+    self.addCleanup(adb_patcher.stop)
+
+  def mock_chrome_stable(self, browser_cls: Type[mock_browser.MockBrowser]):
+    return mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls)
diff --git a/tests/crossbench/cli/config/test_browser.py b/tests/crossbench/cli/config/test_browser.py
new file mode 100644
index 0000000..fd9d004
--- /dev/null
+++ b/tests/crossbench/cli/config/test_browser.py
@@ -0,0 +1,469 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import unittest
+
+import hjson
+from immutabledict import immutabledict
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.chrome.chrome import Chrome
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
+from crossbench.cli.config.network import NetworkConfig, NetworkSpeedPreset
+from crossbench.exception import MultiException
+from crossbench.types import JsonDict
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.cli.config.base import (ADB_DEVICES_OUTPUT,
+                                              ADB_DEVICES_SINGLE_OUTPUT,
+                                              XCTRACE_DEVICES_OUTPUT,
+                                              XCTRACE_DEVICES_SINGLE_OUTPUT,
+                                              BaseConfigTestCase)
+
+
+class BrowserConfigTestCase(BaseConfigTestCase):
+
+  def test_equal(self):
+    path = Chrome.stable_path(self.platform)
+    self.assertEqual(
+        BrowserConfig(path, DriverConfig(BrowserDriverType.default())),
+        BrowserConfig(path, DriverConfig(BrowserDriverType.default())))
+    self.assertNotEqual(
+        BrowserConfig(path, DriverConfig(BrowserDriverType.default())),
+        BrowserConfig(
+            path,
+            DriverConfig(
+                BrowserDriverType.default(), settings=immutabledict(custom=1))))
+    self.assertNotEqual(
+        BrowserConfig(path, DriverConfig(BrowserDriverType.default())),
+        BrowserConfig(
+            pth.AnyPath("foo"), DriverConfig(BrowserDriverType.default())))
+
+  def test_hashable(self):
+    _ = hash(BrowserConfig.default())
+    _ = hash(
+        BrowserConfig(
+            pth.AnyPath("foo"),
+            DriverConfig(
+                BrowserDriverType.default(), settings=immutabledict(custom=1))))
+
+  def test_parse_name_or_path(self):
+    path = Chrome.stable_path(self.platform)
+    self.assertEqual(
+        BrowserConfig.parse("chrome"),
+        BrowserConfig(path, DriverConfig(BrowserDriverType.default())))
+    self.assertEqual(
+        BrowserConfig.parse(str(path)),
+        BrowserConfig(path, DriverConfig(BrowserDriverType.default())))
+
+  def test_parse_invalid_name(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse("")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse("a-random-name")
+    self.assertIn("a-random-name", str(cm.exception))
+
+  def test_parse_invalid_path(self):
+    path = pth.AnyPath("foo/bar")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse(str(path))
+    self.assertIn(str(path), str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse("selenium/bar")
+    self.assertIn("selenium", str(cm.exception))
+    self.assertIn("bar", str(cm.exception))
+
+  def test_parse_invalid_windows_path(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse("selenium\\bar")
+    self.assertIn("selenium\\\\bar", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse("C:\\selenium\\bar")
+    self.assertIn("C:\\\\selenium\\\\bar", str(cm.exception))
+
+  def test_parse_simple_missing_driver(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse(":chrome")
+    self.assertIn("driver", str(cm.exception))
+
+  def test_parse_invalid_network_preset(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse("selenium:chrome:1xx2")
+    self.assertIn("network", str(cm.exception))
+    self.assertIn("1xx2", str(cm.exception))
+
+  def test_parse_simple_with_driver(self):
+    self.assertEqual(
+        BrowserConfig.parse("selenium:chrome"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER)))
+    self.assertEqual(
+        BrowserConfig.parse("webdriver:chrome"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER)))
+    self.assertEqual(
+        BrowserConfig.parse("applescript:chrome"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.APPLE_SCRIPT)))
+    self.assertEqual(
+        BrowserConfig.parse("osa:chrome"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.APPLE_SCRIPT)))
+
+  def test_parse_simple_with_driver_with_network(self):
+    self.assertEqual(
+        BrowserConfig.parse("chrome:4G"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER),
+            NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G)))
+    self.assertEqual(
+        BrowserConfig.parse("selenium:chrome:4G"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER),
+            NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G)))
+
+  def test_parse_simple_ambiguous_with_driver_ios(self):
+    self.platform.sh_results = [XCTRACE_DEVICES_OUTPUT]
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = BrowserConfig.parse("ios:chrome")
+    self.assertIn("devices", str(cm.exception))
+
+  def test_parse_simple_with_driver_ios(self):
+    self.platform.sh_results = [
+        XCTRACE_DEVICES_SINGLE_OUTPUT, XCTRACE_DEVICES_SINGLE_OUTPUT
+    ]
+    config = BrowserConfig.parse("ios:chrome")
+    self.assertEqual(
+        config,
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.IOS)))
+    self.assertIsNone(config.network)
+    self.platform.sh_results = [
+        XCTRACE_DEVICES_SINGLE_OUTPUT,
+    ]
+    config = BrowserConfig.parse("ios:chrome:live")
+    self.assertEqual(config.network, NetworkConfig.default())
+
+  def test_parse_simple_with_driver_ios_with_network(self):
+    self.platform.sh_results = [
+        XCTRACE_DEVICES_SINGLE_OUTPUT, XCTRACE_DEVICES_SINGLE_OUTPUT
+    ]
+    config = BrowserConfig.parse("ios:chrome:4G")
+    self.assertEqual(
+        config,
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.IOS),
+            NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G)))
+    self.assertEqual(config.network,
+                     NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G))
+
+  def test_parse_simple_ambiguous_with_driver_android(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = BrowserConfig.parse("adb:chrome")
+    self.assertIn("devices", str(cm.exception))
+
+  def test_parse_simple_with_driver_android(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("adb:chrome"),
+        BrowserConfig(
+            pth.AnyPosixPath("com.android.chrome"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+    self.assertListEqual(self.platform.sh_results, [])
+
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("android:com.chrome.beta"),
+        BrowserConfig(
+            pth.AnyPosixPath("com.chrome.beta"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+    self.assertListEqual(self.platform.sh_results, [])
+
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("android:chrome-beta"),
+        BrowserConfig(
+            pth.AnyPosixPath("com.chrome.beta"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+    self.assertListEqual(self.platform.sh_results, [])
+
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("adb:chrome-dev"),
+        BrowserConfig(
+            pth.AnyPosixPath("com.chrome.dev"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+    self.assertListEqual(self.platform.sh_results, [])
+
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("android:chrome-canary"),
+        BrowserConfig(
+            pth.AnyPosixPath("com.chrome.canary"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+    self.assertListEqual(self.platform.sh_results, [])
+
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("android:chromium"),
+        BrowserConfig(
+            pth.AnyPosixPath("org.chromium.chrome"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+    self.assertListEqual(self.platform.sh_results, [])
+
+  def test_parse_simple_with_local_apk(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("adb:/chrome/src/out/Release/chromium.apk"),
+        BrowserConfig(
+            pth.LocalPosixPath("/chrome/src/out/Release/chromium.apk"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+
+  def test_parse_simple_with_local_built_apk_helper(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    self.assertEqual(
+        BrowserConfig.parse("adb:/chrome/src/out/Release/chrome_public_apk"),
+        BrowserConfig(
+            pth.LocalPosixPath("/chrome/src/out/Release/chrome_public_apk"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+
+  @unittest.skip("Non-path browser short names are not yet supported "
+                 "in complex configs.")
+  def test_parse_inline_hjson_android(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+    config_dict: JsonDict = {
+        "browser": "com.android.chrome",
+        "driver": "android",
+    }
+    self.assertEqual(
+        BrowserConfig.parse(config_dict),
+        BrowserConfig(
+            pth.AnyPath("com.android.chrome"),
+            DriverConfig(BrowserDriverType.ANDROID)))
+    self.assertListEqual(self.platform.sh_results, [])
+
+  def test_parse_invalid_android_package(self):
+    self.platform.sh_results = [ADB_DEVICES_SINGLE_OUTPUT]
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse("")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse("adb:com.Foo .bar. com")
+    self.assertIn("com.Foo .bar. com", str(cm.exception))
+
+  def test_parse_fail_android_browser_string_not_dict(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse({"browser": "adb:chrome"})
+    self.assertIn("browser", str(cm.exception))
+    self.assertIn("short-form", str(cm.exception))
+
+  @unittest.skipIf(plt.PLATFORM.is_win,
+                   "Chrome downloading not supported on windows.")
+  def test_parse_chrome_version(self):
+    self.assertEqual(
+        BrowserConfig.parse("applescript:chrome-m100"),
+        BrowserConfig("chrome-m100",
+                      DriverConfig(BrowserDriverType.APPLE_SCRIPT)))
+    self.assertEqual(
+        BrowserConfig.parse("selenium:chrome-116.0.5845.4"),
+        BrowserConfig("chrome-116.0.5845.4",
+                      DriverConfig(BrowserDriverType.WEB_DRIVER)))
+
+  def test_parse_invalid_chrome_version(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = BrowserConfig.parse("applescript:chrome-m1")
+    self.assertIn("m1", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = BrowserConfig.parse("selenium:chrome-116.845.4.3.2.1.0")
+    self.assertIn("116.845.4.3.2.1.0", str(cm.exception))
+
+  def test_parse_adb_phone_serial(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT, ADB_DEVICES_OUTPUT]
+    config = BrowserConfig.parse("0a388e93:chrome")
+    assert isinstance(config, BrowserConfig)
+    self.assertListEqual(self.platform.sh_results, [])
+    self.assertEqual(len(self.platform.sh_cmds), 2)
+
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    expected_driver = DriverConfig(
+        BrowserDriverType.ANDROID, device_id="0a388e93")
+    self.assertEqual(len(self.platform.sh_results), 0)
+    self.assertEqual(len(self.platform.sh_cmds), 3)
+    self.assertEqual(
+        config,
+        BrowserConfig(pth.AnyPosixPath("com.android.chrome"), expected_driver))
+
+  @unittest.skipIf(plt.PLATFORM.is_macos, "Incompatible platform")
+  def test_parse_adb_phone_serial_invalid_macos(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = BrowserConfig.parse("0XXXXXX:chrome")
+    self.assertIn("0XXXXXX", str(cm.exception))
+    self.assertEqual(len(self.platform.sh_cmds), 1)
+
+  @unittest.skipIf(not plt.PLATFORM.is_macos, "Incompatible platform")
+  def test_parse_adb_phone_serial_invalid_non_macos(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT, XCTRACE_DEVICES_OUTPUT]
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = BrowserConfig.parse("0XXXXXX:chrome")
+    self.assertIn("0XXXXXX", str(cm.exception))
+    self.assertEqual(len(self.platform.sh_cmds), 2)
+
+  def test_parse_invalid_driver(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse("____:chrome")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      # This has to be dealt with in users of DriverConfig.parse.
+      BrowserConfig.parse("::chrome")
+
+  def test_parse_invalid_hjson(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse("{:::}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse("{}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse("}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse("{path:something}")
+
+  def test_parse_inline_hjson(self):
+    config_dict: JsonDict = {"browser": "chrome", "driver": {"type": "adb",}}
+
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    with self.assertRaises(MultiException) as cm:
+      _ = BrowserConfig.parse(hjson.dumps(config_dict))
+    self.assertIn("devices", str(cm.exception))
+
+    self.platform.sh_results = [ADB_DEVICES_SINGLE_OUTPUT]
+    config_1 = BrowserConfig.parse(hjson.dumps(config_dict))
+    assert isinstance(config_1, BrowserConfig)
+    self.assertEqual(config_1.driver.type, BrowserDriverType.ANDROID)
+
+    self.platform.sh_results = [ADB_DEVICES_SINGLE_OUTPUT]
+    config_2 = BrowserConfig.parse_dict(config_dict)
+    assert isinstance(config_2, BrowserConfig)
+    self.assertEqual(config_2.driver.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config_1, config_2)
+
+    short_config_dict: JsonDict = {
+        "browser": "chrome",
+        "driver": "adb",
+    }
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    with self.assertRaises(MultiException) as cm:
+      _ = BrowserConfig.parse(hjson.dumps(short_config_dict))
+    self.assertIn("devices", str(cm.exception))
+
+    self.platform.sh_results = [ADB_DEVICES_SINGLE_OUTPUT]
+    config_3 = BrowserConfig.parse_dict(short_config_dict)
+    assert isinstance(config_3, BrowserConfig)
+    self.assertEqual(config_3.driver.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config_1, config_3)
+
+  def test_parse_inline_hjson_short_string(self):
+    # We cannot easily configure the driver property from within the browser
+    # config property.
+    config_dict: JsonDict = {
+        "browser": "adb:chrome",
+    }
+    with self.assertRaises(argparse.ArgumentTypeError):
+      BrowserConfig.parse_dict(config_dict)
+
+  def test_parse_inline_driver_browser(self):
+    driver_path = pth.LocalPath("custom/chromedriver")
+    config_dict: JsonDict = {
+        "browser": "chrome",
+        "driver": str(driver_path),
+    }
+    with self.assertRaises(ValueError):
+      BrowserConfig.parse(hjson.dumps(config_dict))
+    self.fs.create_file(driver_path, st_size=100)
+    config = BrowserConfig.parse(hjson.dumps(config_dict))
+    assert isinstance(config, BrowserConfig)
+    self.assertEqual(config.browser,
+                     mock_browser.MockChromeStable.mock_app_path())
+    self.assertEqual(config.driver.type, BrowserDriverType.WEB_DRIVER)
+    self.assertEqual(config.driver.path, driver_path)
+
+  def test_parse_with_range_simple(self):
+    versions = BrowserConfig.parse_with_range("chrome-m100")
+    self.assertTupleEqual(versions, (BrowserConfig.parse("chrome-m100"),))
+
+  def test_parse_with_range(self):
+    result = (BrowserConfig.parse("chrome-m99"),
+              BrowserConfig.parse("chrome-m100"),
+              BrowserConfig.parse("chrome-m101"),
+              BrowserConfig.parse("chrome-m102"))
+    versions = BrowserConfig.parse_with_range("chrome-m99...chrome-m102")
+    self.assertTupleEqual(versions, result)
+    versions = BrowserConfig.parse_with_range("chrome-m99...m102")
+    self.assertTupleEqual(versions, result)
+    versions = BrowserConfig.parse_with_range("chrome-m99...102")
+    self.assertTupleEqual(versions, result)
+
+  def test_parse_with_range_invalid_empty(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse_with_range("")
+    self.assertIn("empty", str(cm.exception))
+
+  def test_parse_with_range_invalid_prefix(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse_with_range("chr-m100...chrome-m200")
+    msg = str(cm.exception)
+    self.assertIn("'chr-m'", msg)
+    self.assertIn("'chrome-m'", msg)
+
+  def test_parse_with_range_invalid_limit(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse_with_range("chr-m100...chr-m90")
+    msg = str(cm.exception).lower()
+    self.assertIn("larger", msg)
+    self.assertIn("chr-m100...chr-m90", msg)
+
+  def test_parse_with_range_missing_digits(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse_with_range("chr-m...chrome-m90")
+    msg = str(cm.exception).lower()
+    self.assertIn("start", msg)
+    self.assertIn("'chr-m'", msg)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserConfig.parse_with_range("chr-m100...chr")
+    msg = str(cm.exception).lower()
+    self.assertIn("limit", msg)
+    self.assertIn("'chr'", msg)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_browser_variants.py b/tests/crossbench/cli/config/test_browser_variants.py
new file mode 100644
index 0000000..f5d62a1
--- /dev/null
+++ b/tests/crossbench/cli/config/test_browser_variants.py
@@ -0,0 +1,1173 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import copy
+import json
+import unittest
+from typing import Dict, Tuple, Type
+from unittest import mock
+
+import hjson
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.cli.config.base import (ADB_DEVICES_SINGLE_OUTPUT,
+                                              BaseConfigTestCase)
+from tests.crossbench.mock_helper import AndroidAdbMockPlatform, MockAdb
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.browsers.chrome.applescript import ChromeAppleScript
+from crossbench.browsers.chrome.chrome import Chrome
+from crossbench.browsers.chrome.webdriver import (ChromeWebDriver,
+                                                  ChromeWebDriverAndroid,
+                                                  ChromeWebDriverChromeOsSsh,
+                                                  ChromeWebDriverSsh,
+                                                  LocalChromeWebDriverAndroid)
+from crossbench.browsers.chromium.applescript import ChromiumAppleScript
+from crossbench.browsers.chromium.webdriver import (ChromiumWebDriver,
+                                                    ChromiumWebDriverAndroid,
+                                                    ChromiumWebDriverSsh)
+from crossbench.browsers.safari.safari import Safari
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
+from crossbench.cli.config.network import NetworkConfig
+from crossbench.config import ConfigError
+
+
+class TestBrowserVariantsConfig(BaseConfigTestCase):
+  # pylint: disable=expression-not-assigned
+
+  EXAMPLE_CONFIG_PATH = test_helper.config_dir() / "doc/browser.config.hjson"
+
+  EXAMPLE_REMOTE_CONFIG_PATH = (
+      test_helper.config_dir() / "doc/remote_browser.config.hjson")
+
+  def setUp(self):
+    super().setUp()
+    self.browser_lookup: Dict[str, Tuple[
+        Type[mock_browser.MockBrowser], BrowserConfig]] = {
+            "chr-stable":
+                (mock_browser.MockChromeStable,
+                 BrowserConfig(mock_browser.MockChromeStable.mock_app_path())),
+            "chr-dev":
+                (mock_browser.MockChromeDev,
+                 BrowserConfig(mock_browser.MockChromeDev.mock_app_path())),
+            "chrome-stable":
+                (mock_browser.MockChromeStable,
+                 BrowserConfig(mock_browser.MockChromeStable.mock_app_path())),
+            "chrome-dev":
+                (mock_browser.MockChromeDev,
+                 BrowserConfig(mock_browser.MockChromeDev.mock_app_path())),
+        }
+    for _, (_, browser_config) in self.browser_lookup.items():
+      self.assertTrue(browser_config.path.exists())
+
+  def _expect_linux_ssh(self, cmd, **kwargs):
+    return self.platform.expect_sh("ssh", "-p", "22", "user@my-linux-machine",
+                                   cmd, **kwargs)
+
+  def _expect_chromeos_ssh(self, cmd, **kwargs):
+    return self.platform.expect_sh("ssh", "-p", "22",
+                                   "root@my-chromeos-machine", cmd, **kwargs)
+
+  def test_parse_browser_config_template(self):
+    if not self.EXAMPLE_CONFIG_PATH.exists():
+      raise unittest.SkipTest(
+          f"Test file {self.EXAMPLE_CONFIG_PATH} does not exist")
+    self.fs.add_real_file(self.EXAMPLE_CONFIG_PATH)
+    with self.EXAMPLE_CONFIG_PATH.open(encoding="utf-8") as f:
+      config = BrowserVariantsConfig(
+          browser_lookup_override=self.browser_lookup)
+      config.parse_text_io(f, args=self.mock_args)
+    self.assertIn("flag-group-1", config.flags_config)
+    self.assertGreaterEqual(len(config.flags_config), 1)
+    self.assertGreaterEqual(len(config.variants), 1)
+
+  def test_parse_remote_browser_config_template(self):
+    if not self.EXAMPLE_REMOTE_CONFIG_PATH.exists():
+      raise unittest.SkipTest(
+          f"Test file {self.EXAMPLE_REMOTE_CONFIG_PATH} does not exist")
+    self.fs.add_real_file(self.EXAMPLE_REMOTE_CONFIG_PATH)
+
+    self._expect_linux_ssh("uname -m", result="arm64")
+    self._expect_linux_ssh("'[' -e /path/to/google/chrome ']'")
+    self._expect_linux_ssh("'[' -f /path/to/google/chrome ']'")
+    self._expect_linux_ssh("'[' -e /path/to/google/chrome ']'")
+    self._expect_linux_ssh(
+        "/path/to/google/chrome --version", result="102.22.33.44")
+    self._expect_linux_ssh("env")
+    self._expect_linux_ssh("'[' -d /tmp ']'")
+    self._expect_linux_ssh("mktemp -d /tmp/chrome.XXXXXXXXXXX")
+
+    self._expect_chromeos_ssh("'[' -e /usr/local/autotest/bin/autologin.py ']'")
+    self._expect_chromeos_ssh("uname -m", result="arm64")
+    self._expect_chromeos_ssh("'[' -e /opt/google/chrome/chrome ']'")
+    self._expect_chromeos_ssh("'[' -f /opt/google/chrome/chrome ']'")
+    self._expect_chromeos_ssh("'[' -e /opt/google/chrome/chrome ']'")
+    self._expect_chromeos_ssh(
+        "/opt/google/chrome/chrome --version", result="125.0.6422.60")
+    self._expect_chromeos_ssh("env")
+    self._expect_chromeos_ssh("'[' -d /tmp ']'")
+    self._expect_chromeos_ssh("mktemp -d /tmp/chrome.XXXXXXXXXXX")
+
+    with self.EXAMPLE_REMOTE_CONFIG_PATH.open(encoding="utf-8") as f:
+      config = BrowserVariantsConfig()
+      config.parse_text_io(f, args=self.mock_args)
+      self.assertEqual(len(config.variants), 2)
+      for variant in config.variants:
+        self.assertTrue(variant.platform.is_remote)
+        self.assertTrue(variant.platform.is_linux)
+      self.assertEqual(config.variants[0].platform.name, "linux_ssh")
+      self.assertEqual(config.variants[1].platform.name, "chromeos_ssh")
+      self.assertEqual(config.variants[0].version, "102.22.33.44")
+      self.assertEqual(config.variants[1].version, "125.0.6422.60")
+
+  def test_browser_labels_attributes(self):
+    browsers = BrowserVariantsConfig(
+        {
+            "browsers": {
+                "chrome-stable-default": {
+                    "path": "chrome-stable",
+                },
+                "chrome-stable-noopt": {
+                    "path": "chrome-stable",
+                    "flags": ["--js-flags=--max-opt=0",]
+                },
+                "chrome-stable-custom": {
+                    "label": "custom-label-property",
+                    "path": "chrome-stable",
+                    "flags": ["--js-flags=--max-opt=0",]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args).variants
+    self.assertEqual(len(browsers), 3)
+    self.assertEqual(browsers[0].label, "chrome-stable-default")
+    self.assertEqual(browsers[1].label, "chrome-stable-noopt")
+    self.assertEqual(browsers[2].label, "custom-label-property")
+
+  def test_browser_label_args(self):
+    self.platform.sh_results = [ADB_DEVICES_SINGLE_OUTPUT]
+    args = self.mock_args
+    adb_config = BrowserConfig.parse("adb:chrome")
+    desktop_config = BrowserConfig.parse("chrome")
+    args.browser = [
+        adb_config,
+        desktop_config,
+    ]
+    self.assertFalse(self.platform.sh_results)
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT,
+        ADB_DEVICES_SINGLE_OUTPUT,
+    ]
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      if browser_config is adb_config:
+        return mock_browser.MockChromeAndroidStable
+      if browser_config is desktop_config:
+        return mock_browser.MockChromeStable
+      raise ValueError("Unknown browser_config")
+
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        side_effect=mock_get_browser_cls), mock.patch(
+            "crossbench.plt.android_adb.AndroidAdbPlatform.machine",
+            new_callable=mock.PropertyMock,
+            return_value=plt.MachineArch.ARM_64):
+      browsers = BrowserVariantsConfig.from_cli_args(args).variants
+    self.assertEqual(len(browsers), 2)
+    self.assertEqual(browsers[0].label, "android.arm64.remote_0")
+    self.assertEqual(browsers[1].label, f"{self.platform}_1")
+
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "browsers": {
+                  "chrome-stable-label": {
+                      "path": "chrome-stable",
+                  },
+                  "chrome-stable-custom": {
+                      "label": "chrome-stable-label",
+                      "path": "chrome-stable",
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args).variants
+    message = str(cm.exception)
+    self.assertIn("chrome-stable-label", message)
+    self.assertIn("chrome-stable-custom", message)
+
+  def test_parse_invalid_browser_type(self):
+    for invalid in (None, 1, []):
+      with self.assertRaises(ConfigError) as cm:
+        _ = BrowserVariantsConfig(
+            {
+                "browsers": {
+                    "chrome-stable-default": invalid
+                }
+            },
+            args=self.mock_args).variants
+      self.assertIn("Expected str or dict", str(cm.exception))
+
+  def test_browser_custom_driver_variants(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT,
+        ADB_DEVICES_SINGLE_OUTPUT, ADB_DEVICES_SINGLE_OUTPUT
+    ]
+
+    def mock_get_browser_platform(
+        browser_config: BrowserConfig) -> plt.Platform:
+      if browser_config.driver.type == BrowserDriverType.ANDROID:
+        return AndroidAdbMockPlatform(self.platform, adb=MockAdb(self.platform))
+      return self.platform
+
+    with self.mock_chrome_stable(
+        mock_browser.MockChromeAndroidStable), mock.patch.object(
+            BrowserVariantsConfig,
+            "_get_browser_platform",
+            side_effect=mock_get_browser_platform):
+      browsers = BrowserVariantsConfig(
+          {
+              "browsers": {
+                  "chrome-stable-default": "chrome-stable",
+                  "chrome-stable-adb": "adb:chrome",
+                  "chrome-stable-adb2": {
+                      "path": "chrome",
+                      "driver": "adb"
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args).variants
+    self.assertEqual(len(browsers), 3)
+    self.assertEqual(browsers[0].label, "chrome-stable-default")
+    self.assertEqual(browsers[1].label, "chrome-stable-adb")
+    self.assertEqual(browsers[2].label, "chrome-stable-adb2")
+    self.assertIsInstance(browsers[0], mock_browser.MockChromeStable)
+    self.assertIsInstance(browsers[1], mock_browser.MockChromeAndroidStable)
+    self.assertIsInstance(browsers[2], mock_browser.MockChromeAndroidStable)
+
+  def test_flag_combination_invalid(self):
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {
+                      "invalid-flag-name": [None, "", "v1"],
+                  },
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": ["group1",]
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args).variants
+    message = str(cm.exception)
+    self.assertIn("group1", message)
+    self.assertIn("invalid-flag-name", message)
+
+  def test_flag_combination_none(self):
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {
+                      "--foo": ["None,", "", "v1"],
+                  },
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": ["group1"]
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args).variants
+    self.assertIn("None", str(cm.exception))
+
+  def test_flag_combination_duplicate(self):
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {
+                      "--duplicate-flag": [None, "", "v1"],
+                  },
+                  "group2": {
+                      "--duplicate-flag": [None, "", "v1"],
+                  }
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": ["group1", "group2"]
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args).variants
+    self.assertIn("--duplicate-flag", str(cm.exception))
+
+  def test_empty(self):
+    with self.assertRaises(ConfigError):
+      BrowserVariantsConfig({"other": {}}, args=self.mock_args).variants
+    with self.assertRaises(ConfigError):
+      BrowserVariantsConfig({"browsers": {}}, args=self.mock_args).variants
+
+  def test_unknown_group(self):
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": ["unknown-flag-group"]
+                  }
+              }
+          },
+          args=self.mock_args).variants
+    self.assertIn("unknown-flag-group", str(cm.exception))
+
+  def test_duplicate_group(self):
+    with self.assertRaises(ConfigError):
+      BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {}
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": ["group1", "group1"]
+                  }
+              }
+          },
+          args=self.mock_args).variants
+
+  def test_non_list_group(self):
+    BrowserVariantsConfig(
+        {
+            "flags": {
+                "group1": {}
+            },
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                    "flags": "group1"
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args).variants
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {}
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": 1
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args).variants
+    self.assertIn("chrome-stable", str(cm.exception))
+    self.assertIn("flags", str(cm.exception))
+
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {}
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": {
+                          "group1": True
+                      }
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args).variants
+    self.assertIn("chrome-stable", str(cm.exception))
+    self.assertIn("flags", str(cm.exception))
+
+  def test_duplicate_flag_variant_value(self):
+    with self.assertRaises(ConfigError) as cm:
+      BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {
+                      "--flag": ["repeated", "repeated"]
+                  }
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": "group1",
+                  }
+              }
+          },
+          args=self.mock_args).variants
+    self.assertIn("group1", str(cm.exception))
+    self.assertIn("--flag", str(cm.exception))
+
+  def test_unknown_path(self):
+    with self.assertRaises(Exception):
+      BrowserVariantsConfig(
+          {
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "path/does/not/exist",
+                  }
+              }
+          },
+          args=self.mock_args).variants
+    with self.assertRaises(Exception):
+      BrowserVariantsConfig(
+          {
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-unknown",
+                  }
+              }
+          },
+          args=self.mock_args).variants
+
+  def test_flag_combination_simple(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "group1": {
+                    "--foo": [None, "", "v1"],
+                }
+            },
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                    "flags": ["group1"]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    browsers = config.variants
+    self.assertEqual(len(browsers), 3)
+    for browser in browsers:
+      assert isinstance(browser, mock_browser.MockChromeStable)
+      self.assertDictEqual(browser.js_flags.to_dict(), {})
+    self.assertDictEqual(browsers[0].flags.to_dict(), {})
+    self.assertDictEqual(browsers[1].flags.to_dict(), {"--foo": None})
+    self.assertDictEqual(browsers[2].flags.to_dict(), {"--foo": "v1"})
+
+  def test_flag_list(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "group1": [
+                    "",
+                    "--foo",
+                    "-foo=v1",
+                ]
+            },
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                    "flags": ["group1"]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    browsers = config.variants
+    self.assertEqual(len(browsers), 3)
+    for browser in browsers:
+      assert isinstance(browser, mock_browser.MockChromeStable)
+      self.assertDictEqual(browser.js_flags.to_dict(), {})
+    self.assertDictEqual(browsers[0].flags.to_dict(), {})
+    self.assertDictEqual(browsers[1].flags.to_dict(), {"--foo": None})
+    self.assertDictEqual(browsers[2].flags.to_dict(), {"-foo": "v1"})
+
+  def test_flag_combination(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "group1": {
+                    "--foo": [None, "", "v1"],
+                    "--bar": [None, "", "v1"],
+                }
+            },
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                    "flags": ["group1"]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    self.assertEqual(len(config.variants), 3 * 3)
+
+  def test_flag_combination_mixed_inline(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "compile-hints-experiment": {
+                    "--enable-features": [None, "ConsumeCompileHints"]
+                }
+            },
+            "browsers": {
+                "chrome-release": {
+                    "path": "chrome-stable",
+                    "flags": ["--no-sandbox", "compile-hints-experiment"]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    browsers = config.variants
+    self.assertEqual(len(browsers), 2)
+    self.assertListEqual(["--no-sandbox"], list(browsers[0].flags))
+    self.assertListEqual(
+        ["--no-sandbox", "--enable-features=ConsumeCompileHints"],
+        list(browsers[1].flags))
+
+  def test_flag_single_inline(self):
+    config = BrowserVariantsConfig(
+        {
+            "browsers": {
+                "chrome-release": {
+                    "path": "chrome-stable",
+                    "flags": "--no-sandbox",
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    browsers = config.variants
+    self.assertEqual(len(browsers), 1)
+    self.assertListEqual(["--no-sandbox"], list(browsers[0].flags))
+
+  def test_flag_combination_mixed_fixed(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "compile-hints-experiment": {
+                    "--no-sandbox": "",
+                    "--enable-features": [None, "ConsumeCompileHints"]
+                }
+            },
+            "browsers": {
+                "chrome-release": {
+                    "path": "chrome-stable",
+                    "flags": "compile-hints-experiment"
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    browsers = config.variants
+    self.assertEqual(len(browsers), 2)
+    self.assertListEqual(["--no-sandbox"], list(browsers[0].flags))
+    self.assertListEqual(
+        ["--no-sandbox", "--enable-features=ConsumeCompileHints"],
+        list(browsers[1].flags))
+
+  def test_conflicting_chrome_features(self):
+    with self.assertRaises(ConfigError) as cm:
+      _ = BrowserVariantsConfig(
+          {
+              "flags": {
+                  "compile-hints-experiment": {
+                      "--enable-features": [None, "ConsumeCompileHints"]
+                  }
+              },
+              "browsers": {
+                  "chrome-release": {
+                      "path":
+                          "chrome-stable",
+                      "flags": [
+                          "--disable-features=ConsumeCompileHints",
+                          "compile-hints-experiment"
+                      ]
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args)
+    msg = str(cm.exception)
+    self.assertIn("ConsumeCompileHints", msg)
+
+  def test_no_flags(self):
+    config = BrowserVariantsConfig(
+        {
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                },
+                "chrome-dev": {
+                    "path": "chrome-dev",
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    self.assertEqual(len(config.variants), 2)
+    browser_0 = config.variants[0]
+    assert isinstance(browser_0, mock_browser.MockChromeStable)
+    self.assertEqual(browser_0.app_path,
+                     mock_browser.MockChromeStable.mock_app_path())
+    browser_1 = config.variants[1]
+    assert isinstance(browser_1, mock_browser.MockChromeDev)
+    self.assertEqual(browser_1.app_path,
+                     mock_browser.MockChromeDev.mock_app_path())
+
+  def test_custom_driver(self):
+    chromedriver = pth.LocalPath("path/to/chromedriver")
+    variants_config = {
+        "browsers": {
+            "chrome-stable": {
+                "browser": "chrome-stable",
+                "driver": str(chromedriver),
+            }
+        }
+    }
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      BrowserVariantsConfig(
+          copy.deepcopy(variants_config),
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args)
+    self.assertIn(str(chromedriver), str(cm.exception))
+
+    self.fs.create_file(chromedriver, st_size=100)
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        return_value=mock_browser.MockChromeStable):
+      config = BrowserVariantsConfig(
+          variants_config,
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args)
+    self.assertTrue(variants_config["browsers"]["chrome-stable"])
+    self.assertEqual(len(config.variants), 1)
+    browser_0 = config.variants[0]
+    assert isinstance(browser_0, mock_browser.MockChromeStable)
+    self.assertEqual(browser_0.app_path,
+                     mock_browser.MockChromeStable.mock_app_path())
+
+  def test_inline_flags(self):
+    with mock.patch.object(
+        ChromeWebDriver, "_extract_version",
+        return_value="101.22.333.44"), mock.patch.object(
+            Chrome,
+            "stable_path",
+            return_value=mock_browser.MockChromeStable.mock_app_path()):
+
+      config = BrowserVariantsConfig(
+          {
+              "browsers": {
+                  "stable": {
+                      "path": "chrome-stable",
+                      "flags": ["--foo=bar"]
+                  }
+              }
+          },
+          args=self.mock_args)
+      self.assertEqual(len(config.variants), 1)
+      browser = config.variants[0]
+      # TODO: Fix once app lookup is cleaned up
+      self.assertEqual(browser.app_path,
+                       mock_browser.MockChromeStable.mock_app_path())
+      self.assertEqual(browser.version, "101.22.333.44")
+      self.assertEqual(browser.flags["--foo"], "bar")
+
+  def test_inline_load_safari(self):
+    if not plt.PLATFORM.is_macos:
+      return
+    with mock.patch.object(Safari, "_extract_version", return_value="16.0"):
+      config = BrowserVariantsConfig(
+          {"browsers": {
+              "safari": {
+                  "path": "safari",
+              }
+          }}, args=self.mock_args)
+      self.assertEqual(len(config.variants), 1)
+
+  def test_flag_combination_with_fixed(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "group1": {
+                    "--foo": [None, "", "v1"],
+                    "--bar": [None, "", "w1"],
+                    "--always_1": "true",
+                    "--always_2": "true",
+                    "--always_3": "true",
+                }
+            },
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                    "flags": ["group1"]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    self.assertEqual(len(config.variants), 3 * 3)
+    for browser in config.variants:
+      assert isinstance(browser, mock_browser.MockChromeStable)
+      self.assertEqual(browser.app_path,
+                       mock_browser.MockChromeStable.mock_app_path())
+      expected_flags = (
+          "--always_1=true --always_2=true --always_3=true",
+          "--bar --always_1=true --always_2=true --always_3=true",
+          "--bar=w1 --always_1=true --always_2=true --always_3=true",
+          "--foo --always_1=true --always_2=true --always_3=true",
+          "--foo --bar --always_1=true --always_2=true --always_3=true",
+          "--foo --bar=w1 --always_1=true --always_2=true --always_3=true",
+          "--foo=v1 --always_1=true --always_2=true --always_3=true",
+          "--foo=v1 --bar --always_1=true --always_2=true --always_3=true",
+          "--foo=v1 --bar=w1 --always_1=true --always_2=true --always_3=true",
+      )
+    self.verify_variant_flags(config.variants, expected_flags)
+
+  def verify_variant_flags(self, variants, expected_flags):
+    self.assertEqual(len(variants), len(expected_flags))
+    for index, browser in enumerate(variants):
+      self.assertEqual(
+          str(browser.flags), expected_flags[index],
+          f"Unexpected flags for variant[{index}]")
+
+  def test_flag_combination_js_flags_with_fixed(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "group1": {
+                    "--js-flags": [
+                        None, "--max-opt=1,--trace-ic", "--max-opt=2 --log-all"
+                    ],
+                },
+                "group2": {
+                    "default": "--bar=v1 --foo=w2"
+                }
+            },
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                    "flags": ["group1", "group2"]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    self.assertEqual(len(config.variants), 3)
+    for browser in config.variants:
+      assert isinstance(browser, mock_browser.MockChromeStable)
+      self.assertEqual(browser.app_path,
+                       mock_browser.MockChromeStable.mock_app_path())
+    expected_flags = (
+        "--bar=v1 --foo=w2",
+        "--bar=v1 --foo=w2 --js-flags=--max-opt=1,--trace-ic",
+        "--bar=v1 --foo=w2 --js-flags=--max-opt=2,--log-all",
+    )
+    self.verify_variant_flags(config.variants, expected_flags)
+
+  def test_flag_combination_js_flags_combinations_invalid(self):
+    with self.assertRaises(ConfigError) as cm:
+      _ = BrowserVariantsConfig(
+          {
+              "flags": {
+                  "group1": {
+                      "--js-flags": [
+                          None, "--max-opt=2,--trace-ic",
+                          "--max-opt=3 --log-all"
+                      ],
+                  },
+                  "group2": {
+                      "default": "--js-flags=--no-sparkplug"
+                  }
+              },
+              "browsers": {
+                  "chrome-stable": {
+                      "path": "chrome-stable",
+                      "flags": ["group1", "group2"]
+                  }
+              }
+          },
+          browser_lookup_override=self.browser_lookup,
+          args=self.mock_args)
+    self.assertIn("--js-flags", str(cm.exception))
+
+  def test_flag_group_combination(self):
+    config = BrowserVariantsConfig(
+        {
+            "flags": {
+                "group1": {
+                    "--foo": [None, "", "v1"],
+                },
+                "group2": {
+                    "--bar": [None, "", "w1"],
+                },
+                "group3": {
+                    "--other": ["x1", "x2"],
+                }
+            },
+            "browsers": {
+                "chrome-stable": {
+                    "path": "chrome-stable",
+                    "flags": ["group1", "group2", "group3"]
+                }
+            }
+        },
+        browser_lookup_override=self.browser_lookup,
+        args=self.mock_args)
+    self.assertEqual(len(config.variants), 3 * 3 * 2)
+    expected_flags = (
+        "--other=x1",
+        "--other=x2",
+        "--bar --other=x1",
+        "--bar --other=x2",
+        "--bar=w1 --other=x1",
+        "--bar=w1 --other=x2",
+        "--foo --other=x1",
+        "--foo --other=x2",
+        "--foo --bar --other=x1",
+        "--foo --bar --other=x2",
+        "--foo --bar=w1 --other=x1",
+        "--foo --bar=w1 --other=x2",
+        "--foo=v1 --other=x1",
+        "--foo=v1 --other=x2",
+        "--foo=v1 --bar --other=x1",
+        "--foo=v1 --bar --other=x2",
+        "--foo=v1 --bar=w1 --other=x1",
+        "--foo=v1 --bar=w1 --other=x2",
+    )
+    self.verify_variant_flags(config.variants, expected_flags)
+
+  def test_from_cli_args_browser_config(self):
+    if self.platform.is_win:
+      self.skipTest("No auto-download available on windows")
+    browser_cls = mock_browser.MockChromeStable
+    # TODO: migrate to with_stem once python 3.9 is available everywhere
+    suffix = browser_cls.mock_app_path().suffix
+    browser_bin = browser_cls.mock_app_path().with_name(
+        f"Custom Google Chrome{suffix}")
+    browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
+    config_data = {"browsers": {"chrome-stable": {"path": str(browser_bin),}}}
+    config_file = pth.LocalPath("config.hjson")
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=None,
+        browser_config=config_file,
+        driver_path=None)
+    with mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    self.assertEqual(len(config.variants), 1)
+    browser = config.variants[0]
+    self.assertIsInstance(browser, browser_cls)
+    self.assertEqual(browser.app_path, browser_bin)
+
+  def test_from_cli_args_browser(self):
+    if self.platform.is_win:
+      self.skipTest("No auto-download available on windows")
+    browser_cls = mock_browser.MockChromeStable
+    # TODO: migrate to with_stem once python 3.9 is available everywhere
+    suffix = browser_cls.mock_app_path().suffix
+    browser_bin = browser_cls.mock_app_path().with_name(
+        f"Custom Google Chrome{suffix}")
+    browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=[
+            BrowserConfig(browser_bin),
+        ],
+        browser_config=None,
+        enable_features=None,
+        disable_features=None,
+        driver_path=None,
+        js_flags=None,
+        other_browser_args=[])
+    with mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    self.assertEqual(len(config.variants), 1)
+    browser = config.variants[0]
+    self.assertIsInstance(browser, browser_cls)
+    self.assertEqual(browser.app_path, browser_bin)
+
+  def test_from_cli_args_browser_additional_flags(self):
+    browser_cls = mock_browser.MockChromeStable
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=[
+            BrowserConfig.parse_str("chrome"),
+        ],
+        browser_config=None,
+        driver_path=None,
+        enable_features="feature_on",
+        disable_features="feature_off",
+        js_flags=None,
+        other_browser_args=["--no-sandbox", "--enable-logging=stderr"])
+    with mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    self.assertEqual(len(config.variants), 1)
+    browser = config.variants[0]
+    self.assertIsInstance(browser, browser_cls)
+    self.assertFalse(browser.js_flags)
+    self.assertEqual(browser.flags["--enable-features"], "feature_on")
+    self.assertEqual(browser.flags["--disable-features"], "feature_off")
+    self.assertIn("--no-sandbox", browser.flags)
+    self.assertEqual(browser.flags["--enable-logging"], "stderr")
+
+  def test_from_cli_args_browser_js_flags(self):
+    browser_cls = mock_browser.MockChromeStable
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=[
+            BrowserConfig.parse_str("chrome"),
+        ],
+        browser_config=None,
+        driver_path=None,
+        enable_features=None,
+        disable_features=None,
+        js_flags=["--max-opt=1"],
+        other_browser_args=[])
+    with mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    self.assertEqual(len(config.variants), 1)
+    browser = config.variants[0]
+    self.assertIsInstance(browser, browser_cls)
+    self.assertEqual(browser.js_flags.to_dict(), {"--max-opt": "1"})
+
+  def test_from_cli_args_browser_extra_browser_js_flags(self):
+    browser_cls = mock_browser.MockChromeStable
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=[
+            BrowserConfig.parse_str("chrome"),
+        ],
+        browser_config=None,
+        driver_path=None,
+        enable_features=None,
+        disable_features=None,
+        js_flags=[],
+        other_browser_args=["--js-flags=--max-opt=1,--log-all"])
+    with mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    self.assertEqual(len(config.variants), 1)
+    browser = config.variants[0]
+    self.assertIsInstance(browser, browser_cls)
+    self.assertEqual(browser.js_flags.to_dict(), {
+        "--max-opt": "1",
+        "--log-all": None
+    })
+
+  def test_from_cli_args_browser_multiple_js_flags(self):
+    browser_cls = mock_browser.MockChromeStable
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=[
+            BrowserConfig.parse_str("chrome"),
+        ],
+        browser_config=None,
+        driver_path=None,
+        enable_features="feature_on",
+        disable_features="feature_off",
+        js_flags=["--max-opt=1", "--max-opt=2,--log-all"],
+        other_browser_args=["--no-sandbox", "--enable-logging=stderr"])
+    with mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    self.assertEqual(len(config.variants), 2)
+    browser_0 = config.variants[0]
+    self.assertIsInstance(browser_0, browser_cls)
+    self.assertEqual(browser_0.js_flags.to_dict(), {"--max-opt": "1"})
+    browser_1 = config.variants[1]
+    self.assertIsInstance(browser_1, browser_cls)
+    self.assertEqual(browser_1.js_flags.to_dict(), {
+        "--max-opt": "2",
+        "--log-all": None
+    })
+
+    for browser in config.variants:
+      self.assertEqual(browser.flags["--enable-features"], "feature_on")
+      self.assertEqual(browser.flags["--disable-features"], "feature_off")
+      self.assertIn("--no-sandbox", browser.flags)
+      self.assertEqual(browser.flags["--enable-logging"], "stderr")
+
+  def test_from_cli_args_browser_config_network_override(self):
+    ts_proxy_path = pth.LocalPath("/tsproxy/tsproxy.py")
+    self.fs.create_file(ts_proxy_path, st_size=100)
+    browser_config_dict = {
+        "browsers": {
+            "default-network": {
+                "path": "chrome-stable",
+                "network": "default"
+            },
+            "default": "chrome-stable",
+            "custom-network": {
+                "path": "chrome-stable",
+                "network": "4G"
+            }
+        }
+    }
+    config_file = pth.LocalPath("browsers.config.json")
+    with config_file.open("w", encoding="utf-8") as f:
+      json.dump(browser_config_dict, f)
+    network_3g = NetworkConfig.parse("3G-slow")
+    network_4g = NetworkConfig.parse("4G")
+    self.assertNotEqual(network_3g.speed.in_kbps, network_4g.speed.in_kbps)
+    args = mock.Mock(
+        browser=None,
+        browser_config=config_file,
+        network=network_3g,
+        enable_features=None,
+        disable_features=None,
+        driver_path=None,
+        js_flags=None,
+        other_browser_args=[])
+
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        return_value=mock_browser.MockChromeStable
+    ), mock.patch(
+        "crossbench.network.traffic_shaping.ts_proxy.TsProxyFinder") as finder:
+      finder.return_value = mock.Mock(path=ts_proxy_path)
+      config = BrowserVariantsConfig.from_cli_args(args,)
+    self.assertEqual(len(config.variants), 3)
+    browser_1, browser_2, browser_3 = config.variants  # pylint: disable=unbalanced-tuple-unpacking
+    # Browser 1 provides an explicit default override:
+    self.assertTrue(browser_1.network.is_live)
+    self.assertTrue(browser_1.network.traffic_shaper.is_live)
+    # Browser 2: uses the default --network:
+    self.assertTrue(browser_2.network.is_live)
+    self.assertFalse(browser_2.network.traffic_shaper.is_live)
+    self.assertEqual(browser_2.network.traffic_shaper.ts_proxy.in_kbps,
+                     network_3g.speed.in_kbps)
+    # Browser 3; Uses an explicit 4G override:
+    self.assertTrue(browser_3.network.is_live)
+    self.assertFalse(browser_3.network.traffic_shaper.is_live)
+    self.assertEqual(browser_3.network.traffic_shaper.ts_proxy.in_kbps,
+                     network_4g.speed.in_kbps)
+
+  def test_get_browser_cls_unsupported(self):
+    variants = BrowserVariantsConfig()
+    with self.assertRaisesRegex(argparse.ArgumentTypeError,
+                                "Unsupported browser"):
+      config = BrowserConfig(browser=pth.AnyPath("your/custom/browser.exe"))
+      variants.get_browser_cls(config)
+
+  def test_get_browser_cls_chrome_default(self):
+    variants = BrowserVariantsConfig()
+    config = BrowserConfig(browser=pth.AnyPath("Chrome.app"))
+    self.assertIs(variants.get_browser_cls(config), ChromeWebDriver)
+    config = BrowserConfig(browser=pth.AnyPath("Chrome.exe"))
+    self.assertIs(variants.get_browser_cls(config), ChromeWebDriver)
+
+  def test_get_browser_cls_chromium_default(self):
+    variants = BrowserVariantsConfig()
+    config = BrowserConfig(browser=pth.AnyPath("Chromium.app"))
+    self.assertIs(variants.get_browser_cls(config), ChromiumWebDriver)
+    config = BrowserConfig(browser=pth.AnyPath("Chromium.exe"))
+    self.assertIs(variants.get_browser_cls(config), ChromiumWebDriver)
+
+  def test_get_browser_cls_chrome_driver_types(self):
+    variants = BrowserVariantsConfig()
+    expected_classes = (
+        (BrowserDriverType.APPLE_SCRIPT, ChromeAppleScript),
+        (BrowserDriverType.WEB_DRIVER, ChromeWebDriver),
+        (BrowserDriverType.LINUX_SSH, ChromeWebDriverSsh),
+    )
+    for driver_type, browser_cls in expected_classes:
+      config = BrowserConfig(
+          browser=pth.AnyPath("Chrome.bin"),
+          driver=DriverConfig(type=driver_type))
+      self.assertIs(variants.get_browser_cls(config), browser_cls)
+
+  def test_get_browser_cls_chromium_driver_types(self):
+    variants = BrowserVariantsConfig()
+    expected_classes = (
+        (BrowserDriverType.APPLE_SCRIPT, ChromiumAppleScript),
+        (BrowserDriverType.WEB_DRIVER, ChromiumWebDriver),
+        (BrowserDriverType.LINUX_SSH, ChromiumWebDriverSsh),
+    )
+    for driver_type, browser_cls in expected_classes:
+      config = BrowserConfig(
+          browser=pth.AnyPath("Chromium.bin"),
+          driver=DriverConfig(type=driver_type))
+      self.assertIs(variants.get_browser_cls(config), browser_cls)
+
+  def test_get_browser_cls_chromium_android_default(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT,
+    ]
+    variants = BrowserVariantsConfig()
+    config = BrowserConfig(
+        browser=pth.AnyPath("chromium.apk"),
+        driver=DriverConfig(type=BrowserDriverType.ANDROID))
+    self.assertIs(variants.get_browser_cls(config), ChromiumWebDriverAndroid)
+
+  def test_get_browser_cls_chrome_android_default(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT,
+    ]
+    variants = BrowserVariantsConfig()
+    config = BrowserConfig(
+        browser=pth.AnyPath("chrome.apk"),
+        driver=DriverConfig(type=BrowserDriverType.ANDROID))
+    self.assertIs(variants.get_browser_cls(config), ChromeWebDriverAndroid)
+
+  def test_get_browser_cls_chrome_android_local_helper(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_SINGLE_OUTPUT,
+    ]
+    variants = BrowserVariantsConfig()
+    apk_helper = pth.AnyPath("/home/user/Documents/chrome/src/"
+                             "out/arm64.apk/bin/chrome_public_apk")
+    config = BrowserConfig(
+        browser=apk_helper, driver=DriverConfig(type=BrowserDriverType.ANDROID))
+    self.assertIs(variants.get_browser_cls(config), LocalChromeWebDriverAndroid)
+
+  def test_get_browser_cls_chromium_android_local_helper(self):
+    """Currently there is no nice way to distinguish a local build between
+    chrome/chromium."""
+
+  def test_get_browser_cls_chromeos_ssh_default(self):
+    self.platform.sh_results = []
+    variants = BrowserVariantsConfig()
+    with mock.patch.object(
+        DriverConfig, "validate_chromeos", return_value=None) as mock_method:
+      driver = DriverConfig(type=BrowserDriverType.CHROMEOS_SSH)
+    mock_method.assert_called_once()
+    config = BrowserConfig(browser=pth.AnyPath("chrome"), driver=driver)
+    self.assertIs(variants.get_browser_cls(config), ChromeWebDriverChromeOsSsh)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_driver.py b/tests/crossbench/cli/config/test_driver.py
new file mode 100644
index 0000000..6930feb
--- /dev/null
+++ b/tests/crossbench/cli/config/test_driver.py
@@ -0,0 +1,251 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import unittest
+
+import hjson
+
+from crossbench import plt
+from crossbench.cli.config.driver import (AmbiguousDriverIdentifier,
+                                          BrowserDriverType, DriverConfig)
+from crossbench.exception import ArgumentTypeMultiException
+from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
+from tests import test_helper
+from tests.crossbench.cli.config.base import (ADB_DEVICES_OUTPUT,
+                                              XCTRACE_DEVICES_SINGLE_OUTPUT,
+                                              BaseConfigTestCase)
+
+
+class BrowserDriverTypeTestCase(unittest.TestCase):
+
+  def test_default(self):
+    self.assertEqual(BrowserDriverType.default(), BrowserDriverType.WEB_DRIVER)
+
+  def test_parse_invalid(self):
+    for invalid in ["invalid", None, [], (), {}]:
+      with self.assertRaises(argparse.ArgumentTypeError):
+        BrowserDriverType.parse(invalid)
+
+  def test_parse_str(self):
+    test_data = {
+        "": BrowserDriverType.default(),
+        "selenium": BrowserDriverType.WEB_DRIVER,
+        "webdriver": BrowserDriverType.WEB_DRIVER,
+        "applescript": BrowserDriverType.APPLE_SCRIPT,
+        "osa": BrowserDriverType.APPLE_SCRIPT,
+        "android": BrowserDriverType.ANDROID,
+        "adb": BrowserDriverType.ANDROID,
+        "iphone": BrowserDriverType.IOS,
+        "ios": BrowserDriverType.IOS,
+        "ssh": BrowserDriverType.LINUX_SSH,
+        "chromeos-ssh": BrowserDriverType.CHROMEOS_SSH,
+    }
+    for value, result in test_data.items():
+      self.assertEqual(BrowserDriverType.parse(value), result)
+
+  def test_parse_enum(self):
+    for driver_type in BrowserDriverType:
+      self.assertEqual(BrowserDriverType.parse(driver_type), driver_type)
+
+
+class DriverConfigTestCase(BaseConfigTestCase):
+
+  def test_default(self):
+    default = DriverConfig.default()
+    self.assertEqual(default.type, BrowserDriverType.WEB_DRIVER)
+    self.assertTrue(default.is_local)
+    self.assertFalse(default.is_remote)
+
+  def test_parse_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = DriverConfig.parse("")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = DriverConfig.parse(":")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = DriverConfig.parse("{:}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = DriverConfig.parse("}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = DriverConfig.parse("{")
+
+  def test_parse_driver_path_invalid(self):
+    driver_path = self.out_dir / "driver"
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = DriverConfig.parse(str(driver_path))
+    self.assertIn(str(driver_path), str(cm.exception))
+
+    self.fs.create_file(driver_path)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = DriverConfig.parse(str(driver_path))
+    message = str(cm.exception)
+    self.assertIn(str(driver_path), message)
+    self.assertIn("empty", message)
+
+  def test_parse_driver_path(self):
+    chromedriver_path = self.out_dir / "chromedriver"
+    self.fs.create_file(chromedriver_path, st_size=100)
+    driver = DriverConfig.parse(str(chromedriver_path))
+    self.assertEqual(driver.path, chromedriver_path)
+
+    config = {"path": str(chromedriver_path)}
+    driver_2 = DriverConfig.parse(config)
+    self.assertEqual(driver_2.path, chromedriver_path)
+    self.assertEqual(driver, driver_2)
+
+  def test_parse_dict_device_id_conflict(self):
+    self.platform.sh_results = []
+    config_dict = {
+        "type": "adb",
+        "device_id": "1234",
+        "settings": {
+            "device_id": "ABCD"
+        }
+    }
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DriverConfig.parse(config_dict)
+    self.assertIn("1234", str(cm.exception))
+    self.assertIn("ABCD", str(cm.exception))
+
+  def test_parse_dict_chromeos_ssh(self):
+    config_dict = {
+        "type": "chromeos-ssh",
+        "settings": {
+            "host": "chromeos6-row17-rack14-host7",
+            "port": "9515",
+            "ssh_port": "22",
+            "ssh_user": "root"
+        }
+    }
+    ssh_user = config_dict["settings"]["ssh_user"]
+    ssh_host = config_dict["settings"]["host"]
+    self.platform.expect_sh("ssh", "-p", config_dict["settings"]["ssh_port"],
+                            f"{ssh_user}@{ssh_host}",
+                            f"'[' -e {ChromeOsSshPlatform.AUTOLOGIN_PATH} ']'")
+    config = DriverConfig.parse(config_dict)
+    assert isinstance(config, DriverConfig)
+    self.assertEqual(config.type, BrowserDriverType.CHROMEOS_SSH)
+    self.assertTrue(config.is_remote)
+    self.assertFalse(config.is_local)
+    platform = config.get_platform()
+    assert isinstance(platform, ChromeOsSshPlatform)
+    self.assertEqual(platform.host, "chromeos6-row17-rack14-host7")
+    self.assertEqual(platform.port, 9515)
+    self.assertEqual(platform.ssh_port, 22)
+    self.assertEqual(platform.ssh_user, "root")
+
+  def test_parse_inline_json_adb(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    config_dict = {"type": "adb", "settings": {"device_id": "0a388e93"}}
+    config_1 = DriverConfig.parse(hjson.dumps(config_dict))
+    assert isinstance(config_1, DriverConfig)
+    self.assertEqual(config_1.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config_1.device_id, "0a388e93")
+    self.assertEqual(config_1.settings["device_id"], "0a388e93")
+    self.assertTrue(config_1.is_remote)
+    self.assertFalse(config_1.is_local)
+    self.assertIsNone(config_1.adb_bin)
+
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    config_2 = DriverConfig.parse_dict(config_dict)
+    assert isinstance(config_2, DriverConfig)
+    self.assertEqual(config_2.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config_2.device_id, "0a388e93")
+    self.assertEqual(config_2.settings["device_id"], "0a388e93")
+    self.assertTrue(config_2.is_remote)
+    self.assertFalse(config_2.is_local)
+    self.assertIsNone(config_2.adb_bin)
+    self.assertEqual(config_1, config_2)
+
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    config_dict = {"type": "adb", "device_id": "0a388e93"}
+    config_3 = DriverConfig.parse_dict(config_dict)
+    assert isinstance(config_3, DriverConfig)
+    self.assertEqual(config_3.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config_3.device_id, "0a388e93")
+    self.assertTrue(config_3.is_remote)
+    self.assertFalse(config_3.is_local)
+    self.assertIsNone(config_3.settings)
+    self.assertIsNone(config_2.adb_bin)
+    self.assertNotEqual(config_1, config_3)
+    self.assertNotEqual(config_2, config_3)
+
+  def test_parse_custom_adb_bin(self):
+    adb_bin = self.out_dir / "adb"
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    config_dict = {
+        "type": "adb",
+        "device_id": "0a388e93",
+        "adb_bin": str(adb_bin)
+    }
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = DriverConfig.parse(hjson.dumps(config_dict))
+    self.assertIn(str(adb_bin), str(cm.exception))
+    self.fs.create_file(adb_bin, st_size=100)
+    config = DriverConfig.parse(hjson.dumps(config_dict))
+    assert isinstance(config, DriverConfig)
+    self.assertEqual(config.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config.adb_bin, adb_bin)
+
+  def test_parse_adb_phone_identifier_unknown(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    if self.platform.is_macos:
+      self.platform.expect_sh(result=XCTRACE_DEVICES_SINGLE_OUTPUT)
+
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = DriverConfig.parse("Unknown Device X")
+    self.assertIn("Unknown Device X", str(cm.exception))
+
+  def test_parse_adb_phone_identifier_multiple(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT]
+    with self.assertRaises(ArgumentTypeMultiException) as cm:
+      _ = DriverConfig.parse("emulator.*")
+    message: str = str(cm.exception)
+    self.assertIn("emulator-5554", message)
+    self.assertIn("emulator-5556", message)
+    self.assertTrue(len(cm.exception), 1)
+    self.assertTrue(cm.exception.matching(AmbiguousDriverIdentifier))
+    self.assertEqual(len(self.platform.sh_cmds), 1)
+
+  def test_parse_adb_phone_identifier(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT, ADB_DEVICES_OUTPUT]
+
+    config = DriverConfig.parse("Nexus_7")
+    assert isinstance(config, DriverConfig)
+    self.assertEqual(len(self.platform.sh_cmds), 2)
+
+    self.assertEqual(config.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config.device_id, "0a388e93")
+    self.assertTrue(config.is_remote)
+    self.assertFalse(config.is_local)
+
+  def test_parse_adb_phone_serial(self):
+    self.platform.sh_results = [ADB_DEVICES_OUTPUT, ADB_DEVICES_OUTPUT]
+
+    config = DriverConfig.parse("0a388e93")
+    assert isinstance(config, DriverConfig)
+    self.assertEqual(len(self.platform.sh_cmds), 2)
+
+    self.assertEqual(config.type, BrowserDriverType.ANDROID)
+    self.assertEqual(config.device_id, "0a388e93")
+
+  @unittest.skipIf(not plt.PLATFORM.is_macos, "Incompatible platform")
+  def test_parse_ios_phone_serial(self):
+    self.platform.sh_results = [
+        ADB_DEVICES_OUTPUT, XCTRACE_DEVICES_SINGLE_OUTPUT,
+        XCTRACE_DEVICES_SINGLE_OUTPUT
+    ]
+
+    config = DriverConfig.parse("00001111-11AA22BB33DD")
+    assert isinstance(config, DriverConfig)
+    self.assertEqual(len(self.platform.sh_cmds), 3)
+
+    self.assertEqual(config.type, BrowserDriverType.IOS)
+    self.assertEqual(config.device_id, "00001111-11AA22BB33DD")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_flags.py b/tests/crossbench/cli/config/test_flags.py
new file mode 100644
index 0000000..8b9fded
--- /dev/null
+++ b/tests/crossbench/cli/config/test_flags.py
@@ -0,0 +1,416 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import unittest
+
+from crossbench.cli.config.browser_variants import (FlagsConfig,
+                                                    FlagsGroupConfig,
+                                                    FlagsVariantConfig)
+from crossbench.config import ConfigError
+from crossbench.exception import ArgumentTypeMultiException
+from crossbench.flags.base import Flags
+from tests import test_helper
+
+
+class FlagsConfigTestCase(unittest.TestCase):
+
+  def test_invalid_empty(self):
+    with self.assertRaises(ArgumentTypeMultiException) as cm:
+      FlagsConfig.parse("")
+    self.assertIn("empty", str(cm.exception).lower())
+    with self.assertRaises(ConfigError) as cm:
+      FlagsConfig.parse_str("")
+    self.assertIn("empty", str(cm.exception).lower())
+
+  def test_empty_dict(self):
+    config = FlagsConfig.parse({})
+    self.assertFalse(config)
+
+  def test_parse_empty_group(self):
+    config = FlagsConfig.parse({
+        "a": None,
+        "b": {},
+        "c": tuple(),
+    })
+    self.assertEqual(len(config), 3)
+    for group in config.values():
+      self.assertFalse(group)
+    self.assertFalse(config["a"])
+    self.assertFalse(config["b"])
+    self.assertFalse(config["c"])
+
+  def test_parse_str(self):
+    config = FlagsConfig.parse("--foo --bar")
+    self.assertEqual(len(config), 1)
+    self.assertEqual(str(config["default"][0].flags), "--foo --bar")
+
+  def test_parse_single_str_groups(self):
+    config = FlagsConfig.parse({
+        "a": "--foo=1 --bar",
+        "b": "--foo=2 --bar",
+    })
+    self.assertEqual(len(config), 2)
+    self.assertEqual(len(config["a"]), 1)
+    self.assertEqual(len(config["b"]), 1)
+    flags_a = config["a"][0].flags
+    flags_b = config["b"][0].flags
+    self.assertEqual(len(flags_a), 2)
+    self.assertEqual(len(flags_b), 2)
+    self.assertEqual(str(flags_a), "--foo=1 --bar")
+    self.assertEqual(str(flags_b), "--foo=2 --bar")
+
+  def test_parse_single_dict_groups(self):
+    config = FlagsConfig.parse({
+        "a": {
+            "--foo": "1",
+            "--bar": None,
+        },
+        "b": {
+            "--foo": "2",
+            "--bar": None
+        }
+    })
+    self.assertEqual(len(config), 2)
+    self.assertEqual(len(config["a"]), 1)
+    self.assertEqual(len(config["b"]), 1)
+    flags_a = config["a"][0].flags
+    flags_b = config["b"][0].flags
+    self.assertEqual(len(flags_a), 2)
+    self.assertEqual(len(flags_b), 2)
+    self.assertEqual(str(flags_a), "--foo=1 --bar")
+    self.assertEqual(str(flags_b), "--foo=2 --bar")
+
+  def test_parse_multi_str_groups(self):
+    config = FlagsConfig.parse({
+        "a": [
+            "--foo=1 --bar=1",
+            "--foo=1 --bar=2",
+        ],
+        "b": "--foo=2 --bar",
+    })
+    self.assertEqual(len(config), 2)
+    self.assertEqual(len(config["a"]), 2)
+    self.assertEqual(len(config["b"]), 1)
+    labels = tuple(v.label for v in config["a"])  # pylint: disable=no-member
+    self.assertTupleEqual(labels, ("foo=1_bar=1", "foo=1_bar=2"))
+    variants_a = config["a"]
+    flags_a_1 = variants_a[0].flags
+    flags_a_2 = variants_a[1].flags
+    self.assertEqual(str(flags_a_1), "--foo=1 --bar=1")
+    self.assertEqual(str(flags_a_2), "--foo=1 --bar=2")
+
+    flags_b = config["b"][0].flags
+    self.assertEqual(len(flags_b), 2)
+    self.assertEqual(str(flags_b), "--foo=2 --bar")
+
+  def test_parse_multi_dict_str_groups(self):
+    config = FlagsConfig.parse({
+        "a": {
+            "label_a_1": "--foo=1 --bar=1",
+            "label_a_2": "--foo=1 --bar=2",
+        }
+    })
+    self.assertEqual(len(config), 1)
+    self.assertEqual(len(config["a"]), 2)
+
+    self.assertTupleEqual(
+        tuple(v.label for v in config["a"]), ("label_a_1", "label_a_2"))
+    variants_a = config["a"]
+    flags_a_1 = variants_a[0].flags
+    flags_a_2 = variants_a[1].flags
+    self.assertEqual(str(flags_a_1), "--foo=1 --bar=1")
+    self.assertEqual(str(flags_a_2), "--foo=1 --bar=2")
+
+  def test_parse_multi_dict_dict_groups(self):
+    config = FlagsConfig.parse({
+        "a": {
+            "label_a_1": {
+                "--foo": "1",
+                "--bar": "1"
+            },
+            "label_a_2": {
+                "--bar": "2",
+                "--foo": "1",
+            }
+        }
+    })
+    self.assertEqual(len(config), 1)
+    self.assertEqual(len(config["a"]), 2)
+    self.assertTupleEqual(
+        tuple(v.label for v in config["a"]), ("label_a_1", "label_a_2"))
+    variants_a = config["a"]
+    flags_a_1 = variants_a[0].flags
+    flags_a_2 = variants_a[1].flags
+    self.assertEqual(str(flags_a_1), "--foo=1 --bar=1")
+    self.assertEqual(str(flags_a_2), "--bar=2 --foo=1")
+
+  def test_parse_variants_groups(self):
+    config = FlagsConfig.parse(
+        {"a": {
+            "--foo": [None, "1"],
+            "--bar": ["1", "2"],
+        }})
+    self.assertEqual(len(config), 1)
+    self.assertEqual(len(config["a"]), 4)
+
+    self.assertTupleEqual(
+        tuple(v.label for v in config["a"]),
+        ("bar=1", "bar=2", "foo=1_bar=1", "foo=1_bar=2"))
+    variants_a = config["a"]
+    self.assertEqual(str(variants_a[0].flags), "--bar=1")
+    self.assertEqual(str(variants_a[1].flags), "--bar=2")
+    self.assertEqual(str(variants_a[2].flags), "--foo=1 --bar=1")
+    self.assertEqual(str(variants_a[3].flags), "--foo=1 --bar=2")
+
+
+class FlagsVariantConfigTestCase(unittest.TestCase):
+
+  def test_empty(self):
+    empty = FlagsVariantConfig("default")
+    self.assertEqual(empty.label, "default")
+    self.assertFalse(empty.flags)
+    self.assertEqual(empty.index, 0)
+
+  def test_merge_copy(self):
+    flags_a = Flags.parse("--foo-a")
+    flags_b = Flags.parse("--bar-b=1")
+    variant_a = FlagsVariantConfig("label_a", 0, flags_a)
+    variant_b = FlagsVariantConfig("label_b", 1, flags_b)
+    variant = variant_a.merge_copy(variant_b)
+    self.assertEqual(variant.label, "label_a_label_b")
+    self.assertEqual(str(variant.flags), "--foo-a --bar-b=1")
+    self.assertEqual(variant.index, 0)
+
+    variant = variant_a.merge_copy(variant_b, index=11, label="custom_label")
+    self.assertEqual(variant.label, "custom_label")
+    self.assertEqual(str(variant.flags), "--foo-a --bar-b=1")
+    self.assertEqual(variant.index, 11)
+
+  def test_equal(self):
+    variant_a = FlagsVariantConfig.parse("label_a", 0, "--foo=a")
+    variant_b = FlagsVariantConfig.parse("label_b", 1, "--foo=a")
+    variant_c = FlagsVariantConfig.parse("label_b", 1, "--foo=b")
+    self.assertEqual(variant_a, variant_b)
+    self.assertEqual(variant_b, variant_a)
+    self.assertNotEqual(variant_a, variant_c)
+    self.assertNotEqual(variant_b, variant_c)
+    variants = set((variant_a,))
+    self.assertIn(variant_a, variants)
+    self.assertIn(variant_b, variants)
+    self.assertNotIn(variant_c, variants)
+
+
+class FlagsGroupConfigTestCase(unittest.TestCase):
+
+  def test_parse_empty(self):
+    for empty in (None, [], (), {}, "", "  "):
+      with self.subTest(flags=empty):
+        self.assertFalse(FlagsGroupConfig.parse(empty))
+
+  def test_parse_invalid(self):
+    for invalid in (-1, 0, 1):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(ConfigError):
+          FlagsGroupConfig.parse(invalid)
+
+  def test_parse_str_single(self):
+    group = FlagsGroupConfig.parse("--foo-a=1")
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-a=1")
+    self.assertEqual(group[0].label, "default")
+
+  def test_parse_str_multiple(self):
+    group = FlagsGroupConfig.parse(("--foo-a=1 --bar", "--foo-a=2"))
+    self.assertEqual(len(group), 2)
+    self.assertEqual(str(group[0].flags), "--foo-a=1 --bar")
+    self.assertEqual(str(group[1].flags), "--foo-a=2")
+
+  def test_parse_str_multiple_empty(self):
+    group = FlagsGroupConfig.parse(("", "--foo", "-foo=v1"))
+    self.assertEqual(len(group), 3)
+    self.assertEqual(str(group[0].flags), "")
+    self.assertEqual(str(group[1].flags), "--foo")
+    self.assertEqual(str(group[2].flags), "-foo=v1")
+
+  def test_parse_dict_simple(self):
+    group = FlagsGroupConfig.parse({"--foo": "1", "--bar": "2"})
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo=1 --bar=2")
+    self.assertEqual(group[0].label, "default")
+
+  def test_parse_dict_invalid_variant(self):
+    for invalid in (-1, 0):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(ValueError):
+          FlagsGroupConfig.parse({
+              "--foo": "1",
+              "--invalid": invalid,
+              "--bar": "2",
+          })
+
+  def test_parse_duplicate_variant_value(self):
+    for duplicate in (None, "", "value"):
+      with self.subTest(duplicate=duplicate):
+        with self.assertRaises(ValueError) as cm:
+          FlagsGroupConfig.parse({"--duplicate": [duplicate, duplicate]})
+        self.assertIn("duplicate", str(cm.exception))
+    with self.assertRaises(ConfigError) as cm:
+      FlagsGroupConfig.parse(
+          ["--foo --duplicate='foo'", "--foo --duplicate='foo'"])
+    self.assertIn("duplicate", str(cm.exception))
+
+  def test_parse_dict_single_with_labels(self):
+    group = FlagsGroupConfig.parse({
+        "config_1": "--foo=1 --bar",
+        "config_2": "",
+    })
+    self.assertEqual(len(group), 2)
+    self.assertEqual(str(group[0].flags), "--foo=1 --bar")
+    self.assertEqual(str(group[1].flags), "")
+    self.assertEqual(group[0].label, "config_1")
+    self.assertEqual(group[1].label, "config_2")
+    for index, group in enumerate(group):
+      self.assertEqual(group.index, index)
+
+  def test_parse_dict_with_labels_duplicate_flags(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = FlagsGroupConfig.parse({
+          "config_1": "--foo=1 --bar",
+          "config_2": "--foo=1 --bar",
+      })
+    self.assertIn("duplicate", str(cm.exception).lower())
+    self.assertIn("--foo=1 --bar", str(cm.exception).lower())
+
+  def test_parse_dict_single(self):
+    group = FlagsGroupConfig.parse({
+        "--foo": "1",
+        "--bar": None,
+    })
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo=1 --bar")
+
+  def test_parse_dict_multiple_3_x_1(self):
+    group = FlagsGroupConfig.parse({
+        "--foo": [None, "1", "2"],
+        "--bar": None,
+    })
+    self.assertEqual(len(group), 3)
+    self.assertEqual(str(group[0].flags), "--bar")
+    self.assertEqual(str(group[1].flags), "--foo=1 --bar")
+    self.assertEqual(str(group[2].flags), "--foo=2 --bar")
+    for index, group in enumerate(group):
+      self.assertEqual(group.index, index)
+
+  def test_parse_dict_multiple_2_x_2(self):
+    group = FlagsGroupConfig.parse({
+        "--foo": [None, "a"],
+        "--bar": [None, "b"],
+    })
+    self.assertEqual(len(group), 4)
+    self.assertEqual(str(group[0].flags), "")
+    self.assertEqual(str(group[1].flags), "--bar=b")
+    self.assertEqual(str(group[2].flags), "--foo=a")
+    self.assertEqual(str(group[3].flags), "--foo=a --bar=b")
+    self.assertEqual(group[0].label, "default")
+    self.assertEqual(group[1].label, "bar=b")
+    self.assertEqual(group[2].label, "foo=a")
+    self.assertEqual(group[3].label, "foo=a_bar=b")
+    for index, group in enumerate(group):
+      self.assertEqual(group.index, index)
+
+  def test_product_single(self):
+    group_a = FlagsGroupConfig.parse("--foo-a=1")
+    group_b = FlagsGroupConfig.parse("--foo-b=1")
+    self.assertEqual(group_a[0].label, "default")
+    self.assertEqual(group_b[0].label, "default")
+    group = group_a.product(group_b)
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-a=1 --foo-b=1")
+    self.assertEqual(group[0].label, "default")
+
+  def test_product_empty_empty(self):
+    group_a = FlagsGroupConfig()
+    group_b = FlagsGroupConfig()
+    group = group_a.product(group_b)
+    self.assertFalse(group)
+    group = group_a.product(group_b, group_b, group_b)
+    self.assertFalse(group)
+
+  def test_product_same(self):
+    group_a = FlagsGroupConfig.parse("--foo-b=1")
+    self.assertEqual(group_a[0].label, "default")
+    group = group_a.product(group_a)
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-b=1")
+    self.assertEqual(group[0].label, "default")
+    group = group_a.product(group_a, group_a, group_a)
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-b=1")
+    self.assertEqual(group[0].label, "default")
+
+  def test_product_same_values(self):
+    group_a = FlagsGroupConfig.parse("--foo-b=1")
+    group_b = FlagsGroupConfig.parse("--foo-b=1")
+    group = group_a.product(group_b)
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-b=1")
+    group = group_a.product(group_a, group_a, group_a)
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-b=1")
+
+  def test_product_empty(self):
+    group_a = FlagsGroupConfig.parse("")
+    group_b = FlagsGroupConfig.parse("--foo-b=1")
+    group = group_a.product(group_b)
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-b=1")
+    group = group_b.product(group_a)
+    self.assertEqual(len(group), 1)
+    self.assertEqual(str(group[0].flags), "--foo-b=1")
+
+  def test_product_2_x_1(self):
+    group_a = FlagsGroupConfig.parse((
+        None,
+        "--foo-a=1",
+    ))
+    group_b = FlagsGroupConfig.parse("--foo-b=1")
+    group = group_a.product(group_b)
+    self.assertEqual(len(group), 2)
+    self.assertEqual(str(group[0].flags), "--foo-b=1")
+    self.assertEqual(str(group[1].flags), "--foo-a=1 --foo-b=1")
+    self.assertEqual(group[0].label, "default")
+    self.assertEqual(group[1].label, "foo_a=1")
+
+  def test_product_2_x_2(self):
+    group_a = FlagsGroupConfig.parse((
+        None,
+        "--foo-a=1",
+    ))
+    group_b = FlagsGroupConfig.parse((None, "--foo-b=1"))
+    group = group_a.product(group_b)
+    self.assertEqual(len(group), 4)
+    self.assertEqual(str(group[0].flags), "")
+    self.assertEqual(str(group[1].flags), "--foo-b=1")
+    self.assertEqual(str(group[2].flags), "--foo-a=1")
+    self.assertEqual(str(group[3].flags), "--foo-a=1 --foo-b=1")
+    self.assertEqual(group[0].label, "default")
+    self.assertEqual(group[1].label, "foo_b=1")
+    self.assertEqual(group[2].label, "foo_a=1")
+    self.assertEqual(group[3].label, "foo_a=1_foo_b=1")
+    for index, group in enumerate(group):
+      self.assertEqual(group.index, index)
+
+  def test_product_conflicting(self):
+    group_a = FlagsGroupConfig.parse(("--foo=1"))
+    group_b = FlagsGroupConfig.parse(("--foo=2"))
+    with self.assertRaises(ValueError) as cm:
+      group_a.product(group_b)
+    self.assertIn("different previous value", str(cm.exception))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_network.py b/tests/crossbench/cli/config/test_network.py
new file mode 100644
index 0000000..5ca1fa6
--- /dev/null
+++ b/tests/crossbench/cli/config/test_network.py
@@ -0,0 +1,257 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import json
+
+from crossbench import path as pth
+from crossbench.cli.config.network import (NetworkConfig, NetworkSpeedConfig,
+                                           NetworkSpeedPreset, NetworkType)
+from tests import test_helper
+from tests.crossbench.cli.config.base import BaseConfigTestCase
+
+
+class NetworkSpeedConfigTestCase(BaseConfigTestCase):
+
+  def test_parse_invalid(self):
+    for invalid in ("", None, "---"):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          NetworkSpeedConfig.parse(invalid)
+        with self.assertRaises(argparse.ArgumentTypeError):
+          NetworkSpeedConfig.parse_str(str(invalid))
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        NetworkSpeedConfig.parse("not a speed preset value")
+      self.assertIn("choices are", str(cm.exception).lower())
+
+  def test_parse_default(self):
+    config = NetworkSpeedConfig.parse("default")
+    self.assertEqual(config, NetworkSpeedConfig.default())
+
+  def test_default(self):
+    config = NetworkSpeedConfig.default()
+    self.assertIsNone(config.rtt_ms)
+    self.assertIsNone(config.in_kbps)
+    self.assertIsNone(config.out_kbps)
+    self.assertIsNone(config.window)
+
+  def test_parse_speed_preset(self):
+    config = NetworkSpeedConfig.parse("4G")
+    self.assertNotEqual(config, NetworkSpeedConfig.default())
+
+    for preset in NetworkSpeedPreset:  # pytype: disable=missing-parameter
+      config = NetworkSpeedConfig.parse(str(preset))
+      self.assertEqual(config, NetworkSpeedConfig.parse_preset(preset))
+
+  def test_parse_invalid_preset(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkSpeedConfig.parse("1xx4")
+    self.assertIn("1xx4", str(cm.exception))
+    self.assertIn("Choices are", str(cm.exception))
+
+  def test_parse_dict(self):
+    config = NetworkSpeedConfig.parse({
+        "rtt_ms": 100,
+        "in_kbps": 200,
+        "out_kbps": 300,
+        "window": 400
+    })
+    self.assertIsNone(config.ts_proxy)
+    self.assertEqual(config.rtt_ms, 100)
+    self.assertEqual(config.in_kbps, 200)
+    self.assertEqual(config.out_kbps, 300)
+    self.assertEqual(config.window, 400)
+
+  def test_parse_invalid_dict(self):
+    for int_property in ("rtt_ms", "in_kbps", "out_kbps", "window"):
+      with self.subTest(config_property=int_property):
+        with self.assertRaises(argparse.ArgumentTypeError) as cm:
+          _ = NetworkSpeedConfig.parse({int_property: -100})
+        self.assertIn(int_property, str(cm.exception))
+
+  def test_parse_ts_proxy_path(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      _ = NetworkSpeedConfig.parse({"ts_proxy": "/some/random/path"})
+    self.assertIn("ts_proxy", str(cm.exception))
+    ts_proxy = pth.LocalPath("/python/ts_proxy.py")
+    self.fs.create_file(ts_proxy, st_size=100)
+    config = NetworkSpeedConfig.parse({"ts_proxy": str(ts_proxy)})
+    self.assertEqual(config.ts_proxy, ts_proxy)
+
+
+class NetworkConfigTestCase(BaseConfigTestCase):
+
+  def test_parse_invalid(self):
+    for invalid in ("", None, "---", "something"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        NetworkConfig.parse(invalid)
+      with self.assertRaises(argparse.ArgumentTypeError):
+        NetworkConfig.parse_str(str(invalid))
+
+  def test_parse_default(self):
+    config = NetworkConfig.parse("default")
+    self.assertEqual(config, NetworkConfig.default())
+
+  def test_default(self):
+    config = NetworkConfig.default()
+    self.assertEqual(config.type, NetworkType.LIVE)
+    self.assertEqual(config.speed, NetworkSpeedConfig.default())
+    config_1 = NetworkConfig.parse({})
+    self.assertEqual(config, config_1)
+    config_2 = NetworkConfig.parse("{}")
+    self.assertEqual(config, config_2)
+
+  def test_parse_replay_archive_invalid(self):
+    path = pth.LocalPath("/foo/bar/wprgo.archive")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse(str(path))
+    message = str(cm.exception)
+    self.assertIn("wpr.go archive", message)
+    self.assertIn("exist", message)
+
+    self.fs.create_file(path)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse(str(path))
+    message = str(cm.exception)
+    self.assertIn("wpr.go archive", message)
+    self.assertIn("empty", message)
+
+  def test_parse_wprgo_archive(self):
+    path = pth.LocalPath("/foo/bar/wprgo.archive")
+    self.fs.create_file(path, st_size=1024)
+    config = NetworkConfig.parse(str(path))
+    assert isinstance(config, NetworkConfig)
+    self.assertEqual(config.type, NetworkType.WPR)
+    self.assertEqual(config.path, path)
+    self.assertEqual(config.speed, NetworkSpeedConfig.default())
+
+  def test_parse_wprgo_archive_url(self):
+    url = "gs://bucket/wprgo.archive"
+    config = NetworkConfig.parse(url)
+    assert isinstance(config, NetworkConfig)
+    self.assertEqual(config.type, NetworkType.WPR)
+    self.assertEqual(config.url, url)
+    self.assertEqual(config.speed, NetworkSpeedConfig.default())
+
+  def test_invalid_constructor_params(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = NetworkConfig(path=pth.LocalPath("foo/bar"))
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = NetworkConfig(type=NetworkType.LOCAL, path=None)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = NetworkConfig(type=NetworkType.WPR, path=None)
+
+  def test_parse_speed_preset(self):
+    for preset in NetworkSpeedPreset:  # pytype: disable=missing-parameter
+      config = NetworkConfig.parse_str(preset.value)
+      self.assertEqual(config.speed, NetworkSpeedConfig.parse_preset(preset))
+
+  def test_parse_live_preset(self):
+    live_a = NetworkConfig.parse_live("4G")
+    live_b = NetworkConfig.parse_live(NetworkSpeedConfig.parse("4G"))
+    live_c = NetworkConfig.parse_live(
+        NetworkSpeedConfig.parse(NetworkSpeedPreset.MOBILE_4G))
+    live_d = NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G)
+    self.assertEqual(live_a, live_b)
+    self.assertEqual(live_a, live_c)
+    self.assertEqual(live_a, live_d)
+
+  def test_parse_wpr_invalid(self):
+    dir_path = pth.LocalPath("test/dir")
+    dir_path.mkdir(parents=True)
+    for invalid in ("", "default", "4G", dir_path, str(dir_path)):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        NetworkConfig.parse_wpr(invalid)
+
+  def test_parse_wpr(self):
+    archive_path = pth.LocalPath("test/archive.wprgo")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse_wpr(archive_path)
+    self.assertIn(str(archive_path), str(cm.exception))
+    self.fs.create_file(archive_path, st_size=100)
+    config = NetworkConfig.parse_wpr(archive_path)
+    self.assertEqual(config.type, NetworkType.WPR)
+    self.assertEqual(config.speed, NetworkSpeedConfig.default())
+    self.assertEqual(config.path, archive_path)
+    self.assertEqual(config, NetworkConfig.parse(archive_path))
+
+  def test_parse_dict_default(self):
+    config = NetworkConfig.parse({})
+    self.assertEqual(config, NetworkConfig.default())
+
+  def test_parse_local_dict_default(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      # Missing path
+      NetworkConfig.parse_local({})
+
+  def test_parse_dict_speed(self):
+    config_dict = {"speed": "4G"}
+    config: NetworkConfig = NetworkConfig.parse(dict(config_dict))
+    self.assertNotEqual(config, NetworkConfig.default())
+    self.assertEqual(config.type, NetworkType.LIVE)
+    self.assertEqual(
+        config.speed,
+        NetworkSpeedConfig.parse_preset(NetworkSpeedPreset.MOBILE_4G))
+    self.assertIsNone(config.path)
+    self.assertTrue(config_dict)
+    config_1 = NetworkConfig.parse(json.dumps(config_dict))
+    self.assertEqual(config, config_1)
+
+  def test_parse_dict_wpr(self):
+    archive_path = pth.LocalPath("test/archive.wprgo")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse({"type": "wpr", "path": archive_path})
+    self.assertIn(str(archive_path), str(cm.exception))
+    self.fs.create_file(archive_path, st_size=100)
+    config_dict = {"type": "wpr", "path": str(archive_path)}
+    config = NetworkConfig.parse(dict(config_dict))
+    self.assertEqual(config, NetworkConfig.parse_wpr(archive_path))
+    self.assertTrue(config_dict)
+    config_1 = NetworkConfig.parse(json.dumps(config_dict))
+    self.assertEqual(config, config_1)
+
+  def test_parse_dict_local(self):
+    benchmark_folder = pth.LocalPath("third_party/speedometer/v3.0")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse({"type": "local", "path": benchmark_folder})
+    self.assertIn(str(benchmark_folder), str(cm.exception))
+    self.fs.create_file(benchmark_folder / "index.html", st_size=100)
+    url = "http://foo:1234"
+    config_dict = {"type": "local", "path": str(benchmark_folder), "url": url}
+    config = NetworkConfig.parse(dict(config_dict))
+    self.assertEqual(config.type, NetworkType.LOCAL)
+    self.assertEqual(config.path, benchmark_folder)
+    self.assertEqual(config.url, url)
+    self.assertTrue(config_dict)
+    config_1 = NetworkConfig.parse(json.dumps(config_dict))
+    self.assertEqual(config, config_1)
+    local_config_dict = dict(config_dict)
+    del local_config_dict["type"]
+    config_local = NetworkConfig.parse_local(dict(local_config_dict))
+    self.assertEqual(config, config_local)
+    config_local = NetworkConfig.parse_local(json.dumps(local_config_dict))
+    self.assertEqual(config, config_local)
+
+  def test_parse_local_file(self):
+    benchmark_folder = pth.LocalPath("third_party/speedometer/v3.0")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse(benchmark_folder)
+    self.assertIn(str(benchmark_folder), str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse_local(benchmark_folder)
+    self.assertIn(str(benchmark_folder), str(cm.exception))
+    self.fs.create_file(benchmark_folder / "index.html", st_size=100)
+    config = NetworkConfig.parse(str(benchmark_folder))
+    self.assertEqual(config.type, NetworkType.LOCAL)
+    self.assertEqual(config.path, benchmark_folder)
+    self.assertIsNone(config.url)
+    self.assertEqual(config, NetworkConfig.parse(benchmark_folder))
+    self.assertEqual(config, NetworkConfig.parse_local(str(benchmark_folder)))
+    self.assertEqual(config, NetworkConfig.parse_local(benchmark_folder))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_probe.py b/tests/crossbench/cli/config/test_probe.py
new file mode 100644
index 0000000..c437e0c
--- /dev/null
+++ b/tests/crossbench/cli/config/test_probe.py
@@ -0,0 +1,161 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+from unittest import mock
+
+import hjson
+
+from crossbench import path as pth
+from crossbench.cli.config.probe import ProbeConfig, ProbeListConfig
+from crossbench.probes.power_sampler import PowerSamplerProbe
+from crossbench.probes.v8.log import V8LogProbe
+from crossbench.types import JsonDict
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class TestProbeConfig(CrossbenchFakeFsTestCase):
+  # pylint: disable=expression-not-assigned
+
+  def parse_config(self, config_data) -> ProbeListConfig:
+    probe_config_file = pth.LocalPath("/probe.config.hjson")
+    with probe_config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+    return ProbeListConfig.parse(probe_config_file)
+
+  def test_invalid_empty(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      self.parse_config({}).probes
+    with self.assertRaises(argparse.ArgumentTypeError):
+      self.parse_config({"foo": {}}).probes
+
+  def test_invalid_names(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      self.parse_config({"probes": {"invalid probe name": {}}}).probes
+
+  def test_empty(self):
+    config = self.parse_config({"probes": {}})
+    self.assertListEqual(config.probes, [])
+
+  def test_single_v8_log(self):
+    js_flags = ["--log-maps", "--log-function-events"]
+    config = self.parse_config(
+        {"probes": {
+            "v8.log": {
+                "prof": True,
+                "js_flags": js_flags,
+            }
+        }})
+    self.assertTrue(len(config.probes), 1)
+    probe = config.probes[0]
+    assert isinstance(probe, V8LogProbe)
+    for flag in js_flags + ["--log-all"]:
+      self.assertIn(flag, probe.js_flags)
+
+  def test_from_cli_args(self):
+    file = pth.LocalPath("probe.config.hjson")
+    js_flags = ["--log-maps", "--log-function-events"]
+    config_data: JsonDict = {
+        "probes": {
+            "v8.log": {
+                "prof": True,
+                "js_flags": js_flags,
+            }
+        }
+    }
+    with file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+    args = mock.Mock(probe_config=file)
+    config = ProbeListConfig.from_cli_args(args)
+    self.assertTrue(len(config.probes), 1)
+    probe = config.probes[0]
+    assert isinstance(probe, V8LogProbe)
+    for flag in js_flags + ["--log-all"]:
+      self.assertIn(flag, probe.js_flags)
+
+  def test_inline_config(self):
+    mock_d8_file = pth.LocalPath("out/d8")
+    self.fs.create_file(mock_d8_file, st_size=8 * 1024)
+    config_data = {"d8_binary": str(mock_d8_file)}
+    args = mock.Mock(probe_config=None, throw=True, wraps=False)
+
+    args.probe = [
+        ProbeConfig.parse(f"v8.log{hjson.dumps(config_data)}"),
+    ]
+    config = ProbeListConfig.from_cli_args(args)
+    self.assertTrue(len(config.probes), 1)
+    probe = config.probes[0]
+    self.assertTrue(isinstance(probe, V8LogProbe))
+
+    args.probe = [
+        ProbeConfig.parse(f"v8.log:{hjson.dumps(config_data)}"),
+    ]
+    config = ProbeListConfig.from_cli_args(args)
+    self.assertTrue(len(config.probes), 1)
+    probe = config.probes[0]
+    self.assertTrue(isinstance(probe, V8LogProbe))
+
+  def test_inline_config_invalid(self):
+    mock_d8_file = pth.LocalPath("out/d8")
+    self.fs.create_file(mock_d8_file)
+    config_data = {"d8_binary": str(mock_d8_file)}
+    trailing_brace = "}"
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ProbeConfig.parse(f"v8.log{hjson.dumps(config_data)}{trailing_brace}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ProbeConfig.parse(f"v8.log:{hjson.dumps(config_data)}{trailing_brace}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ProbeConfig.parse("v8.log::")
+
+  def test_inline_config_dir_instead_of_file(self):
+    mock_dir = pth.LocalPath("some/dir")
+    mock_dir.mkdir(parents=True)
+    config_data = {"d8_binary": str(mock_dir)}
+    args = mock.Mock(
+        probe=[ProbeConfig.parse(f"v8.log{hjson.dumps(config_data)}")],
+        probe_config=None,
+        throw=True,
+        wraps=False)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ProbeListConfig.from_cli_args(args)
+    self.assertIn(str(mock_dir), str(cm.exception))
+
+  def test_inline_config_non_existent_file(self):
+    config_data = {"d8_binary": "does/not/exist/d8"}
+    args = mock.Mock(
+        probe=[ProbeConfig.parse(f"v8.log{hjson.dumps(config_data)}")],
+        probe_config=None,
+        throw=True,
+        wraps=False)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ProbeListConfig.from_cli_args(args)
+    expected_path = pth.LocalPath("does/not/exist/d8")
+    self.assertIn(str(expected_path), str(cm.exception))
+
+  def test_multiple_probes(self):
+    powersampler_bin = pth.LocalPath("/powersampler.bin")
+    powersampler_bin.touch()
+    config = self.parse_config({
+        "probes": {
+            "v8.log": {
+                "log_all": True,
+            },
+            "powersampler": {
+                "bin_path": str(powersampler_bin)
+            }
+        }
+    })
+    self.assertTrue(len(config.probes), 2)
+    log_probe = config.probes[0]
+    assert isinstance(log_probe, V8LogProbe)
+    powersampler_probe = config.probes[1]
+    assert isinstance(powersampler_probe, PowerSamplerProbe)
+    self.assertEqual(powersampler_probe.bin_path, powersampler_bin)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_secrets.py b/tests/crossbench/cli/config/test_secrets.py
new file mode 100644
index 0000000..f704583
--- /dev/null
+++ b/tests/crossbench/cli/config/test_secrets.py
@@ -0,0 +1,84 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+
+import hjson
+from immutabledict import immutabledict
+
+from crossbench.cli.config.secrets import Secret, SecretsConfig, SecretType
+from tests.crossbench.cli.config.base import BaseConfigTestCase
+
+
+class SecretsConfigTestCase(BaseConfigTestCase):
+
+  def test_parse_empty(self):
+    secrets = SecretsConfig.parse({})
+    self.assertEqual(secrets.secrets, immutabledict())
+
+  def test_parse_google(self):
+    secrets = SecretsConfig.parse(
+        {"google": {
+            "password": "pw",
+            "account": "user@test.com"
+        }})
+    self.assertEqual(secrets.secrets[SecretType.GOOGLE],
+                     Secret(SecretType.GOOGLE, "user@test.com", "pw"))
+    secrets = SecretsConfig.parse(
+        {"google": {
+            "user": "user@test.com",
+            "password": ""
+        }})
+    self.assertEqual(secrets.secrets[SecretType.GOOGLE],
+                     Secret(SecretType.GOOGLE, "user@test.com", ""))
+
+  def test_equal_empty(self):
+    secrets_1 = SecretsConfig.parse({})
+    secrets_2 = SecretsConfig.parse({})
+    self.assertEqual(secrets_1, secrets_1)
+    self.assertEqual(secrets_1, secrets_2)
+    self.assertEqual(secrets_2, secrets_1)
+
+  def test_equal_single_item(self):
+    secrets_empty = SecretsConfig.parse({})
+    secrets_1 = SecretsConfig.parse(
+        {"google": {
+            "password": "pw",
+            "account": "user@test.com"
+        }})
+    secrets_2 = SecretsConfig.parse(
+        {"google": {
+            "password": "pw",
+            "account": "user@test.com"
+        }})
+    self.assertEqual(secrets_1, secrets_1)
+    self.assertEqual(secrets_1, secrets_2)
+    self.assertEqual(secrets_2, secrets_1)
+    self.assertNotEqual(secrets_1, secrets_empty)
+    self.assertNotEqual(secrets_empty, secrets_1)
+    self.assertNotEqual(secrets_2, secrets_empty)
+    self.assertNotEqual(secrets_empty, secrets_2)
+
+  def test_not_equal_single_item(self):
+    secrets_1 = SecretsConfig.parse(
+        {"google": {
+            "password": "pw",
+            "account": "user@test.com"
+        }})
+    secrets_2 = SecretsConfig.parse(
+        {"google": {
+            "password": "PASSWORD",
+            "account": "user@test.com"
+        }})
+    self.assertNotEqual(secrets_1, secrets_2)
+
+  def test_parse_inline_hjson(self):
+    config_data = {"google": {"password": "pw", "account": "user@test.com"}}
+    secrets_inline_hjson = SecretsConfig.parse(hjson.dumps(config_data))
+    secrets_inline_json = SecretsConfig.parse(json.dumps(config_data))
+    secrets_dict = SecretsConfig.parse(config_data)
+    self.assertEqual(secrets_inline_hjson, secrets_dict)
+    self.assertEqual(secrets_inline_json, secrets_dict)
diff --git a/tests/crossbench/cli/test_cli_fast_a.py b/tests/crossbench/cli/test_cli_fast_a.py
new file mode 100644
index 0000000..44a91b5
--- /dev/null
+++ b/tests/crossbench/cli/test_cli_fast_a.py
@@ -0,0 +1,439 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import json
+import pathlib
+import unittest
+from unittest import mock
+
+import hjson
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCliTestCase, SysExitTestException
+
+from crossbench import __version__, plt
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.env import HostEnvironmentConfig
+
+
+class FastCliTestCasePartA(BaseCliTestCase):
+  """These tests are run as part of the presubmit and should be
+  reasonably fast.
+  Slow tests run on the CQ are in CliSlowTestCase.
+
+  Keep FastCliTestCasePartA and FastCliTestCasePartB balanced for faster local
+  presubmit checks.
+  """
+
+  def test_invalid(self):
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("unknown subcommand", "--invalid flag")
+
+  def test_describe_invalid_empty(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "")
+    self.assertEqual(cm.exception.exit_code, 0)
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "", "--json")
+    self.assertEqual(cm.exception.exit_code, 0)
+
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "--unknown")
+    self.assertEqual(cm.exception.exit_code, 0)
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "--unknown", "--json")
+    self.assertEqual(cm.exception.exit_code, 0)
+
+  def test_describe_invalid_probe(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "probe", "unknown probe")
+    self.assertEqual(cm.exception.exit_code, 0)
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "probe", "unknown probe", "--json")
+    self.assertEqual(cm.exception.exit_code, 0)
+
+  def test_describe_invalid_benchmark(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "benchmark", "unknown benchmark")
+    self.assertEqual(cm.exception.exit_code, 0)
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "benchmark", "unknown benchmark", "--json")
+    self.assertEqual(cm.exception.exit_code, 0)
+
+  def test_describe_invalid_all(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "all", "unknown probe or benchmark")
+    self.assertEqual(cm.exception.exit_code, 0)
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("describe", "--json", "all", "unknown probe or benchmark")
+    self.assertEqual(cm.exception.exit_code, 0)
+
+  def test_describe(self):
+    # Non-json output shouldn't fail
+    self.run_cli("describe")
+    self.run_cli("describe", "all")
+    _, stdout, stderr = self.run_cli_output("describe", "--json")
+    self.assertFalse(stderr)
+    data = json.loads(stdout)
+    self.assertIn("benchmarks", data)
+    self.assertIn("probes", data)
+    self.assertIsInstance(data["benchmarks"], dict)
+    self.assertIsInstance(data["probes"], dict)
+
+  def test_describe_benchmarks(self):
+    # Non-json output shouldn't fail
+    self.run_cli("describe", "benchmarks")
+    _, stdout, stderr = self.run_cli_output("describe", "--json", "benchmarks")
+    self.assertFalse(stderr)
+    data = json.loads(stdout)
+    self.assertNotIn("benchmarks", data)
+    self.assertNotIn("probes", data)
+    self.assertIsInstance(data, dict)
+    self.assertIn("loading", data)
+
+  def test_describe_probes(self):
+    # Non-json output shouldn't fail
+    self.run_cli("describe", "probes")
+    _, stdout, stderr = self.run_cli_output("describe", "--json", "probes")
+    self.assertFalse(stderr)
+    data = json.loads(stdout)
+    self.assertNotIn("benchmarks", data)
+    self.assertNotIn("probes", data)
+    self.assertIsInstance(data, dict)
+    self.assertIn("v8.log", data)
+
+  def test_describe_all(self):
+    self.run_cli("describe", "probes")
+    _, stdout, stderr = self.run_cli_output("describe", "all")
+    self.assertFalse(stderr)
+    self.assertIn("benchmarks", stdout)
+    self.assertIn("v8.log", stdout)
+    self.assertIn("speedometer", stdout)
+
+  def test_describe_all_filtered(self):
+    self.run_cli("describe", "probes")
+    _, stdout, stderr = self.run_cli_output("describe", "all", "v8.log")
+    self.assertFalse(stderr)
+    self.assertNotIn("benchmarks", stdout)
+    self.assertIn("v8.log", stdout)
+    self.assertNotIn("speedometer", stdout)
+
+  def test_describe_all_json(self):
+    self.run_cli("describe", "probes")
+    _, stdout, stderr = self.run_cli_output("describe", "--json", "all")
+    self.assertFalse(stderr)
+    data = json.loads(stdout)
+    self.assertIsInstance(data, dict)
+    self.assertIn("benchmarks", data)
+    self.assertIn("v8.log", data["probes"])
+
+  def test_describe_all_json_filtered(self):
+    self.run_cli("describe", "probes")
+    _, stdout, stderr = self.run_cli_output("describe", "--json", "all",
+                                            "v8.log")
+    self.assertFalse(stderr)
+    data = json.loads(stdout)
+    self.assertIsInstance(data, dict)
+    self.assertEqual(data["benchmarks"], {})
+    self.assertEqual(len(data["probes"]), 1)
+    self.assertIn("v8.log", data["probes"])
+
+  def test_help(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("--help")
+    self.assertEqual(cm.exception.exit_code, 0)
+    _, stdout, stderr = self.run_cli_output(
+        "--help", raises=SysExitTestException)
+    self.assertFalse(stderr)
+    self.assertIn("usage:", stdout)
+    self.assertIn("Subcommands:", stdout)
+    # Check for top-level option:
+    self.assertIn("--no-color", stdout)
+    self.assertIn("Disable colored output", stdout)
+    self.assertIn("Available Probes for all Benchmarks:", stdout)
+
+  def test_help_subcommand(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("help")
+    self.assertEqual(cm.exception.exit_code, 0)
+    _, stdout, stderr = self.run_cli_output("help", raises=SysExitTestException)
+    self.assertFalse(stderr)
+    self.assertIn("usage:", stdout)
+    self.assertIn("Subcommands:", stdout)
+    # Check for top-level option:
+    self.assertIn("--no-color", stdout)
+    self.assertIn("Disable colored output", stdout)
+    self.assertIn("Available Probes for all Benchmarks:", stdout)
+
+  def test_version(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("--version")
+    self.assertEqual(cm.exception.exit_code, 0)
+    _, stdout, stderr = self.run_cli_output(
+        "--version", raises=SysExitTestException)
+    self.assertFalse(stderr)
+    self.assertIn(__version__, stdout)
+
+  def test_version_subcommand(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("version")
+    self.assertEqual(cm.exception.exit_code, 0)
+    _, stdout, stderr = self.run_cli_output(
+        "version", raises=SysExitTestException)
+    self.assertFalse(stderr)
+    self.assertIn(__version__, stdout)
+
+  def test_subcommand_run_subcommand(self):
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", "run", f"--urls={url}", "--env-validation=skip",
+                   "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+
+  def test_invalid_probe(self):
+    with self.assertRaises(argparse.ArgumentError), self.patch_get_browser():
+      self.run_cli("loading", "--probe=invalid_probe_name", "--throw")
+
+  def test_basic_probe_setting(self):
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", "--probe=v8.log", f"--urls={url}",
+                   "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        self.assertIn("--log-all", browser.js_flags)
+
+  def test_invalid_empty_probe_config_file(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_file.touch()
+    with self.patch_get_browser():
+      url = "http://test.com"
+      with self.assertRaises(argparse.ArgumentError) as cm:
+        self.run_cli("loading", f"--probe-config={config_file}",
+                     f"--urls={url}", "--env-validation=skip", "--throw")
+      message = str(cm.exception)
+      self.assertIn("--probe-config", message)
+      self.assertIn("empty", message)
+      for browser in self.browsers:
+        self.assertListEqual([], browser.url_list[self.SPLASH_URLS_LEN:])
+        self.assertNotIn("--log", browser.js_flags)
+
+  def test_empty_probe_config_file(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {"probes": {}}
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", f"--probe-config={config_file}", f"--urls={url}",
+                   "--env-validation=skip")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        self.assertNotIn("--log", browser.js_flags)
+
+  def test_invalid_probe_config_file(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {"probes": {"invalid probe name": {}}}
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+    with self.patch_get_browser():
+      url = "http://test.com"
+      with self.assertRaises(argparse.ArgumentTypeError):
+        self.run_cli("loading", f"--probe-config={config_file}",
+                     f"--urls={url}", "--env-validation=skip", "--throw")
+      for browser in self.browsers:
+        self.assertListEqual([], browser.url_list)
+        self.assertEqual(len(browser.js_flags), 0)
+
+  def test_probe_config_file(self):
+    config_file = pathlib.Path("/config.hjson")
+    js_flags = ["--log-foo", "--log-bar"]
+    config_data = {"probes": {"v8.log": {"js_flags": js_flags}}}
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", f"--probe-config={config_file}", f"--urls={url}",
+                   "--env-validation=skip")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        for flag in js_flags:
+          self.assertIn(flag, browser.js_flags)
+
+  def test_probe_config_file_invalid_probe(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {"probes": {"invalid probe name": {}}}
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+    with self.assertRaises(
+        argparse.ArgumentTypeError) as cm, self.patch_get_browser():
+      self.run_cli("loading", f"--probe-config={config_file}",
+                   "--urls=http://test.com", "--env-validation=skip", "--throw")
+    self.assertIn("invalid probe name", str(cm.exception))
+
+  def test_empty_config_file_properties(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {"probes": {}, "env": {}, "browsers": {}, "network": {}}
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+    with self.assertRaises(
+        argparse.ArgumentTypeError) as cm, self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
+                   "--env-validation=skip", "--throw")
+    self.assertIn("no config properties", str(cm.exception))
+
+  def test_empty_config_files(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {}
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+    with self.assertRaises(
+        argparse.ArgumentTypeError) as cm, self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
+                   "--env-validation=skip", "--throw")
+    self.assertIn("no config properties", str(cm.exception))
+
+  def test_conflicting_config_flags(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {"probes": {}, "env": {}, "browsers": {}, "network": {}}
+    for config_flag in ("--probe-config", "--env-config", "--browser-config",
+                        "--network-config"):
+      with config_file.open("w", encoding="utf-8") as f:
+        hjson.dump(config_data, f)
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        self.run_cli("sp2", f"--config={config_file}",
+                     f"{config_flag}={config_file}", "--env-validation=skip",
+                     "--throw")
+      message = str(cm.exception)
+      self.assertIn("--config", message)
+      self.assertIn(config_flag, message)
+
+  def test_config_file_with_probe(self):
+    config_file = pathlib.Path("/config.hjson")
+    js_flags = ["--log-foo", "--log-bar"]
+    config_data = {
+        "probes": {
+            "v8.log": {
+                "js_flags": js_flags
+            }
+        },
+        "env": {},
+        "browsers": {},
+        "network": {},
+    }
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
+                   "--env-validation=skip")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        for flag in js_flags:
+          self.assertIn(flag, browser.js_flags)
+
+  def test_config_file_with_env(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {
+        "probes": {},
+        "env": {
+            "screen_brightness_percent": 66,
+            "cpu_max_usage_percent": 77,
+        },
+        "browsers": {},
+        "network": {},
+    }
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+
+    with self.patch_get_browser():
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
+                         "--env-validation=skip")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        self.assertFalse(browser.js_flags)
+      config = cli.runner.env.config
+      self.assertEqual(config.disk_min_free_space_gib,
+                       HostEnvironmentConfig.IGNORE)
+      self.assertEqual(config.screen_brightness_percent, 66)
+      self.assertEqual(config.cpu_max_usage_percent, 77)
+
+  def test_config_file_with_browser(self):
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {
+        "probes": {},
+        "env": {},
+        "browsers": {
+            "browser_1": {
+                "path": "chrome-dev",
+            },
+            "browser_2": {
+                "path": "chrome-stable"
+            }
+        },
+        "network": {},
+    }
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      path_str = str(browser_config.path).lower()
+      if "dev" in path_str:
+        return mock_browser.MockChromeDev
+      return mock_browser.MockChromeStable
+
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        side_effect=mock_get_browser_cls):
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
+                         "--env-validation=skip")
+      browsers = cli.runner.browsers
+      self.assertEqual(len(browsers), 2)
+      self.assertEqual(browsers[0].label, "browser_1")
+      self.assertEqual(browsers[1].label, "browser_2")
+      for browser in browsers:
+        self.assertFalse(browser.js_flags)
+
+  def test_invalid_browser_identifier(self):
+    with self.assertRaises(argparse.ArgumentError) as cm:
+      self.run_cli("loading", "--browser=unknown_browser_identifier",
+                   "--urls=http://test.com", "--env-validation=skip", "--throw")
+    self.assertIn("--browser", str(cm.exception))
+    self.assertIn("unknown_browser_identifier", str(cm.exception))
+
+  def test_unknown_browser_binary(self):
+    browser_bin = pathlib.Path("/foo/custom/browser.bin")
+    browser_bin.parent.mkdir(parents=True)
+    browser_bin.touch()
+    with self.assertRaises(argparse.ArgumentError) as cm:
+      self.run_cli("loading", f"--browser={browser_bin}",
+                   "--urls=http://test.com", "--env-validation=skip", "--throw")
+    self.assertIn("--browser", str(cm.exception))
+    self.assertIn(str(browser_bin), str(cm.exception))
+
+  @unittest.skipUnless(plt.PLATFORM.is_win, "Can only run on windows")
+  def test_unknown_browser_binary_win(self):
+    browser_bin = pathlib.Path("C:\\foo\\custom\\browser.bin")
+    browser_bin.parent.mkdir(parents=True)
+    browser_bin.touch()
+    with self.assertRaises(argparse.ArgumentError) as cm:
+      self.run_cli("loading", f"--browser={browser_bin}",
+                   "--urls=http://test.com", "--env-validation=skip", "--throw")
+    self.assertIn("--browser", str(cm.exception))
+    self.assertIn(str(browser_bin), str(cm.exception))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/test_cli_fast_b.py b/tests/crossbench/cli/test_cli_fast_b.py
new file mode 100644
index 0000000..903000b
--- /dev/null
+++ b/tests/crossbench/cli/test_cli_fast_b.py
@@ -0,0 +1,530 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import datetime as dt
+import json
+import os
+import pathlib
+from typing import List, Optional, Type
+from unittest import mock
+
+import hjson
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCliTestCase, SysExitTestException
+from tests.crossbench.cli.config.base import XCTRACE_DEVICES_SINGLE_OUTPUT
+
+from crossbench import __version__, plt
+from crossbench.browsers import splash_screen, viewport
+from crossbench.cli.cli import CrossBenchCLI
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
+from crossbench.env import ValidationMode
+from crossbench.parse import LateArgumentError
+from crossbench.path import AnyPath
+from crossbench.probes import internal
+from crossbench.runner.runner import Runner
+
+
+class FastCliTestCasePartA(BaseCliTestCase):
+  """These tests are run as part of the presubmit and should be
+  reasonably fast.
+  Slow tests run on the CQ are in CliSlowTestCase.
+
+  Keep FastCliTestCasePartA and FastCliTestCasePartB balanced for faster local
+  presubmit checks.
+  """
+
+  def test_custom_chrome_browser_binary(self):
+    if self.platform.is_win:
+      self.skipTest("No auto-download available on windows")
+    browser_cls = mock_browser.MockChromeStable
+    # TODO: migrate to with_stem once python 3.9 is available everywhere
+    suffix = browser_cls.mock_app_path().suffix
+    browser_bin = browser_cls.mock_app_path().with_name(
+        f"Custom Google Chrome{suffix}")
+    browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
+
+    with mock.patch.object(
+        BrowserVariantsConfig, "get_browser_cls",
+        return_value=browser_cls) as get_browser_cls:
+      self.run_cli("loading", f"--browser={browser_bin}",
+                   "--urls=http://test.com", "--env-validation=skip")
+    get_browser_cls.assert_called_once_with(
+        BrowserConfig(browser_bin, DriverConfig.default()))
+
+  def test_custom_chrome_browser_binary_custom_flags(self):
+    if self.platform.is_win:
+      self.skipTest("No auto-download available on windows")
+    browser_cls = mock_browser.MockChromeStable
+    # TODO: migrate to with_stem once python 3.9 is available everywhere
+    suffix = browser_cls.mock_app_path().suffix
+    browser_bin = browser_cls.mock_app_path().with_name(
+        f"Custom Google Chrome{suffix}")
+    browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
+
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls", return_value=browser_cls), mock.patch.object(
+            CrossBenchCLI, "_run_benchmark") as run_benchmark:
+      self.run_cli("loading", f"--browser={browser_bin}",
+                   "--urls=http://test.com", "--env-validation=skip", "--",
+                   "--chrome-flag1=value1", "--chrome-flag2")
+    run_benchmark.assert_called_once()
+    runner = run_benchmark.call_args[0][1]
+    self.assertIsInstance(runner, Runner)
+    self.assertEqual(len(runner.browsers), 1)
+    browser = runner.browsers[0]
+    self.assertListEqual(["--chrome-flag1=value1", "--chrome-flag2"],
+                         list(browser.flags))
+
+  def test_browser_identifiers_duplicate(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      self.run_cli("loading", "--browser=chrome", "--browser=chrome",
+                   "--urls=http://test.com", "--env-validation=skip", "--throw")
+
+  def test_browser_identifiers_multiple(self):
+    mock_browsers: List[Type[mock_browser.MockBrowser]] = [
+        mock_browser.MockChromeStable,
+        mock_browser.MockChromeBeta,
+        mock_browser.MockChromeDev,
+    ]
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
+      for mock_browser_cls in mock_browsers:
+        if mock_browser_cls.mock_app_path() == browser_config.path:
+          return mock_browser_cls
+      raise ValueError("Unknown browser path")
+
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        side_effect=mock_get_browser_cls) as get_browser_cls:
+      url = "http://test.com"
+      self.run_cli("loading", "--browser=chrome-beta",
+                   "--browser=chrome-stable", "--browser=chrome-dev",
+                   f"--urls={url}", "--env-validation=skip",
+                   f"--out-dir={self.out_dir}")
+      self.assertTrue(self.out_dir.exists())
+      get_browser_cls.assert_called()
+      # Example:  BROWSER / "cb.results.json"
+      result_files = list(
+          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+      self.assertEqual(len(result_files), 3)
+      versions = []
+      for result_file in result_files:
+        with result_file.open(encoding="utf-8") as f:
+          results = json.load(f)
+        versions.append(results["browser"]["version"])
+        self.assertIn("test.com", results["stories"])
+      self.assertTrue(len(set(versions)), 3)
+      for mock_browser_cls in mock_browsers:
+        self.assertIn(mock_browser_cls.VERSION, versions)
+
+  def test_browser_identifiers_multiple_same_major_version(self):
+
+    class MockChromeBeta2(mock_browser.MockChromeBeta):
+      VERSION = "100.22.33.100"
+
+    class MockChromeDev2(mock_browser.MockChromeDev):
+      VERSION = "100.22.33.200"
+
+    mock_browsers: List[Type[mock_browser.MockBrowser]] = [
+        MockChromeBeta2,
+        MockChromeDev2,
+    ]
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
+      for mock_browser_cls in mock_browsers:
+        if mock_browser_cls.mock_app_path() == browser_config.path:
+          return mock_browser_cls
+      raise ValueError("Unknown browser path")
+
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        side_effect=mock_get_browser_cls) as get_browser_cls:
+      url = "http://test.com"
+      self.run_cli("loading", "--browser=chrome-dev", "--browser=chrome-beta",
+                   f"--urls={url}", "--env-validation=skip",
+                   f"--out-dir={self.out_dir}")
+      self.assertTrue(self.out_dir.exists())
+      get_browser_cls.assert_called()
+      # Example:  BROWSER / "cb.results.json"
+      result_files = list(
+          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+      self.assertEqual(len(result_files), 2)
+      versions = []
+      for result_file in result_files:
+        with result_file.open(encoding="utf-8") as f:
+          results = json.load(f)
+        versions.append(results["browser"]["version"])
+        self.assertIn("test.com", results["stories"])
+      self.assertTrue(len(set(versions)), 2)
+      for mock_browser_cls in mock_browsers:
+        self.assertIn(mock_browser_cls.VERSION, versions)
+
+  def test_browser_identifiers_multiple_same_version(self):
+
+    class MockChromeBeta2(mock_browser.MockChromeBeta):
+      VERSION = "100.22.33.999"
+
+    class MockChromeDev2(mock_browser.MockChromeDev):
+      VERSION = "100.22.33.999"
+
+    mock_browsers: List[Type[mock_browser.MockBrowser]] = [
+        MockChromeBeta2,
+        MockChromeDev2,
+    ]
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
+      for mock_browser_cls in mock_browsers:
+        if mock_browser_cls.mock_app_path() == browser_config.path:
+          return mock_browser_cls
+      raise ValueError("Unknown browser path")
+
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        side_effect=mock_get_browser_cls) as get_browser_cls:
+      url = "http://test.com"
+      self.run_cli("loading", "--browser=chrome-dev", "--browser=chrome-beta",
+                   f"--urls={url}", "--env-validation=skip",
+                   f"--out-dir={self.out_dir}")
+      self.assertTrue(self.out_dir.exists())
+      get_browser_cls.assert_called()
+      # Example:  BROWSER / "cb.results.json"
+      result_files = list(
+          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+      self.assertEqual(len(result_files), 2)
+      versions = []
+      for result_file in result_files:
+        with result_file.open(encoding="utf-8") as f:
+          results = json.load(f)
+        versions.append(results["browser"]["version"])
+        self.assertIn("test.com", results["stories"])
+      self.assertTrue(len(set(versions)), 1)
+      for mock_browser_cls in mock_browsers:
+        self.assertIn(mock_browser_cls.VERSION, versions)
+
+  def test_browser_different_drivers(self):
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      if browser_config.driver.type == BrowserDriverType.IOS:
+        self.assertEqual(browser_config.path,
+                         mock_browser.MockChromeStable.mock_app_path())
+        return mock_browser.MockChromeStable
+      if browser_config.driver.type == BrowserDriverType.WEB_DRIVER:
+        self.assertEqual(browser_config.path,
+                         mock_browser.MockChromeBeta.mock_app_path())
+        return mock_browser.MockChromeBeta
+      self.assertEqual(browser_config.driver.type,
+                       BrowserDriverType.APPLE_SCRIPT)
+      self.assertEqual(browser_config.path,
+                       mock_browser.MockChromeDev.mock_app_path())
+      return mock_browser.MockChromeDev
+
+    self.platform.expect_sh(result=XCTRACE_DEVICES_SINGLE_OUTPUT)
+    with mock.patch.object(
+        BrowserVariantsConfig,
+        "get_browser_cls",
+        side_effect=mock_get_browser_cls) as get_browser_cls:
+      url = "http://test.com"
+      self.run_cli("loading", "--browser=ios:chrome-stable",
+                   "--browser=selenium:chrome-beta",
+                   "--browser=applescript:chrome-dev", f"--urls={url}",
+                   "--env-validation=skip", f"--out-dir={self.out_dir}")
+      self.assertTrue(self.out_dir.exists())
+      get_browser_cls.assert_called()
+      # Example:  BROWSER / "cb.results.json"
+      result_files = list(
+          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+      self.assertEqual(len(result_files), 3)
+      versions = []
+      for result_file in result_files:
+        with result_file.open(encoding="utf-8") as f:
+          results = json.load(f)
+        versions.append(results["browser"]["version"])
+        self.assertIn("test.com", results["stories"])
+      self.assertTrue(len(set(versions)), 1)
+      self.assertIn(mock_browser.MockChromeStable.VERSION, versions)
+      self.assertIn(mock_browser.MockChromeBeta.VERSION, versions)
+      self.assertIn(mock_browser.MockChromeDev.VERSION, versions)
+
+  def test_probe_invalid_inline_json_config(self):
+    with self.assertRaises(
+        argparse.ArgumentError) as cm, self.patch_get_browser():
+      self.run_cli("loading", "--probe=v8.log{invalid json: d a t a}",
+                   "--urls=cnn", "--env-validation=skip", "--throw")
+    message = str(cm.exception)
+    self.assertIn("{invalid json: d a t a}", message)
+
+  def test_probe_empty_inline_json_config(self):
+    js_flags = ["--log-foo", "--log-bar"]
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", "--probe=v8.log{}", f"--urls={url}",
+                   "--env-validation=skip")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        for flag in js_flags:
+          self.assertNotIn(flag, browser.js_flags)
+
+  def test_probe_inline_json_config(self):
+    js_flags = ["--log-foo", "--log-bar"]
+    json_config = json.dumps({"js_flags": js_flags})
+    with self.patch_get_browser():
+      url = "http://test.com"
+      self.run_cli("loading", f"--probe=v8.log{json_config}", f"--urls={url}",
+                   "--env-validation=skip")
+      for browser in self.browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        for flag in js_flags:
+          self.assertIn(flag, browser.js_flags)
+
+  def test_env_config_name(self):
+    with self.patch_get_browser():
+      self.run_cli("loading", "--env=strict", "--urls=http://test.com",
+                   "--env-validation=skip", "--throw")
+
+  def test_env_config_inline_hjson(self):
+    with self.patch_get_browser():
+      self.run_cli("loading", "--env={\"power_use_battery\":false}",
+                   "--urls=http://test.com", "--env-validation=skip")
+
+  def test_env_config_inline_invalid(self):
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("loading", "--env=not a valid name",
+                   "--urls=http://test.com", "--env-validation=skip")
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("loading", "--env={not valid hjson}",
+                   "--urls=http://test.com", "--env-validation=skip")
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("loading", "--env={unknown_property:1}",
+                   "--urls=http://test.com", "--env-validation=skip")
+
+  def test_conflicting_driver_path(self):
+    mock_browsers: List[Type[mock_browser.MockBrowser]] = [
+        mock_browser.MockChromeStable,
+        mock_browser.MockFirefox,
+    ]
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
+      for mock_browser_cls in mock_browsers:
+        if mock_browser_cls.mock_app_path() == browser_config.path:
+          return mock_browser_cls
+      raise ValueError("Unknown browser path")
+
+    driver_path = self.out_dir / "driver"
+    self.fs.create_file(driver_path, st_size=1024)
+    with self.assertRaises(LateArgumentError) as cm:
+      with mock.patch.object(
+          BrowserVariantsConfig,
+          "get_browser_cls",
+          side_effect=mock_get_browser_cls):
+        self.run_cli("loading", "--browser=chrome", "--browser=firefox",
+                     f"--driver-path={driver_path}", "--urls=http://test.com",
+                     "--env-validation=skip", "--throw")
+    self.assertIn("--driver-path", str(cm.exception))
+
+  def test_env_config_invalid_file(self):
+    config = pathlib.Path("/test.config.hjson")
+    # No "env" property
+    with config.open("w", encoding="utf-8") as f:
+      hjson.dump({}, f)
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("loading", f"--env-config={config}",
+                   "--urls=http://test.com", "--env-validation=skip")
+    # "env" not a dict
+    with config.open("w", encoding="utf-8") as f:
+      hjson.dump({"env": []}, f)
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("loading", f"--env-config={config}",
+                   "--urls=http://test.com", "--env-validation=skip")
+    with config.open("w", encoding="utf-8") as f:
+      hjson.dump({"env": {"unknown_property_name": 1}}, f)
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("loading", f"--env-config={config}",
+                   "--urls=http://test.com", "--env-validation=skip")
+
+  def test_parse_env_config_file(self):
+    config = pathlib.Path("/test.config.hjson")
+    with config.open("w", encoding="utf-8") as f:
+      hjson.dump({"env": {}}, f)
+    with self.patch_get_browser():
+      self.run_cli("loading", f"--env-config={config}",
+                   "--urls=http://test.com", "--env-validation=skip")
+
+  def test_env_invalid_inline_and_file(self):
+    config = pathlib.Path("/test.config.hjson")
+    with config.open("w", encoding="utf-8") as f:
+      hjson.dump({"env": {}}, f)
+    with self.assertRaises(SysExitTestException):
+      self.run_cli("loading", "--env=strict", f"--env-config={config}",
+                   "--urls=http://test.com", "--env-validation=skip")
+
+  def test_invalid_splashscreen(self):
+    with self.assertRaises(argparse.ArgumentError) as cm:
+      self.run_cli("loading", "--browser=chrome", "--urls=http://test.com",
+                   "--env-validation=skip", "--splash-screen=unknown-value",
+                   "--throw")
+    message = str(cm.exception)
+    self.assertIn("--splash-screen", message)
+    self.assertIn("unknown-value", message)
+
+  def test_splash_screen_none(self):
+    with self.mock_chrome_stable():
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
+                         "--throw", "--splash-screen=none")
+      for browser in cli.runner.browsers:
+        assert isinstance(browser, mock_browser.MockChromeStable)
+        self.assertEqual(browser.splash_screen, splash_screen.SplashScreen.NONE)
+        self.assertListEqual([url], browser.url_list)
+        self.assertEqual(len(browser.js_flags), 0)
+
+  def test_splash_screen_minimal(self):
+    with self.mock_chrome_stable():
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
+                         "--throw", "--splash-screen=minimal")
+      for browser in cli.runner.browsers:
+        assert isinstance(browser, mock_browser.MockChromeStable)
+        self.assertEqual(browser.splash_screen,
+                         splash_screen.SplashScreen.MINIMAL)
+        self.assertEqual(len(browser.url_list), 3)
+        self.assertIn(url, browser.url_list)
+        self.assertEqual(len(browser.js_flags), 0)
+
+  def test_splash_screen_url(self):
+    with self.mock_chrome_stable():
+      splash_url = "http://splash.com"
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
+                         "--throw", f"--splash-screen={splash_url}")
+      for browser in cli.runner.browsers:
+        assert isinstance(browser, mock_browser.MockChromeStable)
+        self.assertIsInstance(browser.splash_screen,
+                              splash_screen.URLSplashScreen)
+        self.assertEqual(len(browser.url_list), 3)
+        self.assertEqual(splash_url, browser.url_list[0])
+        self.assertEqual(len(browser.js_flags), 0)
+
+  def test_viewport_invalid(self):
+    with self.assertRaises(argparse.ArgumentError) as cm:
+      self.run_cli("loading", "--browser=chrome", "--urls=http://test.com",
+                   "--env-validation=skip", "--viewport=-123", "--throw")
+    message = str(cm.exception)
+    self.assertIn("--viewport", message)
+    self.assertIn("-123", message)
+
+  def test_viewport_maximized(self):
+    with self.mock_chrome_stable():
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
+                         "--throw", "--viewport=maximized")
+      for browser in cli.runner.browsers:
+        assert isinstance(browser, mock_browser.MockChromeStable)
+        self.assertEqual(browser.viewport, viewport.Viewport.MAXIMIZED)
+        self.assertEqual(len(browser.url_list), 3)
+        self.assertEqual(len(browser.js_flags), 0)
+
+  def test_powersampler_invalid_multiple_runs(self):
+    powersampler_bin = self.out_dir / "powersampler"
+    self.fs.create_file(powersampler_bin, st_size=1024)
+    config_str = json.dumps({"bin_path": str(powersampler_bin)})
+    with self.mock_chrome_stable():
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        self.run_cli("loading", "--browser=chrome",
+                     f"--probe=powersampler:{config_str}", "--repeat=10",
+                     "--urls=http://test.com", "--env-validation=skip",
+                     "--throw")
+      self.assertIn("powersampler", str(cm.exception))
+
+  def test_fast(self):
+    with self.mock_chrome_stable():
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--throw", "--fast")
+      self.assertEqual(cli.args.splash_screen, splash_screen.SplashScreen.NONE)
+      self.assertEqual(cli.args.cool_down_time, dt.timedelta(0))
+      self.assertEqual(cli.args.env_validation, ValidationMode.SKIP)
+      for browser in cli.runner.browsers:
+        assert isinstance(browser, mock_browser.MockChromeStable)
+        self.assertIs(browser.splash_screen, splash_screen.SplashScreen.NONE)
+        self.assertListEqual(browser.url_list, [url])
+        self.assertEqual(len(browser.js_flags), 0)
+
+  def test_create_symlinks(self):
+    with self.mock_chrome_stable():
+      out_dir = self.out_dir / "create_symlinks"
+      self.assertFalse(out_dir.exists())
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--throw", "--fast",
+                         f"--out-dir={out_dir}")
+      self.assertTrue(cli.args.create_symlinks)
+      links = list(out_dir.glob("*/sessions/*"))
+      self.assertEqual(len(links), 1)
+      self.assertTrue(links[0].is_symlink())
+      links = list(out_dir.glob("*/stories/**/session"))
+      self.assertEqual(len(links), 1)
+      self.assertTrue(links[0].is_symlink())
+
+  def test_no_symlinks(self):
+    with self.mock_chrome_stable():
+      out_dir = self.out_dir / "no_symlinks"
+      self.assertFalse(out_dir.exists())
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--throw", "--fast",
+                         "--no-symlinks", f"--out-dir={out_dir}")
+      self.assertFalse(cli.args.create_symlinks)
+      for dirpath, dirnames, filenames in os.walk(out_dir):
+        dirpath = pathlib.Path(dirpath)
+        for name in dirnames + filenames:
+          self.assertFalse((dirpath / name).is_symlink())
+
+  def test_debug(self):
+    with self.mock_chrome_stable():
+      url = "http://test.com"
+      cli = self.run_cli("loading", f"--urls={url}", "--debug")
+      self.assertTrue(cli.args.throw)
+      self.assertEqual(cli.args.verbosity, 3)
+      for browser in cli.runner.browsers:
+        assert isinstance(browser, mock_browser.MockChromeStable)
+        self.assertEqual(len(browser.url_list), 3)
+        self.assertEqual(len(browser.js_flags), 0)
+
+  def test_debugger_not_found(self):
+    searched_binaries = []
+    original_search_binary = plt.PLATFORM.search_binary
+
+    def mock_search_binary(binary) -> Optional[AnyPath]:
+      searched_binaries.append(binary)
+      if "gdb" in str(binary) or "lldb" in str(binary):
+        return None
+      return original_search_binary(binary)
+
+    for debugger in ("lldb", "gdb", "lldb"):
+      searched_binaries = []
+      with self.mock_chrome_stable(), mock.patch.object(
+          plt.PLATFORM, "search_binary", side_effect=mock_search_binary):
+        with self.assertRaises(ValueError) as cm:
+          self.run_cli("loading", "--urls=cnn", f"--{debugger}", "--throw")
+        self.assertIn(debugger, str(cm.exception))
+        _, _, stderr = self.run_cli_output(
+            "loading",
+            "--urls=cnn",
+            f"--{debugger}",
+            raises=SysExitTestException)
+        self.assertIn(f"Unknown binary: {debugger}", stderr)
+        self.assertIn(pathlib.Path(debugger), searched_binaries)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/test_cli_slow.py b/tests/crossbench/cli/test_cli_slow.py
new file mode 100644
index 0000000..7a67833
--- /dev/null
+++ b/tests/crossbench/cli/test_cli_slow.py
@@ -0,0 +1,200 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import json
+import pathlib
+from typing import Dict, List, Type
+from unittest import mock
+
+import hjson
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCliTestCase, SysExitTestException
+
+from crossbench import __version__
+from crossbench.browsers.settings import Settings
+from crossbench.cli.cli import CrossBenchCLI
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.cli.config.driver import BrowserDriverType
+from crossbench.network.local_file_server import LocalFileNetwork
+from crossbench.probes import internal
+
+
+class CliSlowTestCase(BaseCliTestCase):
+  """Collection of slower tests that are not worth running
+  as part of the presubmit"""
+
+  def test_subcommand_help(self):
+    for benchmark_cls in CrossBenchCLI.BENCHMARKS:
+      subcommands = (benchmark_cls.NAME,) + benchmark_cls.aliases()
+      for subcommand in subcommands:
+        with self.assertRaises(SysExitTestException) as cm:
+          self.run_cli(subcommand, "--help")
+        self.assertEqual(cm.exception.exit_code, 0)
+        _, stdout, stderr = self.run_cli_output(
+            subcommand, "--help", raises=SysExitTestException)
+        self.assertFalse(stderr)
+        self.assertIn("--env-validation ENV_VALIDATION", stdout)
+
+  def test_subcommand_help_subcommand(self):
+    for benchmark_cls in CrossBenchCLI.BENCHMARKS:
+      subcommands = (benchmark_cls.NAME,) + benchmark_cls.aliases()
+      for subcommand in subcommands:
+        with self.assertRaises(SysExitTestException) as cm:
+          self.run_cli(subcommand, "help")
+        self.assertEqual(cm.exception.exit_code, 0)
+        _, stdout, stderr = self.run_cli_output(
+            subcommand, "help", raises=SysExitTestException)
+        self.assertFalse(stderr)
+        self.assertIn("--env-validation ENV_VALIDATION", stdout)
+
+  def test_subcommand_describe_subcommand(self):
+    for benchmark_cls in CrossBenchCLI.BENCHMARKS:
+      subcommands = (benchmark_cls.NAME,) + benchmark_cls.aliases()
+      for subcommand in subcommands:
+        with self.assertRaises(SysExitTestException) as cm:
+          self.run_cli(subcommand, "describe")
+        self.assertEqual(cm.exception.exit_code, 0)
+        _, stdout, stderr = self.run_cli_output(
+            subcommand, "describe", raises=SysExitTestException)
+        output = stderr + stdout
+        self.assertIn("See `describe benchmark ", output)
+
+  def test_browser_identifiers(self):
+    browsers: Dict[str, Type[mock_browser.MockBrowser]] = {
+        "chrome": mock_browser.MockChromeStable,
+        "chrome-stable": mock_browser.MockChromeStable,
+        "chr-stable": mock_browser.MockChromeStable,
+        "chrome-beta": mock_browser.MockChromeBeta,
+        "chr-beta": mock_browser.MockChromeBeta,
+        "chrome-dev": mock_browser.MockChromeDev,
+        "edge": mock_browser.MockEdgeStable,
+        "edge-stable": mock_browser.MockEdgeStable,
+        "edge-beta": mock_browser.MockEdgeBeta,
+        "edge-dev": mock_browser.MockEdgeDev,
+        "ff": mock_browser.MockFirefox,
+        "firefox": mock_browser.MockFirefox,
+        "firefox-dev": mock_browser.MockFirefoxDeveloperEdition,
+        "firefox-developer-edition": mock_browser.MockFirefoxDeveloperEdition,
+        "ff-dev": mock_browser.MockFirefoxDeveloperEdition,
+        "firefox-nightly": mock_browser.MockFirefoxNightly,
+        "ff-nightly": mock_browser.MockFirefoxNightly,
+        "ff-trunk": mock_browser.MockFirefoxNightly,
+    }
+    if not self.platform.is_linux:
+      browsers["chr-canary"] = mock_browser.MockChromeCanary
+      browsers["chrome-canary"] = mock_browser.MockChromeCanary
+      browsers["edge-canary"] = mock_browser.MockEdgeCanary
+    if self.platform.is_macos:
+      browsers.update({
+          "safari": mock_browser.MockSafari,
+          "sf": mock_browser.MockSafari,
+          "safari-technology-preview": mock_browser.MockSafariTechnologyPreview,
+          "sf-tp": mock_browser.MockSafariTechnologyPreview,
+          "tp": mock_browser.MockSafariTechnologyPreview,
+      })
+
+    for identifier, browser_cls in browsers.items():
+      out_dir = self.out_dir / identifier
+      self.assertFalse(out_dir.exists())
+      with mock.patch.object(
+          BrowserVariantsConfig, "get_browser_cls",
+          return_value=browser_cls) as get_browser_cls:
+        url = "http://test.com"
+        self.run_cli("loading", f"--browser={identifier}", f"--urls={url}",
+                     "--env-validation=skip", f"--out-dir={out_dir}")
+        self.assertTrue(out_dir.exists())
+        get_browser_cls.assert_called_once()
+        result_files = list(
+            out_dir.glob(f"**/{internal.ResultsSummaryProbe.NAME}.json"))
+        result_file = result_files[1]
+        with result_file.open(encoding="utf-8") as f:
+          results = json.load(f)
+        self.assertEqual(results["browser"]["version"], browser_cls.VERSION)
+        self.assertIn("test.com", results["stories"])
+
+  def test_config_file_with_network(self):
+    local_server_path = pathlib.Path("custom/server")
+    local_server_path.mkdir(parents=True)
+    self.fs.create_file(local_server_path / "index.html", st_size=100)
+    config_file = pathlib.Path("/config.hjson")
+    config_data = {
+        "probes": {},
+        "env": {},
+        "browsers": {},
+        "network": str(local_server_path),
+    }
+    with config_file.open("w", encoding="utf-8") as f:
+      hjson.dump(config_data, f)
+
+    browsers = []
+
+    def get_browser(self, args: argparse.Namespace):
+      session = Settings(
+          platform=self.platform, network=args.network.create(self.platform))
+      browsers = [
+          mock_browser.MockChromeDev("dev", settings=session),
+      ]
+      return browsers
+
+    with mock.patch.object(CrossBenchCLI, "_get_browsers", get_browser):
+      url = "http://test.com"
+      self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
+                   "--env-validation=skip")
+      for browser in browsers:
+        self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
+        assert isinstance(browser.network, LocalFileNetwork)
+        network: LocalFileNetwork = browser.network
+        self.assertFalse(network.is_live)
+        self.assertEqual(network.path, local_server_path)
+
+  def test_multiple_browser_compatible_flags(self):
+    mock_browsers: List[Type[mock_browser.MockBrowser]] = [
+        mock_browser.MockChromeStable,
+        mock_browser.MockFirefox,
+        mock_browser.MockChromeDev,
+    ]
+
+    def mock_get_browser_cls(browser_config: BrowserConfig):
+      self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
+      for mock_browser_cls in mock_browsers:
+        if mock_browser_cls.mock_app_path() == browser_config.path:
+          return mock_browser_cls
+      raise ValueError("Unknown browser path")
+
+    for chrome_flag in ("--js-flags=--no-opt", "--enable-features=Foo",
+                        "--disable-features=bar"):
+      # Fail for chrome flags for non-chrome browser
+      with self.assertRaises(argparse.ArgumentTypeError), mock.patch.object(
+          BrowserVariantsConfig,
+          "get_browser_cls",
+          side_effect=mock_get_browser_cls):
+        self.run_cli("loading", "--urls=http://test.com",
+                     "--env-validation=skip", "--throw", "--browser=firefox",
+                     chrome_flag)
+      # Fail for mixed browsers and chrome flags
+      with self.assertRaises(argparse.ArgumentTypeError), mock.patch.object(
+          BrowserVariantsConfig,
+          "get_browser_cls",
+          side_effect=mock_get_browser_cls):
+        self.run_cli("loading", "--urls=http://test.com",
+                     "--env-validation=skip", "--throw", "--browser=chrome",
+                     "--browser=firefox", chrome_flag)
+      with self.assertRaises(argparse.ArgumentTypeError), mock.patch.object(
+          BrowserVariantsConfig,
+          "get_browser_cls",
+          side_effect=mock_get_browser_cls):
+        self.run_cli("loading", "--urls=http://test.com",
+                     "--env-validation=skip", "--throw", "--browser=chrome",
+                     "--browser=firefox", "--", chrome_flag)
+    # Flags for the same type are allowed.
+    with self.patch_get_browser():
+      self.run_cli("loading", "--urls=http://test.com", "--env-validation=skip",
+                   "--throw", "--browser=chrome", "--browser=chrome-dev", "--",
+                   "--js-flags=--no-opt")
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/helper/__init__.py b/tests/crossbench/helper/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/helper/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/helper/test_path_finder.py b/tests/crossbench/helper/test_path_finder.py
new file mode 100644
index 0000000..abbebf1
--- /dev/null
+++ b/tests/crossbench/helper/test_path_finder.py
@@ -0,0 +1,129 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import os
+import pathlib
+from unittest import mock
+
+from crossbench.helper.path_finder import (ChromiumBuildBinaryFinder,
+                                           ChromiumCheckoutFinder,
+                                           V8CheckoutFinder, V8ToolsFinder)
+from tests import test_helper
+from tests.crossbench.base import BaseCrossbenchTestCase
+from tests.crossbench.mock_helper import (LinuxMockPlatform, MacOsMockPlatform,
+                                          WinMockPlatform)
+
+
+class BaseCheckoutTestCase(BaseCrossbenchTestCase):
+
+  def _add_v8_checkout_files(self, checkout_dir: pathlib.Path) -> None:
+    self.assertIsNone(V8CheckoutFinder(self.platform).path)
+    (checkout_dir / ".git").mkdir(parents=True)
+    self.assertIsNone(V8CheckoutFinder(self.platform).path)
+    self.fs.create_file(checkout_dir / "include" / "v8.h", st_size=100)
+
+  def _add_chrome_checkout_files(self, checkout_dir: pathlib.Path) -> None:
+    self.assertIsNone(ChromiumCheckoutFinder(self.platform).path)
+    self._add_v8_checkout_files(checkout_dir / "v8")
+    (checkout_dir / ".git").mkdir(parents=True)
+    self.assertIsNone(ChromiumCheckoutFinder(self.platform).path)
+    (checkout_dir / "chrome").mkdir(parents=True)
+
+
+class V8CheckoutFinderTestCase(BaseCheckoutTestCase):
+
+  def test_find_none(self):
+    self.assertIsNone(V8CheckoutFinder(self.platform).path)
+
+  def test_D8_PATH(self):
+    with mock.patch.dict(os.environ, {}, clear=True):
+      self.assertIsNone(V8CheckoutFinder(self.platform).path)
+    candidate_dir = pathlib.Path("/custom/v8/")
+    d8_path = candidate_dir / "out/x64.release/d8"
+    with mock.patch.dict(os.environ, {"D8_PATH": str(d8_path)}, clear=True):
+      self.assertIsNone(V8CheckoutFinder(self.platform).path)
+    self._add_v8_checkout_files(candidate_dir)
+    with mock.patch.dict(os.environ, {"D8_PATH": str(d8_path)}, clear=True):
+      self.assertEqual(
+          pathlib.Path(V8CheckoutFinder(self.platform).path), candidate_dir)
+    # Still NONE without custom D8_PATH env var.
+    self.assertIsNone(V8CheckoutFinder(self.platform).path)
+
+  def test_known_location(self):
+    checkout_dir = pathlib.Path.home() / "v8/v8"
+    self.assertIsNone(V8CheckoutFinder(self.platform).path)
+    checkout_dir.mkdir(parents=True)
+    self._add_v8_checkout_files(checkout_dir)
+    self.assertEqual(V8CheckoutFinder(self.platform).path, checkout_dir)
+
+  def test_module_relative(self):
+    with mock.patch.dict(os.environ, {}, clear=True):
+      self.assertIsNone(V8CheckoutFinder(self.platform).path)
+      path = pathlib.Path(__file__)
+      self.assertFalse(path.exists())
+      if "google3" in path.parts:
+        fake_chrome_root = path.parents[6]
+      else:
+        # pylint: disable=line-too-long
+        # In:   chromium/src/third_party/crossbench/tests/crossbench/probes/test_helper.py
+        # Out:  chromium/src
+        fake_chrome_root = path.parents[5]
+      checkout_dir = fake_chrome_root / "v8"
+      self.assertIsNone(V8CheckoutFinder(self.platform).path)
+      self._add_chrome_checkout_files(fake_chrome_root)
+      self.assertIsNotNone(ChromiumCheckoutFinder(self.platform).path)
+      self.assertEqual(
+          pathlib.Path(V8CheckoutFinder(self.platform).path), checkout_dir)
+
+
+class ChromiumBuildBinaryFinderTestCase(BaseCheckoutTestCase):
+
+  def test_find_none(self):
+    finder = ChromiumBuildBinaryFinder(self.platform, "custom_binary")
+    self.assertIsNone(finder.path)
+    self.assertIsNone(finder.path)
+    self.assertEqual(finder.binary_name, "custom_binary")
+    candidate_dir = pathlib.Path("/chr/src/out/x64.Release")
+    self.assertIsNone(
+        ChromiumBuildBinaryFinder(self.platform, "custom_binary",
+                                  (candidate_dir,)).path)
+
+  def test_find_candidate(self):
+    checkout_dir = pathlib.Path("/foo/bar/chr/src/")
+    candidate = checkout_dir / "out/x64.Release/custom_binary"
+    self.fs.create_file(candidate, st_size=100)
+    self.assertTrue(candidate.is_file)
+    self.assertIsNone(
+        ChromiumBuildBinaryFinder(self.platform, "custom_binary",
+                                  (candidate.parent,)).path)
+    self._add_chrome_checkout_files(checkout_dir)
+    self.assertEqual(
+        ChromiumBuildBinaryFinder(self.platform, "custom_binary",
+                                  (candidate.parent,)).path, candidate)
+
+  def test_find_default(self):
+    checkout_dir = pathlib.Path.home() / "Documents/chromium/src"
+    candidate = checkout_dir / "out/Release/custom_binary"
+    self.fs.create_file(candidate, st_size=100)
+    assert checkout_dir.is_dir()
+    self._add_chrome_checkout_files(checkout_dir)
+    self.assertEqual(
+        ChromiumBuildBinaryFinder(self.platform, "custom_binary").path,
+        candidate)
+
+
+class V8ToolsFinderTestCase(BaseCheckoutTestCase):
+
+  def test_defaults(self):
+    # TODO: use AndroidAdbMockPlatform(self.platform) as well
+    for platform in (self.platform, LinuxMockPlatform(), MacOsMockPlatform(),
+                     WinMockPlatform()):
+      finder = V8ToolsFinder(platform)
+      self.assertIsNone(finder.d8_binary)
+      self.assertIsNone(finder.v8_checkout)
+      self.assertIsNone(finder.tick_processor)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/mock_browser.py b/tests/crossbench/mock_browser.py
new file mode 100644
index 0000000..5d34f3c
--- /dev/null
+++ b/tests/crossbench/mock_browser.py
@@ -0,0 +1,496 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import contextlib
+import copy
+import dataclasses
+import pathlib
+from typing import (TYPE_CHECKING, Any, Iterator, List, Optional, Tuple, Type,
+                    Union, cast)
+
+from crossbench import plt
+from crossbench.browsers.all import Chrome, Chromium, Edge, Firefox, Safari
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.browser import Browser
+from crossbench.browsers.settings import Settings
+from crossbench.flags.chrome import ChromeFeatures, ChromeFlags
+from crossbench.flags.js_flags import JSFlags
+from crossbench.network.base import Network
+from crossbench.plt.android_adb import AndroidAdbPlatform
+
+if TYPE_CHECKING:
+  import datetime as dt
+  import re
+
+  from crossbench.cli.config.secrets import Secret
+  from crossbench.flags.base import FlagsData
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+@dataclasses.dataclass(frozen=True)
+class JsInvocation:
+  result: Any
+  script: Optional[Union[str, re.Pattern]] = None
+  arguments: Optional[List[Any]] = None
+  timeout: Optional[dt.timedelta] = None
+
+
+class MockNetwork(Network):
+
+  @contextlib.contextmanager
+  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+    with super().open(session):
+      assert session.browser.network is self
+      yield self
+      assert self.is_running
+
+
+class MockBrowser(Browser, metaclass=abc.ABCMeta):
+  MACOS_BIN_NAME: str = ""
+  VERSION: str = "100.22.33.44"
+
+  @classmethod
+  @abc.abstractmethod
+  def mock_app_path(cls, platform: plt.Platform) -> pathlib.Path:
+    pass
+
+  @classmethod
+  def setup_fs(cls, fs, platform: plt.Platform = plt.PLATFORM) -> None:
+    app_path = cls.mock_app_path(platform)
+    macos_bin_name = app_path.stem
+    if cls.MACOS_BIN_NAME:
+      macos_bin_name = cls.MACOS_BIN_NAME
+    cls.setup_bin(fs, app_path, macos_bin_name, platform)
+
+  @classmethod
+  def setup_bin(cls,
+                fs,
+                bin_path: pathlib.Path,
+                macos_bin_name: str,
+                platform: plt.Platform = plt.PLATFORM) -> None:
+    if platform.is_macos:
+      assert bin_path.suffix == ".app"
+      bin_path = bin_path / "Contents" / "MacOS" / macos_bin_name
+    elif platform.is_win:
+      assert bin_path.suffix == ".exe"
+    if not bin_path.exists():
+      fs.create_file(bin_path)
+
+  @classmethod
+  def default_flags(cls, initial_data: FlagsData = None) -> ChromeFlags:
+    return ChromeFlags(initial_data)
+
+  def __init__(self,
+               label: str,
+               path: Optional[pathlib.Path] = None,
+               settings: Optional[Settings] = None):
+    settings = settings or Settings()
+    platform = settings.platform
+    path = path or self.mock_app_path(platform)
+    self.app_path = path
+    if maybe_driver := settings.driver_path:
+      assert isinstance(maybe_driver, pathlib.Path) and maybe_driver.exists()
+    super().__init__(label, path, settings=settings)
+    self.url_list: List[str] = []
+    self.expected_js: List[JsInvocation] = []
+    self.expected_is_logged_in: List[Secret] = []
+    self.invoked_js: List[JsInvocation] = []
+    self.did_run: bool = False
+    self.clear_cache_dir: bool = False
+    self.tab_handler_generator = self._tab_handler_generator()
+    self.tab_list: List[int] = [next(self.tab_handler_generator)]
+
+  def expect_js(
+      self,
+      expected_js: Optional[JsInvocation] = None,
+      result: Any = None,
+  ) -> None:
+    if not expected_js:
+      self.expected_js.append(JsInvocation(result=result))
+      return
+    self.expected_js.append(expected_js)
+    return
+
+  def was_js_invoked(self, script: str) -> bool:
+    return any(script is invoked_js.script for invoked_js in self.invoked_js)
+
+  def expect_is_logged_in(self, secret: Secret) -> None:
+    self.expected_is_logged_in.append(secret)
+
+  def clear_cache(self) -> None:
+    pass
+
+  def start(self, session: BrowserSessionRunGroup) -> None:
+    assert not self._is_running
+    self._is_running = True
+    self.did_run = True
+
+  def force_quit(self) -> None:
+    if not self._is_running:
+      return
+    self._is_running = False
+
+  def _extract_version(self) -> str:
+    return self.VERSION
+
+  def user_agent(self) -> str:
+    return f"Mock Browser {self.type_name}, {self.VERSION}"
+
+  def show_url(self, url, target: Optional[str] = None) -> None:
+    self.url_list.append(url)
+
+  def current_window_id(self) -> str:
+    return str(self.tab_list[-1])
+
+  def _tab_handler_generator(self):
+    tab_handler = 0
+    while True:
+      yield tab_handler
+      tab_handler += 1
+
+  def switch_to_new_tab(self) -> None:
+    self.tab_list.append(next(self.tab_handler_generator))
+
+  def js(self, script, timeout: Optional[dt.timedelta] = None, arguments=()):
+    self.invoked_js.append(
+        JsInvocation(
+            result=None, script=script, arguments=arguments, timeout=timeout))
+
+    if self.expected_js is None:
+      return None
+
+    assert self.expected_js, ("Not enough expected_js available. "
+                              "Please add another expected_js entry for "
+                              f"arguments={arguments} \n"
+                              f"Script: {script}")
+    expectation = self.expected_js.pop(0)
+
+    if expectation.timeout:
+      assert expectation.timeout == timeout, (
+          f"JS timeout does not match. "
+          f"Expected: {expectation.timeout} Got: {timeout}")
+
+    if expected_script := expectation.script:
+      if isinstance(expected_script, str):
+        result = expected_script == script
+      else:
+        result = expected_script.fullmatch(script)
+      assert result, (f"JS script does not match expectation. "
+                      f"Expected: {expected_script} Got: {script}")
+
+    if expectation.arguments:
+      assert len(expectation.arguments) == len(arguments), (
+          f"Number of JS arguments does not match. "
+          f"Expected: {len(expectation.arguments)} Got: {len(arguments)}")
+
+      for expected_argument, argument in zip(expectation.arguments, arguments):
+        assert expected_argument == argument, (
+            f"Arguments do not match. "
+            f"Expected: {expected_argument} Got: {argument}")
+
+    # Return copies to avoid leaking data between repetitions.
+    return copy.deepcopy(expectation.result)
+
+  def is_logged_in(self, secret: Secret, strict: bool = False) -> bool:
+    for login in self.expected_is_logged_in:
+      if login.type == secret.type:
+        if login.username == secret.username:
+          return True
+        if strict:
+          raise RuntimeError("Secret mismatch")
+    return False
+
+def app_root(platform: plt.Platform) -> pathlib.Path:
+  if platform.is_macos:
+    return pathlib.Path("/Applications")
+  if platform.is_win:
+    return pathlib.Path("C:/Program Files")
+  return pathlib.Path("/usr/bin")
+
+
+class MockChromiumBrowser(MockBrowser, metaclass=abc.ABCMeta):
+
+  def _setup_flags(self, settings: Settings) -> ChromeFlags:
+    flags = ChromeFlags(settings.flags)
+    flags.js_flags.update(settings.js_flags)
+    return flags
+
+  @property
+  def chrome_flags(self) -> ChromeFlags:
+    chrome_flags = cast(ChromeFlags, self.flags)
+    assert isinstance(chrome_flags, ChromeFlags)
+    return chrome_flags
+
+  @property
+  def js_flags(self) -> JSFlags:
+    return self.chrome_flags.js_flags
+
+  @property
+  def features(self) -> ChromeFeatures:
+    return self.chrome_flags.features
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
+
+
+# Inject MockBrowser into the browser hierarchy for easier testing.
+Chromium.register(MockChromiumBrowser)
+
+
+class MockChromeBrowser(MockChromiumBrowser, metaclass=abc.ABCMeta):
+
+  @property
+  def type_name(self) -> str:
+    return "chrome"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
+
+
+Chrome.register(MockChromeBrowser)
+if not TYPE_CHECKING:
+  assert issubclass(MockChromeBrowser, Chrome)
+
+
+class MockChromeStable(MockChromeBrowser):
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Google Chrome.app"
+    if platform.is_win:
+      return app_root(platform) / "Google/Chrome/Application/chrome.exe"
+    return app_root(platform) / "google-chrome"
+
+
+if not TYPE_CHECKING:
+  assert issubclass(MockChromeStable, Chromium)
+  assert issubclass(MockChromeStable, Chrome)
+
+
+class MockChromeAndroidStable(MockChromeStable):
+
+  @property
+  def platform(self) -> AndroidAdbPlatform:
+    assert isinstance(
+        self._platform,
+        AndroidAdbPlatform), (f"Invalid platform: {self._platform}")
+    return cast(AndroidAdbPlatform, self._platform)
+
+  def _resolve_binary(self, path: pathlib.Path) -> pathlib.Path:
+    return path
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return (BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
+            | BrowserAttributes.MOBILE)
+
+
+class MockChromeBeta(MockChromeBrowser):
+  VERSION = "101.22.33.44"
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Google Chrome Beta.app"
+    if platform.is_win:
+      return app_root(platform) / "Google/Chrome Beta/Application/chrome.exe"
+    return app_root(platform) / "google-chrome-beta"
+
+
+class MockChromeDev(MockChromeBrowser):
+  VERSION = "102.22.33.44"
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Google Chrome Dev.app"
+    if platform.is_win:
+      return app_root(platform) / "Google/Chrome Dev/Application/chrome.exe"
+    return app_root(platform) / "google-chrome-unstable"
+
+
+class MockChromeCanary(MockChromeBrowser):
+  VERSION = "103.22.33.44"
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Google Chrome Canary.app"
+    if platform.is_win:
+      return app_root(platform) / "Google/Chrome SxS/Application/chrome.exe"
+    return app_root(platform) / "google-chrome-canary"
+
+
+class MockEdgeBrowser(MockChromiumBrowser, metaclass=abc.ABCMeta):
+
+  @property
+  def type_name(self) -> str:
+    return "edge"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.EDGE | BrowserAttributes.CHROMIUM_BASED
+
+
+Edge.register(MockEdgeBrowser)
+if not TYPE_CHECKING:
+  assert issubclass(MockEdgeBrowser, Chromium)
+  assert issubclass(MockEdgeBrowser, Edge)
+
+
+class MockEdgeStable(MockEdgeBrowser):
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Microsoft Edge.app"
+    if platform.is_win:
+      return app_root(platform) / "Microsoft/Edge/Application/msedge.exe"
+    return app_root(platform) / "microsoft-edge"
+
+
+class MockEdgeBeta(MockEdgeBrowser):
+  VERSION = "101.22.33.44"
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Microsoft Edge Beta.app"
+    if platform.is_win:
+      return app_root(platform) / "Microsoft/Edge Beta/Application/msedge.exe"
+    return app_root(platform) / "microsoft-edge-beta"
+
+
+class MockEdgeDev(MockEdgeBrowser):
+  VERSION = "102.22.33.44"
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Microsoft Edge Dev.app"
+    if platform.is_win:
+      return app_root(platform) / "Microsoft/Edge Dev/Application/msedge.exe"
+    return app_root(platform) / "microsoft-edge-dev"
+
+
+class MockEdgeCanary(MockEdgeBrowser):
+  VERSION = "103.22.33.44"
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Microsoft Edge Canary.app"
+    if platform.is_win:
+      return app_root(platform) / "Microsoft/Edge SxS/Application/msedge.exe"
+    return app_root(platform) / "unsupported/msedge-canary"
+
+
+class MockSafariBrowser(MockBrowser, metaclass=abc.ABCMeta):
+
+  @property
+  def type_name(self) -> str:
+    return "safari"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.SAFARI
+
+
+Safari.register(MockSafariBrowser)
+if not TYPE_CHECKING:
+  assert issubclass(MockSafariBrowser, Safari)
+
+
+class MockSafari(MockSafariBrowser):
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Safari.app"
+    if platform.is_win:
+      return app_root(platform) / "Unsupported/Safari.exe"
+    return pathlib.Path("/unsupported-platform/Safari")
+
+
+class MockSafariTechnologyPreview(MockSafariBrowser):
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Safari Technology Preview.app"
+    if platform.is_win:
+      return app_root(platform) / "Unsupported/Safari Technology Preview.exe"
+    return pathlib.Path("/unsupported-platform/Safari Technology Preview")
+
+
+class MockFirefoxBrowser(MockBrowser, metaclass=abc.ABCMeta):
+
+  @property
+  def type_name(self) -> str:
+    return "firefox"
+
+  @property
+  def attributes(self) -> BrowserAttributes:
+    return BrowserAttributes.FIREFOX
+
+
+Firefox.register(MockFirefoxBrowser)
+if not TYPE_CHECKING:
+  assert issubclass(MockFirefoxBrowser, Firefox)
+
+
+class MockFirefox(MockFirefoxBrowser):
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Firefox.app"
+    if platform.is_win:
+      return app_root(platform) / "Mozilla Firefox/firefox.exe"
+    return app_root(platform) / "firefox"
+
+
+class MockFirefoxDeveloperEdition(MockFirefoxBrowser):
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Firefox Developer Edition.app"
+    if platform.is_win:
+      return app_root(platform) / "Firefox Developer Edition/firefox.exe"
+    return app_root(platform) / "firefox-developer-edition"
+
+
+class MockFirefoxNightly(MockFirefoxBrowser):
+
+  @classmethod
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return app_root(platform) / "Firefox Nightly.app"
+    if platform.is_win:
+      return app_root(platform) / "Firefox Nightly/firefox.exe"
+    return app_root(platform) / "firefox-trunk"
+
+
+ALL: Tuple[Type[MockBrowser], ...] = (
+    MockChromeCanary,
+    MockChromeDev,
+    MockChromeBeta,
+    MockChromeStable,
+    MockEdgeCanary,
+    MockEdgeDev,
+    MockEdgeBeta,
+    MockEdgeStable,
+    MockSafari,
+    MockSafariTechnologyPreview,
+    MockFirefox,
+    MockFirefoxDeveloperEdition,
+    MockFirefoxNightly,
+)
diff --git a/tests/crossbench/mock_helper.py b/tests/crossbench/mock_helper.py
new file mode 100644
index 0000000..3311c5c
--- /dev/null
+++ b/tests/crossbench/mock_helper.py
@@ -0,0 +1,310 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import collections
+import datetime as dt
+import pathlib
+import shlex
+from subprocess import CompletedProcess
+from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Mapping,
+                    Optional, Sequence, Union)
+
+import psutil
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.benchmarks.base import SubStoryBenchmark
+from crossbench.cli.cli import CrossBenchCLI
+from crossbench.plt.android_adb import Adb, AndroidAdbPlatform
+from crossbench.plt.base import MachineArch, Platform
+from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
+from crossbench.plt.linux import LinuxPlatform
+from crossbench.plt.linux_ssh import LinuxSshPlatform
+from crossbench.plt.macos import MacOSPlatform
+from crossbench.plt.win import WinPlatform
+from crossbench.runner.run import Run
+from crossbench.stories.story import Story
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import ListCmdArgs, TupleCmdArgs
+  from crossbench.runner.runner import Runner
+
+
+GIB = 1014**3
+
+
+
+class MockPlatformMixin:
+
+  def __init__(self, *args, is_battery_powered=False, **kwargs):
+    self._is_battery_powered = is_battery_powered
+    # Cache some helper properties that might fail under pyfakefs.
+    self._sh_cmds: List[TupleCmdArgs] = []
+    self._expected_sh_cmds: Optional[List[TupleCmdArgs]] = None
+    self._sh_results: List[bytes] = []
+    self.file_contents: Dict[pth.AnyPath, List[str]] = (
+        collections.defaultdict(list))
+    self.sleeps: List[dt.timedelta] = []
+    super().__init__(*args, **kwargs)
+
+  def expect_sh(self,
+                *args: Union[str, pathlib.Path],
+                result: Union[str, bytes] = "") -> None:
+    if args:
+      if self._expected_sh_cmds is None:
+        self._expected_sh_cmds = []
+      self._expected_sh_cmds.append(self._convert_sh_args(*args))
+    if isinstance(result, str):
+      result = result.encode("utf-8")
+    assert isinstance(result, bytes)
+    self._sh_results.append(result)
+
+  def _convert_sh_args(self, *args: Union[str, pathlib.Path]) -> TupleCmdArgs:
+    converted_args : ListCmdArgs = []
+    for arg in args:
+      if not isinstance(arg, (str, pathlib.PurePath)):
+        arg = str(arg)
+      converted_args.append(arg)
+    return tuple(converted_args)
+
+  @property
+  def sh_results(self) -> List[bytes]:
+    return list(self._sh_results)
+
+  @sh_results.setter
+  def sh_results(self, results: Iterable[Union[str, bytes]]) -> None:
+    assert not self._sh_results, "Trying to override non-consumed results"
+    assert not self._expected_sh_cmds, (
+        "expect_sh() cannot be used together with sh_results")
+    for result in results:
+      self.expect_sh(result=result)
+
+  @property
+  def sh_cmds(self) -> List[TupleCmdArgs]:
+    return list(self._sh_cmds)
+
+  @property
+  def expected_sh_cmds(self) -> Optional[List[TupleCmdArgs]]:
+    if self._expected_sh_cmds is None:
+      return None
+    return list(self._expected_sh_cmds)
+
+  @property
+  def name(self) -> str:
+    return f"mock.{super().name}"
+
+  @property
+  def machine(self) -> MachineArch:
+    return MachineArch.ARM_64
+
+  @property
+  def version(self) -> str:
+    return "1.2.3.4.5"
+
+  @property
+  def device(self) -> str:
+    return "TestBook Pro"
+
+  @property
+  def cpu(self) -> str:
+    return "Mega CPU @ 3.00GHz"
+
+  @property
+  def is_battery_powered(self) -> bool:
+    return self._is_battery_powered
+
+  def is_thermal_throttled(self) -> bool:
+    return False
+
+  def disk_usage(self, path: pathlib.Path):
+    del path
+    # pylint: disable=protected-access
+    return psutil._common.sdiskusage(
+        total=GIB * 100, used=20 * GIB, free=80 * GIB, percent=20)
+
+  def cpu_usage(self) -> float:
+    return 0.1
+
+  def cpu_details(self) -> Dict[str, Any]:
+    return {"physical cores": 2, "logical cores": 4, "info": self.cpu}
+
+  def set_file_contents(self,
+                        file: pth.AnyPathLike,
+                        data: str,
+                        encoding: str = "utf-8") -> None:
+    del encoding
+    file_path = self.path(file)
+    self.file_contents[file_path].append(data)
+
+  def system_details(self):
+    return {"CPU": "20-core 3.1 GHz"}
+
+  def sleep(self, duration):
+    self.sleeps.append(duration)
+
+  def processes(self, attrs=()):
+    del attrs
+    return []
+
+  def process_children(self, parent_pid: int, recursive=False):
+    del parent_pid, recursive
+    return []
+
+  def foreground_process(self):
+    return None
+
+  def search_platform_binary(
+      self,
+      name: str,
+      macos: Sequence[str] = (),
+      win: Sequence[str] = (),
+      linux: Sequence[str] = ()
+  ) -> pth.AnyPath:
+    del macos, win, linux
+    return self.path(f"/usr/bin/{name}")
+
+  def sh_stdout_bytes(self,
+                      *args: Union[str, pathlib.Path],
+                      shell: bool = False,
+                      quiet: bool = False,
+                      stdin=None,
+                      env: Optional[Mapping[str, str]] = None,
+                      check: bool = True) -> bytes:
+    del shell, quiet, stdin, env, check
+    if self._expected_sh_cmds is not None:
+      assert self._expected_sh_cmds, (
+          f"Missing expected sh_cmds, but got: {args}")
+      # Convert all args to str first, sh accepts both str and Paths.
+      expected = tuple(map(str, self._expected_sh_cmds[0]))
+      str_args = tuple(map(str, args))
+      assert expected == str_args, (f"After {len(self._sh_cmds)} cmds: \n"
+                                    f"  expected: {expected}\n"
+                                    f"  got:      {str_args}")
+      self._expected_sh_cmds.pop(0)
+    self._sh_cmds.append(args)
+    if not self._sh_results:
+      cmd = shlex.join(map(str, args))
+      raise ValueError(f"After {len(self._sh_cmds)} cmds: "
+                       f"MockPlatform has no more sh outputs for cmd: {cmd}")
+    return self._sh_results.pop(0)
+
+  def sh(self,
+         *args: Union[str, pathlib.Path],
+         shell: bool = False,
+         capture_output: bool = False,
+         stdout=None,
+         stderr=None,
+         stdin=None,
+         env: Optional[Mapping[str, str]] = None,
+         quiet: bool = False,
+         check: bool = False):
+    del capture_output, stderr, stdin, stdout
+    self.sh_stdout(*args, shell=shell, quiet=quiet, env=env, check=check)
+    # TODO: Generalize this in the future, to mimic failing `sh` calls.
+    return CompletedProcess(args, 0)
+
+
+class PosixMockPlatformMixin(MockPlatformMixin):
+  pass
+
+
+class WinMockPlatformMixin(MockPlatformMixin):
+  # TODO: use wrapper fake path to get windows-path formatting by default
+  # when running on posix.
+
+  def path(self, path: pth.AnyPathLike) -> pth.AnyPath:
+    return pathlib.PureWindowsPath(path)
+
+
+class LinuxMockPlatform(PosixMockPlatformMixin, LinuxPlatform):
+  pass
+
+
+class LinuxSshMockPlatform(PosixMockPlatformMixin, LinuxSshPlatform):
+  pass
+
+
+class ChromeOsSshMockPlatform(PosixMockPlatformMixin, ChromeOsSshPlatform):
+  pass
+
+
+class MacOsMockPlatform(PosixMockPlatformMixin, MacOSPlatform):
+  pass
+
+
+class WinMockPlatform(WinMockPlatformMixin, WinPlatform):
+  pass
+
+
+class MockAdb(Adb):
+
+  def start_server(self) -> None:
+    pass
+
+  def stop_server(self) -> None:
+    pass
+
+  def kill_server(self) -> None:
+    pass
+
+
+class AndroidAdbMockPlatform(MockPlatformMixin, AndroidAdbPlatform):
+  pass
+
+
+class GenericMockPlatform(MockPlatformMixin, Platform):
+  pass
+
+
+if plt.PLATFORM.is_linux:
+  MockPlatform = LinuxMockPlatform
+elif plt.PLATFORM.is_macos:
+  MockPlatform = MacOsMockPlatform
+elif plt.PLATFORM.is_win:
+  MockPlatform = WinMockPlatform
+else:
+  raise RuntimeError(f"Unsupported platform: {plt.PLATFORM}")
+
+
+class MockStory(Story):
+
+  @classmethod
+  def all_story_names(cls):
+    return ["story_1", "story_2"]
+
+  def run(self, run: Run) -> None:
+    pass
+
+
+class MockBenchmark(SubStoryBenchmark):
+  NAME = "mock-benchmark"
+  DEFAULT_STORY_CLS = MockStory
+
+
+class MockCLI(CrossBenchCLI):
+  runner: Runner
+  platform: Platform
+
+  def __init__(self, *args, **kwargs) -> None:
+    self.platform = kwargs.pop("platform")
+    super().__init__(*args, **kwargs)
+
+  def _get_runner(self, args, benchmark, env_config, env_validation_mode,
+                  timing):
+    if not args.out_dir:
+      # Use stable mock out dir
+      args.out_dir = pathlib.Path("/results")
+      assert not args.out_dir.exists()
+    runner_kwargs = self.RUNNER_CLS.kwargs_from_cli(args)
+    self.runner = self.RUNNER_CLS(
+        benchmark=benchmark,
+        env_config=env_config,
+        env_validation_mode=env_validation_mode,
+        timing=timing,
+        **runner_kwargs,
+        # Use custom platform
+        platform=self.platform)
+    return self.runner
diff --git a/tests/crossbench/network/__init__.py b/tests/crossbench/network/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/network/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/network/test_live.py b/tests/crossbench/network/test_live.py
new file mode 100644
index 0000000..85ff45b
--- /dev/null
+++ b/tests/crossbench/network/test_live.py
@@ -0,0 +1,35 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from unittest import mock
+
+from crossbench.network.live import LiveNetwork
+from tests import test_helper
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class LiveNetworkTestCase(BaseCrossbenchTestCase):
+
+  def test_defaults(self):
+    network = LiveNetwork(browser_platform=self.platform)
+    self.assertTrue(network.traffic_shaper.is_live)
+    self.assertFalse(network.traffic_shaper.is_running)
+    self.assertFalse(network.is_running)
+    self.assertIn("live", str(network).lower())
+
+  def test_open(self):
+    network = LiveNetwork(browser_platform=self.platform)
+    mock_browser_session = mock.Mock()
+    with network.open(mock_browser_session):
+      self.assertTrue(network.is_running)
+      self.assertFalse(network.extra_flags(self.browsers[0].attributes))
+      # Should not be able to double open the network.
+      with self.assertRaises(AssertionError):
+        with network.open(mock_browser_session):
+          pass
+    self.assertFalse(network.is_running)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/network/test_ts_proxy.py b/tests/crossbench/network/test_ts_proxy.py
new file mode 100644
index 0000000..1aa2e6e
--- /dev/null
+++ b/tests/crossbench/network/test_ts_proxy.py
@@ -0,0 +1,109 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import pathlib
+from unittest import mock
+
+from crossbench.network.traffic_shaping.ts_proxy import (TsProxyProcess,
+                                                         TsProxyServer,
+                                                         TsProxyTrafficShaper)
+from tests import test_helper
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class TsProxyBaseTestCase(BaseCrossbenchTestCase):
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.ts_proxy_path = pathlib.Path("/chrome/tsproxy/tsproxy.py")
+    self.fs.create_file(self.ts_proxy_path, st_size=100)
+    # Avoid dealing with fcntl for testing.
+    patcher = mock.patch.object(
+        TsProxyProcess, "_setup_non_blocking_io", return_value=None)
+    self.addCleanup(patcher.stop)
+    patcher.start()
+
+
+class TsProxyTestCase(TsProxyBaseTestCase):
+
+  def test_ts_proxy_traffic_shaper_no_tsproxy(self):
+    with self.assertRaises(RuntimeError):
+      TsProxyTrafficShaper(self.platform)
+
+  def test_ts_proxy_traffic_shaper_default(self):
+    ts_proxy = TsProxyTrafficShaper(self.platform, self.ts_proxy_path)
+    self.assertFalse(ts_proxy.is_running)
+
+
+class TsProxyServerTestCase(TsProxyBaseTestCase):
+
+  def test_construct_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      TsProxyServer(pathlib.Path("does/not/exist"))
+
+  def test_basic_instance(self):
+    server = TsProxyServer(self.ts_proxy_path)
+    self.assertFalse(server.is_running)
+
+    with self.assertRaises(AssertionError):
+      server.set_traffic_settings()
+    with self.assertRaises(AssertionError):
+      _ = server.socks_proxy_port
+    self.assertIsNone(server.stop())
+
+  def test_basic_instance_http_port(self):
+    server = TsProxyServer(self.ts_proxy_path, http_port=8080)
+    self.assertFalse(server.is_running)
+    with self.assertRaises(AssertionError):
+      _ = server.socks_proxy_port
+    self.assertIsNone(server.stop())
+
+  def test_ports(self):
+    with self.assertRaises(ValueError):
+      TsProxyServer(self.ts_proxy_path, https_port=400)
+    with self.assertRaises(ValueError):
+      TsProxyServer(self.ts_proxy_path, http_port=400, https_port=400)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      TsProxyServer(self.ts_proxy_path, http_port=-400, https_port=400)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      TsProxyServer(self.ts_proxy_path, http_port=400, https_port=-400)
+
+  def test_start_server(self):
+    server = TsProxyServer(self.ts_proxy_path)
+
+    proc = mock.Mock()
+    proc.configure_mock(**{
+        "poll.return_value": None,
+        "communicate.return_value": (None, None)
+    })
+    proc.stdout = mock.Mock()
+    proc.stdout.configure_mock(**{
+        "readline.return_value":
+            "Started Socks5 proxy server on 127.0.0.1:43210"
+    })
+    proc.stderr = mock.Mock()
+
+    def popen_mock(cmd, *args, **kwargs):
+      self.assertEqual(cmd[1], self.ts_proxy_path)
+      self.assertEqual(cmd[2], "--port=0")
+      del args, kwargs
+      return proc
+
+    with mock.patch("subprocess.Popen", side_effect=popen_mock) as popen:
+      self.assertFalse(server.is_running)
+      with server:
+        self.assertTrue(server.is_running)
+        self.assertEqual(server.socks_proxy_port, 43210)
+        proc.stdout.readline.assert_called_once()
+        # Set return value for exit command.
+        proc.stdout.readline.return_value = "OK"
+      self.assertFalse(server.is_running)
+
+    popen.assert_called_once()
+    proc.stdin.write.assert_called_with("exit\n")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/__init__.py b/tests/crossbench/plt/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/tests/crossbench/plt/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/plt/helper.py b/tests/crossbench/plt/helper.py
new file mode 100644
index 0000000..0f2f03f
--- /dev/null
+++ b/tests/crossbench/plt/helper.py
@@ -0,0 +1,80 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import pathlib
+
+from crossbench import plt
+from crossbench.plt.posix import PosixPlatform
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+from tests.crossbench.mock_helper import MockPlatform
+
+
+class BaseMockPlatformTestCase(CrossbenchFakeFsTestCase, metaclass=abc.ABCMeta):
+  __test__ = False
+  platform: plt.Platform
+  mock_platform: MockPlatform
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.mock_platform_setup()
+
+  def mock_platform_setup(self):
+    self.mock_platform = MockPlatform()  # pytype: disable=not-instantiable
+    self.platform = self.mock_platform
+
+  def tearDown(self):
+    expected_sh_cmds = self.mock_platform.expected_sh_cmds
+    if expected_sh_cmds is not None:
+      self.assertListEqual(expected_sh_cmds, [],
+                           "Got additional unused shell cmds.")
+    super().tearDown()
+
+  def expect_sh(self, *args, result=""):
+    self.mock_platform.expect_sh(*args, result=result)
+
+  def test_is_android(self):
+    self.assertFalse(self.platform.is_android)
+
+  def test_is_macos(self):
+    self.assertFalse(self.platform.is_macos)
+
+  def test_is_linux(self):
+    self.assertFalse(self.platform.is_linux)
+
+  def test_is_win(self):
+    self.assertFalse(self.platform.is_win)
+
+  def test_is_posix(self):
+    self.assertFalse(self.platform.is_posix)
+
+  def test_is_remote_ssh(self):
+    self.assertFalse(self.platform.is_remote_ssh)
+
+  def test_is_chromeos(self):
+    self.assertFalse(self.platform.is_chromeos)
+
+
+class BasePosixMockPlatformTestCase(BaseMockPlatformTestCase):
+  platform: PosixPlatform
+
+  def tearDown(self) -> None:
+    assert isinstance(self.platform, PosixPlatform)
+    super().tearDown()
+
+  def test_is_posix(self):
+    self.assertTrue(self.platform.is_posix)
+
+  def test_path_conversion(self):
+    self.assertIsInstance(self.platform.path("foo/bar"), pathlib.PurePosixPath)
+    self.assertIsInstance(
+        self.platform.path(pathlib.PurePath("foo/bar")), pathlib.PurePosixPath)
+    self.assertIsInstance(
+        self.platform.path(pathlib.PureWindowsPath("foo/bar")),
+        pathlib.PurePosixPath)
+    self.assertIsInstance(
+        self.platform.path(pathlib.PurePosixPath("foo/bar")),
+        pathlib.PurePosixPath)
diff --git a/tests/crossbench/plt/test_android_adb.py b/tests/crossbench/plt/test_android_adb.py
new file mode 100644
index 0000000..709e58f
--- /dev/null
+++ b/tests/crossbench/plt/test_android_adb.py
@@ -0,0 +1,430 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pathlib
+import unittest
+from typing import Final
+from unittest import mock
+
+from pyfakefs.fake_filesystem import OSType
+
+from crossbench import path as pth
+from crossbench.plt.android_adb import Adb, AndroidAdbPlatform
+from crossbench.plt.arch import MachineArch
+from tests import test_helper
+from tests.crossbench.mock_helper import WinMockPlatform
+from tests.crossbench.plt.helper import BasePosixMockPlatformTestCase
+
+ADB_DEVICE_SAMPLE_OUTPUT = (
+    "List of devices attached\n"
+    "emulator-5556 device product:sdk_google_phone_x86_64 "
+    "model:Android_SDK_built_for_x86_64 device:generic_x86_64\n")
+ADB_DEVICES_SAMPLE_OUTPUT = (
+    f"{ADB_DEVICE_SAMPLE_OUTPUT}"
+    "emulator-5554 device product:sdk_google_phone_x86 "
+    "model:Android_SDK_built_for_x86 device:generic_x86\n"
+    "0a388e93      device usb:1-1 product:razor model:Nexus_7 device:flo\n")
+
+DUMPSYS_DISPLAY_OUTPUT: Final[str] = """
+  SensorObserver
+    mIsProxActive=false
+    mDozeStateByDisplay:
+      0 -> false
+BrightnessSynchronizer
+  mLatestIntBrightness=43
+  mLatestFloatBrightness=0.163
+  mCurrentUpdate=null
+"""
+
+
+class BaseAndroidAdbMockPlatformTestCase(BasePosixMockPlatformTestCase):
+  DEVICE_ID = "emulator-5554"
+  platform: AndroidAdbPlatform
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.adb_setup()
+    self.platform = AndroidAdbPlatform(
+        self.mock_platform, self.DEVICE_ID, adb=self.adb)
+
+  def adb_setup(self):
+    adb_patcher = mock.patch(
+        "crossbench.plt.android_adb._find_adb_bin",
+        return_value=pathlib.Path("adb"))
+    adb_patcher.start()
+    self.addCleanup(adb_patcher.stop)
+    self.expect_startup_devices()
+    self.adb = Adb(self.mock_platform, self.DEVICE_ID)
+
+  def expect_startup_devices(self, devices: str = ADB_DEVICES_SAMPLE_OUTPUT):
+    self.expect_sh(pathlib.Path("adb"), "start-server")
+    self.expect_sh(pathlib.Path("adb"), "devices", "-l", result=devices)
+
+  def expect_adb(self, *args, result=""):
+    self.expect_sh(
+        pathlib.Path("adb"), "-s", self.DEVICE_ID, *args, result=result)
+
+  def test_is_android(self):
+    self.assertTrue(self.platform.is_android)
+
+
+
+class AndroidAdbOnWinMockPlatformTestCase(BaseAndroidAdbMockPlatformTestCase):
+  __test__ = True
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.fs.os = OSType.WINDOWS
+
+  def mock_platform_setup(self):
+    self.mock_platform = WinMockPlatform()
+
+  @unittest.skip(
+      "earlier pyfakefs versions don't handle posix on win properly.")
+  def test_host_platform(self):
+    self.assertTrue(self.platform.host_platform.is_win)
+    self.assertIsInstance(
+        self.platform.host_path("foo/bar"), pathlib.PureWindowsPath)
+    self.assertNotEqual(
+        str(self.platform.host_path("foo/bar")),
+        str(self.platform.path("foo/bar")))
+
+  @unittest.skip(
+      "earlier pyfakefs versions don't handle posix on win properly.")
+  def test_mktemp(self):
+    self.assertTrue(self.platform.default_tmp_dir.is_absolute())
+    self.assertIsInstance(self.platform.default_tmp_dir, pathlib.PurePosixPath)
+    self.expect_adb("shell", "mktemp", "-d",
+                    "/data/local/tmp/custom_prefix.XXXXXXXXXXX")
+    self.platform.mkdtemp("custom_prefix")
+
+  @unittest.skip(
+      "earlier pyfakefs versions don't handle posix on win properly.")
+  def test_push(self):
+    local_path = self.mock_platform.path("C:/foo/push.local.data")
+    remote_path = self.platform.default_tmp_dir / "push.remote.data"
+    self.assertIsInstance(local_path, pathlib.PureWindowsPath)
+    self.fs.create_file(local_path, contents="some data")
+    self.expect_adb("push", "C:\\foo\\push.local.data",
+                    "/data/local/tmp/push.remote.data")
+    self.platform.push(local_path, remote_path)
+
+  @unittest.skip(
+      "earlier pyfakefs versions don't handle posix on win properly.")
+  def test_push_remote_win_path(self):
+    local_path = self.mock_platform.path("C:/foo/push.local.data")
+    remote_path = self.mock_platform.path("custom/push.remote.data")
+    self.assertIsInstance(local_path, pathlib.PureWindowsPath)
+    self.fs.create_file(local_path, contents="some data")
+    self.expect_adb("push", "C:\\foo\\push.local.data",
+                    "custom/push.remote.data")
+    self.platform.push(local_path, remote_path)
+
+
+class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
+  __test__ = True
+
+  def test_create_no_devices(self):
+    self.expect_startup_devices("List of devices attached")
+    with self.assertRaises(ValueError):
+      Adb(self.mock_platform, self.DEVICE_ID)
+
+  def test_create_default_too_many_devices(self):
+    self.expect_startup_devices()
+    with self.assertRaises(ValueError) as cm:
+      Adb(self.mock_platform)
+    self.assertIn("too many", str(cm.exception).lower())
+
+  def test_create_default_one_device(self):
+    self.expect_startup_devices(ADB_DEVICE_SAMPLE_OUTPUT)
+    adb = Adb(self.mock_platform)
+    self.assertEqual(adb.serial_id, "emulator-5556")
+
+  def test_create_default_one_device_invalid(self):
+    self.expect_startup_devices(ADB_DEVICE_SAMPLE_OUTPUT)
+    with self.assertRaises(ValueError) as cm:
+      Adb(self.mock_platform, "")
+    self.assertIn("invalid device identifier", str(cm.exception).lower())
+
+  def test_create_by_name(self):
+    self.expect_startup_devices(ADB_DEVICES_SAMPLE_OUTPUT)
+    adb = Adb(self.mock_platform, "Nexus_7")
+    self.assertEqual(adb.serial_id, "0a388e93")
+    self.expect_startup_devices(ADB_DEVICES_SAMPLE_OUTPUT)
+    adb = Adb(self.mock_platform, "Nexus 7")
+    self.assertEqual(adb.serial_id, "0a388e93")
+
+  def test_create_by_name_duplicate(self):
+    self.expect_startup_devices(ADB_DEVICES_SAMPLE_OUTPUT)
+    with self.assertRaises(ValueError) as cm:
+      Adb(self.mock_platform, "Android_SDK_built_for_x86")
+    self.assertIn("devices", str(cm.exception).lower())
+
+  def test_basic_properties(self):
+    self.assertTrue(self.platform.is_remote)
+    self.assertEqual(self.platform.name, "android")
+    self.assertIs(self.platform.host_platform, self.mock_platform)
+    self.assertEqual(self.platform.default_tmp_dir,
+                     pathlib.PurePosixPath("/data/local/tmp/"))
+
+  def test_adb_basic_properties(self):
+    self.assertEqual(self.adb.serial_id, self.DEVICE_ID)
+    self.assertDictEqual(
+        self.adb.device_info, {
+            "device": "generic_x86",
+            "model": "Android_SDK_built_for_x86",
+            "product": "sdk_google_phone_x86"
+        })
+    self.assertIn(self.DEVICE_ID, str(self.adb))
+
+  def test_has_root(self):
+    self.expect_adb("shell", "id", result="uid=2000(shell) gid=2000(shell)")
+    self.assertFalse(self.adb.has_root())
+    self.expect_adb("shell", "id", result="uid=0(root)n gid=0(root)")
+    self.assertTrue(self.adb.has_root())
+
+  def test_version(self):
+    self.expect_adb(
+        "shell", "getprop", "ro.build.version.release", result="999")
+    self.assertEqual(self.platform.version, "999")
+    # Subsequent calls are cached.
+    self.assertEqual(self.platform.version, "999")
+
+  def test_device(self):
+    self.expect_adb("shell", "getprop", "ro.product.model", result="Pixel 999")
+    self.assertEqual(self.platform.device, "Pixel 999")
+    # Subsequent calls are cached.
+    self.assertEqual(self.platform.device, "Pixel 999")
+
+  def test_cpu(self):
+    self.expect_adb(
+        "shell", "getprop", "dalvik.vm.isa.arm.variant", result="cortex-a999")
+    self.expect_adb("shell", "getprop", "ro.board.platform", result="msmnile")
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile")
+    # Subsequent calls are cached.
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile")
+
+  def test_cpu_detailed(self):
+    self.expect_adb(
+        "shell", "getprop", "dalvik.vm.isa.arm.variant", result="cortex-a999")
+    self.expect_adb("shell", "getprop", "ro.board.platform", result="msmnile")
+    self.expect_adb(
+        "shell",
+        "cat",
+        self.platform.path("/sys/devices/system/cpu/possible"),
+        result="0-998")
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 999 cores")
+    # Subsequent calls are cached.
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 999 cores")
+
+  def test_adb(self):
+    self.assertIs(self.platform.adb, self.adb)
+
+  def test_machine_unknown(self):
+    self.expect_adb(
+        "shell", "getprop", "ro.product.cpu.abi", result="arm37-XXX")
+    with self.assertRaises(ValueError) as cm:
+      self.assertEqual(self.platform.machine, MachineArch.ARM_64)
+    self.assertIn("arm37-XXX", str(cm.exception))
+
+  def test_machine_arm64(self):
+    self.expect_adb(
+        "shell", "getprop", "ro.product.cpu.abi", result="arm64-v8a")
+    self.assertEqual(self.platform.machine, MachineArch.ARM_64)
+    # Subsequent calls are cached.
+    self.assertEqual(self.platform.machine, MachineArch.ARM_64)
+
+  def test_machine_arm32(self):
+    self.expect_adb(
+        "shell", "getprop", "ro.product.cpu.abi", result="armeabi-v7a")
+    self.assertEqual(self.platform.machine, MachineArch.ARM_32)
+    # Subsequent calls are cached.
+    self.assertEqual(self.platform.machine, MachineArch.ARM_32)
+
+  def test_app_path_to_package_invalid_path(self):
+    path = pathlib.Path("path/to/app.bin")
+    with self.assertRaises(ValueError) as cm:
+      self.platform.app_path_to_package(path)
+    self.assertIn(str(path), str(cm.exception))
+
+  def test_app_path_to_package_not_installed(self):
+    with self.assertRaises(ValueError) as cm:
+      self.expect_adb(
+          "shell",
+          "cmd",
+          "package",
+          "list",
+          "packages",
+          result=("package:com.google.android.wifi.resources\n"
+                  "package:com.google.android.GoogleCamera"))
+      self.platform.app_path_to_package(pathlib.Path("com.custom.app"))
+    self.assertIn("com.custom.app", str(cm.exception))
+    self.assertIn("not installed", str(cm.exception))
+
+  def test_app_path_to_package(self):
+    path = pathlib.Path("com.custom.app")
+    self.expect_adb(
+        "shell",
+        "cmd",
+        "package",
+        "list",
+        "packages",
+        result=("package:com.google.android.wifi.resources\n"
+                "package:com.custom.app"))
+    self.assertEqual(self.platform.app_path_to_package(path), "com.custom.app")
+
+  def test_app_version(self):
+    path = pathlib.Path("com.custom.app")
+    self.expect_adb(
+        "shell",
+        "cmd",
+        "package",
+        "list",
+        "packages",
+        result="package:com.custom.app")
+    self.expect_adb(
+        "shell",
+        "dumpsys",
+        "package",
+        "com.custom.app",
+        result="versionName=9.999")
+    self.assertEqual(self.platform.app_version(path), "9.999")
+
+  def test_app_version_unkown(self):
+    path = pathlib.Path("com.custom.app")
+    self.expect_adb(
+        "shell",
+        "cmd",
+        "package",
+        "list",
+        "packages",
+        result="package:com.custom.app")
+    self.expect_adb(
+        "shell", "dumpsys", "package", "com.custom.app", result="something")
+    with self.assertRaises(ValueError) as cm:
+      self.platform.app_version(path)
+    self.assertIn("something", str(cm.exception))
+    self.assertIn("com.custom.app", str(cm.exception))
+
+  def test_get_relative_cpu_speed(self):
+    self.assertGreater(self.platform.get_relative_cpu_speed(), 0)
+
+  def test_check_autobrightness(self):
+    self.assertTrue(self.platform.check_autobrightness())
+
+  def get_main_display_brightness(self):
+    display_info = ("BrightnessSynchronizer\n"
+                    "mLatestFloatBrightness=0.5\n"
+                    "mLatestIntBrightness=128\n"
+                    "mPendingUpdate=null")
+    self.expect_adb("shell", "dumpsys", "display", result=display_info)
+    self.assertEqual(self.platform.get_main_display_brightness(), 50)
+    # Values are not cached
+    display_info = ("BrightnessSynchronizer\n"
+                    "mLatestFloatBrightness=1.0\n"
+                    "mLatestIntBrightness=255\n"
+                    "mPendingUpdate=null")
+    self.expect_adb("shell", "dumpsys", "display", result=display_info)
+    self.assertEqual(self.platform.get_main_display_brightness(), 100)
+
+  def test_search_binary_empty_path(self):
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_binary(pathlib.Path(""))
+    self.assertIn("empty path", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_binary("")
+    self.assertIn("empty path", str(cm.exception))
+
+  def test_search_binary(self):
+    ls_path = self.platform.path("/system/bin/ls")
+    self.expect_adb(
+        "shell", "which", self.platform.path("ls"), result=str(ls_path))
+    self.expect_adb("shell", "[", "-e", ls_path, "]", result="")
+    path = self.platform.search_binary("ls")
+    self.assertEqual(str(path), str(ls_path))
+
+  def test_binary_lookup_override(self):
+    # Overriding the default test for android.
+    ls_path = self.platform.path("ls")
+    override_path = self.platform.path("/root/sbin/ls")
+    # override_binary checks if the result binary exists.
+    self.expect_adb("shell", "which", override_path, result=str(override_path))
+    self.expect_adb("shell", "[", "-e", override_path, "]", result="")
+    with self.platform.override_binary(ls_path, override_path):
+      path = self.platform.search_binary("ls")
+      self.assertEqual(path, override_path)
+
+  def test_search_binary_app_package_non(self):
+    self.expect_adb(
+        "shell", "which", self.platform.path("com.google.chrome"), result="")
+    self.expect_adb("shell", "cmd", "package", "list", "packages", result="")
+    path = self.platform.search_binary("com.google.chrome")
+    self.assertIsNone(path)
+
+    self.expect_adb(
+        "shell", "which", self.platform.path("com.google.chrome"), result="")
+    self.expect_adb(
+        "shell",
+        "cmd",
+        "package",
+        "list",
+        "packages",
+        result="package:com.google.chrome")
+    path = self.platform.search_binary("com.google.chrome")
+    self.assertEqual(path, pathlib.PurePosixPath("com.google.chrome"))
+
+  def test_search_binary_app_package_lookup_override(self):
+    chrome_package = self.platform.path("com.google.chrome")
+    chrome_dev_package = self.platform.path("com.chrome.dev")
+    self.expect_adb("shell", "which", chrome_dev_package, result="")
+    self.expect_adb(
+        "shell",
+        "cmd",
+        "package",
+        "list",
+        "packages",
+        result="package:com.chrome.dev")
+    with self.platform.override_binary(chrome_package, chrome_dev_package):
+      path = self.platform.search_binary(chrome_package)
+      self.assertEqual(chrome_dev_package, path)
+
+  def test_override_binary_non_existing_package(self):
+    chrome_package = self.platform.path("com.google.chrome")
+    chrome_dev_package = self.platform.path("com.chrome.dev")
+    self.expect_adb("shell", "which", chrome_dev_package, result="")
+    self.expect_adb("shell", "cmd", "package", "list", "packages", result="")
+    with self.assertRaises(ValueError) as cm:
+      with self.platform.override_binary(chrome_package, chrome_dev_package):
+        pass
+    self.assertIn(str(chrome_package), str(cm.exception))
+    self.assertIn(str(chrome_dev_package), str(cm.exception))
+
+  def test_home(self):
+    # not implemented yet
+    with self.assertRaises(RuntimeError):
+      self.platform.home()
+
+  def test_get_main_display_brightness(self):
+    self.expect_adb(
+        "shell", "dumpsys", "display", result=DUMPSYS_DISPLAY_OUTPUT)
+    brightness = self.platform.get_main_display_brightness()
+    self.assertEqual(brightness, 16)
+
+  def test_iterdir(self):
+    self.expect_adb("shell", "[", "-d", "parent_dir/child_dir", "]")
+    self.expect_adb(
+        "shell", "ls", "-1", "parent_dir/child_dir", result="file1\nfile2\n")
+
+    self.assertSetEqual(
+        set(self.platform.iterdir(pth.AnyWindowsPath("parent_dir\\child_dir"))),
+        {
+            pth.AnyPosixPath("parent_dir/child_dir/file1"),
+            pth.AnyPosixPath("parent_dir/child_dir/file2")
+        })
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_bin.py b/tests/crossbench/plt/test_bin.py
new file mode 100644
index 0000000..f7c1abb
--- /dev/null
+++ b/tests/crossbench/plt/test_bin.py
@@ -0,0 +1,240 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import os
+import pathlib
+import unittest
+from unittest import mock
+
+import crossbench.path as pth
+from crossbench import plt
+from crossbench.plt import PLATFORM
+from crossbench.plt.bin import (Binary, BinaryNotFoundError, LinuxBinary,
+                                MacOsBinary, PosixBinary, WinBinary)
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+from tests.crossbench.mock_helper import (LinuxMockPlatform, MacOsMockPlatform,
+                                          WinMockPlatform)
+
+
+class BinaryTestCase(CrossbenchFakeFsTestCase):
+
+  def setUp(self) -> None:
+    super().setUp()
+    self._all_mock_platforms = (
+        LinuxMockPlatform(),
+        MacOsMockPlatform(),
+        WinMockPlatform(),
+        # TODO: add adb testing
+    )
+    self._all_platforms = (PLATFORM,) + self._all_mock_platforms
+
+  def all_mock_platforms(self):
+    yield from self._all_mock_platforms
+
+  def all_platforms(self):
+    yield from self._all_platforms
+
+  def create_binary_path(self, path: pth.AnyPathLike) -> pth.LocalPath:
+    result = pth.LocalPath(path)
+    self.fs.create_file(result, st_size=100)
+    return result
+
+  def test_create_without_binary(self):
+    with self.assertRaises(ValueError):
+      Binary(name="test")
+    with self.assertRaises(ValueError):
+      Binary(name="test", posix="")
+
+  def test_new_windows_binary_invalid(self):
+    with self.assertRaises(ValueError):
+      WinBinary("custom")
+    with self.assertRaises(ValueError):
+      WinBinary(pth.AnyPath("custom"))
+    with self.assertRaises(ValueError):
+      WinBinary(pth.AnyPath("foo/bar/custom.py"))
+
+  def test_new_windows_binary(self):
+    binary = WinBinary("crossbench_mock_binary.exe")
+    self.assertEqual(binary.name, "crossbench_mock_binary.exe")
+    platform = WinMockPlatform()
+    path = platform.local_path("C:/Users/user-name/AppData/Local/Programs/"
+                               "crossbench/crossbench_mock_binary.exe")
+    with self.assertRaises(ValueError):
+      with platform.override_binary(binary, path):
+        self.assertEqual(binary.resolve(platform), path)
+
+    self.fs.create_file(path, st_size=100)
+    with mock.patch("shutil.which", return_value=path) as cm:
+      with platform.override_binary(binary, path):
+        self.assertEqual(binary.resolve(platform), path)
+        self.assertEqual(binary.resolve_cached(platform), path)
+    cm.assert_called_once_with(os.fspath(path))
+
+    # Still cached
+    self.assertEqual(binary.resolve_cached(platform), path)
+    with self.assertRaises(BinaryNotFoundError):
+      self.assertEqual(binary.resolve(platform), path)
+
+    binary.resolve_cached.cache_clear()
+    with self.assertRaises(BinaryNotFoundError):
+      self.assertEqual(binary.resolve(platform), path)
+    with self.assertRaises(BinaryNotFoundError):
+      self.assertEqual(binary.resolve_cached(platform), path)
+
+  def test_basic_accessor(self):
+    binary = Binary("test", default="foo/bar/test")
+    self.assertEqual(binary.name, "test")
+
+  def test_basic_accessor_multiple(self):
+    binary = Binary("test", default=("foo/bar/test1", "foo/bar/test2"))
+    self.assertEqual(binary.name, "test")
+
+  def test_unknown_binary(self):
+    binary = Binary("crossbench_mock_binary", default="crossbench_mock_binary")
+    for platform in self.all_platforms():
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve(platform)
+
+  def test_known_binary_default(self):
+    for platform in self.all_mock_platforms():
+      with self.subTest(platform=platform):
+        default = pth.AnyPath("foo/bar/default/crossbench_mock_binary")
+        result = default
+        if platform.is_win:
+          result = pth.AnyPath("foo/bar/default/crossbench_mock_binary.exe")
+        binary = Binary("crossbench_mock_binary", default=default)
+        self.assertEqual(binary.platform_path(platform), (pth.AnyPath(result),))
+        with self.assertRaises(BinaryNotFoundError):
+          binary.resolve(platform)
+        with self.assertRaises(BinaryNotFoundError):
+          binary.resolve_cached(platform)
+        self.fs.create_file(result, st_size=100)
+        self.assertEqual(pth.AnyPath(binary.resolve(platform)), result)
+        self.assertEqual(pth.AnyPath(binary.resolve_cached(platform)), result)
+        self.fs.remove(result)
+
+  def test_known_binary_default_multiple(self):
+    for platform in self.all_mock_platforms():
+      with self.subTest(platform=platform):
+        default_miss = pth.AnyPath("foo/bar/default/fake")
+        default = pth.AnyPath("foo/bar/default/crossbench_mock_binary")
+        result = default
+        if platform.is_win:
+          default_miss = pth.AnyPath("foo/bar/default/fake.exe")
+          result = pth.AnyPath("foo/bar/default/crossbench_mock_binary.exe")
+        binary = Binary(
+            "crossbench_mock_binary", default=(default_miss, default))
+        self.assertEqual(
+            binary.platform_path(platform), (
+                pth.AnyPath(default_miss),
+                pth.AnyPath(result),
+            ))
+        with self.assertRaises(BinaryNotFoundError):
+          binary.resolve(platform)
+        with self.assertRaises(BinaryNotFoundError):
+          binary.resolve_cached(platform)
+        self.fs.create_file(result, st_size=100)
+        self.assertEqual(pth.AnyPath(binary.resolve(platform)), result)
+        self.assertEqual(pth.AnyPath(binary.resolve_cached(platform)), result)
+        self.fs.remove(result)
+
+  @unittest.skipUnless(plt.PLATFORM.is_posix, "Only supported on posix")
+  def test_known_binary_linux(self):
+    result = self.create_binary_path(
+        pth.AnyPosixPath("foo/bar/default/crossbench_mock_binary"))
+    binary = Binary("crossbench_mock_binary", linux=result)
+    self.validate_known_binary_linux(result, binary)
+    binary = LinuxBinary(result)
+    self.validate_known_binary_linux(result, binary)
+
+  def validate_known_binary_linux(self, result, binary):
+    result = pth.AnyPosixPath(result)
+    platform = LinuxMockPlatform()
+    self.assertEqual(str(binary.resolve(platform)), str(result))
+    self.assertEqual(str(binary.resolve_cached(platform)), str(result))
+
+    for platform in self.all_mock_platforms():
+      if platform.is_linux:
+        continue
+      self.assertEqual(binary.platform_path(platform), ())
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve(platform)
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve_cached(platform)
+
+  @unittest.skipUnless(plt.PLATFORM.is_posix, "Only supported on posix")
+  def test_known_binary_macos(self):
+    result = self.create_binary_path("foo/bar/default/crossbench_mock_binary")
+    binary = Binary("crossbench_mock_binary", macos=result)
+    self.validate_known_binary_macos(result, binary)
+    binary = MacOsBinary(result)
+    self.validate_known_binary_macos(result, binary)
+
+  def validate_known_binary_macos(self, result, binary):
+    platform = MacOsMockPlatform()
+    self.assertEqual(binary.resolve(platform), result)
+    self.assertEqual(binary.resolve_cached(platform), result)
+
+    for platform in self.all_mock_platforms():
+      if platform.is_macos:
+        continue
+      self.assertEqual(binary.platform_path(platform), ())
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve(platform)
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve_cached(platform)
+
+  @unittest.skipUnless(plt.PLATFORM.is_posix, "Only supported on posix")
+  def test_known_binary_posix(self):
+    result = self.create_binary_path("foo/bar/default/crossbench_mock_binary")
+    binary = Binary("crossbench_mock_binary", posix=result)
+    self.validate_known_binary_posix(result, binary)
+    binary = PosixBinary(result)
+    self.validate_known_binary_posix(result, binary)
+
+  def validate_known_binary_posix(self, result, binary):
+    for platform in self.all_mock_platforms():
+      if not platform.is_posix:
+        continue
+      self.assertEqual(binary.resolve(platform), result)
+      self.assertEqual(binary.resolve_cached(platform), result)
+
+    for platform in self.all_mock_platforms():
+      if platform.is_posix:
+        continue
+      self.assertEqual(binary.platform_path(platform), ())
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve(platform)
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve_cached(platform)
+
+  def test_known_binary_win(self):
+    result = self.create_binary_path(
+        "foo/bar/default/crossbench_mock_binary.exe")
+    result = pathlib.PureWindowsPath(result)
+    binary = Binary("crossbench_mock_binary", win=result)
+    self.validate_known_binary_win(result, binary)
+    binary = WinBinary(result)
+    self.validate_known_binary_win(result, binary)
+
+  def validate_known_binary_win(self, result, binary):
+    platform = WinMockPlatform()
+    self.assertEqual(binary.resolve(platform), result)
+    self.assertEqual(binary.resolve_cached(platform), result)
+
+    for platform in self.all_mock_platforms():
+      if platform.is_win:
+        continue
+      self.assertEqual(binary.platform_path(platform), ())
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve(platform)
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve_cached(platform)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_chromeos_ssh.py b/tests/crossbench/plt/test_chromeos_ssh.py
new file mode 100644
index 0000000..1270247
--- /dev/null
+++ b/tests/crossbench/plt/test_chromeos_ssh.py
@@ -0,0 +1,32 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
+from tests import test_helper
+from tests.crossbench.plt.test_linux_ssh import LinuxSshMockPlatformTestCase
+
+
+class ChromeOsSshMockPlatformTestCase(LinuxSshMockPlatformTestCase):
+  SSH_USER = "chronos"
+  platform: ChromeOsSshPlatform
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.platform = ChromeOsSshPlatform(
+        self.mock_platform,
+        host=self.HOST,
+        port=self.PORT,
+        ssh_port=self.SSH_PORT,
+        ssh_user=self.SSH_USER)
+
+  def test_name(self):
+    self.assertEqual(self.platform.name, "chromeos_ssh")
+
+  def test_is_chromeos(self):
+    self.assertTrue(self.platform.is_chromeos)
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_linux_ssh.py b/tests/crossbench/plt/test_linux_ssh.py
new file mode 100644
index 0000000..1c30f84
--- /dev/null
+++ b/tests/crossbench/plt/test_linux_ssh.py
@@ -0,0 +1,75 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench import path as pth
+from crossbench import plt
+from tests import test_helper
+from tests.crossbench.plt.helper import BasePosixMockPlatformTestCase
+
+
+class LinuxSshMockPlatformTestCase(BasePosixMockPlatformTestCase):
+  __test__ = True
+  HOST = "host"
+  PORT = 9515
+  SSH_PORT = 22
+  SSH_USER = "user"
+  platform: plt.LinuxSshPlatform
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.platform = plt.LinuxSshPlatform(
+        self.mock_platform,
+        host=self.HOST,
+        port=self.PORT,
+        ssh_port=self.SSH_PORT,
+        ssh_user=self.SSH_USER)
+
+  def test_is_linux(self):
+    self.assertTrue(self.platform.is_linux)
+
+  def test_is_remote_ssh(self):
+    self.assertTrue(self.platform.is_remote_ssh)
+
+  def test_basic_properties(self):
+    self.assertTrue(self.platform.is_remote)
+    self.assertEqual(self.platform.host, self.HOST)
+    self.assertEqual(self.platform.port, self.PORT)
+    self.assertIs(self.platform.host_platform, self.mock_platform)
+    self.assertTrue(self.platform.is_posix)
+
+  def test_name(self):
+    self.assertEqual(self.platform.name, "linux_ssh")
+
+  def test_version(self):
+    self._expect_sh_ssh("uname -r", result="999")
+    self.assertEqual(self.platform.version, "999")
+    # Subsequent calls are cached.
+    self.assertEqual(self.platform.version, "999")
+
+
+  def test_iterdir(self):
+    self._expect_sh_ssh("'[' -d parent_dir/child_dir ']'")
+    self._expect_sh_ssh("ls -1 parent_dir/child_dir", result="file1\nfile2\n")
+
+    self.assertSetEqual(
+        set(self.platform.iterdir(pth.AnyWindowsPath("parent_dir\\child_dir"))),
+        {
+            pth.AnyPosixPath("parent_dir/child_dir/file1"),
+            pth.AnyPosixPath("parent_dir/child_dir/file2")
+        })
+
+  def _expect_sh_ssh(self, *args, result=""):
+    self.mock_platform.expect_sh(
+        "ssh",
+        "-p",
+        str(self.SSH_PORT),
+        f"{self.SSH_USER}@{self.HOST}",
+        *args,
+        result=result)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_macos.py b/tests/crossbench/plt/test_macos.py
new file mode 100644
index 0000000..58ec727
--- /dev/null
+++ b/tests/crossbench/plt/test_macos.py
@@ -0,0 +1,137 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import plistlib
+
+from pyfakefs.fake_filesystem import OSType
+
+from crossbench import path as pth
+from tests import test_helper
+from tests.crossbench.mock_helper import MacOsMockPlatform
+from tests.crossbench.plt.helper import BasePosixMockPlatformTestCase
+
+
+class MacOsMockPlatformTestCase(BasePosixMockPlatformTestCase):
+  __test__ = True
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.fs.os = OSType.MACOS
+
+  def mock_platform_setup(self) -> None:
+    self.mock_platform = MacOsMockPlatform()
+    self.platform = self.mock_platform
+
+  def test_name(self):
+    self.assertEqual(self.platform.name, "mock.macos")
+
+  def test_is_macos(self):
+    self.assertTrue(self.platform.is_macos)
+
+  def test_app_version_non_existing(self):
+    app_path = pth.AnyPath("/Applications/Google Chrome.app")
+    self.assertFalse(self.platform.exists(app_path))
+    with self.assertRaisesRegex(ValueError, "not exist"):
+      self.platform.app_version(app_path)
+
+  def test_app_version_binary(self):
+    app_path = pth.AnyPath("/opt/homebrew/bin/brew")
+    self.fs.create_file(app_path, st_size=100)
+    self.expect_sh(app_path, "--version", result="111.22.3")
+    self.assertEqual(self.platform.app_version(app_path), "111.22.3")
+
+  def test_app_version(self):
+    app_path = pth.LocalPath("/Applications/Google Chrome.app")
+    with self.assertRaisesRegex(ValueError, str(app_path)):
+      self.platform.app_version(app_path)
+    app_path.mkdir(parents=True)
+    with self.assertRaisesRegex(ValueError, str(app_path)):
+      self.platform.app_version(app_path)
+
+    binary_path = app_path / "Contents/MacOS/Google Chrome"
+    binary_path.parent.mkdir(parents=True)
+    with self.assertRaisesRegex(ValueError, "Info.plist"):
+      self.platform.app_version(app_path)
+
+    info_plist = app_path / "Contents/Info.plist"
+    self.fs.create_file(info_plist)
+    with self.assertRaisesRegex(ValueError, "Invalid file"):
+      self.platform.app_version(app_path)
+
+    with info_plist.open("wb") as f:
+      plistlib.dump({}, f)
+    with self.assertRaisesRegex(ValueError, str(app_path)):
+      self.platform.app_version(app_path)
+
+    with info_plist.open("wb") as f:
+      plistlib.dump({"CFBundleShortVersionString": "129.9.6668.103"}, f)
+    self.assertEqual(self.platform.app_version(app_path), "129.9.6668.103")
+
+  def test_app_version_binary_inside_app(self):
+    binary_path = pth.LocalPath("/Applications/Safari Technology Preview.app/"
+                                "Contents/MacOS/safaridriver")
+    self.fs.create_file(binary_path, st_size=100)
+    self.expect_sh(binary_path, "--version", result="(Release 203, 19620.1.6)")
+    self.assertEqual(
+        self.platform.app_version(binary_path), "(Release 203, 19620.1.6)")
+
+  def test_search_binary(self):
+    app_path = pth.LocalPath("/Applications/Google Chrome.app")
+    self.assertIsNone(self.platform.search_binary(app_path))
+    binary_path = app_path / "Contents/MacOS/Google Chrome"
+    self.fs.create_file(binary_path, st_size=100)
+    self.assertEqual(self.platform.search_binary(app_path), binary_path)
+
+  def test_search_binary_custom_bundle_executable(self):
+    app_path = pth.LocalPath("/Applications/Google Chrome.app")
+    self.assertIsNone(self.platform.search_binary(app_path))
+    binary_path = app_path / "Contents/MacOS/Chrome"
+    binary_path.parent.mkdir(parents=True)
+    with self.assertRaisesRegex(ValueError, "Info.plist"):
+      self.platform.search_binary(app_path)
+
+    info_plist = app_path / "Contents/Info.plist"
+    self.fs.create_file(info_plist)
+    with self.assertRaisesRegex(ValueError, "Invalid file"):
+      self.platform.search_binary(app_path)
+
+    with info_plist.open("wb") as f:
+      plistlib.dump({}, f)
+    with self.assertRaisesRegex(ValueError, str(app_path)):
+      self.platform.search_binary(app_path)
+
+    with info_plist.open("wb") as f:
+      plistlib.dump({"CFBundleExecutable": str(binary_path)}, f)
+    with self.assertRaisesRegex(ValueError, str(app_path)):
+      self.platform.search_binary(app_path)
+
+    self.fs.create_file(binary_path, st_size=100)
+    # Single binary is always resolved directly
+    self.assertEqual(self.platform.search_binary(app_path), binary_path)
+
+    # Adding another binary will still resolve to CFBundleExecutable
+    self.fs.create_file(binary_path.parent / "Other", st_size=100)
+    self.assertEqual(self.platform.search_binary(app_path), binary_path)
+
+  def test_search_binary_single(self):
+    app_path = pth.LocalPath("/Applications/Custom.app")
+    binary_path = app_path / "Contents/MacOS/CustomA"
+    self.fs.create_file(binary_path, st_size=100)
+    self.assertEqual(self.platform.search_binary(app_path), binary_path)
+
+  def test_search_binary_multiple_binaries(self):
+    app_path = pth.LocalPath("/Applications/Custom.app")
+    self.fs.create_file(app_path / "Contents/MacOS/CustomA", st_size=100)
+    self.fs.create_file(app_path / "Contents/MacOS/CustomB", st_size=100)
+    info_plist = app_path / "Contents/Info.plist"
+    with info_plist.open("wb") as f:
+      plistlib.dump({}, f)
+    with self.assertRaisesRegex(ValueError, "binaries"):
+      self.platform.search_binary(app_path)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_native_platform.py b/tests/crossbench/plt/test_native_platform.py
new file mode 100644
index 0000000..6086280
--- /dev/null
+++ b/tests/crossbench/plt/test_native_platform.py
@@ -0,0 +1,678 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import os
+import pathlib
+import sys
+import tempfile
+import unittest
+
+from crossbench import compat, plt
+from crossbench.plt.base import DEFAULT_CACHE_DIR
+from crossbench.plt.posix import PosixPlatform
+from tests import test_helper
+
+
+class NativePlatformTestCase(unittest.TestCase):
+
+  def setUp(self):
+    self.platform: plt.Platform = plt.PLATFORM
+
+  def test_sleep(self):
+    self.platform.sleep(0)
+    self.platform.sleep(0.01)
+    self.platform.sleep(dt.timedelta())
+    self.platform.sleep(dt.timedelta(seconds=0.1))
+
+  def test_cpu_details(self):
+    details = self.platform.cpu_details()
+    self.assertLess(0, details["physical cores"])
+
+  def test_get_relative_cpu_speed(self):
+    self.assertGreater(self.platform.get_relative_cpu_speed(), 0)
+
+  def test_is_thermal_throttled(self):
+    self.assertIsInstance(self.platform.is_thermal_throttled(), bool)
+
+  def test_is_battery_powered(self):
+    self.assertIsInstance(self.platform.is_battery_powered, bool)
+    self.assertEqual(
+        self.platform.is_battery_powered,
+        plt.PLATFORM.is_battery_powered,
+    )
+
+  def test_cpu_usage(self):
+    self.assertGreaterEqual(self.platform.cpu_usage(), 0)
+
+  def test_system_details(self):
+    self.assertIsNotNone(self.platform.system_details())
+
+  def test_environ(self):
+    env = self.platform.environ
+    self.assertTrue(env)
+
+  def test_which_none(self):
+    with self.assertRaises(ValueError):
+      self.platform.which("")
+
+  def test_which_invalid_binary(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      self.assertIsNone(self.platform.which(tmp_dirname))
+
+  def test_search_binary_empty_path(self):
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_binary(pathlib.Path())
+    self.assertIn("empty", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_binary(pathlib.Path(""))
+    self.assertIn("empty", str(cm.exception))
+
+  def test_search_app_empty_path(self):
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_app(pathlib.Path())
+    self.assertIn("empty", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_app(pathlib.Path(""))
+    self.assertIn("empty", str(cm.exception))
+
+  def test_cat(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      file = pathlib.Path(tmp_dirname) / "test.txt"
+      with file.open("w") as f:
+        f.write("a b c d e f 11")
+      result = self.platform.cat(file)
+      self.assertEqual(result, "a b c d e f 11")
+
+  def test_cat_bytes(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      file = pathlib.Path(tmp_dirname) / "test.data"
+      with file.open("wb") as f:
+        f.write(b"a b c d e f 11")
+      result = self.platform.cat_bytes(file)
+      self.assertEqual(result, b"a b c d e f 11")
+
+  def test_mkdir(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      path = pathlib.Path(tmp_dirname) / "foo" / "bar"
+      self.assertFalse(self.platform.exists(path))
+      self.platform.mkdir(path)
+      self.assertTrue(path.is_dir())
+
+  def test_rm_file(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      path = pathlib.Path(tmp_dirname) / "foo.txt"
+      path.touch()
+      self.assertTrue(path.is_file())
+      self.platform.rm(path)
+      self.assertFalse(self.platform.exists(path))
+
+  def test_rm_dir(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      path = pathlib.Path(tmp_dirname) / "foo" / "bar"
+      path.mkdir(parents=True, exist_ok=False)
+      self.assertTrue(path.is_dir())
+      with self.assertRaises(Exception):
+        self.platform.rm(path.parent)
+      self.platform.rm(path.parent, dir=True)
+      self.assertFalse(self.platform.exists(path))
+      self.assertFalse(path.parent.exists())
+
+  def test_mkdtemp(self):
+    result = self.platform.mkdtemp(prefix="a_custom_prefix")
+    self.assertTrue(self.platform.is_dir(result))
+    self.assertIn("a_custom_prefix", result.name)
+    self.platform.rm(result, dir=True)
+    self.assertFalse(self.platform.exists(result))
+
+  def test_mkdtemp_dir(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_dir = pathlib.Path(tmp_dirname)
+      result = self.platform.mkdtemp(dir=tmp_dir)
+      self.assertTrue(self.platform.is_dir(result))
+      self.assertTrue(compat.is_relative_to(result, tmp_dir))
+    self.assertFalse(self.platform.exists(result))
+
+  def test_mktemp(self):
+    result = self.platform.mktemp(prefix="a_custom_prefix")
+    self.assertTrue(self.platform.is_file(result))
+    self.assertIn("a_custom_prefix", result.name)
+    self.platform.rm(result)
+    self.assertFalse(self.platform.exists(result))
+
+  def test_mktemp_dir(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_dir = pathlib.Path(tmp_dirname)
+      result = self.platform.mktemp(dir=tmp_dir)
+      self.assertTrue(self.platform.is_file(result))
+      self.assertTrue(compat.is_relative_to(result, tmp_dir))
+    self.assertFalse(self.platform.exists(result))
+
+  def test_exists(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_dir = pathlib.Path(tmp_dirname)
+      self.assertTrue(self.platform.exists(tmp_dir))
+      self.assertFalse(self.platform.exists(tmp_dir / "foo"))
+
+  def test_touch(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_file = pathlib.Path(tmp_dirname) / "test.txt"
+      self.assertFalse(tmp_file.exists())
+      self.assertFalse(self.platform.exists(tmp_file))
+      self.platform.touch(tmp_file)
+      self.assertTrue(tmp_file.exists())
+      self.assertTrue(self.platform.exists(tmp_file))
+      self.assertEqual(tmp_file.stat().st_size, 0)
+
+  def test_rename(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_file = pathlib.Path(tmp_dirname) / "test.txt"
+      tmp_file_renamed = tmp_file.with_name("test_renamed.txt")
+      self.platform.touch(tmp_file)
+      self.assertTrue(tmp_file.exists())
+      self.assertFalse(tmp_file_renamed.exists())
+      result = self.platform.rename(tmp_file, tmp_file_renamed)
+      self.assertEqual(result, tmp_file_renamed)
+      self.assertFalse(tmp_file.exists())
+      self.assertTrue(tmp_file_renamed.exists())
+
+  def test_default_tmp_dir(self):
+    self.assertTrue(self.platform.is_dir(self.platform.default_tmp_dir))
+
+  def test_NamedTemporaryFile(self):
+    with self.platform.NamedTemporaryFile("custom_prefix") as path:
+      self.assertIn("custom_prefix", str(path))
+      self.assertTrue(self.platform.is_file(path))
+      self.assertTrue(self.platform.exists(path))
+    self.assertFalse(self.platform.exists(path))
+
+  def test_copy(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      src_file = pathlib.Path(tmp_dirname) / "src.txt"
+      dst_file = pathlib.Path(tmp_dirname) / "dst.txt"
+      with self.assertRaises(ValueError) as cm:
+        self.assertFalse(self.platform.exists(src_file))
+        self.platform.copy(src_file, dst_file)
+      self.assertIn(str(src_file), str(cm.exception))
+      self.assertFalse(self.platform.exists(src_file))
+      self.assertFalse(self.platform.exists(dst_file))
+
+      src_file.write_text("some data")
+      self.assertTrue(self.platform.exists(src_file))
+      self.platform.copy(src_file, dst_file)
+      self.assertTrue(self.platform.exists(src_file))
+      self.assertTrue(self.platform.exists(dst_file))
+      self.assertEqual(self.platform.cat(src_file), "some data")
+      self.assertEqual(self.platform.cat(dst_file), "some data")
+
+  def test_home(self):
+    self.assertEqual(self.platform.home(), pathlib.Path.home())
+
+  def test_absolute_absolute(self):
+    if self.platform.is_win:
+      absolute_path = pathlib.Path("C:/foo")
+    else:
+      absolute_path = pathlib.Path("/foo")
+    self.assertTrue(absolute_path.is_absolute())
+    self.assertEqual(self.platform.absolute(absolute_path), absolute_path)
+
+  def test_absolute_relative(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    relative_path = pathlib.Path("../../foo")
+    self.assertFalse(relative_path.is_absolute())
+    self.assertEqual(
+        self.platform.absolute(relative_path), relative_path.absolute())
+
+  def test_glob(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_dir = pathlib.Path(tmp_dirname)
+      self.assertFalse(list(self.platform.glob(tmp_dir, "*")))
+      a = tmp_dir / "a"
+      b = tmp_dir / "b"
+      self.platform.touch(a)
+      self.platform.touch(b)
+      self.assertListEqual(sorted(self.platform.glob(tmp_dir, "*")), [a, b])
+
+  def test_set_file_contents(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_file = pathlib.Path(tmp_dirname) / "test.txt"
+      self.assertFalse(self.platform.exists(tmp_file))
+      self.platform.mkdir(tmp_file.parent)
+      self.platform.touch(tmp_file)
+      self.assertFalse(self.platform.cat(tmp_file))
+
+      self.platform.set_file_contents(tmp_file, "custom data")
+      self.assertTrue(self.platform.exists(tmp_file))
+      self.assertEqual(self.platform.cat(tmp_file), "custom data")
+
+  def test_set_file_contents_dir(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      self.assertTrue(self.platform.is_dir(tmp_dirname))
+      tmp_dir_path = self.platform.path(tmp_dirname)
+      self.assertTrue(self.platform.is_dir(tmp_dir_path))
+      with self.assertRaises(Exception) as cm:
+        self.platform.set_file_contents(tmp_dirname, "data")
+      self.assertIn(tmp_dir_path.name, str(cm.exception))
+
+  def test_path_tests(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_dir = pathlib.Path(tmp_dirname)
+      self.assertTrue(self.platform.exists(tmp_dir))
+      self.assertTrue(self.platform.is_dir(tmp_dir))
+      self.assertFalse(self.platform.is_file(tmp_dir))
+
+      foo_dir = tmp_dir / "foo"
+      self.assertFalse(self.platform.exists(foo_dir))
+      self.assertFalse(self.platform.is_dir(foo_dir))
+      self.assertFalse(self.platform.is_file(foo_dir))
+      self.platform.mkdir(foo_dir)
+      self.assertTrue(self.platform.exists(foo_dir))
+      self.assertTrue(self.platform.is_dir(foo_dir))
+      self.assertFalse(self.platform.is_file(foo_dir))
+
+      bar_file = tmp_dir / "bar.txt"
+      self.assertFalse(self.platform.exists(bar_file))
+      self.assertFalse(self.platform.is_dir(bar_file))
+      self.assertFalse(self.platform.is_file(bar_file))
+      self.platform.touch(bar_file)
+      self.assertTrue(self.platform.exists(bar_file))
+      self.assertFalse(self.platform.is_dir(bar_file))
+      self.assertTrue(self.platform.is_file(bar_file))
+
+  def test_cache_dir(self):
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      try:
+        self.platform.set_cache_dir(tmp_dir)
+        cache_dir = self.platform.local_cache_dir("test")
+        self.assertTrue(self.platform.is_dir(cache_dir))
+        self.assertEqual(cache_dir.parent, tmp_dir)
+      finally:
+        self.platform.rm(cache_dir, dir=True, missing_ok=True)
+        if self.platform.is_local:
+          self.platform.set_cache_dir(DEFAULT_CACHE_DIR)
+
+  def test_default_local_cache_dir(self):
+    if self.platform.is_remote:
+      return
+    cache_dir = self.platform.local_cache_dir()
+    try:
+      self.assertTrue(self.platform.is_dir(cache_dir))
+      self.assertEqual(cache_dir, DEFAULT_CACHE_DIR)
+    finally:
+      self.platform.rm(cache_dir, dir=True, missing_ok=True)
+
+  def test_local_cache_dir(self):
+    if self.platform.is_remote:
+      return
+    cache_dir = self.platform.local_cache_dir("test")
+    try:
+      self.assertTrue(self.platform.is_dir(cache_dir))
+      self.assertEqual(cache_dir.parent, DEFAULT_CACHE_DIR)
+    finally:
+      self.platform.rm(cache_dir, dir=True, missing_ok=True)
+
+  def test_has_display(self):
+    self.assertIn(self.platform.has_display, (True, False))
+
+  def test_processes(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    processes = self.platform.processes(["name"])
+    self.assertTrue(processes)
+    for process_info in processes:
+      self.assertIn("name", process_info)
+
+  def test_process_running(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    if self.platform.is_win:
+      self.skipTest("Too Slow on windows")
+    if test_helper.is_google_env():
+      self.skipTest("Not supported yet in google environment.")
+    self.assertFalse(self.platform.process_running([]))
+    self.assertFalse(
+        self.platform.process_running(["crossbench_invalid_test_bin"]))
+    executable = pathlib.Path(sys.executable)
+    self.assertTrue(self.platform.process_running([executable.name]))
+
+  def test_process_info(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    if test_helper.is_google_env():
+      self.skipTest("Not supported yet in google environment.")
+    process_info = self.platform.process_info(os.getpid())
+    self.assertIn("python", process_info["name"].lower())
+
+  def test_process_children(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    process_info = self.platform.process_children(os.getpid())
+    self.assertIsInstance(process_info, list)
+    process_info = self.platform.process_children(os.getpid(), recursive=True)
+    self.assertIsInstance(process_info, list)
+
+  @unittest.skipIf(
+      not plt.PLATFORM.which("python3"), reason="python3 not installed")
+  def test_binary_lookup_override(self):
+    test_binary = "crossbench-non-existing-test-binary"
+    self.assertIsNone(self.platform.lookup_binary_override(test_binary))
+    self.assertIsNone(self.platform.which(test_binary))
+    # Use an arbitrary existing binary for testing.
+    override_binary = self.platform.which("python3")
+    self.assertTrue(override_binary)
+    with self.platform.override_binary(test_binary, override_binary):
+      self.assertEqual(self.platform.which(test_binary), override_binary)
+      with self.platform.override_binary(test_binary, None):
+        self.assertIsNone(self.platform.lookup_binary_override(test_binary))
+        self.assertIsNone(self.platform.which(test_binary))
+      self.assertEqual(self.platform.which(test_binary), override_binary)
+    self.assertIsNone(self.platform.lookup_binary_override(test_binary))
+    self.assertIsNone(self.platform.which(test_binary))
+
+
+@unittest.skipIf(not plt.PLATFORM.is_posix, "Incompatible platform")
+class PosixNativePlatformTestCase(NativePlatformTestCase):
+  platform: PosixPlatform
+
+  def setUp(self):
+    super().setUp()
+    assert isinstance(plt.PLATFORM, PosixPlatform)
+    self.platform: PosixPlatform = plt.PLATFORM
+
+  def test_sh(self):
+    ls = self.platform.sh_stdout("ls")
+    self.assertTrue(ls)
+    lsa = self.platform.sh_stdout("ls", "-a")
+    self.assertTrue(lsa)
+    self.assertNotEqual(ls, lsa)
+
+  def test_sh_bytes(self):
+    ls_bytes = self.platform.sh_stdout_bytes("ls")
+    self.assertIsInstance(ls_bytes, bytes)
+    ls_str = self.platform.sh_stdout("ls")
+    self.assertEqual(ls_str, ls_bytes.decode("utf-8"))
+
+  def test_which(self):
+    ls_bin = self.platform.which("ls")
+    self.assertIsNotNone(ls_bin)
+    bash_bin = self.platform.which("bash")
+    self.assertIsNotNone(bash_bin)
+    self.assertNotEqual(ls_bin, bash_bin)
+    self.assertTrue(pathlib.Path(ls_bin).exists())
+    self.assertTrue(pathlib.Path(bash_bin).exists())
+
+  def test_system_details(self):
+    details = self.platform.system_details()
+    self.assertTrue(details)
+
+  def test_search_binary(self):
+    result_path = self.platform.search_binary(pathlib.Path("ls"))
+    self.assertIsNotNone(result_path)
+    self.assertIn("ls", result_path.parts)
+    self.assertTrue(self.platform.exists(result_path))
+
+  def test_search_binary_posix_lookup_override(self):
+    path = pathlib.Path("ls")
+    override = self.platform.which("cp")
+    with self.platform.override_binary(path, override):
+      result_path = self.platform.search_binary(path)
+      self.assertEqual(result_path, override)
+      self.assertTrue(self.platform.exists(result_path))
+
+    result_path_2 = self.platform.search_binary(path)
+    self.assertNotEqual(result_path_2, result_path)
+    self.assertTrue(self.platform.exists(result_path_2))
+    self.assertIsNone(self.platform.lookup_binary_override(path))
+
+  def test_environ(self):
+    env = self.platform.environ
+    self.assertTrue(env)
+    self.assertIn("PATH", env)
+    self.assertTrue(list(env))
+
+  def test_environ_set_property(self):
+    env = self.platform.environ
+    custom_key = f"CROSSBENCH_TEST_KEY_{len(env)}"
+    self.assertNotIn(custom_key, env)
+    with self.assertRaises(Exception):
+      env[custom_key] = 1234
+    env[custom_key] = "1234"
+    self.assertEqual(env[custom_key], "1234")
+    self.assertIn(custom_key, env)
+    del env[custom_key]
+    self.assertNotIn(custom_key, env)
+
+  def test_app_version(self):
+    if test_helper.is_google_env():
+      self.skipTest("Not supported yet in google environment.")
+    python_path = sys.executable
+    with self.assertRaises(ValueError):
+      self.platform.app_version("path/to/invalid/test/crossbench/bin")
+    version = self.platform.app_version(python_path)
+    self.assertTrue(version)
+
+class MockRemotePosixPlatform(type(plt.PLATFORM)):
+
+  @property
+  def host_platform(self):
+    return plt.PLATFORM
+
+  def is_remote(self) -> bool:
+    return True
+
+  def local_path(self, path):
+    # override to bypass is_local checks
+    return pathlib.Path(path)
+
+  def sh(self, *args, **kwargs):
+    return plt.PLATFORM.sh(*args, **kwargs)
+
+  def sh_stdout(self, *args, **kwargs):
+    return plt.PLATFORM.sh_stdout(*args, **kwargs)
+
+
+@unittest.skipIf(not plt.PLATFORM.is_posix, "Incompatible platform")
+class MockRemotePosixPlatformTestCase(PosixNativePlatformTestCase):
+  """All Posix operations should also work on a remote platform (e.g. via SSH).
+  This test fakes this by temporarily changing the current PLATFORM's is_remote
+  getter to return True"""
+
+  def setUp(self):
+    super().setUp()
+    self.platform = MockRemotePosixPlatform()
+
+  def test_is_remote(self):
+    self.assertTrue(self.platform.is_remote)
+
+  def tests_default_tmp_dir(self):
+    self.assertEqual(self.platform.default_tmp_dir,
+                     plt.PLATFORM.default_tmp_dir)
+
+  def test_environ_set_property(self):
+    raise self.skipTest("Not supported on remote platforms")
+
+  def test_cpu_usage(self):
+    raise self.skipTest("Not supported on remote platforms")
+
+
+@unittest.skipIf(not plt.PLATFORM.is_macos, "Incompatible platform")
+class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
+  platform: plt.MacOSPlatform
+
+  def setUp(self):
+    super().setUp()
+    assert isinstance(plt.PLATFORM, plt.MacOSPlatform)
+    self.platform = plt.PLATFORM
+
+  def test_search_app_binary_not_found(self):
+    binary = self.platform.search_binary(pathlib.Path("Invalid App Name"))
+    self.assertIsNone(binary)
+    binary = self.platform.search_binary(pathlib.Path("Non-existent App.app"))
+    self.assertIsNone(binary)
+
+  def test_search_app_binary(self):
+    binary = self.platform.search_binary(pathlib.Path("Safari.app"))
+    self.assertIsNotNone(binary)
+    self.assertTrue(self.platform.is_file(binary))
+    # We should get the binary not the app bundle
+    self.assertFalse(binary.suffix, ".app")
+    self.assertEqual(binary.name, "Safari")
+
+  def test_search_app_binary_override(self):
+    override = pathlib.Path("/System/Applications/Calendar.app")
+    with self.platform.override_binary("Safari.app", override):
+      binary = self.platform.search_binary(pathlib.Path("Safari.app"))
+      self.assertIsNotNone(binary)
+      self.assertTrue(self.platform.is_file(binary))
+      # We should get the binary not the app bundle
+      self.assertFalse(binary.suffix, ".app")
+    self.assertEqual(binary.name, "Calendar")
+
+  def test_search_app_invalid(self):
+    with self.assertRaises(ValueError):
+      self.platform.search_app(pathlib.Path("Invalid App Name"))
+
+  def test_search_app_none(self):
+    self.assertIsNone(self.platform.search_app(pathlib.Path("No App.app")))
+
+  def test_search_app(self):
+    binary = self.platform.search_app(pathlib.Path("Safari.app"))
+    self.assertIsNotNone(binary)
+    self.assertTrue(self.platform.exists(binary))
+    self.assertTrue(self.platform.is_dir(binary))
+
+  def test_search_app_override(self):
+    override = pathlib.Path("/System/Applications/Calendar.app")
+    with self.platform.override_binary("Safari.app", override):
+      binary = self.platform.search_app(pathlib.Path("Safari.app"))
+      self.assertIsNotNone(binary)
+      self.assertTrue(self.platform.exists(binary))
+      self.assertTrue(self.platform.is_dir(binary))
+      self.assertEqual(binary.name, "Calendar.app")
+
+  def test_app_version_app(self):
+    app = self.platform.search_app(pathlib.Path("Safari.app"))
+    self.assertIsNotNone(app)
+    self.assertTrue(app.is_dir())
+    version = self.platform.app_version(app)
+    self.assertRegex(version, r"[0-9]+\.[0-9]+")
+
+  def test_app_version_app_binary(self):
+    binary = self.platform.search_binary(pathlib.Path("Safari.app"))
+    self.assertIsNotNone(binary)
+    self.assertTrue(binary.is_file())
+    version = self.platform.app_version(binary)
+    self.assertRegex(version, r"[0-9]+\.[0-9]+")
+
+  def test_app_version_binary(self):
+    binary = pathlib.Path("/usr/bin/safaridriver")
+    self.assertTrue(binary.is_file())
+    version = self.platform.app_version(binary)
+    self.assertRegex(version, r"[0-9]+\.[0-9]+")
+
+  def test_name(self):
+    self.assertEqual(self.platform.name, "macos")
+
+  def test_version(self):
+    self.assertTrue(self.platform.version)
+    self.assertRegex(self.platform.version, r"[0-9]+\.[0-9]")
+
+  def test_device(self):
+    self.assertTrue(self.platform.device)
+    self.assertRegex(self.platform.device, r"[a-zA-Z]+[0-9]+,[0-9]+")
+
+  def test_cpu(self):
+    self.assertTrue(self.platform.cpu)
+    self.assertRegex(self.platform.cpu, r".* [0-9]+ cores")
+
+  def test_foreground_process(self):
+    self.assertTrue(self.platform.foreground_process())
+
+  def test_is_macos(self):
+    self.assertTrue(self.platform.is_macos)
+    self.assertFalse(self.platform.is_linux)
+    self.assertFalse(self.platform.is_win)
+    self.assertFalse(self.platform.is_remote)
+
+  def test_set_main_screen_brightness(self):
+    prev_level = plt.PLATFORM.get_main_display_brightness()
+    brightness_level = 32
+    plt.PLATFORM.set_main_display_brightness(brightness_level)
+    self.assertEqual(brightness_level,
+                     plt.PLATFORM.get_main_display_brightness())
+    plt.PLATFORM.set_main_display_brightness(prev_level)
+    self.assertEqual(prev_level, plt.PLATFORM.get_main_display_brightness())
+
+  def test_check_autobrightness(self):
+    self.platform.check_autobrightness()
+
+  def test_exec_apple_script(self):
+    self.assertEqual(
+        self.platform.exec_apple_script('copy "a value" to stdout').strip(),
+        "a value")
+
+  def test_exec_apple_script_args(self):
+    result = self.platform.exec_apple_script(  # pylint: disable=assignment-from-no-return
+        "copy item 1 of argv to stdout", "a value", "b")
+    self.assertEqual(result.strip(), "a value")
+    result = self.platform.exec_apple_script(  # pylint: disable=assignment-from-no-return
+        "copy item 2 of argv to stdout", "a value", "b")
+    self.assertEqual(result.strip(), "b")
+
+  def test_exec_apple_script_invalid(self):
+    with self.assertRaises(plt.SubprocessError):
+      self.platform.exec_apple_script("something is not right 11")
+
+
+@unittest.skipIf(not plt.PLATFORM.is_win, "Incompatible platform")
+class WinNativePlatformTestCase(NativePlatformTestCase):
+  platform: plt.WinPlatform
+
+  def setUp(self):
+    super().setUp()
+    assert isinstance(plt.PLATFORM, plt.WinPlatform)
+    self.platform = plt.PLATFORM
+
+  def test_sh(self):
+    ls = self.platform.sh_stdout("ls")
+    self.assertTrue(ls)
+
+  def test_search_binary(self):
+    with self.assertRaises(ValueError):
+      self.platform.search_binary(pathlib.Path("does not exist"))
+    path = self.platform.search_binary(
+        pathlib.Path("Windows NT/Accessories/wordpad.exe"))
+    self.assertTrue(path and path.exists())
+
+  def test_app_version(self):
+    path = self.platform.search_binary(
+        pathlib.Path("Windows NT/Accessories/wordpad.exe"))
+    self.assertTrue(path and path.exists())
+    version = self.platform.app_version(path)
+    self.assertIsNotNone(version)
+
+  def test_is_macos(self):
+    self.assertFalse(self.platform.is_macos)
+    self.assertFalse(self.platform.is_linux)
+    self.assertTrue(self.platform.is_win)
+    self.assertFalse(self.platform.is_remote)
+
+  def test_has_display(self):
+    self.assertIn(self.platform.has_display, (True, False))
+
+  def test_version(self):
+    self.assertTrue(self.platform.version)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_platform.py b/tests/crossbench/plt/test_platform.py
new file mode 100644
index 0000000..356b8eb
--- /dev/null
+++ b/tests/crossbench/plt/test_platform.py
@@ -0,0 +1,47 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import unittest
+
+from crossbench.plt import MachineArch
+from tests import test_helper
+
+
+class MachineArchTestCase(unittest.TestCase):
+
+  def test_is_arm(self):
+    self.assertFalse(MachineArch.IA32.is_arm)
+    self.assertFalse(MachineArch.X64.is_arm)
+    self.assertTrue(MachineArch.ARM_32.is_arm)
+    self.assertTrue(MachineArch.ARM_64.is_arm)
+
+  def test_is_intel(self):
+    self.assertTrue(MachineArch.IA32.is_intel)
+    self.assertTrue(MachineArch.X64.is_intel)
+    self.assertFalse(MachineArch.ARM_32.is_intel)
+    self.assertFalse(MachineArch.ARM_64.is_intel)
+
+  def test_is_32bit(self):
+    self.assertTrue(MachineArch.IA32.is_32bit)
+    self.assertFalse(MachineArch.X64.is_32bit)
+    self.assertTrue(MachineArch.ARM_32.is_32bit)
+    self.assertFalse(MachineArch.ARM_64.is_32bit)
+
+  def test_is_64bit(self):
+    self.assertFalse(MachineArch.IA32.is_64bit)
+    self.assertTrue(MachineArch.X64.is_64bit)
+    self.assertFalse(MachineArch.ARM_32.is_64bit)
+    self.assertTrue(MachineArch.ARM_64.is_64bit)
+
+  def test_str(self):
+    self.assertEqual(str(MachineArch.IA32), "ia32")
+    self.assertEqual(str(MachineArch.X64), "x64")
+    self.assertEqual(str(MachineArch.ARM_32), "arm32")
+    self.assertEqual(str(MachineArch.ARM_64), "arm64")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_win.py b/tests/crossbench/plt/test_win.py
new file mode 100644
index 0000000..afc1866
--- /dev/null
+++ b/tests/crossbench/plt/test_win.py
@@ -0,0 +1,84 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import os
+import pathlib
+from unittest import mock
+
+from crossbench import path as pth
+from tests import test_helper
+from tests.crossbench.mock_helper import WinMockPlatform
+from tests.crossbench.plt.helper import BaseMockPlatformTestCase
+
+
+class WinMockPlatformTestCase(BaseMockPlatformTestCase):
+  __test__ = True
+
+  def mock_platform_setup(self):
+    self.mock_platform = WinMockPlatform()
+    self.platform = self.mock_platform
+
+  def path(self, path: pth.AnyPathLike) -> pathlib.PureWindowsPath:
+    return pathlib.PureWindowsPath(path)
+
+  def test_is_win(self):
+    self.assertTrue(self.platform.is_win)
+
+  def test_path_conversion(self):
+    self.assertIsInstance(
+        self.platform.path("foo/bar"), pathlib.PureWindowsPath)
+    self.assertIsInstance(
+        self.platform.path(pathlib.PurePath("foo/bar")),
+        pathlib.PureWindowsPath)
+    self.assertIsInstance(
+        self.platform.path(pathlib.PureWindowsPath("foo/bar")),
+        pathlib.PureWindowsPath)
+    self.assertIsInstance(
+        self.platform.path(pathlib.PurePosixPath("foo/bar")),
+        pathlib.PureWindowsPath)
+
+  def test_which(self):
+    bin_path = self.path("foo/bar/default/crossbench_mock_binary.exe")
+    self.assertIsNone(self.platform.which(bin_path))
+    with mock.patch("shutil.which", return_value=bin_path) as cm:
+      self.assertEqual(self.platform.which(bin_path), bin_path)
+    cm.assert_called_once_with(os.fspath(bin_path))
+
+  def test_which_invalid(self):
+    with self.assertRaises(ValueError) as cm:
+      self.platform.which("")
+    self.assertIn("empty", str(cm.exception))
+
+  def test_search_binary_invalid(self):
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_binary("")
+    self.assertIn("empty", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      self.platform.search_binary("foo/bar")
+    self.assertIn(".exe", str(cm.exception))
+
+  def test_search_binary_broken_which(self):
+    bin_path = self.path("foo/bar/default/crossbench_mock_binary.exe")
+    self.assertIsNone(self.platform.search_app(bin_path))
+    with mock.patch("shutil.which", return_value=bin_path) as cm:
+      with self.assertRaises(AssertionError) as search_cm:
+        self.assertEqual(self.platform.search_app(bin_path), bin_path)
+      self.assertIn("exist", str(search_cm.exception))
+    cm.assert_called_once_with(os.fspath(bin_path))
+
+  def test_search_binary(self):
+    bin_path = self.path("foo/bar/default/crossbench_mock_binary.exe")
+    self.assertFalse(self.platform.exists(bin_path))
+    self.assertIsNone(self.platform.search_app(bin_path))
+    self.fs.create_file(self.platform.local_path(bin_path), st_size=100)
+    self.assertTrue(self.platform.exists(bin_path))
+    with mock.patch("shutil.which", return_value=bin_path) as cm:
+      self.assertEqual(self.platform.search_app(bin_path), bin_path)
+    cm.assert_called_once_with(os.fspath(bin_path))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/__init__.py b/tests/crossbench/probes/__init__.py
new file mode 100644
index 0000000..3ea02f9
--- /dev/null
+++ b/tests/crossbench/probes/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/probes/helper.py b/tests/crossbench/probes/helper.py
new file mode 100644
index 0000000..b26aaf7
--- /dev/null
+++ b/tests/crossbench/probes/helper.py
@@ -0,0 +1,116 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import copy
+import json
+from typing import (TYPE_CHECKING, Any, Callable, Iterable, List, Sequence,
+                    Tuple, Union)
+
+from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+from crossbench.benchmarks.loading.page.combined import CombinedPage
+from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.probes.probe import Probe
+from crossbench.runner.runner import Runner
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.loading.page.base import Page
+
+class GenericProbeTestCase(BaseCrossbenchTestCase):
+
+  def create_runner(self,
+                    stories: Sequence[Page],
+                    js_side_effects: Union[List[Any], Callable[[Page],
+                                                               List[Any]]],
+                    separate: bool = False,
+                    repetitions: int = 3,
+                    warmup_repetitions: int = 0,
+                    cache_temperatures: Iterable[str] = ("default",),
+                    throw: bool = True) -> Runner:
+    self.assertTrue(stories)
+    if not separate and len(stories) > 1:
+      stories = [CombinedPage(stories)]
+    if isinstance(js_side_effects, list):
+      js_side_effects_fn = lambda story: js_side_effects  # pylint: disable=unnecessary-lambda-assignment
+    else:
+      js_side_effects_fn = js_side_effects
+    # The order should match Runner.get_runs
+    for _ in range(warmup_repetitions + repetitions):
+      for story in stories:
+        story_js_side_effects = js_side_effects_fn(story)
+        for browser in self.browsers:
+          for js_result in story_js_side_effects:
+            browser.expect_js(result=js_result)
+
+    for browser in self.browsers:
+      browser.expected_js = copy.deepcopy(browser.expected_js)
+
+    benchmark = PageLoadBenchmark(stories)  # pytype: disable=not-instantiable
+    self.assertTrue(len(benchmark.describe()) > 0)
+    runner = Runner(
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        env_config=HostEnvironmentConfig(),
+        env_validation_mode=ValidationMode.SKIP,
+        platform=self.platform,
+        repetitions=repetitions,
+        warmup_repetitions=warmup_repetitions,
+        cache_temperatures=cache_temperatures,
+        throw=throw)
+    return runner
+
+  def get_non_empty_json_results(self, runner: Runner,
+                                probe: Probe) -> Tuple[Any, Any, Any, Any]:
+    story_json_file = runner.runs[0].results[probe].json
+    with story_json_file.open() as f:
+      story_json_data = json.load(f)
+    self.assertIsNotNone(story_json_data)
+
+    repetitions_json_file = runner.repetitions_groups[0].results[probe].json
+    with repetitions_json_file.open() as f:
+      repetitions_json_data = json.load(f)
+    self.assertIsNotNone(repetitions_json_data)
+
+    stories_json_file = runner.story_groups[0].results[probe].json
+    with stories_json_file.open() as f:
+      stories_json_data = json.load(f)
+    self.assertIsNotNone(stories_json_data)
+
+    browsers_json_file = runner.browser_group.results[probe].json
+    with browsers_json_file.open() as f:
+      browsers_json_data = json.load(f)
+    self.assertIsNotNone(browsers_json_data)
+    return (story_json_data, repetitions_json_data, stories_json_data,
+            browsers_json_data)
+
+  def get_non_empty_results_str(
+      self,
+      runner: Runner,
+      probe: Probe,
+      suffix: str,
+      has_browsers_data: bool = True) -> Tuple[str, str, str, str]:
+    story_file = runner.runs[0].results[probe].get_all(suffix)[0]
+    story_data = story_file.read_text()
+    self.assertTrue(story_data)
+
+    repetitions_file = runner.repetitions_groups[0].results[probe].get_all(
+        suffix)[0]
+    repetitions_data = repetitions_file.read_text()
+    self.assertTrue(repetitions_data)
+
+    stories_file = runner.story_groups[0].results[probe].get_all(suffix)[0]
+    stories_data = stories_file.read_text()
+    self.assertTrue(stories_data)
+
+    if has_browsers_data:
+      browsers_file = runner.browser_group.results[probe].get_all(suffix)[0]
+      browsers_data = browsers_file.read_text()
+      self.assertTrue(browsers_data)
+    else:
+      browsers_data = ""
+
+    return (story_data, repetitions_data, stories_data, browsers_data)
diff --git a/tests/crossbench/probes/test_chrome_histograms.py b/tests/crossbench/probes/test_chrome_histograms.py
new file mode 100644
index 0000000..a4736dd
--- /dev/null
+++ b/tests/crossbench/probes/test_chrome_histograms.py
@@ -0,0 +1,181 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import unittest
+from typing import Dict
+
+import hjson
+import pytest
+
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.probes.chrome_histograms import (ChromeHistogramMetric,
+                                                 ChromeHistogramSample,
+                                                 ChromeHistogramsProbe,
+                                                 parse_histogram_metrics)
+from tests import test_helper
+from tests.crossbench.probes.helper import GenericProbeTestCase
+
+
+class ChromeHistogramProbeTestCase(GenericProbeTestCase):
+  HISTOGRAM_NAME = "test"
+
+  BASELINE_HEADER = (
+      "Histogram: test recorded 50 samples, mean = 57.4 (flags = 0x41)")
+
+  BASELINE_BODY = """0  -----O                     (5 = 10.0%) {0.0%}
+10 ... 
+20 -----O                     (5 = 10.0%) {10.0%}
+30 -------O                   (7 = 14.0%) {20.0%}
+40 -----O                     (5 = 10.0%) {34.0%}
+50 -----O                     (5 = 10.0%) {44.0%}
+60 -----O                     (5 = 10.0%) {54.0%}
+70 ----O                      (4 = 8.0%) {64.0%}
+80 --O                        (2 = 4.0%) {72.0%}
+90 ------------O              (12 = 24.0%) {76.0%}
+"""
+
+  DELTA_HEADER = (
+      "Histogram: test recorded 100 samples, mean = 52.11 (flags = 0x41)")
+  DELTA_BODY = """0  ------------O              (12 = 12.0%) {0.0%}
+10 -------O                   (7 = 7.0%) {12.0%}
+20 -----------O               (11 = 11.0%) {19.0%}
+30 ---------O                 (9 = 9.0%) {30.0%}
+40 --------------O            (14 = 14.0%) {39.0%}
+50 ------O                    (6 = 6.0%) {53.0%}
+60 --------O                  (8 = 8.0%) {59.0%}
+70 --------O                  (8 = 8.0%) {67.0%}
+80 -------O                   (7 = 7.0%) {75.0%}
+90 ------------------O        (18 = 18.0%) {82.0%}
+"""
+
+  def _sample_json(self, name: str, header: str, body: str) -> Dict:
+    return {
+        "name": name,
+        "header": header,
+        "body": body,
+    }
+
+  def _baseline(self) -> ChromeHistogramSample:
+    json = self._sample_json(self.HISTOGRAM_NAME, self.BASELINE_HEADER,
+                             self.BASELINE_BODY)
+    return ChromeHistogramSample.from_json(json)
+
+  def _delta(self) -> ChromeHistogramSample:
+    json = self._sample_json(self.HISTOGRAM_NAME, self.DELTA_HEADER,
+                             self.DELTA_BODY)
+    return ChromeHistogramSample.from_json(json)
+
+  def test_parse_histogram_metrics_invalid(self):
+    with pytest.raises(
+        argparse.ArgumentTypeError,
+        match="invalid.metric foo is not a valid metric"):
+      parse_histogram_metrics({"invalid.metric": ["foo"]})
+    with pytest.raises(
+        argparse.ArgumentTypeError,
+        match="invalid.metric p101 is not a valid percentile"):
+      parse_histogram_metrics({"invalid.metric": ["p101"]})
+
+  def _parse_one_metric(self, histogram_name: str,
+                        metric_type: str) -> ChromeHistogramMetric:
+    metrics = parse_histogram_metrics({histogram_name: [metric_type]})
+    if len(metrics) != 1:
+      raise ValueError(f"expected exactly 1 metric, got {len(metrics)}")
+    return metrics[0]
+
+  def test_count(self):
+    metric = self._parse_one_metric(self.HISTOGRAM_NAME, "count")
+    value = metric.compute(self._delta(), self._baseline())
+    self.assertEqual(50, value)
+
+  def test_mean(self):
+    metric = self._parse_one_metric(self.HISTOGRAM_NAME, "mean")
+    value = metric.compute(self._delta(), self._baseline())
+    self.assertEqual(value, 46.82)
+
+  def test_mean_no_baseline(self):
+    metric = self._parse_one_metric(self.HISTOGRAM_NAME, "mean")
+    value = metric.compute(self._delta(),
+                           ChromeHistogramSample(self.HISTOGRAM_NAME))
+    self.assertEqual(value, 52.11)
+
+  def test_percentile(self):
+    metrics = parse_histogram_metrics(
+        {self.HISTOGRAM_NAME: ["p25", "p50", "p75", "p90", "p99"]})
+    values = map(lambda m: m.compute(self._delta(), self._baseline()), metrics)
+    self.assertListEqual([16.875, 43, 75, 90, 90], list(values))
+
+  def test_sample_invalid_header(self):
+    with pytest.raises(
+        argparse.ArgumentTypeError,
+        match="test histogram header has invalid data: foo"):
+      ChromeHistogramSample.from_json(
+          self._sample_json("test", "foo", self.BASELINE_BODY))
+
+  def test_sample_invalid_body(self):
+    with pytest.raises(
+        argparse.ArgumentTypeError,
+        match="test histogram body line 11 has invalid data: bar"):
+      ChromeHistogramSample.from_json(
+          self._sample_json("test", self.BASELINE_HEADER,
+                            self.BASELINE_BODY + "bar\n"))
+
+  def test_sample_count_header_body_mismatch(self):
+    with pytest.raises(
+        Exception,
+        match="Histogram test has 50 total samples, but buckets add to 100"):
+      ChromeHistogramSample.from_json(
+          self._sample_json("test", self.BASELINE_HEADER, self.DELTA_BODY))
+
+  def test_sample_bucket_max(self):
+    self.assertEqual(10, self._delta().bucket_max(0))
+    self.assertEqual(20, self._delta().bucket_max(10))
+    self.assertEqual(None, self._delta().bucket_max(90))
+
+  def test_sample_diff_percentile_invalid(self):
+    with pytest.raises(Exception, match="-1 is not a valid percentile"):
+      self._delta().diff_percentile(self._baseline(), -1)
+
+    with pytest.raises(
+        Exception, match="test can not compute percentile without any samples"):
+      self._delta().diff_percentile(self._delta(), 50)
+
+  def test_sample_diff_mean_invalid(self):
+    with pytest.raises(
+        Exception, match="test can not compute mean without any samples"):
+      self._delta().diff_mean(self._delta())
+
+    no_mean = ChromeHistogramSample.from_json(
+        self._sample_json("test",
+                          "Histogram: test recorded 50 samples (flags = 0x41)",
+                          self.BASELINE_BODY))
+    with pytest.raises(
+        Exception, match="test has no mean reported, is it an enum histogram?"):
+      self._delta().diff_mean(no_mean)
+
+  def test_sample_name(self):
+    self.assertEqual(self.HISTOGRAM_NAME, self._delta().name)
+
+  @unittest.skipIf(hjson.__name__ != "hjson", "hjson not available")
+  def test_parse_example_config(self):
+    config_file = (
+        test_helper.config_dir() / "doc/probe/chrome_histograms.hjson")
+    self.fs.add_real_file(config_file)
+    self.assertTrue(config_file.is_file())
+    probes = ProbeListConfig.parse_path(config_file).probes
+    self.assertEqual(len(probes), 1)
+    probe = probes[0]
+    self.assertIsInstance(probe, ChromeHistogramsProbe)
+    isinstance(probe, ChromeHistogramsProbe)
+    probe: ChromeHistogramsProbe = probe
+    self.assertListEqual([metric.name for metric in probe.metrics], [
+        "WebVitals.FirstContentfulPaint3_count",
+        "WebVitals.FirstContentfulPaint3_mean",
+        "WebVitals.FirstContentfulPaint3_p50",
+        "WebVitals.FirstContentfulPaint3_p90",
+        "Startup.FirstWebContents.NonEmptyPaint3_count",
+        "Startup.FirstWebContents.NonEmptyPaint3_mean",
+        "Startup.FirstWebContents.NonEmptyPaint3_p50",
+        "Startup.FirstWebContents.NonEmptyPaint3_p90",
+    ])
diff --git a/tests/crossbench/probes/test_config.py b/tests/crossbench/probes/test_config.py
new file mode 100644
index 0000000..6851192
--- /dev/null
+++ b/tests/crossbench/probes/test_config.py
@@ -0,0 +1,231 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import unittest
+
+from crossbench import compat
+from crossbench.probes.probe import Probe, ProbeConfigParser
+from tests import test_helper
+
+
+class MockProbe(Probe):
+  """
+  Probe DOC Text
+  """
+
+
+class CustomArgType:
+
+  def __init__(self, value):
+    self.value = value
+
+
+def custom_arg_type(value):
+  return CustomArgType(value)
+
+
+class ProbeConfigTestCase(unittest.TestCase):
+
+  def test_help_text(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("bool", type=bool)
+    parser.add_argument("bool_default", type=bool, default=False)
+    parser.add_argument("str_empty_default", type=str, default="")
+    parser.add_argument("bool_list", type=bool, default=(False,), is_list=True)
+    parser.add_argument("any_list", type=None, default=(1,), is_list=True)
+    parser.add_argument(
+        "empty_default_list", type=None, default=[], is_list=True)
+    parser.add_argument("custom_type", type=custom_arg_type)
+    parser.add_argument("custom_help", type=bool, help="custom help")
+    help_text = str(parser)
+    self.assertIn("Probe DOC Text", help_text)
+    self.assertIn("bool_default", help_text)
+    self.assertIn("str_empty_default", help_text)
+    self.assertIn("bool_list", help_text)
+    self.assertIn("any_list", help_text)
+    self.assertIn("empty_default_list", help_text)
+    self.assertIn("custom_type", help_text)
+    self.assertIn("custom_help", help_text)
+
+  def test_invalid_config_duplicate(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("bool", type=bool)
+    with self.assertRaises(ValueError):
+      parser.add_argument("bool", type=bool)
+
+  def test_config_defaults(self):
+    parser = ProbeConfigParser(MockProbe)
+    with self.assertRaises(ValueError):
+      parser.add_argument("bool", type=bool, default=1)
+    parser.add_argument("any", type=object, default=1)
+
+  def test_config_defaults_list(self):
+    parser = ProbeConfigParser(MockProbe)
+    with self.assertRaisesRegex(ValueError, "True"):
+      parser.add_argument("bool", type=bool, is_list=True, default=True)
+    with self.assertRaisesRegex(ValueError, "string"):
+      parser.add_argument("str", type=str, is_list=True, default="str")
+    with self.assertRaises(ValueError):
+      parser.add_argument("bool", type=bool, is_list=True, default=(1, 1))
+    parser.add_argument("bool", type=bool, is_list=True, default=(True, False))
+    parser.add_argument(
+        "custom_list",
+        type=lambda x: x + 1,
+        is_list=True,
+        default=(True, False))
+
+  def test_bool_missing_property(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("bool_argument_name", type=bool, required=True)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"other": True})
+
+  def test_bool_invalid_value(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("bool_argument_name", type=bool)
+    parser_required = ProbeConfigParser(MockProbe)
+    parser_required.add_argument("bool_argument_name", type=bool, required=True)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"bool_argument_name": "not a bool"})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"bool_argument_name": ""})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"bool_argument_name": {}})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"bool_argument_name": []})
+    # Argument is not required, this should pass
+    parser.kwargs_from_config({"bool_argument_name": None})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser_required.kwargs_from_config({"bool_argument_name": None})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"bool_argument_name": 0})
+
+  def test_bool_default(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("bool_argument_name", type=bool, default=False)
+
+    config_data = {}
+    kwargs = parser.kwargs_from_config(config_data)
+    self.assertDictEqual(config_data, {})
+    self.assertDictEqual(kwargs, {"bool_argument_name": False})
+
+    config_data = {"bool_argument_name": True}
+    kwargs = parser.kwargs_from_config(config_data)
+    self.assertDictEqual(config_data, {"bool_argument_name": True})
+    self.assertDictEqual(kwargs, {"bool_argument_name": True})
+
+  def test_bool(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("bool_argument_name", type=bool)
+    config_data = {"bool_argument_name": True}
+    kwargs = parser.kwargs_from_config(config_data)
+    self.assertDictEqual(config_data, {"bool_argument_name": True})
+    self.assertDictEqual(kwargs, {"bool_argument_name": True})
+
+  def test_int_list_invalid(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("int_list", type=int, is_list=True, default=[111, 222])
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"int_list": 9})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"int_list": ["0", "1"]})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"int_list": "0,1"})
+
+  def test_int_list(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("int_list", type=int, is_list=True, default=[111, 222])
+    kwargs = parser.kwargs_from_config({})
+    self.assertDictEqual(kwargs, {"int_list": [111, 222]})
+
+    config_data = {"int_list": [0, 1]}
+    kwargs = parser.kwargs_from_config(config_data)
+    self.assertDictEqual(config_data, {"int_list": [0, 1]})
+    self.assertDictEqual(kwargs, {"int_list": [0, 1]})
+
+  def test_custom_type(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("custom", type=custom_arg_type)
+    config_data = {"custom": [1, 2, "stuff"]}
+    kwargs = parser.kwargs_from_config(config_data)
+    self.assertDictEqual(config_data, {"custom": [1, 2, "stuff"]})
+    result = kwargs["custom"]
+    self.assertIsInstance(result, CustomArgType)
+    self.assertListEqual(result.value, [1, 2, "stuff"])
+
+  def test_no_type(self):
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("custom", type=None)
+    for data in ["", "a", {"a": 1}, set(), []]:
+      config_data = {"custom": data}
+      kwargs = parser.kwargs_from_config(config_data)
+      self.assertIs(kwargs["custom"], data)
+
+  def test_no_type_choices(self):
+    parser = ProbeConfigParser(MockProbe)
+    with self.assertRaises(ValueError):
+      parser.add_argument("unused", type=None, choices=[1, 1, 1])
+    with self.assertRaises(AssertionError):
+      parser.add_argument("unused", type=None, choices=[])
+    parser.add_argument("choice", type=None, choices=["a", "b"])
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"choice": ""})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"choice": "unknown"})
+    kwargs = parser.kwargs_from_config({"choice": "a"})
+    self.assertIs(kwargs["choice"], "a")
+    kwargs = parser.kwargs_from_config({"choice": "b"})
+    self.assertIs(kwargs["choice"], "b")
+
+  def test_enum_type(self):
+
+    class MyEnum(compat.StrEnum):
+      ONE = "one"
+      TWO = "two"
+
+    parser = ProbeConfigParser(MockProbe)
+    with self.assertRaises(AssertionError):
+      parser.add_argument("unused", type=MyEnum, choices=["ONE", "TWO"])
+    with self.assertRaises(AssertionError):
+      parser.add_argument("unused", type=MyEnum, choices=["one"])
+    parser.add_argument("my-enum-one", type=MyEnum, choices=[MyEnum.ONE])
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"my-enum-one": ""})
+    kwargs = parser.kwargs_from_config({"my-enum-one": "two"})
+    self.assertIs(kwargs["my-enum-one"], MyEnum.TWO)
+    kwargs = parser.kwargs_from_config({"my-enum-one": "one"})
+    self.assertIs(kwargs["my-enum-one"], MyEnum.ONE)
+
+    parser.add_argument("my-enum", type=MyEnum)
+    kwargs = parser.kwargs_from_config({"my-enum": "one"})
+    self.assertIs(kwargs["my-enum"], MyEnum.ONE)
+    kwargs = parser.kwargs_from_config({"my-enum": "two"})
+    self.assertIs(kwargs["my-enum"], MyEnum.TWO)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"my-enum": ""})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"my-enum": "three"})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser.kwargs_from_config({"my-enum": "TWO"})
+
+  def test_enum_with_help(self):
+
+    class MyEnum(compat.StrEnumWithHelp):
+      ONE = ("oneX", "the one help")
+      TWO = ("twoX", "the two help")
+
+    parser = ProbeConfigParser(MockProbe)
+    parser.add_argument("my-enum", type=MyEnum, choices=[MyEnum.ONE])
+    text = str(parser)
+    self.assertIn("the one help", text)
+    self.assertIn("the two help", text)
+    self.assertIn("oneX", text)
+    self.assertIn("twoX", text)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_config_presets.py b/tests/crossbench/probes/test_config_presets.py
new file mode 100644
index 0000000..07bb7d0
--- /dev/null
+++ b/tests/crossbench/probes/test_config_presets.py
@@ -0,0 +1,93 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import pathlib
+from typing import Dict, List, Type
+
+from pyfakefs import fake_filesystem_unittest
+
+import crossbench.path
+from crossbench import plt
+from crossbench.benchmarks.loading.loadline_presets import \
+    LoadLineTabletBenchmark
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.helper import ChangeCWD
+from crossbench.helper.path_finder import default_chromium_candidates
+from crossbench.probes.all import GENERAL_PURPOSE_PROBES
+from crossbench.probes.probe import Probe
+from tests import test_helper
+
+PROBE_LOOKUP: Dict[str, Type[Probe]] = {
+    probe_cls.NAME: probe_cls for probe_cls in GENERAL_PURPOSE_PROBES
+}
+
+
+class ProbeConfigTestCase(fake_filesystem_unittest.TestCase):
+  """Parse all example probe configs in config/probe and config/doc/probe
+
+  More detailed tests should go into dedicated probe/test_{PROBE_NAME}.py
+  files.
+  """
+
+  def setUp(self) -> None:
+    self.real_config_dir = test_helper.config_dir()
+    super().setUp()
+    self.setUpPyfakefs(modules_to_reload=[crossbench.path])
+    if test_helper.is_google_env():
+      self.fs.add_real_directory("/build/cas")
+    self.set_up_required_paths()
+
+  def set_up_required_paths(self):
+    chrome_dir = default_chromium_candidates(plt.PLATFORM)[0]
+    self.fs.create_dir(chrome_dir / "v8")
+    self.fs.create_dir(chrome_dir / "chrome")
+    self.fs.create_dir(chrome_dir / ".git")
+
+    perfetto_tools = chrome_dir / "third_party/perfetto/tools"
+    self.fs.create_file(perfetto_tools / "traceconv")
+    self.fs.create_file(perfetto_tools / "trace_processor")
+
+  def _test_parse_config_dir(self,
+                             real_config_dir: pathlib.Path) -> List[Probe]:
+    probes = []
+    self.fs.add_real_directory(
+        real_config_dir, lazy_read=not test_helper.is_google_env())
+    for probe_config in real_config_dir.glob("**/*.config.hjson"):
+      with ChangeCWD(probe_config.parent):
+        probes += self._parse_config(probe_config)
+    return probes
+
+  def _parse_config(self, config_file: pathlib.Path) -> List[Probe]:
+    probe_name = config_file.parent.name
+    if probe_name not in PROBE_LOOKUP:
+      probe_name = config_file.name.split(".")[0]
+    probe_cls = PROBE_LOOKUP[probe_name]
+
+    probes = ProbeListConfig.parse_path(config_file).probes
+    self.assertTrue(probes)
+    self.assertTrue(
+        any(map(lambda probe: isinstance(probe, probe_cls), probes)))
+    for probe in probes:
+      self.assertFalse(probe.is_attached)
+    return probes
+
+  def test_parse_example_configs(self):
+    probe_config_presets = self.real_config_dir / "probe"
+    probes = self._test_parse_config_dir(probe_config_presets)
+    self.assertTrue(probes)
+
+  def test_parse_doc_configs(self):
+    probe_config_doc = self.real_config_dir / "doc/probe"
+    probes = self._test_parse_config_dir(probe_config_doc)
+    self.assertTrue(probes)
+
+  def test_parse_loadline_configs(self):
+    probe_config = LoadLineTabletBenchmark.default_probe_config_path()
+    self.fs.add_real_file(probe_config)
+    probes = ProbeListConfig.parse_path(probe_config).probes
+    self.assertTrue(probes)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_dtrace.py b/tests/crossbench/probes/test_dtrace.py
new file mode 100644
index 0000000..1905e61
--- /dev/null
+++ b/tests/crossbench/probes/test_dtrace.py
@@ -0,0 +1,29 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.probes.dtrace import DTraceProbe
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class DTraceProbeTestCase(CrossbenchFakeFsTestCase):
+
+  def test_parse_example_config(self):
+    config_file = test_helper.config_dir() / "doc/probe/dtrace.config.hjson"
+    self.fs.add_real_file(config_file)
+    self.assertTrue(config_file.is_file())
+    example_script_file = config_file.parent / "dtrace.config.example.d"
+    self.fs.create_file(example_script_file, st_size=100)
+    self.assertTrue(example_script_file.is_file())
+    probes = ProbeListConfig.parse_path(config_file).probes
+    self.assertEqual(len(probes), 1)
+    probe = probes[0]
+    self.assertIsInstance(probe, DTraceProbe)
+    isinstance(probe, DTraceProbe)
+    self.assertEqual(probe.script_path, example_script_file)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_frequency.py b/tests/crossbench/probes/test_frequency.py
new file mode 100644
index 0000000..d320ef0
--- /dev/null
+++ b/tests/crossbench/probes/test_frequency.py
@@ -0,0 +1,230 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+from typing import List
+from unittest import mock
+
+from immutabledict import immutabledict
+
+from crossbench import path as pth
+from crossbench.browsers.browser import Browser
+from crossbench.env import HostEnvironment
+from crossbench.plt.linux import LinuxPlatform
+from crossbench.probes.cpu_frequency_map import CPUFrequencyMap
+from crossbench.probes.frequency import FrequencyProbe, FrequencyProbeContext
+from crossbench.runner.run import Run
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+# TODO(crbug.com/372862708): Turn most of these into unit tests for
+# CPUFrequencyMap and leave only 1-2 tests that verify the communication between
+# the 2 classes.
+
+
+class FrequencyProbeTestCase(CrossbenchFakeFsTestCase):
+  __test__ = True
+
+  def setUp(self):
+    super().setUp()
+    self.platform = LinuxPlatform()
+
+  def test_parse_invalid_map_value(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "Invalid value"):
+      FrequencyProbe.from_config({"cpus": {"cpu0": "invalid"}})
+
+  def test_parse_conflicting_wildcard(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError,
+                                "should be the only key"):
+      FrequencyProbe.from_config({"cpus": {"*": "max", "cpu0": "min"}})
+
+  def test_key(self):
+    key1 = FrequencyProbe.from_config({"cpus": {"cpu0": 1111}}).key
+    key2 = FrequencyProbe.from_config({"cpus": {"*": 2222}}).key
+
+    self.assertIsNotNone(key1)
+    self.assertIsNotNone(key2)
+    self.assertNotEqual(key1, key2)
+
+  def test_validate_fails_due_to_missing_cpus_dir(self):
+    probe = FrequencyProbe.from_config({"cpus": {"cpu0": 42}})
+    # No call to self._create_cpu_dir().
+
+    with self.assertRaisesRegex(FileNotFoundError,
+                                "/sys/devices/system/cpu not found"):
+      probe.validate_browser(
+          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
+
+  def test_validate_fails_due_to_missing_cpu_name(self):
+    probe = FrequencyProbe.from_config({"cpus": {"nonexistent-cpu": 1}})
+    self._create_cpu_dir("cpu0", [1])
+
+    with self.assertRaisesRegex(ValueError, "nonexistent-cpu"):
+      probe.validate_browser(
+          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
+
+  def test_validate_fails_due_to_missing_numerical_frequency(self):
+    probe = FrequencyProbe.from_config({"cpus": {"cpu0": 42}})
+    self._create_cpu_dir("cpu0", [1, 2])
+    self._create_cpu_dir("cpu1", [42])
+
+    with self.assertRaisesRegex(
+        ValueError, r"Target frequency 42 for cpu0 not allowed in linux.*. "
+        r"Available frequencies: \[1, 2\]"):
+      probe.validate_browser(
+          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
+
+  def test_validate_fails_due_to_missing_numerical_frequency_with_wildcard(
+      self):
+    probe = FrequencyProbe.from_config({"cpus": {"*": 42}})
+    self._create_cpu_dir("cpu0", [1, 2])
+
+    with self.assertRaisesRegex(
+        ValueError, r"Target frequency 42 for cpu0 not allowed in linux.*. "
+        r"Available frequencies: \[1, 2\]"):
+      probe.validate_browser(
+          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
+
+  def test_validate_succeeds_with_extremes(self):
+    probe = FrequencyProbe.from_config({"cpus": {"cpu0": "max", "cpu1": "min"}})
+    self._create_cpu_dir("cpu0", [1, 2])
+    self._create_cpu_dir("cpu1", [1, 2])
+    browser = self._create_mock_browser()
+
+    # Implicitly asserts no exception occurs.
+    probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
+    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
+        browser.platform)
+
+    self.assertDictEqual(
+        dict(frequency_map), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 1,
+        })
+
+
+  def test_validate_succeeds_without_wildcard(self):
+    probe = FrequencyProbe.from_config(
+        {"cpus": {
+            "cpu0": 2,
+            "cpu1": 2,
+            "cpu2": 2
+        }})
+    # Use different orders to stress the parsing logic.
+    self._create_cpu_dir("cpu0", [2, 1, 3])
+    self._create_cpu_dir("cpu1", [1, 2, 3])
+    self._create_cpu_dir("cpu2", [1, 3, 2])
+    self._create_cpu_dir("cpu3", [42, 42, 42])
+    self._create_cpu_dir("cpu4", [42, 42, 42])
+    browser = self._create_mock_browser()
+
+    # Implicitly asserts no exception occurs.
+    probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
+    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
+        browser.platform)
+
+    self.assertDictEqual(
+        dict(frequency_map), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu2/cpufreq"): 2,
+        })
+
+  def test_validate_succeeds_with_wildcard(self):
+    probe = FrequencyProbe.from_config({"cpus": {"*": 2}})
+    # Use different orders to stress the parsing logic.
+    self._create_cpu_dir("cpu0", [2, 1, 3])
+    self._create_cpu_dir("cpu1", [1, 2, 3])
+    self._create_cpu_dir("cpu2", [1, 3, 2])
+    browser = self._create_mock_browser()
+
+    # Implicitly asserts no exception occurs.
+    probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
+    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
+        browser.platform)
+
+    self.assertDictEqual(
+        dict(frequency_map), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu2/cpufreq"): 2,
+        })
+
+  def test_validate_succeeds_for_empty_configs(self):
+    browser = self._create_mock_browser()
+    self._create_cpu_dir("cpu0", [1, 2, 3])
+
+    FrequencyProbe.from_config({}).validate_browser(
+        mock.Mock(spec=HostEnvironment), browser)
+    FrequencyProbe.from_config({
+        "cpus": {},
+    }).validate_browser(mock.Mock(spec=HostEnvironment), browser)
+
+  def test_validate_string_wildcard(self):
+    probe = FrequencyProbe.from_config({"cpus": "max"})
+    self._create_cpu_dir("cpu0", [1, 2, 3])
+    self._create_cpu_dir("cpu1", [1, 2, 3])
+    browser = self._create_mock_browser()
+
+    # Implicitly asserts no exception occurs.
+    probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
+    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
+        browser.platform)
+
+    self.assertDictEqual(
+        dict(frequency_map), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 3,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 3,
+        })
+
+  def test_start_and_stop(self):
+    self._create_cpu_dir("cpu0", [1, 2, 3])
+    mock_map = mock.Mock(spec=CPUFrequencyMap)
+    mock_map.get_target_frequencies = mock.Mock(
+        return_value=immutabledict(
+            {pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2}))
+    mock_probe = mock.Mock(spec=FrequencyProbe)
+    type(mock_probe).cpu_frequency_map = mock.PropertyMock(
+        return_value=mock_map)
+    mock_run = mock.Mock(spec=Run)
+    mock_run.browser = self._create_mock_browser()
+    context = FrequencyProbeContext(mock_probe, mock_run)
+
+    min_file = pth.AnyPosixPath(
+        "/sys/devices/system/cpu/cpu0/cpufreq/scaling_min_freq")
+    max_file = pth.AnyPosixPath(
+        "/sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq")
+    self.assertEqual(self.platform.cat(min_file), "1\n")
+    self.assertEqual(self.platform.cat(max_file), "3\n")
+
+    context.start()
+
+    self.assertEqual(self.platform.cat(min_file), "2\n")
+    self.assertEqual(self.platform.cat(max_file), "2\n")
+    mock_map.get_target_frequencies.assert_called_with(self.platform)
+
+    context.stop()
+
+    self.assertEqual(self.platform.cat(min_file), "1\n")
+    self.assertEqual(self.platform.cat(max_file), "3\n")
+
+  def _create_mock_browser(self):
+    mock_browser = mock.Mock(spec=Browser)
+    mock_browser.platform = self.platform
+    return mock_browser
+
+  def _create_cpu_dir(self, cpu_name: str, available_frequencies: List[int]):
+    cpu_dir = pth.AnyPosixPath(f"/sys/devices/system/cpu/{cpu_name}/cpufreq")
+    self.platform.mkdir(cpu_dir, parents=True, exist_ok=True)
+    self.platform.set_file_contents(
+        cpu_dir / "scaling_available_frequencies",
+        " ".join(map(str, available_frequencies)) + "\n")
+    self.platform.set_file_contents(cpu_dir / "scaling_min_freq",
+                                    str(min(available_frequencies)) + "\n")
+    self.platform.set_file_contents(cpu_dir / "scaling_max_freq",
+                                    str(max(available_frequencies)) + "\n")
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_helper.py b/tests/crossbench/probes/test_helper.py
new file mode 100644
index 0000000..1a34688
--- /dev/null
+++ b/tests/crossbench/probes/test_helper.py
@@ -0,0 +1,338 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import csv
+import pathlib
+import unittest
+from typing import List, Optional
+
+from crossbench.probes import helper
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class TestMergeCSV(CrossbenchFakeFsTestCase):
+
+  def merge(self,
+            *args,
+            delimiter: str = "\t",
+            headers: Optional[List[str]] = None,
+            row_header_len: int = 1):
+    csv_files = []
+    for index, content in enumerate(args):
+      csv_file = pathlib.Path(f"test.{index}.csv")
+      with csv_file.open("w", newline="", encoding="utf-8") as f:
+        csv.writer(f, delimiter=delimiter).writerows(content)
+      csv_files.append(csv_file)
+    return helper.merge_csv(
+        csv_files,
+        delimiter=delimiter,
+        headers=headers,
+        row_header_len=row_header_len)
+
+  def test_merge_single(self):
+    data = [
+        ["Metric", "Run1"],
+        ["Total", "200"],
+    ]
+    for delimiter in ["\t", ","]:
+      merged = self.merge(data, delimiter=delimiter)
+      self.assertListEqual(merged, data)
+
+  def test_merge_single_padding(self):
+    data = [
+        ["Metric", "Run1", "Run2"],
+        ["marker"],
+        ["Total", "200", "300"],
+    ]
+    merged = self.merge(data, headers=None)
+    self.assertListEqual(merged, [
+        ["Metric", "Run1", "Run2"],
+        ["marker", None, None],
+        ["Total", "200", "300"],
+    ])
+
+  def test_merge_single_file_header(self):
+    data = [
+        ["Total", "200"],
+    ]
+    for delimiter in ["\t", ","]:
+      merged = self.merge(data, delimiter=delimiter, headers=["custom"])
+      self.assertListEqual(merged, [
+          [None, "custom"],
+          ["Total", "200"],
+      ])
+
+  def test_merge_two_padding(self):
+    data_1 = [
+        ["marker"],
+        ["Total", "101", "102"],
+    ]
+    data_2 = [
+        ["marker"],
+        ["Total", "201"],
+    ]
+    merged = self.merge(data_1, data_2, headers=["col_1", "col_2"])
+    self.assertListEqual(merged, [
+        [None, "col_1", None, "col_2"],
+        ["marker", None, None, None],
+        ["Total", "101", "102", "201"],
+    ])
+
+  def test_merge_two_long_row_header(self):
+    data_1 = [
+        ["full-marker", "marker"],
+        ["Full/Total", "Total", "101", "102"],
+    ]
+    data_2 = [
+        ["full-marker", "marker"],
+        ["Full/Total", "Total", "201"],
+    ]
+    merged = self.merge(
+        data_1, data_2, headers=["col_1", "col_2"], row_header_len=2)
+    self.assertListEqual(merged, [
+        [None, None, "col_1", None, "col_2"],
+        ["full-marker", "marker", None, None, None],
+        ["Full/Total", "Total", "101", "102", "201"],
+    ])
+
+  def test_merge_two_disjoint_consecutive(self):
+    data_1 = [
+        ["marker"],
+        ["A", "101", "102"],
+        ["B", "101", "102"],
+    ]
+    data_2 = [
+        ["marker"],
+        ["C", "201"],
+        ["D", "201"],
+    ]
+    merged = self.merge(data_1, data_2)
+    self.assertListEqual(merged, [
+        ["marker", None, None, None],
+        ["A", "101", "102", None],
+        ["B", "101", "102", None],
+        ["C", None, None, "201"],
+        ["D", None, None, "201"],
+    ])
+
+  def test_merge_two_disjoint_interleaved(self):
+    data_1 = [
+        ["marker"],
+        ["B", "101", "102"],
+        ["C", "201"],
+    ]
+    data_2 = [
+        ["marker"],
+        ["A", "101", "102"],
+        ["D", "201"],
+    ]
+    merged = self.merge(data_1, data_2)
+    self.assertListEqual(merged, [
+        ["marker", None, None, None, None],
+        ["A", None, None, "101", "102"],
+        ["B", "101", "102", None, None],
+        ["C", "201", None, None, None],
+        ["D", None, None, "201", None],
+    ])
+
+  def test_merge_two_missing(self):
+    data_1 = [
+        ["marker"],
+        ["Total-A0"],
+        ["Total-A1", "101"],
+        ["Total-A2", "111", "112"],
+        ["Total-A3", "301", "302"],
+        ["Total-B", "01"],
+        ["Total-X", "201", "202"],
+    ]
+    data_2 = [
+        ["marker"],
+        ["Total-B", "02"],
+        ["Total-C1", "401", "402"],
+        ["Total-C2", "501"],
+        ["Total-C3", "601", "602"],
+        ["Total-C4", "701"],
+        ["Total-X", "203"],
+    ]
+    merged = self.merge(data_1, data_2, headers=["col_1", "col_2"])
+    self.assertListEqual(merged, [
+        [None, "col_1", None, "col_2", None],
+        ["marker", None, None, None, None],
+        ["Total-A0", None, None, None, None],
+        ["Total-A1", "101", None, None, None],
+        ["Total-A2", "111", "112", None, None],
+        ["Total-A3", "301", "302", None, None],
+        ["Total-B", "01", None, "02", None],
+        ["Total-C1", None, None, "401", "402"],
+        ["Total-C2", None, None, "501", None],
+        ["Total-C3", None, None, "601", "602"],
+        ["Total-C4", None, None, "701", None],
+        ["Total-X", "201", "202", "203", None],
+    ])
+
+  def test_merge_two_duplicate(self):
+    data_1 = [
+        ["A", "101"],
+        ["A", "201"],
+    ]
+    data_2 = [
+        ["A", "301"],
+        ["A", "401"],
+    ]
+    merged = self.merge(data_1, data_2)
+    self.assertListEqual(merged, [
+        ["A", "101", "301"],
+        ["A", "201", "401"],
+    ])
+
+  def test_merge_two_partial_duplicate(self):
+    data_1 = [
+        ["marker"],
+        ["A", "101"],
+        ["A", "201"],
+        ["B", "B01"],
+    ]
+    data_2 = [
+        ["marker"],
+        ["A", "301"],
+        ["A", "401"],
+        ["C", "C01"],
+    ]
+    merged = self.merge(data_1, data_2)
+    self.assertListEqual(merged, [
+        ["marker", None, None],
+        ["A", "101", "301"],
+        ["A", "201", "401"],
+        ["B", "B01", None],
+        ["C", None, "C01"],
+    ])
+
+
+class TestFlatten(unittest.TestCase):
+
+  def flatten(self, *data, key_fn=None, sort: bool = True):
+    return helper.Flatten(*data, key_fn=key_fn, sort=sort).data
+
+  def test_single(self):
+    data = {
+        "a": 1,
+        "b": 2,
+    }
+    flattened = self.flatten(data)
+    self.assertDictEqual(flattened, data)
+
+  def test_single_sort(self):
+    data = {
+        "b": 2,
+        "a": 1,
+    }
+    flattened_keys = tuple(self.flatten(data, sort=True).keys())
+    self.assertTupleEqual(flattened_keys, ("a", "b"))
+    flattened_keys = tuple(self.flatten(data, sort=False).keys())
+    self.assertTupleEqual(flattened_keys, ("b", "a"))
+
+  def test_single_nested(self):
+    data = {
+        "a": 1,
+        "b": {
+            "a": 2,
+            "b": 3
+        },
+    }
+    flattened = self.flatten(data)
+    self.assertDictEqual(flattened, {"a": 1, "b/a": 2, "b/b": 3})
+
+  def test_single_key_fn(self):
+    data = {
+        "a": 1,
+        "b": 2,
+    }
+    flattened = self.flatten(data, key_fn=lambda path: "prefix_" + path[0])
+    self.assertDictEqual(flattened, {
+        "prefix_a": 1,
+        "prefix_b": 2,
+    })
+
+  def test_single_key_fn_filtering(self):
+    data = {
+        "a": 1,
+        "b": 2,
+    }
+    flattened = self.flatten(
+        data,
+        key_fn=lambda path: None if path[0] == "a" else "prefix_" + path[0])
+    self.assertDictEqual(flattened, {
+        "prefix_b": 2,
+    })
+
+  def test_single_nested_key_fn(self):
+    data = {
+        "a": 1,
+        "b": {
+            "a": 2,
+            "b": 3
+        },
+    }
+    with self.assertRaises(ValueError):
+      # Fail on duplicate entries
+      self.flatten(data, key_fn=lambda path: "prefix_" + path[0])
+
+    flattened = self.flatten(
+        data, key_fn=lambda path: "prefix_" + "/".join(path))
+    self.assertDictEqual(flattened, {
+        "prefix_a": 1,
+        "prefix_b/a": 2,
+        "prefix_b/b": 3,
+    })
+
+  def test_single_nested_key_fn_filtering(self):
+    data = {
+        "a": 1,
+        "b": {
+            "a": 2,
+            "b": 3
+        },
+    }
+    flattened = self.flatten(
+        data,
+        key_fn=lambda path: None
+        if path[-1] == "a" else "prefix_" + "/".join(path))
+    self.assertDictEqual(flattened, {
+        "prefix_b/b": 3,
+    })
+
+  def test_multiple_flat(self):
+    data_1 = {
+        "a": 1,
+        "b": 2,
+    }
+    with self.assertRaises(ValueError):
+      # duplicate entries
+      self.flatten(data_1, data_1)
+    data_2 = {
+        "c": 3,
+        "d": 4,
+    }
+    flattened = self.flatten(data_1, data_2)
+    self.assertDictEqual(flattened, {
+        "a": 1,
+        "b": 2,
+        "c": 3,
+        "d": 4,
+    })
+
+  def test_null(self):
+    data = {
+        "a": 1,
+        "b": None,
+    }
+    flattened = self.flatten(data)
+    self.assertDictEqual(flattened, {
+        "a": 1,
+    })
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_js.py b/tests/crossbench/probes/test_js.py
new file mode 100644
index 0000000..dc16400
--- /dev/null
+++ b/tests/crossbench/probes/test_js.py
@@ -0,0 +1,85 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from crossbench.benchmarks.loading.page.live import LivePage
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.probes.js import JSProbe
+from tests import test_helper
+from tests.crossbench.probes.helper import GenericProbeTestCase
+
+
+class TestJSProbe(GenericProbeTestCase):
+
+  def test_parse_example_config(self):
+    config_file = test_helper.config_dir() / "doc/probe/js.config.hjson"
+    self.fs.add_real_file(config_file)
+    self.assertTrue(config_file.is_file())
+    probes = ProbeListConfig.parse_path(config_file).probes
+    self.assertEqual(len(probes), 1)
+    probe = probes[0]
+    self.assertIsInstance(probe, JSProbe)
+    isinstance(probe, JSProbe)
+    self.assertTrue(probe.metric_js)
+
+  def test_parse_config(self):
+    config = {
+        "setup": "globalThis.metrics = {};",
+        "js": "return globalThis.metrics;",
+    }
+    probe = JSProbe.config_parser().parse(config)
+    self.assertIsInstance(probe, JSProbe)
+    self.assertEqual(probe.setup_js, "globalThis.metrics = {};")
+    self.assertEqual(probe.metric_js, "return globalThis.metrics;")
+
+
+  def test_simple_loading_case(self):
+    config = {
+        "setup": "globalThis.metrics = {};",
+        "js": "return globalThis.metrics;",
+    }
+    probe = JSProbe.config_parser().parse(config)
+    stories = [
+        LivePage("google", "https://google.com"),
+        LivePage("amazon", "https://amazon.com")
+    ]
+    repetitions = 2
+    runner = self.create_runner(
+        stories,
+        js_side_effects=[
+            # setup:
+            None,
+            # js:
+            {
+                "metric1": 1.1,
+                "metric2": 2.2
+            }
+        ],
+        repetitions=repetitions,
+        separate=True,
+        throw=True)
+    runner.attach_probe(probe)
+    runner.run()
+    self.assertTrue(runner.is_success)
+    js_result_files = list(runner.out_dir.glob(f"**/{probe.name}.json"))
+    # One file per story repetition
+    result_count = len(self.browsers) * len(stories) * repetitions
+    # One merged result per story
+    result_count += len(self.browsers) * len(stories)
+    # One merged results per browser
+    result_count += len(self.browsers)
+    # One top-level
+    result_count += 1
+    self.assertEqual(len(js_result_files), result_count)
+
+    (story_data, repetitions_data, stories_data,
+     browsers_data) = self.get_non_empty_json_results(runner, probe)
+    self.assertIsInstance(story_data, dict)
+    self.assertIsInstance(repetitions_data, dict)
+    self.assertIsInstance(stories_data, dict)
+    self.assertIsInstance(browsers_data, dict)
+    # TODO: check probe result contents
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_metric.py b/tests/crossbench/probes/test_metric.py
new file mode 100644
index 0000000..d30e7d1
--- /dev/null
+++ b/tests/crossbench/probes/test_metric.py
@@ -0,0 +1,287 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import json
+import pathlib
+import unittest
+
+from crossbench.probes.metric import CSVFormatter, Metric, MetricsMerger
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class FormatMetricTestCase(unittest.TestCase):
+
+  def test_no_stdev(self):
+    self.assertEqual(Metric.format(100), "100")
+    self.assertEqual(Metric.format(0), "0")
+    self.assertEqual(Metric.format(1.5), "1.5")
+    self.assertEqual(Metric.format(100, 0), "100")
+    self.assertEqual(Metric.format(0, 0), "0")
+    self.assertEqual(Metric.format(1.5, 0), "1.5")
+
+  def test_stdev(self):
+    self.assertEqual(Metric.format(100, 10), "100  10%")
+    self.assertEqual(Metric.format(100, 1), "100.0  1.0%")
+    self.assertEqual(Metric.format(100, 1.5), "100.0  1.5%")
+    self.assertEqual(Metric.format(100, 0.1), "100.00  0.10%")
+    self.assertEqual(Metric.format(100, 0.12), "100.00  0.12%")
+    self.assertEqual(Metric.format(100, 0.125), "100.00  0.12%")
+
+  def test_round_stdev(self):
+    value = 100.123456789
+    percent = value / 100
+    self.assertEqual(Metric.format(value, percent * 10.1234), "100  10%")
+    self.assertEqual(Metric.format(value, percent * 1.2345), "100.1  1.2%")
+    self.assertEqual(Metric.format(value, percent * 0.12345), "100.12  0.12%")
+    self.assertEqual(
+        Metric.format(value, percent * 0.012345), "100.123  0.012%")
+    self.assertEqual(
+        Metric.format(value, percent * 0.0012345), "100.1235  0.0012%")
+    self.assertEqual(
+        Metric.format(value, percent * 0.00012345), "100.12346  0.00012%")
+
+
+class MetricTestCase(unittest.TestCase):
+
+  def test_empty(self):
+    values = Metric()
+    self.assertTrue(values.is_numeric)
+    self.assertEqual(len(values), 0)
+
+  def test_is_numeric(self):
+    values = Metric([1, 2, 3, 4])
+    self.assertTrue(values.is_numeric)
+    values.append(5)
+    self.assertTrue(values.is_numeric)
+    values.append("6")
+    self.assertFalse(values.is_numeric)
+
+    values = Metric([1, 2, 3, "4"])
+    self.assertFalse(values.is_numeric)
+
+  def test_to_json_empty(self):
+    json_data = Metric().to_json()
+    self.assertDictEqual(json_data, {"values": []})
+
+  def test_to_json_any(self):
+    json_data = Metric(["a", "b", "c"]).to_json()
+    self.assertDictEqual(json_data, {"values": ["a", "b", "c"]})
+
+  def test_to_json_repeated(self):
+    json_data = Metric(["a", "a", "a"]).to_json()
+    self.assertEqual(json_data, "a")
+
+  def test_to_json_numeric_repeated(self):
+    json_data = Metric([1, 1, 1]).to_json()
+    self.assertListEqual(json_data["values"], [1, 1, 1])
+    self.assertEqual(json_data["min"], 1)
+    self.assertEqual(json_data["max"], 1)
+    self.assertEqual(json_data["geomean"], 1)
+    self.assertEqual(json_data["average"], 1)
+    self.assertEqual(json_data["stddevPercent"], 0)
+
+  def test_to_json_numeric_average_0(self):
+    json_data = Metric([-1, 0, 1]).to_json()
+    self.assertListEqual(json_data["values"], [-1, 0, 1])
+    self.assertEqual(json_data["min"], -1)
+    self.assertEqual(json_data["max"], 1)
+    self.assertEqual(json_data["geomean"], 0)
+    self.assertEqual(json_data["average"], 0)
+    self.assertEqual(json_data["stddevPercent"], 0)
+
+
+class MetricsMergerTestCase(CrossbenchFakeFsTestCase):
+
+  def test_empty(self):
+    merger = MetricsMerger()
+    self.assertDictEqual(merger.to_json(), {})
+    self.assertListEqual(CSVFormatter(merger).table, [])
+
+  def test_add_flat(self):
+    input_data = {"a": 1, "b": 2}
+    merger = MetricsMerger()
+    merger.add(input_data)
+    data = merger.data
+    self.assertEqual(len(data), 2)
+    self.assertIsInstance(data["a"], Metric)
+    self.assertIsInstance(data["b"], Metric)
+    self.assertListEqual(data["a"].values, [1])
+    self.assertListEqual(data["b"].values, [2])
+
+    merger.add(input_data)
+    data = merger.data
+    self.assertEqual(len(data), 2)
+    self.assertListEqual(data["a"].values, [1, 1])
+    self.assertListEqual(data["b"].values, [2, 2])
+
+  def test_add_hierarchical(self):
+    input_data = {
+        "a": {
+            "a": {
+                "a": 1,
+                "b": 2
+            }
+        },
+        "b": 2,
+    }
+    merger = MetricsMerger()
+    merger.add(input_data)
+    data = merger.data
+    self.assertListEqual(list(data.keys()), ["a/a/a", "a/a/b", "b"])
+    self.assertIsInstance(data["a/a/a"], Metric)
+    self.assertIsInstance(data["a/a/b"], Metric)
+    self.assertIsInstance(data["b"], Metric)
+
+  def test_repeated_numeric(self):
+    merger = MetricsMerger()
+    input_data = {
+        "a": {
+            "aa": 1,
+            "ab": 2
+        },
+        "b": 3,
+        "c": {
+            "cc": {
+                "ccc": 4
+            }
+        },
+    }
+    merger.add(input_data)
+    merger.add(input_data)
+    data = merger.data
+    self.assertEqual(len(data), 4)
+    self.assertListEqual(data["a/aa"].values, [1, 1])
+    self.assertListEqual(data["a/ab"].values, [2, 2])
+    self.assertListEqual(data["b"].values, [3, 3])
+    self.assertListEqual(data["c/cc/ccc"].values, [4, 4])
+
+  BASIC_NESTED_DATA = {
+      "a": {
+          "a": {
+              "a": 1,
+              "b": 2
+          }
+      },
+      "b": 3,
+  }
+
+  def test_custom_key_fn(self):
+
+    def under_join(segments):
+      return "_".join(segments)
+
+    merger = MetricsMerger(key_fn=under_join)
+    merger.add(self.BASIC_NESTED_DATA)
+    data = merger.data
+    self.assertListEqual(list(data.keys()), ["a_a_a", "a_a_b", "b"])
+
+  def test_merge_serialized_same(self):
+    merger = MetricsMerger()
+    merger.add(self.BASIC_NESTED_DATA)
+    self.assertListEqual(list(merger.data.keys()), ["a/a/a", "a/a/b", "b"])
+    path_a = pathlib.Path("merged_a.json")
+    path_b = pathlib.Path("merged_b.json")
+    with path_a.open("w", encoding="utf-8") as f:
+      json.dump(merger.to_json(), f)
+    with path_b.open("w", encoding="utf-8") as f:
+      json.dump(merger.to_json(), f)
+
+    merger = MetricsMerger.merge_json_list([path_a, path_b],
+                                           merge_duplicate_paths=True)
+    data = merger.data
+    self.assertListEqual(list(data.keys()), ["a/a/a", "a/a/b", "b"])
+    self.assertListEqual(data["a/a/a"].values, [1, 1])
+    self.assertListEqual(data["a/a/b"].values, [2, 2])
+    self.assertListEqual(data["b"].values, [3, 3])
+
+    # All duplicate entries are ignored
+    merger = MetricsMerger.merge_json_list([path_a, path_b],
+                                           merge_duplicate_paths=False)
+    self.assertListEqual(list(merger.data.keys()), [])
+
+  def test_merge_serialized_different_data(self):
+    merger_a = MetricsMerger({"a": {"a": 1}})
+    merger_b = MetricsMerger({"a": {"b": 2}})
+    path_a = pathlib.Path("merged_a.json")
+    path_b = pathlib.Path("merged_b.json")
+    with path_a.open("w", encoding="utf-8") as f:
+      json.dump(merger_a.to_json(), f)
+    with path_b.open("w", encoding="utf-8") as f:
+      json.dump(merger_b.to_json(), f)
+
+    merger = MetricsMerger.merge_json_list([path_a, path_b],
+                                           merge_duplicate_paths=True)
+    data = merger.data
+    self.assertListEqual(list(data.keys()), ["a/a", "a/b"])
+    self.assertListEqual(data["a/a"].values, [1])
+    self.assertListEqual(data["a/b"].values, [2])
+
+    merger = MetricsMerger.merge_json_list([path_a, path_b],
+                                           merge_duplicate_paths=False)
+    data = merger.data
+    self.assertListEqual(list(data.keys()), ["a/a", "a/b"])
+
+  def test_to_csv_no_path(self) -> None:
+    merger = MetricsMerger()
+    merger.add(self.BASIC_NESTED_DATA)
+    csv = CSVFormatter(
+        merger, lambda metric: metric.geomean, include_parts=False).table
+    self.assertListEqual(csv, [
+        ("a/a/a", 1.0),
+        ("a/a/b", 2.0),
+        ("b", 3.0),
+    ])
+
+  def test_to_csv_path(self) -> None:
+    merger = MetricsMerger()
+    merger.add(self.BASIC_NESTED_DATA)
+    csv = CSVFormatter(
+        merger, lambda metric: metric.geomean, include_parts=True).table
+    self.assertListEqual(csv, [
+        ("a/a/a", "a", "a", "a", 1.0),
+        ("a/a/b", "a", "a", "b", 2.0),
+        ("b", "b", "", "", 3.0),
+    ])
+
+  def test_to_csv_header(self) -> None:
+    merger = MetricsMerger()
+    merger.add({"a/b/c": 1, "d": 2})
+    headers = [
+        ("a", "custom", "header", "line"),
+        (1, 2, 3, 4, 5),
+    ]
+    csv = CSVFormatter(
+        merger,
+        lambda metric: metric.geomean,
+        headers=headers,
+        include_parts=True).table
+    self.assertListEqual(csv, [
+        ("a", "", "", "", "custom", "header", "line"),
+        (1, "", "", "", 2, 3, 4, 5),
+        ("a/b/c", "a", "b", "c", 1.0),
+        ("d", "d", "", "", 2.0),
+    ])
+
+
+class CSVFormatterTestCase(unittest.TestCase):
+
+  def test_format(self):
+    metrics = MetricsMerger({
+        "Total/average": 10,
+        "Total/score": 20,
+        "cdjs/average": 30,
+        "cdjs/score": 40,
+    })
+    table = CSVFormatter(metrics, lambda metric: metric.geomean).table
+    self.assertSequenceEqual(table, [
+        ("Total/average", "Total", "average", 10.0),
+        ("Total/score", "Total", "score", 20.0),
+        ("cdjs/average", "cdjs", "average", 30.0),
+        ("cdjs/score", "cdjs", "score", 40.0),
+    ])
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_perfetto.py b/tests/crossbench/probes/test_perfetto.py
new file mode 100644
index 0000000..5284bf2
--- /dev/null
+++ b/tests/crossbench/probes/test_perfetto.py
@@ -0,0 +1,35 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import unittest
+
+import crossbench.path as pth
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.probes.all import PerfettoProbe
+from tests import test_helper
+
+
+class PerfettoProbeTestCase(unittest.TestCase):
+
+  def test_missing_config(self):
+    with self.assertRaises(ValueError) as cm:
+      PerfettoProbe.from_config({})
+    self.assertIn("config", str(cm.exception))
+
+  def test_parse_config(self):
+    probe: PerfettoProbe = PerfettoProbe.from_config({"textproto": "TEXTPROTO"})
+    self.assertEqual("TEXTPROTO", probe.textproto)
+    self.assertEqual(pth.AnyPath("perfetto"), probe.perfetto_bin)
+
+  def test_parse_example_config(self):
+    config_file = test_helper.config_dir() / "doc/probe/perfetto.config.hjson"
+    self.assertTrue(config_file.is_file())
+    probes = ProbeListConfig.parse_path(config_file).probes
+    self.assertEqual(len(probes), 1)
+    probe = probes[0]
+    self.assertIsInstance(probe, PerfettoProbe)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_probe.py b/tests/crossbench/probes/test_probe.py
new file mode 100644
index 0000000..489ff1a
--- /dev/null
+++ b/tests/crossbench/probes/test_probe.py
@@ -0,0 +1,171 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import inspect
+
+import crossbench.path as pth
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.probes.all import GENERAL_PURPOSE_PROBES, INTERNAL_PROBES
+from crossbench.probes.debugger import DebuggerProbe
+from crossbench.probes.frequency import FrequencyProbe
+from crossbench.probes.dtrace import DTraceProbe
+from crossbench.probes.dump_html import DumpHtmlProbe
+from crossbench.probes.perfetto.perfetto import PerfettoProbe
+from crossbench.probes.perfetto.tracing import TracingProbe
+from crossbench.probes.performance_entries import PerformanceEntriesProbe
+from crossbench.probes.polling import ShellPollingProbe
+from crossbench.probes.power_sampler import PowerSamplerProbe
+from crossbench.probes.powermetrics import PowerMetricsProbe
+from crossbench.probes.probe import Probe
+from crossbench.probes.profiling.browser_profiling import BrowserProfilingProbe
+from crossbench.probes.profiling.system_profiling import ProfilingProbe
+from crossbench.probes.screenshot import ScreenshotProbe
+from crossbench.probes.system_stats import SystemStatsProbe
+from crossbench.probes.v8.builtins_pgo import V8BuiltinsPGOProbe
+from crossbench.probes.v8.log import V8LogProbe
+from crossbench.probes.v8.rcs import V8RCSProbe
+from crossbench.probes.v8.turbolizer import V8TurbolizerProbe
+from crossbench.probes.video import VideoProbe
+from crossbench.probes.web_page_replay.recorder import WebPageReplayProbe
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class ProbeListConfigTestCase(CrossbenchFakeFsTestCase):
+
+  def test_invalid_empty(self):
+    with self.assertRaises(ValueError) as cm:
+      ProbeListConfig.parse({"probes": ""})
+    self.assertIn("str", str(cm.exception).lower())
+    with self.assertRaises(ValueError) as cm:
+      ProbeListConfig.parse({"browsers": {}})
+    self.assertIn("probes", str(cm.exception).lower())
+
+  def test_empty(self):
+    probe_list = ProbeListConfig.parse({"probes": []})
+    self.assertEqual(probe_list.probes, [])
+    probe_list = ProbeListConfig.parse({"probes": {}})
+    self.assertEqual(probe_list.probes, [])
+
+
+class ProbeTestCase(CrossbenchFakeFsTestCase):
+
+  def probe_instances(self):
+    yield from self.internal_probe_instances()
+    yield from self.general_purpose_probe_instances()
+
+  def internal_probe_instances(self):
+    for probe_cls in self.internal_probe_classes():
+      with self.subTest(probe_cls=probe_cls):
+        try:
+          yield probe_cls()
+        except GeneratorExit:
+          break
+
+  def general_purpose_probe_instances(self):
+    yield BrowserProfilingProbe()
+    yield DTraceProbe(pth.LocalPath("script.dtrace"))
+    yield DebuggerProbe(pth.LocalPath("debugger.bin"))
+    yield DumpHtmlProbe()
+    yield FrequencyProbe.from_config({})
+    yield PerfettoProbe("textproto", pth.LocalPath("perfetto.bin"))
+    yield PerformanceEntriesProbe()
+    yield PowerMetricsProbe()
+    yield PowerSamplerProbe()
+    yield ProfilingProbe()
+    yield ScreenshotProbe()
+    yield ShellPollingProbe(cmd=["ls"])
+    yield SystemStatsProbe()
+    yield TracingProbe()
+    yield V8BuiltinsPGOProbe()
+    yield V8LogProbe()
+    yield V8RCSProbe()
+    yield V8TurbolizerProbe()
+    yield VideoProbe()
+    yield WebPageReplayProbe(wpr_go_bin=self.create_file("wpr.go"))
+
+  def probe_classes(self):
+    yield from self.internal_probe_classes()
+    yield from self.general_purpose_probe_classes()
+
+  def all_probe_subclasses(self, probe_cls=Probe):
+    for probe_sub_cls in probe_cls.__subclasses__():
+      if "Mock" in str(probe_sub_cls):
+        continue
+      if not inspect.isabstract(probe_sub_cls):
+        yield probe_sub_cls
+      yield from self.all_probe_subclasses(probe_sub_cls)
+
+  def internal_probe_classes(self):
+    for probe_cls in INTERNAL_PROBES:
+      with self.subTest(probe_cls=probe_cls):
+        try:
+          yield probe_cls
+        except GeneratorExit:
+          break
+
+  def general_purpose_probe_classes(self):
+    for probe_cls in GENERAL_PURPOSE_PROBES:
+      with self.subTest(probe_cls=probe_cls):
+        try:
+          yield probe_cls
+        except GeneratorExit:
+          break
+
+  def test_properties(self):
+    for probe_cls in self.internal_probe_classes():
+      self.assertFalse(probe_cls.IS_GENERAL_PURPOSE)
+    for probe_cls in self.general_purpose_probe_classes():
+      self.assertTrue(probe_cls.IS_GENERAL_PURPOSE)
+    for probe_cls in self.probe_classes():
+      self.assertTrue(probe_cls.NAME)
+
+  def test_default_lists(self):
+    count = 0
+    for probe_cls in self.all_probe_subclasses():
+      count += 1
+      if probe_cls.IS_GENERAL_PURPOSE:
+        self.assertIn(probe_cls, GENERAL_PURPOSE_PROBES)
+    self.assertGreater(count,
+                       len(GENERAL_PURPOSE_PROBES) + len(INTERNAL_PROBES))
+
+  def test_help(self):
+    for probe_cls in self.probe_classes():
+      help_text = probe_cls.help_text()
+      self.assertTrue(help)
+      summary = probe_cls.summary_text()
+      self.assertTrue(summary)
+      self.assertIn(summary, help_text)
+
+  def test_config_parser(self):
+    for probe_cls in self.probe_classes():
+      config_parser = probe_cls.config_parser()
+      self.assertEqual(config_parser.probe_cls, probe_cls)
+
+  def test_basic_probe_instances(self):
+    keys = set()
+    names = set()
+    for probe_instance in self.probe_instances():
+      _ = hash(probe_instance)
+      key = probe_instance.key
+      self.assertIsInstance(key, tuple)
+      self.assertNotIn(key, keys)
+      keys.add(key)
+      self.assertTrue(probe_instance.name)
+      self.assertNotIn(probe_instance.name, names)
+      names.add(probe_instance.name)
+
+  def test_is_internal(self):
+    for probe_instance in self.internal_probe_instances():
+      self.assertTrue(probe_instance.is_internal)
+    for probe_instance in self.general_purpose_probe_instances():
+      self.assertFalse(probe_instance.is_internal)
+
+  def test_is_attached(self):
+    for probe_instance in self.general_purpose_probe_instances():
+      self.assertFalse(probe_instance.is_attached)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_probe_results.py b/tests/crossbench/probes/test_probe_results.py
new file mode 100644
index 0000000..3f18b9a
--- /dev/null
+++ b/tests/crossbench/probes/test_probe_results.py
@@ -0,0 +1,413 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import pathlib
+
+from crossbench.probes.probe import Probe
+from crossbench.probes.results import (BrowserProbeResult,
+                                       DuplicateProbeResult, EmptyProbeResult,
+                                       LocalProbeResult, ProbeResultDict)
+from crossbench.runner.run import Run
+from tests import test_helper
+from tests.crossbench.base import (BaseCrossbenchTestCase,
+                                   CrossbenchFakeFsTestCase)
+
+
+class ProbeResultTestCase(CrossbenchFakeFsTestCase):
+
+  def test_is_empty(self):
+    empty = EmptyProbeResult()
+    self.assertTrue(empty.is_empty)
+    self.assertFalse(empty)
+    combined = empty.merge(EmptyProbeResult())
+    self.assertTrue(combined.is_empty)
+    url = LocalProbeResult(url=("http://test.com",))
+    self.assertFalse(url.is_empty)
+    self.assertTrue(url)
+    combined = empty.merge(url)
+    self.assertFalse(combined.is_empty)
+    self.assertTrue(combined)
+
+  def test_equal_empty(self):
+    empty = EmptyProbeResult()
+    self.assertEqual(empty, empty)
+    self.assertEqual(EmptyProbeResult(), EmptyProbeResult())
+    local_empty = LocalProbeResult()
+    self.assertEqual(local_empty, EmptyProbeResult())
+    self.assertEqual(local_empty, local_empty)
+    self.assertNotEqual(LocalProbeResult(), None)
+    self.assertNotEqual(None, LocalProbeResult())
+
+  def test_is_remote(self):
+    empty = EmptyProbeResult()
+    self.assertFalse(empty.is_remote)
+    local_empty = LocalProbeResult()
+    self.assertFalse(local_empty.is_remote)
+
+  def test_equal_single(self):
+    url = "http://test.com"
+    self.assertEqual(LocalProbeResult(url=(url,)), LocalProbeResult(url=(url,)))
+    url_b = "http://foo.test.com"
+    self.assertNotEqual(
+        LocalProbeResult(url=(url,)), LocalProbeResult(url=(url_b,)))
+
+
+  def test_invalid_files(self):
+    with self.assertRaises(ValueError):
+      LocalProbeResult(file=[pathlib.Path("foo.json")])
+    with self.assertRaises(ValueError):
+      LocalProbeResult(file=[pathlib.Path("foo.csv")])
+    with self.assertRaises(ValueError):
+      LocalProbeResult(json=[pathlib.Path("foo.csv")])
+    with self.assertRaises(ValueError):
+      LocalProbeResult(csv=[pathlib.Path("foo.json")])
+
+  def test_inexistent_files(self):
+    with self.assertRaises(ValueError):
+      LocalProbeResult(file=[pathlib.Path("not_there.txt")])
+    with self.assertRaises(ValueError):
+      LocalProbeResult(csv=[pathlib.Path("not_there.csv")])
+    with self.assertRaises(ValueError):
+      LocalProbeResult(json=[pathlib.Path("not_there.json")])
+
+  def test_result_url(self):
+    url = "http://foo.bar.com"
+    with self.assertRaises(DuplicateProbeResult):
+      _ = LocalProbeResult(url=[url, url])
+    result = LocalProbeResult(url=[url])
+    self.assertFalse(result.is_empty)
+    self.assertEqual(result.url, url)
+    self.assertListEqual(result.url_list, [url])
+    self.assertListEqual(list(result.all_files()), [])
+    failed = None
+    with self.assertRaises(ValueError):
+      failed = result.file
+    with self.assertRaises(ValueError):
+      failed = result.json
+    with self.assertRaises(ValueError):
+      failed = result.csv
+    self.assertIsNone(failed)
+    json_data = result.to_json()
+    self.assertDictEqual(json_data, {"url": (url,)})
+
+  def test_result_any_file(self):
+    path = self.create_file("result.txt")
+    with self.assertRaises(DuplicateProbeResult):
+      _ = LocalProbeResult(file=[path, path])
+    result = LocalProbeResult(file=[path])
+    self.assertFalse(result.is_empty)
+    self.assertNotEqual(
+        result, LocalProbeResult(file=[
+            self.create_file("result2.txt"),
+        ]))
+    self.assertEqual(result.file, path)
+    self.assertListEqual(result.file_list, [path])
+    self.assertListEqual(list(result.all_files()), [path])
+    failed = None
+    with self.assertRaises(ValueError):
+      failed = result.url
+    with self.assertRaises(ValueError):
+      failed = result.json
+    with self.assertRaises(ValueError):
+      failed = result.csv
+    self.assertIsNone(failed)
+
+  def test_result_csv(self):
+    path = self.create_file("result.csv")
+    with self.assertRaises(DuplicateProbeResult):
+      _ = LocalProbeResult(csv=[path, path])
+    result = LocalProbeResult(csv=[path])
+    self.assertFalse(result.is_empty)
+    self.assertNotEqual(
+        result, LocalProbeResult(csv=[
+            self.create_file("result2.csv"),
+        ]))
+    self.assertEqual(result.csv, path)
+    self.assertEqual(result.get("csv"), path)
+    self.assertListEqual(result.csv_list, [path])
+    self.assertListEqual(result.get_all("csv"), [path])
+    self.assertListEqual(list(result.all_files()), [path])
+    self.assertEqual(result.file, path)
+    failed = None
+    with self.assertRaises(ValueError):
+      failed = result.url
+    with self.assertRaises(ValueError):
+      failed = result.json
+    self.assertIsNone(failed)
+
+  def test_result_json(self):
+    path = self.create_file("result.json")
+    with self.assertRaises(DuplicateProbeResult):
+      _ = LocalProbeResult(json=[path, path])
+    with self.assertRaises(DuplicateProbeResult):
+      _ = LocalProbeResult(file=[path, path])
+    result = LocalProbeResult(json=[path])
+    self.assertFalse(result.is_empty)
+    self.assertNotEqual(
+        result, LocalProbeResult(json=[
+            self.create_file("result2.json"),
+        ]))
+    self.assertEqual(result.json, path)
+    self.assertEqual(result.get("json"), path)
+    self.assertListEqual(result.json_list, [path])
+    self.assertListEqual(result.get_all("json"), [path])
+    self.assertListEqual(list(result.all_files()), [path])
+    self.assertEqual(result.file, path)
+    failed = None
+    with self.assertRaises(ValueError):
+      failed = result.url
+    with self.assertRaises(ValueError):
+      failed = result.csv
+    self.assertIsNone(failed)
+
+  def test_multiple_urls(self):
+    url1 = "http://one.com"
+    url2 = "http://two.com"
+    result = LocalProbeResult(url=(url1, url2))
+    self.assertFalse(result.is_empty)
+    self.assertFalse(result.has_files)
+    with self.assertRaises(ValueError):
+      _ = result.file
+    with self.assertRaises(ValueError):
+      _ = result.url
+    self.assertSequenceEqual(result.url_list, (url1, url2))
+
+  def test_multiple_files(self):
+    json1 = self.create_file("result_1.json")
+    json2 = self.create_file("result_2.json")
+    zip1 = self.create_file("result.zip")
+    result = LocalProbeResult(file=(json1, json2, zip1))
+    self.assertFalse(result.is_empty)
+    self.assertTrue(result.has_files)
+    with self.assertRaises(ValueError):
+      _ = result.file
+    with self.assertRaises(ValueError):
+      _ = result.json
+    self.assertSequenceEqual(result.file_list, (json1, json2, zip1))
+    self.assertSequenceEqual(result.json_list, (json1, json2))
+    self.assertSequenceEqual(result.get_all("json"), (json1, json2))
+    self.assertEqual(result.get("zip"), zip1)
+    self.assertEqual(result.get_all("zip"), [zip1])
+    with self.assertRaises(ValueError):
+      _ = result.get("other")
+
+  def test_merge(self):
+    file = self.create_file("result.custom")
+    json = self.create_file("result.json")
+    csv = self.create_file("result.csv")
+    url = "http://foo.bar.com"
+    trace = self.create_file("trace.pb")
+
+    result = LocalProbeResult(
+        url=(url,), file=(file,), json=(json,), csv=(csv,), trace=(trace,))
+    self.assertFalse(result.is_empty)
+    self.assertListEqual(list(result.all_files()), [file, json, csv, trace])
+    self.assertListEqual(result.url_list, [url])
+    self.assertListEqual(result.trace_list, [trace])
+
+    merged = result.merge(EmptyProbeResult())
+    self.assertFalse(merged.is_empty)
+    self.assertListEqual(list(merged.all_files()), [file, json, csv, trace])
+    self.assertListEqual(merged.url_list, [url])
+    self.assertListEqual(merged.trace_list, [trace])
+
+    file_2 = self.create_file("result.2.custom")
+    json_2 = self.create_file("result.2.json")
+    csv_2 = self.create_file("result.2.csv")
+    url_2 = "http://foo.bar.com/2"
+    trace_2 = self.create_file("trace.2.pb")
+    other = LocalProbeResult(
+        url=(url_2,),
+        file=(file_2,),
+        json=(json_2,),
+        csv=(csv_2,),
+        trace=(trace_2,))
+    merged = result.merge(other)
+    self.assertFalse(merged.is_empty)
+    self.assertListEqual(
+        list(merged.all_files()),
+        [file, file_2, json, json_2, csv, csv_2, trace, trace_2])
+    self.assertListEqual(merged.url_list, [url, url_2])
+    # result is unchanged:
+    self.assertFalse(result.is_empty)
+    self.assertListEqual(list(result.all_files()), [file, json, csv, trace])
+    self.assertListEqual(result.url_list, [url])
+    self.assertListEqual(result.trace_list, [trace])
+    # other is unchanged:
+    self.assertFalse(other.is_empty)
+    self.assertListEqual(
+        list(other.all_files()), [file_2, json_2, csv_2, trace_2])
+    self.assertListEqual(other.url_list, [url_2])
+    self.assertListEqual(other.trace_list, [trace_2])
+
+  def test_merge_duplicate_files(self):
+    path = self.create_file("result.custom")
+    result_1 = LocalProbeResult(file=(path,))
+    result_2 = LocalProbeResult(file=(path,))
+    with self.assertRaises(DuplicateProbeResult):
+      result_1.merge(result_1)
+    with self.assertRaises(DuplicateProbeResult):
+      result_1.merge(result_2)
+    with self.assertRaises(DuplicateProbeResult):
+      result_2.merge(result_1)
+
+  def test_traces_are_files(self):
+    trace = self.create_file("trace.pb")
+
+    result = LocalProbeResult(trace=(trace,))
+    self.assertFalse(result.is_empty)
+    self.assertListEqual(list(result.all_files()), [trace])
+    self.assertListEqual(list(result.trace_list), [trace])
+
+  def test_traces_can_be_duplicate(self):
+    trace = self.create_file("trace.pb")
+
+    result = LocalProbeResult(trace=(trace,), file=(trace,))
+    self.assertFalse(result.is_empty)
+    self.assertListEqual(list(result.all_files()), [trace])
+    self.assertListEqual(list(result.trace_list), [trace])
+
+
+class MockRun:
+
+  def __init__(self, browser, browser_platform):
+    self.brower = browser
+    self.browser_platform = browser_platform
+    self.is_remote = False
+
+
+class BrowserProbeResultTestCase(BaseCrossbenchTestCase):
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.run = MockRun(self.browsers[0], self.platform)
+
+  def test_empty(self):
+    result = BrowserProbeResult(self.run)
+    self.assertTrue(result.is_empty)
+    self.assertFalse(result.is_remote)
+
+  def test_remote_empty(self):
+    self.run.is_remote = True
+    result = BrowserProbeResult(self.run)
+    self.assertTrue(result.is_empty)
+    self.assertEqual(result, EmptyProbeResult())
+    self.assertEqual(result, LocalProbeResult())
+
+  def test_remote_only_urls(self):
+    self.run.is_remote = True
+    result = BrowserProbeResult(self.run, url=("http://test.com",))
+    self.assertFalse(result.is_empty)
+    self.assertNotEqual(result, EmptyProbeResult())
+    self.assertEqual(result, LocalProbeResult(url=("http://test.com",)))
+    self.assertNotEqual(result, LocalProbeResult(url=("http://test.com/bar",)))
+
+  def test_local_browser_equal_local_run(self):
+    url = "http://foo.bar.com"
+    file = self.create_file("results/file.any")
+    json = self.create_file("results/file.json")
+    csv = self.create_file("results/file.csv")
+    local = LocalProbeResult((url,), (file, json, csv))
+    browser = BrowserProbeResult(self.run, (url,), (file, json, csv))
+    self.assertEqual(local, browser)
+    local_kwargs = LocalProbeResult(
+        url=(url,), file=(file,), json=(json,), csv=(csv,))
+    browser_kwargs = BrowserProbeResult(
+        self.run, url=(url,), file=(file,), json=(json,), csv=(csv,))
+    self.assertEqual(local, browser)
+    self.assertEqual(local, browser_kwargs)
+    self.assertEqual(local_kwargs, browser)
+    self.assertEqual(local_kwargs, browser_kwargs)
+
+  def test_copy_remote_files(self):
+    # pylint: disable=attribute-defined-outside-init
+    out_dir_local = pathlib.Path("local/results")
+    out_dir_remote = pathlib.Path("remote/results")
+    out_dir_local.mkdir(parents=True)
+    out_dir_remote.mkdir(parents=True)
+    self.assertTrue(out_dir_local.is_dir())
+    self.assertTrue(out_dir_remote.is_dir())
+    remote_txt = self.create_file(
+        out_dir_remote / "result.txt", contents="a1 b2 c3")
+    remote_json = self.create_file(
+        out_dir_remote / "result.json", contents="[]")
+    self.run.is_remote = True
+    self.run.out_dir = out_dir_local
+    self.run.browser_tmp_dir = out_dir_remote
+    with self.assertRaises(DuplicateProbeResult):
+      _ = BrowserProbeResult(self.run, file=(remote_txt, remote_txt))
+    with self.assertRaises(DuplicateProbeResult):
+      _ = BrowserProbeResult(self.run, json=(remote_json, remote_json))
+    result = BrowserProbeResult(
+        self.run, file=(remote_txt,), json=(remote_json,))
+    self.assertTrue(remote_txt.is_file())
+    with self.assertRaises(ValueError):
+      _ = result.file
+    self.assertTrue(result.has_files)
+    self.assertNotEqual(remote_json, result.json)
+    self.assertTrue(result.json.is_file())
+    self.assertEqual(result.json.read_text(), "[]")
+    self.assertNotEqual(remote_txt, result.get("txt"))
+    self.assertEqual(result.get("txt").read_text(), "a1 b2 c3")
+
+
+class MockProbe(Probe):
+  """
+  Probe DOC Text
+  """
+  NAME = "mock-probe"
+
+  def get_context(self, run: Run):
+    pass
+
+
+class ProbeResultDictTestCase(CrossbenchFakeFsTestCase):
+
+  def setUp(self) -> None:
+    super().setUp()
+    self.result_location = pathlib.Path("test/out/results")
+    self.result_dict = ProbeResultDict(self.result_location)
+    self.local_result = LocalProbeResult()
+
+  def test_create_empty(self):
+    self.assertEqual(len(self.result_dict), 0)
+    self.assertFalse(self.result_dict)
+    self.assertNotIn(MockProbe(), self.result_dict)
+
+  def test_get_item(self):
+    probe = MockProbe()
+    with self.assertRaises(KeyError):
+      _ = self.result_dict[probe]
+    self.result_dict[probe] = self.local_result
+    self.assertIs(self.result_dict[probe], self.local_result)
+
+  def test_get(self):
+    probe = MockProbe()
+    self.assertIsNone(self.result_dict.get(probe))
+    self.assertEqual(self.result_dict.get(probe, 1234), 1234)
+    self.result_dict[probe] = self.local_result
+    self.assertIs(self.result_dict.get(probe), self.local_result)
+
+  def test_to_json_empty(self):
+    probe = MockProbe()
+    self.result_dict[probe] = self.local_result
+    json = self.result_dict.to_json()
+    self.assertDictEqual(json, {MockProbe.NAME: None})
+
+  def test_to_json_result(self):
+    csv = self.create_file("result.csv")
+    txt = self.create_file("result.txt")
+    self.local_result = LocalProbeResult(csv=(csv,), txt=(txt,))
+    probe = MockProbe()
+    self.result_dict[probe] = self.local_result
+    json = self.result_dict.to_json()
+    self.assertDictEqual(
+        json, {MockProbe.NAME: {
+            "csv": [str(csv)],
+            "txt": [str(txt)]
+        }})
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_system_profiling.py b/tests/crossbench/probes/test_system_profiling.py
new file mode 100644
index 0000000..8941877
--- /dev/null
+++ b/tests/crossbench/probes/test_system_profiling.py
@@ -0,0 +1,330 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import pathlib
+import unittest
+
+from crossbench.browsers.settings import Settings
+from crossbench.probes.profiling.system_profiling import (
+    RENDERER_CMD_PATH, CallGraphMode, CleanupMode, ProfilingProbe, TargetMode,
+    generate_simpleperf_command_line)
+from tests import test_helper
+from tests.crossbench.mock_browser import (MockChromeStable, MockFirefox,
+                                           MockSafari)
+from tests.crossbench.mock_helper import LinuxMockPlatform, MacOsMockPlatform
+from tests.crossbench.probes.helper import GenericProbeTestCase
+
+
+class SystemProfilingProbeTestCase(GenericProbeTestCase):
+
+  def setUp(self):
+    super().setUp()
+    self.fs.add_real_file(RENDERER_CMD_PATH)
+
+  def test_simpleperf_command_line_with_tid(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.RENDERER_MAIN_ONLY,
+            app_name="com.android.chrome",
+            renderer_pid=1234,
+            renderer_main_tid=5678,
+            call_graph_mode=CallGraphMode.DWARF,
+            frequency=None,
+            count=None,
+            cpus=None,
+            events=None,
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-t", "5678", "--call-graph", "dwarf",
+                "--post-unwind=yes", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_pid(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.RENDERER_PROCESS_ONLY,
+            app_name="com.android.chrome",
+            renderer_pid=1234,
+            renderer_main_tid=5678,
+            call_graph_mode=CallGraphMode.DWARF,
+            frequency=None,
+            count=None,
+            cpus=None,
+            events=None,
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-p", "1234", "--call-graph", "dwarf",
+                "--post-unwind=yes", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_app(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.BROWSER_APP_ONLY,
+            app_name="com.chrome.beta",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.DWARF,
+            frequency=None,
+            count=None,
+            cpus=None,
+            events=None,
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "--app", "com.chrome.beta",
+                "--call-graph", "dwarf", "--post-unwind=yes", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_systemwide(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.SYSTEM_WIDE,
+            app_name="org.chromium.chrome",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.DWARF,
+            frequency=None,
+            count=None,
+            cpus=None,
+            events=None,
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-a", "--call-graph", "dwarf",
+                "--post-unwind=yes", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_frequency(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.SYSTEM_WIDE,
+            app_name="org.chromium.chrome",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.FRAME_POINTER,
+            frequency=1234,
+            count=None,
+            cpus=None,
+            events=None,
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-a", "--call-graph", "fp", "-f",
+                "1234", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_count(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.SYSTEM_WIDE,
+            app_name="org.chromium.chrome",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.FRAME_POINTER,
+            frequency=None,
+            count=5,
+            cpus=None,
+            events=None,
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-a", "--call-graph", "fp", "-c", "5",
+                "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_cpu(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.SYSTEM_WIDE,
+            app_name="org.chromium.chrome",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.FRAME_POINTER,
+            frequency=None,
+            count=None,
+            cpus=[0, 1, 2],
+            events=None,
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-a", "--call-graph", "fp", "--cpu",
+                "0,1,2", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_events(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.SYSTEM_WIDE,
+            app_name="org.chromium.chrome",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.NO_CALL_GRAPH,
+            frequency=1234,
+            count=5,
+            cpus=None,
+            events=["cpu-cycles", "instructions"],
+            grouped_events=None,
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-a", "-f", "1234", "-c", "5", "-e",
+                "cpu-cycles,instructions", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_grouped_events(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.SYSTEM_WIDE,
+            app_name="org.chromium.chrome",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.NO_CALL_GRAPH,
+            frequency=1234,
+            count=5,
+            cpus=None,
+            events=None,
+            grouped_events=["cpu-cycles", "instructions"],
+            add_counters=None,
+            output_path=output_path), [
+                "simpleperf", "record", "-a", "-f", "1234", "-c", "5",
+                "--group", "cpu-cycles,instructions", "-o", output_path
+            ])
+
+  def test_simpleperf_command_line_with_add_counters(self):
+    output_path = pathlib.Path("simpleperf.perf.data")
+    self.assertListEqual(
+        generate_simpleperf_command_line(
+            target=TargetMode.SYSTEM_WIDE,
+            app_name="org.chromium.chrome",
+            renderer_pid=None,
+            renderer_main_tid=None,
+            call_graph_mode=CallGraphMode.NO_CALL_GRAPH,
+            frequency=1234,
+            count=5,
+            cpus=None,
+            events=["sched:sched_switch"],
+            grouped_events=None,
+            add_counters=["cpu-cycles", "instructions"],
+            output_path=output_path), [
+                "simpleperf", "record", "-a", "-f", "1234", "-c", "5", "-e",
+                "sched:sched_switch", "--add-counter",
+                "cpu-cycles,instructions", "--no-inherit", "-o", output_path
+            ])
+
+  def test_create_non_defaults(self):
+    probe = ProfilingProbe.from_config({
+        "js": False,
+        "browser_process": True,
+        "spare_renderer_process": True,
+        "v8_interpreted_frames": False,
+        "pprof": False,
+        "cleanup": "never",
+        "target": "renderer_process_only",
+        "pin_renderer_main_core": 3,
+        "call_graph_mode": "dwarf",
+        "frequency": 1200,
+        "count": 430,
+        "cpu": [1, 2, 3],
+        "events": ["instructions", "cache-misses"],
+        "grouped_events": ["cache-references", "cache-misses"],
+        "add_counters": ["aa", "bb"],
+    })
+    self.assertTrue(probe.key)
+    self.assertFalse(probe.sample_js)
+    self.assertTrue(probe.sample_browser_process)
+    self.assertFalse(probe.run_pprof)
+    self.assertTrue(probe.cleanup_mode, CleanupMode.NEVER)
+    self.assertEqual(probe.target, TargetMode.RENDERER_PROCESS_ONLY)
+    self.assertTrue(probe.start_profiling_after_setup)
+    self.assertEqual(probe.pin_renderer_main_core, 3)
+    self.assertEqual(probe.call_graph_mode, CallGraphMode.DWARF)
+    self.assertEqual(probe.frequency, 1200)
+    self.assertEqual(probe.count, 430)
+    self.assertEqual(probe.cpu, (1, 2, 3))
+    self.assertEqual(probe.events, ("instructions", "cache-misses"))
+    self.assertEqual(probe.grouped_events, ("cache-references", "cache-misses"))
+    self.assertEqual(probe.add_counters, ("aa", "bb"))
+
+  def test_create_custom_frequency(self):
+    probe = ProfilingProbe.from_config({"freq": "max"})
+    self.assertEqual(probe.frequency, "max")
+    probe = ProfilingProbe.from_config({"freq": 333})
+    self.assertEqual(probe.frequency, 333)
+
+  def test_create_invalid_frequency(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "frequency"):
+      _ = ProfilingProbe.from_config({"freq": -100})
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "frequency"):
+      _ = ProfilingProbe.from_config({"freq": "maaaaxxx"})
+
+  def test_spare_renderer(self):
+    browser_a = self.browsers[0]
+    browser_b = self.browsers[0]
+
+    probe_spare = ProfilingProbe(spare_renderer_process=True)
+    browser_a.attach_probe(probe_spare)
+    self.assertNotIn("SpareRendererForSitePerProcess",
+                     browser_b.features.disabled)
+
+    probe_no_spare = ProfilingProbe(spare_renderer_process=False)
+    browser_b.attach_probe(probe_no_spare)
+    self.assertIn("SpareRendererForSitePerProcess", browser_b.features.disabled)
+
+  def test_attach_unsupported(self):
+    probe = ProfilingProbe()
+
+    macos_platform = MacOsMockPlatform()
+    test_browsers = (MockSafari, MockFirefox, MockChromeStable)
+    for browser_cls in test_browsers:
+      browser_cls.setup_fs(self.fs, macos_platform)
+      name = browser_cls.__name__
+      browser_cls(
+          name, settings=Settings(platform=macos_platform)).attach_probe(probe)
+
+    linux_platform = LinuxMockPlatform()
+    for browser_cls in test_browsers:
+      browser_cls.setup_fs(self.fs, linux_platform)
+    with self.assertRaises(AssertionError):
+      MockFirefox(
+          "firefox",
+          settings=Settings(platform=linux_platform)).attach_probe(probe)
+    MockChromeStable(
+        "chrome",
+        settings=Settings(platform=linux_platform)).attach_probe(probe)
+
+
+class EnumTestCase(unittest.TestCase):
+
+  def test_cleanup_mode(self):
+    self.assertIs(CleanupMode(True), CleanupMode.ALWAYS)
+    self.assertIs(CleanupMode(False), CleanupMode.NEVER)
+
+    self.assertIs(CleanupMode("always"), CleanupMode.ALWAYS)
+    self.assertIs(CleanupMode("never"), CleanupMode.NEVER)
+    self.assertIs(CleanupMode("auto"), CleanupMode.AUTO)
+
+  def test_target_mode(self):
+    self.assertIs(
+        TargetMode("renderer_main_only"), TargetMode.RENDERER_MAIN_ONLY)
+    self.assertIs(
+        TargetMode("RENDERER_MAIN_ONLY"), TargetMode.RENDERER_MAIN_ONLY)
+
+  def test_call_graph_mode(self):
+    self.assertIs(CallGraphMode("frame_pointer"), CallGraphMode.FRAME_POINTER)
+    self.assertIs(CallGraphMode("FRAME_POINTER"), CallGraphMode.FRAME_POINTER)
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_thermal_monitor.py b/tests/crossbench/probes/test_thermal_monitor.py
new file mode 100644
index 0000000..8670e7d
--- /dev/null
+++ b/tests/crossbench/probes/test_thermal_monitor.py
@@ -0,0 +1,111 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import json
+import unittest
+
+from crossbench.browsers.settings import Settings
+from crossbench.probes.thermal_monitor import (ThermalMonitorProbe,
+                                               ThermalStatus)
+from tests import test_helper
+from tests.crossbench.mock_browser import MockChromeAndroidStable
+from tests.crossbench.mock_helper import AndroidAdbMockPlatform, MockAdb
+from tests.crossbench.runner.helper import BaseRunnerTestCase
+
+
+class ThermalStatusTestCase(unittest.TestCase):
+
+  def test_thermal_status_short_names(self):
+    self.assertIs(ThermalStatus.parse("none"), ThermalStatus.NONE)
+    self.assertIs(ThermalStatus.parse("light"), ThermalStatus.LIGHT)
+    self.assertIs(ThermalStatus.parse("moderate"), ThermalStatus.MODERATE)
+    self.assertIs(ThermalStatus.parse("severe"), ThermalStatus.SEVERE)
+    self.assertIs(ThermalStatus.parse("critical"), ThermalStatus.CRITICAL)
+    self.assertIs(ThermalStatus.parse("emergency"), ThermalStatus.EMERGENCY)
+    self.assertIs(ThermalStatus.parse("shutdown"), ThermalStatus.SHUTDOWN)
+
+  def test_thermal_status_long_names(self):
+    self.assertIs(
+        ThermalStatus.parse("THERMAL_STATUS_NONE"), ThermalStatus.NONE)
+    self.assertIs(
+        ThermalStatus.parse("THERMAL_STATUS_LIGHT"), ThermalStatus.LIGHT)
+    self.assertIs(
+        ThermalStatus.parse("THERMAL_STATUS_MODERATE"), ThermalStatus.MODERATE)
+    self.assertIs(
+        ThermalStatus.parse("THERMAL_STATUS_SEVERE"), ThermalStatus.SEVERE)
+    self.assertIs(
+        ThermalStatus.parse("THERMAL_STATUS_CRITICAL"), ThermalStatus.CRITICAL)
+    self.assertIs(
+        ThermalStatus.parse("THERMAL_STATUS_EMERGENCY"),
+        ThermalStatus.EMERGENCY)
+    self.assertIs(
+        ThermalStatus.parse("THERMAL_STATUS_SHUTDOWN"), ThermalStatus.SHUTDOWN)
+
+  def test_thermal_status_numbers(self):
+    self.assertIs(ThermalStatus.parse("-1"), ThermalStatus.UNAVAILABLE)
+    self.assertIs(ThermalStatus.parse("0"), ThermalStatus.NONE)
+    self.assertIs(ThermalStatus.parse("1"), ThermalStatus.LIGHT)
+    self.assertIs(ThermalStatus.parse("2"), ThermalStatus.MODERATE)
+    self.assertIs(ThermalStatus.parse("3"), ThermalStatus.SEVERE)
+    self.assertIs(ThermalStatus.parse("4"), ThermalStatus.CRITICAL)
+    self.assertIs(ThermalStatus.parse("5"), ThermalStatus.EMERGENCY)
+    self.assertIs(ThermalStatus.parse("6"), ThermalStatus.SHUTDOWN)
+
+
+class TestThermalMonitorProbe(BaseRunnerTestCase):
+
+  def test_android_run(self):
+    self.platform.expect_sh(
+        "/usr/bin/adb",
+        "devices",
+        "-l",
+        result="List of devices attached\n123 device usb:0 product:a model:b")
+    adb_platform = AndroidAdbMockPlatform(
+        self.platform, adb=MockAdb(self.platform))
+    runner = self.default_runner(browsers=[
+        MockChromeAndroidStable(
+            "adb:chrome", settings=Settings(platform=adb_platform))
+    ])
+
+    adb_platform.expect_sh(
+        "dumpsys",
+        "thermalservice",
+        result="HAL Ready: true\nThermal Status: 0")
+    adb_platform.expect_sh(
+        "dumpsys",
+        "thermalservice",
+        result="HAL Ready: true\nThermal Status: 1")
+    adb_platform.expect_sh(
+        "dumpsys",
+        "thermalservice",
+        result="HAL Ready: true\nThermal Status: 2")
+    adb_platform.expect_sh(
+        "dumpsys",
+        "thermalservice",
+        result="HAL Ready: true\nThermal Status: 0")
+
+    runner.run(is_dry_run=False)
+
+    self.assertEqual(len(runner.runs), 2)
+    self.assertTrue(runner.is_success)
+
+    run = runner.runs[0]
+    self.assertTrue(run.is_success)
+    results = run.results.get_by_name(ThermalMonitorProbe.NAME)
+    with results.json.open() as f:
+      thermal_data = json.load(f)
+      self.assertIn("max_observed_status", thermal_data)
+      self.assertEqual(thermal_data["max_observed_status"], 1)
+
+    run = runner.runs[1]
+    self.assertTrue(run.is_success)
+    results = run.results.get_by_name(ThermalMonitorProbe.NAME)
+    with results.json.open() as f:
+      thermal_data = json.load(f)
+      self.assertIn("max_observed_status", thermal_data)
+      self.assertEqual(thermal_data["max_observed_status"], 2)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_trace_processor.py b/tests/crossbench/probes/test_trace_processor.py
new file mode 100644
index 0000000..33625b4
--- /dev/null
+++ b/tests/crossbench/probes/test_trace_processor.py
@@ -0,0 +1,106 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import json
+import unittest
+
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.probes.all import TraceProcessorProbe
+from tests import test_helper
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class TraceProcessorProbeTestCase(unittest.TestCase):
+
+  @unittest.skipIf(not plt.PLATFORM.which("trace_processor"),
+                   "trace_processor not available")
+  def test_parse_example_config(self):
+    config_file = (
+        test_helper.config_dir() / "doc/probe/trace_processor.config.hjson")
+    self.assertTrue(config_file.is_file())
+    probes = ProbeListConfig.parse_path(config_file).probes
+    self.assertEqual(len(probes), 2)
+    probe = probes[0]
+    self.assertIsInstance(probe, TraceProcessorProbe)
+
+
+class TraceProcessorResultTestCase(BaseCrossbenchTestCase):
+
+  def test_merge_browsers(self):
+    probe: TraceProcessorProbe = TraceProcessorProbe.from_config("")
+
+    browser = unittest.mock.MagicMock()
+    browser.label = "browser"
+    browser.unique_name = "browser"
+
+    story = unittest.mock.MagicMock()
+    story.name = "story"
+
+    result1 = unittest.mock.MagicMock()
+    csv1 = self.create_file("run1/query.csv", contents="foo,bar\n1,2\n")
+    json1 = self.create_file(
+        "run1/metric.json", contents=json.dumps({"foo": {
+            "bar": 7
+        }}))
+    result1.csv_list = [csv1]
+    result1.json_list = [json1]
+
+    run1 = unittest.mock.MagicMock()
+    run1.repetition = 0
+    run1.results = {probe: result1}
+    run1.browser = browser
+    run1.story = story
+    run1.temperature = "default"
+
+    result2 = unittest.mock.MagicMock()
+    csv2 = self.create_file("run2/query.csv", contents="foo,bar\n3,4\n")
+    json2 = self.create_file(
+        "run2/metric.json", contents=json.dumps({"foo": {
+            "bar": 9
+        }}))
+    result2.csv_list = [csv2]
+    result2.json_list = [json2]
+
+    run2 = unittest.mock.MagicMock()
+    run2.repetition = 1
+    run2.results = {probe: result2}
+    run2.browser = browser
+    run2.story = story
+    run2.temperature = "default"
+
+    rep_group = unittest.mock.MagicMock()
+    rep_group.story = story
+    rep_group.runs = [run1, run2]
+
+    story_group = unittest.mock.MagicMock()
+    story_group.browser = browser
+    story_group.repetitions_groups = [rep_group]
+
+    browsers_run_group = unittest.mock.MagicMock()
+    browsers_run_group.get_local_probe_result_path = unittest.mock.MagicMock(
+        return_value=pth.LocalPath("result/"))
+    browsers_run_group.story_groups = [story_group]
+    browsers_run_group.runs = [run1, run2]
+
+    merged_result = probe.merge_browsers(browsers_run_group)
+    self.assertEqual(len(merged_result.csv_list), 1)
+    self.assertEqual(len(merged_result.json_list), 1)
+
+    expected_csv = ("foo,bar,cb_browser,cb_story,cb_temperature,cb_run\n"
+                    "1,2,browser,story,default,0\n"
+                    "3,4,browser,story,default,1\n")
+    with merged_result.csv.open("r") as f:
+      self.assertEqual(f.read(), expected_csv)
+
+    with merged_result.json.open("r") as f:
+      metrics = json.load(f)
+    self.assertTrue("foo/bar" in metrics)
+    self.assertTrue("values" in metrics["foo/bar"])
+    self.assertEqual([7, 9], metrics["foo/bar"]["values"])
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_v8_log.py b/tests/crossbench/probes/test_v8_log.py
new file mode 100644
index 0000000..564c1ec
--- /dev/null
+++ b/tests/crossbench/probes/test_v8_log.py
@@ -0,0 +1,84 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import unittest
+
+from crossbench.probes.all import V8LogProbe
+from tests import test_helper
+
+
+class V8LogProbeTestCase(unittest.TestCase):
+
+  def test_invalid_flags(self):
+    with self.assertRaises(ValueError):
+      V8LogProbe(js_flags=["--no-opt"])
+
+  def test_disabling_flag(self):
+    probe = V8LogProbe(log_all=True, js_flags=["--no-log-maps"])
+    self.assertSetEqual({"--log-all", "--no-log-maps"},
+                        set(probe.js_flags.keys()))
+
+  def test_conflicting_flags(self):
+    with self.assertRaises(Exception):
+      V8LogProbe(js_flags=["--log-maps", "--no-log-maps"])
+    with self.assertRaises(Exception):
+      V8LogProbe(prof=True, js_flags=["--no-prof"])
+
+  def test_parse_invalid_config(self):
+    with self.assertRaises(ValueError):
+      # No logging enabled
+      V8LogProbe.from_config({
+          "log_all": False,
+          "prof": False,
+          "profview": False
+      })
+    with self.assertRaises(ValueError) as cm:
+      # profview needs prof
+      V8LogProbe.from_config({
+          "log_all": False,
+          "prof": False,
+          "profview": True
+      })
+    self.assertIn("profview", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError):
+      V8LogProbe.from_config({"log_all": []})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      V8LogProbe.from_config({"prof": 12})
+    with self.assertRaises(ValueError):
+      V8LogProbe.from_config({"js_flags": [1]})
+    with self.assertRaises(ValueError):
+      V8LogProbe.from_config({"js_flags": ["--log-all", True]})
+
+  def test_parse_config(self):
+    probe: V8LogProbe = V8LogProbe.from_config({})
+    self.assertSetEqual({"--log-all"}, set(probe.js_flags.keys()))
+
+    probe = V8LogProbe.from_config({"prof": False})
+    self.assertSetEqual({"--log-all"}, set(probe.js_flags.keys()))
+
+    probe = V8LogProbe.from_config({"prof": True})
+    self.assertSetEqual({"--log-all"}, set(probe.js_flags.keys()))
+
+    probe = V8LogProbe.from_config({"js_flags": None})
+    self.assertSetEqual({"--log-all"}, set(probe.js_flags.keys()))
+
+    probe = V8LogProbe.from_config({"js_flags": []})
+    self.assertSetEqual({"--log-all"}, set(probe.js_flags.keys()))
+
+    probe = V8LogProbe.from_config(
+        {"js_flags": ["--no-log-ic", "--no-log-maps"]})
+    self.assertSetEqual({"--log-all", "--no-log-ic", "--no-log-maps"},
+                        set(probe.js_flags.keys()))
+
+    probe = V8LogProbe.from_config({
+        "log_all": False,
+        "js_flags": ["--no-log-ic", "--no-log-maps"]
+    })
+    self.assertSetEqual({"--prof", "--no-log-ic", "--no-log-maps"},
+                        set(probe.js_flags.keys()))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_v8_rcs.py b/tests/crossbench/probes/test_v8_rcs.py
new file mode 100644
index 0000000..113b6b1
--- /dev/null
+++ b/tests/crossbench/probes/test_v8_rcs.py
@@ -0,0 +1,128 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from typing import Final
+
+from crossbench.benchmarks.loading.page.live import LivePage
+from crossbench.probes.v8.rcs import V8RCSProbe
+from tests import test_helper
+from tests.crossbench.probes.helper import GenericProbeTestCase
+
+EXAMPLE_RCS_DATA: Final[str] = """
+                      Runtime Function/C++ Builtin        Time             Count
+========================================================================================
+                                  FunctionCallback     94.96ms  38.47%     65908  29.19%
+                                      JS_Execution     19.37ms   7.85%       976   0.43%
+          PreParseBackgroundWithVariableResolution     14.49ms   5.87%      5175   2.29%
+                              ParseFunctionLiteral     10.25ms   4.15%      2209   0.98%
+                                   CompileIgnition      9.30ms   3.77%      2236   0.99%
+"""
+
+
+class V8RCSProbeTestCase(GenericProbeTestCase):
+
+  def test_simple_loading_case(self):
+    probe = V8RCSProbe()
+    stories = [
+        LivePage("google", "https://google.com"),
+        LivePage("amazon", "https://amazon.com")
+    ]
+    repetitions = 2
+    runner = self.create_runner(
+        stories,
+        js_side_effects=[EXAMPLE_RCS_DATA],
+        repetitions=repetitions,
+        separate=True,
+        throw=True)
+    runner.attach_probe(probe)
+    runner.run()
+    self.assertTrue(runner.is_success)
+
+    for run in runner.runs:
+      self.assertIn("--runtime-call-stats", run.browser.js_flags)
+
+    # One file per story repetition
+    result_count = len(self.browsers) * len(stories) * repetitions
+    # One merged result per story
+    result_count += len(self.browsers) * len(stories)
+    # One merged results per browser
+    result_count += len(self.browsers)
+    # Symlinked summary files:
+    rcs_result_files = list(runner.out_dir.glob(f"**/{probe.name}.txt"))
+    self.assertEqual(len(rcs_result_files), result_count)
+    # Cache-temperatures files
+    rcs_result_files = list(runner.out_dir.glob(f"**/{probe.name}/*.rcs.txt"))
+    self.assertEqual(len(rcs_result_files), result_count)
+
+    (story_data, reps_data, stories_data, _) = self.get_non_empty_results_str(
+        runner, probe, "txt", has_browsers_data=False)
+
+    self.assertEqual(story_data.count(EXAMPLE_RCS_DATA), 1)
+    self.assertEqual(reps_data.count(EXAMPLE_RCS_DATA), repetitions)
+    self.assertEqual(
+        stories_data.count(EXAMPLE_RCS_DATA),
+        len(stories) * repetitions)
+
+    self.assertEqual(story_data.count("== Page: "), 0)
+    self.assertEqual(reps_data.count("== Page: "), 1)
+    self.assertEqual(stories_data.count("== Page: "), len(stories))
+
+  def validate_cache_temperatures_files(self, probe, group, cache_temperatures):
+    rcs_result_files = list(group.path.glob(f"{probe.name}/*.rcs.txt"))
+    self.assertEqual(len(rcs_result_files), len(cache_temperatures) + 1)
+    self.assertTrue((group.path / f"{probe.name}.txt").is_file())
+    for index, cache_temperature in enumerate(cache_temperatures):
+      path = group.path / probe.name / f"{index}_{cache_temperature}.rcs.txt"
+      self.assertTrue(path.is_file(), f"{path} does not exist")
+
+  def test_simple_loading_case_cache_temperatures(self):
+    probe = V8RCSProbe()
+    stories = [
+        LivePage("google", "https://google.com"),
+        LivePage("amazon", "https://amazon.com")
+    ]
+    repetitions = 2
+    cache_temperatures = ("cold", "warm")
+    runner = self.create_runner(
+        stories,
+        js_side_effects=[EXAMPLE_RCS_DATA, EXAMPLE_RCS_DATA],
+        repetitions=repetitions,
+        cache_temperatures=cache_temperatures,
+        separate=True,
+        throw=True)
+    runner.attach_probe(probe)
+    runner.run()
+    self.assertTrue(runner.is_success)
+
+    repetition_group = runner.repetitions_groups[0]
+    self.validate_cache_temperatures_files(probe, repetition_group,
+                                           cache_temperatures)
+    story_group = runner.story_groups[0]
+    self.validate_cache_temperatures_files(probe, story_group,
+                                           cache_temperatures)
+
+    rcs_result_files = list(runner.out_dir.glob(f"**/{probe.name}.txt"))
+    # One merged file for each story and cache temp + all.rcs.txt:
+    result_count = len(self.browsers) * len(stories) * (
+        len(cache_temperatures) + 1)
+    # One merged results per browser and cache temp + all.rcs.txt
+    result_count += len(self.browsers) * (len(cache_temperatures) + 1)
+    # One merged results per browser
+    result_count += len(self.browsers)
+    # Without symlinked summary files:
+    rcs_result_files = list(runner.out_dir.glob(f"**/{probe.name}/*.rcs.txt"))
+    self.assertEqual(len(rcs_result_files), result_count)
+
+    top_level_rcs_files = list((runner.out_dir / probe.name).iterdir())
+    self.assertEqual(len(top_level_rcs_files), len(self.browsers))
+
+    with self.assertLogs() as cm:
+      probe.log_browsers_result(runner.browser_group)
+    log_output = "\n".join(cm.output)
+    for top_level_rcs_file in top_level_rcs_files:
+      self.assertIn(str(top_level_rcs_file), log_output)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/__init__.py b/tests/crossbench/runner/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/tests/crossbench/runner/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/runner/groups/__init__.py b/tests/crossbench/runner/groups/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/crossbench/runner/groups/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/runner/groups/base.py b/tests/crossbench/runner/groups/base.py
new file mode 100644
index 0000000..85ffa40
--- /dev/null
+++ b/tests/crossbench/runner/groups/base.py
@@ -0,0 +1,26 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file
+
+from typing import Optional
+
+from crossbench.browsers.browser import Browser
+from crossbench.flags.base import Flags
+from crossbench.runner.groups.session import BrowserSessionRunGroup
+from tests.crossbench.runner.helper import BaseRunnerTestCase
+
+
+class BaseRunGroupTestCase(BaseRunnerTestCase):
+
+  def setUp(self):
+    super().setUp()
+    self.root_dir = self.out_dir / "custom"
+    self.runner = self.default_runner()
+
+  def default_session(self,
+                      browser: Optional[Browser] = None,
+                      throw: bool = True):
+    browser = browser or self.browsers[0]
+    return BrowserSessionRunGroup(self.runner.env, self.runner.probes, browser,
+                                  Flags(), 0, self.root_dir,
+                                  self.runner.create_symlinks, throw)
diff --git a/tests/crossbench/runner/groups/test_groups.py b/tests/crossbench/runner/groups/test_groups.py
new file mode 100644
index 0000000..f3350cf
--- /dev/null
+++ b/tests/crossbench/runner/groups/test_groups.py
@@ -0,0 +1,101 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file
+
+from typing import Iterable
+
+from crossbench.runner.groups.browsers import BrowsersRunGroup
+from crossbench.runner.groups.cache_temperatures import \
+    CacheTemperaturesRunGroup
+from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+from crossbench.runner.groups.stories import StoriesRunGroup
+from crossbench.runner.run import Run
+from tests import test_helper
+from tests.crossbench.runner.groups.base import BaseRunGroupTestCase
+from tests.crossbench.runner.helper import MockRun
+
+
+class RunGroupTestCase(BaseRunGroupTestCase):
+
+  def create_groups(self, runs: Iterable[Run], throw: bool = True):
+    cache_temperatures_groups = CacheTemperaturesRunGroup.groups(
+        runs, throw=throw)
+    repetitions_groups = RepetitionsRunGroup.groups(cache_temperatures_groups,
+                                                    throw)
+    story_groups = StoriesRunGroup.groups(repetitions_groups, throw)
+    browser_group = BrowsersRunGroup(story_groups, throw)
+    return browser_group
+
+  def test_create_empty(self):
+    with self.assertRaises(ValueError):
+      self.create_groups([])
+
+  def test_create_single(self):
+    session = self.default_session(throw=True)
+    run_0 = MockRun(self.runner, session, "story 0")
+    browser_group = self.create_groups([run_0])
+    self.assertListEqual(list(browser_group.runs), [run_0])
+    story_groups = list(browser_group.story_groups)
+    self.assertEqual(len(story_groups), 1)
+    self.assertListEqual(list(story_groups[0].runs), [run_0])
+    repetitions_group = list(story_groups[0].repetitions_groups)
+    self.assertEqual(len(repetitions_group), 1)
+
+  def test_single_story_multiple_repetitions(self):
+    session = self.default_session(throw=True)
+    run_0 = MockRun(self.runner, session, "story 0", repetition=0)
+    run_1 = MockRun(self.runner, session, "story 0", repetition=1)
+    browser_group = self.create_groups([run_0, run_1])
+    self.assertListEqual(list(browser_group.runs), [run_0, run_1])
+    story_groups = list(browser_group.story_groups)
+    self.assertEqual(len(story_groups), 1)
+    repetitions_groups = list(story_groups[0].repetitions_groups)
+    self.assertEqual(len(repetitions_groups), 1)
+    repetitions_group = repetitions_groups[0]
+    cache_temp_groups = list(repetitions_group.cache_temperatures_groups)
+    self.assertEqual(len(cache_temp_groups), 2)
+    self.assertListEqual(list(cache_temp_groups[0].runs), [run_0])
+    self.assertListEqual(list(cache_temp_groups[1].runs), [run_1])
+    cache_temp_repetitions_group = list(
+        repetitions_group.cache_temperature_repetitions_groups)
+    self.assertEqual(len(cache_temp_repetitions_group), 1)
+    self.assertListEqual(
+        list(cache_temp_repetitions_group[0].runs), [run_0, run_1])
+    self.assertEqual(cache_temp_repetitions_group[0].cache_temperature,
+                     "default")
+
+  def test_single_story_multiple_repetitions_cache_temperatures(self):
+    session = self.default_session(throw=True)
+    run_0 = MockRun(
+        self.runner, session, "story 0", repetition=0, temperature="cold")
+    run_1 = MockRun(
+        self.runner, session, "story 0", repetition=0, temperature="warm")
+    run_2 = MockRun(
+        self.runner, session, "story 0", repetition=1, temperature="cold")
+    run_3 = MockRun(
+        self.runner, session, "story 0", repetition=1, temperature="warm")
+
+    browser_group = self.create_groups([run_0, run_1, run_2, run_3])
+    self.assertListEqual(list(browser_group.runs), [run_0, run_1, run_2, run_3])
+    story_groups = list(browser_group.story_groups)
+    self.assertEqual(len(story_groups), 1)
+    repetitions_groups = list(story_groups[0].repetitions_groups)
+    self.assertEqual(len(repetitions_groups), 1)
+    repetitions_group = repetitions_groups[0]
+    cache_temp_groups = list(repetitions_group.cache_temperatures_groups)
+    self.assertEqual(len(cache_temp_groups), 2)
+    self.assertListEqual(list(cache_temp_groups[0].runs), [run_0, run_1])
+    self.assertListEqual(list(cache_temp_groups[1].runs), [run_2, run_3])
+    cache_temp_repetitions_group = list(
+        repetitions_group.cache_temperature_repetitions_groups)
+    self.assertEqual(len(cache_temp_groups), 2)
+    self.assertListEqual(
+        list(cache_temp_repetitions_group[0].runs), [run_0, run_2])
+    self.assertListEqual(
+        list(cache_temp_repetitions_group[1].runs), [run_1, run_3])
+    self.assertEqual(cache_temp_repetitions_group[0].cache_temperature, "cold")
+    self.assertEqual(cache_temp_repetitions_group[1].cache_temperature, "warm")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/groups/test_session.py b/tests/crossbench/runner/groups/test_session.py
new file mode 100644
index 0000000..2444d77
--- /dev/null
+++ b/tests/crossbench/runner/groups/test_session.py
@@ -0,0 +1,300 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from unittest import mock
+
+from crossbench import compat
+from crossbench.helper.state import UnexpectedStateError
+from tests import test_helper
+from tests.crossbench.runner.groups.base import BaseRunGroupTestCase
+from tests.crossbench.runner.helper import MockProbe, MockRun
+
+# Due to laziness we access internal variables in the test here.
+# Adding an accessor would wrongly hint that these variables are public.
+# pylint: disable=protected-access
+
+class BrowserSessionRunGroupTestCase(BaseRunGroupTestCase):
+
+  def test_basic_properties(self):
+    session = self.default_session()
+    self.assertEqual(session.index, 0)
+    self.assertIs(session.browser, self.browsers[0])
+    self.assertFalse(session.is_single_run)
+    self.assertFalse(session.is_running)
+    self.assertEqual(session.root_dir, self.root_dir)
+    self.assertFalse(session.extra_flags)
+    self.assertFalse(session.extra_js_flags)
+    self.assertIn("0", str(session.info_stack))
+    self.assertIn(str(self.browsers[0].unique_name), str(session.info_stack))
+    self.assertEqual(session.info["runs"], 0)
+    self.assertEqual(session.info["index"], 0)
+    self.assertIn("0", str(session))
+    self.assertIn(str(self.browsers[0]), str(session))
+    self.assertTrue(session.browser_tmp_dir.is_dir())
+    with self.assertRaises(IndexError):
+      _ = session.timing
+
+  def test_out_dir_single_run(self):
+    session = self.default_session()
+    with self.assertRaises(UnexpectedStateError):
+      _ = session.out_dir
+    run_1 = MockRun(self.runner, session, "story 1")
+    session.append(run_1)
+    with self.assertRaises(UnexpectedStateError):
+      _ = session.out_dir
+    session.set_ready()
+    self.assertEqual(session.out_dir, run_1.out_dir)
+    self.assertNotEqual(session.out_dir, session.raw_session_dir)
+    # session dirs are only created when opening the session.
+    self.assertFalse(session.out_dir.exists())
+
+  def test_out_dir_multiple_runs(self):
+    session = self.default_session()
+    run_1 = MockRun(self.runner, session, "story 1")
+    run_2 = MockRun(self.runner, session, "story 2")
+    session.append(run_1)
+    session.append(run_2)
+    session.set_ready()
+    self.assertNotEqual(session.out_dir, run_1.out_dir)
+    self.assertEqual(session.out_dir, session.raw_session_dir)
+
+  def test_append(self):
+    session = self.default_session()
+    run_1 = MockRun(self.runner, session, "story 1")
+    session.append(run_1)
+    self.assertListEqual(list(session.runs), [run_1])
+    self.assertEqual(session.info["runs"], 1)
+    self.assertTrue(session.is_single_run)
+    self.assertFalse(session.is_running)
+    self.assertIs(session.first_run, run_1)
+    self.assertIs(session.timing, run_1.timing)
+
+    run_2 = MockRun(self.runner, session, "story 2")
+    session.append(run_2)
+    self.assertListEqual(list(session.runs), [run_1, run_2])
+    self.assertEqual(session.info["runs"], 2)
+
+    session.set_ready()
+    self.assertFalse(session.is_single_run)
+    self.assertFalse(session.is_running)
+    self.assertIs(session.first_run, run_1)
+    self.assertFalse(session.extra_flags)
+    self.assertFalse(session.extra_js_flags)
+
+    self.assertTrue(session.is_first_run(run_1))
+    self.assertFalse(session.is_first_run(run_2))
+
+  def test_append_after_ready(self):
+    session = self.default_session()
+    run_1 = MockRun(self.runner, session, "story 1")
+    session.append(run_1)
+    session.set_ready()
+    with self.assertRaises(UnexpectedStateError):
+      session.append(MockRun(self.runner, session, "story 3"))
+
+  def test_append_wrong_session(self):
+    session_1 = self.default_session()
+    run_1 = MockRun(self.runner, session_1, "run 0")
+    session_1.append(run_1)
+    session_2 = self.default_session(self.browsers[1])
+    run_2 = MockRun(self.runner, session_2, "run 0")
+    with self.assertRaises(AssertionError):
+      session_1.append(run_2)
+    run_3 = MockRun(self.runner, session_1, "run 0")
+    run_3.browser = self.browsers[1]
+    with self.assertRaises(AssertionError):
+      session_1.append(run_3)
+
+  def test_append_different_probes(self):
+    session = self.default_session()
+    run_1 = MockRun(self.runner, session, "story 0")
+    run_1.probes = []
+    run_2 = MockRun(self.runner, session, "story 0")
+    run_2.probes = [MockProbe()]
+    session.append(run_1)
+    session.append(run_2)
+    with self.assertRaises(ValueError):
+      session.set_ready()
+
+  def test_set_ready(self):
+    with self.assertRaises(ValueError):
+      session = self.default_session()
+      session.set_ready()
+    session = self.default_session()
+    session.append(MockRun(self.runner, session, "story 0"))
+    session.set_ready()
+    self.assertFalse(session.extra_flags)
+    self.assertFalse(session.extra_js_flags)
+
+  def test_open_not_ready(self):
+    session = self.default_session()
+    self.assertFalse(session.is_running)
+    did_run = False
+    with self.assertRaises(UnexpectedStateError):
+      with session.open():
+        did_run = True
+    self.assertFalse(session.is_running)
+    self.assertFalse(did_run)
+
+  def test_open_not_ready_with_run(self):
+    session = self.default_session()
+    run = MockRun(self.runner, session, "story 0")
+    session.append(run)
+    self.assertFalse(session.is_running)
+    did_run = False
+    with self.assertRaises(UnexpectedStateError):
+      with session.open():
+        did_run = True
+    self.assertFalse(session.is_running)
+    self.assertTrue(session.is_success)
+    self.assertFalse(run.did_setup)
+    self.assertFalse(run.did_run)
+    self.assertFalse(did_run)
+
+  def test_open(self):
+    session = self.default_session()
+    run = MockRun(self.runner, session, "story 0")
+    session.append(run)
+    session.set_ready()
+    self.assertFalse(session.is_running)
+    self.assertFalse(run.did_setup)
+    self.assertFalse(run.did_teardown)
+    did_run = False
+    with session.open() as startup_is_success:
+      self.assertTrue(session.is_running)
+      self.assertTrue(run.did_setup)
+      self.assertTrue(session.browser.is_running)
+      self.assertFalse(run.did_teardown_browser)
+      self.assertTrue(session._probe_context_manager.is_running)
+      # runs would be triggered here...
+      did_run = True
+    self.assertTrue(startup_is_success)
+    self.assertFalse(session.is_running)
+    self.assertFalse(session.browser.is_running)
+    self.assertFalse(session._probe_context_manager.is_running)
+    self.assertTrue(session.is_success)
+    self.assertTrue(session.path.is_dir())
+    session_symlinks = list((session.browser_dir / "sessions").iterdir())
+    self.assertEqual(len(session_symlinks), 1)
+    self.assertEqual(compat.readlink(session_symlinks[0]), session.path)
+    self.assertTrue(run.did_setup)
+    self.assertFalse(run.did_run)
+    self.assertTrue(run.did_teardown_browser)
+    self.assertTrue(did_run)
+    # Using mock runs here... didn't create runs symlinks
+    self.assertFalse((session.browser_dir / "runs").exists())
+
+  def test_open_dry_run(self):
+    session = self.default_session()
+    run = MockRun(self.runner, session, "story 0")
+    session.append(run)
+    session.set_ready()
+    self.assertFalse(session.is_running)
+    did_run = False
+    with session.open(is_dry_run=True) as startup_is_success:
+      self.assertTrue(session.is_running)
+      self.assertFalse(session.browser.is_running)
+      self.assertTrue(session._probe_context_manager.is_running)
+      # runs would be triggered here...
+      did_run = True
+    self.assertTrue(startup_is_success)
+    self.assertFalse(session.is_running)
+    self.assertFalse(session.browser.is_running)
+    self.assertFalse(session._probe_context_manager.is_running)
+    self.assertTrue(run.did_setup)
+    self.assertFalse(run.did_teardown_browser)
+    self.assertTrue(did_run)
+
+  def test_open_inner_throw(self):
+    session = self.default_session(throw=True)
+    run = MockRun(self.runner, session, "story 0")
+    session.append(run)
+    session.set_ready()
+    did_run = False
+    with self.assertRaises(ValueError):
+      with session.open() as startup_is_success:
+        self.assertTrue(session.browser.is_running)
+        self.assertFalse(run.did_teardown_browser)
+        self.assertTrue(session._probe_context_manager.is_running)
+        did_run = True
+        raise ValueError("Test run failed")
+    self.assertTrue(startup_is_success)
+    self.assertTrue(did_run)
+    self._validate_post_inner_throw(session, run)
+
+  def _validate_post_inner_throw(self, session, run):
+    # Startup succeed, the inner evaluation failed.
+    self.assertFalse(session._probe_context_manager.is_running)
+    self.assertFalse(session.browser.is_running)
+    self.assertFalse(session.is_running)
+    self.assertFalse(session.is_success)
+    self.assertTrue(run.did_setup)
+    self.assertTrue(run.did_teardown_browser)
+    self.assertIn("Test run failed", str(session.exceptions[0].exception))
+
+  def test_open_inner_throw_capture(self):
+    session = self.default_session(throw=False)
+    run = MockRun(self.runner, session, "story 0")
+    session.append(run)
+    session.set_ready()
+    did_run = False
+    with session.open() as startup_is_success:
+      self.assertTrue(session.browser.is_running)
+      self.assertFalse(run.did_teardown_browser)
+      self.assertTrue(session._probe_context_manager.is_running)
+      did_run = True
+      raise ValueError("Test run failed")
+    self.assertTrue(did_run)
+    # Startup succeed, the inner evaluation failed.
+    self.assertTrue(startup_is_success)
+    self._validate_post_inner_throw(session, run)
+    self.assertEqual(len(session.exceptions), 1)
+
+  def test_open_network_error(self):
+    session = self.default_session(throw=False)
+    run = MockRun(self.runner, session, "story 0")
+    session.append(run)
+    session.set_ready()
+    did_run = False
+    with mock.patch.object(
+        session.network,
+        "open",
+        side_effect=ValueError("Network startup error")):
+      with session.open() as startup_is_success:
+        # Due to how context managers work we run the inner code even if
+        # the setup failed.
+        self.assertFalse(startup_is_success)
+        did_run = True
+    self.assertTrue(did_run)
+    self.assertEqual(len(session.exceptions), 1)
+    self._validate_open_network_error(session, run)
+
+  def test_open_network_error_throw(self):
+    session = self.default_session(throw=True)
+    run = MockRun(self.runner, session, "story 0")
+    session.append(run)
+    session.set_ready()
+    did_run = False
+    with self.assertRaises(ValueError) as cm:
+      with mock.patch.object(
+          session.network,
+          "open",
+          side_effect=ValueError("Network startup error")):
+        with session.open():
+          did_run = True
+    self.assertFalse(did_run)
+    self.assertIn("Network startup error", str(cm.exception))
+    self._validate_open_network_error(session, run)
+
+  def _validate_open_network_error(self, session, run):
+    self.assertFalse(session._probe_context_manager.is_running)
+    self.assertFalse(session.browser.is_running)
+    self.assertFalse(session.is_running)
+    self.assertFalse(session.is_success)
+    self.assertTrue(run.did_setup)
+    self.assertFalse(run.did_teardown_browser)
+    self.assertIn("Network startup error", str(session.exceptions[0].exception))
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/helper.py b/tests/crossbench/runner/helper.py
new file mode 100644
index 0000000..57d5c0d
--- /dev/null
+++ b/tests/crossbench/runner/helper.py
@@ -0,0 +1,201 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import abc
+import datetime as dt
+import json
+import pathlib
+from typing import Any, List, Optional
+
+from crossbench.browsers.browser import Browser
+from crossbench.browsers.settings import Settings
+from crossbench.env import HostEnvironment
+from crossbench.exception import Annotator
+from crossbench.path import safe_filename
+from crossbench.probes.probe import Probe
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.results import LocalProbeResult, ProbeResult
+from crossbench.runner.actions import Actions
+from crossbench.runner.run import Run
+from crossbench.runner.runner import Runner
+from crossbench.runner.timing import Timing
+from tests.crossbench.base import BaseCrossbenchTestCase
+from tests.crossbench.mock_browser import MockChromeDev, MockFirefox
+from tests.crossbench.mock_helper import MockBenchmark, MockStory
+
+
+class MockBrowser:
+
+  def __init__(self, unique_name: str, platform) -> None:
+    self.unique_name = unique_name
+    self.platform = platform
+    self.network = MockNetwork()
+
+  def __str__(self):
+    return self.unique_name
+
+
+class MockRun:
+
+  def __init__(self,
+               runner,
+               browser_session,
+               story="story",
+               repetition=0,
+               is_warmup=False,
+               temperature="default",
+               index=0,
+               name="run 0") -> None:
+    self.runner = runner
+    self.browser_session = browser_session
+    self.browser = browser_session.browser
+    self.browser_platform = self.browser.platform
+    self._exceptions = Annotator(False)
+    self.repetition = repetition
+    self.is_warmup = is_warmup
+    self.temperature = temperature
+    self.name = name
+    self.probes = []
+    self.timing = Timing()
+    self.is_success = True
+    self.index = index
+    self.story = story
+    self.out_dir = (
+        browser_session.root_dir / safe_filename(self.browser.unique_name) /
+        "stories" / name / f"repetition={self.repetition}" / self.temperature)
+    self.group_dir = self.out_dir.parent
+    self.did_setup = False
+    self.did_run = False
+    self.did_teardown = False
+    self.did_teardown_browser = False
+    self.is_dry_run: Optional[bool] = None
+
+  def validate_env(self, env: HostEnvironment):
+    pass
+
+  def setup(self, is_dry_run: bool) -> None:
+    assert self.is_dry_run is None
+    self.is_dry_run = is_dry_run
+    assert not self.did_setup
+    self.did_setup = True
+
+  def actions(self,
+              name: str,
+              verbose: bool = False,
+              measure: bool = True) -> Actions:
+    return Actions(name, self, verbose=verbose, measure=measure)
+
+  @property
+  def exceptions(self) -> Annotator:
+    return self._exceptions
+
+  def max_end_datetime(self) -> dt.datetime:
+    return dt.datetime.max
+
+  def run(self, is_dry_run: bool) -> None:
+    assert self.is_dry_run is is_dry_run
+    assert not self.did_run
+    self.did_run = True
+
+  def teardown(self, is_dry_run: bool) -> None:
+    assert self.is_dry_run is is_dry_run
+    assert not self.did_teardown
+    self.did_teardown = True
+
+  def _teardown_browser(self, is_dry_run: bool) -> None:
+    assert self.is_dry_run is is_dry_run
+    assert not self.did_teardown_browser
+    self.did_teardown_browser = True
+    self.browser.quit()
+
+  def __repr__(self):
+    return f"MockRun({self.name}, id={hex(id(self))})"
+
+  def __str__(self):
+    return self.name
+
+
+class MockPlatform:
+
+  def __init__(self, name) -> None:
+    self.name = name
+
+  def __str__(self):
+    return self.name
+
+
+class MockRunner:
+
+  def __init__(self) -> None:
+    self.benchmark = MockBenchmark(stories=[MockStory("mock_story")])
+    self.runs = tuple()
+    self.platform = MockPlatform("test-platform")
+    self.repetitions = 1
+    self.create_symlinks = True
+    self.probes = []
+    self.browsers = []
+    self.out_dir = pathlib.Path("results/out")
+    self.timing = Timing()
+    self.env = HostEnvironment(self.platform, self.out_dir, self.browsers,
+                               self.probes, self.repetitions)
+
+
+class MockNetwork:
+  pass
+
+
+class MockProbe(Probe):
+  NAME = "test-probe"
+
+  def __init__(self, test_data: Any = ()) -> None:
+    super().__init__()
+    self.test_data = test_data
+
+  @property
+  def result_path_name(self) -> str:
+    return f"{self.name}.json"
+
+  def get_context(self, run: Run):
+    return MockProbeContext(self, run)
+
+
+class MockProbeContext(ProbeContext):
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    with self.result_path.open("w") as f:
+      json.dump(self.probe.test_data, f)
+    return LocalProbeResult(json=(self.result_path,))
+
+
+class BaseRunnerTestCase(BaseCrossbenchTestCase, metaclass=abc.ABCMeta):
+
+  def setUp(self):
+    super().setUp()
+    self.out_dir = pathlib.Path("/testing/out_dir")
+    self.out_dir.parent.mkdir(exist_ok=False, parents=True)
+    self.stories = [MockStory("story_1"), MockStory("story_2")]
+    self.benchmark = MockBenchmark(self.stories)
+    self.browsers: List[Browser] = [
+        MockChromeDev("chrome-dev", settings=Settings(platform=self.platform)),
+        MockFirefox(
+            "firefox-stable", settings=Settings(platform=self.platform))
+    ]
+
+  def default_runner(self,
+                     browsers: Optional[List[Browser]] = None,
+                     throw: bool = True) -> Runner:
+    if browsers is None:
+      browsers = self.browsers
+    return Runner(
+        self.out_dir,
+        browsers,
+        self.benchmark,
+        platform=self.platform,
+        throw=throw)
diff --git a/tests/crossbench/runner/test_run.py b/tests/crossbench/runner/test_run.py
new file mode 100644
index 0000000..d6ca5f8
--- /dev/null
+++ b/tests/crossbench/runner/test_run.py
@@ -0,0 +1,24 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import datetime as dt
+
+from crossbench.probes.screenshot import ScreenshotProbe
+from crossbench.runner.run import Run
+from tests.crossbench.mock_helper import MockStory
+from tests.crossbench.runner.groups.base import BaseRunGroupTestCase
+from tests.crossbench.runner.helper import MockProbe
+
+
+class RunTestCase(BaseRunGroupTestCase):
+
+  def test_find_probe_context(self):
+    self.runner.attach_probe(MockProbe())
+    session = self.default_session()
+    run = Run(self.runner, session, MockStory("mock story"), 1, False,
+              "1_default", 1, "test run", dt.timedelta(minutes=1), True)
+    session.set_ready()
+    with session.open():
+      self.assertIsNotNone(run.find_probe_context(MockProbe))
+      self.assertIsNone(run.find_probe_context(ScreenshotProbe))
diff --git a/tests/crossbench/runner/test_runner.py b/tests/crossbench/runner/test_runner.py
new file mode 100644
index 0000000..a8e238e
--- /dev/null
+++ b/tests/crossbench/runner/test_runner.py
@@ -0,0 +1,457 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import json
+import pathlib
+import unittest
+from unittest import mock
+
+from crossbench import compat
+from crossbench.browsers.browser import Browser
+from crossbench.env import HostEnvironment
+from crossbench.flags.base import Flags
+from crossbench.helper.state import UnexpectedStateError
+from crossbench.probes import all as all_probes
+from crossbench.probes.probe import ProbeIncompatibleBrowser
+from crossbench.runner.groups.session import BrowserSessionRunGroup
+from crossbench.runner.groups.thread import RunThreadGroup
+from crossbench.runner.runner import Runner, ThreadMode
+from tests import test_helper
+from tests.crossbench.mock_browser import MockChromeDev
+from tests.crossbench.mock_helper import MockBenchmark
+from tests.crossbench.runner.helper import (BaseRunnerTestCase, MockBrowser,
+                                            MockPlatform, MockProbe,
+                                            MockProbeContext, MockRun,
+                                            MockRunner)
+
+
+# Skip strict type checks for better mocking
+# pytype: disable=wrong-arg-types
+class TestThreadModeTestCase(unittest.TestCase):
+  # pylint has some issues with enums.
+  # pylint: disable=no-member
+
+  def create_session(self, browser, index) -> BrowserSessionRunGroup:
+    return BrowserSessionRunGroup(
+        self.env,
+        self.probes,
+        browser,
+        Flags(),
+        index,
+        self.root_dir,
+        create_symlinks=True,
+        throw=True)
+
+  def setUp(self) -> None:
+    self.platform_a = MockPlatform("platform a")
+    self.platform_b = MockPlatform("platform b")
+    self.browser_a_1 = MockBrowser("mock browser a 1", self.platform_a)
+    self.browser_a_2 = MockBrowser("mock browser b 1", self.platform_a)
+    self.browser_b_1 = MockBrowser("mock browser b 1", self.platform_b)
+    self.browser_b_2 = MockBrowser("mock browser b 2", self.platform_b)
+    self.runner = MockRunner()
+    self.root_dir = pathlib.Path()
+    self.env = self.runner.env
+    self.probes = []
+    self.runs = (
+        MockRun(self.runner, self.create_session(self.browser_a_1, 1), "run 1"),
+        MockRun(self.runner, self.create_session(self.browser_a_2, 2), "run 2"),
+        MockRun(self.runner, self.create_session(self.browser_a_1, 3), "run 3"),
+        MockRun(self.runner, self.create_session(self.browser_a_2, 4), "run 4"),
+        MockRun(self.runner, self.create_session(self.browser_b_1, 5), "run 5"),
+        MockRun(self.runner, self.create_session(self.browser_b_2, 6), "run 6"),
+        MockRun(self.runner, self.create_session(self.browser_b_1, 7), "run 7"),
+        MockRun(self.runner, self.create_session(self.browser_b_2, 8), "run 8"),
+    )
+    self.runner.runs = self.runs
+
+  def test_default_runs(self):
+    session_ids = {run.browser_session.index for run in self.runs}
+    self.assertEqual(len(session_ids), len(self.runs))
+
+  def test_group_none(self):
+    groups = ThreadMode.NONE.group(self.runs)
+    self.assertEqual(len(groups), 1)
+    self.assertTupleEqual(groups[0].runs, self.runs)
+    self.assertEqual(groups[0].index, 0)
+
+  def test_group_platform(self):
+    groups = ThreadMode.PLATFORM.group(self.runs)
+    self.assertEqual(len(groups), 2)
+    group_a, group_b = groups
+    self.assertTupleEqual(group_a.runs, self.runs[:4])
+    self.assertTupleEqual(group_b.runs, self.runs[4:])
+    self.assertEqual(group_a.index, 0)
+    self.assertEqual(group_b.index, 1)
+
+  def test_group_browser(self):
+    groups = ThreadMode.BROWSER.group(self.runs)
+    self.assertEqual(len(groups), 4)
+    self.assertTupleEqual(groups[0].runs, (self.runs[0], self.runs[2]))
+    self.assertTupleEqual(groups[1].runs, (self.runs[1], self.runs[3]))
+    self.assertTupleEqual(groups[2].runs, (self.runs[4], self.runs[6]))
+    self.assertTupleEqual(groups[3].runs, (self.runs[5], self.runs[7]))
+    for index, group in enumerate(groups):
+      self.assertEqual(group.index, index)
+
+  def test_group_session(self):
+    groups = ThreadMode.SESSION.group(self.runs)
+    self.assertEqual(len(groups), len(self.runs))
+    for group, run in zip(groups, self.runs):
+      self.assertTupleEqual(group.runs, (run,))
+    for index, group in enumerate(groups):
+      self.assertEqual(group.index, index)
+
+  def test_group_session_2(self):
+    session_1 = self.create_session(self.browser_a_1, 1)
+    session_2 = self.create_session(self.browser_a_2, 2)
+    runs = (
+        MockRun(self.runner, session_1, "story 1"),
+        MockRun(self.runner, session_2, "story 2"),
+        MockRun(self.runner, session_1, "story 3"),
+        MockRun(self.runner, session_2, "story 4"),
+    )
+    groups = ThreadMode.SESSION.group(runs)
+    group_a, group_b = groups
+    self.assertTupleEqual(group_a.runs, (runs[0], runs[2]))
+    self.assertTupleEqual(group_b.runs, (runs[1], runs[3]))
+    for index, group in enumerate(groups):
+      self.assertEqual(group.index, index)
+
+
+class RunnerTestCase(BaseRunnerTestCase):
+
+  def test_default_instance(self):
+    runner = self.default_runner()
+    self.assertSequenceEqual(self.stories, runner.stories)
+    self.assertSequenceEqual(self.browsers, runner.browsers)
+    self.assertEqual(runner.repetitions, 1)
+    self.assertEqual(len(runner.platforms), 1)
+    self.assertTrue(runner.exceptions.is_success)
+    default_probes = list(runner.default_probes)
+    self.assertListEqual(list(runner.probes), default_probes)
+    self.assertEqual(len(default_probes), len(all_probes.INTERNAL_PROBES))
+    self.assertEqual(len(runner.runs), 0)
+    # no runs => is_success == false
+    self.assertFalse(runner.is_success)
+
+  def test_dry_run(self):
+    self.test_run(is_dry_run=True)
+
+  def test_run(self, is_dry_run=False):
+    runner = self.default_runner()
+
+    runner.run(is_dry_run)
+    # Don't reuse the Runner:
+    with self.assertRaises(UnexpectedStateError):
+      runner.run(is_dry_run)
+
+    self.assertEqual(len(runner.runs), 4)
+    self.assertTrue(runner.is_success)
+    for run in runner.runs:
+      self.assertTrue(run.is_success)
+      self.assertEqual(len(run.results), len(all_probes.INTERNAL_PROBES))
+      for probe in runner.probes:
+        self.assertIn(probe, run.results)
+
+  def test_run_mock_probe(self):
+    runner = self.default_runner()
+    probe = MockProbe("custom_probe_data")
+    runner.attach_probe(probe)
+    self.assertIn(probe, runner.probes)
+    for browser in runner.browsers:
+      self.assertIn(probe, browser.probes)
+
+    runner.run()
+    self.assertTrue(runner.is_success)
+    for run in runner.runs:
+      results = run.results[probe]
+      with results.json.open() as f:
+        probe_data = json.load(f)
+        self.assertEqual(probe_data, "custom_probe_data")
+      browser_dir = runner.out_dir / run.browser.unique_name
+      # Pyfakefs is having some issues with relative symlinks, thus we're
+      # manually combining the paths.
+      runs_dir = browser_dir / "runs"
+      run_symlink = runs_dir / compat.readlink(runs_dir / str(run.index))
+      self.assertEqual(run_symlink.resolve(), run.out_dir)
+    for browser in runner.browsers:
+      runs_symlinks = list(
+          (runner.out_dir / browser.unique_name / "runs").iterdir())
+      self.assertEqual(len(runs_symlinks), 2)
+
+
+  def test_attach_probe_twice(self):
+    runner = self.default_runner()
+    probe = MockProbe("custom_probe_data")
+    runner.attach_probe(probe)
+    # Cannot attach same probe twice.
+    with self.assertRaises(ValueError) as cm:
+      runner.attach_probe(probe)
+    self.assertIn("twice", str(cm.exception))
+    self.assertIn(probe, runner.probes)
+    self.assertNotIn(probe, runner.default_probes)
+
+  def test_attach_incompatible_probe(self):
+    runner = self.default_runner()
+    probe = MockProbe("custom_probe_data")
+
+    def mock_validate_browser(env: HostEnvironment, browser: Browser):
+      del env
+      nonlocal probe
+      raise ProbeIncompatibleBrowser(probe, browser, "mock invalid")
+
+    probe.validate_browser = mock_validate_browser
+    with self.assertRaises(ProbeIncompatibleBrowser) as cm:
+      runner.attach_probe(probe)
+    self.assertIn("mock invalid", str(cm.exception))
+    # matching_browser_only = True silence the error
+    runner.attach_probe(probe, matching_browser_only=True)
+    # No browser matches => probe is not available
+    self.assertNotIn(probe, runner.probes)
+    self.assertNotIn(probe, runner.default_probes)
+    for browser in self.browsers:
+      self.assertNotIn(probe, browser.probes)
+
+  def test_attach_partially_incompatible_probe(self):
+    runner = self.default_runner()
+    probe = MockProbe("custom_probe_data")
+    compatible_browser = self.browsers[1]
+
+    def mock_validate_browser(env: HostEnvironment, browser: Browser):
+      del env
+      nonlocal probe
+      nonlocal compatible_browser
+      if browser != compatible_browser:
+        raise ProbeIncompatibleBrowser(probe, browser, "mock invalid")
+
+    # Attaching incompatible probes raises errors by default.
+    probe.validate_browser = mock_validate_browser
+    with self.assertRaises(ProbeIncompatibleBrowser) as cm:
+      runner.attach_probe(probe)
+    self.assertIn("mock invalid", str(cm.exception))
+    # matching_browser_only = True silences the error
+    runner.attach_probe(probe, matching_browser_only=True)
+    self.assertIn(probe, runner.probes)
+    self.assertNotIn(probe, runner.default_probes)
+    for browser in self.browsers:
+      if browser == compatible_browser:
+        self.assertIn(probe, browser.probes)
+      else:
+        self.assertNotIn(probe, browser.probes)
+
+
+class CustomException(Exception):
+  pass
+
+
+def run_setup_fail(is_dry_run):
+  raise CustomException()
+
+
+class RunThreadGroupTestCase(BaseRunnerTestCase):
+
+  def tearDown(self) -> None:
+    for browser in self.browsers:
+      self.assertFalse(browser.is_running)
+    return super().tearDown()
+
+  def test_create_no_runs(self):
+    with self.assertRaises(AssertionError):
+      RunThreadGroup([])
+
+  def test_different_runners(self):
+    runs_a = list(self.default_runner().get_runs())
+    self.out_dir = self.out_dir.parent / "second_out_dir"
+    runner_b = Runner(
+        self.out_dir, [MockChromeDev("chrome-dev-2")],
+        self.benchmark,
+        platform=self.platform,
+        throw=True)
+    runs_b = list(runner_b.get_runs())
+    self.assertNotEqual(runs_a[0].runner, runs_b[0].runner)
+    with self.assertRaises(AssertionError) as cm:
+      RunThreadGroup(runs_a + runs_b)
+    self.assertIn("same Runner", str(cm.exception))
+
+  def test_simple_runs(self):
+    runner = self.default_runner()
+    runs = tuple(runner.get_runs())
+    thread = RunThreadGroup(runs)
+    self.assertEqual(thread.index, 0)
+    self.assertEqual(thread.runner, runner)
+    self.assertSequenceEqual(thread.runs, runs)
+    self.assertTrue(thread.is_success)
+
+    run_count = 0
+
+    def test_run(run_method):
+      nonlocal run_count
+      run_count += 1
+      run_method(is_dry_run=False)
+
+    for run in runs:
+      run.run = (  # pylint: disable=unnecessary-direct-lambda-call
+          lambda run_method: lambda is_dry_run: test_run(run_method))(
+              run.run)
+
+    thread.run()
+
+    self.assertTrue(thread.is_success)
+    self.assertSequenceEqual(thread.runs, runs)
+    self.assertEqual(run_count, 4)
+
+  def test_run_fail_run_probe_get_context(self):
+    # 2 runs, same browser different stories
+    runner = self.default_runner(browsers=[self.browsers[1]], throw=False)
+    probe = MockProbe("custom_probe_data")
+    runner.attach_probe(probe)
+    self.assertTrue(probe.is_attached)
+    runs = tuple(runner.get_runs())
+    thread = RunThreadGroup(runs)
+    failing_session, successful_session = thread.browser_sessions
+    failing_run, successful_run = runs
+
+    setup_fail_count = 0
+
+    def mock_get_context_fail(run):
+      if run == successful_run:
+        return MockProbeContext(probe, run)
+      nonlocal setup_fail_count
+      setup_fail_count += 1
+      raise CustomException()
+
+    probe.get_context = mock_get_context_fail
+
+    self.assertEqual(setup_fail_count, 0)
+    thread.run()
+    self.assertEqual(setup_fail_count, 1)
+
+    self.assertTrue(successful_session.is_success)
+    self.assertTrue(successful_run.is_success)
+
+    # Errors are propagated up:
+    for exceptions_holder in (runner, thread, failing_session, failing_run):
+      self.assertFalse(exceptions_holder.is_success)
+      exceptions = exceptions_holder.exceptions
+      self.assertEqual(len(exceptions), 1)
+      exception_entry = exceptions[0]
+      self.assertIsInstance(exception_entry.exception, CustomException)
+
+  def test_run_fail_run_probe_setup(self):
+    # 2 runs, same browser different stories
+    runner = self.default_runner(browsers=[self.browsers[1]], throw=False)
+    probe = MockProbe("custom_probe_data")
+    runner.attach_probe(probe)
+    self.assertTrue(probe.is_attached)
+    runs = tuple(runner.get_runs())
+    thread = RunThreadGroup(runs)
+    failing_session, successful_session = thread.browser_sessions
+    failing_run, successful_run = runs
+
+    setup_fail_count = 0
+
+    def mock_setup_fail() -> None:
+      nonlocal setup_fail_count
+      setup_fail_count += 1
+      raise CustomException()
+
+    def mock_get_context_fail(run):
+      context = MockProbeContext(probe, run)
+      if run == failing_run:
+        context.setup = mock_setup_fail
+      return context
+
+    probe.get_context = mock_get_context_fail
+
+    self.assertEqual(setup_fail_count, 0)
+    thread.run()
+    self.assertEqual(setup_fail_count, 1)
+
+    self.assertTrue(successful_session.is_success)
+    self.assertTrue(successful_run.is_success)
+
+    # Errors are propagated up:
+    for exceptions_holder in (runner, thread, failing_session, failing_run):
+      self.assertFalse(exceptions_holder.is_success)
+      exceptions = exceptions_holder.exceptions
+      self.assertEqual(len(exceptions), 1)
+      exception_entry = exceptions[0]
+      self.assertIsInstance(exception_entry.exception, CustomException)
+
+  def test_run_fail_one_browser_setup(self):
+    # 2 runs, same story, different browsers
+    benchmark = MockBenchmark(stories=[self.stories[0]])
+    runner = Runner(
+        self.out_dir, self.browsers, benchmark, platform=self.platform)
+    runs = tuple(runner.get_runs())
+    thread = RunThreadGroup(runs)
+    failing_session, successful_session = thread.browser_sessions
+    failing_run, successful_run = runs
+    self.assertNotEqual(failing_run.browser, successful_run.browser)
+
+    setup_fail_count = 0
+
+    def mock_start_fail(session: BrowserSessionRunGroup) -> None:
+      del session
+      nonlocal setup_fail_count
+      setup_fail_count += 1
+      raise CustomException()
+
+    failing_run.browser.start = mock_start_fail
+
+    self.assertEqual(setup_fail_count, 0)
+    thread.run()
+    self.assertEqual(setup_fail_count, 1)
+
+    self.assertTrue(successful_session.is_success)
+    self.assertTrue(successful_run.is_success)
+
+    # browser startup failures should also propagate down to all runs.
+    for exceptions_holder in (runner, thread, failing_session, failing_run):
+      self.assertFalse(exceptions_holder.is_success)
+      exceptions = exceptions_holder.exceptions
+      self.assertEqual(len(exceptions), 1)
+      exception_entry = exceptions[0]
+      self.assertIsInstance(exception_entry.exception, CustomException)
+
+  def test_run_fail_run(self):
+    # 4 runs = (2 browser) x (2 stories)
+    runner = self.default_runner(throw=False)
+    runs = tuple(runner.get_runs())
+    thread = RunThreadGroup(runs)
+    failing_run = runs[0]
+    failing_session = failing_run.browser_session
+
+    run_fail_count = 0
+
+    def mock_run_story_fail():
+      nonlocal run_fail_count
+      run_fail_count += 1
+      raise CustomException()
+
+    with mock.patch.object(failing_run, "_run_story", mock_run_story_fail):
+      self.assertEqual(run_fail_count, 0)
+      thread.run()
+      self.assertEqual(run_fail_count, 1)
+
+      for session in thread.browser_sessions:
+        if session != failing_run.browser_session:
+          self.assertTrue(session.is_success)
+      for run in runs:
+        if run != failing_run:
+          self.assertTrue(run.is_success)
+
+      # Errors are propagate up:
+      for exceptions_holder in (runner, thread, failing_session, failing_run):
+        self.assertFalse(exceptions_holder.is_success)
+        exceptions = exceptions_holder.exceptions
+        self.assertEqual(len(exceptions), 1)
+        exception_entry = exceptions[0]
+        self.assertIsInstance(exception_entry.exception, CustomException)
+
+# pytype: enable=wrong-arg-types
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/test_timing.py b/tests/crossbench/runner/test_timing.py
new file mode 100644
index 0000000..739f32f
--- /dev/null
+++ b/tests/crossbench/runner/test_timing.py
@@ -0,0 +1,140 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import datetime as dt
+import unittest
+
+from crossbench.runner.timing import SAFE_MAX_TIMEOUT_TIMEDELTA, Timing
+from tests import test_helper
+
+
+class TimingTestCase(unittest.TestCase):
+
+  def test_default_instance(self):
+    t = Timing()
+    self.assertEqual(t.unit, dt.timedelta(seconds=1))
+    self.assertEqual(t.timeout_unit, dt.timedelta())
+    self.assertEqual(t.timedelta(10), dt.timedelta(seconds=10))
+    self.assertEqual(t.units(1), 1)
+    self.assertEqual(t.units(dt.timedelta(seconds=1)), 1)
+
+  def test_to_json(self):
+    t = Timing()
+    self.assertDictEqual(t.to_json(), {
+        "coolDownTime": 1.0,
+        "runTimeout": 0.0,
+        "timeoutUnit": 0.0,
+        "unit": 1.0
+    })
+    t = Timing(
+        unit=dt.timedelta(seconds=10), timeout_unit=dt.timedelta(seconds=11))
+    self.assertDictEqual(t.to_json(), {
+        "coolDownTime": 1.0,
+        "runTimeout": 0.0,
+        "timeoutUnit": 11.0,
+        "unit": 10.0
+    })
+
+  def test_default_instance_slowdown(self):
+    t = Timing(
+        unit=dt.timedelta(seconds=10), timeout_unit=dt.timedelta(seconds=11))
+    self.assertEqual(t.unit, dt.timedelta(seconds=10))
+    self.assertEqual(t.timeout_unit, dt.timedelta(seconds=11))
+    self.assertEqual(t.timedelta(10), dt.timedelta(seconds=100))
+    self.assertEqual(t.units(100), 10)
+    self.assertEqual(t.units(dt.timedelta(seconds=100)), 10)
+    self.assertEqual(t.timeout_timedelta(10), dt.timedelta(seconds=110))
+
+  def test_default_instance_speedup(self):
+    t = Timing(unit=dt.timedelta(seconds=0.1))
+    self.assertEqual(t.unit, dt.timedelta(seconds=0.1))
+    self.assertEqual(t.timedelta(10), dt.timedelta(seconds=1))
+    self.assertEqual(t.units(1), 10)
+    self.assertEqual(t.units(dt.timedelta(seconds=1)), 10)
+
+  def test_invalid_params(self):
+    with self.assertRaises(ValueError) as cm:
+      _ = Timing(cool_down_time=dt.timedelta(seconds=-1))
+    self.assertIn("Timing.cool_down_time", str(cm.exception))
+
+    with self.assertRaises(ValueError) as cm:
+      _ = Timing(unit=dt.timedelta(seconds=-1))
+    self.assertIn("Timing.unit", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      _ = Timing(unit=dt.timedelta())
+    self.assertIn("Timing.unit", str(cm.exception))
+
+    with self.assertRaises(ValueError) as cm:
+      _ = Timing(run_timeout=dt.timedelta(seconds=-1))
+    self.assertIn("Timing.run_timeout", str(cm.exception))
+
+  def test_to_units(self):
+    t = Timing()
+    self.assertEqual(t.units(100), 100)
+    self.assertEqual(t.units(dt.timedelta(minutes=1.5)), 90)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+    t = Timing(unit=dt.timedelta(seconds=10))
+    self.assertEqual(t.units(100), 10)
+    self.assertEqual(t.units(dt.timedelta(minutes=1.5)), 9)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+    t = Timing(unit=dt.timedelta(seconds=0.1))
+    self.assertEqual(t.units(100), 1000)
+    self.assertEqual(t.units(dt.timedelta(minutes=1.5)), 900)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+  def test_to_timedelta(self):
+    t = Timing()
+    self.assertEqual(t.timedelta(12).total_seconds(), 12)
+    self.assertEqual(t.timedelta(dt.timedelta(minutes=1.5)).total_seconds(), 90)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+    t = Timing(unit=dt.timedelta(seconds=10))
+    self.assertEqual(t.timedelta(12).total_seconds(), 120)
+    self.assertEqual(
+        t.timedelta(dt.timedelta(minutes=1.5)).total_seconds(), 900)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+    t = Timing(unit=dt.timedelta(seconds=0.5))
+    self.assertEqual(t.timedelta(12).total_seconds(), 6)
+    self.assertEqual(t.timedelta(dt.timedelta(minutes=1.5)).total_seconds(), 45)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+  def test_timeout_timing(self):
+    t = Timing(
+        unit=dt.timedelta(seconds=1), timeout_unit=dt.timedelta(seconds=10))
+    self.assertEqual(t.timedelta(12).total_seconds(), 12)
+    self.assertEqual(t.timeout_timedelta(12).total_seconds(), 120)
+
+  def test_timeout_timing_invalid(self):
+    with self.assertRaises(ValueError):
+      _ = Timing(
+          unit=dt.timedelta(seconds=1), timeout_unit=dt.timedelta(seconds=0.1))
+    with self.assertRaises(ValueError):
+      _ = Timing(
+          unit=dt.timedelta(seconds=1), timeout_unit=dt.timedelta(seconds=-1))
+
+  def test_no_timeout(self):
+    self.assertFalse(Timing().has_no_timeout)
+    t = Timing(timeout_unit=dt.timedelta.max)
+    self.assertTrue(t.has_no_timeout)
+    self.assertEqual(t.timedelta(12).total_seconds(), 12)
+    self.assertEqual(t.timeout_timedelta(0.000001), SAFE_MAX_TIMEOUT_TIMEDELTA)
+    self.assertEqual(t.timeout_timedelta(12), SAFE_MAX_TIMEOUT_TIMEDELTA)
+
+  def test_timeout_overflow(self):
+    t = Timing(timeout_unit=dt.timedelta(days=1000))
+    self.assertEqual(t.timeout_timedelta(12), SAFE_MAX_TIMEOUT_TIMEDELTA)
+    self.assertEqual(t.timeout_timedelta(1500), SAFE_MAX_TIMEOUT_TIMEDELTA)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_config.py b/tests/crossbench/test_config.py
new file mode 100644
index 0000000..4c58507
--- /dev/null
+++ b/tests/crossbench/test_config.py
@@ -0,0 +1,652 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import enum
+import json
+import pathlib
+import unittest
+from typing import Any, Dict, List, Optional
+
+from immutabledict import immutabledict
+
+from crossbench import compat
+from crossbench.config import ConfigEnum, ConfigObject, ConfigParser
+from crossbench.parse import NumberParser, ObjectParser
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+@enum.unique
+class GenericEnum(compat.StrEnumWithHelp):
+  A = ("a", "A Help")
+  B = ("b", "B Help")
+  C = ("c", "C Help")
+
+
+@enum.unique
+class CustomConfigEnum(ConfigEnum):
+  A = ("a", "A Help")
+  B = ("b", "B Help")
+  C = ("c", "C Help")
+
+class CustomValueEnum(enum.Enum):
+
+  @classmethod
+  def _missing_(cls, value: Any) -> Optional[CustomValueEnum]:
+    if value is True:
+      return CustomValueEnum.A_OR_TRUE
+    if value is False:
+      return CustomValueEnum.B_OR_FALSE
+    return super()._missing_(value)
+
+  DEFAULT = "default"
+  A_OR_TRUE = "a"
+  B_OR_FALSE = "b"
+
+
+@dataclasses.dataclass(frozen=True)
+class CustomNestedConfigObject(ConfigObject):
+  name: str
+
+  @classmethod
+  def parse_str(cls, value: str) -> CustomNestedConfigObject:
+    if ":" in value:
+      raise ValueError("Invalid Config")
+    if not value:
+      raise ValueError("Got empty input")
+    return cls(name=value)
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any]) -> CustomNestedConfigObject:
+    return cls.config_parser().parse(config)
+
+  @classmethod
+  def config_parser(cls) -> ConfigParser[CustomNestedConfigObject]:
+    parser = ConfigParser("CustomNestedConfigObject parser", cls)
+    parser.add_argument("name", type=str, required=True)
+    return parser
+
+
+@dataclasses.dataclass(frozen=True)
+class CustomConfigObject(ConfigObject):
+
+  name: str
+  array: Optional[List[str]] = None
+  integer: Optional[int] = None
+  nested: Optional[CustomNestedConfigObject] = None
+  choices: str = ""
+  generic_enum: GenericEnum = GenericEnum.A
+  config_enum: CustomConfigEnum = CustomConfigEnum.A
+  custom_value_enum: CustomValueEnum = CustomValueEnum.DEFAULT
+  depending_nested: Optional[Dict[str, Any]] = None
+  depending_many: Optional[Dict[str, Any]] = None
+
+  @classmethod
+  def default(cls) -> CustomConfigObject:
+    return cls("default")
+
+  @classmethod
+  def parse_str(cls, value: str) -> CustomConfigObject:
+    if ":" in value:
+      raise ValueError("Invalid Config")
+    if not value:
+      raise ValueError("Got empty input")
+    return cls(name=value)
+
+  @classmethod
+  def parse_depending_nested(
+      cls, value: Optional[str],
+      nested: CustomNestedConfigObject) -> Optional[Dict]:
+    if not value:
+      return None
+    return {
+        "value": ObjectParser.non_empty_str(value),
+        "nested": ObjectParser.not_none(nested, "nested")
+    }
+
+  @classmethod
+  def parse_depending_many(cls, value: Optional[str], array: List[Any],
+                           integer: int,
+                           nested: CustomNestedConfigObject) -> Optional[Dict]:
+    if not value:
+      return None
+    return {
+        "value": ObjectParser.non_empty_str(value),
+        "nested": ObjectParser.not_none(nested, "nested"),
+        "array": ObjectParser.not_none(array, "array"),
+        "integer": NumberParser.positive_int(integer, "integer"),
+    }
+
+
+  @classmethod
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> CustomConfigObject:
+    return cls.config_parser().parse(config, **kwargs)
+
+  @classmethod
+  def config_parser(cls) -> ConfigParser[CustomConfigObject]:
+    parser = cls.base_config_parser()
+    parser.add_argument(
+        "name", aliases=("name_alias", "name_alias2"), type=str, required=True)
+    parser.add_argument("array", type=list)
+    parser.add_argument("integer", type=NumberParser.positive_int)
+    parser.add_argument("nested", type=CustomNestedConfigObject)
+    parser.add_argument("generic_enum", type=GenericEnum)
+    parser.add_argument("config_enum", type=CustomConfigEnum)
+    parser.add_argument(
+        "custom_value_enum",
+        type=CustomValueEnum,
+        default=CustomValueEnum.DEFAULT)
+    parser.add_argument("choices", type=str, choices=("x", "y", "z"))
+    parser.add_argument(
+        "depending_nested",
+        type=CustomConfigObject.parse_depending_nested,
+        depends_on=("nested",))
+    parser.add_argument(
+        "depending_many",
+        type=CustomConfigObject.parse_depending_many,
+        depends_on=("array", "integer", "nested"))
+    return parser
+
+  @classmethod
+  def base_config_parser(cls) -> ConfigParser[CustomConfigObject]:
+    return ConfigParser("CustomConfigObject parser", cls)
+
+
+class CustomConfigObjectStrict(CustomConfigObject):
+
+  @classmethod
+  def base_config_parser(cls) -> ConfigParser[CustomConfigObjectStrict]:
+    return ConfigParser(
+        "CustomConfigObjectStrict parser", cls, allow_unused_config_data=False)
+
+
+class CustomConfigObjectWithDefault(CustomConfigObject):
+
+  @classmethod
+  def base_config_parser(cls) -> ConfigParser[CustomConfigObjectWithDefault]:
+    return ConfigParser("CustomConfigObject parser", cls, default=cls.default())
+
+
+class CustomConfigObjectToArgumentValue(CustomConfigObject):
+
+  def to_argument_value(self):
+    return (self.name, self.array, self.integer)
+
+
+class ConfigParserTestCase(unittest.TestCase):
+
+  def setUp(self):
+    super().setUp()
+    self.parser = ConfigParser("ConfigParserTestCase parser",
+                               CustomConfigObject)
+
+  def test_invalid_type(self):
+    with self.assertRaises(TypeError):
+      self.parser.add_argument("foo", type="something")  # pytype: disable=wrong-arg-types
+
+  def test_invalid_alias(self):
+    with self.assertRaises(ValueError):
+      self.parser.add_argument("foo", aliases=("foo",), type=str)
+    with self.assertRaises(ValueError):
+      self.parser.add_argument(
+          "foo", aliases=("foo_alias", "foo_alias"), type=str)
+
+  def test_duplicate(self):
+    self.parser.add_argument("foo", type=str)
+    with self.assertRaises(ValueError):
+      self.parser.add_argument("foo", type=str)
+    with self.assertRaises(ValueError):
+      self.parser.add_argument("foo2", aliases=("foo",), type=str)
+
+  def test_invalid_string_depends_on(self):
+    with self.assertRaises(TypeError):
+      self.parser.add_argument(
+          "custom",
+          type=CustomConfigObject.parse_depending_nested,
+          depends_on="other")  # pytype: disable=wrong-arg-types
+
+  def test_invalid_depends_on_nof_arguments(self):
+    with self.assertRaises(TypeError) as cm:
+      self.parser.add_argument("any", type=lambda x: x, depends_on=("other",))
+    self.assertIn("arguments", str(cm.exception))
+
+  def test_invalid_depends_on(self):
+    with self.assertRaises(ValueError):
+      self.parser.add_argument("any", type=None, depends_on=("other",))
+
+    with self.assertRaises(ValueError):
+      self.parser.add_argument("enum", type=GenericEnum, depends_on=("other",))
+    with self.assertRaises(ValueError):
+      self.parser.add_argument("enum", type=ConfigEnum, depends_on=("other",))
+
+    for primitive_type in (bool, float, int, str):
+      with self.assertRaises(TypeError):
+        self.parser.add_argument(
+            "param", type=primitive_type, depends_on=("other",))
+
+  def test_recursive_depends_on(self):
+    self.parser.add_argument(
+        "x", type=lambda value, y: value + y, depends_on=("y",))
+    self.parser.add_argument(
+        "y", type=lambda value, x: value + x, depends_on=("x",))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      self.parser.parse({"x": 1, "y": 100})
+    self.assertIn("Recursive", str(cm.exception))
+
+  def test_invalid_default_arg(self):
+    with self.assertRaisesRegex(ValueError, "default"):
+      self.parser.add_argument("name_1", type=str, default=None, required=False)
+    with self.assertRaisesRegex(ValueError, "default"):
+      self.parser.add_argument("name_1", type=str, default=None, required=True)
+    with self.assertRaisesRegex(ValueError, "default"):
+      self.parser.add_argument("name_2", type=str, default="", required=True)
+    with self.assertRaisesRegex(ValueError, "default"):
+      self.parser.add_argument("name_3", type=str, default=123, required=False)
+
+  def test_default_str_arg(self):
+    self.parser.add_argument("name_1", type=str, default="", required=False)
+
+  def test_default(self):
+    self.parser.add_argument("name", type=str, required=True)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      self.parser.parse({})
+    self.assertIn("no value", str(cm.exception).lower())
+    parser = ConfigParser(
+        "ConfigParserTestCase parser",
+        CustomConfigObject,
+        default=CustomConfigObject.default())
+    config = parser.parse({})
+    self.assertEqual(config, CustomConfigObject.default())
+
+  def test_invalid_default(self):
+    with self.assertRaises(TypeError) as cm:
+      ConfigParser(  # pytype: disable=wrong-arg-types
+          "ConfigParserTestCase parser",
+          CustomConfigObject,
+          default="something else")
+    self.assertIn("instance", str(cm.exception))
+
+  def test_config_object_to_argument_value(self):
+    result = CustomConfigObjectToArgumentValue.config_parser().parse(
+        {"name": "custom-name"})
+    self.assertIsInstance(result, CustomConfigObjectToArgumentValue)
+    parser = ConfigParser("TestParser", dict)
+    parser.add_argument("data", type=CustomConfigObjectToArgumentValue)
+
+    result = parser.parse({})
+    self.assertDictEqual(result, {"data": None})
+    result = parser.parse({"data": {"name": "a name"}})
+    self.assertDictEqual(result, {"data": ("a name", None, None)})
+    result = parser.parse(
+        {"data": {
+            "name": "a name",
+            "integer": 1,
+            "array": [1, 2]
+        }})
+    self.assertDictEqual(result, {"data": ("a name", [1, 2], 1)})
+
+
+class ConfigObjectTestCase(CrossbenchFakeFsTestCase):
+
+  def test_help(self):
+    help_text = CustomConfigObject.config_parser().help
+    self.assertIn("name", help_text)
+    self.assertIn("array", help_text)
+    self.assertIn("integer", help_text)
+    self.assertIn("nested", help_text)
+    self.assertIn("generic_enum", help_text)
+    self.assertIn("config_enum", help_text)
+    self.assertIn("custom_value_enum", help_text)
+    self.assertIn("choices", help_text)
+    self.assertIn("depending_nested", help_text)
+    self.assertIn("depending_many", help_text)
+
+  def test_value_has_path_prefix(self):
+    for value in ("/foo/bar", "~/foo/bar", "../foo/bar", "..\\foo\\bar",
+                  "./foo/bar", "C:\\foo\\bar", "C:/foo/bar"):
+      with self.subTest(value=value):
+        self.assertTrue(CustomConfigObject.value_has_path_prefix(value))
+    for value in ("foo/bar", "foo:bar", "foo", "{foo:'/foo/bar'}", "http://foo",
+                  "c://", "c://bar", "C:../bar", "..//foo", "..//foo/bar",
+                  "~:bar", "~.bar", "~//df", "foo/~bar", "foo~bar/foo",
+                  "http://someurl.com/~myproject/index.html"):
+      with self.subTest(value=value):
+        self.assertFalse(CustomConfigObject.value_has_path_prefix(value))
+
+  def test_parse_invalid_str(self):
+    for invalid in ("", None, 1, []):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        CustomConfigObject.parse(invalid)
+
+  def test_parse_dict_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse({})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse({"name": "foo", "array": 1})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse({"name": "foo", "name_alias": "foo"})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse({"name": "foo", "array": [], "integer": "a"})
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse_dict({
+          "name": "foo",
+          "array": [],
+          "integer": "a"
+      })
+
+  def test_parse_dict(self):
+    config = CustomConfigObject.parse({"name": "foo"})
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "foo")
+    config = CustomConfigObject.parse({"name": "foo", "array": []})
+    self.assertEqual(config.name, "foo")
+    self.assertListEqual(config.array, [])
+    data = {"name": "foo", "array": [1, 2, 3], "integer": 153}
+    config = CustomConfigObject.parse(dict(data))
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "foo")
+    self.assertListEqual(config.array, [1, 2, 3])
+    self.assertEqual(config.integer, 153)
+    config_2 = CustomConfigObject.parse_dict(dict(data))
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config, config_2)
+
+  def test_load_dict_extra_kwargs(self):
+    config = CustomConfigObject.parse({
+        "name": "foo",
+    }, array=[], integer=123)
+    self.assertEqual(config.name, "foo")
+    self.assertListEqual(config.array, [])
+    self.assertEqual(config.integer, 123)
+
+  def test_load_dict_extra_kwargs_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse({
+          "name": "foo",
+      }, array=123, integer=[])
+    self.assertIn("array", str(cm.exception))
+
+  def test_load_dict_extra_kwargs_duplicate_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse({
+          "name": "foo",
+      }, name="bar")
+    self.assertIn("name", str(cm.exception))
+
+  def test_load_dict_extra_kwargs_duplicate(self):
+    config = CustomConfigObject.parse({
+        "name": "foo",
+    }, name="foo", integer=123)
+    self.assertEqual(config.name, "foo")
+    self.assertEqual(config.integer, 123)
+    config = CustomConfigObject.parse({
+        "name": "foo",
+    }, name=None, integer=999)
+    self.assertEqual(config.name, "foo")
+    self.assertEqual(config.integer, 999)
+
+  def test_load_dict_unused(self):
+    config_data = {"name": "foo", "unused_data": 666}
+    config = CustomConfigObject.parse(config_data)
+    self.assertTrue(config_data)
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "foo")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObjectStrict.parse(config_data)
+    self.assertIn("unused_data", str(cm.exception))
+    self.assertTrue(config_data)
+
+  def test_load_dict_unused_extra_kwargs(self):
+    config_data = {"name": "foo", "unused_data": 666}
+    config = CustomConfigObject.parse(config_data, other_unused=999)
+    self.assertTrue(config_data)
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "foo")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObjectStrict.parse(config_data, other_unused=999)
+    self.assertIn("unused_data", str(cm.exception))
+    self.assertIn("other_unused", str(cm.exception))
+    self.assertTrue(config_data)
+
+  def test_load_dict_default(self):
+    self.assertIsNone(CustomConfigObject.config_parser().default)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse({})
+    self.assertIsNone(CustomConfigObject.config_parser().default,
+                      CustomConfigObjectWithDefault.default())
+    config = CustomConfigObjectWithDefault.parse({})
+    self.assertEqual(config, CustomConfigObjectWithDefault.default())
+
+  def test_parse_dict_alias(self):
+    config = CustomConfigObject.parse({"name_alias": "foo"})
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "foo")
+
+  def test_parse_dict_custom_value_enum(self):
+    config = CustomConfigObject.parse({"name_alias": "foo"})
+    assert isinstance(config, CustomConfigObject)
+    self.assertIs(config.custom_value_enum, CustomValueEnum.DEFAULT)
+    for config_value, result in ((CustomValueEnum.A_OR_TRUE,
+                                  CustomValueEnum.A_OR_TRUE),
+                                 ("a", CustomValueEnum.A_OR_TRUE),
+                                 (True, CustomValueEnum.A_OR_TRUE),
+                                 (CustomValueEnum.B_OR_FALSE,
+                                  CustomValueEnum.B_OR_FALSE),
+                                 ("b", CustomValueEnum.B_OR_FALSE),
+                                 (False, CustomValueEnum.B_OR_FALSE),
+                                 ("default", CustomValueEnum.DEFAULT)):
+      config = CustomConfigObject.parse({
+          "name_alias": "foo",
+          "custom_value_enum": config_value
+      })
+      self.assertIs(config.custom_value_enum, result)
+
+  def test_parse_dict_custom_value_enum_invalid(self):
+    for invalid in (1, 2, {}, "A", "B"):
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        CustomConfigObject.parse({
+            "name_alias": "foo",
+            "custom_value_enum": invalid
+        })
+      self.assertIn(f"{invalid}", str(cm.exception))
+
+  def test_parse_str(self):
+    config = CustomConfigObject.parse("a name")
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "a name")
+
+  def test_parse_path_missing_file(self):
+    path = pathlib.Path("invalid.file")
+    self.assertFalse(path.exists())
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse(path)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse_path(path)
+
+  def test_parse_path_empty_file(self):
+    path = pathlib.Path("test_file.json")
+    self.assertFalse(path.exists())
+    path.touch()
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse(path)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse_path(path)
+
+  def test_parse_path_invalid_json_file(self):
+    path = pathlib.Path("test_file.json")
+    path.write_text("{{", encoding="utf-8")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse(path)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      CustomConfigObject.parse_path(path)
+
+  def test_parse_path_empty_json_object(self):
+    path = pathlib.Path("test_file.json")
+    with path.open("w", encoding="utf-8") as f:
+      json.dump({}, f)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse(path)
+    self.assertIn("non-empty data", str(cm.exception))
+
+  def test_parse_path_invalid_json_array(self):
+    path = pathlib.Path("test_file.json")
+    with path.open("w", encoding="utf-8") as f:
+      json.dump([], f)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse(path)
+    self.assertIn("non-empty data", str(cm.exception))
+
+  def test_parse_path_minimal(self):
+    path = pathlib.Path("test_file.json")
+    with path.open("w", encoding="utf-8") as f:
+      json.dump({"name": "Config Name"}, f)
+    config = CustomConfigObject.parse_path(path)
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "Config Name")
+    self.assertIsNone(config.array)
+    self.assertIsNone(config.integer)
+    self.assertIsNone(config.nested)
+    config_2 = CustomConfigObject.parse(str(path))
+    self.assertEqual(config, config_2)
+
+  TEST_DICT = immutabledict({
+      "name": "Config Name",
+      "array": [1, 3],
+      "integer": 166
+  })
+
+  def test_parse_path_full(self):
+    path = pathlib.Path("test_file.json")
+    with path.open("w", encoding="utf-8") as f:
+      json.dump(dict(self.TEST_DICT), f)
+    config = CustomConfigObject.parse_path(path)
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "Config Name")
+    self.assertListEqual(config.array, [1, 3])
+    self.assertEqual(config.integer, 166)
+    self.assertIsNone(config.nested)
+    config_2 = CustomConfigObject.parse(str(path))
+    self.assertEqual(config, config_2)
+
+  def test_parse_dict_full(self):
+    config = CustomConfigObject.parse_dict(dict(self.TEST_DICT))
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "Config Name")
+    self.assertListEqual(config.array, [1, 3])
+    self.assertEqual(config.integer, 166)
+    self.assertIsNone(config.nested)
+
+  TEST_DICT_NESTED = immutabledict({"name": "a nested name"})
+
+  def test_parse_dict_nested(self):
+    test_dict = dict(self.TEST_DICT)
+    test_dict["nested"] = dict(self.TEST_DICT_NESTED)
+    config = CustomConfigObject.parse_dict(test_dict)
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.name, "Config Name")
+    self.assertListEqual(config.array, [1, 3])
+    self.assertEqual(config.integer, 166)
+    self.assertEqual(config.nested,
+                     CustomNestedConfigObject(name="a nested name"))
+
+  def test_parse_dict_nested_file(self):
+    path = pathlib.Path("nested.json")
+    self.assertFalse(path.exists())
+    with path.open("w", encoding="utf-8") as f:
+      json.dump(dict(self.TEST_DICT_NESTED), f)
+    test_dict = dict(self.TEST_DICT)
+    test_dict["nested"] = str(path)
+    config = CustomConfigObject.parse_dict(test_dict)
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.nested,
+                     CustomNestedConfigObject(name="a nested name"))
+
+  def test_parse_missing_depending(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse({"name": "foo", "depending_nested": "a value"})
+    self.assertIn("depending_nested", str(cm.exception))
+    self.assertIn("Expected nested", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse({
+          "name": "foo",
+          "depending_nested": "a value",
+          "nested": None
+      })
+    self.assertIn("depending_nested", str(cm.exception))
+    self.assertIn("Expected nested", str(cm.exception))
+
+  def test_parse_depending_simple(self):
+    config = CustomConfigObject.parse({
+        "name": "foo",
+        "nested": "nested string value",
+        "depending_nested": "a value"
+    })
+    self.assertDictEqual(config.depending_nested, {
+        "value": "a value",
+        "nested": config.nested
+    })
+
+  def test_parse_generic_enum(self):
+    test_dict = dict(self.TEST_DICT)
+    test_dict["generic_enum"] = "b"
+    config = CustomConfigObject.parse_dict(test_dict)
+    self.assertIs(config.generic_enum, GenericEnum.B)
+    test_dict = dict(self.TEST_DICT)
+    test_dict["generic_enum"] = "c"
+    config = CustomConfigObject.parse_dict(test_dict)
+    self.assertIs(config.generic_enum, GenericEnum.C)
+
+  def test_parse_generic_enum_invalid(self):
+    test_dict = dict(self.TEST_DICT)
+    test_dict["generic_enum"] = "unknown value"
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse_dict(test_dict)
+    error_message = str(cm.exception).lower()
+    self.assertIn("choices are", error_message)
+    self.assertIn("generic_enum", error_message)
+
+  def test_parse_config_enum(self):
+    test_dict = dict(self.TEST_DICT)
+    test_dict["config_enum"] = "b"
+    config = CustomConfigObject.parse_dict(test_dict)
+    self.assertIs(config.config_enum, CustomConfigEnum.B)
+    test_dict = dict(self.TEST_DICT)
+    test_dict["config_enum"] = "c"
+    config = CustomConfigObject.parse_dict(test_dict)
+    self.assertIs(config.config_enum, CustomConfigEnum.C)
+
+  def test_parse_custom_enum_invalid(self):
+    test_dict = dict(self.TEST_DICT)
+    test_dict["config_enum"] = "unknown value"
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      CustomConfigObject.parse_dict(test_dict)
+    error_message = str(cm.exception).lower()
+    self.assertIn("choices are", error_message)
+    self.assertIn("config_enum", error_message)
+
+
+class ConfigEnumTestCase(unittest.TestCase):
+
+  def test_parse_invalid(self):
+    for invalid in ("", None):
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        CustomConfigEnum.parse(invalid)
+      error_message = str(cm.exception)
+      self.assertIn("Choices are", error_message)
+      self.assertIn("CustomConfigEnum", error_message)
+
+  def test_parse(self):
+    for value, result in ((CustomConfigEnum.A,
+                           CustomConfigEnum.A), ("a", CustomConfigEnum.A),
+                          (CustomConfigEnum.B,
+                           CustomConfigEnum.B), ("c", CustomConfigEnum.C)):
+      self.assertIs(CustomConfigEnum.parse(value), result)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_env.py b/tests/crossbench/test_env.py
new file mode 100644
index 0000000..2540cc2
--- /dev/null
+++ b/tests/crossbench/test_env.py
@@ -0,0 +1,341 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import pathlib
+import unittest
+from unittest import mock
+
+import hjson
+
+from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
+                            ValidationError, ValidationMode)
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class HostEnvironmentConfigTestCase(unittest.TestCase):
+
+  def test_combine_bool_value(self):
+    default = HostEnvironmentConfig()
+    self.assertIsNone(default.power_use_battery)
+
+    battery = HostEnvironmentConfig(power_use_battery=True)
+    self.assertTrue(battery.power_use_battery)
+    self.assertTrue(battery.merge(battery).power_use_battery)
+    self.assertTrue(default.merge(battery).power_use_battery)
+    self.assertTrue(battery.merge(default).power_use_battery)
+
+    power = HostEnvironmentConfig(power_use_battery=False)
+    self.assertFalse(power.power_use_battery)
+    self.assertFalse(power.merge(power).power_use_battery)
+    self.assertFalse(default.merge(power).power_use_battery)
+    self.assertFalse(power.merge(default).power_use_battery)
+
+    with self.assertRaises(ValueError):
+      power.merge(battery)
+
+  def test_combine_min_float_value(self):
+    default = HostEnvironmentConfig()
+    self.assertIsNone(default.cpu_min_relative_speed)
+
+    high = HostEnvironmentConfig(cpu_min_relative_speed=1)
+    self.assertEqual(high.cpu_min_relative_speed, 1)
+    self.assertEqual(high.merge(high).cpu_min_relative_speed, 1)
+    self.assertEqual(default.merge(high).cpu_min_relative_speed, 1)
+    self.assertEqual(high.merge(default).cpu_min_relative_speed, 1)
+
+    low = HostEnvironmentConfig(cpu_min_relative_speed=0.5)
+    self.assertEqual(low.cpu_min_relative_speed, 0.5)
+    self.assertEqual(low.merge(low).cpu_min_relative_speed, 0.5)
+    self.assertEqual(default.merge(low).cpu_min_relative_speed, 0.5)
+    self.assertEqual(low.merge(default).cpu_min_relative_speed, 0.5)
+
+    self.assertEqual(high.merge(low).cpu_min_relative_speed, 1)
+
+  def test_combine_max_float_value(self):
+    default = HostEnvironmentConfig()
+    self.assertIsNone(default.cpu_max_usage_percent)
+
+    high = HostEnvironmentConfig(cpu_max_usage_percent=100)
+    self.assertEqual(high.cpu_max_usage_percent, 100)
+    self.assertEqual(high.merge(high).cpu_max_usage_percent, 100)
+    self.assertEqual(default.merge(high).cpu_max_usage_percent, 100)
+    self.assertEqual(high.merge(default).cpu_max_usage_percent, 100)
+
+    low = HostEnvironmentConfig(cpu_max_usage_percent=0)
+    self.assertEqual(low.cpu_max_usage_percent, 0)
+    self.assertEqual(low.merge(low).cpu_max_usage_percent, 0)
+    self.assertEqual(default.merge(low).cpu_max_usage_percent, 0)
+    self.assertEqual(low.merge(default).cpu_max_usage_percent, 0)
+
+    self.assertEqual(high.merge(low).cpu_max_usage_percent, 0)
+
+  def test_parse_example_config_file(self):
+    example_config_file = pathlib.Path(
+        __file__).parent.parent / "config/doc/env.config.hjson"
+    if not example_config_file.exists():
+      raise unittest.SkipTest(f"Test file {example_config_file} does not exist")
+    with example_config_file.open(encoding="utf-8") as f:
+      data = hjson.load(f)
+    HostEnvironmentConfig(**data["env"])
+
+
+class HostEnvironmentTestCase(CrossbenchFakeFsTestCase):
+
+  def setUp(self):
+    super().setUp()
+    self.mock_platform = mock.Mock()
+    self.mock_platform.processes.return_value = []
+    self.out_dir = pathlib.Path("results/current_benchmark_run_results")
+    self.fs.create_file(self.out_dir)
+    self.mock_runner = mock.Mock(
+        platform=self.mock_platform,
+        repetitions=1,
+        probes=[],
+        browsers=[],
+        out_dir=self.out_dir)
+
+  def create_env(self, *args, **kwargs) -> HostEnvironment:
+    return HostEnvironment(self.mock_platform, self.mock_runner.out_dir,
+                           self.mock_runner.browsers, self.mock_runner.probes,
+                           self.mock_runner.repetitions, *args, **kwargs)
+
+  def test_instantiate(self):
+    env = self.create_env()
+    self.assertEqual(env.platform, self.mock_platform)
+
+    config = HostEnvironmentConfig()
+    env = self.create_env(config)
+    self.assertSequenceEqual(env.browsers, self.mock_runner.browsers)
+    self.assertEqual(env.config, config)
+
+  def test_warn_mode_skip(self):
+    config = HostEnvironmentConfig()
+    env = self.create_env(config, ValidationMode.SKIP)
+    env.handle_warning("foo")
+
+  def test_warn_mode_fail(self):
+    config = HostEnvironmentConfig()
+    env = self.create_env(config, ValidationMode.THROW)
+    with self.assertRaises(ValidationError) as cm:
+      env.handle_warning("custom env check warning")
+    self.assertIn("custom env check warning", str(cm.exception))
+
+  def test_warn_mode_prompt(self):
+    config = HostEnvironmentConfig()
+    env = self.create_env(config, ValidationMode.PROMPT)
+    with mock.patch("builtins.input", return_value="Y") as cm:
+      env.handle_warning("custom env check warning")
+    cm.assert_called_once()
+    self.assertIn("custom env check warning", cm.call_args[0][0])
+    with mock.patch("builtins.input", return_value="n") as cm:
+      with self.assertRaises(ValidationError):
+        env.handle_warning("custom env check warning")
+    cm.assert_called_once()
+    self.assertIn("custom env check warning", cm.call_args[0][0])
+
+  def test_warn_mode_warn(self):
+    config = HostEnvironmentConfig()
+    env = self.create_env(config, ValidationMode.WARN)
+    with mock.patch("logging.warning") as cm:
+      env.handle_warning("custom env check warning")
+    cm.assert_called_once()
+    self.assertIn("custom env check warning", cm.call_args[0][0])
+
+  def test_validate_skip(self):
+    env = self.create_env(HostEnvironmentConfig(), ValidationMode.SKIP)
+    env.validate()
+
+  def test_validate_warn(self):
+    env = self.create_env(HostEnvironmentConfig(), ValidationMode.WARN)
+    with mock.patch("logging.warning") as cm:
+      env.validate()
+    cm.assert_not_called()
+    self.mock_platform.sh_stdout.assert_not_called()
+    self.mock_platform.sh.assert_not_called()
+
+  def test_validate_warn_no_probes(self):
+    env = self.create_env(
+        HostEnvironmentConfig(require_probes=True), ValidationMode.WARN)
+    with mock.patch("logging.warning") as cm:
+      env.validate()
+    cm.assert_called_once()
+    self.mock_platform.sh_stdout.assert_not_called()
+    self.mock_platform.sh.assert_not_called()
+
+  def test_request_battery_power_on(self):
+    env = self.create_env(
+        HostEnvironmentConfig(power_use_battery=True), ValidationMode.THROW)
+    self.mock_platform.is_battery_powered = True
+    env.validate()
+
+    self.mock_platform.is_battery_powered = False
+    with self.assertRaises(Exception) as cm:
+      env.validate()
+    self.assertIn("battery", str(cm.exception).lower())
+
+  def test_request_battery_power_off(self):
+    env = self.create_env(
+        HostEnvironmentConfig(power_use_battery=False), ValidationMode.THROW)
+    self.mock_platform.is_battery_powered = True
+    with self.assertRaises(ValidationError) as cm:
+      env.validate()
+    self.assertIn("battery", str(cm.exception).lower())
+
+    self.mock_platform.is_battery_powered = False
+    env.validate()
+
+  def test_request_battery_power_off_conflicting_probe(self):
+    self.mock_platform.is_battery_powered = False
+
+    mock_probe = mock.Mock()
+    mock_probe.configure_mock(BATTERY_ONLY=True, name="mock_probe")
+    self.mock_runner.probes = [mock_probe]
+    env = self.create_env(
+        HostEnvironmentConfig(power_use_battery=False), ValidationMode.THROW)
+
+    with self.assertRaises(ValidationError) as cm:
+      env.validate()
+    message = str(cm.exception).lower()
+    self.assertIn("mock_probe", message)
+    self.assertIn("battery", message)
+
+    mock_probe.BATTERY_ONLY = False
+    env.validate()
+
+  def test_request_is_headless_default(self):
+    env = self.create_env(
+        HostEnvironmentConfig(browser_is_headless=HostEnvironmentConfig.IGNORE),
+        ValidationMode.THROW)
+    mock_browser = mock.Mock(platform=self.mock_platform)
+    self.mock_runner.browsers = [mock_browser]
+
+    mock_browser.viewport.is_headless = False
+    env.validate()
+
+    mock_browser.viewport.is_headless = True
+    env.validate()
+
+  def test_request_is_headless_true(self):
+    mock_browser = mock.Mock(
+        platform=self.mock_platform, path=pathlib.Path("bin/browser_a"))
+    self.mock_runner.browsers = [mock_browser]
+    env = self.create_env(
+        HostEnvironmentConfig(browser_is_headless=True), ValidationMode.THROW)
+
+    self.mock_platform.has_display = True
+    mock_browser.viewport.is_headless = False
+    with self.assertRaises(ValidationError) as cm:
+      env.validate()
+    self.assertIn("is_headless", str(cm.exception))
+
+    self.mock_platform.has_display = False
+    with self.assertRaises(ValidationError) as cm:
+      env.validate()
+
+    self.mock_platform.has_display = True
+    mock_browser.viewport.is_headless = True
+    env.validate()
+
+    self.mock_platform.has_display = False
+    env.validate()
+
+  def test_request_is_headless_false(self):
+    mock_browser = mock.Mock(
+        platform=self.mock_platform, path=pathlib.Path("bin/browser_a"))
+    self.mock_runner.browsers = [mock_browser]
+    env = self.create_env(
+        HostEnvironmentConfig(browser_is_headless=False), ValidationMode.THROW)
+
+    self.mock_platform.has_display = True
+    mock_browser.viewport.is_headless = False
+    env.validate()
+
+    self.mock_platform.has_display = False
+    with self.assertRaises(ValidationError) as cm:
+      env.validate()
+
+    self.mock_platform.has_display = True
+    mock_browser.viewport.is_headless = True
+    with self.assertRaises(ValidationError) as cm:
+      env.validate()
+    self.assertIn("is_headless", str(cm.exception))
+
+  def test_results_dir_single(self):
+    env = self.create_env()
+    with mock.patch("logging.warning") as cm:
+      env.validate()
+    cm.assert_not_called()
+
+  def test_results_dir_non_existent(self):
+    self.mock_runner.out_dir = pathlib.Path("does/not/exist")
+    env = self.create_env()
+    with mock.patch("logging.warning") as cm:
+      env.validate()
+    cm.assert_not_called()
+
+  def test_results_dir_many(self):
+    # Create fake test result dirs:
+    for i in range(30):
+      (self.out_dir.parent / str(i)).mkdir()
+    env = self.create_env()
+    with mock.patch("logging.warning") as cm:
+      env.validate()
+    cm.assert_called_once()
+
+  def test_results_dir_too_many(self):
+    # Create fake test result dirs:
+    for i in range(100):
+      (self.out_dir.parent / str(i)).mkdir()
+    env = self.create_env()
+    with mock.patch("logging.error") as cm:
+      env.validate()
+    cm.assert_called_once()
+
+  def test_check_installed_missing(self):
+
+    def which_none(_):
+      return None
+
+    self.mock_platform.which = which_none
+    env = self.create_env()
+    with self.assertRaises(ValidationError) as cm:
+      env.check_installed(["custom_binary"])
+    self.assertIn("custom_binary", str(cm.exception))
+    with self.assertRaises(ValidationError) as cm:
+      env.check_installed(["custom_binary_a", "custom_binary_b"])
+    self.assertIn("custom_binary_a", str(cm.exception))
+    self.assertIn("custom_binary_b", str(cm.exception))
+
+  def test_check_installed_partially_missing(self):
+
+    def which_custom(binary):
+      if binary == "custom_binary_b":
+        return "/bin/custom_binary_b"
+      return None
+
+    self.mock_platform.which = which_custom
+    env = self.create_env()
+    env.check_installed(["custom_binary_b"])
+    with self.assertRaises(ValidationError) as cm:
+      env.check_installed(["custom_binary_a", "custom_binary_b"])
+    self.assertIn("custom_binary_a", str(cm.exception))
+    self.assertNotIn("custom_binary_b", str(cm.exception))
+
+
+class ValidationModeTestCase(unittest.TestCase):
+
+  def test_construct(self):
+    self.assertIs(ValidationMode("throw"), ValidationMode.THROW)
+    self.assertIs(ValidationMode("THROW"), ValidationMode.THROW)
+    self.assertIs(ValidationMode("prompt"), ValidationMode.PROMPT)
+    self.assertIs(ValidationMode("PROMPT"), ValidationMode.PROMPT)
+    self.assertIs(ValidationMode("warn"), ValidationMode.WARN)
+    self.assertIs(ValidationMode("WARN"), ValidationMode.WARN)
+    self.assertIs(ValidationMode("skip"), ValidationMode.SKIP)
+    self.assertIs(ValidationMode("SKIP"), ValidationMode.SKIP)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_exception.py b/tests/crossbench/test_exception.py
new file mode 100644
index 0000000..9478a21
--- /dev/null
+++ b/tests/crossbench/test_exception.py
@@ -0,0 +1,331 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import unittest
+from contextlib import contextmanager
+from unittest import mock
+
+from crossbench.exception import (ArgumentTypeMultiException, Entry,
+                                  ExceptionAnnotator, MultiException, annotate,
+                                  annotate_argparsing)
+from tests import test_helper
+
+
+class CustomException(Exception):
+  pass
+
+
+class CustomException2(Exception):
+  pass
+
+
+class CustomValueError(ValueError):
+  pass
+
+class ExceptionHandlerTestCase(unittest.TestCase):
+
+  def test_invalid_get_item(self):
+    annotator = ExceptionAnnotator()
+    with self.assertRaises(TypeError):
+      _ = annotator["invalid key"]
+    with self.assertRaises(IndexError):
+      _ = annotator[1]
+
+  def test_getitem(self):
+    annotator = ExceptionAnnotator()
+    with annotator.capture("exception"):
+      raise CustomException("AAA")
+    with annotator.capture("exception"):
+      raise CustomException("BBB")
+    self.assertEqual(len(annotator), 2)
+    entry_0 = annotator[0]
+    entry_1 = annotator[1]
+    self.assertIsNot(entry_0, entry_1)
+    self.assertIs(annotator[-1], entry_1)
+    with self.assertRaises(IndexError):
+      _ = annotator[2]
+
+  def test_annotate(self):
+    with self.assertRaises(MultiException) as cm:
+      with annotate("BBB"):
+        with annotate("AAA"):
+          raise ValueError("an exception")
+    exception: MultiException = cm.exception
+    annotator: ExceptionAnnotator = exception.annotator
+    self.assertTrue(len(annotator), 1)
+    entry: Entry = annotator[0]
+    self.assertTupleEqual(entry.info_stack, ("BBB", "AAA"))
+    self.assertIsInstance(entry.exception, ValueError)
+
+  def test_annotate_argparse(self):
+    with self.assertRaises(ArgumentTypeMultiException) as cm:
+      with annotate_argparsing("BBB"):
+        with annotate("AAA"):
+          with annotate("000"):
+            raise ValueError("an exception")
+    exception: MultiException = cm.exception
+    self.assertIsInstance(exception, argparse.ArgumentTypeError)
+    annotator: ExceptionAnnotator = exception.annotator
+    self.assertTrue(len(annotator), 1)
+    entry: Entry = annotator[0]
+    self.assertTupleEqual(entry.info_stack, ("BBB", "AAA", "000"))
+    self.assertIsInstance(entry.exception, ValueError)
+
+  def test_annotate_argparse_nested(self):
+    with self.assertRaises(ArgumentTypeMultiException) as cm:
+      with annotate_argparsing("BBB"):
+        with annotate_argparsing("AAA"):
+          with annotate_argparsing("000"):
+            raise CustomValueError("an exception")
+    exception: MultiException = cm.exception
+    self.assertIsInstance(exception, argparse.ArgumentTypeError)
+    annotator: ExceptionAnnotator = exception.annotator
+    self.assertTrue(len(annotator), 1)
+    entry: Entry = annotator[0]
+    self.assertListEqual(
+        annotator.matching(CustomValueError), [
+            entry.exception,
+        ])
+    self.assertTupleEqual(entry.info_stack, ("BBB", "AAA", "000"))
+    self.assertIsInstance(entry.exception, ValueError)
+
+  def test_annotate_argparse_pass_through(self):
+    with self.assertRaises(ArgumentTypeMultiException) as cm:
+      with annotate_argparsing("BBB"):
+        with annotate_argparsing("AAA"):
+          with annotate_argparsing("000"):
+            raise argparse.ArgumentTypeError("some arg type error")
+    self.assertEqual(len(cm.exception), 1)
+    exception: argparse.ArgumentTypeError = cm.exception.matching(
+        argparse.ArgumentTypeError)[0]
+    self.assertIsInstance(exception, argparse.ArgumentTypeError)
+    self.assertEqual(str(exception), "some arg type error")
+
+  def test_annotate_collecting(self):
+    annotator = ExceptionAnnotator()
+    with self.assertRaises(MultiException) as cm:
+      with annotator.annotate("AAA"):
+        with annotator.annotate("000"):
+          raise ValueError("an exception")
+    exception: MultiException = cm.exception
+    self.assertIsInstance(exception, MultiException)
+    self.assertFalse(annotator.is_success)
+    self.assertTrue(len(annotator), 1)
+    entry: Entry = annotator[0]
+    self.assertTupleEqual(entry.info_stack, ("AAA", "000"))
+    self.assertIsInstance(entry.exception, ValueError)
+
+  def test_empty(self):
+    annotator = ExceptionAnnotator()
+    self.assertTrue(annotator.is_success)
+    self.assertEqual(len(annotator), 0)
+    self.assertListEqual(annotator.to_json(), [])
+    with mock.patch("logging.error") as logging_mock:
+      annotator.log()
+    # No exceptions => no error output
+    logging_mock.assert_not_called()
+
+  def test_handle_exception(self):
+    annotator = ExceptionAnnotator()
+    exception = ValueError("custom message")
+    try:
+      raise exception
+    except ValueError as e:
+      annotator.append(e)
+    self.assertFalse(annotator.is_success)
+    serialized = annotator.to_json()
+    self.assertEqual(len(serialized), 1)
+    self.assertEqual(serialized[0]["title"], str(exception))
+    with mock.patch("logging.debug") as logging_mock:
+      annotator.log()
+    logging_mock.assert_has_calls([mock.call(exception)])
+
+  def test_handle_rethrow(self):
+    annotator = ExceptionAnnotator(throw=True)
+    exception = ValueError("custom message")
+    with self.assertRaises(ValueError) as cm:
+      try:
+        raise exception
+      except ValueError as e:
+        annotator.append(e)
+    self.assertEqual(cm.exception, exception)
+    self.assertFalse(annotator.is_success)
+    serialized = annotator.to_json()
+    self.assertEqual(len(serialized), 1)
+    self.assertEqual(serialized[0]["title"], str(exception))
+
+  def test_info_stack(self):
+    annotator = ExceptionAnnotator(throw=True)
+    exception = ValueError("custom message")
+    with self.assertRaises(ValueError) as cm, annotator.info(
+        "info 1", "info 2"):
+      self.assertTupleEqual(annotator.info_stack, ("info 1", "info 2"))
+      try:
+        raise exception
+      except ValueError as e:
+        annotator.append(e)
+    self.assertEqual(cm.exception, exception)
+    self.assertFalse(annotator.is_success)
+    self.assertEqual(len(annotator), 1)
+    entry = annotator[0]
+    self.assertTupleEqual(entry.info_stack, ("info 1", "info 2"))
+    serialized = annotator.to_json()
+    self.assertEqual(len(serialized), 1)
+    self.assertEqual(serialized[0]["title"], str(exception))
+    self.assertEqual(serialized[0]["info_stack"], ("info 1", "info 2"))
+
+  def test_info_stack_logging(self):
+    annotator = ExceptionAnnotator()
+    try:
+      with annotator.info("info 1", "info 2"):
+        raise ValueError("custom message")
+    except ValueError as e:
+      annotator.append(e)
+    with self.assertLogs(level="ERROR") as cm:
+      annotator.log()
+    output = "\n".join(cm.output)
+    self.assertIn("info 1", output)
+    self.assertIn("info 2", output)
+    self.assertIn("custom message", output)
+
+  def test_handle_keyboard_interrupt(self):
+    annotator = ExceptionAnnotator()
+    keyboard_interrupt = KeyboardInterrupt()
+    with mock.patch("sys.exit", side_effect=ValueError) as exit_mock:
+      with self.assertRaises(ValueError) as cm:
+        try:
+          raise keyboard_interrupt
+        except KeyboardInterrupt as e:
+          annotator.append(e)
+      self.assertNotEqual(cm.exception, keyboard_interrupt)
+    exit_mock.assert_called_once_with(0)
+
+  def test_extend(self):
+    annotator_1 = ExceptionAnnotator()
+    try:
+      raise ValueError("error_1")
+    except ValueError as e:
+      annotator_1.append(e)
+    annotator_2 = ExceptionAnnotator()
+    try:
+      raise ValueError("error_2")
+    except ValueError as e:
+      annotator_2.append(e)
+    annotator_3 = ExceptionAnnotator()
+    annotator_4 = ExceptionAnnotator()
+    self.assertFalse(annotator_1.is_success)
+    self.assertFalse(annotator_2.is_success)
+    self.assertTrue(annotator_3.is_success)
+    self.assertTrue(annotator_4.is_success)
+
+    self.assertEqual(len(annotator_1), 1)
+    self.assertEqual(len(annotator_2), 1)
+    annotator_2.extend(annotator_1)
+    self.assertEqual(len(annotator_2), 2)
+    self.assertFalse(annotator_1.is_success)
+    self.assertFalse(annotator_2.is_success)
+
+    self.assertEqual(len(annotator_1), 1)
+    self.assertEqual(len(annotator_3), 0)
+    self.assertEqual(len(annotator_4), 0)
+    annotator_3.extend(annotator_1)
+    annotator_3.extend(annotator_4)
+    self.assertEqual(len(annotator_3), 1)
+    self.assertFalse(annotator_3.is_success)
+    self.assertTrue(annotator_4.is_success)
+
+  def test_extend_nested(self):
+    annotator_1 = ExceptionAnnotator()
+    annotator_2 = ExceptionAnnotator()
+    exception_1 = ValueError("error_1")
+    exception_2 = ValueError("error_2")
+    with annotator_1.capture("info 1", "info 2", exceptions=(ValueError,)):
+      raise exception_1
+    self.assertEqual(len(annotator_1), 1)
+    self.assertEqual(len(annotator_2), 0)
+    with annotator_1.info("info 1", "info 2"):
+      with annotator_2.capture("info 3", "info 4", exceptions=(ValueError,)):
+        raise exception_2
+      annotator_1.extend(annotator_2, is_nested=True)
+    self.assertEqual(len(annotator_1), 2)
+    self.assertEqual(len(annotator_2), 1)
+    self.assertTupleEqual(annotator_1[0].info_stack, ("info 1", "info 2"))
+    self.assertTupleEqual(annotator_1[1].info_stack,
+                          ("info 1", "info 2", "info 3", "info 4"))
+    self.assertTupleEqual(annotator_2[0].info_stack, ("info 3", "info 4"))
+
+  def test_contextmanager(self):
+    annotator = ExceptionAnnotator()
+
+    @contextmanager
+    def context(value):
+      with annotator.capture("entry"):
+        yield value
+
+    with context("custom value") as context_value:
+      raise CustomException("custom exception")
+
+    self.assertEqual(context_value, "custom value")
+    self.assertFalse(annotator.is_success)
+    self.assertEqual(len(annotator), 1)
+    self.assertIn("custom exception", str(annotator[0]))
+
+  def test_contextmanager_raise_before_yield_capture(self):
+
+    @contextmanager
+    def context_simple(value):
+      raise RuntimeError("exception before yield")
+
+    did_run = False
+    with self.assertRaises(RuntimeError) as cm:
+      with context_simple("custom value 1"):
+        did_run = True
+        raise CustomException("custom exception 1")
+    self.assertFalse(did_run)
+    self.assertIn("exception before yield", str(cm.exception))
+
+    annotator = ExceptionAnnotator()
+
+    @contextmanager
+    def context_capture(value):
+      with annotator.capture("entry"):
+        raise RuntimeError("exception before yield")
+      yield value
+
+    did_run = False
+    with self.assertRaises(CustomException) as cm:
+      with context_capture("custom value 2"):
+        did_run = True
+        raise CustomException("custom exception 2")
+    self.assertTrue(did_run)
+    self.assertIn("custom exception 2", str(cm.exception))
+    self.assertFalse(annotator.is_success)
+    self.assertEqual(len(annotator), 1)
+    self.assertIsInstance(annotator[0].exception, RuntimeError)
+
+  def test_contextmanager_raise_before_yield_annotate(self):
+    annotator = ExceptionAnnotator()
+
+    @contextmanager
+    def context_annotate(value):
+      with annotator.annotate("entry"):
+        raise RuntimeError("exception before yield")
+      yield value
+
+    did_run = False
+    with self.assertRaises(MultiException) as cm:
+      with context_annotate("custom value 3"):
+        did_run = True
+        raise CustomException("custom exception 3")
+    self.assertFalse(did_run)
+    self.assertIn("exception before yield", str(cm.exception))
+    self.assertFalse(annotator.is_success)
+    self.assertEqual(len(annotator), 1)
+    self.assertIsInstance(annotator[0].exception, RuntimeError)
+
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_flags.py b/tests/crossbench/test_flags.py
new file mode 100644
index 0000000..33ad2ac
--- /dev/null
+++ b/tests/crossbench/test_flags.py
@@ -0,0 +1,926 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import abc
+import unittest
+
+from crossbench.flags.base import Flags, FrozenFlagsError
+from crossbench.flags.chrome import (ChromeBaseFeatures, ChromeBlinkFeatures,
+                                     ChromeFeatures, ChromeFlags)
+from crossbench.flags.js_flags import JSFlags
+from crossbench.flags.known_chrome_flags import KNOWN_CHROME_FLAGS
+from crossbench.flags.known_js_flags import KNOWN_JS_FLAGS
+from tests import test_helper
+
+
+class TestFlags(unittest.TestCase):
+
+  CLASS = Flags
+
+  def test_construct(self):
+    flags = self.CLASS()
+    self.assertEqual(len(flags), 0)
+    self.assertNotIn("foo", flags)
+
+  def test_construct_dict(self):
+    flags = self.CLASS({"--foo": "v1", "--bar": "v2"})
+    self.assertIn("--foo", flags)
+    self.assertIn("--bar", flags)
+    self.assertEqual(flags["--foo"], "v1")
+    self.assertEqual(flags["--bar"], "v2")
+
+  def test_construct_list(self):
+    flags = self.CLASS(("--foo", "--bar"))
+    self.assertIn("--foo", flags)
+    self.assertIn("--bar", flags)
+    self.assertIsNone(flags["--foo"])
+    self.assertIsNone(flags["--bar"])
+    with self.assertRaises(ValueError):
+      self.CLASS(("--foo=v1", "--bar=v2"))
+    flags = self.CLASS((("--foo", "v3"), "--bar"))
+    self.assertEqual(flags["--foo"], "v3")
+    self.assertIsNone(flags["--bar"])
+
+  def test_construct_flags(self):
+    original_flags = self.CLASS({"--foo": "v1", "--bar": "v2"})
+    flags = self.CLASS(original_flags)
+    self.assertIn("--foo", flags)
+    self.assertIn("--bar", flags)
+    self.assertEqual(flags["--foo"], "v1")
+    self.assertEqual(flags["--bar"], "v2")
+
+  def test_set(self):
+    flags = self.CLASS()
+    flags["--foo"] = "v1"
+    with self.assertRaises(ValueError):
+      flags["--foo"] = "v2"
+    # setting the same value is ok
+    flags["--foo"] = "v1"
+    self.assertEqual(flags["--foo"], "v1")
+    flags.set("--bar")
+    self.assertIn("--foo", flags)
+    self.assertIn("--bar", flags)
+    self.assertIsNone(flags["--bar"])
+    with self.assertRaises(ValueError):
+      flags.set("--bar", "v3")
+    flags.set("--bar", "v4", override=True)
+    self.assertEqual(flags["--foo"], "v1")
+    self.assertEqual(flags["--bar"], "v4")
+
+  def test_set_invalid(self):
+    flags = self.CLASS()
+    with self.assertRaises(TypeError) as cm:
+      flags["--foo"] = 123  # pytype: disable=unsupported-operands
+    self.assertIn("123", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      flags["foo"] = 123  # pytype: disable=unsupported-operands
+    self.assertIn("-", str(cm.exception))
+
+  def test_set_invalid_flag_name(self):
+    flags = self.CLASS()
+    for invalid in ("- -foo", "--f oo", "", "-", "--", "--foo\n", "--\nfoo",
+                    "--foo,"):
+      with self.subTest(invalid_flag=invalid):
+        with self.assertRaises(ValueError):
+          flags.set(invalid)
+        self.assertFalse(invalid in flags)
+
+  def test_get_list(self):
+    flags = self.CLASS({"--foo": "v1", "--bar": None})
+    self.assertEqual(list(flags), ["--foo=v1", "--bar"])
+
+  def test_copy(self):
+    flags = self.CLASS({"--foo": "v1", "--bar": None})
+    copy = flags.copy()
+    self.assertEqual(list(flags), list(copy))
+    self.assertEqual(str(flags), str(copy))
+    self.assertTrue(copy)
+
+  def test_copy_frozen(self):
+    flags = self.CLASS({"--foo": "v1", "--bar": None})
+    flags.freeze()
+    self.assertTrue(flags.is_frozen)
+    copy = flags.copy()
+    with self.assertRaises(FrozenFlagsError):
+      flags["--custom"] = "123"
+    self.assertNotIn("--custom", flags)
+    copy["--custom"] = "123"
+    self.assertEqual(copy["--custom"], "123")
+    copy.freeze()
+    with self.assertRaises(FrozenFlagsError):
+      copy["--custom-other"] = "123"
+
+  def test_update(self):
+    flags = self.CLASS({"--foo": "v1", "--bar": None})
+    with self.assertRaises(ValueError):
+      flags.update({"--bar": "v2"})
+    self.assertEqual(flags["--foo"], "v1")
+    self.assertIsNone(flags["--bar"])
+    flags.update({"--bar": "v2"}, override=True)
+    self.assertEqual(flags["--foo"], "v1")
+    self.assertEqual(flags["--bar"], "v2")
+    self.assertTrue(flags)
+
+  def test_str_basic(self):
+    flags = self.CLASS({"--foo": None})
+    self.assertEqual(str(flags), "--foo")
+    flags = self.CLASS({"--foo": "bar"})
+    self.assertEqual(str(flags), "--foo=bar")
+
+  def test_str_multiple(self):
+    flags = self.CLASS({
+        "--flag1": "value1",
+        "--flag2": None,
+        "--flag3": "value3"
+    })
+    self.assertEqual(str(flags), "--flag1=value1 --flag2 --flag3=value3")
+
+  def test_merge(self):
+    flags = self.CLASS({"--foo": "v1", "--bar": None})
+    with self.assertRaises(ValueError):
+      flags.merge({"--bar": "v2"})
+    self.assertEqual(flags["--foo"], "v1")
+    self.assertIsNone(flags["--bar"])
+    self.assertTrue(flags)
+
+  def test_parse_single(self):
+    flags = self.CLASS.parse("--foo")
+    self.assertEqual(len(flags), 1)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], None)
+    self.assertEqual(str(flags), "--foo")
+
+    flags = self.CLASS.parse("--foo=123")
+    self.assertEqual(len(flags), 1)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], "123")
+    self.assertEqual(str(flags), "--foo=123")
+
+    flags = self.CLASS.parse("--foo=--bar123")
+    self.assertEqual(len(flags), 1)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], "--bar123")
+    self.assertEqual(str(flags), "--foo=--bar123")
+
+  def test_parse_nested(self):
+    flags = self.CLASS.parse("--foo=--bar=123")
+    self.assertEqual(len(flags), 1)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], "--bar=123")
+    self.assertEqual(str(flags), "--foo=--bar=123")
+
+  def test_parse_multiple(self):
+    flags = self.CLASS.parse("--foo --bar")
+    self.assertEqual(len(flags), 2)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], None)
+    self.assertEqual(flags["--bar"], None)
+    flags = self.CLASS.parse("--foo --bar=1")
+    self.assertEqual(len(flags), 2)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], None)
+    self.assertEqual(flags["--bar"], "1")
+    flags = self.CLASS.parse("--foo=1 --bar=2")
+    self.assertEqual(len(flags), 2)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], "1")
+    self.assertEqual(flags["--bar"], "2")
+    flags = self.CLASS.parse("--foo='1' --bar='2'")
+    self.assertEqual(len(flags), 2)
+    self.assertTrue(flags)
+    self.assertEqual(flags["--foo"], "1")
+    self.assertEqual(flags["--bar"], "2")
+
+  def test_hashable(self):
+    flags = self.CLASS.parse("--foo")
+    flags["--bar"] = "10"
+    test_set = {flags}
+    self.assertIn(flags, test_set)
+    self.assertIn(self.CLASS.parse("--foo --bar=10"), test_set)
+    self.assertNotIn(self.CLASS.parse("--foo --bar=999"), test_set)
+    # post-hash modification are not allowed anymore:
+    with self.assertRaises(FrozenFlagsError) as cm:
+      flags["--bar"] = "0"
+    self.assertIn("frozen", str(cm.exception))
+
+  def test_iter(self):
+    flags = self.CLASS.parse("--foo --bar=1")
+    self.assertListEqual(list(flags), ["--foo", "--bar=1"])
+    self.assertListEqual([*flags], ["--foo", "--bar=1"])
+
+  def test_bool_basic(self):
+    self.assertFalse(self.CLASS())
+    self.assertTrue(self.CLASS.parse("--foo --bar"))
+
+
+class TestChromeFlags(TestFlags):
+
+  CLASS = ChromeFlags
+
+  def test_js_flags(self):
+    flags = self.CLASS({
+        "--foo": None,
+        "--bar": "v1",
+    })
+    self.assertIsNone(flags["--foo"])
+    self.assertEqual(flags["--bar"], "v1")
+    self.assertTrue(flags)
+    self.assertFalse(flags.js_flags)
+    self.assertNotIn("--js-flags", flags)
+    with self.assertRaises(ValueError):
+      flags["--js-flags"] = "--js-foo, --no-js-foo"
+    flags["--js-flags"] = "--js-foo=v3, --no-js-bar"
+    with self.assertRaises(ValueError):
+      flags["--js-flags"] = "--js-foo=v4, --no-js-bar"
+    js_flags = flags.js_flags
+    self.assertTrue(js_flags)
+    self.assertNotIn(flags["--js-flags"], js_flags)
+    self.assertEqual(js_flags["--js-foo"], "v3")
+    self.assertIsNone(js_flags["--no-js-bar"])
+
+  def test_set_empty_js_flags(self):
+    flags = self.CLASS({
+        "--foo": None,
+        "--bar": "v1",
+    })
+    self.assertNotIn("--js-flags", flags)
+    self.assertTrue(flags)
+    with self.assertRaises(ValueError):
+      flags["--js-flags"] = None
+    self.assertNotIn("--js-flags", flags)
+    self.assertFalse(flags.js_flags)
+    flags["--js-flags"] = ""
+    self.assertNotIn("--js-flags", flags)
+    self.assertFalse(flags.js_flags)
+    flags["--js-flags"] = "  "
+    self.assertNotIn("--js-flags", flags)
+    self.assertFalse(flags.js_flags)
+
+  def test_set_js_flags_invalid(self):
+    flags = self.CLASS()
+    for invalid in ("-foo", "--bar'f'", "--", "-8", "--8"):
+      with self.subTest(js_flag=invalid):
+        with self.assertRaises(ValueError) as cm:
+          flags["--js-flags"] = invalid
+        self.assertNotIn("--js-flags", flags)
+        self.assertIn(invalid, str(cm.exception))
+    for invalid in ("--foo=", "--foo,--bar=,--baz", "---foo", "--foo,--,--bar",
+                    "--foo;;;,;;;--bar"):
+      with self.subTest(js_flag=invalid):
+        with self.assertRaises(ValueError) as cm:
+          flags["--js-flags"] = invalid
+        self.assertNotIn("--js-flags", flags)
+
+  def test_js_flags_initial_data(self):
+    flags = self.CLASS({
+        "--js-flags": "--foo=v1,--no-bar",
+    })
+    js_flags = flags.js_flags
+    self.assertEqual(js_flags["--foo"], "v1")
+    self.assertIsNone(js_flags["--no-bar"])
+    self.assertTrue(flags)
+    self.assertTrue(flags.js_flags)
+
+  def test_features(self):
+    flags = self.CLASS()
+    features = flags.features
+    self.assertFalse(flags)
+    self.assertFalse(flags.features)
+    self.assertTrue(features.is_empty)
+    flags["--enable-features"] = "F1,F2"
+    self.assertTrue(flags)
+    self.assertTrue(flags.features)
+    with self.assertRaises(ValueError):
+      flags["--disable-features"] = "F1,F2"
+    with self.assertRaises(ValueError):
+      flags["--disable-features"] = "F2,F1"
+    flags["--disable-features"] = "F3,F4"
+    self.assertEqual(features.enabled, {"F1": None, "F2": None})
+    self.assertEqual(flags["--enable-features"], "F1,F2")
+    self.assertEqual(features.disabled, set(("F3", "F4")))
+    self.assertEqual(flags["--disable-features"], "F3,F4")
+    self.assertTrue(flags)
+    self.assertTrue(flags.features)
+
+  def test_blink_features(self):
+    flags = self.CLASS()
+    features = flags.blink_features
+    self.assertFalse(flags)
+    self.assertFalse(flags.blink_features)
+    self.assertTrue(features.is_empty)
+    flags["--enable-blink-features"] = "F1,F2"
+    self.assertTrue(flags)
+    self.assertTrue(flags.blink_features)
+    with self.assertRaises(ValueError):
+      flags["--disable-blink-features"] = "F1,F2"
+    with self.assertRaises(ValueError):
+      flags["--disable-blink-features"] = "F2,F1"
+    flags["--disable-blink-features"] = "F3,F4"
+    self.assertEqual(features.enabled, {"F1": None, "F2": None})
+    self.assertEqual(flags["--enable-blink-features"], "F1,F2")
+    self.assertEqual(features.disabled, set(("F3", "F4")))
+    self.assertEqual(flags["--disable-blink-features"], "F3,F4")
+
+  def test_features_invalid_none(self):
+    flags = self.CLASS()
+    features = flags.features
+    self.assertFalse(features)
+    self.assertTrue(features.is_empty)
+    with self.assertRaises(ValueError):
+      flags["--disable-features"] = None
+    self.assertFalse(features)
+    self.assertTrue(features.is_empty)
+    with self.assertRaises(ValueError):
+      flags["--enable-features"] = None
+    self.assertFalse(features)
+    self.assertTrue(features.is_empty)
+
+  def test_blink_features_invalid_none(self):
+    flags = self.CLASS()
+    features = flags.blink_features
+    self.assertTrue(features.is_empty)
+    with self.assertRaises(ValueError):
+      flags["--disable-blink-features"] = None
+    self.assertTrue(features.is_empty)
+    with self.assertRaises(ValueError):
+      flags["--enable-blink-features"] = None
+    self.assertNotIn("--enable-blink-features", flags)
+    self.assertTrue(features.is_empty)
+
+  def test_user_data_dir(self):
+    flags = self.CLASS()
+    for invalid in (None, "", "  "):
+      with self.subTest(user_dat_dir=invalid):
+        with self.assertRaises(ValueError) as cm:
+          flags["--user-data-dir"] = invalid
+        self.assertIn("empty string", str(cm.exception))
+
+  def test_get_list(self):
+    flags = self.CLASS()
+    flags["--user-data-dir"] = "/tmp"
+    flags.set("--single-process")
+    flags["--js-flags"] = "--js-foo=v3, --no-js-bar"
+    flags["--enable-features"] = "F1,F2"
+    flags["--disable-features"] = "F3,F4"
+    flags["--enable-blink-features"] = "BLINK_F1,BLINK_F2"
+    flags["--disable-blink-features"] = "BLINK_F3,BLINK_F4"
+    flags_list = list(flags)
+    self.assertListEqual(flags_list, [
+        "--user-data-dir=/tmp",
+        "--single-process",
+        "--js-flags=--js-foo=v3,--no-js-bar",
+        "--enable-features=F1,F2",
+        "--disable-features=F3,F4",
+        "--enable-blink-features=BLINK_F1,BLINK_F2",
+        "--disable-blink-features=BLINK_F3,BLINK_F4",
+    ])
+
+  def test_to_dict(self):
+    flags = self.CLASS()
+    flags["--user-data-dir"] = "/tmp"
+    flags.set("--single-process")
+    flags["--js-flags"] = "--js-foo=v3, --no-js-bar"
+    flags["--enable-features"] = "F1,F2"
+    flags["--disable-features"] = "F3,F4"
+    flags["--enable-blink-features"] = "BLINK_F1,BLINK_F2"
+    flags["--disable-blink-features"] = "BLINK_F3,BLINK_F4"
+    self.assertDictEqual(
+        flags.to_dict(), {
+            "--user-data-dir": "/tmp",
+            "--single-process": None,
+            "--js-flags": "--js-foo=v3,--no-js-bar",
+            "--enable-features": "F1,F2",
+            "--disable-features": "F3,F4",
+            "--enable-blink-features": "BLINK_F1,BLINK_F2",
+            "--disable-blink-features": "BLINK_F3,BLINK_F4",
+        })
+
+  def test_initial_data_empty(self):
+    flags = self.CLASS()
+    flags_copy = self.CLASS(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertFalse(flags_copy)
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertFalse(flags_copy)
+
+  def test_initial_data_simple(self):
+    flags = self.CLASS()
+    flags["--no-sandbox"] = None
+    flags_copy = self.CLASS(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+
+  def test_initial_data_js_flags(self):
+    flags = self.CLASS()
+    flags["--js-flags"] = "--js-foo=v3, --no-js-bar"
+    flags_copy = self.CLASS(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+
+  def test_initial_data_features(self):
+    flags = self.CLASS()
+    flags["--enable-features"] = "F1,F2"
+    flags["--disable-features"] = "F3,F4"
+    flags_copy = self.CLASS(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+
+  def test_initial_data_blink_features(self):
+    flags = self.CLASS()
+    flags["--enable-blink-features"] = "BLINK_F1,BLINK_F2"
+    flags["--disable-blink-features"] = "BLINK_F3,BLINK_F4"
+    flags_copy = self.CLASS(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+
+  def test_initial_data_all(self):
+    flags = self.CLASS()
+    flags["--no-sandbox"] = None
+    flags["--js-flags"] = "--js-foo=v3, --no-js-bar"
+    flags["--enable-features"] = "F1,F2"
+    flags["--disable-features"] = "F3,F4"
+    flags["--enable-blink-features"] = "BLINK_F1,BLINK_F2"
+    flags["--disable-blink-features"] = "BLINK_F3,BLINK_F4"
+    flags_copy = self.CLASS(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertListEqual(list(flags), list(flags_copy))
+    self.assertTrue(flags_copy)
+
+  def test_set_js_flags(self):
+    flags = self.CLASS()
+    flags["--js-flags"] = "--foo=a/b/c-d-e.log,--bar=a--b/c ,--no-baz"
+    self.assertEqual(flags.js_flags["--foo"], "a/b/c-d-e.log")
+    self.assertEqual(flags.js_flags["--bar"], "a--b/c")
+    self.assertEqual(flags.js_flags["--no-baz"], None)
+
+  def test_js_flags_separators(self):
+    flags_1 = self.CLASS()
+    flags_1["--js-flags"] = "--f-one=1,--no-f-two,--f-three=3"
+    flags_2 = self.CLASS()
+    flags_2["--js-flags"] = "--f-one=1 --no-f-two --f-three=3"
+    flags_3 = self.CLASS()
+    flags_3["--js-flags"] = "--f-one='1',--no-f-two,--f-three=\"3\""
+    flags_4 = self.CLASS()
+    flags_4["--js-flags"] = "--f-one='1' --no-f-two, --f-three=\"3\""
+
+    list_1 = list(flags_1.js_flags)
+    list_2 = list(flags_2.js_flags)
+    self.assertListEqual(list_1, list_2)
+    list_3 = list(flags_3.js_flags)
+    self.assertListEqual(list_1, list_3)
+    list_4 = list(flags_4.js_flags)
+    self.assertListEqual(list_1, list_4)
+
+    for flags in (flags_1, flags_2, flags_3):
+      self.assertEqual(flags.js_flags["--f-one"], "1")
+      self.assertEqual(flags.js_flags["--no-f-two"], None)
+      self.assertEqual(flags.js_flags["--f-three"], "3")
+
+  def test_set_invalid_js_flags(self):
+    flags = self.CLASS()
+    flags["--js-flags"] = "--foo=1--bar"
+    for invalid in ("--bar,=", "-bar=1", "--bar,,", "--", "-", "a=b",
+                    "--bar==1", "--bar==--bar", "--bar='1\", --foo=1",
+                    "--foo='1'--bar", "--bar='a b c'"):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(ValueError):
+          flags["--js-flags"] = invalid
+
+  def test_merge(self):
+    flags = self.CLASS({
+        "--foo": "v1",
+        "--bar": None,
+        "--js-flags": "--log-maps,--log-ic",
+        "--enable-features": "feature_1,feature_2",
+        "--disable-features": "feature_3",
+        "--enable-blink-features": "blink_feature_1,blink_feature_2",
+        "--disable-blink-features": "blink_feature_3"
+    })
+    with self.assertRaises(ValueError):
+      flags.merge({"--bar": "v2"})
+    with self.assertRaises(ValueError):
+      flags.merge({"--js-flags": "--no-log-maps"})
+    with self.assertRaises(ValueError):
+      flags.merge({"--disable-features": "feature_1,"})
+    with self.assertRaises(ValueError):
+      flags.merge({"--enable-features": "feature_3"})
+    with self.assertRaises(ValueError):
+      flags.merge({"--enable-blink-features": "blink_feature_3"})
+    flags.merge({
+        "--js-flags": "--log-all",
+        "--enable-features": "feature_x",
+        "--disable-features": "feature_y,feature_z",
+        "--enable-blink-features": "blink_feature_x",
+        "--disable-blink-features": "blink_feature_y,blink_feature_z"
+    })
+    self.assertListEqual(
+        list(flags.js_flags), ["--log-maps", "--log-ic", "--log-all"])
+    self.assertListEqual(
+        list(flags.features), [
+            "--enable-features=feature_1,feature_2,feature_x",
+            "--disable-features=feature_3,feature_y,feature_z"
+        ])
+    self.assertListEqual(
+        list(flags.blink_features), [
+            "--enable-blink-features="
+            "blink_feature_1,blink_feature_2,blink_feature_x",
+            "--disable-blink-features="
+            "blink_feature_3,blink_feature_y,blink_feature_z"
+        ])
+
+  def test_flag_typos_enable_features(self):
+    for invalid_flag in ("--enable-feature", "--enabled-feature",
+                         "--enabled-features"):
+      with self.assertLogs(level="ERROR") as cm:
+        self.CLASS({invalid_flag: "feature_1"})
+      output = "\n".join(cm.output)
+      self.assertIn(invalid_flag, output)
+      self.assertIn("--enable-features", output)
+
+    for invalid_flag in ("--disable-feature", "--disabled-feature",
+                         "--disabled-features"):
+      with self.assertLogs(level="ERROR") as cm:
+        self.CLASS({invalid_flag: "feature_1"})
+      output = "\n".join(cm.output)
+      self.assertIn(invalid_flag, output)
+      self.assertIn("--disable-features", output)
+
+  def test_flag_typos_enable_blink_features(self):
+    for invalid_flag in ("--enable-blink-feature", "--enabled-blink-feature",
+                         "--enabled-blink-features"):
+      with self.assertLogs(level="ERROR") as cm:
+        self.CLASS({invalid_flag: "feature_1"})
+      output = "\n".join(cm.output)
+      self.assertIn(invalid_flag, output)
+      self.assertIn("--enable-blink-features", output)
+
+    for invalid_flag in ("--disable-blink-feature", "--disabled-blink-feature",
+                         "--disabled-blink-features"):
+      with self.assertLogs(level="ERROR") as cm:
+        self.CLASS({invalid_flag: "feature_1"})
+      output = "\n".join(cm.output)
+      self.assertIn(invalid_flag, output)
+      self.assertIn("--disable-blink-features", output)
+
+  def test_flag_js_flags_as_chrome_flags(self):
+    for invalid_flag in ("--no-maglev", "--maglev"):
+      flags = self.CLASS()
+      with self.assertLogs(level="ERROR") as cm:
+        flags.set(invalid_flag)
+      self.assertIn(invalid_flag, str(cm.output))
+      self.assertIn(invalid_flag, flags)
+
+  def test_known_flags(self):
+    for chrome_flag in KNOWN_CHROME_FLAGS:
+      self.assertNotIn("=", chrome_flag, "Only allow names, no values")
+
+  def test_known_flags_chrome_overlap(self):
+    for chrome_flag in KNOWN_CHROME_FLAGS:
+      self.assertNotIn(chrome_flag, KNOWN_JS_FLAGS)
+
+class TestJSFlags(TestFlags):
+
+  CLASS = JSFlags
+
+  def test_invalid_js_flags(self):
+    flags = self.CLASS()
+    with self.assertRaises(ValueError) as cm:
+      flags.set("-foo")
+    self.assertIn("'-foo'", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      flags.set("--foo,--bar")
+    self.assertIn("'--foo,--bar'", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      flags.set("--v8-log", "foo,bar")
+    self.assertIn("comma", str(cm.exception).lower())
+    self.assertIn("--v8-log", str(cm.exception))
+    self.assertIn("foo,bar", str(cm.exception))
+    with self.assertRaises(ValueError) as cm:
+      flags["--foo"] = "a b c d"
+    self.assertIn("whitespace", str(cm.exception).lower())
+    self.assertIn("--foo", str(cm.exception))
+    self.assertIn("a b c d", str(cm.exception))
+
+  def test_conflicting_flags(self):
+    with self.assertRaises(ValueError):
+      flags = self.CLASS(("--foo", "--no-foo"))
+    with self.assertRaises(ValueError):
+      flags = self.CLASS(("--foo", "--nofoo"))
+    flags = self.CLASS(("--foo", "--no-bar"))
+    self.assertIsNone(flags["--foo"])
+    self.assertIsNone(flags["--no-bar"])
+    self.assertIn("--foo", flags)
+    self.assertNotIn("--no-foo", flags)
+    self.assertNotIn("--bar", flags)
+    self.assertIn("--no-bar", flags)
+
+  def test_conflicting_override(self):
+    flags = self.CLASS(("--foo", "--no-bar"))
+    with self.assertRaises(ValueError):
+      flags.set("--no-foo")
+    with self.assertRaises(ValueError):
+      flags.set("--nofoo")
+    flags.set("--nobar")
+    with self.assertRaises(ValueError):
+      flags.set("--bar")
+    with self.assertRaises(ValueError):
+      flags.set("--foo", "v2")
+    self.assertIsNone(flags["--foo"])
+    self.assertIsNone(flags["--no-bar"])
+
+    flags.set("--no-foo", override=True)
+    self.assertNotIn("--foo", flags)
+    self.assertIn("--no-foo", flags)
+    self.assertNotIn("--bar", flags)
+    self.assertIn("--no-bar", flags)
+
+    flags.set("--bar", override=True)
+    self.assertNotIn("--foo", flags)
+    self.assertIn("--no-foo", flags)
+    self.assertIn("--bar", flags)
+    self.assertNotIn("--no-bar", flags)
+
+  def test_str_multiple(self):
+    flags = self.CLASS({
+        "--flag-a": "value1",
+        "--flag-b": None,
+        "--flag-c": "value3"
+    })
+    self.assertEqual(str(flags), "--flag-a=value1,--flag-b,--flag-c=value3")
+
+  def test_initial_data_empty(self):
+    flags = self.CLASS()
+    flags_copy = self.CLASS(flags)
+    self.assertEqual(str(flags), str(flags_copy))
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertEqual(str(flags), str(flags_copy))
+
+  def test_initial_data(self):
+    flags = self.CLASS({
+        "--flag-a": "value1",
+        "--flag-b": None,
+        "--flag-c": "value3"
+    })
+    flags_copy = self.CLASS(flags)
+    self.assertEqual(str(flags), str(flags_copy))
+    flags_copy = self.CLASS()
+    flags_copy.update(flags)
+    self.assertEqual(str(flags), str(flags_copy))
+
+  def test_parse_nested(self):
+    self.skipTest("Not supported for JSFlags")
+
+  def test_known_flags(self):
+    self.assertNotIn(
+        "--help", KNOWN_JS_FLAGS,
+        "--help is also present in chrome, this should be filtered out")
+    for flag in KNOWN_JS_FLAGS:
+      self.assertFalse(
+          flag.startswith("--no"), "Strip --no prefix from all flags.")
+      self.assertNotIn("=", flag, "Only allow names, no values")
+
+  def test_known_flags_chrome_overlap(self):
+    for js_flag in KNOWN_JS_FLAGS:
+      self.assertNotIn(js_flag, KNOWN_CHROME_FLAGS)
+
+
+class _ChromeBaseFeaturesTestCase(unittest.TestCase, metaclass=abc.ABCMeta):
+
+  @abc.abstractmethod
+  def instance(self) -> ChromeBaseFeatures:
+    pass
+
+  def test_empty(self):
+    features = self.instance()
+    self.assertEqual(str(features), "")
+    features_list = list(features)
+    self.assertEqual(len(features_list), 0)
+    self.assertDictEqual(features.enabled, {})
+    self.assertSetEqual(features.disabled, set())
+
+  def test_enable_simple(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.enable("feature2")
+    features_list = list(features)
+    self.assertEqual(len(features_list), 1)
+    features_str = str(features)
+    self.assertIn("=feature1,feature2", features_str)
+
+  def test_disable_simple(self):
+    features = self.instance()
+    features.disable("feature1")
+    features.disable("feature2")
+    features_list = list(features)
+    self.assertEqual(len(features_list), 1)
+    features_str = str(features)
+    self.assertIn("=feature1,feature2", features_str)
+
+  def test_enable_disable(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.disable("feature2")
+    features_list = list(features)
+    self.assertEqual(len(features_list), 2)
+    features_str = str(features)
+    self.assertIn("feature1", features_str)
+    self.assertIn("feature2", features_str)
+    self.assertDictEqual(features.enabled, {"feature1": None})
+    self.assertSetEqual(features.disabled, {"feature2"})
+
+  def test_update_same(self):
+    features_1 = self.instance()
+    features_1.disable("feature1")
+    features_2 = self.instance()
+    features_2.disable("feature1")
+    features_1.update(features_2)
+    self.assertEqual(str(features_1), str(features_2))
+
+  def test_update_add(self):
+    features_1 = self.instance()
+    features_1.disable("feature1")
+    features_1.enable("feature2")
+    features_2 = self.instance()
+    features_2.disable("featureX")
+    features_2.enable("featureY")
+    features_1.update(features_2)
+    self.assertSetEqual(features_1.disabled, {"feature1", "featureX"})
+    self.assertSetEqual(
+        set(features_1.enabled.keys()), {"feature2", "featureY"})
+
+  def test_update_conflict(self):
+    features_1 = self.instance()
+    features_1.enable("feature1")
+    features_2 = self.instance()
+    features_2.disable("feature1")
+    with self.assertRaises(ValueError):
+      features_1.update(features_2)
+
+  def test_enable_disable_frozen(self):
+    features = self.instance()
+    features.freeze()
+    with self.assertRaises(FrozenFlagsError):
+      features.disable("feature1")
+    with self.assertRaises(FrozenFlagsError):
+      features.enable("feature2")
+
+
+class ChromeFeaturesTestCase(_ChromeBaseFeaturesTestCase):
+
+  def instance(self) -> ChromeFeatures:
+    return ChromeFeatures()
+
+  def test_enable_complex_features(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.enable("feature2:k1")
+    features.enable("feature3:k1/v1/k2/v2")
+    features.enable("feature4<Trial1:k1/v1/k2/v2")
+    features.enable("feature5<Trial1.Group1:k1/v1/k2/v2")
+    features_list = list(features)
+    self.assertEqual(len(features_list), 1)
+
+  def test_disable_complex_features(self):
+    features = self.instance()
+    features.disable("feature1")
+    features.disable("feature2:k1")
+    features.disable("feature3:k1/v1/k2/v2")
+    features.disable("feature4<Trial1:k1/v1/k2/v2")
+    features.disable("feature5<Trial1.Group1:k1/v1/k2/v2")
+    features_list = list(features)
+    self.assertEqual(len(features_list), 1)
+    features_str = str(features)
+    self.assertIn("feature1", features_str)
+    self.assertIn("feature2", features_str)
+    self.assertIn("feature3", features_str)
+    self.assertIn("feature4", features_str)
+
+  def test_enable_simple_chrome(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.enable("feature2")
+    self.assertEqual(str(features), "--enable-features=feature1,feature2")
+
+  def test_disable_simple_chrome(self):
+    features = self.instance()
+    features.disable("feature1")
+    features.disable("feature2")
+    self.assertEqual(str(features), "--disable-features=feature1,feature2")
+
+  def test_enable_disable_chrome(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.disable("feature2")
+    self.assertEqual(
+        str(features), "--enable-features=feature1 --disable-features=feature2")
+
+  def test_enable_disable_complex(self):
+    features = self.instance()
+    features.enable("feature0")
+    features.enable("feature1:k1/v1")
+    features.enable("feature2<Trial.Group:k2/v2")
+    features.disable("feature3:k3/v3")
+    self.assertDictEqual(features.enabled, {
+        "feature0": None,
+        "feature1": ":k1/v1",
+        "feature2": "<Trial.Group:k2/v2"
+    })
+    self.assertSetEqual(features.disabled, {"feature3"})
+
+  def test_conflicting_values_enabled(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.enable("feature1")
+    with self.assertRaises(ValueError):
+      features.disable("feature1")
+    with self.assertRaises(ValueError):
+      features.enable("feature1:k1/v1")
+    features_str = str(features)
+    self.assertEqual(features_str, "--enable-features=feature1")
+
+  def test_conflicting_values_disabled(self):
+    features = self.instance()
+    features.disable("feature1")
+    features.disable("feature1")
+    with self.assertRaises(ValueError):
+      features.enable("feature1")
+    features.disable("feature1:k1/v1")
+    features_str = str(features)
+    self.assertEqual(features_str, "--disable-features=feature1")
+
+
+class ChromeBlinkFeaturesTestCase(_ChromeBaseFeaturesTestCase):
+
+  def instance(self) -> ChromeBlinkFeatures:
+    return ChromeBlinkFeatures()
+
+  def test_empty(self):
+    features = self.instance()
+    self.assertEqual(str(features), "")
+    features_list = list(features)
+    self.assertEqual(len(features_list), 0)
+    self.assertDictEqual(features.enabled, {})
+    self.assertSetEqual(features.disabled, set())
+
+  def test_enable_basic_features(self):
+    features = self.instance()
+    features.enable("feature1")
+
+  def test_enable_invalid(self):
+    features = self.instance()
+    for invalid in ("feature2:k1", "feature3:k1/v1/k2/v2",
+                    "feature4<Trial1:k1/v1/k2/v2",
+                    "feature5<Trial1.Group1:k1/v1/k2/v2"):
+      with self.assertRaises(ValueError):
+        features.enable(invalid)
+    self.assertTrue(features.is_empty)
+
+  def test_enable_simple_chrome_blink(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.enable("feature2")
+    self.assertEqual(str(features), "--enable-blink-features=feature1,feature2")
+
+  def test_disable_simple_chrome_blink(self):
+    features = self.instance()
+    features.disable("feature1")
+    features.disable("feature2")
+    self.assertEqual(
+        str(features), "--disable-blink-features=feature1,feature2")
+
+  def test_enable_disable_chrome_blink(self):
+    features = self.instance()
+    features.enable("feature1")
+    features.disable("feature2")
+    self.assertEqual(
+        str(features),
+        "--enable-blink-features=feature1 --disable-blink-features=feature2")
+
+
+del _ChromeBaseFeaturesTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_helper.py b/tests/crossbench/test_helper.py
new file mode 100644
index 0000000..9e8ffe8
--- /dev/null
+++ b/tests/crossbench/test_helper.py
@@ -0,0 +1,338 @@
+# Copyright 2022 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import datetime as dt
+import enum
+import pathlib
+import unittest
+
+from crossbench import compat, helper, plt
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class WaitTestCase(unittest.TestCase):
+
+  def test_invalid_wait_ranges(self):
+    with self.assertRaises(AssertionError):
+      helper.WaitRange(min=-1)
+    with self.assertRaises(AssertionError):
+      helper.WaitRange(timeout=0)
+    with self.assertRaises(AssertionError):
+      helper.WaitRange(factor=0.2)
+    with self.assertRaises(AssertionError):
+      helper.WaitRange(delay=100)
+
+  def test_range(self):
+    durations = list(
+        helper.WaitRange(min=1, max=16, factor=2, max_iterations=5))
+    self.assertListEqual(durations, [
+        dt.timedelta(seconds=1),
+        dt.timedelta(seconds=2),
+        dt.timedelta(seconds=4),
+        dt.timedelta(seconds=8),
+        dt.timedelta(seconds=16)
+    ])
+
+  def test_range_with_delay(self):
+    durations = list(
+        helper.WaitRange(min=1, max=16, factor=2, max_iterations=5, delay=5.5))
+    self.assertListEqual(durations, [
+        dt.timedelta(seconds=5.5),
+        dt.timedelta(seconds=1),
+        dt.timedelta(seconds=2),
+        dt.timedelta(seconds=4),
+        dt.timedelta(seconds=8),
+        dt.timedelta(seconds=16)
+    ])
+
+  def test_range_extended(self):
+    durations = list(
+        helper.WaitRange(min=1, max=16, factor=2, max_iterations=5 + 4))
+    self.assertListEqual(
+        durations,
+        [
+            dt.timedelta(seconds=1),
+            dt.timedelta(seconds=2),
+            dt.timedelta(seconds=4),
+            dt.timedelta(seconds=8),
+            dt.timedelta(seconds=16),
+            # After 5 iterations the interval is no longer increased
+            dt.timedelta(seconds=16),
+            dt.timedelta(seconds=16),
+            dt.timedelta(seconds=16),
+            dt.timedelta(seconds=16)
+        ])
+
+  def test_wait_with_backoff(self):
+    data = []
+    delta = 0.0005
+    for time_spent, time_left in helper.WaitRange(
+        min=0.01, max=0.05).wait_with_backoff():
+      data.append((time_spent, time_left))
+      if len(data) == 2:
+        break
+      plt.PLATFORM.sleep(delta)
+    self.assertEqual(len(data), 2)
+    first_time_spent, first_time_left = data[0]
+    second_time_spent, second_time_left = data[1]
+    self.assertLessEqual(first_time_spent + delta, second_time_spent)
+    self.assertGreaterEqual(first_time_left, second_time_left + delta)
+
+
+class DurationsTestCase(unittest.TestCase):
+
+  def test_single(self):
+    durations = helper.Durations()
+    self.assertTrue(len(durations) == 0)
+    self.assertDictEqual(durations.to_json(), {})
+    with durations.measure("a"):
+      pass
+    self.assertGreaterEqual(durations["a"].total_seconds(), 0)
+    self.assertTrue(len(durations) == 1)
+
+  def test_invalid_twice(self):
+    durations = helper.Durations()
+    with durations.measure("a"):
+      pass
+    with self.assertRaises(AssertionError):
+      with durations.measure("a"):
+        pass
+    self.assertTrue(len(durations) == 1)
+    self.assertListEqual(list(durations.to_json().keys()), ["a"])
+
+  def test_multiple(self):
+    durations = helper.Durations()
+    for name in ["a", "b", "c"]:
+      with durations.measure(name):
+        pass
+    self.assertEqual(len(durations), 3)
+    self.assertListEqual(list(durations.to_json().keys()), ["a", "b", "c"])
+
+
+class ChangeCWDTestCase(CrossbenchFakeFsTestCase):
+
+  def test_basic(self):
+    old_cwd = pathlib.Path.cwd()
+    new_cwd = pathlib.Path("/foo/bar").absolute()
+    new_cwd.mkdir(parents=True)
+    with helper.ChangeCWD(new_cwd):
+      self.assertNotEqual(old_cwd, pathlib.Path.cwd())
+      self.assertEqual(new_cwd, pathlib.Path.cwd())
+    self.assertEqual(old_cwd, pathlib.Path.cwd())
+    self.assertNotEqual(new_cwd, pathlib.Path.cwd())
+
+
+class FileSizeTestCase(CrossbenchFakeFsTestCase):
+
+  def test_empty(self):
+    test_file = pathlib.Path("test.txt")
+    test_file.touch()
+    size = helper.get_file_size(test_file)
+    self.assertEqual(size, "0.00 B")
+
+  def test_bytes(self):
+    test_file = pathlib.Path("test.txt")
+    self.fs.create_file(test_file, st_size=501)
+    size = helper.get_file_size(test_file)
+    self.assertEqual(size, "501.00 B")
+
+  def test_kib(self):
+    test_file = pathlib.Path("test.txt")
+    self.fs.create_file(test_file, st_size=1024 * 2)
+    size = helper.get_file_size(test_file)
+    self.assertEqual(size, "2.00 KiB")
+
+  def test_kib_fraction(self):
+    test_file = pathlib.Path("test.txt")
+    self.fs.create_file(test_file, st_size=int(1024 * 2.51))
+    size = helper.get_file_size(test_file)
+    self.assertEqual(size, "2.51 KiB")
+
+  def test_sort_by_file_size(self):
+    small = pathlib.Path("smol")
+    medium = pathlib.Path("medium")
+    large = pathlib.Path("laaaarge")
+    self.fs.create_file(small, st_size=100)
+    self.fs.create_file(medium, st_size=200)
+    self.fs.create_file(large, st_size=300)
+    result = helper.sort_by_file_size([small, medium, large])
+    self.assertListEqual(result, [small, medium, large])
+    result = helper.sort_by_file_size([medium, large, small])
+    self.assertListEqual(result, [small, medium, large])
+    result = helper.sort_by_file_size([large, medium, small])
+    self.assertListEqual(result, [small, medium, large])
+
+
+class GroupByTestCase(unittest.TestCase):
+
+  def test_empty(self):
+    grouped = helper.group_by([], key=str)
+    self.assertDictEqual({}, grouped)
+
+  def test_basic(self):
+    grouped = helper.group_by([1, 1, 1, 2, 2, 3], key=str)
+    self.assertListEqual(list(grouped.keys()), ["1", "2", "3"])
+    self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
+
+  def test_basic_out_of_order(self):
+    grouped = helper.group_by([2, 3, 2, 1, 1, 1], key=str)
+    self.assertListEqual(list(grouped.keys()), ["1", "2", "3"])
+    self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
+
+  def test_basic_input_order(self):
+    grouped = helper.group_by([2, 3, 2, 1, 1, 1], key=str, sort_key=None)
+    self.assertListEqual(list(grouped.keys()), ["2", "3", "1"])
+    self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
+
+  def test_basic_custom_order(self):
+    grouped = helper.group_by([2, 3, 2, 1, 1, 1],
+                              key=str,
+                              sort_key=lambda item: int(item[0]))
+    self.assertListEqual(list(grouped.keys()), ["1", "2", "3"])
+    self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
+    # Try reverse sorting
+    grouped = helper.group_by([2, 3, 2, 1, 1, 1],
+                              key=str,
+                              sort_key=lambda item: -int(item[0]))
+    self.assertListEqual(list(grouped.keys()), ["3", "2", "1"])
+    self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
+
+  def test_custom_key(self):
+    grouped = helper.group_by([1.1, 1.2, 1.3, 2.1, 2.2, 3.1], key=int)
+    self.assertDictEqual({1: [1.1, 1.2, 1.3], 2: [2.1, 2.2], 3: [3.1]}, grouped)
+
+  def test_custom_value(self):
+    grouped = helper.group_by([1, 1, 1, 2, 2, 3],
+                              key=str,
+                              value=lambda x: x * 100)
+    self.assertDictEqual({
+        "1": [100, 100, 100],
+        "2": [200, 200],
+        "3": [300]
+    }, grouped)
+
+  def test_custom_group(self):
+    grouped = helper.group_by([1, 1, 1, 2, 2, 3],
+                              key=str,
+                              group=lambda key: ["custom"])
+    self.assertDictEqual(
+        {
+            "1": ["custom", 1, 1, 1],
+            "2": ["custom", 2, 2],
+            "3": ["custom", 3]
+        }, grouped)
+
+  def test_custom_group_out_of_order(self):
+    grouped = helper.group_by([1, 1, 1, 2, 2, 3],
+                              key=str,
+                              group=lambda key: ["custom"])
+    self.assertDictEqual(
+        {
+            "1": ["custom", 1, 1, 1],
+            "2": ["custom", 2, 2],
+            "3": ["custom", 3]
+        }, grouped)
+
+
+class ConcatFilesTestCase(CrossbenchFakeFsTestCase):
+
+  def setUp(self):
+    super().setUp()
+    self.platform = plt.PLATFORM
+
+  def test_single(self):
+    input_file = pathlib.Path("input")
+    self.fs.create_file(input_file, contents="input content")
+    output = pathlib.Path("ouput")
+    self.platform.concat_files([input_file], output)
+    self.assertEqual(output.read_text(encoding="utf-8"), "input content")
+
+  def test_multiple(self):
+    input_a = pathlib.Path("input_1")
+    self.fs.create_file(input_a, contents="AAA")
+    input_b = pathlib.Path("input_2")
+    self.fs.create_file(input_b, contents="BBB")
+    output = pathlib.Path("ouput")
+    self.platform.concat_files([input_a, input_b], output)
+    self.assertEqual(output.read_text(encoding="utf-8"), "AAABBB")
+
+
+class StrEnumWithHelpTestCase(unittest.TestCase):
+
+  @enum.unique
+  class TestEnum(compat.StrEnumWithHelp):
+    A = ("a", "help a")
+    B = ("b", "help b")
+
+  def test_lookup(self):
+    self.assertIs(self.TestEnum("a"), self.TestEnum.A)  # pytype: disable=wrong-arg-types
+    self.assertIs(self.TestEnum("b"), self.TestEnum.B)  # pytype: disable=wrong-arg-types
+    self.assertIs(self.TestEnum["A"], self.TestEnum.A)
+    self.assertIs(self.TestEnum["B"], self.TestEnum.B)
+
+  def test_value_help(self):
+    # pylint: disable=no-member
+    self.assertEqual(self.TestEnum.A.name, "A")
+    self.assertEqual(self.TestEnum.B.name, "B")
+    self.assertEqual(self.TestEnum.A.value, "a")
+    self.assertEqual(self.TestEnum.B.value, "b")
+    self.assertEqual(self.TestEnum.A.help, "help a")
+    self.assertEqual(self.TestEnum.B.help, "help b")
+
+  def test_in(self):
+    self.assertIn(self.TestEnum.A, self.TestEnum)
+    self.assertIn(self.TestEnum.B, self.TestEnum)
+
+  def test_str(self):
+    self.assertEqual(str(self.TestEnum.A), "a")
+    self.assertEqual(str(self.TestEnum.B), "b")
+
+  def test_list(self):
+    self.assertEqual(len(self.TestEnum), 2)
+    self.assertListEqual(
+        list(self.TestEnum), [self.TestEnum.A, self.TestEnum.B])
+
+  def test_help_items(self):
+    self.assertListEqual(self.TestEnum.help_text_items(), [("'a'", "help a"),
+                                                           ("'b'", "help b")])
+
+
+class UpdateUrlQueryTestCase(unittest.TestCase):
+
+  def test_empty(self):
+    self.assertEqual("http://test.com",
+                     helper.update_url_query("http://test.com", {}))
+    self.assertEqual("https://test.com",
+                     helper.update_url_query("https://test.com", {}))
+    self.assertEqual("https://test.com?foo=bar",
+                     helper.update_url_query("https://test.com?foo=bar", {}))
+
+  def test_empty_add(self):
+    self.assertEqual("http://test.com?foo=bar",
+                     helper.update_url_query("http://test.com", {"foo": "bar"}))
+    self.assertEqual(
+        "http://test.com?foo=bar#status",
+        helper.update_url_query("http://test.com#status", {"foo": "bar"}))
+    self.assertEqual(
+        "http://test.com?xyz=10&foo=bar#status",
+        helper.update_url_query("http://test.com?xyz=10#status",
+                                {"foo": "bar"}))
+
+  def test_override(self):
+    self.assertEqual(
+        "http://test.com?foo=bar",
+        helper.update_url_query("http://test.com?foo=BAR", {"foo": "bar"}))
+    self.assertEqual(
+        "http://test.com?foo=bar#status",
+        helper.update_url_query("http://test.com?foo=BAR#status",
+                                {"foo": "bar"}))
+    self.assertEqual(
+        "http://test.com?foo=bar&xyz=10#status",
+        helper.update_url_query("http://test.com?foo=BAR&xyz=10#status",
+                                {"foo": "bar"}))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_parse.py b/tests/crossbench/test_parse.py
new file mode 100644
index 0000000..e5d5783
--- /dev/null
+++ b/tests/crossbench/test_parse.py
@@ -0,0 +1,589 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import json
+import pathlib
+import unittest
+from typing import Any
+from urllib import parse as urlparse
+
+from crossbench.parse import (DurationParser, NumberParser, ObjectParser,
+                              PathParser)
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class DurationParserTestCase(unittest.TestCase):
+
+  def test_parse_negative(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      DurationParser.positive_duration(-1)
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DurationParser.positive_duration("-1")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DurationParser.positive_or_zero_duration("-1")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DurationParser.positive_or_zero_duration(dt.timedelta(seconds=-1))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DurationParser.positive_duration("-1")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DurationParser.positive_duration(dt.timedelta(seconds=-1))
+    self.assertIn("-1", str(cm.exception))
+    self.assertEqual(DurationParser.any_duration("-1.5").total_seconds(), -1.5)
+
+  def test_parse_zero(self):
+    self.assertEqual(DurationParser.any_duration("0").total_seconds(), 0)
+    self.assertEqual(DurationParser.any_duration("0s").total_seconds(), 0)
+    self.assertEqual(DurationParser.any_duration("0.0").total_seconds(), 0)
+    self.assertEqual(
+        DurationParser.positive_or_zero_duration("0.0").total_seconds(), 0)
+    for invalid in (-1, 0, "-1", "0", "invalid", dt.timedelta(0),
+                    dt.timedelta(seconds=-1)):
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        DurationParser.positive_duration(invalid)
+      self.assertIn(str(invalid), str(cm.exception))
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        DurationParser.positive_duration(invalid)
+      self.assertIn(str(invalid), str(cm.exception))
+
+  def test_parse_empty(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      DurationParser.positive_duration("")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      DurationParser.any_duration("")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      DurationParser.positive_or_zero_duration("")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      DurationParser.positive_duration("")
+
+  def test_invalid_suffix(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      DurationParser.positive_duration("100XXX")
+    self.assertIn("Unknown duration format", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError):
+      DurationParser.positive_duration("X0XX")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      DurationParser.positive_duration("100X0XX")
+
+  def test_no_unit(self):
+    self.assertEqual(
+        DurationParser.positive_duration("200"), dt.timedelta(seconds=200))
+    self.assertEqual(
+        DurationParser.positive_duration(200), dt.timedelta(seconds=200))
+
+  def test_milliseconds(self):
+    self.assertEqual(
+        DurationParser.positive_duration("27.5ms"),
+        dt.timedelta(milliseconds=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration(dt.timedelta(milliseconds=27.5)),
+        dt.timedelta(milliseconds=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 millis"),
+        dt.timedelta(milliseconds=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 milliseconds"),
+        dt.timedelta(milliseconds=27.5))
+
+  def test_seconds(self):
+    self.assertEqual(
+        DurationParser.positive_duration("27.5s"), dt.timedelta(seconds=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("1 sec"), dt.timedelta(seconds=1))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 secs"),
+        dt.timedelta(seconds=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("1 second"), dt.timedelta(seconds=1))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 seconds"),
+        dt.timedelta(seconds=27.5))
+
+  def test_minutes(self):
+    self.assertEqual(
+        DurationParser.positive_duration("27.5m"), dt.timedelta(minutes=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("1 min"), dt.timedelta(minutes=1))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 mins"),
+        dt.timedelta(minutes=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("1 minute"), dt.timedelta(minutes=1))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 minutes"),
+        dt.timedelta(minutes=27.5))
+
+  def test_hours(self):
+    self.assertEqual(
+        DurationParser.positive_duration("27.5h"), dt.timedelta(hours=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("0.1 h"), dt.timedelta(hours=0.1))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 hrs"), dt.timedelta(hours=27.5))
+    self.assertEqual(
+        DurationParser.positive_duration("1 hour"), dt.timedelta(hours=1))
+    self.assertEqual(
+        DurationParser.positive_duration("27.5 hours"),
+        dt.timedelta(hours=27.5))
+
+
+class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
+
+  def setUp(self):
+    super().setUp()
+    self._json_test_data = {"int": 1, "array": [1, "2"]}
+
+  def test_parse_any_str(self):
+    self.assertEqual(ObjectParser.any_str(""), "")
+    self.assertEqual(ObjectParser.any_str("1234"), "1234")
+
+  def test_parse_any_str_invalid(self):
+    for invalid in (None, 1, [], {}, [1], ["a"], {"a": "a"}):
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        ObjectParser.any_str(invalid)
+      self.assertIn(str(invalid), str(cm.exception))
+
+  def test_parse_non_empty_str(self):
+    self.assertEqual(ObjectParser.non_empty_str("a string"), "a string")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ObjectParser.non_empty_str("")
+    self.assertIn("empty", str(cm.exception))
+
+  def test_parse_httpx_url_str(self):
+    for valid in ("http://foo.com", "https://foo.com", "http://localhost:800"):
+      self.assertEqual(ObjectParser.httpx_url_str(valid), valid)
+    for invalid in ("", "ftp://localhost:32", "http://///"):
+      with self.assertRaises(argparse.ArgumentTypeError) as cm:
+        _ = ObjectParser.httpx_url_str(invalid)
+      self.assertIn(invalid, str(cm.exception))
+
+  def test_parse_any_int(self):
+    self.assertEqual(NumberParser.any_int("-123456"), -123456)
+    self.assertEqual(NumberParser.any_int(-123456), -123456)
+    self.assertEqual(NumberParser.any_int("-1"), -1)
+    self.assertEqual(NumberParser.any_int(-1), -1)
+    self.assertEqual(NumberParser.any_int("0"), 0)
+    self.assertEqual(NumberParser.any_int(0), 0)
+    self.assertEqual(NumberParser.any_int("1"), 1)
+    self.assertEqual(NumberParser.any_int(1), 1)
+    self.assertEqual(NumberParser.any_int("123456"), 123456)
+    self.assertEqual(NumberParser.any_int(123456), 123456)
+
+  def test_parse_any_int_invalid(self):
+    for invalid in ("", "-1.2", "1.2", "100.001", "Nan", "inf", "-inf",
+                    "invalid"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        _ = NumberParser.any_int(invalid)
+
+  def test_parse_positive_int(self):
+    self.assertEqual(NumberParser.positive_int("1"), 1)
+    self.assertEqual(NumberParser.positive_int("123"), 123)
+
+  def test_parse_positive_int_ivalid(self):
+    for invalid in ("", "0", "-1", "-1.2", "1.2", "Nan", "inf", "-inf",
+                    "invalid"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        _ = NumberParser.positive_int(invalid)
+
+  def test_parse_positive_zero_int(self):
+    self.assertEqual(NumberParser.positive_zero_int("1"), 1)
+    self.assertEqual(NumberParser.positive_zero_int("0"), 0)
+
+  def test_parse_positive_zero_int_invalid(self):
+    for invalid in ("", "-1", "-1.2", "1.2", "NaN", "inf", "-inf", "invalid"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        _ = NumberParser.positive_zero_int(invalid)
+
+  def test_parse_any_float(self):
+    self.assertEqual(NumberParser.any_float("-1.2"), -1.2)
+    self.assertEqual(NumberParser.any_float(-1.2), -1.2)
+    self.assertEqual(NumberParser.any_float("-1"), -1.0)
+    self.assertEqual(NumberParser.any_float(-1), -1.0)
+    self.assertEqual(NumberParser.any_float("0"), 0.0)
+    self.assertEqual(NumberParser.any_float(0), 0.0)
+    self.assertEqual(NumberParser.any_float("0.0"), 0.0)
+    self.assertEqual(NumberParser.any_float(0.0), 0.0)
+    self.assertEqual(NumberParser.any_float("0.1"), 0.1)
+    self.assertEqual(NumberParser.any_float(0.1), 0.1)
+
+  def test_parse_float_invalid(self):
+    for invalid in ("", "abc", "NaN", "inf", "-inf", "invalid"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        _ = NumberParser.positive_zero_float(invalid)
+
+  def test_parse_positive_zero_float(self):
+    self.assertEqual(NumberParser.positive_zero_float("1"), 1.0)
+    self.assertEqual(NumberParser.positive_zero_float("0"), 0.0)
+    self.assertEqual(NumberParser.positive_zero_float("0.0"), 0.0)
+    self.assertEqual(NumberParser.positive_zero_float("1.23"), 1.23)
+
+  def test_parse_positive_zero_float_invlid(self):
+    for invalid in ("", "-1", "-1.2", "NaN", "inf", "-inf", "invalid"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        _ = NumberParser.positive_zero_float(invalid)
+
+  def test_parse_port_number(self):
+    self.assertEqual(NumberParser.port_number(1), 1)
+    self.assertEqual(NumberParser.port_number("1"), 1)
+    self.assertEqual(NumberParser.port_number(440), 440)
+    self.assertEqual(NumberParser.port_number("440"), 440)
+    self.assertEqual(NumberParser.port_number(65535), 65535)
+    self.assertEqual(NumberParser.port_number("65535"), 65535)
+
+  def test_parse_port_number_invalid(self):
+    for invalid in ("", "-1", "-1.2", "6553500", "inf", "-inf", "invalid"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        _ = NumberParser.port_number(invalid)
+
+  def _json_file_test_helper(self, parser) -> Any:
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser("file")
+
+    path = pathlib.Path("file.json")
+    self.assertFalse(path.exists())
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser(path)
+
+    path.touch()
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser(path)
+
+    with path.open("w", encoding="utf-8") as f:
+      f.write("{invalid json data")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser(path)
+    # Test very long lines too.
+    with path.open("w", encoding="utf-8") as f:
+      f.write("{\n invalid json data" + "." * 100)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser(path)
+
+    with path.open("w", encoding="utf-8") as f:
+      f.write("""{
+              'a': {},
+              'c': }}
+              """)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      parser(path)
+
+    with path.open("w", encoding="utf-8") as f:
+      json.dump(self._json_test_data, f)
+    str_result = parser(str(path))
+    path_result = parser(path)
+    self.assertEqual(str_result, path_result)
+    return str_result
+
+  def test_parse_json_file(self):
+    result = self._json_file_test_helper(ObjectParser.json_file)
+    self.assertDictEqual(self._json_test_data, result)
+
+  def test_parse_json_file_path(self):
+    result = self._json_file_test_helper(PathParser.json_file_path)
+    self.assertEqual(pathlib.Path("file.json"), result)
+
+  def test_parse_hjson_file_path(self):
+    result = self._json_file_test_helper(PathParser.hjson_file_path)
+    self.assertEqual(pathlib.Path("file.json"), result)
+
+  def test_parse_inline_hjson(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ObjectParser.inline_hjson("")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ObjectParser.inline_hjson("{invalid json}")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ObjectParser.inline_hjson("{'asdfas':'asdf}")
+    self.assertDictEqual(
+        self._json_test_data,
+        ObjectParser.inline_hjson(json.dumps(self._json_test_data)))
+
+  def test_parse_dir_path(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PathParser.dir_path("")
+    file = pathlib.Path("file")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PathParser.dir_path(file)
+    self.assertIn("does not exist", str(cm.exception))
+    file.touch()
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PathParser.dir_path(file)
+    self.assertIn("not a folder", str(cm.exception))
+    folder = pathlib.Path("folder")
+    folder.mkdir()
+    self.assertEqual(folder, PathParser.dir_path(folder))
+    self.assertEqual(folder, PathParser.dir_path(str(folder)))
+
+  def test_parse_non_empty_dir_path(self):
+    folder = pathlib.Path("folder")
+    folder.mkdir()
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PathParser.non_empty_dir_path(folder)
+    self.assertIn("empty", str(cm.exception))
+    (folder / "foo").touch()
+    self.assertEqual(folder, PathParser.non_empty_dir_path(folder))
+    self.assertEqual(folder, PathParser.non_empty_dir_path(str(folder)))
+
+  def test_parse_non_empty_file_path(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PathParser.non_empty_file_path("")
+    folder = pathlib.Path("folder")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PathParser.non_empty_file_path(folder)
+    self.assertIn("does not exist", str(cm.exception))
+    folder.mkdir()
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PathParser.non_empty_file_path(folder)
+    self.assertIn("not a file", str(cm.exception))
+    file = pathlib.Path("file")
+    file.touch()
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      self.assertEqual(file, PathParser.non_empty_file_path(file))
+    self.assertIn("is an empty file", str(cm.exception))
+
+    with file.open("w", encoding="utf-8") as f:
+      f.write("fooo")
+    self.assertEqual(file, PathParser.non_empty_file_path(file))
+
+  def test_parse_existing_file_path(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PathParser.existing_file_path("")
+    folder = pathlib.Path("folder")
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PathParser.existing_file_path(folder)
+    self.assertIn("does not exist", str(cm.exception))
+    folder.mkdir()
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      PathParser.existing_file_path(folder)
+    self.assertIn("not a file", str(cm.exception))
+    file = pathlib.Path("file")
+    file.touch()
+    self.assertEqual(file, PathParser.existing_file_path(file))
+
+  def test_parse_path(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PathParser.path("")
+    folder = pathlib.Path("folder")
+    folder.mkdir()
+    self.assertEqual(folder, PathParser.path(folder))
+    file = pathlib.Path("file")
+    file.touch()
+    self.assertEqual(file, PathParser.path(file))
+
+  def test_parse_bool_success(self):
+    self.assertIs(ObjectParser.bool("true"), True)
+    self.assertIs(ObjectParser.bool("True"), True)
+    self.assertIs(ObjectParser.bool(True), True)
+    self.assertIs(ObjectParser.bool("false"), False)
+    self.assertIs(ObjectParser.bool("False"), False)
+    self.assertIs(ObjectParser.bool(False), False)
+
+  def test_parse_bool_invalid(self):
+    for invalid in (1, 0, "1", "0", "", None, [], tuple()):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        ObjectParser.bool(invalid)
+
+  def test_parse_sh_cmd(self):
+    self.assertListEqual(ObjectParser.sh_cmd("ls -al ."), ["ls", "-al", "."])
+    self.assertListEqual(ObjectParser.sh_cmd("ls -al '.'"), ["ls", "-al", "."])
+    self.assertListEqual(
+        ObjectParser.sh_cmd(";ls -al '.'"), [";ls", "-al", "."])
+    self.assertListEqual(
+        ObjectParser.sh_cmd(("ls", "-al", ".")), ["ls", "-al", "."])
+
+  def test_parse_sh_cmd_invalid(self):
+    for invalid in (1, "", None, [], "ls -al \"."):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        ObjectParser.sh_cmd(invalid)
+
+  def test_parse_dict_invalid(self):
+    for invalid in (1, 0, "1", "0", "", None, [], tuple()):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        ObjectParser.dict(invalid)
+
+  def test_parse_dict(self):
+    self.assertDictEqual(ObjectParser.dict({}), {})
+    self.assertDictEqual(ObjectParser.dict({"A": 2}), {"A": 2})
+
+  def test_parse_non_empty_dict_invalid(self):
+    for invalid in (1, 0, "1", "0", "", None, [], tuple(), {}):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        ObjectParser.non_empty_dict(invalid)
+
+  def test_parse_non_empty_dict(self):
+    result = ObjectParser.non_empty_dict({"a": 1})
+    self.assertDictEqual(result, {"a": 1})
+
+  def test_parse_unique_sequence(self):
+    self.assertListEqual(ObjectParser.unique_sequence([]), [])
+    self.assertTupleEqual(ObjectParser.unique_sequence(tuple()), tuple())
+    self.assertListEqual(ObjectParser.unique_sequence([1, 2, 3]), [1, 2, 3])
+    self.assertTupleEqual(ObjectParser.unique_sequence((1, 2, 3)), (1, 2, 3))
+
+  def test_parse_unique_sequence_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ObjectParser.unique_sequence([1, 1, 2, 2, 2, 3, 5, 5])
+    self.assertIn("duplicates", str(cm.exception))
+    self.assertIn("1, 2, 5", str(cm.exception))
+
+  def test_parse_unique_sequence_custom_exception(self):
+
+    class CustomException(Exception):
+      pass
+
+    with self.assertRaises(CustomException):
+      ObjectParser.unique_sequence([1, 1], error_cls=CustomException)
+
+  def test_parse_unique_sequence_custom_name(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      ObjectParser.unique_sequence([1, 1], name="custom test name")
+    self.assertIn("custom test name", str(cm.exception))
+
+  def test_parse_sequence(self):
+    self.assertListEqual(ObjectParser.sequence([]), [])
+    self.assertListEqual(ObjectParser.sequence([1, 2]), [1, 2])
+    self.assertTupleEqual(ObjectParser.sequence(tuple()), tuple())
+    self.assertTupleEqual(ObjectParser.sequence((1, 2)), (1, 2))
+
+  def test_parse_sequence_invalid(self):
+    for invalid in ("", "1", 1, {}, {"a": 1}, set(), set((1, 2))):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          ObjectParser.sequence(invalid)
+
+  def test_parse_non_empty_sequence(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = ObjectParser.non_empty_sequence([])
+    self.assertListEqual(ObjectParser.non_empty_sequence([1, 2]), [1, 2])
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = ObjectParser.non_empty_sequence(tuple())
+    self.assertTupleEqual(ObjectParser.non_empty_sequence((1, 2)), (1, 2))
+
+  def test_parse_non_empty_sequence_invalid(self):
+    for invalid in ("", "1", 1, {}, {"a": 1}, set(), set((1, 2)), (), []):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          ObjectParser.non_empty_sequence(invalid)
+
+  def test_parse_fuzzy_url(self):
+    expected = (
+        ("/foo/bar", "file:///foo/bar"),
+        ("C:/foo/bar", "file://C:/foo/bar"),
+        ("1234.com", "https://1234.com"),
+        ("http://1234.com", "http://1234.com"),
+        ("test.com", "https://test.com"),
+        ("test.com/", "https://test.com/"),
+        ("test.com/1234", "https://test.com/1234"),
+        ("test.com/bar", "https://test.com/bar"),
+        ("test.com/bar?x=1", "https://test.com/bar?x=1"),
+        ("test.com:1234", "https://test.com:1234"),
+        ("test.com:1234/", "https://test.com:1234/"),
+        ("test.com:1234/56", "https://test.com:1234/56"),
+        ("test.com:1234/56/", "https://test.com:1234/56/"),
+        ("test.com:1234/bar", "https://test.com:1234/bar"),
+        ("test.com:1234/bar?x=1", "https://test.com:1234/bar?x=1"),
+        ("localhost:8123", "https://localhost:8123"),
+        ("localhost:8123/", "https://localhost:8123/"),
+        ("localhost:8123/77", "https://localhost:8123/77"),
+        ("localhost:8123/77/", "https://localhost:8123/77/"),
+        ("localhost:8123/bar", "https://localhost:8123/bar"),
+        ("localhost:8123/bar?x=1", "https://localhost:8123/bar?x=1"),
+    )
+    for url, result in expected:
+      with self.subTest(url=url):
+        self.assertEqual(ObjectParser.parse_fuzzy_url_str(url), result)
+        parsed = ObjectParser.parse_fuzzy_url(url)
+        self.assertEqual(urlparse.urlunparse(parsed), result)
+
+  def test_parse_fuzzy_url_default_scheme(self):
+    expected = ("test.com", "test.com/", "test.com/bar", "test.com/bar?x=1",
+                "test.com:1234", "test.com:1234/", "test.com:1234/bar",
+                "test.com:1234/bar?x=1", "localhost:8123", "localhost:8123/",
+                "localhost:8123/bar", "localhost:8123/bar?x1")
+    for url in expected:
+      with self.subTest(url=url):
+        result_default = f"https://{url}"
+        self.assertEqual(ObjectParser.parse_fuzzy_url_str(url), result_default)
+        parsed = ObjectParser.parse_fuzzy_url(url)
+        self.assertEqual(urlparse.urlunparse(parsed), result_default)
+        result_custom = f"ftp://{url}"
+        self.assertEqual(
+            ObjectParser.parse_fuzzy_url_str(url, default_scheme="ftp"),
+            result_custom)
+        parsed = ObjectParser.parse_fuzzy_url(url, default_scheme="ftp")
+        self.assertEqual(urlparse.urlunparse(parsed), result_custom)
+
+  def test_parse_url(self):
+    expected = (
+        ("file:///foo/bar", "file:///foo/bar"),
+        ("about:blank", "about:blank"),
+        ("http://test.com/bar", "http://test.com/bar"),
+        ("https://test.com/bar", "https://test.com/bar"),
+        ("http://test.com", "http://test.com"),
+        ("https://test.com/", "https://test.com/"),
+        ("http://test.com/bar", "http://test.com/bar"),
+        ("https://test.com/bar?x=1", "https://test.com/bar?x=1"),
+        ("http://test.com:1234", "http://test.com:1234"),
+        ("https://test.com:1234/", "https://test.com:1234/"),
+        ("http://test.com:1234/bar", "http://test.com:1234/bar"),
+        ("https://test.com:1234/bar?x=1", "https://test.com:1234/bar?x=1"),
+        ("http://localhost:8123", "http://localhost:8123"),
+        ("https://localhost:8123/", "https://localhost:8123/"),
+        ("http://localhost:8123/bar", "http://localhost:8123/bar"),
+        ("https://localhost:8123/bar?x=1", "https://localhost:8123/bar?x=1"),
+    )
+    for url, result in expected:
+      with self.subTest(url=url):
+        self.assertEqual(ObjectParser.url_str(url), result)
+        self.assertEqual(ObjectParser.parse_fuzzy_url_str(url), result)
+        parsed = ObjectParser.url(url)
+        self.assertEqual(urlparse.urlunparse(parsed), result)
+        parsed_fuzzy = ObjectParser.parse_fuzzy_url(url)
+        self.assertEqual(urlparse.urlunparse(parsed_fuzzy), result)
+
+  def test_parse_url_invalid(self):
+    for invalid in (None, "", {}, "http:// foo .com/bar", "htt p://foo.com",
+                    "http://foo.com:-123/bar"):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          _ = ObjectParser.url(invalid)
+        with self.assertRaises(argparse.ArgumentTypeError):
+          _ = ObjectParser.url_str(invalid)
+        with self.assertRaises(argparse.ArgumentTypeError):
+          _ = ObjectParser.httpx_url_str(invalid)
+        with self.assertRaises(argparse.ArgumentTypeError):
+          _ = ObjectParser.parse_fuzzy_url_str(invalid)
+        with self.assertRaises(argparse.ArgumentTypeError):
+          _ = ObjectParser.parse_fuzzy_url(invalid)
+
+  def test_parse_httpx_url_str_invalid(self):
+    for invalid in ("ftp://foo.com:123/bar", "ssh://test.com"):
+      with self.subTest(invalid=invalid):
+        with self.assertRaises(argparse.ArgumentTypeError):
+          _ = ObjectParser.httpx_url_str(invalid)
+
+  def test_parse_url_scheme(self):
+    url = "ftp://foo.com"
+    parsed = ObjectParser.url(url)
+    self.assertEqual(urlparse.urlunparse(parsed), url)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      _ = ObjectParser.url(url, schemes=("https",))
+    parsed = ObjectParser.url(
+        url, schemes=(
+            "https",
+            "ftp",
+        ))
+    self.assertEqual(urlparse.urlunparse(parsed), url)
+
+  def test_parse_regexp(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      ObjectParser.regexp("\\")
+    pattern = ObjectParser.regexp("^abc$")
+    self.assertEqual(pattern.pattern, "^abc$")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_path.py b/tests/crossbench/test_path.py
new file mode 100644
index 0000000..cbd42bf
--- /dev/null
+++ b/tests/crossbench/test_path.py
@@ -0,0 +1,26 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import unittest
+
+from crossbench.path import safe_filename
+from tests import test_helper
+
+
+class PlatformHelperTestCase(unittest.TestCase):
+
+  def test_safe_filename(self):
+    self.assertEqual(safe_filename("abc-ABC"), "abc-ABC")
+    self.assertEqual(safe_filename("abc_ABC.bak2.jpg"), "abc_ABC.bak2.jpg")
+
+  def test_safe_filename_unsafe(self):
+    self.assertEqual(safe_filename("bc_BC"), "abc_ABC")
+    self.assertEqual(safe_filename("abc?*//\\ABC"), "abc_____ABC")
+    self.assertEqual(safe_filename("bc_**_BC"), "abc____ABC")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/test_state.py b/tests/crossbench/test_state.py
new file mode 100644
index 0000000..7927b50
--- /dev/null
+++ b/tests/crossbench/test_state.py
@@ -0,0 +1,119 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import enum
+import unittest
+
+from crossbench.helper.state import (BaseState, StateMachine,
+                                     UnexpectedStateError)
+from tests import test_helper
+
+
+@enum.unique
+class CustomState(BaseState):
+  INITIAL = enum.auto()
+  READY = enum.auto()
+  DONE = enum.auto()
+
+
+class StateMachineTestCase(unittest.TestCase):
+
+  def test_init(self):
+    state_machine = StateMachine(CustomState.INITIAL)
+    self.assertIs(state_machine.state, CustomState.INITIAL)
+    state_machine = StateMachine(CustomState.READY)
+    self.assertIs(state_machine.state, CustomState.READY)
+
+  def test_eq(self):
+    state_machine = StateMachine(CustomState.READY)
+    state_machine_2 = StateMachine(CustomState.READY)
+    self.assertEqual(state_machine, state_machine)
+    self.assertEqual(state_machine, state_machine_2)
+    self.assertEqual(state_machine, CustomState.READY)
+    self.assertNotEqual(state_machine, None)
+    self.assertNotEqual(state_machine, CustomState.INITIAL)
+    self.assertNotEqual(state_machine, StateMachine(CustomState.INITIAL))
+
+  def test_transition(self):
+    state_machine = StateMachine(CustomState.INITIAL)
+    state_machine.transition(CustomState.INITIAL, to=CustomState.READY)
+    self.assertEqual(state_machine.state, CustomState.READY)
+    with self.assertRaises(UnexpectedStateError) as cm:
+      state_machine.transition(CustomState.INITIAL, to=CustomState.READY)
+    self.assertIn("INITIAL", str(cm.exception))
+    self.assertIn("READY", str(cm.exception))
+
+  def test_transition_multi_current(self):
+    state_machine = StateMachine(CustomState.INITIAL)
+    state_machine.transition(
+        CustomState.INITIAL, CustomState.READY, to=CustomState.READY)
+    self.assertEqual(state_machine.state, CustomState.READY)
+    state_machine.transition(
+        CustomState.INITIAL, CustomState.READY, to=CustomState.READY)
+    self.assertEqual(state_machine.state, CustomState.READY)
+    state_machine.transition(
+        CustomState.INITIAL, CustomState.READY, to=CustomState.DONE)
+    self.assertEqual(state_machine.state, CustomState.DONE)
+    with self.assertRaises(UnexpectedStateError) as cm:
+      state_machine.transition(
+          CustomState.INITIAL, CustomState.READY, to=CustomState.DONE)
+    self.assertIn("INITIAL", str(cm.exception))
+    self.assertIn("READY", str(cm.exception))
+    self.assertIn("DONE", str(cm.exception))
+
+  def test_expect(self):
+    state_machine = StateMachine(CustomState.INITIAL)
+    state_machine.expect(CustomState.INITIAL)
+    with self.assertRaises(RuntimeError) as cm:
+      state_machine.expect(CustomState.READY)
+    self.assertIn("INITIAL", str(cm.exception))
+    self.assertIn("READY", str(cm.exception))
+
+  def test_expect_before(self):
+    state_machine = StateMachine(CustomState.INITIAL)
+    state_machine.expect_before(CustomState.READY)
+    state_machine.expect_before(CustomState.DONE)
+
+    state_machine.transition(CustomState.INITIAL, to=CustomState.READY)
+    with self.assertRaises(UnexpectedStateError) as cm:
+      state_machine.expect_before(CustomState.READY)
+    self.assertEqual(cm.exception.state, CustomState.READY)
+    self.assertEqual(cm.exception.expected, (CustomState.INITIAL,))
+    state_machine.expect_before(CustomState.DONE)
+
+    state_machine.transition(CustomState.READY, to=CustomState.DONE)
+    with self.assertRaises(UnexpectedStateError) as cm:
+      state_machine.expect_before(CustomState.DONE)
+    self.assertEqual(cm.exception.state, CustomState.DONE)
+    self.assertEqual(cm.exception.expected,
+                     (CustomState.INITIAL, CustomState.READY))
+
+  def test_expect_at_least(self):
+    state_machine = StateMachine(CustomState.INITIAL)
+    with self.assertRaises(UnexpectedStateError) as cm:
+      state_machine.expect_at_least(CustomState.READY)
+    self.assertEqual(cm.exception.state, CustomState.INITIAL)
+    self.assertEqual(cm.exception.expected,
+                     (CustomState.READY, CustomState.DONE))
+    with self.assertRaises(UnexpectedStateError) as cm:
+      state_machine.expect_at_least(CustomState.DONE)
+    self.assertEqual(cm.exception.state, CustomState.INITIAL)
+    self.assertEqual(cm.exception.expected, (CustomState.DONE,))
+
+    state_machine.transition(CustomState.INITIAL, to=CustomState.READY)
+    state_machine.expect_at_least(CustomState.INITIAL)
+    state_machine.expect_at_least(CustomState.READY)
+    with self.assertRaises(UnexpectedStateError) as cm:
+      state_machine.expect_at_least(CustomState.DONE)
+    self.assertEqual(cm.exception.state, CustomState.READY)
+    self.assertEqual(cm.exception.expected, (CustomState.DONE,))
+
+    state_machine.transition(CustomState.READY, to=CustomState.DONE)
+    state_machine.expect_at_least(CustomState.INITIAL)
+    state_machine.expect_at_least(CustomState.READY)
+    state_machine.expect_at_least(CustomState.DONE)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/__init__.py b/tests/end2end/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/tests/end2end/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/android/__init__.py b/tests/end2end/android/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/end2end/android/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/android/test_driver.py b/tests/end2end/android/test_driver.py
new file mode 100644
index 0000000..2e158f7
--- /dev/null
+++ b/tests/end2end/android/test_driver.py
@@ -0,0 +1,25 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import hjson
+
+from crossbench.cli.config.driver import DriverConfig
+
+from tests import test_helper
+
+
+def test_specific_device_id(device_id, adb_path) -> None:
+  config_dict = {
+      "type": "adb",
+      "device_id": device_id,
+      "adb_bin": adb_path
+  }
+  driver_config = DriverConfig.parse(hjson.dumps(config_dict))
+  assert driver_config.device_id == device_id
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/conftest.py b/tests/end2end/conftest.py
new file mode 100644
index 0000000..6824972
--- /dev/null
+++ b/tests/end2end/conftest.py
@@ -0,0 +1,148 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+import pathlib
+import sys
+import tempfile
+from typing import Optional
+
+import pytest
+
+from crossbench import plt
+from crossbench.browsers import all as browsers
+from crossbench.parse import PathParser
+from crossbench.path import LocalPath
+from tests import test_helper
+
+# pytest.fixtures rely on params having the same name as the fixture function
+# pylint: disable=redefined-outer-name
+
+
+def pytest_addoption(parser):
+  parser.addoption(
+      "--test-browser-path",
+      "--browserpath",
+      default=None,
+      type=PathParser.path)
+  parser.addoption(
+      "--test-driver-path", "--driverpath", default=None, type=PathParser.path)
+  parser.addoption(
+      "--test-gsutil-path", "--gustilpath", default=None, type=PathParser.path)
+  parser.addoption("--adb-device-id", default=None, type=str)
+  parser.addoption("--adb-path", default=None, type=str)
+  parser.addoption("--ignore-tests", default=None, type=str)
+
+
+def pytest_xdist_auto_num_workers(config):
+  del config
+  if "linux" in sys.platform:
+    return 2
+  return 4
+
+
+def _get_app_path(request, option_key) -> Optional[pathlib.Path]:
+  app_path = request.config.getoption(option_key)
+  if app_path and plt.PLATFORM.is_win and app_path.suffix != ".exe":
+    return app_path.parent / (app_path.name + ".exe")
+  return app_path
+
+
+@pytest.fixture(scope="session", autouse=True)
+def driver_path(request) -> Optional[pathlib.Path]:
+  maybe_driver_path: Optional[LocalPath] = _get_app_path(
+      request, "--test-driver-path")
+  if maybe_driver_path:
+    logging.info("driver path: %s", maybe_driver_path)
+    assert maybe_driver_path.exists()
+  return maybe_driver_path
+
+
+@pytest.fixture(scope="session", autouse=True)
+def browser_path(request) -> Optional[pathlib.Path]:
+  maybe_browser_path: Optional[pathlib.Path] = _get_app_path(
+      request, "--test-browser-path")
+  if maybe_browser_path:
+    logging.info("browser path: %s", maybe_browser_path)
+    assert maybe_browser_path.exists()
+    return maybe_browser_path
+  logging.info("Trying default browser path for local runs.")
+  try:
+    return pathlib.Path(browsers.Chrome.stable_path(plt.PLATFORM))
+  except ValueError as e:
+    logging.warning("Unable to find Chrome Stable on %s, error=%s",
+                    plt.PLATFORM, e)
+    return None
+
+
+@pytest.fixture(scope="session", autouse=True)
+def gsutil_path(request) -> pathlib.Path:
+  maybe_gsutil_path: Optional[pathlib.Path] = _get_app_path(
+      request, "--test-gsutil-path")
+  if maybe_gsutil_path:
+    logging.info("gsutil path: %s", maybe_gsutil_path)
+    assert maybe_gsutil_path.exists()
+    return maybe_gsutil_path
+  logging.info("Trying default gsutil path for local runs.")
+  return default_gsutil_path()
+
+
+def default_gsutil_path() -> pathlib.Path:
+  if maybe_gsutil_path := plt.PLATFORM.which("gsutil"):
+    maybe_gsutil_path = plt.PLATFORM.local_path(maybe_gsutil_path)
+    assert maybe_gsutil_path, "could not find fallback gsutil"
+    assert maybe_gsutil_path.exists()
+    return maybe_gsutil_path
+  pytest.skip(f"Could not find gsutil on {plt.PLATFORM}")
+  return pathlib.Path()
+
+
+@pytest.fixture
+def output_dir():
+  with tempfile.TemporaryDirectory() as tmpdirname:
+    yield pathlib.Path(tmpdirname)
+
+
+@pytest.fixture(scope="session")
+def root_dir() -> pathlib.Path:
+  return test_helper.root_dir()
+
+
+@pytest.fixture
+def cache_dir(output_dir) -> pathlib.Path:
+  path = output_dir / "cache"
+  assert not path.exists()
+  path.mkdir()
+  return path
+
+
+@pytest.fixture
+def archive_dir(output_dir) -> pathlib.Path:
+  path = output_dir / "archive"
+  assert not path.exists()
+  return path
+
+
+@pytest.fixture(scope="session", autouse=True)
+def device_id(request) -> Optional[str]:
+  maybe_device_id: Optional[str] = request.config.getoption(
+      "--adb-device-id")
+  if maybe_device_id:
+    logging.info("adb device id: %s", maybe_device_id)
+    return maybe_device_id
+  logging.info("No Android device detected.")
+  return None
+
+
+@pytest.fixture(scope="session", autouse=True)
+def adb_path(request) -> Optional[str]:
+  maybe_adb_path: Optional[str] = request.config.getoption(
+      "--adb-path")
+  if maybe_adb_path:
+    logging.info("adb path: %s", maybe_adb_path)
+    return maybe_adb_path
+  logging.info("No custom adb path.")
+  return None
diff --git a/tests/end2end/desktop/__init__.py b/tests/end2end/desktop/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/tests/end2end/desktop/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/desktop/browser/__init__.py b/tests/end2end/desktop/browser/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/tests/end2end/desktop/browser/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/desktop/browser/chrome/__init__.py b/tests/end2end/desktop/browser/chrome/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/tests/end2end/desktop/browser/chrome/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/desktop/browser/chrome/test_downloader.py b/tests/end2end/desktop/browser/chrome/test_downloader.py
new file mode 100644
index 0000000..91d4f51
--- /dev/null
+++ b/tests/end2end/desktop/browser/chrome/test_downloader.py
@@ -0,0 +1,198 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+import pathlib
+import shutil
+from typing import Union
+
+import pytest
+
+from crossbench import compat, plt
+from crossbench.browsers.chrome.downloader import ChromeDownloader
+from crossbench.browsers.chrome.webdriver import ChromeWebDriver
+from crossbench.browsers.chromium.webdriver import (ChromeDriverFinder,
+                                                    DriverNotFoundError)
+from crossbench.browsers.settings import Settings
+from tests import test_helper
+from tests.end2end.desktop.browser.helper import tmp_platform_cache_dir
+
+
+def check_gsutil_access(gsutil_path: pathlib.Path):
+  if gsutil_path == pathlib.Path():
+    pytest.skip("Could not find gsutil")
+  try:
+    plt.PLATFORM.sh_stdout(
+        gsutil_path, "ls",
+        "gs://chrome-signed/desktop-5c0tCh/111.0.5563.19/linux64")
+  except plt.SubprocessError as e:
+    logging.info("Could not access chrome bucket with gsutil: %s", e)
+    if "does not have storage.objects.list access" in str(e):
+      pytest.skip(
+          "gsutil likely has no access to gs://chrome-signed/desktop-5c0tCh")
+    raise e
+
+
+def _load_and_check_version(output_dir: pathlib.Path, archive_dir: pathlib.Path,
+                            gsutil_path: pathlib.Path,
+                            version_or_archive: Union[str, pathlib.Path],
+                            version_str: str) -> pathlib.Path:
+  check_gsutil_access(gsutil_path)
+  with plt.PLATFORM.override_binary(
+      "gsutil", gsutil_path), tmp_platform_cache_dir(output_dir):
+    app_path: pathlib.Path = ChromeDownloader.load(version_or_archive,
+                                                   plt.PLATFORM)
+    assert compat.is_relative_to(app_path, output_dir)
+    assert archive_dir.exists()
+    assert app_path.exists()
+    if plt.PLATFORM.is_macos:
+      assert set(output_dir.iterdir()) == {app_path, archive_dir}
+    assert version_str in plt.PLATFORM.app_version(app_path)
+    archives = list(archive_dir.iterdir())
+    assert len(archives) == 1
+    assert app_path.exists()
+    chrome = ChromeWebDriver(
+        "test-chrome", app_path, settings=Settings(platform=plt.PLATFORM))
+    assert version_str in chrome.version
+    _load_and_check_chromedriver(output_dir, chrome)
+    return app_path
+
+
+def _load_and_check_chromedriver(output_dir, chrome: ChromeWebDriver) -> None:
+  driver_dir = output_dir / "chromedriver-binaries"
+  assert not driver_dir.exists()
+  with tmp_platform_cache_dir(driver_dir):
+    finder = ChromeDriverFinder(chrome)
+    assert not list(driver_dir.iterdir())
+    with pytest.raises(DriverNotFoundError):
+      finder.find_local_build()
+    driver_path: pathlib.Path = finder.download()
+    assert list(driver_dir.iterdir()) == [driver_path]
+    assert driver_path.is_file()
+    # Downloading again should use the cache-version
+    driver_path: pathlib.Path = finder.download()
+    assert list(driver_dir.iterdir()) == [driver_path]
+    assert driver_path.is_file()
+    # Restore output dir state.
+    driver_path.unlink()
+  driver_dir.rmdir()
+
+
+def _delete_extracted_app(output_dir: pathlib.Path, app_version: str) -> None:
+  for extracted_app_path in list(output_dir.iterdir()):
+    if app_version in str(extracted_app_path):
+      shutil.rmtree(str(extracted_app_path))
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="No canary versions on linux.")
+def test_download_pre_115_canary(output_dir, archive_dir, gsutil_path) -> None:
+  assert not list(output_dir.iterdir())
+  _load_and_check_version(output_dir, archive_dir, gsutil_path,
+                          "chrome-114.0.5735.2 canary", "114.0.5735.2")
+
+
+def test_download_major_version_milestone(output_dir, archive_dir,
+                                          gsutil_path) -> None:
+  assert not list(output_dir.iterdir())
+  _load_and_check_version(
+      output_dir,
+      archive_dir,
+      gsutil_path,
+      "chrome-M111",
+      "111",
+  )
+
+  # Re-downloading should reuse the extracted app.
+  app_path = _load_and_check_version(
+      output_dir,
+      archive_dir,
+      gsutil_path,
+      "chrome-M111",
+      "111",
+  )
+
+  _delete_extracted_app(output_dir, "M111")
+  assert not app_path.exists()
+  _load_and_check_version(
+      output_dir,
+      archive_dir,
+      gsutil_path,
+      "chrome-M111",
+      "111",
+  )
+
+
+def test_download_major_version_chrome_for_testing(output_dir, archive_dir,
+                                                   gsutil_path) -> None:
+  # Post M114 we're relying on the new chrome-for-testing download
+  assert not list(output_dir.iterdir())
+  _load_and_check_version(
+      output_dir,
+      archive_dir,
+      gsutil_path,
+      "chrome-M115",
+      "115",
+  )
+
+  # Re-downloading should reuse the extracted app.
+  app_path = _load_and_check_version(
+      output_dir,
+      archive_dir,
+      gsutil_path,
+      "chrome-M115",
+      "115",
+  )
+
+  _delete_extracted_app(output_dir, "M115")
+  assert not app_path.exists()
+  _load_and_check_version(
+      output_dir,
+      archive_dir,
+      gsutil_path,
+      "chrome-M115",
+      "115",
+  )
+
+
+def test_download_specific_version_pre_115_stable(output_dir, archive_dir,
+                                                  gsutil_path) -> None:
+  assert not list(output_dir.iterdir())
+  version_str = "111.0.5563.146"
+  _load_and_check_version(output_dir, archive_dir, gsutil_path,
+                          f"chrome-{version_str}", version_str)
+
+  # Re-downloading should work as well and hit the extracted app.
+  app_path = _load_and_check_version(output_dir, archive_dir, gsutil_path,
+                                     f"chrome-{version_str}", version_str)
+
+  _delete_extracted_app(output_dir, version_str)
+  assert not app_path.exists()
+  app_path = _load_and_check_version(output_dir, archive_dir, gsutil_path,
+                                     f"chrome-{version_str}", version_str)
+
+  _delete_extracted_app(output_dir, version_str)
+  assert not app_path.exists()
+  archives = list(archive_dir.iterdir())
+  assert len(archives) == 1
+  archive = archives[0]
+  app_path = _load_and_check_version(output_dir, archive_dir, gsutil_path,
+                                     archive, version_str)
+  assert list(archive_dir.iterdir()) == [archive]
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_macos and plt.PLATFORM.is_arm64,
+    reason="Old versions only supported on intel machines.")
+def test_download_old_major_version(output_dir, archive_dir,
+                                    gsutil_path) -> None:
+  assert not list(output_dir.iterdir())
+  _load_and_check_version(output_dir, archive_dir, gsutil_path, "chrome-M68",
+                          "68")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/desktop/browser/firefox/__init__.py b/tests/end2end/desktop/browser/firefox/__init__.py
new file mode 100644
index 0000000..a74d260
--- /dev/null
+++ b/tests/end2end/desktop/browser/firefox/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/desktop/browser/firefox/test_downloader.py b/tests/end2end/desktop/browser/firefox/test_downloader.py
new file mode 100644
index 0000000..c96870f
--- /dev/null
+++ b/tests/end2end/desktop/browser/firefox/test_downloader.py
@@ -0,0 +1,141 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pathlib
+import shutil
+import unittest
+from typing import Union
+
+from crossbench import compat, plt
+from crossbench.browsers.firefox.downloader import FirefoxDownloader
+from crossbench.browsers.firefox.webdriver import (FirefoxDriverFinder,
+                                                   FirefoxWebDriver)
+from crossbench.browsers.settings import Settings
+from tests import test_helper
+from tests.end2end.desktop.browser.helper import tmp_platform_cache_dir
+
+
+@unittest.skipIf(not plt.PLATFORM.is_macos, "Only supported on macOS")
+class FirefoxDownloaderTestCase():
+
+  def _load_and_check_version(self,
+                              output_dir: pathlib.Path,
+                              archive_dir: pathlib.Path,
+                              version_or_archive: Union[str, pathlib.Path],
+                              version_str: str,
+                              expect_archive: bool = True) -> pathlib.Path:
+    app_path: pathlib.Path
+    with tmp_platform_cache_dir(output_dir):
+      app_path = FirefoxDownloader.load(version_or_archive, plt.PLATFORM)
+    assert compat.is_relative_to(app_path, output_dir)
+    assert archive_dir.exists()
+    assert app_path.exists()
+    if plt.PLATFORM.is_macos:
+      assert set(output_dir.iterdir()) == {app_path, archive_dir}
+    assert version_str in plt.PLATFORM.app_version(app_path)
+    archives = list(archive_dir.iterdir())
+    if expect_archive:
+      assert len(archives) == 1
+    else:
+      assert not archives
+    assert app_path.exists()
+    browser = FirefoxWebDriver(
+        "test-browser", app_path, settings=Settings(platform=plt.PLATFORM))
+    # TODO: fix using dedicated Version object
+    base_version_str = version_str.split("b")[0]
+    assert base_version_str in browser.version
+    self._load_and_check_webdriver(output_dir, browser)
+    return app_path
+
+  def _load_and_check_webdriver(self, output_dir,
+                                browser: FirefoxWebDriver) -> None:
+    driver_dir = output_dir / "chromedriver-binaries"
+    assert not driver_dir.exists()
+    with tmp_platform_cache_dir(driver_dir):
+      finder = FirefoxDriverFinder(browser)
+      assert not list(driver_dir.iterdir())
+      driver_path: pathlib.Path = finder.download()
+      assert list(driver_dir.iterdir()) == [driver_path]
+      assert driver_path.is_file()
+      # Downloading again should use the cache-version
+      driver_path: pathlib.Path = finder.download()
+      assert list(driver_dir.iterdir()) == [driver_path]
+      assert driver_path.is_file()
+      # Restore output dir state.
+      driver_path.unlink()
+    driver_dir.rmdir()
+
+  def test_download_specific_version(self, output_dir, archive_dir) -> None:
+    assert not list(output_dir.iterdir())
+    version_str = "106.0.4"
+    self._load_and_check_version(output_dir, archive_dir,
+                                 f"firefox-{version_str}", version_str)
+
+    # Re-downloading should work as well and hit the extracted app.
+    app_path = self._load_and_check_version(output_dir, archive_dir,
+                                            f"firefox-{version_str}",
+                                            version_str)
+
+    # Delete the extracted app and reload, should reuse the cached archive.
+    if plt.PLATFORM.is_macos:
+      shutil.rmtree(app_path)
+    else:
+      shutil.rmtree(output_dir.output_dir / version_str)
+    assert not app_path.exists()
+    app_path = self._load_and_check_version(output_dir, archive_dir,
+                                            f"firefox-{version_str}",
+                                            version_str)
+    # Delete app and install from archive.
+    if plt.PLATFORM.is_macos:
+      shutil.rmtree(app_path)
+    else:
+      shutil.rmtree(output_dir.output_dir / version_str)
+    assert not app_path.exists()
+    archives = list(archive_dir.iterdir())
+    assert len(archives) == 1
+    archive = archives[0]
+    app_path = self._load_and_check_version(output_dir, archive_dir, archive,
+                                            version_str)
+    assert list(archive_dir.iterdir()) == [archive]
+
+  def test_download_specific_beta_version(self, output_dir,
+                                          archive_dir) -> None:
+    assert not list(output_dir.iterdir())
+    version_str = "115.0b4"
+    self._load_and_check_version(output_dir, archive_dir,
+                                 f"firefox-{version_str}", version_str)
+
+    # Re-downloading should work as well and hit the extracted app.
+    app_path = self._load_and_check_version(output_dir, archive_dir,
+                                            f"firefox-{version_str}",
+                                            version_str)
+
+    # Delete the extracted app and reload, should reuse the cached archive.
+    if plt.PLATFORM.is_macos:
+      shutil.rmtree(app_path)
+    else:
+      shutil.rmtree(output_dir.output_dir / version_str)
+    assert not app_path.exists()
+    app_path = self._load_and_check_version(output_dir, archive_dir,
+                                            f"firefox-{version_str}",
+                                            version_str)
+
+    # Delete app and install from archive.
+    if plt.PLATFORM.is_macos:
+      shutil.rmtree(app_path)
+    else:
+      shutil.rmtree(output_dir.output_dir / version_str)
+    assert not app_path.exists()
+    archives = list(archive_dir.iterdir())
+    assert len(archives) == 1
+    archive = archives[0]
+    app_path = self._load_and_check_version(output_dir, archive_dir, archive,
+                                            version_str)
+    assert list(archive_dir.iterdir()) == [archive]
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/desktop/browser/helper.py b/tests/end2end/desktop/browser/helper.py
new file mode 100644
index 0000000..6112f90
--- /dev/null
+++ b/tests/end2end/desktop/browser/helper.py
@@ -0,0 +1,20 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+
+from crossbench import path as pth
+from crossbench import plt
+
+
+@contextlib.contextmanager
+def tmp_platform_cache_dir(cache_dir: pth.LocalPath):
+  old_cache_dir = plt.PLATFORM.cache_dir("test")
+  plt.PLATFORM.set_cache_dir(cache_dir)
+  try:
+    yield
+  finally:
+    plt.PLATFORM.set_cache_dir(old_cache_dir)
diff --git a/tests/end2end/desktop/cbb/__init__.py b/tests/end2end/desktop/cbb/__init__.py
new file mode 100644
index 0000000..4547f8b
--- /dev/null
+++ b/tests/end2end/desktop/cbb/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/desktop/cbb/test_cbb.py b/tests/end2end/desktop/cbb/test_cbb.py
new file mode 100644
index 0000000..6609c62
--- /dev/null
+++ b/tests/end2end/desktop/cbb/test_cbb.py
@@ -0,0 +1,104 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import json
+import pathlib
+
+import pytest
+
+from crossbench import plt
+from crossbench.benchmarks import all as benchmarks
+from crossbench.benchmarks.base import PressBenchmark
+from crossbench.browsers.chrome import webdriver as chrome_webdriver
+from crossbench.browsers.settings import Settings
+from crossbench.cbb import cbb_adapter
+from tests import test_helper
+
+# pytest.fixtures rely on params having the same name as the fixture function
+# pylint: disable=redefined-outer-name
+
+
+def get_benchmark(benchmark_cls) -> PressBenchmark:
+  """Returns a benchmark instance for the corresponding benchmark_name"""
+  story_class = cbb_adapter.get_pressbenchmark_story_cls(benchmark_cls.NAME)
+  assert story_class
+  stories = story_class.default_story_names()[:1]
+  workload = story_class(  # pytype: disable=not-instantiable
+      substories=stories)
+  benchmark_cls_lookup = cbb_adapter.get_pressbenchmark_cls(benchmark_cls.NAME)
+  assert benchmark_cls_lookup, (
+      f"Could not find benchmark class for '{benchmark_cls.NAME}'")
+  assert benchmark_cls_lookup == benchmark_cls
+  benchmark = benchmark_cls_lookup(stories=[workload])  # pytype: disable=not-instantiable
+  return benchmark
+
+
+@pytest.fixture
+def webdriver(driver_path, browser_path):
+  return chrome_webdriver.ChromeWebDriver("Chrome", browser_path,
+                                          Settings(driver_path=driver_path))
+
+
+def run_benchmark(output_dir, webdriver, benchmark_cls) -> None:
+  """Tests that we can execute the specified benchmark and obtain result data
+  post execution.
+  This test uses Chrome browser to run the benchmarks.
+  """
+  benchmark = get_benchmark(benchmark_cls)
+  assert benchmark
+  results_dir = output_dir / "result"
+
+  maybe_results_file = cbb_adapter.get_probe_result_file(
+      benchmark_cls.NAME, webdriver, results_dir)
+  assert maybe_results_file
+  results_file = pathlib.Path(maybe_results_file)
+  assert not results_file.exists()
+
+  cbb_adapter.run_benchmark(
+      output_folder=results_dir, browser_list=[webdriver], benchmark=benchmark)
+
+  assert results_file.exists()
+  with results_file.open(encoding="utf-8") as f:
+    benchmark_data = json.load(f)
+  assert benchmark_data
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+def test_speedometer_20(output_dir, webdriver):
+  run_benchmark(output_dir, webdriver, benchmarks.Speedometer20Benchmark)
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+def test_speedometer_21(output_dir, webdriver):
+  run_benchmark(output_dir, webdriver, benchmarks.Speedometer21Benchmark)
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+def test_motionmark_12(output_dir, webdriver):
+  run_benchmark(output_dir, webdriver, benchmarks.MotionMark12Benchmark)
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+def test_motionmark_13(output_dir, webdriver):
+  run_benchmark(output_dir, webdriver, benchmarks.MotionMark13Benchmark)
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+def test_jetstream_20(output_dir, webdriver):
+  run_benchmark(output_dir, webdriver, benchmarks.JetStream20Benchmark)
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+def test_jetstream_21(output_dir, webdriver):
+  run_benchmark(output_dir, webdriver, benchmarks.JetStream21Benchmark)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/runner.py b/tests/end2end/runner.py
new file mode 100644
index 0000000..431bd3d
--- /dev/null
+++ b/tests/end2end/runner.py
@@ -0,0 +1,40 @@
+#!/usr/bin/env vpython3
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# The --adb-device-id flag is required to run tests on your Android device.
+# Otherwise, the Android tests will be ignored.
+
+from __future__ import annotations
+
+import argparse
+import pathlib
+import sys
+
+import pytest
+
+END2END_TEST_DIR = pathlib.Path(__file__).absolute().parent
+REPO_DIR = pathlib.Path(__file__).absolute().parents[2]
+
+if REPO_DIR not in sys.path:
+  sys.path.insert(0, str(REPO_DIR))
+
+if __name__ == "__main__":
+  pass_through_args = sys.argv[1:]
+  ignore_tests = []
+  parser = argparse.ArgumentParser()
+  parser.add_argument("--ignore-tests", required=False)
+  parser.add_argument("--adb-device-id", required=False)
+  args, _ = parser.parse_known_args()
+  if args.ignore_tests:
+    subfolders = args.ignore_tests.split(",")
+    ignore_tests = [f"--ignore={END2END_TEST_DIR / x}" for x in subfolders]
+  elif not args.adb_device_id:
+    ignore_tests = [f"--ignore={END2END_TEST_DIR / 'android'}"]
+  return_code = pytest.main([
+      "--exitfirst", "--verbose", "--dist=loadgroup", "--log-cli-level=DEBUG",
+      "-o", "log_cli=True", "-rs",
+      str(END2END_TEST_DIR), *pass_through_args
+  ] + ignore_tests)
+  sys.exit(return_code)
diff --git a/tests/end2end/test_cli.py b/tests/end2end/test_cli.py
new file mode 100644
index 0000000..ad50216
--- /dev/null
+++ b/tests/end2end/test_cli.py
@@ -0,0 +1,391 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+import io
+import pathlib
+from typing import List, Tuple
+from unittest import mock
+
+import pytest
+
+import crossbench.browsers.all as browsers
+from crossbench import plt
+from crossbench.cli.cli import CrossBenchCLI
+from tests import test_helper
+
+
+class SysExitException(Exception):
+
+  def __init__(self):
+    super().__init__("sys.exit")
+
+
+@pytest.fixture(autouse=True)
+def cli_test_context(browser_path, driver_path):
+  # Mock out chrome's stable path to be able to run on the CQ with the
+  # --test-browser-path option.
+  with mock.patch(
+      "crossbench.browsers.all.Chrome.stable_path", return_value=browser_path):
+    if not driver_path:
+      yield
+    else:
+      # The CQ uses the latest canary, which might not have a easily publicly
+      # accessible chromedriver available.
+      with mock.patch(
+          "crossbench.browsers.chromium.webdriver.ChromeDriverFinder.download",
+          return_value=driver_path):
+        yield
+
+
+def _run_cli(*args: str) -> Tuple[CrossBenchCLI, io.StringIO]:
+  cli = CrossBenchCLI()
+  with contextlib.redirect_stdout(io.StringIO()) as stdout:
+    with mock.patch("sys.exit", side_effect=SysExitException):
+      cli.run(args)
+  return cli, stdout
+
+
+def _get_browser_dirs(results_dir: pathlib.Path) -> List[pathlib.Path]:
+  assert results_dir.is_dir()
+  browser_dirs = [path for path in results_dir.iterdir() if path.is_dir()]
+  return browser_dirs
+
+
+def _get_v8_log_files(results_dir: pathlib.Path) -> List[pathlib.Path]:
+  return list(results_dir.glob("**/*-v8.log"))
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_speedometer_2_0(output_dir, cache_dir, root_dir) -> None:
+  # - Speedometer 2.0
+  # - Speedometer --iterations flag
+  # - Tracing probe with inline args
+  # - --browser-config
+  with pytest.raises(SysExitException):
+    _run_cli("speedometer_2.0", "--help")
+  _run_cli("describe", "benchmark", "speedometer_2.0")
+  browser_config = root_dir / "config/doc/browser.config.hjson"
+  assert browser_config.is_file()
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli("sp_2.0", f"--browser-config={browser_config}", "--iterations=2",
+           "--env-validation=skip", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", "--probe=tracing:{preset:'minimal'}")
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_speedometer_2_1(output_dir, cache_dir) -> None:
+  # - Speedometer 2.1
+  # - Story filtering with regexp
+  # - V8 probes
+  # - minimal splashscreen
+  # - inline probe arguments
+  with pytest.raises(SysExitException):
+    _run_cli("speedometer_2.1", "--help")
+  _run_cli("describe", "benchmark", "speedometer_2.1")
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli(
+      "sp2.1",
+      "--browser=chrome-stable",
+      "--splashscreen=minimal",
+      "--iterations=2",
+      "--env-validation=skip",
+      f"--out-dir={results_dir}",
+      f"--cache-dir={cache_dir}",
+      "--stories=.*Vanilla.*",
+      # V8 --prof doesn't always work on linux, skip it.
+      "--probe=v8.log:"
+      "{log_all:false, js_flags:['--log-maps'], prof:false, profview:false}",
+      "--probe=v8.turbolizer",
+      "--debug")
+
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 1
+  v8_log_files = _get_v8_log_files(results_dir)
+  assert len(v8_log_files) > 1
+
+
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+def test_speedometer_2_1_custom_chrome_download(output_dir, cache_dir) -> None:
+  # - Custom chrome version downloads
+  # - headless
+  if not plt.PLATFORM.which("gsutil"):
+    pytest.skip("Missing required 'gsutil', skipping test.")
+  results_dir = output_dir / "results"
+  # TODO: speed up --browser=chrome-M111 and add it.
+  assert len(list(cache_dir.iterdir())) == 0
+  _run_cli("sp2.1", f"--cache-dir={cache_dir}", "--browser=chrome-M113",
+           "--browser=chrome-111.0.5563.110", "--headless", "--iterations=1",
+           "--env-validation=skip", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", "--stories=.*Vanilla.*")
+
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 2
+  v8_log_files = _get_v8_log_files(results_dir)
+  assert not v8_log_files
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_speedometer_2_1_chrome_safari(output_dir, cache_dir,
+                                       driver_path) -> None:
+  # - Speedometer 3
+  # - Merging stories over multiple iterations and browsers
+  # - Testing safari
+  # - --verbose flag
+  # - no splashscreen
+  # This fails on the CQ bot, so make sure we skip it there:
+  if driver_path:
+    pytest.skip("Skipping test on CQ.")
+  platform = plt.PLATFORM
+  if not platform.is_macos and (not platform.exists(
+      browsers.Safari.default_path(platform))):
+    pytest.skip("Test requires Safari, skipping on non macOS devices.")
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli("sp2.1", "--browser=chrome", "--browser=safari",
+           "--splashscreen=none", "--iterations=1", "--repeat=2",
+           "--env-validation=skip", "--verbose", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", "--stories=.*React.*")
+
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 2
+  v8_log_files = _get_v8_log_files(results_dir)
+  assert not v8_log_files
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_jetstream_2_0(output_dir, cache_dir) -> None:
+  # - jetstream 2.0
+  # - merge / run separate stories
+  # - custom multiple --js-flags
+  # - custom viewport
+  # - quiet flag
+  with pytest.raises(SysExitException):
+    _run_cli("jetstream_2.0", "--help")
+  _run_cli("describe", "--json", "benchmark", "jetstream_2.0")
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli("jetstream_2.0", "--browser=chrome-stable", "--separate",
+           "--repeat=2", "--env-validation=skip", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", "--viewport=maximised",
+           "--stories=.*date-format.*", "--quiet",
+           "--js-flags=--log,--log-opt,--log-deopt", "--", "--no-sandbox")
+
+  v8_log_files = _get_v8_log_files(results_dir)
+  assert len(v8_log_files) > 1
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 1
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_jetstream_2_1(output_dir, cache_dir, root_dir) -> None:
+  # - jetstream 2.1
+  # - custom --time-unit
+  # - explicit single story
+  # - custom splashscreen
+  # - custom viewport
+  # - --probe-config
+  with pytest.raises(SysExitException):
+    _run_cli("jetstream_2.1", "--help")
+  _run_cli("describe", "benchmark", "jetstream_2.1")
+  probe_config = root_dir / "config/doc/probe.config.hjson"
+  assert probe_config.is_file()
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  chrome_version = "--browser=chrome"
+  _run_cli("jetstream_2.1", chrome_version, "--env-validation=skip",
+           "--splashscreen=http://google.com", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", "--viewport=900x800", "--stories=Box2D",
+           "--time-unit=0.9", f"--probe-config={probe_config}", "--throw")
+
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 1
+  v8_log_files = _get_v8_log_files(results_dir)
+  assert len(v8_log_files) > 1
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_jetstream_2_2(output_dir, cache_dir, root_dir) -> None:
+  # - jetstream 2.2
+  # - custom --time-unit
+  # - explicit single story
+  # - custom splashscreen
+  # - custom viewport
+  # - --probe-config
+  with pytest.raises(SysExitException):
+    _run_cli("jetstream_2.2", "--help")
+  _run_cli("describe", "benchmark", "jetstream_2.2")
+  probe_config = root_dir / "config/doc/probe.config.hjson"
+  assert probe_config.is_file()
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  chrome_version = "--browser=chrome"
+  _run_cli("jetstream_2.2", chrome_version, "--env-validation=skip",
+           "--splashscreen=http://google.com", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", "--viewport=900x800", "--stories=Box2D",
+           "--time-unit=0.9", f"--probe-config={probe_config}", "--throw")
+
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 1
+  v8_log_files = _get_v8_log_files(results_dir)
+  assert len(v8_log_files) > 1
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading(output_dir, cache_dir) -> None:
+  # - loading using named pages with timeouts
+  # - custom cooldown time
+  # - custom viewport
+  # - performance.mark probe
+  with pytest.raises(SysExitException):
+    _run_cli("loading", "--help")
+  _run_cli("describe", "benchmark", "loading")
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli("loading", "--browser=chr", "--env-validation=skip",
+           f"--out-dir={results_dir}", f"--cache-dir={cache_dir}",
+           "--viewport=headless", "--stories=cnn", "--cool-down-time=2.5",
+           "--probe=performance.entries")
+
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 1
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+def test_loading_page_config(output_dir, cache_dir, root_dir) -> None:
+  # - loading with config file
+  page_config = root_dir / "config/doc/page.config.hjson"
+  assert page_config.is_file()
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli("loading", "--env-validation=skip", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", f"--page-config={page_config}",
+           "--probe=performance.entries", "--no-splash", "--cool-down-time=0",
+           "--throw")
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading_playback_urls(output_dir, cache_dir) -> None:
+  # - loading using url
+  # - combined pages and --playback controller
+  results_dir = output_dir / "results"
+
+  assert not results_dir.exists()
+  _run_cli("loading", "--env-validation=skip", f"--out-dir={results_dir}",
+           f"--cache-dir={cache_dir}", "--playback=5.3s",
+           "--viewport=fullscreen",
+           "--stories=http://google.com,0.5,http://bing.com,0.4",
+           "--probe=performance.entries")
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading_playback(output_dir, cache_dir) -> None:
+  # - loading using named pages with timeouts
+  # - separate pages and --playback controller
+  # - viewport-size via chrome flag
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli("loading", "--browser=chr", "--env-validation=skip",
+           f"--out-dir={results_dir}", f"--cache-dir={cache_dir}",
+           "--playback=5.3s", "--separate", "--stories=twitter,2,facebook,0.4",
+           "--probe=performance.entries", "--", "--window-size=900,500",
+           "--window-position=150,150")
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading_playback_firefox(output_dir, cache_dir) -> None:
+  # - loading using named pages with timeouts
+  # - --playback controller
+  # - Firefox
+  platform = plt.PLATFORM
+  try:
+    if not platform.exists(browsers.Firefox.default_path(platform)):
+      pytest.skip("Test requires Firefox.")
+  except Exception:  # pylint: disable=broad-exception-caught
+    pytest.skip("Test requires Firefox.")
+  results_dir = output_dir / "results"
+  assert not results_dir.exists()
+  _run_cli("loading", "--browser=chr", "--browser=ff", "--env-validation=skip",
+           f"--out-dir={results_dir}", f"--cache-dir={cache_dir}",
+           "--playback=2x", "--stories=twitter,1,facebook,0.4",
+           "--probe=performance.entries")
+
+  browser_dirs = _get_browser_dirs(results_dir)
+  assert len(browser_dirs) == 2
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/test_helper.py b/tests/test_helper.py
new file mode 100644
index 0000000..3bf604f
--- /dev/null
+++ b/tests/test_helper.py
@@ -0,0 +1,33 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pathlib
+import sys
+from typing import Union
+
+import pytest
+
+from crossbench import config
+
+is_google_env = config.is_google_env
+root_dir = config.root_dir
+config_dir = config.config_dir
+
+
+def crossbench_dir() -> pathlib.Path:
+  if is_google_env():
+    return root_dir()
+  return root_dir() / "crossbench"
+
+
+def run_pytest(path: Union[str, pathlib.Path], *args):
+  extra_args = [*args, *sys.argv[1:]]
+  # Run tests single-threaded by default when running the test file directly.
+  if "-n" not in extra_args:
+    extra_args.extend(["-n", "1"])
+  if "-r" not in extra_args:
+    extra_args.extend(["-r", "s"])
+  sys.exit(pytest.main([str(path), *extra_args]))
```

