```diff
diff --git a/.gitmodules b/.gitmodules
deleted file mode 100644
index 44b3bf86..00000000
--- a/.gitmodules
+++ /dev/null
@@ -1,6 +0,0 @@
-[submodule "third_party/tsproxy"]
-	path = third_party/tsproxy
-	url = https://chromium.googlesource.com/external/github.com/catchpoint/WebPageTest.tsproxy
-[submodule "third_party/webpagereplay"]
-	path = third_party/webpagereplay
-	url = https://chromium.googlesource.com/webpagereplay
diff --git a/.pylintrc b/.pylintrc
index ee2e2420..6b6f2e56 100644
--- a/.pylintrc
+++ b/.pylintrc
@@ -19,7 +19,8 @@ persistent=no
 
 # List of plugins (as comma separated values of python modules names) to load,
 # usually to register additional checkers.
-load-plugins=
+load-plugins=pylint.extensions.check_elif,pylint.extensions.for_any_all
+# pylint.extensions.typing
 
 # Use multiple processes to speed up Pylint.
 jobs=4
@@ -59,7 +60,7 @@ disable=abstract-method,
         basestring-builtin,
         buffer-builtin,
         c-extension-no-member,
-        consider-using-enumerate,
+        # consider-using-enumerate,
         cmp-builtin,
         cmp-method,
         coerce-builtin,
@@ -73,14 +74,14 @@ disable=abstract-method,
         filter-builtin-not-iterating,
         fixme,
         getslice-method,
-        global-statement,
+        # global-statement,
         hex-method,
         idiv-method,
         implicit-str-concat,
         import-error,
         import-self,
         import-star-module-level,
-        inconsistent-return-statements,
+        # inconsistent-return-statements,
         input-builtin,
         intern-builtin,
         invalid-str-codec,
@@ -96,10 +97,10 @@ disable=abstract-method,
         next-method-called,
         next-method-defined,
         no-absolute-import,
-        no-else-break,
-        no-else-continue,
-        no-else-raise,
-        no-else-return,
+        # no-else-break,
+        # no-else-continue,
+        # no-else-raise,
+        # no-else-return,
         no-init,  # added
         no-member,
         no-name-in-module,
@@ -111,7 +112,7 @@ disable=abstract-method,
         old-octal-literal,
         old-raise-syntax,
         parameter-unpacking,
-        print-statement,
+        # print-statement,
         raising-string,
         range-builtin-not-iterating,
         raw_input-builtin,
@@ -137,14 +138,14 @@ disable=abstract-method,
         too-many-public-methods,
         too-many-return-statements,
         too-many-statements,
-        trailing-newlines,
+        # trailing-newlines,
         unichr-builtin,
         unicode-builtin,
         unnecessary-pass,
         unpacking-in-except,
-        useless-else-on-loop,
-        useless-object-inheritance,
-        useless-suppression,
+        # useless-else-on-loop,
+        # useless-object-inheritance,
+        # useless-suppression,
         using-cmp-argument,
         # wrong-import-order,
         xrange-builtin,
diff --git a/.vpython3 b/.vpython3
index 03d1a0b6..b9683659 100644
--- a/.vpython3
+++ b/.vpython3
@@ -1,11 +1,11 @@
 # Copyright 2022 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
-
+python_version: "3.11"
 
 wheel: <
   name: "infra/python/wheels/pytype/${vpython_platform}"
-  version: "version:2024.1.24"
+  version: "version:2024.9.13"
   not_match_tag: <
     platform: "win_amd64"
   >
@@ -13,46 +13,42 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/pytest-py3"
-  version: "version:6.2.2"
+  version: "version:8.3.4"
 >
 
-# Required by pytest 6.2.2 on Windows only
 wheel: <
-  name: "infra/python/wheels/atomicwrites-py2_py3"
-  version: "version:1.3.0"
-  match_tag: <
-    platform: "win_amd64"
-  >
+  name: "infra/python/wheels/mypy-py3"
+  version: "version:1.13.0"
 >
 
 wheel: <
   name: "infra/python/wheels/selenium-py3"
-  version: "version:4.10.0"
+  version: "version:4.28.1"
 >
 
 wheel: <
   name: "infra/python/wheels/psutil/${vpython_platform}"
-  version: "version:5.8.0.chromium.3"
+  version: "version:5.9.8"
 >
 
 wheel: <
   name: "infra/python/wheels/websockets-py3"
-  version: "version:10.3"
+  version: "version:13.0"
 >
 
 wheel: <
   name: "infra/python/wheels/pyfakefs-py3"
-  version: "version:5.5.0"
+  version: "version:5.7.3"
 >
 
 wheel: <
-  name: "infra/python/wheels/attrs-py2_py3"
-  version: "version:21.4.0"
+  name: "infra/python/wheels/attrs-py3"
+  version: "version:24.2.0"
 >
 
 wheel: <
   name: "infra/python/wheels/py-py2_py3"
-  version: "version:1.10.0"
+  version: "version:1.11.0"
 >
 
 wheel: <
@@ -67,12 +63,12 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/pluggy-py3"
-  version: "version:0.13.1"
+  version: "version:1.5.0"
 >
 
 wheel: <
   name: "infra/python/wheels/colorama-py2_py3"
-  version: "version:0.4.1"
+  version: "version:0.4.6"
 >
 
 wheel: <
@@ -92,7 +88,7 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/pyyaml-py3"
-  version: "version:5.3.1"
+  version: "version:6.0.1"
 >
 
 wheel: <
@@ -102,32 +98,22 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/mypy-extensions-py3"
-  version: "version:0.4.3"
+  version: "version:1.0.0"
 >
 
 wheel: <
   name: "infra/python/wheels/importlab-py3"
-  version: "version:0.8"
->
-
-wheel: <
-  name: "infra/python/wheels/zstandard/${vpython_platform}"
-  version: "version:0.16.0"
+  version: "version:0.8.1"
 >
 
 wheel: <
   name: "infra/python/wheels/networkx-py3"
-  version: "version:2.5"
->
-
-wheel: <
-  name: "infra/python/wheels/decorator-py3"
-  version: "version:5.0.9"
+  version: "version:3.1"
 >
 
 wheel: <
   name: "infra/python/wheels/ninja/${vpython_platform}"
-  version: "version:1.10.2.4"
+  version: "version:1.10.2.4.chromium.1"
 >
 
 wheel: <
@@ -137,12 +123,12 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/typing-extensions-py3"
-  version: "version:4.3.0"
+  version: "version:4.12.2"
 >
 
 wheel: <
   name: "infra/python/wheels/jinja2-py3"
-  version: "version:3.1.2"
+  version: "version:3.1.4"
 >
 
 wheel: <
@@ -151,93 +137,83 @@ wheel: <
 >
 
 wheel: <
-  name: "infra/python/wheels/packaging-py2_py3"
-  version: "version:16.8"
+  name: "infra/python/wheels/packaging-py3"
+  version: "version:24.1"
 >
 
 wheel: <
-  name: "infra/python/wheels/pyparsing-py2_py3"
-  version: "version:2.4.7"
+  name: "infra/python/wheels/pyparsing-py3"
+  version: "version:3.2.0"
 >
 
 wheel: <
   name: "infra/python/wheels/six-py2_py3"
-  version: "version:1.10.0"
+  version: "version:1.16.0"
 >
 
 wheel: <
   name: "infra/python/wheels/trio-py3"
-  version: "version:0.20.0"
+  version: "version:0.22.1"
 >
 
 wheel: <
   name: "infra/python/wheels/trio-websocket-py3"
-  version: "version:0.9.2"
+  version: "version:0.10.3"
 >
 
 wheel: <
-  name: "infra/python/wheels/urllib3-py2_py3"
-  version: "version:1.26.6"
+  name: "infra/python/wheels/exceptiongroup-py3"
+  version: "version:1.1.2"
 >
 
 wheel: <
-  name: "infra/python/wheels/sortedcontainers-py3"
-  version: "version:2.4.0"
+  name: "infra/python/wheels/urllib3-py3"
+  version: "version:2.1.0"
 >
 
 wheel: <
-  name: "infra/python/wheels/outcome-py3"
-  version: "version:1.1.0"
+  name: "infra/python/wheels/sortedcontainers-py3"
+  version: "version:2.4.0"
 >
 
 wheel: <
-  name: "infra/python/wheels/async-generator-py3"
-  version: "version:1.10"
+  name: "infra/python/wheels/outcome-py3"
+  version: "version:1.2.0"
 >
 
 wheel: <
   name: "infra/python/wheels/sniffio-py3"
-  version: "version:1.2.0"
+  version: "version:1.3.0"
 >
 
 wheel: <
-  name: "infra/python/wheels/idna-py2_py3"
-  version: "version:2.10"
+  name: "infra/python/wheels/idna-py3"
+  version: "version:3.4"
 >
 
 wheel: <
   name: "infra/python/wheels/wsproto-py3"
-  version: "version:1.1.0"
+  version: "version:1.2.0"
 >
 
 wheel: <
   name: "infra/python/wheels/h11-py3"
-  version: "version:0.13.0"
+  version: "version:0.14.0"
 >
 
 wheel: <
   name: "infra/python/wheels/certifi-py3"
-  version: "version:2023.5.7"
->
-
-wheel: <
-  name: "infra/python/wheels/pyopenssl-py2_py3"
-  version: "version:19.0.0"
->
-
-wheel: <
-  name: "infra/python/wheels/cryptography/${vpython_platform}"
-  version: "version:3.3.1.chromium.1"
+  version: "version:2024.7.4"
 >
 
 wheel: <
   name: "infra/python/wheels/cffi/${vpython_platform}"
-  version: "version:1.14.5.chromium.7"
+  version: "version:1.15.1.chromium.2"
 >
 
 wheel: <
   name: "infra/python/wheels/pycparser-py2_py3"
-  version: "version:2.19"
+  version: "version:2.21"
 >
 
 wheel: <
@@ -247,7 +223,7 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/tabulate-py3"
-  version: "version:0.8.10"
+  version: "version:0.9.0"
 >
 
 wheel: <
@@ -257,7 +233,7 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/pycnite-py3"
-  version: "version:2023.10.11"
+  version: "version:2024.07.31"
 >
 
 wheel: <
@@ -267,17 +243,17 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/charset_normalizer-py3"
-  version: "version:2.0.4"
+  version: "version:3.3.2"
 >
 
 wheel: <
   name: "infra/python/wheels/debugpy/${vpython_platform}"
-  version: "version:1.5.1"
+  version: "version:1.8.0"
 >
 
 wheel: <
   name: "infra/python/wheels/markupsafe/${vpython_platform}"
-  version: "version:2.0.1"
+  version: "version:2.1.5"
 >
 
 wheel: <
@@ -287,14 +263,15 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/pandas/${vpython_platform}"
-  version: "version:1.3.2.chromium.1"
+  version: "version:2.2.3.chromium.1"
 >
 
 wheel: <
   name: "infra/python/wheels/python-dateutil-py2_py3"
-  version: "version:2.7.3"
+  version: "version:2.9.0"
 >
 
+
 wheel: <
   name: "infra/python/wheels/numpy/${vpython_platform}"
   version: "version:1.23.5.chromium.4"
@@ -307,10 +284,65 @@ wheel: <
 
 wheel: <
   name: "infra/python/wheels/perfetto-py3"
-  version: "version:0.10.0"
+  version: "version:0.11.0"
 >
 
 wheel: <
   name: "infra/python/wheels/protobuf-py3"
   version: "version:4.25.3"
+>
+
+wheel: <
+  name: "infra/python/wheels/pygments-py3"
+  version: "version:2.14.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/google-auth-py2_py3"
+  version: "version:2.32.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/rsa-py3"
+  version: "version:4.9.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/pyasn1_modules-py2_py3"
+  version: "version:0.3.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/cachetools-py3"
+  version: "version:5.3.3"
+>
+
+wheel: <
+  name: "infra/python/wheels/pyasn1-py2_py3"
+  version: "version:0.5.1"
+>
+
+wheel: <
+  name: "infra/python/wheels/tzdata-py2_py3"
+  version: "version:2023.4"
+>
+
+wheel: <
+  name: "infra/python/wheels/msgspec/${vpython_platform}"
+  version: "version:0.18.6"
+>
+
+wheel: <
+  name: "infra/python/wheels/websocket_client-py2_py3"
+  version: "version:1.8.0"
+>
+
+wheel: <
+  name: "infra/python/wheels/sqlalchemy/${vpython_platform}"
+  version: "version:2.0.4"
+>
+
+wheel: <
+  name: "infra/python/wheels/greenlet/${vpython_platform}"
+  version: "version:3.0.1"
 >
\ No newline at end of file
diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
new file mode 100644
index 00000000..cfcd68ef
--- /dev/null
+++ b/CONTRIBUTING.md
@@ -0,0 +1,87 @@
+# CONTRIBUTING
+
+## How to Contribute
+
+We'd love to accept your patches and contributions to this project. There are
+just a few small guidelines you need to follow.
+
+### Contributor License Agreement
+
+Contributions to this project must be accompanied by a Contributor License
+Agreement. You (or your employer) retain the copyright to your contribution;
+this simply gives us permission to use and redistribute your contributions as
+part of the project. Head over to <https://cla.developers.google.com/> to see
+your current agreements on file or to sign a new one.
+
+You generally only need to submit a CLA once, so if you've already submitted one
+(even if it was for a different project), you probably don't need to do it
+again.
+
+### Code Reviews
+
+All submissions, including submissions by project members, require review. We
+use Gerrit for this purpose. Consult
+[Gerrit Help](https://gerrit-review.googlesource.com/Documentation/intro-gerrit-walkthrough.html)
+for more information on using gerrit.
+
+### Community Guidelines
+
+This project follows [Google's Open Source Community
+Guidelines](https://opensource.google/conduct/).
+
+
+## Coding Guidelines
+crossbench tries to follow
+[Google's Python Style Guide](https://google.github.io/styleguide/pyguide.html).
+
+### General rules
+- Avoid code comments, they bit-rot easily. Write tests to document unexpected
+  behavior and add helper methods and objects to make your code more readable.
+- No code comment that trivially describes what the code does.
+- Document classes, tests and config files instead.
+
+### Testing
+- New code should be unittested.
+- Check local coverage by running
+  `poetry run pytest tests/crossbench/ --cov=crossbench --cov-report=html`.
+- All ConfigObject classes should have dedicated unittests.
+
+### Typing
+- Move all type-checking-only imports in a `if TYPE_CHECKING` block.
+- Avoid generic types like `Any`.
+- Type-annotate all method parameters and return types.
+- Type-annotate variables on first use.
+
+#### Typing-tools
+- Fix all mypy errors: `poetry run mypy crossbench --check-untyped-defs `.
+- Fix all pytype errors: `poetry run pytype -j auto crossbench`.
+
+### ConfigObject and Input Validation
+Any non-trivial configuration should use a dedicate ConfigObject.
+We get many benefits from using ConfigObject and ConfigParsers:
+- Better warning message on wrong configurations.
+- We can easily split complex configurations into separate files.
+- ConfigParser can be used to generate help texts.
+
+Coding guidelines:
+- Make sure that any configuration is best suited for local running
+  and debugging.
+- If possible also use dedicated ConfigObject for inner objects.
+- Use ConfigParser for parsing serialized configurations in `parse_dict`.
+- If possible provide simple shortcuts in the `parse_str`,
+  they are useful on the command line.
+- Parsing / verifying input values is done using helpers in `crossbench.parse`.
+- Failing input validation raises `argparse.ArgumentTypeError`
+  so we get proper warning on the cli.
+- ConfigObject subclasses have separate unittests.
+- Provide example configurations with help texts and explanations in
+  `config/doc` and make sure these files are parsed and unittested.
+
+
+### Maintenance
+The supported python versions are listed in the `.vpython3` and the
+`pyproject.toml` file.
+This has to be in sync with chrome infra's vpython3 version.
+
+- Regularly update the poetry packages using `poetry update`
+- Regularly update the vpython3 packages specified in `.vpython3`
\ No newline at end of file
diff --git a/LICENSE b/LICENSE
index b0928307..0de174a6 100644
--- a/LICENSE
+++ b/LICENSE
@@ -49,4 +49,21 @@ Files: flags/known_chrome_flags.py
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
-#
\ No newline at end of file
+#
+
+
+
+Files: cli/exception_formatter.py
+Copyright (c) 2014, Anton Backer <olegov@gmail.com>
+
+Permission to use, copy, modify, and/or distribute this software for any
+purpose with or without fee is hereby granted, provided that the above
+copyright notice and this permission notice appear in all copies.
+
+THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
+REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
+FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
+INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
+OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+PERFORMANCE OF THIS SOFTWARE.
\ No newline at end of file
diff --git a/METADATA b/METADATA
index ca222c02..820265db 100644
--- a/METADATA
+++ b/METADATA
@@ -1,16 +1,20 @@
-name: "crossbench"
-description:
-    "Crossbench is a cross-browser/cross-benchmark runner to extract "
-    "performance numbers."
+# This project was upgraded with external_updater.
+# Usage: tools/external_updater/updater.sh update external/chromium-crossbench
+# For more info, check https://cs.android.com/android/platform/superproject/main/+/main:tools/external_updater/README.md
 
+name: "crossbench"
+description: "Crossbench is a cross-browser/cross-benchmark runner to extract performance numbers."
 third_party {
+  license_type: NOTICE
+  last_upgrade_date {
+    year: 2025
+    month: 3
+    day: 25
+  }
   identifier {
     type: "Git"
     value: "https://chromium.googlesource.com/crossbench"
+    version: "64ee2d5026c0c4c7b9794c885d4a0e196d3ff726"
     primary_source: true
-    version: "49340d5b69d458f1496edc23064dd9969b2033fa"
   }
-  version: "49340d5b69d458f1496edc23064dd9969b2033fa"
-  last_upgrade_date { year: 2024 month: 11 day: 11 }
-  license_type: NOTICE
 }
diff --git a/PRESUBMIT.py b/PRESUBMIT.py
index 68ee25e5..b7a0fb40 100644
--- a/PRESUBMIT.py
+++ b/PRESUBMIT.py
@@ -3,84 +3,154 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+from __future__ import annotations
+
 import pathlib
 import platform
 import re
+from typing import Iterable, List, Optional
 
 USE_PYTHON3 = True
 
 
-def ModifiedFiles(input_api, filename_pattern="*.py"):
-  files = [file.AbsoluteLocalPath() for file in input_api.AffectedFiles()]
-  files_to_check = []
-  for file_path in files:
-    if not input_api.fnmatch.fnmatch(file_path, filename_pattern):
-      continue
-    file_path_pattern = re.escape(
-        input_api.os_path.relpath(file_path, input_api.PresubmitLocalPath()))
-    files_to_check.append(file_path_pattern)
-  return files_to_check
-
-
 def CheckChange(input_api, output_api, on_commit):
   tests = []
   results = []
   testing_env = dict(input_api.environ)
-  testing_path = pathlib.Path(input_api.PresubmitLocalPath())
-  crossbench_test_path = testing_path / "tests" / "crossbench"
+  root_path = pathlib.Path(input_api.PresubmitLocalPath())
+  crossbench_test_path = root_path / "tests" / "crossbench"
   testing_env["PYTHONPATH"] = input_api.os_path.pathsep.join(
-      map(str, [testing_path, crossbench_test_path]))
+      map(str, [root_path, crossbench_test_path]))
+  # ---------------------------------------------------------------------------
+  modified_py_files: List[str] | None = ModifiedFiles(input_api, on_commit)
+
+  # ---------------------------------------------------------------------------
+  # Validate the vpython spec:
   # ---------------------------------------------------------------------------
-  # Validate the vpython spec
   if platform.system() in ("Linux", "Darwin"):
     tests += input_api.canned_checks.CheckVPythonSpec(input_api, output_api)
+
   # ---------------------------------------------------------------------------
-  if on_commit:
-    files_to_check = [r"^[^\.]+\.py$"]
-  else:
-    # By default, the pylint canned check lints all Python files together to
-    # check for potential problems between dependencies. This is slow to run
-    # across all of crossbench (>2 min), so only lint affected files.
-    files_to_check = ModifiedFiles(input_api)
+  # License header checks:
+  # ---------------------------------------------------------------------------
+  results += input_api.canned_checks.CheckLicense(input_api, output_api)
+
+  # ---------------------------------------------------------------------------
+  # Pylint:
+  # ---------------------------------------------------------------------------
+  pylint_file_patterns_to_check: List[str] = PylintFilePatternsToCheck(
+      on_commit, modified_py_files)
   tests += input_api.canned_checks.GetPylint(
       input_api,
       output_api,
-      files_to_check=files_to_check,
+      files_to_check=pylint_file_patterns_to_check,
       pylintrc=".pylintrc",
-      version="2.17")
+      version="3.2")
+
   # ---------------------------------------------------------------------------
-  # License header checks
-  results += input_api.canned_checks.CheckLicense(input_api, output_api)
+  # MyPy:
   # ---------------------------------------------------------------------------
-  # Only run test_cli to speed up the presubmit checks
-  if on_commit:
-    dirs_to_check = crossbench_test_path.glob("**")
-    files_to_check = [r".*test_.*\.py$"]
-  else:
-    # Only check a small subset on upload
-    dirs_to_check = [crossbench_test_path / "cli"]
-    files_to_check = [r".*test_cli_fast_.*\.py$"]
-  for dir_to_check in dirs_to_check:
+  mypy_files_to_check: List[str] = MypyFilesToCheck(input_api, on_commit,
+                                                    modified_py_files)
+  tests.append(
+      input_api.Command(
+          name="mypy",
+          cmd=[
+              input_api.python3_executable,
+              "-m",
+              "mypy",
+              "--check-untyped-defs",
+              "--pretty",
+          ] + mypy_files_to_check,
+          message=output_api.PresubmitError,
+          kwargs={},
+          python3=True,
+      ))
+
+  # ---------------------------------------------------------------------------
+  # Unittest:
+  # ---------------------------------------------------------------------------
+  test_dirs_to_check, test_file_patterns_to_check = TestFilePatternsToCheck(
+      on_commit, crossbench_test_path)
+  for test_dir_to_check in test_dirs_to_check:
     # Skip potentially empty dirs
-    if dir_to_check.name == "__pycache__":
+    if test_dir_to_check.name == "__pycache__":
       continue
     # End-to-end tests require custom setup and are not suited for presubmits.
-    if "end2end" in dir_to_check.parts:
+    if "end2end" in test_dir_to_check.parts:
       continue
     tests += input_api.canned_checks.GetUnitTestsInDirectory(
         input_api,
         output_api,
-        directory=dir_to_check,
+        directory=test_dir_to_check,
         env=testing_env,
-        files_to_check=files_to_check,
+        files_to_check=test_file_patterns_to_check,
         skip_shebang_check=True,
         run_on_python2=False)
+
   # ---------------------------------------------------------------------------
   # Run all test
+  # ---------------------------------------------------------------------------
   results += input_api.RunTests(tests)
   return results
 
 
+def ModifiedFiles(input_api,
+                  on_commit: bool,
+                  filename_pattern="*.py") -> Optional[List[str]]:
+  if on_commit:
+    return None
+  files = [file.AbsoluteLocalPath() for file in input_api.AffectedFiles()]
+  files_to_check = []
+  for file_path in files:
+    if not input_api.fnmatch.fnmatch(file_path, filename_pattern):
+      continue
+    if not input_api.os_path.exists(file_path):
+      continue
+    file_path = input_api.os_path.relpath(file_path,
+                                          input_api.PresubmitLocalPath())
+    files_to_check.append(file_path)
+  return files_to_check
+
+
+def PylintFilePatternsToCheck(on_commit, modified_py_files) -> List[str]:
+  if on_commit:
+    # Test all files on commit
+    return [r"^[^\.]+\.py$"]
+  # By default, the pylint canned check lints all Python files together to
+  # check for potential problems between dependencies. This is slow to run
+  # across all of crossbench (>2 min), so only lint affected files.
+  return [re.escape(file) for file in modified_py_files]
+
+
+def MypyFilesToCheck(input_api, on_commit, modified_py_files) -> List[str]:
+  root_path = pathlib.Path(input_api.PresubmitLocalPath())
+  mypy_files_to_check = {"PRESUBMIT.py"}
+  crossbench_path = root_path / "crossbench"
+  if on_commit:
+    mypy_files_to_check.add(str(crossbench_path))
+  else:
+    mypy_files_to_check.update(modified_py_files)
+  # TODO: enable mypy on all tests
+  result = []
+  for file in mypy_files_to_check:
+    if not file.startswith("tests/"):
+      result.append(file)
+  return result
+
+
+def TestFilePatternsToCheck(on_commit, crossbench_test_path):
+  # Only run test_cli to speed up the presubmit checks
+  if on_commit:
+    test_dirs_to_check: Iterable[pathlib.Path] = crossbench_test_path.glob("**")
+    test_files_to_check = [r".*test_.*\.py$"]
+  else:
+    # Only check a small subset on upload
+    test_dirs_to_check = [crossbench_test_path / "cli"]
+    test_files_to_check = [r".*test_cli_fast_.*\.py$"]
+  return test_dirs_to_check, test_files_to_check
+
+
 def CheckChangeOnUpload(input_api, output_api):
   return CheckChange(input_api, output_api, on_commit=False)
 
diff --git a/README.chromium b/README.chromium
index f119111a..bc2c58f4 100644
--- a/README.chromium
+++ b/README.chromium
@@ -3,7 +3,7 @@ Short Name: crossbench
 URL: https://chromium.googlesource.com/crossbench
 Version: N/A
 Revision: DEPS
-License: BSD
+License: BSD-3-Clause, MIT
 License File: LICENSE
 Security Critical: No
 Shipped: no
diff --git a/README.md b/README.md
index 92cc06f5..8137d74c 100644
--- a/README.md
+++ b/README.md
@@ -69,11 +69,19 @@ You can specify a browser with `--browser=<name>`. You can repeat the
 multiple browsers use `--browser-config` (or pass simple flags after `--` to
 the browser).
 
+Single browser example:
 ```bash
 ./cb.py speedometer --browser=$BROWSER -- --enable-field-trial-config
 ```
-#### `--browser` flag on desktop:
 
+Multi-browser example:
+```bash
+./cb.py sp3 --stories='TodoMVC.*' \
+  --browser=firefox --browser=safari \
+  --browser=chrome-M123-dev --browser=./out/Release/Chromium.app
+```
+
+#### `--browser` flag on desktop:
 | Flag | Description |
 |------|-------------|
 |`--browser=chrome-stable`| Use the installed Chrome stable on the host. Also works with `beta`, `dev` and `canary` versions. |
@@ -81,9 +89,12 @@ the browser).
 |`--browser=safari-stable`| Use the installed Safari stable version on the host. Also works with `technology-preview` |
 |`--browser=firefox-stable`| Use the installed Firefox stable version on the host. Also works with `dev` and `nightly` versions. |
 |`--browser=./out/Release/chrome`| Use a locally compiled chrome version. Any path to a chrome binary will work. |
-|`--browser=chrome-m123`| Download the latest M123 chrome release and install it locally |
-|`--browser=chrome-125.0.6422.112`| Download and install a specific chrome version. |
-|`--browser=chrome-M100...M123`| Download and install a range of 24 different chrome milestones. |
+|`--browser=chrome-m123`| Download the latest M123 chrome stable release and install it locally |
+|`--browser=chrome-M123-canary`| Download the latest M123 chrome canary release and install it locally |
+|`--browser=chrome-125.0.6422.112`| Download and install a specific stable chrome version. |
+|`--browser=chrome-125.0.6422.112-dev`| Download and install a specific dev chrome version. |
+|`--browser=chrome-M100...M123`| Download and install a range of 24 different chrome stable milestones. |
+
 
 #### `--browser` flag on mobile:
 You can directly run on attached android devices using the device ID or unique device names.
@@ -126,6 +137,17 @@ Both ChromeDriver and Autotest are pre-installed on ChromeOS test images.
 Detailed instructions for flashing Chromebooks with test images are provided at:
 go/arc-setup-dev-mode-dut#usb-cros-test-image.
 
+### Safari on macOS
+
+Safari needs some extra steps to work:
+
+- `safaridriver --enable` to allow automation
+- Open the Safari settings:
+  - "Advanced" tab: Check "Show features for web developers"
+  - "Developer" tab: Check "Allow remote automation"
+  - "Developer" tab: Optional, if you plan to use the apple-script browser, also check "Allow JavaScript from Apple Events"
+
+
 ### Probes
 Probes define a way to extract arbitrary (performance) numbers from a
 host or running browser. This can reach from running simple JS-snippets to
@@ -219,7 +241,7 @@ to setup the correct environment for testing and debugging.
 ```bash
 # a) On debian:
 sudo apt-get install python3.10 python3-poetry
-# b) With python 3.9 to 3.11 installed already:
+# b) With python 3.11 installed already:
 pip3 install poetry
 ```
 
@@ -235,8 +257,8 @@ python3 -c "import sysconfig; print(sysconfig.get_path('scripts'))";
 Install the necessary dependencies from the lock file using poetry:
 
 ```bash
-# Select the python version you want to use (3.9 to 3.10):
-poetry env use 3.10
+# Select the python version you want to use (3.11):
+poetry env use 3.11
 poetry install
 
 # For windows you have to skip pytype support:
diff --git a/WATCHLISTS b/WATCHLISTS
index 9e3d96cb..4d8406ae 100644
--- a/WATCHLISTS
+++ b/WATCHLISTS
@@ -15,7 +15,9 @@
   },
   'WATCHLISTS': {
     'all': [
-      'cbruni+watch@google.com',
+      'cbruni+watch@chromium.org',
+      'faridzad+watch@google.com',
+      'johnchen+watch@chromium.org',
     ],
   },
 }
\ No newline at end of file
diff --git a/config/benchmark/loadline/README.md b/config/benchmark/loadline/README.md
index dbe304ac..70d1b281 100644
--- a/config/benchmark/loadline/README.md
+++ b/config/benchmark/loadline/README.md
@@ -9,6 +9,13 @@ workload. The benchmark has two workload variants:
 
 *   Android Tablet web performance workload ("tablet").
 
+Google employees: see [go/loadline-internal](http://go/loadline-internal) for
+Google-specific info.
+
+See the
+[LoadLine component](https://g-issues.chromium.org/issues?q=status:open%20componentid:1670299)
+for the list of open bugs.
+
 ## tl;dr: Running the Benchmark
 
 Run "phone" workload:
@@ -176,24 +183,26 @@ be reproducible/comparable).
 ### Repetitions {#repetitions}
 
 By default, the benchmark runs **100** repetitions, as we have found that this
-brings the noise to an acceptable level. You can override this setting via
-`--repetitions`
+brings the noise to an acceptable level. For quicker experiments, it's possible
+to run just 10 repetitions (at the expense of higher variance / lower
+confidence) using the following command:
+
+```
+./cb.py loadline-phone-fast --browser <browser>
+```
+
+You can also run an arbitrary number of repetitions by providing the
+`--repetitions` flag.
 
 ### Thermal Throttling
 
 Given the high number of repetitions in the standard configuration, thermal
 throttling can be an issue, especially in more thermally constricted devices. A
 one size fits all solution to this problem is quite hard; even detecting this is
-very device specific. So for the first version of the benchmark, we leave it up
-to the user to determine if the results of the benchmark might be influenced by
-thermal issues. Crossbench has a way of adding a delay between repetitions that
-can be used to mitigate this problem (at the expense of longer running times):
-`--cool-down-time`.
-
-In the future, we want to look at ways to aid users in detecting / mitigating
-thermal throttling (e.g. notify users that thermal throttling happened during
-the test or automatically waiting between repetitions until the device is in a
-good thermal state).
+very device specific. The `--cool-down-threshold` flag can be used to try to
+detect thermal throttling based on the device's overall thermal status. If you
+still see thermal issues while using this flag, try adding fixed delays between
+repetitions via `--cool-down-time` instead.
 
 ## Configuration
 
@@ -245,8 +254,7 @@ it may be useful to collect more detailed traces and compute additional metrics.
 This can be done with the following command:
 
 ```
-./cb.py loadline-phone --browser <browser>\
-  --probe-config config/benchmark/loadline/probe_config_experimental.hjson
+./cb.py loadline-phone-debug --browser <browser>
 ```
 
 Note that collecting detailed traces incurs significant overhead, so the
@@ -266,7 +274,9 @@ If you see a `Could not find wpr.go binary` error:
 
 Follow the
 [crossbench development instructions](https://chromium.googlesource.com/crossbench/#development)
-to check out code and run crossbench standalone.
+to check out code and run crossbench standalone. Make sure to `fetch` using
+depot\_tools instead of cloning the git repository, this ensures that third
+party dependencies are set up correctly.
 
 ### Problems accessing the cloud bucket
 
@@ -276,5 +286,5 @@ case, save the archive file corresponding to the version you are running
 run the benchmark as follows:
 
 ```
-./cb.py loadline-phone --network <path to archive.wprgo>
+./cb.py loadline-phone --browser <browser> --network <path to archive.wprgo>
 ```
diff --git a/config/benchmark/loadline/cnn_instrumentation.js b/config/benchmark/loadline/cnn_instrumentation.js
index 981a2993..7184ab19 100644
--- a/config/benchmark/loadline/cnn_instrumentation.js
+++ b/config/benchmark/loadline/cnn_instrumentation.js
@@ -2,31 +2,31 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-const button_selector = 'button[id=onetrust-accept-btn-handler]'
-const headline_text_id = 'maincontent'
+const button_selector = 'button[id=onetrust-accept-btn-handler]';
+const headline_text_id = 'maincontent';
 
 const button_observer = new MutationObserver(mutations => {
-  const button = document.querySelector(button_selector)
+  const button = document.querySelector(button_selector);
   if (!button) {
-    return
+    return;
   }
   // This script can run multiple times.
   if (localStorage.getItem('already_run') === 'already_run') {
-    return
+    return;
   }
-  localStorage.setItem('already_run', 'already_run')
-  performance.mark('cookie_banner_shown')
-  button.click()
-})
+  localStorage.setItem('already_run', 'already_run');
+  button_observer.disconnect();
+  button.click();
+});
 
 button_observer.observe(document, {childList: true, subtree: true});
 
 const headline_observer = new MutationObserver(mutations => {
-  performance.mark('update');
-  const headline = document.getElementById(headline_text_id)
+  const headline = document.getElementById(headline_text_id);
   if (!headline) {
-    return
+    return;
   }
+  headline_observer.disconnect();
   performance.mark('maincontent.created');
 });
 
diff --git a/config/benchmark/loadline/globo_instrumentation.js b/config/benchmark/loadline/globo_instrumentation.js
index 91d49e03..0c3e263b 100644
--- a/config/benchmark/loadline/globo_instrumentation.js
+++ b/config/benchmark/loadline/globo_instrumentation.js
@@ -2,33 +2,34 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-const button_selector = 'button[aria-label=Consent]'
-const banner_selector = 'div[class=fc-consent-root]'
-var banner_observer;
+const button_selector = 'button[aria-label=Consent]';
+const banner_selector = 'div[class=fc-consent-root]';
+let banner_observer;
 
 const button_observer = new MutationObserver(mutations => {
-  const button = document.querySelector(button_selector)
+  const button = document.querySelector(button_selector);
   if (!button) {
-    return
+    return;
   }
   // This script can run multiple times.
   if (localStorage.getItem('already_run') === 'already_run') {
-    return
+    return;
   }
-  localStorage.setItem('already_run', 'already_run')
-  performance.mark('cookie_banner_created')
-  const banner_node = document.querySelector(banner_selector)
+  localStorage.setItem('already_run', 'already_run');
+  button_observer.disconnect();
+  const banner_node = document.querySelector(banner_selector);
   banner_observer = new MutationObserver(function(e) {
     e.forEach(function(m) {
       m.removedNodes.forEach(function(n) {
         if (n === banner_node) {
-          performance.mark('cookie_banner_gone')
+          performance.mark('cookie_banner_gone');
+          banner_observer.disconnect();
         }
-      })
-    })
+      });
+    });
   });
   banner_observer.observe(banner_node.parentNode, {childList: true});
-  button.click()
+  button.click();
 })
 
 button_observer.observe(document, {childList: true, subtree: true});
diff --git a/config/benchmark/loadline/probe_config_experimental.hjson b/config/benchmark/loadline/probe_config_experimental.hjson
index 2bdd8d25..5c455b63 100644
--- a/config/benchmark/loadline/probe_config_experimental.hjson
+++ b/config/benchmark/loadline/probe_config_experimental.hjson
@@ -16,33 +16,63 @@
         "loadline/experimental/worker",
       ],
     },
+    video: {
+      generate_timestrip: false,
+      merge_runs: false,
+    },
     perfetto: {
+      trace_browser_startup: true,
       textproto: '''
         buffers {
           size_kb: 300000
           fill_policy: DISCARD
         }
+        buffers {
+          size_kb: 2048
+          fill_policy: DISCARD
+        }
+        data_sources {
+          config {
+            name: "android.packages_list"
+            target_buffer: 1
+          }
+        }
+        data_sources {
+          config {
+            name: "linux.process_stats"
+            target_buffer: 1
+            process_stats_config {
+              scan_all_processes_on_start: true
+            }
+          }
+        }
         data_sources {
           config {
             name: "org.chromium.trace_metadata"
+            target_buffer: 1
+          }
+        }
+        data_sources: {
+          config {
+            name: "android.surfaceflinger.frametimeline"
           }
         }
         data_sources {
           config {
             name: "track_event"
-            chrome_config {
-                trace_config: "{\"record_mode\":\"record-until-full\",\"included_categories\":[\"benchmark\",\"loading\",\"toplevel\",\"toplevel.flow\",\"devtools.timeline\",\"interactions\",\"v8\",\"v8.execute\",\"blink\",\"blink.user_timing\",\"blink.worker\",\"navigation\",\"gpu\",\"scheduler\",\"disabled-by-default-v8.compile\",\"disabled-by-default-v8.runtime_stats\",\"disabled-by-default-histogram_samples\",\"disabled-by-default-devtools.timeline\"],\"excluded_categories\":[\"*\"],\"histogram_names\":[\"Blink.UseCounter.Features\"]}"
-                privacy_filtering_enabled: false
-                client_priority: USER_INITIATED
-            }
             track_event_config {
               disabled_categories: "*"
               enabled_categories: "benchmark"
               enabled_categories: "loading"
+              enabled_categories: "power"
               enabled_categories: "toplevel"
               enabled_categories: "toplevel.flow"
               enabled_categories: "devtools.timeline"
+              enabled_categories: "devtools.timeline.frame"
               enabled_categories: "interactions"
+              enabled_categories: "scrolling.input"
+              enabled_categories: "Graphics.Pipeline"
+              enabled_categories: "viz"
               enabled_categories: "v8"
               enabled_categories: "v8.execute"
               enabled_categories: "blink"
@@ -54,6 +84,7 @@
               enabled_categories: "disabled-by-default-v8.compile"
               enabled_categories: "disabled-by-default-v8.runtime_stats"
               enabled_categories: "disabled-by-default-histogram_samples"
+              enabled_categories: "disabled-by-default-devtools.screenshot"
               enabled_categories: "disabled-by-default-devtools.timeline"
               enabled_categories: "__metadata"
               timestamp_unit_multiplier: 1000
@@ -63,22 +94,52 @@
             }
           }
         }
-        data_sources: {
-            config {
-                name: "linux.ftrace"
-                ftrace_config {
-                    ftrace_events: "sched/sched_switch"
-                    ftrace_events: "power/suspend_resume"
-                    ftrace_events: "sched/sched_wakeup"
-                    ftrace_events: "sched/sched_wakeup_new"
-                    ftrace_events: "sched/sched_waking"
-                    ftrace_events: "sched/sched_process_exit"
-                    ftrace_events: "sched/sched_process_free"
-                    ftrace_events: "task/task_newtask"
-                    ftrace_events: "task/task_rename"
-                }
+        data_sources {
+          config {
+            name: "linux.sys_stats"
+            sys_stats_config {
+              stat_period_ms: 1000
+              stat_counters: STAT_CPU_TIMES
+              stat_counters: STAT_FORK_COUNT
+              cpufreq_period_ms: 1000
             }
+          }
+        }
+        data_sources {
+          config {
+            name: "linux.ftrace"
+            ftrace_config {
+              ftrace_events: "ftrace/print"
+              ftrace_events: "power/clock_enable"
+              ftrace_events: "power/clock_disable"
+              ftrace_events: "power/clock_set_rate"
+              ftrace_events: "power/cpu_frequency"
+              ftrace_events: "power/cpu_idle"
+              ftrace_events: "power/gpu_frequency"
+              ftrace_events: "power/suspend_resume"
+              ftrace_events: "regulator/regulator_set_voltage"
+              ftrace_events: "regulator/regulator_set_voltage_complete"
+              ftrace_events: "sched/sched_blocked_reason"
+              ftrace_events: "sched/sched_cpu_util_cfs"
+              ftrace_events: "sched/sched_find_energy_efficient_cpu"
+              ftrace_events: "sched/sched_switch"
+              ftrace_events: "sched/sched_wakeup"
+              ftrace_events: "sched/sched_wakeup_new"
+              ftrace_events: "sched/sched_waking"
+              ftrace_events: "sched/sched_process_exit"
+              ftrace_events: "sched/sched_process_free"
+              ftrace_events: "task/task_newtask"
+              ftrace_events: "task/task_rename"
+              atrace_categories: "hal"
+              atrace_categories: "thermal"
+              compact_sched {
+                enabled: true
+              }
+              symbolize_ksyms: true
+            }
+          }
         }
+        data_source_stop_timeout_ms: 500
       '''
     }
   }
diff --git a/config/benchmark/loadline/probe_config_experimental_lightweight.hjson b/config/benchmark/loadline/probe_config_experimental_lightweight.hjson
new file mode 100644
index 00000000..7ff9a012
--- /dev/null
+++ b/config/benchmark/loadline/probe_config_experimental_lightweight.hjson
@@ -0,0 +1,101 @@
+{
+  probes: {
+    trace_processor: {
+      queries: [
+        "loadline/benchmark_score",
+        "loadline/breakdown",
+      ],
+    },
+    perfetto: {
+      trace_browser_startup: true,
+      textproto: '''
+        buffers {
+          size_kb: 300000
+          fill_policy: DISCARD
+        }
+        buffers {
+          size_kb: 2048
+          fill_policy: DISCARD
+        }
+        data_sources {
+          config {
+            name: "android.packages_list"
+            target_buffer: 1
+          }
+        }
+        data_sources {
+          config {
+            name: "linux.process_stats"
+            target_buffer: 1
+            process_stats_config {
+              scan_all_processes_on_start: true
+            }
+          }
+        }
+        data_sources {
+          config {
+            name: "org.chromium.trace_metadata"
+            target_buffer: 1
+          }
+        }
+        data_sources: {
+          config {
+            name: "android.surfaceflinger.frametimeline"
+          }
+        }
+        data_sources {
+          config {
+            name: "track_event"
+            track_event_config {
+              disabled_categories: "*"
+              enabled_categories: "benchmark"
+              enabled_categories: "blink.user_timing"
+              enabled_categories: "devtools.timeline"
+              enabled_categories: "devtools.timeline.frame"
+              enabled_categories: "gpu"
+              enabled_categories: "Graphics.Pipeline"
+              enabled_categories: "loading"
+              enabled_categories: "navigation"
+              enabled_categories: "toplevel"
+              enabled_categories: "toplevel.flow"
+              enabled_categories: "v8"
+              enabled_categories: "disabled-by-default-devtools.timeline"
+              enabled_categories: "__metadata"
+              timestamp_unit_multiplier: 1000
+              enable_thread_time_sampling: true
+              filter_debug_annotations: false
+              filter_dynamic_event_names: false
+            }
+          }
+        }
+        data_sources {
+          config {
+            name: "linux.ftrace"
+            ftrace_config {
+              ftrace_events: "power/cpu_frequency"
+              ftrace_events: "power/cpu_idle"
+              ftrace_events: "sched/sched_blocked_reason"
+              ftrace_events: "sched/sched_cpu_util_cfs"
+              ftrace_events: "sched/sched_find_energy_efficient_cpu"
+              ftrace_events: "sched/sched_switch"
+              ftrace_events: "sched/sched_wakeup"
+              ftrace_events: "sched/sched_wakeup_new"
+              ftrace_events: "sched/sched_waking"
+              ftrace_events: "sched/sched_process_exit"
+              ftrace_events: "sched/sched_process_free"
+              ftrace_events: "task/task_newtask"
+              ftrace_events: "task/task_rename"
+              atrace_categories: "am"
+              atrace_apps: "chrome"
+              compact_sched {
+                enabled: true
+              }
+              symbolize_ksyms: true
+            }
+          }
+        }
+        data_source_stop_timeout_ms: 500
+      '''
+    }
+  }
+}
diff --git a/config/benchmark/loadline/youtube_instrumentation.js b/config/benchmark/loadline/youtube_instrumentation.js
index bdf96e57..aa1c69d8 100644
--- a/config/benchmark/loadline/youtube_instrumentation.js
+++ b/config/benchmark/loadline/youtube_instrumentation.js
@@ -3,35 +3,36 @@
 // found in the LICENSE file.
 
 const button_selector =
-    'div.body.style-scope.ytd-consent-bump-v2-lightbox > div.eom-buttons.style-scope.ytd-consent-bump-v2-lightbox > div:nth-child(1) > ytd-button-renderer:nth-child(1) > yt-button-shape > button'
+    'div.body.style-scope.ytd-consent-bump-v2-lightbox > div.eom-buttons.style-scope.ytd-consent-bump-v2-lightbox > div:nth-child(1) > ytd-button-renderer:nth-child(1) > yt-button-shape > button';
 const banner_selector =
-    'ytd-consent-bump-v2-lightbox > tp-yt-paper-dialog[id=dialog]'
+    'ytd-consent-bump-v2-lightbox > tp-yt-paper-dialog[id=dialog]';
 
 const button_observer = new MutationObserver(mutations => {
-  const button = document.querySelector(button_selector)
+  const button = document.querySelector(button_selector);
   if (!button) {
-    return
+    return;
   }
-  const banner_node = document.querySelector(banner_selector)
+  const banner_node = document.querySelector(banner_selector);
   if (!banner_node) {
-    return
+    return;
   }
   if (localStorage.getItem('already_run') === 'already_run') {
-    return
+    return;
   }
-  localStorage.setItem('already_run', 'already_run')
+  localStorage.setItem('already_run', 'already_run');
+  button_observer.disconnect();
   const banner_observer = new MutationObserver(function(e) {
     for (m of e) {
       if (m.type == 'attributes' && banner_node.style.display == 'none') {
-        performance.mark('cookie_banner_gone')
-        break
+        banner_observer.disconnect();
+        performance.mark('cookie_banner_gone');
+        break;
       }
     }
   });
   banner_observer.observe(
       banner_node, {attributes: true, attributeFilter: ['style']});
-  performance.mark('cookie_banner_shown')
-  button.click()
-})
+  button.click();
+});
 
 button_observer.observe(document, {childList: true, subtree: true});
diff --git a/config/doc/page.config.hjson b/config/doc/page.config.hjson
index e8481938..edf1474e 100644
--- a/config/doc/page.config.hjson
+++ b/config/doc/page.config.hjson
@@ -23,12 +23,23 @@
         //
         //  CLICK: {
         //      action: "click",
-        //      selector: [CSS_SELECTOR, XPATH_SELECTOR],
-        //      required: BOOL,
-        //      scroll_into_view: BOOL,
+        //      position: POSITION,
         //      timeout: DURATION,
+        //      verify: [CSS_SELECTOR, XPATH_SELECTOR],
         //  }
         //
+        //  POSITION: {
+        //    x: NUMBER,
+        //    y: NUMBER,
+        //  } | {
+        //    selector: [CSS_SELECTOR, XPATH_SELECTOR],
+        //    scroll_into_view: BOOL = false,
+        //    required: BOOL = true,
+        //    wait: BOOL = false,
+        //  } | [
+        //    CSS_SELECTOR, XPATH_SELECTOR
+        //  ]
+        //
         //  WAIT: {
         //      action: "wait",
         //      duration: DURATION,
@@ -51,13 +62,17 @@
             // Click away the cookie banner:
       {
         "action": "click",
-        "required": false,
-        "selector": "xpath///button/div[contains(text(),'akzeptieren')]"
+        "position": {
+          "required": false,
+          "selector": "xpath///button/div[contains(text(),'akzeptieren')]",
+        },
       },
       {
         "action": "click",
-        "required": false,
-        "selector": "xpath///button/div[contains(text(),'Accept')]"
+        "position": {
+          "required": false,
+          "selector": "xpath///button/div[contains(text(),'Accept')]",
+        },
       },
       {
         "action": "scroll",
@@ -97,13 +112,17 @@
             // Click away the cookie banner:
       {
         "action": "click",
-        "required": false,
-        "selector": "xpath///*/button[contains(@aria-label, 'akzeptieren')]"
+        "position": {
+          "required": false,
+          "selector": "xpath///*/button[contains(@aria-label, 'akzeptieren')]",
+        },
       },
       {
         "action": "click",
-        "required": false,
-        "selector": "xpath///*/button[contains(@aria-label, 'Accept')]"
+        "position": {
+          "required": false,
+          "selector": "xpath///*/button[contains(@aria-label, 'Accept')]",
+        },
       },
       {
         "action": "scroll",
diff --git a/config/doc/probe/trace_config_file.json b/config/doc/probe/trace_config_file.json
new file mode 100644
index 00000000..483fc202
--- /dev/null
+++ b/config/doc/probe/trace_config_file.json
@@ -0,0 +1,23 @@
+{
+  "startup_duration": 4,
+  "trace_config": {
+    "included_categories": [
+      "disabled-by-default-memory-infra"
+    ],
+    "excluded_categories": [
+      "*"
+    ],
+    "memory_dump_config": {
+      "triggers": [
+        {
+          "mode": "light",
+          "periodic_interval_ms": 50
+        },
+        {
+          "mode": "detailed",
+          "periodic_interval_ms": 1000
+        }
+      ]
+    }
+  }
+}
\ No newline at end of file
diff --git a/config/doc/probe/trace_processor.config.hjson b/config/doc/probe/trace_processor.config.hjson
index 6e402cac..ad5fc9b6 100644
--- a/config/doc/probe/trace_processor.config.hjson
+++ b/config/doc/probe/trace_processor.config.hjson
@@ -2,7 +2,16 @@
 {
   probes: {
     trace_processor: {
-      queries: ["speedometer_cpu_time"],
+      queries: [
+        // Queries can be specified as a reference to a file in
+        // crossbench/probes/perfetto/trace_processor/queries:
+        "speedometer_cpu_time",
+        // Or specified inline:
+        {
+          name: "my_query",
+          sql: "select dur from slice where slice.name = 'my_slice'",
+        },
+      ],
       metrics: ["trace_stats"],
     },
     perfetto: {
diff --git a/config/doc/probe/tracing.config.hjson b/config/doc/probe/tracing.config.hjson
new file mode 100644
index 00000000..f1111296
--- /dev/null
+++ b/config/doc/probe/tracing.config.hjson
@@ -0,0 +1,8 @@
+// tracing probe example config
+{
+  "probes": {
+    "tracing": {
+      "trace_config": "./trace_config_file.json"
+    }
+  }
+}
\ No newline at end of file
diff --git a/config/doc/remote_browser.config.hjson b/config/doc/remote_browser.config.hjson
index 4be37176..b5ec03cc 100644
--- a/config/doc/remote_browser.config.hjson
+++ b/config/doc/remote_browser.config.hjson
@@ -12,6 +12,22 @@
         }
       }
     },
+    // Automatically start chromedriver and forward the port by omitting
+    // driver.settings.port.
+    // Provide the location of chromedriver on the remote machine with
+    // driver.path. If no path is provided, chromedriver must be in $PATH.
+    "linux-ssh-chrome-auto-start-driver": {
+      "path": "/path/to/google/chrome",
+      "driver": {
+        "type": "ssh",
+        "path": "/path/to/chromedriver",
+        "settings": {
+          "host": "my-linux-machine",
+          "ssh_port": 22,
+          "ssh_user": "user"
+        }
+      }
+    },
     "chromeos-ssh-chrome": {
       "path": "/opt/google/chrome/chrome",
       "driver": {
@@ -23,6 +39,21 @@
           "ssh_user": "root"
         }
       }
-    }
+    },
+    // Also automatically start chromedriver on ChromeOS if the port is missing.
+    // If no path to chromedriver is provided, then the default chromedriver
+    // in ChromeOS test images is used.
+    "chromeos-ssh-chrome-auto-start-driver": {
+      "path": "/opt/google/chrome/chrome",
+      "driver": {
+        "type": "chromeos-ssh",
+        "path": "/path/to/chromedriver",
+        "settings": {
+          "host": "my-chromeos-machine",
+          "ssh_port": 22,
+          "ssh_user": "root"
+        }
+      }
+    },
   }
 }
diff --git a/config/doc/templated.config.hjson b/config/doc/templated.config.hjson
new file mode 100644
index 00000000..7261de94
--- /dev/null
+++ b/config/doc/templated.config.hjson
@@ -0,0 +1,47 @@
+{
+  // An example of how to use config templates to enable parameterized tests.
+  //
+  // This example uses page config, but config templates are supported for any
+  // config types.
+  //
+  // For readability the template config is included inline in this example, but
+  // the template can also be a filepath to a different file.
+  //
+  // Parameters can be declared using the $[PARAM_NAME] notation and will be
+  // substituted using the corresponding entry in "args". Parameters can be any
+  // type - including complex types like lists or dicts.
+  //
+  // To escape parameter substitution, use the escape sequence "$[[ ]".
+  // For example: "$[[ don't substitute ]" will result in
+  // "$[ don't substitute ]" in the final config.
+
+  "args": {
+    "GOOGLE_URL": "https://www.google.com",
+    "COOKIE_BANNER_ACTION": {
+        "action": "click",
+        "position": {
+          "required": false,
+          "selector": "xpath///button/div[contains(text(),'akzeptieren')]",
+        },
+    },
+    "SCROLL_DISTANCE": 500,
+    "SCROLL_DURATION": "10s"
+  },
+  "template": {
+    pages: {
+        "Google": [
+            {
+                "action": "get",
+                "url": "$[GOOGLE_URL]",
+                "duration": "2s"
+            },
+            "$[COOKIE_BANNER_ACTION]",
+            {
+                "action": "scroll",
+                "distance": "$[SCROLL_DISTANCE]",
+                "duration": "$[SCROLL_DURATION]"
+            }
+        ]
+    }
+  }
+}
\ No newline at end of file
diff --git a/config/team/woa/android_input_page_config.hjson b/config/team/woa/android_input_page_config.hjson
index ad9bcc0d..56b154f2 100644
--- a/config/team/woa/android_input_page_config.hjson
+++ b/config/team/woa/android_input_page_config.hjson
@@ -4,7 +4,10 @@
     CNN: [
       {action: "get", url: "https://edition.cnn.com"},
       {action: "wait", duration: '5s'},
-      {action: "click", source: "touch", selector: "button[id=onetrust-accept-btn-handler]"},
+      {action: "click", source: "touch", position: {
+        "required": false,
+        "selector": "button[id=onetrust-accept-btn-handler]",
+      }},
       {action: "wait", duration: '5s'},
       {action: "swipe", duration: '1s', startx: 500, starty: 1800, endx: 500, endy: 800},
       {action: "wait", duration: '5s'},
diff --git a/config/team/woa/speedometer_android_gc.hjson b/config/team/woa/speedometer_android_gc.hjson
new file mode 100644
index 00000000..0430b57b
--- /dev/null
+++ b/config/team/woa/speedometer_android_gc.hjson
@@ -0,0 +1,52 @@
+{
+  browsers: {
+    chrome: {
+      browser: "chrome-dev"
+      driver: {
+        type: "adb",
+      }}}
+  env: {}
+  probes: {
+    perfetto: {
+      textproto: '''
+buffers {
+  size_kb: 300000
+  fill_policy: DISCARD
+}
+data_sources: {
+    config {
+        name: "track_event"
+        chrome_config {
+            trace_config: "{\"record_mode\":\"record-until-full\"}"
+            privacy_filtering_enabled: false
+            client_priority: USER_INITIATED
+        }
+        track_event_config {
+            disabled_categories: "*"
+            enabled_categories: "disabled-by-default-v8.gc"
+            enabled_categories: "v8.gc"
+            enabled_categories: "disabled-by-default-cppgc"
+            enabled_categories: "cppgc"
+            enabled_categories: "blink.user_timing"
+            enabled_categories: "__metadata"
+            timestamp_unit_multiplier: 1000
+            filter_debug_annotations: false
+            enable_thread_time_sampling: true
+            filter_dynamic_event_names: false
+        }
+    }
+}
+data_sources: {
+    config {
+        name: "org.chromium.trace_metadata"
+        chrome_config {
+            trace_config: "{\"record_mode\":\"record-until-full\"}"
+            privacy_filtering_enabled: false
+            client_priority: USER_INITIATED
+        }
+    }
+}
+'''
+    }
+  }
+}
diff --git a/config/team/woa/speedometer_power.probe.config.hjson b/config/team/woa/speedometer_power.probe.config.hjson
new file mode 100644
index 00000000..6568d9a6
--- /dev/null
+++ b/config/team/woa/speedometer_power.probe.config.hjson
@@ -0,0 +1,66 @@
+{
+  probes: {
+    trace_processor: {
+      queries: [
+        "speedometer_compute_power_via_rails",
+        "speedometer_compute_power_via_wattson",
+      ],
+    },
+    perfetto: {
+      textproto: '''
+        buffers: {
+            size_kb: 63488
+            fill_policy: DISCARD
+        }
+        data_sources: {
+          config {
+            name: "track_event"
+            track_event_config {
+              disabled_categories: "*"
+              enabled_categories: "blink.user_timing"
+            }
+          }
+        }
+        data_sources {
+          config {
+            name: "org.chromium.trace_metadata"
+          }
+        }
+        data_sources: {
+            config {
+                name: "android.power"
+                android_power_config {
+                    battery_poll_ms: 200
+                    collect_power_rails: true
+                }
+            }
+        }
+        data_sources {
+          config {
+            name: "linux.ftrace"
+            ftrace_config {
+              # Per go/wattson-userguide (sorry, Googlers only).
+              ftrace_events: "power/cpu_frequency"
+              ftrace_events: "power/cpu_idle"
+              ftrace_events: "power/suspend_resume"
+              ftrace_events: "devfreq/devfreq_frequency"
+              # The "Scheduling details" and "CPU frequency and idle states"
+              # toggles are also needed and map to the events below.
+              ftrace_events: "sched/sched_switch"
+              ftrace_events: "sched/sched_blocked_reason"
+              ftrace_events: "sched/sched_wakeup"
+              ftrace_events: "sched/sched_wakeup_new"
+              ftrace_events: "sched/sched_waking"
+              ftrace_events: "sched/sched_process_exit"
+              ftrace_events: "sched/sched_process_free"
+              ftrace_events: "task/task_newtask"
+              ftrace_events: "task/task_rename"
+              symbolize_ksyms: true
+              disable_generic_events: true
+            }
+          }
+        }
+      ''',
+    },
+  },
+}
diff --git a/crossbench/action_runner/action/action.py b/crossbench/action_runner/action/action.py
index b20ca8cb..4925c7d1 100644
--- a/crossbench/action_runner/action/action.py
+++ b/crossbench/action_runner/action/action.py
@@ -6,11 +6,15 @@ from __future__ import annotations
 
 import abc
 import datetime as dt
-from typing import TYPE_CHECKING, Any, Dict, Type, TypeVar
+import functools
+import json
+from typing import TYPE_CHECKING, Any, Dict, Self, Type, TypeVar
+
+from typing_extensions import override
 
 from crossbench import exception
 from crossbench.action_runner.action.action_type import ActionType
-from crossbench.config import ConfigObject, ConfigParser
+from crossbench.config import ConfigObject, ConfigParser, UnusedPropertiesMode
 from crossbench.parse import DurationParser, NumberParser, ObjectParser
 
 if TYPE_CHECKING:
@@ -24,8 +28,9 @@ class ActionTypeConfigParser(ConfigParser):
   Action Configs. This way we can pop the 'value' or 'type' key from the
   config dict."""
 
-  def __init__(self):
-    super().__init__("ActionType parser", ActionType)
+  def __init__(self) -> None:
+    super().__init__(
+        ActionType, unused_properties_mode=UnusedPropertiesMode.IGNORE)
     self.add_argument(
         "action",
         aliases=("type",),
@@ -33,48 +38,59 @@ class ActionTypeConfigParser(ConfigParser):
         required=True)
 
   def new_instance_from_kwargs(self, kwargs: Dict[str, Any]) -> ActionType:
-    return ActionType(kwargs["action"])
+    return ActionType(kwargs["action"])  # type: ignore
 
 
 _ACTION_TYPE_CONFIG_PARSER = ActionTypeConfigParser()
 
 ACTION_TIMEOUT = dt.timedelta(seconds=20)
 
-ActionT = TypeVar("ActionT", bound="Action")
-
 # Lazily initialized Action class lookup.
 ACTIONS: Dict[ActionType, Type[Action]] = {}
 
+# TODO: remove once pytype is fixed/replaced since it gets confused with Self
+# annotations on classmethods with decorators.
+ActionT = TypeVar("ActionT", bound="Action")
 
 class Action(ConfigObject, metaclass=abc.ABCMeta):
   TYPE: ActionType = ActionType.GET
 
   @classmethod
+  @override
   def parse_str(cls, value: str) -> Action:
     return ACTIONS[ActionType.GET].parse_str(value)
 
   @classmethod
-  def parse_dict(cls: Type[ActionT], config: Dict[str, Any]) -> ActionT:
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
     action_type: ActionType = _ACTION_TYPE_CONFIG_PARSER.parse(config)
-    action_cls: Type[ActionT] = ACTIONS[action_type]
+    action_cls: Type[Self] = ACTIONS[action_type]  # type: ignore
+    # Drop _ACTION_TYPE_CONFIG_PARSER arguments/aliases and avoid warnings
+    config = dict(config)
+    config.pop("action", None)
+    config.pop("type", None)
+
     with exception.annotate_argparsing(
         f"Parsing Action details  ...{{ action: \"{action_type}\", ...}}:"):
-      action = action_cls.config_parser().parse(config)
+      action = action_cls.config_parser().parse(config, **kwargs)
     assert isinstance(action, cls), f"Expected {cls} but got {type(action)}"
     return action
 
   @classmethod
+  @override
+  @functools.cache
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
-    parser = ConfigParser(f"{cls.__name__} parser", cls)
-    parser.add_argument(
-        "index", type=NumberParser.positive_zero_int, required=False, default=0)
+    parser = ConfigParser(cls)
+    parser.add_argument("index", type=NumberParser.positive_zero_int, default=0)
     parser.add_argument(
         "timeout",
         type=DurationParser.positive_duration,
         default=ACTION_TIMEOUT)
     return parser
 
-  def __init__(self, timeout: dt.timedelta = ACTION_TIMEOUT, index: int = 0):
+  def __init__(self,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
     self._timeout: dt.timedelta = timeout
     self._index = index
     self.validate()
@@ -99,6 +115,7 @@ class Action(ConfigObject, metaclass=abc.ABCMeta):
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     pass
 
+  @override
   def validate(self) -> None:
     if self._timeout.total_seconds() < 0:
       raise ValueError(
@@ -114,3 +131,6 @@ class Action(ConfigObject, metaclass=abc.ABCMeta):
     if isinstance(other, Action):
       return self.to_json() == other.to_json()
     return False
+
+  def __hash__(self) -> int:
+    return hash(json.dumps(self.to_json()))
diff --git a/crossbench/action_runner/action/action_type.py b/crossbench/action_runner/action/action_type.py
index 5e2dc48f..506c8f1d 100644
--- a/crossbench/action_runner/action/action_type.py
+++ b/crossbench/action_runner/action/action_type.py
@@ -27,6 +27,10 @@ class ActionType(ConfigEnum):
       "Only supported in chromium-based browsers."))
   SCREENSHOT = ("screenshot", "Take a screenshot")
   SWITCH_TAB = ("switch_tab", "Switch the tab that actions are sent to")
+  CLOSE_TAB = ("close_tab", "Close the specified tab")
+  WAIT_FOR_DOWNLOAD = ("wait_for_download", "wait for a download to complete")
   WAIT_FOR_READY_STATE = ("wait_for_ready_state",
                           "Wait for a specific document.readyState")
   DUMP_HTML = ("dump_html", "Dump the current document's HTML")
+  MEET_CREATE = ("meet_create", "Create a Google Meet meeting")
+  MEET_SCRIPT = ("meet_script", "Run a script to automate Meet bot actions")
diff --git a/crossbench/action_runner/action/all.py b/crossbench/action_runner/action/all.py
index 7a143f60..b7a62f26 100644
--- a/crossbench/action_runner/action/all.py
+++ b/crossbench/action_runner/action/all.py
@@ -8,17 +8,22 @@ from typing import Tuple, Type
 
 from crossbench.action_runner.action.action import ACTIONS, Action
 from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.close_tab import CloseTabAction
 from crossbench.action_runner.action.dump_html import DumpHtmlAction
 from crossbench.action_runner.action.get import GetAction
 from crossbench.action_runner.action.inject_new_document_script import \
     InjectNewDocumentScriptAction
 from crossbench.action_runner.action.js import JsAction
+from crossbench.action_runner.action.meet_create import MeetCreateAction
+from crossbench.action_runner.action.meet_script import MeetScriptAction
 from crossbench.action_runner.action.screenshot import ScreenshotAction
 from crossbench.action_runner.action.scroll import ScrollAction
 from crossbench.action_runner.action.swipe import SwipeAction
 from crossbench.action_runner.action.switch_tab import SwitchTabAction
 from crossbench.action_runner.action.text_input import TextInputAction
 from crossbench.action_runner.action.wait import WaitAction
+from crossbench.action_runner.action.wait_for_download import (
+    WaitForDownloadAction)
 from crossbench.action_runner.action.wait_for_element import \
     WaitForElementAction
 from crossbench.action_runner.action.wait_for_ready_state import \
@@ -26,16 +31,20 @@ from crossbench.action_runner.action.wait_for_ready_state import \
 
 ACTIONS_TUPLE: Tuple[Type[Action], ...] = (
     ClickAction,
+    CloseTabAction,
     DumpHtmlAction,
     GetAction,
     InjectNewDocumentScriptAction,
     JsAction,
+    MeetCreateAction,
+    MeetScriptAction,
     ScreenshotAction,
     ScrollAction,
     SwipeAction,
     SwitchTabAction,
     TextInputAction,
     WaitAction,
+    WaitForDownloadAction,
     WaitForElementAction,
     WaitForReadyStateAction,
 )
diff --git a/crossbench/action_runner/action/base_duration.py b/crossbench/action_runner/action/base_duration.py
index 89d9e164..e464198e 100644
--- a/crossbench/action_runner/action/base_duration.py
+++ b/crossbench/action_runner/action/base_duration.py
@@ -5,8 +5,11 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
                                                     ActionT)
 from crossbench.action_runner.action.action_type import ActionType
@@ -27,9 +30,11 @@ class BaseDurationAction(Action):
     super().__init__(timeout, index)
 
   @property
+  @override
   def duration(self) -> dt.timedelta:
     return self._duration
 
+  @override
   def validate(self) -> None:
     super().validate()
     self.validate_duration()
@@ -39,6 +44,7 @@ class BaseDurationAction(Action):
       raise ValueError(
           f"{self}.duration should be positive, but got {self.duration}")
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["duration"] = self.duration.total_seconds()
@@ -49,6 +55,8 @@ class DurationAction(BaseDurationAction):
   TYPE: ActionType = ActionType.WAIT
 
   @classmethod
+  @override
+  @functools.cache
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument(
diff --git a/crossbench/action_runner/action/base_input_source.py b/crossbench/action_runner/action/base_input_source.py
index 5636c70a..fe3ddd9c 100644
--- a/crossbench/action_runner/action/base_input_source.py
+++ b/crossbench/action_runner/action/base_input_source.py
@@ -6,8 +6,11 @@ from __future__ import annotations
 
 import abc
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Tuple, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
 from crossbench.action_runner.action.base_duration import BaseDurationAction
 from crossbench.benchmarks.loading.input_source import InputSource
@@ -20,6 +23,8 @@ if TYPE_CHECKING:
 class InputSourceAction(BaseDurationAction, metaclass=abc.ABCMeta):
 
   @classmethod
+  @override
+  @functools.cache
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument(
@@ -38,6 +43,7 @@ class InputSourceAction(BaseDurationAction, metaclass=abc.ABCMeta):
   def input_source(self) -> InputSource:
     return self._input_source
 
+  @override
   def validate(self) -> None:
     super().validate()
     self.validate_input_source()
@@ -51,6 +57,7 @@ class InputSourceAction(BaseDurationAction, metaclass=abc.ABCMeta):
   def supported_input_sources(self) -> Tuple[InputSource, ...]:
     pass
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["source"] = self.input_source
diff --git a/crossbench/action_runner/action/base_tab_action.py b/crossbench/action_runner/action/base_tab_action.py
new file mode 100644
index 00000000..4f5d24f3
--- /dev/null
+++ b/crossbench/action_runner/action/base_tab_action.py
@@ -0,0 +1,74 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import functools
+import re
+from typing import TYPE_CHECKING, Optional, Type
+
+from typing_extensions import override
+
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
+                                                    ActionT)
+from crossbench.parse import NumberParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.config import ConfigParser
+  from crossbench.types import JsonDict
+
+
+class BaseTabAction(Action, metaclass=abc.ABCMeta):
+
+  @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "tab_index",
+        type=NumberParser.any_int,
+        help=(
+            "The index of the tab. Tabs are indexed in creation "
+            "order. Negative values are allowed, e.g. -1 is the most recently "
+            "opened tab."))
+    parser.add_argument("title", type=ObjectParser.regexp)
+    parser.add_argument("url", type=ObjectParser.regexp)
+    return parser
+
+  def __init__(self,
+               tab_index: Optional[int] = None,
+               title: Optional[re.Pattern] = None,
+               url: Optional[re.Pattern] = None,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._tab_index = tab_index
+    self._title = title
+    self._url = url
+    super().__init__(timeout, index)
+
+  @property
+  def title(self) -> Optional[re.Pattern]:
+    return self._title
+
+  @property
+  def url(self) -> Optional[re.Pattern]:
+    return self._url
+
+  @property
+  def tab_index(self) -> Optional[int]:
+    return self._tab_index
+
+  @override
+  def to_json(self) -> JsonDict:
+    details = super().to_json()
+    if self._tab_index:
+      details["tab_index"] = self._tab_index
+    if self._title:
+      details["title"] = str(self._title.pattern)
+    if self._url:
+      details["url"] = str(self._url.pattern)
+    return details
diff --git a/crossbench/action_runner/action/bond.py b/crossbench/action_runner/action/bond.py
new file mode 100644
index 00000000..c3ddb556
--- /dev/null
+++ b/crossbench/action_runner/action/bond.py
@@ -0,0 +1,13 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.action_runner.action.action import Action
+
+
+class BondAction(Action):
+  """
+  Base class for all actions that use the bond API exposed on ActionRunner.bond.
+  """
diff --git a/crossbench/action_runner/action/click.py b/crossbench/action_runner/action/click.py
index f23a3db6..ecacb560 100644
--- a/crossbench/action_runner/action/click.py
+++ b/crossbench/action_runner/action/click.py
@@ -5,14 +5,17 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Optional, Tuple, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.base_input_source import InputSourceAction
+from crossbench.action_runner.action.position import PositionConfig
 from crossbench.benchmarks.loading.input_source import InputSource
-from crossbench.benchmarks.loading.point import Point
-from crossbench.parse import DurationParser, NumberParser, ObjectParser
+from crossbench.parse import DurationParser, ObjectParser
 
 if TYPE_CHECKING:
   from crossbench.action_runner.base import ActionRunner
@@ -25,92 +28,65 @@ class ClickAction(InputSourceAction):
   TYPE: ActionType = ActionType.CLICK
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
-    parser.add_argument("selector", type=ObjectParser.non_empty_str)
-    parser.add_argument("required", type=ObjectParser.bool, default=False)
     parser.add_argument(
-        "scroll_into_view", type=ObjectParser.bool, default=False)
-    parser.add_argument("x", type=NumberParser.positive_zero_int)
-    parser.add_argument("y", type=NumberParser.positive_zero_int)
+        "position",
+        aliases=("pos", "selector"),
+        type=PositionConfig,
+        required=True)
     parser.add_argument(
         "duration",
         type=DurationParser.positive_or_zero_duration,
         default=dt.timedelta())
+    parser.add_argument("verify", type=ObjectParser.non_empty_str)
     return parser
 
   def __init__(self,
                source: InputSource,
+               position: PositionConfig,
                duration: dt.timedelta = dt.timedelta(),
-               selector: Optional[str] = None,
-               required: bool = False,
-               scroll_into_view: bool = False,
-               x: Optional[int] = None,
-               y: Optional[int] = None,
+               verify: Optional[str] = None,
                timeout: dt.timedelta = ACTION_TIMEOUT,
-               index: int = 0):
-    # TODO: convert to custom selector object.
-    self._selector = selector
-    self._required: bool = required
-    self._scroll_into_view: bool = scroll_into_view
-    self._coordinates: Optional[Point] = None
-    if x is not None and y is not None:
-      self._coordinates = Point(x, y)
+               index: int = 0) -> None:
+    self._position = position
+    self._verify = verify
     super().__init__(source, duration, timeout, index)
 
   @property
-  def selector(self) -> Optional[str]:
-    return self._selector
-
-  @property
-  def required(self) -> bool:
-    return self._required
-
-  @property
-  def scroll_into_view(self) -> bool:
-    return self._scroll_into_view
+  def position(self) -> PositionConfig:
+    return self._position
 
   @property
-  def coordinates(self) -> Optional[Point]:
-    return self._coordinates
+  def verify(self) -> Optional[str]:
+    return self._verify
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.click(run, self)
 
+  @override
   def validate(self) -> None:
     super().validate()
 
-    if self._selector and self._coordinates:
-      raise ValueError("Only one is allowed: either selector or coordinates")
-
-    if not self._selector and not self._coordinates:
-      raise ValueError("Either selector or coordinates are required")
-
-    if self._input_source is InputSource.JS and self._coordinates:
+    if self._input_source is InputSource.JS and self.position.coordinates:
       raise ValueError("X,Y Coordinates cannot be used with JS click source.")
 
-    if self._required and self._coordinates:
-      raise ValueError("'required' is not compatible with coordinates")
-
-    if self._scroll_into_view and self._coordinates:
-      raise ValueError("'scroll_into_view' is not compatible with coordinates")
-
+  @override
   def validate_duration(self) -> None:
     # A click action is allowed to have a zero duration.
     return
 
+  @override
   def supported_input_sources(self) -> Tuple[InputSource, ...]:
     return (InputSource.JS, InputSource.TOUCH, InputSource.MOUSE)
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
-
-    if self._selector:
-      details["selector"] = self._selector
-      details["required"] = self._required
-      details["scroll_into_view"] = self._scroll_into_view
-    else:
-      assert self._coordinates
-      details["x"] = self._coordinates.x
-      details["y"] = self._coordinates.y
+    details["position"] = self._position.to_json()
+    if self._verify:
+      details["verify"] = self._verify
     return details
diff --git a/crossbench/action_runner/action/close_tab.py b/crossbench/action_runner/action/close_tab.py
new file mode 100644
index 00000000..e5e0e99e
--- /dev/null
+++ b/crossbench/action_runner/action/close_tab.py
@@ -0,0 +1,34 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import functools
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.action_runner.action.base_tab_action import BaseTabAction
+from crossbench.action_runner.action.action_type import ActionType
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.action.action import ActionT
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+
+
+class CloseTabAction(BaseTabAction):
+  TYPE: ActionType = ActionType.CLOSE_TAB
+
+  @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    return parser
+
+  @override
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.close_tab(run, self)
diff --git a/crossbench/action_runner/action/dump_html.py b/crossbench/action_runner/action/dump_html.py
index f1916e4b..656d60ad 100644
--- a/crossbench/action_runner/action/dump_html.py
+++ b/crossbench/action_runner/action/dump_html.py
@@ -6,6 +6,8 @@ from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import Action
 from crossbench.action_runner.action.action_type import ActionType
 
@@ -17,5 +19,6 @@ if TYPE_CHECKING:
 class DumpHtmlAction(Action):
   TYPE: ActionType = ActionType.DUMP_HTML
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.dump_html(run, self)
diff --git a/crossbench/action_runner/action/get.py b/crossbench/action_runner/action/get.py
index 409289e7..616222b2 100644
--- a/crossbench/action_runner/action/get.py
+++ b/crossbench/action_runner/action/get.py
@@ -5,7 +5,10 @@
 from __future__ import annotations
 
 import datetime as dt
-from typing import TYPE_CHECKING, Type
+import functools
+from typing import TYPE_CHECKING, Self, Type
+
+from typing_extensions import override
 
 from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
 from crossbench.action_runner.action.action_type import ActionType
@@ -24,14 +27,16 @@ class GetAction(BaseDurationAction):
   TYPE: ActionType = ActionType.GET
 
   @classmethod
-  def parse_str(cls, value: str) -> GetAction:
-    return cls(url=ObjectParser.parse_fuzzy_url_str(value))
+  @override
+  def parse_str(cls, value: str) -> Self:
+    return cls(url=ObjectParser.fuzzy_url_str(value))
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
-    parser.add_argument(
-        "url", type=ObjectParser.parse_fuzzy_url_str, required=True)
+    parser.add_argument("url", type=ObjectParser.fuzzy_url_str, required=True)
     parser.add_argument(
         "duration",
         type=DurationParser.positive_or_zero_duration,
@@ -48,7 +53,7 @@ class GetAction(BaseDurationAction):
                timeout: dt.timedelta = ACTION_TIMEOUT,
                ready_state: ReadyState = ReadyState.ANY,
                target: WindowTarget = WindowTarget.SELF,
-               index: int = 0):
+               index: int = 0) -> None:
     if not url:
       raise ValueError(f"{self}.url is missing")
     self._url: str = url
@@ -56,6 +61,7 @@ class GetAction(BaseDurationAction):
     self._target = target
     super().__init__(duration, timeout, index)
 
+  @override
   def validate_duration(self) -> None:
     if self.ready_state != ReadyState.ANY:
       if self.duration != dt.timedelta():
@@ -73,6 +79,7 @@ class GetAction(BaseDurationAction):
     return self._ready_state
 
   @property
+  @override
   def duration(self) -> dt.timedelta:
     return self._duration
 
@@ -80,9 +87,11 @@ class GetAction(BaseDurationAction):
   def target(self) -> WindowTarget:
     return self._target
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.get(run, self)
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["url"] = self.url
diff --git a/crossbench/action_runner/action/inject_new_document_script.py b/crossbench/action_runner/action/inject_new_document_script.py
index d9ec0089..cc7c5376 100644
--- a/crossbench/action_runner/action/inject_new_document_script.py
+++ b/crossbench/action_runner/action/inject_new_document_script.py
@@ -6,6 +6,8 @@ from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.js import JsAction
 
@@ -17,5 +19,6 @@ if TYPE_CHECKING:
 class InjectNewDocumentScriptAction(JsAction):
   TYPE: ActionType = ActionType.INJECT_NEW_DOCUMENT_SCRIPT
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.inject_new_document_script(run, self)
diff --git a/crossbench/action_runner/action/js.py b/crossbench/action_runner/action/js.py
index 9bfbbde2..33980ef0 100644
--- a/crossbench/action_runner/action/js.py
+++ b/crossbench/action_runner/action/js.py
@@ -5,9 +5,12 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 import logging
 from typing import TYPE_CHECKING, Any, Dict, Optional, Type
 
+from typing_extensions import override
+
 from crossbench import exception
 from crossbench import path as pth
 from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
@@ -36,6 +39,8 @@ class JsAction(Action):
   TYPE: ActionType = ActionType.JS
 
   @classmethod
+  @override
+  @functools.cache
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument("script", type=ObjectParser.non_empty_str)
@@ -74,15 +79,18 @@ class JsAction(Action):
   def script(self) -> str:
     return self._script
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.js(run, self)
 
+  @override
   def validate(self) -> None:
     super().validate()
     if not self.script:
       raise ValueError(
           f"{self}.script is missing or the provided script file is empty.")
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     if self._original_script:
diff --git a/crossbench/action_runner/action/meet_create.py b/crossbench/action_runner/action/meet_create.py
new file mode 100644
index 00000000..9e8a6bbe
--- /dev/null
+++ b/crossbench/action_runner/action/meet_create.py
@@ -0,0 +1,57 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import functools
+from typing import TYPE_CHECKING, Optional, Type
+
+from typing_extensions import override
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.bond import BondAction
+from crossbench.action_runner.action.enums import WindowTarget
+from crossbench.bond.bond import AddBotsConfig
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+
+
+class MeetCreateAction(BondAction):
+  TYPE: ActionType = ActionType.MEET_CREATE
+
+  @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument("bots", type=AddBotsConfig)
+    parser.add_argument(
+        "target", type=WindowTarget.parse, default=WindowTarget.SELF)
+    return parser
+
+  def __init__(self,
+               bots: Optional[AddBotsConfig] = None,
+               target: WindowTarget = WindowTarget.SELF,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._bots = bots
+    self._target = target
+    super().__init__(timeout, index)
+
+  @property
+  def bots(self) -> Optional[AddBotsConfig]:
+    return self._bots
+
+  @property
+  def target(self) -> WindowTarget:
+    return self._target
+
+  @override
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.bond.meet_create(run, self)
diff --git a/crossbench/action_runner/action/meet_script.py b/crossbench/action_runner/action/meet_script.py
new file mode 100644
index 00000000..2839da13
--- /dev/null
+++ b/crossbench/action_runner/action/meet_script.py
@@ -0,0 +1,52 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import functools
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.action_runner.action.bond import BondAction
+from crossbench.parse import ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.config import ConfigParser
+  from crossbench.runner.run import Run
+
+
+# This action is different from the `JsAction` in that it is not executed on the
+# client side, but rather on the server side. This allows for more complex
+# interactions with the Meet API, such as directing bots to present, or pin a
+# participant.
+class MeetScriptAction(BondAction):
+  TYPE: ActionType = ActionType.MEET_SCRIPT
+
+  @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "script", type=ObjectParser.non_empty_str, required=True)
+    return parser
+
+  def __init__(self,
+               script: str,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._script = script
+    super().__init__(timeout, index)
+
+  @property
+  def script(self) -> str:
+    return self._script
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.bond.meet_script(run, self)
diff --git a/crossbench/action_runner/action/position.py b/crossbench/action_runner/action/position.py
new file mode 100644
index 00000000..3e31ed17
--- /dev/null
+++ b/crossbench/action_runner/action/position.py
@@ -0,0 +1,137 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import functools
+from typing import TYPE_CHECKING, Dict, Self, Type
+
+from typing_extensions import override
+
+from crossbench.benchmarks.loading.point import Point
+from crossbench.config import ConfigObject, ConfigParser, UnusedPropertiesMode
+from crossbench.parse import NumberParser, ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.types import JsonDict
+
+
+@dataclasses.dataclass(frozen=True)
+class CoordinatesConfig(ConfigObject):
+  x: int
+  y: int
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str):
+    del value
+    raise NotImplementedError("Cannot create CoordinatesConfig from string")
+
+  @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
+  def config_parser(
+      cls: Type[CoordinatesConfig]) -> ConfigParser[CoordinatesConfig]:
+    parser = ConfigParser(
+        cls, unused_properties_mode=UnusedPropertiesMode.ERROR)
+    parser.add_argument("x", type=NumberParser.positive_zero_int, required=True)
+    parser.add_argument("y", type=NumberParser.positive_zero_int, required=True)
+    return parser
+
+  def point(self) -> Point:
+    return Point(self.x, self.y)
+
+
+@dataclasses.dataclass(frozen=True)
+class SelectorConfig(ConfigObject):
+  selector: str
+
+  required: bool
+  scroll_into_view: bool
+  wait: bool
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    selector = ObjectParser.non_empty_str(value, "selector")
+    return cls(
+        selector=selector, required=True, scroll_into_view=False, wait=False)
+
+  @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
+  def config_parser(cls: Type[SelectorConfig]) -> ConfigParser[SelectorConfig]:
+    parser = ConfigParser(
+        cls, unused_properties_mode=UnusedPropertiesMode.ERROR)
+    parser.add_argument(
+        "selector", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument("required", type=ObjectParser.bool, default=True)
+    parser.add_argument(
+        "scroll_into_view", type=ObjectParser.bool, default=False)
+    parser.add_argument("wait", type=ObjectParser.bool, default=False)
+    return parser
+
+
+@dataclasses.dataclass(frozen=True)
+class PositionConfig(ConfigObject):
+  coordinates: CoordinatesConfig | None = None
+  selector: SelectorConfig | None = None
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    return cls(selector=SelectorConfig.parse_str(value))
+
+  @classmethod
+  @override
+  def parse_dict(cls, config: Dict, **kwargs) -> Self:
+    selector_parser = SelectorConfig.config_parser()
+    if selector_parser.has_all_required_args(config):
+      return cls(selector=selector_parser.parse(config))
+
+    coordinates_parser = CoordinatesConfig.config_parser()
+    if coordinates_parser.has_all_required_args(config):
+      return cls(coordinates=coordinates_parser.parse(config))
+
+    raise argparse.ArgumentTypeError(
+        f"{config} is not a valid coordinate or selector")
+
+  @classmethod
+  def from_coordinates(cls, x: int, y: int) -> Self:
+    return cls(coordinates=CoordinatesConfig(x, y))
+
+  @classmethod
+  def from_selector(cls,
+                    selector: str,
+                    required: bool = True,
+                    scroll_into_view: bool = False,
+                    wait: bool = False) -> Self:
+    return cls(
+        selector=SelectorConfig(
+            selector=selector,
+            required=required,
+            scroll_into_view=scroll_into_view,
+            wait=wait))
+
+  @override
+  def validate(self) -> None:
+    super().validate()
+    if bool(self.coordinates) == bool(self.selector):
+      raise ValueError(
+          "Position config must have exactly one coordinates or selector")
+
+  def to_json(self) -> JsonDict:
+    if coordinates := self.coordinates:
+      return {"x": coordinates.x, "y": coordinates.y}
+    if selector := self.selector:
+      return {
+          "required": selector.required,
+          "scroll_into_view": selector.scroll_into_view,
+          "selector": selector.selector,
+          "wait": selector.wait,
+      }
+    raise ValueError(
+        "Position config must have exactly one coordinates or selector")
diff --git a/crossbench/action_runner/action/screenshot.py b/crossbench/action_runner/action/screenshot.py
index ffa47576..f3a9c19c 100644
--- a/crossbench/action_runner/action/screenshot.py
+++ b/crossbench/action_runner/action/screenshot.py
@@ -6,6 +6,8 @@ from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import Action
 from crossbench.action_runner.action.action_type import ActionType
 
@@ -17,5 +19,6 @@ if TYPE_CHECKING:
 class ScreenshotAction(Action):
   TYPE: ActionType = ActionType.SCREENSHOT
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.screenshot(run, self)
diff --git a/crossbench/action_runner/action/scroll.py b/crossbench/action_runner/action/scroll.py
index 60ba47e0..3d180774 100644
--- a/crossbench/action_runner/action/scroll.py
+++ b/crossbench/action_runner/action/scroll.py
@@ -5,8 +5,11 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Optional, Tuple, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.base_input_source import InputSourceAction
@@ -24,6 +27,8 @@ class ScrollAction(InputSourceAction):
   TYPE: ActionType = ActionType.SCROLL
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument("distance", type=NumberParser.any_float, default=500)
@@ -62,9 +67,11 @@ class ScrollAction(InputSourceAction):
   def required(self) -> bool:
     return self._required
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.scroll(run, self)
 
+  @override
   def validate(self) -> None:
     super().validate()
     if not self.distance:
@@ -74,9 +81,11 @@ class ScrollAction(InputSourceAction):
       raise ValueError(
           "'required' can only be used when a selector is specified")
 
+  @override
   def supported_input_sources(self) -> Tuple[InputSource, ...]:
     return (InputSource.JS, InputSource.TOUCH)
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["distance"] = str(self.distance)
diff --git a/crossbench/action_runner/action/swipe.py b/crossbench/action_runner/action/swipe.py
index 80cf1103..c9c599e9 100644
--- a/crossbench/action_runner/action/swipe.py
+++ b/crossbench/action_runner/action/swipe.py
@@ -5,8 +5,11 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.base_duration import DurationAction
@@ -23,6 +26,8 @@ class SwipeAction(DurationAction):
   TYPE: ActionType = ActionType.SWIPE
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument(
@@ -71,9 +76,11 @@ class SwipeAction(DurationAction):
   def end_y(self) -> int:
     return self._end_y
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.swipe(run, self)
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["start_x"] = self._start_x
diff --git a/crossbench/action_runner/action/switch_tab.py b/crossbench/action_runner/action/switch_tab.py
index cf4dbfe5..f2a7c6d1 100644
--- a/crossbench/action_runner/action/switch_tab.py
+++ b/crossbench/action_runner/action/switch_tab.py
@@ -4,71 +4,38 @@
 
 from __future__ import annotations
 
-import datetime as dt
-import re
-from typing import TYPE_CHECKING, Optional, Type
+import functools
+from typing import TYPE_CHECKING, Type
 
-from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
-                                                    ActionT)
+from typing_extensions import override
+
+from crossbench.action_runner.action.base_tab_action import BaseTabAction
 from crossbench.action_runner.action.action_type import ActionType
-from crossbench.parse import NumberParser, ObjectParser
 
 if TYPE_CHECKING:
+  from crossbench.action_runner.action.action import ActionT
   from crossbench.action_runner.base import ActionRunner
   from crossbench.config import ConfigParser
   from crossbench.runner.run import Run
-  from crossbench.types import JsonDict
 
 
-class SwitchTabAction(Action):
+class SwitchTabAction(BaseTabAction):
   TYPE: ActionType = ActionType.SWITCH_TAB
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
-    parser.add_argument(
-        "tab_index",
-        type=NumberParser.any_int,
-        help=(
-            "The index of the tab to switch to. Tabs are indexed in creation "
-            "order. Negative values are allowed, e.g. -1 is the most recently "
-            "opened tab."))
-    parser.add_argument("title", type=ObjectParser.regexp)
-    parser.add_argument("url", type=ObjectParser.regexp)
     return parser
 
-  def __init__(self,
-               tab_index: Optional[int] = None,
-               title: Optional[re.Pattern] = None,
-               url: Optional[re.Pattern] = None,
-               timeout: dt.timedelta = ACTION_TIMEOUT,
-               index: int = 0) -> None:
-    self._title = title
-    self._url = url
-    self._tab_index = tab_index
-    super().__init__(timeout, index)
-
-  @property
-  def title(self) -> Optional[re.Pattern]:
-    return self._title
-
-  @property
-  def url(self) -> Optional[re.Pattern]:
-    return self._url
-
-  @property
-  def tab_index(self) -> Optional[int]:
-    return self._tab_index
-
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.switch_tab(run, self)
 
-  def to_json(self) -> JsonDict:
-    details = super().to_json()
-    if self._tab_index:
-      details["tab_index"] = self._tab_index
-    if self._title:
-      details["title"] = str(self._title.pattern)
-    if self._url:
-      details["url"] = str(self._url.pattern)
-    return details
+  @override
+  def validate(self) -> None:
+    super().validate()
+
+    if not self.title and not self.url and self.tab_index is None:
+      raise ValueError("One of tab_index, title, or url is required.")
diff --git a/crossbench/action_runner/action/text_input.py b/crossbench/action_runner/action/text_input.py
index 9b013b7a..02ac2891 100644
--- a/crossbench/action_runner/action/text_input.py
+++ b/crossbench/action_runner/action/text_input.py
@@ -5,8 +5,11 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Tuple, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import ACTION_TIMEOUT, ActionT
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.base_input_source import InputSourceAction
@@ -24,6 +27,8 @@ class TextInputAction(InputSourceAction):
   TYPE: ActionType = ActionType.TEXT_INPUT
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument("text", type=ObjectParser.non_empty_str, required=True)
@@ -46,21 +51,26 @@ class TextInputAction(InputSourceAction):
   def text(self) -> str:
     return self._text
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.text_input(run, self)
 
+  @override
   def validate(self) -> None:
     super().validate()
     if not self._text:
       raise ValueError(f"{self}.text is missing.")
 
+  @override
   def validate_duration(self) -> None:
     # A text input action is allowed to have a zero duration.
     return
 
+  @override
   def supported_input_sources(self) -> Tuple[InputSource, ...]:
     return (InputSource.JS, InputSource.KEYBOARD)
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["text"] = self._text
diff --git a/crossbench/action_runner/action/wait.py b/crossbench/action_runner/action/wait.py
index af7c5f59..18309c4e 100644
--- a/crossbench/action_runner/action/wait.py
+++ b/crossbench/action_runner/action/wait.py
@@ -6,6 +6,8 @@ from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.base_duration import DurationAction
 
@@ -17,5 +19,7 @@ if TYPE_CHECKING:
 class WaitAction(DurationAction):
   TYPE: ActionType = ActionType.WAIT
 
+
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.wait(run, self)
diff --git a/crossbench/action_runner/action/wait_for_download.py b/crossbench/action_runner/action/wait_for_download.py
new file mode 100644
index 00000000..1fc48178
--- /dev/null
+++ b/crossbench/action_runner/action/wait_for_download.py
@@ -0,0 +1,52 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import functools
+import re
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
+                                                    ActionT)
+from crossbench.action_runner.action.action_type import ActionType
+from crossbench.config import ConfigParser
+from crossbench.parse import ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.runner.run import Run
+
+
+class WaitForDownloadAction(Action):
+  TYPE: ActionType = ActionType.WAIT_FOR_DOWNLOAD
+
+  @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
+  def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
+    parser = super().config_parser()
+    parser.add_argument(
+        "pattern",
+        type=ObjectParser.regexp,
+        help="A regexp to search downloaded file names",
+        required=True)
+    return parser
+
+  def __init__(self,
+               pattern: re.Pattern,
+               timeout: dt.timedelta = ACTION_TIMEOUT,
+               index: int = 0) -> None:
+    self._pattern = pattern
+    super().__init__(timeout, index)
+
+  @property
+  def pattern(self) -> re.Pattern:
+    return self._pattern
+
+  def run_with(self, run: Run, action_runner: ActionRunner) -> None:
+    action_runner.wait_for_download(run, self)
diff --git a/crossbench/action_runner/action/wait_for_element.py b/crossbench/action_runner/action/wait_for_element.py
index a50ede40..032c9faf 100644
--- a/crossbench/action_runner/action/wait_for_element.py
+++ b/crossbench/action_runner/action/wait_for_element.py
@@ -5,12 +5,15 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
                                                     ActionT)
 from crossbench.action_runner.action.action_type import ActionType
-from crossbench.parse import ObjectParser
+from crossbench.parse import NumberParser, ObjectParser
 
 if TYPE_CHECKING:
   from crossbench.action_runner.base import ActionRunner
@@ -23,32 +26,58 @@ class WaitForElementAction(Action):
   TYPE: ActionType = ActionType.WAIT_FOR_ELEMENT
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument(
         "selector", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "expected_count",
+        type=NumberParser.positive_int,
+        required=False,
+        default=1)
+    parser.add_argument("or_more", type=bool, required=False, default=False)
     return parser
 
   def __init__(self,
                selector: str,
+               expected_count: int,
+               or_more: bool,
                timeout: dt.timedelta = ACTION_TIMEOUT,
-               index: int = 0):
+               index: int = 0) -> None:
     self._selector = selector
+    self._expected_count = expected_count
+    self._or_more = or_more
     super().__init__(timeout, index)
 
   @property
   def selector(self) -> str:
     return self._selector
 
+  @property
+  def expected_count(self) -> int:
+    return self._expected_count
+
+  @property
+  def or_more(self) -> bool:
+    return self._or_more
+
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.wait_for_element(run, self)
 
+  @override
   def validate(self) -> None:
     super().validate()
     if not self.selector:
       raise ValueError(f"{self}.selector is missing.")
+    NumberParser.positive_int(self.expected_count, "expected_count")
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["selector"] = self.selector
+    details["expected_count"] = self.expected_count
+    details["or_more"] = self.or_more
     return details
diff --git a/crossbench/action_runner/action/wait_for_ready_state.py b/crossbench/action_runner/action/wait_for_ready_state.py
index c5e00a9e..3beccbd0 100644
--- a/crossbench/action_runner/action/wait_for_ready_state.py
+++ b/crossbench/action_runner/action/wait_for_ready_state.py
@@ -5,8 +5,11 @@
 from __future__ import annotations
 
 import datetime as dt
+import functools
 from typing import TYPE_CHECKING, Type
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import (ACTION_TIMEOUT, Action,
                                                     ActionT)
 from crossbench.action_runner.action.action_type import ActionType
@@ -23,6 +26,8 @@ class WaitForReadyStateAction(Action):
   TYPE: ActionType = ActionType.WAIT_FOR_READY_STATE
 
   @classmethod
+  @override
+  @functools.lru_cache(maxsize=1)
   def config_parser(cls: Type[ActionT]) -> ConfigParser[ActionT]:
     parser = super().config_parser()
     parser.add_argument(
@@ -32,7 +37,7 @@ class WaitForReadyStateAction(Action):
   def __init__(self,
                timeout: dt.timedelta = ACTION_TIMEOUT,
                ready_state: ReadyState = ReadyState.COMPLETE,
-               index: int = 0):
+               index: int = 0) -> None:
     self._ready_state = ready_state
     super().__init__(timeout, index)
 
@@ -40,9 +45,11 @@ class WaitForReadyStateAction(Action):
   def ready_state(self) -> ReadyState:
     return self._ready_state
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner) -> None:
     action_runner.wait_for_ready_state(run, self)
 
+  @override
   def to_json(self) -> JsonDict:
     details = super().to_json()
     details["ready_state"] = str(self.ready_state)
diff --git a/crossbench/action_runner/android_input_action_runner.py b/crossbench/action_runner/android_input_action_runner.py
index 40402e4a..03a9e113 100644
--- a/crossbench/action_runner/android_input_action_runner.py
+++ b/crossbench/action_runner/android_input_action_runner.py
@@ -11,10 +11,12 @@ from typing import List, Optional
 
 from crossbench.action_runner.action import all as i_action
 from crossbench.action_runner.base import InputSourceNotImplementedError
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
 from crossbench.action_runner.display_rectangle import DisplayRectangle
 from crossbench.action_runner.element_not_found_error import \
     ElementNotFoundError
+from crossbench.action_runner.screenshot_annotation import (
+    ScreenshotPointAnnotation, ScreenshotRectAnnotation)
 from crossbench.benchmarks.loading.point import Point
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.runner.actions import Actions
@@ -28,7 +30,7 @@ class ViewportInfo:
                window_inner_height: int,
                window_inner_width: int,
                element_rect: Optional[DisplayRectangle] = None) -> None:
-    self._element_rect: Optional[DisplayRectangle] = None
+    self._element_rect: DisplayRectangle | None = None
 
     # On android, clank does not report the correct window.devicePixelRatio
     # when a page is zoomed.
@@ -59,6 +61,7 @@ class ViewportInfo:
     if element_rect:
       self._element_rect = (element_rect * self.actual_pixel_ratio).shift_by(
           self._chrome_window)
+      self._element_rect = self.chrome_window.intersection(self._element_rect)
 
   @property
   def chrome_window(self) -> DisplayRectangle:
@@ -80,11 +83,11 @@ class ViewportInfo:
     return distance * self.actual_pixel_ratio
 
 
-class AndroidInputActionRunner(BasicActionRunner):
+class AndroidInputActionRunner(DefaultActionRunner):
 
   # Represents the position of the chrome main window relative to the entire
   # screen as reported by Android window manager.
-  _raw_chrome_window_bounds: Optional[DisplayRectangle] = None
+  _raw_chrome_window_bounds: DisplayRectangle | None = None
 
   @property
   def raw_chrome_window_bounds(self) -> DisplayRectangle:
@@ -130,10 +133,8 @@ return [
             raise ElementNotFoundError(action.selector)
           return
 
-      scrollable_top = scroll_area.top
-      scrollable_bottom = scroll_area.bottom
-
-      max_swipe_distance = scrollable_bottom - scrollable_top
+      (scrollable_top, scrollable_bottom,
+       max_swipe_distance) = scroll_area.get_scrollable_area()
 
       remaining_distance = abs(total_scroll_distance)
 
@@ -181,34 +182,55 @@ return [
     if action.duration > dt.timedelta():
       raise InputSourceNotImplementedError(self, action, action.input_source,
                                            "Non-zero duration not implemented")
-
+    coordinates: Point | None = None
     with run.actions("ClickAction", measure=False) as actions:
 
-      coordinates = action.coordinates
-
-      if action.selector:
-        viewport_info = self._get_viewport_info(run, actions, action.selector,
-                                                action.scroll_into_view)
+      if coordinates_config := action.position.coordinates:
+        coordinates = coordinates_config.point()
+      elif selector_config := action.position.selector:
+        if selector_config.wait:
+          self.wait_for_element_impl(
+              actions,
+              selector=selector_config.selector,
+              timeout=action.timeout,
+              scroll_into_view=selector_config.scroll_into_view,
+              check_element_rect=True,
+              required=selector_config.required)
+
+        viewport_info = self._get_viewport_info(
+            run, actions, selector_config.selector,
+            selector_config.scroll_into_view)
 
         rect = viewport_info.element_rect()
         if not rect:
           logging.warning("No clickable element_rect found for %s",
-                          action.selector)
-          if action.required:
-            raise ElementNotFoundError(action.selector)
+                          selector_config.selector)
+          if selector_config.required:
+            raise ElementNotFoundError(selector_config.selector)
           return
 
+        self.add_failure_screenshot_annotation(
+            ScreenshotRectAnnotation(label=selector_config.selector, rect=rect))
         coordinates = Point(rect.mid_x, rect.mid_y)
 
       cmd: List[str] = ["input"]
 
       if use_mouse:
         cmd.append("mouse")
-
+      assert coordinates, "missing coordinates"
+      self.add_failure_screenshot_annotation(
+          ScreenshotPointAnnotation(label="click", point=coordinates))
       cmd.extend(["tap", str(coordinates.x), str(coordinates.y)])
 
       run.browser_platform.sh(*cmd)
 
+      if action.verify:
+        self.wait_for_element_impl(
+            actions,
+            selector=action.verify,
+            timeout=action.timeout,
+            check_element_rect=True)
+
   def _swipe_impl(self, run: Run, start_x: int, start_y: int, end_x: int,
                   end_y: int, duration: dt.timedelta) -> None:
 
@@ -241,7 +263,7 @@ return [
     if not self._raw_chrome_window_bounds:
       self._raw_chrome_window_bounds = self._find_chrome_window_size(run)
 
-    element_rect: Optional[DisplayRectangle] = None
+    element_rect: DisplayRectangle | None = None
     if found_element:
       element_rect = DisplayRectangle(Point(left, top), width, height)
 
@@ -271,18 +293,14 @@ return [
     #
     # mAppBounds=Rect(0, 0 - 480, 800)
     browser_main_window_name = self._get_browser_window_name(
-        run.browser.attributes)
-
-    raw_window_config = run.browser_platform.sh_stdout(
-        "dumpsys",
-        "window",
-        "windows",
-        "|",
-        "grep",
-        "-E",
-        "-A100",
-        browser_main_window_name,
-    )
+        run.browser.attributes())
+
+    raw_window_config = run.browser_platform.sh_stdout("dumpsys", "window",
+                                                       "windows")
+
+    raw_window_config = raw_window_config[raw_window_config
+                                          .find(browser_main_window_name):]
+
     match = self._BOUNDS_RE.search(raw_window_config)
     if not match:
       raise RuntimeError("Could not find chrome window bounds")
diff --git a/crossbench/action_runner/base.py b/crossbench/action_runner/base.py
index 0c587084..c3c2f389 100644
--- a/crossbench/action_runner/base.py
+++ b/crossbench/action_runner/base.py
@@ -4,11 +4,13 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Iterable, Optional
+from typing import TYPE_CHECKING, Iterable, List, Optional, Sequence
 
 from crossbench import exception
 from crossbench.action_runner.action_runner_listener import \
     ActionRunnerListener
+from crossbench.action_runner.bond_base import BondActionRunner
+from crossbench.action_runner.screenshot_annotation import ScreenshotAnnotation
 from crossbench.benchmarks.loading.input_source import InputSource
 
 if TYPE_CHECKING:
@@ -18,7 +20,6 @@ if TYPE_CHECKING:
   from crossbench.benchmarks.loading.page.combined import CombinedPage
   from crossbench.benchmarks.loading.page.interactive import InteractivePage
   from crossbench.benchmarks.loading.tab_controller import TabController
-  from crossbench.path import LocalPath
   from crossbench.runner.run import Run
 
 
@@ -55,17 +56,17 @@ class InputSourceNotImplementedError(ActionNotImplementedError):
 
     super().__init__(runner, action, input_source_message)
 
-
 class ActionRunner:
 
-  def __init__(self):
+  def __init__(self) -> None:
     self._listener = ActionRunnerListener()
+    # TODO: Don't share state across runs
+    self._info_stack: exception.TInfoStack | None = None
 
-  def set_listener(self, listener):
-    self._listener = listener
+    self._failure_screenshot_annotations: List[ScreenshotAnnotation] = []
 
-  # TODO: Don't share state across runs
-  _info_stack: Optional[exception.TInfoStack]
+  def set_listener(self, listener: ActionRunnerListener) -> None:
+    self._listener = listener
 
   # info_stack is a unique identifier for the currently running or most recently
   # run action.
@@ -75,6 +76,14 @@ class ActionRunner:
       raise RuntimeError("info_stack can not be called before run_blocks")
     return self._info_stack
 
+  @property
+  def bond(self) -> BondActionRunner:
+    return BondActionRunner()
+
+  def teardown(self, run: Run) -> None:
+    del run
+    pass
+
   def run_blocks(self, run: Run, page: InteractivePage,
                  blocks: Iterable[ActionBlock]) -> None:
     for block in blocks:
@@ -87,6 +96,7 @@ class ActionRunner:
     with exception.annotate(f"Running block {block_index}: {block.label}"):
       for action_index, action in enumerate(block, start=1):
         self._info_stack = (f"block_{block_index}", f"action_{action_index}")
+        self._failure_screenshot_annotations = []
         action.run_with(run, self)
 
   def wait(self, run: Run, action: i_action.WaitAction) -> None:
@@ -171,10 +181,21 @@ class ActionRunner:
       self, run: Run, action: i_action.InjectNewDocumentScriptAction) -> None:
     raise ActionNotImplementedError(self, action)
 
-  def screenshot_impl(self, run: Run, suffix: str) -> None:
-    del run, suffix
+  def screenshot_impl(
+      self,
+      run: Run,
+      suffix: str,
+      annotations: Optional[Sequence[ScreenshotAnnotation]] = None) -> None:
+    del run, suffix, annotations
     raise NotImplementedError("screenshot_impl not implemented")
 
+  def add_failure_screenshot_annotation(
+      self, annotation: ScreenshotAnnotation) -> None:
+    self._failure_screenshot_annotations.append(annotation)
+
+  def failure_screenshot(self, run: Run, suffix: str) -> None:
+    self.screenshot_impl(run, suffix, self._failure_screenshot_annotations)
+
   def screenshot(self, run: Run, action: i_action.ScreenshotAction) -> None:
     del action
     with run.actions("Screenshot", measure=False):
@@ -195,7 +216,7 @@ class ActionRunner:
       run.runner.wait(duration)
 
   def run_page_multiple_tabs(self, run: Run, tabs: TabController,
-                             pages: Iterable[Page]):
+                             pages: Iterable[Page]) -> None:
     # TODO: refactor possible logics to TabController.
     browser = run.browser
     for _ in tabs:
@@ -214,14 +235,14 @@ class ActionRunner:
         raise
 
   def run_combined_page(self, run: Run, page: CombinedPage,
-                        multiple_tabs: bool):
+                        multiple_tabs: bool) -> None:
     if multiple_tabs:
       self.run_page_multiple_tabs(run, page.tabs, page.pages)
     else:
       for sub_page in page.pages:
         sub_page.run_with(run, self, False)
 
-  def run_interactive_page_once(self, run: Run, page: InteractivePage):
+  def run_interactive_page_once(self, run: Run, page: InteractivePage) -> None:
     try:
       self.run_blocks(run, page, page.blocks)
       self._maybe_navigate_to_about_blank(run, page)
@@ -230,13 +251,14 @@ class ActionRunner:
       raise
 
   def run_interactive_page(self, run: Run, page: InteractivePage,
-                           multiple_tabs: bool):
+                           multiple_tabs: bool) -> None:
     if multiple_tabs:
       self.run_page_multiple_tabs(run, page.tabs, [page])
     else:
       self.run_interactive_page_once(run, page)
 
-  def run_setup(self, run: Run, page: InteractivePage, setup: ActionBlock):
+  def run_setup(self, run: Run, page: InteractivePage,
+                setup: ActionBlock) -> None:
     try:
       with exception.annotate("setup"):
         setup.run_with(self, run, page)
@@ -244,13 +266,21 @@ class ActionRunner:
       page.create_failure_artifacts(run, "setup-failure")
       raise
 
-  def run_login(self, run: Run, page: InteractivePage, login: ActionBlock):
+  def run_login(self, run: Run, page: InteractivePage,
+                login: ActionBlock) -> None:
     try:
       with exception.annotate("login"):
-        login.run_with(self, run, page)
+        with run.browser.network.traffic_shaper.pause():
+          login.run_with(self, run, page)
     except Exception:
       page.create_failure_artifacts(run, "login-failure")
       raise
 
   def switch_tab(self, run: Run, action: i_action.SwitchTabAction):
     raise ActionNotImplementedError(self, action)
+
+  def close_tab(self, run: Run, action: i_action.CloseTabAction):
+    raise ActionNotImplementedError(self, action)
+
+  def wait_for_download(self, run: Run, action: i_action.WaitForDownloadAction):
+    raise ActionNotImplementedError(self, action)
diff --git a/crossbench/action_runner/bond_base.py b/crossbench/action_runner/bond_base.py
new file mode 100644
index 00000000..e906f1e9
--- /dev/null
+++ b/crossbench/action_runner/bond_base.py
@@ -0,0 +1,40 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.action import all as i_action
+  from crossbench.action_runner.action.bond import BondAction
+  from crossbench.runner.run import Run
+
+
+class BondActionNotImplementedError(NotImplementedError):
+
+  def __init__(self,
+               runner: BondActionRunner,
+               action: BondAction,
+               msg_context: str = "") -> None:
+    self.runner = runner
+    self.action = action
+
+    if msg_context:
+      msg_context = ". Context: " + msg_context
+
+    message = (f"{str(action.TYPE).capitalize()}-action "
+               f"not implemented in {type(runner).__name__}{msg_context}")
+    super().__init__(message)
+
+
+class BondActionRunner:
+
+  def meet_create(self, run: Run, action: i_action.MeetCreateAction):
+    del run
+    raise BondActionNotImplementedError(self, action)
+
+  def meet_script(self, run: Run, action: i_action.MeetScriptAction):
+    del run
+    raise BondActionNotImplementedError(self, action)
diff --git a/crossbench/action_runner/chromeos_input_action_runner.py b/crossbench/action_runner/chromeos_input_action_runner.py
index f445a619..5d3c90ad 100644
--- a/crossbench/action_runner/chromeos_input_action_runner.py
+++ b/crossbench/action_runner/chromeos_input_action_runner.py
@@ -4,18 +4,21 @@
 
 from __future__ import annotations
 
+import atexit
 import dataclasses
 import datetime as dt
 import shlex
 import subprocess
-from typing import TYPE_CHECKING
+from typing import TYPE_CHECKING, Self
 
 import crossbench.path as pth
 from crossbench.action_runner.action import all as i_action
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
 from crossbench.action_runner.display_rectangle import DisplayRectangle
 from crossbench.action_runner.element_not_found_error import \
     ElementNotFoundError
+from crossbench.action_runner.screenshot_annotation import (
+    ScreenshotPointAnnotation, ScreenshotRectAnnotation)
 from crossbench.benchmarks.loading.point import Point
 from crossbench.parse import NumberParser
 
@@ -30,12 +33,12 @@ SCRIPTS_DIR = pth.LocalPath(__file__).parent / "chromeos_scripts"
 
 class ChromeOSViewportInfo:
 
-  def __init__(self, device_pixel_ratio, window_outer_width, window_inner_width,
-               window_inner_height, screen_width, screen_height,
-               screen_avail_width, screen_avail_height, window_offset_x,
-               window_offset_y,
+  def __init__(self, device_pixel_ratio: float, window_outer_width: int,
+               window_inner_width: int, window_inner_height: int,
+               screen_width: int, screen_height: int, screen_avail_width: int,
+               screen_avail_height: int, window_offset_x: int,
+               window_offset_y: int,
                element_rect: Optional[DisplayRectangle]) -> None:
-
     # The actual screen width and height in pixels.
     # Corrects for any zoom/scaling factors.
     # 80 is a common factor of most display pixel widths, so use it as a common
@@ -76,7 +79,7 @@ class ChromeOSViewportInfo:
     self._browser_viewable = DisplayRectangle(
         Point(window_offset_x, window_offset_y), visible_width, visible_height)
 
-    self._element_rect: Optional[DisplayRectangle] = None
+    self._element_rect: DisplayRectangle | None = None
     if element_rect:
       self._element_rect = self._dom_rect_to_native_rect(element_rect)
 
@@ -122,14 +125,14 @@ class TouchDevice:
   y_max: int
 
   @classmethod
-  def parse_str(cls: Type[TouchDevice], config: str) -> TouchDevice:
+  def parse_str(cls, config: str) -> Self:
     # The first line of output is always 'Performing autotest_lib import'
     # Followed by the output we care about.
     touch_device_values = config.splitlines()[1].split(" ")
 
-    return TouchDevice(touch_device_values[0],
-                       NumberParser.positive_zero_int(touch_device_values[1]),
-                       NumberParser.positive_zero_int(touch_device_values[2]))
+    return cls(touch_device_values[0],
+               NumberParser.positive_zero_int(touch_device_values[1]),
+               NumberParser.positive_zero_int(touch_device_values[2]))
 
   def __str__(self) -> str:
     return f"{self.device_path} {self.x_max} {self.y_max}"
@@ -148,7 +151,7 @@ class ChromeOSTouchEvent:
   # The start position in terms of the device's screen resolution
   start_position: Point
   # The end position in terms of the device's screen resolution
-  end_position: Optional[Point] = None
+  end_position: Point | None = None
 
   duration: dt.timedelta = dt.timedelta()
 
@@ -216,8 +219,8 @@ E: <time> 0000 0000 0
     increment_distance_y = (end_position.y -
                             start_position.y) / num_position_updates
 
-    current_position_x = start_position.x
-    current_position_y = start_position.y
+    current_position_x: float = start_position.x
+    current_position_y: float = start_position.y
 
     for _ in range(num_position_updates):
       current_event_time_seconds += 1.0 / self._TOUCH_UPDATE_HERTZ
@@ -254,15 +257,22 @@ E: <time> 0000 0000 0
         "<y>", str(round(position.y))).replace("<time>", f"{time:.6f}")
 
 
-class ChromeOSInputActionRunner(BasicActionRunner):
+class ChromeOSInputActionRunner(DefaultActionRunner):
 
-  def __init__(self):
+  def __init__(self) -> None:
     super().__init__()
-    self._touch_device: Optional[TouchDevice] = None
-    self._remote_tmp_file = ""
+    self._touch_device: TouchDevice | None = None
+    self._mouse_process: subprocess.Popen | None = None
+
+    atexit.register(self._kill_mouse_process)
+
+  def _kill_mouse_process(self) -> None:
+    if self._mouse_process:
+      self._mouse_process.kill()
+      self._mouse_process.wait()
 
   def click_touch(self, run: Run, action: i_action.ClickAction) -> None:
-    if self._touch_device is None:
+    if not self._touch_device:
       self._touch_device = self._setup_touch_device(run)
 
     with run.actions("ClickAction", measure=False) as actions:
@@ -281,27 +291,48 @@ class ChromeOSInputActionRunner(BasicActionRunner):
               end_position=None,
               duration=action.duration))
 
+      if action.verify:
+        self.wait_for_element_impl(
+            actions,
+            selector=action.verify,
+            timeout=action.timeout,
+            check_element_rect=True)
+
   def click_mouse(self, run: Run, action: i_action.ClickAction) -> None:
     with run.actions("ClickAction", measure=False) as actions:
 
       click_location, viewport = self._get_click_location(actions, action)
 
+      if not self._mouse_process:
+        self._mouse_process = self._setup_mouse_process(
+            run, viewport.native_screen.width, viewport.native_screen.height)
+
       if not click_location:
         return
 
-      browser_platform = run.browser_platform
-      self._remote_tmp_file = browser_platform.mktemp()
-      script = (SCRIPTS_DIR / "mouse.py").read_text()
-      browser_platform.set_file_contents(self._remote_tmp_file, script)
+      click_string: str = (f"{action.duration.total_seconds()}\n"
+                           f"{click_location.x}\n"
+                           f"{click_location.y}\n")
+
+      assert self._mouse_process.stdin
+      self._mouse_process.stdin.write(click_string.encode("utf-8"))
+      self._mouse_process.stdin.flush()
+
+      assert self._mouse_process.stdout
+      output = int(self._mouse_process.stdout.readline())
 
-      run.browser_platform.sh("python3", self._remote_tmp_file,
-                              str(viewport.native_screen.width),
-                              str(viewport.native_screen.height),
-                              str(action.duration.total_seconds()),
-                              str(click_location.x), str(click_location.y))
+      if output != 0:
+        raise RuntimeError(f"Failed to perform click: {output}")
+
+      if action.verify:
+        self.wait_for_element_impl(
+            actions,
+            selector=action.verify,
+            timeout=action.timeout,
+            check_element_rect=True)
 
   def scroll_touch(self, run: Run, action: i_action.ScrollAction) -> None:
-    if self._touch_device is None:
+    if not self._touch_device:
       self._touch_device = self._setup_touch_device(run)
 
     with run.actions("ScrollAction", measure=False) as actions:
@@ -321,7 +352,8 @@ class ChromeOSInputActionRunner(BasicActionRunner):
           return
         scroll_area = viewport_info.element_rect
 
-      max_swipe_distance = scroll_area.bottom - scroll_area.top
+      (scrollable_top, scrollable_bottom,
+       max_swipe_distance) = scroll_area.get_scrollable_area()
 
       remaining_distance = abs(total_scroll_distance)
 
@@ -337,13 +369,13 @@ class ChromeOSInputActionRunner(BasicActionRunner):
         if total_scroll_distance > 0:
           # If scrolling down, the swipe should start at the bottom and end
           # above.
-          y_start = scroll_area.bottom
-          y_end = scroll_area.bottom - current_distance
+          y_start: int = scrollable_bottom
+          y_end: int = round(scrollable_bottom - current_distance)
 
         else:
           # If scrolling up, the swipe should start at the top and end below.
-          y_start = scroll_area.top
-          y_end = scroll_area.top + current_distance
+          y_start = scrollable_top
+          y_end = round(scrollable_top + current_distance)
 
         self._execute_touch_playback(
             run,
@@ -359,45 +391,67 @@ class ChromeOSInputActionRunner(BasicActionRunner):
   def text_input_keyboard(self, run: Run,
                           action: i_action.TextInputAction) -> None:
     browser_platform = run.browser_platform
-    self._remote_tmp_file = browser_platform.mktemp()
-    script = (SCRIPTS_DIR / "text_input.py").read_text()
-    browser_platform.set_file_contents(self._remote_tmp_file, script)
 
-    try:
-      typing_process = browser_platform.popen(
-          "python3", self._remote_tmp_file, bufsize=0, stdin=subprocess.PIPE)
+    script = (SCRIPTS_DIR / "text_input.py").read_text()
 
-      self._rate_limit_keystrokes(
-          run, action, lambda run, actions, text: typing_process.stdin.write(
-              text.encode("utf-8")))
-    finally:
-      typing_process.stdin.close()
-      typing_process.wait(timeout=action.timeout.total_seconds())
+    with browser_platform.NamedTemporaryFile() as script_file:
+      browser_platform.set_file_contents(script_file, script)
+      typing_process: subprocess.Popen | None = None
+      try:
+        typing_process = browser_platform.popen(
+            "python3", script_file, bufsize=0, stdin=subprocess.PIPE)
+        typing_stdin = typing_process.stdin
+        assert typing_stdin, "Got no stdin"
+
+        self._rate_limit_keystrokes(
+            run, action,
+            lambda run, actions, text: typing_stdin.write(text.encode("utf-8")))
+      finally:
+        if typing_stdin:
+          typing_stdin.close()
+        if typing_process:
+          typing_process.wait(timeout=action.timeout.total_seconds())
 
   def _get_click_location(
       self, actions: Actions, action: i_action.ClickAction
   ) -> Tuple[Optional[Point], ChromeOSViewportInfo]:
-    viewport_info: ChromeOSViewportInfo = self._get_viewport_info(
-        actions, action.selector, action.scroll_into_view)
-
-    if action.selector:
+    if selector_config := action.position.selector:
+      if selector_config.wait:
+        self.wait_for_element_impl(
+            actions,
+            selector=selector_config.selector,
+            timeout=action.timeout,
+            scroll_into_view=selector_config.scroll_into_view,
+            check_element_rect=True,
+            required=selector_config.required)
+
+      viewport_info = self._get_viewport_info(actions, selector_config.selector,
+                                              selector_config.scroll_into_view)
       element_rect = viewport_info.element_rect
       if not element_rect:
-        if action.required:
-          raise ElementNotFoundError(action.selector)
+        if selector_config.required:
+          raise ElementNotFoundError(selector_config.selector)
         return (None, viewport_info)
-      click_location: Point = element_rect.middle
-    else:
-      click_location = action.coordinates
-
-    assert click_location, "Invalid click location click action."
-
-    return (click_location, viewport_info)
-
-  def _get_viewport_info(self,
-                         actions: Actions,
-                         selector: Optional[str],
-                         scroll_into_view=False) -> ChromeOSViewportInfo:
+      self.add_failure_screenshot_annotation(
+          ScreenshotRectAnnotation(
+              label=selector_config.selector, rect=element_rect))
+      click_location = element_rect.middle
+      self.add_failure_screenshot_annotation(
+          ScreenshotPointAnnotation(label="click", point=click_location))
+      return (click_location, viewport_info)
+    if coordinates_config := action.position.coordinates:
+      viewport_info = self._get_viewport_info(actions, None, False)
+      click_location = coordinates_config.point()
+      self.add_failure_screenshot_annotation(
+          ScreenshotPointAnnotation(label="click", point=click_location))
+      return (click_location, viewport_info)
+    raise RuntimeError("Missing coordinates")
+
+  def _get_viewport_info(
+      self,
+      actions: Actions,
+      selector: Optional[str],
+      scroll_into_view: bool = False) -> ChromeOSViewportInfo:
 
     script = ""
     if selector:
@@ -410,7 +464,7 @@ class ChromeOSInputActionRunner(BasicActionRunner):
      element_left, element_top, element_width, element_height) = actions.js(
          script, arguments=[selector, scroll_into_view])
 
-    element_rect: Optional[DisplayRectangle] = None
+    element_rect: DisplayRectangle | None = None
 
     if found_element:
       element_rect = DisplayRectangle(
@@ -440,12 +494,36 @@ class ChromeOSInputActionRunner(BasicActionRunner):
           "Failed to query touchscreen information from device.") from e
 
   def _setup_touch_device(self, run: Run) -> TouchDevice:
-    self._remote_tmp_file = run.browser_platform.mktemp()
-
     touch_device_output = self._query_touch_device(run)
-
     return TouchDevice.parse_str(touch_device_output)
 
+  def _setup_mouse_process(self, run: Run, screen_width: int,
+                           screen_height: int) -> subprocess.Popen:
+    browser_platform = run.browser_platform
+    script = (SCRIPTS_DIR / "mouse.py").read_text()
+
+    with browser_platform.NamedTemporaryFile() as script_file:
+      browser_platform.set_file_contents(script_file, script)
+
+      mouse_process = browser_platform.popen(
+          "python3",
+          script_file,
+          str(screen_width),
+          str(screen_height),
+          stdin=subprocess.PIPE,
+          stdout=subprocess.PIPE)
+
+      if mouse_process.poll() is not None:
+        raise RuntimeError("Failed to start ChromeOS mouse process.")
+
+      assert mouse_process.stdout
+      output = int(mouse_process.stdout.readline())
+
+      if output != 0:
+        raise RuntimeError(f"Failed to start mouse process: {output}")
+
+      return mouse_process
+
   def _execute_touch_playback(self, run: Run,
                               touch_event: ChromeOSTouchEvent) -> None:
     # Ideally the touch event data could just be sent to |input| of evemu-play,
@@ -457,15 +535,17 @@ class ChromeOSInputActionRunner(BasicActionRunner):
 
     # Because of this weird behavior, create a temp file on the device first
     # that contains the touch events.
+    assert self._touch_device, "Missing touch_device"
 
     touch_event_cmds = str(touch_event)
 
-    run.browser_platform.set_file_contents(self._remote_tmp_file,
-                                           touch_event_cmds)
+    browser_platform = run.browser_platform
 
-    # Then run evemu-play with the input redirected from the temp file.
-    run.browser_platform.sh(
-        f"evemu-play --insert-slot0 "
-        f"{shlex.quote(self._touch_device.device_path)} < "
-        f"{self._remote_tmp_file}",
-        shell=True)
+    with browser_platform.NamedTemporaryFile() as playback_file:
+      browser_platform.set_file_contents(playback_file, touch_event_cmds)
+      # Then run evemu-play with the input redirected from the temp file.
+      run.browser_platform.sh(
+          f"evemu-play --insert-slot0 "
+          f"{shlex.quote(self._touch_device.device_path)} < "
+          f"{playback_file}",
+          shell=True)
diff --git a/crossbench/action_runner/chromeos_scripts/mouse.py b/crossbench/action_runner/chromeos_scripts/mouse.py
index 78b7fb90..f98ce250 100644
--- a/crossbench/action_runner/chromeos_scripts/mouse.py
+++ b/crossbench/action_runner/chromeos_scripts/mouse.py
@@ -13,9 +13,6 @@ import uinput
 
 screen_width = int(sys.argv[1])
 screen_height = int(sys.argv[2])
-click_duration = float(sys.argv[3])
-x = int(sys.argv[4])
-y = int(sys.argv[5])
 
 events = (
     uinput.ABS_X + (0, screen_width, 0, 0),
@@ -27,11 +24,22 @@ events = (
 with uinput.Device(events) as device:
   # The system needs a bit of time before it can start processing events from
   # the newly registered device.
-  time.sleep(0.1)
+  time.sleep(0.2)
 
-  device.emit(uinput.ABS_X, x, syn=False)
-  device.emit(uinput.ABS_Y, y)
+  sys.stdout.write("0\n")
+  sys.stdout.flush()
 
-  device.emit(uinput.BTN_LEFT, 1)
-  time.sleep(click_duration)
-  device.emit(uinput.BTN_LEFT, 0)
+  while True:
+    duration = float(sys.stdin.readline())
+    x = int(sys.stdin.readline())
+    y = int(sys.stdin.readline())
+
+    device.emit(uinput.ABS_X, x, syn=False)
+    device.emit(uinput.ABS_Y, y)
+
+    device.emit(uinput.BTN_LEFT, 1)
+    time.sleep(duration)
+    device.emit(uinput.BTN_LEFT, 0)
+
+    sys.stdout.write("0\n")
+    sys.stdout.flush()
diff --git a/crossbench/action_runner/config.py b/crossbench/action_runner/config.py
index fc69e9ba..956ea9be 100644
--- a/crossbench/action_runner/config.py
+++ b/crossbench/action_runner/config.py
@@ -10,9 +10,9 @@ from typing import Any
 from crossbench.action_runner.android_input_action_runner import \
     AndroidInputActionRunner
 from crossbench.action_runner.base import ActionRunner
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
 from crossbench.action_runner.chromeos_input_action_runner import \
     ChromeOSInputActionRunner
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
 
 
 # TODO: migrate to full config.ConfigObject
@@ -23,7 +23,7 @@ class ActionRunnerConfig:
     if isinstance(value, ActionRunner):
       return value
     if value == "basic":
-      return BasicActionRunner()
+      return DefaultActionRunner()
     if value == "android":
       return AndroidInputActionRunner()
     if value == "chromeos":
diff --git a/crossbench/action_runner/basic_action_runner.py b/crossbench/action_runner/default_action_runner.py
similarity index 59%
rename from crossbench/action_runner/basic_action_runner.py
rename to crossbench/action_runner/default_action_runner.py
index 225a3535..3cfb4951 100644
--- a/crossbench/action_runner/basic_action_runner.py
+++ b/crossbench/action_runner/default_action_runner.py
@@ -7,48 +7,70 @@ from __future__ import annotations
 import datetime as dt
 import logging
 import time
-from typing import TYPE_CHECKING, Callable, Tuple
+from typing import TYPE_CHECKING, Any, Callable, Optional, Sequence, Tuple
+
+from typing_extensions import override
 
 from crossbench.action_runner.action import all as i_action
 from crossbench.action_runner.action.enums import ReadyState
 from crossbench.action_runner.base import (ActionRunner,
                                            InputSourceNotImplementedError)
+from crossbench.action_runner.default_bond_action_runner import \
+    DefaultBondActionRunner
 from crossbench.action_runner.element_not_found_error import \
     ElementNotFoundError
+from crossbench.action_runner.screenshot_annotation import ScreenshotAnnotation
+from crossbench.probes.downloads import DownloadsProbe, DownloadsProbeContext
 from crossbench.probes.dump_html import DumpHtmlProbe, DumpHtmlProbeContext
-from crossbench.probes.screenshot import ScreenshotProbe, ScreenshotProbeContext
+from crossbench.probes.screenshot import (ScreenshotProbe,
+                                          ScreenshotProbeContext)
 
 if TYPE_CHECKING:
+  from crossbench.action_runner.bond_base import BondActionRunner
   from crossbench.runner.actions import Actions
   from crossbench.runner.run import Run
 
 
-class BasicActionRunner(ActionRunner):
+class DefaultActionRunner(ActionRunner):
   XPATH_SELECT_ELEMENT = """
-      let element = document.evaluate(arguments[0], document).iterateNext();
+      let elements = [];
+      let xpathResult = document.evaluate(arguments[0], document);
+      let currentElement = xpathResult.iterateNext();
+      let element = currentElement;
+      while (currentElement) {
+        elements.push(currentElement);
+        currentElement = xpathResult.iterateNext();
+      }
   """
 
   CSS_SELECT_ELEMENT = """
-      let element = document.querySelector(arguments[0]);
+      let elements = document.querySelectorAll(arguments[0]);
+      let element = elements[0];
   """
 
   CHECK_ELEMENT_EXISTS = """
-      if (!element) return false;
+      if (!element) return 0;
   """
 
   ELEMENT_SCROLL_INTO_VIEW = """
       element.scrollIntoView();
   """
 
+  CHECK_ELEMENT_RECT = """
+      const rect = element.getBoundingClientRect();
+      if (rect.width === 0 || rect.height === 0) return 0;
+  """
+
   ELEMENT_CLICK = """
       element.click();
   """
 
   RETURN_SUCCESS = """
-      return true;
+      return elements.length;
   """
 
   SELECT_WINDOW = """
+      let elements = [window];
       let element = window;
   """
 
@@ -57,16 +79,19 @@ class BasicActionRunner(ActionRunner):
   """
 
   GET_CURRENT_SCROLL_POSITION = """
-      if (!element) return [false, 0];
-      return [true, element[arguments[1]]];
+      if (!element) return [0, 0];
+      return [elements.length, element[arguments[1]]];
   """
 
+  _bond: DefaultBondActionRunner | None = None
+
   def get_selector_script(self,
                           selector: str,
-                          check_element_exists=False,
-                          scroll_into_view=False,
-                          click=False,
-                          return_on_success=False) -> Tuple[str, str]:
+                          check_element_exists: bool = False,
+                          scroll_into_view: bool = False,
+                          check_element_rect: bool = False,
+                          click: bool = False,
+                          return_on_success: bool = False) -> Tuple[str, str]:
     # TODO: support more selector types
 
     script: str = ""
@@ -84,6 +109,9 @@ class BasicActionRunner(ActionRunner):
     if scroll_into_view:
       script += self.ELEMENT_SCROLL_INTO_VIEW
 
+    if check_element_rect:
+      script += self.CHECK_ELEMENT_RECT
+
     if click:
       script += self.ELEMENT_CLICK
 
@@ -92,6 +120,13 @@ class BasicActionRunner(ActionRunner):
 
     return selector, script
 
+  @property
+  @override
+  def bond(self) -> BondActionRunner:
+    if not self._bond:
+      self._bond = DefaultBondActionRunner(self)
+    return self._bond
+
   def _wait_for_ready_state(self, actions: Actions, ready_state: ReadyState,
                             timeout: dt.timedelta) -> None:
     # Make sure we also finish if readyState jumps directly
@@ -102,6 +137,13 @@ class BasicActionRunner(ActionRunner):
           return state === '{ready_state}' || state === "complete";
         """, 0.2, timeout.total_seconds())
 
+  @override
+  def teardown(self, run: Run) -> None:
+    del run
+    if self._bond:
+      self._bond.teardown()
+
+  @override
   def get(self, run: Run, action: i_action.GetAction) -> None:
     # TODO: potentially refactor the timing and logging out to the base class.
     start_time = time.time()
@@ -122,26 +164,39 @@ class BasicActionRunner(ActionRunner):
         logging.info("%s took longer (%s) than expected action duration (%s).",
                      action, run_duration, action.duration)
 
+  @override
   def click_js(self, run: Run, action: i_action.ClickAction) -> None:
 
     if action.duration > dt.timedelta():
       raise InputSourceNotImplementedError(self, action, action.input_source,
                                            "Non-zero duration not implemented")
-    selector = action.selector
-    if not selector:
+    selector_config = action.position.selector
+    if not selector_config:
       raise RuntimeError("Missing selector")
 
     selector, script = self.get_selector_script(
-        selector,
+        selector_config.selector,
         check_element_exists=True,
-        scroll_into_view=action.scroll_into_view,
+        scroll_into_view=selector_config.scroll_into_view,
         click=True,
         return_on_success=True)
 
     with run.actions("ClickAction", measure=False) as actions:
-      if not actions.js(script, arguments=[selector]) and action.required:
+      if selector_config.wait:
+        self.wait_for_element_impl(
+            actions,
+            selector=selector_config.selector,
+            timeout=action.timeout,
+            required=selector_config.required)
+      if not actions.js(
+          script, arguments=[selector]) and selector_config.required:
         raise ElementNotFoundError(selector)
 
+      if action.verify:
+        self.wait_for_element_impl(
+            actions, selector=action.verify, timeout=action.timeout)
+
+  @override
   def scroll_js(self, run: Run, action: i_action.ScrollAction) -> None:
     with run.actions("ScrollAction", measure=False) as actions:
       selector = ""
@@ -181,28 +236,82 @@ class BasicActionRunner(ActionRunner):
       scroll_y = initial_scroll_y + distance
       actions.js(do_scroll_script, arguments=[selector, scroll_y])
 
+  def wait_for_element_impl(self,
+                            actions: Actions,
+                            selector: str,
+                            timeout: dt.timedelta,
+                            expected_count: int = 1,
+                            or_more: bool = False,
+                            scroll_into_view: bool = False,
+                            check_element_rect: bool = False,
+                            required: bool = True) -> None:
+    selector, selector_script = self.get_selector_script(
+        selector=selector,
+        check_element_exists=True,
+        scroll_into_view=scroll_into_view,
+        check_element_rect=check_element_rect,
+        return_on_success=True)
+    # TODO: if check_element_rect, we should wait for the position to be the
+    # same
+
+    def _exact_match(js_result: int) -> bool:
+      return js_result == expected_count
+
+    def _or_more_match(js_result: int) -> bool:
+      return js_result >= expected_count
+
+    success_condition = _exact_match
+
+    if or_more:
+      success_condition = _or_more_match
+
+    try:
+      actions.wait_js_condition(
+          selector_script,
+          min_wait=0.2,
+          timeout=timeout,
+          arguments=(selector,),
+          success_condition=success_condition)
+    except TimeoutError as e:
+      if required:
+        raise
+      logging.debug("Element %s not found: %s", selector, e)
+
+  @override
   def wait_for_element(self, run: Run,
                        action: i_action.WaitForElementAction) -> None:
     with run.actions("WaitForElementAction", measure=False) as actions:
-      actions.wait_js_condition(
-          f"return !!document.querySelector({repr(action.selector)})", 0.2,
-          action.timeout)
-
+      self.wait_for_element_impl(
+          actions=actions,
+          selector=action.selector,
+          expected_count=action.expected_count,
+          or_more=action.or_more,
+          timeout=action.timeout)
+
+  @override
   def wait_for_ready_state(self, run: Run,
                            action: i_action.WaitForReadyStateAction) -> None:
     with run.actions(
         f"Wait for ready state {action.ready_state}", measure=False) as actions:
       self._wait_for_ready_state(actions, action.ready_state, action.timeout)
 
+  @override
   def inject_new_document_script(
       self, run: Run, action: i_action.InjectNewDocumentScriptAction) -> None:
     run.browser.run_script_on_new_document(action.script)
 
+  @override
   def switch_tab(self, run: Run, action: i_action.SwitchTabAction) -> None:
     with run.actions("SwitchTabAction", measure=False):
       run.browser.switch_tab(action.title, action.url, action.tab_index,
                              action.timeout)
 
+  @override
+  def close_tab(self, run: Run, action: i_action.CloseTabAction) -> None:
+    with run.actions("CloseTabAction", measure=False):
+      run.browser.close_tab(action.title, action.url, action.tab_index,
+                            action.timeout)
+
   def _get_scroll_field(self, has_selector: bool) -> str:
     if has_selector:
       return "scrollTop"
@@ -210,11 +319,9 @@ class BasicActionRunner(ActionRunner):
 
   def _rate_limit_keystrokes(
       self, run: Run, action: i_action.TextInputAction,
-      do_type_function: Callable[[Run, Actions, str], None]) -> None:
+      do_type_function: Callable[[Run, Actions, str], Any]) -> None:
     character_delay_s = (action.duration / len(action.text)).total_seconds()
-
     start_time = time.time()
-
     action_expected_end_time = start_time + action.duration.total_seconds()
 
     with run.actions("TextInput", measure=False) as actions:
@@ -246,15 +353,21 @@ class BasicActionRunner(ActionRunner):
             "text_input action is behind schedule! Consider extending this "
             "action's duration otherwise the action may timeout.")
 
-  def screenshot_impl(self, run: Run, suffix: str) -> None:
+  @override
+  def screenshot_impl(
+      self,
+      run: Run,
+      suffix: str,
+      annotations: Optional[Sequence[ScreenshotAnnotation]] = None) -> None:
     ctx = run.find_probe_context(ScreenshotProbe)
     if not ctx:
       logging.warning("No screenshot probe for screenshot on %s",
                       repr(self.info_stack))
       return
     assert isinstance(ctx, ScreenshotProbeContext)
-    ctx.screenshot("_".join(self.info_stack) + f"_{suffix}")
+    ctx.screenshot("_".join(self.info_stack) + f"_{suffix}", annotations)
 
+  @override
   def dump_html_impl(self, run: Run, suffix: str) -> None:
     ctx = run.find_probe_context(DumpHtmlProbe)
     if not ctx:
@@ -263,3 +376,17 @@ class BasicActionRunner(ActionRunner):
       return
     assert isinstance(ctx, DumpHtmlProbeContext)
     ctx.dump_html("_".join(self.info_stack) + f"_{suffix}")
+
+  def wait_for_download(self, run: Run,
+                        action: i_action.WaitForDownloadAction) -> None:
+    with run.actions("WaitForDownload", measure=False):
+      ctx = run.find_probe_context(DownloadsProbe)
+      if not ctx:
+        raise RuntimeError("No downloads probe for wait_for_download on "
+                           f"{repr(self.info_stack)}")
+      assert isinstance(ctx, DownloadsProbeContext)
+
+      wait_range = run.wait_range(min_wait=0.2, timeout=action.timeout, delay=0)
+      for _ in wait_range.wait_with_backoff():
+        if ctx.download_complete(action.pattern):
+          return
diff --git a/crossbench/action_runner/default_bond_action_runner.py b/crossbench/action_runner/default_bond_action_runner.py
new file mode 100644
index 00000000..a797519b
--- /dev/null
+++ b/crossbench/action_runner/default_bond_action_runner.py
@@ -0,0 +1,64 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from typing_extensions import override
+
+from crossbench.action_runner.action.enums import ReadyState
+from crossbench.action_runner.action.get import GetAction
+from crossbench.action_runner.bond_base import BondActionRunner
+from crossbench.bond.bond import BondClient
+from crossbench.parse import ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.action_runner.action import all as i_action
+  from crossbench.action_runner.base import ActionRunner
+  from crossbench.browsers.browser import Browser
+  from crossbench.runner.run import Run
+
+
+class DefaultBondActionRunner(BondActionRunner):
+
+  def __init__(self, action_runner: ActionRunner) -> None:
+    self._action_runner: ActionRunner = action_runner
+    self._bond_client: BondClient | None = None
+
+  def bond_client(self, run: Run) -> BondClient:
+    if not self._bond_client:
+      secret = run.secrets.bond
+      if not secret:
+        raise RuntimeError("No bond service account secret provided")
+      self._bond_client = BondClient(secret)
+    return self._bond_client
+
+  def teardown(self) -> None:
+    if self._bond_client:
+      self._bond_client.teardown()
+      self._bond_client = None
+
+  def get_current_conference_code(self, browser: Browser) -> str:
+    url = ObjectParser.url(browser.current_url)
+    if url.hostname != "meet.google.com":
+      raise RuntimeError(f"Unsupported URL for Bond action: {url.geturl()}")
+    # Conference code is url path without leading '/'
+    return url.path[1:]
+
+  @override
+  def meet_create(self, run: Run, action: i_action.MeetCreateAction) -> None:
+    bond_client = self.bond_client(run)
+    conference_code = bond_client.create_meeting()
+    if action.bots:
+      bond_client.add_bots(conference_code, action.bots)
+    url = f"https://meet.google.com/{conference_code}"
+    self._action_runner.get(
+        run,
+        GetAction(url, ready_state=ReadyState.COMPLETE, target=action.target))
+
+  def meet_script(self, run: Run, action: i_action.MeetScriptAction) -> None:
+    conference_code = self.get_current_conference_code(run.browser)
+    bond_client = self.bond_client(run)
+    bond_client.run_script(conference_code, action.script)
diff --git a/crossbench/action_runner/display_rectangle.py b/crossbench/action_runner/display_rectangle.py
index 4518e8dd..0a65de6f 100644
--- a/crossbench/action_runner/display_rectangle.py
+++ b/crossbench/action_runner/display_rectangle.py
@@ -6,10 +6,12 @@ from __future__ import annotations
 
 import dataclasses
 
+from typing import Tuple
 from typing_extensions import Self
 
 from crossbench.benchmarks.loading.point import Point
 
+SCROLL_BOUNDS_OFFSET_FACTOR: float = 0.1
 
 @dataclasses.dataclass(frozen=False)
 # Represents a rectangular section of the device's display.
@@ -38,6 +40,38 @@ class DisplayRectangle:
         Point(self.origin.x + other.origin.x, self.origin.y + other.origin.y),
         self.width, self.height)
 
+  def get_scrollable_area(self) -> Tuple[int, int, int]:
+    scrollable_top = self.top
+    scrollable_bottom = self.bottom
+    max_swipe_distance = scrollable_bottom - scrollable_top
+
+    trim_amount = int(round(max_swipe_distance * SCROLL_BOUNDS_OFFSET_FACTOR))
+
+    scrollable_top += trim_amount
+    scrollable_bottom -= trim_amount
+
+    return (scrollable_top, scrollable_bottom,
+            scrollable_bottom - scrollable_top)
+
+  # Returns the sub-rectangle of |other| that exists within |self|.
+  # |other| must have the same reference origin as |self|.
+  def intersection(self, other: Self) -> DisplayRectangle:
+    assert other.left < self.right and other.top < self.bottom, (
+        "Rectangles do not intersect. Maybe you need to add 'scroll_into_view'."
+    )
+
+    width: int = other.width
+
+    if other.right > self.right:
+      width = self.right - other.left
+
+    height: int = other.height
+
+    if other.bottom > self.bottom:
+      height = self.bottom - other.top
+
+    return DisplayRectangle(other.origin, width, height)
+
   @property
   def left(self) -> int:
     return self.origin.x
diff --git a/crossbench/action_runner/screenshot_annotation.py b/crossbench/action_runner/screenshot_annotation.py
new file mode 100644
index 00000000..3c7c846b
--- /dev/null
+++ b/crossbench/action_runner/screenshot_annotation.py
@@ -0,0 +1,66 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import abc
+import dataclasses
+from typing import Sequence
+from xml.sax.saxutils import escape
+
+from typing_extensions import override
+
+from crossbench.action_runner.display_rectangle import DisplayRectangle
+from crossbench.benchmarks.loading.point import Point
+
+
+@dataclasses.dataclass(frozen=True)
+class ScreenshotAnnotation(abc.ABC):
+  label: str
+
+  @abc.abstractmethod
+  def svg_annotation(self) -> str:
+    pass
+
+
+def annotate_screenshot_svg(screen_width: int, screen_height: int,
+                            screenshot_file: str,
+                            annotations: Sequence[ScreenshotAnnotation]) -> str:
+  all_annotations = ''.join(
+      [annotation.svg_annotation() for annotation in annotations])
+  return (f'<svg version="1.1"'
+          f' width="{screen_width}" height="{screen_height}"'
+          ' xmlns="http://www.w3.org/2000/svg">'
+          f'<image href="{screenshot_file}"'
+          f' width="{screen_width}" height="{screen_height}" />'
+          f'{all_annotations}'
+          '</svg>')
+
+
+@dataclasses.dataclass(frozen=True)
+class ScreenshotRectAnnotation(ScreenshotAnnotation):
+  rect: DisplayRectangle
+
+  @override
+  def svg_annotation(self) -> str:
+    rect = self.rect
+    return (f'<rect x="{rect.left}" y="{rect.top}"'
+            f' width="{rect.width}" height="{rect.height}"'
+            ' fill="rgb(255 255 0 / 0.5)">'
+            f'<title>{escape(self.label)}</title>'
+            '</rect>')
+
+
+@dataclasses.dataclass(frozen=True)
+class ScreenshotPointAnnotation(ScreenshotAnnotation):
+  point: Point
+
+  @override
+  def svg_annotation(self) -> str:
+    x = self.point.x
+    y = self.point.y
+    return (f'<g><title>{escape(self.label)}</title>'
+            f'<polygon points="{x},{y} {x-48},{y-24} {x-24},{y-48}"'
+            ' fill="rgb(0 0 255 / 0.33)" />'
+            f'<rect x="{x-0.5}" y="{y-0.5}"'
+            ' width="1" height="1" fill="rgb(0 0 255)" />'
+            '</g>')
diff --git a/crossbench/benchmarks/all.py b/crossbench/benchmarks/all.py
index 01d14cf3..be7c026d 100644
--- a/crossbench/benchmarks/all.py
+++ b/crossbench/benchmarks/all.py
@@ -8,16 +8,22 @@ from __future__ import annotations
 from crossbench.benchmarks.jetstream import (JetStream20Benchmark,
                                              JetStream21Benchmark,
                                              JetStream22Benchmark,
-                                             JetStream30Benchmark)
-from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+                                             JetStreamMainBenchmark)
+from crossbench.benchmarks.loading.loading_benchmark import LoadingBenchmark
 from crossbench.benchmarks.loading.loadline_presets import (
-    LoadLinePhoneBenchmark, LoadLineTabletBenchmark)
+    LoadLinePhoneBenchmark,
+    LoadLinePhoneDebugBenchmark,
+    LoadLinePhoneFastBenchmark,
+    LoadLineTabletBenchmark,
+    LoadLineTabletDebugBenchmark,
+    LoadLineTabletFastBenchmark)
 from crossbench.benchmarks.manual import ManualBenchmark
 from crossbench.benchmarks.memory.memory_benchmark import MemoryBenchmark
-from crossbench.benchmarks.motionmark import (MotionMark10Benchmark,
-                                              MotionMark11Benchmark,
-                                              MotionMark12Benchmark,
-                                              MotionMark13Benchmark)
+from crossbench.benchmarks.motionmark import (
+    MotionMark10Benchmark, MotionMark11Benchmark, MotionMark12Benchmark,
+    MotionMark13Benchmark, MotionMark131Benchmark, MotionMarkMainBenchmark)
 from crossbench.benchmarks.speedometer import (Speedometer20Benchmark,
                                                Speedometer21Benchmark,
-                                               Speedometer30Benchmark)
+                                               Speedometer30Benchmark,
+                                               Speedometer31Benchmark,
+                                               SpeedometerMainBenchmark)
diff --git a/crossbench/benchmarks/base.py b/crossbench/benchmarks/base.py
index ad753ae6..24908e6c 100644
--- a/crossbench/benchmarks/base.py
+++ b/crossbench/benchmarks/base.py
@@ -9,40 +9,29 @@ import argparse
 import logging
 import re
 from typing import (TYPE_CHECKING, Any, Dict, Generic, List, Optional, Sequence,
-                    Tuple, Type, TypeVar, cast)
+                    Tuple, Type, TypeAlias, TypeVar, cast)
 
 from ordered_set import OrderedSet
+from typing_extensions import override
 
-from crossbench import helper
 from crossbench.cli.parser import CrossBenchArgumentParser
 from crossbench.flags.base import Flags
+from crossbench.helper import txt_helper
 from crossbench.parse import ObjectParser
 from crossbench.stories.press_benchmark import PressBenchmarkStory
 from crossbench.stories.story import Story
 
 if TYPE_CHECKING:
   from crossbench import path as pth
+  from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
   from crossbench.browsers.attributes import BrowserAttributes
   from crossbench.runner.runner import Runner
 
 
-class BenchmarkProbeMixin:
-  NAME: str = ""
-  IS_GENERAL_PURPOSE: bool = False
-
-  def __init__(self, *args, **kwargs):
-    self._benchmark = kwargs.pop("benchmark")
-    assert isinstance(self._benchmark, Benchmark)
-    super().__init__(*args, **kwargs)
-
-  @property
-  def benchmark(self) -> Benchmark:
-    return self._benchmark
-
 
 class Benchmark(abc.ABC):
   NAME: str = ""
-  DEFAULT_STORY_CLS: Type[Story] = Story
+  DEFAULT_STORY_CLS: Type[Story] = Story  # type: ignore
   PROBES: Tuple[Type[BenchmarkProbeMixin], ...] = ()
   DEFAULT_REPETITIONS: int = 1
 
@@ -81,15 +70,19 @@ class Benchmark(abc.ABC):
   @classmethod
   def describe(cls) -> Dict[str, Any]:
     return {
-        "name": cls.NAME,
-        "description": "\n".join(helper.wrap_lines(cls.cli_description(), 70)),
+        "name":
+            cls.NAME,
+        "aliases":
+            cls.aliases() or "None",
+        "description":
+            "\n".join(txt_helper.wrap_lines(cls.cli_description(), 70)),
         "stories": [],
         "probes-default": {
             probe_cls.NAME:
                 "\n".join(
                     list(
-                        helper.wrap_lines((probe_cls.__doc__ or "").strip(),
-                                          70))) for probe_cls in cls.PROBES
+                        txt_helper.wrap_lines((probe_cls.__doc__ or "").strip(),
+                                              70))) for probe_cls in cls.PROBES
         }
     }
 
@@ -199,17 +192,25 @@ class StoryFilter(Generic[StoryT], metaclass=abc.ABCMeta):
   def create_stories(self, separate: bool) -> Sequence[StoryT]:
     pass
 
+  def log_stories(self, stories: Sequence[StoryT]) -> None:
+    substory_names = [name for story in stories for name in story.substories]
+    stories_str = ", ".join(substory_names)
+    logging.info(" SELECTED %s STORIES AND %s SUBSTORIES: %s", len(stories),
+                 len(substory_names), stories_str)
+
 
 class SubStoryBenchmark(Benchmark, metaclass=abc.ABCMeta):
-  STORY_FILTER_CLS: Type[StoryFilter] = StoryFilter
+  STORY_FILTER_CLS: Type[StoryFilter] = StoryFilter  # type: ignore
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, subparsers, aliases: Sequence[str] = ()) -> CrossBenchArgumentParser:
     parser = super().add_cli_parser(subparsers, aliases)
     return parser
 
   @classmethod
+  @override
   def cli_description(cls) -> str:
     desc = super().cli_description()
     desc += "\n\n"
@@ -225,6 +226,7 @@ class SubStoryBenchmark(Benchmark, metaclass=abc.ABCMeta):
     return desc
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["stories"] = cls.stories_from_cli_args(args)
@@ -236,6 +238,7 @@ class SubStoryBenchmark(Benchmark, metaclass=abc.ABCMeta):
                                               args).stories
 
   @classmethod
+  @override
   def describe(cls) -> Dict[str, Any]:
     data = super().describe()
     data["stories"] = cls.all_story_names()
@@ -267,6 +270,7 @@ class PressBenchmarkStoryFilter(StoryFilter[PressBenchmarkStoryT],
   """
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["separate"] = args.separate
@@ -277,8 +281,8 @@ class PressBenchmarkStoryFilter(StoryFilter[PressBenchmarkStoryT],
                story_cls: Type[PressBenchmarkStoryT],
                patterns: Sequence[str],
                separate: bool = False,
-               url: Optional[str] = None):
-    self.url: Optional[str] = url
+               url: Optional[str] = None) -> None:
+    self.url: str | None = url
     self._selected_names: OrderedSet[str] = OrderedSet()
     super().__init__(story_cls, patterns, separate)
     assert issubclass(self.story_cls, PressBenchmarkStory)
@@ -288,6 +292,7 @@ class PressBenchmarkStoryFilter(StoryFilter[PressBenchmarkStoryT],
           f"Known story names cannot start with '-', but got '{name}'.")
       assert not name == "all", "Known story name cannot match 'all'."
 
+  @override
   def process_all(self, patterns: Sequence[str]) -> None:
     if not isinstance(patterns, (list, tuple)):
       raise ValueError("Expected Sequence of story name or patterns "
@@ -367,20 +372,24 @@ class PressBenchmarkStoryFilter(StoryFilter[PressBenchmarkStoryT],
                        "previously filtered story names.")
     return substories
 
+  @override
   def create_stories(self, separate: bool) -> Sequence[PressBenchmarkStoryT]:
-    logging.info("SELECTED STORIES: %s",
-                 str(list(map(str, self._selected_names))))
     names = list(self._selected_names)
-    return self.create_stories_from_names(names, separate)
+    stories = self.create_stories_from_names(names, separate)
+    self.log_stories(stories)
+    return stories
 
   def create_stories_from_names(
       self, names: List[str], separate: bool) -> Sequence[PressBenchmarkStoryT]:
     return self.story_cls.from_names(names, separate=separate, url=self.url)
 
 
+VersionParts: TypeAlias = Tuple[str] | Tuple[int, ...]
+
 class PressBenchmark(SubStoryBenchmark):
   STORY_FILTER_CLS = PressBenchmarkStoryFilter
-  DEFAULT_STORY_CLS: Type[PressBenchmarkStory] = PressBenchmarkStory
+  DEFAULT_STORY_CLS: Type[
+      PressBenchmarkStory] = PressBenchmarkStory  # type: ignore
 
   @classmethod
   @abc.abstractmethod
@@ -394,22 +403,33 @@ class PressBenchmark(SubStoryBenchmark):
 
   @classmethod
   @abc.abstractmethod
-  def version(cls) -> Tuple[int, ...]:
+  def version(cls) -> VersionParts:
     raise NotImplementedError()
 
   @classmethod
+  @override
   def aliases(cls) -> Tuple[str, ...]:
-    version = [str(v) for v in cls.version()]
+    raw_version: VersionParts = cls.version()
+    is_branch_version = (
+        len(raw_version) == 1 and isinstance(raw_version[0], str))
+    if not is_branch_version:
+      assert (all((isinstance(part, int)) for part in raw_version)), (
+          "All version parts should be integers.")
+    version = [str(v) for v in raw_version]
     assert version, "Expected non-empty version tuple."
     version_names = []
     dot_version = ".".join(version)
     for name in (cls.short_base_name(), cls.base_name()):
       assert name, "Expected non-empty base name."
-      version_names.append(f"{name}{dot_version}")
-      version_names.append(f"{name}_{dot_version}")
+      if not is_branch_version:
+        version_names.append(f"{name}{dot_version}")
+      version_name = f"{name}_{dot_version}"
+      if version_name != cls.NAME:
+        version_names.append(version_name)
     return tuple(version_names)
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, subparsers, aliases: Sequence[str] = ()) -> CrossBenchArgumentParser:
     parser = super().add_cli_parser(subparsers, aliases)
@@ -422,6 +442,7 @@ class PressBenchmark(SubStoryBenchmark):
         "--live",
         "--live-url",
         "--browser-ben",
+        "--browserben",
         dest="custom_benchmark_url",
         const=None,
         action="store_const",
@@ -450,23 +471,26 @@ class PressBenchmark(SubStoryBenchmark):
     return parser
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["custom_url"] = args.custom_benchmark_url
     return kwargs
 
   @classmethod
+  @override
   def describe(cls) -> Dict[str, Any]:
     data = super().describe()
     assert issubclass(cls.DEFAULT_STORY_CLS, PressBenchmarkStory)
     data["url"] = cls.DEFAULT_STORY_CLS.URL
     data["url-official"] = cls.DEFAULT_STORY_CLS.URL_OFFICIAL
     data["url-local"] = cls.DEFAULT_STORY_CLS.URL_LOCAL
+    data["version"] = ".".join(map(str, cls.version()))
     return data
 
   def __init__(self,
                stories: Sequence[Story],
-               custom_url: Optional[str] = None):
+               custom_url: Optional[str] = None) -> None:
     super().__init__(stories)
     self.custom_url = custom_url
     if custom_url:
@@ -474,6 +498,7 @@ class PressBenchmark(SubStoryBenchmark):
         press_story = cast(PressBenchmarkStory, story)
         assert press_story.url == custom_url
 
+  @override
   def setup(self, runner: Runner) -> None:
     super().setup(runner)
     self.validate_url(runner)
diff --git a/crossbench/benchmarks/benchmark_probe.py b/crossbench/benchmarks/benchmark_probe.py
new file mode 100644
index 00000000..6ff00e23
--- /dev/null
+++ b/crossbench/benchmarks/benchmark_probe.py
@@ -0,0 +1,24 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import Benchmark
+
+
+class BenchmarkProbeMixin:
+  NAME: str = ""
+  IS_GENERAL_PURPOSE: bool = False
+
+  def __init__(self, *args, **kwargs) -> None:
+    self._benchmark: Benchmark = kwargs.pop("benchmark")
+    #assert isinstance(self._benchmark, Benchmark)
+    super().__init__(*args, **kwargs)
+
+  @property
+  def benchmark(self) -> Benchmark:
+    return self._benchmark
diff --git a/crossbench/benchmarks/benchmark_validator.py b/crossbench/benchmarks/benchmark_validator.py
new file mode 100644
index 00000000..0fc696bf
--- /dev/null
+++ b/crossbench/benchmarks/benchmark_validator.py
@@ -0,0 +1,29 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import inspect
+from typing import TYPE_CHECKING, Type
+
+from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
+from crossbench.probes.probe import Probe
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import Benchmark
+
+
+def validate_cls(cls: Type[Benchmark]) -> None:
+  for benchmark_probe_cls in cls.PROBES:
+    assert inspect.isclass(benchmark_probe_cls), (
+        f"{cls}.PROBES must contain classes only, "
+        f"but got {type(benchmark_probe_cls)}")
+    assert issubclass(
+        benchmark_probe_cls,
+        Probe), (f"Expected Probe class but got {type(benchmark_probe_cls)}")
+    assert issubclass(benchmark_probe_cls, BenchmarkProbeMixin), (
+        f"{benchmark_probe_cls} should be BenchmarkProbeMixin "
+        f"for {type(cls)}.PROBES")
+    assert benchmark_probe_cls.NAME, (  # type: ignore
+        f"Expected probe.NAME for {benchmark_probe_cls}")
diff --git a/crossbench/benchmarks/jetstream/__init__.py b/crossbench/benchmarks/jetstream/__init__.py
index 229e21f4..e67802f2 100644
--- a/crossbench/benchmarks/jetstream/__init__.py
+++ b/crossbench/benchmarks/jetstream/__init__.py
@@ -7,4 +7,5 @@ from __future__ import annotations
 from crossbench.benchmarks.jetstream.jetstream_2_0 import JetStream20Benchmark
 from crossbench.benchmarks.jetstream.jetstream_2_1 import JetStream21Benchmark
 from crossbench.benchmarks.jetstream.jetstream_2_2 import JetStream22Benchmark
-from crossbench.benchmarks.jetstream.jetstream_3_0 import JetStream30Benchmark
+from crossbench.benchmarks.jetstream.jetstream_main import \
+    JetStreamMainBenchmark
diff --git a/crossbench/benchmarks/jetstream/jetstream.py b/crossbench/benchmarks/jetstream/jetstream.py
index dad96fbe..ff2fc252 100644
--- a/crossbench/benchmarks/jetstream/jetstream.py
+++ b/crossbench/benchmarks/jetstream/jetstream.py
@@ -7,14 +7,18 @@ from __future__ import annotations
 import abc
 import json
 import logging
+import statistics
 from collections import defaultdict
-from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
-                    cast)
+from typing import (TYPE_CHECKING, Any, Dict, Final, List, Optional, Sequence,
+                    Tuple, Type, cast)
 
-from crossbench.benchmarks.base import BenchmarkProbeMixin, PressBenchmark
-from crossbench.probes.json import JsonResultProbe
-from crossbench.probes.metric import (CSVFormatter, Metric, MetricsMerger,
-                                      geomean)
+from typing_extensions import override
+
+from crossbench.benchmarks.base import PressBenchmark
+from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
+from crossbench.parse import ObjectParser
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
+from crossbench.probes.metric import CSVFormatter, Metric, MetricsMerger
 from crossbench.probes.results import ProbeResult, ProbeResultDict
 
 if TYPE_CHECKING:
@@ -36,59 +40,23 @@ class JetStreamProbe(
   JetStream-specific Probe.
   Extracts all JetStream times and scores.
   """
-  FLATTEN: bool = False
-  JS: str = """
-  let results = Object.create(null);
-  let benchmarks = []
-  for (let benchmark of JetStream.benchmarks) {
-    const data = { score: benchmark.score };
-    if ("worst4" in benchmark) {
-      data.firstIteration = benchmark.firstIteration;
-      data.average = benchmark.average;
-      data.worst4 = benchmark.worst4;
-    } else if ("runTime" in benchmark) {
-      data.runTime = benchmark.runTime;
-      data.startupTime = benchmark.startupTime;
-    } else if ("mainRun" in benchmark) {
-      data.mainRun = benchmark.mainRun;
-      data.stdlib = benchmark.stdlib;
-    }
-    results[benchmark.plan.name] = data;
-    benchmarks.push(benchmark);
-  };
-  return results;
-"""
+
+  TOTAL_METRIC_KEY: Final[str] = "Total/score"
 
   @property
   def jetstream(self) -> JetStreamBenchmark:
     return cast(JetStreamBenchmark, self.benchmark)
 
-  def to_json(self, actions: Actions) -> Dict[str, float]:
-    data = actions.js(self.JS)
-    assert len(data) > 0, "No benchmark data generated"
-    return data
-
-  def process_json_data(self, json_data: Dict[str, Any]) -> Dict[str, Any]:
-    assert "Total" not in json_data, (
-        "JSON result data already contains a ['Total'] entry.")
-    json_data["Total"] = self._compute_total_metrics(json_data)
-    return json_data
-
-  def _compute_total_metrics(self, json_data: Dict[str,
-                                                   Any]) -> Dict[str, float]:
-    # Manually add all total scores
-    accumulated_metrics = defaultdict(list)
-    for _, metrics in json_data.items():
-      for metric, value in metrics.items():
-        accumulated_metrics[metric].append(value)
-    total: Dict[str, float] = {}
-    for metric, values in accumulated_metrics.items():
-      total[metric] = geomean(values)
-    return total
+  @abc.abstractmethod
+  @override
+  def get_context_cls(self) -> Type[JetStreamProbeContext]:
+    pass
 
+  @override
   def log_run_result(self, run: Run) -> None:
     self._log_result(run.results, single_result=True)
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     self._log_result(group.results, single_result=False)
 
@@ -110,6 +78,7 @@ class JetStreamProbe(
       else:
         self._log_result_metrics(data)
 
+  @override
   def _extract_result_metrics_table(self, metrics: Dict[str, Any],
                                     table: Dict[str, List[str]]) -> None:
     for metric_key, metric_value in metrics.items():
@@ -118,17 +87,33 @@ class JetStreamProbe(
       table[metric_key].append(
           Metric.format(metric_value["average"], metric_value["stddev"]))
       # Separate runs don't produce a score
-    if "Total/score" in metrics:
-      metric_value = metrics["Total/score"]
+    if self.TOTAL_METRIC_KEY in metrics:
+      metric_value = metrics[self.TOTAL_METRIC_KEY]
       table["Score"].append(
           Metric.format(metric_value["average"], metric_value["stddev"]))
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     merged = MetricsMerger.merge_json_list(
         story_group.results[self].json
         for story_group in group.repetitions_groups)
+    # We discard the score when merging separate line item runs, recompute it!
+    if self.TOTAL_METRIC_KEY not in merged.data:
+      merged.data[self.TOTAL_METRIC_KEY] = self._compute_total_score(merged)
     return self.write_group_result(group, merged, JetStreamCSVFormatter)
 
+  def _compute_total_score(self, merged: MetricsMerger) -> Metric:
+    line_item_scores: List[List[float]] = []
+    for key, metric in merged.data.items():
+      if self._is_valid_metric_key(key):
+        line_item_scores.append(metric.values)
+    total_score = Metric()
+    for iteration_line_items_score_values in zip(*line_item_scores):
+      iteration_score = Metric(iteration_line_items_score_values).geomean
+      total_score.append(iteration_score)
+    return total_score
+
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     return self.merge_browsers_json_list(group).merge(
         self.merge_browsers_csv_list(group))
@@ -141,34 +126,92 @@ class JetStreamProbe(
       return True
     return parts[0] != "Total" and parts[1] == "score"
 
+
+class JetStreamProbeContext(JsonResultProbeContext):
+  FLATTEN: bool = False
+  JS: str = """
+  let results = Object.create(null);
+  let benchmarks = []
+  for (let benchmark of JetStream.benchmarks) {
+    const data = { score: benchmark.score };
+    if ("worst4" in benchmark) {
+      data.firstIteration = benchmark.firstIteration;
+      data.average = benchmark.average;
+      data.worst4 = benchmark.worst4;
+    } else if ("runTime" in benchmark) {
+      data.runTime = benchmark.runTime;
+      data.startupTime = benchmark.startupTime;
+    } else if ("mainRun" in benchmark) {
+      data.mainRun = benchmark.mainRun;
+      data.stdlib = benchmark.stdlib;
+    }
+    results[benchmark.plan.name] = data;
+    benchmarks.push(benchmark);
+  };
+  return JSON.stringify(results);
+"""
+
+  @override
+  def to_json(self, actions: Actions) -> Dict[str, float]:
+    # Use serialized json as transport format to preserve object key order.
+    json_payload = actions.js(self.JS)
+    json_data = json.loads(json_payload)
+    ObjectParser.non_empty_dict(json_data, f"{self.probe.name} metrics")
+    return json_data
+
+  @override
+  def process_json_data(self, json_data: Json) -> Json:
+    assert isinstance(json_data, dict)
+    assert "Total" not in json_data, (
+        "JSON result data already contains a ['Total'] entry.")
+    json_data["Total"] = self._compute_total_metrics(json_data)
+    return json_data
+
+  def _compute_total_metrics(self, json_data: Dict[str,
+                                                   Any]) -> Dict[str, float]:
+    # Manually add all total scores
+    accumulated_metrics = defaultdict(list)
+    for _, metrics in json_data.items():
+      for metric, value in metrics.items():
+        accumulated_metrics[metric].append(value)
+    total: Dict[str, float] = {}
+    for metric, values in accumulated_metrics.items():
+      total[metric] = statistics.geometric_mean(values)
+    return total
+
+
 class JetStreamCSVFormatter(CSVFormatter):
+  TOTAL_METRIC_KEY: Final[str] = JetStreamProbe.TOTAL_METRIC_KEY
 
+  @override
   def format_items(self, data: Dict[str, Json],
                    sort: bool) -> Sequence[Tuple[str, Json]]:
     items = list(data.items())
     if sort:
       items.sort()
     # Copy all /score items to the top:
-    total_key = "Total/score"
     score_items = []
     for key, value in items:
-      if key != total_key and key.endswith("/score"):
+      if key != self.TOTAL_METRIC_KEY and key.endswith("/score"):
         score_items.append((key, value))
-    total_item = [(total_key, data[total_key])]
+    total_item = [(self.TOTAL_METRIC_KEY, data[self.TOTAL_METRIC_KEY])]
     return total_item + score_items + items
 
 
 class JetStreamBenchmark(PressBenchmark, metaclass=abc.ABCMeta):
 
   @classmethod
+  @override
   def short_base_name(cls) -> str:
     return "js"
 
   @classmethod
+  @override
   def base_name(cls) -> str:
     return "jetstream"
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
   ) -> CrossBenchArgumentParser:
@@ -182,6 +225,7 @@ class JetStreamBenchmark(PressBenchmark, metaclass=abc.ABCMeta):
     return parser
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["detailed_metrics"] = args.detailed_metrics
@@ -190,7 +234,7 @@ class JetStreamBenchmark(PressBenchmark, metaclass=abc.ABCMeta):
   def __init__(self,
                stories: Sequence[Story],
                custom_url: Optional[str] = None,
-               detailed_metrics: bool = False):
+               detailed_metrics: bool = False) -> None:
     self._detailed_metrics = detailed_metrics
     super().__init__(stories, custom_url)
 
diff --git a/crossbench/benchmarks/jetstream/jetstream_2.py b/crossbench/benchmarks/jetstream/jetstream_2.py
index fec1625a..27fe5106 100644
--- a/crossbench/benchmarks/jetstream/jetstream_2.py
+++ b/crossbench/benchmarks/jetstream/jetstream_2.py
@@ -5,11 +5,20 @@
 from __future__ import annotations
 
 import abc
+import argparse
 import datetime as dt
-from typing import TYPE_CHECKING, Tuple, Type
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    Type)
 
+from typing_extensions import override
+
+from crossbench.benchmarks.base import PressBenchmarkStoryFilter
 from crossbench.benchmarks.jetstream.jetstream import (JetStreamBenchmark,
-                                                       JetStreamProbe)
+                                                       JetStreamProbe,
+                                                       JetStreamProbeContext)
+from crossbench.helper import url_helper
+from crossbench.parse import NumberParser
 from crossbench.stories.press_benchmark import PressBenchmarkStory
 
 if TYPE_CHECKING:
@@ -23,6 +32,10 @@ class JetStream2Probe(JetStreamProbe, metaclass=abc.ABCMeta):
   """
 
 
+class JetStream2ProbeContext(JetStreamProbeContext):
+  pass
+
+
 class JetStream2Story(PressBenchmarkStory, metaclass=abc.ABCMeta):
   URL_LOCAL: str = "http://localhost:8000/"
   SUBSTORIES: Tuple[str, ...] = (
@@ -92,10 +105,41 @@ class JetStream2Story(PressBenchmarkStory, metaclass=abc.ABCMeta):
       "3d-cube-SP",
   )
 
+  def __init__(self,
+               substories: Sequence[str] = (),
+               iterations: Optional[int] = None,
+               url: Optional[str] = None) -> None:
+    self._iterations: int | None = iterations
+    if iterations is not None:
+      self._iterations = NumberParser.positive_int(
+          self._iterations, "iteration count", parse_str=False)
+    super().__init__(url=url, substories=substories)
+
   @property
+  @override
   def substory_duration(self) -> dt.timedelta:
     return dt.timedelta(seconds=2)
 
+  @property
+  def iterations(self) -> Optional[int]:
+    return self._iterations
+
+  @property
+  def url_params(self) -> Dict[str, str]:
+    params: Dict[str, str] = {}
+    if self.iterations:
+      params["iterationCount"] = str(self.iterations)
+    return params
+
+  @override
+  def get_run_url(self, run: Run) -> str:
+    url = super().get_run_url(run)
+    url = url_helper.update_url_query(url, self.url_params)
+    if url != self.url:
+      logging.info("CUSTOM URL: %s", url)
+    return url
+
+  @override
   def setup(self, run: Run) -> None:
     with run.actions("Setup") as actions:
       actions.show_url(self.get_run_url(run))
@@ -133,5 +177,51 @@ class JetStream2Story(PressBenchmarkStory, metaclass=abc.ABCMeta):
 ProbeClsTupleT = Tuple[Type[JetStream2Probe], ...]
 
 
+class JetStream2BenchmarkStoryFilter(PressBenchmarkStoryFilter):
+  __doc__ = PressBenchmarkStoryFilter.__doc__
+
+  @classmethod
+  @override
+  def add_cli_parser(
+      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser = super().add_cli_parser(parser)
+    parser.add_argument(
+        "--iterations",
+        "--iteration-count",
+        default=None,
+        type=NumberParser.positive_int,
+        help="Number of iterations each JetStream subtest is run "
+        "within the same session. \n"
+        "Note: --repetitions restarts the whole benchmark, --iterations runs "
+        "the same test tests n-times within the same session without the setup "
+        "overhead of starting up a whole new browser. \n"
+        "This option is not supported on the official benchmark "
+        "before version 3.0.")
+    return parser
+
+  @classmethod
+  @override
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["iterations"] = args.iterations
+    return kwargs
+
+  def __init__(self,
+               story_cls: Type[JetStream2Story],
+               patterns: Sequence[str],
+               separate: bool = False,
+               url: Optional[str] = None,
+               iterations: Optional[int] = None) -> None:
+    self.iterations = iterations
+    assert issubclass(story_cls, JetStream2Story)
+    super().__init__(story_cls, patterns, separate, url)
+
+  @override
+  def create_stories_from_names(self, names: List[str],
+                                separate: bool) -> Sequence[JetStream2Story]:
+    return self.story_cls.from_names(
+        names, separate=separate, url=self.url, iterations=self.iterations)
+
+
 class JetStream2Benchmark(JetStreamBenchmark):
-  pass
+  STORY_FILTER_CLS = JetStream2BenchmarkStoryFilter
diff --git a/crossbench/benchmarks/jetstream/jetstream_2_0.py b/crossbench/benchmarks/jetstream/jetstream_2_0.py
index f98287c4..9b4ba505 100644
--- a/crossbench/benchmarks/jetstream/jetstream_2_0.py
+++ b/crossbench/benchmarks/jetstream/jetstream_2_0.py
@@ -4,18 +4,31 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
 
 from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
                                                          JetStream2Probe,
+                                                         JetStream2ProbeContext,
                                                          JetStream2Story,
                                                          ProbeClsTupleT)
 
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class JetStream20Probe(JetStream2Probe):
   __doc__ = JetStream2Probe.__doc__
   NAME: str = "jetstream_2.0"
 
+  @override
+  def get_context_cls(self) -> Type[JetStream20ProbeContext]:
+    return JetStream20ProbeContext
+
+
+class JetStream20ProbeContext(JetStream2ProbeContext):
+  pass
+
 
 class JetStream20Story(JetStream2Story):
   __doc__ = JetStream2Story.__doc__
@@ -34,5 +47,6 @@ class JetStream20Benchmark(JetStream2Benchmark):
   PROBES: ProbeClsTupleT = (JetStream20Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (2, 0)
diff --git a/crossbench/benchmarks/jetstream/jetstream_2_1.py b/crossbench/benchmarks/jetstream/jetstream_2_1.py
index df638048..d14cb5fc 100644
--- a/crossbench/benchmarks/jetstream/jetstream_2_1.py
+++ b/crossbench/benchmarks/jetstream/jetstream_2_1.py
@@ -4,18 +4,31 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
 
 from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
                                                          JetStream2Probe,
+                                                         JetStream2ProbeContext,
                                                          JetStream2Story,
                                                          ProbeClsTupleT)
 
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class JetStream21Probe(JetStream2Probe):
   __doc__ = JetStream2Probe.__doc__
   NAME: str = "jetstream_2.1"
 
+  @override
+  def get_context_cls(self) -> Type[JetStream21ProbeContext]:
+    return JetStream21ProbeContext
+
+
+class JetStream21ProbeContext(JetStream2ProbeContext):
+  pass
+
 
 class JetStream21Story(JetStream2Story):
   __doc__ = JetStream2Story.__doc__
@@ -34,5 +47,6 @@ class JetStream21Benchmark(JetStream2Benchmark):
   PROBES: ProbeClsTupleT = (JetStream21Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (2, 1)
diff --git a/crossbench/benchmarks/jetstream/jetstream_2_2.py b/crossbench/benchmarks/jetstream/jetstream_2_2.py
index 902daf3d..e362f72c 100644
--- a/crossbench/benchmarks/jetstream/jetstream_2_2.py
+++ b/crossbench/benchmarks/jetstream/jetstream_2_2.py
@@ -4,18 +4,31 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Tuple, Type
+
+from typing_extensions import override
 
 from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
                                                          JetStream2Probe,
+                                                         JetStream2ProbeContext,
                                                          JetStream2Story,
                                                          ProbeClsTupleT)
 
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class JetStream22Probe(JetStream2Probe):
   __doc__ = JetStream2Probe.__doc__
   NAME: str = "jetstream_2.2"
 
+  @override
+  def get_context_cls(self) -> Type[JetStream22ProbeContext]:
+    return JetStream22ProbeContext
+
+
+class JetStream22ProbeContext(JetStream2ProbeContext):
+  pass
+
 
 class JetStream22Story(JetStream2Story):
   __doc__ = JetStream2Story.__doc__
@@ -34,9 +47,11 @@ class JetStream22Benchmark(JetStream2Benchmark):
   PROBES: ProbeClsTupleT = (JetStream22Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (2, 2)
 
   @classmethod
+  @override
   def aliases(cls) -> Tuple[str, ...]:
     return ("js", "jetstream", "js2", "jetstream_2") + super().aliases()
diff --git a/crossbench/benchmarks/jetstream/jetstream_3.py b/crossbench/benchmarks/jetstream/jetstream_3.py
index 0750f747..9841e23f 100644
--- a/crossbench/benchmarks/jetstream/jetstream_3.py
+++ b/crossbench/benchmarks/jetstream/jetstream_3.py
@@ -9,6 +9,7 @@ from typing import Tuple, Type
 
 from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
                                                          JetStream2Probe,
+                                                         JetStream2ProbeContext,
                                                          JetStream2Story)
 
 
@@ -20,6 +21,10 @@ class JetStream3Probe(JetStream2Probe, metaclass=abc.ABCMeta):
   """
 
 
+class JetStream3ProbeContext(JetStream2ProbeContext):
+  pass
+
+
 # TODO: introduce JetStreamStory
 class JetStream3Story(JetStream2Story, metaclass=abc.ABCMeta):
   SUBSTORIES: Tuple[str, ...] = ()
diff --git a/crossbench/benchmarks/jetstream/jetstream_3_0.py b/crossbench/benchmarks/jetstream/jetstream_main.py
similarity index 70%
rename from crossbench/benchmarks/jetstream/jetstream_3_0.py
rename to crossbench/benchmarks/jetstream/jetstream_main.py
index 67fdf629..61c87229 100644
--- a/crossbench/benchmarks/jetstream/jetstream_3_0.py
+++ b/crossbench/benchmarks/jetstream/jetstream_main.py
@@ -1,27 +1,41 @@
-# Copyright 2024 The Chromium Authors
+# Copyright 2025 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Tuple, Type
+
+from typing_extensions import override
 
 from crossbench.benchmarks.jetstream.jetstream_3 import (JetStream3Benchmark,
                                                          JetStream3Probe,
+                                                         JetStream3ProbeContext,
                                                          JetStream3Story,
                                                          ProbeClsTupleT)
 
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
+
 
-class JetStream30Probe(JetStream3Probe):
+class JetStreamMainProbe(JetStream3Probe):
   __doc__ = JetStream3Probe.__doc__
-  NAME: str = "jetstream_3.0"
+  NAME: str = "jetstream_main"
+
+  @override
+  def get_context_cls(self) -> Type[JetStreamMainProbeContext]:
+    return JetStreamMainProbeContext
+
 
+class JetStreamMainProbeContext(JetStream3ProbeContext):
+  pass
 
-class JetStream30Story(JetStream3Story):
+
+class JetStreamMainStory(JetStream3Story):
   __doc__ = JetStream3Story.__doc__
-  NAME: str = "jetstream_3.0"
-  URL: str = "https://chromium-workloads.web.app/jetstream/v3.0/"
-  URL_OFFICIAL: str = "https://browserbench.org/JetStream3.0/"
+  NAME: str = "jetstream_main"
+  URL: str = "https://chromium-workloads.web.app/jetstream/main/"
+  URL_OFFICIAL: str = "https://chromium-workloads.web.app/jetstream/main/"
   SUBSTORIES: Tuple[str, ...] = (
       "WSL",
       "UniPoker",
@@ -109,19 +123,16 @@ class JetStream30Story(JetStream3Story):
   )
 
 
-class JetStream30Benchmark(JetStream3Benchmark):
+class JetStreamMainBenchmark(JetStream3Benchmark):
   """
-  Benchmark runner for JetStream 3.0.
+  Benchmark runner for the JetStream main developement vresion.
   """
 
-  NAME: str = "jetstream_3.0"
-  DEFAULT_STORY_CLS = JetStream30Story
-  PROBES: ProbeClsTupleT = (JetStream30Probe,)
-
-  @classmethod
-  def version(cls) -> Tuple[int, ...]:
-    return (3, 0)
+  NAME: str = "jetstream_main"
+  DEFAULT_STORY_CLS = JetStreamMainStory
+  PROBES: ProbeClsTupleT = (JetStreamMainProbe,)
 
   @classmethod
-  def aliases(cls) -> Tuple[str, ...]:
-    return ("js3", "jetstream_3") + super().aliases()
+  @override
+  def version(cls) -> VersionParts:
+    return ("main",)
diff --git a/crossbench/benchmarks/loading/config/blocks.py b/crossbench/benchmarks/loading/config/blocks.py
index f78d9f7e..06c41131 100644
--- a/crossbench/benchmarks/loading/config/blocks.py
+++ b/crossbench/benchmarks/loading/config/blocks.py
@@ -7,8 +7,11 @@ from __future__ import annotations
 import argparse
 import dataclasses
 import datetime as dt
+import functools
 from typing import (TYPE_CHECKING, Any, Dict, Final, Iterator, List, Optional,
-                    Sequence, Tuple, Type, cast)
+                    Self, Sequence, Tuple, cast)
+
+from typing_extensions import override
 
 from crossbench import exception
 from crossbench.action_runner.action.action import Action
@@ -35,26 +38,31 @@ class ActionBlock(ConfigObject):
   actions: Tuple[Action, ...] = tuple()
 
   @classmethod
-  def parse_str(cls: Type[ActionBlock], value: str) -> ActionBlock:
+  @override
+  def parse_str(cls, value: str) -> Self:
     raise NotImplementedError("Cannot create action blocks from strings")
 
   @classmethod
-  def parse_other(cls: Type[ActionBlock], value: Any, **kwargs) -> ActionBlock:
+  def parse_other(cls, value: Any, **kwargs) -> Self:
     if isinstance(value, (tuple, list)):
       return cls.parse_sequence(value, **kwargs)
     return super().parse_other(value, **kwargs)
 
   @classmethod
+  @override
   def parse_dict(  # pylint: disable=arguments-differ
-      cls: Type,
+      cls,
       config: Dict[str, Any],
       label: Optional[str] = None,
-      index: Optional[int] = None):
-    return cls.config_parser().parse(config, label=label, index=index)
+      index: Optional[int] = None,
+      **kwargs) -> Self:
+    return cls.config_parser().parse(config, label=label, index=index, **kwargs)
 
   @classmethod
-  def config_parser(cls: Type[ActionBlock]) -> ConfigParser[ActionBlock]:
-    parser = ConfigParser(f"{cls.__name__} parser", cls)
+  @override
+  @functools.cache
+  def config_parser(cls) -> ConfigParser[Self]:  # type: ignore #override
+    parser = ConfigParser(cls)
     parser.add_argument("label", type=cls._parse_block_label, default="default")
     parser.add_argument(
         "index", type=NumberParser.positive_zero_int, default=0, required=False)
@@ -63,13 +71,14 @@ class ActionBlock(ConfigObject):
     return parser
 
   @classmethod
-  def parse_sequence(cls: Type[ActionBlock],
+  def parse_sequence(cls,
                      config: Sequence[Dict[str, Any]],
                      label: Optional[str] = None,
-                     index: Optional[int] = None) -> ActionBlock:
+                     index: Optional[int] = None) -> Self:
     with exception.annotate_argparsing(
         "Parsing default block action sequence:"):
       return cls.parse_dict({"actions": config}, label=label, index=index)
+    raise exception.UnreachableError()
 
   @classmethod
   def _parse_block_label(cls, value: Any) -> Optional[str]:
@@ -81,6 +90,7 @@ class ActionBlock(ConfigObject):
           f"Block label {repr(label)} is reserved for login blocks")
     return value
 
+  @override
   def validate(self) -> None:
     super().validate()
     self.validate_actions()
@@ -141,15 +151,13 @@ class ActionBlockListConfig(ConfigObject):
     return self.blocks
 
   @classmethod
-  def parse_other(cls: Type[ActionBlockListConfig],
-                  value: Any) -> ActionBlockListConfig:
+  def parse_other(cls, value: Any) -> Self:
     if isinstance(value, (tuple, list)):
       return cls.parse_sequence(value)
     return super().parse_other(value)
 
   @classmethod
-  def parse_sequence(cls: Type[ActionBlockListConfig],
-                     config: Sequence[Dict[str, Any]]) -> ActionBlockListConfig:
+  def parse_sequence(cls, config: Sequence[Dict[str, Any]]) -> Self:
     """Parse either a sequence of blocks or a sequence of actions for an
     implicit default block.
 
@@ -188,8 +196,8 @@ class ActionBlockListConfig(ConfigObject):
     return isinstance(sample, str) or "action" in sample
 
   @classmethod
-  def parse_dict(cls: Type[ActionBlockListConfig],
-                 config: Dict[str, Any]) -> ActionBlockListConfig:
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
     config = ObjectParser.non_empty_dict(config, "blocks")
 
     def block_config_data_gen():
@@ -201,7 +209,7 @@ class ActionBlockListConfig(ConfigObject):
     return cls._parse_blocks(block_config_data_gen())
 
   @classmethod
-  def _parse_blocks(cls, block_config_data_gen) -> ActionBlockListConfig:
+  def _parse_blocks(cls, block_config_data_gen) -> Self:
     blocks: List[ActionBlock] = []
     for index, label, block_data in block_config_data_gen:
       block = cls._parse_block(index, label, block_data)
@@ -220,19 +228,17 @@ class ActionBlockListConfig(ConfigObject):
     return ActionBlock.parse(block_data, label=label, index=index)
 
   @classmethod
-  def parse_str(cls, value: str) -> ActionBlockListConfig:
+  @override
+  def parse_str(cls, value: str) -> Self:
     raise NotImplementedError("Cannot create action blocks from strings")
 
+  @override
   def validate(self) -> None:
     super().validate()
     if not self.blocks:
       raise ValueError("Missing action blocks.")
     ObjectParser.non_empty_sequence(self.blocks, "blocks")
-    found_get = False
     for index, block in enumerate(self.blocks):
       if index != block.index:
         raise ValueError(
             f"blocks[{index}].index should be {index}, but got {block.index}")
-      found_get |= any(action.TYPE == ActionType.GET for action in block)
-    if not found_get:
-      raise ValueError("Expected at least one get action in one of the blocks.")
diff --git a/crossbench/benchmarks/loading/config/login/base.py b/crossbench/benchmarks/loading/config/login/base.py
index 041219ba..7663f440 100644
--- a/crossbench/benchmarks/loading/config/login/base.py
+++ b/crossbench/benchmarks/loading/config/login/base.py
@@ -4,52 +4,41 @@
 
 from __future__ import annotations
 
-import logging
 from typing import TYPE_CHECKING, Final
 
+from typing_extensions import override
+
 from crossbench.benchmarks.loading.config.blocks import ActionBlock
 
 if TYPE_CHECKING:
-  from crossbench.benchmarks.loading.page.interactive import InteractivePage
-  from crossbench.cli.config.secrets import Secret, SecretType
+  from crossbench.cli.config.secrets import UsernamePassword
   from crossbench.runner.run import Run
 
 
 class BaseLoginBlock(ActionBlock):
   LABEL: Final[str] = "login"
 
+  @override
   def validate(self) -> None:
     super().validate()
     assert self.index == 0, (
         f"Login block has to be the first, but got {self.index}")
 
   @property
+  @override
   def is_login(self) -> bool:
     return True
 
-  def get_secret(
-      self,
-      run: Run,
-      page: InteractivePage,
-      type: SecretType  # pylint: disable=redefined-builtin
-  ) -> Secret:
-    logging.debug("Looking up secrets {%s} for page %s", type, page)
-    if secret := page.secrets.get(type):
-      return secret
-    if secret := run.browser.secrets.get(type):
-      return secret
-    raise LookupError(f"Could not find any secret for {repr(str(type))} "
-                      f"on {page} or on {run.browser}")
-
   def is_logged_in(self,
                    run: Run,
-                   secret: Secret,
+                   secret: UsernamePassword,
                    strict: bool = False) -> bool:
     return run.browser.is_logged_in(secret, strict)
 
 
 class PresetLoginBlock(BaseLoginBlock):
 
+  @override
   def validate_actions(self) -> None:
     """Skip validation, since PresetLoginBlocks have an unknown number
     of actions."""
diff --git a/crossbench/benchmarks/loading/config/login/custom.py b/crossbench/benchmarks/loading/config/login/custom.py
index 96a9d504..165e364e 100644
--- a/crossbench/benchmarks/loading/config/login/custom.py
+++ b/crossbench/benchmarks/loading/config/login/custom.py
@@ -6,6 +6,8 @@ from __future__ import annotations
 
 import dataclasses
 
+from typing_extensions import override
+
 from crossbench.benchmarks.loading.config.login.base import BaseLoginBlock
 from crossbench.benchmarks.loading.config.login.login_type import (LOGIN_LOOKUP,
                                                                    LoginType)
@@ -15,6 +17,7 @@ from crossbench.benchmarks.loading.config.login.login_type import (LOGIN_LOOKUP,
 class LoginBlock(BaseLoginBlock):
 
   @classmethod
-  def parse_str(cls, value: str) -> BaseLoginBlock:
+  @override
+  def parse_str(cls, value: str) -> BaseLoginBlock:  # type: ignore
     login_type = LoginType.parse(value)
     return LOGIN_LOOKUP[login_type]()
diff --git a/crossbench/benchmarks/loading/config/login/google.py b/crossbench/benchmarks/loading/config/login/google.py
index aced045f..a88db3d1 100644
--- a/crossbench/benchmarks/loading/config/login/google.py
+++ b/crossbench/benchmarks/loading/config/login/google.py
@@ -6,13 +6,14 @@ from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench.benchmarks.loading.config.login.base import PresetLoginBlock
-from crossbench.cli.config.secret_type import SecretType
 
 if TYPE_CHECKING:
   from crossbench.action_runner.base import ActionRunner
   from crossbench.benchmarks.loading.page.interactive import InteractivePage
-  from crossbench.cli.config.secrets import Secret
+  from crossbench.cli.config.secrets import UsernamePassword
   from crossbench.runner.actions import Actions
   from crossbench.runner.run import Run
 
@@ -39,9 +40,12 @@ class GoogleLogin(PresetLoginBlock):
               f"inputField.value = {repr(input_val)};"
               f"document.getElementById({repr(button_name)}).click();")
 
+  @override
   def run_with(self, runner: ActionRunner, run: Run,
                page: InteractivePage) -> None:
-    secret: Secret = self.get_secret(run, page, SecretType.GOOGLE)
+    secret: UsernamePassword | None = run.secrets.google
+    if not secret:
+      raise RuntimeError("No google login provided")
 
     if self.is_logged_in(run, secret, strict=True):
       return
@@ -58,14 +62,14 @@ class GoogleLogin(PresetLoginBlock):
       else:
         self._standard_login(action, secret)
 
-  def _standard_login(self, action, secret):
+  def _standard_login(self, action: Actions, secret) -> None:
     self._submit_login_field(action, "Enter your password", secret.password,
                              "passwordNext")
     action.wait_js_condition(
         "return document.URL.startsWith('https://myaccount.google.com');", 0.2,
         10)
 
-  def _test_account_login(self, action, secret):
+  def _test_account_login(self, action: Actions, secret) -> None:
     self._submit_login_field(action, "Enter trusted contact\\s email",
                              secret.password, "verifycontactNext")
     # TODO: handle account passkey setup, for now each test account needs a
diff --git a/crossbench/benchmarks/loading/config/page.py b/crossbench/benchmarks/loading/config/page.py
index 7d5771fc..06a1c4e5 100644
--- a/crossbench/benchmarks/loading/config/page.py
+++ b/crossbench/benchmarks/loading/config/page.py
@@ -6,9 +6,10 @@ from __future__ import annotations
 
 import dataclasses
 import datetime as dt
-from typing import (TYPE_CHECKING, Any, Dict, Iterator, Optional, Sequence,
-                    Tuple, Type, cast)
-from urllib import parse as urlparse
+from typing import (TYPE_CHECKING, Any, Dict, Iterator, Optional, Self,
+                    Sequence, Tuple, cast)
+
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.action_runner.action.action_type import ActionType
@@ -19,7 +20,7 @@ from crossbench.benchmarks.loading.config.login.custom import LoginBlock
 from crossbench.benchmarks.loading.page.live import PAGES
 from crossbench.benchmarks.loading.playback_controller import \
     PlaybackController
-from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.cli.config.secrets import Secrets
 from crossbench.config import ConfigObject, ConfigParser
 from crossbench.parse import DurationParser, ObjectParser
 
@@ -29,24 +30,25 @@ if TYPE_CHECKING:
 
 @dataclasses.dataclass(frozen=True)
 class PageConfig(ConfigObject):
-  label: Optional[str] = None
-  playback: Optional[PlaybackController] = None
-  secrets: SecretsConfig = SecretsConfig()
-  login: Optional[LoginBlock] = None
-  setup: Optional[ActionBlock] = None
+  label: str | None = None
+  playback: PlaybackController | None = None
+  secrets: Secrets = Secrets()
+  login: LoginBlock | None = None
+  setup: ActionBlock | None = None
   blocks: Tuple[ActionBlock, ...] = tuple()
 
   @classmethod
-  def parse_other(cls: Type[PageConfig], value: Any, **kwargs) -> PageConfig:
+  def parse_other(cls, value: Any, **kwargs) -> Self:
     if isinstance(value, (list, tuple)):
       return cls.parse_sequence(value, **kwargs)
     return super().parse_other(value)
 
   @classmethod
+  @override
   def parse_str(  # pylint: disable=arguments-differ
-      cls: Type[PageConfig],
+      cls,
       value: str,
-      label: Optional[str] = None) -> PageConfig:
+      label: Optional[str] = None) -> Self:
     """
     Simple comma-separated string with optional duration:
       value = URL,[DURATION]
@@ -58,40 +60,43 @@ class PageConfig(ConfigObject):
       url = PAGES[raw_url].url
       label = label or raw_url
     else:
-      url = ObjectParser.parse_fuzzy_url_str(raw_url)
+      url = ObjectParser.fuzzy_url_str(raw_url)
     if len(parts) == 2:
       duration = DurationParser.positive_duration(parts[1])
     return cls.from_url(label, url, duration)
 
   @classmethod
-  def parse_sequence(cls: Type[PageConfig],
+  def parse_sequence(cls,
                      value: Sequence[Any],
                      label: Optional[str] = None,
-                     secrets: Optional[SecretsConfig] = None) -> PageConfig:
+                     secrets: Optional[Secrets] = None) -> Self:
     value = ObjectParser.non_empty_sequence(value, "story actions or blocks")
     blocks = ActionBlockListConfig.parse_sequence(value)
     if label is not None:
       label = ObjectParser.non_empty_str(label, "label")
-    secrets = secrets or SecretsConfig()
+    secrets = secrets or Secrets()
     return cls(label, secrets=secrets, blocks=blocks.blocks)
 
   @classmethod
+  @override
   def parse_dict(  # pylint: disable=arguments-differ
-      cls: Type[PageConfig],
+      cls,
       config: Dict[str, Any],
       label: Optional[str] = None,
-      secrets: Optional[SecretsConfig] = None) -> PageConfig:
+      secrets: Optional[Secrets] = None,
+      **kwargs) -> Self:
     config = ObjectParser.non_empty_dict(config, "story actions or blocks")
     page_config = cls.config_parser().parse(
-        config, label=label, secrets=secrets)
+        config, label=label, secrets=secrets, **kwargs)
     return page_config
 
   @classmethod
-  def config_parser(cls: Type[PageConfig]) -> ConfigParser[PageConfig]:
-    parser = ConfigParser(f"{cls.__name__} parser", cls)
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
     parser.add_argument("label", type=ObjectParser.non_empty_str)
     parser.add_argument("playback", type=PlaybackController.parse)
-    parser.add_argument("secrets", type=SecretsConfig, default=SecretsConfig())
+    parser.add_argument("secrets", type=Secrets, default=Secrets())
     parser.add_argument("login", type=LoginBlock)
     parser.add_argument("setup", type=ActionBlock)
     parser.add_argument(
@@ -104,10 +109,10 @@ class PageConfig(ConfigObject):
   def from_url(cls,
                label: Optional[str],
                url: str,
-               duration: dt.timedelta = dt.timedelta()) -> PageConfig:
+               duration: dt.timedelta = dt.timedelta()) -> Self:
     actions = (GetAction(url, duration=duration),)
     blocks = (ActionBlock(actions=actions),)
-    return PageConfig(label=label, blocks=blocks)
+    return cls(label=label, blocks=blocks)
 
   def actions(self) -> Iterator[Action]:
     for block in self.blocks:
@@ -123,7 +128,7 @@ class PageConfig(ConfigObject):
 
   @property
   def url_label(self) -> str:
-    url = urlparse.urlparse(self.first_url)
+    url = ObjectParser.url(self.first_url)
     if url.scheme == "about":
       return url.path
     if url.scheme == "file":
diff --git a/crossbench/benchmarks/loading/config/pages.py b/crossbench/benchmarks/loading/config/pages.py
index 0b072ac8..b1103194 100644
--- a/crossbench/benchmarks/loading/config/pages.py
+++ b/crossbench/benchmarks/loading/config/pages.py
@@ -8,19 +8,22 @@ import argparse
 import dataclasses
 import datetime as dt
 import logging
-from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
-                    Type)
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Self, Sequence,
+                    Tuple)
+
+from typing_extensions import override
 
 from crossbench import exception
 from crossbench import path as pth
 from crossbench.action_runner.action.click import ClickAction
 from crossbench.action_runner.action.enums import ReadyState
 from crossbench.action_runner.action.get import GetAction
+from crossbench.action_runner.action.position import PositionConfig
 from crossbench.action_runner.action.wait import WaitAction
 from crossbench.benchmarks.loading.config.blocks import ActionBlock
 from crossbench.benchmarks.loading.config.page import PageConfig
 from crossbench.benchmarks.loading.input_source import InputSource
-from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.cli.config.secrets import Secrets
 from crossbench.config import ConfigObject
 from crossbench.parse import DurationParseError, DurationParser, ObjectParser
 
@@ -31,8 +34,9 @@ if TYPE_CHECKING:
 @dataclasses.dataclass(frozen=True)
 class PagesConfig(ConfigObject):
   pages: Tuple[PageConfig, ...] = ()
-  secrets: Optional[SecretsConfig] = None
+  secrets: Secrets | None = None
 
+  @override
   def validate(self) -> None:
     super().validate()
     for index, page in enumerate(self.pages):
@@ -40,13 +44,18 @@ class PagesConfig(ConfigObject):
           f"pages[{index}] is not a PageConfig but {type(page).__name__}")
 
   @classmethod
-  def parse_str(cls, value: str) -> PagesConfig:
+  @override
+  def parse_str(cls, value: str) -> Self:
     """
     Simple comma-separate config:
     value = URL, [DURATION], ...
     """
+    value = ObjectParser.non_empty_str(value)
+    if value[0] == "{":
+      return cls.parse_inline_hjson(value)
+
     values: List[str] = []
-    previous_part: Optional[str] = None
+    previous_part: str | None = None
     for part in value.strip().split(","):
       part = ObjectParser.non_empty_str(part, "url or duration")
       try:
@@ -63,18 +72,18 @@ class PagesConfig(ConfigObject):
     return cls.parse_sequence(values)
 
   @classmethod
-  def parse_unknown_path(cls, path: pth.LocalPath, **kwargs) -> PagesConfig:
+  def parse_unknown_path(cls, path: pth.LocalPath, **kwargs) -> Self:
     # Make sure we get errors for invalid files.
     return cls.parse_config_path(path, **kwargs)
 
   @classmethod
-  def parse_other(cls, value: Any, **kwargs) -> PagesConfig:
+  def parse_other(cls, value: Any, **kwargs) -> Self:
     if isinstance(value, (list, tuple)):
       return cls.parse_sequence(value, **kwargs)
     return super().parse_other(value, **kwargs)
 
   @classmethod
-  def parse_sequence(cls, values: Sequence[str]) -> PagesConfig:
+  def parse_sequence(cls, values: Sequence[str]) -> Self:
     """
     Variant a): List of comma-separate URLs
       [ "URL,[DURATION]", ... ]
@@ -82,15 +91,17 @@ class PagesConfig(ConfigObject):
     # TODO: support parsing a list of PageConfig dicts
     if not values:
       raise argparse.ArgumentTypeError("Got empty page list.")
+    ObjectParser.non_empty_sequence(values, "page list")
     pages: List[PageConfig] = []
     for index, single_line_config in enumerate(values):
       with exception.annotate_argparsing(
           f"Parsing pages[{index}]: {repr(single_line_config)}"):
         pages.append(PageConfig.parse_str(single_line_config))
-    return PagesConfig(pages=tuple(pages))
+    return cls(pages=tuple(pages))
 
   @classmethod
-  def parse_dict(cls, config: Dict) -> PagesConfig:
+  @override
+  def parse_dict(cls, config: Dict, **kwargs) -> Self:
     """
     Variant a):
       { "pages": { "LABEL": PAGE_CONFIG }, "secrets": { ... } }
@@ -99,20 +110,19 @@ class PagesConfig(ConfigObject):
       if "pages" not in config:
         raise argparse.ArgumentTypeError(
             "Config does not provide a 'pages' dict.")
-      secrets: Optional[SecretsConfig] = None
+      secrets: Secrets | None = None
       if secrets_data := config.get("secrets"):
-        secrets = SecretsConfig.parse(secrets_data)
+        secrets = Secrets.parse(secrets_data)
       pages_config = ObjectParser.non_empty_dict(config["pages"], "pages")
       with exception.annotate_argparsing("Parsing config 'pages'"):
         pages = cls._parse_pages(pages_config, secrets)
-        return PagesConfig(pages, secrets)
+        return cls(pages, secrets)
     raise exception.UnreachableError()
 
   @classmethod
-  def _parse_pages(
-      cls,
-      data: Dict[str, Any],
-      secrets: Optional[SecretsConfig] = None) -> Tuple[PageConfig, ...]:
+  def _parse_pages(cls,
+                   data: Dict[str, Any],
+                   secrets: Optional[Secrets] = None) -> Tuple[PageConfig, ...]:
     pages = []
     for name, page_config in data.items():
       with exception.annotate_argparsing(f"Parsing story ...['{name}']"):
@@ -121,15 +131,22 @@ class PagesConfig(ConfigObject):
         pages.append(page)
     return tuple(pages)
 
+  def __eq__(self, value: object) -> bool:
+    if not isinstance(value, PagesConfig):
+      return False
+    return self.pages == value.pages and self.secrets == value.secrets
+
 
 class DevToolsRecorderPagesConfig(PagesConfig):
 
   @classmethod
-  def parse_str(cls: Type[PagesConfig], value: str) -> PagesConfig:
+  @override
+  def parse_str(cls, value: str) -> Self:
     raise NotImplementedError()
 
   @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> DevToolsRecorderPagesConfig:
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
     config = ObjectParser.non_empty_dict(config)
     with exception.annotate_argparsing("Loading DevTools recording file"):
       title = ObjectParser.non_empty_str(config["title"], "title")
@@ -137,7 +154,7 @@ class DevToolsRecorderPagesConfig(PagesConfig):
       # Use default block
       blocks = (ActionBlock(actions=actions),)
       pages = (PageConfig(label=title, blocks=blocks),)
-      return DevToolsRecorderPagesConfig(pages)
+      return cls(pages)
     raise exception.UnreachableError()
 
   @classmethod
@@ -176,16 +193,16 @@ class DevToolsRecorderPagesConfig(PagesConfig):
     selector = cls._parse_selectors(step["selectors"])
     return ClickAction(
         InputSource.JS,
-        selector=selector,
-        scroll_into_view=True,
+        position=PositionConfig.from_selector(
+            selector=selector, scroll_into_view=True),
         timeout=default_timeout)
 
   @classmethod
   def _parse_selectors(cls, selectors: List[List[str]]) -> str:
-    xpath: Optional[str] = None
-    aria: Optional[str] = None
-    text: Optional[str] = None
-    css: Optional[str] = None
+    xpath: str | None = None
+    aria: str | None = None
+    text: str | None = None
+    css: str | None = None
     # Detect all single-element selectors first.
     for selector_list in selectors:
       if len(selector_list) != 1:
@@ -227,12 +244,14 @@ class ListPagesConfig(PagesConfig):
   VALID_EXTENSIONS: Tuple[str, ...] = (".txt", ".list")
 
   @classmethod
-  def parse_str(cls, value: str) -> PagesConfig:
+  @override
+  def parse_str(cls, value: str) -> Self:
     raise argparse.ArgumentTypeError(
         f"URL list file {repr(value)} does not exist.")
 
   @classmethod
-  def parse_path(cls, path: pth.LocalPath, **kwargs) -> PagesConfig:
+  @override
+  def parse_path(cls, path: pth.LocalPath, **kwargs) -> Self:
     assert not kwargs, f"{cls.__name__} does not support extra kwargs"
     pages: List[PageConfig] = []
     with exception.annotate_argparsing(f"Loading Pages list file: {path.name}"):
@@ -246,10 +265,11 @@ class ListPagesConfig(PagesConfig):
               logging.warning("Skipping empty line %s", line)
               continue
             pages.append(PageConfig.parse(single_line_config))
-    return PagesConfig(pages=tuple(pages))
+    return cls(pages=tuple(pages))
 
   @classmethod
-  def parse_dict(cls, config: Dict) -> PagesConfig:
+  @override
+  def parse_dict(cls, config: Dict, **kwargs) -> Self:
     config = ObjectParser.non_empty_dict(config, "pages")
     with exception.annotate_argparsing("Parsing scenarios / pages"):
       if "pages" not in config:
diff --git a/crossbench/benchmarks/loading/loading_benchmark.py b/crossbench/benchmarks/loading/loading_benchmark.py
index 52c3c43e..61b771f8 100644
--- a/crossbench/benchmarks/loading/loading_benchmark.py
+++ b/crossbench/benchmarks/loading/loading_benchmark.py
@@ -6,11 +6,11 @@ from __future__ import annotations
 
 import argparse
 import datetime as dt
-import logging
 from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
                     Type)
 
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from typing_extensions import override
+
 from crossbench.action_runner.config import ActionRunnerConfig
 from crossbench.benchmarks.base import StoryFilter, SubStoryBenchmark
 from crossbench.benchmarks.loading.config.pages import (
@@ -49,6 +49,7 @@ class LoadingPageFilter(StoryFilter[Page]):
   stories: Sequence[Page]
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
     parser = super().add_cli_parser(parser)
@@ -158,6 +159,7 @@ class LoadingPageFilter(StoryFilter[Page]):
         "for more details.")
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["separate"] = args.separate
@@ -172,6 +174,7 @@ class LoadingPageFilter(StoryFilter[Page]):
     self._args: argparse.Namespace = args
     super().__init__(story_cls, patterns, separate)
 
+  @override
   def process_all(self, patterns: Sequence[str]) -> None:
     name_or_url_list = patterns
     if len(name_or_url_list) == 1:
@@ -203,8 +206,9 @@ class LoadingPageFilter(StoryFilter[Page]):
     for page_config in config.pages:
       stories.append(cls._story_from_config(args, page_config, use_labels))
 
-    if use_labels:
+    if not use_labels:
       # Double check that the urls are unique
+
       urls = set(page_config.first_url for page_config in config.pages)
       if len(urls) != len(config.pages):
         raise argparse.ArgumentTypeError(
@@ -233,20 +237,21 @@ class LoadingPageFilter(StoryFilter[Page]):
       return LivePage(label, config.first_url, duration, playback, tabs,
                       args.about_blank_duration)
     return InteractivePage(label, config.blocks, config.setup, config.login,
-                           config.secrets.as_dict(), playback, tabs,
+                           config.secrets, playback, tabs,
                            args.about_blank_duration, args.run_login,
                            args.run_setup)
 
+  @override
   def create_stories(self, separate: bool) -> Sequence[Page]:
-    logging.info("SELECTED STORIES: %s", str(list(map(str, self.stories))))
     if not separate and len(self.stories) > 1:
       combined_name = "_".join(page.name for page in self.stories)
       self.stories = (CombinedPage(self.stories, combined_name,
                                    self._args.playback, self._args.tabs),)
+    self.log_stories(self.stories)
     return self.stories
 
 
-class PageLoadBenchmark(SubStoryBenchmark):
+class LoadingBenchmark(SubStoryBenchmark):
   """
   Benchmark runner for loading pages.
 
@@ -266,16 +271,17 @@ class PageLoadBenchmark(SubStoryBenchmark):
   STORY_FILTER_CLS = LoadingPageFilter
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
   ) -> CrossBenchArgumentParser:
     parser = super().add_cli_parser(subparsers, aliases)
     cls.STORY_FILTER_CLS.add_cli_parser(parser)
-
     parser.add_argument(
         "--action-runner",
         type=ActionRunnerConfig.parse,
-        help="Set the action runner for interactive pages.")
+        help="Set the action runner for interactive pages.",
+        required=False)
     return parser
 
   @classmethod
@@ -283,6 +289,7 @@ class PageLoadBenchmark(SubStoryBenchmark):
     return args.separate
 
   @classmethod
+  @override
   def stories_from_cli_args(cls, args: argparse.Namespace) -> Sequence[Story]:
     has_default_stories: bool = args.stories and args.stories == "default"
     if config := cls.get_pages_config(args):
@@ -310,7 +317,11 @@ class PageLoadBenchmark(SubStoryBenchmark):
     return super().stories_from_cli_args(args)
 
   @classmethod
-  def get_pages_config(cls, args: argparse.Namespace) -> Optional[PagesConfig]:
+  def get_pages_config(cls,
+                       args: Optional[argparse.Namespace] = None
+                      ) -> Optional[PagesConfig]:
+    if not args:
+      raise ValueError("Missing args")
     if global_config := args.config:
       # TODO: migrate --config to an already parsed hjson/json dict
       config_file = global_config
@@ -326,27 +337,34 @@ class PageLoadBenchmark(SubStoryBenchmark):
     return args.pages_config
 
   @classmethod
+  @override
   def aliases(cls) -> Tuple[str, ...]:
     return ("load", "ld")
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["action_runner"] = args.action_runner
     return kwargs
 
   @classmethod
+  @override
   def all_story_names(cls) -> Sequence[str]:
     return sorted(LivePage.all_story_names())
 
   def __init__(self,
                stories: Sequence[Page],
                action_runner: Optional[ActionRunner] = None) -> None:
-    self._action_runner = action_runner or BasicActionRunner()
+    self._action_runner = action_runner
     for story in stories:
       assert isinstance(story, Page)
     super().__init__(stories)
 
   @property
-  def action_runner(self) -> ActionRunner:
+  def action_runner(self) -> Optional[ActionRunner]:
     return self._action_runner
+
+  @action_runner.setter
+  def action_runner(self, action_runner: Optional[ActionRunner]) -> None:
+    self._action_runner = action_runner
diff --git a/crossbench/benchmarks/loading/loadline_presets.py b/crossbench/benchmarks/loading/loadline_presets.py
index 4f335a4d..372e2c72 100644
--- a/crossbench/benchmarks/loading/loadline_presets.py
+++ b/crossbench/benchmarks/loading/loadline_presets.py
@@ -7,32 +7,33 @@ from __future__ import annotations
 import abc
 import argparse
 import logging
-from typing import TYPE_CHECKING, Optional, Sequence, Tuple
+from typing import TYPE_CHECKING, Optional, Sequence, Tuple, Type
 
 import numpy as np
 import pandas as pd
 from tabulate import tabulate
+from typing_extensions import override
 
 from crossbench import config
 from crossbench import path as pth
-from crossbench.benchmarks.base import BenchmarkProbeMixin
+from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
 from crossbench.benchmarks.loading.config.pages import PagesConfig
-from crossbench.benchmarks.loading.loading_benchmark import (LoadingPageFilter,
-                                                             PageLoadBenchmark)
+from crossbench.benchmarks.loading.loading_benchmark import (LoadingBenchmark,
+                                                             LoadingPageFilter)
 from crossbench.flags.base import Flags
 from crossbench.probes.perfetto.trace_processor.trace_processor import \
     TraceProcessorProbe
 from crossbench.probes.probe import Probe, ProbeContext
-from crossbench.probes.results import EmptyProbeResult, ProbeResult
+from crossbench.probes.results import LocalProbeResult
 
 if TYPE_CHECKING:
   from crossbench.benchmarks.loading.page.base import Page
   from crossbench.browsers.attributes import BrowserAttributes
+  from crossbench.probes.results import ProbeResult
   from crossbench.runner.groups.browsers import BrowsersRunGroup
-  from crossbench.runner.runner import Run
 
-CONFIG_DIR = config.config_dir()
-LOADLINE_DIR = CONFIG_DIR / "benchmark" / "loadline"
+CONFIG_DIR: pth.LocalPath = config.config_dir()
+LOADLINE_DIR: pth.LocalPath = CONFIG_DIR / "benchmark" / "loadline"
 
 # We should increase the minor version number every time there are any changes
 # that might affect the benchmark score.
@@ -48,10 +49,12 @@ class LoadLinePageFilter(LoadingPageFilter):
     pass
 
   @classmethod
+  @override
   def default_stories(cls) -> Tuple[Page, ...]:
     return cls.all_stories()
 
   @classmethod
+  @override
   def all_stories(cls) -> Tuple[Page, ...]:
     return ()
 
@@ -60,9 +63,11 @@ class LoadLineProbe(BenchmarkProbeMixin, Probe):
   IS_GENERAL_PURPOSE = False
   NAME = "loadline_probe"
 
-  def get_context(self, run: Run) -> Optional[LoadLineProbeContext]:
-    return LoadLineProbeContext(self, run)
+  @override
+  def get_context_cls(self,) -> Type[LoadLineProbeContext]:
+    return LoadLineProbeContext
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     logging.info("-" * 80)
     logging.critical("LoadLine Benchmark (%s)", VERSION_STRING)
@@ -75,14 +80,15 @@ class LoadLineProbe(BenchmarkProbeMixin, Probe):
             headers="keys",
             tablefmt="plain"))
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     csv_file = group.get_local_probe_result_path(self).with_suffix(".csv")
     self._compute_score(group).to_csv(csv_file)
-    return ProbeResult(csv=(csv_file,))
+    return LocalProbeResult(csv=(csv_file,))
 
   def _compute_score(self, group: BrowsersRunGroup) -> pd.DataFrame:
     all_results = group.results.get_by_name(TraceProcessorProbe.NAME).csv_list
-    loadline_result: Optional[pth.LocalPath] = None
+    loadline_result: pth.LocalPath | None = None
     for result in all_results:
       # Look for the "loadline/benchmark_score" trace processor query result.
       if result.name == "loadline_benchmark_score.csv":
@@ -109,23 +115,29 @@ class LoadLineProbeContext(ProbeContext[LoadLineProbe]):
   def start(self) -> None:
     pass
 
+  @override
   def start_story_run(self) -> None:
+    benchmark_type = ("loadline-phone" if "phone" in self.probe.benchmark.NAME
+                      else "loadline-tablet")
     self.browser.performance_mark(
-        f"LoadLine/{self.probe.benchmark.NAME}/{self.run.story.name}")
+        f"LoadLine/{benchmark_type}/{self.run.story.name}")
 
   def stop(self) -> None:
     pass
 
   def teardown(self) -> ProbeResult:
-    return EmptyProbeResult()
+    return self.empty_result()
 
 
-class LoadLineBenchmark(PageLoadBenchmark, metaclass=abc.ABCMeta):
+class LoadLineBenchmark(LoadingBenchmark, metaclass=abc.ABCMeta):
   STORY_FILTER_CLS = LoadLinePageFilter
   PROBES = (LoadLineProbe,)
   DEFAULT_REPETITIONS = 100
 
+  _page_config: PagesConfig | None = None
+
   @classmethod
+  @override
   def requires_separate(cls, args: argparse.Namespace) -> bool:
     # Perfetto metrics used in the benchmark require a separate Perfetto
     # session for each run.
@@ -137,6 +149,7 @@ class LoadLineBenchmark(PageLoadBenchmark, metaclass=abc.ABCMeta):
 
   @classmethod
   @abc.abstractmethod
+  @override
   def default_network_config_path(cls) -> pth.LocalPath:
     pass
 
@@ -146,51 +159,127 @@ class LoadLineBenchmark(PageLoadBenchmark, metaclass=abc.ABCMeta):
     pass
 
   @classmethod
+  @override
   def get_pages_config(
       cls, args: Optional[argparse.Namespace] = None) -> PagesConfig:
-    return PagesConfig.parse(cls.default_pages_config_path())
+    # Use manual caching, since args is not hashable.
+    if cls._page_config is None:
+      cls._page_config = PagesConfig.parse(cls.default_pages_config_path())
+    return cls._page_config
 
   @classmethod
+  @override
   def all_story_names(cls) -> Sequence[str]:
     return tuple(page.any_label for page in cls.get_pages_config().pages)
 
 
+class LoadLinePhoneBenchmark(LoadLineBenchmark):
+  """LoadLine benchmark for phones.
+  """
+  NAME = "loadline-phone"
+
+  @classmethod
+  @override
+  def default_pages_config_path(cls) -> pth.LocalPath:
+    return pth.LocalPath(LOADLINE_DIR) / "page_config_phone.hjson"
+
+  @classmethod
+  @override
+  def default_network_config_path(cls) -> pth.LocalPath:
+    return pth.LocalPath(LOADLINE_DIR) / "network_config_phone.hjson"
+
+  @classmethod
+  @override
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("loading-phone", "load-phone", "ld-phone")
+
+
 class LoadLineTabletBenchmark(LoadLineBenchmark):
-  """LoadLine benchmark for tablet.
+  """LoadLine benchmark for tablets.
   """
   NAME = "loadline-tablet"
 
   @classmethod
+  @override
   def default_pages_config_path(cls) -> pth.LocalPath:
     return pth.LocalPath(LOADLINE_DIR) / "page_config_tablet.hjson"
 
   @classmethod
+  @override
   def default_network_config_path(cls) -> pth.LocalPath:
     return pth.LocalPath(LOADLINE_DIR) / "network_config_tablet.hjson"
 
   @classmethod
+  @override
   def aliases(cls) -> Tuple[str, ...]:
     return ("loading-tablet", "load-tablet", "ld-tablet")
 
   @classmethod
+  @override
   def extra_flags(cls, browser_attributes: BrowserAttributes) -> Flags:
     assert browser_attributes.is_chromium_based
     return Flags(["--request-desktop-sites"])
 
 
-class LoadLinePhoneBenchmark(LoadLineBenchmark):
-  """LoadLine benchmark for phones.
+class LoadLinePhoneDebugBenchmark(LoadLinePhoneBenchmark):
+  """LoadLine benchmark for phones, with more tracing categories, for easier
+  performance analysis.
   """
-  NAME = "loadline-phone"
+  NAME = "loadline-phone-debug"
+  DEFAULT_REPETITIONS = 1
 
   @classmethod
-  def default_pages_config_path(cls) -> pth.LocalPath:
-    return pth.LocalPath(LOADLINE_DIR) / "page_config_phone.hjson"
+  @override
+  def default_probe_config_path(cls) -> pth.LocalPath:
+    return (pth.LocalPath(LOADLINE_DIR) /
+                "probe_config_experimental_lightweight.hjson")
 
   @classmethod
-  def default_network_config_path(cls) -> pth.LocalPath:
-    return pth.LocalPath(LOADLINE_DIR) / "network_config_phone.hjson"
+  @override
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("loading-phone-debug", "load-phone-debug", "ld-phone-debug")
+
+
+class LoadLineTabletDebugBenchmark(LoadLineTabletBenchmark):
+  """LoadLine benchmark for tablets, with more tracing categories, for easier
+  performance analysis.
+  """
+  NAME = "loadline-tablet-debug"
+  DEFAULT_REPETITIONS = 1
+
+  @classmethod
+  @override
+  def default_probe_config_path(cls) -> pth.LocalPath:
+    return (pth.LocalPath(LOADLINE_DIR) /
+                "probe_config_experimental_lightweight.hjson")
 
   @classmethod
+  @override
   def aliases(cls) -> Tuple[str, ...]:
-    return ("loading-phone", "load-phone", "ld-phone")
+    return ("loading-tablet-debug", "load-tablet-debug", "ld-tablet-debug")
+
+
+class LoadLinePhoneFastBenchmark(LoadLinePhoneBenchmark):
+  """LoadLine benchmark for phones, with less repetitions, for faster local
+  experiments.
+  """
+  NAME = "loadline-phone-fast"
+  DEFAULT_REPETITIONS = 10
+
+  @classmethod
+  @override
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("loading-phone-fast", "load-phone-fast", "ld-phone-fast")
+
+
+class LoadLineTabletFastBenchmark(LoadLineTabletBenchmark):
+  """LoadLine benchmark for tablets, with less repetitions, for faster local
+  experiments.
+  """
+  NAME = "loadline-tablet-fast"
+  DEFAULT_REPETITIONS = 10
+
+  @classmethod
+  @override
+  def aliases(cls) -> Tuple[str, ...]:
+    return ("loading-tablet-fast", "load-tablet-fast", "ld-tablet-fast")
diff --git a/crossbench/benchmarks/loading/page/base.py b/crossbench/benchmarks/loading/page/base.py
index 62e80bd4..246ae561 100644
--- a/crossbench/benchmarks/loading/page/base.py
+++ b/crossbench/benchmarks/loading/page/base.py
@@ -6,16 +6,24 @@ from __future__ import annotations
 
 import abc
 import datetime as dt
-from typing import TYPE_CHECKING, List, Tuple, cast
+from typing import TYPE_CHECKING, List, Optional, Tuple, cast
 
+from typing_extensions import override
+
+from crossbench.action_runner.android_input_action_runner import \
+    AndroidInputActionRunner
+from crossbench.action_runner.base import ActionRunner
+from crossbench.action_runner.chromeos_input_action_runner import \
+    ChromeOSInputActionRunner
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
 from crossbench.benchmarks.loading.playback_controller import \
     PlaybackController
 from crossbench.benchmarks.loading.tab_controller import TabController
 from crossbench.stories.story import Story
 
 if TYPE_CHECKING:
-  from crossbench.action_runner.base import ActionRunner
-  from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+  from crossbench.benchmarks.loading.loading_benchmark import LoadingBenchmark
+  from crossbench.cli.config.secrets import Secrets
   from crossbench.runner.run import Run
 
 DEFAULT_DURATION_SECONDS = 15
@@ -27,6 +35,7 @@ PAGE_LIST: List[Page] = []
 class Page(Story, metaclass=abc.ABCMeta):
 
   @classmethod
+  @override
   def all_story_names(cls) -> Tuple[str, ...]:
     assert PAGE_LIST, "Missing predefined page list"
     # TODO: move all story names magic to the dedicated StoryFilter.
@@ -38,11 +47,12 @@ class Page(Story, metaclass=abc.ABCMeta):
                duration: dt.timedelta = DEFAULT_DURATION,
                playback: PlaybackController = PlaybackController.default(),
                tabs: TabController = TabController.default(),
-               about_blank_duration: dt.timedelta = dt.timedelta()):
+               about_blank_duration: dt.timedelta = dt.timedelta(),
+               secrets: Optional[Secrets] = None) -> None:
     self._playback: PlaybackController = playback
     self._tabs: TabController = tabs
     self._about_blank_duration = about_blank_duration
-    super().__init__(name, duration)
+    super().__init__(name, duration, secrets)
 
   @property
   def about_blank_duration(self) -> dt.timedelta:
@@ -71,5 +81,16 @@ class Page(Story, metaclass=abc.ABCMeta):
 
 def get_action_runner(run: Run) -> ActionRunner:
   # TODO: make sure we have a single instance per Run
-  benchmark = cast("PageLoadBenchmark", run.benchmark)
+  benchmark = cast("LoadingBenchmark", run.benchmark)
+
+  if not benchmark.action_runner:
+    platform = run.browser.platform
+
+    if platform.is_android:
+      benchmark.action_runner = AndroidInputActionRunner()
+    elif platform.is_chromeos:
+      benchmark.action_runner = ChromeOSInputActionRunner()
+    else:
+      benchmark.action_runner = DefaultActionRunner()
+
   return benchmark.action_runner
diff --git a/crossbench/benchmarks/loading/page/combined.py b/crossbench/benchmarks/loading/page/combined.py
index dee19e22..9b40cc8e 100644
--- a/crossbench/benchmarks/loading/page/combined.py
+++ b/crossbench/benchmarks/loading/page/combined.py
@@ -5,7 +5,9 @@
 from __future__ import annotations
 
 import datetime as dt
-from typing import TYPE_CHECKING, Iterable
+from typing import TYPE_CHECKING, Iterable, Tuple
+
+from typing_extensions import override
 
 from crossbench.benchmarks.loading.page.base import Page, get_action_runner
 from crossbench.benchmarks.loading.playback_controller import \
@@ -20,12 +22,14 @@ if TYPE_CHECKING:
 
 class CombinedPage(Page):
 
-  def __init__(self,
-               pages: Iterable[Page],
-               name: str = "combined",
-               playback: PlaybackController = PlaybackController.default(),
-               tabs: TabController = TabController.default(),
-               about_blank_duration: dt.timedelta = dt.timedelta()):
+  def __init__(
+      self,
+      pages: Iterable[Page],
+      name: str = "combined",
+      playback: PlaybackController = PlaybackController.default(),
+      tabs: TabController = TabController.default(),
+      about_blank_duration: dt.timedelta = dt.timedelta()
+  ) -> None:
     self._pages = tuple(pages)
     assert self._pages, "No sub-pages provided for CombinedPage"
     assert len(self._pages) >= 1, "Combined Page needs at least one page"
@@ -39,6 +43,7 @@ class CombinedPage(Page):
     self.url = None
 
   @property
+  @override
   def tabs(self) -> TabController:
     return self._tabs
 
@@ -47,20 +52,34 @@ class CombinedPage(Page):
     return self._pages
 
   @property
+  @override
+  def substories(self) -> Tuple[str, ...]:
+    return tuple(
+        substory for page in self._pages for substory in page.substories)
+
+  @property
+  @override
   def first_url(self) -> str:
     return self._pages[0].first_url
 
+  @override
   def details_json(self) -> JsonDict:
     result = super().details_json()
     result["pages"] = list(page.details_json() for page in self._pages)
     return result
 
+  @override
+  def teardown(self, run: Run) -> None:
+    for page in self._pages:
+      page.teardown(run)
+
   def run(self, run: Run) -> None:
     action_runner = get_action_runner(run)
     multiple_tabs = self.tabs.multiple_tabs
     for _ in self._playback:
       action_runner.run_combined_page(run, self, multiple_tabs)
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner,
                multiple_tabs: bool) -> None:
     action_runner.run_combined_page(run, self, multiple_tabs)
diff --git a/crossbench/benchmarks/loading/page/interactive.py b/crossbench/benchmarks/loading/page/interactive.py
index 85f3f0cd..9599a506 100644
--- a/crossbench/benchmarks/loading/page/interactive.py
+++ b/crossbench/benchmarks/loading/page/interactive.py
@@ -8,7 +8,7 @@ import datetime as dt
 import logging
 from typing import TYPE_CHECKING, Optional, Tuple, cast
 
-from immutabledict import immutabledict
+from typing_extensions import override
 
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.get import GetAction
@@ -21,7 +21,7 @@ if TYPE_CHECKING:
   from crossbench.action_runner.base import ActionRunner
   from crossbench.benchmarks.loading.config.blocks import ActionBlock
   from crossbench.benchmarks.loading.config.login.custom import LoginBlock
-  from crossbench.cli.config.secrets import SecretsDict
+  from crossbench.cli.config.secrets import Secrets
   from crossbench.runner.run import Run
   from crossbench.types import JsonDict
 
@@ -33,12 +33,12 @@ class InteractivePage(Page):
                blocks: Tuple[ActionBlock, ...],
                setup: Optional[ActionBlock] = None,
                login: Optional[LoginBlock] = None,
-               secrets: Optional[SecretsDict] = None,
+               secrets: Optional[Secrets] = None,
                playback: PlaybackController = PlaybackController.default(),
                tabs: TabController = TabController.default(),
                about_blank_duration: dt.timedelta = dt.timedelta(),
                run_login: bool = True,
-               run_setup: bool = True):
+               run_setup: bool = True) -> None:
     assert name, "missing name"
     self._name: str = name
     assert isinstance(blocks, tuple)
@@ -48,11 +48,11 @@ class InteractivePage(Page):
         "No login blocks allowed as normal action block")
     self._setup_block = setup
     self._login_block = login
-    self._secrets: SecretsDict = secrets or immutabledict()
     self._run_login = run_login
     self._run_setup = run_setup
     duration = self._get_duration()
-    super().__init__(self._name, duration, playback, tabs, about_blank_duration)
+    super().__init__(self._name, duration, playback, tabs, about_blank_duration,
+                     secrets)
 
   @property
   def login_block(self) -> Optional[ActionBlock]:
@@ -67,10 +67,7 @@ class InteractivePage(Page):
     return self._blocks
 
   @property
-  def secrets(self) -> SecretsDict:
-    return self._secrets
-
-  @property
+  @override
   def first_url(self) -> str:
     for block in self.blocks:
       for action in block:
@@ -83,7 +80,7 @@ class InteractivePage(Page):
                                message: str = "failure") -> None:
     action_runner = get_action_runner(run)
     try:
-      action_runner.screenshot_impl(run, message)
+      action_runner.failure_screenshot(run, message)
     except Exception as e:  # pylint: disable=broad-except
       logging.error("Failed to take a failure screenshot: %s", str(e))
 
@@ -92,6 +89,7 @@ class InteractivePage(Page):
     except Exception as e:  # pylint: disable=broad-except
       logging.error("Failed to dump HTML on failure: %s", str(e))
 
+  @override
   def setup(self, run: Run) -> None:
     action_runner = get_action_runner(run)
     if self._run_login and (login_block := self.login_block):
@@ -99,16 +97,23 @@ class InteractivePage(Page):
     if self._run_setup and (setup_block := self.setup_block):
       action_runner.run_setup(run, self, setup_block)
 
+  @override
+  def teardown(self, run: Run) -> None:
+    action_runner = get_action_runner(run)
+    action_runner.teardown(run)
+
   def run(self, run: Run) -> None:
     action_runner = get_action_runner(run)
     multiple_tabs = self.tabs.multiple_tabs
     for _ in self._playback:
       action_runner.run_interactive_page(run, self, multiple_tabs)
 
+  @override
   def run_with(self, run: Run, action_runner: ActionRunner,
                multiple_tabs: bool) -> None:
     action_runner.run_interactive_page(run, self, multiple_tabs)
 
+  @override
   def details_json(self) -> JsonDict:
     result = super().details_json()
     result["actions"] = list(block.to_json() for block in self._blocks)
diff --git a/crossbench/benchmarks/loading/page/live.py b/crossbench/benchmarks/loading/page/live.py
index 72c36b4f..f66ed7f1 100644
--- a/crossbench/benchmarks/loading/page/live.py
+++ b/crossbench/benchmarks/loading/page/live.py
@@ -7,6 +7,8 @@ from __future__ import annotations
 import datetime as dt
 from typing import TYPE_CHECKING, Dict, Tuple
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.get import GetAction
 from crossbench.benchmarks.loading.config.blocks import ActionBlock
 from crossbench.benchmarks.loading.page.base import DEFAULT_DURATION, PAGE_LIST
@@ -22,6 +24,7 @@ if TYPE_CHECKING:
 class LivePage(InteractivePage):
 
   @classmethod
+  @override
   def all_story_names(cls) -> Tuple[str, ...]:
     return tuple(page.name for page in PAGE_LIST)
 
@@ -44,12 +47,14 @@ class LivePage(InteractivePage):
         tabs=tabs,
         about_blank_duration=about_blank_duration)
 
+  @override
   def details_json(self) -> JsonDict:
     result = super().details_json()
     result["url"] = str(self.url)
     return result
 
   @property
+  @override
   def first_url(self) -> str:
     return self.url
 
@@ -92,5 +97,5 @@ assert not PAGE_LIST, "PAGE_LIST was already initialized."
 PAGE_LIST.extend(LIVE_PAGES)
 
 PAGES: Dict[str, LivePage] = {page.name: page for page in LIVE_PAGES}
-PAGE_LIST_SMALL = (PAGES["facebook"], PAGES["maps"], PAGES["timesofindia"],
-                   PAGES["cnn"])
+PAGE_LIST_SMALL: Tuple[LivePage, ...] = (PAGES["facebook"], PAGES["maps"],
+                                         PAGES["timesofindia"], PAGES["cnn"])
diff --git a/crossbench/benchmarks/loading/playback_controller.py b/crossbench/benchmarks/loading/playback_controller.py
index 6552cf20..44092b70 100644
--- a/crossbench/benchmarks/loading/playback_controller.py
+++ b/crossbench/benchmarks/loading/playback_controller.py
@@ -70,17 +70,18 @@ class TimeoutPlaybackController(PlaybackController):
 
   def __iter__(self) -> Iterator[None]:
     end = dt.datetime.now() + self.duration
-    while True:
+    yield None
+    if not self.duration:
+      return
+    while dt.datetime.now() <= end:
       yield None
-      if dt.datetime.now() > end:
-        return
 
 
 @dataclasses.dataclass(frozen=True)
 class RepeatPlaybackController(PlaybackController):
   count : int
 
-  def __post_init__(self):
+  def __post_init__(self) -> None:
     NumberParser.positive_int(self.count, " page playback count")
 
   def __iter__(self) -> Iterator[None]:
diff --git a/crossbench/benchmarks/loading/tab_controller.py b/crossbench/benchmarks/loading/tab_controller.py
index 4aee2ba4..3a6c8e28 100644
--- a/crossbench/benchmarks/loading/tab_controller.py
+++ b/crossbench/benchmarks/loading/tab_controller.py
@@ -6,7 +6,9 @@ from __future__ import annotations
 
 import abc
 import dataclasses
-from typing import Any, Dict, Iterator
+from typing import Iterator
+
+from typing_extensions import override
 
 from crossbench.config import ConfigObject
 from crossbench.parse import NumberParser
@@ -17,10 +19,7 @@ class TabController(ConfigObject):
   is_forever: bool
 
   @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> TabController:
-    raise NotImplementedError("Cannot create tab controller from dict")
-
-  @classmethod
+  @override
   def parse_str(cls, value: str) -> TabController:
     if not value or value == "single":
       return cls.single()
diff --git a/crossbench/benchmarks/manual/manual_benchmark.py b/crossbench/benchmarks/manual/manual_benchmark.py
index 23e06711..c911e8a8 100644
--- a/crossbench/benchmarks/manual/manual_benchmark.py
+++ b/crossbench/benchmarks/manual/manual_benchmark.py
@@ -9,9 +9,11 @@ import datetime as dt
 import logging
 from typing import TYPE_CHECKING, Any, Dict, Optional, Sequence, Tuple
 
-from crossbench import helper
+from typing_extensions import override
+
 from crossbench.benchmarks.base import Benchmark
 from crossbench.cli.ui import timer
+from crossbench.helper import input_helper
 from crossbench.parse import DurationParser
 from crossbench.stories.story import Story
 
@@ -27,13 +29,14 @@ class ManualStory(Story, metaclass=abc.ABCMeta):
   STORY_NAME = "manual"
 
   def __init__(self, start_after: Optional[dt.timedelta],
-               run_for: Optional[dt.timedelta]):
+               run_for: Optional[dt.timedelta]) -> None:
     self._start_after = start_after
     self._run_for = run_for
     duration = ((start_after or dt.timedelta()) +
                 (run_for or dt.timedelta(seconds=30)))
     super().__init__(self.STORY_NAME, duration)
 
+  @override
   def setup(self, run: Run) -> None:
     if self._start_after is None:
       logging.info("-" * 80)
@@ -44,7 +47,7 @@ class ManualStory(Story, metaclass=abc.ABCMeta):
       logging.critical(
           "The browser has launched. Measurement will start in %s" +
           " (or press enter to start immediately)", self._start_after)
-      helper.input_with_timeout(timeout=self._start_after)
+      input_helper.input_with_timeout(timeout=self._start_after)
     logging.info("Starting Manual Benchmark...")
 
   def run(self, run: Run) -> None:
@@ -66,10 +69,11 @@ class ManualStory(Story, metaclass=abc.ABCMeta):
       logging.critical(
           "Measurement has started. The browser will close in %s" +
           " (or press enter to close immediately)", self._run_for)
-      helper.input_with_timeout(timeout=self._run_for)
+      input_helper.input_with_timeout(timeout=self._run_for)
 
 
   @classmethod
+  @override
   def all_story_names(cls) -> Tuple[str, ...]:
     return (ManualStory.STORY_NAME,)
 
@@ -90,6 +94,7 @@ class ManualBenchmark(Benchmark, metaclass=abc.ABCMeta):
     super().__init__([ManualStory(start_after=start_after, run_for=run_for)])
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
   ) -> CrossBenchArgumentParser:
@@ -97,18 +102,17 @@ class ManualBenchmark(Benchmark, metaclass=abc.ABCMeta):
     parser.add_argument(
         "--start-after",
         help="How long to wait until measurement starts",
-        required=False,
         type=DurationParser.positive_or_zero_duration)
     parser.add_argument(
         "--run-for",
         "--stop-after",
         "--duration",
         help="How long to run measurement for",
-        required=False,
         type=DurationParser.positive_duration)
     return parser
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["start_after"] = args.start_after
diff --git a/crossbench/benchmarks/memory/memory_benchmark.py b/crossbench/benchmarks/memory/memory_benchmark.py
index 227b594a..cb36a801 100644
--- a/crossbench/benchmarks/memory/memory_benchmark.py
+++ b/crossbench/benchmarks/memory/memory_benchmark.py
@@ -11,16 +11,17 @@ from typing import TYPE_CHECKING, Any, Dict, Optional, Sequence, Tuple, Type
 
 import selenium.common.exceptions
 import urllib3.exceptions
+from typing_extensions import override
 
-from crossbench import helper
 from crossbench.action_runner.action_runner_listener import \
     ActionRunnerListener
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
-from crossbench.benchmarks.base import (BenchmarkProbeMixin, StoryFilter,
-                                        SubStoryBenchmark)
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
+from crossbench.benchmarks.base import StoryFilter, SubStoryBenchmark
+from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
 from crossbench.benchmarks.loading.page.base import Page
 from crossbench.benchmarks.loading.page.live import LivePage
 from crossbench.benchmarks.loading.tab_controller import TabController
+from crossbench.helper import url_helper
 from crossbench.parse import NumberParser
 from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
 from crossbench.probes.metric import MetricsMerger
@@ -37,6 +38,7 @@ if TYPE_CHECKING:
   from crossbench.runner.groups.browsers import BrowsersRunGroup
   from crossbench.runner.groups.stories import StoriesRunGroup
   from crossbench.runner.run import Run
+  from crossbench.types import JsonDict
 
 
 class MemoryProbe(BenchmarkProbeMixin, JsonResultProbe):
@@ -46,16 +48,19 @@ class MemoryProbe(BenchmarkProbeMixin, JsonResultProbe):
   """
   NAME: str = "memory_probe"
 
-  def get_context(self, run: Run) -> MemoryProbeContext:
-    return MemoryProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[MemoryProbeContext]:
+    return MemoryProbeContext
 
-  def to_json(self, actions: Actions) -> Dict[str, float]:
+  def to_json(self, actions: Actions) -> JsonDict:
     raise NotImplementedError(
         "should not be called, data comes from memory probe context")
 
+  @override
   def log_run_result(self, run: Run) -> None:
     self._log_result(run.results, single_result=True)
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     self._log_result(group.results, single_result=False)
 
@@ -78,12 +83,14 @@ class MemoryProbe(BenchmarkProbeMixin, JsonResultProbe):
       else:
         self._log_result_metrics(data)
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     merged = MetricsMerger.merge_json_list(
         repetitions_group.results[self].json
         for repetitions_group in group.repetitions_groups)
     return self.write_group_result(group, merged)
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     return self.merge_browsers_json_list(group).merge(
         self.merge_browsers_csv_list(group))
@@ -99,6 +106,9 @@ class MemoryProbeContext(ActionRunnerListener,
       raise TypeError("The probe only works for MemoryBenchmark")
     cur_benchmark.action_runner.set_listener(self)
     self._skippable_tab_count = cur_benchmark._skippable_tab_count
+    self._target_tab_count = cur_benchmark.get_target_tab_count()
+    self._intensive_tab_switch_count = \
+      cur_benchmark.get_intensive_tab_switch_count()
     # Records the navigation_start_time time for each window handle.
     self._navigation_time_ms: Dict[str, float] = {}
     self._tab_count: int = 1
@@ -106,10 +116,11 @@ class MemoryProbeContext(ActionRunnerListener,
   def start(self) -> None:
     pass
 
-  def to_json(self, actions: Actions) -> Dict[str, int]:
+  @override
+  def to_json(self, actions: Actions) -> JsonDict:
     return {"alive_tab_count": self._tab_count - 1}
 
-  def _increment_tab_count(self):
+  def _increment_tab_count(self) -> None:
     self._tab_count += 1
 
   def _record_navigation_time(self, run: Run) -> None:
@@ -144,7 +155,7 @@ class MemoryProbeContext(ActionRunnerListener,
               "is: %s ", run.browser, self._tab_count - 1)
           raise StopStoryException("Found a page that has been reloaded.")
 
-  def _check_error_msg(self, e: Exception):
+  def _check_error_msg(self, e: Exception) -> bool:
     if isinstance(e, selenium.common.exceptions.WebDriverException
                  ) and "page crash" in str(e):
       return True
@@ -157,6 +168,7 @@ class MemoryProbeContext(ActionRunnerListener,
       return True
     return False
 
+  @override
   def handle_error(self, run: Run, e: Exception) -> None:
     """
     If there is a page crash error or a http request time out
@@ -169,14 +181,45 @@ class MemoryProbeContext(ActionRunnerListener,
           "is: %s ", run.browser, self._tab_count - 1)
       raise StopStoryException(f"Found a Tab Crash/Timeout: {e}")
 
+  @override
   def handle_page_run(self, run: Run) -> None:
     self._record_navigation_time(run)
     if self._tab_count > self._skippable_tab_count:
       self._check_liveness(run)
+    # Conduct intensive tab switch between the target num of tabs.
+    if self._intensive_tab_switch_count > 0 \
+      and self._tab_count == self._target_tab_count:
+      self._intensive_tab_switch(run)
+      self._collect_tab_switch_metric(run)
 
+  @override
   def handle_new_tab(self, run: Run) -> None:
     self._increment_tab_count()
 
+  def _intensive_tab_switch(self, run: Run) -> None:
+    cur_tab_switch_count = 0
+    with run.actions("Intensive Tab Switching", measure=False) as action:
+      while cur_tab_switch_count < self._intensive_tab_switch_count:
+        for handle, _ in self._navigation_time_ms.items():
+          cur_tab_switch_count += 1
+          logging.debug(
+              "Browser: %s. Switching to handle: %s. "
+              "Current tab switch count: %s", run.browser, handle,
+              cur_tab_switch_count)
+          action.switch_window(handle)
+          action.wait(2)
+
+  def _collect_tab_switch_metric(self, run: Run) -> None:
+    with run.actions("Collect Tab Switch Metric", measure=False) as action:
+      browser = run.browser
+      browser.switch_to_new_tab()
+      switch_duration_histogram = \
+        "chrome://histograms/#Browser.Tabs.TotalSwitchDuration3"
+      browser.show_url(switch_duration_histogram)
+      content = action.js(
+          "let content = document.documentElement.innerText; return content;")
+      logging.info("TabSwitchDuration Metrics: %s", content)
+
 
 class MemoryBenchmarkStoryFilter(StoryFilter[Page]):
   """
@@ -189,6 +232,7 @@ class MemoryBenchmarkStoryFilter(StoryFilter[Page]):
   URL = "https://chromium-workloads.web.app/web-tests/main/synthetic/memory"
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
     parser = super().add_cli_parser(parser)
@@ -249,6 +293,7 @@ class MemoryBenchmarkStoryFilter(StoryFilter[Page]):
     return parser
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["args"] = args
@@ -263,6 +308,7 @@ class MemoryBenchmarkStoryFilter(StoryFilter[Page]):
 
     super().__init__(story_cls, patterns, separate)
 
+  @override
   def process_all(self, patterns: Sequence[str]) -> None:
     self.stories = self.stories_from_cli_args(self._args)
 
@@ -276,14 +322,15 @@ class MemoryBenchmarkStoryFilter(StoryFilter[Page]):
     }
     if not args.random_per_page:
       url_params["randomperpage"] = "false"
-    url = helper.update_url_query(cls.URL, url_params)
+    url = url_helper.update_url_query(cls.URL, url_params)
     stories: Sequence[Page] = []
     page = LivePage("memory", url, dt.timedelta(seconds=2), tabs=args.tabs)
     stories = [page]
     return stories
 
+  @override
   def create_stories(self, separate: bool) -> Sequence[Page]:
-    logging.info("SELECTED STORIES: %s", ", ".join(map(str, self.stories)))
+    self.log_stories(self.stories)
     return self.stories
 
 
@@ -298,6 +345,7 @@ class MemoryBenchmark(SubStoryBenchmark):
   PROBES: Tuple[Type[MemoryProbe], ...] = (MemoryProbe,)
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
   ) -> CrossBenchArgumentParser:
@@ -308,35 +356,56 @@ class MemoryBenchmark(SubStoryBenchmark):
         type=NumberParser.positive_int,
         default=0,
         help="The number of tabs that can be skipped for liveness checking.")
+    parser.add_argument(
+        "--intensive-tab-switch-count",
+        type=NumberParser.positive_int,
+        default=0,
+        help="The num of tab switch for stress testing.")
     return parser
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["skippable_tab_count"] = args.skippable_tab_count
+    kwargs["target_tab_count"] = args.tabs.count
+    kwargs["intensive_tab_switch_count"] = args.intensive_tab_switch_count
     return kwargs
 
   @classmethod
+  @override
   def stories_from_cli_args(cls, args: argparse.Namespace) -> Sequence[Page]:
     super().stories_from_cli_args(args)
     stories = MemoryBenchmarkStoryFilter.stories_from_cli_args(args)
     return stories
 
   @classmethod
+  @override
   def all_story_names(cls) -> Tuple[str, ...]:
     return ()
 
   def __init__(self,
                stories: Sequence[Page],
                skippable_tab_count: int = 0,
+               target_tab_count: int = 0,
+               intensive_tab_switch_count: int = 0,
                action_runner: Optional[ActionRunner] = None) -> None:
-    self._action_runner = action_runner or BasicActionRunner()
+    self._action_runner = action_runner or DefaultActionRunner()
     for story in stories:
       assert isinstance(story, Page)
     super().__init__(stories)
     self._skippable_tab_count = skippable_tab_count
+    self._target_tab_count = target_tab_count
+    self._intensive_tab_switch_count = intensive_tab_switch_count
+
+  def get_target_tab_count(self) -> int:
+    return self._target_tab_count
+
+  def get_intensive_tab_switch_count(self) -> int:
+    return self._intensive_tab_switch_count
 
   @classmethod
+  @override
   def describe(cls) -> Dict[str, Any]:
     data = super().describe()
     data["url"] = cls.STORY_FILTER_CLS.URL
diff --git a/crossbench/benchmarks/motionmark/__init__.py b/crossbench/benchmarks/motionmark/__init__.py
index 16bcedeb..10809d7c 100644
--- a/crossbench/benchmarks/motionmark/__init__.py
+++ b/crossbench/benchmarks/motionmark/__init__.py
@@ -12,9 +12,14 @@ from crossbench.benchmarks.motionmark.motionmark_1_2 import \
     MotionMark12Benchmark
 from crossbench.benchmarks.motionmark.motionmark_1_3 import \
     MotionMark13Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_3_1 import \
+    MotionMark131Benchmark
+from crossbench.benchmarks.motionmark.motionmark_main import \
+    MotionMarkMainBenchmark
 
 benchmark_classes = (MotionMark10Benchmark, MotionMark11Benchmark,
-                     MotionMark12Benchmark, MotionMark13Benchmark)
+                     MotionMark12Benchmark, MotionMark13Benchmark,
+                     MotionMark131Benchmark, MotionMarkMainBenchmark)
 
 _versions = set()
 for benchmark_cls in benchmark_classes:
diff --git a/crossbench/benchmarks/motionmark/base.py b/crossbench/benchmarks/motionmark/base.py
index 2b7d7afc..b0d232c7 100644
--- a/crossbench/benchmarks/motionmark/base.py
+++ b/crossbench/benchmarks/motionmark/base.py
@@ -4,15 +4,18 @@
 
 from __future__ import annotations
 
-from crossbench.benchmarks.base import PressBenchmark
+from typing_extensions import override
 
+from crossbench.benchmarks.base import PressBenchmark
 
 class MotionMarkBenchmark(PressBenchmark):
 
   @classmethod
+  @override
   def short_base_name(cls) -> str:
     return "mm"
 
   @classmethod
+  @override
   def base_name(cls) -> str:
     return "motionmark"
diff --git a/crossbench/benchmarks/motionmark/motionmark_1.py b/crossbench/benchmarks/motionmark/motionmark_1.py
index d547047a..8915b3ab 100644
--- a/crossbench/benchmarks/motionmark/motionmark_1.py
+++ b/crossbench/benchmarks/motionmark/motionmark_1.py
@@ -9,13 +9,15 @@ import datetime as dt
 import itertools
 import json
 import logging
-from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Type
 
-from crossbench.benchmarks.base import BenchmarkProbeMixin
+from typing_extensions import override
+
+from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
 from crossbench.benchmarks.motionmark.base import MotionMarkBenchmark
-from crossbench.helper import update_url_query
+from crossbench.helper import url_helper
 from crossbench.probes.helper import Flatten
-from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
 from crossbench.probes.metric import Metric, MetricsMerger
 from crossbench.probes.results import ProbeResult, ProbeResultDict
 from crossbench.stories.press_benchmark import PressBenchmarkStory
@@ -43,31 +45,29 @@ class MotionMark1Probe(BenchmarkProbeMixin, JsonResultProbe, abc.ABC):
   MotionMark-specific Probe.
   Extracts all MotionMark times and scores.
   """
-  JS = """
-    return window.benchmarkRunnerClient.results.results;
-  """
-
-  def to_json(self, actions: Actions) -> Json:
-    return actions.js(self.JS)
 
-  def flatten_json_data(self, json_data: List) -> Json:
-    assert isinstance(json_data, list) and len(json_data) == 1, (
-        "Motion12MarkProbe requires a results list.")
-    return Flatten(json_data[0], key_fn=_clean_up_path_segments).data
+  @abc.abstractmethod
+  @override
+  def get_context_cls(self) -> Type[MotionMark1ProbeContext]:
+    pass
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     merged = MetricsMerger.merge_json_list(
         story_group.results[self].json
         for story_group in group.repetitions_groups)
     return self.write_group_result(group, merged)
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     return self.merge_browsers_json_list(group).merge(
         self.merge_browsers_csv_list(group))
 
+  @override
   def log_run_result(self, run: Run) -> None:
     self._log_result(run.results, single_result=True)
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     self._log_result(group.results, single_result=False)
 
@@ -90,6 +90,7 @@ class MotionMark1Probe(BenchmarkProbeMixin, JsonResultProbe, abc.ABC):
       else:
         self._log_result_metrics(data)
 
+  @override
   def _extract_result_metrics_table(self, metrics: Dict[str, Any],
                                     table: Dict[str, List[str]]) -> None:
     for metric_key, metric in metrics.items():
@@ -107,6 +108,22 @@ class MotionMark1Probe(BenchmarkProbeMixin, JsonResultProbe, abc.ABC):
     return len(parts) == 2 or parts[-1] == "score"
 
 
+class MotionMark1ProbeContext(JsonResultProbeContext):
+  JS = """
+    return window.benchmarkRunnerClient.results.results;
+  """
+
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    return actions.js(self.JS)
+
+  @override
+  def flatten_json_data(self, json_data: List) -> Json:
+    assert isinstance(json_data, list) and len(json_data) == 1, (
+        "Motion12MarkProbe requires a results list.")
+    return Flatten(json_data[0], key_fn=_clean_up_path_segments).data
+
+
 class MotionMark1Story(PressBenchmarkStory):
   URL_LOCAL: str = "http://localhost:8000/"
   ALL_STORIES = {
@@ -210,10 +227,12 @@ class MotionMark1Story(PressBenchmarkStory):
   READY_JS: str = "return true;"
 
   @classmethod
+  @override
   def default_story_names(cls) -> Tuple[str, ...]:
     return cls.ALL_STORIES["MotionMark"]
 
   @property
+  @override
   def substory_duration(self) -> dt.timedelta:
     return dt.timedelta(seconds=35)
 
@@ -223,11 +242,13 @@ class MotionMark1Story(PressBenchmarkStory):
 
   def prepare_test_url(self) -> str:
     if (url_params := self.url_params) or not self.has_default_substories:
-      updated_url = update_url_query(f"{self.url}/developer.html", url_params)
+      updated_url = url_helper.update_url_query(f"{self.url}/developer.html",
+                                                url_params)
       logging.info("CUSTOM URL: %s", updated_url)
       return updated_url
     return self.url
 
+  @override
   def setup(self, run: Run) -> None:
     test_url = self.prepare_test_url()
     use_developer_url = test_url != self.url
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_0.py b/crossbench/benchmarks/motionmark/motionmark_1_0.py
index f244ee13..414a862a 100644
--- a/crossbench/benchmarks/motionmark/motionmark_1_0.py
+++ b/crossbench/benchmarks/motionmark/motionmark_1_0.py
@@ -4,17 +4,29 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Type
 
-from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
-                                                           MotionMark1Probe,
-                                                           MotionMark1Story)
+from typing_extensions import override
 
+from crossbench.benchmarks.motionmark.motionmark_1 import (
+    MotionMark1Benchmark, MotionMark1Probe, MotionMark1ProbeContext,
+    MotionMark1Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class MotionMark10Probe(MotionMark1Probe):
   __doc__ = MotionMark1Probe.__doc__
   NAME = "motionmark_1.0"
 
+  @override
+  def get_context_cls(self) -> Type[MotionMark10ProbeContext]:
+    return MotionMark10ProbeContext
+
+
+class MotionMark10ProbeContext(MotionMark1ProbeContext):
+  pass
+
 
 class MotionMark10Story(MotionMark1Story):
   NAME = "motionmark_1.0"
@@ -34,5 +46,6 @@ class MotionMark10Benchmark(MotionMark1Benchmark):
   PROBES = (MotionMark10Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (1, 0)
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_1.py b/crossbench/benchmarks/motionmark/motionmark_1_1.py
index a7beff9b..acac96ac 100644
--- a/crossbench/benchmarks/motionmark/motionmark_1_1.py
+++ b/crossbench/benchmarks/motionmark/motionmark_1_1.py
@@ -4,17 +4,29 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Type
 
-from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
-                                                           MotionMark1Probe,
-                                                           MotionMark1Story)
+from typing_extensions import override
 
+from crossbench.benchmarks.motionmark.motionmark_1 import (
+    MotionMark1Benchmark, MotionMark1Probe, MotionMark1ProbeContext,
+    MotionMark1Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class MotionMark11Probe(MotionMark1Probe):
   __doc__ = MotionMark1Probe.__doc__
   NAME = "motionmark_1.1"
 
+  @override
+  def get_context_cls(self) -> Type[MotionMark11ProbeContext]:
+    return MotionMark11ProbeContext
+
+
+class MotionMark11ProbeContext(MotionMark1ProbeContext):
+  pass
+
 
 class MotionMark11Story(MotionMark1Story):
   NAME = "motionmark_1.1"
@@ -34,5 +46,6 @@ class MotionMark11Benchmark(MotionMark1Benchmark):
   PROBES = (MotionMark11Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (1, 1)
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_2.py b/crossbench/benchmarks/motionmark/motionmark_1_2.py
index da80803d..7d644cdf 100644
--- a/crossbench/benchmarks/motionmark/motionmark_1_2.py
+++ b/crossbench/benchmarks/motionmark/motionmark_1_2.py
@@ -4,17 +4,29 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Type
 
-from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
-                                                           MotionMark1Probe,
-                                                           MotionMark1Story)
+from typing_extensions import override
 
+from crossbench.benchmarks.motionmark.motionmark_1 import (
+    MotionMark1Benchmark, MotionMark1Probe, MotionMark1ProbeContext,
+    MotionMark1Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class MotionMark12Probe(MotionMark1Probe):
   __doc__ = MotionMark1Probe.__doc__
   NAME = "motionmark_1.2"
 
+  @override
+  def get_context_cls(self) -> Type[MotionMark12ProbeContext]:
+    return MotionMark12ProbeContext
+
+
+class MotionMark12ProbeContext(MotionMark1ProbeContext):
+  pass
+
 
 class MotionMark12Story(MotionMark1Story):
   NAME = "motionmark_1.2"
@@ -34,5 +46,6 @@ class MotionMark12Benchmark(MotionMark1Benchmark):
   PROBES = (MotionMark12Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (1, 2)
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_3.py b/crossbench/benchmarks/motionmark/motionmark_1_3.py
index 6428343f..8d3b60bd 100644
--- a/crossbench/benchmarks/motionmark/motionmark_1_3.py
+++ b/crossbench/benchmarks/motionmark/motionmark_1_3.py
@@ -5,17 +5,29 @@
 from __future__ import annotations
 
 import datetime as dt
-from typing import Tuple
+from typing import TYPE_CHECKING, Type
 
-from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
-                                                           MotionMark1Probe,
-                                                           MotionMark1Story)
+from typing_extensions import override
 
+from crossbench.benchmarks.motionmark.motionmark_1 import (
+    MotionMark1Benchmark, MotionMark1Probe, MotionMark1ProbeContext,
+    MotionMark1Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class MotionMark13Probe(MotionMark1Probe):
   __doc__ = MotionMark1Probe.__doc__
   NAME = "motionmark_1.3"
 
+  @override
+  def get_context_cls(self) -> Type[MotionMark13ProbeContext]:
+    return MotionMark13ProbeContext
+
+
+class MotionMark13ProbeContext(MotionMark1ProbeContext):
+  pass
+
 
 class MotionMark13Story(MotionMark1Story):
   NAME = "motionmark_1.3"
@@ -41,5 +53,6 @@ class MotionMark13Benchmark(MotionMark1Benchmark):
   PROBES = (MotionMark13Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
-    return (1, 3)
+  @override
+  def version(cls) -> VersionParts:
+    return (1, 3, 0)
diff --git a/crossbench/benchmarks/motionmark/motionmark_1_3_1.py b/crossbench/benchmarks/motionmark/motionmark_1_3_1.py
new file mode 100644
index 00000000..5681449d
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/motionmark_1_3_1.py
@@ -0,0 +1,59 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (
+    MotionMark1Benchmark, MotionMark1Probe, MotionMark1ProbeContext,
+    MotionMark1Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
+
+
+class MotionMark131Probe(MotionMark1Probe):
+  __doc__ = MotionMark1Probe.__doc__
+  NAME = "motionmark_1.3.1"
+
+  @override
+  def get_context_cls(self) -> Type[MotionMark131ProbeContext]:
+    return MotionMark131ProbeContext
+
+
+class MotionMark131ProbeContext(MotionMark1ProbeContext):
+  pass
+
+
+class MotionMark131Story(MotionMark1Story):
+  NAME = "motionmark_1.3.1"
+  URL: str = "https://chromium-workloads.web.app/motionmark/v1.3.1/MotionMark/"
+  URL_OFFICIAL: str = "https://browserbench.org/MotionMark1.3.1/"
+  READY_TIMEOUT: dt.timedelta = dt.timedelta(seconds=12)
+  DEVELOPER_READY_JS: str = (
+      "return !(document.querySelector('#frame-rate-detection span'));")
+  READY_JS: str = (
+      "return !!("
+      "   document.querySelector('#frame-rate-label')?.textContent?.trim());")
+
+
+class MotionMark131Benchmark(MotionMark1Benchmark):
+  """
+  Benchmark runner for MotionMark 1.3.1.
+
+  See https://browserbench.org/MotionMark1.3.1/ for more details.
+  """
+
+  NAME = "motionmark_1.3.1"
+  DEFAULT_STORY_CLS = MotionMark131Story
+  PROBES = (MotionMark131Probe,)
+
+  @classmethod
+  @override
+  def version(cls) -> VersionParts:
+    return (1, 3, 1)
diff --git a/crossbench/benchmarks/motionmark/motionmark_main.py b/crossbench/benchmarks/motionmark/motionmark_main.py
new file mode 100644
index 00000000..b8084a05
--- /dev/null
+++ b/crossbench/benchmarks/motionmark/motionmark_main.py
@@ -0,0 +1,59 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (
+    MotionMark1Benchmark, MotionMark1Probe, MotionMark1ProbeContext,
+    MotionMark1Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
+
+
+class MotionMarkMainProbe(MotionMark1Probe):
+  __doc__ = MotionMark1Probe.__doc__
+  NAME = "motionmark_main"
+
+  @override
+  def get_context_cls(self) -> Type[MotionMarkMainProbeContext]:
+    return MotionMarkMainProbeContext
+
+
+class MotionMarkMainProbeContext(MotionMark1ProbeContext):
+  pass
+
+
+class MotionMarkMainStory(MotionMark1Story):
+  NAME = "motionmark_main"
+  URL: str = "https://chromium-workloads.web.app/motionmark/main/MotionMark/"
+  URL_OFFICIAL: str = "https://chromium-workloads.web.app/motionmark/main/MotionMark/"
+  READY_TIMEOUT: dt.timedelta = dt.timedelta(seconds=12)
+  DEVELOPER_READY_JS: str = (
+      "return !(document.querySelector('#frame-rate-detection span'));")
+  READY_JS: str = (
+      "return !!("
+      "   document.querySelector('#frame-rate-label')?.textContent?.trim());")
+
+
+class MotionMarkMainBenchmark(MotionMark1Benchmark):
+  """
+  Benchmark runner for MotionMark main.
+
+  See https://browserbench.org/MotionMarkmain/ for more details.
+  """
+
+  NAME = "motionmark_main"
+  DEFAULT_STORY_CLS = MotionMarkMainStory
+  PROBES = (MotionMarkMainProbe,)
+
+  @classmethod
+  @override
+  def version(cls) -> VersionParts:
+    return ("main",)
diff --git a/crossbench/benchmarks/speedometer/__init__.py b/crossbench/benchmarks/speedometer/__init__.py
index 90688c35..0234d992 100644
--- a/crossbench/benchmarks/speedometer/__init__.py
+++ b/crossbench/benchmarks/speedometer/__init__.py
@@ -4,16 +4,22 @@
 
 from __future__ import annotations
 
+from typing import Final
+
 from crossbench.benchmarks.speedometer.speedometer_2_0 import \
     Speedometer20Benchmark
 from crossbench.benchmarks.speedometer.speedometer_2_1 import \
     Speedometer21Benchmark
 from crossbench.benchmarks.speedometer.speedometer_3_0 import \
     Speedometer30Benchmark
+from crossbench.benchmarks.speedometer.speedometer_3_1 import \
+    Speedometer31Benchmark
+from crossbench.benchmarks.speedometer.speedometer_main import \
+    SpeedometerMainBenchmark
 
-benchmark_classes = [
-    Speedometer20Benchmark, Speedometer21Benchmark, Speedometer30Benchmark
-]
+benchmark_classes: Final = (Speedometer20Benchmark, Speedometer21Benchmark,
+                            Speedometer30Benchmark, Speedometer31Benchmark,
+                            SpeedometerMainBenchmark)
 
 _versions = set()
 for benchmark_cls in benchmark_classes:
diff --git a/crossbench/benchmarks/speedometer/speedometer.py b/crossbench/benchmarks/speedometer/speedometer.py
index 8359aec9..582538fd 100644
--- a/crossbench/benchmarks/speedometer/speedometer.py
+++ b/crossbench/benchmarks/speedometer/speedometer.py
@@ -8,15 +8,18 @@ import abc
 import datetime as dt
 import json
 import logging
-from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
-                    Type)
+from typing import (TYPE_CHECKING, Any, Dict, Final, List, Optional, Sequence,
+                    Tuple, Type)
 
-from crossbench import helper
-from crossbench.benchmarks.base import (BenchmarkProbeMixin, PressBenchmark,
+from typing_extensions import override
+
+from crossbench.benchmarks.base import (PressBenchmark,
                                         PressBenchmarkStoryFilter)
-from crossbench.parse import NumberParser
+from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
+from crossbench.helper import url_helper
+from crossbench.parse import NumberParser, ObjectParser
 from crossbench.probes.helper import Flatten
-from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
 from crossbench.probes.metric import Metric, MetricsMerger
 from crossbench.probes.results import ProbeResult, ProbeResultDict
 from crossbench.stories.press_benchmark import PressBenchmarkStory
@@ -42,33 +45,44 @@ class SpeedometerProbe(
   Speedometer-specific probe (compatible with v2.X and v3.X).
   Extracts all speedometer times and scores.
   """
-  JS: str = "return window.suiteValues;"
   SORT_KEYS: bool = False
+  SCORE_METRIC_KEY: Final[str] = "Score"
 
-  def to_json(self, actions: Actions) -> Json:
-    return actions.js(self.JS)
-
-  def flatten_json_data(self, json_data: Any) -> Json:
-    # json_data may contain multiple iterations, merge those first
-    assert isinstance(json_data, list), f"Expected list got {type(json_data)}"
-    merged = MetricsMerger(
-        json_data, key_fn=_probe_remove_tests_segments).to_json(
-            value_fn=lambda values: values.geomean, sort=self.SORT_KEYS)
-    return Flatten(merged, sort=self.SORT_KEYS).data
+  @abc.abstractmethod
+  @override
+  def get_context_cls(self) -> Type[SpeedometerProbeContext]:
+    pass
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     merged = MetricsMerger.merge_json_list(
         repetitions_group.results[self].json
         for repetitions_group in group.repetitions_groups)
+    if self.SCORE_METRIC_KEY not in merged.data:
+      merged.data[self.SCORE_METRIC_KEY] = self._compute_total_score(merged)
     return self.write_group_result(group, merged)
 
+  def _compute_total_score(self, merged: MetricsMerger) -> Metric:
+    line_item_scores: List[List[float]] = []
+    for key, metric in merged.data.items():
+      if self._is_valid_metric_key(key):
+        line_item_scores.append(metric.values)
+    total_score = Metric()
+    for iteration_line_items_score_values in zip(*line_item_scores):
+      iteration_score = Metric(iteration_line_items_score_values).geomean
+      total_score.append(iteration_score)
+    return total_score
+
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     return self.merge_browsers_json_list(group).merge(
         self.merge_browsers_csv_list(group))
 
+  @override
   def log_run_result(self, run: Run) -> None:
     self._log_result(run.results, single_result=True)
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     self._log_result(group.results, single_result=False)
 
@@ -91,6 +105,7 @@ class SpeedometerProbe(
       else:
         self._log_result_metrics(data)
 
+  @override
   def _extract_result_metrics_table(self, metrics: Dict[str, Any],
                                     table: Dict[str, List[str]]) -> None:
     for metric_key, metric in metrics.items():
@@ -104,6 +119,25 @@ class SpeedometerProbe(
     pass
 
 
+class SpeedometerProbeContext(JsonResultProbeContext):
+  JS = "return JSON.stringify(window.suiteValues);"
+
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    # Use serialized json as transport format to preserve object key order.
+    json_payload = actions.js(self.JS)
+    return json.loads(json_payload)
+
+  @override
+  def flatten_json_data(self, json_data: Any) -> Json:
+    # json_data may contain multiple iterations, merge those first
+    json_data = ObjectParser.non_empty_sequence(json_data,
+                                                f"{self.probe.name} metrics")
+    merged = MetricsMerger(
+        json_data, key_fn=_probe_remove_tests_segments).to_json(
+            value_fn=lambda values: values.geomean, sort=self.probe.SORT_KEYS)
+    return Flatten(merged, sort=self.probe.SORT_KEYS).data
+
 
 class SpeedometerStory(PressBenchmarkStory, metaclass=abc.ABCMeta):
   URL_LOCAL: str = "http://localhost:8000/"
@@ -112,9 +146,11 @@ class SpeedometerStory(PressBenchmarkStory, metaclass=abc.ABCMeta):
   def __init__(self,
                substories: Sequence[str] = (),
                iterations: Optional[int] = None,
-               url: Optional[str] = None):
-    self._iterations: int = iterations or self.DEFAULT_ITERATIONS
-    assert self.iterations >= 1, f"Invalid iterations count: '{iterations}'."
+               url: Optional[str] = None) -> None:
+    self._iterations: int = NumberParser.positive_int(
+        iterations or self.DEFAULT_ITERATIONS,
+        "iteration count",
+        parse_str=False)
     super().__init__(url=url, substories=substories)
 
   @property
@@ -122,6 +158,7 @@ class SpeedometerStory(PressBenchmarkStory, metaclass=abc.ABCMeta):
     return self._iterations
 
   @property
+  @override
   def substory_duration(self) -> dt.timedelta:
     return self.iterations * self.single_substory_duration
 
@@ -130,6 +167,7 @@ class SpeedometerStory(PressBenchmarkStory, metaclass=abc.ABCMeta):
     return dt.timedelta(seconds=0.4)
 
   @property
+  @override
   def slow_duration(self) -> dt.timedelta:
     """Max duration that covers run-times on slow machines and/or
     debug-mode browsers.
@@ -140,10 +178,13 @@ class SpeedometerStory(PressBenchmarkStory, metaclass=abc.ABCMeta):
 
   @property
   def url_params(self) -> Dict[str, str]:
-    if self.iterations == self.DEFAULT_ITERATIONS:
-      return {}
-    return {"iterationCount": str(self.iterations)}
+    params: Dict[str, str] = {}
+    if self.iterations != self.DEFAULT_ITERATIONS:
+      params["iterationCount"] = str(self.iterations)
+    return params
+
 
+  @override
   def setup(self, run: Run) -> None:
     updated_url = self.get_run_url(run)
     with run.actions("Setup") as actions:
@@ -153,9 +194,10 @@ class SpeedometerStory(PressBenchmarkStory, metaclass=abc.ABCMeta):
       self._setup_benchmark_client(actions)
       actions.wait(0.5)
 
+  @override
   def get_run_url(self, run: Run) -> str:
     url = super().get_run_url(run)
-    url = helper.update_url_query(url, self.url_params)
+    url = url_helper.update_url_query(url, self.url_params)
     if url != self.url:
       logging.info("CUSTOM URL: %s", url)
     return url
@@ -218,6 +260,7 @@ class SpeedometerBenchmarkStoryFilter(PressBenchmarkStoryFilter):
   __doc__ = PressBenchmarkStoryFilter.__doc__
 
   @classmethod
+  @override
   def add_cli_parser(
       cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
     parser = super().add_cli_parser(parser)
@@ -234,6 +277,7 @@ class SpeedometerBenchmarkStoryFilter(PressBenchmarkStoryFilter):
     return parser
 
   @classmethod
+  @override
   def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
     kwargs = super().kwargs_from_cli(args)
     kwargs["iterations"] = args.iterations
@@ -244,11 +288,12 @@ class SpeedometerBenchmarkStoryFilter(PressBenchmarkStoryFilter):
                patterns: Sequence[str],
                separate: bool = False,
                url: Optional[str] = None,
-               iterations: Optional[int] = None):
+               iterations: Optional[int] = None) -> None:
     self.iterations = iterations
     assert issubclass(story_cls, SpeedometerStory)
     super().__init__(story_cls, patterns, separate, url)
 
+  @override
   def create_stories_from_names(self, names: List[str],
                                 separate: bool) -> Sequence[SpeedometerStory]:
     return self.story_cls.from_names(
@@ -261,9 +306,11 @@ class SpeedometerBenchmark(PressBenchmark, metaclass=abc.ABCMeta):
   STORY_FILTER_CLS = SpeedometerBenchmarkStoryFilter
 
   @classmethod
+  @override
   def short_base_name(cls) -> str:
     return "sp"
 
   @classmethod
+  @override
   def base_name(cls) -> str:
     return "speedometer"
diff --git a/crossbench/benchmarks/speedometer/speedometer_2.py b/crossbench/benchmarks/speedometer/speedometer_2.py
index 3610fefb..bbbce97f 100644
--- a/crossbench/benchmarks/speedometer/speedometer_2.py
+++ b/crossbench/benchmarks/speedometer/speedometer_2.py
@@ -4,19 +4,19 @@
 
 from __future__ import annotations
 
-import logging
-from typing import TYPE_CHECKING, Any, Tuple
+from typing import Any, Dict, Tuple
 
-from crossbench import helper
-from crossbench.benchmarks.speedometer.speedometer import (SpeedometerProbe,
-                                                           SpeedometerStory)
+from typing_extensions import override
 
-if TYPE_CHECKING:
-  from crossbench.runner.run import Run
+from crossbench.benchmarks.speedometer.speedometer import (
+    SpeedometerProbe, SpeedometerProbeContext, SpeedometerStory)
+from crossbench.helper import url_helper
+from crossbench.parse import ObjectParser
 
 
 class Speedometer2Probe(SpeedometerProbe):
 
+  @override
   def _is_valid_metric_key(self, metric_key: str) -> bool:
     parts = metric_key.split("/")
     if len(parts) == 2:
@@ -25,9 +25,16 @@ class Speedometer2Probe(SpeedometerProbe):
       return parts[0] in ("Geomean", "Score")
     return parts[-1] == "total"
 
+
+class Speedometer2ProbeContext(SpeedometerProbeContext):
+
+  @override
   def process_json_data(self, json_data) -> Any:
+    json_data = ObjectParser.non_empty_sequence(json_data,
+                                                f"{self.probe.name} metrics")
     # Move aggregate scores to the end
     for iteration_data in json_data:
+      assert isinstance(iteration_data, dict)
       iteration_data["Mean"] = iteration_data.pop("mean")
       iteration_data["Total"] = iteration_data.pop("total")
       iteration_data["Geomean"] = iteration_data.pop("geomean")
@@ -56,11 +63,12 @@ class Speedometer2Story(SpeedometerStory):
       "Flight-TodoMVC",
   )
 
-  def log_run_test_url(self, run: Run) -> None:
+  @property
+  def test_url(self) -> str:
     test_url = f"{self.URL}/InteractiveRunner.html"
-    params = self.url_params
+    params: Dict[str, str] = self.url_params
     if len(self.substories) == 1:
       params["suite"] = self.substories[0]
     params["startAutomatically"] = "true"
-    official_test_url = helper.update_url_query(test_url, params)
-    logging.info("STORY PUBLIC TEST URL: %s", official_test_url)
+    official_test_url = url_helper.update_url_query(test_url, params)
+    return official_test_url
diff --git a/crossbench/benchmarks/speedometer/speedometer_2_0.py b/crossbench/benchmarks/speedometer/speedometer_2_0.py
index 4a6c2208..06c66512 100644
--- a/crossbench/benchmarks/speedometer/speedometer_2_0.py
+++ b/crossbench/benchmarks/speedometer/speedometer_2_0.py
@@ -4,17 +4,29 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
 
 from crossbench.benchmarks.speedometer.speedometer import (ProbeClsTupleT,
                                                            SpeedometerBenchmark)
-from crossbench.benchmarks.speedometer.speedometer_2 import (Speedometer2Probe,
-                                                             Speedometer2Story)
+from crossbench.benchmarks.speedometer.speedometer_2 import (
+    Speedometer2Probe, Speedometer2ProbeContext, Speedometer2Story)
 
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class Speedometer20Probe(Speedometer2Probe):
   NAME: str = "speedometer_2.0"
 
+  @override
+  def get_context_cls(self) -> Type[Speedometer20ProbeContext]:
+    return Speedometer20ProbeContext
+
+
+class Speedometer20ProbeContext(Speedometer2ProbeContext):
+  pass
+
 
 class Speedometer20Story(Speedometer2Story):
   NAME: str = "speedometer_2.0"
@@ -31,5 +43,6 @@ class Speedometer20Benchmark(SpeedometerBenchmark):
   PROBES: ProbeClsTupleT = (Speedometer20Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (2, 0)
diff --git a/crossbench/benchmarks/speedometer/speedometer_2_1.py b/crossbench/benchmarks/speedometer/speedometer_2_1.py
index fbf4c98d..6346d0ea 100644
--- a/crossbench/benchmarks/speedometer/speedometer_2_1.py
+++ b/crossbench/benchmarks/speedometer/speedometer_2_1.py
@@ -4,17 +4,30 @@
 
 from __future__ import annotations
 
-from typing import Tuple
+from typing import TYPE_CHECKING, Tuple, Type
+
+from typing_extensions import override
 
 from crossbench.benchmarks.speedometer.speedometer import (ProbeClsTupleT,
                                                            SpeedometerBenchmark)
-from crossbench.benchmarks.speedometer.speedometer_2 import (Speedometer2Probe,
-                                                             Speedometer2Story)
+from crossbench.benchmarks.speedometer.speedometer_2 import (
+    Speedometer2Probe, Speedometer2ProbeContext, Speedometer2Story)
 
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
 
 class Speedometer21Probe(Speedometer2Probe):
   NAME: str = "speedometer_2.1"
 
+  @override
+  def get_context_cls(self) -> Type[Speedometer21ProbeContext]:
+    return Speedometer21ProbeContext
+
+
+class Speedometer21ProbeContext(Speedometer2ProbeContext):
+  pass
+
+
 
 class Speedometer21Story(Speedometer2Story):
   NAME: str = "speedometer_2.1"
@@ -31,9 +44,11 @@ class Speedometer21Benchmark(SpeedometerBenchmark):
   PROBES: ProbeClsTupleT = (Speedometer21Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (2, 1)
 
   @classmethod
+  @override
   def aliases(cls) -> Tuple[str, ...]:
     return ("sp", "speedometer", "sp2", "speedometer2") + super().aliases()
diff --git a/crossbench/benchmarks/speedometer/speedometer_3.py b/crossbench/benchmarks/speedometer/speedometer_3.py
new file mode 100644
index 00000000..eee5ccbf
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer_3.py
@@ -0,0 +1,451 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+import datetime as dt
+import enum
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
+                    Type, cast)
+
+from typing_extensions import override
+
+from crossbench.benchmarks.speedometer.speedometer import (
+    SpeedometerBenchmark, SpeedometerBenchmarkStoryFilter, SpeedometerProbe,
+    SpeedometerProbeContext, SpeedometerStory)
+from crossbench.browsers import viewport as vp
+from crossbench.helper import url_helper
+from crossbench.parse import DurationParser, NumberParser, ObjectParser
+from crossbench.stories.story import Story
+from crossbench.str_enum_with_help import StrEnumWithHelp
+
+if TYPE_CHECKING:
+  from crossbench.cli.parser import CrossBenchArgumentParser
+  from crossbench.runner.actions import Actions
+  from crossbench.types import Json
+
+  ShuffleSeedT = str | int | None
+
+
+class Speedometer3Probe(SpeedometerProbe, metaclass=abc.ABCMeta):
+  """
+  Speedometer3-specific probe (compatible with v3 benchmarks).
+  Extracts all speedometer times and scores.
+  """
+
+  @property
+  def speedometer(self) -> Speedometer3Benchmark:
+    return cast(Speedometer3Benchmark, self.benchmark)
+
+  @override
+  def _is_valid_metric_key(self, metric_key: str) -> bool:
+    parts = metric_key.split("/")
+    if len(parts) != 1:
+      return False
+    if self.speedometer.detailed_metrics:
+      return True
+    if metric_key.startswith("Iteration-"):
+      return False
+    if metric_key == "Geomean":
+      return False
+    return True
+
+
+class Speedometer3ProbeContext(SpeedometerProbeContext, metaclass=abc.ABCMeta):
+  JS = "return JSON.stringify(window.benchmarkClient.metrics);"
+
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    json_data = super().to_json(actions)
+    return ObjectParser.non_empty_dict(json_data, "speedometer metrics")
+
+  @override
+  def flatten_json_data(self, json_data: Any) -> Json:
+    result: Dict[str, float] = {}
+    assert isinstance(json_data, dict), f"Expected dict, got {type(json_data)}"
+    for name, metric in json_data.items():
+      result[name] = metric["mean"]
+    return result
+
+
+@enum.unique
+class MeasurementMethod(StrEnumWithHelp):
+  RAF = ("raf", "requestAnimationFrame-based measurement")
+  TIMER = ("timer", "setTimeout-based measurement")
+
+
+def to_ms(duration: dt.timedelta) -> int:
+  return int(round(duration.total_seconds() * 1000))
+
+
+def parse_shuffle_seed(value: Optional[Any]) -> ShuffleSeedT:
+  if value in (None, "off", "generate"):
+    return value
+  if isinstance(value, int):
+    return value
+  return NumberParser.any_int(value, "shuffle-seed")
+
+
+# Generated by running this JS snippet and updating the bools:
+#  JSON.stringify(
+#    Suites.reduce((data, e) => {
+#        data[e.name]={ tags:e.tags, enabled:!e.disabled};
+#        return data}, {}))
+#  .replaceAll(":true", ":True")
+#  .replaceAll(":false", ":False");
+SPEEDOMETER_3_STORY_DATA = {
+    "TodoMVC-JavaScript-ES5": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-JavaScript-ES5-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-JavaScript-ES6-Webpack": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-JavaScript-ES6-Webpack-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-WebComponents": {
+        "tags": ["all", "default", "todomvc", "webcomponents"],
+        "enabled": True
+    },
+    "TodoMVC-WebComponents-Complex-DOM": {
+        "tags": ["all", "todomvc", "webcomponents", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-React": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-React-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-React-Redux": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-React-Redux-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-Backbone": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-Backbone-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-Angular": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-Angular-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-Vue": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-Vue-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex", "complex-default"],
+        "enabled": False
+    },
+    "TodoMVC-jQuery": {
+        "tags": ["all", "default", "todomvc"],
+        "enabled": True
+    },
+    "TodoMVC-jQuery-Complex-DOM": {
+        "tags": ["all", "todomvc", "complex"],
+        "enabled": False
+    },
+    "TodoMVC-Preact": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-Preact-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-Svelte": {
+        "tags": ["all", "todomvc"],
+        "enabled": False
+    },
+    "TodoMVC-Svelte-Complex-DOM": {
+        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
+        "enabled": True
+    },
+    "TodoMVC-Lit": {
+        "tags": ["all", "todomvc", "webcomponents"],
+        "enabled": False
+    },
+    "TodoMVC-Lit-Complex-DOM": {
+        "tags": [
+            "all", "default", "todomvc", "webcomponents", "complex",
+            "complex-default"
+        ],
+        "enabled": True
+    },
+    "NewsSite-Next": {
+        "tags": ["all", "default", "newssite", "language"],
+        "enabled": True
+    },
+    "NewsSite-Nuxt": {
+        "tags": ["all", "default", "newssite"],
+        "enabled": True
+    },
+    "Editor-CodeMirror": {
+        "tags": ["all", "default", "editor"],
+        "enabled": True
+    },
+    "Editor-TipTap": {
+        "tags": ["all", "default", "editor"],
+        "enabled": True
+    },
+    "Charts-observable-plot": {
+        "tags": ["all", "default", "chart"],
+        "enabled": True
+    },
+    "Charts-chartjs": {
+        "tags": ["all", "default", "chart"],
+        "enabled": True
+    },
+    "React-Stockcharts-SVG": {
+        "tags": ["all", "default", "chart", "svg"],
+        "enabled": True
+    },
+    "Perf-Dashboard": {
+        "tags": ["all", "default", "chart", "webcomponents"],
+        "enabled": True
+    }
+}
+
+
+class Speedometer3Story(SpeedometerStory, metaclass=abc.ABCMeta):
+  __doc__ = SpeedometerStory.__doc__
+  URL_LOCAL: str = "http://127.0.0.1:8080"
+  SUBSTORIES: Tuple[str, ...] = tuple(SPEEDOMETER_3_STORY_DATA.keys())
+
+  @classmethod
+  @override
+  def default_story_names(cls) -> Tuple[str, ...]:
+    return tuple(
+        tuple(name for name, data in SPEEDOMETER_3_STORY_DATA.items()
+              if data["enabled"]))
+
+  def __init__(self,
+               substories: Sequence[str] = (),
+               iterations: Optional[int] = None,
+               sync_wait: Optional[dt.timedelta] = None,
+               sync_warmup: Optional[dt.timedelta] = None,
+               measurement_method: Optional[MeasurementMethod] = None,
+               viewport: Optional[vp.Viewport] = None,
+               shuffle_seed: ShuffleSeedT = None,
+               url: Optional[str] = None) -> None:
+    self._sync_wait = DurationParser.positive_or_zero_duration(
+        sync_wait or dt.timedelta(0), "sync_wait")
+    self._sync_warmup = DurationParser.positive_or_zero_duration(
+        sync_warmup or dt.timedelta(0), "sync_warmup")
+    self._measurement_method: MeasurementMethod = (
+        measurement_method or MeasurementMethod.RAF)
+    self._viewport = None
+    if viewport:
+      self._viewport = vp.Viewport.parse_sized(viewport)
+    self._shuffle_seed: ShuffleSeedT = parse_shuffle_seed(shuffle_seed)
+    super().__init__(url=url, substories=substories, iterations=iterations)
+
+  @property
+  @override
+  def single_substory_duration(self) -> dt.timedelta:
+    return dt.timedelta(seconds=0.25)
+
+  @property
+  def sync_wait(self) -> dt.timedelta:
+    return self._sync_wait
+
+  @property
+  def sync_warmup(self) -> dt.timedelta:
+    return self._sync_warmup
+
+  @property
+  def measurement_method(self) -> MeasurementMethod:
+    return self._measurement_method
+
+  @property
+  def viewport(self) -> Optional[vp.Viewport]:
+    return self._viewport
+
+  @property
+  def shuffle_seed(self) -> ShuffleSeedT:
+    return self._shuffle_seed
+
+  @property
+  @override
+  def url_params(self) -> Dict[str, str]:
+    url_params: Dict[str, str] = super().url_params
+    if sync_wait := self.sync_wait:
+      url_params["waitBeforeSync"] = str(to_ms(sync_wait))
+    if sync_warmup := self.sync_warmup:
+      url_params["warmupBeforeSync"] = str(to_ms(sync_warmup))
+    if self.measurement_method != MeasurementMethod.RAF:
+      url_params["measurementMethod"] = str(self.measurement_method)
+    if viewport := self.viewport:
+      url_params["viewport"] = f"{viewport.width}x{viewport.height}"
+    if self.shuffle_seed is not None:
+      url_params["shuffleSeed"] = str(self.shuffle_seed)
+    if tuple(self.substories) != self.default_story_names():
+      url_params["suites"] = ",".join(self.substories)
+    return url_params
+
+  @property
+  def test_url(self) -> str:
+    params: Dict[str, str] = self.url_params
+    params["developerMode"] = "true"
+    params["startAutomatically"] = "true"
+    official_test_url = url_helper.update_url_query(self.URL, params)
+    return official_test_url
+
+
+class Speedometer3BenchmarkStoryFilter(SpeedometerBenchmarkStoryFilter):
+  __doc__ = SpeedometerBenchmarkStoryFilter.__doc__
+
+  @classmethod
+  @override
+  def add_cli_parser(
+      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
+    parser = super().add_cli_parser(parser)
+    parser.add_argument(
+        "--sync-wait",
+        default=dt.timedelta(0),
+        type=DurationParser.positive_or_zero_duration,
+        help="Add a custom wait timeout before each sync step.")
+    parser.add_argument(
+        "--sync-warmup",
+        default=dt.timedelta(0),
+        type=DurationParser.positive_or_zero_duration,
+        help="Run a warmup loop for the given duration before each sync step.")
+
+    measurement_method_group = parser.add_argument_group(
+        "Measurement Method Option")
+    measurement_method_group = parser.add_mutually_exclusive_group()
+    measurement_method_group.add_argument(
+        "--raf",
+        dest="measurement_method",
+        default=MeasurementMethod.RAF,
+        const=MeasurementMethod.RAF,
+        action="store_const",
+        help=("Use the default requestAnimationFrame-based approach "
+              "for async time measurement."))
+    measurement_method_group.add_argument(
+        "--timer",
+        dest="measurement_method",
+        const=MeasurementMethod.TIMER,
+        action="store_const",
+        help=("Use the 'classical' setTimeout-based approach "
+              "for async time measurement. "
+              "This might omit measuring some async work."))
+
+    parser.add_argument(
+        "--story-viewport",
+        type=vp.Viewport.parse_sized,
+        help="Specify the speedometer workload viewport size.")
+    parser.add_argument(
+        "--shuffle-seed",
+        type=parse_shuffle_seed,
+        help=("Set a shuffle seed to run the stories in a"
+              "non-default order."))
+    return parser
+
+  @classmethod
+  @override
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["iterations"] = args.iterations
+    kwargs["measurement_method"] = args.measurement_method
+    kwargs["sync_wait"] = args.sync_wait
+    kwargs["sync_warmup"] = args.sync_warmup
+    kwargs["viewport"] = args.story_viewport
+    kwargs["shuffle_seed"] = args.shuffle_seed
+    return kwargs
+
+  def __init__(self,
+               story_cls: Type[SpeedometerStory],
+               patterns: Sequence[str],
+               separate: bool = False,
+               url: Optional[str] = None,
+               iterations: Optional[int] = None,
+               measurement_method: Optional[MeasurementMethod] = None,
+               sync_wait: Optional[dt.timedelta] = None,
+               sync_warmup: Optional[dt.timedelta] = None,
+               viewport: Optional[vp.Viewport] = None,
+               shuffle_seed: ShuffleSeedT = None) -> None:
+    self.measurement_method = measurement_method
+    self.sync_wait = sync_wait
+    self.sync_warmup = sync_warmup
+    self.viewport = viewport
+    self.shuffle_seed: ShuffleSeedT = shuffle_seed
+    assert issubclass(story_cls, Speedometer3Story)
+    super().__init__(story_cls, patterns, separate, url, iterations=iterations)
+
+  @override
+  def create_stories_from_names(self, names: List[str],
+                                separate: bool) -> Sequence[SpeedometerStory]:
+    return self.story_cls.from_names(
+        names,
+        separate=separate,
+        url=self.url,
+        iterations=self.iterations,
+        measurement_method=self.measurement_method,
+        sync_wait=self.sync_wait,
+        sync_warmup=self.sync_warmup,
+        viewport=self.viewport,
+        shuffle_seed=self.shuffle_seed)
+
+
+class Speedometer3Benchmark(SpeedometerBenchmark, metaclass=abc.ABCMeta):
+  """
+  Abstract benchmark runner for Speedometer 3.
+  """
+  STORY_FILTER_CLS = Speedometer3BenchmarkStoryFilter
+
+  @classmethod
+  @override
+  def add_cli_parser(
+      cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
+  ) -> CrossBenchArgumentParser:
+    parser = super().add_cli_parser(subparsers, aliases)
+    parser.add_argument(
+        "--detailed-metrics",
+        "--details",
+        default=False,
+        action="store_true",
+        help="Report more detailed internal metrics.")
+    return parser
+
+  @classmethod
+  @override
+  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
+    kwargs = super().kwargs_from_cli(args)
+    kwargs["detailed_metrics"] = args.detailed_metrics
+    return kwargs
+
+  def __init__(self,
+               stories: Sequence[Story],
+               custom_url: Optional[str] = None,
+               detailed_metrics: bool = False) -> None:
+    self._detailed_metrics = detailed_metrics
+    super().__init__(stories, custom_url)
+
+  @property
+  def detailed_metrics(self) -> bool:
+    return self._detailed_metrics
diff --git a/crossbench/benchmarks/speedometer/speedometer_3_0.py b/crossbench/benchmarks/speedometer/speedometer_3_0.py
index cfc4bccb..59a6a3d4 100644
--- a/crossbench/benchmarks/speedometer/speedometer_3_0.py
+++ b/crossbench/benchmarks/speedometer/speedometer_3_0.py
@@ -1,458 +1,59 @@
-# Copyright 2023 The Chromium Authors
+# Copyright 2025 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
 from __future__ import annotations
 
-import argparse
-import datetime as dt
-import enum
-import logging
-from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
-                    Type, Union, cast)
+from typing import TYPE_CHECKING, Tuple, Type
 
-from crossbench import compat, helper
-from crossbench.benchmarks.speedometer.speedometer import (
-    ProbeClsTupleT, SpeedometerBenchmark, SpeedometerBenchmarkStoryFilter,
-    SpeedometerProbe, SpeedometerStory)
-from crossbench.browsers import viewport as vp
-from crossbench.parse import DurationParser, NumberParser
-from crossbench.stories.story import Story
+from typing_extensions import override
+
+from crossbench.benchmarks.speedometer.speedometer_3 import (
+    Speedometer3Benchmark, Speedometer3Probe, Speedometer3ProbeContext,
+    Speedometer3Story)
 
 if TYPE_CHECKING:
-  from crossbench.cli.parser import CrossBenchArgumentParser
-  from crossbench.runner.run import Run
-  ShuffleSeedT = Optional[Union[str, int]]
-  from crossbench.runner.actions import Actions
-  from crossbench.types import Json
+  from crossbench.benchmarks.base import VersionParts
+  from crossbench.benchmarks.speedometer.speedometer import ProbeClsTupleT
 
 
-class Speedometer30Probe(SpeedometerProbe):
+class Speedometer30Probe(Speedometer3Probe):
   """
   Speedometer3-specific probe (compatible with v3.0).
   Extracts all speedometer times and scores.
   """
   NAME: str = "speedometer_3.0"
-  JS: str = "return window.benchmarkClient.metrics"
-
-  @property
-  def speedometer(self) -> Speedometer30Benchmark:
-    return cast(Speedometer30Benchmark, self.benchmark)
-
-  def to_json(self, actions: Actions) -> Json:
-    return actions.js(self.JS)
-
-  def process_json_data(self, json_data) -> Any:
-    # Move aggregate scores to the end
-    aggregate_keys = []
-    for metric_key in json_data.keys():
-      if metric_key.startswith("Iteration-"):
-        aggregate_keys.append(metric_key)
-    aggregate_keys.extend(["Geomean", "Score"])
-    for metric_key in aggregate_keys:
-      json_data[metric_key] = json_data.pop(metric_key)
-    return json_data
-
-  def flatten_json_data(self, json_data: Any) -> Json:
-    result: Dict[str, float] = {}
-    assert isinstance(json_data, dict), f"Expected dict, got {type(json_data)}"
-    for name, metric in json_data.items():
-      result[name] = metric["mean"]
-    return result
-
-  def _is_valid_metric_key(self, metric_key: str) -> bool:
-    parts = metric_key.split("/")
-    if len(parts) != 1:
-      return False
-    if self.speedometer.detailed_metrics:
-      return True
-    if metric_key.startswith("Iteration-"):
-      return False
-    if metric_key == "Geomean":
-      return False
-    return True
-
-
-@enum.unique
-class MeasurementMethod(compat.StrEnumWithHelp):
-  RAF = ("raf", "requestAnimationFrame-based measurement")
-  TIMER = ("timer", "setTimeout-based measurement")
-
-
-def to_ms(duration: dt.timedelta) -> int:
-  return int(round(duration.total_seconds() * 1000))
 
+  @override
+  def get_context_cls(self) -> Type[Speedometer30ProbeContext]:
+    return Speedometer30ProbeContext
 
-def parse_shuffle_seed(value: Optional[Any]) -> ShuffleSeedT:
-  if value in (None, "off", "generate"):
-    return value
-  if isinstance(value, int):
-    return value
-  return NumberParser.any_int(value, "shuffle-seed")
 
+class Speedometer30ProbeContext(Speedometer3ProbeContext):
+  pass
 
-# Generated by running this JS snippet and updating the bools:
-#  JSON.stringify(
-#    Suites.reduce((data, e) => {
-#        data[e.name]={ tags:e.tags, enabled:!e.disabled};
-#        return data}, {}))
-#  .replaceAll(":true", ":True")
-#  .replaceAll(":false", ":False");
-SPEEDOMETER_3_STORY_DATA = {
-    "TodoMVC-JavaScript-ES5": {
-        "tags": ["all", "default", "todomvc"],
-        "enabled": True
-    },
-    "TodoMVC-JavaScript-ES5-Complex-DOM": {
-        "tags": ["all", "todomvc", "complex"],
-        "enabled": False
-    },
-    "TodoMVC-JavaScript-ES6-Webpack": {
-        "tags": ["all", "todomvc"],
-        "enabled": False
-    },
-    "TodoMVC-JavaScript-ES6-Webpack-Complex-DOM": {
-        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
-        "enabled": True
-    },
-    "TodoMVC-WebComponents": {
-        "tags": ["all", "default", "todomvc", "webcomponents"],
-        "enabled": True
-    },
-    "TodoMVC-WebComponents-Complex-DOM": {
-        "tags": ["all", "todomvc", "webcomponents", "complex"],
-        "enabled": False
-    },
-    "TodoMVC-React": {
-        "tags": ["all", "todomvc"],
-        "enabled": False
-    },
-    "TodoMVC-React-Complex-DOM": {
-        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
-        "enabled": True
-    },
-    "TodoMVC-React-Redux": {
-        "tags": ["all", "default", "todomvc"],
-        "enabled": True
-    },
-    "TodoMVC-React-Redux-Complex-DOM": {
-        "tags": ["all", "todomvc", "complex"],
-        "enabled": False
-    },
-    "TodoMVC-Backbone": {
-        "tags": ["all", "default", "todomvc"],
-        "enabled": True
-    },
-    "TodoMVC-Backbone-Complex-DOM": {
-        "tags": ["all", "todomvc", "complex"],
-        "enabled": False
-    },
-    "TodoMVC-Angular": {
-        "tags": ["all", "todomvc"],
-        "enabled": False
-    },
-    "TodoMVC-Angular-Complex-DOM": {
-        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
-        "enabled": True
-    },
-    "TodoMVC-Vue": {
-        "tags": ["all", "default", "todomvc"],
-        "enabled": True
-    },
-    "TodoMVC-Vue-Complex-DOM": {
-        "tags": ["all", "todomvc", "complex", "complex-default"],
-        "enabled": False
-    },
-    "TodoMVC-jQuery": {
-        "tags": ["all", "default", "todomvc"],
-        "enabled": True
-    },
-    "TodoMVC-jQuery-Complex-DOM": {
-        "tags": ["all", "todomvc", "complex"],
-        "enabled": False
-    },
-    "TodoMVC-Preact": {
-        "tags": ["all", "todomvc"],
-        "enabled": False
-    },
-    "TodoMVC-Preact-Complex-DOM": {
-        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
-        "enabled": True
-    },
-    "TodoMVC-Svelte": {
-        "tags": ["all", "todomvc"],
-        "enabled": False
-    },
-    "TodoMVC-Svelte-Complex-DOM": {
-        "tags": ["all", "default", "todomvc", "complex", "complex-default"],
-        "enabled": True
-    },
-    "TodoMVC-Lit": {
-        "tags": ["all", "todomvc", "webcomponents"],
-        "enabled": False
-    },
-    "TodoMVC-Lit-Complex-DOM": {
-        "tags": [
-            "all", "default", "todomvc", "webcomponents", "complex",
-            "complex-default"
-        ],
-        "enabled": True
-    },
-    "NewsSite-Next": {
-        "tags": ["all", "default", "newssite", "language"],
-        "enabled": True
-    },
-    "NewsSite-Nuxt": {
-        "tags": ["all", "default", "newssite"],
-        "enabled": True
-    },
-    "Editor-CodeMirror": {
-        "tags": ["all", "default", "editor"],
-        "enabled": True
-    },
-    "Editor-TipTap": {
-        "tags": ["all", "default", "editor"],
-        "enabled": True
-    },
-    "Charts-observable-plot": {
-        "tags": ["all", "default", "chart"],
-        "enabled": True
-    },
-    "Charts-chartjs": {
-        "tags": ["all", "default", "chart"],
-        "enabled": True
-    },
-    "React-Stockcharts-SVG": {
-        "tags": ["all", "default", "chart", "svg"],
-        "enabled": True
-    },
-    "Perf-Dashboard": {
-        "tags": ["all", "default", "chart", "webcomponents"],
-        "enabled": True
-    }
-}
 
-
-class Speedometer30Story(SpeedometerStory):
-  __doc__ = SpeedometerStory.__doc__
+class Speedometer30Story(Speedometer3Story):
+  __doc__ = Speedometer3Story.__doc__
   NAME: str = "speedometer_3.0"
   URL: str = "https://chromium-workloads.web.app/speedometer/v3.0/"
   URL_OFFICIAL: str = "https://browserbench.org/Speedometer3.0/"
-  URL_LOCAL: str = "http://127.0.0.1:7000"
-  SUBSTORIES: Tuple[str, ...] = tuple(SPEEDOMETER_3_STORY_DATA.keys())
-
-  @classmethod
-  def default_story_names(cls) -> Tuple[str, ...]:
-    return tuple(
-        tuple(name for name, data in SPEEDOMETER_3_STORY_DATA.items()
-              if data["enabled"]))
-
-  def __init__(self,
-               substories: Sequence[str] = (),
-               iterations: Optional[int] = None,
-               sync_wait: Optional[dt.timedelta] = None,
-               sync_warmup: Optional[dt.timedelta] = None,
-               measurement_method: Optional[MeasurementMethod] = None,
-               viewport: Optional[vp.Viewport] = None,
-               shuffle_seed: ShuffleSeedT = None,
-               url: Optional[str] = None):
-    self._sync_wait = DurationParser.positive_or_zero_duration(
-        sync_wait or dt.timedelta(0), "sync_wait")
-    self._sync_warmup = DurationParser.positive_or_zero_duration(
-        sync_warmup or dt.timedelta(0), "sync_warmup")
-    self._measurement_method: MeasurementMethod = (
-        measurement_method or MeasurementMethod.RAF)
-    self._viewport = None
-    if viewport:
-      self._viewport = vp.Viewport.parse_sized(viewport)
-    self._shuffle_seed: ShuffleSeedT = parse_shuffle_seed(shuffle_seed)
-    super().__init__(url=url, substories=substories, iterations=iterations)
-
-  @property
-  def single_substory_duration(self) -> dt.timedelta:
-    return dt.timedelta(seconds=0.25)
-
-  @property
-  def sync_wait(self) -> dt.timedelta:
-    return self._sync_wait
-
-  @property
-  def sync_warmup(self) -> dt.timedelta:
-    return self._sync_warmup
-
-  @property
-  def measurement_method(self) -> MeasurementMethod:
-    return self._measurement_method
-
-  @property
-  def viewport(self) -> Optional[vp.Viewport]:
-    return self._viewport
 
-  @property
-  def shuffle_seed(self) -> ShuffleSeedT:
-    return self._shuffle_seed
 
-  @property
-  def url_params(self) -> Dict[str, str]:
-    url_params = super().url_params
-    if sync_wait := self.sync_wait:
-      url_params["waitBeforeSync"] = str(to_ms(sync_wait))
-    if sync_warmup := self.sync_warmup:
-      url_params["warmupBeforeSync"] = str(to_ms(sync_warmup))
-    if self.measurement_method != MeasurementMethod.RAF:
-      url_params["measurementMethod"] = str(self.measurement_method)
-    if viewport := self.viewport:
-      url_params["viewport"] = f"{viewport.width}x{viewport.height}"
-    if self.shuffle_seed is not None:
-      url_params["shuffleSeed"] = str(self.shuffle_seed)
-    return url_params
-
-  def log_run_test_url(self, run: Run) -> None:
-    del run
-    params = self.url_params
-    params["suites"] = ",".join(self.substories)
-    params["developerMode"] = "true"
-    params["startAutomatically"] = "true"
-    official_test_url = helper.update_url_query(self.URL, params)
-    logging.info("STORY PUBLIC TEST URL: %s", official_test_url)
-
-
-class Speedometer3BenchmarkStoryFilter(SpeedometerBenchmarkStoryFilter):
-  __doc__ = SpeedometerBenchmarkStoryFilter.__doc__
-
-  @classmethod
-  def add_cli_parser(
-      cls, parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
-    parser = super().add_cli_parser(parser)
-    parser.add_argument(
-        "--sync-wait",
-        default=dt.timedelta(0),
-        type=DurationParser.positive_or_zero_duration,
-        help="Add a custom wait timeout before each sync step.")
-    parser.add_argument(
-        "--sync-warmup",
-        default=dt.timedelta(0),
-        type=DurationParser.positive_or_zero_duration,
-        help="Run a warmup loop for the given duration before each sync step.")
-
-    measurement_method_group = parser.add_argument_group(
-        "Measurement Method Option")
-    measurement_method_group = parser.add_mutually_exclusive_group()
-    measurement_method_group.add_argument(
-        "--raf",
-        dest="measurement_method",
-        default=MeasurementMethod.RAF,
-        const=MeasurementMethod.RAF,
-        action="store_const",
-        help=("Use the default requestAnimationFrame-based approach "
-              "for async time measurement."))
-    measurement_method_group.add_argument(
-        "--timer",
-        dest="measurement_method",
-        const=MeasurementMethod.TIMER,
-        action="store_const",
-        help=("Use the 'classical' setTimeout-based approach "
-              "for async time measurement. "
-              "This might omit measuring some async work."))
-
-    parser.add_argument(
-        "--story-viewport",
-        type=vp.Viewport.parse_sized,
-        help="Specify the speedometer workload viewport size.")
-    parser.add_argument(
-        "--shuffle-seed",
-        type=parse_shuffle_seed,
-        help=("Set a shuffle seed to run the stories in a"
-              "non-default order."))
-    return parser
-
-  @classmethod
-  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
-    kwargs = super().kwargs_from_cli(args)
-    kwargs["iterations"] = args.iterations
-    kwargs["measurement_method"] = args.measurement_method
-    kwargs["sync_wait"] = args.sync_wait
-    kwargs["sync_warmup"] = args.sync_warmup
-    kwargs["viewport"] = args.story_viewport
-    kwargs["shuffle_seed"] = args.shuffle_seed
-    return kwargs
-
-  def __init__(self,
-               story_cls: Type[SpeedometerStory],
-               patterns: Sequence[str],
-               separate: bool = False,
-               url: Optional[str] = None,
-               iterations: Optional[int] = None,
-               measurement_method: Optional[MeasurementMethod] = None,
-               sync_wait: Optional[dt.timedelta] = None,
-               sync_warmup: Optional[dt.timedelta] = None,
-               viewport: Optional[vp.Viewport] = None,
-               shuffle_seed: ShuffleSeedT = None):
-    self.measurement_method = measurement_method
-    self.sync_wait = sync_wait
-    self.sync_warmup = sync_warmup
-    self.viewport = viewport
-    self.shuffle_seed: ShuffleSeedT = shuffle_seed
-    assert issubclass(story_cls, Speedometer30Story)
-    super().__init__(story_cls, patterns, separate, url, iterations=iterations)
-
-  def create_stories_from_names(self, names: List[str],
-                                separate: bool) -> Sequence[SpeedometerStory]:
-    return self.story_cls.from_names(
-        names,
-        separate=separate,
-        url=self.url,
-        iterations=self.iterations,
-        measurement_method=self.measurement_method,
-        sync_wait=self.sync_wait,
-        sync_warmup=self.sync_warmup,
-        viewport=self.viewport,
-        shuffle_seed=self.shuffle_seed)
-
-
-class Speedometer30Benchmark(SpeedometerBenchmark):
+class Speedometer30Benchmark(Speedometer3Benchmark):
   """
   Benchmark runner for Speedometer 3.0
   """
   NAME: str = "speedometer_3.0"
-  DEFAULT_STORY_CLS = Speedometer30Story
-  STORY_FILTER_CLS = Speedometer3BenchmarkStoryFilter
+  DEFAULT_STORY_CLS = Speedometer30Story  # type: ignore
   PROBES: ProbeClsTupleT = (Speedometer30Probe,)
 
   @classmethod
-  def version(cls) -> Tuple[int, ...]:
+  @override
+  def version(cls) -> VersionParts:
     return (3, 0)
 
   @classmethod
+  @override
   def aliases(cls) -> Tuple[str, ...]:
     return ("sp3", "speedometer_3") + super().aliases()
-
-  @classmethod
-  def add_cli_parser(
-      cls, subparsers: argparse.ArgumentParser, aliases: Sequence[str] = ()
-  ) -> CrossBenchArgumentParser:
-    parser = super().add_cli_parser(subparsers, aliases)
-    parser.add_argument(
-        "--detailed-metrics",
-        "--details",
-        default=False,
-        action="store_true",
-        help="Report more detailed internal metrics.")
-    return parser
-
-  @classmethod
-  def kwargs_from_cli(cls, args: argparse.Namespace) -> Dict[str, Any]:
-    kwargs = super().kwargs_from_cli(args)
-    kwargs["detailed_metrics"] = args.detailed_metrics
-    return kwargs
-
-  def __init__(self,
-               stories: Sequence[Story],
-               custom_url: Optional[str] = None,
-               detailed_metrics: bool = False):
-    self._detailed_metrics = detailed_metrics
-    super().__init__(stories, custom_url)
-
-  @property
-  def detailed_metrics(self) -> bool:
-    return self._detailed_metrics
diff --git a/crossbench/benchmarks/speedometer/speedometer_3_1.py b/crossbench/benchmarks/speedometer/speedometer_3_1.py
new file mode 100644
index 00000000..8f27433f
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer_3_1.py
@@ -0,0 +1,54 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.benchmarks.speedometer.speedometer_3 import (
+    Speedometer3Benchmark, Speedometer3Probe, Speedometer3ProbeContext,
+    Speedometer3Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
+  from crossbench.benchmarks.speedometer.speedometer import ProbeClsTupleT
+
+
+class Speedometer31Probe(Speedometer3Probe):
+  """
+  Speedometer3-specific probe (compatible with v3.1).
+  Extracts all speedometer times and scores.
+  """
+  NAME: str = "speedometer_3.1"
+
+  @override
+  def get_context_cls(self) -> Type[Speedometer31ProbeContext]:
+    return Speedometer31ProbeContext
+
+
+class Speedometer31ProbeContext(Speedometer3ProbeContext):
+  pass
+
+
+class Speedometer31Story(Speedometer3Story):
+  __doc__ = Speedometer3Story.__doc__
+  NAME: str = "speedometer_3.1"
+  URL: str = "https://chromium-workloads.web.app/speedometer/v3.1/"
+  URL_OFFICIAL: str = "https://browserbench.org/Speedometer3.1/"
+
+
+class Speedometer31Benchmark(Speedometer3Benchmark):
+  """
+  Benchmark runner for Speedometer 3.1
+  """
+  NAME: str = "speedometer_3.1"
+  DEFAULT_STORY_CLS = Speedometer31Story  # type: ignore
+  PROBES: ProbeClsTupleT = (Speedometer31Probe,)
+
+  @classmethod
+  @override
+  def version(cls) -> VersionParts:
+    return (3, 1)
diff --git a/crossbench/benchmarks/speedometer/speedometer_main.py b/crossbench/benchmarks/speedometer/speedometer_main.py
new file mode 100644
index 00000000..497476c2
--- /dev/null
+++ b/crossbench/benchmarks/speedometer/speedometer_main.py
@@ -0,0 +1,55 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.benchmarks.speedometer.speedometer_3 import (
+    Speedometer3Benchmark, Speedometer3Probe, Speedometer3ProbeContext,
+    Speedometer3Story)
+
+if TYPE_CHECKING:
+  from crossbench.benchmarks.base import VersionParts
+  from crossbench.benchmarks.speedometer.speedometer import ProbeClsTupleT
+
+
+class SpeedometerMainProbe(Speedometer3Probe):
+  """
+  Speedometer3-specific probe (compatible with the main version).
+  Extracts all speedometer times and scores.
+  """
+  NAME: str = "speedometer_main"
+
+  @override
+  def get_context_cls(self) -> Type[SpeedometerMainProbeContext]:
+    return SpeedometerMainProbeContext
+
+
+class SpeedometerMainProbeContext(Speedometer3ProbeContext):
+  pass
+
+
+class SpeedometerMainStory(Speedometer3Story):
+  __doc__ = Speedometer3Story.__doc__
+  NAME: str = "speedometer_main"
+  URL: str = "https://chromium-workloads.web.app/speedometer/main/"
+  URL_OFFICIAL: str = "https://chromium-workloads.web.app/speedometer/main/"
+
+
+class SpeedometerMainBenchmark(Speedometer3Benchmark):
+  """
+  Benchmark runner for the Speedometer main version.
+  """
+  NAME: str = "speedometer_main"
+  DEFAULT_STORY_CLS = SpeedometerMainStory  # type: ignore
+  PROBES: ProbeClsTupleT = (SpeedometerMainProbe,)
+
+  @classmethod
+  @override
+  def version(cls) -> VersionParts:
+    # Using fake next version as a hack.
+    return ("main",)
diff --git a/crossbench/bond/__init__.py b/crossbench/bond/__init__.py
new file mode 100644
index 00000000..b20ab3aa
--- /dev/null
+++ b/crossbench/bond/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/bond/bond.py b/crossbench/bond/bond.py
new file mode 100644
index 00000000..1e0b6a02
--- /dev/null
+++ b/crossbench/bond/bond.py
@@ -0,0 +1,209 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+import enum
+from typing import Any, Mapping, Self, Sequence, Set
+
+import google.auth.transport.requests
+import requests
+from google.auth.credentials import TokenState
+from google.oauth2 import service_account
+from typing_extensions import override
+
+from crossbench.cli.config.secrets import ServiceAccount
+from crossbench.config import ConfigEnum, ConfigObject, ConfigParser
+from crossbench.helper import url_helper
+from crossbench.parse import NumberParser, ObjectParser
+
+
+@enum.unique
+class MeetLayout(ConfigEnum):
+  AUTOMATIC = ("AUTOMATIC", "Automatically pick a layout based on bot count")
+  SPOTLIGHT = ("SPOTLIGHT", "Google Meet spotlight layout")
+  BRADY_BUNCH = ("BRADY_BUNCH", "Google Meet brady bunch layout")
+  BRADY_BUNCH_4_4 = ("BRADY_BUNCH_4_4", "Google Meet brady bunch 4x4 layout")
+  BRADY_BUNCH_7_7 = ("BRADY_BUNCH_7_7", "Google Meet brady bunch 7x7 layout")
+
+
+@dataclasses.dataclass(frozen=True)
+class AddBotsConfig(ConfigObject):
+  num_of_bots: int
+  ttl_secs: int
+  allow_vp9: bool
+  send_vp9: bool
+  audio_file_path: str
+  mute_audio: bool
+  video_fps: int
+  mute_video: bool
+  requested_layout: MeetLayout
+  video_file_path: str | None
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    del value
+    raise NotImplementedError("Cannot create AddBotsConfig from string")
+
+  @classmethod
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
+    parser.add_argument(
+        "num_of_bots", type=NumberParser.positive_int, required=True)
+    parser.add_argument(
+        "ttl_secs", type=NumberParser.positive_int, required=True)
+    parser.add_argument("allow_vp9", type=ObjectParser.bool, default=True)
+    parser.add_argument("send_vp9", type=ObjectParser.bool, default=True)
+    parser.add_argument(
+        "audio_file_path",
+        type=ObjectParser.non_empty_str,
+        default="what_color_is_cheese_32bit_48k_stereo.raw")
+    parser.add_argument("mute_audio", type=ObjectParser.bool, default=False)
+    parser.add_argument("video_fps", type=NumberParser.positive_int, default=24)
+    parser.add_argument("mute_video", type=ObjectParser.bool, default=False)
+    parser.add_argument(
+        "requested_layout", type=MeetLayout, default=MeetLayout.AUTOMATIC)
+    parser.add_argument(
+        "video_file_path", type=ObjectParser.non_empty_str, default=None)
+
+    return parser
+
+  def to_request_body_json(self, conference_code: str) -> Any:
+    requested_layout = self.requested_layout
+    if requested_layout is MeetLayout.AUTOMATIC:
+      if self.num_of_bots <= 1:
+        requested_layout = MeetLayout.SPOTLIGHT
+      elif self.num_of_bots <= 5:
+        requested_layout = MeetLayout.BRADY_BUNCH
+      elif self.num_of_bots <= 15:
+        requested_layout = MeetLayout.BRADY_BUNCH_4_4
+      else:
+        requested_layout = MeetLayout.BRADY_BUNCH_7_7
+
+    media_options = {
+        "audio_file_path": self.audio_file_path,
+        "mute_audio": self.mute_audio,
+        "video_fps": self.video_fps,
+        "mute_video": self.mute_video,
+        "requested_layout": requested_layout.value,
+    }
+    if self.video_file_path:
+      media_options["video_file_path"] = self.video_file_path
+
+    body_json = {
+        "num_of_bots": self.num_of_bots,
+        "ttl_secs": self.ttl_secs,
+        "video_call_options": {
+            "allow_vp9": self.allow_vp9,
+            "send_vp9": self.send_vp9,
+        },
+        "media_options": media_options,
+        "backend_options": {
+            "mesi_apiary_url": MESI_APIARY_URL,
+            "mas_one_platform_url": MAS_ONEPLATFORM_URL,
+        },
+        "conference": {
+            "conference_code": conference_code,
+        },
+        "bot_type": "MEETINGS",
+    }
+    if not self.video_file_path:
+      body_json[
+          "video_selection_strategy"] = "ROUND_ROBIN_VIDEO_SELECTION_STRATEGY"
+
+    return body_json
+
+
+ENDPOINT = "https://bond-pa.sandbox.googleapis.com"
+MESI_APIARY_URL = "https://hangouts.googleapis.com/hangouts/v1_meetings/"
+MAS_ONEPLATFORM_URL = "https://preprod-meetings.googleapis.com"
+SCOPE = "https://www.googleapis.com/auth/meetings"
+
+
+class BondClient:
+  _credentials: service_account.Credentials
+  _meetings_with_bots: Set[str]
+
+  def __init__(self, secret: ServiceAccount) -> None:
+    self._credentials = service_account.Credentials.from_service_account_info(
+        secret.to_json(), scopes=[SCOPE])
+    self._meetings_with_bots = set()
+
+  def _get_request_headers(self) -> Mapping[str, str]:
+    if self._credentials.token_state is not TokenState.FRESH:
+      self._credentials.refresh(google.auth.transport.requests.Request())
+    assert self._credentials.token
+    return {"Authorization": f"Bearer {self._credentials.token}"}
+
+  def _post_with_retry(self,
+                       url: str,
+                       body_json: Any,
+                       retry: int = 3) -> requests.Response:
+    headers = self._get_request_headers()
+    return url_helper.post(url, body_json, headers, retry)
+
+
+  def create_meeting(self) -> str:
+    request_body_json = {
+        "conference_type": "THOR",
+        "backend_options": {
+            "mesi_apiary_url": MESI_APIARY_URL,
+            "mas_one_platform_url": MAS_ONEPLATFORM_URL
+        }
+    }
+    response = self._post_with_retry(f"{ENDPOINT}/v1/conferences:create",
+                                     request_body_json)
+    resonse_body_dict = ObjectParser.dict(response.json())
+    conference = ObjectParser.dict(resonse_body_dict["conference"],
+                                   "conference")
+    conference_code = ObjectParser.non_empty_str(conference["conferenceCode"],
+                                                 "conferenceCode")
+    return conference_code
+
+  def add_bots(self, conference_code: str,
+               config: AddBotsConfig) -> Sequence[int]:
+    request_body_json = config.to_request_body_json(conference_code)
+    response = self._post_with_retry(
+        f"{ENDPOINT}/v1/conference/{conference_code}/bots:add",
+        request_body_json)
+    response_body_dict = ObjectParser.dict(response.json())
+    num_of_failures = NumberParser.positive_zero_int(
+        response_body_dict["numOfFailures"], "numOfFailures")
+    if num_of_failures > 0:
+      raise RuntimeError(f"{num_of_failures} failures when adding bots")
+    bot_ids = ObjectParser.sequence(response_body_dict["botIds"])
+    for bot_id in bot_ids:
+      NumberParser.any_int(bot_id)
+    self._meetings_with_bots.add(conference_code)
+    return bot_ids
+
+  def run_script(self, conference_code: str, script: str) -> None:
+    request_body_json = {
+        "script": script,
+        "conference": {
+            "conference_code": conference_code,
+        },
+    }
+    self._post_with_retry(f"{ENDPOINT}/v1/conference/{conference_code}/script",
+                          request_body_json)
+
+  def remove_all_bots(self, conference_code: str) -> None:
+    request_body_json = {
+        "conference": {
+            "conference_code": conference_code,
+        },
+        "bot_type": "MEETINGS",
+        "remove_all": True,
+    }
+    self._post_with_retry(
+        f"{ENDPOINT}/v1/conference/{conference_code}/bots:remove",
+        request_body_json)
+
+  def teardown(self) -> None:
+    for conference_code in self._meetings_with_bots:
+      self.remove_all_bots(conference_code)
+    self._meetings_with_bots = set()
diff --git a/crossbench/bond/test_bond.py b/crossbench/bond/test_bond.py
new file mode 100644
index 00000000..2ac84f8f
--- /dev/null
+++ b/crossbench/bond/test_bond.py
@@ -0,0 +1,89 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import unittest
+
+from crossbench.bond.bond import (MAS_ONEPLATFORM_URL, MESI_APIARY_URL,
+                                  AddBotsConfig, MeetLayout)
+from tests import test_helper
+
+
+class AddBotsConfigTestCase(unittest.TestCase):
+
+  def test_minimal(self) -> None:
+    config_dict = {"num_of_bots": 3, "ttl_secs": 123}
+    config = AddBotsConfig.parse_dict(config_dict)
+    config.validate()
+
+    self.assertEqual(
+        config.to_request_body_json("meet-code"), {
+            "num_of_bots": 3,
+            "ttl_secs": 123,
+            "video_call_options": {
+                "allow_vp9": True,
+                "send_vp9": True,
+            },
+            "media_options": {
+                "audio_file_path": "what_color_is_cheese_32bit_48k_stereo.raw",
+                "mute_audio": False,
+                "video_fps": 24,
+                "mute_video": False,
+                "requested_layout": str(MeetLayout.BRADY_BUNCH)
+            },
+            "backend_options": {
+                "mesi_apiary_url": MESI_APIARY_URL,
+                "mas_one_platform_url": MAS_ONEPLATFORM_URL,
+            },
+            "conference": {
+                "conference_code": "meet-code",
+            },
+            "bot_type": "MEETINGS",
+            "video_selection_strategy": "ROUND_ROBIN_VIDEO_SELECTION_STRATEGY",
+        })
+
+  def test_all(self) -> None:
+    config_dict = {
+        "num_of_bots": 4,
+        "ttl_secs": 234,
+        "allow_vp9": False,
+        "send_vp9": False,
+        "audio_file_path": "audio.raw",
+        "mute_audio": True,
+        "video_fps": 144,
+        "mute_video": True,
+        "requested_layout": MeetLayout.SPOTLIGHT,
+        "video_file_path": "video.raw"
+    }
+    config = AddBotsConfig.parse_dict(config_dict)
+    config.validate()
+
+    self.assertEqual(
+        config.to_request_body_json("meet-code"), {
+            "num_of_bots": 4,
+            "ttl_secs": 234,
+            "video_call_options": {
+                "allow_vp9": False,
+                "send_vp9": False,
+            },
+            "media_options": {
+                "audio_file_path": "audio.raw",
+                "mute_audio": True,
+                "video_fps": 144,
+                "mute_video": True,
+                "requested_layout": str(MeetLayout.SPOTLIGHT),
+                "video_file_path": "video.raw",
+            },
+            "backend_options": {
+                "mesi_apiary_url": MESI_APIARY_URL,
+                "mas_one_platform_url": MAS_ONEPLATFORM_URL,
+            },
+            "conference": {
+                "conference_code": "meet-code",
+            },
+            "bot_type": "MEETINGS",
+        })
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/crossbench/browsers/all.py b/crossbench/browsers/all.py
index d436a34c..b75fd68f 100644
--- a/crossbench/browsers/all.py
+++ b/crossbench/browsers/all.py
@@ -15,8 +15,10 @@ from crossbench.browsers.chrome.webdriver import (ChromeWebDriver,
 from crossbench.browsers.chromium.applescript import ChromiumAppleScript
 from crossbench.browsers.chromium.chromium import Chromium
 from crossbench.browsers.chromium.webdriver import (
-    ChromiumWebDriver, ChromiumWebDriverAndroid, ChromiumWebDriverChromeOsSsh,
-    ChromiumWebDriverSsh, LocalChromiumWebDriverAndroid)
+    ChromiumBasedWebDriver, ChromiumWebDriver, ChromiumWebDriverAndroid,
+    ChromiumWebDriverChromeOsSsh, ChromiumWebDriverSsh,
+    LocalChromiumWebDriverAndroid)
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
 from crossbench.browsers.edge.edge import Edge
 from crossbench.browsers.edge.webdriver import EdgeWebDriver
 from crossbench.browsers.firefox.firefox import Firefox
diff --git a/crossbench/browsers/applescript.py b/crossbench/browsers/applescript.py
index ae4d302f..f0ff9172 100644
--- a/crossbench/browsers/applescript.py
+++ b/crossbench/browsers/applescript.py
@@ -12,14 +12,16 @@ import subprocess
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple
 
 import psutil
+from typing_extensions import override
 
-from crossbench import helper, plt
+from crossbench import plt
 from crossbench.browsers.browser import Browser
-from crossbench.env import HostEnvironment, ValidationError
+from crossbench.env import ValidationError
 
 if TYPE_CHECKING:
   import datetime as dt
 
+  from crossbench.env import HostEnvironment
   from crossbench.path import AnyPath
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
@@ -115,12 +117,14 @@ class AppleScriptBrowser(Browser, metaclass=abc.ABCMeta):
                                                  **kwargs)
     return self.platform.exec_apple_script(wrapper_script, *args)
 
+  @override
   def validate_env(self, env: HostEnvironment) -> None:
     super().validate_env(env)
     self._check_system_events_allowed(env)
 
+  @override
   def start(self, session: BrowserSessionRunGroup) -> None:
-    assert not self._is_running
+    super().start(session)
     # Start process directly
     startup_flags = self._get_browser_flags_for_session(session)
     self._log_browser_start(startup_flags)
@@ -169,6 +173,7 @@ class AppleScriptBrowser(Browser, metaclass=abc.ABCMeta):
   def _setup_window(self) -> None:
     pass
 
+  @override
   def js(
       self,
       script: str,
@@ -184,6 +189,7 @@ class AppleScriptBrowser(Browser, metaclass=abc.ABCMeta):
       raise AppleScript.JavaScriptFromAppleScriptException(result)
     return result
 
+  @override
   def show_url(self, url: str, target: Optional[str] = None) -> None:
     if target not in (None, "_self"):
       raise NotImplementedError(
@@ -191,6 +197,7 @@ class AppleScriptBrowser(Browser, metaclass=abc.ABCMeta):
     self._exec_apple_script(self.APPLE_SCRIPT_SET_URL, url=url)
     self.platform.sleep(0.5)
 
+  @override
   def quit(self) -> None:
     self._exec_apple_script("quit")
-    helper.wait_and_kill(self._browser_process)
+    self.platform.terminate_gracefully(self._browser_process)
diff --git a/crossbench/browsers/browser.py b/crossbench/browsers/browser.py
index 42075f85..6e0bc645 100644
--- a/crossbench/browsers/browser.py
+++ b/crossbench/browsers/browser.py
@@ -16,15 +16,15 @@ from ordered_set import OrderedSet
 from crossbench import path as pth
 from crossbench import plt
 from crossbench.browsers.settings import Settings
+from crossbench.browsers.version import BrowserVersion, UnknownBrowserVersion
 from crossbench.flags.base import Flags, FlagsData, FlagsT
 
 if TYPE_CHECKING:
   import re
 
   from crossbench.browsers.attributes import BrowserAttributes
-  from crossbench.browsers.splash_screen import SplashScreen
   from crossbench.browsers.viewport import Viewport
-  from crossbench.cli.config.secrets import Secret, SecretsDict
+  from crossbench.cli.config.secrets import Secrets, UsernamePassword
   from crossbench.env import HostEnvironment
   from crossbench.flags.chrome import ChromeFeatures
   from crossbench.flags.js_flags import JSFlags
@@ -40,61 +40,60 @@ class Browser(abc.ABC):
   def default_flags(cls, initial_data: FlagsData = None) -> Flags:
     return Flags(initial_data)
 
+  @classmethod
+  @abc.abstractmethod
+  def type_name(cls) -> str:
+    pass
+
+  @classmethod
+  @abc.abstractmethod
+  def attributes(cls) -> BrowserAttributes:
+    pass
+
   def __init__(self,
                label: str,
                path: Optional[pth.AnyPath] = None,
-               settings: Optional[Settings] = None):
+               settings: Optional[Settings] = None) -> None:
     self._settings = settings or Settings()
     self._platform = self._settings.platform
     self.label: str = label
-    self._unique_name: str = ""
-    self.app_name: str = self.type_name
-    self.version: str = "custom"
-    self.major_version: int = 0
+    self.app_name: str = self.type_name()
     self.app_path: pth.AnyPath = pth.AnyPath()
-    self.path = pth.AnyPath()
-    self._setup_path(path)
+    self._path = pth.AnyPath()
+    self._is_local_build: bool = False
+    self._unique_name: str = ""
+    self._version: BrowserVersion = UnknownBrowserVersion()
+    self._init_path_and_version(path)
     self._is_running: bool = False
-    self._pid: Optional[int] = None
+    self._pid: int | None = None
     self._probes: OrderedSet[Probe] = OrderedSet()
-    self._flags: Flags = self._setup_flags(self._settings)
-    self.log_file: Optional[pth.AnyPath] = None
-    self.cache_dir: Optional[pth.AnyPath] = self._settings.cache_dir
-    self.clear_cache_dir: bool = True
-    self._setup_cache_dir(self._settings)
-
-  def _setup_path(self, path: Optional[pth.AnyPath] = None) -> None:
+    self._flags: Flags = self._init_flags(self._settings)
+    self.log_file: pth.AnyPath | None = None
+    # Optional location of the browser's main cache dir.
+    # If set and settings.clear_cache, this should be cleared before and after
+    # running the browser.
+    # For chrome browsers this corresponds to the user-data-dir.
+    self._cache_dir: pth.AnyPath | None = None
+
+  def _init_path_and_version(self, path: Optional[pth.AnyPath] = None) -> None:
     if not path:
       # TODO: separate class for remote browser (selenium) without an explicit
       # binary path.
-      self.unique_name = f"{self.type_name}_{self.label}".lower()
+      self._version = self._extract_version()
+      self._unique_name = f"{self.type_name()}_{self.label}".lower()
       return
-    self.path = self._resolve_binary(path)
+    self._path = self._init_resolve_binary(path)
     # TODO clean up
     if not self.platform.is_android:
       assert self.path.is_absolute()
-    self.version = self._extract_version()
-    self.major_version = int(self.version.split(".")[0])
-    self.unique_name = f"{self.type_name}_v{self.major_version}_{self.label}"
+    self._version = self._extract_version()
+    self._unique_name = f"{self.type_name()}_v{self.version.major}_{self.label}"
 
-  def _setup_flags(self, settings: Settings) -> Flags:
+  def _init_flags(self, settings: Settings) -> Flags:
     assert not self._settings.js_flags, (
         f"{self} doesn't support custom js_flags")
     return self.default_flags(settings.flags)
 
-  def _setup_cache_dir(self, settings: Settings) -> None:
-    pass
-
-  @property
-  @abc.abstractmethod
-  def type_name(self) -> str:
-    pass
-
-  @property
-  @abc.abstractmethod
-  def attributes(self) -> BrowserAttributes:
-    pass
-
   @property
   def platform(self) -> plt.Platform:
     return self._platform
@@ -103,6 +102,10 @@ class Browser(abc.ABC):
   def host_platform(self) -> plt.Platform:
     return self._platform.host_platform
 
+  @property
+  def version(self) -> BrowserVersion:
+    return self._version
+
   @property
   def unique_name(self) -> str:
     return self._unique_name
@@ -113,17 +116,29 @@ class Browser(abc.ABC):
     # Replace any potentially unsafe chars in the name
     self._unique_name = pth.safe_filename(name).lower()
 
+  @property
+  def path(self) -> pth.AnyPath:
+    return self._path
+
+  @property
+  def driver_logging(self) -> bool:
+    return self._settings.driver_logging
+
   @property
   def network(self) -> Network:
     return self._settings.network
 
   @property
-  def secrets(self) -> SecretsDict:
+  def secrets(self) -> Secrets:
     return self._settings.secrets
 
   @property
-  def splash_screen(self) -> SplashScreen:
-    return self._settings.splash_screen
+  def settings(self):
+    return self._settings
+
+  @property
+  def clear_cache_dir(self) -> bool:
+    return self._settings.clear_cache_dir
 
   @property
   def viewport(self) -> Viewport:
@@ -141,6 +156,14 @@ class Browser(abc.ABC):
   def http_request_timeout(self) -> dt.timedelta:
     return self._settings.http_request_timeout
 
+  @property
+  def driver_path(self) -> Optional[pth.AnyPath]:
+    return self._settings.driver_path
+
+  @property
+  def is_local_build(self) -> bool:
+    return self._is_local_build
+
   @property
   def probes(self) -> Iterable[Probe]:
     return iter(self._probes)
@@ -194,6 +217,10 @@ class Browser(abc.ABC):
   def is_remote(self) -> bool:
     return self.platform.is_remote
 
+  @property
+  def cache_dir(self) -> Optional[pth.AnyPath]:
+    return self._cache_dir
+
   def set_log_file(self, path: pth.AnyPath) -> None:
     self.log_file = path
 
@@ -202,18 +229,22 @@ class Browser(abc.ABC):
     assert self.log_file
     return self.log_file.with_suffix(".stdout.log")
 
-  def _resolve_binary(self, path: pth.AnyPath) -> pth.AnyPath:
+  @property
+  def driver_log_file(self) -> Optional[pth.LocalPath]:
+    return None
+
+  def _init_resolve_binary(self, path: pth.AnyPath) -> pth.AnyPath:
     path = self.platform.absolute(path)
     assert self.platform.exists(path), f"Binary at path={path} does not exist."
     self.app_path = path
     self.app_name = self.app_path.stem
     if self.platform.is_macos:
-      path = self._resolve_macos_binary(path)
+      path = self._init_resolve_macos_binary(path)
     assert self.platform.is_file(path), (
         f"Binary at path={path} is not a file.")
     return path
 
-  def _resolve_macos_binary(self, path: pth.AnyPath) -> pth.AnyPath:
+  def _init_resolve_macos_binary(self, path: pth.AnyPath) -> pth.AnyPath:
     assert self.platform.is_macos
     candidate = self.platform.search_binary(path)
     if not candidate or not self.platform.is_file(candidate):
@@ -229,34 +260,44 @@ class Browser(abc.ABC):
   def details_json(self) -> JsonDict:
     return {
         "label": self.label,
-        "browser": self.type_name,
+        "browser": self.type_name(),
         "unique_name": self.unique_name,
         "app_name": self.app_name,
-        "version": self.version,
+        "version": self.version.parts_str,
+        "channel": self.version.channel_name,
         "flags": tuple(self.flags),
         "js_flags": tuple(),
         "path": os.fspath(self.path),
         "clear_cache_dir": self.clear_cache_dir,
-        "major_version": self.major_version,
+        "major_version": self.version.major,
         "log": {}
     }
 
+  def validate(self):
+    self.validate_flags()
+    self.validate_binary()
+
+  def validate_flags(self) -> None:
+    """ Helper method is called from the Runner before any Runs / Sessions
+    have started."""
+
   def validate_binary(self) -> None:
     """ Helper method is called from the Runner before any Runs / Sessions
     have started."""
 
-  def setup_binary(self) -> None:
+  def setup(self) -> None:
+    assert not self._is_running, "setup() called in wrong order."
+    self._setup_binary()
+    assert not self._cache_dir
+    self._cache_dir = self._setup_cache_dir()
+
+  def _setup_binary(self) -> None:
     """ This helper is called in the setup steps of each Session.
     This can be used to install a custom binary on remote devices. """
 
-  def setup(self, session: BrowserSessionRunGroup) -> None:
-    assert not self._is_running, (
-        "Previously used browser was not correctly stopped.")
-    self.clear_cache()
-    self.start(session)
-    assert self._is_running
-
-  def is_logged_in(self, secret: Secret, strict: bool = False) -> bool:
+  def is_logged_in(self,
+                   secret: UsernamePassword,
+                   strict: bool = False) -> bool:
     """Determines whether the browser is already logged in with the given
     credentials.
 
@@ -276,35 +317,44 @@ class Browser(abc.ABC):
     return False
 
   @abc.abstractmethod
-  def _extract_version(self) -> str:
+  def _extract_version(self) -> BrowserVersion:
     pass
 
-  def clear_cache(self) -> None:
-    if self.clear_cache_dir and self.cache_dir:
-      self.platform.rm(self.cache_dir, missing_ok=True, dir=True)
-      self.platform.mkdir(self.cache_dir, parents=True)
-
   @abc.abstractmethod
-  def start(self, session: BrowserSessionRunGroup) -> None:
+  def _setup_cache_dir(self) -> Optional[pth.AnyPath]:
     pass
 
+  def _teardown_cache_dir(self) -> None:
+    self._clear_cache(self._cache_dir)
+
+  def _clear_cache(self, cache_dir: Optional[pth.AnyPath]) -> None:
+    if self.clear_cache_dir and cache_dir:
+      logging.debug("CLEAR CACHE: %s", cache_dir)
+      self.platform.rm(cache_dir, missing_ok=True, dir=True)
+    self._cache_dir = None
+
+  def start(self, session: BrowserSessionRunGroup) -> None:
+    del session
+    assert not self._is_running, (
+        "Previously used browser was not correctly stopped.")
+
   def _log_browser_start(self,
                          args: Tuple[str, ...],
                          driver_path: Optional[pth.AnyPath] = None) -> None:
-    logging.info("STARTING BROWSER Binary:  %s", self.path)
-    logging.info("STARTING BROWSER Version: %s", self.version)
+    logging.info(" STARTING BROWSER Binary:  %s", self.path)
+    logging.info("  STARTING BROWSER Version: %s", self.version)
     if driver_path:
-      logging.info("STARTING BROWSER Driver:  %s", driver_path)
-    logging.info("STARTING BROWSER Network: %s", self.network)
-    logging.info("STARTING BROWSER Probes:  %s",
+      logging.info(" STARTING BROWSER Driver:  %s", driver_path)
+    logging.info("  STARTING BROWSER Network: %s", self.network)
+    logging.info(" STARTING BROWSER Probes:  %s",
                  ", ".join(p.NAME for p in self.probes))
-    logging.info("STARTING BROWSER Flags:   %s", shlex.join(args))
+    logging.info(" STARTING BROWSER Flags:   %s", shlex.join(args))
 
   def _get_browser_flags_for_session(
       self, session: BrowserSessionRunGroup) -> Tuple[str, ...]:
     flags_copy: Flags = self.flags.copy()
     flags_copy.update(session.extra_flags)
-    flags_copy.update(self.network.extra_flags(self.attributes))
+    flags_copy.update(self.network.extra_flags(self.attributes()))
     flags_copy = self._filter_flags_for_run(flags_copy)
     return tuple(flags_copy)
 
@@ -317,6 +367,7 @@ class Browser(abc.ABC):
       self.force_quit()
     finally:
       self._pid = None
+      self._teardown_cache_dir()
 
   def force_quit(self) -> None:
     if not self._is_running:
@@ -359,13 +410,30 @@ class Browser(abc.ABC):
       url: Optional[re.Pattern] = None,
       tab_index: Optional[int] = None,
       timeout: dt.timedelta = dt.timedelta(seconds=0)
-  ) -> None:
+  ) -> str:
     del title
     del url
     del tab_index
     del timeout
     raise NotImplementedError(f"Switching tabs is not supported by {self}")
 
+  def close_tab(
+      self,
+      title: Optional[re.Pattern] = None,
+      url: Optional[re.Pattern] = None,
+      tab_index: Optional[int] = None,
+      timeout: dt.timedelta = dt.timedelta(seconds=0)
+  ) -> None:
+    del title
+    del url
+    del tab_index
+    del timeout
+    raise NotImplementedError(f"Closing tabs is not supported by {self}")
+
+  @property
+  def current_url(self) -> str:
+    raise NotImplementedError(f"Getting current url is not supported by {self}")
+
   @abc.abstractmethod
   def show_url(self, url: str, target: Optional[str] = None) -> None:
     pass
@@ -393,11 +461,11 @@ class Browser(abc.ABC):
     platform_prefix = ""
     if self.platform.is_remote:
       platform_prefix = str(self.platform)
-    return f"{platform_prefix}{self.type_name.capitalize()}:{self.label}"
+    return f"{platform_prefix}{self.type_name().capitalize()}:{self.label}"
 
   def __hash__(self) -> int:
     # Poor-man's hash, browsers should be unique.
     return hash(id(self))
 
-  def performance_mark(self, name: str):
+  def performance_mark(self, name: str) -> None:
     self.js("performance.mark(arguments[0]);", arguments=[name])
diff --git a/crossbench/browsers/browser_helper.py b/crossbench/browsers/browser_helper.py
index a70b5075..dbb1a443 100644
--- a/crossbench/browsers/browser_helper.py
+++ b/crossbench/browsers/browser_helper.py
@@ -7,7 +7,7 @@ from __future__ import annotations
 import re
 from typing import Optional
 
-_FLAG_TO_PATH_RE = re.compile(r"[-/\\:.]")
+_FLAG_TO_PATH_RE: re.Pattern[str] = re.compile(r"[-/\\:.]")
 
 
 def convert_flags_to_label(*flags: str, index: Optional[int] = None) -> str:
diff --git a/crossbench/browsers/chrome/applescript.py b/crossbench/browsers/chrome/applescript.py
index b1e4a1c1..fdcd4e08 100644
--- a/crossbench/browsers/chrome/applescript.py
+++ b/crossbench/browsers/chrome/applescript.py
@@ -9,22 +9,24 @@ from typing import TYPE_CHECKING
 from selenium import webdriver
 from selenium.webdriver.chrome.options import Options as ChromeOptions
 from selenium.webdriver.chrome.service import Service as ChromeService
+from typing_extensions import override
 
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chrome.helper import ChromePathMixin
+from crossbench.browsers.chrome.base import ChromeBaseMixin
 from crossbench.browsers.chromium.applescript import ChromiumAppleScript
 
 if TYPE_CHECKING:
   from selenium.webdriver.chromium.webdriver import ChromiumDriver
 
 
-class ChromeAppleScript(ChromePathMixin, ChromiumAppleScript):
+class ChromeAppleScript(ChromeBaseMixin, ChromiumAppleScript):
 
   WEB_DRIVER_OPTIONS = ChromeOptions
   WEB_DRIVER_SERVICE = ChromeService
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return (BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
             | BrowserAttributes.APPLESCRIPT)
 
diff --git a/crossbench/browsers/chrome/helper.py b/crossbench/browsers/chrome/base.py
similarity index 77%
rename from crossbench/browsers/chrome/helper.py
rename to crossbench/browsers/chrome/base.py
index ed5dd4fe..c4c7d9fb 100644
--- a/crossbench/browsers/chrome/helper.py
+++ b/crossbench/browsers/chrome/base.py
@@ -4,15 +4,22 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING
+import abc
+from typing import TYPE_CHECKING, Type
 
-from crossbench import plt
+from crossbench.browsers.chrome.version import ChromeVersion
 
 if TYPE_CHECKING:
+  from crossbench import plt
+  from crossbench.browsers.chromium.version import ChromiumVersion
   from crossbench.path import AnyPath
 
 
-class ChromePathMixin:
+class ChromeBaseMixin(abc.ABC):
+
+  @classmethod
+  def version_cls(cls) -> Type[ChromiumVersion]:
+    return ChromeVersion
 
   @classmethod
   def default_path(cls, platform: plt.Platform) -> AnyPath:
@@ -47,8 +54,9 @@ class ChromePathMixin:
     return platform.search_app_or_executable(
         "Chrome Canary",
         macos=["Google Chrome Canary.app"],
+        linux=["google-chrome-canary"],
         win=["Google/Chrome SxS/Application/chrome.exe"])
 
-  @property
-  def type_name(self) -> str:
+  @classmethod
+  def type_name(cls) -> str:
     return "chrome"
diff --git a/crossbench/browsers/chrome/chrome.py b/crossbench/browsers/chrome/chrome.py
index c8c44c28..2258b38b 100644
--- a/crossbench/browsers/chrome/chrome.py
+++ b/crossbench/browsers/chrome/chrome.py
@@ -4,13 +4,16 @@
 
 from __future__ import annotations
 
+from typing_extensions import override
+
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chrome.helper import ChromePathMixin
-from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.browsers.chrome.base import ChromeBaseMixin
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
 
 
-class Chrome(ChromePathMixin, Chromium):
+class Chrome(ChromeBaseMixin, ChromiumBased):
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
diff --git a/crossbench/browsers/chrome/downloader.py b/crossbench/browsers/chrome/downloader.py
index 8aa93323..10125ab4 100644
--- a/crossbench/browsers/chrome/downloader.py
+++ b/crossbench/browsers/chrome/downloader.py
@@ -5,20 +5,23 @@
 from __future__ import annotations
 
 import contextlib
-import json
 import logging
+import os
+import shutil
 import tempfile
 import zipfile
 from typing import (TYPE_CHECKING, Dict, Final, Iterable, List, Optional, Tuple,
-                    Type, Union, cast)
+                    Type, cast)
+
+from typing_extensions import override
 
-from crossbench import helper
 from crossbench import path as pth
 from crossbench.browsers.chrome.version import ChromeVersion
 from crossbench.browsers.downloader import (DMGArchiveHelper, Downloader,
                                             IncompatibleVersionError,
                                             RPMArchiveHelper)
 from crossbench.browsers.version import BrowserVersion, BrowserVersionChannel
+from crossbench.helper import url_helper
 from crossbench.plt.android_adb import AndroidAdbPlatform
 from crossbench.plt.base import SubprocessError
 
@@ -41,12 +44,13 @@ class ChromeDownloader(Downloader):
       ("android", "arm64"): "android",
   }
 
-  def __init__(self, *args, **kwargs):
-    self._gsutil: Optional[pth.AnyPath] = None
+  def __init__(self, *args, **kwargs) -> None:
+    self._gsutil: pth.AnyPath | None = None
     super().__init__(*args, **kwargs)
 
   @classmethod
-  def is_valid_version(cls, path_or_identifier: str):
+  @override
+  def is_valid_version(cls, path_or_identifier: str) -> bool:
     return ChromeVersion.is_valid_unique(path_or_identifier)
 
   @classmethod
@@ -59,6 +63,7 @@ class ChromeDownloader(Downloader):
             path.name.endswith(cls.ARCHIVE_SUFFIX))
 
   @classmethod
+  @override
   def _get_loader_cls(cls,
                       browser_platform: Platform) -> Type[ChromeDownloader]:
     if browser_platform.is_macos:
@@ -73,6 +78,7 @@ class ChromeDownloader(Downloader):
         "Downloading chrome is only supported on linux and macOS, "
         f"but not on {browser_platform.name} {browser_platform.machine}")
 
+  @override
   def _pre_check(self) -> None:
     super()._pre_check()
     if not self._requested_version:
@@ -91,12 +97,15 @@ class ChromeDownloader(Downloader):
     assert self._gsutil, "gsutil not be found."
     return self._gsutil
 
+  @override
   def _requested_version_validation(self) -> None:
     pass
 
+  @override
   def _parse_version(self, version_identifier: str) -> BrowserVersion:
     return ChromeVersion.parse_unique(version_identifier)
 
+  @override
   def _find_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
     # Quick probe for complete versions
     if self._requested_version.is_complete:
@@ -123,14 +132,14 @@ class ChromeDownloader(Downloader):
     logging.debug("LIST ALL VERSIONS for M%s: %s", milestone, url)
     version_urls: List[Tuple[BrowserVersion, str]] = []
     try:
-      with helper.urlopen(url) as response:
-        raw_infos = json.loads(response.read().decode("utf-8"))["versions"]
-        version_urls = [
-            self._create_version_url(
-                ChromeVersion(
-                    map(int, info["version"].split(".")), requested_channel))
-            for info in raw_infos
-        ]
+      response = url_helper.get(url, retry=3)
+      raw_infos = response.json()["versions"]
+      version_urls = [
+          self._create_version_url(
+              ChromeVersion(
+                  map(int, info["version"].split(".")), requested_channel))
+          for info in raw_infos
+      ]
     except Exception as e:
       raise ValueError(
           f"Could not find version {self._requested_version} "
@@ -173,6 +182,7 @@ class ChromeDownloader(Downloader):
           return archive_version, archive_url
     return self._requested_version, None
 
+  @override
   def _download_archive(self, archive_url: str, tmp_dir: pth.LocalPath) -> None:
     self.host_platform.sh(self.gsutil, "cp", archive_url, tmp_dir)
     archive_candidates = list(tmp_dir.glob("*"))
@@ -182,20 +192,20 @@ class ChromeDownloader(Downloader):
     candidate = archive_candidates[0]
     assert not self._archive_path.exists(), (
         f"Archive was already downloaded: {self._archive_path}")
-    candidate.replace(self._archive_path)
+    shutil.move(os.fspath(candidate), os.fspath(self._archive_path))
 
 
 class ChromeDownloaderLinux(ChromeDownloader):
   ARCHIVE_SUFFIX: str = ".rpm"
 
   @classmethod
+  @override
   def is_valid(cls, path_or_identifier: pth.AnyPathLike,
                browser_platform: Platform) -> bool:
     return cls._is_valid(path_or_identifier, browser_platform)
 
-  def __init__(self, version_identifier: Union[str, pth.LocalPath],
-               browser_type: str, platform_name: str,
-               browser_platform: Platform):
+  def __init__(self, version_identifier: str | pth.LocalPath, browser_type: str,
+               platform_name: str, browser_platform: Platform) -> None:
     assert not browser_type
     if browser_platform.is_linux and browser_platform.is_x64:
       platform_name = "linux64"
@@ -205,14 +215,20 @@ class ChromeDownloaderLinux(ChromeDownloader):
     super().__init__(version_identifier, "chrome", platform_name,
                      browser_platform)
 
+  @override
   def _installed_app_path(self) -> pth.LocalPath:
     dir_name = "chrome-unstable"
     if self._requested_version.is_stable or self._requested_version.is_unknown:
       dir_name = "chrome"
     if self._requested_version.is_beta:
       dir_name = "chrome-beta"
+    if self._requested_version.is_alpha:
+      dir_name = "chrome-unstable"
+    if self._requested_version.is_pre_alpha:
+      dir_name = "chrome-canary"
     return self._extracted_path() / "opt/google" / dir_name / "chrome"
 
+  @override
   def _archive_urls(
       self, folder_url: str,
       version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
@@ -226,14 +242,17 @@ class ChromeDownloaderLinux(ChromeDownloader):
             f"{folder_url}google-chrome-beta-{parts_str}-1.x86_64.rpm")
     if version.is_beta:
       return (beta,)
-    dev = (ChromeVersion.alpha(parts),
+    dev = (ChromeVersion.dev(parts),
            f"{folder_url}google-chrome-unstable-{parts_str}-1.x86_64.rpm")
     if version.is_alpha:
       return (dev,)
+    canary = (ChromeVersion.canary(parts),
+              f"{folder_url}google-chrome-canary-{parts_str}-1.x86_64.rpm")
     if version.is_pre_alpha:
-      raise ValueError(f"Canary not supported on linux: {version}")
-    return (stable, beta, dev)
+      return (canary,)
+    return (stable, beta, dev, canary)
 
+  @override
   def _install_archive(self, archive_path: pth.LocalPath) -> None:
     extracted_path = self._extracted_path()
     RPMArchiveHelper.extract(self.host_platform, archive_path, extracted_path)
@@ -245,19 +264,20 @@ class ChromeDownloaderMacOS(ChromeDownloader):
   MIN_MAC_ARM64_MILESTONE: Final[int] = 87
 
   @classmethod
+  @override
   def is_valid(cls, path_or_identifier: pth.AnyPathLike,
                browser_platform: Platform) -> bool:
     return cls._is_valid(path_or_identifier, browser_platform)
 
-  def __init__(self, version_identifier: Union[str, pth.LocalPath],
-               browser_type: str, platform_name: str,
-               browser_platform: Platform):
+  def __init__(self, version_identifier: str | pth.LocalPath, browser_type: str,
+               platform_name: str, browser_platform: Platform) -> None:
     assert not browser_type
     assert browser_platform.is_macos, f"{type(self)} can only be used on macOS"
     platform_name = "mac-universal"
     super().__init__(version_identifier, "chrome", platform_name,
                      browser_platform)
 
+  @override
   def _requested_version_validation(self) -> None:
     assert self._browser_platform.is_macos
     major_version: int = self._requested_version.major
@@ -267,6 +287,7 @@ class ChromeDownloaderMacOS(ChromeDownloader):
           "Native Mac arm64/m1 Chrome version is available with M87, "
           f"but requested M{major_version}.")
 
+  @override
   def _download_archive(self, archive_url: str, tmp_dir: pth.LocalPath) -> None:
     assert self._browser_platform.is_macos
     if self._browser_platform.is_arm64 and (self._requested_version.major
@@ -276,6 +297,7 @@ class ChromeDownloaderMacOS(ChromeDownloader):
           f"but requested {self._requested_version} is too old.")
     super()._download_archive(archive_url, tmp_dir)
 
+  @override
   def _archive_urls(
       self, folder_url: str,
       version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
@@ -290,23 +312,26 @@ class ChromeDownloaderMacOS(ChromeDownloader):
             f"{folder_url}GoogleChromeBeta-{version_str}.dmg")
     if version.is_beta:
       return (beta,)
-    dev = (ChromeVersion.alpha(parts),
+    dev = (ChromeVersion.dev(parts),
            f"{folder_url}GoogleChromeDev-{version_str}.dmg")
     if version.is_alpha:
       return (dev,)
-    canary = (ChromeVersion.pre_alpha(parts),
+    canary = (ChromeVersion.canary(parts),
               f"{folder_url}GoogleChromeCanary-{version_str}.dmg")
     if version.is_pre_alpha:
       return (canary,)
     return (stable, beta, dev, canary)
 
+  @override
   def _extracted_path(self) -> pth.LocalPath:
     # TODO: support local vs remote
     return self._installed_app_path()
 
+  @override
   def _installed_app_path(self) -> pth.LocalPath:
     return self._out_dir / f"Google Chrome {self._requested_version}.app"
 
+  @override
   def _install_archive(self, archive_path: pth.LocalPath) -> None:
     extracted_path = self._extracted_path()
     if archive_path.suffix == ".dmg":
@@ -341,13 +366,13 @@ class ChromeDownloaderAndroid(ChromeDownloader):
   }
 
   @classmethod
+  @override
   def is_valid(cls, path_or_identifier: pth.AnyPathLike,
                browser_platform: Platform) -> bool:
     return cls._is_valid(path_or_identifier, browser_platform)
 
-  def __init__(self, version_identifier: Union[str, pth.LocalPath],
-               browser_type: str, platform_name: str,
-               browser_platform: Platform):
+  def __init__(self, version_identifier: str | pth.LocalPath, browser_type: str,
+               platform_name: str, browser_platform: Platform) -> None:
     assert not browser_type
     assert browser_platform.is_android, (
         f"{type(self)} can only be used on Android")
@@ -362,11 +387,13 @@ class ChromeDownloaderAndroid(ChromeDownloader):
   def adb(self) -> Adb:
     return cast(AndroidAdbPlatform, self._browser_platform).adb
 
+  @override
   def _pre_check(self) -> None:
     super()._pre_check()
     assert self._browser_platform.is_android, (
         f"Expected android but got {self._browser_platform}")
 
+  @override
   def _requested_version_validation(self) -> None:
     assert self._browser_platform.is_android
     # TODO: support custom android builds
@@ -375,6 +402,7 @@ class ChromeDownloaderAndroid(ChromeDownloader):
     else:
       self._platform_name = self.ARM_64_HIGH_BUILD
 
+  @override
   def _installed_app_version(self, app_path: pth.LocalPath) -> BrowserVersion:
     raw_version = self._browser_platform.app_version(app_path)
     channel = BrowserVersionChannel.STABLE
@@ -385,6 +413,7 @@ class ChromeDownloaderAndroid(ChromeDownloader):
         break
     return ChromeVersion.parse(raw_version, channel)
 
+  @override
   def _archive_urls(
       self, folder_url: str,
       version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
@@ -416,9 +445,11 @@ class ChromeDownloaderAndroid(ChromeDownloader):
     #   return "Monochrome"
     return "TrichromeChromeGoogle6432"
 
+  @override
   def _extracted_path(self) -> pth.LocalPath:
     return self._archive_path
 
+  @override
   def _installed_app_path(self) -> pth.LocalPath:
     for channel, (package_name, _) in self.CHANNEL_PACKAGE_LOOKUP.items():
       if channel in self._archive_url:
@@ -427,6 +458,7 @@ class ChromeDownloaderAndroid(ChromeDownloader):
     package_name, _ = self.CHANNEL_PACKAGE_LOOKUP["Stable"]
     return pth.LocalPath(package_name)
 
+  @override
   def _find_matching_installed_version(self) -> Optional[pth.LocalPath]:
     # TODO: we should use aapt and read the package name directly from
     # the apk: `aapt dump badging <path-to-apk> | grep package:\ name`
@@ -446,6 +478,7 @@ class ChromeDownloaderAndroid(ChromeDownloader):
         logging.debug("Ignoring installed package %s: %s", package_name, e)
     return None
 
+  @override
   def _download_archive(self, archive_url: str, tmp_dir: pth.LocalPath) -> None:
     super()._download_archive(archive_url, tmp_dir)
     if "TrichromeChromeGoogle" not in archive_url:
@@ -472,6 +505,7 @@ class ChromeDownloaderAndroid(ChromeDownloader):
       yield lib_url, lib_tmp_dir
     self._archive_path = main_archive_path
 
+  @override
   def _install_archive(self, archive_path: pth.LocalPath) -> None:
     # TODO: move browser installation to browser startup to allow
     # multiple versions on android in a single crossbench invocation
@@ -489,19 +523,20 @@ class ChromeDownloaderWin(ChromeDownloader):
   STORAGE_URL: str = "gs://chrome-unsigned/desktop-5c0tCh/"
 
   @classmethod
+  @override
   def is_valid(cls, path_or_identifier: pth.AnyPathLike,
                browser_platform: Platform) -> bool:
     return cls._is_valid(path_or_identifier, browser_platform)
 
-  def __init__(self, version_identifier: Union[str, pth.LocalPath],
-               browser_type: str, platform_name: str,
-               browser_platform: Platform):
+  def __init__(self, version_identifier: str | pth.LocalPath, browser_type: str,
+               platform_name: str, browser_platform: Platform) -> None:
     assert not browser_type
     assert browser_platform.is_win, f"{type(self)} can only be used on windows"
     platform_name = "win64-clang"
     super().__init__(version_identifier, "chrome", platform_name,
                      browser_platform)
 
+  @override
   def _archive_urls(
       self, folder_url: str,
       version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
@@ -510,13 +545,16 @@ class ChromeDownloaderWin(ChromeDownloader):
               f"{folder_url}{self.ARCHIVE_STEM}.zip")
     return (stable,)
 
+  @override
   def _extracted_path(self) -> pth.LocalPath:
     # TODO: support local vs remote
     return self._out_dir / f"Google Chrome {self._requested_version}"
 
+  @override
   def _installed_app_path(self) -> pth.LocalPath:
     return self._extracted_path() / "chrome.exe"
 
+  @override
   def _install_archive(self, archive_path: pth.LocalPath) -> None:
     extracted_path = self._extracted_path()
     tmp_path = self.host_platform.mkdtemp()
diff --git a/crossbench/browsers/chrome/version.py b/crossbench/browsers/chrome/version.py
index 4f01cd47..5fe36a0b 100644
--- a/crossbench/browsers/chrome/version.py
+++ b/crossbench/browsers/chrome/version.py
@@ -5,7 +5,9 @@
 from __future__ import annotations
 
 import re
-from typing import Optional
+from typing import Iterable, Optional, Self
+
+from typing_extensions import override
 
 from crossbench.browsers.chromium.version import ChromiumVersion
 
@@ -13,20 +15,31 @@ from crossbench.browsers.chromium.version import ChromiumVersion
 class ChromeVersion(ChromiumVersion):
 
   _PREFIX_RE = re.compile(
-      r"(?:google )?chr(?:ome)?[- ]?"
+      r"(?:google )?chr(?:ome(?: for testing)?)?[- ]?"
       rf"(?:{ChromiumVersion._CHANNEL_RE.pattern})?[- ]?m?", re.I)
 
   @classmethod
+  @override
   def _validate_prefix(cls, prefix: Optional[str]) -> bool:
     if not prefix:
       return True
     prefix = prefix.lower()
     if prefix.strip() == "m":
       return True
-    return bool(cls._PREFIX_RE.fullmatch(prefix))
+    return (bool(cls._PREFIX_RE.fullmatch(prefix)) or
+            super()._validate_prefix(prefix))
 
   @classmethod
+  @override
   def _validate_suffix(cls, suffix: Optional[str]) -> bool:
     if suffix and "(Official Build)" in suffix:
       return True
     return super()._validate_suffix(suffix)
+
+  @classmethod
+  def dev(cls, parts: Iterable[int], version_str: str = "") -> Self:
+    return cls.alpha(parts, version_str)
+
+  @classmethod
+  def canary(cls, parts: Iterable[int], version_str: str = "") -> Self:
+    return cls.pre_alpha(parts, version_str)
diff --git a/crossbench/browsers/chrome/webdriver.py b/crossbench/browsers/chrome/webdriver.py
index 14bb37d6..fa7168ed 100644
--- a/crossbench/browsers/chrome/webdriver.py
+++ b/crossbench/browsers/chrome/webdriver.py
@@ -11,13 +11,15 @@ import selenium.common.exceptions
 from selenium import webdriver
 from selenium.webdriver.chrome.options import Options as ChromeOptions
 from selenium.webdriver.chrome.service import Service as ChromeService
+from typing_extensions import override
 
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chrome.helper import ChromePathMixin
+from crossbench.browsers.chrome.base import ChromeBaseMixin
 from crossbench.browsers.chromium.webdriver import (
-    ChromiumWebDriver, ChromiumWebDriverAndroid, ChromiumWebDriverChromeOsSsh,
-    ChromiumWebDriverSsh, LocalChromiumWebDriverAndroid,
-    build_chromedriver_instructions)
+    ChromiumBasedWebDriver, ChromiumWebDriverAndroid,
+    ChromiumWebDriverChromeOsSsh, ChromiumWebDriverSsh,
+    LocalChromiumWebDriverAndroid)
+from crossbench.browsers.chromium_based import helper
 from crossbench.browsers.webdriver import DriverException
 
 if TYPE_CHECKING:
@@ -26,16 +28,18 @@ if TYPE_CHECKING:
   from selenium.webdriver.chromium.webdriver import ChromiumDriver
 
 
-class ChromeWebDriver(ChromePathMixin, ChromiumWebDriver):
+class ChromeWebDriver(ChromeBaseMixin, ChromiumBasedWebDriver):
 
   WEB_DRIVER_OPTIONS = ChromeOptions
   WEB_DRIVER_SERVICE = ChromeService
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return (BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
             | BrowserAttributes.WEBDRIVER)
 
+  @override
   def _create_driver(self, options: ChromiumOptions,
                      service: ChromiumService) -> ChromiumDriver:
     assert isinstance(options, ChromeOptions)
@@ -44,15 +48,8 @@ class ChromeWebDriver(ChromePathMixin, ChromiumWebDriver):
       return webdriver.Chrome(options=options, service=service)
     except selenium.common.exceptions.WebDriverException as e:
       msg: List[str] = [f"Could not start WebDriver: {e.msg}"]
-      if self.platform.is_android:
-        msg += [
-            f"Possibly missing chrome settings on {self.platform}.",
-            "Please make sure to allow chrome-flags on "
-            "non-rooted android devices:",
-            "chrome://flags#enable-command-line-on-non-rooted-devices",
-        ]
       if self.is_locally_compiled():
-        msg.append(build_chromedriver_instructions(self.app_path.parent))
+        msg.append(helper.build_chromedriver_instructions(self.app_path.parent))
       msg_str = "\n".join(msg)
       logging.error(msg_str)
       raise DriverException(msg_str) from e
diff --git a/crossbench/browsers/chromium/applescript.py b/crossbench/browsers/chromium/applescript.py
index ece4eaeb..596fb918 100644
--- a/crossbench/browsers/chromium/applescript.py
+++ b/crossbench/browsers/chromium/applescript.py
@@ -4,15 +4,18 @@
 
 from __future__ import annotations
 
+from typing_extensions import override
+
 from crossbench.browsers.applescript import AppleScriptBrowser
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.browsers.chromium.base import ChromiumBaseMixin
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
 
 
 # TODO: fix https://source.chromium.org/chromium/chromium/src/+/main:chrome/browser/ui/browser_commands_mac.mm;drc=ddf482c0cf47fc8e47e5cfc5c112e2313e066cb8;bpv=1;bpt=1;l=38
 # TODO: Auto-set: prefs::kAllowJavascriptAppleEvents
 # TODO: add --enable-automation flag
-class ChromiumAppleScript(Chromium, AppleScriptBrowser):
+class ChromiumAppleScript(ChromiumBaseMixin, ChromiumBased, AppleScriptBrowser):
   APPLE_SCRIPT_ALLOW_JS_MENU: str = (
       "View > Developer > Allow JavaScript from Apple Events")
   APPLE_SCRIPT_JS_COMMAND: str = (
@@ -20,10 +23,12 @@ class ChromiumAppleScript(Chromium, AppleScriptBrowser):
   APPLE_SCRIPT_SET_URL: str = (
       "set URL of the active tab of front window to %(url)s")
 
+  @override
   def _setup_window(self) -> None:
     pass
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return (BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
             | BrowserAttributes.APPLESCRIPT)
diff --git a/crossbench/browsers/chromium/base.py b/crossbench/browsers/chromium/base.py
new file mode 100644
index 00000000..e60d6c8e
--- /dev/null
+++ b/crossbench/browsers/chromium/base.py
@@ -0,0 +1,36 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type
+
+from crossbench.browsers.chromium.version import ChromiumVersion
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath
+  from crossbench.plt.base import Platform
+
+
+class ChromiumBaseMixin:
+
+  @classmethod
+  def version_cls(cls) -> Type[ChromiumVersion]:
+    return ChromiumVersion
+
+  @classmethod
+  def default_path(cls, platform: Platform) -> AnyPath:
+    return cls.canary_path(platform)
+
+  @classmethod
+  def canary_path(cls, platform: Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Chromium",
+        macos=["Chromium.app"],
+        linux=["google-chromium", "chromium"],
+        win=["Google/Chromium/Application/chromium.exe"])
+
+  @classmethod
+  def type_name(cls) -> str:
+    return "chromium"
diff --git a/crossbench/browsers/chromium/chromium.py b/crossbench/browsers/chromium/chromium.py
index e01bf17b..48acb382 100644
--- a/crossbench/browsers/chromium/chromium.py
+++ b/crossbench/browsers/chromium/chromium.py
@@ -1,256 +1,24 @@
-# Copyright 2022 The Chromium Authors
+# Copyright 2024 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
 from __future__ import annotations
 
-import argparse
-import logging
-import re
-from typing import TYPE_CHECKING, Optional, TextIO, Tuple, cast
+from typing_extensions import override
 
-from crossbench import path as pth
-from crossbench import plt
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.browser import Browser
-from crossbench.browsers.browser_helper import convert_flags_to_label
-from crossbench.browsers.viewport import Viewport
-from crossbench.flags.chrome import ChromeFeatures, ChromeFlags
-from crossbench.types import JsonDict
+from crossbench.browsers.chromium.base import ChromiumBaseMixin
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
 
-if TYPE_CHECKING:
-  from crossbench.browsers.settings import Settings
-  from crossbench.flags.base import Flags, FlagsData
-  from crossbench.flags.js_flags import JSFlags
-  from crossbench.runner.groups.session import BrowserSessionRunGroup
 
-
-class Chromium(Browser):
-  MIN_HEADLESS_NEW_VERSION: int = 112
-  DEFAULT_FLAGS: Tuple[str, ...] = (
-      "--no-default-browser-check",
-      "--disable-component-update",
-      "--disable-sync",
-      "--disable-extensions",
-      "--no-first-run",
-      # This could be enabled via feature-flags as well.
-      "--disable-search-engine-choice-screen",
-  )
-  FLAGS_FOR_DISABLING_BACKGROUND_INTERVENTIONS: Tuple[str, ...] = (
-      "--disable-background-timer-throttling",
-      "--disable-renderer-backgrounding",
-  )
-  # All flags that might affect how finch / field-trials are loaded.
-  FIELD_TRIAL_FLAGS: Tuple[str, ...] = (
-      "--force-fieldtrials",
-      "--variations-server-url",
-      "--variations-insecure-server-url",
-      "--variations-test-seed-path",
-      "--enable-field-trial-config",
-      "--disable-variations-safe-mode",
-  )
-  NO_EXPERIMENTS_FLAGS: Tuple[str, ...] = (
-      "--no-experiments",
-      "--enable-benchmarking",
-      "--disable-field-trial-config",
-  )
+class Chromium(ChromiumBaseMixin, ChromiumBased):
 
   @classmethod
-  def default_path(cls, platform: plt.Platform) -> pth.AnyPath:
-    return platform.search_app_or_executable(
-        "Chromium",
-        macos=["Chromium.app"],
-        linux=["google-chromium", "chromium"],
-        win=["Google/Chromium/Application/chromium.exe"])
+  @override
+  def attributes(cls) -> BrowserAttributes:
+    return BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
 
   @classmethod
-  def default_flags(cls, initial_data: FlagsData = None) -> ChromeFlags:
-    return ChromeFlags(initial_data)
-
-  def __init__(self,
-               label: str,
-               path: pth.AnyPath,
-               settings: Optional[Settings] = None):
-    super().__init__(label, path, settings=settings)
-    self._stdout_log_file: Optional[TextIO] = None
-    assert isinstance(self._flags, ChromeFlags)
-
-  def _setup_flags(self, settings: Settings) -> ChromeFlags:
-    flags: Flags = settings.flags
-    js_flags: Flags = settings.js_flags
-    self._flags = self.default_flags(self.DEFAULT_FLAGS)
-    self._flags.update(flags)
-
-    if "--allow-background-interventions" in self._flags.data:
-      # The --allow-background-interventions flag should have no value.
-      assert self._flags.get("--allow-background-interventions") is None
-    else:
-      self._flags.update(self.FLAGS_FOR_DISABLING_BACKGROUND_INTERVENTIONS)
-
-    # Explicitly disable field-trials by default on all chrome flavours:
-    # By default field-trials are enabled on non-Chrome branded builds, but
-    # are auto-enabled on everything else. This gives very confusing results
-    # when comparing local builds to official binaries.
-    field_trial_flags = [
-        flag for flag in self.FIELD_TRIAL_FLAGS if flag in self._flags
-    ]
-    if not field_trial_flags:
-      logging.info("Disabling experiments/finch/field-trials for %s", self)
-      for flag in self.NO_EXPERIMENTS_FLAGS:
-        self._flags.set(flag)
-    else:
-      logging.warning("Running with field-trials or finch experiments.")
-      no_finch_flags = [
-          flag for flag in self.NO_EXPERIMENTS_FLAGS if flag in self._flags
-      ]
-      if no_finch_flags:
-        raise argparse.ArgumentTypeError(
-            "Conflicting flag groups set: "
-            f"{field_trial_flags} vs {no_finch_flags}.\n"
-            "Cannot enable and disable finch / field-trials at the same time.")
-
-    self.js_flags.update(js_flags)
-    self._maybe_disable_gpu_compositing()
-    return self._flags
-
-  def _maybe_disable_gpu_compositing(self) -> None:
-    # Chrome Remote Desktop provide no GPU and older chrome versions
-    # don't handle this well.
-    if self.major_version > 92 or ("CHROME_REMOTE_DESKTOP_SESSION"
-                                   not in self.platform.environ):
-      return
-    self.flags.set("--disable-gpu-compositing")
-    self.flags.set("--no-sandbox")
-
-  def _setup_cache_dir(self, settings: Settings) -> None:
-    cache_dir = settings.cache_dir
-    if cache_dir is None:
-      maybe_cache_dir = self._flags.get("--user-data-dir", None)
-      if maybe_cache_dir:
-        cache_dir = pth.AnyPath(maybe_cache_dir)
-    if cache_dir is None:
-      self.cache_dir = self.platform.mkdtemp(prefix=self.type_name)
-      self.clear_cache_dir = True
-    else:
-      self.cache_dir = cache_dir
-      self.clear_cache_dir = False
-
-  def _extract_version(self) -> str:
-    assert self.path
-    version_string = self.platform.app_version(self.path)
-    # Sample output: "Chromium 90.0.4430.212 dev" => "90.0.4430.212"
-    matches = re.findall(r"[\d\.]+", version_string)
-    if not matches:
-      raise ValueError(
-          f"Could not extract version number from '{version_string}' "
-          f"for '{self.path}'")
-    return str(matches[0])
-
-  @property
-  def type_name(self) -> str:
+  @override
+  def type_name(cls) -> str:
     return "chromium"
-
-  @property
-  def attributes(self) -> BrowserAttributes:
-    return BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
-
-  @property
-  def is_headless(self) -> bool:
-    return "--headless" in self._flags
-
-  @property
-  def chrome_log_file(self) -> pth.AnyPath:
-    assert self.log_file
-    return self.log_file.with_suffix(f".{self.type_name}.log")
-
-  @property
-  def flags(self) -> ChromeFlags:
-    return cast(ChromeFlags, self._flags)
-
-  @property
-  def js_flags(self) -> JSFlags:
-    return cast(ChromeFlags, self._flags).js_flags
-
-  @property
-  def features(self) -> ChromeFeatures:
-    return cast(ChromeFlags, self._flags).features
-
-  def details_json(self) -> JsonDict:
-    details: JsonDict = super().details_json()
-    if self.log_file:
-      log = cast(JsonDict, details["log"])
-      log[self.type_name] = str(self.chrome_log_file)
-      log["stdout"] = str(self.stdout_log_file)
-    details["js_flags"] = tuple(self.js_flags)
-    return details
-
-  def _get_browser_flags_for_session(
-      self, session: BrowserSessionRunGroup) -> Tuple[str, ...]:
-    js_flags_copy = self.js_flags.copy()
-    js_flags_copy.update(session.extra_js_flags)
-
-    flags_copy = self.flags.copy()
-    flags_copy.update(session.extra_flags)
-    flags_copy.update(self.network.extra_flags(self.attributes))
-    self._handle_viewport_flags(flags_copy)
-
-    if len(js_flags_copy):
-      flags_copy["--js-flags"] = str(js_flags_copy)
-    if user_data_dir := self.flags.get("--user-data-dir"):
-      assert user_data_dir == str(
-          self.cache_dir), (f"--user-data-dir path: {user_data_dir} was passed "
-                            f"but does not match cache-dir: {self.cache_dir}")
-    if self.cache_dir:
-      flags_copy["--user-data-dir"] = str(self.cache_dir)
-    if self.log_file:
-      flags_copy.set("--enable-logging")
-      flags_copy["--log-file"] = str(self.chrome_log_file)
-
-    flags_copy = self._filter_flags_for_run(flags_copy)
-
-    return tuple(flags_copy)
-
-  def _handle_viewport_flags(self, flags: Flags) -> None:
-    self._sync_viewport_flag(flags, "--start-fullscreen",
-                             self.viewport.is_fullscreen, Viewport.FULLSCREEN)
-    self._sync_viewport_flag(flags, "--start-maximized",
-                             self.viewport.is_maximized, Viewport.MAXIMIZED)
-    self._sync_viewport_flag(flags, "--headless", self.viewport.is_headless,
-                             Viewport.HEADLESS)
-    # M112 added --headless=new as replacement for --headless
-    if "--headless" in flags and (self.major_version >=
-                                  self.MIN_HEADLESS_NEW_VERSION):
-      if flags["--headless"] is None:
-        logging.info("Replacing --headless with --headless=new")
-        flags.set("--headless", "new", override=True)
-
-    if self.viewport.is_default:
-      update_viewport = False
-      width, height = self.viewport.size
-      x, y = self.viewport.position
-      if "--window-size" in flags:
-        update_viewport = True
-        width, height = map(int, flags["--window-size"].split(","))
-      if "--window-position" in flags:
-        update_viewport = True
-        x, y = map(int, flags["--window-position"].split(","))
-      if update_viewport:
-        self.viewport = Viewport(width, height, x, y)
-    if self.viewport.has_size:
-      flags["--window-size"] = f"{self.viewport.width},{self.viewport.height}"
-      flags["--window-position"] = f"{self.viewport.x},{self.viewport.y}"
-    else:
-      for flag in ("--window-position", "--window-size"):
-        if flag in flags:
-          flag_value = flags[flag]
-          raise ValueError(f"Viewport {self.viewport} conflicts with flag "
-                           f"{flag}={flag_value}")
-
-  def get_label_from_flags(self) -> str:
-    return convert_flags_to_label(*self.flags, *self.js_flags)
-
-  def quit(self) -> None:
-    super().quit()
-    if self._stdout_log_file:
-      self._stdout_log_file.close()
-      self._stdout_log_file = None
diff --git a/crossbench/browsers/chromium/driver_finder.py b/crossbench/browsers/chromium/driver_finder.py
new file mode 100644
index 00000000..355a758d
--- /dev/null
+++ b/crossbench/browsers/chromium/driver_finder.py
@@ -0,0 +1,408 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+import os
+import re
+import shutil
+import stat
+import tempfile
+import zipfile
+from typing import TYPE_CHECKING, Dict, Final, List, Optional, Tuple
+
+from crossbench import exception
+from crossbench import path as pth
+from crossbench.browsers.chrome.version import ChromeVersion
+from crossbench.browsers.chromium_based import helper
+from crossbench.helper import url_helper
+
+if TYPE_CHECKING:
+  from crossbench.browsers.chromium_based.webdriver import \
+      ChromiumBasedWebDriver
+  from crossbench.browsers.version import BrowserVersion
+  from crossbench.plt.base import Platform
+
+
+class ChromeDriverFinder:
+  driver_path: pth.LocalPath
+
+  def __init__(self, browser: ChromiumBasedWebDriver) -> None:
+    self.browser = browser
+    self.platform: Platform = browser.platform
+    self.host_platform: Platform = browser.platform.host_platform
+    extension: str = ""
+    if self.host_platform.is_win:
+      extension = ".exe"
+    cache_dir = self.host_platform.local_cache_dir("driver")
+    self.driver_path: pth.LocalPath = (
+        cache_dir / f"chromedriver-{self.browser.version.major}{extension}")
+    self._validate_browser()
+
+  def _validate_browser(self) -> None:
+    browser_platform = self.browser.platform
+    if browser_platform.is_local:
+      return
+    # Some remote platforms rely on a local chromedriver
+    if (browser_platform.is_android or browser_platform.is_remote_ssh):
+      return
+    raise RuntimeError("Cannot download chromedriver for remote browser yet")
+
+  def find_local_build(self) -> pth.LocalPath:
+    assert self.browser.app_path
+    # assume it's a local build
+    lookup_dir = pth.LocalPath(self.browser.app_path.parent)
+    driver_path = lookup_dir / "chromedriver"
+    if self.platform.is_win:
+      driver_path = driver_path.with_suffix(".exe")
+    if self.platform.is_file(driver_path):
+      return driver_path
+    error_message: List[str] = [f"Driver '{driver_path}' does not exist."]
+    if helper.is_build_dir(lookup_dir, self.platform):
+      error_message += [helper.build_chromedriver_instructions(lookup_dir)]
+    else:
+      error_message += ["Please manually provide a chromedriver binary."]
+    raise DriverNotFoundError("\n".join(error_message))
+
+  def download(self) -> pth.LocalPath:
+    if not self.host_platform.is_file(self.driver_path):
+      with exception.annotate(
+          f"Downloading chromedriver for {self.browser.version}"):
+        self._download()
+    return self.driver_path
+
+  def _download(self) -> None:
+    milestone = self.browser.version.major
+    logging.info("CHROMEDRIVER Downloading from %s v%s",
+                 self.browser.type_name(), milestone)
+    if self._try_download_cft(milestone):
+      return
+    if self._try_download_pre_115_stable(milestone):
+      return
+    if self._try_download_canary(milestone):
+      return
+    raise DriverNotFoundError(
+        "Please manually compile/download chromedriver for "
+        f"{self.browser.type_name()} {self.browser.version}")
+
+  def _try_download_cft(self, milestone: int) -> bool:
+    if milestone < self.CFT_MIN_MILESTONE:
+      return False
+    listing_url, url = self._get_cft_url(milestone)
+    return self._try_download_url(milestone, url, listing_url)
+
+  def _try_download_pre_115_stable(self, milestone: int) -> bool:
+    listing_url, url = self._get_pre_115_stable_url(milestone)
+    return self._try_download_url(milestone, url, listing_url)
+
+  def _try_download_canary(self, milestone: int) -> bool:
+    listing_url, url = self._get_canary_url()
+    return self._try_download_url(milestone, url, listing_url)
+
+  def _try_download_url(self, milestone: int, url: Optional[str],
+                        listing_url: Optional[str]) -> bool:
+    if not url:
+      return False
+    logging.info("CHROMEDRIVER Downloading M%s: %s", milestone, listing_url or
+                 url)
+    maybe_driver: pth.LocalPath | None = None
+    with tempfile.TemporaryDirectory() as tmp_dir:
+      if ".zip" not in url:
+        maybe_driver = pth.LocalPath(tmp_dir) / "chromedriver"
+        self.host_platform.download_to(url, maybe_driver)
+      else:
+        maybe_driver = self._download_zip_url(url, tmp_dir)
+      if not maybe_driver or not maybe_driver.is_file():
+        raise DriverNotFoundError(
+            f"Extracted driver at {maybe_driver} does not exist.")
+      self.driver_path.parent.mkdir(parents=True, exist_ok=True)
+      shutil.move(os.fspath(maybe_driver), os.fspath(self.driver_path))
+      self.driver_path.chmod(self.driver_path.stat().st_mode | stat.S_IEXEC)
+    return True
+
+  def _download_zip_url(self, url: str,
+                        tmp_dir: str) -> Optional[pth.LocalPath]:
+    zip_file = pth.LocalPath(tmp_dir) / "download.zip"
+    self.host_platform.download_to(url, zip_file)
+    with zipfile.ZipFile(zip_file, "r") as zip_ref:
+      zip_ref.extractall(zip_file.parent)
+    zip_file.unlink()
+    candidates: List[pth.LocalPath] = [
+        path for path in zip_file.parent.glob("**/*")
+        if path.is_file() and "chromedriver" in path.name
+    ]
+    # Find exact match first:
+    maybe_drivers: List[pth.LocalPath] = [
+        path for path in candidates if path.stem == "chromedriver"
+    ]
+    # Backup less strict matching:
+    maybe_drivers += candidates
+    if not maybe_drivers:
+      return None
+    return maybe_drivers[0]
+
+  # Using CFT as abbreviation for Chrome For Testing here.
+  CFT_MIN_MILESTONE = 115
+  CFT_BASE_URL: str = "https://googlechromelabs.github.io/chrome-for-testing"
+  CFT_VERSION_URL: str = f"{CFT_BASE_URL}/{{version}}.json"
+  CFT_LATEST_URL: str = f"{CFT_BASE_URL}/LATEST_RELEASE_{{major}}"
+
+  CFT_PLATFORM: Final[Dict[Tuple[str, str], str]] = {
+      ("linux", "x64"): "linux64",
+      ("macos", "x64"): "mac-x64",
+      ("macos", "arm64"): "mac-arm64",
+      ("win", "ia32"): "win32",
+      ("win", "x64"): "win64"
+  }
+
+  def _get_cft_url(self, milestone: int) -> Tuple[str, Optional[str]]:
+    logging.debug("ChromeDriverFinder: Looking up chrome-for-testing version.")
+    platform_name: str | None = self.CFT_PLATFORM.get(self.host_platform.key)
+    if not platform_name:
+      raise DriverNotFoundError(
+          f"Unsupported platform {self.host_platform.key} for chromedriver.")
+    listing_url, version_data = self._get_cft_version_data(milestone)
+    download_url: str | None = None
+    if version_data:
+      download_url = self._get_cft_driver_download_url(version_data,
+                                                       platform_name)
+    return (listing_url, download_url)
+
+  def _get_cft_version_data(self, milestone: int) -> Tuple[str, Optional[Dict]]:
+    logging.debug("ChromeDriverFinder: Trying direct download url")
+    listing_url, data = self._get_cft_precise_version_data(self.browser.version)
+    if data:
+      return listing_url, data
+    logging.debug(
+        "ChromeDriverFinder: Invalid precise version url %s, "
+        "using M%s", listing_url, milestone)
+    return self._get_ctf_milestone_data(milestone)
+
+  def _get_cft_precise_version_data(
+      self, version: BrowserVersion) -> Tuple[str, Optional[Dict]]:
+    version_url: str = self.CFT_VERSION_URL.format(version=version.parts_str)
+    try:
+      response = url_helper.get(version_url)
+      version_data = response.json()
+      return (version_url, version_data)
+    except url_helper.RequestException as e:
+      logging.debug("ChromeDriverFinder: "
+                    "Precise version download failed %s", e)
+      return (version_url, None)
+
+  def _get_ctf_milestone_data(self,
+                              milestone: int) -> Tuple[str, Optional[Dict]]:
+    latest_version_url: str = self.CFT_LATEST_URL.format(major=milestone)
+    try:
+      response = url_helper.get(latest_version_url)
+      alternative_version = ChromeVersion.parse(response.text.strip())
+      logging.debug(
+          "ChromeDriverFinder: Using alternative version %s "
+          "for M%s", alternative_version, milestone)
+      return self._get_cft_precise_version_data(alternative_version)
+    except url_helper.RequestException:
+      return (self.CFT_BASE_URL, None)
+
+  def _get_cft_driver_download_url(self, version_data,
+                                   platform_name) -> Optional[str]:
+    if all_downloads := version_data.get("downloads"):
+      driver_downloads: Dict = all_downloads.get("chromedriver", [])
+      for download in driver_downloads:
+        if isinstance(download, dict) and download["platform"] == platform_name:
+          return download["url"]
+    return None
+
+  PRE_115_STABLE_URL: str = "http://chromedriver.storage.googleapis.com"
+
+  def _get_pre_115_stable_url(self,
+                              milestone: int) -> Tuple[str, Optional[str]]:
+    logging.debug(
+        "ChromeDriverFinder: "
+        "Looking upe old-style stable version M%s", milestone)
+    assert milestone < self.CFT_MIN_MILESTONE
+    listing_url = f"{self.PRE_115_STABLE_URL}/index.html"
+    driver_version: str | None = self._get_pre_115_driver_version(milestone)
+    if not driver_version:
+      return listing_url, None
+    if self.host_platform.is_linux:
+      arch_suffix = "linux64"
+    elif self.host_platform.is_macos:
+      arch_suffix = "mac64"
+      if self.host_platform.is_arm64:
+        # The uploaded chromedriver archives changed the naming scheme after
+        # chrome version 106.0.5249.21 for Arm64 (previously m1):
+        #   before: chromedriver_mac64_m1.zip
+        #   after:  chromedriver_mac_arm64.zip
+        last_old_naming_version = (106, 0, 5249, 21)
+        version_tuple = tuple(map(int, driver_version.split(".")))
+        if version_tuple <= last_old_naming_version:
+          arch_suffix = "mac64_m1"
+        else:
+          arch_suffix = "mac_arm64"
+    elif self.host_platform.is_win:
+      arch_suffix = "win32"
+    else:
+      raise DriverNotFoundError("Unsupported chromedriver platform")
+    url = (f"{self.PRE_115_STABLE_URL}/{driver_version}/"
+           f"chromedriver_{arch_suffix}.zip")
+    return listing_url, url
+
+  def _get_pre_115_driver_version(self, milestone) -> Optional[str]:
+    if milestone < 70:
+      return self._get_pre_70_driver_version(milestone)
+    url = f"{self.PRE_115_STABLE_URL}/LATEST_RELEASE_{milestone}"
+    try:
+      response = url_helper.get(url)
+      return response.text
+    except url_helper.HTTPError as e:
+      if e.response.status_code != 404:
+        raise DriverNotFoundError(f"Could not query {url}") from e
+      logging.debug("ChromeDriverFinder: Could not load latest release url %s",
+                    e)
+    return None
+
+  def _get_pre_70_driver_version(self, milestone) -> Optional[str]:
+    response = url_helper.get(f"{self.PRE_115_STABLE_URL}/2.46/notes.txt")
+    lines: List[str] = response.text.splitlines()
+    for i, line in enumerate(lines):
+      if not line.startswith("---"):
+        continue
+      [min_version, max_version] = map(int, re.findall(r"\d+", lines[i + 1]))
+      if min_version <= milestone <= max_version:
+        match = re.search(r"\d\.\d+", line)
+        if not match:
+          raise DriverNotFoundError(f"Could not parse version number: {line}")
+        return match.group(0)
+    return None
+
+  CHROMIUM_DASH_URL: str = "https://chromiumdash.appspot.com/fetch_releases"
+  CHROMIUM_LISTING_URL: str = (
+      "https://www.googleapis.com/storage/v1/b/chromium-browser-snapshots/o/")
+  CHROMIUM_DASH_PARAMS: Dict[Tuple[str, str], Dict] = {
+      ("linux", "x64"): {
+          "dash_platform": "linux",
+          "dash_channel": "dev",
+          "dash_limit": 10,
+      },
+      ("macos", "x64"): {
+          "dash_platform": "mac",
+      },
+      ("macos", "arm64"): {
+          "dash_platform": "mac",
+      },
+      ("win", "ia32"): {
+          "dash_platform": "win",
+      },
+      ("win", "x64"): {
+          "dash_platform": "win64",
+      },
+  }
+  CHROMIUM_LISTING_PREFIX: Dict[Tuple[str, str], str] = {
+      ("linux", "x64"): "Linux_x64",
+      ("macos", "x64"): "Mac",
+      ("macos", "arm64"): "Mac_Arm",
+      ("win", "ia32"): "Win",
+      ("win", "x64"): "Win_x64",
+  }
+
+  def _get_canary_url(self) -> Tuple[str, Optional[str]]:
+    logging.debug(
+        "ChromeDriverFinder: Try downloading the chromedriver canary version")
+    properties = self.CHROMIUM_DASH_PARAMS.get(self.host_platform.key)
+    if not properties:
+      raise DriverNotFoundError(
+          f"Unsupported platform={self.platform}, key={self.host_platform.key}")
+    dash_platform = properties["dash_platform"]
+    dash_channel = properties.get("dash_channel", "canary")
+    # Limit should be > len(canary_versions) so we also get potentially
+    # the latest dev version (only beta / stable have official driver binaries).
+    dash_limit = properties.get("dash_limit", 100)
+    url = url_helper.update_url_query(
+        self.CHROMIUM_DASH_URL, {
+            "platform": dash_platform,
+            "channel": dash_channel,
+            "milestone": str(self.browser.version.major),
+            "num": str(dash_limit),
+        })
+    chromium_base_position = 0
+    response = url_helper.get(url)
+    version_infos = list(response.json())
+    if not version_infos:
+      raise DriverNotFoundError("Could not find latest version info for "
+                                f"platform={self.host_platform}")
+    for version_info in version_infos:
+      if version_info["version"] == self.browser.version.parts_str:
+        chromium_base_position = int(
+            version_info["chromium_main_branch_position"])
+        break
+
+    if not chromium_base_position and version_infos:
+      fallback_version_info = None
+      # Try matching latest milestone
+      for version_info in version_infos:
+        if version_info["milestone"] == self.browser.version.major:
+          fallback_version_info = version_info
+          break
+
+      if not fallback_version_info:
+        # Android has a slightly different release cycle than the desktop
+        # versions. Assume that the latest canary version is good enough
+        fallback_version_info = version_infos[0]
+      chromium_base_position = int(
+          fallback_version_info["chromium_main_branch_position"])
+      logging.warning(
+          "Falling back to latest (not precisely matching) "
+          "canary chromedriver %s (expected %s)",
+          fallback_version_info["version"], self.browser.version)
+
+    if not chromium_base_position:
+      raise DriverNotFoundError("Could not find matching canary chromedriver "
+                                f"for {self.browser.version}")
+    # Use prefixes to limit listing results and increase chances of finding
+    # a matching version
+    listing_prefix = self.CHROMIUM_LISTING_PREFIX.get(self.host_platform.key)
+    if not listing_prefix:
+      raise NotImplementedError(
+          f"Unsupported chromedriver platform {self.host_platform}")
+    base_prefix = str(chromium_base_position)[:4]
+    listing_url: str = url_helper.update_url_query(self.CHROMIUM_LISTING_URL, {
+        "prefix": f"{listing_prefix}/{base_prefix}",
+        "maxResults": "10000"
+    })
+    listing = url_helper.get(listing_url).json()
+
+    versions: List[Tuple[int, str]] = []
+    logging.debug("Filtering %s candidate URLs.", len(listing["items"]))
+    for version in listing["items"]:
+      if "name" not in version:
+        continue
+      if "mediaLink" not in version:
+        continue
+      name = version["name"]
+      if "chromedriver" not in name:
+        continue
+      parts = name.split("/")
+      if "chromedriver" not in parts[-1] or len(parts) < 3:
+        continue
+      base = parts[1]
+      try:
+        int(base)
+      except ValueError:
+        # Ignore base if it is not an int
+        continue
+      versions.append((int(base), version["mediaLink"]))
+    versions.sort()
+    logging.debug("Found candidates: %s", versions)
+    logging.debug("chromium_base_position=%s", chromium_base_position)
+
+    for i, (base, url) in enumerate(versions):
+      if base > chromium_base_position:
+        base, url = versions[i - 1]
+        return listing_url, url
+    return listing_url, None
+
+
+class DriverNotFoundError(ValueError):
+  pass
diff --git a/crossbench/browsers/chromium/version.py b/crossbench/browsers/chromium/version.py
index 17e268ff..ebd456ac 100644
--- a/crossbench/browsers/chromium/version.py
+++ b/crossbench/browsers/chromium/version.py
@@ -7,6 +7,8 @@ from __future__ import annotations
 import re
 from typing import Dict, Final, Optional, Tuple
 
+from typing_extensions import override
+
 from crossbench.browsers.version import (BrowserVersion, BrowserVersionChannel,
                                          PartialBrowserVersionError)
 
@@ -32,6 +34,7 @@ class ChromiumVersion(BrowserVersion):
   _CHANNEL_RE = re.compile("|".join(_CHANNEL_LOOKUP.keys()), re.I)
 
   @classmethod
+  @override
   def _parse(
       cls,
       full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
@@ -130,10 +133,12 @@ class ChromiumVersion(BrowserVersion):
     return bool(cls._VALID_SUFFIX_MATCH.fullmatch(suffix))
 
   @property
+  @override
   def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
     return (self.comparable_parts(self._PARTS_LEN), self._channel)
 
   @property
+  @override
   def has_complete_parts(self) -> bool:
     return len(self.parts) == 4
 
@@ -157,6 +162,7 @@ class ChromiumVersion(BrowserVersion):
   def is_canary(self) -> bool:
     return self.is_pre_alpha
 
+  @override
   def _channel_name(self, channel: BrowserVersionChannel) -> str:
     if name := self._CHANNEL_NAME_LOOKUP[channel]:
       return name
@@ -167,18 +173,22 @@ class ChromeDriverVersion(ChromiumVersion):
   _EMPTY_COMMIT_HASH: Final = "0000000000000000000000000000000000000000"
 
   @classmethod
+  @override
   def _validate_prefix(cls, prefix: Optional[str]) -> bool:
     if not prefix:
       return False
-    return prefix.lower() in ("chromedriver ", "chromedriver-")
+    return prefix.lower() in ("chromedriver ", "chromedriver-",
+                              "microsoft edge webdriver ")
 
   @classmethod
+  @override
   def _parse_default_channel(cls, full_version: str) -> BrowserVersionChannel:
     if cls._EMPTY_COMMIT_HASH in full_version:
       return BrowserVersionChannel.PRE_ALPHA
     return BrowserVersionChannel.STABLE
 
   @classmethod
+  @override
   def _validate_suffix(cls, suffix: Optional[str]) -> bool:
     # TODO: extract commit hash / branch info from newer versions
     return True
diff --git a/crossbench/browsers/chromium/webdriver.py b/crossbench/browsers/chromium/webdriver.py
index c49745bb..2fb31e25 100644
--- a/crossbench/browsers/chromium/webdriver.py
+++ b/crossbench/browsers/chromium/webdriver.py
@@ -4,259 +4,43 @@
 
 from __future__ import annotations
 
-import abc
 import atexit
-import datetime as dt
-import json
 import logging
-import os
 import re
-import shutil
-import stat
-import tempfile
-import urllib.error
-import zipfile
-from typing import (TYPE_CHECKING, Any, Dict, Final, Iterable, List, Optional,
-                    Sequence, Tuple, Type, cast)
+import subprocess
+from typing import TYPE_CHECKING, Any, Optional, Sequence, Tuple, cast
 
 import hjson
 from immutabledict import immutabledict
-from selenium.webdriver.chromium.options import ChromiumOptions
-from selenium.webdriver.chromium.service import ChromiumService
-from selenium.webdriver.chromium.webdriver import ChromiumDriver
+from selenium.webdriver.chromium import webdriver as chromium_webdriver
 from selenium.webdriver.remote.webdriver import WebDriver as RemoteWebDriver
+from typing_extensions import override
 
-from crossbench import exception, helper
+from crossbench import exception
 from crossbench import path as pth
-from crossbench import plt
-from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chromium.chromium import Chromium
-from crossbench.browsers.chromium.version import (ChromeDriverVersion,
-                                                  ChromiumVersion)
-from crossbench.browsers.webdriver import WebDriverBrowser
-from crossbench.cli.config.secret_type import SecretType
-from crossbench.flags.chrome import ChromeFlags
+from crossbench.browsers.chromium.base import ChromiumBaseMixin
+from crossbench.browsers.chromium_based.webdriver import ChromiumBasedWebDriver
+from crossbench.cli.config.secrets import GoogleUsernamePassword
+from crossbench.helper import wait
+from crossbench.parse import NumberParser
 from crossbench.plt.android_adb import AndroidAdbPlatform
+from crossbench.plt.bin import Binaries
 from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
 from crossbench.plt.linux_ssh import LinuxSshPlatform
 
 if TYPE_CHECKING:
   from selenium import webdriver
+  from selenium.webdriver.chromium.options import ChromiumOptions
+  from selenium.webdriver.chromium.service import ChromiumService
 
   from crossbench.browsers.settings import Settings
-  from crossbench.cli.config.secrets import Secret
+  from crossbench.browsers.version import BrowserVersion
+  from crossbench.cli.config.secrets import UsernamePassword
   from crossbench.flags.base import FlagsT
   from crossbench.plt.base import Platform
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
 
-class ChromiumWebDriver(WebDriverBrowser, Chromium, metaclass=abc.ABCMeta):
-
-  WEB_DRIVER_OPTIONS: Type[ChromiumOptions] = ChromiumOptions
-  WEB_DRIVER_SERVICE: Type[ChromiumService] = ChromiumService
-
-  @property
-  def attributes(self) -> BrowserAttributes:
-    return (BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
-            | BrowserAttributes.WEBDRIVER)
-
-  def use_local_chromedriver(self) -> bool:
-    return self.major_version == 0 or self.is_locally_compiled()
-
-  def is_locally_compiled(self) -> bool:
-    return pth.LocalPath(self.app_path.parent / "args.gn").exists()
-
-  def _execute_cdp_cmd(self, driver: webdriver.Remote, cmd: str,
-                       cmd_args: dict):
-    return driver.execute("executeCdpCommand", {
-        "cmd": cmd,
-        "params": cmd_args
-    })["value"]
-
-  def _find_driver(self) -> pth.AnyPath:
-    if self._driver_path:
-      return self._driver_path
-    finder = ChromeDriverFinder(self)
-    assert self.app_path
-    if self.use_local_chromedriver():
-      return finder.find_local_build()
-    try:
-      return finder.download()
-    except DriverNotFoundError as original_download_error:
-      logging.debug(
-          "Could not download chromedriver, "
-          "falling back to finding local build: %s", original_download_error)
-      try:
-        return finder.find_local_build()
-      except DriverNotFoundError as e:
-        logging.debug("Could not find fallback chromedriver: %s", e)
-        raise original_download_error from e
-      # to make an old pytype version happy
-      return pth.LocalPath()
-
-  def _start_driver(self, session: BrowserSessionRunGroup,
-                    driver_path: pth.AnyPath) -> webdriver.Remote:
-    return self._start_chromedriver(session, driver_path)
-
-  def _start_chromedriver(self, session: BrowserSessionRunGroup,
-                          driver_path: pth.AnyPath) -> ChromiumDriver:
-    assert not self._is_running
-    assert self.log_file
-    args = self._get_browser_flags_for_session(session)
-    options = self._create_options(session, args)
-
-    self._log_browser_start(args, driver_path)
-    service_args: List[str] = []
-    log_path: Optional[str] = None
-    if self._settings.driver_logging:
-      service_args += ["--verbose"]
-      log_path = os.fspath(self.driver_log_file)
-    # pytype: disable=wrong-keyword-args
-    service = self.WEB_DRIVER_SERVICE(
-        executable_path=os.fspath(driver_path),
-        log_path=log_path,
-        service_args=service_args)
-    # TODO: support remote platforms
-    service.log_file = pth.LocalPath(self.stdout_log_file).open(  # pylint: disable=consider-using-with
-        "w", encoding="utf-8")
-    driver = self._create_driver(options, service)
-    # pytype: enable=wrong-keyword-args
-    # Prevent debugging overhead.
-    self._execute_cdp_cmd(driver, "Runtime.setMaxCallStackSizeToCapture",
-                          {"size": 0})
-    return driver
-
-  def _create_options(self, session: BrowserSessionRunGroup,
-                      args: Sequence[str]) -> ChromiumOptions:
-    assert not self._is_running
-    options: ChromiumOptions = self.WEB_DRIVER_OPTIONS()
-    options.set_capability("browserVersion", str(self.major_version))
-    # Don't wait for document-ready.
-    options.set_capability("pageLoadStrategy", "eager")
-    for arg in args:
-      options.add_argument(arg)
-    options.binary_location = os.fspath(self.path)
-    session.setup_selenium_options(options)
-    return options
-
-  @abc.abstractmethod
-  def _create_driver(self, options: ChromiumOptions,
-                     service: ChromiumService) -> ChromiumDriver:
-    pass
-
-  def _validate_driver_version(self) -> None:
-    assert self._driver_path, "No driver available"
-    error_message = None
-    if self.is_local and is_build_dir(
-        self.platform.local_path(self.app_path.parent)):
-      error_message = self._validate_locally_built_driver(
-          self.platform.local_path(self._driver_path))
-    else:
-      error_message = self._validate_any_driver_version(self._driver_path)
-    if error_message:
-      raise RuntimeError("\n".join(error_message))
-
-  def _validate_locally_built_driver(
-      self, driver_path: pth.LocalPath) -> Optional[Iterable[str]]:
-    # TODO: migrate to version object on the browser
-    browser_version = ChromiumVersion.parse(self.version)
-    driver_version = ChromeDriverVersion.parse(
-        self.platform.app_version(driver_path))
-    if browser_version.parts == driver_version.parts:
-      return None
-    return (f"Chromedriver version mismatch: driver={driver_version.parts_str} "
-            f"browser={browser_version.parts_str} ({self}).",
-            build_chromedriver_instructions(driver_path.parent))
-
-  def _validate_any_driver_version(
-      self, driver_path: pth.AnyPath) -> Optional[Iterable[str]]:
-    raw_version_str = self.host_platform.sh_stdout(driver_path, "--version")
-    driver_version = ChromeDriverVersion.parse(raw_version_str)
-    if driver_version.major == self.major_version:
-      return None
-    return (f"Chromedriver version mismatch: driver={driver_version} "
-            f"browser={self.version} ({self})",)
-
-  def run_script_on_new_document(self, script: str) -> None:
-    self._execute_cdp_cmd(self._private_driver,
-                          "Page.addScriptToEvaluateOnNewDocument",
-                          {"source": script})
-
-  def current_window_id(self) -> str:
-    return str(self._private_driver.current_window_handle)
-
-  def switch_window(self, window_id: str) -> None:
-    self._private_driver.switch_to.window(window_id)
-
-  def switch_tab(
-      self,
-      title: Optional[re.Pattern] = None,
-      url: Optional[re.Pattern] = None,
-      tab_index: Optional[int] = None,
-      timeout: dt.timedelta = dt.timedelta(seconds=0)
-  ) -> None:
-    driver = self._private_driver
-    original_handle = driver.current_window_handle
-    for _ in helper.wait_with_backoff(timeout, self.platform):
-      # Search through other handles starting from current_window_handle + 1
-      try:
-        i = driver.window_handles.index(original_handle)
-      except ValueError as e:
-        raise RuntimeError("Original starting tab no longer exists") from e
-
-      if tab_index is not None:
-        handles = [driver.window_handles[tab_index]]
-      else:
-        handles = driver.window_handles[i + 1:] + driver.window_handles[:i]
-
-      for handle in handles:
-        driver.switch_to.window(handle)
-        if title is not None:
-          if title.match(driver.title) is None:
-            continue
-        if url is not None:
-          if url.match(driver.current_url) is None:
-            continue
-        return
-    error = "No new tab found"
-    if title is not None:
-      error += f" with title matching {repr(title.pattern)}"
-    if url is not None:
-      error += f" with url matching {repr(url.pattern)}"
-    if tab_index is not None:
-      error += f" with tab_index matching {tab_index}"
-    raise RuntimeError(error)
-
-  def start_profiling(self) -> None:
-    assert isinstance(self._private_driver, ChromiumDriver)
-    # TODO: reuse the TraceProbe categories,
-    self._execute_cdp_cmd(
-        self._private_driver, "Tracing.start", {
-            "transferMode":
-                "ReturnAsStream",
-            "includedCategories": [
-                "devtools.timeline",
-                "v8.execute",
-                "disabled-by-default-devtools.timeline",
-                "disabled-by-default-devtools.timeline.frame",
-                "toplevel",
-                "blink.console",
-                "blink.user_timing",
-                "latencyInfo",
-                "disabled-by-default-devtools.timeline.stack",
-                "disabled-by-default-v8.cpu_profiler",
-            ],
-        })
-
-  def stop_profiling(self) -> Any:
-    assert isinstance(self._private_driver, ChromiumDriver)
-    data = self._execute_cdp_cmd(self._private_driver,
-                                 "Tracing.tracingComplete", {})
-    # TODO: use webdriver bidi to get the async Tracing.end event.
-    # self._execute_cdp_cmd(self._driver, "Tracing.end", {})
-    return data
-
-
 # Android is high-tech and reads chrome flags from an app-specific file.
 # TODO: extend support to more than just chrome.
 _FLAG_ROOT: pth.AnyPosixPath = pth.AnyPosixPath("/data/local/tmp/")
@@ -267,15 +51,28 @@ FLAGS_CONTENT_SHELL: pth.AnyPosixPath = (
 FLAGS_CHROME: pth.AnyPosixPath = _FLAG_ROOT / "chrome-command-line"
 
 
-class ChromiumWebDriverAndroid(ChromiumWebDriver):
+class ChromiumWebDriver(ChromiumBaseMixin, ChromiumBasedWebDriver):
+
+  @override
+  def _create_driver(
+      self, options: ChromiumOptions,
+      service: ChromiumService) -> chromium_webdriver.ChromiumDriver:
+    return chromium_webdriver.ChromiumDriver(
+        browser_name="chromium",
+        vendor_prefix="goog",
+        options=options,
+        service=service)
+
+
+class ChromiumWebDriverAndroid(ChromiumBasedWebDriver):
 
   def __init__(self,
                label: str,
                path: Optional[pth.AnyPath] = None,
-               settings: Optional[Settings] = None):
+               settings: Optional[Settings] = None) -> None:
     assert settings, "Android browser needs custom settings and platform"
     self._chrome_command_line_path: pth.AnyPath = FLAGS_CHROME
-    self._previous_command_line_contents: Optional[str] = None
+    self._previous_command_line_contents: str | None = None
     super().__init__(label, path, settings)
     self._android_package: str = self._lookup_android_package(self.path)
     if not self._android_package:
@@ -290,40 +87,29 @@ class ChromiumWebDriverAndroid(ChromiumWebDriver):
     return self._android_package
 
   @property
+  @override
   def platform(self) -> AndroidAdbPlatform:
     assert isinstance(
         self._platform,
         AndroidAdbPlatform), (f"Invalid platform: {self._platform}")
     return cast(AndroidAdbPlatform, self._platform)
 
-  def _resolve_binary(self, path: pth.AnyPath) -> pth.AnyPath:
+  def _init_resolve_binary(self, path: pth.AnyPath) -> pth.AnyPath:
     return path
 
-  # TODO: implement setting a clean profile on android
-  _UNSUPPORTED_FLAGS: Tuple[str, ...] = (
-      "--user-data-dir",
+  UNSUPPORTED_FLAGS: Tuple[str, ...] = (
       "--disable-sync",
       "--window-size",
       "--window-position",
   )
 
-  def _filter_flags_for_run(self, flags: FlagsT) -> FlagsT:
-    assert isinstance(flags, ChromeFlags)
-    chrome_flags = cast(ChromeFlags, flags)
-    for flag in self._UNSUPPORTED_FLAGS:
-      if flag not in chrome_flags:
-        continue
-      flag_value = chrome_flags.pop(flag, None)
-      logging.debug("Chrome Android: Removed unsupported flag: %s=%s", flag,
-                    flag_value)
-    return chrome_flags
-
+  @override
   def _start_driver(self, session: BrowserSessionRunGroup,
                     driver_path: pth.AnyPath) -> webdriver.Remote:
     self.adb_force_stop()
     if session.browser.wipe_system_user_data:
       self.adb_force_clear()
-      self.platform.adb.grant_notification_permissions(self.android_package)
+      self.platform.adb.grant_permissions(self.android_package)
     self._backup_chrome_flags()
     atexit.register(self._restore_chrome_flags)
     return self._start_chromedriver(session, driver_path)
@@ -370,6 +156,7 @@ class ChromiumWebDriverAndroid(ChromiumWebDriver):
                                       self._previous_command_line_contents)
     self._previous_command_line_contents = None
 
+  @override
   def _create_options(self, session: BrowserSessionRunGroup,
                       args: Sequence[str]) -> ChromiumOptions:
     options: ChromiumOptions = super()._create_options(session, args)
@@ -377,11 +164,19 @@ class ChromiumWebDriverAndroid(ChromiumWebDriver):
     options.add_experimental_option("androidPackage", self.android_package)
     options.add_experimental_option("androidDeviceSerial",
                                     self.platform.adb.serial_id)
+    if not self.clear_cache_dir:
+      options.add_experimental_option("androidKeepAppDataDir", True)
     return options
 
-  def setup_binary(self) -> None:
-    super().setup_binary()
-    self.platform.adb.grant_notification_permissions(self.android_package)
+  @override
+  def _setup_binary(self) -> None:  # pytype: disable=override-error
+    super()._setup_binary()
+    self.platform.adb.grant_permissions(self.android_package)
+
+  @override
+  def _setup_window(self) -> None:  # pytype: disable=override-error
+    logging.debug("%s: Skipping viewport settings %s on %s",
+                  type(self).__name__, self.viewport, self)
 
 
 class LocalChromiumWebDriverAndroid(ChromiumWebDriverAndroid):
@@ -399,22 +194,26 @@ class LocalChromiumWebDriverAndroid(ChromiumWebDriverAndroid):
   def __init__(self,
                label: str,
                path: Optional[pth.AnyPath] = None,
-               settings: Optional[Settings] = None):
+               settings: Optional[Settings] = None) -> None:
     if self.is_apk_helper(path):
       raise ValueError(
           "Locally built chrome version needs package, got empty path")
     assert settings, "Android browser needs custom settings and platform"
+    assert path, "Got invalid path"
     self._package_info: immutabledict[str, Any] = self._parse_package_info(
         settings.platform, path)
     super().__init__(label, path, settings)
 
+  @override
   def _lookup_android_package(self, path: pth.AnyPath) -> str:
     return self._package_info["Package name"]
 
-  def _extract_version(self) -> str:
-    return self._package_info["versionName"]
+  # TODO: enable override again.
+  # @override
+  def _extract_version(self) -> BrowserVersion:
+    return self.version_cls().parse(self._package_info["versionName"])
 
-  def _parse_package_info(self, platform: plt.Platform,
+  def _parse_package_info(self, platform: Platform,
                           path: pth.AnyPath) -> immutabledict[str, Any]:
     output = platform.host_platform.sh_stdout(
         path, "package-info").rstrip().splitlines()
@@ -424,20 +223,100 @@ class LocalChromiumWebDriverAndroid(ChromiumWebDriverAndroid):
       package_info[key] = hjson.loads(value)
     return immutabledict(package_info)
 
-  def setup_binary(self) -> None:
-    super().setup_binary()
+  @override
+  def _setup_binary(self) -> None:
+    super()._setup_binary()
     self.host_platform.sh_stdout(self.path, "install",
                                  f"--device={self.platform.serial_id}")
 
 
-class ChromiumWebDriverSsh(ChromiumWebDriver):
+class AutoForwardingRemoteWebDriver(RemoteWebDriver):
+  """
+  Wraps RemoteWebDriver, but starts, stops, and forwards ports for chromedriver.
+  """
+
+  # Example ss output line (with whitespace shortened):
+  # LISTEN 0 5 127.0.0.1:34595 0.0.0.0:* users:(("chromedriver",pid=80388,fd=8))
+  SS_CHROMEDRIVER_LINE_RE = re.compile(
+      r"^LISTEN\s+"
+      # Recv-Q
+      r"\d+\s+"
+      # Send-Q
+      r"\d+\s+"
+      # Local Address:Port
+      r"127.0.0.1:(?P<port>\d+)\s+"
+      # Peer Address:Port
+      r"\S+\s+"
+      # Process
+      r"users:\(\("
+      r"\"chromedriver\",pid=\d+,fd=\d+"
+      r"\)\)\s*$",
+      re.MULTILINE)
+
+  _platform: LinuxSshPlatform
+  _forward_port: int
+  _chromedriver: subprocess.Popen | None
+
+  def __init__(
+      self,
+      platform: LinuxSshPlatform,
+      chromedriver_path: Optional[pth.AnyPath],
+      options: ChromiumOptions,
+  ) -> None:
+    with exception.annotate("Starting chromedriver"):
+      self._platform = platform
+      self._killall_chromedriver()
+      self._chromedriver = platform.popen(
+          chromedriver_path or Binaries.CHROMEDRIVER.resolve(platform),
+          stdin=subprocess.PIPE)
+      atexit.register(self._stop_remote_driver)
+      driver_port = self._wait_for_driver_port()
+      self._forward_port = platform.port_forward(0, driver_port)
+      logging.info(
+          "Chromedriver listening on %d forwarded through local port %d",
+          driver_port, self._forward_port)
+    super().__init__(f"http://127.0.0.1:{self._forward_port}", options=options)
+
+  def quit(self) -> None:
+    try:
+      super().quit()
+    finally:
+      self._stop_remote_driver()
+
+  def _stop_remote_driver(self) -> None:
+    if not self._chromedriver:
+      return
+    try:
+      self._chromedriver.terminate()
+      self._chromedriver = None
+    finally:
+      # Closing the ssh connection doesn't terminate chromedriver, so kill it.
+      self._killall_chromedriver()
+      if self._forward_port:
+        self._platform.stop_port_forward(self._forward_port)
+        self._forward_port = 0
+
+  def _killall_chromedriver(self) -> None:
+    self._platform.sh("killall", "chromedriver", check=False)
+
+  def _wait_for_driver_port(self) -> int:
+    for _ in wait.wait_with_backoff(10):
+      listening = self._platform.sh_stdout("ss", "-HOlntp")
+      if m := self.SS_CHROMEDRIVER_LINE_RE.search(listening):
+        return NumberParser.port_number(m[1], "driver port")
+    raise RuntimeError("not reached")
+
+
+class ChromiumWebDriverSsh(ChromiumBasedWebDriver):
 
   @property
+  @override
   def platform(self) -> LinuxSshPlatform:
     assert isinstance(self._platform,
                       LinuxSshPlatform), (f"Invalid platform: {self._platform}")
     return cast(LinuxSshPlatform, self._platform)
 
+  @override
   def _start_driver(self, session: BrowserSessionRunGroup,
                     driver_path: pth.AnyPath) -> RemoteWebDriver:
     del driver_path
@@ -446,423 +325,65 @@ class ChromiumWebDriverSsh(ChromiumWebDriver):
     platform = self.platform
     host = platform.host
     port = platform.port
+    if port == 0:
+      return AutoForwardingRemoteWebDriver(
+          platform, self._settings.driver_path, options=options)
     driver = RemoteWebDriver(f"http://{host}:{port}", options=options)
     return driver
 
 
-class ChromiumWebDriverChromeOsSsh(ChromiumWebDriver):
+class ChromiumWebDriverChromeOsSsh(ChromiumBasedWebDriver):
 
   @property
+  @override
   def platform(self) -> ChromeOsSshPlatform:
     assert isinstance(
         self._platform,
         ChromeOsSshPlatform), (f"Invalid platform: {self._platform}")
     return cast(ChromeOsSshPlatform, self._platform)
 
+  UNSUPPORTED_FLAGS: Tuple[str, ...] = (
+      "--user-data-dir",
+      "--window-size",
+      "--window-position",
+  )
+
+  @override
   def _start_driver(self, session: BrowserSessionRunGroup,
                     driver_path: pth.AnyPath) -> RemoteWebDriver:
     del driver_path
     platform = self.platform
     host = platform.host
     port = platform.port
-    args = self._get_browser_flags_for_session(session)
+    args: Tuple[str, ...] = self._get_browser_flags_for_session(session)
     # TODO(spadhi): correctly handle flags:
     #   1. decide which flags to pass to chrome vs chromedriver
     #   2. investigate irrelevant / unsupported flags on ChromeOS
     #   3. filter out and pass the chrome flags to the debugging session below
     #   4. pass the remaining flags to RemoteWebDriver options
-    google_login = session.browser.secrets.get(SecretType.GOOGLE)
+    google_login = session.browser.secrets.google
     if google_login:
       dbg_port = platform.create_debugging_session(
-          username=google_login.username, password=google_login.password)
+          username=google_login.username,
+          password=google_login.password,
+          browser_flags=args)
     else:
-      dbg_port = platform.create_debugging_session()
+      dbg_port = platform.create_debugging_session(browser_flags=args)
     options = self._create_options(session, args)
     options.add_experimental_option("debuggerAddress", f"127.0.0.1:{dbg_port}")
-    driver = RemoteWebDriver(f"http://{host}:{port}", options=options)
-    return driver
+
+    if port == 0:
+      return AutoForwardingRemoteWebDriver(
+          platform, self._settings.driver_path, options=options)
+    return RemoteWebDriver(f"http://{host}:{port}", options=options)
 
   # On ChromeOS, the system profile is the same as the browser profile.
-  def is_logged_in(self, secret: Secret, strict: bool = False) -> bool:
-    if secret.type != SecretType.GOOGLE:
-      return False
-    if secret.username == self.platform.username:
+  def is_logged_in(self,
+                   secret: UsernamePassword,
+                   strict: bool = False) -> bool:
+    if secret.username == self.platform.username and isinstance(
+        secret, GoogleUsernamePassword):
       return True
     if not strict:
       return False
     raise RuntimeError("Login of non-primary Google accounts not supported")
-
-
-class DriverNotFoundError(ValueError):
-  pass
-
-
-def build_chromedriver_instructions(build_dir: pth.AnyPath) -> str:
-  return ("Please build 'chromedriver' manually for local builds:\n"
-          f"    autoninja -C {build_dir} chromedriver")
-
-
-def is_build_dir(path: pth.LocalPath,
-                 platform: plt.Platform = plt.PLATFORM) -> bool:
-  return platform.is_file(path / "args.gn")
-
-
-class ChromeDriverFinder:
-  driver_path: pth.LocalPath
-
-  def __init__(self, browser: ChromiumWebDriver):
-    self.browser = browser
-    self.platform: Platform = browser.platform
-    self.host_platform: Platform = browser.platform.host_platform
-    extension: str = ""
-    if self.host_platform.is_win:
-      extension = ".exe"
-    cache_dir = self.host_platform.local_cache_dir("driver")
-    self.driver_path: pth.LocalPath = (
-        cache_dir / f"chromedriver-{self.browser.major_version}{extension}")
-    self._validate_browser()
-
-  def _validate_browser(self) -> None:
-    browser_platform = self.browser.platform
-    if browser_platform.is_local:
-      return
-    # Some remote platforms rely on a local chromedriver
-    if (browser_platform.is_android or browser_platform.is_remote_ssh):
-      return
-    raise RuntimeError("Cannot download chromedriver for remote browser yet")
-
-  def find_local_build(self) -> pth.LocalPath:
-    assert self.browser.app_path
-    # assume it's a local build
-    lookup_dir = pth.LocalPath(self.browser.app_path.parent)
-    driver_path = lookup_dir / "chromedriver"
-    if self.platform.is_win:
-      driver_path = driver_path.with_suffix(".exe")
-    if self.platform.is_file(driver_path):
-      return driver_path
-    error_message: List[str] = [f"Driver '{driver_path}' does not exist."]
-    if is_build_dir(lookup_dir, self.platform):
-      error_message += [build_chromedriver_instructions(lookup_dir)]
-    else:
-      error_message += ["Please manually provide a chromedriver binary."]
-    raise DriverNotFoundError("\n".join(error_message))
-
-  def download(self) -> pth.LocalPath:
-    if not self.platform.is_file(self.driver_path):
-      with exception.annotate(
-          f"Downloading chromedriver for {self.browser.version}"):
-        self._download()
-    return self.driver_path
-
-  def _download(self) -> None:
-    milestone = self.browser.major_version
-    logging.info("CHROMEDRIVER Downloading from %s v%s", self.browser.type_name,
-                 milestone)
-    url: Optional[str] = None
-    listing_url: Optional[str] = None
-    if milestone >= self.CFT_MIN_MILESTONE:
-      listing_url, url = self._get_cft_url(milestone)
-    if not url:
-      listing_url, url = self._get_pre_115_stable_url(milestone)
-      if not url:
-        listing_url, url = self._get_canary_url()
-
-    if not url:
-      raise DriverNotFoundError(
-          "Please manually compile/download chromedriver for "
-          f"{self.browser.type_name} {self.browser.version}")
-
-    logging.info("CHROMEDRIVER Downloading M%s: %s", milestone, listing_url or
-                 url)
-    with tempfile.TemporaryDirectory() as tmp_dir:
-      if ".zip" not in url:
-        maybe_driver = pth.LocalPath(tmp_dir) / "chromedriver"
-        self.host_platform.download_to(url, maybe_driver)
-      else:
-        zip_file = pth.LocalPath(tmp_dir) / "download.zip"
-        self.host_platform.download_to(url, zip_file)
-        with zipfile.ZipFile(zip_file, "r") as zip_ref:
-          zip_ref.extractall(zip_file.parent)
-        zip_file.unlink()
-        maybe_driver = None
-        candidates: List[pth.LocalPath] = [
-            path for path in zip_file.parent.glob("**/*")
-            if path.is_file() and "chromedriver" in path.name
-        ]
-        # Find exact match first:
-        maybe_drivers: List[pth.LocalPath] = [
-            path for path in candidates if path.stem == "chromedriver"
-        ]
-        # Backup less strict matching:
-        maybe_drivers += candidates
-        if len(maybe_drivers) > 0:
-          maybe_driver = maybe_drivers[0]
-      if not maybe_driver or not maybe_driver.is_file():
-        raise DriverNotFoundError(
-            f"Extracted driver at {maybe_driver} does not exist.")
-      self.driver_path.parent.mkdir(parents=True, exist_ok=True)
-      shutil.move(os.fspath(maybe_driver), os.fspath(self.driver_path))
-      self.driver_path.chmod(self.driver_path.stat().st_mode | stat.S_IEXEC)
-
-  # Using CFT as abbreviation for Chrome For Testing here.
-  CFT_MIN_MILESTONE = 115
-  CFT_BASE_URL: str = "https://googlechromelabs.github.io/chrome-for-testing"
-  CFT_VERSION_URL: str = f"{CFT_BASE_URL}/{{version}}.json"
-  CFT_LATEST_URL: str = f"{CFT_BASE_URL}/LATEST_RELEASE_{{major}}"
-
-  CFT_PLATFORM: Final[Dict[Tuple[str, str], str]] = {
-      ("linux", "x64"): "linux64",
-      ("macos", "x64"): "mac-x64",
-      ("macos", "arm64"): "mac-arm64",
-      ("win", "ia32"): "win32",
-      ("win", "x64"): "win64"
-  }
-
-  def _get_cft_url(self, milestone: int) -> Tuple[str, Optional[str]]:
-    logging.debug("ChromeDriverFinder: Looking up chrome-for-testing version.")
-    platform_name: Optional[str] = self.CFT_PLATFORM.get(self.host_platform.key)
-    if not platform_name:
-      raise DriverNotFoundError(
-          f"Unsupported platform {self.host_platform.key} for chromedriver.")
-    listing_url, version_data = self._get_cft_version_data(milestone)
-    download_url: Optional[str] = None
-    if version_data:
-      download_url = self._get_cft_driver_download_url(version_data,
-                                                       platform_name)
-    return (listing_url, download_url)
-
-  def _get_cft_version_data(self, milestone: int) -> Tuple[str, Optional[Dict]]:
-    logging.debug("ChromeDriverFinder: Trying direct download url")
-    listing_url, data = self._get_cft_precise_version_data(self.browser.version)
-    if data:
-      return listing_url, data
-    logging.debug(
-        "ChromeDriverFinder: Invalid precise version url %s, "
-        "using M%s", listing_url, milestone)
-    return self._get_ctf_milestone_data(milestone)
-
-  def _get_cft_precise_version_data(self,
-                                    version: str) -> Tuple[str, Optional[Dict]]:
-    version_url = self.CFT_VERSION_URL.format(version=version)
-    try:
-      with helper.urlopen(version_url) as response:
-        version_data = json.loads(response.read().decode("utf-8"))
-        return (version_url, version_data)
-    except urllib.error.HTTPError as e:
-      logging.debug("ChromeDriverFinder: "
-                    "Precise version download failed %s", e)
-      return (version_url, None)
-
-  def _get_ctf_milestone_data(self,
-                              milestone: int) -> Tuple[str, Optional[Dict]]:
-    latest_version_url = self.CFT_LATEST_URL.format(major=milestone)
-    try:
-      with helper.urlopen(latest_version_url) as response:
-        alternative_version = response.read().decode("utf-8").strip()
-        logging.debug(
-            "ChromeDriverFinder: Using alternative version %s "
-            "for M%s", alternative_version, milestone)
-        return self._get_cft_precise_version_data(alternative_version)
-    except urllib.error.HTTPError:
-      return (self.CFT_BASE_URL, None)
-
-  def _get_cft_driver_download_url(self, version_data,
-                                   platform_name) -> Optional[str]:
-    if all_downloads := version_data.get("downloads"):
-      driver_downloads: Dict = all_downloads.get("chromedriver", [])
-      for download in driver_downloads:
-        if isinstance(download, dict) and download["platform"] == platform_name:
-          return download["url"]
-    return None
-
-  PRE_115_STABLE_URL: str = "http://chromedriver.storage.googleapis.com"
-
-  def _get_pre_115_stable_url(self,
-                              milestone: int) -> Tuple[str, Optional[str]]:
-    logging.debug(
-        "ChromeDriverFinder: "
-        "Looking upe old-style stable version M%s", milestone)
-    assert milestone < self.CFT_MIN_MILESTONE
-    listing_url = f"{self.PRE_115_STABLE_URL}/index.html"
-    driver_version: Optional[str] = self._get_pre_115_driver_version(milestone)
-    if not driver_version:
-      return listing_url, None
-    if self.host_platform.is_linux:
-      arch_suffix = "linux64"
-    elif self.host_platform.is_macos:
-      arch_suffix = "mac64"
-      if self.host_platform.is_arm64:
-        # The uploaded chromedriver archives changed the naming scheme after
-        # chrome version 106.0.5249.21 for Arm64 (previously m1):
-        #   before: chromedriver_mac64_m1.zip
-        #   after:  chromedriver_mac_arm64.zip
-        last_old_naming_version = (106, 0, 5249, 21)
-        version_tuple = tuple(map(int, driver_version.split(".")))
-        if version_tuple <= last_old_naming_version:
-          arch_suffix = "mac64_m1"
-        else:
-          arch_suffix = "mac_arm64"
-    elif self.host_platform.is_win:
-      arch_suffix = "win32"
-    else:
-      raise DriverNotFoundError("Unsupported chromedriver platform")
-    url = (f"{self.PRE_115_STABLE_URL}/{driver_version}/"
-           f"chromedriver_{arch_suffix}.zip")
-    return listing_url, url
-
-  def _get_pre_115_driver_version(self, milestone) -> Optional[str]:
-    if milestone < 70:
-      return self._get_pre_70_driver_version(milestone)
-    url = f"{self.PRE_115_STABLE_URL}/LATEST_RELEASE_{milestone}"
-    try:
-      with helper.urlopen(url) as response:
-        return response.read().decode("utf-8")
-    except urllib.error.HTTPError as e:
-      if e.code != 404:
-        raise DriverNotFoundError(f"Could not query {url}") from e
-      logging.debug("ChromeDriverFinder: Could not load latest release url %s",
-                    e)
-    return None
-
-  def _get_pre_70_driver_version(self, milestone) -> Optional[str]:
-    with helper.urlopen(
-        f"{self.PRE_115_STABLE_URL}/2.46/notes.txt") as response:
-      lines = response.read().decode("utf-8").splitlines()
-    for i, line in enumerate(lines):
-      if not line.startswith("---"):
-        continue
-      [min_version, max_version] = map(int, re.findall(r"\d+", lines[i + 1]))
-      if min_version <= milestone <= max_version:
-        match = re.search(r"\d\.\d+", line)
-        if not match:
-          raise DriverNotFoundError(f"Could not parse version number: {line}")
-        return match.group(0)
-    return None
-
-  CHROMIUM_DASH_URL: str = "https://chromiumdash.appspot.com/fetch_releases"
-  CHROMIUM_LISTING_URL: str = (
-      "https://www.googleapis.com/storage/v1/b/chromium-browser-snapshots/o/")
-  CHROMIUM_DASH_PARAMS: Dict[Tuple[str, str], Dict] = {
-      ("linux", "x64"): {
-          "dash_platform": "linux",
-          "dash_channel": "dev",
-          "dash_limit": 10,
-      },
-      ("macos", "x64"): {
-          "dash_platform": "mac",
-      },
-      ("macos", "arm64"): {
-          "dash_platform": "mac",
-      },
-      ("win", "ia32"): {
-          "dash_platform": "win",
-      },
-      ("win", "x64"): {
-          "dash_platform": "win64",
-      },
-  }
-  CHROMIUM_LISTING_PREFIX: Dict[Tuple[str, str], str] = {
-      ("linux", "x64"): "Linux_x64",
-      ("macos", "x64"): "Mac",
-      ("macos", "arm64"): "Mac_Arm",
-      ("win", "ia32"): "Win",
-      ("win", "x64"): "Win_x64",
-  }
-
-  def _get_canary_url(self) -> Tuple[str, Optional[str]]:
-    logging.debug(
-        "ChromeDriverFinder: Try downloading the chromedriver canary version")
-    properties = self.CHROMIUM_DASH_PARAMS.get(self.host_platform.key)
-    if not properties:
-      raise DriverNotFoundError(
-          f"Unsupported platform={self.platform}, key={self.host_platform.key}")
-    dash_platform = properties["dash_platform"]
-    dash_channel = properties.get("dash_channel", "canary")
-    # Limit should be > len(canary_versions) so we also get potentially
-    # the latest dev version (only beta / stable have official driver binaries).
-    dash_limit = properties.get("dash_limit", 100)
-    url = helper.update_url_query(
-        self.CHROMIUM_DASH_URL, {
-            "platform": dash_platform,
-            "channel": dash_channel,
-            "milestone": str(self.browser.major_version),
-            "num": str(dash_limit),
-        })
-    chromium_base_position = 0
-    with helper.urlopen(url) as response:
-      version_infos = list(json.loads(response.read().decode("utf-8")))
-      if not version_infos:
-        raise DriverNotFoundError("Could not find latest version info for "
-                                  f"platform={self.host_platform}")
-      for version_info in version_infos:
-        if version_info["version"] == self.browser.version:
-          chromium_base_position = int(
-              version_info["chromium_main_branch_position"])
-          break
-
-    if not chromium_base_position and version_infos:
-      fallback_version_info = None
-      # Try matching latest milestone
-      for version_info in version_infos:
-        if version_info["milestone"] == self.browser.major_version:
-          fallback_version_info = version_info
-          break
-
-      if not fallback_version_info:
-        # Android has a slightly different release cycle than the desktop
-        # versions. Assume that the latest canary version is good enough
-        fallback_version_info = version_infos[0]
-      chromium_base_position = int(
-          fallback_version_info["chromium_main_branch_position"])
-      logging.warning(
-          "Falling back to latest (not precisely matching) "
-          "canary chromedriver %s (expected %s)",
-          fallback_version_info["version"], self.browser.version)
-
-    if not chromium_base_position:
-      raise DriverNotFoundError("Could not find matching canary chromedriver "
-                                f"for {self.browser.version}")
-    # Use prefixes to limit listing results and increase chances of finding
-    # a matching version
-    listing_prefix = self.CHROMIUM_LISTING_PREFIX.get(self.host_platform.key)
-    if not listing_prefix:
-      raise NotImplementedError(
-          f"Unsupported chromedriver platform {self.host_platform}")
-    base_prefix = str(chromium_base_position)[:4]
-    listing_url = helper.update_url_query(self.CHROMIUM_LISTING_URL, {
-        "prefix": f"{listing_prefix}/{base_prefix}",
-        "maxResults": "10000"
-    })
-    with helper.urlopen(listing_url) as response:
-      listing = json.loads(response.read().decode("utf-8"))
-
-    versions = []
-    logging.debug("Filtering %s candidate URLs.", len(listing["items"]))
-    for version in listing["items"]:
-      if "name" not in version:
-        continue
-      if "mediaLink" not in version:
-        continue
-      name = version["name"]
-      if "chromedriver" not in name:
-        continue
-      parts = name.split("/")
-      if "chromedriver" not in parts[-1] or len(parts) < 3:
-        continue
-      base = parts[1]
-      try:
-        int(base)
-      except ValueError:
-        # Ignore base if it is not an int
-        continue
-      versions.append((int(base), version["mediaLink"]))
-    versions.sort()
-    logging.debug("Found candidates: %s", versions)
-    logging.debug("chromium_base_position=%s", chromium_base_position)
-
-    for i in range(len(versions)):
-      base, url = versions[i]
-      if base > chromium_base_position:
-        base, url = versions[i - 1]
-        return listing_url, url
-    return listing_url, None
diff --git a/crossbench/browsers/chromium_based/__init__.py b/crossbench/browsers/chromium_based/__init__.py
new file mode 100644
index 00000000..4547f8b8
--- /dev/null
+++ b/crossbench/browsers/chromium_based/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/browsers/chromium_based/chromium_based.py b/crossbench/browsers/chromium_based/chromium_based.py
new file mode 100644
index 00000000..f4ea5412
--- /dev/null
+++ b/crossbench/browsers/chromium_based/chromium_based.py
@@ -0,0 +1,270 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+import logging
+from typing import TYPE_CHECKING, Optional, TextIO, Tuple, Type, cast
+
+from typing_extensions import override
+
+from crossbench import path as pth
+from crossbench.browsers.browser import Browser
+from crossbench.browsers.browser_helper import convert_flags_to_label
+from crossbench.browsers.chromium_based import helper
+from crossbench.browsers.version import BrowserVersionChannel
+from crossbench.browsers.viewport import Viewport
+from crossbench.flags.chrome import ChromeFlags
+from crossbench.types import JsonDict
+
+if TYPE_CHECKING:
+  from crossbench.browsers.chromium.version import ChromiumVersion
+  from crossbench.browsers.settings import Settings
+  from crossbench.browsers.version import BrowserVersion
+  from crossbench.flags.base import Flags, FlagsData
+  from crossbench.flags.chrome import ChromeFeatures
+  from crossbench.flags.js_flags import JSFlags
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class ChromiumBased(Browser):
+  MIN_HEADLESS_NEW_VERSION: int = 112
+  DEFAULT_FLAGS: Tuple[str, ...] = (
+      "--no-default-browser-check",
+      "--disable-component-update",
+      "--disable-sync",
+      "--disable-extensions",
+      "--no-first-run",
+      # This could be enabled via feature-flags as well.
+      "--disable-search-engine-choice-screen",
+  )
+  FLAGS_FOR_DISABLING_BACKGROUND_INTERVENTIONS: Tuple[str, ...] = (
+      "--disable-background-timer-throttling",
+      "--disable-renderer-backgrounding",
+  )
+
+  @classmethod
+  @abc.abstractmethod
+  def version_cls(cls) -> Type[ChromiumVersion]:
+    pass
+
+  @classmethod
+  @override
+  def default_flags(cls, initial_data: FlagsData = None) -> ChromeFlags:
+    return ChromeFlags(initial_data)
+
+  def __init__(self,
+               label: str,
+               path: pth.AnyPath,
+               settings: Optional[Settings] = None) -> None:
+    super().__init__(label, path, settings=settings)
+    self._stdout_log_file: TextIO | None = None
+    assert isinstance(self._flags, ChromeFlags)
+
+  @override
+  def _extract_version(self) -> BrowserVersion:
+    if path := self.path:
+      self._is_local_build = helper.is_in_build_dir(path, self.platform)
+    version = self.version_cls().parse(self.platform.app_version(self.path))
+    # Locally-built chrome versions should not have a channel
+    if self.is_local_build:
+      version = version.with_channel(BrowserVersionChannel.ANY)
+    return version
+
+  @override
+  def _init_flags(self, settings: Settings) -> ChromeFlags:
+    flags: Flags = settings.flags
+    js_flags: Flags = settings.js_flags
+    self._flags = self.default_flags(self.DEFAULT_FLAGS)
+    self._flags.update(flags)
+
+    if "--allow-background-interventions" in self._flags.data:
+      # The --allow-background-interventions flag should have no value.
+      assert self._flags.get("--allow-background-interventions") is None
+    else:
+      self._flags.update(self.FLAGS_FOR_DISABLING_BACKGROUND_INTERVENTIONS)
+
+    # Explicitly disable field-trials by default on all chrome flavours:
+    # By default field-trials are disabled on non-Chrome branded builds, but
+    # are auto-enabled on everything else. This gives very confusing results
+    # when comparing local builds to official binaries.
+    field_trial_flags: ChromeFlags = self._flags.field_trial_flags
+    if not field_trial_flags:
+      logging.info("Disabling experiments/finch/field-trials for %s", self)
+      for flag in ChromeFlags.NO_EXPERIMENTS_FLAGS:
+        self._flags.set(flag)
+    else:
+      logging.warning("Running with field-trials or finch experiments.")
+
+    self.js_flags.update(js_flags)
+    self._maybe_disable_gpu_compositing()
+    # Run early validation for conflicting command-line flags.
+    self.validate_flags()
+    return self._flags
+
+  def _maybe_disable_gpu_compositing(self) -> None:
+    # Chrome Remote Desktop provides no GPU and older chrome versions
+    # don't handle this well.
+    if self.version.major > 92 or ("CHROME_REMOTE_DESKTOP_SESSION"
+                                   not in self.platform.environ):
+      return
+    self.flags.set("--disable-gpu-compositing")
+    self.flags.set("--no-sandbox")
+
+  @override
+  def validate_flags(self) -> None:
+    super().validate_flags()
+    field_trial_flags: ChromeFlags = self.flags.field_trial_flags
+    no_finch_flags = self.flags.no_experiments_flags
+    if field_trial_flags and no_finch_flags:
+      raise argparse.ArgumentTypeError(
+          f"Conflicting {self.type_name()} flags detected: "
+          f"{field_trial_flags} vs {no_finch_flags}.\n"
+          "Cannot enable and disable finch / field-trials at the same time.")
+
+  @override
+  def _setup_cache_dir(self) -> Optional[pth.AnyPath]:
+    # See documentation for more details:
+    # https://chromium.googlesource.com/chromium/src/+/main/docs/user_data_dir.md
+    # We only deal with the user-data-dir here and ignore the user-cache-dir.
+    user_data_dir = self.settings.cache_dir
+    if flag_user_data_dir := self._flags.get("--user-data-dir", None):
+      if user_data_dir and str(user_data_dir) != str(flag_user_data_dir):
+        raise ValueError("Conflicting cache_dir from "
+                         f"settings.cache_dir={repr(str(user_data_dir))} and "
+                         f"--user-data-dir={repr(str(flag_user_data_dir))}")
+      return pth.AnyPath(flag_user_data_dir)
+
+    if user_data_dir:
+      return user_data_dir
+
+    temp_dir = None
+    if self.platform.is_android:
+      # On Android, not all apps have permission to write to /data/local/tmp.
+      # We use a folder on external storage instead.
+      # This does not affect the user-cache-dir which needs to be cleared
+      # separately.
+      temp_dir = "/storage/emulated/0/Documents"
+    # Using a temp-dir on macos also forces the user-cache-dir to be there.
+    user_data_dir = self.platform.mkdtemp(
+        prefix=f"{self.type_name()}_", dir=temp_dir)
+    return user_data_dir
+
+  @property
+  def user_data_dir(self) -> Optional[pth.AnyPath]:
+    # On chromium-based browsers we can have two separate caching dirs:
+    # - user-data-dir containing all profile data
+    # - cache-dir containing profile independent caches
+    return self._cache_dir
+
+  @property
+  def is_headless(self) -> bool:
+    return "--headless" in self._flags
+
+  @property
+  def chrome_log_file(self) -> pth.AnyPath:
+    assert self.log_file
+    return self.log_file.with_suffix(f".{self.type_name()}.log")
+
+  @property
+  @override
+  def flags(self) -> ChromeFlags:
+    return cast(ChromeFlags, self._flags)
+
+  @property
+  @override
+  def js_flags(self) -> JSFlags:
+    return cast(ChromeFlags, self._flags).js_flags
+
+  @property
+  @override
+  def features(self) -> ChromeFeatures:
+    return cast(ChromeFlags, self._flags).features
+
+  @override
+  def details_json(self) -> JsonDict:
+    details: JsonDict = super().details_json()
+    if self.log_file:
+      log = cast(JsonDict, details["log"])
+      log[self.type_name()] = str(self.chrome_log_file)
+      log["stdout"] = str(self.stdout_log_file)
+    details["js_flags"] = tuple(self.js_flags)
+    return details
+
+  @override
+  def _get_browser_flags_for_session(
+      self, session: BrowserSessionRunGroup) -> Tuple[str, ...]:
+    js_flags_copy = self.js_flags.copy()
+    js_flags_copy.update(session.extra_js_flags)
+
+    flags_copy = self.flags.copy()
+    flags_copy.update(session.extra_flags)
+    flags_copy.update(self.network.extra_flags(self.attributes()))
+    self._handle_viewport_flags(flags_copy)
+
+    if len(js_flags_copy):
+      flags_copy["--js-flags"] = str(js_flags_copy)
+    if user_data_dir := self.flags.get("--user-data-dir"):
+      assert user_data_dir == str(
+          self.cache_dir), (f"--user-data-dir path: {user_data_dir} was passed "
+                            f"but does not match cache-dir: {self.cache_dir}")
+    if self.cache_dir:
+      flags_copy["--user-data-dir"] = str(self.cache_dir)
+    if self.log_file:
+      flags_copy.set("--enable-logging")
+      flags_copy["--log-file"] = str(self.chrome_log_file)
+
+    flags_copy = self._filter_flags_for_run(flags_copy)
+
+    return tuple(flags_copy)
+
+  def _handle_viewport_flags(self, flags: Flags) -> None:
+    self._sync_viewport_flag(flags, "--start-fullscreen",
+                             self.viewport.is_fullscreen, Viewport.FULLSCREEN)
+    self._sync_viewport_flag(flags, "--start-maximized",
+                             self.viewport.is_maximized, Viewport.MAXIMIZED)
+    self._sync_viewport_flag(flags, "--headless", self.viewport.is_headless,
+                             Viewport.HEADLESS)
+    # M112 added --headless=new as replacement for --headless
+    if "--headless" in flags and (self.version.major
+                                  >= self.MIN_HEADLESS_NEW_VERSION):
+      if flags["--headless"] is None:
+        logging.info("Replacing --headless with --headless=new")
+        flags.set("--headless", "new", should_override=True)
+
+    if self.viewport.is_default:
+      update_viewport = False
+      width, height = self.viewport.size
+      x, y = self.viewport.position
+      if "--window-size" in flags:
+        update_viewport = True
+        width, height = map(int, flags["--window-size"].split(","))
+      if "--window-position" in flags:
+        update_viewport = True
+        x, y = map(int, flags["--window-position"].split(","))
+      if update_viewport:
+        self.viewport = Viewport(width, height, x, y)
+    if self.viewport.has_size:
+      flags["--window-size"] = f"{self.viewport.width},{self.viewport.height}"
+      flags["--window-position"] = f"{self.viewport.x},{self.viewport.y}"
+    else:
+      for flag in ("--window-position", "--window-size"):
+        if flag in flags:
+          flag_value = flags[flag]
+          raise ValueError(f"Viewport {self.viewport} conflicts with flag "
+                           f"{flag}={flag_value}")
+
+  def get_label_from_flags(self) -> str:
+    return convert_flags_to_label(*self.flags, *self.js_flags)
+
+  @override
+  def quit(self) -> None:
+    try:
+      super().quit()
+    finally:
+      if self._stdout_log_file:
+        self._stdout_log_file.close()
+        self._stdout_log_file = None
diff --git a/crossbench/browsers/chromium_based/helper.py b/crossbench/browsers/chromium_based/helper.py
new file mode 100644
index 00000000..6226d1ed
--- /dev/null
+++ b/crossbench/browsers/chromium_based/helper.py
@@ -0,0 +1,27 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench import path as pth
+  from crossbench.plt.base import Platform
+
+
+def build_chromedriver_instructions(build_dir: pth.AnyPath) -> str:
+  return ("Please build 'chromedriver' manually for local builds:\n"
+          f"    autoninja -C {build_dir} chromedriver")
+
+
+def is_build_dir(path: pth.AnyPath, platform: Platform) -> bool:
+  return platform.is_file(path / "args.gn")
+
+
+def is_in_build_dir(path: pth.AnyPath, platform: Platform) -> bool:
+  # bypass potentially expensive checks
+  if "src" not in path.parts:
+    return False
+  return any(is_build_dir(parent, platform) for parent in path.parents)
diff --git a/crossbench/browsers/chromium_based/webdriver.py b/crossbench/browsers/chromium_based/webdriver.py
new file mode 100644
index 00000000..b4499144
--- /dev/null
+++ b/crossbench/browsers/chromium_based/webdriver.py
@@ -0,0 +1,308 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import datetime as dt
+import logging
+import os
+from typing import (TYPE_CHECKING, Any, Iterable, List, Optional, Sequence,
+                    Tuple, Type, cast)
+
+from selenium.webdriver.chromium.options import ChromiumOptions
+from selenium.webdriver.chromium.service import ChromiumService
+from selenium.webdriver.chromium.webdriver import ChromiumDriver
+from typing_extensions import override
+
+from crossbench import path as pth
+from crossbench.browsers.attributes import BrowserAttributes
+from crossbench.browsers.chromium.driver_finder import (ChromeDriverFinder,
+                                                        DriverNotFoundError)
+from crossbench.browsers.chromium.version import (ChromeDriverVersion,
+                                                  ChromiumVersion)
+from crossbench.browsers.chromium_based import helper
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
+from crossbench.browsers.webdriver import WebDriverBrowser
+from crossbench.flags.base import FlagsT
+from crossbench.flags.chrome import ChromeFlags
+from crossbench.helper import wait
+
+if TYPE_CHECKING:
+  import re
+
+  from selenium import webdriver
+
+  from crossbench.browsers.version import BrowserVersion
+  from crossbench.runner.groups.session import BrowserSessionRunGroup
+
+
+class ChromiumBasedWebDriver(
+    WebDriverBrowser, ChromiumBased, metaclass=abc.ABCMeta):
+
+  WEB_DRIVER_OPTIONS: Type[ChromiumOptions] = ChromiumOptions
+  WEB_DRIVER_SERVICE: Type[ChromiumService] = ChromiumService
+  UNSUPPORTED_FLAGS: Tuple[str, ...] = ()
+
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
+    return (BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
+            | BrowserAttributes.WEBDRIVER)
+
+  def use_local_chromedriver(self) -> bool:
+    return self.version.major == 0 or self.is_locally_compiled()
+
+  def is_locally_compiled(self) -> bool:
+    return pth.LocalPath(self.app_path.parent / "args.gn").exists()
+
+  def _execute_cdp_cmd(self, driver: webdriver.Remote, cmd: str,
+                       cmd_args: dict):
+    return driver.execute("executeCdpCommand", {
+        "cmd": cmd,
+        "params": cmd_args
+    })["value"]
+
+  @override
+  def _filter_flags_for_run(self, flags: FlagsT) -> FlagsT:
+    assert isinstance(flags, ChromeFlags)
+    chrome_flags: ChromeFlags = cast(ChromeFlags, flags)
+    for flag in self.UNSUPPORTED_FLAGS:
+      if flag not in chrome_flags:
+        continue
+      flag_value = chrome_flags.pop(flag, None)
+      logging.debug("Chromium: Removed unsupported flag: %s=%s", flag,
+                    flag_value)
+    return chrome_flags  # type: ignore
+
+  @override
+  def _find_driver(self) -> pth.AnyPath:
+    if self._driver_path:
+      return self._driver_path
+    finder = ChromeDriverFinder(self)
+    assert self.app_path
+    if self.use_local_chromedriver():
+      return finder.find_local_build()
+    try:
+      return finder.download()
+    except DriverNotFoundError as original_download_error:
+      logging.debug(
+          "Could not download chromedriver, "
+          "falling back to finding local build: %s", original_download_error)
+      try:
+        return finder.find_local_build()
+      except DriverNotFoundError as e:
+        logging.debug("Could not find fallback chromedriver: %s", e)
+        raise original_download_error from e
+      # to make an old pytype version happy
+      return pth.LocalPath()
+
+  @override
+  def _start_driver(self, session: BrowserSessionRunGroup,
+                    driver_path: pth.AnyPath) -> webdriver.Remote:
+    return self._start_chromedriver(session, driver_path)
+
+  def _start_chromedriver(self, session: BrowserSessionRunGroup,
+                          driver_path: pth.AnyPath) -> ChromiumDriver:
+    assert not self._is_running
+    assert self.log_file
+    args = self._get_browser_flags_for_session(session)
+    options = self._create_options(session, args)
+
+    self._log_browser_start(args, driver_path)
+    service_args: List[str] = []
+    if self._settings.driver_logging:
+      service_args += [
+          "--verbose", f"--log-path={os.fspath(self._setup_driver_log_file())}"
+      ]
+
+    adb_port = os.environ.get("ANDROID_ADB_SERVER_PORT")
+    if adb_port and adb_port.isdigit():
+      service_args += ["--adb-port=" + adb_port]
+
+    # pytype: disable=wrong-keyword-args
+    assert self._stdout_log_file is None
+    self._stdout_log_file = self.log_file.with_suffix(
+        ".browser.stdout.log").open("w+")
+    service = self.WEB_DRIVER_SERVICE(
+        executable_path=os.fspath(driver_path),
+        service_args=service_args,
+        log_output=self._stdout_log_file,
+    )
+    if hasattr(service, "log_file"):
+      # TODO: remove once we upgrade the min selenium version
+      # Workaround for older selenium versions which ignore the log_file kwarg.
+      setattr(service, "log_file", self._stdout_log_file)
+
+    # TODO: support remote platforms
+    driver = self._create_driver(options, service)
+    # pytype: enable=wrong-keyword-args
+    # Prevent debugging overhead.
+    self._execute_cdp_cmd(driver, "Runtime.setMaxCallStackSizeToCapture",
+                          {"size": 0})
+    return driver
+
+  def _create_options(self, session: BrowserSessionRunGroup,
+                      args: Sequence[str]) -> ChromiumOptions:
+    assert not self._is_running
+    options: ChromiumOptions = self.WEB_DRIVER_OPTIONS()
+    options.set_capability("browserVersion", str(self.version.major))
+    # Don't wait for document-ready.
+    options.set_capability("pageLoadStrategy", "eager")
+    for arg in args:
+      options.add_argument(arg)
+    options.binary_location = os.fspath(self.path)
+    session.setup_selenium_options(options)
+    return options
+
+  @abc.abstractmethod
+  def _create_driver(self, options: ChromiumOptions,
+                     service: ChromiumService) -> ChromiumDriver:
+    pass
+
+  @override
+  def _validate_driver_version(self) -> None:
+    assert self._driver_path, "No driver available"
+    error_message = None
+    if self.is_local and helper.is_build_dir(
+        self.platform.local_path(self.app_path.parent), self.platform):
+      error_message = self._validate_locally_built_driver(
+          self.platform.local_path(self._driver_path))
+    else:
+      error_message = self._validate_any_driver_version(self._driver_path)
+    if error_message:
+      raise RuntimeError("\n".join(error_message))
+
+  def _validate_locally_built_driver(
+      self, driver_path: pth.LocalPath) -> Optional[Iterable[str]]:
+    # TODO: migrate to version object on the browser
+    browser_version: BrowserVersion = self.version
+    assert isinstance(browser_version, ChromiumVersion)
+    driver_version = ChromeDriverVersion.parse(
+        self.platform.app_version(driver_path))
+    if browser_version.parts == driver_version.parts:
+      return None
+    return (f"Chromedriver version mismatch: driver={driver_version.parts_str} "
+            f"browser={browser_version.parts_str} ({self}).",
+            helper.build_chromedriver_instructions(driver_path.parent))
+
+  def _validate_any_driver_version(
+      self, driver_path: pth.AnyPath) -> Optional[Iterable[str]]:
+    raw_version_str = self.host_platform.sh_stdout(driver_path, "--version")
+    driver_version = ChromeDriverVersion.parse(raw_version_str)
+    if driver_version.major == self.version.major:
+      return None
+    return (f"Chromedriver version mismatch: driver={driver_version} "
+            f"browser={self.version} ({self})",)
+
+  @override
+  def run_script_on_new_document(self, script: str) -> None:
+    self._execute_cdp_cmd(self._private_driver,
+                          "Page.addScriptToEvaluateOnNewDocument",
+                          {"source": script})
+
+  @override
+  def current_window_id(self) -> str:
+    return str(self._private_driver.current_window_handle)
+
+  @override
+  def switch_window(self, window_id: str) -> None:
+    self._private_driver.switch_to.window(window_id)
+
+  @override
+  def switch_tab(
+      self,
+      title: Optional[re.Pattern] = None,
+      url: Optional[re.Pattern] = None,
+      tab_index: Optional[int] = None,
+      timeout: dt.timedelta = dt.timedelta(seconds=0)
+  ) -> str:
+    driver = self._private_driver
+    original_handle = driver.current_window_handle
+    for _ in wait.wait_with_backoff(timeout):
+      # Search through other handles starting from current_window_handle + 1
+      try:
+        i = driver.window_handles.index(original_handle)
+      except ValueError as e:
+        raise RuntimeError("Original starting tab no longer exists") from e
+
+      if tab_index is not None:
+        handles = [driver.window_handles[tab_index]]
+      else:
+        handles = driver.window_handles[i:] + driver.window_handles[:i]
+
+      for handle in handles:
+        driver.switch_to.window(handle)
+        if title is not None:
+          if title.match(driver.title) is None:
+            continue
+        if url is not None:
+          if url.match(driver.current_url) is None:
+            continue
+        return handle
+    error = "No new tab found"
+    if title is not None:
+      error += f" with title matching {repr(title.pattern)}"
+    if url is not None:
+      error += f" with url matching {repr(url.pattern)}"
+    if tab_index is not None:
+      error += f" with tab_index matching {tab_index}"
+    raise RuntimeError(error)
+
+  @override
+  def close_tab(
+      self,
+      title: Optional[re.Pattern] = None,
+      url: Optional[re.Pattern] = None,
+      tab_index: Optional[int] = None,
+      timeout: dt.timedelta = dt.timedelta(seconds=0)
+  ) -> None:
+    driver = self._private_driver
+    original_handle = driver.current_window_handle
+    tab_to_close = original_handle
+
+    if title or url or (tab_index is not None):
+      tab_to_close = self.switch_tab(title, url, tab_index, timeout)
+
+    driver.close()
+
+    if tab_to_close != original_handle:
+      driver.switch_to.window(original_handle)
+    else:
+      # When a tab closes itself, arbitrarily default
+      # to switching to the first tab.
+      driver.switch_to.window(driver.window_handles[0])
+
+  @property
+  def current_url(self) -> str:
+    return self._private_driver.current_url
+
+  def start_profiling(self) -> None:
+    assert isinstance(self._private_driver, ChromiumDriver)
+    # TODO: reuse the TraceProbe categories,
+    self._execute_cdp_cmd(
+        self._private_driver, "Tracing.start", {
+            "transferMode":
+                "ReturnAsStream",
+            "includedCategories": [
+                "devtools.timeline",
+                "v8.execute",
+                "disabled-by-default-devtools.timeline",
+                "disabled-by-default-devtools.timeline.frame",
+                "toplevel",
+                "blink.console",
+                "blink.user_timing",
+                "latencyInfo",
+                "disabled-by-default-devtools.timeline.stack",
+                "disabled-by-default-v8.cpu_profiler",
+            ],
+        })
+
+  def stop_profiling(self) -> Any:
+    assert isinstance(self._private_driver, ChromiumDriver)
+    data = self._execute_cdp_cmd(self._private_driver,
+                                 "Tracing.tracingComplete", {})
+    # TODO: use webdriver bidi to get the async Tracing.end event.
+    # self._execute_cdp_cmd(self._driver, "Tracing.end", {})
+    return data
diff --git a/crossbench/browsers/downloader.py b/crossbench/browsers/downloader.py
index acc309b5..9bbaaf32 100644
--- a/crossbench/browsers/downloader.py
+++ b/crossbench/browsers/downloader.py
@@ -12,11 +12,13 @@ import re
 import shutil
 import sys
 import tempfile
-from typing import TYPE_CHECKING, Final, Iterable, Optional, Tuple, Type, Union
+from typing import TYPE_CHECKING, Final, Iterable, Optional, Tuple, Type
+
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.browsers.version import BrowserVersion, UnknownBrowserVersion
-from crossbench.helper import Spinner
+from crossbench.helper.spinner import Spinner
 
 if TYPE_CHECKING:
   from crossbench.plt.base import Platform
@@ -48,7 +50,7 @@ class Downloader(abc.ABC):
     pass
 
   @classmethod
-  def load(cls, archive_path_or_version_identifier: Union[str, pth.LocalPath],
+  def load(cls, archive_path_or_version_identifier: str | pth.LocalPath,
            browser_platform: Platform) -> pth.LocalPath:
     logging.debug("Downloading chrome %s binary for %s",
                   archive_path_or_version_identifier, browser_platform)
@@ -57,10 +59,9 @@ class Downloader(abc.ABC):
                                     browser_platform)
     return loader.app_path
 
-  def __init__(self, archive_path_or_version_identifier: Union[str,
-                                                               pth.LocalPath],
+  def __init__(self, archive_path_or_version_identifier: str | pth.LocalPath,
                browser_type: str, platform_name: str,
-               browser_platform: Platform):
+               browser_platform: Platform) -> None:
     assert browser_type, "Missing browser_type"
     self._browser_type = browser_type
     self._browser_platform = browser_platform
@@ -80,8 +81,8 @@ class Downloader(abc.ABC):
     self._validate()
 
   def find(
-      self, archive_path_or_version_identifier: Union[str, pth.LocalPath]
-  ) -> pth.LocalPath:
+      self,
+      archive_path_or_version_identifier: str | pth.LocalPath) -> pth.LocalPath:
     version_value = os.fspath(archive_path_or_version_identifier)
     if self.is_valid_version(version_value):
       self._requested_version = self._parse_version(version_value)
@@ -140,7 +141,7 @@ class Downloader(abc.ABC):
     self._install_archive(self._archive_path)
     return self._installed_app_path()
 
-  def _try_download_version_archive(self):
+  def _try_download_version_archive(self) -> bool:
     if self._archive_path.exists():
       return False
     archive_version, archive_url = self._find_archive_url()
@@ -268,22 +269,23 @@ class ArchiveHelper(abc.ABC):
 class RPMArchiveHelper(ArchiveHelper):
 
   @classmethod
+  @override
   def extract(cls, platform: Platform, archive_path: pth.LocalPath,
               dest_path: pth.LocalPath) -> pth.LocalPath:
-    assert platform.which("rpm2cpio"), (
-        "Need rpm2cpio to extract downloaded .rpm archive")
-    assert platform.which("cpio"), (
-        "Need cpio to extract downloaded .rpm archive")
+    rpm2cpio = platform.which("rpm2cpio")
+    assert rpm2cpio, ("Need rpm2cpio to extract downloaded .rpm archive")
+    cpio = platform.which("cpio")
+    assert cpio, ("Need cpio to extract downloaded .rpm archive")
     cpio_file = archive_path.with_suffix(".cpio")
     assert not cpio_file.exists()
     archive_path.parent.mkdir(parents=True, exist_ok=True)
     with cpio_file.open("w") as f:
-      platform.sh("rpm2cpio", archive_path, stdout=f)
+      platform.sh(rpm2cpio, archive_path, stdout=f)
     assert cpio_file.is_file(), f"Could not extract archive: {archive_path}"
     assert not dest_path.exists()
     with cpio_file.open() as f:
       platform.sh(
-          "cpio",
+          cpio,
           "--extract",
           f"--directory={dest_path}",
           "--make-directories",
@@ -304,7 +306,7 @@ class DMGArchiveHelper:
     result = platform.sh_stdout("hdiutil", "attach", "-plist",
                                 archive_path).strip()
     data = plistlib.loads(str.encode(result))
-    dmg_path: Optional[pth.LocalPath] = None
+    dmg_path: pth.LocalPath | None = None
     for item in data["system-entities"]:
       mount_point = item.get("mount-point", None)
       if mount_point:
diff --git a/crossbench/browsers/edge/base.py b/crossbench/browsers/edge/base.py
new file mode 100644
index 00000000..4e20798d
--- /dev/null
+++ b/crossbench/browsers/edge/base.py
@@ -0,0 +1,61 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type
+
+from crossbench.browsers.edge.version import EdgeVersion
+
+if TYPE_CHECKING:
+  from crossbench import plt
+  from crossbench.browsers.chromium.version import ChromiumVersion
+  from crossbench.path import AnyPath
+
+
+class EdgeBaseMixin:
+
+  @classmethod
+  def version_cls(cls) -> Type[ChromiumVersion]:
+    return EdgeVersion
+
+  @classmethod
+  def default_path(cls, platform: plt.Platform) -> AnyPath:
+    return cls.stable_path(platform)
+
+  @classmethod
+  def stable_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Stable",
+        macos=["Microsoft Edge.app"],
+        linux=["microsoft-edge"],
+        win=["Microsoft/Edge/Application/msedge.exe"])
+
+  @classmethod
+  def beta_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Beta",
+        macos=["Microsoft Edge Beta.app"],
+        linux=["microsoft-edge-beta"],
+        win=["Microsoft/Edge Beta/Application/msedge.exe"])
+
+  @classmethod
+  def dev_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Dev",
+        macos=["Microsoft Edge Dev.app"],
+        linux=["microsoft-edge-dev"],
+        win=["Microsoft/Edge Dev/Application/msedge.exe"])
+
+  @classmethod
+  def canary_path(cls, platform: plt.Platform) -> AnyPath:
+    return platform.search_app_or_executable(
+        "Edge Canary",
+        macos=["Microsoft Edge Canary.app"],
+        linux=[],
+        win=["Microsoft/Edge SxS/Application/msedge.exe"])
+
+  @classmethod
+  def type_name(cls) -> str:
+    return "edge"
diff --git a/crossbench/browsers/edge/edge.py b/crossbench/browsers/edge/edge.py
index ba88aeec..4d978f49 100644
--- a/crossbench/browsers/edge/edge.py
+++ b/crossbench/browsers/edge/edge.py
@@ -4,65 +4,21 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING
+from typing_extensions import override
 
-from crossbench import plt
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.browsers.edge.base import EdgeBaseMixin
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
 
-if TYPE_CHECKING:
-  from crossbench.path import AnyPath
 
-
-class EdgePathMixin:
-  @classmethod
-  def default_path(cls, platform: plt.Platform) -> AnyPath:
-    return cls.stable_path(platform)
-
-  @classmethod
-  def stable_path(cls, platform: plt.Platform) -> AnyPath:
-    return platform.search_app_or_executable(
-        "Edge Stable",
-        macos=["Microsoft Edge.app"],
-        linux=["microsoft-edge"],
-        win=["Microsoft/Edge/Application/msedge.exe"])
-
-  @classmethod
-  def beta_path(cls, platform: plt.Platform) -> AnyPath:
-    return platform.search_app_or_executable(
-        "Edge Beta",
-        macos=["Microsoft Edge Beta.app"],
-        linux=["microsoft-edge-beta"],
-        win=["Microsoft/Edge Beta/Application/msedge.exe"])
-
-  @classmethod
-  def dev_path(cls, platform: plt.Platform) -> AnyPath:
-    return platform.search_app_or_executable(
-        "Edge Dev",
-        macos=["Microsoft Edge Dev.app"],
-        linux=["microsoft-edge-dev"],
-        win=["Microsoft/Edge Dev/Application/msedge.exe"])
-
-  @classmethod
-  def canary_path(cls, platform: plt.Platform) -> AnyPath:
-    return platform.search_app_or_executable(
-        "Edge Canary",
-        macos=["Microsoft Edge Canary.app"],
-        linux=[],
-        win=["Microsoft/Edge SxS/Application/msedge.exe"])
-
-  @property
-  def type_name(self) -> str:
-    return "edge"
-
-
-class Edge(EdgePathMixin, Chromium):
+class Edge(EdgeBaseMixin, ChromiumBased):
   DEFAULT_FLAGS = (
       "--enable-benchmarking",
       "--disable-extensions",
       "--no-first-run",
   )
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.EDGE | BrowserAttributes.CHROMIUM_BASED
diff --git a/crossbench/browsers/edge/version.py b/crossbench/browsers/edge/version.py
new file mode 100644
index 00000000..091abf78
--- /dev/null
+++ b/crossbench/browsers/edge/version.py
@@ -0,0 +1,44 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import re
+from typing import Iterable, Optional, Self
+
+from typing_extensions import override
+
+from crossbench.browsers.chromium.version import ChromiumVersion
+
+
+class EdgeVersion(ChromiumVersion):
+
+  _PREFIX_RE = re.compile(
+      rf"microsoft edge(?:{ChromiumVersion._CHANNEL_RE.pattern})? ", re.I)
+
+  @classmethod
+  @override
+  def _validate_prefix(cls, prefix: Optional[str]) -> bool:
+    if not prefix:
+      return True
+    prefix = prefix.lower()
+    if prefix.strip() == "m":
+      return True
+    return (bool(cls._PREFIX_RE.fullmatch(prefix)) or
+            super()._validate_prefix(prefix))
+
+  @classmethod
+  @override
+  def _validate_suffix(cls, suffix: Optional[str]) -> bool:
+    if suffix and "(Official Build)" in suffix:
+      return True
+    return super()._validate_suffix(suffix)
+
+  @classmethod
+  def dev(cls, parts: Iterable[int], version_str: str = "") -> Self:
+    return cls.alpha(parts, version_str)
+
+  @classmethod
+  def canary(cls, parts: Iterable[int], version_str: str = "") -> Self:
+    return cls.pre_alpha(parts, version_str)
diff --git a/crossbench/browsers/edge/webdriver.py b/crossbench/browsers/edge/webdriver.py
index c0f4c70b..86bf8b0a 100644
--- a/crossbench/browsers/edge/webdriver.py
+++ b/crossbench/browsers/edge/webdriver.py
@@ -14,13 +14,14 @@ from typing import TYPE_CHECKING
 from selenium import webdriver
 from selenium.webdriver.edge.options import Options as EdgeOptions
 from selenium.webdriver.edge.service import Service as EdgeService
+from typing_extensions import override
 
 import crossbench
 import crossbench.exception
 from crossbench import path as pth
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chromium.webdriver import ChromiumWebDriver
-from crossbench.browsers.edge.edge import EdgePathMixin
+from crossbench.browsers.chromium.webdriver import ChromiumBasedWebDriver
+from crossbench.browsers.edge.base import EdgeBaseMixin
 
 if TYPE_CHECKING:
   from selenium.webdriver.chromium.webdriver import ChromiumDriver
@@ -28,25 +29,31 @@ if TYPE_CHECKING:
   from crossbench import plt
 
 
-class EdgeWebDriver(EdgePathMixin, ChromiumWebDriver):
+class EdgeWebDriver(EdgeBaseMixin, ChromiumBasedWebDriver):
 
   WEB_DRIVER_OPTIONS = EdgeOptions
   WEB_DRIVER_SERVICE = EdgeService
 
-  @property
-  def type_name(self) -> str:
+  @classmethod
+  @override
+  def type_name(cls) -> str:
     return "edge"
 
+  @override
   def _find_driver(self) -> pth.AnyPath:
     finder = EdgeWebDriverDownloader(self)
     return finder.download()
 
-  def _create_driver(self, options: EdgeOptions,
-                     service: EdgeService) -> ChromiumDriver:
+  @override
+  def _create_driver(
+      self,
+      options: EdgeOptions,  # type: ignore
+      service: EdgeService) -> ChromiumDriver:  # type: ignore
     return webdriver.Edge(options=options, service=service)
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return (BrowserAttributes.EDGE | BrowserAttributes.CHROMIUM_BASED
             | BrowserAttributes.WEBDRIVER)
 
@@ -64,7 +71,7 @@ class EdgeWebDriverDownloader:
       self.extension = ".exe"
     cache_dir = self.platform.host_platform.local_cache_dir("driver")
     self.driver_path: pth.LocalPath = (
-        cache_dir / f"edgedriver-{self.browser.major_version}{self.extension}")
+        cache_dir / f"edgedriver-{self.browser.version.major}{self.extension}")
 
   def download(self) -> pth.LocalPath:
     if not self.driver_path.exists():
@@ -76,7 +83,7 @@ class EdgeWebDriverDownloader:
   def _download(self) -> None:
     arch = self._arch_identifier()
     archive_name = f"edgedriver_{arch}.zip"
-    url = self.BASE_URL + f"/{self.browser.version}/{archive_name}"
+    url = self.BASE_URL + f"/{self.browser.version.parts_str}/{archive_name}"
     logging.info("EDGEDRIVER downloading %s: %s", self.browser.version, url)
     with tempfile.TemporaryDirectory() as tmp_dir:
       archive_file = pth.LocalPath(tmp_dir) / archive_name
diff --git a/crossbench/browsers/firefox/downloader.py b/crossbench/browsers/firefox/downloader.py
index c66868de..e1c47040 100644
--- a/crossbench/browsers/firefox/downloader.py
+++ b/crossbench/browsers/firefox/downloader.py
@@ -5,12 +5,15 @@
 from __future__ import annotations
 
 import abc
-import urllib.parse
-from typing import (TYPE_CHECKING, Dict, Final, Iterable, Optional, Tuple, Type,
-                    Union)
+import os
+import shutil
+from typing import TYPE_CHECKING, Dict, Final, Iterable, Optional, Tuple, Type
+
+from typing_extensions import override
 
 from crossbench.browsers.downloader import DMGArchiveHelper, Downloader
 from crossbench.browsers.firefox.version import FirefoxVersion
+from crossbench.helper import url_helper
 
 if TYPE_CHECKING:
   from crossbench.browsers.version import BrowserVersion
@@ -34,6 +37,7 @@ class FirefoxDownloader(Downloader):
   STORAGE_URL: str = "https://ftp.mozilla.org/pub/firefox/releases/"
 
   @classmethod
+  @override
   def _get_loader_cls(cls,
                       browser_platform: Platform) -> Type[FirefoxDownloader]:
     if browser_platform.is_macos:
@@ -46,6 +50,7 @@ class FirefoxDownloader(Downloader):
                      f"{browser_platform.name} {browser_platform.machine}")
 
   @classmethod
+  @override
   def is_valid_version(cls, path_or_identifier: str) -> bool:
     return FirefoxVersion.is_valid_unique(path_or_identifier)
 
@@ -58,9 +63,8 @@ class FirefoxDownloader(Downloader):
     return (browser_platform.exists(path) and
             path.name.endswith(cls.ARCHIVE_SUFFIX))
 
-  def __init__(self, version_identifier: Union[str,
-                                               LocalPath], browser_type: str,
-               platform_name: str, browser_platform: Platform):
+  def __init__(self, version_identifier: str | LocalPath, browser_type: str,
+               platform_name: str, browser_platform: Platform) -> None:
     assert not browser_type
     assert not platform_name
     firefox_platform_name = _PLATFORM_NAME_LOOKUP.get(browser_platform.key)
@@ -71,12 +75,15 @@ class FirefoxDownloader(Downloader):
     super().__init__(version_identifier, "firefox", firefox_platform_name,
                      browser_platform)
 
+  @override
   def _parse_version(self, version_identifier: str) -> BrowserVersion:
     return FirefoxVersion.parse(version_identifier)
 
+  @override
   def _requested_version_validation(self) -> None:
     pass
 
+  @override
   def _find_archive_url(self) -> Tuple[BrowserVersion, Optional[str]]:
     # Quick probe for complete versions
     if self._requested_version.is_complete:
@@ -88,6 +95,7 @@ class FirefoxDownloader(Downloader):
         f"{self.STORAGE_URL}{self._requested_version.parts_str}/mac/en-GB")
     return tuple(self._archive_urls(folder_url, self._requested_version))[0]
 
+  @override
   def _download_archive(self, archive_url: str, tmp_dir: LocalPath) -> None:
     self._browser_platform.download_to(
         archive_url, tmp_dir / f"archive.{self.ARCHIVE_SUFFIX}")
@@ -98,9 +106,10 @@ class FirefoxDownloader(Downloader):
     candidate = archive_candidates[0]
     assert not self._archive_path.exists(), (
         f"Archive was already downloaded: {self._archive_path}")
-    candidate.replace(self._archive_path)
+    shutil.move(os.fspath(candidate), os.fspath(self._archive_path))
 
   @abc.abstractmethod
+  @override
   def _install_archive(self, archive_path: LocalPath) -> None:
     pass
 
@@ -109,19 +118,23 @@ class FirefoxDownloaderLinux(FirefoxDownloader):
   ARCHIVE_SUFFIX: str = ".tar.bz2"
 
   @classmethod
+  @override
   def is_valid(cls, path_or_identifier: AnyPathLike,
                browser_platform: Platform) -> bool:
     return cls._is_valid(path_or_identifier, browser_platform)
 
+  @override
   def _installed_app_path(self) -> LocalPath:
     # TODO: support local vs remote
     return self._extracted_path() / "firefox-bin"
 
+  @override
   def _archive_urls(
       self, folder_url: str,
       version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
     return ((version, f"{folder_url}/firefox-{version.parts_str}.tar.bz2"),)
 
+  @override
   def _install_archive(self, archive_path: LocalPath) -> None:
     raise NotImplementedError("Missing linux support")
 
@@ -131,10 +144,12 @@ class FirefoxDownloaderMacOS(FirefoxDownloader):
   MIN_MAC_ARM64_MILESTONE: Final[int] = 84
 
   @classmethod
+  @override
   def is_valid(cls, path_or_identifier: AnyPathLike,
                browser_platform: Platform) -> bool:
     return cls._is_valid(path_or_identifier, browser_platform)
 
+  @override
   def _requested_version_validation(self) -> None:
     major_version: int = self._requested_version.major
     if (self._browser_platform.is_macos and self._browser_platform.is_arm64 and
@@ -143,6 +158,7 @@ class FirefoxDownloaderMacOS(FirefoxDownloader):
           "Native Mac arm64/m1 Firefox version is available with v84, "
           f"but requested {major_version}.")
 
+  @override
   def _download_archive(self, archive_url: str, tmp_dir: LocalPath) -> None:
     assert self._browser_platform.is_macos
     if self._browser_platform.is_arm64 and (self._requested_version
@@ -153,19 +169,23 @@ class FirefoxDownloaderMacOS(FirefoxDownloader):
           f"but requested {self._requested_version} is too old.")
     super()._download_archive(archive_url, tmp_dir)
 
+  @override
   def _archive_urls(
       self, folder_url: str,
       version: BrowserVersion) -> Iterable[Tuple[BrowserVersion, str]]:
-    archive_name = urllib.parse.quote(f"Firefox {version.parts_str}.dmg")
+    archive_name = url_helper.quote(f"firefox {version.parts_str}.dmg")
     return ((version, f"{folder_url}/{archive_name}"),)
 
+  @override
   def _extracted_path(self) -> LocalPath:
     # TODO: support local vs remote
     return self._installed_app_path()
 
+  @override
   def _installed_app_path(self) -> LocalPath:
     return self._out_dir / f"Firefox {self._requested_version}.app"
 
+  @override
   def _install_archive(self, archive_path: LocalPath) -> None:
     extracted_path = self._extracted_path()
     DMGArchiveHelper.extract(self.host_platform, archive_path, extracted_path)
@@ -175,9 +195,11 @@ class FirefoxDownloaderMacOS(FirefoxDownloader):
 class FirefoxDownloaderWin(FirefoxDownloader):
 
   @classmethod
+  @override
   def is_valid(cls, path_or_identifier: AnyPathLike,
                browser_platform: Platform) -> bool:
     return False
 
+  @override
   def _install_archive(self, archive_path: LocalPath) -> None:
     raise NotImplementedError("Missing windows support")
diff --git a/crossbench/browsers/firefox/firefox.py b/crossbench/browsers/firefox/firefox.py
index 96659866..65fe6aa5 100644
--- a/crossbench/browsers/firefox/firefox.py
+++ b/crossbench/browsers/firefox/firefox.py
@@ -4,12 +4,14 @@
 
 from __future__ import annotations
 
-import re
-from typing import TYPE_CHECKING, Tuple
+from typing import TYPE_CHECKING, Optional, Tuple
+
+from typing_extensions import override
 
 from crossbench import plt
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.browsers.browser import Browser
+from crossbench.browsers.firefox.version import FirefoxVersion
 from crossbench.browsers.viewport import Viewport
 from crossbench.browsers.webdriver import WebDriverBrowser
 
@@ -46,34 +48,32 @@ class Firefox(Browser):
         linux=["firefox-nightly", "firefox-trunk"],
         win=["Firefox Nightly/firefox.exe"])
 
-  def _setup_cache_dir(self, settings: Settings) -> None:
-    cache_dir = settings.cache_dir
-    if cache_dir:
-      self.cache_dir = cache_dir
-      self.clear_cache_dir = False
-    else:
-      self.cache_dir: AnyPath = settings.platform.mkdtemp(prefix="firefox")
-      self.clear_cache_dir = True
-
-  @property
-  def type_name(self) -> str:
+  @classmethod
+  @override
+  def type_name(cls) -> str:
     return "firefox"
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.FIREFOX
 
-  def _extract_version(self) -> str:
-    assert self.path
-    version_string = self.platform.app_version(self.path)
-    # "Firefox 107.0" => "107.0"
-    return str(re.findall(r"[\d\.]+", version_string)[0])
+  @override
+  def _setup_cache_dir(self) -> Optional[AnyPath]:
+    if cache_dir := self.settings.cache_dir:
+      return cache_dir
+    return self.platform.mkdtemp(prefix="firefox")
+
+  @override
+  def _extract_version(self) -> FirefoxVersion:
+    return FirefoxVersion.parse(self.platform.app_version(self.path))
 
+  @override
   def _get_browser_flags_for_session(
       self, session: BrowserSessionRunGroup) -> Tuple[str, ...]:
     flags_copy = self.flags.copy()
     flags_copy.update(session.extra_flags)
-    flags_copy.update(self.network.extra_flags(self.attributes))
+    flags_copy.update(self.network.extra_flags(self.attributes()))
     self._handle_viewport_flags(flags_copy)
     if self.log_file:
       flags_copy["--MOZ_LOG_FILE"] = str(self.log_file)
@@ -113,7 +113,6 @@ class Firefox(Browser):
                         WebDriverBrowser) and self.viewport.size != (0, 0):
         raise ValueError(f"Browser {self} cannot handle viewport position: "
                          f"{self.viewport.position}")
-    else:
-      if not isinstance(self, WebDriverBrowser):
-        raise ValueError(
-            f"Browser {self} cannot handle viewport mode: {self.viewport}")
+    elif not isinstance(self, WebDriverBrowser):
+      raise ValueError(
+          f"Browser {self} cannot handle viewport mode: {self.viewport}")
diff --git a/crossbench/browsers/firefox/version.py b/crossbench/browsers/firefox/version.py
index aead2120..c04e15f4 100644
--- a/crossbench/browsers/firefox/version.py
+++ b/crossbench/browsers/firefox/version.py
@@ -7,6 +7,8 @@ from __future__ import annotations
 import re
 from typing import Dict, Final, Optional, Tuple
 
+from typing_extensions import override
+
 from crossbench.browsers.version import BrowserVersion, BrowserVersionChannel
 
 
@@ -15,7 +17,9 @@ class FirefoxVersion(BrowserVersion):
   _PREFIX_RE = re.compile(r"(mozilla )?(ff|firefox)[ -]?", re.I)
   _VERSION_RE = re.compile(r"(?P<prefix>[^\d]*)"
                            r"(?P<version>"
-                           r"(?P<parts>\d+\.\d+(?P<channel>[ab.])\d+)"
+                           r"(?P<parts>\d+\.\d+"
+                           r"(?:(?P<channel_short>[ab.])\d+)?"
+                           r")"
                            r") ?(?P<channel_long>esr|any)?")
   _SPLIT_RE = re.compile(r"[ab.]")
   _CHANNEL_LOOKUP: Dict[str, BrowserVersionChannel] = {
@@ -27,8 +31,13 @@ class FirefoxVersion(BrowserVersion):
       "a": BrowserVersionChannel.ALPHA,
       "any": BrowserVersionChannel.ANY,
   }
+  _CHANNEL_LONG_LOOKUP: Dict[str, BrowserVersionChannel] = {
+      "developer edition": BrowserVersionChannel.BETA,
+      "nightly": BrowserVersionChannel.ALPHA,
+  }
 
   @classmethod
+  @override
   def _parse(
       cls,
       full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
@@ -41,19 +50,27 @@ class FirefoxVersion(BrowserVersion):
     version_str = matches["version"]
     version_parts = matches["parts"]
     assert version_parts and version_str
-    if matches["channel_long"] and matches["channel"] != ".":
-      raise cls.parse_error("Invalid ESR/Any channel version", full_version)
-    browser_channel = cls._parse_channel(matches)
-    parts = tuple(map(int, cls._SPLIT_RE.split(version_parts)))
+    browser_channel = cls._parse_channel(full_version, matches)
+    parts: Tuple[int, ...] = tuple(map(int, cls._SPLIT_RE.split(version_parts)))
+    if len(parts) == 2:
+      parts += (0,)
     if len(parts) != 3:
       raise cls.parse_error("Invalid number of version number parts",
                             full_version)
     return parts, browser_channel, version_str
 
   @classmethod
-  def _parse_channel(cls, matches) -> BrowserVersionChannel:
-    channel_str: str = (matches["channel_long"] or matches["channel"] or
-                        "stable").lower()
+  def _parse_channel(cls, full_version: str, matches) -> BrowserVersionChannel:
+    channel_long: str | None = matches["channel_long"]
+    channel_short: str | None = matches["channel_short"]
+    if not channel_long and not channel_short:
+      full_version_lower = full_version.lower()
+      for long_name, channel in cls._CHANNEL_LONG_LOOKUP.items():
+        if long_name in full_version_lower:
+          return channel
+    if channel_long and channel_short != ".":
+      raise cls.parse_error("Invalid ESR/Any channel version", full_version)
+    channel_str: str = (channel_long or channel_short or "stable").lower()
     return cls._CHANNEL_LOOKUP[channel_str]
 
   @classmethod
@@ -62,6 +79,7 @@ class FirefoxVersion(BrowserVersion):
       return True
     return bool(cls._PREFIX_RE.match(prefix))
 
+  @override
   def _channel_name(self, channel: BrowserVersionChannel) -> str:
     if channel == BrowserVersionChannel.LTS:
       return "esr"
@@ -74,9 +92,11 @@ class FirefoxVersion(BrowserVersion):
     raise ValueError(f"Unsupported channel: {channel}")
 
   @property
+  @override
   def has_complete_parts(self) -> bool:
     return len(self.parts) == 3
 
   @property
+  @override
   def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
     return (self.comparable_parts(self._PARTS_LEN), self._channel)
diff --git a/crossbench/browsers/firefox/webdriver.py b/crossbench/browsers/firefox/webdriver.py
index 15da878a..06d11c41 100644
--- a/crossbench/browsers/firefox/webdriver.py
+++ b/crossbench/browsers/firefox/webdriver.py
@@ -4,24 +4,25 @@
 
 from __future__ import annotations
 
-import json
 import logging
 import os
 import shutil
 import stat
 import tempfile
-from typing import TYPE_CHECKING, Dict, List, Optional, Tuple
+from typing import TYPE_CHECKING, Dict, List, Tuple
 
 from selenium import webdriver
 from selenium.webdriver.firefox.firefox_profile import FirefoxProfile
 from selenium.webdriver.firefox.options import Options as FirefoxOptions
 from selenium.webdriver.firefox.service import Service as FirefoxService
+from typing_extensions import override
 
-from crossbench import exception, helper
+from crossbench import exception
 from crossbench import path as pth
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.browsers.firefox.firefox import Firefox
 from crossbench.browsers.webdriver import WebDriverBrowser
+from crossbench.helper import url_helper
 
 if TYPE_CHECKING:
   from crossbench.runner.groups.session import BrowserSessionRunGroup
@@ -29,14 +30,17 @@ if TYPE_CHECKING:
 
 class FirefoxWebDriver(WebDriverBrowser, Firefox):
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.FIREFOX | BrowserAttributes.WEBDRIVER
 
+  @override
   def _find_driver(self) -> pth.AnyPath:
     finder = FirefoxDriverFinder(self)
     return finder.download()
 
+  @override
   def _start_driver(self, session: BrowserSessionRunGroup,
                     driver_path: pth.AnyPath) -> webdriver.Remote:
     return self._start_firefox_driver(session, driver_path)
@@ -46,7 +50,7 @@ class FirefoxWebDriver(WebDriverBrowser, Firefox):
     assert not self._is_running
     assert self.log_file
     options = FirefoxOptions()
-    options.set_capability("browserVersion", str(self.major_version))
+    options.set_capability("browserVersion", str(self.version.major))
     # Don't wait for document-ready.
     options.set_capability("pageLoadStrategy", "eager")
     args = self._get_browser_flags_for_session(session)
@@ -59,23 +63,24 @@ class FirefoxWebDriver(WebDriverBrowser, Firefox):
       options.profile = FirefoxProfile(self.cache_dir)
     self._log_browser_start(args, driver_path)
     service_args: List[str] = []
-    log_path: Optional[str] = None
+    driver_log_path: str | None = None
     if self._settings.driver_logging:
+      # TODO: Separate browser from driver logging
       service_args += ["--log", "debug"]
-      log_path = os.fspath(self.driver_log_file)
+      driver_log_path = os.fspath(self._setup_driver_log_file())
     # Explicitly copy the env vars for FirefoxBrowserProfilerProbeContext
     env_copy = dict(self.platform.environ)
     service = FirefoxService(
         executable_path=os.fspath(driver_path),
-        log_path=log_path,
+        log_output=driver_log_path,  # type: ignore
+        # TODO: remove after upgrading the vpython selenium version.
+        log_path=driver_log_path,
         service_args=service_args,
         env=env_copy)
-    # TODO support remote platforms:
-    service.log_file = self.host_platform.local_path(self.stdout_log_file).open(
-        "w", encoding="utf-8")
     driver = webdriver.Firefox(options=options, service=service)
     return driver
 
+  @override
   def _validate_driver_version(self) -> None:
     # TODO
     # version = self.platform.sh_stdout(self._driver_path, "--version")
@@ -85,7 +90,7 @@ class FirefoxWebDriver(WebDriverBrowser, Firefox):
 class FirefoxDriverFinder:
   RELEASES_URL = "https://api.github.com/repos/mozilla/geckodriver/releases"
 
-  def __init__(self, browser: FirefoxWebDriver):
+  def __init__(self, browser: FirefoxWebDriver) -> None:
     self.browser = browser
     self.platform = browser.platform
     self.extension = ""
@@ -93,7 +98,7 @@ class FirefoxDriverFinder:
       self.extension = ".exe"
     cache_dir = self.platform.host_platform.local_cache_dir("driver")
     self.driver_path = (
-        cache_dir / f"geckodriver-{self.browser.major_version}{self.extension}")
+        cache_dir / f"geckodriver-{self.browser.version.major}{self.extension}")
 
   def download(self) -> pth.LocalPath:
     if not self.driver_path.exists():
@@ -143,7 +148,7 @@ class FirefoxDriverFinder:
     return url, archive_type
 
   def _get_driver_version(self) -> Tuple[int, int, int]:
-    version = self.browser.major_version
+    version = self.browser.version.major
     # See https://firefox-source-docs.mozilla.org/testing/geckodriver/Support.html
     if version < 52:
       raise ValueError(f"Firefox {version} is too old for geckodriver.")
@@ -160,8 +165,8 @@ class FirefoxDriverFinder:
     return (9999, 9999, 9999)
 
   def _load_releases(self) -> Dict[Tuple[int, ...], Dict]:
-    with helper.urlopen(self.RELEASES_URL) as response:
-      releases = json.loads(response.read().decode("utf-8"))
+    response = url_helper.get(self.RELEASES_URL)
+    releases = response.json()
     assert isinstance(releases, list)
     versions = {}
     for release in releases:
diff --git a/crossbench/browsers/safari/applescript.py b/crossbench/browsers/safari/applescript.py
index 96976571..dcc68884 100644
--- a/crossbench/browsers/safari/applescript.py
+++ b/crossbench/browsers/safari/applescript.py
@@ -4,6 +4,8 @@
 
 from __future__ import annotations
 
+from typing_extensions import override
+
 from crossbench.browsers.applescript import AppleScriptBrowser
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.browsers.safari.safari import Safari
@@ -17,6 +19,7 @@ class SafariAppleScript(Safari, AppleScriptBrowser):
   APPLE_SCRIPT_SET_URL: str = (
       "set URL of the current tab of front window to %(url)s")
 
+  @override
   def _setup_window(self) -> None:
     self._exec_apple_script(f"""
       tell application "System Events"
@@ -41,6 +44,7 @@ class SafariAppleScript(Safari, AppleScriptBrowser):
       self._exec_apple_script("set the bounds of the first window to {%s}" %
                               bounds)
 
+  @override
   def quit(self) -> None:
     super().quit()
     # Safari doesn't react to "quit" when using the full app path.
@@ -49,6 +53,7 @@ class SafariAppleScript(Safari, AppleScriptBrowser):
           quit
         end tell""")
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.SAFARI | BrowserAttributes.APPLESCRIPT
diff --git a/crossbench/browsers/safari/safari.py b/crossbench/browsers/safari/safari.py
index 906becda..90b206eb 100644
--- a/crossbench/browsers/safari/safari.py
+++ b/crossbench/browsers/safari/safari.py
@@ -7,14 +7,17 @@ from __future__ import annotations
 import logging
 from typing import TYPE_CHECKING, Optional
 
-from crossbench import compat
+from typing_extensions import override
+
 from crossbench import path as pth
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.browsers.browser import Browser
+from crossbench.browsers.safari.version import SafariVersion
 
 if TYPE_CHECKING:
   from crossbench import plt
   from crossbench.browsers.settings import Settings
+  from crossbench.browsers.version import BrowserVersion
 
 
 SAFARIDRIVER_PATH = pth.AnyPosixPath("/usr/bin/safaridriver")
@@ -27,7 +30,7 @@ def find_safaridriver(bin_path: pth.AnyPath,
   if platform.exists(driver_path):
     return driver_path
   # The system-default Safari version doesn't come with the driver
-  assert compat.is_relative_to(bin_path, Safari.default_path(platform)), (
+  assert bin_path.is_relative_to(Safari.default_path(platform)), (
       f"Expected default Safari.app binary but got {bin_path}")
   return SAFARIDRIVER_PATH
 
@@ -42,53 +45,53 @@ class Safari(Browser):
   def technology_preview_path(cls, platform: plt.Platform) -> pth.AnyPath:
     return platform.path("/Applications/Safari Technology Preview.app")
 
+  @classmethod
+  @override
+  def type_name(cls) -> str:
+    return "safari"
+
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
+    return BrowserAttributes.SAFARI
+
   def __init__(self,
                label: str,
                path: pth.AnyPath,
-               settings: Optional[Settings] = None):
+               settings: Optional[Settings] = None) -> None:
+    self.bundle_name: str = ""
     super().__init__(label, path, settings=settings)
     assert self.platform.is_macos, "Safari only works on MacOS"
-    self.bundle_name: str = ""
 
-  def _setup_path(self, path: Optional[pth.AnyPath] = None) -> None:
-    super()._setup_path(path)
+  def _init_path_and_version(self, path: Optional[pth.AnyPath] = None) -> None:
+    super()._init_path_and_version(path)
     assert self.path
     self.bundle_name = self.path.stem.replace(" ", "")
+    assert self.bundle_name
 
-  def _setup_cache_dir(self, settings: Settings) -> None:
-    assert settings.cache_dir is None, (
+  @override
+  def _extract_version(self) -> SafariVersion:
+    assert self.path
+    app_version: str = self.platform.app_version(self.path)
+    driver_version = self.platform.app_version(
+        find_safaridriver(self.path, self.platform))
+    return SafariVersion.parse(f"{app_version} {driver_version}")
+
+  @override
+  def _setup_cache_dir(self) -> Optional[pth.AnyPath]:
+    assert self.settings.cache_dir is None, (
         "Cannot set custom cache dir for Safari")
     assert self.bundle_name, "Missing bundle_name"
-    self.cache_dir = self.platform.home() / (
+    cache_dir = self.platform.home() / (
         f"Library/Containers/com.apple.{self.bundle_name}/Data/Library/Caches")
-
-  @property
-  def type_name(self) -> str:
-    return "safari"
-
-  @property
-  def attributes(self) -> BrowserAttributes:
-    return BrowserAttributes.SAFARI
-
-  def clear_cache(self) -> None:
-    self._clear_cache()
-
-  def _clear_cache(self) -> None:
-    logging.info("CLEAR CACHE: %s", self)
-    self.platform.exec_apple_script(f"""
-      tell application "{self.app_path}" to activate
-      tell application "System Events"
-          keystroke "e" using {{command down, option down}}
-      end tell""")
-
-  def _extract_version(self) -> str:
-    # Use the shipped safaridriver to get the more detailed version
-    # TODO: support remote platform
-    driver_version = self.platform.app_version(
-        find_safaridriver(self.path, self.platform))
-    # Input: "Included with Safari 16.6 (18615.3.6.11.1)"
-    # Output: " (18615.3.6.11.1)"
-    driver_version = " (" + driver_version.split(" (", maxsplit=1)[1]
-    assert self.path
-    app_path = self.path.parents[2]
-    return self.platform.app_version(app_path) + driver_version
+    if not self.platform.exists(cache_dir.parent):
+      logging.warning("Could not find existing config dir for %s.", self)
+      return None
+    self._clear_cache(cache_dir)
+    return cache_dir
+
+  @override
+  def _clear_cache(self, cache_dir: Optional[pth.AnyPath]) -> None:
+    super()._clear_cache(cache_dir)
+    # This magic wait lowers safaridriver startup failures.
+    self.platform.sleep(0.5)
diff --git a/crossbench/browsers/safari/version.py b/crossbench/browsers/safari/version.py
index 776ac9e4..e541880f 100644
--- a/crossbench/browsers/safari/version.py
+++ b/crossbench/browsers/safari/version.py
@@ -5,35 +5,69 @@
 from __future__ import annotations
 
 import re
-from typing import Final, Tuple
+from typing import TYPE_CHECKING, Final, Tuple
+
+from typing_extensions import override
 
 from crossbench.browsers.version import BrowserVersion, BrowserVersionChannel
 
+if TYPE_CHECKING:
+  VersionParseResult = Tuple[Tuple[int, ...], BrowserVersionChannel, str]
 
 class SafariVersion(BrowserVersion):
-  _MIN_PARTS_LEN: Final[int] = 4
-  _VERSION_RE = re.compile(
-      r"(?P<major_minor>\d+\.\d+)"
-      r"[^(]+ "
-      r"\((?P<version>(Release (?P<release>\d+), )?(?P<parts>([\d.]+)+))\)"
-      r".*", re.I)
+  _MIN_MAJOR_PARTS_LEN: Final[int] = 3
+  _MIN_PARTS_LEN: Final[int] = 3
+  _SIMPLE_VERSION_RE = re.compile(
+      r"(?P<name>Safari(?: Technology Preview)?) "
+      r"(?P<parts>(?:[\d.]+)+)", re.I)
+  _COMPLEX_VERSION_RE = re.compile(r"[^\d]*"
+                                   r"(?P<major_parts>[\d.]+)"
+                                   #  r"[^(0-9]+ "
+                                   r".*\("
+                                   r"(?P<version>(Release (?P<release>\d+), )?"
+                                   r"(?P<parts>[\d.]+))"
+                                   r"\).*")
+
+  @classmethod
+  @override
+  def _parse(cls, full_version: str) -> VersionParseResult:
+    if "Safari" in full_version:
+      full_version = full_version.strip()
+      if matches := cls._SIMPLE_VERSION_RE.fullmatch(full_version):
+        return cls._parse_simple_version(full_version, matches)
+      if matches := cls._COMPLEX_VERSION_RE.fullmatch(full_version):
+        return cls._parse_complex_version(full_version, matches)
+    raise cls.parse_error("Could not extract version number", full_version)
 
   @classmethod
-  def _parse(
-      cls,
-      full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
-    matches = cls._VERSION_RE.fullmatch(full_version.strip())
-    if not matches:
-      raise cls.parse_error("Could not extract version number", full_version)
+  def _parse_complex_version(cls, full_version: str,
+                             matches) -> VersionParseResult:
     version_str = matches["version"]
     parts_str = matches["parts"]
-    major_minor_str = matches["major_minor"]
-    assert version_str and parts_str and major_minor_str
+    major_parts_str = matches["major_parts"]
+    assert version_str and parts_str and major_parts_str
     channel = cls._parse_channel(full_version)
-    major, minor = tuple(map(int, major_minor_str.split(".")))
+    major_parts = tuple(map(int, major_parts_str.split(".")))
+    if len(major_parts) < cls._MIN_MAJOR_PARTS_LEN:
+      major_parts += (0,) * (cls._MIN_MAJOR_PARTS_LEN - len(major_parts))
+    major_parts = major_parts[:cls._MIN_MAJOR_PARTS_LEN]
     release = 0
     if release_str := matches["release"]:
       release = int(release_str)
+    parts = cls._parse_parts(full_version, parts_str)
+    parts = major_parts + (release,) + parts
+    return parts, channel, f"{major_parts_str} ({version_str})"
+
+  @classmethod
+  def _parse_simple_version(cls, full_version: str,
+                            matches) -> VersionParseResult:
+    channel: BrowserVersionChannel = cls._parse_channel(full_version)
+    parts = cls._parse_parts(full_version, matches["parts"])
+    parts += (0,)
+    return parts, channel, full_version
+
+  @classmethod
+  def _parse_parts(cls, full_version: str, parts_str: str) -> Tuple[int, ...]:
     try:
       parts = tuple(map(int, parts_str.split(".")))
     except ValueError as e:
@@ -42,8 +76,7 @@ class SafariVersion(BrowserVersion):
     if len(parts) < cls._MIN_PARTS_LEN:
       raise cls.parse_error("Invalid number of version number parts",
                             full_version)
-    parts = (major, minor, release) + parts
-    return parts, channel, f"{major_minor_str} ({version_str})"
+    return parts
 
   @classmethod
   def _parse_channel(cls, full_version: str) -> BrowserVersionChannel:
@@ -54,6 +87,7 @@ class SafariVersion(BrowserVersion):
     return BrowserVersionChannel.STABLE
 
   @property
+  @override
   def has_complete_parts(self) -> bool:
     return len(self.parts) >= self._MIN_PARTS_LEN
 
@@ -63,8 +97,9 @@ class SafariVersion(BrowserVersion):
 
   @property
   def release(self) -> int:
-    return self._parts[2]
+    return self._parts[self._MIN_MAJOR_PARTS_LEN]
 
+  @override
   def _channel_name(self, channel: BrowserVersionChannel) -> str:
     if channel == BrowserVersionChannel.STABLE:
       return "stable"
@@ -73,5 +108,6 @@ class SafariVersion(BrowserVersion):
     raise ValueError(f"Unsupported channel: {channel}")
 
   @property
+  @override
   def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
     return (self.comparable_parts(self._MIN_PARTS_LEN), self._channel)
diff --git a/crossbench/browsers/safari/webdriver.py b/crossbench/browsers/safari/webdriver.py
index 0e8d3127..739a4b15 100644
--- a/crossbench/browsers/safari/webdriver.py
+++ b/crossbench/browsers/safari/webdriver.py
@@ -12,15 +12,17 @@ from typing import TYPE_CHECKING, Any, Dict, Optional, Set, Type
 from selenium import webdriver
 from selenium.webdriver.safari.options import Options as SafariOptions
 from selenium.webdriver.safari.service import Service as SafariService
+from typing_extensions import override
 
-from crossbench import exception, helper
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.browsers.safari.safari import Safari, find_safaridriver
 from crossbench.browsers.webdriver import DriverException, WebDriverBrowser
+from crossbench.helper.spinner import Spinner
+from crossbench.helper.wait import WaitRange
 
 if TYPE_CHECKING:
   from crossbench.browsers.settings import Settings
-  from crossbench.path import AnyPath
+  from crossbench.path import AnyPath, LocalPath
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
 
@@ -31,25 +33,27 @@ class SafariWebDriver(WebDriverBrowser, Safari):
   def __init__(self,
                label: str,
                path: AnyPath,
-               settings: Optional[Settings] = None):
+               settings: Optional[Settings] = None) -> None:
     super().__init__(label, path, settings)
     assert self.platform.is_macos
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.SAFARI | BrowserAttributes.WEBDRIVER
 
-  def clear_cache(self) -> None:
-    # skip the default caching, and only do it after launching the browser
-    # via selenium.
-    pass
-
+  @override
   def _find_driver(self) -> AnyPath:
     # TODO: support remote platform
     assert self.platform.is_local, "Remote platform is not supported yet"
     return self.host_platform.local_path(
         find_safaridriver(self.path, self.platform))
 
+  @override
+  def _setup_driver_log_file(self) -> LocalPath:
+    raise NotImplementedError("Cannot use custom driver log path for Safari")
+
+  @override
   def _start_driver(self, session: BrowserSessionRunGroup,
                     driver_path: AnyPath) -> webdriver.Remote:
     return self._start_safari_driver(session, driver_path)
@@ -62,18 +66,13 @@ class SafariWebDriver(WebDriverBrowser, Safari):
 
     options: SafariOptions = self._get_driver_options(session)
     session.setup_selenium_options(options)
-    self._force_clear_cache(session)
 
     service = SafariService(executable_path=os.fspath(driver_path))
     driver_kwargs = {"service": service, "options": options}
 
-    if webdriver.__version__ == "4.1.0":
-      # Manually inject desired options for older selenium versions
-      # (currently fixed version from vpython3).
-      self._legacy_settings(options, driver_kwargs)
-
-    with helper.Spinner():
+    with Spinner():
       driver = self._start_driver_with_retries(driver_kwargs)
+      self.platform.sleep(0.5)
 
     assert driver.session_id, "Could not start webdriver"
     logs: AnyPath = (
@@ -81,8 +80,8 @@ class SafariWebDriver(WebDriverBrowser, Safari):
         driver.session_id)
     all_logs = list(self.platform.glob(logs, "safaridriver*"))
     if all_logs:
-      self.log_file = all_logs[0]
-      assert self.platform.is_file(self.log_file)
+      self._driver_log_file = all_logs[0]
+      assert self.platform.is_file(self._driver_log_file)
     return driver
 
   # TODO(cbruni): implement iOS platform
@@ -92,7 +91,7 @@ class SafariWebDriver(WebDriverBrowser, Safari):
     # Let's give it several chances to start up.
     seen_exceptions: Set[Type[Exception]] = set()
     retries = 0
-    for _ in helper.WaitRange(
+    for _ in WaitRange(
         min=2, timeout=self.MAX_STARTUP_TIMEOUT).wait_with_backoff():
       try:
         return webdriver.Safari(**driver_kwargs)
@@ -108,18 +107,6 @@ class SafariWebDriver(WebDriverBrowser, Safari):
         seen_exceptions.add(type(e))
     raise DriverException("Could not start SafariWebDriver")
 
-  def _legacy_settings(self, options, driver_kwargs) -> None:
-    logging.debug("SafariDriver: using legacy capabilities")
-    options.binary_location = str(self.path)
-    driver_kwargs["desired_capabilities"] = options.to_capabilities()
-
-  def _force_clear_cache(self, session: BrowserSessionRunGroup) -> None:
-    del session
-    with exception.annotate("Clearing Browser Cache"):
-      self._clear_cache()
-      self.platform.exec_apple_script(f"""
-        tell application "{self.app_path}" to quit """)
-
   def _get_driver_options(self,
                           session: BrowserSessionRunGroup) -> SafariOptions:
     options = SafariOptions()
@@ -137,6 +124,7 @@ class SafariWebDriver(WebDriverBrowser, Safari):
       options.use_technology_preview = True
     return options
 
+  @override
   def _validate_driver_version(self) -> None:
     # The bundled driver is always ok
     assert self._driver_path
@@ -144,10 +132,11 @@ class SafariWebDriver(WebDriverBrowser, Safari):
       if parent == self.path.parent:
         return
     version = self.platform.sh_stdout(self._driver_path, "--version")
-    assert str(self.major_version) in version, (
+    assert str(self.version.major) in version, (
         f"safaridriver={self._driver_path} version='{version}' "
-        f" doesn't match safari version={self.major_version}")
+        f" doesn't match safari version={self.version.major}")
 
+  @override
   def _setup_window(self) -> None:
     super()._setup_window()
     self.platform.exec_apple_script(f"""
@@ -155,18 +144,29 @@ class SafariWebDriver(WebDriverBrowser, Safari):
           activate
         end tell""")
 
+  @override
   def quit(self) -> None:
     super().quit()
-    # Safari needs some additional push to quit properly
-    self.platform.exec_apple_script(f"""
-        tell application "{self.app_name}"
-          quit
-        end tell""")
+    if self.platform.is_macos:
+      # Safari needs some additional push to quit properly
+      self.platform.exec_apple_script(f"""
+          tell application "{self.app_name}"
+            quit
+          end tell""")
+
+  @override
+  def force_quit(self) -> None:
+    try:
+      super().force_quit()
+    finally:
+      # Certain safaridriver versions keep on lingering around when they fail.
+      self.platform.sh("killall", "-9", "safaridriver", check=False)
 
 
 class SafariWebdriverIOS(SafariWebDriver):
   MAX_STARTUP_TIMEOUT = dt.timedelta(seconds=15)
 
+  @override
   def _get_driver_options(self,
                           session: BrowserSessionRunGroup) -> SafariOptions:
     options = super()._get_driver_options(session)
@@ -185,14 +185,6 @@ class SafariWebdriverIOS(SafariWebDriver):
       options.set_capability(key, value)
     return options
 
+  @override
   def _setup_window(self) -> None:
     pass
-
-  def _force_clear_cache(self, session: BrowserSessionRunGroup) -> None:
-    pass
-
-  def quit(self) -> None:
-    self._private_driver.close()
-    self.platform.sleep(1.0)
-    self._private_driver.quit()
-    self.force_quit()
diff --git a/crossbench/browsers/settings.py b/crossbench/browsers/settings.py
index 09cca3cb..e0453b72 100644
--- a/crossbench/browsers/settings.py
+++ b/crossbench/browsers/settings.py
@@ -7,44 +7,50 @@ from __future__ import annotations
 import datetime as dt
 from typing import TYPE_CHECKING, Optional
 
+from typing_extensions import override
+
 from crossbench import path as pth
 from crossbench import plt
 from crossbench.browsers.splash_screen import SplashScreen
 from crossbench.browsers.viewport import Viewport
+from crossbench.cli.config.secrets import Secrets
 from crossbench.flags.base import Flags, FlagsData
 from crossbench.flags.chrome import ChromeFlags
 from crossbench.network.live import LiveNetwork
 
 if TYPE_CHECKING:
-  from crossbench.cli.config.secrets import Secret, SecretsDict, SecretType
   from crossbench.network.base import Network
 
 
 class Settings:
   """Container object for browser agnostic settings."""
 
-  def __init__(self,
-               flags: Optional[FlagsData] = None,
-               js_flags: Optional[FlagsData] = None,
-               cache_dir: Optional[pth.AnyPath] = None,
-               network: Optional[Network] = None,
-               driver_path: Optional[pth.AnyPath] = None,
-               viewport: Optional[Viewport] = None,
-               splash_screen: Optional[SplashScreen] = None,
-               platform: Optional[plt.Platform] = None,
-               secrets: Optional[SecretsDict] = None,
-               driver_logging: bool = False,
-               wipe_system_user_data: bool = False,
-               http_request_timeout: dt.timedelta = dt.timedelta()):
+  def __init__(
+      self,
+      flags: Optional[FlagsData] = None,
+      js_flags: Optional[FlagsData] = None,
+      cache_dir: Optional[pth.AnyPath] = None,
+      clear_cache_dir: bool = True,
+      network: Optional[Network] = None,
+      driver_path: Optional[pth.AnyPath] = None,
+      viewport: Optional[Viewport] = None,
+      splash_screen: Optional[SplashScreen] = None,
+      platform: Optional[plt.Platform] = None,
+      secrets: Secrets = Secrets(),
+      driver_logging: bool = False,
+      wipe_system_user_data: bool = False,
+      http_request_timeout: dt.timedelta = dt.timedelta()
+  ) -> None:
     self._flags = self._convert_flags(flags, "flags")
     self._js_flags = self._extract_js_flags(self._flags, js_flags)
     self._cache_dir = cache_dir
+    self._clear_cache_dir = clear_cache_dir
     self._platform = platform or plt.PLATFORM
     self._driver_path = driver_path
     self._network: Network = network or LiveNetwork()
     self._viewport: Viewport = viewport or Viewport.DEFAULT
     self._splash_screen: SplashScreen = splash_screen or SplashScreen.DEFAULT
-    self._secrets: SecretsDict = secrets or {}
+    self._secrets: Secrets = secrets
     self._driver_logging = driver_logging
     self._wipe_system_user_data = wipe_system_user_data
     self._http_request_timeout = http_request_timeout
@@ -86,6 +92,10 @@ class Settings:
   def cache_dir(self) -> Optional[pth.AnyPath]:
     return self._cache_dir
 
+  @property
+  def clear_cache_dir(self) -> bool:
+    return self._clear_cache_dir
+
   @property
   def driver_path(self) -> Optional[pth.AnyPath]:
     return self._driver_path
@@ -99,7 +109,7 @@ class Settings:
     return self._network
 
   @property
-  def secrets(self) -> SecretsDict:
+  def secrets(self) -> Secrets:
     return self._secrets
 
   @property
@@ -115,10 +125,12 @@ class Settings:
     return self._http_request_timeout
 
   @property
+  @override
   def viewport(self) -> Viewport:
     return self._viewport
 
   @viewport.setter
+  @override
   def viewport(self, value: Viewport) -> None:
     assert self._viewport.is_default
     self._viewport = value
diff --git a/crossbench/browsers/splash_screen.py b/crossbench/browsers/splash_screen.py
index c96c64ee..59751682 100644
--- a/crossbench/browsers/splash_screen.py
+++ b/crossbench/browsers/splash_screen.py
@@ -5,15 +5,26 @@
 from __future__ import annotations
 
 import abc
+import dataclasses
 import html
-import urllib.parse
 from argparse import ArgumentTypeError
 from typing import TYPE_CHECKING, Any, Dict
 
+from typing_extensions import override
+
 from crossbench import path as pth
+from crossbench.helper import url_helper
 
 if TYPE_CHECKING:
-  from crossbench.runner.run import Run
+  from crossbench.browsers.browser import Browser
+  from crossbench.runner.actions import Actions
+
+
+@dataclasses.dataclass(frozen=True)
+class SplashScreenData:
+  is_warmup: bool
+  browser: Browser
+  run_details: Dict
 
 
 class SplashScreen:
@@ -39,14 +50,13 @@ class SplashScreen:
       return URLSplashScreen(maybe_path.absolute().as_uri())
     raise ArgumentTypeError(f"Unknown splashscreen: {value}")
 
-  def run(self, run: Run) -> None:
+  def run(self, action: Actions, info: SplashScreenData) -> None:
     pass
 
 
 _BLANK_PAGE_HTML = "<html></html>"
 _BLANK_PAGE_DATA_URL = (
-    f"data:text/html;charset=utf-8,{urllib.parse.quote(_BLANK_PAGE_HTML)}")
-
+    f"data:text/html;charset=utf-8,{url_helper.quote(_BLANK_PAGE_HTML)}")
 
 class BaseURLSplashScreen(SplashScreen, metaclass=abc.ABCMeta):
 
@@ -54,26 +64,26 @@ class BaseURLSplashScreen(SplashScreen, metaclass=abc.ABCMeta):
     super().__init__()
     self._timeout = timeout
 
-  def run(self, run: Run) -> None:
-    with run.actions("SplashScreen") as action:
-      action.show_url(self.get_url(run))
-      action.wait(self._timeout)
-      action.show_url(_BLANK_PAGE_DATA_URL)
+  def run(self, action: Actions, info: SplashScreenData) -> None:
+    action.show_url(self.get_url(info))
+    action.wait(self._timeout)
+    action.show_url(_BLANK_PAGE_DATA_URL)
 
   @abc.abstractmethod
-  def get_url(self, run: Run) -> str:
+  def get_url(self, info: SplashScreenData) -> str:
     pass
 
 
 class DetailedSplashScreen(BaseURLSplashScreen):
 
-  def get_url(self, run: Run) -> str:
-    browser = run.browser
+  @override
+  def get_url(self, info: SplashScreenData) -> str:
+    browser: Browser = info.browser
     title = html.escape(browser.app_name.title())
-    version = html.escape(browser.version)
+    version = html.escape(str(browser.version))
     run_type = "Run"
     bg_color = "#000"
-    if run.is_warmup:
+    if info.is_warmup:
       title = f"Warmup: {title}"
       run_type = "Warmup Run"
       bg_color = "#444"
@@ -92,11 +102,11 @@ class DetailedSplashScreen(BaseURLSplashScreen):
         "</style>",
         "</head><body>",
         f"<h1>{title} {version}</h1>",
-        self._render_browser_details(run),
-        self._render_run_details(run),
+        self._render_browser_details(info),
+        self._render_run_details(info),
         "</body></html>",
     ))
-    data_url = f"data:text/html;charset=utf-8,{urllib.parse.quote(page)}"
+    data_url = f"data:text/html;charset=utf-8,{url_helper.quote(page)}"
     return data_url
 
   def _render_properties(self, title: str, properties: Dict[str, Any]) -> str:
@@ -107,19 +117,20 @@ class DetailedSplashScreen(BaseURLSplashScreen):
     section += "</dl>"
     return section
 
-  def _render_browser_details(self, run: Run) -> str:
-    browser = run.browser
+  def _render_browser_details(self, info: SplashScreenData) -> str:
+    browser: Browser = info.browser
     properties = {"User Agent": browser.user_agent(), **browser.details_json()}
     return self._render_properties("Browser Details", properties)
 
-  def _render_run_details(self, run: Run) -> str:
-    return self._render_properties("Run Details", run.details_json())
+  def _render_run_details(self, info: SplashScreenData) -> str:
+    return self._render_properties("Run Details", info.run_details)
 
 
 class MinimalSplashScreen(DetailedSplashScreen):
 
-  def _render_browser_details(self, run: Run) -> str:
-    properties = {"User Agent": run.browser.user_agent()}
+  @override
+  def _render_browser_details(self, info: SplashScreenData) -> str:
+    properties = {"User Agent": info.browser.user_agent()}
     return self._render_properties("Browser Details", properties)
 
 
@@ -129,7 +140,9 @@ class URLSplashScreen(BaseURLSplashScreen):
     super().__init__(timeout)
     self._url = url
 
-  def get_url(self, run: Run) -> str:
+  @override
+  def get_url(self, info: SplashScreenData) -> str:
+    del info
     return self._url
 
   @property
diff --git a/crossbench/browsers/version.py b/crossbench/browsers/version.py
index 6a17d8c3..787c9952 100644
--- a/crossbench/browsers/version.py
+++ b/crossbench/browsers/version.py
@@ -9,7 +9,9 @@ import dataclasses
 import enum
 import functools
 import re
-from typing import Any, Final, Iterable, Optional, Tuple, Type, TypeVar
+from typing import Any, Final, Iterable, Optional, Self, Tuple
+
+from typing_extensions import override
 
 
 @dataclasses.dataclass
@@ -48,7 +50,7 @@ class BrowserVersionChannel(_BrowserVersionChannelMixin, enum.Enum):
 
 class BrowserVersionParseError(ValueError):
 
-  def __init__(self, name: str, msg: str, version: str):
+  def __init__(self, name: str, msg: str, version: str) -> None:
     self._version = version
     super().__init__(f"Invalid {name} {repr(version)}: {msg}")
 
@@ -61,9 +63,7 @@ class BrowserVersionNoChannelError(ValueError):
   pass
 
 
-BrowserVersionT = TypeVar("BrowserVersionT", bound="BrowserVersion")
-
-_VERSION_DIGITS_ONLY_RE = re.compile(r"\d+(\.\d+)*")
+_VERSION_DIGITS_ONLY_RE: re.Pattern[str] = re.compile(r"\d+(\.\d+)*")
 
 
 @functools.total_ordering
@@ -76,7 +76,7 @@ class BrowserVersion(abc.ABC):
   _version_str: str
 
   @classmethod
-  def parse_unique(cls: Type[BrowserVersionT], value: str) -> BrowserVersionT:
+  def parse_unique(cls, value: str) -> Self:
     """Parse a unique version identifier for a browser.
     Unlike the parse() method, this should only parse input values that can
     be unambiguously associated with a specific BrowserVersion."""
@@ -86,9 +86,9 @@ class BrowserVersion(abc.ABC):
     return cls.parse(value)
 
   @classmethod
-  def parse(cls: Type[BrowserVersionT],
+  def parse(cls,
             value: str,
-            channel: Optional[BrowserVersionChannel] = None) -> BrowserVersionT:
+            channel: Optional[BrowserVersionChannel] = None) -> Self:
     (parts, parsed_channel, version_str) = cls._parse(value)
     parts = cls._validate_parts(parts, value)
     return cls(parts, channel or parsed_channel, version_str)
@@ -123,39 +123,27 @@ class BrowserVersion(abc.ABC):
     return BrowserVersionParseError(cls.__name__, msg, version)
 
   @classmethod
-  def any(cls: Type[BrowserVersionT],
-          parts: Iterable[int],
-          version_str: str = "") -> BrowserVersionT:
+  def any(cls, parts: Iterable[int], version_str: str = "") -> Self:
     return cls(parts, BrowserVersionChannel.ANY, version_str)
 
   @classmethod
-  def lts(cls: Type[BrowserVersionT],
-          parts: Iterable[int],
-          version_str: str = "") -> BrowserVersionT:
+  def lts(cls, parts: Iterable[int], version_str: str = "") -> Self:
     return cls(parts, BrowserVersionChannel.LTS, version_str)
 
   @classmethod
-  def stable(cls: Type[BrowserVersionT],
-             parts: Iterable[int],
-             version_str: str = "") -> BrowserVersionT:
+  def stable(cls, parts: Iterable[int], version_str: str = "") -> Self:
     return cls(parts, BrowserVersionChannel.STABLE, version_str)
 
   @classmethod
-  def beta(cls: Type[BrowserVersionT],
-           parts: Iterable[int],
-           version_str: str = "") -> BrowserVersionT:
+  def beta(cls, parts: Iterable[int], version_str: str = "") -> Self:
     return cls(parts, BrowserVersionChannel.BETA, version_str)
 
   @classmethod
-  def alpha(cls: Type[BrowserVersionT],
-            parts: Iterable[int],
-            version_str: str = "") -> BrowserVersionT:
+  def alpha(cls, parts: Iterable[int], version_str: str = "") -> Self:
     return cls(parts, BrowserVersionChannel.ALPHA, version_str)
 
   @classmethod
-  def pre_alpha(cls: Type[BrowserVersionT],
-                parts: Iterable[int],
-                version_str: str = "") -> BrowserVersionT:
+  def pre_alpha(cls, parts: Iterable[int], version_str: str = "") -> Self:
     return cls(parts, BrowserVersionChannel.PRE_ALPHA, version_str)
 
   def __init__(self,
@@ -262,6 +250,11 @@ class BrowserVersion(abc.ABC):
   def key(self) -> Tuple[Tuple[int, ...], BrowserVersionChannel]:
     return (self._parts, self._channel)
 
+  def with_channel(self, channel: BrowserVersionChannel) -> Self:
+    if self.channel == channel:
+      return self
+    return type(self)(self.parts, channel, self.version_str)  # pytype: disable=not-instantiable
+
   def __str__(self) -> str:
     if not self._version_str:
       if not self._parts:
@@ -274,15 +267,19 @@ class BrowserVersion(abc.ABC):
         f"{self.__class__.__name__}"
         f"({self.parts_str}, {self.channel_name}, {repr(self._version_str)})")
 
+  def is_compatible_type(self, other: BrowserVersion) -> bool:
+    return isinstance(other, type(self)) or isinstance(self, type(other))
+
   def __eq__(self, other: Any) -> bool:
-    if not isinstance(other, type(self)):
+    if not self.is_compatible_type(other):
       return False
     return self.key == other.key
 
   def __le__(self, other: Any) -> bool:
-    if not isinstance(other, type(self)):
-      raise TypeError("Cannot compare versions from different browsers: "
-                      f"{self} vs. {other}.")
+    if not self.is_compatible_type(other):
+      raise TypeError("Cannot compare versions from unrelated browsers: "
+                      f"{type(self).__name__} vs. "
+                      f"{type(other).__name__}.")
     if self.is_channel_version and other.is_channel_version:
       return self._channel <= other._channel
     if self.is_channel_version:
@@ -320,18 +317,22 @@ class UnknownBrowserVersion(BrowserVersion):
     super().__init__(parts, BrowserVersionChannel.ANY, version_str)
 
   @classmethod
+  @override
   def _parse(
       cls,
       full_version: str) -> Tuple[Tuple[int, ...], BrowserVersionChannel, str]:
     raise RuntimeError("UnknownBrowserVersion does not support parsing")
 
+  @override
   def _channel_name(self, channel: BrowserVersionChannel) -> str:
     return "unknown"
 
   @property
+  @override
   def has_complete_parts(self) -> bool:
     return False
 
   @property
+  @override
   def is_unknown(self) -> bool:
     return True
diff --git a/crossbench/browsers/viewport.py b/crossbench/browsers/viewport.py
index d846a12e..ff6d60e4 100644
--- a/crossbench/browsers/viewport.py
+++ b/crossbench/browsers/viewport.py
@@ -8,11 +8,9 @@ import enum
 from argparse import ArgumentTypeError
 from typing import Any, Tuple
 
-from crossbench import compat
-
 
 @enum.unique
-class ViewportMode(compat.StrEnum):
+class ViewportMode(enum.StrEnum):
   SIZE = "size"
   MAXIMIZED = "maximized"
   FULLSCREEN = "fullscreen"
@@ -66,7 +64,7 @@ class Viewport:
                height: int = 1000,
                x: int = 10,
                y: int = 50,
-               mode: ViewportMode = ViewportMode.SIZE):
+               mode: ViewportMode = ViewportMode.SIZE) -> None:
     self._width = width
     self._height = height
     self._x = x
diff --git a/crossbench/browsers/webdriver.py b/crossbench/browsers/webdriver.py
index bc1d35ae..2ceee37b 100644
--- a/crossbench/browsers/webdriver.py
+++ b/crossbench/browsers/webdriver.py
@@ -10,15 +10,18 @@ import logging
 import os
 import time
 import traceback
-from typing import TYPE_CHECKING, Any, List, Optional, Sequence, cast
+from typing import TYPE_CHECKING, Any, List, Optional, Sequence, Tuple, cast
 
 import selenium.common.exceptions
 import urllib3
 from selenium import webdriver
 from selenium.webdriver.remote.remote_connection import RemoteConnection
+from typing_extensions import override
 
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.browsers.browser import Browser
+from crossbench.browsers.version import BrowserVersion, UnknownBrowserVersion
+from crossbench.probes.internal.browser.driver_log import BrowserDriverLogProbe
 from crossbench.types import JsonDict
 
 if TYPE_CHECKING:
@@ -49,29 +52,30 @@ class DriverException(RuntimeError):
 
 
 class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
+  # TODO: properly annotate this lazily initialized instance variable.
   _private_driver: webdriver.Remote
-  _driver_path: Optional[AnyPath]
-  _driver_pid: int
-  _pid: int
-  log_file: Optional[LocalPath]
 
   def __init__(self,
                label: str,
                path: Optional[AnyPath] = None,
-               settings: Optional[Settings] = None):
+               settings: Optional[Settings] = None) -> None:
     super().__init__(label, path, settings)
-    self._driver_path = self._settings.driver_path
-
-  @property
-  def attributes(self) -> BrowserAttributes:
+    self._driver_path: AnyPath | None = self._settings.driver_path
+    self._driver_log_file: LocalPath | None = None
+    self._driver_pid: int = 0
+    self._pid: int = 0
+    self.log_file: LocalPath | None = None
+
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.WEBDRIVER
 
   @property
-  def driver_log_file(self) -> LocalPath:
-    log_file = self.log_file
-    assert log_file
-    return log_file.with_suffix(".driver.log")
+  def driver_log_file(self) -> Optional[LocalPath]:
+    return self._driver_log_file
 
+  @override
   def validate_binary(self) -> None:
     super().validate_binary()
     self._driver_path = self.platform.absolute(self._find_driver())
@@ -87,18 +91,21 @@ class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
   def _validate_driver_version(self) -> None:
     pass
 
+  @override
   def validate_env(self, env: HostEnvironment) -> None:
     super().validate_env(env)
     self._validate_driver_version()
 
+  @override
   def start(self, session: BrowserSessionRunGroup) -> None:
+    super().start(session)
     assert self._driver_path
     if timeout := self.http_request_timeout:
       logging.debug("Setting http request timeout to %s", timeout)
       RemoteConnection.set_timeout(timeout.total_seconds())
     try:
       self._private_driver = self._start_driver(session, self._driver_path)
-    except selenium.common.exceptions.SessionNotCreatedException as e:
+    except selenium.common.exceptions.WebDriverException as e:
       msg = e.msg or "Could not create Webdriver session."
       raise DriverException(msg, self) from e
     self._is_running = True
@@ -146,11 +153,21 @@ class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
       timeouts.page_load = timing.timeout_timedelta(page_load).total_seconds()
     self._private_driver.timeouts = timeouts
 
+  def _setup_driver_log_file(self) -> LocalPath:
+    log_file = self.log_file
+    assert log_file, "Missing browser log file"
+    self._driver_log_file = log_file.with_suffix(".driver.log")
+    assert self._driver_log_file.name == BrowserDriverLogProbe.NAME, (
+        f"Expected driver log file name {BrowserDriverLogProbe.NAME}, "
+        f"but got: {self._driver_log_file}")
+    return self._driver_log_file
+
   def _setup_window(self) -> None:
     # Force main window to foreground.
     self._private_driver.switch_to.window(
         self._private_driver.current_window_handle)
-    if self.viewport.is_headless:
+    if (self.viewport.is_headless or
+        not self._private_driver.capabilities["setWindowRect"]):
       return
     if self.viewport.is_fullscreen:
       self._private_driver.fullscreen_window()
@@ -166,20 +183,21 @@ class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
                     driver_path: AnyPath) -> webdriver.Remote:
     pass
 
+  @override
   def details_json(self) -> JsonDict:
     details: JsonDict = super().details_json()
     log = cast(JsonDict, details["log"])
-    if self.log_file:
+    if self.driver_log_file:
       log["driver"] = os.fspath(self.driver_log_file)
     return details
 
+  @override
   def show_url(self, url: str, target: Optional[str] = None) -> None:
     logging.debug("WebDriverBrowser.show_url(%s, %s)", url, target)
     try:
       if target in ("_self", None):
-        handles = self._private_driver.window_handles
-        assert handles, "Browser has no more opened windows."
-        self._private_driver.switch_to.window(handles[-1])
+        # Do the navigation in the active tab.
+        pass
       elif target == "_new_tab":
         self._private_driver.switch_to.new_window("tab")
       elif target == "_new_window":
@@ -192,9 +210,11 @@ class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
         self._wrap_webdriver_exception(e, msg, url)
       raise
 
+  @override
   def switch_to_new_tab(self) -> None:
     self._private_driver.switch_to.new_window("tab")
 
+  @override
   def screenshot(self, path: LocalPath) -> None:
     if not self._private_driver.get_screenshot_as_file(path.as_posix()):
       raise DriverException(
@@ -212,6 +232,7 @@ class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
           f"Browser failed to load URL={url}. "
           f"The device is not connected to the internet.", self) from e
 
+  @override
   def js(
       self,
       script: str,
@@ -241,11 +262,15 @@ class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
             urllib3.exceptions.MaxRetryError) as e:
       logging.debug("%s: Got errors while closing all tabs: {%s}", self, e)
 
+  @override
   def quit(self) -> None:
-    assert self._is_running
-    self.close_all_tabs()
-    self.force_quit()
+    try:
+      assert self._is_running
+      self.close_all_tabs()
+    finally:
+      super().quit()
 
+  @override
   def force_quit(self) -> None:
     if getattr(self, "_private_driver", None) is None or not self._is_running:
       return
@@ -282,48 +307,57 @@ class WebDriverBrowser(Browser, metaclass=abc.ABCMeta):
 class RemoteWebDriver(WebDriverBrowser, Browser):
   """Represent a remote WebDriver that has already been started"""
 
-  def __init__(self, label: str, driver: webdriver.Remote) -> None:
-    super().__init__(label=label, path=None)
-    self._private_driver = driver
-    self.version: str = driver.capabilities["browserVersion"]
-    self.major_version: int = int(self.version.split(".")[0])
-
-  @property
-  def type_name(self) -> str:
+  @classmethod
+  @override
+  def type_name(cls) -> str:
     return "remote"
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.WEBDRIVER | BrowserAttributes.REMOTE
 
+  def __init__(self, label: str, driver: webdriver.Remote) -> None:
+    self._private_driver = driver
+    super().__init__(label=label, path=None)
+
+  @override
+  def _extract_version(self) -> BrowserVersion:
+    raw_version: str = self._private_driver.capabilities["browserVersion"]
+    parts: Tuple[int, ...] = tuple(map(int, raw_version.split(".")))
+    return UnknownBrowserVersion(parts, version_str=raw_version)
+
+  @override
   def _validate_driver_version(self) -> None:
     pass
 
-  def _extract_version(self) -> str:
-    raise NotImplementedError()
-
+  @override
   def _find_driver(self) -> LocalPath:
     raise NotImplementedError()
 
+  @override
   def _start_driver(self, session: BrowserSessionRunGroup,
                     driver_path: AnyPath) -> webdriver.Remote:
     raise NotImplementedError()
 
-  def setup_binary(self) -> None:
+  @override
+  def _setup_binary(self) -> None:
+    pass
+
+  @override
+  def _setup_cache_dir(self):
+    pass
+
+  def validate_binary(self) -> None:
     pass
 
+  @override
   def start(self, session: BrowserSessionRunGroup) -> None:
     # Driver has already been started. We just need to mark it as running.
     self._is_running = True
-    if self.viewport.is_fullscreen:
-      self._private_driver.fullscreen_window()
-    elif self.viewport.is_maximized:
-      self._private_driver.maximize_window()
-    else:
-      self._private_driver.set_window_position(self.viewport.x, self.viewport.y)
-      self._private_driver.set_window_size(self.viewport.width,
-                                           self.viewport.height)
+    self._setup_window()
 
+  @override
   def quit(self) -> None:
     # External code that started the driver is responsible for shutting it down.
     self._is_running = False
diff --git a/crossbench/cbb/cbb_adapter.py b/crossbench/cbb/cbb_adapter.py
index 83c6b939..d9b304a5 100644
--- a/crossbench/cbb/cbb_adapter.py
+++ b/crossbench/cbb/cbb_adapter.py
@@ -13,9 +13,10 @@ with corresponding changes in CBB in google3
 from __future__ import annotations
 
 import datetime as dt
-from typing import TYPE_CHECKING, List, Optional, Type
+from typing import TYPE_CHECKING, Dict, List, Optional, Type
 
 from selenium import webdriver
+from typing_extensions import override
 
 import crossbench.benchmarks.all as benchmarks
 import crossbench.browsers.browser
@@ -32,18 +33,27 @@ if TYPE_CHECKING:
   from crossbench.stories.story import Story
 
 press_benchmarks: List[Type[PressBenchmark]] = [
+    # Speedometer:
     benchmarks.Speedometer20Benchmark,
     benchmarks.Speedometer21Benchmark,
     benchmarks.Speedometer30Benchmark,
+    benchmarks.Speedometer31Benchmark,
+    benchmarks.SpeedometerMainBenchmark,
+    # MotionMark:
     benchmarks.MotionMark12Benchmark,
     benchmarks.MotionMark13Benchmark,
+    benchmarks.MotionMark131Benchmark,
+    benchmarks.MotionMarkMainBenchmark,
+    # JetStream:
     benchmarks.JetStream20Benchmark,
     benchmarks.JetStream21Benchmark,
     benchmarks.JetStream22Benchmark,
-    benchmarks.JetStream30Benchmark,
+    benchmarks.JetStreamMainBenchmark,
 ]
 
-press_benchmarks_dict = {cls.NAME: cls for cls in press_benchmarks}
+press_benchmarks_dict: Dict[str, Type[PressBenchmark]] = {
+    cls.NAME: cls for cls in press_benchmarks
+}
 
 
 def get_pressbenchmark_cls(
@@ -86,7 +96,6 @@ def create_remote_webdriver(driver: webdriver.Remote
   """
 
   browser = cb_webdriver.RemoteWebDriver("default", driver)
-  browser.version = driver.capabilities["browserVersion"]
   return browser
 
 
@@ -119,6 +128,7 @@ def get_probe_result_file(benchmark_name: str,
 
 class CbbRunner(crossbench.runner.runner.Runner):
 
+  @override
   def create_run(self, browser_session: BrowserSessionRunGroup, story: Story,
                  repetition: int, is_warmup: bool, temperature: str, index: int,
                  name: str, timeout: dt.timedelta, throw: bool) -> Run:
@@ -128,7 +138,8 @@ class CbbRunner(crossbench.runner.runner.Runner):
 
 class CbbRun(Run):
 
-  def _create_session_dir(self) -> None:
+  @override
+  def _setup_session_dir(self) -> None:
     # Don't create symlink loops and skip this step
     pass
 
diff --git a/crossbench/cli/btp.py b/crossbench/cli/btp.py
index 5d6e22c4..bc0c19b0 100644
--- a/crossbench/cli/btp.py
+++ b/crossbench/cli/btp.py
@@ -5,7 +5,7 @@
 
 import argparse
 import logging
-from typing import Dict, Optional, Sequence
+from typing import Dict, Sequence
 
 from perfetto.batch_trace_processor.api import (BatchTraceProcessor,
                                                 BatchTraceProcessorConfig,
@@ -14,7 +14,7 @@ from perfetto.trace_processor.api import TraceProcessorConfig
 from perfetto.trace_uri_resolver.resolver import TraceUriResolver
 
 from crossbench import path as pth
-from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
 from crossbench.cli.parser import CrossBenchArgumentParser
 from crossbench.parse import PathParser
 from crossbench.probes.perfetto.trace_processor.trace_processor import (
@@ -26,7 +26,8 @@ DEFAULT_CONFIG_PATH = (
     ROOT_DIR / "config" / "benchmark" / "loadline" / "probe_config.hjson")
 
 class MergedTraceUriResolver(TraceUriResolver):
-  def __init__(self, result_path: pth.LocalPath):
+
+  def __init__(self, result_path: pth.LocalPath) -> None:
 
     def metadata(path) -> Dict[str, str]:
       parts = str(path).split("/")
@@ -47,7 +48,8 @@ class MergedTraceUriResolver(TraceUriResolver):
     return self._resolved
 
 class BTPUtil:
-  def __init__(self):
+
+  def __init__(self) -> None:
     self.parser = CrossBenchArgumentParser(
       description=("Runs trace processor queries in a batch mode on existing "
                    "benchmark results, without re-running the benchmark "
@@ -76,11 +78,11 @@ class BTPUtil:
         help=("Name of the query to compute (the query must be present in the "
               "trace_processor/queries/ dir). Repeat for multiple queries."))
 
-  def run(self, argv: Sequence[str]):
+  def run(self, argv: Sequence[str]) -> None:
     args = self.parser.parse_args(argv)
 
     probe_config = ProbeListConfig.parse_path(args.probe_config)
-    tp: Optional[TraceProcessorProbe] = None
+    tp: TraceProcessorProbe | None = None
     for probe in probe_config.probes:
       if isinstance(probe, TraceProcessorProbe):
         tp = probe
diff --git a/crossbench/cli/cli.py b/crossbench/cli/cli.py
index 92c92301..a5c02fcd 100644
--- a/crossbench/cli/cli.py
+++ b/crossbench/cli/cli.py
@@ -5,51 +5,37 @@
 from __future__ import annotations
 
 import argparse
-import datetime as dt
-import json
 import logging
+import os
 import sys
 import textwrap
 import traceback
 from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Tuple,
-                    Type, Union)
+                    Type)
 
 import tabulate as tbl
 
 import crossbench.benchmarks.all as benchmarks
 from crossbench import __version__
 from crossbench import path as pth
-from crossbench import plt
 from crossbench.benchmarks.base import Benchmark
-from crossbench.browsers import splash_screen, viewport
-from crossbench.cli import ui
-from crossbench.cli.config.browser import BrowserConfig
-from crossbench.cli.config.browser_variants import BrowserVariantsConfig
-from crossbench.cli.config.env import (parse_env_config_file,
-                                       parse_inline_env_config)
-from crossbench.cli.config.network import NetworkConfig
-from crossbench.cli.config.probe import (PROBE_LOOKUP, ProbeConfig,
-                                         ProbeListConfig)
-from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.cli import exception_formatter, ui
 from crossbench.cli.parser import CrossBenchArgumentParser
-from crossbench.cli.subcommand.devtools_recorder_proxy.default import \
-    CrossbenchDevToolsRecorderProxy
-from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
-                            ValidationMode)
-from crossbench.parse import (DurationParser, LateArgumentError, ObjectParser,
-                              PathParser)
-from crossbench.probes.all import GENERAL_PURPOSE_PROBES, DebuggerProbe
-from crossbench.probes.internal import ErrorsProbe
-from crossbench.probes.thermal_monitor import ThermalStatus
+from crossbench.cli.subcommand.benchmark import BenchmarkSubcommand
+from crossbench.cli.subcommand.describe import DescribeSubcommand
+from crossbench.cli.subcommand.devtools_recorder_proxy.subcommand import \
+    DevtoolsRecorderProxySubcommand
+from crossbench.cli.subcommand.help import HelpSubcommand
+from crossbench.cli.subcommand.version import VersionSubcommand
+from crossbench.parse import LateArgumentError
+from crossbench.probes.all import GENERAL_PURPOSE_PROBES
 from crossbench.runner.runner import Runner
-from crossbench.runner.timing import Timing
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
-  from crossbench.probes.probe import Probe
-  from crossbench.runner.run import Run
   BenchmarkClsT = Type[Benchmark]
   BrowserLookupTableT = Dict[str, Tuple[Type[Browser], pth.LocalPath]]
+  from crossbench.cli.subcommand.base import CrossbenchSubcommand
 
 
 class CrossBenchArgumentError(argparse.ArgumentError):
@@ -71,8 +57,7 @@ class CrossBenchArgumentError(argparse.ArgumentError):
             f"{formatted}")
 
 
-argparse.ArgumentError = CrossBenchArgumentError
-
+argparse.ArgumentError = CrossBenchArgumentError  # type: ignore
 
 class EnableDebuggingAction(argparse.Action):
   """Custom action to set both --throw and -vvv."""
@@ -80,54 +65,20 @@ class EnableDebuggingAction(argparse.Action):
   def __call__(self,
                parser: argparse.ArgumentParser,
                namespace: argparse.Namespace,
-               values: Union[str, Sequence[Any], None],
+               values: str | Sequence[Any] | None,
                option_string: Optional[str] = None) -> None:
     setattr(namespace, "throw", True)
     setattr(namespace, "verbosity", 3)
     setattr(namespace, "driver_logging", True)
 
 
-class EnableFastAction(argparse.Action):
-  """Custom action to enable fast test runs"""
-
-  def __call__(self,
-               parser: argparse.ArgumentParser,
-               namespace: argparse.Namespace,
-               values: Union[str, Sequence[Any], None],
-               option_string: Optional[str] = None) -> None:
-    setattr(namespace, "cool_down_time", dt.timedelta())
-    setattr(namespace, "splash_screen", splash_screen.SplashScreen.NONE)
-    setattr(namespace, "env_validation", ValidationMode.SKIP)
-
-
-class AppendDebuggerProbeAction(argparse.Action):
-  """Custom action to set multiple args when --gdb or --lldb are set:
-  - Add a DebuggerProbe config.
-  - Increase --timeout-unit to a large value to keep debug session alive for a
-    longer time.
-  """
-
-  def __call__(self,
-               parser: argparse.ArgumentParser,
-               namespace: argparse.Namespace,
-               values: Union[str, Sequence[Any], None],
-               option_string: Optional[str] = None) -> None:
-    probes: List[ProbeConfig] = getattr(namespace, self.dest, [])
-    probe_settings = {"debugger": "gdb"}
-    if option_string and "lldb" in option_string:
-      probe_settings["debugger"] = "lldb"
-    probes.append(ProbeConfig(DebuggerProbe, probe_settings))
-    if not getattr(namespace, "timeout_unit", None):
-      # Set a very large --timeout-unit to allow for very slow debugging without
-      # causing timeouts (for instance when waiting on a breakpoint).
-      setattr(namespace, "timeout_unit", dt.timedelta.max)
-
-
 class MainCrossBenchArgumentParser(CrossBenchArgumentParser):
 
   def print_help(self, file=None) -> None:
     super().print_help(file=file)
     self.print_probes(file=file)
+    self.print_urls(file=file)
+    self.print_example(file=file)
 
   def print_probes(self, file=None) -> None:
     lines = [
@@ -150,44 +101,95 @@ class MainCrossBenchArgumentParser(CrossBenchArgumentParser):
     file.write(textwrap.indent(contents, "    "))
     file.write("\n")
 
+  def print_urls(self, file=None) -> None:
+    file = file or sys.stdout
+    file.write("\n")
+    file.write("URLS:\n")
+    file.write("  Source: https://chromium.googlesource.com/crossbench\n")
+    file.write("  Bugs:   "
+               "https://issues.chromium.org/u/1/issues/new?component=1456712\n")
+
+  def print_example(self, file=None) -> None:
+    file = file or sys.stdout
+    file.write("\n")
+    file.write("EXAMPLE:\n")
+    file.write("  ./cb.py speedometer --browser=chrome-m131 "
+               "--browser=out/release/chrome --probe=profiling\n\n")
+    readme_file = pth.AnyPath(__file__).parent / "README.md"
+    file.write(f"  See {readme_file} for more details.\n")
 
 class CrossBenchCLI:
   BENCHMARKS: Tuple[BenchmarkClsT, ...] = (
+      # JetStream:
       benchmarks.JetStream20Benchmark,
       benchmarks.JetStream21Benchmark,
       benchmarks.JetStream22Benchmark,
-      benchmarks.JetStream30Benchmark,
+      benchmarks.JetStreamMainBenchmark,
+      # Loading:
+      benchmarks.LoadingBenchmark,
+      # LoadLine:
       benchmarks.LoadLinePhoneBenchmark,
+      benchmarks.LoadLinePhoneDebugBenchmark,
+      benchmarks.LoadLinePhoneFastBenchmark,
       benchmarks.LoadLineTabletBenchmark,
+      benchmarks.LoadLineTabletDebugBenchmark,
+      benchmarks.LoadLineTabletFastBenchmark,
+      # Manual:
       benchmarks.ManualBenchmark,
+      # Memory:
+      benchmarks.MemoryBenchmark,
+      # Motionmark
       benchmarks.MotionMark10Benchmark,
       benchmarks.MotionMark11Benchmark,
       benchmarks.MotionMark12Benchmark,
       benchmarks.MotionMark13Benchmark,
-      benchmarks.PageLoadBenchmark,
+      benchmarks.MotionMark131Benchmark,
+      benchmarks.MotionMarkMainBenchmark,
+      # Speedometer:
       benchmarks.Speedometer20Benchmark,
       benchmarks.Speedometer21Benchmark,
       benchmarks.Speedometer30Benchmark,
-      benchmarks.MemoryBenchmark,
+      benchmarks.Speedometer31Benchmark,
+      benchmarks.SpeedometerMainBenchmark,
   )
 
   RUNNER_CLS: Type[Runner] = Runner
 
   def __init__(self, enable_logging: bool = True) -> None:
     self._enable_logging = enable_logging
-    self._console_handler: Optional[logging.StreamHandler] = None
-    self._subparsers: Dict[BenchmarkClsT, CrossBenchArgumentParser] = {}
+    self._console_handler: logging.StreamHandler | None = None
+    self._benchmark_subcommands: Dict[BenchmarkClsT, BenchmarkSubcommand] = {}
     self.parser = MainCrossBenchArgumentParser(
         description=("A cross browser and cross benchmark runner "
-                     "with configurable measurement probes."))
-    self.describe_parser = CrossBenchArgumentParser()
-    self.recorder_parser = CrossBenchArgumentParser()
-    self.args = argparse.Namespace()
+                     "with configurable measurement probes.\n"))
+    self._subparsers = self._setup_subparsers()
     self._setup_parser()
-    self._setup_subparser()
+    self._describe_subcommand = DescribeSubcommand(self)
+    self._help_subcommand = HelpSubcommand(self)
+    self._version_subcommand = VersionSubcommand(self)
+    self._recorder_proxy_subcommand = DevtoolsRecorderProxySubcommand(self)
+    self._last_subcommand: CrossbenchSubcommand | None = None
+    self.args = argparse.Namespace()
+    self._setup_subcommands()
+
+  @property
+  def subparsers(self):
+    return self._subparsers
+
+  @property
+  def describe_subcommand(self) -> DescribeSubcommand:
+    return self._describe_subcommand
+
+  @property
+  def help_subcommand(self) -> HelpSubcommand:
+    return self._help_subcommand
+
+  @property
+  def last_subcommand(self) -> CrossbenchSubcommand | None:
+    return self._last_subcommand
 
   def _setup_parser(self) -> None:
-    self._add_verbosity_argument(self.parser)
+    self.add_verbosity_argument(self.parser)
     # Disable colors by default when piped to a file.
     has_color = hasattr(sys.stdout, "isatty") and sys.stdout.isatty()
     self.parser.add_argument(
@@ -199,7 +201,16 @@ class CrossBenchCLI:
     self.parser.add_argument(
         "--version", action="version", version=f"%(prog)s {__version__}")
 
-  def _add_verbosity_argument(self, parser: argparse.ArgumentParser) -> None:
+  def _setup_subparsers(
+      self) -> argparse._SubParsersAction[CrossBenchArgumentParser]:
+    subparsers = self.parser.add_subparsers(
+        title="Subcommands",
+        dest="subcommand",
+        required=True,
+        parser_class=CrossBenchArgumentParser)
+    return subparsers
+
+  def add_verbosity_argument(self, parser: argparse.ArgumentParser) -> None:
     debug_group = parser.add_argument_group("Verbosity / Debugging Options")
     verbosity_group = debug_group.add_mutually_exclusive_group()
     verbosity_group.add_argument(
@@ -218,13 +229,7 @@ class CrossBenchCLI:
         default=0,
         help=("Increase output verbosity. "
               "Repeat for more verbose output (0..2)."))
-    debug_group.add_argument(
-        "--driver-logging",
-        "--verbose-driver",
-        action="store_true",
-        default=False,
-        help=("Enable verbose webdriver logging. "
-              "Disabled by default, automatically enable with --debug"))
+
     debug_group.add_argument(
         "--throw",
         action="store_true",
@@ -238,833 +243,19 @@ class CrossBenchCLI:
         nargs=0,
         help="Enable debug output, equivalent to --throw -vvv")
 
-    debugger_group = debug_group.add_mutually_exclusive_group()
-    debugger_group.add_argument(
-        "--gdb",
-        action=AppendDebuggerProbeAction,
-        nargs=0,
-        dest="probe",
-        help=("Launch chrome with gdb or lldb attached to all processes. "
-              " See 'describe probe debugger' for more options."))
-    debugger_group.add_argument(
-        "--lldb",
-        action=AppendDebuggerProbeAction,
-        nargs=0,
-        dest="probe",
-        help=("Launch chrome with lldb attached to all processes."
-              " See 'describe probe debugger' for more options."))
-
-  def _setup_subparser(self) -> None:
-    self.subparsers = self.parser.add_subparsers(
-        title="Subcommands",
-        dest="subcommand",
-        required=True,
-        parser_class=CrossBenchArgumentParser)
+  def _setup_subcommands(self) -> None:
     for benchmark_cls in self.BENCHMARKS:
-      self._setup_benchmark_subparser(benchmark_cls)
-    self._setup_help_subparser()
-    self._setup_describe_subparser()
-    self._setup_recorder_subparser()
+      subcommand = BenchmarkSubcommand(self, benchmark_cls)
+      self._benchmark_subcommands[benchmark_cls] = subcommand
 
-  def _setup_recorder_subparser(self) -> None:
-    self.recorder_parser = CrossbenchDevToolsRecorderProxy.add_subcommand(
-        self.subparsers)
-    assert isinstance(self.recorder_parser, CrossBenchArgumentParser)
-    self._add_verbosity_argument(self.recorder_parser)
-
-  def _setup_describe_subparser(self) -> None:
-    self.describe_parser = self.subparsers.add_parser(
-        "describe", aliases=["desc"], help="Print all benchmarks and stories")
-    assert isinstance(self.describe_parser, CrossBenchArgumentParser)
-    self.describe_parser.add_argument(
-        "category",
-        nargs="?",
-        choices=["all", "benchmark", "benchmarks", "probe", "probes"],
-        default="all",
-        help="Limit output to the given category, defaults to 'all'")
-    self.describe_parser.add_argument(
-        "filter",
-        nargs="?",
-        help=("Only display the given item from the provided category. "
-              "By default all items are displayed. "
-              "Example: describe probes v8.log"))
-    self.describe_parser.add_argument(
-        "--json",
-        default=False,
-        action="store_true",
-        help="Print the data as json data")
-    self.describe_parser.set_defaults(subcommand_fn=self.describe_subcommand)
-    self._add_verbosity_argument(self.describe_parser)
-
-  def _setup_help_subparser(self) -> None:
-    # Just for completeness we want to support "--help" and "help"
-    help_parser = self.subparsers.add_parser(
-        "help", help="Print the top-level, same as --help")
-    help_parser.set_defaults(subcommand_fn=self.help_subcommand)
-    version_parser = self.subparsers.add_parser(
-        "version",
-        help="Show program's version number and exit, same as --version")
-    version_parser.set_defaults(subcommand_fn=self.version_subcommand)
-    assert isinstance(self.describe_parser, CrossBenchArgumentParser)
-    self._add_verbosity_argument(self.describe_parser)
-
-  def describe_subcommand(self, args: argparse.Namespace) -> None:
-    benchmarks_data: Dict[str, Any] = {}
-    for benchmark_cls in self.BENCHMARKS:
-      aliases: Tuple[str, ...] = benchmark_cls.aliases()
-      if args.filter:
-        if benchmark_cls.NAME != args.filter and args.filter not in aliases:
-          continue
-      benchmark_info = benchmark_cls.describe()
-      benchmark_info["aliases"] = aliases or "None"
-      benchmark_info["help"] = f"See `{benchmark_cls.NAME} --help`"
-      benchmarks_data[benchmark_cls.NAME] = benchmark_info
-    data: Dict[str, Dict[str, Any]] = {
-        "benchmarks": benchmarks_data,
-        "probes": {
-            str(probe_cls.NAME): probe_cls.help_text()
-            for probe_cls in GENERAL_PURPOSE_PROBES
-            if not args.filter or probe_cls.NAME == args.filter
-        }
-    }
-    if args.json:
-      if args.category in ("probe", "probes"):
-        data = data["probes"]
-        if not data:
-          self.error(f"No matching probe found: '{args.filter}'")
-      elif args.category in ("benchmark", "benchmarks"):
-        data = data["benchmarks"]
-        if not data:
-          self.error(f"No matching benchmark found: '{args.filter}'")
-      else:
-        assert args.category == "all"
-        if not data["benchmarks"] and not data["probes"]:
-          self.error(f"No matching benchmarks or probes found: '{args.filter}'")
-      print(json.dumps(data, indent=2))
-      return
-    # Create tabular format
-    printed_any = False
-    if args.category in ("all", "benchmark", "benchmarks"):
-      table: List[List[Optional[str]]] = [["Benchmark", "Property", "Value"]]
-      for benchmark_name, values in data["benchmarks"].items():
-        table.append([
-            benchmark_name,
-        ])
-        for name, value in values.items():
-          if isinstance(value, (tuple, list)):
-            value = "\n".join(value)
-          elif isinstance(value, dict):
-            if not value.items():
-              value = "[]"
-            else:
-              kwargs = {"maxcolwidths": 60}
-              value = tbl.tabulate(value.items(), tablefmt="plain", **kwargs)
-          table.append([None, name, value])
-      if len(table) <= 1:
-        if args.category != "all":
-          self.error(f"No matching benchmark found: '{args.filter}'")
-      else:
-        printed_any = True
-        print(tbl.tabulate(table, tablefmt="grid"))
-
-    if args.category in ("all", "probe", "probes"):
-      table = [["Probe", "Help"]]
-      for probe_name, probe_desc in data["probes"].items():
-        table.append([probe_name, probe_desc])
-      if len(table) <= 1:
-        if args.category != "all":
-          self.error(f"No matching probe found: '{args.filter}'")
-      else:
-        printed_any = True
-        print(tbl.tabulate(table, tablefmt="grid"))
-
-    if not printed_any:
-      self.error(f"No matching benchmarks or probes found: '{args.filter}'")
-
-  def help_subcommand(self, args: argparse.Namespace) -> None:
-    del args
-    self.parser.print_help()
-    sys.exit(0)
-
-  def version_subcommand(self, args: argparse.Namespace) -> None:
-    del args
-    print(f"{sys.argv[0]} {__version__}")
-    sys.exit(0)
-
-  def _setup_benchmark_subparser(self, benchmark_cls: Type[Benchmark]) -> None:
-    subparser = benchmark_cls.add_cli_parser(self.subparsers,
-                                             benchmark_cls.aliases())
-    self.RUNNER_CLS.add_cli_parser(benchmark_cls, subparser)
-    assert isinstance(subparser, argparse.ArgumentParser), (
-        f"Benchmark class {benchmark_cls}.add_cli_parser did not return "
-        f"an ArgumentParser: {subparser}")
-    self._subparsers[benchmark_cls] = subparser
-
-    runner_group = subparser.add_argument_group("Runner Options", "")
-    runner_group.add_argument(
-        "--cache-dir",
-        type=pth.LocalPath,
-        default=None,
-        help=("Used for caching browser binaries and archives. "
-              "Defaults to binary_cache"))
-
-    cooldown_group = runner_group.add_mutually_exclusive_group()
-    cooldown_group.add_argument(
-        "--cool-down-threshold",
-        type=ThermalStatus.parse,
-        help=("Pause execution when the device reaches this thermal status. "
-              "Exucution resumes once the status drops below the threshold. "
-              "Only available on Android."))
-    cooldown_group.add_argument(
-        "--cool-down-time",
-        "--cool-down",
-        type=DurationParser.positive_or_zero_duration,
-        default=dt.timedelta(seconds=2),
-        help=("Wait between repetitions for a fixed amount of time. "
-              f"Format: {DurationParser.help()}"))
-    cooldown_group.add_argument(
-        "--no-cool-down",
-        action="store_const",
-        dest="cool_down_time",
-        const=dt.timedelta(seconds=0),
-        help=("Disable cool-down between runs (might cause CPU throttling), "
-              "equivalent to --cool-down=0."))
-    cooldown_group.add_argument(
-        "--fast",
-        action=EnableFastAction,
-        nargs=0,
-        help=("Switch to a fast run mode "
-              "which might yield unstable performance results. "
-              "Equivalent to --cool-down=0 --no-splash --env-validation=skip."))
-
-    runner_group.add_argument(
-        "--time-unit",
-        type=DurationParser.any_duration,
-        default=dt.timedelta(seconds=1),
-        help=("Absolute duration of 1 time unit in the runner. "
-              "Increase this for slow builds or machines. "
-              f"Format: {DurationParser.help()}"))
-    runner_group.add_argument(
-        "--timeout-unit",
-        type=DurationParser.any_duration,
-        default=dt.timedelta(),
-        help=("Absolute duration of 1 time unit for timeouts in the runner. "
-              "Unlike --time-unit, this does only apply for timeouts, "
-              "as opposed to say initial wait times or sleeps."
-              f"Format: {DurationParser.help()}"))
-    runner_group.add_argument(
-        "--run-timeout",
-        type=DurationParser.positive_or_zero_duration,
-        default=dt.timedelta(),
-        help=("Sets the same timeout per run on all browsers. "
-              "Runs will be aborted after the given timeout. "
-              f"Format: {DurationParser.help()}"))
-    runner_group.add_argument(
-        "--start-delay",
-        type=DurationParser.positive_or_zero_duration,
-        default=dt.timedelta(),
-        help=("Delay before running the core workload, "
-              "after a story's/workload's setup, "
-              "and after starting the browser."))
-    runner_group.add_argument(
-        "--stop-delay",
-        type=DurationParser.positive_or_zero_duration,
-        default=dt.timedelta(),
-        help=("Delay after running the core workload, "
-              "before story's/workload's teardown, "
-              "and before quitting the browser."))
-
-    network_group = subparser.add_argument_group("Network Options", "")
-    network_settings_group = network_group.add_mutually_exclusive_group()
-    network_settings_group.add_argument(
-        "--network",
-        type=NetworkConfig.parse,
-        help=("Either an inline network config or an file path to full "
-              "network config hjson file (see --network-config)."))
-    network_settings_group.add_argument(
-        "--network-config",
-        metavar="DIR",
-        type=NetworkConfig.parse_config_path,
-        help=NetworkConfig.help())
-    network_settings_group.add_argument(
-        "--local-file-server",
-        "--local-fileserver",
-        "--file-server",
-        "--fileserver",
-        type=NetworkConfig.parse_local,
-        metavar="DIR",
-        dest="network",
-        help="Start a local http file server at the given directory.")
-    network_settings_group.add_argument(
-        "--wpr",
-        "--web-page-replay",
-        type=NetworkConfig.parse_wpr,
-        metavar="WPR_ARCHIVE",
-        dest="network",
-        help=("Use wpr.archive to replay network requests "
-              "via a local proxy server. "
-              "Archives can be recorded with --probe=wpr. "
-              "WPR_ARCHIVE can be a local file or a gs:// google storage url."))
-
-    env_group = subparser.add_argument_group("Environment Options", "")
-    env_settings_group = env_group.add_mutually_exclusive_group()
-    env_settings_group.add_argument(
-        "--env",
-        type=parse_inline_env_config,
-        help=("Set default runner environment settings. "
-              f"Possible values: {', '.join(HostEnvironment.CONFIGS)}"
-              "or an inline hjson configuration (see --env-config). "
-              "Mutually exclusive with --env-config"))
-    env_settings_group.add_argument(
-        "--env-config",
-        type=parse_env_config_file,
-        help=("Path to an env.config.hjson file that specifies detailed "
-              "runner environment settings and requirements. "
-              "See config/env.config.hjson for more details."
-              "Mutually exclusive with --env"))
-
-    env_group.add_argument(
-        "--env-validation",
-        default=ValidationMode.PROMPT,
-        type=ValidationMode,
-        help=(
-            "Set how runner env is validated (see als --env-config/--env):\n" +
-            ValidationMode.help_text(indent=2)))
-    env_group.add_argument(
-        "--dry-run",
-        action="store_true",
-        default=False,
-        help="Don't run any browsers or probes")
-
-    browser_group = subparser.add_argument_group(
-        "Browser Options", "Any other browser option can be passed "
-        "after the '--' arguments separator.")
-    browser_config_group = browser_group.add_mutually_exclusive_group()
-    browser_config_group.add_argument(
-        "--browser",
-        "-b",
-        type=BrowserConfig.parse_with_range,
-        action="extend",
-        default=[],
-        help=(
-            "Browser binary, defaults to 'chrome-stable'."
-            "Use this to test a simple browser variant. "
-            "Use [chrome, chrome-stable, chrome-dev, chrome-canary, "
-            "safari, safari-tp, "
-            "firefox, firefox-stable, firefox-dev, firefox-nightly, "
-            "edge, edge-stable, edge-beta, edge-dev, edge-canary] "
-            "for system default browsers or a full path. \n"
-            "* Use --browser=chrome-M107 to download the latest version for a "
-            "specific milestone\n"
-            "* Use ... to test milestone ranges --browser=chr-M100...M125"
-            "* Use --browser=chrome-100.0.4896.168 to download a specific "
-            "chrome version (macOS and linux for googlers and chrome only). \n"
-            "* Use --browser=path/to/archive.dmg on macOS or "
-            "--browser=path/to/archive.rpm on linux "
-            "for locally cached versions (chrome only).\n"
-            "* Use --browser=\"${ADB_SERIAL}:chrome\" "
-            "(e.g. --browser='0a388e93:chrome') for specific "
-            "android devices or --browser='adb:chrome' if only once device is "
-            "attached.\n"
-            "Repeat for adding multiple browsers. "
-            "The browser result dir's name is "
-            "'${BROWSER}_${PLATFORM}_${INDEX}' "
-            "$INDEX corresponds to the order on the command line."
-            "Cannot be used together with --browser-config"))
-    browser_config_group.add_argument(
-        "--browser-config",
-        type=PathParser.hjson_file_path,
-        help=("Browser configuration.json file. "
-              "Use this to run multiple browsers and/or multiple "
-              "flag configurations. "
-              "See config/doc/browser.config.hjson on how to set up a complex "
-              "configuration file. "
-              "Cannot be used together with --browser."))
-    browser_group.add_argument(
-        "--driver-path",
-        type=PathParser.file_path,
-        help=("Use the same custom driver path for all specified browsers. "
-              "Version mismatches might cause crashes."))
-    browser_group.add_argument(
-        "--config",
-        type=PathParser.hjson_file_path,
-        help=("Specify a common config for --probe-config, --browser-config, "
-              "--network-config and --env-config."))
-    browser_group.add_argument(
-        "--secrets",
-        dest="secrets",
-        type=SecretsConfig.parse,
-        default=SecretsConfig(),
-        help="Path to file containing login secrets")
-
-    browser_group.add_argument(
-        "--wipe-system-user-data",
-        dest="wipe_system_user_data",
-        default=False,
-        action="store_true",
-        help="Clear user data at the beginning of the test "
-        "(be careful using it).")
-    browser_group.add_argument(
-        "--http-request-timeout",
-        type=DurationParser.positive_or_zero_duration,
-        default=dt.timedelta(),
-        help=("Set the timeout of http request. "
-              f"Format: {DurationParser.help()}. "
-              "When not specified, there will be no timeout."))
-
-    splashscreen_group = browser_group.add_mutually_exclusive_group()
-    splashscreen_group.add_argument(
-        "--splash-screen",
-        "--splashscreen",
-        "--splash",
-        type=splash_screen.SplashScreen.parse,
-        default=splash_screen.SplashScreen.DETAILED,
-        help=("Set the splashscreen shown before each run. "
-              "Choices: 'default', 'none', 'minimal', 'detailed,' or "
-              "a path or a URL."))
-    splashscreen_group.add_argument(
-        "--no-splash",
-        "--nosplash",
-        dest="splash_screen",
-        const=splash_screen.SplashScreen.NONE,
-        action="store_const",
-        help="Shortcut for --splash-screen=none")
-
-    viewport_group = browser_group.add_mutually_exclusive_group()
-    # pytype: disable=missing-parameter
-    viewport_group.add_argument(
-        "--viewport",
-        default=viewport.Viewport.DEFAULT,
-        type=viewport.Viewport.parse,
-        help=("Set the browser window position."
-              "Options: size and position, "
-              f"{', '.join(str(e) for e in viewport.ViewportMode)}. "
-              "Examples: --viewport=1550x300 --viewport=fullscreen. "
-              f"Default: {viewport.Viewport.DEFAULT}"))
-    # pytype: enable=missing-parameter
-    viewport_group.add_argument(
-        "--headless",
-        dest="viewport",
-        const=viewport.Viewport.HEADLESS,
-        action="store_const",
-        help=("Start the browser in headless if supported. "
-              "Equivalent to --viewport=headless."))
-
-    chrome_args = subparser.add_argument_group(
-        "Browsers Options: Chrome/Chromium",
-        "For convenience these arguments are directly are forwarded "
-        "directly to chrome. ")
-    chrome_args.add_argument(
-        "--js-flags", dest="js_flags", action="append", default=[])
-
-    doc_str = "See chrome's base/feature_list.h source file for more details"
-    chrome_args.add_argument(
-        "--enable-features",
-        help="Comma-separated list of enabled chrome features. " + doc_str,
-        default="")
-    chrome_args.add_argument(
-        "--disable-features",
-        help="Command-separated list of disabled chrome features. " + doc_str,
-        default="")
-
-    field_trial_group = chrome_args.add_mutually_exclusive_group()
-    field_trial_group.add_argument(
-        "--enable-field-trial-config",
-        "--enable-field-trials",
-        default=None,
-        action="store_true",
-        help=("Use chrome's field-trial configs, "
-              "disabled by default by crossbench"))
-    field_trial_group.add_argument(
-        "--disable-field-trial-config",
-        "--disable-field-trials",
-        dest="enable_field_trial_config",
-        action="store_false",
-        help=("Explicitly disable field-trial configs."
-              "Off by default on official builds, "
-              "and disabled by default by crossbench."))
-
-    probe_group = subparser.add_argument_group("Probe Options", "")
-    probe_config_group = probe_group.add_mutually_exclusive_group()
-    probe_config_group.add_argument(
-        "--probe",
-        action="append",
-        type=ProbeConfig.parse,
-        default=[],
-        help=(
-            "Enable general purpose probes to measure data on all cb.stories. "
-            "This argument can be specified multiple times to add more probes. "
-            "Use inline hjson (e.g. --probe=\"$NAME{$CONFIG}\") "
-            "to configure probes. "
-            "Individual probe configs can be specified in files as well: "
-            "--probe='path/to/config.hjson'."
-            "Use 'describe probes' or 'describe probe $NAME' for probe "
-            "configuration details."
-            "Cannot be used together with --probe-config."
-            f"\n\nChoices: {', '.join(PROBE_LOOKUP.keys())}"))
-    probe_config_group.add_argument(
-        "--probe-config",
-        type=PathParser.hjson_file_path,
-        default=benchmark_cls.default_probe_config_path(),
-        help=("Browser configuration.json file. "
-              "Use this config file to specify more complex Probe settings."
-              "See config/doc/probe.config.hjson on how to set up a complex "
-              "configuration file. "
-              "Cannot be used together with --probe."))
-    subparser.set_defaults(
-        subcommand_fn=self.benchmark_subcommand, benchmark_cls=benchmark_cls)
-    self._add_verbosity_argument(subparser)
-    subparser.add_argument("other_browser_args", nargs="*")
-
-  def benchmark_subcommand(self, args: argparse.Namespace) -> None:
-    benchmark = None
-    runner = None
-    if args.cache_dir:
-      plt.PLATFORM.set_cache_dir(args.cache_dir)
-    self._benchmark_subcommand_helper(args)
-    try:
-      self._benchmark_subcommand_process_args(args)
-      benchmark = self._get_benchmark(args)
-      with plt.PLATFORM.TemporaryDirectory(prefix="crossbench") as tmp_dirname:
-        if args.dry_run:
-          args.out_dir = pth.LocalPath(tmp_dirname) / "results"
-        args.browser = self._get_browsers(args)
-        probes = self._get_probes(args)
-        env_config = self._get_env_config(args)
-        env_validation_mode = self._get_env_validation_mode(args)
-        timing = self._get_timing(args)
-        runner = self._get_runner(args, benchmark, env_config,
-                                  env_validation_mode, timing)
-
-        # We prevent running multiple stories in repetition OR if multiple
-        # browsers are open when 'power' probes are used since it might distort
-        # the data.
-        if len(args.browser) > 1 or args.repetitions > 1:
-          probe_names = [probe.name for probe in probes if probe.BATTERY_ONLY]
-          if probe_names:
-            names_str = ",".join(probe_names)
-            raise argparse.ArgumentTypeError(
-                f"Cannot use [{names_str}] probe(s) "
-                "with repeat > 1 and/or with multiple browsers. We need to "
-                "always start at the same battery level, and by running "
-                "stories on multiple browsers or multiples time will create "
-                "erroneous data.")
-
-        for probe in probes:
-          runner.attach_probe(probe, matching_browser_only=True)
-
-        self._run_benchmark(args, runner)
-    except KeyboardInterrupt:
-      sys.exit(2)
-    except LateArgumentError as e:
-      if args.throw:
-        raise
-      self.handle_late_argument_error(e)
-    except Exception as e:  # pylint: disable=broad-except
-      if args.throw:
-        raise
-      self._log_benchmark_subcommand_failure(benchmark, runner, e)
-      sys.exit(3)
-
-  def _benchmark_subcommand_helper(self, args: argparse.Namespace) -> None:
-    """Handle common subcommand mistakes that are not easily implementable
-    with argparse.
-    run: => just run the benchmark
-    help => use --help
-    describe => use describe benchmark NAME
-    """
-    if not args.other_browser_args:
-      return
-    maybe_command = args.other_browser_args[0]
-    if maybe_command == "run":
-      args.other_browser_args.pop()
-      return
-    if maybe_command == "help":
-      self._subparsers[args.benchmark_cls].print_help()
-      sys.exit(0)
-    if maybe_command == "describe":
-      logging.warning("See `describe benchmark %s` for more options",
-                      args.benchmark_cls.NAME)
-      # Patch args to simulate: describe benchmark BENCHMARK_NAME
-      args.category = "benchmarks"
-      args.filter = args.benchmark_cls.NAME
-      args.json = False
-      self.describe_subcommand(args)
-      sys.exit(0)
-
-  def _process_network_args(self, args) -> None:
-    # The order of preference of flags is as follows:
-    # Explicitly specified network config > explicitly specified network >
-    # benchmark-specific network config > default network.
-    if network_config := args.network_config:
-      args.network = network_config
-    elif args.network:
-      pass
-    elif network_config := args.benchmark_cls.default_network_config_path():
-      args.network = network_config
-    else:
-      args.network = NetworkConfig.default()
-
-  def _benchmark_subcommand_process_args(self, args) -> None:
-    if args.config:
-      self._process_config_args(args)
-    else:
-      # We keep separate *_config args so we can throw in case they conflict
-      # with --config. Since we don't use argparse's dest, we have to manually
-      # copy the args.*_config back.
-      self._process_network_args(args)
-
-  def _process_config_args(self, args) -> None:
-    if args.env_config:
-      raise argparse.ArgumentTypeError(
-          "--config cannot be used together with --env-config")
-    if args.network_config:
-      raise argparse.ArgumentTypeError(
-          "--config cannot be used together with --network-config")
-    if args.browser_config:
-      raise argparse.ArgumentTypeError(
-          "--config cannot be used together with --browser-config")
-    if args.probe_config:
-      raise argparse.ArgumentTypeError(
-          "--config cannot be used together with --probe-config")
-
-    config_file = args.config
-    config_data = ObjectParser.hjson_file(config_file)
-    found_any_config = False
-
-    if config_data.get("env"):
-      args.env_config = parse_env_config_file(config_file)
-      found_any_config = True
-    else:
-      logging.warning("Skipping env config: no 'env' property in %s",
-                      config_file)
-
-    if network_config_data := config_data.get("network"):
-      # TODO: migrate all --config helper to this format
-      args.network = NetworkConfig.parse(network_config_data)
-      found_any_config = True
-    else:
-      logging.warning("Skipping network config: no 'network' property in %s",
-                      config_file)
-    if not args.network:
-      args.network = NetworkConfig.default()
-
-    if config_data.get("browsers"):
-      args.browser_config = config_file
-      found_any_config = True
-    else:
-      logging.warning("Skipping browsers config: No 'browsers' property in %s",
-                      config_file)
-
-    if config_data.get("probes"):
-      args.probe_config = config_file
-      found_any_config = True
-    else:
-      logging.warning("Skipping probes config: no 'probes' property in %s",
-                      config_file)
-
-    if not found_any_config:
-      raise argparse.ArgumentTypeError(
-          f"--config: config file has no config properties {config_file}")
-
-  def _log_benchmark_subcommand_failure(self, benchmark: Optional[Benchmark],
-                                        runner: Optional[Runner],
-                                        e: Exception) -> None:
-    logging.debug(e)
-    logging.error("")
-    logging.error("#" * 80)
-    logging.error("SUBCOMMAND UNSUCCESSFUL got %s:", e.__class__.__name__)
-    logging.error("-" * 80)
-    self._log_benchmark_subcommand_exception(e)
-    logging.error("-" * 80)
-    if benchmark:
-      logging.error("Running '%s' was not successful:", benchmark.NAME)
-    logging.error(
-        "- Use --debug for very verbose output (equivalent to --throw -vvv)")
-    if runner and runner.runs:
-      self._log_runner_debug_hints(runner)
-    else:
-      logging.error("- Check %s.json detailed backtraces", ErrorsProbe.NAME)
-    logging.error("#" * 80)
-    sys.exit(3)
-
-  def _log_benchmark_subcommand_exception(self, e: Exception) -> None:
-    message = str(e)
-    if message:
-      logging.error(message)
-      return
-    if isinstance(e, AssertionError):
-      self._log_assertion_error_statement(e)
-
-  def _log_assertion_error_statement(self, e: AssertionError) -> None:
-    _, exception, tb = sys.exc_info()
-    if exception is not e:
+  def log_assertion_error_statement(self, e: AssertionError) -> None:
+    _, exc_exception, tb = sys.exc_info()
+    if exc_exception is not e:
       return
     tb_info = traceback.extract_tb(tb)
     filename, line, _, text = tb_info[-1]
     logging.info("%s:%s: %s", filename, line, text)
 
-  def _log_runner_debug_hints(self, runner: Runner) -> None:
-    failed_runs = [run for run in runner.runs if not run.is_success]
-    if not failed_runs:
-      return
-    candidates: List[pth.LocalPath] = [
-        *runner.out_dir.glob(f"{ErrorsProbe.NAME}*"),
-    ]
-    for failed_run in failed_runs:
-      candidates.extend(failed_run.out_dir.glob(f"{ErrorsProbe.NAME}*"))
-      candidates.extend(failed_run.out_dir.glob("*.log"))
-
-    failed_run = failed_runs[0]
-    logging.error("- Check log outputs (1 of %d failed runs):",
-                  len(failed_runs))
-    limit = 3
-    for log_file in candidates[:limit]:
-      try:
-        log_file = log_file.relative_to(pth.LocalPath.cwd())
-      except Exception as e:  # pylint: disable=broad-except
-        logging.debug("Could not create relative log_file: %s", e)
-      logging.error("  - %s", log_file)
-    if (pending := len(candidates) - limit) > 0:
-      logging.error("  - ... and %d more interesting %s.json or *.log files",
-                    pending, ErrorsProbe.NAME)
-
-  def _run_benchmark(self, args: argparse.Namespace, runner: Runner) -> None:
-    try:
-      runner.run(is_dry_run=args.dry_run)
-      logging.info("")
-      self._log_results(args, runner, is_success=runner.is_success)
-    except:  # pylint: disable=broad-except
-      self._log_results(args, runner, is_success=False)
-      raise
-    finally:
-      self._update_symlinks(args, runner)
-
-  def _update_symlinks(self, args: argparse.Namespace, runner: Runner) -> None:
-    if not args.create_symlinks:
-      logging.debug("Symlink disabled by command line option")
-      return
-    if plt.PLATFORM.is_win:
-      logging.debug("Skipping session_dir symlink on windows.")
-      return
-    if not args.out_dir and runner.out_dir.exists():
-      self._update_default_results_symlinks(runner)
-      self._create_runs_results_symlinks(runner)
-
-  def _update_default_results_symlinks(self, runner: Runner) -> None:
-    results_root = runner.out_dir.parent
-    latest_link = results_root / "latest"
-    if latest_link.is_symlink():
-      latest_link.unlink()
-    if not latest_link.exists():
-      latest_link.symlink_to(
-          runner.out_dir.relative_to(results_root), target_is_directory=True)
-    else:
-      logging.error("Could not create %s", latest_link)
-
-  def _create_runs_results_symlinks(self, runner: Runner) -> None:
-    results_root = runner.out_dir.parent
-    runs: Tuple[Run, ...] = runner.all_runs
-    if not runs:
-      logging.debug("Skip creating result symlinks in '%s': no runs produced.",
-                    results_root)
-      return
-    out_dir = runner.out_dir
-    first_run_dir = out_dir / "first_run"
-    last_run_dir = out_dir / "last_run"
-    if first_run_dir.exists():
-      logging.error("Cannot create first_run symlink: %s", first_run_dir)
-    else:
-      first_run_dir.symlink_to(runs[0].out_dir.relative_to(out_dir))
-    if last_run_dir.exists():
-      logging.error("Cannot create last_run symlink: %s", last_run_dir)
-    else:
-      last_run_dir.symlink_to(runs[-1].out_dir.relative_to(out_dir))
-
-    runs_dir = out_dir / "runs"
-    runs_dir.mkdir()
-    for run in runs:
-      if not run.out_dir.exists():
-        continue
-      relative = pth.LocalPath("..") / run.out_dir.relative_to(out_dir)
-      (runs_dir / str(run.index)).symlink_to(relative)
-
-    sessions_dir = out_dir / "sessions"
-    sessions_dir.mkdir()
-    for session in set(run.browser_session for run in runs):
-      relative = pth.LocalPath("..") / session.path.relative_to(out_dir)
-      (sessions_dir / str(session.index)).symlink_to(relative)
-
-  def _log_results(self, args: argparse.Namespace, runner: Runner,
-                   is_success: bool) -> None:
-    logging.info("=" * 80)
-    if is_success:
-      logging.critical("RESULTS: %s", runner.out_dir)
-    else:
-      logging.critical("RESULTS (maybe incomplete/broken): %s", runner.out_dir)
-    logging.info("=" * 80)
-    if not runner.has_browser_group:
-      logging.debug("No browser group in %s", runner)
-      return
-    browser_group = runner.browser_group
-    for probe in runner.probes:
-      try:
-        probe.log_browsers_result(browser_group)
-      except Exception as e:  # pylint: disable=broad-except
-        if args.throw:
-          raise
-        logging.warning("log_result_summary failed: %s", e)
-
-  def _get_browsers(self, args: argparse.Namespace) -> Sequence[Browser]:
-    # TODO: move browser instance create to separate method.
-    # TODO: move --browser-config parsing to BrowserVariantsConfig
-    args.browser_config = BrowserVariantsConfig.from_cli_args(args)
-    return args.browser_config.variants
-
-  def _get_probes(self, args: argparse.Namespace) -> Sequence[Probe]:
-    # TODO: move probe creation to separate method
-    # TODO: move --probe-config parsing to ProbeListConfig
-    args.probe_config = ProbeListConfig.from_cli_args(args)
-    return args.probe_config.probes
-
-  def _get_benchmark(self, args: argparse.Namespace) -> Benchmark:
-    benchmark_cls = self._get_benchmark_cls(args)
-    assert (issubclass(benchmark_cls, Benchmark)), (
-        f"benchmark_cls={benchmark_cls} is not subclass of Runner")
-    return benchmark_cls.from_cli_args(args)
-
-  def _get_benchmark_cls(self, args: argparse.Namespace) -> Type[Benchmark]:
-    return args.benchmark_cls
-
-  def _get_env_validation_mode(self,
-                               args: argparse.Namespace) -> ValidationMode:
-    return args.env_validation
-
-  def _get_env_config(self, args: argparse.Namespace) -> HostEnvironmentConfig:
-    # TODO: move env_config to args.env and use ConfigObject
-    if args.env:
-      return args.env
-    if args.env_config:
-      return args.env_config
-    return HostEnvironmentConfig()
-
-  def _get_timing(self, args: argparse.Namespace) -> Timing:
-    timeout_unit: dt.timedelta = args.timeout_unit or args.time_unit
-    return Timing(args.cool_down_time, args.time_unit, timeout_unit,
-                  args.run_timeout, args.start_delay, args.stop_delay)
-
-  def _get_runner(self, args: argparse.Namespace, benchmark: Benchmark,
-                  env_config: HostEnvironmentConfig,
-                  env_validation_mode: ValidationMode,
-                  timing: Timing) -> Runner:
-    runner_kwargs = self.RUNNER_CLS.kwargs_from_cli(args)
-    return self.RUNNER_CLS(
-        benchmark=benchmark,
-        env_config=env_config,
-        env_validation_mode=env_validation_mode,
-        timing=timing,
-        **runner_kwargs)
-
   def run(self, argv: Sequence[str]) -> None:
     self._init_logging(argv)
     unprocessed_argv: List[str] = []
@@ -1084,7 +275,8 @@ class CrossBenchCLI:
     # Properly initialize logging after having parsed all args
     self._setup_logging()
     try:
-      self.args.subcommand_fn(self.args)
+      self._last_subcommand = self.args.crossbench_subcommand
+      self.args.crossbench_subcommand.run(self.args)
     finally:
       self._teardown_logging()
 
@@ -1092,23 +284,26 @@ class CrossBenchCLI:
     self.error(f"error argument {e.flag}: {e.message}")
 
   def error(self, message: str) -> None:
-    parser: CrossBenchArgumentParser = self.parser
+    parser: argparse.ArgumentParser = self.parser
     # Try to use the subparser to print nicer usage help on errors.
     # ArgumentParser tends to default to the toplevel parser instead of the
     # current subcommand, which in turn prints the wrong usage text.
-    subcommand: str = getattr(self.args, "subcommand", "")
-    if subcommand == "describe":
-      parser = self.describe_parser
+    subcommand_name: str = getattr(self.args, "subcommand", "")
+    if subcommand_name == "describe":
+      parser = self._describe_subcommand.parser
     else:
       maybe_benchmark_cls = getattr(self.args, "benchmark_cls", None)
       if maybe_benchmark_cls:
-        parser = self._subparsers[maybe_benchmark_cls]
-    if subcommand:
-      parser.fail(f"{subcommand}: {message}")
-    else:
+        parser = self._benchmark_subcommands[maybe_benchmark_cls].parser
+    if subcommand_name:
+      message = f"{subcommand_name}: {message}"
+    if isinstance(parser, CrossBenchArgumentParser):
       parser.fail(message)
+    else:
+      parser.error(message)
 
   def _init_logging(self, argv: Sequence[str]) -> None:
+    sys.excepthook = exception_formatter.excepthook
     assert self._console_handler is None
     if not self._enable_logging:
       logging.getLogger().setLevel(logging.CRITICAL)
@@ -1117,6 +312,8 @@ class CrossBenchCLI:
     self._console_handler.addFilter(logging.Filter("root"))
     self._console_handler.setLevel(logging.INFO)
     logging.getLogger().setLevel(logging.INFO)
+    # Clear existing handlers in case logging has been initialized prematurely.
+    logging.getLogger().handlers = []
     logging.getLogger().addHandler(self._console_handler)
 
     # Manually extract values to allow logging for failing arguments.
@@ -1124,10 +321,17 @@ class CrossBenchCLI:
       self._console_handler.setLevel(logging.DEBUG)
       logging.getLogger().setLevel(logging.DEBUG)
     # TODO: move to ui helpers
-    ui.COLOR_LOGGING = "--no-color" not in argv
+    ui.COLOR_LOGGING = self._detect_terminal_color(argv)
     if ui.COLOR_LOGGING:
       self._console_handler.setFormatter(ui.ColoredLogFormatter())
 
+  def _detect_terminal_color(self, argv: Sequence[str]) -> bool:
+    if "--no-color" in argv:
+      return False
+    if os.environ.get("NO_COLOR", ""):
+      return False
+    return True
+
   def _setup_logging(self) -> None:
     if not self._enable_logging:
       return
@@ -1139,7 +343,8 @@ class CrossBenchCLI:
     elif self.args.verbosity >= 1:
       self._console_handler.setLevel(logging.DEBUG)
       logging.getLogger().setLevel(logging.DEBUG)
-    ui.COLOR_LOGGING = self.args.color
+    if not self.args.color:
+      ui.COLOR_LOGGING = False
     if ui.COLOR_LOGGING:
       self._console_handler.setFormatter(ui.ColoredLogFormatter())
     else:
diff --git a/crossbench/cli/config/browser.py b/crossbench/cli/config/browser.py
index 8a9225da..ec25a895 100644
--- a/crossbench/cli/config/browser.py
+++ b/crossbench/cli/config/browser.py
@@ -9,20 +9,24 @@ import dataclasses
 import logging
 import os
 import re
-from typing import Any, Dict, Optional, TextIO, Tuple, cast
+from typing import Any, Optional, Self, TextIO, Tuple, cast
 
 import hjson
+from typing_extensions import override
 
-import crossbench.browsers.all as browsers
+import crossbench.browsers.all as all_browsers
 from crossbench import exception
 from crossbench import path as pth
 from crossbench import plt
 from crossbench.browsers.chrome.downloader import ChromeDownloader
 from crossbench.browsers.firefox.downloader import FirefoxDownloader
-from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
-from crossbench.cli.config.network import NetworkConfig, NetworkSpeedPreset
+from crossbench.cli.config.driver import DriverConfig
+from crossbench.cli.config.driver_type import BrowserDriverType
+from crossbench.cli.config.env import ENV_CONFIG_PRESETS, EnvironmentConfig
+from crossbench.cli.config.network import NetworkConfig
+from crossbench.cli.config.network_speed import NetworkSpeedPreset
 from crossbench.config import ConfigObject, ConfigParser
-from crossbench.parse import NumberParser, PathParser
+from crossbench.parse import NumberParser, ObjectParser, PathParser
 
 SUPPORTED_BROWSER = ("chromium", "chrome", "safari", "edge", "firefox")
 
@@ -37,11 +41,16 @@ SUPPORTED_BROWSER = ("chromium", "chrome", "safari", "edge", "firefox")
 # - "selenium:C:\out\x64.release\chrome:4G"
 NETWORK_PRESETS: str = "|".join(
     re.escape(preset.value) for preset in NetworkSpeedPreset)  # pytype: disable=missing-parameter
-SHORT_FORM_RE = re.compile(r"((?P<driver>\w{3,}):)??"
-                           r"(?P<path>([A-Z]:[/\\])?[^:]+)"
-                           f"(:(?P<network>{NETWORK_PRESETS}))?")
-ANDROID_PACKAGE_RE = re.compile(r"[a-z]+(\.[a-z]+){2,}")
-VERSION_FOR_RANGE_RE = re.compile(r"(?P<prefix>[^\d]*)(?P<milestone>\d+)")
+ENV_PRESETS: str = "|".join(re.escape(preset) for preset in ENV_CONFIG_PRESETS)
+
+SHORT_FORM_RE: re.Pattern[str] = re.compile(
+    r"((?P<driver>\w{3,}):)??"
+    r"(?P<path>([A-Z]:[/\\])?[^:]+)"
+    f"(:(?P<network>{NETWORK_PRESETS}))?"
+    f"(:(?P<env>{ENV_PRESETS}))?")
+ANDROID_PACKAGE_RE: re.Pattern[str] = re.compile(r"[a-z]+(\.[a-z]+){2,}")
+VERSION_FOR_RANGE_RE: re.Pattern[str] = re.compile(
+    r"(?P<prefix>[^\d]*)(?P<milestone>\d+)")
 
 
 @dataclasses.dataclass(frozen=True)
@@ -51,7 +60,11 @@ class BrowserConfig(ConfigObject):
   # Make network optional since --network provides a global default and we do
   # want to have the option to explicitly specify the default network in a
   # browser config.
-  network: Optional[NetworkConfig] = None
+  network: NetworkConfig | None = None
+  env: EnvironmentConfig | None = None
+
+  cache_dir: pth.AnyPath | None = None
+  clear_cache: bool | None = None
 
   def __post_init__(self) -> None:
     if not self.browser:
@@ -60,37 +73,39 @@ class BrowserConfig(ConfigObject):
       raise ValueError(f"{type(self).__name__}.driver cannot be None.")
 
   @classmethod
-  def default(cls) -> BrowserConfig:
+  def default(cls) -> Self:
     return cls(
-        browsers.Chrome.stable_path(plt.PLATFORM), DriverConfig.default())
+        all_browsers.Chrome.stable_path(plt.PLATFORM), DriverConfig.default())
 
   @classmethod
-  def parse_str(cls, value: str) -> BrowserConfig:
+  @override
+  def parse_str(cls, value: str) -> Self:
     if not value:
       raise argparse.ArgumentTypeError("Cannot parse empty string")
-    network: Optional[NetworkConfig] = None
+    path: pth.AnyPathLike | None = None
     driver = DriverConfig.default()
-    path: Optional[pth.AnyPathLike] = None
+    network: NetworkConfig | None = None
+    env: EnvironmentConfig | None = None
     if ":" not in value or cls.value_has_path_prefix(value):
       # Variant 1: $PATH_OR_IDENTIFIER
       path = cls._parse_path_or_identifier(value)
     elif value[0] != "{":
       # Variant 2: ${DRIVER_TYPE}:${PATH_OR_IDENTIFIER}:${NETWORK}
-      driver, path, network = cls._parse_inline_short_form(value)
+      driver, path, network, env = cls._parse_inline_short_form(value)
     else:
       # Variant 3: Full inline hjson
       return cls.parse_inline_hjson(value)
     assert path, "Invalid path"
-    return cls(path, driver, network)
+    return cls(path, driver, network, env)
 
   @classmethod
-  def parse_with_range(cls, value: Any) -> Tuple[BrowserConfig, ...]:
+  def parse_with_range(cls, value: Any) -> Tuple[Self, ...]:
     if isinstance(value, str):
       return cls._parse_with_range(value)
     return (cls.parse(value),)
 
   @classmethod
-  def _parse_with_range(cls, value: str) -> Tuple[BrowserConfig, ...]:
+  def _parse_with_range(cls, value: str) -> Tuple[Self, ...]:
     if not value:
       raise argparse.ArgumentTypeError("Cannot parse empty string")
     parts = value.split("...", maxsplit=1)
@@ -153,7 +168,7 @@ class BrowserConfig(ConfigObject):
       if cls._is_downloadable_identifier(maybe_path_or_identifier):
         return maybe_path_or_identifier
       # Assume a path since short-names never contain back-/slashes.
-      if driver_type.is_remote:
+      if driver_type.is_remote_browser:
         path = PathParser.path(maybe_path_or_identifier)
       else:
         path = PathParser.existing_path(maybe_path_or_identifier)
@@ -203,83 +218,82 @@ class BrowserConfig(ConfigObject):
     if identifier in ("chrome", "chrome-stable", "chr-stable", "chr"):
       if driver_type == BrowserDriverType.ANDROID:
         return pth.AnyPosixPath("com.android.chrome")
-      return browsers.Chrome.stable_path(platform)
+      return all_browsers.Chrome.stable_path(platform)
     if identifier in ("chrome-app"):
       if driver_type == BrowserDriverType.ANDROID:
         return pth.AnyPosixPath("com.google.android.apps.chrome")
     if identifier in ("chrome-beta", "chr-beta"):
       if driver_type == BrowserDriverType.ANDROID:
         return pth.AnyPosixPath("com.chrome.beta")
-      return browsers.Chrome.beta_path(platform)
+      return all_browsers.Chrome.beta_path(platform)
     if identifier in ("chrome-dev", "chr-dev"):
       if driver_type == BrowserDriverType.ANDROID:
         return pth.AnyPosixPath("com.chrome.dev")
-      return browsers.Chrome.dev_path(platform)
+      return all_browsers.Chrome.dev_path(platform)
     if identifier in ("chrome-canary", "chr-canary"):
       if driver_type == BrowserDriverType.ANDROID:
         return pth.AnyPosixPath("com.chrome.canary")
-      return browsers.Chrome.canary_path(platform)
+      return all_browsers.Chrome.canary_path(platform)
     if identifier == "chromium":
       if driver_type == BrowserDriverType.ANDROID:
         return pth.AnyPosixPath("org.chromium.chrome")
-      return browsers.Chromium.default_path(platform)
+      return all_browsers.Chromium.default_path(platform)
     if identifier in ("edge", "edge-stable"):
-      return browsers.Edge.stable_path(platform)
+      return all_browsers.Edge.stable_path(platform)
     if identifier == "edge-beta":
-      return browsers.Edge.beta_path(platform)
+      return all_browsers.Edge.beta_path(platform)
     if identifier == "edge-dev":
-      return browsers.Edge.dev_path(platform)
+      return all_browsers.Edge.dev_path(platform)
     if identifier == "edge-canary":
-      return browsers.Edge.canary_path(platform)
+      return all_browsers.Edge.canary_path(platform)
     if identifier in ("safari", "sf", "safari-stable", "sf-stable"):
-      return browsers.Safari.default_path(platform)
+      return all_browsers.Safari.default_path(platform)
     if identifier in ("safari-technology-preview", "safari-tp", "sf-tp", "tp"):
-      return browsers.Safari.technology_preview_path(platform)
+      return all_browsers.Safari.technology_preview_path(platform)
     if identifier in ("firefox", "firefox-stable", "ff", "ff-stable"):
-      return browsers.Firefox.default_path(platform)
+      return all_browsers.Firefox.default_path(platform)
     if identifier in ("firefox-dev", "firefox-developer-edition", "ff-dev"):
-      return browsers.Firefox.developer_edition_path(platform)
+      return all_browsers.Firefox.developer_edition_path(platform)
     if identifier in ("firefox-nightly", "ff-nightly", "ff-trunk"):
-      return browsers.Firefox.nightly_path(platform)
+      return all_browsers.Firefox.nightly_path(platform)
     return None
 
   @classmethod
   def is_supported_browser_path(cls, path: pth.AnyPath) -> bool:
     path_str = os.fspath(path).lower()
-    for short_name in SUPPORTED_BROWSER:
-      if short_name in path_str:
-        return True
-    return False
+    return any(short_name in path_str for short_name in SUPPORTED_BROWSER)
 
   @classmethod
   def _parse_inline_short_form(
       cls, value: str
-  ) -> Tuple[DriverConfig, pth.AnyPathLike, Optional[NetworkConfig]]:
-    assert ":" in value
+  ) -> Tuple[DriverConfig, pth.AnyPathLike, Optional[NetworkConfig],
+             Optional[EnvironmentConfig]]:
+    assert ":" in value, f"Invalid short config {repr(value)} for {cls}"
     match = SHORT_FORM_RE.fullmatch(value)
     if not match:
       raise argparse.ArgumentTypeError(
           f"Invalid browser short form: '{value}' \n"
           "A browser path/identifier and "
           "at least a driver or network preset have to be present")
-    driver_identifier = match.group("driver")
     path_or_identifier = match.group("path")
-    network_identifier = match.group("network")
     if not path_or_identifier:
       raise argparse.ArgumentTypeError(
           "Browser short form: missing path or browser identifier.")
     driver = DriverConfig.default()
-    if driver_identifier is not None:
-      driver = cast(DriverConfig, DriverConfig.parse(match.group("driver")))
+    if driver_identifier := match.group("driver"):
+      driver = cast(DriverConfig, DriverConfig.parse(driver_identifier))
     path: pth.AnyPathLike = cls._parse_path_or_identifier(
         path_or_identifier, driver.type)
     network = None
-    if network_identifier is not None:
+    if network_identifier := match.group("network"):
       network = NetworkConfig.parse_str(network_identifier)
-    return (driver, path, network)
+    env = None
+    if env_identifier := match.group("env"):
+      env = EnvironmentConfig.parse_str(env_identifier)
+    return (driver, path, network, env)
 
   @classmethod
-  def parse_text_io(cls, f: TextIO) -> BrowserConfig:
+  def parse_text_io(cls, f: TextIO) -> Self:
     with exception.annotate(f"Loading browser config file: {f.name}"):
       config = {}
       with exception.annotate("Parsing hjson"):
@@ -289,12 +303,9 @@ class BrowserConfig(ConfigObject):
     raise argparse.ArgumentTypeError(f"Could not parse : '{f.name}'")
 
   @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> BrowserConfig:
-    return cls.config_parser().parse(config)
-
-  @classmethod
-  def config_parser(cls) -> ConfigParser[BrowserConfig]:
-    parser = ConfigParser("BrowserConfig parser", cls)
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
     parser.add_argument(
         "browser",
         aliases=("path",),
@@ -303,9 +314,28 @@ class BrowserConfig(ConfigObject):
         depends_on=("driver",))
     parser.add_argument(
         "driver", type=DriverConfig, default=DriverConfig.default())
-    parser.add_argument("network", required=False, type=NetworkConfig)
+    parser.add_argument("network", type=NetworkConfig)
+    parser.add_argument(
+        "cache_dir",
+        aliases=("browser_cache", "browser_cache_dir"),
+        type=PathParser.optional_any_path,
+        default=None)
+    parser.add_argument(
+        "clear_cache",
+        aliases=("clear_cache_dir", "clear_browser_cache",
+                 "clear_browser_cache_dir"),
+        type=ObjectParser.optional_bool,
+        default=None)
     return parser
 
+  @property
+  def is_remote(self) -> bool:
+    return self.driver.type.is_remote_browser
+
+  @property
+  def is_local(self) -> bool:
+    return self.driver.type.is_local_browser
+
   @property
   def path(self) -> pth.AnyPath:
     assert isinstance(self.browser, pth.AnyPath)
diff --git a/crossbench/cli/config/browser_variants.py b/crossbench/cli/config/browser_variants.py
index 1bd007e1..391f1a54 100644
--- a/crossbench/cli/config/browser_variants.py
+++ b/crossbench/cli/config/browser_variants.py
@@ -4,19 +4,18 @@
 
 from __future__ import annotations
 
+import abc
 import argparse
 import contextlib
 import dataclasses
-import functools
 import logging
-from typing import (TYPE_CHECKING, Any, Dict, Final, Iterator, List, Optional,
-                    Sequence, Set, TextIO, Tuple, Type, Union, cast)
+from typing import (TYPE_CHECKING, Any, Dict, Iterator, List, Optional, Self,
+                    Sequence, Set, TextIO, Tuple, Type, cast)
 
 import hjson
-from immutabledict import immutabledict
-from ordered_set import OrderedSet
+from typing_extensions import override
 
-import crossbench.browsers.all as browsers
+import crossbench.browsers.all as all_browsers
 from crossbench import exception
 from crossbench import path as pth
 from crossbench import plt
@@ -25,17 +24,20 @@ from crossbench.browsers.chrome.downloader import ChromeDownloader
 from crossbench.browsers.firefox.downloader import FirefoxDownloader
 from crossbench.browsers.settings import Settings
 from crossbench.cli.config.browser import BrowserConfig
-from crossbench.cli.config.driver import BrowserDriverType
+from crossbench.cli.config.driver_type import BrowserDriverType
+from crossbench.cli.config.flags import (DEFAULT_LABEL, FlagsConfig,
+                                         FlagsGroupConfig, FlagsVariantConfig)
 from crossbench.cli.config.network import NetworkConfig
-from crossbench.config import ConfigError, ConfigObject
+from crossbench.config import ConfigError
 from crossbench.flags.base import Flags
 from crossbench.flags.chrome import ChromeFlags
+from crossbench.helper.cwd import ChangeCWD
 from crossbench.network.base import Network
 from crossbench.parse import LateArgumentError, ObjectParser
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
-  FlagGroupItemT = Optional[Tuple[str, Optional[str]]]
+  FlagGroupItemT = Tuple[str, str | None] | None
   BrowserLookupTableT = Dict[str, Tuple[Type[Browser], "BrowserConfig"]]
 
 
@@ -54,281 +56,362 @@ def _flags_to_label(flags: Flags) -> str:
   return convert_flags_to_label(*flags)
 
 
-FlagItemT = Tuple[str, Optional[str]]
-FlagVariantsDictT = Dict[str, List[str]]
+@dataclasses.dataclass(frozen=True)
+class BrowserVariantConfig():
+  label: str
+  browser_cls: Type[Browser]
+  browser_config: BrowserConfig
+  settings: Settings
 
-DEFAULT_LABEL: Final[str] = "default"
+  @property
+  def path(self) -> pth.AnyPath:
+    return self.browser_config.path
 
+  @property
+  def js_flags(self) -> Flags:
+    return self.settings.js_flags
 
-@dataclasses.dataclass(frozen=True)
-class FlagsVariantConfig:
-  label: str
-  index: int = 0
-  flags: Flags = dataclasses.field(default_factory=lambda: Flags().freeze())
+  @property
+  def flags(self) -> Flags:
+    return self.settings.flags
+
+  @property
+  def platform(self) -> plt.Platform:
+    return self.settings.platform
+
+
+class BaseBrowserVariantsConfig(abc.ABC):
 
   @classmethod
-  def parse(cls, name: str, index: int, data: Any) -> FlagsVariantConfig:
-    return cls(name, index, Flags.parse(data).freeze())
-
-  def merge_copy(self,
-                 other: FlagsVariantConfig,
-                 label: Optional[str] = None,
-                 index: int = -1) -> FlagsVariantConfig:
-    index = self.index if index < 0 else index
-    new_label = label or f"{self.label}_{other.label}"
-    return FlagsVariantConfig(new_label, index,
-                              self.flags.merge_copy(other.flags).freeze())
-
-  def __hash__(self) -> int:
-    return hash(self.flags)
-
-  def __eq__(self, other: Any) -> bool:
-    if not isinstance(other, FlagsVariantConfig):
-      return False
-    return self.flags == other.flags
+  @abc.abstractmethod
+  def from_cli_args(cls, args: argparse.Namespace) -> BaseBrowserVariantsConfig:
+    pass
 
+  def __init__(
+      self,
+      browser_lookup_override: Optional[BrowserLookupTableT] = None) -> None:
+    self.flags_config: FlagsConfig = FlagsConfig()
+    self._variants: List[BrowserVariantConfig] = []
+    self._unique_labels: Set[str] = set()
+    self._browser_lookup_override = browser_lookup_override or {}
 
-try:
-  FlagsGroupConfigTuple = tuple[FlagsVariantConfig, ...]
-except:  # pylint: disable=bare-except
-  # Python 3.8 fallback
-  FlagsGroupConfigTuple = tuple
+  @property
+  def variants(self) -> List[BrowserVariantConfig]:
+    assert self._variants
+    return list(self._variants)
 
+  @property
+  def browsers(self) -> List[Browser]:
+    browsers = [
+        variant.browser_cls(variant.label, variant.path, variant.settings)
+        for variant in self._variants
+    ]
+    self._ensure_unique_browser_names(browsers)
+    return browsers
 
-class FlagsGroupConfig(FlagsGroupConfigTuple):
-  """
-  Config container for a list of FlagsVariantConfig:
-  FlagsGroupConfig(
-    FlagsVariantConfig("default"),
-    FlagsVariantConfig("max_opt_1", "--js-flags='--max-opt=1'),
-    FlagsVariantConfig("max_opt_2", "--js-flags='--max-opt=2'),
-    ...
-  )
-  """
+  def __len__(self) -> int:
+    return len(self._variants)
 
-  @classmethod
-  def parse(cls, data: Any) -> FlagsGroupConfig:
-    if data is None:
-      return FlagsGroupConfig()
-    if isinstance(data, str):
-      return cls.parse_str(data)
-    if isinstance(data, dict):
-      return cls.parse_dict(data)
-    if isinstance(data, (list, tuple)):
-      return cls.parse_sequence(data)
-    raise ConfigError(f"Invalid type {type(data)}: {repr(data)}")
+  def __bool__(self) -> bool:
+    return bool(self._variants)
 
-  @classmethod
-  def parse_dict(cls, config: Dict) -> FlagsGroupConfig:
-    if not config:
-      return FlagsGroupConfig()
-    all_flag_keys = all(key.startswith("-") for key in config.keys())
-    all_str_values = all(isinstance(value, str) for value in config.values())
-    if not all_flag_keys:
-      return cls.parse_dict_with_labels(config)
-    if all_str_values:
-      return cls.parse_dict_simple(config)
-    return cls._parse_variants_dict(config)
+  def extend(self, other: BaseBrowserVariantsConfig) -> None:
+    if self is other:
+      raise ValueError(f"Cannot extend {type(self)} with itself.")
+    self._variants.extend(other.variants)
 
-  @classmethod
-  def parse_dict_with_labels(cls, config: Dict) -> FlagsGroupConfig:
-    variants: OrderedSet[FlagsVariantConfig] = OrderedSet()
-    logging.debug("Using custom flag group labels")
-    for label, value in config.items():
-      with exception.annotate_argparsing(
-          f"Parsing flag variant ...[{repr(label)}]:"):
-        variant = FlagsVariantConfig.parse(label, len(variants), value)
-        if variant in variants:
-          raise ConfigError(f"Duplicate flag variant: {value}")
-        variants.add(variant)
-    return FlagsGroupConfig(tuple(variants))
+  def _ensure_unique_browser_names(self, browsers: List[Browser]) -> None:
+    if self._has_unique_variant_names(browsers):
+      return
+    # Expand to full version names
+    for browser in browsers:
+      browser.unique_name = (
+          f"{browser.type_name()}_{browser.version}_{browser.label}")
+    if self._has_unique_variant_names(browsers):
+      return
+    logging.info("Got unique browser names and versions, "
+                 "please use --browser-config for more meaningful names")
+    # Last resort, add index
+    for index, browser in enumerate(browsers):
+      browser.unique_name += f"_{index}"
+    assert self._has_unique_variant_names(browsers)
 
-  @classmethod
-  def parse_dict_simple(cls, config: Dict) -> FlagsGroupConfig:
-    logging.debug("Using single flag group dict")
-    variants = (FlagsVariantConfig.parse(DEFAULT_LABEL, 0, config),)
-    return FlagsGroupConfig(variants)
+  def _has_unique_variant_names(self, browsers: List[Browser]) -> bool:
+    names = [browser.unique_name for browser in browsers]
+    unique_names = set(names)
+    return len(unique_names) == len(names)
 
-  @classmethod
-  def _parse_variants_dict(cls, data: Dict[str, Any]) -> FlagsGroupConfig:
-    # data == {
-    #  "--flag": None,
-    #  "--flag-b": "custom flag value",
-    #  "--flag-c": (None, "value 2", "value 3"),
-    # }
-    cls._validate_variants_dict(data)
-    per_flag_groups: List[FlagsGroupConfig] = []
-    for flag_name, flag_data in data.items():
-      per_flag_groups.append(cls._dict_variant_to_group(flag_name, flag_data))
-
-    variants = per_flag_groups[0]
-    for next_variant in per_flag_groups[1:]:
-      variants = variants.product(next_variant)
-    return variants
+  def _is_valid_browser_path(self, browser_config: BrowserConfig) -> bool:
+    if browser_config.is_remote:
+      # TODO: add remote path validation
+      return True
+    return pth.LocalPath(browser_config.path).exists()
+
+  def _flags_to_label(self, name: str, flags: Flags) -> str:
+    return f"{name}_{convert_flags_to_label(*flags)}"
+
+  def _create_unique_variant_labels(self, name: str,
+                                    raw_browser_data: str | Dict[str, Any],
+                                    flag_variants: FlagsGroupConfig) -> Dict:
+    labels_lookup: Dict[FlagsVariantConfig, str] = {}
+    group_labels = set(variant.label for variant in flag_variants)
+    use_unique_variant_label = len(group_labels) == len(flag_variants)
+
+    for variant in flag_variants:
+      label = name
+      if isinstance(raw_browser_data, dict):
+        label = raw_browser_data.get("label", name)
+      if len(flag_variants) > 1:
+        if use_unique_variant_label:
+          label = f"{name}_{variant.label}"
+        else:
+          # TODO: This case might not happen anymore
+          label = self._flags_to_label(name, variant.flags)
+      labels_lookup[variant] = label
+    return labels_lookup
+
+  def _check_unique_label(self, label: str) -> bool:
+    if label in self._unique_labels:
+      return False
+    self._unique_labels.add(label)
+    return True
+
+  def _validate_flags(self, browser_name: str,
+                      flag_group_names: List[str]) -> None:
+    if isinstance(flag_group_names, str):
+      flag_group_names = [flag_group_names]
+    if not isinstance(flag_group_names, list):
+      raise ConfigError(
+          f"'flags' is not a list for browser={repr(browser_name)}")
+    ObjectParser.unique_sequence(flag_group_names, error_cls=ConfigError)
+
+  def _log_browser_variants(self, name: str,
+                            flag_variants: FlagsGroupConfig) -> None:
+    logging.info(" SELECTED BROWSER: '%s' with %s flag variants:", name,
+                 len(flag_variants))
+    for i, variant in enumerate(flag_variants):
+      logging.info("   %s: %s", i, variant.flags)
 
   @classmethod
-  def _validate_variants_dict(cls, data: Dict[str, Any]) -> None:
-    flags = Flags()
-    for flag_name, flag_value in data.items():
-      with exception.annotate_argparsing(
-          f"Parsing flag variant ...[{flag_name}]:"):
-        flags.set(flag_name)
-        if flag_value is None:
-          continue
-        if not isinstance(flag_value, (str, list, tuple)):
-          raise ConfigError(
-              f"Invalid flag variant value (None, str or sequence): "
-              f"{flag_name}={repr(flag_value)}")
-        if isinstance(flag_value, (list, tuple)):
-          ObjectParser.unique_sequence(
-              flag_value, f"flag {repr(flag_name)} variant values", ConfigError)
+  def get_browser_cls(cls, browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    path: pth.AnyPath = browser_config.path
+    assert not isinstance(path, str), "Invalid path"
+    if not BrowserConfig.is_supported_browser_path(path):
+      raise argparse.ArgumentTypeError(f"Unsupported browser path='{path}'")
+    path_str = str(browser_config.path).lower()
+    if "safari" in path_str:
+      return cls.get_safari_browser_cls(browser_config)
+    if "chrome" in path_str:
+      return cls.get_chrome_browser_cls(browser_config)
+    if "chromium" in path_str:
+      return cls.get_chromium_browser_cls(browser_config)
+    if "firefox" in path_str:
+      if driver == BrowserDriverType.WEB_DRIVER:
+        return all_browsers.FirefoxWebDriver
+    if "edge" in path_str:
+      return all_browsers.EdgeWebDriver
+    raise argparse.ArgumentTypeError(f"Unsupported browser path='{path}'")
 
   @classmethod
-  def _dict_variant_to_group(cls, flag_name: str,
-                             data: Any) -> FlagsGroupConfig:
-    if data is None:
-      return cls.parse_str(flag_name)
-    if isinstance(data, str):
-      data_str: str = data.strip()
-      if not data_str:
-        return cls.parse_str(flag_name)
-      data = (data_str,)
-    assert isinstance(data, (list, tuple)), "Invalid flag variant type"
-    flags: OrderedSet[Optional[Flags]] = OrderedSet()
-    for variant in data:
-      if variant is None:
-        flag = None
-      elif not variant.strip():
-        flag = Flags((flag_name,))
-      else:
-        cls._validate_variant_flag(flag_name, variant)
-        flag = Flags({flag_name: variant})
-      if flag in flags:
-        raise ConfigError("Same flag variant was specified more than once: "
-                          f"{repr(flag)} for entry {repr(flag_name)}")
-      flags.add(flag)
-    return cls.parse_sequence(flags)
+  def get_safari_browser_cls(cls,
+                             browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    if driver == BrowserDriverType.IOS:
+      return all_browsers.SafariWebdriverIOS
+    if driver == BrowserDriverType.WEB_DRIVER:
+      return all_browsers.SafariWebDriver
+    if driver == BrowserDriverType.APPLE_SCRIPT:
+      return all_browsers.SafariAppleScript
+    raise argparse.ArgumentTypeError(f"Unsupported Safari driver: {driver}")
 
   @classmethod
-  def _validate_variant_flag(cls, flag_name: str, flag_value: Any) -> None:
-    if flag_value == "None,":
-      raise ConfigError("Please use null (from json) instead of "
-                        f"None (from python) for flag {repr(flag_name)}")
+  def get_chrome_browser_cls(cls,
+                             browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    if driver == BrowserDriverType.WEB_DRIVER:
+      return all_browsers.ChromeWebDriver
+    if driver == BrowserDriverType.APPLE_SCRIPT:
+      return all_browsers.ChromeAppleScript
+    if driver == BrowserDriverType.ANDROID:
+      if all_browsers.LocalChromeWebDriverAndroid.is_apk_helper(
+          browser_config.path):
+        return all_browsers.LocalChromeWebDriverAndroid
+      return all_browsers.ChromeWebDriverAndroid
+    if driver == BrowserDriverType.LINUX_SSH:
+      return all_browsers.ChromeWebDriverSsh
+    if driver == BrowserDriverType.CHROMEOS_SSH:
+      return all_browsers.ChromeWebDriverChromeOsSsh
+    raise argparse.ArgumentTypeError(f"Unsupported Chrome driver: {driver}")
 
   @classmethod
-  def parse_sequence(cls, data: Sequence) -> FlagsGroupConfig:
-    variants: List[FlagsVariantConfig] = []
-    duplicates: Set[str] = set()
-    for flag_data in data:
-      if not flag_data:
-        flags = Flags()
+  def get_chromium_browser_cls(cls,
+                               browser_config: BrowserConfig) -> Type[Browser]:
+    driver = browser_config.driver.type
+    # TODO: technically this should be ChromiumWebDriver
+    if driver == BrowserDriverType.WEB_DRIVER:
+      return all_browsers.ChromiumWebDriver
+    if driver == BrowserDriverType.APPLE_SCRIPT:
+      return all_browsers.ChromiumAppleScript
+    if driver == BrowserDriverType.ANDROID:
+      if all_browsers.LocalChromiumWebDriverAndroid.is_apk_helper(
+          browser_config.path):
+        return all_browsers.LocalChromiumWebDriverAndroid
+      return all_browsers.ChromiumWebDriverAndroid
+    if driver == BrowserDriverType.LINUX_SSH:
+      return all_browsers.ChromiumWebDriverSsh
+    if driver == BrowserDriverType.CHROMEOS_SSH:
+      return all_browsers.ChromiumWebDriverChromeOsSsh
+    raise argparse.ArgumentTypeError(f"Unsupported chromium driver: {driver}")
+
+  def _get_browser_platform(self,
+                            browser_config: BrowserConfig) -> plt.Platform:
+    return browser_config.get_platform()
+
+  def _extract_chrome_flags(self,
+                            args: argparse.Namespace) -> List[ChromeFlags]:
+    initial_flags = ChromeFlags()
+
+    if args.enable_features:
+      initial_flags["--enable-features"] = args.enable_features
+    if args.disable_features:
+      initial_flags["--disable-features"] = args.disable_features
+    if args.enable_field_trial_config is True:
+      initial_flags.set("--enable-field-trial-config")
+    if args.enable_field_trial_config is False:
+      initial_flags.set("--disable-field-trial-config")
+
+    flags_sets = [initial_flags]
+    if not args.js_flags:
+      return flags_sets
+
+    def copy_and_set_js_flags(flags: ChromeFlags,
+                              js_flags_str: str) -> ChromeFlags:
+      flags = flags.copy()
+      if not js_flags_str.strip():
+        assert not flags.js_flags
       else:
-        flags = Flags.parse(flag_data)
-      if flag_data in duplicates:
-        raise ConfigError(f"Duplicate variant: {flags}")
-      duplicates.add(flag_data)
-      variants.append(
-          FlagsVariantConfig(_flags_to_label(flags), len(variants), flags))
-    return FlagsGroupConfig(tuple(variants))
+        for js_flag in js_flags_str.split(","):
+          js_flag_name, js_flag_value = Flags.split(js_flag.lstrip())
+          flags.js_flags.set(js_flag_name, js_flag_value)
+      return flags
 
-  @classmethod
-  def parse_str(cls, value: str) -> FlagsGroupConfig:
-    if not value.strip():
-      return FlagsGroupConfig()
-    variants = (FlagsVariantConfig.parse(DEFAULT_LABEL, 0, value),)
-    return FlagsGroupConfig(variants)
-
-  def product(self, *args: FlagsGroupConfig) -> FlagsGroupConfig:
-    return functools.reduce(lambda a, b: a.inner_product(b), args, self)
-
-  def inner_product(self, other: FlagsGroupConfig) -> FlagsGroupConfig:
-    """Create a new FlagsGroupConfig as the combination of
-    self.variants x other.variants"""
-    new_variants: List[FlagsVariantConfig] = []
-    new_labels: Set[str] = set()
-    if not other:
-      return self
-    if not self:
-      return other
-    for variant in self:
-      for variant_other in other:
-        new_label = self._unique_product_label(new_labels, variant,
-                                               variant_other)
-        new_labels.add(new_label)
-        new_variant: FlagsVariantConfig = variant.merge_copy(
-            variant_other, index=len(new_variants), label=new_label)
-        new_variants.append(new_variant)
-
-    return FlagsGroupConfig(tuple(new_variants))
-
-  def _unique_product_label(self, label_set: Set[str],
-                            variant_a: FlagsVariantConfig,
-                            variant_b: FlagsVariantConfig) -> str:
-    default = f"{variant_a.label}_{variant_b.label}"
-    if variant_a.label == DEFAULT_LABEL:
-      default = variant_b.label
-    if variant_b.label == DEFAULT_LABEL:
-      default = variant_a.label
-    label = default
-    if not variant_a.flags:
-      label = variant_b.label
-    if not variant_b.flags:
-      label = variant_a.label
-    if label not in label_set:
-      return label
-    if default not in label_set:
-      return default
-    return f"{default}_{len(label_set)}"
-
-
-class FlagsConfig(ConfigObject, immutabledict[str, FlagsGroupConfig]):
+    flags_sets = [
+        copy_and_set_js_flags(flags, js_flags_str)
+        for flags in flags_sets
+        for js_flags_str in args.js_flags
+    ]
+    return flags_sets
+
+  def _config_for_maybe_downloaded_binary(self,
+                               browser_config: BrowserConfig) -> BrowserConfig:
+    path_or_identifier = browser_config.browser
+    if isinstance(path_or_identifier, pth.AnyPath):
+      return browser_config
+    browser_platform = self._get_browser_platform(browser_config)
+    if ChromeDownloader.is_valid(path_or_identifier, browser_platform):
+      downloaded = ChromeDownloader.load(path_or_identifier, browser_platform)
+    elif FirefoxDownloader.is_valid(path_or_identifier, browser_platform):
+      downloaded = FirefoxDownloader.load(path_or_identifier, browser_platform)
+    else:
+      raise ValueError(
+          f"No version-download support for browser: {path_or_identifier}")
+    return BrowserConfig(downloaded, browser_config.driver)
+
+  def _get_driver_path(self, args: argparse.Namespace,
+                       browser_config: BrowserConfig) -> Optional[pth.AnyPath]:
+    if browser_config.driver.is_remote:
+      return args.remote_driver_path or browser_config.driver.path
+    return args.driver_path or browser_config.driver.path
+
+
+  def _append_variant(self, args: argparse.Namespace, label: str,
+                      browser_cls: Type[Browser], browser_config: BrowserConfig,
+                      flags: Flags, browser_platform: plt.Platform,
+                      network: Network) -> BrowserVariantConfig:
+    if not self._is_valid_browser_path(browser_config):
+      raise ConfigError(f"Browser binary does not exist: {browser_config.path}")
+    assert label
+    browser_cache_dir = args.browser_cache_dir or browser_config.cache_dir
+    clear_cache_dir: bool | None = args.clear_browser_cache_dir
+    if clear_cache_dir is None:
+      clear_cache_dir = browser_config.clear_cache
+    if clear_cache_dir is None:
+      clear_cache_dir = True
+    settings = Settings(
+        cache_dir=browser_cache_dir,
+        clear_cache_dir=clear_cache_dir,
+        flags=flags,
+        network=network,
+        driver_path=self._get_driver_path(args, browser_config),
+        viewport=args.viewport,
+        splash_screen=args.splash_screen,
+        platform=browser_platform,
+        secrets=args.secrets,
+        driver_logging=args.driver_logging,
+        wipe_system_user_data=args.wipe_system_user_data,
+        http_request_timeout=args.http_request_timeout)
+    browser_variant = BrowserVariantConfig(label, browser_cls, browser_config,
+                                           settings)
+    if not self._check_unique_label(label):
+      raise ConfigError(f"Got non-unique label: {repr(label)}")
+    self._variants.append(browser_variant)
+    return browser_variant
+
+  def _get_browser_network(self, network_config: pth.LocalPath | NetworkConfig,
+                           browser_platform: plt.Platform) -> Network:
+    if not isinstance(network_config, NetworkConfig):
+      network_config = NetworkConfig.parse(network_config)
+    return network_config.create(browser_platform)
+
+
+class BrowserVariantsConfig(BaseBrowserVariantsConfig):
 
   @classmethod
-  def parse_str(cls, value: str) -> FlagsConfig:
-    if not value:
-      raise ConfigError("Cannot parse empty string")
-    return cls({"default": FlagsGroupConfig.parse_str(value)})
+  @override
+  def from_cli_args(cls, args: argparse.Namespace) -> BaseBrowserVariantsConfig:
+    browser_variants = cls()
+    if args.browser_config:
+      browser_variants.extend(BrowserVariantsConfigDict.from_cli_args(args))
+    if args.browser:
+      browser_variants.extend(BrowserVariantConfigArgs.from_cli_args(args))
+    if browser_variants:
+      return browser_variants
+    return cls.default(args)
 
   @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> FlagsConfig:
-    groups: Dict[str, FlagsGroupConfig] = {}
-    for group_name, group_data in config.items():
-      with exception.annotate(f"Parsing flag-group: flags[{repr(group_name)}]"):
-        groups[group_name] = FlagsGroupConfig.parse(group_data)
-    return cls(groups)
+  def default(cls, args: argparse.Namespace) -> BrowserVariantConfigArgs:
+    # Make sure we have at least one default browser as variant.
+    default_variants = BrowserVariantConfigArgs()
+    default_variants.parse_sequence(args, [BrowserConfig.default()])
+    return default_variants
 
 
-class BrowserVariantsConfig:
+class BrowserVariantsConfigDict(BaseBrowserVariantsConfig):
 
   @classmethod
-  def from_cli_args(cls, args: argparse.Namespace) -> BrowserVariantsConfig:
-    browser_config = BrowserVariantsConfig()
-    if args.browser_config:
-      with late_argument_type_error_wrapper("--browser-config"):
-        path = args.browser_config.expanduser()
-        with path.open(encoding="utf-8") as f:
-          browser_config.parse_text_io(f, args)
-    else:
-      with late_argument_type_error_wrapper("--browser"):
-        browser_config.parse_args(args)
-    return browser_config
+  @override
+  def from_cli_args(cls, args: argparse.Namespace) -> Self:
+    config_variants = cls()
+    with late_argument_type_error_wrapper("--browser-config"):
+      path = args.browser_config.expanduser().absolute()
+      config_variants.parse_config_path(path, args)
+    return config_variants
 
   def __init__(self,
                raw_config_data: Optional[Dict[str, Any]] = None,
                browser_lookup_override: Optional[BrowserLookupTableT] = None,
-               args: Optional[argparse.Namespace] = None):
-    self.flags_config: FlagsConfig = FlagsConfig()
-    self._variants: List[Browser] = []
-    self._unique_names: Set[str] = set()
-    self._browser_lookup_override = browser_lookup_override or {}
+               args: Optional[argparse.Namespace] = None) -> None:
+    super().__init__(browser_lookup_override)
     if raw_config_data:
       assert args, "args object needed when loading from dict."
       self.parse_dict(raw_config_data, args)
 
-  @property
-  def variants(self) -> List[Browser]:
-    assert self._variants
-    return self._variants
+  def parse_config_path(self, path: pth.LocalPath,
+                        args: argparse.Namespace) -> None:
+    with ChangeCWD(path.parent):
+      with path.open(encoding="utf-8") as f:
+        self.parse_text_io(f, args)
 
   def parse_text_io(self, f: TextIO, args: argparse.Namespace) -> None:
     with exception.annotate(f"Loading browser config file: {f.name}"):
@@ -350,58 +433,41 @@ class BrowserVariantsConfig:
       if not config["browsers"]:
         raise ConfigError("Config contains empty 'browsers' dict.")
       with exception.annotate("Parsing config['browsers']"):
-        self._parse_browsers(config["browsers"], args)
+        self._parse_dict_browsers(config["browsers"], args)
 
-  def parse_args(self, args: argparse.Namespace) -> None:
-    browser_list: List[BrowserConfig] = args.browser or [
-        BrowserConfig.default()
-    ]
-    assert isinstance(browser_list, list)
-    browser_list = ObjectParser.unique_sequence(browser_list,
-                                                "--browser arguments")
-    for i, browser in enumerate(browser_list):
-      with exception.annotate(f"Append browser {i}"):
-        self._append_browser(args, browser)
-    self._verify_browser_flags(args)
-    self._ensure_unique_browser_names()
-
-  def _parse_browsers(self, data: Dict[str, Any],
-                      args: argparse.Namespace) -> None:
+  def _parse_dict_browsers(self, data: Dict[str, Any],
+                           args: argparse.Namespace) -> None:
     for name, browser_config in data.items():
       with exception.annotate(f"Parsing browsers[{repr(name)}]"):
         self._parse_browser(name, browser_config, args)
-    self._ensure_unique_browser_names()
 
   def _parse_browser(self, name: str, raw_browser_data: Any,
                      args: argparse.Namespace) -> None:
     if isinstance(raw_browser_data, (dict, str)):
-      return self._parse_browser_dict(name, raw_browser_data, args)
+      return self._parse_dict_browser_dict(name, raw_browser_data, args)
     raise argparse.ArgumentTypeError(
         f"Expected str or dict, got {type(raw_browser_data).__name__}: "
         f"{repr(raw_browser_data)}")
 
-  def _parse_browser_dict(self, name: str,
-                          raw_browser_data: Union[str, Dict[str, Any]],
-                          args: argparse.Namespace) -> None:
-    path_or_identifier: Optional[str] = None
+  def _parse_dict_browser_dict(self, name: str,
+                               raw_browser_data: str | Dict[str, Any],
+                               args: argparse.Namespace) -> None:
+    path_or_identifier: str | None = None
     if isinstance(raw_browser_data, dict):
       path_or_identifier = raw_browser_data.get("path")
     else:
       path_or_identifier = raw_browser_data
-    browser_cls: Type[Browser]
+    browser_cls: Type[Browser] | None = None
     if path_or_identifier and (path_or_identifier
                                in self._browser_lookup_override):
       browser_cls, browser_config = self._browser_lookup_override[
           path_or_identifier]
     else:
-      browser_config = self._maybe_downloaded_binary(
+      browser_config = self._config_for_maybe_downloaded_binary(
           cast(BrowserConfig, BrowserConfig.parse(raw_browser_data)))
       browser_cls = self.get_browser_cls(browser_config)
-    if not browser_config.driver.type.is_remote and (not pth.LocalPath(
-        browser_config.path).exists()):
-      raise ConfigError(
-          f"browsers[{repr(name)}].path='{browser_config.path}' does not exist."
-      )
+    assert browser_cls
+
     flag_variants: FlagsGroupConfig = self._get_browser_variants(
         name, raw_browser_data)
     self._log_browser_variants(name, flag_variants)
@@ -416,60 +482,12 @@ class BrowserVariantsConfig:
         network = self._get_browser_network(network_config, browser_platform)
       # TODO: move the browser instantiation to a separate step and only
       # create BrowserConfig objects first.
-      # pytype: disable=not-instantiable
-      settings = Settings(
-          flags=browser_flags,
-          network=network,
-          driver_path=args.driver_path or browser_config.driver.path,
-          # TODO: support all args in the browser.config file
-          viewport=args.viewport,
-          splash_screen=args.splash_screen,
-          platform=browser_platform,
-          secrets=args.secrets.as_dict(),
-          driver_logging=args.driver_logging,
-          wipe_system_user_data=args.wipe_system_user_data,
-          http_request_timeout=args.http_request_timeout)
-      browser_instance = browser_cls(
-          label=label, path=browser_config.path, settings=settings)
-      # pytype: enable=not-instantiable
-      self._variants.append(browser_instance)
-
-  def _flags_to_label(self, name: str, flags: Flags) -> str:
-    return f"{name}_{_flags_to_label(flags)}"
-
-  def _create_unique_variant_labels(self, name: str,
-                                    raw_browser_data: Union[str, Dict[str,
-                                                                      Any]],
-                                    flag_variants: FlagsGroupConfig) -> Dict:
-    labels_lookup: Dict[FlagsVariantConfig, str] = {}
-    group_labels = set(variant.label for variant in flag_variants)
-    use_unique_variant_label = len(group_labels) == len(flag_variants)
-
-    for variant in flag_variants:
-      label = name
-      if isinstance(raw_browser_data, dict):
-        label = raw_browser_data.get("label", name)
-      if len(flag_variants) > 1:
-        if use_unique_variant_label:
-          label = f"{name}_{variant.label}"
-        else:
-          # TODO: This case might not happen anymore
-          label = self._flags_to_label(name, variant.flags)
-      if not self._check_unique_label(label):
-        raise ConfigError(f"browsers[{repr(name)}] has non-unique label: "
-                          f"{repr(label)}")
-      labels_lookup[variant] = label
-    return labels_lookup
-
-  def _check_unique_label(self, label: str) -> bool:
-    if label in self._unique_names:
-      return False
-    self._unique_names.add(label)
-    return True
+      self._append_variant(args, label, browser_cls, browser_config,
+                           browser_flags, browser_platform, network)
 
   def _get_browser_variants(
       self, browser_name: str,
-      raw_browser_data: Union[str, Dict[str, Any]]) -> FlagsGroupConfig:
+      raw_browser_data: str | Dict[str, Any]) -> FlagsGroupConfig:
     default_variant = FlagsVariantConfig(DEFAULT_LABEL)
     flag_variants = FlagsGroupConfig((default_variant,))
     if not isinstance(raw_browser_data, dict):
@@ -506,148 +524,70 @@ class BrowserVariantsConfig:
       flag_groups.append(FlagsGroupConfig.parse_dict(flag_data))
     return flag_groups
 
-  def _validate_flags(self, browser_name: str, flag_group_names: List[str]):
-    if isinstance(flag_group_names, str):
-      flag_group_names = [flag_group_names]
-    if not isinstance(flag_group_names, list):
-      raise ConfigError(
-          f"'flags' is not a list for browser={repr(browser_name)}")
-    seen_flag_group_names: Set[str] = set()
-    for flag_group_name in flag_group_names:
-      if flag_group_name in seen_flag_group_names:
-        raise ConfigError(f"Duplicate group name {repr(flag_group_name)} "
-                          f"for browser={repr(browser_name)}")
-
-  def _log_browser_variants(self, name: str,
-                            flag_variants: FlagsGroupConfig) -> None:
-    logging.info("SELECTED BROWSER: '%s' with %s flag variants:", name,
-                 len(flag_variants))
-    for i, variant in enumerate(flag_variants):
-      logging.info("   %s: %s", i, variant.flags)
-
-  def get_browser_cls(self, browser_config: BrowserConfig) -> Type[Browser]:
-    driver = browser_config.driver.type
-    path: pth.AnyPath = browser_config.path
-    assert not isinstance(path, str), "Invalid path"
-    if not BrowserConfig.is_supported_browser_path(path):
-      raise argparse.ArgumentTypeError(f"Unsupported browser path='{path}'")
-    path_str = str(browser_config.path).lower()
-    if "safari" in path_str:
-      return self._get_safari_browser_cls(browser_config)
-    if "chrome" in path_str:
-      return self._get_chrome_browser_cls(browser_config)
-    if "chromium" in path_str:
-      return self._get_chromium_browser_cls(browser_config)
-    if "firefox" in path_str:
-      if driver == BrowserDriverType.WEB_DRIVER:
-        return browsers.FirefoxWebDriver
-    if "edge" in path_str:
-      return browsers.EdgeWebDriver
-    raise argparse.ArgumentTypeError(f"Unsupported browser path='{path}'")
-
-  def _get_safari_browser_cls(self,
-                              browser_config: BrowserConfig) -> Type[Browser]:
-    driver = browser_config.driver.type
-    if driver == BrowserDriverType.IOS:
-      return browsers.SafariWebdriverIOS
-    if driver == BrowserDriverType.WEB_DRIVER:
-      return browsers.SafariWebDriver
-    if driver == BrowserDriverType.APPLE_SCRIPT:
-      return browsers.SafariAppleScript
-    raise argparse.ArgumentTypeError(f"Unsupported Safari driver: {driver}")
-
-  def _get_chrome_browser_cls(self,
-                              browser_config: BrowserConfig) -> Type[Browser]:
-    driver = browser_config.driver.type
-    if driver == BrowserDriverType.WEB_DRIVER:
-      return browsers.ChromeWebDriver
-    if driver == BrowserDriverType.APPLE_SCRIPT:
-      return browsers.ChromeAppleScript
-    if driver == BrowserDriverType.ANDROID:
-      if browsers.LocalChromeWebDriverAndroid.is_apk_helper(
-          browser_config.path):
-        return browsers.LocalChromeWebDriverAndroid
-      return browsers.ChromeWebDriverAndroid
-    if driver == BrowserDriverType.LINUX_SSH:
-      return browsers.ChromeWebDriverSsh
-    if driver == BrowserDriverType.CHROMEOS_SSH:
-      return browsers.ChromeWebDriverChromeOsSsh
-    raise argparse.ArgumentTypeError(f"Unsupported Chrome driver: {driver}")
-
-  def _get_chromium_browser_cls(self,
-                                browser_config: BrowserConfig) -> Type[Browser]:
-    driver = browser_config.driver.type
-    # TODO: technically this should be ChromiumWebDriver
-    if driver == BrowserDriverType.WEB_DRIVER:
-      return browsers.ChromiumWebDriver
-    if driver == BrowserDriverType.APPLE_SCRIPT:
-      return browsers.ChromiumAppleScript
-    if driver == BrowserDriverType.ANDROID:
-      if browsers.LocalChromiumWebDriverAndroid.is_apk_helper(
-          browser_config.path):
-        return browsers.LocalChromiumWebDriverAndroid
-      return browsers.ChromiumWebDriverAndroid
-    if driver == BrowserDriverType.LINUX_SSH:
-      return browsers.ChromiumWebDriverSsh
-    if driver == BrowserDriverType.CHROMEOS_SSH:
-      return browsers.ChromiumWebDriverChromeOsSsh
-    raise argparse.ArgumentTypeError(f"Unsupported chromium driver: {driver}")
 
-  def _get_browser_platform(self,
-                            browser_config: BrowserConfig) -> plt.Platform:
-    return browser_config.get_platform()
+class BrowserVariantConfigArgs(BaseBrowserVariantsConfig):
 
-  def _ensure_unique_browser_names(self) -> None:
-    if self._has_unique_variant_names():
-      return
-    # Expand to full version names
-    for browser in self._variants:
-      browser.unique_name = (
-          f"{browser.type_name}_{browser.version}_{browser.label}")
-    if self._has_unique_variant_names():
-      return
-    logging.info("Got unique browser names and versions, "
-                 "please use --browser-config for more meaningful names")
-    # Last resort, add index
-    for index, browser in enumerate(self._variants):
-      browser.unique_name += f"_{index}"
-    assert self._has_unique_variant_names()
+  @classmethod
+  @override
+  def from_cli_args(cls, args: argparse.Namespace) -> Self:
+    args_variants = cls()
+    with late_argument_type_error_wrapper("--browser"):
+      args_variants.parse_args(args)
+    return args_variants
 
-  def _has_unique_variant_names(self) -> bool:
-    names = [browser.unique_name for browser in self._variants]
-    unique_names = set(names)
-    return len(unique_names) == len(names)
+  def parse_args(self, args: argparse.Namespace) -> None:
+    self.parse_sequence(args, args.browser)
 
-  def _extract_chrome_flags(self,
-                            args: argparse.Namespace) -> List[ChromeFlags]:
-    initial_flags = ChromeFlags()
+  def parse_sequence(self, args: argparse.Namespace,
+                     browsers: Sequence[BrowserConfig]) -> None:
+    browsers = ObjectParser.unique_sequence(browsers, "--browser arguments")
+    for i, browser in enumerate(browsers):
+      with exception.annotate(f"Append browser {i}"):
+        self._append_browser(args, browser)
+    self._verify_browser_flags(args)
 
-    if args.enable_features:
-      initial_flags["--enable-features"] = args.enable_features
-    if args.disable_features:
-      initial_flags["--disable-features"] = args.disable_features
-    if args.enable_field_trial_config is True:
-      initial_flags.set("--enable-field-trial-config")
-    if args.enable_field_trial_config is False:
-      initial_flags.set("--disable-field-trial-config")
+  def _append_browser(self, args: argparse.Namespace,
+                      browser_config: BrowserConfig) -> None:
+    assert browser_config, "Expected non-empty BrowserConfig."
+    browser_config = self._config_for_maybe_downloaded_binary(browser_config)
+    browser_cls: Type[Browser] = self.get_browser_cls(browser_config)
+    flags_sets: List[Flags] = [browser_cls.default_flags()]
+    flags_sets = self._extend_flags_sets(args, flags_sets, browser_cls)
 
-    flags_sets = [initial_flags]
-    if not args.js_flags:
-      return flags_sets
+    browser_platform = self._get_browser_platform(browser_config)
+    with exception.annotate_argparsing("Creating network config"):
+      network_config = browser_config.network or args.network
+      network = self._get_browser_network(network_config, browser_platform)
 
-    def copy_and_set_js_flags(flags: ChromeFlags,
-                              js_flags_str: str) -> ChromeFlags:
-      flags = flags.copy()
-      for js_flag in js_flags_str.split(","):
-        js_flag_name, js_flag_value = Flags.split(js_flag.lstrip())
-        flags.js_flags.set(js_flag_name, js_flag_value)
-      return flags
+    name = f"{browser_platform}_{len(self._unique_labels)}"
+    for flags in flags_sets:
+      label: str = name
+      if len(flags_sets) > 1:
+        label = self._flags_to_label(label, flags)
+      browser_variant = self._append_variant(args, label, browser_cls,
+                                             browser_config, flags,
+                                             browser_platform, network)
+      logging.info(" SELECTED BROWSER: name=%s path='%s' ",
+                   browser_variant.label, browser_variant.path)
+
+  def _extend_flags_sets(self, args: argparse.Namespace,
+                         flags_sets: List[Flags],
+                         browser_cls: Type[Browser]) -> List[Flags]:
+    if browser_cls.attributes().is_chromium_based:
+      assert all(isinstance(flags, ChromeFlags) for flags in flags_sets)
+      # Add chrome flags:
+      extra_flag_sets = self._extract_chrome_flags(args)
+      flags_sets = [
+          flags.merge_copy(extra_flags)
+          for flags in flags_sets
+          for extra_flags in extra_flag_sets
+      ]
+    # Add genertic browser args:
+    for flag_str in args.other_browser_args:
+      flag_name, flag_value = Flags.split(flag_str)
+      for flags in flags_sets:
+        flags.set(flag_name, flag_value)
 
-    flags_sets = [
-        copy_and_set_js_flags(flags, js_flags_str)
-        for flags in flags_sets
-        for js_flags_str in args.js_flags
-    ]
     return flags_sets
 
   def _verify_browser_flags(self, args: argparse.Namespace) -> None:
@@ -655,101 +595,28 @@ class BrowserVariantsConfig:
       for flag_name, value in chrome_flags.items():
         if not value:
           continue
-        for browser in self._variants:
-          if not browser.attributes.is_chromium_based:
+        for variant in self._variants:
+          browser_cls = variant.browser_cls
+          if not browser_cls.attributes().is_chromium_based:
             raise argparse.ArgumentTypeError(
                 f"Used chrome/chromium-specific flags {flag_name} "
-                f"for non-chrome {browser.unique_name}.\n"
+                f"for non-chrome {browser_cls.type_name()}.\n"
                 "Use --browser-config for complex variants.")
-    browser_types = set(browser.type_name for browser in self._variants)
+    browser_types = set(
+        variant.browser_cls.type_name() for variant in self._variants)
     if len(browser_types) == 1:
       return
     if args.driver_path:
       raise argparse.ArgumentTypeError(
           f"Cannot use custom --driver-path='{args.driver_path}' "
           f"for multiple browser {browser_types}.")
+    if args.remote_driver_path:
+      raise argparse.ArgumentTypeError(
+          f"Cannot use custom --remote-driver-path='{args.remote_driver_path}' "
+          f"for multiple browser {browser_types}.")
     if args.other_browser_args:
       raise argparse.ArgumentTypeError(
           f"Multiple browser types {browser_types} "
           "cannot be used with common extra browser flags: "
           f"{args.other_browser_args}.\n"
           "Use --browser-config for complex variants.")
-
-  def _maybe_downloaded_binary(self,
-                               browser_config: BrowserConfig) -> BrowserConfig:
-    path_or_identifier = browser_config.browser
-    if isinstance(path_or_identifier, pth.AnyPath):
-      return browser_config
-    browser_platform = self._get_browser_platform(browser_config)
-    if ChromeDownloader.is_valid(path_or_identifier, browser_platform):
-      downloaded = ChromeDownloader.load(path_or_identifier, browser_platform)
-    elif FirefoxDownloader.is_valid(path_or_identifier, browser_platform):
-      downloaded = FirefoxDownloader.load(path_or_identifier, browser_platform)
-    else:
-      raise ValueError(
-          f"No version-download support for browser: {path_or_identifier}")
-    return BrowserConfig(downloaded, browser_config.driver)
-
-  def _append_browser(self, args: argparse.Namespace,
-                      browser_config: BrowserConfig) -> None:
-    assert browser_config, "Expected non-empty BrowserConfig."
-    browser_config = self._maybe_downloaded_binary(browser_config)
-    browser_cls: Type[Browser] = self.get_browser_cls(browser_config)
-    path: pth.AnyPath = browser_config.path
-    flags_sets = [browser_cls.default_flags()]
-
-    if browser_config.driver.is_local and not pth.LocalPath(path).exists():
-      raise argparse.ArgumentTypeError(f"Browser binary does not exist: {path}")
-
-    if issubclass(browser_cls, browsers.Chromium):
-      assert all(isinstance(flags, ChromeFlags) for flags in flags_sets)
-
-      extra_flag_sets = self._extract_chrome_flags(args)
-      flags_sets = [
-          flags.merge_copy(extra_flags)
-          for flags in flags_sets
-          for extra_flags in extra_flag_sets
-      ]
-
-    for flag_str in args.other_browser_args:
-      flag_name, flag_value = Flags.split(flag_str)
-      for flags in flags_sets:
-        flags.set(flag_name, flag_value)
-
-    browser_platform = self._get_browser_platform(browser_config)
-    with exception.annotate_argparsing("Creating network config"):
-      network_config = browser_config.network or args.network
-      network = self._get_browser_network(network_config, browser_platform)
-
-    name = f"{browser_platform}_{len(self._unique_names)}"
-    for flags in flags_sets:
-      label = name
-      if len(flags_sets) > 1:
-        label = self._flags_to_label(label, flags)
-      assert self._check_unique_label(label), f"Non-unique label: {label}"
-      settings = Settings(
-          flags=flags,
-          network=network,
-          driver_path=args.driver_path or browser_config.driver.path,
-          viewport=args.viewport,
-          splash_screen=args.splash_screen,
-          platform=browser_platform,
-          secrets=args.secrets.as_dict(),
-          driver_logging=args.driver_logging,
-          wipe_system_user_data=args.wipe_system_user_data,
-          http_request_timeout=args.http_request_timeout)
-
-      browser_instance = browser_cls(  # pytype: disable=not-instantiable # pylint: disable=abstract-class-instantiated
-          label=label,
-          path=path,
-          settings=settings)
-      logging.info("SELECTED BROWSER: name=%s path='%s' ",
-                   browser_instance.unique_name, path)
-      self._variants.append(browser_instance)
-
-  def _get_browser_network(self, network_config: Union[pth.LocalPath,
-                                                       NetworkConfig],
-                           browser_platform: plt.Platform) -> Network:
-    if not isinstance(network_config, NetworkConfig):
-      network_config = NetworkConfig.parse(network_config)
-    return network_config.create(browser_platform)
diff --git a/crossbench/cli/config/driver.py b/crossbench/cli/config/driver.py
index 6496a639..dabae7e9 100644
--- a/crossbench/cli/config/driver.py
+++ b/crossbench/cli/config/driver.py
@@ -6,16 +6,16 @@ from __future__ import annotations
 
 import argparse
 import dataclasses
-import enum
 import logging
 import re
-from typing import TYPE_CHECKING, Any, Dict, List, Optional, cast
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Self, Type, cast
 
 from immutabledict import immutabledict
+from typing_extensions import override
 
-from crossbench import compat
 from crossbench import path as pth
 from crossbench import plt
+from crossbench.cli.config.driver_type import BrowserDriverType
 from crossbench.config import ConfigObject, ConfigParser
 from crossbench.parse import NumberParser, ObjectParser, PathParser
 from crossbench.plt.android_adb import Adb, AndroidAdbPlatform, adb_devices
@@ -26,80 +26,44 @@ if TYPE_CHECKING:
   from crossbench.path import AnyPath, LocalPath
 
 
-@enum.unique
-class BrowserDriverType(compat.StrEnumWithHelp):
-  WEB_DRIVER = ("WebDriver", "Use Selenium with webdriver, for local runs.")
-  APPLE_SCRIPT = ("AppleScript", "Use AppleScript, for local macOS runs only")
-  ANDROID = ("Android",
-             "Use Webdriver for android. Allows to specify additional settings")
-  IOS = ("iOS", "Placeholder, unsupported at the moment")
-  LINUX_SSH = ("Remote Linux",
-               "Use remote webdriver and execute commands via SSH")
-  CHROMEOS_SSH = ("Remote ChromeOS",
-                  "Use remote ChromeDriver and execute commands via SSH")
-
-  @classmethod
-  def default(cls) -> BrowserDriverType:
-    return cls.WEB_DRIVER
-
-  @classmethod
-  def parse(cls, value: Any) -> BrowserDriverType:
-    if isinstance(value, cls):
-      return value
-    if value == "":
-      return BrowserDriverType.default()
-    value = ObjectParser.non_empty_str(value, "driver_type")
-    identifier = value.lower()
-    if identifier in ("selenium", "webdriver"):
-      return BrowserDriverType.WEB_DRIVER
-    if identifier in ("applescript", "osa"):
-      return BrowserDriverType.APPLE_SCRIPT
-    if identifier in ("android", "adb"):
-      return BrowserDriverType.ANDROID
-    if identifier in ("iphone", "ios"):
-      return BrowserDriverType.IOS
-    if identifier == "ssh":
-      return BrowserDriverType.LINUX_SSH
-    if identifier == "chromeos-ssh":
-      return BrowserDriverType.CHROMEOS_SSH
-    raise argparse.ArgumentTypeError(f"Unknown driver type: {repr(value)}")
-
-  @property
-  def is_remote(self):
-    if self.name in ("ANDROID", "CHROMEOS_SSH", "LINUX_SSH"):
-      return True
-    return False
-
-  @property
-  def is_local(self):
-    return not self.is_remote
-
-
 class AmbiguousDriverIdentifier(argparse.ArgumentTypeError):
   pass
 
 
-IOS_UUID_RE = re.compile(r"[0-9A-Z]+-[0-9A-Z-]+")
+IOS_UUID_RE: re.Pattern[str] = re.compile(r"[0-9A-Z]+-[0-9A-Z-]+")
+
+
+def driver_path(
+    value: Optional[pth.AnyPathLike],
+    type: BrowserDriverType,  #pylint: disable=redefined-builtin
+    name: str = "driver path"
+) -> Optional[pth.AnyPath]:
+  if not value:
+    return None
+  if type.is_remote_driver:
+    return PathParser.any_path(value, name)
+  return plt.PLATFORM.parse_local_binary_path(value, name)
 
 
 @dataclasses.dataclass(frozen=True)
 class DriverConfig(ConfigObject):
   type: BrowserDriverType = BrowserDriverType.default()
-  path: Optional[AnyPath] = None
-  device_id: Optional[str] = None
-  adb_bin: Optional[AnyPath] = None
-  settings: Optional[immutabledict] = None
+  path: AnyPath | None = None
+  device_id: str | None = None
+  adb_bin: AnyPath | None = None
+  settings: immutabledict | None = None
 
   @classmethod
   def default(cls) -> DriverConfig:
     return cls(BrowserDriverType.default())
 
   @classmethod
-  def parse_str(cls, value: str) -> DriverConfig:
+  @override
+  def parse_str(cls, value: str) -> Self:
     if not value:
       raise argparse.ArgumentTypeError("Cannot parse empty string")
     # Variant 1: $PATH
-    path: Optional[LocalPath] = pth.try_resolve_existing_path(value)
+    path: LocalPath | None = pth.try_resolve_existing_path(value)
     driver_type: BrowserDriverType = BrowserDriverType.default()
     if path:
       if path.stat().st_size == 0:
@@ -122,14 +86,14 @@ class DriverConfig(ConfigObject):
         except ValueError as e:
           logging.debug("Parsing short inline driver config failed: %s", e)
           raise original_error from e
-    return DriverConfig(driver_type, path)
+    return cls(driver_type, path)
 
   @classmethod
-  def parse_short_settings(cls, value: str,
-                           platform: plt.Platform) -> DriverConfig:
+  def parse_short_settings(cls: Type[Self], value: str,
+                           platform: plt.Platform) -> Self:
     """Check for short versions and multiple candidates"""
     logging.debug("Looking for driver candidates: %s", value)
-    candidate: Optional[DriverConfig]
+    candidate: Self | None = None
     if candidate := cls.try_parse_adb_settings(value, platform):
       return candidate
     if platform.is_macos:
@@ -140,7 +104,7 @@ class DriverConfig(ConfigObject):
 
   @classmethod
   def try_parse_adb_settings(cls, value: str,
-                             platform: plt.Platform) -> Optional[DriverConfig]:
+                             platform: plt.Platform) -> Optional[Self]:
     candidate_serials: List[str] = []
     pattern: re.Pattern = cls.compile_search_pattern(value)
     for serial, info in adb_devices(platform).items():
@@ -161,12 +125,11 @@ class DriverConfig(ConfigObject):
       logging.debug("No matching adb devices found.")
       return None
     assert len(candidate_serials) == 1
-    return DriverConfig(
-        BrowserDriverType.ANDROID, device_id=candidate_serials[0])
+    return cls(BrowserDriverType.ANDROID, device_id=candidate_serials[0])
 
   @classmethod
   def try_parse_ios_settings(cls, value: str,
-                             platform: plt.Platform) -> Optional[DriverConfig]:
+                             platform: plt.Platform) -> Optional[Self]:
     candidate_serials: List[str] = []
     pattern: re.Pattern = cls.compile_search_pattern(value)
     for uuid, device_info in ios_devices(platform).items():
@@ -184,7 +147,7 @@ class DriverConfig(ConfigObject):
       logging.debug("No matching ios devices found.")
       return None
     assert len(candidate_serials) == 1
-    return DriverConfig(BrowserDriverType.IOS, device_id=candidate_serials[0])
+    return cls(BrowserDriverType.IOS, device_id=candidate_serials[0])
 
   @classmethod
   def compile_search_pattern(cls, maybe_pattern: str) -> re.Pattern:
@@ -197,21 +160,17 @@ class DriverConfig(ConfigObject):
       return re.compile(re.escape(maybe_pattern))
 
   @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> DriverConfig:
-    return cls.config_parser().parse(config)
-
-  @classmethod
-  def config_parser(cls) -> ConfigParser[DriverConfig]:
-    parser = ConfigParser("DriverConfig parser", cls)
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
     parser.add_argument(
         "type",
         type=BrowserDriverType.parse,
         default=BrowserDriverType.default())
-    # TODO: likely distinguish between local and remote driver path
     parser.add_argument(
         "path",
-        type=PathParser.binary_path,
-        required=False,
+        type=driver_path,
+        depends_on=("type",),
         help="Path to the driver executable")
     parser.add_argument(
         "settings",
@@ -224,12 +183,11 @@ class DriverConfig(ConfigObject):
         help="Device ID / Serial ID / Unique device name")
     parser.add_argument(
         "adb_bin",
-        type=PathParser.binary_path,
-        required=False,
+        type=plt.PLATFORM.parse_local_binary_path,
         help="Path to the adb binary, only valid for Android.")
     return parser
 
-  def __post_init__(self):
+  def __post_init__(self) -> None:
     if not self.type:
       raise ValueError(f"{type(self).__name__}.type cannot be None.")
     try:
@@ -241,12 +199,13 @@ class DriverConfig(ConfigObject):
 
   @property
   def is_remote(self) -> bool:
-    return self.type.is_remote
+    return self.type.is_remote_driver
 
   @property
   def is_local(self) -> bool:
-    return self.type.is_local
+    return self.type.is_local_driver
 
+  @override
   def validate(self) -> None:
     if self.type == BrowserDriverType.ANDROID:
       self.validate_android()
@@ -260,6 +219,12 @@ class DriverConfig(ConfigObject):
       # the ChromeOS validation function validates the "client".
       # Consider moving this logic elsewhere in the future.
       self.validate_chromeos()
+    if self.is_local:
+      self.validate_local()
+
+  def validate_local(self) -> None:
+    if self.path:
+      plt.PLATFORM.parse_local_binary_path(self.path)
 
   def validate_android(self) -> None:
     platform = plt.PLATFORM
@@ -279,7 +244,7 @@ class DriverConfig(ConfigObject):
           f"Could not find ADB device with device_id={repr(self.device_id)}. "
           f"Choices are {names}.")
     if self.adb_bin:
-      PathParser.binary_path(self.adb_bin, platform=platform)
+      platform.parse_binary_path(self.adb_bin)
 
   def validate_chromeos(self) -> None:
     platform = self.get_platform()
@@ -321,21 +286,39 @@ class DriverConfig(ConfigObject):
       return self.get_ssh_platform()
     return plt.PLATFORM
 
+  def _parse_ssh_platform_driver_port(self) -> int:
+    port = None
+    if settings := self.settings:
+      port = settings.get("port")
+    if port in (None, 0):
+      # The driver port is allowed to be 0 on ssh platforms. If so, we will
+      # automatically start chromedriver.
+      return 0
+    return NumberParser.port_number(port)
+
   def get_ssh_platform(self) -> plt.Platform:
     assert self.settings
     host = ObjectParser.non_empty_str(self.settings.get("host"), "host")
-    port = NumberParser.port_number(self.settings.get("port"), "port")
+    port = self._parse_ssh_platform_driver_port()
     ssh_port = NumberParser.port_number(
         self.settings.get("ssh_port"), "ssh port")
     ssh_user = ObjectParser.non_empty_str(
         self.settings.get("ssh_user"), "ssh user")
     if self.type == BrowserDriverType.CHROMEOS_SSH:
+
+      try:
+        enable_arc = ObjectParser.bool(
+            self.settings.get("enable_arc"), "enable arc", strict=True)
+      except argparse.ArgumentTypeError:
+        enable_arc = False
+
       return ChromeOsSshPlatform(
           plt.PLATFORM,
           host=host,
           port=port,
           ssh_port=ssh_port,
-          ssh_user=ssh_user)
+          ssh_user=ssh_user,
+          enable_arc=enable_arc)
     return plt.LinuxSshPlatform(
         plt.PLATFORM,
         host=host,
diff --git a/crossbench/cli/config/driver_type.py b/crossbench/cli/config/driver_type.py
new file mode 100644
index 00000000..a36967a4
--- /dev/null
+++ b/crossbench/cli/config/driver_type.py
@@ -0,0 +1,72 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import enum
+from typing import Any
+
+from crossbench.parse import ObjectParser
+from crossbench.str_enum_with_help import StrEnumWithHelp
+
+
+@enum.unique
+class BrowserDriverType(StrEnumWithHelp):
+  WEB_DRIVER = ("WebDriver", "Use Selenium with webdriver, for local runs.")
+  APPLE_SCRIPT = ("AppleScript", "Use AppleScript, for local macOS runs only")
+  ANDROID = ("Android",
+             "Use Webdriver for android. Allows to specify additional settings")
+  IOS = ("iOS", "Placeholder, unsupported at the moment")
+  LINUX_SSH = ("Remote Linux",
+               "Use remote webdriver and execute commands via SSH")
+  CHROMEOS_SSH = ("Remote ChromeOS",
+                  "Use remote ChromeDriver and execute commands via SSH")
+
+  @classmethod
+  def default(cls) -> BrowserDriverType:
+    return cls.WEB_DRIVER
+
+  @classmethod
+  def parse(cls, value: Any) -> BrowserDriverType:
+    if isinstance(value, cls):
+      return value
+    if value == "":
+      return BrowserDriverType.default()
+    value = ObjectParser.non_empty_str(value, "driver_type")
+    identifier = value.lower()
+    if identifier in ("selenium", "webdriver"):
+      return BrowserDriverType.WEB_DRIVER
+    if identifier in ("applescript", "osa"):
+      return BrowserDriverType.APPLE_SCRIPT
+    if identifier in ("android", "adb"):
+      return BrowserDriverType.ANDROID
+    if identifier in ("iphone", "ios"):
+      return BrowserDriverType.IOS
+    if identifier == "ssh":
+      return BrowserDriverType.LINUX_SSH
+    if identifier == "chromeos-ssh":
+      return BrowserDriverType.CHROMEOS_SSH
+    raise argparse.ArgumentTypeError(f"Unknown driver type: {repr(value)}")
+
+  @property
+  def is_remote_driver(self) -> bool:
+    if self in (BrowserDriverType.CHROMEOS_SSH, BrowserDriverType.LINUX_SSH):
+      return True
+    return False
+
+  @property
+  def is_local_driver(self) -> bool:
+    return not self.is_remote_driver
+
+  @property
+  def is_remote_browser(self) -> bool:
+    if self in (BrowserDriverType.ANDROID, BrowserDriverType.CHROMEOS_SSH,
+                BrowserDriverType.LINUX_SSH):
+      return True
+    return False
+
+  @property
+  def is_local_browser(self) -> bool:
+    return not self.is_remote_browser
diff --git a/crossbench/cli/config/env.py b/crossbench/cli/config/env.py
index 8ed4aa09..e81607bd 100644
--- a/crossbench/cli/config/env.py
+++ b/crossbench/cli/config/env.py
@@ -5,46 +5,194 @@
 from __future__ import annotations
 
 import argparse
-from typing import TYPE_CHECKING
+import dataclasses
+import enum
+from typing import (TYPE_CHECKING, Any, Callable, Dict, List, Optional, Self,
+                    TypeAlias)
 
-import hjson
+from typing_extensions import override
 
-from crossbench.env import HostEnvironment, HostEnvironmentConfig
-from crossbench.parse import ObjectParser, PathParser
+from crossbench.config import ConfigObject, ConfigParser
+from crossbench.parse import NumberParser, ObjectParser
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 if TYPE_CHECKING:
-  from crossbench.path import LocalPath
+  Number: TypeAlias = float | int
 
+@enum.unique
+class ValidationMode(StrEnumWithHelp):
+  THROW = ("throw", "Strict mode, throw and abort on env issues")
+  PROMPT = ("prompt", "Prompt to accept potential env issues")
+  WARN = ("warn", "Only display a warning for env issue")
+  SKIP = ("skip", "Don't perform any env validation")
 
-def parse_inline_env_config(value: str) -> HostEnvironmentConfig:
-  if value in HostEnvironment.CONFIGS:
-    return HostEnvironment.CONFIGS[value]
-  if value[0] != "{":
-    raise argparse.ArgumentTypeError(
-        f"Invalid env config name: '{value}'. "
-        f"choices = {list(HostEnvironment.CONFIGS.keys())}")
-  # Assume hjson data
-  kwargs = None
-  msg = ""
-  try:
-    kwargs = ObjectParser.inline_hjson(value)
-    return HostEnvironmentConfig(**kwargs)
-  except Exception as e:
-    msg = f"\n{e}"
-    raise argparse.ArgumentTypeError(
-        f"Invalid inline config string: {value}{msg}") from e
-
-
-def parse_env_config_file(value: str) -> HostEnvironmentConfig:
-  config_path: LocalPath = PathParser.file_path(value)
-  try:
-    with config_path.open(encoding="utf-8") as f:
-      data = hjson.load(f)
-    if "env" not in data:
-      raise argparse.ArgumentTypeError("No 'env' property found")
-    kwargs = data["env"]
-    return HostEnvironmentConfig(**kwargs)
-  except Exception as e:
-    msg = f"\n{e}"
+
+def merge_bool(name: str, left: Optional[bool],
+               right: Optional[bool]) -> Optional[bool]:
+  if left is None:
+    return right
+  if right is None:
+    return left
+  if left != right:
+    raise ValueError(f"Conflicting merge values for {name}: "
+                     f"{left} vs. {right}")
+  return left
+
+
+
+
+def merge_number_max(name: str, left: Optional[Number],
+                     right: Optional[Number]) -> Optional[Number]:
+  del name
+  if left is None:
+    return right
+  if right is None:
+    return left
+  return max(left, right)
+
+
+def merge_number_min(name: str, left: Optional[Number],
+                     right: Optional[Number]) -> Optional[Number]:
+  del name
+  if left is None:
+    return right
+  if right is None:
+    return left
+  return min(left, right)
+
+
+def merge_str_list(name: str, left: Optional[List[str]],
+                   right: Optional[List[str]]) -> Optional[List[str]]:
+  del name
+  if left is None:
+    return right
+  if right is None:
+    return left
+  return left + right
+
+
+ENV_CONFIG_PRESETS: Dict[str, "EnvironmentConfig"] = {}
+
+
+@dataclasses.dataclass(frozen=True)
+class EnvironmentConfig(ConfigObject):
+  IGNORE = None
+
+  browser_allow_background: bool | None = IGNORE
+  browser_allow_existing_process: bool | None = IGNORE
+  browser_is_headless: bool | None = IGNORE
+  cpu_max_usage_percent: float | None = IGNORE
+  cpu_min_relative_speed: float | None = IGNORE
+  disk_min_free_space_gib: float | None = IGNORE
+  power_use_battery: bool | None = IGNORE
+  require_probes: bool | None = IGNORE
+  screen_allow_autobrightness: bool | None = IGNORE
+  screen_brightness_percent: int | None = IGNORE
+  system_allow_monitoring: bool | None = IGNORE
+  system_forbidden_process_names: List[str] | None = IGNORE
+
+  @classmethod
+  def default(cls) -> EnvironmentConfig:
+    return ENV_CONFIG_PRESETS["default"]
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> EnvironmentConfig:
+    value = ObjectParser.non_empty_str(value)
+    if preset := ENV_CONFIG_PRESETS.get(value):
+      return preset
+    if value[0] == "{":
+      return cls.parse_inline_hjson(value)
     raise argparse.ArgumentTypeError(
-        f"Invalid env config file: {value}{msg}") from e
+        f"Unknown host config preset {repr(value)}. "
+        f"Choices are {','.join(ENV_CONFIG_PRESETS.keys())}")
+
+  @classmethod
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
+    if "env" in config:
+      config = config["env"]
+    return super().parse_dict(config, **kwargs)
+
+  @classmethod
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
+    parser.add_argument("browser_allow_background", type=ObjectParser.bool)
+    parser.add_argument(
+        "browser_allow_existing_process",
+        type=ObjectParser.bool,
+        default=cls.IGNORE)
+    parser.add_argument("browser_is_headless", type=ObjectParser.bool)
+    parser.add_argument(
+        "cpu_max_usage_percent",
+        type=NumberParser.int_range(0, 100),
+        default=cls.IGNORE)
+    parser.add_argument(
+        "cpu_min_relative_speed",
+        type=NumberParser.int_range(0, 1),
+        default=cls.IGNORE)
+    parser.add_argument(
+        "disk_min_free_space_gib",
+        type=NumberParser.positive_float,
+        default=cls.IGNORE)
+    parser.add_argument("power_use_battery", type=ObjectParser.bool)
+    parser.add_argument("require_probes", type=ObjectParser.bool)
+    parser.add_argument(
+        "screen_allow_autobrightness",
+        type=ObjectParser.bool,
+        default=cls.IGNORE)
+    parser.add_argument("screen_brightness_percent", type=int)
+    parser.add_argument("system_allow_monitoring", type=ObjectParser.bool)
+    parser.add_argument(
+        "system_forbidden_process_names", type=str, is_list=True)
+    return parser
+
+  def merge(self, other: EnvironmentConfig) -> EnvironmentConfig:
+    mergers: Dict[str, Callable[[str, Any, Any], Any]] = {
+        "browser_allow_background": merge_bool,
+        "browser_allow_existing_process": merge_bool,
+        "browser_is_headless": merge_bool,
+        "cpu_max_usage_percent": merge_number_min,
+        "cpu_min_relative_speed": merge_number_max,
+        "disk_min_free_space_gib": merge_number_max,
+        "power_use_battery": merge_bool,
+        "require_probes": merge_bool,
+        "screen_allow_autobrightness": merge_bool,
+        "screen_brightness_percent": merge_number_max,
+        "system_allow_monitoring": merge_bool,
+        "system_forbidden_process_names": merge_str_list,
+    }
+    kwargs = {}
+    for name, merger in mergers.items():
+      self_value = getattr(self, name)
+      other_value = getattr(other, name)
+      kwargs[name] = merger(name, self_value, other_value)
+    return EnvironmentConfig(**kwargs)
+
+
+_config_default = EnvironmentConfig()
+_config_strict = EnvironmentConfig(
+    cpu_max_usage_percent=98,
+    cpu_min_relative_speed=1,
+    system_allow_monitoring=False,
+    browser_allow_existing_process=False,
+    require_probes=True,
+)
+_config_battery: EnvironmentConfig = _config_strict.merge(
+    EnvironmentConfig(power_use_battery=True))
+_config_power: EnvironmentConfig = _config_strict.merge(
+    EnvironmentConfig(power_use_battery=False))
+_config_catan: EnvironmentConfig = _config_strict.merge(
+    EnvironmentConfig(
+        screen_brightness_percent=65,
+        system_forbidden_process_names=["terminal", "iterm2"],
+        screen_allow_autobrightness=False))
+
+ENV_CONFIG_PRESETS.update({
+    "default": _config_default,
+    "strict": _config_strict,
+    "battery": _config_battery,
+    "power": _config_power,
+    "catan": _config_catan,
+})
diff --git a/crossbench/cli/config/flags.py b/crossbench/cli/config/flags.py
new file mode 100644
index 00000000..c91bdc2e
--- /dev/null
+++ b/crossbench/cli/config/flags.py
@@ -0,0 +1,303 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import functools
+import logging
+from typing import (TYPE_CHECKING, Any, Dict, Final, Iterable, List, Optional,
+                    Self, Sequence, Set, Tuple, Type)
+
+from immutabledict import immutabledict
+from ordered_set import OrderedSet
+from typing_extensions import override
+
+from crossbench import exception
+from crossbench.browsers.browser_helper import convert_flags_to_label
+from crossbench.config import ConfigError, ConfigObject
+from crossbench.flags.base import Flags
+from crossbench.flags.chrome import ChromeFlags
+from crossbench.flags.js_flags import JSFlags
+from crossbench.parse import ObjectParser
+
+if TYPE_CHECKING:
+  from crossbench.flags.base import FlagsData
+
+
+DEFAULT_LABEL: Final[str] = "default"
+
+
+def _parse_flags(flag_data: str | list | tuple | FlagsData | None) -> Flags:
+  if not flag_data:
+    return Flags().freeze()
+  if isinstance(flag_data, str):
+    return Flags.parse_str(flag_data).freeze()
+  if isinstance(flag_data, (list, tuple)):
+    return _parse_flags_sequence(flag_data)
+  return Flags.parse(flag_data).freeze()
+
+
+def _parse_flags_sequence(flag_data: Iterable) -> Flags:
+  split_flags = (Flags.split(flag) for flag in flag_data)
+  return Flags(split_flags).freeze()
+
+@dataclasses.dataclass(frozen=True)
+class FlagsVariantConfig:
+  label: str
+  index: int = 0
+  flags: Flags = dataclasses.field(default_factory=lambda: Flags().freeze())
+
+  @classmethod
+  def parse(cls, name: str, index: int, data: Any) -> FlagsVariantConfig:
+    return cls(name, index, _parse_flags(data))
+
+  def merge_copy(self,
+                 other: FlagsVariantConfig,
+                 label: Optional[str] = None,
+                 index: int = -1) -> FlagsVariantConfig:
+    index = self.index if index < 0 else index
+    new_label = label or f"{self.label}_{other.label}"
+    return FlagsVariantConfig(new_label, index,
+                              self.flags.merge_copy(other.flags).freeze())
+
+  def __hash__(self) -> int:
+    return hash(self.flags)
+
+  def __eq__(self, other: Any) -> bool:
+    if not isinstance(other, FlagsVariantConfig):
+      return False
+    return self.flags == other.flags
+
+
+class FlagsGroupConfig(Tuple[FlagsVariantConfig, ...]):
+  """
+  Config container for a list of FlagsVariantConfig:
+  FlagsGroupConfig(
+    FlagsVariantConfig("default"),
+    FlagsVariantConfig("max_opt_1", "--js-flags='--max-opt=1'),
+    FlagsVariantConfig("max_opt_2", "--js-flags='--max-opt=2'),
+    ...
+  )
+  """
+
+  @classmethod
+  def parse(cls, data: Any) -> Self:
+    if data is None:
+      return cls()
+    if isinstance(data, str):
+      return cls.parse_str(data)
+    if isinstance(data, dict):
+      return cls.parse_dict(data)
+    if isinstance(data, (list, tuple)):
+      return cls.parse_sequence(data)
+    raise ConfigError(f"Invalid type {type(data)}: {repr(data)}")
+
+  @classmethod
+  def parse_dict(cls, config: Dict) -> Self:
+    if not config:
+      return cls()
+    all_flag_keys = all(key.startswith("-") for key in config.keys())
+    all_str_values = all(isinstance(value, str) for value in config.values())
+    if not all_flag_keys:
+      return cls.parse_dict_with_labels(config)
+    if all_str_values:
+      return cls.parse_dict_simple(config)
+    return cls._parse_variants_dict(config)
+
+  @classmethod
+  def parse_dict_with_labels(cls, config: Dict) -> Self:
+    variants: OrderedSet[FlagsVariantConfig] = OrderedSet()
+    logging.debug("Using custom flag group labels")
+    for label, value in config.items():
+      with exception.annotate_argparsing(
+          f"Parsing flag variant ...[{repr(label)}]:"):
+        variant = FlagsVariantConfig.parse(label, len(variants), value)
+        if variant in variants:
+          raise ConfigError(f"Duplicate flag variant: {value}")
+        variants.add(variant)
+    return cls(tuple(variants))
+
+  @classmethod
+  def parse_dict_simple(cls, config: Dict) -> Self:
+    logging.debug("Using single flag group dict")
+    variants = (FlagsVariantConfig.parse(DEFAULT_LABEL, 0, config),)
+    return cls(variants)
+
+  @classmethod
+  def _parse_variants_dict(cls: Type[Self], data: Dict[str, Any]) -> Self:
+    # data == {
+    #  "--flag": None,
+    #  "--flag-b": "custom flag value",
+    #  "--flag-c": (None, "value 2", "value 3"),
+    # }
+    cls._validate_variants_dict(data)
+    # TODO: Use List[Self] once pytype supports it.
+    per_flag_groups: List = []
+    for flag_name, flag_data in data.items():
+      group = cls._dict_variant_to_group(flag_name, flag_data)
+      assert isinstance(group, cls)
+      per_flag_groups.append(group)
+
+    variants = per_flag_groups[0]
+    for next_variant in per_flag_groups[1:]:
+      variants = variants.product(next_variant)
+    return variants
+
+  @classmethod
+  def _validate_variants_dict(cls, data: Dict[str, Any]) -> None:
+    flags = Flags()
+    for flag_name, flag_value in data.items():
+      with exception.annotate_argparsing(
+          f"Parsing flag variant ...[{flag_name}]:"):
+        flags.set(flag_name)
+        if flag_value is None:
+          continue
+        if not isinstance(flag_value, (str, list, tuple)):
+          raise ConfigError(
+              f"Invalid flag variant value (None, str or sequence): "
+              f"{flag_name}={repr(flag_value)}")
+        if isinstance(flag_value, (list, tuple)):
+          ObjectParser.unique_sequence(
+              flag_value, f"flag {repr(flag_name)} variant values", ConfigError)
+
+  @classmethod
+  def _dict_variant_to_group(cls, flag_name: str, data: Any) -> Self:
+    if data is None:
+      return cls.parse_str(flag_name)
+    if isinstance(data, str):
+      data_str: str = data.strip()
+      if not data_str:
+        return cls.parse_str(flag_name)
+      data = (data_str,)
+    assert isinstance(data, (list, tuple)), "Invalid flag variant type"
+    flags: OrderedSet[Flags | None] = OrderedSet()
+    for variant in data:
+      if variant is None:
+        flag = None
+      elif not variant.strip():
+        flag = Flags((flag_name,))
+      else:
+        cls._validate_variant_flag(flag_name, variant)
+        flag = Flags({flag_name: variant})
+      if flag in flags:
+        raise ConfigError("Same flag variant was specified more than once: "
+                          f"{repr(flag)} for entry {repr(flag_name)}")
+      flags.add(flag)
+    return cls.parse_sequence(flags)
+
+  @classmethod
+  def _validate_variant_flag(cls, flag_name: str, flag_value: Any) -> None:
+    if flag_value == "None,":
+      raise ConfigError("Please use null (from json) instead of "
+                        f"None (from python) for flag {repr(flag_name)}")
+
+  @classmethod
+  def parse_sequence(cls, data: Sequence) -> Self:
+    variants: List[FlagsVariantConfig] = []
+    duplicates: Set[str] = set()
+    for flag_data in data:
+      flags = _parse_flags(flag_data)
+      if flag_data in duplicates:
+        raise ConfigError(f"Duplicate variant: {flags}")
+      duplicates.add(flag_data)
+      label = convert_flags_to_label(*flags)
+      variants.append(FlagsVariantConfig(label, len(variants), flags))
+    return cls(tuple(variants))
+
+  @classmethod
+  def parse_str(cls, value: str) -> Self:
+    if not value.strip():
+      return cls()
+    variants = (FlagsVariantConfig.parse(DEFAULT_LABEL, 0, value),)
+    return cls(variants)
+
+  @classmethod
+  def parse_args(cls, args: argparse.Namespace) -> Self:
+    args_config = cls.config_from_args_flags(args)
+    return cls.parse(args_config)
+
+  @classmethod
+  def config_from_args_flags(
+      cls, args: argparse.Namespace) -> Dict[str, List[str] | str | None]:
+    initial_flags = ChromeFlags(_parse_flags(args.other_browser_args))
+    if args.enable_features:
+      initial_flags["--enable-features"] = args.enable_features
+    if args.disable_features:
+      initial_flags["--disable-features"] = args.disable_features
+    if args.enable_field_trial_config is True:
+      initial_flags.set("--enable-field-trial-config")
+    if args.enable_field_trial_config is False:
+      initial_flags.set("--disable-field-trial-config")
+
+    args_config: Dict[str, List[str] | str | None] = dict(initial_flags.items())
+    if args.js_flags:
+      # Create a variant for every js flag:
+      args_config["--js-flags"] = [
+          str(JSFlags.parse(flags)) for flags in args.js_flags
+      ]
+    return args_config
+
+
+  def product(self, *args: Self) -> Self:
+    return functools.reduce(lambda a, b: a.inner_product(b), args, self)
+
+  def inner_product(self, other: Self) -> Self:
+    """Create a new FlagsGroupConfig as the combination of
+    self.variants x other.variants"""
+    new_variants: List[FlagsVariantConfig] = []
+    new_labels: Set[str] = set()
+    if not other:
+      return self
+    if not self:
+      return other
+    for variant in self:
+      for variant_other in other:
+        new_label = self._unique_product_label(new_labels, variant,
+                                               variant_other)
+        new_labels.add(new_label)
+        new_variant: FlagsVariantConfig = variant.merge_copy(
+            variant_other, index=len(new_variants), label=new_label)
+        new_variants.append(new_variant)
+
+    return type(self)(tuple(new_variants))
+
+  def _unique_product_label(self, label_set: Set[str],
+                            variant_a: FlagsVariantConfig,
+                            variant_b: FlagsVariantConfig) -> str:
+    default = f"{variant_a.label}_{variant_b.label}"
+    if variant_a.label == DEFAULT_LABEL:
+      default = variant_b.label
+    if variant_b.label == DEFAULT_LABEL:
+      default = variant_a.label
+    label = default
+    if not variant_a.flags:
+      label = variant_b.label
+    if not variant_b.flags:
+      label = variant_a.label
+    if label not in label_set:
+      return label
+    if default not in label_set:
+      return default
+    return f"{default}_{len(label_set)}"
+
+
+class FlagsConfig(ConfigObject, immutabledict[str, FlagsGroupConfig]):
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    if not value:
+      raise ConfigError("Cannot parse empty string")
+    return cls({"default": FlagsGroupConfig.parse_str(value)})
+
+  @classmethod
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
+    groups: Dict[str, FlagsGroupConfig] = {}
+    for group_name, group_data in config.items():
+      with exception.annotate(f"Parsing flag-group: flags[{repr(group_name)}]"):
+        groups[group_name] = FlagsGroupConfig.parse(group_data)
+    return cls(groups)
diff --git a/crossbench/cli/config/network.py b/crossbench/cli/config/network.py
index f116f662..7c13517d 100644
--- a/crossbench/cli/config/network.py
+++ b/crossbench/cli/config/network.py
@@ -7,9 +7,12 @@ from __future__ import annotations
 import argparse
 import dataclasses
 import enum
-from typing import TYPE_CHECKING, Any, Dict, Optional
+from typing import TYPE_CHECKING, Any, Optional, Self
+
+from typing_extensions import override
 
 from crossbench import exception
+from crossbench.cli.config.network_speed import NetworkSpeedConfig
 from crossbench.config import ConfigEnum, ConfigObject, ConfigParser
 from crossbench.network.live import LiveNetwork
 from crossbench.network.local_file_server import LocalFileNetwork
@@ -17,7 +20,7 @@ from crossbench.network.replay.wpr import (GS_PREFIX, LocalWprReplayNetwork,
                                            RemoteWprReplayNetwork)
 from crossbench.network.traffic_shaping import ts_proxy
 from crossbench.network.traffic_shaping.live import NoTrafficShaper
-from crossbench.parse import NumberParser, PathParser
+from crossbench.parse import PathParser
 
 if TYPE_CHECKING:
   from crossbench import path as pth
@@ -28,7 +31,6 @@ if TYPE_CHECKING:
 # We're using 'type' here a lot, let's skip the warnings from pylint.
 # pylint: disable=redefined-builtin
 
-
 @enum.unique
 class NetworkType(ConfigEnum):
   LIVE = ("live", "Live network.")
@@ -36,135 +38,47 @@ class NetworkType(ConfigEnum):
   LOCAL = ("local", "Serve content from a local http file server.")
 
 
-def _settings_str(name: str) -> str:
-  settings = ts_proxy.TRAFFIC_SETTINGS[name]
-  return (f"rtt={settings['rtt_ms']}ms, "
-          f"in={settings['in_kbps']} kbps,"
-          f"out={settings['out_kbps']} kbps")
-
-
-@enum.unique
-class NetworkSpeedPreset(ConfigEnum):
-  """Presets that match ts_proxy settings."""
-  LIVE = ("live", "Untroubled default network settings")
-  MOBILE_3G_SLOW = ("3G-slow",
-                    f"Slow 3G network settings: {_settings_str('3G-slow')}")
-  MOBILE_3G_REGULAR = (
-      "3G-regular",
-      f"Regular 3G network settings: {_settings_str('3G-regular')}")
-  MOBILE_3G_FAST = ("3G-fast",
-                    f"Slow 3G network settings: {_settings_str('3G-fast')}")
-  MOBILE_4G = ("4G", f"Regular 4G network settings: {_settings_str('4G')}")
-
-
-@dataclasses.dataclass(frozen=True)
-class NetworkSpeedConfig(ConfigObject):
-  ts_proxy: Optional[pth.AnyPath] = None
-  rtt_ms: Optional[int] = None
-  in_kbps: Optional[int] = None
-  out_kbps: Optional[int] = None
-  window: Optional[int] = None
-
-  @classmethod
-  def default(cls) -> NetworkSpeedConfig:
-    return NetworkSpeedConfig()
-
-  @classmethod
-  def parse(cls, value: Any, **kwargs) -> NetworkSpeedConfig:
-    if isinstance(value, NetworkSpeedPreset):
-      return cls.parse_preset(value)
-    return super().parse(value, **kwargs)
-
-  @classmethod
-  def parse_str(cls, value: str) -> NetworkSpeedConfig:
-    if not value:
-      raise argparse.ArgumentTypeError("Cannot parse empty string")
-    if value == "default":
-      return cls.default()
-    preset = NetworkSpeedPreset.parse(value)
-    return cls.parse_preset(preset)
-
-  @classmethod
-  def parse_preset(cls, preset: NetworkSpeedPreset) -> NetworkSpeedConfig:
-    if preset == NetworkSpeedPreset.LIVE:
-      return cls.default()
-    preset_kwargs = ts_proxy.TRAFFIC_SETTINGS[str(preset)]
-    return cls(**preset_kwargs)
-
-  @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> NetworkSpeedConfig:
-    return cls.config_parser().parse(config)
-
-  @classmethod
-  def config_parser(cls) -> ConfigParser[NetworkSpeedConfig]:
-    parser = ConfigParser(
-        "NetworkSpeedConfig parser", cls, default=NetworkSpeedConfig.default())
-    parser.add_argument(
-        "ts_proxy", type=PathParser.existing_file_path, required=False)
-    # See tsproxy.py --help
-    parser.add_argument(
-        "rtt_ms",
-        type=NumberParser.positive_int,
-        help="Round Trip Time Latency (in ms).")
-    parser.add_argument(
-        "in_kbps",
-        type=NumberParser.positive_int,
-        help="Download Bandwidth (in 1000 bits/s - Kbps).")
-    parser.add_argument(
-        "out_kbps",
-        type=NumberParser.positive_int,
-        help="Upload Bandwidth (in 1000 bits/s - Kbps).")
-    parser.add_argument(
-        "window",
-        default=10,
-        type=NumberParser.positive_int,
-        help="Emulated TCP initial congestion window (defaults to 10).")
-    return parser
-
-  @classmethod
-  def help(cls) -> str:
-    return cls.config_parser().help
-
-  @property
-  def is_live(self):
-    return self == self.default()
-
-
 @dataclasses.dataclass(frozen=True)
 class NetworkConfig(ConfigObject):
   type: NetworkType = NetworkType.LIVE
   speed: NetworkSpeedConfig = NetworkSpeedConfig.default()
-  path: Optional[pth.LocalPath] = None
-  url: Optional[str] = None
-  wpr_go_bin: Optional[pth.LocalPath] = None
+  path: pth.LocalPath | None = None
+  url: str | None = None
+  wpr_go_bin: pth.LocalPath | None = None
   persist_server: bool = False
   run_on_device: bool = False
+  skip_injection: bool = False
 
   ARCHIVE_EXTENSIONS = (".archive", ".wprgo")
   VALID_EXTENSIONS = ConfigObject.VALID_EXTENSIONS + ARCHIVE_EXTENSIONS
 
   @classmethod
-  def default(cls, type: Optional[NetworkType] = None) -> NetworkConfig:
-    return NetworkConfig(type=type or NetworkType.LIVE)
+  def default(cls, type: Optional[NetworkType] = None) -> Self:
+    return cls(type=type or NetworkType.LIVE)
 
   @classmethod
-  def config_parser(cls) -> ConfigParser[NetworkConfig]:
-    parser = ConfigParser(
-        "NetworkConfig parser", cls, default=NetworkConfig.default())
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls, default=cls.default())
     parser.add_argument("type", type=NetworkType, default=NetworkType.LIVE)
     parser.add_argument(
         "speed", type=NetworkSpeedConfig, default=NetworkSpeedConfig.default())
-    parser.add_argument("path", type=PathParser.existing_path, required=False)
-    parser.add_argument("url", type=str, required=False)
+    parser.add_argument("path", type=PathParser.existing_path)
+    parser.add_argument("url", type=str)
     parser.add_argument(
         "wpr_go_bin",
         type=PathParser.existing_file_path,
-        required=False,
         help=("Location of the wpr.go binary or source, "
               "used for WPR replay network. "
               "If not specified, a default lookup in known locations is used."))
     parser.add_argument("persist_server", type=bool, default=False)
     parser.add_argument("run_on_device", type=bool, default=False)
+    parser.add_argument(
+        "skip_injection",
+        type=bool,
+        default=False,
+        help=("Don't inject the deterministic.js script into every response "
+              "in WPR replay mode. Makes WPR response timings more stable."))
     return parser
 
   @classmethod
@@ -172,14 +86,14 @@ class NetworkConfig(ConfigObject):
     return cls.config_parser().help
 
   @classmethod
-  def parse_wpr(cls, value: Any) -> NetworkConfig:
-    config: NetworkConfig = cls.parse(value)
+  def parse_wpr(cls, value: Any) -> Self:
+    config = cls.parse(value)
     if config.type != NetworkType.WPR:
       raise argparse.ArgumentTypeError(f"Expected wpr, but got {config.type}")
     return config
 
   @classmethod
-  def parse_local(cls, value: Any) -> NetworkConfig:
+  def parse_local(cls, value: Any) -> Self:
     config = cls.parse(value, type=NetworkType.LOCAL)
     if config.type != NetworkType.LOCAL:
       raise argparse.ArgumentTypeError(
@@ -187,10 +101,11 @@ class NetworkConfig(ConfigObject):
     return config
 
   @classmethod
+  @override
   def parse_str(  # pylint: disable=arguments-differ
       cls,
       value: str,
-      type: Optional[NetworkType] = None) -> NetworkConfig:
+      type: Optional[NetworkType] = None) -> Self:
     if not value:
       raise argparse.ArgumentTypeError("Network: Cannot parse empty string")
     if value == "default":
@@ -209,42 +124,43 @@ class NetworkConfig(ConfigObject):
     return cls.parse_live(value)
 
   @classmethod
-  def parse_live(cls, value: Any) -> NetworkConfig:
+  def parse_live(cls, value: Any) -> Self:
     with exception.annotate_argparsing("Live network with speed config"):
       speed = NetworkSpeedConfig.parse(value)
       return cls(NetworkType.LIVE, speed)
     raise exception.UnreachableError()
 
   @classmethod
+  @override
   def is_valid_path(cls, path: pth.LocalPath) -> bool:
     if path.suffix in cls.ARCHIVE_EXTENSIONS:
       return True
     # for local file server
-    if path.is_dir():
-      return True
+    try:
+      if path.is_dir():
+        return True
+    except OSError:
+      pass
     return super().is_valid_path(path)
 
   @classmethod
-  def parse_path(cls, path: pth.LocalPath, **kwargs) -> NetworkConfig:
+  def parse_path(cls, path: pth.LocalPath, **kwargs) -> Self:
     if path.suffix in cls.ARCHIVE_EXTENSIONS:
       return cls.parse_wpr_archive_path(path)
     if path.is_dir():
-      return NetworkConfig(NetworkType.LOCAL, path=path)
+      return cls(NetworkType.LOCAL, path=path)
     return super().parse_path(path, **kwargs)
 
   @classmethod
-  def parse_wpr_archive_path(cls, path: pth.LocalPath) -> NetworkConfig:
+  def parse_wpr_archive_path(cls, path: pth.LocalPath) -> Self:
     path = PathParser.non_empty_file_path(path, "wpr.go archive")
-    return NetworkConfig(type=NetworkType.WPR, path=path)
+    return cls(type=NetworkType.WPR, path=path)
 
   @classmethod
-  def parse_wpr_archive_url(cls, url: str) -> NetworkConfig:
-    return NetworkConfig(type=NetworkType.WPR, url=url)
-
-  @classmethod
-  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> NetworkConfig:
-    return cls.config_parser().parse(config, **kwargs)
+  def parse_wpr_archive_url(cls, url: str) -> Self:
+    return cls(type=NetworkType.WPR, url=url)
 
+  @override
   def validate(self) -> None:
     if not self.type:
       raise argparse.ArgumentTypeError("Missing NetworkConfig.type.")
@@ -279,6 +195,9 @@ class NetworkConfig(ConfigObject):
     if self.run_on_device and self.type is not NetworkType.WPR:
       raise argparse.ArgumentTypeError(
           "run_on_device can only be used for the WPR replay network")
+    if self.skip_injection and self.type is not NetworkType.WPR:
+      raise argparse.ArgumentTypeError(
+          "skip_injection can only be used for the WPR replay network")
 
   def create(self, browser_platform: Platform) -> Network:
     with exception.annotate_argparsing(
@@ -292,14 +211,23 @@ class NetworkConfig(ConfigObject):
                                 browser_platform)
       if self.type is NetworkType.WPR:
         if self.run_on_device and browser_platform.is_remote:
-          if not browser_platform.is_android:
-            raise ValueError("run_on_device only supported on Android")
+          if not RemoteWprReplayNetwork.is_compatible(browser_platform):
+            raise ValueError(
+                f"run_on_device is unsupported on {browser_platform}")
           return RemoteWprReplayNetwork(
-              self.url or str(self.path), traffic_shaper, self.wpr_go_bin,
-              browser_platform, self.persist_server)
+              self.url or str(self.path),
+              traffic_shaper,
+              self.wpr_go_bin,
+              browser_platform,
+              self.persist_server,
+              inject_deterministic_script=not self.skip_injection)
         return LocalWprReplayNetwork(
-            self.url or str(self.path), traffic_shaper, self.wpr_go_bin,
-            browser_platform, self.persist_server)
+            self.url or str(self.path),
+            traffic_shaper,
+            self.wpr_go_bin,
+            browser_platform,
+            self.persist_server,
+            inject_deterministic_script=not self.skip_injection)
     raise ValueError(f"Unknown network type {self.type}")
 
   def _create_traffic_shaper(self, browser_platform: Platform) -> TrafficShaper:
diff --git a/crossbench/cli/config/network_speed.py b/crossbench/cli/config/network_speed.py
new file mode 100644
index 00000000..47f3eec4
--- /dev/null
+++ b/crossbench/cli/config/network_speed.py
@@ -0,0 +1,114 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import dataclasses
+import enum
+from typing import TYPE_CHECKING, Any, Self
+
+from typing_extensions import override
+
+from crossbench.config import ConfigEnum, ConfigObject, ConfigParser
+from crossbench.network.traffic_shaping import ts_proxy_settings
+from crossbench.parse import NumberParser, PathParser
+
+if TYPE_CHECKING:
+  from crossbench import path as pth
+
+# We're using 'type' here a lot, let's skip the warnings from pylint.
+# pylint: disable=redefined-builtin
+
+
+def _settings_str(name: str) -> str:
+  settings = ts_proxy_settings.TRAFFIC_SETTINGS[name]
+  return (f"rtt={settings['rtt_ms']}ms, "
+          f"in={settings['in_kbps']} kbps,"
+          f"out={settings['out_kbps']} kbps")
+
+
+@enum.unique
+class NetworkSpeedPreset(ConfigEnum):
+  """Presets that match ts_proxy settings."""
+  LIVE = ("live", "Untroubled default network settings")
+  MOBILE_3G_SLOW = ("3G-slow",
+                    f"Slow 3G network settings: {_settings_str('3G-slow')}")
+  MOBILE_3G_REGULAR = (
+      "3G-regular",
+      f"Regular 3G network settings: {_settings_str('3G-regular')}")
+  MOBILE_3G_FAST = ("3G-fast",
+                    f"Slow 3G network settings: {_settings_str('3G-fast')}")
+  MOBILE_4G = ("4G", f"Regular 4G network settings: {_settings_str('4G')}")
+
+
+@dataclasses.dataclass(frozen=True)
+class NetworkSpeedConfig(ConfigObject):
+  ts_proxy: pth.AnyPath | None = None
+  rtt_ms: int | None = None
+  in_kbps: int | None = None
+  out_kbps: int | None = None
+  window: int | None = None
+
+  @classmethod
+  def default(cls) -> Self:
+    return cls()
+
+  @classmethod
+  @override
+  def parse(cls, value: Any, **kwargs) -> Self:
+    if isinstance(value, NetworkSpeedPreset):
+      return cls.parse_preset(value)
+    return super().parse(value, **kwargs)
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    if not value:
+      raise argparse.ArgumentTypeError("Cannot parse empty string")
+    if value == "default":
+      return cls.default()
+    preset = NetworkSpeedPreset.parse(value)
+    return cls.parse_preset(preset)
+
+  @classmethod
+  def parse_preset(cls, preset: NetworkSpeedPreset) -> Self:
+    if preset == NetworkSpeedPreset.LIVE:
+      return cls.default()
+    preset_kwargs = ts_proxy_settings.TRAFFIC_SETTINGS[str(preset)]
+    return cls(**preset_kwargs)
+
+  @classmethod
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls, default=cls.default())
+    parser.add_argument(
+        "ts_proxy", type=PathParser.existing_file_path, required=False)
+    # See tsproxy.py --help
+    parser.add_argument(
+        "rtt_ms",
+        type=NumberParser.positive_int,
+        help="Round Trip Time Latency (in ms).")
+    parser.add_argument(
+        "in_kbps",
+        type=NumberParser.positive_int,
+        help="Download Bandwidth (in 1000 bits/s - Kbps).")
+    parser.add_argument(
+        "out_kbps",
+        type=NumberParser.positive_int,
+        help="Upload Bandwidth (in 1000 bits/s - Kbps).")
+    parser.add_argument(
+        "window",
+        default=10,
+        type=NumberParser.positive_int,
+        help="Emulated TCP initial congestion window (defaults to 10).")
+    return parser
+
+  @classmethod
+  def help(cls) -> str:
+    return cls.config_parser().help
+
+  @property
+  def is_live(self) -> bool:
+    return self == self.default()
diff --git a/crossbench/cli/config/probe.py b/crossbench/cli/config/probe.py
index e000e900..fee93b09 100644
--- a/crossbench/cli/config/probe.py
+++ b/crossbench/cli/config/probe.py
@@ -4,13 +4,12 @@
 
 from __future__ import annotations
 
-import argparse
 import dataclasses
 import re
-from typing import (TYPE_CHECKING, Any, Dict, Final, Iterable, List, Optional,
-                    Sequence, Type)
+from typing import TYPE_CHECKING, Any, Dict, Final, Self, Type
+
+from typing_extensions import override
 
-from crossbench import exception
 from crossbench.config import ConfigError, ConfigObject
 from crossbench.parse import ObjectParser
 from crossbench.probes.all import GENERAL_PURPOSE_PROBES
@@ -33,17 +32,18 @@ _PROBE_CONFIG_RE: Final[re.Pattern] = re.compile(
 
 @dataclasses.dataclass(frozen=True)
 class ProbeConfig(ConfigObject):
-  cls: Type[Probe]
+  probe_cls: Type[Probe]
   config: Dict[str, Any] = dataclasses.field(default_factory=dict)
 
   def __post_init__(self) -> None:
-    if not self.cls:
+    if not self.probe_cls:
       raise ValueError(f"{type(self).__name__}.cls cannot be None.")
     if self.config is None:
       raise ValueError(f"{type(self).__name__}.config cannot be None.")
 
   @classmethod
-  def parse_str(cls, value: str) -> ProbeConfig:
+  @override
+  def parse_str(cls, value: str) -> Self:
     # 1. variant: known probe
     if value in PROBE_LOOKUP:
       return cls(PROBE_LOOKUP[value])
@@ -64,13 +64,13 @@ class ProbeConfig(ConfigObject):
     return cls.parse_dict(config)
 
   @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> ProbeConfig:
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
     probe_name = ObjectParser.non_empty_str(config.pop("name"), "name")
     return cls.parse_probe_dict(probe_name, config)
 
   @classmethod
-  def parse_probe_dict(cls, probe_name: str, config: Dict[str,
-                                                          Any]) -> ProbeConfig:
+  def parse_probe_dict(cls, probe_name: str, config: Dict[str, Any]) -> Self:
     if probe_cls := PROBE_LOOKUP.get(probe_name):
       return cls(probe_cls, config)
     raise cls._unknown_probe_error(probe_name)
@@ -85,67 +85,4 @@ class ProbeConfig(ConfigObject):
 
   @property
   def name(self) -> str:
-    return self.cls.NAME
-
-
-class ProbeListConfig(ConfigObject):
-
-  @classmethod
-  def from_cli_args(cls, args: argparse.Namespace) -> ProbeListConfig:
-    with exception.annotate_argparsing():
-      if args.probe_config:
-        return cls.parse_path(args.probe_config)
-      return cls(args.probe)
-
-  @classmethod
-  def parse_other(cls: Type[ProbeListConfig], value: Any) -> ProbeListConfig:
-    if isinstance(value, (tuple, list)):
-      return cls.parse_sequence(value)
-    return super().parse_other(value)
-
-  @classmethod
-  def parse_sequence(cls: Type[ProbeListConfig],
-                     config: Sequence[Dict[str, Any]]) -> ProbeListConfig:
-    probe_configs: List[ProbeConfig] = []
-    for index, probe_config in enumerate(config):
-      probe_config = ObjectParser.dict(probe_config, f"probes[{index}]")
-      probe_configs.append(ProbeConfig.parse_dict(probe_config))
-    return cls(probe_configs)
-
-  @classmethod
-  def parse_dict(cls: Type[ProbeListConfig],
-                 config: Dict[str, Any]) -> ProbeListConfig:
-    # Support global configs with {"probes": ...}
-    if "probes" in config:
-      config = config["probes"]
-      if isinstance(config, (tuple, list)):
-        return cls.parse_sequence(config)
-    elif "browsers" in config or "flags" in config:
-      raise ProbeConfigError("Missing 'probes' property in global config.")
-    config = ObjectParser.dict(config, "probes")
-    probe_configs: List[ProbeConfig] = []
-    for probe_name, config_data in config.items():
-      with exception.annotate(f"Parsing probe config probes['{probe_name}']"):
-        probe_configs.append(
-            ProbeConfig.parse_probe_dict(probe_name, config_data))
-    return cls(probe_configs)
-
-  @classmethod
-  def parse_str(cls, value: str) -> ProbeListConfig:
-    raise NotImplementedError()
-
-  def __init__(self, probes: Optional[Iterable[ProbeConfig]] = None):
-    self._probes: List[Probe] = []
-    if not probes:
-      return
-    for probe_config in probes:
-      with exception.annotate(f"Parsing --probe={probe_config.name}"):
-        self._add_probe(probe_config)
-
-  @property
-  def probes(self) -> List[Probe]:
-    return self._probes
-
-  def _add_probe(self, probe_config: ProbeConfig) -> None:
-    probe: Probe = probe_config.cls.from_config(probe_config.config)
-    self._probes.append(probe)
+    return self.probe_cls.NAME
diff --git a/crossbench/cli/config/probe_list.py b/crossbench/cli/config/probe_list.py
new file mode 100644
index 00000000..11724c2b
--- /dev/null
+++ b/crossbench/cli/config/probe_list.py
@@ -0,0 +1,113 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import logging
+from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Self, Sequence
+
+from typing_extensions import override
+
+from crossbench import exception
+from crossbench.cli.config.probe import ProbeConfig, ProbeConfigError
+from crossbench.config import ConfigObject
+from crossbench.parse import ObjectParser
+
+if TYPE_CHECKING:
+  import crossbench.path as pth
+  from crossbench.probes.probe import Probe
+
+
+class ProbeListConfig(ConfigObject):
+
+  @classmethod
+  def from_cli_args(cls, args: argparse.Namespace) -> Self:
+    with exception.annotate_argparsing():
+      config_from_args = cls(args.probe)
+      if not args.probe_config:
+        return config_from_args
+      probe_config_path: pth.LocalPath = args.probe_config
+      config_from_file = cls.parse_path(probe_config_path)
+      with exception.annotate(
+          f"Merging probe config ({probe_config_path.name}) with cli --probe:"):
+        return config_from_file.merge(config_from_args, should_override=True)
+    raise exception.UnreachableError()
+
+  @classmethod
+  def parse_other(cls, value: Any) -> Self:
+    if isinstance(value, (tuple, list)):
+      return cls.parse_sequence(value)
+    return super().parse_other(value)
+
+  @classmethod
+  def parse_sequence(cls, config: Sequence[Dict[str, Any]]) -> Self:
+    probe_configs: List[ProbeConfig] = []
+    for index, probe_config in enumerate(config):
+      with exception.annotate(f"Parsing probes[{index}]"):
+        probe_configs.append(ProbeConfig.parse(probe_config))
+    return cls(probe_configs)
+
+  @classmethod
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
+    # Support global configs with {"probes": ...}
+    if "probes" in config:
+      config = config["probes"]
+      if isinstance(config, (tuple, list)):
+        return cls.parse_sequence(config)
+    elif "browsers" in config or "flags" in config:
+      raise ProbeConfigError("Missing 'probes' property in global config.")
+    config = ObjectParser.dict(config, "probes")
+    probe_configs: List[ProbeConfig] = []
+    for probe_name, config_data in config.items():
+      with exception.annotate(f"Parsing probe config probes['{probe_name}']"):
+        probe_configs.append(
+            ProbeConfig.parse_probe_dict(probe_name, config_data))
+    return cls(probe_configs)
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    raise NotImplementedError()
+
+  def __init__(
+      self,
+      probe_configs: Iterable[ProbeConfig] = tuple(),
+      probes: Iterable[Probe] = tuple()
+  ) -> None:
+    self._probes: Dict[str, Probe] = {}
+    if not probe_configs and not probes:
+      return
+    for probe_config in probe_configs:
+      with exception.annotate(f"Parsing --probe={probe_config.name}"):
+        self._add_probe_config(probe_config)
+    for probe in probes:
+      self._add_probe(probe)
+
+  @property
+  def probes(self) -> List[Probe]:
+    return list(self._probes.values())
+
+  def _add_probe_config(self, probe_config: ProbeConfig) -> None:
+    probe: Probe = probe_config.probe_cls.from_config(probe_config.config)
+    self._add_probe(probe)
+
+  def _add_probe(self, probe: Probe) -> None:
+    if probe.name in self._probes:
+      raise ValueError(f"Duplicate probe: {probe.name}")
+    self._probes[probe.name] = probe
+
+  def merge(self, other: Self, should_override: bool = False) -> Self:
+    merged_probes = {probe.name: probe for probe in self.probes}
+    for probe in other.probes:
+      name = probe.name
+      if name in merged_probes:
+        if not should_override:
+          raise ValueError(f"Duplicate probe: {name}")
+        logging.warning("PROBES: Overriding existing probe %s!", name)
+      merged_probes[name] = probe
+
+    merged = type(self)(probes=merged_probes.values())
+    return merged
diff --git a/crossbench/cli/config/secrets.py b/crossbench/cli/config/secrets.py
index 7d2318a2..c146795b 100644
--- a/crossbench/cli/config/secrets.py
+++ b/crossbench/cli/config/secrets.py
@@ -5,56 +5,50 @@
 from __future__ import annotations
 
 import dataclasses
-from typing import Dict, Type
+from typing import TYPE_CHECKING, Self
 
-from immutabledict import immutabledict
+from typing_extensions import override
 
-from crossbench import exception
-from crossbench.cli.config.secret_type import SecretType
 from crossbench.config import ConfigObject, ConfigParser
 from crossbench.parse import ObjectParser
 
-SecretsDict = immutabledict[SecretType, "Secret"]
+if TYPE_CHECKING:
+  from crossbench.types import JsonDict
 
 
 @dataclasses.dataclass(frozen=True)
-class SecretsConfig(ConfigObject):
-  secrets: SecretsDict = dataclasses.field(default_factory=immutabledict)
+class Secrets(ConfigObject):
+  google: UsernamePassword | None = None
+  bond: ServiceAccount | None = None
 
   @classmethod
-  def parse_str(cls, value: str) -> SecretsConfig:
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
+    parser.add_argument("google", type=GoogleUsernamePassword)
+    parser.add_argument("bond", type=ServiceAccount)
+    return parser
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
     if value[0] == "{":
       return cls.parse_inline_hjson(value)
-    # TODO: maybe support passwd style string format
     raise NotImplementedError("Cannot create secrets from string")
 
-  @classmethod
-  def parse_dict(cls, config: Dict) -> SecretsConfig:
-    secrets = {}
-    for type_str, secret_data in config.items():
-      secret_type = SecretType.parse(type_str)
-      with exception.annotate_argparsing("Parsing Secret details:"):
-        secret = Secret.parse_dict(secret_data, type=secret_type)
-      assert isinstance(secret,
-                        Secret), f"Expected {cls} but got {type(secret)}"
-      assert secret_type not in secrets, f"Duplicate entry for {type_str}"
-      secrets[secret_type] = secret
-    return SecretsConfig(immutabledict(secrets))
-
-  def as_dict(self) -> SecretsDict:
-    return self.secrets
-
+  def merge(self, fallback: Secrets) -> Self:
+    return type(self)(self.google or fallback.google, self.bond or
+                      fallback.bond)
 
 @dataclasses.dataclass(frozen=True)
-class Secret(ConfigObject):
-  type: SecretType
+class UsernamePassword(ConfigObject):
   username: str
   password: str
 
   @classmethod
-  def config_parser(cls: Type[Secret]) -> ConfigParser[Secret]:
-    parser = ConfigParser(f"{cls.__name__} parser", cls)
-    parser.add_argument("type", type=SecretType, required=True)
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
     parser.add_argument(
         "username",
         aliases=("user", "usr", "account"),
@@ -68,11 +62,76 @@ class Secret(ConfigObject):
     return parser
 
   @classmethod
-  def parse_dict(  # pylint: disable=arguments-differ
-      cls, config: Dict, **kwargs) -> Secret:
-    return cls.config_parser().parse(config, **kwargs)
-
-  @classmethod
-  def parse_str(cls, value: str):
+  @override
+  def parse_str(cls, value: str) -> Self:
     # TODO: maybe support passwd style string format
     raise NotImplementedError("Cannot support")
+
+
+class GoogleUsernamePassword(UsernamePassword):
+  pass
+
+
+@dataclasses.dataclass(frozen=True)
+class ServiceAccount(ConfigObject):
+  type: str
+  project_id: str
+  private_key_id: str
+  private_key: str
+  client_email: str
+  client_id: str
+  auth_uri: str
+  token_uri: str
+  auth_provider_x509_cert_url: str
+  client_x509_cert_url: str
+  universe_domain: str
+
+  @classmethod
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
+    parser.add_argument("type", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "project_id", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "private_key_id", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "private_key", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "client_email", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "client_id", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "auth_uri", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "token_uri", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "auth_provider_x509_cert_url",
+        type=ObjectParser.non_empty_str,
+        required=True)
+    parser.add_argument(
+        "client_x509_cert_url", type=ObjectParser.non_empty_str, required=True)
+    parser.add_argument(
+        "universe_domain", type=ObjectParser.non_empty_str, required=True)
+    return parser
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    del value
+    raise NotImplementedError("ServiceAccount from string not supported")
+
+  def to_json(self) -> JsonDict:
+    return {
+        "type": self.type,
+        "project_id": self.project_id,
+        "private_key_id": self.private_key_id,
+        "private_key": self.private_key,
+        "client_email": self.client_email,
+        "client_id": self.client_id,
+        "auth_uri": self.auth_uri,
+        "token_uri": self.token_uri,
+        "auth_provider_x509_cert_url": self.auth_provider_x509_cert_url,
+        "client_x509_cert_url": self.client_x509_cert_url,
+        "universe_domain": self.universe_domain,
+    }
diff --git a/crossbench/cli/exception_formatter.py b/crossbench/cli/exception_formatter.py
new file mode 100644
index 00000000..00868235
--- /dev/null
+++ b/crossbench/cli/exception_formatter.py
@@ -0,0 +1,135 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# Most of this code is originally based on the colored_traceback package:
+
+# Copyright (c) 2014, Anton Backer <olegov@gmail.com>
+# Permission to use, copy, modify, and/or distribute this software for any
+# purpose with or without fee is hereby granted, provided that the above
+# copyright notice and this permission notice appear in all copies.
+# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
+# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+# AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
+# INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+# LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
+# OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+# PERFORMANCE OF THIS SOFTWARE.
+
+from __future__ import annotations
+
+import io
+import logging
+import traceback
+from typing import Callable, List
+
+from pygments import highlight
+from pygments.formatters import get_formatter_by_name
+from pygments.lexers import get_lexer_by_name
+from pygments.util import ClassNotFound
+
+from crossbench.cli import ui
+
+
+def _get_term_color_support() -> int:
+  try:
+    import curses  # pylint: disable=import-outside-toplevel
+  except ImportError:
+    # Probably Windows, which doesn't have great curses support
+    return 16
+  curses.setupterm()
+  return curses.tigetnum("colors")
+
+
+def _determine_formatter(style: str = "default", colors=None):
+  colors = colors or _get_term_color_support()
+  logging.debug("Detected support for %s colors", colors)
+  if colors == 256:
+    fmt_options = {"style": style}
+  elif style in ("light", "dark"):
+    fmt_options = {"bg": style}
+  else:
+    fmt_options = {"bg": "dark"}
+  fmt_alias = "terminal256" if colors == 256 else "terminal"
+  try:
+    return get_formatter_by_name(fmt_alias, **fmt_options)
+  except ClassNotFound as e:
+    logging.debug("Error setting up colorizer: %s", e)
+    return get_formatter_by_name(fmt_alias)
+
+
+def _get_causes(ex_type, ex_value, tb) -> List[traceback.TracebackException]:
+  tb_exception = traceback.TracebackException(ex_type, ex_value, tb)
+  causes: List[traceback.TracebackException] = []
+  current = tb_exception
+  while True:
+    causes.append(current)
+    if current.__cause__ is not None:
+      current = current.__cause__
+    elif (current.__context__ is not None and not current.__suppress_context__):
+      current = current.__context__
+    else:
+      break
+  return causes
+
+
+def _get_tb_printer() -> Callable[[str], None]:
+  try:
+    if ui.COLOR_LOGGING:
+      return _get_formatting_tb_printer()
+  except Exception as e:  # pylint: disable=broad-exception-caught
+    logging.debug("Failed to initializer error formatting: %s", e)
+  return print
+
+
+def _get_formatting_tb_printer() -> Callable[[str], None]:
+  formatter = _determine_formatter()
+  lexer = get_lexer_by_name("py3tb")
+
+  def formatting_tb_printer(formatted_tb: str) -> None:
+    print(highlight(formatted_tb, lexer, formatter))
+
+  return formatting_tb_printer
+
+
+def excepthook(ex_type, ex_value, tb) -> None:
+  causes: List[traceback.TracebackException] = _get_causes(
+      ex_type, ex_value, tb)
+  tb_printer = _get_tb_printer()
+
+  print("-" * 80)
+  # Print exception causes in non-reverse order compared to the default
+  # python traceback formatter. This way we keep the stack order consistent
+  # where the inner frame is *always* printed below the outer frame.
+  # This makes scanning for exceptions much more intuitive.
+  for i, cause in enumerate(causes):
+    if i:
+      print("")
+    buffer = io.StringIO()
+    # TODO: use better helpers when migrated to 3.11.
+    for line in cause.format(chain=False):
+      print(line, file=buffer, end="")
+    tb_printer(buffer.getvalue())
+
+  if len(causes) > 0:
+    print("-" * 80)
+    print("OUTERMOST EXCEPTION SUMMARY:")
+    print("-" * 80)
+    formatted_tb: str = _print_outermost_exception(causes[0])
+    tb_printer(formatted_tb)
+
+
+def _print_outermost_exception(
+    last_exception: traceback.TracebackException) -> str:
+  buffer = io.StringIO()
+  if stack := last_exception.stack:
+    innermost_frame: traceback.FrameSummary = stack[-1]
+    # TODO: use better helpers when migrated to 3.11.
+    stack_summary = traceback.StackSummary.from_list((innermost_frame,))
+    print("  ...", file=buffer)
+    for line in stack_summary.format():
+      print(line, file=buffer, end="")
+  # TODO: use better helpers when migrated to 3.11.
+  for line in last_exception.format_exception_only():
+    print(line, file=buffer, end=None)
+  return buffer.getvalue()
diff --git a/crossbench/cli/parser.py b/crossbench/cli/parser.py
index 107a1ed4..d2813e8b 100644
--- a/crossbench/cli/parser.py
+++ b/crossbench/cli/parser.py
@@ -7,20 +7,23 @@ from __future__ import annotations
 import argparse
 import logging
 import sys
+from typing import Never, Optional
 
 import colorama
 
 from crossbench.cli import ui
 
 
-# Needed to gap the diff between 3.8 and 3.9 default args that change throwing
-# behavior.
-class _BaseCrossBenchArgumentParser(argparse.ArgumentParser):
+class CrossBenchArgumentParser(argparse.ArgumentParser):
 
-  def fail(self, message) -> None:
+  def __init__(self, *args, **kwargs) -> None:
+    kwargs["exit_on_error"] = False
+    super().__init__(*args, **kwargs)
+
+  def fail(self, message: str) -> None:
     super().error(message)
 
-  def exit(self, status=0, message=None) -> None:
+  def exit(self, status: int = 0, message: Optional[str] = None) -> Never:
     if message:
       if status == 0:
         logging.info(message)
@@ -32,23 +35,3 @@ class _BaseCrossBenchArgumentParser(argparse.ArgumentParser):
         if ui.COLOR_LOGGING:
           print(str(colorama.Style.RESET_ALL))
     sys.exit(status)
-
-
-if sys.version_info < (3, 9, 0):
-
-  class CrossBenchArgumentParser(_BaseCrossBenchArgumentParser):
-
-    def error(self, message) -> None:
-      # Let the CrossBenchCLI handle all errors and simplify testing.
-      exception = sys.exc_info()[1]
-      if isinstance(exception, BaseException):
-        raise exception
-      raise argparse.ArgumentError(None, message)
-
-else:
-
-  class CrossBenchArgumentParser(_BaseCrossBenchArgumentParser):
-
-    def __init__(self, *args, **kwargs) -> None:
-      kwargs["exit_on_error"] = False
-      super().__init__(*args, **kwargs)
diff --git a/crossbench/cli/subcommand/base.py b/crossbench/cli/subcommand/base.py
new file mode 100644
index 00000000..734bb270
--- /dev/null
+++ b/crossbench/cli/subcommand/base.py
@@ -0,0 +1,42 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import argparse
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.cli.cli import CrossBenchCLI
+
+
+class CrossbenchSubcommand(abc.ABC):
+
+  def __init__(self, cli: CrossBenchCLI) -> None:
+    self._cli = cli
+    self._parser: argparse.ArgumentParser = self.add_cli_parser()
+    self._parser.set_defaults(crossbench_subcommand=self)
+
+  @property
+  def cli(self) -> CrossBenchCLI:
+    return self._cli
+
+  @property
+  def parser(self) -> argparse.ArgumentParser:
+    return self._parser
+
+  @abc.abstractmethod
+  def add_cli_parser(self) -> argparse.ArgumentParser:
+    pass
+
+  @abc.abstractmethod
+  def run(self, args: argparse.Namespace) -> None:
+    pass
+
+  def error(self, message: str) -> None:
+    self.cli.error(message)
+
+  def fail(self, message: str) -> None:
+    self._parser.error(message)
diff --git a/crossbench/cli/subcommand/benchmark.py b/crossbench/cli/subcommand/benchmark.py
new file mode 100644
index 00000000..f60d17e6
--- /dev/null
+++ b/crossbench/cli/subcommand/benchmark.py
@@ -0,0 +1,834 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import datetime as dt
+import itertools
+import logging
+import sys
+from typing import TYPE_CHECKING, Any, List, Optional, Sequence, Tuple, Type
+
+from typing_extensions import override
+
+from crossbench import exception
+from crossbench import path as pth
+from crossbench import plt
+from crossbench.benchmarks.base import Benchmark
+from crossbench.browsers.splash_screen import SplashScreen
+from crossbench.browsers.viewport import Viewport, ViewportMode
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.cli.config.env import (ENV_CONFIG_PRESETS, EnvironmentConfig,
+                                       ValidationMode)
+from crossbench.cli.config.network import NetworkConfig
+from crossbench.cli.config.probe import PROBE_LOOKUP, ProbeConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
+from crossbench.cli.config.secrets import Secrets
+from crossbench.cli.subcommand.base import CrossbenchSubcommand
+from crossbench.parse import (DurationParser, LateArgumentError, ObjectParser,
+                              PathParser)
+from crossbench.probes.debugger import DebuggerProbe
+from crossbench.probes.internal.errors import ErrorsProbe
+from crossbench.probes.thermal_monitor import ThermalStatus
+from crossbench.runner.run_annotation import RunAnnotation
+from crossbench.runner.runner import Runner
+from crossbench.runner.timing import Timing
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.cli.cli import CrossBenchCLI
+  from crossbench.probes.probe import Probe
+  from crossbench.runner.run import Run
+
+
+class EnableFastAction(argparse.Action):
+  """Custom action to enable fast test runs"""
+
+  def __call__(self,
+               parser: argparse.ArgumentParser,
+               namespace: argparse.Namespace,
+               values: str | Sequence[Any] | None,
+               option_string: Optional[str] = None) -> None:
+    setattr(namespace, "cool_down_time", dt.timedelta())
+    setattr(namespace, "splash_screen", SplashScreen.NONE)
+    setattr(namespace, "env_validation", ValidationMode.SKIP)
+
+
+class AppendDebuggerProbeAction(argparse.Action):
+  """Custom action to set multiple args when --gdb or --lldb are set:
+  - Add a DebuggerProbe config.
+  - Increase --timeout-unit to a large value to keep debug session alive for a
+    longer time.
+  """
+
+  def __call__(self,
+               parser: argparse.ArgumentParser,
+               namespace: argparse.Namespace,
+               values: str | Sequence[Any] | None,
+               option_string: Optional[str] = None) -> None:
+    probes: List[ProbeConfig] = getattr(namespace, self.dest, [])
+    probe_settings = {"debugger": "gdb"}
+    if option_string and "lldb" in option_string:
+      probe_settings["debugger"] = "lldb"
+    probes.append(ProbeConfig(DebuggerProbe, probe_settings))
+    if not getattr(namespace, "timeout_unit", None):
+      # Set a very large --timeout-unit to allow for very slow debugging without
+      # causing timeouts (for instance when waiting on a breakpoint).
+      setattr(namespace, "timeout_unit", dt.timedelta.max)
+
+
+class BenchmarkSubcommand(CrossbenchSubcommand):
+
+  def __init__(self, cli: CrossBenchCLI,
+               benchmark_cls: Type[Benchmark]) -> None:
+    self._benchmark_cls = benchmark_cls
+    self._runner_cls: Type[Runner] = Runner
+    self._runner: Runner | None = None
+    super().__init__(cli)
+
+  @property
+  def runner(self) -> Runner:
+    assert self._runner, "No runner"
+    return self._runner
+
+  @override
+  def add_cli_parser(self) -> argparse.ArgumentParser:
+    subparser = self._benchmark_cls.add_cli_parser(
+        self.cli.subparsers, self._benchmark_cls.aliases())
+    assert isinstance(subparser, argparse.ArgumentParser), (
+        f"Benchmark class {self._benchmark_cls}.add_cli_parser did not return "
+        f"an ArgumentParser: {subparser}")
+    self._runner_cls.add_cli_parser(self._benchmark_cls, subparser)
+    self._add_arguments(subparser)
+    self.cli.add_verbosity_argument(subparser)
+    self._add_debugger_arguments(subparser)
+    subparser.add_argument("other_browser_args", nargs="*")
+    return subparser
+
+  def _add_arguments(self, subparser: argparse.ArgumentParser) -> None:
+    runner_group = subparser.add_argument_group("Runner Options", "")
+    runner_group.add_argument(
+        "--cache-dir",
+        type=pth.LocalPath,
+        default=None,
+        help=("Used for caching browser binaries and archives. "
+              "Defaults to binary_cache"))
+
+    cooldown_group = runner_group.add_mutually_exclusive_group()
+    cooldown_group.add_argument(
+        "--cool-down-threshold",
+        type=ThermalStatus.parse,
+        help=("Pause execution when the device reaches this thermal status. "
+              "Execution resumes once the status drops below the threshold. "
+              "Only available on Android."))
+    cooldown_group.add_argument(
+        "--cool-down-time",
+        "--cool-down",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(seconds=2),
+        help=("Wait between repetitions for a fixed amount of time. "
+              f"Format: {DurationParser.help()}"))
+    cooldown_group.add_argument(
+        "--no-cool-down",
+        action="store_const",
+        dest="cool_down_time",
+        const=dt.timedelta(seconds=0),
+        help=("Disable cool-down between runs (might cause CPU throttling), "
+              "equivalent to --cool-down=0."))
+    cooldown_group.add_argument(
+        "--fast",
+        action=EnableFastAction,
+        nargs=0,
+        help=("Switch to a fast run mode "
+              "which might yield unstable performance results. "
+              "Equivalent to --cool-down=0 --no-splash --env-validation=skip."))
+
+    runner_group.add_argument(
+        "--time-unit",
+        type=DurationParser.any_duration,
+        default=dt.timedelta(seconds=1),
+        help=("Absolute duration of 1 time unit in the runner. "
+              "Increase this for slow builds or machines. "
+              f"Format: {DurationParser.help()}"))
+    runner_group.add_argument(
+        "--timeout-unit",
+        type=DurationParser.any_duration,
+        default=dt.timedelta(),
+        help=("Absolute duration of 1 time unit for timeouts in the runner. "
+              "Unlike --time-unit, this does only apply for timeouts, "
+              "as opposed to say initial wait times or sleeps."
+              f"Format: {DurationParser.help()}"))
+    runner_group.add_argument(
+        "--run-timeout",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Sets the same timeout per run on all browsers. "
+              "Runs will be aborted after the given timeout. "
+              f"Format: {DurationParser.help()}"))
+    runner_group.add_argument(
+        "--start-delay",
+        "--startup-delay",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Delay before running the core workload, "
+              "after a story's/workload's setup, "
+              "and after starting the browser."))
+    runner_group.add_argument(
+        "--stop-delay",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Delay after running the core workload, "
+              "before story's/workload's teardown, "
+              "and before quitting the browser."))
+
+    network_group = subparser.add_argument_group("Network Options", "")
+    network_settings_group = network_group.add_mutually_exclusive_group()
+    network_settings_group.add_argument(
+        "--network",
+        type=NetworkConfig.parse,
+        help=("Either an inline network config or an file path to full "
+              "network config hjson file (see --network-config)."))
+    network_settings_group.add_argument(
+        "--network-config",
+        metavar="DIR",
+        type=NetworkConfig.parse_config_path,
+        help=NetworkConfig.help())
+    network_settings_group.add_argument(
+        "--local-file-server",
+        "--local-fileserver",
+        "--file-server",
+        "--fileserver",
+        type=NetworkConfig.parse_local,
+        metavar="DIR",
+        dest="network",
+        help="Start a local http file server at the given directory.")
+    network_settings_group.add_argument(
+        "--wpr",
+        "--web-page-replay",
+        type=NetworkConfig.parse_wpr,
+        metavar="WPR_ARCHIVE",
+        dest="network",
+        help=("Use wpr.archive to replay network requests "
+              "via a local proxy server. "
+              "Archives can be recorded with --probe=wpr. "
+              "WPR_ARCHIVE can be a local file or a gs:// google storage url."))
+
+    env_group = subparser.add_argument_group("Environment Options", "")
+    env_settings_group = env_group.add_mutually_exclusive_group()
+    env_settings_group.add_argument(
+        "--env",
+        type=EnvironmentConfig.parse,
+        help=("Set default runner environment settings. {}"
+              f"Possible values: {', '.join(ENV_CONFIG_PRESETS.keys())}"
+              "or an inline hjson configuration (see --env-config). "
+              "Mutually exclusive with --env-config"))
+    env_settings_group.add_argument(
+        "--env-config",
+        type=EnvironmentConfig.parse_config_path,
+        help=("Path to an env.config.hjson file that specifies detailed "
+              "runner environment settings and requirements. "
+              "See config/env.config.hjson for more details."
+              "Mutually exclusive with --env"))
+
+    env_group.add_argument(
+        "--env-validation",
+        default=ValidationMode.PROMPT,
+        type=ValidationMode,  # type: ignore
+        help=(
+            "Set how runner env is validated (see als --env-config/--env):\n" +
+            ValidationMode.help_text(indent=2)))
+    env_group.add_argument(
+        "--dry-run",
+        action="store_true",
+        default=False,
+        help="Don't run any browsers or probes")
+
+    browser_group = subparser.add_argument_group(
+        "Browser Options", "Any other browser option can be passed "
+        "after the '--' arguments separator.")
+    browser_config_group = browser_group.add_mutually_exclusive_group()
+    browser_config_group.add_argument(
+        "--browser",
+        "-b",
+        type=BrowserConfig.parse_with_range,
+        action="extend",
+        default=[],
+        help=(
+            "Browser binary, defaults to 'chrome-stable'."
+            "Use this to test a simple browser variant. "
+            "Use [chrome, chrome-stable, chrome-dev, chrome-canary, "
+            "safari, safari-tp, "
+            "firefox, firefox-stable, firefox-dev, firefox-nightly, "
+            "edge, edge-stable, edge-beta, edge-dev, edge-canary] "
+            "for system default browsers or a full path. \n"
+            "* Use --browser=chrome-M107 to download the latest version for a "
+            "specific milestone\n"
+            "* Use ... to test milestone ranges --browser=chr-M100...M125"
+            "* Use --browser=chrome-100.0.4896.168 to download a specific "
+            "chrome version (macOS and linux for googlers and chrome only). \n"
+            "* Use --browser=path/to/archive.dmg on macOS or "
+            "--browser=path/to/archive.rpm on linux "
+            "for locally cached versions (chrome only).\n"
+            "* Use --browser=\"${ADB_SERIAL}:chrome\" "
+            "(e.g. --browser='0a388e93:chrome') for specific "
+            "android devices or --browser='adb:chrome' if only once device is "
+            "attached.\n"
+            "Repeat for adding multiple browsers. "
+            "The browser result dir's name is "
+            "'${BROWSER}_${PLATFORM}_${INDEX}' "
+            "$INDEX corresponds to the order on the command line."
+            "Cannot be used together with --browser-config"))
+    browser_config_group.add_argument(
+        "--browser-config",
+        type=PathParser.hjson_file_path,
+        help=("Browser configuration.json file. "
+              "Use this to run multiple browsers and/or multiple "
+              "flag configurations. "
+              "See config/doc/browser.config.hjson on how to set up a complex "
+              "configuration file. "
+              "Cannot be used together with --browser."))
+    browser_group.add_argument(
+        "--driver-path",
+        type=PathParser.file_path,
+        help=("Use the same custom driver path for all specified browsers. "
+              "Version mismatches might cause crashes."))
+    browser_group.add_argument(
+        "--remote-driver-path",
+        type=PathParser.any_path,
+        help=("Use the same custom driver path for all specified remote"
+              " browsers. Version mismatches might cause crashes."))
+    browser_group.add_argument(
+        "--config",
+        type=PathParser.hjson_file_path,
+        help=("Specify a common config for --probe-config, --browser-config, "
+              "--network-config and --env-config."))
+    browser_group.add_argument(
+        "--secrets",
+        dest="secrets",
+        type=Secrets.parse,
+        default=Secrets(),
+        help="Path to file containing login secrets")
+
+    browser_group.add_argument(
+        "--wipe-system-user-data",
+        default=False,
+        action="store_true",
+        help="Clear user data at the beginning of the test "
+        "(Android-only, be careful using it).")
+    browser_group.add_argument(
+        "--browser-cache-dir",
+        "--browser-cache",
+        "--user-data-dir",
+        type=pth.AnyPath,
+        help="Set an explicit browser cache dir")
+
+    browser_cache_group = subparser.add_argument_group(
+        "Browser Options: Caches",
+        "By default tmp caches are auto-created and cleared at startup.")
+    cache_options = browser_cache_group.add_mutually_exclusive_group()
+    cache_options.add_argument(
+        "--keep-browser-cache",
+        "--no-clear-browser-cache",
+        dest="clear_browser_cache_dir",
+        action="store_false",
+        default=None,
+        help=("Do not clear the browser cache dir after every run. "
+              "This will affect performance and leak user data across runs."))
+    cache_options.add_argument(
+        "--clear-browser-cache",
+        "--clear-browser-cache-dir",
+        dest="clear_browser_cache_dir",
+        action="store_true",
+        help=("Force clear browser cache dir (default). "
+              "Use this flag to override browser config values"))
+
+    browser_group.add_argument(
+        "--http-request-timeout",
+        type=DurationParser.positive_or_zero_duration,
+        default=dt.timedelta(),
+        help=("Set the timeout of http request. "
+              f"Format: {DurationParser.help()}. "
+              "When not specified, there will be no timeout."))
+
+    splashscreen_group = browser_group.add_mutually_exclusive_group()
+    splashscreen_group.add_argument(
+        "--splash-screen",
+        "--splashscreen",
+        "--splash",
+        type=SplashScreen.parse,
+        default=SplashScreen.DETAILED,
+        help=("Set the splashscreen shown before each run. "
+              "Choices: 'default', 'none', 'minimal', 'detailed,' or "
+              "a path or a URL."))
+    splashscreen_group.add_argument(
+        "--no-splash",
+        "--nosplash",
+        dest="splash_screen",
+        const=SplashScreen.NONE,
+        action="store_const",
+        help="Shortcut for --splash-screen=none")
+
+    viewport_group = browser_group.add_mutually_exclusive_group()
+    # pytype: disable=missing-parameter
+    viewport_group.add_argument(
+        "--viewport",
+        default=Viewport.DEFAULT,
+        type=Viewport.parse,
+        help=("Set the browser window position."
+              "Options: size and position, "
+              f"{', '.join(str(e) for e in ViewportMode)}. "
+              "Examples: --viewport=1550x300 --viewport=fullscreen. "
+              f"Default: {Viewport.DEFAULT}"))
+    # pytype: enable=missing-parameter
+    viewport_group.add_argument(
+        "--headless",
+        dest="viewport",
+        const=Viewport.HEADLESS,
+        action="store_const",
+        help=("Start the browser in headless if supported. "
+              "Equivalent to --viewport=headless."))
+
+    chrome_args = subparser.add_argument_group(
+        "Browsers Options: Chrome/Chromium",
+        "For convenience these arguments are directly are forwarded "
+        "directly to chrome. ")
+    chrome_args.add_argument(
+        "--js-flags", dest="js_flags", action="append", default=[])
+
+    doc_str = "See chrome's base/feature_list.h source file for more details"
+    chrome_args.add_argument(
+        "--enable-features",
+        help="Comma-separated list of enabled chrome features. " + doc_str,
+        default="")
+    chrome_args.add_argument(
+        "--disable-features",
+        help="Command-separated list of disabled chrome features. " + doc_str,
+        default="")
+
+    field_trial_group = chrome_args.add_mutually_exclusive_group()
+    field_trial_group.add_argument(
+        "--enable-field-trial-config",
+        "--enable-field-trials",
+        default=None,
+        action="store_true",
+        help=("Use chrome's field-trial configs, "
+              "disabled by default by crossbench"))
+    field_trial_group.add_argument(
+        "--disable-field-trial-config",
+        "--disable-field-trials",
+        dest="enable_field_trial_config",
+        action="store_false",
+        help=("Explicitly disable field-trial configs."
+              "Off by default on official builds, "
+              "and disabled by default by crossbench."))
+
+    probe_group = subparser.add_argument_group("Probe Options", "")
+    probe_group.add_argument(
+        "--probe",
+        action="append",
+        type=ProbeConfig.parse,
+        default=[],
+        help=(
+            "Enable general purpose probes to measure data on all cb.stories. "
+            "This argument can be specified multiple times to add more probes. "
+            "Use inline hjson (e.g. --probe=\"$NAME{$CONFIG}\") "
+            "to configure probes. "
+            "Individual probe configs can be specified in files as well: "
+            "--probe='path/to/config.hjson'."
+            "Use 'describe probes' or 'describe probe $NAME' for probe "
+            "configuration details."
+            f"\n\nChoices: {', '.join(PROBE_LOOKUP.keys())}"))
+    probe_group.add_argument(
+        "--probe-config",
+        type=PathParser.hjson_file_path,
+        default=self._benchmark_cls.default_probe_config_path(),
+        help=("Browser configuration.json file. "
+              "Use this config file to specify more complex Probe settings."
+              "See config/doc/probe.config.hjson on how to set up a complex "
+              "configuration file."))
+
+  def _add_debugger_arguments(self, subparser: argparse.ArgumentParser) -> None:
+    debug_group = subparser.add_argument_group("Verbosity / Debugging Options")
+    debug_group.add_argument(
+        "--driver-logging",
+        "--verbose-driver",
+        action="store_true",
+        default=False,
+        help=("Enable verbose webdriver logging. "
+              "Disabled by default, automatically enable with --debug"))
+    debugger_group = debug_group.add_mutually_exclusive_group()
+    debugger_group.add_argument(
+        "--gdb",
+        action=AppendDebuggerProbeAction,
+        nargs=0,
+        dest="probe",
+        help=("Launch chrome with gdb or lldb attached to all processes. "
+              " See 'describe probe debugger' for more options."))
+    debugger_group.add_argument(
+        "--lldb",
+        action=AppendDebuggerProbeAction,
+        nargs=0,
+        dest="probe",
+        help=("Launch chrome with lldb attached to all processes."
+              " See 'describe probe debugger' for more options."))
+
+  @override
+  def run(self, args: argparse.Namespace) -> None:
+    benchmark: Benchmark | None = None
+    if args.cache_dir:
+      plt.PLATFORM.set_cache_dir(args.cache_dir)
+    self._helper(args)
+    try:
+      self._process_args(args)
+      benchmark = self._get_benchmark(args)
+      with plt.PLATFORM.TemporaryDirectory(prefix="crossbench") as tmp_dirname:
+        if args.dry_run:
+          args.out_dir = pth.LocalPath(tmp_dirname) / "results"
+        args.browser = self._get_browsers(args)
+        probes: Sequence[Probe] = self._get_probes(args)
+        env_config: EnvironmentConfig = self._get_env_config(args)
+        env_validation_mode: ValidationMode = self._get_env_validation_mode(
+            args)
+        timing: Timing = self._get_timing(args)
+        self._runner = self._get_runner(args, benchmark, env_config,
+                                        env_validation_mode, timing)
+
+        # We prevent running multiple stories in repetition OR if multiple
+        # browsers are open when 'power' probes are used since it might distort
+        # the data.
+        if len(args.browser) > 1 or args.repetitions > 1:
+          probe_names = [probe.name for probe in probes if probe.BATTERY_ONLY]
+          if probe_names:
+            names_str = ",".join(probe_names)
+            raise argparse.ArgumentTypeError(
+                f"Cannot use [{names_str}] probe(s) "
+                "with repeat > 1 and/or with multiple browsers. We need to "
+                "always start at the same battery level, and by running "
+                "stories on multiple browsers or multiples time will create "
+                "erroneous data.")
+
+        for probe in probes:
+          self.runner.attach_probe(probe, matching_browser_only=True)
+
+        self._run_benchmark(args, self.runner)
+    except KeyboardInterrupt:
+      sys.exit(2)
+    except LateArgumentError as e:
+      if args.throw:
+        raise
+      self.cli.handle_late_argument_error(e)
+    except Exception as e:  # pylint: disable=broad-except
+      if args.throw:
+        raise
+      self._log_benchmark_subcommand_failure(benchmark, self._runner, e)
+      sys.exit(3)
+
+  def _helper(self, args: argparse.Namespace) -> None:
+    """Handle common subcommand mistakes that are not easily implementable
+    with argparse.
+    run      => just run the benchmark
+    help     => use --help
+    describe => use describe benchmark NAME
+    """
+    if not args.other_browser_args:
+      return
+    maybe_command = args.other_browser_args[0]
+    if maybe_command == "run":
+      args.other_browser_args.pop()
+      return
+    if maybe_command == "help":
+      self._parser.print_help()
+      sys.exit(0)
+    if maybe_command == "describe":
+      logging.warning("See `describe benchmark %s` for more options",
+                      self._benchmark_cls.NAME)
+      # Patch args to simulate: describe benchmark BENCHMARK_NAME
+      args.category = "benchmarks"
+      args.filter = self._benchmark_cls.NAME
+      args.json = False
+      self.cli.describe_subcommand.run(args)
+      sys.exit(0)
+
+  def _process_args(self, args) -> None:
+    if args.config:
+      self._process_config_args(args)
+    else:
+      # We keep separate *_config args so we can throw in case they conflict
+      # with --config. Since we don't use argparse's dest, we have to manually
+      # copy the args.*_config back.
+      self._process_network_args(args)
+
+  def _process_network_args(self, args) -> None:
+    # The order of preference of flags is as follows:
+    # Explicitly specified network config > explicitly specified network >
+    # benchmark-specific network config > default network.
+    if network_config := args.network_config:
+      args.network = network_config
+    elif args.network:
+      pass
+    elif network_config := self._benchmark_cls.default_network_config_path():
+      args.network = network_config
+    else:
+      args.network = NetworkConfig.default()
+
+  def _process_env_args(self, args) -> None:
+    if network_config := args.env_config:
+      args.env = network_config
+    elif args.env:
+      pass
+    else:
+      args.env = EnvironmentConfig.default()
+
+  def _process_config_args(self, args) -> None:
+    if args.env_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --env-config")
+    if args.network_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --network-config")
+    if args.browser_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --browser-config")
+    if args.probe_config:
+      raise argparse.ArgumentTypeError(
+          "--config cannot be used together with --probe-config")
+
+    config_file = args.config
+    config_data = ObjectParser.hjson_file(config_file)
+    found_any_config = False
+
+    if env_config_data := config_data.get("env"):
+      args.env = EnvironmentConfig.parse(env_config_data)
+      found_any_config = True
+    else:
+      logging.warning("Skipping env config: no 'env' property in %s",
+                      config_file)
+    if not args.env:
+      args.env = EnvironmentConfig.default()
+
+    if network_config_data := config_data.get("network"):
+      # TODO: migrate all --config helper to this format
+      args.network = NetworkConfig.parse(network_config_data)
+      found_any_config = True
+    else:
+      logging.warning("Skipping network config: no 'network' property in %s",
+                      config_file)
+    if not args.network:
+      args.network = NetworkConfig.default()
+
+    if config_data.get("browsers"):
+      args.browser_config = config_file
+      found_any_config = True
+    else:
+      logging.warning("Skipping browsers config: No 'browsers' property in %s",
+                      config_file)
+
+    if config_data.get("probes"):
+      args.probe_config = config_file
+      found_any_config = True
+    else:
+      logging.warning("Skipping probes config: no 'probes' property in %s",
+                      config_file)
+
+    if not found_any_config:
+      raise argparse.ArgumentTypeError(
+          f"--config: config file has no config properties {config_file}")
+
+  def _log_benchmark_subcommand_failure(self, benchmark: Optional[Benchmark],
+                                        runner: Optional[Runner],
+                                        e: Exception) -> None:
+    logging.debug(e)
+    logging.error("")
+    logging.error("#" * 80)
+    message: str = "SUBCOMMAND"
+    if benchmark:
+      message = f"{benchmark.NAME.upper()} BENCHMARK"
+    logging.error("%s FAILED WITH %s:", message, e.__class__.__name__)
+    logging.error("-" * 80)
+    self._log_benchmark_subcommand_exception(e)
+    logging.error("-" * 80)
+    if runner and runner.runs:
+      self._log_runner_debug_hints(runner)
+    else:
+      logging.error("- Check %s.json detailed backtraces", ErrorsProbe.NAME)
+    logging.error(
+        "- Use --debug for very verbose output (equivalent to --throw -vvv)")
+    logging.error("#" * 80)
+    sys.exit(3)
+
+  def _log_benchmark_subcommand_exception(self, e: Exception) -> None:
+    message = str(e)
+    if message:
+      logging.error(message)
+      return
+    if isinstance(e, AssertionError):
+      self.cli.log_assertion_error_statement(e)
+
+  def _run_benchmark(self, args: argparse.Namespace, runner: Runner) -> None:
+    try:
+      runner.run(is_dry_run=args.dry_run)
+      logging.info("")
+      self._log_results(args, runner, is_success=runner.is_success)
+    except:  # pylint: disable=broad-except
+      self._log_results(args, runner, is_success=False)
+      raise
+    finally:
+      self._update_symlinks(args, runner)
+
+  def _update_symlinks(self, args: argparse.Namespace, runner: Runner) -> None:
+    if not args.create_symlinks:
+      logging.debug("Symlink disabled by command line option")
+      return
+    if not args.out_dir and runner.out_dir.exists():
+      self._update_default_results_symlinks(runner)
+      self._create_runs_results_symlinks(runner)
+
+  def _update_default_results_symlinks(self, runner: Runner) -> None:
+    assert runner.create_symlinks
+    results_root = runner.out_dir.parent
+    latest_link = results_root / "latest"
+    if latest_link.is_symlink():
+      latest_link.unlink()
+    if not latest_link.exists():
+      latest_link.symlink_to(
+          runner.out_dir.relative_to(results_root), target_is_directory=True)
+    else:
+      logging.error("Could not create %s", latest_link)
+
+  def _create_runs_results_symlinks(self, runner: Runner) -> None:
+    assert runner.create_symlinks
+    results_root = runner.out_dir.parent
+    runs: Tuple[Run, ...] = runner.all_runs
+    if not runs:
+      logging.debug("Skip creating result symlinks in '%s': no runs produced.",
+                    results_root)
+      return
+    out_dir = runner.out_dir
+    first_run_dir = out_dir / "first_run"
+    last_run_dir = out_dir / "last_run"
+    if first_run_dir.exists():
+      logging.error("Cannot create first_run symlink: %s", first_run_dir)
+    else:
+      first_run_dir.symlink_to(runs[0].out_dir.relative_to(out_dir))
+    if last_run_dir.exists():
+      logging.error("Cannot create last_run symlink: %s", last_run_dir)
+    else:
+      last_run_dir.symlink_to(runs[-1].out_dir.relative_to(out_dir))
+
+    runs_dir = out_dir / "runs"
+    runs_dir.mkdir()
+    for run in runs:
+      if not run.out_dir.exists():
+        continue
+      relative = pth.LocalPath("..") / run.out_dir.relative_to(out_dir)
+      (runs_dir / str(run.index)).symlink_to(relative)
+
+    sessions_dir = out_dir / "sessions"
+    sessions_dir.mkdir()
+    for session in set(run.browser_session for run in runs):
+      relative = pth.LocalPath("..") / session.path.relative_to(out_dir)
+      (sessions_dir / str(session.index)).symlink_to(relative)
+
+  def _log_results(self, args: argparse.Namespace, runner: Runner,
+                   is_success: bool) -> None:
+    logging.info("=" * 80)
+    if is_success:
+      logging.critical("RESULTS: %s", runner.out_dir)
+    else:
+      logging.critical("RESULTS (maybe incomplete/broken): %s", runner.out_dir)
+    logging.info("=" * 80)
+    self._log_run_annotations(runner)
+    if not runner.has_browser_group:
+      logging.debug("No browser group in %s", runner)
+      return
+    browser_group = runner.browser_group
+    for probe in runner.probes:
+      try:
+        probe.log_browsers_result(browser_group)
+      except Exception as e:  # pylint: disable=broad-except
+        if args.throw:
+          raise
+        logging.warning("log_result_summary failed: %s", e)
+
+  def _log_run_annotations(self, runner: Runner) -> None:
+    all_annotations = set(
+        itertools.chain.from_iterable(run.annotations for run in runner.runs))
+    RunAnnotation.log_all(all_annotations)
+
+  def _get_browsers(self, args: argparse.Namespace) -> Sequence[Browser]:
+    # TODO: move browser instance create to separate method.
+    # TODO: move --browser-config parsing to BrowserVariantsConfig
+    args.browser_config = BrowserVariantsConfig.from_cli_args(args)
+    browsers = args.browser_config.browsers
+    return browsers
+
+  def _get_probes(self, args: argparse.Namespace) -> Sequence[Probe]:
+    # TODO: move probe creation to separate method
+    # TODO: move --probe-config parsing to ProbeListConfig
+    args.probe_config = ProbeListConfig.from_cli_args(args)
+    return args.probe_config.probes
+
+  def _get_benchmark(self, args: argparse.Namespace) -> Benchmark:
+    benchmark_cls: Type[Benchmark] = self._get_benchmark_cls(args)
+    assert (issubclass(benchmark_cls, Benchmark)), (
+        f"benchmark_cls={benchmark_cls} is not subclass of Runner")
+    with exception.annotate_argparsing(
+        f"Parsing {benchmark_cls.NAME} arguments"):
+      return benchmark_cls.from_cli_args(args)
+    raise exception.UnreachableError()
+
+  def _get_benchmark_cls(self, args: argparse.Namespace) -> Type[Benchmark]:
+    del args
+    return self._benchmark_cls
+
+  def _get_env_validation_mode(self,
+                               args: argparse.Namespace) -> ValidationMode:
+    return args.env_validation
+
+  def _get_env_config(self, args: argparse.Namespace) -> EnvironmentConfig:
+    return args.env
+
+  def _get_timing(self, args: argparse.Namespace) -> Timing:
+    timeout_unit: dt.timedelta = args.timeout_unit or args.time_unit
+    return Timing(args.cool_down_time, args.time_unit, timeout_unit,
+                  args.run_timeout, args.start_delay, args.stop_delay)
+
+  def _get_runner(self, args: argparse.Namespace, benchmark: Benchmark,
+                  env_config: EnvironmentConfig,
+                  env_validation_mode: ValidationMode,
+                  timing: Timing) -> Runner:
+    runner_kwargs = self._runner_cls.kwargs_from_cli(args)
+    return self._runner_cls(
+        benchmark=benchmark,
+        env_config=env_config,
+        env_validation_mode=env_validation_mode,
+        timing=timing,
+        **runner_kwargs)
+
+  def _log_runner_debug_hints(self, runner: Runner) -> None:
+    failed_runs = [run for run in runner.runs if not run.is_success]
+    if not failed_runs:
+      return
+    candidates: List[pth.LocalPath] = [
+        *runner.out_dir.glob(f"{ErrorsProbe.NAME}*"),
+    ]
+    for failed_run in failed_runs:
+      candidates.extend(failed_run.out_dir.glob(f"{ErrorsProbe.NAME}*"))
+      candidates.extend(failed_run.out_dir.glob("*.log"))
+
+    failed_run = failed_runs[0]
+    logging.error("- Check log outputs (example 1 of %d failed runs):",
+                  len(failed_runs))
+    limit = 3
+    for log_file in candidates[:limit]:
+      try:
+        log_file = log_file.relative_to(pth.LocalPath.cwd())
+      except Exception as e:  # pylint: disable=broad-except
+        logging.debug("Could not create relative log_file: %s", e)
+      logging.error("  - %s", log_file)
+    if (pending := len(candidates) - limit) > 0:
+      logging.error("  - ... and %d more interesting %s.json or *.log files",
+                    pending, ErrorsProbe.NAME)
diff --git a/crossbench/cli/subcommand/describe.py b/crossbench/cli/subcommand/describe.py
new file mode 100644
index 00000000..c1cd706c
--- /dev/null
+++ b/crossbench/cli/subcommand/describe.py
@@ -0,0 +1,125 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+from argparse import Namespace
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple
+
+import tabulate as tbl
+from typing_extensions import override
+
+from crossbench.cli.parser import CrossBenchArgumentParser
+from crossbench.cli.subcommand.base import CrossbenchSubcommand
+from crossbench.probes.all import GENERAL_PURPOSE_PROBES
+
+if TYPE_CHECKING:
+  import argparse
+
+
+class DescribeSubcommand(CrossbenchSubcommand):
+
+  def add_cli_parser(self) -> argparse.ArgumentParser:
+    describe_parser = self.cli.subparsers.add_parser(
+        "describe", aliases=["desc"], help="Print all benchmarks and stories")
+    assert isinstance(describe_parser, CrossBenchArgumentParser)
+    describe_parser.add_argument(
+        "category",
+        nargs="?",
+        choices=["all", "benchmark", "benchmarks", "probe", "probes"],
+        default="all",
+        help="Limit output to the given category, defaults to 'all'")
+    describe_parser.add_argument(
+        "filter",
+        nargs="?",
+        help=("Only display the given item from the provided category. "
+              "By default all items are displayed. "
+              "Example: describe probes v8.log"))
+    describe_parser.add_argument(
+        "--json",
+        default=False,
+        action="store_true",
+        help="Print the data as json data")
+    self.cli.add_verbosity_argument(describe_parser)
+    return describe_parser
+
+  @override
+  def run(self, args: Namespace) -> None:
+    self.describe(args.filter, args.category, args.json)
+
+  def describe(self,
+               search_str: Optional[str] = None,
+               category: Optional[str] = "all",
+               print_json: bool = False) -> None:
+    benchmarks_data: Dict[str, Any] = {}
+    for benchmark_cls in self.cli.BENCHMARKS:
+      aliases: Tuple[str, ...] = benchmark_cls.aliases()
+      if search_str:
+        if benchmark_cls.NAME != search_str and search_str not in aliases:
+          continue
+      benchmark_info = benchmark_cls.describe()
+      benchmark_info["help"] = f"See `{benchmark_cls.NAME} --help`"
+      benchmarks_data[benchmark_cls.NAME] = benchmark_info
+    data: Dict[str, Dict[str, Any]] = {
+        "benchmarks": benchmarks_data,
+        "probes": {
+            str(probe_cls.NAME): probe_cls.help_text()
+            for probe_cls in GENERAL_PURPOSE_PROBES
+            if not search_str or probe_cls.NAME == search_str
+        }
+    }
+    if print_json:
+      if category in ("probe", "probes"):
+        data = data["probes"]
+        if not data:
+          self.error(f"No matching probe found: '{search_str}'")
+      elif category in ("benchmark", "benchmarks"):
+        data = data["benchmarks"]
+        if not data:
+          self.error(f"No matching benchmark found: '{search_str}'")
+      else:
+        assert category == "all"
+        if not data["benchmarks"] and not data["probes"]:
+          self.error(f"No matching benchmarks or probes found: '{search_str}'")
+      print(json.dumps(data, indent=2))
+      return
+    # Create tabular format
+    printed_any = False
+    if category in ("all", "benchmark", "benchmarks"):
+      table: List[List[Optional[str]]] = [["Benchmark", "Property", "Value"]]
+      for benchmark_name, values in data["benchmarks"].items():
+        table.append([
+            benchmark_name,
+        ])
+        for name, value in values.items():
+          if isinstance(value, (tuple, list)):
+            value = "\n".join(value)
+          elif isinstance(value, dict):
+            if not value.items():
+              value = "[]"
+            else:
+              kwargs = {"maxcolwidths": 60}
+              value = tbl.tabulate(value.items(), tablefmt="plain", **kwargs)
+          table.append([None, name, value])
+      if len(table) <= 1:
+        if category != "all":
+          self.error(f"No matching benchmark found: '{search_str}'")
+      else:
+        printed_any = True
+        print(tbl.tabulate(table, tablefmt="grid"))
+
+    if category in ("all", "probe", "probes"):
+      table = [["Probe", "Help"]]
+      for probe_name, probe_desc in data["probes"].items():
+        table.append([probe_name, probe_desc])
+      if len(table) <= 1:
+        if category != "all":
+          self.error(f"No matching probe found: '{search_str}'")
+      else:
+        printed_any = True
+        print(tbl.tabulate(table, tablefmt="grid"))
+
+    if not printed_any:
+      self.error(f"No matching benchmarks or probes found: '{search_str}'")
diff --git a/crossbench/cli/subcommand/devtools_recorder_proxy/default.py b/crossbench/cli/subcommand/devtools_recorder_proxy/default.py
index ba6c4285..3778f234 100644
--- a/crossbench/cli/subcommand/devtools_recorder_proxy/default.py
+++ b/crossbench/cli/subcommand/devtools_recorder_proxy/default.py
@@ -16,14 +16,15 @@ import sys
 import tempfile
 from typing import TYPE_CHECKING, Any, Coroutine, Dict, Optional, Tuple
 
-import websockets
-from websockets.server import WebSocketServerProtocol
+from websockets import server as websockets
 
-from crossbench import compat, helper
 from crossbench import path as pth
+from crossbench import plt
 from crossbench.helper.state import BaseState, StateMachine
 
 if TYPE_CHECKING:
+  from asyncio.subprocess import Process
+
   from crossbench.plt.base import ListCmdArgs
   from crossbench.types import JsonDict
 
@@ -38,7 +39,7 @@ class State(BaseState):
 
 
 @enum.unique
-class Response(compat.StrEnum):
+class Response(enum.StrEnum):
   STATUS = "status"
   OUTPUT = "output"
 
@@ -51,13 +52,12 @@ class CrossbenchDevToolsRecorderProxy:
   DEFAULT_PORT = 44645
 
   @classmethod
-  def add_subcommand(cls, subparsers) -> argparse.ArgumentParser:
+  def add_cli_parser(cls, subparsers) -> argparse.ArgumentParser:
     parser = subparsers.add_parser(
         "devtools-recorder-proxy",
         aliases=["devtools"],
         help=("Starts a local server to communicate with the "
               "DevTools Recorder extension."))
-    parser.set_defaults(subcommand_fn=cls._subcommand)
     parser.add_argument(
         "--disable-token-authentication",
         dest="use_auth_token",
@@ -68,12 +68,12 @@ class CrossbenchDevToolsRecorderProxy:
     return parser
 
   @classmethod
-  def _subcommand(cls, args: argparse.Namespace) -> None:
+  def run_subcommand(cls, args: argparse.Namespace) -> None:
     instance: CrossbenchDevToolsRecorderProxy = cls(
         use_auth_token=args.use_auth_token)
     instance.run()
 
-  _websocket: WebSocketServerProtocol
+  _websocket: websockets.WebSocketServerProtocol
 
   def __init__(self, use_auth_token: bool = True) -> None:
     self._token: str = secrets.token_hex(16)
@@ -81,8 +81,8 @@ class CrossbenchDevToolsRecorderProxy:
     self._print_cmd_output: bool = False
     self._port: int = self.DEFAULT_PORT
     self._state = StateMachine(State.CONNECTED)
-    self._crossbench_task: Optional[asyncio.Task] = None
-    self._crossbench_process = None
+    self._crossbench_task: asyncio.Task | None = None
+    self._crossbench_process: Process | None = None
     self._tmp_json = pth.LocalPath(
         tempfile.mkdtemp("crossbench_proxy")) / "devtools_recorder.json"
 
@@ -96,7 +96,7 @@ class CrossbenchDevToolsRecorderProxy:
       logging.exception(e)
       serve = websockets.serve(self.handler, "localhost")
     async with serve as server:
-      self._port = server.sockets[0].getsockname()[1]
+      self._port = list(server.sockets)[0].getsockname()[1]
       logging.info("#" * 80)
       logging.info("#" * 80)
       logging.info("# Crossbench DevTools Recorder Replay Server Started")
@@ -112,7 +112,8 @@ class CrossbenchDevToolsRecorderProxy:
       logging.info("#" * 80)
       await asyncio.Future()  # run forever
 
-  async def handler(self, websocket: WebSocketServerProtocol) -> None:
+  async def handler(self,
+                    websocket: websockets.WebSocketServerProtocol) -> None:
     self._websocket = websocket
     async for message in websocket:
       await self._send_message(self._handle_message(message))
@@ -142,7 +143,8 @@ class CrossbenchDevToolsRecorderProxy:
     logging.debug("SEND Response: %s", response_json)
     await self._websocket.send(response_json)
 
-  async def _handle_message(self, message) -> Optional[Tuple[Response, Any]]:
+  async def _handle_message(
+      self, message: bytearray | bytes | str) -> Optional[Tuple[Response, Any]]:
     logging.debug("RECEIVE Message: %s", message)
     try:
       payload: Dict[str, Any] = json.loads(message)
@@ -166,9 +168,9 @@ class CrossbenchDevToolsRecorderProxy:
     return None
 
   async def _stop_command(self) -> Tuple[Response, str]:
-    if self._crossbench_process:
+    if process := self._crossbench_process:
       logging.info("# CROSSBENCH COMMAND: KILL")
-      helper.wait_and_kill(self._crossbench_process)
+      plt.PLATFORM.terminate_gracefully(process)
     self._state.transition(State.CONNECTED, State.CONNECTED, to=State.CONNECTED)
     return await self._status_command()
 
diff --git a/crossbench/cli/subcommand/devtools_recorder_proxy/empty.py b/crossbench/cli/subcommand/devtools_recorder_proxy/empty.py
index 421c5903..2d46d4b0 100644
--- a/crossbench/cli/subcommand/devtools_recorder_proxy/empty.py
+++ b/crossbench/cli/subcommand/devtools_recorder_proxy/empty.py
@@ -12,8 +12,12 @@ class CrossbenchDevToolsRecorderProxy:
   supported."""
 
   @classmethod
-  def add_subcommand(cls, subparsers) -> argparse.ArgumentParser:
+  def add_cli_parser(cls, subparsers) -> argparse.ArgumentParser:
     return subparsers.add_parser(
         "devtools-recorder-proxy",
         aliases=["devtools"],
         help="Unsupported operation")
+
+  @classmethod
+  def run_subcommand(cls, args: argparse.Namespace) -> None:
+    raise NotImplementedError()
diff --git a/crossbench/cli/subcommand/devtools_recorder_proxy/subcommand.py b/crossbench/cli/subcommand/devtools_recorder_proxy/subcommand.py
new file mode 100644
index 00000000..067e2286
--- /dev/null
+++ b/crossbench/cli/subcommand/devtools_recorder_proxy/subcommand.py
@@ -0,0 +1,28 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+from typing_extensions import override
+
+from crossbench.cli.subcommand.base import CrossbenchSubcommand
+from crossbench.cli.subcommand.devtools_recorder_proxy.default import \
+    CrossbenchDevToolsRecorderProxy
+
+if TYPE_CHECKING:
+  import argparse
+
+
+class DevtoolsRecorderProxySubcommand(CrossbenchSubcommand):
+
+  @override
+  def add_cli_parser(self) -> argparse.ArgumentParser:
+    parser = CrossbenchDevToolsRecorderProxy.add_cli_parser(self.cli.subparsers)
+    return parser
+
+  @override
+  def run(self, args: argparse.Namespace) -> None:
+    CrossbenchDevToolsRecorderProxy.run_subcommand(args)
diff --git a/crossbench/cli/subcommand/help.py b/crossbench/cli/subcommand/help.py
new file mode 100644
index 00000000..1b8b5983
--- /dev/null
+++ b/crossbench/cli/subcommand/help.py
@@ -0,0 +1,39 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import sys
+from typing import TYPE_CHECKING
+
+from typing_extensions import override
+
+from crossbench.cli.subcommand.base import CrossbenchSubcommand
+
+if TYPE_CHECKING:
+  import argparse
+
+
+class HelpSubcommand(CrossbenchSubcommand):
+
+  @override
+  def add_cli_parser(self) -> argparse.ArgumentParser:
+    # Just for completeness we want to support "--help" and "help"
+    help_parser = self.cli.subparsers.add_parser(
+        "help",
+        help=("Print the top-level by default, same as --help. "
+              "Use `help $PROBE`, or `help $BENCHMARK` to print more details."))
+    help_parser.add_argument(
+        "probe_or_benchmark",
+        nargs="?",
+        help="Use a benchmark or probe name to display more details.")
+    return help_parser
+
+  @override
+  def run(self, args: argparse.Namespace) -> None:
+    if search_str := args.probe_or_benchmark:
+      self.cli.describe_subcommand.describe(search_str)
+    else:
+      self.cli.parser.print_help()
+    sys.exit(0)
diff --git a/crossbench/cli/subcommand/version.py b/crossbench/cli/subcommand/version.py
new file mode 100644
index 00000000..014f869a
--- /dev/null
+++ b/crossbench/cli/subcommand/version.py
@@ -0,0 +1,31 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import sys
+from typing import TYPE_CHECKING
+
+from typing_extensions import override
+
+from crossbench import __version__
+from crossbench.cli.subcommand.base import CrossbenchSubcommand
+
+if TYPE_CHECKING:
+  import argparse
+
+
+class VersionSubcommand(CrossbenchSubcommand):
+
+  @override
+  def add_cli_parser(self) -> argparse.ArgumentParser:
+    version_parser = self.cli.subparsers.add_parser(
+        "version",
+        help="Show program's version number and exit, same as --version")
+    return version_parser
+
+  @override
+  def run(self, args: argparse.Namespace) -> None:
+    print(f"{sys.argv[0]} {__version__}")
+    sys.exit(0)
diff --git a/crossbench/cli/ui.py b/crossbench/cli/ui.py
index b3ecc6bc..2d44a39e 100644
--- a/crossbench/cli/ui.py
+++ b/crossbench/cli/ui.py
@@ -2,15 +2,19 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+from __future__ import annotations
+
 import contextlib
 import datetime as dt
 import logging
 import sys
-from typing import Iterator
+import threading
+from typing import TYPE_CHECKING, Iterator, Optional, Tuple, Type
 
 import colorama
 
-from crossbench import helper
+if TYPE_CHECKING:
+  from types import TracebackType
 
 colorama.init()
 
@@ -39,10 +43,14 @@ class ColoredLogFormatter(logging.Formatter):
     formatter = logging.Formatter(log_fmt)
     return formatter.format(record)
 
-  def formatException(self, ei) -> str:
+  def formatException(
+      self,
+      ei: Tuple[Type[BaseException], BaseException, Optional[TracebackType]]
+      | Tuple[None, ...]
+  ) -> str:
     return ""
 
-  def formatStack(self, stack_info) -> str:
+  def formatStack(self, stack_info: str) -> str:
     return ""
 
 
@@ -55,5 +63,18 @@ def timer(msg: str = "Elapsed Time") -> Iterator[None]:
     indent = colorama.Cursor.FORWARD() * 3
     sys.stdout.write(f"{indent}{msg}: {delta}\r")
 
-  with helper.RepeatTimer(interval=0.25, function=print_timer):
+  with RepeatTimer(interval=0.25, function=print_timer):
     yield
+
+
+class RepeatTimer(threading.Timer):
+
+  def run(self) -> None:
+    while not self.finished.wait(self.interval):
+      self.function(*self.args, **self.kwargs)
+
+  def __enter__(self, *args, **kwargs) -> None:
+    self.start()
+
+  def __exit__(self, *args, **kwargs) -> None:
+    self.cancel()
diff --git a/crossbench/compat.py b/crossbench/compat.py
deleted file mode 100644
index 25fb4d32..00000000
--- a/crossbench/compat.py
+++ /dev/null
@@ -1,80 +0,0 @@
-# Copyright 2023 The Chromium Authors
-# Use of this source code is governed by a BSD-style license that can be
-# found in the LICENSE file.
-""" A collection of helpers that rely on non-crossbench code."""
-
-from __future__ import annotations
-
-import enum
-import os
-import sys
-import textwrap
-from typing import List, NamedTuple, Optional, Tuple, Type, TypeVar, cast
-
-import tabulate
-
-from crossbench import path as pth
-
-if sys.version_info >= (3, 11):
-  from enum import StrEnum  # pylint: disable=unused-import
-else:
-
-  class StrEnum(str, enum.Enum):
-
-    def __str__(self) -> str:
-      return str(self.value)
-
-
-if sys.version_info >= (3, 9):
-
-  def is_relative_to(path_a: pth.AnyPath, path_b: pth.AnyPath) -> bool:
-    return path_a.is_relative_to(path_b)
-
-  def readlink(path: pth.LocalPath) -> pth.LocalPath:
-    return path.readlink()
-else:
-
-  def is_relative_to(path_a: pth.AnyPath, path_b: pth.AnyPath) -> bool:
-    try:
-      path_a.relative_to(path_b)
-      return True
-    except ValueError:
-      return False
-
-  def readlink(path: pth.LocalPath) -> pth.LocalPath:
-    return pth.LocalPath(os.readlink(path))
-
-
-class StrHelpDataMixin(NamedTuple):
-  value: str
-  help: str
-
-
-StrEnumWithHelpT = TypeVar("StrEnumWithHelpT", bound="StrEnumWithHelp")
-
-class StrEnumWithHelp(StrHelpDataMixin, enum.Enum):
-
-  @classmethod
-  def _missing_(cls: Type[StrEnumWithHelpT],
-                value) -> Optional[StrEnumWithHelpT]:
-    value = str(value).lower()
-    for member in cls:
-      if member.value == value:
-        return member
-    return None
-
-  @classmethod
-  def help_text_items(cls) -> List[Tuple[str, str]]:
-    return [
-        (repr(instance.value), instance.help) for instance in cls  # pytype: disable=missing-parameter
-    ]
-
-  @classmethod
-  def help_text(cls, indent: int = 0) -> str:
-    text: str = tabulate.tabulate(cls.help_text_items(), tablefmt="plain")
-    if indent:
-      return textwrap.indent(text, " " * indent)
-    return text
-
-  def __str__(self) -> str:
-    return cast(str, self.value)
diff --git a/crossbench/config.py b/crossbench/config.py
index 0c3a0670..883055b0 100644
--- a/crossbench/config.py
+++ b/crossbench/config.py
@@ -8,25 +8,31 @@ import abc
 import argparse
 import collections
 import collections.abc
+import dataclasses
 import enum
+import functools
 import inspect
+import json
 import logging
+import re
 import textwrap
 from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, Generic,
-                    Iterable, List, Optional, Set, Tuple, Type, TypeVar, Union,
-                    cast)
+                    Iterable, List, Optional, Self, Set, Tuple, Type,
+                    TypeAlias, TypeVar, cast)
 from urllib.parse import urlparse
 
 import tabulate
+from typing_extensions import override
 
-# Use indirection to support pyfakefs
-from crossbench import compat, exception, helper
+from crossbench import exception
 from crossbench import path as pth
-from crossbench.helper import ChangeCWD
+from crossbench.helper import txt_helper
+from crossbench.helper.cwd import ChangeCWD
 from crossbench.parse import ObjectParser, PathParser
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 if TYPE_CHECKING:
-  ArgParserType = Union[Callable[..., Any], Type]
+  ArgParserType: TypeAlias = Callable[..., Any] | Type
 
 
 class ConfigError(argparse.ArgumentTypeError):
@@ -47,7 +53,7 @@ class _ConfigArgParser:
       name: str,
       type: Optional[ArgParserType],
       default: Any = NOT_SET,
-      choices: Optional[frozenset[Any]] = None,
+      choices: Optional[Iterable[Any]] = None,
       aliases: Iterable[str] = tuple(),
       help: Optional[str] = None,
       is_list: bool = False,
@@ -57,18 +63,20 @@ class _ConfigArgParser:
     self.name: str = name
     self.aliases = tuple(aliases)
     self._validate_aliases()
-    self.type: Optional[ArgParserType] = type
+    self.type: ArgParserType | None = type
     self.required: bool = required
-    self.help: Optional[str] = help
+    self.help: str | None = help
     self.is_list: bool = is_list
     type_is_class = inspect.isclass(type)
     self.type_is_class: bool = type_is_class
-    self.is_enum: bool = type_is_class and issubclass(type, enum.Enum)
-    self.config_object_type: Optional[Type[ConfigObject]] = None
-    if type_is_class and issubclass(type, ConfigObject):
-      self.config_object_type = type
+    self.is_enum: bool = type_is_class and issubclass(
+        type,  # type: ignore
+        enum.Enum)
+    self.config_object_type: Type[ConfigObject] | None = None
+    if type_is_class and issubclass(type, ConfigObject):  # type: ignore
+      self.config_object_type = type  # type: ignore
     self.depends_on = frozenset(depends_on) if depends_on else frozenset()
-    self.choices: Optional[frozenset] = self._validate_choices(choices)
+    self.choices: frozenset | None = self._validate_choices(choices)
     if self.type:
       self._validate_callable()
     self.default = self._validate_default(default)
@@ -114,7 +122,7 @@ class _ConfigArgParser:
     ObjectParser.unique_sequence(self.aliases, "aliases", ValueError)
 
   def _validate_choices(
-      self, choices: Optional[frozenset[Any]]) -> Optional[frozenset]:
+      self, choices: Optional[Iterable[Any]]) -> Optional[frozenset]:
     if self.is_enum:
       return self._validate_enum_choices(choices)
     if choices is None:
@@ -127,17 +135,18 @@ class _ConfigArgParser:
     return frozen_choices
 
   def _validate_enum_choices(
-      self, choices: Optional[frozenset[Any]]) -> Optional[frozenset]:
+      self, choices: Optional[Iterable[Any]]) -> Optional[frozenset]:
     assert self.is_enum
     assert self.type
     enum_type: Type[enum.Enum] = cast(Type[enum.Enum], self.type)
     if choices is None:
       return frozenset(enum for enum in enum_type)
-    for choice in choices:
+    frozen_choices = frozenset(choices)
+    for choice in frozen_choices:
       assert isinstance(
           choice,
           enum_type), (f"Enum choices must be {enum_type}, but got: {choice}")
-    return frozenset(choices)
+    return frozen_choices
 
   def _validate_default(self, default: Any) -> Any:
     if default is NOT_SET:
@@ -152,7 +161,7 @@ class _ConfigArgParser:
     if self.is_enum:
       return self._validate_enum_default(default)
     # TODO: Remove once pytype can handle self.type
-    maybe_class: Optional[ArgParserType] = self.type
+    maybe_class: ArgParserType | None = self.type
     if self.is_list:
       self._validate_list_default(default, maybe_class)
     elif maybe_class and inspect.isclass(maybe_class):
@@ -225,24 +234,23 @@ class _ConfigArgParser:
     if self.type is None:
       if self.is_list:
         items.append(("type", "list"))
+    elif self.is_list:
+      items.append(("type", f"List[{self.type.__qualname__}]"))
     else:
-      if self.is_list:
-        items.append(("type", f"List[{self.type.__qualname__}]"))
-      else:
-        items.append(("type", str(self.type.__qualname__)))
+      items.append(("type", str(self.type.__qualname__)))
 
     if self.required:
       items.append(("required", ""))
     elif self.default is None:
       items.append(("default", "not set"))
-    else:
-      if self.is_list:
-        if not self.default:
-          items.append(("default", "[]"))
-        else:
-          items.append(("default", ",".join(map(str, self.default))))
+    elif self.is_list:
+      if not self.default:
+        items.append(("default", "[]"))
       else:
-        items.append(("default", str(self.default)))
+        items.append(("default", ",".join(map(str, self.default))))
+    else:
+      items.append(("default", str(self.default)))
+
     if self.is_enum:
       items.extend(self._enum_help_text())
     elif self.choices:
@@ -258,7 +266,7 @@ class _ConfigArgParser:
 
   def _enum_help_text(self) -> List[Tuple[str, str]]:
     if self.type and hasattr(self.type, "help_text_items"):
-      # See compat.StrEnumWithHelp
+      # See str_enum_with_help.StrEnumWithHelp
       return [("choices", ""), *self.type.help_text_items()]
     assert self.choices
     return [self._choices_help_text(choice.value for choice in self.choices)]
@@ -289,7 +297,7 @@ class _ConfigArgParser:
     return self.parse_data(data, depending_kwargs)
 
   def _pop_alias(self, config_data) -> Optional[Any]:
-    value: Optional[Any] = None
+    value: Any | None = None
     found: bool = False
     for alias in self.aliases:
       if alias not in config_data:
@@ -327,13 +335,13 @@ class _ConfigArgParser:
           f"additional depending arguments, but got: {depending_kwargs}")
 
   def parse_list_data(self, data: Any,
-                      depending_kwargs: Dict[str, Any]) -> List[Any]:
+                      depending_kwargs: Dict[str, Any]) -> Tuple[Any]:
     if isinstance(data, str):
       data = data.split(",")
     if not isinstance(data, (list, tuple)):
       raise ValueError(f"{self.cls_name}.{self.name}: "
                        f"Expected sequence got {type(data).__name__}")
-    return [self.parse_data(value, depending_kwargs) for value in data]
+    return tuple(self.parse_data(value, depending_kwargs) for value in data)
 
   def parse_data(self, data: Any, depending_kwargs: Dict[str, Any]) -> Any:
     if self.is_enum:
@@ -355,41 +363,37 @@ class _ConfigArgParser:
       if not isinstance(data, (float, int)):
         raise ValueError(
             f"{self.cls_name}.{self.name}: Expected number, got {data}")
-    if self.config_object_type:
+    if config_object_type := self.config_object_type:
       # TODO: support custom depending kwargs with ConfigObject
       self._validate_type_without_depending_kwargs(depending_kwargs)
-      return self.parse_config_object(data)
+      return self.parse_config_object(config_object_type, data)
     return self.type(data, **depending_kwargs)
 
-  def parse_config_object(self, data) -> Any:
-    config_object: ConfigObject = self.config_object_type.parse(data)
+  def parse_config_object(self, config_object_type: Type[ConfigObject],
+                          data) -> Any:
+    config_object: ConfigObject = config_object_type.parse(data)
     return config_object.to_argument_value()
 
   def parse_enum_data(self, data: Any) -> enum.Enum:
     assert self.is_enum
     assert self.choices
-    assert self.type
-    assert isinstance(self.type, type), "type for enum has to be a Class."
-    if issubclass(self.type, ConfigEnum):
-      return self.type.parse(data)
-    assert issubclass(self.type, enum.Enum)
-    return ObjectParser.enum(self.name, self.type, data, self.choices)
-
-
+    instance_type = self.type
+    assert instance_type
+    assert isinstance(instance_type, type), "type for enum has to be a Class."
+    if issubclass(instance_type, ConfigEnum):
+      return instance_type.parse(data)  # type: ignore
+    assert issubclass(instance_type, enum.Enum)
+    return ObjectParser.enum(self.name, instance_type, data, self.choices)
 
 
-ConfigEnumT = TypeVar("ConfigEnumT", bound="ConfigEnum")
 
-
-class ConfigEnum(compat.StrEnumWithHelp):
+class ConfigEnum(StrEnumWithHelp):
 
   @classmethod
-  def parse(cls: Type[ConfigEnumT], value: Any) -> ConfigEnumT:
+  def parse(cls, value: Any) -> Self:
     return ObjectParser.enum(cls.__name__, cls, value, cls)
 
 
-ConfigObjectT = TypeVar("ConfigObjectT", bound="ConfigObject")
-
 class ConfigObject(abc.ABC):
   """A ConfigObject is a placeholder object with parsed values from
   a ConfigParser.
@@ -398,10 +402,11 @@ class ConfigObject(abc.ABC):
   - It is then used to create a real instance of an object.
   """
   VALID_EXTENSIONS: Tuple[str, ...] = (".hjson", ".json")
+  VALID_SCHEME: Tuple[str, ...] = ("http", "https", "file", "gs", "ftp")
 
   @classmethod
   def value_has_path_prefix(cls, value: str) -> bool:
-    return PathParser.PATH_PREFIX.match(value) is not None
+    return PathParser.value_has_path_prefix(value)
 
   def __post_init__(self) -> None:
     self.validate()
@@ -417,7 +422,7 @@ class ConfigObject(abc.ABC):
     return self
 
   @classmethod
-  def parse(cls: Type[ConfigObjectT], value: Any, **kwargs) -> ConfigObjectT:
+  def parse(cls, value: Any, **kwargs) -> Self:
     # Quick return for default values used by parsers.
     if isinstance(value, cls):
       return value
@@ -427,82 +432,359 @@ class ConfigObject(abc.ABC):
     raise exception.UnreachableError()
 
   @classmethod
-  def _parse(cls: Type[ConfigObjectT], value: Any, **kwargs) -> ConfigObjectT:
+  def _parse(cls, value: Any, **kwargs) -> Self:
     if isinstance(value, dict):
+      if (cls is not _TemplatedConfigParser and
+          _TemplatedConfigParser.is_template_invocation(value)):
+        result = cls.parse(_TemplatedConfigParser.parse_and_substitute(value))
+        return result
       return cls.parse_dict(value, **kwargs)
     if not value:
       raise ConfigError(f"{cls.__name__}: Empty config value")
     if isinstance(value, pth.LocalPath):
       return cls.parse_path(value, **kwargs)
     if isinstance(value, str):
-      if urlparse(value).scheme:
-        # TODO(346197734): use parse_url here
-        return cls.parse_str(value, **kwargs)
-      try:
-        maybe_path = pth.LocalPath(value).expanduser()
-        if cls.is_valid_path(maybe_path):
-          return cls.parse_path(maybe_path, **kwargs)
-        if cls.value_has_path_prefix(value):
-          return cls.parse_unknown_path(maybe_path, **kwargs)
-      except OSError:
-        pass
-      return cls.parse_str(value, **kwargs)
+      return cls._parse_str(value, **kwargs)
     return cls.parse_other(value, **kwargs)
 
   @classmethod
-  def parse_other(cls: Type[ConfigObjectT], value: Any) -> ConfigObjectT:
+  def _parse_str(cls, value: Any, **kwargs) -> Self:
+    if cls.is_valid_url(value):
+      # TODO(346197734): use parse_url here
+      return cls.parse_str(value, **kwargs)
+    try:
+      maybe_path = pth.LocalPath(value).expanduser()
+      if cls.is_valid_path(maybe_path):
+        return cls.parse_path(maybe_path, **kwargs)
+      if cls.value_has_path_prefix(value):
+        return cls.parse_unknown_path(maybe_path, **kwargs)
+    except OSError:
+      pass
+    return cls.parse_str(value, **kwargs)
+
+  @classmethod
+  def parse_other(cls, value: Any) -> Self:
     raise ConfigError(
         f"Invalid config input type {type(value).__name__}: {value}")
 
   @classmethod
   @abc.abstractmethod
-  def parse_str(cls: Type[ConfigObjectT], value: str) -> ConfigObjectT:
+  def parse_str(cls, value: str) -> Self:
     """Custom implementation for parsing config values that are
     not handled by the default .parse(...) method."""
     raise NotImplementedError()
 
   @classmethod
   def is_valid_path(cls, path: pth.LocalPath) -> bool:
-    if not path.is_file():
-      return False
-    return path.suffix in cls.VALID_EXTENSIONS
+    try:
+      if path.is_file():
+        return path.suffix in cls.VALID_EXTENSIONS
+    except OSError:
+      # Ignore any OSError caused by too long path names.
+      pass
+    return False
 
   @classmethod
-  def parse_unknown_path(cls: Type[ConfigObjectT], path: pth.LocalPath,
-                         **kwargs) -> ConfigObjectT:
+  def is_valid_url(cls, value: Any) -> bool:
+    return urlparse(value).scheme in cls.VALID_SCHEME
+
+  @classmethod
+  def parse_unknown_path(cls, path: pth.LocalPath, **kwargs) -> Self:
     # TODO: this should be redirected to parse_config_path
     return cls.parse_str(str(path), **kwargs)
 
   @classmethod
-  def parse_path(cls: Type[ConfigObjectT], path: pth.LocalPath,
-                 **kwargs) -> ConfigObjectT:
+  def parse_path(cls, path: pth.LocalPath, **kwargs) -> Self:
     return cls.parse_config_path(path, **kwargs)
 
   @classmethod
-  def parse_inline_hjson(cls: Type[ConfigObjectT], value: str,
-                         **kwargs) -> ConfigObjectT:
+  def parse_inline_hjson(cls, value: str, **kwargs) -> Self:
     with exception.annotate(f"Parsing inline {cls.__name__}"):
       data = ObjectParser.inline_hjson(value)
       return cls.parse_dict(data, **kwargs)
     raise exception.UnreachableError()
 
   @classmethod
-  def parse_config_path(cls: Type[ConfigObjectT], path: pth.LocalPathLike,
-                        **kwargs) -> ConfigObjectT:
+  def parse_config_path(cls, path: pth.LocalPathLike, **kwargs) -> Self:
     with exception.annotate_argparsing(f"Parsing {cls.__name__} file: {path}"):
       file_path = PathParser.existing_file_path(path)
       data = ObjectParser.dict_hjson_file(file_path)
       with ChangeCWD(file_path.parent):
-        return cls.parse_dict(data, **kwargs)
+        return cls.parse(data, **kwargs)
     raise exception.UnreachableError()
 
   @classmethod
-  @abc.abstractmethod
-  def parse_dict(cls: Type[ConfigObjectT], config: Dict[str,
-                                                        Any]) -> ConfigObjectT:
+  def parse_dict(cls: Type[Self], config: Dict[str, Any], **kwargs) -> Self:
+    parser: ConfigParser[Self] = cls.config_parser()
+    result: Self = parser.parse(config, **kwargs)
+    return result
+
+  @classmethod
+  def config_parser(cls) -> ConfigParser[Self]:
     raise NotImplementedError()
 
 
+class _PrimitiveConfigObject(ConfigObject):
+  """An implementation of a ConfigObject that returns Primitive types (such as
+  strings, ints, floats) and recursively parses complex types (such as dicts).
+  This is used to allow for early loading of nested configs specified by
+  filepath.
+  """
+
+  def __init__(self, value: Any):
+    self._value = value
+
+  @property
+  def value(self) -> Any:
+    return self._value
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    return cls(value)
+
+  @classmethod
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> Self:
+    result: Dict[str, Any] = {}
+
+    for key, value in config.items():
+      result[key] = _PrimitiveConfigObject.parse(value, **kwargs).value
+
+    return cls(result)
+
+  @classmethod
+  def parse_other(cls, value: Any) -> Self:
+    return cls(value)
+
+
+@dataclasses.dataclass(frozen=False)
+class TemplateArg:
+  name: str
+  value: Any
+  used: bool = False
+
+  def __post_init__(self):
+    if not self.name:
+      raise argparse.ArgumentTypeError("name cannot be empty")
+
+  def set_used(self) -> None:
+    self.used = True
+
+
+def template_args(value: Any) -> Dict[str, TemplateArg]:
+  dict_value = ObjectParser.dict(value)
+
+  for arg_key, arg_value in dict_value.items():
+    with exception.annotate_argparsing(
+        f"Parsing ...[{repr(arg_key)}] = {repr(arg_value)}"):
+
+      if not arg_key.isupper():
+        logging.warning("Arg names should be uppercase: %s", arg_key)
+
+      dict_value[arg_key] = TemplateArg(name=arg_key, value=arg_value)
+
+  return dict_value
+
+
+class ConfigTemplateError(argparse.ArgumentTypeError):
+
+  def __init__(self, message: str) -> None:
+    super().__init__(message)
+
+
+class _TemplatedConfigParser(ConfigObject):
+
+  # Matches args of the format: $[.. arg name ..]
+  ARG_RE = re.compile(r"\$\[([^\][[^\]]*)\]")
+
+  # Matches escape sequences of the above: $[[ should not be replaced ]
+  ESCAPED_ARG_RE = re.compile(r"\$\[\[([^\]].*)\]")
+
+  VALID_KEYS_FOR_TEMPLATE_OBJECT: Final[frozenset] = frozenset([
+      frozenset(["template", "args"]),
+      frozenset(["template", "unbound_args"]),
+      frozenset(["template", "args", "unbound_args"]),
+  ])
+
+  def __init__(self,
+               template: Any,
+               args: Optional[Dict[str, TemplateArg]] = None,
+               unbound_args: Optional[Iterable[str]] = None):
+    self._template: Any = template
+    self._args: Dict[str, TemplateArg] = args if args else {}
+    self._unbound_args: Set[str] = set(unbound_args) if unbound_args else set()
+    self._missing_args: Set[str] = set()
+
+    self.validate()
+
+    with exception.annotate("Processing Templates:"):
+      self._result = self._substitute()
+
+  @override
+  def validate(self) -> None:
+    if not self._args and not self._unbound_args:
+      raise ConfigTemplateError(
+          "Either 'args' or 'unbound_args' are required for template usage.")
+
+    for (arg_name, template_arg) in self._args.items():
+      arg_value = template_arg.value
+
+      if isinstance(arg_value, str):
+        if f"$[{arg_name}]" in arg_value:
+          raise ConfigTemplateError(
+              f"Arguments cannot be self-referencing: {arg_name}. "
+              "If you are trying to forward an arg value from a higher level "
+              "template, add the argument name to the 'unbound_args' field.")
+
+  @classmethod
+  def is_template_invocation(cls, value: Any) -> bool:
+    return isinstance(value, dict) and set(
+        value.keys()) in cls.VALID_KEYS_FOR_TEMPLATE_OBJECT
+
+  @classmethod
+  @override
+  def config_parser(cls: Type[Self]) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
+    parser.add_argument("template", type=ObjectParser.not_none, required=True)
+    parser.add_argument("args", type=template_args, required=False, default={})
+    parser.add_argument(
+        "unbound_args", type=str, required=False, default=[], is_list=True)
+    return parser
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    raise NotImplementedError("Cannot create templated config from strings")
+
+  @classmethod
+  def parse_and_substitute(cls, value: Any) -> Self:
+    value = cls.parse(value)
+    assert isinstance(value, _TemplatedConfigParser)
+    return value.result
+
+  @property
+  def result(self) -> Any:
+    return self._result
+
+  def _substitute(self) -> Any:
+    result = self._substitute_args(self._template)
+
+    if self._missing_args:
+      raise ConfigTemplateError(f"The following arguments were not supplied"
+                                f" but are required: {self._missing_args}")
+
+    unused_args: List[str] = []
+
+    for (arg_name, arg_value) in self._args.items():
+      if not arg_value.used:
+        unused_args.append(arg_name)
+
+    if unused_args:
+      logging.warning("The following config args were supplied but unused:")
+      for unused_arg in unused_args:
+        logging.warning(unused_arg)
+
+    logging.debug(
+        "Argument substitution resulted in the following config object:")
+    logging.debug(json.dumps(result, indent=2))
+
+    return result
+
+  def _substitute_args(self, value: Any) -> Any:
+    if self.is_template_invocation(value):
+      value = _TemplatedConfigParser.parse_and_substitute(value)
+
+    # If the value is a string, first parse it in case it expands to a different
+    # form (i.e. when a filepath expands to a hjson dictionary)
+    if isinstance(value, str):
+      value = _PrimitiveConfigObject.parse(value).value
+
+    if isinstance(value, str):
+      value = self._substitute_str(value)
+
+    if isinstance(value, str):
+      return self._fix_escape_sequence(value)
+
+    if isinstance(value, dict):
+      return self._substitute_dict(value)
+
+    if isinstance(value, list):
+      return self._substitute_list(value)
+
+    return value
+
+  def _substitute_dict(self, value: Dict[Any, Any]) -> Dict[Any, Any]:
+    result: Dict[Any, Any] = {}
+
+    for child_key, child_value in value.items():
+      with exception.annotate(f"Processing ...['{child_key}']:"):
+        result[self._substitute_args(child_key)] = self._substitute_args(
+            child_value)
+    return result
+
+  def _substitute_list(self, value: List[Any]) -> List[Any]:
+    result: List[Any] = []
+    for index, child_value in enumerate(value):
+      with exception.annotate(f"Parsing List index: {index}:"):
+        result.append(self._substitute_args(child_value))
+    return result
+
+  def _substitute_str(self, value: str) -> Any:
+
+    while matches := list(re.finditer(self.ARG_RE, value)):
+
+      made_a_substitution: bool = False
+
+      # Reverse matches so that string indices don't get messed up while we
+      # substitute.
+      matches.reverse()
+      for m in matches:
+        arg_name = m.group(1)
+        assert arg_name
+
+        if arg_name in self._unbound_args:
+          continue
+
+        if not (template_arg := self._args.get(arg_name)):
+          self._missing_args.add(arg_name)
+          continue
+
+        made_a_substitution = True
+
+        arg_value = template_arg.value
+        template_arg.set_used()
+
+        if m.group(0) == value:
+          # Arg pattern is the whole string, replace the whole value to allow
+          # non-string values to be substituted.
+          return arg_value
+        if not isinstance(arg_value, (str, int, float)):
+          raise ConfigTemplateError((
+              f"Argument {repr(arg_name)} with type {type(arg_value).__name__} "
+              f"can not be substituted into {repr(value)}, "
+              f"must be str/int/float"
+          ))
+
+        value = value[:m.start()] + str(arg_value) + value[m.end():]
+
+      if not made_a_substitution:
+        break
+
+    return value
+
+  def _fix_escape_sequence(self, value: str) -> str:
+    matches = list(re.finditer(self.ESCAPED_ARG_RE, value))
+    # Reverse matches so that string indices don't get messed up while we
+    # substitute.
+    matches.reverse()
+    result: str = value
+    for m in matches:
+      escaped_value = m.group(1)
+      result = result[:m.start()] + f"$[{escaped_value}]" + result[m.end():]
+    return result
+
+
 class _ConfigKwargsParser:
 
   def __init__(self, parser: ConfigParser, config_data: Dict[str, Any]):
@@ -554,18 +836,30 @@ class _ConfigKwargsParser:
     return dict(self._kwargs)
 
 
+@enum.unique
+class UnusedPropertiesMode(enum.StrEnum):
+  IGNORE = "ignore"
+  WARN = "warn"
+  ERROR = "error"
+
+
 ConfigResultObjectT = TypeVar("ConfigResultObjectT", bound="object")
 
 class ConfigParser(Generic[ConfigResultObjectT]):
 
-  def __init__(self,
-               title: str,
-               cls: Type[ConfigResultObjectT],
-               default: Optional[ConfigResultObjectT] = None,
-               allow_unused_config_data: bool = True) -> None:
-    self.title = title
-    assert title, "No title provided"
+  def __init__(
+      self,
+      cls: Type[ConfigResultObjectT],
+      title: Optional[str] = None,
+      default: Optional[ConfigResultObjectT] = None,
+      unused_properties_mode: UnusedPropertiesMode = UnusedPropertiesMode.WARN
+  ) -> None:
     self._cls = cls
+    if title is None:
+      title = f"{cls.__name__} parser"
+    if not title:
+      raise ValueError("Got empty title.")
+    self.title = title
     if default:
       if not isinstance(default, cls):
         raise TypeError(
@@ -573,7 +867,7 @@ class ConfigParser(Generic[ConfigResultObjectT]):
     self._default = default
     self._args: Dict[str, _ConfigArgParser] = {}
     self._arg_names: Set[str] = set()
-    self._allow_unused_config_data = allow_unused_config_data
+    self._unused_properties_mode = unused_properties_mode
 
   @property
   def default(self) -> Optional[ConfigResultObjectT]:
@@ -605,6 +899,16 @@ class ConfigParser(Generic[ConfigResultObjectT]):
   def get_argument(self, arg_name: str) -> _ConfigArgParser:
     return self._args[arg_name]
 
+  def has_all_required_args(self, config_data: Dict[str, Any]) -> bool:
+    config_keys: Set[str] = set(config_data.keys())
+    for arg in self._args.values():
+      if arg.required:
+        names = set(arg.aliases)
+        names.add(arg.name)
+        if not config_keys.intersection(names):
+          return False
+    return True
+
   def kwargs_from_config(self, config_data: Dict[str, Any],
                          **extra_kwargs) -> Dict[str, Any]:
     with exception.annotate_argparsing(
@@ -644,8 +948,10 @@ class ConfigParser(Generic[ConfigResultObjectT]):
 
   def _handle_unused_config_data(self, unused_config_data: Dict[str,
                                                                 Any]) -> None:
-    logging.debug("Got unused properties: %s", unused_config_data.keys())
-    if not self._allow_unused_config_data:
+    if self._unused_properties_mode == UnusedPropertiesMode.IGNORE:
+      return
+    logging.warning("Got unused properties: %s", unused_config_data.keys())
+    if self._unused_properties_mode == UnusedPropertiesMode.ERROR:
       unused_keys = ", ".join(map(repr, unused_config_data.keys()))
       raise argparse.ArgumentTypeError(
           f"Config for {self._cls.__name__} contains unused properties: "
@@ -673,6 +979,7 @@ class ConfigParser(Generic[ConfigResultObjectT]):
   def summary(self) -> str:
     return self.doc.splitlines()[0]
 
+  @functools.lru_cache(maxsize=1)
   def __str__(self) -> str:
     parts: List[str] = []
     doc_string = self.doc
@@ -684,11 +991,12 @@ class ConfigParser(Generic[ConfigResultObjectT]):
       if parts:
         return parts[0]
       return ""
-    parts.append(f"{self.title} Configuration:")
+    parts.append(f"{self.cls.__name__} Configuration/Settings:")
     parts.append("")
     for arg in self._args.values():
       parts.append(f"{arg.name}:")
-      parts.extend(helper.wrap_lines(arg.help_text, width=width, indent="  "))
+      parts.extend(
+          txt_helper.wrap_lines(arg.help_text, width=width, indent="  "))
       parts.append("")
     return "\n".join(parts)
 
diff --git a/crossbench/decor/base.py b/crossbench/decor/base.py
index 727778f6..e96cf2cd 100644
--- a/crossbench/decor/base.py
+++ b/crossbench/decor/base.py
@@ -7,22 +7,25 @@ from __future__ import annotations
 import abc
 import datetime as dt
 import enum
-from typing import Dict, Generic, Optional, Set, Type, TypeVar
+from typing import TYPE_CHECKING, Dict, Generic, Set, Type, TypeVar
 
 from crossbench import plt
 from crossbench.config import ConfigParser
+from crossbench.decor.target_protocol import DecoratorTargetProtocol
 from crossbench.helper.state import BaseState, StateMachine
-from crossbench.probes.results import EmptyProbeResult, ProbeResult
+from crossbench.probes.results import EmptyProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.probes.results import ProbeResult
 
 DecoratorT = TypeVar("DecoratorT", bound="Decorator")
-DecoratorTargetT = TypeVar("DecoratorTargetT")
+DecoratorTargetT = TypeVar("DecoratorTargetT", bound=DecoratorTargetProtocol)
 
 
 class DecoratorConfigParser(ConfigParser[DecoratorT]):
 
   def __init__(self, probe_cls: Type[DecoratorT]) -> None:
-    super().__init__(
-        probe_cls.__name__, probe_cls, allow_unused_config_data=False)
+    super().__init__(probe_cls)
     self._probe_cls = probe_cls
 
 
@@ -93,11 +96,11 @@ class DecoratorContext(abc.ABC, Generic[DecoratorT, DecoratorTargetT]):
 
   def __init__(self, decorator: DecoratorT, target: DecoratorTargetT) -> None:
     self._decorator = decorator
-    self._target = target
+    self._target: DecoratorTargetT = target
     self._state = StateMachine(self._State.READY)
     self._is_success: bool = False
-    self._start_time: Optional[dt.datetime] = None
-    self._stop_time: Optional[dt.datetime] = None
+    self._start_time: dt.datetime | None = None
+    self._stop_time: dt.datetime | None = None
     self._label = f"{type(self).__name__} {self.name}"
 
   @property
@@ -133,7 +136,7 @@ class DecoratorContext(abc.ABC, Generic[DecoratorT, DecoratorTargetT]):
 
   def __enter__(self) -> None:
     self._state.transition(self._State.READY, to=self._State.STARTING)
-    with self._target.exception_handler(f"{self._label} start"):
+    with self._target.exception_capture(f"{self._label} start"):
       try:
         self.start()
         self._state.transition(self._State.STARTING, to=self._State.RUNNING)
@@ -143,7 +146,7 @@ class DecoratorContext(abc.ABC, Generic[DecoratorT, DecoratorTargetT]):
 
   def __exit__(self, exc_type, exc_value, traceback) -> None:
     self._state.expect(self._State.RUNNING, self._State.FAILURE)
-    with self._target.exception_handler(f"{self._label} stop"):
+    with self._target.exception_capture(f"{self._label} stop"):
       try:
         self.stop()
         if self._state == self._State.RUNNING:
diff --git a/crossbench/decor/run/run_decorator.py b/crossbench/decor/run/run_decorator.py
index e26bfb11..f35d1691 100644
--- a/crossbench/decor/run/run_decorator.py
+++ b/crossbench/decor/run/run_decorator.py
@@ -5,11 +5,10 @@
 from __future__ import annotations
 
 import abc
-from typing import Set, TypeVar
-
-from crossbench.runner.run import Run
+from typing import Self, Set, TypeVar
 
 from crossbench.decor import base
+from crossbench.runner.run import Run
 
 RunDecoratorT = TypeVar("RunDecoratorT", bound="RunDecorator")
 
@@ -20,8 +19,7 @@ class RunDecorator(base.Decorator[Run]):
     return self._targets
 
   @abc.abstractmethod
-  def get_context(self: RunDecoratorT,
-                  target: Run) -> RunDecoratorContext[RunDecoratorT]:
+  def get_context(self: Self, target: Run) -> RunDecoratorContext[Self]:
     pass
 
 
diff --git a/crossbench/decor/session/session_decorator.py b/crossbench/decor/session/session_decorator.py
index 196ebb3c..fec436e8 100644
--- a/crossbench/decor/session/session_decorator.py
+++ b/crossbench/decor/session/session_decorator.py
@@ -5,7 +5,7 @@
 from __future__ import annotations
 
 import abc
-from typing import Set, TypeVar
+from typing import Self, Set, TypeVar
 
 from crossbench.decor import base
 from crossbench.runner.groups.session import BrowserSessionRunGroup
@@ -20,8 +20,7 @@ class SessionDecorator(base.Decorator[Run]):
     return self._targets
 
   @abc.abstractmethod
-  def get_context(self: SessionDecoratorT,
-                  target: Run) -> SessionDecoratorContext[SessionDecoratorT]:
+  def get_context(self: Self, target: Run) -> SessionDecoratorContext[Self]:
     pass
 
 
diff --git a/crossbench/decor/target_protocol.py b/crossbench/decor/target_protocol.py
new file mode 100644
index 00000000..8a964e13
--- /dev/null
+++ b/crossbench/decor/target_protocol.py
@@ -0,0 +1,20 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+from typing import TYPE_CHECKING, Protocol
+
+if TYPE_CHECKING:
+  from crossbench.exception import ExceptionAnnotationScope, TExceptionTypes
+
+
+class DecoratorTargetProtocol(Protocol):
+
+  @abc.abstractmethod
+  def exception_capture(
+      self, *stack_entries: str, exceptions: TExceptionTypes = (Exception,)
+  ) -> ExceptionAnnotationScope:
+    pass
diff --git a/crossbench/env.py b/crossbench/env.py
index f6e04b92..2e8ddb79 100644
--- a/crossbench/env.py
+++ b/crossbench/env.py
@@ -4,142 +4,27 @@
 
 from __future__ import annotations
 
-import dataclasses
 import datetime as dt
-import enum
 import logging
 import os
-import urllib.request
-from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterable, List,
-                    Optional, Tuple, Union)
-from urllib.parse import urlparse
+from typing import TYPE_CHECKING, Dict, Iterable, List, Optional, Tuple
 
 import colorama
 
-from crossbench import compat, helper, plt
+from crossbench import plt
+from crossbench.cli.config.env import EnvironmentConfig, ValidationMode
+from crossbench.helper import collection_helper, url_helper
+from crossbench.parse import ObjectParser
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
-  from crossbench.path import LocalPath
+  from crossbench.path import AnyPathLike, LocalPath
   from crossbench.plt.base import CmdArg, Platform
   from crossbench.probes.probe import Probe
 
-
-def merge_bool(name: str, left: Optional[bool],
-               right: Optional[bool]) -> Optional[bool]:
-  if left is None:
-    return right
-  if right is None:
-    return left
-  if left != right:
-    raise ValueError(f"Conflicting merge values for {name}: "
-                     f"{left} vs. {right}")
-  return left
-
-
-Number = Union[float, int]
-
-
-def merge_number_max(name: str, left: Optional[Number],
-                     right: Optional[Number]) -> Optional[Number]:
-  del name
-  if left is None:
-    return right
-  if right is None:
-    return left
-  return max(left, right)
-
-
-def merge_number_min(name: str, left: Optional[Number],
-                     right: Optional[Number]) -> Optional[Number]:
-  del name
-  if left is None:
-    return right
-  if right is None:
-    return left
-  return min(left, right)
-
-
-def merge_str_list(name: str, left: Optional[List[str]],
-                   right: Optional[List[str]]) -> Optional[List[str]]:
-  del name
-  if left is None:
-    return right
-  if right is None:
-    return left
-  return left + right
-
-
-@dataclasses.dataclass(frozen=True)
-class HostEnvironmentConfig:
-  IGNORE = None
-
-  disk_min_free_space_gib: Optional[float] = IGNORE
-  power_use_battery: Optional[bool] = IGNORE
-  screen_brightness_percent: Optional[int] = IGNORE
-  cpu_max_usage_percent: Optional[float] = IGNORE
-  cpu_min_relative_speed: Optional[float] = IGNORE
-  system_allow_monitoring: Optional[bool] = IGNORE
-  browser_allow_existing_process: Optional[bool] = IGNORE
-  browser_allow_background: Optional[bool] = IGNORE
-  browser_is_headless: Optional[bool] = IGNORE
-  require_probes: Optional[bool] = IGNORE
-  system_forbidden_process_names: Optional[List[str]] = IGNORE
-  screen_allow_autobrightness: Optional[bool] = IGNORE
-
-  def merge(self, other: HostEnvironmentConfig) -> HostEnvironmentConfig:
-    mergers: Dict[str, Callable[[str, Any, Any], Any]] = {
-        "disk_min_free_space_gib": merge_number_max,
-        "power_use_battery": merge_bool,
-        "screen_brightness_percent": merge_number_max,
-        "cpu_max_usage_percent": merge_number_min,
-        "cpu_min_relative_speed": merge_number_max,
-        "system_allow_monitoring": merge_bool,
-        "browser_allow_existing_process": merge_bool,
-        "browser_allow_background": merge_bool,
-        "browser_is_headless": merge_bool,
-        "require_probes": merge_bool,
-        "system_forbidden_process_names": merge_str_list,
-        "screen_allow_autobrightness": merge_bool,
-    }
-    kwargs = {}
-    for name, merger in mergers.items():
-      self_value = getattr(self, name)
-      other_value = getattr(other, name)
-      kwargs[name] = merger(name, self_value, other_value)
-    return HostEnvironmentConfig(**kwargs)
-
-
-@enum.unique
-class ValidationMode(compat.StrEnumWithHelp):
-  THROW = ("throw", "Strict mode, throw and abort on env issues")
-  PROMPT = ("prompt", "Prompt to accept potential env issues")
-  WARN = ("warn", "Only display a warning for env issue")
-  SKIP = ("skip", "Don't perform any env validation")
-
-
 class ValidationError(Exception):
   pass
 
-
-_config_default = HostEnvironmentConfig()
-_config_strict = HostEnvironmentConfig(
-    cpu_max_usage_percent=98,
-    cpu_min_relative_speed=1,
-    system_allow_monitoring=False,
-    browser_allow_existing_process=False,
-    require_probes=True,
-)
-_config_battery = _config_strict.merge(
-    HostEnvironmentConfig(power_use_battery=True))
-_config_power = _config_strict.merge(
-    HostEnvironmentConfig(power_use_battery=False))
-_config_catan = _config_strict.merge(
-    HostEnvironmentConfig(
-        screen_brightness_percent=65,
-        system_forbidden_process_names=["terminal", "iterm2"],
-        screen_allow_autobrightness=False))
-
 STALE_RESULT_ICONS = {
     75: "",
     100: "",
@@ -165,13 +50,6 @@ class HostEnvironment:
     fail:     Fast-fail on mismatch
   """
 
-  CONFIGS = {
-      "default": _config_default,
-      "strict": _config_strict,
-      "battery": _config_battery,
-      "power": _config_power,
-      "catan": _config_catan,
-  }
 
   def __init__(self,
                platform: Platform,
@@ -179,10 +57,10 @@ class HostEnvironment:
                browsers: Iterable[Browser],
                probes: Iterable[Probe],
                repetitions: int,
-               config: Optional[HostEnvironmentConfig] = None,
-               validation_mode: ValidationMode = ValidationMode.THROW):
+               config: Optional[EnvironmentConfig] = None,
+               validation_mode: ValidationMode = ValidationMode.THROW) -> None:
     self._wait_until = dt.datetime.now()
-    self._config = config or HostEnvironmentConfig()
+    self._config = config or EnvironmentConfig()
     self._out_dir = out_dir
     self._browsers = tuple(browsers)
     self._probes = tuple(probes)
@@ -203,7 +81,7 @@ class HostEnvironment:
     return self._browsers
 
   @property
-  def config(self) -> HostEnvironmentConfig:
+  def config(self) -> EnvironmentConfig:
     return self._config
 
   @property
@@ -253,33 +131,35 @@ class HostEnvironment:
 
   def validate_url(self,
                    url: str,
-                   platform: plt.Platform = plt.PLATFORM) -> bool:
+                   platform: Optional[plt.Platform] = None) -> bool:
     if self._validation_mode == ValidationMode.SKIP:
       return True
-    result = urlparse(url)
+    platform = platform or plt.PLATFORM
+    result = ObjectParser.url(url)
     if result.scheme == "file":
       return platform.exists(result.path)
     if platform.is_remote and result.hostname in ("localhost", "127.0.0.1"):
       # TODO: support remote URL verification, for now we just assume that
       # checking a live site is ok.
       return True
+    if not all([result.scheme in ["http", "https"], result.netloc]):
+      return False
+    if self._validation_mode != ValidationMode.PROMPT:
+      return True
     try:
-      if not all([result.scheme in ["http", "https"], result.netloc]):
-        return False
-      if self._validation_mode != ValidationMode.PROMPT:
-        return True
-      with urllib.request.urlopen(url, timeout=5) as request:
-        if request.getcode() == 200:
-          return True
-        logging.debug("Could not load URL '%s', got %s", url, request)
-    except urllib.error.URLError as e:
-      logging.debug("Could not parse URL '%s' got error: %s", url, e)
-    return False
+      url_helper.get(url, timeout=5)
+      return True
+    except url_helper.HTTPError as e:
+      logging.debug("Could not load URL '%s', got %s", url, e)
+      return False
 
   def _check_system_monitoring(self) -> None:
     # TODO(cbruni): refactor to use list_... and disable_system_monitoring api
     if self._platform.is_macos:
-      self._check_crowdstrike()
+      any_browser_on_macos = any(
+          browser.platform.is_macos for browser in self.browsers)
+      if any_browser_on_macos:
+        self._check_crowdstrike()
 
   def _check_crowdstrike(self) -> None:
     """Crowdstrike security monitoring (for googlers go/crowdstrike-falcon) can
@@ -307,7 +187,7 @@ class HostEnvironment:
 
   def _check_disk_space(self) -> None:
     limit = self._config.disk_min_free_space_gib
-    if limit is HostEnvironmentConfig.IGNORE:
+    if limit is EnvironmentConfig.IGNORE:
       return
     # Check the remaining disk space on the FS where we write the results.
     usage = self._platform.disk_usage(self._out_dir)
@@ -318,7 +198,7 @@ class HostEnvironment:
 
   def _check_power(self) -> None:
     use_battery = self._config.power_use_battery
-    if use_battery is HostEnvironmentConfig.IGNORE:
+    if use_battery is EnvironmentConfig.IGNORE:
       return
     battery_probes = []
     # Certain probes may require battery power:
@@ -338,7 +218,7 @@ class HostEnvironment:
 
   def _check_cpu_usage(self) -> None:
     max_cpu_usage = self._config.cpu_max_usage_percent
-    if max_cpu_usage is HostEnvironmentConfig.IGNORE:
+    if max_cpu_usage is EnvironmentConfig.IGNORE:
       return
     cpu_usage_percent = round(100 * self._platform.cpu_usage(), 1)
     if cpu_usage_percent > max_cpu_usage:
@@ -348,7 +228,7 @@ class HostEnvironment:
 
   def _check_cpu_temperature(self) -> None:
     min_relative_speed = self._config.cpu_min_relative_speed
-    if min_relative_speed is HostEnvironmentConfig.IGNORE:
+    if min_relative_speed is EnvironmentConfig.IGNORE:
       return
     cpu_speed = self._platform.get_relative_cpu_speed()
     if cpu_speed < min_relative_speed:
@@ -361,7 +241,7 @@ class HostEnvironment:
     # Verify that no terminals are running.
     # They introduce too much overhead. (As measured with powermetrics)
     system_forbidden_process_names = self._config.system_forbidden_process_names
-    if system_forbidden_process_names is HostEnvironmentConfig.IGNORE:
+    if system_forbidden_process_names is EnvironmentConfig.IGNORE:
       return
     process_found = self._platform.process_running(
         system_forbidden_process_names)
@@ -386,14 +266,22 @@ class HostEnvironment:
   def _check_running_binaries(self) -> None:
     if self._config.browser_allow_existing_process:
       return
-    grouped_browsers: Dict[plt.Platform, List[Browser]] = helper.group_by(
-        self.browsers, key=lambda browser: browser.platform)
+    grouped_browsers: Dict[plt.Platform,
+                           List[Browser]] = collection_helper.group_by(
+                               self.browsers,
+                               key=lambda browser: browser.platform)
     for platform, browsers in grouped_browsers.items():
       self._check_running_binaries_on_platform(platform, browsers)
 
   def _check_running_binaries_on_platform(
       self, platform: plt.Platform, platform_browsers: List[Browser]) -> None:
-    browser_binaries: Dict[str, List[Browser]] = helper.group_by(
+    # On Android, an app's process lifetime is not controlled by the user or
+    # the app itself. OS can start/terminate processes in the background, so
+    # we don't check for those.
+    if platform.is_android:
+      return
+
+    browser_binaries: Dict[str, List[Browser]] = collection_helper.group_by(
         platform_browsers, key=lambda browser: os.fspath(browser.path))
     own_pid = os.getpid()
     for proc_info in platform.processes(["cmdline", "exe", "pid", "name"]):
@@ -430,7 +318,7 @@ class HostEnvironment:
 
   def _check_screen_brightness(self) -> None:
     brightness = self._config.screen_brightness_percent
-    if brightness is HostEnvironmentConfig.IGNORE:
+    if brightness is EnvironmentConfig.IGNORE:
       return
     assert 0 <= brightness <= 100, f"Invalid brightness={brightness}"
     self._platform.set_main_display_brightness(brightness)
@@ -443,7 +331,7 @@ class HostEnvironment:
   def _check_headless(self) -> None:
     # TODO: migrate to full viewport support
     requested_headless = self._config.browser_is_headless
-    if requested_headless is HostEnvironmentConfig.IGNORE:
+    if requested_headless is EnvironmentConfig.IGNORE:
       return
     if self._platform.is_linux and not requested_headless:
       # Check that the system can run browsers with a UI.
@@ -467,7 +355,7 @@ class HostEnvironment:
         raise ValidationError(
             f"Probe='{probe.NAME}' validation failed: {e}") from e
     require_probes = self._config.require_probes
-    if require_probes is HostEnvironmentConfig.IGNORE:
+    if require_probes is EnvironmentConfig.IGNORE:
       return
     if self._config.require_probes and not self._probes:
       self.handle_validation_warning("No probes specified.")
@@ -502,6 +390,53 @@ class HostEnvironment:
           "Terminal.app does not launch apps in the foreground.\n"
           "Please use iTerm.app for a better experience.")
 
+  def _check_file_access(self) -> None:
+    if self._platform.is_macos:
+      has_safari = any(
+          browser.attributes().is_safari for browser in self.browsers)
+      if has_safari:
+        self._check_safari_cache_dir_access()
+    self._check_results_dir_access()
+
+  def _check_safari_cache_dir_access(self) -> None:
+    safari_cache_dir = (
+        self.platform.home() /
+        "Library/Containers/com.apple.Safari/Data/Library/Caches")
+    if not self._has_read_write_access(safari_cache_dir):
+      self._file_access_access_warning("Safari's cache directory")
+
+  def _check_results_dir_access(self) -> None:
+    out_dir = self._out_dir.parent
+    if self._has_read_write_access(out_dir):
+      return
+    self._file_access_access_warning(f"the parent result dir: {out_dir})")
+
+  def _has_read_write_access(self, test_dir: AnyPathLike) -> bool:
+    try:
+      self.platform.mkdir(test_dir, exist_ok=True, parents=True)
+      with self.platform.NamedTemporaryFile(
+          prefix="crossbench_file_access_test", dir=test_dir) as test_file:
+        self.platform.set_file_contents(test_file, test_file.name)
+        assert self.platform.get_file_contents(test_file) == test_file.name
+        self.platform.rm(test_file)
+        return True
+    except Exception as e:  # pylint: disable=broad-except
+      logging.debug("Failed file access test: %s", e)
+      return False
+
+  def _file_access_access_warning(self, dir_name: str) -> None:
+    if not self.platform.is_macos:
+      self.handle_validation_warning(f"Could not modify {dir_name}")
+      return
+
+    term_program = self._platform.environ.get("TERM_PROGRAM",
+                                              "the current terminal App")
+    self.handle_validation_warning(
+        f"Could not modify {dir_name}.\n"
+        "Likely missing 'Full Disk Access' macOS Privacy & Security "
+        f"permission for {term_program}.")
+
+
   def check_browser_focused(self, browser: Browser) -> None:
     if (self._config.browser_allow_background or not browser.pid or
         browser.viewport.is_headless):
@@ -521,10 +456,10 @@ class HostEnvironment:
 
   def validate(self) -> None:
     logging.info("-" * 80)
+    message = "  VALIDATE ENVIRONMENT"
     if self._validation_mode == ValidationMode.SKIP:
-      logging.info("VALIDATE ENVIRONMENT: SKIP")
+      logging.info("%s: SKIP", message)
       return
-    message = "VALIDATE ENVIRONMENT"
     if self._validation_mode != ValidationMode.WARN:
       message += " (--env-validation=warn for soft warnings)"
     message += ": %s"
@@ -544,6 +479,7 @@ class HostEnvironment:
     self._check_forbidden_system_process()
     self._check_screen_autobrightness()
     self._check_macos_terminal()
+    self._check_file_access()
 
   def check_installed(self,
                       binaries: Iterable[str],
diff --git a/crossbench/exception.py b/crossbench/exception.py
index ed36dc38..ed3cc092 100644
--- a/crossbench/exception.py
+++ b/crossbench/exception.py
@@ -13,7 +13,7 @@ from dataclasses import dataclass
 from types import TracebackType
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Type
 
-from crossbench import helper
+from crossbench.helper import collection_helper, txt_helper
 from crossbench.types import JsonList
 
 if TYPE_CHECKING:
@@ -37,9 +37,9 @@ class MultiException(ValueError):
   are automatically added to active ExceptionAnnotator in an
   ExceptionAnnotationScope."""
 
-  def __init__(self, message: str, exceptions: ExceptionAnnotator):
+  def __init__(self, message: str, exceptions: ExceptionAnnotator) -> None:
     super().__init__(message)
-    self.exceptions = exceptions
+    self.exceptions: ExceptionAnnotator = exceptions
 
   def __len__(self) -> int:
     return len(self.exceptions)
@@ -67,20 +67,18 @@ class ExceptionAnnotationScope:
       entries: Tuple[str, ...],
       throw_cls: Optional[Type[BaseException]] = None,
   ) -> None:
-    logging.debug("ExceptionAnnotationScope: %s", entries)
+    logging.debug("EAS: %s%s", "  " * annotator.depth, " ".join(entries))
     self._annotator = annotator
     self._exception_types = exception_types
     self._ignore_exception_types = ignore_exception_types + (
         StopIteration, GeneratorExit, StopAsyncIteration)
     self._ignore_exception_types = ignore_exception_types
     self._added_info_stack_entries = entries
-    self._throw_cls: Optional[Type[BaseException]] = throw_cls
+    self._throw_cls: Type[BaseException] | None = throw_cls
     self._previous_info_stack: TInfoStack = ()
 
   def __enter__(self) -> ExceptionAnnotationScope:
-    self._annotator._pending_exceptions.clear()
-    self._previous_info_stack = self._annotator.info_stack
-    self._annotator._info_stack = self._previous_info_stack + (
+    self._previous_info_stack = self._annotator.enter(
         self._added_info_stack_entries)
     return self
 
@@ -88,12 +86,12 @@ class ExceptionAnnotationScope:
                exception_value: Optional[BaseException],
                traceback: Optional[TracebackType]) -> bool:
     if not exception_value or not exception_type:
-      self._annotator._info_stack = self._previous_info_stack
+      self._annotator.leave(self._previous_info_stack)
       # False => exception not handled
       return False
     if issubclass(exception_type, self._ignore_exception_types) and (
         not issubclass(exception_type, MultiException)):
-      self._annotator._info_stack = self._previous_info_stack
+      self._annotator.leave(self._previous_info_stack)
       # False => exception not handled, directly forward
       return False
     logging.debug("Intermediate Exception: %s:%s", exception_type,
@@ -104,16 +102,14 @@ class ExceptionAnnotationScope:
       # Handle matching exceptions directly here and prevent further
       # exception handling by returning True.
       self._annotator.append(exception_value)
-      self._annotator._info_stack = self._previous_info_stack
+      self._annotator.leave(self._previous_info_stack)
       if self._throw_cls:
-        self._annotator.assert_success(
-            exception_cls=self._throw_cls,
-            log=False,
-        )
+        self._annotator.assert_success(exception_cls=self._throw_cls)
       return True
     if exception_value not in self._annotator._pending_exceptions:
       self._annotator._pending_exceptions[
           exception_value] = self._annotator.info_stack
+    self._annotator._info_stack = self._previous_info_stack
     # False => exception not handled
     return False
 
@@ -129,7 +125,7 @@ class ExceptionAnnotator:
                throw_cls: Optional[Type[BaseException]] = None) -> None:
     self._exceptions: List[Entry] = []
     self.throw: bool = throw
-    self._throw_cls: Optional[Type[BaseException]] = throw_cls
+    self._throw_cls: Type[BaseException] | None = throw_cls
     # The info_stack adds additional meta information to handle exceptions.
     # Unlike the source-based backtrace, this can contain dynamic information
     # for easier debugging.
@@ -138,6 +134,7 @@ class ExceptionAnnotator:
     # use in the `handle` method.
     # This is cleared whenever we enter a  new ExceptionAnnotationScope.
     self._pending_exceptions: Dict[BaseException, TInfoStack] = {}
+    self._depth = 0
 
   @property
   def is_success(self) -> bool:
@@ -151,6 +148,10 @@ class ExceptionAnnotator:
   def exceptions(self) -> List[Entry]:
     return self._exceptions
 
+  @property
+  def depth(self) -> int:
+    return self._depth
+
   def __getitem__(self, key: Any) -> Entry:
     if not isinstance(key, int):
       raise TypeError(f"Expected int key, but got: {key}")
@@ -159,6 +160,17 @@ class ExceptionAnnotator:
   def __len__(self) -> int:
     return len(self._exceptions)
 
+  def enter(self, added_info_stack_entries: Tuple[str, ...]) -> Tuple[str, ...]:
+    self._depth += 1
+    self._pending_exceptions.clear()
+    previous_stack = self._info_stack
+    self._info_stack = previous_stack + added_info_stack_entries
+    return previous_stack
+
+  def leave(self, previous_stack: Tuple[str, ...]) -> None:
+    self._depth -= 1
+    self._info_stack = previous_stack
+
   def matching(self, *args: Type[BaseException]) -> List[BaseException]:
     result = []
     for entry in self._exceptions:
@@ -167,14 +179,13 @@ class ExceptionAnnotator:
         result.append(exception)
     return result
 
-  def assert_success(self,
-                     message: Optional[str] = None,
-                     exception_cls: Type[BaseException] = MultiException,
-                     log: bool = True) -> None:
+  def assert_success(
+      self,
+      message: Optional[str] = None,
+      exception_cls: Type[BaseException] = MultiException,
+  ) -> None:
     if self.is_success:
       return
-    if log:
-      self.log()
     if message is None:
       message = "{}"
     message = message.format(self)
@@ -246,18 +257,21 @@ class ExceptionAnnotator:
     if self.throw:
       raise  # pylint: disable=misplaced-bare-raise
 
-  def log(self) -> None:
+  def log(self, message: str, separator: str = "=") -> None:
     if self.is_success:
       return
-    logging.error("=" * 80)
-    logging.error("ERRORS occurred (1/%d):", len(self._exceptions))
-    logging.error("=" * 80)
+    logging.error(separator * 80)
+    if len(self._exceptions) == 1:
+      logging.error("%s:", message)
+    else:
+      logging.error("%s (1/%d):", message, len(self._exceptions))
+    logging.error(separator * 80)
     for entry in self._exceptions:
       logging.debug(entry.exception)
       logging.debug("\n".join(entry.traceback))
       logging.debug("-" * 80)
     is_first_entry = True
-    grouped_entries: Dict[TInfoStack, List[Entry]] = helper.group_by(
+    grouped_entries: Dict[TInfoStack, List[Entry]] = collection_helper.group_by(
         self._exceptions, key=lambda entry: entry.info_stack, sort_key=None)
     for info_stack, entries in grouped_entries.items():
       logging_level = logging.ERROR if is_first_entry else logging.DEBUG
@@ -270,7 +284,7 @@ class ExceptionAnnotator:
       for entry in entries:
         logging.log(logging_level, "- " * 40)
         logging.log(logging_level, "Type: %s:",
-                    helper.type_name(type(entry.exception)))
+                    txt_helper.type_name(type(entry.exception)))
         logging.log(logging_level, "      %s", self.format_exception(entry))
         logging_level = logging.DEBUG
       logging.log(logging_level, "-" * 80)
@@ -281,7 +295,7 @@ class ExceptionAnnotator:
   def to_json(self) -> JsonList:
     return [{
         "info_stack": entry.info_stack,
-        "type": helper.type_name(type(entry.exception)),
+        "type": txt_helper.type_name(type(entry.exception)),
         "title": self.format_exception(entry),
         "trace": entry.traceback
     } for entry in self._exceptions]
@@ -323,8 +337,9 @@ class ArgumentTypeMultiException(MultiException, argparse.ArgumentTypeError):
   pass
 
 
-def annotate_argparsing(*stack_entries: str,
-                        exceptions: TExceptionTypes = (Exception,)):
+def annotate_argparsing(
+    *stack_entries: str, exceptions: TExceptionTypes = (Exception,)
+) -> ExceptionAnnotationScope:
   """Use this to annotate argument parsing-related code blocks to get more
   readable annotated exception back.
   - Wraps multiple exception in an ArgumentTypeMultiException
diff --git a/crossbench/flags/base.py b/crossbench/flags/base.py
index 2759c9b5..990a30f4 100644
--- a/crossbench/flags/base.py
+++ b/crossbench/flags/base.py
@@ -6,24 +6,23 @@ from __future__ import annotations
 
 import collections
 import re
-from typing import (Any, Dict, Iterable, Iterator, List, Optional, Tuple, Type,
-                    TypeVar, Union)
+from typing import (Any, Dict, Iterable, Iterator, List, Optional, Self, Set,
+                    Tuple, TypeAlias, TypeVar, Union)
+
+from typing_extensions import override
 
 
 class FrozenFlagsError(RuntimeError):
   pass
 
 
-FreezableT = TypeVar("FreezableT", bound="Freezable")
-
-
 class Freezable:
 
   def __init__(self, *args, **kwargs) -> None:
     self._frozen = False
     super().__init__(*args, **kwargs)
 
-  def __hash__(self):
+  def __hash__(self) -> int:
     self.freeze()
     return hash(str(self))
 
@@ -31,7 +30,7 @@ class Freezable:
   def is_frozen(self) -> bool:
     return self._frozen
 
-  def freeze(self: FreezableT) -> FreezableT:
+  def freeze(self: Self) -> Self:
     self._frozen = True
     return self
 
@@ -43,11 +42,9 @@ class Freezable:
     raise FrozenFlagsError(msg)
 
 
-BasicFlagsT = TypeVar("BasicFlagsT", bound="BasicFlags")
-
 
-FlagsData = Optional[Union[Dict[str, str], "Flags",
-                           Iterable[Union[Tuple[str, Optional[str]], str]]]]
+FlagsData: TypeAlias = Union[None, Dict[str, str], "Flags",
+                             Iterable[str | Tuple[str, str | None]]]
 
 
 class BasicFlags(Freezable, collections.UserDict):
@@ -76,7 +73,7 @@ class BasicFlags(Freezable, collections.UserDict):
     return (flag_str, None)
 
   @classmethod
-  def parse(cls: Type[BasicFlagsT], data: Any) -> BasicFlagsT:
+  def parse(cls, data: Any) -> Self:
     if isinstance(data, cls):
       return data
     if isinstance(data, str):
@@ -84,35 +81,32 @@ class BasicFlags(Freezable, collections.UserDict):
     return cls(data)
 
   @classmethod
-  def parse_str(cls: Type[BasicFlagsT], raw_flags: str) -> BasicFlagsT:
+  def parse_str(cls, raw_flags: str) -> Self:
     return cls._parse_str(raw_flags)
 
   @classmethod
-  def _parse_str(cls: Type[BasicFlagsT],
-                 raw_flags: str,
-                 msg: str = "flag") -> BasicFlagsT:
+  def _parse_str(cls, raw_flags: str, msg: str = "flag") -> Self:
     raw_flags = raw_flags.strip()
     if not raw_flags:
       return cls()
-    flag_parts: List[Tuple[str, Optional[str]]] = []
-    current_end: Optional[int] = None
+    flag_parts: List[Tuple[str, str | None]] = []
+    current_end: int | None = None
     for match in cls._PARSE_RE.finditer(raw_flags):
       if current_end is None:
         if match.start() != 0:
           part = raw_flags[:match.start()]
           raise ValueError(f"Invalid {msg} part at pos=0: {repr(part)}")
-      else:
-        if current_end != match.start():
-          raise ValueError(f"Invalid {msg}: could not consume all data")
+      elif current_end != match.start():
+        raise ValueError(f"Invalid {msg}: could not consume all data")
       current_end = match.end()
 
       groups = match.groupdict()
-      maybe_flag_name: Optional[str] = groups.get("name")
+      maybe_flag_name: str | None = groups.get("name")
       if not maybe_flag_name:
         raise ValueError(f"Invalid {msg}: {repr(raw_flags)}")
       # Re-assign since pytype doesn't remove the Optional.
       flag_name: str = maybe_flag_name
-      flag_value: Optional[str] = (
+      flag_value: str | None = (
           groups.get("value_single_quotes") or
           groups.get("value_double_quotes") or groups.get("value_no_quotes"))
       if groups.get("equal") and not flag_value:
@@ -135,18 +129,18 @@ class BasicFlags(Freezable, collections.UserDict):
   def set(self,
           flag_name: str,
           flag_value: Optional[str] = None,
-          override: bool = False) -> None:
-    self._set(flag_name, flag_value, override)
+          should_override: bool = False) -> None:
+    self._set(flag_name, flag_value, should_override)
 
   def _set(self,
            flag_name: str,
            flag_value: Optional[str] = None,
-           override: bool = False) -> None:
+           should_override: bool = False) -> None:
     self.assert_not_frozen()
     self._validate_flag_name(flag_name)
     if flag_value:
       self._validate_flag_value(flag_name, flag_value)
-    self._validate_override(flag_name, flag_value, override)
+    self._validate_override(flag_name, flag_value, should_override)
     self.data[flag_name] = flag_value
 
   def _validate_flag_name(self, flag_name: str) -> None:
@@ -173,8 +167,8 @@ class BasicFlags(Freezable, collections.UserDict):
           f"but got: {repr(flag_value)}")
 
   def _validate_override(self, flag_name: str, flag_value: Optional[str],
-                         override: bool) -> None:
-    if override or flag_name not in self:
+                         should_override: bool) -> None:
+    if should_override or flag_name not in self:
       return
     old_value = self[flag_name]
     if flag_value != old_value:
@@ -182,27 +176,28 @@ class BasicFlags(Freezable, collections.UserDict):
                        f"with a different previous value: {repr(old_value)}")
 
   # pylint: disable=arguments-differ
-  def update(self,
-             initial_data: FlagsData = None,
-             override: bool = False) -> None:
+  def update(  # type: ignore
+      self,
+      initial_data: FlagsData = None,
+      should_override: bool = False) -> None:
     # pylint: disable=arguments-differ
     if initial_data is None:
       return
     if isinstance(initial_data, (Flags, dict)):
       for flag_name, flag_value in initial_data.items():
-        self.set(flag_name, flag_value, override)
+        self.set(flag_name, flag_value, should_override)
     else:
       for flag_name_or_items in initial_data:
         if isinstance(flag_name_or_items, str):
-          self.set(flag_name_or_items, None, override)
+          self.set(flag_name_or_items, None, should_override)
         else:
           flag_name, flag_value = flag_name_or_items
-          self.set(flag_name, flag_value, override)
+          self.set(flag_name, flag_value, should_override)
 
   def merge(self, other: FlagsData) -> None:
     self.update(other)
 
-  def copy(self: BasicFlagsT) -> BasicFlagsT:
+  def copy(self: Self) -> Self:
     return self.__class__(self)
 
   def merge_copy(self, other: FlagsData):
@@ -210,13 +205,22 @@ class BasicFlags(Freezable, collections.UserDict):
     ret.merge(other)
     return ret
 
+  def filtered(self: Self, flag_names: Iterable[str]) -> Self:
+    flag_names_set: Set[str] = set(flag_names)
+    filtered_flags = {k: v for k, v in self.items() if k in flag_names_set}
+    return self.__class__(filtered_flags)
+
+  def contains_without_value(self, key: str) -> bool:
+    return key in self.data and self.data[key] is None
+
   def _describe(self, flag_name: str) -> str:
     value = self.get(flag_name)
     if value is None:
       return flag_name
     return f"{flag_name}={value}"
 
-  def items(self) -> Iterable[Tuple[str, Optional[str]]]:
+  @override
+  def items(self) -> Iterable[Tuple[str, Optional[str]]]:  # type: ignore
     return self.data.items()
 
   def to_dict(self) -> Dict[str, Optional[str]]:
@@ -250,6 +254,7 @@ class Flags(BasicFlags):
                          fr"((?P<equal>=)({BasicFlags._VALUE_PATTERN})?)?"
                          fr"{BasicFlags._END_OR_SEPARATOR_PATTERN}")
 
+  @override
   def _validate_flag_name(self, flag_name: str) -> None:
     super()._validate_flag_name(flag_name)
     if not self._FLAG_NAME_RE.fullmatch(flag_name):
diff --git a/crossbench/flags/chrome.py b/crossbench/flags/chrome.py
index 2d11e61d..a5a34edc 100644
--- a/crossbench/flags/chrome.py
+++ b/crossbench/flags/chrome.py
@@ -6,9 +6,10 @@ from __future__ import annotations
 
 import abc
 import logging
-from typing import Dict, Iterable, Iterator, Optional, Tuple
+from typing import Dict, Final, Iterable, Iterator, Optional, Tuple
 
 from ordered_set import OrderedSet
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.flags.base import Flags, FlagsData, Freezable
@@ -25,6 +26,29 @@ class ChromeFlags(Flags):
   """
   _JS_FLAG = "--js-flags"
 
+  # All flags that might affect how finch / field-trials are loaded.
+  FIELD_TRIAL_FLAGS: Final[Tuple[str, ...]] = (
+      "--force-fieldtrials",
+      "--variations-server-url",
+      "--variations-insecure-server-url",
+      "--variations-test-seed-path",
+      "--enable-field-trial-config",
+      "--disable-variations-safe-mode",
+      # The benchmarking flag without value is a no-experiment flag. However,
+      # when used as '--enable-benchmarking=enable-field-trial-config' it
+      # works with experiments.
+      "--enable-benchmarking",
+  )
+
+  NO_EXPERIMENTS_FLAGS: Final[Tuple[str, ...]] = (
+      "--no-experiments",
+      # The benchmarking flag without value is a no-experiment flag. However,
+      # when used as '--enable-benchmarking=enable-field-trial-config' it
+      # works with experiments.
+      "--enable-benchmarking",
+      "--disable-field-trial-config",
+  )
+
   def __init__(self, initial_data: FlagsData = None) -> None:
     self._features = ChromeFeatures()
     self._blink_features = ChromeBlinkFeatures()
@@ -52,10 +76,11 @@ class ChromeFlags(Flags):
       return self._blink_features.disabled_str()
     return super().__getitem__(key)
 
+  @override
   def _set(self,
            flag_name: str,
            flag_value: Optional[str] = None,
-           override: bool = False) -> None:
+           should_override: bool = False) -> None:
     self.assert_not_frozen()
     # pylint: disable=signature-differs
     if flag_name == ChromeFeatures.ENABLE_FLAG:
@@ -81,15 +106,16 @@ class ChromeFlags(Flags):
     elif flag_name == self._JS_FLAG:
       if flag_value is None:
         raise ValueError(f"{self._JS_FLAG} cannot be None")
-      self._set_js_flag(flag_value, override)
+      self._set_js_flag(flag_value, should_override)
     else:
       flag_value = self._verify_flag(flag_name, flag_value)
-      super()._set(flag_name, flag_value, override)
+      super()._set(flag_name, flag_value, should_override)
 
-  def _set_js_flag(self, raw_js_flags: str, override: bool) -> None:
+  def _set_js_flag(self, raw_js_flags: str, should_override: bool) -> None:
     new_js_flags = JSFlags(self._js_flags)
     for js_flag_name, js_flag_value in JSFlags.parse(raw_js_flags).items():
-      new_js_flags.set(js_flag_name, js_flag_value, override=override)
+      new_js_flags.set(
+          js_flag_name, js_flag_value, should_override=should_override)
     self._js_flags.update(new_js_flags)
 
   def _verify_flag(self, name: str, value: Optional[str]) -> Optional[str]:
@@ -151,6 +177,36 @@ class ChromeFlags(Flags):
   def js_flags(self) -> JSFlags:
     return self._js_flags
 
+  def has_enable_benchmarking_field_trials(self):
+    # Enable the benchmarking extension with field trial configs which
+    # requires a special value. See `ShouldUseFieldTrialTestingConfig()`.
+    # https://crsrc.org/c/components/variations/service/variations_field_trial_creator_base.cc;l=138;drc=27d34700b83f381c62e3a348de2e6dfdc08364b8
+    return self.get("--enable-benchmarking") == "enable-field-trial-config"
+
+  @property
+  def field_trial_flags(self) -> ChromeFlags:
+    filtered = self.filtered(self.FIELD_TRIAL_FLAGS)
+    if "--enable-benchmarking" in self and (
+        not self.has_enable_benchmarking_field_trials()):
+      del filtered["--enable-benchmarking"]
+    return filtered
+
+  @property
+  def no_experiments_flags(self) -> ChromeFlags:
+    filtered = self.filtered(self.NO_EXPERIMENTS_FLAGS)
+    # Special case for --enable-benchmarking which disables field trials
+    # by default, unless it has a "enable-field-trial-config" value.
+    if self.has_enable_benchmarking_field_trials():
+      del filtered["--enable-benchmarking"]
+    return filtered
+
+  def enable_benchmarking_extension(self) -> None:
+    if self.field_trial_flags:
+      self.set("--enable-benchmarking", "enable-field-trial-config")
+    else:
+      self.set("--enable-benchmarking")
+
+  @override
   def merge(self, other: FlagsData) -> None:
     if not isinstance(other, ChromeFlags):
       other = ChromeFlags(other)
@@ -163,7 +219,8 @@ class ChromeFlags(Flags):
   def base_items(self) -> Iterable[Tuple[str, Optional[str]]]:
     yield from super().items()
 
-  def items(self) -> Iterable[Tuple[str, Optional[str]]]:
+  @override
+  def items(self) -> Iterable[Tuple[str, Optional[str]]]:  # type: ignore
     yield from self.base_items()
     if self._js_flags:
       yield (self._JS_FLAG, str(self.js_flags))
@@ -181,7 +238,7 @@ class ChromeBaseFeatures(Freezable, abc.ABC):
 
   def __init__(self) -> None:
     super().__init__()
-    self._enabled: Dict[str, Optional[str]] = {}
+    self._enabled: Dict[str, str | None] = {}
     self._disabled: OrderedSet[str] = OrderedSet()
 
   @property
@@ -262,7 +319,7 @@ class ChromeBaseFeatures(Freezable, abc.ABC):
     for flag_name, features_str in self.items():
       yield f"{flag_name}={features_str}"
 
-  def __bool__(self):
+  def __bool__(self) -> bool:
     return bool(self._enabled) or bool(self._disabled)
 
   def __str__(self) -> str:
@@ -283,6 +340,7 @@ class ChromeFeatures(ChromeBaseFeatures):
   ENABLE_FLAG: str = "--enable-features"
   DISABLE_FLAG: str = "--disable-features"
 
+  @override
   def _parse_feature_parts(self, feature: str) -> Tuple[str, Optional[str]]:
     parts = feature.split("<")
     if len(parts) == 2:
@@ -309,6 +367,7 @@ class ChromeBlinkFeatures(ChromeBaseFeatures):
   ENABLE_FLAG: str = "--enable-blink-features"
   DISABLE_FLAG: str = "--disable-blink-features"
 
+  @override
   def _parse_feature_parts(self, feature: str) -> Tuple[str, Optional[str]]:
     if "<" in feature or ":" in feature:
       raise ValueError("blink features do not have params, "
diff --git a/crossbench/flags/js_flags.py b/crossbench/flags/js_flags.py
index f76196fb..52c826b5 100644
--- a/crossbench/flags/js_flags.py
+++ b/crossbench/flags/js_flags.py
@@ -5,7 +5,9 @@
 from __future__ import annotations
 
 import re
-from typing import Optional
+from typing import Optional, Self
+
+from typing_extensions import override
 
 from crossbench.flags.base import Flags
 
@@ -31,21 +33,20 @@ class JSFlags(Flags):
                          fr"{_END_OR_SEPARATOR_PATTERN}")
 
   @classmethod
-  def parse_str(cls, raw_flags: str) -> JSFlags:
+  @override
+  def parse_str(cls, raw_flags: str) -> Self:
     return cls._parse_str(raw_flags, "--js-flags")
 
-  def copy(self) -> JSFlags:
-    return self.__class__(self)
-
+  @override
   def _set(self,
            flag_name: str,
            flag_value: Optional[str] = None,
-           override: bool = False) -> None:
+           should_override: bool = False) -> None:
     self._validate_js_flag_name(flag_name)
     if flag_value is not None:
       self._validate_js_flag_value(flag_name, flag_value)
-    self._check_negated_flag(flag_name, override)
-    super()._set(flag_name, flag_value, override)
+    self._check_negated_flag(flag_name, should_override)
+    super()._set(flag_name, flag_value, should_override)
 
   def _validate_js_flag_value(self, flag_name: str, flag_value: str) -> None:
     if not isinstance(flag_value, str):
@@ -67,14 +68,14 @@ class JSFlags(Flags):
       raise ValueError(f"--js-flags: Invalid flag name {repr(flag_name)}. \n"
                        "Check invalid characters in the V8 flag name?")
 
-  def _check_negated_flag(self, flag_name: str, override: bool) -> None:
+  def _check_negated_flag(self, flag_name: str, should_override: bool) -> None:
     if flag_name.startswith(self._NO_PREFIX):
       enabled = flag_name[len(self._NO_PREFIX):]
       # Check for --no-foo form
       if enabled.startswith("-"):
         enabled = enabled[1:]
       enabled = "--" + enabled
-      if override:
+      if should_override:
         del self[enabled]
       elif enabled in self:
         raise ValueError(
@@ -88,7 +89,7 @@ class JSFlags(Flags):
         disabled = f"--no{flag_name[2:]}"
         if disabled not in self:
           return
-      if override:
+      if should_override:
         del self[disabled]
       else:
         raise ValueError(f"Conflicting flag {flag_name}, "
diff --git a/crossbench/helper/__init__.py b/crossbench/helper/__init__.py
index d8dfe438..d271f03d 100644
--- a/crossbench/helper/__init__.py
+++ b/crossbench/helper/__init__.py
@@ -3,437 +3,3 @@
 # found in the LICENSE file.
 
 from __future__ import annotations
-
-import atexit
-import datetime as dt
-import logging
-import os
-import shlex
-import sys
-import textwrap
-import threading
-import time
-import urllib
-import urllib.error
-import urllib.parse as urlparse
-import urllib.request
-from subprocess import Popen, TimeoutExpired
-from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, Iterable,
-                    Iterator, List, Optional, Tuple, Type, TypeVar, Union)
-
-from crossbench import plt
-
-if TYPE_CHECKING:
-  import signal
-
-  from crossbench.path import AnyPath, LocalPath
-
-  InputT = TypeVar("InputT")
-  KeyT = TypeVar("KeyT")
-  GroupT = TypeVar("GroupT")
-  PathT = TypeVar("PathT", bound=AnyPath)
-
-assert hasattr(shlex,
-               "join"), ("Please update to python v3.8 that has shlex.join")
-
-
-
-def group_by(collection: Iterable[InputT],
-             key: Callable[[InputT], KeyT],
-             value: Optional[Callable[[InputT], Any]] = None,
-             group: Optional[Callable[[KeyT], GroupT]] = None,
-             sort_key: Optional[Callable[[Tuple[KeyT, GroupT]], Any]] = str
-            ) -> Dict[KeyT, GroupT]:
-  """
-  Works similar to itertools.groupby but does a global, SQL-style grouping
-  instead of a line-by-line basis like uniq.
-
-  key:   a function that returns the grouping key for a group
-  group: a function that accepts a group_key and returns a group object that
-    has an append() method.
-  """
-  assert key, "No key function provided"
-  key_fn = key
-  value_fn = value or (lambda item: item)
-  group_fn: Callable[[KeyT], GroupT] = group or (lambda key: [])
-  groups: Dict[KeyT, GroupT] = {}
-  for input_item in collection:
-    group_key: KeyT = key_fn(input_item)
-    group_item = value_fn(input_item)
-    if group_key not in groups:
-      new_group: GroupT = group_fn(group_key)
-      groups[group_key] = new_group
-      new_group.append(group_item)
-    else:
-      groups[group_key].append(group_item)
-  if sort_key:
-    # sort keys as well for more predictable behavior
-    return dict(sorted(groups.items(), key=sort_key))
-  return dict(groups.items())
-
-
-def sort_by_file_size(files: Iterable[PathT],
-                      platform: plt.Platform = plt.PLATFORM) -> List[PathT]:
-  return sorted(files, key=lambda f: (platform.file_size(f), f.name))
-
-
-SIZE_UNITS: Final[Tuple[str, ...]] = ("B", "KiB", "MiB", "GiB", "TiB")
-
-
-def get_file_size(file: AnyPath,
-                  digits: int = 2,
-                  platform: plt.Platform = plt.PLATFORM) -> str:
-  size: float = float(platform.file_size(file))
-  unit_index = 0
-  divisor = 1024.0
-  while (unit_index < len(SIZE_UNITS)) and size >= divisor:
-    unit_index += 1
-    size /= divisor
-  return f"{size:.{digits}f} {SIZE_UNITS[unit_index]}"
-
-# =============================================================================
-
-
-def urlopen(url: str, timeout: Union[int, float] = 10):
-  try:
-    logging.debug("Opening url: %s", url)
-    return urllib.request.urlopen(url, timeout=timeout)
-  except (urllib.error.HTTPError, urllib.error.URLError) as e:
-    logging.info("Could not load url=%s", url)
-    raise e
-
-
-# =============================================================================
-
-
-class ChangeCWD:
-
-  def __init__(self, destination: LocalPath) -> None:
-    self.new_dir = destination
-    self.prev_dir: Optional[str] = None
-
-  def __enter__(self) -> None:
-    self.prev_dir = os.getcwd()
-    os.chdir(self.new_dir)
-    logging.debug("CWD=%s", self.new_dir)
-
-  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
-    assert self.prev_dir, "ChangeCWD was not entered correctly."
-    os.chdir(self.prev_dir)
-
-
-class SystemSleepPreventer:
-  """
-  Prevent the system from going to sleep while running the benchmark.
-  """
-
-  def __init__(self) -> None:
-    self._process: Optional[Popen] = None
-
-  def __enter__(self) -> None:
-    if plt.PLATFORM.is_macos:
-      self._process = plt.PLATFORM.popen("caffeinate", "-imdsu")
-      atexit.register(self.stop_process)
-    # TODO: Add linux support
-
-  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
-    self.stop_process()
-
-  def stop_process(self) -> None:
-    if self._process:
-      self._process.kill()
-      self._process = None
-
-
-class TimeScope:
-  """
-  Measures and logs the time spend during the lifetime of the TimeScope.
-  """
-
-  def __init__(self, message: str, level: int = 3) -> None:
-    self._message = message
-    self._level = level
-    self._start: Optional[dt.datetime] = None
-    self._duration: dt.timedelta = dt.timedelta()
-
-  @property
-  def message(self) -> str:
-    return self._message
-
-  @property
-  def duration(self) -> dt.timedelta:
-    return self._duration
-
-  def __enter__(self) -> TimeScope:
-    self._start = dt.datetime.now()
-    return self
-
-  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
-    assert self._start
-    self._duration = dt.datetime.now() - self._start
-    logging.log(self._level, "%s duration=%s", self._message, self._duration)
-
-
-def as_timedelta(value: Union[int, float, dt.timedelta]) -> dt.timedelta:
-  if isinstance(value, dt.timedelta):
-    return value
-  return dt.timedelta(seconds=value)
-
-
-class WaitRange:
-  """
-  Create wait/sleep ranges with the given parameters:
-
-  If present we start with the initial delay, and then exponentially
-  increase the sleep/wait time by the given factor, until we reach the max
-  sleep time.
-
-  | delay | min | min * factor | ... | min * factor ** N | max | ... | max |
-  | ----------------------------- timeout ---------------------------------|
-
-  The timeout puts an upper bound to the total sleep time when using
-  wait_with_backoff().
-  """
-  min: dt.timedelta
-  max: dt.timedelta
-  initial_sleep: dt.timedelta
-  max_iterations: Optional[int]
-
-  def __init__(
-      self,
-      min: Union[int, float, dt.timedelta] = 0.1,  # pylint: disable=redefined-builtin
-      timeout: Union[int, float, dt.timedelta] = 10,
-      factor: float = 1.01,
-      max: Optional[Union[int, float, dt.timedelta]] = None,  # pylint: disable=redefined-builtin
-      max_iterations: Optional[int] = None,
-      delay: Union[int, float, dt.timedelta] = 0) -> None:
-    self.min = as_timedelta(min)
-    assert self.min.total_seconds() > 0
-    if not max:
-      self.max = self.min * 10
-    else:
-      self.max = as_timedelta(max)
-    assert self.min <= self.max
-    assert 1.0 < factor
-    self.factor = factor
-    self.timeout = as_timedelta(timeout)
-    assert 0 < self.timeout.total_seconds()
-    self.delay = as_timedelta(delay)
-    assert self.delay <= self.timeout
-    assert max_iterations is None or max_iterations > 0
-    self.max_iterations = max_iterations
-
-  def __iter__(self) -> Iterator[dt.timedelta]:
-    i = 0
-    if self.delay:
-      yield self.delay
-    current_sleep = self.min
-    while self.max_iterations is None or i < self.max_iterations:
-      yield current_sleep
-      current_sleep = min(current_sleep * self.factor, self.max)
-      i += 1
-
-  def wait_with_backoff(
-      self,
-      platform: plt.Platform = plt.PLATFORM) -> Iterator[Tuple[float, float]]:
-    start = dt.datetime.now()
-    timeout = self.timeout
-    for sleep_for in self:
-      duration = dt.datetime.now() - start
-      if duration > self.timeout:
-        raise TimeoutError(f"Waited for {duration}")
-      time_left = timeout - duration
-      yield duration.total_seconds(), time_left.total_seconds()
-      platform.sleep(sleep_for.total_seconds())
-
-
-def wait_with_backoff(
-    wait_range: Union[int, float, dt.timedelta, WaitRange],
-    platform: plt.Platform = plt.PLATFORM) -> Iterator[Tuple[float, float]]:
-  if not isinstance(wait_range, WaitRange):
-    wait_range = WaitRange(timeout=wait_range)
-  return wait_range.wait_with_backoff(platform)
-
-
-class DurationMeasureContext:
-
-  def __init__(self, durations: Durations, name: str) -> None:
-    self._start_time = dt.datetime.utcfromtimestamp(0)
-    self._durations = durations
-    self._name = name
-
-  def __enter__(self) -> DurationMeasureContext:
-    self._start_time = dt.datetime.now()
-    return self
-
-  def __exit__(self, exc_type, exc_value, traceback) -> None:
-    assert self._start_time
-    delta = dt.datetime.now() - self._start_time
-    self._durations[self._name] = delta
-
-
-class Durations:
-  """
-  Helper object to track durations.
-  """
-
-  def __init__(self) -> None:
-    self._durations: Dict[str, dt.timedelta] = {}
-
-  def __getitem__(self, name: str) -> dt.timedelta:
-    return self._durations[name]
-
-  def __setitem__(self, name: str, duration: dt.timedelta) -> None:
-    assert name not in self._durations, f"Cannot set '{name}' duration twice!"
-    self._durations[name] = duration
-
-  def __len__(self) -> int:
-    return len(self._durations)
-
-  def measure(self, name: str) -> DurationMeasureContext:
-    assert name not in self._durations, (
-        f"Cannot measure '{name}' duration twice!")
-    return DurationMeasureContext(self, name)
-
-  def to_json(self) -> Dict[str, float]:
-    return {
-        name: self._durations[name].total_seconds()
-        for name in sorted(self._durations.keys())
-    }
-
-
-def wrap_lines(body: str, width: int = 80, indent: str = "") -> Iterable[str]:
-  for line in body.splitlines():
-    if len(line) <= width:
-      yield f"{indent}{line}"
-      continue
-    for split in textwrap.wrap(line, width):
-      yield f"{indent}{split}"
-
-
-def type_name(t: Type) -> str:
-  module = t.__module__
-  if not module:
-    return t.__qualname__
-  return f"{module}.{t.__qualname__}"
-
-
-class Spinner:
-  CURSORS = ""
-
-  def __init__(self, sleep: float = 0.5) -> None:
-    self._is_running = False
-    self._sleep_time = sleep
-
-  def __enter__(self) -> None:
-    # Only enable the spinner if the output is an interactive terminal.
-    is_atty = hasattr(sys.stdout, "isatty") and sys.stdout.isatty()
-    if is_atty:
-      self._is_running = True
-      threading.Thread(target=self._spin).start()
-
-  def __exit__(self, exc_type, exc_value, traceback) -> None:
-    if self._is_running:
-      self._is_running = False
-      self._sleep()
-
-  def _cursors(self) -> Iterable[str]:
-    while True:
-      yield from Spinner.CURSORS
-
-  def _spin(self) -> None:
-    stdout = sys.stdout
-    for cursor in self._cursors():
-      if not self._is_running:
-        return
-      # Print the current wait-cursor and send a carriage return to move to the
-      # start of the line.
-      stdout.write(f" {cursor}\r")
-      stdout.flush()
-      self._sleep()
-
-  def _sleep(self) -> None:
-    time.sleep(self._sleep_time)
-
-
-
-def update_url_query(url: str, query_params: Dict[str, str]) -> str:
-  parsed_url = urlparse.urlparse(url)
-  query = dict(urlparse.parse_qsl(parsed_url.query))
-  query.update(query_params)
-  parsed_url = parsed_url._replace(query=urlparse.urlencode(query, doseq=True))
-  return parsed_url.geturl()
-
-
-def wait_and_kill(process: Popen,
-                  timeout=1,
-                  signal: Optional[signal.Signals] = None) -> None:
-  """Graceful process termination:
-  1. Send signal if provided,
-  2. wait for the given time,
-  3. terminate(),
-  4. Last stage: kill process.
-  """
-  logging.debug("wait_and_kill: %s", process)
-  try:
-    wait_and_terminate(process, timeout, signal)
-  finally:
-    try:
-      process.kill()
-    except ProcessLookupError:
-      pass
-
-
-def wait_and_terminate(process,
-                       timeout=1,
-                       signal: Optional[signal.Signals] = None) -> None:
-  if process.poll() is not None:
-    return
-  logging.debug("Terminating process: %s", process)
-  try:
-    if signal:
-      process.send_signal(signal)
-    process.wait(timeout)
-    return
-  except TimeoutExpired as e:
-    logging.debug("Got timeout while waiting "
-                  "for process shutdown (%s): %s", process, e)
-  except Exception as e:  # pylint: disable=broad-except
-    logging.debug("Ignoring exception during process termination: %s", e)
-  finally:
-    try:
-      process.terminate()
-    except ProcessLookupError:
-      pass
-
-
-class RepeatTimer(threading.Timer):
-
-  def run(self) -> None:
-    while not self.finished.wait(self.interval):
-      self.function(*self.args, **self.kwargs)
-
-  def __enter__(self, *args, **kwargs):
-    self.start()
-
-  def __exit__(self, *args, **kwargs):
-    self.cancel()
-
-
-def input_with_timeout(timeout=dt.timedelta(seconds=10), default=None):
-  result_container = [default]
-  wait = threading.Thread(
-      target=_input, args=[
-          result_container,
-      ])
-  wait.daemon = True
-  wait.start()
-  wait.join(timeout=timeout.total_seconds())
-  return result_container[0]
-
-
-def _input(results_container):
-  try:
-    results_container[0] = input()
-  except KeyboardInterrupt:
-    pass
diff --git a/crossbench/helper/collection_helper.py b/crossbench/helper/collection_helper.py
new file mode 100644
index 00000000..ce843108
--- /dev/null
+++ b/crossbench/helper/collection_helper.py
@@ -0,0 +1,52 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterable, Optional,
+                    Tuple, TypeVar)
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath
+
+  InputT = TypeVar("InputT")
+  KeyT = TypeVar("KeyT")
+  GroupT = TypeVar("GroupT")
+  PathT = TypeVar("PathT", bound=AnyPath)
+
+
+def group_by(
+    collection: Iterable[InputT],
+    key: Callable[[InputT], KeyT],
+    value: Optional[Callable[[InputT], Any]] = None,
+    group: Optional[Callable[[KeyT], GroupT]] = None,
+    sort_key: Optional[Callable[[Tuple[KeyT, GroupT]], Any]] = str
+) -> Dict[KeyT, GroupT]:
+  """
+  Works similar to itertools.groupby but does a global, SQL-style grouping
+  instead of a line-by-line basis like uniq.
+
+  key:   a function that returns the grouping key for a group
+  group: a function that accepts a group_key and returns a group object that
+    has an append() method.
+  """
+  if not key:  # type: ignore
+    raise ValueError("No key function provided")
+  key_fn = key
+  value_fn = value or (lambda item: item)
+  group_fn: Callable[[KeyT], GroupT] = group or (lambda key: [])  # type: ignore
+  groups: Dict[KeyT, GroupT] = {}
+  for input_item in collection:
+    group_key: KeyT = key_fn(input_item)
+    group_item = value_fn(input_item)
+    if group_key not in groups:
+      new_group: GroupT = group_fn(group_key)
+      groups[group_key] = new_group
+      new_group.append(group_item)  # type: ignore
+    else:
+      groups[group_key].append(group_item)  # type: ignore
+  if sort_key:
+    # sort keys as well for more predictable behavior
+    return dict(sorted(groups.items(), key=sort_key))
+  return dict(groups.items())
diff --git a/crossbench/helper/cwd.py b/crossbench/helper/cwd.py
new file mode 100644
index 00000000..e17a04ef
--- /dev/null
+++ b/crossbench/helper/cwd.py
@@ -0,0 +1,28 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+import os
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.path import LocalPath
+
+
+class ChangeCWD:
+
+  def __init__(self, destination: LocalPath) -> None:
+    self.new_dir = destination
+    self.prev_dir: str | None = None
+
+  def __enter__(self) -> None:
+    self.prev_dir = os.getcwd()
+    os.chdir(self.new_dir)
+    logging.debug("CWD=%s", self.new_dir)
+
+  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+    assert self.prev_dir, "ChangeCWD was not entered correctly."
+    os.chdir(self.prev_dir)
diff --git a/crossbench/helper/durations.py b/crossbench/helper/durations.py
new file mode 100644
index 00000000..42395748
--- /dev/null
+++ b/crossbench/helper/durations.py
@@ -0,0 +1,85 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+from typing import Dict
+
+
+class DurationMeasureContext:
+
+  def __init__(self, durations: Durations, name: str) -> None:
+    self._start_time = dt.datetime.utcfromtimestamp(0)
+    self._durations = durations
+    self._name = name
+
+  def __enter__(self) -> DurationMeasureContext:
+    self._start_time = dt.datetime.now()
+    return self
+
+  def __exit__(self, exc_type, exc_value, traceback) -> None:
+    assert self._start_time
+    delta = dt.datetime.now() - self._start_time
+    self._durations[self._name] = delta
+
+
+class Durations:
+  """
+  Helper object to track durations.
+  """
+
+  def __init__(self) -> None:
+    self._durations: Dict[str, dt.timedelta] = {}
+
+  def __getitem__(self, name: str) -> dt.timedelta:
+    return self._durations[name]
+
+  def __setitem__(self, name: str, duration: dt.timedelta) -> None:
+    assert name not in self._durations, f"Cannot set '{name}' duration twice!"
+    self._durations[name] = duration
+
+  def __len__(self) -> int:
+    return len(self._durations)
+
+  def measure(self, name: str) -> DurationMeasureContext:
+    assert name not in self._durations, (
+        f"Cannot measure '{name}' duration twice!")
+    return DurationMeasureContext(self, name)
+
+  def to_json(self) -> Dict[str, float]:
+    return {
+        name: self._durations[name].total_seconds()
+        for name in sorted(self._durations.keys())
+    }
+
+
+class TimeScope:
+  """
+  Measures and logs the time spend during the lifetime of the TimeScope.
+  """
+
+  def __init__(self, message: str, level: int = 3) -> None:
+    self._message = message
+    self._level = level
+    self._start: dt.datetime | None = None
+    self._duration: dt.timedelta = dt.timedelta()
+
+  @property
+  def message(self) -> str:
+    return self._message
+
+  @property
+  def duration(self) -> dt.timedelta:
+    return self._duration
+
+  def __enter__(self) -> TimeScope:
+    self._start = dt.datetime.now()
+    return self
+
+  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+    assert self._start
+    self._duration = dt.datetime.now() - self._start
+    logging.log(self._level, "%s duration=%s", self._message, self._duration)
diff --git a/crossbench/helper/fs_helper.py b/crossbench/helper/fs_helper.py
new file mode 100644
index 00000000..056ba32d
--- /dev/null
+++ b/crossbench/helper/fs_helper.py
@@ -0,0 +1,36 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import (TYPE_CHECKING, Final, Iterable, List, Optional, Tuple,
+                    TypeVar)
+
+from crossbench import plt
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath
+  PathT = TypeVar("PathT", bound=AnyPath)
+
+
+def sort_by_file_size(files: Iterable[PathT],
+                      platform: Optional[plt.Platform] = None) -> List[PathT]:
+  real_platform = platform or plt.PLATFORM
+  return sorted(files, key=lambda f: (real_platform.file_size(f), f.name))
+
+
+SIZE_UNITS: Final[Tuple[str, ...]] = ("B", "KiB", "MiB", "GiB", "TiB")
+
+
+def get_file_size(file: AnyPath,
+                  digits: int = 2,
+                  platform: Optional[plt.Platform] = None) -> str:
+  real_platform = platform or plt.PLATFORM
+  size: float = float(real_platform.file_size(file))
+  unit_index = 0
+  divisor = 1024.0
+  while (unit_index < len(SIZE_UNITS)) and size >= divisor:
+    unit_index += 1
+    size /= divisor
+  return f"{size:.{digits}f} {SIZE_UNITS[unit_index]}"
diff --git a/crossbench/helper/input_helper.py b/crossbench/helper/input_helper.py
new file mode 100644
index 00000000..65164b31
--- /dev/null
+++ b/crossbench/helper/input_helper.py
@@ -0,0 +1,28 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import threading
+
+
+def input_with_timeout(
+    timeout: dt.timedelta = dt.timedelta(seconds=10), default=None):
+  result_container = [default]
+  wait = threading.Thread(
+      target=_input, args=[
+          result_container,
+      ])
+  wait.daemon = True
+  wait.start()
+  wait.join(timeout=timeout.total_seconds())
+  return result_container[0]
+
+
+def _input(results_container) -> None:
+  try:
+    results_container[0] = input()
+  except KeyboardInterrupt:
+    pass
diff --git a/crossbench/helper/path_finder.py b/crossbench/helper/path_finder.py
index 9e0f92b2..17f76f59 100644
--- a/crossbench/helper/path_finder.py
+++ b/crossbench/helper/path_finder.py
@@ -8,6 +8,8 @@ import abc
 import logging
 from typing import TYPE_CHECKING, Iterator, Optional, Tuple
 
+from typing_extensions import override
+
 from crossbench import path as pth
 
 if TYPE_CHECKING:
@@ -21,7 +23,7 @@ class BaseToolFinder(abc.ABC):
                                                   ...] = tuple()) -> None:
     self._platform = platform
     self._candidates = candidates + self.default_candidates()
-    self._path: Optional[pth.AnyPath] = self._find_path()
+    self._path: pth.AnyPath | None = self._find_path()
     if self._path:
       assert self.is_valid_path(self._path)
 
@@ -92,9 +94,11 @@ class ChromiumCheckoutFinder(BaseToolFinder):
   """Finds a chromium src checkout at either given locations or at
   some preset known checkout locations."""
 
+  @override
   def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
     return default_chromium_candidates(self.platform)
 
+  @override
   def is_valid_path(self, candidate: pth.AnyPath) -> bool:
     return is_chromium_checkout_dir(self.platform, candidate)
 
@@ -127,12 +131,14 @@ class ChromiumBuildBinaryFinder(BaseToolFinder):
       for build in ("Release", "release", "rel", "Optdebug", "optdebug", "opt"):
         yield candidate_out / build / self._binary_name
 
+  @override
   def _find_path(self) -> Optional[pth.AnyPath]:
     for candidate in self._iterate_candidate_bin_paths():
       if self.is_valid_path(candidate):
         return candidate
     return None
 
+  @override
   def is_valid_path(self, candidate: pth.AnyPath) -> bool:
     assert candidate.name == self._binary_name
     if not self.platform.is_file(candidate):
@@ -145,6 +151,7 @@ class ChromiumBuildBinaryFinder(BaseToolFinder):
 
 class V8CheckoutFinder(BaseToolFinder):
 
+  @override
   def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
     if self.platform.is_android:
       return ()
@@ -160,6 +167,7 @@ class V8CheckoutFinder(BaseToolFinder):
         self._platform.path("C:/src/v8/"),
     )
 
+  @override
   def _find_path(self) -> Optional[pth.AnyPath]:
     if v8_checkout := super()._find_path():
       return v8_checkout
@@ -173,6 +181,7 @@ class V8CheckoutFinder(BaseToolFinder):
         return candidate_dir
     return None
 
+  @override
   def is_valid_path(self, candidate: pth.AnyPath) -> bool:
     v8_header_file = candidate / "include/v8.h"
     return (self.platform.is_file(v8_header_file) and
@@ -189,13 +198,13 @@ class V8ToolsFinder:
                d8_binary: Optional[pth.AnyPath] = None,
                v8_checkout: Optional[pth.AnyPath] = None) -> None:
     self.platform = platform
-    self.d8_binary: Optional[pth.AnyPath] = d8_binary
-    self.v8_checkout: Optional[pth.AnyPath] = None
+    self.d8_binary: pth.AnyPath | None = d8_binary
+    self.v8_checkout: pth.AnyPath | None = None
     if v8_checkout:
       self.v8_checkout = v8_checkout
     else:
       self.v8_checkout = V8CheckoutFinder(self.platform).path
-    self.tick_processor: Optional[pth.AnyPath] = None
+    self.tick_processor: pth.AnyPath | None = None
     self.d8_binary = self._find_d8()
     if self.d8_binary:
       self.tick_processor = self._find_v8_tick_processor()
@@ -256,6 +265,7 @@ class V8ToolsFinder:
 
 class BaseChromiumBinaryToolFinder(BaseToolFinder):
 
+  @override
   def is_valid_path(self, candidate: pth.AnyPath) -> bool:
     return self._platform.is_file(candidate)
 
@@ -263,6 +273,7 @@ class BaseChromiumBinaryToolFinder(BaseToolFinder):
   def chrome_path(cls) -> pth.AnyPath:
     raise NotImplementedError()
 
+  @override
   def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
     relative_path = chromium_src_relative_local_path() / self.chrome_path()
     if maybe_chrome := ChromiumCheckoutFinder(self._platform).path:
@@ -270,18 +281,45 @@ class BaseChromiumBinaryToolFinder(BaseToolFinder):
     return (relative_path,)
 
 
-class TraceconvFinder(BaseChromiumBinaryToolFinder):
+class PerfettoToolFinder(BaseChromiumBinaryToolFinder, metaclass=abc.ABCMeta):
+
+  @classmethod
+  @abc.abstractmethod
+  def default_binary_name(cls) -> str:
+    pass
+
+  @classmethod
+  def perfetto_tools_dir(cls) -> pth.AnyPath:
+    return pth.AnyPath("third_party/perfetto/tools")
 
   @classmethod
+  @override
   def chrome_path(cls) -> pth.AnyPath:
-    return pth.AnyPath("third_party/perfetto/tools/traceconv")
+    return cls.perfetto_tools_dir() / cls.default_binary_name()
 
 
-class TraceProcessorFinder(BaseChromiumBinaryToolFinder):
+class TraceconvFinder(PerfettoToolFinder):
 
   @classmethod
-  def chrome_path(cls) -> pth.AnyPath:
-    return pth.AnyPath("third_party/perfetto/tools/trace_processor")
+  @override
+  def default_binary_name(cls) -> str:
+    return "traceconv"
+
+
+class TraceboxFinder(PerfettoToolFinder):
+
+  @classmethod
+  @override
+  def default_binary_name(cls) -> str:
+    return "tracebox"
+
+
+class TraceProcessorFinder(PerfettoToolFinder):
+
+  @classmethod
+  @override
+  def default_binary_name(cls) -> str:
+    return "trace_processor"
 
 
 CROSSBENCH_DIR = pth.LocalPath(__file__).parents[2]
@@ -289,6 +327,7 @@ CROSSBENCH_DIR = pth.LocalPath(__file__).parents[2]
 
 class BaseCrossbenchBinaryToolFinder(BaseChromiumBinaryToolFinder):
 
+  @override
   def default_candidates(self) -> Tuple[pth.AnyPath, ...]:
     candidates = super().default_candidates()
     return (CROSSBENCH_DIR / self.crossbench_path(),) + candidates
@@ -302,10 +341,12 @@ class BaseCrossbenchBinaryToolFinder(BaseChromiumBinaryToolFinder):
 class WprGoToolFinder(BaseCrossbenchBinaryToolFinder):
 
   @classmethod
+  @override
   def chrome_path(cls) -> pth.AnyPath:
     return pth.AnyPath("third_party/catapult/web_page_replay_go/src/wpr.go")
 
   @classmethod
+  @override
   def crossbench_path(cls) -> pth.AnyPath:
     return pth.AnyPath("third_party/webpagereplay/src/wpr.go")
 
@@ -313,9 +354,11 @@ class WprGoToolFinder(BaseCrossbenchBinaryToolFinder):
 class TsProxyFinder(BaseCrossbenchBinaryToolFinder):
 
   @classmethod
+  @override
   def chrome_path(cls) -> pth.AnyPath:
     return pth.AnyPath("third_party/catapult/third_party/tsproxy/tsproxy.py")
 
   @classmethod
+  @override
   def crossbench_path(cls) -> pth.AnyPath:
     return pth.AnyPath("third_party/tsproxy/tsproxy.py")
diff --git a/crossbench/helper/sleep_preventer.py b/crossbench/helper/sleep_preventer.py
new file mode 100644
index 00000000..cad9c3fb
--- /dev/null
+++ b/crossbench/helper/sleep_preventer.py
@@ -0,0 +1,38 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from subprocess import Popen
+
+  from crossbench import plt
+
+
+class SystemSleepPreventer:
+  """
+  Prevent the system from going to sleep while running the benchmark.
+  """
+
+  def __init__(self, platform: plt.Platform) -> None:
+    self._process: Popen | None = None
+    self._platform = platform
+
+  def __enter__(self) -> None:
+    if self._platform.is_macos:
+      self._process = self._platform.popen("caffeinate", "-imdsu")
+      atexit.register(self.stop_process)
+    # TODO: Add linux support
+
+  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+    self.stop_process()
+
+  def stop_process(self) -> None:
+    atexit.unregister(self.stop_process)
+    if self._process:
+      self._process.kill()
+      self._process = None
diff --git a/crossbench/helper/spinner.py b/crossbench/helper/spinner.py
new file mode 100644
index 00000000..b76f6258
--- /dev/null
+++ b/crossbench/helper/spinner.py
@@ -0,0 +1,48 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import sys
+import threading
+import time
+from typing import Iterable
+
+
+class Spinner:
+  CURSORS = ""
+
+  def __init__(self, sleep: float = 0.5) -> None:
+    self._is_running = False
+    self._sleep_time = sleep
+
+  def __enter__(self) -> None:
+    # Only enable the spinner if the output is an interactive terminal.
+    is_atty = hasattr(sys.stdout, "isatty") and sys.stdout.isatty()
+    if is_atty:
+      self._is_running = True
+      threading.Thread(target=self._spin).start()
+
+  def __exit__(self, exc_type, exc_value, traceback) -> None:
+    if self._is_running:
+      self._is_running = False
+      self._sleep()
+
+  def _cursors(self) -> Iterable[str]:
+    while True:
+      yield from Spinner.CURSORS
+
+  def _spin(self) -> None:
+    stdout = sys.stdout
+    for cursor in self._cursors():
+      if not self._is_running:
+        return
+      # Print the current wait-cursor and send a carriage return to move to the
+      # start of the line.
+      stdout.write(f" {cursor}\r")
+      stdout.flush()
+      self._sleep()
+
+  def _sleep(self) -> None:
+    time.sleep(self._sleep_time)
diff --git a/crossbench/helper/state.py b/crossbench/helper/state.py
index eb962e16..7ff1926f 100644
--- a/crossbench/helper/state.py
+++ b/crossbench/helper/state.py
@@ -83,4 +83,4 @@ class StateMachine(Generic[StateT]):
       raise UnexpectedStateError(self._state, valid_states)
 
   def __str__(self) -> str:
-    return f"{self._state}"
+    return self._state.name
diff --git a/crossbench/helper/txt_helper.py b/crossbench/helper/txt_helper.py
new file mode 100644
index 00000000..c82784f2
--- /dev/null
+++ b/crossbench/helper/txt_helper.py
@@ -0,0 +1,24 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import textwrap
+from typing import Iterable, Type
+
+
+def wrap_lines(body: str, width: int = 80, indent: str = "") -> Iterable[str]:
+  for line in body.splitlines():
+    if len(line) <= width:
+      yield f"{indent}{line}"
+      continue
+    for split in textwrap.wrap(line, width):
+      yield f"{indent}{split}"
+
+
+def type_name(t: Type) -> str:
+  module = t.__module__
+  if not module:
+    return t.__qualname__
+  return f"{module}.{t.__qualname__}"
diff --git a/crossbench/helper/url_helper.py b/crossbench/helper/url_helper.py
new file mode 100644
index 00000000..9a765b14
--- /dev/null
+++ b/crossbench/helper/url_helper.py
@@ -0,0 +1,97 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+import urllib.parse as urlparse
+from typing import Any, Dict, Iterator, Mapping, Optional
+
+import requests
+
+from crossbench.helper import wait
+from crossbench.runner.timing import AnyTime
+
+DEFAULT_REQUEST_TIMEOUT = dt.timedelta(seconds=10)
+
+RequestException = requests.RequestException
+HTTPError = requests.HTTPError
+ConnectionError = requests.ConnectionError  # pylint: disable=redefined-builtin
+
+Response = requests.Response
+
+
+def get(url: str,
+        timeout: AnyTime = DEFAULT_REQUEST_TIMEOUT,
+        retry: int = 0,
+        verbose: bool = True) -> requests.Response:
+  max_request_count = retry + 1
+  request_timeout_seconds = to_seconds(timeout) / max_request_count
+  for i in _retry(retry):
+    try:
+      if verbose:
+        logging.debug("GET: url: %s", url)
+      response = requests.get(url, timeout=request_timeout_seconds)
+      response.raise_for_status()
+      return response
+    except requests.RequestException as e:
+      if i < retry:
+        if verbose:
+          logging.warning("GET request failed url=%s, retrying: %s", url, e)
+        continue
+      if verbose:
+        logging.error("GET request failed url=%s", url)
+      raise e
+  raise RuntimeError("Could not complete request")
+
+
+def post(url: str,
+         body_json: Optional[Any] = None,
+         headers: Optional[Mapping[str, str]] = None,
+         timeout: AnyTime = DEFAULT_REQUEST_TIMEOUT,
+         retry: int = 0,
+         verbose: bool = True) -> requests.Response:
+  max_request_count = retry + 1
+  request_timeout_seconds = to_seconds(timeout) / max_request_count
+  for i in _retry(retry):
+    try:
+      response = requests.post(
+          url, headers=headers, json=body_json, timeout=request_timeout_seconds)
+      response.raise_for_status()
+      return response
+    except requests.RequestException as e:
+      if i < retry:
+        if verbose:
+          logging.warning("POST request failed url=%s retrying: %s", url, e)
+        continue
+      if verbose:
+        logging.error("POST request failed url=%s", url)
+      raise e
+  raise RuntimeError("Could not complete request")
+
+
+def to_seconds(delta: AnyTime) -> float:
+  if isinstance(delta, dt.timedelta):
+    return delta.total_seconds()
+  return delta
+
+
+def _retry(retry: int) -> Iterator[int]:
+  max_iterations = retry + 1
+  wait_range = wait.WaitRange(min=1, max_iterations=max_iterations)
+  for i, _, _ in wait_range.wait_with_backoff():
+    yield i
+
+
+def update_url_query(url: str, query_params: Dict[str, str]) -> str:
+  parsed_url = urlparse.urlparse(url)
+  query = dict(urlparse.parse_qsl(parsed_url.query))
+  query.update(query_params)
+  parsed_url = parsed_url._replace(query=urlparse.urlencode(query, doseq=True))
+  return parsed_url.geturl()
+
+
+def quote(value: str) -> str:
+  return urlparse.quote(value)
diff --git a/crossbench/helper/wait.py b/crossbench/helper/wait.py
new file mode 100644
index 00000000..4f77cce0
--- /dev/null
+++ b/crossbench/helper/wait.py
@@ -0,0 +1,111 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import datetime as dt
+import logging
+import math
+import time
+from typing import Iterator, Optional, Tuple
+
+from crossbench.runner.timing import AnyTime, AnyTimeUnit
+
+
+def as_timedelta(value: int | float | dt.timedelta) -> dt.timedelta:
+  if isinstance(value, dt.timedelta):
+    return value
+  return dt.timedelta(seconds=value)
+
+
+class WaitRange:
+  """
+  Create wait/sleep ranges with the given parameters:
+
+  If present we start with the initial delay, and then exponentially
+  increase the sleep/wait time by the given factor, until we reach the max
+  sleep time.
+
+  | delay | min | min * factor | ... | min * factor ** N |  ... | max |
+  | --------------------------- timeout ------------------------------|
+  | i=0   | i=1 | i=2          | ............... | i=max_iterations-1 |
+
+  The timeout puts an upper bound to the total sleep time when using
+  wait_with_backoff().
+  """
+
+  def __init__(
+      self,
+      min: AnyTime = 0.1,  # pylint: disable=redefined-builtin
+      timeout: AnyTime = 10,
+      factor: float = 1.01,
+      max: Optional[AnyTime] = None,  # pylint: disable=redefined-builtin
+      max_iterations: int | float = math.inf,
+      delay: AnyTime = 0) -> None:
+    self._min: dt.timedelta = as_timedelta(min)
+    assert self._min.total_seconds() > 0
+    if not max:
+      self._max: dt.timedelta = self._min * 10
+    else:
+      self._max = as_timedelta(max)
+    assert self._min <= self._max
+    assert 1.0 < factor
+    self._factor: float = factor
+    self._timeout: dt.timedelta = as_timedelta(timeout)
+    assert 0 < self._timeout.total_seconds()
+    self._delay = as_timedelta(delay)
+    assert self._delay <= self._timeout
+    assert max_iterations > 0
+    self._max_iterations: int | float = max_iterations
+
+  @property
+  def timeout(self) -> dt.timedelta:
+    return self._timeout
+
+  def __iter__(self) -> Iterator[Tuple[int, dt.timedelta]]:
+    i = 0
+    if self._delay:
+      yield i, self._delay
+      i += 1
+
+    current_sleep = self._min
+    while True:
+      if self._max_iterations <= i:
+        break
+      yield i, current_sleep
+      current_sleep = min(current_sleep * self._factor, self._max)
+      i += 1
+
+  def wait_with_backoff(
+      self,) -> Iterator[Tuple[int, dt.timedelta, dt.timedelta]]:
+    start = dt.datetime.now()
+    timeout = self._timeout
+    for i, sleep_for in self:
+      duration = dt.datetime.now() - start
+      if duration > self._timeout:
+        raise TimeoutError(f"Waited for {duration}")
+      time_left = timeout - duration
+      yield i, duration, time_left
+      sleep_f(sleep_for.total_seconds())
+
+
+def sleep(seconds: AnyTimeUnit) -> None:
+  if isinstance(seconds, dt.timedelta):
+    seconds = seconds.total_seconds()
+  sleep_f(seconds)
+
+
+def sleep_f(seconds: float) -> None:
+  if seconds == 0:
+    return
+  logging.debug("WAIT %ss", seconds)
+  time.sleep(seconds)
+
+
+def wait_with_backoff(
+    wait_range: AnyTime | WaitRange,
+) -> Iterator[Tuple[int, dt.timedelta, dt.timedelta]]:
+  if not isinstance(wait_range, WaitRange):
+    wait_range = WaitRange(timeout=wait_range)
+  return wait_range.wait_with_backoff()
diff --git a/crossbench/network/base.py b/crossbench/network/base.py
index 73aab25a..5e3dc061 100644
--- a/crossbench/network/base.py
+++ b/crossbench/network/base.py
@@ -6,7 +6,7 @@ from __future__ import annotations
 
 import abc
 import contextlib
-from typing import TYPE_CHECKING, Iterator, Optional
+from typing import TYPE_CHECKING, Iterator, Optional, TypeVar
 
 from crossbench import plt
 from crossbench.network.traffic_shaping.live import NoTrafficShaper
@@ -18,11 +18,14 @@ if TYPE_CHECKING:
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
 
+NetworkT = TypeVar("NetworkT", bound="Network")
+
 class Network(abc.ABC):
 
   def __init__(self,
                traffic_shaper: Optional[TrafficShaper] = None,
-               browser_platform: plt.Platform = plt.PLATFORM) -> None:
+               browser_platform: Optional[plt.Platform] = None) -> None:
+    browser_platform = browser_platform or plt.PLATFORM
     self._traffic_shaper = traffic_shaper or NoTrafficShaper(browser_platform)
     self._browser_platform = browser_platform
     self._host_platform = browser_platform.host_platform
@@ -80,7 +83,8 @@ class Network(abc.ABC):
     return self.traffic_shaper.extra_flags(browser_attributes)
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+  def open(self: NetworkT,
+           session: BrowserSessionRunGroup) -> Iterator[NetworkT]:
     del session
     assert not self._is_running, "Cannot start network more than once."
     self._is_running = True
diff --git a/crossbench/network/live.py b/crossbench/network/live.py
index 3c5eeb7b..2538b954 100644
--- a/crossbench/network/live.py
+++ b/crossbench/network/live.py
@@ -5,23 +5,28 @@
 from __future__ import annotations
 
 import contextlib
-from typing import TYPE_CHECKING, Iterator
+from typing import TYPE_CHECKING, Iterator, TypeVar
+
+from typing_extensions import override
 
 from crossbench.network.base import Network
 
 if TYPE_CHECKING:
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
-
+LiveNetworkT = TypeVar("LiveNetworkT", bound="LiveNetwork")
 
 class LiveNetwork(Network):
 
   @property
+  @override
   def is_live(self) -> bool:
     return True
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+  @override
+  def open(self: LiveNetworkT,
+           session: BrowserSessionRunGroup) -> Iterator[LiveNetworkT]:
     with super().open(session):
       with self._traffic_shaper.open(self, session):
         # TODO: implement
diff --git a/crossbench/network/local_file_server.py b/crossbench/network/local_file_server.py
index f40cdda0..b542bd6e 100644
--- a/crossbench/network/local_file_server.py
+++ b/crossbench/network/local_file_server.py
@@ -12,39 +12,48 @@ import logging
 import os
 import threading
 from typing import (TYPE_CHECKING, Final, Iterator, Mapping, Optional, Tuple,
-                    Type)
+                    Type, TypeVar)
 
 from immutabledict import immutabledict
+from typing_extensions import override
 
-from crossbench import plt
 from crossbench.network.base import Network
 from crossbench.parse import ObjectParser
 
 if TYPE_CHECKING:
+  from crossbench import plt
   from crossbench.network.traffic_shaping.base import TrafficShaper
   from crossbench.path import LocalPath
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
-DEFAULT_HOST = "localhost"
-DEFAULT_PORT = 8000
+_DEFAULT_HOST = "localhost"
+_DEFAULT_PORT = 8000
+
 # List of known headers that are served by the default HTTPServer and might
 # be accidentally overridden by provided extra headers.
-CONFLICTING_EXTRA_HEADERS: Final[frozenset[str]] = frozenset(
+_CONFLICTING_EXTRA_HEADERS: Final[frozenset[str]] = frozenset(
     map(lambda header: header.lower(),
         ("Content-Type", "Content-Length", "Last-Modified", "Server", "Date",
          "Connection", "Location")))
 
+# Enable cross original isolation for high-precision timers.
+# This can be easily override by profiling a custom HEADER.txt file in the
+# served directory.
+_DEFAULT_HEADERS: Final[immutabledict[str, str]] = immutabledict({
+    "Cross-Origin-Opener-Policy": "same-origin",
+    "Cross-Origin-Embedder-Policy": "require-corp"
+})
 
 class CustomHeadersRequestHandler(http.server.SimpleHTTPRequestHandler):
 
   @classmethod
   def bind(
-      cls: Type[CustomHeadersRequestHandler],
+      cls,
       server_dir: LocalPath,
       extra_headers: Mapping[str, str],
   ) -> Type[http.server.SimpleHTTPRequestHandler]:
     # Use a temporary class to bind arguments.
-    class BoundDirectoryRequestHandler(cls):
+    class BoundDirectoryRequestHandler(cls):  # type: ignore
 
       def __init__(self, *args, **kwargs):
         super().__init__(
@@ -59,28 +68,30 @@ class CustomHeadersRequestHandler(http.server.SimpleHTTPRequestHandler):
                *args,
                directory: Optional[str] = None,
                extra_headers: Optional[Mapping[str, str]] = None,
-               **kwargs):
+               **kwargs) -> None:
     self._extra_headers: immutabledict[str, str] = (
         immutabledict(extra_headers) if extra_headers else immutabledict())
     super().__init__(*args, directory=directory, **kwargs)
 
-  def end_headers(self):
+  def end_headers(self) -> None:
     if self._extra_headers:
       self._send_custom_headers()
     super().end_headers()
 
-  def _send_custom_headers(self):
+  def _send_custom_headers(self) -> None:
     for key, value in self._extra_headers.items():
       self.send_header(key, value)
 
 
+LocalFileNetworkT = TypeVar("LocalFileNetworkT", bound="LocalFileNetwork")
+
 class LocalFileNetwork(Network):
 
   def __init__(self,
                path: LocalPath,
                url: Optional[str],
                traffic_shaper: Optional[TrafficShaper] = None,
-               browser_platform: plt.Platform = plt.PLATFORM):
+               browser_platform: Optional[plt.Platform] = None) -> None:
     super().__init__(traffic_shaper, browser_platform)
     self._path = path
     self._host, self._port = self._parse_url(url)
@@ -90,6 +101,7 @@ class LocalFileNetwork(Network):
       self._validate_extra_headers()
 
   @property
+  @override
   def is_local_file_server(self) -> bool:
     return True
 
@@ -98,8 +110,8 @@ class LocalFileNetwork(Network):
     return self._path
 
   def _parse_url(self, url: Optional[str]) -> Tuple[str, int]:
-    host: str = DEFAULT_HOST
-    port: int = DEFAULT_PORT
+    host: str = _DEFAULT_HOST
+    port: int = _DEFAULT_PORT
     if not url:
       return host, port
     parsed_url = ObjectParser.url(url)
@@ -114,24 +126,25 @@ class LocalFileNetwork(Network):
       header_file = self._path / name
       if header_file.exists():
         return self._read_headers_file(header_file)
-    return immutabledict()
+    return _DEFAULT_HEADERS
 
   def _read_headers_file(self,
                          header_file: LocalPath) -> immutabledict[str, str]:
-    with header_file.open("rb") as f:
-      # Reuse python's email message library to parse headers
-      message = email.parser.BytesParser().parsebytes(f.read())
-      return immutabledict(message)
+    # Reuse python's email message library to parse headers
+    message = email.parser.BytesParser().parsebytes(header_file.read_bytes())
+    return immutabledict(message)
 
-  def _validate_extra_headers(self):
+  def _validate_extra_headers(self) -> None:
     for key, value in self._extra_headers.items():
-      if key.lower() in CONFLICTING_EXTRA_HEADERS:
+      if key.lower() in _CONFLICTING_EXTRA_HEADERS:
         logging.error(
             "BROWSER Network: Extra header overrides server defaults: '%s: %s'",
             key, value)
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+  @override
+  def open(self: LocalFileNetworkT,
+           session: BrowserSessionRunGroup) -> Iterator[LocalFileNetworkT]:
     with super().open(session):
       with self._open_local_file_server():
         # TODO: properly hook up traffic shaper for the local http server
@@ -179,15 +192,18 @@ class LocalFileNetwork(Network):
       browser_platform.stop_reverse_port_forward(self._port)
 
   @property
+  @override
   def http_port(self) -> Optional[int]:
     return self._port
 
   @property
+  @override
   def https_port(self) -> Optional[int]:
     # TODO: support https locally
     return None
 
   @property
+  @override
   def host(self) -> Optional[str]:
     return self._host
 
diff --git a/crossbench/network/replay/base.py b/crossbench/network/replay/base.py
index eff23f47..2a37f3bd 100644
--- a/crossbench/network/replay/base.py
+++ b/crossbench/network/replay/base.py
@@ -7,38 +7,43 @@ from __future__ import annotations
 import contextlib
 import logging
 import re
-from typing import TYPE_CHECKING, Iterator, Optional, Union
+from typing import TYPE_CHECKING, Iterator, Optional, TypeVar
 from urllib.parse import urlparse
 
+from typing_extensions import override
+
 from crossbench import exception
 from crossbench import path as pth
-from crossbench import plt
-from crossbench.helper import Spinner
+from crossbench.helper.spinner import Spinner
 from crossbench.network.base import Network
 from crossbench.parse import PathParser
 
 if TYPE_CHECKING:
+  from crossbench import plt
   from crossbench.network.traffic_shaping.base import TrafficShaper
   from crossbench.path import LocalPath
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
 
 GS_PREFIX = "gs://"
-GSUTIL_LS_MD5_RE = re.compile(r"Hash \(md5\):\s*([A-Za-z0-9+/]+)=*")
+GSUTIL_LS_MD5_RE: re.Pattern[str] = re.compile(
+    r"Hash \(md5\):\s*([A-Za-z0-9+/]+)=*")
 
+ReplayNetworkT = TypeVar("ReplayNetworkT", bound="ReplayNetwork")
 
 class ReplayNetwork(Network):
   """ A network implementation that can be used to replay requests
   from a an archive."""
 
   def __init__(self,
-               archive: Union[pth.LocalPath, str],
+               archive: pth.LocalPath | str,
                traffic_shaper: Optional[TrafficShaper] = None,
-               browser_platform: plt.Platform = plt.PLATFORM):
+               browser_platform: Optional[plt.Platform] = None) -> None:
     super().__init__(traffic_shaper, browser_platform)
     self._archive_path = self._ensure_archive(archive)
 
   @property
+  @override
   def is_wpr(self) -> bool:
     return True
 
@@ -47,7 +52,9 @@ class ReplayNetwork(Network):
     return self._archive_path
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+  @override
+  def open(self: ReplayNetworkT,
+           session: BrowserSessionRunGroup) -> Iterator[ReplayNetworkT]:
     with super().open(session):
       with self._open_replay_server(session):
         with self._traffic_shaper.open(self, session):
@@ -79,7 +86,7 @@ class ReplayNetwork(Network):
       self.host_platform.sh("gsutil", "cp", url, local_path)
     return local_path
 
-  def _ensure_archive(self, archive: Union[pth.LocalPath, str]) -> LocalPath:
+  def _ensure_archive(self, archive: pth.LocalPath | str) -> LocalPath:
     if isinstance(archive, str) and archive.startswith(GS_PREFIX):
       return self._download_gcloud_archive(url=archive)
     return PathParser.existing_file_path(archive).resolve()
diff --git a/crossbench/network/replay/web_page_replay.py b/crossbench/network/replay/web_page_replay.py
index a414a84c..755c7f44 100644
--- a/crossbench/network/replay/web_page_replay.py
+++ b/crossbench/network/replay/web_page_replay.py
@@ -14,16 +14,19 @@ import subprocess
 import time
 from typing import Iterable, Optional, TextIO, Tuple
 
-from crossbench import helper
+from typing_extensions import override
+
+from crossbench.helper import url_helper
+from crossbench.helper.cwd import ChangeCWD
 from crossbench.helper.path_finder import WprGoToolFinder
 from crossbench.parse import NumberParser, PathParser
 from crossbench.path import AnyPath, LocalPath
 from crossbench.plt import PLATFORM, Platform, TupleCmdArgs
 
-_WPR_PORT_RE = re.compile(r".*Starting server on "
-                          r"(?P<protocol>http|https)://"
-                          r"(?P<host>[^:]+):"
-                          r"(?P<port>\d+)")
+_WPR_PORT_RE: re.Pattern[str] = re.compile(r".*Starting server on "
+                                           r"(?P<protocol>http|https)://"
+                                           r"(?P<host>[^:]+):"
+                                           r"(?P<port>\d+)")
 
 
 class WprStartupError(RuntimeError):
@@ -46,17 +49,17 @@ class WprBase(abc.ABC):
                key_file: Optional[AnyPath] = None,
                cert_file: Optional[AnyPath] = None,
                log_path: Optional[LocalPath] = None,
-               platform: Platform = PLATFORM):
+               platform: Platform = PLATFORM) -> None:
     self._platform: Platform = platform
-    self._process: Optional[subprocess.Popen] = None
-    self._log_path: Optional[LocalPath] = None
+    self._process: subprocess.Popen | None = None
+    self._log_path: LocalPath | None = None
     if log_path:
       self._log_path = PathParser.not_existing_path(log_path)
-    self._log_file: Optional[TextIO] = None
+    self._log_file: TextIO | None = None
     self._bin_path = bin_path
     self._go_cmd: TupleCmdArgs = ()
-    self._local_http_port: int = 0
-    self._local_https_port: int = 0
+    self._host_http_port: int = 0
+    self._host_https_port: int = 0
 
     wpr_root: LocalPath
     if self._bin_path.suffix == ".go":
@@ -82,8 +85,8 @@ class WprBase(abc.ABC):
         assert inject_scripts is not None
 
     self._archive_path = self._validate_archive_path(archive_path)
-    (self._http_port,
-     self._https_port) = self._validate_ports(http_port, https_port)
+    (self._device_http_port,
+     self._device_https_port) = self._validate_ports(http_port, https_port)
     self._num_parsed_ports: int = 0
     self._host: str = host
     if self._platform.is_remote:
@@ -132,11 +135,11 @@ class WprBase(abc.ABC):
 
   @property
   def http_port(self) -> int:
-    return self._http_port
+    return self._device_http_port
 
   @property
   def https_port(self) -> int:
-    return self._https_port
+    return self._device_https_port
 
   @property
   def host(self) -> str:
@@ -154,8 +157,8 @@ class WprBase(abc.ABC):
   @property
   def base_cmd_flags(self) -> TupleCmdArgs:
     cmd: TupleCmdArgs = (
-        f"--http_port={self._http_port}",
-        f"--https_port={self._https_port}",
+        f"--http_port={self._device_http_port}",
+        f"--https_port={self._device_https_port}",
         f"--https_key_file={self._key_file}",
         f"--https_cert_file={self._cert_file}",
     )
@@ -171,8 +174,9 @@ class WprBase(abc.ABC):
       atexit.register(self.stop)
       logging.info("WPR: waiting for startup...")
       self._wait_for_startup()
-      logging.info("WPR: Started wpr.go %s: DONE (http_port=%s, http_port=%s)",
-                   self.NAME, self.http_port, self.https_port)
+      logging.info(("WPR: Started wpr.go %s: "
+                    "DONE (platform=%s, http_port=%s, http_port=%s)"),
+                   self.NAME, self._platform, self.http_port, self.https_port)
     except BaseException as e:
       if isinstance(e, Exception):
         logging.debug("WPR got startup errors: %s %s", type(e), e)
@@ -188,16 +192,17 @@ class WprBase(abc.ABC):
     self._num_parsed_ports = 0
     if self._log_path:
       self._log_file = self._log_path.open("w", encoding="utf-8")  # pylint: disable=consider-using-with
-    work_dir = (
-        self._bin_path.parent if self._platform.is_local else LocalPath.cwd())
-    with helper.ChangeCWD(work_dir):
+    work_dir: LocalPath = LocalPath.cwd()
+    if self._platform.is_local:
+      work_dir = self._platform.local_path(self._bin_path.parent)
+    with ChangeCWD(work_dir):
       logging.debug("Logging to %s", self._log_path)
       self._process = self._platform.popen(
           *go_cmd, stdout=self._log_file, stderr=self._log_file)
     if not self._process:
       raise WprStartupError(f"Could not start {type(self).__name__}")
 
-  def _handle_startup_error(self):
+  def _handle_startup_error(self) -> None:
     logging.error("WPR: Could not start %s", type(self).__name__)
     if not self._log_path or not self._log_path.exists():
       return
@@ -211,13 +216,20 @@ class WprBase(abc.ABC):
 
   def _forward_ports(self) -> None:
     if self._platform.is_remote:
-      self._local_http_port = self._platform.port_forward(0, self._http_port)
-      self._local_https_port = self._platform.port_forward(0, self._https_port)
+      self._host_http_port = self._platform.port_forward(
+          0, self._device_http_port)
+      self._host_https_port = self._platform.port_forward(
+          0, self._device_https_port)
+    else:
+      self._host_http_port = self._device_http_port
+      self._host_https_port = self._device_https_port
 
   def _stop_forward_ports(self) -> None:
     if self._platform.is_remote:
-      self._platform.stop_port_forward(self._local_http_port)
-      self._platform.stop_port_forward(self._local_https_port)
+      if self._host_http_port:
+        self._platform.stop_port_forward(self._host_http_port)
+      if self._host_https_port:
+        self._platform.stop_port_forward(self._host_https_port)
 
   def _wait_for_startup(self) -> None:
     assert self._process, "process not started"
@@ -238,10 +250,9 @@ class WprBase(abc.ABC):
     self._forward_ports()
     time.sleep(0.1)
     try:
-      with self._open_wpr_cmd_url("generate-200") as r:
-        if r.status == 200:
-          return
-    except Exception as e:  # pylint: disable=broad-except
+      self._open_wpr_cmd_url("generate-200")
+      return
+    except url_helper.HTTPError as e:
       logging.debug("Could not query wpr server: %s", e)
     self._raise_startup_failure()
 
@@ -259,10 +270,10 @@ class WprBase(abc.ABC):
       protocol = match["protocol"].lower()
       port = int(match["port"])
       if protocol == "http":
-        self._http_port = port
+        self._device_http_port = port
         self._num_parsed_ports += 1
       elif protocol == "https":
-        self._https_port = port
+        self._device_https_port = port
         self._num_parsed_ports += 1
       else:
         logging.error("WPR: got invalid protocol: %s", line)
@@ -270,35 +281,37 @@ class WprBase(abc.ABC):
       if not self._host:
         raise WprStartupError(f"WPR: could not parse host from: {line}")
 
-    if self._num_parsed_ports == 2 and self._http_port and self._https_port:
-      logging.debug("WPR: https_port=%s http_port=%s", self._https_port,
-                    self._http_port)
+    if self._num_parsed_ports == 2 and (self._device_http_port and
+                                        self._device_https_port):
+      logging.debug("WPR: https_port=%s http_port=%s", self._device_https_port,
+                    self._device_http_port)
       return True
     return False
 
-  def _open_wpr_cmd_url(self, cmd: str):
-    http_port = (
-        self._local_http_port if self._platform.is_remote else self._http_port)
-    test_url = f"http://{self._host}:{http_port}/web-page-replay-{cmd}"
-    return helper.urlopen(test_url, timeout=1)
+  def _open_wpr_cmd_url(self,
+                        cmd: str,
+                        verbose: bool = True) -> url_helper.Response:
+    test_url = (
+        f"http://{self._host}:{self._host_http_port}/web-page-replay-{cmd}")
+    return url_helper.get(test_url, timeout=1, verbose=verbose)
 
   def stop(self, force_shutdown: bool = False) -> None:
+    atexit.unregister(self.stop)
     if self._process and not force_shutdown:
       self._shut_down()
     if self._log_file:
       self._log_file.close()
       self._log_file = None
     if self._process:
-      helper.wait_and_kill(self._process, timeout=1)
+      self._platform.terminate_gracefully(self._process, timeout=1)
     self._process = None
     self._stop_forward_ports()
 
   def _shut_down(self) -> None:
     logging.info("WPR: shutting down recorder.")
     try:
-      with self._open_wpr_cmd_url("command-exit"):
-        pass
-    except IOError:
+      self._open_wpr_cmd_url("command-exit", verbose=False)
+    except url_helper.ConnectionError:
       # The above request always fails because WPR closes the connection
       # without response.
       pass
@@ -312,9 +325,11 @@ class WprRecorder(WprBase):
     return self._platform.local_path(self._cert_file)
 
   @property
+  @override
   def cmd(self) -> TupleCmdArgs:
     return ("record",) + super().base_cmd_flags + (str(self._archive_path),)
 
+  @override
   def _validate_archive_path(self, path: AnyPath) -> LocalPath:
     return PathParser.not_existing_path(path, "Wpr.go result archive")
 
@@ -339,20 +354,22 @@ class WprReplayServer(WprBase):
                log_path: Optional[LocalPath] = None,
                fuzzy_url_matching: bool = True,
                serve_chronologically: bool = True,
-               platform: Platform = PLATFORM):
+               platform: Platform = PLATFORM) -> None:
     super().__init__(archive_path, bin_path, http_port, https_port, host,
                      inject_scripts, key_file, cert_file, log_path, platform)
-    self._rules_file: Optional[AnyPath] = None
+    self._rules_file: AnyPath | None = None
     if rules_file:
       self._rules_file = PathParser.non_empty_file_path(rules_file)
     self._fuzzy_url_matching: bool = fuzzy_url_matching
     self._serve_chronologically: bool = serve_chronologically
 
+  @override
   def _validate_archive_path(self, path: AnyPath) -> AnyPath:
     assert self._platform.is_file(path)
     return path
 
   @property
+  @override
   def cmd(self) -> TupleCmdArgs:
     cmd = ("replay",) + super().base_cmd_flags
     if self._rules_file:
diff --git a/crossbench/network/replay/wpr.py b/crossbench/network/replay/wpr.py
index 9da18260..6d7ba1b0 100644
--- a/crossbench/network/replay/wpr.py
+++ b/crossbench/network/replay/wpr.py
@@ -6,17 +6,19 @@ from __future__ import annotations
 
 import abc
 import contextlib
-import hashlib
+import dataclasses
 import logging
-from typing import TYPE_CHECKING, Iterator, List, Optional, Union
+from typing import (TYPE_CHECKING, Final, Iterator, List, Mapping, Optional,
+                    Tuple, TypeVar)
+
+from typing_extensions import override
 
 from crossbench.flags.base import Flags
 from crossbench.helper.path_finder import WprGoToolFinder
 from crossbench.network.replay.base import GS_PREFIX, ReplayNetwork
 from crossbench.network.replay.web_page_replay import WprReplayServer
-from crossbench.parse import PathParser
+from crossbench.path import check_hash
 from crossbench.plt import PLATFORM, Platform
-from crossbench.plt.arch import MachineArch
 
 if TYPE_CHECKING:
   from crossbench.browsers.attributes import BrowserAttributes
@@ -28,46 +30,62 @@ if TYPE_CHECKING:
 # use value for pylint
 assert GS_PREFIX
 
-BASE_URL = "gs://chromium-telemetry/binary_dependencies"
-
-WPR_PREBUILT_ARCH_MAP = {
-    MachineArch.ARM_64: {
-        "url": f"{BASE_URL}/wpr_go_129a66a1378dfcbb815596f66ca680728f77da36",
-        "file_hash": "129a66a1378dfcbb815596f66ca680728f77da36",
-    },
-    MachineArch.ARM_32: {
-        "url": f"{BASE_URL}/wpr_go_92ff5bdb9370b36d2844c2f018e2b7d9c3b8ed39",
-        "file_hash": "92ff5bdb9370b36d2844c2f018e2b7d9c3b8ed39",
-    },
-    MachineArch.X64: {
-        "url": f"{BASE_URL}/wpr_go_6caa467dc6bef92e1c34256f539f8ed8f26a2fe1",
-        "file_hash": "6caa467dc6bef92e1c34256f539f8ed8f26a2fe1",
-    },
-}
+WPR_BASE_URL = "gs://chromium-telemetry/binary_dependencies"
+
 
+@dataclasses.dataclass
+class WPRCloudBinary:
+  file_hash: str
+
+  @property
+  def url(self) -> str:
+    return f"{WPR_BASE_URL}/wpr_go_{self.file_hash}"
+
+
+# See third_party/catapult/telemetry/telemetry/binary_dependencies.json
+WPR_PREBUILT_LOOKUP: Final[Mapping[Tuple[str, str], WPRCloudBinary]] = {
+    ("android", "arm64"):
+        WPRCloudBinary("129a66a1378dfcbb815596f66ca680728f77da36"),
+    ("android", "arm32"):
+        WPRCloudBinary("92ff5bdb9370b36d2844c2f018e2b7d9c3b8ed39"),
+    ("android", "x64"):
+        WPRCloudBinary("6caa467dc6bef92e1c34256f539f8ed8f26a2fe1"),
+    # On arm64 ChromeOS, use the same binary as arm64 Linux.
+    ("chromeos_ssh", "arm64"):
+        WPRCloudBinary("129a66a1378dfcbb815596f66ca680728f77da36"),
+    # On x64 ChromeOS, use the same binary as x64 Linux.
+    ("chromeos_ssh", "x64"):
+        WPRCloudBinary("6caa467dc6bef92e1c34256f539f8ed8f26a2fe1"),
+    ("linux", "x64"):
+        WPRCloudBinary("6caa467dc6bef92e1c34256f539f8ed8f26a2fe1"),
+    ("macos", "arm64"):
+        WPRCloudBinary("c68bd02b247e38a68a8e8ca154164fab75638e2e"),
+    ("macos", "x64"):
+        WPRCloudBinary("57443617185913f5e9af20e69a105419eb4cbea5"),
+    ("win", "x64"):
+        WPRCloudBinary("8b5310e99091991b949103b1edf39db45c7818f5"),
+}
 
-def check_hash(file_path: LocalPath, file_hash: str) -> bool:
-  if not file_path.exists():
-    return False
-  sha1 = hashlib.sha1()
-  sha1.update(file_path.read_bytes())
-  return sha1.hexdigest() == file_hash
 
+WprReplayNetworkT = TypeVar("WprReplayNetworkT", bound="WprReplayNetwork")
 
 class WprReplayNetwork(ReplayNetwork):
 
   def __init__(self,
-               archive: Union[LocalPath, str],
+               archive: LocalPath | str,
                traffic_shaper: Optional[TrafficShaper] = None,
                wpr_go_bin: Optional[LocalPath] = None,
                browser_platform: Platform = PLATFORM,
-               persist_server: bool = False):
+               persist_server: bool = False,
+               inject_deterministic_script: bool = True) -> None:
     super().__init__(archive, traffic_shaper, browser_platform)
-    self._server: Optional[WprReplayServer] = None
-    self._tmp_dir: Optional[AnyPath] = None
+    self._server: WprReplayServer | None = None
+    self._tmp_dir: AnyPath | None = None
     self._persist_server = persist_server
+    self._inject_deterministic_script = inject_deterministic_script
     self._ensure_wpr_go(wpr_go_bin)
 
+  @override
   def extra_flags(self, browser_attributes: BrowserAttributes) -> Flags:
     assert self.is_running, "Extra network flags are not valid"
     assert self._server
@@ -99,11 +117,13 @@ class WprReplayNetwork(ReplayNetwork):
     pass
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+  @override
+  def open(self: WprReplayNetworkT,
+           session: BrowserSessionRunGroup) -> Iterator[WprReplayNetworkT]:
     with super().open(session):
       yield self
 
-  def _ensure_server_started(self, session: BrowserSessionRunGroup):
+  def _ensure_server_started(self, session: BrowserSessionRunGroup) -> None:
     log_dir = session.browser_dir if self._persist_server else session.out_dir
     if not self._server or not self._persist_server:
       self._server = self._create_server(log_dir)
@@ -114,37 +134,46 @@ class WprReplayNetwork(ReplayNetwork):
       logging.debug("WPR server already started")
 
   @contextlib.contextmanager
+  @override
   def _open_replay_server(self, session: BrowserSessionRunGroup):
     self._ensure_server_started(session)
 
     try:
       yield self
     finally:
-      if not self._persist_server:
+      if not self._persist_server and self._server:
         self._server.stop()
 
   @property
+  @override
   def http_port(self) -> int:
     assert self._server, "WPR is not running"
     return self._server.http_port
 
   @property
+  @override
   def https_port(self) -> int:
     assert self._server, "WPR is not running"
     return self._server.https_port
 
   @property
+  @override
   def host(self) -> str:
     assert self._server, "WPR is not running"
     return self._server.host
 
+  @property
+  def inject_deterministic_script(self) -> bool:
+    return self._inject_deterministic_script
+
   def __str__(self) -> str:
     return f"WPR(archive={self.archive_path}, speed={self.traffic_shaper})"
 
 
 class LocalWprReplayNetwork(WprReplayNetwork):
 
-  def _ensure_wpr_go(self, wpr_go_bin: Optional[LocalPath] = None):
+  @override
+  def _ensure_wpr_go(self, wpr_go_bin: Optional[LocalPath] = None) -> None:
     if not wpr_go_bin:
       if local_wpr_go := WprGoToolFinder(self.host_platform).path:
         wpr_go_bin = self.host_platform.local_path(local_wpr_go)
@@ -153,11 +182,13 @@ class LocalWprReplayNetwork(WprReplayNetwork):
           f"Could not find wpr.go binary on {self.host_platform}")
     if wpr_go_bin.suffix == ".go" and not self.host_platform.which("go"):
       raise ValueError(f"'go' binary not found on {self.host_platform}")
-    self._wpr_go_bin: LocalPath = self.host_platform.local_path(
-        PathParser.binary_path(wpr_go_bin, "wpr.go source"))
+    self._wpr_go_bin: LocalPath = self.host_platform.parse_local_binary_path(
+        wpr_go_bin, "wpr.go source")
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+  @override
+  def open(self: LocalWprReplayNetwork,
+           session: BrowserSessionRunGroup) -> Iterator[LocalWprReplayNetwork]:
     with super().open(session):
       with self._forward_ports(session):
         yield self
@@ -180,39 +211,51 @@ class LocalWprReplayNetwork(WprReplayNetwork):
     browser_platform.stop_reverse_port_forward(http_port)
     browser_platform.stop_reverse_port_forward(https_port)
 
+  @override
   def _create_server(self, log_dir: LocalPath) -> WprReplayServer:
+    inject_scripts: List[AnyPath] | None = (
+        None if self.inject_deterministic_script else [])
     return WprReplayServer(
         self.archive_path,
         self._wpr_go_bin,
+        inject_scripts=inject_scripts,
         log_path=log_dir / "network.wpr.log",
         platform=self.host_platform)
 
 
 class RemoteWprReplayNetwork(WprReplayNetwork):
 
-  def _ensure_wpr_go(self, wpr_go_bin: Optional[LocalPath] = None):
-    assert self.browser_platform.is_android
+  @classmethod
+  def is_compatible(cls, platform: Platform) -> bool:
+    return platform.is_android or platform.is_chromeos
+
+  @override
+  def _ensure_wpr_go(self, wpr_go_bin: Optional[LocalPath] = None) -> None:
+    assert RemoteWprReplayNetwork.is_compatible(self.browser_platform)
     if wpr_go_bin:
       if wpr_go_bin.suffix == ".go":
         raise ValueError(f"Can't run .go files on {self.browser_platform}")
     else:
       wpr_go_bin = self._download_prebuilt_wpr()
-    self._wpr_go_bin: LocalPath = self.host_platform.local_path(
-        PathParser.binary_path(wpr_go_bin, "wpr.go binary"))
+    self._wpr_go_bin: LocalPath = self.host_platform.parse_local_binary_path(
+        wpr_go_bin, "wpr.go binary")
 
   def _download_prebuilt_wpr(self) -> LocalPath:
-    wpr_info = WPR_PREBUILT_ARCH_MAP[self.browser_platform.machine]
+    wpr_cloud_binary = WPR_PREBUILT_LOOKUP[self.browser_platform.key]
     local_wpr_go_bin = (
         self.host_platform.local_cache_dir("wpr") /
         str(self.browser_platform.machine) / "wpr_go")
-    if not check_hash(local_wpr_go_bin, wpr_info["file_hash"]):
-      self.host_platform.sh("gsutil", "cp", wpr_info["url"], local_wpr_go_bin)
-    assert check_hash(local_wpr_go_bin, wpr_info["file_hash"])
+    if not check_hash(local_wpr_go_bin, wpr_cloud_binary.file_hash):
+      self.host_platform.sh("gsutil", "cp", wpr_cloud_binary.url,
+                            local_wpr_go_bin)
+    assert check_hash(local_wpr_go_bin, wpr_cloud_binary.file_hash)
 
     return local_wpr_go_bin
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[ReplayNetwork]:
+  @override
+  def open(self: RemoteWprReplayNetwork,
+           session: BrowserSessionRunGroup) -> Iterator[RemoteWprReplayNetwork]:
     with self._remote_temp_dir(session):
       with super().open(session):
         yield self
@@ -233,29 +276,32 @@ class RemoteWprReplayNetwork(WprReplayNetwork):
   def _push_required_files(self) -> List[AnyPath]:
     host_platform = self.host_platform
     if local_wpr_go := WprGoToolFinder(host_platform).path:
-      wpr_root = self.host_platform.path(local_wpr_go.parents[1])
+      wpr_root = self.host_platform.local_path(local_wpr_go.parents[1])
     else:
       raise RuntimeError(f"Could not fine local wpr.go on {host_platform}")
 
-    all_files = [self._archive_path,
-                 wpr_root / "ecdsa_key.pem",
-                 wpr_root / "ecdsa_cert.pem",
-                 wpr_root / "deterministic.js"]
-    remote_files = [self._push_file(f) for f in all_files]
+    all_files: List[LocalPath] = [
+        self._archive_path, wpr_root / "ecdsa_key.pem",
+        wpr_root / "ecdsa_cert.pem", wpr_root / "deterministic.js"
+    ]
+    remote_files = [self._push_file(path) for path in all_files]
 
     remote_wpr_go_bin = self._push_file(self._wpr_go_bin)
     self.browser_platform.sh("chmod", "+x", remote_wpr_go_bin)
 
     return [remote_wpr_go_bin] + remote_files
 
+  @override
   def _create_server(self, log_dir: LocalPath) -> WprReplayServer:
     wpr_go_bin, archive, key_file, cert_file, inject_script =\
         self._push_required_files()
+    inject_scripts: List[AnyPath] = ([inject_script] if
+                                     self.inject_deterministic_script else [])
     return WprReplayServer(
         archive_path=archive,
         bin_path=wpr_go_bin,
         key_file=key_file,
         cert_file=cert_file,
-        inject_scripts=[inject_script],
+        inject_scripts=inject_scripts,
         log_path=log_dir / "network.wpr.log",
         platform=self.browser_platform)
diff --git a/crossbench/network/traffic_shaping/base.py b/crossbench/network/traffic_shaping/base.py
index 75c9b4a1..15ba3c52 100644
--- a/crossbench/network/traffic_shaping/base.py
+++ b/crossbench/network/traffic_shaping/base.py
@@ -6,7 +6,9 @@ from __future__ import annotations
 
 import abc
 import contextlib
-from typing import TYPE_CHECKING, Iterator
+from typing import TYPE_CHECKING, Iterator, TypeVar
+
+from typing_extensions import override
 
 from crossbench.flags.base import Flags
 
@@ -17,9 +19,11 @@ if TYPE_CHECKING:
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
 
+TrafficShaperT = TypeVar("TrafficShaperT", bound="TrafficShaper")
+
 class TrafficShaper(abc.ABC):
 
-  def __init__(self, browser_platform: Platform):
+  def __init__(self, browser_platform: Platform) -> None:
     self._browser_platform = browser_platform
     self._is_running = False
 
@@ -45,8 +49,8 @@ class TrafficShaper(abc.ABC):
     return Flags()
 
   @contextlib.contextmanager
-  def open(self, network: Network,
-           session: BrowserSessionRunGroup) -> Iterator[TrafficShaper]:
+  def open(self: TrafficShaperT, network: Network,
+           session: BrowserSessionRunGroup) -> Iterator[TrafficShaperT]:
     del network, session
     assert not self._is_running, "Cannot start network more than once."
     self._is_running = True
@@ -54,3 +58,9 @@ class TrafficShaper(abc.ABC):
       yield self
     finally:
       self._is_running = False
+
+  @contextlib.contextmanager
+  @override
+  def pause(self):
+    """Temporarily pause traffic shaping if supported."""
+    yield None
diff --git a/crossbench/network/traffic_shaping/live.py b/crossbench/network/traffic_shaping/live.py
index dd0e491b..e31c0b06 100644
--- a/crossbench/network/traffic_shaping/live.py
+++ b/crossbench/network/traffic_shaping/live.py
@@ -4,12 +4,15 @@
 
 from __future__ import annotations
 
+from typing_extensions import override
+
 from crossbench.network.traffic_shaping.base import TrafficShaper
 
 
 class NoTrafficShaper(TrafficShaper):
 
   @property
+  @override
   def is_live(self) -> bool:
     return True
 
diff --git a/crossbench/network/traffic_shaping/ts_proxy.py b/crossbench/network/traffic_shaping/ts_proxy.py
index 664f616f..fb1d69a1 100644
--- a/crossbench/network/traffic_shaping/ts_proxy.py
+++ b/crossbench/network/traffic_shaping/ts_proxy.py
@@ -13,14 +13,16 @@ import logging
 import os
 import re
 import shlex
-import signal
 import subprocess
 import sys
-from typing import IO, TYPE_CHECKING, Iterator, List, Optional, Union
+from typing import IO, TYPE_CHECKING, Iterator, List, Optional, Self, TypeVar
+
+from typing_extensions import override
 
-from crossbench import helper
 from crossbench.flags.base import Flags
+from crossbench.helper import wait
 from crossbench.helper.path_finder import TsProxyFinder
+from crossbench.network.traffic_shaping import ts_proxy_settings
 from crossbench.network.traffic_shaping.base import TrafficShaper
 from crossbench.parse import NumberParser, PathParser
 
@@ -33,7 +35,7 @@ if TYPE_CHECKING:
 
 fcntl = None
 try:
-  import fcntl
+  import fcntl  # type: ignore
 except ModuleNotFoundError as not_found:
   logging.debug("No fcntl support %s", not_found)
 
@@ -43,43 +45,17 @@ class TsProxyServerError(Exception):
   """Catch-all exception for tsProxy Server."""
 
 
-_PORT_RE = re.compile(r"Started Socks5 proxy server on "
-                      r"(?P<host>[^:]*):"
-                      r"(?P<port>\d+)")
-DEFAULT_TIMEOUT = 5
+_PORT_RE: re.Pattern[str] = re.compile(r"Started Socks5 proxy server on "
+                                       r"(?P<host>[^:]*):"
+                                       r"(?P<port>\d+)")
 
 
-def parse_ts_socks_proxy_port(output_line):
+def parse_ts_socks_proxy_port(output_line) -> Optional[int]:
   if match := _PORT_RE.match(output_line):
     return int(match.group("port"))
   return None
 
 
-# TODO: improve and double check
-TRAFFIC_SETTINGS = {
-    "3G-slow": {
-        "rtt_ms": 400,
-        "in_kbps": 400,
-        "out_kbps": 400,
-    },
-    "3G-regular": {
-        "rtt_ms": 300,
-        "in_kbps": 1600,
-        "out_kbps": 768,
-    },
-    "3G-fast": {
-        "rtt_ms": 150,
-        "in_kbps": 1600,
-        "out_kbps": 768,
-    },
-    "4G": {
-        "rtt_ms": 170,
-        "in_kbps": 9000,
-        "out_kbps": 9000,
-    },
-}
-
-
 class TsProxyServer:
   """
   TsProxy provides basic latency, download and upload traffic shaping. This
@@ -90,6 +66,7 @@ class TsProxyServer:
   """
 
   def __init__(self,
+               platform: Platform,
                ts_proxy_path: LocalPath,
                host: Optional[str] = None,
                socks_proxy_port: Optional[int] = None,
@@ -99,8 +76,9 @@ class TsProxyServer:
                in_kbps: Optional[int] = None,
                out_kbps: Optional[int] = None,
                window: Optional[int] = None,
-               verbose: bool = True):
-    self._proc: Optional[TsProxyProcess] = None
+               verbose: bool = True) -> None:
+    self._platform = platform
+    self._proc: TsProxyProcess | None = None
     self._ts_proxy_path = PathParser.existing_file_path(ts_proxy_path)
     self._socks_proxy_port = socks_proxy_port
     self._host = host
@@ -131,12 +109,13 @@ class TsProxyServer:
   def is_running(self) -> bool:
     return self._proc is not None
 
-  def set_traffic_settings(self,
-                           rtt_ms: Optional[int] = None,
-                           in_kbps: Optional[int] = None,
-                           out_kbps: Optional[int] = None,
-                           window: Optional[int] = None,
-                           timeout=DEFAULT_TIMEOUT) -> None:
+  def set_traffic_settings(
+      self,
+      rtt_ms: Optional[int] = None,
+      in_kbps: Optional[int] = None,
+      out_kbps: Optional[int] = None,
+      window: Optional[int] = None,
+      timeout: int = ts_proxy_settings.DEFAULT_TIMEOUT) -> None:
     assert self._proc, "ts_proxy is not running."
     self._proc.set_traffic_settings(rtt_ms, in_kbps, out_kbps, window, timeout)
 
@@ -167,7 +146,7 @@ class TsProxyServer:
 
   def start(self) -> None:
     assert not self._proc, "ts_proxy is already running."
-    self._proc = TsProxyProcess(self._ts_proxy_path, self._host,
+    self._proc = TsProxyProcess(self._platform, self._ts_proxy_path, self._host,
                                 self._socks_proxy_port, self._http_port,
                                 self._https_port, self._rtt_ms, self._in_kbps,
                                 self._out_kbps, self._window, self._verbose)
@@ -182,36 +161,39 @@ class TsProxyServer:
     self._proc = None
     return err
 
-  def __enter__(self):
+  def __enter__(self) -> Self:
     self.start()
     return self
 
-  def __exit__(self, unused_exc_type, unused_exc_val, unused_exc_tb):
+  def __exit__(self, unused_exc_type, unused_exc_val, unused_exc_tb) -> None:
     self.stop()
 
 
 class TsProxyProcess:
   """Separate wrapper around the ts_proxy to simplify pytype testing."""
 
-  def __init__(self,
-               ts_proxy_path: LocalPath,
-               host: Optional[str] = None,
-               socks_proxy_port: Optional[int] = None,
-               http_port: Optional[int] = None,
-               https_port: Optional[int] = None,
-               rtt_ms: Optional[int] = None,
-               in_kbps: Optional[int] = None,
-               out_kbps: Optional[int] = None,
-               window: Optional[int] = None,
-               verbose: bool = False,
-               timeout: Union[int, float] = DEFAULT_TIMEOUT) -> None:
+  def __init__(
+      self,
+      platform: Platform,
+      ts_proxy_path: LocalPath,
+      host: Optional[str] = None,
+      socks_proxy_port: Optional[int] = None,
+      http_port: Optional[int] = None,
+      https_port: Optional[int] = None,
+      rtt_ms: Optional[int] = None,
+      in_kbps: Optional[int] = None,
+      out_kbps: Optional[int] = None,
+      window: Optional[int] = None,
+      verbose: bool = False,
+      timeout: int | float = ts_proxy_settings.DEFAULT_TIMEOUT) -> None:
+    self._platform = platform
     """Start TsProxy server and verify that it started."""
     cmd: ListCmdArgs = [
         sys.executable,
         ts_proxy_path,
     ]
-    self._socks_proxy_port: Optional[int] = socks_proxy_port
-    self._initial_socks_proxy_port: Optional[int] = socks_proxy_port
+    self._socks_proxy_port: int | None = socks_proxy_port
+    self._initial_socks_proxy_port: int | None = socks_proxy_port
     if not socks_proxy_port:
       # Use port 0 so tsproxy picks a random available port.
       cmd.append("--port=0")
@@ -219,23 +201,23 @@ class TsProxyProcess:
       cmd.append(f"--port={socks_proxy_port}")
     if verbose:
       cmd.append("--verbose")
-    self._in_kbps: Optional[int] = in_kbps
+    self._in_kbps: int | None = in_kbps
     if in_kbps:
       cmd.append(f"--inkbps={in_kbps}")
-    self._out_kbps: Optional[int] = out_kbps
+    self._out_kbps: int | None = out_kbps
     if out_kbps:
       cmd.append(f"--outkbps={out_kbps}")
-    self._window: Optional[int] = window
+    self._window: int | None = window
     if window:
       cmd.append(f"--window={window}")
-    self._rtt_ms: Optional[int] = rtt_ms
+    self._rtt_ms: int | None = rtt_ms
     if rtt_ms:
       cmd.append(f"--rtt={rtt_ms}")
-    self._host: Optional[str] = host
+    self._host: str | None = host
     if host:
       cmd.append(f"--desthost={host}")
-    self._http_port: Optional[int] = http_port
-    self._https_port: Optional[int] = https_port
+    self._http_port: int | None = http_port
+    self._https_port: int | None = https_port
     TsProxyServer.verify_ports(http_port, https_port)
     mapports = []
     if https_port:
@@ -247,20 +229,21 @@ class TsProxyProcess:
     self._verify_default_encoding()
     # In python3 universal_newlines forces subprocess to encode/decode,
     # allowing per-line buffering.
-    proc = subprocess.Popen(  # pylint: disable=consider-using-with
+    process = subprocess.Popen(  # pylint: disable=consider-using-with
         cmd,
         stdout=subprocess.PIPE,
         stdin=subprocess.PIPE,
         # stderr=subprocess.PIPE,
         bufsize=1,
         universal_newlines=True)
-    assert proc and proc.stdout and proc.stdin, "Could not start ts_proxy"
-    self._proc = proc
-    if stdout := proc.stdout:
+    assert process and process.stdout and process.stdin, (
+        "Could not start ts_proxy")
+    self._process = process
+    if stdout := process.stdout:
       self._stdout: IO[str] = stdout
     else:
       raise RuntimeError("Missing stdout")
-    if stdin := proc.stdin:
+    if stdin := process.stdin:
       self._stdin: IO[str] = stdin
     else:
       raise RuntimeError("Missing stdin")
@@ -271,6 +254,7 @@ class TsProxyProcess:
   def _setup_non_blocking_io(self) -> None:
     logging.debug("TsProxy: fcntl is supported, trying to set "
                   "non blocking I/O for the ts_proxy process")
+    assert fcntl, "Did not load fcntl module"
     fd = self._stdout.fileno()
     fl = fcntl.fcntl(fd, fcntl.F_GETFL)
     fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)  # pylint: disable=no-member
@@ -288,8 +272,8 @@ class TsProxyProcess:
     if encoding != "UTF-8":
       logging.warning("Decoding will use %s instead of UTF-8", encoding)
 
-  def _wait_for_startup(self, timeout: Union[int, float]) -> None:
-    for _ in helper.wait_with_backoff(timeout):
+  def _wait_for_startup(self, timeout: int | float) -> None:
+    for _ in wait.wait_with_backoff(timeout):
       if self._has_started():
         logging.info("TsProxy: port=%i", self._socks_proxy_port)
         return
@@ -299,7 +283,7 @@ class TsProxyProcess:
         f"Starting tsproxy timed out after {timeout} seconds")
 
   def _has_started(self) -> bool:
-    if self._proc.poll() is not None:
+    if self._process.poll() is not None:
       return False
     self._stdout.flush()
     output_line = self._read_line_ts_proxy_stdout(timeout=5)
@@ -310,17 +294,18 @@ class TsProxyProcess:
     self._socks_proxy_port = NumberParser.port_number(port, "socks_proxy_port")
     return True
 
-  def _read_line_ts_proxy_stdout(self, timeout: Union[int, float]) -> str:
-    for _ in helper.wait_with_backoff(timeout):
+  def _read_line_ts_proxy_stdout(self, timeout: int | float) -> str:
+    for _ in wait.wait_with_backoff(timeout):
       try:
         return self._stdout.readline().strip()
       except IOError as io_error:
         logging.debug("TsProxy: Error while reading tsproxy line: %s", io_error)
     return ""
 
-  def _send_command(self,
-                    command: str,
-                    timeout: Union[int, float] = DEFAULT_TIMEOUT) -> None:
+  def _send_command(
+      self,
+      command: str,
+      timeout: int | float = ts_proxy_settings.DEFAULT_TIMEOUT) -> None:
     logging.debug("TsProxy: Sending command to ts_proxy_server: %s", command)
     self._stdin.write(f"{command}\n")
     command_output = self._wait_for_status_response(timeout)
@@ -330,10 +315,10 @@ class TsProxyProcess:
     if not success:
       raise TsProxyServerError(f"Failed to execute command: {command}")
 
-  def _wait_for_status_response(self, timeout: Union[int, float]) -> List[str]:
+  def _wait_for_status_response(self, timeout: int | float) -> List[str]:
     logging.debug("TsProxy: waiting for status response")
     command_output = []
-    for _ in helper.wait_with_backoff(timeout):
+    for _ in wait.wait_with_backoff(timeout):
       self._stdin.flush()
       self._stdout.flush()
       last_output = self._read_line_ts_proxy_stdout(timeout)
@@ -342,12 +327,13 @@ class TsProxyProcess:
         break
     return command_output
 
-  def set_traffic_settings(self,
-                           rtt_ms: Optional[int] = None,
-                           in_kbps: Optional[int] = None,
-                           out_kbps: Optional[int] = None,
-                           window: Optional[int] = None,
-                           timeout=DEFAULT_TIMEOUT) -> None:
+  def set_traffic_settings(
+      self,
+      rtt_ms: Optional[int] = None,
+      in_kbps: Optional[int] = None,
+      out_kbps: Optional[int] = None,
+      window: Optional[int] = None,
+      timeout: float | int = ts_proxy_settings.DEFAULT_TIMEOUT) -> None:
     if rtt_ms is not None and self._rtt_ms != rtt_ms:
       assert rtt_ms >= 0, f"Invalid rtt value: {rtt_ms}"
       self._send_command(f"set rtt {rtt_ms}", timeout)
@@ -363,19 +349,24 @@ class TsProxyProcess:
       self._send_command(f"set outkbps {out_kbps}", timeout)
       self._out_kbps = out_kbps
 
-    if window is not None and self._window != window:
-      assert window >= 0, f"Invalid window value: {window}"
-      self._send_command(f"set window {window}", timeout)
-      self._window = window
+    # TODO: implement support in tsproxy
+    del window
+    # if window is not None and self._window != window:
+    #   assert window >= 0, f"Invalid window value: {window}"
+    #   self._send_command(f"set window {window}", timeout)
+    #   self._window = window
 
   def stop(self) -> Optional[str]:
     self._send_command("exit")
-    helper.wait_and_kill(self._proc, signal=signal.SIGINT)
-    _, err = self._proc.communicate()
+    self._platform.terminate_gracefully(self._process)
+    _, err = self._process.communicate()
     self._socks_proxy_port = self._initial_socks_proxy_port
     return err
 
 
+TsProxyTrafficShaperT = TypeVar(
+    "TsProxyTrafficShaperT", bound="TsProxyTrafficShaper")
+
 class TsProxyTrafficShaper(TrafficShaper):
 
   def __init__(self,
@@ -384,7 +375,7 @@ class TsProxyTrafficShaper(TrafficShaper):
                rtt_ms: Optional[int] = None,
                in_kbps: Optional[int] = None,
                out_kbps: Optional[int] = None,
-               window: Optional[int] = None):
+               window: Optional[int] = None) -> None:
     super().__init__(browser_platform)
     if not ts_proxy_path:
       if maybe_ts_proxy_path := TsProxyFinder(self.host_platform).path:
@@ -394,6 +385,7 @@ class TsProxyTrafficShaper(TrafficShaper):
           f"Could not find ts_proxy script on {self.host_platform}")
     # Early instantiation to validate inputs.
     self._ts_proxy = TsProxyServer(
+        self.host_platform,
         self.host_platform.local_path(ts_proxy_path),
         rtt_ms=rtt_ms,
         in_kbps=in_kbps,
@@ -407,8 +399,9 @@ class TsProxyTrafficShaper(TrafficShaper):
     return self._ts_proxy
 
   @contextlib.contextmanager
-  def open(self, network: Network,
-           session: BrowserSessionRunGroup) -> Iterator[TrafficShaper]:
+  @override
+  def open(self: TsProxyTrafficShaperT, network: Network,
+           session: BrowserSessionRunGroup) -> Iterator[TsProxyTrafficShaperT]:
     if not network.is_live:
       self._ts_proxy = self._create_remapping_ts_proxy(network)
 
@@ -418,8 +411,28 @@ class TsProxyTrafficShaper(TrafficShaper):
         with self._forward_ports(network, session):
           yield self
 
+  @contextlib.contextmanager
+  @override
+  def pause(self):
+    old_settings = {
+        "rtt_ms": self._ts_proxy.rtt_ms,
+        "in_kbps": self._ts_proxy.in_kbps,
+        "out_kbps": self._ts_proxy.out_kbps,
+        "window": self._ts_proxy.window,
+    }
+    try:
+      logging.info("TRAFFIC SHAPING: Pausing")
+      self._ts_proxy.set_traffic_settings(0, 0, 0,
+                                          ts_proxy_settings.DEFAULT_WINDOW_SIZE)
+      yield None
+    finally:
+      logging.info("TRAFFIC SHAPING: Restoring settings")
+      self._ts_proxy.set_traffic_settings(
+          **old_settings, timeout=ts_proxy_settings.DEFAULT_TIMEOUT)
+
   def _create_remapping_ts_proxy(self, network) -> TsProxyServer:
     return TsProxyServer(
+        self.host_platform,
         self._ts_proxy.ts_proxy_path,
         rtt_ms=self._ts_proxy.rtt_ms,
         in_kbps=self._ts_proxy.in_kbps,
@@ -443,6 +456,7 @@ class TsProxyTrafficShaper(TrafficShaper):
     if browser_platform.is_remote:
       browser_platform.stop_reverse_port_forward(ts_proxy_port)
 
+  @override
   def extra_flags(self, browser_attributes: BrowserAttributes) -> Flags:
     if not browser_attributes.is_chromium_based:
       raise ValueError(
diff --git a/crossbench/network/traffic_shaping/ts_proxy_settings.py b/crossbench/network/traffic_shaping/ts_proxy_settings.py
new file mode 100644
index 00000000..5f6eb297
--- /dev/null
+++ b/crossbench/network/traffic_shaping/ts_proxy_settings.py
@@ -0,0 +1,35 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import Any, Final, Mapping
+
+from immutabledict import immutabledict
+
+# TODO: improve and double check
+TRAFFIC_SETTINGS: Final[Mapping[str, Any]] = immutabledict({
+    "3G-slow": {
+        "rtt_ms": 400,
+        "in_kbps": 400,
+        "out_kbps": 400,
+    },
+    "3G-regular": {
+        "rtt_ms": 300,
+        "in_kbps": 1600,
+        "out_kbps": 768,
+    },
+    "3G-fast": {
+        "rtt_ms": 150,
+        "in_kbps": 1600,
+        "out_kbps": 768,
+    },
+    "4G": {
+        "rtt_ms": 170,
+        "in_kbps": 9000,
+        "out_kbps": 9000,
+    },
+})
+DEFAULT_WINDOW_SIZE: Final[int] = 10
+DEFAULT_TIMEOUT: Final[int] = 5
diff --git a/crossbench/parse.py b/crossbench/parse.py
index 827f8cae..0412f120 100644
--- a/crossbench/parse.py
+++ b/crossbench/parse.py
@@ -12,15 +12,16 @@ import logging
 import math
 import re
 import shlex
-from typing import (Any, Dict, Final, Iterable, List, Optional, Sequence, Type,
-                    TypeVar, Union, cast)
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, Iterable, List,
+                    Optional, Sequence, Type, TypeVar, cast)
 from urllib import parse as urlparse
 
 import hjson
 
 from crossbench import path as pth
-from crossbench import plt
 
+if TYPE_CHECKING:
+  from crossbench import plt
 
 def type_str(value: Any) -> str:
   return type(value).__name__
@@ -34,12 +35,19 @@ class PathParser:
                            r")(\\|/)[^\\/]")
 
   @classmethod
-  def path(cls, value: pth.AnyPathLike, name: str = "value") -> pth.LocalPath:
-    value = ObjectParser.not_none(value, "path")
-    if not value:
+  def value_has_path_prefix(cls, value: str) -> bool:
+    return cls.PATH_PREFIX.match(value) is not None
+
+  @classmethod
+  def path(cls,
+           value: Optional[pth.AnyPathLike],
+           name: str = "value") -> pth.LocalPath:
+    path_value: pth.AnyPathLike = ObjectParser.not_none(value,
+                                                        "path")  # type: ignore
+    if not path_value:
       raise argparse.ArgumentTypeError("Invalid empty path.")
     try:
-      path = pth.LocalPath(value).expanduser()
+      path = pth.LocalPath(path_value).expanduser()
     except RuntimeError as e:
       raise argparse.ArgumentTypeError(
           f"Invalid Path {name} {repr(value)}': {e}") from e
@@ -112,34 +120,43 @@ class PathParser:
     return path
 
   @classmethod
-  def binary_path(cls,
-                  value: Optional[pth.AnyPathLike],
-                  name: str = "binary",
-                  platform: Optional[plt.Platform] = None) -> pth.AnyPath:
-    platform = platform or plt.PLATFORM
-    maybe_path = platform.path(ObjectParser.not_none(value, name))
+  def binary_path(
+      cls,
+      value: Optional[pth.AnyPathLike],
+      platform: plt.Platform,
+      name: str = "binary",
+  ) -> pth.AnyPath:
+    not_none: pth.AnyPathLike = ObjectParser.not_none(value,
+                                                      name)  # type: ignore
+    maybe_path: pth.AnyPath = platform.path(not_none)
     if platform.is_file(maybe_path):
       return maybe_path
-    maybe_bin = platform.search_binary(maybe_path)
-    if not maybe_bin:
-      raise argparse.ArgumentTypeError(f"Unknown binary: {value}")
-    return maybe_bin
+    if maybe_bin := platform.search_binary(maybe_path):
+      return maybe_bin
+    raise argparse.ArgumentTypeError(f"Unknown binary: {value}")
 
   @classmethod
   def any_path(cls,
                value: Optional[pth.AnyPathLike],
                name: str = "value") -> pth.AnyPath:
     """Parse a path than can be on a local or remote file system."""
-    some_value: pth.AnyPathLike = ObjectParser.not_none(value, name)
-    if not some_value:
-      raise argparse.ArgumentTypeError(f"Expected non empty path {name}.")
-    return pth.AnyPath(some_value)
+    if some_value := ObjectParser.not_none(value, name):
+      return pth.AnyPath(some_value)  # type: ignore
+    raise argparse.ArgumentTypeError(f"Expected non empty path {name}.")
+
+  @classmethod
+  def optional_any_path(
+      cls, value: Optional[pth.AnyPathLike]) -> Optional[pth.AnyPath]:
+    if value is None:
+      return None
+    return cls.any_path(value)
 
   @classmethod
   def local_binary_path(cls,
                         value: Optional[pth.AnyPathLike],
+                        platform: plt.Platform,
                         name: str = "binary") -> pth.LocalPath:
-    return cast(pth.LocalPath, cls.binary_path(value, name))
+    return cast(pth.LocalPath, cls.binary_path(value, platform, name))
 
   @classmethod
   def json_file_path(cls, value: pth.AnyPathLike) -> pth.LocalPath:
@@ -167,7 +184,7 @@ class PathParser:
 
 
 EnumT = TypeVar("EnumT", bound=enum.Enum)
-NotNoneT = TypeVar("NotNoneT", bound=Any)
+NotNoneT = TypeVar("NotNoneT")
 SequenceT = TypeVar("SequenceT", bound=Sequence)
 
 
@@ -175,7 +192,7 @@ class ObjectParser:
 
   @classmethod
   def enum(cls, label: str, enum_cls: Type[EnumT], data: Any,
-           choices: Union[Type[EnumT], Iterable[EnumT]]) -> EnumT:
+           choices: Type[EnumT] | Iterable[EnumT]) -> EnumT:
     try:
       # Try direct conversion, relying on the Enum._missing_ hook:
       enum_value = enum_cls(data)
@@ -272,7 +289,7 @@ class ObjectParser:
 
   @classmethod
   def non_empty_sequence(cls, value: Any, name: str = "value") -> Sequence[Any]:
-    sequence_value = cls.sequence(value)
+    sequence_value = cls.sequence(value, name)
     if not sequence_value:
       raise argparse.ArgumentTypeError(
           f"Expected {name} to be a non-empty sequence.")
@@ -297,6 +314,15 @@ class ObjectParser:
       raise argparse.ArgumentTypeError(f"Non-empty string {name} expected.")
     return value
 
+  @classmethod
+  def str_or_file_contents(cls, value: Any, name: str = "value") -> str:
+    if isinstance(value, str):
+      str_value: str = cls.non_empty_str(value, name=name)
+      if not PathParser.value_has_path_prefix(str_value):
+        return str_value
+    path = PathParser.file_path(value, name=name)
+    return cls.non_empty_str(path.read_text(encoding="utf-8"), name=name)
+
   @classmethod
   def url_str(cls,
               value: str,
@@ -322,25 +348,25 @@ class ObjectParser:
   PORT_URL_PATH_RE = re.compile(r"^[0-9]+(?:/|$)")
 
   @classmethod
-  def parse_fuzzy_url_str(cls,
-                          value: str,
-                          name: str = "url",
-                          schemes: Sequence[str] = ("http", "https", "about",
-                                                    "file"),
-                          default_scheme: str = "https") -> str:
-    parsed = cls.parse_fuzzy_url(value, name, schemes, default_scheme)
+  def fuzzy_url_str(cls,
+                    value: str,
+                    name: str = "url",
+                    schemes: Sequence[str] = ("http", "https", "about", "file",
+                                              "data"),
+                    default_scheme: str = "https") -> str:
+    parsed = cls.fuzzy_url(value, name, schemes, default_scheme)
     return urlparse.urlunparse(parsed)
 
   @classmethod
-  def parse_fuzzy_url(cls,
-                      value: str,
-                      name: str = "url",
-                      schemes: Sequence[str] = ("http", "https", "about",
-                                                "file"),
-                      default_scheme: str = "https") -> urlparse.ParseResult:
+  def fuzzy_url(cls,
+                value: str,
+                name: str = "url",
+                schemes: Sequence[str] = ("http", "https", "about", "file",
+                                          "data"),
+                default_scheme: str = "https") -> urlparse.ParseResult:
     assert default_scheme, "missing default scheme value"
     value = cls.non_empty_str(value, name)
-    if PathParser.PATH_PREFIX.match(value):
+    if PathParser.value_has_path_prefix(value):
       value = f"file://{value}"
     else:
       parsed = cls.base_url(value)
@@ -371,7 +397,7 @@ class ObjectParser:
             f"but got {repr(parsed.scheme)} for url {repr(value)}")
       if port := parsed.port:
         _ = NumberParser.port_number(port, f"{name} port")
-      if scheme in ("file", "about"):
+      if scheme in ("file", "about", "data"):
         return parsed
       hostname = parsed.hostname
       if not hostname:
@@ -387,14 +413,24 @@ class ObjectParser:
     return parsed
 
   @classmethod
-  def bool(cls, value: Any, name: str = "value") -> bool:
+  def optional_bool(cls,
+                    value: Any,
+                    name: str = "value",
+                    strict: bool = False) -> Optional[bool]:
+    if value is None:
+      return None
+    return cls.bool(value, name, strict)
+
+  @classmethod
+  def bool(cls, value: Any, name: str = "value", strict: bool = False) -> bool:
     if isinstance(value, bool):
       return value
     value = str(value).lower()
-    if value == "true":
-      return True
-    if value == "false":
-      return False
+    if not strict:
+      if value == "true":
+        return True
+      if value == "false":
+        return False
     raise argparse.ArgumentTypeError(
         f"Expected bool {name} but got {type_str(value)}: {repr(value)}")
 
@@ -447,6 +483,10 @@ class ObjectParser:
     except re.error as e:
       raise argparse.ArgumentTypeError(f"Invalid regexp {name}: {value}") from e
 
+  @classmethod
+  def safe_filename(cls, value: Any, name: str = "safe filename") -> str:
+    return pth.safe_filename(cls.non_empty_str(value, name))
+
 
 _MAX_LEN = 70
 
@@ -499,15 +539,45 @@ class NumberParser:
       raise argparse.ArgumentTypeError(f"Invalid {name}: {repr(value)}") from e
 
   @classmethod
-  def positive_zero_float(cls, value: Any, name: str = "float") -> float:
+  def positive_float(cls, value: Any, name: str = "float") -> float:
     value_f = cls.any_float(value, name)
-    if not math.isfinite(value_f) or value_f < 0:
+    if not math.isfinite(value_f) or value_f <= 0:
       raise argparse.ArgumentTypeError(
-          f"Expected {name} >= 0, but got: {value_f}")
+          f"Expected {name} > 0, but got: {value_f}")
     return value_f
 
   @classmethod
-  def any_int(cls, value: Any, name: str = "value") -> int:
+  def positive_zero_float(cls, value: Any, name: str = "float") -> float:
+    return cls.float_range(0.0, math.inf, name=name)(value)
+
+  @classmethod
+  def float_range(  # pylint: disable=redefined-builtin
+      cls,
+      min: float = 0.0,
+      max: float = math.inf,
+      name: str = "float") -> Callable[[Any], float]:
+    assert min < max, f"Expected min={min} to be less than max={max}"
+
+    def float_ranged(value: Any) -> float:
+      value_f = cls.any_float(value, name)
+      if not math.isfinite(value_f) or value_f < min or max < value_f:
+        raise argparse.ArgumentTypeError(
+            f"Expected {min} <= {name} <= {max}, but got: {value_f}")
+      return value_f
+
+    return float_ranged
+
+  @classmethod
+  def any_int(cls,
+              value: Any,
+              name: str = "value",
+              parse_str: bool = True) -> int:
+    if (not parse_str and
+        isinstance(value, str)) or (not isinstance(value, (int, float, str))):
+      raise argparse.ArgumentTypeError(
+          f"Expected integer {name}, but got {type_str(value)}: {repr(value)}")
+    if isinstance(value, float) and not value.is_integer():
+      raise argparse.ArgumentTypeError(f"Invalid integer {name}: {repr(value)}")
     try:
       return int(value)
     except ValueError as e:
@@ -515,28 +585,47 @@ class NumberParser:
           f"Invalid integer {name}: {repr(value)}") from e
 
   @classmethod
-  def positive_zero_int(cls, value: Any, name: str = "value") -> int:
-    value_i = cls.any_int(value, name)
-    if value_i < 0:
-      raise argparse.ArgumentTypeError(
-          f"Expected integer {name} >= 0, but got: {value_i}")
-    return value_i
+  def positive_zero_int(cls,
+                        value: Any,
+                        name: str = "value",
+                        parse_str: bool = True) -> int:
+    return cls.int_range(0.0, name=name, parse_str=parse_str)(value)
 
   @classmethod
-  def positive_int(cls, value: Any, name: str = "value") -> int:
-    value_i = cls.any_int(value, name)
+  def positive_int(cls,
+                   value: Any,
+                   name: str = "value",
+                   parse_str: bool = True) -> int:
+    value_i = cls.any_int(value, name, parse_str)
     if not math.isfinite(value_i) or value_i <= 0:
       raise argparse.ArgumentTypeError(
           f"Expected integer {name} > 0, but got: {value_i}")
     return value_i
 
   @classmethod
-  def port_number(cls, value: Any, name: str = "port") -> int:
-    port = cls.any_int(value, name)
-    if 1 <= port <= 65535:
-      return port
-    raise argparse.ArgumentTypeError(
-        f"Invalid Port: expected 1 <= {name} <= 65535, but got: {repr(port)}")
+  def int_range(  # pylint: disable=redefined-builtin
+      cls,
+      min: float = 0.0,
+      max: float = math.inf,
+      name: str = "value",
+      parse_str: bool = True) -> Callable[[Any], int]:
+    assert min < max, f"Expected min={min} to be less than max={max}"
+
+    def int_ranged(value: Any) -> int:
+      value_i = cls.any_int(value, name, parse_str)
+      if not math.isfinite(value_i) or value_i < min or max < value_i:
+        raise argparse.ArgumentTypeError(
+            f"Expected integer {min} <= {name} <= {max}, but got: {value_i}")
+      return value_i
+
+    return int_ranged
+
+  @classmethod
+  def port_number(cls,
+                  value: Any,
+                  name: str = "port",
+                  parse_str: bool = True) -> int:
+    return cls.int_range(1, 65535, name, parse_str)(value)
 
 
 class LateArgumentError(argparse.ArgumentTypeError):
diff --git a/crossbench/path.py b/crossbench/path.py
index 6b8e1b78..3fe318ca 100644
--- a/crossbench/path.py
+++ b/crossbench/path.py
@@ -2,28 +2,29 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+import hashlib
 import pathlib
 import re
 import unicodedata
-from typing import Optional, Union
+from typing import Optional, TypeAlias
 
 # A path that can refer to files on a remote platform with potentially
 # a different Path flavour (e.g. Win vs Posix).
-AnyPath = pathlib.PurePath
-AnyPosixPath = pathlib.PurePosixPath
-AnyWindowsPath = pathlib.PureWindowsPath
+AnyPath: TypeAlias = pathlib.PurePath
+AnyPosixPath: TypeAlias = pathlib.PurePosixPath
+AnyWindowsPath: TypeAlias = pathlib.PureWindowsPath
 
-AnyPathLike = Union[str, AnyPath]
+AnyPathLike: TypeAlias = str | AnyPath
 
 # A path that only ever refers to files on the local host / runner platform.
 # Not that Path inherits from PurePath, and thus we can use a LocalPath in
 # all places a RemotePath is expected.
-LocalPath = pathlib.Path
-LocalPosixPath = pathlib.PosixPath
+LocalPath: TypeAlias = pathlib.Path
+LocalPosixPath: TypeAlias = pathlib.PosixPath
 
-LocalPathLike = Union[str, LocalPath]
+LocalPathLike: TypeAlias = str | LocalPath
 
-_UNSAFE_FILENAME_CHARS_RE = re.compile(r"[^a-zA-Z0-9+\-_.]")
+_UNSAFE_FILENAME_CHARS_RE: re.Pattern[str] = re.compile(r"[^a-zA-Z0-9+\-_.]")
 
 
 def safe_filename(name: str) -> str:
@@ -42,3 +43,11 @@ def try_resolve_existing_path(value: str) -> Optional[LocalPath]:
   if maybe_path.exists():
     return maybe_path
   return None
+
+
+def check_hash(file_path: LocalPath, file_hash: str) -> bool:
+  if not file_path.exists():
+    return False
+  sha1 = hashlib.sha1()
+  sha1.update(file_path.read_bytes())
+  return sha1.hexdigest() == file_hash
diff --git a/crossbench/plt/android_adb.py b/crossbench/plt/android_adb.py
index b66ad2c8..cf86139d 100644
--- a/crossbench/plt/android_adb.py
+++ b/crossbench/plt/android_adb.py
@@ -6,16 +6,23 @@ from __future__ import annotations
 
 import functools
 import logging
+import math
 import re
 import shlex
 import subprocess
 from typing import TYPE_CHECKING, Any, Dict, List, Mapping, Optional, Tuple
 
+from typing_extensions import override
+
 from crossbench import path as pth
-from crossbench.parse import PathParser
+from crossbench.parse import NumberParser
 from crossbench.plt.arch import MachineArch
 from crossbench.plt.posix import RemotePosixPlatform
 
+# Defines the Android permissions to be granted.
+# TODO(381985595): make this configurable.
+ANDROID_PERMISSIONS = ["POST_NOTIFICATIONS", "CAMERA", "RECORD_AUDIO"]
+
 if TYPE_CHECKING:
   from crossbench.plt.base import CmdArg, ListCmdArgs, Platform
   from crossbench.types import JsonDict
@@ -48,9 +55,16 @@ def adb_devices(
 
 
 def _parse_adb_device_info(value: str) -> Dict[str, str]:
+  """
+  Convert a line from adb devices -l into a descriptive dictionary.
+  `value` is a line of output, typically:
+  ABCDEF01234567 device 2-1 product:shiba model:AOSP device:shiba transport_id:3
+
+  Some older versions of adb would not contain the `2-1` part.
+  """
   parts = value.split(" ")
   assert parts[0], "device"
-  return dict(part.split(":") for part in parts[1:])
+  return dict(part.split(":") for part in parts[1:] if ":" in part)
 
 
 class Adb:
@@ -65,7 +79,7 @@ class Adb:
                adb_bin: Optional[pth.AnyPath] = None) -> None:
     self._host_platform = host_platform
     if adb_bin:
-      self._adb_bin = PathParser.binary_path(adb_bin, platform=host_platform)
+      self._adb_bin = host_platform.parse_binary_path(adb_bin)
     else:
       self._adb_bin = _find_adb_bin(host_platform)
     self.start_server()
@@ -129,23 +143,14 @@ class Adb:
   def device_info(self) -> Dict[str, str]:
     return self._device_info
 
-  def popen(self,
-            *args: CmdArg,
-            bufsize=-1,
-            shell: bool = False,
-            stdout=None,
-            stderr=None,
-            stdin=None,
-            env: Optional[Mapping[str, str]] = None,
-            quiet: bool = False) -> subprocess.Popen:
-    del shell
-    assert not env, "ADB does not support setting env vars."
-    if not quiet:
-      logging.debug("SHELL: %s", shlex.join(map(str, args)))
-    adb_cmd: ListCmdArgs = [self._adb_bin, "-s", self._serial_id, "shell"]
+  def _build_adb_cmd(self,
+                     *args: CmdArg,
+                     use_serial_id: bool = True) -> ListCmdArgs:
+    adb_cmd: ListCmdArgs = [self._adb_bin]
+    if use_serial_id:
+      adb_cmd.extend(("-s", self._serial_id))
     adb_cmd.extend(args)
-    return self._host_platform.popen(
-        *adb_cmd, bufsize=bufsize, stdout=stdout, stderr=stderr, stdin=stdin)
+    return adb_cmd
 
   def _adb(self,
            *args: CmdArg,
@@ -159,12 +164,7 @@ class Adb:
            check: bool = True,
            use_serial_id: bool = True) -> subprocess.CompletedProcess:
     del shell
-    adb_cmd: ListCmdArgs = []
-    if use_serial_id:
-      adb_cmd = [self._adb_bin, "-s", self._serial_id]
-    else:
-      adb_cmd = [self._adb_bin]
-    adb_cmd.extend(args)
+    adb_cmd = self._build_adb_cmd(*args, use_serial_id=use_serial_id)
     return self._host_platform.sh(
         *adb_cmd,
         capture_output=capture_output,
@@ -196,28 +196,38 @@ class Adb:
                         stdin=None,
                         use_serial_id: bool = True,
                         check: bool = True) -> bytes:
-    adb_cmd: ListCmdArgs = []
-    if use_serial_id:
-      adb_cmd = [self._adb_bin, "-s", self._serial_id]
-    else:
-      adb_cmd = [self._adb_bin]
-    adb_cmd.extend(args)
+    adb_cmd = self._build_adb_cmd(*args, use_serial_id=use_serial_id)
     return self._host_platform.sh_stdout_bytes(
         *adb_cmd, quiet=quiet, check=check, stdin=stdin)
 
+  def build_shell_cmd(self, *args: CmdArg, shell: bool = False) -> ListCmdArgs:
+    self._host_platform.validate_shell_args(args, shell)
+    shell_cmd: ListCmdArgs = ["shell"]
+    if not shell:
+      shell_cmd.append(shlex.join(map(str, args)))
+    elif len(args) == 1:
+      shell_cmd.append(args[0])
+    else:
+      raise ValueError("Expected single sh arg with shell=True, "
+                       f"but got: {args}")
+    adb_shell_cmd = self._build_adb_cmd(*shell_cmd)
+    return adb_shell_cmd
+
   def shell_stdout(self,
                    *args: CmdArg,
+                   shell: bool = False,
                    quiet: bool = False,
                    encoding: str = "utf-8",
                    stdin=None,
                    env: Optional[Mapping[str, str]] = None,
                    check: bool = True) -> str:
     result = self.shell_stdout_bytes(
-        *args, quiet=quiet, stdin=stdin, env=env, check=check)
+        *args, shell=shell, quiet=quiet, stdin=stdin, env=env, check=check)
     return result.decode(encoding)
 
   def shell_stdout_bytes(self,
                          *args: CmdArg,
+                         shell: bool = False,
                          quiet: bool = False,
                          stdin=None,
                          env: Optional[Mapping[str, str]] = None,
@@ -229,10 +239,9 @@ class Adb:
     # -x: disable remote exit codes and stdout/stderr separation
     if env:
       raise ValueError("ADB shell only supports an empty env for now.")
-    #Need to escape spaces in args for adb shell
-    str_args = map(lambda x: str(x).replace(" ", "\\ "), args)
-    return self._adb_stdout_bytes(
-        "shell", *str_args, stdin=stdin, quiet=quiet, check=check)
+    shell_cmd = self.build_shell_cmd(*args, shell=shell)
+    return self._host_platform.sh_stdout_bytes(
+        *shell_cmd, stdin=stdin, quiet=quiet, check=check)
 
   def shell(self,
             *args: CmdArg,
@@ -244,11 +253,12 @@ class Adb:
             env: Optional[Mapping[str, str]] = None,
             quiet: bool = False,
             check: bool = True) -> subprocess.CompletedProcess:
+    if env:
+      raise ValueError("ADB shell only supports an empty env for now.")
     # See shell_stdout for more `adb shell` options.
-    adb_cmd: ListCmdArgs = ["shell", *args]
-    return self._adb(
-        *adb_cmd,
-        shell=shell,
+    shell_cmd = self.build_shell_cmd(*args, shell=shell)
+    return self._host_platform.sh(
+        *shell_cmd,
         capture_output=capture_output,
         stdout=stdout,
         stderr=stderr,
@@ -266,13 +276,20 @@ class Adb:
   def kill_server(self) -> None:
     self._adb_stdout("kill-server", use_serial_id=False)
 
+  def root(self) -> None:
+    self._adb("root", use_serial_id=False)
+
+  def unroot(self) -> None:
+    self._adb("unroot", use_serial_id=False)
+
   def devices(self) -> Dict[str, Dict[str, str]]:
     return adb_devices(self._host_platform, self._adb_bin)
 
   def forward(self, local: int, remote: int, protocol: str = "tcp") -> int:
     stdout = self._adb_stdout(
         "forward", f"{protocol}:{local}", f"{protocol}:{remote}")
-    return int(stdout)
+    local_port = NumberParser.port_number(stdout, "local_port")
+    return local_port
 
   def forward_remove(self, local: int, protocol: str = "tcp") -> None:
     self._adb("forward", "--remove", f"{protocol}:{local}")
@@ -280,7 +297,8 @@ class Adb:
   def reverse(self, remote: int, local: int, protocol: str = "tcp") -> int:
     stdout = self._adb_stdout(
         "reverse", f"{protocol}:{remote}", f"{protocol}:{local}")
-    return int(stdout)
+    remote_port = NumberParser.port_number(stdout, "remote_port")
+    return remote_port
 
   def reverse_remove(self, remote: int, protocol: str = "tcp") -> None:
     self._adb("reverse", "--remove", f"{protocol}:{remote}")
@@ -394,19 +412,22 @@ class Adb:
       else:
         raise
 
-  def grant_notification_permissions(self, package_name: str) -> None:
+  def grant_permissions(self, package_name: str) -> None:
     if self.build_version < 13:
       # Notification permission setting is needed for Android 13 and above.
       # https://developer.android.com/develop/ui/views/notifications/notification-permission  # pylint: disable=line-too-long
       return
     if not package_name:
       raise ValueError("Got empty package name")
-    cmd: ListCmdArgs = ["pm", "grant"]
+    user: str | None = None
     if self.build_version >= 14:
       user = self.cmd("user", "get-main-user").strip()
-      cmd.extend(["--user", user])
-    cmd.extend([package_name, "android.permission.POST_NOTIFICATIONS"])
-    self.shell(*cmd)
+    for perm in ANDROID_PERMISSIONS:
+      cmd: ListCmdArgs = ["pm", "grant"]
+      if user:
+        cmd.extend(["--user", user])
+      cmd.extend([package_name, f"android.permission.{perm}"])
+      self.shell(*cmd)
 
 
 class AndroidAdbPlatform(RemotePosixPlatform):
@@ -416,25 +437,27 @@ class AndroidAdbPlatform(RemotePosixPlatform):
                device_identifier: Optional[str] = None,
                adb: Optional[Adb] = None) -> None:
     super().__init__(host_platform)
-    self._system_details: Optional[Dict[str, Any]] = None
-    self._cpu_details: Optional[Dict[str, Any]] = None
     assert not host_platform.is_remote, (
         "adb on remote platform is not supported yet")
     self._adb = adb or Adb(host_platform, device_identifier)
 
   @property
+  @override
   def is_android(self) -> bool:
     return True
 
   @property
+  @override
   def name(self) -> str:
     return "android"
 
   @functools.cached_property
+  @override
   def version(self) -> str:  #pylint: disable=invalid-overridden-method
     return str(self.adb.build_version)
 
   @functools.cached_property
+  @override
   def device(self) -> str:  #pylint: disable=invalid-overridden-method
     return self.adb.getprop("ro.product.model")
 
@@ -443,14 +466,18 @@ class AndroidAdbPlatform(RemotePosixPlatform):
     return self._adb.serial_id
 
   @functools.cached_property
+  @override
   def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
     variant = self.adb.getprop("dalvik.vm.isa.arm.variant")
     platform = self.adb.getprop("ro.board.platform")
     cpu_str = f"{variant} {platform}"
-    if cores_info := self._get_cpu_cores_info():
-      cpu_str = f"{cpu_str} {cores_info}"
+    if num_cores := self.cpu_cores(logical=False):
+      cpu_str = f"{cpu_str} {num_cores} cores"
     return cpu_str
 
+  def cpu_usage(self) -> float:
+    return math.nan
+
   @property
   def adb(self) -> Adb:
     return self._adb
@@ -463,6 +490,7 @@ class AndroidAdbPlatform(RemotePosixPlatform):
   }
 
   @functools.cached_property
+  @override
   def machine(self) -> MachineArch:  #pylint: disable=invalid-overridden-method
     cpu_abi = self.adb.getprop("ro.product.cpu.abi")
     arch = self._MACHINE_ARCH_LOOKUP.get(cpu_abi, None)
@@ -470,16 +498,23 @@ class AndroidAdbPlatform(RemotePosixPlatform):
       raise ValueError(f"Unknown android CPU ABI: {cpu_abi}")
     return arch
 
+  @override
+  def get_relative_cpu_speed(self) -> float:
+    # TODO figure out
+    return 1.0
+
   def app_path_to_package(self, app_path: pth.AnyPathLike) -> str:
     path = self.path(app_path)
-    if len(path.parts) > 1:
+    parts = path.parts
+    if len(parts) > 1:
       raise ValueError(f"Invalid android package name: '{path}'")
-    package: str = path.parts[0]
+    package: str = parts[0]
     packages = self.adb.packages()
     if package not in packages:
       raise ValueError(f"Package '{package}' is not installed on {self._adb}")
     return package
 
+  @override
   def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
     app_or_bin_path = self.path(app_or_bin)
     if not app_or_bin_path.parts:
@@ -490,11 +525,13 @@ class AndroidAdbPlatform(RemotePosixPlatform):
       return app_or_bin_path
     return None
 
+  @override
   def home(self) -> pth.AnyPath:
     raise RuntimeError("Cannot access home dir on (non-rooted) android device")
 
   _VERSION_NAME_RE = re.compile(r"versionName=(?P<version>.+)")
 
+  @override
   def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
     # adb shell dumpsys package com.chrome.canary | grep versionName -C2
     package = self.app_path_to_package(app_or_bin)
@@ -505,29 +542,20 @@ class AndroidAdbPlatform(RemotePosixPlatform):
           f"Could not find version for '{package}': {package_info}")
     return match_result.group("version")
 
+  @override
   def process_children(self,
                        parent_pid: int,
                        recursive: bool = False) -> List[Dict[str, Any]]:
     # TODO: implement
     return []
 
+  @override
   def foreground_process(self) -> Optional[Dict[str, Any]]:
     # adb shell dumpsys activity activities
     # TODO: implement
     return None
 
-  def get_relative_cpu_speed(self) -> float:
-    # TODO figure out
-    return 1.0
-
-  def python_details(self) -> JsonDict:
-    # Python is not available on android.
-    return {}
-
-  def os_details(self) -> JsonDict:
-    # TODO: add more info
-    return {"version": self.version}
-
+  @override
   def check_autobrightness(self) -> bool:
     # adb shell dumpsys display
     # TODO: implement.
@@ -536,6 +564,7 @@ class AndroidAdbPlatform(RemotePosixPlatform):
   _BRIGHTNESS_RE = re.compile(
       r"mLatestFloatBrightness=(?P<brightness>[0-9]+\.[0-9]+)")
 
+  @override
   def get_main_display_brightness(self) -> int:
     display_info: str = self.adb.shell_stdout("dumpsys", "display")
     match_result = self._BRIGHTNESS_RE.search(display_info)
@@ -544,9 +573,15 @@ class AndroidAdbPlatform(RemotePosixPlatform):
     return int(float(match_result.group("brightness")) * 100)
 
   @property
+  @override
   def default_tmp_dir(self) -> pth.AnyPath:
     return self.path("/data/local/tmp/")
 
+  @override
+  def build_shell_cmd(self, *args: CmdArg, shell: bool = False) -> ListCmdArgs:
+    return self.adb.build_shell_cmd(*args, shell=shell)
+
+  @override
   def sh(self,
          *args: CmdArg,
          shell: bool = False,
@@ -556,7 +591,7 @@ class AndroidAdbPlatform(RemotePosixPlatform):
          stdin=None,
          env: Optional[Mapping[str, str]] = None,
          quiet: bool = False,
-         check: bool = False) -> subprocess.CompletedProcess:
+         check: bool = True) -> subprocess.CompletedProcess:
     return self.adb.shell(
         *args,
         shell=shell,
@@ -568,6 +603,7 @@ class AndroidAdbPlatform(RemotePosixPlatform):
         quiet=quiet,
         check=check)
 
+  @override
   def sh_stdout_bytes(self,
                       *args: CmdArg,
                       shell: bool = False,
@@ -575,42 +611,36 @@ class AndroidAdbPlatform(RemotePosixPlatform):
                       stdin=None,
                       env: Optional[Mapping[str, str]] = None,
                       check: bool = True) -> bytes:
-    # The shell option is not supported on adb.
-    del shell
     return self.adb.shell_stdout_bytes(
-        *args, stdin=stdin, env=env, quiet=quiet, check=check)
-
-  def popen(self,
-            *args: CmdArg,
-            bufsize=-1,
-            shell: bool = False,
-            stdout=None,
-            stderr=None,
-            stdin=None,
-            env: Optional[Mapping[str, str]] = None,
-            quiet: bool = False) -> subprocess.Popen:
-    return self.adb.popen(
-        *args,
-        bufsize=bufsize,
-        shell=shell,
-        stdout=stdout,
-        stderr=stderr,
-        stdin=stdin,
-        env=env,
-        quiet=quiet)
+        *args, shell=shell, stdin=stdin, env=env, quiet=quiet, check=check)
 
+  @override
   def port_forward(self, local_port: int, remote_port: int) -> int:
-    return self.adb.forward(local_port, remote_port, protocol="tcp")
-
+    local_port = NumberParser.positive_zero_int(local_port, "local_port")
+    remote_port = NumberParser.port_number(remote_port, "remote_port")
+    local_port = self.adb.forward(local_port, remote_port, protocol="tcp")
+    logging.debug("Forwarded Remote Port: %s:%s <= %s:%s",
+                  self._host_platform.name, local_port, self, remote_port)
+    return local_port
+
+  @override
   def stop_port_forward(self, local_port: int) -> None:
     self.adb.forward_remove(local_port, protocol="tcp")
 
+  @override
   def reverse_port_forward(self, remote_port: int, local_port: int) -> int:
-    return self.adb.reverse(remote_port, local_port, protocol="tcp")
-
+    remote_port = NumberParser.positive_zero_int(remote_port, "remote_port")
+    local_port = NumberParser.port_number(local_port, "local_port")
+    remote_port = self.adb.reverse(remote_port, local_port, protocol="tcp")
+    logging.debug("Forwarded Local Port: %s:%s => %s:%s", self._host_platform,
+                  local_port, self, remote_port)
+    return remote_port
+
+  @override
   def stop_reverse_port_forward(self, remote_port: int) -> None:
     self.adb.reverse_remove(remote_port, protocol="tcp")
 
+  @override
   def pull(self, from_path: pth.AnyPath,
            to_path: pth.LocalPath) -> pth.LocalPath:
     device_path = self.path(from_path)
@@ -621,11 +651,13 @@ class AndroidAdbPlatform(RemotePosixPlatform):
     self.adb.pull(device_path, local_host_path)
     return to_path
 
+  @override
   def push(self, from_path: pth.LocalPath, to_path: pth.AnyPath) -> pth.AnyPath:
     to_path = self.path(to_path)
     self.adb.push(self.host_path(from_path), to_path)
     return to_path
 
+  @override
   def processes(self,
                 attrs: Optional[List[str]] = None) -> List[Dict[str, Any]]:
     lines = self.sh_stdout("ps", "-A", "-o", "PID,NAME").splitlines()
@@ -639,56 +671,76 @@ class AndroidAdbPlatform(RemotePosixPlatform):
       res.append({"pid": int(tokens[0]), "name": tokens[1]})
     return res
 
+  @functools.lru_cache(maxsize=1)
+  @override
   def cpu_details(self) -> Dict[str, Any]:
-    if self._cpu_details:
-      return self._cpu_details
     # TODO: Implement properly (i.e. remove all n/a values)
-    self._cpu_details = {
+    return {
         "info": self.cpu,
-        "physical cores": "n/a",
-        "logical cores": "n/a",
+        "physical cores": self.cpu_cores(logical=False),
+        "logical cores": self.cpu_cores(logical=True),
         "usage": "n/a",
         "total usage": "n/a",
         "system load": "n/a",
-        "max frequency": "n/a",
         "min frequency": "n/a",
+        "max frequency": "n/a",
         "current frequency": "n/a",
     }
-    return self._cpu_details
 
   _GETPROP_RE = re.compile(r"^\[(?P<key>[^\]]+)\]: \[(?P<value>[^\]]+)\]$")
 
+  @functools.lru_cache(maxsize=1)
+  @override
+  def system_details(self) -> Dict[str, Any]:
+    system_details = super().system_details()
+    system_details.update({
+        "Android": self._getprop_system_details(),
+    })
+    return system_details
+
   def _getprop_system_details(self) -> Dict[str, Any]:
-    details = super().system_details()
     properties: Dict[str, str] = {}
     for line in self.adb.shell_stdout("getprop").strip().splitlines():
       result = self._GETPROP_RE.fullmatch(line)
       if result:
         properties[result.group("key")] = result.group("value")
-    details["android"] = properties
-    return details
-
-  def system_details(self) -> Dict[str, Any]:
-    if self._system_details:
-      return self._system_details
+    return properties
 
+  @functools.lru_cache(maxsize=1)
+  @override
+  def python_details(self) -> JsonDict:
     # TODO: Implement properly (i.e. remove all n/a values)
-    self._system_details = {
-        "machine": self.sh_stdout("uname", "-m").split()[0],
-        "os": {
-            "system": self.sh_stdout("uname", "-s").split()[0],
-            "release": self.sh_stdout("uname", "-r").split()[0],
-            "version": self.sh_stdout("uname", "-v").split()[0],
-            "platform": "n/a",
-        },
-        "python": {
+    return {
             "version": "n/a",
             "bits": "n/a",
-        },
-        "CPU": self.cpu_details(),
-        "Android": self._getprop_system_details(),
     }
-    return self._system_details
 
+
+  @property
+  @override
+  def is_battery_powered(self) -> bool:
+    battery_info = self.adb.dumpsys("battery").lower()
+    # Looking for any power source, i.e. 'AC powered: true'
+    has_external_power = " powered: true" in battery_info
+    return not has_external_power
+
+  @override
   def screenshot(self, result_path: pth.AnyPath) -> None:
     self.sh("screencap", "-p", result_path)
+
+  _DUMPSYS_WINDOW_DISPLAYS_RE = re.compile(r" cur=(?P<x>\d+)x(?P<y>\d+) ")
+
+  @override
+  def display_resolution(self) -> Tuple[int, int]:
+    displays_out = self.sh_stdout("dumpsys", "window", "displays")
+    match_result = self._DUMPSYS_WINDOW_DISPLAYS_RE.search(displays_out)
+    if match_result is None:
+      raise ValueError(
+          "Could not find display resolution in "
+          f"'adb shell -s {self.adb.serial_id} dumpsys window displays'")
+    x = NumberParser.positive_int(match_result.group("x"))
+    y = NumberParser.positive_int(match_result.group("y"))
+    return (x, y)
+
+  def user_id(self) -> int:
+    return NumberParser.any_int(self.sh_stdout("am", "get-current-user"))
diff --git a/crossbench/plt/base.py b/crossbench/plt/base.py
index f10eb71b..d69058d0 100644
--- a/crossbench/plt/base.py
+++ b/crossbench/plt/base.py
@@ -5,8 +5,10 @@
 from __future__ import annotations
 
 import abc
+import atexit
 import collections.abc
 import contextlib
+import dataclasses
 import datetime as dt
 import functools
 import inspect
@@ -16,33 +18,40 @@ import pathlib
 import platform as py_platform
 import shlex
 import shutil
+import socket
 import subprocess
 import sys
 import tempfile
-import time
 import urllib.error
 import urllib.parse
 import urllib.request
-from typing import (TYPE_CHECKING, Any, Callable, Dict, Final, Generator,
-                    Iterable, Iterator, List, Mapping, Optional, Sequence,
-                    Tuple, Union)
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Generator, Iterable,
+                    Iterator, List, Mapping, Optional, Sequence, Tuple, Type,
+                    TypeAlias)
 
 import psutil
 
+from crossbench import parse
 from crossbench import path as pth
+from crossbench.helper import wait
+from crossbench.plt import proc_helper
 from crossbench.plt.arch import MachineArch
 from crossbench.plt.bin import Binary
+from crossbench.plt.remote import RemotePopen
 
 if TYPE_CHECKING:
-  from crossbench.path import LocalPath
-  from crossbench.types import JsonDict
-
+  from asyncio.subprocess import Process
+  from subprocess import Popen
 
-CmdArg = pth.AnyPathLike
-ListCmdArgs = List[CmdArg]
-TupleCmdArgs = Tuple[CmdArg, ...]
-CmdArgs = Union[ListCmdArgs, TupleCmdArgs]
+  from crossbench.plt.signals import AnySignals, Signals
+  from crossbench.types import JsonDict
+  ProcessLike: TypeAlias = Popen | Process | int
 
+CmdArg: TypeAlias = pth.AnyPathLike
+SequenceCmdArgs: TypeAlias = Sequence[CmdArg]
+ListCmdArgs: TypeAlias = List[CmdArg]
+TupleCmdArgs: TypeAlias = Tuple[CmdArg, ...]
+CmdArgs: TypeAlias = ListCmdArgs | TupleCmdArgs
 
 class Environ(collections.abc.MutableMapping, metaclass=abc.ABCMeta):
   pass
@@ -84,8 +93,12 @@ class SubprocessError(subprocess.CalledProcessError):
     return f"{self.platform}: {super_str}\nstderr:{self.stderr.decode()}"
 
 
-_IGNORED_PROCESS_EXCEPTIONS: Final = (psutil.NoSuchProcess, psutil.AccessDenied,
-                                      psutil.ZombieProcess)
+@dataclasses.dataclass
+class CPUFreqInfo:
+  min: float
+  max: float
+  current: float
+
 
 DEFAULT_CACHE_DIR = pth.LocalPath(__file__).parents[2] / "cache"
 
@@ -94,9 +107,7 @@ class Platform(abc.ABC):
 
   def __init__(self) -> None:
     self._binary_lookup_override: Dict[str, pth.AnyPath] = {}
-    self._cache_dir: Optional[pth.AnyPath] = None
-    if self.is_local:
-      self._cache_dir = DEFAULT_CACHE_DIR
+    self._cache_dir_root: pth.AnyPath | None = None
 
   def assert_is_local(self) -> None:
     if self.is_local:
@@ -106,6 +117,11 @@ class Platform(abc.ABC):
     raise RuntimeError(f"{type(self).__name__}.{caller}(...) is not supported "
                        "on remote platform")
 
+  @property
+  @abc.abstractmethod
+  def signals(self) -> Type[AnySignals]:
+    pass
+
   @property
   @abc.abstractmethod
   def name(self) -> str:
@@ -126,6 +142,13 @@ class Platform(abc.ABC):
   def cpu(self) -> str:
     pass
 
+  @functools.lru_cache(maxsize=2)
+  def cpu_cores(self, logical: bool) -> int:
+    self.assert_is_local()
+    if cores := psutil.cpu_count(logical=logical):
+      return cores
+    return 0
+
   @property
   def full_version(self) -> str:
     return f"{self.name} {self.version} {self.machine}"
@@ -158,6 +181,7 @@ class Platform(abc.ABC):
       return MachineArch.ARM_32
     raise NotImplementedError(f"Unsupported machine type: {raw}")
 
+  @functools.lru_cache(maxsize=1)
   def _raw_machine_arch(self) -> str:
     self.assert_is_local()
     return py_platform.machine()
@@ -221,6 +245,84 @@ class Platform(abc.ABC):
       return False
     return not status.power_plugged
 
+  @functools.lru_cache(maxsize=1)
+  def cpu_details(self) -> Dict[str, Any]:
+    self.assert_is_local()
+    details = {
+        "physical cores":
+            self.cpu_cores(logical=False),
+        "logical cores":
+            self.cpu_cores(logical=True),
+        "usage":
+            psutil.cpu_percent(  # pytype: disable=attribute-error
+                percpu=True, interval=0.1),
+        "total usage":
+            psutil.cpu_percent(),
+        "system load":
+            psutil.getloadavg(),
+        "info":
+            self.cpu,
+        "min frequency":
+            "N/A",
+        "max frequency":
+            "N/A",
+        "current frequency":
+            "N/A",
+    }
+    if cpu_freq := self._cpu_freq():
+      details.update({
+          "min frequency": f"{cpu_freq.min:.2f}Mhz",
+          "max frequency": f"{cpu_freq.max:.2f}Mhz",
+          "current frequency": f"{cpu_freq.current:.2f}Mhz",
+      })
+    return details
+
+  def _cpu_freq(self) -> Optional[CPUFreqInfo]:
+    self.assert_is_local()
+    cpu_freq = psutil.cpu_freq()
+    return CPUFreqInfo(cpu_freq.min, cpu_freq.max, cpu_freq.current)
+
+
+  @functools.lru_cache(maxsize=1)
+  def system_details(self) -> Dict[str, Any]:
+    return {
+        "machine": str(self.machine),
+        "os": self.os_details(),
+        "python": self.python_details(),
+        "CPU": self.cpu_details(),
+    }
+
+  @functools.lru_cache(maxsize=1)
+  def os_details(self) -> JsonDict:
+    self.assert_is_local()
+    return {
+        "system": py_platform.system(),
+        "release": py_platform.release(),
+        "version": py_platform.version(),
+        "platform": py_platform.platform(),
+    }
+
+  @functools.lru_cache(maxsize=1)
+  def python_details(self) -> JsonDict:
+    self.assert_is_local()
+    return {
+        "version": py_platform.python_version(),
+        "bits": 64 if sys.maxsize > 2**32 else 32,
+    }
+
+  def get_relative_cpu_speed(self) -> float:
+    return 1
+
+  def is_thermal_throttled(self) -> bool:
+    return self.get_relative_cpu_speed() < 1
+
+  def disk_usage(self, path: pth.AnyPathLike) -> psutil._common.sdiskusage:
+    return psutil.disk_usage(str(self.local_path(path)))
+
+  def cpu_usage(self) -> float:
+    self.assert_is_local()
+    return 1 - psutil.cpu_times_percent().idle / 100
+
   def _search_executable(
       self,
       name: str,
@@ -286,20 +388,29 @@ class Platform(abc.ABC):
     This can be false on linux without $DISPLAY, true an all other platforms."""
     return True
 
-  def sleep(self, seconds: Union[int, float, dt.timedelta]) -> None:
-    if isinstance(seconds, dt.timedelta):
-      seconds = seconds.total_seconds()
-    if seconds == 0:
-      return
-    logging.debug("WAIT %ss", seconds)
-    time.sleep(seconds)
+  def sleep(self, seconds: int | float | dt.timedelta) -> None:
+    wait.sleep(seconds)
+
+  def parse_binary_path(self,
+                        value: pth.AnyPathLike,
+                        name: str = "value") -> pth.AnyPath:
+    # Helper to avoid circular imports.
+    return parse.PathParser.binary_path(value, self, name)
+
+  def parse_local_binary_path(self,
+                              value: pth.AnyPathLike,
+                              name: str = "value") -> pth.LocalPath:
+    self.assert_is_local()
+    # Helper to avoid circular imports.
+    return parse.PathParser.local_binary_path(value, self, name)
+
 
   def which(self, binary_name: pth.AnyPathLike) -> Optional[pth.AnyPath]:
     if not binary_name:
       raise ValueError("Got empty path")
     self.assert_is_local()
-    if override := self.lookup_binary_override(binary_name):
-      return override
+    if binary_override := self.lookup_binary_override(binary_name):
+      return binary_override
     if result := shutil.which(os.fspath(binary_name)):
       return self.path(result)
     return None
@@ -309,7 +420,7 @@ class Platform(abc.ABC):
     return self._binary_lookup_override.get(os.fspath(binary_name))
 
   def set_binary_lookup_override(self, binary_name: pth.AnyPathLike,
-                                 new_path: Optional[pth.AnyPath]):
+                                 new_path: Optional[pth.AnyPath]) -> None:
     name = os.fspath(binary_name)
     if new_path is None:
       prev_result = self._binary_lookup_override.pop(name, None)
@@ -324,7 +435,7 @@ class Platform(abc.ABC):
     self._binary_lookup_override[name] = new_path
 
   @contextlib.contextmanager
-  def override_binary(self, binary: Union[pth.AnyPathLike, Binary],
+  def override_binary(self, binary: pth.AnyPathLike | Binary,
                       result: Optional[pth.AnyPath]):
     binary_name: pth.AnyPathLike = ""
     if isinstance(binary, Binary):
@@ -342,6 +453,49 @@ class Platform(abc.ABC):
     finally:
       self.set_binary_lookup_override(binary_name, prev_override)
 
+  def send_signal(self, process: ProcessLike, signal: Signals) -> None:
+    self.assert_is_local()
+    if isinstance(process, int):
+      os.kill(process, signal.value)
+    else:
+      process.send_signal(signal.value)
+
+  def terminate(self, process: ProcessLike) -> None:
+    self._handle_process_tree(process, lambda process: process.terminate())
+
+  def kill(self, process: ProcessLike) -> None:
+    self._handle_process_tree(process, lambda process: process.kill())
+
+  def terminate_gracefully(self,
+                           process: ProcessLike,
+                           timeout: int = 1,
+                           signal: Optional[Signals] = None) -> None:
+    proc_helper.terminate_gracefully(self, process, timeout, signal)
+
+  def process_pid(self, process: ProcessLike) -> int:
+    if isinstance(process, int):
+      return process
+    if isinstance(process, RemotePopen):
+      assert self.is_remote, (
+          f"Cannot access remote process {process} on local platform {self}")
+      return process.remote_pid
+    return process.pid
+
+  def _handle_process_tree(self, process: ProcessLike,
+                           callback: Callable[[psutil.Process], None]) -> None:
+    self.assert_is_local()
+    try:
+      pid: int = self.process_pid(process)
+      ps_process = psutil.Process(pid)
+      for child_process in ps_process.children(recursive=True):
+        try:
+          callback(child_process)
+        except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
+          pass
+      callback(ps_process)
+    except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
+      pass
+
   def processes(self,
                 attrs: Optional[List[str]] = None) -> List[Dict[str, Any]]:
     # TODO(cbruni): support remote platforms
@@ -355,7 +509,7 @@ class Platform(abc.ABC):
       try:
         if proc.name().lower() in process_name_list:
           return proc.name()
-      except _IGNORED_PROCESS_EXCEPTIONS:
+      except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
         pass
     return None
 
@@ -366,7 +520,7 @@ class Platform(abc.ABC):
     # TODO(cbruni): support remote platforms
     try:
       process = psutil.Process(parent_pid)
-    except _IGNORED_PROCESS_EXCEPTIONS:
+    except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
       return []
     return self._collect_process_dict(process.children(recursive=recursive))
 
@@ -376,37 +530,32 @@ class Platform(abc.ABC):
     for process in process_iterator:
       try:
         process_info_list.append(process.as_dict())
-      except _IGNORED_PROCESS_EXCEPTIONS:
+      except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
         pass
     return process_info_list
 
-  def process_info(self, pid: int) -> Optional[Dict[str, Any]]:
+  def process_info(self, process: ProcessLike) -> Optional[Dict[str, Any]]:
     self.assert_is_local()
     # TODO(cbruni): support remote platforms
     try:
+      pid = self.process_pid(process)
       return psutil.Process(pid).as_dict()
-    except _IGNORED_PROCESS_EXCEPTIONS:
+    except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
       return None
 
   def foreground_process(self) -> Optional[Dict[str, Any]]:
     return None
 
-  def terminate(self, proc_pid: int) -> None:
-    self.assert_is_local()
-    # TODO(cbruni): support remote platforms
-    process = psutil.Process(proc_pid)
-    for proc in process.children(recursive=True):
-      proc.terminate()
-    process.terminate()
-
   @property
   def default_tmp_dir(self) -> pth.AnyPath:
     self.assert_is_local()
     return self.path(tempfile.gettempdir())
 
   def port_forward(self, local_port: int, remote_port: int) -> int:
+    """ Forwards a device remote_port to a local port."""
     if remote_port != local_port:
       raise ValueError("Cannot forward a remote port on a local platform.")
+    parse.NumberParser.port_number(local_port, "local_port")
     self.assert_is_local()
     return local_port
 
@@ -415,8 +564,10 @@ class Platform(abc.ABC):
     self.assert_is_local()
 
   def reverse_port_forward(self, remote_port: int, local_port: int) -> int:
+    """ Forwards a local port to a device port."""
     if remote_port != local_port:
       raise ValueError("Cannot forward a remote port on a local platform.")
+    parse.NumberParser.port_number(remote_port, "remote_port")
     self.assert_is_local()
     return remote_port
 
@@ -424,31 +575,58 @@ class Platform(abc.ABC):
     del remote_port
     self.assert_is_local()
 
+  def is_port_used(self, port: int) -> bool:
+    self.assert_is_local()
+    for conn in psutil.net_connections(kind="inet"):
+      if conn.status == psutil.CONN_LISTEN and conn.laddr:
+        if conn.laddr.port == port:
+          return True
+    return False
+
+  def wait_for_port(self, port: int, timeout: dt.timedelta) -> None:
+    for _ in wait.wait_with_backoff(timeout):
+      if self.is_port_used(port):
+        break
+
+  def get_free_port(self) -> int:
+    self.assert_is_local()
+    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
+      s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
+      s.bind(("localhost", 0))
+      return s.getsockname()[1]
+
   def local_cache_dir(self, name: Optional[str] = None) -> pth.LocalPath:
     return self.local_path(self.cache_dir(name))
 
   def cache_dir(self, name: Optional[str] = None) -> pth.AnyPath:
-    assert self._cache_dir, "missing cache dir"
+    if self._cache_dir_root is None:
+      self._cache_dir_root = self._lazy_setup_cache_dir()
+    assert self._cache_dir_root, "missing cache dir"
     if not name:
-      dir = self._cache_dir
+      dir = self._cache_dir_root
     else:
-      dir = self._cache_dir / pth.safe_filename(name)
+      dir = self._cache_dir_root / pth.safe_filename(name)
     self.mkdir(dir, parents=True, exist_ok=True)
     return dir
 
+  def _lazy_setup_cache_dir(self) -> pth.AnyPath:
+    if self.is_local and DEFAULT_CACHE_DIR:
+      return self.local_path(DEFAULT_CACHE_DIR)
+    tmp_cache_dir = self.default_tmp_dir / "crossbench_cache"
+    atexit.register(self.rm, tmp_cache_dir, dir=True, missing_ok=True)
+    return tmp_cache_dir
+
   def set_cache_dir(self, path: pth.AnyPath) -> None:
-    self._cache_dir = path
-    self.mkdir(path, parents=True, exist_ok=True)
+    self._cache_dir_root = self.path(path)
+    self.mkdir(path, parents=True)
 
   def cat(self, file: pth.AnyPathLike, encoding: str = "utf-8") -> str:
     """Meow! I return the file contents as a str."""
-    with self.local_path(file).open(encoding=encoding) as f:
-      return f.read()
+    return self.local_path(file).read_text(encoding=encoding)
 
   def cat_bytes(self, file: pth.AnyPathLike) -> bytes:
     """Hiss! I return the file contents as bytes."""
-    with self.local_path(file).open("rb") as f:
-      return f.read()
+    return self.local_path(file).read_bytes()
 
   def get_file_contents(self,
                         file: pth.AnyPathLike,
@@ -459,8 +637,7 @@ class Platform(abc.ABC):
                         file: pth.AnyPathLike,
                         data: str,
                         encoding: str = "utf-8") -> None:
-    with self.local_path(file).open("w", encoding=encoding) as f:
-      f.write(data)
+    self.local_path(file).write_text(data, encoding)
 
   def pull(self, from_path: pth.AnyPath,
            to_path: pth.LocalPath) -> pth.LocalPath:
@@ -489,16 +666,18 @@ class Platform(abc.ABC):
                to_path: pth.AnyPathLike) -> pth.AnyPath:
     from_path = self.local_path(from_path)
     to_path = self.local_path(to_path)
-    self.mkdir(to_path.parent, parents=True, exist_ok=True)
-    shutil.copytree(os.fspath(from_path), os.fspath(to_path))
+    if from_path != to_path:
+      self.mkdir(to_path.parent, parents=True, exist_ok=True)
+      shutil.copytree(os.fspath(from_path), os.fspath(to_path))
     return to_path
 
   def copy_file(self, from_path: pth.AnyPathLike,
                 to_path: pth.AnyPathLike) -> pth.AnyPath:
     from_path = self.local_path(from_path)
     to_path = self.local_path(to_path)
-    self.mkdir(to_path.parent, parents=True, exist_ok=True)
-    shutil.copy2(os.fspath(from_path), os.fspath(to_path))
+    if from_path != to_path:
+      self.mkdir(to_path.parent, parents=True, exist_ok=True)
+      shutil.copy2(os.fspath(from_path), os.fspath(to_path))
     return to_path
 
   def rm(self,
@@ -545,13 +724,17 @@ class Platform(abc.ABC):
   def absolute(self, path: pth.AnyPathLike) -> pth.AnyPath:
     """Convert an arbitrary path to a platform-specific absolute path"""
     platform_path: pth.AnyPath = self.path(path)
-    if platform_path.is_absolute():
-      return platform_path
     if self.is_local:
       return self.local_path(platform_path).absolute()
+    if platform_path.is_absolute():
+      return platform_path
     raise RuntimeError(
         f"Converting relative to absolute paths is not supported on {self}")
 
+  def is_absolute(self, path: pth.AnyPathLike) -> bool:
+    path = self.path(path)
+    return path.is_absolute()
+
   def home(self) -> pth.AnyPath:
     return pathlib.Path.home()
 
@@ -569,8 +752,7 @@ class Platform(abc.ABC):
       self,
       prefix: Optional[str] = None,
       dir: Optional[pth.AnyPathLike] = None):
-    tmp_file: LocalPath = self.host_platform.local_path(
-        self.host_platform.mktemp(prefix, dir))
+    tmp_file: pth.AnyPath = self.mktemp(prefix, dir)
     try:
       yield tmp_file
     finally:
@@ -619,6 +801,9 @@ class Platform(abc.ABC):
     # TODO: support remotely
     return self.local_path(path).glob(pattern)
 
+  def chmod(self, path: pth.AnyPathLike, mode: int) -> None:
+    self.local_path(path).chmod(mode)
+
   def file_size(self, path: pth.AnyPathLike) -> int:
     # TODO: support remotely
     return self.local_path(path).stat().st_size
@@ -652,9 +837,14 @@ class Platform(abc.ABC):
         check=check)
     return completed_process.stdout
 
+  def validate_shell_args(self, args: TupleCmdArgs, shell: bool) -> None:
+    if shell and len(args) != 1:
+      raise ValueError("Expected single sh arg with shell=True, "
+                       f"but got: {args}")
+
   def popen(self,
             *args: CmdArg,
-            bufsize=-1,
+            bufsize: int = -1,
             shell: bool = False,
             stdout=None,
             stderr=None,
@@ -662,6 +852,7 @@ class Platform(abc.ABC):
             env: Optional[Mapping[str, str]] = None,
             quiet: bool = False) -> subprocess.Popen:
     self.assert_is_local()
+    self.validate_shell_args(args, shell)
     if not quiet:
       logging.debug("SHELL: %s", shlex.join(map(str, args)))
       logging.debug("CWD: %s", os.getcwd())
@@ -685,6 +876,7 @@ class Platform(abc.ABC):
          quiet: bool = False,
          check: bool = True) -> subprocess.CompletedProcess:
     self.assert_is_local()
+    self.validate_shell_args(args, shell)
     if not quiet:
       logging.debug("SHELL: %s", shlex.join(map(str, args)))
       logging.debug("CWD: %s", os.getcwd())
@@ -723,81 +915,15 @@ class Platform(abc.ABC):
     # pylint: disable=unused-argument
     return True
 
-  def get_relative_cpu_speed(self) -> float:
-    return 1
-
-  def is_thermal_throttled(self) -> bool:
-    return self.get_relative_cpu_speed() < 1
-
-  def disk_usage(self, path: pth.AnyPathLike) -> psutil._common.sdiskusage:
-    return psutil.disk_usage(str(self.local_path(path)))
-
-  def cpu_usage(self) -> float:
-    self.assert_is_local()
-    return 1 - psutil.cpu_times_percent().idle / 100
-
-  def cpu_details(self) -> Dict[str, Any]:
-    self.assert_is_local()
-    details = {
-        "physical cores":
-            psutil.cpu_count(logical=False),
-        "logical cores":
-            psutil.cpu_count(logical=True),
-        "usage":
-            psutil.cpu_percent(  # pytype: disable=attribute-error
-                percpu=True, interval=0.1),
-        "total usage":
-            psutil.cpu_percent(),
-        "system load":
-            psutil.getloadavg(),
-        "info":
-            self.cpu,
-    }
-    try:
-      cpu_freq = psutil.cpu_freq()
-    except FileNotFoundError as e:
-      logging.debug("psutil.cpu_freq() failed (normal on macOS M1): %s", e)
-      return details
-    details.update({
-        "max frequency": f"{cpu_freq.max:.2f}Mhz",
-        "min frequency": f"{cpu_freq.min:.2f}Mhz",
-        "current frequency": f"{cpu_freq.current:.2f}Mhz",
-    })
-    return details
-
-  def system_details(self) -> Dict[str, Any]:
-    return {
-        "machine": str(self.machine),
-        "os": self.os_details(),
-        "python": self.python_details(),
-        "CPU": self.cpu_details(),
-    }
-
-  def os_details(self) -> JsonDict:
-    self.assert_is_local()
-    return {
-        "system": py_platform.system(),
-        "release": py_platform.release(),
-        "version": py_platform.version(),
-        "platform": py_platform.platform(),
-    }
-
-  def python_details(self) -> JsonDict:
-    self.assert_is_local()
-    return {
-        "version": py_platform.python_version(),
-        "bits": 64 if sys.maxsize > 2**32 else 32,
-    }
-
-  def download_to(self, url: str, path: pth.LocalPath) -> pth.LocalPath:
+  def download_to(self, url: str, path: pth.AnyPath) -> pth.AnyPath:
     self.assert_is_local()
     logging.debug("DOWNLOAD: %s\n       TO: %s", url, path)
-    assert not path.exists(), f"Download destination {path} exists already."
+    assert not self.exists(path), f"Download destination {path} exists already."
     try:
       urllib.request.urlretrieve(url, path)
     except (urllib.error.HTTPError, urllib.error.URLError) as e:
       raise OSError(f"Could not load {url}") from e
-    assert path.exists(), (
+    assert self.exists(path), (
         f"Downloading {url} failed. Downloaded file {path} doesn't exist.")
     return path
 
@@ -831,3 +957,12 @@ class Platform(abc.ABC):
     # TODO: support screen coordinates
     raise NotImplementedError(
         "'screenshot' is only available on MacOS for now")
+
+  def display_resolution(self) -> Tuple[int, int]:
+    raise NotImplementedError(
+        "'display_resolution' is only available on Android and ChromeOS for "
+        "now")
+
+  def user_id(self) -> int:
+    self.assert_is_local()
+    return os.getuid()
diff --git a/crossbench/plt/bin.py b/crossbench/plt/bin.py
index 12a0da6f..e8735b96 100644
--- a/crossbench/plt/bin.py
+++ b/crossbench/plt/bin.py
@@ -5,17 +5,21 @@
 from __future__ import annotations
 
 import functools
-from typing import TYPE_CHECKING, Iterable, Optional, Tuple, Union
+from typing import TYPE_CHECKING, Iterable, Optional, Tuple, TypeAlias
+
+from typing_extensions import override
 
 from crossbench import path as pth
 
 if TYPE_CHECKING:
   from crossbench.plt.base import Platform
+  BinaryLookup: TypeAlias = pth.AnyPathLike | Iterable[pth.AnyPathLike]
+
 
 
 class BinaryNotFoundError(RuntimeError):
 
-  def __init__(self, binary: Binary, platform: Platform):
+  def __init__(self, binary: Binary, platform: Platform) -> None:
     self.binary = binary
     self.platform = platform
     super().__init__(self._create_message())
@@ -29,18 +33,16 @@ class BinaryNotFoundError(RuntimeError):
 
 class UnsupportedPlatformError(BinaryNotFoundError):
 
-  def __init__(self, binary: Binary, platform: Platform, expected: str):
+  def __init__(self, binary: Binary, platform: Platform, expected: str) -> None:
     self.expected_platform_name: str = expected
     super().__init__(binary, platform)
 
+  @override
   def _create_message(self) -> str:
     return (f"Could not find binary '{self.binary}' on {self.platform}. "
             f"Only supported on {self.expected_platform_name}")
 
 
-BinaryLookup = Union[pth.AnyPathLike, Iterable[pth.AnyPathLike]]
-
-
 class Binary:
   """A binary abstraction for multiple platforms.
   Use this implementation to define binaries that exist on multiple platforms.
@@ -53,7 +55,8 @@ class Binary:
                linux: Optional[BinaryLookup] = None,
                android: Optional[BinaryLookup] = None,
                macos: Optional[BinaryLookup] = None,
-               win: Optional[BinaryLookup] = None) -> None:
+               win: Optional[BinaryLookup] = None,
+               chromeos: Optional[BinaryLookup] = None) -> None:
     self._name = name
     self._default = self._convert(default)
     self._posix = self._convert(posix)
@@ -62,7 +65,8 @@ class Binary:
     self._macos = self._convert(macos)
     self._win = self._convert(win)
     self._validate_win()
-    if not any((default, posix, linux, android, macos, win)):
+    self._chromeos = self._convert(chromeos)
+    if not any((chromeos, default, posix, linux, android, macos, win)):
       raise ValueError("At least one platform binary must be provided")
 
   def _convert(self,
@@ -90,7 +94,7 @@ class Binary:
   def __str__(self) -> str:
     return self._name
 
-  @functools.lru_cache(maxsize=None)  # pylint: disable=method-cache-max-size-none
+  @functools.cache  # pylint: disable=method-cache-max-size-none
   def resolve_cached(self, platform: Platform) -> pth.AnyPath:
     return self.resolve(platform)
 
@@ -103,6 +107,8 @@ class Binary:
     raise BinaryNotFoundError(self, platform)
 
   def platform_path(self, platform: Platform) -> Tuple[pth.AnyPath, ...]:
+    if self._chromeos and platform.is_chromeos:
+      return self._chromeos
     if self._linux and platform.is_linux:
       return self._linux
     if self._android and platform.is_android:
@@ -129,9 +135,10 @@ class Binary:
 
 class PosixBinary(Binary):
 
-  def __init__(self, name: pth.AnyPathLike):
+  def __init__(self, name: pth.AnyPathLike) -> None:
     super().__init__(pth.AnyPosixPath(name).name, posix=name)
 
+  @override
   def _validate_platform(self, platform: Platform) -> None:
     if not platform.is_posix:
       raise UnsupportedPlatformError(self, platform, "posix")
@@ -139,9 +146,10 @@ class PosixBinary(Binary):
 
 class MacOsBinary(Binary):
 
-  def __init__(self, name: pth.AnyPathLike):
+  def __init__(self, name: pth.AnyPathLike) -> None:
     super().__init__(pth.AnyPosixPath(name).name, macos=name)
 
+  @override
   def _validate_platform(self, platform: Platform) -> None:
     if not platform.is_macos:
       raise UnsupportedPlatformError(self, platform, "macos")
@@ -149,9 +157,10 @@ class MacOsBinary(Binary):
 
 class LinuxBinary(Binary):
 
-  def __init__(self, name: pth.AnyPathLike):
+  def __init__(self, name: pth.AnyPathLike) -> None:
     super().__init__(pth.AnyPosixPath(name).name, linux=name)
 
+  @override
   def _validate_platform(self, platform: Platform) -> None:
     if not platform.is_posix:
       raise UnsupportedPlatformError(self, platform, "linux")
@@ -159,9 +168,10 @@ class LinuxBinary(Binary):
 
 class AndroidBinary(Binary):
 
-  def __init__(self, name: pth.AnyPathLike):
+  def __init__(self, name: pth.AnyPathLike) -> None:
     super().__init__(pth.AnyPosixPath(name).name, android=name)
 
+  @override
   def _validate_platform(self, platform: Platform) -> None:
     if not platform.is_android:
       raise UnsupportedPlatformError(self, platform, "android")
@@ -169,15 +179,28 @@ class AndroidBinary(Binary):
 
 class WinBinary(Binary):
 
-  def __init__(self, name: pth.AnyPathLike):
+  def __init__(self, name: pth.AnyPathLike) -> None:
     super().__init__(pth.AnyWindowsPath(name).name, win=name)
 
+  @override
   def _validate_platform(self, platform: Platform) -> None:
     if not platform.is_win:
       raise UnsupportedPlatformError(self, platform, "windows")
 
 
+class ChromeOSBinary(Binary):
+
+  def __init__(self, name: pth.AnyPathLike) -> None:
+    super().__init__(pth.AnyPosixPath(name).name, chromeos=name)
+
+  @override
+  def _validate_platform(self, platform: Platform) -> None:
+    if not platform.is_chromeos:
+      raise UnsupportedPlatformError(self, platform, "chromeos")
+
+
 class Binaries:
+  ADB = Binary("adb", default="adb", win="adb.exe")
   CPIO = LinuxBinary("cpio")
   FFMPEG = Binary("ffmpeg", posix="ffmpeg")
   GCERTSTATUS = Binary("gcertstatus", posix="gcertstatus")
@@ -192,6 +215,10 @@ class Binaries:
   RPM2CPIO = LinuxBinary("rpm2cpio")
   SIMPLEPERF = AndroidBinary("simpleperf")
   XCTRACE = MacOsBinary("xctrace")
+  CHROMEDRIVER = Binary(
+      "chromedriver",
+      chromeos="/usr/local/chromedriver/chromedriver",
+      linux="chromedriver")
 
 
 class Browsers:
diff --git a/crossbench/plt/chromeos_ssh.py b/crossbench/plt/chromeos_ssh.py
index 3aa04146..cbb30bd8 100644
--- a/crossbench/plt/chromeos_ssh.py
+++ b/crossbench/plt/chromeos_ssh.py
@@ -4,14 +4,20 @@
 
 from __future__ import annotations
 
+import json
+import logging
+import subprocess
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench import path as pth
 from crossbench import plt
+from crossbench.parse import NumberParser, ObjectParser
 from crossbench.plt.linux_ssh import LinuxSshPlatform
 
 if TYPE_CHECKING:
-  from typing import Optional
+  from typing import List, Optional, Tuple
 
   from crossbench.flags.chrome import ChromeFlags
   from crossbench.plt.base import ListCmdArgs
@@ -22,11 +28,16 @@ class ChromeOsSshPlatform(LinuxSshPlatform):
   AUTOLOGIN_PATH = pth.AnyPosixPath("/usr/local/autotest/bin/autologin.py")
   DEVTOOLS_PORT_PATH = pth.AnyPosixPath("/home/chronos/DevToolsActivePort")
 
-  def __init__(self, *args, **kwargs):
-    self._username: Optional[str] = None
+  def __init__(self, *args, enable_arc: bool = False, **kwargs) -> None:
     super().__init__(*args, **kwargs)
+    self._enable_arc: bool = enable_arc
+    self._username: str | None = None
+    # `/tmp` on ChromeOS is mounted with `noexec` flag.
+    # Instead, we use `/usr/local/tmp`, which allows executions of binaries.
+    self._default_tmp_dir = pth.AnyPosixPath("/usr/local/tmp")
 
   @property
+  @override
   def name(self) -> str:
     return "chromeos_ssh"
 
@@ -35,22 +46,45 @@ class ChromeOsSshPlatform(LinuxSshPlatform):
     return self._username
 
   @property
+  def enable_arc(self) -> bool:
+    return self._enable_arc
+
+  @property
+  @override
   def is_chromeos(self) -> bool:
     return True
 
   def create_debugging_session(self,
-                               browser_flags: Optional[ChromeFlags] = None,
+                               browser_flags: Optional[Tuple[str, ...]] = None,
                                username: Optional[str] = None,
                                password: Optional[str] = None) -> int:
+    disable_extensions_flag: str = "--disable-extensions"
+
+    flags_for_session: List[str] = []
+
+    if browser_flags:
+      flags_for_session = list(browser_flags)
+
     try:
       args: ListCmdArgs = [self.AUTOLOGIN_PATH]
+      if self.enable_arc:
+        if disable_extensions_flag in flags_for_session:
+          logging.warning(
+              "'%s' is not compatible with ARC."
+              " Proceeding without this flag.", disable_extensions_flag)
+          flags_for_session.remove(disable_extensions_flag)
+        args.append("--arc")
       if username and password:
         self._username = username
         args.extend(("-u", username, "-p", password))
-      if browser_flags:
+      if flags_for_session:
         args.append("--")
-        args.extend(browser_flags)
-      self.sh(*args)
+        args.extend(flags_for_session)
+      autologin_output = self.sh(
+          *args, stdout=subprocess.PIPE,
+          stderr=subprocess.STDOUT).stdout.decode("utf-8")
+      logging.debug("Autologin Output:")
+      logging.debug(autologin_output)
     except plt.SubprocessError as e:
       raise RuntimeError("Autologin failed.") from e
     try:
@@ -58,3 +92,20 @@ class ChromeOsSshPlatform(LinuxSshPlatform):
     except plt.SubprocessError as e:
       raise RuntimeError("Could not read remote debugging port.") from e
     return int(dbg_port)
+
+  @override
+  def screenshot(self, result_path: pth.AnyPath) -> None:
+    self.sh("screenshot", result_path)
+
+  @override
+  def display_resolution(self) -> Tuple[int, int]:
+    display_info_json = self.sh_stdout("cros-health-tool", "telem",
+                                       "--category=display")
+    display_info = json.loads(display_info_json)
+    display_info = ObjectParser.dict(display_info, "display info")
+    embedded_display = ObjectParser.dict(display_info.get("embedded_display"))
+    resolution_horizontal = NumberParser.positive_int(
+        embedded_display.get("resolution_horizontal"), "resolution_horizontal")
+    resolution_vertical = NumberParser.positive_int(
+        embedded_display.get("resolution_vertical"), "resolution_vertical")
+    return (resolution_horizontal, resolution_vertical)
diff --git a/crossbench/plt/ios.py b/crossbench/plt/ios.py
index f76d4dd1..05e59a51 100644
--- a/crossbench/plt/ios.py
+++ b/crossbench/plt/ios.py
@@ -11,7 +11,7 @@ from typing import TYPE_CHECKING, Dict
 if TYPE_CHECKING:
   from crossbench.plt.base import Platform
 
-pattern = re.compile(
+pattern: re.Pattern[str] = re.compile(
     r"(?P<name>[^\(\)]) \((?P<version>[0-9\.]+)\) \((?P<uuid>[0-9A-Z-]+)\)")
 
 
diff --git a/crossbench/plt/linux.py b/crossbench/plt/linux.py
index 2b41e8b8..edd38ba7 100644
--- a/crossbench/plt/linux.py
+++ b/crossbench/plt/linux.py
@@ -6,12 +6,15 @@ from __future__ import annotations
 
 import functools
 import os
-from typing import Any, Dict, Optional, Tuple
+from typing import Any, Dict, Optional, Tuple, Type
+
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.plt.base import SubprocessError
 from crossbench.plt.posix import PosixPlatform
 from crossbench.plt.remote import RemotePlatformMixin
+from crossbench.plt.signals import LinuxSignals
 
 
 class LinuxPlatform(PosixPlatform):
@@ -27,17 +30,24 @@ class LinuxPlatform(PosixPlatform):
   )
 
   @property
+  @override
   def is_linux(self) -> bool:
     return True
 
   @property
+  @override
   def name(self) -> str:
     return "linux"
 
+  @property
+  def signals(self) -> Type[LinuxSignals]:
+    return LinuxSignals
+
   def check_system_monitoring(self, disable: bool = False) -> bool:
     return True
 
   @functools.cached_property
+  @override
   def device(self) -> str:  #pylint: disable=invalid-overridden-method
     try:
       id_dir = self.path("/sys/devices/virtual/dmi/id")
@@ -48,33 +58,38 @@ class LinuxPlatform(PosixPlatform):
       return "UNKNOWN"
 
   @functools.cached_property
+  @override
   def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
     cpu_str = "UNKNOWN"
     for line in self.cat(self.path("/proc/cpuinfo")).splitlines():
       if line.startswith("model name"):
         _, cpu_str = line.split(":", maxsplit=2)
         break
-    if cores_info := self._get_cpu_cores_info():
-      cpu_str = f"{cpu_str} {cores_info}"
+    if num_cores := self.cpu_cores:
+      cpu_str = f"{cpu_str} {num_cores} cores"
     return cpu_str
 
   @property
+  @override
   def has_display(self) -> bool:
     return "DISPLAY" in os.environ
 
   @property
+  @override
   def is_battery_powered(self) -> bool:
     if self.is_local:
       return super().is_battery_powered
-    if self.which("on_ac_power"):
-      return self.sh("on_ac_power", check=False).returncode == 1
+    if on_ac_power := self.which("on_ac_power"):
+      return self.sh(on_ac_power, check=False).returncode == 1
     return False
 
+  @functools.lru_cache(maxsize=1)
+  @override
   def system_details(self) -> Dict[str, Any]:
     details = super().system_details()
     for info_bin in ("lscpu", "inxi"):
-      if self.which(info_bin):
-        details[info_bin] = self.sh_stdout(info_bin)
+      if info_bin_path := self.which(info_bin):
+        details[info_bin] = self.sh_stdout(info_bin_path)
     return details
 
   def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
diff --git a/crossbench/plt/linux_ssh.py b/crossbench/plt/linux_ssh.py
index 55fdf48a..2e0bc13e 100644
--- a/crossbench/plt/linux_ssh.py
+++ b/crossbench/plt/linux_ssh.py
@@ -4,10 +4,16 @@
 
 from __future__ import annotations
 
+import atexit
+import datetime as dt
+import logging
 import shlex
 import subprocess
-from typing import TYPE_CHECKING, Any, Dict, List, Mapping, Optional
+from typing import Tuple, TYPE_CHECKING, Any, Dict, List, Optional
 
+from typing_extensions import override
+
+from crossbench import parse
 from crossbench.plt.arch import MachineArch
 from crossbench.plt.linux import RemoteLinuxPlatform
 from crossbench.plt.ssh import SshPlatformMixin
@@ -19,99 +25,41 @@ if TYPE_CHECKING:
 
 class LinuxSshPlatform(SshPlatformMixin, RemoteLinuxPlatform):
 
+  PORT_FORWARDING_TIMEOUT = dt.timedelta(seconds=10)
+
   def __init__(self, host_platform: Platform, host: str, port: int,
                ssh_port: int, ssh_user: str) -> None:
-    super().__init__(host_platform)
-    self._machine: Optional[MachineArch] = None
-    self._system_details: Optional[Dict[str, Any]] = None
-    self._cpu_details: Optional[Dict[str, Any]] = None
-    # TODO: move ssh-related code to SshPlatformMixin
-    self._host = host
-    self._port = port
-    self._ssh_port = ssh_port
-    self._ssh_user = ssh_user
+    super().__init__(host_platform, host, port, ssh_port, ssh_user)
+    self._machine: MachineArch | None = None
+    self._system_details: Dict[str, Any] | None = None
+    self._cpu_details: Dict[str, Any] | None = None
+    self._port_forward_popens: Dict[int, subprocess.Popen] = {}
+    self._reverse_port_forward_popens: Dict[int, subprocess.Popen] = {}
+    atexit.register(self._stop_all_port_forward)
 
   @property
+  @override
   def name(self) -> str:
     return "linux_ssh"
 
-  @property
-  def host(self) -> str:
-    return self._host
-
-  @property
-  def port(self) -> int:
-    return self._port
-
-  @property
-  def ssh_user(self) -> str:
-    return self._ssh_user
-
-  @property
-  def ssh_port(self) -> int:
-    return self._ssh_port
-
-  def _build_ssh_cmd(self, *args: CmdArg, shell=False) -> ListCmdArgs:
+  def _build_ssh_cmd(self, *args: CmdArg, shell: bool = False) -> ListCmdArgs:
+    self.validate_shell_args(args, shell)
     ssh_cmd: ListCmdArgs = [
         "ssh", "-p", f"{self._ssh_port}", f"{self._ssh_user}@{self._host}"
     ]
+    ssh_cmd.append(shlex.join(map(str, args)))
+
     if shell:
-      ssh_cmd.append(*args)
-    else:
-      ssh_cmd.append(shlex.join(map(str, args)))
+      combined_ssh_cmd: str = ""
+      for cmd in ssh_cmd:
+        combined_ssh_cmd = combined_ssh_cmd + str(cmd) + " "
+      return [combined_ssh_cmd]
+
     return ssh_cmd
 
-  def sh_stdout_bytes(self,
-                      *args: CmdArg,
-                      shell: bool = False,
-                      quiet: bool = False,
-                      stdin=None,
-                      env: Optional[Mapping[str, str]] = None,
-                      check: bool = True) -> bytes:
-    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
-    return self._host_platform.sh_stdout_bytes(
-        *ssh_cmd, quiet=quiet, stdin=stdin, env=env, check=check)
-
-  def sh(self,
-         *args: CmdArg,
-         shell: bool = False,
-         capture_output: bool = False,
-         stdout=None,
-         stderr=None,
-         stdin=None,
-         env: Optional[Mapping[str, str]] = None,
-         quiet: bool = False,
-         check: bool = True) -> subprocess.CompletedProcess:
-    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
-    return self._host_platform.sh(
-        *ssh_cmd,
-        capture_output=capture_output,
-        stdout=stdout,
-        stderr=stderr,
-        stdin=stdin,
-        env=env,
-        quiet=quiet,
-        check=check)
-
-  def popen(self,
-            *args: CmdArg,
-            bufsize=-1,
-            shell: bool = False,
-            stdout=None,
-            stderr=None,
-            stdin=None,
-            env: Optional[Mapping[str, str]] = None,
-            quiet: bool = False) -> subprocess.Popen:
-    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
-    return self._host_platform.popen(
-        *ssh_cmd,
-        bufsize=bufsize,
-        shell=shell,
-        stdout=stdout,
-        stderr=stderr,
-        stdin=stdin,
-        env=env,
-        quiet=quiet)
+  @override
+  def build_shell_cmd(self, *args: CmdArg, shell: bool = False) -> ListCmdArgs:
+    return self._build_ssh_cmd(*args, shell=shell)
 
   def processes(self,
                 attrs: Optional[List[str]] = None) -> List[Dict[str, Any]]:
@@ -128,6 +76,8 @@ class LinuxSshPlatform(SshPlatformMixin, RemoteLinuxPlatform):
     return res
 
   def push(self, from_path: LocalPath, to_path: AnyPath) -> AnyPath:
+    self.mkdir(to_path.parent, parents=True, exist_ok=True)
+
     scp_cmd: CmdArgs = [
         "scp", "-P", f"{self._ssh_port}", f"{from_path}",
         f"{self._ssh_user}@{self._host}:{to_path}"
@@ -136,9 +86,70 @@ class LinuxSshPlatform(SshPlatformMixin, RemoteLinuxPlatform):
     return to_path
 
   def pull(self, from_path: AnyPath, to_path: LocalPath) -> LocalPath:
+    self._host_platform.mkdir(to_path.parent, parents=True, exist_ok=True)
+
     scp_cmd: CmdArgs = [
         "scp", "-P", f"{self._ssh_port}",
-        f"{self._ssh_user}@{self._host}:{from_path}", f"{to_path}"
+        f"{self._ssh_user}@{self._host}:{from_path}", to_path
     ]
     self._host_platform.sh_stdout(*scp_cmd)
     return to_path
+
+  def port_forward(self, local_port: int, remote_port: int) -> int:
+    local_port, remote_port = self._validate_forwarding_ports(
+        local_port, remote_port)
+    self._port_forward_popens[local_port] = self.host_platform.popen(
+        *self._build_ssh_cmd("-NL", f"{local_port}:localhost:{remote_port}"))
+    self.host_platform.wait_for_port(local_port, self.PORT_FORWARDING_TIMEOUT)
+    logging.debug("Forwarded Remote Port: %s:%s <= %s:%s", self._host_platform,
+                  local_port, self, remote_port)
+    return local_port
+
+  def _validate_forwarding_ports(self, local_port: int,
+                                 remote_port: int) -> Tuple[int, int]:
+    local_port = parse.NumberParser.positive_zero_int(local_port, "local_port")
+    remote_port = parse.NumberParser.port_number(remote_port, "remote_port")
+    if not local_port:
+      local_port = self.host_platform.get_free_port()
+    if local_port in self._port_forward_popens:
+      raise RuntimeError(f"Cannot forward local port {local_port} twice.")
+    return local_port, remote_port
+
+  def stop_port_forward(self, local_port: int) -> None:
+    self._port_forward_popens.pop(local_port).terminate()
+
+  def reverse_port_forward(self, remote_port: int, local_port: int) -> int:
+    # TODO: this should likely match with adb, where we support 0
+    # for auto-allocating a remote_port
+    remote_port, local_port = self._validate_reverse_forwarding_ports(
+        remote_port, local_port)
+    self._reverse_port_forward_popens[remote_port] = self.host_platform.popen(
+        *self._build_ssh_cmd("-NR", f"{remote_port}:localhost:{local_port}"))
+    self.wait_for_port(remote_port, self.PORT_FORWARDING_TIMEOUT)
+    logging.debug("Forwarded Local Port: %s:%s => %s:%s", self._host_platform,
+                  local_port, self, remote_port)
+    return remote_port
+
+  def _validate_reverse_forwarding_ports(self, remote_port: int,
+                                         local_port: int) -> Tuple[int, int]:
+    remote_port = parse.NumberParser.port_number(remote_port, "remote_port")
+    local_port = parse.NumberParser.positive_zero_int(local_port, "local_port")
+    if not local_port:
+      local_port = self.host_platform.get_free_port()
+    if remote_port in self._reverse_port_forward_popens:
+      raise RuntimeError(f"Cannot forward remote port {remote_port} twice.")
+    return remote_port, local_port
+
+  def stop_reverse_port_forward(self, remote_port: int) -> None:
+    self._reverse_port_forward_popens.pop(remote_port).terminate()
+
+  def _stop_all_port_forward(self) -> None:
+    for port in list(self._port_forward_popens.keys()):
+      self.stop_port_forward(port)
+    for port in list(self._reverse_port_forward_popens.keys()):
+      self.stop_reverse_port_forward(port)
+
+    assert not self._port_forward_popens, (
+        "Did not stop all port forwarding processes.")
+    assert not self._reverse_port_forward_popens, (
+        "Did not stop all reverse port forwarding processes.")
diff --git a/crossbench/plt/macos.py b/crossbench/plt/macos.py
index 77e01ff0..80e6d5c6 100644
--- a/crossbench/plt/macos.py
+++ b/crossbench/plt/macos.py
@@ -10,14 +10,20 @@ import json
 import logging
 import plistlib
 import re
+import socket
 import traceback as tb
 from subprocess import SubprocessError
-from typing import Any, Dict, Optional, Tuple
+from typing import TYPE_CHECKING, Any, Dict, Optional, Tuple, Type
 
 import psutil
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.plt.posix import PosixPlatform
+from crossbench.plt.signals import MacOSSignals
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import CPUFreqInfo
 
 
 class MacOSPlatform(PosixPlatform):
@@ -32,37 +38,93 @@ class MacOSPlatform(PosixPlatform):
   LSAPPINFO_PID_LINE_RE = r"\s*pid = ([0-9]+).*"
 
   @property
+  @override
   def is_macos(self) -> bool:
     return True
 
   @property
+  @override
   def name(self) -> str:
     return "macos"
 
+  @property
+  def signals(self) -> Type[MacOSSignals]:
+    return MacOSSignals
+
   @functools.cached_property
+  @override
   def version(self) -> str:
     return self.sh_stdout("sw_vers", "-productVersion").strip()
 
   @functools.cached_property
+  def version_parts(self) -> Tuple[int, ...]:
+    return tuple(map(int, self.version.split(".")))
+
+  @functools.cached_property
+  @override
   def device(self) -> str:  #pylint: disable=invalid-overridden-method
-    return self.sh_stdout("sysctl", "hw.model").strip().split(maxsplit=1)[1]
+    return self.sh_stdout("sysctl", "-n", "hw.model").strip()
 
   @functools.cached_property
+  @override
   def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
     brand = self.sh_stdout("sysctl", "-n", "machdep.cpu.brand_string").strip()
-    cores_info = self._get_cpu_cores_info()
-    return f"{brand} {cores_info}"
+    num_cores = self.cpu_cores(logical=True)
+    return f"{brand} {num_cores} cores"
 
-  def _get_cpu_cores_info(self):
-    cores = self.sh_stdout("sysctl", "-n", "machdep.cpu.core_count").strip()
-    return f"{cores} cores"
+  @functools.lru_cache(maxsize=2)
+  @override
+  def cpu_cores(self, logical: bool = False) -> int:
+    if self.is_local:
+      return super().cpu_cores(logical)
+    sysctl_name = "hw.logicalcpu_max" if logical else "hw.physicalcpu_max"
+    cores = self.sh_stdout("sysctl", "-n", sysctl_name).strip()
+    return int(cores)
 
   @property
+  @override
   def is_battery_powered(self) -> bool:
     if self.is_local:
       return super().is_battery_powered
     return "Battery Power" in self.sh_stdout("pmset", "-g", "batt")
 
+  def get_relative_cpu_speed(self) -> float:
+    try:
+      lines = self.sh_stdout("pmset", "-g", "therm").split()
+      for index, line in enumerate(lines):
+        if line == "CPU_Speed_Limit":
+          return int(lines[index + 2]) / 100.0
+    except SubprocessError:
+      pass
+    logging.debug("Could not get relative CPU speed: %s", tb.format_exc())
+    return 1
+
+  @functools.lru_cache(maxsize=1)
+  @override
+  def system_details(self) -> Dict[str, Any]:
+    details = super().system_details()
+    details.update({
+        "system_profiler":
+            self.sh_stdout("system_profiler", "SPHardwareDataType"),
+        "sysctl_machdep_cpu":
+            self.sh_stdout("sysctl", "machdep.cpu"),
+        "sysctl_hw":
+            self.sh_stdout("sysctl", "hw"),
+    })
+    return details
+
+  def _cpu_freq(self) -> Optional[CPUFreqInfo]:
+    if self.is_remote:
+      return super()._cpu_freq()
+    # BUG(394337121): older macOs versions on arm segfault with python 3.11
+    if self.is_arm64 and self.version_parts < (12, 0):
+      return None
+    try:
+      return super()._cpu_freq()
+    except FileNotFoundError as e:
+      logging.debug("psutil.cpu_freq() failed (normal on macOS M1): %s", e)
+      return None
+
   def _find_app_binary_path(self, app_path: pth.AnyPath) -> pth.AnyPath:
     assert app_path.suffix == ".app", f"Expected .app but got {app_path}"
     bin_path = app_path / "Contents" / "MacOS" / app_path.stem
@@ -144,6 +206,7 @@ class MacOSPlatform(PosixPlatform):
     assert self.is_dir(app_path)
     return app_path
 
+  @override
   def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
     app_or_bin = self.path(app_or_bin)
     if not self.exists(app_or_bin):
@@ -161,10 +224,15 @@ class MacOSPlatform(PosixPlatform):
     if self.exists(info_plist):
       plist = plistlib.loads(self.cat_bytes(info_plist))
       if version_string := plist.get("CFBundleShortVersionString"):
-        return version_string
+        display_name = plist.get("CFBundleDisplayName")
+        if not display_name:
+          # Fallback. Apps like Firefox have no CFBundleDisplayName.
+          display_name = plist.get("CFBundleName")
+        return f"{display_name} {version_string}"
+
 
     # Backup solution use the binary (not the .app bundle) with --version.
-    maybe_bin_path: Optional[pth.AnyPath] = app_or_bin
+    maybe_bin_path: pth.AnyPath | None = app_or_bin
     if app_or_bin.suffix == ".app":
       maybe_bin_path = self.search_binary(app_or_bin)
     if not maybe_bin_path:
@@ -213,29 +281,6 @@ class MacOSPlatform(PosixPlatform):
 
     return None
 
-  def get_relative_cpu_speed(self) -> float:
-    try:
-      lines = self.sh_stdout("pmset", "-g", "therm").split()
-      for index, line in enumerate(lines):
-        if line == "CPU_Speed_Limit":
-          return int(lines[index + 2]) / 100.0
-    except SubprocessError:
-      pass
-    logging.debug("Could not get relative CPU speed: %s", tb.format_exc())
-    return 1
-
-  def system_details(self) -> Dict[str, Any]:
-    details = super().system_details()
-    details.update({
-        "system_profiler":
-            self.sh_stdout("system_profiler", "SPHardwareDataType"),
-        "sysctl_machdep_cpu":
-            self.sh_stdout("sysctl", "machdep.cpu"),
-        "sysctl_hw":
-            self.sh_stdout("sysctl", "hw"),
-    })
-    return details
-
   def check_system_monitoring(self, disable: bool = False) -> bool:
     return self.check_crowdstrike(disable)
 
@@ -250,8 +295,10 @@ class MacOSPlatform(PosixPlatform):
             if auto_brightness := display.get("spdisplays_ambient_brightness"):
               return auto_brightness == "spdisplays_yes"
         raise ValueError(
-            "Could not find 'spdisplays_ndrvs' from SPDisplaysDataType")
-    raise ValueError("Could not get 'SPDisplaysDataType' form system profiler")
+            "Could not find 'spdisplays_ndrvs' from SPDisplaysDataType. "
+            f"Output={output}")
+    raise ValueError("Could not get 'SPDisplaysDataType' form system profiler. "
+                     f"Output={output}")
 
   def check_crowdstrike(self, disable: bool = False) -> bool:
     falconctl = self.path(
@@ -338,8 +385,17 @@ class MacOSPlatform(PosixPlatform):
     display_brightness = ctypes.c_float()  # pylint: disable=no-value-for-parameter
     ret = display_services.DisplayServicesGetBrightness(
         main_display, ctypes.byref(display_brightness))
-    assert ret == 0
+    assert ret == 0, f"ret={ret}, display_brightness={display_brightness}"
     return round(display_brightness.value * 100)
 
   def screenshot(self, result_path: pth.AnyPath) -> None:
     self.sh("screencapture", "-x", result_path)
+
+  @override
+  def is_port_used(self, port: int) -> bool:
+    # We need a custom solution for macos:
+    # - psutil.net_connections requires root access on macos
+    # - 'ss' is not available by default on macos
+    # This is a semi-ideal solution as it creates a temporary local server.
+    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
+      return s.connect_ex(("localhost", port)) == 0
diff --git a/crossbench/plt/posix.py b/crossbench/plt/posix.py
index 317a7034..72db0704 100644
--- a/crossbench/plt/posix.py
+++ b/crossbench/plt/posix.py
@@ -7,14 +7,23 @@ from __future__ import annotations
 import abc
 import functools
 import logging
-import re
-from typing import TYPE_CHECKING, Any, Dict, Generator, Iterator, Optional
+import pathlib
+import shlex
+import subprocess
+from typing import (TYPE_CHECKING, Any, Dict, Generator, Iterator, List,
+                    Mapping, Optional, Set, Type)
+
+from typing_extensions import override
 
 from crossbench import path as pth
-from crossbench.plt.base import Environ, ListCmdArgs, Platform, SubprocessError
-from crossbench.plt.remote import RemotePlatformMixin
+from crossbench.plt import proc_helper
+from crossbench.plt.base import Environ, Platform, SubprocessError
+from crossbench.plt.remote import RemotePlatformMixin, RemotePopen
+from crossbench.plt.signals import PosixBaseSignal
 
 if TYPE_CHECKING:
+  from crossbench.plt.base import CmdArg, ListCmdArgs, ProcessLike
+  from crossbench.plt.signals import AnyPosixSignals, Signals
   from crossbench.types import JsonDict
 
 
@@ -23,45 +32,89 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
 
   def __init__(self) -> None:
     super().__init__()
-    self._default_tmp_dir: pth.AnyPath = pth.AnyPosixPath("")
+    self._default_tmp_dir: pth.AnyPath | None = None
+
+  @property
+  def signals(self) -> Type[AnyPosixSignals]:
+    return PosixBaseSignal
 
   @functools.cached_property
+  @override
   def version(self) -> str:  #pylint: disable=invalid-overridden-method
     return self.sh_stdout("uname", "-r").strip()
 
-  def _raw_machine_arch(self):
+  @functools.lru_cache(maxsize=1)
+  def _raw_machine_arch(self) -> str:
     if self.is_local:
       return super()._raw_machine_arch()
     return self.sh_stdout("uname", "-m").strip()
 
-  def _get_cpu_cores_info(self) -> str:
-    try:
-      max_cores_file = self.path("/sys/devices/system/cpu/possible")
-      _, max_core = self.cat(max_cores_file).strip().split("-", maxsplit=1)
-      cores = int(max_core) + 1
-      return f"{cores} cores"
-    except Exception as e:  # pylint: disable=broad-except
-      logging.debug("Failed to get detailed CPU stats: %s", e)
-      return ""
-
-  _GET_CPONF_PROC_RE: re.Pattern = re.compile(
-      r".*PROCESSORS_CONF[^0-9]+(?P<cores>[0-9]+)")
-
+  @functools.lru_cache(maxsize=2)
+  @override
+  def cpu_cores(self, logical: bool) -> int:
+    if self.is_local:
+      return super().cpu_cores(logical)
+    if cores := self._parse_cpuinfo(logical):
+      return cores
+    if logical:
+      if getconf := self.which("getconf"):
+        if result := self.sh_stdout(getconf, "_NPROCESSORS_ONLN"):
+          return int(result)
+    logging.debug("Failed to get num CPU cores")
+    return 0
+
+  def _parse_cpuinfo(self, logical: bool) -> int:
+    assert not self.is_macos, "unsupported operation on macos"
+    entries = self.sh_stdout("grep", "-E", "processor|core id|physical id",
+                             "/proc/cpuinfo")
+    logical_cores: Set[int] = set()
+    core_ids: List[int] = []
+    physical_ids: List[int] = []
+
+    for line in entries.splitlines():
+      line = line.strip()
+      if line:
+        key, value = line.rsplit(": ", maxsplit=1)
+        match key.strip():
+          case "processor":
+            logical_cores.add(int(value))
+          case "core id":
+            core_ids.append(int(value))
+          case "physical id":
+            physical_ids.append(int(value))
+
+    if logical:
+      return len(logical_cores)
+
+    if core_ids:
+      if len(core_ids) == len(physical_ids):
+        pairs = set(zip(core_ids, physical_ids))
+        return len(pairs)
+      logging.debug("Invalid cpuinfo data: Cannot determine core counts.")
+
+    # Android doesn't report core-id in cpuinfo, assuming single-threaded
+    # CPUs and report physical_cores
+    if self.is_android:
+      return len(logical_cores)
+    return 0
+
+
+  @functools.lru_cache(maxsize=1)
+  @override
   def cpu_details(self) -> Dict[str, Any]:
     if self.is_local:
       return super().cpu_details()
-    cores = -1
-    if self.which("nproc"):
-      cores = int(self.sh_stdout("nproc"))
-    elif self.which("getconf"):
-      result = self._GET_CPONF_PROC_RE.search(self.sh_stdout("getconf", "-a"))
-      if result:
-        cores = int(result["cores"])
     return {
-        "physical cores": cores,
         "info": self.cpu,
+        "physical cores": self.cpu_cores(logical=False),
+        "logical cores": self.cpu_cores(logical=True),
+        "min frequency": "n/a",
+        "max frequency": "n/a",
+        "current frequency": "n/a",
     }
 
+  @functools.lru_cache(maxsize=1)
+  @override
   def os_details(self) -> JsonDict:
     if self.is_local:
       return super().os_details()
@@ -74,16 +127,19 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
 
   _PY_VERSION: str = "import sys; print(64 if sys.maxsize > 2**32 else 32)"
 
+  @functools.lru_cache(maxsize=1)
+  @override
   def python_details(self) -> JsonDict:
     if self.is_local:
       return super().python_details()
-    if not self.which("python3"):
-      return {"version": "unknown", "bits": 64}
-    return {
-        "version": self.sh_stdout("python3", "--version").strip(),
-        "bits": int(self.sh_stdout("python3", "-c", self._PY_VERSION).strip())
-    }
-
+    if python3 := self.which("python3"):
+      return {
+          "version": self.sh_stdout(python3, "--version").strip(),
+          "bits": int(self.sh_stdout(python3, "-c", self._PY_VERSION).strip())
+      }
+    return {"version": "unknown", "bits": 64}
+
+  @override
   def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
     app_or_bin = self.path(app_or_bin)
     if not self.exists(app_or_bin):
@@ -91,8 +147,9 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
     return self.sh_stdout(app_or_bin, "--version")
 
   @property
+  @override
   def default_tmp_dir(self) -> pth.AnyPath:
-    if self._default_tmp_dir.parts:
+    if self._default_tmp_dir and self._default_tmp_dir.parts:
       return self._default_tmp_dir
     if self.is_local:
       self._default_tmp_dir = self.path(super().default_tmp_dir)
@@ -105,24 +162,36 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
       tmp_path = self.path(env[tmp_var])
       if self.is_dir(tmp_path):
         self._default_tmp_dir = tmp_path
+        assert self.is_absolute(self._default_tmp_dir)
         return tmp_path
     self._default_tmp_dir = self.path("/tmp")
     assert self.is_dir(self._default_tmp_dir), (
         f"Fallback tmp dir does not exist: {self._default_tmp_dir}")
     return self._default_tmp_dir
 
+  @override
   def path(self, path: pth.AnyPathLike) -> pth.AnyPath:
+    converted_path = path
+    if isinstance(path, pathlib.PureWindowsPath):
+      # Special-case posix-absolute WindowsPath.
+      # for instance: WindowsPath("/usr/local/bin") or WindowsPath("C:/var/tmp")
+      parts = path.parts
+      if parts[0] in ("\\", "C:\\"):
+        # Reassemble parts for an absolute posix path.
+        parts = ("/", *path.parts[1:])
+        converted_path = pth.AnyPosixPath(*parts)
     if self.is_local:
-      return pth.LocalPosixPath(path)
-    return pth.AnyPosixPath(path)
+      return pth.LocalPosixPath(converted_path)
+    return pth.AnyPosixPath(converted_path)
 
+  @override
   def which(self, binary_name: pth.AnyPathLike) -> Optional[pth.AnyPath]:
     if self.is_local:
       return super().which(binary_name)
     if not binary_name:
       raise ValueError("Got empty path")
-    if override := self.lookup_binary_override(binary_name):
-      return override
+    if binary_override := self.lookup_binary_override(binary_name):
+      return binary_override
     try:
       if maybe_path := self.sh_stdout("which", self.path(binary_name)).strip():
         maybe_bin = self.path(maybe_path)
@@ -132,16 +201,19 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
       pass
     return None
 
+  @override
   def cat(self, file: pth.AnyPathLike, encoding: str = "utf-8") -> str:
     if self.is_local:
       return super().cat(file, encoding)
     return self.sh_stdout("cat", self.path(file), encoding=encoding)
 
+  @override
   def cat_bytes(self, file: pth.AnyPathLike) -> bytes:
     if self.is_local:
       return super().cat_bytes(file)
     return self.sh_stdout_bytes("cat", self.path(file))
 
+  @override
   def rm(self,
          path: pth.AnyPathLike,
          dir: bool = False,
@@ -156,6 +228,7 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
     else:
       self.sh("rm", self.path(path))
 
+  @override
   def rename(self, src_path: pth.AnyPathLike,
              dst_path: pth.AnyPathLike) -> pth.AnyPath:
     if self.is_local:
@@ -164,17 +237,20 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
     self.sh("mv", self.path(src_path), dst_path)
     return dst_path
 
+  @override
   def home(self) -> pth.AnyPath:
     if self.is_local:
       return super().home()
     return self.path(self.sh_stdout("printenv", "HOME").strip())
 
+  @override
   def touch(self, path: pth.AnyPathLike) -> None:
     if self.is_local:
       super().touch(path)
     else:
       self.sh("touch", self.path(path))
 
+  @override
   def mkdir(self,
             path: pth.AnyPathLike,
             parents: bool = True,
@@ -186,6 +262,7 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
     else:
       self.sh("mkdir", "-p", self.path(path))
 
+  @override
   def mkdtemp(self,
               prefix: Optional[str] = None,
               dir: Optional[pth.AnyPathLike] = None) -> pth.AnyPath:
@@ -193,6 +270,7 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
       return super().mkdtemp(prefix, dir)
     return self._mktemp_sh(is_dir=True, prefix=prefix, dir=dir)
 
+  @override
   def mktemp(self,
              prefix: Optional[str] = None,
              dir: Optional[pth.AnyPathLike] = None) -> pth.AnyPath:
@@ -212,6 +290,7 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
     result = self.sh_stdout(*args)
     return self.path(result.strip())
 
+  @override
   def copy_dir(self, from_path: pth.AnyPathLike,
                to_path: pth.AnyPathLike) -> pth.AnyPath:
     if self.is_local:
@@ -220,10 +299,12 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
     to_path = self.path(to_path)
     if not self.exists(from_path):
       raise ValueError(f"Cannot copy non-existing source path: {from_path}")
-    self.mkdir(to_path.parent, parents=True, exist_ok=True)
-    self.sh("cp", "-R", from_path, to_path)
+    if from_path != to_path:
+      self.mkdir(to_path.parent, parents=True, exist_ok=True)
+      self.sh("cp", "-R", from_path, to_path)
     return to_path
 
+  @override
   def copy_file(self, from_path: pth.AnyPathLike,
                 to_path: pth.AnyPathLike) -> pth.AnyPath:
     if self.is_local:
@@ -232,10 +313,12 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
     to_path = self.path(to_path)
     if not self.exists(from_path):
       raise ValueError(f"Cannot copy non-existing source path: {from_path}")
-    self.mkdir(to_path.parent, parents=True, exist_ok=True)
-    self.sh("cp", from_path, to_path)
+    if from_path != to_path:
+      self.mkdir(to_path.parent, parents=True, exist_ok=True)
+      self.sh("cp", from_path, to_path)
     return to_path
 
+  @override
   def set_file_contents(self,
                         file: pth.AnyPathLike,
                         data: str,
@@ -249,21 +332,25 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
       self.host_platform.set_file_contents(tmp_file, data, encoding=encoding)
       self.push(tmp_file, dest_file)
 
+  @override
   def exists(self, path: pth.AnyPathLike) -> bool:
     if self.is_local:
       return super().exists(path)
     return self.sh("[", "-e", self.path(path), "]", check=False).returncode == 0
 
+  @override
   def is_file(self, path: pth.AnyPathLike) -> bool:
     if self.is_local:
       return super().is_file(path)
     return self.sh("[", "-f", self.path(path), "]", check=False).returncode == 0
 
+  @override
   def is_dir(self, path: pth.AnyPathLike) -> bool:
     if self.is_local:
       return super().is_dir(path)
     return self.sh("[", "-d", self.path(path), "]", check=False).returncode == 0
 
+  @override
   def iterdir(self,
               path: pth.AnyPathLike) -> Generator[pth.AnyPath, None, None]:
     if self.is_local:
@@ -275,16 +362,58 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
       raise NotADirectoryError(f"Not a directory: {remote_path}")
 
     for name in self.sh_stdout("ls", "-1",
-                               remote_path).rstrip("\n").split("\n"):
+                               remote_path).rstrip("\n").splitlines():
       yield remote_path / name
 
-  def terminate(self, proc_pid: int) -> None:
-    self.sh("kill", "-s", "TERM", str(proc_pid))
+  @override
+  def chmod(self, path: pth.AnyPathLike, mode: int) -> None:
+    if self.is_local:
+      super().chmod(path, mode)
+    else:
+      # strip the prefix
+      oct_mode = oct(mode)[2:]
+      self.sh("chmod", oct_mode, self.path(path))
+
+  @override
+  def send_signal(self, process: ProcessLike, signal: Signals) -> None:
+    if self.is_local:
+      super().send_signal(process, signal)
+      return
+    if pid := self.process_pid(process):
+      kill_process = self.sh(
+          "kill", f"-{int(signal)}", str(pid), check=False, capture_output=True)
+      # wait for the process to finish.
+      if kill_process.returncode > 0:
+        error_str = kill_process.stdout.decode("utf-8")
+        error_str += kill_process.stderr.decode("utf-8")
+        raise ProcessLookupError(f"{self}: {error_str}")
+
+  @override
+  def terminate(self, process: ProcessLike) -> None:
+    if self.is_local:
+      super().terminate(process)
+    else:
+      try:
+        self.send_signal(process, self.signals.SIGTERM)
+      except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
+        pass
+
+  @override
+  def kill(self, process: ProcessLike) -> None:
+    if self.is_local:
+      super().kill(process)
+    else:
+      try:
+        self.send_signal(process, self.signals.SIGKILL)
+      except proc_helper.PROCESS_NOT_FOUND_EXCEPTIONS:
+        pass
 
-  def process_info(self, pid: int) -> Optional[Dict[str, Any]]:
+  @override
+  def process_info(self, process: ProcessLike) -> Optional[Dict[str, Any]]:
     if self.is_local:
-      return super().process_info(pid)
+      return super().process_info(process)
     try:
+      pid = self.process_pid(process)
       lines = self.sh_stdout("ps", "-o", "comm", "-p", str(pid)).splitlines()
       if len(lines) <= 1:
         return None
@@ -296,11 +425,21 @@ class PosixPlatform(Platform, metaclass=abc.ABCMeta):
       return None
 
   @property
+  @override
   def environ(self) -> Environ:
     if self.is_local:
       return super().environ
     return RemotePosixEnviron(self)
 
+  @override
+  def is_port_used(self, port: int) -> bool:
+    return bool(self.sh_stdout("ss", "-HOlnt", "sport", "=", f"{port}"))
+
+  def user_id(self) -> int:
+    if self.is_local:
+      return super().user_id()
+    return int(self.sh_stdout("id", "-u").strip())
+
 
 class RemotePosixEnviron(Environ):
 
@@ -334,4 +473,33 @@ class RemotePosixEnviron(Environ):
 
 
 class RemotePosixPlatform(RemotePlatformMixin, PosixPlatform):
-  pass
+
+  @override
+  def popen(self,
+            *args: CmdArg,
+            bufsize: int = -1,
+            shell: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False) -> subprocess.Popen:
+    del shell
+    assert not (self.is_android and env), "ADB does not support env vars"
+
+    with self.NamedTemporaryFile("popen_pid_") as temp_pid_file:
+      shell_cmd = shlex.join(map(str, args))
+      # Capture the PID and wait on the process to finish.
+      shell_cmd += f" & PID=$! && echo $PID >{temp_pid_file} && wait $PID"
+      if not quiet:
+        logging.debug("REMOTE SHELL: %s", shell_cmd)
+
+      host_platform_cmd = self.build_shell_cmd(shell_cmd, shell=True)
+
+      remote_popen = RemotePopen(
+          self, host_platform_cmd, bufsize=bufsize, stdout=stdout,
+          stderr=stderr, stdin=stdin)
+      remote_pid = int(self.cat(temp_pid_file))
+      remote_popen.set_remote_pid(remote_pid)
+
+    return remote_popen
diff --git a/crossbench/plt/proc_helper.py b/crossbench/plt/proc_helper.py
new file mode 100644
index 00000000..1fdf3b2a
--- /dev/null
+++ b/crossbench/plt/proc_helper.py
@@ -0,0 +1,49 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+from subprocess import Popen, TimeoutExpired
+from typing import TYPE_CHECKING, Final, Optional
+
+import psutil
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import Platform, ProcessLike
+  from crossbench.plt.signals import Signals
+
+PROCESS_NOT_FOUND_EXCEPTIONS: Final = (psutil.NoSuchProcess,
+                                       psutil.AccessDenied,
+                                       psutil.ZombieProcess, ProcessLookupError)
+
+
+def terminate_gracefully(platform: Platform,
+                         process: ProcessLike,
+                         timeout: int = 1,
+                         signal: Optional[Signals] = None) -> None:
+  """Graceful process termination
+    1. Send the provided signal or SIGTERM by default
+    2. Wait for the process to terminate
+    3. Kill the process
+  """
+  if not signal:
+    signal = platform.signals.SIGTERM
+
+  try:
+    platform.send_signal(process, signal)
+    # TODO(392938079): support timeout on more process types
+    if isinstance(process, Popen):
+      process.wait(timeout)
+    return
+  except TimeoutExpired as e:
+    logging.debug("Got timeout while waiting "
+                  "for process shutdown (%s): %s", process, e)
+  except PROCESS_NOT_FOUND_EXCEPTIONS as e:  # pylint: disable=broad-except
+    logging.debug("Ignoring exception during process termination: %s", e)
+  finally:
+    try:
+      platform.kill(process)
+    except PROCESS_NOT_FOUND_EXCEPTIONS:
+      pass
diff --git a/crossbench/plt/remote.py b/crossbench/plt/remote.py
index 0ba913c2..34f42611 100644
--- a/crossbench/plt/remote.py
+++ b/crossbench/plt/remote.py
@@ -4,16 +4,20 @@
 
 from __future__ import annotations
 
+import subprocess
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 if TYPE_CHECKING:
   from crossbench.path import AnyPathLike, LocalPath
-  from crossbench.plt.base import Platform
+  from crossbench.plt.base import CmdArg, ListCmdArgs, Platform
+  from crossbench.plt.signals import Signals
 
 
 class RemotePlatformMixin:
 
-  def __init__(self, host_platform: Platform):
+  def __init__(self, host_platform: Platform) -> None:
     super().__init__()
     self._host_platform: Platform = host_platform
 
@@ -27,3 +31,52 @@ class RemotePlatformMixin:
 
   def host_path(self, path: AnyPathLike) -> LocalPath:
     return self._host_platform.local_path(path)
+
+  def build_shell_cmd(self, *args: CmdArg, shell: bool = False) -> ListCmdArgs:
+    raise NotImplementedError()
+
+
+class RemotePopen(subprocess.Popen):
+  """
+  A wrapper class to represent a process running on a remote platform.
+
+  Allows to send signals to the remote process and gracefully wait for its
+  termination.
+  """
+
+
+  def __init__(self,
+               platform: Platform,
+               args: ListCmdArgs,
+               bufsize: int = -1,
+               stdout=None,
+               stderr=None,
+               stdin=None) -> None:
+    self._platform: Platform = platform
+    assert self._platform.is_remote, (
+        f"Cannot create remote process on local platform {self._platform}")
+    self._remote_pid: int | None = None
+    super().__init__(
+        args, bufsize=bufsize, stdout=stdout, stderr=stderr, stdin=stdin)
+
+  def set_remote_pid(self, pid: int) -> None:
+    assert self._remote_pid is None, "Should not set remote PID twice"
+    self._remote_pid = pid
+
+  @property
+  def remote_pid(self) -> int:
+    assert self._remote_pid, "remote process has no PID"
+    return self._remote_pid
+
+  @override
+  def send_signal(self, signal: int | Signals) -> None:
+    signal = self._platform.signals(signal)
+    self._platform.send_signal(self.remote_pid, signal)
+
+  @override
+  def terminate(self) -> None:
+    self._platform.terminate(self.remote_pid)
+
+  @override
+  def kill(self) -> None:
+    self._platform.kill(self.remote_pid)
diff --git a/crossbench/plt/signals.py b/crossbench/plt/signals.py
new file mode 100644
index 00000000..7b0205a3
--- /dev/null
+++ b/crossbench/plt/signals.py
@@ -0,0 +1,180 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+import signal
+from typing import TypeAlias
+
+
+class Signals(enum.IntEnum):
+  pass
+
+
+@enum.unique
+class WinSignals(Signals):
+  CTRL_C_EVENT = 0
+  CTRL_BREAK_EVENT = 1
+  SIGABRT = signal.SIGABRT
+  SIGFPE = signal.SIGFPE
+  SIGILL = signal.SIGILL
+  SIGINT = signal.SIGINT
+  SIGSEGV = signal.SIGSEGV
+  SIGTERM = signal.SIGTERM
+  SIGBREAK = 21
+
+
+# Python doesn't allow enum subclasses so we have to duplicate enum values
+# This thoroughly tested in SignalsTestCase for consistency.
+class _PosixSignals(Signals):
+  pass
+
+
+class PosixBaseSignal(_PosixSignals):
+  """ Signals names AND values supported on all posix platforms. """
+  SIGABRT = signal.SIGABRT
+  SIGFPE = signal.SIGFPE
+  SIGILL = signal.SIGILL
+  SIGINT = signal.SIGINT
+  SIGSEGV = signal.SIGSEGV
+  SIGTERM = signal.SIGTERM
+  SIGHUP = 1
+  SIGQUIT = 3
+  SIGTRAP = 5
+  SIGKILL = 9
+  SIGPIPE = 13
+  SIGALRM = 14
+  SIGTTIN = 21
+  SIGTTOU = 22
+  SIGXCPU = 24
+  SIGXFSZ = 25
+  SIGVTALRM = 26
+  SIGPROF = 27
+  SIGWINCH = 28
+
+
+class PosixSignals(_PosixSignals):
+  """ Signal names (not values) support on all posix platforms.
+  See specific subclasses for platform-specific values."""
+  SIGABRT = signal.SIGABRT
+  SIGFPE = signal.SIGFPE
+  SIGILL = signal.SIGILL
+  SIGINT = signal.SIGINT
+  SIGSEGV = signal.SIGSEGV
+  SIGTERM = signal.SIGTERM
+  SIGHUP = 1
+  SIGQUIT = 3
+  SIGTRAP = 5
+  SIGIOT = 6
+  SIGBUS = 7
+  SIGKILL = 9
+  SIGUSR1 = 10
+  SIGUSR2 = 12
+  SIGPIPE = 13
+  SIGALRM = 14
+  SIGCLD = 17
+  SIGCHLD = 17
+  SIGCONT = 18
+  SIGSTOP = 19
+  SIGTSTP = 20
+  SIGTTIN = 21
+  SIGTTOU = 22
+  SIGURG = 23
+  SIGXCPU = 24
+  SIGXFSZ = 25
+  SIGVTALRM = 26
+  SIGPROF = 27
+  SIGWINCH = 28
+  SIGIO = 29
+  SIGPOLL = 29
+  SIGPWR = 30
+  SIGSYS = 31
+  SIGRTMIN = 34
+  SIGRTMAX = 64
+
+
+class LinuxSignals(_PosixSignals):
+  # Source:
+  # https://man7.org/linux/man-pages/man7/signal.7.html
+  SIGABRT = signal.SIGABRT
+  SIGFPE = signal.SIGFPE
+  SIGILL = signal.SIGILL
+  SIGINT = signal.SIGINT
+  SIGSEGV = signal.SIGSEGV
+  SIGTERM = signal.SIGTERM
+  SIGHUP = 1
+  SIGQUIT = 3
+  SIGTRAP = 5
+  SIGIOT = 6
+  SIGBUS = 7
+  SIGKILL = 9
+  SIGUSR1 = 10
+  SIGUSR2 = 12
+  SIGPIPE = 13
+  SIGALRM = 14
+  SIGSTKFLT = 16
+  SIGCLD = 17
+  SIGCHLD = 17
+  SIGCONT = 18
+  SIGSTOP = 19
+  SIGTSTP = 20
+  SIGTTIN = 21
+  SIGTTOU = 22
+  SIGURG = 23
+  SIGXCPU = 24
+  SIGXFSZ = 25
+  SIGVTALRM = 26
+  SIGPROF = 27
+  SIGWINCH = 28
+  SIGIO = 29
+  SIGPOLL = 29
+  SIGPWR = 30
+  SIGSYS = 31
+  SIGRTMIN = 34
+  SIGRTMAX = 64
+
+
+class MacOSSignals(_PosixSignals):
+  # Source:
+  # https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man3/signal.3.html
+  SIGABRT = signal.SIGABRT
+  SIGFPE = signal.SIGFPE
+  SIGILL = signal.SIGILL
+  SIGINT = signal.SIGINT
+  SIGSEGV = signal.SIGSEGV
+  SIGTERM = signal.SIGTERM
+  SIGHUP = 1
+  SIGQUIT = 3
+  SIGTRAP = 5
+  SIGEMT = 7
+  SIGIOT = 6
+  SIGKILL = 9
+  SIGBUS = 10
+  SIGSYS = 12
+  SIGPIPE = 13
+  SIGALRM = 14
+  SIGURG = 16
+  SIGSTOP = 17
+  SIGTSTP = 18
+  SIGCONT = 19
+  SIGCHLD = 20
+  SIGTTIN = 21
+  SIGTTOU = 22
+  SIGIO = 23
+  SIGXCPU = 24
+  SIGXFSZ = 25
+  SIGVTALRM = 26
+  SIGPROF = 27
+  SIGWINCH = 28
+  SIGINFO = 29
+  SIGUSR1 = 30
+  SIGUSR2 = 31
+
+
+# Type unions of concrete Signals implementations.
+AnySignals: TypeAlias = (
+    WinSignals | PosixBaseSignal | PosixSignals | LinuxSignals | MacOSSignals)
+AnyPosixSignals: TypeAlias = (
+    PosixBaseSignal | PosixSignals | LinuxSignals | MacOSSignals)
diff --git a/crossbench/plt/ssh.py b/crossbench/plt/ssh.py
index 4ca568db..99e3a5a6 100644
--- a/crossbench/plt/ssh.py
+++ b/crossbench/plt/ssh.py
@@ -5,18 +5,99 @@
 from __future__ import annotations
 
 import abc
-from typing import TYPE_CHECKING
+import subprocess
+from typing import TYPE_CHECKING, Mapping, Optional
+
+from crossbench.plt.base import Platform
+from crossbench.plt.remote import RemotePlatformMixin
 
 if TYPE_CHECKING:
   from crossbench.plt.base import CmdArg, ListCmdArgs
 
 
-class SshPlatformMixin(abc.ABC):
+class SshPlatformMixin(RemotePlatformMixin, metaclass=abc.ABCMeta):
+
+  def __init__(self, host_platform: Platform, host: str, port: int,
+               ssh_port: int, ssh_user: str) -> None:
+    super().__init__(host_platform)
+    self._host = host
+    self._port = port
+    self._ssh_port = ssh_port
+    self._ssh_user = ssh_user
+
+  @property
+  def host(self) -> str:
+    return self._host
+
+  @property
+  def port(self) -> int:
+    return self._port
+
+  @property
+  def ssh_user(self) -> str:
+    return self._ssh_user
+
+  @property
+  def ssh_port(self) -> int:
+    return self._ssh_port
 
   @property
   def is_remote_ssh(self) -> bool:
     return True
 
   @abc.abstractmethod
-  def _build_ssh_cmd(self, *args: CmdArg, shell=False) -> ListCmdArgs:
+  def _build_ssh_cmd(self, *args: CmdArg, shell: bool = False) -> ListCmdArgs:
     pass
+
+  def sh_stdout_bytes(self,
+                      *args: CmdArg,
+                      shell: bool = False,
+                      quiet: bool = False,
+                      stdin=None,
+                      env: Optional[Mapping[str, str]] = None,
+                      check: bool = True) -> bytes:
+    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
+    return self._host_platform.sh_stdout_bytes(
+        *ssh_cmd, shell=False, quiet=quiet, stdin=stdin, env=env, check=check)
+
+  def sh(self,
+         *args: CmdArg,
+         shell: bool = False,
+         capture_output: bool = False,
+         stdout=None,
+         stderr=None,
+         stdin=None,
+         env: Optional[Mapping[str, str]] = None,
+         quiet: bool = False,
+         check: bool = True) -> subprocess.CompletedProcess:
+    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
+    return self._host_platform.sh(
+        *ssh_cmd,
+        shell=shell,
+        capture_output=capture_output,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet,
+        check=check)
+
+  def popen(self,
+            *args: CmdArg,
+            bufsize: int = -1,
+            shell: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False) -> subprocess.Popen:
+    ssh_cmd: ListCmdArgs = self._build_ssh_cmd(*args, shell=shell)
+    return self._host_platform.popen(
+        *ssh_cmd,
+        shell=False,
+        bufsize=bufsize,
+        stdout=stdout,
+        stderr=stderr,
+        stdin=stdin,
+        env=env,
+        quiet=quiet)
diff --git a/crossbench/plt/win.py b/crossbench/plt/win.py
index 415d2da8..b4a310b6 100644
--- a/crossbench/plt/win.py
+++ b/crossbench/plt/win.py
@@ -8,10 +8,13 @@ import functools
 import logging
 import os
 import shutil
-from typing import Optional
+from typing import Optional, Type
+
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.plt.base import Platform
+from crossbench.plt.signals import WinSignals
 
 
 class WinPlatform(Platform):
@@ -25,27 +28,39 @@ class WinPlatform(Platform):
   )
 
   @property
+  def signals(self) -> Type[WinSignals]:
+    return WinSignals
+
+  @property
+  @override
   def is_win(self) -> bool:
     return True
 
   @property
+  @override
   def name(self) -> str:
     return "win"
 
   @property
+  @override
   def device(self) -> str:
     # TODO: implement
     return ""
 
   @functools.cached_property
+  @override
   def version(self) -> str:  #pylint: disable=invalid-overridden-method
     return self.sh_stdout("cmd", "/c", "ver").strip()
 
   @functools.cached_property
+  @override
   def cpu(self) -> str:  #pylint: disable=invalid-overridden-method
-    return self.sh_stdout("wmic", "cpu", "get",
-                          "name").strip().splitlines()[2].strip()
+    return self.sh_stdout(
+      "powershell", "-c",
+      "Get-CIMInstance -query 'select * from Win32_Processor' | ft Name"
+    ).strip().splitlines()[2].strip()
 
+  @override
   def search_binary(self, app_or_bin: pth.AnyPathLike) -> Optional[pth.AnyPath]:
     self.assert_is_local()
     app_or_bin_path: pth.AnyPath = self.path(app_or_bin)
@@ -64,6 +79,7 @@ class WinPlatform(Platform):
         return result_path
     return None
 
+  @override
   def app_version(self, app_or_bin: pth.AnyPathLike) -> str:
     app_or_bin = self.path(app_or_bin)
     if not self.exists(app_or_bin):
@@ -71,7 +87,10 @@ class WinPlatform(Platform):
     if version := self.sh_stdout(
         "powershell", "-command",
         f"(Get-Item '{app_or_bin}').VersionInfo.ProductVersion").strip():
-      return version
+      name = self.sh_stdout(
+          "powershell", "-command",
+          f"(Get-Item '{app_or_bin}').VersionInfo.ProductName").strip()
+      return f"{name} {version}"
     try:
       # Fall back to command-line tools.
       if version := self.sh_stdout(app_or_bin, "--version").strip():
@@ -81,6 +100,7 @@ class WinPlatform(Platform):
     raise ValueError(f"Could not extract version for {app_or_bin}")
 
 
+  @override
   def symlink_or_copy(self, src: pth.AnyPathLike,
                       dst: pth.AnyPathLike) -> pth.AnyPath:
     """Windows does not support symlinking without admin support.
diff --git a/crossbench/probes/all.py b/crossbench/probes/all.py
index a61798d1..758fbd86 100644
--- a/crossbench/probes/all.py
+++ b/crossbench/probes/all.py
@@ -4,18 +4,22 @@
 
 from __future__ import annotations
 
-from typing import Tuple, Type
+from typing import TYPE_CHECKING, Tuple, Type
 
-from crossbench.probes.android_logcat import AndroidLogcatProbe
+from crossbench.probes.android_logcat import LogcatAndroidProbe
 from crossbench.probes.chrome_histograms import ChromeHistogramsProbe
 from crossbench.probes.debugger import DebuggerProbe
+from crossbench.probes.downloads import DownloadsProbe
 from crossbench.probes.dtrace import DTraceProbe
 from crossbench.probes.dump_html import DumpHtmlProbe
 from crossbench.probes.frequency import FrequencyProbe
 from crossbench.probes.helper import INTERNAL_NAME_PREFIX
-from crossbench.probes.internal import (DurationsProbe, ErrorsProbe,
-                                        InternalProbe, LogProbe,
-                                        ResultsSummaryProbe, SystemDetailsProbe)
+from crossbench.probes.internal.browser.driver_log import BrowserDriverLogProbe
+from crossbench.probes.internal.durations import DurationsProbe
+from crossbench.probes.internal.errors import ErrorsProbe
+from crossbench.probes.internal.log import LogProbe
+from crossbench.probes.internal.summary import ResultsSummaryProbe
+from crossbench.probes.internal.system_details import SystemDetailsProbe
 from crossbench.probes.js import JSProbe
 from crossbench.probes.json import JsonResultProbe
 from crossbench.probes.perfetto.perfetto import PerfettoProbe
@@ -23,7 +27,7 @@ from crossbench.probes.perfetto.trace_processor.trace_processor import \
     TraceProcessorProbe
 from crossbench.probes.perfetto.tracing import TracingProbe
 from crossbench.probes.performance_entries import PerformanceEntriesProbe
-from crossbench.probes.polling import ShellPollingProbe
+from crossbench.probes.polling import PollingShellProbe
 from crossbench.probes.power_sampler import PowerSamplerProbe
 from crossbench.probes.powermetrics import PowerMetricsProbe
 from crossbench.probes.probe import Probe
@@ -40,6 +44,10 @@ from crossbench.probes.v8.turbolizer import V8TurbolizerProbe
 from crossbench.probes.video import VideoProbe
 from crossbench.probes.web_page_replay.recorder import WebPageReplayProbe
 
+if TYPE_CHECKING:
+  from crossbench.probes.internal.base import InternalProbe
+  InternalProbeTuple = Tuple[Type[InternalProbe], ...]
+
 ABSTRACT_PROBES: Tuple[Type[Probe], ...] = (Probe, JsonResultProbe)
 
 # Probes that are not user-configurable
@@ -48,36 +56,51 @@ ABSTRACT_PROBES: Tuple[Type[Probe], ...] = (Probe, JsonResultProbe)
 # reads the values of the other internal probes and thus needs to be the first
 # to be initialized and the last to be teared down to write out a summary
 # result of all the other probes.
-INTERNAL_PROBES: Tuple[Type[InternalProbe], ...] = (
+
+# Internal probes that are always installed and are non configurable.
+NON_CONFIGURABLE_INTERNAL_PROBES: InternalProbeTuple = (
     ResultsSummaryProbe,
     DurationsProbe,
     ErrorsProbe,
     LogProbe,
     SystemDetailsProbe,
-    ThermalMonitorProbe,
 )
+# Internal probes that are configurable by command line flags but always
+# installed.
+CONFIGURABLE_INTERNAL_PROBES: InternalProbeTuple = (ThermalMonitorProbe,)
+DEFAULT_INTERNAL_PROBES: InternalProbeTuple = (
+    NON_CONFIGURABLE_INTERNAL_PROBES + CONFIGURABLE_INTERNAL_PROBES)
+
+# Internal probes that are configurable and only optionally installed.
+OPTIONAL_INTERNAL_PROBES: InternalProbeTuple = (BrowserDriverLogProbe,)
+
+INTERNAL_PROBES: InternalProbeTuple = (
+    DEFAULT_INTERNAL_PROBES + OPTIONAL_INTERNAL_PROBES)
+
 # ResultsSummaryProbe should always be processed last, and thus must be the
 # first probe to be added to any browser.
-assert INTERNAL_PROBES[0] == ResultsSummaryProbe
-assert INTERNAL_PROBES[1] == DurationsProbe
+assert DEFAULT_INTERNAL_PROBES[0] == ResultsSummaryProbe
+assert DEFAULT_INTERNAL_PROBES[1] == DurationsProbe
+
 
 # Probes that can be used on arbitrary stories and may be user configurable.
 GENERAL_PURPOSE_PROBES: Tuple[Type[Probe], ...] = (
-    AndroidLogcatProbe,
     BrowserProfilingProbe,
     ChromeHistogramsProbe,
-    DTraceProbe,
     DebuggerProbe,
+    DownloadsProbe,
+    DTraceProbe,
     DumpHtmlProbe,
     FrequencyProbe,
     JSProbe,
+    LogcatAndroidProbe,
     PerfettoProbe,
     PerformanceEntriesProbe,
+    PollingShellProbe,
     PowerMetricsProbe,
     PowerSamplerProbe,
     ProfilingProbe,
     ScreenshotProbe,
-    ShellPollingProbe,
     ShellProbe,
     SystemStatsProbe,
     TraceProcessorProbe,
@@ -97,7 +120,7 @@ for probe_cls in GENERAL_PURPOSE_PROBES:
   assert not probe_cls.NAME.startswith(INTERNAL_NAME_PREFIX), (
       f"General purpose {probe_cls}.NAME cannot start with 'cb.'")
 
-for probe_cls in INTERNAL_PROBES:
+for probe_cls in DEFAULT_INTERNAL_PROBES:
   assert not probe_cls.IS_GENERAL_PURPOSE, (
       f"Internal Probe {probe_cls} should not marked for GENERAL_PURPOSE")
   assert probe_cls.NAME
diff --git a/crossbench/probes/android_logcat.py b/crossbench/probes/android_logcat.py
index ed1a2595..4c51731a 100644
--- a/crossbench/probes/android_logcat.py
+++ b/crossbench/probes/android_logcat.py
@@ -4,9 +4,10 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Iterable, Optional, Tuple, cast
+from typing import TYPE_CHECKING, Iterable, Self, Tuple, Type, cast
+
+from typing_extensions import override
 
-from crossbench.plt.android_adb import AndroidAdbPlatform
 from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
                                      ProbeIncompatibleBrowser)
 from crossbench.probes.result_location import ResultLocation
@@ -15,20 +16,21 @@ from crossbench.probes.results import LocalProbeResult, ProbeResult
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.env import HostEnvironment
+  from crossbench.plt.android_adb import AndroidAdbPlatform
   from crossbench.runner.run import Run
 
 
-class AndroidLogcatProbe(Probe):
+class LogcatAndroidProbe(Probe):
   """
   Android-only probe to collect logcat traces.
   """
   NAME = "logcat"
   RESULT_LOCATION = ResultLocation.LOCAL
-
   IS_GENERAL_PURPOSE = True
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "filterspec",
@@ -38,7 +40,7 @@ class AndroidLogcatProbe(Probe):
         help="Filter specifications are a series of <tag>[:priority]")
     return parser
 
-  def __init__(self, filterspec: Iterable[str]):
+  def __init__(self, filterspec: Iterable[str]) -> None:
     super().__init__()
     self._filterspec = tuple(filterspec)
 
@@ -46,33 +48,37 @@ class AndroidLogcatProbe(Probe):
   def filterspec(self) -> Tuple[str, ...]:
     return self._filterspec
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     if not browser.platform.is_android:
       raise ProbeIncompatibleBrowser(self, browser, "Only supported on android")
 
-  def get_context(self, run: Run) -> AndroidLogcatProbeContext:
-    return AndroidLogcatProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[AndroidLogcatProbeContext]:
+    return AndroidLogcatProbeContext
 
 
-class AndroidLogcatProbeContext(ProbeContext[AndroidLogcatProbe]):
+class AndroidLogcatProbeContext(ProbeContext[LogcatAndroidProbe]):
 
-  def __init__(self, probe: AndroidLogcatProbe, run: Run) -> None:
+  def __init__(self, probe: LogcatAndroidProbe, run: Run) -> None:
     super().__init__(probe, run)
-    self._logcat_start_time: Optional[str] = None
+    self._logcat_start_time: str | None = None
 
   def _get_browser_platform_time(self) -> str:
     return self.browser_platform.sh_stdout("date",
                                            "+%Y-%m-%d %H:%M:%S").rstrip()
 
-  def _log_to_logcat(self, msg: str):
+  def _log_to_logcat(self, msg: str) -> None:
     self.browser_platform.sh("log", "-t", "crossbench", msg)
 
   @property
+  @override
   def browser_platform(self) -> AndroidAdbPlatform:
     browser_platform = super().browser_platform
-    assert isinstance(browser_platform, AndroidAdbPlatform)
-    return cast(AndroidAdbPlatform, browser_platform)
+    assert browser_platform.is_android, (
+        f"Expected android platform, but got {browser_platform}")
+    return cast("AndroidAdbPlatform", browser_platform)
 
   def start(self) -> None:
     self._logcat_start_time = self._get_browser_platform_time()
@@ -85,8 +91,7 @@ class AndroidLogcatProbeContext(ProbeContext[AndroidLogcatProbe]):
     assert self._logcat_start_time
     file = self.local_result_path.with_suffix(".txt")
     with file.open("w", encoding="utf-8") as f:
-      self.host_platform.sh(
-          "adb",
+      self.browser_platform.sh(
           "logcat",
           "-t",
           self._logcat_start_time + ".000",
diff --git a/crossbench/probes/chrome_histograms.py b/crossbench/probes/chrome_histograms.py
index 8a8587e1..b271bfbc 100644
--- a/crossbench/probes/chrome_histograms.py
+++ b/crossbench/probes/chrome_histograms.py
@@ -10,17 +10,20 @@ import dataclasses
 import functools
 import logging
 import re
-from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence
+from typing import (TYPE_CHECKING, Any, Dict, List, Optional, Self, Sequence,
+                    Type)
+
+from typing_extensions import override
 
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.browser import Browser
-from crossbench.env import HostEnvironment
 from crossbench.parse import ObjectParser
 from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
 from crossbench.probes.probe import ProbeConfigParser
 from crossbench.probes.result_location import ResultLocation
 
 if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
   from crossbench.runner.actions import Actions
   from crossbench.runner.run import Run
   from crossbench.types import Json
@@ -53,9 +56,10 @@ class ChromeHistogramMetric(abc.ABC):
 
 class ChromeHistogramCountMetric(ChromeHistogramMetric):
 
-  def __init__(self, histogram_name: str):
+  def __init__(self, histogram_name: str) -> None:
     super().__init__(f"{histogram_name}_count", histogram_name)
 
+  @override
   def compute(self, delta: ChromeHistogramSample,
               baseline: ChromeHistogramSample) -> float:
     return delta.diff_count(baseline)
@@ -63,9 +67,10 @@ class ChromeHistogramCountMetric(ChromeHistogramMetric):
 
 class ChromeHistogramMeanMetric(ChromeHistogramMetric):
 
-  def __init__(self, histogram_name: str):
+  def __init__(self, histogram_name: str) -> None:
     super().__init__(f"{histogram_name}_mean", histogram_name)
 
+  @override
   def compute(self, delta: ChromeHistogramSample,
               baseline: ChromeHistogramSample) -> float:
     return delta.diff_mean(baseline)
@@ -73,16 +78,17 @@ class ChromeHistogramMeanMetric(ChromeHistogramMetric):
 
 class ChromeHistogramPercentileMetric(ChromeHistogramMetric):
 
-  def __init__(self, histogram_name: str, percentile: int):
+  def __init__(self, histogram_name: str, percentile: int) -> None:
     super().__init__(f"{histogram_name}_p{percentile}", histogram_name)
     self._percentile = percentile
 
+  @override
   def compute(self, delta: ChromeHistogramSample,
               baseline: ChromeHistogramSample) -> float:
     return delta.diff_percentile(baseline, self._percentile)
 
 
-PERCENTILE_METRIC_RE = re.compile(r"^p(\d+)$")
+PERCENTILE_METRIC_RE: re.Pattern[str] = re.compile(r"^p(\d+)$")
 
 
 def parse_histogram_metrics(value: Any,
@@ -122,7 +128,8 @@ class ChromeHistogramsProbe(JsonResultProbe):
   RESULT_LOCATION = ResultLocation.LOCAL
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "metrics",
@@ -130,7 +137,9 @@ class ChromeHistogramsProbe(JsonResultProbe):
         type=parse_histogram_metrics,
         help=("Required dictionary of Chrome UMA histogram metric names. "
               "Histograms are recorded before and after a test and any "
-              "differences logged."))
+              "differences logged."
+              "See tools/metrics/histograms/metadata/storage/histograms.xml"
+              "or chrome://histograms for a list of available histograms."))
     return parser
 
   def __init__(self, metrics: Sequence[ChromeHistogramMetric]) -> None:
@@ -145,17 +154,14 @@ class ChromeHistogramsProbe(JsonResultProbe):
     super().validate_browser(env, browser)
     self.expect_browser(browser, BrowserAttributes.CHROMIUM_BASED)
 
-  def to_json(self, actions: Actions) -> Json:
-    raise NotImplementedError("should not be called, data comes from context")
-
-  def get_context(self, run: Run) -> ChromeHistogramsProbeContext:
-    return ChromeHistogramsProbeContext(self, run)
+  def get_context_cls(self) -> Type[ChromeHistogramsProbeContext]:
+    return ChromeHistogramsProbeContext
 
 
 @dataclasses.dataclass
 class ChromeHistogramBucket:
   min: int
-  max: int
+  max: int | None
   count: int
 
 
@@ -204,7 +210,7 @@ class ChromeHistogramSample:
 
     bucket_counts: Dict[int, int] = {}
     bucket_maxes: Dict[int, int] = {}
-    prev_min: Optional[int] = None
+    prev_min: int | None = None
     for i, line in enumerate(body.splitlines(), start=1):
       m = re.match(cls._BUCKET_RE, line)
       if not m:
@@ -231,7 +237,7 @@ class ChromeHistogramSample:
                mean: Optional[float] = 0,
                flags: int = 0,
                bucket_counts: Optional[Dict[int, int]] = None,
-               bucket_maxes: Optional[Dict[int, int]] = None):
+               bucket_maxes: Optional[Dict[int, int]] = None) -> None:
     self._name = name
     self._count = count
     self._mean = mean
@@ -262,7 +268,7 @@ class ChromeHistogramSample:
     buckets: ChromeHistogramBuckets = []
     for bucket_min, bucket_count in self._bucket_counts.items():
       bucket_count = bucket_count - baseline.bucket_count(bucket_min)
-      bucket_max: Optional[int] = self._bucket_maxes.get(bucket_min)
+      bucket_max: int | None = self._bucket_maxes.get(bucket_min)
       buckets.append(
           ChromeHistogramBucket(bucket_min, bucket_max, bucket_count))
     return buckets
@@ -329,8 +335,8 @@ chrome.send("requestHistograms", ["crossbench_histograms_1", "", true]);
 
   def __init__(self, probe: ChromeHistogramsProbe, run: Run) -> None:
     super().__init__(probe, run)
-    self._baseline: Optional[Dict[str, ChromeHistogramSample]] = None
-    self._delta: Optional[Dict[str, ChromeHistogramSample]] = None
+    self._baseline: Dict[str, ChromeHistogramSample] | None = None
+    self._delta: Dict[str, ChromeHistogramSample] | None = None
 
   def dump_histograms(self, name: str) -> Dict[str, ChromeHistogramSample]:
     with self.run.actions(
@@ -355,6 +361,7 @@ chrome.send("requestHistograms", ["crossbench_histograms_1", "", true]);
     self._delta = self.dump_histograms("stop")
     super().stop()
 
+  @override
   def to_json(self, actions: Actions) -> Json:
     del actions
     assert self._baseline, "Did not extract start histograms"
diff --git a/crossbench/probes/chromium_probe.py b/crossbench/probes/chromium_probe.py
index a6726570..71dfd45a 100644
--- a/crossbench/probes/chromium_probe.py
+++ b/crossbench/probes/chromium_probe.py
@@ -6,6 +6,8 @@ from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.probes.probe import Probe
 
@@ -16,6 +18,12 @@ if TYPE_CHECKING:
 
 class ChromiumProbe(Probe):
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     self.expect_browser(browser, BrowserAttributes.CHROMIUM_BASED)
+
+  @override
+  def attach(self, browser: Browser) -> None:
+    self.expect_browser(browser, BrowserAttributes.CHROMIUM_BASED)
+    super().attach(browser)
diff --git a/crossbench/probes/cpu_frequency_map.py b/crossbench/probes/cpu_frequency_map.py
index b4023029..cc00f34c 100644
--- a/crossbench/probes/cpu_frequency_map.py
+++ b/crossbench/probes/cpu_frequency_map.py
@@ -4,18 +4,20 @@
 
 from __future__ import annotations
 
-from abc import ABCMeta, abstractmethod
+import abc
 import argparse
+import enum
 import re
-from typing import Any, Dict, Hashable, List, Pattern, TYPE_CHECKING, Type, Union
+from typing import TYPE_CHECKING, Any, Dict, Hashable, List, Pattern, TypeAlias
 
 from immutabledict import immutabledict
+from typing_extensions import override
 
 from crossbench import exception
 from crossbench import path as pth
-from crossbench.compat import StrEnum
 from crossbench.config import ConfigObject
 from crossbench.parse import NumberParser, ObjectParser
+
 if TYPE_CHECKING:
   from crossbench.plt.base import Platform
 
@@ -29,37 +31,37 @@ _WILDCARD_CONFIG_KEY = "*"
 _CPU_NAME_REGEX: Pattern[str] = re.compile("cpu[0-9]+$")
 
 
-class _ExtremeFrequency(StrEnum):
+class _ExtremeFrequency(enum.StrEnum):
   MAX = "max"
   MIN = "min"
 
 
 if TYPE_CHECKING:
-  FrequencyType = Union[_ExtremeFrequency, int]
+  FrequencyType: TypeAlias = _ExtremeFrequency | int
 
 
-class CPUFrequencyMap(ConfigObject, metaclass=ABCMeta):
+class CPUFrequencyMap(ConfigObject, metaclass=abc.ABCMeta):
 
-  @abstractmethod
+  @abc.abstractmethod
   def get_target_frequencies(
       self, platform: Platform) -> immutabledict[pth.AnyPosixPath, int]:
     raise NotImplementedError()
 
   @property
-  @abstractmethod
+  @abc.abstractmethod
   def key(self) -> Hashable:
     raise NotImplementedError()
 
   @classmethod
-  def parse_dict(cls: Type[CPUFrequencyMap],
-                 config: Dict[str, Any]) -> CPUFrequencyMap:
+  @override
+  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> CPUFrequencyMap:
     if _WILDCARD_CONFIG_KEY in config:
       return WildcardCPUFrequencyMap(config)
-
     return ExplicitCPUFrequencyMap(config)
 
   @classmethod
-  def parse_str(cls: Type[CPUFrequencyMap], value: str) -> CPUFrequencyMap:
+  @override
+  def parse_str(cls, value: str) -> CPUFrequencyMap:
     return CPUFrequencyMap.parse_dict({_WILDCARD_CONFIG_KEY: value})
 
   @classmethod
@@ -114,7 +116,7 @@ class CPUFrequencyMap(ConfigObject, metaclass=ABCMeta):
 
 class WildcardCPUFrequencyMap(CPUFrequencyMap):
 
-  def __init__(self, frequencies: Dict):
+  def __init__(self, frequencies: Dict) -> None:
     if len(frequencies) != 1:
       raise argparse.ArgumentTypeError(
           f"A wildcard ({_WILDCARD_CONFIG_KEY}) in "
@@ -123,6 +125,7 @@ class WildcardCPUFrequencyMap(CPUFrequencyMap):
     self._target_frequency = CPUFrequencyMap._parse_frequency(
         list(frequencies.values())[0])
 
+  @override
   def get_target_frequencies(
       self, platform: Platform) -> immutabledict[pth.AnyPosixPath, int]:
     return immutabledict({
@@ -133,21 +136,23 @@ class WildcardCPUFrequencyMap(CPUFrequencyMap):
     })
 
   @property
+  @override
   def key(self) -> Hashable:
     return self._target_frequency
 
 
 class ExplicitCPUFrequencyMap(CPUFrequencyMap):
 
-  def __init__(self, frequencies: Dict):
+  def __init__(self, frequencies: Dict) -> None:
     typed_map: Dict[str, FrequencyType] = {}
     for k, v in frequencies.items():
       with exception.annotate_argparsing(f"Parsing cpu frequency: {k}, {v}"):
         typed_map[ObjectParser.non_empty_str(k)] = (
             CPUFrequencyMap._parse_frequency(v))
-    self._frequencies: immutabledict[str, Union[_ExtremeFrequency,
-                                                int]] = immutabledict(typed_map)
+    self._frequencies: immutabledict[str,
+                                     FrequencyType] = immutabledict(typed_map)
 
+  @override
   def get_target_frequencies(
       self, platform: Platform) -> immutabledict[pth.AnyPosixPath, int]:
     return immutabledict({
@@ -157,5 +162,6 @@ class ExplicitCPUFrequencyMap(CPUFrequencyMap):
     })
 
   @property
+  @override
   def key(self) -> Hashable:
     return self._frequencies
diff --git a/crossbench/probes/debugger.py b/crossbench/probes/debugger.py
index e7d0063e..c329e36c 100644
--- a/crossbench/probes/debugger.py
+++ b/crossbench/probes/debugger.py
@@ -5,21 +5,22 @@
 from __future__ import annotations
 
 import shlex
-from typing import TYPE_CHECKING, Dict, Iterable
+from typing import TYPE_CHECKING, Dict, Iterable, Self, Type
+
+from typing_extensions import override
 
 from crossbench import plt
 from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.parse import PathParser
 from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
-                                     ProbeKeyT, ProbeValidationError)
+                                     ProbeKeyT)
+from crossbench.probes.probe_error import ProbeValidationError
 from crossbench.probes.result_location import ResultLocation
-from crossbench.probes.results import EmptyProbeResult, ProbeResult
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.env import HostEnvironment
   from crossbench.path import LocalPath
-  from crossbench.runner.run import Run
+  from crossbench.probes.results import ProbeResult
 
 _DEBUGGER_LOOKUP: Dict[str, str] = {
     "macos": "lldb",
@@ -38,11 +39,12 @@ class DebuggerProbe(Probe):
   IS_GENERAL_PURPOSE = True
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "debugger",
-        type=PathParser.binary_path,
+        type=plt.PLATFORM.parse_local_binary_path,
         default=_DEBUGGER_LOOKUP.get(plt.PLATFORM.name,
                                      "debugger probe not supported"),
         help="Set a custom debugger binary. "
@@ -88,6 +90,7 @@ class DebuggerProbe(Probe):
     self._spare_renderer_process = spare_renderer_process
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("debugger", str(self._debugger_bin)),
@@ -97,6 +100,7 @@ class DebuggerProbe(Probe):
         ("spare_renderer_process", self._spare_renderer_process),
     )
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     self.expect_browser(browser, BrowserAttributes.CHROMIUM_BASED)
@@ -109,9 +113,10 @@ class DebuggerProbe(Probe):
     if not browser.platform.which("xterm"):
       raise ProbeValidationError(self, "Please install xterm on your system.")
 
+  @override
   def attach(self, browser: Browser) -> None:
     super().attach(browser)
-    assert browser.attributes.is_chromium_based
+    assert browser.attributes().is_chromium_based
     flags = browser.flags
     flags.set("--no-sandbox")
     flags.set("--disable-hang-monitor")
@@ -146,8 +151,9 @@ class DebuggerProbe(Probe):
       debugger_cmd += ["--args"]
     return shlex.join(debugger_cmd)
 
-  def get_context(self, run: Run) -> DebuggerContext:
-    return DebuggerContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[DebuggerContext]:
+    return DebuggerContext
 
 
 class DebuggerContext(ProbeContext[DebuggerProbe]):
@@ -159,4 +165,4 @@ class DebuggerContext(ProbeContext[DebuggerProbe]):
     pass
 
   def teardown(self) -> ProbeResult:
-    return EmptyProbeResult()
+    return self.empty_result()
diff --git a/crossbench/probes/downloads.py b/crossbench/probes/downloads.py
new file mode 100644
index 00000000..b94ba79a
--- /dev/null
+++ b/crossbench/probes/downloads.py
@@ -0,0 +1,225 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import re
+import shlex
+from dataclasses import dataclass
+from typing import TYPE_CHECKING, Iterable, List, Set
+
+import crossbench.path as pth
+from crossbench.parse import ObjectParser
+from crossbench.probes.probe import Probe, ProbeConfigParser
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.result_location import ResultLocation
+from crossbench.probes.results import EmptyProbeResult, ProbeResult
+
+if TYPE_CHECKING:
+
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.run import Run
+
+
+class DownloadsProbe(Probe):
+  """
+  Probe that captures downloads from websites and allows loading tests to wait
+  for a download to complete.
+  """
+  NAME = "downloads"
+  RESULT_LOCATION = ResultLocation.BROWSER
+
+  CHROME_OS_DOWNLOADS_DIR = pth.AnyPath("/home/chronos/user/MyFiles/Downloads")
+
+  @classmethod
+  def config_parser(cls) -> ProbeConfigParser:
+    parser = super().config_parser()
+    parser.add_argument(
+        "clear_downloads",
+        aliases=("clear",),
+        type=ObjectParser.bool,
+        default=False,
+        help="Delete all files in the download folder before every run.")
+    parser.add_argument(
+        "save_downloads",
+        aliases=("save",),
+        type=ObjectParser.bool,
+        default=True,
+        help=("Copy all files downloaded during a test to the test results"
+              " folder."))
+    return parser
+
+  def __init__(self,
+               clear_downloads: bool = False,
+               save_downloads: bool = False) -> None:
+    super().__init__()
+    self._clear_downloads: bool = clear_downloads
+    self._save_downlaods: bool = save_downloads
+
+  def get_context(self, run: Run) -> DownloadsProbeContext:
+    if run.browser_platform.is_android:
+      return AndroidWebDriverDownloadsProbeContext(self, run)
+
+    if run.browser_platform.is_chromeos:
+      return FileWatchDownloadsProbeContext(self, run,
+                                            self.CHROME_OS_DOWNLOADS_DIR)
+    raise NotImplementedError(
+        f"Probe({self}): Unsupported browser: {run.browser}")
+
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    del group
+    # No need to merge downloads, users can find them in the individual run
+    # results folders.
+    return EmptyProbeResult()
+
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    del group
+    # No need to merge downloads, users can find them in the individual run
+    # results folders.
+    return EmptyProbeResult()
+
+  @property
+  def clear_downloads(self) -> bool:
+    return self._clear_downloads
+
+  @property
+  def save_downloads(self) -> bool:
+    return self._save_downlaods
+
+
+class DownloadsProbeContext(ProbeContext[DownloadsProbe]):
+
+  def __init__(self, probe: DownloadsProbe, run: Run) -> None:
+    super().__init__(probe, run)
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    downloads_dir = super().get_default_result_path()
+    self.browser_platform.mkdir(downloads_dir)
+    return downloads_dir
+
+  @abc.abstractmethod
+  def download_complete(self, pattern: re.Pattern) -> bool:
+    pass
+
+
+class FileWatchDownloadsProbeContext(DownloadsProbeContext):
+
+  def __init__(self, probe: DownloadsProbe, run: Run,
+               downloads_dir: pth.AnyPath) -> None:
+    super().__init__(probe, run)
+    self._downloads_dir: pth.AnyPath = downloads_dir
+    self._existing_downloads: Set[pth.AnyPath] = set()
+    self._results: List[pth.AnyPath] = []
+
+  def downloads(self, include_pending: bool = True) -> Iterable[pth.AnyPath]:
+    downloads = self.browser_platform.iterdir(self._downloads_dir)
+    if include_pending:
+      return downloads
+    return [file for file in downloads if file.suffix != ".crdownload"]
+
+  def start(self) -> None:
+    if self.probe.clear_downloads:
+      for file in self.downloads():
+        self.browser_platform.rm(file)
+      self._existing_downloads = set()
+    else:
+      self._existing_downloads = set(self.downloads())
+
+  def stop(self) -> None:
+    if not self.probe.save_downloads:
+      return
+    for file in self.downloads():
+      if file in self._existing_downloads:
+        continue
+      to_path = self.result_path / file.name
+      self.browser_platform.copy_file(file, to_path)
+      self._results.append(to_path)
+
+  def teardown(self) -> ProbeResult:
+    return self.browser_result(file=self._results)
+
+  def download_complete(self, pattern: re.Pattern) -> bool:
+    return any(pattern.search(file.name) for file in self.downloads())
+
+
+@dataclass(frozen=True)
+class AndroidDownload:
+  id: str
+  display_name: str
+
+
+class AndroidWebDriverDownloadsProbeContext(DownloadsProbeContext):
+  CONTENT_QUERY_RE = re.compile(r"Row: \d+ _display_name=(.*), _id=(\d+)")
+  CONTENT_QUERY_NO_RESULTS = "No result found."
+
+  def __init__(self, probe: DownloadsProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._existing_downloads: Set[AndroidDownload] = set()
+    self._user_id: str = str(self.browser_platform.user_id())
+    self._results: List[pth.AnyPath] = []
+
+  def downloads(self,
+                include_pending: bool = True) -> Iterable[AndroidDownload]:
+    result: List[AndroidDownload] = []
+    args = [
+        "content", "query", "--user", self._user_id, "--uri",
+        "content://media/external/downloads", "--where", "is_download=1",
+        "--projection", "_display_name:_id"
+    ]
+    if not include_pending:
+      args.append("--where")
+      args.append("is_pending=0")
+    rows = self.browser_platform.sh_stdout(*args)
+    if rows.strip() == self.CONTENT_QUERY_NO_RESULTS:
+      return result
+    for row in rows.splitlines():
+      if match := self.CONTENT_QUERY_RE.match(row):
+        result.append(
+            AndroidDownload(display_name=match.group(1), id=match.group(2)))
+      else:
+        raise RuntimeError(
+            f"Android downloads content query unexpect result row: {row}")
+
+    return result
+
+  def delete(self, download: AndroidDownload) -> None:
+    self.browser_platform.sh("content", "delete", "--user", self._user_id,
+                             "--uri", "content://media/external/downloads",
+                             "--where", f"_id='{download.id}'")
+
+  def start(self) -> None:
+    if self.probe.clear_downloads:
+      for download in self.downloads():
+        self.delete(download)
+    self._existing_downloads = set(self.downloads())
+
+  def stop(self) -> None:
+    if not self.probe.save_downloads:
+      return
+    for download in self.downloads():
+      if download in self._existing_downloads:
+        continue
+      to_path = self.result_path / download.display_name
+      read_downloads_cmd = (
+          "content",
+          "read",
+          "--user",
+          self._user_id,
+          "--uri",
+          f"content://media/external/downloads/{download.id}",
+      )
+      cmd = (
+          shlex.join(read_downloads_cmd) + ">" +
+          shlex.quote(self.browser_platform.path(to_path).as_posix()))
+      self.browser_platform.sh(cmd, shell=True)
+      self._results.append(to_path)
+
+  def teardown(self) -> ProbeResult:
+    return self.browser_result(file=self._results)
+
+  def download_complete(self, pattern: re.Pattern) -> bool:
+    downloads = self.downloads(include_pending=False)
+    return any(pattern.search(download.display_name) for download in downloads)
diff --git a/crossbench/probes/dtrace.py b/crossbench/probes/dtrace.py
index ccd76d76..86dc45dd 100644
--- a/crossbench/probes/dtrace.py
+++ b/crossbench/probes/dtrace.py
@@ -6,11 +6,14 @@ from __future__ import annotations
 
 import atexit
 import subprocess
-from typing import TYPE_CHECKING, Optional, TextIO
+from typing import TYPE_CHECKING, Self, TextIO, Type
+
+from typing_extensions import override
 
 from crossbench.parse import PathParser
 from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
-                                     ProbeKeyT, ProbeValidationError)
+                                     ProbeKeyT)
+from crossbench.probes.probe_error import ProbeValidationError
 from crossbench.probes.result_location import ResultLocation
 
 if TYPE_CHECKING:
@@ -30,16 +33,19 @@ class DTraceProbe(Probe):
   RESULT_LOCATION = ResultLocation.BROWSER
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
-    parser.add_argument("script_path", type=PathParser.non_empty_file_path)
+    parser.add_argument(
+        "script_path", required=True, type=PathParser.non_empty_file_path)
     return parser
 
-  def __init__(self, script_path: LocalPath):
+  def __init__(self, script_path: LocalPath) -> None:
     super().__init__()
     self._script_path = script_path.resolve()
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (("script_path", str(self.script_path)),)
 
@@ -47,6 +53,7 @@ class DTraceProbe(Probe):
   def script_path(self) -> LocalPath:
     return self._script_path
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     self.expect_macos(browser)
@@ -79,8 +86,9 @@ class DTraceProbe(Probe):
           self, "Cannot execute 'sudo dtrace'. "
           "This probe will fail to start.") from e
 
-  def get_context(self, run: Run) -> DTraceProbeContext:
-    return DTraceProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[DTraceProbeContext]:
+    return DTraceProbeContext
 
 
 class DTraceProbeContext(ProbeContext[DTraceProbe]):
@@ -91,8 +99,8 @@ class DTraceProbeContext(ProbeContext[DTraceProbe]):
     self._output_path: LocalPath = (
         self.local_result_path.with_suffix(".output.txt"))
     self._log_path: LocalPath = self.local_result_path.with_suffix(".log")
-    self._dtrace_process: Optional[subprocess.Popen] = None
-    self._log_file: Optional[TextIO] = None
+    self._dtrace_process: subprocess.Popen | None = None
+    self._log_file: TextIO | None = None
     atexit.register(self.stop_dtrace_process)
 
   def start(self) -> None:
diff --git a/crossbench/probes/dump_html.py b/crossbench/probes/dump_html.py
index 69ba7b8c..954d661b 100644
--- a/crossbench/probes/dump_html.py
+++ b/crossbench/probes/dump_html.py
@@ -5,18 +5,19 @@
 from __future__ import annotations
 
 import datetime as dt
-
 import os
-from typing import List, Optional
+from typing import TYPE_CHECKING, List, Optional, Self, Type
+
+from typing_extensions import override
 
-from crossbench.path import AnyPath
 from crossbench.probes.probe import Probe, ProbeConfigParser
 from crossbench.probes.probe_context import ProbeContext
 from crossbench.probes.result_location import ResultLocation
-from crossbench.probes.results import EmptyProbeResult, ProbeResult
-from crossbench.runner.groups.browsers import BrowsersRunGroup
-from crossbench.runner.groups.repetitions import RepetitionsRunGroup
-from crossbench.runner.run import Run
+
+if TYPE_CHECKING:
+  from crossbench.path import AnyPath
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
 
 
 class DumpHtmlProbe(Probe):
@@ -27,21 +28,18 @@ class DumpHtmlProbe(Probe):
   RESULT_LOCATION = ResultLocation.LOCAL
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     # TODO: support stop dumps
     return parser
 
-  def get_context(self, run: Run) -> DumpHtmlProbeContext:
-    return DumpHtmlProbeContext(self, run)
-
-  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
-    # TODO: implement
-    return EmptyProbeResult()
+  @override
+  def get_context_cls(self) -> Type[DumpHtmlProbeContext]:
+    return DumpHtmlProbeContext
 
-  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
-    # TODO: implement
-    return EmptyProbeResult()
+  # TODO: implement merge_repetitions()
+  # TODO: implement merge_browsers()
 
 
 class DumpHtmlProbeContext(ProbeContext[DumpHtmlProbe]):
@@ -50,6 +48,7 @@ class DumpHtmlProbeContext(ProbeContext[DumpHtmlProbe]):
     super().__init__(probe, run)
     self._results: List[AnyPath] = []
 
+  @override
   def get_default_result_path(self) -> AnyPath:
     dump_dir = super().get_default_result_path()
     os.mkdir(dump_dir)
@@ -67,11 +66,11 @@ class DumpHtmlProbeContext(ProbeContext[DumpHtmlProbe]):
     path = self.result_path / f"{label}.html"
     html = self.browser.js("return document.children[0].outerHTML",
                            dt.timedelta(seconds=10))
-    with open(path, "w", encoding="utf-8") as dump_file:
-      dump_file.write(html)
+    self.host_platform.set_file_contents(path, html)
     self._results.append(path)
 
+  @override
   def teardown(self) -> ProbeResult:
     if not self.browser_platform.is_dir(self.result_path):
-      return EmptyProbeResult()
+      return self.empty_result()
     return self.browser_result(file=tuple(self._results))
diff --git a/crossbench/probes/env_modifier.py b/crossbench/probes/env_modifier.py
index 4df77da3..2f74eea3 100644
--- a/crossbench/probes/env_modifier.py
+++ b/crossbench/probes/env_modifier.py
@@ -2,10 +2,14 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+from __future__ import annotations
+
+import abc
+
 from crossbench.probes.probe import Probe
 
 
-class EnvModifier(Probe):
+class EnvModifier(Probe, metaclass=abc.ABCMeta):
   """
   A class that modifies the running environment without actually producing
   data like a Probe.
diff --git a/crossbench/probes/frequency.py b/crossbench/probes/frequency.py
index 64e1c4ec..24e8e3f0 100644
--- a/crossbench/probes/frequency.py
+++ b/crossbench/probes/frequency.py
@@ -2,19 +2,24 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+from __future__ import annotations
+
 import dataclasses
-from typing import List
+from typing import TYPE_CHECKING, List, Self, Type
 
 from immutabledict import immutabledict
+from typing_extensions import override
 
 from crossbench import path as pth
-from crossbench.browsers.browser import Browser
 from crossbench.probes.cpu_frequency_map import CPUFrequencyMap
-from crossbench.env import HostEnvironment
 from crossbench.probes.env_modifier import EnvModifier
-from crossbench.probes.probe import (ProbeConfigParser, ProbeContext, ProbeKeyT)
-from crossbench.probes.results import EmptyProbeResult, ProbeResult
-from crossbench.runner.run import Run
+from crossbench.probes.probe import ProbeConfigParser, ProbeContext, ProbeKeyT
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.env import HostEnvironment
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
 
 
 class FrequencyProbe(EnvModifier):
@@ -63,12 +68,13 @@ class FrequencyProbe(EnvModifier):
   IS_GENERAL_PURPOSE = True
   PRODUCES_DATA = False
 
-  def __init__(self, cpus: CPUFrequencyMap):
+  def __init__(self, cpus: CPUFrequencyMap) -> None:
     super().__init__()
     self._cpu_frequency_map: CPUFrequencyMap = cpus
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "cpus",
@@ -78,9 +84,11 @@ class FrequencyProbe(EnvModifier):
     return parser
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (("cpus", self._cpu_frequency_map.key),)
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     # As long as a valid platform map can be derived, all is good.
@@ -90,8 +98,9 @@ class FrequencyProbe(EnvModifier):
   def cpu_frequency_map(self) -> CPUFrequencyMap:
     return self._cpu_frequency_map
 
-  def get_context(self, run: Run):
-    return FrequencyProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[FrequencyProbeContext]:
+    return FrequencyProbeContext
 
 
 @dataclasses.dataclass(frozen=True)
@@ -144,4 +153,4 @@ class FrequencyProbeContext(ProbeContext[FrequencyProbe]):
           state.dir / self._MAX_FREQUENCY_FILE, state.max)
 
   def teardown(self) -> ProbeResult:
-    return EmptyProbeResult()
+    return self.empty_result()
diff --git a/crossbench/probes/helper.py b/crossbench/probes/helper.py
index 2830c070..3ffcddda 100644
--- a/crossbench/probes/helper.py
+++ b/crossbench/probes/helper.py
@@ -154,7 +154,7 @@ def merge_csv(csv_list: Sequence[LocalPath],
 def _merge_csv_prepare_row_headers(table: List[List[Any]],
                                    known_row_headers: Set[Tuple[str, ...]],
                                    csv_file: LocalPath, row_header_len: int,
-                                   delimiter: str):
+                                   delimiter: str) -> int:
   with csv_file.open(encoding="utf-8") as first_file:
     for csv_row in csv.reader(first_file, delimiter=delimiter):
       if row_header_len == -1:
@@ -179,7 +179,7 @@ def _detect_row_header_len(row: List[str]) -> int:
 
 def _merge_csv_append(csv_data: List[List[Any]], table: List[List[Any]],
                       table_headers, row_header_len: int, headers,
-                      known_row_headers, table_row_len):
+                      known_row_headers, table_row_len) -> int:
   # Find the max row width in added csv_data.
   max_csv_row_len = max(len(row) for row in csv_data) - row_header_len
   if table:
diff --git a/crossbench/probes/internal.py b/crossbench/probes/internal.py
deleted file mode 100644
index 644d8ee1..00000000
--- a/crossbench/probes/internal.py
+++ /dev/null
@@ -1,275 +0,0 @@
-# Copyright 2023 The Chromium Authors
-# Use of this source code is governed by a BSD-style license that can be
-# found in the LICENSE file.
-
-from __future__ import annotations
-
-import json
-import logging
-from typing import TYPE_CHECKING, Iterable, Optional
-
-from crossbench.probes import probe
-from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
-from crossbench.probes.metric import MetricsMerger
-from crossbench.probes.results import (EmptyProbeResult, ProbeResult,
-                                       ProbeResultDict)
-
-if TYPE_CHECKING:
-  from crossbench.runner.actions import Actions
-  from crossbench.runner.groups.browsers import BrowsersRunGroup
-  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
-  from crossbench.runner.groups.stories import StoriesRunGroup
-  from crossbench.runner.run import Run
-  from crossbench.types import Json, JsonDict, JsonList
-
-
-class InternalProbe(probe.Probe):
-  IS_GENERAL_PURPOSE = False
-
-  @property
-  def is_internal(self) -> bool:
-    return True
-
-
-class InternalJsonResultProbe(JsonResultProbe, InternalProbe):
-  IS_GENERAL_PURPOSE = False
-  FLATTEN = False
-
-  def get_context(self, run: Run) -> InternalJsonResultProbeContext:
-    return InternalJsonResultProbeContext(self, run)
-
-
-class InternalJsonResultProbeContext(
-    JsonResultProbeContext[InternalJsonResultProbe]):
-
-  def stop(self) -> None:
-    # Only extract data in the late teardown phase.
-    pass
-
-  def teardown(self) -> ProbeResult:
-    self._json_data = self.extract_json(self.run)  # pylint: disable=no-member
-    return super().teardown()
-
-
-class LogProbe(InternalProbe):
-  """
-  Runner-internal meta-probe: Collects the python logging data from the runner
-  itself.
-  """
-  NAME = "cb.log"
-
-  def get_context(self, run: Run) -> LogProbeContext:
-    return LogProbeContext(self, run)
-
-
-class LogProbeContext(probe.ProbeContext[LogProbe]):
-
-  def __init__(self, probe_instance: LogProbe, run: Run) -> None:
-    super().__init__(probe_instance, run)
-    self._log_handler: Optional[logging.Handler] = None
-
-  def setup(self) -> None:
-    log_formatter = logging.Formatter(
-        "%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s] "
-        "[%(name)s]  %(message)s")
-    self._log_handler = logging.FileHandler(self.result_path)
-    self._log_handler.setFormatter(log_formatter)
-    self._log_handler.setLevel(logging.DEBUG)
-    logging.getLogger().addHandler(self._log_handler)
-
-  def start(self) -> None:
-    pass
-
-  def stop(self) -> None:
-    pass
-
-  def teardown(self) -> ProbeResult:
-    assert self._log_handler
-    logging.getLogger().removeHandler(self._log_handler)
-    self._log_handler = None
-    return ProbeResult(file=(self.local_result_path,))
-
-
-class SystemDetailsProbe(InternalJsonResultProbe):
-  """
-  Runner-internal meta-probe: Collects the browser's system/platform details.
-  """
-  NAME = "cb.system.details"
-
-  def to_json(self, actions: Actions) -> Json:
-    return actions.run.browser_platform.system_details()
-
-  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
-    return EmptyProbeResult()
-
-
-class ErrorsProbe(InternalJsonResultProbe):
-  """
-  Runner-internal meta-probe: Collects all errors from running stories and/or
-  from merging probe data.
-  """
-  NAME = "cb.errors"
-
-  def to_json(self, actions: Actions) -> Json:
-    return actions.run.exceptions.to_json()
-
-  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
-    return self._merge_group(group, (run.results for run in group.runs))
-
-  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
-    return self._merge_group(
-        group, (rep_group.results for rep_group in group.repetitions_groups))
-
-  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
-    return self._merge_group(
-        group, (story_group.results for story_group in group.story_groups))
-
-  def _merge_group(self, group,
-                   results_iter: Iterable[ProbeResultDict]) -> ProbeResult:
-    merged_errors = []
-
-    for results in results_iter:
-      result = results[self]
-      if not result:
-        continue
-      source_file = result.json
-      assert source_file.is_file()
-      with source_file.open(encoding="utf-8") as f:
-        repetition_errors = json.load(f)
-        assert isinstance(repetition_errors, list)
-        merged_errors.extend(repetition_errors)
-
-    group_errors = group.exceptions.to_json()
-    assert isinstance(group_errors, list)
-    merged_errors.extend(group_errors)
-
-    if not merged_errors:
-      return EmptyProbeResult()
-
-    return self.write_group_result(group, merged_errors)
-
-
-class DurationsProbe(InternalJsonResultProbe):
-  """
-  Runner-internal meta-probe: Collects timing information for various components
-  of the runner (and the times spent in individual stories as well).
-  """
-  NAME = "cb.durations"
-
-  def to_json(self, actions: Actions) -> Json:
-    return actions.run.durations.to_json()
-
-  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
-    merged = MetricsMerger.merge_json_list(
-        (repetitions_group.results[self].json
-         for repetitions_group in group.repetitions_groups),
-        merge_duplicate_paths=True)
-    return self.write_group_result(group, merged, csv_formatter=None)
-
-  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
-    merged = MetricsMerger.merge_json_list(
-        (story_group.results[self].json for story_group in group.story_groups),
-        merge_duplicate_paths=True)
-    return self.write_group_result(group, merged, csv_formatter=None)
-
-
-class ResultsSummaryProbe(InternalJsonResultProbe):
-  """
-  Runner-internal meta-probe: Collects a summary results.json with all the Run
-  information, including all paths to the results of all attached Probes.
-  """
-  NAME = "cb.results"
-  # Given that this is  a meta-Probe that summarizes the data from other
-  # probes we exclude it from the default results lists.
-  PRODUCES_DATA = False
-
-  @property
-  def is_attached(self) -> bool:
-    return True
-
-  def to_json(self, actions: Actions) -> JsonDict:
-    return actions.run.details_json()
-
-  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
-    repetitions: JsonList = []
-    browser: Optional[JsonDict] = None
-
-    for run in group.runs:
-      source_file = run.results[self].json
-      assert source_file.is_file()
-      with source_file.open(encoding="utf-8") as f:
-        repetition_data = json.load(f)
-      if browser is None:
-        browser = repetition_data["browser"]
-        del browser["log"]
-      repetitions.append({
-          "cwd": repetition_data["cwd"],
-          "probes": repetition_data["probes"],
-          "success": repetition_data["success"],
-          "errors": repetition_data["errors"],
-      })
-
-    merged_data: JsonDict = {
-        "cwd": str(group.path),
-        "story": group.story.details_json(),
-        "browser": browser,
-        "group": group.info,
-        "repetitions": repetitions,
-        "probes": group.results.to_json(),
-        "success": group.is_success,
-        "errors": group.exceptions.error_messages(),
-    }
-    return self.write_group_result(group, merged_data, csv_formatter=None)
-
-  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
-    stories: JsonDict = {}
-    browser = None
-
-    for repetitions_group in group.repetitions_groups:
-      source_file = repetitions_group.results[self].json
-      assert source_file.is_file()
-      with source_file.open(encoding="utf-8") as f:
-        merged_story_data = json.load(f)
-      if browser is None:
-        browser = merged_story_data["browser"]
-      story_info = merged_story_data["story"]
-      stories[story_info["name"]] = {
-          "cwd": merged_story_data["cwd"],
-          "duration": story_info["duration"],
-          "probes": merged_story_data["probes"],
-          "errors": merged_story_data["errors"],
-      }
-
-    merged_data: JsonDict = {
-        "cwd": str(group.path),
-        "browser": browser,
-        "stories": stories,
-        "group": group.info,
-        "probes": group.results.to_json(),
-        "success": group.is_success,
-        "errors": group.exceptions.error_messages(),
-    }
-    return self.write_group_result(group, merged_data, csv_formatter=None)
-
-  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
-    browsers: JsonDict = {}
-    for story_group in group.story_groups:
-      source_file = story_group.results[self].json
-      assert source_file.is_file()
-      with source_file.open(encoding="utf-8") as f:
-        merged_browser_data = json.load(f)
-      browser_info = merged_browser_data["browser"]
-      browsers[browser_info["unique_name"]] = {
-          "cwd": merged_browser_data["cwd"],
-          "probes": merged_browser_data["probes"],
-          "errors": merged_browser_data["errors"],
-      }
-
-    merged_data: JsonDict = {
-        "cwd": str(group.path),
-        "browsers": browsers,
-        "probes": group.results.to_json(),
-        "success": group.is_success,
-        "errors": group.exceptions.error_messages(),
-    }
-    return self.write_group_result(group, merged_data, csv_formatter=None)
diff --git a/crossbench/probes/internal/__init__.py b/crossbench/probes/internal/__init__.py
new file mode 100644
index 00000000..e9d2bfac
--- /dev/null
+++ b/crossbench/probes/internal/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/internal/base.py b/crossbench/probes/internal/base.py
new file mode 100644
index 00000000..582ee018
--- /dev/null
+++ b/crossbench/probes/internal/base.py
@@ -0,0 +1,51 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type, TypeVar
+
+from typing_extensions import override
+
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
+from crossbench.probes.probe import Probe
+
+if TYPE_CHECKING:
+  from crossbench.probes.results import ProbeResult
+
+
+class InternalProbe(Probe):
+  IS_GENERAL_PURPOSE = False
+
+  @property
+  @override
+  def is_internal(self) -> bool:
+    return True
+
+
+class InternalJsonResultProbe(JsonResultProbe, InternalProbe):
+  IS_GENERAL_PURPOSE = False
+
+  @override
+  def get_context_cls(self) -> Type[InternalJsonResultProbeContext]:
+    return InternalJsonResultProbeContext
+
+
+InternalJsonResultProbeT = TypeVar(
+    "InternalJsonResultProbeT", bound="InternalJsonResultProbe")
+
+
+class InternalJsonResultProbeContext(
+    JsonResultProbeContext[InternalJsonResultProbeT]):
+  FLATTEN = False
+
+  @override
+  def stop(self) -> None:
+    # Only extract data in the late teardown phase.
+    pass
+
+  @override
+  def teardown(self) -> ProbeResult:
+    self._json_data = self.extract_json(self.run)  # pylint: disable=no-member
+    return super().teardown()
diff --git a/crossbench/probes/internal/browser/__init__.py b/crossbench/probes/internal/browser/__init__.py
new file mode 100644
index 00000000..e9d2bfac
--- /dev/null
+++ b/crossbench/probes/internal/browser/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/internal/browser/driver_log.py b/crossbench/probes/internal/browser/driver_log.py
new file mode 100644
index 00000000..9a4ae135
--- /dev/null
+++ b/crossbench/probes/internal/browser/driver_log.py
@@ -0,0 +1,50 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.probes.internal.base import InternalProbe
+from crossbench.probes.probe_context import ProbeContext
+
+if TYPE_CHECKING:
+  from crossbench.probes.results import ProbeResult
+
+
+class BrowserDriverLogProbe(InternalProbe):
+  """
+  Runner-internal: Collects the driver logs
+  """
+  NAME = "browser.driver.log"
+
+  @override
+  def get_context_cls(self) -> Type[BrowserDriverLogProbeContext]:
+    return BrowserDriverLogProbeContext
+
+
+class BrowserDriverLogProbeContext(ProbeContext[BrowserDriverLogProbe]):
+
+  @override
+  def setup(self) -> None:
+    pass
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    # TODO: support remote driver log
+    driver_log_file = self.browser.driver_log_file
+    if not driver_log_file:
+      return self.empty_result()
+    # safaridriver writes the log to non-configurable system-folder from which
+    # we need to copy it out.
+    if driver_log_file != self.local_result_path:
+      self.host_platform.copy_file(driver_log_file, self.local_result_path)
+    return self.local_result(file=(self.local_result_path,))
diff --git a/crossbench/probes/internal/durations.py b/crossbench/probes/internal/durations.py
new file mode 100644
index 00000000..786194d5
--- /dev/null
+++ b/crossbench/probes/internal/durations.py
@@ -0,0 +1,54 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.probes.internal.base import (InternalJsonResultProbe,
+                                             InternalJsonResultProbeContext)
+from crossbench.probes.metric import MetricsMerger
+
+if TYPE_CHECKING:
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.types import Json
+
+
+class DurationsProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects timing information for various components
+  of the runner (and the times spent in individual stories as well).
+  """
+  NAME = "cb.durations"
+
+  @override
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        (repetitions_group.results[self].json
+         for repetitions_group in group.repetitions_groups),
+        merge_duplicate_paths=True)
+    return self.write_group_result(group, merged, csv_formatter=None)
+
+  @override
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    merged = MetricsMerger.merge_json_list(
+        (story_group.results[self].json for story_group in group.story_groups),
+        merge_duplicate_paths=True)
+    return self.write_group_result(group, merged, csv_formatter=None)
+
+  @override
+  def get_context_cls(self) -> Type[InternalJsonResultProbeContext]:
+    return DurationsProbeContext
+
+
+class DurationsProbeContext(InternalJsonResultProbeContext):
+
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    return self.run.durations.to_json()
diff --git a/crossbench/probes/internal/errors.py b/crossbench/probes/internal/errors.py
new file mode 100644
index 00000000..ad003675
--- /dev/null
+++ b/crossbench/probes/internal/errors.py
@@ -0,0 +1,79 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+from typing import TYPE_CHECKING, Iterable, Type
+
+from typing_extensions import override
+
+from crossbench.probes.internal.base import (InternalJsonResultProbe,
+                                             InternalJsonResultProbeContext)
+from crossbench.probes.results import EmptyProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.probes.results import ProbeResult, ProbeResultDict
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.base import RunGroup
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.types import Json, JsonList
+
+
+class ErrorsProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects all errors from running stories and/or
+  from merging probe data.
+  """
+  NAME = "cb.errors"
+
+  @override
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    return self._merge_group(group, (run.results for run in group.runs))
+
+  @override
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    return self._merge_group(
+        group, (rep_group.results for rep_group in group.repetitions_groups))
+
+  @override
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    return self._merge_group(
+        group, (story_group.results for story_group in group.story_groups))
+
+  def _merge_group(self, group: RunGroup,
+                   results_iter: Iterable[ProbeResultDict]) -> ProbeResult:
+    merged_errors: JsonList = []
+
+    for results in results_iter:
+      result = results[self]
+      if not result:
+        continue
+      source_file = result.json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        repetition_errors = json.load(f)
+        assert isinstance(repetition_errors, list)
+        merged_errors.extend(repetition_errors)
+
+    group_errors = group.exceptions.to_json()
+    assert isinstance(group_errors, list)
+    merged_errors.extend(group_errors)
+
+    if not merged_errors:
+      return EmptyProbeResult()
+    return self.write_group_result(group, merged_errors, csv_formatter=None)
+
+  @override
+  def get_context_cls(self) -> Type[ErrorsProbeContext]:
+    return ErrorsProbeContext
+
+
+class ErrorsProbeContext(InternalJsonResultProbeContext):
+
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    return self.run.exceptions.to_json()
diff --git a/crossbench/probes/internal/log.py b/crossbench/probes/internal/log.py
new file mode 100644
index 00000000..4cfef110
--- /dev/null
+++ b/crossbench/probes/internal/log.py
@@ -0,0 +1,58 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import logging
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.probes.internal.base import InternalProbe
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.results import ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+
+
+class LogProbe(InternalProbe):
+  """
+  Runner-internal meta-probe: Collects the python logging data from the runner
+  itself.
+  """
+  NAME = "cb.log"
+
+  @override
+  def get_context_cls(self) -> Type[LogProbeContext]:
+    return LogProbeContext
+
+
+class LogProbeContext(ProbeContext[LogProbe]):
+
+  def __init__(self, probe_instance: LogProbe, run: Run) -> None:
+    super().__init__(probe_instance, run)
+    self._log_handler: logging.Handler | None = None
+
+  @override
+  def setup(self) -> None:
+    log_formatter = logging.Formatter(
+        "%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s] "
+        "[%(name)s]  %(message)s")
+    self._log_handler = logging.FileHandler(self.result_path)
+    self._log_handler.setFormatter(log_formatter)
+    self._log_handler.setLevel(logging.DEBUG)
+    logging.getLogger().addHandler(self._log_handler)
+
+  def start(self) -> None:
+    pass
+
+  def stop(self) -> None:
+    pass
+
+  def teardown(self) -> ProbeResult:
+    assert self._log_handler
+    logging.getLogger().removeHandler(self._log_handler)
+    self._log_handler = None
+    return self.local_result(file=(self.local_result_path,))
diff --git a/crossbench/probes/internal/summary.py b/crossbench/probes/internal/summary.py
new file mode 100644
index 00000000..e42fa498
--- /dev/null
+++ b/crossbench/probes/internal/summary.py
@@ -0,0 +1,136 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+from typing import TYPE_CHECKING, List, Type
+
+from typing_extensions import override
+
+from crossbench.probes.internal.base import (InternalJsonResultProbe,
+                                             InternalJsonResultProbeContext)
+from crossbench.probes.results import ProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.browsers import BrowsersRunGroup
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.runner.groups.stories import StoriesRunGroup
+  from crossbench.types import Json, JsonDict
+
+
+class ResultsSummaryProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects a summary results.json with all the Run
+  information, including all paths to the results of all attached Probes.
+  """
+  NAME = "cb.results"
+  # Given that this is  a meta-Probe that summarizes the data from other
+  # probes we exclude it from the default results lists.
+  PRODUCES_DATA = False
+
+  @property
+  @override
+  def is_attached(self) -> bool:
+    return True
+
+  @override
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    repetitions: List[JsonDict] = []
+    browser: JsonDict | None = None
+
+    for run in group.runs:
+      source_file = run.results[self].json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        repetition_data = json.load(f)
+      if browser is None:
+        browser = repetition_data["browser"]
+        del browser["log"]
+      repetition_summary: JsonDict = {
+          "cwd": repetition_data["cwd"],
+          "probes": repetition_data["probes"],
+          "success": repetition_data["success"],
+          "errors": repetition_data["errors"],
+      }
+      repetitions.append(repetition_summary)
+
+    merged_data: JsonDict = {
+        "cwd": str(group.path),
+        "story": group.story.details_json(),
+        "browser": browser,
+        "group": group.info,
+        "repetitions": repetitions,
+        "probes": group.results.to_json(),
+        "success": group.is_success,
+        "errors": group.exceptions.error_messages(),
+    }
+    return self.write_group_result(group, merged_data, csv_formatter=None)
+
+  @override
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    stories: JsonDict = {}
+    browser = None
+
+    for repetitions_group in group.repetitions_groups:
+      source_file = repetitions_group.results[self].json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        merged_story_data = json.load(f)
+      if browser is None:
+        browser = merged_story_data["browser"]
+      story_info = merged_story_data["story"]
+      stories[story_info["name"]] = {
+          "cwd": merged_story_data["cwd"],
+          "duration": story_info["duration"],
+          "probes": merged_story_data["probes"],
+          "errors": merged_story_data["errors"],
+      }
+
+    merged_data: JsonDict = {
+        "cwd": str(group.path),
+        "browser": browser,
+        "stories": stories,
+        "group": group.info,
+        "probes": group.results.to_json(),
+        "success": group.is_success,
+        "errors": group.exceptions.error_messages(),
+    }
+    return self.write_group_result(group, merged_data, csv_formatter=None)
+
+  @override
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    browsers: JsonDict = {}
+    for story_group in group.story_groups:
+      source_file = story_group.results[self].json
+      assert source_file.is_file()
+      with source_file.open(encoding="utf-8") as f:
+        merged_browser_data = json.load(f)
+      browser_info = merged_browser_data["browser"]
+      browsers[browser_info["unique_name"]] = {
+          "cwd": merged_browser_data["cwd"],
+          "probes": merged_browser_data["probes"],
+          "errors": merged_browser_data["errors"],
+      }
+
+    merged_data: JsonDict = {
+        "cwd": str(group.path),
+        "browsers": browsers,
+        "probes": group.results.to_json(),
+        "success": group.is_success,
+        "errors": group.exceptions.error_messages(),
+    }
+    return self.write_group_result(group, merged_data, csv_formatter=None)
+
+  @override
+  def get_context_cls(self) -> Type[InternalJsonResultProbeContext]:
+    return ResultsSummaryProbeContext
+
+
+class ResultsSummaryProbeContext(InternalJsonResultProbeContext):
+
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    return self.run.details_json()
diff --git a/crossbench/probes/internal/system_details.py b/crossbench/probes/internal/system_details.py
new file mode 100644
index 00000000..6b580972
--- /dev/null
+++ b/crossbench/probes/internal/system_details.py
@@ -0,0 +1,41 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
+
+from crossbench.probes.internal.base import (InternalJsonResultProbe,
+                                             InternalJsonResultProbeContext)
+from crossbench.probes.results import EmptyProbeResult
+
+if TYPE_CHECKING:
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.actions import Actions
+  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
+  from crossbench.types import Json
+
+
+class SystemDetailsProbe(InternalJsonResultProbe):
+  """
+  Runner-internal meta-probe: Collects the browser's system/platform details.
+  """
+  NAME = "cb.system.details"
+
+  @override
+  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
+    return EmptyProbeResult()
+
+  @override
+  def get_context_cls(self) -> Type[InternalJsonResultProbeContext]:
+    return SystemDetailsProbeContext
+
+
+class SystemDetailsProbeContext(InternalJsonResultProbeContext):
+
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    return self.run.browser_platform.system_details()
diff --git a/crossbench/probes/js.py b/crossbench/probes/js.py
index 858dcaad..5b4fddd4 100644
--- a/crossbench/probes/js.py
+++ b/crossbench/probes/js.py
@@ -4,7 +4,9 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Optional, Self, Type
+
+from typing_extensions import override
 
 from crossbench.parse import ObjectParser
 from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
@@ -17,7 +19,6 @@ if TYPE_CHECKING:
   from crossbench.runner.actions import Actions
   from crossbench.runner.groups.browsers import BrowsersRunGroup
   from crossbench.runner.groups.stories import StoriesRunGroup
-  from crossbench.runner.run import Run
   from crossbench.types import Json
 
 
@@ -35,7 +36,8 @@ class JSProbe(JsonResultProbe):
   IS_GENERAL_PURPOSE = True
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "setup",
@@ -67,18 +69,15 @@ class JSProbe(JsonResultProbe):
     return self._metric_js
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("setup_js", self._setup_js),
         ("metric_js", self._metric_js),
     )
 
-  def to_json(self, actions: Actions) -> Json:
-    data = actions.js(self._metric_js)
-    return ObjectParser.non_empty_dict(data, "JS metric data")
-
-  def get_context(self, run: Run) -> JSProbeContext:
-    return JSProbeContext(self, run)
+  def get_context_cls(self) -> Type[JSProbeContext]:
+    return JSProbeContext
 
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     merged = MetricsMerger.merge_json_list(
@@ -93,6 +92,11 @@ class JSProbe(JsonResultProbe):
 
 class JSProbeContext(JsonResultProbeContext[JSProbe]):
 
+  @override
+  def to_json(self, actions: Actions) -> Json:
+    data = actions.js(self.probe.metric_js)
+    return ObjectParser.non_empty_dict(data, "JS metric data")
+
   def start(self) -> None:
     if setup_js := self.probe.setup_js:
       with self.run.actions(f"Probe({self.probe.name}) setup") as actions:
diff --git a/crossbench/probes/json.py b/crossbench/probes/json.py
index a367c552..6be3bc85 100644
--- a/crossbench/probes/json.py
+++ b/crossbench/probes/json.py
@@ -10,16 +10,17 @@ import json
 import logging
 from collections import defaultdict
 from typing import (TYPE_CHECKING, Any, Callable, Dict, Generic, List, Optional,
-                    Type, TypeVar, Union)
+                    Tuple, Type, TypeVar)
 
 from tabulate import tabulate
+from typing_extensions import override
 
 from crossbench.probes import helper
 from crossbench.probes.metric import (CSVFormatter, MetricsMerger,
                                       metric_geomean)
-from crossbench.probes.probe import Probe, ProbeContext, ProbeMissingDataError
-from crossbench.probes.results import (EmptyProbeResult, LocalProbeResult,
-                                       ProbeResult)
+from crossbench.probes.probe import Probe, ProbeContext
+from crossbench.probes.probe_error import ProbeMissingDataError
+from crossbench.probes.results import LocalProbeResult, ProbeResult
 
 if TYPE_CHECKING:
   from crossbench.path import LocalPath
@@ -41,30 +42,14 @@ class JsonResultProbe(Probe, metaclass=abc.ABCMeta):
   subclass.
   """
 
-  FLATTEN = True
   SORT_KEYS = True
 
   @property
+  @override
   def result_path_name(self) -> str:
     return f"{self.name}.json"
 
-  @abc.abstractmethod
-  def to_json(self, actions: Actions) -> Json:
-    """
-    Override in subclasses.
-    Returns json-serializable data.
-    """
-    return None
-
-  def flatten_json_data(self, json_data: Any) -> Json:
-    return helper.Flatten(json_data).data
-
-  def process_json_data(self, json_data) -> Any:
-    return json_data
-
-  def get_context(self, run: Run) -> JsonResultProbeContext:
-    return JsonResultProbeContext(self, run)
-
+  @override
   def merge_repetitions(
       self,
       group: RepetitionsRunGroup,
@@ -119,7 +104,7 @@ class JsonResultProbe(Probe, metaclass=abc.ABCMeta):
   def write_group_result(
       self,
       group: RunGroup,
-      merged_data: Union[Dict, List, MetricsMerger],
+      merged_data: Dict | List | MetricsMerger,
       csv_formatter: Optional[Type[CSVFormatter]] = CSVFormatter,
       value_fn: Callable[[Any], Any] = metric_geomean) -> ProbeResult:
     merged_json_path = group.get_local_probe_result_path(self)
@@ -153,7 +138,7 @@ class JsonResultProbe(Probe, metaclass=abc.ABCMeta):
     # 0 | metric 0 full path, metric path[0] ... metric path[N], metric 0 value
     #     ...                                                    ...
     # M | metric M full path, ...                                metric M value
-    headers = []
+    headers: List[Tuple[str, Any]] = []
     for label, info_value in group.info.items():
       headers.append((label, info_value))
     csv_data = csv_formatter(
@@ -189,8 +174,12 @@ class JsonResultProbe(Probe, metaclass=abc.ABCMeta):
 JsonResultProbeT = TypeVar("JsonResultProbeT", bound="JsonResultProbe")
 
 
-class JsonResultProbeContext(ProbeContext[JsonResultProbeT],
-                             Generic[JsonResultProbeT]):
+class JsonResultProbeContext(
+    ProbeContext[JsonResultProbeT],
+    Generic[JsonResultProbeT],
+    metaclass=abc.ABCMeta):
+
+  FLATTEN: bool = True
 
   def __init__(self, probe: JsonResultProbeT, run: Run) -> None:
     super().__init__(probe, run)
@@ -200,8 +189,13 @@ class JsonResultProbeContext(ProbeContext[JsonResultProbeT],
   def probe(self) -> JsonResultProbeT:
     return super().probe
 
+  @abc.abstractmethod
   def to_json(self, actions: Actions) -> Json:
-    return self.probe.to_json(actions)
+    """
+    Override in subclasses.
+    Returns json-serializable data.
+    """
+    return None
 
   def start(self) -> None:
     pass
@@ -211,7 +205,7 @@ class JsonResultProbeContext(ProbeContext[JsonResultProbeT],
 
   def teardown(self) -> ProbeResult:
     if self._json_data is None:
-      return EmptyProbeResult()
+      return self.empty_result()
     self._json_data = self.process_json_data(self._json_data)
     return self.write_json(self.run, self._json_data)
 
@@ -228,7 +222,7 @@ class JsonResultProbeContext(ProbeContext[JsonResultProbeT],
       assert json_data is not None, (
           f"Probe({self.probe.name}) produced no Json data.")
       raw_file = self.local_result_path
-      if self.probe.FLATTEN:
+      if self.FLATTEN:
         raw_file = raw_file.with_suffix(".json.nested")
         flattened_file = self.local_result_path
         flat_json_data = self.flatten_json_data(json_data)
@@ -247,7 +241,7 @@ class JsonResultProbeContext(ProbeContext[JsonResultProbeT],
     return LocalProbeResult(json=(raw_file,))
 
   def process_json_data(self, json_data: Json) -> Json:
-    return self.probe.process_json_data(json_data)
+    return json_data
 
   def flatten_json_data(self, json_data: Any) -> Json:
-    return self.probe.flatten_json_data(json_data)
+    return helper.Flatten(json_data).data
diff --git a/crossbench/probes/metric.py b/crossbench/probes/metric.py
index 68ae0455..1fdb20c0 100644
--- a/crossbench/probes/metric.py
+++ b/crossbench/probes/metric.py
@@ -6,10 +6,10 @@ from __future__ import annotations
 
 import json
 import logging
-import math
+import statistics
 from math import floor, log10
-from typing import (TYPE_CHECKING, Any, Callable, Dict, Hashable, Iterable,
-                    List, Optional, Sequence, Set, Tuple, Union)
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterable, List,
+                    Optional, Sequence, Set, Tuple)
 
 from crossbench.probes import helper
 
@@ -30,9 +30,7 @@ class Metric:
   """
 
   @classmethod
-  def format(cls,
-             value: Union[float, int],
-             stddev: Optional[float] = None) -> str:
+  def format(cls, value: float | int, stddev: Optional[float] = None) -> str:
     """Format value and stdev to only expose significant + 1 digits.
     Example outputs:
       100  10%
@@ -57,8 +55,11 @@ class Metric:
     assert isinstance(values, list)
     return cls(values)
 
-  def __init__(self, values: Optional[List] = None) -> None:
-    self.values = values or []
+  def __init__(self, values: Optional[Iterable] = None) -> None:
+    if not values:
+      self.values: List[float] = []
+    else:
+      self.values = list(values)
     self._is_numeric: bool = all(map(is_number, self.values))
 
   def __len__(self) -> int:
@@ -86,30 +87,32 @@ class Metric:
   @property
   def average(self) -> float:
     assert self._is_numeric
-    return sum(self.values) / len(self.values)
+    if not self.values:
+      return 0
+    return statistics.fmean(self.values)
 
   @property
   def geomean(self) -> float:
     assert self._is_numeric
-    return geomean(self.values)
+    if self.min <= 0:
+      logging.debug("Ignoring negative values for geomean")
+      return 0
+    return statistics.geometric_mean(self.values)
 
   @property
   def stddev(self) -> float:
     assert self._is_numeric
+    if len(self.values) < 2:
+      return 0
     # We're ignoring here any actual distribution of the data and use this as a
     # rough estimate of the quality of the data
-    average = self.average
-    variance = 0.0
-    for value in self.values:
-      variance += (average - value)**2
-    variance /= len(self.values)
-    return math.sqrt(variance)
+    return statistics.stdev(self.values)
 
   def append(self, value: Any) -> None:
     self.values.append(value)
     self._is_numeric = self._is_numeric and is_number(value)
 
-  def to_json(self) -> JsonDict:
+  def to_json(self) -> Json:
     json_data: JsonDict = {"values": self.values}
     if not self.values:
       return json_data
@@ -126,20 +129,11 @@ class Metric:
         json_data["stddevPercent"] = (stddev / average) * 100
       return json_data
     # Try to simplify repeated non-numeric values
-    if not isinstance(self.values[0], Hashable):
-      return json_data
-    if len(set(self.values)) == 1:
-      return self.values[0]
-    return json_data
-
-
-def geomean(values: Iterable[Union[int, float]]) -> float:
-  product: float = 1
-  length: int = 0
-  for value in values:
-    product *= value
-    length += 1
-  return product**(1 / length)
+    first_value = self.values[0]
+    for value in self.values[1:]:
+      if value != first_value:
+        return json_data
+    return first_value
 
 
 def metric_geomean(metric: Metric) -> float:
@@ -189,7 +183,7 @@ class MetricsMerger:
     return merger
 
   def __init__(self,
-               *args: Union[Dict, List[Dict]],
+               *args: Dict | List[Dict],
                key_fn: Optional[helper.KeyFnType] = None):
     """Create a new MetricsMerger
 
@@ -232,7 +226,7 @@ class MetricsMerger:
       else:
         self._data[key] = Metric.from_json(item)
 
-  def add(self, data: Union[Dict, List[Dict]]) -> None:
+  def add(self, data: Dict | List[Dict]) -> None:
     """ Merge "arbitrary" hierarchical data that ends up having primitive leafs.
     Anything that is not a dict is considered a leaf node.
     """
@@ -244,12 +238,11 @@ class MetricsMerger:
       self._merge(data)
 
   def _merge(
-      self, data: Union[Dict,
-                        List[Dict]], parent_path: Tuple[str, ...] = ()) -> None:
+      self, data: Dict | List[Dict], parent_path: Tuple[str, ...] = ()) -> None:
     assert isinstance(data, dict)
     for property_name, value in data.items():
       path = parent_path + (property_name,)
-      key: Optional[str] = self._key_fn(path)
+      key: str | None = self._key_fn(path)
       if key is None:
         continue
       if isinstance(value, dict):
diff --git a/crossbench/probes/perfetto/__init__.py b/crossbench/probes/perfetto/__init__.py
index 4547f8b8..e9d2bfac 100644
--- a/crossbench/probes/perfetto/__init__.py
+++ b/crossbench/probes/perfetto/__init__.py
@@ -1,3 +1,5 @@
 # Copyright 2024 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/perfetto/downloader.py b/crossbench/probes/perfetto/downloader.py
new file mode 100644
index 00000000..82db23a0
--- /dev/null
+++ b/crossbench/probes/perfetto/downloader.py
@@ -0,0 +1,76 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Final, Mapping, Optional, Tuple
+
+from crossbench import exception, plt
+
+if TYPE_CHECKING:
+  import crossbench.path as pth
+
+_BASE_STORAGE_URL = (
+    "https://commondatastorage.googleapis.com/perfetto-luci-artifacts")
+
+# Copied from perfetto sources:
+# https://crsrc.org/c/third_party/perfetto/python/perfetto/prebuilts/manifests/tracebox.py
+PLATFORM_LOOKUP: Final[Mapping[Tuple[str, str], str]] = {
+    ("linux", "x64"): "linux-amd64",
+    ("linux", "arm64"): "linux-arm64",
+    ("linux", "arm32"): "linux-arm",
+    ("chromeos_ssh", "x64"): "linux-amd64",
+    ("chromeos_ssh", "arm64"): "linux-arm64",
+    ("chromeos_ssh", "arm32"): "linux-arm",
+    ("macos", "x64"): "mac-amd64",
+    ("macos", "arm64"): "mac-arm64",
+    ("android", "arm32"): "android-arm",
+    ("android", "arm64"): "android-arm64",
+    ("android", "ia32"): "android-x86",
+    ("android", "x64"): "android-x64",
+}
+
+
+class PerfettoToolDownloader:
+
+  def __init__(self,
+               tool: str,
+               version: str = "v49.0",
+               platform: Optional[plt.Platform] = None) -> None:
+    self._version = version
+    self._tool = tool
+    self._platform = platform or plt.PLATFORM
+
+  @property
+  def version(self) -> str:
+    return self._version
+
+  @property
+  def url(self) -> str:
+    # TODO: use new platform.lookup helper.
+    platform_name = PLATFORM_LOOKUP[self._platform.key]
+    return f"{_BASE_STORAGE_URL}/{self._version}/{platform_name}/{self._tool}"
+
+  @property
+  def path(self) -> pth.AnyPath:
+    out_dir = self._platform.cache_dir("perfetto")
+    version_dir = out_dir / self._version
+    result_path = version_dir / self._tool
+    return result_path
+
+  def download(self) -> pth.AnyPath:
+    result_path = self.path
+    if self._platform.exists(result_path):
+      return result_path
+    with exception.annotate(f"Downloading {self._tool} binary"):
+      self._platform.mkdir(result_path.parent, parents=True, exist_ok=True)
+      self._platform.download_to(self.url, result_path)
+      self._platform.chmod(result_path, 0o755)
+    with exception.annotate(f"Validate {self._tool} binary"):
+      version_str = self._platform.sh_stdout(result_path, "--version")
+      if self.version not in version_str:
+        raise RuntimeError(f"{self._tool} has a different version, "
+                           f"expected {self.version}, got: {version_str}")
+
+    return result_path
diff --git a/crossbench/probes/perfetto/perfetto.py b/crossbench/probes/perfetto/perfetto.py
index 4a4177a9..6134857c 100644
--- a/crossbench/probes/perfetto/perfetto.py
+++ b/crossbench/probes/perfetto/perfetto.py
@@ -5,32 +5,37 @@
 from __future__ import annotations
 
 import abc
+import atexit
 import logging
 import subprocess
-from typing import TYPE_CHECKING, Iterable, Optional, cast
+from typing import TYPE_CHECKING, Iterable, Self, cast
+
+from typing_extensions import override
 
-from crossbench import helper
 from crossbench import path as pth
-from crossbench.parse import PathParser
+from crossbench.helper import fs_helper
+from crossbench.helper.wait import WaitRange
+from crossbench.parse import NumberParser, ObjectParser, PathParser
 from crossbench.plt.android_adb import AndroidAdbPlatform
 from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
+from crossbench.probes.perfetto.downloader import PerfettoToolDownloader
 from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
-                                     ProbeIncompatibleBrowser, ProbeKeyT)
+                                     ProbeKeyT)
 from crossbench.probes.result_location import ResultLocation
 from crossbench.probes.results import LocalProbeResult, ProbeResult
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
-  from crossbench.env import HostEnvironment
+  from crossbench.plt.base import TupleCmdArgs
   from crossbench.runner.groups.browsers import BrowsersRunGroup
   from crossbench.runner.run import Run
 
 _PERFETTO_CONFIG_REMOTE_DIR_ANDROID = pth.AnyPath(
     "/data/misc/perfetto-configs/")
 _PERFETTO_TRACE_REMOTE_DIR_ANDROID = pth.AnyPath("/data/misc/perfetto-traces/")
-
 _PERFETTO_REMOTE_DIR_CROS = pth.AnyPath("/usr/local/tmp")
 
+
 class PerfettoProbe(Probe):
   """
   A probe to collect Perfetto system traces that can be viewed on
@@ -54,34 +59,53 @@ class PerfettoProbe(Probe):
   IS_GENERAL_PURPOSE = True
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "textproto",
-        type=str,
+        type=ObjectParser.str_or_file_contents,
         help=("Serialized perfetto configuration. "
               "See probe instructions for more details"))
     parser.add_argument(
         "perfetto_bin",
         type=PathParser.any_path,
-        default="perfetto",
-        help="Perfetto binary on the browser device")
+        default=pth.AnyPath("perfetto"),
+        help="Perfetto binary on the browser device (android, chrome-os)")
+    parser.add_argument(
+        "tracebox_bin",
+        type=PathParser.any_path,
+        default=pth.AnyPath("tracebox"),
+        help="Tracebox binary on the browser device (linux, macos). "
+        "Auto downloaded on local devices.")
+    parser.add_argument(
+        "trace_browser_startup",
+        type=bool,
+        default=False,
+        help="Start perfetto tracing before launching the browser.")
     return parser
 
-  def __init__(self, textproto: str, perfetto_bin: pth.AnyPath):
+  def __init__(self,
+               textproto: str,
+               perfetto_bin: pth.AnyPath,
+               tracebox_bin: pth.AnyPath,
+               trace_browser_startup: bool = False) -> None:
     super().__init__()
     if not textproto:
       raise ValueError("Please specify a tracing config")
     self._textproto = textproto
-    if not perfetto_bin:
-      raise ValueError("Please specify a perfetto binary.")
     self._perfetto_bin = perfetto_bin
+    self._tracebox_bin = tracebox_bin
+    self._trace_browser_startup = trace_browser_startup
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("textproto", self.textproto),
         ("perfetto_bin", str(self.perfetto_bin)),
+        ("tracebox_bin", str(self.tracebox_bin)),
+        ("trace_browser_startup", str(self.trace_browser_startup)),
     )
 
   @property
@@ -93,23 +117,29 @@ class PerfettoProbe(Probe):
     return self._perfetto_bin
 
   @property
+  def tracebox_bin(self) -> pth.AnyPath:
+    return self._tracebox_bin
+
+  @property
+  def trace_browser_startup(self) -> bool:
+    return self._trace_browser_startup
+
+  @property
+  @override
   def result_path_name(self) -> str:
     return "perfetto.trace.pb"
 
-  def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
-    super().validate_browser(env, browser)
-    if not (browser.platform.is_android or browser.platform.is_chromeos):
-      raise ProbeIncompatibleBrowser(self, browser,
-                                     "Only supported on android or ChromeOS")
-
+  @override
   def attach(self, browser: Browser) -> None:
-    assert browser.attributes.is_chromium_based
+    assert browser.attributes().is_chromium_based
     browser.features.enable("EnablePerfettoSystemTracing")
     super().attach(browser)
 
+  @override
   def log_run_result(self, run: Run) -> None:
     self._log_results([run])
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     self._log_results(group.runs)
 
@@ -119,13 +149,15 @@ class PerfettoProbe(Probe):
     for run in runs:
       result_file = run.results[self].file
       logging.critical("  - %s : %s", result_file,
-                       helper.get_file_size(result_file))
+                       fs_helper.get_file_size(result_file))
 
   def get_context(self, run: Run) -> PerfettoProbeContext:
     # TODO: support more platforms
     if run.browser_platform.is_chromeos:
       return ChromeOsPerfettoProbeContext(self, run)
-    return AndroidPerfettoProbeContext(self, run)
+    if run.browser_platform.is_android:
+      return AndroidPerfettoProbeContext(self, run)
+    return DesktopPerfettoProbeContext(self, run)
 
 
 class PerfettoProbeContext(ProbeContext[PerfettoProbe], metaclass=abc.ABCMeta):
@@ -133,21 +165,26 @@ class PerfettoProbeContext(ProbeContext[PerfettoProbe], metaclass=abc.ABCMeta):
     super().__init__(probe, run)
     self._host_config_file: pth.LocalPath = (
         run.out_dir / "perfetto_config.textproto")
-    self._pid: Optional[int] = None
-
+    self._perfetto_pid: int | None = None
 
   def setup(self) -> None:
-    assert self._pid is None
+    assert self._perfetto_pid is None
     for p in self.browser_platform.processes():
       if p["name"] == "perfetto":
         logging.warning("PERFETTO: killing existing session pid: %s", p["pid"])
         self.browser_platform.terminate(p["pid"])
-
-    if not self.browser_platform.which(self.probe.perfetto_bin):
+    self._setup_validate_bin()
+    self._setup_push_perfetto_config()
+    if self.probe.trace_browser_startup:
+      self._start_perfetto()
+
+  def _setup_validate_bin(self) -> None:
+    binary = self.perfetto_cmd[0]
+    if not self.browser_platform.which(binary):
       raise ValueError(
-          f"perfetto bin '{self.probe.perfetto_bin}' cannot be found "
-          f"on {self.browser_platform}")
+          f"{repr(binary)} cannot be found on {self.browser_platform}")
 
+  def _setup_push_perfetto_config(self) -> None:
     self.host_platform.set_file_contents(self._host_config_file,
                                          self.probe.textproto)
     self.browser_platform.push(self._host_config_file,
@@ -161,40 +198,59 @@ class PerfettoProbeContext(ProbeContext[PerfettoProbe], metaclass=abc.ABCMeta):
   def get_default_result_path(self) -> pth.AnyPath:
     pass
 
+  @property
+  def perfetto_cmd(self) -> TupleCmdArgs:
+    return (self.probe.perfetto_bin,)
+
   def start(self) -> None:
+    if self.probe.trace_browser_startup:
+      if not self._perfetto_pid:
+        raise RuntimeError("Perfetto was not started")
+      return
+    self._start_perfetto()
+    self.browser.performance_mark("crossbench-probe-perfetto-start")
+
+  def stop(self) -> None:
+    self.browser.performance_mark("crossbench-probe-perfetto-stop")
+    logging.info("PERFETTO: stopping")
+    if not self._perfetto_pid:
+      raise RuntimeError("Perfetto was not started")
+    self._stop_perfetto()
+
+  def _start_perfetto(self) -> None:
     logging.info("PERFETTO: starting")
-    proc = self.browser_platform.sh(
-        self.probe.perfetto_bin,
+    cmd: TupleCmdArgs = self.perfetto_cmd + (
         "--background",
         "--config",
         self.get_browser_config_path(),
         "--txt",
         "--out",
         self.result_path,
-        capture_output=True)
+    )
+    proc = self.browser_platform.sh(*cmd, capture_output=True)
     if proc.returncode > 0:
       logging.error("perfetto command failed with stderr: %s", proc.stderr)
       raise subprocess.CalledProcessError(proc.returncode, proc.args,
                                           proc.stdout, proc.stderr)
 
-    self._pid = int(proc.stdout.decode("utf-8").rstrip())
-    self.browser.performance_mark("crossbench-probe-perfetto-start")
+    self._perfetto_pid = NumberParser.positive_int(
+        proc.stdout.decode("utf-8").rstrip(), "perfetto pid")
+    atexit.register(self._stop_perfetto)
 
-  def stop(self) -> None:
-    self.browser.performance_mark("crossbench-probe-perfetto-stop")
-    logging.info("PERFETTO: stopping")
-    if not self._pid:
-      raise RuntimeError("Perfetto was not started")
-    # TODO(cbruni): replace with wait_and_terminate
-    self.browser_platform.terminate(self._pid)
+  def _stop_perfetto(self) -> None:
+    if not self._perfetto_pid:
+      return
+    atexit.unregister(self._stop_perfetto)
+    # TODO(cbruni): replace with terminate_gracefully
+    self.browser_platform.terminate(self._perfetto_pid)
     try:
-      for _ in helper.WaitRange(1, 30).wait_with_backoff():
-        if not self.browser_platform.process_info(self._pid):
+      for _ in WaitRange(1, 30).wait_with_backoff():
+        if not self.browser_platform.process_info(self._perfetto_pid):
           break
     except TimeoutError:
       logging.error("perfetto process did not stop after 30s. "
                     "The trace might be incomplete.")
-    self._pid = None
+    self._perfetto_pid = None
 
   def teardown(self) -> ProbeResult:
     # Copy files:
@@ -210,15 +266,69 @@ class PerfettoProbeContext(ProbeContext[PerfettoProbe], metaclass=abc.ABCMeta):
     return LocalProbeResult(trace=(local_result_file,))
 
 
+class DesktopPerfettoProbeContext(PerfettoProbeContext):
+
+  def __init__(self, probe: PerfettoProbe, run: Run) -> None:
+    self._tracebox_proc: subprocess.Popen | None = None
+    super().__init__(probe, run)
+    self._tracebox_bin = self.probe.tracebox_bin
+
+  @override
+  def get_browser_config_path(self) -> pth.AnyPath:
+    return self.result_path.with_name("perfetto_config.textproto")
+
+  @override
+  def get_default_result_path(self) -> pth.AnyPath:
+    return self._run.get_default_probe_result_path(
+        self._probe).with_name("perfetto.trace.pb")
+
+  @override
+  def setup(self) -> None:
+    super().setup()
+    self._tracebox_proc = self._setup_tracebox()
+
+  @override
+  def _setup_validate_bin(self) -> None:
+    if not self.browser_platform.which(self._tracebox_bin):
+      self._tracebox_bin = PerfettoToolDownloader(
+          "tracebox", platform=self.browser_platform).download()
+    super()._setup_validate_bin()
+
+  @override
+  def teardown(self) -> ProbeResult:
+    self._teardown_tracebox()
+    return super().teardown()
+
+  def _setup_tracebox(self) -> subprocess.Popen:
+    tracebox_proc = self.browser_platform.popen(self._tracebox_bin, "traced",
+                                                "traced_probes")
+    atexit.register(self._teardown_tracebox)
+    return tracebox_proc
+
+  def _teardown_tracebox(self) -> None:
+    if self._tracebox_proc:
+      atexit.unregister(self._teardown_tracebox)
+      self._tracebox_proc.terminate()
+      self._tracebox_proc = None
+
+  @property
+  @override
+  def perfetto_cmd(self) -> TupleCmdArgs:
+    return (self._tracebox_bin, "perfetto")
+
+
 class AndroidPerfettoProbeContext(PerfettoProbeContext):
 
+  @override
   def get_browser_config_path(self) -> pth.AnyPath:
     return _PERFETTO_CONFIG_REMOTE_DIR_ANDROID / "perfetto_config.textproto"
 
+  @override
   def get_default_result_path(self) -> pth.AnyPath:
     return _PERFETTO_TRACE_REMOTE_DIR_ANDROID / "perfetto.trace.pb"
 
   @property
+  @override
   def browser_platform(self) -> AndroidAdbPlatform:
     browser_platform = super().browser_platform
     assert isinstance(browser_platform, AndroidAdbPlatform)
@@ -228,13 +338,16 @@ class AndroidPerfettoProbeContext(PerfettoProbeContext):
 class ChromeOsPerfettoProbeContext(PerfettoProbeContext):
 
   @property
+  @override
   def browser_platform(self) -> ChromeOsSshPlatform:
     browser_platform = super().browser_platform
     isinstance(browser_platform, ChromeOsSshPlatform)
     return cast(ChromeOsSshPlatform, browser_platform)
 
+  @override
   def get_browser_config_path(self) -> pth.AnyPath:
     return _PERFETTO_REMOTE_DIR_CROS / "perfetto_config.textproto"
 
+  @override
   def get_default_result_path(self) -> pth.AnyPath:
     return _PERFETTO_REMOTE_DIR_CROS / "perfetto.trace.pb"
diff --git a/crossbench/probes/perfetto/trace_processor/__init__.py b/crossbench/probes/perfetto/trace_processor/__init__.py
index 4547f8b8..e9d2bfac 100644
--- a/crossbench/probes/perfetto/trace_processor/__init__.py
+++ b/crossbench/probes/perfetto/trace_processor/__init__.py
@@ -1,3 +1,5 @@
 # Copyright 2024 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_stages.sql b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_stages.sql
new file mode 100644
index 00000000..cee110e0
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/modules/ext/loadline_stages.sql
@@ -0,0 +1,75 @@
+INCLUDE PERFETTO MODULE ext.loadline_benchmark;
+
+DROP VIEW IF EXISTS loadline_presentation;
+CREATE VIEW loadline_presentation AS
+SELECT
+  first_navigation_start() + 60e9 / loadline_benchmark_score() AS presentation;
+
+DROP VIEW IF EXISTS loadline_request;
+CREATE VIEW loadline_request AS
+SELECT ts AS start_request, ts + dur AS end_request
+FROM slice
+WHERE
+  name = 'WillStartRequest'
+  AND ts >= first_navigation_start()
+ORDER BY ts
+LIMIT 1;
+
+DROP VIEW IF EXISTS loadline_renderer_ready;
+CREATE VIEW loadline_renderer_ready AS
+SELECT ts + dur AS renderer_ready
+FROM slice
+WHERE
+  name = 'ReadyToCommitNavigation'
+  AND ts >= first_navigation_start()
+ORDER BY ts
+LIMIT 1;
+
+-- Find the frame in the pipeline which was chosen as the "loading complete"
+-- moment for the purpose of LoadLine score. The exact end timestamp might
+-- differ a little due to rounding error, so we allow 1ms discrepancy while
+-- matching. This should not match any extra frames since frames are aligned to
+-- vsyncs, and vsync interval is usually 8-17ms.
+DROP VIEW IF EXISTS loadline_frame;
+CREATE VIEW loadline_frame AS
+SELECT id
+FROM slice, loadline_presentation
+WHERE
+  name = 'PipelineReporter'
+  AND ts + dur BETWEEN presentation - 1e6 AND presentation + 1e6
+  AND extract_arg(arg_set_id, 'chrome_frame_reporter.state') = 'STATE_PRESENTED_ALL'
+ORDER BY ts
+LIMIT 1;
+
+DROP VIEW IF EXISTS loadline_frame_commit;
+CREATE VIEW loadline_frame_commit AS
+SELECT child.ts + child.dur AS frame_commit
+FROM loadline_frame, descendant_slice(loadline_frame.id) AS child
+WHERE child.name = 'Commit';
+
+DROP VIEW IF EXISTS loadline_submit_compositor_frame;
+CREATE VIEW loadline_submit_compositor_frame AS
+SELECT child.ts AS submit_compositor_frame
+FROM loadline_frame, descendant_slice(loadline_frame.id) AS child
+WHERE child.name = 'SubmitCompositorFrameToPresentationCompositorFrame';
+
+DROP VIEW IF EXISTS loadline_frame_swap;
+CREATE VIEW loadline_frame_swap AS
+SELECT child.ts + child.dur AS frame_swap
+FROM loadline_frame, descendant_slice(loadline_frame.id) AS child
+WHERE child.name = 'StartDrawToSwapStart';
+
+DROP VIEW IF EXISTS loadline_stages;
+CREATE VIEW loadline_stages AS
+SELECT
+  first_navigation_start() AS navigation_start,
+  start_request,
+  end_request,
+  renderer_ready,
+  frame_commit,
+  submit_compositor_frame,
+  frame_swap,
+  presentation
+FROM loadline_presentation, loadline_request, loadline_renderer_ready,
+     loadline_frame_commit, loadline_submit_compositor_frame, loadline_frame_swap;
+
diff --git a/crossbench/probes/perfetto/trace_processor/queries/loadline/breakdown.sql b/crossbench/probes/perfetto/trace_processor/queries/loadline/breakdown.sql
new file mode 100644
index 00000000..358f4fff
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/loadline/breakdown.sql
@@ -0,0 +1,18 @@
+INCLUDE PERFETTO MODULE ext.loadline_stages;
+
+-- Reports durations of loadline stages in milliseconds.
+-- Stages approximately correspond to the Chrome subsystem which is most
+-- important for the page loading performance.
+-- For more info on page loading process in Chrome, see the following docs:
+-- https://chromium.googlesource.com/chromium/src/+/main/docs/navigation.md
+-- https://chromium.googlesource.com/chromium/src/+/main/docs/life_of_a_frame.md
+-- https://chromium.googlesource.com/chromium/src/+/main/components/page_load_metrics/
+SELECT
+  (start_request - navigation_start) / 1e6 AS init,
+  (end_request - start_request) / 1e6 AS network,
+  (renderer_ready - end_request) / 1e6 AS launch,
+  (frame_commit - renderer_ready) / 1e6 AS renderer,
+  (submit_compositor_frame - frame_commit) / 1e6 AS compositor,
+  (frame_swap - submit_compositor_frame) / 1e6 AS gpu,
+  (presentation - frame_swap) / 1e6 AS surfaceflinger
+FROM loadline_stages;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/speedometer_compute_power_via_rails.sql b/crossbench/probes/perfetto/trace_processor/queries/speedometer_compute_power_via_rails.sql
new file mode 100644
index 00000000..faf7b581
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/speedometer_compute_power_via_rails.sql
@@ -0,0 +1,80 @@
+-- For Google Pixel devices, the speedometer_compute_power_via_rails query
+-- estimates the total power consumed during a speedometer run, by leveraging
+-- go/pixel-odpm-rails counters (sorry, Googlers only). It includes all rails
+-- related to the SoC's compute logic (e.g. CPU, GPU, memory, fabric; but
+-- excluding e.g. display)
+
+SELECT IMPORT('chrome.speedometer');
+SELECT IMPORT('android.power_rails');
+
+-- TODO(b/393047085): Move (some of) these views into TP stdlib to allow reuse.
+
+DROP VIEW IF EXISTS speedometer_bounds;
+CREATE VIEW speedometer_bounds AS
+SELECT
+  MIN(ts) AS ts,
+  MAX(ts+dur) - MIN(ts) AS dur
+FROM chrome_speedometer_measure;
+
+DROP VIEW IF EXISTS power_rails_for_join;
+CREATE VIEW power_rails_for_join AS
+SELECT
+  *,
+  HASH(power_rail_name) as hashed_rail_name
+FROM android_power_rails_counters;
+
+DROP TABLE IF EXISTS speedometer_rails_joined;
+CREATE VIRTUAL TABLE speedometer_rails_joined
+USING SPAN_JOIN(
+  speedometer_bounds,
+  power_rails_for_join PARTITIONED hashed_rail_name
+);
+
+DROP VIEW IF EXISTS speedometer_rail_energies;
+CREATE VIEW speedometer_rail_energies AS
+SELECT
+  *,
+  -- consumed energy in microjoule.
+  end_energy_uj - start_energy_uj AS energy_delta_uj,
+  -- average power in milliwatt.
+  (end_energy_uj - start_energy_uj)/dur*1e6 AS average_power_mw
+FROM (
+  SELECT
+    power_rail_name,
+    MAX(ts + dur) - MIN(ts) AS dur,
+    MIN(energy_since_boot) AS start_energy_uj,
+    -- energy_since_boot_at_end may be null if the rail's value didn't change
+    -- during Speedometer's run. In that case, end energy = start energy.
+    IFNULL(
+      MAX(energy_since_boot_at_end),
+      MIN(energy_since_boot)) AS end_energy_uj
+  FROM speedometer_rails_joined
+  GROUP BY power_rail_name
+);
+
+-- See documentation at the top of the file.
+DROP VIEW IF EXISTS speedometer_compute_power_via_rails;
+CREATE VIEW speedometer_compute_power_via_rails AS
+SELECT
+  SUM(energy_delta_uj) as energy_uj,
+  SUM(average_power_mw) as average_power_mw
+FROM speedometer_rail_energies
+WHERE
+  -- TODO(b/393047085): Verify rails to include, this is an informed guess.
+  power_rail_name IN (
+    'power.rails.cpu.big',
+    'power.rails.cpu.mid',
+    'power.rails.cpu.little',
+    'power.rails.ddr.a',
+    'power.rails.ddr.b',
+    'power.rails.ddr.c',
+    'power.rails.memory.interface',
+    'power.rails.system.fabric',
+    'power.rails.ldo.main.a',
+    'power.rails.ldo.main.b',
+    'power.rails.ldo.sub',
+    'power.rails.gpu'
+  );
+
+SELECT *
+FROM speedometer_compute_power_via_rails;
diff --git a/crossbench/probes/perfetto/trace_processor/queries/speedometer_compute_power_via_wattson.sql b/crossbench/probes/perfetto/trace_processor/queries/speedometer_compute_power_via_wattson.sql
new file mode 100644
index 00000000..e356037d
--- /dev/null
+++ b/crossbench/probes/perfetto/trace_processor/queries/speedometer_compute_power_via_wattson.sql
@@ -0,0 +1,35 @@
+-- For Google Pixel devices, the speedometer_compute_power_via_wattson query
+-- estimates the total power consumed during a speedometer run, by leveraging
+-- go/wattson-userguide (sorry, Googlers only).
+
+SELECT IMPORT('chrome.speedometer');
+SELECT IMPORT('wattson.curves.estimates');
+
+DROP VIEW IF EXISTS speedometer_bounds;
+CREATE VIEW speedometer_bounds
+AS
+SELECT
+  MIN(ts) AS ts,
+  MAX(ts + dur) - MIN(ts) AS dur
+FROM chrome_speedometer_measure;
+
+DROP TABLE IF EXISTS wattson_estimates_in_bounds;
+CREATE VIRTUAL TABLE wattson_estimates_in_bounds
+USING
+  SPAN_JOIN(
+    speedometer_bounds,
+    _system_state_mw);
+
+DROP VIEW IF EXISTS speedometer_compute_power_via_wattson;
+CREATE VIEW speedometer_compute_power_via_wattson
+AS
+SELECT
+  1e-6 * SUM(
+    dur * (
+      IFNULL(cpu0_mw, 0) + IFNULL(cpu1_mw, 0) + IFNULL(cpu2_mw, 0) +
+      IFNULL(cpu3_mw, 0) + IFNULL(cpu4_mw, 0) + IFNULL(cpu5_mw, 0) +
+      IFNULL(cpu6_mw, 0) + IFNULL(cpu7_mw, 0) + IFNULL(dsu_scu_mw, 0)))
+    AS total_energy_microjoule
+FROM wattson_estimates_in_bounds;
+
+SELECT * FROM speedometer_compute_power_via_wattson;
diff --git a/crossbench/probes/perfetto/trace_processor/trace_processor.py b/crossbench/probes/perfetto/trace_processor/trace_processor.py
index 63f0d843..29dd79bf 100644
--- a/crossbench/probes/perfetto/trace_processor/trace_processor.py
+++ b/crossbench/probes/perfetto/trace_processor/trace_processor.py
@@ -5,10 +5,12 @@
 from __future__ import annotations
 
 import collections
+import dataclasses
 import json
 import logging
 import zipfile
-from typing import TYPE_CHECKING, Dict, Iterable, List, Optional, Tuple, Union
+from typing import (TYPE_CHECKING, Dict, Iterable, List, Optional, Self, Tuple,
+                    Type)
 
 import pandas as pd
 from google.protobuf.json_format import MessageToJson
@@ -18,9 +20,12 @@ from perfetto.trace_processor.api import TraceProcessor, TraceProcessorConfig
 from perfetto.trace_uri_resolver.path import PathUriResolver
 from perfetto.trace_uri_resolver.registry import ResolverRegistry
 from perfetto.trace_uri_resolver.resolver import TraceUriResolver
+from typing_extensions import override
 
 from crossbench import path as pth
-from crossbench.parse import PathParser
+from crossbench import plt
+from crossbench.config import ConfigObject, ConfigParser
+from crossbench.parse import ObjectParser, PathParser
 from crossbench.probes.metric import MetricsMerger
 from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeContext
 from crossbench.probes.results import LocalProbeResult, ProbeResult
@@ -35,10 +40,35 @@ _QUERIES_DIR = pth.LocalPath(__file__).parent / "queries"
 _MODULES_DIR = pth.LocalPath(__file__).parent / "modules/ext"
 
 
+@dataclasses.dataclass(frozen=True)
+class TraceProcessorQueryConfig(ConfigObject):
+  name: str
+  sql: str
+
+  @classmethod
+  @override
+  def parse_str(cls, value: str) -> Self:
+    name = ObjectParser.safe_filename(value)
+    sql_path = PathParser.existing_file_path(_QUERIES_DIR / f"{value}.sql",
+                                             "sql query")
+    sql = sql_path.read_text(encoding="utf-8")
+    return cls(name=name, sql=sql)
+
+  @classmethod
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
+    parser.add_argument("name", type=ObjectParser.safe_filename, required=True)
+    parser.add_argument(
+        "sql", type=ObjectParser.str_or_file_contents, required=True)
+    return parser
+
+
 class CrossbenchTraceUriResolver(TraceUriResolver):
   PREFIX = "crossbench"
 
-  def __init__(self, traces: Union[Iterable[Run], TraceProcessorProbeContext]):
+  def __init__(self,
+               traces: Iterable[Run] | TraceProcessorProbeContext) -> None:
 
     def metadata(run: Run) -> Dict[str, str]:
       return {
@@ -75,12 +105,12 @@ class TraceProcessorProbe(Probe):
   NAME = "trace_processor"
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "batch",
         type=bool,
-        required=False,
         default=False,
         help="Run queries in batch mode when all the test runs are done. This "
         "can considerably reduce the run time at the expense of higher "
@@ -94,29 +124,31 @@ class TraceProcessorProbe(Probe):
         help="Name of metric to be run (can be any metric from Perfetto)")
     parser.add_argument(
         "queries",
-        type=str,
+        type=TraceProcessorQueryConfig,
         is_list=True,
         default=tuple(),
-        help="Name of query to be run (under probes/trace_processor/queries)")
+        help="Name of query to be run (under probes/trace_processor/queries) "
+        "or { name: str, sql: str } containing the name and SQL query to run")
     parser.add_argument(
         "trace_processor_bin",
         type=PathParser.local_binary_path,
-        required=False,
         help="Path to the trace_processor binary")
     return parser
 
   def __init__(self,
                batch: bool,
                metrics: Iterable[str],
-               queries: Iterable[str],
-               trace_processor_bin: Optional[pth.LocalPath] = None):
+               queries: Iterable[TraceProcessorQueryConfig],
+               trace_processor_bin: Optional[pth.LocalPath] = None) -> None:
     super().__init__()
     self._batch = batch
     self._metrics = tuple(metrics)
+    ObjectParser.unique_sequence([query.name for query in queries],
+                                 name="query names")
     self._queries = tuple(queries)
-    self._trace_processor_bin: Optional[pth.LocalPath] = None
+    self._trace_processor_bin: pth.LocalPath | None = None
     if trace_processor_bin:
-      self._trace_processor_bin = PathParser.local_binary_path(
+      self._trace_processor_bin = plt.PLATFORM.parse_local_binary_path(
           trace_processor_bin, "trace_processor")
 
   @property
@@ -128,7 +160,7 @@ class TraceProcessorProbe(Probe):
     return self._metrics
 
   @property
-  def queries(self) -> Tuple[str, ...]:
+  def queries(self) -> Tuple[TraceProcessorQueryConfig, ...]:
     return self._queries
 
   @property
@@ -158,11 +190,14 @@ class TraceProcessorProbe(Probe):
         bin_path=self.trace_processor_bin,
         resolver_registry=ResolverRegistry(
             resolvers=[CrossbenchTraceUriResolver, PathUriResolver]),
+        load_timeout=10,
         extra_flags=extra_flags)
 
-  def get_context(self, run: Run) -> TraceProcessorProbeContext:
-    return TraceProcessorProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[TraceProcessorProbeContext]:
+    return TraceProcessorProbeContext
 
+  @override
   def validate_env(self, env: HostEnvironment) -> None:
     super().validate_env(env)
     self._check_sql()
@@ -176,8 +211,7 @@ class TraceProcessorProbe(Probe):
       for metric in self.metrics:
         tp.metric([metric])
       for query in self.queries:
-        query_path = _QUERIES_DIR / f"{query}.sql"
-        tp.query(query_path.read_text())
+        tp.query(query.sql)
 
   def _add_cb_columns(self, df: pd.DataFrame, run: Run) -> pd.DataFrame:
     df["cb_browser"] = run.browser.unique_name
@@ -213,6 +247,7 @@ class TraceProcessorProbe(Probe):
         for metric_name, merged in merged_metrics.items()
     }
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     if self.needs_btp_run:
       return self._run_btp(group)
@@ -247,10 +282,9 @@ class TraceProcessorProbe(Probe):
         traces=CrossbenchTraceUriResolver(group.runs),
         config=btp_config) as btp:
 
-      def run_query(query: str):
-        query_path = _QUERIES_DIR / f"{query}.sql"
-        csv_file = group_dir / f"{pth.safe_filename(query)}.csv"
-        btp.query_and_flatten(query_path.read_text()).to_csv(
+      def run_query(query: TraceProcessorQueryConfig):
+        csv_file = group_dir / f"{query.name}.csv"
+        btp.query_and_flatten(query.sql).to_csv(
             path_or_buf=csv_file, index=False)
         return csv_file
 
@@ -268,6 +302,7 @@ class TraceProcessorProbe(Probe):
 
     return LocalProbeResult(csv=csv_files, json=json_files)
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     logging.info("-" * 80)
     logging.critical("TraceProcessor merged traces:")
@@ -304,7 +339,7 @@ class TraceProcessorProbeContext(ProbeContext[TraceProcessorProbe]):
           zip_file.write(f, arcname=f.relative_to(self.run.out_dir))
     return LocalProbeResult(trace=(self.merged_trace_path,))
 
-  def _maybe_run_tp(self):
+  def _maybe_run_tp(self) -> ProbeResult:
     if not self.probe.needs_tp_run:
       return LocalProbeResult()
 
@@ -315,10 +350,9 @@ class TraceProcessorProbeContext(ProbeContext[TraceProcessorProbe]):
 
   def _run_queries(self, tp: TraceProcessor) -> LocalProbeResult:
 
-    def run_query(query: str):
-      query_path = _QUERIES_DIR / f"{query}.sql"
-      csv_file = self.local_result_path / f"{pth.safe_filename(query)}.csv"
-      tp.query(query_path.read_text()).as_pandas_dataframe().to_csv(
+    def run_query(query: TraceProcessorQueryConfig):
+      csv_file = self.local_result_path / f"{query.name}.csv"
+      tp.query(query.sql).as_pandas_dataframe().to_csv(
           path_or_buf=csv_file, index=False)
       return csv_file
 
@@ -331,8 +365,9 @@ class TraceProcessorProbeContext(ProbeContext[TraceProcessorProbe]):
     def run_metric(metric: str):
       json_file = self.local_result_path / f"{pth.safe_filename(metric)}.json"
       proto = tp.metric([metric])
-      with json_file.open("x") as f:
-        f.write(MessageToJson(proto))
+      assert not json_file.exists(), (
+          f"Cannot override previously generated metric {json_file}")
+      json_file.write_text(MessageToJson(proto))
       return json_file
 
     with self.run.actions("TRACE_PROCESSOR: Running metrics", verbose=True):
@@ -340,5 +375,5 @@ class TraceProcessorProbeContext(ProbeContext[TraceProcessorProbe]):
       return LocalProbeResult(json=files)
 
   @property
-  def merged_trace_path(self):
+  def merged_trace_path(self) -> pth.LocalPath:
     return self.local_result_path / "merged_trace.zip"
diff --git a/crossbench/probes/perfetto/tracing.py b/crossbench/probes/perfetto/tracing.py
index a86a1f16..2b5090ac 100644
--- a/crossbench/probes/perfetto/tracing.py
+++ b/crossbench/probes/perfetto/tracing.py
@@ -8,7 +8,9 @@ import argparse
 import enum
 import logging
 import sys
-from typing import TYPE_CHECKING, Dict, Optional, Sequence, Set
+from typing import FrozenSet, TYPE_CHECKING, Dict, Optional, Self, Sequence, Set, Type
+
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.config import ConfigEnum
@@ -22,16 +24,15 @@ if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.plt.base import ListCmdArgs
   from crossbench.probes.results import ProbeResult
-  from crossbench.runner.run import Run
 
 # TODO: go over these again and clean the categories.
-MINIMAL_CONFIG = frozenset((
+MINIMAL_CONFIG: FrozenSet[str] = frozenset((
     "blink.user_timing",
     "toplevel",
     "v8",
     "v8.execute",
 ))
-DEVTOOLS_TRACE_CONFIG = frozenset((
+DEVTOOLS_TRACE_CONFIG: FrozenSet[str] = frozenset((
     "blink.console",
     "blink.user_timing",
     "devtools.timeline",
@@ -49,7 +50,7 @@ DEVTOOLS_TRACE_CONFIG = frozenset((
     "toplevel",
     "v8.execute",
 ))
-V8_TRACE_CONFIG = frozenset((
+V8_TRACE_CONFIG: FrozenSet[str] = frozenset((
     "blink",
     "blink.user_timing",
     "browser",
@@ -85,10 +86,11 @@ V8_TRACE_CONFIG = frozenset((
     "v8.execute",
     "wayland",
 ))
-V8_GC_STATS_TRACE_CONFIG = V8_TRACE_CONFIG | frozenset(
+V8_GC_STATS_TRACE_CONFIG: FrozenSet[str] = V8_TRACE_CONFIG | frozenset(
     ("disabled-by-default-v8.gc_stats",))
 
 TRACE_PRESETS: Dict[str, frozenset[str]] = {
+    "empty": frozenset(),
     "minimal": MINIMAL_CONFIG,
     "devtools": DEVTOOLS_TRACE_CONFIG,
     "v8": V8_TRACE_CONFIG,
@@ -133,7 +135,8 @@ def parse_trace_config_file_path(value: str) -> pth.LocalPath:
     raise argparse.ArgumentTypeError(
         "Empty trace config: no trace categories or memory dumps configured.")
   RecordMode.parse(config.get("record_mode", RecordMode.CONTINUOUSLY))
-  return pth.LocalPath(value)
+  config_file_path = pth.LocalPath(value)
+  return config_file_path.absolute()
 
 
 ANDROID_TRACE_CONFIG_PATH = pth.AnyPosixPath(
@@ -145,16 +148,20 @@ class TracingProbe(ChromiumProbe):
   Chromium-only Probe to collect tracing / perfetto data that can be used by
   chrome://tracing or https://ui.perfetto.dev/.
 
-  Currently WIP
+  Configuration:
+  Currently you can configure the tracing probe in three different ways:
+  - preset:       Using a common preset, by default set to "minimal",
+  - categories:   Add more categories to the current selected preset,
+  - trace_config: Use a predefined trace config file that overrides the two
+                  previous options.
   """
   NAME = "tracing"
   RESULT_LOCATION = ResultLocation.BROWSER
   CHROMIUM_FLAGS = ("--enable-perfetto",)
 
-  HELP_URL = "https://bit.ly/chrome-about-tracing"
-
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "preset",
@@ -162,18 +169,23 @@ class TracingProbe(ChromiumProbe):
         default="minimal",
         choices=TRACE_PRESETS.keys(),
         help=("Use predefined trace categories, "
-              f"see source {__file__} for more details."))
+              f"see source {__file__} for more details. "
+              "This is cumulative with the categories option."))
     parser.add_argument(
         "categories",
         is_list=True,
         default=[],
         type=str,
-        help=f"A list of trace categories to enable.\n{cls.HELP_URL}")
+        help=("A list of trace categories to enable.\n"
+              "https://bit.ly/chrome-about-tracing\n"
+              "This is cumulative with the preset option."))
     parser.add_argument(
         "trace_config",
         type=parse_trace_config_file_path,
         help=("Sets Chromium's --trace-config-file to the given json config.\n"
-              "https://bit.ly/chromium-memory-startup-tracing "))
+              "https://bit.ly/chromium-memory-startup-tracing\n"
+              "'trace_config' is incompatible with the preset and categories "
+              "option."))
     parser.add_argument(
         "startup_duration",
         default=0,
@@ -211,13 +223,13 @@ class TracingProbe(ChromiumProbe):
                record_format: RecordFormat = RecordFormat.PROTO,
                traceconv: Optional[pth.LocalPath] = None) -> None:
     super().__init__()
-    self._trace_config: Optional[pth.LocalPath] = trace_config
+    self._trace_config: pth.LocalPath | None = trace_config
     self._categories: Set[str] = set(categories or MINIMAL_CONFIG)
-    self._preset: Optional[str] = preset
+    self._preset: str | None = preset
     if preset:
       self._categories.update(TRACE_PRESETS[preset])
     if self._trace_config:
-      if self._categories != set(MINIMAL_CONFIG):
+      if self._categories and self._categories != set(MINIMAL_CONFIG):
         raise argparse.ArgumentTypeError(
             "TracingProbe requires either a list of "
             "trace categories or a trace_config file.")
@@ -226,7 +238,7 @@ class TracingProbe(ChromiumProbe):
     self._startup_duration: int = startup_duration
     self._record_mode: RecordMode = record_mode
     self._record_format: RecordFormat = record_format
-    self._traceconv: Optional[pth.LocalPath] = traceconv
+    self._traceconv: pth.LocalPath | None = traceconv
     if not traceconv and self._record_format == RecordFormat.PROTO:
       self._find_traceconv()
 
@@ -236,6 +248,7 @@ class TracingProbe(ChromiumProbe):
       logging.debug("Using default traceconv: %s", traceconv)
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (("preset", self._preset),
                           ("categories", tuple(self._categories)),
@@ -245,6 +258,7 @@ class TracingProbe(ChromiumProbe):
                           ("traceconv", str(self._traceconv)))
 
   @property
+  @override
   def result_path_name(self) -> str:
     return f"trace.{self._record_format.value}"  # pylint: disable=no-member
 
@@ -256,8 +270,25 @@ class TracingProbe(ChromiumProbe):
   def record_format(self) -> RecordFormat:
     return self._record_format
 
+  @property
+  def record_mode(self) -> RecordMode:
+    return self._record_mode
+
+  @property
+  def categories(self) -> Set[str]:
+    return set(self._categories)
+
+  @property
+  def trace_config_file(self) -> Optional[pth.LocalPath]:
+    return self._trace_config
+
+  @property
+  def startup_duration(self) -> int:
+    return self._startup_duration
+
+  @override
   def attach(self, browser: Browser) -> None:
-    assert browser.attributes.is_chromium_based
+    assert browser.attributes().is_chromium_based
     flags = browser.flags
     flags.update(self.CHROMIUM_FLAGS)
     # Force proto file so we can convert it to legacy json as well.
@@ -275,12 +306,13 @@ class TracingProbe(ChromiumProbe):
       flags["--enable-tracing"] = ",".join(self._categories)
     super().attach(browser)
 
-  def get_context(self, run: Run) -> TracingProbeContext:
-    return TracingProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[TracingProbeContext]:
+    return TracingProbeContext
 
 
 class TracingProbeContext(ProbeContext[TracingProbe]):
-  _traceconv: Optional[pth.AnyPath]
+  _traceconv: pth.AnyPath | None
   _record_format: RecordFormat
 
   def setup(self) -> None:
@@ -296,7 +328,7 @@ class TracingProbeContext(ProbeContext[TracingProbe]):
   def teardown(self) -> ProbeResult:
     if self._record_format == RecordFormat.JSON:
       return self.browser_result(json=(self.result_path,))
-    traceconv: Optional[pth.LocalPath] = self.probe.traceconv
+    traceconv: pth.LocalPath | None = self.probe.traceconv
     result = self.browser_result(proto=(self.result_path,))
     if not traceconv:
       logging.info(
@@ -317,7 +349,7 @@ class TracingProbeContext(ProbeContext[TracingProbe]):
     json_trace_file = local_proto.with_suffix(".json")
     cmd: ListCmdArgs = [traceconv, "json", self.result_path, json_trace_file]
     if not self.host_platform.is_posix:
-      python_executable = sys.argv[0]
-      cmd = [python_executable] + cmd
+      python_executable: ListCmdArgs = [sys.argv[0]]
+      cmd = python_executable + cmd
     self.host_platform.sh(*cmd)
     return json_trace_file
diff --git a/crossbench/probes/performance_entries.py b/crossbench/probes/performance_entries.py
index 5bd841ba..5afec4f3 100644
--- a/crossbench/probes/performance_entries.py
+++ b/crossbench/probes/performance_entries.py
@@ -1,13 +1,16 @@
 # Copyright 2022 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
+
 from __future__ import annotations
 
 import logging
-from typing import TYPE_CHECKING
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
 
 from crossbench.probes import metric
-from crossbench.probes.json import JsonResultProbe
+from crossbench.probes.json import JsonResultProbe, JsonResultProbeContext
 from crossbench.probes.probe import ProbeIncompatibleBrowser
 
 if TYPE_CHECKING:
@@ -29,12 +32,43 @@ class PerformanceEntriesProbe(JsonResultProbe):
   """
   NAME = "performance.entries"
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     if not hasattr(browser, "js"):
       raise ProbeIncompatibleBrowser(self, browser,
                                      "Needs browser with JS-execution support")
 
+  @override
+  def get_context_cls(self) -> Type[PerformanceEntriesProbeContext]:
+    return PerformanceEntriesProbeContext
+
+  @override
+  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
+    stories = list(group.stories)
+    if len(stories) > 1:
+      logging.warning(
+          "%s: Merging performance.entries from %d possibly unrelated pages %s",
+          group.browser.unique_name, len(stories),
+          ", ".join(story.name for story in stories))
+    merged = metric.MetricsMerger.merge_json_list(
+        (story_group.results[self].json
+         for story_group in group.repetitions_groups),
+        merge_duplicate_paths=True)
+    return self.write_group_result(group, merged)
+
+  @override
+  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
+    # TODO: recreate the CSV from the merged JSON files since we might not
+    # get the same values in all browsers.
+    # TODO: Add merged browser data with separate stories.
+    return self.merge_browsers_json_list(group).merge(
+        self.merge_browsers_csv_list(group))
+
+
+class PerformanceEntriesProbeContext(JsonResultProbeContext):
+
+  @override
   def to_json(self, actions: Actions) -> Json:
     return actions.js("""
       let data = { __proto__: null, paint: {}, mark: {} };
@@ -59,23 +93,3 @@ class PerformanceEntriesProbe(JsonResultProbe):
       }
       return data;
       """)
-
-  def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
-    stories = list(group.stories)
-    if len(stories) > 1:
-      logging.warning(
-          "%s: Merging performance.entries from %d possibly unrelated pages %s",
-          group.browser.unique_name, len(stories),
-          ", ".join(story.name for story in stories))
-    merged = metric.MetricsMerger.merge_json_list(
-        (story_group.results[self].json
-         for story_group in group.repetitions_groups),
-        merge_duplicate_paths=True)
-    return self.write_group_result(group, merged)
-
-  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
-    # TODO: recreate the CSV from the merged JSON files since we might not
-    # get the same values in all browsers.
-    # TODO: Add merged browser data with separate stories.
-    return self.merge_browsers_json_list(group).merge(
-        self.merge_browsers_csv_list(group))
diff --git a/crossbench/probes/polling.py b/crossbench/probes/polling.py
index c8ea9343..09e53ba9 100644
--- a/crossbench/probes/polling.py
+++ b/crossbench/probes/polling.py
@@ -9,7 +9,9 @@ import datetime as dt
 import logging
 import threading
 import time
-from typing import TYPE_CHECKING, Iterable
+from typing import TYPE_CHECKING, Iterable, Self, Type
+
+from typing_extensions import override
 
 from crossbench.parse import DurationParser, ObjectParser
 from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeKeyT
@@ -23,6 +25,7 @@ if TYPE_CHECKING:
   from crossbench.plt.base import CmdArg, TupleCmdArgs
   from crossbench.runner.run import Run
 
+
 class PollingProbe(Probe, metaclass=abc.ABCMeta):
   """
   Abstract probe to periodically collect the results of any bash cmd.
@@ -31,7 +34,8 @@ class PollingProbe(Probe, metaclass=abc.ABCMeta):
   IS_GENERAL_PURPOSE = False
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "interval",
@@ -52,6 +56,7 @@ class PollingProbe(Probe, metaclass=abc.ABCMeta):
       raise ValueError(f"Polling interval must be >= 0.1s, but got: {interval}")
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (("cmd", tuple(self.cmd)),
                           ("interval", self.interval.total_seconds()))
@@ -64,17 +69,19 @@ class PollingProbe(Probe, metaclass=abc.ABCMeta):
   def cmd(self) -> TupleCmdArgs:
     return self._cmd
 
+  @override
   def validate_env(self, env: HostEnvironment) -> None:
     super().validate_env(env)
     if env.repetitions != 1:
       env.handle_warning(f"Probe={self.NAME} cannot merge data over multiple "
                          f"repetitions={env.repetitions}.")
 
-  def get_context(self, run: Run) -> PollingProbeContext:
-    return PollingProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[PollingProbeContext]:
+    return PollingProbeContext
 
 
-class ShellPollingProbe(PollingProbe):
+class PollingShellProbe(PollingProbe):
   """
   General-purpose probe to periodically collect the stdout of a given bash cmd.
   """
@@ -83,7 +90,8 @@ class ShellPollingProbe(PollingProbe):
   NAME = "poll"
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "cmd",
@@ -101,6 +109,7 @@ class PollingProbeContext(ProbeContext[PollingProbe]):
     self._poller = CMDPoller(self.browser_platform, self.probe.cmd,
                              self.probe.interval, self.local_result_path)
 
+  @override
   def setup(self) -> None:
     self.local_result_path.mkdir()
 
@@ -117,7 +126,7 @@ class PollingProbeContext(ProbeContext[PollingProbe]):
 class CMDPoller(threading.Thread):
 
   def __init__(self, platform: plt.Platform, cmd: Iterable[CmdArg],
-               interval: dt.timedelta, path: LocalPath):
+               interval: dt.timedelta, path: LocalPath) -> None:
     super().__init__()
     self._platform = platform
     self._cmd: TupleCmdArgs = tuple(cmd)
@@ -140,8 +149,7 @@ class CMDPoller(threading.Thread):
       data = self._platform.sh_stdout(*self._cmd)
       datetime_str = poll_start.strftime("%Y-%m-%d_%H%M%S_%f")
       out_file = self._path / f"{datetime_str}.txt"
-      with out_file.open("w", encoding="utf-8") as f:
-        f.write(data)
+      out_file.write_text(data, encoding="utf-8")
 
       poll_end = dt.datetime.now()
       diff = (poll_end - poll_start).total_seconds()
diff --git a/crossbench/probes/power_sampler.py b/crossbench/probes/power_sampler.py
index 5f4cc07e..cc1c4aaf 100644
--- a/crossbench/probes/power_sampler.py
+++ b/crossbench/probes/power_sampler.py
@@ -10,14 +10,18 @@ import datetime as dt
 import enum
 import logging
 import subprocess
-from typing import TYPE_CHECKING, Optional, Sequence, Tuple
+from typing import TYPE_CHECKING, Optional, Self, Sequence, Tuple, Type
 
-from crossbench import compat, helper
+from typing_extensions import override
+
+from crossbench import plt
 from crossbench.helper.path_finder import ChromiumBuildBinaryFinder
-from crossbench.parse import DurationParser, PathParser
+from crossbench.parse import DurationParser
 from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
-                                     ProbeKeyT, ProbeValidationError)
+                                     ProbeKeyT)
+from crossbench.probes.probe_error import ProbeValidationError
 from crossbench.probes.result_location import ResultLocation
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
@@ -28,7 +32,7 @@ if TYPE_CHECKING:
 
 
 @enum.unique
-class SamplerType(compat.StrEnumWithHelp):
+class SamplerType(StrEnumWithHelp):
   MAIN_DISPLAY = ("main_display",
                   "Samples the backlight level of the main display.")
   BATTERY = ("battery", "Provides data retrieved from the IOPMPowerSource.")
@@ -59,9 +63,10 @@ class PowerSamplerProbe(Probe):
                           SamplerType.MAIN_DISPLAY)
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
-    parser.add_argument("bin_path", type=PathParser.binary_path)
+    parser.add_argument("bin_path", type=plt.PLATFORM.parse_local_binary_path)
     parser.add_argument(
         "sampling_interval",
         type=DurationParser.positive_duration,
@@ -80,9 +85,9 @@ class PowerSamplerProbe(Probe):
                bin_path: Optional[AnyPath] = None,
                sampling_interval: dt.timedelta = dt.timedelta(),
                samplers: Sequence[SamplerType] = SAMPLERS,
-               wait_for_battery: bool = True):
+               wait_for_battery: bool = True) -> None:
     super().__init__()
-    self._bin_path: Optional[AnyPath] = bin_path
+    self._bin_path: AnyPath | None = bin_path
     if not self._bin_path:
       logging.debug("No default power_sampler binary provided.")
     self._sampling_interval = sampling_interval
@@ -93,6 +98,7 @@ class PowerSamplerProbe(Probe):
     self._wait_for_battery = wait_for_battery
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("bin_path", str(self.bin_path)),
@@ -117,6 +123,7 @@ class PowerSamplerProbe(Probe):
   def wait_for_battery(self) -> bool:
     return self._wait_for_battery
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     self.expect_macos(browser)
     if not browser.platform.is_battery_powered:
@@ -142,7 +149,8 @@ class PowerSamplerProbe(Probe):
         return maybe_path
     raise self.missing_power_sampler_error(browser_platform, maybe_build_dir)
 
-  def missing_power_sampler_error(self, browser_platform, maybe_build_dir):
+  def missing_power_sampler_error(self, browser_platform,
+                                  maybe_build_dir) -> ProbeValidationError:
     is_build_dir = browser_platform.is_file(maybe_build_dir / "args.gn")
     if not is_build_dir:
       maybe_build_dir = browser_platform.path(
@@ -154,8 +162,9 @@ class PowerSamplerProbe(Probe):
     ]
     return ProbeValidationError(self, "\n".join(error_message))
 
-  def get_context(self, run: Run) -> PowerSamplerProbeContext:
-    return PowerSamplerProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[PowerSamplerProbeContext]:
+    return PowerSamplerProbeContext
 
 
 class PowerSamplerProbeContext(ProbeContext[PowerSamplerProbe]):
@@ -163,9 +172,9 @@ class PowerSamplerProbeContext(ProbeContext[PowerSamplerProbe]):
   def __init__(self, probe: PowerSamplerProbe, run: Run) -> None:
     super().__init__(probe, run)
     self._bin_path: AnyPath = probe.find_power_sampler_bin(self.browser)
-    self._active_user_process: Optional[subprocess.Popen] = None
-    self._power_process: Optional[subprocess.Popen] = None
-    self._power_battery_process: Optional[subprocess.Popen] = None
+    self._active_user_process: subprocess.Popen | None = None
+    self._power_process: subprocess.Popen | None = None
+    self._power_battery_process: subprocess.Popen | None = None
     self._power_output: AnyPath = self.result_path.with_suffix(".power.json")
     self._power_battery_output: AnyPath = self.result_path.with_suffix(
         ".power_battery.json")
@@ -219,13 +228,13 @@ class PowerSamplerProbeContext(ProbeContext[PowerSamplerProbe]):
 
   def stop_processes(self) -> None:
     if self._power_process:
-      helper.wait_and_kill(self._power_process)
+      self.browser_platform.terminate_gracefully(self._power_process)
       self._power_process = None
     if self._power_battery_process:
-      helper.wait_and_kill(self._power_battery_process)
+      self.browser_platform.terminate_gracefully(self._power_battery_process)
       self._power_battery_process = None
     if self._active_user_process:
-      helper.wait_and_kill(self._active_user_process)
+      self.browser_platform.terminate_gracefully(self._active_user_process)
       self._active_user_process = None
 
   def _wait_for_battery_not_full(self, run: Run) -> None:
diff --git a/crossbench/probes/powermetrics.py b/crossbench/probes/powermetrics.py
index 23f44463..5f8a585f 100644
--- a/crossbench/probes/powermetrics.py
+++ b/crossbench/probes/powermetrics.py
@@ -8,13 +8,15 @@ import atexit
 import datetime as dt
 import enum
 import subprocess
-from typing import TYPE_CHECKING, Optional, Sequence, Tuple
+from typing import TYPE_CHECKING, Self, Sequence, Tuple, Type
+
+from typing_extensions import override
 
-from crossbench import compat, helper
 from crossbench.parse import DurationParser
 from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
                                      ProbeKeyT)
 from crossbench.probes.result_location import ResultLocation
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
@@ -25,7 +27,7 @@ if TYPE_CHECKING:
 
 
 @enum.unique
-class SamplerType(compat.StrEnumWithHelp):
+class SamplerType(StrEnumWithHelp):
   BATTERY = ("battery", "Battery level")
   CPU_POWER = ("cpu_power",
                "CPU power and per-core frequency and idle residency")
@@ -52,7 +54,8 @@ class PowerMetricsProbe(Probe):
                           SamplerType.TASKS, SamplerType.THERMAL)
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "sampling_interval",
@@ -64,7 +67,7 @@ class PowerMetricsProbe(Probe):
 
   def __init__(self,
                sampling_interval: dt.timedelta = dt.timedelta(),
-               samplers: Sequence[SamplerType] = SAMPLERS):
+               samplers: Sequence[SamplerType] = SAMPLERS) -> None:
     super().__init__()
     self._sampling_interval = sampling_interval
     if sampling_interval.total_seconds() < 0:
@@ -72,6 +75,7 @@ class PowerMetricsProbe(Probe):
     self._samplers = tuple(samplers)
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("sampling_interval", self.sampling_interval.total_seconds()),
@@ -86,19 +90,21 @@ class PowerMetricsProbe(Probe):
   def samplers(self) -> Tuple[SamplerType, ...]:
     return self._samplers
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     self.expect_macos(browser)
 
-  def get_context(self, run: Run) -> PowerMetricsProbeContext:
-    return PowerMetricsProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[PowerMetricsProbeContext]:
+    return PowerMetricsProbeContext
 
 
 class PowerMetricsProbeContext(ProbeContext[PowerMetricsProbe]):
 
   def __init__(self, probe: PowerMetricsProbe, run: Run) -> None:
     super().__init__(probe, run)
-    self._power_metrics_process: Optional[subprocess.Popen] = None
+    self._power_metrics_process: subprocess.Popen | None = None
     self._output_plist_file: AnyPath = self.result_path.with_suffix(".plist")
 
   def start(self) -> None:
@@ -127,5 +133,5 @@ class PowerMetricsProbeContext(ProbeContext[PowerMetricsProbe]):
 
   def stop_process(self) -> None:
     if self._power_metrics_process:
-      helper.wait_and_kill(self._power_metrics_process)
+      self.browser_platform.terminate_gracefully(self._power_metrics_process)
       self._power_metrics_process = None
diff --git a/crossbench/probes/probe.py b/crossbench/probes/probe.py
index 7b5e4832..75f43c9a 100644
--- a/crossbench/probes/probe.py
+++ b/crossbench/probes/probe.py
@@ -5,12 +5,16 @@
 from __future__ import annotations
 
 import abc
-from typing import (TYPE_CHECKING, Dict, Hashable, Optional, Set, Tuple, Type,
-                    TypeVar)
+from typing import (TYPE_CHECKING, Dict, Hashable, Optional, Self, Set, Tuple,
+                    Type, TypeVar)
+
+from typing_extensions import override
 
 from crossbench import plt
-from crossbench.config import ConfigParser
+from crossbench.config import ConfigParser, UnusedPropertiesMode
 from crossbench.probes.probe_context import ProbeContext, ProbeSessionContext
+from crossbench.probes.probe_error import ProbeIncompatibleBrowser
+from crossbench.probes.probe_result_key import ProbeResultKey
 from crossbench.probes.result_location import ResultLocation
 from crossbench.probes.results import EmptyProbeResult, ProbeResult
 
@@ -33,7 +37,10 @@ ProbeT = TypeVar("ProbeT", bound="Probe")
 class ProbeConfigParser(ConfigParser[ProbeT]):
 
   def __init__(self, probe_cls: Type[ProbeT]) -> None:
-    super().__init__("Probe", probe_cls, allow_unused_config_data=False)
+    super().__init__(
+        probe_cls,
+        f"{probe_cls.NAME} probe parser",
+        unused_properties_mode=UnusedPropertiesMode.ERROR)
     self._probe_cls: Type[ProbeT] = probe_cls
 
   @property
@@ -41,30 +48,11 @@ class ProbeConfigParser(ConfigParser[ProbeT]):
     return self._probe_cls
 
 
-class ProbeMissingDataError(ValueError):
-  pass
-
-
-class ProbeValidationError(ValueError):
-
-  def __init__(self, probe: Probe, message: str) -> None:
-    self.probe = probe
-    super().__init__(f"Probe({probe.NAME}): {message}")
-
-
-class ProbeIncompatibleBrowser(ProbeValidationError):
-
-  def __init__(self,
-               probe: Probe,
-               browser: Browser,
-               message: str = "Incompatible browser") -> None:
-    super().__init__(probe, f"{message}, got {browser.attributes}")
-
 
 ProbeKeyT = Tuple[Tuple[str, Hashable], ...]
 
 
-class Probe(abc.ABC):
+class Probe(ProbeResultKey, abc.ABC):
   """
   Abstract Probe class.
 
@@ -92,7 +80,7 @@ class Probe(abc.ABC):
   NAME: str = ""
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     return ProbeConfigParser(cls)
 
   @classmethod
@@ -149,6 +137,7 @@ class Probe(abc.ABC):
     return plt.PLATFORM
 
   @property
+  @override
   def name(self) -> str:
     return self.NAME
 
@@ -191,7 +180,7 @@ class Probe(abc.ABC):
                      browser: Browser,
                      attributes: BrowserAttributes,
                      message: Optional[str] = None) -> None:
-    if attributes in browser.attributes:
+    if attributes in browser.attributes():
       return
     if not message:
       message = f"Incompatible browser, expected {attributes}"
@@ -231,14 +220,18 @@ class Probe(abc.ABC):
     del group
     return EmptyProbeResult()
 
-  @abc.abstractmethod
-  def get_context(self: ProbeT, run: Run) -> Optional[ProbeContext[ProbeT]]:
-    pass
+  def get_context(self: Self, run: Run) -> Optional[ProbeContext[Self]]:
+    probe_cls: Type[ProbeContext[Self]] = self.get_context_cls()
+    return probe_cls(self, run)
+
+  def get_context_cls(self: Self) -> Type[ProbeContext[Self]]:
+    raise NotImplementedError(f"Missing default ProbeContext class for {self}")
 
-  def get_session_context(
-      self: ProbeT,
-      session: BrowserSessionRunGroup) -> Optional[ProbeSessionContext[ProbeT]]:
+  def get_session_context(  # pylint: disable=useless-return
+      self: Self,
+      session: BrowserSessionRunGroup) -> Optional[ProbeSessionContext[Self]]:
     del session
+    return None
 
   def log_run_result(self, run: Run) -> None:
     """
diff --git a/crossbench/probes/probe_context.py b/crossbench/probes/probe_context.py
index d1ccca5b..4afc2f90 100644
--- a/crossbench/probes/probe_context.py
+++ b/crossbench/probes/probe_context.py
@@ -10,6 +10,8 @@ import datetime as dt
 from typing import (TYPE_CHECKING, Generic, Iterable, Iterator, Optional,
                     TypeVar)
 
+from typing_extensions import override
+
 from crossbench import plt
 from crossbench.probes.results import (BrowserProbeResult, EmptyProbeResult,
                                        LocalProbeResult, ProbeResult)
@@ -46,8 +48,8 @@ class BaseProbeContext(Generic[ProbeT], metaclass=abc.ABCMeta):
     self._result_origin = result_origin
     self._is_active: bool = False
     self._is_success: bool = False
-    self._start_time: Optional[dt.datetime] = None
-    self._stop_time: Optional[dt.datetime] = None
+    self._start_time: dt.datetime | None = None
+    self._stop_time: dt.datetime | None = None
 
   def set_start_time(self, start_datetime: dt.datetime) -> None:
     assert self._start_time is None
@@ -59,14 +61,14 @@ class BaseProbeContext(Generic[ProbeT], metaclass=abc.ABCMeta):
     assert not self._is_active
     assert not self._is_success
 
-    with self.result_origin.exception_handler(f"Probe {self.name} start"):
+    with self.result_origin.exception_capture(f"Probe {self.name} start"):
       self._is_active = True
       self.start()
 
     try:
       yield
     finally:
-      with self.result_origin.exception_handler(f"Probe {self.name} stop"):
+      with self.result_origin.exception_capture(f"Probe {self.name} stop"):
         self.stop()
         self._is_success = True
         assert self._stop_time is None
@@ -157,10 +159,15 @@ class BaseProbeContext(Generic[ProbeT], metaclass=abc.ABCMeta):
     """Helper to create LocalProbeResult."""
     return LocalProbeResult(url=url, file=file, **kwargs)
 
+  def empty_result(self) -> EmptyProbeResult:
+    return EmptyProbeResult()
+
   def setup(self) -> None:
     """
     Called before starting the browser, typically used to set run-specific
     browser flags.
+    If an error is thrown here, *none* of the other hooks
+    (start, stop, teardown) will be called.
     """
 
   @abc.abstractmethod
@@ -195,26 +202,32 @@ class ProbeContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
     return self._run
 
   @property
+  @override
   def result_origin(self) -> ResultOrigin:
     return self._run
 
   @property
+  @override
   def session(self) -> BrowserSessionRunGroup:
     return self._run.session
 
   @property
+  @override
   def browser(self) -> Browser:
     return self._run.browser
 
   @property
+  @override
   def runner(self) -> Runner:
     return self._run.runner
 
   @property
+  @override
   def result_path(self) -> AnyPath:
     return self._default_result_path
 
   @property
+  @override
   def local_result_path(self) -> LocalPath:
     return self.host_platform.local_path(self.result_path)
 
@@ -226,11 +239,12 @@ class ProbeContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
     del options
 
   @abc.abstractmethod
+  @override
   def start(self) -> None:
     """
     Called immediately before starting the given Run, after the browser started.
     This method should have as little overhead as possible. If possible,
-    delegate heavy computation to the "SetUp" method.
+    delegate heavy computation to the "setup" method.
     """
 
   def start_story_run(self) -> None:
@@ -246,6 +260,7 @@ class ProbeContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
     """
 
   @abc.abstractmethod
+  @override
   def stop(self) -> None:
     """
     Called immediately after finishing the given Run with the browser still
@@ -256,16 +271,18 @@ class ProbeContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
     return None
 
   @abc.abstractmethod
+  @override
   def teardown(self) -> ProbeResult:
     """
     Called after stopping all probes and shutting down the browser.
+    Not called if an error was thrown in the setup method.
     Returns
     - None if no data was collected
     - If Data was collected:
       - Either a path (or list of paths) to results file
       - Directly a primitive json-serializable object containing the data
     """
-    return EmptyProbeResult()
+    return self.empty_result()
 
 
 class ProbeSessionContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
@@ -284,17 +301,21 @@ class ProbeSessionContext(BaseProbeContext[ProbeT], metaclass=abc.ABCMeta):
     return self._session.get_default_probe_result_path(self._probe)
 
   @property
+  @override
   def session(self) -> BrowserSessionRunGroup:
     return self._session
 
   @property
+  @override
   def result_origin(self) -> ResultOrigin:
     return self._session
 
   @property
+  @override
   def browser(self) -> Browser:
     return self._session.browser
 
   @property
+  @override
   def result_path(self) -> AnyPath:
     return self._default_result_path
diff --git a/crossbench/probes/probe_error.py b/crossbench/probes/probe_error.py
new file mode 100644
index 00000000..ad5d124e
--- /dev/null
+++ b/crossbench/probes/probe_error.py
@@ -0,0 +1,31 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+  from crossbench.probes.probe import Probe
+
+
+class ProbeMissingDataError(ValueError):
+  pass
+
+
+class ProbeValidationError(ValueError):
+
+  def __init__(self, probe: Probe, message: str) -> None:
+    self.probe = probe
+    super().__init__(f"Probe({probe.NAME}): {message}")
+
+
+class ProbeIncompatibleBrowser(ProbeValidationError):
+
+  def __init__(self,
+               probe: Probe,
+               browser: Browser,
+               message: str = "Incompatible browser") -> None:
+    super().__init__(probe, f"{message}, got {browser.attributes()}")
diff --git a/crossbench/cli/config/secret_type.py b/crossbench/probes/probe_result_key.py
similarity index 53%
rename from crossbench/cli/config/secret_type.py
rename to crossbench/probes/probe_result_key.py
index 940700a8..6ac02224 100644
--- a/crossbench/cli/config/secret_type.py
+++ b/crossbench/probes/probe_result_key.py
@@ -4,11 +4,11 @@
 
 from __future__ import annotations
 
-import enum
+import typing
 
-from crossbench.config import ConfigEnum
 
+class ProbeResultKey(typing.Protocol):
 
-@enum.unique
-class SecretType(ConfigEnum):
-  GOOGLE = ("google", "Google account name and password")
+  @property
+  def name(self) -> str:
+    raise NotImplementedError()
diff --git a/crossbench/probes/profiling/__init__.py b/crossbench/probes/profiling/__init__.py
index a74d260c..67eefa28 100644
--- a/crossbench/probes/profiling/__init__.py
+++ b/crossbench/probes/profiling/__init__.py
@@ -1,3 +1,5 @@
 # Copyright 2023 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/profiling/browser_profiling.py b/crossbench/probes/profiling/browser_profiling.py
index d807bc74..208f3471 100644
--- a/crossbench/probes/profiling/browser_profiling.py
+++ b/crossbench/probes/profiling/browser_profiling.py
@@ -7,16 +7,18 @@ from __future__ import annotations
 import abc
 import enum
 import json
-from typing import TYPE_CHECKING, List, Optional, cast
+from typing import TYPE_CHECKING, List, Optional, Self, cast
 
 from selenium.webdriver.safari.options import Options as SafariOptions
+from typing_extensions import override
 
-from crossbench import compat
-from crossbench.browsers.chromium.webdriver import ChromiumWebDriver
+from crossbench.browsers.chromium.webdriver import ChromiumBasedWebDriver
 from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
-                                     ProbeIncompatibleBrowser, ProbeKeyT,
-                                     ProbeValidationError)
+                                     ProbeKeyT)
+from crossbench.probes.probe_error import (ProbeIncompatibleBrowser,
+                                           ProbeValidationError)
 from crossbench.probes.result_location import ResultLocation
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 if TYPE_CHECKING:
   from selenium.webdriver.common.options import BaseOptions
@@ -29,7 +31,7 @@ if TYPE_CHECKING:
 
 
 @enum.unique
-class MozProfilerStartupFeatures(compat.StrEnumWithHelp):
+class MozProfilerStartupFeatures(StrEnumWithHelp):
   """Options for MOZ_PROFILER_STARTUP_FEATURES env var.
     Extracted via MOZ_PROFILER_HELP=1 ./firefox-nightly-en/firefox
     """
@@ -68,7 +70,7 @@ class MozProfilerStartupFeatures(compat.StrEnumWithHelp):
 
 
 @enum.unique
-class FirefoxProfilerEnvVars(compat.StrEnum):
+class FirefoxProfilerEnvVars(enum.StrEnum):
   # If set to any value other than '' or '0'/'N'/'n', starts the
   # profiler immediately on start-up.
   STARTUP = "MOZ_PROFILER_STARTUP"
@@ -90,7 +92,8 @@ class BrowserProfilingProbe(Probe):
   IS_GENERAL_PURPOSE = True
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "moz_profiler_startup_features",
@@ -99,14 +102,17 @@ class BrowserProfilingProbe(Probe):
         default=[])
     return parser
 
-  def __init__(self,
-               moz_profiler_startup_features: Optional[
-                   List[MozProfilerStartupFeatures]] = None):
+  def __init__(
+      self,
+      moz_profiler_startup_features: Optional[
+          List[MozProfilerStartupFeatures]] = None
+  ) -> None:
     super().__init__()
     self._moz_profiler_startup_features: List[
         MozProfilerStartupFeatures] = moz_profiler_startup_features or []
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("moz_profiler_startup_features",
@@ -116,25 +122,29 @@ class BrowserProfilingProbe(Probe):
   def moz_profiler_startup_features(self) -> List[MozProfilerStartupFeatures]:
     return self._moz_profiler_startup_features
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     if browser.platform.is_remote:
       raise ProbeValidationError(
           self, f"Only works on local browser, but got {browser}.")
-    attributes = browser.attributes
+    attributes = browser.attributes()
     if attributes.is_chromium_based or attributes.is_safari:
       return
     if attributes.is_firefox:
-      browser_env = browser.platform.environ
-      for env_var in list(FirefoxProfilerEnvVars):
-        if env_var.value in browser_env:
-          env.handle_warning(
-              f"Probe({self}) conflicts with existing "
-              f"env[{env_var.value}]={browser_env[env_var.value]}")
+      self._validate_firefox(env, browser)
     raise ProbeIncompatibleBrowser(self, browser)
 
+  def _validate_firefox(self, env: HostEnvironment, browser: Browser) -> None:
+    browser_env = browser.platform.environ
+    for env_var in list(FirefoxProfilerEnvVars):
+      env_var_str = str(env_var)
+      if env_var_str in browser_env:
+        env.handle_warning(f"Probe({self}) conflicts with existing "
+                           f"env[{env_var_str}]={browser_env[env_var_str]}")
+
   def get_context(self, run: Run) -> BrowserProfilingProbeContext:
-    attributes = run.browser.attributes
+    attributes = run.browser.attributes()
     if attributes.is_chromium_based:
       return ChromiumWebDriverBrowserProfilerProbeContext(self, run)
     if attributes.is_firefox:
@@ -148,6 +158,7 @@ class BrowserProfilingProbe(Probe):
 class BrowserProfilingProbeContext(
     ProbeContext[BrowserProfilingProbe], metaclass=abc.ABCMeta):
 
+  @override
   def setup(self) -> None:
     pass
 
@@ -161,13 +172,14 @@ class BrowserProfilingProbeContext(
 class ChromiumWebDriverBrowserProfilerProbeContext(BrowserProfilingProbeContext
                                                   ):
 
+  @override
   def get_default_result_path(self) -> AnyPath:
     return (super().get_default_result_path().parent /
-            f"{self.browser.type_name}.profile.json")
+            f"{self.browser.type_name()}.profile.json")
 
   @property
-  def chromium(self) -> ChromiumWebDriver:
-    return cast(ChromiumWebDriver, self.browser)
+  def chromium(self) -> ChromiumBasedWebDriver:
+    return cast(ChromiumBasedWebDriver, self.browser)
 
   def start(self) -> None:
     self.chromium.start_profiling()
@@ -188,9 +200,11 @@ class ChromiumWebDriverBrowserProfilerProbeContext(BrowserProfilingProbeContext
 
 class FirefoxBrowserProfilerProbeContext(BrowserProfilingProbeContext):
 
+  @override
   def get_default_result_path(self) -> AnyPath:
     return super().get_default_result_path().parent / "firefox.profile.json"
 
+  @override
   def setup(self) -> None:
     env = self.browser.platform.environ
     env[FirefoxProfilerEnvVars.STARTUP] = "y"
@@ -199,6 +213,7 @@ class FirefoxBrowserProfilerProbeContext(BrowserProfilingProbeContext):
           str(feature) for feature in self.probe.moz_profiler_startup_features)
     env[FirefoxProfilerEnvVars.SHUTDOWN] = str(self.result_path)
 
+  @override
   def teardown(self) -> ProbeResult:
     env = self.browser.platform.environ
     del env[FirefoxProfilerEnvVars.STARTUP]
@@ -209,13 +224,16 @@ class FirefoxBrowserProfilerProbeContext(BrowserProfilingProbeContext):
 
 class SafariWebdriverBrowserProfilerProbeContext(BrowserProfilingProbeContext):
 
+  @override
   def get_default_result_path(self) -> AnyPath:
     return super().get_default_result_path().parent / "safari.timeline.json"
 
+  @override
   def setup_selenium_options(self, options: BaseOptions) -> None:
     assert isinstance(options, SafariOptions)
     cast(SafariOptions, options).automatic_profiling = True
 
+  @override
   def stop(self) -> None:
     # TODO: Update this mess when Safari supports a command-line option
     # to download the profile.
@@ -244,5 +262,6 @@ class SafariWebdriverBrowserProfilerProbeContext(BrowserProfilingProbeContext):
         end tell
       end tell""")
 
+  @override
   def teardown(self) -> ProbeResult:
     return self.browser_result(json=[self.result_path])
diff --git a/crossbench/probes/profiling/context/__init__.py b/crossbench/probes/profiling/context/__init__.py
new file mode 100644
index 00000000..e9d2bfac
--- /dev/null
+++ b/crossbench/probes/profiling/context/__init__.py
@@ -0,0 +1,5 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/profiling/context/android.py b/crossbench/probes/profiling/context/android.py
new file mode 100644
index 00000000..b07d8fd5
--- /dev/null
+++ b/crossbench/probes/profiling/context/android.py
@@ -0,0 +1,186 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import io
+import logging
+import subprocess
+import time
+from typing import TYPE_CHECKING, Iterable, List, Optional, Tuple, cast
+
+from typing_extensions import override
+
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
+from crossbench.probes.profiling.context.base import PosixProfilingContext
+from crossbench.probes.profiling.enum import CallGraphMode, TargetMode
+
+if TYPE_CHECKING:
+  import crossbench.path as pth
+  from crossbench.plt.base import ListCmdArgs
+  from crossbench.probes.results import ProbeResult
+
+
+class AndroidProfilingContext(PosixProfilingContext):
+
+  def _generate_command_line(self) -> ListCmdArgs:
+    renderer_pid: int | None = None
+    renderer_main_tid: int | None = None
+    if self.probe.target in (TargetMode.RENDERER_MAIN_ONLY,
+                             TargetMode.RENDERER_PROCESS_ONLY):
+      renderer_pid, renderer_main_tid = self.renderer_pid_tid
+    return generate_simpleperf_command_line(
+        self.probe.target,
+        str(self.run.browser.path),
+        renderer_pid,
+        renderer_main_tid,
+        self.probe.call_graph_mode,
+        self.probe.frequency,
+        self.probe.count,
+        self.probe.cpu,
+        self.probe.events,
+        self.probe.grouped_events,
+        self.probe.add_counters,
+        self.result_path,
+    )
+
+  def _start_simpleperf(self) -> None:
+    command_line = self._generate_command_line()
+    logging.info("Starting simpleperf with command line: %s.", command_line)
+    self._profiling_process = self.browser_platform.popen(
+        *command_line, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
+    # Wait a bit for simpleperf to start and (potentially) terminate on error.
+    time.sleep(1)
+    if self._profiling_process.poll():
+      error_msg: str = ""
+      if stdout := self._profiling_process.stdout:
+        if isinstance(stdout, io.BufferedReader):
+          error_msg = stdout.read().decode("utf-8")
+          logging.error(error_msg)
+      raise ValueError(f"Unable to start simpleperf. {error_msg}")
+    atexit.register(self.stop_process)
+    self.browser.performance_mark("crossbench-probe-profiling-start")
+
+  def _get_simpleperf_pids(self) -> List[int]:
+    simpleperf_pids = []
+    for process in self.browser_platform.processes():
+      if process["name"] == "simpleperf":
+        simpleperf_pids.append(process["pid"])
+    return simpleperf_pids
+
+  def _stop_existing_simpleperf(self) -> None:
+    for simpleperf_pid in self._get_simpleperf_pids():
+      logging.warning("Terminating existing simpleperf process: %d.",
+                      simpleperf_pid)
+      self.browser_platform.terminate(simpleperf_pid)
+
+  def _cpu_mask(self, cpus: Iterable) -> str:
+    assert max(cpus) < 32, "Cpu index too high"
+    mask = 0
+    for cpu in cpus:
+      mask |= (1 << cpu)
+    return f"{mask:x}"
+
+  def _pin_renderer_main_core(self, cpu: int) -> None:
+    _, renderer_main_tid = self.renderer_pid_tid
+    self.browser_platform.sh("taskset", "-p", self._cpu_mask([cpu]),
+                             str(renderer_main_tid))
+
+  def get_default_result_path(self) -> pth.AnyPath:
+    return super().get_default_result_path().parent / "simpleperf.perf.data"
+
+  def setup(self) -> None:
+    assert self.browser.platform.is_android, (
+        f"Expected Android platform, found {type(self.browser.platform)}.")
+    assert self.browser.attributes().is_chromium_based, (
+        f"Expected Chromium-based browser, found {type(self.browser)}.")
+    if (self.browser.platform.is_android and
+        self.browser.attributes().is_chromium_based):
+      chromium = cast(ChromiumBased, self.browser)
+      # Set `--enable-benchmarking` explicitly for
+      # retrieving Renderer PID, if needed.
+      chromium.flags.set("--enable-benchmarking")
+    self._stop_existing_simpleperf()
+
+  def start(self) -> None:
+    if not self.probe.start_profiling_after_setup:
+      self._start_simpleperf()
+
+  @override
+  def start_story_run(self) -> None:
+    super().start_story_run()
+    if self.probe.pin_renderer_main_core is not None:
+      self._pin_renderer_main_core(self.probe.pin_renderer_main_core)
+
+    if self.probe.start_profiling_after_setup:
+      self._start_simpleperf()
+
+  def stop(self) -> None:
+    self.stop_process()
+
+  def stop_process(self) -> None:
+    if self._profiling_process:
+      self.browser_platform.terminate_gracefully(
+          self._profiling_process,
+          timeout=30,
+          signal=self.browser_platform.signals.SIGINT)
+      self._profiling_process = None
+      self.browser.performance_mark("crossbench-probe-profiling-stop")
+
+  def teardown(self) -> ProbeResult:
+    return self.browser_result(trace=[self.result_path])
+
+
+def generate_simpleperf_command_line(
+    target: TargetMode,
+    app_name: str,
+    renderer_pid: Optional[int],
+    renderer_main_tid: Optional[int],
+    call_graph_mode: CallGraphMode,
+    frequency: Optional[int | str],
+    count: Optional[int],
+    cpus: Tuple[int, ...],
+    events: Tuple[str, ...],
+    grouped_events: Tuple[str, ...],
+    add_counters: Tuple[str, ...],
+    output_path: pth.AnyPath,
+) -> ListCmdArgs:
+  command_line: ListCmdArgs = ["simpleperf", "record"]
+  if target == TargetMode.RENDERER_MAIN_ONLY:
+    assert renderer_main_tid is not None
+    command_line.extend(["-t", str(renderer_main_tid)])
+  elif target == TargetMode.RENDERER_PROCESS_ONLY:
+    assert renderer_pid is not None
+    command_line.extend(["-p", str(renderer_pid)])
+  elif target == TargetMode.BROWSER_APP_ONLY:
+    command_line.extend(["--app", app_name])
+  else:  # TargetMode.SYSTEM_WIDE
+    command_line.append("-a")
+  if call_graph_mode == CallGraphMode.FRAME_POINTER:
+    command_line.extend(["--call-graph", "fp"])
+  elif call_graph_mode == CallGraphMode.DWARF:
+    # Use "--post-unwind=yes" while unwinding with DWARF, to reduce
+    # unwinding overhead during profiling.
+    command_line.extend(["--call-graph", "dwarf", "--post-unwind=yes"])
+  else:
+    assert call_graph_mode == CallGraphMode.NO_CALL_GRAPH, (
+        f"Invalid call_graph_mode: {call_graph_mode}")
+  if frequency is not None:
+    command_line.extend(["-f", str(frequency)])
+  if count is not None:
+    command_line.extend(["-c", str(count)])
+  if cpus:
+    command_line.extend(["--cpu", ",".join(map(str, cpus))])
+  # Events and counters need to be provided after `-f` and `-c`.
+  if events:
+    command_line.extend(["-e", ",".join(events)])
+  if grouped_events:
+    command_line.extend(["--group", ",".join(grouped_events)])
+  if add_counters:
+    command_line.extend(["--add-counter", ",".join(add_counters)])
+    # `--no-inherit` is required by simpleperf when `--add-counter` is used.
+    command_line.append("--no-inherit")
+  command_line.extend(["-o", output_path])
+  return command_line
diff --git a/crossbench/probes/profiling/context/base.py b/crossbench/probes/profiling/context/base.py
new file mode 100644
index 00000000..22f590b6
--- /dev/null
+++ b/crossbench/probes/profiling/context/base.py
@@ -0,0 +1,73 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import abc
+import logging
+import subprocess
+from functools import cached_property
+from typing import TYPE_CHECKING, Tuple, cast
+
+from typing_extensions import override
+
+from crossbench.plt.posix import PosixPlatform
+from crossbench.probes.probe_context import ProbeContext
+from crossbench.probes.v8.log import V8LogProbe
+
+if TYPE_CHECKING:
+  from crossbench.probes.profiling.system_profiling import ProfilingProbe
+  from crossbench.runner.run import Run
+
+
+class ProfilingContext(ProbeContext, metaclass=abc.ABCMeta):
+
+  def __init__(self, probe: ProfilingProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    self._profiling_process: subprocess.Popen | None = None
+    self._story_ready = False
+
+  def setup_v8_log_path(self) -> None:
+    if any(isinstance(probe, V8LogProbe) for probe in self.run.probes):
+      return
+    # Try to get a bit a cleaner output folder by redirecting v8 logging output
+    # to v8.log.
+    v8_log_dir = self.result_path.parent / V8LogProbe.NAME / "v8.log"
+    self.browser_platform.mkdir(v8_log_dir)
+    self.session.extra_js_flags["--logfile"] = str(v8_log_dir)
+
+  @override
+  def start_story_run(self) -> None:
+    self._story_ready = True
+
+  @cached_property
+  def renderer_pid_tid(self) -> Tuple[int, int]:
+    assert self._story_ready, (
+        "Fetching renderer PID/TID before the story is loaded could lead to "
+        "the wrong PID/TID being used. This should never happen TM!")
+    renderer_pid: int | None = None
+    renderer_main_tid: int | None = None
+    with self.run.actions("Get Renderer PID/TID") as actions:
+      renderer_pid = actions.js(
+          "return chrome?.benchmarking?.getRendererPid?.();")
+      renderer_main_tid = actions.js(
+          "return chrome?.benchmarking?.getRendererMainTid?.();")
+    if renderer_pid is None or renderer_main_tid is None:
+      error_message = (
+          "Unable to get Renderer PID/TID from browser. "
+          "Is the browser binary a sufficiently new version? "
+          "For RENDERER_MAIN_ONLY/RENDERER_PROCESS_ONLY profiling, at least "
+          "https://chromium-review.googlesource.com/c/chromium/src/+/5374765 "
+          "is required.")
+      logging.error(error_message)
+      raise ValueError(error_message)
+    return renderer_pid, renderer_main_tid
+
+
+class PosixProfilingContext(ProfilingContext):
+
+  @property
+  @override
+  def browser_platform(self) -> PosixPlatform:
+    return cast(PosixPlatform, super().browser_platform)
diff --git a/crossbench/probes/profiling/context/linux.py b/crossbench/probes/profiling/context/linux.py
new file mode 100644
index 00000000..fe409817
--- /dev/null
+++ b/crossbench/probes/profiling/context/linux.py
@@ -0,0 +1,271 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import json
+import logging
+import multiprocessing
+import time
+from typing import TYPE_CHECKING, Dict, List, Optional
+
+from typing_extensions import override
+
+from crossbench import plt
+from crossbench.browsers.chromium.version import ChromiumVersion
+from crossbench.helper import fs_helper
+from crossbench.helper.spinner import Spinner
+from crossbench.probes.profiling.context.base import PosixProfilingContext
+from crossbench.probes.profiling.enum import CleanupMode
+
+if TYPE_CHECKING:
+  import crossbench.path as pth
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+
+V8_PERF_PROF_PATH_FLAG_MIN_VERSION = ChromiumVersion((118, 0, 5993, 48))
+PERF_DATA_PATTERN = "*.perf.data"
+JIT_DUMP_PATTERN = "jit-*.dump"
+
+
+class LinuxProfilingContext(PosixProfilingContext):
+  TEMP_FILE_PATTERNS = (
+      "*.perf.data.jitted",
+      "jitted-*.so",
+      JIT_DUMP_PATTERN,
+  )
+
+  @override
+  def get_default_result_path(self) -> pth.AnyPath:
+    result_dir = super().get_default_result_path()
+    self.browser_platform.mkdir(result_dir)
+    return result_dir
+
+  @property
+  def has_perf_prof_path(self) -> bool:
+    return self.browser.version > V8_PERF_PROF_PATH_FLAG_MIN_VERSION
+
+  @override
+  def setup(self) -> None:
+    self.setup_v8_log_path()
+    if self.has_perf_prof_path:
+      self.session.extra_js_flags["--perf-prof-path"] = str(self.result_path)
+
+  def start(self) -> None:
+    if not self.probe.sample_browser_process:
+      return
+    if self.run.browser.pid is None:
+      logging.warning("Cannot sample browser process")
+      return
+    perf_data_file: pth.AnyPath = self.result_path / "browser.perf.data"
+    # TODO: not fully working yet
+    self._profiling_process = self.browser_platform.popen(
+        "perf", "record", f"--call-graph={self.probe.call_graph_mode or 'fp'}",
+        f"--freq={self.probe.frequency or 'max'}",
+        f"--clockid={self.probe.clockid or 'mono'}",
+        f"--output={perf_data_file}", f"--pid={self.run.browser.pid}")
+    if self._profiling_process.poll():
+      raise ValueError("Could not start linux profiler")
+    atexit.register(self.stop_process)
+
+  def stop(self) -> None:
+    self.stop_process()
+
+  def stop_process(self) -> None:
+    if self._profiling_process:
+      self.browser_platform.terminate_gracefully(self._profiling_process)
+      self._profiling_process = None
+
+  def teardown(self) -> ProbeResult:
+    # Waiting for linux-perf to flush all perf data
+    if self.probe.sample_browser_process:
+      logging.debug("Waiting for browser process to stop")
+      time.sleep(3)
+    if self.probe.sample_browser_process:
+      logging.info("Browser process did not stop after 3s. "
+                   "You might get partial profiles")
+    time.sleep(2)
+
+    perf_files: List[pth.AnyPath] = fs_helper.sort_by_file_size(
+        list(self.browser_platform.glob(self.result_path, PERF_DATA_PATTERN)),
+        self.browser_platform)
+    raw_perf_files = perf_files
+    urls: List[str] = []
+    try:
+      if self.probe.sample_js:
+        perf_files = self._inject_v8_symbols(self.run, perf_files)
+      if self.probe.run_pprof:
+        urls = self._export_to_pprof(self.run, perf_files)
+    finally:
+      self._clean_up_temp_files(self.run)
+    if self.probe.run_pprof:
+      logging.debug("Profiling results: %s", urls)
+      return self.browser_result(url=urls, file=raw_perf_files)
+    if self.browser_platform.which("pprof"):
+      logging.info("Run pprof over all (or single) perf data files "
+                   "for interactive analysis:")
+      logging.info("   pprof --http=localhost:1984 %s",
+                   " ".join(map(str, perf_files)))
+    return self.browser_result(trace=perf_files)
+
+  def _inject_v8_symbols(self, run: Run,
+                         perf_files: List[pth.AnyPath]) -> List[pth.AnyPath]:
+    with run.actions(
+        f"Probe {self.probe.name}: "
+        f"Injecting V8 symbols into {len(perf_files)} profiles",
+        verbose=True), Spinner():
+      # Filter out empty files
+      perf_files = [
+          file for file in perf_files
+          if self.browser_platform.file_size(file) > 0
+      ]
+      if self.browser_platform.is_remote:
+        # Use loop, as we cannot easily serialize the remote platform.
+        perf_jitted_files = [
+            linux_perf_probe_inject_v8_symbols(file, self.browser_platform)
+            for file in perf_files
+        ]
+      else:
+        assert self.browser_platform == plt.PLATFORM
+        with multiprocessing.Pool() as pool:
+          perf_jitted_files = list(
+              pool.imap(linux_perf_probe_inject_v8_symbols, perf_files))
+      return [file for file in perf_jitted_files if file is not None]
+
+  def _export_to_pprof(self, run: Run,
+                       perf_files: List[pth.AnyPath]) -> List[str]:
+    assert self.probe.run_pprof
+    run_details_json = json.dumps(run.get_browser_details_json())
+    with run.actions(
+        f"Probe {self.probe.name}: "
+        f"exporting {len(perf_files)} profiles to pprof (slow)",
+        verbose=True), Spinner():
+      self.browser_platform.sh(
+          "gcertstatus >&/dev/null || "
+          "(echo 'Authenticating with gcert:'; gcert)",
+          shell=True)
+      size = len(perf_files)
+      items = zip(perf_files, [run_details_json] * size)
+      urls: List[str] = []
+      if self.browser_platform.is_remote:
+        # Use loop, as we cannot easily serialize the remote platform.
+        for perf_data_file, run_details in items:
+          url = linux_perf_probe_pprof(perf_data_file, run_details,
+                                       self.browser_platform)
+          if url:
+            urls.append(url)
+      else:
+        assert self.browser_platform == plt.PLATFORM
+        with multiprocessing.Pool() as pool:
+          urls = [
+              url for url in pool.starmap(linux_perf_probe_pprof, items) if url
+          ]
+      try:
+        if perf_files:
+          # TODO: Add "combined" profile again
+          pass
+      except Exception as e:  # pylint: disable=broad-except
+        logging.debug("Failed to run pprof: %s", e)
+      return urls
+
+  def _clean_up_temp_files(self, run: Run) -> None:
+    if self.probe.cleanup_mode == CleanupMode.NEVER:
+      logging.debug("%s: skipping cleanup", self.probe)
+      return
+    if self.probe.cleanup_mode == CleanupMode.AUTO:
+      if not self.probe.run_pprof:
+        logging.debug("%s: skipping auto cleanup without pprof upload",
+                      self.probe)
+        return
+    for pattern in self.TEMP_FILE_PATTERNS:
+      for file in run.out_dir.glob(pattern):
+        file.unlink()
+
+
+def prepare_linux_perf_env(platform: plt.Platform,
+                           cwd: pth.AnyPath) -> Dict[str, str]:
+  env: Dict[str, str] = dict(platform.environ)
+  env["JITDUMPDIR"] = str(platform.absolute(cwd))
+  return env
+
+
+KB = 1024
+
+
+def linux_perf_probe_inject_v8_symbols(
+    perf_data_file: pth.AnyPath,
+    platform: Optional[plt.Platform] = None) -> Optional[pth.AnyPath]:
+  platform = platform or plt.PLATFORM
+  assert platform.is_file(perf_data_file)
+  output_file = perf_data_file.with_suffix(".data.jitted")
+  assert not platform.exists(output_file)
+  env = prepare_linux_perf_env(platform, perf_data_file.parent)
+  try:
+    # TODO: use remote chdir
+    platform.sh(
+        "perf",
+        "inject",
+        "--jit",
+        f"--input={perf_data_file}",
+        f"--output={output_file}",
+        env=env)
+  except plt.SubprocessError as e:
+    if platform.file_size(perf_data_file) > 200 * KB:
+      logging.warning("Failed processing: %s\n%s", perf_data_file, e)
+    else:
+      # TODO: investigate why almost all small perf.data files fail
+      logging.debug("Failed processing small profile (likely empty): %s\n%s",
+                    perf_data_file, e)
+  if not platform.exists(output_file):
+    return None
+  return output_file
+
+
+def linux_perf_probe_pprof(
+    perf_data_file: pth.AnyPath,
+    run_details: str,
+    platform: Optional[plt.Platform] = None) -> Optional[str]:
+  platform = platform or plt.PLATFORM
+  size = fs_helper.get_file_size(perf_data_file, platform=platform)
+  env = prepare_linux_perf_env(platform, perf_data_file.parent)
+  url = ""
+  try:
+    url = platform.sh_stdout(
+        "pprof",
+        "-flame",
+        f"-add_comment={run_details}",
+        perf_data_file,
+        env=env,
+    ).strip()
+  except plt.SubprocessError as e:
+    # Occasionally small .jitted files fail, likely due perf inject silently
+    # failing?
+    raw_perf_data_file = perf_data_file.with_suffix("")
+    if (perf_data_file.suffix == ".jitted" and
+        platform.exists(raw_perf_data_file)):
+      logging.debug(
+          "pprof best-effort: falling back to standard perf data "
+          "without js symbols: %s \n"
+          "Got failures for %s: %s", raw_perf_data_file, perf_data_file.name, e)
+      try:
+        perf_data_file = raw_perf_data_file
+        url = platform.sh_stdout(
+            "pprof",
+            "-flame",
+            f"-add_comment={run_details}",
+            raw_perf_data_file,
+        ).strip()
+      except plt.SubprocessError as e2:
+        logging.debug("pprof -flame failed: %s", e2)
+    if not url:
+      logging.warning("Failed processing: %s\n%s", perf_data_file, e)
+      return None
+  if perf_data_file.suffix == ".jitted":
+    logging.info("PPROF (with js-symbols):")
+  else:
+    logging.info("PPROF (no js-symbols):")
+  logging.info("  linux-perf:   %s %s", perf_data_file.name, size)
+  logging.info("  pprof result: %s", url)
+  return url
diff --git a/crossbench/probes/profiling/context/macos.py b/crossbench/probes/profiling/context/macos.py
new file mode 100644
index 00000000..4b99e101
--- /dev/null
+++ b/crossbench/probes/profiling/context/macos.py
@@ -0,0 +1,107 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import atexit
+import logging
+import time
+from typing import TYPE_CHECKING, Final, Optional
+
+from typing_extensions import override
+
+import crossbench.path as pth
+from crossbench.helper.spinner import Spinner
+from crossbench.probes.profiling.context.base import PosixProfilingContext
+from crossbench.probes.profiling.enum import TargetMode
+
+if TYPE_CHECKING:
+  from crossbench.probes.profiling.system_profiling import ProfilingProbe
+  from crossbench.probes.results import ProbeResult
+  from crossbench.runner.run import Run
+
+
+_MAC_TRACE_TEMPLATE_PATH: Final[pth.LocalPath] = pth.LocalPath(
+    __file__).parents[1] / "time-profile.tracetemplate"
+
+_XPATH_EXPRESSION: Final[str] = (
+    "//trace-toc/run/data/table["
+    "@category=\"PointsOfInterest\" and @schema=\"os-signpost\"]|"
+    "//trace-toc/run/data/table[@schema=\"cpu-profile\"]")
+
+
+class MacOSProfilingContext(PosixProfilingContext):
+
+  def __init__(self, probe: ProfilingProbe, run: Run) -> None:
+    super().__init__(probe, run)
+    assert self.probe.target in (
+        TargetMode.SYSTEM_WIDE, TargetMode.RENDERER_PROCESS_ONLY), (
+            f"Unsupported profiling mode for Mac: {str(self.probe.target)}")
+
+  @override
+  def get_default_result_path(self) -> pth.AnyPath:
+    return super().get_default_result_path().parent / "profile.trace"
+
+  def _start_xctrace(self, pid: Optional[int] = None) -> None:
+    assert self.browser_platform.is_file(_MAC_TRACE_TEMPLATE_PATH), (
+        f"Didn't find {_MAC_TRACE_TEMPLATE_PATH}")
+
+    atexit.register(self.stop_process)
+
+    process_filter = ["--all-processes"
+                     ] if pid is None else ["--attach", str(pid)]
+    self._profiling_process = self.browser_platform.popen(
+        "xctrace", "record", "--template", _MAC_TRACE_TEMPLATE_PATH,
+        *process_filter, "--output", self.result_path)
+    # xctrace takes some time to start up
+    time.sleep(3)
+    if self._profiling_process.poll():
+      raise ValueError("Could not start xctrace")
+
+  def start(self) -> None:
+    pass
+
+  @override
+  def start_story_run(self) -> None:
+    super().start_story_run()
+    # In theory this could start earlier but we leave it here as the
+    # renderer-process mode requires us to run when we are guaranteed
+    # to have a renderer available.
+    if self.probe.target == TargetMode.SYSTEM_WIDE:
+      self._start_xctrace()
+    elif self.probe.target == TargetMode.RENDERER_PROCESS_ONLY:
+      self._start_xctrace(self.renderer_pid_tid[0])
+
+  def stop(self) -> None:
+    # Needs to be SIGINT for xctrace, terminate won't work.
+    assert self._profiling_process
+    self.browser_platform.send_signal(self._profiling_process,
+                                      self.browser_platform.signals.SIGINT)
+
+  def teardown(self) -> ProbeResult:
+    self.stop_process()
+    trace_xml_path = self._export_trace_xml()
+    return self.browser_result(file=(self.result_path,), xml=(trace_xml_path,))
+
+  def _export_trace_xml(self) -> pth.AnyPath:
+    trace_xml_path = self.result_path.with_name("profile.trace.xml")
+    with self.run.actions(
+        f"Probe {self.probe.name}: Exporting {trace_xml_path.name}",
+        verbose=True), Spinner():
+      self.browser_platform.sh("xctrace", "export", "--input", self.result_path,
+                               "--output", trace_xml_path, "--xpath",
+                               _XPATH_EXPRESSION)
+      return trace_xml_path
+
+  def stop_process(self) -> None:
+    if not self._profiling_process:
+      return
+    logging.info("  Waiting for xctrace profiles (slow)...")
+    with Spinner():
+      self.browser_platform.terminate_gracefully(
+          self._profiling_process,
+          signal=self.browser_platform.signals.SIGINT,
+          timeout=60)
+    self._profiling_process = None
+    atexit.unregister(self.stop_process)
diff --git a/crossbench/probes/profiling/enum.py b/crossbench/probes/profiling/enum.py
new file mode 100644
index 00000000..95879782
--- /dev/null
+++ b/crossbench/probes/profiling/enum.py
@@ -0,0 +1,47 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+from typing import Optional
+
+from crossbench.str_enum_with_help import StrEnumWithHelp
+
+
+@enum.unique
+class CleanupMode(StrEnumWithHelp):
+
+  @classmethod
+  def _missing_(cls, value) -> Optional[CleanupMode]:
+    if value is True:
+      return CleanupMode.ALWAYS
+    if value is False:
+      return CleanupMode.NEVER
+    return super()._missing_(value)
+
+  ALWAYS = ("always", "Always clean up temp files")
+  AUTO = ("auto", "Best-guess auto-cleanup")
+  NEVER = ("never", "Always clean up temp files")
+
+
+@enum.unique
+class TargetMode(StrEnumWithHelp):
+  RENDERER_MAIN_ONLY = ("renderer_main_only",
+                        "Profile Renderer Main thread only")
+  RENDERER_PROCESS_ONLY = ("renderer_process_only",
+                           "Profile Renderer process only")
+  BROWSER_APP_ONLY = ("browser_app_only",
+                      "Profile all processes of the Browser App only")
+  SYSTEM_WIDE = ("system_wide", "Run system-wide profiling")
+
+
+@enum.unique
+class CallGraphMode(StrEnumWithHelp):
+  # Refer to the documentation below for more details and comparison
+  # between these options:
+  # https://android.googlesource.com/platform/system/extras/+/master/simpleperf/doc/README.md.
+  NO_CALL_GRAPH = ("no_call_graph", "Do not record a call graph")
+  DWARF = ("dwarf", "Run DWARF-based unwinding unwinding")
+  FRAME_POINTER = ("fp", "Run frame pointer unwinding")
diff --git a/crossbench/probes/profiling/system_profiling.py b/crossbench/probes/profiling/system_profiling.py
index 40b0194f..00887a9f 100644
--- a/crossbench/probes/profiling/system_profiling.py
+++ b/crossbench/probes/profiling/system_profiling.py
@@ -4,87 +4,42 @@
 
 from __future__ import annotations
 
-import abc
-import atexit
-import enum
-import io
-import json
 import logging
-import multiprocessing
 import shlex
-import signal
-import subprocess
-import time
-from functools import cached_property
-from typing import (TYPE_CHECKING, Any, Dict, Final, Iterable, List, Optional,
-                    Sequence, Tuple, Union, cast)
+from typing import (TYPE_CHECKING, Any, Final, Iterable, Optional, Self,
+                    Sequence, Tuple, cast)
+
+from typing_extensions import override
 
-from crossbench import helper
 from crossbench import path as pth
 from crossbench import plt
-from crossbench.browsers.attributes import BrowserAttributes
-from crossbench.browsers.chrome.version import ChromeVersion
-from crossbench.browsers.chromium.chromium import Chromium
-from crossbench.compat import StrEnumWithHelp
+from crossbench.browsers.chromium_based.chromium_based import ChromiumBased
+from crossbench.helper import fs_helper
 from crossbench.parse import NumberParser, ObjectParser
-from crossbench.plt.base import ListCmdArgs
-from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
+from crossbench.probes.probe import (Probe, ProbeConfigParser,
                                      ProbeIncompatibleBrowser, ProbeKeyT)
+from crossbench.probes.profiling.context.android import AndroidProfilingContext
+from crossbench.probes.profiling.context.linux import LinuxProfilingContext
+from crossbench.probes.profiling.context.macos import MacOSProfilingContext
+from crossbench.probes.profiling.enum import (CallGraphMode, CleanupMode,
+                                              TargetMode)
 from crossbench.probes.result_location import ResultLocation
-from crossbench.probes.v8.log import V8LogProbe
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.env import HostEnvironment
-  from crossbench.probes.results import ProbeResult
+  from crossbench.probes.profiling.context.base import ProfilingContext
   from crossbench.runner.groups.browsers import BrowsersRunGroup
   from crossbench.runner.run import Run
 
 
-@enum.unique
-class CleanupMode(StrEnumWithHelp):
-
-  @classmethod
-  def _missing_(cls, value) -> Optional[CleanupMode]:
-    if value is True:
-      return CleanupMode.ALWAYS
-    if value is False:
-      return CleanupMode.NEVER
-    return super()._missing_(value)
-
-  ALWAYS = ("always", "Always clean up temp files")
-  AUTO = ("auto", "Best-guess auto-cleanup")
-  NEVER = ("never", "Always clean up temp files")
-
-
-@enum.unique
-class TargetMode(StrEnumWithHelp):
-  RENDERER_MAIN_ONLY = ("renderer_main_only",
-                        "Profile Renderer Main thread only")
-  RENDERER_PROCESS_ONLY = ("renderer_process_only",
-                           "Profile Renderer process only")
-  BROWSER_APP_ONLY = ("browser_app_only",
-                      "Profile all processes of the Browser App only")
-  SYSTEM_WIDE = ("system_wide", "Run system-wide profiling")
-
-
-@enum.unique
-class CallGraphMode(StrEnumWithHelp):
-  # Refer to the documentation below for more details and comparison
-  # between these options:
-  # https://android.googlesource.com/platform/system/extras/+/master/simpleperf/doc/README.md.
-  NO_CALL_GRAPH = ("no_call_graph", "Do not record a call graph")
-  DWARF = ("dwarf", "Run DWARF-based unwinding unwinding")
-  FRAME_POINTER = ("frame_pointer", "Run frame pointer unwinding")
-
-
 V8_INTERPRETED_FRAMES_FLAG = "--interpreted-frames-native-stack"
 
 RENDERER_CMD_PATH: Final[pth.LocalPath] = pth.LocalPath(
     __file__).parent / "linux-perf-chrome-renderer-cmd.sh"
 
 
-def perf_frequency(value: Any) -> Union[str, int]:
+def perf_frequency(value: Any) -> str | int:
   if value == "max":
     return "max"
   return NumberParser.positive_int(value, "frequency")
@@ -108,7 +63,8 @@ class ProfilingProbe(Probe):
   IS_GENERAL_PURPOSE = True
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "js",
@@ -156,7 +112,7 @@ class ProfilingProbe(Probe):
         "target",
         type=TargetMode,
         default=TargetMode.BROWSER_APP_ONLY,
-        help=("Chrome-on-Android-only: "
+        help=("Chrome-on-Android/Chrome-on-Mac: "
               "Profile either Renderer main/process only, "
               "or all processes of the Browser App, or system-wide. "
               "If Renderer main/process profiling is selected, "
@@ -240,23 +196,25 @@ class ProfilingProbe(Probe):
               "details."))
     return parser
 
-  def __init__(self,
-               js: bool = True,
-               v8_interpreted_frames: bool = True,
-               pprof: bool = True,
-               cleanup: CleanupMode = CleanupMode.AUTO,
-               browser_process: bool = False,
-               spare_renderer_process: bool = False,
-               target: TargetMode = TargetMode.BROWSER_APP_ONLY,
-               pin_renderer_main_core: Optional[int] = None,
-               call_graph_mode: CallGraphMode = CallGraphMode.FRAME_POINTER,
-               frequency: Optional[Union[int, str]] = None,
-               clockid: Optional[str] = None,
-               count: Optional[int] = None,
-               cpu: Sequence[int] = (),
-               events: Sequence[str] = (),
-               grouped_events: Sequence[str] = (),
-               add_counters: Sequence[str] = ()):
+  def __init__(
+      self,
+      js: bool = True,
+      v8_interpreted_frames: bool = True,
+      pprof: bool = True,
+      cleanup: CleanupMode = CleanupMode.AUTO,
+      browser_process: bool = False,
+      spare_renderer_process: bool = False,
+      target: TargetMode = TargetMode.BROWSER_APP_ONLY,
+      pin_renderer_main_core: Optional[int] = None,
+      call_graph_mode: CallGraphMode = CallGraphMode.FRAME_POINTER,
+      frequency: Optional[int | str] = None,
+      clockid: Optional[str] = None,
+      count: Optional[int] = None,
+      cpu: Sequence[int] = (),
+      events: Sequence[str] = (),
+      grouped_events: Sequence[str] = (),
+      add_counters: Sequence[str] = ()
+  ) -> None:
     super().__init__()
     self._sample_js: bool = js
     self._sample_browser_process: bool = browser_process
@@ -267,20 +225,21 @@ class ProfilingProbe(Probe):
     if v8_interpreted_frames:
       assert js, "Cannot expose V8 interpreted frames without js profiling."
     self._target: TargetMode = target
-    self._pin_renderer_main_core: Optional[int] = pin_renderer_main_core
+    self._pin_renderer_main_core: int | None = pin_renderer_main_core
     self._call_graph_mode: CallGraphMode = call_graph_mode
     self._start_profiling_after_setup: bool = target in (
         TargetMode.RENDERER_MAIN_ONLY,
         TargetMode.RENDERER_PROCESS_ONLY) or pin_renderer_main_core is not None
-    self._frequency: Optional[Union[int, str]] = frequency
-    self._clockid: Optional[str] = clockid
-    self._count: Optional[int] = count
+    self._frequency: int | str | None = frequency
+    self._clockid: str | None = clockid
+    self._count: int | None = count
     self._cpu: Tuple[int, ...] = tuple(cpu)
     self._events: Tuple[str, ...] = tuple(events)
     self._grouped_events: Tuple[str, ...] = tuple(grouped_events)
     self._add_counters: Tuple[str, ...] = tuple(add_counters)
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("js", self._sample_js),
@@ -334,7 +293,7 @@ class ProfilingProbe(Probe):
     return self._start_profiling_after_setup
 
   @property
-  def frequency(self) -> Optional[Union[int, str]]:
+  def frequency(self) -> Optional[int | str]:
     return self._frequency
 
   @property
@@ -361,17 +320,7 @@ class ProfilingProbe(Probe):
   def add_counters(self) -> Tuple[str, ...]:
     return self._add_counters
 
-  def attach(self, browser: Browser) -> None:
-    super().attach(browser)
-    if browser.platform.is_linux or browser.platform.is_android:
-      assert browser.attributes.is_chromium_based, (
-          f"Expected Chromium-based browser, found {type(browser)}.")
-    if browser.attributes.is_chromium_based:
-      chromium = cast(Chromium, browser)
-      if not self._spare_renderer_process:
-        chromium.features.disable("SpareRendererForSitePerProcess")
-      self._attach(chromium)
-
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     browser_platform = browser.platform
     if browser_platform.is_linux:
@@ -382,6 +331,9 @@ class ProfilingProbe(Probe):
       self._validate_android(env, browser)
     else:
       raise ProbeIncompatibleBrowser(self, browser)
+    if browser.attributes().is_chromium_based:
+      chromium = cast(ChromiumBased, browser)
+      self._validate_chromium_based(chromium)
     if self.run_pprof:
       self._validate_pprof(env, browser)
     # Check that certain Android-only options are
@@ -391,6 +343,10 @@ class ProfilingProbe(Probe):
     if not browser_platform.is_android:
       self._validate_non_android_perf_settings(browser)
 
+  def _validate_chromium_based(self, browser: ChromiumBased) -> None:
+    if self._start_profiling_after_setup:
+      self._validate_benchmarking_extension_version(browser)
+
   def _validate_perf_settings(self, browser) -> None:
     unsupported_settings = (
         ("frequency", self._frequency),
@@ -431,24 +387,24 @@ class ProfilingProbe(Probe):
       env.handle_warning(f"Probe={self.NAME} cannot merge data over multiple "
                          f"repetitions={env.repetitions}.")
 
-  def _assert_is_chrome_with_extension(self, browser: Browser) -> None:
-    assert (
-        BrowserAttributes.CHROME in browser.attributes and
-        browser.major_version >= 124), (
-            "For RENDERER_MAIN_ONLY/RENDERER_PROCESS_ONLY profiling, "
-            "browser version >= M124 https://crrev.com/c/5374765 is required.")
-
-  def _requires_chrome_with_extension(self) -> bool:
-    return self._target in (TargetMode.RENDERER_MAIN_ONLY,
-                            TargetMode.RENDERER_PROCESS_ONLY
-                           ) or self._pin_renderer_main_core is not None
+    supported_mac_targets = (TargetMode.SYSTEM_WIDE,
+                             TargetMode.RENDERER_PROCESS_ONLY)
+    assert self._target in supported_mac_targets, (
+        f"Unsupported profile target for Mac: {self._target}. "
+        f"Should be one of {str(supported_mac_targets)}.")
 
   def _validate_android(self, env: HostEnvironment, browser: Browser) -> None:
     del env
-    if self._requires_chrome_with_extension():
-      self._assert_is_chrome_with_extension(browser)
     assert browser.platform.which("simpleperf"), "simpleperf is not available"
 
+  def _validate_benchmarking_extension_version(self,
+                                               browser: ChromiumBased) -> None:
+    assert (
+        browser.attributes().is_chromium_based and
+        browser.version.major >= 124), (
+            "For RENDERER_MAIN_ONLY/RENDERER_PROCESS_ONLY profiling, "
+            "browser version >= M124 https://crrev.com/c/5374765 is required.")
+
   def _validate_pprof(self, env: HostEnvironment, browser: Browser) -> None:
     assert self._run_pprof
     host_platform = browser.host_platform
@@ -461,14 +417,28 @@ class ProfilingProbe(Probe):
       # Converting xctrace to pprof is not supported on macos
       return
     try:
-      if gcertstatus := browser.platform.which("gcertstatus"):
-        browser.platform.sh(gcertstatus)
+      if gcertstatus := host_platform.which("gcertstatus"):
+        host_platform.sh(gcertstatus)
         return
       env.handle_warning("Could not find gcertstatus")
     except plt.SubprocessError:
       env.handle_warning("Please run gcert for generating pprof results")
 
-  def _attach(self, browser: Chromium) -> None:
+  @override
+  def attach(self, browser: Browser) -> None:
+    super().attach(browser)
+    if browser.platform.is_linux or browser.platform.is_android:
+      assert browser.attributes().is_chromium_based, (
+          f"Expected Chromium-based browser, found {type(browser)}.")
+    if browser.attributes().is_chromium_based:
+      chromium = cast(ChromiumBased, browser)
+      self._attach_chromium(chromium)
+
+  def _attach_chromium(self, browser: ChromiumBased) -> None:
+    if not self._spare_renderer_process:
+      browser.features.disable("SpareRendererForSitePerProcess")
+    if self._start_profiling_after_setup:
+      browser.flags.enable_benchmarking_extension()
     if self._sample_js:
       if browser.platform.is_linux:
         browser.js_flags.set("--perf-prof")
@@ -479,7 +449,7 @@ class ProfilingProbe(Probe):
     # Disable sandbox to write profiling data
     browser.flags.set("--no-sandbox")
 
-  def _set_renderer_cmd_prefix(self, browser):
+  def _set_renderer_cmd_prefix(self, browser) -> None:
     assert not browser.platform.is_remote, (
         "Copying renderer command prefix to remote platform is "
         "not implemented yet")
@@ -504,9 +474,11 @@ class ProfilingProbe(Probe):
       cmd_prefix.append(f"--perf-args={shlex.join(custom_perf_args)}")
     browser.flags["--renderer-cmd-prefix"] = shlex.join(cmd_prefix)
 
+  @override
   def log_run_result(self, run: Run) -> None:
     self._log_results([run])
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     self._log_results(group.runs)
 
@@ -521,7 +493,7 @@ class ProfilingProbe(Probe):
     for i, run in enumerate(filtered_runs):
       self._log_run_result_summary(run, i)
 
-  def _log_results_overview(self, filtered_runs):
+  def _log_results_overview(self, filtered_runs) -> None:
     if len(filtered_runs) <= 1:
       return
     if any(run.browser_platform.is_macos for run in filtered_runs):
@@ -544,7 +516,7 @@ class ProfilingProbe(Probe):
       return
     largest_perf_file = perf_files[-1]
     logging.critical("    %s : %s", largest_perf_file,
-                     helper.get_file_size(largest_perf_file))
+                     fs_helper.get_file_size(largest_perf_file))
     if len(perf_files) <= 1:
       return
     glob = "*.perf.data"
@@ -561,487 +533,3 @@ class ProfilingProbe(Probe):
     if run.browser_platform.is_android:
       return AndroidProfilingContext(self, run)
     raise NotImplementedError("Invalid platform")
-
-
-class ProfilingContext(ProbeContext[ProfilingProbe], metaclass=abc.ABCMeta):
-
-  def setup_v8_log_path(self) -> None:
-    if any(isinstance(probe, V8LogProbe) for probe in self.run.probes):
-      return
-    # Try to get a bit a cleaner output folder by redirecting v8 logging output
-    # to v8.log.
-    v8_log_dir = self.result_path.parent / V8LogProbe.NAME / "v8.log"
-    self.browser_platform.mkdir(v8_log_dir)
-    self.session.extra_js_flags["--logfile"] = str(v8_log_dir)
-
-
-class MacOSProfilingContext(ProfilingContext):
-  _process: Optional[subprocess.Popen]
-
-  def get_default_result_path(self) -> pth.AnyPath:
-    return super().get_default_result_path().parent / "profile.trace"
-
-  def start(self) -> None:
-    self._process = self.browser_platform.popen("xctrace", "record",
-                                                "--template", "Time Profiler",
-                                                "--all-processes", "--output",
-                                                self.result_path)
-    # xctrace takes some time to start up
-    time.sleep(3)
-    if self._process.poll():
-      raise ValueError("Could not start xctrace")
-    atexit.register(self.stop_process)
-
-  def stop(self) -> None:
-    # Needs to be SIGINT for xctrace, terminate won't work.
-    assert self._process
-    self._process.send_signal(signal.SIGINT)
-
-  def teardown(self) -> ProbeResult:
-    self.stop_process()
-    return self.browser_result(file=(self.result_path,))
-
-  def stop_process(self) -> None:
-    if self._process:
-      logging.info("  Waiting for xctrace profiles (slow)...")
-      with helper.Spinner():
-        helper.wait_and_kill(self._process, signal=signal.SIGINT, timeout=60)
-      self._process = None
-    atexit.unregister(self.stop_process)
-
-
-V8_PERF_PROF_PATH_FLAG_MIN_VERSION = ChromeVersion((118, 0, 5993, 48))
-PERF_DATA_PATTERN = "*.perf.data"
-JIT_DUMP_PATTERN = "jit-*.dump"
-
-
-class LinuxProfilingContext(ProfilingContext):
-  TEMP_FILE_PATTERNS = (
-      "*.perf.data.jitted",
-      "jitted-*.so",
-      JIT_DUMP_PATTERN,
-  )
-
-  def __init__(self, probe: ProfilingProbe, run: Run) -> None:
-    super().__init__(probe, run)
-    self._perf_process: Optional[subprocess.Popen] = None
-
-  def get_default_result_path(self) -> pth.AnyPath:
-    result_dir = super().get_default_result_path()
-    self.browser_platform.mkdir(result_dir)
-    return result_dir
-
-  @property
-  def has_perf_prof_path(self) -> bool:
-    # TODO: replace with full version comparison
-    return self.browser.major_version > V8_PERF_PROF_PATH_FLAG_MIN_VERSION.major
-
-  def setup(self) -> None:
-    self.setup_v8_log_path()
-    if self.has_perf_prof_path:
-      self.session.extra_js_flags["--perf-prof-path"] = str(self.result_path)
-
-  def start(self) -> None:
-    if not self.probe.sample_browser_process:
-      return
-    if self.run.browser.pid is None:
-      logging.warning("Cannot sample browser process")
-      return
-    perf_data_file: pth.AnyPath = self.result_path / "browser.perf.data"
-    # TODO: not fully working yet
-    self._perf_process = self.browser_platform.popen(
-        "perf", "record", f"--call-graph={self.probe.call_graph_mode or 'fp'}",
-        f"--freq={self.probe.frequency or 'max'}",
-        f"--clockid={self.probe.clockid or 'mono'}",
-        f"--output={perf_data_file}", f"--pid={self.run.browser.pid}")
-    if self._perf_process.poll():
-      raise ValueError("Could not start linux profiler")
-    atexit.register(self.stop_process)
-
-  def stop(self) -> None:
-    self.stop_process()
-
-  def stop_process(self) -> None:
-    if self._perf_process:
-      helper.wait_and_kill(self._perf_process)
-      self._perf_process = None
-
-  def teardown(self) -> ProbeResult:
-    # Waiting for linux-perf to flush all perf data
-    if self.probe.sample_browser_process:
-      logging.debug("Waiting for browser process to stop")
-      time.sleep(3)
-    if self.probe.sample_browser_process:
-      logging.info("Browser process did not stop after 3s. "
-                   "You might get partial profiles")
-    time.sleep(2)
-
-    perf_files: List[pth.AnyPath] = helper.sort_by_file_size(
-        list(self.browser_platform.glob(self.result_path, PERF_DATA_PATTERN)),
-        self.browser_platform)
-    raw_perf_files = perf_files
-    urls: List[str] = []
-    try:
-      if self.probe.sample_js:
-        perf_files = self._inject_v8_symbols(self.run, perf_files)
-      if self.probe.run_pprof:
-        urls = self._export_to_pprof(self.run, perf_files)
-    finally:
-      self._clean_up_temp_files(self.run)
-    if self.probe.run_pprof:
-      logging.debug("Profiling results: %s", urls)
-      return self.browser_result(url=urls, file=raw_perf_files)
-    if self.browser_platform.which("pprof"):
-      logging.info("Run pprof over all (or single) perf data files "
-                   "for interactive analysis:")
-      logging.info("   pprof --http=localhost:1984 %s",
-                   " ".join(map(str, perf_files)))
-    return self.browser_result(trace=perf_files)
-
-  def _inject_v8_symbols(self, run: Run,
-                         perf_files: List[pth.AnyPath]) -> List[pth.AnyPath]:
-    with run.actions(
-        f"Probe {self.probe.name}: "
-        f"Injecting V8 symbols into {len(perf_files)} profiles",
-        verbose=True), helper.Spinner():
-      # Filter out empty files
-      perf_files = [
-          file for file in perf_files
-          if self.browser_platform.file_size(file) > 0
-      ]
-      if self.browser_platform.is_remote:
-        # Use loop, as we cannot easily serialize the remote platform.
-        perf_jitted_files = [
-            linux_perf_probe_inject_v8_symbols(file, self.browser_platform)
-            for file in perf_files
-        ]
-      else:
-        assert self.browser_platform == plt.PLATFORM
-        with multiprocessing.Pool() as pool:
-          perf_jitted_files = list(
-              pool.imap(linux_perf_probe_inject_v8_symbols, perf_files))
-      return [file for file in perf_jitted_files if file is not None]
-
-  def _export_to_pprof(self, run: Run,
-                       perf_files: List[pth.AnyPath]) -> List[str]:
-    assert self.probe.run_pprof
-    run_details_json = json.dumps(run.get_browser_details_json())
-    with run.actions(
-        f"Probe {self.probe.name}: "
-        f"exporting {len(perf_files)} profiles to pprof (slow)",
-        verbose=True), helper.Spinner():
-      self.browser_platform.sh(
-          "gcertstatus >&/dev/null || "
-          "(echo 'Authenticating with gcert:'; gcert)",
-          shell=True)
-      size = len(perf_files)
-      items = zip(perf_files, [run_details_json] * size)
-      urls: List[str] = []
-      if self.browser_platform.is_remote:
-        # Use loop, as we cannot easily serialize the remote platform.
-        for perf_data_file, run_details in items:
-          url = linux_perf_probe_pprof(perf_data_file, run_details,
-                                       self.browser_platform)
-          if url:
-            urls.append(url)
-      else:
-        assert self.browser_platform == plt.PLATFORM
-        with multiprocessing.Pool() as pool:
-          urls = [
-              url for url in pool.starmap(linux_perf_probe_pprof, items) if url
-          ]
-      try:
-        if perf_files:
-          # TODO: Add "combined" profile again
-          pass
-      except Exception as e:  # pylint: disable=broad-except
-        logging.debug("Failed to run pprof: %s", e)
-      return urls
-
-  def _clean_up_temp_files(self, run: Run) -> None:
-    if self.probe.cleanup_mode == CleanupMode.NEVER:
-      logging.debug("%s: skipping cleanup", self.probe)
-      return
-    if self.probe.cleanup_mode == CleanupMode.AUTO:
-      if not self.probe.run_pprof:
-        logging.debug("%s: skipping auto cleanup without pprof upload",
-                      self.probe)
-        return
-    for pattern in self.TEMP_FILE_PATTERNS:
-      for file in run.out_dir.glob(pattern):
-        file.unlink()
-
-
-def prepare_linux_perf_env(platform: plt.Platform,
-                           cwd: pth.AnyPath) -> Dict[str, str]:
-  env: Dict[str, str] = dict(platform.environ)
-  env["JITDUMPDIR"] = str(platform.absolute(cwd))
-  return env
-
-
-KB = 1024
-
-
-def linux_perf_probe_inject_v8_symbols(
-    perf_data_file: pth.AnyPath,
-    platform: Optional[plt.Platform] = None) -> Optional[pth.AnyPath]:
-  platform = platform or plt.PLATFORM
-  assert platform.is_file(perf_data_file)
-  output_file = perf_data_file.with_suffix(".data.jitted")
-  assert not platform.exists(output_file)
-  env = prepare_linux_perf_env(platform, perf_data_file.parent)
-  try:
-    # TODO: use remote chdir
-    platform.sh(
-        "perf",
-        "inject",
-        "--jit",
-        f"--input={perf_data_file}",
-        f"--output={output_file}",
-        env=env)
-  except plt.SubprocessError as e:
-    if platform.file_size(perf_data_file) > 200 * KB:
-      logging.warning("Failed processing: %s\n%s", perf_data_file, e)
-    else:
-      # TODO: investigate why almost all small perf.data files fail
-      logging.debug("Failed processing small profile (likely empty): %s\n%s",
-                    perf_data_file, e)
-  if not platform.exists(output_file):
-    return None
-  return output_file
-
-
-def linux_perf_probe_pprof(
-    perf_data_file: pth.AnyPath,
-    run_details: str,
-    platform: Optional[plt.Platform] = None) -> Optional[str]:
-  size = helper.get_file_size(perf_data_file)
-  platform = platform or plt.PLATFORM
-  env = prepare_linux_perf_env(platform, perf_data_file.parent)
-  url = ""
-  try:
-    url = platform.sh_stdout(
-        "pprof",
-        "-flame",
-        f"-add_comment={run_details}",
-        perf_data_file,
-        env=env,
-    ).strip()
-  except plt.SubprocessError as e:
-    # Occasionally small .jitted files fail, likely due perf inject silently
-    # failing?
-    raw_perf_data_file = perf_data_file.with_suffix("")
-    if (perf_data_file.suffix == ".jitted" and
-        platform.exists(raw_perf_data_file)):
-      logging.debug(
-          "pprof best-effort: falling back to standard perf data "
-          "without js symbols: %s \n"
-          "Got failures for %s: %s", raw_perf_data_file, perf_data_file.name, e)
-      try:
-        perf_data_file = raw_perf_data_file
-        url = platform.sh_stdout(
-            "pprof",
-            "-flame",
-            f"-add_comment={run_details}",
-            raw_perf_data_file,
-        ).strip()
-      except plt.SubprocessError as e2:
-        logging.debug("pprof -flame failed: %s", e2)
-    if not url:
-      logging.warning("Failed processing: %s\n%s", perf_data_file, e)
-      return None
-  if perf_data_file.suffix == ".jitted":
-    logging.info("PPROF (with js-symbols):")
-  else:
-    logging.info("PPROF (no js-symbols):")
-  logging.info("  linux-perf:   %s %s", perf_data_file.name, size)
-  logging.info("  pprof result: %s", url)
-  return url
-
-
-class AndroidProfilingContext(ProfilingContext):
-
-  def __init__(self, probe: ProfilingProbe, run: Run) -> None:
-    super().__init__(probe, run)
-    self._simpleperf_process: Optional[subprocess.Popen] = None
-    self._story_ready = False
-
-  @cached_property
-  def _renderer_pid_tid(self) -> Tuple[int, int]:
-    assert self._story_ready, (
-        "Fetching renderer PID/TID before the story is loaded could lead to "
-        "the wrong PID/TID being used. This should never happen TM!")
-    renderer_pid: Optional[int] = None
-    renderer_main_tid: Optional[int] = None
-    with self.run.actions("Get Renderer PID/TID") as actions:
-      renderer_pid = actions.js(
-          "return chrome?.benchmarking?.getRendererPid?.();")
-      renderer_main_tid = actions.js(
-          "return chrome?.benchmarking?.getRendererMainTid?.();")
-    if renderer_pid is None or renderer_main_tid is None:
-      error_message = (
-          "Unable to get Renderer PID/TID from browser. "
-          "Is the browser binary a sufficiently new version? "
-          "For RENDERER_MAIN_ONLY/RENDERER_PROCESS_ONLY profiling, at least "
-          "https://chromium-review.googlesource.com/c/chromium/src/+/5374765 "
-          "is required.")
-      logging.error(error_message)
-      raise ValueError(error_message)
-    return renderer_pid, renderer_main_tid
-
-  def _generate_command_line(self) -> ListCmdArgs:
-    renderer_pid: Optional[int] = None
-    renderer_main_tid: Optional[int] = None
-    if self.probe.target in (TargetMode.RENDERER_MAIN_ONLY,
-                             TargetMode.RENDERER_PROCESS_ONLY):
-      renderer_pid, renderer_main_tid = self._renderer_pid_tid
-    return generate_simpleperf_command_line(
-        self.probe.target,
-        str(self.run.browser.path),
-        renderer_pid,
-        renderer_main_tid,
-        self.probe.call_graph_mode,
-        self.probe.frequency,
-        self.probe.count,
-        self.probe.cpu,
-        self.probe.events,
-        self.probe.grouped_events,
-        self.probe.add_counters,
-        self.result_path,
-    )
-
-  def _start_simpleperf(self) -> None:
-    command_line = self._generate_command_line()
-    logging.info("Starting simpleperf with command line: %s.", command_line)
-    self._simpleperf_process = self.browser_platform.popen(
-        *command_line, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
-    # Wait a bit for simpleperf to start and (potentially) terminate on error.
-    time.sleep(1)
-    if self._simpleperf_process.poll():
-      error_msg: str = ""
-      if stdout := self._simpleperf_process.stdout:
-        if isinstance(stdout, io.BufferedReader):
-          error_msg = stdout.read().decode("utf-8")
-          logging.error(error_msg)
-      raise ValueError(f"Unable to start simpleperf. {error_msg}")
-    atexit.register(self.stop_process)
-    self.browser.performance_mark("crossbench-probe-profiling-start")
-
-  def _get_simpleperf_pids(self) -> List[int]:
-    simpleperf_pids = []
-    for process in self.browser_platform.processes():
-      if process["name"] == "simpleperf":
-        simpleperf_pids.append(process["pid"])
-    return simpleperf_pids
-
-  def _stop_existing_simpleperf(self) -> None:
-    for simpleperf_pid in self._get_simpleperf_pids():
-      logging.warning("Terminating existing simpleperf process: %d.",
-                      simpleperf_pid)
-      self.browser_platform.terminate(simpleperf_pid)
-
-  def _cpu_mask(self, cpus: Iterable) -> str:
-    assert max(cpus) < 32, "Cpu index too high"
-    mask = 0
-    for cpu in cpus:
-      mask |= (1 << cpu)
-    return f"{mask:x}"
-
-  def _pin_renderer_main_core(self, cpu: int):
-    _, renderer_main_tid = self._renderer_pid_tid
-    self.browser_platform.sh("taskset", "-p", self._cpu_mask([cpu]),
-                             str(renderer_main_tid))
-
-  def get_default_result_path(self) -> pth.AnyPath:
-    return super().get_default_result_path().parent / "simpleperf.perf.data"
-
-  def setup(self) -> None:
-    assert self.browser.platform.is_android, (
-        f"Expected Android platform, found {type(self.browser.platform)}.")
-    assert self.browser.attributes.is_chromium_based, (
-        f"Expected Chromium-based browser, found {type(self.browser)}.")
-    if (self.browser.platform.is_android and
-        self.browser.attributes.is_chromium_based):
-      chromium = cast(Chromium, self.browser)
-      # Set `--enable-benchmarking` explicitly for
-      # retrieving Renderer PID, if needed.
-      chromium.flags.set("--enable-benchmarking")
-    self._stop_existing_simpleperf()
-
-  def start(self) -> None:
-    if not self.probe.start_profiling_after_setup:
-      self._start_simpleperf()
-
-  def start_story_run(self) -> None:
-    self._story_ready = True
-    if self.probe.pin_renderer_main_core is not None:
-      self._pin_renderer_main_core(self.probe.pin_renderer_main_core)
-
-    if self.probe.start_profiling_after_setup:
-      self._start_simpleperf()
-
-  def stop(self) -> None:
-    self.stop_process()
-
-  def stop_process(self) -> None:
-    if self._simpleperf_process:
-      helper.wait_and_kill(
-          self._simpleperf_process, timeout=30, signal=signal.SIGINT)
-      self._simpleperf_process = None
-      self.browser.performance_mark("crossbench-probe-profiling-stop")
-
-  def teardown(self) -> ProbeResult:
-    return self.browser_result(trace=[self.result_path])
-
-
-def generate_simpleperf_command_line(
-    target: TargetMode,
-    app_name: str,
-    renderer_pid: Optional[int],
-    renderer_main_tid: Optional[int],
-    call_graph_mode: CallGraphMode,
-    frequency: Optional[Union[int, str]],
-    count: Optional[int],
-    cpus: Tuple[int, ...],
-    events: Tuple[str, ...],
-    grouped_events: Tuple[str, ...],
-    add_counters: Tuple[str, ...],
-    output_path: pth.AnyPath,
-) -> ListCmdArgs:
-  command_line: ListCmdArgs = ["simpleperf", "record"]
-  if target == TargetMode.RENDERER_MAIN_ONLY:
-    assert renderer_main_tid is not None
-    command_line.extend(["-t", str(renderer_main_tid)])
-  elif target == TargetMode.RENDERER_PROCESS_ONLY:
-    assert renderer_pid is not None
-    command_line.extend(["-p", str(renderer_pid)])
-  elif target == TargetMode.BROWSER_APP_ONLY:
-    command_line.extend(["--app", app_name])
-  else:  # TargetMode.SYSTEM_WIDE
-    command_line.append("-a")
-  if call_graph_mode == CallGraphMode.FRAME_POINTER:
-    command_line.extend(["--call-graph", "fp"])
-  elif call_graph_mode == CallGraphMode.DWARF:
-    # Use "--post-unwind=yes" while unwinding with DWARF, to reduce
-    # unwinding overhead during profiling.
-    command_line.extend(["--call-graph", "dwarf", "--post-unwind=yes"])
-  else:
-    assert call_graph_mode == CallGraphMode.NO_CALL_GRAPH, (
-        f"Invalid call_graph_mode: {call_graph_mode}")
-  if frequency is not None:
-    command_line.extend(["-f", str(frequency)])
-  if count is not None:
-    command_line.extend(["-c", str(count)])
-  if cpus:
-    command_line.extend(["--cpu", ",".join(map(str, cpus))])
-  # Events and counters need to be provided after `-f` and `-c`.
-  if events:
-    command_line.extend(["-e", ",".join(events)])
-  if grouped_events:
-    command_line.extend(["--group", ",".join(grouped_events)])
-  if add_counters:
-    command_line.extend(["--add-counter", ",".join(add_counters)])
-    # `--no-inherit` is required by simpleperf when `--add-counter` is used.
-    command_line.append("--no-inherit")
-  command_line.extend(["-o", output_path])
-  return command_line
diff --git a/crossbench/probes/profiling/time-profile.tracetemplate b/crossbench/probes/profiling/time-profile.tracetemplate
new file mode 100644
index 00000000..375a0efd
Binary files /dev/null and b/crossbench/probes/profiling/time-profile.tracetemplate differ
diff --git a/crossbench/probes/result_location.py b/crossbench/probes/result_location.py
index 9e0806be..0c5da0f5 100644
--- a/crossbench/probes/result_location.py
+++ b/crossbench/probes/result_location.py
@@ -6,11 +6,11 @@ from __future__ import annotations
 
 import enum
 
-from crossbench import compat
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 
 @enum.unique
-class ResultLocation(compat.StrEnumWithHelp):
+class ResultLocation(StrEnumWithHelp):
   LOCAL = ("local",
            "Probe always produces results on the runner's local platform.")
   BROWSER = ("browser",
diff --git a/crossbench/probes/results.py b/crossbench/probes/results.py
index 7550d9fb..37a3902a 100644
--- a/crossbench/probes/results.py
+++ b/crossbench/probes/results.py
@@ -11,14 +11,15 @@ from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Tuple,
 
 from immutabledict import immutabledict
 from ordered_set import OrderedSet
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.parse import ObjectParser
 from crossbench.probes.helper import INTERNAL_NAME_PREFIX
+from crossbench.probes.probe_result_key import ProbeResultKey
+from crossbench.runner.probe_result_origin import ProbeResultOrigin
 
 if TYPE_CHECKING:
-  from crossbench.probes.probe import Probe
-  from crossbench.runner.result_origin import ResultOrigin
   from crossbench.types import JsonDict
 
 
@@ -39,7 +40,7 @@ class ProbeResult(abc.ABC):
                url: Optional[Iterable[str]] = None,
                file: Optional[Iterable[pth.LocalPath]] = None,
                trace: Optional[Iterable[pth.LocalPath]] = None,
-               **kwargs: Iterable[pth.LocalPath]):
+               **kwargs: Iterable[pth.LocalPath]) -> None:
     self._url_list: Tuple[str, ...] = ()
     if url:
       self._url_list = ObjectParser.unique_sequence(
@@ -90,7 +91,7 @@ class ProbeResult(abc.ABC):
               tmp_files: Dict[str, OrderedSet[pth.LocalPath]],
               files: Iterable[pth.LocalPath],
               suffix: Optional[str] = None,
-              allow_duplicates=False) -> None:
+              allow_duplicates: bool = False) -> None:
     for file in files:
       self._append(
           tmp_files, file, suffix=suffix, allow_duplicates=allow_duplicates)
@@ -101,8 +102,10 @@ class ProbeResult(abc.ABC):
         raise ValueError(f"Expected exactly one file with suffix {suffix}, "
                          f"but got {files_with_suffix}")
       return files_with_suffix[0]
-    raise ValueError(f"No files with suffix '.{suffix}'. "
-                     f"Options are {tuple(self._files.keys())}")
+    choices: str = f"Options are {tuple(self._files.keys())}."
+    if self.is_empty:
+      choices = "Empty ProbeResult."
+    raise ValueError(f"No files with suffix '.{suffix}'. {choices}")
 
   def get_all(self, suffix: str) -> List[pth.LocalPath]:
     if files_with_suffix := self._files.get(suffix):
@@ -230,12 +233,12 @@ class BrowserProbeResult(ProbeResult):
   """
 
   def __init__(self,
-               result_origin: ResultOrigin,
+               result_origin: ProbeResultOrigin,
                url: Optional[Iterable[str]] = None,
                file: Optional[Iterable[pth.AnyPath]] = None,
-               **kwargs: Iterable[pth.AnyPath]):
+               **kwargs: Iterable[pth.AnyPath]) -> None:
     self._browser_file = file
-    local_file: Optional[Iterable[pth.LocalPath]] = None
+    local_file: Iterable[pth.LocalPath] | None = None
     local_kwargs: Dict[str, Iterable[pth.LocalPath]] = {}
     self._is_remote = result_origin.is_remote
     if self._is_remote:
@@ -251,10 +254,11 @@ class BrowserProbeResult(ProbeResult):
     super().__init__(url, local_file, **local_kwargs)
 
   @property
+  @override
   def is_remote(self) -> bool:
     return self._is_remote
 
-  def _copy_files(self, result_origin: ResultOrigin,
+  def _copy_files(self, result_origin: ProbeResultOrigin,
                   paths: Iterable[pth.AnyPath]) -> Iterable[pth.LocalPath]:
     assert paths, "Got no remote paths to copy."
     # Copy result files from remote tmp dir to local results dir
@@ -286,17 +290,17 @@ class ProbeResultDict:
     self._path = path
     self._dict: Dict[str, ProbeResult] = {}
 
-  def __setitem__(self, probe: Probe, result: ProbeResult) -> None:
+  def __setitem__(self, probe: ProbeResultKey, result: ProbeResult) -> None:
     assert isinstance(result, ProbeResult)
     self._dict[probe.name] = result
 
-  def __getitem__(self, probe: Probe) -> ProbeResult:
+  def __getitem__(self, probe: ProbeResultKey) -> ProbeResult:
     name = probe.name
     if name not in self._dict:
       raise KeyError(f"No results for probe='{name}'")
     return self._dict[name]
 
-  def __contains__(self, probe: Probe) -> bool:
+  def __contains__(self, probe: ProbeResultKey) -> bool:
     return probe.name in self._dict
 
   def __bool__(self) -> bool:
@@ -305,7 +309,7 @@ class ProbeResultDict:
   def __len__(self) -> int:
     return len(self._dict)
 
-  def get(self, probe: Probe, default: Any = None) -> ProbeResult:
+  def get(self, probe: ProbeResultKey, default: Any = None) -> ProbeResult:
     return self._dict.get(probe.name, default)
 
   def get_by_name(self, name: str, default: Any = None) -> ProbeResult:
@@ -318,13 +322,12 @@ class ProbeResultDict:
     for probe_name, results in self._dict.items():
       if isinstance(results, (pth.AnyPath, str)):
         data[probe_name] = str(results)
+      elif results.is_empty:
+        if not probe_name.startswith(INTERNAL_NAME_PREFIX):
+          logging.debug("probe=%s did not produce any data.", probe_name)
+        data[probe_name] = None
       else:
-        if results.is_empty:
-          if not probe_name.startswith(INTERNAL_NAME_PREFIX):
-            logging.debug("probe=%s did not produce any data.", probe_name)
-          data[probe_name] = None
-        else:
-          data[probe_name] = results.to_json()
+        data[probe_name] = results.to_json()
     return data
 
   def all_traces(self) -> Iterable[pth.LocalPath]:
diff --git a/crossbench/probes/screenshot.py b/crossbench/probes/screenshot.py
index 7726dd4c..c61cf986 100644
--- a/crossbench/probes/screenshot.py
+++ b/crossbench/probes/screenshot.py
@@ -5,19 +5,21 @@
 from __future__ import annotations
 
 import datetime as dt
-from typing import TYPE_CHECKING, List, Optional
+from typing import TYPE_CHECKING, List, Optional, Self, Sequence, Type
 
-from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
-                                     ProbeMissingDataError)
+from typing_extensions import override
+
+from crossbench.action_runner.screenshot_annotation import (
+    ScreenshotAnnotation, annotate_screenshot_svg)
+from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeContext
+from crossbench.probes.probe_error import ProbeMissingDataError
 from crossbench.probes.result_location import ResultLocation
-from crossbench.probes.results import EmptyProbeResult, ProbeResult
+from crossbench.probes.results import ProbeResult
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Viewport
   from crossbench.env import HostEnvironment
   from crossbench.path import AnyPath
-  from crossbench.runner.groups.browsers import BrowsersRunGroup
-  from crossbench.runner.groups.repetitions import RepetitionsRunGroup
   from crossbench.runner.run import Run
 
 
@@ -30,7 +32,8 @@ class ScreenshotProbe(Probe):
   IMAGE_FORMAT = "png"
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     # TODO: support interval-based screenshots
     return parser
@@ -45,16 +48,12 @@ class ScreenshotProbe(Probe):
         env.handle_warning(
             f"Viewport for '{browser}' might include toolbar: {viewport}")
 
-  def get_context(self, run: Run) -> ScreenshotProbeContext:
-    return ScreenshotProbeContext(self, run)
-
-  def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
-    # TODO: implement
-    return EmptyProbeResult()
+  @override
+  def get_context_cls(self) -> Type[ScreenshotProbeContext]:
+    return ScreenshotProbeContext
 
-  def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
-    # TODO: implement
-    return EmptyProbeResult()
+  # TODO: implement merge_repetitions()
+  # TODO: implement merge_browsers()
 
 
 class ScreenshotProbeContext(ProbeContext[ScreenshotProbe]):
@@ -63,6 +62,7 @@ class ScreenshotProbeContext(ProbeContext[ScreenshotProbe]):
     super().__init__(probe, run)
     self._results: List[AnyPath] = []
 
+  @override
   def get_default_result_path(self) -> AnyPath:
     screenshot_dir = super().get_default_result_path()
     self.browser_platform.mkdir(screenshot_dir)
@@ -71,24 +71,43 @@ class ScreenshotProbeContext(ProbeContext[ScreenshotProbe]):
   def start(self) -> None:
     self.screenshot("start")
 
+  @override
   def start_story_run(self) -> None:
     self.screenshot("start_story")
 
+  @override
   def stop_story_run(self) -> None:
     self.screenshot("stop_story")
 
   def stop(self) -> None:
     self.screenshot("stop")
 
-  def screenshot(self, label: Optional[str] = None) -> None:
+  def _annotate_screenshot(self, screenshot_file_name: str, label: str,
+                           annotations: Sequence[ScreenshotAnnotation]) -> None:
+    (screen_width, screen_height) = self.browser_platform.display_resolution()
+    svg = annotate_screenshot_svg(screen_width, screen_height,
+                                  screenshot_file_name, annotations)
+    svg_path = self.result_path / f"{label}.svg"
+    self.browser_platform.set_file_contents(svg_path, svg)
+    self._results.append(svg_path)
+
+  def screenshot(
+      self,
+      label: Optional[str] = None,
+      annotations: Optional[Sequence[ScreenshotAnnotation]] = None) -> None:
     # TODO: support screen coordinates
     if not label:
       label = str(dt.datetime.now().strftime("%Y-%m-%d_%H%M%S"))
-    path = self.result_path / f"{label}.{ScreenshotProbe.IMAGE_FORMAT}"
+    file_name = f"{label}.{ScreenshotProbe.IMAGE_FORMAT}"
+    path = self.result_path / file_name
     # TODO: use the browser's implementation first which might be more portable
     self.browser_platform.screenshot(path)
     self._results.append(path)
 
+    if annotations:
+      self._annotate_screenshot(file_name, label, annotations)
+
+  @override
   def teardown(self) -> ProbeResult:
     if not self.browser_platform.is_dir(self.result_path):
       raise ProbeMissingDataError(
diff --git a/crossbench/probes/shell.py b/crossbench/probes/shell.py
index 83a89eab..5753e168 100644
--- a/crossbench/probes/shell.py
+++ b/crossbench/probes/shell.py
@@ -4,7 +4,9 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Iterable, List, Optional
+from typing import TYPE_CHECKING, Iterable, List, Optional, Self, Type
+
+from typing_extensions import override
 
 from crossbench.parse import ObjectParser
 from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeKeyT
@@ -29,33 +31,30 @@ class ShellProbe(Probe):
   RESULT_LOCATION = ResultLocation.LOCAL
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "setup_cmd",
         aliases=("setup",),
         type=ObjectParser.sh_cmd,
-        required=False,
         help="CMD is run before the browser is started.")
     parser.add_argument(
         "start_cmd",
         type=ObjectParser.sh_cmd,
         aliases=("start",),
-        required=False,
         help=("CMD is run right before each story is started "
               "and the browser is already running."))
     parser.add_argument(
         "start_story_run_cmd",
         aliases=("start-story",),
         type=ObjectParser.sh_cmd,
-        required=False,
         help=("CMD is run right before the measurement phase "
               "of a story is started."))
     parser.add_argument(
         "stop_story_run_cmd",
         aliases=("stop-story",),
         type=ObjectParser.sh_cmd,
-        required=False,
         help=("CMD is run right after the measurement phase "
               "of a story has ended."))
     parser.add_argument(
@@ -69,7 +68,6 @@ class ShellProbe(Probe):
         "teardown_cmd",
         aliases=("teardown",),
         type=ObjectParser.sh_cmd,
-        required=False,
         help="CMD is run after the browser is stopped.")
     return parser
 
@@ -92,6 +90,7 @@ class ShellProbe(Probe):
         tuple(teardown_cmd) if teardown_cmd else ())
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("setup_cmd", tuple(map(str, self.stop_cmd))),
@@ -126,14 +125,16 @@ class ShellProbe(Probe):
   def teardown_cmd(self) -> TupleCmdArgs:
     return self._teardown_cmd
 
+  @override
   def validate_env(self, env: HostEnvironment) -> None:
     super().validate_env(env)
     if env.repetitions != 1:
       env.handle_warning(f"Probe={self.NAME} cannot merge data over multiple "
                          f"repetitions={env.repetitions}.")
 
-  def get_context(self, run: Run) -> ShellProbeContext:
-    return ShellProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[ShellProbeContext]:
+    return ShellProbeContext
 
 
 class ShellProbeContext(ProbeContext[ShellProbe]):
@@ -154,6 +155,7 @@ class ShellProbeContext(ProbeContext[ShellProbe]):
     with stdout_path.open("w") as stdout, stderr_path.open("w") as stderr:
       self.browser_platform.sh(*cmd, shell=True, stdout=stdout, stderr=stderr)
 
+  @override
   def setup(self) -> None:
     self.host_platform.mkdir(self.local_result_path)
     self._maybe_run_cmd("setup", self.probe.setup_cmd)
@@ -161,9 +163,11 @@ class ShellProbeContext(ProbeContext[ShellProbe]):
   def start(self) -> None:
     self._maybe_run_cmd("start", self.probe.start_cmd)
 
+  @override
   def start_story_run(self) -> None:
     self._maybe_run_cmd("start_story_run", self.probe.start_story_run_cmd)
 
+  @override
   def stop_story_run(self) -> None:
     self._maybe_run_cmd("stop_story_run", self.probe.stop_story_run_cmd)
 
diff --git a/crossbench/probes/system_stats.py b/crossbench/probes/system_stats.py
index 74b470f4..85175ff9 100644
--- a/crossbench/probes/system_stats.py
+++ b/crossbench/probes/system_stats.py
@@ -7,8 +7,10 @@ from __future__ import annotations
 import datetime as dt
 from typing import TYPE_CHECKING
 
+from typing_extensions import override
+
 from crossbench.probes.polling import PollingProbe
-from crossbench.probes.probe import ProbeValidationError
+from crossbench.probes.probe_error import ProbeValidationError
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
@@ -28,6 +30,7 @@ class SystemStatsProbe(PollingProbe):
       self, interval: dt.timedelta = dt.timedelta(seconds=0.1)) -> None:
     super().__init__(self.CMD, interval)
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     if not (browser.platform.is_linux or browser.platform.is_macos):
diff --git a/crossbench/probes/thermal_monitor.py b/crossbench/probes/thermal_monitor.py
index 6e9fa6e1..5491feae 100644
--- a/crossbench/probes/thermal_monitor.py
+++ b/crossbench/probes/thermal_monitor.py
@@ -11,9 +11,11 @@ import re
 from enum import IntEnum
 from typing import TYPE_CHECKING, Iterable, Optional
 
-from crossbench import helper
-from crossbench.probes.internal import (InternalJsonResultProbe,
-                                        InternalJsonResultProbeContext)
+from typing_extensions import override
+
+from crossbench.helper.wait import WaitRange
+from crossbench.probes.internal.base import (InternalJsonResultProbe,
+                                             InternalJsonResultProbeContext)
 from crossbench.probes.probe import ProbeIncompatibleBrowser
 from crossbench.probes.result_location import ResultLocation
 from crossbench.probes.results import EmptyProbeResult, LocalProbeResult
@@ -21,6 +23,7 @@ from crossbench.probes.results import EmptyProbeResult, LocalProbeResult
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.env import HostEnvironment
+  from crossbench.probes.probe_context import ProbeContext
   from crossbench.probes.results import ProbeResult, ProbeResultDict
   from crossbench.runner.actions import Actions
   from crossbench.runner.groups.browsers import BrowsersRunGroup
@@ -29,8 +32,9 @@ if TYPE_CHECKING:
   from crossbench.runner.run import Run
   from crossbench.types import Json
 
-THERMAL_STATUS_RE = re.compile(r"Thermal Status: (?P<status>\d+)")
-COOLDOWN_WAIT_RANGE = helper.WaitRange(
+THERMAL_STATUS_RE: re.Pattern[str] = re.compile(
+    r"Thermal Status: (?P<status>\d+)")
+COOLDOWN_WAIT_RANGE = WaitRange(
     min=dt.timedelta(seconds=1), timeout=dt.timedelta(minutes=5))
 
 
@@ -67,14 +71,15 @@ class ThermalMonitorProbe(InternalJsonResultProbe):
 
   def __init__(self,
                cool_down_time: dt.timedelta = dt.timedelta(),
-               threshold: Optional[ThermalStatus] = None):
+               threshold: Optional[ThermalStatus] = None) -> None:
     super().__init__()
-    self._threshold: Optional[ThermalStatus] = threshold
-    self._cool_down_time: Optional[dt.timedelta] = cool_down_time
+    self._threshold: ThermalStatus | None = threshold
+    self._cool_down_time: dt.timedelta = cool_down_time
     if threshold is not None and threshold <= 0:
       raise ValueError("Threshold must be positive")
 
   @property
+  @override
   def result_path_name(self) -> str:
     return "cb.thermal_monitor.json"
 
@@ -89,19 +94,23 @@ class ThermalMonitorProbe(InternalJsonResultProbe):
   def to_json(self, actions: Actions) -> Json:
     raise NotImplementedError("Should not be called, data comes from context")
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     if self.threshold is not None and not browser.platform.is_android:
       raise ProbeIncompatibleBrowser(
           self, browser, "Thermal thresholds only supported on android")
 
+  @override
   def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
     return self._merge_group(group, (run.results for run in group.runs))
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     return self._merge_group(
         group, (rep_group.results for rep_group in group.repetitions_groups))
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     return self._merge_group(
         group, (story_group.results for story_group in group.story_groups))
@@ -134,6 +143,7 @@ class ThermalMonitorProbe(InternalJsonResultProbe):
 
     return LocalProbeResult(json=(merged_path,))
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     if self not in group.results:
       return
@@ -154,13 +164,14 @@ class ThermalMonitorProbe(InternalJsonResultProbe):
       logging.error("Significant thermal throttling detected during execution, "
                     "scores are not representative of the device performance.")
 
-  def get_context(self, run: Run) -> ThermalMonitorProbeContext:
+  def get_context(self, run: Run) -> Optional[ProbeContext]:
     if run.browser.platform.is_android:
       return AndroidThermalMonitorProbeContext(self, run)
     return ThermalMonitorProbeContext(self, run)
 
 
-class ThermalMonitorProbeContext(InternalJsonResultProbeContext):
+class ThermalMonitorProbeContext(
+    InternalJsonResultProbeContext[ThermalMonitorProbe]):
 
   def __init__(self, probe: ThermalMonitorProbe, run: Run) -> None:
     super().__init__(probe, run)
@@ -180,6 +191,7 @@ class ThermalMonitorProbeContext(InternalJsonResultProbeContext):
         break
       logging.info("COOLDOWN: still hot, waiting some more")
 
+  @override
   def to_json(self, actions: Actions) -> Json:
     del actions
     return {}
@@ -215,6 +227,7 @@ class AndroidThermalMonitorProbeContext(ThermalMonitorProbeContext):
       logging.error("COOLDOWN: device is still too hot after waiting for %s",
                     COOLDOWN_WAIT_RANGE.timeout)
 
+  @override
   def setup(self) -> None:
     if self.probe.threshold is not None:
       self._wait_if_necessary(self.probe.threshold)
@@ -225,6 +238,7 @@ class AndroidThermalMonitorProbeContext(ThermalMonitorProbeContext):
     self._max_observed_status = max(self._max_observed_status, current_status)
     logging.debug("Thermal throttling before run: %s", current_status.name)
 
+  @override
   def teardown(self) -> ProbeResult:
     current_status = self._get_thermal_status()
     self._max_observed_status = max(self._max_observed_status, current_status)
@@ -234,6 +248,7 @@ class AndroidThermalMonitorProbeContext(ThermalMonitorProbeContext):
     # register the run as a failure to process it correctly later.
     return super().teardown()
 
+  @override
   def to_json(self, actions: Actions) -> Json:
     del actions
     return {"max_observed_status": self._max_observed_status.value}
diff --git a/crossbench/probes/v8/__init__.py b/crossbench/probes/v8/__init__.py
index 3ea02f95..d271f03d 100644
--- a/crossbench/probes/v8/__init__.py
+++ b/crossbench/probes/v8/__init__.py
@@ -1,3 +1,5 @@
 # Copyright 2022 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/v8/builtins_pgo.py b/crossbench/probes/v8/builtins_pgo.py
index 3d95cf1c..54a88112 100644
--- a/crossbench/probes/v8/builtins_pgo.py
+++ b/crossbench/probes/v8/builtins_pgo.py
@@ -4,7 +4,9 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
 
 from crossbench.probes.chromium_probe import ChromiumProbe
 from crossbench.probes.probe import ProbeContext
@@ -14,7 +16,6 @@ if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.runner.groups.repetitions import RepetitionsRunGroup
   from crossbench.runner.groups.stories import StoriesRunGroup
-  from crossbench.runner.run import Run
 
 
 class V8BuiltinsPGOProbe(ChromiumProbe):
@@ -24,15 +25,16 @@ class V8BuiltinsPGOProbe(ChromiumProbe):
   """
   NAME = "v8.builtins.pgo"
 
+  @override
   def attach(self, browser: Browser) -> None:
-    assert browser.attributes.is_chromium_based, (
-        "Expected Chromium-based browser.")
     super().attach(browser)
     browser.js_flags.set("--allow-natives-syntax")
 
-  def get_context(self, run: Run) -> V8BuiltinsPGOProbeContext:
-    return V8BuiltinsPGOProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[V8BuiltinsPGOProbeContext]:
+    return V8BuiltinsPGOProbeContext
 
+  @override
   def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
     merged_result_path = group.get_local_probe_result_path(self)
     result_files = (run.results[self].file for run in group.runs)
@@ -40,6 +42,7 @@ class V8BuiltinsPGOProbe(ChromiumProbe):
         inputs=result_files, output=merged_result_path)
     return LocalProbeResult(file=(result_file,))
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     merged_result_path = group.get_local_probe_result_path(self)
     result_files = (g.results[self].file for g in group.repetitions_groups)
@@ -49,8 +52,9 @@ class V8BuiltinsPGOProbe(ChromiumProbe):
 
 
 class V8BuiltinsPGOProbeContext(ProbeContext[V8BuiltinsPGOProbe]):
-  _pgo_counters: Optional[str] = None
+  _pgo_counters: str | None = None
 
+  @override
   def setup(self) -> None:
     pass
 
diff --git a/crossbench/probes/v8/log.py b/crossbench/probes/v8/log.py
index dad3adbf..f249f47b 100644
--- a/crossbench/probes/v8/log.py
+++ b/crossbench/probes/v8/log.py
@@ -9,19 +9,22 @@ import multiprocessing
 import os
 import re
 import subprocess
-from typing import TYPE_CHECKING, Iterable, List, Optional, cast
+from typing import TYPE_CHECKING, Iterable, List, Optional, Self, Type, cast
 
-from crossbench import compat, helper, plt
-from crossbench.browsers.browser import Browser
-from crossbench.browsers.chromium.chromium import Chromium
+from typing_extensions import override
+
+from crossbench import plt
 from crossbench.flags.js_flags import JSFlags
+from crossbench.helper import fs_helper
 from crossbench.helper.path_finder import V8ToolsFinder
+from crossbench.helper.spinner import Spinner
 from crossbench.parse import PathParser
 from crossbench.probes.chromium_probe import ChromiumProbe
 from crossbench.probes.probe import ProbeConfigParser, ProbeContext, ProbeKeyT
 from crossbench.probes.result_location import ResultLocation
 
 if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
   from crossbench.env import HostEnvironment
   from crossbench.path import AnyPath, LocalPath
   from crossbench.probes.results import ProbeResult
@@ -47,7 +50,8 @@ class V8LogProbe(ChromiumProbe):
   _FLAG_RE = re.compile("^--(prof|log-|no-log-).*$")
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "log_all",
@@ -97,8 +101,8 @@ class V8LogProbe(ChromiumProbe):
     super().__init__()
     self._profview: bool = profview
     self._js_flags = JSFlags()
-    self._d8_binary: Optional[LocalPath] = d8_binary
-    self._v8_checkout: Optional[LocalPath] = v8_checkout
+    self._d8_binary: LocalPath | None = d8_binary
+    self._v8_checkout: LocalPath | None = v8_checkout
     assert isinstance(log_all,
                       bool), (f"Expected bool value, got log_all={log_all}")
     assert isinstance(prof, bool), f"Expected bool value, got log_all={prof}"
@@ -118,6 +122,7 @@ class V8LogProbe(ChromiumProbe):
       raise ValueError(f"{self}: V8LogProbe has no effect")
 
   @property
+  @override
   def key(self) -> ProbeKeyT:
     return super().key + (
         ("profview", self._profview),
@@ -130,29 +135,31 @@ class V8LogProbe(ChromiumProbe):
   def js_flags(self) -> JSFlags:
     return self._js_flags.copy()
 
+  @override
   def validate_env(self, env: HostEnvironment) -> None:
     super().validate_env(env)
     if env.repetitions != 1:
       env.handle_warning(f"Probe({self.NAME}) cannot merge data over multiple "
                          f"repetitions={env.repetitions}.")
 
+  @override
   def validate_browser(self, env: HostEnvironment, browser: Browser) -> None:
     super().validate_browser(env, browser)
     # --prof sometimes causes issues on enterprise chrome on linux.
     if _PROF_FLAG not in self._js_flags:
       return
-    if not browser.platform.is_linux or browser.major_version <= 106:
+    if not browser.platform.is_linux or browser.version.major <= 106:
       return
     for search_path in cast(plt.LinuxPlatform, browser.platform).SEARCH_PATHS:
-      if compat.is_relative_to(browser.path, search_path):
+      if browser.path.is_relative_to(search_path):
         logging.error(
             "Probe with V8 --prof might not work with enterprise profiles")
 
+  @override
   def attach(self, browser: Browser) -> None:
     super().attach(browser)
-    assert isinstance(browser, Chromium)
-
-    browser = cast(Chromium, browser)
+    assert browser.attributes().is_chromium_based, (
+        f"Expected chromium-based browser, but got {browser}")
     browser.flags.set("--no-sandbox")
     browser.js_flags.update(self._js_flags)
 
@@ -182,9 +189,11 @@ class V8LogProbe(ChromiumProbe):
                        [(finder.d8_binary, finder.tick_processor, log_file)
                         for log_file in log_files]))
 
-  def get_context(self, run: Run) -> V8LogProbeContext:
-    return V8LogProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[V8LogProbeContext]:
+    return V8LogProbeContext
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     runs: List[Run] = list(run for run in group.runs if self in run.results)
     if not runs:
@@ -204,7 +213,7 @@ class V8LogProbe(ChromiumProbe):
       logging.info("Run %d: %s", i + 1, run.name)
       largest_log_file = log_files[-1]
       logging.critical("    %s : %s", largest_log_file,
-                       helper.get_file_size(largest_log_file))
+                       fs_helper.get_file_size(largest_log_file))
       if len(log_files) > 1:
         logging.info("    %s/.*v8.log: %d files", largest_log_file.parent,
                      len(log_files))
@@ -213,7 +222,7 @@ class V8LogProbe(ChromiumProbe):
         continue
       largest_profview_file = profview_files[-1]
       logging.critical("    %s : %s", largest_profview_file,
-                       helper.get_file_size(largest_profview_file))
+                       fs_helper.get_file_size(largest_profview_file))
       if len(profview_files) > 1:
         logging.info("    %s/*.profview.json: %d more files",
                      largest_profview_file.parent, len(profview_files))
@@ -221,11 +230,13 @@ class V8LogProbe(ChromiumProbe):
 
 class V8LogProbeContext(ProbeContext[V8LogProbe]):
 
+  @override
   def get_default_result_path(self) -> AnyPath:
     log_dir = super().get_default_result_path()
     self.browser_platform.mkdir(log_dir)
     return log_dir / self.probe.result_path_name
 
+  @override
   def setup(self) -> None:
     self.session.extra_js_flags["--logfile"] = str(self.result_path)
 
@@ -237,13 +248,13 @@ class V8LogProbeContext(ProbeContext[V8LogProbe]):
 
   def teardown(self) -> ProbeResult:
     log_dir = self.result_path.parent
-    log_files = helper.sort_by_file_size(
+    log_files = fs_helper.sort_by_file_size(
         self.browser_platform.glob(log_dir, "*-v8.log"), self.browser_platform)
     # Only convert a v8.log file with profile ticks.
     json_list: List[AnyPath] = []
     maybe_js_flags = getattr(self.browser, "js_flags", {})
     if _PROF_FLAG in maybe_js_flags or _LOG_ALL_FLAG in maybe_js_flags:
-      with helper.Spinner():
+      with Spinner():
         json_list = self.probe.process_log_files(log_files)
     return self.browser_result(file=tuple(log_files), json=json_list)
 
diff --git a/crossbench/probes/v8/rcs.py b/crossbench/probes/v8/rcs.py
index 9a07a7e1..e23dad3d 100644
--- a/crossbench/probes/v8/rcs.py
+++ b/crossbench/probes/v8/rcs.py
@@ -6,11 +6,13 @@ from __future__ import annotations
 
 import collections
 import logging
-from typing import TYPE_CHECKING, Optional, Union, cast
+from typing import TYPE_CHECKING, Type
+
+from typing_extensions import override
 
-from crossbench.browsers.chromium.chromium import Chromium
 from crossbench.probes.chromium_probe import ChromiumProbe
-from crossbench.probes.probe import ProbeContext, ProbeMissingDataError
+from crossbench.probes.probe import ProbeContext
+from crossbench.probes.probe_error import ProbeMissingDataError
 from crossbench.probes.results import LocalProbeResult, ProbeResult
 
 if TYPE_CHECKING:
@@ -20,7 +22,6 @@ if TYPE_CHECKING:
   from crossbench.runner.groups.repetitions import (
       CacheTemperatureRepetitionsRunGroup, RepetitionsRunGroup)
   from crossbench.runner.groups.stories import StoriesRunGroup
-  from crossbench.runner.run import Run
 
 
 class V8RCSProbe(ChromiumProbe):
@@ -31,18 +32,17 @@ class V8RCSProbe(ChromiumProbe):
   """
   NAME = "v8.rcs"
 
+  @override
   def attach(self, browser: Browser) -> None:
-    assert isinstance(browser, Chromium), "Expected Chromium-based browser."
     super().attach(browser)
-    chromium = cast(Chromium, browser)
-    chromium.js_flags.update(("--runtime-call-stats", "--allow-natives-syntax"))
+    browser.js_flags.update(("--runtime-call-stats", "--allow-natives-syntax"))
 
-  def get_context(self, run: Run) -> V8RCSProbeContext:
-    return V8RCSProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[V8RCSProbeContext]:
+    return V8RCSProbeContext
 
-  def concat_group_files(self,
-                         group: Union[RepetitionsRunGroup,
-                                      CacheTemperatureRepetitionsRunGroup],
+  def concat_group_files(self, group: RepetitionsRunGroup
+                         | CacheTemperatureRepetitionsRunGroup,
                          file_name: str) -> LocalPath:
     result_dir = group.get_local_probe_result_dir(self)
     result_files = (run.results[self].file for run in group.runs)
@@ -52,6 +52,7 @@ class V8RCSProbe(ChromiumProbe):
         prefix=f"\n== Page: {group.story.name}\n")
     return result_file
 
+  @override
   def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
     all_file = self.concat_group_files(group, "all.rcs.txt")
     result_files = [all_file]
@@ -65,6 +66,7 @@ class V8RCSProbe(ChromiumProbe):
                                        result_dir.with_suffix(".rcs.txt"))
     return LocalProbeResult(file=tuple(result_files))
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     name_groups = collections.defaultdict(list)
     for repetition_group in group.repetitions_groups:
@@ -82,6 +84,7 @@ class V8RCSProbe(ChromiumProbe):
                                        result_dir.with_suffix(".rcs.txt"))
     return LocalProbeResult(file=(src_file,))
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     # We put all the fils by in a toplevel v8.rcs folder
     result_dir = group.get_local_probe_result_dir(self)
@@ -98,6 +101,7 @@ class V8RCSProbe(ChromiumProbe):
       files.append(dest_file)
     return LocalProbeResult(file=files)
 
+  @override
   def log_browsers_result(self, group: BrowsersRunGroup) -> None:
     if self not in group.results:
       return
@@ -110,8 +114,9 @@ class V8RCSProbe(ChromiumProbe):
 
 
 class V8RCSProbeContext(ProbeContext[V8RCSProbe]):
-  _rcs_table: Optional[str] = None
+  _rcs_table: str | None = None
 
+  @override
   def setup(self) -> None:
     pass
 
diff --git a/crossbench/probes/v8/turbolizer.py b/crossbench/probes/v8/turbolizer.py
index 102effa7..cdabae54 100644
--- a/crossbench/probes/v8/turbolizer.py
+++ b/crossbench/probes/v8/turbolizer.py
@@ -4,10 +4,11 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, cast
+from typing import TYPE_CHECKING, Type
 
-from crossbench import helper
-from crossbench.browsers.chromium.chromium import Chromium
+from typing_extensions import override
+
+from crossbench.helper import fs_helper
 from crossbench.probes.chromium_probe import ChromiumProbe
 from crossbench.probes.probe import ProbeContext
 from crossbench.probes.result_location import ResultLocation
@@ -17,7 +18,6 @@ from crossbench.probes.results import (BrowserProbeResult, LocalProbeResult,
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.path import AnyPath
-  from crossbench.runner.run import Run
 
 
 class V8TurbolizerProbe(ChromiumProbe):
@@ -29,15 +29,15 @@ class V8TurbolizerProbe(ChromiumProbe):
   NAME = "v8.turbolizer"
   RESULT_LOCATION = ResultLocation.BROWSER
 
+  @override
   def attach(self, browser: Browser) -> None:
     super().attach(browser)
-    assert isinstance(browser, Chromium)
-    chromium = cast(Chromium, browser)
-    chromium.flags.set("--no-sandbox")
-    chromium.js_flags.set("--trace-turbo")
+    browser.flags.set("--no-sandbox")
+    browser.js_flags.set("--trace-turbo")
 
-  def get_context(self, run: Run) -> V8TurbolizerProbeContext:
-    return V8TurbolizerProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[V8TurbolizerProbeContext]:
+    return V8TurbolizerProbeContext
 
 
 class V8TurbolizerProbeContext(ProbeContext[V8TurbolizerProbe]):
@@ -50,6 +50,7 @@ class V8TurbolizerProbeContext(ProbeContext[V8TurbolizerProbe]):
     self.browser_platform.mkdir(turbolizer_log_dir, exist_ok=True)
     return turbolizer_log_dir
 
+  @override
   def setup(self) -> None:
     js_flags = self.session.extra_js_flags
     js_flags["--trace-turbo-path"] = str(self.results_dir)
@@ -69,5 +70,5 @@ class V8TurbolizerProbeContext(ProbeContext[V8TurbolizerProbe]):
     local_log_dir = result.file
     assert local_log_dir.is_dir()
     # Sort files locally after transferring them.
-    log_files = helper.sort_by_file_size(local_log_dir.glob("*"))
+    log_files = fs_helper.sort_by_file_size(local_log_dir.glob("*"))
     return LocalProbeResult(file=log_files)
diff --git a/crossbench/probes/video.py b/crossbench/probes/video.py
index e6d1c6b3..d7d88f71 100644
--- a/crossbench/probes/video.py
+++ b/crossbench/probes/video.py
@@ -7,14 +7,15 @@ from __future__ import annotations
 import atexit
 import logging
 import os
-import signal
 import subprocess
 import tempfile
-from typing import TYPE_CHECKING, Dict, List, Optional, TextIO, Tuple, Union
+from typing import TYPE_CHECKING, Dict, List, Self, TextIO, Tuple, Type
 
-from crossbench import helper
-from crossbench.probes.probe import (Probe, ProbeConfigParser, ProbeContext,
-                                     ProbeMissingDataError)
+from typing_extensions import override
+
+from crossbench.helper import collection_helper
+from crossbench.probes.probe import Probe, ProbeConfigParser, ProbeContext
+from crossbench.probes.probe_error import ProbeMissingDataError
 from crossbench.probes.result_location import ResultLocation
 from crossbench.probes.results import (EmptyProbeResult, LocalProbeResult,
                                        ProbeResult)
@@ -44,7 +45,8 @@ class VideoProbe(Probe):
   FRAMERATE = 60
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument(
         "generate_timestrip",
@@ -68,6 +70,7 @@ class VideoProbe(Probe):
     self._merge_runs = merge_runs
 
   @property
+  @override
   def result_path_name(self) -> str:
     return f"{self.name}.mp4"
 
@@ -79,6 +82,7 @@ class VideoProbe(Probe):
   def merge_runs(self) -> bool:
     return self._merge_runs
 
+  @override
   def validate_env(self, env: HostEnvironment) -> None:
     super().validate_env(env)
     if env.repetitions > 10:
@@ -117,9 +121,11 @@ class VideoProbe(Probe):
             f"Viewport size for {browser} is {viewport}, "
             f"which differs from first viewport {first_viewport}. ")
 
-  def get_context(self, run: Run) -> VideoProbeContext:
-    return VideoProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[VideoProbeContext]:
+    return VideoProbeContext
 
+  @override
   def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
     if not self.merge_runs:
       return LocalProbeResult()
@@ -136,7 +142,7 @@ class VideoProbe(Probe):
     group_files = [video_file]
     logging.info("VIDEO merge page repetitions")
     browser = group.browser
-    video_file_inputs: List[Union[str, LocalPath]] = []
+    video_file_inputs: List[str | LocalPath] = []
     for run in runs:
       video_file_inputs += ["-i", run.results[self].file_list[0]]
     draw_text = ("fontfile='/Library/Fonts/Arial.ttf':"
@@ -163,6 +169,7 @@ class VideoProbe(Probe):
 
     return LocalProbeResult(file=group_files)
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     """Merge story videos from multiple browser/configurations"""
     if not self.merge_runs:
@@ -170,8 +177,10 @@ class VideoProbe(Probe):
     groups = list(group.repetitions_groups)
     if len(groups) <= 1:
       return EmptyProbeResult()
-    grouped: Dict[Story, List[RepetitionsRunGroup]] = helper.group_by(
-        groups, key=lambda repetitions_group: repetitions_group.story)
+    grouped: Dict[Story,
+                  List[RepetitionsRunGroup]] = collection_helper.group_by(
+                      groups,
+                      key=lambda repetitions_group: repetitions_group.story)
 
     result_dir = group.get_local_probe_result_path(self)
     result_dir = result_dir / result_dir.stem
@@ -222,8 +231,8 @@ class VideoProbeContext(ProbeContext[VideoProbe]):
 
   def __init__(self, probe: VideoProbe, run: Run) -> None:
     super().__init__(probe, run)
-    self._record_process: Optional[subprocess.Popen] = None
-    self._recorder_log_file: Optional[TextIO] = None
+    self._record_process: subprocess.Popen | None = None
+    self._recorder_log_file: TextIO | None = None
 
   def start(self) -> None:
     browser = self.run.browser
@@ -271,9 +280,11 @@ class VideoProbeContext(ProbeContext[VideoProbe]):
       # The mac screencapture stops on the first (arbitrary) input.
       self._record_process.communicate(input=b"stop")
     elif self.browser_platform.is_android:
-      self._record_process.send_signal(signal.SIGINT)
+      assert not self._record_process.poll(), ("screencapture stopped early. ")
+      self.browser_platform.send_signal(
+          self._record_process, signal=self.browser_platform.signals.SIGINT)
     else:
-      self._record_process.terminate()
+      self.browser_platform.terminate(self._record_process)
 
   def teardown(self) -> ProbeResult:
     assert self._record_process, "Screen recorder stopped early."
@@ -299,10 +310,11 @@ class VideoProbeContext(ProbeContext[VideoProbe]):
 
   def stop_process(self) -> None:
     if self._record_process:
-      helper.wait_and_kill(self._record_process, timeout=5)
+      self.browser_platform.terminate_gracefully(self._record_process,
+                                                 timeout=5)
       self._record_process = None
 
-  def _convert_to_constant_framerate(self):
+  def _convert_to_constant_framerate(self) -> None:
     # On some platforms (android for certain) we get VFR videos which confuse
     # the next video extraction / conversion steps.
     vrf_video_result = (
diff --git a/crossbench/probes/web_page_replay/__init__.py b/crossbench/probes/web_page_replay/__init__.py
index a74d260c..67eefa28 100644
--- a/crossbench/probes/web_page_replay/__init__.py
+++ b/crossbench/probes/web_page_replay/__init__.py
@@ -1,3 +1,5 @@
 # Copyright 2023 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
+
+from __future__ import annotations
diff --git a/crossbench/probes/web_page_replay/recorder.py b/crossbench/probes/web_page_replay/recorder.py
index 51835311..dc7c8b7e 100644
--- a/crossbench/probes/web_page_replay/recorder.py
+++ b/crossbench/probes/web_page_replay/recorder.py
@@ -5,11 +5,13 @@
 from __future__ import annotations
 
 import shutil
-from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Union
+from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Self, Type
 
 from immutabledict import immutabledict
+from typing_extensions import override
 
-from crossbench import helper, plt
+from crossbench import plt
+from crossbench.helper.cwd import ChangeCWD
 from crossbench.helper.path_finder import WprGoToolFinder
 from crossbench.network.replay.web_page_replay import WprRecorder
 from crossbench.parse import PathParser
@@ -40,12 +42,13 @@ class WebPageReplayProbe(Probe):
   NAME = "wpr"
 
   @classmethod
-  def config_parser(cls) -> ProbeConfigParser:
+  @override
+  def config_parser(cls) -> ProbeConfigParser[Self]:
     parser = super().config_parser()
     parser.add_argument("http_port", type=int, default=8080, required=False)
     parser.add_argument("https_port", type=int, default=8081, required=False)
     parser.add_argument(
-        "wpr_go_bin", type=PathParser.binary_path, required=False)
+        "wpr_go_bin", type=plt.PLATFORM.parse_local_binary_path, required=False)
     parser.add_argument(
         "key_file", type=PathParser.existing_file_path, required=False)
     parser.add_argument(
@@ -74,7 +77,7 @@ class WebPageReplayProbe(Probe):
                key_file: Optional[LocalPath] = None,
                cert_file: Optional[LocalPath] = None,
                use_test_root_certificate: bool = False,
-               record_setup: bool = True):
+               record_setup: bool = True) -> None:
     super().__init__()
     host_platform = plt.PLATFORM
     if not wpr_go_bin:
@@ -82,8 +85,8 @@ class WebPageReplayProbe(Probe):
         wpr_go_bin = host_platform.local_path(local_wpr_path)
     if not wpr_go_bin:
       raise RuntimeError(f"Could not find wpr.go on {host_platform}")
-    self._wpr_go_bin: LocalPath = host_platform.local_path(
-        PathParser.binary_path(wpr_go_bin, "wpr.go"))
+    self._wpr_go_bin: LocalPath = host_platform.parse_local_binary_path(
+        wpr_go_bin, "wpr.go")
 
     self._recorder_kwargs: immutabledict[str, Any] = immutabledict(
         bin_path=wpr_go_bin,
@@ -120,25 +123,30 @@ class WebPageReplayProbe(Probe):
     return self._record_setup
 
   @property
+  @override
   def result_path_name(self) -> str:
     return "archive.wprgo"
 
   def is_compatible(self, browser: Browser) -> bool:
-    return browser.attributes.is_chromium_based and browser.platform.is_local
+    return browser.attributes().is_chromium_based and browser.platform.is_local
 
-  def get_context(self, run: Run) -> WprRecorderProbeContext:
-    return WprRecorderProbeContext(self, run)
+  @override
+  def get_context_cls(self) -> Type[WprRecorderProbeContext]:
+    return WprRecorderProbeContext
 
+  @override
   def merge_repetitions(self, group: RepetitionsRunGroup) -> ProbeResult:
     results = [run.results[self].file for run in group.runs]
     return self.merge_group(results, group)
 
+  @override
   def merge_stories(self, group: StoriesRunGroup) -> ProbeResult:
     results = [
         subgroup.results[self].file for subgroup in group.repetitions_groups
     ]
     return self.merge_group(results, group)
 
+  @override
   def merge_browsers(self, group: BrowsersRunGroup) -> ProbeResult:
     results = [subgroup.results[self].file for subgroup in group.story_groups]
     return self.merge_group(results, group)
@@ -153,11 +161,11 @@ class WebPageReplayProbe(Probe):
     shutil.copy(first_wprgo, result_file)
     for repetition_file in results:
       self.httparchive_merge(repetition_file, result_file)
-    return ProbeResult(file=[result_file])
+    return LocalProbeResult(file=[result_file])
 
   def httparchive_merge(self, input_archive: LocalPath,
                         output_archive: LocalPath) -> None:
-    cmd: List[Union[str, LocalPath]] = [
+    cmd: List[str | LocalPath] = [
         "go",
         "run",
         self._wpr_go_bin.parent / "httparchive.go",
@@ -166,7 +174,7 @@ class WebPageReplayProbe(Probe):
         input_archive,
         output_archive,
     ]
-    with helper.ChangeCWD(self._wpr_go_bin.parent):
+    with ChangeCWD(self._wpr_go_bin.parent):
       self.host_platform.sh(*cmd)
 
 
@@ -186,6 +194,7 @@ class WprRecorderProbeContext(ProbeContext[WebPageReplayProbe]):
     self._recorder = WprRecorder(**kwargs)
     self._browser_platform = run.browser_platform
 
+  @override
   def setup(self) -> None:
     self._recorder.start()
     self._setup_extra_flags()
@@ -227,5 +236,12 @@ class WprRecorderProbeContext(ProbeContext[WebPageReplayProbe]):
     pass
 
   def teardown(self) -> ProbeResult:
+    self._teardown_port_forwarding()
     self._recorder.stop()
     return LocalProbeResult(file=(self.local_result_path,))
+
+  def _teardown_port_forwarding(self) -> None:
+    if self._browser_platform.is_remote:
+      self._browser_platform.stop_reverse_port_forward(self._recorder.http_port)
+      self._browser_platform.stop_reverse_port_forward(
+          self._recorder.https_port)
diff --git a/crossbench/results_db/__init__.py b/crossbench/results_db/__init__.py
new file mode 100644
index 00000000..b20ab3aa
--- /dev/null
+++ b/crossbench/results_db/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/results_db/db.py b/crossbench/results_db/db.py
new file mode 100644
index 00000000..583095a3
--- /dev/null
+++ b/crossbench/results_db/db.py
@@ -0,0 +1,85 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+import logging
+from typing import TYPE_CHECKING, Iterable, List, Optional
+
+import sqlalchemy
+from sqlalchemy import orm
+
+from crossbench.results_db.records.base import BaseRecord
+from crossbench.results_db.records.browser import BrowserRecord
+from crossbench.results_db.records.platform import PlatformRecord
+from crossbench.results_db.records.run import RunRecord
+
+if TYPE_CHECKING:
+  from crossbench import path as pth
+  from crossbench.browsers.browser import Browser
+  from crossbench.plt.base import Platform
+  from crossbench.runner.run import Run
+
+
+class ResultsDB:
+
+  def __init__(self, db_file: Optional[pth.LocalPath] = None):
+    self._db_file: Optional[pth.LocalPath] = db_file
+    init_tables: bool = True
+    engine_url: str = "sqlite:///:memory:"
+    if db_file:
+      init_tables = not db_file.exists()
+      engine_url = f"sqlite:///{self._db_file}"
+    is_debug_logging = logging.getLogger().isEnabledFor(logging.DEBUG)
+    self._engine = sqlalchemy.create_engine(engine_url, echo=is_debug_logging)
+    if init_tables:
+      BaseRecord.metadata.create_all(self._engine)
+
+  @property
+  def is_in_memory(self) -> bool:
+    return not self._db_file
+
+  @property
+  def db_file(self) -> pth.LocalPath:
+    if not self._db_file:
+      raise RuntimeError("In-memory ResultDB has no DB file.")
+    return self._db_file
+
+  @property
+  def engine(self) -> sqlalchemy.engine.Engine:
+    return self._engine
+
+  @contextlib.contextmanager
+  def session(self):
+    with orm.Session(self._engine) as session:
+      yield session
+
+  def setup_runs(self, runs: List[Run]) -> None:
+    platforms = {run.browser_platform for run in runs}
+    self.add_platforms(platforms)
+    browsers = {run.browser for run in runs}
+    self.add_browsers(browsers)
+    self.add_runs(runs)
+
+  def add_runs(self, runs: List[Run]) -> None:
+    with self.session() as session:
+      for run in runs:
+        record = RunRecord.create(session, run)
+        session.add(record)
+      session.commit()
+
+  def add_platforms(self, platforms: Iterable[Platform]) -> None:
+    with self.session() as session:
+      for platform in set(platforms):
+        record = PlatformRecord.create(session, platform)
+        session.add(record)
+      session.commit()
+
+  def add_browsers(self, browsers: Iterable[Browser]) -> None:
+    with self.session() as session:
+      for browser in set(browsers):
+        record = BrowserRecord.create(session, browser)
+        session.add(record)
+      session.commit()
diff --git a/crossbench/results_db/records/__init__.py b/crossbench/results_db/records/__init__.py
new file mode 100644
index 00000000..b20ab3aa
--- /dev/null
+++ b/crossbench/results_db/records/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/crossbench/results_db/records/base.py b/crossbench/results_db/records/base.py
new file mode 100644
index 00000000..305d14e9
--- /dev/null
+++ b/crossbench/results_db/records/base.py
@@ -0,0 +1,11 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from sqlalchemy import orm
+
+
+class BaseRecord(orm.DeclarativeBase):
+  pass
diff --git a/crossbench/results_db/records/browser.py b/crossbench/results_db/records/browser.py
new file mode 100644
index 00000000..2c540bce
--- /dev/null
+++ b/crossbench/results_db/records/browser.py
@@ -0,0 +1,63 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Self
+
+from sqlalchemy import orm
+from sqlalchemy import types as orm_types
+from sqlalchemy.orm import Mapped
+from sqlalchemy.sql import schema as orm_schema
+
+from crossbench.results_db.records.base import BaseRecord
+from crossbench.results_db.records.platform import PlatformRecord
+
+if TYPE_CHECKING:
+  from crossbench.browsers.browser import Browser
+
+
+class BrowserRecord(BaseRecord):
+  __tablename__ = "browser"
+
+  @classmethod
+  def create(cls, session, browser: Browser) -> Self:
+    js_flags = ""
+    if browser.attributes().is_chromium_based:
+      js_flags = str(browser.js_flags)
+
+    return cls(
+        label=browser.label,
+        name=browser.type_name(),
+        path=str(browser.path),
+        version=str(browser.version),
+        channel=browser.version.channel_name,
+        flags=str(browser.flags),
+        js_flags=str(js_flags),
+        driver="N/A",
+        driver_version="N/A",
+        driver_path=str(browser.driver_path),
+        platform=session.query(PlatformRecord).filter(
+            PlatformRecord.name == browser.platform.name).first(),
+    )
+
+  label: Mapped[str] = orm.mapped_column(orm_types.String(), primary_key=True)
+  name: Mapped[str] = orm.mapped_column(orm_types.String())
+  path: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  version: Mapped[str] = orm.mapped_column(orm_types.String())
+  channel: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  flags: Mapped[str] = orm.mapped_column(orm_types.String())
+  js_flags: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  driver: Mapped[str] = orm.mapped_column(orm_types.String())
+  driver_version: Mapped[str] = orm.mapped_column(orm_types.String())
+  driver_path: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  platform_label: Mapped[int] = orm.mapped_column(
+      orm_schema.ForeignKey("platform.label"))
+  platform: Mapped[PlatformRecord] = orm.relationship()
+
+  # TODO: more settings
diff --git a/crossbench/results_db/records/platform.py b/crossbench/results_db/records/platform.py
new file mode 100644
index 00000000..9e37696f
--- /dev/null
+++ b/crossbench/results_db/records/platform.py
@@ -0,0 +1,58 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Self
+
+from sqlalchemy import orm
+from sqlalchemy import types as orm_types
+from sqlalchemy.orm import Mapped
+
+from crossbench.results_db.records.base import BaseRecord
+
+if TYPE_CHECKING:
+  from crossbench.plt.base import Platform
+
+
+class PlatformRecord(BaseRecord):
+  __tablename__ = "platform"
+
+  @classmethod
+  def create(cls, session, platform: Platform) -> Self:
+    del session
+    os_details = platform.os_details()
+    cpu_details = platform.cpu_details()
+    python_details = platform.python_details()
+
+    return cls(
+        label=str(platform),
+        name=platform.name,
+        os_name=os_details["system"],
+        os_version=os_details["release"],
+        os_version_name=os_details["version"],
+        cpu_architecture=str(platform.machine),
+        cpu_physical_cores=cpu_details["physical cores"],
+        cpu_logical_cores=cpu_details["logical cores"],
+        cpu_max_frequency=cpu_details.get("max frequency", "N/A"),
+        cpu_min_frequency=cpu_details.get("min frequency", "N/A"),
+        hw_model=platform.device,
+        python_version=python_details["version"])
+
+  label: Mapped[str] = orm.mapped_column(orm_types.String(), primary_key=True)
+  name: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  os_name: Mapped[str] = orm.mapped_column(orm_types.String())
+  os_version: Mapped[str] = orm.mapped_column(orm_types.String())
+  os_version_name: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  cpu_architecture: Mapped[str] = orm.mapped_column(orm_types.String())
+  cpu_physical_cores: Mapped[int] = orm.mapped_column(orm_types.Integer())
+  cpu_logical_cores: Mapped[int] = orm.mapped_column(orm_types.Integer())
+  cpu_max_frequency: Mapped[str] = orm.mapped_column(orm_types.String())
+  cpu_min_frequency: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  hw_model: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  python_version: Mapped[str] = orm.mapped_column(orm_types.String())
diff --git a/crossbench/results_db/records/run.py b/crossbench/results_db/records/run.py
new file mode 100644
index 00000000..00b85d04
--- /dev/null
+++ b/crossbench/results_db/records/run.py
@@ -0,0 +1,44 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing import TYPE_CHECKING, Self
+
+from sqlalchemy import orm
+from sqlalchemy import types as orm_types
+from sqlalchemy.orm import Mapped
+from sqlalchemy.sql import schema as orm_schema
+
+from crossbench.results_db.records.base import BaseRecord
+from crossbench.results_db.records.browser import BrowserRecord
+
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+
+
+class RunRecord(BaseRecord):
+  __tablename__ = "run"
+
+  @classmethod
+  def create(cls, session, run: Run) -> Self:
+    return cls(
+        index=run.index,
+        repetition=run.repetition,
+        cache_temperature=str(run.temperature),
+        name=run.name,
+        browser=session.query(BrowserRecord).filter(
+            BrowserRecord.label == run.browser.label).first(),
+        story=run.story.name)
+
+  index: Mapped[int] = orm.mapped_column(orm_types.Integer(), primary_key=True)
+  repetition: Mapped[int] = orm.mapped_column(orm_types.Integer())
+  cache_temperature: Mapped[str] = orm.mapped_column(orm_types.String())
+  name: Mapped[str] = orm.mapped_column(orm_types.String())
+
+  browser_label: Mapped[int] = orm.mapped_column(
+      orm_schema.ForeignKey("browser.label"))
+  browser: Mapped[BrowserRecord] = orm.relationship()
+
+  story: Mapped[str] = orm.mapped_column(orm_types.String())
diff --git a/crossbench/runner/actions.py b/crossbench/runner/actions.py
index f7bff62a..f4a77b7f 100644
--- a/crossbench/runner/actions.py
+++ b/crossbench/runner/actions.py
@@ -7,31 +7,43 @@ from __future__ import annotations
 import datetime as dt
 import logging
 import sys
-from typing import TYPE_CHECKING, Any, Optional, Sequence, Union
+from typing import TYPE_CHECKING, Any, Callable, Optional, Sequence, Type
 
-from crossbench import helper
+from crossbench.helper.durations import TimeScope
+from crossbench.parse import ObjectParser
 
 if TYPE_CHECKING:
+  from types import TracebackType
+
   from crossbench import plt
   from crossbench.browsers.browser import Browser
   from crossbench.exception import ExceptionAnnotationScope
   from crossbench.runner.run import Run
   from crossbench.runner.runner import Runner
-  from crossbench.runner.timing import Timing
+  from crossbench.runner.timing import AnyTimeUnit, Timing
+
+
+def _default_success_condition(js_result: Any) -> bool:
+  if js_result is True:
+    return True
 
+  ObjectParser.bool(js_result, strict=True)
 
-class Actions(helper.TimeScope):
+  return False
+
+class Actions(TimeScope):
 
   _max_end_datetime: dt.datetime
 
-  def __init__(self,
-               message: str,
-               run: Run,
-               runner: Optional[Runner] = None,
-               browser: Optional[Browser] = None,
-               verbose: bool = False,
-               measure: bool = True,
-               timeout: dt.timedelta = dt.timedelta()):
+  def __init__(
+      self,
+      message: str,
+      run: Run,
+      runner: Optional[Runner] = None,
+      browser: Optional[Browser] = None,
+      verbose: bool = False,
+      measure: bool = True,
+      timeout: dt.timedelta = dt.timedelta()) -> None:
     assert message, "Actions need a name"
     super().__init__(message)
     self._exception_annotation: ExceptionAnnotationScope = run.exceptions.info(
@@ -52,10 +64,6 @@ class Actions(helper.TimeScope):
   def timing(self) -> Timing:
     return self._runner.timing
 
-  @property
-  def run(self) -> Run:
-    return self._run
-
   @property
   def platform(self) -> plt.Platform:
     return self._run.browser_platform
@@ -72,13 +80,15 @@ class Actions(helper.TimeScope):
       sys.stdout.write(f"   {self._message.ljust(30)}\r")
     return self
 
-  def __exit__(self, exc_type, exc_value, exc_traceback) -> None:
+  def __exit__(self, exc_type: Optional[Type[BaseException]],
+               exc_value: Optional[BaseException],
+               exc_traceback: Optional[TracebackType]) -> None:
     self._is_active = False
     self._exception_annotation.__exit__(exc_type, exc_value, exc_traceback)
     super().__exit__(exc_type, exc_value, exc_traceback)
     logging.debug("Action end: %s", self._message)
     if self._measure:
-      self.run.durations[f"actions-duration {self.message}"] = self.duration
+      self._run.durations[f"actions-duration {self.message}"] = self.duration
 
   def _assert_is_active(self) -> None:
     assert self._is_active, "Actions have to be used in a with scope"
@@ -91,35 +101,39 @@ class Actions(helper.TimeScope):
 
   def js(self,
          js_code: str,
-         timeout: Union[int, float, dt.timedelta] = 10,
+         timeout: AnyTimeUnit = 10,
+         absolute_time: bool = False,
          arguments: Sequence[object] = (),
          **kwargs) -> Any:
     self._assert_is_active()
     assert js_code, "js_code must be a valid JS script"
     if kwargs:
       js_code = js_code.format(**kwargs)
-    delta = self.timing.timeout_timedelta(timeout)
+    delta = self.timing.timeout_timedelta(timeout, absolute_time)
     return self._browser.js(js_code, delta, arguments=arguments)
 
-  def wait_js_condition(self,
-                        js_code: str,
-                        min_wait: Union[dt.timedelta, float],
-                        timeout: Union[dt.timedelta, float],
-                        delay: Union[dt.timedelta, float] = 0) -> None:
-    wait_range = helper.WaitRange(
-        min=self.timing.timedelta(min_wait),
-        timeout=self.timing.timeout_timedelta(timeout),
-        delay=delay)
+  def wait_js_condition(
+      self,
+      js_code: str,
+      min_wait: AnyTimeUnit,
+      timeout: AnyTimeUnit,
+      delay: AnyTimeUnit = 0,
+      absolute_time: bool = False,
+      arguments: Sequence[object] = (),
+      success_condition: Callable[[Any], bool] = _default_success_condition
+  ) -> None:
+    wait_range = self._run.wait_range(min_wait, timeout, delay)
     assert "return" in js_code, (
         f"Missing return statement in js-wait code: {js_code}")
-    for _, time_left in wait_range.wait_with_backoff():
-      time_units = self.timing.units(time_left)
-      result = self.js(js_code, timeout=time_units, absolute_time=True)
-      if result:
+    for _, _, time_left in wait_range.wait_with_backoff():
+      time_units = self.timing.units(time_left, absolute_time)
+      result = self.js(
+          js_code,
+          timeout=time_units,
+          absolute_time=absolute_time,
+          arguments=arguments)
+      if success_condition(result):
         return
-      assert result is False, (
-          f"js_code did not return a bool, but got: {result}\n"
-          f"js-code: {js_code}")
 
   def show_url(self, url: str, target: Optional[str] = None) -> None:
     self._assert_is_active()
@@ -131,8 +145,8 @@ class Actions(helper.TimeScope):
         raise ValueError(f"Invalid target: {target}")
       self._browser.show_url(url, target=target)
 
-  def wait(
-      self, seconds: Union[dt.timedelta,
-                           float] = dt.timedelta(seconds=1)) -> None:
+  def wait(self,
+           time: AnyTimeUnit = dt.timedelta(seconds=1),
+           absolute_time: bool = False) -> None:
     self._assert_is_active()
-    self.platform.sleep(seconds)
+    self._runner.wait(time, absolute_time)
diff --git a/crossbench/runner/groups/base.py b/crossbench/runner/groups/base.py
index f97a143d..aa4f2e65 100644
--- a/crossbench/runner/groups/base.py
+++ b/crossbench/runner/groups/base.py
@@ -5,7 +5,7 @@
 from __future__ import annotations
 
 import abc
-from typing import TYPE_CHECKING, Iterable, Optional
+from typing import TYPE_CHECKING, Iterable
 
 from crossbench import exception
 from crossbench.probes.results import ProbeResult, ProbeResultDict
@@ -15,15 +15,15 @@ if TYPE_CHECKING:
   from crossbench.probes.probe import Probe
   from crossbench.runner.run import Run
   from crossbench.runner.runner import Runner
-  from crossbench.types import JsonDict
+  from crossbench.types import JsonMapping
 
 
 class RunGroup(abc.ABC):
 
   def __init__(self, throw: bool = False) -> None:
     self._exceptions = exception.Annotator(throw)
-    self._path: Optional[LocalPath] = None
-    self._merged_probe_results: Optional[ProbeResultDict] = None
+    self._path: LocalPath | None = None
+    self._merged_probe_results: ProbeResultDict | None = None
 
   def _set_path(self, path: LocalPath) -> None:
     assert self._path is None
@@ -69,7 +69,7 @@ class RunGroup(abc.ABC):
         yield run
 
   @property
-  def info(self) -> JsonDict:
+  def info(self) -> JsonMapping:
     return {
         "runs": len(tuple(self.runs)),
         "failed runs": len(tuple(self.failed_runs))
diff --git a/crossbench/runner/groups/browsers.py b/crossbench/runner/groups/browsers.py
index 355d8e1b..63bc9141 100644
--- a/crossbench/runner/groups/browsers.py
+++ b/crossbench/runner/groups/browsers.py
@@ -6,6 +6,8 @@ from __future__ import annotations
 
 from typing import TYPE_CHECKING, Iterable
 
+from typing_extensions import override
+
 from crossbench.runner.groups.base import RunGroup
 
 if TYPE_CHECKING:
@@ -43,13 +45,16 @@ class BrowsersRunGroup(RunGroup):
       yield from story_group.repetitions_groups
 
   @property
+  @override
   def runs(self) -> Iterable[Run]:
     for group in self._story_groups:
       yield from group.runs
 
   @property
+  @override
   def info_stack(self) -> exception.TInfoStack:
     return ("Merging results from multiple browsers",)
 
+  @override
   def _merge_probe_results(self, probe: Probe) -> ProbeResult:
     return probe.merge_browsers(self)
diff --git a/crossbench/runner/groups/cache_temperatures.py b/crossbench/runner/groups/cache_temperatures.py
index 2e7e223d..bc3a5ba0 100644
--- a/crossbench/runner/groups/cache_temperatures.py
+++ b/crossbench/runner/groups/cache_temperatures.py
@@ -4,9 +4,11 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Iterable, List, Optional, Tuple
+from typing import TYPE_CHECKING, Iterable, List, Tuple
 
-from crossbench import helper
+from typing_extensions import override
+
+from crossbench.helper import collection_helper
 from crossbench.runner.groups.base import RunGroup
 
 if TYPE_CHECKING:
@@ -15,9 +17,8 @@ if TYPE_CHECKING:
   from crossbench.probes.probe import Probe
   from crossbench.probes.results import ProbeResult
   from crossbench.runner.run import Run
-  from crossbench.runner.runner import Runner
   from crossbench.stories.story import Story
-  from crossbench.types import JsonDict
+  from crossbench.types import JsonDict, JsonMapping
 
 
 class CacheTemperaturesRunGroup(RunGroup):
@@ -31,17 +32,17 @@ class CacheTemperaturesRunGroup(RunGroup):
              runs: Iterable[Run],
              throw: bool = False) -> Tuple[CacheTemperaturesRunGroup, ...]:
     return tuple(
-        helper.group_by(
+        collection_helper.group_by(
             runs,
             key=lambda run: (run.story, run.browser, run.repetition),
             group=lambda _: cls(throw),
             sort_key=None).values())
 
-  def __init__(self, throw: bool = False):
+  def __init__(self, throw: bool = False) -> None:
     super().__init__(throw)
     self._runs: List[Run] = []
-    self._story: Optional[Story] = None
-    self._browser: Optional[Browser] = None
+    self._story: Story | None = None
+    self._browser: Browser | None = None
     self._repetition = -1
     self._cache_temperature = ""
 
@@ -58,6 +59,7 @@ class CacheTemperaturesRunGroup(RunGroup):
     self._runs.append(run)
 
   @property
+  @override
   def runs(self) -> Iterable[Run]:
     return iter(self._runs)
 
@@ -76,6 +78,7 @@ class CacheTemperaturesRunGroup(RunGroup):
     return self._browser
 
   @property
+  @override
   def info_stack(self) -> exception.TInfoStack:
     return (
         "Merging results from multiple cache temperatures",
@@ -85,13 +88,15 @@ class CacheTemperaturesRunGroup(RunGroup):
     )
 
   @property
-  def info(self) -> JsonDict:
-    info = {
+  @override
+  def info(self) -> JsonMapping:
+    info: JsonDict = {
         "story": str(self.story),
         "repetition": self.repetition,
     }
     info.update(super().info)
     return info
 
+  @override
   def _merge_probe_results(self, probe: Probe) -> ProbeResult:
     return probe.merge_cache_temperatures(self)
diff --git a/crossbench/runner/groups/repetitions.py b/crossbench/runner/groups/repetitions.py
index d2625883..13ebf8ec 100644
--- a/crossbench/runner/groups/repetitions.py
+++ b/crossbench/runner/groups/repetitions.py
@@ -4,9 +4,11 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Dict, Iterable, List, Optional, Tuple
+from typing import TYPE_CHECKING, Dict, Iterable, List, Tuple
 
-from crossbench import helper
+from typing_extensions import override
+
+from crossbench.helper import collection_helper
 from crossbench.path import LocalPath
 from crossbench.runner.groups.base import RunGroup
 
@@ -19,7 +21,7 @@ if TYPE_CHECKING:
       CacheTemperaturesRunGroup
   from crossbench.runner.run import Run
   from crossbench.stories.story import Story
-  from crossbench.types import JsonDict
+  from crossbench.types import JsonDict, JsonMapping
 
 
 class RepetitionsRunGroup(RunGroup):
@@ -33,19 +35,19 @@ class RepetitionsRunGroup(RunGroup):
              run_groups: Iterable[CacheTemperaturesRunGroup],
              throw: bool = False) -> Tuple[RepetitionsRunGroup, ...]:
     return tuple(
-        helper.group_by(
+        collection_helper.group_by(
             run_groups,
             key=lambda group: (group.browser, group.story),
             group=lambda _: cls(throw),
             sort_key=None).values())
 
-  def __init__(self, throw: bool = False):
+  def __init__(self, throw: bool = False) -> None:
     super().__init__(throw)
     self._cache_temperatures_groups: List[CacheTemperaturesRunGroup] = []
     self._cache_temperature_repetitions_groups: Dict[
         str, CacheTemperatureRepetitionsRunGroup] = {}
-    self._story: Optional[Story] = None
-    self._browser: Optional[Browser] = None
+    self._story: Story | None = None
+    self._browser: Browser | None = None
 
   def append(self, group: CacheTemperaturesRunGroup) -> None:
     if self._path is None:
@@ -87,21 +89,25 @@ class RepetitionsRunGroup(RunGroup):
     return list(self._cache_temperature_repetitions_groups.values())
 
   @property
+  @override
   def runs(self) -> Iterable[Run]:
     for group in self._cache_temperatures_groups:
       yield from group.runs
 
   @property
+  @override
   def info_stack(self) -> exception.TInfoStack:
     return ("Merging results from multiple repetitions",
             f"browser={self.browser.unique_name}", f"story={self.story}")
 
   @property
-  def info(self) -> JsonDict:
+  @override
+  def info(self) -> JsonMapping:
     info: JsonDict = {"story": str(self.story)}
     info.update(super().info)
     return info
 
+  @override
   def _merge_probe_results(self, probe: Probe) -> ProbeResult:
     return probe.merge_repetitions(self)
 
@@ -114,7 +120,7 @@ class CacheTemperatureRepetitionsRunGroup(RunGroup):
 
   def __init__(self,
                repetitions_group: RepetitionsRunGroup,
-               throw: bool = False):
+               throw: bool = False) -> None:
     super().__init__(throw)
     self._repetitions_group = repetitions_group
     self._set_path(repetitions_group.path)
@@ -134,6 +140,7 @@ class CacheTemperatureRepetitionsRunGroup(RunGroup):
     return self._repetitions_group.browser
 
   @property
+  @override
   def path(self) -> LocalPath:
     return self._repetitions_group.path
 
@@ -142,18 +149,21 @@ class CacheTemperatureRepetitionsRunGroup(RunGroup):
     return self._cache_temperature
 
   @property
+  @override
   def runs(self) -> Iterable[Run]:
     return iter(self._runs)
 
   @property
+  @override
   def info_stack(self) -> exception.TInfoStack:
     info_stack = self.repetitions_group.info_stack
     info_stack += (f"cache_temperature={self.cache_temperature}",)
     return info_stack
 
   @property
-  def info(self) -> JsonDict:
-    info = self._repetitions_group.info
+  @override
+  def info(self) -> JsonMapping:
+    info: JsonMapping = self._repetitions_group.info
     return info
 
   def append(self, run: Run) -> None:
@@ -162,5 +172,6 @@ class CacheTemperatureRepetitionsRunGroup(RunGroup):
     assert self._cache_temperature == run.temperature
     self._runs.append(run)
 
+  @override
   def _merge_probe_results(self, probe: Probe) -> ProbeResult:
     raise NotImplementedError("Unsupported")
diff --git a/crossbench/runner/groups/session.py b/crossbench/runner/groups/session.py
index b3e9a4e4..4b326eb4 100644
--- a/crossbench/runner/groups/session.py
+++ b/crossbench/runner/groups/session.py
@@ -9,10 +9,13 @@ import enum
 import logging
 from typing import TYPE_CHECKING, Iterable, Iterator, List, Optional, Tuple
 
+from typing_extensions import override
+
 from crossbench.exception import TInfoStack
 from crossbench.flags.base import Flags
 from crossbench.flags.js_flags import JSFlags
-from crossbench.helper import ChangeCWD, Durations
+from crossbench.helper.cwd import ChangeCWD
+from crossbench.helper.durations import Durations
 from crossbench.helper.state import BaseState, StateMachine
 from crossbench.probes.probe_context import ProbeSessionContext
 from crossbench.probes.results import EmptyProbeResult, ProbeResultDict
@@ -31,7 +34,7 @@ if TYPE_CHECKING:
   from crossbench.probes.results import ProbeResult
   from crossbench.runner.run import Run
   from crossbench.runner.timing import Timing
-  from crossbench.types import JsonDict
+  from crossbench.types import JsonDict, JsonMapping
 
 
 @enum.unique
@@ -66,7 +69,7 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     self._index: int = index
     self._runs: List[Run] = []
     self._root_dir: LocalPath = root_dir
-    self._browser_tmp_dir: Optional[AnyPath] = None
+    self._browser_tmp_dir: AnyPath | None = None
     self._extra_js_flags = JSFlags()
     self._extra_flags = extra_flags
     # Temporary objects, reset after all runs are ready (see set_ready).
@@ -134,6 +137,7 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     return self.raw_session_dir
 
   @property
+  @override
   def out_dir(self) -> LocalPath:
     return self._get_session_dir()
 
@@ -150,6 +154,7 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     return self._env
 
   @property
+  @override
   def probes(self) -> Iterable[Probe]:
     return iter(self._probes)
 
@@ -158,6 +163,7 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     return self._network
 
   @property
+  @override
   def browser(self) -> Browser:
     return self._browser
 
@@ -174,6 +180,7 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     return self._root_dir
 
   @property
+  @override
   def runs(self) -> Iterable[Run]:
     return iter(self._runs)
 
@@ -197,18 +204,20 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     assert isinstance(details_json["flags"], tuple)
     details_json["flags"] += tuple(self._extra_flags)
 
-  def setup_selenium_options(self, options: ArgOptions):
+  def setup_selenium_options(self, options: ArgOptions) -> None:
     # Using only the first run, since all runs need to have the same probes.
     self.first_run.setup_selenium_options(options)
 
   @property
+  @override
   def info_stack(self) -> TInfoStack:
     return ("Merging results from multiple browser sessions",
             f"browser={self.browser.unique_name}", f"session={self.index}")
 
   @property
-  def info(self) -> JsonDict:
-    info_dict = super().info
+  @override
+  def info(self) -> JsonMapping:
+    info_dict = dict(super().info)
     info_dict.update({"index": self.index})
     return info_dict
 
@@ -216,16 +225,19 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     return f"Session({self.browser}, {self.index})"
 
   @property
+  @override
   def browser_tmp_dir(self) -> AnyPath:
     if not self._browser_tmp_dir:
       prefix = f"cb_browser_session_{self.index}"
       self._browser_tmp_dir = self.browser_platform.mkdtemp(prefix)
     return self._browser_tmp_dir
 
+  @override
   def merge(self, probes: Iterable[Probe]) -> None:
     # TODO: implement merging of session probes
     pass
 
+  @override
   def _merge_probe_results(self, probe: Probe) -> ProbeResult:
     return EmptyProbeResult()
 
@@ -279,7 +291,7 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
 
   def _setup_browser(self) -> None:
     self._state.expect(State.SETUP)
-    self.browser.setup_binary()
+    self.browser.setup()
 
   def _setup_session_dir(self) -> None:
     self._state.expect(State.SETUP)
@@ -288,9 +300,6 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
       if not self._create_symlinks:
         logging.debug("Symlink disabled by command line option")
         return
-      if self.host_platform.is_win:
-        logging.debug("Skipping session_dir symlink on windows.")
-        return
       if self.is_single_run:
         # If there is a single run per session we reuse the run-dir.
         self.raw_session_dir.parent.mkdir(parents=True, exist_ok=True)
@@ -331,7 +340,8 @@ class BrowserSessionRunGroup(RunGroup, ResultOrigin):
     with self.measure("browser-setup"):
       try:
         # pytype somehow gets the package path wrong here, disabling for now.
-        self._browser.setup(self)
+        self._browser.start(self)
+        assert self._browser.is_running, "Browser did not start up correctly"
       except Exception as e:
         logging.debug("Browser setup failed: %s", e)
         # Clean up half-setup browser instances
@@ -369,7 +379,7 @@ class ProbeSessionContextManager(ProbeContextManager[BrowserSessionRunGroup,
                                                      ProbeSessionContext]):
 
   def __init__(self, session: BrowserSessionRunGroup,
-               probe_results: ProbeResultDict):
+               probe_results: ProbeResultDict) -> None:
     super().__init__(session, probe_results)
 
   def get_probe_context(self, probe: Probe) -> Optional[ProbeSessionContext]:
diff --git a/crossbench/runner/groups/stories.py b/crossbench/runner/groups/stories.py
index 97b0a741..6e76dfed 100644
--- a/crossbench/runner/groups/stories.py
+++ b/crossbench/runner/groups/stories.py
@@ -4,9 +4,11 @@
 
 from __future__ import annotations
 
-from typing import TYPE_CHECKING, Iterable, List, Optional, Tuple
+from typing import TYPE_CHECKING, Iterable, List, Tuple
 
-from crossbench import helper
+from typing_extensions import override
+
+from crossbench.helper import collection_helper
 from crossbench.runner.groups.base import RunGroup
 
 if TYPE_CHECKING:
@@ -19,7 +21,7 @@ if TYPE_CHECKING:
   from crossbench.runner.groups.repetitions import RepetitionsRunGroup
   from crossbench.runner.run import Run
   from crossbench.stories.story import Story
-  from crossbench.types import JsonDict
+  from crossbench.types import JsonDict, JsonMapping
 
 
 class StoriesRunGroup(RunGroup):
@@ -30,14 +32,14 @@ class StoriesRunGroup(RunGroup):
   def __init__(self, throw: bool = False) -> None:
     super().__init__(throw)
     self._repetitions_groups: List[RepetitionsRunGroup] = []
-    self._browser: Optional[Browser] = None
+    self._browser: Browser | None = None
 
   @classmethod
   def groups(cls,
              run_groups: Iterable[RepetitionsRunGroup],
              throw: bool = False) -> Tuple[StoriesRunGroup, ...]:
     return tuple(
-        helper.group_by(
+        collection_helper.group_by(
             run_groups,
             key=lambda run_group: run_group.browser,
             group=lambda _: cls(throw),
@@ -61,6 +63,7 @@ class StoriesRunGroup(RunGroup):
       yield from group.cache_temperatures_groups
 
   @property
+  @override
   def runs(self) -> Iterable[Run]:
     for group in self._repetitions_groups:
       yield from group.runs
@@ -75,6 +78,7 @@ class StoriesRunGroup(RunGroup):
     return (group.story for group in self._repetitions_groups)
 
   @property
+  @override
   def info_stack(self) -> exception.TInfoStack:
     return (
         "Merging results from multiple stories",
@@ -82,11 +86,14 @@ class StoriesRunGroup(RunGroup):
     )
 
   @property
-  def info(self) -> JsonDict:
-    info = {
+  @override
+  def info(self) -> JsonMapping:
+    info: JsonDict = {
         "label": self.browser.label,
         "browser": self.browser.app_name.title(),
-        "version": self.browser.version,
+        "version": self.browser.version.parts_str,
+        "major_version": self.browser.version.major,
+        "channel": self.browser.version.channel_name,
         "os": self.browser.platform.full_version,
         "device": self.browser.platform.device,
         "cpu": self.browser.platform.cpu,
@@ -98,5 +105,6 @@ class StoriesRunGroup(RunGroup):
     info.update(super().info)
     return info
 
+  @override
   def _merge_probe_results(self, probe: Probe) -> ProbeResult:
     return probe.merge_stories(self)
diff --git a/crossbench/runner/groups/thread.py b/crossbench/runner/groups/thread.py
index aa9ff668..4f17d60c 100644
--- a/crossbench/runner/groups/thread.py
+++ b/crossbench/runner/groups/thread.py
@@ -25,7 +25,10 @@ class RunThreadGroup(threading.Thread):
   - If runs are executed in parallel, multiple RunThreadGroup are used
   """
 
-  def __init__(self, runs: Iterable[Run], index=0, throw: bool = False) -> None:
+  def __init__(self,
+               runs: Iterable[Run],
+               index: int = 0,
+               throw: bool = False) -> None:
     super().__init__()
     self._index = index
     self._exceptions = exception.Annotator(throw)
@@ -82,7 +85,7 @@ class RunThreadGroup(threading.Thread):
   def is_success(self) -> bool:
     return self._exceptions.is_success
 
-  def _log_run(self, run: Run):
+  def _log_run(self, run: Run) -> None:
     logging.info("=" * 80)
     label = ""
     if run.is_warmup:
@@ -124,10 +127,11 @@ class RunThreadGroup(threading.Thread):
     if not browser_session.is_single_run:
       self._log_run(run)
     if not run.is_success:
-      logging.info("%s: Skipping %s due to setup errors.", self, run)
-    else:
-      run.run(self.is_dry_run)
+      logging.warning("%s: Got setup errors.", run)
+    run.run(self.is_dry_run)
+    run.log_annotations()
     if run.is_success:
       run.log_results()
     else:
       browser_session.exceptions.extend(run.exceptions)
+      run.log_failure()
diff --git a/crossbench/runner/probe_context_manager.py b/crossbench/runner/probe_context_manager.py
index 67b2fa0d..dc3fb96e 100644
--- a/crossbench/runner/probe_context_manager.py
+++ b/crossbench/runner/probe_context_manager.py
@@ -27,11 +27,14 @@ ProbeContextT = TypeVar("ProbeContextT", bound=BaseProbeContext)
 class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
 
   def __init__(self, result_origin: ResultOriginT,
-               probe_results: ProbeResultDict):
+               probe_results: ProbeResultDict) -> None:
     self._state = StateMachine(State.INITIAL)
     self._origin = result_origin
     self._probe_results = probe_results
     self._probe_contexts: Dict[Type[Probe], ProbeContextT] = {}
+    # Contains all probe context where the setup succeeded.
+    self._setup_probe_contexts: List[ProbeContextT] = []
+    self._failed_probe_contexts: List[ProbeContextT] = []
     # TODO: either prefix timers or use custom duration
     self._durations = result_origin.durations
     self._exceptions = result_origin.exceptions
@@ -44,11 +47,15 @@ class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
   def is_running(self) -> bool:
     return self._state == State.RUN
 
-  def measure(self, name):
+  @property
+  def is_success(self) -> bool:
+    return self._exceptions.is_success
+
+  def _measure(self, name: str):
     return self._origin.measure(name)
 
   @contextlib.contextmanager
-  def capture(self, label: str, measure: bool = False):
+  def _capture(self, label: str, measure: bool = False):
     with self._exceptions.capture(label):
       if not measure:
         yield
@@ -56,27 +63,22 @@ class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
         with self._origin.durations.measure(label):
           yield
 
-  @property
-  def is_success(self) -> bool:
-    return self._exceptions.is_success
-
-  def setup(self, probes: Iterable[Probe], is_dry_run: bool):
+  def setup(self, probes: Iterable[Probe], is_dry_run: bool) -> None:
     self._state.transition(State.INITIAL, to=State.SETUP)
     if not is_dry_run:
-      if not self._setup_probes(tuple(probes), is_dry_run):
-        return
+      self._setup_probes(tuple(probes))
     self._state.transition(State.SETUP, to=State.READY)
 
-  def _setup_probes(self, probes: Tuple[Probe, ...], is_dry_run: bool) -> bool:
-    with self.capture("probes-setup", measure=True):
+  def _setup_probes(self, probes: Tuple[Probe, ...]) -> bool:
+    # We always have internal probes
+    assert probes, "No probes provided"
+    with self._capture("probes-setup", measure=True):
       self._validate_probes(probes)
       self._create_contexts(probes)
       self._setup_contexts()
-    if not self.is_success:
-      self._handle_setup_error(is_dry_run)
     return self.is_success
 
-  def _validate_probes(self, probes: Tuple[Probe, ...]):
+  def _validate_probes(self, probes: Tuple[Probe, ...]) -> None:
     assert not self._probe_contexts, "Wrong probe context initialization order"
     probe_set = set()
     for probe in probes:
@@ -85,31 +87,28 @@ class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
       assert probe.is_attached, (
           f"Probe {probe.name} is not properly attached to a browser")
 
-  def _create_contexts(self, probes: Tuple[Probe, ...]):
+  def _create_contexts(self, probes: Tuple[Probe, ...]) -> None:
+    unique_contexts = set()
     for probe in probes:
       if probe.PRODUCES_DATA:
         self._probe_results[probe] = EmptyProbeResult()
-      with self.capture(f"{probe.name} get_context"):
+      with self._capture(f"{probe.name} get_context"):
         if probe_context := self.get_probe_context(probe):
+          assert probe_context not in unique_contexts
+          unique_contexts.add(probe_context)
           probe_cls = type(probe)
           assert probe_cls not in self._probe_contexts
           self._probe_contexts[probe_cls] = probe_context
 
-  def _setup_contexts(self):
+  def _setup_contexts(self) -> None:
     for probe_context in self._probe_contexts.values():
-      with self.capture(f"probes-setup {probe_context.name}"):
-        probe_context.setup()
-
-  def _handle_setup_error(self, is_dry_run: bool) -> None:
-    self._state.transition(State.SETUP, to=State.DONE)
-    logging.debug("Handling setup error")
-    assert not self.is_success
-    # Special handling for crucial runner probes
-    internal_probe_contexts = [
-        context for context in self._probe_contexts.values()
-        if context.probe.is_internal
-    ]
-    self._teardown(internal_probe_contexts, is_dry_run, setup_error=True)
+      with self._capture(f"probes-setup {probe_context.name}"):
+        try:
+          probe_context.setup()
+          self._setup_probe_contexts.append(probe_context)
+        except:
+          self._failed_probe_contexts.append(probe_context)
+          raise
 
   @contextlib.contextmanager
   def open(self, is_dry_run: bool):
@@ -117,7 +116,7 @@ class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
     probe_start_time = dt.datetime.now()
     combined_contexts = contextlib.ExitStack()
 
-    for probe_context in self._probe_contexts.values():
+    for probe_context in self._setup_probe_contexts:
       probe_context.set_start_time(probe_start_time)
       if not is_dry_run:
         combined_contexts.enter_context(probe_context.open())
@@ -126,12 +125,13 @@ class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
       self._durations["probes-start"] = dt.datetime.now() - probe_start_time
       yield self
 
-  def teardown(self, is_dry_run: bool, setup_error: bool = False) -> None:
+  def teardown(self, is_dry_run: bool) -> None:
     self._state.transition(State.READY, State.RUN, to=State.DONE)
-    with self.measure("probes-teardown"):
-      self._teardown(
-          list(self._probe_contexts.values()), is_dry_run, setup_error)
+    with self._measure("probes-teardown"):
+      self._teardown(self._setup_probe_contexts, is_dry_run)
       self._probe_contexts = {}
+      self._setup_probe_contexts = []
+      self._failed_probe_contexts = []
 
   def _teardown(self,
                 probe_contexts: List[ProbeContextT],
@@ -144,7 +144,7 @@ class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
     if is_dry_run:
       return
     for probe_context in reversed(probe_contexts):
-      with self.capture(f"Probe {probe_context.name} teardown", measure=True):
+      with self._capture(f"Probe {probe_context.name} teardown", measure=True):
         assert probe_context.result_origin == self._origin
         probe_results: ProbeResult = probe_context.teardown()
         probe = probe_context.probe
@@ -157,6 +157,10 @@ class ProbeContextManager(Generic[ResultOriginT, ProbeContextT], abc.ABC):
   def get_probe_context(self, probe: Probe) -> Optional[ProbeContextT]:
     pass
 
-  def find_probe_context(self,
-                         cls: Type[ProbeT]) -> Optional[ProbeContext[ProbeT]]:
-    return self._probe_contexts.get(cls)
+  def find_probe_context(
+      self, probe_cls: Type[ProbeT]) -> Optional[ProbeContext[ProbeT]]:
+    if probe_context := self._probe_contexts.get(probe_cls):
+      assert isinstance(probe_context.probe, probe_cls), (
+          f"Expected instance of {probe_cls}: got {probe_context.probe}")
+      return probe_context  # type: ignore
+    return None
diff --git a/crossbench/runner/probe_result_origin.py b/crossbench/runner/probe_result_origin.py
new file mode 100644
index 00000000..b8d5c15d
--- /dev/null
+++ b/crossbench/runner/probe_result_origin.py
@@ -0,0 +1,35 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import typing
+from typing import TYPE_CHECKING
+
+if TYPE_CHECKING:
+  from crossbench import path as pth
+  from crossbench.plt.base import Platform
+
+
+class ProbeResultOrigin(typing.Protocol):
+
+  @property
+  def browser_platform(self) -> Platform:
+    raise NotImplementedError()
+
+  @property
+  def host_platform(self) -> Platform:
+    raise NotImplementedError()
+
+  @property
+  def browser_tmp_dir(self) -> pth.AnyPath:
+    raise NotImplementedError()
+
+  @property
+  def is_remote(self) -> bool:
+    raise NotImplementedError()
+
+  @property
+  def out_dir(self) -> pth.LocalPath:
+    raise NotImplementedError()
diff --git a/crossbench/runner/result_origin.py b/crossbench/runner/result_origin.py
index 698a1f47..15eecb58 100644
--- a/crossbench/runner/result_origin.py
+++ b/crossbench/runner/result_origin.py
@@ -10,20 +10,24 @@ import logging
 from collections.abc import Generator
 from typing import TYPE_CHECKING, Iterable, Tuple
 
+from typing_extensions import override
+
 from crossbench import plt
-from crossbench.helper import DurationMeasureContext, Durations
+from crossbench.decor.target_protocol import DecoratorTargetProtocol
 from crossbench.probes.result_location import ResultLocation
+from crossbench.runner.probe_result_origin import ProbeResultOrigin
 
 if TYPE_CHECKING:
   from crossbench.browsers.browser import Browser
   from crossbench.exception import (Annotator, ExceptionAnnotationScope,
                                     TExceptionTypes)
+  from crossbench.helper.durations import DurationMeasureContext, Durations
   from crossbench.path import AnyPath, LocalPath
   from crossbench.probes.probe import Probe
   from crossbench.runner.runner import Runner
 
 
-class ResultOrigin(abc.ABC):
+class ResultOrigin(DecoratorTargetProtocol, ProbeResultOrigin, abc.ABC):
   """Base class for Run and BrowserSession, both places where
   probe results can be placed."""
 
@@ -32,6 +36,7 @@ class ResultOrigin(abc.ABC):
     return self.browser_platform.is_local
 
   @property
+  @override
   def is_remote(self) -> bool:
     return self.browser_platform.is_remote
 
@@ -66,10 +71,12 @@ class ResultOrigin(abc.ABC):
         f"Cannot access on runner on {type(self).__name__}")
 
   @property
+  @override
   def host_platform(self) -> plt.Platform:
     return self.browser.host_platform
 
   @property
+  @override
   def browser_platform(self) -> plt.Platform:
     return self.browser.platform
 
@@ -92,7 +99,8 @@ class ResultOrigin(abc.ABC):
   def exception_info(self, *stack_entries: str) -> ExceptionAnnotationScope:
     return self.exceptions.info(*stack_entries)
 
-  def exception_handler(
+  @override
+  def exception_capture(
       self, *stack_entries: str, exceptions: TExceptionTypes = (Exception,)
   ) -> ExceptionAnnotationScope:
     return self.exceptions.capture(*stack_entries, exceptions=exceptions)
diff --git a/crossbench/runner/run.py b/crossbench/runner/run.py
index 7a82f8ca..569eaf28 100644
--- a/crossbench/runner/run.py
+++ b/crossbench/runner/run.py
@@ -7,12 +7,18 @@ from __future__ import annotations
 import datetime as dt
 import enum
 import logging
-from typing import TYPE_CHECKING, Optional, Type
+from typing import TYPE_CHECKING, Iterable, Optional, Set, Type
+
+from typing_extensions import override
 
-from crossbench import compat
 from crossbench import path as pth
+from crossbench.browsers.splash_screen import SplashScreenData
+from crossbench.cli.config.secrets import Secrets
+from crossbench.env import ValidationError
 from crossbench.exception import Annotator, TInfoStack
-from crossbench.helper import ChangeCWD, Durations, Spinner
+from crossbench.helper.cwd import ChangeCWD
+from crossbench.helper.durations import Durations
+from crossbench.helper.spinner import Spinner
 from crossbench.helper.state import State, StateMachine
 from crossbench.probes.probe_context import ProbeContext
 from crossbench.probes.results import ProbeResultDict
@@ -20,7 +26,9 @@ from crossbench.runner.actions import Actions
 from crossbench.runner.exception import StopStoryException
 from crossbench.runner.probe_context_manager import ProbeContextManager
 from crossbench.runner.result_origin import ResultOrigin
+from crossbench.runner.run_annotation import RunAnnotation
 from crossbench.runner.timing import Timing
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 if TYPE_CHECKING:
   from selenium.webdriver.common.options import ArgOptions
@@ -28,16 +36,18 @@ if TYPE_CHECKING:
   from crossbench.benchmarks.base import Benchmark
   from crossbench.browsers.browser import Browser
   from crossbench.env import HostEnvironment
+  from crossbench.helper.wait import WaitRange
   from crossbench.probes.probe import Probe, ProbeT
+  from crossbench.results_db.db import ResultsDB
   from crossbench.runner.groups.session import BrowserSessionRunGroup
-  from crossbench.runner.probe_context_manager import ProbeContextT
   from crossbench.runner.runner import Runner
+  from crossbench.runner.timing import AnyTimeUnit
   from crossbench.stories.story import Story
   from crossbench.types import JsonDict
 
 
 @enum.unique
-class Temperature(compat.StrEnumWithHelp):
+class Temperature(StrEnumWithHelp):
   COLD = ("cold", "first run")
   WARM = ("warm", "second run")
   HOT = ("hot", "third run")
@@ -55,7 +65,8 @@ class Run(ResultOrigin):
                index: int,
                name: Optional[str] = None,
                timeout: dt.timedelta = dt.timedelta(),
-               throw: bool = False):
+               throw: bool = False) -> None:
+    super().__init__()
     self._state = StateMachine(State.INITIAL)
     self._runner = runner
     self._browser_session = browser_session
@@ -76,12 +87,13 @@ class Run(ResultOrigin):
     self._start_datetime = dt.datetime.utcfromtimestamp(0)
     self._timeout = timeout
     self._exceptions = Annotator(throw)
-    self._browser_tmp_dir: Optional[pth.AnyPath] = None
+    self._browser_tmp_dir: pth.AnyPath | None = None
     self._probe_context_manager = ProbeRunContextManager(
         self, self._probe_results)
+    self._annotations: Set[RunAnnotation] = set()
 
   def __str__(self) -> str:
-    return f"Run({self.name}, {self._state}, {self.browser})"
+    return f"Run({self.name}, state={self._state}, {self.browser})"
 
   def _get_out_dir(self) -> pth.LocalPath:
     return (self._browser_session.browser_dir / "stories" /
@@ -98,11 +110,15 @@ class Run(ResultOrigin):
               measure: bool = True) -> Actions:
     return Actions(name, self, verbose=verbose, measure=measure)
 
+  def wait_range(self, min_wait: AnyTimeUnit, timeout: AnyTimeUnit,
+                 delay: AnyTimeUnit) -> WaitRange:
+    return self.runner.wait_range(min_wait, timeout, delay)
+
   @property
   def info_stack(self) -> TInfoStack:
     return (
         f"Run({self.name})",
-        (f"browser={self.browser.type_name} label={self.browser.label} "
+        (f"browser={self.browser.type_name()} label={self.browser.label} "
          f"binary={self.browser.path}"),
         f"story={self.story}",
         f"repetition={self.repetition_name}",
@@ -134,6 +150,9 @@ class Run(ResultOrigin):
             "global": self.timing.to_json(),
         },
         "success": self.is_success,
+        "annotations": [
+            annotation.to_json() for annotation in self._annotations
+        ],
         "errors": self.exceptions.error_messages()
     }
 
@@ -181,9 +200,14 @@ class Run(ResultOrigin):
     return self._index
 
   @property
+  @override
   def runner(self) -> Runner:
     return self._runner
 
+  @property
+  def results_db(self) -> ResultsDB:
+    return self.runner.results_db
+
   @property
   def benchmark(self) -> Benchmark:
     return self._runner.benchmark
@@ -193,6 +217,7 @@ class Run(ResultOrigin):
     return self._browser_session
 
   @property
+  @override
   def browser(self) -> Browser:
     return self._browser
 
@@ -202,6 +227,7 @@ class Run(ResultOrigin):
     return self.runner.env
 
   @property
+  @override
   def out_dir(self) -> pth.LocalPath:
     """A local directory where all result files are gathered.
     Results from browsers on remote platforms are transferred to this dir
@@ -209,6 +235,7 @@ class Run(ResultOrigin):
     return self._out_dir
 
   @property
+  @override
   def browser_tmp_dir(self) -> pth.AnyPath:
     """Returns a path to a tmp dir on the browser platform."""
     if not self._browser_tmp_dir:
@@ -229,6 +256,7 @@ class Run(ResultOrigin):
     return self._name
 
   @property
+  @override
   def exceptions(self) -> Annotator:
     return self._exceptions
 
@@ -240,6 +268,21 @@ class Run(ResultOrigin):
   def session(self) -> BrowserSessionRunGroup:
     return self._browser_session
 
+  def annotate(self, annotation: RunAnnotation) -> None:
+    self._annotations.add(annotation)
+
+  @property
+  def annotations(self) -> Iterable[RunAnnotation]:
+    return iter(self._annotations)
+
+  @property
+  def secrets(self) -> Secrets:
+    return self.story.secrets.merge(fallback=self.browser.secrets)
+
+  @property
+  def create_symlinks(self) -> bool:
+    return self.runner.create_symlinks
+
   def get_browser_details_json(self) -> JsonDict:
     details_json = self.browser.details_json()
     self.session.add_flag_details(details_json)
@@ -261,7 +304,7 @@ class Run(ResultOrigin):
       self._probe_context_manager.setup(self.probes, is_dry_run)
     self._log_setup()
 
-  def setup_selenium_options(self, options: ArgOptions):
+  def setup_selenium_options(self, options: ArgOptions) -> None:
     # TODO: move explicitly to session.
     self._probe_context_manager.setup_selenium_options(options)
 
@@ -272,13 +315,15 @@ class Run(ResultOrigin):
     if not self.runner.create_symlinks:
       logging.debug("Symlinks disabled by command line option")
       return
-    self._create_runs_dir()
-    self._create_session_dir()
+    self._setup_runs_dir()
+    self._setup_session_dir()
 
-  def _create_runs_dir(self) -> None:
+  def _setup_runs_dir(self) -> None:
     browser_dir = self.browser_session.browser_dir
     runs_dir = browser_dir / "runs"
     runs_dir.mkdir(parents=True, exist_ok=True)
+    if not self.create_symlinks:
+      return
     # Source: BROWSER / "runs" / RUN
     # Target: BROWSER / "stories" / STORY / REPETITION / CACHE_TEMP
     run_dir = runs_dir / str(self.index)
@@ -286,12 +331,11 @@ class Run(ResultOrigin):
         pth.LocalPath("../") / self.out_dir.relative_to(browser_dir))
     run_dir.symlink_to(relative_out_dir, target_is_directory=True)
 
-  def _create_session_dir(self) -> None:
+  def _setup_session_dir(self) -> None:
     session_run_dir = self._out_dir / "session"
     assert not session_run_dir.exists(), (
         f"Cannot setup session dir twice: {session_run_dir}")
-    if self.host_platform.is_win:
-      logging.debug("Skipping session_dir symlink on windows.")
+    if not self.create_symlinks:
       return
     # Source: BROWSER / "stories" / STORY / REPETITION / CACHE_TEMP / "session"
     # Target: BROWSER / "sessions" / SESSION
@@ -302,13 +346,13 @@ class Run(ResultOrigin):
 
   def _log_setup(self) -> None:
     logging.debug("SETUP")
-    logging.info(
+    logging.debug(
         "PROBES: %s",
         ", ".join(probe.NAME for probe in self.probes if not probe.is_internal))
     logging.debug("PROBES ALL: %s",
                   ", ".join(probe.NAME for probe in self.probes))
     self.story.log_run_details(self)
-    logging.info("RUN DIR: %s", self._out_dir)
+    logging.info(" RUN DIR:                  %s", self._out_dir)
     logging.debug("CWD %s", self._out_dir)
 
   def run(self, is_dry_run: bool) -> None:
@@ -325,7 +369,7 @@ class Run(ResultOrigin):
 
   def _run(self, is_dry_run: bool) -> None:
     self._state.transition(State.READY, to=State.RUN)
-    self.browser.splash_screen.run(self)
+    self._run_splashscreen()
     with self._probe_context_manager.open(is_dry_run):
       logging.info("RUNNING STORY")
       self._state.expect(State.RUN)
@@ -338,18 +382,31 @@ class Run(ResultOrigin):
         # throttled down non-foreground browser.
         self._exceptions.append(e)
       if self.is_success:
-        with self.exceptions.capture():
-          self.environment.check_browser_focused(self.browser)
+        self._run_success_validation()
+
+  def _run_splashscreen(self) -> None:
+    with self.actions("SplashScreen") as actions:
+      display_data = SplashScreenData(self.is_warmup, self.browser,
+                                      self.details_json())
+      self.browser.settings.splash_screen.run(actions, display_data)
 
   def _run_story(self) -> None:
     self._run_story_setup()
+    if delay := self.timing.start_delay:
+      self._run_story_wait(delay, "Start Delay")
     try:
       self._story.run(self)
     except StopStoryException as e:
       logging.debug("Stop story: %s", e)
     finally:
+      if delay := self.timing.stop_delay:
+        self._run_story_wait(delay, "Stop Delay")
       self._run_story_teardown()
 
+  def _run_story_wait(self, delay: dt.timedelta, label: str) -> None:
+    logging.info("%s: %s", label, delay)
+    self.runner.wait(delay, absolute_time=True)
+
   def _run_story_setup(self) -> None:
     with self.measure("story-setup"):
       self._story.setup(self)
@@ -360,6 +417,12 @@ class Run(ResultOrigin):
     with self.measure("story-tear-down"):
       self._story.teardown(self)
 
+  def _run_success_validation(self) -> None:
+    try:
+      self.environment.check_browser_focused(self.browser)
+    except ValidationError as e:
+      self.annotate(RunAnnotation.warning(str(e)))
+
   def teardown(self, is_dry_run: bool) -> None:
     self._state.transition(State.RUN, to=State.DONE)
     self._teardown_browser(is_dry_run)
@@ -393,33 +456,47 @@ class Run(ResultOrigin):
     for probe in self.probes:
       probe.log_run_result(self)
 
-  def find_probe_context(self,
-                         cls: Type[ProbeT]) -> Optional[ProbeContext[ProbeT]]:
-    return self._probe_context_manager.find_probe_context(cls)
+  def log_failure(self) -> None:
+    assert not self.is_success
+    self._exceptions.log(f" RUN {self.index+1} GOT ERRORS", separator="-")
+
+  def log_annotations(self) -> None:
+    if not self._annotations:
+      return
+    logging.info("- " * 40)
+    RunAnnotation.log_all(self.annotations, limit=10)
+
+  def find_probe_context(
+      self, probe_cls: Type[ProbeT]) -> Optional[ProbeContext[ProbeT]]:
+    return self._probe_context_manager.find_probe_context(probe_cls)
 
 
 class ProbeRunContextManager(ProbeContextManager[Run, ProbeContext]):
 
-  def __init__(self, run: Run, probe_results: ProbeResultDict):
+  def __init__(self, run: Run, probe_results: ProbeResultDict) -> None:
     super().__init__(run, probe_results)
 
+  @property
+  def run(self) -> Run:
+    return self._origin
+
   def get_probe_context(self, probe: Probe) -> Optional[ProbeContext]:
-    return probe.get_context(self._origin)
+    return probe.get_context(self.run)
 
-  def setup_selenium_options(self, options: ArgOptions):
+  def setup_selenium_options(self, options: ArgOptions) -> None:
     for probe_context in self._probe_contexts.values():
       probe_context.setup_selenium_options(options)
 
   def start_story(self) -> None:
-    with self.measure("probes-start_story_run"):
+    with self._measure("probes-start_story_run"):
       for probe_context in self._probe_contexts.values():
-        with self._origin.exception_handler(
+        with self.run.exception_capture(
             f"Probe {probe_context.name} start_story_run"):
           probe_context.start_story_run()
 
   def stop_story(self) -> None:
-    with self.measure("probes-stop_story_run"):
+    with self._measure("probes-stop_story_run"):
       for probe_context in self._probe_contexts.values():
-        with self._origin.exception_handler(
+        with self.run.exception_capture(
             f"Probe {probe_context.name} stop_story_run"):
           probe_context.stop_story_run()
diff --git a/crossbench/runner/run_annotation.py b/crossbench/runner/run_annotation.py
new file mode 100644
index 00000000..b867fc06
--- /dev/null
+++ b/crossbench/runner/run_annotation.py
@@ -0,0 +1,84 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import dataclasses
+import enum
+import logging
+from typing import TYPE_CHECKING, Dict, Final, Iterable, List
+
+from crossbench.helper import collection_helper
+
+if TYPE_CHECKING:
+  from crossbench.types import JsonDict
+
+
+@enum.unique
+class WarnLevel(enum.IntEnum):
+  FATAL = 3
+  ERROR = 2
+  WARNING = 1
+  INFO = 0
+
+
+WARN_COLORS_LOOKUP: Final = {
+    WarnLevel.FATAL: "",
+    WarnLevel.ERROR: "",
+    WarnLevel.WARNING: "",
+    WarnLevel.INFO: ""
+}
+
+LOG_LEVEL_LOOKUP: Final = {
+    WarnLevel.FATAL: logging.FATAL,
+    WarnLevel.ERROR: logging.ERROR,
+    WarnLevel.WARNING: logging.WARNING,
+    WarnLevel.INFO: logging.INFO
+}
+
+
+@dataclasses.dataclass(frozen=True)
+class RunAnnotation:
+  message: str
+  level: WarnLevel = WarnLevel.INFO
+
+  @classmethod
+  def fatal(cls, message: str) -> RunAnnotation:
+    return cls(message, level=WarnLevel.FATAL)
+
+  @classmethod
+  def error(cls, message: str) -> RunAnnotation:
+    return cls(message, level=WarnLevel.ERROR)
+
+  @classmethod
+  def warning(cls, message: str) -> RunAnnotation:
+    return cls(message, level=WarnLevel.WARNING)
+
+  @classmethod
+  def info(cls, message: str) -> RunAnnotation:
+    return cls(message, level=WarnLevel.INFO)
+
+  def to_json(self) -> JsonDict:
+    return {"message": self.message, "level": self.level.name}
+
+  def log(self) -> None:
+    logging.log(LOG_LEVEL_LOOKUP[self.level], "%s: %s",
+                WARN_COLORS_LOOKUP[self.level], self.message)
+
+  @classmethod
+  def log_all(cls,
+              annotations: Iterable[RunAnnotation],
+              limit: int = 2) -> None:
+    groups: Dict[WarnLevel, List[RunAnnotation]] = collection_helper.group_by(
+        annotations, lambda annotation: annotation.level)
+    if not groups:
+      return
+    logging.info("RUN ANNOTATIONS:")
+    for level in WarnLevel:
+      if annotations_group := groups.get(level):
+        for annotation in annotations_group[:limit]:
+          annotation.log()
+        skipped = len(annotations_group) - limit
+        if skipped > 0:
+          logging.info("   ... and %s more", skipped)
diff --git a/crossbench/runner/runner.py b/crossbench/runner/runner.py
index 01e1d38d..f5197077 100644
--- a/crossbench/runner/runner.py
+++ b/crossbench/runner/runner.py
@@ -7,25 +7,28 @@ from __future__ import annotations
 import argparse
 import datetime as dt
 import enum
-import inspect
 import logging
 from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Optional,
-                    Sequence, Set, Tuple, Type, Union)
+                    Sequence, Set, Tuple, Type)
 
-from crossbench import compat, exception, helper
+from crossbench import exception
 from crossbench import path as pth
 from crossbench import plt
-from crossbench.benchmarks.base import BenchmarkProbeMixin
-from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
-                            ValidationMode)
+from crossbench.benchmarks import benchmark_validator
+from crossbench.benchmarks.benchmark_probe import BenchmarkProbeMixin
+from crossbench.env import EnvironmentConfig, HostEnvironment, ValidationMode
+from crossbench.helper import collection_helper
+from crossbench.helper.sleep_preventer import SystemSleepPreventer
 from crossbench.helper.state import BaseState, StateMachine
+from crossbench.helper.wait import WaitRange
 from crossbench.parse import NumberParser, ObjectParser
 from crossbench.probes import all as all_probes
-from crossbench.probes.internal import ResultsSummaryProbe
+from crossbench.probes.internal.summary import ResultsSummaryProbe
 from crossbench.probes.perfetto.trace_processor.trace_processor import \
     TraceProcessorProbe
 from crossbench.probes.probe import Probe, ProbeIncompatibleBrowser
 from crossbench.probes.thermal_monitor import ThermalStatus
+from crossbench.results_db.db import ResultsDB
 from crossbench.runner.groups.browsers import BrowsersRunGroup
 from crossbench.runner.groups.cache_temperatures import \
     CacheTemperaturesRunGroup
@@ -35,10 +38,13 @@ from crossbench.runner.groups.stories import StoriesRunGroup
 from crossbench.runner.groups.thread import RunThreadGroup
 from crossbench.runner.run import Run
 from crossbench.runner.timing import Timing
+from crossbench.str_enum_with_help import StrEnumWithHelp
 
 if TYPE_CHECKING:
   from crossbench.benchmarks.base import Benchmark
   from crossbench.browsers.browser import Browser
+  from crossbench.runner.groups.base import RunGroup
+  from crossbench.runner.timing import AnyTimeUnit
   from crossbench.stories.story import Story
 
 
@@ -48,7 +54,7 @@ class RunnerException(exception.MultiException):
 
 
 @enum.unique
-class ThreadMode(compat.StrEnumWithHelp):
+class ThreadMode(StrEnumWithHelp):
   NONE = ("none", (
       "Execute all browser-sessions sequentially, default. "
       "Low interference risk, use for worry-free time-critical measurements."))
@@ -68,13 +74,14 @@ class ThreadMode(compat.StrEnumWithHelp):
       return [RunThreadGroup(runs)]
     groups: Dict[Any, List[Run]] = {}
     if self == ThreadMode.SESSION:
-      groups = helper.group_by(
+      groups = collection_helper.group_by(
           runs, lambda run: run.browser_session, sort_key=None)
     elif self == ThreadMode.PLATFORM:
-      groups = helper.group_by(
+      groups = collection_helper.group_by(
           runs, lambda run: run.browser_platform, sort_key=None)
     elif self == ThreadMode.BROWSER:
-      groups = helper.group_by(runs, lambda run: run.browser, sort_key=None)
+      groups = collection_helper.group_by(
+          runs, lambda run: run.browser, sort_key=None)
     else:
       raise ValueError(f"Unexpected thread mode: {self}")
     return [
@@ -138,18 +145,25 @@ class Runner:
         "--thread-mode",
         "--parallel",
         default=ThreadMode.NONE,
-        type=ThreadMode,
+        type=ThreadMode,  # type: ignore
         help=("Change how Runs are executed.\n" +
               ThreadMode.help_text(indent=2)))
 
     out_dir_group = parser.add_argument_group("Output Directory Options")
-    out_dir_group.add_argument(
+    symlink_group = out_dir_group.add_mutually_exclusive_group()
+    symlink_group.add_argument(
         "--no-symlinks",
         "--nosymlinks",
         dest="create_symlinks",
         action="store_false",
-        default=True,
-        help="Do not create symlinks in the output directory.")
+        default=not plt.PLATFORM.is_win,
+        help=("Do not create symlinks in the output directory. "
+              "Disabled by defauly on windows."))
+    symlink_group.add_argument(
+        "--symlinks",
+        dest="create_symlinks",
+        action="store_true",
+        help="Allow create symlinks in the output directory.")
 
     out_dir_xor_group = out_dir_group.add_mutually_exclusive_group()
     out_dir_xor_group.add_argument(
@@ -194,8 +208,8 @@ class Runner:
                browsers: Sequence[Browser],
                benchmark: Benchmark,
                additional_probes: Iterable[Probe] = (),
-               platform: plt.Platform = plt.PLATFORM,
-               env_config: Optional[HostEnvironmentConfig] = None,
+               platform: Optional[plt.Platform] = None,
+               env_config: Optional[EnvironmentConfig] = None,
                env_validation_mode: ValidationMode = ValidationMode.THROW,
                repetitions: int = 1,
                warmup_repetitions: int = 0,
@@ -204,13 +218,14 @@ class Runner:
                cool_down_threshold: Optional[ThermalStatus] = None,
                thread_mode: ThreadMode = ThreadMode.NONE,
                throw: bool = False,
-               create_symlinks: bool = True):
+               create_symlinks: bool = True,
+               in_memory_result_db: bool = False) -> None:
     self._state = StateMachine(RunnerState.INITIAL)
     self.out_dir = out_dir.absolute()
     assert not self.out_dir.exists(), f"out_dir={self.out_dir} exists already"
     self.out_dir.mkdir(parents=True)
     self._timing = timing
-    self._cool_down_threshold: Optional[ThermalStatus] = cool_down_threshold
+    self._cool_down_threshold: ThermalStatus | None = cool_down_threshold
     self._browsers: Tuple[Browser, ...] = tuple(browsers)
     self._validate_browser_labels()
     self._benchmark = benchmark
@@ -226,33 +241,30 @@ class Runner:
     self._measured_runs: List[Run] = []
     self._thread_mode = thread_mode
     self._exceptions = exception.Annotator(throw)
-    self._platform = platform
+    self._platform = platform or plt.PLATFORM
     self._env = HostEnvironment(self.platform, self.out_dir, self.browsers,
                                 self.probes, self.repetitions, env_config,
                                 env_validation_mode)
     self._attach_default_probes(additional_probes)
     self._prepare_benchmark()
+    if in_memory_result_db:
+      self._results_db = ResultsDB()
+    else:
+      self._results_db = ResultsDB(self.out_dir / "results.db")
     self._cache_temperatures_groups: Tuple[CacheTemperaturesRunGroup, ...] = ()
     self._repetitions_groups: Tuple[RepetitionsRunGroup, ...] = ()
     self._story_groups: Tuple[StoriesRunGroup, ...] = ()
-    self._browser_group: Optional[BrowsersRunGroup] = None
+    self._browser_group: BrowsersRunGroup | None = None
     self._create_symlinks: bool = create_symlinks
 
   def _prepare_benchmark(self) -> None:
-    benchmark_probe_cls: Type[BenchmarkProbeMixin]
+    benchmark_validator.validate_cls(type(self._benchmark))
     for benchmark_probe_cls in self._benchmark.PROBES:
-      assert inspect.isclass(benchmark_probe_cls), (
-          f"{self._benchmark}.PROBES must contain classes only, "
-          f"but got {type(benchmark_probe_cls)}")
-      assert issubclass(
-          benchmark_probe_cls,
-          Probe), (f"Expected Probe class but got {type(benchmark_probe_cls)}")
-      assert issubclass(benchmark_probe_cls, BenchmarkProbeMixin), (
-          f"{benchmark_probe_cls} should be BenchmarkProbeMixin "
-          f"for {type(self._benchmark)}.PROBES")
-      assert benchmark_probe_cls.NAME, (
-          f"Expected probe.NAME for {benchmark_probe_cls}")
-      self.attach_probe(benchmark_probe_cls(benchmark=self._benchmark))
+      probe = benchmark_probe_cls(benchmark=self._benchmark)
+      assert (isinstance(probe, Probe) and
+              isinstance(probe, BenchmarkProbeMixin)), (
+                  f"Expected BenchmarkProbe, got {probe}")
+      self.attach_probe(probe)
 
   def _validate_browser_labels(self) -> None:
     assert self.browsers, "No browsers provided"
@@ -262,15 +274,7 @@ class Runner:
   def _attach_default_probes(self, probe_list: Iterable[Probe]) -> None:
     assert len(self._probes) == 0
     assert len(self._default_probes) == 0
-    for probe_cls in all_probes.INTERNAL_PROBES:
-      if probe_cls == all_probes.ThermalMonitorProbe:
-        thermal_monitor_probe = all_probes.ThermalMonitorProbe(
-            cool_down_time=self._timing.cool_down_time,
-            threshold=self._cool_down_threshold)
-        self._attach_default_probe(thermal_monitor_probe)
-      else:
-        default_probe: Probe = probe_cls()  # pytype: disable=not-instantiable
-        self._attach_default_probe(default_probe)
+    self._attach_internal_probes()
 
     for index, probe in enumerate(probe_list):
       assert (not isinstance(probe, TraceProcessorProbe) or index == 0), (
@@ -281,6 +285,23 @@ class Runner:
     # so all other probes have data by the time we write the results summary.
     assert isinstance(self._probes[0], ResultsSummaryProbe)
 
+  def _attach_internal_probes(self) -> None:
+    for probe_cls in all_probes.NON_CONFIGURABLE_INTERNAL_PROBES:
+      default_probe: Probe = probe_cls()  # pytype: disable=not-instantiable
+      self._attach_default_probe(default_probe)
+
+    thermal_monitor_probe = all_probes.ThermalMonitorProbe(
+        cool_down_time=self._timing.cool_down_time,
+        threshold=self._cool_down_threshold)
+    self._attach_default_probe(thermal_monitor_probe)
+
+    # TODO: pass in the flag to the runner for a cleaner setup.
+    if any(browser.driver_logging for browser in self.browsers):
+      if not all(browser.driver_logging for browser in self.browsers):
+        raise RuntimeError("Driver logging must be enabled on all browsers")
+      driver_logging_probe = all_probes.BrowserDriverLogProbe()
+      self._attach_default_probe(driver_logging_probe)
+
   def _attach_default_probe(self, probe: Probe) -> None:
     self.attach_probe(probe)
     self._default_probes.append(probe)
@@ -367,6 +388,10 @@ class Runner:
   def platforms(self) -> Set[plt.Platform]:
     return set(browser.platform for browser in self.browsers)
 
+  @property
+  def results_db(self) -> ResultsDB:
+    return self._results_db
+
   @property
   def all_runs(self) -> Tuple[Run, ...]:
     return tuple(self._all_runs)
@@ -400,26 +425,26 @@ class Runner:
   def has_browser_group(self) -> bool:
     return self._browser_group is not None
 
-  def wait(self,
-           time: Union[int, float, dt.timedelta],
-           absolute_time: bool = False) -> None:
+  def wait_range(self, min_wait: AnyTimeUnit, timeout: AnyTimeUnit,
+                 delay: AnyTimeUnit) -> WaitRange:
+    timing = self.timing
+    return WaitRange(
+        min=timing.timedelta(min_wait),
+        timeout=timing.timeout_timedelta(timeout),
+        delay=timing.timedelta(delay))
+
+  def wait(self, time: AnyTimeUnit, absolute_time: bool = False) -> None:
     if not time:
       return
-    if not absolute_time:
-      delta = self.timing.timedelta(time)
-    else:
-      if isinstance(time, (int, float)):
-        delta = dt.timedelta(seconds=time)
-      else:
-        delta = time
+    delta = self.timing.timedelta(time, absolute_time)
     self._platform.sleep(delta)
 
   def run(self, is_dry_run: bool = False) -> None:
     self._state.expect(RunnerState.INITIAL)
-    with helper.SystemSleepPreventer():
+    with SystemSleepPreventer(self._platform):
       with self._exceptions.annotate("Preparing"):
         self._setup()
-      with self._exceptions.annotate("Running"):
+      with self._exceptions.capture("Running"):
         self._run(is_dry_run)
 
     if self._exceptions.throw:
@@ -430,6 +455,9 @@ class Runner:
     self.assert_successful_sessions_and_runs()
 
   def _setup(self) -> None:
+    """ Mostly perform validations.
+    Unlike later phases, any exception in here will cause the runner to stop.
+    """
     self._state.transition(RunnerState.INITIAL, to=RunnerState.SETUP)
     logging.info("-" * 80)
     logging.info("SETUP")
@@ -438,29 +466,30 @@ class Runner:
         f"Invalid repetitions count: {self.repetitions}")
     assert self.browsers, "No browsers provided: self.browsers is empty"
     assert self.stories, "No stories provided: self.stories is empty"
-    self._validate_browsers()
-    self._exceptions.assert_success()
+    self._setup_validate_browsers()
     with self._exceptions.annotate("Preparing Runs"):
       self._all_runs = list(self.get_runs())
       assert self._all_runs, f"{type(self)}.get_runs() produced no runs"
-      logging.info("DISCOVERED %d RUN(S)", len(self._all_runs))
+      logging.info(" SETUP %d RUN(S)", len(self._all_runs))
       self._measured_runs = [run for run in self._all_runs if not run.is_warmup]
-    with self._exceptions.capture("Preparing Environment"):
+    with self._exceptions.annotate("Preparing Environment"):
       self._env.setup()
     with self._exceptions.annotate(
         f"Preparing Benchmark: {self._benchmark.NAME}"):
       self._benchmark.setup(self)
-
-  def _validate_browsers(self) -> None:
-    logging.info("PREPARING %d BROWSER(S)", len(self.browsers))
-    for browser in self.browsers:
-      with self._exceptions.capture(
-          f"Preparing browser type={browser.type_name} "
-          f"unique_name={browser.unique_name}"):
-        self._validate_browser(browser)
-
-  def _validate_browser(self, browser: Browser) -> None:
-    browser.validate_binary()
+    self._results_db.setup_runs(self._all_runs)
+
+  def _setup_validate_browsers(self) -> None:
+    logging.info(" SETUP %d BROWSER(S)", len(self.browsers))
+    with self._exceptions.annotate("Validating all browsers"):
+      for browser in self.browsers:
+        with self._exceptions.capture(
+            f"Preparing browser type={browser.type_name()} "
+            f"unique_name={browser.unique_name}"):
+          self._setup_validate_browser(browser)
+
+  def _setup_validate_browser(self, browser: Browser) -> None:
+    browser.validate()
     for probe in browser.probes:
       assert probe in self._probes, (
           f"Browser {browser} probe {probe} not in Runner.probes. "
@@ -482,7 +511,8 @@ class Runner:
       for story in self.stories:
         for browser in self.browsers:
           # TODO: implement browser-session start/stop
-          extra_benchmark_flags = self.benchmark.extra_flags(browser.attributes)
+          extra_benchmark_flags = self.benchmark.extra_flags(
+              browser.attributes())
           browser_session = BrowserSessionRunGroup(self.env, self.probes,
                                                    browser,
                                                    extra_benchmark_flags,
@@ -516,10 +546,26 @@ class Runner:
                index, name, timeout, throw)
 
   def assert_successful_sessions_and_runs(self) -> None:
-    failed_runs = list(run for run in self.runs if not run.is_success)
-    self._exceptions.assert_success(
-        f"Runs Failed: {len(failed_runs)}/{len(tuple(self.runs))} runs failed.",
-        RunnerException)
+    if self._exceptions.is_success:
+      return
+    failed_runs: int = len(list(run for run in self.runs if not run.is_success))
+    all_runs: int = len(tuple(self.runs))
+    num_exceptions = len(self._exceptions)
+    message: str = (
+        f"{failed_runs}/{all_runs} Runs had {num_exceptions} error(s).")
+    if not failed_runs:
+      # No need to log the error here, since merging probe data is the last
+      # step and errors have already been printed right before calling this
+      # helper.
+      message = f"Merged probe data with {num_exceptions} error(s)"
+    else:
+      # Print run failures, since they potentially have been printed the last
+      # time very high up.
+      logging.error("=" * 80)
+      logging.error(" %s", message.upper())
+      logging.error("=" * 80)
+    # Raise a RunnerException to be handled in the CLI.
+    self._exceptions.assert_success(message, RunnerException)
 
   def _get_thread_groups(self) -> List[RunThreadGroup]:
     # Also include warmup runs here.
@@ -553,36 +599,45 @@ class Runner:
   def _teardown(self) -> None:
     self._state.transition(RunnerState.RUNNING, to=RunnerState.TEARDOWN)
     logging.info("=" * 80)
-    logging.info("RUNS COMPLETED")
-    logging.info("-" * 80)
+    if self.is_success:
+      logging.info(" %s RUNS COMPLETED SUCCESSFULLY", len(self.runs))
+    else:
+      logging.warning(" %s RUNS COMPLETED WITH ERRORS", len(self.runs))
+    logging.info("=" * 80)
     logging.info("MERGING PROBE DATA")
+    self._teardown_merge_probe_data()
 
+  def _teardown_merge_probe_data(self) -> None:
     throw = self._exceptions.throw
-
-    logging.debug("MERGING PROBE DATA: cache temperatures")
     self._cache_temperatures_groups = CacheTemperaturesRunGroup.groups(
         self._measured_runs, throw)
-    for cache_temp_group in self._cache_temperatures_groups:
-      cache_temp_group.merge(self.probes)
-      self._exceptions.extend(cache_temp_group.exceptions, is_nested=True)
+    self._teardown_merge_run_group("cache temperatures",
+                                   self._cache_temperatures_groups)
 
-    logging.debug("MERGING PROBE DATA: repetitions")
     self._repetitions_groups = RepetitionsRunGroup.groups(
         self._cache_temperatures_groups, throw)
-    for repetition_group in self._repetitions_groups:
-      repetition_group.merge(self.probes)
-      self._exceptions.extend(repetition_group.exceptions, is_nested=True)
+    self._teardown_merge_run_group("repetitions", self._repetitions_groups)
 
-    logging.debug("MERGING PROBE DATA: stories")
     self._story_groups = StoriesRunGroup.groups(self._repetitions_groups, throw)
-    for story_group in self._story_groups:
-      story_group.merge(self.probes)
-      self._exceptions.extend(story_group.exceptions, is_nested=True)
+    self._teardown_merge_run_group("stories", self._story_groups)
 
-    logging.debug("MERGING PROBE DATA: browsers")
     self._browser_group = BrowsersRunGroup(self._story_groups, throw)
-    self._browser_group.merge(self.probes)
-    self._exceptions.extend(self._browser_group.exceptions, is_nested=True)
+    self._teardown_merge_run_group("browsers", [self._browser_group])
+
+  def _teardown_merge_run_group(self, group_name: str,
+                                groups: Iterable[RunGroup]) -> None:
+    logging.debug("MERGING PROBE DATA: %s", group_name)
+    group_exceptions = exception.ExceptionAnnotator(self._exceptions.throw)
+    try:
+      for group in groups:
+        group.merge(self.probes)
+        group_exceptions.extend(group.exceptions, is_nested=True)
+    finally:
+      self._exceptions.extend(group_exceptions)
+      if not group_exceptions.is_success:
+        group_exceptions.log(
+            f" MERGED {group_name.upper()} PROBE DATA WITH ERRORS",
+            separator="-")
 
 
 TEMPERATURE_ICONS = {
diff --git a/crossbench/runner/timing.py b/crossbench/runner/timing.py
index f1239ba0..479d876a 100644
--- a/crossbench/runner/timing.py
+++ b/crossbench/runner/timing.py
@@ -6,13 +6,17 @@ from __future__ import annotations
 
 import dataclasses
 import datetime as dt
-from typing import Dict, Union
+from typing import Dict, TypeAlias
 
 # Arbitrary very large number that doesn't break any browser driver protocol.
 # chromedriver likely uses an uint32 ms internally, 2**30ms == 12days.
 SAFE_MAX_TIMEOUT_TIMEDELTA = dt.timedelta(milliseconds=2**30)
 
 
+AnyTime: TypeAlias = float | int | dt.timedelta
+AnyTimeUnit: TypeAlias = float | int | dt.timedelta
+
+
 @dataclasses.dataclass(frozen=True)
 class Timing:
   cool_down_time: dt.timedelta = dt.timedelta(seconds=1)
@@ -43,17 +47,46 @@ class Timing:
       raise ValueError(
           f"Timing.run_timeout, must be >= 0, but got {self.run_timeout}")
 
-  def units(self, time: Union[float, int, dt.timedelta]) -> float:
+  def units(self, time: AnyTime, absolute_time: bool = False) -> int | float:
+    """Convert absolute time (seconds, timedelta) to relative time units."""
     if isinstance(time, dt.timedelta):
       seconds = time.total_seconds()
     else:
       seconds = time
     if seconds < 0:
       raise ValueError(f"Unexpected negative time: {seconds}s")
+    if absolute_time:
+      return seconds
     return seconds / self.unit.total_seconds()
 
-  def _convert_to_seconds(
-      self, time_units: Union[float, int, dt.timedelta]) -> Union[float, int]:
+  def timedelta(self,
+                time_units: AnyTimeUnit,
+                absolute_time: bool = False) -> dt.timedelta:
+    """Converts relative time units to absolute time."""
+    return self._to_timedelta(time_units, self.unit, absolute_time)
+
+  def timeout_timedelta(self,
+                        time_units: AnyTimeUnit,
+                        absolute_time: bool = False) -> dt.timedelta:
+    """Converts relative time units to absolute time for timeouts.
+    Note that timeouts can have a separate time unit."""
+    if self.has_no_timeout:
+      return SAFE_MAX_TIMEOUT_TIMEDELTA
+    timeout_unit = self.timeout_unit or self.unit
+    return self._to_timedelta(time_units, timeout_unit, absolute_time)
+
+  def _to_timedelta(self,
+                    time_units: AnyTimeUnit,
+                    time_unit_duration: dt.timedelta,
+                    absolute_time: bool = False) -> dt.timedelta:
+    time_units_f: float | int = self._to_units_f(time_units)
+    if absolute_time:
+      absolute_time_f = dt.timedelta(seconds=time_units_f)
+    else:
+      absolute_time_f = time_units_f * time_unit_duration
+    return self._to_safe_range(absolute_time_f)
+
+  def _to_units_f(self, time_units: AnyTimeUnit) -> float | int:
     if isinstance(time_units, dt.timedelta):
       seconds = time_units.total_seconds()
     else:
@@ -63,18 +96,6 @@ class Timing:
       raise ValueError(f"Time-units must be >= 0, but got {seconds}")
     return seconds
 
-  def timedelta(self, time_units: Union[float, int,
-                                        dt.timedelta]) -> dt.timedelta:
-    seconds_f = self._convert_to_seconds(time_units)
-    return self._to_safe_range(seconds_f * self.unit)
-
-  def timeout_timedelta(
-      self, time_units: Union[float, int, dt.timedelta]) -> dt.timedelta:
-    if self.has_no_timeout:
-      return SAFE_MAX_TIMEOUT_TIMEDELTA
-    seconds_f = self._convert_to_seconds(time_units)
-    return self._to_safe_range(seconds_f * (self.timeout_unit or self.unit))
-
   def _to_safe_range(self, result: dt.timedelta) -> dt.timedelta:
     if result > SAFE_MAX_TIMEOUT_TIMEDELTA:
       return SAFE_MAX_TIMEOUT_TIMEDELTA
diff --git a/crossbench/scripts.py b/crossbench/scripts.py
index dfc3cae1..2442f009 100644
--- a/crossbench/scripts.py
+++ b/crossbench/scripts.py
@@ -3,19 +3,20 @@
 # found in the LICENSE file.
 
 import sys
+from typing import List, Optional
 
 from crossbench.cli.btp import BTPUtil
 from crossbench.cli.cli import CrossBenchCLI
 
 
-def crossbench(argv=None) -> None:
+def crossbench(argv: Optional[List[str]] = None) -> None:
   if not argv:
     argv = sys.argv
   cli = CrossBenchCLI()
   cli.run(argv[1:])
 
 
-def cb_btp(argv=None) -> None:
+def cb_btp(argv: Optional[List[str]] = None) -> None:
   if not argv:
     argv = sys.argv
   btp = BTPUtil()
diff --git a/crossbench/stories/press_benchmark.py b/crossbench/stories/press_benchmark.py
index cc4a8627..89db7aa1 100644
--- a/crossbench/stories/press_benchmark.py
+++ b/crossbench/stories/press_benchmark.py
@@ -7,15 +7,14 @@ from __future__ import annotations
 import abc
 import datetime as dt
 import logging
-from typing import List, Optional, Sequence, Tuple, Type, TypeVar
+from typing import List, Optional, Self, Sequence, Tuple
+
+from typing_extensions import override
 
 from crossbench.parse import ObjectParser
 from crossbench.runner.run import Run
 from crossbench.stories.story import Story
 
-PressBenchmarkStoryT = TypeVar(
-    "PressBenchmarkStoryT", bound="PressBenchmarkStory")
-
 
 class PressBenchmarkStory(Story, metaclass=abc.ABCMeta):
   NAME: str = ""
@@ -25,6 +24,7 @@ class PressBenchmarkStory(Story, metaclass=abc.ABCMeta):
   SUBSTORIES: Tuple[str, ...] = ()
 
   @classmethod
+  @override
   def all_story_names(cls) -> Tuple[str, ...]:
     assert cls.SUBSTORIES
     return cls.SUBSTORIES
@@ -36,25 +36,25 @@ class PressBenchmarkStory(Story, metaclass=abc.ABCMeta):
     return cls.all_story_names()
 
   @classmethod
-  def all(cls: Type[PressBenchmarkStoryT],
+  def all(cls,
           separate: bool = False,
           url: Optional[str] = None,
-          **kwargs) -> List[PressBenchmarkStoryT]:
+          **kwargs) -> List[Self]:
     return cls.from_names(cls.all_story_names(), separate, url, **kwargs)
 
   @classmethod
-  def default(cls: Type[PressBenchmarkStoryT],
+  def default(cls,
               separate: bool = False,
               url: Optional[str] = None,
-              **kwargs) -> List[PressBenchmarkStoryT]:
+              **kwargs) -> List[Self]:
     return cls.from_names(cls.default_story_names(), separate, url, **kwargs)
 
   @classmethod
-  def from_names(cls: Type[PressBenchmarkStoryT],
+  def from_names(cls,
                  substories: Sequence[str],
                  separate: bool = False,
                  url: Optional[str] = None,
-                 **kwargs) -> List[PressBenchmarkStoryT]:
+                 **kwargs) -> List[Self]:
     if not substories:
       raise ValueError("No substories provided")
     if separate:
@@ -91,7 +91,7 @@ class PressBenchmarkStory(Story, metaclass=abc.ABCMeta):
     super().__init__(*args, **kwargs)
     # If the _custom_url is empty, we generate a matching URL when the
     # local file server is used.
-    self._custom_url: Optional[str] = url
+    self._custom_url: str | None = url
 
   def _get_unique_name(self) -> str:
     substories_set = set(self._substories)
@@ -125,8 +125,9 @@ class PressBenchmarkStory(Story, metaclass=abc.ABCMeta):
     return self.url
 
   @property
-  def substories(self) -> List[str]:
-    return list(self._substories)
+  @override
+  def substories(self) -> Tuple[str, ...]:
+    return tuple(self._substories)
 
   @property
   def has_default_substories(self) -> bool:
@@ -170,10 +171,15 @@ class PressBenchmarkStory(Story, metaclass=abc.ABCMeta):
       assert substory in self.SUBSTORIES, (f"Unknown {self.NAME} substory %s" %
                                            substory)
 
+  @override
   def log_run_details(self, run: Run) -> None:
     super().log_run_details(run)
     self.log_run_test_url(run)
 
-  def log_run_test_url(self, run: Run):
+  @property
+  def test_url(self) -> str:
+    return self.URL
+
+  def log_run_test_url(self, run: Run) -> None:
     del run
-    logging.info("STORY PUBLIC TEST URL: %s", self.URL)
+    logging.info(" STORY PUBLIC TEST URL:    %s", self.test_url)
diff --git a/crossbench/stories/story.py b/crossbench/stories/story.py
index affeedce..f37f98ee 100644
--- a/crossbench/stories/story.py
+++ b/crossbench/stories/story.py
@@ -7,8 +7,9 @@ from __future__ import annotations
 import abc
 import datetime as dt
 import logging
-from typing import TYPE_CHECKING, Sequence
+from typing import TYPE_CHECKING, Optional, Sequence, Tuple
 
+from crossbench.cli.config.secrets import Secrets
 from crossbench.path import safe_filename
 
 if TYPE_CHECKING:
@@ -24,10 +25,12 @@ class Story(abc.ABC):
 
   def __init__(self,
                name: str,
-               duration: dt.timedelta = dt.timedelta(seconds=15)):
+               duration: dt.timedelta = dt.timedelta(seconds=15),
+               secrets: Optional[Secrets] = None) -> None:
     assert name, "Invalid page name"
     self._name = safe_filename(name)
     self._duration = duration
+    self._secrets = secrets or Secrets()
     if self._duration:
       assert self._duration.total_seconds() > 0, (
           f"Duration must be non-empty, but got: {duration}")
@@ -36,17 +39,25 @@ class Story(abc.ABC):
   def name(self) -> str:
     return self._name
 
+  @property
+  def substories(self) -> Tuple[str, ...]:
+    return (self.name,)
+
   @property
   def duration(self) -> dt.timedelta:
     return self._duration
 
+  @property
+  def secrets(self) -> Secrets:
+    return self._secrets
+
   def details_json(self) -> JsonDict:
     return {"name": self.name, "duration": self.duration.total_seconds()}
 
   def log_run_details(self, run: Run) -> None:
-    logging.info("STORY:          %s", self)
+    logging.info(" STORY:                    %s", self)
     timing = run.timing
-    logging.info("STORY DURATION: expected=%s timeout=%s",
+    logging.info(" STORY DURATION:           expected=%s timeout=%s",
                  timing.timedelta(self.duration),
                  timing.timeout_timedelta(self.duration))
 
diff --git a/crossbench/str_enum_with_help.py b/crossbench/str_enum_with_help.py
new file mode 100644
index 00000000..34106c20
--- /dev/null
+++ b/crossbench/str_enum_with_help.py
@@ -0,0 +1,44 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+import textwrap
+from typing import Any, List, NamedTuple, Optional, Self, Tuple, Type, cast
+
+import tabulate
+
+
+class StrHelpDataMixin(NamedTuple):
+  value: str
+  help: str
+
+
+
+class StrEnumWithHelp(StrHelpDataMixin, enum.Enum):
+
+  @classmethod
+  def _missing_(cls: Type[Self], value: Any) -> Optional[Self]:
+    value = str(value).lower()
+    for member in cls:
+      if member.value == value:
+        return member
+    return None
+
+  @classmethod
+  def help_text_items(cls) -> List[Tuple[str, str]]:
+    return [
+        (repr(instance.value), instance.help) for instance in cls  # pytype: disable=missing-parameter
+    ]
+
+  @classmethod
+  def help_text(cls, indent: int = 0) -> str:
+    text: str = tabulate.tabulate(cls.help_text_items(), tablefmt="plain")
+    if indent:
+      return textwrap.indent(text, " " * indent)
+    return text
+
+  def __str__(self) -> str:
+    return cast(str, self.value)
diff --git a/crossbench/types.py b/crossbench/types.py
index 0b6b13b0..c3215b22 100644
--- a/crossbench/types.py
+++ b/crossbench/types.py
@@ -4,9 +4,14 @@
 
 from __future__ import annotations
 
-from typing import Dict, List, Tuple, Union
+from typing import (Dict, List, Mapping, MutableMapping, Sequence, Tuple,
+                    TypeAlias, Union)
 
-Json = Union["JsonDict", "JsonList", "JsonTuple", str, int, float, bool, None]
-JsonDict = Dict[str, Json]
-JsonList = List[Json]
-JsonTuple = Tuple[Json, ...]
+Json: TypeAlias = Union["JsonMapping", "JsonSequence", str, int, float, bool,
+                        None]
+JsonMapping: TypeAlias = Mapping[str, Json]
+JsonMutableMapping: TypeAlias = MutableMapping[str, Json]
+JsonDict: TypeAlias = Dict[str, Json]
+JsonSequence: TypeAlias = Sequence[Json]
+JsonList: TypeAlias = List[Json]
+JsonTuple: TypeAlias = Tuple[Json, ...]
diff --git a/docs/contributing.md b/docs/contributing.md
deleted file mode 100644
index dfee3760..00000000
--- a/docs/contributing.md
+++ /dev/null
@@ -1,28 +0,0 @@
-# How to Contribute
-
-We'd love to accept your patches and contributions to this project. There are
-just a few small guidelines you need to follow.
-
-## Contributor License Agreement
-
-Contributions to this project must be accompanied by a Contributor License
-Agreement. You (or your employer) retain the copyright to your contribution;
-this simply gives us permission to use and redistribute your contributions as
-part of the project. Head over to <https://cla.developers.google.com/> to see
-your current agreements on file or to sign a new one.
-
-You generally only need to submit a CLA once, so if you've already submitted one
-(even if it was for a different project), you probably don't need to do it
-again.
-
-## Code Reviews
-
-All submissions, including submissions by project members, require review. We
-use Gerrit for this purpose. Consult
-[Gerrit Help](https://gerrit-review.googlesource.com/Documentation/intro-gerrit-walkthrough.html)
-for more information on using gerrit.
-
-## Community Guidelines
-
-This project follows [Google's Open Source Community
-Guidelines](https://opensource.google/conduct/).
diff --git a/mypy.ini b/mypy.ini
index 02060272..52f010f0 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -1,2 +1,5 @@
 [mypy]
-disable_error_code = import
\ No newline at end of file
+disable_error_code = import
+
+[google.auth.*]
+follow_untyped_imports = True
\ No newline at end of file
diff --git a/poetry.lock b/poetry.lock
index cb639453..8a391cbf 100644
--- a/poetry.lock
+++ b/poetry.lock
@@ -1,4 +1,4 @@
-# This file is automatically @generated by Poetry 1.5.1 and should not be changed by hand.
+# This file is automatically @generated by Poetry 1.8.4 and should not be changed by hand.
 
 [[package]]
 name = "astroid"
@@ -11,9 +11,6 @@ files = [
     {file = "astroid-3.3.5.tar.gz", hash = "sha256:5cfc40ae9f68311075d27ef68a4841bdc5cc7f6cf86671b49f00607d30188e2d"},
 ]
 
-[package.dependencies]
-typing-extensions = {version = ">=4.0.0", markers = "python_version < \"3.11\""}
-
 [[package]]
 name = "attrs"
 version = "24.2.0"
@@ -33,6 +30,17 @@ docs = ["cogapp", "furo", "myst-parser", "sphinx", "sphinx-notfound-page", "sphi
 tests = ["cloudpickle", "hypothesis", "mypy (>=1.11.1)", "pympler", "pytest (>=4.3.0)", "pytest-mypy-plugins", "pytest-xdist[psutil]"]
 tests-mypy = ["mypy (>=1.11.1)", "pytest-mypy-plugins"]
 
+[[package]]
+name = "cachetools"
+version = "5.5.0"
+description = "Extensible memoizing collections and decorators"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "cachetools-5.5.0-py3-none-any.whl", hash = "sha256:02134e8439cdc2ffb62023ce1debca2944c3f289d66bb17ead3ab3dede74b292"},
+    {file = "cachetools-5.5.0.tar.gz", hash = "sha256:2cc24fb4cbe39633fb7badd9db9ca6295d766d9c2995f245725a46715d050f2a"},
+]
+
 [[package]]
 name = "certifi"
 version = "2024.8.30"
@@ -123,6 +131,120 @@ files = [
 [package.dependencies]
 pycparser = "*"
 
+[[package]]
+name = "charset-normalizer"
+version = "3.4.0"
+description = "The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet."
+optional = false
+python-versions = ">=3.7.0"
+files = [
+    {file = "charset_normalizer-3.4.0-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:4f9fc98dad6c2eaa32fc3af1417d95b5e3d08aff968df0cd320066def971f9a6"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:0de7b687289d3c1b3e8660d0741874abe7888100efe14bd0f9fd7141bcbda92b"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:5ed2e36c3e9b4f21dd9422f6893dec0abf2cca553af509b10cd630f878d3eb99"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:40d3ff7fc90b98c637bda91c89d51264a3dcf210cade3a2c6f838c7268d7a4ca"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1110e22af8ca26b90bd6364fe4c763329b0ebf1ee213ba32b68c73de5752323d"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:86f4e8cca779080f66ff4f191a685ced73d2f72d50216f7112185dc02b90b9b7"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7f683ddc7eedd742e2889d2bfb96d69573fde1d92fcb811979cdb7165bb9c7d3"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:27623ba66c183eca01bf9ff833875b459cad267aeeb044477fedac35e19ba907"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:f606a1881d2663630ea5b8ce2efe2111740df4b687bd78b34a8131baa007f79b"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:0b309d1747110feb25d7ed6b01afdec269c647d382c857ef4663bbe6ad95a912"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-musllinux_1_2_ppc64le.whl", hash = "sha256:136815f06a3ae311fae551c3df1f998a1ebd01ddd424aa5603a4336997629e95"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-musllinux_1_2_s390x.whl", hash = "sha256:14215b71a762336254351b00ec720a8e85cada43b987da5a042e4ce3e82bd68e"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:79983512b108e4a164b9c8d34de3992f76d48cadc9554c9e60b43f308988aabe"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-win32.whl", hash = "sha256:c94057af19bc953643a33581844649a7fdab902624d2eb739738a30e2b3e60fc"},
+    {file = "charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl", hash = "sha256:55f56e2ebd4e3bc50442fbc0888c9d8c94e4e06a933804e2af3e89e2f9c1c749"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:0d99dd8ff461990f12d6e42c7347fd9ab2532fb70e9621ba520f9e8637161d7c"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:c57516e58fd17d03ebe67e181a4e4e2ccab1168f8c2976c6a334d4f819fe5944"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:6dba5d19c4dfab08e58d5b36304b3f92f3bd5d42c1a3fa37b5ba5cdf6dfcbcee"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bf4475b82be41b07cc5e5ff94810e6a01f276e37c2d55571e3fe175e467a1a1c"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ce031db0408e487fd2775d745ce30a7cd2923667cf3b69d48d219f1d8f5ddeb6"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:8ff4e7cdfdb1ab5698e675ca622e72d58a6fa2a8aa58195de0c0061288e6e3ea"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3710a9751938947e6327ea9f3ea6332a09bf0ba0c09cae9cb1f250bd1f1549bc"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:82357d85de703176b5587dbe6ade8ff67f9f69a41c0733cf2425378b49954de5"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:47334db71978b23ebcf3c0f9f5ee98b8d65992b65c9c4f2d34c2eaf5bcaf0594"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:8ce7fd6767a1cc5a92a639b391891bf1c268b03ec7e021c7d6d902285259685c"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-musllinux_1_2_ppc64le.whl", hash = "sha256:f1a2f519ae173b5b6a2c9d5fa3116ce16e48b3462c8b96dfdded11055e3d6365"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-musllinux_1_2_s390x.whl", hash = "sha256:63bc5c4ae26e4bc6be6469943b8253c0fd4e4186c43ad46e713ea61a0ba49129"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:bcb4f8ea87d03bc51ad04add8ceaf9b0f085ac045ab4d74e73bbc2dc033f0236"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-win32.whl", hash = "sha256:9ae4ef0b3f6b41bad6366fb0ea4fc1d7ed051528e113a60fa2a65a9abb5b1d99"},
+    {file = "charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl", hash = "sha256:cee4373f4d3ad28f1ab6290684d8e2ebdb9e7a1b74fdc39e4c211995f77bec27"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:0713f3adb9d03d49d365b70b84775d0a0d18e4ab08d12bc46baa6132ba78aaf6"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:de7376c29d95d6719048c194a9cf1a1b0393fbe8488a22008610b0361d834ecf"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:4a51b48f42d9358460b78725283f04bddaf44a9358197b889657deba38f329db"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b295729485b06c1a0683af02a9e42d2caa9db04a373dc38a6a58cdd1e8abddf1"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ee803480535c44e7f5ad00788526da7d85525cfefaf8acf8ab9a310000be4b03"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3d59d125ffbd6d552765510e3f31ed75ebac2c7470c7274195b9161a32350284"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8cda06946eac330cbe6598f77bb54e690b4ca93f593dee1568ad22b04f347c15"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:07afec21bbbbf8a5cc3651aa96b980afe2526e7f048fdfb7f1014d84acc8b6d8"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:6b40e8d38afe634559e398cc32b1472f376a4099c75fe6299ae607e404c033b2"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:b8dcd239c743aa2f9c22ce674a145e0a25cb1566c495928440a181ca1ccf6719"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:84450ba661fb96e9fd67629b93d2941c871ca86fc38d835d19d4225ff946a631"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:44aeb140295a2f0659e113b31cfe92c9061622cadbc9e2a2f7b8ef6b1e29ef4b"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:1db4e7fefefd0f548d73e2e2e041f9df5c59e178b4c72fbac4cc6f535cfb1565"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-win32.whl", hash = "sha256:5726cf76c982532c1863fb64d8c6dd0e4c90b6ece9feb06c9f202417a31f7dd7"},
+    {file = "charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl", hash = "sha256:b197e7094f232959f8f20541ead1d9862ac5ebea1d58e9849c1bf979255dfac9"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:dd4eda173a9fcccb5f2e2bd2a9f423d180194b1bf17cf59e3269899235b2a114"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:e9e3c4c9e1ed40ea53acf11e2a386383c3304212c965773704e4603d589343ed"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:92a7e36b000bf022ef3dbb9c46bfe2d52c047d5e3f3343f43204263c5addc250"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:54b6a92d009cbe2fb11054ba694bc9e284dad30a26757b1e372a1fdddaf21920"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1ffd9493de4c922f2a38c2bf62b831dcec90ac673ed1ca182fe11b4d8e9f2a64"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:35c404d74c2926d0287fbd63ed5d27eb911eb9e4a3bb2c6d294f3cfd4a9e0c23"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4796efc4faf6b53a18e3d46343535caed491776a22af773f366534056c4e1fbc"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:e7fdd52961feb4c96507aa649550ec2a0d527c086d284749b2f582f2d40a2e0d"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:92db3c28b5b2a273346bebb24857fda45601aef6ae1c011c0a997106581e8a88"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:ab973df98fc99ab39080bfb0eb3a925181454d7c3ac8a1e695fddfae696d9e90"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:4b67fdab07fdd3c10bb21edab3cbfe8cf5696f453afce75d815d9d7223fbe88b"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:aa41e526a5d4a9dfcfbab0716c7e8a1b215abd3f3df5a45cf18a12721d31cb5d"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:ffc519621dce0c767e96b9c53f09c5d215578e10b02c285809f76509a3931482"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-win32.whl", hash = "sha256:f19c1585933c82098c2a520f8ec1227f20e339e33aca8fa6f956f6691b784e67"},
+    {file = "charset_normalizer-3.4.0-cp313-cp313-win_amd64.whl", hash = "sha256:707b82d19e65c9bd28b81dde95249b07bf9f5b90ebe1ef17d9b57473f8a64b7b"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:dbe03226baf438ac4fda9e2d0715022fd579cb641c4cf639fa40d53b2fe6f3e2"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:dd9a8bd8900e65504a305bf8ae6fa9fbc66de94178c420791d0293702fce2df7"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:b8831399554b92b72af5932cdbbd4ddc55c55f631bb13ff8fe4e6536a06c5c51"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a14969b8691f7998e74663b77b4c36c0337cb1df552da83d5c9004a93afdb574"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dcaf7c1524c0542ee2fc82cc8ec337f7a9f7edee2532421ab200d2b920fc97cf"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:425c5f215d0eecee9a56cdb703203dda90423247421bf0d67125add85d0c4455"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-musllinux_1_2_aarch64.whl", hash = "sha256:d5b054862739d276e09928de37c79ddeec42a6e1bfc55863be96a36ba22926f6"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-musllinux_1_2_i686.whl", hash = "sha256:f3e73a4255342d4eb26ef6df01e3962e73aa29baa3124a8e824c5d3364a65748"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-musllinux_1_2_ppc64le.whl", hash = "sha256:2f6c34da58ea9c1a9515621f4d9ac379871a8f21168ba1b5e09d74250de5ad62"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-musllinux_1_2_s390x.whl", hash = "sha256:f09cb5a7bbe1ecae6e87901a2eb23e0256bb524a79ccc53eb0b7629fbe7677c4"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-musllinux_1_2_x86_64.whl", hash = "sha256:0099d79bdfcf5c1f0c2c72f91516702ebf8b0b8ddd8905f97a8aecf49712c621"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-win32.whl", hash = "sha256:9c98230f5042f4945f957d006edccc2af1e03ed5e37ce7c373f00a5a4daa6149"},
+    {file = "charset_normalizer-3.4.0-cp37-cp37m-win_amd64.whl", hash = "sha256:62f60aebecfc7f4b82e3f639a7d1433a20ec32824db2199a11ad4f5e146ef5ee"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:af73657b7a68211996527dbfeffbb0864e043d270580c5aef06dc4b659a4b578"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:cab5d0b79d987c67f3b9e9c53f54a61360422a5a0bc075f43cab5621d530c3b6"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:9289fd5dddcf57bab41d044f1756550f9e7cf0c8e373b8cdf0ce8773dc4bd417"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6b493a043635eb376e50eedf7818f2f322eabbaa974e948bd8bdd29eb7ef2a51"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:9fa2566ca27d67c86569e8c85297aaf413ffab85a8960500f12ea34ff98e4c41"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a8e538f46104c815be19c975572d74afb53f29650ea2025bbfaef359d2de2f7f"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6fd30dc99682dc2c603c2b315bded2799019cea829f8bf57dc6b61efde6611c8"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:2006769bd1640bdf4d5641c69a3d63b71b81445473cac5ded39740a226fa88ab"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:dc15e99b2d8a656f8e666854404f1ba54765871104e50c8e9813af8a7db07f12"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:ab2e5bef076f5a235c3774b4f4028a680432cded7cad37bba0fd90d64b187d19"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-musllinux_1_2_ppc64le.whl", hash = "sha256:4ec9dd88a5b71abfc74e9df5ebe7921c35cbb3b641181a531ca65cdb5e8e4dea"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-musllinux_1_2_s390x.whl", hash = "sha256:43193c5cda5d612f247172016c4bb71251c784d7a4d9314677186a838ad34858"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:aa693779a8b50cd97570e5a0f343538a8dbd3e496fa5dcb87e29406ad0299654"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-win32.whl", hash = "sha256:7706f5850360ac01d80c89bcef1640683cc12ed87f42579dab6c5d3ed6888613"},
+    {file = "charset_normalizer-3.4.0-cp38-cp38-win_amd64.whl", hash = "sha256:c3e446d253bd88f6377260d07c895816ebf33ffffd56c1c792b13bff9c3e1ade"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:980b4f289d1d90ca5efcf07958d3eb38ed9c0b7676bf2831a54d4f66f9c27dfa"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:f28f891ccd15c514a0981f3b9db9aa23d62fe1a99997512b0491d2ed323d229a"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a8aacce6e2e1edcb6ac625fb0f8c3a9570ccc7bfba1f63419b3769ccf6a00ed0"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bd7af3717683bea4c87acd8c0d3d5b44d56120b26fd3f8a692bdd2d5260c620a"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:5ff2ed8194587faf56555927b3aa10e6fb69d931e33953943bc4f837dfee2242"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:e91f541a85298cf35433bf66f3fab2a4a2cff05c127eeca4af174f6d497f0d4b"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:309a7de0a0ff3040acaebb35ec45d18db4b28232f21998851cfa709eeff49d62"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:285e96d9d53422efc0d7a17c60e59f37fbf3dfa942073f666db4ac71e8d726d0"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:5d447056e2ca60382d460a604b6302d8db69476fd2015c81e7c35417cfabe4cd"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:20587d20f557fe189b7947d8e7ec5afa110ccf72a3128d61a2a387c3313f46be"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-musllinux_1_2_ppc64le.whl", hash = "sha256:130272c698667a982a5d0e626851ceff662565379baf0ff2cc58067b81d4f11d"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-musllinux_1_2_s390x.whl", hash = "sha256:ab22fbd9765e6954bc0bcff24c25ff71dcbfdb185fcdaca49e81bac68fe724d3"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:7782afc9b6b42200f7362858f9e73b1f8316afb276d316336c0ec3bd73312742"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-win32.whl", hash = "sha256:2de62e8801ddfff069cd5c504ce3bc9672b23266597d4e4f50eda28846c322f2"},
+    {file = "charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl", hash = "sha256:95c3c157765b031331dd4db3c775e58deaee050a3042fcad72cbc4189d7c8dca"},
+    {file = "charset_normalizer-3.4.0-py3-none-any.whl", hash = "sha256:fe9f97feb71aa9896b81973a7bbada8c49501dc73e58a10fcef6663af95e5079"},
+    {file = "charset_normalizer-3.4.0.tar.gz", hash = "sha256:223217c3d4f82c3ac5e29032b3f1c2eb0fb591b72161f86d93f5719079dae93e"},
+]
+
 [[package]]
 name = "colorama"
 version = "0.4.6"
@@ -205,9 +327,6 @@ files = [
     {file = "coverage-7.6.4.tar.gz", hash = "sha256:29fc0f17b1d3fea332f8001d4558f8214af7f1d87a345f3a133c901d60347c73"},
 ]
 
-[package.dependencies]
-tomli = {version = "*", optional = true, markers = "python_full_version <= \"3.11.0a6\" and extra == \"toml\""}
-
 [package.extras]
 toml = ["tomli"]
 
@@ -261,20 +380,6 @@ files = [
 graph = ["objgraph (>=1.7.2)"]
 profile = ["gprof2dot (>=2022.7.29)"]
 
-[[package]]
-name = "exceptiongroup"
-version = "1.2.2"
-description = "Backport of PEP 654 (exception groups)"
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "exceptiongroup-1.2.2-py3-none-any.whl", hash = "sha256:3111b9d131c238bec2f8f516e123e14ba243563fb135d3fe885990585aa7795b"},
-    {file = "exceptiongroup-1.2.2.tar.gz", hash = "sha256:47c2edf7c6738fafb49fd34290706d1a1a2f4d1c6df275526b62cbb4aa5393cc"},
-]
-
-[package.extras]
-test = ["pytest (>=6)"]
-
 [[package]]
 name = "execnet"
 version = "2.1.1"
@@ -289,6 +394,29 @@ files = [
 [package.extras]
 testing = ["hatch", "pre-commit", "pytest", "tox"]
 
+[[package]]
+name = "google-auth"
+version = "2.36.0"
+description = "Google Authentication Library"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "google_auth-2.36.0-py2.py3-none-any.whl", hash = "sha256:51a15d47028b66fd36e5c64a82d2d57480075bccc7da37cde257fc94177a61fb"},
+    {file = "google_auth-2.36.0.tar.gz", hash = "sha256:545e9618f2df0bcbb7dcbc45a546485b1212624716975a1ea5ae8149ce769ab1"},
+]
+
+[package.dependencies]
+cachetools = ">=2.0.0,<6.0"
+pyasn1-modules = ">=0.2.1"
+rsa = ">=3.1.4,<5"
+
+[package.extras]
+aiohttp = ["aiohttp (>=3.6.2,<4.0.0.dev0)", "requests (>=2.20.0,<3.0.0.dev0)"]
+enterprise-cert = ["cryptography", "pyopenssl"]
+pyopenssl = ["cryptography (>=38.0.3)", "pyopenssl (>=20.0.0)"]
+reauth = ["pyu2f (>=0.1.5)"]
+requests = ["requests (>=2.20.0,<3.0.0.dev0)"]
+
 [[package]]
 name = "gprof2dot"
 version = "2024.6.6"
@@ -300,6 +428,92 @@ files = [
     {file = "gprof2dot-2024.6.6.tar.gz", hash = "sha256:fa1420c60025a9eb7734f65225b4da02a10fc6dd741b37fa129bc6b41951e5ab"},
 ]
 
+[[package]]
+name = "greenlet"
+version = "3.1.1"
+description = "Lightweight in-process concurrent programming"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "greenlet-3.1.1-cp310-cp310-macosx_11_0_universal2.whl", hash = "sha256:0bbae94a29c9e5c7e4a2b7f0aae5c17e8e90acbfd3bf6270eeba60c39fce3563"},
+    {file = "greenlet-3.1.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0fde093fb93f35ca72a556cf72c92ea3ebfda3d79fc35bb19fbe685853869a83"},
+    {file = "greenlet-3.1.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:36b89d13c49216cadb828db8dfa6ce86bbbc476a82d3a6c397f0efae0525bdd0"},
+    {file = "greenlet-3.1.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:94b6150a85e1b33b40b1464a3f9988dcc5251d6ed06842abff82e42632fac120"},
+    {file = "greenlet-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:93147c513fac16385d1036b7e5b102c7fbbdb163d556b791f0f11eada7ba65dc"},
+    {file = "greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:da7a9bff22ce038e19bf62c4dd1ec8391062878710ded0a845bcf47cc0200617"},
+    {file = "greenlet-3.1.1-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:b2795058c23988728eec1f36a4e5e4ebad22f8320c85f3587b539b9ac84128d7"},
+    {file = "greenlet-3.1.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:ed10eac5830befbdd0c32f83e8aa6288361597550ba669b04c48f0f9a2c843c6"},
+    {file = "greenlet-3.1.1-cp310-cp310-win_amd64.whl", hash = "sha256:77c386de38a60d1dfb8e55b8c1101d68c79dfdd25c7095d51fec2dd800892b80"},
+    {file = "greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl", hash = "sha256:e4d333e558953648ca09d64f13e6d8f0523fa705f51cae3f03b5983489958c70"},
+    {file = "greenlet-3.1.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:09fc016b73c94e98e29af67ab7b9a879c307c6731a2c9da0db5a7d9b7edd1159"},
+    {file = "greenlet-3.1.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d5e975ca70269d66d17dd995dafc06f1b06e8cb1ec1e9ed54c1d1e4a7c4cf26e"},
+    {file = "greenlet-3.1.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3b2813dc3de8c1ee3f924e4d4227999285fd335d1bcc0d2be6dc3f1f6a318ec1"},
+    {file = "greenlet-3.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e347b3bfcf985a05e8c0b7d462ba6f15b1ee1c909e2dcad795e49e91b152c383"},
+    {file = "greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:9e8f8c9cb53cdac7ba9793c276acd90168f416b9ce36799b9b885790f8ad6c0a"},
+    {file = "greenlet-3.1.1-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:62ee94988d6b4722ce0028644418d93a52429e977d742ca2ccbe1c4f4a792511"},
+    {file = "greenlet-3.1.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:1776fd7f989fc6b8d8c8cb8da1f6b82c5814957264d1f6cf818d475ec2bf6395"},
+    {file = "greenlet-3.1.1-cp311-cp311-win_amd64.whl", hash = "sha256:48ca08c771c268a768087b408658e216133aecd835c0ded47ce955381105ba39"},
+    {file = "greenlet-3.1.1-cp312-cp312-macosx_11_0_universal2.whl", hash = "sha256:4afe7ea89de619adc868e087b4d2359282058479d7cfb94970adf4b55284574d"},
+    {file = "greenlet-3.1.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f406b22b7c9a9b4f8aa9d2ab13d6ae0ac3e85c9a809bd590ad53fed2bf70dc79"},
+    {file = "greenlet-3.1.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:c3a701fe5a9695b238503ce5bbe8218e03c3bcccf7e204e455e7462d770268aa"},
+    {file = "greenlet-3.1.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2846930c65b47d70b9d178e89c7e1a69c95c1f68ea5aa0a58646b7a96df12441"},
+    {file = "greenlet-3.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:99cfaa2110534e2cf3ba31a7abcac9d328d1d9f1b95beede58294a60348fba36"},
+    {file = "greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:1443279c19fca463fc33e65ef2a935a5b09bb90f978beab37729e1c3c6c25fe9"},
+    {file = "greenlet-3.1.1-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:b7cede291382a78f7bb5f04a529cb18e068dd29e0fb27376074b6d0317bf4dd0"},
+    {file = "greenlet-3.1.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:23f20bb60ae298d7d8656c6ec6db134bca379ecefadb0b19ce6f19d1f232a942"},
+    {file = "greenlet-3.1.1-cp312-cp312-win_amd64.whl", hash = "sha256:7124e16b4c55d417577c2077be379514321916d5790fa287c9ed6f23bd2ffd01"},
+    {file = "greenlet-3.1.1-cp313-cp313-macosx_11_0_universal2.whl", hash = "sha256:05175c27cb459dcfc05d026c4232f9de8913ed006d42713cb8a5137bd49375f1"},
+    {file = "greenlet-3.1.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:935e943ec47c4afab8965954bf49bfa639c05d4ccf9ef6e924188f762145c0ff"},
+    {file = "greenlet-3.1.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:667a9706c970cb552ede35aee17339a18e8f2a87a51fba2ed39ceeeb1004798a"},
+    {file = "greenlet-3.1.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:b8a678974d1f3aa55f6cc34dc480169d58f2e6d8958895d68845fa4ab566509e"},
+    {file = "greenlet-3.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:efc0f674aa41b92da8c49e0346318c6075d734994c3c4e4430b1c3f853e498e4"},
+    {file = "greenlet-3.1.1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:0153404a4bb921f0ff1abeb5ce8a5131da56b953eda6e14b88dc6bbc04d2049e"},
+    {file = "greenlet-3.1.1-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:275f72decf9932639c1c6dd1013a1bc266438eb32710016a1c742df5da6e60a1"},
+    {file = "greenlet-3.1.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:c4aab7f6381f38a4b42f269057aee279ab0fc7bf2e929e3d4abfae97b682a12c"},
+    {file = "greenlet-3.1.1-cp313-cp313-win_amd64.whl", hash = "sha256:b42703b1cf69f2aa1df7d1030b9d77d3e584a70755674d60e710f0af570f3761"},
+    {file = "greenlet-3.1.1-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f1695e76146579f8c06c1509c7ce4dfe0706f49c6831a817ac04eebb2fd02011"},
+    {file = "greenlet-3.1.1-cp313-cp313t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:7876452af029456b3f3549b696bb36a06db7c90747740c5302f74a9e9fa14b13"},
+    {file = "greenlet-3.1.1-cp313-cp313t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:4ead44c85f8ab905852d3de8d86f6f8baf77109f9da589cb4fa142bd3b57b475"},
+    {file = "greenlet-3.1.1-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8320f64b777d00dd7ccdade271eaf0cad6636343293a25074cc5566160e4de7b"},
+    {file = "greenlet-3.1.1-cp313-cp313t-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:6510bf84a6b643dabba74d3049ead221257603a253d0a9873f55f6a59a65f822"},
+    {file = "greenlet-3.1.1-cp313-cp313t-musllinux_1_1_aarch64.whl", hash = "sha256:04b013dc07c96f83134b1e99888e7a79979f1a247e2a9f59697fa14b5862ed01"},
+    {file = "greenlet-3.1.1-cp313-cp313t-musllinux_1_1_x86_64.whl", hash = "sha256:411f015496fec93c1c8cd4e5238da364e1da7a124bcb293f085bf2860c32c6f6"},
+    {file = "greenlet-3.1.1-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:47da355d8687fd65240c364c90a31569a133b7b60de111c255ef5b606f2ae291"},
+    {file = "greenlet-3.1.1-cp37-cp37m-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:98884ecf2ffb7d7fe6bd517e8eb99d31ff7855a840fa6d0d63cd07c037f6a981"},
+    {file = "greenlet-3.1.1-cp37-cp37m-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f1d4aeb8891338e60d1ab6127af1fe45def5259def8094b9c7e34690c8858803"},
+    {file = "greenlet-3.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:db32b5348615a04b82240cc67983cb315309e88d444a288934ee6ceaebcad6cc"},
+    {file = "greenlet-3.1.1-cp37-cp37m-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:dcc62f31eae24de7f8dce72134c8651c58000d3b1868e01392baea7c32c247de"},
+    {file = "greenlet-3.1.1-cp37-cp37m-musllinux_1_1_aarch64.whl", hash = "sha256:1d3755bcb2e02de341c55b4fca7a745a24a9e7212ac953f6b3a48d117d7257aa"},
+    {file = "greenlet-3.1.1-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:b8da394b34370874b4572676f36acabac172602abf054cbc4ac910219f3340af"},
+    {file = "greenlet-3.1.1-cp37-cp37m-win32.whl", hash = "sha256:a0dfc6c143b519113354e780a50381508139b07d2177cb6ad6a08278ec655798"},
+    {file = "greenlet-3.1.1-cp37-cp37m-win_amd64.whl", hash = "sha256:54558ea205654b50c438029505def3834e80f0869a70fb15b871c29b4575ddef"},
+    {file = "greenlet-3.1.1-cp38-cp38-macosx_11_0_universal2.whl", hash = "sha256:346bed03fe47414091be4ad44786d1bd8bef0c3fcad6ed3dee074a032ab408a9"},
+    {file = "greenlet-3.1.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:dfc59d69fc48664bc693842bd57acfdd490acafda1ab52c7836e3fc75c90a111"},
+    {file = "greenlet-3.1.1-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d21e10da6ec19b457b82636209cbe2331ff4306b54d06fa04b7c138ba18c8a81"},
+    {file = "greenlet-3.1.1-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:37b9de5a96111fc15418819ab4c4432e4f3c2ede61e660b1e33971eba26ef9ba"},
+    {file = "greenlet-3.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6ef9ea3f137e5711f0dbe5f9263e8c009b7069d8a1acea822bd5e9dae0ae49c8"},
+    {file = "greenlet-3.1.1-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:85f3ff71e2e60bd4b4932a043fbbe0f499e263c628390b285cb599154a3b03b1"},
+    {file = "greenlet-3.1.1-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:95ffcf719966dd7c453f908e208e14cde192e09fde6c7186c8f1896ef778d8cd"},
+    {file = "greenlet-3.1.1-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:03a088b9de532cbfe2ba2034b2b85e82df37874681e8c470d6fb2f8c04d7e4b7"},
+    {file = "greenlet-3.1.1-cp38-cp38-win32.whl", hash = "sha256:8b8b36671f10ba80e159378df9c4f15c14098c4fd73a36b9ad715f057272fbef"},
+    {file = "greenlet-3.1.1-cp38-cp38-win_amd64.whl", hash = "sha256:7017b2be767b9d43cc31416aba48aab0d2309ee31b4dbf10a1d38fb7972bdf9d"},
+    {file = "greenlet-3.1.1-cp39-cp39-macosx_11_0_universal2.whl", hash = "sha256:396979749bd95f018296af156201d6211240e7a23090f50a8d5d18c370084dc3"},
+    {file = "greenlet-3.1.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ca9d0ff5ad43e785350894d97e13633a66e2b50000e8a183a50a88d834752d42"},
+    {file = "greenlet-3.1.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f6ff3b14f2df4c41660a7dec01045a045653998784bf8cfcb5a525bdffffbc8f"},
+    {file = "greenlet-3.1.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:94ebba31df2aa506d7b14866fed00ac141a867e63143fe5bca82a8e503b36437"},
+    {file = "greenlet-3.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:73aaad12ac0ff500f62cebed98d8789198ea0e6f233421059fa68a5aa7220145"},
+    {file = "greenlet-3.1.1-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:63e4844797b975b9af3a3fb8f7866ff08775f5426925e1e0bbcfe7932059a12c"},
+    {file = "greenlet-3.1.1-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:7939aa3ca7d2a1593596e7ac6d59391ff30281ef280d8632fa03d81f7c5f955e"},
+    {file = "greenlet-3.1.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:d0028e725ee18175c6e422797c407874da24381ce0690d6b9396c204c7f7276e"},
+    {file = "greenlet-3.1.1-cp39-cp39-win32.whl", hash = "sha256:5e06afd14cbaf9e00899fae69b24a32f2196c19de08fcb9f4779dd4f004e5e7c"},
+    {file = "greenlet-3.1.1-cp39-cp39-win_amd64.whl", hash = "sha256:3319aa75e0e0639bc15ff54ca327e8dc7a6fe404003496e3c6925cd3142e0e22"},
+    {file = "greenlet-3.1.1.tar.gz", hash = "sha256:4ce3ac6cdb6adf7946475d7ef31777c26d94bccc377e070a7986bd2d5c515467"},
+]
+
+[package.extras]
+docs = ["Sphinx", "furo"]
+test = ["objgraph", "psutil"]
+
 [[package]]
 name = "h11"
 version = "0.14.0"
@@ -584,52 +798,52 @@ yaml = ["pyyaml"]
 
 [[package]]
 name = "mypy"
-version = "1.12.1"
+version = "1.15.0"
 description = "Optional static typing for Python"
 optional = false
-python-versions = ">=3.8"
+python-versions = ">=3.9"
 files = [
-    {file = "mypy-1.12.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:3d7d4371829184e22fda4015278fbfdef0327a4b955a483012bd2d423a788801"},
-    {file = "mypy-1.12.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:f59f1dfbf497d473201356966e353ef09d4daec48caeacc0254db8ef633a28a5"},
-    {file = "mypy-1.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:b947097fae68004b8328c55161ac9db7d3566abfef72d9d41b47a021c2fba6b1"},
-    {file = "mypy-1.12.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:96af62050971c5241afb4701c15189ea9507db89ad07794a4ee7b4e092dc0627"},
-    {file = "mypy-1.12.1-cp310-cp310-win_amd64.whl", hash = "sha256:d90da248f4c2dba6c44ddcfea94bb361e491962f05f41990ff24dbd09969ce20"},
-    {file = "mypy-1.12.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:1230048fec1380faf240be6385e709c8570604d2d27ec6ca7e573e3bc09c3735"},
-    {file = "mypy-1.12.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:02dcfe270c6ea13338210908f8cadc8d31af0f04cee8ca996438fe6a97b4ec66"},
-    {file = "mypy-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:a5a437c9102a6a252d9e3a63edc191a3aed5f2fcb786d614722ee3f4472e33f6"},
-    {file = "mypy-1.12.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:186e0c8346efc027ee1f9acf5ca734425fc4f7dc2b60144f0fbe27cc19dc7931"},
-    {file = "mypy-1.12.1-cp311-cp311-win_amd64.whl", hash = "sha256:673ba1140a478b50e6d265c03391702fa11a5c5aff3f54d69a62a48da32cb811"},
-    {file = "mypy-1.12.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:9fb83a7be97c498176fb7486cafbb81decccaef1ac339d837c377b0ce3743a7f"},
-    {file = "mypy-1.12.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:389e307e333879c571029d5b93932cf838b811d3f5395ed1ad05086b52148fb0"},
-    {file = "mypy-1.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:94b2048a95a21f7a9ebc9fbd075a4fcd310410d078aa0228dbbad7f71335e042"},
-    {file = "mypy-1.12.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:4ee5932370ccf7ebf83f79d1c157a5929d7ea36313027b0d70a488493dc1b179"},
-    {file = "mypy-1.12.1-cp312-cp312-win_amd64.whl", hash = "sha256:19bf51f87a295e7ab2894f1d8167622b063492d754e69c3c2fed6563268cb42a"},
-    {file = "mypy-1.12.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:d34167d43613ffb1d6c6cdc0cc043bb106cac0aa5d6a4171f77ab92a3c758bcc"},
-    {file = "mypy-1.12.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:427878aa54f2e2c5d8db31fa9010c599ed9f994b3b49e64ae9cd9990c40bd635"},
-    {file = "mypy-1.12.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:5fcde63ea2c9f69d6be859a1e6dd35955e87fa81de95bc240143cf00de1f7f81"},
-    {file = "mypy-1.12.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:d54d840f6c052929f4a3d2aab2066af0f45a020b085fe0e40d4583db52aab4e4"},
-    {file = "mypy-1.12.1-cp313-cp313-win_amd64.whl", hash = "sha256:20db6eb1ca3d1de8ece00033b12f793f1ea9da767334b7e8c626a4872090cf02"},
-    {file = "mypy-1.12.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:b16fe09f9c741d85a2e3b14a5257a27a4f4886c171d562bc5a5e90d8591906b8"},
-    {file = "mypy-1.12.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:0dcc1e843d58f444fce19da4cce5bd35c282d4bde232acdeca8279523087088a"},
-    {file = "mypy-1.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:e10ba7de5c616e44ad21005fa13450cd0de7caaa303a626147d45307492e4f2d"},
-    {file = "mypy-1.12.1-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:0e6fe449223fa59fbee351db32283838a8fee8059e0028e9e6494a03802b4004"},
-    {file = "mypy-1.12.1-cp38-cp38-win_amd64.whl", hash = "sha256:dc6e2a2195a290a7fd5bac3e60b586d77fc88e986eba7feced8b778c373f9afe"},
-    {file = "mypy-1.12.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:de5b2a8988b4e1269a98beaf0e7cc71b510d050dce80c343b53b4955fff45f19"},
-    {file = "mypy-1.12.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:843826966f1d65925e8b50d2b483065c51fc16dc5d72647e0236aae51dc8d77e"},
-    {file = "mypy-1.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:9fe20f89da41a95e14c34b1ddb09c80262edcc295ad891f22cc4b60013e8f78d"},
-    {file = "mypy-1.12.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:8135ffec02121a75f75dc97c81af7c14aa4ae0dda277132cfcd6abcd21551bfd"},
-    {file = "mypy-1.12.1-cp39-cp39-win_amd64.whl", hash = "sha256:a7b76fa83260824300cc4834a3ab93180db19876bce59af921467fd03e692810"},
-    {file = "mypy-1.12.1-py3-none-any.whl", hash = "sha256:ce561a09e3bb9863ab77edf29ae3a50e65685ad74bba1431278185b7e5d5486e"},
-    {file = "mypy-1.12.1.tar.gz", hash = "sha256:f5b3936f7a6d0e8280c9bdef94c7ce4847f5cdfc258fbb2c29a8c1711e8bb96d"},
+    {file = "mypy-1.15.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:979e4e1a006511dacf628e36fadfecbcc0160a8af6ca7dad2f5025529e082c13"},
+    {file = "mypy-1.15.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:c4bb0e1bd29f7d34efcccd71cf733580191e9a264a2202b0239da95984c5b559"},
+    {file = "mypy-1.15.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:be68172e9fd9ad8fb876c6389f16d1c1b5f100ffa779f77b1fb2176fcc9ab95b"},
+    {file = "mypy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:c7be1e46525adfa0d97681432ee9fcd61a3964c2446795714699a998d193f1a3"},
+    {file = "mypy-1.15.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:2e2c2e6d3593f6451b18588848e66260ff62ccca522dd231cd4dd59b0160668b"},
+    {file = "mypy-1.15.0-cp310-cp310-win_amd64.whl", hash = "sha256:6983aae8b2f653e098edb77f893f7b6aca69f6cffb19b2cc7443f23cce5f4828"},
+    {file = "mypy-1.15.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:2922d42e16d6de288022e5ca321cd0618b238cfc5570e0263e5ba0a77dbef56f"},
+    {file = "mypy-1.15.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:2ee2d57e01a7c35de00f4634ba1bbf015185b219e4dc5909e281016df43f5ee5"},
+    {file = "mypy-1.15.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:973500e0774b85d9689715feeffcc980193086551110fd678ebe1f4342fb7c5e"},
+    {file = "mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:5a95fb17c13e29d2d5195869262f8125dfdb5c134dc8d9a9d0aecf7525b10c2c"},
+    {file = "mypy-1.15.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:1905f494bfd7d85a23a88c5d97840888a7bd516545fc5aaedff0267e0bb54e2f"},
+    {file = "mypy-1.15.0-cp311-cp311-win_amd64.whl", hash = "sha256:c9817fa23833ff189db061e6d2eff49b2f3b6ed9856b4a0a73046e41932d744f"},
+    {file = "mypy-1.15.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:aea39e0583d05124836ea645f412e88a5c7d0fd77a6d694b60d9b6b2d9f184fd"},
+    {file = "mypy-1.15.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:2f2147ab812b75e5b5499b01ade1f4a81489a147c01585cda36019102538615f"},
+    {file = "mypy-1.15.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:ce436f4c6d218a070048ed6a44c0bbb10cd2cc5e272b29e7845f6a2f57ee4464"},
+    {file = "mypy-1.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:8023ff13985661b50a5928fc7a5ca15f3d1affb41e5f0a9952cb68ef090b31ee"},
+    {file = "mypy-1.15.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:1124a18bc11a6a62887e3e137f37f53fbae476dc36c185d549d4f837a2a6a14e"},
+    {file = "mypy-1.15.0-cp312-cp312-win_amd64.whl", hash = "sha256:171a9ca9a40cd1843abeca0e405bc1940cd9b305eaeea2dda769ba096932bb22"},
+    {file = "mypy-1.15.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:93faf3fdb04768d44bf28693293f3904bbb555d076b781ad2530214ee53e3445"},
+    {file = "mypy-1.15.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:811aeccadfb730024c5d3e326b2fbe9249bb7413553f15499a4050f7c30e801d"},
+    {file = "mypy-1.15.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:98b7b9b9aedb65fe628c62a6dc57f6d5088ef2dfca37903a7d9ee374d03acca5"},
+    {file = "mypy-1.15.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:c43a7682e24b4f576d93072216bf56eeff70d9140241f9edec0c104d0c515036"},
+    {file = "mypy-1.15.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:baefc32840a9f00babd83251560e0ae1573e2f9d1b067719479bfb0e987c6357"},
+    {file = "mypy-1.15.0-cp313-cp313-win_amd64.whl", hash = "sha256:b9378e2c00146c44793c98b8d5a61039a048e31f429fb0eb546d93f4b000bedf"},
+    {file = "mypy-1.15.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:e601a7fa172c2131bff456bb3ee08a88360760d0d2f8cbd7a75a65497e2df078"},
+    {file = "mypy-1.15.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:712e962a6357634fef20412699a3655c610110e01cdaa6180acec7fc9f8513ba"},
+    {file = "mypy-1.15.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:f95579473af29ab73a10bada2f9722856792a36ec5af5399b653aa28360290a5"},
+    {file = "mypy-1.15.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:8f8722560a14cde92fdb1e31597760dc35f9f5524cce17836c0d22841830fd5b"},
+    {file = "mypy-1.15.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:1fbb8da62dc352133d7d7ca90ed2fb0e9d42bb1a32724c287d3c76c58cbaa9c2"},
+    {file = "mypy-1.15.0-cp39-cp39-win_amd64.whl", hash = "sha256:d10d994b41fb3497719bbf866f227b3489048ea4bbbb5015357db306249f7980"},
+    {file = "mypy-1.15.0-py3-none-any.whl", hash = "sha256:5469affef548bd1895d86d3bf10ce2b44e33d86923c29e4d675b3e323437ea3e"},
+    {file = "mypy-1.15.0.tar.gz", hash = "sha256:404534629d51d3efea5c800ee7c42b72a6554d6c400e6a79eafe15d11341fd43"},
 ]
 
 [package.dependencies]
-mypy-extensions = ">=1.0.0"
-tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
-typing-extensions = ">=4.6.0"
+mypy_extensions = ">=1.0.0"
+typing_extensions = ">=4.6.0"
 
 [package.extras]
 dmypy = ["psutil (>=4.0)"]
+faster-cache = ["orjson"]
 install-types = ["pip"]
 mypyc = ["setuptools (>=50)"]
 reports = ["lxml"]
@@ -809,12 +1023,7 @@ files = [
 ]
 
 [package.dependencies]
-numpy = [
-    {version = ">=1.17.3", markers = "(platform_machine != \"aarch64\" and platform_machine != \"arm64\") and python_version < \"3.10\""},
-    {version = ">=1.19.2", markers = "platform_machine == \"aarch64\" and python_version < \"3.10\""},
-    {version = ">=1.20.0", markers = "platform_machine == \"arm64\" and python_version < \"3.10\""},
-    {version = ">=1.21.0", markers = "python_version >= \"3.10\""},
-]
+numpy = {version = ">=1.21.0", markers = "python_version >= \"3.10\""}
 python-dateutil = ">=2.7.3"
 pytz = ">=2017.3"
 
@@ -823,12 +1032,12 @@ test = ["hypothesis (>=3.58)", "pytest (>=6.0)", "pytest-xdist"]
 
 [[package]]
 name = "perfetto"
-version = "0.10.0"
+version = "0.11.0"
 description = "Python API for Perfetto's Trace Processor"
 optional = false
 python-versions = "*"
 files = [
-    {file = "perfetto-0.10.0.tar.gz", hash = "sha256:d6ead832a9aea2da26562977f0403e6fbefb70920041eb08791cfaf6689579c3"},
+    {file = "perfetto-0.11.0.tar.gz", hash = "sha256:eea8d1ca8bec12c55d33c9db5b6e0ea380f06c2a318472ca319a956c2aec67f1"},
 ]
 
 [package.dependencies]
@@ -913,6 +1122,31 @@ files = [
 [package.extras]
 test = ["enum34", "ipaddress", "mock", "pywin32", "wmi"]
 
+[[package]]
+name = "pyasn1"
+version = "0.6.1"
+description = "Pure-Python implementation of ASN.1 types and DER/BER/CER codecs (X.208)"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pyasn1-0.6.1-py3-none-any.whl", hash = "sha256:0d632f46f2ba09143da3a8afe9e33fb6f92fa2320ab7e886e2d0f7672af84629"},
+    {file = "pyasn1-0.6.1.tar.gz", hash = "sha256:6f580d2bdd84365380830acf45550f2511469f673cb4a5ae3857a3170128b034"},
+]
+
+[[package]]
+name = "pyasn1-modules"
+version = "0.4.1"
+description = "A collection of ASN.1-based protocols modules"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pyasn1_modules-0.4.1-py3-none-any.whl", hash = "sha256:49bfa96b45a292b711e986f222502c1c9a5e1f4e568fc30e2574a6c7d07838fd"},
+    {file = "pyasn1_modules-0.4.1.tar.gz", hash = "sha256:c28e2dbf9c06ad61c71a075c7e0f9fd0f1b0bb2d2ad4377f240d33ac2ab60a7c"},
+]
+
+[package.dependencies]
+pyasn1 = ">=0.4.6,<0.7.0"
+
 [[package]]
 name = "pycnite"
 version = "2024.7.31"
@@ -956,15 +1190,29 @@ tests = ["chardet", "parameterized", "pytest", "pytest-cov", "pytest-xdist[psuti
 
 [[package]]
 name = "pyfakefs"
-version = "5.7.1"
+version = "5.7.4"
 description = "pyfakefs implements a fake file system that mocks the Python file system modules."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "pyfakefs-5.7.1-py3-none-any.whl", hash = "sha256:6503ffe7f401701cf974b502311f926da2b0657a72244a6ba36e985ceb3dd783"},
-    {file = "pyfakefs-5.7.1.tar.gz", hash = "sha256:24774c632f3b67ea26fd56b08115ba7c339d5cd65655410bca8572d73a1ae9a4"},
+    {file = "pyfakefs-5.7.4-py3-none-any.whl", hash = "sha256:3e763d700b91c54ade6388be2cfa4e521abc00e34f7defb84ee511c73031f45f"},
+    {file = "pyfakefs-5.7.4.tar.gz", hash = "sha256:4971e65cc80a93a1e6f1e3a4654909c0c493186539084dc9301da3d68c8878fe"},
+]
+
+[[package]]
+name = "pygments"
+version = "2.18.0"
+description = "Pygments is a syntax highlighting package written in Python."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pygments-2.18.0-py3-none-any.whl", hash = "sha256:b8e6aca0523f3ab76fee51799c488e38782ac06eafcf95e7ba832985c8e7b13a"},
+    {file = "pygments-2.18.0.tar.gz", hash = "sha256:786ff802f32e91311bff3889f6e9a86e81505fe99f2735bb6d60ae0c5004f199"},
 ]
 
+[package.extras]
+windows-terminal = ["colorama (>=0.4.6)"]
+
 [[package]]
 name = "pylint"
 version = "3.3.1"
@@ -979,16 +1227,11 @@ files = [
 [package.dependencies]
 astroid = ">=3.3.4,<=3.4.0-dev0"
 colorama = {version = ">=0.4.5", markers = "sys_platform == \"win32\""}
-dill = [
-    {version = ">=0.2", markers = "python_version < \"3.11\""},
-    {version = ">=0.3.6", markers = "python_version >= \"3.11\""},
-]
+dill = {version = ">=0.3.6", markers = "python_version >= \"3.11\""}
 isort = ">=4.2.5,<5.13.0 || >5.13.0,<6"
 mccabe = ">=0.6,<0.8"
 platformdirs = ">=2.2.0"
-tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
 tomlkit = ">=0.10.1"
-typing-extensions = {version = ">=3.10.0", markers = "python_version < \"3.10\""}
 
 [package.extras]
 spelling = ["pyenchant (>=3.2,<4.0)"]
@@ -1033,11 +1276,9 @@ files = [
 
 [package.dependencies]
 colorama = {version = "*", markers = "sys_platform == \"win32\""}
-exceptiongroup = {version = ">=1.0.0rc8", markers = "python_version < \"3.11\""}
 iniconfig = "*"
 packaging = "*"
 pluggy = ">=0.12,<2.0"
-tomli = {version = ">=1.0.0", markers = "python_version < \"3.11\""}
 
 [package.extras]
 testing = ["argcomplete", "attrs (>=19.2.0)", "hypothesis (>=3.56)", "mock", "nose", "pygments (>=2.7.2)", "requests", "setuptools", "xmlschema"]
@@ -1130,27 +1371,21 @@ six = ">=1.5"
 
 [[package]]
 name = "pytype"
-version = "2024.9.13"
+version = "2024.10.11"
 description = "Python type inferencer"
 optional = false
-python-versions = ">=3.8"
+python-versions = ">=3.10"
 files = [
-    {file = "pytype-2024.9.13-cp310-cp310-macosx_12_0_x86_64.whl", hash = "sha256:52c0005d220b27f9c933e4077de700c4e8171abce0c2af72f4c6263a85ff5bce"},
-    {file = "pytype-2024.9.13-cp310-cp310-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:2d5dc847c2fe98bac044f956e2fc9f074f09704b64436522b81ede7dd5fa3653"},
-    {file = "pytype-2024.9.13-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:529f19141c6170d96a38909df430ca52e6904eaef851ad2690cf632f17d2c195"},
-    {file = "pytype-2024.9.13-cp311-cp311-macosx_10_14_universal2.whl", hash = "sha256:38f3eddf05d8530ef16d3d7c2da2556148b9975fc7c3405ac3073022e1a7434b"},
-    {file = "pytype-2024.9.13-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:1b530eae5ab421a2dc9c4ef53f68629c5a622545150ae9702dbb811f56852a63"},
-    {file = "pytype-2024.9.13-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:eb9eaaaf6c33e2716fdce1cf4166d3e5099372d8898b69ab7673225928096456"},
-    {file = "pytype-2024.9.13-cp312-cp312-macosx_10_14_universal2.whl", hash = "sha256:53b767d85f374c7483c8b2849dceb811a15fcb01520e245dd82bd7c0e2befefb"},
-    {file = "pytype-2024.9.13-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:176a5bbc0cb0882918a0b48818b95df2c15811e3a8391da089ffc5b33fea7013"},
-    {file = "pytype-2024.9.13-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:7bdaf1eaaf17a13741f67686c2d4c94c30279cd682c7e4cf535e41fc911b0e59"},
-    {file = "pytype-2024.9.13-cp38-cp38-macosx_12_0_x86_64.whl", hash = "sha256:425011cc45fba8c83af796155049f9db89d11e8aedbfb21bc1c99408f4a2c4e3"},
-    {file = "pytype-2024.9.13-cp38-cp38-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:6e500727967b843488c1978114778162ef00fee9be49dfa5b4758dcbbcc55dd9"},
-    {file = "pytype-2024.9.13-cp38-cp38-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:b9b40beab6ef04fc260d86a8ef47b25d1b525dbc4cfbcb73151fd74210c176df"},
-    {file = "pytype-2024.9.13-cp39-cp39-macosx_12_0_x86_64.whl", hash = "sha256:b5fdc24b60938ee846dfbdf08b5ea96e934e7d69c34eb1f8fb7707083d177f0e"},
-    {file = "pytype-2024.9.13-cp39-cp39-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:8dcfd509118c2d7e0787e72832b45e30037af1c29dfcb733a7e8014f58337287"},
-    {file = "pytype-2024.9.13-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:9df731062dc18518a46135c4825ad966e1a275ffc0723dd62f9771b420889da0"},
-    {file = "pytype-2024.9.13.tar.gz", hash = "sha256:941046ca0f1c43b79162bb51836fef0ba6608012d99f6833148c249f22216f26"},
+    {file = "pytype-2024.10.11-cp310-cp310-macosx_12_0_x86_64.whl", hash = "sha256:1c5a43b132b19928a38ba1dbcf8f4e3f67a41ea26087ccf26ae371c4076c3809"},
+    {file = "pytype-2024.10.11-cp310-cp310-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:5dd9ecb48aa46ecef14b39f1bbe8ff7e586e499639a056c05bd4436ca0b35d82"},
+    {file = "pytype-2024.10.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:37d8dfdf23679abfdfe047efef7239a438a038e580d7e0767c0403a6be07cea0"},
+    {file = "pytype-2024.10.11-cp311-cp311-macosx_10_14_universal2.whl", hash = "sha256:2e31a964aa82e1ac317adbe17b77010e4f362882df1ce7ad15ef0cf0bb97039f"},
+    {file = "pytype-2024.10.11-cp311-cp311-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:15e2f39590cc08ef8e6704cfa5c1db6fbbee2799891f9d8adbf821f883a54745"},
+    {file = "pytype-2024.10.11-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:ead3408fc9622ba8a357c9a6b9b49059a9b8add0a3b8390a9ab490f62a984005"},
+    {file = "pytype-2024.10.11-cp312-cp312-macosx_10_14_universal2.whl", hash = "sha256:cdc881cce9541a475ec48989a5ab889e6274a85afbf6da0e30266d0823f66d42"},
+    {file = "pytype-2024.10.11-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:13327d0d17b981fe2660dd3a69f97bf09a526f93debc40bb44b240628e0b55c1"},
+    {file = "pytype-2024.10.11-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:fb98711679e631b01b09b09185504fbf38d60f119280918e244a602cf843b0fe"},
+    {file = "pytype-2024.10.11.tar.gz", hash = "sha256:ae5ff82f0b07d5ad68d4ec32a3e8de44fad6ed565a821a76aca50a14df382274"},
 ]
 
 [package.dependencies]
@@ -1160,7 +1395,7 @@ importlab = ">=0.8"
 jinja2 = ">=3.1.2"
 libcst = ">=1.0.1"
 msgspec = ">=0.18.6"
-networkx = "<3.2"
+networkx = ">=2.8"
 ninja = ">=1.10.0.post2"
 pycnite = ">=2024.07.31"
 pydot = ">=1.4.2"
@@ -1241,15 +1476,50 @@ files = [
     {file = "pyyaml-6.0.2.tar.gz", hash = "sha256:d584d9ec91ad65861cc08d42e834324ef890a082e591037abe114850ff7bbc3e"},
 ]
 
+[[package]]
+name = "requests"
+version = "2.32.3"
+description = "Python HTTP for Humans."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "requests-2.32.3-py3-none-any.whl", hash = "sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6"},
+    {file = "requests-2.32.3.tar.gz", hash = "sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760"},
+]
+
+[package.dependencies]
+certifi = ">=2017.4.17"
+charset-normalizer = ">=2,<4"
+idna = ">=2.5,<4"
+urllib3 = ">=1.21.1,<3"
+
+[package.extras]
+socks = ["PySocks (>=1.5.6,!=1.5.7)"]
+use-chardet-on-py3 = ["chardet (>=3.0.2,<6)"]
+
+[[package]]
+name = "rsa"
+version = "4.9"
+description = "Pure-Python RSA implementation"
+optional = false
+python-versions = ">=3.6,<4"
+files = [
+    {file = "rsa-4.9-py3-none-any.whl", hash = "sha256:90260d9058e514786967344d0ef75fa8727eed8a7d2e43ce9f4bcf1b536174f7"},
+    {file = "rsa-4.9.tar.gz", hash = "sha256:e38464a49c6c85d7f1351b0126661487a7e0a14a50f1675ec50eb34d4f20ef21"},
+]
+
+[package.dependencies]
+pyasn1 = ">=0.1.3"
+
 [[package]]
 name = "selenium"
-version = "4.25.0"
+version = "4.26.1"
 description = "Official Python bindings for Selenium WebDriver"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "selenium-4.25.0-py3-none-any.whl", hash = "sha256:3798d2d12b4a570bc5790163ba57fef10b2afee958bf1d80f2a3cf07c4141f33"},
-    {file = "selenium-4.25.0.tar.gz", hash = "sha256:95d08d3b82fb353f3c474895154516604c7f0e6a9a565ae6498ef36c9bac6921"},
+    {file = "selenium-4.26.1-py3-none-any.whl", hash = "sha256:1db3f3a0cd5bb07624fa8a3905a6fdde1595a42185a0617077c361dc53d104fb"},
+    {file = "selenium-4.26.1.tar.gz", hash = "sha256:7640f3f08ae7f4e450f895678e8a10a55eb4e4ca18311ed675ecc4684b96b683"},
 ]
 
 [package.dependencies]
@@ -1293,6 +1563,101 @@ files = [
     {file = "sortedcontainers-2.4.0.tar.gz", hash = "sha256:25caa5a06cc30b6b83d11423433f65d1f9d76c4c6a0c90e3379eaa43b9bfdb88"},
 ]
 
+[[package]]
+name = "sqlalchemy"
+version = "2.0.38"
+description = "Database Abstraction Library"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:5e1d9e429028ce04f187a9f522818386c8b076723cdbe9345708384f49ebcec6"},
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:b87a90f14c68c925817423b0424381f0e16d80fc9a1a1046ef202ab25b19a444"},
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:402c2316d95ed90d3d3c25ad0390afa52f4d2c56b348f212aa9c8d072a40eee5"},
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6493bc0eacdbb2c0f0d260d8988e943fee06089cd239bd7f3d0c45d1657a70e2"},
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:0561832b04c6071bac3aad45b0d3bb6d2c4f46a8409f0a7a9c9fa6673b41bc03"},
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:49aa2cdd1e88adb1617c672a09bf4ebf2f05c9448c6dbeba096a3aeeb9d4d443"},
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-win32.whl", hash = "sha256:64aa8934200e222f72fcfd82ee71c0130a9c07d5725af6fe6e919017d095b297"},
+    {file = "SQLAlchemy-2.0.38-cp310-cp310-win_amd64.whl", hash = "sha256:c57b8e0841f3fce7b703530ed70c7c36269c6d180ea2e02e36b34cb7288c50c7"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:bf89e0e4a30714b357f5d46b6f20e0099d38b30d45fa68ea48589faf5f12f62d"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:8455aa60da49cb112df62b4721bd8ad3654a3a02b9452c783e651637a1f21fa2"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f53c0d6a859b2db58332e0e6a921582a02c1677cc93d4cbb36fdf49709b327b2"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b3c4817dff8cef5697f5afe5fec6bc1783994d55a68391be24cb7d80d2dbc3a6"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:c9cea5b756173bb86e2235f2f871b406a9b9d722417ae31e5391ccaef5348f2c"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:40e9cdbd18c1f84631312b64993f7d755d85a3930252f6276a77432a2b25a2f3"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-win32.whl", hash = "sha256:cb39ed598aaf102251483f3e4675c5dd6b289c8142210ef76ba24aae0a8f8aba"},
+    {file = "SQLAlchemy-2.0.38-cp311-cp311-win_amd64.whl", hash = "sha256:f9d57f1b3061b3e21476b0ad5f0397b112b94ace21d1f439f2db472e568178ae"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:12d5b06a1f3aeccf295a5843c86835033797fea292c60e72b07bcb5d820e6dd3"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:e036549ad14f2b414c725349cce0772ea34a7ab008e9cd67f9084e4f371d1f32"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ee3bee874cb1fadee2ff2b79fc9fc808aa638670f28b2145074538d4a6a5028e"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e185ea07a99ce8b8edfc788c586c538c4b1351007e614ceb708fd01b095ef33e"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:b79ee64d01d05a5476d5cceb3c27b5535e6bb84ee0f872ba60d9a8cd4d0e6579"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:afd776cf1ebfc7f9aa42a09cf19feadb40a26366802d86c1fba080d8e5e74bdd"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-win32.whl", hash = "sha256:a5645cd45f56895cfe3ca3459aed9ff2d3f9aaa29ff7edf557fa7a23515a3725"},
+    {file = "SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl", hash = "sha256:1052723e6cd95312f6a6eff9a279fd41bbae67633415373fdac3c430eca3425d"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:ecef029b69843b82048c5b347d8e6049356aa24ed644006c9a9d7098c3bd3bfd"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:9c8bcad7fc12f0cc5896d8e10fdf703c45bd487294a986903fe032c72201596b"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2a0ef3f98175d77180ffdc623d38e9f1736e8d86b6ba70bff182a7e68bed7727"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8b0ac78898c50e2574e9f938d2e5caa8fe187d7a5b69b65faa1ea4648925b096"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:9eb4fa13c8c7a2404b6a8e3772c17a55b1ba18bc711e25e4d6c0c9f5f541b02a"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:5dba1cdb8f319084f5b00d41207b2079822aa8d6a4667c0f369fce85e34b0c86"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-win32.whl", hash = "sha256:eae27ad7580529a427cfdd52c87abb2dfb15ce2b7a3e0fc29fbb63e2ed6f8120"},
+    {file = "SQLAlchemy-2.0.38-cp313-cp313-win_amd64.whl", hash = "sha256:b335a7c958bc945e10c522c069cd6e5804f4ff20f9a744dd38e748eb602cbbda"},
+    {file = "SQLAlchemy-2.0.38-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:40310db77a55512a18827488e592965d3dec6a3f1e3d8af3f8243134029daca3"},
+    {file = "SQLAlchemy-2.0.38-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3d3043375dd5bbcb2282894cbb12e6c559654c67b5fffb462fda815a55bf93f7"},
+    {file = "SQLAlchemy-2.0.38-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:70065dfabf023b155a9c2a18f573e47e6ca709b9e8619b2e04c54d5bcf193178"},
+    {file = "SQLAlchemy-2.0.38-cp37-cp37m-musllinux_1_2_aarch64.whl", hash = "sha256:c058b84c3b24812c859300f3b5abf300daa34df20d4d4f42e9652a4d1c48c8a4"},
+    {file = "SQLAlchemy-2.0.38-cp37-cp37m-musllinux_1_2_x86_64.whl", hash = "sha256:0398361acebb42975deb747a824b5188817d32b5c8f8aba767d51ad0cc7bb08d"},
+    {file = "SQLAlchemy-2.0.38-cp37-cp37m-win32.whl", hash = "sha256:a2bc4e49e8329f3283d99840c136ff2cd1a29e49b5624a46a290f04dff48e079"},
+    {file = "SQLAlchemy-2.0.38-cp37-cp37m-win_amd64.whl", hash = "sha256:9cd136184dd5f58892f24001cdce986f5d7e96059d004118d5410671579834a4"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:665255e7aae5f38237b3a6eae49d2358d83a59f39ac21036413fab5d1e810578"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:92f99f2623ff16bd4aaf786ccde759c1f676d39c7bf2855eb0b540e1ac4530c8"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:aa498d1392216fae47eaf10c593e06c34476ced9549657fca713d0d1ba5f7248"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a9afbc3909d0274d6ac8ec891e30210563b2c8bdd52ebbda14146354e7a69373"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:57dd41ba32430cbcc812041d4de8d2ca4651aeefad2626921ae2a23deb8cd6ff"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:3e35d5565b35b66905b79ca4ae85840a8d40d31e0b3e2990f2e7692071b179ca"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-win32.whl", hash = "sha256:f0d3de936b192980209d7b5149e3c98977c3810d401482d05fb6d668d53c1c63"},
+    {file = "SQLAlchemy-2.0.38-cp38-cp38-win_amd64.whl", hash = "sha256:3868acb639c136d98107c9096303d2d8e5da2880f7706f9f8c06a7f961961149"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:07258341402a718f166618470cde0c34e4cec85a39767dce4e24f61ba5e667ea"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:0a826f21848632add58bef4f755a33d45105d25656a0c849f2dc2df1c71f6f50"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:386b7d136919bb66ced64d2228b92d66140de5fefb3c7df6bd79069a269a7b06"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2f2951dc4b4f990a4b394d6b382accb33141d4d3bd3ef4e2b27287135d6bdd68"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:8bf312ed8ac096d674c6aa9131b249093c1b37c35db6a967daa4c84746bc1bc9"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:6db316d6e340f862ec059dc12e395d71f39746a20503b124edc255973977b728"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-win32.whl", hash = "sha256:c09a6ea87658695e527104cf857c70f79f14e9484605e205217aae0ec27b45fc"},
+    {file = "SQLAlchemy-2.0.38-cp39-cp39-win_amd64.whl", hash = "sha256:12f5c9ed53334c3ce719155424dc5407aaa4f6cadeb09c5b627e06abb93933a1"},
+    {file = "SQLAlchemy-2.0.38-py3-none-any.whl", hash = "sha256:63178c675d4c80def39f1febd625a6333f44c0ba269edd8a468b156394b27753"},
+    {file = "sqlalchemy-2.0.38.tar.gz", hash = "sha256:e5a4d82bdb4bf1ac1285a68eab02d253ab73355d9f0fe725a97e1e0fa689decb"},
+]
+
+[package.dependencies]
+greenlet = {version = "!=0.4.17", markers = "python_version < \"3.14\" and (platform_machine == \"aarch64\" or platform_machine == \"ppc64le\" or platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"AMD64\" or platform_machine == \"win32\" or platform_machine == \"WIN32\")"}
+typing-extensions = ">=4.6.0"
+
+[package.extras]
+aiomysql = ["aiomysql (>=0.2.0)", "greenlet (!=0.4.17)"]
+aioodbc = ["aioodbc", "greenlet (!=0.4.17)"]
+aiosqlite = ["aiosqlite", "greenlet (!=0.4.17)", "typing_extensions (!=3.10.0.1)"]
+asyncio = ["greenlet (!=0.4.17)"]
+asyncmy = ["asyncmy (>=0.2.3,!=0.2.4,!=0.2.6)", "greenlet (!=0.4.17)"]
+mariadb-connector = ["mariadb (>=1.0.1,!=1.1.2,!=1.1.5,!=1.1.10)"]
+mssql = ["pyodbc"]
+mssql-pymssql = ["pymssql"]
+mssql-pyodbc = ["pyodbc"]
+mypy = ["mypy (>=0.910)"]
+mysql = ["mysqlclient (>=1.4.0)"]
+mysql-connector = ["mysql-connector-python"]
+oracle = ["cx_oracle (>=8)"]
+oracle-oracledb = ["oracledb (>=1.0.1)"]
+postgresql = ["psycopg2 (>=2.7)"]
+postgresql-asyncpg = ["asyncpg", "greenlet (!=0.4.17)"]
+postgresql-pg8000 = ["pg8000 (>=1.29.1)"]
+postgresql-psycopg = ["psycopg (>=3.0.7)"]
+postgresql-psycopg2binary = ["psycopg2-binary"]
+postgresql-psycopg2cffi = ["psycopg2cffi"]
+postgresql-psycopgbinary = ["psycopg[binary] (>=3.0.7)"]
+pymysql = ["pymysql"]
+sqlcipher = ["sqlcipher3_binary"]
+
 [[package]]
 name = "tabulate"
 version = "0.8.10"
@@ -1318,17 +1683,6 @@ files = [
     {file = "toml-0.10.2.tar.gz", hash = "sha256:b3bda1d108d5dd99f4a20d24d9c348e91c4db7ab1b749200bded2f839ccbe68f"},
 ]
 
-[[package]]
-name = "tomli"
-version = "2.0.2"
-description = "A lil' TOML parser"
-optional = false
-python-versions = ">=3.8"
-files = [
-    {file = "tomli-2.0.2-py3-none-any.whl", hash = "sha256:2ebe24485c53d303f690b0ec092806a085f07af5a5aa1464f3931eec36caaa38"},
-    {file = "tomli-2.0.2.tar.gz", hash = "sha256:d46d457a85337051c36524bc5349dd91b1877838e2979ac5ced3e710ed8a60ed"},
-]
-
 [[package]]
 name = "tomlkit"
 version = "0.13.2"
@@ -1354,7 +1708,6 @@ files = [
 [package.dependencies]
 attrs = ">=23.2.0"
 cffi = {version = ">=1.14", markers = "os_name == \"nt\" and implementation_name != \"pypy\""}
-exceptiongroup = {version = "*", markers = "python_version < \"3.11\""}
 idna = "*"
 outcome = "*"
 sniffio = ">=1.3.0"
@@ -1372,7 +1725,6 @@ files = [
 ]
 
 [package.dependencies]
-exceptiongroup = {version = "*", markers = "python_version < \"3.11\""}
 trio = ">=0.11"
 wsproto = ">=0.14"
 
@@ -1518,5 +1870,5 @@ h11 = ">=0.9.0,<1"
 
 [metadata]
 lock-version = "2.0"
-python-versions = ">=3.9,<3.12"
-content-hash = "6bafb9b450faac0435cb5cd5a0a01441346b9f5e89e2abc4d1ca74e0767e98a6"
+python-versions = ">=3.11,<3.12"
+content-hash = "078185284245670688817b4e65a29321e55ff458526b1752b34637f15a98a216"
diff --git a/pyproject.toml b/pyproject.toml
index 1258d409..0fca5532 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -21,20 +21,24 @@ classifiers = [
 
 [tool.poetry.dependencies]
 colorama = "^0.4.6"
+google-auth = "^2.36.0"
 hjson = "^3.1.0"
 immutabledict = "^4.1.0"
 numpy = "^1.23.5"
 ordered-set = "^4.1.0"
 pandas = "^1.1.3"
-perfetto = "^0.10.0"
+perfetto = "^0.11.0"
 protobuf = "^4.25.3"
 psutil = "^5.9.1"
-python = ">=3.9,<3.12"
+python = ">=3.11,<3.12"
 python-dateutil = "2.7.3"
 pytz = "^2024.1"
+requests = "^2.32.3"
 selenium = "^4.1.0"
 tabulate = "^0.8.10"
 websockets = "^11.0.3"
+pygments = "^2.14.0"
+sqlalchemy = "^2.0.38"
 
 [tool.poetry.scripts]
 crossbench = 'crossbench.scripts:crossbench'
@@ -44,7 +48,7 @@ cb_btp = 'crossbench.scripts:cb_btp'
 [tool.poetry.group.dev.dependencies]
 debugpy = "^1.6.3"
 isort = "^5.10.1"
-pyfakefs = "^5.2.2"
+pyfakefs = "^5.7.3"
 pylint = "^3.0"
 pytest = "^7.4.2"
 pytest-cov = "^4.0.0"
@@ -54,8 +58,8 @@ mypy = "^1.8"
 pytest-profiling = "^1.7.0"
 
 [tool.poetry.group.dev-pytype.dependencies]
-python = ">=3.9,<3.12"
-pytype = { version = "^2024.1.24", markers = "sys_platform != 'win32'" }
+python = ">=3.11,<3.12"
+pytype = { version = "^2024.10.11", markers = "sys_platform != 'win32'" }
 
 [build-system]
 requires = ["poetry_core>=1.1.5"]
diff --git a/tests/crossbench/action_runner/action_runner_test_case.py b/tests/crossbench/action_runner/action_runner_test_case.py
index 04bb9171..d761d951 100644
--- a/tests/crossbench/action_runner/action_runner_test_case.py
+++ b/tests/crossbench/action_runner/action_runner_test_case.py
@@ -2,11 +2,31 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+import datetime as dt
+import logging
+from unittest import mock
+
 from tests.crossbench.base import CrossbenchFakeFsTestCase
 
 
 class ActionRunnerTestCase(CrossbenchFakeFsTestCase):
 
+  def setUp(self) -> None:
+    super().setUp()
+
+    init_time = dt.datetime.now()
+    datetime_patcher = mock.patch("datetime.datetime", spec=dt.datetime)
+    self.datetime_mock = datetime_patcher.start()
+    self.addCleanup(datetime_patcher.stop)
+    self.datetime_mock.now.return_value = init_time
+
+    def sleep_side_effect(seconds):
+      self.datetime_mock.now.return_value += dt.timedelta(seconds)
+      logging.debug("mocked time advanced %fs to %s", seconds,
+                    self.datetime_mock.now.return_value)
+
+    self.sleep_mock.side_effect = sleep_side_effect
+
   def tearDown(self):
     expected_sh_cmds = self.platform.expected_sh_cmds
     if expected_sh_cmds is not None:
diff --git a/tests/crossbench/action_runner/test_screenshot_annotation.py b/tests/crossbench/action_runner/test_screenshot_annotation.py
new file mode 100644
index 00000000..60e5758b
--- /dev/null
+++ b/tests/crossbench/action_runner/test_screenshot_annotation.py
@@ -0,0 +1,54 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import unittest
+import xml.etree.ElementTree as ET
+
+from crossbench.action_runner.display_rectangle import DisplayRectangle
+from crossbench.action_runner.screenshot_annotation import (
+    ScreenshotPointAnnotation, ScreenshotRectAnnotation,
+    annotate_screenshot_svg)
+from crossbench.benchmarks.loading.point import Point
+from tests import test_helper
+
+
+class ScreenshotAnnotationTestCase(unittest.TestCase):
+  SVG_NAMESPACE = {"": "http://www.w3.org/2000/svg"}
+
+  def test_empty(self):
+    svg = ET.fromstring(
+        annotate_screenshot_svg(1366, 768, "screenshot.png", []))
+    self.assertEqual(svg.attrib["width"], "1366")
+    self.assertEqual(svg.attrib["height"], "768")
+    image = svg.find(
+        ".//image[@href='screenshot.png'][@width='1366'][@height='768']",
+        self.SVG_NAMESPACE)
+    self.assertIsNotNone(image)
+
+  def test_point(self):
+    svg = ET.fromstring(
+        annotate_screenshot_svg(
+            1366, 768, "screenshot.png",
+            [ScreenshotPointAnnotation("point", Point(123, 456))]))
+    g = svg.find(".//g[title='point']", self.SVG_NAMESPACE)
+    self.assertIsNotNone(g)
+    rect = g.find("./rect[@x='122.5'][@y='455.5']", self.SVG_NAMESPACE)
+    self.assertIsNotNone(rect)
+
+  def test_rect(self):
+    svg = ET.fromstring(
+        annotate_screenshot_svg(1366, 768, "screenshot.png", [
+            ScreenshotRectAnnotation("rect",
+                                     DisplayRectangle(Point(123, 456), 89, 97))
+        ]))
+    rect = svg.find(
+        ".//rect[title='rect'][@x='123'][@y='456'][@width='89'][@height='97']",
+        self.SVG_NAMESPACE)
+    self.assertIsNotNone(rect)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/base.py b/tests/crossbench/base.py
index 0fb85f43..4776cf42 100644
--- a/tests/crossbench/base.py
+++ b/tests/crossbench/base.py
@@ -10,13 +10,11 @@ import datetime as dt
 import io
 import logging
 import pathlib
-from typing import Final, List, Optional, Sequence, Tuple
+from typing import Final, List, Optional, Sequence, Tuple, Type
 from unittest import mock
 
 from pyfakefs import fake_filesystem_unittest
-from tests import test_helper
-from tests.crossbench import mock_browser
-from tests.crossbench.mock_helper import MockCLI, MockPlatform
+from typing_extensions import override
 
 import crossbench
 from crossbench import path as pth
@@ -25,10 +23,15 @@ from crossbench.benchmarks.loading.loadline_presets import \
     LoadLineTabletBenchmark
 from crossbench.browsers.browser import Browser
 from crossbench.browsers.settings import Settings
-from crossbench.cli.cli import CrossBenchCLI
-from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from crossbench.cli.config.browser_variants import BaseBrowserVariantsConfig
 from crossbench.cli.config.network import NetworkConfig
-from crossbench.cli.config.secrets import SecretsConfig
+from crossbench.cli.config.secrets import Secrets
+from crossbench.cli.subcommand.benchmark import BenchmarkSubcommand
+from crossbench.helper.sleep_preventer import SystemSleepPreventer
+from crossbench.runner.runner import Runner
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.mock_helper import MockCLI, MockPlatform
 
 
 class CrossbenchFakeFsTestCase(
@@ -36,7 +39,7 @@ class CrossbenchFakeFsTestCase(
 
   def setUp(self) -> None:
     super().setUp()
-    self.setUpPyfakefs(modules_to_reload=[crossbench, mock_browser, pth])
+    self.setUpPyfakefs(modules_to_reload=[crossbench, mock_browser, pth, plt])
     # gettext is used extensively in argparse
     gettext_patcher = mock.patch(
         "gettext.dgettext", side_effect=lambda domain, message: message)
@@ -44,40 +47,44 @@ class CrossbenchFakeFsTestCase(
     self.addCleanup(gettext_patcher.stop)
 
     sleep_patcher = mock.patch("time.sleep", return_value=None)
-    sleep_patcher.start()
+    self.sleep_mock = sleep_patcher.start()
     self.addCleanup(sleep_patcher.stop)
+    # This is platform specific and causes issues pending sh commands
+    self.sleep_preventer_patcher = mock.patch.object(SystemSleepPreventer,
+                                                     "__enter__")
+    self.addCleanup(self.sleep_preventer_patcher.stop)
+    self.sleep_preventer_patcher.start()
+
 
-  def create_file(self,
-                  path_str: str,
-                  contents: Optional[str] = None) -> pathlib.Path:
+  def create_file(self, path_str: str, contents: str = "") -> pathlib.Path:
     path = pathlib.Path(path_str)
     self.fs.create_file(path, contents=contents)
     return path
 
 
+TEST_WARNING = "Test Warning"
+
+
 class BaseCrossbenchTestCase(CrossbenchFakeFsTestCase, metaclass=abc.ABCMeta):
 
   def filter_splashscreen_urls(self, urls: Sequence[str]) -> List[str]:
     return [url for url in urls if not url.startswith("data:")]
 
+  @override
   def setUp(self) -> None:
     # Instantiate MockPlatform before setting up fake_filesystem so we can
     # still interact with the original, real plt.Platform object for extracting
     # basic system information.
     self.platform = MockPlatform()  # pytype: disable=not-instantiable
+    self.platform.use_fs = True
     super().setUp()
     self._default_log_level = logging.getLogger().getEffectiveLevel()
     logging.getLogger().setLevel(logging.CRITICAL)
     for mock_browser_cls in mock_browser.ALL:
       mock_browser_cls.setup_fs(self.fs)
-      self.assertTrue(mock_browser_cls.mock_app_path().exists())
+      self.assertTrue(mock_browser_cls.mock_app_path(self.platform).exists())
     self.out_dir = pathlib.Path("/tmp/results/test")
     self.out_dir.parent.mkdir(parents=True)
-    self.fs.add_real_directory(
-        LoadLineTabletBenchmark.default_network_config_path().parent,
-        lazy_read=not test_helper.is_google_env())
-    if test_helper.is_google_env():
-      self.fs.add_real_directory("/build/cas")
     self.browsers: List[mock_browser.MockBrowser] = [
         mock_browser.MockChromeDev(
             "dev", settings=Settings(platform=self.platform)),
@@ -92,14 +99,17 @@ class BaseCrossbenchTestCase(CrossbenchFakeFsTestCase, metaclass=abc.ABCMeta):
     self.mock_args = mock.Mock(
         wraps=False,
         driver_path=None,
+        remote_driver_path=None,
         network_config=None,
         browser_config=None,
         viewport=None,
         splash_screen=None,
-        secrets=SecretsConfig(),
+        secrets=Secrets(),
         wipe_system_user_data=False,
         http_request_timeout=dt.timedelta(),
         cache_dir=pathlib.Path("test_cache_dir"),
+        browser_cache_dir=None,
+        clear_browser_cache_dir=None,
         enable_features=None,
         disable_features=None,
         js_flags=None,
@@ -109,6 +119,20 @@ class BaseCrossbenchTestCase(CrossbenchFakeFsTestCase, metaclass=abc.ABCMeta):
         other_browser_args=[],
         driver_logging=False)
 
+  def setup_loadline_config(self):
+    config_dir = LoadLineTabletBenchmark.default_network_config_path().parent
+    self.fs.add_real_directory(
+        config_dir,
+        lazy_read=not test_helper.is_google_env())
+    if test_helper.is_google_env():
+      # On google3, all files have been replaced by symlinks. The link targets
+      # must be added in order for these symlinks to resolve.
+      for child in config_dir.glob("**/*"):
+        if child.is_symlink():
+          link_target = child.readlink()
+          if not link_target.exists():
+            self.fs.add_real_file(link_target)
+
   def tearDown(self) -> None:
     logging.getLogger().setLevel(self._default_log_level)
     self.assertListEqual(self.platform.sh_results, [])
@@ -126,6 +150,7 @@ class BaseCliTestCase(BaseCrossbenchTestCase):
 
   SPLASH_URLS_LEN: Final[int] = 2
 
+  @override
   def setUp(self) -> None:
     super().setUp()
 
@@ -146,6 +171,8 @@ class BaseCliTestCase(BaseCrossbenchTestCase):
     self.addCleanup(patcher.stop)
     patcher.start()
 
+    self.setup_loadline_config()
+
   def run_cli_output(self,
                      *args,
                      raises=None,
@@ -161,14 +188,53 @@ class BaseCliTestCase(BaseCrossbenchTestCase):
     mock_stderr.close()
     return cli, stdout, stderr
 
+  @contextlib.contextmanager
+  def _patch_get_runner(self):
+    with mock.patch.object(
+        BenchmarkSubcommand, "_get_runner", side_effect=self._mock_get_runner):
+      yield
+
+  def _mock_get_runner(self, args, benchmark, env_config, env_validation_mode,
+                       timing):
+    if not args.out_dir:
+      # Use stable mock out dir
+      args.out_dir = pathlib.Path("/results")
+      assert not args.out_dir.exists()
+    runner_kwargs = Runner.kwargs_from_cli(args)
+    runner = Runner(
+        benchmark=benchmark,
+        env_config=env_config,
+        env_validation_mode=env_validation_mode,
+        timing=timing,
+        **runner_kwargs,
+        # Use custom platform
+        platform=self.platform,
+        in_memory_result_db=True)
+    return runner
+
+  @contextlib.contextmanager
+  def _patch_sys_exit(self):
+    with mock.patch(
+        "sys.exit", side_effect=SysExitTestException), mock.patch.object(
+            plt, "PLATFORM", self.platform):
+      yield
+
+  @contextlib.contextmanager
+  def _patch_get_browser_cls(self,
+                             return_value: Optional[Type[Browser]] = None,
+                             **kwargs):
+    if not kwargs:
+      kwargs["return_value"] = return_value or mock_browser.MockChromeStable
+    with mock.patch.object(BaseBrowserVariantsConfig, "get_browser_cls",
+                           **kwargs) as patcher:
+      yield patcher
+
   def run_cli(self,
               *args,
               raises=None,
               enable_logging: bool = False) -> MockCLI:
     cli = MockCLI(platform=self.platform, enable_logging=enable_logging)
-    with mock.patch(
-        "sys.exit", side_effect=SysExitTestException), mock.patch.object(
-            plt, "PLATFORM", self.platform):
+    with self._patch_sys_exit(), self._patch_get_runner():
       if raises:
         with self.assertRaises(raises):
           cli.run(args)
@@ -176,16 +242,11 @@ class BaseCliTestCase(BaseCrossbenchTestCase):
         cli.run(args)
     return cli
 
-  def mock_chrome_stable(self):
-    return mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
-        return_value=mock_browser.MockChromeStable)
-
   @contextlib.contextmanager
-  def patch_get_browser(self, return_value: Optional[Sequence[Browser]] = None):
+  def _patch_get_browser(self,
+                         return_value: Optional[Sequence[Browser]] = None):
     if not return_value:
       return_value = self.browsers
     with mock.patch.object(
-        CrossBenchCLI, "_get_browsers", return_value=return_value):
+        BenchmarkSubcommand, "_get_browsers", return_value=return_value):
       yield
diff --git a/tests/crossbench/benchmarks/helper.py b/tests/crossbench/benchmarks/helper.py
index 638480e0..9fbc7438 100644
--- a/tests/crossbench/benchmarks/helper.py
+++ b/tests/crossbench/benchmarks/helper.py
@@ -5,6 +5,8 @@
 import abc
 from typing import Sequence, Type
 
+from typing_extensions import override
+
 from crossbench.benchmarks import base as benchmark
 from tests.crossbench.base import BaseCrossbenchTestCase
 
@@ -13,13 +15,14 @@ class BaseBenchmarkTestCase(BaseCrossbenchTestCase, metaclass=abc.ABCMeta):
 
   @property
   @abc.abstractmethod
-  def benchmark_cls(self):
+  def benchmark_cls(self) -> Type[benchmark.Benchmark]:
     pass
 
   @property
   def story_cls(self):
     return self.benchmark_cls.DEFAULT_STORY_CLS
 
+  @override
   def setUp(self):
     super().setUp()
     self.assertTrue(
@@ -29,6 +32,9 @@ class BaseBenchmarkTestCase(BaseCrossbenchTestCase, metaclass=abc.ABCMeta):
   def test_describe(self):
     self.assertIsInstance(self.benchmark_cls.describe(), dict)
 
+  def test_aliases(self):
+    self.assertNotIn(self.benchmark_cls.NAME, self.benchmark_cls.aliases())
+
 
 class SubStoryTestCase(BaseBenchmarkTestCase, metaclass=abc.ABCMeta):
 
diff --git a/tests/crossbench/benchmarks/jetstream_helper.py b/tests/crossbench/benchmarks/jetstream_helper.py
index 579ec26d..d620ec0d 100644
--- a/tests/crossbench/benchmarks/jetstream_helper.py
+++ b/tests/crossbench/benchmarks/jetstream_helper.py
@@ -3,16 +3,21 @@
 # found in the LICENSE file.
 
 import abc
+import argparse
 import copy
 import csv
+import json
+from dataclasses import dataclass
 from typing import Optional, Type
 from unittest import mock
 
+from typing_extensions import override
+
 from crossbench.benchmarks.jetstream.jetstream_2 import (JetStream2Benchmark,
                                                          JetStream2Probe,
+                                                         JetStream2ProbeContext,
                                                          JetStream2Story)
-from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
-                            ValidationMode)
+from crossbench.env import EnvironmentConfig, HostEnvironment, ValidationMode
 from crossbench.runner.runner import Runner
 from tests.crossbench.benchmarks import helper
 
@@ -22,11 +27,13 @@ class JetStream2BaseTestCase(
 
   @property
   @abc.abstractmethod
+  @override
   def benchmark_cls(self) -> Type[JetStream2Benchmark]:
     pass
 
   @property
   @abc.abstractmethod
+  @override
   def story_cls(self) -> Type[JetStream2Story]:
     pass
 
@@ -35,6 +42,11 @@ class JetStream2BaseTestCase(
   def probe_cls(self) -> Type[JetStream2Probe]:
     pass
 
+  @property
+  @abc.abstractmethod
+  def probe_context_cls(self) -> Type[JetStream2ProbeContext]:
+    pass
+
   def test_run_throw(self):
     self._test_run(throw=True)
 
@@ -80,7 +92,7 @@ class JetStream2BaseTestCase(
           browser.expect_js()
           # Wait until done
           browser.expect_js(result=True)
-          browser.expect_js(result=jetstream_probe_results)
+          browser.expect_js(result=json.dumps(jetstream_probe_results))
     for browser in self.browsers:
       browser.expected_js = copy.deepcopy(browser.expected_js)
 
@@ -90,11 +102,12 @@ class JetStream2BaseTestCase(
         self.out_dir,
         self.browsers,
         benchmark,
-        env_config=HostEnvironmentConfig(),
+        env_config=EnvironmentConfig(),
         env_validation_mode=ValidationMode.SKIP,
         platform=self.platform,
         repetitions=repetitions,
-        throw=throw)
+        throw=throw,
+        in_memory_result_db=True)
     with mock.patch.object(
         HostEnvironment, "validate_url", return_value=True) as cm:
       runner.run()
@@ -102,7 +115,7 @@ class JetStream2BaseTestCase(
     for browser in self.browsers:
       urls = self.filter_splashscreen_urls(browser.url_list)
       self.assertEqual(len(urls), repetitions)
-      self.assertTrue(browser.was_js_invoked(self.probe_cls.JS))
+      self.assertTrue(browser.was_js_invoked(self.probe_context_cls.JS))
 
     csv_file = self.out_dir / f"{self.probe_cls.NAME}.csv"
     with csv_file.open(encoding="utf-8") as f:
@@ -134,6 +147,36 @@ class JetStream2BaseTestCase(
     self.assertIn("102.22.33.44", output)
     self.assertIn("100.22.33.44", output)
 
+  @dataclass
+  class Namespace(argparse.Namespace):
+    stories = "default"
+    iterations: int | None = None
+    separate: bool = False
+    custom_benchmark_url: str | None = None
+    detailed_metrics: bool = False
+
+  def test_iterations_kwargs(self):
+    args = self.Namespace()
+    args.stories = "default"
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertIsNone(story.iterations)
+    self.assertDictEqual(story.url_params, {})
+
+    args.iterations = 10
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.iterations, 10)
+    self.assertDictEqual(story.url_params, {"iterationCount": "10"})
+
+    args.iterations = 123
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.iterations, 123)
+    self.assertDictEqual(story.url_params, {"iterationCount": "123"})
 
 # TODO: introduce JetStreamBaseTestCase
 class JetStream3BaseTestCase(JetStream2BaseTestCase, metaclass=abc.ABCMeta):
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_action_runner_config.py b/tests/crossbench/benchmarks/loading/action_runner/test_action_runner_config.py
index ebd3448c..cee47541 100644
--- a/tests/crossbench/benchmarks/loading/action_runner/test_action_runner_config.py
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_action_runner_config.py
@@ -9,10 +9,10 @@ import unittest
 
 from crossbench.action_runner.android_input_action_runner import \
     AndroidInputActionRunner
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
 from crossbench.action_runner.chromeos_input_action_runner import \
     ChromeOSInputActionRunner
 from crossbench.action_runner.config import ActionRunnerConfig
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
 from tests import test_helper
 
 
@@ -26,7 +26,7 @@ class ActionRunnerConfigTest(unittest.TestCase):
 
   def test_parse_basic(self):
     action_runner = ActionRunnerConfig.parse("basic")
-    self.assertIsInstance(action_runner, BasicActionRunner)
+    self.assertIsInstance(action_runner, DefaultActionRunner)
 
   def test_parse_android(self):
     action_runner = ActionRunnerConfig.parse("android")
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_android_input_action_runner.py b/tests/crossbench/benchmarks/loading/action_runner/test_android_input_action_runner.py
index b1acc4cb..368749ab 100644
--- a/tests/crossbench/benchmarks/loading/action_runner/test_android_input_action_runner.py
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_android_input_action_runner.py
@@ -7,8 +7,11 @@ import pathlib
 import unittest
 from typing import Optional, Tuple
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action import Action
 from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.position import PositionConfig
 from crossbench.action_runner.action.scroll import ScrollAction
 from crossbench.action_runner.action.swipe import SwipeAction
 from crossbench.action_runner.action.text_input import TextInputAction
@@ -24,7 +27,8 @@ from crossbench.browsers.settings import Settings
 from crossbench.flags.base import Flags
 from crossbench.runner.groups.session import BrowserSessionRunGroup
 from tests import test_helper
-from tests.crossbench.action_runner.action_runner_test_case import ActionRunnerTestCase
+from tests.crossbench.action_runner.action_runner_test_case import \
+    ActionRunnerTestCase
 from tests.crossbench.mock_browser import JsInvocation, MockChromeAndroidStable
 from tests.crossbench.mock_helper import (AndroidAdbMockPlatform,
                                           LinuxMockPlatform, MockAdb)
@@ -112,6 +116,7 @@ class ViewportInfoTestCase(unittest.TestCase):
 class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
   __test__ = True
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.host_platform = LinuxMockPlatform()
@@ -148,12 +153,8 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
         "dumpsys",
         "window",
         "windows",
-        "|",
-        "grep",
-        "-E",
-        "-A100",
-        "chrome.Main",
-        result=(f"mAppBounds=Rect({app_bounds.left}, "
+        result=(f"chrome.Main\n"
+                f"mAppBounds=Rect({app_bounds.left}, "
                 f"{app_bounds.top} - {app_bounds.right}, {app_bounds.bottom})"))
 
     if not window_inner_height:
@@ -190,30 +191,35 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_text_input_zero_duration(self):
     self.platform.expect_sh("input", "keyboard", "text", "Some%ssample%stext")
-
     text_input_action = TextInputAction(InputSource.KEYBOARD, dt.timedelta(),
                                         "Some sample text")
-
+    self.assertFalse(self.runner.mock_waits)
     self.run_action(text_input_action)
+    self.assertFalse(self.runner.mock_waits)
+
 
   def test_text_input_non_zero_duration(self):
     text_input_action = TextInputAction(InputSource.KEYBOARD,
                                         dt.timedelta(seconds=1), "aaa")
-
     for _ in range(3):
       self.platform.expect_sh("input", "keyboard", "text", "a")
-
+    self.assertFalse(self.runner.mock_waits)
     self.run_action(text_input_action)
+    self.assertTrue(self.runner.mock_waits)
 
   def test_click_touch_coordinates(self):
-    click_action = ClickAction(InputSource.TOUCH, x=100, y=200)
+    click_action = ClickAction(
+        InputSource.TOUCH,
+        position=PositionConfig.from_coordinates(x=100, y=200))
 
     self.platform.expect_sh("input", "tap", "100", "200")
 
     self.run_action(click_action)
 
   def test_click_mouse_coordinates(self):
-    click_action = ClickAction(InputSource.MOUSE, x=100, y=200)
+    click_action = ClickAction(
+        InputSource.MOUSE,
+        position=PositionConfig.from_coordinates(x=100, y=200))
 
     self.platform.expect_sh("input", "mouse", "tap", "100", "200")
 
@@ -221,7 +227,9 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_mouse_non_zero_duration_fails(self):
     click_action = ClickAction(
-        InputSource.MOUSE, duration=dt.timedelta(seconds=1), x=0, y=0)
+        InputSource.MOUSE,
+        duration=dt.timedelta(seconds=1),
+        position=PositionConfig.from_coordinates(x=0, y=0))
 
     with self.assertRaises(InputSourceNotImplementedError) as cm:
       self.run_action(click_action)
@@ -229,7 +237,9 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_touch_non_zero_duration_fails(self):
     click_action = ClickAction(
-        InputSource.TOUCH, duration=dt.timedelta(seconds=1), x=0, y=0)
+        InputSource.TOUCH,
+        duration=dt.timedelta(seconds=1),
+        position=PositionConfig.from_coordinates(x=0, y=0))
 
     with self.assertRaises(InputSourceNotImplementedError) as cm:
       self.run_action(click_action)
@@ -237,18 +247,18 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_selector_passes_selector_string(self):
     click_action = ClickAction(
-        InputSource.TOUCH, selector="div[]", required=False)
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(selector="div[]", required=False))
 
     self.expect_action_setup(found_element=False, js_args=["div[]", False])
 
     self.run_action(click_action)
 
-  def test_click_selector_scroll_into_viwe_passes_scroll_true(self):
+  def test_click_selector_scroll_into_view_passes_scroll_true(self):
     click_action = ClickAction(
         InputSource.TOUCH,
-        selector="div[]",
-        required=False,
-        scroll_into_view=True)
+        position=PositionConfig.from_selector(
+            selector="div[]", required=False, scroll_into_view=True))
 
     self.expect_action_setup(found_element=False, js_args=["div[]", True])
 
@@ -256,7 +266,8 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_selector_non_existant_element_raises(self):
     click_action = ClickAction(
-        InputSource.TOUCH, selector="div[]", required=True)
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(selector="div[]", required=True))
 
     self.expect_action_setup(found_element=False)
 
@@ -266,7 +277,8 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_touch_selector_non_required_element_success(self):
     click_action = ClickAction(
-        InputSource.TOUCH, selector="div[]", required=False)
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(selector="div[]", required=False))
 
     self.expect_action_setup(found_element=False)
 
@@ -274,7 +286,8 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_mouse_selector_non_required_element_success(self):
     click_action = ClickAction(
-        InputSource.MOUSE, selector="div[]", required=False)
+        InputSource.MOUSE,
+        position=PositionConfig.from_selector(selector="div[]", required=False))
 
     self.expect_action_setup(found_element=False)
 
@@ -282,7 +295,8 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_touch_selector_success(self):
     click_action = ClickAction(
-        InputSource.TOUCH, selector="div[]", required=True)
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(selector="div[]", required=True))
 
     self.expect_action_setup(
         found_element=True,
@@ -295,7 +309,8 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_mouse_selector_success(self):
     click_action = ClickAction(
-        InputSource.MOUSE, selector="div[]", required=True)
+        InputSource.MOUSE,
+        position=PositionConfig.from_selector(selector="div[]", required=True))
 
     self.expect_action_setup(
         found_element=True,
@@ -306,6 +321,32 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
 
     self.run_action(click_action)
 
+  def test_click_wait_timeout_required(self):
+    click_action = ClickAction(
+        InputSource.MOUSE,
+        position=PositionConfig.from_selector(
+            selector="#selector", required=True, wait=True),
+        # Set timeout to 0.1 to timeout after 1 call to wait_for_element_impl.
+        timeout=dt.timedelta(seconds=0.1))
+    self.browser.expect_js(JsInvocation(arguments=("#selector",), result=False))
+
+    with self.assertRaises(TimeoutError):
+      self.run_action(click_action)
+
+  def test_click_wait_timeout_unrequired(self):
+    click_action = ClickAction(
+        InputSource.MOUSE,
+        position=PositionConfig.from_selector(
+            selector="#selector", required=False, wait=True),
+        # Set timeout to 0.1 to timeout after 1 call to wait_for_element_impl.
+        timeout=dt.timedelta(seconds=0.1))
+    self.browser.expect_js(JsInvocation(arguments=("#selector",), result=False))
+
+    # We continue to execute the click even after the wait fails.
+    self.expect_action_setup(found_element=False)
+
+    self.run_action(click_action)
+
   def test_scroll_selector_non_required_element_success(self):
     scroll_action = ScrollAction(
         InputSource.TOUCH, distance=100, selector="div[]", required=False)
@@ -333,7 +374,7 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
         window_inner_height=200,
         window_inner_width=200)
 
-    self.platform.expect_sh("input", "swipe", "50", "100", "50", "50", "1000")
+    self.platform.expect_sh("input", "swipe", "50", "90", "50", "40", "1000")
 
     self.run_action(scroll_action)
 
@@ -343,7 +384,7 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
     self.expect_action_setup(
         found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 10, 10))
 
-    self.platform.expect_sh("input", "swipe", "5", "10", "5", "9", "1000")
+    self.platform.expect_sh("input", "swipe", "5", "9", "5", "8", "1000")
 
     self.run_action(scroll_action)
 
@@ -353,17 +394,17 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
     self.expect_action_setup(
         found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 10, 10))
 
-    self.platform.expect_sh("input", "swipe", "5", "0", "5", "1", "1000")
+    self.platform.expect_sh("input", "swipe", "5", "1", "5", "2", "1000")
 
     self.run_action(scroll_action)
 
   def test_scroll_window_scrolls_window_bounds(self):
-    scroll_action = ScrollAction(InputSource.TOUCH, distance=100)
+    scroll_action = ScrollAction(InputSource.TOUCH, distance=80)
 
     self.expect_action_setup(
         found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 100, 100))
 
-    self.platform.expect_sh("input", "swipe", "50", "100", "50", "0", "1000")
+    self.platform.expect_sh("input", "swipe", "50", "90", "50", "10", "1000")
 
     self.run_action(scroll_action)
 
@@ -376,20 +417,20 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
         app_bounds=DisplayRectangle(Point(0, 0), 100, 100),
         element_bounds=DisplayRectangle(Point(10, 10), 80, 80))
 
-    self.platform.expect_sh("input", "swipe", "50", "90", "50", "80", "1000")
+    self.platform.expect_sh("input", "swipe", "50", "82", "50", "72", "1000")
 
     self.run_action(scroll_action)
 
   def test_scroll_touch_duration_single_scroll(self):
     scroll_action = ScrollAction(
         InputSource.TOUCH,
-        distance=100,
+        distance=80,
         duration=dt.timedelta(milliseconds=3000))
 
     self.expect_action_setup(
         found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 100, 100))
 
-    self.platform.expect_sh("input", "swipe", "50", "100", "50", "0", "3000")
+    self.platform.expect_sh("input", "swipe", "50", "90", "50", "10", "3000")
 
     self.run_action(scroll_action)
 
@@ -399,10 +440,10 @@ class AndroidInputActionRunnerTestCase(ActionRunnerTestCase):
     self.expect_action_setup(
         found_element=False, app_bounds=DisplayRectangle(Point(0, 0), 100, 100))
 
-    for _ in range(9):
-      self.platform.expect_sh("input", "swipe", "50", "100", "50", "0", "100")
+    for _ in range(12):
+      self.platform.expect_sh("input", "swipe", "50", "90", "50", "10", "80")
 
-    self.platform.expect_sh("input", "swipe", "50", "100", "50", "1", "99")
+    self.platform.expect_sh("input", "swipe", "50", "90", "50", "51", "39")
 
     self.run_action(scroll_action)
 
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_chromeos_input_action_runner.py b/tests/crossbench/benchmarks/loading/action_runner/test_chromeos_input_action_runner.py
index 96482def..178d14dc 100644
--- a/tests/crossbench/benchmarks/loading/action_runner/test_chromeos_input_action_runner.py
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_chromeos_input_action_runner.py
@@ -9,6 +9,7 @@ from typing import Optional
 
 from crossbench.action_runner.action.action import Action
 from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.position import PositionConfig
 from crossbench.action_runner.action.scroll import ScrollAction
 from crossbench.action_runner.chromeos_input_action_runner import (
     SCRIPTS_DIR, ChromeOSInputActionRunner, ChromeOSTouchEvent,
@@ -25,7 +26,7 @@ from tests import test_helper
 from tests.crossbench.action_runner.action_runner_test_case import ActionRunnerTestCase
 from tests.crossbench.mock_browser import JsInvocation, MockChromeStable
 from tests.crossbench.mock_helper import (ChromeOsSshMockPlatform,
-                                          LinuxMockPlatform)
+                                          LinuxMockPlatform, MockPopen, MockFd)
 from tests.crossbench.runner.helper import MockRun, MockRunner
 
 
@@ -365,10 +366,6 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     path = SCRIPTS_DIR / "query_touch_device.py"
     self.fs.create_file(path, contents="query_touch_device")
 
-    self.platform.expect_sh("env")
-    self.platform.expect_sh("[", "-d", "/tmp", "]")
-    self.platform.expect_sh("mktemp", "/tmp/None.XXXXXXXXXXX")
-
     path = SCRIPTS_DIR / "get_window_positions.js"
     self.fs.create_file(path, contents="get_window_positions")
 
@@ -381,7 +378,14 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     self.browser.expect_js(expected_js=expected_js)
 
     for _ in range(touch_count):
-      self.platform.expect_sh("evemu-play --insert-slot0 /dev/input/event0 < .")
+      self.platform.expect_sh(
+          "mktemp",
+          "/usr/local/tmp/None.XXXXXXXXXXX",
+          result="/usr/local/tmp/None.RANDOM")
+      self.platform.expect_sh("evemu-play --insert-slot0 /dev/input/event0 <"
+                              " /usr/local/tmp/None.RANDOM")
+      self.platform.expect_sh("[", "-e", "/usr/local/tmp/None.RANDOM", "]")
+      self.platform.expect_sh("rm", "/usr/local/tmp/None.RANDOM")
 
   def expect_mouse_click(
       self,
@@ -397,13 +401,29 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     path = SCRIPTS_DIR / "mouse.py"
     self.fs.create_file(path, contents="mouse")
 
+    self.platform.expect_sh(
+        "mktemp",
+        "/usr/local/tmp/None.XXXXXXXXXXX",
+        result="/usr/local/tmp/None.RANDOM")
+    self.platform.expect_sh("python3", "/usr/local/tmp/None.RANDOM", "1920",
+                            "1080")
+    self.platform.expect_sh("[", "-e", "/usr/local/tmp/None.RANDOM", "]")
+    self.platform.expect_sh("rm", "/usr/local/tmp/None.RANDOM")
+
+    mouse_process_stdin: MockFd = MockFd()
+    mouse_process_stdout: MockFd = MockFd()
+
+    mouse_process_stdout.read_returns.append("0\n".encode("utf-8"))
+
     if clicked_coordinates:
-      self.platform.expect_sh("env")
-      self.platform.expect_sh("[", "-d", "/tmp", "]")
-      self.platform.expect_sh("mktemp", "/tmp/None.XXXXXXXXXXX")
-      self.platform.expect_sh("python3", ".", "1920", "1080",
-                              click_duration.total_seconds(),
-                              clicked_coordinates.x, clicked_coordinates.y)
+      mouse_process_stdin.expected_writes.append(
+          f"{click_duration.total_seconds()}\n"
+          f"{clicked_coordinates.x}\n{clicked_coordinates.y}\n".encode("utf-8"))
+      mouse_process_stdout.read_returns.append("0\n".encode("utf-8"))
+
+    mock_mouse_process: MockPopen = MockPopen(mouse_process_stdout,
+                                              mouse_process_stdin)
+    self.platform.popens.append(mock_mouse_process)
 
   def assert_coordinates_touched(
       self,
@@ -426,7 +446,8 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     self.assertEqual(actual_playback, str(expected_event))
 
   def test_click_touch_coordinates(self):
-    click_action = ClickAction(InputSource.TOUCH, x=50, y=50)
+    click_action = ClickAction(
+        InputSource.TOUCH, position=PositionConfig.from_coordinates(x=50, y=50))
 
     self.expect_touch_setup(expected_js=self._NO_ELEMENT_JS_RESULT)
 
@@ -435,7 +456,8 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     self.assert_coordinates_touched(Point(50, 50))
 
   def test_click_mouse_coordinates(self):
-    click_action = ClickAction(InputSource.MOUSE, x=50, y=50)
+    click_action = ClickAction(
+        InputSource.MOUSE, position=PositionConfig.from_coordinates(x=50, y=50))
 
     self.expect_mouse_click(
         expected_js=self._NO_ELEMENT_JS_RESULT,
@@ -447,7 +469,9 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     click_duration = dt.timedelta(seconds=100)
 
     click_action = ClickAction(
-        InputSource.TOUCH, x=50, y=50, duration=click_duration)
+        InputSource.TOUCH,
+        position=PositionConfig.from_coordinates(x=50, y=50),
+        duration=click_duration)
 
     self.expect_touch_setup(expected_js=self._NO_ELEMENT_JS_RESULT)
 
@@ -459,7 +483,9 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     click_duration = dt.timedelta(seconds=100)
 
     click_action = ClickAction(
-        InputSource.MOUSE, x=50, y=50, duration=click_duration)
+        InputSource.MOUSE,
+        position=PositionConfig.from_coordinates(x=50, y=50),
+        duration=click_duration)
 
     self.expect_mouse_click(
         expected_js=self._NO_ELEMENT_JS_RESULT,
@@ -470,7 +496,8 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_touch_selector_non_existent_element_raises(self):
     click_action = ClickAction(
-        InputSource.TOUCH, selector="div[]", required=True)
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(selector="div[]", required=True))
 
     self.expect_touch_setup(
         touch_count=0, expected_js=self._NO_ELEMENT_JS_RESULT)
@@ -480,17 +507,21 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_mouse_selector_non_existent_element_raises(self):
     click_action = ClickAction(
-        InputSource.MOUSE, selector="div[]", required=True)
+        InputSource.MOUSE,
+        position=PositionConfig.from_selector(selector="div[]", required=True))
 
-    self.expect_mouse_click(
-        expected_js=self._NO_ELEMENT_JS_RESULT, clicked_coordinates=None)
+    path = SCRIPTS_DIR / "get_window_positions.js"
+    self.fs.create_file(path, contents="get_window_positions")
+
+    self.browser.expect_js(expected_js=self._NO_ELEMENT_JS_RESULT)
 
     with self.assertRaisesRegex(ElementNotFoundError, "matching DOM"):
       self.run_action(click_action)
 
   def test_click_touch_selector_non_required_element_success(self):
     click_action = ClickAction(
-        InputSource.TOUCH, selector="div[]", required=False)
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(selector="div[]", required=False))
 
     self.expect_touch_setup(
         touch_count=0, expected_js=self._NO_ELEMENT_JS_RESULT)
@@ -499,7 +530,8 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
 
   def test_click_mouse_selector_non_required_element_success(self):
     click_action = ClickAction(
-        InputSource.MOUSE, selector="div[]", required=False)
+        InputSource.MOUSE,
+        position=PositionConfig.from_selector(selector="div[]", required=False))
 
     self.expect_mouse_click(
         expected_js=self._NO_ELEMENT_JS_RESULT, clicked_coordinates=None)
@@ -509,7 +541,8 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
   def test_click_touch_selector_success(self):
 
     click_action = ClickAction(
-        InputSource.TOUCH, selector="div[]", required=True)
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(selector="div[]", required=True))
 
     self.expect_touch_setup(
         expected_js=JsInvocation(result=[
@@ -537,7 +570,8 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
   def test_click_mouse_selector_success(self):
 
     click_action = ClickAction(
-        InputSource.MOUSE, selector="div[]", required=True)
+        InputSource.MOUSE,
+        position=PositionConfig.from_selector(selector="div[]", required=True))
 
     self.expect_mouse_click(
         expected_js=JsInvocation(result=[
@@ -561,6 +595,34 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
 
     self.run_action(click_action)
 
+  def test_click_wait_timeout_required(self):
+    click_action = ClickAction(
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(
+            selector="#selector", required=True, wait=True),
+        # Set timeout to 0.1 to timeout after 1 call to wait_for_element_impl.
+        timeout=dt.timedelta(seconds=0.1))
+
+    self.expect_touch_setup(
+        touch_count=0, expected_js=self._NO_ELEMENT_JS_RESULT)
+
+    with self.assertRaises(TimeoutError):
+      self.run_action(click_action)
+
+  def test_click_wait_timeout_unrequired(self):
+    click_action = ClickAction(
+        InputSource.TOUCH,
+        position=PositionConfig.from_selector(
+            selector="#selector", required=False, wait=True),
+        # Set timeout to 0.1 to timeout after 1 call to wait_for_element_impl.
+        timeout=dt.timedelta(seconds=0.1))
+
+    self.expect_touch_setup(
+        touch_count=0, expected_js=self._NO_ELEMENT_JS_RESULT)
+    self.browser.expect_js(self._NO_ELEMENT_JS_RESULT)
+
+    self.run_action(click_action)
+
   def test_scroll_touch_window_success(self):
 
     scroll_duration: dt.timedelta = dt.timedelta(seconds=2)
@@ -590,14 +652,14 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     self.run_action(scroll_action)
 
     self.assert_coordinates_touched(
-        Point(960, 1080), Point(960, 980), scroll_duration)
+        Point(960, 972), Point(960, 872), scroll_duration)
 
   def test_scroll_touch_window_multi_step_success(self):
 
     scroll_duration: dt.timedelta = dt.timedelta(seconds=2)
 
     scroll_action = ScrollAction(
-        InputSource.TOUCH, distance=2000, duration=scroll_duration)
+        InputSource.TOUCH, distance=1600, duration=scroll_duration)
 
     self.expect_touch_setup(
         expected_js=JsInvocation(result=[
@@ -622,9 +684,11 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     self.run_action(scroll_action)
 
     self.assert_coordinates_touched(
-        Point(960, 1080), Point(960, 0), scroll_duration * (1080 / 2000))
+        Point(960, 972), Point(960, 108),
+        scroll_duration * ((972 - 108) / 1600))
     self.assert_coordinates_touched(
-        Point(960, 1080), Point(960, 160), scroll_duration * (920 / 2000))
+        Point(960, 972), Point(960, 236),
+        scroll_duration * ((972 - 236) / 1600))
 
   def test_scroll_touch_selector_required_not_found_raises(self):
     scroll_action = ScrollAction(
@@ -722,7 +786,7 @@ class ChromeOSInputActionRunnerTestCase(ActionRunnerTestCase):
     self.run_action(scroll_action)
 
     self.assert_coordinates_touched(
-        Point(35, 620), Point(35, 520), scroll_duration)
+        Point(35, 560), Point(35, 460), scroll_duration)
 
 
 if __name__ == "__main__":
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_default_bond_action_runner.py b/tests/crossbench/benchmarks/loading/action_runner/test_default_bond_action_runner.py
new file mode 100644
index 00000000..323adda1
--- /dev/null
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_default_bond_action_runner.py
@@ -0,0 +1,33 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
+from crossbench.action_runner.default_bond_action_runner import (
+    DefaultBondActionRunner)
+from tests import test_helper
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class DefaultBondActionRunnerTestCase(BaseCrossbenchTestCase):
+
+  def test_get_current_conference_code(self):
+    action_runner = DefaultActionRunner()
+    bond_action_runner = DefaultBondActionRunner(action_runner)
+    for browser in self.browsers:
+      browser.set_current_url("https://meet.google.com/abc-def-ghi")
+      code = bond_action_runner.get_current_conference_code(browser=browser)
+      self.assertEqual(code, "abc-def-ghi")
+
+  def test_get_current_conference_code_invalid(self):
+    action_runner = DefaultActionRunner()
+    bond_action_runner = DefaultBondActionRunner(action_runner)
+    for browser in self.browsers:
+      browser.set_current_url("https://www.google.com")
+      with self.assertRaisesRegex(RuntimeError,
+                                  "Unsupported URL for Bond action"):
+        bond_action_runner.get_current_conference_code(browser=browser)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/action_runner/test_display_rectangle.py b/tests/crossbench/benchmarks/loading/action_runner/test_display_rectangle.py
index 06079a9a..892dc358 100644
--- a/tests/crossbench/benchmarks/loading/action_runner/test_display_rectangle.py
+++ b/tests/crossbench/benchmarks/loading/action_runner/test_display_rectangle.py
@@ -6,6 +6,7 @@ import unittest
 
 from crossbench.action_runner.display_rectangle import DisplayRectangle
 from crossbench.benchmarks.loading.point import Point
+from tests import test_helper
 
 
 class DisplayRectangleTestCase(unittest.TestCase):
@@ -51,3 +52,39 @@ class DisplayRectangleTestCase(unittest.TestCase):
     self.assertFalse(DisplayRectangle(Point(5, 6), 0, 1))
     self.assertFalse(DisplayRectangle(Point(3, 4), 1, 0))
     self.assertTrue(DisplayRectangle(Point(1, 2), 1, 1))
+
+  def test_display_rectangle_scrollable_area(self):
+    rect = DisplayRectangle(Point(100, 200), 500, 600)
+
+    (scrollable_top, scrollable_bottom,
+     max_scroll_distance) = rect.get_scrollable_area()
+
+    self.assertEqual(scrollable_top, 260)
+    self.assertEqual(scrollable_bottom, 740)
+    self.assertEqual(max_scroll_distance, 480)
+
+  def test_display_rectangle_intersection_not_contained(self):
+    rect = DisplayRectangle(Point(0, 0), 10, 10)
+
+    with self.assertRaises(AssertionError):
+      rect.intersection(DisplayRectangle(Point(11, 11), 10, 10))
+
+  def test_display_rectangle_intersection_fully_contained(self):
+    big_rect = DisplayRectangle(Point(10, 10), 10, 10)
+
+    small_rect = DisplayRectangle(Point(11, 11), 1, 1)
+
+    self.assertEqual(small_rect, big_rect.intersection(small_rect))
+
+  def test_display_rectangle_intersection_partial(self):
+    big_rect = DisplayRectangle(Point(10, 10), 10, 10)
+
+    small_rect = DisplayRectangle(Point(15, 15), 10, 10)
+
+    self.assertEqual(
+        DisplayRectangle(Point(15, 15), 5, 5),
+        big_rect.intersection(small_rect))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/config/test_blocks.py b/tests/crossbench/benchmarks/loading/config/test_blocks.py
index 31d1e6ab..9f0061e2 100644
--- a/tests/crossbench/benchmarks/loading/config/test_blocks.py
+++ b/tests/crossbench/benchmarks/loading/config/test_blocks.py
@@ -29,6 +29,8 @@ class ActionBlockTestCase(unittest.TestCase):
     self.assertEqual(len(block), 1)
     self.assertTupleEqual(tuple(block), (action,))
     self.assertEqual(block.duration, dt.timedelta(seconds=3))
+    self.assertTrue(hash(block))
+    self.assertSetEqual({block}, {block, block})
 
     block = ActionBlock.parse(block.to_json())
     self.assertTrue(bool(block))
@@ -45,6 +47,8 @@ class ActionBlockTestCase(unittest.TestCase):
     self.assertEqual(len(block), 2)
     self.assertTupleEqual(tuple(block), (action_1, action_2))
     self.assertEqual(block.duration, dt.timedelta(seconds=3))
+    self.assertTrue(hash(block))
+    self.assertSetEqual({block}, {block, block})
 
     block = ActionBlock.parse(block.to_json())
     self.assertTrue(bool(block))
diff --git a/tests/crossbench/benchmarks/loading/config/test_example_configs.py b/tests/crossbench/benchmarks/loading/config/test_example_configs.py
index e3c65e65..562bd21d 100644
--- a/tests/crossbench/benchmarks/loading/config/test_example_configs.py
+++ b/tests/crossbench/benchmarks/loading/config/test_example_configs.py
@@ -4,10 +4,11 @@
 
 from __future__ import annotations
 
+import datetime as dt
 import hjson
 
 from crossbench.benchmarks.loading.config.pages import PagesConfig
-from crossbench.helper import ChangeCWD
+from crossbench.helper.cwd import ChangeCWD
 from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
 
@@ -37,6 +38,32 @@ class TestExamplePageConfig(CrossbenchFakeFsTestCase):
       self.assertEqual(len(page.blocks), 1)
       self.assertGreater(len(page.blocks[0].actions), 1)
 
+  def test_parse_example_templated_config_file(self):
+    example_config_file = (
+        test_helper.config_dir() / "doc/templated.config.hjson")
+    self.fs.add_real_file(example_config_file)
+
+    file_config = PagesConfig.parse(example_config_file)
+    self.assertEqual(len(file_config.pages), 1)
+
+    page = file_config.pages[0]
+    self.assertEqual(len(page.blocks), 1)
+
+    block = page.blocks[0]
+    self.assertEqual(len(block.actions), 3)
+
+    get_action = block.actions[0]
+    self.assertEqual(get_action.url, "https://www.google.com")
+
+    cookie_banner_action = block.actions[1]
+    self.assertIsNotNone(cookie_banner_action.position.selector)
+    self.assertEqual(cookie_banner_action.position.selector.selector,
+                     "xpath///button/div[contains(text(),'akzeptieren')]")
+
+    scroll_action = block.actions[2]
+    self.assertEqual(scroll_action.distance, 500)
+    self.assertEqual(scroll_action.duration, dt.timedelta(seconds=10))
+
   def test_parse_android_page_config_file(self):
     example_config_file = (
         test_helper.config_dir() / "team/woa/android_input_page_config.hjson")
diff --git a/tests/crossbench/benchmarks/loading/config/test_login.py b/tests/crossbench/benchmarks/loading/config/test_login.py
index 6ab145ca..3e05fa02 100644
--- a/tests/crossbench/benchmarks/loading/config/test_login.py
+++ b/tests/crossbench/benchmarks/loading/config/test_login.py
@@ -5,16 +5,17 @@
 import pathlib
 from unittest import mock
 
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
 from crossbench.benchmarks.loading.config.pages import PagesConfig
 from crossbench.benchmarks.loading.loading_benchmark import LoadingPageFilter
 from crossbench.browsers.settings import Settings
-from crossbench.cli.config.secrets import Secret
-from crossbench.cli.config.secret_type import SecretType
+from crossbench.cli.config.secrets import (GoogleUsernamePassword,
+                                           UsernamePassword)
 from crossbench.flags.base import Flags
 from crossbench.runner.groups.session import BrowserSessionRunGroup
 from tests import test_helper
-from tests.crossbench.action_runner.action_runner_test_case import ActionRunnerTestCase
+from tests.crossbench.action_runner.action_runner_test_case import \
+    ActionRunnerTestCase
 from tests.crossbench.mock_browser import MockChromeStable
 from tests.crossbench.mock_helper import (ChromeOsSshMockPlatform,
                                           LinuxMockPlatform)
@@ -62,7 +63,7 @@ class ChromeOSLoginTestCase(ActionRunnerTestCase):
                                           Flags(), 1, self.root_dir, True, True)
     self.run = MockRun(self.runner, self.session, "run 1")
 
-    self.action_runner = BasicActionRunner()
+    self.action_runner = DefaultActionRunner()
     self.mock_args = mock.Mock()
 
   def expect_google_login(self):
@@ -80,25 +81,27 @@ class ChromeOSLoginTestCase(ActionRunnerTestCase):
 
     self.expect_google_login()
 
+    self.run.story_secrets = page[0].secrets
     config.pages[0].login.run_with(self.action_runner, self.run, page[0])
 
   def test_logged_in_google_account(self):
     config = PagesConfig.parse(self._CONFIG_DATA)
     page = LoadingPageFilter.stories_from_config(self.mock_args, config)
 
-    self.browser.expect_is_logged_in(
-        Secret(SecretType.GOOGLE, "test", "s3cr3t"))
+    self.browser.expect_is_logged_in(GoogleUsernamePassword("test", "s3cr3t"))
 
+    self.run.story_secrets = page[0].secrets
     config.pages[0].login.run_with(self.action_runner, self.run, page[0])
 
   def test_logged_in_non_google_account(self):
     config = PagesConfig.parse(self._CONFIG_DATA)
     page = LoadingPageFilter.stories_from_config(self.mock_args, config)
 
-    self.browser.expect_is_logged_in(Secret(None, "test", "s3cr3t"))
+    self.browser.expect_is_logged_in(UsernamePassword("test", "s3cr3t"))
 
     self.expect_google_login()
 
+    self.run.story_secrets = page[0].secrets
     config.pages[0].login.run_with(self.action_runner, self.run, page[0])
 
 
diff --git a/tests/crossbench/benchmarks/loading/config/test_page.py b/tests/crossbench/benchmarks/loading/config/test_page.py
index 68e519c5..03190e58 100644
--- a/tests/crossbench/benchmarks/loading/config/test_page.py
+++ b/tests/crossbench/benchmarks/loading/config/test_page.py
@@ -10,6 +10,7 @@ import unittest
 
 from crossbench.benchmarks.loading.config.login.google import GoogleLogin
 from crossbench.benchmarks.loading.config.page import PageConfig
+from crossbench.action_runner.action.get import GetAction
 from tests import test_helper
 
 
@@ -107,6 +108,8 @@ class PageConfigTestsCase(unittest.TestCase):
     self.assertEqual(config_1.first_url, "http://test.com/0")
     self.assertEqual(len(config_1.blocks), 1)
     self.assertEqual(len(tuple(config_1.actions())), 2)
+    self.assertIsInstance(config_1.blocks[0].actions[0], GetAction)
+    self.assertIsInstance(config_1.blocks[0].actions[1], GetAction)
     self.assertEqual(config_1.blocks[0].actions[0].url, "http://test.com/0")
     self.assertEqual(config_1.blocks[0].actions[1].url,
                      "http://test.com/0,123s")
@@ -132,11 +135,6 @@ class PageConfigTestsCase(unittest.TestCase):
     self.assertEqual(config.first_url, "https://cnn")
     self.assertEqual(len(config.blocks), 1)
 
-  def test_parse_actions_no_get(self):
-    with self.assertRaises(argparse.ArgumentTypeError) as cm:
-      PageConfig.parse([{"action": "click", "selector": "#foo"}])
-    self.assertIn("get", str(cm.exception))
-
   def test_parse_action_sequence(self):
     config = PageConfig.parse([{
         "action": "get",
diff --git a/tests/crossbench/benchmarks/loading/config/test_pages.py b/tests/crossbench/benchmarks/loading/config/test_pages.py
index ebdffcd9..39bad52c 100644
--- a/tests/crossbench/benchmarks/loading/config/test_pages.py
+++ b/tests/crossbench/benchmarks/loading/config/test_pages.py
@@ -19,8 +19,7 @@ from crossbench.benchmarks.loading.config.login.google import GoogleLogin
 from crossbench.benchmarks.loading.config.page import PageConfig
 from crossbench.benchmarks.loading.config.pages import (
     DevToolsRecorderPagesConfig, ListPagesConfig, PagesConfig)
-from crossbench.cli.config.secret_type import SecretType
-from crossbench.cli.config.secrets import Secret, SecretsConfig
+from crossbench.cli.config.secrets import GoogleUsernamePassword, Secrets
 from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
 
@@ -138,19 +137,6 @@ class PagesConfigTestCase(CrossbenchFakeFsTestCase):
       PagesConfig.parse(config_data)
     self.assertIn("empty", str(cm.exception).lower())
 
-  def test_parse_empty_missing_get_action(self):
-    config_data = {
-        "pages": {
-            "Google Story": [{
-                "action": "wait",
-                "duration": 5
-            }]
-        }
-    }
-    with self.assertRaises(argparse.ArgumentTypeError) as cm:
-      PagesConfig.parse(config_data)
-    self.assertIn("get", str(cm.exception).lower())
-
   def test_example(self):
     config_data = {
         "pages": {
@@ -179,9 +165,13 @@ class PagesConfigTestCase(CrossbenchFakeFsTestCase):
     assert not file.exists()
     with file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
-    pages = PagesConfig.parse(str(file)).pages
+    file_config = PagesConfig.parse(str(file))
+    self.assertEqual(config, file_config)
+    pages = file_config.pages
     self.assert_single_google_story(pages)
-    self.assertIsNone(config.pages[0].login)
+    self.assertIsNone(pages[0].login)
+
+    self.assertEqual(config, PagesConfig.parse(json.dumps(config_data)))
 
   def test_example_with_login(self):
     config_data = {
@@ -232,7 +222,6 @@ class PagesConfigTestCase(CrossbenchFakeFsTestCase):
                     },
                     {
                         "action": "scroll",
-                        "direction": "down",
                         "duration": 3
                     },
                 ]
@@ -268,8 +257,8 @@ class PagesConfigTestCase(CrossbenchFakeFsTestCase):
         }
     }
     pages = PagesConfig.parse(config_data)
-    secret = Secret(SecretType.GOOGLE, "test", "s3cr3t")
-    self.assertEqual(pages.secrets, SecretsConfig({secret.type: secret}))
+    secret = GoogleUsernamePassword("test", "s3cr3t")
+    self.assertEqual(pages.secrets, Secrets(google=secret))
     self.assertEqual(pages.pages[0].first_url, "http://google.com")
 
   def test_no_scenarios(self):
@@ -313,16 +302,6 @@ class PagesConfigTestCase(CrossbenchFakeFsTestCase):
         with self.assertRaises(argparse.ArgumentTypeError):
           PagesConfig.parse_dict(config_dict)
 
-  def test_missing_get_action_scenario(self):
-    with self.assertRaises(argparse.ArgumentTypeError):
-      PagesConfig.parse_dict(
-          {"pages": {
-              "TEST": [{
-                  "action": "wait",
-                  "duration": 5.0
-              }]
-          }})
-
   def test_get_action_durations(self):
     durations = [
         ("5", 5),
@@ -485,7 +464,9 @@ class DevToolsRecorderPageConfigTestCase(CrossbenchFakeFsTestCase):
     action = actions[0]
     self.assertEqual(action.TYPE, ActionType.CLICK)
     assert isinstance(action, ClickAction)
-    self.assertEqual(action.selector, "[aria-label='Search Google']")
+    self.assertIsNotNone(action.position.selector)
+    self.assertEqual(action.position.selector.selector,
+                     "[aria-label='Search Google']")
 
     config["selectors"] = [["aria/SIMPLE"], ["#rso > div:nth-of-type(3) h3"],
                            ["xpath///*[@id=\"rso\"]"],
@@ -493,7 +474,9 @@ class DevToolsRecorderPageConfigTestCase(CrossbenchFakeFsTestCase):
                            ["text/SIMPLE"]]
     action = DevToolsRecorderPagesConfig.parse_step(config)[0]
     assert isinstance(action, ClickAction)
-    self.assertEqual(action.selector, "xpath///*[@id=\"rso\"]")
+    self.assertIsNotNone(action.position.selector)
+    self.assertEqual(action.position.selector.selector,
+                     "xpath///*[@id=\"rso\"]")
 
     config["selectors"] = [
         ["aria/SIMPLE"],
@@ -501,14 +484,18 @@ class DevToolsRecorderPageConfigTestCase(CrossbenchFakeFsTestCase):
     ]
     action = DevToolsRecorderPagesConfig.parse_step(config)[0]
     assert isinstance(action, ClickAction)
-    self.assertEqual(action.selector, "#rso > div:nth-of-type(3) h3")
+    self.assertIsNotNone(action.position.selector)
+    self.assertEqual(action.position.selector.selector,
+                     "#rso > div:nth-of-type(3) h3")
 
     config["selectors"] = [
         ["#rso > div:nth-of-type(3) h3"],
     ]
     action = DevToolsRecorderPagesConfig.parse_step(config)[0]
     assert isinstance(action, ClickAction)
-    self.assertEqual(action.selector, "#rso > div:nth-of-type(3) h3")
+    self.assertIsNotNone(action.position.selector)
+    self.assertEqual(action.position.selector.selector,
+                     "#rso > div:nth-of-type(3) h3")
 
     config["selectors"] = [
         ["aria/SIMPLE", "area/OTHER"],
@@ -516,14 +503,18 @@ class DevToolsRecorderPageConfigTestCase(CrossbenchFakeFsTestCase):
     ]
     action = DevToolsRecorderPagesConfig.parse_step(config)[0]
     assert isinstance(action, ClickAction)
-    self.assertEqual(action.selector, "#rso > div:nth-of-type(3) h3")
+    self.assertIsNotNone(action.position.selector)
+    self.assertEqual(action.position.selector.selector,
+                     "#rso > div:nth-of-type(3) h3")
 
     config["selectors"] = [
         ["text/Content"],
     ]
     action = DevToolsRecorderPagesConfig.parse_step(config)[0]
     assert isinstance(action, ClickAction)
-    self.assertEqual(action.selector, "xpath///*[text()='Content']")
+    self.assertIsNotNone(action.position.selector)
+    self.assertEqual(action.position.selector.selector,
+                     "xpath///*[text()='Content']")
 
 
 class ListPageConfigTestCase(CrossbenchFakeFsTestCase):
@@ -553,6 +544,8 @@ class ListPageConfigTestCase(CrossbenchFakeFsTestCase):
     config_dict = ListPagesConfig.parse({"pages": "http://foo.bar.com,23s"})
     config_str = PagesConfig(
         pages=(PageConfig.parse("http://foo.bar.com,23s"),))
+    self.assertIsInstance(config_dict, ListPagesConfig)
+    self.assertIsInstance(config_str, PagesConfig)
     self.assertEqual(config_dict, config_str)
 
   @unittest.skip("Combined pages per line not supported yet")
diff --git a/tests/crossbench/benchmarks/loading/test_action.py b/tests/crossbench/benchmarks/loading/test_action.py
index cf4beb3c..f6e38c3d 100644
--- a/tests/crossbench/benchmarks/loading/test_action.py
+++ b/tests/crossbench/benchmarks/loading/test_action.py
@@ -5,15 +5,21 @@
 from __future__ import annotations
 
 import datetime as dt
+import unittest
 
-from crossbench.action_runner.action.action import ACTION_TIMEOUT
+from crossbench.action_runner.action.action import (ACTION_TIMEOUT, ACTIONS,
+                                                    Action)
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.action.click import ClickAction
+from crossbench.action_runner.action.close_tab import CloseTabAction
 from crossbench.action_runner.action.enums import ReadyState, WindowTarget
 from crossbench.action_runner.action.get import GetAction
 from crossbench.action_runner.action.inject_new_document_script import \
     InjectNewDocumentScriptAction
 from crossbench.action_runner.action.js import JsAction
+from crossbench.action_runner.action.position import (CoordinatesConfig,
+                                                      PositionConfig,
+                                                      SelectorConfig)
 from crossbench.action_runner.action.scroll import ScrollAction
 from crossbench.action_runner.action.swipe import SwipeAction
 from crossbench.action_runner.action.switch_tab import SwitchTabAction
@@ -30,6 +36,21 @@ from tests.crossbench.base import CrossbenchFakeFsTestCase
 
 class ActionTestCase(CrossbenchFakeFsTestCase):
 
+  def test_action_type_lookup(self):
+    for action_type in ActionType:
+      action_cls = ACTIONS[action_type]
+      self.assertTrue(issubclass(action_cls, Action))
+      # Ensure that all Action subclasses have cached config_parser for
+      # efficiently parsing larger page configs with many actions:
+      # - Use  @functools.cache for base classes
+      # - Use  @functools.lru_cache(maxsize=1) for leaf classes
+      self.assertIs(action_cls.config_parser().cls, action_cls)
+      self.assertIs(
+          action_cls.config_parser(), action_cls.config_parser(),
+          f"{action_cls}: missing "
+          "@functools.lru_cache decorator on config_parser() method")
+      self.assertIs(action_cls.TYPE, action_type)
+
   def test_parse_get_default(self):
     config_dict = {"action": "get", "url": "http://crossben.ch"}
     action = GetAction.parse_dict(config_dict)
@@ -229,11 +250,12 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
     self.assertEqual(action.TYPE, ActionType.CLICK)
     self.assertEqual(action.timeout, ACTION_TIMEOUT)
     self.assertEqual(action.input_source, InputSource.JS)
-    self.assertEqual(action.selector, "#button")
-    self.assertFalse(action.required)
-    self.assertFalse(action.scroll_into_view)
-    self.assertIsNone(action.coordinates)
+    self.assertEqual(action.position.selector.selector, "#button")
+    self.assertTrue(action.position.selector.required)
+    self.assertFalse(action.position.selector.scroll_into_view)
+    self.assertIsNone(action.position.coordinates)
     self.assertTrue(action.has_timeout)
+    self.assertIsNone(action.verify)
     action.validate()
 
     action_2 = ClickAction.parse_dict(action.to_json())
@@ -241,18 +263,24 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
     action_2.validate()
 
   def test_parse_click_minimal_coordinates(self):
-    config_dict = {"action": "click", "source": "touch", "x": 1, "y": 2}
+    config_dict = {
+        "action": "click",
+        "source": "touch",
+        "position": {
+            "x": 1,
+            "y": 2
+        }
+    }
     action = ClickAction.parse_dict(config_dict)
 
     self.assertEqual(action.TYPE, ActionType.CLICK)
     self.assertEqual(action.timeout, ACTION_TIMEOUT)
     self.assertEqual(action.input_source, InputSource.TOUCH)
-    self.assertIsNone(action.selector)
-    self.assertFalse(action.required)
-    self.assertFalse(action.scroll_into_view)
-    self.assertEqual(action.coordinates.x, 1)
-    self.assertEqual(action.coordinates.y, 2)
+    self.assertIsNone(action.position.selector)
+    self.assertEqual(action.position.coordinates.x, 1)
+    self.assertEqual(action.position.coordinates.y, 2)
     self.assertTrue(action.has_timeout)
+    self.assertIsNone(action.verify)
     action.validate()
 
     action_2 = ClickAction.parse_dict(action.to_json())
@@ -263,9 +291,13 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
     config_dict = {
         "action": "click",
         "source": "js",
-        "selector": "#button",
-        "required": True,
-        "scroll_into_view": True,
+        "position": {
+            "selector": "#button",
+            "required": True,
+            "scroll_into_view": True,
+            "wait": True,
+        },
+        "verify": "#id",
         "timeout": "12s"
     }
     action = ClickAction.parse_dict(config_dict)
@@ -273,10 +305,12 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
     self.assertEqual(action.TYPE, ActionType.CLICK)
     self.assertEqual(action.timeout, dt.timedelta(seconds=12))
     self.assertEqual(action.input_source, InputSource.JS)
-    self.assertEqual(action.selector, "#button")
-    self.assertTrue(action.required)
-    self.assertTrue(action.scroll_into_view)
+    self.assertEqual(action.position.selector.selector, "#button")
+    self.assertTrue(action.position.selector.required)
+    self.assertTrue(action.position.selector.scroll_into_view)
+    self.assertTrue(action.position.selector.wait)
     self.assertTrue(action.has_timeout)
+    self.assertEqual(action.verify, "#id")
     action.validate()
 
     action_2 = ClickAction.parse_dict(action.to_json())
@@ -304,60 +338,61 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
   def test_parse_click_invalid_selector(self):
     with self.assertRaises(ValueError) as cm:
       ClickAction.parse_dict({"action": "click", "selector": ""})
-    self.assertIn("selector", str(cm.exception))
-
-  def test_parse_click_selector_and_coordinates(self):
-    with self.assertRaises(ValueError) as cm:
-      ClickAction.parse_dict({
-          "action": "click",
-          "source": "TOUCH",
-          "selector": "#button",
-          "x": 0,
-          "y": 0
-      })
-    self.assertIn("either selector or coordinates", str(cm.exception))
+    self.assertIn("Empty config value", str(cm.exception))
 
-  def test_parse_click_incomplete_coordinates(self):
     with self.assertRaises(ValueError) as cm:
-      ClickAction.parse_dict({"action": "click", "source": "TOUCH", "x": 0})
-    self.assertIn("Either selector or coordinates", str(cm.exception))
+      ClickAction.parse_dict({"action": "click", "position": {"selector": ""}})
+    self.assertIn("Non-empty string value expected", str(cm.exception))
 
-  def test_parse_click_coordinates_with_required(self):
+  def test_parse_click_selector_and_coordinates(self):
     with self.assertRaises(ValueError) as cm:
       ClickAction.parse_dict({
           "action": "click",
           "source": "TOUCH",
-          "x": 0,
-          "y": 0,
-          "required": "true"
+          "position": {
+              "selector": "#button",
+              "x": 0,
+              "y": 0
+          },
       })
-    self.assertIn("required", str(cm.exception))
+    self.assertIn("contains unused properties", str(cm.exception))
 
-  def test_parse_click_coordinates_with_scroll(self):
+  def test_parse_click_incomplete_coordinates(self):
     with self.assertRaises(ValueError) as cm:
       ClickAction.parse_dict({
           "action": "click",
           "source": "TOUCH",
-          "x": 0,
-          "y": 0,
-          "scroll_into_view": "true"
+          "position": {
+              "x": 0
+          }
       })
-    self.assertIn("scroll_into_view", str(cm.exception))
+    self.assertIn("is not a valid coordinate or selector", str(cm.exception))
 
   def test_parse_click_coordinates_with_js(self):
     with self.assertRaises(ValueError) as cm:
       ClickAction.parse_dict({
           "action": "click",
           "source": "JS",
-          "x": 0,
-          "y": 0
+          "position": {
+              "x": 0,
+              "y": 0,
+          },
       })
     self.assertIn("JS", str(cm.exception))
 
-  def test_parse_click_missing_coordinates_and_selector(self):
+  def test_parse_click_missing_position(self):
     with self.assertRaises(ValueError) as cm:
       ClickAction.parse_dict({"action": "click", "source": "TOUCH"})
-    self.assertIn("Either selector or coordinates", str(cm.exception))
+    self.assertIn("required config option 'position'", str(cm.exception))
+
+  def test_parse_click_missing_coordinates_and_selector(self):
+    with self.assertRaises(ValueError) as cm:
+      ClickAction.parse_dict({
+          "action": "click",
+          "source": "TOUCH",
+          "position": {}
+      })
+    self.assertIn("coordinate or selector", str(cm.exception))
 
   def test_parse_swipe(self):
     config_dict = {
@@ -486,6 +521,43 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
     self.assertEqual(action, action_2)
     action_2.validate()
 
+  def test_parse_wait_for_element_expected_count(self):
+    config_dict = {
+        "action": "wait_for_element",
+        "selector": "#button",
+        "expected_count": "5"
+    }
+    action = WaitForElementAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.WAIT_FOR_ELEMENT)
+    self.assertEqual(action.selector, "#button")
+    self.assertEqual(action.expected_count, 5)
+    self.assertFalse(action.or_more)
+    action.validate()
+
+    action_2 = WaitForElementAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_wait_for_element_expected_count_or_more(self):
+    config_dict = {
+        "action": "wait_for_element",
+        "selector": "#button",
+        "expected_count": "15",
+        "or_more": True
+    }
+    action = WaitForElementAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.WAIT_FOR_ELEMENT)
+    self.assertEqual(action.selector, "#button")
+    self.assertEqual(action.expected_count, 15)
+    self.assertTrue(action.or_more)
+    action.validate()
+
+    action_2 = WaitForElementAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
   def test_js_script(self):
     config_dict = {
         "action": "js",
@@ -727,15 +799,41 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
     config_dict = {
         "action": "switch_tab",
     }
-    action = SwitchTabAction.parse_dict(config_dict)
+    with self.assertRaisesRegex(ValueError, "tab_index, title, or url"):
+      SwitchTabAction.parse_dict(config_dict)
 
-    self.assertEqual(action.TYPE, ActionType.SWITCH_TAB)
-    self.assertEqual(action.tab_index, None)
-    self.assertEqual(action.title, None)
-    self.assertEqual(action.url, None)
+  def test_parse_close_tab_all_args(self):
+    config_dict = {
+        "action": "close_tab",
+        "tab_index": 17,
+        "title": "^Example.*",
+        "url": "http(s)?://example.com"
+    }
+    action = CloseTabAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.CLOSE_TAB)
+    self.assertEqual(action.tab_index, 17)
+    self.assertEqual(action.title.pattern, "^Example.*")
+    self.assertEqual(action.url.pattern, "http(s)?://example.com")
     action.validate()
 
-    action_2 = SwitchTabAction.parse_dict(action.to_json())
+    action_2 = CloseTabAction.parse_dict(action.to_json())
+    self.assertEqual(action, action_2)
+    action_2.validate()
+
+  def test_parse_close_tab_no_args(self):
+    config_dict = {
+        "action": "close_tab",
+    }
+    action = CloseTabAction.parse_dict(config_dict)
+
+    self.assertEqual(action.TYPE, ActionType.CLOSE_TAB)
+    self.assertFalse(action.tab_index)
+    self.assertFalse(action.title)
+    self.assertFalse(action.url)
+    action.validate()
+
+    action_2 = CloseTabAction.parse_dict(action.to_json())
     self.assertEqual(action, action_2)
     action_2.validate()
 
@@ -768,5 +866,42 @@ class ActionTestCase(CrossbenchFakeFsTestCase):
     self.assertEqual(action, action_2)
     action_2.validate()
 
+
+class PositionConfigTestCasse(unittest.TestCase):
+
+  def test_parse_position_from_coordinates(self):
+    position = PositionConfig.from_coordinates(123, 456)
+    self.assertIsNone(position.selector)
+    self.assertIsNotNone(position.coordinates)
+    self.assertEqual(123, position.coordinates.x)
+    self.assertEqual(456, position.coordinates.y)
+
+  def test_parse_position_from_selector_defaults(self):
+    position = PositionConfig.from_selector("#id")
+    self.assertIsNone(position.coordinates)
+    self.assertIsNotNone(position.selector)
+    self.assertEqual("#id", position.selector.selector)
+    self.assertTrue(position.selector.required)
+    self.assertFalse(position.selector.scroll_into_view)
+    self.assertFalse(position.selector.wait)
+
+  def test_parse_position_from_selector_all(self):
+    position = PositionConfig.from_selector(
+        selector="#id", required=False, scroll_into_view=True, wait=True)
+    self.assertIsNone(position.coordinates)
+    self.assertIsNotNone(position.selector)
+    self.assertEqual("#id", position.selector.selector)
+    self.assertFalse(position.selector.required)
+    self.assertTrue(position.selector.scroll_into_view)
+    self.assertTrue(position.selector.wait)
+
+  def test_selector_and_coordinates_raises(self):
+    with self.assertRaisesRegex(ValueError, "exactly one"):
+      PositionConfig(
+          coordinates=CoordinatesConfig(x=123, y=456),
+          selector=SelectorConfig(
+              "#id", required=True, scroll_into_view=False, wait=False))
+
+
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/test_loading.py b/tests/crossbench/benchmarks/loading/test_loading.py
index 117ddf55..008c8047 100644
--- a/tests/crossbench/benchmarks/loading/test_loading.py
+++ b/tests/crossbench/benchmarks/loading/test_loading.py
@@ -12,16 +12,18 @@ import json
 import pathlib
 import re
 import unittest
-from typing import List, Sequence, cast
+from typing import List, Sequence
 from unittest import mock
 
+from typing_extensions import override
+
 from crossbench.action_runner.action.action_type import ActionType
 from crossbench.action_runner.base import ActionRunner
-from crossbench.action_runner.basic_action_runner import BasicActionRunner
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
 from crossbench.benchmarks.loading.config.blocks import ActionBlockListConfig
 from crossbench.benchmarks.loading.config.login.google import GOOGLE_LOGIN_URL
-from crossbench.benchmarks.loading.loading_benchmark import (LoadingPageFilter,
-                                                             PageLoadBenchmark)
+from crossbench.benchmarks.loading.loading_benchmark import (LoadingBenchmark,
+                                                             LoadingPageFilter)
 from crossbench.benchmarks.loading.page.combined import CombinedPage
 from crossbench.benchmarks.loading.page.interactive import InteractivePage
 from crossbench.benchmarks.loading.page.live import (PAGE_LIST, PAGE_LIST_SMALL,
@@ -30,28 +32,30 @@ from crossbench.benchmarks.loading.playback_controller import \
     PlaybackController
 from crossbench.benchmarks.loading.tab_controller import TabController
 from crossbench.browsers.settings import Settings
-from crossbench.cli.config.secrets import SecretsConfig
-from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.cli.config.secrets import Secrets
+from crossbench.env import EnvironmentConfig, ValidationMode
 from crossbench.runner.runner import Runner
 from tests import test_helper
 from tests.crossbench.base import BaseCliTestCase
-from tests.crossbench.benchmarks import helper
+from tests.crossbench.benchmarks.helper import SubStoryTestCase
 from tests.crossbench.mock_browser import JsInvocation
 
 
-class TestPageLoadBenchmark(helper.SubStoryTestCase):
+class TestPageLoadBenchmark(SubStoryTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
-    return PageLoadBenchmark
+    return LoadingBenchmark
 
+  @override
   def story_filter(  # pylint: disable=arguments-differ
       self,
       patterns: Sequence[str],
       separate: bool = True,
       playback: PlaybackController = PlaybackController.default(),
       tabs: TabController = TabController.default(),
-      action_runner: ActionRunner = BasicActionRunner(),
+      action_runner: ActionRunner = DefaultActionRunner(),
       about_blank_duration: dt.timedelta = dt.timedelta(),
       run_login: bool = True,
       run_setup: bool = True) -> LoadingPageFilter:
@@ -62,8 +66,9 @@ class TestPageLoadBenchmark(helper.SubStoryTestCase):
         action_runner=action_runner,
         run_login=run_login,
         run_setup=run_setup)
-    return cast(LoadingPageFilter,
-                super().story_filter(patterns, args=args, separate=separate))
+    story_filter = super().story_filter(patterns, args=args, separate=separate)
+    assert isinstance(story_filter, LoadingPageFilter)
+    return story_filter
 
   def test_page_list(self):
     self.assertTrue(PAGE_LIST)
@@ -143,6 +148,27 @@ class TestPageLoadBenchmark(helper.SubStoryTestCase):
     self._test_run(stories)
     self._assert_urls_loaded([story.url for story in PAGE_LIST])
 
+  def test_substories_single(self):
+    page = LivePage("test", "https://test.com", dt.timedelta(seconds=5))
+    self.assertSequenceEqual(page.substories, ["test"])
+
+  def test_substories_combined(self):
+    page = CombinedPage(PAGE_LIST)
+    self.assertSequenceEqual(page.substories,
+                             [story.name for story in PAGE_LIST])
+    page_0 = LivePage("test_0", "https://test.com/1", dt.timedelta(seconds=5))
+    page_1 = LivePage("test_1", "https://test.com/1", dt.timedelta(seconds=5))
+    page = CombinedPage([page_0, page_1])
+    self.assertSequenceEqual(page.substories, ["test_0", "test_1"])
+
+  def test_substories_nested(self):
+    page_0 = LivePage("test_0", "https://test.com/1", dt.timedelta(seconds=5))
+    page_1 = LivePage("test_1", "https://test.com/1", dt.timedelta(seconds=5))
+    page_2 = CombinedPage([page_0, page_1])
+    page_3 = LivePage("test_3", "https://test.com/3", dt.timedelta(seconds=5))
+    page = CombinedPage([page_2, page_3])
+    self.assertSequenceEqual(page.substories, ["test_0", "test_1", "test_3"])
+
   def test_run_default(self):
     stories = PAGE_LIST
     self._test_run(stories)
@@ -202,10 +228,11 @@ class TestPageLoadBenchmark(helper.SubStoryTestCase):
         self.out_dir,
         self.browsers,
         benchmark,
-        env_config=HostEnvironmentConfig(),
+        env_config=EnvironmentConfig(),
         env_validation_mode=ValidationMode.SKIP,
         platform=self.platform,
-        throw=throw)
+        throw=throw,
+        in_memory_result_db=True)
     runner.run()
     self.assertTrue(runner.is_success)
     self.assertTrue(self.browsers[0].did_run)
@@ -222,7 +249,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
 
   def test_invalid_duplicate_urls_stories(self):
     with self.assertRaises(argparse.ArgumentTypeError) as cm:
-      with self.patch_get_browser():
+      with self._patch_get_browser():
         url = "http://test.com"
         self.run_cli("loading", "run", f"--urls={url}", f"--stories={url}",
                      "--env-validation=skip", "--throw")
@@ -231,7 +258,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
 
   def test_invalid_duplicate_urls_config(self):
     with self.assertRaises(argparse.ArgumentError) as cm:
-      with self.patch_get_browser():
+      with self._patch_get_browser():
         self.run_cli("loading", "run", "--urls=https://test.com",
                      "--page-config=config.hjson", "--env-validation=skip",
                      "--throw")
@@ -240,7 +267,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
 
   def test_invalid_duplicate_stories_config(self):
     with self.assertRaises(argparse.ArgumentTypeError) as cm:
-      with self.patch_get_browser():
+      with self._patch_get_browser():
         self.run_cli("loading", "run", "--stories=https://test.com",
                      "--page-config=config.hjson", "--env-validation=skip",
                      "--throw")
@@ -263,7 +290,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       json.dump(config_data, f)
     with self.assertRaises(argparse.ArgumentTypeError) as cm:
-      with self.patch_get_browser():
+      with self._patch_get_browser():
         self.run_cli("loading", "run", "--stories=https://test.com",
                      "--config=config.hjson", "--page-config=config.hjson",
                      "--env-validation=skip", "--throw")
@@ -279,7 +306,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
     url_2 = "http://two.test.com"
     with config.open("w", encoding="utf-8") as f:
       f.write("\n".join((url_1, url_2)))
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "run", f"--urls-file={config}",
                    "--env-validation=skip", "--throw")
       for browser in self.browsers:
@@ -293,7 +320,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
     url_2 = "http://two.test.com"
     with config.open("w", encoding="utf-8") as f:
       f.write("\n".join((url_1, url_2)))
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "run", f"--urls-file={config}",
                    "--env-validation=skip", "--separate", "--throw")
       for browser in self.browsers:
@@ -302,7 +329,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
         self.assertEqual(url_2, browser.url_list[self.SPLASH_URLS_LEN * 2 + 1])
 
   def test_urls_single(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", "run", f"--urls={url}", "--env-validation=skip",
                    "--throw")
@@ -310,7 +337,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
         self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
 
   def test_urls_multiple(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url_1 = "http://one.test.com"
       url_2 = "http://two.test.com"
       self.run_cli("loading", "run", f"--urls={url_1},{url_2}",
@@ -320,7 +347,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
                              browser.url_list[self.SPLASH_URLS_LEN:])
 
   def test_urls_multiple_separate(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url_1 = "http://one.test.com"
       url_2 = "http://two.test.com"
       self.run_cli("loading", "run", f"--urls={url_1},{url_2}",
@@ -331,7 +358,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
         self.assertEqual(url_2, browser.url_list[self.SPLASH_URLS_LEN * 2 + 1])
 
   def test_repeat_playback(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url_1 = "http://one.test.com"
       url_2 = "http://two.test.com"
       self.run_cli("loading", "run", f"--urls={url_1},{url_2}", "--playback=2x",
@@ -341,7 +368,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
                              browser.url_list[self.SPLASH_URLS_LEN:])
 
   def test_repeat_playback_separate(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url_1 = "http://one.test.com"
       url_2 = "http://two.test.com"
       self.run_cli("loading", "run", f"--urls={url_1},{url_2}", "--playback=2x",
@@ -374,7 +401,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
     url_1, url_2, config = self.simple_pages_config()
     config_file = pathlib.Path("test/page_config.json")
     self.fs.create_file(config_file, contents=json.dumps(config))
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "run", f"--page-config={config_file}",
                    "--env-validation=skip", "--throw")
       for browser in self.browsers:
@@ -428,7 +455,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
     config_file = pathlib.Path("test/page_config.json")
     self.fs.create_file(config_file, contents=json.dumps(config))
     self.setup_expected_google_login_js()
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "run", f"--page-config={config_file}",
                    "--env-validation=skip", "--throw")
       for browser in self.browsers:
@@ -445,16 +472,17 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
             "password": "s3cr3t"
         }
     }
-    secrets_dict = SecretsConfig.parse(secrets_data).as_dict()
+    secrets = Secrets.parse(secrets_data)
     self.setup_expected_google_login_js()
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       with mock.patch.object(
           Settings, "secrets",
           new_callable=mock.PropertyMock) as mock_get_secrets:
-        mock_get_secrets.return_value = secrets_dict
+        mock_get_secrets.return_value = secrets
         self.run_cli("loading", "run", f"--page-config={config_file}",
                      "--env-validation=skip", "--throw",
                      f"--secrets={json.dumps(secrets_data)}")
+        self.assertEqual(mock_get_secrets.call_count, 2)
       for browser in self.browsers:
         self.assertListEqual([GOOGLE_LOGIN_URL, url_1, url_2],
                              browser.url_list[self.SPLASH_URLS_LEN:])
@@ -464,7 +492,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
     config_file = pathlib.Path("test/page_config.json")
     self.fs.create_file(config_file, contents=json.dumps(config))
     self.setup_expected_google_login_js()
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       with self.assertRaises(Exception) as cm:
         self.run_cli("loading", "run", f"--page-config={config_file}",
                      "--env-validation=skip", "--throw")
@@ -491,7 +519,7 @@ class LoadingBenchmarkCliTestCase(BaseCliTestCase):
     }
     with global_config_file.open("w", encoding="utf-8") as f:
       json.dump(global_config_data, f)
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "run", f"--config={global_config_file}",
                    "--env-validation=skip", "--throw")
       for browser in self.browsers:
@@ -709,5 +737,8 @@ class ActionBlockListConfigTestCase(unittest.TestCase):
     self.assertIn("login", str(cm.exception))
 
 
+# Don't expose abstract base test cases.
+del SubStoryTestCase, BaseCliTestCase
+
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/loading/test_playback_controller.py b/tests/crossbench/benchmarks/loading/test_playback_controller.py
index ae6d65c6..65cde027 100644
--- a/tests/crossbench/benchmarks/loading/test_playback_controller.py
+++ b/tests/crossbench/benchmarks/loading/test_playback_controller.py
@@ -7,6 +7,7 @@ from __future__ import annotations
 import argparse
 import datetime as dt
 import unittest
+from unittest import mock
 
 from crossbench.benchmarks.loading.playback_controller import (
     ForeverPlaybackController, PlaybackController, RepeatPlaybackController,
@@ -97,6 +98,25 @@ class PlaybackControllerTestCase(unittest.TestCase):
         1 for _ in PlaybackController.timeout(dt.timedelta(milliseconds=0.1)))
     self.assertGreaterEqual(iterations, 1)
 
+  def test_timeout_mocked(self):
+    controller = PlaybackController.timeout(dt.timedelta(seconds=1))
+    now = dt.datetime.now()
+    with mock.patch(
+        "crossbench.benchmarks.loading.playback_controller.dt") as mock_dt:
+      mock_dt.datetime.now.return_value = now
+      iterator = iter(controller)
+      for _ in range(100):
+        next(iterator)
+      mock_dt.datetime.now.return_value = now + dt.timedelta(seconds=0.9)
+      for _ in range(100):
+        next(iterator)
+      mock_dt.datetime.now.return_value = now + dt.timedelta(seconds=1)
+      for _ in range(100):
+        next(iterator)
+      mock_dt.datetime.now.return_value = now + dt.timedelta(seconds=1.1)
+      with self.assertRaises(StopIteration):
+        next(iterator)
+
   def test_forever(self):
     count = 0
     for _ in PlaybackController.forever():
diff --git a/tests/crossbench/benchmarks/speedometer_helper.py b/tests/crossbench/benchmarks/speedometer_helper.py
index efa01207..56a17388 100644
--- a/tests/crossbench/benchmarks/speedometer_helper.py
+++ b/tests/crossbench/benchmarks/speedometer_helper.py
@@ -11,10 +11,12 @@ from dataclasses import dataclass
 from typing import Dict, List, Optional, Sequence, Type
 from unittest import mock
 
-from crossbench.benchmarks.speedometer.speedometer import (SpeedometerBenchmark,
-                                                           SpeedometerProbe,
-                                                           SpeedometerStory)
-from crossbench.env import HostEnvironmentConfig, ValidationMode
+from typing_extensions import override
+
+from crossbench.benchmarks.speedometer.speedometer import (
+    SpeedometerBenchmark, SpeedometerProbe, SpeedometerProbeContext,
+    SpeedometerStory)
+from crossbench.env import EnvironmentConfig, ValidationMode
 from crossbench.runner.runner import Runner
 from tests.crossbench.benchmarks import helper
 
@@ -24,11 +26,13 @@ class SpeedometerBaseTestCase(
 
   @property
   @abc.abstractmethod
+  @override
   def benchmark_cls(self) -> Type[SpeedometerBenchmark]:
     pass
 
   @property
   @abc.abstractmethod
+  @override
   def story_cls(self) -> Type[SpeedometerStory]:
     pass
 
@@ -37,6 +41,11 @@ class SpeedometerBaseTestCase(
   def probe_cls(self) -> Type[SpeedometerProbe]:
     pass
 
+  @property
+  @abc.abstractmethod
+  def probe_context_cls(self) -> Type[SpeedometerProbeContext]:
+    pass
+
   @property
   @abc.abstractmethod
   def name(self) -> str:
@@ -49,18 +58,19 @@ class SpeedometerBaseTestCase(
 
   @dataclass
   class Namespace(argparse.Namespace):
-    stories = "all"
+    stories = "default"
     iterations: int = 10
     separate: bool = False
-    custom_benchmark_url: Optional[str] = None
+    custom_benchmark_url: str | None = None
+
 
   def test_iterations_kwargs(self):
     args = self.Namespace()
     self.benchmark_cls.from_cli_args(args)
-    with self.assertRaises(TypeError):
+    with self.assertRaises(argparse.ArgumentTypeError):
       args.iterations = "-10"  # pytype: disable=annotation-type-mismatch
       self.benchmark_cls.from_cli_args(args)
-    with self.assertRaises(TypeError):
+    with self.assertRaises(argparse.ArgumentTypeError):
       args.iterations = "1234"  # pytype: disable=annotation-type-mismatch
       benchmark = self.benchmark_cls.from_cli_args(args)
     args.iterations = 1234
@@ -165,7 +175,7 @@ class SpeedometerBaseTestCase(
           browser.expect_js()
           # Wait until done
           browser.expect_js(result=True)
-          browser.expect_js(result=speedometer_probe_results)
+          browser.expect_js(result=json.dumps(speedometer_probe_results))
     for browser in self.browsers:
       browser.expected_js = copy.deepcopy(browser.expected_js)
 
@@ -175,12 +185,13 @@ class SpeedometerBaseTestCase(
         self.out_dir,
         self.browsers,
         benchmark,
-        env_config=HostEnvironmentConfig(),
+        env_config=EnvironmentConfig(),
         env_validation_mode=ValidationMode.SKIP,
         platform=self.platform,
         repetitions=repetitions,
         warmup_repetitions=warmup_repetitions,
-        throw=throw)
+        throw=throw,
+        in_memory_result_db=True)
     with mock.patch.object(self.benchmark_cls, "validate_url") as cm:
       runner.run()
     cm.assert_called_once()
@@ -198,7 +209,7 @@ class SpeedometerBaseTestCase(
       urls = self.filter_splashscreen_urls(browser.url_list)
       if expected_num_urls is not None:
         self.assertEqual(len(urls), expected_num_urls)
-      self.assertTrue(browser.was_js_invoked(self.probe_cls.JS))
+      self.assertTrue(browser.was_js_invoked(self.probe_context_cls.JS))
       self.assertListEqual(browser.expected_js, [])
 
     with self.assertLogs(level="INFO") as cm:
@@ -300,6 +311,7 @@ class SpeedometerBaseTestCase(
 
 
 class Speedometer2BaseTestCase(SpeedometerBaseTestCase, metaclass=abc.ABCMeta):
+
   EXAMPLE_STORY_DATA = {
       "tests": {
           "Adding100Items": {
@@ -327,6 +339,7 @@ class Speedometer2BaseTestCase(SpeedometerBaseTestCase, metaclass=abc.ABCMeta):
       "total": 121.40000000596046
   }
 
+  @override
   def _generate_test_probe_results(self, iterations, story):
     return [{
         "tests": {
diff --git a/tests/crossbench/benchmarks/test_all.py b/tests/crossbench/benchmarks/test_all.py
index 67595d06..6f14f364 100644
--- a/tests/crossbench/benchmarks/test_all.py
+++ b/tests/crossbench/benchmarks/test_all.py
@@ -11,10 +11,16 @@ from ordered_set import OrderedSet
 from crossbench.benchmarks.jetstream.jetstream_2_0 import JetStream20Benchmark
 from crossbench.benchmarks.jetstream.jetstream_2_1 import JetStream21Benchmark
 from crossbench.benchmarks.jetstream.jetstream_2_2 import JetStream22Benchmark
-from crossbench.benchmarks.jetstream.jetstream_3_0 import JetStream30Benchmark
-from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+from crossbench.benchmarks.jetstream.jetstream_main import \
+    JetStreamMainBenchmark
+from crossbench.benchmarks.loading.loading_benchmark import LoadingBenchmark
 from crossbench.benchmarks.loading.loadline_presets import (
-    LoadLinePhoneBenchmark, LoadLineTabletBenchmark)
+    LoadLinePhoneBenchmark,
+    LoadLinePhoneDebugBenchmark,
+    LoadLinePhoneFastBenchmark,
+    LoadLineTabletBenchmark,
+    LoadLineTabletDebugBenchmark,
+    LoadLineTabletFastBenchmark)
 from crossbench.benchmarks.manual.manual_benchmark import ManualBenchmark
 from crossbench.benchmarks.memory.memory_benchmark import MemoryBenchmark
 from crossbench.benchmarks.motionmark.motionmark_1_0 import \
@@ -25,30 +31,46 @@ from crossbench.benchmarks.motionmark.motionmark_1_2 import \
     MotionMark12Benchmark
 from crossbench.benchmarks.motionmark.motionmark_1_3 import \
     MotionMark13Benchmark
+from crossbench.benchmarks.motionmark.motionmark_1_3_1 import \
+    MotionMark131Benchmark
+from crossbench.benchmarks.motionmark.motionmark_main import \
+    MotionMarkMainBenchmark
 from crossbench.benchmarks.speedometer.speedometer_2_0 import \
     Speedometer20Benchmark
 from crossbench.benchmarks.speedometer.speedometer_2_1 import \
     Speedometer21Benchmark
 from crossbench.benchmarks.speedometer.speedometer_3_0 import \
     Speedometer30Benchmark
+from crossbench.benchmarks.speedometer.speedometer_3_1 import \
+    Speedometer31Benchmark
+from crossbench.benchmarks.speedometer.speedometer_main import \
+    SpeedometerMainBenchmark
 from tests import test_helper
 
 ALL = (
     JetStream20Benchmark,
     JetStream21Benchmark,
     JetStream22Benchmark,
-    JetStream30Benchmark,
+    JetStreamMainBenchmark,
     LoadLinePhoneBenchmark,
+    LoadLinePhoneDebugBenchmark,
+    LoadLinePhoneFastBenchmark,
     LoadLineTabletBenchmark,
+    LoadLineTabletDebugBenchmark,
+    LoadLineTabletFastBenchmark,
     ManualBenchmark,
     MotionMark10Benchmark,
     MotionMark11Benchmark,
     MotionMark12Benchmark,
     MotionMark13Benchmark,
-    PageLoadBenchmark,
+    MotionMark131Benchmark,
+    MotionMarkMainBenchmark,
+    LoadingBenchmark,
     Speedometer20Benchmark,
     Speedometer21Benchmark,
     Speedometer30Benchmark,
+    Speedometer31Benchmark,
+    SpeedometerMainBenchmark,
     MemoryBenchmark,
 )
 
@@ -75,8 +97,8 @@ class AllBenchmarksTestCase(unittest.TestCase):
       if benchmark_cls is MemoryBenchmark:
         continue
       if issubclass(benchmark_cls,
-                    PageLoadBenchmark) and (benchmark_cls
-                                            is not PageLoadBenchmark):
+                    LoadingBenchmark) and (benchmark_cls
+                                           is not LoadingBenchmark):
         continue
       self.assertNotIn(benchmark_cls.DEFAULT_STORY_CLS, seen_story_classes)
       seen_story_classes.add(benchmark_cls.DEFAULT_STORY_CLS)
diff --git a/tests/crossbench/benchmarks/test_benchmark.py b/tests/crossbench/benchmarks/test_benchmark.py
index 5d2427c9..fcf9d026 100644
--- a/tests/crossbench/benchmarks/test_benchmark.py
+++ b/tests/crossbench/benchmarks/test_benchmark.py
@@ -5,6 +5,8 @@
 import datetime as dt
 import unittest
 
+from typing_extensions import override
+
 from crossbench.benchmarks.base import PressBenchmarkStoryFilter
 from crossbench.runner.run import Run
 from crossbench.stories.press_benchmark import PressBenchmarkStory
@@ -22,6 +24,7 @@ class MockStory(PressBenchmarkStory):
   )
 
   @property
+  @override
   def substory_duration(self) -> dt.timedelta:
     return dt.timedelta(seconds=0.1)
 
diff --git a/tests/crossbench/benchmarks/test_jetstream.py b/tests/crossbench/benchmarks/test_jetstream.py
index 8841ba1a..27b213b6 100644
--- a/tests/crossbench/benchmarks/test_jetstream.py
+++ b/tests/crossbench/benchmarks/test_jetstream.py
@@ -4,19 +4,21 @@
 
 import unittest
 
+from typing_extensions import override
+
 from crossbench.benchmarks.jetstream.jetstream import JetStreamCSVFormatter
-from crossbench.benchmarks.jetstream.jetstream_2_0 import (JetStream20Benchmark,
-                                                           JetStream20Probe,
-                                                           JetStream20Story)
-from crossbench.benchmarks.jetstream.jetstream_2_1 import (JetStream21Benchmark,
-                                                           JetStream21Probe,
-                                                           JetStream21Story)
-from crossbench.benchmarks.jetstream.jetstream_2_2 import (JetStream22Benchmark,
-                                                           JetStream22Probe,
-                                                           JetStream22Story)
-from crossbench.benchmarks.jetstream.jetstream_3_0 import (JetStream30Benchmark,
-                                                           JetStream30Probe,
-                                                           JetStream30Story)
+from crossbench.benchmarks.jetstream.jetstream_2_0 import (
+    JetStream20Benchmark, JetStream20Probe, JetStream20ProbeContext,
+    JetStream20Story)
+from crossbench.benchmarks.jetstream.jetstream_2_1 import (
+    JetStream21Benchmark, JetStream21Probe, JetStream21ProbeContext,
+    JetStream21Story)
+from crossbench.benchmarks.jetstream.jetstream_2_2 import (
+    JetStream22Benchmark, JetStream22Probe, JetStream22ProbeContext,
+    JetStream22Story)
+from crossbench.benchmarks.jetstream.jetstream_main import (
+    JetStreamMainBenchmark, JetStreamMainProbe, JetStreamMainProbeContext,
+    JetStreamMainStory)
 from crossbench.probes.metric import MetricsMerger
 from tests import test_helper
 # Only import module to avoid exposing the abstract test classes to the runner.
@@ -25,6 +27,15 @@ from tests.crossbench.benchmarks import jetstream_helper
 
 class JetStreamCSVFormatterTestCase(unittest.TestCase):
 
+  def test_throw_missing_score(self):
+    metrics = MetricsMerger({
+        "Total/average": 10,
+        "cdjs/average": 30,
+        "cdjs/score": 40,
+    })
+    with self.assertRaisesRegex(KeyError, "Total/score"):
+      _ = JetStreamCSVFormatter(metrics, lambda metric: metric.geomean).table
+
   def test_format_sorted(self):
     metrics = MetricsMerger({
         "Total/average": 10,
@@ -32,7 +43,8 @@ class JetStreamCSVFormatterTestCase(unittest.TestCase):
         "cdjs/average": 30,
         "cdjs/score": 40,
     })
-    table = JetStreamCSVFormatter(metrics, lambda metric: metric.geomean).table
+    table = JetStreamCSVFormatter(
+        metrics, lambda metric: round(metric.geomean, 10)).table
     self.assertSequenceEqual(table, [
         ("Total/score", "Total", "score", 20.0),
         ("cdjs/score", "cdjs", "score", 40.0),
@@ -50,7 +62,7 @@ class JetStreamCSVFormatterTestCase(unittest.TestCase):
         "Total/score": 20,
     })
     table = JetStreamCSVFormatter(
-        metrics, lambda metric: metric.geomean, sort=False).table
+        metrics, lambda metric: round(metric.geomean, 10), sort=False).table
     self.assertSequenceEqual(table, [
         ("Total/score", "Total", "score", 20.0),
         ("cdjs/score", "cdjs", "score", 40.0),
@@ -64,17 +76,25 @@ class JetStreamCSVFormatterTestCase(unittest.TestCase):
 class JetStream20TestCase(jetstream_helper.JetStream2BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return JetStream20Benchmark
 
   @property
+  @override
   def story_cls(self):
     return JetStream20Story
 
   @property
+  @override
   def probe_cls(self):
     return JetStream20Probe
 
+  @property
+  @override
+  def probe_context_cls(self):
+    return JetStream20ProbeContext
+
   @property
   def name(self):
     return "jetstream_2.0"
@@ -83,17 +103,25 @@ class JetStream20TestCase(jetstream_helper.JetStream2BaseTestCase):
 class JetStream21TestCase(jetstream_helper.JetStream2BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return JetStream21Benchmark
 
   @property
+  @override
   def story_cls(self):
     return JetStream21Story
 
   @property
+  @override
   def probe_cls(self):
     return JetStream21Probe
 
+  @property
+  @override
+  def probe_context_cls(self):
+    return JetStream21ProbeContext
+
   @property
   def name(self):
     return "jetstream_2.1"
@@ -102,39 +130,56 @@ class JetStream21TestCase(jetstream_helper.JetStream2BaseTestCase):
 class JetStream22TestCase(jetstream_helper.JetStream2BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return JetStream22Benchmark
 
   @property
+  @override
   def story_cls(self):
     return JetStream22Story
 
   @property
+  @override
   def probe_cls(self):
     return JetStream22Probe
 
   @property
+  @override
+  def probe_context_cls(self):
+    return JetStream22ProbeContext
+
+  @property
+  @override
   def name(self):
     return "jetstream_2.2"
 
 
-class JetStream30TestCase(jetstream_helper.JetStream3BaseTestCase):
+class JetStreamMainTestCase(jetstream_helper.JetStream3BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
-    return JetStream30Benchmark
+    return JetStreamMainBenchmark
 
   @property
+  @override
   def story_cls(self):
-    return JetStream30Story
+    return JetStreamMainStory
 
   @property
+  @override
   def probe_cls(self):
-    return JetStream30Probe
+    return JetStreamMainProbe
+
+  @property
+  @override
+  def probe_context_cls(self):
+    return JetStreamMainProbeContext
 
   @property
   def name(self):
-    return "jetstream_3.0"
+    return "jetstream_main"
 
 
 if __name__ == "__main__":
diff --git a/tests/crossbench/benchmarks/test_loadline.py b/tests/crossbench/benchmarks/test_loadline.py
new file mode 100644
index 00000000..58a467eb
--- /dev/null
+++ b/tests/crossbench/benchmarks/test_loadline.py
@@ -0,0 +1,108 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# pytype: disable=attribute-error
+
+from __future__ import annotations
+
+import abc
+import argparse
+import datetime as dt
+from typing import Sequence
+
+from typing_extensions import override
+
+from crossbench.action_runner.default_action_runner import DefaultActionRunner
+from crossbench.benchmarks.loading.loadline_presets import (
+    LoadLinePageFilter, LoadLinePhoneBenchmark, LoadLineTabletBenchmark)
+from crossbench.benchmarks.loading.playback_controller import \
+    PlaybackController
+from crossbench.benchmarks.loading.tab_controller import TabController
+from tests import test_helper
+from tests.crossbench.base import BaseCliTestCase
+from tests.crossbench.benchmarks.helper import SubStoryTestCase
+
+
+# TODO(378584786): use shared helper mixin with TestPageLoadBenchmark
+class BaseLoadLineBenchmarkTestCase(SubStoryTestCase, metaclass=abc.ABCMeta):
+
+  @override
+  def setUp(self):
+    super().setUp()
+    self.setup_loadline_config()
+
+  @override
+  def story_filter(  # pylint: disable=arguments-differ
+      self,
+      patterns: Sequence[str],
+      separate: bool = True,
+  ) -> LoadLinePageFilter:
+    args = argparse.Namespace(
+        about_blank_duration=dt.timedelta(),
+        playback=PlaybackController.default(),
+        tabs=TabController.default(),
+        action_runner=DefaultActionRunner(),
+        run_login=True,
+        run_setup=True)
+    story_filter = super().story_filter(patterns, args=args, separate=separate)
+    assert isinstance(story_filter, LoadLinePageFilter)
+    return story_filter
+
+  def test_all_stories(self):
+    # TODO: preload the story names from the config files
+    stories = self.story_filter(["all"]).stories
+    self.assertFalse(stories)
+
+  def test_default_stories(self):
+    # TODO: preload the story names from the config files
+    stories = self.story_filter(["default"]).stories
+    self.assertFalse(stories)
+
+  def test_get_pages_config(self):
+    config = self.benchmark_cls.get_pages_config()
+    # Ensure it's cached
+    self.assertIs(config, self.benchmark_cls.get_pages_config())
+
+  def test_get_pages_config_variants(self):
+    configs = [
+        LoadLineTabletBenchmark.get_pages_config(),
+        LoadLinePhoneBenchmark.get_pages_config()
+    ]
+    self.assertNotEqual(configs[0], configs[1])
+
+
+class TestLoadLineTabletBenchmark(BaseLoadLineBenchmarkTestCase):
+
+  @property
+  @override
+  def benchmark_cls(self):
+    return LoadLineTabletBenchmark
+
+
+class TestLoadLinePhoneBenchmark(BaseLoadLineBenchmarkTestCase):
+
+  @property
+  @override
+  def benchmark_cls(self):
+    return LoadLinePhoneBenchmark
+
+
+class LoadLineBenchmarkCliTestCase(BaseCliTestCase):
+
+  def test_run_default_phone(self):
+    # TODO(378584786): implement
+    pass
+
+  def test_run_default_tablet(self):
+    # TODO(378584786): implement
+    pass
+
+
+# Don't expose abstract base test cases.
+del BaseLoadLineBenchmarkTestCase
+del BaseCliTestCase
+del SubStoryTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/benchmarks/test_manual.py b/tests/crossbench/benchmarks/test_manual.py
index 97ffbf1e..6c8b827d 100644
--- a/tests/crossbench/benchmarks/test_manual.py
+++ b/tests/crossbench/benchmarks/test_manual.py
@@ -8,8 +8,10 @@ import datetime as dt
 from typing import Optional
 from unittest import mock
 
+from typing_extensions import override
+
 from crossbench.benchmarks.manual.manual_benchmark import ManualBenchmark
-from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.env import EnvironmentConfig, ValidationMode
 from crossbench.runner.runner import Runner
 from tests import test_helper
 from tests.crossbench.benchmarks.helper import BaseBenchmarkTestCase
@@ -18,6 +20,7 @@ from tests.crossbench.benchmarks.helper import BaseBenchmarkTestCase
 class TestManualBenchmark(BaseBenchmarkTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return ManualBenchmark
 
@@ -55,11 +58,12 @@ class TestManualBenchmark(BaseBenchmarkTestCase):
         self.out_dir,
         self.browsers,
         benchmark,
-        env_config=HostEnvironmentConfig(),
+        env_config=EnvironmentConfig(),
         env_validation_mode=ValidationMode.SKIP,
         platform=self.platform,
         repetitions=repetitions,
-        throw=True)
+        throw=True,
+        in_memory_result_db=True)
 
     with self.assertLogs(level="INFO") as cm:
       runner.run()
diff --git a/tests/crossbench/benchmarks/test_memory.py b/tests/crossbench/benchmarks/test_memory.py
index 20e25fff..86061337 100644
--- a/tests/crossbench/benchmarks/test_memory.py
+++ b/tests/crossbench/benchmarks/test_memory.py
@@ -6,11 +6,13 @@ import argparse
 import copy
 import csv
 
+from typing_extensions import override
+
 from crossbench.benchmarks.loading.page.live import LivePage
 from crossbench.benchmarks.loading.tab_controller import TabController
 from crossbench.benchmarks.memory.memory_benchmark import (
     MemoryBenchmark, MemoryBenchmarkStoryFilter, MemoryProbe)
-from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.env import EnvironmentConfig, ValidationMode
 from crossbench.runner.runner import Runner
 from tests import test_helper
 from tests.crossbench.benchmarks import helper
@@ -19,10 +21,12 @@ from tests.crossbench.benchmarks import helper
 class MemoryBenchmarkTestCase(helper.BaseBenchmarkTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return MemoryBenchmark
 
   @property
+  @override
   def story_cls(self):
     return MemoryBenchmarkStoryFilter
 
@@ -78,11 +82,12 @@ class MemoryBenchmarkTestCase(helper.BaseBenchmarkTestCase):
         self.out_dir,
         self.browsers,
         benchmark,
-        env_config=HostEnvironmentConfig(),
+        env_config=EnvironmentConfig(),
         env_validation_mode=ValidationMode.SKIP,
         platform=self.platform,
         repetitions=repetitions,
-        throw=throw)
+        throw=throw,
+        in_memory_result_db=True)
 
     runner.run()
     assert runner.is_success
diff --git a/tests/crossbench/benchmarks/test_motionmark.py b/tests/crossbench/benchmarks/test_motionmark.py
index 5ce3f8bf..84edcdf3 100644
--- a/tests/crossbench/benchmarks/test_motionmark.py
+++ b/tests/crossbench/benchmarks/test_motionmark.py
@@ -8,15 +8,24 @@ import csv
 from typing import Optional, Type
 from unittest import mock
 
-from crossbench.benchmarks.motionmark.motionmark_1 import (MotionMark1Benchmark,
-                                                           MotionMark1Probe,
-                                                           MotionMark1Story)
+from typing_extensions import override
+
+from crossbench.benchmarks.motionmark.motionmark_1 import (
+    MotionMark1Benchmark, MotionMark1Probe, MotionMark1ProbeContext,
+    MotionMark1Story)
 from crossbench.benchmarks.motionmark.motionmark_1_2 import (
-    MotionMark12Benchmark, MotionMark12Probe, MotionMark12Story)
+    MotionMark12Benchmark, MotionMark12Probe, MotionMark12ProbeContext,
+    MotionMark12Story)
 from crossbench.benchmarks.motionmark.motionmark_1_3 import (
-    MotionMark13Benchmark, MotionMark13Probe, MotionMark13Story)
-from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
-                            ValidationMode)
+    MotionMark13Benchmark, MotionMark13Probe, MotionMark13ProbeContext,
+    MotionMark13Story)
+from crossbench.benchmarks.motionmark.motionmark_1_3_1 import (
+    MotionMark131Benchmark, MotionMark131Probe, MotionMark131ProbeContext,
+    MotionMark131Story)
+from crossbench.benchmarks.motionmark.motionmark_main import (
+    MotionMarkMainBenchmark, MotionMarkMainProbe, MotionMarkMainProbeContext,
+    MotionMarkMainStory)
+from crossbench.env import EnvironmentConfig, HostEnvironment, ValidationMode
 from crossbench.runner.runner import Runner
 from tests import test_helper
 from tests.crossbench.benchmarks import helper
@@ -27,11 +36,13 @@ class MotionMark1BaseTestCase(
 
   @property
   @abc.abstractmethod
+  @override
   def benchmark_cls(self) -> Type[MotionMark1Benchmark]:
     pass
 
   @property
   @abc.abstractmethod
+  @override
   def story_cls(self) -> Type[MotionMark1Story]:
     pass
 
@@ -40,6 +51,11 @@ class MotionMark1BaseTestCase(
   def probe_cls(self) -> Type[MotionMark1Probe]:
     pass
 
+  @property
+  @abc.abstractmethod
+  def probe_context_cls(self) -> Type[MotionMark1ProbeContext]:
+    pass
+
 
   EXAMPLE_PROBE_DATA = [{
       "testsResults": {
@@ -141,11 +157,12 @@ class MotionMark1BaseTestCase(
         self.out_dir,
         self.browsers,
         benchmark,
-        env_config=HostEnvironmentConfig(),
+        env_config=EnvironmentConfig(),
         env_validation_mode=ValidationMode.SKIP,
         platform=self.platform,
         repetitions=repetitions,
-        throw=throw)
+        throw=throw,
+        in_memory_result_db=True)
     with mock.patch.object(
         HostEnvironment, "validate_url", return_value=True) as cm:
       runner.run()
@@ -154,7 +171,7 @@ class MotionMark1BaseTestCase(
     for browser in self.browsers:
       urls = self.filter_splashscreen_urls(browser.url_list)
       self.assertEqual(len(urls), repetitions)
-      self.assertTrue(browser.was_js_invoked(self.probe_cls.JS))
+      self.assertTrue(browser.was_js_invoked(self.probe_context_cls.JS))
     with (self.out_dir /
           f"{self.probe_cls.NAME}.csv").open(encoding="utf-8") as f:
       csv_data = list(csv.DictReader(f, delimiter="\t"))
@@ -174,32 +191,94 @@ class MotionMark1BaseTestCase(
 class MotionMark12TestCase(MotionMark1BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return MotionMark12Benchmark
 
   @property
+  @override
   def story_cls(self):
     return MotionMark12Story
 
   @property
+  @override
   def probe_cls(self):
     return MotionMark12Probe
 
+  @property
+  @override
+  def probe_context_cls(self):
+    return MotionMark12ProbeContext
+
 
 class MotionMark13TestCase(MotionMark1BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return MotionMark13Benchmark
 
   @property
+  @override
   def story_cls(self):
     return MotionMark13Story
 
   @property
+  @override
   def probe_cls(self):
     return MotionMark13Probe
 
+  @property
+  @override
+  def probe_context_cls(self):
+    return MotionMark13ProbeContext
+
+
+class MotionMark131TestCase(MotionMark1BaseTestCase):
+
+  @property
+  @override
+  def benchmark_cls(self):
+    return MotionMark131Benchmark
+
+  @property
+  @override
+  def story_cls(self):
+    return MotionMark131Story
+
+  @property
+  @override
+  def probe_cls(self):
+    return MotionMark131Probe
+
+  @property
+  @override
+  def probe_context_cls(self):
+    return MotionMark131ProbeContext
+
+
+class MotionMarkMainTestCase(MotionMark1BaseTestCase):
+
+  @property
+  @override
+  def benchmark_cls(self):
+    return MotionMarkMainBenchmark
+
+  @property
+  @override
+  def story_cls(self):
+    return MotionMarkMainStory
+
+  @property
+  @override
+  def probe_cls(self):
+    return MotionMarkMainProbe
+
+  @property
+  @override
+  def probe_context_cls(self):
+    return MotionMarkMainProbeContext
+
 
 del MotionMark1BaseTestCase
 
diff --git a/tests/crossbench/benchmarks/test_speedometer.py b/tests/crossbench/benchmarks/test_speedometer.py
index 5c41f863..019e0894 100644
--- a/tests/crossbench/benchmarks/test_speedometer.py
+++ b/tests/crossbench/benchmarks/test_speedometer.py
@@ -6,14 +6,26 @@ import argparse
 import datetime as dt
 import json
 from dataclasses import dataclass
+from typing import Any
+
+from typing_extensions import override
 
 from crossbench.benchmarks.speedometer.speedometer_2_0 import (
-    Speedometer20Benchmark, Speedometer20Probe, Speedometer20Story)
+    Speedometer20Benchmark, Speedometer20Probe, Speedometer20ProbeContext,
+    Speedometer20Story)
 from crossbench.benchmarks.speedometer.speedometer_2_1 import (
-    Speedometer21Benchmark, Speedometer21Probe, Speedometer21Story)
+    Speedometer21Benchmark, Speedometer21Probe, Speedometer21ProbeContext,
+    Speedometer21Story)
+from crossbench.benchmarks.speedometer.speedometer_3 import MeasurementMethod
 from crossbench.benchmarks.speedometer.speedometer_3_0 import (
-    MeasurementMethod, Speedometer30Benchmark, Speedometer30Probe,
+    Speedometer30Benchmark, Speedometer30Probe, Speedometer30ProbeContext,
     Speedometer30Story)
+from crossbench.benchmarks.speedometer.speedometer_3_1 import (
+    Speedometer31Benchmark, Speedometer31Probe, Speedometer31ProbeContext,
+    Speedometer31Story)
+from crossbench.benchmarks.speedometer.speedometer_main import (
+    SpeedometerMainBenchmark, SpeedometerMainProbe, SpeedometerMainProbeContext,
+    SpeedometerMainStory)
 from crossbench.browsers.viewport import Viewport
 from tests import test_helper
 from tests.crossbench.benchmarks.speedometer_helper import (
@@ -23,18 +35,27 @@ from tests.crossbench.benchmarks.speedometer_helper import (
 class Speedometer20TestCase(Speedometer2BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return Speedometer20Benchmark
 
   @property
+  @override
   def story_cls(self):
     return Speedometer20Story
 
   @property
+  @override
   def probe_cls(self):
     return Speedometer20Probe
 
   @property
+  @override
+  def probe_context_cls(self):
+    return Speedometer20ProbeContext
+
+  @property
+  @override
   def name(self):
     return "speedometer_2.0"
 
@@ -51,39 +72,32 @@ class Speedometer20TestCase(Speedometer2BaseTestCase):
 class Speedometer21TestCase(Speedometer2BaseTestCase):
 
   @property
+  @override
   def benchmark_cls(self):
     return Speedometer21Benchmark
 
   @property
+  @override
   def story_cls(self):
     return Speedometer21Story
 
   @property
+  @override
   def probe_cls(self):
     return Speedometer21Probe
 
   @property
-  def name(self):
-    return "speedometer_2.1"
-
-
-class Speedometer30TestCase(SpeedometerBaseTestCase):
+  @override
+  def probe_context_cls(self):
+    return Speedometer21ProbeContext
 
   @property
-  def benchmark_cls(self):
-    return Speedometer30Benchmark
-
-  @property
-  def story_cls(self):
-    return Speedometer30Story
+  @override
+  def name(self):
+    return "speedometer_2.1"
 
-  @property
-  def probe_cls(self):
-    return Speedometer30Probe
 
-  @property
-  def name(self):
-    return "speedometer_3.0"
+class Speedometer3BaseTestCase(SpeedometerBaseTestCase):
 
   @property
   def name_all(self):
@@ -98,7 +112,7 @@ class Speedometer30TestCase(SpeedometerBaseTestCase):
     shuffle_seed = None
     detailed_metrics = False
 
-  EXAMPLE_STORY_DATA = {}
+  EXAMPLE_STORY_DATA: dict[str, Any] = {}
 
   def _generate_s3_metrics(self, name, values):
     return {
@@ -115,19 +129,22 @@ class Speedometer30TestCase(SpeedometerBaseTestCase):
         "values": values
     }
 
+  @override
   def _generate_test_probe_results(self, iterations, story):
     values = [21.3] * iterations
-    probe_result = {
-        "Geomean": self._generate_s3_metrics("Geomean", values),
-        "Score": self._generate_s3_metrics("Score", values),
-    }
+    probe_result = {}
+    for substory_name in story.substories:
+      probe_result[substory_name] = self._generate_s3_metrics(
+          substory_name, values)
+
     for iteration in range(iterations):
       key = f"Iteration-{iteration}-Total"
       probe_result[key] = self._generate_s3_metrics(key, values)
 
-    for substory_name in story.substories:
-      probe_result[substory_name] = self._generate_s3_metrics(
-          substory_name, values)
+    probe_result.update({
+        "Geomean": self._generate_s3_metrics("Geomean", values),
+        "Score": self._generate_s3_metrics("Score", values),
+    })
     return probe_result
 
   def test_run_combined(self):
@@ -163,17 +180,65 @@ class Speedometer30TestCase(SpeedometerBaseTestCase):
 
   def test_measurement_method_kwargs(self):
     args = self.Namespace()
+    args.stories = "default"
     benchmark = self.benchmark_cls.from_cli_args(args)
-    for story in benchmark.stories:
-      assert isinstance(story, self.story_cls)
-      self.assertEqual(story.measurement_method, MeasurementMethod.RAF)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.name, self.name)
+    self.assertEqual(story.measurement_method, MeasurementMethod.RAF)
+    self.assertDictEqual(story.url_params, {})
 
     args.measurement_method = MeasurementMethod.TIMER
     benchmark = self.benchmark_cls.from_cli_args(args)
-    for story in benchmark.stories:
-      assert isinstance(story, self.story_cls)
-      self.assertEqual(story.measurement_method, MeasurementMethod.TIMER)
-      self.assertDictEqual(story.url_params, {"measurementMethod": "timer"})
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.name, self.name)
+    self.assertEqual(story.measurement_method, MeasurementMethod.TIMER)
+    self.assertDictEqual(story.url_params, {"measurementMethod": "timer"})
+
+  def test_all_stories_kwargs_url_params(self):
+    args = self.Namespace()
+    args.stories = "all"
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.name, "all")
+    self.assertEqual(story.measurement_method, MeasurementMethod.RAF)
+    self.assertDictEqual(story.url_params,
+                         {"suites": ",".join(story.SUBSTORIES)})
+
+  def test_single_story_kwargs(self):
+    args = self.Namespace()
+    args.stories = "TodoMVC-jQuery"
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.name, "TodoMVC-jQuery")
+    self.assertEqual(story.measurement_method, MeasurementMethod.RAF)
+    self.assertDictEqual(story.url_params, {"suites": "TodoMVC-jQuery"})
+
+  def test_iterations_kwargs(self):
+    args = self.Namespace()
+    args.stories = "default"
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.iterations, 10)
+    self.assertDictEqual(story.url_params, {})
+
+    args.iterations = 10
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.iterations, 10)
+    self.assertDictEqual(story.url_params, {})
+
+    args.iterations = 123
+    benchmark = self.benchmark_cls.from_cli_args(args)
+    (story,) = benchmark.stories
+    assert isinstance(story, self.story_cls)
+    self.assertEqual(story.iterations, 123)
+    self.assertDictEqual(story.url_params, {"iterationCount": "123"})
 
   def test_sync_wait_kwargs(self):
     args = self.Namespace()
@@ -247,9 +312,143 @@ class Speedometer30TestCase(SpeedometerBaseTestCase):
       self.assertEqual(story.shuffle_seed, 1234)
       self.assertDictEqual(story.url_params, {"shuffleSeed": "1234"})
 
+  def test_run_default(self):
+    runner = self._test_run(iterations=10)
+    self._verify_results(runner)
+    default_story_name = self.story_cls.SUBSTORIES[0]
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(f"{self.story_cls.URL}?suites={default_story_name}", urls)
+      self.assertNotIn(
+          f"{self.story_cls.URL_LOCAL}?suites={default_story_name}", urls)
+
+  def test_run_warmups(self):
+    runner = self._test_run(iterations=10, warmup_repetitions=1)
+    self._verify_results(runner)
+    default_story_name = self.story_cls.SUBSTORIES[0]
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(f"{self.story_cls.URL}?suites={default_story_name}", urls)
+      self.assertNotIn(
+          f"{self.story_cls.URL_LOCAL}?suites={default_story_name}", urls)
+
+  def test_run_custom_url(self):
+    custom_url = "http://test.example.com/speedometer"
+    runner = self._test_run(custom_url=custom_url, iterations=10)
+    default_story_name = self.story_cls.SUBSTORIES[0]
+    self._verify_results(runner)
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(f"{custom_url}?suites={default_story_name}", urls)
+      self.assertNotIn(f"{self.story_cls.URL}?suites={default_story_name}",
+                       urls)
+      self.assertNotIn(
+          f"{self.story_cls.URL_LOCAL}?suites={default_story_name}", urls)
+
+  def test_run_custom_iterations(self):
+    runner = self._test_run(iterations=7)
+    self._verify_results(runner)
+    default_story_name = self.story_cls.SUBSTORIES[0]
+    for browser in self.browsers:
+      urls = self.filter_splashscreen_urls(browser.url_list)
+      self.assertIn(
+          f"{self.story_cls.URL}?iterationCount=7&suites={default_story_name}",
+          urls)
+      self.assertNotIn(self.story_cls.URL, urls)
+      self.assertNotIn(
+          f"{self.story_cls.URL_LOCAL}?iterationCount=7"
+          f"&suites={default_story_name}", urls)
+      self.assertNotIn(self.story_cls.URL_LOCAL, urls)
+
+
+class Speedometer30TestCase(Speedometer3BaseTestCase):
+
+  @property
+  @override
+  def benchmark_cls(self):
+    return Speedometer30Benchmark
+
+  @property
+  @override
+  def story_cls(self):
+    return Speedometer30Story
+
+  @property
+  @override
+  def probe_cls(self):
+    return Speedometer30Probe
+
+  @property
+  @override
+  def probe_context_cls(self):
+    return Speedometer30ProbeContext
+
+  @property
+  @override
+  def name(self):
+    return "speedometer_3.0"
+
+
+class Speedometer31TestCase(Speedometer3BaseTestCase):
+
+  @property
+  @override
+  def benchmark_cls(self):
+    return Speedometer31Benchmark
+
+  @property
+  @override
+  def story_cls(self):
+    return Speedometer31Story
+
+  @property
+  @override
+  def probe_cls(self):
+    return Speedometer31Probe
+
+  @property
+  @override
+  def probe_context_cls(self):
+    return Speedometer31ProbeContext
+
+  @property
+  @override
+  def name(self):
+    return "speedometer_3.1"
+
+
+class SpeedometeMainTestCase(Speedometer3BaseTestCase):
+
+  @property
+  @override
+  def benchmark_cls(self):
+    return SpeedometerMainBenchmark
+
+  @property
+  @override
+  def story_cls(self):
+    return SpeedometerMainStory
+
+  @property
+  @override
+  def probe_cls(self):
+    return SpeedometerMainProbe
+
+  @property
+  @override
+  def probe_context_cls(self):
+    return SpeedometerMainProbeContext
+
+  @property
+  @override
+  def name(self):
+    return "speedometer_main"
+
 #  Don't expose abstract BaseTestCase to test runner
 del SpeedometerBaseTestCase
 del Speedometer2BaseTestCase
+del Speedometer3BaseTestCase
+
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/chrome/test_chrome.py b/tests/crossbench/browsers/chrome/test_chrome.py
index 6b384092..c951483e 100644
--- a/tests/crossbench/browsers/chrome/test_chrome.py
+++ b/tests/crossbench/browsers/chrome/test_chrome.py
@@ -4,20 +4,24 @@
 
 import argparse
 
-from tests import test_helper
-from tests.crossbench import mock_browser
-from tests.crossbench.base import BaseCrossbenchTestCase
+from typing_extensions import override
 
 from crossbench import path as pth
+from crossbench.browsers.chrome.version import ChromeVersion
 from crossbench.browsers.chrome.webdriver import (ChromeWebDriver,
                                                   LocalChromeWebDriverAndroid)
 from crossbench.browsers.settings import Settings
+from crossbench.flags.chrome import ChromeFlags
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCrossbenchTestCase
 
 
 class ChromeWebDriverForTesting(ChromeWebDriver):
 
-  def _extract_version(self) -> str:
-    return mock_browser.MockChromeStable.VERSION
+  @override
+  def _extract_version(self) -> ChromeVersion:
+    return ChromeVersion.parse(mock_browser.MockChromeStable.VERSION)
 
 
 class ChromeWebdriverTestCase(BaseCrossbenchTestCase):
@@ -53,15 +57,21 @@ class ChromeWebdriverTestCase(BaseCrossbenchTestCase):
     self.assertNotIn("--disable-field-trial-config", browser_field_trial.flags)
 
   def test_auto_disabling_field_trials_all(self):
-    for field_trial_flag in ChromeWebDriver.FIELD_TRIAL_FLAGS:
+    for field_trial_flag in ChromeFlags.FIELD_TRIAL_FLAGS:
+      if field_trial_flag == "--enable-benchmarking":
+        continue
       browser = ChromeWebDriverForTesting(
           label="browser-label",
           path=mock_browser.MockChromeStable.mock_app_path(),
           settings=Settings(flags=[field_trial_flag], platform=self.platform))
-      flags = browser.flags
-      for no_experiment_flag in ChromeWebDriver.NO_EXPERIMENTS_FLAGS:
-        self.assertNotIn(no_experiment_flag, flags)
-
+      flags: ChromeFlags = browser.flags
+      self.assertIn(field_trial_flag, flags)
+      self.assertFalse(flags.no_experiments_flags)
+
+  def test_is_local_build_mock_browser(self):
+    self.assertTrue(self.browsers)
+    for browser in self.browsers:
+      self.assertFalse(browser.is_local_build)
 
 class LocalChromeWebDriverAndroidTestCase(BaseCrossbenchTestCase):
 
diff --git a/tests/crossbench/browsers/chrome/test_downloader.py b/tests/crossbench/browsers/chrome/test_downloader.py
index 5a852c06..02125774 100644
--- a/tests/crossbench/browsers/chrome/test_downloader.py
+++ b/tests/crossbench/browsers/chrome/test_downloader.py
@@ -7,6 +7,8 @@ from __future__ import annotations
 import abc
 import pathlib
 
+from typing_extensions import override
+
 from crossbench.browsers.chrome.downloader import (ChromeDownloader,
                                                    ChromeDownloaderLinux,
                                                    ChromeDownloaderMacOS,
@@ -112,6 +114,7 @@ class AbstractChromeDownloaderTestCase(
 class BasicChromeDownloaderTestCaseLinux(AbstractChromeDownloaderTestCase):
   __test__ = True
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.platform.is_linux = True
@@ -128,6 +131,7 @@ class BasicChromeDownloaderTestCaseLinux(AbstractChromeDownloaderTestCase):
 class BasicChromeDownloaderTestCaseMacOS(AbstractChromeDownloaderTestCase):
   __test__ = True
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.platform.is_macos = True
diff --git a/tests/crossbench/browsers/chromium/test_chromium.py b/tests/crossbench/browsers/chromium/test_chromium.py
index a1c10cf8..70494ad2 100644
--- a/tests/crossbench/browsers/chromium/test_chromium.py
+++ b/tests/crossbench/browsers/chromium/test_chromium.py
@@ -2,12 +2,17 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
-from tests import test_helper
-from tests.crossbench.base import BaseCrossbenchTestCase
+import pathlib
+from unittest import mock
 
 from crossbench import path as pth
-from crossbench.browsers.chromium.webdriver import \
-    LocalChromiumWebDriverAndroid
+from crossbench.browsers.chromium.webdriver import (
+    ChromiumWebDriver, LocalChromiumWebDriverAndroid)
+from crossbench.browsers.chromium_based import helper
+from crossbench.browsers.settings import Settings
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCrossbenchTestCase
 
 
 class LocalChromeWebDriverAndroidTestCase(BaseCrossbenchTestCase):
@@ -22,6 +27,34 @@ class LocalChromeWebDriverAndroidTestCase(BaseCrossbenchTestCase):
         LocalChromiumWebDriverAndroid.is_apk_helper(
             pth.AnyPath("org.chromium.chrome")))
 
+  def test_is_local_build_mock_browser(self):
+    self.assertTrue(self.browsers)
+    for browser in self.browsers:
+      self.assertFalse(browser.is_local_build)
+
+  def test_is_local_build(self):
+    build_dir = pathlib.Path("/home/testuser/chrome/src/out/release")
+    path = build_dir / mock_browser.MockChromium.mock_app_binary()
+    self.fs.create_file(path, st_size=1000)
+    self.assertFalse(helper.is_in_build_dir(path, self.platform))
+
+    version_str = mock_browser.MockChromium.VERSION
+    with mock.patch.object(
+        self.platform, "app_version", return_value=version_str):
+      # Missing args.gn => cannot detect local build:
+      browser = ChromiumWebDriver(
+          "local", path=path, settings=Settings(platform=self.platform))
+      self.assertFalse(browser.is_local_build)
+      self.assertEqual(browser.version.version_str, version_str)
+
+      self.fs.create_file(build_dir / "args.gn")
+      self.assertTrue(helper.is_in_build_dir(path, self.platform))
+      browser = ChromiumWebDriver(
+          "local", path=path, settings=Settings(platform=self.platform))
+      self.assertTrue(browser.is_local_build)
+      self.assertFalse(browser.version.has_channel)
+      self.assertEqual(browser.version.version_str, version_str)
+
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/downloader_helper.py b/tests/crossbench/browsers/downloader_helper.py
index 26951fec..4ee5fb08 100644
--- a/tests/crossbench/browsers/downloader_helper.py
+++ b/tests/crossbench/browsers/downloader_helper.py
@@ -8,12 +8,15 @@ import abc
 import pathlib
 from unittest import mock
 
+from typing_extensions import override
+
 from tests.crossbench.base import BaseCrossbenchTestCase
 
 
 class AbstractDownloaderTestCase(BaseCrossbenchTestCase, metaclass=abc.ABCMeta):
   __test__ = False
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.platform = mock.Mock(
diff --git a/tests/crossbench/browsers/edge/__init__.py b/tests/crossbench/browsers/edge/__init__.py
new file mode 100644
index 00000000..b20ab3aa
--- /dev/null
+++ b/tests/crossbench/browsers/edge/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/browsers/edge/test_edge.py b/tests/crossbench/browsers/edge/test_edge.py
new file mode 100644
index 00000000..0105eeca
--- /dev/null
+++ b/tests/crossbench/browsers/edge/test_edge.py
@@ -0,0 +1,76 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+
+from typing_extensions import override
+
+from crossbench.browsers.edge.version import EdgeVersion
+from crossbench.browsers.edge.webdriver import EdgeWebDriver
+from crossbench.browsers.settings import Settings
+from crossbench.flags.chrome import ChromeFlags
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class EdgeWebDriverForTesting(EdgeWebDriver):
+
+  @override
+  def _extract_version(self) -> EdgeVersion:
+    return EdgeVersion.parse(mock_browser.MockEdgeStable.VERSION)
+
+
+class EdgeWebdriverTestCase(BaseCrossbenchTestCase):
+
+  def test_conflicting_finch_flags(self) -> None:
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      EdgeWebDriverForTesting(
+          label="browser-label",
+          path=mock_browser.MockEdgeStable.mock_app_path(),
+          settings=Settings(
+              js_flags=[],
+              flags=[
+                  "--disable-field-trial-config", "--enable-field-trial-config"
+              ],
+              platform=self.platform))
+    msg = str(cm.exception)
+    self.assertIn("--enable-field-trial-config", msg)
+    self.assertIn("--disable-field-trial-config", msg)
+
+  def test_auto_disabling_field_trials(self):
+    browser = EdgeWebDriverForTesting(
+        label="browser-label",
+        path=mock_browser.MockEdgeStable.mock_app_path(),
+        settings=Settings(platform=self.platform))
+    self.assertIn("--disable-field-trial-config", browser.flags)
+
+    browser_field_trial = EdgeWebDriverForTesting(
+        label="browser-label",
+        path=mock_browser.MockEdgeStable.mock_app_path(),
+        settings=Settings(
+            flags=["--force-fieldtrials"], platform=self.platform))
+    self.assertIn("--force-fieldtrials", browser_field_trial.flags)
+    self.assertNotIn("--disable-field-trial-config", browser_field_trial.flags)
+
+  def test_auto_disabling_field_trials_all(self):
+    for field_trial_flag in ChromeFlags.FIELD_TRIAL_FLAGS:
+      if field_trial_flag == "--enable-benchmarking":
+        continue
+      browser = EdgeWebDriverForTesting(
+          label="browser-label",
+          path=mock_browser.MockEdgeStable.mock_app_path(),
+          settings=Settings(flags=[field_trial_flag], platform=self.platform))
+      flags: ChromeFlags = browser.flags
+      self.assertIn(field_trial_flag, flags)
+      self.assertFalse(flags.no_experiments_flags)
+
+  def test_is_local_build_mock_browser(self):
+    self.assertTrue(self.browsers)
+    for browser in self.browsers:
+      self.assertFalse(browser.is_local_build)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/firefox/test_downloader.py b/tests/crossbench/browsers/firefox/test_downloader.py
index ce138a66..302c34b8 100644
--- a/tests/crossbench/browsers/firefox/test_downloader.py
+++ b/tests/crossbench/browsers/firefox/test_downloader.py
@@ -7,6 +7,8 @@ from __future__ import annotations
 import abc
 import pathlib
 
+from typing_extensions import override
+
 from crossbench.browsers.firefox.downloader import (FirefoxDownloader,
                                                     FirefoxDownloaderLinux,
                                                     FirefoxDownloaderMacOS,
@@ -72,6 +74,7 @@ class AbstractFirefoxDownloaderTestCase(
 class BasicFirefoxDownloaderLinuxTestCase(AbstractFirefoxDownloaderTestCase):
   __test__ = True
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.platform.is_linux = True
@@ -88,6 +91,7 @@ class BasicFirefoxDownloaderLinuxTestCase(AbstractFirefoxDownloaderTestCase):
 class BasicFirefoxDownloaderMacOSTestCase(AbstractFirefoxDownloaderTestCase):
   __test__ = True
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.platform.is_macos = True
diff --git a/tests/crossbench/browsers/test_settings.py b/tests/crossbench/browsers/test_settings.py
index 2b9ef8ac..b74f1373 100644
--- a/tests/crossbench/browsers/test_settings.py
+++ b/tests/crossbench/browsers/test_settings.py
@@ -14,6 +14,7 @@ from crossbench.browsers.viewport import Viewport
 from crossbench.flags.base import Flags
 from crossbench.flags.chrome import ChromeFlags
 from crossbench.flags.js_flags import JSFlags
+from tests import test_helper
 
 
 class SettingsTestCase(unittest.TestCase):
@@ -23,10 +24,12 @@ class SettingsTestCase(unittest.TestCase):
     self.assertEqual(settings.flags, Flags())
     self.assertEqual(settings.js_flags, Flags())
     self.assertIsNone(settings.cache_dir)
+    self.assertTrue(settings.clear_cache_dir)
     self.assertEqual(settings.viewport, Viewport.DEFAULT)
     self.assertIsNone(settings.driver_path)
     self.assertEqual(settings.splash_screen, SplashScreen.DEFAULT)
     self.assertTrue(settings.network.is_live)
+    self.assertFalse(settings.wipe_system_user_data)
     self.assertEqual(settings.platform, plt.PLATFORM)
 
   def test_custom(self):
@@ -36,6 +39,7 @@ class SettingsTestCase(unittest.TestCase):
         flags,
         js_flags,
         cache_dir=pth.LocalPath("cache"),
+        clear_cache_dir=False,
         viewport=Viewport.FULLSCREEN,
         driver_path=pth.LocalPath("driver"),
         splash_screen=SplashScreen.DETAILED,
@@ -43,6 +47,7 @@ class SettingsTestCase(unittest.TestCase):
     self.assertEqual(settings.flags, flags)
     self.assertEqual(settings.js_flags, js_flags)
     self.assertEqual(settings.cache_dir, pth.LocalPath("cache"))
+    self.assertFalse(settings.clear_cache_dir)
     self.assertEqual(settings.viewport, Viewport.FULLSCREEN)
     self.assertEqual(settings.driver_path, pth.LocalPath("driver"))
     self.assertEqual(settings.splash_screen, SplashScreen.DETAILED)
@@ -88,3 +93,7 @@ class SettingsTestCase(unittest.TestCase):
     with self.assertRaises(ValueError) as cm:
       _ = Settings(flags, js_flags=Flags({"--js-two": "js-2"}))
     self.assertIn("js-flags", str(cm.exception))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/browsers/test_version.py b/tests/crossbench/browsers/test_version.py
index 40e74cd2..171e0445 100644
--- a/tests/crossbench/browsers/test_version.py
+++ b/tests/crossbench/browsers/test_version.py
@@ -8,6 +8,8 @@ import abc
 import unittest
 from typing import cast
 
+from typing_extensions import override
+
 from crossbench.browsers.chrome.version import ChromeVersion
 from crossbench.browsers.chromium.version import (ChromeDriverVersion,
                                                   ChromiumVersion)
@@ -157,7 +159,6 @@ class _BrowserVersionTestCase(unittest.TestCase, metaclass=abc.ABCMeta):
     _ = hash(version.key)
     self.assertEqual(version, self.VERSION_CLS.lts(version.parts))
 
-
   def test_parse_stable(self):
     version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
     self.assertEqual(version.channel, BrowserVersionChannel.STABLE)
@@ -276,6 +277,22 @@ class _BrowserVersionTestCase(unittest.TestCase, metaclass=abc.ABCMeta):
     self.assertTrue(version_beta.contains(version_beta))
     self.assertTrue(version_stable.contains(version_stable))
 
+  def test_with_channel(self):
+    version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
+    self.assertEqual(version.channel, BrowserVersionChannel.STABLE)
+    stable_copy = version.with_channel(BrowserVersionChannel.STABLE)
+    self.assertIs(version, stable_copy)
+
+    alpha_copy = version.with_channel(BrowserVersionChannel.ALPHA)
+    self.assertEqual(alpha_copy.channel, BrowserVersionChannel.ALPHA)
+    self.assertEqual(alpha_copy.parts, version.parts)
+    self.assertEqual(alpha_copy.version_str, version.version_str)
+
+    any_copy = version.with_channel(BrowserVersionChannel.ANY)
+    self.assertFalse(any_copy.has_channel)
+    self.assertEqual(any_copy.parts, version.parts)
+    self.assertEqual(any_copy.version_str, version.version_str)
+
 
 class ChromiumVersionTestCase(_BrowserVersionTestCase):
   ANY_VERSION_STR = ""
@@ -286,6 +303,7 @@ class ChromiumVersionTestCase(_BrowserVersionTestCase):
   PRE_ALPHA_VERSION_STR = ""
   VERSION_CLS = ChromiumVersion
 
+  @override
   def parse(self, value: str) -> ChromiumVersion:
     return ChromiumVersion.parse(value)
 
@@ -313,7 +331,7 @@ class ChromiumVersionTestCase(_BrowserVersionTestCase):
 
   def test_init_invalid(self):
     with self.assertRaises(BrowserVersionParseError):
-      ChromiumVersion(None)
+      ChromiumVersion(None)  # pytype: disable=wrong-arg-types
     with self.assertRaises(BrowserVersionParseError):
       ChromiumVersion((-1, -2))
 
@@ -396,6 +414,54 @@ class ChromiumVersionTestCase(_BrowserVersionTestCase):
     with self.assertRaises(PartialBrowserVersionError):
       _ = version.patch
 
+  def test_compare_others_eq(self):
+    chromium_version = ChromiumVersion.parse("Chromium 125.1.6416.3")
+    chrome_version = ChromeVersion.parse("Google Chrome 125.1.6416.3")
+    self.assertFalse(chromium_version < chrome_version)
+    self.assertTrue(chromium_version <= chrome_version)
+    self.assertFalse(chrome_version < chromium_version)
+    self.assertTrue(chrome_version <= chromium_version)
+    self.assertEqual(chrome_version, chromium_version)
+
+  def test_compare_others_lt(self):
+    chromium_version = ChromiumVersion.parse("Chromium 100.1.6416.3")
+    chrome_version = ChromeVersion.parse("Google Chrome 125.1.6416.3")
+    self.assertTrue(chromium_version < chrome_version)
+    self.assertTrue(chromium_version <= chrome_version)
+    self.assertFalse(chrome_version < chromium_version)
+    self.assertFalse(chrome_version <= chromium_version)
+    self.assertFalse(chrome_version == chromium_version)
+
+  def test_compare_others_lt_any_channel(self):
+    chromium_version = ChromiumVersion.parse("Chromium 100.1.6416.3 Any")
+    chrome_version = ChromeVersion.parse("Google Chrome 125.1.6416.3 stable")
+    self.assertFalse(chromium_version.has_channel)
+    self.assertTrue(chrome_version.has_channel)
+    self.assertTrue(chromium_version < chrome_version)
+    self.assertTrue(chromium_version <= chrome_version)
+    self.assertFalse(chrome_version < chromium_version)
+    self.assertFalse(chrome_version <= chromium_version)
+    self.assertFalse(chrome_version == chromium_version)
+    # Reverse any / stable:
+    chromium_version = ChromiumVersion.parse("Chromium 100.1.6416.3 stable")
+    chrome_version = ChromeVersion.parse("Google Chrome 125.1.6416.3 Any")
+    self.assertTrue(chromium_version.has_channel)
+    self.assertFalse(chrome_version.has_channel)
+    self.assertTrue(chromium_version < chrome_version)
+    self.assertTrue(chromium_version <= chrome_version)
+    self.assertFalse(chrome_version < chromium_version)
+    self.assertFalse(chrome_version <= chromium_version)
+    self.assertFalse(chrome_version == chromium_version)
+
+  def test_compare_others_incompatible(self):
+    chromium_version = ChromiumVersion.parse("Chromium 125.1.6416.3")
+    safari_version = SafariVersion.parse(
+        SafariBrowserVersionTestCase.STABLE_VERSION_STR)
+    with self.assertRaisesRegex(TypeError, "SafariVersion"):
+      _ = chromium_version < safari_version
+    with self.assertRaisesRegex(TypeError, "SafariVersion"):
+      _ = safari_version < chromium_version
+
 
 class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
   ANY_VERSION_STR = "Google Chrome 115.0.5790.114 Any"
@@ -406,6 +472,7 @@ class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
   PRE_ALPHA_VERSION_STR = "Google Chrome 117.0.5921.0 canary"
   VERSION_CLS = ChromeVersion
 
+  @override
   def parse(self, value: str) -> ChromeVersion:
     return ChromeVersion.parse(value)
 
@@ -420,14 +487,8 @@ class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
       self.parse("Chrome ")
     with self.assertRaises(BrowserVersionParseError):
       self.parse("Chrome 121 121")
-    with self.assertRaises(BrowserVersionParseError):
-      self.parse("Chromium 115.1.5790.114")
-    with self.assertRaises(BrowserVersionParseError):
-      self.parse("Chromium 115")
     with self.assertRaises(BrowserVersionParseError):
       self.parse("Chromium X.X.X.X")
-    with self.assertRaises(BrowserVersionParseError):
-      self.parse("Chromium M115")
     with self.assertRaises(BrowserVersionParseError):
       self.parse("M1")
     with self.assertRaises(BrowserVersionParseError):
@@ -464,6 +525,17 @@ class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
         self.parse("Google Chrome 115.0.5790.114"),
         self.parse("chrome m115.0.5790.114"))
 
+  def test_parse_chromium_prefix(self):
+    self.assertEqual(
+        self.parse("Chromium 115.1.5790.114"),
+        self.parse("Chrome 115.1.5790.114"))
+    self.assertEqual(
+        self.parse("Chromium 115"),
+        self.parse("Chrome 115"))
+    self.assertEqual(
+        self.parse("Chromium M115"),
+        self.parse("Chrome M115"))
+
   def test_parse_channel(self):
     self.assertEqual(
         self.parse(self.BETA_VERSION_STR),
@@ -512,6 +584,11 @@ class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
     beta_version = ChromeVersion.beta(version.parts)
     self.assertEqual(beta_version, version)
 
+  def test_parse_beta_chrome_alternative(self):
+    version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
+    alternative = self._parse_helper("Google Chrome Beta 116.0.5845.50")
+    self.assertEqual(alternative, version)
+
   def test_parse_alpha_chrome(self):
     version: BrowserVersion = self._parse_helper(self.ALPHA_VERSION_STR)
     self.assertEqual(version.major, 117)
@@ -524,6 +601,13 @@ class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
     self.assertFalse(chrome_version.is_canary)
     alpha_version = ChromeVersion.alpha(version.parts)
     self.assertEqual(alpha_version, version)
+    dev_version = ChromeVersion.dev(version.parts)
+    self.assertEqual(dev_version, version)
+
+  def test_parse_alpha_chrome_alternative(self):
+    version: BrowserVersion = self._parse_helper(self.ALPHA_VERSION_STR)
+    alternative = self._parse_helper("Google Chrome Dev 117.0.5911.2")
+    self.assertEqual(alternative, version)
 
   def test_parse_pre_alpha_chrome(self):
     version: BrowserVersion = self._parse_helper(self.PRE_ALPHA_VERSION_STR)
@@ -537,6 +621,13 @@ class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
     self.assertTrue(chrome_version.is_canary)
     pre_alpha_version = ChromeVersion.pre_alpha(version.parts)
     self.assertEqual(pre_alpha_version, version)
+    canary_version = ChromeVersion.canary(version.parts)
+    self.assertEqual(canary_version, version)
+
+  def test_parse_pre_alpha_chrome_alternative(self):
+    version: BrowserVersion = self._parse_helper(self.PRE_ALPHA_VERSION_STR)
+    alternative = self._parse_helper("Google Chrome Canary 117.0.5921.0")
+    self.assertEqual(alternative, version)
 
   def test_parse_partial_milestone(self):
     version = self.parse("Chrome 125")
@@ -717,6 +808,15 @@ class ChromeBrowserVersionTestCase(_BrowserVersionTestCase):
     self.assertFalse(milestone_125_beta.contains(channel_beta))
 
 
+class ChromeForTestingBrowserVersionTestCase(ChromeBrowserVersionTestCase):
+  ANY_VERSION_STR = "Google Chrome for Testing 115.0.5790.114 Any"
+  LTS_VERSION_STR = ""
+  STABLE_VERSION_STR = "Google Chrome for Testing 115.0.5790.114"
+  BETA_VERSION_STR = "Google Chrome for Testing 116.0.5845.50 beta"
+  ALPHA_VERSION_STR = "Google Chrome for Testing 117.0.5911.2 dev"
+  PRE_ALPHA_VERSION_STR = "Google Chrome for Testing 117.0.5921.0 canary"
+
+
 class ChromeDriverBrowserVersionTestCase(_BrowserVersionTestCase):
   ANY_VERSION_STR = ""
   LTS_VERSION_STR = ""
@@ -730,6 +830,17 @@ class ChromeDriverBrowserVersionTestCase(_BrowserVersionTestCase):
                            "0000000000000000000000000000000000000000)")
   VERSION_CLS = ChromeDriverVersion
 
+  @override
+  def parse(self, value: str) -> BrowserVersion:
+    return ChromeDriverVersion.parse(value)
+
+
+class MicrosoftEdgeWebdriverVersionTestCase(_BrowserVersionTestCase):
+  STABLE_VERSION_STR = ("Microsoft Edge WebDriver 131.0.2903.112"
+                        "(16ab910a6e75f1c7d2da060bbe9ac569dfe64f70)")
+  VERSION_CLS = ChromeDriverVersion
+
+  @override
   def parse(self, value: str) -> BrowserVersion:
     return ChromeDriverVersion.parse(value)
 
@@ -739,12 +850,13 @@ class FirefoxVersionTestCase(_BrowserVersionTestCase):
   LTS_VERSION_STR = "Mozilla Firefox 114.0.1esr"
   STABLE_VERSION_STR = "Mozilla Firefox 115.0.3"
   # IRL Firefox version numbers do not distinct beta from stable. so we
-  # remap Firefox Dev => beta.
+  # remap Firefox Developer Edition => beta channel.
   BETA_VERSION_STR = "Mozilla Firefox 116.0b4"
   ALPHA_VERSION_STR = "Mozilla Firefox 117.0a1"
   PRE_ALPHA_VERSION_STR = ""
   VERSION_CLS = FirefoxVersion
 
+  @override
   def parse(self, value: str) -> BrowserVersion:
     return FirefoxVersion.parse(value)
 
@@ -786,18 +898,43 @@ class FirefoxVersionTestCase(_BrowserVersionTestCase):
     self.assertEqual(version.minor, 0)
     self.assertEqual(version.channel_name, "stable")
 
+  def test_parse_stable_alternatives(self):
+    version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
+    for version_str in ("Firefox 115.0.3",):
+      alternative = self._parse_helper(version_str)
+      self.assertEqual(version, alternative)
+
   def test_parse_beta_firefox(self):
     version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
     self.assertEqual(version.major, 116)
     self.assertEqual(version.minor, 0)
     self.assertEqual(version.channel_name, "dev")
 
+  def test_parse_beta_alternatives(self):
+    version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
+    self.assertEqual(
+        version,
+        self._parse_helper("Mozilla Firefox Developer Edition 116.0b4",))
+    self.assertEqual(version,
+                     self._parse_helper("Firefox Developer Edition 116.0b4"))
+    # Some developer versions on mac don't have 3-part version numbers.
+    alternative = self._parse_helper("Firefox Developer Edition 116.0")
+    self.assertTrue(alternative.is_beta)
+    self.assertEqual(alternative.parts, (116, 0, 0))
+
   def test_parse_alpha_firefox(self):
     version: BrowserVersion = self._parse_helper(self.ALPHA_VERSION_STR)
     self.assertEqual(version.major, 117)
     self.assertEqual(version.minor, 0)
     self.assertEqual(version.channel_name, "nightly")
 
+  def test_parse_alpha_alternatives(self):
+    version: BrowserVersion = self._parse_helper(self.ALPHA_VERSION_STR)
+    for version_str in ("Mozilla Firefox Nightly 117.0a1",
+                        "Firefox Nightly 117.0a1"):
+      alternative = self._parse_helper(version_str)
+      self.assertEqual(version, alternative)
+
   def test_str(self):
     self.assertEqual(str(self.parse(self.LTS_VERSION_STR)), "114.0.1 esr")
     self.assertEqual(str(self.parse(self.STABLE_VERSION_STR)), "115.0.3 stable")
@@ -816,6 +953,7 @@ class SafariBrowserVersionTestCase(_BrowserVersionTestCase):
   PRE_ALPHA_VERSION_STR = ""
   VERSION_CLS = SafariVersion
 
+  @override
   def parse(self, value: str) -> BrowserVersion:
     return SafariVersion.parse(value)
 
@@ -830,6 +968,8 @@ class SafariBrowserVersionTestCase(_BrowserVersionTestCase):
       self.parse("16.6 XXX (18615.3...12.11.2)")
     with self.assertRaises(BrowserVersionParseError):
       self.parse("16.6 XXX (18615.3)")
+    with self.assertRaises(BrowserVersionParseError):
+      self.parse("Safari 16.6 XXX (18615.3)")
 
   def test_parse_stable_safari(self):
     version: BrowserVersion = self._parse_helper(self.STABLE_VERSION_STR)
@@ -840,6 +980,12 @@ class SafariBrowserVersionTestCase(_BrowserVersionTestCase):
     self.assertEqual(safari_version.release, 0)
     self.assertEqual(version.channel_name, "stable")
 
+  def test_parse_stable_alternative(self):
+    version: BrowserVersion = self._parse_helper("Safari 18.1.1")
+    self.assertTrue(version.is_stable)
+    self.assertEqual(version.parts, (18, 1, 1, 0))
+    self.assertTrue(version.is_complete)
+
   def test_parse_beta_safari(self):
     version: BrowserVersion = self._parse_helper(self.BETA_VERSION_STR)
     self.assertEqual(version.major, 17)
@@ -849,6 +995,26 @@ class SafariBrowserVersionTestCase(_BrowserVersionTestCase):
     self.assertEqual(safari_version.release, 175)
     self.assertEqual(version.channel_name, "technology preview")
 
+  def test_parse_beta_alternative(self):
+    version: BrowserVersion = self._parse_helper(
+        "Safari Technology Preview 20621.1.6")
+    self.assertTrue(version.is_beta)
+    self.assertEqual(version.parts, (20621, 1, 6, 0))
+    self.assertTrue(version.is_complete)
+
+  def test_parse_with_driver_version(self):
+    version = self._parse_helper(
+        "Safari 18.1.1 Included with Safari 18.1.1 (20619.2.8.11.12)")
+    self.assertTrue(version.is_stable)
+    self.assertEqual(version.major, 18)
+    self.assertEqual(version.parts, (18, 1, 1, 0, 20619, 2, 8, 11, 12))
+    version = self._parse_helper(
+        "Safari 18.2 "
+        "Included with Safari Technology Preview (Release 209, 20621.1.6)")
+    self.assertTrue(version.is_beta)
+    self.assertEqual(version.major, 18)
+    self.assertEqual(version.parts, (18, 2, 0, 209, 20621, 1, 6))
+
   def test_str(self):
     self.assertEqual(
         str(self.parse(self.STABLE_VERSION_STR)),
@@ -860,6 +1026,7 @@ class SafariBrowserVersionTestCase(_BrowserVersionTestCase):
 
 class BrowserVersionTestCase(unittest.TestCase):
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.sf_version = SafariVersion.parse(
diff --git a/tests/crossbench/cli/config/base.py b/tests/crossbench/cli/config/base.py
index ce17d6f9..6eaa12f9 100644
--- a/tests/crossbench/cli/config/base.py
+++ b/tests/crossbench/cli/config/base.py
@@ -4,16 +4,15 @@
 
 from __future__ import annotations
 
-from typing import Type
 from unittest import mock
 
-from tests.crossbench import mock_browser
-from tests.crossbench.base import BaseCrossbenchTestCase
+from typing_extensions import override
 
 from crossbench import path as pth
-from crossbench.cli.config.browser_variants import BrowserVariantsConfig
+from tests.crossbench.base import BaseCrossbenchTestCase
+from tests.crossbench.mock_helper import ShResult
 
-XCTRACE_DEVICES_OUTPUT = """
+XCTRACE_DEVICES_OUTPUT = ShResult("""
 == Devices ==
 a-macbookpro3 (00001234-AAAA-BBBB-0000-11AA22BB33DD)
 An iPhone (17.1.2) (00001111-11AA22BB33DD)
@@ -25,8 +24,9 @@ An iPhone Pro Max (17.1.0) (00003333-11AA22BB33DD)
 == Simulators ==
 iPad (10th generation) (17.0.1) (00001234-AAAA-BBBB-1111-11AA22BB33DD)
 iPad (9th generation) Simulator (15.5) (00001234-AAAA-BBBB-2222-11AA22BB33DD
-"""
-XCTRACE_DEVICES_SINGLE_OUTPUT = """
+""")
+
+XCTRACE_DEVICES_SINGLE_OUTPUT = ShResult("""
 == Devices ==
 a-macbookpro3 (00001234-AAAA-BBBB-0000-11AA22BB33DD)
 An iPhone (17.1.2) (00001111-11AA22BB33DD)
@@ -37,15 +37,17 @@ An iPhone Pro (17.1.1) (00002222-11AA22BB33DD)
 == Simulators ==
 iPad (10th generation) (17.0.1) (00001234-AAAA-BBBB-1111-11AA22BB33DD)
 iPad (9th generation) Simulator (15.5) (00001234-AAAA-BBBB-2222-11AA22BB33DD
-"""
+""")
 
-ADB_DEVICES_SINGLE_OUTPUT = (
+ADB_DEVICES_SINGLE_OUTPUT_RESULT = (
     "List of devices attached\n"
     "emulator-5556 device product:sdk_google_phone_x86_64 "
     "model:Android_SDK_built_for_x86_64 device:generic_x86_64\n")
 
-ADB_DEVICES_OUTPUT = (
-    f"{ADB_DEVICES_SINGLE_OUTPUT}"
+ADB_DEVICES_SINGLE_OUTPUT = ShResult(ADB_DEVICES_SINGLE_OUTPUT_RESULT)
+
+ADB_DEVICES_OUTPUT = ShResult(
+    f"{ADB_DEVICES_SINGLE_OUTPUT_RESULT}"
     "emulator-5554 device product:sdk_google_phone_x86 "
     "model:Android_SDK_built_for_x86 device:generic_x86\n"
     "0a388e93      device usb:1-1 product:razor model:Nexus_7 device:flo\n")
@@ -53,6 +55,7 @@ ADB_DEVICES_OUTPUT = (
 
 class BaseConfigTestCase(BaseCrossbenchTestCase):
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     adb_patcher = mock.patch(
@@ -60,7 +63,3 @@ class BaseConfigTestCase(BaseCrossbenchTestCase):
         return_value=pth.LocalPath("adb"))
     adb_patcher.start()
     self.addCleanup(adb_patcher.stop)
-
-  def mock_chrome_stable(self, browser_cls: Type[mock_browser.MockBrowser]):
-    return mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls)
diff --git a/tests/crossbench/cli/config/test_browser.py b/tests/crossbench/cli/config/test_browser.py
index fd9d0041..bb64e3f5 100644
--- a/tests/crossbench/cli/config/test_browser.py
+++ b/tests/crossbench/cli/config/test_browser.py
@@ -13,9 +13,13 @@ from immutabledict import immutabledict
 from crossbench import path as pth
 from crossbench import plt
 from crossbench.browsers.chrome.chrome import Chrome
-from crossbench.cli.config.browser import BrowserConfig
-from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
-from crossbench.cli.config.network import NetworkConfig, NetworkSpeedPreset
+from crossbench.cli.config.browser import (ENV_PRESETS, NETWORK_PRESETS,
+                                           BrowserConfig)
+from crossbench.cli.config.driver import DriverConfig
+from crossbench.cli.config.driver_type import BrowserDriverType
+from crossbench.cli.config.env import ENV_CONFIG_PRESETS
+from crossbench.cli.config.network import NetworkConfig
+from crossbench.cli.config.network_speed import NetworkSpeedPreset
 from crossbench.exception import MultiException
 from crossbench.types import JsonDict
 from tests import test_helper
@@ -29,6 +33,13 @@ from tests.crossbench.cli.config.base import (ADB_DEVICES_OUTPUT,
 
 class BrowserConfigTestCase(BaseConfigTestCase):
 
+  def test_preset_no_overlap(self):
+    # make sure we have unique names between the two preset names so we
+    # can have simple short version browser specs
+    network_preset_names = NETWORK_PRESETS.split("|")
+    env_preset_names = ENV_PRESETS.split("|")
+    self.assertFalse(set(network_preset_names).intersection(env_preset_names))
+
   def test_equal(self):
     path = Chrome.stable_path(self.platform)
     self.assertEqual(
@@ -134,6 +145,36 @@ class BrowserConfigTestCase(BaseConfigTestCase):
             DriverConfig(BrowserDriverType.WEB_DRIVER),
             NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G)))
 
+  def test_parse_simple_with_driver_with_env(self):
+    self.assertEqual(
+        BrowserConfig.parse("chrome:battery"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER),
+            env=ENV_CONFIG_PRESETS["battery"]))
+    self.assertEqual(
+        BrowserConfig.parse("selenium:chrome:battery"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER),
+            env=ENV_CONFIG_PRESETS["battery"]))
+
+  def test_parse_simple_with_driver_with_network_and_env(self):
+    self.assertEqual(
+        BrowserConfig.parse("chrome:4G:battery"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER),
+            NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G),
+            ENV_CONFIG_PRESETS["battery"]))
+    self.assertEqual(
+        BrowserConfig.parse("selenium:chrome:4G:battery"),
+        BrowserConfig(
+            Chrome.stable_path(self.platform),
+            DriverConfig(BrowserDriverType.WEB_DRIVER),
+            NetworkConfig.parse_live(NetworkSpeedPreset.MOBILE_4G),
+            ENV_CONFIG_PRESETS["battery"]))
+
   def test_parse_simple_ambiguous_with_driver_ios(self):
     self.platform.sh_results = [XCTRACE_DEVICES_OUTPUT]
     with self.assertRaises(argparse.ArgumentTypeError) as cm:
diff --git a/tests/crossbench/cli/config/test_browser_variants.py b/tests/crossbench/cli/config/test_browser_variants.py
index f5d62a1c..c3e24e4a 100644
--- a/tests/crossbench/cli/config/test_browser_variants.py
+++ b/tests/crossbench/cli/config/test_browser_variants.py
@@ -5,23 +5,22 @@
 from __future__ import annotations
 
 import argparse
+import contextlib
 import copy
 import json
 import unittest
-from typing import Dict, Tuple, Type
+from typing import Dict, Optional, Tuple, Type
 from unittest import mock
 
 import hjson
-from tests import test_helper
-from tests.crossbench import mock_browser
-from tests.crossbench.cli.config.base import (ADB_DEVICES_SINGLE_OUTPUT,
-                                              BaseConfigTestCase)
-from tests.crossbench.mock_helper import AndroidAdbMockPlatform, MockAdb
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench import plt
+from crossbench.browsers.browser import Browser
 from crossbench.browsers.chrome.applescript import ChromeAppleScript
 from crossbench.browsers.chrome.chrome import Chrome
+from crossbench.browsers.chrome.version import ChromeVersion
 from crossbench.browsers.chrome.webdriver import (ChromeWebDriver,
                                                   ChromeWebDriverAndroid,
                                                   ChromeWebDriverChromeOsSsh,
@@ -33,10 +32,19 @@ from crossbench.browsers.chromium.webdriver import (ChromiumWebDriver,
                                                     ChromiumWebDriverSsh)
 from crossbench.browsers.safari.safari import Safari
 from crossbench.cli.config.browser import BrowserConfig
-from crossbench.cli.config.browser_variants import BrowserVariantsConfig
-from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
+from crossbench.cli.config.browser_variants import (BaseBrowserVariantsConfig,
+                                                    BrowserVariantsConfig,
+                                                    BrowserVariantsConfigDict)
+from crossbench.cli.config.driver import DriverConfig
+from crossbench.cli.config.driver_type import BrowserDriverType
 from crossbench.cli.config.network import NetworkConfig
 from crossbench.config import ConfigError
+from crossbench.helper.cwd import ChangeCWD
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.cli.config.base import (ADB_DEVICES_SINGLE_OUTPUT,
+                                              BaseConfigTestCase)
+from tests.crossbench.mock_helper import AndroidAdbMockPlatform, MockAdb
 
 
 class TestBrowserVariantsConfig(BaseConfigTestCase):
@@ -47,6 +55,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
   EXAMPLE_REMOTE_CONFIG_PATH = (
       test_helper.config_dir() / "doc/remote_browser.config.hjson")
 
+  @override
   def setUp(self):
     super().setUp()
     self.browser_lookup: Dict[str, Tuple[
@@ -67,6 +76,16 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     for _, (_, browser_config) in self.browser_lookup.items():
       self.assertTrue(browser_config.path.exists())
 
+  @contextlib.contextmanager
+  def _patch_get_browser_cls(self,
+                             return_value: Optional[Type[Browser]] = None,
+                             **kwargs):
+    if not kwargs:
+      kwargs["return_value"] = return_value or mock_browser.MockChromeStable
+    with mock.patch.object(BaseBrowserVariantsConfig, "get_browser_cls",
+                           **kwargs):
+      yield
+
   def _expect_linux_ssh(self, cmd, **kwargs):
     return self.platform.expect_sh("ssh", "-p", "22", "user@my-linux-machine",
                                    cmd, **kwargs)
@@ -88,47 +107,109 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     self.assertGreaterEqual(len(config.flags_config), 1)
     self.assertGreaterEqual(len(config.variants), 1)
 
-  def test_parse_remote_browser_config_template(self):
-    if not self.EXAMPLE_REMOTE_CONFIG_PATH.exists():
-      raise unittest.SkipTest(
-          f"Test file {self.EXAMPLE_REMOTE_CONFIG_PATH} does not exist")
-    self.fs.add_real_file(self.EXAMPLE_REMOTE_CONFIG_PATH)
-
+  def _expect_sh_linux_ssh_browser_config(self):
     self._expect_linux_ssh("uname -m", result="arm64")
+
+  def _expect_sh_linux_ssh_browser_instance(self):
     self._expect_linux_ssh("'[' -e /path/to/google/chrome ']'")
     self._expect_linux_ssh("'[' -f /path/to/google/chrome ']'")
     self._expect_linux_ssh("'[' -e /path/to/google/chrome ']'")
     self._expect_linux_ssh(
         "/path/to/google/chrome --version", result="102.22.33.44")
-    self._expect_linux_ssh("env")
-    self._expect_linux_ssh("'[' -d /tmp ']'")
-    self._expect_linux_ssh("mktemp -d /tmp/chrome.XXXXXXXXXXX")
 
+  def _expect_sh_chromeos_ssh_browser_config(self):
     self._expect_chromeos_ssh("'[' -e /usr/local/autotest/bin/autologin.py ']'")
     self._expect_chromeos_ssh("uname -m", result="arm64")
+
+  def _expect_sh_chromeos_ssh_browser_instance(self):
     self._expect_chromeos_ssh("'[' -e /opt/google/chrome/chrome ']'")
     self._expect_chromeos_ssh("'[' -f /opt/google/chrome/chrome ']'")
     self._expect_chromeos_ssh("'[' -e /opt/google/chrome/chrome ']'")
     self._expect_chromeos_ssh(
         "/opt/google/chrome/chrome --version", result="125.0.6422.60")
-    self._expect_chromeos_ssh("env")
-    self._expect_chromeos_ssh("'[' -d /tmp ']'")
-    self._expect_chromeos_ssh("mktemp -d /tmp/chrome.XXXXXXXXXXX")
+
+  def test_parse_remote_browser_config_template(self):
+    self.fs.add_real_file(self.EXAMPLE_REMOTE_CONFIG_PATH)
+
+    self._expect_sh_linux_ssh_browser_config()
+    self._expect_sh_linux_ssh_browser_config()
+    self._expect_sh_chromeos_ssh_browser_config()
+    self._expect_sh_chromeos_ssh_browser_config()
+
+    self._expect_sh_linux_ssh_browser_instance()
+    self._expect_sh_linux_ssh_browser_instance()
+    self._expect_sh_chromeos_ssh_browser_instance()
+    self._expect_sh_chromeos_ssh_browser_instance()
 
     with self.EXAMPLE_REMOTE_CONFIG_PATH.open(encoding="utf-8") as f:
-      config = BrowserVariantsConfig()
+      config = BrowserVariantsConfigDict()
       config.parse_text_io(f, args=self.mock_args)
-      self.assertEqual(len(config.variants), 2)
-      for variant in config.variants:
+      browsers = config.browsers
+      self.assertEqual(len(browsers), 4)
+      for variant in browsers:
         self.assertTrue(variant.platform.is_remote)
         self.assertTrue(variant.platform.is_linux)
-      self.assertEqual(config.variants[0].platform.name, "linux_ssh")
-      self.assertEqual(config.variants[1].platform.name, "chromeos_ssh")
-      self.assertEqual(config.variants[0].version, "102.22.33.44")
-      self.assertEqual(config.variants[1].version, "125.0.6422.60")
+
+      self.assertIsNone(browsers[0].driver_path)
+      self.assertEqual(str(browsers[1].driver_path), "/path/to/chromedriver")
+      self.assertIsNone(browsers[2].driver_path)
+      self.assertEqual(str(browsers[3].driver_path), "/path/to/chromedriver")
+
+      self.assertEqual(browsers[0].platform.name, "linux_ssh")
+      self.assertEqual(browsers[1].platform.name, "linux_ssh")
+      self.assertEqual(browsers[2].platform.name, "chromeos_ssh")
+      self.assertEqual(browsers[3].platform.name, "chromeos_ssh")
+      self.assertEqual(browsers[0].version.parts_str, "102.22.33.44")
+      self.assertEqual(browsers[1].version.parts_str, "102.22.33.44")
+      self.assertEqual(browsers[2].version.parts_str, "125.0.6422.60")
+      self.assertEqual(browsers[3].version.parts_str, "125.0.6422.60")
+
+  def test_parse_remote_browser_config_template_override_driver_path(self):
+    override_driver_path = pth.AnyPosixPath("/path/to/override/chromedriver")
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=None,
+        driver_path=None,
+        remote_driver_path=override_driver_path)
+    config = BrowserVariantsConfigDict()
+
+    self._expect_sh_linux_ssh_browser_config()
+    self._expect_sh_linux_ssh_browser_config()
+    config_dict = {
+        "browsers": {
+            "linux-ssh-chrome-auto-start-driver": {
+                "path": "/path/to/google/chrome",
+                "driver": {
+                    "type": "ssh",
+                    "path": "/path/to/chromedriver",
+                    "settings": {
+                        "host": "my-linux-machine",
+                        "ssh_port": 22,
+                        "ssh_user": "user"
+                    }
+                }
+            },
+            "linux-ssh-chrome-auto-start-driver-no-path": {
+                "path": "/path/to/google/chrome",
+                "driver": {
+                    "type": "ssh",
+                    "settings": {
+                        "host": "my-linux-machine",
+                        "ssh_port": 22,
+                        "ssh_user": "user"
+                    }
+                }
+            },
+        }
+    }
+    config.parse_dict(config_dict, args)
+    variants = config.variants
+    self.assertEqual(len(variants), 2)
+    self.assertEqual(variants[0].settings.driver_path, override_driver_path)
+    self.assertEqual(variants[1].settings.driver_path, override_driver_path)
 
   def test_browser_labels_attributes(self):
-    browsers = BrowserVariantsConfig(
+    browsers = BrowserVariantsConfigDict(
         {
             "browsers": {
                 "chrome-stable-default": {
@@ -174,20 +255,18 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         return mock_browser.MockChromeStable
       raise ValueError("Unknown browser_config")
 
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
+    with self._patch_get_browser_cls(
         side_effect=mock_get_browser_cls), mock.patch(
             "crossbench.plt.android_adb.AndroidAdbPlatform.machine",
             new_callable=mock.PropertyMock,
             return_value=plt.MachineArch.ARM_64):
-      browsers = BrowserVariantsConfig.from_cli_args(args).variants
-    self.assertEqual(len(browsers), 2)
-    self.assertEqual(browsers[0].label, "android.arm64.remote_0")
-    self.assertEqual(browsers[1].label, f"{self.platform}_1")
+      variants = BrowserVariantsConfig.from_cli_args(args).variants
+    self.assertEqual(len(variants), 2)
+    self.assertEqual(variants[0].label, "android.arm64.remote_0")
+    self.assertEqual(variants[1].label, f"{self.platform}_1")
 
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "browsers": {
                   "chrome-stable-label": {
@@ -208,7 +287,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
   def test_parse_invalid_browser_type(self):
     for invalid in (None, 1, []):
       with self.assertRaises(ConfigError) as cm:
-        _ = BrowserVariantsConfig(
+        _ = BrowserVariantsConfigDict(
             {
                 "browsers": {
                     "chrome-stable-default": invalid
@@ -229,12 +308,12 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         return AndroidAdbMockPlatform(self.platform, adb=MockAdb(self.platform))
       return self.platform
 
-    with self.mock_chrome_stable(
+    with self._patch_get_browser_cls(
         mock_browser.MockChromeAndroidStable), mock.patch.object(
-            BrowserVariantsConfig,
+            BaseBrowserVariantsConfig,
             "_get_browser_platform",
             side_effect=mock_get_browser_platform):
-      browsers = BrowserVariantsConfig(
+      variants_config = BrowserVariantsConfigDict(
           {
               "browsers": {
                   "chrome-stable-default": "chrome-stable",
@@ -246,18 +325,21 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
               }
           },
           browser_lookup_override=self.browser_lookup,
-          args=self.mock_args).variants
-    self.assertEqual(len(browsers), 3)
-    self.assertEqual(browsers[0].label, "chrome-stable-default")
-    self.assertEqual(browsers[1].label, "chrome-stable-adb")
-    self.assertEqual(browsers[2].label, "chrome-stable-adb2")
-    self.assertIsInstance(browsers[0], mock_browser.MockChromeStable)
-    self.assertIsInstance(browsers[1], mock_browser.MockChromeAndroidStable)
-    self.assertIsInstance(browsers[2], mock_browser.MockChromeAndroidStable)
+          args=self.mock_args)
+      variants = variants_config.variants
+    self.assertEqual(len(variants), 3)
+    self.assertEqual(variants[0].label, "chrome-stable-default")
+    self.assertEqual(variants[1].label, "chrome-stable-adb")
+    self.assertEqual(variants[2].label, "chrome-stable-adb2")
+    self.assertEqual(variants[0].browser_cls, mock_browser.MockChromeStable)
+    self.assertEqual(variants[1].browser_cls,
+                     mock_browser.MockChromeAndroidStable)
+    self.assertEqual(variants[2].browser_cls,
+                     mock_browser.MockChromeAndroidStable)
 
   def test_flag_combination_invalid(self):
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {
@@ -279,7 +361,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
 
   def test_flag_combination_none(self):
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {
@@ -299,7 +381,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
 
   def test_flag_combination_duplicate(self):
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {
@@ -322,13 +404,13 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
 
   def test_empty(self):
     with self.assertRaises(ConfigError):
-      BrowserVariantsConfig({"other": {}}, args=self.mock_args).variants
+      BrowserVariantsConfigDict({"other": {}}, args=self.mock_args).variants
     with self.assertRaises(ConfigError):
-      BrowserVariantsConfig({"browsers": {}}, args=self.mock_args).variants
+      BrowserVariantsConfigDict({"browsers": {}}, args=self.mock_args).variants
 
   def test_unknown_group(self):
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "browsers": {
                   "chrome-stable": {
@@ -341,8 +423,8 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     self.assertIn("unknown-flag-group", str(cm.exception))
 
   def test_duplicate_group(self):
-    with self.assertRaises(ConfigError):
-      BrowserVariantsConfig(
+    with self.assertRaisesRegex(ConfigError, "group1"):
+      BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {}
@@ -354,10 +436,10 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
                   }
               }
           },
-          args=self.mock_args).variants
+          args=self.mock_args).browsers
 
   def test_non_list_group(self):
-    BrowserVariantsConfig(
+    BrowserVariantsConfigDict(
         {
             "flags": {
                 "group1": {}
@@ -372,7 +454,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         browser_lookup_override=self.browser_lookup,
         args=self.mock_args).variants
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {}
@@ -390,7 +472,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     self.assertIn("flags", str(cm.exception))
 
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {}
@@ -411,7 +493,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
 
   def test_duplicate_flag_variant_value(self):
     with self.assertRaises(ConfigError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {
@@ -431,7 +513,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
 
   def test_unknown_path(self):
     with self.assertRaises(Exception):
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "browsers": {
                   "chrome-stable": {
@@ -441,7 +523,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
           },
           args=self.mock_args).variants
     with self.assertRaises(Exception):
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           {
               "browsers": {
                   "chrome-stable": {
@@ -452,7 +534,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
           args=self.mock_args).variants
 
   def test_flag_combination_simple(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "group1": {
@@ -471,14 +553,14 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     browsers = config.variants
     self.assertEqual(len(browsers), 3)
     for browser in browsers:
-      assert isinstance(browser, mock_browser.MockChromeStable)
+      self.assertEqual(browser.browser_cls, mock_browser.MockChromeStable)
       self.assertDictEqual(browser.js_flags.to_dict(), {})
     self.assertDictEqual(browsers[0].flags.to_dict(), {})
     self.assertDictEqual(browsers[1].flags.to_dict(), {"--foo": None})
     self.assertDictEqual(browsers[2].flags.to_dict(), {"--foo": "v1"})
 
   def test_flag_list(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "group1": [
@@ -499,14 +581,14 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     browsers = config.variants
     self.assertEqual(len(browsers), 3)
     for browser in browsers:
-      assert isinstance(browser, mock_browser.MockChromeStable)
+      self.assertEqual(browser.browser_cls, mock_browser.MockChromeStable)
       self.assertDictEqual(browser.js_flags.to_dict(), {})
     self.assertDictEqual(browsers[0].flags.to_dict(), {})
     self.assertDictEqual(browsers[1].flags.to_dict(), {"--foo": None})
     self.assertDictEqual(browsers[2].flags.to_dict(), {"-foo": "v1"})
 
   def test_flag_combination(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "group1": {
@@ -526,7 +608,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     self.assertEqual(len(config.variants), 3 * 3)
 
   def test_flag_combination_mixed_inline(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "compile-hints-experiment": {
@@ -550,7 +632,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         list(browsers[1].flags))
 
   def test_flag_single_inline(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "browsers": {
                 "chrome-release": {
@@ -566,7 +648,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     self.assertListEqual(["--no-sandbox"], list(browsers[0].flags))
 
   def test_flag_combination_mixed_fixed(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "compile-hints-experiment": {
@@ -592,7 +674,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
 
   def test_conflicting_chrome_features(self):
     with self.assertRaises(ConfigError) as cm:
-      _ = BrowserVariantsConfig(
+      _ = BrowserVariantsConfigDict(
           {
               "flags": {
                   "compile-hints-experiment": {
@@ -616,7 +698,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     self.assertIn("ConsumeCompileHints", msg)
 
   def test_no_flags(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "browsers": {
                 "chrome-stable": {
@@ -631,13 +713,9 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         args=self.mock_args)
     self.assertEqual(len(config.variants), 2)
     browser_0 = config.variants[0]
-    assert isinstance(browser_0, mock_browser.MockChromeStable)
-    self.assertEqual(browser_0.app_path,
-                     mock_browser.MockChromeStable.mock_app_path())
+    self.assertEqual(browser_0.browser_cls, mock_browser.MockChromeStable)
     browser_1 = config.variants[1]
-    assert isinstance(browser_1, mock_browser.MockChromeDev)
-    self.assertEqual(browser_1.app_path,
-                     mock_browser.MockChromeDev.mock_app_path())
+    self.assertEqual(browser_1.browser_cls, mock_browser.MockChromeDev)
 
   def test_custom_driver(self):
     chromedriver = pth.LocalPath("path/to/chromedriver")
@@ -650,37 +728,33 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         }
     }
     with self.assertRaises(argparse.ArgumentTypeError) as cm:
-      BrowserVariantsConfig(
+      BrowserVariantsConfigDict(
           copy.deepcopy(variants_config),
           browser_lookup_override=self.browser_lookup,
           args=self.mock_args)
     self.assertIn(str(chromedriver), str(cm.exception))
 
     self.fs.create_file(chromedriver, st_size=100)
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
-        return_value=mock_browser.MockChromeStable):
-      config = BrowserVariantsConfig(
+    with self._patch_get_browser_cls(mock_browser.MockChromeStable):
+      config = BrowserVariantsConfigDict(
           variants_config,
           browser_lookup_override=self.browser_lookup,
           args=self.mock_args)
     self.assertTrue(variants_config["browsers"]["chrome-stable"])
     self.assertEqual(len(config.variants), 1)
     browser_0 = config.variants[0]
-    assert isinstance(browser_0, mock_browser.MockChromeStable)
-    self.assertEqual(browser_0.app_path,
-                     mock_browser.MockChromeStable.mock_app_path())
+    self.assertEqual(browser_0.browser_cls, mock_browser.MockChromeStable)
 
   def test_inline_flags(self):
     with mock.patch.object(
-        ChromeWebDriver, "_extract_version",
-        return_value="101.22.333.44"), mock.patch.object(
+        ChromeWebDriver,
+        "_extract_version",
+        return_value=ChromeVersion.parse("101.22.333.44")), mock.patch.object(
             Chrome,
             "stable_path",
             return_value=mock_browser.MockChromeStable.mock_app_path()):
 
-      config = BrowserVariantsConfig(
+      config = BrowserVariantsConfigDict(
           {
               "browsers": {
                   "stable": {
@@ -690,28 +764,29 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
               }
           },
           args=self.mock_args)
-      self.assertEqual(len(config.variants), 1)
-      browser = config.variants[0]
+      browsers = config.browsers
+      self.assertEqual(len(browsers), 1)
+      browser = browsers[0]
       # TODO: Fix once app lookup is cleaned up
       self.assertEqual(browser.app_path,
                        mock_browser.MockChromeStable.mock_app_path())
-      self.assertEqual(browser.version, "101.22.333.44")
+      self.assertEqual(browser.version.parts_str, "101.22.333.44")
       self.assertEqual(browser.flags["--foo"], "bar")
 
   def test_inline_load_safari(self):
     if not plt.PLATFORM.is_macos:
       return
-    with mock.patch.object(Safari, "_extract_version", return_value="16.0"):
-      config = BrowserVariantsConfig(
-          {"browsers": {
-              "safari": {
-                  "path": "safari",
-              }
-          }}, args=self.mock_args)
-      self.assertEqual(len(config.variants), 1)
+    config = BrowserVariantsConfigDict(
+        {"browsers": {
+            "safari": {
+                "path": "safari",
+            }
+        }}, args=self.mock_args)
+    self.assertEqual(len(config.variants), 1)
+    self.assertTrue(issubclass(config.variants[0].browser_cls, Safari))
 
   def test_flag_combination_with_fixed(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "group1": {
@@ -732,10 +807,8 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         browser_lookup_override=self.browser_lookup,
         args=self.mock_args)
     self.assertEqual(len(config.variants), 3 * 3)
-    for browser in config.variants:
-      assert isinstance(browser, mock_browser.MockChromeStable)
-      self.assertEqual(browser.app_path,
-                       mock_browser.MockChromeStable.mock_app_path())
+    for variant in config.variants:
+      self.assertEqual(variant.browser_cls, mock_browser.MockChromeStable)
       expected_flags = (
           "--always_1=true --always_2=true --always_3=true",
           "--bar --always_1=true --always_2=true --always_3=true",
@@ -757,7 +830,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
           f"Unexpected flags for variant[{index}]")
 
   def test_flag_combination_js_flags_with_fixed(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "group1": {
@@ -779,10 +852,8 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         browser_lookup_override=self.browser_lookup,
         args=self.mock_args)
     self.assertEqual(len(config.variants), 3)
-    for browser in config.variants:
-      assert isinstance(browser, mock_browser.MockChromeStable)
-      self.assertEqual(browser.app_path,
-                       mock_browser.MockChromeStable.mock_app_path())
+    for variant in config.variants:
+      self.assertEqual(variant.browser_cls, mock_browser.MockChromeStable)
     expected_flags = (
         "--bar=v1 --foo=w2",
         "--bar=v1 --foo=w2 --js-flags=--max-opt=1,--trace-ic",
@@ -792,7 +863,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
 
   def test_flag_combination_js_flags_combinations_invalid(self):
     with self.assertRaises(ConfigError) as cm:
-      _ = BrowserVariantsConfig(
+      _ = BrowserVariantsConfigDict(
           {
               "flags": {
                   "group1": {
@@ -817,7 +888,7 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     self.assertIn("--js-flags", str(cm.exception))
 
   def test_flag_group_combination(self):
-    config = BrowserVariantsConfig(
+    config = BrowserVariantsConfigDict(
         {
             "flags": {
                 "group1": {
@@ -866,13 +937,11 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     if self.platform.is_win:
       self.skipTest("No auto-download available on windows")
     browser_cls = mock_browser.MockChromeStable
-    # TODO: migrate to with_stem once python 3.9 is available everywhere
-    suffix = browser_cls.mock_app_path().suffix
-    browser_bin = browser_cls.mock_app_path().with_name(
-        f"Custom Google Chrome{suffix}")
+    browser_bin = browser_cls.mock_app_path().with_stem("Custom Google Chrome")
     browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
     config_data = {"browsers": {"chrome-stable": {"path": str(browser_bin),}}}
-    config_file = pth.LocalPath("config.hjson")
+    config_file = pth.LocalPath("config/config.hjson")
+    config_file.parent.mkdir()
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
 
@@ -881,22 +950,25 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         browser=None,
         browser_config=config_file,
         driver_path=None)
-    with mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+    with self._patch_get_browser_cls(browser_cls):
       config = BrowserVariantsConfig.from_cli_args(args)
     self.assertEqual(len(config.variants), 1)
-    browser = config.variants[0]
+    self.assertEqual(config.variants[0].browser_cls, browser_cls)
+    browser = config.browsers[0]
     self.assertIsInstance(browser, browser_cls)
     self.assertEqual(browser.app_path, browser_bin)
 
+  def test_from_cli_args_browser_config_relative_path(self):
+    some_dir = pth.LocalPath("custom/test/dir")
+    some_dir.mkdir(parents=True)
+    with ChangeCWD(some_dir):
+      self.test_from_cli_args_browser_config()
+
   def test_from_cli_args_browser(self):
     if self.platform.is_win:
       self.skipTest("No auto-download available on windows")
     browser_cls = mock_browser.MockChromeStable
-    # TODO: migrate to with_stem once python 3.9 is available everywhere
-    suffix = browser_cls.mock_app_path().suffix
-    browser_bin = browser_cls.mock_app_path().with_name(
-        f"Custom Google Chrome{suffix}")
+    browser_bin = browser_cls.mock_app_path().with_stem("Custom Google Chrome")
     browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
     args = mock.Mock(
         network=NetworkConfig.default(),
@@ -909,11 +981,11 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         driver_path=None,
         js_flags=None,
         other_browser_args=[])
-    with mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+    with self._patch_get_browser_cls(browser_cls):
       config = BrowserVariantsConfig.from_cli_args(args)
-    self.assertEqual(len(config.variants), 1)
-    browser = config.variants[0]
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 1)
+    browser = browsers[0]
     self.assertIsInstance(browser, browser_cls)
     self.assertEqual(browser.app_path, browser_bin)
 
@@ -930,11 +1002,11 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         disable_features="feature_off",
         js_flags=None,
         other_browser_args=["--no-sandbox", "--enable-logging=stderr"])
-    with mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+    with self._patch_get_browser_cls(browser_cls):
       config = BrowserVariantsConfig.from_cli_args(args)
-    self.assertEqual(len(config.variants), 1)
-    browser = config.variants[0]
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 1)
+    browser = browsers[0]
     self.assertIsInstance(browser, browser_cls)
     self.assertFalse(browser.js_flags)
     self.assertEqual(browser.flags["--enable-features"], "feature_on")
@@ -955,11 +1027,11 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         disable_features=None,
         js_flags=["--max-opt=1"],
         other_browser_args=[])
-    with mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+    with self._patch_get_browser_cls(browser_cls):
       config = BrowserVariantsConfig.from_cli_args(args)
-    self.assertEqual(len(config.variants), 1)
-    browser = config.variants[0]
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 1)
+    browser = browsers[0]
     self.assertIsInstance(browser, browser_cls)
     self.assertEqual(browser.js_flags.to_dict(), {"--max-opt": "1"})
 
@@ -976,17 +1048,72 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         disable_features=None,
         js_flags=[],
         other_browser_args=["--js-flags=--max-opt=1,--log-all"])
-    with mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+    with self._patch_get_browser_cls(browser_cls):
       config = BrowserVariantsConfig.from_cli_args(args)
-    self.assertEqual(len(config.variants), 1)
-    browser = config.variants[0]
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 1)
+    browser = browsers[0]
     self.assertIsInstance(browser, browser_cls)
     self.assertEqual(browser.js_flags.to_dict(), {
         "--max-opt": "1",
         "--log-all": None
     })
 
+  def test_from_cli_args_browser_multiple_js_flags_empty_base(self):
+    browser_cls = mock_browser.MockChromeStable
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=[
+            BrowserConfig.parse_str("chrome"),
+        ],
+        browser_config=None,
+        driver_path=None,
+        enable_features="",
+        disable_features="",
+        js_flags=[" ", "--max-opt=2,--log-all"],
+        other_browser_args=[])
+    with self._patch_get_browser_cls(browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 2)
+    browser_0 = browsers[0]
+    self.assertIsInstance(browser_0, browser_cls)
+    self.assertEqual(browser_0.js_flags.to_dict(), {})
+    browser_1 = browsers[1]
+    self.assertIsInstance(browser_1, browser_cls)
+    self.assertEqual(browser_1.js_flags.to_dict(), {
+        "--max-opt": "2",
+        "--log-all": None
+    })
+
+  def test_from_cli_args_browser_multiple_js_flags_empty_base_defaults(self):
+    browser_cls = mock_browser.MockChromeStable
+    args = mock.Mock(
+        network=NetworkConfig.default(),
+        browser=[
+            BrowserConfig.parse_str("chrome"),
+        ],
+        browser_config=None,
+        driver_path=None,
+        enable_features="",
+        disable_features="",
+        js_flags=[" ", "--max-opt=2,--log-all"],
+        other_browser_args=["--js-flags=--no-turbofan"])
+    with self._patch_get_browser_cls(browser_cls):
+      config = BrowserVariantsConfig.from_cli_args(args)
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 2)
+    browser_0 = browsers[0]
+    self.assertIsInstance(browser_0, browser_cls)
+    self.assertEqual(browser_0.js_flags.to_dict(), {"--no-turbofan": None})
+    browser_1 = browsers[1]
+    self.assertIsInstance(browser_1, browser_cls)
+    self.assertEqual(browser_1.js_flags.to_dict(), {
+        "--no-turbofan": None,
+        "--max-opt": "2",
+        "--log-all": None
+    })
+
   def test_from_cli_args_browser_multiple_js_flags(self):
     browser_cls = mock_browser.MockChromeStable
     args = mock.Mock(
@@ -1000,14 +1127,14 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         disable_features="feature_off",
         js_flags=["--max-opt=1", "--max-opt=2,--log-all"],
         other_browser_args=["--no-sandbox", "--enable-logging=stderr"])
-    with mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls", return_value=browser_cls):
+    with self._patch_get_browser_cls(browser_cls):
       config = BrowserVariantsConfig.from_cli_args(args)
-    self.assertEqual(len(config.variants), 2)
-    browser_0 = config.variants[0]
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 2)
+    browser_0 = browsers[0]
     self.assertIsInstance(browser_0, browser_cls)
     self.assertEqual(browser_0.js_flags.to_dict(), {"--max-opt": "1"})
-    browser_1 = config.variants[1]
+    browser_1 = browsers[1]
     self.assertIsInstance(browser_1, browser_cls)
     self.assertEqual(browser_1.js_flags.to_dict(), {
         "--max-opt": "2",
@@ -1020,6 +1147,65 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
       self.assertIn("--no-sandbox", browser.flags)
       self.assertEqual(browser.flags["--enable-logging"], "stderr")
 
+  @unittest.skip("Not yet supported")
+  def test_from_cli_args_browser_config_js_flags(self):
+    browser_config = {
+        "browsers": {
+            "chrome_no_tf": {
+                "flags": ["--js-flags=--no-turbofan"],
+                "path": "chrome"
+            }
+        }
+    }
+    with self.platform.NamedTemporaryFile() as config_file:
+      with config_file.open("w", encoding="utf-8") as f:
+        json.dump(browser_config, f)
+
+      args = mock.Mock(
+          network=NetworkConfig.default(),
+          browser=[],
+          browser_config=config_file,
+          driver_path=None,
+          enable_features=None,
+          disable_features=None,
+          js_flags=["--max-opt=1,--log-al"])
+      with self._patch_get_browser_cls():
+        config = BrowserVariantsConfig.from_cli_args(args)
+
+    self.assertEqual(len(config.variants), 1)
+    browser = config.variants[0]
+    self.assertEqual(browser.js_flags.to_dict(), {
+        "--no-turbofan": None,
+        "--max-opt": "1",
+        "--log-all": None
+    })
+
+  def test_from_cli_args_and_config(self):
+    browser_config = {"browsers": {"chrome_no_tf": {"path": "chrome"}}}
+    chrome_stable = BrowserConfig.parse_str("chrome")
+    chrome_dev = BrowserConfig.parse_str("chrome-dev")
+
+    with self.platform.NamedTemporaryFile() as config_file:
+      with config_file.open("w", encoding="utf-8") as f:
+        json.dump(browser_config, f)
+
+      args = mock.Mock(
+          network=NetworkConfig.default(),
+          browser=[chrome_dev],
+          browser_config=config_file,
+          driver_path=None,
+          enable_features=None,
+          disable_features=None,
+          js_flags=[],
+          other_browser_args=[])
+      config = BrowserVariantsConfig.from_cli_args(args)
+
+    variants = config.variants
+    self.assertEqual(len(variants), 2)
+    self.assertEqual(variants[0].browser_config, chrome_stable)
+    self.assertEqual(variants[1].browser_config, chrome_dev)
+
+
   def test_from_cli_args_browser_config_network_override(self):
     ts_proxy_path = pth.LocalPath("/tsproxy/tsproxy.py")
     self.fs.create_file(ts_proxy_path, st_size=100)
@@ -1052,16 +1238,13 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
         js_flags=None,
         other_browser_args=[])
 
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
-        return_value=mock_browser.MockChromeStable
-    ), mock.patch(
+    with self._patch_get_browser_cls(mock_browser.MockChromeStable), mock.patch(
         "crossbench.network.traffic_shaping.ts_proxy.TsProxyFinder") as finder:
       finder.return_value = mock.Mock(path=ts_proxy_path)
       config = BrowserVariantsConfig.from_cli_args(args,)
-    self.assertEqual(len(config.variants), 3)
-    browser_1, browser_2, browser_3 = config.variants  # pylint: disable=unbalanced-tuple-unpacking
+    browsers = config.browsers
+    self.assertEqual(len(browsers), 3)
+    browser_1, browser_2, browser_3 = browsers  # pylint: disable=unbalanced-tuple-unpacking
     # Browser 1 provides an explicit default override:
     self.assertTrue(browser_1.network.is_live)
     self.assertTrue(browser_1.network.traffic_shaper.is_live)
@@ -1168,6 +1351,105 @@ class TestBrowserVariantsConfig(BaseConfigTestCase):
     config = BrowserConfig(browser=pth.AnyPath("chrome"), driver=driver)
     self.assertIs(variants.get_browser_cls(config), ChromeWebDriverChromeOsSsh)
 
+  def test_cache_dir_empty(self):
+    args = self.mock_args
+    config_data = {
+        "browsers": {
+            "chrome-release": {
+                "path": "chrome-stable",
+                "cache_dir": None
+            }
+        }
+    }
+    self.assertIsNone(args.browser_cache_dir)
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertIsNone(browser.settings.cache_dir)
+
+    args.browser_cache_dir = "/var/tmp/override/cache"
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertEqual(str(browser.settings.cache_dir), "/var/tmp/override/cache")
+
+  def test_cache_dir(self):
+    args = self.mock_args
+    config_data = {
+        "browsers": {
+            "chrome-release": {
+                "path": "chrome-stable",
+                "cache_dir": "foo/bar/cache"
+            }
+        }
+    }
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertEqual(str(browser.settings.cache_dir), "foo/bar/cache")
+    self.assertTrue(browser.settings.clear_cache_dir)
+
+    args.browser_cache_dir = "/var/tmp/override/cache"
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertEqual(str(browser.settings.cache_dir), "/var/tmp/override/cache")
+    self.assertTrue(browser.settings.clear_cache_dir)
+
+  def test_clear_cache_dir(self):
+    args = self.mock_args
+    config_data = {
+        "browsers": {
+            "chrome-release": {
+                "path": "chrome-stable",
+                "cache_dir": "foo/bar/cache",
+                "clear_cache_dir": False,
+            }
+        }
+    }
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertIsNone(args.clear_browser_cache_dir)
+    self.assertEqual(str(browser.settings.cache_dir), "foo/bar/cache")
+    self.assertFalse(browser.settings.clear_cache_dir)
+
+    args.clear_browser_cache_dir = False
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertEqual(str(browser.settings.cache_dir), "foo/bar/cache")
+    self.assertFalse(browser.settings.clear_cache_dir)
+
+    args.clear_browser_cache_dir = True
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertEqual(str(browser.settings.cache_dir), "foo/bar/cache")
+    self.assertTrue(browser.settings.clear_cache_dir)
+
+  def test_clear_cache_dir_override_positive(self):
+    args = self.mock_args
+    config_data = {
+        "browsers": {
+            "chrome-release": {
+                "path": "chrome-stable",
+                "cache_dir": "foo/bar/cache",
+                "clear_cache_dir": True,
+            }
+        }
+    }
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertIsNone(args.clear_browser_cache_dir)
+    self.assertEqual(str(browser.settings.cache_dir), "foo/bar/cache")
+    self.assertTrue(browser.settings.clear_cache_dir)
+
+    args.clear_browser_cache_dir = False
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertEqual(str(browser.settings.cache_dir), "foo/bar/cache")
+    self.assertFalse(browser.settings.clear_cache_dir)
+
+    args.clear_browser_cache_dir = True
+    config = BrowserVariantsConfigDict(config_data, args=args)
+    browser = config.variants[0]
+    self.assertEqual(str(browser.settings.cache_dir), "foo/bar/cache")
+    self.assertTrue(browser.settings.clear_cache_dir)
+
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_driver.py b/tests/crossbench/cli/config/test_driver.py
index 6930feb3..38106888 100644
--- a/tests/crossbench/cli/config/test_driver.py
+++ b/tests/crossbench/cli/config/test_driver.py
@@ -11,7 +11,8 @@ import hjson
 
 from crossbench import plt
 from crossbench.cli.config.driver import (AmbiguousDriverIdentifier,
-                                          BrowserDriverType, DriverConfig)
+                                          DriverConfig)
+from crossbench.cli.config.driver_type import BrowserDriverType
 from crossbench.exception import ArgumentTypeMultiException
 from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
 from tests import test_helper
@@ -20,38 +21,6 @@ from tests.crossbench.cli.config.base import (ADB_DEVICES_OUTPUT,
                                               BaseConfigTestCase)
 
 
-class BrowserDriverTypeTestCase(unittest.TestCase):
-
-  def test_default(self):
-    self.assertEqual(BrowserDriverType.default(), BrowserDriverType.WEB_DRIVER)
-
-  def test_parse_invalid(self):
-    for invalid in ["invalid", None, [], (), {}]:
-      with self.assertRaises(argparse.ArgumentTypeError):
-        BrowserDriverType.parse(invalid)
-
-  def test_parse_str(self):
-    test_data = {
-        "": BrowserDriverType.default(),
-        "selenium": BrowserDriverType.WEB_DRIVER,
-        "webdriver": BrowserDriverType.WEB_DRIVER,
-        "applescript": BrowserDriverType.APPLE_SCRIPT,
-        "osa": BrowserDriverType.APPLE_SCRIPT,
-        "android": BrowserDriverType.ANDROID,
-        "adb": BrowserDriverType.ANDROID,
-        "iphone": BrowserDriverType.IOS,
-        "ios": BrowserDriverType.IOS,
-        "ssh": BrowserDriverType.LINUX_SSH,
-        "chromeos-ssh": BrowserDriverType.CHROMEOS_SSH,
-    }
-    for value, result in test_data.items():
-      self.assertEqual(BrowserDriverType.parse(value), result)
-
-  def test_parse_enum(self):
-    for driver_type in BrowserDriverType:
-      self.assertEqual(BrowserDriverType.parse(driver_type), driver_type)
-
-
 class DriverConfigTestCase(BaseConfigTestCase):
 
   def test_default(self):
@@ -89,7 +58,7 @@ class DriverConfigTestCase(BaseConfigTestCase):
     chromedriver_path = self.out_dir / "chromedriver"
     self.fs.create_file(chromedriver_path, st_size=100)
     driver = DriverConfig.parse(str(chromedriver_path))
-    self.assertEqual(driver.path, chromedriver_path)
+    self.assertEqual(str(driver.path), str(chromedriver_path))
 
     config = {"path": str(chromedriver_path)}
     driver_2 = DriverConfig.parse(config)
@@ -145,8 +114,10 @@ class DriverConfigTestCase(BaseConfigTestCase):
     self.assertEqual(config_1.type, BrowserDriverType.ANDROID)
     self.assertEqual(config_1.device_id, "0a388e93")
     self.assertEqual(config_1.settings["device_id"], "0a388e93")
-    self.assertTrue(config_1.is_remote)
-    self.assertFalse(config_1.is_local)
+    self.assertFalse(config_1.is_remote)
+    self.assertTrue(config_1.is_local)
+    self.assertTrue(config_1.type.is_remote_browser)
+    self.assertFalse(config_1.type.is_local_browser)
     self.assertIsNone(config_1.adb_bin)
 
     self.platform.sh_results = [ADB_DEVICES_OUTPUT]
@@ -155,8 +126,10 @@ class DriverConfigTestCase(BaseConfigTestCase):
     self.assertEqual(config_2.type, BrowserDriverType.ANDROID)
     self.assertEqual(config_2.device_id, "0a388e93")
     self.assertEqual(config_2.settings["device_id"], "0a388e93")
-    self.assertTrue(config_2.is_remote)
-    self.assertFalse(config_2.is_local)
+    self.assertFalse(config_2.is_remote)
+    self.assertTrue(config_2.is_local)
+    self.assertTrue(config_2.type.is_remote_browser)
+    self.assertFalse(config_2.type.is_local_browser)
     self.assertIsNone(config_2.adb_bin)
     self.assertEqual(config_1, config_2)
 
@@ -166,8 +139,10 @@ class DriverConfigTestCase(BaseConfigTestCase):
     assert isinstance(config_3, DriverConfig)
     self.assertEqual(config_3.type, BrowserDriverType.ANDROID)
     self.assertEqual(config_3.device_id, "0a388e93")
-    self.assertTrue(config_3.is_remote)
-    self.assertFalse(config_3.is_local)
+    self.assertFalse(config_3.is_remote)
+    self.assertTrue(config_3.is_local)
+    self.assertTrue(config_3.type.is_remote_browser)
+    self.assertFalse(config_3.type.is_local_browser)
     self.assertIsNone(config_3.settings)
     self.assertIsNone(config_2.adb_bin)
     self.assertNotEqual(config_1, config_3)
@@ -219,8 +194,8 @@ class DriverConfigTestCase(BaseConfigTestCase):
 
     self.assertEqual(config.type, BrowserDriverType.ANDROID)
     self.assertEqual(config.device_id, "0a388e93")
-    self.assertTrue(config.is_remote)
-    self.assertFalse(config.is_local)
+    self.assertFalse(config.is_remote)
+    self.assertTrue(config.is_local)
 
   def test_parse_adb_phone_serial(self):
     self.platform.sh_results = [ADB_DEVICES_OUTPUT, ADB_DEVICES_OUTPUT]
diff --git a/tests/crossbench/cli/config/test_driver_type.py b/tests/crossbench/cli/config/test_driver_type.py
new file mode 100644
index 00000000..037d3652
--- /dev/null
+++ b/tests/crossbench/cli/config/test_driver_type.py
@@ -0,0 +1,79 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import argparse
+import unittest
+
+from crossbench.cli.config.driver_type import BrowserDriverType
+from tests import test_helper
+
+
+class BrowserDriverTypeTestCase(unittest.TestCase):
+
+  def test_default(self):
+    self.assertEqual(BrowserDriverType.default(), BrowserDriverType.WEB_DRIVER)
+
+  def test_parse_invalid(self):
+    for invalid in ["invalid", None, [], (), {}]:
+      with self.assertRaises(argparse.ArgumentTypeError):
+        BrowserDriverType.parse(invalid)
+
+  def test_parse_str(self):
+    test_data = {
+        "": BrowserDriverType.default(),
+        "selenium": BrowserDriverType.WEB_DRIVER,
+        "webdriver": BrowserDriverType.WEB_DRIVER,
+        "applescript": BrowserDriverType.APPLE_SCRIPT,
+        "osa": BrowserDriverType.APPLE_SCRIPT,
+        "android": BrowserDriverType.ANDROID,
+        "adb": BrowserDriverType.ANDROID,
+        "iphone": BrowserDriverType.IOS,
+        "ios": BrowserDriverType.IOS,
+        "ssh": BrowserDriverType.LINUX_SSH,
+        "chromeos-ssh": BrowserDriverType.CHROMEOS_SSH,
+    }
+    for value, result in test_data.items():
+      self.assertEqual(BrowserDriverType.parse(value), result)
+
+  def test_parse_enum(self):
+    for driver_type in BrowserDriverType:
+      self.assertEqual(BrowserDriverType.parse(driver_type), driver_type)
+
+  def test_is_remote_browser_generic(self):
+    for driver_type in BrowserDriverType:
+      self.assertNotEqual(driver_type.is_local_browser,
+                          driver_type.is_remote_browser)
+
+  def test_is_remote_driver_generic(self):
+    for driver_type in BrowserDriverType:
+      self.assertNotEqual(driver_type.is_local_driver,
+                          driver_type.is_remote_driver)
+
+  def test_is_remote_driver_implication(self):
+    for driver_type in BrowserDriverType:
+      if driver_type.is_remote_driver:
+        self.assertTrue(driver_type.is_remote_browser)
+
+  def test_is_remote_driver(self):
+    remote_driver_types = {
+        BrowserDriverType.CHROMEOS_SSH, BrowserDriverType.LINUX_SSH
+    }
+    for driver_type in BrowserDriverType:
+      self.assertEqual(driver_type.is_remote_driver, driver_type
+                       in remote_driver_types)
+
+  def test_is_remote_browser(self):
+    remote_browser_types = {
+        BrowserDriverType.ANDROID, BrowserDriverType.CHROMEOS_SSH,
+        BrowserDriverType.LINUX_SSH
+    }
+    for driver_type in BrowserDriverType:
+      self.assertEqual(driver_type.is_remote_browser, driver_type
+                       in remote_browser_types)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_env.py b/tests/crossbench/cli/config/test_env.py
new file mode 100644
index 00000000..4873dcc2
--- /dev/null
+++ b/tests/crossbench/cli/config/test_env.py
@@ -0,0 +1,111 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import unittest
+
+import hjson
+
+from crossbench.cli.config.env import ENV_CONFIG_PRESETS, EnvironmentConfig
+from tests import test_helper
+from tests.crossbench.cli.config.base import BaseConfigTestCase
+
+
+class EnvironmentConfigTestCase(BaseConfigTestCase):
+
+  def test_parse_global_config_dict(self):
+    env_config_data = {
+        "screen_brightness_percent": 66,
+        "cpu_max_usage_percent": 77,
+    }
+    config_data = {
+        "probes": {},
+        "env": env_config_data,
+        "browsers": {},
+        "network": {},
+    }
+    direct = EnvironmentConfig.parse(env_config_data)
+    nested = EnvironmentConfig.parse(config_data)
+    self.assertEqual(direct, nested)
+    self.assertEqual(direct.disk_min_free_space_gib, EnvironmentConfig.IGNORE)
+    self.assertEqual(direct.screen_brightness_percent, 66)
+    self.assertEqual(direct.cpu_max_usage_percent, 77)
+
+  def test_parse_empty_dict(self):
+    self.assertEqual(EnvironmentConfig.parse({}), ENV_CONFIG_PRESETS["default"])
+
+  def test_parse_dict(self):
+    config_data = {"cpu_min_relative_speed": None, "cpu_max_usage_percent": 12}
+    config = EnvironmentConfig.parse(config_data)
+    self.assertEqual(config, EnvironmentConfig.parse({"env": config_data}))
+    self.assertIsNone(config.cpu_min_relative_speed)
+    self.assertEqual(config.cpu_max_usage_percent, 12)
+
+  def test_combine_bool_value(self):
+    default = EnvironmentConfig()
+    self.assertIsNone(default.power_use_battery)
+
+    battery = EnvironmentConfig(power_use_battery=True)
+    self.assertTrue(battery.power_use_battery)
+    self.assertTrue(battery.merge(battery).power_use_battery)
+    self.assertTrue(default.merge(battery).power_use_battery)
+    self.assertTrue(battery.merge(default).power_use_battery)
+
+    power = EnvironmentConfig(power_use_battery=False)
+    self.assertFalse(power.power_use_battery)
+    self.assertFalse(power.merge(power).power_use_battery)
+    self.assertFalse(default.merge(power).power_use_battery)
+    self.assertFalse(power.merge(default).power_use_battery)
+
+    with self.assertRaises(ValueError):
+      power.merge(battery)
+
+  def test_combine_min_float_value(self):
+    default = EnvironmentConfig()
+    self.assertIsNone(default.cpu_min_relative_speed)
+
+    high = EnvironmentConfig(cpu_min_relative_speed=1)
+    self.assertEqual(high.cpu_min_relative_speed, 1)
+    self.assertEqual(high.merge(high).cpu_min_relative_speed, 1)
+    self.assertEqual(default.merge(high).cpu_min_relative_speed, 1)
+    self.assertEqual(high.merge(default).cpu_min_relative_speed, 1)
+
+    low = EnvironmentConfig(cpu_min_relative_speed=0.5)
+    self.assertEqual(low.cpu_min_relative_speed, 0.5)
+    self.assertEqual(low.merge(low).cpu_min_relative_speed, 0.5)
+    self.assertEqual(default.merge(low).cpu_min_relative_speed, 0.5)
+    self.assertEqual(low.merge(default).cpu_min_relative_speed, 0.5)
+
+    self.assertEqual(high.merge(low).cpu_min_relative_speed, 1)
+
+  def test_combine_max_float_value(self):
+    default = EnvironmentConfig()
+    self.assertIsNone(default.cpu_max_usage_percent)
+
+    high = EnvironmentConfig(cpu_max_usage_percent=100)
+    self.assertEqual(high.cpu_max_usage_percent, 100)
+    self.assertEqual(high.merge(high).cpu_max_usage_percent, 100)
+    self.assertEqual(default.merge(high).cpu_max_usage_percent, 100)
+    self.assertEqual(high.merge(default).cpu_max_usage_percent, 100)
+
+    low = EnvironmentConfig(cpu_max_usage_percent=0)
+    self.assertEqual(low.cpu_max_usage_percent, 0)
+    self.assertEqual(low.merge(low).cpu_max_usage_percent, 0)
+    self.assertEqual(default.merge(low).cpu_max_usage_percent, 0)
+    self.assertEqual(low.merge(default).cpu_max_usage_percent, 0)
+
+    self.assertEqual(high.merge(low).cpu_max_usage_percent, 0)
+
+  def test_parse_example_config_file(self):
+    example_config_file = test_helper.config_dir() / "doc/env.config.hjson"
+    if not example_config_file.exists():
+      raise unittest.SkipTest(f"Test file {example_config_file} does not exist")
+    with example_config_file.open(encoding="utf-8") as f:
+      data = hjson.load(f)
+    EnvironmentConfig(**data["env"])
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_flags.py b/tests/crossbench/cli/config/test_flags.py
index 8b9fded1..b2685b8e 100644
--- a/tests/crossbench/cli/config/test_flags.py
+++ b/tests/crossbench/cli/config/test_flags.py
@@ -125,6 +125,23 @@ class FlagsConfigTestCase(unittest.TestCase):
     self.assertEqual(str(flags_a_1), "--foo=1 --bar=1")
     self.assertEqual(str(flags_a_2), "--foo=1 --bar=2")
 
+  def test_parse_multi_dict_list_groups(self):
+    config = FlagsConfig.parse({
+        "a": {
+            "label_a_1": ["--foo=1", "--bar=1"],
+            "label_a_2": ["--foo=1", "--bar=2"],
+        }
+    })
+    self.assertEqual(len(config), 1)
+    self.assertEqual(len(config["a"]), 2)
+    self.assertTupleEqual(
+        tuple(v.label for v in config["a"]), ("label_a_1", "label_a_2"))
+    variants_a = config["a"]
+    flags_a_1 = variants_a[0].flags
+    flags_a_2 = variants_a[1].flags
+    self.assertEqual(str(flags_a_1), "--foo=1 --bar=1")
+    self.assertEqual(str(flags_a_2), "--foo=1 --bar=2")
+
   def test_parse_multi_dict_dict_groups(self):
     config = FlagsConfig.parse({
         "a": {
@@ -229,6 +246,12 @@ class FlagsGroupConfigTestCase(unittest.TestCase):
     self.assertEqual(str(group[0].flags), "--foo-a=1 --bar")
     self.assertEqual(str(group[1].flags), "--foo-a=2")
 
+  def test_parse_list_multiple(self):
+    group = FlagsGroupConfig.parse((("--foo-a=1", "--bar"), "--foo-a=2"))
+    self.assertEqual(len(group), 2)
+    self.assertEqual(str(group[0].flags), "--foo-a=1 --bar")
+    self.assertEqual(str(group[1].flags), "--foo-a=2")
+
   def test_parse_str_multiple_empty(self):
     group = FlagsGroupConfig.parse(("", "--foo", "-foo=v1"))
     self.assertEqual(len(group), 3)
@@ -411,6 +434,95 @@ class FlagsGroupConfigTestCase(unittest.TestCase):
       group_a.product(group_b)
     self.assertIn("different previous value", str(cm.exception))
 
+  def mock_args(self, **kwargs):
+    args = argparse.Namespace(
+        browser=kwargs.pop("browser", []),
+        browser_config=kwargs.pop("browser_config", None),
+        enable_features=kwargs.pop("enable_features", []),
+        disable_features=kwargs.pop("disable_features", []),
+        js_flags=kwargs.pop("js_flags", []),
+        enable_field_trial_config=kwargs.pop("enable_field_trial_config", None),
+        other_browser_args=kwargs.pop("other_browser_args", []))
+    assert not kwargs, f"got unused kwargss: {kwargs}"
+    return args
+
+  def test_parse_args_other_browser_args_1(self):
+    args = self.mock_args(other_browser_args=("--foo=1",))
+    group_args = FlagsGroupConfig.parse_args(args)
+    group_a = FlagsGroupConfig.parse(("--foo=1",))
+    group_b = FlagsGroupConfig.parse("--foo=1")
+    self.assertEqual(group_args, group_a)
+    self.assertEqual(group_args, group_b)
+
+  def test_parse_args_other_browser_args_2(self):
+    args = self.mock_args(other_browser_args=("--foo=1", "--bar"))
+    group_inline = FlagsGroupConfig.parse_args(args)
+    raw_flags = "--foo=1 --bar"
+    group_a = FlagsGroupConfig.parse((raw_flags,))
+    group_b = FlagsGroupConfig.parse(raw_flags)
+    self.assertEqual(group_inline, group_a)
+    self.assertEqual(group_inline, group_b)
+
+  def test_parse_args_features(self):
+    args = self.mock_args(
+        other_browser_args=("--foo=1", "--bar"),
+        enable_features="Feature1",
+        disable_features="Feature2")
+    group_inline = FlagsGroupConfig.parse_args(args)
+    raw_flags = ("--foo=1 --bar"
+                 " --enable-features=Feature1 --disable-features=Feature2")
+    group_a = FlagsGroupConfig.parse((raw_flags,))
+    group_b = FlagsGroupConfig.parse(raw_flags)
+    self.assertEqual(group_inline, group_a)
+    self.assertEqual(group_inline, group_b)
+
+  def test_parse_args_enable_field_trials(self):
+    args = self.mock_args(enable_field_trial_config=True)
+    group_inline = FlagsGroupConfig.parse_args(args)
+    raw_flags = "--enable-field-trial-config"
+    group_a = FlagsGroupConfig.parse((raw_flags,))
+    group_b = FlagsGroupConfig.parse(raw_flags)
+    self.assertEqual(group_inline, group_a)
+    self.assertEqual(group_inline, group_b)
+
+  def test_parse_args_disable_field_trials(self):
+    args = self.mock_args(enable_field_trial_config=False)
+    group_inline = FlagsGroupConfig.parse_args(args)
+    raw_flags = "--disable-field-trial-config"
+    group_a = FlagsGroupConfig.parse((raw_flags,))
+    group_b = FlagsGroupConfig.parse(raw_flags)
+    self.assertEqual(group_inline, group_a)
+    self.assertEqual(group_inline, group_b)
+
+  def test_parse_args_js_flags_1(self):
+    args = self.mock_args(js_flags=["--max-opt=1,--log-all"])
+    group_inline = FlagsGroupConfig.parse_args(args)
+    raw_flags = "--js-flags='--max-opt=1,--log-all'"
+    group_a = FlagsGroupConfig.parse((raw_flags,))
+    group_b = FlagsGroupConfig.parse(raw_flags)
+    self.assertEqual(group_inline, group_a)
+    self.assertEqual(group_inline, group_b)
+
+  def test_parse_args_js_flags_2(self):
+    args = self.mock_args(js_flags=["--max-opt=1", "--log-all"])
+    group_inline = FlagsGroupConfig.parse_args(args)
+    group_a = FlagsGroupConfig.parse(
+        ("--js-flags=--max-opt=1", "--js-flags=--log-all"))
+    self.assertEqual(group_inline, group_a)
+
+  def test_parse_args_combined(self):
+    args = self.mock_args(
+        other_browser_args=("--bar"),
+        enable_features="Feature1",
+        js_flags=["--max-opt=1", "--log-all"])
+    group_inline = FlagsGroupConfig.parse_args(args)
+    group_a = FlagsGroupConfig.parse(
+        ("--bar --enable-features=Feature1 --js-flags=--max-opt=1",
+         "--bar --enable-features=Feature1 --js-flags=--log-all"))
+    self.assertEqual(group_inline, group_a)
+
+
+
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_network.py b/tests/crossbench/cli/config/test_network.py
index 5ca1fa64..f48d18e6 100644
--- a/tests/crossbench/cli/config/test_network.py
+++ b/tests/crossbench/cli/config/test_network.py
@@ -9,7 +9,8 @@ import json
 
 from crossbench import path as pth
 from crossbench.cli.config.network import (NetworkConfig, NetworkSpeedConfig,
-                                           NetworkSpeedPreset, NetworkType)
+                                           NetworkType)
+from crossbench.cli.config.network_speed import NetworkSpeedPreset
 from tests import test_helper
 from tests.crossbench.cli.config.base import BaseConfigTestCase
 
@@ -213,6 +214,17 @@ class NetworkConfigTestCase(BaseConfigTestCase):
     config_1 = NetworkConfig.parse(json.dumps(config_dict))
     self.assertEqual(config, config_1)
 
+  def test_parse_dict_wpr_only_flags(self):
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse({"type": "live", "persist_server": True})
+    self.assertIn("can only be used for the WPR", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse({"type": "live", "run_on_device": True})
+    self.assertIn("can only be used for the WPR", str(cm.exception))
+    with self.assertRaises(argparse.ArgumentTypeError) as cm:
+      NetworkConfig.parse({"type": "live", "skip_injection": True})
+    self.assertIn("can only be used for the WPR", str(cm.exception))
+
   def test_parse_dict_local(self):
     benchmark_folder = pth.LocalPath("third_party/speedometer/v3.0")
     with self.assertRaises(argparse.ArgumentTypeError) as cm:
diff --git a/tests/crossbench/cli/config/test_probe.py b/tests/crossbench/cli/config/test_probe_list.py
similarity index 50%
rename from tests/crossbench/cli/config/test_probe.py
rename to tests/crossbench/cli/config/test_probe_list.py
index c437e0cc..6a1b3695 100644
--- a/tests/crossbench/cli/config/test_probe.py
+++ b/tests/crossbench/cli/config/test_probe_list.py
@@ -10,15 +10,17 @@ from unittest import mock
 import hjson
 
 from crossbench import path as pth
-from crossbench.cli.config.probe import ProbeConfig, ProbeListConfig
+from crossbench.cli.config.probe import ProbeConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
 from crossbench.probes.power_sampler import PowerSamplerProbe
 from crossbench.probes.v8.log import V8LogProbe
+from crossbench.probes.v8.rcs import V8RCSProbe
 from crossbench.types import JsonDict
 from tests import test_helper
-from tests.crossbench.base import CrossbenchFakeFsTestCase
+from tests.crossbench.cli.config.base import BaseConfigTestCase
 
 
-class TestProbeConfig(CrossbenchFakeFsTestCase):
+class TestProbeListConfig(BaseConfigTestCase):
   # pylint: disable=expression-not-assigned
 
   def parse_config(self, config_data) -> ProbeListConfig:
@@ -69,7 +71,7 @@ class TestProbeConfig(CrossbenchFakeFsTestCase):
     }
     with file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
-    args = mock.Mock(probe_config=file)
+    args = mock.Mock(probe_config=file, probe=[])
     config = ProbeListConfig.from_cli_args(args)
     self.assertTrue(len(config.probes), 1)
     probe = config.probes[0]
@@ -156,6 +158,126 @@ class TestProbeConfig(CrossbenchFakeFsTestCase):
     assert isinstance(powersampler_probe, PowerSamplerProbe)
     self.assertEqual(powersampler_probe.bin_path, powersampler_bin)
 
+  def test_parse_args_empty(self):
+    args = mock.Mock(probe_config=None, probe=[])
+    probe_list = ProbeListConfig.from_cli_args(args)
+    self.assertFalse(probe_list.probes)
+
+  def test_parse_sequence(self):
+    probe_list = ProbeListConfig.parse(["v8.rcs", "v8.log"])
+    probes = probe_list.probes
+    self.assertEqual(len(probes), 2)
+    self.assertIsInstance(probes[0], V8RCSProbe)
+    self.assertIsInstance(probes[1], V8LogProbe)
+
+  def test_parse_dict_simple(self):
+    probe_list = ProbeListConfig.parse({"v8.rcs": {}, "v8.log": {}})
+    probes = probe_list.probes
+    self.assertEqual(len(probes), 2)
+    self.assertIsInstance(probes[0], V8RCSProbe)
+    self.assertIsInstance(probes[1], V8LogProbe)
+    # respect input order
+    probe_list = ProbeListConfig.parse({"v8.log": {}, "v8.rcs": {}})
+    probes = probe_list.probes
+    self.assertEqual(len(probes), 2)
+    self.assertIsInstance(probes[0], V8LogProbe)
+    self.assertIsInstance(probes[1], V8RCSProbe)
+
+  def test_parse_dict_nested_config(self):
+    probe_list = ProbeListConfig.parse({"probes": {"v8.rcs": {}, "v8.log": {}}})
+    probes = probe_list.probes
+    self.assertEqual(len(probes), 2)
+    self.assertIsInstance(probes[0], V8RCSProbe)
+    self.assertIsInstance(probes[1], V8LogProbe)
+
+  def test_parse_args_single_probe_config(self):
+    args = mock.Mock(probe_config=None, probe=[ProbeConfig.parse("v8.log")])
+    probe_list = ProbeListConfig.from_cli_args(args)
+    probes = probe_list.probes
+    self.assertEqual(len(probes), 1)
+    probe = probes[0]
+    self.assertIsInstance(probe, V8LogProbe)
+
+  def test_parse_args_multiple_probe_config(self):
+    args = mock.Mock(
+        probe_config=None,
+        probe=[
+            ProbeConfig.parse("v8.log"),
+            ProbeConfig.parse("v8.rcs"),
+        ])
+    probe_list = ProbeListConfig.from_cli_args(args)
+    probes = probe_list.probes
+    self.assertEqual(len(probes), 2)
+    self.assertIsInstance(probes[0], V8LogProbe)
+    self.assertIsInstance(probes[1], V8RCSProbe)
+
+  def test_empty_config_file(self):
+    with self.platform.NamedTemporaryFile() as config_file:
+      with config_file.open("w", encoding="utf-8") as f:
+        hjson.dump({"probes": []}, f)
+      args = mock.Mock(probe_config=config_file, probe=[])
+      probe_list = ProbeListConfig.from_cli_args(args)
+      self.assertFalse(probe_list.probes)
+
+  def test_merge_empty_config_file_with_single_probe(self):
+    with self.platform.NamedTemporaryFile() as config_file:
+      with config_file.open("w", encoding="utf-8") as f:
+        hjson.dump({"probes": []}, f)
+      args = mock.Mock(
+          probe_config=config_file, probe=[ProbeConfig.parse("v8.log")])
+      probe_list = ProbeListConfig.from_cli_args(args)
+      probes = probe_list.probes
+      self.assertEqual(len(probes), 1)
+      probe = probes[0]
+      self.assertIsInstance(probe, V8LogProbe)
+
+  def test_merge_config_file_single_probe(self):
+    with self.platform.NamedTemporaryFile() as config_file:
+      with config_file.open("w", encoding="utf-8") as f:
+        hjson.dump({"probes": ["v8.rcs"]}, f)
+      args = mock.Mock(
+          probe_config=config_file, probe=[ProbeConfig.parse("v8.log")])
+      probe_list = ProbeListConfig.from_cli_args(args)
+      probes = probe_list.probes
+      self.assertEqual(len(probes), 2)
+      self.assertIsInstance(probes[0], V8RCSProbe)
+      self.assertIsInstance(probes[1], V8LogProbe)
+
+  def test_merge_config_file_conflict(self):
+    # By default --probe args override --probe-config args
+    with self.platform.NamedTemporaryFile() as config_file:
+      with config_file.open("w", encoding="utf-8") as f:
+        hjson.dump({"probes": ["v8.rcs"]}, f)
+      args = mock.Mock(
+          probe_config=config_file, probe=[ProbeConfig.parse("v8.rcs")])
+      probe_list = ProbeListConfig.from_cli_args(args)
+      probes = probe_list.probes
+      self.assertEqual(len(probes), 1)
+      probe = probes[0]
+      self.assertIsInstance(probe, V8RCSProbe)
+
+  def test_merge_conflict_raw(self):
+    probe_list_a = ProbeListConfig(
+        [ProbeConfig.parse("v8.log"),
+         ProbeConfig.parse("v8.rcs")])
+    probe_list_b = ProbeListConfig([ProbeConfig.parse("v8.rcs")])
+    with self.assertRaisesRegex(ValueError, "Duplicate"):
+      probe_list_a.merge(probe_list_b)
+    with self.assertRaisesRegex(ValueError, "Duplicate"):
+      probe_list_b.merge(probe_list_a)
+
+    merged_a_b = probe_list_a.merge(probe_list_b, should_override=True)
+    probes = merged_a_b.probes
+    self.assertEqual(len(probes), 2)
+    self.assertIsInstance(probes[0], V8LogProbe)
+    self.assertIsInstance(probes[1], V8RCSProbe)
+
+    merged_b_a = probe_list_b.merge(probe_list_a, should_override=True)
+    probes = merged_b_a.probes
+    self.assertEqual(len(probes), 2)
+    self.assertIsInstance(probes[0], V8RCSProbe)
+    self.assertIsInstance(probes[1], V8LogProbe)
+
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/config/test_secrets.py b/tests/crossbench/cli/config/test_secrets.py
index f704583d..a5408890 100644
--- a/tests/crossbench/cli/config/test_secrets.py
+++ b/tests/crossbench/cli/config/test_secrets.py
@@ -7,49 +7,82 @@ from __future__ import annotations
 import json
 
 import hjson
-from immutabledict import immutabledict
 
-from crossbench.cli.config.secrets import Secret, SecretsConfig, SecretType
+from crossbench.cli.config.secrets import (GoogleUsernamePassword, Secrets,
+                                           ServiceAccount)
+from tests import test_helper
 from tests.crossbench.cli.config.base import BaseConfigTestCase
 
 
 class SecretsConfigTestCase(BaseConfigTestCase):
 
   def test_parse_empty(self):
-    secrets = SecretsConfig.parse({})
-    self.assertEqual(secrets.secrets, immutabledict())
+    secrets = Secrets.parse({})
+    self.assertEqual(secrets.google, None)
 
   def test_parse_google(self):
-    secrets = SecretsConfig.parse(
+    secrets = Secrets.parse(
         {"google": {
             "password": "pw",
             "account": "user@test.com"
         }})
-    self.assertEqual(secrets.secrets[SecretType.GOOGLE],
-                     Secret(SecretType.GOOGLE, "user@test.com", "pw"))
-    secrets = SecretsConfig.parse(
+    self.assertEqual(secrets.google,
+                     GoogleUsernamePassword("user@test.com", "pw"))
+    secrets = Secrets.parse(
         {"google": {
             "user": "user@test.com",
             "password": ""
         }})
-    self.assertEqual(secrets.secrets[SecretType.GOOGLE],
-                     Secret(SecretType.GOOGLE, "user@test.com", ""))
+    self.assertEqual(secrets.google,
+                     GoogleUsernamePassword("user@test.com", ""))
+
+  def test_parse_bond(self):
+    secrets = Secrets.parse({
+        "bond": {
+            "type": "service_account",
+            "project_id": "my-project",
+            "private_key_id": "0BADC0DE",
+            "private_key": "-----BEGIN PRIVATE KEY-----\n...",
+            "client_email": "name@example.com",
+            "client_id": "7",
+            "auth_uri": "https://example.com/oauth",
+            "token_uri": "https://example.com/token",
+            "auth_provider_x509_cert_url": "https://example.com/certs",
+            "client_x509_cert_url": "https://example.com/x509/my-project.cert",
+            "universe_domain": "example.com",
+        }
+    })
+    self.assertEqual(
+        secrets.bond,
+        ServiceAccount(
+            type="service_account",
+            project_id="my-project",
+            private_key_id="0BADC0DE",
+            private_key="-----BEGIN PRIVATE KEY-----\n...",
+            client_email="name@example.com",
+            client_id="7",
+            auth_uri="https://example.com/oauth",
+            token_uri="https://example.com/token",
+            auth_provider_x509_cert_url="https://example.com/certs",
+            client_x509_cert_url="https://example.com/x509/my-project.cert",
+            universe_domain="example.com",
+        ))
 
   def test_equal_empty(self):
-    secrets_1 = SecretsConfig.parse({})
-    secrets_2 = SecretsConfig.parse({})
+    secrets_1 = Secrets.parse({})
+    secrets_2 = Secrets.parse({})
     self.assertEqual(secrets_1, secrets_1)
     self.assertEqual(secrets_1, secrets_2)
     self.assertEqual(secrets_2, secrets_1)
 
   def test_equal_single_item(self):
-    secrets_empty = SecretsConfig.parse({})
-    secrets_1 = SecretsConfig.parse(
+    secrets_empty = Secrets.parse({})
+    secrets_1 = Secrets.parse(
         {"google": {
             "password": "pw",
             "account": "user@test.com"
         }})
-    secrets_2 = SecretsConfig.parse(
+    secrets_2 = Secrets.parse(
         {"google": {
             "password": "pw",
             "account": "user@test.com"
@@ -63,12 +96,12 @@ class SecretsConfigTestCase(BaseConfigTestCase):
     self.assertNotEqual(secrets_empty, secrets_2)
 
   def test_not_equal_single_item(self):
-    secrets_1 = SecretsConfig.parse(
+    secrets_1 = Secrets.parse(
         {"google": {
             "password": "pw",
             "account": "user@test.com"
         }})
-    secrets_2 = SecretsConfig.parse(
+    secrets_2 = Secrets.parse(
         {"google": {
             "password": "PASSWORD",
             "account": "user@test.com"
@@ -77,8 +110,26 @@ class SecretsConfigTestCase(BaseConfigTestCase):
 
   def test_parse_inline_hjson(self):
     config_data = {"google": {"password": "pw", "account": "user@test.com"}}
-    secrets_inline_hjson = SecretsConfig.parse(hjson.dumps(config_data))
-    secrets_inline_json = SecretsConfig.parse(json.dumps(config_data))
-    secrets_dict = SecretsConfig.parse(config_data)
+    secrets_inline_hjson = Secrets.parse(hjson.dumps(config_data))
+    secrets_inline_json = Secrets.parse(json.dumps(config_data))
+    secrets_dict = Secrets.parse(config_data)
     self.assertEqual(secrets_inline_hjson, secrets_dict)
     self.assertEqual(secrets_inline_json, secrets_dict)
+
+  def test_merge(self):
+    secrets_1 = Secrets.parse(
+        {"google": {
+            "password": "pw",
+            "account": "user1@test.com"
+        }})
+    secrets_2 = Secrets.parse(
+        {"google": {
+            "password": "PASSWORD",
+            "account": "user2@test.com"
+        }})
+    merged = secrets_1.merge(fallback=secrets_2)
+    self.assertEqual(secrets_1, merged)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/cli/test_cli_fast_a.py b/tests/crossbench/cli/test_cli_fast_a.py
index 44a91b53..3de104e8 100644
--- a/tests/crossbench/cli/test_cli_fast_a.py
+++ b/tests/crossbench/cli/test_cli_fast_a.py
@@ -6,17 +6,16 @@ import argparse
 import json
 import pathlib
 import unittest
-from unittest import mock
 
 import hjson
-from tests import test_helper
-from tests.crossbench import mock_browser
-from tests.crossbench.base import BaseCliTestCase, SysExitTestException
 
 from crossbench import __version__, plt
+from crossbench.cli.cli import CrossBenchCLI
 from crossbench.cli.config.browser import BrowserConfig
-from crossbench.cli.config.browser_variants import BrowserVariantsConfig
-from crossbench.env import HostEnvironmentConfig
+from crossbench.env import EnvironmentConfig
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCliTestCase, SysExitTestException
 
 
 class FastCliTestCasePartA(BaseCliTestCase):
@@ -28,6 +27,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
   presubmit checks.
   """
 
+  def test_benchmark_order(self):
+    sorted_benchmark_classes = sorted(
+        CrossBenchCLI.BENCHMARKS, key=lambda cls: cls.NAME)
+    self.assertSequenceEqual(sorted_benchmark_classes, CrossBenchCLI.BENCHMARKS)
+
   def test_invalid(self):
     with self.assertRaises(SysExitTestException):
       self.run_cli("unknown subcommand", "--invalid flag")
@@ -168,6 +172,26 @@ class FastCliTestCasePartA(BaseCliTestCase):
     self.assertIn("Disable colored output", stdout)
     self.assertIn("Available Probes for all Benchmarks:", stdout)
 
+  def test_help_subcommand_probe(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("help", "v8.log")
+    self.assertEqual(cm.exception.exit_code, 0)
+    _, stdout, stderr = self.run_cli_output(
+        "help", "v8.log", raises=SysExitTestException)
+    self.assertFalse(stderr)
+    self.assertIn("v8.log", stdout)
+    self.assertIn("V8LogProbe", stdout)
+
+  def test_help_subcommand_benchmark(self):
+    with self.assertRaises(SysExitTestException) as cm:
+      self.run_cli("help", "sp3.0")
+    self.assertEqual(cm.exception.exit_code, 0)
+    _, stdout, stderr = self.run_cli_output(
+        "help", "sp3.0", raises=SysExitTestException)
+    self.assertFalse(stderr)
+    self.assertIn("Speedometer 3.0", stdout)
+    self.assertIn("https://browserbench.org/Speedometer3.0/", stdout)
+
   def test_version(self):
     with self.assertRaises(SysExitTestException) as cm:
       self.run_cli("--version")
@@ -187,7 +211,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     self.assertIn(__version__, stdout)
 
   def test_subcommand_run_subcommand(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", "run", f"--urls={url}", "--env-validation=skip",
                    "--throw")
@@ -195,11 +219,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
         self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
 
   def test_invalid_probe(self):
-    with self.assertRaises(argparse.ArgumentError), self.patch_get_browser():
+    with self.assertRaises(argparse.ArgumentError), self._patch_get_browser():
       self.run_cli("loading", "--probe=invalid_probe_name", "--throw")
 
   def test_basic_probe_setting(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", "--probe=v8.log", f"--urls={url}",
                    "--env-validation=skip", "--throw")
@@ -210,7 +234,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
   def test_invalid_empty_probe_config_file(self):
     config_file = pathlib.Path("/config.hjson")
     config_file.touch()
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       with self.assertRaises(argparse.ArgumentError) as cm:
         self.run_cli("loading", f"--probe-config={config_file}",
@@ -228,7 +252,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
 
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", f"--probe-config={config_file}", f"--urls={url}",
                    "--env-validation=skip")
@@ -241,7 +265,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     config_data = {"probes": {"invalid probe name": {}}}
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       with self.assertRaises(argparse.ArgumentTypeError):
         self.run_cli("loading", f"--probe-config={config_file}",
@@ -257,7 +281,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
 
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", f"--probe-config={config_file}", f"--urls={url}",
                    "--env-validation=skip")
@@ -272,7 +296,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
     with self.assertRaises(
-        argparse.ArgumentTypeError) as cm, self.patch_get_browser():
+        argparse.ArgumentTypeError) as cm, self._patch_get_browser():
       self.run_cli("loading", f"--probe-config={config_file}",
                    "--urls=http://test.com", "--env-validation=skip", "--throw")
     self.assertIn("invalid probe name", str(cm.exception))
@@ -283,7 +307,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
     with self.assertRaises(
-        argparse.ArgumentTypeError) as cm, self.patch_get_browser():
+        argparse.ArgumentTypeError) as cm, self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
                    "--env-validation=skip", "--throw")
@@ -295,7 +319,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
     with self.assertRaises(
-        argparse.ArgumentTypeError) as cm, self.patch_get_browser():
+        argparse.ArgumentTypeError) as cm, self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
                    "--env-validation=skip", "--throw")
@@ -332,7 +356,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
 
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
                    "--env-validation=skip")
@@ -355,16 +379,15 @@ class FastCliTestCasePartA(BaseCliTestCase):
     with config_file.open("w", encoding="utf-8") as f:
       hjson.dump(config_data, f)
 
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       cli = self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
                          "--env-validation=skip")
       for browser in self.browsers:
         self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
         self.assertFalse(browser.js_flags)
-      config = cli.runner.env.config
-      self.assertEqual(config.disk_min_free_space_gib,
-                       HostEnvironmentConfig.IGNORE)
+      config = cli.last_subcommand.runner.env.config
+      self.assertEqual(config.disk_min_free_space_gib, EnvironmentConfig.IGNORE)
       self.assertEqual(config.screen_brightness_percent, 66)
       self.assertEqual(config.cpu_max_usage_percent, 77)
 
@@ -392,14 +415,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
         return mock_browser.MockChromeDev
       return mock_browser.MockChromeStable
 
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
-        side_effect=mock_get_browser_cls):
+    with self._patch_get_browser_cls(side_effect=mock_get_browser_cls):
       url = "http://test.com"
       cli = self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
                          "--env-validation=skip")
-      browsers = cli.runner.browsers
+      browsers = cli.last_subcommand.runner.browsers
       self.assertEqual(len(browsers), 2)
       self.assertEqual(browsers[0].label, "browser_1")
       self.assertEqual(browsers[1].label, "browser_2")
diff --git a/tests/crossbench/cli/test_cli_fast_b.py b/tests/crossbench/cli/test_cli_fast_b.py
index 903000be..3e77590a 100644
--- a/tests/crossbench/cli/test_cli_fast_b.py
+++ b/tests/crossbench/cli/test_cli_fast_b.py
@@ -11,22 +11,23 @@ from typing import List, Optional, Type
 from unittest import mock
 
 import hjson
-from tests import test_helper
-from tests.crossbench import mock_browser
-from tests.crossbench.base import BaseCliTestCase, SysExitTestException
-from tests.crossbench.cli.config.base import XCTRACE_DEVICES_SINGLE_OUTPUT
 
 from crossbench import __version__, plt
-from crossbench.browsers import splash_screen, viewport
-from crossbench.cli.cli import CrossBenchCLI
+from crossbench.browsers import viewport
+from crossbench.browsers.splash_screen import SplashScreen, URLSplashScreen
 from crossbench.cli.config.browser import BrowserConfig
-from crossbench.cli.config.browser_variants import BrowserVariantsConfig
-from crossbench.cli.config.driver import BrowserDriverType, DriverConfig
+from crossbench.cli.config.driver import DriverConfig
+from crossbench.cli.config.driver_type import BrowserDriverType
+from crossbench.cli.subcommand.benchmark import BenchmarkSubcommand
 from crossbench.env import ValidationMode
 from crossbench.parse import LateArgumentError
 from crossbench.path import AnyPath
-from crossbench.probes import internal
+from crossbench.probes.internal.summary import ResultsSummaryProbe
 from crossbench.runner.runner import Runner
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCliTestCase, SysExitTestException
+from tests.crossbench.cli.config.base import XCTRACE_DEVICES_SINGLE_OUTPUT
 
 
 class FastCliTestCasePartA(BaseCliTestCase):
@@ -42,15 +43,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
     if self.platform.is_win:
       self.skipTest("No auto-download available on windows")
     browser_cls = mock_browser.MockChromeStable
-    # TODO: migrate to with_stem once python 3.9 is available everywhere
-    suffix = browser_cls.mock_app_path().suffix
-    browser_bin = browser_cls.mock_app_path().with_name(
-        f"Custom Google Chrome{suffix}")
+    browser_bin = browser_cls.mock_app_path(
+        self.platform).with_stem("Custom Google Chrome")
     browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
 
-    with mock.patch.object(
-        BrowserVariantsConfig, "get_browser_cls",
-        return_value=browser_cls) as get_browser_cls:
+    with self._patch_get_browser_cls(browser_cls) as get_browser_cls:
       self.run_cli("loading", f"--browser={browser_bin}",
                    "--urls=http://test.com", "--env-validation=skip")
     get_browser_cls.assert_called_once_with(
@@ -60,16 +57,12 @@ class FastCliTestCasePartA(BaseCliTestCase):
     if self.platform.is_win:
       self.skipTest("No auto-download available on windows")
     browser_cls = mock_browser.MockChromeStable
-    # TODO: migrate to with_stem once python 3.9 is available everywhere
-    suffix = browser_cls.mock_app_path().suffix
-    browser_bin = browser_cls.mock_app_path().with_name(
-        f"Custom Google Chrome{suffix}")
+    browser_bin = browser_cls.mock_app_path(
+        self.platform).with_stem("Custom Google Chrome")
     browser_cls.setup_bin(self.fs, browser_bin, "Chrome")
 
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls", return_value=browser_cls), mock.patch.object(
-            CrossBenchCLI, "_run_benchmark") as run_benchmark:
+    with self._patch_get_browser_cls(browser_cls), mock.patch.object(
+        BenchmarkSubcommand, "_run_benchmark") as run_benchmark:
       self.run_cli("loading", f"--browser={browser_bin}",
                    "--urls=http://test.com", "--env-validation=skip", "--",
                    "--chrome-flag1=value1", "--chrome-flag2")
@@ -96,13 +89,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
     def mock_get_browser_cls(browser_config: BrowserConfig):
       self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
       for mock_browser_cls in mock_browsers:
-        if mock_browser_cls.mock_app_path() == browser_config.path:
+        if mock_browser_cls.mock_app_path(self.platform) == browser_config.path:
           return mock_browser_cls
       raise ValueError("Unknown browser path")
 
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
+    with self._patch_get_browser_cls(
         side_effect=mock_get_browser_cls) as get_browser_cls:
       url = "http://test.com"
       self.run_cli("loading", "--browser=chrome-beta",
@@ -113,7 +104,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
       get_browser_cls.assert_called()
       # Example:  BROWSER / "cb.results.json"
       result_files = list(
-          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+          self.out_dir.glob(f"*/*/{ResultsSummaryProbe.NAME}.json"))
       self.assertEqual(len(result_files), 3)
       versions = []
       for result_file in result_files:
@@ -141,13 +132,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
     def mock_get_browser_cls(browser_config: BrowserConfig):
       self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
       for mock_browser_cls in mock_browsers:
-        if mock_browser_cls.mock_app_path() == browser_config.path:
+        if mock_browser_cls.mock_app_path(self.platform) == browser_config.path:
           return mock_browser_cls
       raise ValueError("Unknown browser path")
 
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
+    with self._patch_get_browser_cls(
         side_effect=mock_get_browser_cls) as get_browser_cls:
       url = "http://test.com"
       self.run_cli("loading", "--browser=chrome-dev", "--browser=chrome-beta",
@@ -157,7 +146,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
       get_browser_cls.assert_called()
       # Example:  BROWSER / "cb.results.json"
       result_files = list(
-          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+          self.out_dir.glob(f"*/*/{ResultsSummaryProbe.NAME}.json"))
       self.assertEqual(len(result_files), 2)
       versions = []
       for result_file in result_files:
@@ -185,13 +174,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
     def mock_get_browser_cls(browser_config: BrowserConfig):
       self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
       for mock_browser_cls in mock_browsers:
-        if mock_browser_cls.mock_app_path() == browser_config.path:
+        if mock_browser_cls.mock_app_path(self.platform) == browser_config.path:
           return mock_browser_cls
       raise ValueError("Unknown browser path")
 
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
+    with self._patch_get_browser_cls(
         side_effect=mock_get_browser_cls) as get_browser_cls:
       url = "http://test.com"
       self.run_cli("loading", "--browser=chrome-dev", "--browser=chrome-beta",
@@ -201,7 +188,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
       get_browser_cls.assert_called()
       # Example:  BROWSER / "cb.results.json"
       result_files = list(
-          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+          self.out_dir.glob(f"*/*/{ResultsSummaryProbe.NAME}.json"))
       self.assertEqual(len(result_files), 2)
       versions = []
       for result_file in result_files:
@@ -217,23 +204,23 @@ class FastCliTestCasePartA(BaseCliTestCase):
 
     def mock_get_browser_cls(browser_config: BrowserConfig):
       if browser_config.driver.type == BrowserDriverType.IOS:
-        self.assertEqual(browser_config.path,
-                         mock_browser.MockChromeStable.mock_app_path())
+        self.assertEqual(
+            browser_config.path,
+            mock_browser.MockChromeStable.mock_app_path(self.platform))
         return mock_browser.MockChromeStable
       if browser_config.driver.type == BrowserDriverType.WEB_DRIVER:
-        self.assertEqual(browser_config.path,
-                         mock_browser.MockChromeBeta.mock_app_path())
+        self.assertEqual(
+            browser_config.path,
+            mock_browser.MockChromeBeta.mock_app_path(self.platform))
         return mock_browser.MockChromeBeta
       self.assertEqual(browser_config.driver.type,
                        BrowserDriverType.APPLE_SCRIPT)
       self.assertEqual(browser_config.path,
-                       mock_browser.MockChromeDev.mock_app_path())
+                       mock_browser.MockChromeDev.mock_app_path(self.platform))
       return mock_browser.MockChromeDev
 
     self.platform.expect_sh(result=XCTRACE_DEVICES_SINGLE_OUTPUT)
-    with mock.patch.object(
-        BrowserVariantsConfig,
-        "get_browser_cls",
+    with self._patch_get_browser_cls(
         side_effect=mock_get_browser_cls) as get_browser_cls:
       url = "http://test.com"
       self.run_cli("loading", "--browser=ios:chrome-stable",
@@ -244,7 +231,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
       get_browser_cls.assert_called()
       # Example:  BROWSER / "cb.results.json"
       result_files = list(
-          self.out_dir.glob(f"*/*/{internal.ResultsSummaryProbe.NAME}.json"))
+          self.out_dir.glob(f"*/*/{ResultsSummaryProbe.NAME}.json"))
       self.assertEqual(len(result_files), 3)
       versions = []
       for result_file in result_files:
@@ -259,7 +246,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
 
   def test_probe_invalid_inline_json_config(self):
     with self.assertRaises(
-        argparse.ArgumentError) as cm, self.patch_get_browser():
+        argparse.ArgumentError) as cm, self._patch_get_browser():
       self.run_cli("loading", "--probe=v8.log{invalid json: d a t a}",
                    "--urls=cnn", "--env-validation=skip", "--throw")
     message = str(cm.exception)
@@ -267,7 +254,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
 
   def test_probe_empty_inline_json_config(self):
     js_flags = ["--log-foo", "--log-bar"]
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", "--probe=v8.log{}", f"--urls={url}",
                    "--env-validation=skip")
@@ -279,7 +266,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
   def test_probe_inline_json_config(self):
     js_flags = ["--log-foo", "--log-bar"]
     json_config = json.dumps({"js_flags": js_flags})
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       url = "http://test.com"
       self.run_cli("loading", f"--probe=v8.log{json_config}", f"--urls={url}",
                    "--env-validation=skip")
@@ -289,12 +276,12 @@ class FastCliTestCasePartA(BaseCliTestCase):
           self.assertIn(flag, browser.js_flags)
 
   def test_env_config_name(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "--env=strict", "--urls=http://test.com",
                    "--env-validation=skip", "--throw")
 
   def test_env_config_inline_hjson(self):
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "--env={\"power_use_battery\":false}",
                    "--urls=http://test.com", "--env-validation=skip")
 
@@ -318,17 +305,14 @@ class FastCliTestCasePartA(BaseCliTestCase):
     def mock_get_browser_cls(browser_config: BrowserConfig):
       self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
       for mock_browser_cls in mock_browsers:
-        if mock_browser_cls.mock_app_path() == browser_config.path:
+        if mock_browser_cls.mock_app_path(self.platform) == browser_config.path:
           return mock_browser_cls
       raise ValueError("Unknown browser path")
 
     driver_path = self.out_dir / "driver"
     self.fs.create_file(driver_path, st_size=1024)
     with self.assertRaises(LateArgumentError) as cm:
-      with mock.patch.object(
-          BrowserVariantsConfig,
-          "get_browser_cls",
-          side_effect=mock_get_browser_cls):
+      with self._patch_get_browser_cls(side_effect=mock_get_browser_cls):
         self.run_cli("loading", "--browser=chrome", "--browser=firefox",
                      f"--driver-path={driver_path}", "--urls=http://test.com",
                      "--env-validation=skip", "--throw")
@@ -358,7 +342,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     config = pathlib.Path("/test.config.hjson")
     with config.open("w", encoding="utf-8") as f:
       hjson.dump({"env": {}}, f)
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", f"--env-config={config}",
                    "--urls=http://test.com", "--env-validation=skip")
 
@@ -380,39 +364,37 @@ class FastCliTestCasePartA(BaseCliTestCase):
     self.assertIn("unknown-value", message)
 
   def test_splash_screen_none(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       url = "http://test.com"
       cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
                          "--throw", "--splash-screen=none")
-      for browser in cli.runner.browsers:
+      for browser in cli.last_subcommand.runner.browsers:
         assert isinstance(browser, mock_browser.MockChromeStable)
-        self.assertEqual(browser.splash_screen, splash_screen.SplashScreen.NONE)
+        self.assertEqual(browser.settings.splash_screen, SplashScreen.NONE)
         self.assertListEqual([url], browser.url_list)
         self.assertEqual(len(browser.js_flags), 0)
 
   def test_splash_screen_minimal(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       url = "http://test.com"
       cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
                          "--throw", "--splash-screen=minimal")
-      for browser in cli.runner.browsers:
+      for browser in cli.last_subcommand.runner.browsers:
         assert isinstance(browser, mock_browser.MockChromeStable)
-        self.assertEqual(browser.splash_screen,
-                         splash_screen.SplashScreen.MINIMAL)
+        self.assertEqual(browser.settings.splash_screen, SplashScreen.MINIMAL)
         self.assertEqual(len(browser.url_list), 3)
         self.assertIn(url, browser.url_list)
         self.assertEqual(len(browser.js_flags), 0)
 
   def test_splash_screen_url(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       splash_url = "http://splash.com"
       url = "http://test.com"
       cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
                          "--throw", f"--splash-screen={splash_url}")
-      for browser in cli.runner.browsers:
+      for browser in cli.last_subcommand.runner.browsers:
         assert isinstance(browser, mock_browser.MockChromeStable)
-        self.assertIsInstance(browser.splash_screen,
-                              splash_screen.URLSplashScreen)
+        self.assertIsInstance(browser.settings.splash_screen, URLSplashScreen)
         self.assertEqual(len(browser.url_list), 3)
         self.assertEqual(splash_url, browser.url_list[0])
         self.assertEqual(len(browser.js_flags), 0)
@@ -426,11 +408,11 @@ class FastCliTestCasePartA(BaseCliTestCase):
     self.assertIn("-123", message)
 
   def test_viewport_maximized(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       url = "http://test.com"
       cli = self.run_cli("loading", f"--urls={url}", "--env-validation=skip",
                          "--throw", "--viewport=maximized")
-      for browser in cli.runner.browsers:
+      for browser in cli.last_subcommand.runner.browsers:
         assert isinstance(browser, mock_browser.MockChromeStable)
         self.assertEqual(browser.viewport, viewport.Viewport.MAXIMIZED)
         self.assertEqual(len(browser.url_list), 3)
@@ -440,7 +422,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
     powersampler_bin = self.out_dir / "powersampler"
     self.fs.create_file(powersampler_bin, st_size=1024)
     config_str = json.dumps({"bin_path": str(powersampler_bin)})
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       with self.assertRaises(argparse.ArgumentTypeError) as cm:
         self.run_cli("loading", "--browser=chrome",
                      f"--probe=powersampler:{config_str}", "--repeat=10",
@@ -449,20 +431,20 @@ class FastCliTestCasePartA(BaseCliTestCase):
       self.assertIn("powersampler", str(cm.exception))
 
   def test_fast(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       url = "http://test.com"
       cli = self.run_cli("loading", f"--urls={url}", "--throw", "--fast")
-      self.assertEqual(cli.args.splash_screen, splash_screen.SplashScreen.NONE)
+      self.assertEqual(cli.args.splash_screen, SplashScreen.NONE)
       self.assertEqual(cli.args.cool_down_time, dt.timedelta(0))
       self.assertEqual(cli.args.env_validation, ValidationMode.SKIP)
-      for browser in cli.runner.browsers:
+      for browser in cli.last_subcommand.runner.browsers:
         assert isinstance(browser, mock_browser.MockChromeStable)
-        self.assertIs(browser.splash_screen, splash_screen.SplashScreen.NONE)
+        self.assertIs(browser.settings.splash_screen, SplashScreen.NONE)
         self.assertListEqual(browser.url_list, [url])
         self.assertEqual(len(browser.js_flags), 0)
 
   def test_create_symlinks(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       out_dir = self.out_dir / "create_symlinks"
       self.assertFalse(out_dir.exists())
       url = "http://test.com"
@@ -477,7 +459,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
       self.assertTrue(links[0].is_symlink())
 
   def test_no_symlinks(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       out_dir = self.out_dir / "no_symlinks"
       self.assertFalse(out_dir.exists())
       url = "http://test.com"
@@ -490,12 +472,12 @@ class FastCliTestCasePartA(BaseCliTestCase):
           self.assertFalse((dirpath / name).is_symlink())
 
   def test_debug(self):
-    with self.mock_chrome_stable():
+    with self._patch_get_browser_cls():
       url = "http://test.com"
       cli = self.run_cli("loading", f"--urls={url}", "--debug")
       self.assertTrue(cli.args.throw)
       self.assertEqual(cli.args.verbosity, 3)
-      for browser in cli.runner.browsers:
+      for browser in cli.last_subcommand.runner.browsers:
         assert isinstance(browser, mock_browser.MockChromeStable)
         self.assertEqual(len(browser.url_list), 3)
         self.assertEqual(len(browser.js_flags), 0)
@@ -512,7 +494,7 @@ class FastCliTestCasePartA(BaseCliTestCase):
 
     for debugger in ("lldb", "gdb", "lldb"):
       searched_binaries = []
-      with self.mock_chrome_stable(), mock.patch.object(
+      with self._patch_get_browser_cls(), mock.patch.object(
           plt.PLATFORM, "search_binary", side_effect=mock_search_binary):
         with self.assertRaises(ValueError) as cm:
           self.run_cli("loading", "--urls=cnn", f"--{debugger}", "--throw")
diff --git a/tests/crossbench/cli/test_cli_slow.py b/tests/crossbench/cli/test_cli_slow.py
index 7a67833e..7a49ad62 100644
--- a/tests/crossbench/cli/test_cli_slow.py
+++ b/tests/crossbench/cli/test_cli_slow.py
@@ -5,31 +5,68 @@
 import argparse
 import json
 import pathlib
-from typing import Dict, List, Type
+from typing import Dict, List, Tuple, Type
 from unittest import mock
 
 import hjson
-from tests import test_helper
-from tests.crossbench import mock_browser
-from tests.crossbench.base import BaseCliTestCase, SysExitTestException
 
 from crossbench import __version__
 from crossbench.browsers.settings import Settings
 from crossbench.cli.cli import CrossBenchCLI
 from crossbench.cli.config.browser import BrowserConfig
-from crossbench.cli.config.browser_variants import BrowserVariantsConfig
 from crossbench.cli.config.driver import BrowserDriverType
+from crossbench.cli.subcommand.benchmark import BenchmarkSubcommand
 from crossbench.network.local_file_server import LocalFileNetwork
-from crossbench.probes import internal
+from crossbench.probes.internal.summary import ResultsSummaryProbe
+from tests import test_helper
+from tests.crossbench import mock_browser
+from tests.crossbench.base import BaseCliTestCase, SysExitTestException
 
 
 class CliSlowTestCase(BaseCliTestCase):
   """Collection of slower tests that are not worth running
   as part of the presubmit"""
 
-  def test_subcommand_help(self):
-    for benchmark_cls in CrossBenchCLI.BENCHMARKS:
-      subcommands = (benchmark_cls.NAME,) + benchmark_cls.aliases()
+  def get_test_subcommands(self, benchmark_cls) -> Tuple[str, ...]:
+    subcommands = (benchmark_cls.NAME,)
+    # Only test one alias for speeding up testing:
+    if aliases := benchmark_cls.aliases():
+      subcommands = subcommands + (aliases[0],)
+    return subcommands
+
+  def test_subcommand_help_part_1(self):
+    self.verify_subcommand_help(0)
+
+  def test_subcommand_help_part_2(self):
+    self.verify_subcommand_help(1)
+
+  def test_subcommand_help_part_3(self):
+    self.verify_subcommand_help(2)
+
+  def test_subcommand_help_part_4(self):
+    self.verify_subcommand_help(3)
+
+  def test_subcommand_help_part_5(self):
+    self.verify_subcommand_help(4)
+
+  def test_subcommand_help_part_6(self):
+    self.verify_subcommand_help(5)
+
+  def test_subcommand_help_part_7(self):
+    self.verify_subcommand_help(6)
+
+  def test_subcommand_help_part_8(self):
+    self.verify_subcommand_help(7)
+
+  def test_subcommand_help_part_9(self):
+    self.verify_subcommand_help(8)
+
+  def test_subcommand_help_part_10(self):
+    self.verify_subcommand_help(9)
+
+  def verify_subcommand_help(self, chunk: int):
+    for benchmark_cls in CrossBenchCLI.BENCHMARKS[chunk::10]:
+      subcommands = self.get_test_subcommands(benchmark_cls)
       for subcommand in subcommands:
         with self.assertRaises(SysExitTestException) as cm:
           self.run_cli(subcommand, "--help")
@@ -39,9 +76,39 @@ class CliSlowTestCase(BaseCliTestCase):
         self.assertFalse(stderr)
         self.assertIn("--env-validation ENV_VALIDATION", stdout)
 
-  def test_subcommand_help_subcommand(self):
-    for benchmark_cls in CrossBenchCLI.BENCHMARKS:
-      subcommands = (benchmark_cls.NAME,) + benchmark_cls.aliases()
+  def test_subcommand_help_subcommand_part_1(self):
+    self.verify_subcommand_help_subcommand(0)
+
+  def test_subcommand_help_subcommand_part_2(self):
+    self.verify_subcommand_help_subcommand(1)
+
+  def test_subcommand_help_subcommand_part_3(self):
+    self.verify_subcommand_help_subcommand(2)
+
+  def test_subcommand_help_subcommand_part_4(self):
+    self.verify_subcommand_help_subcommand(3)
+
+  def test_subcommand_help_subcommand_part_5(self):
+    self.verify_subcommand_help_subcommand(4)
+
+  def test_subcommand_help_subcommand_part_6(self):
+    self.verify_subcommand_help_subcommand(5)
+
+  def test_subcommand_help_subcommand_part_7(self):
+    self.verify_subcommand_help_subcommand(6)
+
+  def test_subcommand_help_subcommand_part_8(self):
+    self.verify_subcommand_help_subcommand(7)
+
+  def test_subcommand_help_subcommand_part_9(self):
+    self.verify_subcommand_help_subcommand(8)
+
+  def test_subcommand_help_subcommand_part_10(self):
+    self.verify_subcommand_help_subcommand(10)
+
+  def verify_subcommand_help_subcommand(self, chunk: int):
+    for benchmark_cls in CrossBenchCLI.BENCHMARKS[chunk::10]:
+      subcommands = self.get_test_subcommands(benchmark_cls)
       for subcommand in subcommands:
         with self.assertRaises(SysExitTestException) as cm:
           self.run_cli(subcommand, "help")
@@ -51,9 +118,39 @@ class CliSlowTestCase(BaseCliTestCase):
         self.assertFalse(stderr)
         self.assertIn("--env-validation ENV_VALIDATION", stdout)
 
-  def test_subcommand_describe_subcommand(self):
-    for benchmark_cls in CrossBenchCLI.BENCHMARKS:
-      subcommands = (benchmark_cls.NAME,) + benchmark_cls.aliases()
+  def test_subcommand_describe_subcommand_part_1(self):
+    self.verify_subcommand_describe_subcommand(0)
+
+  def test_subcommand_describe_subcommand_part_2(self):
+    self.verify_subcommand_describe_subcommand(1)
+
+  def test_subcommand_describe_subcommand_part_3(self):
+    self.verify_subcommand_describe_subcommand(2)
+
+  def test_subcommand_describe_subcommand_part_4(self):
+    self.verify_subcommand_describe_subcommand(3)
+
+  def test_subcommand_describe_subcommand_part_5(self):
+    self.verify_subcommand_describe_subcommand(4)
+
+  def test_subcommand_describe_subcommand_part_6(self):
+    self.verify_subcommand_describe_subcommand(5)
+
+  def test_subcommand_describe_subcommand_part_7(self):
+    self.verify_subcommand_describe_subcommand(6)
+
+  def test_subcommand_describe_subcommand_part_8(self):
+    self.verify_subcommand_describe_subcommand(7)
+
+  def test_subcommand_describe_subcommand_part_9(self):
+    self.verify_subcommand_describe_subcommand(8)
+
+  def test_subcommand_describe_subcommand_part_10(self):
+    self.verify_subcommand_describe_subcommand(9)
+
+  def verify_subcommand_describe_subcommand(self, chunk: int):
+    for benchmark_cls in CrossBenchCLI.BENCHMARKS[chunk::10]:
+      subcommands = self.get_test_subcommands(benchmark_cls)
       for subcommand in subcommands:
         with self.assertRaises(SysExitTestException) as cm:
           self.run_cli(subcommand, "describe")
@@ -63,7 +160,19 @@ class CliSlowTestCase(BaseCliTestCase):
         output = stderr + stdout
         self.assertIn("See `describe benchmark ", output)
 
-  def test_browser_identifiers(self):
+  def test_browser_identifiers_part_1(self):
+    self.verify_browser_identifiers(0)
+
+  def test_browser_identifiers_part_2(self):
+    self.verify_browser_identifiers(1)
+
+  def test_browser_identifiers_part_3(self):
+    self.verify_browser_identifiers(2)
+
+  def test_browser_identifiers_part_4(self):
+    self.verify_browser_identifiers(3)
+
+  def verify_browser_identifiers(self, chunk: int):
     browsers: Dict[str, Type[mock_browser.MockBrowser]] = {
         "chrome": mock_browser.MockChromeStable,
         "chrome-stable": mock_browser.MockChromeStable,
@@ -97,19 +206,18 @@ class CliSlowTestCase(BaseCliTestCase):
           "tp": mock_browser.MockSafariTechnologyPreview,
       })
 
-    for identifier, browser_cls in browsers.items():
+    items_chunk: List[Tuple[str, Type[mock_browser.MockBrowser]]] = list(
+        browsers.items())[chunk::4]
+    for identifier, browser_cls in items_chunk:
       out_dir = self.out_dir / identifier
       self.assertFalse(out_dir.exists())
-      with mock.patch.object(
-          BrowserVariantsConfig, "get_browser_cls",
-          return_value=browser_cls) as get_browser_cls:
+      with self._patch_get_browser_cls(browser_cls) as get_browser_cls:
         url = "http://test.com"
         self.run_cli("loading", f"--browser={identifier}", f"--urls={url}",
                      "--env-validation=skip", f"--out-dir={out_dir}")
         self.assertTrue(out_dir.exists())
         get_browser_cls.assert_called_once()
-        result_files = list(
-            out_dir.glob(f"**/{internal.ResultsSummaryProbe.NAME}.json"))
+        result_files = list(out_dir.glob(f"**/{ResultsSummaryProbe.NAME}.json"))
         result_file = result_files[1]
         with result_file.open(encoding="utf-8") as f:
           results = json.load(f)
@@ -134,16 +242,20 @@ class CliSlowTestCase(BaseCliTestCase):
 
     def get_browser(self, args: argparse.Namespace):
       session = Settings(
-          platform=self.platform, network=args.network.create(self.platform))
+          platform=self.cli.platform,
+          network=args.network.create(self.cli.platform))
       browsers = [
           mock_browser.MockChromeDev("dev", settings=session),
       ]
       return browsers
 
-    with mock.patch.object(CrossBenchCLI, "_get_browsers", get_browser):
+    with (mock.patch.object(BenchmarkSubcommand, "_get_browsers", get_browser),
+          mock.patch.object(LocalFileNetwork, "_open_local_file_server") as
+          mock_network_open):
       url = "http://test.com"
       self.run_cli("loading", f"--config={config_file}", f"--urls={url}",
                    "--env-validation=skip")
+      mock_network_open.assert_called_once()
       for browser in browsers:
         self.assertListEqual([url], browser.url_list[self.SPLASH_URLS_LEN:])
         assert isinstance(browser.network, LocalFileNetwork)
@@ -161,37 +273,34 @@ class CliSlowTestCase(BaseCliTestCase):
     def mock_get_browser_cls(browser_config: BrowserConfig):
       self.assertEqual(browser_config.driver.type, BrowserDriverType.WEB_DRIVER)
       for mock_browser_cls in mock_browsers:
-        if mock_browser_cls.mock_app_path() == browser_config.path:
+        if mock_browser_cls.mock_app_path(self.platform) == browser_config.path:
           return mock_browser_cls
       raise ValueError("Unknown browser path")
 
     for chrome_flag in ("--js-flags=--no-opt", "--enable-features=Foo",
                         "--disable-features=bar"):
       # Fail for chrome flags for non-chrome browser
-      with self.assertRaises(argparse.ArgumentTypeError), mock.patch.object(
-          BrowserVariantsConfig,
-          "get_browser_cls",
-          side_effect=mock_get_browser_cls):
+      with self.assertRaises(
+          argparse.ArgumentTypeError), self._patch_get_browser_cls(
+              side_effect=mock_get_browser_cls):
         self.run_cli("loading", "--urls=http://test.com",
                      "--env-validation=skip", "--throw", "--browser=firefox",
                      chrome_flag)
       # Fail for mixed browsers and chrome flags
-      with self.assertRaises(argparse.ArgumentTypeError), mock.patch.object(
-          BrowserVariantsConfig,
-          "get_browser_cls",
-          side_effect=mock_get_browser_cls):
+      with self.assertRaises(
+          argparse.ArgumentTypeError), self._patch_get_browser_cls(
+              side_effect=mock_get_browser_cls):
         self.run_cli("loading", "--urls=http://test.com",
                      "--env-validation=skip", "--throw", "--browser=chrome",
                      "--browser=firefox", chrome_flag)
-      with self.assertRaises(argparse.ArgumentTypeError), mock.patch.object(
-          BrowserVariantsConfig,
-          "get_browser_cls",
-          side_effect=mock_get_browser_cls):
+      with self.assertRaises(
+          argparse.ArgumentTypeError), self._patch_get_browser_cls(
+              side_effect=mock_get_browser_cls):
         self.run_cli("loading", "--urls=http://test.com",
                      "--env-validation=skip", "--throw", "--browser=chrome",
                      "--browser=firefox", "--", chrome_flag)
     # Flags for the same type are allowed.
-    with self.patch_get_browser():
+    with self._patch_get_browser():
       self.run_cli("loading", "--urls=http://test.com", "--env-validation=skip",
                    "--throw", "--browser=chrome", "--browser=chrome-dev", "--",
                    "--js-flags=--no-opt")
diff --git a/tests/crossbench/helper/test_path_finder.py b/tests/crossbench/helper/test_path_finder.py
index abbebf1a..4e1f5168 100644
--- a/tests/crossbench/helper/test_path_finder.py
+++ b/tests/crossbench/helper/test_path_finder.py
@@ -8,6 +8,8 @@ from unittest import mock
 
 from crossbench.helper.path_finder import (ChromiumBuildBinaryFinder,
                                            ChromiumCheckoutFinder,
+                                           TraceboxFinder, TraceconvFinder,
+                                           TraceProcessorFinder,
                                            V8CheckoutFinder, V8ToolsFinder)
 from tests import test_helper
 from tests.crossbench.base import BaseCrossbenchTestCase
@@ -113,6 +115,32 @@ class ChromiumBuildBinaryFinderTestCase(BaseCheckoutTestCase):
         candidate)
 
 
+class PerfettoToolFinderTestCase(BaseCheckoutTestCase):
+
+  def test_find_traceconv(self):
+    self._find_tool(TraceconvFinder, "traceconv")
+
+  def test_find_tracebox(self):
+    self._find_tool(TraceboxFinder, "tracebox")
+
+  def test_find_trace_processor(self):
+    self._find_tool(TraceProcessorFinder, "trace_processor")
+
+  def _find_tool(self, finder_cls, name):
+    finder = finder_cls(self.platform)
+    self.assertIsNone(finder.path)
+    self.assertIsNone(finder.path)
+    checkout_dir = pathlib.Path.home() / "Documents/chromium/src"
+    false_candidate = checkout_dir / "third_party/perfetto/tools/another_binary"
+    self.fs.create_file(false_candidate, st_size=100)
+    self.assertIsNone(finder_cls(self.platform).path)
+    candidate = checkout_dir / "third_party/perfetto/tools" / name
+    self.fs.create_file(candidate, st_size=100)
+    self.assertIsNone(finder_cls(self.platform).path)
+    self._add_chrome_checkout_files(checkout_dir)
+    self.assertEqual(finder_cls(self.platform).path, candidate)
+
+
 class V8ToolsFinderTestCase(BaseCheckoutTestCase):
 
   def test_defaults(self):
diff --git a/tests/crossbench/meta_test.py b/tests/crossbench/meta_test.py
new file mode 100644
index 00000000..d9089889
--- /dev/null
+++ b/tests/crossbench/meta_test.py
@@ -0,0 +1,34 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pathlib
+import unittest
+
+from tests import test_helper
+
+RUN_SNIPPET = """
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
+""".strip()
+UNITTEST_DIR = pathlib.Path(__file__).parent
+
+
+class MetaTestCase(unittest.TestCase):
+
+  def test_unittest_runner_snippet(self):
+    # - All unittests files must end with the snippet for the CQ to pick it up.
+    # - pytest files (in end2end) use a different approach that doesn't rely
+    #   on a per-file runner
+    for test_file in UNITTEST_DIR.glob("**/test_*.py"):
+      with self.subTest(test_file=str(test_file)):
+        self.assertTrue(
+            test_file.read_text().rstrip().endswith(RUN_SNIPPET),
+            f"{test_file} misses runner snippet: "
+            "test_helper.run_pytest(__file__)")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/mock_browser.py b/tests/crossbench/mock_browser.py
index 5d34f3c8..716d2231 100644
--- a/tests/crossbench/mock_browser.py
+++ b/tests/crossbench/mock_browser.py
@@ -10,13 +10,16 @@ import copy
 import dataclasses
 import pathlib
 from typing import (TYPE_CHECKING, Any, Iterator, List, Optional, Tuple, Type,
-                    Union, cast)
+                    cast)
+
+from typing_extensions import override
 
 from crossbench import plt
-from crossbench.browsers.all import Chrome, Chromium, Edge, Firefox, Safari
 from crossbench.browsers.attributes import BrowserAttributes
 from crossbench.browsers.browser import Browser
+from crossbench.browsers.chromium.version import ChromiumVersion
 from crossbench.browsers.settings import Settings
+from crossbench.browsers.version import BrowserVersion
 from crossbench.flags.chrome import ChromeFeatures, ChromeFlags
 from crossbench.flags.js_flags import JSFlags
 from crossbench.network.base import Network
@@ -26,7 +29,8 @@ if TYPE_CHECKING:
   import datetime as dt
   import re
 
-  from crossbench.cli.config.secrets import Secret
+  from crossbench import path as pth
+  from crossbench.cli.config.secrets import UsernamePassword
   from crossbench.flags.base import FlagsData
   from crossbench.runner.groups.session import BrowserSessionRunGroup
 
@@ -34,15 +38,17 @@ if TYPE_CHECKING:
 @dataclasses.dataclass(frozen=True)
 class JsInvocation:
   result: Any
-  script: Optional[Union[str, re.Pattern]] = None
-  arguments: Optional[List[Any]] = None
-  timeout: Optional[dt.timedelta] = None
+  script: str | re.Pattern | None = None
+  arguments: List[Any] | None = None
+  timeout: dt.timedelta | None = None
 
 
 class MockNetwork(Network):
 
   @contextlib.contextmanager
-  def open(self, session: BrowserSessionRunGroup) -> Iterator[Network]:
+  @override
+  def open(self: MockNetwork,
+           session: BrowserSessionRunGroup) -> Iterator[MockNetwork]:
     with super().open(session):
       assert session.browser.network is self
       yield self
@@ -81,6 +87,7 @@ class MockBrowser(Browser, metaclass=abc.ABCMeta):
       fs.create_file(bin_path)
 
   @classmethod
+  @override
   def default_flags(cls, initial_data: FlagsData = None) -> ChromeFlags:
     return ChromeFlags(initial_data)
 
@@ -97,12 +104,12 @@ class MockBrowser(Browser, metaclass=abc.ABCMeta):
     super().__init__(label, path, settings=settings)
     self.url_list: List[str] = []
     self.expected_js: List[JsInvocation] = []
-    self.expected_is_logged_in: List[Secret] = []
+    self.expected_is_logged_in: List[UsernamePassword] = []
     self.invoked_js: List[JsInvocation] = []
     self.did_run: bool = False
-    self.clear_cache_dir: bool = False
     self.tab_handler_generator = self._tab_handler_generator()
     self.tab_list: List[int] = [next(self.tab_handler_generator)]
+    self._current_url: str = ""
 
   def expect_js(
       self,
@@ -118,31 +125,42 @@ class MockBrowser(Browser, metaclass=abc.ABCMeta):
   def was_js_invoked(self, script: str) -> bool:
     return any(script is invoked_js.script for invoked_js in self.invoked_js)
 
-  def expect_is_logged_in(self, secret: Secret) -> None:
+  def expect_is_logged_in(self, secret: UsernamePassword) -> None:
     self.expected_is_logged_in.append(secret)
 
-  def clear_cache(self) -> None:
+  @override
+  def _setup_cache_dir(self) -> Optional[pth.AnyPath]:
+    return None
+
+  @override
+  def _clear_cache(self, cache_dir: Optional[pth.AnyPath]) -> None:
     pass
 
+  @override
   def start(self, session: BrowserSessionRunGroup) -> None:
     assert not self._is_running
     self._is_running = True
     self.did_run = True
 
+  @override
   def force_quit(self) -> None:
     if not self._is_running:
       return
     self._is_running = False
 
-  def _extract_version(self) -> str:
-    return self.VERSION
+  @override
+  def _extract_version(self) -> BrowserVersion:
+    return ChromiumVersion.parse(self.VERSION)
 
+  @override
   def user_agent(self) -> str:
-    return f"Mock Browser {self.type_name}, {self.VERSION}"
+    return f"Mock Browser {self.type_name()}, {self.VERSION}"
 
+  @override
   def show_url(self, url, target: Optional[str] = None) -> None:
     self.url_list.append(url)
 
+  @override
   def current_window_id(self) -> str:
     return str(self.tab_list[-1])
 
@@ -152,9 +170,11 @@ class MockBrowser(Browser, metaclass=abc.ABCMeta):
       yield tab_handler
       tab_handler += 1
 
+  @override
   def switch_to_new_tab(self) -> None:
     self.tab_list.append(next(self.tab_handler_generator))
 
+  @override
   def js(self, script, timeout: Optional[dt.timedelta] = None, arguments=()):
     self.invoked_js.append(
         JsInvocation(
@@ -195,15 +215,26 @@ class MockBrowser(Browser, metaclass=abc.ABCMeta):
     # Return copies to avoid leaking data between repetitions.
     return copy.deepcopy(expectation.result)
 
-  def is_logged_in(self, secret: Secret, strict: bool = False) -> bool:
+  @override
+  def is_logged_in(self,
+                   secret: UsernamePassword,
+                   strict: bool = False) -> bool:
     for login in self.expected_is_logged_in:
-      if login.type == secret.type:
+      if type(login) is type(secret):
         if login.username == secret.username:
           return True
         if strict:
           raise RuntimeError("Secret mismatch")
     return False
 
+  def set_current_url(self, url: str) -> None:
+    self._current_url = url
+
+  @property
+  def current_url(self) -> str:
+    return self._current_url
+
+
 def app_root(platform: plt.Platform) -> pathlib.Path:
   if platform.is_macos:
     return pathlib.Path("/Applications")
@@ -212,9 +243,10 @@ def app_root(platform: plt.Platform) -> pathlib.Path:
   return pathlib.Path("/usr/bin")
 
 
-class MockChromiumBrowser(MockBrowser, metaclass=abc.ABCMeta):
+class MockChromiumBasedBrowser(MockBrowser, metaclass=abc.ABCMeta):
 
-  def _setup_flags(self, settings: Settings) -> ChromeFlags:
+  @override
+  def _init_flags(self, settings: Settings) -> ChromeFlags:
     flags = ChromeFlags(settings.flags)
     flags.js_flags.update(settings.js_flags)
     return flags
@@ -226,41 +258,66 @@ class MockChromiumBrowser(MockBrowser, metaclass=abc.ABCMeta):
     return chrome_flags
 
   @property
+  @override
   def js_flags(self) -> JSFlags:
     return self.chrome_flags.js_flags
 
   @property
+  @override
   def features(self) -> ChromeFeatures:
     return self.chrome_flags.features
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
 
 
-# Inject MockBrowser into the browser hierarchy for easier testing.
-Chromium.register(MockChromiumBrowser)
+class MockChromium(MockChromiumBasedBrowser):
+  VERSION = "101.22.33.44"
 
+  @classmethod
+  def mock_app_binary(cls,
+                      platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    if platform.is_macos:
+      return pathlib.Path("Chromium.app/Contents/MacOS/Chromium")
+    if platform.is_win:
+      return pathlib.Path("Google/Chromium/Application/chromium.exe")
+    return pathlib.Path("chromium")
 
-class MockChromeBrowser(MockChromiumBrowser, metaclass=abc.ABCMeta):
+  @classmethod
+  @override
+  def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
+    return app_root(platform) / cls.mock_app_binary(platform)
 
-  @property
-  def type_name(self) -> str:
-    return "chrome"
+  @classmethod
+  # TODO: enable @override again
+  def type_name(cls) -> str:
+    return "chromium"
 
-  @property
-  def attributes(self) -> BrowserAttributes:
-    return BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
+  @classmethod
+  # TODO: enable @override again
+  def attributes(cls) -> BrowserAttributes:
+    return BrowserAttributes.CHROMIUM | BrowserAttributes.CHROMIUM_BASED
 
 
-Chrome.register(MockChromeBrowser)
-if not TYPE_CHECKING:
-  assert issubclass(MockChromeBrowser, Chrome)
+class MockChromeBrowser(MockChromiumBasedBrowser, metaclass=abc.ABCMeta):
+
+  @classmethod
+  # TODO: enable @override again
+  def type_name(cls) -> str:
+    return "chrome"
+
+  @classmethod
+  # TODO: enable @override again
+  def attributes(cls) -> BrowserAttributes:
+    return BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
 
 
 class MockChromeStable(MockChromeBrowser):
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Google Chrome.app"
@@ -269,25 +326,23 @@ class MockChromeStable(MockChromeBrowser):
     return app_root(platform) / "google-chrome"
 
 
-if not TYPE_CHECKING:
-  assert issubclass(MockChromeStable, Chromium)
-  assert issubclass(MockChromeStable, Chrome)
-
-
 class MockChromeAndroidStable(MockChromeStable):
 
   @property
+  @override
   def platform(self) -> AndroidAdbPlatform:
     assert isinstance(
         self._platform,
         AndroidAdbPlatform), (f"Invalid platform: {self._platform}")
     return cast(AndroidAdbPlatform, self._platform)
 
-  def _resolve_binary(self, path: pathlib.Path) -> pathlib.Path:
+  @override
+  def _init_resolve_binary(self, path: pth.AnyPath) -> pth.AnyPath:
     return path
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return (BrowserAttributes.CHROME | BrowserAttributes.CHROMIUM_BASED
             | BrowserAttributes.MOBILE)
 
@@ -296,6 +351,7 @@ class MockChromeBeta(MockChromeBrowser):
   VERSION = "101.22.33.44"
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Google Chrome Beta.app"
@@ -308,6 +364,7 @@ class MockChromeDev(MockChromeBrowser):
   VERSION = "102.22.33.44"
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Google Chrome Dev.app"
@@ -320,6 +377,7 @@ class MockChromeCanary(MockChromeBrowser):
   VERSION = "103.22.33.44"
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Google Chrome Canary.app"
@@ -328,26 +386,23 @@ class MockChromeCanary(MockChromeBrowser):
     return app_root(platform) / "google-chrome-canary"
 
 
-class MockEdgeBrowser(MockChromiumBrowser, metaclass=abc.ABCMeta):
+class MockEdgeBrowser(MockChromiumBasedBrowser, metaclass=abc.ABCMeta):
 
-  @property
-  def type_name(self) -> str:
+  @classmethod
+  @override
+  def type_name(cls) -> str:
     return "edge"
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.EDGE | BrowserAttributes.CHROMIUM_BASED
 
 
-Edge.register(MockEdgeBrowser)
-if not TYPE_CHECKING:
-  assert issubclass(MockEdgeBrowser, Chromium)
-  assert issubclass(MockEdgeBrowser, Edge)
-
-
 class MockEdgeStable(MockEdgeBrowser):
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Microsoft Edge.app"
@@ -360,6 +415,7 @@ class MockEdgeBeta(MockEdgeBrowser):
   VERSION = "101.22.33.44"
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Microsoft Edge Beta.app"
@@ -372,6 +428,7 @@ class MockEdgeDev(MockEdgeBrowser):
   VERSION = "102.22.33.44"
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Microsoft Edge Dev.app"
@@ -384,6 +441,7 @@ class MockEdgeCanary(MockEdgeBrowser):
   VERSION = "103.22.33.44"
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Microsoft Edge Canary.app"
@@ -394,23 +452,21 @@ class MockEdgeCanary(MockEdgeBrowser):
 
 class MockSafariBrowser(MockBrowser, metaclass=abc.ABCMeta):
 
-  @property
-  def type_name(self) -> str:
+  @classmethod
+  @override
+  def type_name(cls) -> str:
     return "safari"
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.SAFARI
 
 
-Safari.register(MockSafariBrowser)
-if not TYPE_CHECKING:
-  assert issubclass(MockSafariBrowser, Safari)
-
-
 class MockSafari(MockSafariBrowser):
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Safari.app"
@@ -422,6 +478,7 @@ class MockSafari(MockSafariBrowser):
 class MockSafariTechnologyPreview(MockSafariBrowser):
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Safari Technology Preview.app"
@@ -432,23 +489,21 @@ class MockSafariTechnologyPreview(MockSafariBrowser):
 
 class MockFirefoxBrowser(MockBrowser, metaclass=abc.ABCMeta):
 
-  @property
-  def type_name(self) -> str:
+  @classmethod
+  @override
+  def type_name(cls) -> str:
     return "firefox"
 
-  @property
-  def attributes(self) -> BrowserAttributes:
+  @classmethod
+  @override
+  def attributes(cls) -> BrowserAttributes:
     return BrowserAttributes.FIREFOX
 
 
-Firefox.register(MockFirefoxBrowser)
-if not TYPE_CHECKING:
-  assert issubclass(MockFirefoxBrowser, Firefox)
-
-
 class MockFirefox(MockFirefoxBrowser):
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Firefox.app"
@@ -460,6 +515,7 @@ class MockFirefox(MockFirefoxBrowser):
 class MockFirefoxDeveloperEdition(MockFirefoxBrowser):
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Firefox Developer Edition.app"
@@ -471,6 +527,7 @@ class MockFirefoxDeveloperEdition(MockFirefoxBrowser):
 class MockFirefoxNightly(MockFirefoxBrowser):
 
   @classmethod
+  @override
   def mock_app_path(cls, platform: plt.Platform = plt.PLATFORM) -> pathlib.Path:
     if platform.is_macos:
       return app_root(platform) / "Firefox Nightly.app"
diff --git a/tests/crossbench/mock_helper.py b/tests/crossbench/mock_helper.py
index 3311c5cb..8c23a0a7 100644
--- a/tests/crossbench/mock_helper.py
+++ b/tests/crossbench/mock_helper.py
@@ -5,23 +5,26 @@
 from __future__ import annotations
 
 import collections
+import dataclasses
 import datetime as dt
+import functools
 import pathlib
 import shlex
-from subprocess import CompletedProcess
-from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Mapping,
-                    Optional, Sequence, Union)
+import subprocess
+from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Mapping, Optional,
+                    Sequence)
 
 import psutil
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench import plt
 from crossbench.benchmarks.base import SubStoryBenchmark
 from crossbench.cli.cli import CrossBenchCLI
 from crossbench.plt.android_adb import Adb, AndroidAdbPlatform
-from crossbench.plt.base import MachineArch, Platform
+from crossbench.plt.base import MachineArch, Platform, SubprocessError
 from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
-from crossbench.plt.linux import LinuxPlatform
+from crossbench.plt.linux import LinuxPlatform, RemoteLinuxPlatform
 from crossbench.plt.linux_ssh import LinuxSshPlatform
 from crossbench.plt.macos import MacOSPlatform
 from crossbench.plt.win import WinPlatform
@@ -29,13 +32,43 @@ from crossbench.runner.run import Run
 from crossbench.stories.story import Story
 
 if TYPE_CHECKING:
-  from crossbench.plt.base import ListCmdArgs, TupleCmdArgs
+  from crossbench.plt.base import CmdArg, ListCmdArgs, TupleCmdArgs
   from crossbench.runner.runner import Runner
 
 
 GIB = 1014**3
 
 
+@dataclasses.dataclass(frozen=True)
+class DownloadMockData:
+  url: str
+  path: pth.AnyPath
+  data: bytes | None = None
+
+
+class ShResult:
+
+  def __init__(self, result: str | bytes = "", success: bool = True) -> None:
+    if isinstance(result, str):
+      result = result.encode("utf-8")
+
+    assert isinstance(result, bytes)
+
+    self._result = result
+    self._success = success
+
+  @property
+  def result(self) -> bytes:
+    return self._result
+
+  @property
+  def stdout(self) -> bytes:
+    return self.result
+
+  @property
+  def success(self) -> bool:
+    return self._success
+
 
 class MockPlatformMixin:
 
@@ -43,26 +76,59 @@ class MockPlatformMixin:
     self._is_battery_powered = is_battery_powered
     # Cache some helper properties that might fail under pyfakefs.
     self._sh_cmds: List[TupleCmdArgs] = []
-    self._expected_sh_cmds: Optional[List[TupleCmdArgs]] = None
-    self._sh_results: List[bytes] = []
+    self._expected_sh_cmds: List[TupleCmdArgs] | None = None
+    self._sh_results: List[ShResult] = []
+    self._download_results: List[DownloadMockData] = []
     self.file_contents: Dict[pth.AnyPath, List[str]] = (
         collections.defaultdict(list))
     self.sleeps: List[dt.timedelta] = []
+    self.use_mock_name = True
+    self.use_fs = False
+    self._machine_arch: [MachineArch] = None  # type: ignore
+    self.popens: List[MockPopen] = []
+    self.mkdir_calls: int = 0
     super().__init__(*args, **kwargs)
 
-  def expect_sh(self,
-                *args: Union[str, pathlib.Path],
-                result: Union[str, bytes] = "") -> None:
+  def os_details(self):
+    return {
+        "system": "mock os system",
+        "release": "mock os release",
+        "version": "mock os version",
+        "platform": "mock os platform",
+    }
+
+  def expect_download(self,
+                      url: str,
+                      path: pth.AnyPath,
+                      data: Optional[bytes] = None):
+    self._download_results.append(DownloadMockData(url, path, data))
+
+  def download_to(self, url: str, path: pth.AnyPath) -> pth.AnyPath:
+    assert self._download_results, (
+        f"No more download test data, but requested: {url}")
+    provided_data = self._download_results.pop()
+    assert url == provided_data.url, (f"Expected download url {url}, "
+                                      f"but got: {provided_data.url}")
+    assert path == provided_data.path, (
+        f"Expected download result path {path}, but got: {provided_data.path}")
+    if provided_data.data:
+      pathlib.Path(path).write_bytes(provided_data.data)
+    else:
+      self.touch(path)
+    return path
+
+  def expect_sh(self, *args: CmdArg,
+                result: str | ShResult = ShResult()) -> None:
     if args:
       if self._expected_sh_cmds is None:
         self._expected_sh_cmds = []
       self._expected_sh_cmds.append(self._convert_sh_args(*args))
     if isinstance(result, str):
-      result = result.encode("utf-8")
-    assert isinstance(result, bytes)
+      result = ShResult(result)
+    assert isinstance(result, ShResult)
     self._sh_results.append(result)
 
-  def _convert_sh_args(self, *args: Union[str, pathlib.Path]) -> TupleCmdArgs:
+  def _convert_sh_args(self, *args: CmdArg) -> TupleCmdArgs:
     converted_args : ListCmdArgs = []
     for arg in args:
       if not isinstance(arg, (str, pathlib.PurePath)):
@@ -71,11 +137,11 @@ class MockPlatformMixin:
     return tuple(converted_args)
 
   @property
-  def sh_results(self) -> List[bytes]:
+  def sh_results(self) -> List[ShResult]:
     return list(self._sh_results)
 
   @sh_results.setter
-  def sh_results(self, results: Iterable[Union[str, bytes]]) -> None:
+  def sh_results(self, results: Iterable[ShResult]) -> None:
     assert not self._sh_results, "Trying to override non-consumed results"
     assert not self._expected_sh_cmds, (
         "expect_sh() cannot be used together with sh_results")
@@ -94,12 +160,20 @@ class MockPlatformMixin:
 
   @property
   def name(self) -> str:
-    return f"mock.{super().name}"
+    if self.use_mock_name:
+      return f"mock.{super().name}"
+    return super().name
 
   @property
   def machine(self) -> MachineArch:
+    if self._machine_arch:
+      return self._machine_arch
     return MachineArch.ARM_64
 
+  @machine.setter
+  def machine(self, value: MachineArch) -> None:
+    self._machine_arch = value
+
   @property
   def version(self) -> str:
     return "1.2.3.4.5"
@@ -119,7 +193,7 @@ class MockPlatformMixin:
   def is_thermal_throttled(self) -> bool:
     return False
 
-  def disk_usage(self, path: pathlib.Path):
+  def disk_usage(self, path: pth.AnyPathLike) -> psutil._common.sdiskusage:
     del path
     # pylint: disable=protected-access
     return psutil._common.sdiskusage(
@@ -128,6 +202,7 @@ class MockPlatformMixin:
   def cpu_usage(self) -> float:
     return 0.1
 
+  @functools.lru_cache(maxsize=1)
   def cpu_details(self) -> Dict[str, Any]:
     return {"physical cores": 2, "logical cores": 4, "info": self.cpu}
 
@@ -135,10 +210,12 @@ class MockPlatformMixin:
                         file: pth.AnyPathLike,
                         data: str,
                         encoding: str = "utf-8") -> None:
-    del encoding
     file_path = self.path(file)
     self.file_contents[file_path].append(data)
+    if self.use_fs:
+      super().set_file_contents(file_path, data, encoding)
 
+  @functools.lru_cache(maxsize=1)
   def system_details(self):
     return {"CPU": "20-core 3.1 GHz"}
 
@@ -167,7 +244,7 @@ class MockPlatformMixin:
     return self.path(f"/usr/bin/{name}")
 
   def sh_stdout_bytes(self,
-                      *args: Union[str, pathlib.Path],
+                      *args: CmdArg,
                       shell: bool = False,
                       quiet: bool = False,
                       stdin=None,
@@ -189,10 +266,15 @@ class MockPlatformMixin:
       cmd = shlex.join(map(str, args))
       raise ValueError(f"After {len(self._sh_cmds)} cmds: "
                        f"MockPlatform has no more sh outputs for cmd: {cmd}")
-    return self._sh_results.pop(0)
+
+    sh_result = self._sh_results.pop(0)
+    if not sh_result.success:
+      raise SubprocessError(self, subprocess.CompletedProcess(args, -1))
+
+    return sh_result.result
 
   def sh(self,
-         *args: Union[str, pathlib.Path],
+         *args: CmdArg,
          shell: bool = False,
          capture_output: bool = False,
          stdout=None,
@@ -200,11 +282,89 @@ class MockPlatformMixin:
          stdin=None,
          env: Optional[Mapping[str, str]] = None,
          quiet: bool = False,
-         check: bool = False):
+         check: bool = True):
     del capture_output, stderr, stdin, stdout
-    self.sh_stdout(*args, shell=shell, quiet=quiet, env=env, check=check)
+    result = self.sh_stdout(
+        *args, shell=shell, quiet=quiet, env=env, check=check)
     # TODO: Generalize this in the future, to mimic failing `sh` calls.
-    return CompletedProcess(args, 0)
+    return subprocess.CompletedProcess(args, 0, stdout=result.encode("utf-8"))
+
+  def popen(self,
+            *args: CmdArg,
+            bufsize=-1,
+            shell: bool = False,
+            stdout=None,
+            stderr=None,
+            stdin=None,
+            env: Optional[Mapping[str, str]] = None,
+            quiet: bool = False) -> MockPopen:
+    del bufsize, stdout, stderr, stdin
+    self.sh_stdout(*args, shell=shell, quiet=quiet, env=env)
+
+    if not self.popens:
+      raise ValueError("No valid mock popen.")
+
+    return self.popens.pop(0)
+
+  def mkdir(self,
+            path: pth.AnyPathLike,
+            parents: bool = True,
+            exist_ok: bool = True) -> None:
+    super().mkdir(path, parents, exist_ok)
+    self.mkdir_calls += 1
+
+
+class MockFd:
+
+  def __init__(self):
+    self.expected_writes: List[bytes] = []
+    self.read_returns: List[bytes] = []
+
+  def __del__(self):
+    assert not self.expected_writes
+    assert not self.read_returns
+
+  def write(self, data: bytes):
+    if not self.expected_writes:
+      raise ValueError("No expected writes.")
+
+    expected = self.expected_writes.pop(0)
+
+    assert data == expected, (
+        f"Expected write does not match. Expected: {expected} Got: {data!r}")
+
+  def readline(self):
+    if not self.read_returns:
+      raise ValueError("No read returns.")
+
+    return self.read_returns.pop(0)
+
+  def flush(self):
+    return
+
+
+class MockPopen:
+
+  def __init__(self, stdout: MockFd, stdin: MockFd):
+    self._stdout: MockFd = stdout
+    self._stdin: MockFd = stdin
+
+  def poll(self):
+    return
+
+  def kill(self):
+    return
+
+  def wait(self):
+    return
+
+  @property
+  def stdin(self):
+    return self._stdin
+
+  @property
+  def stdout(self):
+    return self._stdout
 
 
 class PosixMockPlatformMixin(MockPlatformMixin):
@@ -223,6 +383,10 @@ class LinuxMockPlatform(PosixMockPlatformMixin, LinuxPlatform):
   pass
 
 
+class RemoteLinuxMockPlatform(PosixMockPlatformMixin, RemoteLinuxPlatform):
+  pass
+
+
 class LinuxSshMockPlatform(PosixMockPlatformMixin, LinuxSshPlatform):
   pass
 
@@ -241,12 +405,15 @@ class WinMockPlatform(WinMockPlatformMixin, WinPlatform):
 
 class MockAdb(Adb):
 
+  @override
   def start_server(self) -> None:
     pass
 
+  @override
   def stop_server(self) -> None:
     pass
 
+  @override
   def kill_server(self) -> None:
     pass
 
@@ -272,6 +439,7 @@ else:
 class MockStory(Story):
 
   @classmethod
+  @override
   def all_story_names(cls):
     return ["story_1", "story_2"]
 
@@ -291,20 +459,3 @@ class MockCLI(CrossBenchCLI):
   def __init__(self, *args, **kwargs) -> None:
     self.platform = kwargs.pop("platform")
     super().__init__(*args, **kwargs)
-
-  def _get_runner(self, args, benchmark, env_config, env_validation_mode,
-                  timing):
-    if not args.out_dir:
-      # Use stable mock out dir
-      args.out_dir = pathlib.Path("/results")
-      assert not args.out_dir.exists()
-    runner_kwargs = self.RUNNER_CLS.kwargs_from_cli(args)
-    self.runner = self.RUNNER_CLS(
-        benchmark=benchmark,
-        env_config=env_config,
-        env_validation_mode=env_validation_mode,
-        timing=timing,
-        **runner_kwargs,
-        # Use custom platform
-        platform=self.platform)
-    return self.runner
diff --git a/tests/crossbench/network/test_live.py b/tests/crossbench/network/test_live.py
index 85ff45b8..ed916b9d 100644
--- a/tests/crossbench/network/test_live.py
+++ b/tests/crossbench/network/test_live.py
@@ -23,7 +23,7 @@ class LiveNetworkTestCase(BaseCrossbenchTestCase):
     mock_browser_session = mock.Mock()
     with network.open(mock_browser_session):
       self.assertTrue(network.is_running)
-      self.assertFalse(network.extra_flags(self.browsers[0].attributes))
+      self.assertFalse(network.extra_flags(self.browsers[0].attributes()))
       # Should not be able to double open the network.
       with self.assertRaises(AssertionError):
         with network.open(mock_browser_session):
diff --git a/tests/crossbench/network/test_ts_proxy.py b/tests/crossbench/network/test_ts_proxy.py
index 1aa2e6ed..dd784351 100644
--- a/tests/crossbench/network/test_ts_proxy.py
+++ b/tests/crossbench/network/test_ts_proxy.py
@@ -3,18 +3,24 @@
 # found in the LICENSE file.
 
 import argparse
+import contextlib
 import pathlib
 from unittest import mock
 
+from typing_extensions import override
+
+from crossbench.network.base import Network
 from crossbench.network.traffic_shaping.ts_proxy import (TsProxyProcess,
                                                          TsProxyServer,
                                                          TsProxyTrafficShaper)
+from crossbench.runner.groups.session import BrowserSessionRunGroup
 from tests import test_helper
 from tests.crossbench.base import BaseCrossbenchTestCase
 
 
 class TsProxyBaseTestCase(BaseCrossbenchTestCase):
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.ts_proxy_path = pathlib.Path("/chrome/tsproxy/tsproxy.py")
@@ -25,8 +31,35 @@ class TsProxyBaseTestCase(BaseCrossbenchTestCase):
     self.addCleanup(patcher.stop)
     patcher.start()
 
+  @contextlib.contextmanager
+  def startup_process_mock(self):
+    proc = mock.Mock()
+    proc.configure_mock(**{
+        "poll.return_value": None,
+        "communicate.return_value": (None, None)
+    })
+    proc.stdout = mock.Mock()
+    proc.stdout.configure_mock(**{
+        "readline.return_value":
+            "Started Socks5 proxy server on 127.0.0.1:43210"
+    })
+    proc.stderr = mock.Mock()
+
+    def popen_mock(cmd, *args, **kwargs):
+      self.assertEqual(cmd[1], self.ts_proxy_path)
+      self.assertEqual(cmd[2], "--port=0")
+      del args, kwargs
+      return proc
+
+    with mock.patch("subprocess.Popen", side_effect=popen_mock) as mock_popen:
+      with mock.patch.object(self.platform,
+                             "terminate_gracefully") as terminate_gracefully:
+        yield proc
+    mock_popen.assert_called_once()
+    terminate_gracefully.assert_called_once()
 
-class TsProxyTestCase(TsProxyBaseTestCase):
+
+class TsProxyTrafficShaperTestCase(TsProxyBaseTestCase):
 
   def test_ts_proxy_traffic_shaper_no_tsproxy(self):
     with self.assertRaises(RuntimeError):
@@ -36,15 +69,85 @@ class TsProxyTestCase(TsProxyBaseTestCase):
     ts_proxy = TsProxyTrafficShaper(self.platform, self.ts_proxy_path)
     self.assertFalse(ts_proxy.is_running)
 
+  def test_ts_proxy_open(self):
+    ts_proxy = TsProxyTrafficShaper(self.platform, self.ts_proxy_path)
+    network = Network(ts_proxy, self.platform)
+    session = mock.Mock(spec=BrowserSessionRunGroup)
+
+    with self.startup_process_mock() as proc:
+      with ts_proxy.open(network, session):
+        self.assertTrue(ts_proxy.is_running)
+        self.assertEqual(proc.stdout.readline.call_count, 1)
+        proc.stdout.readline.return_value = "OK"
+    proc.stdin.write.assert_called_with("exit\n")
+    self.assertEqual(proc.stdout.readline.call_count, 2)
+
+  def test_ts_proxy_pause(self):
+    ts_proxy = TsProxyTrafficShaper(self.platform, self.ts_proxy_path)
+    network = Network(ts_proxy, self.platform)
+    session = mock.Mock(spec=BrowserSessionRunGroup)
+
+    with self.startup_process_mock() as proc:
+      with ts_proxy.open(network, session):
+        self.assertTrue(ts_proxy.is_running)
+        self.assertEqual(proc.stdout.readline.call_count, 1)
+        # All setting updates are "OK"
+        proc.stdout.readline.return_value = "OK"
+        with ts_proxy.pause():
+          self.assertEqual(proc.stdout.readline.call_count, 4)
+          self.assertTrue(ts_proxy.is_running)
+        self.assertTrue(ts_proxy.is_running)
+        # Default settings are already set.
+        self.assertEqual(proc.stdout.readline.call_count, 4)
+    self.assertEqual(proc.stdout.readline.call_count, 5)
+    proc.stdin.write.assert_called_with("exit\n")
+
+  def test_ts_proxy_pause_custom(self):
+    ts_proxy = TsProxyTrafficShaper(
+        self.platform,
+        self.ts_proxy_path,
+        rtt_ms=101,
+        in_kbps=102,
+        out_kbps=103)
+    network = Network(ts_proxy, self.platform)
+    session = mock.Mock(spec=BrowserSessionRunGroup)
+
+    with self.startup_process_mock() as proc:
+      with ts_proxy.open(network, session):
+        stdout_readline = proc.stdout.readline
+        stdin_write = proc.stdin.write
+
+        self.assertTrue(ts_proxy.is_running)
+        self.assertEqual(stdout_readline.call_count, 1)
+        stdout_readline.reset_mock()
+        # All setting updates are "OK"
+        stdout_readline.return_value = "OK"
+
+        with ts_proxy.pause():
+          self.assertEqual(stdout_readline.call_count, 3)
+          stdin_write.assert_any_call("set rtt 0\n")
+          stdin_write.assert_any_call("set inkbps 0\n")
+          stdin_write.assert_any_call("set outkbps 0\n")
+          self.assertTrue(ts_proxy.is_running)
+
+        self.assertEqual(stdout_readline.call_count, 6)
+        stdin_write.assert_any_call("set rtt 101\n")
+        stdin_write.assert_any_call("set inkbps 102\n")
+        stdin_write.assert_any_call("set outkbps 103\n")
+        stdout_readline.reset_mock()
+        stdin_write.reset_mock()
+    stdout_readline.assert_called_once()
+    stdin_write.assert_called_once_with("exit\n")
+
 
 class TsProxyServerTestCase(TsProxyBaseTestCase):
 
   def test_construct_invalid(self):
     with self.assertRaises(argparse.ArgumentTypeError):
-      TsProxyServer(pathlib.Path("does/not/exist"))
+      TsProxyServer(self.platform, pathlib.Path("does/not/exist"))
 
   def test_basic_instance(self):
-    server = TsProxyServer(self.ts_proxy_path)
+    server = TsProxyServer(self.platform, self.ts_proxy_path)
     self.assertFalse(server.is_running)
 
     with self.assertRaises(AssertionError):
@@ -54,7 +157,7 @@ class TsProxyServerTestCase(TsProxyBaseTestCase):
     self.assertIsNone(server.stop())
 
   def test_basic_instance_http_port(self):
-    server = TsProxyServer(self.ts_proxy_path, http_port=8080)
+    server = TsProxyServer(self.platform, self.ts_proxy_path, http_port=8080)
     self.assertFalse(server.is_running)
     with self.assertRaises(AssertionError):
       _ = server.socks_proxy_port
@@ -62,36 +165,20 @@ class TsProxyServerTestCase(TsProxyBaseTestCase):
 
   def test_ports(self):
     with self.assertRaises(ValueError):
-      TsProxyServer(self.ts_proxy_path, https_port=400)
+      TsProxyServer(self.platform, self.ts_proxy_path, https_port=400)
     with self.assertRaises(ValueError):
-      TsProxyServer(self.ts_proxy_path, http_port=400, https_port=400)
+      TsProxyServer(
+          self.platform, self.ts_proxy_path, http_port=400, https_port=400)
     with self.assertRaises(argparse.ArgumentTypeError):
-      TsProxyServer(self.ts_proxy_path, http_port=-400, https_port=400)
+      TsProxyServer(
+          self.platform, self.ts_proxy_path, http_port=-400, https_port=400)
     with self.assertRaises(argparse.ArgumentTypeError):
-      TsProxyServer(self.ts_proxy_path, http_port=400, https_port=-400)
+      TsProxyServer(
+          self.platform, self.ts_proxy_path, http_port=400, https_port=-400)
 
   def test_start_server(self):
-    server = TsProxyServer(self.ts_proxy_path)
-
-    proc = mock.Mock()
-    proc.configure_mock(**{
-        "poll.return_value": None,
-        "communicate.return_value": (None, None)
-    })
-    proc.stdout = mock.Mock()
-    proc.stdout.configure_mock(**{
-        "readline.return_value":
-            "Started Socks5 proxy server on 127.0.0.1:43210"
-    })
-    proc.stderr = mock.Mock()
-
-    def popen_mock(cmd, *args, **kwargs):
-      self.assertEqual(cmd[1], self.ts_proxy_path)
-      self.assertEqual(cmd[2], "--port=0")
-      del args, kwargs
-      return proc
-
-    with mock.patch("subprocess.Popen", side_effect=popen_mock) as popen:
+    server = TsProxyServer(self.platform, self.ts_proxy_path)
+    with self.startup_process_mock() as proc:
       self.assertFalse(server.is_running)
       with server:
         self.assertTrue(server.is_running)
@@ -100,8 +187,6 @@ class TsProxyServerTestCase(TsProxyBaseTestCase):
         # Set return value for exit command.
         proc.stdout.readline.return_value = "OK"
       self.assertFalse(server.is_running)
-
-    popen.assert_called_once()
     proc.stdin.write.assert_called_with("exit\n")
 
 
diff --git a/tests/crossbench/plt/helper.py b/tests/crossbench/plt/helper.py
index 0f2f03f1..72d574e7 100644
--- a/tests/crossbench/plt/helper.py
+++ b/tests/crossbench/plt/helper.py
@@ -5,8 +5,14 @@
 from __future__ import annotations
 
 import abc
+import argparse
 import pathlib
+import unittest
+from unittest import mock
 
+from typing_extensions import override
+
+import crossbench.path as pth
 from crossbench import plt
 from crossbench.plt.posix import PosixPlatform
 from tests.crossbench.base import CrossbenchFakeFsTestCase
@@ -18,10 +24,18 @@ class BaseMockPlatformTestCase(CrossbenchFakeFsTestCase, metaclass=abc.ABCMeta):
   platform: plt.Platform
   mock_platform: MockPlatform
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.mock_platform_setup()
 
+  def mock_platform_str(self, platform, name) -> None:
+    # Mock out str(platform) to avoid secondary errors when printing the
+    # platform name in failing tests.
+    patcher = mock.patch.object(type(platform), "__str__", return_value=name)
+    self.addCleanup(patcher.stop)
+    patcher.start()
+
   def mock_platform_setup(self):
     self.mock_platform = MockPlatform()  # pytype: disable=not-instantiable
     self.platform = self.mock_platform
@@ -57,10 +71,40 @@ class BaseMockPlatformTestCase(CrossbenchFakeFsTestCase, metaclass=abc.ABCMeta):
   def test_is_chromeos(self):
     self.assertFalse(self.platform.is_chromeos)
 
+  def test_port_forward_invalid(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "local_port"):
+      self.platform.port_forward(-1, -1)
+
+  def test_reverse_port_forward_invalid(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "remote_port"):
+      self.platform.reverse_port_forward(-1, -1)
+
+
+class BaseLocalMockPlatformTestMixin:
+
+  def test_local_port_forward_invalid(self):
+    with self.assertRaisesRegex(ValueError, "local platform"):
+      self.platform.port_forward(1000, 2000)
+
+  def test_local_reverse_port_forward_invalid(self):
+    with self.assertRaisesRegex(ValueError, "local platform"):
+      self.platform.reverse_port_forward(1000, 2000)
+
+  def test_local_reverse_port_forward(self):
+    port = self.platform.get_free_port()
+    self.assertEqual(self.platform.reverse_port_forward(port, port), port)
+    self.platform.stop_reverse_port_forward(port)
+
+  def test_local_port_forward(self):
+    port = self.platform.get_free_port()
+    self.assertEqual(self.platform.port_forward(port, port), port)
+    self.platform.stop_port_forward(port)
+
 
 class BasePosixMockPlatformTestCase(BaseMockPlatformTestCase):
   platform: PosixPlatform
 
+  @override
   def tearDown(self) -> None:
     assert isinstance(self.platform, PosixPlatform)
     super().tearDown()
@@ -78,3 +122,21 @@ class BasePosixMockPlatformTestCase(BaseMockPlatformTestCase):
     self.assertIsInstance(
         self.platform.path(pathlib.PurePosixPath("foo/bar")),
         pathlib.PurePosixPath)
+
+  @unittest.skipUnless(plt.PLATFORM.is_win, "Incompatible platform")
+  def test_win_absolute_path_conversion(self):
+    windows_path = pth.AnyWindowsPath("/foo/bar/file")
+    abs_path = self.platform.absolute(windows_path)
+    self.assertEqual(str(abs_path), "/foo/bar/file")
+    self.assertIsInstance(abs_path, pth.AnyPosixPath)
+    self.assertTrue(abs_path.is_absolute())
+    self.assertTrue(self.platform.is_absolute(abs_path))
+
+  @unittest.skipUnless(plt.PLATFORM.is_win, "Incompatible platform")
+  def test_win_absolute_path_conversion_drive(self):
+    windows_path = pth.AnyWindowsPath("C:/foo/bar/file")
+    abs_path = self.platform.absolute(windows_path)
+    self.assertEqual(str(abs_path), "/foo/bar/file")
+    self.assertIsInstance(abs_path, pth.AnyPosixPath)
+    self.assertTrue(abs_path.is_absolute())
+    self.assertTrue(self.platform.is_absolute(abs_path))
diff --git a/tests/crossbench/plt/test_android_adb.py b/tests/crossbench/plt/test_android_adb.py
index 709e58f4..40233b8b 100644
--- a/tests/crossbench/plt/test_android_adb.py
+++ b/tests/crossbench/plt/test_android_adb.py
@@ -4,12 +4,16 @@
 
 from __future__ import annotations
 
+import argparse
 import pathlib
+import textwrap
 import unittest
 from typing import Final
-from unittest import mock
+from unittest import mock, skipIf
 
+import pyfakefs
 from pyfakefs.fake_filesystem import OSType
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.plt.android_adb import Adb, AndroidAdbPlatform
@@ -44,11 +48,16 @@ class BaseAndroidAdbMockPlatformTestCase(BasePosixMockPlatformTestCase):
   DEVICE_ID = "emulator-5554"
   platform: AndroidAdbPlatform
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.adb_setup()
     self.platform = AndroidAdbPlatform(
         self.mock_platform, self.DEVICE_ID, adb=self.adb)
+    self.mock_platform_str(self.platform, "adb.mock_platform.arm64")
+
+  def test_str(self):
+    self.assertEqual(str(self.platform), "adb.mock_platform.arm64")
 
   def adb_setup(self):
     adb_patcher = mock.patch(
@@ -70,15 +79,33 @@ class BaseAndroidAdbMockPlatformTestCase(BasePosixMockPlatformTestCase):
   def test_is_android(self):
     self.assertTrue(self.platform.is_android)
 
-
+  def test_is_battery_powered(self):
+    dumpsys_battery_output = textwrap.dedent("""
+      AC powered: false
+      USB powered: false
+      Wireless powered: true
+      Max charging current: 3000000
+    """)
+    self.expect_adb("shell", "dumpsys battery", result=dumpsys_battery_output)
+    self.assertFalse(self.platform.is_battery_powered)
+    dumpsys_battery_output = textwrap.dedent("""
+      AC powered: false
+      USB powered: false
+      Wireless powered: false
+      Max charging current: 3000000
+    """)
+    self.expect_adb("shell", "dumpsys battery", result=dumpsys_battery_output)
+    self.assertTrue(self.platform.is_battery_powered)
 
 class AndroidAdbOnWinMockPlatformTestCase(BaseAndroidAdbMockPlatformTestCase):
   __test__ = True
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.fs.os = OSType.WINDOWS
 
+  @override
   def mock_platform_setup(self):
     self.mock_platform = WinMockPlatform()
 
@@ -97,8 +124,8 @@ class AndroidAdbOnWinMockPlatformTestCase(BaseAndroidAdbMockPlatformTestCase):
   def test_mktemp(self):
     self.assertTrue(self.platform.default_tmp_dir.is_absolute())
     self.assertIsInstance(self.platform.default_tmp_dir, pathlib.PurePosixPath)
-    self.expect_adb("shell", "mktemp", "-d",
-                    "/data/local/tmp/custom_prefix.XXXXXXXXXXX")
+    self.expect_adb("shell",
+                    "mktemp -d  /data/local/tmp/custom_prefix.XXXXXXXXXXX")
     self.platform.mkdtemp("custom_prefix")
 
   @unittest.skip(
@@ -187,59 +214,60 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
     self.assertTrue(self.adb.has_root())
 
   def test_version(self):
-    self.expect_adb(
-        "shell", "getprop", "ro.build.version.release", result="999")
+    self.expect_adb("shell", "getprop ro.build.version.release", result="999")
     self.assertEqual(self.platform.version, "999")
     # Subsequent calls are cached.
     self.assertEqual(self.platform.version, "999")
 
   def test_device(self):
-    self.expect_adb("shell", "getprop", "ro.product.model", result="Pixel 999")
+    self.expect_adb("shell", "getprop ro.product.model", result="Pixel 999")
     self.assertEqual(self.platform.device, "Pixel 999")
     # Subsequent calls are cached.
     self.assertEqual(self.platform.device, "Pixel 999")
 
   def test_cpu(self):
     self.expect_adb(
-        "shell", "getprop", "dalvik.vm.isa.arm.variant", result="cortex-a999")
-    self.expect_adb("shell", "getprop", "ro.board.platform", result="msmnile")
-    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile")
+        "shell", "getprop dalvik.vm.isa.arm.variant", result="cortex-a999")
+    self.expect_adb("shell", "getprop ro.board.platform", result="msmnile")
+    cpu_info = "processor       : 0\nprocessor       : 1"
+    self.expect_adb(
+        "shell",
+        "grep -E 'processor|core id|physical id' /proc/cpuinfo",
+        result=cpu_info)
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 2 cores")
     # Subsequent calls are cached.
-    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile")
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 2 cores")
 
   def test_cpu_detailed(self):
     self.expect_adb(
-        "shell", "getprop", "dalvik.vm.isa.arm.variant", result="cortex-a999")
-    self.expect_adb("shell", "getprop", "ro.board.platform", result="msmnile")
+        "shell", "getprop dalvik.vm.isa.arm.variant", result="cortex-a999")
+    self.expect_adb("shell", "getprop ro.board.platform", result="msmnile")
+    cpu_info = "processor       : 0\nprocessor       : 1"
     self.expect_adb(
         "shell",
-        "cat",
-        self.platform.path("/sys/devices/system/cpu/possible"),
-        result="0-998")
-    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 999 cores")
+        "grep -E 'processor|core id|physical id' /proc/cpuinfo",
+        result=cpu_info)
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 2 cores")
     # Subsequent calls are cached.
-    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 999 cores")
+    self.assertEqual(self.platform.cpu, "cortex-a999 msmnile 2 cores")
 
   def test_adb(self):
     self.assertIs(self.platform.adb, self.adb)
 
   def test_machine_unknown(self):
-    self.expect_adb(
-        "shell", "getprop", "ro.product.cpu.abi", result="arm37-XXX")
+    self.expect_adb("shell", "getprop ro.product.cpu.abi", result="arm37-XXX")
     with self.assertRaises(ValueError) as cm:
       self.assertEqual(self.platform.machine, MachineArch.ARM_64)
     self.assertIn("arm37-XXX", str(cm.exception))
 
   def test_machine_arm64(self):
-    self.expect_adb(
-        "shell", "getprop", "ro.product.cpu.abi", result="arm64-v8a")
+    self.expect_adb("shell", "getprop ro.product.cpu.abi", result="arm64-v8a")
     self.assertEqual(self.platform.machine, MachineArch.ARM_64)
     # Subsequent calls are cached.
     self.assertEqual(self.platform.machine, MachineArch.ARM_64)
 
   def test_machine_arm32(self):
-    self.expect_adb(
-        "shell", "getprop", "ro.product.cpu.abi", result="armeabi-v7a")
+    self.expect_adb("shell", "getprop ro.product.cpu.abi", result="armeabi-v7a")
     self.assertEqual(self.platform.machine, MachineArch.ARM_32)
     # Subsequent calls are cached.
     self.assertEqual(self.platform.machine, MachineArch.ARM_32)
@@ -248,16 +276,13 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
     path = pathlib.Path("path/to/app.bin")
     with self.assertRaises(ValueError) as cm:
       self.platform.app_path_to_package(path)
-    self.assertIn(str(path), str(cm.exception))
+    self.assertIn(str(self.platform.path(path)), str(cm.exception))
 
   def test_app_path_to_package_not_installed(self):
     with self.assertRaises(ValueError) as cm:
       self.expect_adb(
           "shell",
-          "cmd",
-          "package",
-          "list",
-          "packages",
+          "cmd package list packages",
           result=("package:com.google.android.wifi.resources\n"
                   "package:com.google.android.GoogleCamera"))
       self.platform.app_path_to_package(pathlib.Path("com.custom.app"))
@@ -268,10 +293,7 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
     path = pathlib.Path("com.custom.app")
     self.expect_adb(
         "shell",
-        "cmd",
-        "package",
-        "list",
-        "packages",
+        "cmd package list packages",
         result=("package:com.google.android.wifi.resources\n"
                 "package:com.custom.app"))
     self.assertEqual(self.platform.app_path_to_package(path), "com.custom.app")
@@ -279,31 +301,17 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
   def test_app_version(self):
     path = pathlib.Path("com.custom.app")
     self.expect_adb(
-        "shell",
-        "cmd",
-        "package",
-        "list",
-        "packages",
-        result="package:com.custom.app")
+        "shell", "cmd package list packages", result="package:com.custom.app")
     self.expect_adb(
-        "shell",
-        "dumpsys",
-        "package",
-        "com.custom.app",
-        result="versionName=9.999")
+        "shell", "dumpsys package com.custom.app", result="versionName=9.999")
     self.assertEqual(self.platform.app_version(path), "9.999")
 
-  def test_app_version_unkown(self):
+  def test_app_version_unknown(self):
     path = pathlib.Path("com.custom.app")
     self.expect_adb(
-        "shell",
-        "cmd",
-        "package",
-        "list",
-        "packages",
-        result="package:com.custom.app")
+        "shell", "cmd package list packages", result="package:com.custom.app")
     self.expect_adb(
-        "shell", "dumpsys", "package", "com.custom.app", result="something")
+        "shell", "dumpsys package com.custom.app", result="something")
     with self.assertRaises(ValueError) as cm:
       self.platform.app_version(path)
     self.assertIn("something", str(cm.exception))
@@ -340,9 +348,8 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
 
   def test_search_binary(self):
     ls_path = self.platform.path("/system/bin/ls")
-    self.expect_adb(
-        "shell", "which", self.platform.path("ls"), result=str(ls_path))
-    self.expect_adb("shell", "[", "-e", ls_path, "]", result="")
+    self.expect_adb("shell", "which ls", result=str(ls_path))
+    self.expect_adb("shell", f"'[' -e {ls_path} ']'", result="")
     path = self.platform.search_binary("ls")
     self.assertEqual(str(path), str(ls_path))
 
@@ -351,27 +358,23 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
     ls_path = self.platform.path("ls")
     override_path = self.platform.path("/root/sbin/ls")
     # override_binary checks if the result binary exists.
-    self.expect_adb("shell", "which", override_path, result=str(override_path))
-    self.expect_adb("shell", "[", "-e", override_path, "]", result="")
+    self.expect_adb(
+        "shell", f"which {override_path}", result=str(override_path))
+    self.expect_adb("shell", f"'[' -e {override_path} ']'", result="")
     with self.platform.override_binary(ls_path, override_path):
       path = self.platform.search_binary("ls")
       self.assertEqual(path, override_path)
 
   def test_search_binary_app_package_non(self):
-    self.expect_adb(
-        "shell", "which", self.platform.path("com.google.chrome"), result="")
-    self.expect_adb("shell", "cmd", "package", "list", "packages", result="")
+    self.expect_adb("shell", "which com.google.chrome", result="")
+    self.expect_adb("shell", "cmd package list packages", result="")
     path = self.platform.search_binary("com.google.chrome")
     self.assertIsNone(path)
 
-    self.expect_adb(
-        "shell", "which", self.platform.path("com.google.chrome"), result="")
+    self.expect_adb("shell", "which com.google.chrome", result="")
     self.expect_adb(
         "shell",
-        "cmd",
-        "package",
-        "list",
-        "packages",
+        "cmd package list packages",
         result="package:com.google.chrome")
     path = self.platform.search_binary("com.google.chrome")
     self.assertEqual(path, pathlib.PurePosixPath("com.google.chrome"))
@@ -379,14 +382,9 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
   def test_search_binary_app_package_lookup_override(self):
     chrome_package = self.platform.path("com.google.chrome")
     chrome_dev_package = self.platform.path("com.chrome.dev")
-    self.expect_adb("shell", "which", chrome_dev_package, result="")
+    self.expect_adb("shell", f"which {chrome_dev_package}", result="")
     self.expect_adb(
-        "shell",
-        "cmd",
-        "package",
-        "list",
-        "packages",
-        result="package:com.chrome.dev")
+        "shell", "cmd package list packages", result="package:com.chrome.dev")
     with self.platform.override_binary(chrome_package, chrome_dev_package):
       path = self.platform.search_binary(chrome_package)
       self.assertEqual(chrome_dev_package, path)
@@ -394,8 +392,8 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
   def test_override_binary_non_existing_package(self):
     chrome_package = self.platform.path("com.google.chrome")
     chrome_dev_package = self.platform.path("com.chrome.dev")
-    self.expect_adb("shell", "which", chrome_dev_package, result="")
-    self.expect_adb("shell", "cmd", "package", "list", "packages", result="")
+    self.expect_adb("shell", f"which {chrome_dev_package}", result="")
+    self.expect_adb("shell", "cmd package list packages", result="")
     with self.assertRaises(ValueError) as cm:
       with self.platform.override_binary(chrome_package, chrome_dev_package):
         pass
@@ -408,15 +406,17 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
       self.platform.home()
 
   def test_get_main_display_brightness(self):
-    self.expect_adb(
-        "shell", "dumpsys", "display", result=DUMPSYS_DISPLAY_OUTPUT)
+    self.expect_adb("shell", "dumpsys display", result=DUMPSYS_DISPLAY_OUTPUT)
     brightness = self.platform.get_main_display_brightness()
     self.assertEqual(brightness, 16)
 
+  @skipIf(
+      tuple(map(int, pyfakefs.__version__.split("."))) < (5, 5),
+      "pth.AnyWindowsPath does not work correctly with older pyfakefs")
   def test_iterdir(self):
-    self.expect_adb("shell", "[", "-d", "parent_dir/child_dir", "]")
+    self.expect_adb("shell", "'[' -d parent_dir/child_dir ']'")
     self.expect_adb(
-        "shell", "ls", "-1", "parent_dir/child_dir", result="file1\nfile2\n")
+        "shell", "ls -1 parent_dir/child_dir", result="file1\nfile2\n")
 
     self.assertSetEqual(
         set(self.platform.iterdir(pth.AnyWindowsPath("parent_dir\\child_dir"))),
@@ -425,6 +425,79 @@ class AndroidAdbMockPlatformTest(BaseAndroidAdbMockPlatformTestCase):
             pth.AnyPosixPath("parent_dir/child_dir/file2")
         })
 
+  def test_cat_file(self):
+    self.expect_adb("shell", "cat path/to/a/file")
+    self.platform.cat(self.platform.path("path/to/a/file"))
+    self.expect_adb("shell", "cat 'path/with a space/to/a/file'")
+    self.platform.cat(self.platform.path("path/with a space/to/a/file"))
+
+  def test_sh_shell_invalid(self):
+    with self.assertRaisesRegex(ValueError, "shell=True"):
+      self.platform.sh_stdout("ls", "folder with space", shell=True)
+
+  def test_sh_shell(self):
+    self.expect_adb("shell", "ls sdcard", result="FILE1\nFILE2\n")
+    self.assertEqual(self.platform.sh_stdout("ls", "sdcard"), "FILE1\nFILE2\n")
+
+    self.expect_adb("shell", "ls 'folder with space'", result="FOLDER\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls", "folder with space"), "FOLDER\n")
+
+    self.expect_adb("shell", "'ls foo && ls bar'", result="FILE1\nFILE2\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls foo && ls bar"), "FILE1\nFILE2\n")
+
+    self.expect_adb("shell", "ls foo && ls bar", result="FILE1\nFILE2\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls foo && ls bar", shell=True),
+        "FILE1\nFILE2\n")
+
+    self.expect_adb("shell", "ls foo '&&' ls bar", result="FILE1\nFILE2\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls", "foo", "&&", "ls", "bar"),
+        "FILE1\nFILE2\n")
+
+  def test_port_forward(self):
+    self.expect_adb("forward", "tcp:0", "tcp:33221", result="666")
+    self.expect_adb("forward", "--remove", "tcp:666")
+    port = self.platform.port_forward(0, 33221)
+    self.assertEqual(port, 666)
+    self.platform.stop_port_forward(port)
+
+  def test_reverse_port_forward(self):
+    self.expect_adb("reverse", "tcp:0", "tcp:33221", result="666")
+    self.expect_adb("reverse", "--remove", "tcp:666")
+    port = self.platform.reverse_port_forward(0, 33221)
+    self.assertEqual(port, 666)
+    self.platform.stop_reverse_port_forward(port)
+
+  def test_port_forward_invalid(self):
+    super().test_port_forward_invalid()
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "remote_port"):
+      self.platform.port_forward(1111, 0)
+
+  def test_reverse_port_forward_invalid(self):
+    super().test_reverse_port_forward_invalid()
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "local_port"):
+      self.platform.reverse_port_forward(1111, 0)
+
+  def test_display_resolution(self):
+    self.expect_adb(
+        "shell",
+        "dumpsys window displays",
+        result="WINDOW MANAGER DISPLAY CONTENTS (dumpsys window displays)\n"
+        "Display: mDisplayId=0 (organized)\n"
+        "init=1366x768 136dpi mMinSizeOfResizeableTaskDp=220 "
+        "cur=1366x768 app=1366x768 rng=768x768-1366x1366\n"
+        "deferred=false mLayoutNeeded=false")
+    [horizontal, vertical] = self.platform.display_resolution()
+    self.assertEqual(horizontal, 1366)
+    self.assertEqual(vertical, 768)
+
+  def test_user_id(self):
+    self.expect_adb("shell", "am get-current-user", result="10")
+    self.assertEqual(self.platform.user_id(), 10)
+
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_platform.py b/tests/crossbench/plt/test_arch.py
similarity index 97%
rename from tests/crossbench/plt/test_platform.py
rename to tests/crossbench/plt/test_arch.py
index 356b8ebf..f7c681a7 100644
--- a/tests/crossbench/plt/test_platform.py
+++ b/tests/crossbench/plt/test_arch.py
@@ -6,7 +6,7 @@ from __future__ import annotations
 
 import unittest
 
-from crossbench.plt import MachineArch
+from crossbench.plt.arch import MachineArch
 from tests import test_helper
 
 
diff --git a/tests/crossbench/plt/test_bin.py b/tests/crossbench/plt/test_bin.py
index f7c1abb2..ad395ccd 100644
--- a/tests/crossbench/plt/test_bin.py
+++ b/tests/crossbench/plt/test_bin.py
@@ -9,19 +9,25 @@ import pathlib
 import unittest
 from unittest import mock
 
+from pyfakefs.fake_filesystem import OSType
+from typing_extensions import override
+
 import crossbench.path as pth
 from crossbench import plt
 from crossbench.plt import PLATFORM
-from crossbench.plt.bin import (Binary, BinaryNotFoundError, LinuxBinary,
-                                MacOsBinary, PosixBinary, WinBinary)
+from crossbench.plt.bin import (Binary, BinaryNotFoundError, ChromeOSBinary,
+                                LinuxBinary, MacOsBinary, PosixBinary,
+                                WinBinary)
 from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
-from tests.crossbench.mock_helper import (LinuxMockPlatform, MacOsMockPlatform,
+from tests.crossbench.mock_helper import (ChromeOsSshMockPlatform,
+                                          LinuxMockPlatform, MacOsMockPlatform,
                                           WinMockPlatform)
 
 
 class BinaryTestCase(CrossbenchFakeFsTestCase):
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self._all_mock_platforms = (
@@ -142,6 +148,44 @@ class BinaryTestCase(CrossbenchFakeFsTestCase):
         self.assertEqual(pth.AnyPath(binary.resolve_cached(platform)), result)
         self.fs.remove(result)
 
+  @unittest.skipUnless(plt.PLATFORM.is_posix, "Only supported on posix")
+  def test_known_binary_chromeos(self):
+    path = pth.AnyPosixPath("foo/bar/default/crossbench_mock_binary")
+    binary = Binary("crossbench_mock_binary", chromeos=path)
+    self.validate_known_binary_chromeos(path, binary)
+    binary = ChromeOSBinary(path)
+    self.validate_known_binary_chromeos(path, binary)
+
+  def validate_known_binary_chromeos(self, result, binary):
+    result = pth.AnyPosixPath(result)
+    platform = ChromeOsSshMockPlatform(
+        host_platform=LinuxMockPlatform(),
+        host="dut",
+        port=0,
+        ssh_port=22,
+        ssh_user="root")
+
+    platform.expect_sh("which", result, result=str(result))
+    platform.expect_sh("[", "-e", result, "]", result="")
+    platform.expect_sh("[", "-e", result, "]", result="")
+    self.assertEqual(str(binary.resolve(platform)), str(result))
+
+    platform.expect_sh("which", result, result=str(result))
+    platform.expect_sh("[", "-e", result, "]", result="")
+    platform.expect_sh("[", "-e", result, "]", result="")
+    self.assertEqual(str(binary.resolve_cached(platform)), str(result))
+
+    self.assertEqual(str(binary.resolve_cached(platform)), str(result))
+
+    for platform in self.all_mock_platforms():
+      if platform.is_chromeos:
+        continue
+      self.assertEqual(binary.platform_path(platform), ())
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve(platform)
+      with self.assertRaises(BinaryNotFoundError):
+        binary.resolve_cached(platform)
+
   @unittest.skipUnless(plt.PLATFORM.is_posix, "Only supported on posix")
   def test_known_binary_linux(self):
     result = self.create_binary_path(
@@ -213,6 +257,7 @@ class BinaryTestCase(CrossbenchFakeFsTestCase):
         binary.resolve_cached(platform)
 
   def test_known_binary_win(self):
+    self.fs.os = OSType.WINDOWS
     result = self.create_binary_path(
         "foo/bar/default/crossbench_mock_binary.exe")
     result = pathlib.PureWindowsPath(result)
diff --git a/tests/crossbench/plt/test_chromeos_ssh.py b/tests/crossbench/plt/test_chromeos_ssh.py
index 1270247d..3992b522 100644
--- a/tests/crossbench/plt/test_chromeos_ssh.py
+++ b/tests/crossbench/plt/test_chromeos_ssh.py
@@ -3,6 +3,9 @@
 # found in the LICENSE file.
 
 from __future__ import annotations
+import pathlib
+
+from typing_extensions import override
 
 from crossbench.plt.chromeos_ssh import ChromeOsSshPlatform
 from tests import test_helper
@@ -13,14 +16,19 @@ class ChromeOsSshMockPlatformTestCase(LinuxSshMockPlatformTestCase):
   SSH_USER = "chronos"
   platform: ChromeOsSshPlatform
 
+  @override
   def setUp(self) -> None:
     super().setUp()
+    self._init_platform()
+
+  def _init_platform(self, enable_arc=False):
     self.platform = ChromeOsSshPlatform(
         self.mock_platform,
         host=self.HOST,
         port=self.PORT,
         ssh_port=self.SSH_PORT,
-        ssh_user=self.SSH_USER)
+        ssh_user=self.SSH_USER,
+        enable_arc=enable_arc)
 
   def test_name(self):
     self.assertEqual(self.platform.name, "chromeos_ssh")
@@ -28,5 +36,78 @@ class ChromeOsSshMockPlatformTestCase(LinuxSshMockPlatformTestCase):
   def test_is_chromeos(self):
     self.assertTrue(self.platform.is_chromeos)
 
+  def test_basic_properties(self):
+    super().test_basic_properties()
+    self.assertEqual(self.platform.default_tmp_dir,
+                     pathlib.PurePosixPath("/usr/local/tmp/"))
+
+  def test_display_resolution(self):
+    cros_health_tool_out = '''
+    {
+      "embedded_display": {
+        "display_height": "140",
+        "display_name": "NV116WHM-T14",
+        "display_width": "260",
+        "edid_version": "1.4",
+        "input_type": "Digital",
+        "manufacture_week": 1,
+        "manufacture_year": 2019,
+        "manufacturer": "BOE",
+        "model_id": 2303,
+        "privacy_screen_enabled": false,
+        "privacy_screen_supported": false,
+        "refresh_rate": 59.99822202162979,
+        "resolution_horizontal": "1366",
+        "resolution_vertical": "768"
+      }
+    }'''
+    self._expect_sh_ssh(
+        "cros-health-tool telem --category=display",
+        result=cros_health_tool_out)
+    [horizontal, vertical] = self.platform.display_resolution()
+    self.assertEqual(horizontal, 1366)
+    self.assertEqual(vertical, 768)
+
+  def test_create_debugging_session(self):
+    expected_port = 80
+
+    self._expect_sh_ssh(
+        "/usr/local/autotest/bin/autologin.py -u username -p password")
+    self._expect_sh_ssh(
+        "cat /home/chronos/DevToolsActivePort", result=f"{expected_port}")
+    port = self.platform.create_debugging_session(
+        browser_flags=(), username="username", password="password")
+
+    self.assertEqual(port, expected_port)
+
+  def test_create_debugging_session_arc(self):
+    self._init_platform(enable_arc=True)
+    expected_port = 80
+
+    self._expect_sh_ssh(
+        "/usr/local/autotest/bin/autologin.py --arc -u username -p password")
+    self._expect_sh_ssh(
+        "cat /home/chronos/DevToolsActivePort", result=f"{expected_port}")
+    port = self.platform.create_debugging_session(
+        browser_flags=(), username="username", password="password")
+
+    self.assertEqual(port, expected_port)
+
+  def test_create_debugging_session_arc_removes_disable_extensions(self):
+    self._init_platform(enable_arc=True)
+    expected_port = 80
+
+    self._expect_sh_ssh("/usr/local/autotest/bin/autologin.py --arc"
+                        " -u username -p password -- --another-flag")
+    self._expect_sh_ssh(
+        "cat /home/chronos/DevToolsActivePort", result=f"{expected_port}")
+    port = self.platform.create_debugging_session(
+        browser_flags=("--disable-extensions", "--another-flag"),
+        username="username",
+        password="password")
+
+    self.assertEqual(port, expected_port)
+
+
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_linux.py b/tests/crossbench/plt/test_linux.py
new file mode 100644
index 00000000..47bd5648
--- /dev/null
+++ b/tests/crossbench/plt/test_linux.py
@@ -0,0 +1,142 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import textwrap
+from unittest import mock
+
+from pyfakefs.fake_filesystem import OSType
+from typing_extensions import override
+
+from tests import test_helper
+from tests.crossbench.mock_helper import (LinuxMockPlatform,
+                                          RemoteLinuxMockPlatform)
+from tests.crossbench.plt.helper import (BaseLocalMockPlatformTestMixin,
+                                         BasePosixMockPlatformTestCase)
+
+
+class LinuxMockPlatformTestCase(BaseLocalMockPlatformTestMixin,
+                                BasePosixMockPlatformTestCase):
+  __test__ = True
+
+  @override
+  def setUp(self) -> None:
+    super().setUp()
+    self.fs.os = OSType.LINUX
+
+  @override
+  def mock_platform_setup(self) -> None:
+    self.mock_platform = LinuxMockPlatform()
+    self.platform = self.mock_platform
+
+  def test_name(self):
+    self.assertEqual(self.platform.name, "mock.linux")
+
+  def test_is_linux(self):
+    self.assertTrue(self.platform.is_linux)
+
+  @mock.patch("psutil.cpu_count")
+  def test_cpu_cores(self, mock_cpu_count):
+    mock_cpu_count.return_value = 12
+    self.assertEqual(self.platform.cpu_cores(logical=True), 12)
+    mock_cpu_count.assert_called_once()
+
+    mock_cpu_count.return_value = 6
+    self.assertEqual(self.platform.cpu_cores(logical=False), 6)
+    self.assertEqual(mock_cpu_count.call_count, 2)
+
+
+class RemoteLinuxMockPlatformTestCase(LinuxMockPlatformTestCase):
+
+  @override
+  def mock_platform_setup(self) -> None:
+    self.host_platform = LinuxMockPlatform()
+    self.mock_platform = RemoteLinuxMockPlatform(self.host_platform)
+    self.platform = self.mock_platform
+
+  def cpu_info(self, processor_id, physical_id, core_id):
+    return textwrap.dedent(f"""
+        processor       : {processor_id}
+        vendor_id       : GenuineIntel
+        cpu family      : 1
+        model           : 12
+        model name      : Intel(R) Xeon(R) 3456 CPU @ 7.80GHz
+        stepping        : 9
+        microcode       : 0x123456
+        cpu MHz         : 1234.000
+        cache size      : 3456 KB
+        physical id     : {physical_id}
+        core id         : {core_id}
+        fpu             : yes
+        fpu_exception   : yes
+        cpuid level     : 12
+        wp              : yes
+      """)
+
+  def expect_sh_cpu_info(self, cpu_info):
+    self.platform.expect_sh(
+        "grep",
+        "-E",
+        "processor|core id|physical id",
+        "/proc/cpuinfo",
+        result=cpu_info)
+
+  @override
+  def test_cpu_cores(self):
+    single_core_info = self.cpu_info(0, 0, 0)
+    self.expect_sh_cpu_info(single_core_info)
+    self.assertEqual(self.platform.cpu_cores(logical=True), 1)
+    self.assertFalse(self.platform.expected_sh_cmds)
+    # Check that caching works.
+    self.assertEqual(self.platform.cpu_cores(logical=True), 1)
+
+    self.expect_sh_cpu_info(single_core_info)
+    self.assertEqual(self.platform.cpu_cores(logical=False), 1)
+    self.assertFalse(self.platform.expected_sh_cmds)
+    self.assertEqual(self.platform.cpu_cores(logical=False), 1)
+
+  def test_cpu_cores_2_cpu_single_core(self):
+    # 2 physical chips, 1 core, 2 threads
+    dual_chip_result = (
+        self.cpu_info(0, 0, 0) + self.cpu_info(1, 0, 0) +
+        self.cpu_info(2, 1, 0) + self.cpu_info(3, 1, 0))
+    self.expect_sh_cpu_info(dual_chip_result)
+    self.assertEqual(self.platform.cpu_cores(logical=True), 4)
+    self.assertFalse(self.platform.expected_sh_cmds)
+    self.assertEqual(self.platform.cpu_cores(logical=True), 4)
+
+    self.expect_sh_cpu_info(dual_chip_result)
+    self.assertEqual(self.platform.cpu_cores(logical=False), 2)
+    self.assertFalse(self.platform.expected_sh_cmds)
+    self.assertEqual(self.platform.cpu_cores(logical=False), 2)
+
+  def test_cpu_cores_1_cpu_dual_core(self):
+    # 1 physical chips, 2 cores, 2 threads
+    dual_core_result = (
+        self.cpu_info(0, 0, 0) + self.cpu_info(1, 0, 1) +
+        self.cpu_info(2, 0, 0) + self.cpu_info(3, 0, 1))
+    self.expect_sh_cpu_info(dual_core_result)
+    self.assertEqual(self.platform.cpu_cores(logical=True), 4)
+    self.assertFalse(self.platform.expected_sh_cmds)
+    self.assertEqual(self.platform.cpu_cores(logical=True), 4)
+
+    self.expect_sh_cpu_info(dual_core_result)
+    self.assertEqual(self.platform.cpu_cores(logical=False), 2)
+    self.assertFalse(self.platform.expected_sh_cmds)
+    self.assertEqual(self.platform.cpu_cores(logical=False), 2)
+
+  # TODO: implement more mock tests
+  def test_local_reverse_port_forward_invalid(self):
+    pass
+
+  def test_local_reverse_port_forward(self):
+    pass
+
+  def test_local_port_forward(self):
+    pass
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_linux_ssh.py b/tests/crossbench/plt/test_linux_ssh.py
index 1c30f847..d67ea63e 100644
--- a/tests/crossbench/plt/test_linux_ssh.py
+++ b/tests/crossbench/plt/test_linux_ssh.py
@@ -4,6 +4,13 @@
 
 from __future__ import annotations
 
+import contextlib
+import os
+from unittest import mock, skipIf
+
+import pyfakefs
+from typing_extensions import override
+
 from crossbench import path as pth
 from crossbench import plt
 from tests import test_helper
@@ -18,14 +25,34 @@ class LinuxSshMockPlatformTestCase(BasePosixMockPlatformTestCase):
   SSH_USER = "user"
   platform: plt.LinuxSshPlatform
 
+  @override
   def setUp(self) -> None:
     super().setUp()
+    self.host_platform = self.mock_platform
     self.platform = plt.LinuxSshPlatform(
         self.mock_platform,
         host=self.HOST,
         port=self.PORT,
         ssh_port=self.SSH_PORT,
         ssh_user=self.SSH_USER)
+    self.mock_platform_str(self.platform, "linux_ssh_mock_platform")
+
+  def _expect_sh_ssh(self, *args, result=""):
+    self.mock_platform.expect_sh(
+        "ssh",
+        "-p",
+        str(self.SSH_PORT),
+        f"{self.SSH_USER}@{self.HOST}",
+        *args,
+        result=result)
+
+  def _expect_sh_ssh_shell(self, *args, result=""):
+    cmd_string = f"ssh -p {str(self.SSH_PORT)} {self.SSH_USER}@{self.HOST} "
+
+    for arg in args:
+      cmd_string += arg + " "
+
+    self.mock_platform.expect_sh(cmd_string, result=result)
 
   def test_is_linux(self):
     self.assertTrue(self.platform.is_linux)
@@ -49,7 +76,9 @@ class LinuxSshMockPlatformTestCase(BasePosixMockPlatformTestCase):
     # Subsequent calls are cached.
     self.assertEqual(self.platform.version, "999")
 
-
+  @skipIf(
+      tuple(map(int, pyfakefs.__version__.split("."))) < (5, 5),
+      "pth.AnyWindowsPath does not work correctly with older pyfakefs")
   def test_iterdir(self):
     self._expect_sh_ssh("'[' -d parent_dir/child_dir ']'")
     self._expect_sh_ssh("ls -1 parent_dir/child_dir", result="file1\nfile2\n")
@@ -61,15 +90,109 @@ class LinuxSshMockPlatformTestCase(BasePosixMockPlatformTestCase):
             pth.AnyPosixPath("parent_dir/child_dir/file2")
         })
 
-  def _expect_sh_ssh(self, *args, result=""):
+  def test_cat_file(self):
+    self._expect_sh_ssh("cat path/to/a/file")
+    self.platform.cat(self.platform.path("path/to/a/file"))
+    self._expect_sh_ssh("cat 'path/with a space/to/a/file'")
+    self.platform.cat(self.platform.path("path/with a space/to/a/file"))
+
+  def test_sh_shell_invalid(self):
+    with self.assertRaisesRegex(ValueError, "shell=True"):
+      self.platform.sh_stdout("ls", "folder with space", shell=True)
+
+  def test_sh_shell(self):
+    self._expect_sh_ssh("ls sdcard", result="FILE1\nFILE2\n")
+    self.assertEqual(self.platform.sh_stdout("ls", "sdcard"), "FILE1\nFILE2\n")
+
+    self._expect_sh_ssh("ls 'folder with space'", result="FOLDER\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls", "folder with space"), "FOLDER\n")
+
+    self._expect_sh_ssh("'ls foo && ls bar'", result="FILE1\nFILE2\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls foo && ls bar"), "FILE1\nFILE2\n")
+
+    self._expect_sh_ssh_shell("'ls foo && ls bar'", result="FILE1\nFILE2\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls foo && ls bar", shell=True),
+        "FILE1\nFILE2\n")
+
+    self._expect_sh_ssh("ls foo '&&' ls bar", result="FILE1\nFILE2\n")
+    self.assertEqual(
+        self.platform.sh_stdout("ls", "foo", "&&", "ls", "bar"),
+        "FILE1\nFILE2\n")
+
+  @contextlib.contextmanager
+  def mock_popen(self, platform):
+    with mock.patch.object(type(platform), "popen") as patcher:
+      yield patcher
+
+  @contextlib.contextmanager
+  def mock_get_free_port(self, platform, port):
+    with mock.patch.object(
+        type(platform), "get_free_port", return_value=port) as patcher:
+      yield patcher
+
+  @contextlib.contextmanager
+  def mock_wait_for_port(self, platform):
+    with mock.patch.object(type(platform), "wait_for_port") as patcher:
+      yield patcher
+
+  def test_port_forward(self):
+    with self.mock_popen(
+        self.host_platform) as mock_popen, self.mock_wait_for_port(
+            self.host_platform) as mock_wait_for_port:
+      port = self.platform.port_forward(666, 33221)
+    mock_popen.assert_called_once()
+    mock_wait_for_port.assert_called_once()
+    self.assertEqual(port, 666)
+    with self.assertRaisesRegex(RuntimeError, "twice"):
+      port = self.platform.port_forward(666, 33221)
+    self.platform.stop_port_forward(port)
+
+  def test_port_forward_auto_port(self):
+    with self.mock_get_free_port(self.host_platform, 666) as mock_free_port:
+      with self.mock_popen(self.host_platform) as mock_popen:
+        with self.mock_wait_for_port(self.host_platform) as mock_wait_for_port:
+          port = self.platform.port_forward(0, 33221)
+      mock_popen.assert_called_once()
+      mock_wait_for_port.assert_called_once()
+    mock_free_port.assert_called_once()
+    self.assertEqual(port, 666)
+    with self.assertRaisesRegex(RuntimeError, "twice"):
+      port = self.platform.port_forward(666, 33221)
+    self.platform.stop_port_forward(port)
+
+  def test_reverse_port_forward(self):
+    self._expect_sh_ssh("ss -HOlnt sport = 666", result="666")
+    with self.mock_popen(self.host_platform) as mock_popen:
+      port = self.platform.reverse_port_forward(666, 33221)
+    mock_popen.assert_called_once()
+    with self.assertRaisesRegex(RuntimeError, "twice"):
+      self.platform.reverse_port_forward(666, 33221)
+    self.assertEqual(port, 666)
+    self.platform.stop_reverse_port_forward(port)
+
+  def test_push_creates_dest_dir(self):
+    self._expect_sh_ssh("mkdir -p remote/dest/path")
     self.mock_platform.expect_sh(
-        "ssh",
-        "-p",
-        str(self.SSH_PORT),
-        f"{self.SSH_USER}@{self.HOST}",
-        *args,
-        result=result)
+        "scp", "-P", self.SSH_PORT, "source/path/file",
+        f"{self.SSH_USER}@{self.HOST}:remote/dest/path/file")
+    self.platform.push(
+        self.platform.path("source/path/file"),
+        self.platform.path("remote/dest/path/file"))
 
+  def test_pull_creates_dest_dir(self):
+    self.mock_platform.expect_sh(
+        "scp", "-P", self.SSH_PORT,
+        f"{self.SSH_USER}@{self.HOST}:remote/source/path/file",
+        "local/dest/path/file")
+    self.platform.pull(
+        self.platform.path("remote/source/path/file"),
+        self.platform.path("local/dest/path/file"))
+
+    self.assertEqual(self.mock_platform.mkdir_calls, 1)
+    self.assertTrue(os.path.exists("local/dest/path"))
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_macos.py b/tests/crossbench/plt/test_macos.py
index 58ec7272..4c4dca17 100644
--- a/tests/crossbench/plt/test_macos.py
+++ b/tests/crossbench/plt/test_macos.py
@@ -7,20 +7,25 @@ from __future__ import annotations
 import plistlib
 
 from pyfakefs.fake_filesystem import OSType
+from typing_extensions import override
 
 from crossbench import path as pth
 from tests import test_helper
 from tests.crossbench.mock_helper import MacOsMockPlatform
-from tests.crossbench.plt.helper import BasePosixMockPlatformTestCase
+from tests.crossbench.plt.helper import (BaseLocalMockPlatformTestMixin,
+                                         BasePosixMockPlatformTestCase)
 
 
-class MacOsMockPlatformTestCase(BasePosixMockPlatformTestCase):
+class MacOsMockPlatformTestCase(BaseLocalMockPlatformTestMixin,
+                                BasePosixMockPlatformTestCase):
   __test__ = True
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.fs.os = OSType.MACOS
 
+  @override
   def mock_platform_setup(self) -> None:
     self.mock_platform = MacOsMockPlatform()
     self.platform = self.mock_platform
@@ -32,12 +37,28 @@ class MacOsMockPlatformTestCase(BasePosixMockPlatformTestCase):
     self.assertTrue(self.platform.is_macos)
 
   def test_app_version_non_existing(self):
+    app_path = pth.AnyPosixPath("/Applications/Google Chrome.app")
+    self.assertFalse(self.platform.exists(app_path))
+    with self.assertRaisesRegex(ValueError, "not exist"):
+      self.platform.app_version(app_path)
     app_path = pth.AnyPath("/Applications/Google Chrome.app")
     self.assertFalse(self.platform.exists(app_path))
     with self.assertRaisesRegex(ValueError, "not exist"):
       self.platform.app_version(app_path)
 
-  def test_app_version_binary(self):
+  def test_app_version_binary_any_path(self):
+    app_path = pth.AnyPosixPath("/opt/homebrew/bin/brew")
+    self.fs.create_file(app_path, st_size=100)
+    self.expect_sh(app_path, "--version", result="111.22.3")
+    self.assertEqual(self.platform.app_version(app_path), "111.22.3")
+
+  def test_app_version_binary_local_path(self):
+    app_path = pth.LocalPath("/opt/homebrew/bin/brew")
+    self.fs.create_file(app_path, st_size=100)
+    self.expect_sh(app_path, "--version", result="111.22.3")
+    self.assertEqual(self.platform.app_version(app_path), "111.22.3")
+
+  def test_app_version_binary_posix_path(self):
     app_path = pth.AnyPath("/opt/homebrew/bin/brew")
     self.fs.create_file(app_path, st_size=100)
     self.expect_sh(app_path, "--version", result="111.22.3")
@@ -67,8 +88,23 @@ class MacOsMockPlatformTestCase(BasePosixMockPlatformTestCase):
       self.platform.app_version(app_path)
 
     with info_plist.open("wb") as f:
-      plistlib.dump({"CFBundleShortVersionString": "129.9.6668.103"}, f)
-    self.assertEqual(self.platform.app_version(app_path), "129.9.6668.103")
+      plistlib.dump(
+          {
+              "CFBundleShortVersionString": "129.9.6668.103",
+              "CFBundleDisplayName": "Google Chrome",
+          }, f)
+    self.assertEqual(
+        self.platform.app_version(app_path), "Google Chrome 129.9.6668.103")
+
+    with info_plist.open("wb") as f:
+      plistlib.dump(
+          {
+              "CFBundleShortVersionString": "129.9.6668.103",
+              # CFBundleDisplayName is missing but CFBundleName is there.
+              "CFBundleName": "Google Chrome",
+          }, f)
+    self.assertEqual(
+        self.platform.app_version(app_path), "Google Chrome 129.9.6668.103")
 
   def test_app_version_binary_inside_app(self):
     binary_path = pth.LocalPath("/Applications/Safari Technology Preview.app/"
diff --git a/tests/crossbench/plt/test_native_platform.py b/tests/crossbench/plt/test_native_platform.py
index 6086280c..36b1fff9 100644
--- a/tests/crossbench/plt/test_native_platform.py
+++ b/tests/crossbench/plt/test_native_platform.py
@@ -5,22 +5,30 @@
 from __future__ import annotations
 
 import datetime as dt
+import json
 import os
 import pathlib
+import signal
+import socket
+import stat
 import sys
 import tempfile
 import unittest
 
-from crossbench import compat, plt
-from crossbench.plt.base import DEFAULT_CACHE_DIR
+from typing_extensions import override
+
+from crossbench import plt
+from crossbench.plt.base import DEFAULT_CACHE_DIR, SubprocessError
 from crossbench.plt.posix import PosixPlatform
 from tests import test_helper
 
 
 class NativePlatformTestCase(unittest.TestCase):
 
+  @override
   def setUp(self):
     self.platform: plt.Platform = plt.PLATFORM
+    self.known_binary = "python3"
 
   def test_sleep(self):
     self.platform.sleep(0)
@@ -80,46 +88,51 @@ class NativePlatformTestCase(unittest.TestCase):
     self.assertIn("empty", str(cm.exception))
 
   def test_cat(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      file = pathlib.Path(tmp_dirname) / "test.txt"
-      with file.open("w") as f:
-        f.write("a b c d e f 11")
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      file = tmp_dir / "test.txt"
+      self.platform.set_file_contents(file, "a b c d e f 11")
       result = self.platform.cat(file)
       self.assertEqual(result, "a b c d e f 11")
 
   def test_cat_bytes(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      file = pathlib.Path(tmp_dirname) / "test.data"
-      with file.open("wb") as f:
-        f.write(b"a b c d e f 11")
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      file = tmp_dir / "test.data"
+      self.platform.set_file_contents(file, "a b c d e f 11")
       result = self.platform.cat_bytes(file)
       self.assertEqual(result, b"a b c d e f 11")
 
   def test_mkdir(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      path = pathlib.Path(tmp_dirname) / "foo" / "bar"
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      path = tmp_dir / "foo" / "bar"
       self.assertFalse(self.platform.exists(path))
       self.platform.mkdir(path)
-      self.assertTrue(path.is_dir())
+      self.assertTrue(self.platform.is_dir(path))
+      if self.platform.is_local:
+        self.assertTrue(pathlib.Path(path).is_dir())
 
   def test_rm_file(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      path = pathlib.Path(tmp_dirname) / "foo.txt"
-      path.touch()
-      self.assertTrue(path.is_file())
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      path = tmp_dir / "foo.txt"
+      self.platform.touch(path)
+      self.assertTrue(self.platform.is_file(path))
+      if self.platform.is_local:
+        self.assertTrue(pathlib.Path(path).is_file())
       self.platform.rm(path)
       self.assertFalse(self.platform.exists(path))
 
   def test_rm_dir(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      path = pathlib.Path(tmp_dirname) / "foo" / "bar"
-      path.mkdir(parents=True, exist_ok=False)
-      self.assertTrue(path.is_dir())
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      path = tmp_dir / "foo" / "bar"
+      self.platform.mkdir(path, parents=True, exist_ok=False)
+      self.assertTrue(self.platform.is_dir(path))
+      if self.platform.is_local:
+        self.assertTrue(path.is_dir())
       with self.assertRaises(Exception):
         self.platform.rm(path.parent)
       self.platform.rm(path.parent, dir=True)
       self.assertFalse(self.platform.exists(path))
-      self.assertFalse(path.parent.exists())
+      if self.platform.is_local:
+        self.assertFalse(pathlib.Path(path).parent.exists())
 
   def test_mkdtemp(self):
     result = self.platform.mkdtemp(prefix="a_custom_prefix")
@@ -129,11 +142,10 @@ class NativePlatformTestCase(unittest.TestCase):
     self.assertFalse(self.platform.exists(result))
 
   def test_mkdtemp_dir(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_dir = pathlib.Path(tmp_dirname)
+    with self.platform.TemporaryDirectory() as tmp_dir:
       result = self.platform.mkdtemp(dir=tmp_dir)
       self.assertTrue(self.platform.is_dir(result))
-      self.assertTrue(compat.is_relative_to(result, tmp_dir))
+      self.assertTrue(result.is_relative_to(tmp_dir))
     self.assertFalse(self.platform.exists(result))
 
   def test_mktemp(self):
@@ -144,40 +156,48 @@ class NativePlatformTestCase(unittest.TestCase):
     self.assertFalse(self.platform.exists(result))
 
   def test_mktemp_dir(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_dir = pathlib.Path(tmp_dirname)
+    with self.platform.TemporaryDirectory() as tmp_dir:
       result = self.platform.mktemp(dir=tmp_dir)
       self.assertTrue(self.platform.is_file(result))
-      self.assertTrue(compat.is_relative_to(result, tmp_dir))
+      self.assertTrue(result.is_relative_to(tmp_dir))
     self.assertFalse(self.platform.exists(result))
 
   def test_exists(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_dir = pathlib.Path(tmp_dirname)
+    with self.platform.TemporaryDirectory() as tmp_dir:
       self.assertTrue(self.platform.exists(tmp_dir))
       self.assertFalse(self.platform.exists(tmp_dir / "foo"))
 
   def test_touch(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_file = pathlib.Path(tmp_dirname) / "test.txt"
-      self.assertFalse(tmp_file.exists())
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      tmp_file = tmp_dir / "test.txt"
+      if self.platform.is_local:
+        self.assertFalse(tmp_file.exists())
       self.assertFalse(self.platform.exists(tmp_file))
       self.platform.touch(tmp_file)
-      self.assertTrue(tmp_file.exists())
+      if self.platform.is_local:
+        self.assertTrue(tmp_file.exists())
       self.assertTrue(self.platform.exists(tmp_file))
-      self.assertEqual(tmp_file.stat().st_size, 0)
+      if self.platform.is_local:
+        self.assertEqual(tmp_file.stat().st_size, 0)
 
   def test_rename(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_file = pathlib.Path(tmp_dirname) / "test.txt"
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      tmp_file = tmp_dir / "test.txt"
       tmp_file_renamed = tmp_file.with_name("test_renamed.txt")
       self.platform.touch(tmp_file)
-      self.assertTrue(tmp_file.exists())
-      self.assertFalse(tmp_file_renamed.exists())
+      if self.platform.is_local:
+        self.assertTrue(tmp_file.exists())
+        self.assertFalse(tmp_file_renamed.exists())
+      self.assertTrue(self.platform.exists(tmp_file))
+      self.assertFalse(self.platform.exists(tmp_file_renamed))
+
       result = self.platform.rename(tmp_file, tmp_file_renamed)
       self.assertEqual(result, tmp_file_renamed)
-      self.assertFalse(tmp_file.exists())
-      self.assertTrue(tmp_file_renamed.exists())
+      if self.platform.is_local:
+        self.assertFalse(tmp_file.exists())
+        self.assertTrue(tmp_file_renamed.exists())
+      self.assertFalse(self.platform.exists(tmp_file))
+      self.assertTrue(self.platform.exists(tmp_file_renamed))
 
   def test_default_tmp_dir(self):
     self.assertTrue(self.platform.is_dir(self.platform.default_tmp_dir))
@@ -190,9 +210,9 @@ class NativePlatformTestCase(unittest.TestCase):
     self.assertFalse(self.platform.exists(path))
 
   def test_copy(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      src_file = pathlib.Path(tmp_dirname) / "src.txt"
-      dst_file = pathlib.Path(tmp_dirname) / "dst.txt"
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      src_file = tmp_dir / "src.txt"
+      dst_file = tmp_dir / "dst.txt"
       with self.assertRaises(ValueError) as cm:
         self.assertFalse(self.platform.exists(src_file))
         self.platform.copy(src_file, dst_file)
@@ -200,16 +220,52 @@ class NativePlatformTestCase(unittest.TestCase):
       self.assertFalse(self.platform.exists(src_file))
       self.assertFalse(self.platform.exists(dst_file))
 
-      src_file.write_text("some data")
+      self.platform.set_file_contents(src_file, "some data")
       self.assertTrue(self.platform.exists(src_file))
       self.platform.copy(src_file, dst_file)
       self.assertTrue(self.platform.exists(src_file))
       self.assertTrue(self.platform.exists(dst_file))
       self.assertEqual(self.platform.cat(src_file), "some data")
       self.assertEqual(self.platform.cat(dst_file), "some data")
+      # Copying the same file should have no effect:
+      self.platform.copy(src_file, src_file)
+      self.platform.copy(dst_file, dst_file)
+      self.assertEqual(self.platform.cat(src_file), "some data")
+      self.assertEqual(self.platform.cat(dst_file), "some data")
+
+  def test_copy_dir(self):
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      src_file = tmp_dir / "src/file.txt"
+      dst_file = tmp_dir / "dst/file.txt"
+      src_dir = src_file.parent
+      dst_dir = dst_file.parent
+      with self.assertRaises(ValueError) as cm:
+        self.assertFalse(self.platform.exists(src_dir))
+        self.platform.copy(src_dir, dst_dir)
+      self.assertIn(str(src_dir), str(cm.exception))
+      self.assertFalse(self.platform.exists(src_dir))
+      self.assertFalse(self.platform.exists(dst_dir))
+
+      self.platform.mkdir(src_dir)
+      self.platform.set_file_contents(src_file, "some data")
+      self.assertTrue(self.platform.exists(src_file))
+
+      self.platform.copy(src_dir, dst_dir)
+      self.assertTrue(self.platform.exists(src_file))
+      self.assertTrue(self.platform.exists(dst_file))
+      self.assertEqual(self.platform.cat(src_file), "some data")
+      self.assertEqual(self.platform.cat(dst_file), "some data")
+      # Copying the same file should have no effect:
+      self.platform.copy(src_dir, src_dir)
+      self.platform.copy(dst_dir, dst_dir)
+      self.assertEqual(self.platform.cat(src_file), "some data")
+      self.assertEqual(self.platform.cat(dst_file), "some data")
 
   def test_home(self):
-    self.assertEqual(self.platform.home(), pathlib.Path.home())
+    if self.platform.is_local:
+      self.assertEqual(self.platform.home(), pathlib.Path.home())
+    else:
+      self.assertTrue(self.platform.is_dir(self.platform.home()))
 
   def test_absolute_absolute(self):
     if self.platform.is_win:
@@ -230,8 +286,7 @@ class NativePlatformTestCase(unittest.TestCase):
   def test_glob(self):
     if self.platform.is_remote:
       self.skipTest("Not supported yet on remote platforms.")
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_dir = pathlib.Path(tmp_dirname)
+    with self.platform.TemporaryDirectory() as tmp_dir:
       self.assertFalse(list(self.platform.glob(tmp_dir, "*")))
       a = tmp_dir / "a"
       b = tmp_dir / "b"
@@ -242,8 +297,8 @@ class NativePlatformTestCase(unittest.TestCase):
   def test_set_file_contents(self):
     if self.platform.is_remote:
       self.skipTest("Not supported yet on remote platforms.")
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_file = pathlib.Path(tmp_dirname) / "test.txt"
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      tmp_file = tmp_dir / "test.txt"
       self.assertFalse(self.platform.exists(tmp_file))
       self.platform.mkdir(tmp_file.parent)
       self.platform.touch(tmp_file)
@@ -256,7 +311,7 @@ class NativePlatformTestCase(unittest.TestCase):
   def test_set_file_contents_dir(self):
     if self.platform.is_remote:
       self.skipTest("Not supported yet on remote platforms.")
-    with tempfile.TemporaryDirectory() as tmp_dirname:
+    with self.platform.TemporaryDirectory() as tmp_dirname:
       self.assertTrue(self.platform.is_dir(tmp_dirname))
       tmp_dir_path = self.platform.path(tmp_dirname)
       self.assertTrue(self.platform.is_dir(tmp_dir_path))
@@ -265,8 +320,7 @@ class NativePlatformTestCase(unittest.TestCase):
       self.assertIn(tmp_dir_path.name, str(cm.exception))
 
   def test_path_tests(self):
-    with tempfile.TemporaryDirectory() as tmp_dirname:
-      tmp_dir = pathlib.Path(tmp_dirname)
+    with self.platform.TemporaryDirectory() as tmp_dir:
       self.assertTrue(self.platform.exists(tmp_dir))
       self.assertTrue(self.platform.is_dir(tmp_dir))
       self.assertFalse(self.platform.is_file(tmp_dir))
@@ -289,18 +343,36 @@ class NativePlatformTestCase(unittest.TestCase):
       self.assertFalse(self.platform.is_dir(bar_file))
       self.assertTrue(self.platform.is_file(bar_file))
 
+  def test_chmod(self):
+    if self.platform.is_remote:
+      return
+    with self.platform.TemporaryDirectory() as tmp_dir:
+      tmp_file = tmp_dir / "test.txt"
+      self.assertFalse(self.platform.exists(tmp_file))
+      self.platform.set_file_contents(tmp_file, "")
+      mode = 0o400
+      self.platform.chmod(tmp_file, mode)
+      self.assertEqual(os.stat(tmp_file)[stat.ST_MODE] & mode, mode)
+      mode = 0o600
+      self.assertNotEqual(os.stat(tmp_file)[stat.ST_MODE] & mode, mode)
+      self.platform.chmod(tmp_file, mode)
+      self.assertEqual(os.stat(tmp_file)[stat.ST_MODE] & mode, mode)
+
+  @unittest.skipIf(
+      test_helper.is_google_env(), "Source directory is readonly")
   def test_cache_dir(self):
     with self.platform.TemporaryDirectory() as tmp_dir:
       try:
         self.platform.set_cache_dir(tmp_dir)
-        cache_dir = self.platform.local_cache_dir("test")
+        cache_dir = self.platform.cache_dir("test")
         self.assertTrue(self.platform.is_dir(cache_dir))
         self.assertEqual(cache_dir.parent, tmp_dir)
       finally:
-        self.platform.rm(cache_dir, dir=True, missing_ok=True)
         if self.platform.is_local:
           self.platform.set_cache_dir(DEFAULT_CACHE_DIR)
 
+  @unittest.skipIf(
+      test_helper.is_google_env(), "Source directory is readonly")
   def test_default_local_cache_dir(self):
     if self.platform.is_remote:
       return
@@ -311,6 +383,8 @@ class NativePlatformTestCase(unittest.TestCase):
     finally:
       self.platform.rm(cache_dir, dir=True, missing_ok=True)
 
+  @unittest.skipIf(
+      test_helper.is_google_env(), "Source directory is readonly")
   def test_local_cache_dir(self):
     if self.platform.is_remote:
       return
@@ -327,6 +401,8 @@ class NativePlatformTestCase(unittest.TestCase):
   def test_processes(self):
     if self.platform.is_remote:
       self.skipTest("Not supported yet on remote platforms.")
+    if self.platform.is_win:
+      self.skipTest("Too Slow on windows")
     processes = self.platform.processes(["name"])
     self.assertTrue(processes)
     for process_info in processes:
@@ -361,6 +437,37 @@ class NativePlatformTestCase(unittest.TestCase):
     process_info = self.platform.process_children(os.getpid(), recursive=True)
     self.assertIsInstance(process_info, list)
 
+  def test_get_free_port(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    port = self.platform.get_free_port()
+    self.assertGreater(port, 0)
+    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
+      s.bind(("localhost", port))
+      self.assertNotEqual(port, self.platform.get_free_port())
+
+  def test_is_port_used(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    port = self.platform.get_free_port()
+    self.assertFalse(self.platform.is_port_used(port))
+    with socket.create_server(("localhost", port)):
+      self.assertTrue(self.platform.is_port_used(port))
+
+  def test_wait_for_port(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    port = self.platform.get_free_port()
+    with self.assertRaises(TimeoutError):
+      self.platform.wait_for_port(port, timeout=dt.timedelta(seconds=0.01))
+
+  def test_wait_for_port_active(self):
+    if self.platform.is_remote:
+      self.skipTest("Not supported yet on remote platforms.")
+    port = self.platform.get_free_port()
+    with socket.create_server(("localhost", port)):
+      self.platform.wait_for_port(port, timeout=dt.timedelta(seconds=0.01))
+
   @unittest.skipIf(
       not plt.PLATFORM.which("python3"), reason="python3 not installed")
   def test_binary_lookup_override(self):
@@ -368,7 +475,7 @@ class NativePlatformTestCase(unittest.TestCase):
     self.assertIsNone(self.platform.lookup_binary_override(test_binary))
     self.assertIsNone(self.platform.which(test_binary))
     # Use an arbitrary existing binary for testing.
-    override_binary = self.platform.which("python3")
+    override_binary = self.platform.which(self.known_binary)
     self.assertTrue(override_binary)
     with self.platform.override_binary(test_binary, override_binary):
       self.assertEqual(self.platform.which(test_binary), override_binary)
@@ -379,11 +486,22 @@ class NativePlatformTestCase(unittest.TestCase):
     self.assertIsNone(self.platform.lookup_binary_override(test_binary))
     self.assertIsNone(self.platform.which(test_binary))
 
+  def test_signals(self):
+    for signal_name in dir(self.platform.signals):
+      if not signal_name.startswith("SIG"):
+        continue
+      value = getattr(self.platform.signals, signal_name)
+      native_value = getattr(signal, signal_name)
+      self.assertEqual(value, native_value,
+                       f"Mismatching values for {signal_name}")
+
+
 
 @unittest.skipIf(not plt.PLATFORM.is_posix, "Incompatible platform")
 class PosixNativePlatformTestCase(NativePlatformTestCase):
   platform: PosixPlatform
 
+  @override
   def setUp(self):
     super().setUp()
     assert isinstance(plt.PLATFORM, PosixPlatform)
@@ -405,15 +523,43 @@ class PosixNativePlatformTestCase(NativePlatformTestCase):
   def test_which(self):
     ls_bin = self.platform.which("ls")
     self.assertIsNotNone(ls_bin)
-    bash_bin = self.platform.which("bash")
-    self.assertIsNotNone(bash_bin)
-    self.assertNotEqual(ls_bin, bash_bin)
-    self.assertTrue(pathlib.Path(ls_bin).exists())
-    self.assertTrue(pathlib.Path(bash_bin).exists())
+    # self.known_binary is "python3", which does not exist on google3,
+    # as google3 has its own mechanism to start python scripts.
+    if not test_helper.is_google_env():
+      known_binary = self.platform.which(self.known_binary)
+      self.assertIsNotNone(known_binary)
+      self.assertNotEqual(ls_bin, known_binary)
+      self.assertTrue(self.platform.exists(ls_bin))
+      self.assertTrue(self.platform.exists(known_binary))
 
   def test_system_details(self):
     details = self.platform.system_details()
     self.assertTrue(details)
+    self.assertTrue(json.dumps(details))
+
+  def test_os_details(self):
+    details = self.platform.os_details()
+    self.assertTrue(details)
+    self.assertTrue(json.dumps(details))
+    self.assertIn("system", details)
+    self.assertIn("release", details)
+    self.assertIn("version", details)
+
+  def test_cpu_details(self):
+    details = self.platform.cpu_details()
+    self.assertTrue(details)
+    self.assertTrue(json.dumps(details))
+    self.assertIn("info", details)
+    self.assertIn("physical cores", details)
+    self.assertIn("logical cores", details)
+    self.assertIn("min frequency", details)
+    self.assertIn("max frequency", details)
+
+  def test_python_details(self):
+    details = self.platform.python_details()
+    self.assertTrue(details)
+    self.assertTrue(json.dumps(details))
+    self.assertIn("version", details)
 
   def test_search_binary(self):
     result_path = self.platform.search_binary(pathlib.Path("ls"))
@@ -423,10 +569,10 @@ class PosixNativePlatformTestCase(NativePlatformTestCase):
 
   def test_search_binary_posix_lookup_override(self):
     path = pathlib.Path("ls")
-    override = self.platform.which("cp")
-    with self.platform.override_binary(path, override):
+    overridden_binary = self.platform.which("cp")
+    with self.platform.override_binary(path, overridden_binary):
       result_path = self.platform.search_binary(path)
-      self.assertEqual(result_path, override)
+      self.assertEqual(result_path, overridden_binary)
       self.assertTrue(self.platform.exists(result_path))
 
     result_path_2 = self.platform.search_binary(path)
@@ -440,7 +586,20 @@ class PosixNativePlatformTestCase(NativePlatformTestCase):
     self.assertIn("PATH", env)
     self.assertTrue(list(env))
 
+  def test_environ_set_property_fails_on_remote(self):
+    if self.platform.is_local:
+      return
+    env = self.platform.environ
+    custom_key = f"CROSSBENCH_TEST_KEY_{len(env)}"
+    self.assertNotIn(custom_key, env)
+    with self.assertRaises(Exception):
+      env[custom_key] = 1234
+    with self.assertRaises(Exception):
+      env[custom_key] = "1234"
+
   def test_environ_set_property(self):
+    if self.platform.is_remote:
+      return
     env = self.platform.environ
     custom_key = f"CROSSBENCH_TEST_KEY_{len(env)}"
     self.assertNotIn(custom_key, env)
@@ -461,25 +620,88 @@ class PosixNativePlatformTestCase(NativePlatformTestCase):
     version = self.platform.app_version(python_path)
     self.assertTrue(version)
 
+  def test_shell_piping(self):
+    with self.platform.NamedTemporaryFile() as file:
+      result = self.platform.sh_stdout(
+          f"echo 'test data' > {file} && cat {file}", shell=True)
+      self.assertEqual(result, "test data\n")
+
+  def test_simple_shell_status_ok(self):
+    self.platform.sh("ls", shell=False)
+    self.platform.sh("ls && ls", shell=True)
+    self.assertTrue(self.platform.sh_stdout("ls", shell=False))
+    self.assertTrue(self.platform.sh_stdout("ls && ls", shell=True))
+
+  def test_simple_shell_fail(self):
+    with self.assertRaises(SubprocessError):
+      self.platform.sh("ls", "path/to/invalid/test/crossbench/dir", shell=False)
+    with self.assertRaises(SubprocessError):
+      self.platform.sh(
+          "ls path/to/invalid/test/crossbench/dir && ls", shell=True)
+    with self.assertRaises(SubprocessError):
+      self.platform.sh_stdout(
+          "ls", "path/to/invalid/test/crossbench/dir", shell=False)
+    with self.assertRaises(SubprocessError):
+      self.platform.sh_stdout(
+          "ls path/to/invalid/test/crossbench/dir && ls", shell=True)
+
+  def test_simple_shell_fail_ignore(self):
+    self.platform.sh(
+        "ls", "path/to/invalid/test/crossbench/dir", shell=False, check=False)
+    self.platform.sh(
+        "ls path/to/invalid/test/crossbench/dir && ls", shell=True, check=False)
+    self.assertEqual(
+        self.platform.sh_stdout(
+            "ls",
+            "path/to/invalid/test/crossbench/dir",
+            shell=False,
+            check=False), "")
+    self.assertEqual(
+        self.platform.sh_stdout(
+            "ls path/to/invalid/test/crossbench/dir && ls",
+            shell=True,
+            check=False), "")
+
+  def test_popen_watch(self):
+    # TODO: implement mock remote popen
+    if self.platform.is_remote:
+      self.skipTest("Missing remote platform popen")
+      return
+    popen = None
+    try:
+      popen = self.platform.popen("sleep", "5")
+      self.assertTrue(popen.pid)
+      self.assertTrue(self.platform.host_platform.process_info(popen.pid))
+    finally:
+      popen.kill()
+
 class MockRemotePosixPlatform(type(plt.PLATFORM)):
 
   @property
+  @override
   def host_platform(self):
     return plt.PLATFORM
 
+  @property
   def is_remote(self) -> bool:
     return True
 
+  @override
   def local_path(self, path):
     # override to bypass is_local checks
     return pathlib.Path(path)
 
+  @override
   def sh(self, *args, **kwargs):
     return plt.PLATFORM.sh(*args, **kwargs)
 
+  @override
   def sh_stdout(self, *args, **kwargs):
     return plt.PLATFORM.sh_stdout(*args, **kwargs)
 
+  def push(self, from_path, to_path):
+    return self.copy_file(from_path, to_path)
+
 
 @unittest.skipIf(not plt.PLATFORM.is_posix, "Incompatible platform")
 class MockRemotePosixPlatformTestCase(PosixNativePlatformTestCase):
@@ -487,6 +709,7 @@ class MockRemotePosixPlatformTestCase(PosixNativePlatformTestCase):
   This test fakes this by temporarily changing the current PLATFORM's is_remote
   getter to return True"""
 
+  @override
   def setUp(self):
     super().setUp()
     self.platform = MockRemotePosixPlatform()
@@ -504,11 +727,22 @@ class MockRemotePosixPlatformTestCase(PosixNativePlatformTestCase):
   def test_cpu_usage(self):
     raise self.skipTest("Not supported on remote platforms")
 
+  def test_chmod(self):
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_dir = pathlib.Path(tmp_dirname)
+      tmp_file = tmp_dir / "test.txt"
+      self.assertFalse(self.platform.exists(tmp_file))
+      self.platform.touch(tmp_file)
+      self.assertNotEqual(os.stat(tmp_file)[stat.ST_MODE] & 0o755, 0o755)
+      self.platform.chmod(tmp_file, 0o755)
+      self.assertEqual(os.stat(tmp_file)[stat.ST_MODE] & 0o755, 0o755)
+
 
 @unittest.skipIf(not plt.PLATFORM.is_macos, "Incompatible platform")
 class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
   platform: plt.MacOSPlatform
 
+  @override
   def setUp(self):
     super().setUp()
     assert isinstance(plt.PLATFORM, plt.MacOSPlatform)
@@ -529,8 +763,8 @@ class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
     self.assertEqual(binary.name, "Safari")
 
   def test_search_app_binary_override(self):
-    override = pathlib.Path("/System/Applications/Calendar.app")
-    with self.platform.override_binary("Safari.app", override):
+    overridden_binary = pathlib.Path("/System/Applications/Calendar.app")
+    with self.platform.override_binary("Safari.app", overridden_binary):
       binary = self.platform.search_binary(pathlib.Path("Safari.app"))
       self.assertIsNotNone(binary)
       self.assertTrue(self.platform.is_file(binary))
@@ -552,8 +786,8 @@ class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
     self.assertTrue(self.platform.is_dir(binary))
 
   def test_search_app_override(self):
-    override = pathlib.Path("/System/Applications/Calendar.app")
-    with self.platform.override_binary("Safari.app", override):
+    overridden_binary = pathlib.Path("/System/Applications/Calendar.app")
+    with self.platform.override_binary("Safari.app", overridden_binary):
       binary = self.platform.search_app(pathlib.Path("Safari.app"))
       self.assertIsNotNone(binary)
       self.assertTrue(self.platform.exists(binary))
@@ -561,14 +795,15 @@ class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
       self.assertEqual(binary.name, "Calendar.app")
 
   def test_app_version_app(self):
-    app = self.platform.search_app(pathlib.Path("Safari.app"))
+    app = pathlib.Path(self.platform.search_app(pathlib.Path("Safari.app")))
     self.assertIsNotNone(app)
     self.assertTrue(app.is_dir())
     version = self.platform.app_version(app)
     self.assertRegex(version, r"[0-9]+\.[0-9]+")
 
   def test_app_version_app_binary(self):
-    binary = self.platform.search_binary(pathlib.Path("Safari.app"))
+    binary = pathlib.Path(
+        self.platform.search_binary(pathlib.Path("Safari.app")))
     self.assertIsNotNone(binary)
     self.assertTrue(binary.is_file())
     version = self.platform.app_version(binary)
@@ -605,6 +840,8 @@ class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
     self.assertFalse(self.platform.is_remote)
 
   def test_set_main_screen_brightness(self):
+    if test_helper.is_on_swarming():
+      self.skipTest("Skipping this to run in CQ due to crbug.com/396417022.")
     prev_level = plt.PLATFORM.get_main_display_brightness()
     brightness_level = 32
     plt.PLATFORM.set_main_display_brightness(brightness_level)
@@ -614,6 +851,8 @@ class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
     self.assertEqual(prev_level, plt.PLATFORM.get_main_display_brightness())
 
   def test_check_autobrightness(self):
+    if test_helper.is_on_swarming():
+      self.skipTest("Skipping this to run in CQ due to crbug.com/396405604.")
     self.platform.check_autobrightness()
 
   def test_exec_apple_script(self):
@@ -638,6 +877,7 @@ class MacOSNativePlatformTestCase(PosixNativePlatformTestCase):
 class WinNativePlatformTestCase(NativePlatformTestCase):
   platform: plt.WinPlatform
 
+  @override
   def setUp(self):
     super().setUp()
     assert isinstance(plt.PLATFORM, plt.WinPlatform)
@@ -650,13 +890,15 @@ class WinNativePlatformTestCase(NativePlatformTestCase):
   def test_search_binary(self):
     with self.assertRaises(ValueError):
       self.platform.search_binary(pathlib.Path("does not exist"))
-    path = self.platform.search_binary(
-        pathlib.Path("Windows NT/Accessories/wordpad.exe"))
+    path = pathlib.Path(
+        self.platform.search_binary(
+            pathlib.Path("Windows NT/Accessories/wordpad.exe")))
     self.assertTrue(path and path.exists())
 
   def test_app_version(self):
-    path = self.platform.search_binary(
-        pathlib.Path("Windows NT/Accessories/wordpad.exe"))
+    path = pathlib.Path(
+        self.platform.search_binary(
+            pathlib.Path("Windows NT/Accessories/wordpad.exe")))
     self.assertTrue(path and path.exists())
     version = self.platform.app_version(path)
     self.assertIsNotNone(version)
diff --git a/tests/crossbench/plt/test_signals.py b/tests/crossbench/plt/test_signals.py
new file mode 100644
index 00000000..b081737b
--- /dev/null
+++ b/tests/crossbench/plt/test_signals.py
@@ -0,0 +1,79 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import signal
+import unittest
+
+from typing_extensions import override
+
+from crossbench import plt
+from crossbench.plt.signals import (LinuxSignals, MacOSSignals, PosixBaseSignal,
+                                    PosixSignals, WinSignals)
+from tests import test_helper
+
+
+class SignalsTestCase(unittest.TestCase):
+
+  @override
+  def setUp(self):
+    self.platform = plt.PLATFORM
+
+  def signal_names(self, signals_obj):
+    for signal_name in dir(signals_obj):
+      if signal_name.startswith("SIG_"):
+        continue
+      if signal_name.startswith("SIG"):
+        yield signal_name
+
+  def test_plt_matches_python(self):
+    for signal_name in self.signal_names(signal):
+      plt_value = getattr(self.platform.signals, signal_name)
+      py_value = getattr(signal, signal_name)
+      self.assertEqual(plt_value, py_value, f"Signal {signal_name} mismatch")
+
+  def test_python_matches_plt(self):
+    for signal_name in self.signal_names(self.platform.signals):
+      plt_value = getattr(self.platform.signals, signal_name)
+      py_value = getattr(signal, signal_name)
+      self.assertEqual(plt_value, py_value, f"Signal {signal_name} mismatch")
+
+  def test_base_signals(self):
+    base_names = {"SIGABRT", "SIGFPE", "SIGILL", "SIGINT", "SIGSEGV", "SIGTERM"}
+    for posix_subclass in (PosixBaseSignal, PosixSignals, LinuxSignals,
+                           MacOSSignals, WinSignals):
+      subclass_names = set(self.signal_names(posix_subclass))
+      # All BaseSignals must be present.
+      self.assertFalse(base_names.difference(subclass_names))
+
+  def test_posix_base_signals(self):
+    posix_base_names = set(self.signal_names(PosixBaseSignal))
+    for posix_subclass in (PosixSignals, LinuxSignals, MacOSSignals):
+      posix_names = set(self.signal_names(posix_subclass))
+      for signal_name in posix_base_names:
+        # Both value and name must match for all PosixBaseSignal and its
+        # subclasses.
+        self.assertIn(signal_name, posix_names)
+        self.assertEqual(PosixBaseSignal[signal_name],
+                         posix_subclass[signal_name])
+
+  def test_posix_signals(self):
+    posix_names = set(self.signal_names(PosixSignals))
+    linux_names = set(self.signal_names(LinuxSignals))
+    for signal_name in posix_names:
+      self.assertIn(signal_name, linux_names)
+      self.assertEqual(PosixSignals[signal_name], LinuxSignals[signal_name])
+
+  def test_posix_signal_names(self):
+    posix_names = set(self.signal_names(PosixSignals))
+    for posix_subclass in (LinuxSignals, MacOSSignals):
+      posix_names = set(self.signal_names(posix_subclass))
+      for signal_name in posix_names:
+        # Subclasses must have all posix signal names, values might differ.
+        self.assertIn(signal_name, posix_names)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/plt/test_win.py b/tests/crossbench/plt/test_win.py
index afc18666..b13a0f44 100644
--- a/tests/crossbench/plt/test_win.py
+++ b/tests/crossbench/plt/test_win.py
@@ -8,17 +8,24 @@ import os
 import pathlib
 from unittest import mock
 
+from pyfakefs.fake_filesystem import OSType
+from typing_extensions import override
+
 from crossbench import path as pth
 from tests import test_helper
 from tests.crossbench.mock_helper import WinMockPlatform
-from tests.crossbench.plt.helper import BaseMockPlatformTestCase
+from tests.crossbench.plt.helper import (BaseLocalMockPlatformTestMixin,
+                                         BaseMockPlatformTestCase)
 
 
-class WinMockPlatformTestCase(BaseMockPlatformTestCase):
+class WinMockPlatformTestCase(BaseLocalMockPlatformTestMixin,
+                              BaseMockPlatformTestCase):
   __test__ = True
 
+  @override
   def mock_platform_setup(self):
     self.mock_platform = WinMockPlatform()
+    self.fs.os = OSType.WINDOWS
     self.platform = self.mock_platform
 
   def path(self, path: pth.AnyPathLike) -> pathlib.PureWindowsPath:
diff --git a/tests/crossbench/probes/helper.py b/tests/crossbench/probes/helper.py
index b26aaf7c..a503e4fc 100644
--- a/tests/crossbench/probes/helper.py
+++ b/tests/crossbench/probes/helper.py
@@ -7,11 +7,11 @@ from __future__ import annotations
 import copy
 import json
 from typing import (TYPE_CHECKING, Any, Callable, Iterable, List, Sequence,
-                    Tuple, Union)
+                    Tuple)
 
-from crossbench.benchmarks.loading.loading_benchmark import PageLoadBenchmark
+from crossbench.benchmarks.loading.loading_benchmark import LoadingBenchmark
 from crossbench.benchmarks.loading.page.combined import CombinedPage
-from crossbench.env import HostEnvironmentConfig, ValidationMode
+from crossbench.env import EnvironmentConfig, ValidationMode
 from crossbench.probes.probe import Probe
 from crossbench.runner.runner import Runner
 from tests.crossbench.base import BaseCrossbenchTestCase
@@ -23,8 +23,7 @@ class GenericProbeTestCase(BaseCrossbenchTestCase):
 
   def create_runner(self,
                     stories: Sequence[Page],
-                    js_side_effects: Union[List[Any], Callable[[Page],
-                                                               List[Any]]],
+                    js_side_effects: List[Any] | Callable[[Page], List[Any]],
                     separate: bool = False,
                     repetitions: int = 3,
                     warmup_repetitions: int = 0,
@@ -48,19 +47,20 @@ class GenericProbeTestCase(BaseCrossbenchTestCase):
     for browser in self.browsers:
       browser.expected_js = copy.deepcopy(browser.expected_js)
 
-    benchmark = PageLoadBenchmark(stories)  # pytype: disable=not-instantiable
+    benchmark = LoadingBenchmark(stories)  # pytype: disable=not-instantiable
     self.assertTrue(len(benchmark.describe()) > 0)
     runner = Runner(
         self.out_dir,
         self.browsers,
         benchmark,
-        env_config=HostEnvironmentConfig(),
+        env_config=EnvironmentConfig(),
         env_validation_mode=ValidationMode.SKIP,
         platform=self.platform,
         repetitions=repetitions,
         warmup_repetitions=warmup_repetitions,
         cache_temperatures=cache_temperatures,
-        throw=throw)
+        throw=throw,
+        in_memory_result_db=True)
     return runner
 
   def get_non_empty_json_results(self, runner: Runner,
diff --git a/tests/crossbench/probes/profiling/__init__.py b/tests/crossbench/probes/profiling/__init__.py
new file mode 100644
index 00000000..4547f8b8
--- /dev/null
+++ b/tests/crossbench/probes/profiling/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/crossbench/probes/test_system_profiling.py b/tests/crossbench/probes/profiling/test_system_profiling.py
similarity index 94%
rename from tests/crossbench/probes/test_system_profiling.py
rename to tests/crossbench/probes/profiling/test_system_profiling.py
index 89418777..743c3443 100644
--- a/tests/crossbench/probes/test_system_profiling.py
+++ b/tests/crossbench/probes/profiling/test_system_profiling.py
@@ -6,10 +6,16 @@ import argparse
 import pathlib
 import unittest
 
+from typing_extensions import override
+
 from crossbench.browsers.settings import Settings
-from crossbench.probes.profiling.system_profiling import (
-    RENDERER_CMD_PATH, CallGraphMode, CleanupMode, ProfilingProbe, TargetMode,
-    generate_simpleperf_command_line)
+from crossbench.probes.profiling.context.android import \
+    generate_simpleperf_command_line
+from crossbench.probes.profiling.system_profiling import (RENDERER_CMD_PATH,
+                                                          CallGraphMode,
+                                                          CleanupMode,
+                                                          ProfilingProbe,
+                                                          TargetMode)
 from tests import test_helper
 from tests.crossbench.mock_browser import (MockChromeStable, MockFirefox,
                                            MockSafari)
@@ -19,6 +25,7 @@ from tests.crossbench.probes.helper import GenericProbeTestCase
 
 class SystemProfilingProbeTestCase(GenericProbeTestCase):
 
+  @override
   def setUp(self):
     super().setUp()
     self.fs.add_real_file(RENDERER_CMD_PATH)
@@ -323,8 +330,9 @@ class EnumTestCase(unittest.TestCase):
         TargetMode("RENDERER_MAIN_ONLY"), TargetMode.RENDERER_MAIN_ONLY)
 
   def test_call_graph_mode(self):
-    self.assertIs(CallGraphMode("frame_pointer"), CallGraphMode.FRAME_POINTER)
-    self.assertIs(CallGraphMode("FRAME_POINTER"), CallGraphMode.FRAME_POINTER)
+    self.assertIs(CallGraphMode("fp"), CallGraphMode.FRAME_POINTER)
+    self.assertIs(CallGraphMode("FP"), CallGraphMode.FRAME_POINTER)
+
 
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_chrome_histograms.py b/tests/crossbench/probes/test_chrome_histograms.py
index a4736ddd..8fc4cc27 100644
--- a/tests/crossbench/probes/test_chrome_histograms.py
+++ b/tests/crossbench/probes/test_chrome_histograms.py
@@ -9,7 +9,7 @@ from typing import Dict
 import hjson
 import pytest
 
-from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
 from crossbench.probes.chrome_histograms import (ChromeHistogramMetric,
                                                  ChromeHistogramSample,
                                                  ChromeHistogramsProbe,
@@ -179,3 +179,7 @@ class ChromeHistogramProbeTestCase(GenericProbeTestCase):
         "Startup.FirstWebContents.NonEmptyPaint3_p50",
         "Startup.FirstWebContents.NonEmptyPaint3_p90",
     ])
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_config.py b/tests/crossbench/probes/test_config.py
index 68511922..7edb864c 100644
--- a/tests/crossbench/probes/test_config.py
+++ b/tests/crossbench/probes/test_config.py
@@ -3,10 +3,11 @@
 # found in the LICENSE file.
 
 import argparse
+import enum
 import unittest
 
-from crossbench import compat
 from crossbench.probes.probe import Probe, ProbeConfigParser
+from crossbench.str_enum_with_help import StrEnumWithHelp
 from tests import test_helper
 
 
@@ -140,12 +141,12 @@ class ProbeConfigTestCase(unittest.TestCase):
     parser = ProbeConfigParser(MockProbe)
     parser.add_argument("int_list", type=int, is_list=True, default=[111, 222])
     kwargs = parser.kwargs_from_config({})
-    self.assertDictEqual(kwargs, {"int_list": [111, 222]})
+    self.assertDictEqual(kwargs, {"int_list": (111, 222)})
 
     config_data = {"int_list": [0, 1]}
     kwargs = parser.kwargs_from_config(config_data)
     self.assertDictEqual(config_data, {"int_list": [0, 1]})
-    self.assertDictEqual(kwargs, {"int_list": [0, 1]})
+    self.assertDictEqual(kwargs, {"int_list": (0, 1)})
 
   def test_custom_type(self):
     parser = ProbeConfigParser(MockProbe)
@@ -183,7 +184,7 @@ class ProbeConfigTestCase(unittest.TestCase):
 
   def test_enum_type(self):
 
-    class MyEnum(compat.StrEnum):
+    class MyEnum(enum.StrEnum):
       ONE = "one"
       TWO = "two"
 
@@ -214,7 +215,7 @@ class ProbeConfigTestCase(unittest.TestCase):
 
   def test_enum_with_help(self):
 
-    class MyEnum(compat.StrEnumWithHelp):
+    class MyEnum(StrEnumWithHelp):
       ONE = ("oneX", "the one help")
       TWO = ("twoX", "the two help")
 
diff --git a/tests/crossbench/probes/test_config_presets.py b/tests/crossbench/probes/test_config_presets.py
index 07bb7d0b..4173b71f 100644
--- a/tests/crossbench/probes/test_config_presets.py
+++ b/tests/crossbench/probes/test_config_presets.py
@@ -11,8 +11,8 @@ import crossbench.path
 from crossbench import plt
 from crossbench.benchmarks.loading.loadline_presets import \
     LoadLineTabletBenchmark
-from crossbench.cli.config.probe import ProbeListConfig
-from crossbench.helper import ChangeCWD
+from crossbench.cli.config.probe_list import ProbeListConfig
+from crossbench.helper.cwd import ChangeCWD
 from crossbench.helper.path_finder import default_chromium_candidates
 from crossbench.probes.all import GENERAL_PURPOSE_PROBES
 from crossbench.probes.probe import Probe
@@ -34,8 +34,8 @@ class ProbeConfigTestCase(fake_filesystem_unittest.TestCase):
     self.real_config_dir = test_helper.config_dir()
     super().setUp()
     self.setUpPyfakefs(modules_to_reload=[crossbench.path])
-    if test_helper.is_google_env():
-      self.fs.add_real_directory("/build/cas")
+    self._add_real_directory(test_helper.crossbench_dir() /
+                             "probes/perfetto/trace_processor/queries")
     self.set_up_required_paths()
 
   def set_up_required_paths(self):
@@ -51,8 +51,7 @@ class ProbeConfigTestCase(fake_filesystem_unittest.TestCase):
   def _test_parse_config_dir(self,
                              real_config_dir: pathlib.Path) -> List[Probe]:
     probes = []
-    self.fs.add_real_directory(
-        real_config_dir, lazy_read=not test_helper.is_google_env())
+    self._add_real_directory(real_config_dir)
     for probe_config in real_config_dir.glob("**/*.config.hjson"):
       with ChangeCWD(probe_config.parent):
         probes += self._parse_config(probe_config)
@@ -72,6 +71,27 @@ class ProbeConfigTestCase(fake_filesystem_unittest.TestCase):
       self.assertFalse(probe.is_attached)
     return probes
 
+  def _add_real_directory(self, path: crossbench.path.LocalPathLike) -> None:
+    self.fs.add_real_directory(
+        path, lazy_read=not test_helper.is_google_env())
+    if test_helper.is_google_env():
+      # On google3, all files have been replaced by symlinks. The link targets
+      # must be added in order for these symlinks to resolve.
+      for child in path.glob("**/*"):
+        if child.is_symlink():
+          link_target = child.readlink()
+          if not link_target.exists():
+            self.fs.add_real_file(link_target)
+
+  def _add_real_file(self, path: crossbench.path.LocalPathLike) -> None:
+    self.fs.add_real_file(path)
+    if test_helper.is_google_env() and path.is_symlink():
+      # On google3, all files have been replaced by symlinks. The link targets
+      # must be added in order for these symlinks to resolve.
+      link_target = path.readlink()
+      if not link_target.exists():
+        self.fs.add_real_file(link_target)
+
   def test_parse_example_configs(self):
     probe_config_presets = self.real_config_dir / "probe"
     probes = self._test_parse_config_dir(probe_config_presets)
@@ -84,7 +104,7 @@ class ProbeConfigTestCase(fake_filesystem_unittest.TestCase):
 
   def test_parse_loadline_configs(self):
     probe_config = LoadLineTabletBenchmark.default_probe_config_path()
-    self.fs.add_real_file(probe_config)
+    self._add_real_file(probe_config)
     probes = ProbeListConfig.parse_path(probe_config).probes
     self.assertTrue(probes)
 
diff --git a/tests/crossbench/probes/test_cpu_frequency_map.py b/tests/crossbench/probes/test_cpu_frequency_map.py
new file mode 100644
index 00000000..0e323e5d
--- /dev/null
+++ b/tests/crossbench/probes/test_cpu_frequency_map.py
@@ -0,0 +1,159 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+from typing import List
+
+from typing_extensions import override
+
+from crossbench import path as pth
+from crossbench.plt.linux import LinuxPlatform
+from crossbench.probes.cpu_frequency_map import CPUFrequencyMap
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class CPUFrequencyMapTestCase(CrossbenchFakeFsTestCase):
+
+  @override
+  def setUp(self):
+    super().setUp()
+    self.platform = LinuxPlatform()
+
+  def test_parse_invalid_map_value(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "Invalid value"):
+      CPUFrequencyMap.parse({"cpu0": "invalid"})
+
+  def test_parse_conflicting_wildcard(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError,
+                                "should be the only key"):
+      CPUFrequencyMap.parse({"*": "max", "cpu0": "min"})
+
+  def test_key(self):
+    key1 = CPUFrequencyMap.parse({"cpu0": 1111}).key
+    key2 = CPUFrequencyMap.parse({"*": 2222}).key
+
+    self.assertIsNotNone(key1)
+    self.assertIsNotNone(key2)
+    self.assertNotEqual(key1, key2)
+    self.assertTrue(hash(key1))
+    self.assertTrue(hash(key2))
+
+  def test_validate_fails_due_to_missing_cpus_dir(self):
+    frequency_map = CPUFrequencyMap.parse({"cpu0": 42})
+    # No call to self._create_cpu_dir().
+
+    with self.assertRaisesRegex(FileNotFoundError,
+                                "/sys/devices/system/cpu not found"):
+      frequency_map.get_target_frequencies(self.platform)
+
+  def test_validate_fails_due_to_missing_cpu_name(self):
+    frequency_map = CPUFrequencyMap.parse({"nonexistent-cpu": 1})
+    self._create_cpu_dir("cpu0", [1])
+
+    with self.assertRaisesRegex(ValueError, "nonexistent-cpu"):
+      frequency_map.get_target_frequencies(self.platform)
+
+  def test_validate_fails_due_to_missing_numerical_frequency(self):
+    frequency_map = CPUFrequencyMap.parse({"cpu0": 42})
+    self._create_cpu_dir("cpu0", [1, 2])
+    self._create_cpu_dir("cpu1", [42])
+
+    with self.assertRaisesRegex(
+        ValueError, r"Target frequency 42 for cpu0 not allowed in linux.*. "
+        r"Available frequencies: \[1, 2\]"):
+      frequency_map.get_target_frequencies(self.platform)
+
+  def test_validate_fails_due_to_missing_numerical_frequency_with_wildcard(
+      self):
+    frequency_map = CPUFrequencyMap.parse({"*": 42})
+    self._create_cpu_dir("cpu0", [1, 2])
+
+    with self.assertRaisesRegex(
+        ValueError, r"Target frequency 42 for cpu0 not allowed in linux.*. "
+        r"Available frequencies: \[1, 2\]"):
+      frequency_map.get_target_frequencies(self.platform)
+
+  def test_validate_succeeds_with_extremes(self):
+    frequency_map = CPUFrequencyMap.parse({"cpu0": "max", "cpu1": "min"})
+    self._create_cpu_dir("cpu0", [1, 2])
+    self._create_cpu_dir("cpu1", [1, 2])
+
+    target_frequencies = frequency_map.get_target_frequencies(self.platform)
+
+    self.assertDictEqual(
+        dict(target_frequencies), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 1,
+        })
+
+  def test_validate_succeeds_without_wildcard(self):
+    frequency_map = CPUFrequencyMap.parse({"cpu0": 2, "cpu1": 2, "cpu2": 2})
+    # Use different orders to stress the parsing logic.
+    self._create_cpu_dir("cpu0", [2, 1, 3])
+    self._create_cpu_dir("cpu1", [1, 2, 3])
+    self._create_cpu_dir("cpu2", [1, 3, 2])
+    self._create_cpu_dir("cpu3", [42, 42, 42])
+    self._create_cpu_dir("cpu4", [42, 42, 42])
+
+    target_frequencies = frequency_map.get_target_frequencies(self.platform)
+
+    self.assertDictEqual(
+        dict(target_frequencies), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu2/cpufreq"): 2,
+        })
+
+  def test_validate_succeeds_with_wildcard(self):
+    frequency_map = CPUFrequencyMap.parse({"*": 2})
+    # Use different orders to stress the parsing logic.
+    self._create_cpu_dir("cpu0", [2, 1, 3])
+    self._create_cpu_dir("cpu1", [1, 2, 3])
+    self._create_cpu_dir("cpu2", [1, 3, 2])
+
+    target_frequencies = frequency_map.get_target_frequencies(self.platform)
+
+    self.assertDictEqual(
+        dict(target_frequencies), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 2,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu2/cpufreq"): 2,
+        })
+
+  def test_validate_succeeds_for_empty_config(self):
+    self._create_cpu_dir("cpu0", [1, 2, 3])
+
+    target_frequencies = CPUFrequencyMap.parse({}).get_target_frequencies(
+        self.platform)
+
+    self.assertFalse(target_frequencies)
+
+  def test_validate_string_wildcard(self):
+    frequency_map = CPUFrequencyMap.parse("max")
+    self._create_cpu_dir("cpu0", [1, 2, 3])
+    self._create_cpu_dir("cpu1", [1, 2, 3])
+
+    target_frequencies = frequency_map.get_target_frequencies(self.platform)
+
+    self.assertDictEqual(
+        dict(target_frequencies), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 3,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 3,
+        })
+
+  def _create_cpu_dir(self, cpu_name: str, available_frequencies: List[int]):
+    cpu_dir = pth.AnyPosixPath(f"/sys/devices/system/cpu/{cpu_name}/cpufreq")
+    self.platform.mkdir(cpu_dir, parents=True, exist_ok=True)
+    self.platform.set_file_contents(
+        cpu_dir / "scaling_available_frequencies",
+        " ".join(map(str, available_frequencies)) + "\n")
+    self.platform.set_file_contents(cpu_dir / "scaling_min_freq",
+                                    str(min(available_frequencies)) + "\n")
+    self.platform.set_file_contents(cpu_dir / "scaling_max_freq",
+                                    str(max(available_frequencies)) + "\n")
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_dtrace.py b/tests/crossbench/probes/test_dtrace.py
index 1905e610..d42dac29 100644
--- a/tests/crossbench/probes/test_dtrace.py
+++ b/tests/crossbench/probes/test_dtrace.py
@@ -2,7 +2,7 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
-from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
 from crossbench.probes.dtrace import DTraceProbe
 from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
diff --git a/tests/crossbench/probes/test_frequency.py b/tests/crossbench/probes/test_frequency.py
index d320ef09..6acf5c65 100644
--- a/tests/crossbench/probes/test_frequency.py
+++ b/tests/crossbench/probes/test_frequency.py
@@ -2,11 +2,11 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
-import argparse
 from typing import List
 from unittest import mock
 
 from immutabledict import immutabledict
+from typing_extensions import override
 
 from crossbench import path as pth
 from crossbench.browsers.browser import Browser
@@ -19,164 +19,39 @@ from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
 
 
-# TODO(crbug.com/372862708): Turn most of these into unit tests for
-# CPUFrequencyMap and leave only 1-2 tests that verify the communication between
-# the 2 classes.
-
-
 class FrequencyProbeTestCase(CrossbenchFakeFsTestCase):
-  __test__ = True
 
+  @override
   def setUp(self):
     super().setUp()
     self.platform = LinuxPlatform()
 
-  def test_parse_invalid_map_value(self):
-    with self.assertRaisesRegex(argparse.ArgumentTypeError, "Invalid value"):
-      FrequencyProbe.from_config({"cpus": {"cpu0": "invalid"}})
-
-  def test_parse_conflicting_wildcard(self):
-    with self.assertRaisesRegex(argparse.ArgumentTypeError,
-                                "should be the only key"):
-      FrequencyProbe.from_config({"cpus": {"*": "max", "cpu0": "min"}})
-
-  def test_key(self):
-    key1 = FrequencyProbe.from_config({"cpus": {"cpu0": 1111}}).key
-    key2 = FrequencyProbe.from_config({"cpus": {"*": 2222}}).key
-
-    self.assertIsNotNone(key1)
-    self.assertIsNotNone(key2)
-    self.assertNotEqual(key1, key2)
-
-  def test_validate_fails_due_to_missing_cpus_dir(self):
-    probe = FrequencyProbe.from_config({"cpus": {"cpu0": 42}})
-    # No call to self._create_cpu_dir().
-
-    with self.assertRaisesRegex(FileNotFoundError,
-                                "/sys/devices/system/cpu not found"):
-      probe.validate_browser(
-          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
-
-  def test_validate_fails_due_to_missing_cpu_name(self):
-    probe = FrequencyProbe.from_config({"cpus": {"nonexistent-cpu": 1}})
-    self._create_cpu_dir("cpu0", [1])
-
-    with self.assertRaisesRegex(ValueError, "nonexistent-cpu"):
-      probe.validate_browser(
-          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
-
-  def test_validate_fails_due_to_missing_numerical_frequency(self):
-    probe = FrequencyProbe.from_config({"cpus": {"cpu0": 42}})
-    self._create_cpu_dir("cpu0", [1, 2])
-    self._create_cpu_dir("cpu1", [42])
-
-    with self.assertRaisesRegex(
-        ValueError, r"Target frequency 42 for cpu0 not allowed in linux.*. "
-        r"Available frequencies: \[1, 2\]"):
-      probe.validate_browser(
-          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
-
-  def test_validate_fails_due_to_missing_numerical_frequency_with_wildcard(
-      self):
-    probe = FrequencyProbe.from_config({"cpus": {"*": 42}})
-    self._create_cpu_dir("cpu0", [1, 2])
-
-    with self.assertRaisesRegex(
-        ValueError, r"Target frequency 42 for cpu0 not allowed in linux.*. "
-        r"Available frequencies: \[1, 2\]"):
-      probe.validate_browser(
-          mock.Mock(spec=HostEnvironment), self._create_mock_browser())
-
-  def test_validate_succeeds_with_extremes(self):
-    probe = FrequencyProbe.from_config({"cpus": {"cpu0": "max", "cpu1": "min"}})
-    self._create_cpu_dir("cpu0", [1, 2])
-    self._create_cpu_dir("cpu1", [1, 2])
-    browser = self._create_mock_browser()
-
-    # Implicitly asserts no exception occurs.
-    probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
-    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
-        browser.platform)
-
-    self.assertDictEqual(
-        dict(frequency_map), {
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 1,
-        })
-
-
-  def test_validate_succeeds_without_wildcard(self):
+  # Simply tests the communication between FrequencyProbe and CPUFrequencyMap.
+  # Details for the latter are tested in CPUFrequencyMapTestCase.
+  def test_validate(self):
     probe = FrequencyProbe.from_config(
         {"cpus": {
-            "cpu0": 2,
-            "cpu1": 2,
-            "cpu2": 2
+            "cpu10": "min",
+            "cpu20": 20,
+            "cpu30": "max"
         }})
-    # Use different orders to stress the parsing logic.
-    self._create_cpu_dir("cpu0", [2, 1, 3])
-    self._create_cpu_dir("cpu1", [1, 2, 3])
-    self._create_cpu_dir("cpu2", [1, 3, 2])
-    self._create_cpu_dir("cpu3", [42, 42, 42])
-    self._create_cpu_dir("cpu4", [42, 42, 42])
-    browser = self._create_mock_browser()
-
-    # Implicitly asserts no exception occurs.
-    probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
-    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
-        browser.platform)
-
-    self.assertDictEqual(
-        dict(frequency_map), {
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 2,
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu2/cpufreq"): 2,
-        })
-
-  def test_validate_succeeds_with_wildcard(self):
-    probe = FrequencyProbe.from_config({"cpus": {"*": 2}})
-    # Use different orders to stress the parsing logic.
-    self._create_cpu_dir("cpu0", [2, 1, 3])
-    self._create_cpu_dir("cpu1", [1, 2, 3])
-    self._create_cpu_dir("cpu2", [1, 3, 2])
-    browser = self._create_mock_browser()
-
-    # Implicitly asserts no exception occurs.
-    probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
-    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
-        browser.platform)
-
-    self.assertDictEqual(
-        dict(frequency_map), {
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 2,
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 2,
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu2/cpufreq"): 2,
-        })
-
-  def test_validate_succeeds_for_empty_configs(self):
-    browser = self._create_mock_browser()
-    self._create_cpu_dir("cpu0", [1, 2, 3])
-
-    FrequencyProbe.from_config({}).validate_browser(
-        mock.Mock(spec=HostEnvironment), browser)
-    FrequencyProbe.from_config({
-        "cpus": {},
-    }).validate_browser(mock.Mock(spec=HostEnvironment), browser)
-
-  def test_validate_string_wildcard(self):
-    probe = FrequencyProbe.from_config({"cpus": "max"})
-    self._create_cpu_dir("cpu0", [1, 2, 3])
-    self._create_cpu_dir("cpu1", [1, 2, 3])
+    self._create_cpu_dir("cpu10", [20, 10, 30])
+    self._create_cpu_dir("cpu20", [10, 20, 30])
+    self._create_cpu_dir("cpu30", [10, 30, 20])
+    self._create_cpu_dir("cpu40", [42, 42, 42])
+    self._create_cpu_dir("cpu50", [42, 42, 42])
     browser = self._create_mock_browser()
 
     # Implicitly asserts no exception occurs.
     probe.validate_browser(mock.Mock(spec=HostEnvironment), browser)
-    frequency_map = probe.cpu_frequency_map.get_target_frequencies(
+    target_frequencies = probe.cpu_frequency_map.get_target_frequencies(
         browser.platform)
 
     self.assertDictEqual(
-        dict(frequency_map), {
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu0/cpufreq"): 3,
-            pth.AnyPosixPath("/sys/devices/system/cpu/cpu1/cpufreq"): 3,
+        dict(target_frequencies), {
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu10/cpufreq"): 10,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu20/cpufreq"): 20,
+            pth.AnyPosixPath("/sys/devices/system/cpu/cpu30/cpufreq"): 30,
         })
 
   def test_start_and_stop(self):
diff --git a/tests/crossbench/probes/test_js.py b/tests/crossbench/probes/test_js.py
index dc164004..6b66e179 100644
--- a/tests/crossbench/probes/test_js.py
+++ b/tests/crossbench/probes/test_js.py
@@ -3,7 +3,7 @@
 # found in the LICENSE file.
 
 from crossbench.benchmarks.loading.page.live import LivePage
-from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
 from crossbench.probes.js import JSProbe
 from tests import test_helper
 from tests.crossbench.probes.helper import GenericProbeTestCase
diff --git a/tests/crossbench/probes/test_metric.py b/tests/crossbench/probes/test_metric.py
index d30e7d1e..303e796f 100644
--- a/tests/crossbench/probes/test_metric.py
+++ b/tests/crossbench/probes/test_metric.py
@@ -4,6 +4,7 @@
 
 import json
 import pathlib
+import sys
 import unittest
 
 from crossbench.probes.metric import CSVFormatter, Metric, MetricsMerger
@@ -91,6 +92,36 @@ class MetricTestCase(unittest.TestCase):
     self.assertEqual(json_data["average"], 0)
     self.assertEqual(json_data["stddevPercent"], 0)
 
+  def test_sum(self):
+    metric = Metric([1, 3])
+    self.assertEqual(metric.sum, 4)
+    self.assertIsInstance(metric.sum, int)
+
+  def test_average(self):
+    metric = Metric([1, 3])
+    average = metric.average
+    self.assertEqual(average, 2.0)
+    self.assertIsInstance(average, float)
+    self.assertEqual(Metric([0, 0]).average, 0)
+    self.assertEqual(Metric([-1, -1]).average, -1)
+
+  def test_geomean(self):
+    metric = Metric([1, 4])
+    geomean = metric.geomean
+    self.assertEqual(geomean, 2.0)
+    self.assertIsInstance(geomean, float)
+
+    metric = Metric([1.1, 4.1])
+    self.assertLess(geomean, metric.geomean)
+    self.assertIsInstance(metric.geomean, float)
+
+    self.assertEqual(Metric([-1, -1]).geomean, 0)
+
+  def test_geomean_overflow(self):
+    metric = Metric([sys.maxsize] * 20)
+    self.assertLess(0, metric.geomean)
+    self.assertLess(abs(metric.geomean - float(sys.maxsize)), 10**5)
+
 
 class MetricsMergerTestCase(CrossbenchFakeFsTestCase):
 
@@ -156,6 +187,41 @@ class MetricsMergerTestCase(CrossbenchFakeFsTestCase):
     self.assertListEqual(data["a/ab"].values, [2, 2])
     self.assertListEqual(data["b"].values, [3, 3])
     self.assertListEqual(data["c/cc/ccc"].values, [4, 4])
+    json_data = merger.to_json()
+    self.assertListEqual(json_data["a/aa"]["values"], [1, 1])
+    self.assertListEqual(json_data["a/ab"]["values"], [2, 2])
+    self.assertListEqual(json_data["b"]["values"], [3, 3])
+    self.assertListEqual(json_data["c/cc/ccc"]["values"], [4, 4])
+
+  def test_repeated_non_numeric(self):
+    merger = MetricsMerger()
+    input_data = {"a": {"aa": "a.aa", "ab": "a.ab"}}
+    merger.add(input_data)
+    merger.add(input_data)
+    data = merger.data
+    self.assertEqual(len(data), 2)
+    self.assertListEqual(data["a/aa"].values, ["a.aa", "a.aa"])
+    self.assertListEqual(data["a/ab"].values, ["a.ab", "a.ab"])
+    json_data = merger.to_json()
+    self.assertDictEqual(json_data, {"a/aa": "a.aa", "a/ab": "a.ab"})
+
+  def test_repeated_non_numeric_nested(self):
+    merger = MetricsMerger()
+    input_data = {"a": {"aa": "a.aa", "ab": {"cccA": "cccA", "cccB": "cccB"}}}
+    merger.add(input_data)
+    merger.add(input_data)
+    data = merger.data
+    self.assertEqual(len(data), 3)
+    self.assertListEqual(data["a/aa"].values, ["a.aa", "a.aa"])
+    self.assertListEqual(data["a/ab/cccA"].values, ["cccA", "cccA"])
+    self.assertListEqual(data["a/ab/cccB"].values, ["cccB", "cccB"])
+    json_data = merger.to_json()
+    self.assertDictEqual(json_data, {
+        "a/aa": "a.aa",
+        "a/ab/cccA": "cccA",
+        "a/ab/cccB": "cccB"
+    })
+
 
   BASIC_NESTED_DATA = {
       "a": {
@@ -227,7 +293,8 @@ class MetricsMergerTestCase(CrossbenchFakeFsTestCase):
     merger = MetricsMerger()
     merger.add(self.BASIC_NESTED_DATA)
     csv = CSVFormatter(
-        merger, lambda metric: metric.geomean, include_parts=False).table
+        merger, lambda metric: round(metric.geomean, 10),
+        include_parts=False).table
     self.assertListEqual(csv, [
         ("a/a/a", 1.0),
         ("a/a/b", 2.0),
@@ -238,7 +305,8 @@ class MetricsMergerTestCase(CrossbenchFakeFsTestCase):
     merger = MetricsMerger()
     merger.add(self.BASIC_NESTED_DATA)
     csv = CSVFormatter(
-        merger, lambda metric: metric.geomean, include_parts=True).table
+        merger, lambda metric: round(metric.geomean, 10),
+        include_parts=True).table
     self.assertListEqual(csv, [
         ("a/a/a", "a", "a", "a", 1.0),
         ("a/a/b", "a", "a", "b", 2.0),
@@ -274,7 +342,8 @@ class CSVFormatterTestCase(unittest.TestCase):
         "cdjs/average": 30,
         "cdjs/score": 40,
     })
-    table = CSVFormatter(metrics, lambda metric: metric.geomean).table
+    table = CSVFormatter(metrics,
+                         lambda metric: round(metric.geomean, 10)).table
     self.assertSequenceEqual(table, [
         ("Total/average", "Total", "average", 10.0),
         ("Total/score", "Total", "score", 20.0),
diff --git a/tests/crossbench/probes/test_perfetto.py b/tests/crossbench/probes/test_perfetto.py
index 5284bf20..29e2dd62 100644
--- a/tests/crossbench/probes/test_perfetto.py
+++ b/tests/crossbench/probes/test_perfetto.py
@@ -5,9 +5,14 @@
 import unittest
 
 import crossbench.path as pth
-from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
+from crossbench.plt.arch import MachineArch
 from crossbench.probes.all import PerfettoProbe
+from crossbench.probes.perfetto.downloader import PerfettoToolDownloader
 from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+from tests.crossbench.mock_helper import (LinuxMockPlatform, MacOsMockPlatform,
+                                          WinMockPlatform)
 
 
 class PerfettoProbeTestCase(unittest.TestCase):
@@ -31,5 +36,47 @@ class PerfettoProbeTestCase(unittest.TestCase):
     self.assertIsInstance(probe, PerfettoProbe)
 
 
+class PerfettoToolDownloaderTestCase(CrossbenchFakeFsTestCase):
+
+  def test_download_linux(self):
+    platform = LinuxMockPlatform()
+    self._download_perfetto_tool(platform, "linux-arm64")
+    platform = LinuxMockPlatform()
+    platform.machine = MachineArch.ARM_32
+    self._download_perfetto_tool(platform, "linux-arm")
+    platform = LinuxMockPlatform()
+    platform.machine = MachineArch.X64
+    self._download_perfetto_tool(platform, "linux-x64")
+
+  def test_download_macos(self):
+    platform = MacOsMockPlatform()
+    self._download_perfetto_tool(platform, "mac-arm64")
+    platform = MacOsMockPlatform()
+    platform.machine = MachineArch.X64
+    self._download_perfetto_tool(platform, "mac-amd64")
+
+  def test_download_win_invalid(self):
+    platform = WinMockPlatform()
+    with self.assertRaises(Exception):
+      self._download_perfetto_tool(platform, "win-arm64")
+
+  def _download_perfetto_tool(self, platform, key):
+    platform.use_mock_name = False
+    download_path = platform.cache_dir("perfetto") / "v49.0/traceconv"
+    platform.expect_download(
+        "https://commondatastorage.googleapis.com/perfetto-luci-artifacts/"
+        f"v49.0/{key}/traceconv", download_path)
+    platform.expect_sh(
+        download_path,
+        "--version",
+        result=("Perfetto v49.0-33a4fd078 "
+                "(33a4fd07897a9a648664926ea27769278a19ff13)"))
+    result = PerfettoToolDownloader("traceconv", platform=platform).download()
+    self.assertTrue(platform.exists(result))
+    # downloading the same will use the locally cached version
+    result = PerfettoToolDownloader("traceconv", platform=platform).download()
+    self.assertTrue(platform.exists(result))
+
+
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_probe.py b/tests/crossbench/probes/test_probe.py
index 489ff1a5..50bbc1ec 100644
--- a/tests/crossbench/probes/test_probe.py
+++ b/tests/crossbench/probes/test_probe.py
@@ -5,22 +5,33 @@
 import inspect
 
 import crossbench.path as pth
-from crossbench.cli.config.probe import ProbeListConfig
-from crossbench.probes.all import GENERAL_PURPOSE_PROBES, INTERNAL_PROBES
+from crossbench.cli.config.probe_list import ProbeListConfig
+from crossbench.probes.all import (CONFIGURABLE_INTERNAL_PROBES,
+                                   DEFAULT_INTERNAL_PROBES,
+                                   GENERAL_PURPOSE_PROBES, INTERNAL_PROBES,
+                                   NON_CONFIGURABLE_INTERNAL_PROBES,
+                                   OPTIONAL_INTERNAL_PROBES)
+from crossbench.probes.chrome_histograms import ChromeHistogramsProbe
+from crossbench.probes.chromium_probe import ChromiumProbe
 from crossbench.probes.debugger import DebuggerProbe
-from crossbench.probes.frequency import FrequencyProbe
+from crossbench.probes.downloads import DownloadsProbe
 from crossbench.probes.dtrace import DTraceProbe
 from crossbench.probes.dump_html import DumpHtmlProbe
+from crossbench.probes.env_modifier import EnvModifier
+from crossbench.probes.frequency import FrequencyProbe
+from crossbench.probes.js import JSProbe
+from crossbench.probes.json import JsonResultProbe
 from crossbench.probes.perfetto.perfetto import PerfettoProbe
 from crossbench.probes.perfetto.tracing import TracingProbe
 from crossbench.probes.performance_entries import PerformanceEntriesProbe
-from crossbench.probes.polling import ShellPollingProbe
+from crossbench.probes.polling import PollingShellProbe
 from crossbench.probes.power_sampler import PowerSamplerProbe
 from crossbench.probes.powermetrics import PowerMetricsProbe
 from crossbench.probes.probe import Probe
 from crossbench.probes.profiling.browser_profiling import BrowserProfilingProbe
 from crossbench.probes.profiling.system_profiling import ProfilingProbe
 from crossbench.probes.screenshot import ScreenshotProbe
+from crossbench.probes.shell import ShellProbe
 from crossbench.probes.system_stats import SystemStatsProbe
 from crossbench.probes.v8.builtins_pgo import V8BuiltinsPGOProbe
 from crossbench.probes.v8.log import V8LogProbe
@@ -56,26 +67,25 @@ class ProbeTestCase(CrossbenchFakeFsTestCase):
     yield from self.general_purpose_probe_instances()
 
   def internal_probe_instances(self):
-    for probe_cls in self.internal_probe_classes():
-      with self.subTest(probe_cls=probe_cls):
-        try:
-          yield probe_cls()
-        except GeneratorExit:
-          break
+    for probe_cls in INTERNAL_PROBES:
+      yield probe_cls()
 
   def general_purpose_probe_instances(self):
     yield BrowserProfilingProbe()
     yield DTraceProbe(pth.LocalPath("script.dtrace"))
     yield DebuggerProbe(pth.LocalPath("debugger.bin"))
+    yield DownloadsProbe()
     yield DumpHtmlProbe()
     yield FrequencyProbe.from_config({})
-    yield PerfettoProbe("textproto", pth.LocalPath("perfetto.bin"))
+    yield PerfettoProbe("textproto", pth.LocalPath("perfetto.bin"),
+                        pth.LocalPath("tracebox.bin"),
+                        trace_browser_startup=False)
     yield PerformanceEntriesProbe()
     yield PowerMetricsProbe()
     yield PowerSamplerProbe()
     yield ProfilingProbe()
     yield ScreenshotProbe()
-    yield ShellPollingProbe(cmd=["ls"])
+    yield PollingShellProbe(cmd=["ls"])
     yield SystemStatsProbe()
     yield TracingProbe()
     yield V8BuiltinsPGOProbe()
@@ -86,40 +96,37 @@ class ProbeTestCase(CrossbenchFakeFsTestCase):
     yield WebPageReplayProbe(wpr_go_bin=self.create_file("wpr.go"))
 
   def probe_classes(self):
-    yield from self.internal_probe_classes()
-    yield from self.general_purpose_probe_classes()
+    yield from INTERNAL_PROBES
+    yield from GENERAL_PURPOSE_PROBES
+
+  def test_general_purpose_probe_order(self):
+    sorted_probe_classes = sorted(GENERAL_PURPOSE_PROBES, key=lambda x: x.NAME)
+    self.assertSequenceEqual(GENERAL_PURPOSE_PROBES, sorted_probe_classes)
 
   def all_probe_subclasses(self, probe_cls=Probe):
     for probe_sub_cls in probe_cls.__subclasses__():
       if "Mock" in str(probe_sub_cls):
         continue
+      # Filter out abstract helper classes.
+      if probe_sub_cls in (ChromiumProbe, EnvModifier, JsonResultProbe):
+        continue
       if not inspect.isabstract(probe_sub_cls):
         yield probe_sub_cls
       yield from self.all_probe_subclasses(probe_sub_cls)
+    yield from OPTIONAL_INTERNAL_PROBES
 
-  def internal_probe_classes(self):
+  def test_properties(self):
     for probe_cls in INTERNAL_PROBES:
-      with self.subTest(probe_cls=probe_cls):
-        try:
-          yield probe_cls
-        except GeneratorExit:
-          break
+      with self.subTest(probe_cls=str(probe_cls)):
+        self.assertFalse(probe_cls.IS_GENERAL_PURPOSE)
 
-  def general_purpose_probe_classes(self):
     for probe_cls in GENERAL_PURPOSE_PROBES:
-      with self.subTest(probe_cls=probe_cls):
-        try:
-          yield probe_cls
-        except GeneratorExit:
-          break
+      with self.subTest(probe_cls=str(probe_cls)):
+        self.assertTrue(probe_cls.IS_GENERAL_PURPOSE)
 
-  def test_properties(self):
-    for probe_cls in self.internal_probe_classes():
-      self.assertFalse(probe_cls.IS_GENERAL_PURPOSE)
-    for probe_cls in self.general_purpose_probe_classes():
-      self.assertTrue(probe_cls.IS_GENERAL_PURPOSE)
     for probe_cls in self.probe_classes():
-      self.assertTrue(probe_cls.NAME)
+      with self.subTest(probe_cls=str(probe_cls)):
+        self.assertTrue(probe_cls.NAME)
 
   def test_default_lists(self):
     count = 0
@@ -127,8 +134,18 @@ class ProbeTestCase(CrossbenchFakeFsTestCase):
       count += 1
       if probe_cls.IS_GENERAL_PURPOSE:
         self.assertIn(probe_cls, GENERAL_PURPOSE_PROBES)
-    self.assertGreater(count,
-                       len(GENERAL_PURPOSE_PROBES) + len(INTERNAL_PROBES))
+    self.assertGreater(
+        count,
+        len(GENERAL_PURPOSE_PROBES) + len(DEFAULT_INTERNAL_PROBES))
+    self.assertFalse(
+        set(NON_CONFIGURABLE_INTERNAL_PROBES).intersection(
+            set(CONFIGURABLE_INTERNAL_PROBES)))
+    self.assertFalse(
+        set(NON_CONFIGURABLE_INTERNAL_PROBES).intersection(
+            set(OPTIONAL_INTERNAL_PROBES)))
+    self.assertFalse(
+        set(CONFIGURABLE_INTERNAL_PROBES).intersection(
+            set(OPTIONAL_INTERNAL_PROBES)))
 
   def test_help(self):
     for probe_cls in self.probe_classes():
@@ -142,6 +159,34 @@ class ProbeTestCase(CrossbenchFakeFsTestCase):
     for probe_cls in self.probe_classes():
       config_parser = probe_cls.config_parser()
       self.assertEqual(config_parser.probe_cls, probe_cls)
+      self.assertIn(probe_cls.NAME, config_parser.title)
+
+  def test_config_parser_defaults(self):
+    # If possible all probes should define a sane default so they can easily
+    # be experimented with and make it more accessible to explore.
+    # TODO(crbug.com/383572680): provide more default settings
+    requires_configuration = {
+        ChromeHistogramsProbe,
+        DTraceProbe,
+        # Reason: missing lldb binary on some platforms
+        DebuggerProbe,
+        # TODO: provide default settings
+        JSProbe,
+        # TODO: auto-download perfetto bin from storage
+        PerfettoProbe,
+        # TODO: provide default settings
+        PollingShellProbe,
+        # TODO: provide default settings
+        ShellProbe,
+        # TODO: missing wpr, download precompiled wpr from storage
+        WebPageReplayProbe,
+    }
+    for probe_cls in GENERAL_PURPOSE_PROBES:
+      if probe_cls in requires_configuration:
+        continue
+      config_parser = probe_cls.config_parser()
+      probe = config_parser.parse({})
+      self.assertIsInstance(probe, probe_cls)
 
   def test_basic_probe_instances(self):
     keys = set()
@@ -158,13 +203,17 @@ class ProbeTestCase(CrossbenchFakeFsTestCase):
 
   def test_is_internal(self):
     for probe_instance in self.internal_probe_instances():
-      self.assertTrue(probe_instance.is_internal)
+      with self.subTest(probe_cls=str(type(probe_instance))):
+        self.assertTrue(probe_instance.is_internal)
+
     for probe_instance in self.general_purpose_probe_instances():
-      self.assertFalse(probe_instance.is_internal)
+      with self.subTest(probe_cls=str(type(probe_instance))):
+        self.assertFalse(probe_instance.is_internal)
 
   def test_is_attached(self):
     for probe_instance in self.general_purpose_probe_instances():
-      self.assertFalse(probe_instance.is_attached)
+      with self.subTest(probe_cls=str(type(probe_instance))):
+        self.assertFalse(probe_instance.is_attached)
 
 
 if __name__ == "__main__":
diff --git a/tests/crossbench/probes/test_probe_results.py b/tests/crossbench/probes/test_probe_results.py
index 3f18b9a9..b51e111f 100644
--- a/tests/crossbench/probes/test_probe_results.py
+++ b/tests/crossbench/probes/test_probe_results.py
@@ -4,11 +4,12 @@
 
 import pathlib
 
+from typing_extensions import override
+
 from crossbench.probes.probe import Probe
-from crossbench.probes.results import (BrowserProbeResult,
-                                       DuplicateProbeResult, EmptyProbeResult,
-                                       LocalProbeResult, ProbeResultDict)
-from crossbench.runner.run import Run
+from crossbench.probes.results import (BrowserProbeResult, DuplicateProbeResult,
+                                       EmptyProbeResult, LocalProbeResult,
+                                       ProbeResultDict)
 from tests import test_helper
 from tests.crossbench.base import (BaseCrossbenchTestCase,
                                    CrossbenchFakeFsTestCase)
@@ -279,6 +280,7 @@ class MockRun:
 
 class BrowserProbeResultTestCase(BaseCrossbenchTestCase):
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.run = MockRun(self.browsers[0], self.platform)
@@ -358,12 +360,13 @@ class MockProbe(Probe):
   """
   NAME = "mock-probe"
 
-  def get_context(self, run: Run):
+  @override
+  def get_context_cls(self):
     pass
 
-
 class ProbeResultDictTestCase(CrossbenchFakeFsTestCase):
 
+  @override
   def setUp(self) -> None:
     super().setUp()
     self.result_location = pathlib.Path("test/out/results")
diff --git a/tests/crossbench/probes/test_trace_processor.py b/tests/crossbench/probes/test_trace_processor.py
index 33625b49..46f0b689 100644
--- a/tests/crossbench/probes/test_trace_processor.py
+++ b/tests/crossbench/probes/test_trace_processor.py
@@ -2,17 +2,26 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+from argparse import ArgumentTypeError
 import json
 import unittest
 
 from crossbench import path as pth
 from crossbench import plt
-from crossbench.cli.config.probe import ProbeListConfig
+from crossbench.cli.config.probe_list import ProbeListConfig
+from crossbench.exception import ArgumentTypeMultiException
 from crossbench.probes.all import TraceProcessorProbe
+from crossbench.probes.perfetto.trace_processor.trace_processor import TraceProcessorQueryConfig
 from tests import test_helper
 from tests.crossbench.base import BaseCrossbenchTestCase
 
 
+def read_query_sql(name: str) -> str:
+  return (test_helper.crossbench_dir() /
+          "probes/perfetto/trace_processor/queries" /
+          f"{name}.sql").read_text("utf-8")
+
+
 class TraceProcessorProbeTestCase(unittest.TestCase):
 
   @unittest.skipIf(not plt.PLATFORM.which("trace_processor"),
@@ -25,7 +34,66 @@ class TraceProcessorProbeTestCase(unittest.TestCase):
     self.assertEqual(len(probes), 2)
     probe = probes[0]
     self.assertIsInstance(probe, TraceProcessorProbe)
-
+    assert isinstance(probe, TraceProcessorProbe)
+    queries = probe.queries
+    self.assertEqual(len(queries), 2)
+    speedometer_cpu_time_sql = read_query_sql("speedometer_cpu_time")
+    self.assertEqual(queries[0].name, "speedometer_cpu_time")
+    self.assertEqual(queries[0].sql, speedometer_cpu_time_sql)
+
+    inline_name = "my_query"
+    inline_sql = "select dur from slice where slice.name = 'my_slice'"
+    self.assertEqual(queries[1].name, inline_name)
+    self.assertEqual(queries[1].sql, inline_sql)
+
+  def test_query_config_duplicate_name_raises(self):
+    with self.assertRaisesRegex(ArgumentTypeError,
+                                "Unexpected duplicates in query names"):
+      TraceProcessorProbe.from_config({
+          "queries": [
+              "loadline/benchmark_score",
+              {
+                  "name": "loadline_benchmark_score",
+                  "sql": "select * from slice where slice.name = 'comment'",
+              },
+          ],
+      })
+
+
+class TraceProcessorQueryConfigTestCase(unittest.TestCase):
+
+  def test_invalid_name_raises(self):
+    with self.assertRaisesRegex(ArgumentTypeMultiException,
+                                "sql query path does not exist"):
+      TraceProcessorQueryConfig.parse("not_an_actual_query")
+
+  def test_file_query(self):
+    query = TraceProcessorQueryConfig.parse("speedometer_cpu_time")
+    self.assertEqual(query.name, "speedometer_cpu_time")
+    self.assertEqual(query.sql, read_query_sql("speedometer_cpu_time"))
+
+  def test_file_query_name_escaped(self):
+    query = TraceProcessorQueryConfig.parse("loadline/benchmark_score")
+    self.assertEqual(query.name, "loadline_benchmark_score")
+    self.assertEqual(query.sql, read_query_sql("loadline/benchmark_score"))
+
+  def test_inline_query(self):
+    query = TraceProcessorQueryConfig.parse({
+        "name": "comment",
+        "sql": "select * from slice where slice.name = 'comment'",
+    })
+    self.assertEqual(query.name, "comment")
+    self.assertEqual(query.sql,
+                     "select * from slice where slice.name = 'comment'")
+
+  def test_inline_query_name_escaped(self):
+    query = TraceProcessorQueryConfig.parse({
+        "name": "//comment//",
+        "sql": "select * from slice where slice.name = 'comment'",
+    })
+    self.assertEqual(query.name, "__comment__")
+    self.assertEqual(query.sql,
+                     "select * from slice where slice.name = 'comment'")
 
 class TraceProcessorResultTestCase(BaseCrossbenchTestCase):
 
diff --git a/tests/crossbench/probes/test_tracing.py b/tests/crossbench/probes/test_tracing.py
new file mode 100644
index 00000000..b1f85c30
--- /dev/null
+++ b/tests/crossbench/probes/test_tracing.py
@@ -0,0 +1,138 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import argparse
+import json
+from typing import cast
+
+import crossbench.path as pth
+from crossbench.cli.config.probe_list import ProbeListConfig
+from crossbench.probes.all import TracingProbe
+from crossbench.probes.perfetto.tracing import (MINIMAL_CONFIG, RecordFormat,
+                                                RecordMode)
+from tests import test_helper
+from tests.crossbench.base import CrossbenchFakeFsTestCase
+
+
+class TracingProbeTestCase(CrossbenchFakeFsTestCase):
+
+  def test_parse_empty_config(self):
+    probe: TracingProbe = TracingProbe.from_config({})
+    self.assertEqual(probe.categories, MINIMAL_CONFIG)
+    self.assertEqual(probe.record_mode, RecordMode.CONTINUOUSLY)
+    self.assertEqual(probe.record_format, RecordFormat.PROTO)
+    self.assertEqual(probe.startup_duration, 0)
+
+  def test_parse_config(self):
+    probe: TracingProbe = TracingProbe.from_config(
+        {"categories": ["one", "two"]})
+    self.assertEqual(probe.categories, {"one", "two"} | MINIMAL_CONFIG)
+    self.assertEqual(probe.record_mode, RecordMode.CONTINUOUSLY)
+    self.assertEqual(probe.record_format, RecordFormat.PROTO)
+    self.assertEqual(probe.startup_duration, 0)
+
+  def test_parse_config_empty(self):
+    probe: TracingProbe = TracingProbe.from_config({
+        "preset": "empty",
+        "categories": ["one", "two"]
+    })
+    self.assertEqual(probe.categories, {"one", "two"})
+
+  def test_parse_trace_config_file_invalid(self):
+    trace_config_file = pth.LocalPath("trace_config_file.json")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      TracingProbe.from_config({"trace_config": str(trace_config_file)})
+
+    with trace_config_file.open("w", encoding="utf-8") as f:
+      json.dump({}, f)
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "trace_config"):
+      TracingProbe.from_config({"trace_config": str(trace_config_file)})
+
+    with trace_config_file.open("w", encoding="utf-8") as f:
+      json.dump({"trace_config": {}}, f)
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "startup_duration"):
+      TracingProbe.from_config({"trace_config": str(trace_config_file)})
+
+    with trace_config_file.open("w", encoding="utf-8") as f:
+      json.dump({"startup_duration": 0, "trace_config": {}}, f)
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "startup_duration"):
+      TracingProbe.from_config({"trace_config": str(trace_config_file)})
+
+    with trace_config_file.open("w", encoding="utf-8") as f:
+      json.dump({"startup_duration": 10, "trace_config": {}}, f)
+    with self.assertRaisesRegex(argparse.ArgumentTypeError,
+                                "no trace categories"):
+      TracingProbe.from_config({"trace_config": str(trace_config_file)})
+
+    with trace_config_file.open("w", encoding="utf-8") as f:
+      json.dump(
+          {
+              "startup_duration": 10,
+              "trace_config": {},
+              "result_file": "path/to/result"
+          }, f)
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "result_file"):
+      TracingProbe.from_config({"trace_config": str(trace_config_file)})
+
+  def test_parse_trace_config_file(self):
+    trace_config_file = pth.LocalPath("trace_config_file.json")
+    with trace_config_file.open("w", encoding="utf-8") as f:
+      json.dump(
+          {
+              "startup_duration": 10,
+              "trace_config": {
+                  "included_categories": ["one", "two"]
+              }
+          }, f)
+    probe: TracingProbe = TracingProbe.from_config(
+        {"trace_config": str(trace_config_file)})
+    self.assertFalse(probe.categories)
+    trace_config_file = probe.trace_config_file
+    self.assertIsNotNone(trace_config_file)
+    self.assertTrue(trace_config_file.is_file())
+    self.assertEqual(trace_config_file, trace_config_file)
+
+  def test_parse_trace_config_file_conflict(self):
+    trace_config_file = pth.LocalPath("trace_config_file.json")
+    with trace_config_file.open("w", encoding="utf-8") as f:
+      json.dump(
+          {
+              "startup_duration": 10,
+              "trace_config": {
+                  "included_categories": ["one", "two"]
+              }
+          }, f)
+    with self.assertRaisesRegex(argparse.ArgumentTypeError,
+                                "trace categories or a trace_config"):
+      TracingProbe.from_config({
+          "preset": "v8",
+          "trace_config": str(trace_config_file)
+      })
+    with self.assertRaisesRegex(argparse.ArgumentTypeError,
+                                "trace categories or a trace_config"):
+      TracingProbe.from_config({
+          "categories": ["one", "two"],
+          "trace_config": str(trace_config_file)
+      })
+
+  def test_parse_example_config(self):
+    config_file = test_helper.config_dir() / "doc/probe/tracing.config.hjson"
+    self.fs.add_real_file(config_file)
+    self.assertTrue(config_file.is_file())
+    trace_config_file = config_file.parent / "trace_config_file.json"
+    self.fs.add_real_file(trace_config_file)
+    self.assertTrue(trace_config_file.is_file())
+
+    probes = ProbeListConfig.parse_path(config_file).probes
+    self.assertEqual(len(probes), 1)
+    probe = probes[0]
+    self.assertIsInstance(probe, TracingProbe)
+    tracing_probe = cast(TracingProbe, probe)
+    self.assertIsNotNone(tracing_probe.categories)
+    self.assertTrue(tracing_probe.trace_config_file.is_file())
+    self.assertEqual(tracing_probe.trace_config_file, trace_config_file)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/probes/test_v8_log.py b/tests/crossbench/probes/test_v8_log.py
index 564c1ec9..c6bceafa 100644
--- a/tests/crossbench/probes/test_v8_log.py
+++ b/tests/crossbench/probes/test_v8_log.py
@@ -34,14 +34,13 @@ class V8LogProbeTestCase(unittest.TestCase):
           "prof": False,
           "profview": False
       })
-    with self.assertRaises(ValueError) as cm:
+    with self.assertRaisesRegex(ValueError, "profview"):
       # profview needs prof
       V8LogProbe.from_config({
           "log_all": False,
           "prof": False,
           "profview": True
       })
-    self.assertIn("profview", str(cm.exception))
     with self.assertRaises(argparse.ArgumentTypeError):
       V8LogProbe.from_config({"log_all": []})
     with self.assertRaises(argparse.ArgumentTypeError):
diff --git a/tests/crossbench/runner.py b/tests/crossbench/runner.py
new file mode 100644
index 00000000..8a136194
--- /dev/null
+++ b/tests/crossbench/runner.py
@@ -0,0 +1,27 @@
+#!/usr/bin/env vpython3
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pathlib
+import sys
+
+import pytest
+
+FILE_PATH = pathlib.Path(__file__).absolute()
+TEST_DIR = FILE_PATH.parent
+REPO_DIR = FILE_PATH.parents[2]
+
+if REPO_DIR not in sys.path:
+  sys.path.insert(0, str(REPO_DIR))
+
+if __name__ == "__main__":
+  pass_through_args = sys.argv[1:]
+  return_code = pytest.main([
+      "--verbose", "--log-cli-level=DEBUG", "-o", "log_cli=True", "-rs",
+      str(TEST_DIR), *pass_through_args
+  ])
+
+  sys.exit(return_code)
diff --git a/tests/crossbench/runner/groups/base.py b/tests/crossbench/runner/groups/base.py
index 85ffa40a..9baa18cf 100644
--- a/tests/crossbench/runner/groups/base.py
+++ b/tests/crossbench/runner/groups/base.py
@@ -1,9 +1,11 @@
 # Copyright 2024 The Chromium Authors
 # Use of this source code is governed by a BSD-style license that can be
-# found in the LICENSE file
+# found in the LICENSE file.
 
 from typing import Optional
 
+from typing_extensions import override
+
 from crossbench.browsers.browser import Browser
 from crossbench.flags.base import Flags
 from crossbench.runner.groups.session import BrowserSessionRunGroup
@@ -12,6 +14,7 @@ from tests.crossbench.runner.helper import BaseRunnerTestCase
 
 class BaseRunGroupTestCase(BaseRunnerTestCase):
 
+  @override
   def setUp(self):
     super().setUp()
     self.root_dir = self.out_dir / "custom"
diff --git a/tests/crossbench/runner/groups/test_session.py b/tests/crossbench/runner/groups/test_session.py
index 2444d774..19bb0770 100644
--- a/tests/crossbench/runner/groups/test_session.py
+++ b/tests/crossbench/runner/groups/test_session.py
@@ -4,7 +4,6 @@
 
 from unittest import mock
 
-from crossbench import compat
 from crossbench.helper.state import UnexpectedStateError
 from tests import test_helper
 from tests.crossbench.runner.groups.base import BaseRunGroupTestCase
@@ -177,7 +176,7 @@ class BrowserSessionRunGroupTestCase(BaseRunGroupTestCase):
     self.assertTrue(session.path.is_dir())
     session_symlinks = list((session.browser_dir / "sessions").iterdir())
     self.assertEqual(len(session_symlinks), 1)
-    self.assertEqual(compat.readlink(session_symlinks[0]), session.path)
+    self.assertEqual(session_symlinks[0].readlink(), session.path)
     self.assertTrue(run.did_setup)
     self.assertFalse(run.did_run)
     self.assertTrue(run.did_teardown_browser)
@@ -276,7 +275,7 @@ class BrowserSessionRunGroupTestCase(BaseRunGroupTestCase):
     session.append(run)
     session.set_ready()
     did_run = False
-    with self.assertRaises(ValueError) as cm:
+    with self.assertRaisesRegex(ValueError, "Network startup error"):
       with mock.patch.object(
           session.network,
           "open",
@@ -284,7 +283,6 @@ class BrowserSessionRunGroupTestCase(BaseRunGroupTestCase):
         with session.open():
           did_run = True
     self.assertFalse(did_run)
-    self.assertIn("Network startup error", str(cm.exception))
     self._validate_open_network_error(session, run)
 
   def _validate_open_network_error(self, session, run):
diff --git a/tests/crossbench/runner/helper.py b/tests/crossbench/runner/helper.py
index 57d5c0d8..a12d840e 100644
--- a/tests/crossbench/runner/helper.py
+++ b/tests/crossbench/runner/helper.py
@@ -2,28 +2,40 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+from __future__ import annotations
+
 import abc
+import collections
 import datetime as dt
 import json
 import pathlib
-from typing import Any, List, Optional
+from typing import TYPE_CHECKING, Any, List, Optional, Type
+
+from typing_extensions import override
 
+from crossbench.benchmarks.base import Benchmark
 from crossbench.browsers.browser import Browser
 from crossbench.browsers.settings import Settings
+from crossbench.cli.config.secrets import Secrets
 from crossbench.env import HostEnvironment
 from crossbench.exception import Annotator
+from crossbench.helper.wait import WaitRange
 from crossbench.path import safe_filename
 from crossbench.probes.probe import Probe
 from crossbench.probes.probe_context import ProbeContext
 from crossbench.probes.results import LocalProbeResult, ProbeResult
 from crossbench.runner.actions import Actions
-from crossbench.runner.run import Run
 from crossbench.runner.runner import Runner
 from crossbench.runner.timing import Timing
 from tests.crossbench.base import BaseCrossbenchTestCase
 from tests.crossbench.mock_browser import MockChromeDev, MockFirefox
 from tests.crossbench.mock_helper import MockBenchmark, MockStory
 
+if TYPE_CHECKING:
+  from crossbench.runner.run import Run
+  from crossbench.runner.timing import AnyTimeUnit
+
+
 
 class MockBrowser:
 
@@ -56,11 +68,12 @@ class MockRun:
     self.is_warmup = is_warmup
     self.temperature = temperature
     self.name = name
-    self.probes = []
+    self.probes: list[Probe] = []
     self.timing = Timing()
     self.is_success = True
     self.index = index
     self.story = story
+    self.story_secrets = Secrets()
     self.out_dir = (
         browser_session.root_dir / safe_filename(self.browser.unique_name) /
         "stories" / name / f"repetition={self.repetition}" / self.temperature)
@@ -69,7 +82,7 @@ class MockRun:
     self.did_run = False
     self.did_teardown = False
     self.did_teardown_browser = False
-    self.is_dry_run: Optional[bool] = None
+    self.is_dry_run: bool | None = None
 
   def validate_env(self, env: HostEnvironment):
     pass
@@ -90,6 +103,10 @@ class MockRun:
   def exceptions(self) -> Annotator:
     return self._exceptions
 
+  @property
+  def secrets(self) -> Secrets:
+    return self.story_secrets.merge(fallback=self.browser.secrets)
+
   def max_end_datetime(self) -> dt.datetime:
     return dt.datetime.max
 
@@ -103,6 +120,14 @@ class MockRun:
     assert not self.did_teardown
     self.did_teardown = True
 
+  def wait_range(self, min_wait: AnyTimeUnit, timeout: AnyTimeUnit,
+                 delay: AnyTimeUnit) -> WaitRange:
+    timing = self.timing
+    return WaitRange(
+        min=timing.timedelta(min_wait),
+        timeout=timing.timeout_timedelta(timeout),
+        delay=timing.timedelta(delay))
+
   def _teardown_browser(self, is_dry_run: bool) -> None:
     assert self.is_dry_run is is_dry_run
     assert not self.did_teardown_browser
@@ -125,20 +150,27 @@ class MockPlatform:
     return self.name
 
 
+MockWait = collections.namedtuple("MockWait", ("time", "absolute_time"))
+
+
 class MockRunner:
 
   def __init__(self) -> None:
     self.benchmark = MockBenchmark(stories=[MockStory("mock_story")])
-    self.runs = tuple()
+    self.runs: tuple[Run, ...] = tuple()
     self.platform = MockPlatform("test-platform")
     self.repetitions = 1
     self.create_symlinks = True
-    self.probes = []
-    self.browsers = []
+    self.probes: list[Probe] = []
+    self.browsers: list[Browser] = []
     self.out_dir = pathlib.Path("results/out")
     self.timing = Timing()
     self.env = HostEnvironment(self.platform, self.out_dir, self.browsers,
                                self.probes, self.repetitions)
+    self.mock_waits: list[MockWait] = []
+
+  def wait(self, time: AnyTimeUnit, absolute_time: bool = False) -> None:
+    self.mock_waits.append(MockWait(time, absolute_time))
 
 
 class MockNetwork:
@@ -148,16 +180,22 @@ class MockNetwork:
 class MockProbe(Probe):
   NAME = "test-probe"
 
-  def __init__(self, test_data: Any = ()) -> None:
+  def __init__(self,
+               test_data: Any = (),
+               context_cls: Optional[Type[MockProbeContext]] = None) -> None:
     super().__init__()
     self.test_data = test_data
+    self.context_cls = context_cls or MockProbeContext
 
   @property
+  @override
   def result_path_name(self) -> str:
     return f"{self.name}.json"
 
-  def get_context(self, run: Run):
-    return MockProbeContext(self, run)
+  @override
+  def get_context_cls(self):
+    return self.context_cls
+
 
 
 class MockProbeContext(ProbeContext):
@@ -169,33 +207,47 @@ class MockProbeContext(ProbeContext):
     pass
 
   def teardown(self) -> ProbeResult:
-    with self.result_path.open("w") as f:
+    with pathlib.Path(self.result_path).open("w", encoding="utf-8") as f:
       json.dump(self.probe.test_data, f)
     return LocalProbeResult(json=(self.result_path,))
 
 
 class BaseRunnerTestCase(BaseCrossbenchTestCase, metaclass=abc.ABCMeta):
 
+  @override
   def setUp(self):
     super().setUp()
     self.out_dir = pathlib.Path("/testing/out_dir")
     self.out_dir.parent.mkdir(exist_ok=False, parents=True)
     self.stories = [MockStory("story_1"), MockStory("story_2")]
     self.benchmark = MockBenchmark(self.stories)
-    self.browsers: List[Browser] = [
-        MockChromeDev("chrome-dev", settings=Settings(platform=self.platform)),
-        MockFirefox(
-            "firefox-stable", settings=Settings(platform=self.platform))
-    ]
+    self.mock_chrome_dev = MockChromeDev(
+        "chrome-dev", settings=Settings(platform=self.platform))
+    self.mock_firefox = MockFirefox(
+        "firefox-stable", settings=Settings(platform=self.platform))
+    self.browsers: List[Browser] = [self.mock_chrome_dev, self.mock_firefox]
 
   def default_runner(self,
                      browsers: Optional[List[Browser]] = None,
+                     benchmark: Optional[Benchmark] = None,
                      throw: bool = True) -> Runner:
-    if browsers is None:
-      browsers = self.browsers
+    return Runner(
+        self.out_dir,
+        browsers or self.browsers,
+        benchmark or self.benchmark,
+        platform=self.platform,
+        throw=throw,
+        in_memory_result_db=True)
+
+  def single_story_runner(self,
+                          browser: Optional[Browser] = None,
+                          throw: bool = True) -> Runner:
+    browsers = [browser or self.mock_chrome_dev]
+    benchmark = MockBenchmark([self.stories[0]])
     return Runner(
         self.out_dir,
         browsers,
-        self.benchmark,
+        benchmark,
         platform=self.platform,
-        throw=throw)
+        throw=throw,
+        in_memory_result_db=True)
diff --git a/tests/crossbench/runner/test_probe_context_manager.py b/tests/crossbench/runner/test_probe_context_manager.py
new file mode 100644
index 00000000..72ad30fe
--- /dev/null
+++ b/tests/crossbench/runner/test_probe_context_manager.py
@@ -0,0 +1,160 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from typing_extensions import override
+
+from crossbench.helper.state import UnexpectedStateError
+from crossbench.runner.run import ProbeRunContextManager
+from tests import test_helper
+from tests.crossbench.runner.helper import (BaseRunnerTestCase, MockProbe,
+                                            MockProbeContext)
+from tests.crossbench.test_exception import CustomException
+
+
+class FailingMockProbeContext(MockProbeContext):
+
+  @override
+  def setup(self):
+    raise CustomException("failing setup")
+
+
+class ProbeContextManagerTestCase(BaseRunnerTestCase):
+
+  def setup_context_manager(self, throw: bool = True):
+    self.runner = self.single_story_runner(throw=throw)
+    self.cb_run = list(self.runner.get_runs())[0]
+    self.context_manager = ProbeRunContextManager(self.cb_run,
+                                                  self.cb_run.results)
+
+  def test_basic_accessor(self):
+    self.setup_context_manager()
+    self.assertTrue(self.context_manager.is_success)
+    self.assertFalse(self.context_manager.is_ready)
+    self.assertFalse(self.context_manager.is_running)
+
+  def test_wrong_order(self):
+    self.setup_context_manager()
+    with self.assertRaisesRegex(UnexpectedStateError, "INITIAL"):
+      with self.context_manager.open(is_dry_run=False):
+        pass
+    with self.assertRaisesRegex(UnexpectedStateError, "INITIAL"):
+      self.context_manager.teardown(is_dry_run=False)
+
+  def test_setup_no_probes(self):
+    self.setup_context_manager()
+    self.assertFalse(self.context_manager.is_ready)
+    with self.assertRaises(AssertionError):
+      self.context_manager.setup([], is_dry_run=False)
+    self.assertFalse(self.context_manager.is_ready)
+
+  def test_setup_detached_probe(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data")
+    self.assertFalse(self.context_manager.is_ready)
+    with self.assertRaisesRegex(AssertionError, "attached"):
+      self.context_manager.setup([probe], is_dry_run=False)
+    self.assertFalse(self.context_manager.is_ready)
+
+  def test_setup_single_probe(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data")
+    self.runner.attach_probe(probe)
+    self.assertFalse(self.context_manager.is_ready)
+    self.context_manager.setup([probe], is_dry_run=False)
+    self.assertTrue(self.context_manager.is_ready)
+
+  def test_setup_single_probe_dry_run(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data")
+    self.runner.attach_probe(probe)
+    self.assertFalse(self.context_manager.is_ready)
+    self.context_manager.setup([probe], is_dry_run=True)
+    self.assertFalse(self.context_manager.is_running)
+    self.assertTrue(self.context_manager.is_ready)
+
+  def test_setup_teardown_dry_run(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data")
+    self.runner.attach_probe(probe)
+    self.context_manager.setup([probe], is_dry_run=True)
+    self.assertTrue(self.context_manager.is_ready)
+    self.context_manager.teardown(is_dry_run=True)
+    self.assertFalse(self.context_manager.is_ready)
+    self.assertNotIn(probe, self.cb_run.results)
+
+  def test_direct_setup_teardown(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data")
+    self.runner.attach_probe(probe)
+    self.cb_run.out_dir.mkdir(parents=True)
+    self.context_manager.setup([probe], is_dry_run=False)
+    self.assertTrue(self.context_manager.is_ready)
+    self.context_manager.teardown(is_dry_run=False)
+    self.assertFalse(self.context_manager.is_ready)
+    self.assertTrue(self.context_manager.is_success)
+    children = list(self.cb_run.out_dir.iterdir())
+    self.assertEqual(len(children), 1)
+    result_file = self.cb_run.results[probe].file
+    self.assertTrue(result_file.exists())
+    self.assertEqual(result_file, children[0])
+
+  def test_setup_open_teardown_dry_run(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data")
+    self.runner.attach_probe(probe)
+    self.context_manager.setup([probe], is_dry_run=True)
+    self.assertFalse(self.context_manager.is_running)
+    with self.context_manager.open(is_dry_run=True):
+      self.assertTrue(self.context_manager.is_running)
+    self.context_manager.teardown(is_dry_run=True)
+    self.assertFalse(self.context_manager.is_running)
+    self.assertTrue(self.context_manager.is_success)
+    self.assertNotIn(probe, self.cb_run.results)
+
+  def test_setup_open_teardown(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data")
+    self.runner.attach_probe(probe)
+    self.cb_run.out_dir.mkdir(parents=True)
+    self.context_manager.setup([probe], is_dry_run=False)
+    self.assertFalse(self.context_manager.is_running)
+    with self.context_manager.open(is_dry_run=False):
+      self.assertTrue(self.context_manager.is_running)
+    self.context_manager.teardown(is_dry_run=False)
+    self.assertFalse(self.context_manager.is_running)
+    self.assertTrue(self.context_manager.is_success)
+    children = list(self.cb_run.out_dir.iterdir())
+    self.assertEqual(len(children), 1)
+    result_file = self.cb_run.results[probe].file
+    self.assertTrue(result_file.exists())
+    self.assertEqual(result_file, children[0])
+
+  def test_setup_error_throw(self):
+    self.setup_context_manager()
+    probe = MockProbe("custom_probe_data", FailingMockProbeContext)
+    self.runner.attach_probe(probe)
+    with self.assertRaisesRegex(CustomException, "failing setup"):
+      self.context_manager.setup([probe], is_dry_run=False)
+    self.assertFalse(self.context_manager.is_success)
+
+  def test_setup_error(self):
+    self.setup_context_manager(throw=False)
+    probe = MockProbe("custom_probe_data", FailingMockProbeContext)
+    self.runner.attach_probe(probe)
+
+    self.context_manager.setup([probe], is_dry_run=False)
+    self.assertFalse(self.context_manager.is_success)
+    self.assertEqual(len(self.cb_run.exceptions), 1)
+    self.assertTrue(self.cb_run.results[probe].is_empty)
+
+    exception = self.cb_run.exceptions[0].exception
+    self.assertIsInstance(exception, CustomException)
+
+
+del BaseRunnerTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/test_run.py b/tests/crossbench/runner/test_run.py
index d6ca5f84..fedef6c7 100644
--- a/tests/crossbench/runner/test_run.py
+++ b/tests/crossbench/runner/test_run.py
@@ -2,10 +2,14 @@
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
 
+from __future__ import annotations
+
 import datetime as dt
 
 from crossbench.probes.screenshot import ScreenshotProbe
 from crossbench.runner.run import Run
+from crossbench.runner.run_annotation import RunAnnotation
+from tests import test_helper
 from tests.crossbench.mock_helper import MockStory
 from tests.crossbench.runner.groups.base import BaseRunGroupTestCase
 from tests.crossbench.runner.helper import MockProbe
@@ -22,3 +26,23 @@ class RunTestCase(BaseRunGroupTestCase):
     with session.open():
       self.assertIsNotNone(run.find_probe_context(MockProbe))
       self.assertIsNone(run.find_probe_context(ScreenshotProbe))
+
+  def test_annotate(self):
+    session = self.default_session()
+    run = Run(self.runner, session, MockStory("mock story"), 1, False,
+              "1_default", 1, "test run", dt.timedelta(minutes=1), True)
+    self.assertFalse(list(run.annotations))
+    annotation = RunAnnotation.warning("Some warning")
+
+    with self.assertNoLogs(level="INFO"):
+      run.log_annotations()
+
+    run.annotate(annotation)
+    self.assertIn(annotation, run.annotations)
+    with self.assertLogs(level="INFO") as cm:
+      run.log_annotations()
+    self.assertIn("Some warning", " ".join(cm.output))
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/test_run_annotation.py b/tests/crossbench/runner/test_run_annotation.py
new file mode 100644
index 00000000..511952d5
--- /dev/null
+++ b/tests/crossbench/runner/test_run_annotation.py
@@ -0,0 +1,82 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+import unittest
+
+from ordered_set import OrderedSet
+
+from crossbench.runner.run_annotation import RunAnnotation, WarnLevel
+from tests import test_helper
+
+
+class RunAnnotationTestCase(unittest.TestCase):
+
+  def test_fatal(self):
+    message = "FATAL custom message"
+    annotation = RunAnnotation.fatal(message)
+    self.assertEqual(annotation.message, message)
+    self.assertEqual(annotation.level, WarnLevel.FATAL)
+    self.assertTrue(json.dumps(annotation.to_json()))
+    with self.assertLogs(level="FATAL") as cm:
+      annotation.log()
+    self.assertIn(message, "\n".join(cm.output))
+
+  def test_error(self):
+    message = "ERROR custom message"
+    annotation = RunAnnotation.error(message)
+    self.assertEqual(annotation.message, message)
+    self.assertEqual(annotation.level, WarnLevel.ERROR)
+    self.assertTrue(json.dumps(annotation.to_json()))
+    with self.assertLogs(level="ERROR") as cm:
+      annotation.log()
+    self.assertIn(message, "\n".join(cm.output))
+    with self.assertNoLogs(level="FATAL"):
+      annotation.log()
+
+  def test_warning(self):
+    message = "WARNING custom message"
+    annotation = RunAnnotation.warning(message)
+    self.assertEqual(annotation.message, message)
+    self.assertEqual(annotation.level, WarnLevel.WARNING)
+    self.assertTrue(json.dumps(annotation.to_json()))
+    with self.assertLogs(level="WARNING") as cm:
+      annotation.log()
+    self.assertIn(message, "\n".join(cm.output))
+    with self.assertNoLogs(level="ERROR"):
+      annotation.log()
+
+  def test_info(self):
+    message = "INFO custom message"
+    annotation = RunAnnotation.info(message)
+    self.assertEqual(annotation.message, message)
+    self.assertEqual(annotation.level, WarnLevel.INFO)
+    self.assertTrue(json.dumps(annotation.to_json()))
+    with self.assertLogs(level="INFO") as cm:
+      annotation.log()
+    self.assertIn(message, "\n".join(cm.output))
+    with self.assertNoLogs(level="WARNING"):
+      annotation.log()
+
+  def test_log_all(self):
+    annotations = OrderedSet()
+    for level in WarnLevel:
+      for i in range(10):
+        annotations.add(RunAnnotation(f"Annotation {level.name} {i}", level))
+    with self.assertLogs(level="INFO") as cm:
+      RunAnnotation.log_all(annotations, limit=5)
+    output = "\n".join(cm.output)
+    for level in WarnLevel:
+      for i in range(5):
+        message = f"Annotation {level.name} {i}"
+        self.assertIn(message, output)
+      for i in range(5, 10):
+        message = f"Annotation {level.name} {i}"
+        self.assertNotIn(message, output)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/test_runner.py b/tests/crossbench/runner/test_runner.py
index a8e238ea..3f6ede2b 100644
--- a/tests/crossbench/runner/test_runner.py
+++ b/tests/crossbench/runner/test_runner.py
@@ -5,11 +5,15 @@
 import json
 import pathlib
 import unittest
+from typing import TYPE_CHECKING
 from unittest import mock
 
-from crossbench import compat
+from typing_extensions import override
+
 from crossbench.browsers.browser import Browser
+from crossbench.browsers.webdriver import RemoteWebDriver
 from crossbench.env import HostEnvironment
+from crossbench.exception import MultiException
 from crossbench.flags.base import Flags
 from crossbench.helper.state import UnexpectedStateError
 from crossbench.probes import all as all_probes
@@ -25,6 +29,8 @@ from tests.crossbench.runner.helper import (BaseRunnerTestCase, MockBrowser,
                                             MockProbeContext, MockRun,
                                             MockRunner)
 
+if TYPE_CHECKING:
+  from crossbench.probes.probe import Probe
 
 # Skip strict type checks for better mocking
 # pytype: disable=wrong-arg-types
@@ -43,6 +49,7 @@ class TestThreadModeTestCase(unittest.TestCase):
         create_symlinks=True,
         throw=True)
 
+  @override
   def setUp(self) -> None:
     self.platform_a = MockPlatform("platform a")
     self.platform_b = MockPlatform("platform b")
@@ -53,7 +60,7 @@ class TestThreadModeTestCase(unittest.TestCase):
     self.runner = MockRunner()
     self.root_dir = pathlib.Path()
     self.env = self.runner.env
-    self.probes = []
+    self.probes: list[Probe] = []
     self.runs = (
         MockRun(self.runner, self.create_session(self.browser_a_1, 1), "run 1"),
         MockRun(self.runner, self.create_session(self.browser_a_2, 2), "run 2"),
@@ -120,6 +127,13 @@ class TestThreadModeTestCase(unittest.TestCase):
       self.assertEqual(group.index, index)
 
 
+class FailingMockProbeContext(MockProbeContext):
+
+  @override
+  def setup(self):
+    raise CustomException("failing setup")
+
+
 class RunnerTestCase(BaseRunnerTestCase):
 
   def test_default_instance(self):
@@ -131,7 +145,8 @@ class RunnerTestCase(BaseRunnerTestCase):
     self.assertTrue(runner.exceptions.is_success)
     default_probes = list(runner.default_probes)
     self.assertListEqual(list(runner.probes), default_probes)
-    self.assertEqual(len(default_probes), len(all_probes.INTERNAL_PROBES))
+    self.assertEqual(
+        len(default_probes), len(all_probes.DEFAULT_INTERNAL_PROBES))
     self.assertEqual(len(runner.runs), 0)
     # no runs => is_success == false
     self.assertFalse(runner.is_success)
@@ -151,7 +166,8 @@ class RunnerTestCase(BaseRunnerTestCase):
     self.assertTrue(runner.is_success)
     for run in runner.runs:
       self.assertTrue(run.is_success)
-      self.assertEqual(len(run.results), len(all_probes.INTERNAL_PROBES))
+      self.assertEqual(
+          len(run.results), len(all_probes.DEFAULT_INTERNAL_PROBES))
       for probe in runner.probes:
         self.assertIn(probe, run.results)
 
@@ -165,22 +181,145 @@ class RunnerTestCase(BaseRunnerTestCase):
 
     runner.run()
     self.assertTrue(runner.is_success)
+    self.assertEqual(len(runner.runs), 4)
     for run in runner.runs:
-      results = run.results[probe]
-      with results.json.open() as f:
-        probe_data = json.load(f)
-        self.assertEqual(probe_data, "custom_probe_data")
-      browser_dir = runner.out_dir / run.browser.unique_name
-      # Pyfakefs is having some issues with relative symlinks, thus we're
-      # manually combining the paths.
-      runs_dir = browser_dir / "runs"
-      run_symlink = runs_dir / compat.readlink(runs_dir / str(run.index))
-      self.assertEqual(run_symlink.resolve(), run.out_dir)
+      self._validate_successful_run(run, runner, probe, "custom_probe_data")
     for browser in runner.browsers:
       runs_symlinks = list(
           (runner.out_dir / browser.unique_name / "runs").iterdir())
       self.assertEqual(len(runs_symlinks), 2)
 
+  def test_run_remote_web_driver(self):
+    driver = mock.Mock()
+    driver.capabilities = {
+        "browserVersion": "123.0.4567.89",
+        "setWindowRect": False,
+    }
+    browser = RemoteWebDriver("test-driver", driver)
+    runner = self.default_runner(browsers=[browser])
+    runner.run()
+
+  def _validate_successful_run(self, run, runner, probe, probe_data):
+    results = run.results[probe]
+    with results.json.open() as f:
+      probe_data = json.load(f)
+      self.assertEqual(probe_data, probe_data)
+    browser_dir = runner.out_dir / run.browser.unique_name
+    # Pyfakefs is having some issues with relative symlinks, thus we're
+    # manually combining the paths.
+    runs_dir = browser_dir / "runs"
+    run_symlink = runs_dir / (runs_dir / str(run.index)).readlink()
+    self.assertEqual(run_symlink.resolve(), run.out_dir)
+    self._validate_internal_probes(run, runner)
+
+  def _validate_internal_probes(self, run, runner):
+    for probe in runner.probes:
+      if not probe.is_internal:
+        continue
+      result = run.results[probe]
+      self.assertTrue(result)
+
+  def test_single_story_run_mock_probe_partial_setup_fail(self):
+    runner = self.single_story_runner(throw=False)
+
+    probe = MockProbe("custom_probe_data", FailingMockProbeContext)
+    runner.attach_probe(probe)
+    self.assertIn(probe, runner.probes)
+    for browser in runner.browsers:
+      self.assertIn(probe, browser.probes)
+
+    with self.assertRaises(MultiException) as cm:
+      runner.run()
+    self.assertEqual(len(cm.exception), 1)
+    exception = cm.exception.exceptions[0].exception
+    self.assertIsInstance(exception, CustomException)
+
+    self.assertFalse(runner.is_success)
+    self.assertEqual(len(runner.runs), 1)
+    failed_run = list(runner.runs)[0]
+    self.assertFalse(failed_run.is_success)
+    self.assertTrue(failed_run.results[probe].is_empty)
+    self._validate_internal_probes(failed_run, runner)
+
+  def test_single_story_run_mock_probe_calls(self):
+    # Make sure start / stop are called.
+    runner = self.single_story_runner(throw=True)
+    with mock.patch.object(FailingMockProbeContext,
+                           "setup") as setup_mock, mock.patch.object(
+                               FailingMockProbeContext,
+                               "start") as start_mock, mock.patch.object(
+                                   FailingMockProbeContext,
+                                   "stop") as stop_mock:
+      probe = MockProbe("custom_probe_data", FailingMockProbeContext)
+      runner.attach_probe(probe)
+      runner.run()
+    self.assertTrue(runner.is_success)
+    setup_mock.assert_called_once()
+    start_mock.assert_called_once()
+    stop_mock.assert_called_once()
+
+  def test_single_story_run_mock_probe_partial_setup_fail_mock(self):
+    # Make sure start / stop / teardown are not called after a setup failure
+    runner = self.single_story_runner(throw=False)
+    with mock.patch.object(FailingMockProbeContext,
+                           "start") as start_mock, mock.patch.object(
+                               FailingMockProbeContext,
+                               "stop") as stop_mock, mock.patch.object(
+                                   FailingMockProbeContext,
+                                   "teardown") as teardown_mock:
+      probe = MockProbe("custom_probe_data", FailingMockProbeContext)
+      runner.attach_probe(probe)
+      with self.assertRaises(MultiException) as cm:
+        runner.run()
+      exception = cm.exception.exceptions[0].exception
+      self.assertIsInstance(exception, CustomException)
+    self.assertFalse(runner.is_success)
+    start_mock.assert_not_called()
+    stop_mock.assert_not_called()
+    teardown_mock.assert_not_called()
+
+  def test_run_mock_probe_partial_setup_fail(self):
+    runner = self.default_runner(throw=False)
+    setup_count = 0
+
+    class PartialFailingMockProbeContext(MockProbeContext):
+
+      @override
+      def setup(self):
+        nonlocal setup_count
+        setup_count += 1
+        if setup_count == 3:
+          raise CustomException(f"failing setup number {setup_count}")
+
+    probe = MockProbe("custom_probe_data", PartialFailingMockProbeContext)
+    runner.attach_probe(probe)
+    self.assertIn(probe, runner.probes)
+    for browser in runner.browsers:
+      self.assertIn(probe, browser.probes)
+
+    with self.assertRaises(MultiException) as cm:
+      runner.run()
+    self.assertEqual(len(cm.exception), 1)
+    exception = cm.exception.exceptions[0].exception
+    self.assertIsInstance(exception, CustomException)
+
+    self.assertFalse(runner.is_success)
+    self.assertEqual(setup_count, 4)
+    self.assertEqual(len(runner.runs), 4)
+    failed_runs = list(run for run in runner.runs if not run.is_success)
+    self.assertEqual(len(failed_runs), 1)
+    failed_run = failed_runs[0]
+
+    for run in runner.runs:
+      if run is failed_run:
+        continue
+      self.assertTrue(run.is_success)
+      self._validate_successful_run(run, runner, probe, "custom_probe_data")
+
+    self.assertEqual(failed_run.index, 2)
+    self.assertFalse(failed_run.is_success)
+    self.assertTrue(failed_run.results[probe].is_empty)
+    self._validate_internal_probes(failed_run, runner)
 
   def test_attach_probe_twice(self):
     runner = self.default_runner()
@@ -246,12 +385,9 @@ class CustomException(Exception):
   pass
 
 
-def run_setup_fail(is_dry_run):
-  raise CustomException()
-
-
 class RunThreadGroupTestCase(BaseRunnerTestCase):
 
+  @override
   def tearDown(self) -> None:
     for browser in self.browsers:
       self.assertFalse(browser.is_running)
@@ -268,7 +404,8 @@ class RunThreadGroupTestCase(BaseRunnerTestCase):
         self.out_dir, [MockChromeDev("chrome-dev-2")],
         self.benchmark,
         platform=self.platform,
-        throw=True)
+        throw=True,
+        in_memory_result_db=True)
     runs_b = list(runner_b.get_runs())
     self.assertNotEqual(runs_a[0].runner, runs_b[0].runner)
     with self.assertRaises(AssertionError) as cm:
@@ -384,7 +521,11 @@ class RunThreadGroupTestCase(BaseRunnerTestCase):
     # 2 runs, same story, different browsers
     benchmark = MockBenchmark(stories=[self.stories[0]])
     runner = Runner(
-        self.out_dir, self.browsers, benchmark, platform=self.platform)
+        self.out_dir,
+        self.browsers,
+        benchmark,
+        platform=self.platform,
+        in_memory_result_db=True)
     runs = tuple(runner.get_runs())
     thread = RunThreadGroup(runs)
     failing_session, successful_session = thread.browser_sessions
@@ -453,5 +594,7 @@ class RunThreadGroupTestCase(BaseRunnerTestCase):
 
 # pytype: enable=wrong-arg-types
 
+del BaseRunnerTestCase
+
 if __name__ == "__main__":
   test_helper.run_pytest(__file__)
diff --git a/tests/crossbench/runner/test_timing.py b/tests/crossbench/runner/test_timing.py
index 739f32f7..c43fb6ff 100644
--- a/tests/crossbench/runner/test_timing.py
+++ b/tests/crossbench/runner/test_timing.py
@@ -54,20 +54,14 @@ class TimingTestCase(unittest.TestCase):
     self.assertEqual(t.units(dt.timedelta(seconds=1)), 10)
 
   def test_invalid_params(self):
-    with self.assertRaises(ValueError) as cm:
+    with self.assertRaisesRegex(ValueError, "Timing.cool_down_time"):
       _ = Timing(cool_down_time=dt.timedelta(seconds=-1))
-    self.assertIn("Timing.cool_down_time", str(cm.exception))
-
-    with self.assertRaises(ValueError) as cm:
+    with self.assertRaisesRegex(ValueError, "Timing.unit"):
       _ = Timing(unit=dt.timedelta(seconds=-1))
-    self.assertIn("Timing.unit", str(cm.exception))
-    with self.assertRaises(ValueError) as cm:
+    with self.assertRaisesRegex(ValueError, "Timing.unit"):
       _ = Timing(unit=dt.timedelta())
-    self.assertIn("Timing.unit", str(cm.exception))
-
-    with self.assertRaises(ValueError) as cm:
+    with self.assertRaisesRegex(ValueError, "Timing.run_timeout"):
       _ = Timing(run_timeout=dt.timedelta(seconds=-1))
-    self.assertIn("Timing.run_timeout", str(cm.exception))
 
   def test_to_units(self):
     t = Timing()
@@ -88,6 +82,19 @@ class TimingTestCase(unittest.TestCase):
     with self.assertRaises(ValueError):
       _ = t.timedelta(-1)
 
+  def test_to_units_absolute(self):
+    t = Timing()
+    self.assertEqual(t.units(100, absolute_time=True), 100)
+    self.assertEqual(t.units(dt.timedelta(minutes=1.5), absolute_time=True), 90)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+    t = Timing(unit=dt.timedelta(seconds=10))
+    self.assertEqual(t.units(100, absolute_time=True), 100)
+    self.assertEqual(t.units(dt.timedelta(minutes=1.5), absolute_time=True), 90)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
   def test_to_timedelta(self):
     t = Timing()
     self.assertEqual(t.timedelta(12).total_seconds(), 12)
@@ -108,12 +115,47 @@ class TimingTestCase(unittest.TestCase):
     with self.assertRaises(ValueError):
       _ = t.timedelta(-1)
 
+  def test_to_timedelta_absolute(self):
+    t = Timing()
+    self.assertEqual(t.timedelta(12, absolute_time=True).total_seconds(), 12)
+    self.assertEqual(
+        t.timedelta(dt.timedelta(minutes=1.5),
+                    absolute_time=True).total_seconds(), 90)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
+    t = Timing(unit=dt.timedelta(seconds=10))
+    self.assertEqual(t.timedelta(12, absolute_time=True).total_seconds(), 12)
+    self.assertEqual(
+        t.timedelta(dt.timedelta(minutes=1.5),
+                    absolute_time=True).total_seconds(), 90)
+    with self.assertRaises(ValueError):
+      _ = t.timedelta(-1)
+
   def test_timeout_timing(self):
     t = Timing(
-        unit=dt.timedelta(seconds=1), timeout_unit=dt.timedelta(seconds=10))
-    self.assertEqual(t.timedelta(12).total_seconds(), 12)
+        unit=dt.timedelta(seconds=2), timeout_unit=dt.timedelta(seconds=10))
+    self.assertEqual(t.timedelta(12).total_seconds(), 24)
     self.assertEqual(t.timeout_timedelta(12).total_seconds(), 120)
 
+  def test_timeout_timing_fallback(self):
+    t = Timing(unit=dt.timedelta(seconds=2))
+    self.assertEqual(t.timedelta(12).total_seconds(), 24)
+    self.assertEqual(t.timeout_timedelta(12).total_seconds(), 24)
+
+  def test_timeout_timing_absolute(self):
+    t = Timing(
+        unit=dt.timedelta(seconds=1), timeout_unit=dt.timedelta(seconds=10))
+    self.assertEqual(t.timedelta(12, absolute_time=True).total_seconds(), 12)
+    self.assertEqual(
+        t.timeout_timedelta(12, absolute_time=True).total_seconds(), 12)
+
+  def test_timeout_timing_fallback_absolute(self):
+    t = Timing(unit=dt.timedelta(seconds=2))
+    self.assertEqual(t.timedelta(12, absolute_time=True).total_seconds(), 12)
+    self.assertEqual(
+        t.timeout_timedelta(12, absolute_time=True).total_seconds(), 12)
+
   def test_timeout_timing_invalid(self):
     with self.assertRaises(ValueError):
       _ = Timing(
diff --git a/tests/crossbench/test_config.py b/tests/crossbench/test_config.py
index 4c58507e..b927d8b6 100644
--- a/tests/crossbench/test_config.py
+++ b/tests/crossbench/test_config.py
@@ -10,19 +10,23 @@ import enum
 import json
 import pathlib
 import unittest
-from typing import Any, Dict, List, Optional
+from typing import Any, Dict, List, Optional, Self
+from unittest import mock
 
 from immutabledict import immutabledict
+from typing_extensions import override
 
-from crossbench import compat
-from crossbench.config import ConfigEnum, ConfigObject, ConfigParser
+from crossbench.config import (ConfigEnum, ConfigObject, ConfigParser,
+                               UnusedPropertiesMode)
+from crossbench.exception import MultiException
 from crossbench.parse import NumberParser, ObjectParser
+from crossbench.str_enum_with_help import StrEnumWithHelp
 from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
 
 
 @enum.unique
-class GenericEnum(compat.StrEnumWithHelp):
+class GenericEnum(StrEnumWithHelp):
   A = ("a", "A Help")
   B = ("b", "B Help")
   C = ("c", "C Help")
@@ -52,9 +56,11 @@ class CustomValueEnum(enum.Enum):
 @dataclasses.dataclass(frozen=True)
 class CustomNestedConfigObject(ConfigObject):
   name: str
+  option: str | None = None
 
   @classmethod
-  def parse_str(cls, value: str) -> CustomNestedConfigObject:
+  @override
+  def parse_str(cls, value: str) -> Self:
     if ":" in value:
       raise ValueError("Invalid Config")
     if not value:
@@ -62,13 +68,11 @@ class CustomNestedConfigObject(ConfigObject):
     return cls(name=value)
 
   @classmethod
-  def parse_dict(cls, config: Dict[str, Any]) -> CustomNestedConfigObject:
-    return cls.config_parser().parse(config)
-
-  @classmethod
-  def config_parser(cls) -> ConfigParser[CustomNestedConfigObject]:
-    parser = ConfigParser("CustomNestedConfigObject parser", cls)
+  @override
+  def config_parser(cls) -> ConfigParser[Self]:
+    parser = ConfigParser(cls)
     parser.add_argument("name", type=str, required=True)
+    parser.add_argument("option", type=str, required=False)
     return parser
 
 
@@ -76,9 +80,10 @@ class CustomNestedConfigObject(ConfigObject):
 class CustomConfigObject(ConfigObject):
 
   name: str
-  array: Optional[List[str]] = None
-  integer: Optional[int] = None
-  nested: Optional[CustomNestedConfigObject] = None
+  array: List[str] | None = None
+  integer: int | None = None
+  float_field: float | None = None
+  nested: CustomNestedConfigObject | None = None
   choices: str = ""
   generic_enum: GenericEnum = GenericEnum.A
   config_enum: CustomConfigEnum = CustomConfigEnum.A
@@ -91,6 +96,7 @@ class CustomConfigObject(ConfigObject):
     return cls("default")
 
   @classmethod
+  @override
   def parse_str(cls, value: str) -> CustomConfigObject:
     if ":" in value:
       raise ValueError("Invalid Config")
@@ -122,18 +128,15 @@ class CustomConfigObject(ConfigObject):
         "integer": NumberParser.positive_int(integer, "integer"),
     }
 
-
-  @classmethod
-  def parse_dict(cls, config: Dict[str, Any], **kwargs) -> CustomConfigObject:
-    return cls.config_parser().parse(config, **kwargs)
-
   @classmethod
+  @override
   def config_parser(cls) -> ConfigParser[CustomConfigObject]:
     parser = cls.base_config_parser()
     parser.add_argument(
         "name", aliases=("name_alias", "name_alias2"), type=str, required=True)
     parser.add_argument("array", type=list)
     parser.add_argument("integer", type=NumberParser.positive_int)
+    parser.add_argument("float_field", type=NumberParser.any_float)
     parser.add_argument("nested", type=CustomNestedConfigObject)
     parser.add_argument("generic_enum", type=GenericEnum)
     parser.add_argument("config_enum", type=CustomConfigEnum)
@@ -154,22 +157,21 @@ class CustomConfigObject(ConfigObject):
 
   @classmethod
   def base_config_parser(cls) -> ConfigParser[CustomConfigObject]:
-    return ConfigParser("CustomConfigObject parser", cls)
+    return ConfigParser(cls)
 
 
 class CustomConfigObjectStrict(CustomConfigObject):
 
   @classmethod
   def base_config_parser(cls) -> ConfigParser[CustomConfigObjectStrict]:
-    return ConfigParser(
-        "CustomConfigObjectStrict parser", cls, allow_unused_config_data=False)
+    return ConfigParser(cls, unused_properties_mode=UnusedPropertiesMode.ERROR)
 
 
 class CustomConfigObjectWithDefault(CustomConfigObject):
 
   @classmethod
   def base_config_parser(cls) -> ConfigParser[CustomConfigObjectWithDefault]:
-    return ConfigParser("CustomConfigObject parser", cls, default=cls.default())
+    return ConfigParser(cls, default=cls.default())
 
 
 class CustomConfigObjectToArgumentValue(CustomConfigObject):
@@ -180,10 +182,10 @@ class CustomConfigObjectToArgumentValue(CustomConfigObject):
 
 class ConfigParserTestCase(unittest.TestCase):
 
+  @override
   def setUp(self):
     super().setUp()
-    self.parser = ConfigParser("ConfigParserTestCase parser",
-                               CustomConfigObject)
+    self.parser = ConfigParser(CustomConfigObject)
 
   def test_invalid_type(self):
     with self.assertRaises(TypeError):
@@ -219,7 +221,10 @@ class ConfigParserTestCase(unittest.TestCase):
     with self.assertRaises(ValueError):
       self.parser.add_argument("any", type=None, depends_on=("other",))
 
-    with self.assertRaises(ValueError):
+    with self.assertRaises((ValueError, TypeError)):
+      # Raises ValueError on Python 3.11 because depends_on is not allowed.
+      # Raises TypeError on Python 3.12 because GenericEnum can't be called
+      # with multiple parameters.
       self.parser.add_argument("enum", type=GenericEnum, depends_on=("other",))
     with self.assertRaises(ValueError):
       self.parser.add_argument("enum", type=ConfigEnum, depends_on=("other",))
@@ -257,16 +262,25 @@ class ConfigParserTestCase(unittest.TestCase):
       self.parser.parse({})
     self.assertIn("no value", str(cm.exception).lower())
     parser = ConfigParser(
-        "ConfigParserTestCase parser",
-        CustomConfigObject,
-        default=CustomConfigObject.default())
+        CustomConfigObject, default=CustomConfigObject.default())
     config = parser.parse({})
     self.assertEqual(config, CustomConfigObject.default())
 
+  def test_empty_title(self):
+    with self.assertRaisesRegex(ValueError, "title"):
+      ConfigParser(CustomConfigObject, "")
+
+  def test_title(self):
+    parser = ConfigParser(CustomConfigObject, None)
+    self.assertEqual(parser.title, "CustomConfigObject parser")
+    parser = ConfigParser(CustomConfigObject)
+    self.assertEqual(parser.title, "CustomConfigObject parser")
+    parser = ConfigParser(CustomConfigObject, "ParsyMcParser")
+    self.assertEqual(parser.title, "ParsyMcParser")
+
   def test_invalid_default(self):
     with self.assertRaises(TypeError) as cm:
       ConfigParser(  # pytype: disable=wrong-arg-types
-          "ConfigParserTestCase parser",
           CustomConfigObject,
           default="something else")
     self.assertIn("instance", str(cm.exception))
@@ -275,7 +289,7 @@ class ConfigParserTestCase(unittest.TestCase):
     result = CustomConfigObjectToArgumentValue.config_parser().parse(
         {"name": "custom-name"})
     self.assertIsInstance(result, CustomConfigObjectToArgumentValue)
-    parser = ConfigParser("TestParser", dict)
+    parser = ConfigParser(dict)
     parser.add_argument("data", type=CustomConfigObjectToArgumentValue)
 
     result = parser.parse({})
@@ -290,6 +304,13 @@ class ConfigParserTestCase(unittest.TestCase):
         }})
     self.assertDictEqual(result, {"data": ("a name", [1, 2], 1)})
 
+  def test_has_all_required_args(self):
+    config_parser = CustomConfigObjectToArgumentValue.config_parser()
+    self.assertTrue(config_parser.has_all_required_args({"name": "a name"}))
+    self.assertTrue(
+        config_parser.has_all_required_args({"name_alias": "a name"}))
+    self.assertFalse(config_parser.has_all_required_args({"integer": 1}))
+
 
 class ConfigObjectTestCase(CrossbenchFakeFsTestCase):
 
@@ -514,7 +535,7 @@ class ConfigObjectTestCase(CrossbenchFakeFsTestCase):
     config_2 = CustomConfigObject.parse(str(path))
     self.assertEqual(config, config_2)
 
-  TEST_DICT = immutabledict({
+  TEST_DICT: immutabledict[str, Any] = immutabledict({
       "name": "Config Name",
       "array": [1, 3],
       "integer": 166
@@ -541,7 +562,8 @@ class ConfigObjectTestCase(CrossbenchFakeFsTestCase):
     self.assertEqual(config.integer, 166)
     self.assertIsNone(config.nested)
 
-  TEST_DICT_NESTED = immutabledict({"name": "a nested name"})
+  TEST_DICT_NESTED: immutabledict[str, str] = immutabledict(
+      {"name": "a nested name"})
 
   def test_parse_dict_nested(self):
     test_dict = dict(self.TEST_DICT)
@@ -566,6 +588,27 @@ class ConfigObjectTestCase(CrossbenchFakeFsTestCase):
     self.assertEqual(config.nested,
                      CustomNestedConfigObject(name="a nested name"))
 
+  def test_parse_nested_long(self):
+    test_dict = dict(self.TEST_DICT)
+    long_string = "abcd" * 1_000
+    test_dict["nested"] = long_string
+    config = CustomConfigObject.parse_dict(test_dict)
+    assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.nested.name, long_string)
+
+  def test_parse_nested_long_os_error(self):
+    test_dict = dict(self.TEST_DICT)
+    long_string = "abcd" * 100
+    test_dict["nested"] = long_string
+
+    def raise_os_error(self):
+      raise OSError("Invalid file name")
+
+    with mock.patch.object(pathlib.Path, "is_file", raise_os_error):
+      config = CustomConfigObject.parse_dict(test_dict)
+      assert isinstance(config, CustomConfigObject)
+    self.assertEqual(config.nested.name, long_string)
+
   def test_parse_missing_depending(self):
     with self.assertRaises(argparse.ArgumentTypeError) as cm:
       CustomConfigObject.parse({"name": "foo", "depending_nested": "a value"})
@@ -629,6 +672,428 @@ class ConfigObjectTestCase(CrossbenchFakeFsTestCase):
     self.assertIn("choices are", error_message)
     self.assertIn("config_enum", error_message)
 
+  def test_parse_templated_config_missing_arg_throws(self):
+    config = {
+        "template": {
+            "name": "$[missing_arg]"
+        },
+        "args": {
+            "arg": "arg_value"
+        }
+    }
+
+    with self.assertRaisesRegex(MultiException, "missing_arg"):
+      config = CustomConfigObject.parse(config)
+
+  def test_parse_templated_config_multiple_missing_args_throws(self):
+    config = {
+        "template": {
+            "name": "$[missing_arg] $[missing_arg2]"
+        },
+        "args": {
+            "arg": "arg_value"
+        }
+    }
+
+    with self.assertRaises(MultiException) as cm:
+      config = CustomConfigObject.parse(config)
+    self.assertIn("'missing_arg'", str(cm.exception))
+    self.assertIn("'missing_arg2'", str(cm.exception))
+
+  def test_parse_templated_config_unsupported_arg_throws(self):
+    config = {
+        "template": {
+            "name": "text and $[dict-arg]"
+        },
+        "args": {
+            "dict-arg": {
+                "key": "value"
+            }
+        }
+    }
+
+    with self.assertRaisesRegex(argparse.ArgumentTypeError,
+                                "can not be substituted"):
+      config = CustomConfigObject.parse(config)
+
+  def test_parse_templated_config_dict_arg(self):
+    config = {
+        "template": {
+            "name": "top level",
+            "nested": "$[arg]"
+        },
+        "args": {
+            "arg": {
+                "name": "nested"
+            }
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.nested.name, "nested")
+
+  def test_parse_templated_config_empty_arg(self):
+    config = {"template": {"name": "$[arg]"}, "args": {"arg": ""}}
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "")
+
+  def test_parse_templated_config_string_only(self):
+    config = {"template": {"name": "$[arg]"}, "args": {"arg": "arg_value"}}
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "arg_value")
+
+  def test_parse_templated_config_unused_arg(self):
+    config = {
+        "template": {
+            "name": "$[arg]"
+        },
+        "args": {
+            "arg": "arg_value",
+            "unused_arg": "unused"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "arg_value")
+
+  def test_parse_templated_config_string_multiple(self):
+    config = {
+        "template": {
+            "name": "$[one]$[two]$[three]$[four]",
+        },
+        "args": {
+            "one": "1",
+            "two": "2",
+            "three": "3",
+            "four": "4"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "1234")
+
+  def test_parse_templated_config_string_multiple_mixed(self):
+    config = {
+        "template": {
+            "name": "[$[one]_$[two]_$[three]_$[four]]",
+        },
+        "args": {
+            "one": "1",
+            "two": 2,
+            "three": 3.0,
+            "four": 4.56
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "[1_2_3.0_4.56]")
+
+  def test_parse_templated_config_string_nested_matches(self):
+    config = {
+        "template": {
+            "name": "$[$[$[arg]]]",
+        },
+        "args": {
+            "arg": "arg2",
+            "arg2": "arg3",
+            "arg3": "the true arg"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "the true arg")
+
+  def test_parse_templated_config_int(self):
+    config = {
+        "template": {
+            "name": "name",
+            "integer": "$[arg]"
+        },
+        "args": {
+            "arg": 4
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.integer, 4)
+
+  def test_parse_templated_config_float(self):
+    config = {
+        "template": {
+            "name": "name",
+            "float_field": "$[arg]"
+        },
+        "args": {
+            "arg": 1.3
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.float_field, 1.3)
+
+  def test_parse_templated_config_filepath(self):
+    template_path_str = "template_file.hjson"
+    template = {
+        "name": "$[arg]",
+    }
+
+    path = pathlib.Path(template_path_str)
+    with path.open("w", encoding="utf-8") as f:
+      json.dump(template, f)
+
+    args = {"template": template_path_str, "args": {"arg": "arg_value"}}
+
+    config = CustomConfigObject.parse(args)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "arg_value")
+
+  def test_parse_templated_config_two_layer_filepath(self):
+    nested_path_str = "nested.hjson"
+    nested = {"name": "$[arg]"}
+
+    path = pathlib.Path(nested_path_str)
+    with path.open("w", encoding="utf-8") as f:
+      json.dump(nested, f)
+
+    template_path_str = "template_file.hjson"
+    template = {
+        "name": "top level",
+        "nested": nested_path_str,
+    }
+
+    path = pathlib.Path(template_path_str)
+    with path.open("w", encoding="utf-8") as f:
+      json.dump(template, f)
+
+    args = {"template": template_path_str, "args": {"arg": "arg_value"}}
+
+    config = CustomConfigObject.parse(args)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.nested.name, "arg_value")
+
+  def test_parse_templated_config_two_level_template(self):
+    config = {
+        "template": {
+            "name": "$[top-level-arg]",
+            "nested": {
+                "template": {
+                    "name": "$[second-level-arg]"
+                },
+                "args": {
+                    "second-level-arg": "second-level-name"
+                }
+            }
+        },
+        "args": {
+            "top-level-arg": "top-level-name"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "top-level-name")
+    self.assertEqual(config.nested.name, "second-level-name")
+
+  def test_parse_templated_config_two_level_template_files(self):
+    nested_path_str = "nested.hjson"
+    nested = {
+        "template": {
+            "name": "$[nested-name]"
+        },
+        "args": {
+            "nested-name": "nested"
+        }
+    }
+
+    path = pathlib.Path(nested_path_str)
+    with path.open("w", encoding="utf-8") as f:
+      json.dump(nested, f)
+
+    config = {
+        "template": {
+            "name": "$[top-level-arg]",
+            "nested": nested_path_str
+        },
+        "args": {
+            "top-level-arg": "top-level-name"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "top-level-name")
+    self.assertEqual(config.nested.name, "nested")
+
+  def test_parse_templated_config_single_escaped_value(self):
+    config = {
+        "template": {
+            "name": "some text $[[arg] on either side",
+        },
+        "args": {
+            "placeholder": "nothing"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "some text $[arg] on either side")
+
+  def test_parse_templated_config_nested_escaped_value(self):
+    config = {
+        "template": {
+            "name": "$[[ $[[arg] ]",
+        },
+        "args": {
+            "placeholder": "nothing"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "$[ $[[arg] ]")
+
+  def test_parse_templated_config_escaped_value_and_non_escaped(self):
+    config = {
+        "template": {
+            "name": "$[[arg] $[arg]",
+        },
+        "args": {
+            "arg": "arg_value"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "$[arg] arg_value")
+
+  def test_parse_template_single_unbound_arg(self):
+    config = {
+        "template": {
+            "name": "$[arg]",
+            "nested": {
+                "template": {
+                    "name": "$[arg]"
+                },
+                "unbound_args": ["arg"]
+            }
+        },
+        "args": {
+            "arg": "from-top-level"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "from-top-level")
+    self.assertEqual(config.nested.name, "from-top-level")
+
+  def test_parse_template_multiple_unbound_arg(self):
+    config = {
+        "template": {
+            "name": "$[arg]",
+            "nested": {
+                "template": {
+                    "name": "$[arg] $[arg2]"
+                },
+                "unbound_args": ["arg", "arg2"]
+            }
+        },
+        "args": {
+            "arg": "hello",
+            "arg2": "world"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+    self.assertIsInstance(config, CustomConfigObject)
+
+    self.assertEqual(config.name, "hello")
+    self.assertEqual(config.nested.name, "hello world")
+
+  def test_parse_template_unbound_arg_undefined(self):
+    config = {
+        "template": {
+            "name": "$[arg]",
+            "nested": {
+                "template": {
+                    "name": "$[not-an-arg]"
+                },
+                "unbound_args": ["not-an-arg"]
+            }
+        },
+        "args": {
+            "arg": "hello",
+        }
+    }
+
+    with self.assertRaisesRegex(MultiException, "'not-an-arg'"):
+      config = CustomConfigObject.parse(config)
+
+  def test_self_referencing_arg_throws(self):
+    config = {
+        "template": {
+            "name": "$[arg]",
+        },
+        "args": {
+            "arg": "some other $[arg] text"
+        }
+    }
+
+    with self.assertRaisesRegex(MultiException, "self-referencing"):
+      config = CustomConfigObject.parse(config)
+
+  def test_self_referencing_detection_escaped_arg(self):
+    config = {
+        "template": {
+            "name": "$[arg]",
+        },
+        "args": {
+            "arg": "some other $[[arg] text"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+
+  def test_self_referencing_detection_arg_name_no_arg_sequence(self):
+    config = {
+        "template": {
+            "name": "$[arg]",
+        },
+        "args": {
+            "arg": "some other arg text"
+        }
+    }
+
+    config = CustomConfigObject.parse(config)
+
 
 class ConfigEnumTestCase(unittest.TestCase):
 
diff --git a/tests/crossbench/test_env.py b/tests/crossbench/test_env.py
index 2540cc27..dfab09dc 100644
--- a/tests/crossbench/test_env.py
+++ b/tests/crossbench/test_env.py
@@ -4,126 +4,75 @@
 
 import pathlib
 import unittest
+from typing import Any
 from unittest import mock
 
-import hjson
+from typing_extensions import override
 
-from crossbench.env import (HostEnvironment, HostEnvironmentConfig,
-                            ValidationError, ValidationMode)
+from crossbench import plt
+from crossbench.browsers.settings import Settings
+from crossbench.env import (EnvironmentConfig, HostEnvironment, ValidationError,
+                            ValidationMode)
 from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
-
-
-class HostEnvironmentConfigTestCase(unittest.TestCase):
-
-  def test_combine_bool_value(self):
-    default = HostEnvironmentConfig()
-    self.assertIsNone(default.power_use_battery)
-
-    battery = HostEnvironmentConfig(power_use_battery=True)
-    self.assertTrue(battery.power_use_battery)
-    self.assertTrue(battery.merge(battery).power_use_battery)
-    self.assertTrue(default.merge(battery).power_use_battery)
-    self.assertTrue(battery.merge(default).power_use_battery)
-
-    power = HostEnvironmentConfig(power_use_battery=False)
-    self.assertFalse(power.power_use_battery)
-    self.assertFalse(power.merge(power).power_use_battery)
-    self.assertFalse(default.merge(power).power_use_battery)
-    self.assertFalse(power.merge(default).power_use_battery)
-
-    with self.assertRaises(ValueError):
-      power.merge(battery)
-
-  def test_combine_min_float_value(self):
-    default = HostEnvironmentConfig()
-    self.assertIsNone(default.cpu_min_relative_speed)
-
-    high = HostEnvironmentConfig(cpu_min_relative_speed=1)
-    self.assertEqual(high.cpu_min_relative_speed, 1)
-    self.assertEqual(high.merge(high).cpu_min_relative_speed, 1)
-    self.assertEqual(default.merge(high).cpu_min_relative_speed, 1)
-    self.assertEqual(high.merge(default).cpu_min_relative_speed, 1)
-
-    low = HostEnvironmentConfig(cpu_min_relative_speed=0.5)
-    self.assertEqual(low.cpu_min_relative_speed, 0.5)
-    self.assertEqual(low.merge(low).cpu_min_relative_speed, 0.5)
-    self.assertEqual(default.merge(low).cpu_min_relative_speed, 0.5)
-    self.assertEqual(low.merge(default).cpu_min_relative_speed, 0.5)
-
-    self.assertEqual(high.merge(low).cpu_min_relative_speed, 1)
-
-  def test_combine_max_float_value(self):
-    default = HostEnvironmentConfig()
-    self.assertIsNone(default.cpu_max_usage_percent)
-
-    high = HostEnvironmentConfig(cpu_max_usage_percent=100)
-    self.assertEqual(high.cpu_max_usage_percent, 100)
-    self.assertEqual(high.merge(high).cpu_max_usage_percent, 100)
-    self.assertEqual(default.merge(high).cpu_max_usage_percent, 100)
-    self.assertEqual(high.merge(default).cpu_max_usage_percent, 100)
-
-    low = HostEnvironmentConfig(cpu_max_usage_percent=0)
-    self.assertEqual(low.cpu_max_usage_percent, 0)
-    self.assertEqual(low.merge(low).cpu_max_usage_percent, 0)
-    self.assertEqual(default.merge(low).cpu_max_usage_percent, 0)
-    self.assertEqual(low.merge(default).cpu_max_usage_percent, 0)
-
-    self.assertEqual(high.merge(low).cpu_max_usage_percent, 0)
-
-  def test_parse_example_config_file(self):
-    example_config_file = pathlib.Path(
-        __file__).parent.parent / "config/doc/env.config.hjson"
-    if not example_config_file.exists():
-      raise unittest.SkipTest(f"Test file {example_config_file} does not exist")
-    with example_config_file.open(encoding="utf-8") as f:
-      data = hjson.load(f)
-    HostEnvironmentConfig(**data["env"])
+from tests.crossbench.mock_browser import MockSafari
+from tests.crossbench.mock_helper import (LinuxMockPlatform, MacOsMockPlatform,
+                                          MockPlatform)
 
 
 class HostEnvironmentTestCase(CrossbenchFakeFsTestCase):
 
+  @override
   def setUp(self):
     super().setUp()
-    self.mock_platform = mock.Mock()
-    self.mock_platform.processes.return_value = []
-    self.out_dir = pathlib.Path("results/current_benchmark_run_results")
-    self.fs.create_file(self.out_dir)
+    self.platform = self.setup_platform()
+    self.platform.use_fs = True
+    self.out_dir = pathlib.Path(
+        "crossbench/results/current_benchmark_run_results")
+    self.fs.create_dir(self.out_dir)
     self.mock_runner = mock.Mock(
-        platform=self.mock_platform,
+        platform=plt.PLATFORM,
         repetitions=1,
         probes=[],
         browsers=[],
         out_dir=self.out_dir)
 
+  def setup_platform(self):
+    return MockPlatform()
+
+  def patch_property(self, target: Any, name: str, **kwargs):
+    new_callable = kwargs.pop("new_callable", mock.PropertyMock)
+    return mock.patch.object(
+        type(target), name, new_callable=new_callable, **kwargs)
+
   def create_env(self, *args, **kwargs) -> HostEnvironment:
-    return HostEnvironment(self.mock_platform, self.mock_runner.out_dir,
+    return HostEnvironment(self.platform, self.mock_runner.out_dir,
                            self.mock_runner.browsers, self.mock_runner.probes,
                            self.mock_runner.repetitions, *args, **kwargs)
 
   def test_instantiate(self):
     env = self.create_env()
-    self.assertEqual(env.platform, self.mock_platform)
+    self.assertEqual(env.platform, self.platform)
 
-    config = HostEnvironmentConfig()
+    config = EnvironmentConfig()
     env = self.create_env(config)
     self.assertSequenceEqual(env.browsers, self.mock_runner.browsers)
     self.assertEqual(env.config, config)
 
   def test_warn_mode_skip(self):
-    config = HostEnvironmentConfig()
+    config = EnvironmentConfig()
     env = self.create_env(config, ValidationMode.SKIP)
     env.handle_warning("foo")
 
   def test_warn_mode_fail(self):
-    config = HostEnvironmentConfig()
+    config = EnvironmentConfig()
     env = self.create_env(config, ValidationMode.THROW)
     with self.assertRaises(ValidationError) as cm:
       env.handle_warning("custom env check warning")
     self.assertIn("custom env check warning", str(cm.exception))
 
   def test_warn_mode_prompt(self):
-    config = HostEnvironmentConfig()
+    config = EnvironmentConfig()
     env = self.create_env(config, ValidationMode.PROMPT)
     with mock.patch("builtins.input", return_value="Y") as cm:
       env.handle_warning("custom env check warning")
@@ -136,7 +85,7 @@ class HostEnvironmentTestCase(CrossbenchFakeFsTestCase):
     self.assertIn("custom env check warning", cm.call_args[0][0])
 
   def test_warn_mode_warn(self):
-    config = HostEnvironmentConfig()
+    config = EnvironmentConfig()
     env = self.create_env(config, ValidationMode.WARN)
     with mock.patch("logging.warning") as cm:
       env.handle_warning("custom env check warning")
@@ -144,71 +93,84 @@ class HostEnvironmentTestCase(CrossbenchFakeFsTestCase):
     self.assertIn("custom env check warning", cm.call_args[0][0])
 
   def test_validate_skip(self):
-    env = self.create_env(HostEnvironmentConfig(), ValidationMode.SKIP)
+    env = self.create_env(EnvironmentConfig(), ValidationMode.SKIP)
     env.validate()
 
   def test_validate_warn(self):
-    env = self.create_env(HostEnvironmentConfig(), ValidationMode.WARN)
+    env = self.create_env(EnvironmentConfig(), ValidationMode.WARN)
     with mock.patch("logging.warning") as cm:
       env.validate()
     cm.assert_not_called()
-    self.mock_platform.sh_stdout.assert_not_called()
-    self.mock_platform.sh.assert_not_called()
+    self.assertFalse(self.platform.sh_cmds)
 
   def test_validate_warn_no_probes(self):
     env = self.create_env(
-        HostEnvironmentConfig(require_probes=True), ValidationMode.WARN)
+        EnvironmentConfig(require_probes=True), ValidationMode.WARN)
     with mock.patch("logging.warning") as cm:
       env.validate()
     cm.assert_called_once()
-    self.mock_platform.sh_stdout.assert_not_called()
-    self.mock_platform.sh.assert_not_called()
+    self.assertFalse(self.platform.sh_cmds)
 
   def test_request_battery_power_on(self):
-    env = self.create_env(
-        HostEnvironmentConfig(power_use_battery=True), ValidationMode.THROW)
-    self.mock_platform.is_battery_powered = True
-    env.validate()
-
-    self.mock_platform.is_battery_powered = False
-    with self.assertRaises(Exception) as cm:
+    with self.patch_property(self.platform, "is_battery_powered") as mocked:
+      env = self.create_env(
+          EnvironmentConfig(power_use_battery=True), ValidationMode.THROW)
+      mocked.return_value = True
       env.validate()
-    self.assertIn("battery", str(cm.exception).lower())
+
+      mocked.return_value = False
+      with self.assertRaises(Exception) as cm:
+        env.validate()
+      self.assertIn("battery", str(cm.exception).lower())
 
   def test_request_battery_power_off(self):
     env = self.create_env(
-        HostEnvironmentConfig(power_use_battery=False), ValidationMode.THROW)
-    self.mock_platform.is_battery_powered = True
-    with self.assertRaises(ValidationError) as cm:
+        EnvironmentConfig(power_use_battery=False), ValidationMode.THROW)
+    with self.patch_property(self.platform,
+                             "is_battery_powered") as is_battery_powered:
+      is_battery_powered.return_value = True
+      with self.assertRaises(ValidationError) as cm:
+        env.validate()
+      self.assertIn("battery", str(cm.exception).lower())
+      self.assertEqual(is_battery_powered.call_count, 1)
+
+      is_battery_powered.return_value = False
       env.validate()
-    self.assertIn("battery", str(cm.exception).lower())
+      self.assertEqual(is_battery_powered.call_count, 2)
 
-    self.mock_platform.is_battery_powered = False
-    env.validate()
+  def test_mock_request_battery_power_off(self):
+    with self.patch_property(self.platform,
+                             "is_battery_powered") as is_battery_powered:
+      is_battery_powered.return_value = False
+      self.assertFalse(self.platform.is_battery_powered)
+      is_battery_powered.return_value = True
+      self.assertTrue(self.platform.is_battery_powered)
 
   def test_request_battery_power_off_conflicting_probe(self):
-    self.mock_platform.is_battery_powered = False
-
-    mock_probe = mock.Mock()
-    mock_probe.configure_mock(BATTERY_ONLY=True, name="mock_probe")
-    self.mock_runner.probes = [mock_probe]
-    env = self.create_env(
-        HostEnvironmentConfig(power_use_battery=False), ValidationMode.THROW)
-
-    with self.assertRaises(ValidationError) as cm:
+    with self.patch_property(self.platform,
+                             "is_battery_powered") as is_battery_powered:
+      is_battery_powered.return_value = False
+
+      mock_probe = mock.Mock()
+      mock_probe.configure_mock(BATTERY_ONLY=True, name="mock_probe")
+      self.mock_runner.probes = [mock_probe]
+      env = self.create_env(
+          EnvironmentConfig(power_use_battery=False), ValidationMode.THROW)
+
+      with self.assertRaises(ValidationError) as cm:
+        env.validate()
+      message = str(cm.exception).lower()
+      self.assertIn("mock_probe", message)
+      self.assertIn("battery", message)
+
+      mock_probe.BATTERY_ONLY = False
       env.validate()
-    message = str(cm.exception).lower()
-    self.assertIn("mock_probe", message)
-    self.assertIn("battery", message)
-
-    mock_probe.BATTERY_ONLY = False
-    env.validate()
 
   def test_request_is_headless_default(self):
     env = self.create_env(
-        HostEnvironmentConfig(browser_is_headless=HostEnvironmentConfig.IGNORE),
+        EnvironmentConfig(browser_is_headless=EnvironmentConfig.IGNORE),
         ValidationMode.THROW)
-    mock_browser = mock.Mock(platform=self.mock_platform)
+    mock_browser = mock.Mock(platform=self.platform)
     self.mock_runner.browsers = [mock_browser]
 
     mock_browser.viewport.is_headless = False
@@ -219,48 +181,52 @@ class HostEnvironmentTestCase(CrossbenchFakeFsTestCase):
 
   def test_request_is_headless_true(self):
     mock_browser = mock.Mock(
-        platform=self.mock_platform, path=pathlib.Path("bin/browser_a"))
+        platform=self.platform, path=pathlib.Path("bin/browser_a"))
     self.mock_runner.browsers = [mock_browser]
     env = self.create_env(
-        HostEnvironmentConfig(browser_is_headless=True), ValidationMode.THROW)
+        EnvironmentConfig(browser_is_headless=True), ValidationMode.THROW)
 
-    self.mock_platform.has_display = True
-    mock_browser.viewport.is_headless = False
-    with self.assertRaises(ValidationError) as cm:
-      env.validate()
-    self.assertIn("is_headless", str(cm.exception))
+    with self.patch_property(self.platform, "has_display") as has_display:
+      has_display.return_value = True
+      mock_browser.viewport.is_headless = False
+      with self.assertRaises(ValidationError) as cm:
+        env.validate()
+      self.assertIn("is_headless", str(cm.exception))
 
-    self.mock_platform.has_display = False
-    with self.assertRaises(ValidationError) as cm:
-      env.validate()
+      has_display.return_value = False
+      with self.assertRaises(ValidationError) as cm:
+        env.validate()
 
-    self.mock_platform.has_display = True
-    mock_browser.viewport.is_headless = True
-    env.validate()
+      has_display.return_value = True
+      mock_browser.viewport.is_headless = True
+      env.validate()
 
-    self.mock_platform.has_display = False
-    env.validate()
+      has_display.return_value = False
+      env.validate()
 
   def test_request_is_headless_false(self):
+    self.platform = LinuxMockPlatform()
+    self.platform.use_fs = True
     mock_browser = mock.Mock(
-        platform=self.mock_platform, path=pathlib.Path("bin/browser_a"))
+        platform=self.platform, path=pathlib.Path("bin/browser_a"))
     self.mock_runner.browsers = [mock_browser]
     env = self.create_env(
-        HostEnvironmentConfig(browser_is_headless=False), ValidationMode.THROW)
-
-    self.mock_platform.has_display = True
-    mock_browser.viewport.is_headless = False
-    env.validate()
-
-    self.mock_platform.has_display = False
-    with self.assertRaises(ValidationError) as cm:
+        EnvironmentConfig(browser_is_headless=False), ValidationMode.THROW)
+    with self.patch_property(self.platform, "has_display") as has_display:
+      has_display.return_value = True
+      mock_browser.viewport.is_headless = False
       env.validate()
 
-    self.mock_platform.has_display = True
-    mock_browser.viewport.is_headless = True
-    with self.assertRaises(ValidationError) as cm:
-      env.validate()
-    self.assertIn("is_headless", str(cm.exception))
+      has_display.return_value = False
+      self.assertFalse(self.platform.has_display)
+      with self.assertRaises(ValidationError) as cm:
+        env.validate()
+
+      has_display.return_value = True
+      mock_browser.viewport.is_headless = True
+      with self.assertRaises(ValidationError) as cm:
+        env.validate()
+      self.assertIn("is_headless", str(cm.exception))
 
   def test_results_dir_single(self):
     env = self.create_env()
@@ -294,19 +260,20 @@ class HostEnvironmentTestCase(CrossbenchFakeFsTestCase):
     cm.assert_called_once()
 
   def test_check_installed_missing(self):
-
     def which_none(_):
       return None
 
-    self.mock_platform.which = which_none
-    env = self.create_env()
-    with self.assertRaises(ValidationError) as cm:
-      env.check_installed(["custom_binary"])
-    self.assertIn("custom_binary", str(cm.exception))
-    with self.assertRaises(ValidationError) as cm:
-      env.check_installed(["custom_binary_a", "custom_binary_b"])
-    self.assertIn("custom_binary_a", str(cm.exception))
-    self.assertIn("custom_binary_b", str(cm.exception))
+    with mock.patch.object(
+        self.platform, "which", side_effect=which_none) as mock_which:
+      env = self.create_env()
+      with self.assertRaises(ValidationError) as cm:
+        env.check_installed(["custom_binary"])
+      self.assertIn("custom_binary", str(cm.exception))
+      with self.assertRaises(ValidationError) as cm:
+        env.check_installed(["custom_binary_a", "custom_binary_b"])
+      self.assertIn("custom_binary_a", str(cm.exception))
+      self.assertIn("custom_binary_b", str(cm.exception))
+      mock_which.assert_called()
 
   def test_check_installed_partially_missing(self):
 
@@ -315,13 +282,54 @@ class HostEnvironmentTestCase(CrossbenchFakeFsTestCase):
         return "/bin/custom_binary_b"
       return None
 
-    self.mock_platform.which = which_custom
+    with mock.patch.object(
+        self.platform, "which", side_effect=which_custom) as mock_which:
+      env = self.create_env()
+      env.check_installed(["custom_binary_b"])
+      with self.assertRaises(ValidationError) as cm:
+        env.check_installed(["custom_binary_a", "custom_binary_b"])
+      self.assertIn("custom_binary_a", str(cm.exception))
+      self.assertNotIn("custom_binary_b", str(cm.exception))
+      mock_which.assert_called()
+
+  def test_file_access_outdir(self):
+    self._check_file_access()
+
+  def _check_file_access(self):
+    out_dir = self.mock_runner.out_dir
+    self.assertTrue(out_dir.exists())
     env = self.create_env()
-    env.check_installed(["custom_binary_b"])
-    with self.assertRaises(ValidationError) as cm:
-      env.check_installed(["custom_binary_a", "custom_binary_b"])
-    self.assertIn("custom_binary_a", str(cm.exception))
-    self.assertNotIn("custom_binary_b", str(cm.exception))
+    env.validate()
+    with mock.patch.object(
+        self.platform, "mkdir", side_effect=ValueError("No File Access")):
+      env = self.create_env()
+      with self.assertRaisesRegex(ValidationError, str(out_dir.parent)):
+        env.validate()
+    with mock.patch.object(self.platform, "get_file_contents", side_effect=""):
+      env = self.create_env()
+      with self.assertRaisesRegex(ValidationError, str(out_dir.parent)):
+        env.validate()
+
+  def test_macos_file_access_outdir(self):
+    self.platform = MacOsMockPlatform()
+    self.platform.use_fs = True
+    self._check_file_access()
+
+  def test_macos_safari_cache_dir(self):
+    self.platform = MacOsMockPlatform()
+    self.platform.use_fs = True
+    MockSafari.setup_fs(self.fs, self.platform)
+
+    mock_browser = MockSafari("sf", settings=Settings(platform=self.platform))
+    self.mock_runner.browsers = [mock_browser]
+
+    with mock.patch.object(self.platform, "get_file_contents", side_effect=""):
+      env = self.create_env()
+      with self.assertRaisesRegex(ValidationError, "Safari"):
+        env.validate()
+    # success otherwise
+    env.validate()
+
 
 
 class ValidationModeTestCase(unittest.TestCase):
diff --git a/tests/crossbench/test_exception.py b/tests/crossbench/test_exception.py
index 9478a21f..56402899 100644
--- a/tests/crossbench/test_exception.py
+++ b/tests/crossbench/test_exception.py
@@ -123,7 +123,7 @@ class ExceptionHandlerTestCase(unittest.TestCase):
     self.assertEqual(len(annotator), 0)
     self.assertListEqual(annotator.to_json(), [])
     with mock.patch("logging.error") as logging_mock:
-      annotator.log()
+      annotator.log("custom title")
     # No exceptions => no error output
     logging_mock.assert_not_called()
 
@@ -139,7 +139,7 @@ class ExceptionHandlerTestCase(unittest.TestCase):
     self.assertEqual(len(serialized), 1)
     self.assertEqual(serialized[0]["title"], str(exception))
     with mock.patch("logging.debug") as logging_mock:
-      annotator.log()
+      annotator.log("custom title")
     logging_mock.assert_has_calls([mock.call(exception)])
 
   def test_handle_rethrow(self):
@@ -184,10 +184,11 @@ class ExceptionHandlerTestCase(unittest.TestCase):
     except ValueError as e:
       annotator.append(e)
     with self.assertLogs(level="ERROR") as cm:
-      annotator.log()
+      annotator.log("CUSTOM TITLE")
     output = "\n".join(cm.output)
     self.assertIn("info 1", output)
     self.assertIn("info 2", output)
+    self.assertIn("CUSTOM TITLE", output)
     self.assertIn("custom message", output)
 
   def test_handle_keyboard_interrupt(self):
diff --git a/tests/crossbench/test_flags.py b/tests/crossbench/test_flags.py
index 33ad2ac6..c946722e 100644
--- a/tests/crossbench/test_flags.py
+++ b/tests/crossbench/test_flags.py
@@ -64,7 +64,7 @@ class TestFlags(unittest.TestCase):
     self.assertIsNone(flags["--bar"])
     with self.assertRaises(ValueError):
       flags.set("--bar", "v3")
-    flags.set("--bar", "v4", override=True)
+    flags.set("--bar", "v4", should_override=True)
     self.assertEqual(flags["--foo"], "v1")
     self.assertEqual(flags["--bar"], "v4")
 
@@ -117,7 +117,7 @@ class TestFlags(unittest.TestCase):
       flags.update({"--bar": "v2"})
     self.assertEqual(flags["--foo"], "v1")
     self.assertIsNone(flags["--bar"])
-    flags.update({"--bar": "v2"}, override=True)
+    flags.update({"--bar": "v2"}, should_override=True)
     self.assertEqual(flags["--foo"], "v1")
     self.assertEqual(flags["--bar"], "v2")
     self.assertTrue(flags)
@@ -213,9 +213,30 @@ class TestFlags(unittest.TestCase):
     self.assertFalse(self.CLASS())
     self.assertTrue(self.CLASS.parse("--foo --bar"))
 
+  def test_filtered(self):
+    self.assertFalse(self.CLASS().filtered([]))
+    self.assertFalse(self.CLASS.parse("--foo --bar").filtered([]))
+    self.assertEqual(
+        self.CLASS.parse("--foo --bar").filtered(["--foo"]),
+        self.CLASS.parse("--foo"))
+    self.assertEqual(
+        self.CLASS.parse("--foo --bar").filtered(["--bar"]),
+        self.CLASS.parse("--bar"))
+    self.assertEqual(
+        self.CLASS.parse("--foo --bar=1").filtered(["--bar"]),
+        self.CLASS.parse("--bar=1"))
+    self.assertEqual(
+        self.CLASS.parse("--foo --bar").filtered(["--foo", "--bar"]),
+        self.CLASS.parse("--foo --bar"))
+    self.assertEqual(
+        self.CLASS.parse("--foo --bar").filtered(["--bar", "--foo"]),
+        self.CLASS.parse("--foo --bar"))
+    self.assertEqual(
+        self.CLASS.parse("--foo=0 --bar").filtered(["--bar", "--foo"]),
+        self.CLASS.parse("--foo=0 --bar"))
 
-class TestChromeFlags(TestFlags):
 
+class TestChromeFlags(TestFlags):
   CLASS = ChromeFlags
 
   def test_js_flags(self):
@@ -600,8 +621,76 @@ class TestChromeFlags(TestFlags):
     for chrome_flag in KNOWN_CHROME_FLAGS:
       self.assertNotIn(chrome_flag, KNOWN_JS_FLAGS)
 
-class TestJSFlags(TestFlags):
+  def test_field_trial_flags(self):
+    empty = self.CLASS()
+    self.assertFalse(empty.field_trial_flags)
+    some_flags = self.CLASS(("--foo", "--bar"))
+    self.assertFalse(some_flags.field_trial_flags)
+    field_trials = self.CLASS(("--enable-field-trial-config", "--foo"))
+    self.assertEqual(
+        str(field_trials.field_trial_flags), "--enable-field-trial-config")
+    field_trials.set("--enable-benchmarking")
+    self.assertEqual(
+        str(field_trials.field_trial_flags), "--enable-field-trial-config")
+    field_trials.set(
+        "--enable-benchmarking",
+        "enable-field-trial-config",
+        should_override=True)
+    self.assertEqual(
+        str(field_trials.field_trial_flags), "--enable-field-trial-config "
+        "--enable-benchmarking=enable-field-trial-config")
+
+  def test_no_experiments_flags(self):
+    empty = self.CLASS()
+    self.assertFalse(empty.no_experiments_flags)
+    some_flags = self.CLASS(("--foo", "--bar"))
+    self.assertFalse(some_flags.no_experiments_flags)
+    field_trials = self.CLASS(("--disable-field-trial-config", "--foo"))
+    self.assertEqual(
+        str(field_trials.no_experiments_flags), "--disable-field-trial-config")
+    field_trials.set("--enable-benchmarking")
+    self.assertEqual(
+        str(field_trials.no_experiments_flags),
+        "--disable-field-trial-config --enable-benchmarking")
+    field_trials.set(
+        "--enable-benchmarking",
+        "enable-field-trial-config",
+        should_override=True)
+    self.assertEqual(
+        str(field_trials.no_experiments_flags), "--disable-field-trial-config")
+
+  def test_set_enable_benchmarking_extension(self):
+    flags = self.CLASS()
+    flags.enable_benchmarking_extension()
+    self.assertEqual(str(flags), "--enable-benchmarking")
+
+    flags = self.CLASS.parse("--foo")
+    flags.enable_benchmarking_extension()
+    self.assertEqual(str(flags), "--foo --enable-benchmarking")
+
+    flags = self.CLASS.parse("--enable-benchmarking")
+    flags.enable_benchmarking_extension()
+    self.assertEqual(str(flags), "--enable-benchmarking")
+
+    flags = self.CLASS.parse("--enable-benchmarking=enable-field-trial-config")
+    flags.enable_benchmarking_extension()
+    self.assertEqual(
+        str(flags), "--enable-benchmarking=enable-field-trial-config")
+
+    flags = self.CLASS.parse("--enable-field-trial-config")
+    flags.enable_benchmarking_extension()
+    self.assertEqual(
+        str(flags), "--enable-field-trial-config "
+        "--enable-benchmarking=enable-field-trial-config")
 
+    flags = self.CLASS.parse("--foo --enable-field-trial-config --bar")
+    flags.enable_benchmarking_extension()
+    self.assertEqual(
+        str(flags), "--foo --enable-field-trial-config --bar "
+        "--enable-benchmarking=enable-field-trial-config")
+
+
+class TestJSFlags(TestFlags):
   CLASS = JSFlags
 
   def test_invalid_js_flags(self):
@@ -650,13 +739,13 @@ class TestJSFlags(TestFlags):
     self.assertIsNone(flags["--foo"])
     self.assertIsNone(flags["--no-bar"])
 
-    flags.set("--no-foo", override=True)
+    flags.set("--no-foo", should_override=True)
     self.assertNotIn("--foo", flags)
     self.assertIn("--no-foo", flags)
     self.assertNotIn("--bar", flags)
     self.assertIn("--no-bar", flags)
 
-    flags.set("--bar", override=True)
+    flags.set("--bar", should_override=True)
     self.assertNotIn("--foo", flags)
     self.assertIn("--no-foo", flags)
     self.assertIn("--bar", flags)
diff --git a/tests/crossbench/test_helper.py b/tests/crossbench/test_helper.py
index 9e8ffe81..9f47ece0 100644
--- a/tests/crossbench/test_helper.py
+++ b/tests/crossbench/test_helper.py
@@ -6,8 +6,16 @@ import datetime as dt
 import enum
 import pathlib
 import unittest
+from typing import List, Tuple
 
-from crossbench import compat, helper, plt
+from typing_extensions import override
+
+from crossbench import plt
+from crossbench.helper import collection_helper, fs_helper, url_helper
+from crossbench.helper.cwd import ChangeCWD
+from crossbench.helper.durations import Durations
+from crossbench.helper.wait import WaitRange
+from crossbench.str_enum_with_help import StrEnumWithHelp
 from tests import test_helper
 from tests.crossbench.base import CrossbenchFakeFsTestCase
 
@@ -16,61 +24,73 @@ class WaitTestCase(unittest.TestCase):
 
   def test_invalid_wait_ranges(self):
     with self.assertRaises(AssertionError):
-      helper.WaitRange(min=-1)
+      WaitRange(min=-1)
     with self.assertRaises(AssertionError):
-      helper.WaitRange(timeout=0)
+      WaitRange(timeout=0)
     with self.assertRaises(AssertionError):
-      helper.WaitRange(factor=0.2)
+      WaitRange(factor=0.2)
     with self.assertRaises(AssertionError):
-      helper.WaitRange(delay=100)
+      WaitRange(delay=100)
 
   def test_range(self):
+    durations = list(WaitRange(min=1, max=16, factor=2, max_iterations=5))
+    self.assertListEqual(durations, [(0, dt.timedelta(seconds=1)),
+                                     (1, dt.timedelta(seconds=2)),
+                                     (2, dt.timedelta(seconds=4)),
+                                     (3, dt.timedelta(seconds=8)),
+                                     (4, dt.timedelta(seconds=16))])
+
+  def test_range_with_delay(self):
     durations = list(
-        helper.WaitRange(min=1, max=16, factor=2, max_iterations=5))
+        WaitRange(min=1, max=16, factor=2, max_iterations=5, delay=5.5))
     self.assertListEqual(durations, [
-        dt.timedelta(seconds=1),
-        dt.timedelta(seconds=2),
-        dt.timedelta(seconds=4),
-        dt.timedelta(seconds=8),
-        dt.timedelta(seconds=16)
+        (0, dt.timedelta(seconds=5.5)),
+        (1, dt.timedelta(seconds=1)),
+        (2, dt.timedelta(seconds=2)),
+        (3, dt.timedelta(seconds=4)),
+        (4, dt.timedelta(seconds=8)),
     ])
-
-  def test_range_with_delay(self):
     durations = list(
-        helper.WaitRange(min=1, max=16, factor=2, max_iterations=5, delay=5.5))
+        WaitRange(min=1, max=16, factor=2, max_iterations=10, delay=5.5))
     self.assertListEqual(durations, [
-        dt.timedelta(seconds=5.5),
-        dt.timedelta(seconds=1),
-        dt.timedelta(seconds=2),
-        dt.timedelta(seconds=4),
-        dt.timedelta(seconds=8),
-        dt.timedelta(seconds=16)
+        (0, dt.timedelta(seconds=5.5)),
+        (1, dt.timedelta(seconds=1)),
+        (2, dt.timedelta(seconds=2)),
+        (3, dt.timedelta(seconds=4)),
+        (4, dt.timedelta(seconds=8)),
+        (5, dt.timedelta(seconds=16)),
+        (6, dt.timedelta(seconds=16)),
+        (7, dt.timedelta(seconds=16)),
+        (8, dt.timedelta(seconds=16)),
+        (9, dt.timedelta(seconds=16)),
     ])
 
   def test_range_extended(self):
-    durations = list(
-        helper.WaitRange(min=1, max=16, factor=2, max_iterations=5 + 4))
+    durations = list(WaitRange(min=1, max=16, factor=2, max_iterations=5 + 4))
     self.assertListEqual(
         durations,
         [
-            dt.timedelta(seconds=1),
-            dt.timedelta(seconds=2),
-            dt.timedelta(seconds=4),
-            dt.timedelta(seconds=8),
-            dt.timedelta(seconds=16),
+            (0, dt.timedelta(seconds=1)),
+            (1, dt.timedelta(seconds=2)),
+            (2, dt.timedelta(seconds=4)),
+            (3, dt.timedelta(seconds=8)),
+            (4, dt.timedelta(seconds=16)),
             # After 5 iterations the interval is no longer increased
-            dt.timedelta(seconds=16),
-            dt.timedelta(seconds=16),
-            dt.timedelta(seconds=16),
-            dt.timedelta(seconds=16)
+            (5, dt.timedelta(seconds=16)),
+            (6, dt.timedelta(seconds=16)),
+            (7, dt.timedelta(seconds=16)),
+            (8, dt.timedelta(seconds=16))
         ])
 
   def test_wait_with_backoff(self):
-    data = []
-    delta = 0.0005
-    for time_spent, time_left in helper.WaitRange(
+    data: List[Tuple[dt.timedelta, dt.timedelta]] = []
+    delta = dt.timedelta(seconds=0.0005)
+    expected_i = 0
+    for i, time_spent, time_left in WaitRange(
         min=0.01, max=0.05).wait_with_backoff():
       data.append((time_spent, time_left))
+      self.assertEqual(expected_i, i)
+      expected_i += 1
       if len(data) == 2:
         break
       plt.PLATFORM.sleep(delta)
@@ -80,11 +100,29 @@ class WaitTestCase(unittest.TestCase):
     self.assertLessEqual(first_time_spent + delta, second_time_spent)
     self.assertGreaterEqual(first_time_left, second_time_left + delta)
 
+  def test_wait_with_backoff_max_iterations(self):
+    i = 0
+    expected_i = 0
+    for i, _, _ in WaitRange(
+        min=0.01, max=0.05, max_iterations=11).wait_with_backoff():
+      self.assertEqual(expected_i, i)
+      expected_i += 1
+    self.assertEqual(i, 10)
+
+  def test_wait_with_backoff_max_iterations_delay(self):
+    i = 0
+    expected_i = 0
+    for i, _, _ in WaitRange(
+        min=0.01, max=0.05, delay=0.1, max_iterations=11).wait_with_backoff():
+      self.assertEqual(expected_i, i)
+      expected_i += 1
+    self.assertEqual(i, 10)
+
 
 class DurationsTestCase(unittest.TestCase):
 
   def test_single(self):
-    durations = helper.Durations()
+    durations = Durations()
     self.assertTrue(len(durations) == 0)
     self.assertDictEqual(durations.to_json(), {})
     with durations.measure("a"):
@@ -93,7 +131,7 @@ class DurationsTestCase(unittest.TestCase):
     self.assertTrue(len(durations) == 1)
 
   def test_invalid_twice(self):
-    durations = helper.Durations()
+    durations = Durations()
     with durations.measure("a"):
       pass
     with self.assertRaises(AssertionError):
@@ -103,7 +141,7 @@ class DurationsTestCase(unittest.TestCase):
     self.assertListEqual(list(durations.to_json().keys()), ["a"])
 
   def test_multiple(self):
-    durations = helper.Durations()
+    durations = Durations()
     for name in ["a", "b", "c"]:
       with durations.measure(name):
         pass
@@ -117,7 +155,7 @@ class ChangeCWDTestCase(CrossbenchFakeFsTestCase):
     old_cwd = pathlib.Path.cwd()
     new_cwd = pathlib.Path("/foo/bar").absolute()
     new_cwd.mkdir(parents=True)
-    with helper.ChangeCWD(new_cwd):
+    with ChangeCWD(new_cwd):
       self.assertNotEqual(old_cwd, pathlib.Path.cwd())
       self.assertEqual(new_cwd, pathlib.Path.cwd())
     self.assertEqual(old_cwd, pathlib.Path.cwd())
@@ -129,25 +167,25 @@ class FileSizeTestCase(CrossbenchFakeFsTestCase):
   def test_empty(self):
     test_file = pathlib.Path("test.txt")
     test_file.touch()
-    size = helper.get_file_size(test_file)
+    size = fs_helper.get_file_size(test_file)
     self.assertEqual(size, "0.00 B")
 
   def test_bytes(self):
     test_file = pathlib.Path("test.txt")
     self.fs.create_file(test_file, st_size=501)
-    size = helper.get_file_size(test_file)
+    size = fs_helper.get_file_size(test_file)
     self.assertEqual(size, "501.00 B")
 
   def test_kib(self):
     test_file = pathlib.Path("test.txt")
     self.fs.create_file(test_file, st_size=1024 * 2)
-    size = helper.get_file_size(test_file)
+    size = fs_helper.get_file_size(test_file)
     self.assertEqual(size, "2.00 KiB")
 
   def test_kib_fraction(self):
     test_file = pathlib.Path("test.txt")
     self.fs.create_file(test_file, st_size=int(1024 * 2.51))
-    size = helper.get_file_size(test_file)
+    size = fs_helper.get_file_size(test_file)
     self.assertEqual(size, "2.51 KiB")
 
   def test_sort_by_file_size(self):
@@ -157,56 +195,59 @@ class FileSizeTestCase(CrossbenchFakeFsTestCase):
     self.fs.create_file(small, st_size=100)
     self.fs.create_file(medium, st_size=200)
     self.fs.create_file(large, st_size=300)
-    result = helper.sort_by_file_size([small, medium, large])
+    result = fs_helper.sort_by_file_size([small, medium, large])
     self.assertListEqual(result, [small, medium, large])
-    result = helper.sort_by_file_size([medium, large, small])
+    result = fs_helper.sort_by_file_size([medium, large, small])
     self.assertListEqual(result, [small, medium, large])
-    result = helper.sort_by_file_size([large, medium, small])
+    result = fs_helper.sort_by_file_size([large, medium, small])
     self.assertListEqual(result, [small, medium, large])
 
 
 class GroupByTestCase(unittest.TestCase):
 
   def test_empty(self):
-    grouped = helper.group_by([], key=str)
+    grouped = collection_helper.group_by([], key=str)
     self.assertDictEqual({}, grouped)
 
   def test_basic(self):
-    grouped = helper.group_by([1, 1, 1, 2, 2, 3], key=str)
+    grouped = collection_helper.group_by([1, 1, 1, 2, 2, 3], key=str)
     self.assertListEqual(list(grouped.keys()), ["1", "2", "3"])
     self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
 
   def test_basic_out_of_order(self):
-    grouped = helper.group_by([2, 3, 2, 1, 1, 1], key=str)
+    grouped = collection_helper.group_by([2, 3, 2, 1, 1, 1], key=str)
     self.assertListEqual(list(grouped.keys()), ["1", "2", "3"])
     self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
 
   def test_basic_input_order(self):
-    grouped = helper.group_by([2, 3, 2, 1, 1, 1], key=str, sort_key=None)
+    grouped = collection_helper.group_by([2, 3, 2, 1, 1, 1],
+                                         key=str,
+                                         sort_key=None)
     self.assertListEqual(list(grouped.keys()), ["2", "3", "1"])
     self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
 
   def test_basic_custom_order(self):
-    grouped = helper.group_by([2, 3, 2, 1, 1, 1],
-                              key=str,
-                              sort_key=lambda item: int(item[0]))
+    grouped = collection_helper.group_by([2, 3, 2, 1, 1, 1],
+                                         key=str,
+                                         sort_key=lambda item: int(item[0]))
     self.assertListEqual(list(grouped.keys()), ["1", "2", "3"])
     self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
     # Try reverse sorting
-    grouped = helper.group_by([2, 3, 2, 1, 1, 1],
-                              key=str,
-                              sort_key=lambda item: -int(item[0]))
+    grouped = collection_helper.group_by([2, 3, 2, 1, 1, 1],
+                                         key=str,
+                                         sort_key=lambda item: -int(item[0]))
     self.assertListEqual(list(grouped.keys()), ["3", "2", "1"])
     self.assertDictEqual({"1": [1, 1, 1], "2": [2, 2], "3": [3]}, grouped)
 
   def test_custom_key(self):
-    grouped = helper.group_by([1.1, 1.2, 1.3, 2.1, 2.2, 3.1], key=int)
+    grouped = collection_helper.group_by([1.1, 1.2, 1.3, 2.1, 2.2, 3.1],
+                                         key=int)
     self.assertDictEqual({1: [1.1, 1.2, 1.3], 2: [2.1, 2.2], 3: [3.1]}, grouped)
 
   def test_custom_value(self):
-    grouped = helper.group_by([1, 1, 1, 2, 2, 3],
-                              key=str,
-                              value=lambda x: x * 100)
+    grouped = collection_helper.group_by([1, 1, 1, 2, 2, 3],
+                                         key=str,
+                                         value=lambda x: x * 100)
     self.assertDictEqual({
         "1": [100, 100, 100],
         "2": [200, 200],
@@ -214,9 +255,9 @@ class GroupByTestCase(unittest.TestCase):
     }, grouped)
 
   def test_custom_group(self):
-    grouped = helper.group_by([1, 1, 1, 2, 2, 3],
-                              key=str,
-                              group=lambda key: ["custom"])
+    grouped = collection_helper.group_by([1, 1, 1, 2, 2, 3],
+                                         key=str,
+                                         group=lambda key: ["custom"])
     self.assertDictEqual(
         {
             "1": ["custom", 1, 1, 1],
@@ -225,9 +266,9 @@ class GroupByTestCase(unittest.TestCase):
         }, grouped)
 
   def test_custom_group_out_of_order(self):
-    grouped = helper.group_by([1, 1, 1, 2, 2, 3],
-                              key=str,
-                              group=lambda key: ["custom"])
+    grouped = collection_helper.group_by([1, 1, 1, 2, 2, 3],
+                                         key=str,
+                                         group=lambda key: ["custom"])
     self.assertDictEqual(
         {
             "1": ["custom", 1, 1, 1],
@@ -238,6 +279,7 @@ class GroupByTestCase(unittest.TestCase):
 
 class ConcatFilesTestCase(CrossbenchFakeFsTestCase):
 
+  @override
   def setUp(self):
     super().setUp()
     self.platform = plt.PLATFORM
@@ -262,7 +304,7 @@ class ConcatFilesTestCase(CrossbenchFakeFsTestCase):
 class StrEnumWithHelpTestCase(unittest.TestCase):
 
   @enum.unique
-  class TestEnum(compat.StrEnumWithHelp):
+  class TestEnum(StrEnumWithHelp):
     A = ("a", "help a")
     B = ("b", "help b")
 
@@ -303,35 +345,37 @@ class UpdateUrlQueryTestCase(unittest.TestCase):
 
   def test_empty(self):
     self.assertEqual("http://test.com",
-                     helper.update_url_query("http://test.com", {}))
+                     url_helper.update_url_query("http://test.com", {}))
     self.assertEqual("https://test.com",
-                     helper.update_url_query("https://test.com", {}))
-    self.assertEqual("https://test.com?foo=bar",
-                     helper.update_url_query("https://test.com?foo=bar", {}))
+                     url_helper.update_url_query("https://test.com", {}))
+    self.assertEqual(
+        "https://test.com?foo=bar",
+        url_helper.update_url_query("https://test.com?foo=bar", {}))
 
   def test_empty_add(self):
-    self.assertEqual("http://test.com?foo=bar",
-                     helper.update_url_query("http://test.com", {"foo": "bar"}))
+    self.assertEqual(
+        "http://test.com?foo=bar",
+        url_helper.update_url_query("http://test.com", {"foo": "bar"}))
     self.assertEqual(
         "http://test.com?foo=bar#status",
-        helper.update_url_query("http://test.com#status", {"foo": "bar"}))
+        url_helper.update_url_query("http://test.com#status", {"foo": "bar"}))
     self.assertEqual(
         "http://test.com?xyz=10&foo=bar#status",
-        helper.update_url_query("http://test.com?xyz=10#status",
-                                {"foo": "bar"}))
+        url_helper.update_url_query("http://test.com?xyz=10#status",
+                                    {"foo": "bar"}))
 
   def test_override(self):
     self.assertEqual(
         "http://test.com?foo=bar",
-        helper.update_url_query("http://test.com?foo=BAR", {"foo": "bar"}))
+        url_helper.update_url_query("http://test.com?foo=BAR", {"foo": "bar"}))
     self.assertEqual(
         "http://test.com?foo=bar#status",
-        helper.update_url_query("http://test.com?foo=BAR#status",
-                                {"foo": "bar"}))
+        url_helper.update_url_query("http://test.com?foo=BAR#status",
+                                    {"foo": "bar"}))
     self.assertEqual(
         "http://test.com?foo=bar&xyz=10#status",
-        helper.update_url_query("http://test.com?foo=BAR&xyz=10#status",
-                                {"foo": "bar"}))
+        url_helper.update_url_query("http://test.com?foo=BAR&xyz=10#status",
+                                    {"foo": "bar"}))
 
 
 if __name__ == "__main__":
diff --git a/tests/crossbench/test_parse.py b/tests/crossbench/test_parse.py
index e5d57832..6acf2d77 100644
--- a/tests/crossbench/test_parse.py
+++ b/tests/crossbench/test_parse.py
@@ -7,11 +7,14 @@ from __future__ import annotations
 import argparse
 import datetime as dt
 import json
+import math
 import pathlib
 import unittest
 from typing import Any
 from urllib import parse as urlparse
 
+from typing_extensions import override
+
 from crossbench.parse import (DurationParser, NumberParser, ObjectParser,
                               PathParser)
 from tests import test_helper
@@ -134,6 +137,7 @@ class DurationParserTestCase(unittest.TestCase):
 
 class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
 
+  @override
   def setUp(self):
     super().setUp()
     self._json_test_data = {"int": 1, "array": [1, "2"]}
@@ -154,6 +158,26 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
       ObjectParser.non_empty_str("")
     self.assertIn("empty", str(cm.exception))
 
+  def test_parse_str_or_file_contents(self):
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, "empty"):
+      ObjectParser.str_or_file_contents("")
+    self.assertEqual(
+        ObjectParser.str_or_file_contents("some data"), "some data")
+    self.assertEqual(ObjectParser.str_or_file_contents("test.txt"), "test.txt")
+
+  def test_parse_str_or_file_contents_file(self):
+    path = pathlib.Path("./test.txt")
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, str(path)):
+      ObjectParser.str_or_file_contents(path)
+    with self.assertRaisesRegex(argparse.ArgumentTypeError, str(path)):
+      ObjectParser.str_or_file_contents("./test.txt")
+    self.fs.create_file(path, contents="test file contents")
+    self.assertEqual(
+        ObjectParser.str_or_file_contents(path), "test file contents")
+    self.assertEqual(ObjectParser.str_or_file_contents(str(path)), "test.txt")
+    self.assertEqual(
+        ObjectParser.str_or_file_contents("./test.txt"), "test file contents")
+
   def test_parse_httpx_url_str(self):
     for valid in ("http://foo.com", "https://foo.com", "http://localhost:800"):
       self.assertEqual(ObjectParser.httpx_url_str(valid), valid)
@@ -165,38 +189,88 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
   def test_parse_any_int(self):
     self.assertEqual(NumberParser.any_int("-123456"), -123456)
     self.assertEqual(NumberParser.any_int(-123456), -123456)
+    self.assertEqual(NumberParser.any_int(float(-123456)), -123456)
     self.assertEqual(NumberParser.any_int("-1"), -1)
     self.assertEqual(NumberParser.any_int(-1), -1)
+    self.assertEqual(NumberParser.any_int(float(-1)), -1)
     self.assertEqual(NumberParser.any_int("0"), 0)
     self.assertEqual(NumberParser.any_int(0), 0)
+    self.assertEqual(NumberParser.any_int(float(0)), 0)
     self.assertEqual(NumberParser.any_int("1"), 1)
     self.assertEqual(NumberParser.any_int(1), 1)
     self.assertEqual(NumberParser.any_int("123456"), 123456)
     self.assertEqual(NumberParser.any_int(123456), 123456)
 
+  def test_parse_any_int_strict(self):
+    self.assertEqual(NumberParser.any_int(float(0), parse_str=False), 0)
+    self.assertEqual(NumberParser.any_int(1, parse_str=False), 1)
+
   def test_parse_any_int_invalid(self):
-    for invalid in ("", "-1.2", "1.2", "100.001", "Nan", "inf", "-inf",
-                    "invalid"):
+    for invalid in ("", "-1.2", -1.2, "1.2", 1.2, "100.001", 100.001, "Nan",
+                    math.nan, "inf", math.inf, "-inf", -math.inf, "invalid",
+                    None):
       with self.assertRaises(argparse.ArgumentTypeError):
         _ = NumberParser.any_int(invalid)
 
+  def test_parse_any_int_invalid_strict(self):
+    for invalid in ("", "-1.2", -1.2, "1.2", 1.2, "100.001", 100.001, "Nan",
+                    math.nan, "inf", math.inf, "-inf", -math.inf, "invalid",
+                    None):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        _ = NumberParser.any_int(invalid, parse_str=False)
+
   def test_parse_positive_int(self):
     self.assertEqual(NumberParser.positive_int("1"), 1)
+    self.assertEqual(NumberParser.positive_int(1), 1)
     self.assertEqual(NumberParser.positive_int("123"), 123)
-
-  def test_parse_positive_int_ivalid(self):
-    for invalid in ("", "0", "-1", "-1.2", "1.2", "Nan", "inf", "-inf",
-                    "invalid"):
-      with self.assertRaises(argparse.ArgumentTypeError):
+    self.assertEqual(NumberParser.positive_int(123), 123)
+
+  def test_parse_positive_int_invalid(self):
+    for invalid in ("", "0", 0, "-1", -1, "-1.2", -1.2, "1.2", 1.2, "Nan",
+                    math.nan, "inf", math.inf, "-inf", -math.inf, "invalid",
+                    None):
+      with self.assertRaises(
+          argparse.ArgumentTypeError, msg=f"invalid={repr(invalid)}"):
         _ = NumberParser.positive_int(invalid)
 
+  def test_parse_int_range(self):
+    self.assertEqual(NumberParser.int_range(min=0, max=10)("1"), 1)
+    self.assertEqual(NumberParser.int_range(min=0, max=10)(1), 1)
+    self.assertEqual(NumberParser.int_range(min=0, max=200)("123"), 123)
+    self.assertEqual(NumberParser.int_range(min=0, max=200)(123), 123)
+    self.assertEqual(NumberParser.int_range(min=-100, max=200)("-12"), -12)
+    self.assertEqual(NumberParser.int_range(min=-100, max=200)(-12), -12)
+
+  def test_parse_int_range_invalid(self):
+    with self.assertRaises(AssertionError):
+      NumberParser.int_range(1, 1)
+    with self.assertRaises(AssertionError):
+      NumberParser.int_range(10, 1)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      NumberParser.int_range(-1, 10)(-2)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      NumberParser.int_range(-1, 10)(11)
+
+  def test_parse_positive_int_invalid_strict(self):
+    for invalid in ("", "0", 0, "1", "-1", -1, float(-1), "-1.2", -1.2, "1.2",
+                    1.2, "Nan", math.nan, "inf", math.inf, "-inf", -math.inf,
+                    "invalid", None):
+      with self.assertRaises(
+          argparse.ArgumentTypeError, msg=f"invalid={repr(invalid)}"):
+        _ = NumberParser.positive_int(invalid, parse_str=False)
+
   def test_parse_positive_zero_int(self):
     self.assertEqual(NumberParser.positive_zero_int("1"), 1)
+    self.assertEqual(NumberParser.positive_zero_int(1), 1)
+    self.assertEqual(NumberParser.positive_zero_int(float(1)), 1)
     self.assertEqual(NumberParser.positive_zero_int("0"), 0)
+    self.assertEqual(NumberParser.positive_zero_int(0), 0)
 
   def test_parse_positive_zero_int_invalid(self):
-    for invalid in ("", "-1", "-1.2", "1.2", "NaN", "inf", "-inf", "invalid"):
-      with self.assertRaises(argparse.ArgumentTypeError):
+    for invalid in ("", "-1", -1, "-1.2", -1.2, "1.2", 1.2, "NaN", math.nan,
+                    "inf", math.inf, "-inf", -math.inf, "invalid", None):
+      with self.assertRaises(
+          argparse.ArgumentTypeError, msg=f"invalid={repr(invalid)}"):
         _ = NumberParser.positive_zero_int(invalid)
 
   def test_parse_any_float(self):
@@ -222,11 +296,35 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
     self.assertEqual(NumberParser.positive_zero_float("0.0"), 0.0)
     self.assertEqual(NumberParser.positive_zero_float("1.23"), 1.23)
 
-  def test_parse_positive_zero_float_invlid(self):
+  def test_parse_positive_zero_float_invalid(self):
     for invalid in ("", "-1", "-1.2", "NaN", "inf", "-inf", "invalid"):
       with self.assertRaises(argparse.ArgumentTypeError):
         _ = NumberParser.positive_zero_float(invalid)
 
+  def test_parse_float_range(self):
+    self.assertEqual(NumberParser.float_range(min=1, max=2)("1"), 1.0)
+    self.assertEqual(NumberParser.float_range(min=0, max=1)(1), 1.0)
+    self.assertEqual(NumberParser.float_range(min=0, max=1)("0"), 0.0)
+    self.assertEqual(NumberParser.float_range(min=0, max=1)(0), 0.0)
+    self.assertEqual(NumberParser.float_range(min=0, max=1)("0.0"), 0.0)
+    self.assertEqual(NumberParser.float_range(min=0, max=1)(0.0), 0.0)
+    self.assertEqual(NumberParser.float_range(min=0, max=11)("1.23"), 1.23)
+    self.assertEqual(NumberParser.float_range(min=0, max=11)(1.23), 1.23)
+    self.assertEqual(NumberParser.float_range(min=-2, max=11)("-1.1"), -1.1)
+    self.assertEqual(NumberParser.float_range(min=-2, max=11)(-1.1), -1.1)
+
+  def test_parse_float_range_invalid(self):
+    with self.assertRaises(AssertionError):
+      NumberParser.float_range(1, 1)
+    with self.assertRaises(AssertionError):
+      NumberParser.float_range(10, 1.0)
+    with self.assertRaises(AssertionError):
+      NumberParser.float_range(-10.1, -11.0)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      NumberParser.int_range(-1.1, 10.1)(-1.2)
+    with self.assertRaises(argparse.ArgumentTypeError):
+      NumberParser.int_range(-1.1, 10.1)(10.2)
+
   def test_parse_port_number(self):
     self.assertEqual(NumberParser.port_number(1), 1)
     self.assertEqual(NumberParser.port_number("1"), 1)
@@ -373,6 +471,34 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
     file.touch()
     self.assertEqual(file, PathParser.path(file))
 
+  def test_parse_any_path_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PathParser.any_path("")
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PathParser.any_path(None)
+
+  def test_parse_any_path(self):
+    folder = pathlib.Path("folder")
+    folder_pure = pathlib.PurePath(folder)
+    self.assertEqual(folder_pure, PathParser.any_path(folder))
+    folder.mkdir()
+    self.assertEqual(folder_pure, PathParser.any_path(folder))
+    file = pathlib.Path("file")
+    file_pure = pathlib.PurePath(file)
+    self.assertEqual(file_pure, PathParser.any_path(file))
+    file.touch()
+    self.assertEqual(file_pure, PathParser.any_path(file))
+
+  def test_parse_optional_any_path_invalid(self):
+    with self.assertRaises(argparse.ArgumentTypeError):
+      PathParser.optional_any_path("")
+
+  def test_parse_optional_any_path(self):
+    self.assertIsNone(PathParser.optional_any_path(None))
+    folder = pathlib.Path("folder")
+    folder_pure = pathlib.PurePath(folder)
+    self.assertEqual(folder_pure, PathParser.optional_any_path(folder))
+
   def test_parse_bool_success(self):
     self.assertIs(ObjectParser.bool("true"), True)
     self.assertIs(ObjectParser.bool("True"), True)
@@ -381,10 +507,36 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
     self.assertIs(ObjectParser.bool("False"), False)
     self.assertIs(ObjectParser.bool(False), False)
 
+  def test_parse_bool_success_strict(self):
+    self.assertIs(ObjectParser.bool(True, strict=True), True)
+    self.assertIs(ObjectParser.bool(False, strict=True), False)
+
   def test_parse_bool_invalid(self):
     for invalid in (1, 0, "1", "0", "", None, [], tuple()):
       with self.assertRaises(argparse.ArgumentTypeError):
         ObjectParser.bool(invalid)
+        ObjectParser.bool(invalid, strict=True)
+
+  def test_parse_bool_invalid_strict(self):
+    for invalid in (None, "False", "false", "True", "true"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        ObjectParser.bool(invalid, strict=True)
+
+  def test_parse_optional_bool(self):
+    self.assertIsNone(ObjectParser.optional_bool(None))
+    self.assertIs(ObjectParser.optional_bool("true"), True)
+    self.assertIs(ObjectParser.optional_bool("false"), False)
+
+  def test_parse_optional_bool_invalid(self):
+    for invalid in (1, 0, "1", "0", "", [], tuple()):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        ObjectParser.optional_bool(invalid)
+        ObjectParser.optional_bool(invalid, strict=True)
+
+  def test_parse_optional_bool_invalid_strict(self):
+    for invalid in ("False", "false", "True", "true"):
+      with self.assertRaises(argparse.ArgumentTypeError):
+        ObjectParser.optional_bool(invalid, strict=True)
 
   def test_parse_sh_cmd(self):
     self.assertListEqual(ObjectParser.sh_cmd("ls -al ."), ["ls", "-al", "."])
@@ -491,11 +643,13 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
         ("localhost:8123/77/", "https://localhost:8123/77/"),
         ("localhost:8123/bar", "https://localhost:8123/bar"),
         ("localhost:8123/bar?x=1", "https://localhost:8123/bar?x=1"),
+        ("data:text/html,this is some data",
+         "data:text/html,this is some data"),
     )
     for url, result in expected:
       with self.subTest(url=url):
-        self.assertEqual(ObjectParser.parse_fuzzy_url_str(url), result)
-        parsed = ObjectParser.parse_fuzzy_url(url)
+        self.assertEqual(ObjectParser.fuzzy_url_str(url), result)
+        parsed = ObjectParser.fuzzy_url(url)
         self.assertEqual(urlparse.urlunparse(parsed), result)
 
   def test_parse_fuzzy_url_default_scheme(self):
@@ -506,14 +660,14 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
     for url in expected:
       with self.subTest(url=url):
         result_default = f"https://{url}"
-        self.assertEqual(ObjectParser.parse_fuzzy_url_str(url), result_default)
-        parsed = ObjectParser.parse_fuzzy_url(url)
+        self.assertEqual(ObjectParser.fuzzy_url_str(url), result_default)
+        parsed = ObjectParser.fuzzy_url(url)
         self.assertEqual(urlparse.urlunparse(parsed), result_default)
         result_custom = f"ftp://{url}"
         self.assertEqual(
-            ObjectParser.parse_fuzzy_url_str(url, default_scheme="ftp"),
+            ObjectParser.fuzzy_url_str(url, default_scheme="ftp"),
             result_custom)
-        parsed = ObjectParser.parse_fuzzy_url(url, default_scheme="ftp")
+        parsed = ObjectParser.fuzzy_url(url, default_scheme="ftp")
         self.assertEqual(urlparse.urlunparse(parsed), result_custom)
 
   def test_parse_url(self):
@@ -534,14 +688,16 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
         ("https://localhost:8123/", "https://localhost:8123/"),
         ("http://localhost:8123/bar", "http://localhost:8123/bar"),
         ("https://localhost:8123/bar?x=1", "https://localhost:8123/bar?x=1"),
+        ("data:text/html,this is some data",
+         "data:text/html,this is some data"),
     )
     for url, result in expected:
       with self.subTest(url=url):
         self.assertEqual(ObjectParser.url_str(url), result)
-        self.assertEqual(ObjectParser.parse_fuzzy_url_str(url), result)
+        self.assertEqual(ObjectParser.fuzzy_url_str(url), result)
         parsed = ObjectParser.url(url)
         self.assertEqual(urlparse.urlunparse(parsed), result)
-        parsed_fuzzy = ObjectParser.parse_fuzzy_url(url)
+        parsed_fuzzy = ObjectParser.fuzzy_url(url)
         self.assertEqual(urlparse.urlunparse(parsed_fuzzy), result)
 
   def test_parse_url_invalid(self):
@@ -555,9 +711,9 @@ class ObjectParserHelperTestCase(CrossbenchFakeFsTestCase):
         with self.assertRaises(argparse.ArgumentTypeError):
           _ = ObjectParser.httpx_url_str(invalid)
         with self.assertRaises(argparse.ArgumentTypeError):
-          _ = ObjectParser.parse_fuzzy_url_str(invalid)
+          _ = ObjectParser.fuzzy_url_str(invalid)
         with self.assertRaises(argparse.ArgumentTypeError):
-          _ = ObjectParser.parse_fuzzy_url(invalid)
+          _ = ObjectParser.fuzzy_url(invalid)
 
   def test_parse_httpx_url_str_invalid(self):
     for invalid in ("ftp://foo.com:123/bar", "ssh://test.com"):
diff --git a/tests/crossbench/test_results_db.py b/tests/crossbench/test_results_db.py
new file mode 100644
index 00000000..f46f0153
--- /dev/null
+++ b/tests/crossbench/test_results_db.py
@@ -0,0 +1,118 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import contextlib
+import pathlib
+import tempfile
+import unittest
+from unittest import mock
+
+from sqlalchemy.exc import IntegrityError
+
+from crossbench import plt
+from crossbench.results_db.db import ResultsDB
+from crossbench.results_db.records.browser import BrowserRecord
+from crossbench.results_db.records.platform import PlatformRecord
+from crossbench.results_db.records.run import RunRecord
+from tests import test_helper
+from tests.crossbench.base import BaseCrossbenchTestCase
+
+
+class OpenResultDBMixin:
+
+  @contextlib.contextmanager
+  def open_results_db(self, in_memory: bool = False):
+    with tempfile.TemporaryDirectory() as tmp_dir:
+      if in_memory:
+        db = ResultsDB()
+      else:
+        db_file = pathlib.Path(tmp_dir) / "results.db"
+        db = ResultsDB(db_file)
+      yield db
+
+
+class ResultsDBTestCase(OpenResultDBMixin, unittest.TestCase):
+
+  def test_init_in_memory(self):
+    db = ResultsDB()
+    self.assertTrue(db.is_in_memory)
+    with self.assertRaises(RuntimeError):
+      _ = db.db_file
+
+  def test_init_in_file(self):
+    with self.open_results_db() as db:
+      self.assertTrue(db.db_file.exists())
+
+  def test_add_platforms(self):
+    with self.open_results_db() as db:
+      with db.session() as session:
+        self.assertEqual(session.query(PlatformRecord).count(), 0)
+      db.add_platforms([plt.PLATFORM])
+      with db.session() as session:
+        self.assertEqual(session.query(PlatformRecord).count(), 1)
+
+  def test_add_platforms_in_memory(self):
+    with self.open_results_db(in_memory=True) as db:
+      with db.session() as session:
+        self.assertEqual(session.query(PlatformRecord).count(), 0)
+      db.add_platforms([plt.PLATFORM])
+      with db.session() as session:
+        self.assertEqual(session.query(PlatformRecord).count(), 1)
+
+
+class ResultDBMockTestCase(OpenResultDBMixin, BaseCrossbenchTestCase):
+
+  def test_add_browser(self):
+    with self.open_results_db(in_memory=True) as db:
+      with self.assertRaisesRegex(IntegrityError, "platform"):
+        db.add_browsers(self.browsers)
+      with db.session() as session:
+        self.assertEqual(session.query(BrowserRecord).count(), 0)
+      db.add_platforms([browser.platform for browser in self.browsers])
+      db.add_browsers(self.browsers)
+      with db.session() as session:
+        self.assertEqual(session.query(BrowserRecord).count(), 2)
+
+  def test_setup_runs(self):
+    mock_story = mock.Mock()
+    mock_story.name = "story_a"
+    mock_runs = [
+        mock.Mock(
+            index=0,
+            repetition=0,
+            temperature="cold",
+            story=mock_story,
+            browser=self.browsers[0],
+            browser_platform=self.browsers[0].platform),
+        mock.Mock(
+            index=1,
+            repetition=0,
+            temperature="cold",
+            story=mock_story,
+            browser=self.browsers[1],
+            browser_platform=self.browsers[1].platform),
+    ]
+    mock_runs[0].name = "run_0_story_a"
+    mock_runs[1].name = "run_1_story_a"
+    with self.open_results_db(in_memory=True) as db:
+      db.setup_runs(mock_runs)
+      with db.session() as session:
+        self.assertEqual(session.query(RunRecord).count(), 2)
+      with db.session() as session:
+        run_0 = session.query(RunRecord).filter_by(index=0).one()
+        run_1 = session.query(RunRecord).filter_by(index=1).one()
+        self.assertEqual(run_0.name, "run_0_story_a")
+        self.assertEqual(run_1.name, "run_1_story_a")
+        self.assertEqual(run_0.browser.label, self.browsers[0].label)
+        self.assertEqual(run_1.browser.label, self.browsers[1].label)
+        self.assertEqual(run_0.browser.platform.label,
+                         str(self.browsers[0].platform))
+        self.assertEqual(run_1.browser.platform.label,
+                         str(self.browsers[1].platform))
+      with self.assertRaises(IntegrityError):
+        db.setup_runs(mock_runs)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/conftest.py b/tests/end2end/android/conftest.py
new file mode 100644
index 00000000..a5bb569e
--- /dev/null
+++ b/tests/end2end/android/conftest.py
@@ -0,0 +1,35 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+
+import pytest
+
+from crossbench.plt import PLATFORM
+from crossbench.plt.android_adb import Adb
+
+
+@pytest.fixture
+def adb_root(device_id, adb_path):
+  adb = Adb(PLATFORM, device_id, adb_path)
+  if adb.has_root():
+    yield
+  else:
+    adb.root()
+    yield
+    adb.unroot()
+
+
+@pytest.fixture
+def browser_config(device_id, adb_path) -> str:
+  return json.dumps({
+      "browser": "chrome",
+      "driver": {
+          "type": "adb",
+          "device_id": device_id,
+          "adb_bin": adb_path
+      }
+  })
diff --git a/tests/end2end/android/runner.py b/tests/end2end/android/runner.py
new file mode 100644
index 00000000..da9054c2
--- /dev/null
+++ b/tests/end2end/android/runner.py
@@ -0,0 +1,37 @@
+#!/usr/bin/env vpython3
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pathlib
+import sys
+
+import pytest
+
+FILE_PATH = pathlib.Path(__file__).absolute()
+TEST_DIR = FILE_PATH.absolute().parent
+REPO_DIR = FILE_PATH.absolute().parents[3]
+
+if REPO_DIR not in sys.path:
+  sys.path.insert(0, str(REPO_DIR))
+
+if __name__ == "__main__":
+  pass_through_args = sys.argv[1:]
+  return_code = pytest.main([
+      "--verbose", "--dist=no", "--numprocesses=1", "--log-cli-level=DEBUG",
+      "-o", "log_cli=True", "-rs",
+      str(TEST_DIR), *pass_through_args
+  ])
+
+  # Retry failed tests once
+  if return_code > 0:
+    return_code = pytest.main([
+        "--verbose", "--dist=no", "--numprocesses=1", "--log-cli-level=DEBUG",
+        "-o", "log_cli=True", "-rs", "--last-failed",
+        "--last-failed-no-failures=none",
+        str(TEST_DIR), *pass_through_args
+    ])
+
+  sys.exit(return_code)
diff --git a/tests/end2end/android/test_debug.py b/tests/end2end/android/test_debug.py
new file mode 100644
index 00000000..e60827d1
--- /dev/null
+++ b/tests/end2end/android/test_debug.py
@@ -0,0 +1,29 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+
+from crossbench.cli.cli import CrossBenchCLI
+from tests import test_helper
+
+
+def test_debug(browser_config, test_env) -> None:
+  cli = CrossBenchCLI()
+  cli.run([
+      "loading", "--url=blank", f"--browser={browser_config}", "--debug",
+      f"--out-dir={test_env.results_dir}"
+  ] + list(test_env.cq_flags))
+
+  result_files = list(test_env.results_dir.glob("cb.results.json"))
+  assert len(result_files) == 1
+  with result_files[0].open() as f:
+    result = json.load(f)
+    assert result["success"]
+    assert not result["errors"]
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_loading.py b/tests/end2end/android/test_loading.py
new file mode 100644
index 00000000..8693595f
--- /dev/null
+++ b/tests/end2end/android/test_loading.py
@@ -0,0 +1,222 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+import pathlib
+import tempfile
+from typing import Any, Optional
+import urllib.parse
+
+import pytest
+
+from crossbench.benchmarks.loading.input_source import InputSource
+from crossbench.cli.cli import CrossBenchCLI
+from tests import test_helper
+
+
+def _run_loading_test(browser_config: str,
+                      page_config: Any,
+                      test_env: Any,
+                      probe_config_file: Optional[pathlib.Path] = None) -> None:
+  with tempfile.NamedTemporaryFile(
+      mode="w", encoding="utf-8") as page_config_file:
+    json.dump(page_config, page_config_file)
+    page_config_file.flush()
+
+    cli = CrossBenchCLI()
+
+    args = [
+        "loading", f"--browser={browser_config}",
+        f"--page-config={page_config_file.name}", "--action-runner=android"
+    ] + list(test_env.cq_flags)
+
+    if probe_config_file:
+      args.append(f"--probe-config={probe_config_file}")
+
+    cli.run(args)
+
+
+def _run_loading_test_with_probes(browser_config: str, page_config: Any,
+                                  test_env: Any, probe_config: Any) -> None:
+  with tempfile.NamedTemporaryFile(
+      mode="w", encoding="utf-8") as probe_config_file:
+    json.dump(probe_config, probe_config_file)
+    probe_config_file.flush()
+
+    _run_loading_test(browser_config, page_config, test_env,
+                      pathlib.Path(probe_config_file.name))
+
+@pytest.mark.parametrize("input_source", InputSource)
+def test_click(browser_config, input_source, test_env) -> None:
+
+  if input_source is InputSource.KEYBOARD:
+    return
+
+  test_page = urllib.parse.quote("""
+<!DOCTYPE html>
+<html>
+<body>
+  <button id="button">Click me</button>
+  <script>
+    const button = document.getElementById('button');
+
+    button.addEventListener('click',
+    function() {
+      button.id = "clicked-button";
+    });
+  </script>
+</body>
+</html>
+""")
+
+  page_config = {
+      "pages": {
+          "ClickTest": {
+              "actions": [
+                  {
+                      "action": "get",
+                      "url": f"data:text/html;charset=utf-8,{test_page}",
+                      "ready_state": "complete",
+                  },
+                  {
+                      "action": "click",
+                      "position": {
+                          "selector": "button[id='button']",
+                          "required": True,
+                          "scroll_into_view": True,
+                          "wait": True,
+                      },
+                      "verify": "button[id='clicked-button']",
+                      "source": str(input_source),
+                  },
+              ]
+          }
+      }
+  }
+
+  _run_loading_test(browser_config, page_config, test_env)
+
+
+def test_scroll(browser_config, test_env) -> None:
+
+  test_page = urllib.parse.quote("""
+<!DOCTYPE html>
+<html>
+<head>
+  <title>Scroll Test</title>
+  <style>
+    #scrollable-area {
+      height: 200px;
+      overflow-y: auto;
+    }
+    #content {
+      height: 500px;
+    }
+  </style>
+</head>
+<body>
+  <div id="no-scroll"></div>
+  <div id="scrollable-area">
+    <div id="content">
+    </div>
+  </div>
+  <script>
+    const scrollableArea = document.getElementById('scrollable-area');
+    scrollableArea.addEventListener('scroll', function() {
+      document.getElementById('no-scroll').id = 'yes-scroll';
+    });
+  </script>
+</body>
+</html>
+""")
+
+  page_config = {
+      "pages": {
+          "ClickTest": {
+              "actions": [
+                  {
+                      "action": "get",
+                      "url": f"data:text/html;charset=utf-8,{test_page}",
+                      "ready_state": "complete"
+                  },
+                  {
+                      "action": "wait_for_element",
+                      "selector": "div[id='scrollable-area']",
+                      "timeout": "10s"
+                  },
+                  {
+                      "action": "scroll",
+                      "selector": "div[id='scrollable-area']",
+                      "required": True,
+                      "source": "touch",
+                      "distance": 50,
+                  },
+                  {
+                      "action": "wait_for_element",
+                      "selector": "div[id='yes-scroll']",
+                      "timeout": "1s"
+                  },
+              ]
+          }
+      }
+  }
+
+  _run_loading_test(browser_config, page_config, test_env)
+
+
+def test_download(browser_config, test_env):
+  test_page = urllib.parse.quote("""
+<!doctype html>
+<html>
+  <head>
+    <meta charset="utf-8" />
+    <title>Download Test</title>
+  </head>
+  <body>
+    <a
+      id="download"
+      href="data:text/plain;charset=utf-8,A Car"
+      download="car.txt">
+      Download
+    </a>
+  </body>
+</html>
+""")
+
+  page_config = {
+      "pages": {
+          "DownloadTest": {
+              "actions": [{
+                  "action": "get",
+                  "url": f"data:text/html;charset=utf-8,{test_page}",
+                  "ready_state": "complete"
+              }, {
+                  "action": "click",
+                  "position": "#download",
+              }, {
+                  "action": "wait_for_download",
+                  "timeout": "10s",
+                  "pattern": "car.txt"
+              }]
+          }
+      }
+  }
+
+  probe_config = {
+      "probes": {
+          "downloads": {
+              "clear_downloads": True,
+              "save_downloads": True
+          }
+      }
+  }
+
+  _run_loading_test_with_probes(browser_config, page_config, test_env,
+                                probe_config)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_loadline.py b/tests/end2end/android/test_loadline.py
new file mode 100644
index 00000000..e088f861
--- /dev/null
+++ b/tests/end2end/android/test_loadline.py
@@ -0,0 +1,181 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import enum
+import json
+import logging
+
+import pytest
+
+from crossbench.browsers.chrome.version import ChromeVersion
+from crossbench.cli.cli import CrossBenchCLI
+from crossbench.network.replay.wpr import WPR_PREBUILT_LOOKUP
+from crossbench.path import check_hash
+from crossbench.plt import PLATFORM
+from crossbench.plt.android_adb import Adb, AndroidAdbPlatform
+from tests import test_helper
+from tests.test_helper import TestEnv
+
+# pytest.fixtures rely on params having the same name as the fixture function
+# pylint: disable=redefined-outer-name
+
+CHROME_APK_URL = "gs://chrome-telemetry/apks/MonochromeCanary.apk"
+CHROME_APK_HASH = "5de59881c02783d2174e1e891d82c9dbbce09c67"
+
+MIN_VERSION = ChromeVersion.any((130,))
+
+
+@pytest.fixture(autouse=True)
+def adb_test_env(device_id, adb_path, test_env: TestEnv) -> None:
+  tmp_dir = test_env.output_dir / "tmp_dir"
+  assert not tmp_dir.exists()
+
+  adb = Adb(PLATFORM, device_id, adb_path)
+  adb_platform = AndroidAdbPlatform(PLATFORM, adb=adb)
+
+  installed_version_str = adb_platform.app_version("com.android.chrome")
+  installed_version = ChromeVersion.parse(installed_version_str)
+  if installed_version >= MIN_VERSION:
+    logging.info("Using pre-installed chrome version %s", installed_version)
+  else:
+    # Download and install chrome-canary M130 (x64 arch) from the cloud.
+    # The benchmark requires trace events that were introduced in M126.
+    # TODO(crbug/377290309): Remove this workaround when chrome preinstalled
+    # in the emulator image is >=M126.
+    local_apk = tmp_dir / "chrome.apk"
+    PLATFORM.sh("gsutil", "cp", CHROME_APK_URL, local_apk, check=True)
+    assert check_hash(local_apk, CHROME_APK_HASH)
+
+    assert adb_path, "Missing adb"
+    assert device_id, "Missing device id"
+    adb = Adb(PLATFORM, device_id, adb_path)
+    adb.install_apk(local_apk)
+
+  # Download prebuilt wprgo binary to run WPR on the host
+  # TODO(crbug/377290309): Make the test work with on-device WPR.
+  local_wpr = tmp_dir / "wprgo"
+  wpr_cloud_binary = WPR_PREBUILT_LOOKUP[PLATFORM.key]
+  PLATFORM.sh("gsutil", "cp", wpr_cloud_binary.url, local_wpr)
+  assert check_hash(local_wpr, wpr_cloud_binary.file_hash)
+  PLATFORM.sh("chmod", "+x", local_wpr)
+
+
+# TODO(crbug/377290309): Remove the custom browser config when the test passes
+# with the preinstalled browser.
+def _browser_config(device_id, adb_path) -> str:
+  return json.dumps({
+      "browser": "chrome-canary",
+      "driver": {
+          "type": "adb",
+          "device_id": device_id,
+          "adb_bin": adb_path
+      }
+  })
+
+
+def _batch_trace_process_config() -> str:
+  return json.dumps({
+      "queries": ["loadline/benchmark_score"],
+      "batch": True,
+  })
+
+
+class BenchmarkType(enum.StrEnum):
+  PHONE = "loadline-phone"
+  TABLET = "loadline-tablet"
+
+
+def _verify_default_metrics(out_dir, only_total=False):
+  result_csv = out_dir / "loadline_probe.csv"
+  with result_csv.open() as csv:
+    lines = csv.readlines()
+    assert len(lines) == 2
+
+    titles = lines[0].split(",")
+    assert len(titles) == 7
+    assert titles[0] == "browser"
+    assert titles[1] == "TOTAL_SCORE"
+
+    values = lines[1].split(",")
+    assert len(values) == 7
+    values_to_check = values[1:2] if only_total else values[1:]
+    for value in values_to_check:
+      assert value, f"Encountered empty value. CSV contents: {lines}"
+      assert float(value) > 0, f"Expected positive number, but got {value}"
+
+
+def _verify_experimental_metrics(out_dir):
+  expected_files = {
+      "loadline_benchmark_score.csv",
+      "loadline_experimental_interaction_latency.csv",
+      "loadline_experimental_sequence_manager.csv",
+      "loadline_experimental_v8_rcs.csv", "loadline_experimental_cpu.csv",
+      "loadline_experimental_mojo.csv", "loadline_experimental_tlp.csv",
+      "loadline_experimental_web_features.csv", "loadline_experimental_dom.csv",
+      "loadline_experimental_resources.csv", "loadline_experimental_v8.csv",
+      "loadline_experimental_worker.csv"
+  }
+  tp_output_files = list(out_dir.rglob("trace_processor/*.csv"))
+  assert set(f.name for f in tp_output_files) == expected_files
+
+  # Some metrics for some runs might have no values. But we expect at
+  # least one metric to have some values.
+  has_metric_values = False
+  for f in tp_output_files:
+    with f.open() as output_file:
+      lines = output_file.readlines()
+      assert len(lines) >= 1
+      if len(lines) >= 2:
+        has_metric_values = True
+      num_columns = len(lines[0].split(","))
+      assert num_columns > 0
+
+  assert has_metric_values
+
+
+@pytest.mark.parametrize("benchmark_type", BenchmarkType)
+def test_loadline_default(device_id, adb_path, benchmark_type,
+                          test_env: TestEnv) -> None:
+  cli = CrossBenchCLI()
+  browser_config = _browser_config(device_id, adb_path)
+  out_dir = test_env.results_dir / f"default_{benchmark_type}"
+  cli.run([
+      benchmark_type, f"--browser={browser_config}", "--repeat=1", "--throw",
+      f"--out-dir={out_dir}", "--debug"
+  ] + list(test_env.cq_flags))
+  # With only 1 repetition, there's a chance that one story won't produce a
+  # metric. To avoid flaky failures, we only check the total score here.
+  _verify_default_metrics(out_dir, only_total=True)
+
+
+def test_loadline_experimental(device_id, adb_path, test_env: TestEnv) -> None:
+  cli = CrossBenchCLI()
+  browser_config = _browser_config(device_id, adb_path)
+  out_dir = test_env.results_dir
+  probe_config = (
+      test_env.root_dir /
+      "config/benchmark/loadline/probe_config_experimental.hjson")
+  cli.run([
+      BenchmarkType.PHONE, f"--browser={browser_config}", "--repeat=1",
+      "--throw", f"--out-dir={out_dir}", f"--probe-config={probe_config}"
+  ] + list(test_env.cq_flags))
+  _verify_experimental_metrics(out_dir)
+
+
+def test_loadline_batch(device_id, adb_path, test_env: TestEnv) -> None:
+  cli = CrossBenchCLI()
+  browser_config = _browser_config(device_id, adb_path)
+  out_dir = test_env.results_dir
+  cli.run([
+      BenchmarkType.PHONE, f"--browser={browser_config}", "--repeat=2",
+      "--throw", f"--out-dir={out_dir}",
+      f"--probe=trace_processor:{_batch_trace_process_config()}"
+  ] + list(test_env.cq_flags))
+  _verify_default_metrics(out_dir)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_logcat.py b/tests/end2end/android/test_logcat.py
new file mode 100644
index 00000000..a83fe40b
--- /dev/null
+++ b/tests/end2end/android/test_logcat.py
@@ -0,0 +1,36 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+
+from crossbench.cli.cli import CrossBenchCLI
+from tests import test_helper
+
+
+def _logcat_config() -> str:
+  return json.dumps({"filterspec": "ActivityManager:V *:S"})
+
+
+def test_logcat(browser_config, test_env) -> None:
+  cli = CrossBenchCLI()
+  cli.run([
+      "loading", "--url=blank", f"--browser={browser_config}",
+      f"--probe=logcat:{_logcat_config()}", "--throw",
+      f"--out-dir={test_env.results_dir}"
+  ] + list(test_env.cq_flags))
+
+  logcat_files = list(test_env.results_dir.rglob("logcat.txt"))
+  assert len(logcat_files) == 1
+  with logcat_files[0].open() as logcat_file:
+    lines = logcat_file.readlines()
+    assert len(lines) > 1
+    assert "--------- beginning of system" in lines[0]
+    for line in lines[1:]:
+      assert "ActivityManager" in line
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_platform.py b/tests/end2end/android/test_platform.py
new file mode 100644
index 00000000..6b95f040
--- /dev/null
+++ b/tests/end2end/android/test_platform.py
@@ -0,0 +1,85 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pytest
+
+from crossbench import plt
+from crossbench.plt.android_adb import Adb, AndroidAdbPlatform
+from crossbench.plt.remote import RemotePopen
+from tests import test_helper
+from tests.crossbench.plt.test_native_platform import \
+    PosixNativePlatformTestCase
+
+
+@pytest.fixture(scope="class")
+def adb_unittest_fixtures(request, device_id, adb_path):
+  request.cls.device_id = device_id
+  request.cls.adb_path = adb_path
+
+
+@pytest.mark.usefixtures("adb_unittest_fixtures")
+class AndroidAdbPlatformTestCase(PosixNativePlatformTestCase):
+
+  def setUp(self):
+    super().setUp()
+    assert hasattr(self, "device_id")
+    assert hasattr(self, "adb_path")
+    self.adb = Adb(plt.PLATFORM, self.device_id, self.adb_path)
+    self.host_platform = plt.PLATFORM
+    self.platform: AndroidAdbPlatform = AndroidAdbPlatform(
+        self.host_platform, adb=self.adb)
+    assert self.platform.is_android
+    self.known_binary = "dumpsys"
+
+  def test_app_version(self):
+    with self.assertRaises(ValueError):
+      self.platform.app_version("path/to/invalid/test/crossbench/bin")
+    version = self.platform.app_version("com.android.chrome")
+    self.assertTrue(version)
+
+  def test_is_battery_powered(self):
+    self.assertIs(self.platform.is_battery_powered, False)
+
+  def test_home(self):
+    if self.adb.has_root():
+      self.assertTrue(self.platform.is_dir(self.platform.home()))
+
+  def test_cpu_usage(self):
+    self.skipTest("Not supported yet")
+
+  def test_remote_popen(self):
+    popen = None
+    try:
+      popen = self.platform.popen("watch", "ls")
+      self.assertIsInstance(popen, RemotePopen)
+      self.assertTrue(popen.remote_pid)
+      self.assertTrue(popen.pid)
+      process_info = self.platform.process_info(popen.remote_pid)
+      self.assertTrue(process_info)
+      self.assertTrue(self.host_platform.process_info(popen.pid))
+    finally:
+      popen.kill()
+      self.assertIsNone(self.platform.process_info(popen.remote_pid))
+
+  def test_display_resolution(self):
+    [x, y] = self.platform.display_resolution()
+    # We don't know the display resolution of the test device, but we can check
+    # that it doesn't raise and that is has some size.
+    self.assertGreater(x, 0)
+    self.assertGreater(y, 0)
+
+  def test_user_id(self):
+    self.assertGreaterEqual(self.platform.user_id(), 0)
+
+  def test_android_system_details(self):
+    details = self.platform.system_details()
+    self.assertIn("Android", details)
+
+
+del PosixNativePlatformTestCase
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_profiling.py b/tests/end2end/android/test_profiling.py
new file mode 100644
index 00000000..cf282c59
--- /dev/null
+++ b/tests/end2end/android/test_profiling.py
@@ -0,0 +1,50 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+
+from perfetto.trace_processor.api import TraceProcessor
+
+from crossbench.cli.cli import CrossBenchCLI
+from tests import test_helper
+
+
+def _profiling_config() -> str:
+  return json.dumps({
+      "target": "renderer_main_only",
+      "pprof": False,
+      "events": ["cpu-clock"],
+      "count": 500000,
+      "add_counters": ["context-switches"]
+  })
+
+
+def test_profiling_probe(browser_config, test_env, adb_root) -> None:
+  del adb_root
+  cli = CrossBenchCLI()
+  profiling_config = _profiling_config()
+  cli.run([
+      "load", "--url=blank,2s", "--throw", f"--browser={browser_config}",
+      f"--probe=profiling{profiling_config}",
+      f"--out-dir={test_env.results_dir}"
+  ] + list(test_env.cq_flags))
+
+  simpleperf_files = list(test_env.results_dir.rglob("simpleperf.perf.data"))
+  assert len(simpleperf_files) == 1
+  assert simpleperf_files[0].is_file()
+
+  with TraceProcessor(trace=str(simpleperf_files[0])) as tp:
+    perf_sample_count = tp.query(
+        "SELECT count(*) AS cnt FROM perf_sample").as_pandas_dataframe()
+    assert perf_sample_count["cnt"][0] > 0
+    perf_counters = list(tp.query(
+        "SELECT name FROM perf_counter_track").as_pandas_dataframe()["name"])
+    assert "cpu-clock" in perf_counters
+    assert "context-switches" in perf_counters
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_screenshot.py b/tests/end2end/android/test_screenshot.py
new file mode 100644
index 00000000..4a8dbf9a
--- /dev/null
+++ b/tests/end2end/android/test_screenshot.py
@@ -0,0 +1,27 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+from crossbench.cli.cli import CrossBenchCLI
+from tests import test_helper
+
+
+def test_screenshot(browser_config, test_env) -> None:
+  cli = CrossBenchCLI()
+  cli.run([
+      "loading", "--url=blank", f"--browser={browser_config}",
+      "--probe=screenshot:{}", "--throw", f"--out-dir={test_env.results_dir}"
+  ] + list(test_env.cq_flags))
+
+  screenshots = list(test_env.results_dir.rglob("*/screenshot/*.png"))
+  assert set(f.name for f in screenshots) == {
+      "start.png", "start_story.png", "stop.png", "stop_story.png"
+  }
+  for f in screenshots:
+    assert f.stat().st_size > 0
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_speedometer.py b/tests/end2end/android/test_speedometer.py
new file mode 100644
index 00000000..ac851693
--- /dev/null
+++ b/tests/end2end/android/test_speedometer.py
@@ -0,0 +1,36 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import enum
+import pytest
+
+from crossbench.cli.cli import CrossBenchCLI
+from crossbench.parse import NumberParser
+from tests import test_helper
+from tests.test_helper import TestEnv
+
+
+class SpeedometerVersion(enum.StrEnum):
+  V2_0 = "2.0"
+  V2_1 = "2.1"
+  V3_0 = "3.0"
+
+
+@pytest.mark.parametrize("version", SpeedometerVersion)
+def test_speedometer(browser_config, version, test_env: TestEnv) -> None:
+  CrossBenchCLI().run([
+      f"sp{version}", f"--browser={browser_config}",
+      f"--out-dir={test_env.results_dir}"
+  ] + list(test_env.cq_flags))
+
+  with (test_env.results_dir / f"speedometer_{version}.csv").open() as csv:
+    lines = csv.readlines()
+    error_message = f"csv content: {lines}"
+    assert "Score" in lines[-1], error_message
+    assert NumberParser.positive_zero_float(
+        lines[-1].split("\t")[-1]) > 0, error_message
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/android/test_wpr_record_and_replay.py b/tests/end2end/android/test_wpr_record_and_replay.py
new file mode 100644
index 00000000..6ad2f833
--- /dev/null
+++ b/tests/end2end/android/test_wpr_record_and_replay.py
@@ -0,0 +1,84 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import json
+import pathlib
+import tempfile
+from typing import Iterator
+
+import pytest
+
+from crossbench.cli.cli import CrossBenchCLI
+from crossbench.network.replay.wpr import WPR_PREBUILT_LOOKUP
+from crossbench.path import check_hash
+from crossbench.plt import PLATFORM
+from tests import test_helper
+
+# pytest.fixtures rely on params having the same name as the fixture function
+# pylint: disable=redefined-outer-name
+
+
+@pytest.fixture(scope="session")
+def tmp_dir() -> Iterator[pathlib.Path]:
+  with tempfile.TemporaryDirectory() as tmp_dir_name:
+    tmp_dir = pathlib.Path(tmp_dir_name)
+    # Download prebuilt wprgo binary to run WPR on the host
+    local_wpr = tmp_dir / "wprgo"
+    wpr_cloud_binary = WPR_PREBUILT_LOOKUP[PLATFORM.key]
+    PLATFORM.sh("gsutil", "cp", wpr_cloud_binary.url, local_wpr)
+    assert check_hash(local_wpr, wpr_cloud_binary.file_hash)
+    PLATFORM.sh("chmod", "+x", local_wpr)
+
+    yield tmp_dir
+
+
+def _wpr_record_config(wpr_go_bin) -> str:
+  return json.dumps({"wpr_go_bin": str(wpr_go_bin)})
+
+
+def _network_replay_config(archive) -> str:
+  return json.dumps({
+      "type": "wpr",
+      "path": str(archive),
+      "run_on_device": True
+  })
+
+
+def test_wpr_record_and_replay(browser_config, tmp_dir, test_env) -> None:
+  cli = CrossBenchCLI()
+  result_record_dir = tmp_dir / "result_record"
+  target_url = "https://www.google.com/search?q=cats"
+  local_wpr_go = tmp_dir / "wprgo"
+  cli.run([
+      "loading", f"--url={target_url}", f"--browser={browser_config}",
+      f"--probe=wpr:{_wpr_record_config(local_wpr_go)}",
+      f"--out-dir={result_record_dir}"
+  ] + list(test_env.cq_flags))
+
+  archives = list(
+      result_record_dir.glob("*/stories/*/0/0_default/archive.wprgo"))
+  assert len(archives) == 1
+  assert archives[0].stat().st_size > 0
+
+  result_replay_dir = tmp_dir / "result_replay"
+  cli.run([
+      "loading",
+      f"--url={target_url}",
+      f"--browser={browser_config}",
+      f"--network={_network_replay_config(archives[0])}",
+      f"--out-dir={result_replay_dir}",
+  ])
+  wpr_logs = list(
+      result_replay_dir.glob("*/stories/*/0/0_default/network.wpr.log"))
+  assert len(wpr_logs) == 1
+  with wpr_logs[0].open() as wpr_log:
+    lines = wpr_log.readlines()
+    assert any(
+        f"ServeHTTP({target_url}): serving 200 response" in l for l in lines)
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/conftest.py b/tests/end2end/conftest.py
index 6824972d..3730bf78 100644
--- a/tests/end2end/conftest.py
+++ b/tests/end2end/conftest.py
@@ -4,37 +4,54 @@
 
 from __future__ import annotations
 
+import contextlib
 import logging
 import pathlib
+import re
 import sys
 import tempfile
-from typing import Optional
+from typing import Iterator, Optional
+from unittest import mock
 
+import psutil
 import pytest
+from typing_extensions import override
 
 from crossbench import plt
 from crossbench.browsers import all as browsers
+from crossbench.browsers.chrome.chrome import Chrome
+from crossbench.browsers.chromium.chromium import Chromium
+from crossbench.browsers.chromium.driver_finder import ChromeDriverFinder
+from crossbench.cli.config.browser import BrowserConfig
+from crossbench.cli.config.browser_variants import BrowserVariantsConfig
 from crossbench.parse import PathParser
 from crossbench.path import LocalPath
-from tests import test_helper
+from crossbench.plt.android_adb import adb_devices
+from crossbench.plt.bin import Binaries, BinaryNotFoundError
+from tests.test_helper import TestEnv
+
+WIN_APP_SUFFIX = [".exe", ".bat"]
 
 # pytest.fixtures rely on params having the same name as the fixture function
 # pylint: disable=redefined-outer-name
-
+ADB_DEVICE_ID_FLAG = "--adb-device-id"
+ADB_PATH_FLAG = "--adb-path"
+CAS_ARCHIVE_FLAG = "--cas-archive"
+TEST_BROWSER_FLAG = "--test-browser-path"
+TEST_DRIVER_FLAG = "--test-driver-path"
+TEST_GSUTIL_FLAG = "--test-gsutil-path"
 
 def pytest_addoption(parser):
   parser.addoption(
-      "--test-browser-path",
-      "--browserpath",
-      default=None,
-      type=PathParser.path)
+      TEST_BROWSER_FLAG, "--browserpath", default=None, type=PathParser.path)
   parser.addoption(
-      "--test-driver-path", "--driverpath", default=None, type=PathParser.path)
+      TEST_DRIVER_FLAG, "--driverpath", default=None, type=PathParser.path)
   parser.addoption(
-      "--test-gsutil-path", "--gustilpath", default=None, type=PathParser.path)
-  parser.addoption("--adb-device-id", default=None, type=str)
+      TEST_GSUTIL_FLAG, "--gsutilpath", default=None, type=PathParser.path)
+  parser.addoption(ADB_DEVICE_ID_FLAG, default=None, type=str)
   parser.addoption("--adb-path", default=None, type=str)
   parser.addoption("--ignore-tests", default=None, type=str)
+  parser.addoption(CAS_ARCHIVE_FLAG, default=None, type=str)
 
 
 def pytest_xdist_auto_num_workers(config):
@@ -46,25 +63,27 @@ def pytest_xdist_auto_num_workers(config):
 
 def _get_app_path(request, option_key) -> Optional[pathlib.Path]:
   app_path = request.config.getoption(option_key)
-  if app_path and plt.PLATFORM.is_win and app_path.suffix != ".exe":
-    return app_path.parent / (app_path.name + ".exe")
+  if app_path and plt.PLATFORM.is_win and app_path.suffix not in WIN_APP_SUFFIX:
+    if (app_path.parent / (app_path.name + ".bat")).exists():
+      return app_path.parent / (app_path.name + ".bat")
+    if (app_path.parent / (app_path.name + ".exe")).exists():
+      return app_path.parent / (app_path.name + ".exe")
   return app_path
 
 
-@pytest.fixture(scope="session", autouse=True)
+@pytest.fixture(scope="session")
 def driver_path(request) -> Optional[pathlib.Path]:
-  maybe_driver_path: Optional[LocalPath] = _get_app_path(
-      request, "--test-driver-path")
+  maybe_driver_path: LocalPath | None = _get_app_path(request, TEST_DRIVER_FLAG)
   if maybe_driver_path:
     logging.info("driver path: %s", maybe_driver_path)
     assert maybe_driver_path.exists()
   return maybe_driver_path
 
 
-@pytest.fixture(scope="session", autouse=True)
+@pytest.fixture(scope="session")
 def browser_path(request) -> Optional[pathlib.Path]:
-  maybe_browser_path: Optional[pathlib.Path] = _get_app_path(
-      request, "--test-browser-path")
+  maybe_browser_path: pathlib.Path | None = _get_app_path(
+      request, TEST_BROWSER_FLAG)
   if maybe_browser_path:
     logging.info("browser path: %s", maybe_browser_path)
     assert maybe_browser_path.exists()
@@ -78,71 +97,143 @@ def browser_path(request) -> Optional[pathlib.Path]:
     return None
 
 
-@pytest.fixture(scope="session", autouse=True)
-def gsutil_path(request) -> pathlib.Path:
-  maybe_gsutil_path: Optional[pathlib.Path] = _get_app_path(
-      request, "--test-gsutil-path")
-  if maybe_gsutil_path:
-    logging.info("gsutil path: %s", maybe_gsutil_path)
-    assert maybe_gsutil_path.exists()
-    return maybe_gsutil_path
-  logging.info("Trying default gsutil path for local runs.")
-  return default_gsutil_path()
+def is_browser_path_chromium(browser_path) -> bool:
+  # We support local/infra built chrome and chromium versions in the tests
+  # However, the rest of crossbench is fairly strict in that regard, so we
+  # manually patch the default Chrome version to match whatever flavour
+  # (chrome or chromium) we want to use.
+  if not browser_path:
+    return False
+  version_str = plt.PLATFORM.app_version(browser_path)
+  return "chromium" in version_str.lower()
 
 
-def default_gsutil_path() -> pathlib.Path:
-  if maybe_gsutil_path := plt.PLATFORM.which("gsutil"):
-    maybe_gsutil_path = plt.PLATFORM.local_path(maybe_gsutil_path)
-    assert maybe_gsutil_path, "could not find fallback gsutil"
-    assert maybe_gsutil_path.exists()
-    return maybe_gsutil_path
-  pytest.skip(f"Could not find gsutil on {plt.PLATFORM}")
-  return pathlib.Path()
+@pytest.fixture(scope="session")
+def test_chrome_name(browser_path) -> str:
+  if is_browser_path_chromium(browser_path):
+    return "chromium"
+  return "chrome-stable"
 
 
-@pytest.fixture
-def output_dir():
-  with tempfile.TemporaryDirectory() as tmpdirname:
-    yield pathlib.Path(tmpdirname)
+def session_patch_chrome_driver_finder(driver_path, browser_path):
+  if not driver_path:
+    yield
+    return
 
+  class MockChromeDriverFinder(ChromeDriverFinder):
 
-@pytest.fixture(scope="session")
-def root_dir() -> pathlib.Path:
-  return test_helper.root_dir()
+    @override
+    def download(self):
+      if self.browser.path == browser_path:
+        # The CQ uses the latest canary, which might not have a easily publicly
+        # accessible chromedriver available.
+        return driver_path
+      return super().download()
 
+  with mock.patch(
+      "crossbench.browsers.chromium_based.webdriver.ChromeDriverFinder",
+      new=MockChromeDriverFinder):
+    yield
 
-@pytest.fixture
-def cache_dir(output_dir) -> pathlib.Path:
-  path = output_dir / "cache"
-  assert not path.exists()
-  path.mkdir()
-  return path
+
+@pytest.fixture(scope="session", autouse=True)
+def session_patch_chrome_stable(browser_path):
+  if is_browser_path_chromium(browser_path):
+    with mock.patch.object(Chromium, "default_path", return_value=browser_path):
+      yield
+      return
+  with mock.patch.object(Chrome, "stable_path", return_value=browser_path):
+    yield
+
+
+@contextlib.contextmanager
+def mock_patch_chrome_stable(browser_path):
+  is_chromium = is_browser_path_chromium(browser_path)
+  original_get_browser_cls = BrowserVariantsConfig.get_browser_cls
+
+  def mock_get_browser_cls(browser_config: BrowserConfig):
+    nonlocal is_chromium
+    path_str = str(browser_config.path).lower()
+    if "chrome" not in path_str and "chromium" not in path_str:
+      return original_get_browser_cls(browser_config)
+    if is_chromium:
+      return BrowserVariantsConfig.get_chromium_browser_cls(browser_config)
+    return BrowserVariantsConfig.get_chrome_browser_cls(browser_config)
+
+  with mock.patch.object(
+      Chrome, "stable_path", return_value=browser_path), mock.patch.object(
+          BrowserVariantsConfig,
+          "get_browser_cls",
+          side_effect=mock_get_browser_cls):
+    yield
+
+
+@pytest.fixture(scope="session", autouse=True)
+def gsutil_path(request) -> Iterator[pathlib.Path]:
+  if custom_gsutil := _get_app_path(request, TEST_GSUTIL_FLAG):
+    logging.info("gsutil path: %s", custom_gsutil)
+    assert custom_gsutil.exists()
+    with plt.PLATFORM.override_binary("gsutil", custom_gsutil):
+      yield custom_gsutil
+  else:
+    logging.info("Trying default gsutil path for local runs.")
+    yield default_gsutil_path()
+
+
+def default_gsutil_path() -> pathlib.Path:
+  if gsutil_path := plt.PLATFORM.which("gsutil"):
+    gsutil_path = plt.PLATFORM.local_path(gsutil_path)
+    assert gsutil_path, "could not find fallback gsutil"
+    assert gsutil_path.exists()
+    return gsutil_path
+  pytest.skip(f"Could not find gsutil on {plt.PLATFORM}")
+  return pathlib.Path()
 
 
 @pytest.fixture
-def archive_dir(output_dir) -> pathlib.Path:
-  path = output_dir / "archive"
-  assert not path.exists()
-  return path
+def test_env(request):
+  test_name = re.sub(r"[\[\]\\/*?:\"<>|]", "_", request.node.name)
+  maybe_cas_archive: str | None = request.config.getoption(CAS_ARCHIVE_FLAG)
+  if maybe_cas_archive:
+    cas_test_env = TestEnv(pathlib.Path(maybe_cas_archive), test_name)
+    yield cas_test_env
+    cas_test_env.remove_non_result()
+  else:
+    with tempfile.TemporaryDirectory() as tmp_dirname:
+      tmp_test_env = TestEnv(pathlib.Path(tmp_dirname), test_name)
+      yield tmp_test_env
+      if plt.PLATFORM.is_win:
+        for proc in psutil.process_iter():
+          if "chromedriver" in proc.name().lower():
+            proc.kill()
 
 
-@pytest.fixture(scope="session", autouse=True)
-def device_id(request) -> Optional[str]:
-  maybe_device_id: Optional[str] = request.config.getoption(
-      "--adb-device-id")
+@pytest.fixture(scope="session")
+def device_id(request, adb_path) -> Optional[str]:
+  maybe_device_id: str | None = request.config.getoption(ADB_DEVICE_ID_FLAG)
   if maybe_device_id:
     logging.info("adb device id: %s", maybe_device_id)
     return maybe_device_id
+  if adb_path:
+    devices = adb_devices(plt.PLATFORM, adb_path)
+    if len(devices) == 1:
+      device_id, _ = devices.popitem()
+      logging.info("Auto selecting android device: %s", device_id)
+      return device_id
   logging.info("No Android device detected.")
   return None
 
 
-@pytest.fixture(scope="session", autouse=True)
+@pytest.fixture(scope="session")
 def adb_path(request) -> Optional[str]:
-  maybe_adb_path: Optional[str] = request.config.getoption(
-      "--adb-path")
+  maybe_adb_path: str | None = request.config.getoption(ADB_PATH_FLAG)
   if maybe_adb_path:
     logging.info("adb path: %s", maybe_adb_path)
     return maybe_adb_path
-  logging.info("No custom adb path.")
-  return None
+  try:
+    adb_path = Binaries.ADB.resolve(plt.PLATFORM)
+    logging.info("Using default local adb: %s", adb_path)
+    return str(adb_path)
+  except BinaryNotFoundError:
+    logging.info("No custom adb path.")
+    return None
diff --git a/tests/end2end/desktop/browser/chrome/test_downloader.py b/tests/end2end/desktop/browser/chrome/test_downloader.py
index 91d4f51f..4f35f342 100644
--- a/tests/end2end/desktop/browser/chrome/test_downloader.py
+++ b/tests/end2end/desktop/browser/chrome/test_downloader.py
@@ -7,22 +7,23 @@ from __future__ import annotations
 import logging
 import pathlib
 import shutil
-from typing import Union
 
 import pytest
 
-from crossbench import compat, plt
+from crossbench import plt
 from crossbench.browsers.chrome.downloader import ChromeDownloader
 from crossbench.browsers.chrome.webdriver import ChromeWebDriver
-from crossbench.browsers.chromium.webdriver import (ChromeDriverFinder,
-                                                    DriverNotFoundError)
+from crossbench.browsers.chromium.driver_finder import (ChromeDriverFinder,
+                                                        DriverNotFoundError)
 from crossbench.browsers.settings import Settings
 from tests import test_helper
 from tests.end2end.desktop.browser.helper import tmp_platform_cache_dir
+from tests.test_helper import TestEnv
 
 
-def check_gsutil_access(gsutil_path: pathlib.Path):
-  if gsutil_path == pathlib.Path():
+def check_gsutil_access():
+  gsutil_path = plt.PLATFORM.which("gsutil")
+  if not gsutil_path:
     pytest.skip("Could not find gsutil")
   try:
     plt.PLATFORM.sh_stdout(
@@ -37,35 +38,32 @@ def check_gsutil_access(gsutil_path: pathlib.Path):
 
 
 def _load_and_check_version(output_dir: pathlib.Path, archive_dir: pathlib.Path,
-                            gsutil_path: pathlib.Path,
-                            version_or_archive: Union[str, pathlib.Path],
+                            version_or_archive: str | pathlib.Path,
                             version_str: str) -> pathlib.Path:
-  check_gsutil_access(gsutil_path)
-  with plt.PLATFORM.override_binary(
-      "gsutil", gsutil_path), tmp_platform_cache_dir(output_dir):
+  check_gsutil_access()
+  with tmp_platform_cache_dir(output_dir):
     app_path: pathlib.Path = ChromeDownloader.load(version_or_archive,
                                                    plt.PLATFORM)
-    assert compat.is_relative_to(app_path, output_dir)
+    assert app_path.is_relative_to(output_dir)
     assert archive_dir.exists()
     assert app_path.exists()
-    if plt.PLATFORM.is_macos:
-      assert set(output_dir.iterdir()) == {app_path, archive_dir}
     assert version_str in plt.PLATFORM.app_version(app_path)
     archives = list(archive_dir.iterdir())
     assert len(archives) == 1
     assert app_path.exists()
     chrome = ChromeWebDriver(
         "test-chrome", app_path, settings=Settings(platform=plt.PLATFORM))
-    assert version_str in chrome.version
+    assert version_str in str(chrome.version)
     _load_and_check_chromedriver(output_dir, chrome)
     return app_path
 
 
 def _load_and_check_chromedriver(output_dir, chrome: ChromeWebDriver) -> None:
-  driver_dir = output_dir / "chromedriver-binaries"
-  assert not driver_dir.exists()
-  with tmp_platform_cache_dir(driver_dir):
+  chromedriver_binaries_dir = output_dir / "chromedriver-binaries"
+  assert not chromedriver_binaries_dir.exists()
+  with tmp_platform_cache_dir(chromedriver_binaries_dir):
     finder = ChromeDriverFinder(chrome)
+    driver_dir = chromedriver_binaries_dir / "driver"
     assert not list(driver_dir.iterdir())
     with pytest.raises(DriverNotFoundError):
       finder.find_local_build()
@@ -73,125 +71,117 @@ def _load_and_check_chromedriver(output_dir, chrome: ChromeWebDriver) -> None:
     assert list(driver_dir.iterdir()) == [driver_path]
     assert driver_path.is_file()
     # Downloading again should use the cache-version
-    driver_path: pathlib.Path = finder.download()
+    driver_path = finder.download()
     assert list(driver_dir.iterdir()) == [driver_path]
     assert driver_path.is_file()
     # Restore output dir state.
     driver_path.unlink()
-  driver_dir.rmdir()
+    driver_dir.rmdir()
+  chromedriver_binaries_dir.rmdir()
 
 
 def _delete_extracted_app(output_dir: pathlib.Path, app_version: str) -> None:
-  for extracted_app_path in list(output_dir.iterdir()):
+  browser_bin = output_dir / "browser_bin"
+  for extracted_app_path in list(browser_bin.iterdir()):
     if app_version in str(extracted_app_path):
       shutil.rmtree(str(extracted_app_path))
 
 
 @pytest.mark.skipif(
     plt.PLATFORM.is_linux, reason="No canary versions on linux.")
-def test_download_pre_115_canary(output_dir, archive_dir, gsutil_path) -> None:
-  assert not list(output_dir.iterdir())
-  _load_and_check_version(output_dir, archive_dir, gsutil_path,
+def test_download_pre_115_canary(test_env: TestEnv) -> None:
+  test_env.assert_empty_output_dir()
+  _load_and_check_version(test_env.output_dir, test_env.archive_dir,
                           "chrome-114.0.5735.2 canary", "114.0.5735.2")
 
 
-def test_download_major_version_milestone(output_dir, archive_dir,
-                                          gsutil_path) -> None:
-  assert not list(output_dir.iterdir())
+def test_download_major_version_milestone(test_env: TestEnv) -> None:
+  test_env.assert_empty_output_dir()
   _load_and_check_version(
-      output_dir,
-      archive_dir,
-      gsutil_path,
+      test_env.output_dir,
+      test_env.archive_dir,
       "chrome-M111",
       "111",
   )
 
   # Re-downloading should reuse the extracted app.
   app_path = _load_and_check_version(
-      output_dir,
-      archive_dir,
-      gsutil_path,
+      test_env.output_dir,
+      test_env.archive_dir,
       "chrome-M111",
       "111",
   )
 
-  _delete_extracted_app(output_dir, "M111")
+  _delete_extracted_app(test_env.output_dir, "M111")
   assert not app_path.exists()
   _load_and_check_version(
-      output_dir,
-      archive_dir,
-      gsutil_path,
+      test_env.output_dir,
+      test_env.archive_dir,
       "chrome-M111",
       "111",
   )
 
 
-def test_download_major_version_chrome_for_testing(output_dir, archive_dir,
-                                                   gsutil_path) -> None:
+def test_download_major_version_chrome_for_testing(test_env: TestEnv) -> None:
   # Post M114 we're relying on the new chrome-for-testing download
-  assert not list(output_dir.iterdir())
+  test_env.assert_empty_output_dir()
   _load_and_check_version(
-      output_dir,
-      archive_dir,
-      gsutil_path,
+      test_env.output_dir,
+      test_env.archive_dir,
       "chrome-M115",
       "115",
   )
 
   # Re-downloading should reuse the extracted app.
   app_path = _load_and_check_version(
-      output_dir,
-      archive_dir,
-      gsutil_path,
+      test_env.output_dir,
+      test_env.archive_dir,
       "chrome-M115",
       "115",
   )
 
-  _delete_extracted_app(output_dir, "M115")
+  _delete_extracted_app(test_env.output_dir, "M115")
   assert not app_path.exists()
   _load_and_check_version(
-      output_dir,
-      archive_dir,
-      gsutil_path,
+      test_env.output_dir,
+      test_env.archive_dir,
       "chrome-M115",
       "115",
   )
 
 
-def test_download_specific_version_pre_115_stable(output_dir, archive_dir,
-                                                  gsutil_path) -> None:
-  assert not list(output_dir.iterdir())
+def test_download_specific_version_pre_115_stable(test_env: TestEnv) -> None:
+  test_env.assert_empty_output_dir()
   version_str = "111.0.5563.146"
-  _load_and_check_version(output_dir, archive_dir, gsutil_path,
+  _load_and_check_version(test_env.output_dir, test_env.archive_dir,
                           f"chrome-{version_str}", version_str)
 
   # Re-downloading should work as well and hit the extracted app.
-  app_path = _load_and_check_version(output_dir, archive_dir, gsutil_path,
+  app_path = _load_and_check_version(test_env.output_dir, test_env.archive_dir,
                                      f"chrome-{version_str}", version_str)
 
-  _delete_extracted_app(output_dir, version_str)
+  _delete_extracted_app(test_env.output_dir, version_str)
   assert not app_path.exists()
-  app_path = _load_and_check_version(output_dir, archive_dir, gsutil_path,
+  app_path = _load_and_check_version(test_env.output_dir, test_env.archive_dir,
                                      f"chrome-{version_str}", version_str)
 
-  _delete_extracted_app(output_dir, version_str)
+  _delete_extracted_app(test_env.output_dir, version_str)
   assert not app_path.exists()
-  archives = list(archive_dir.iterdir())
+  archives = list(test_env.archive_dir.iterdir())
   assert len(archives) == 1
   archive = archives[0]
-  app_path = _load_and_check_version(output_dir, archive_dir, gsutil_path,
+  app_path = _load_and_check_version(test_env.output_dir, test_env.archive_dir,
                                      archive, version_str)
-  assert list(archive_dir.iterdir()) == [archive]
+  assert list(test_env.archive_dir.iterdir()) == [archive]
 
 
 @pytest.mark.skipif(
     plt.PLATFORM.is_macos and plt.PLATFORM.is_arm64,
     reason="Old versions only supported on intel machines.")
-def test_download_old_major_version(output_dir, archive_dir,
-                                    gsutil_path) -> None:
-  assert not list(output_dir.iterdir())
-  _load_and_check_version(output_dir, archive_dir, gsutil_path, "chrome-M68",
-                          "68")
+def test_download_old_major_version(test_env: TestEnv) -> None:
+  test_env.assert_empty_output_dir()
+  _load_and_check_version(test_env.output_dir, test_env.archive_dir,
+                          "chrome-M68", "68")
 
 
 if __name__ == "__main__":
diff --git a/tests/end2end/desktop/browser/firefox/test_downloader.py b/tests/end2end/desktop/browser/firefox/test_downloader.py
index c96870f1..5332edb6 100644
--- a/tests/end2end/desktop/browser/firefox/test_downloader.py
+++ b/tests/end2end/desktop/browser/firefox/test_downloader.py
@@ -7,9 +7,8 @@ from __future__ import annotations
 import pathlib
 import shutil
 import unittest
-from typing import Union
 
-from crossbench import compat, plt
+from crossbench import plt
 from crossbench.browsers.firefox.downloader import FirefoxDownloader
 from crossbench.browsers.firefox.webdriver import (FirefoxDriverFinder,
                                                    FirefoxWebDriver)
@@ -24,13 +23,13 @@ class FirefoxDownloaderTestCase():
   def _load_and_check_version(self,
                               output_dir: pathlib.Path,
                               archive_dir: pathlib.Path,
-                              version_or_archive: Union[str, pathlib.Path],
+                              version_or_archive: str | pathlib.Path,
                               version_str: str,
                               expect_archive: bool = True) -> pathlib.Path:
     app_path: pathlib.Path
     with tmp_platform_cache_dir(output_dir):
       app_path = FirefoxDownloader.load(version_or_archive, plt.PLATFORM)
-    assert compat.is_relative_to(app_path, output_dir)
+    assert app_path.is_relative_to(output_dir)
     assert archive_dir.exists()
     assert app_path.exists()
     if plt.PLATFORM.is_macos:
@@ -46,7 +45,7 @@ class FirefoxDownloaderTestCase():
         "test-browser", app_path, settings=Settings(platform=plt.PLATFORM))
     # TODO: fix using dedicated Version object
     base_version_str = version_str.split("b")[0]
-    assert base_version_str in browser.version
+    assert base_version_str in str(browser.version)
     self._load_and_check_webdriver(output_dir, browser)
     return app_path
 
@@ -61,21 +60,22 @@ class FirefoxDownloaderTestCase():
       assert list(driver_dir.iterdir()) == [driver_path]
       assert driver_path.is_file()
       # Downloading again should use the cache-version
-      driver_path: pathlib.Path = finder.download()
+      driver_path = finder.download()
       assert list(driver_dir.iterdir()) == [driver_path]
       assert driver_path.is_file()
       # Restore output dir state.
       driver_path.unlink()
     driver_dir.rmdir()
 
-  def test_download_specific_version(self, output_dir, archive_dir) -> None:
-    assert not list(output_dir.iterdir())
+  def test_download_specific_version(self, test_env) -> None:
+    assert not list(test_env.output_dir.iterdir())
     version_str = "106.0.4"
-    self._load_and_check_version(output_dir, archive_dir,
+    self._load_and_check_version(test_env.output_dir, test_env.archive_dir,
                                  f"firefox-{version_str}", version_str)
 
     # Re-downloading should work as well and hit the extracted app.
-    app_path = self._load_and_check_version(output_dir, archive_dir,
+    app_path = self._load_and_check_version(test_env.output_dir,
+                                            test_env.archive_dir,
                                             f"firefox-{version_str}",
                                             version_str)
 
@@ -83,33 +83,35 @@ class FirefoxDownloaderTestCase():
     if plt.PLATFORM.is_macos:
       shutil.rmtree(app_path)
     else:
-      shutil.rmtree(output_dir.output_dir / version_str)
+      shutil.rmtree(test_env.output_dir.output_dir / version_str)
     assert not app_path.exists()
-    app_path = self._load_and_check_version(output_dir, archive_dir,
+    app_path = self._load_and_check_version(test_env.output_dir,
+                                            test_env.archive_dir,
                                             f"firefox-{version_str}",
                                             version_str)
     # Delete app and install from archive.
     if plt.PLATFORM.is_macos:
       shutil.rmtree(app_path)
     else:
-      shutil.rmtree(output_dir.output_dir / version_str)
+      shutil.rmtree(test_env.output_dir.output_dir / version_str)
     assert not app_path.exists()
-    archives = list(archive_dir.iterdir())
+    archives = list(test_env.archive_dir.iterdir())
     assert len(archives) == 1
     archive = archives[0]
-    app_path = self._load_and_check_version(output_dir, archive_dir, archive,
+    app_path = self._load_and_check_version(test_env.output_dir,
+                                            test_env.archive_dir, archive,
                                             version_str)
-    assert list(archive_dir.iterdir()) == [archive]
+    assert list(test_env.archive_dir.iterdir()) == [archive]
 
-  def test_download_specific_beta_version(self, output_dir,
-                                          archive_dir) -> None:
-    assert not list(output_dir.iterdir())
+  def test_download_specific_beta_version(self, test_env) -> None:
+    assert not list(test_env.output_dir.iterdir())
     version_str = "115.0b4"
-    self._load_and_check_version(output_dir, archive_dir,
+    self._load_and_check_version(test_env.output_dir, test_env.archive_dir,
                                  f"firefox-{version_str}", version_str)
 
     # Re-downloading should work as well and hit the extracted app.
-    app_path = self._load_and_check_version(output_dir, archive_dir,
+    app_path = self._load_and_check_version(test_env.output_dir,
+                                            test_env.archive_dir,
                                             f"firefox-{version_str}",
                                             version_str)
 
@@ -117,9 +119,10 @@ class FirefoxDownloaderTestCase():
     if plt.PLATFORM.is_macos:
       shutil.rmtree(app_path)
     else:
-      shutil.rmtree(output_dir.output_dir / version_str)
+      shutil.rmtree(test_env.output_dir.output_dir / version_str)
     assert not app_path.exists()
-    app_path = self._load_and_check_version(output_dir, archive_dir,
+    app_path = self._load_and_check_version(test_env.output_dir,
+                                            test_env.archive_dir,
                                             f"firefox-{version_str}",
                                             version_str)
 
@@ -127,14 +130,15 @@ class FirefoxDownloaderTestCase():
     if plt.PLATFORM.is_macos:
       shutil.rmtree(app_path)
     else:
-      shutil.rmtree(output_dir.output_dir / version_str)
+      shutil.rmtree(test_env.output_dir.output_dir / version_str)
     assert not app_path.exists()
-    archives = list(archive_dir.iterdir())
+    archives = list(test_env.archive_dir.iterdir())
     assert len(archives) == 1
     archive = archives[0]
-    app_path = self._load_and_check_version(output_dir, archive_dir, archive,
+    app_path = self._load_and_check_version(test_env.output_dir,
+                                            test_env.archive_dir, archive,
                                             version_str)
-    assert list(archive_dir.iterdir()) == [archive]
+    assert list(test_env.archive_dir.iterdir()) == [archive]
 
 
 if __name__ == "__main__":
diff --git a/tests/end2end/desktop/cbb/test_cbb.py b/tests/end2end/desktop/cbb/test_cbb.py
index 6609c625..681b9ad3 100644
--- a/tests/end2end/desktop/cbb/test_cbb.py
+++ b/tests/end2end/desktop/cbb/test_cbb.py
@@ -11,9 +11,11 @@ from crossbench import plt
 from crossbench.benchmarks import all as benchmarks
 from crossbench.benchmarks.base import PressBenchmark
 from crossbench.browsers.chrome import webdriver as chrome_webdriver
+from crossbench.browsers.chromium import webdriver as chromium_webdriver
 from crossbench.browsers.settings import Settings
 from crossbench.cbb import cbb_adapter
 from tests import test_helper
+from tests.test_helper import TestEnv
 
 # pytest.fixtures rely on params having the same name as the fixture function
 # pylint: disable=redefined-outer-name
@@ -36,27 +38,33 @@ def get_benchmark(benchmark_cls) -> PressBenchmark:
 
 @pytest.fixture
 def webdriver(driver_path, browser_path):
-  return chrome_webdriver.ChromeWebDriver("Chrome", browser_path,
-                                          Settings(driver_path=driver_path))
+  is_cq = driver_path is not None
+  flags = ["--headless"] if plt.PLATFORM.is_linux and is_cq else []
+  browser_cls = chrome_webdriver.ChromeWebDriver
+  if "chromium" in str(driver_path).lower():
+    browser_cls = chromium_webdriver.ChromiumWebDriver
+  return browser_cls("Chrome", browser_path,
+                     Settings(driver_path=driver_path, flags=flags))
 
 
-def run_benchmark(output_dir, webdriver, benchmark_cls) -> None:
+def run_benchmark(test_env: TestEnv, webdriver, benchmark_cls) -> None:
   """Tests that we can execute the specified benchmark and obtain result data
   post execution.
   This test uses Chrome browser to run the benchmarks.
   """
   benchmark = get_benchmark(benchmark_cls)
   assert benchmark
-  results_dir = output_dir / "result"
 
   maybe_results_file = cbb_adapter.get_probe_result_file(
-      benchmark_cls.NAME, webdriver, results_dir)
+      benchmark_cls.NAME, webdriver, test_env.results_dir)
   assert maybe_results_file
   results_file = pathlib.Path(maybe_results_file)
   assert not results_file.exists()
 
   cbb_adapter.run_benchmark(
-      output_folder=results_dir, browser_list=[webdriver], benchmark=benchmark)
+      output_folder=test_env.results_dir,
+      browser_list=[webdriver],
+      benchmark=benchmark)
 
   assert results_file.exists()
   with results_file.open(encoding="utf-8") as f:
@@ -64,40 +72,44 @@ def run_benchmark(output_dir, webdriver, benchmark_cls) -> None:
   assert benchmark_data
 
 
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-def test_speedometer_20(output_dir, webdriver):
-  run_benchmark(output_dir, webdriver, benchmarks.Speedometer20Benchmark)
+def test_speedometer_20(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.Speedometer20Benchmark)
 
 
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-def test_speedometer_21(output_dir, webdriver):
-  run_benchmark(output_dir, webdriver, benchmarks.Speedometer21Benchmark)
+def test_speedometer_21(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.Speedometer21Benchmark)
 
 
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-def test_motionmark_12(output_dir, webdriver):
-  run_benchmark(output_dir, webdriver, benchmarks.MotionMark12Benchmark)
+def test_speedometer_30(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.Speedometer30Benchmark)
 
 
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-def test_motionmark_13(output_dir, webdriver):
-  run_benchmark(output_dir, webdriver, benchmarks.MotionMark13Benchmark)
+def test_speedometer_31(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.Speedometer31Benchmark)
 
 
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-def test_jetstream_20(output_dir, webdriver):
-  run_benchmark(output_dir, webdriver, benchmarks.JetStream20Benchmark)
+def test_motionmark_12(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.MotionMark12Benchmark)
 
 
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-def test_jetstream_21(output_dir, webdriver):
-  run_benchmark(output_dir, webdriver, benchmarks.JetStream21Benchmark)
+def test_motionmark_13(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.MotionMark13Benchmark)
+
+
+def test_motionmark_131(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.MotionMark131Benchmark)
+
+
+def test_jetstream_20(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.JetStream20Benchmark)
+
+
+def test_jetstream_21(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.JetStream21Benchmark)
+
+
+def test_jetstream_22(test_env: TestEnv, webdriver):
+  run_benchmark(test_env, webdriver, benchmarks.JetStream22Benchmark)
 
 
 if __name__ == "__main__":
diff --git a/tests/end2end/desktop/probes/__init__.py b/tests/end2end/desktop/probes/__init__.py
new file mode 100644
index 00000000..b20ab3aa
--- /dev/null
+++ b/tests/end2end/desktop/probes/__init__.py
@@ -0,0 +1,3 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
diff --git a/tests/end2end/desktop/probes/test_perfetto.py b/tests/end2end/desktop/probes/test_perfetto.py
new file mode 100644
index 00000000..3d44bee7
--- /dev/null
+++ b/tests/end2end/desktop/probes/test_perfetto.py
@@ -0,0 +1,40 @@
+#!/usr/bin/env vpython3
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+
+import pytest
+
+from crossbench import plt
+from crossbench.probes.perfetto.downloader import PerfettoToolDownloader
+from tests.test_helper import TestEnv
+
+
+@contextlib.contextmanager
+def setup_platform_cache_dir():
+  platform = plt.PLATFORM
+  original_cache_dir = platform.cache_dir()
+  with platform.TemporaryDirectory() as temp_dir:
+    try:
+      platform.set_cache_dir(temp_dir)
+      yield platform
+    finally:
+      platform.set_cache_dir(original_cache_dir)
+
+
+@pytest.mark.skipif(plt.PLATFORM.is_win, reason="No binary avilable on windows")
+def test_perfetto_downloader(test_env: TestEnv):
+  if plt.Platform.is_linux and test_env.is_cq:
+    raise pytest.skip("Old glibc on the CQ is too old for tracebox")
+  with setup_platform_cache_dir() as platform:
+    downloader = PerfettoToolDownloader("tracebox", platform=platform)
+    assert not platform.exists(downloader.path)
+    result = downloader.download()
+    assert downloader.path == result
+    assert platform.exists(result)
+    version_str = platform.sh_stdout(result, "--version")
+    assert downloader.version in version_str
diff --git a/tests/end2end/desktop/runner.py b/tests/end2end/desktop/runner.py
new file mode 100644
index 00000000..46339815
--- /dev/null
+++ b/tests/end2end/desktop/runner.py
@@ -0,0 +1,27 @@
+#!/usr/bin/env vpython3
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import pathlib
+import sys
+
+import pytest
+
+FILE_PATH = pathlib.Path(__file__).absolute()
+TEST_DIR = FILE_PATH.absolute().parent
+REPO_DIR = FILE_PATH.absolute().parents[3]
+
+if REPO_DIR not in sys.path:
+  sys.path.insert(0, str(REPO_DIR))
+
+if __name__ == "__main__":
+  pass_through_args = sys.argv[1:]
+  return_code = pytest.main([
+      "--verbose", "--dist=loadgroup", "--log-cli-level=DEBUG", "-o",
+      "log_cli=True", "-rs",
+      str(TEST_DIR), *pass_through_args
+  ])
+  sys.exit(return_code)
diff --git a/tests/end2end/desktop/test_cli.py b/tests/end2end/desktop/test_cli.py
new file mode 100644
index 00000000..9e7557d0
--- /dev/null
+++ b/tests/end2end/desktop/test_cli.py
@@ -0,0 +1,419 @@
+# Copyright 2023 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+from __future__ import annotations
+
+import contextlib
+import io
+import json
+import pathlib
+from typing import List, Optional, Tuple
+from unittest import mock
+
+import pytest
+
+import crossbench.browsers.all as all_browsers
+from crossbench import plt
+from crossbench.cli.cli import CrossBenchCLI
+from tests import test_helper
+from tests.end2end.conftest import mock_patch_chrome_stable
+from tests.test_helper import TestEnv
+
+
+class SysExitException(Exception):
+
+  def __init__(self):
+    super().__init__("sys.exit")
+
+
+def _run_cli(*args: str,
+             extra_flags: tuple[str, ...] = (),
+             test_env: Optional[TestEnv] = None,
+             auto_headless: bool = False) -> Tuple[CrossBenchCLI, io.StringIO]:
+  if test_env is not None:
+    args += (f"--out-dir={test_env.results_dir}",) + test_env.cq_flags
+  if auto_headless and not plt.PLATFORM.has_display:
+    if "--headless" not in args:
+      args += ("--headless",)
+      args = tuple(arg for arg in args if not arg.startswith("--viewport="))
+  args += extra_flags
+  cli = CrossBenchCLI()
+  with contextlib.redirect_stdout(io.StringIO()) as stdout:
+    with mock.patch("sys.exit", side_effect=SysExitException):
+      cli.run(args)
+  return cli, stdout
+
+
+def _get_browser_dirs(results_dir: pathlib.Path) -> List[pathlib.Path]:
+  assert results_dir.is_dir()
+  browser_dirs = [path for path in results_dir.iterdir() if path.is_dir()]
+  return browser_dirs
+
+
+def _get_v8_log_files(results_dir: pathlib.Path) -> List[pathlib.Path]:
+  return list(results_dir.glob("**/*-v8.log"))
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_speedometer_2_0(test_env: TestEnv, browser_path) -> None:
+  # - Speedometer 2.0
+  # - Speedometer --iterations flag
+  # - Tracing probe with inline args
+  # - --browser-config
+  with pytest.raises(SysExitException):
+    _run_cli("speedometer_2.0", "--help")
+  _run_cli("describe", "benchmark", "speedometer_2.0")
+  browser_config = test_env.root_dir / "config/doc/browser.config.hjson"
+  assert browser_config.is_file()
+  results_dir = test_env.results_dir
+  assert not results_dir.exists()
+  with mock_patch_chrome_stable(browser_path):
+    _run_cli(
+        "sp_2.0",
+        f"--browser-config={browser_config}",
+        "--iterations=2",
+        "--stories=jQuery-TodoMVC",
+        "--env-validation=skip",
+        "--probe=tracing:{preset:'minimal'}",
+        test_env=test_env,
+        auto_headless=True)
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_speedometer_2_1(test_env: TestEnv, test_chrome_name) -> None:
+  # - Speedometer 2.1
+  # - Story filtering with regexp
+  # - V8 probes
+  # - minimal splashscreen
+  # - inline probe arguments
+  with pytest.raises(SysExitException):
+    _run_cli("speedometer_2.1", "--help")
+  _run_cli("describe", "benchmark", "speedometer_2.1")
+  _run_cli(
+      "sp2.1",
+      f"--browser={test_chrome_name}",
+      "--splashscreen=minimal",
+      "--iterations=2",
+      "--env-validation=skip",
+      "--stories=.*Vanilla.*",
+      # V8 --prof doesn't always work on linux, skip it.
+      "--probe=v8.log:"
+      "{log_all:false, js_flags:['--log-maps'], prof:false, profview:false}",
+      "--probe=v8.turbolizer",
+      "--debug",
+      test_env=test_env,
+      auto_headless=True)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 1
+  v8_log_files = _get_v8_log_files(test_env.results_dir)
+  assert len(v8_log_files) > 1
+
+
+@pytest.mark.skip_mock
+@pytest.mark.flaky(retries=3, delay=5)
+def test_speedometer_2_1_custom_chrome_download(test_env: TestEnv) -> None:
+  # - Custom chrome version downloads
+  # - headless
+  # Flaky due to downloading live custom builds.
+  # TODO: speed up --browser=chrome-M111 and add it.
+  _run_cli(
+      "sp2.1",
+      "--browser=chrome-M113",
+      "--browser=chrome-111.0.5563.110",
+      "--headless",
+      "--iterations=1",
+      "--env-validation=skip",
+      "--stories=.*Vanilla.*",
+      "--debug",
+      test_env=test_env)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 2
+  v8_log_files = _get_v8_log_files(test_env.results_dir)
+  assert not v8_log_files
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.is_macos, reason="Safari is only available on macos")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_speedometer_2_1_chrome_safari(test_env: TestEnv, driver_path,
+                                       test_chrome_name) -> None:
+  # - Speedometer 3
+  # - Merging stories over multiple iterations and browsers
+  # - Testing safari
+  # - --verbose flag
+  # - no splashscreen
+  # This fails on the CQ bot, so make sure we skip it there:
+  if driver_path:
+    pytest.skip("Skipping test on CQ.")
+  platform = plt.PLATFORM
+  if not platform.is_macos and (not platform.exists(
+      all_browsers.Safari.default_path(platform))):
+    pytest.skip("Test requires Safari, skipping on non macOS devices.")
+  _run_cli(
+      "sp2.1",
+      f"--browser={test_chrome_name}",
+      "--browser=safari",
+      "--splashscreen=none",
+      "--iterations=1",
+      "--repeat=2",
+      "--env-validation=skip",
+      "--verbose",
+      "--stories=.*React.*",
+      test_env=test_env,
+      auto_headless=True)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 2
+  v8_log_files = _get_v8_log_files(test_env.results_dir)
+  assert not v8_log_files
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_jetstream_2_0(test_env: TestEnv, test_chrome_name) -> None:
+  # - jetstream 2.0
+  # - merge / run separate stories
+  # - custom multiple --js-flags
+  # - custom viewport
+  # - quiet flag
+  with pytest.raises(SysExitException):
+    _run_cli("jetstream_2.0", "--help")
+  _run_cli("describe", "--json", "benchmark", "jetstream_2.0")
+  _run_cli(
+      "jetstream_2.0",
+      f"--browser={test_chrome_name}",
+      "--separate",
+      "--repeat=2",
+      "--env-validation=skip",
+      "--viewport=maximised",
+      "--stories=.*date-format.*",
+      "--quiet",
+      "--js-flags=--log,--log-opt,--log-deopt",
+      extra_flags=(
+          "--",
+          "--no-sandbox",
+      ),
+      test_env=test_env,
+      auto_headless=True)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 1
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_jetstream_2_1(test_env: TestEnv, test_chrome_name) -> None:
+  # - jetstream 2.1
+  # - custom --time-unit
+  # - explicit single story
+  # - custom splashscreen
+  # - custom viewport
+  # - --probe-config
+  with pytest.raises(SysExitException):
+    _run_cli("jetstream_2.1", "--help")
+  _run_cli("describe", "benchmark", "jetstream_2.1")
+  probe_config = test_env.root_dir / "config/doc/probe.config.hjson"
+  assert probe_config.is_file()
+  _run_cli(
+      "jetstream_2.1",
+      f"--browser={test_chrome_name}",
+      "--env-validation=skip",
+      "--splashscreen=http://google.com",
+      "--viewport=900x800",
+      "--stories=Box2D",
+      "--time-unit=0.9",
+      f"--probe-config={probe_config}",
+      "--throw",
+      test_env=test_env,
+      auto_headless=True)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 1
+  v8_log_files = _get_v8_log_files(test_env.results_dir)
+  assert len(v8_log_files) > 1
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_jetstream_2_2(test_env: TestEnv, test_chrome_name) -> None:
+  # - jetstream 2.2
+  # - custom --time-unit
+  # - explicit single story
+  # - custom splashscreen
+  # - custom viewport
+  # - --probe-config
+  with pytest.raises(SysExitException):
+    _run_cli("jetstream_2.2", "--help")
+  _run_cli("describe", "benchmark", "jetstream_2.2")
+  probe_config = test_env.root_dir / "config/doc/probe.config.hjson"
+  assert probe_config.is_file()
+  _run_cli(
+      "jetstream_2.2",
+      f"--browser={test_chrome_name}",
+      "--env-validation=skip",
+      "--splashscreen=http://google.com",
+      "--viewport=900x800",
+      "--stories=Box2D",
+      "--time-unit=0.9",
+      f"--probe-config={probe_config}",
+      "--throw",
+      test_env=test_env,
+      auto_headless=True)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 1
+  v8_log_files = _get_v8_log_files(test_env.results_dir)
+  assert len(v8_log_files) > 1
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading(test_env: TestEnv, test_chrome_name) -> None:
+  # - loading using named pages with timeouts
+  # - custom cooldown time
+  # - custom viewport
+  # - performance.mark probe
+  with pytest.raises(SysExitException):
+    _run_cli("loading", "--help")
+  _run_cli("describe", "benchmark", "loading")
+  _run_cli(
+      "loading",
+      f"--browser={test_chrome_name}",
+      "--env-validation=skip",
+      "--viewport=headless",
+      "--stories=cnn",
+      "--cool-down-time=2.5",
+      "--probe=performance.entries",
+      test_env=test_env,
+      auto_headless=True)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 1
+
+
+def test_loading_page_config(test_env: TestEnv, test_chrome_name) -> None:
+  # - loading with config file
+  page_config = test_env.root_dir / "config/doc/page.config.hjson"
+  assert page_config.is_file()
+  _run_cli(
+      "loading",
+      f"--browser={test_chrome_name}",
+      "--env-validation=skip",
+      f"--page-config={page_config}",
+      "--probe=performance.entries",
+      "--no-splash",
+      "--cool-down-time=0",
+      "--throw",
+      test_env=test_env,
+      auto_headless=True)
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading_playback_urls(test_env: TestEnv, test_chrome_name) -> None:
+  # - loading using url
+  # - combined pages and --playback controller
+  _run_cli(
+      "loading",
+      f"--browser={test_chrome_name}",
+      "--env-validation=skip",
+      "--verbose-driver",
+      "--playback=5.3s",
+      "--viewport=fullscreen",
+      "--stories=http://google.com,0.5,http://bing.com,0.4",
+      "--probe=performance.entries",
+      test_env=test_env,
+      auto_headless=True)
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading_playback(test_env: TestEnv, test_chrome_name) -> None:
+  # - loading using named pages with timeouts
+  # - separate pages and --playback controller
+  # - viewport-size via chrome flag
+  args = [
+      "loading",
+      f"--browser={test_chrome_name}",
+      "--env-validation=skip",
+      "--playback=5.3s",
+      "--separate",
+      "--stories=twitter,2,facebook,0.4",
+      "--probe=performance.entries",
+      "--debug",
+  ]
+  if not plt.PLATFORM.is_linux:
+    args.extend([
+        "--",
+        "--window-size=900,500",
+        "--window-position=150,150",
+    ])
+  _run_cli(*args, test_env=test_env, auto_headless=True)
+
+
+@pytest.mark.skipif(
+    not plt.PLATFORM.has_display, reason="Firefox cannot run headless")
+@pytest.mark.xdist_group("end2end-benchmark")
+def test_loading_playback_firefox(test_env: TestEnv, test_chrome_name) -> None:
+  # - loading using named pages with timeouts
+  # - --playback controller
+  # - Firefox
+  platform = plt.PLATFORM
+  try:
+    if not platform.exists(all_browsers.Firefox.default_path(platform)):
+      pytest.skip("Test requires Firefox.")
+  except Exception:  # pylint: disable=broad-exception-caught
+    pytest.skip("Test requires Firefox.")
+  _run_cli(
+      "loading",
+      f"--browser={test_chrome_name}",
+      "--browser=ff",
+      "--env-validation=skip",
+      "--playback=2x",
+      "--stories=twitter,1,facebook,0.4",
+      "--probe=performance.entries",
+      test_env=test_env,
+      auto_headless=True)
+
+  browser_dirs = _get_browser_dirs(test_env.results_dir)
+  assert len(browser_dirs) == 2
+
+
+@pytest.mark.xdist_group("end2end-benchmark")
+@pytest.mark.skipif(
+    plt.PLATFORM.is_win,
+    reason="stdout forwarding is not always supported on windows")
+def test_chrome_stdout_logging(test_env: TestEnv) -> None:
+  # - loading inline hjson
+  # - executing custom JS
+  # - validating chrome browser stdout using generated content to make sure it
+  #   is not just in the driver log as part of the script source.
+  out_dir = test_env.results_dir
+  assert not list(out_dir.glob("**/*.stdout.log"))
+  page_config = {
+      "pages": {
+          "STDOUT TEST": [{
+              "action": "get",
+              "url": "https://www.google.com"
+          }, {
+              "action": "js",
+              "script": "%DebugPrint('TestOutput'.repeat(3))"
+          }]
+      }
+  }
+  _run_cli(
+      "loading",
+      "--browser=chrome",
+      "--env-validation=skip",
+      "--js-flags=--allow-natives-syntax",
+      "--fast",
+      f"--page-config={json.dumps(page_config)}",
+      test_env=test_env,
+      auto_headless=True)
+
+  stdout_files = list(out_dir.glob("**/*.stdout.log"))
+  assert len(stdout_files) == 1
+  stdout_file = stdout_files[0]
+  test_output = "TestOutput" * 3
+  assert test_output in stdout_file.read_text()
+
+
+if __name__ == "__main__":
+  test_helper.run_pytest(__file__)
diff --git a/tests/end2end/runner.py b/tests/end2end/runner.py
index 431bd3dd..d71557e8 100644
--- a/tests/end2end/runner.py
+++ b/tests/end2end/runner.py
@@ -9,6 +9,7 @@
 from __future__ import annotations
 
 import argparse
+import os
 import pathlib
 import sys
 
@@ -22,19 +23,27 @@ if REPO_DIR not in sys.path:
 
 if __name__ == "__main__":
   pass_through_args = sys.argv[1:]
-  ignore_tests = []
+  more_flags = []
   parser = argparse.ArgumentParser()
   parser.add_argument("--ignore-tests", required=False)
   parser.add_argument("--adb-device-id", required=False)
+  parser.add_argument("--test-gsutil-path", required=False)
   args, _ = parser.parse_known_args()
   if args.ignore_tests:
     subfolders = args.ignore_tests.split(",")
-    ignore_tests = [f"--ignore={END2END_TEST_DIR / x}" for x in subfolders]
+    more_flags.extend([f"--ignore={END2END_TEST_DIR / x}" for x in subfolders])
   elif not args.adb_device_id:
-    ignore_tests = [f"--ignore={END2END_TEST_DIR / 'android'}"]
+    more_flags.append(f"--ignore={END2END_TEST_DIR / 'android'}")
+  if args.test_gsutil_path:
+    more_flags.append(f"--test-gsutil-path={args.test_gsutil_path}")
+    current_path = os.environ["PATH"]
+    new_path = pathlib.Path(args.test_gsutil_path).parent / "python-bin"
+    updated_path = f"'{current_path}:{new_path}'"
+    os.environ["PATH"] = updated_path
+    os.environ["DEPOT_TOOLS_UPDATE"] = "0"
   return_code = pytest.main([
-      "--exitfirst", "--verbose", "--dist=loadgroup", "--log-cli-level=DEBUG",
-      "-o", "log_cli=True", "-rs",
+      "--verbose", "--numprocesses=1", "--log-cli-level=DEBUG", "-o",
+      "log_cli=True", "-rs",
       str(END2END_TEST_DIR), *pass_through_args
-  ] + ignore_tests)
+  ] + more_flags)
   sys.exit(return_code)
diff --git a/tests/end2end/test_cli.py b/tests/end2end/test_cli.py
deleted file mode 100644
index ad502166..00000000
--- a/tests/end2end/test_cli.py
+++ /dev/null
@@ -1,391 +0,0 @@
-# Copyright 2023 The Chromium Authors
-# Use of this source code is governed by a BSD-style license that can be
-# found in the LICENSE file.
-
-from __future__ import annotations
-
-import contextlib
-import io
-import pathlib
-from typing import List, Tuple
-from unittest import mock
-
-import pytest
-
-import crossbench.browsers.all as browsers
-from crossbench import plt
-from crossbench.cli.cli import CrossBenchCLI
-from tests import test_helper
-
-
-class SysExitException(Exception):
-
-  def __init__(self):
-    super().__init__("sys.exit")
-
-
-@pytest.fixture(autouse=True)
-def cli_test_context(browser_path, driver_path):
-  # Mock out chrome's stable path to be able to run on the CQ with the
-  # --test-browser-path option.
-  with mock.patch(
-      "crossbench.browsers.all.Chrome.stable_path", return_value=browser_path):
-    if not driver_path:
-      yield
-    else:
-      # The CQ uses the latest canary, which might not have a easily publicly
-      # accessible chromedriver available.
-      with mock.patch(
-          "crossbench.browsers.chromium.webdriver.ChromeDriverFinder.download",
-          return_value=driver_path):
-        yield
-
-
-def _run_cli(*args: str) -> Tuple[CrossBenchCLI, io.StringIO]:
-  cli = CrossBenchCLI()
-  with contextlib.redirect_stdout(io.StringIO()) as stdout:
-    with mock.patch("sys.exit", side_effect=SysExitException):
-      cli.run(args)
-  return cli, stdout
-
-
-def _get_browser_dirs(results_dir: pathlib.Path) -> List[pathlib.Path]:
-  assert results_dir.is_dir()
-  browser_dirs = [path for path in results_dir.iterdir() if path.is_dir()]
-  return browser_dirs
-
-
-def _get_v8_log_files(results_dir: pathlib.Path) -> List[pathlib.Path]:
-  return list(results_dir.glob("**/*-v8.log"))
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_speedometer_2_0(output_dir, cache_dir, root_dir) -> None:
-  # - Speedometer 2.0
-  # - Speedometer --iterations flag
-  # - Tracing probe with inline args
-  # - --browser-config
-  with pytest.raises(SysExitException):
-    _run_cli("speedometer_2.0", "--help")
-  _run_cli("describe", "benchmark", "speedometer_2.0")
-  browser_config = root_dir / "config/doc/browser.config.hjson"
-  assert browser_config.is_file()
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli("sp_2.0", f"--browser-config={browser_config}", "--iterations=2",
-           "--env-validation=skip", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", "--probe=tracing:{preset:'minimal'}")
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_speedometer_2_1(output_dir, cache_dir) -> None:
-  # - Speedometer 2.1
-  # - Story filtering with regexp
-  # - V8 probes
-  # - minimal splashscreen
-  # - inline probe arguments
-  with pytest.raises(SysExitException):
-    _run_cli("speedometer_2.1", "--help")
-  _run_cli("describe", "benchmark", "speedometer_2.1")
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli(
-      "sp2.1",
-      "--browser=chrome-stable",
-      "--splashscreen=minimal",
-      "--iterations=2",
-      "--env-validation=skip",
-      f"--out-dir={results_dir}",
-      f"--cache-dir={cache_dir}",
-      "--stories=.*Vanilla.*",
-      # V8 --prof doesn't always work on linux, skip it.
-      "--probe=v8.log:"
-      "{log_all:false, js_flags:['--log-maps'], prof:false, profview:false}",
-      "--probe=v8.turbolizer",
-      "--debug")
-
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 1
-  v8_log_files = _get_v8_log_files(results_dir)
-  assert len(v8_log_files) > 1
-
-
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-def test_speedometer_2_1_custom_chrome_download(output_dir, cache_dir) -> None:
-  # - Custom chrome version downloads
-  # - headless
-  if not plt.PLATFORM.which("gsutil"):
-    pytest.skip("Missing required 'gsutil', skipping test.")
-  results_dir = output_dir / "results"
-  # TODO: speed up --browser=chrome-M111 and add it.
-  assert len(list(cache_dir.iterdir())) == 0
-  _run_cli("sp2.1", f"--cache-dir={cache_dir}", "--browser=chrome-M113",
-           "--browser=chrome-111.0.5563.110", "--headless", "--iterations=1",
-           "--env-validation=skip", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", "--stories=.*Vanilla.*")
-
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 2
-  v8_log_files = _get_v8_log_files(results_dir)
-  assert not v8_log_files
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_speedometer_2_1_chrome_safari(output_dir, cache_dir,
-                                       driver_path) -> None:
-  # - Speedometer 3
-  # - Merging stories over multiple iterations and browsers
-  # - Testing safari
-  # - --verbose flag
-  # - no splashscreen
-  # This fails on the CQ bot, so make sure we skip it there:
-  if driver_path:
-    pytest.skip("Skipping test on CQ.")
-  platform = plt.PLATFORM
-  if not platform.is_macos and (not platform.exists(
-      browsers.Safari.default_path(platform))):
-    pytest.skip("Test requires Safari, skipping on non macOS devices.")
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli("sp2.1", "--browser=chrome", "--browser=safari",
-           "--splashscreen=none", "--iterations=1", "--repeat=2",
-           "--env-validation=skip", "--verbose", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", "--stories=.*React.*")
-
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 2
-  v8_log_files = _get_v8_log_files(results_dir)
-  assert not v8_log_files
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_jetstream_2_0(output_dir, cache_dir) -> None:
-  # - jetstream 2.0
-  # - merge / run separate stories
-  # - custom multiple --js-flags
-  # - custom viewport
-  # - quiet flag
-  with pytest.raises(SysExitException):
-    _run_cli("jetstream_2.0", "--help")
-  _run_cli("describe", "--json", "benchmark", "jetstream_2.0")
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli("jetstream_2.0", "--browser=chrome-stable", "--separate",
-           "--repeat=2", "--env-validation=skip", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", "--viewport=maximised",
-           "--stories=.*date-format.*", "--quiet",
-           "--js-flags=--log,--log-opt,--log-deopt", "--", "--no-sandbox")
-
-  v8_log_files = _get_v8_log_files(results_dir)
-  assert len(v8_log_files) > 1
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 1
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_jetstream_2_1(output_dir, cache_dir, root_dir) -> None:
-  # - jetstream 2.1
-  # - custom --time-unit
-  # - explicit single story
-  # - custom splashscreen
-  # - custom viewport
-  # - --probe-config
-  with pytest.raises(SysExitException):
-    _run_cli("jetstream_2.1", "--help")
-  _run_cli("describe", "benchmark", "jetstream_2.1")
-  probe_config = root_dir / "config/doc/probe.config.hjson"
-  assert probe_config.is_file()
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  chrome_version = "--browser=chrome"
-  _run_cli("jetstream_2.1", chrome_version, "--env-validation=skip",
-           "--splashscreen=http://google.com", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", "--viewport=900x800", "--stories=Box2D",
-           "--time-unit=0.9", f"--probe-config={probe_config}", "--throw")
-
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 1
-  v8_log_files = _get_v8_log_files(results_dir)
-  assert len(v8_log_files) > 1
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_jetstream_2_2(output_dir, cache_dir, root_dir) -> None:
-  # - jetstream 2.2
-  # - custom --time-unit
-  # - explicit single story
-  # - custom splashscreen
-  # - custom viewport
-  # - --probe-config
-  with pytest.raises(SysExitException):
-    _run_cli("jetstream_2.2", "--help")
-  _run_cli("describe", "benchmark", "jetstream_2.2")
-  probe_config = root_dir / "config/doc/probe.config.hjson"
-  assert probe_config.is_file()
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  chrome_version = "--browser=chrome"
-  _run_cli("jetstream_2.2", chrome_version, "--env-validation=skip",
-           "--splashscreen=http://google.com", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", "--viewport=900x800", "--stories=Box2D",
-           "--time-unit=0.9", f"--probe-config={probe_config}", "--throw")
-
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 1
-  v8_log_files = _get_v8_log_files(results_dir)
-  assert len(v8_log_files) > 1
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_loading(output_dir, cache_dir) -> None:
-  # - loading using named pages with timeouts
-  # - custom cooldown time
-  # - custom viewport
-  # - performance.mark probe
-  with pytest.raises(SysExitException):
-    _run_cli("loading", "--help")
-  _run_cli("describe", "benchmark", "loading")
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli("loading", "--browser=chr", "--env-validation=skip",
-           f"--out-dir={results_dir}", f"--cache-dir={cache_dir}",
-           "--viewport=headless", "--stories=cnn", "--cool-down-time=2.5",
-           "--probe=performance.entries")
-
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 1
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-def test_loading_page_config(output_dir, cache_dir, root_dir) -> None:
-  # - loading with config file
-  page_config = root_dir / "config/doc/page.config.hjson"
-  assert page_config.is_file()
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli("loading", "--env-validation=skip", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", f"--page-config={page_config}",
-           "--probe=performance.entries", "--no-splash", "--cool-down-time=0",
-           "--throw")
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_loading_playback_urls(output_dir, cache_dir) -> None:
-  # - loading using url
-  # - combined pages and --playback controller
-  results_dir = output_dir / "results"
-
-  assert not results_dir.exists()
-  _run_cli("loading", "--env-validation=skip", f"--out-dir={results_dir}",
-           f"--cache-dir={cache_dir}", "--playback=5.3s",
-           "--viewport=fullscreen",
-           "--stories=http://google.com,0.5,http://bing.com,0.4",
-           "--probe=performance.entries")
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_loading_playback(output_dir, cache_dir) -> None:
-  # - loading using named pages with timeouts
-  # - separate pages and --playback controller
-  # - viewport-size via chrome flag
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli("loading", "--browser=chr", "--env-validation=skip",
-           f"--out-dir={results_dir}", f"--cache-dir={cache_dir}",
-           "--playback=5.3s", "--separate", "--stories=twitter,2,facebook,0.4",
-           "--probe=performance.entries", "--", "--window-size=900,500",
-           "--window-position=150,150")
-
-
-@pytest.mark.skipif(
-    not plt.PLATFORM.has_display, reason="end2end test cannot run headless")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_linux, reason="Tests temporarily skipped on linux")
-@pytest.mark.skipif(
-    plt.PLATFORM.is_win, reason="Tests temporarily skipped on windows")
-@pytest.mark.xdist_group("end2end-benchmark")
-def test_loading_playback_firefox(output_dir, cache_dir) -> None:
-  # - loading using named pages with timeouts
-  # - --playback controller
-  # - Firefox
-  platform = plt.PLATFORM
-  try:
-    if not platform.exists(browsers.Firefox.default_path(platform)):
-      pytest.skip("Test requires Firefox.")
-  except Exception:  # pylint: disable=broad-exception-caught
-    pytest.skip("Test requires Firefox.")
-  results_dir = output_dir / "results"
-  assert not results_dir.exists()
-  _run_cli("loading", "--browser=chr", "--browser=ff", "--env-validation=skip",
-           f"--out-dir={results_dir}", f"--cache-dir={cache_dir}",
-           "--playback=2x", "--stories=twitter,1,facebook,0.4",
-           "--probe=performance.entries")
-
-  browser_dirs = _get_browser_dirs(results_dir)
-  assert len(browser_dirs) == 2
-
-
-if __name__ == "__main__":
-  test_helper.run_pytest(__file__)
diff --git a/tests/pytest.ini b/tests/pytest.ini
new file mode 100644
index 00000000..44e6cf35
--- /dev/null
+++ b/tests/pytest.ini
@@ -0,0 +1,8 @@
+# Copyright 2025 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+[pytest]
+markers =
+    skip_mock: Tests which can skip mocking
+    flaky: mark a test as flaky to retry if it fails
diff --git a/tests/test_helper.py b/tests/test_helper.py
index 3bf604ff..bc842ccf 100644
--- a/tests/test_helper.py
+++ b/tests/test_helper.py
@@ -4,9 +4,12 @@
 
 from __future__ import annotations
 
+import os
 import pathlib
+import shutil
 import sys
-from typing import Union
+from dataclasses import dataclass, field
+from typing import Any, Tuple
 
 import pytest
 
@@ -23,7 +26,53 @@ def crossbench_dir() -> pathlib.Path:
   return root_dir() / "crossbench"
 
 
-def run_pytest(path: Union[str, pathlib.Path], *args):
+def is_on_swarming():
+  return "SWARMING_SERVER" in os.environ
+
+
+@dataclass(frozen=True)
+class TestEnv():
+  # Avoid getting PytestCollectionWarning as the class name starts with Test.
+  __test__ = False
+
+  output_dir: pathlib.Path
+  test_name: str
+  is_cq: bool = field(init=False)
+  cq_flags: Tuple[str, ...] = field(init=False)
+  archive_dir: pathlib.Path = field(init=False)
+  results_dir: pathlib.Path = field(init=False)
+  root_dir: pathlib.Path = field(init=False)
+
+  def __post_init__(self):
+    output_path = pathlib.Path(self.output_dir)
+    self._set("is_cq", output_path.parts[-1].startswith("cq_archive_"))
+    self._set("cq_flags", ("--no-symlinks",) if self.is_cq else ())
+    run_seq = 0
+    while True:
+      self._set("output_dir", output_path / self.test_name / str(run_seq))
+      if not self.output_dir.exists():
+        break
+      run_seq += 1
+    self.output_dir.mkdir(parents=True)
+    self._set("archive_dir", self.output_dir / "browser_archive")
+    assert not self.archive_dir.exists()
+    self._set("results_dir", self.output_dir / "results")
+    assert not self.results_dir.exists()
+    self._set("root_dir", root_dir())
+
+  def _set(self, attr: str, value: Any):
+    object.__setattr__(self, attr, value)
+
+  def remove_non_result(self):
+    for output_path in self.output_dir.iterdir():
+      if output_path.is_dir() and output_path != self.results_dir:
+        shutil.rmtree(output_path)
+
+  def assert_empty_output_dir(self):
+    assert not tuple(self.output_dir.glob("**/*"))
+
+
+def run_pytest(path: str | pathlib.Path, *args):
   extra_args = [*args, *sys.argv[1:]]
   # Run tests single-threaded by default when running the test file directly.
   if "-n" not in extra_args:
```

